<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff src/hotspot/share/opto/macro.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="machnode.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.hpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/macro.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,7 ***</span>
  /*
<span class="line-modified">!  * Copyright (c) 2005, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
<span class="line-new-header">--- 1,7 ---</span>
  /*
<span class="line-modified">!  * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 24,18 ***</span>
<span class="line-new-header">--- 24,20 ---</span>
  
  #include &quot;precompiled.hpp&quot;
  #include &quot;compiler/compileLog.hpp&quot;
  #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  #include &quot;libadt/vectset.hpp&quot;
<span class="line-added">+ #include &quot;memory/universe.hpp&quot;</span>
  #include &quot;opto/addnode.hpp&quot;
  #include &quot;opto/arraycopynode.hpp&quot;
  #include &quot;opto/callnode.hpp&quot;
  #include &quot;opto/castnode.hpp&quot;
  #include &quot;opto/cfgnode.hpp&quot;
  #include &quot;opto/compile.hpp&quot;
  #include &quot;opto/convertnode.hpp&quot;
  #include &quot;opto/graphKit.hpp&quot;
<span class="line-added">+ #include &quot;opto/intrinsicnode.hpp&quot;</span>
  #include &quot;opto/locknode.hpp&quot;
  #include &quot;opto/loopnode.hpp&quot;
  #include &quot;opto/macro.hpp&quot;
  #include &quot;opto/memnode.hpp&quot;
  #include &quot;opto/narrowptrnode.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 43,13 ***</span>
<span class="line-new-header">--- 45,15 ---</span>
  #include &quot;opto/opaquenode.hpp&quot;
  #include &quot;opto/phaseX.hpp&quot;
  #include &quot;opto/rootnode.hpp&quot;
  #include &quot;opto/runtime.hpp&quot;
  #include &quot;opto/subnode.hpp&quot;
<span class="line-added">+ #include &quot;opto/subtypenode.hpp&quot;</span>
  #include &quot;opto/type.hpp&quot;
  #include &quot;runtime/sharedRuntime.hpp&quot;
  #include &quot;utilities/macros.hpp&quot;
<span class="line-added">+ #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  #if INCLUDE_G1GC
  #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
  #endif // INCLUDE_G1GC
  #if INCLUDE_SHENANDOAHGC
  #include &quot;gc/shenandoah/c2/shenandoahBarrierSetC2.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 76,10 ***</span>
<span class="line-new-header">--- 80,22 ---</span>
      }
    }
    return nreplacements;
  }
  
<span class="line-added">+ void PhaseMacroExpand::migrate_outs(Node *old, Node *target) {</span>
<span class="line-added">+   assert(old != NULL, &quot;sanity&quot;);</span>
<span class="line-added">+   for (DUIterator_Fast imax, i = old-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-added">+     Node* use = old-&gt;fast_out(i);</span>
<span class="line-added">+     _igvn.rehash_node_delayed(use);</span>
<span class="line-added">+     imax -= replace_input(use, old, target);</span>
<span class="line-added">+     // back up iterator</span>
<span class="line-added">+     --i;</span>
<span class="line-added">+   }</span>
<span class="line-added">+   assert(old-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  void PhaseMacroExpand::copy_call_debug_info(CallNode *oldcall, CallNode * newcall) {
    // Copy debug information and adjust JVMState information
    uint old_dbg_start = oldcall-&gt;tf()-&gt;domain()-&gt;cnt();
    uint new_dbg_start = newcall-&gt;tf()-&gt;domain()-&gt;cnt();
    int jvms_adj  = new_dbg_start - old_dbg_start;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 345,29 ***</span>
      bt = T_OBJECT;
      type = ftype-&gt;make_oopptr();
    }
    Node* res = NULL;
    if (ac-&gt;is_clonebasic()) {
      Node* base = ac-&gt;in(ArrayCopyNode::Src)-&gt;in(AddPNode::Base);
      Node* adr = _igvn.transform(new AddPNode(base, base, MakeConX(offset)));
      const TypePtr* adr_type = _igvn.type(base)-&gt;is_ptr()-&gt;add_offset(offset);
<span class="line-modified">!     res = LoadNode::make(_igvn, ctl, mem, adr, adr_type, type, bt, MemNode::unordered, LoadNode::Pinned);</span>
    } else {
      if (ac-&gt;modifies(offset, offset, &amp;_igvn, true)) {
        assert(ac-&gt;in(ArrayCopyNode::Dest) == alloc-&gt;result_cast(), &quot;arraycopy destination should be allocation&#39;s result&quot;);
<span class="line-modified">!       uint shift  = exact_log2(type2aelembytes(bt));</span>
<span class="line-modified">!       Node* diff = _igvn.transform(new SubINode(ac-&gt;in(ArrayCopyNode::SrcPos), ac-&gt;in(ArrayCopyNode::DestPos)));</span>
  #ifdef _LP64
<span class="line-modified">!       diff = _igvn.transform(new ConvI2LNode(diff));</span>
  #endif
<span class="line-modified">!       diff = _igvn.transform(new LShiftXNode(diff, intcon(shift)));</span>
<span class="line-modified">! </span>
<span class="line-modified">!       Node* off = _igvn.transform(new AddXNode(MakeConX(offset), diff));</span>
<span class="line-modified">!       Node* base = ac-&gt;in(ArrayCopyNode::Src);</span>
<span class="line-modified">!       Node* adr = _igvn.transform(new AddPNode(base, base, off));</span>
<span class="line-modified">!       const TypePtr* adr_type = _igvn.type(base)-&gt;is_ptr()-&gt;add_offset(offset);</span>
<span class="line-modified">!       res = LoadNode::make(_igvn, ctl, mem, adr, adr_type, type, bt, MemNode::unordered, LoadNode::Pinned);</span>
      }
    }
    if (res != NULL) {
      res = _igvn.transform(res);
      if (ftype-&gt;isa_narrowoop()) {
<span class="line-new-header">--- 361,53 ---</span>
      bt = T_OBJECT;
      type = ftype-&gt;make_oopptr();
    }
    Node* res = NULL;
    if (ac-&gt;is_clonebasic()) {
<span class="line-added">+     assert(ac-&gt;in(ArrayCopyNode::Src) != ac-&gt;in(ArrayCopyNode::Dest), &quot;clone source equals destination&quot;);</span>
      Node* base = ac-&gt;in(ArrayCopyNode::Src)-&gt;in(AddPNode::Base);
      Node* adr = _igvn.transform(new AddPNode(base, base, MakeConX(offset)));
      const TypePtr* adr_type = _igvn.type(base)-&gt;is_ptr()-&gt;add_offset(offset);
<span class="line-modified">!     res = LoadNode::make(_igvn, ctl, mem, adr, adr_type, type, bt, MemNode::unordered, LoadNode::UnknownControl);</span>
    } else {
      if (ac-&gt;modifies(offset, offset, &amp;_igvn, true)) {
        assert(ac-&gt;in(ArrayCopyNode::Dest) == alloc-&gt;result_cast(), &quot;arraycopy destination should be allocation&#39;s result&quot;);
<span class="line-modified">!       uint shift = exact_log2(type2aelembytes(bt));</span>
<span class="line-modified">!       Node* src_pos = ac-&gt;in(ArrayCopyNode::SrcPos);</span>
<span class="line-added">+       Node* dest_pos = ac-&gt;in(ArrayCopyNode::DestPos);</span>
<span class="line-added">+       const TypeInt* src_pos_t = _igvn.type(src_pos)-&gt;is_int();</span>
<span class="line-added">+       const TypeInt* dest_pos_t = _igvn.type(dest_pos)-&gt;is_int();</span>
<span class="line-added">+ </span>
<span class="line-added">+       Node* adr = NULL;</span>
<span class="line-added">+       const TypePtr* adr_type = NULL;</span>
<span class="line-added">+       if (src_pos_t-&gt;is_con() &amp;&amp; dest_pos_t-&gt;is_con()) {</span>
<span class="line-added">+         intptr_t off = ((src_pos_t-&gt;get_con() - dest_pos_t-&gt;get_con()) &lt;&lt; shift) + offset;</span>
<span class="line-added">+         Node* base = ac-&gt;in(ArrayCopyNode::Src);</span>
<span class="line-added">+         adr = _igvn.transform(new AddPNode(base, base, MakeConX(off)));</span>
<span class="line-added">+         adr_type = _igvn.type(base)-&gt;is_ptr()-&gt;add_offset(off);</span>
<span class="line-added">+         if (ac-&gt;in(ArrayCopyNode::Src) == ac-&gt;in(ArrayCopyNode::Dest)) {</span>
<span class="line-added">+           // Don&#39;t emit a new load from src if src == dst but try to get the value from memory instead</span>
<span class="line-added">+           return value_from_mem(ac-&gt;in(TypeFunc::Memory), ctl, ft, ftype, adr_type-&gt;isa_oopptr(), alloc);</span>
<span class="line-added">+         }</span>
<span class="line-added">+       } else {</span>
<span class="line-added">+         Node* diff = _igvn.transform(new SubINode(ac-&gt;in(ArrayCopyNode::SrcPos), ac-&gt;in(ArrayCopyNode::DestPos)));</span>
  #ifdef _LP64
<span class="line-modified">!         diff = _igvn.transform(new ConvI2LNode(diff));</span>
  #endif
<span class="line-modified">!         diff = _igvn.transform(new LShiftXNode(diff, intcon(shift)));</span>
<span class="line-modified">! </span>
<span class="line-modified">!         Node* off = _igvn.transform(new AddXNode(MakeConX(offset), diff));</span>
<span class="line-modified">!         Node* base = ac-&gt;in(ArrayCopyNode::Src);</span>
<span class="line-modified">!         adr = _igvn.transform(new AddPNode(base, base, off));</span>
<span class="line-modified">!         adr_type = _igvn.type(base)-&gt;is_ptr()-&gt;add_offset(Type::OffsetBot);</span>
<span class="line-modified">!         if (ac-&gt;in(ArrayCopyNode::Src) == ac-&gt;in(ArrayCopyNode::Dest)) {</span>
<span class="line-added">+           // Non constant offset in the array: we can&#39;t statically</span>
<span class="line-added">+           // determine the value</span>
<span class="line-added">+           return NULL;</span>
<span class="line-added">+         }</span>
<span class="line-added">+       }</span>
<span class="line-added">+       res = LoadNode::make(_igvn, ctl, mem, adr, adr_type, type, bt, MemNode::unordered, LoadNode::UnknownControl);</span>
      }
    }
    if (res != NULL) {
      res = _igvn.transform(res);
      if (ftype-&gt;isa_narrowoop()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 494,11 ***</span>
    Node *alloc_ctrl = alloc-&gt;in(TypeFunc::Control);
    Node *alloc_mem = alloc-&gt;in(TypeFunc::Memory);
    Arena *a = Thread::current()-&gt;resource_area();
    VectorSet visited(a);
  
<span class="line-removed">- </span>
    bool done = sfpt_mem == alloc_mem;
    Node *mem = sfpt_mem;
    while (!done) {
      if (visited.test_set(mem-&gt;_idx)) {
        return NULL;  // found a loop, give up
<span class="line-new-header">--- 534,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 784,11 ***</span>
          offset = array_base + j * (intptr_t)element_size;
        }
  
        const Type *field_type;
        // The next code is taken from Parse::do_get_xxx().
<span class="line-modified">!       if (basic_elem_type == T_OBJECT || basic_elem_type == T_ARRAY) {</span>
          if (!elem_type-&gt;is_loaded()) {
            field_type = TypeInstPtr::BOTTOM;
          } else if (field != NULL &amp;&amp; field-&gt;is_static_constant()) {
            // This can happen if the constant oop is non-perm.
            ciObject* con = field-&gt;constant_value().as_object();
<span class="line-new-header">--- 823,11 ---</span>
          offset = array_base + j * (intptr_t)element_size;
        }
  
        const Type *field_type;
        // The next code is taken from Parse::do_get_xxx().
<span class="line-modified">!       if (is_reference_type(basic_elem_type)) {</span>
          if (!elem_type-&gt;is_loaded()) {
            field_type = TypeInstPtr::BOTTOM;
          } else if (field != NULL &amp;&amp; field-&gt;is_static_constant()) {
            // This can happen if the constant oop is non-perm.
            ciObject* con = field-&gt;constant_value().as_object();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1005,12 ***</span>
          // Eliminate Initialize node.
          InitializeNode *init = use-&gt;as_Initialize();
          assert(init-&gt;outcnt() &lt;= 2, &quot;only a control and memory projection expected&quot;);
          Node *ctrl_proj = init-&gt;proj_out_or_null(TypeFunc::Control);
          if (ctrl_proj != NULL) {
<span class="line-modified">!            assert(init-&gt;in(TypeFunc::Control) == _fallthroughcatchproj, &quot;allocation control projection&quot;);</span>
<span class="line-modified">!           _igvn.replace_node(ctrl_proj, _fallthroughcatchproj);</span>
          }
          Node *mem_proj = init-&gt;proj_out_or_null(TypeFunc::Memory);
          if (mem_proj != NULL) {
            Node *mem = init-&gt;in(TypeFunc::Memory);
  #ifdef ASSERT
<span class="line-new-header">--- 1044,15 ---</span>
          // Eliminate Initialize node.
          InitializeNode *init = use-&gt;as_Initialize();
          assert(init-&gt;outcnt() &lt;= 2, &quot;only a control and memory projection expected&quot;);
          Node *ctrl_proj = init-&gt;proj_out_or_null(TypeFunc::Control);
          if (ctrl_proj != NULL) {
<span class="line-modified">!           _igvn.replace_node(ctrl_proj, init-&gt;in(TypeFunc::Control));</span>
<span class="line-modified">! #ifdef ASSERT</span>
<span class="line-added">+           Node* tmp = init-&gt;in(TypeFunc::Control);</span>
<span class="line-added">+           assert(tmp == _fallthroughcatchproj, &quot;allocation control projection&quot;);</span>
<span class="line-added">+ #endif</span>
          }
          Node *mem_proj = init-&gt;proj_out_or_null(TypeFunc::Memory);
          if (mem_proj != NULL) {
            Node *mem = init-&gt;in(TypeFunc::Memory);
  #ifdef ASSERT
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1248,53 ***</span>
              Node* length,  // array length for an array allocation
              const TypeFunc* slow_call_type, // Type of slow call
              address slow_call_address  // Address of slow call
      )
  {
<span class="line-removed">- </span>
    Node* ctrl = alloc-&gt;in(TypeFunc::Control);
    Node* mem  = alloc-&gt;in(TypeFunc::Memory);
    Node* i_o  = alloc-&gt;in(TypeFunc::I_O);
    Node* size_in_bytes     = alloc-&gt;in(AllocateNode::AllocSize);
    Node* klass_node        = alloc-&gt;in(AllocateNode::KlassNode);
    Node* initial_slow_test = alloc-&gt;in(AllocateNode::InitialTest);
<span class="line-removed">- </span>
    assert(ctrl != NULL, &quot;must have control&quot;);
    // We need a Region and corresponding Phi&#39;s to merge the slow-path and fast-path results.
    // they will not be used if &quot;always_slow&quot; is set
    enum { slow_result_path = 1, fast_result_path = 2 };
    Node *result_region = NULL;
    Node *result_phi_rawmem = NULL;
    Node *result_phi_rawoop = NULL;
    Node *result_phi_i_o = NULL;
  
    // The initial slow comparison is a size check, the comparison
    // we want to do is a BoolTest::gt
<span class="line-modified">!   bool always_slow = false;</span>
    int tv = _igvn.find_int_con(initial_slow_test, -1);
    if (tv &gt;= 0) {
<span class="line-modified">!     always_slow = (tv == 1);</span>
      initial_slow_test = NULL;
    } else {
      initial_slow_test = BoolNode::make_predicate(initial_slow_test, &amp;_igvn);
    }
  
    if (C-&gt;env()-&gt;dtrace_alloc_probes() ||
        (!UseTLAB &amp;&amp; !Universe::heap()-&gt;supports_inline_contig_alloc())) {
      // Force slow-path allocation
<span class="line-modified">!     always_slow = true;</span>
      initial_slow_test = NULL;
    }
  
  
    enum { too_big_or_final_path = 1, need_gc_path = 2 };
    Node *slow_region = NULL;
    Node *toobig_false = ctrl;
  
<span class="line-removed">-   assert (initial_slow_test == NULL || !always_slow, &quot;arguments must be consistent&quot;);</span>
    // generate the initial test if necessary
    if (initial_slow_test != NULL ) {
      slow_region = new RegionNode(3);
  
      // Now make the initial failure test.  Usually a too-big test but
      // might be a TRUE for finalizers or a fancy class check for
      // newInstance0.
<span class="line-new-header">--- 1290,72 ---</span>
              Node* length,  // array length for an array allocation
              const TypeFunc* slow_call_type, // Type of slow call
              address slow_call_address  // Address of slow call
      )
  {
    Node* ctrl = alloc-&gt;in(TypeFunc::Control);
    Node* mem  = alloc-&gt;in(TypeFunc::Memory);
    Node* i_o  = alloc-&gt;in(TypeFunc::I_O);
    Node* size_in_bytes     = alloc-&gt;in(AllocateNode::AllocSize);
    Node* klass_node        = alloc-&gt;in(AllocateNode::KlassNode);
    Node* initial_slow_test = alloc-&gt;in(AllocateNode::InitialTest);
    assert(ctrl != NULL, &quot;must have control&quot;);
<span class="line-added">+ </span>
    // We need a Region and corresponding Phi&#39;s to merge the slow-path and fast-path results.
    // they will not be used if &quot;always_slow&quot; is set
    enum { slow_result_path = 1, fast_result_path = 2 };
    Node *result_region = NULL;
    Node *result_phi_rawmem = NULL;
    Node *result_phi_rawoop = NULL;
    Node *result_phi_i_o = NULL;
  
    // The initial slow comparison is a size check, the comparison
    // we want to do is a BoolTest::gt
<span class="line-modified">!   bool expand_fast_path = true;</span>
    int tv = _igvn.find_int_con(initial_slow_test, -1);
    if (tv &gt;= 0) {
<span class="line-modified">!     // InitialTest has constant result</span>
<span class="line-added">+     //   0 - can fit in TLAB</span>
<span class="line-added">+     //   1 - always too big or negative</span>
<span class="line-added">+     assert(tv &lt;= 1, &quot;0 or 1 if a constant&quot;);</span>
<span class="line-added">+     expand_fast_path = (tv == 0);</span>
      initial_slow_test = NULL;
    } else {
      initial_slow_test = BoolNode::make_predicate(initial_slow_test, &amp;_igvn);
    }
  
    if (C-&gt;env()-&gt;dtrace_alloc_probes() ||
        (!UseTLAB &amp;&amp; !Universe::heap()-&gt;supports_inline_contig_alloc())) {
      // Force slow-path allocation
<span class="line-modified">!     expand_fast_path = false;</span>
      initial_slow_test = NULL;
    }
  
<span class="line-added">+   bool allocation_has_use = (alloc-&gt;result_cast() != NULL);</span>
<span class="line-added">+   if (!allocation_has_use) {</span>
<span class="line-added">+     InitializeNode* init = alloc-&gt;initialization();</span>
<span class="line-added">+     if (init != NULL) {</span>
<span class="line-added">+       yank_initalize_node(init);</span>
<span class="line-added">+       assert(init-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);</span>
<span class="line-added">+       _igvn.remove_dead_node(init);</span>
<span class="line-added">+     }</span>
<span class="line-added">+     if (expand_fast_path &amp;&amp; (initial_slow_test == NULL)) {</span>
<span class="line-added">+       // Remove allocation node and return.</span>
<span class="line-added">+       // Size is a non-negative constant -&gt; no initial check needed -&gt; directly to fast path.</span>
<span class="line-added">+       // Also, no usages -&gt; empty fast path -&gt; no fall out to slow path -&gt; nothing left.</span>
<span class="line-added">+       yank_alloc_node(alloc);</span>
<span class="line-added">+       return;</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
  
    enum { too_big_or_final_path = 1, need_gc_path = 2 };
    Node *slow_region = NULL;
    Node *toobig_false = ctrl;
  
    // generate the initial test if necessary
    if (initial_slow_test != NULL ) {
<span class="line-added">+     assert (expand_fast_path, &quot;Only need test if there is a fast path&quot;);</span>
      slow_region = new RegionNode(3);
  
      // Now make the initial failure test.  Usually a too-big test but
      // might be a TRUE for finalizers or a fancy class check for
      // newInstance0.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1304,157 ***</span>
      Node *toobig_true = new IfTrueNode( toobig_iff );
      transform_later(toobig_true);
      slow_region    -&gt;init_req( too_big_or_final_path, toobig_true );
      toobig_false = new IfFalseNode( toobig_iff );
      transform_later(toobig_false);
<span class="line-modified">!   } else {         // No initial test, just fall into next case</span>
      toobig_false = ctrl;
      debug_only(slow_region = NodeSentinel);
    }
  
    Node *slow_mem = mem;  // save the current memory state for slow path
    // generate the fast allocation code unless we know that the initial test will always go slow
<span class="line-modified">!   if (!always_slow) {</span>
      // Fast path modifies only raw memory.
      if (mem-&gt;is_MergeMem()) {
        mem = mem-&gt;as_MergeMem()-&gt;memory_at(Compile::AliasIdxRaw);
      }
  
      // allocate the Region and Phi nodes for the result
      result_region = new RegionNode(3);
      result_phi_rawmem = new PhiNode(result_region, Type::MEMORY, TypeRawPtr::BOTTOM);
<span class="line-removed">-     result_phi_rawoop = new PhiNode(result_region, TypeRawPtr::BOTTOM);</span>
      result_phi_i_o    = new PhiNode(result_region, Type::ABIO); // I/O is used for Prefetch
  
      // Grab regular I/O before optional prefetch may change it.
      // Slow-path does no I/O so just set it to the original I/O.
      result_phi_i_o-&gt;init_req(slow_result_path, i_o);
  
<span class="line-removed">-     Node* needgc_ctrl = NULL;</span>
      // Name successful fast-path variables
      Node* fast_oop_ctrl;
      Node* fast_oop_rawmem;
  
<span class="line-modified">!     intx prefetch_lines = length != NULL ? AllocatePrefetchLines : AllocateInstancePrefetchLines;</span>
<span class="line-modified">! </span>
<span class="line-modified">!     BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();</span>
<span class="line-modified">!     Node* fast_oop = bs-&gt;obj_allocate(this, ctrl, mem, toobig_false, size_in_bytes, i_o, needgc_ctrl,</span>
<span class="line-modified">!                                       fast_oop_ctrl, fast_oop_rawmem,</span>
<span class="line-modified">!                                       prefetch_lines);</span>
<span class="line-modified">! </span>
<span class="line-modified">!     if (initial_slow_test) {</span>
<span class="line-modified">!       slow_region-&gt;init_req(need_gc_path, needgc_ctrl);</span>
<span class="line-modified">!       // This completes all paths into the slow merge point</span>
<span class="line-removed">-       transform_later(slow_region);</span>
<span class="line-removed">-     } else {                      // No initial slow path needed!</span>
<span class="line-removed">-       // Just fall from the need-GC path straight into the VM call.</span>
<span class="line-removed">-       slow_region = needgc_ctrl;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
<span class="line-removed">-     InitializeNode* init = alloc-&gt;initialization();</span>
<span class="line-removed">-     fast_oop_rawmem = initialize_object(alloc,</span>
<span class="line-removed">-                                         fast_oop_ctrl, fast_oop_rawmem, fast_oop,</span>
<span class="line-removed">-                                         klass_node, length, size_in_bytes);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     // If initialization is performed by an array copy, any required</span>
<span class="line-removed">-     // MemBarStoreStore was already added. If the object does not</span>
<span class="line-removed">-     // escape no need for a MemBarStoreStore. If the object does not</span>
<span class="line-removed">-     // escape in its initializer and memory barrier (MemBarStoreStore or</span>
<span class="line-removed">-     // stronger) is already added at exit of initializer, also no need</span>
<span class="line-removed">-     // for a MemBarStoreStore. Otherwise we need a MemBarStoreStore</span>
<span class="line-removed">-     // so that stores that initialize this object can&#39;t be reordered</span>
<span class="line-removed">-     // with a subsequent store that makes this object accessible by</span>
<span class="line-removed">-     // other threads.</span>
<span class="line-removed">-     // Other threads include java threads and JVM internal threads</span>
<span class="line-removed">-     // (for example concurrent GC threads). Current concurrent GC</span>
<span class="line-removed">-     // implementation: CMS and G1 will not scan newly created object,</span>
<span class="line-removed">-     // so it&#39;s safe to skip storestore barrier when allocation does</span>
<span class="line-removed">-     // not escape.</span>
<span class="line-removed">-     if (!alloc-&gt;does_not_escape_thread() &amp;&amp;</span>
<span class="line-removed">-         !alloc-&gt;is_allocation_MemBar_redundant() &amp;&amp;</span>
<span class="line-removed">-         (init == NULL || !init-&gt;is_complete_with_arraycopy())) {</span>
<span class="line-removed">-       if (init == NULL || init-&gt;req() &lt; InitializeNode::RawStores) {</span>
<span class="line-removed">-         // No InitializeNode or no stores captured by zeroing</span>
<span class="line-removed">-         // elimination. Simply add the MemBarStoreStore after object</span>
<span class="line-removed">-         // initialization.</span>
<span class="line-removed">-         MemBarNode* mb = MemBarNode::make(C, Op_MemBarStoreStore, Compile::AliasIdxBot);</span>
<span class="line-removed">-         transform_later(mb);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         mb-&gt;init_req(TypeFunc::Memory, fast_oop_rawmem);</span>
<span class="line-removed">-         mb-&gt;init_req(TypeFunc::Control, fast_oop_ctrl);</span>
<span class="line-removed">-         fast_oop_ctrl = new ProjNode(mb,TypeFunc::Control);</span>
<span class="line-removed">-         transform_later(fast_oop_ctrl);</span>
<span class="line-removed">-         fast_oop_rawmem = new ProjNode(mb,TypeFunc::Memory);</span>
<span class="line-removed">-         transform_later(fast_oop_rawmem);</span>
        } else {
<span class="line-modified">!         // Add the MemBarStoreStore after the InitializeNode so that</span>
<span class="line-modified">!         // all stores performing the initialization that were moved</span>
<span class="line-modified">!         // before the InitializeNode happen before the storestore</span>
<span class="line-removed">-         // barrier.</span>
<span class="line-removed">- </span>
<span class="line-removed">-         Node* init_ctrl = init-&gt;proj_out_or_null(TypeFunc::Control);</span>
<span class="line-removed">-         Node* init_mem = init-&gt;proj_out_or_null(TypeFunc::Memory);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         MemBarNode* mb = MemBarNode::make(C, Op_MemBarStoreStore, Compile::AliasIdxBot);</span>
<span class="line-removed">-         transform_later(mb);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         Node* ctrl = new ProjNode(init,TypeFunc::Control);</span>
<span class="line-removed">-         transform_later(ctrl);</span>
<span class="line-removed">-         Node* mem = new ProjNode(init,TypeFunc::Memory);</span>
<span class="line-removed">-         transform_later(mem);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         // The MemBarStoreStore depends on control and memory coming</span>
<span class="line-removed">-         // from the InitializeNode</span>
<span class="line-removed">-         mb-&gt;init_req(TypeFunc::Memory, mem);</span>
<span class="line-removed">-         mb-&gt;init_req(TypeFunc::Control, ctrl);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         ctrl = new ProjNode(mb,TypeFunc::Control);</span>
<span class="line-removed">-         transform_later(ctrl);</span>
<span class="line-removed">-         mem = new ProjNode(mb,TypeFunc::Memory);</span>
<span class="line-removed">-         transform_later(mem);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         // All nodes that depended on the InitializeNode for control</span>
<span class="line-removed">-         // and memory must now depend on the MemBarNode that itself</span>
<span class="line-removed">-         // depends on the InitializeNode</span>
<span class="line-removed">-         if (init_ctrl != NULL) {</span>
<span class="line-removed">-           _igvn.replace_node(init_ctrl, ctrl);</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-         if (init_mem != NULL) {</span>
<span class="line-removed">-           _igvn.replace_node(init_mem, mem);</span>
<span class="line-removed">-         }</span>
        }
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
<span class="line-removed">-     if (C-&gt;env()-&gt;dtrace_extended_probes()) {</span>
<span class="line-removed">-       // Slow-path call</span>
<span class="line-removed">-       int size = TypeFunc::Parms + 2;</span>
<span class="line-removed">-       CallLeafNode *call = new CallLeafNode(OptoRuntime::dtrace_object_alloc_Type(),</span>
<span class="line-removed">-                                             CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc_base),</span>
<span class="line-removed">-                                             &quot;dtrace_object_alloc&quot;,</span>
<span class="line-removed">-                                             TypeRawPtr::BOTTOM);</span>
  
<span class="line-modified">!       // Get base of thread-local storage area</span>
<span class="line-modified">!       Node* thread = new ThreadLocalNode();</span>
<span class="line-modified">!       transform_later(thread);</span>
  
<span class="line-modified">!       call-&gt;init_req(TypeFunc::Parms+0, thread);</span>
<span class="line-modified">!       call-&gt;init_req(TypeFunc::Parms+1, fast_oop);</span>
<span class="line-modified">!       call-&gt;init_req(TypeFunc::Control, fast_oop_ctrl);</span>
<span class="line-modified">!       call-&gt;init_req(TypeFunc::I_O    , top()); // does no i/o</span>
<span class="line-modified">!       call-&gt;init_req(TypeFunc::Memory , fast_oop_rawmem);</span>
<span class="line-modified">!       call-&gt;init_req(TypeFunc::ReturnAdr, alloc-&gt;in(TypeFunc::ReturnAdr));</span>
<span class="line-removed">-       call-&gt;init_req(TypeFunc::FramePtr, alloc-&gt;in(TypeFunc::FramePtr));</span>
<span class="line-removed">-       transform_later(call);</span>
<span class="line-removed">-       fast_oop_ctrl = new ProjNode(call,TypeFunc::Control);</span>
<span class="line-removed">-       transform_later(fast_oop_ctrl);</span>
<span class="line-removed">-       fast_oop_rawmem = new ProjNode(call,TypeFunc::Memory);</span>
<span class="line-removed">-       transform_later(fast_oop_rawmem);</span>
      }
  
      // Plug in the successful fast-path into the result merge point
      result_region    -&gt;init_req(fast_result_path, fast_oop_ctrl);
<span class="line-removed">-     result_phi_rawoop-&gt;init_req(fast_result_path, fast_oop);</span>
      result_phi_i_o   -&gt;init_req(fast_result_path, i_o);
      result_phi_rawmem-&gt;init_req(fast_result_path, fast_oop_rawmem);
    } else {
      slow_region = ctrl;
      result_phi_i_o = i_o; // Rename it to use in the following code.
<span class="line-new-header">--- 1365,84 ---</span>
      Node *toobig_true = new IfTrueNode( toobig_iff );
      transform_later(toobig_true);
      slow_region    -&gt;init_req( too_big_or_final_path, toobig_true );
      toobig_false = new IfFalseNode( toobig_iff );
      transform_later(toobig_false);
<span class="line-modified">!   } else {</span>
<span class="line-added">+     // No initial test, just fall into next case</span>
<span class="line-added">+     assert(allocation_has_use || !expand_fast_path, &quot;Should already have been handled&quot;);</span>
      toobig_false = ctrl;
      debug_only(slow_region = NodeSentinel);
    }
  
<span class="line-added">+   // If we are here there are several possibilities</span>
<span class="line-added">+   // - expand_fast_path is false - then only a slow path is expanded. That&#39;s it.</span>
<span class="line-added">+   // no_initial_check means a constant allocation.</span>
<span class="line-added">+   // - If check always evaluates to false -&gt; expand_fast_path is false (see above)</span>
<span class="line-added">+   // - If check always evaluates to true -&gt; directly into fast path (but may bailout to slowpath)</span>
<span class="line-added">+   // if !allocation_has_use the fast path is empty</span>
<span class="line-added">+   // if !allocation_has_use &amp;&amp; no_initial_check</span>
<span class="line-added">+   // - Then there are no fastpath that can fall out to slowpath -&gt; no allocation code at all.</span>
<span class="line-added">+   //   removed by yank_alloc_node above.</span>
<span class="line-added">+ </span>
    Node *slow_mem = mem;  // save the current memory state for slow path
    // generate the fast allocation code unless we know that the initial test will always go slow
<span class="line-modified">!   if (expand_fast_path) {</span>
      // Fast path modifies only raw memory.
      if (mem-&gt;is_MergeMem()) {
        mem = mem-&gt;as_MergeMem()-&gt;memory_at(Compile::AliasIdxRaw);
      }
  
      // allocate the Region and Phi nodes for the result
      result_region = new RegionNode(3);
      result_phi_rawmem = new PhiNode(result_region, Type::MEMORY, TypeRawPtr::BOTTOM);
      result_phi_i_o    = new PhiNode(result_region, Type::ABIO); // I/O is used for Prefetch
  
      // Grab regular I/O before optional prefetch may change it.
      // Slow-path does no I/O so just set it to the original I/O.
      result_phi_i_o-&gt;init_req(slow_result_path, i_o);
  
      // Name successful fast-path variables
      Node* fast_oop_ctrl;
      Node* fast_oop_rawmem;
<span class="line-added">+     if (allocation_has_use) {</span>
<span class="line-added">+       Node* needgc_ctrl = NULL;</span>
<span class="line-added">+       result_phi_rawoop = new PhiNode(result_region, TypeRawPtr::BOTTOM);</span>
  
<span class="line-modified">!       intx prefetch_lines = length != NULL ? AllocatePrefetchLines : AllocateInstancePrefetchLines;</span>
<span class="line-modified">!       BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();</span>
<span class="line-modified">!       Node* fast_oop = bs-&gt;obj_allocate(this, ctrl, mem, toobig_false, size_in_bytes, i_o, needgc_ctrl,</span>
<span class="line-modified">!                                         fast_oop_ctrl, fast_oop_rawmem,</span>
<span class="line-modified">!                                         prefetch_lines);</span>
<span class="line-modified">! </span>
<span class="line-modified">!       if (initial_slow_test != NULL) {</span>
<span class="line-modified">!         // This completes all paths into the slow merge point</span>
<span class="line-modified">!         slow_region-&gt;init_req(need_gc_path, needgc_ctrl);</span>
<span class="line-modified">!         transform_later(slow_region);</span>
        } else {
<span class="line-modified">!         // No initial slow path needed!</span>
<span class="line-modified">!         // Just fall from the need-GC path straight into the VM call.</span>
<span class="line-modified">!         slow_region = needgc_ctrl;</span>
        }
  
<span class="line-modified">!       InitializeNode* init = alloc-&gt;initialization();</span>
<span class="line-modified">!       fast_oop_rawmem = initialize_object(alloc,</span>
<span class="line-modified">!                                           fast_oop_ctrl, fast_oop_rawmem, fast_oop,</span>
<span class="line-added">+                                           klass_node, length, size_in_bytes);</span>
<span class="line-added">+       expand_initialize_membar(alloc, init, fast_oop_ctrl, fast_oop_rawmem);</span>
<span class="line-added">+       expand_dtrace_alloc_probe(alloc, fast_oop, fast_oop_ctrl, fast_oop_rawmem);</span>
  
<span class="line-modified">!       result_phi_rawoop-&gt;init_req(fast_result_path, fast_oop);</span>
<span class="line-modified">!     } else {</span>
<span class="line-modified">!       assert (initial_slow_test != NULL, &quot;sanity&quot;);</span>
<span class="line-modified">!       fast_oop_ctrl   = toobig_false;</span>
<span class="line-modified">!       fast_oop_rawmem = mem;</span>
<span class="line-modified">!       transform_later(slow_region);</span>
      }
  
      // Plug in the successful fast-path into the result merge point
      result_region    -&gt;init_req(fast_result_path, fast_oop_ctrl);
      result_phi_i_o   -&gt;init_req(fast_result_path, i_o);
      result_phi_rawmem-&gt;init_req(fast_result_path, fast_oop_rawmem);
    } else {
      slow_region = ctrl;
      result_phi_i_o = i_o; // Rename it to use in the following code.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1463,25 ***</span>
    // Generate slow-path call
    CallNode *call = new CallStaticJavaNode(slow_call_type, slow_call_address,
                                 OptoRuntime::stub_name(slow_call_address),
                                 alloc-&gt;jvms()-&gt;bci(),
                                 TypePtr::BOTTOM);
<span class="line-modified">!   call-&gt;init_req( TypeFunc::Control, slow_region );</span>
<span class="line-modified">!   call-&gt;init_req( TypeFunc::I_O    , top() )     ;   // does no i/o</span>
<span class="line-modified">!   call-&gt;init_req( TypeFunc::Memory , slow_mem ); // may gc ptrs</span>
<span class="line-modified">!   call-&gt;init_req( TypeFunc::ReturnAdr, alloc-&gt;in(TypeFunc::ReturnAdr) );</span>
<span class="line-modified">!   call-&gt;init_req( TypeFunc::FramePtr, alloc-&gt;in(TypeFunc::FramePtr) );</span>
  
    call-&gt;init_req(TypeFunc::Parms+0, klass_node);
    if (length != NULL) {
      call-&gt;init_req(TypeFunc::Parms+1, length);
    }
  
    // Copy debug information and adjust JVMState information, then replace
    // allocate node with the call
    copy_call_debug_info((CallNode *) alloc,  call);
<span class="line-modified">!   if (!always_slow) {</span>
      call-&gt;set_cnt(PROB_UNLIKELY_MAG(4));  // Same effect as RC_UNCOMMON.
    } else {
      // Hook i_o projection to avoid its elimination during allocation
      // replacement (when only a slow call is generated).
      call-&gt;set_req(TypeFunc::I_O, result_phi_i_o);
<span class="line-new-header">--- 1451,25 ---</span>
    // Generate slow-path call
    CallNode *call = new CallStaticJavaNode(slow_call_type, slow_call_address,
                                 OptoRuntime::stub_name(slow_call_address),
                                 alloc-&gt;jvms()-&gt;bci(),
                                 TypePtr::BOTTOM);
<span class="line-modified">!   call-&gt;init_req(TypeFunc::Control,   slow_region);</span>
<span class="line-modified">!   call-&gt;init_req(TypeFunc::I_O,       top());    // does no i/o</span>
<span class="line-modified">!   call-&gt;init_req(TypeFunc::Memory,    slow_mem); // may gc ptrs</span>
<span class="line-modified">!   call-&gt;init_req(TypeFunc::ReturnAdr, alloc-&gt;in(TypeFunc::ReturnAdr));</span>
<span class="line-modified">!   call-&gt;init_req(TypeFunc::FramePtr,  alloc-&gt;in(TypeFunc::FramePtr));</span>
  
    call-&gt;init_req(TypeFunc::Parms+0, klass_node);
    if (length != NULL) {
      call-&gt;init_req(TypeFunc::Parms+1, length);
    }
  
    // Copy debug information and adjust JVMState information, then replace
    // allocate node with the call
    copy_call_debug_info((CallNode *) alloc,  call);
<span class="line-modified">!   if (expand_fast_path) {</span>
      call-&gt;set_cnt(PROB_UNLIKELY_MAG(4));  // Same effect as RC_UNCOMMON.
    } else {
      // Hook i_o projection to avoid its elimination during allocation
      // replacement (when only a slow call is generated).
      call-&gt;set_req(TypeFunc::I_O, result_phi_i_o);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1503,86 ***</span>
  
    // An allocate node has separate memory projections for the uses on
    // the control and i_o paths. Replace the control memory projection with
    // result_phi_rawmem (unless we are only generating a slow call when
    // both memory projections are combined)
<span class="line-modified">!   if (!always_slow &amp;&amp; _memproj_fallthrough != NULL) {</span>
<span class="line-modified">!     for (DUIterator_Fast imax, i = _memproj_fallthrough-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-removed">-       Node *use = _memproj_fallthrough-&gt;fast_out(i);</span>
<span class="line-removed">-       _igvn.rehash_node_delayed(use);</span>
<span class="line-removed">-       imax -= replace_input(use, _memproj_fallthrough, result_phi_rawmem);</span>
<span class="line-removed">-       // back up iterator</span>
<span class="line-removed">-       --i;</span>
<span class="line-removed">-     }</span>
    }
    // Now change uses of _memproj_catchall to use _memproj_fallthrough and delete
    // _memproj_catchall so we end up with a call that has only 1 memory projection.
    if (_memproj_catchall != NULL ) {
      if (_memproj_fallthrough == NULL) {
        _memproj_fallthrough = new ProjNode(call, TypeFunc::Memory);
        transform_later(_memproj_fallthrough);
      }
<span class="line-modified">!     for (DUIterator_Fast imax, i = _memproj_catchall-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-removed">-       Node *use = _memproj_catchall-&gt;fast_out(i);</span>
<span class="line-removed">-       _igvn.rehash_node_delayed(use);</span>
<span class="line-removed">-       imax -= replace_input(use, _memproj_catchall, _memproj_fallthrough);</span>
<span class="line-removed">-       // back up iterator</span>
<span class="line-removed">-       --i;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     assert(_memproj_catchall-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);</span>
      _igvn.remove_dead_node(_memproj_catchall);
    }
  
    // An allocate node has separate i_o projections for the uses on the control
    // and i_o paths. Always replace the control i_o projection with result i_o
    // otherwise incoming i_o become dead when only a slow call is generated
    // (it is different from memory projections where both projections are
    // combined in such case).
    if (_ioproj_fallthrough != NULL) {
<span class="line-modified">!     for (DUIterator_Fast imax, i = _ioproj_fallthrough-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-removed">-       Node *use = _ioproj_fallthrough-&gt;fast_out(i);</span>
<span class="line-removed">-       _igvn.rehash_node_delayed(use);</span>
<span class="line-removed">-       imax -= replace_input(use, _ioproj_fallthrough, result_phi_i_o);</span>
<span class="line-removed">-       // back up iterator</span>
<span class="line-removed">-       --i;</span>
<span class="line-removed">-     }</span>
    }
    // Now change uses of _ioproj_catchall to use _ioproj_fallthrough and delete
    // _ioproj_catchall so we end up with a call that has only 1 i_o projection.
    if (_ioproj_catchall != NULL ) {
      if (_ioproj_fallthrough == NULL) {
        _ioproj_fallthrough = new ProjNode(call, TypeFunc::I_O);
        transform_later(_ioproj_fallthrough);
      }
<span class="line-modified">!     for (DUIterator_Fast imax, i = _ioproj_catchall-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-removed">-       Node *use = _ioproj_catchall-&gt;fast_out(i);</span>
<span class="line-removed">-       _igvn.rehash_node_delayed(use);</span>
<span class="line-removed">-       imax -= replace_input(use, _ioproj_catchall, _ioproj_fallthrough);</span>
<span class="line-removed">-       // back up iterator</span>
<span class="line-removed">-       --i;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     assert(_ioproj_catchall-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);</span>
      _igvn.remove_dead_node(_ioproj_catchall);
    }
  
    // if we generated only a slow call, we are done
<span class="line-modified">!   if (always_slow) {</span>
      // Now we can unhook i_o.
      if (result_phi_i_o-&gt;outcnt() &gt; 1) {
        call-&gt;set_req(TypeFunc::I_O, top());
      } else {
<span class="line-modified">!       assert(result_phi_i_o-&gt;unique_ctrl_out() == call, &quot;&quot;);</span>
        // Case of new array with negative size known during compilation.
        // AllocateArrayNode::Ideal() optimization disconnect unreachable
        // following code since call to runtime will throw exception.
        // As result there will be no users of i_o after the call.
        // Leave i_o attached to this call to avoid problems in preceding graph.
      }
      return;
    }
  
<span class="line-removed">- </span>
    if (_fallthroughcatchproj != NULL) {
      ctrl = _fallthroughcatchproj-&gt;clone();
      transform_later(ctrl);
      _igvn.replace_node(_fallthroughcatchproj, result_region);
    } else {
<span class="line-new-header">--- 1491,59 ---</span>
  
    // An allocate node has separate memory projections for the uses on
    // the control and i_o paths. Replace the control memory projection with
    // result_phi_rawmem (unless we are only generating a slow call when
    // both memory projections are combined)
<span class="line-modified">!   if (expand_fast_path &amp;&amp; _memproj_fallthrough != NULL) {</span>
<span class="line-modified">!     migrate_outs(_memproj_fallthrough, result_phi_rawmem);</span>
    }
    // Now change uses of _memproj_catchall to use _memproj_fallthrough and delete
    // _memproj_catchall so we end up with a call that has only 1 memory projection.
    if (_memproj_catchall != NULL ) {
      if (_memproj_fallthrough == NULL) {
        _memproj_fallthrough = new ProjNode(call, TypeFunc::Memory);
        transform_later(_memproj_fallthrough);
      }
<span class="line-modified">!     migrate_outs(_memproj_catchall, _memproj_fallthrough);</span>
      _igvn.remove_dead_node(_memproj_catchall);
    }
  
    // An allocate node has separate i_o projections for the uses on the control
    // and i_o paths. Always replace the control i_o projection with result i_o
    // otherwise incoming i_o become dead when only a slow call is generated
    // (it is different from memory projections where both projections are
    // combined in such case).
    if (_ioproj_fallthrough != NULL) {
<span class="line-modified">!     migrate_outs(_ioproj_fallthrough, result_phi_i_o);</span>
    }
    // Now change uses of _ioproj_catchall to use _ioproj_fallthrough and delete
    // _ioproj_catchall so we end up with a call that has only 1 i_o projection.
    if (_ioproj_catchall != NULL ) {
      if (_ioproj_fallthrough == NULL) {
        _ioproj_fallthrough = new ProjNode(call, TypeFunc::I_O);
        transform_later(_ioproj_fallthrough);
      }
<span class="line-modified">!     migrate_outs(_ioproj_catchall, _ioproj_fallthrough);</span>
      _igvn.remove_dead_node(_ioproj_catchall);
    }
  
    // if we generated only a slow call, we are done
<span class="line-modified">!   if (!expand_fast_path) {</span>
      // Now we can unhook i_o.
      if (result_phi_i_o-&gt;outcnt() &gt; 1) {
        call-&gt;set_req(TypeFunc::I_O, top());
      } else {
<span class="line-modified">!       assert(result_phi_i_o-&gt;unique_ctrl_out() == call, &quot;sanity&quot;);</span>
        // Case of new array with negative size known during compilation.
        // AllocateArrayNode::Ideal() optimization disconnect unreachable
        // following code since call to runtime will throw exception.
        // As result there will be no users of i_o after the call.
        // Leave i_o attached to this call to avoid problems in preceding graph.
      }
      return;
    }
  
    if (_fallthroughcatchproj != NULL) {
      ctrl = _fallthroughcatchproj-&gt;clone();
      transform_later(ctrl);
      _igvn.replace_node(_fallthroughcatchproj, result_region);
    } else {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1597,38 ***</span>
      transform_later(slow_result);
      _igvn.replace_node(_resproj, result_phi_rawoop);
    }
  
    // Plug slow-path into result merge point
<span class="line-modified">!   result_region    -&gt;init_req( slow_result_path, ctrl );</span>
<span class="line-removed">-   result_phi_rawoop-&gt;init_req( slow_result_path, slow_result);</span>
<span class="line-removed">-   result_phi_rawmem-&gt;init_req( slow_result_path, _memproj_fallthrough );</span>
    transform_later(result_region);
<span class="line-modified">!   transform_later(result_phi_rawoop);</span>
    transform_later(result_phi_rawmem);
    transform_later(result_phi_i_o);
    // This completes all paths into the result merge point
  }
  
  
  // Helper for PhaseMacroExpand::expand_allocate_common.
  // Initializes the newly-allocated storage.
  Node*
  PhaseMacroExpand::initialize_object(AllocateNode* alloc,
                                      Node* control, Node* rawmem, Node* object,
                                      Node* klass_node, Node* length,
                                      Node* size_in_bytes) {
    InitializeNode* init = alloc-&gt;initialization();
    // Store the klass &amp; mark bits
<span class="line-modified">!   Node* mark_node = NULL;</span>
<span class="line-modified">!   // For now only enable fast locking for non-array types</span>
<span class="line-modified">!   if (UseBiasedLocking &amp;&amp; (length == NULL)) {</span>
<span class="line-removed">-     mark_node = make_load(control, rawmem, klass_node, in_bytes(Klass::prototype_header_offset()), TypeRawPtr::BOTTOM, T_ADDRESS);</span>
<span class="line-removed">-   } else {</span>
<span class="line-removed">-     mark_node = makecon(TypeRawPtr::make((address)markOopDesc::prototype()));</span>
    }
<span class="line-modified">!   rawmem = make_store(control, rawmem, object, oopDesc::mark_offset_in_bytes(), mark_node, T_ADDRESS);</span>
  
    rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);
    int header_size = alloc-&gt;minimum_header_size();  // conservatively small
  
    // Array length
<span class="line-new-header">--- 1558,196 ---</span>
      transform_later(slow_result);
      _igvn.replace_node(_resproj, result_phi_rawoop);
    }
  
    // Plug slow-path into result merge point
<span class="line-modified">!   result_region-&gt;init_req( slow_result_path, ctrl);</span>
    transform_later(result_region);
<span class="line-modified">!   if (allocation_has_use) {</span>
<span class="line-added">+     result_phi_rawoop-&gt;init_req(slow_result_path, slow_result);</span>
<span class="line-added">+     transform_later(result_phi_rawoop);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   result_phi_rawmem-&gt;init_req(slow_result_path, _memproj_fallthrough);</span>
    transform_later(result_phi_rawmem);
    transform_later(result_phi_i_o);
    // This completes all paths into the result merge point
  }
  
<span class="line-added">+ // Remove alloc node that has no uses.</span>
<span class="line-added">+ void PhaseMacroExpand::yank_alloc_node(AllocateNode* alloc) {</span>
<span class="line-added">+   Node* ctrl = alloc-&gt;in(TypeFunc::Control);</span>
<span class="line-added">+   Node* mem  = alloc-&gt;in(TypeFunc::Memory);</span>
<span class="line-added">+   Node* i_o  = alloc-&gt;in(TypeFunc::I_O);</span>
<span class="line-added">+ </span>
<span class="line-added">+   extract_call_projections(alloc);</span>
<span class="line-added">+   if (_fallthroughcatchproj != NULL) {</span>
<span class="line-added">+     migrate_outs(_fallthroughcatchproj, ctrl);</span>
<span class="line-added">+     _igvn.remove_dead_node(_fallthroughcatchproj);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   if (_catchallcatchproj != NULL) {</span>
<span class="line-added">+     _igvn.rehash_node_delayed(_catchallcatchproj);</span>
<span class="line-added">+     _catchallcatchproj-&gt;set_req(0, top());</span>
<span class="line-added">+   }</span>
<span class="line-added">+   if (_fallthroughproj != NULL) {</span>
<span class="line-added">+     Node* catchnode = _fallthroughproj-&gt;unique_ctrl_out();</span>
<span class="line-added">+     _igvn.remove_dead_node(catchnode);</span>
<span class="line-added">+     _igvn.remove_dead_node(_fallthroughproj);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   if (_memproj_fallthrough != NULL) {</span>
<span class="line-added">+     migrate_outs(_memproj_fallthrough, mem);</span>
<span class="line-added">+     _igvn.remove_dead_node(_memproj_fallthrough);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   if (_ioproj_fallthrough != NULL) {</span>
<span class="line-added">+     migrate_outs(_ioproj_fallthrough, i_o);</span>
<span class="line-added">+     _igvn.remove_dead_node(_ioproj_fallthrough);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   if (_memproj_catchall != NULL) {</span>
<span class="line-added">+     _igvn.rehash_node_delayed(_memproj_catchall);</span>
<span class="line-added">+     _memproj_catchall-&gt;set_req(0, top());</span>
<span class="line-added">+   }</span>
<span class="line-added">+   if (_ioproj_catchall != NULL) {</span>
<span class="line-added">+     _igvn.rehash_node_delayed(_ioproj_catchall);</span>
<span class="line-added">+     _ioproj_catchall-&gt;set_req(0, top());</span>
<span class="line-added">+   }</span>
<span class="line-added">+   _igvn.remove_dead_node(alloc);</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void PhaseMacroExpand::expand_initialize_membar(AllocateNode* alloc, InitializeNode* init,</span>
<span class="line-added">+                                                 Node*&amp; fast_oop_ctrl, Node*&amp; fast_oop_rawmem) {</span>
<span class="line-added">+   // If initialization is performed by an array copy, any required</span>
<span class="line-added">+   // MemBarStoreStore was already added. If the object does not</span>
<span class="line-added">+   // escape no need for a MemBarStoreStore. If the object does not</span>
<span class="line-added">+   // escape in its initializer and memory barrier (MemBarStoreStore or</span>
<span class="line-added">+   // stronger) is already added at exit of initializer, also no need</span>
<span class="line-added">+   // for a MemBarStoreStore. Otherwise we need a MemBarStoreStore</span>
<span class="line-added">+   // so that stores that initialize this object can&#39;t be reordered</span>
<span class="line-added">+   // with a subsequent store that makes this object accessible by</span>
<span class="line-added">+   // other threads.</span>
<span class="line-added">+   // Other threads include java threads and JVM internal threads</span>
<span class="line-added">+   // (for example concurrent GC threads). Current concurrent GC</span>
<span class="line-added">+   // implementation: G1 will not scan newly created object,</span>
<span class="line-added">+   // so it&#39;s safe to skip storestore barrier when allocation does</span>
<span class="line-added">+   // not escape.</span>
<span class="line-added">+   if (!alloc-&gt;does_not_escape_thread() &amp;&amp;</span>
<span class="line-added">+     !alloc-&gt;is_allocation_MemBar_redundant() &amp;&amp;</span>
<span class="line-added">+     (init == NULL || !init-&gt;is_complete_with_arraycopy())) {</span>
<span class="line-added">+     if (init == NULL || init-&gt;req() &lt; InitializeNode::RawStores) {</span>
<span class="line-added">+       // No InitializeNode or no stores captured by zeroing</span>
<span class="line-added">+       // elimination. Simply add the MemBarStoreStore after object</span>
<span class="line-added">+       // initialization.</span>
<span class="line-added">+       MemBarNode* mb = MemBarNode::make(C, Op_MemBarStoreStore, Compile::AliasIdxBot);</span>
<span class="line-added">+       transform_later(mb);</span>
<span class="line-added">+ </span>
<span class="line-added">+       mb-&gt;init_req(TypeFunc::Memory, fast_oop_rawmem);</span>
<span class="line-added">+       mb-&gt;init_req(TypeFunc::Control, fast_oop_ctrl);</span>
<span class="line-added">+       fast_oop_ctrl = new ProjNode(mb, TypeFunc::Control);</span>
<span class="line-added">+       transform_later(fast_oop_ctrl);</span>
<span class="line-added">+       fast_oop_rawmem = new ProjNode(mb, TypeFunc::Memory);</span>
<span class="line-added">+       transform_later(fast_oop_rawmem);</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       // Add the MemBarStoreStore after the InitializeNode so that</span>
<span class="line-added">+       // all stores performing the initialization that were moved</span>
<span class="line-added">+       // before the InitializeNode happen before the storestore</span>
<span class="line-added">+       // barrier.</span>
<span class="line-added">+ </span>
<span class="line-added">+       Node* init_ctrl = init-&gt;proj_out_or_null(TypeFunc::Control);</span>
<span class="line-added">+       Node* init_mem = init-&gt;proj_out_or_null(TypeFunc::Memory);</span>
<span class="line-added">+ </span>
<span class="line-added">+       MemBarNode* mb = MemBarNode::make(C, Op_MemBarStoreStore, Compile::AliasIdxBot);</span>
<span class="line-added">+       transform_later(mb);</span>
<span class="line-added">+ </span>
<span class="line-added">+       Node* ctrl = new ProjNode(init, TypeFunc::Control);</span>
<span class="line-added">+       transform_later(ctrl);</span>
<span class="line-added">+       Node* mem = new ProjNode(init, TypeFunc::Memory);</span>
<span class="line-added">+       transform_later(mem);</span>
<span class="line-added">+ </span>
<span class="line-added">+       // The MemBarStoreStore depends on control and memory coming</span>
<span class="line-added">+       // from the InitializeNode</span>
<span class="line-added">+       mb-&gt;init_req(TypeFunc::Memory, mem);</span>
<span class="line-added">+       mb-&gt;init_req(TypeFunc::Control, ctrl);</span>
<span class="line-added">+ </span>
<span class="line-added">+       ctrl = new ProjNode(mb, TypeFunc::Control);</span>
<span class="line-added">+       transform_later(ctrl);</span>
<span class="line-added">+       mem = new ProjNode(mb, TypeFunc::Memory);</span>
<span class="line-added">+       transform_later(mem);</span>
<span class="line-added">+ </span>
<span class="line-added">+       // All nodes that depended on the InitializeNode for control</span>
<span class="line-added">+       // and memory must now depend on the MemBarNode that itself</span>
<span class="line-added">+       // depends on the InitializeNode</span>
<span class="line-added">+       if (init_ctrl != NULL) {</span>
<span class="line-added">+         _igvn.replace_node(init_ctrl, ctrl);</span>
<span class="line-added">+       }</span>
<span class="line-added">+       if (init_mem != NULL) {</span>
<span class="line-added">+         _igvn.replace_node(init_mem, mem);</span>
<span class="line-added">+       }</span>
<span class="line-added">+     }</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void PhaseMacroExpand::expand_dtrace_alloc_probe(AllocateNode* alloc, Node* oop,</span>
<span class="line-added">+                                                 Node*&amp; ctrl, Node*&amp; rawmem) {</span>
<span class="line-added">+   if (C-&gt;env()-&gt;dtrace_extended_probes()) {</span>
<span class="line-added">+     // Slow-path call</span>
<span class="line-added">+     int size = TypeFunc::Parms + 2;</span>
<span class="line-added">+     CallLeafNode *call = new CallLeafNode(OptoRuntime::dtrace_object_alloc_Type(),</span>
<span class="line-added">+                                           CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc_base),</span>
<span class="line-added">+                                           &quot;dtrace_object_alloc&quot;,</span>
<span class="line-added">+                                           TypeRawPtr::BOTTOM);</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Get base of thread-local storage area</span>
<span class="line-added">+     Node* thread = new ThreadLocalNode();</span>
<span class="line-added">+     transform_later(thread);</span>
<span class="line-added">+ </span>
<span class="line-added">+     call-&gt;init_req(TypeFunc::Parms + 0, thread);</span>
<span class="line-added">+     call-&gt;init_req(TypeFunc::Parms + 1, oop);</span>
<span class="line-added">+     call-&gt;init_req(TypeFunc::Control, ctrl);</span>
<span class="line-added">+     call-&gt;init_req(TypeFunc::I_O    , top()); // does no i/o</span>
<span class="line-added">+     call-&gt;init_req(TypeFunc::Memory , ctrl);</span>
<span class="line-added">+     call-&gt;init_req(TypeFunc::ReturnAdr, alloc-&gt;in(TypeFunc::ReturnAdr));</span>
<span class="line-added">+     call-&gt;init_req(TypeFunc::FramePtr, alloc-&gt;in(TypeFunc::FramePtr));</span>
<span class="line-added">+     transform_later(call);</span>
<span class="line-added">+     ctrl = new ProjNode(call, TypeFunc::Control);</span>
<span class="line-added">+     transform_later(ctrl);</span>
<span class="line-added">+     rawmem = new ProjNode(call, TypeFunc::Memory);</span>
<span class="line-added">+     transform_later(rawmem);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ // Remove InitializeNode without use</span>
<span class="line-added">+ void PhaseMacroExpand::yank_initalize_node(InitializeNode* initnode) {</span>
<span class="line-added">+   assert(initnode-&gt;proj_out_or_null(TypeFunc::Parms) == NULL, &quot;No uses allowed&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   Node* ctrl_out  = initnode-&gt;proj_out_or_null(TypeFunc::Control);</span>
<span class="line-added">+   Node* mem_out   = initnode-&gt;proj_out_or_null(TypeFunc::Memory);</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Move all uses of each to</span>
<span class="line-added">+   if (ctrl_out != NULL ) {</span>
<span class="line-added">+     migrate_outs(ctrl_out, initnode-&gt;in(TypeFunc::Control));</span>
<span class="line-added">+     _igvn.remove_dead_node(ctrl_out);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ </span>
<span class="line-added">+   // Move all uses of each to</span>
<span class="line-added">+   if (mem_out != NULL ) {</span>
<span class="line-added">+     migrate_outs(mem_out, initnode-&gt;in(TypeFunc::Memory));</span>
<span class="line-added">+     _igvn.remove_dead_node(mem_out);</span>
<span class="line-added">+   }</span>
<span class="line-added">+ }</span>
  
  // Helper for PhaseMacroExpand::expand_allocate_common.
  // Initializes the newly-allocated storage.
  Node*
  PhaseMacroExpand::initialize_object(AllocateNode* alloc,
                                      Node* control, Node* rawmem, Node* object,
                                      Node* klass_node, Node* length,
                                      Node* size_in_bytes) {
    InitializeNode* init = alloc-&gt;initialization();
    // Store the klass &amp; mark bits
<span class="line-modified">!   Node* mark_node = alloc-&gt;make_ideal_mark(&amp;_igvn, object, control, rawmem);</span>
<span class="line-modified">!   if (!mark_node-&gt;is_Con()) {</span>
<span class="line-modified">!     transform_later(mark_node);</span>
    }
<span class="line-modified">!   rawmem = make_store(control, rawmem, object, oopDesc::mark_offset_in_bytes(), mark_node, TypeX_X-&gt;basic_type());</span>
  
    rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);
    int header_size = alloc-&gt;minimum_header_size();  // conservatively small
  
    // Array length
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2180,12 ***</span>
      // First, check mark word for the biased lock pattern.
      Node* mark_node = make_load(ctrl, mem, obj, oopDesc::mark_offset_in_bytes(), TypeX_X, TypeX_X-&gt;basic_type());
  
      // Get fast path - mark word has the biased lock pattern.
      ctrl = opt_bits_test(ctrl, fast_lock_region, 1, mark_node,
<span class="line-modified">!                          markOopDesc::biased_lock_mask_in_place,</span>
<span class="line-modified">!                          markOopDesc::biased_lock_pattern, true);</span>
      // fast_lock_region-&gt;in(1) is set to slow path.
      fast_lock_mem_phi-&gt;init_req(1, mem);
  
      // Now check that the lock is biased to the current thread and has
      // the same epoch and bias as Klass::_prototype_header.
<span class="line-new-header">--- 2299,12 ---</span>
      // First, check mark word for the biased lock pattern.
      Node* mark_node = make_load(ctrl, mem, obj, oopDesc::mark_offset_in_bytes(), TypeX_X, TypeX_X-&gt;basic_type());
  
      // Get fast path - mark word has the biased lock pattern.
      ctrl = opt_bits_test(ctrl, fast_lock_region, 1, mark_node,
<span class="line-modified">!                          markWord::biased_lock_mask_in_place,</span>
<span class="line-modified">!                          markWord::biased_lock_pattern, true);</span>
      // fast_lock_region-&gt;in(1) is set to slow path.
      fast_lock_mem_phi-&gt;init_req(1, mem);
  
      // Now check that the lock is biased to the current thread and has
      // the same epoch and bias as Klass::_prototype_header.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2209,23 ***</span>
      Node* cast_thread = transform_later(new CastP2XNode(ctrl, thread));
      Node* o_node = transform_later(new OrXNode(cast_thread, proto_node));
      Node* x_node = transform_later(new XorXNode(o_node, mark_node));
  
      // Get slow path - mark word does NOT match the value.
      Node* not_biased_ctrl =  opt_bits_test(ctrl, region, 3, x_node,
<span class="line-modified">!                                       (~markOopDesc::age_mask_in_place), 0);</span>
      // region-&gt;in(3) is set to fast path - the object is biased to the current thread.
      mem_phi-&gt;init_req(3, mem);
  
  
      // Mark word does NOT match the value (thread | Klass::_prototype_header).
  
  
      // First, check biased pattern.
      // Get fast path - _prototype_header has the same biased lock pattern.
      ctrl =  opt_bits_test(not_biased_ctrl, fast_lock_region, 2, x_node,
<span class="line-modified">!                           markOopDesc::biased_lock_mask_in_place, 0, true);</span>
  
      not_biased_ctrl = fast_lock_region-&gt;in(2); // Slow path
      // fast_lock_region-&gt;in(2) - the prototype header is no longer biased
      // and we have to revoke the bias on this object.
      // We are going to try to reset the mark of this object to the prototype
<span class="line-new-header">--- 2328,24 ---</span>
      Node* cast_thread = transform_later(new CastP2XNode(ctrl, thread));
      Node* o_node = transform_later(new OrXNode(cast_thread, proto_node));
      Node* x_node = transform_later(new XorXNode(o_node, mark_node));
  
      // Get slow path - mark word does NOT match the value.
<span class="line-added">+     STATIC_ASSERT(markWord::age_mask_in_place &lt;= INT_MAX);</span>
      Node* not_biased_ctrl =  opt_bits_test(ctrl, region, 3, x_node,
<span class="line-modified">!                                       (~(int)markWord::age_mask_in_place), 0);</span>
      // region-&gt;in(3) is set to fast path - the object is biased to the current thread.
      mem_phi-&gt;init_req(3, mem);
  
  
      // Mark word does NOT match the value (thread | Klass::_prototype_header).
  
  
      // First, check biased pattern.
      // Get fast path - _prototype_header has the same biased lock pattern.
      ctrl =  opt_bits_test(not_biased_ctrl, fast_lock_region, 2, x_node,
<span class="line-modified">!                           markWord::biased_lock_mask_in_place, 0, true);</span>
  
      not_biased_ctrl = fast_lock_region-&gt;in(2); // Slow path
      // fast_lock_region-&gt;in(2) - the prototype header is no longer biased
      // and we have to revoke the bias on this object.
      // We are going to try to reset the mark of this object to the prototype
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2243,23 ***</span>
      Node* old_phi = new PhiNode( rebiased_region, TypeX_X);
      Node* new_phi = new PhiNode( rebiased_region, TypeX_X);
  
      // Get slow path - mark word does NOT match epoch bits.
      Node* epoch_ctrl =  opt_bits_test(ctrl, rebiased_region, 1, x_node,
<span class="line-modified">!                                       markOopDesc::epoch_mask_in_place, 0);</span>
      // The epoch of the current bias is not valid, attempt to rebias the object
      // toward the current thread.
      rebiased_region-&gt;init_req(2, epoch_ctrl);
      old_phi-&gt;init_req(2, mark_node);
      new_phi-&gt;init_req(2, o_node);
  
      // rebiased_region-&gt;in(1) is set to fast path.
      // The epoch of the current bias is still valid but we know
      // nothing about the owner; it might be set or it might be clear.
<span class="line-modified">!     Node* cmask   = MakeConX(markOopDesc::biased_lock_mask_in_place |</span>
<span class="line-modified">!                              markOopDesc::age_mask_in_place |</span>
<span class="line-modified">!                              markOopDesc::epoch_mask_in_place);</span>
      Node* old = transform_later(new AndXNode(mark_node, cmask));
      cast_thread = transform_later(new CastP2XNode(ctrl, thread));
      Node* new_mark = transform_later(new OrXNode(cast_thread, old));
      old_phi-&gt;init_req(1, old);
      new_phi-&gt;init_req(1, new_mark);
<span class="line-new-header">--- 2363,23 ---</span>
      Node* old_phi = new PhiNode( rebiased_region, TypeX_X);
      Node* new_phi = new PhiNode( rebiased_region, TypeX_X);
  
      // Get slow path - mark word does NOT match epoch bits.
      Node* epoch_ctrl =  opt_bits_test(ctrl, rebiased_region, 1, x_node,
<span class="line-modified">!                                       markWord::epoch_mask_in_place, 0);</span>
      // The epoch of the current bias is not valid, attempt to rebias the object
      // toward the current thread.
      rebiased_region-&gt;init_req(2, epoch_ctrl);
      old_phi-&gt;init_req(2, mark_node);
      new_phi-&gt;init_req(2, o_node);
  
      // rebiased_region-&gt;in(1) is set to fast path.
      // The epoch of the current bias is still valid but we know
      // nothing about the owner; it might be set or it might be clear.
<span class="line-modified">!     Node* cmask   = MakeConX(markWord::biased_lock_mask_in_place |</span>
<span class="line-modified">!                              markWord::age_mask_in_place |</span>
<span class="line-modified">!                              markWord::epoch_mask_in_place);</span>
      Node* old = transform_later(new AndXNode(mark_node, cmask));
      cast_thread = transform_later(new CastP2XNode(ctrl, thread));
      Node* new_mark = transform_later(new OrXNode(cast_thread, old));
      old_phi-&gt;init_req(1, old);
      new_phi-&gt;init_req(1, new_mark);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2370,12 ***</span>
      mem_phi = new PhiNode( region, Type::MEMORY, TypeRawPtr::BOTTOM);
      mem_phi-&gt;init_req(3, mem);
  
      Node* mark_node = make_load(ctrl, mem, obj, oopDesc::mark_offset_in_bytes(), TypeX_X, TypeX_X-&gt;basic_type());
      ctrl = opt_bits_test(ctrl, region, 3, mark_node,
<span class="line-modified">!                          markOopDesc::biased_lock_mask_in_place,</span>
<span class="line-modified">!                          markOopDesc::biased_lock_pattern);</span>
    } else {
      region  = new RegionNode(3);
      // create a Phi for the memory state
      mem_phi = new PhiNode( region, Type::MEMORY, TypeRawPtr::BOTTOM);
    }
<span class="line-new-header">--- 2490,12 ---</span>
      mem_phi = new PhiNode( region, Type::MEMORY, TypeRawPtr::BOTTOM);
      mem_phi-&gt;init_req(3, mem);
  
      Node* mark_node = make_load(ctrl, mem, obj, oopDesc::mark_offset_in_bytes(), TypeX_X, TypeX_X-&gt;basic_type());
      ctrl = opt_bits_test(ctrl, region, 3, mark_node,
<span class="line-modified">!                          markWord::biased_lock_mask_in_place,</span>
<span class="line-modified">!                          markWord::biased_lock_pattern);</span>
    } else {
      region  = new RegionNode(3);
      // create a Phi for the memory state
      mem_phi = new PhiNode( region, Type::MEMORY, TypeRawPtr::BOTTOM);
    }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2413,10 ***</span>
<span class="line-new-header">--- 2533,47 ---</span>
    mem_phi-&gt;init_req(2, mem);
    transform_later(mem_phi);
    _igvn.replace_node(_memproj_fallthrough, mem_phi);
  }
  
<span class="line-added">+ void PhaseMacroExpand::expand_subtypecheck_node(SubTypeCheckNode *check) {</span>
<span class="line-added">+   assert(check-&gt;in(SubTypeCheckNode::Control) == NULL, &quot;should be pinned&quot;);</span>
<span class="line-added">+   Node* bol = check-&gt;unique_out();</span>
<span class="line-added">+   Node* obj_or_subklass = check-&gt;in(SubTypeCheckNode::ObjOrSubKlass);</span>
<span class="line-added">+   Node* superklass = check-&gt;in(SubTypeCheckNode::SuperKlass);</span>
<span class="line-added">+   assert(bol-&gt;is_Bool() &amp;&amp; bol-&gt;as_Bool()-&gt;_test._test == BoolTest::ne, &quot;unexpected bool node&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+   for (DUIterator_Last imin, i = bol-&gt;last_outs(imin); i &gt;= imin; --i) {</span>
<span class="line-added">+     Node* iff = bol-&gt;last_out(i);</span>
<span class="line-added">+     assert(iff-&gt;is_If(), &quot;where&#39;s the if?&quot;);</span>
<span class="line-added">+ </span>
<span class="line-added">+     if (iff-&gt;in(0)-&gt;is_top()) {</span>
<span class="line-added">+       _igvn.replace_input_of(iff, 1, C-&gt;top());</span>
<span class="line-added">+       continue;</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     Node* iftrue = iff-&gt;as_If()-&gt;proj_out(1);</span>
<span class="line-added">+     Node* iffalse = iff-&gt;as_If()-&gt;proj_out(0);</span>
<span class="line-added">+     Node* ctrl = iff-&gt;in(0);</span>
<span class="line-added">+ </span>
<span class="line-added">+     Node* subklass = NULL;</span>
<span class="line-added">+     if (_igvn.type(obj_or_subklass)-&gt;isa_klassptr()) {</span>
<span class="line-added">+       subklass = obj_or_subklass;</span>
<span class="line-added">+     } else {</span>
<span class="line-added">+       Node* k_adr = basic_plus_adr(obj_or_subklass, oopDesc::klass_offset_in_bytes());</span>
<span class="line-added">+       subklass = _igvn.transform(LoadKlassNode::make(_igvn, NULL, C-&gt;immutable_memory(), k_adr, TypeInstPtr::KLASS));</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     Node* not_subtype_ctrl = Phase::gen_subtype_check(subklass, superklass, &amp;ctrl, NULL, _igvn);</span>
<span class="line-added">+ </span>
<span class="line-added">+     _igvn.replace_input_of(iff, 0, C-&gt;top());</span>
<span class="line-added">+     _igvn.replace_node(iftrue, not_subtype_ctrl);</span>
<span class="line-added">+     _igvn.replace_node(iffalse, ctrl);</span>
<span class="line-added">+   }</span>
<span class="line-added">+   _igvn.replace_node(check, C-&gt;top());</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  //---------------------------eliminate_macro_nodes----------------------
  // Eliminate scalar replaced allocations and associated locks.
  void PhaseMacroExpand::eliminate_macro_nodes() {
    if (C-&gt;macro_count() == 0)
      return;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2469,10 ***</span>
<span class="line-new-header">--- 2626,12 ---</span>
          break;
        case Node::Class_ArrayCopy:
          break;
        case Node::Class_OuterStripMinedLoop:
          break;
<span class="line-added">+       case Node::Class_SubTypeCheck:</span>
<span class="line-added">+         break;</span>
        default:
          assert(n-&gt;Opcode() == Op_LoopLimit ||
                 n-&gt;Opcode() == Op_Opaque1   ||
                 n-&gt;Opcode() == Op_Opaque2   ||
                 n-&gt;Opcode() == Op_Opaque3   ||
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2500,11 ***</span>
    // Eliminate Opaque and LoopLimit nodes. Do it after all loop optimizations.
    bool progress = true;
    while (progress) {
      progress = false;
      for (int i = C-&gt;macro_count(); i &gt; 0; i--) {
<span class="line-modified">!       Node * n = C-&gt;macro_node(i-1);</span>
        bool success = false;
        debug_only(int old_macro_count = C-&gt;macro_count(););
        if (n-&gt;Opcode() == Op_LoopLimit) {
          // Remove it from macro list and put on IGVN worklist to optimize.
          C-&gt;remove_macro_node(n);
<span class="line-new-header">--- 2659,11 ---</span>
    // Eliminate Opaque and LoopLimit nodes. Do it after all loop optimizations.
    bool progress = true;
    while (progress) {
      progress = false;
      for (int i = C-&gt;macro_count(); i &gt; 0; i--) {
<span class="line-modified">!       Node* n = C-&gt;macro_node(i-1);</span>
        bool success = false;
        debug_only(int old_macro_count = C-&gt;macro_count(););
        if (n-&gt;Opcode() == Op_LoopLimit) {
          // Remove it from macro list and put on IGVN worklist to optimize.
          C-&gt;remove_macro_node(n);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2545,34 ***</span>
        } else if (n-&gt;Opcode() == Op_OuterStripMinedLoop) {
          n-&gt;as_OuterStripMinedLoop()-&gt;adjust_strip_mined_loop(&amp;_igvn);
          C-&gt;remove_macro_node(n);
          success = true;
        }
<span class="line-modified">!       assert(success == (C-&gt;macro_count() &lt; old_macro_count), &quot;elimination reduces macro count&quot;);</span>
        progress = progress || success;
      }
    }
  
    // expand arraycopy &quot;macro&quot; nodes first
    // For ReduceBulkZeroing, we must first process all arraycopy nodes
    // before the allocate nodes are expanded.
<span class="line-modified">!   int macro_idx = C-&gt;macro_count() - 1;</span>
<span class="line-modified">!   while (macro_idx &gt;= 0) {</span>
<span class="line-removed">-     Node * n = C-&gt;macro_node(macro_idx);</span>
      assert(n-&gt;is_macro(), &quot;only macro nodes expected here&quot;);
      if (_igvn.type(n) == Type::TOP || (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0)-&gt;is_top())) {
        // node is unreachable, so don&#39;t try to expand it
        C-&gt;remove_macro_node(n);
<span class="line-modified">!     } else if (n-&gt;is_ArrayCopy()){</span>
<span class="line-modified">!       int macro_count = C-&gt;macro_count();</span>
        expand_arraycopy_node(n-&gt;as_ArrayCopy());
<span class="line-modified">!       assert(C-&gt;macro_count() &lt; macro_count, &quot;must have deleted a node from macro list&quot;);</span>
      }
      if (C-&gt;failing())  return true;
<span class="line-removed">-     macro_idx --;</span>
    }
  
    // expand &quot;macro&quot; nodes
    // nodes are removed from the macro list as they are processed
    while (C-&gt;macro_count() &gt; 0) {
      int macro_count = C-&gt;macro_count();
      Node * n = C-&gt;macro_node(macro_count-1);
<span class="line-new-header">--- 2704,57 ---</span>
        } else if (n-&gt;Opcode() == Op_OuterStripMinedLoop) {
          n-&gt;as_OuterStripMinedLoop()-&gt;adjust_strip_mined_loop(&amp;_igvn);
          C-&gt;remove_macro_node(n);
          success = true;
        }
<span class="line-modified">!       assert(!success || (C-&gt;macro_count() == (old_macro_count - 1)), &quot;elimination must have deleted one node from macro list&quot;);</span>
        progress = progress || success;
      }
    }
  
    // expand arraycopy &quot;macro&quot; nodes first
    // For ReduceBulkZeroing, we must first process all arraycopy nodes
    // before the allocate nodes are expanded.
<span class="line-modified">!   for (int i = C-&gt;macro_count(); i &gt; 0; i--) {</span>
<span class="line-modified">!     Node* n = C-&gt;macro_node(i-1);</span>
      assert(n-&gt;is_macro(), &quot;only macro nodes expected here&quot;);
      if (_igvn.type(n) == Type::TOP || (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0)-&gt;is_top())) {
        // node is unreachable, so don&#39;t try to expand it
        C-&gt;remove_macro_node(n);
<span class="line-modified">!       continue;</span>
<span class="line-modified">!     }</span>
<span class="line-added">+     debug_only(int old_macro_count = C-&gt;macro_count(););</span>
<span class="line-added">+     switch (n-&gt;class_id()) {</span>
<span class="line-added">+     case Node::Class_Lock:</span>
<span class="line-added">+       expand_lock_node(n-&gt;as_Lock());</span>
<span class="line-added">+       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     case Node::Class_Unlock:</span>
<span class="line-added">+       expand_unlock_node(n-&gt;as_Unlock());</span>
<span class="line-added">+       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     case Node::Class_ArrayCopy:</span>
        expand_arraycopy_node(n-&gt;as_ArrayCopy());
<span class="line-modified">!       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);</span>
<span class="line-added">+       break;</span>
<span class="line-added">+     case Node::Class_SubTypeCheck:</span>
<span class="line-added">+       expand_subtypecheck_node(n-&gt;as_SubTypeCheck());</span>
<span class="line-added">+       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);</span>
<span class="line-added">+       break;</span>
      }
      if (C-&gt;failing())  return true;
    }
  
<span class="line-added">+   // All nodes except Allocate nodes are expanded now. There could be</span>
<span class="line-added">+   // new optimization opportunities (such as folding newly created</span>
<span class="line-added">+   // load from a just allocated object). Run IGVN.</span>
<span class="line-added">+   _igvn.set_delay_transform(false);</span>
<span class="line-added">+   _igvn.optimize();</span>
<span class="line-added">+   if (C-&gt;failing())  return true;</span>
<span class="line-added">+ </span>
<span class="line-added">+   _igvn.set_delay_transform(true);</span>
<span class="line-added">+ </span>
    // expand &quot;macro&quot; nodes
    // nodes are removed from the macro list as they are processed
    while (C-&gt;macro_count() &gt; 0) {
      int macro_count = C-&gt;macro_count();
      Node * n = C-&gt;macro_node(macro_count-1);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2587,16 ***</span>
        expand_allocate(n-&gt;as_Allocate());
        break;
      case Node::Class_AllocateArray:
        expand_allocate_array(n-&gt;as_AllocateArray());
        break;
<span class="line-removed">-     case Node::Class_Lock:</span>
<span class="line-removed">-       expand_lock_node(n-&gt;as_Lock());</span>
<span class="line-removed">-       break;</span>
<span class="line-removed">-     case Node::Class_Unlock:</span>
<span class="line-removed">-       expand_unlock_node(n-&gt;as_Unlock());</span>
<span class="line-removed">-       break;</span>
      default:
        assert(false, &quot;unknown node type in macro list&quot;);
      }
      assert(C-&gt;macro_count() &lt; macro_count, &quot;must have deleted a node from macro list&quot;);
      if (C-&gt;failing())  return true;
<span class="line-new-header">--- 2769,10 ---</span>
</pre>
<center><a href="machnode.hpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.hpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>