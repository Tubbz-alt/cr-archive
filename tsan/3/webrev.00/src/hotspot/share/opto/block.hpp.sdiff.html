<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/block.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="block.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="buildOopMap.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/block.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_OPTO_BLOCK_HPP
 26 #define SHARE_OPTO_BLOCK_HPP
 27 
 28 #include &quot;opto/multnode.hpp&quot;
 29 #include &quot;opto/node.hpp&quot;
 30 #include &quot;opto/phase.hpp&quot;

 31 
 32 // Optimization - Graph Style
 33 
 34 class Block;
 35 class CFGLoop;
 36 class MachCallNode;
 37 class Matcher;
 38 class RootNode;
 39 class VectorSet;
 40 class PhaseChaitin;
 41 struct Tarjan;
 42 
 43 //------------------------------Block_Array------------------------------------
 44 // Map dense integer indices to Blocks.  Uses classic doubling-array trick.
 45 // Abstractly provides an infinite array of Block*&#39;s, initialized to NULL.
 46 // Note that the constructor just zeros things, and since I use Arena
 47 // allocation I do not need a destructor to reclaim storage.
 48 class Block_Array : public ResourceObj {
 49   friend class VMStructs;
 50   uint _size;                   // allocated size, as opposed to formal limit
</pre>
<hr />
<pre>
300     // so (last-&gt;is_block_proj() != last) always, then simplify this code
301     // This will not give correct end_idx for block 0 when it only contains root.
302     int last_idx = _nodes.size() - 1;
303     Node *last  = _nodes[last_idx];
304     assert(last-&gt;is_block_proj() == last || last-&gt;is_block_proj() == _nodes[last_idx - _num_succs], &quot;&quot;);
305     return (last-&gt;is_block_proj() == last) ? last_idx : (last_idx - _num_succs);
306   }
307 
308   // Basic blocks have a Node which ends them.  This Node determines which
309   // basic block follows this one in the program flow.  This Node is either an
310   // IfNode, a GotoNode, a JmpNode, or a ReturnNode.
311   Node *end() const { return _nodes[end_idx()]; }
312 
313   // Add an instruction to an existing block.  It must go after the head
314   // instruction and before the end instruction.
315   void add_inst( Node *n ) { insert_node(n, end_idx()); }
316   // Find node in block. Fails if node not in block.
317   uint find_node( const Node *n ) const;
318   // Find and remove n from block list
319   void find_remove( const Node *n );
<span class="line-modified">320   // Check wether the node is in the block.</span>
321   bool contains (const Node *n) const;
322 
323   // Return the empty status of a block
324   enum { not_empty, empty_with_goto, completely_empty };
325   int is_Empty() const;
326 
327   // Forward through connectors
328   Block* non_connector() {
329     Block* s = this;
330     while (s-&gt;is_connector()) {
331       s = s-&gt;_succs[0];
332     }
333     return s;
334   }
335 
336   // Return true if b is a successor of this block
337   bool has_successor(Block* b) const {
338     for (uint i = 0; i &lt; _num_succs; i++ ) {
339       if (non_connector_successor(i) == b) {
340         return true;
</pre>
<hr />
<pre>
482   Block* insert_anti_dependences(Block* LCA, Node* load, bool verify = false);
483   void verify_anti_dependences(Block* LCA, Node* load) const {
484     assert(LCA == get_block_for_node(load), &quot;should already be scheduled&quot;);
485     const_cast&lt;PhaseCFG*&gt;(this)-&gt;insert_anti_dependences(LCA, load, true);
486   }
487 
488   bool move_to_next(Block* bx, uint b_index);
489   void move_to_end(Block* bx, uint b_index);
490 
491   void insert_goto_at(uint block_no, uint succ_no);
492 
493   // Check for NeverBranch at block end.  This needs to become a GOTO to the
494   // true target.  NeverBranch are treated as a conditional branch that always
495   // goes the same direction for most of the optimizer and are used to give a
496   // fake exit path to infinite loops.  At this late stage they need to turn
497   // into Goto&#39;s so that when you enter the infinite loop you indeed hang.
498   void convert_NeverBranch_to_Goto(Block *b);
499 
500   CFGLoop* create_loop_tree();
501   bool is_dominator(Node* dom_node, Node* node);
<span class="line-modified">502 </span>



503   #ifndef PRODUCT
504   bool _trace_opto_pipelining;  // tracing flag
505   #endif
506 
507  public:
508   PhaseCFG(Arena* arena, RootNode* root, Matcher&amp; matcher);
509 
510   void set_latency_for_node(Node* node, int latency) {
511     _node_latency-&gt;at_put_grow(node-&gt;_idx, latency);
512   }
513 
514   uint get_latency_for_node(Node* node) {
515     return _node_latency-&gt;at_grow(node-&gt;_idx);
516   }
517 
518   // Get the outer most frequency
519   double get_outer_loop_frequency() const {
520     return _outer_loop_frequency;
521   }
522 
</pre>
</td>
<td>
<hr />
<pre>
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #ifndef SHARE_OPTO_BLOCK_HPP
 26 #define SHARE_OPTO_BLOCK_HPP
 27 
 28 #include &quot;opto/multnode.hpp&quot;
 29 #include &quot;opto/node.hpp&quot;
 30 #include &quot;opto/phase.hpp&quot;
<span class="line-added"> 31 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
 32 
 33 // Optimization - Graph Style
 34 
 35 class Block;
 36 class CFGLoop;
 37 class MachCallNode;
 38 class Matcher;
 39 class RootNode;
 40 class VectorSet;
 41 class PhaseChaitin;
 42 struct Tarjan;
 43 
 44 //------------------------------Block_Array------------------------------------
 45 // Map dense integer indices to Blocks.  Uses classic doubling-array trick.
 46 // Abstractly provides an infinite array of Block*&#39;s, initialized to NULL.
 47 // Note that the constructor just zeros things, and since I use Arena
 48 // allocation I do not need a destructor to reclaim storage.
 49 class Block_Array : public ResourceObj {
 50   friend class VMStructs;
 51   uint _size;                   // allocated size, as opposed to formal limit
</pre>
<hr />
<pre>
301     // so (last-&gt;is_block_proj() != last) always, then simplify this code
302     // This will not give correct end_idx for block 0 when it only contains root.
303     int last_idx = _nodes.size() - 1;
304     Node *last  = _nodes[last_idx];
305     assert(last-&gt;is_block_proj() == last || last-&gt;is_block_proj() == _nodes[last_idx - _num_succs], &quot;&quot;);
306     return (last-&gt;is_block_proj() == last) ? last_idx : (last_idx - _num_succs);
307   }
308 
309   // Basic blocks have a Node which ends them.  This Node determines which
310   // basic block follows this one in the program flow.  This Node is either an
311   // IfNode, a GotoNode, a JmpNode, or a ReturnNode.
312   Node *end() const { return _nodes[end_idx()]; }
313 
314   // Add an instruction to an existing block.  It must go after the head
315   // instruction and before the end instruction.
316   void add_inst( Node *n ) { insert_node(n, end_idx()); }
317   // Find node in block. Fails if node not in block.
318   uint find_node( const Node *n ) const;
319   // Find and remove n from block list
320   void find_remove( const Node *n );
<span class="line-modified">321   // Check whether the node is in the block.</span>
322   bool contains (const Node *n) const;
323 
324   // Return the empty status of a block
325   enum { not_empty, empty_with_goto, completely_empty };
326   int is_Empty() const;
327 
328   // Forward through connectors
329   Block* non_connector() {
330     Block* s = this;
331     while (s-&gt;is_connector()) {
332       s = s-&gt;_succs[0];
333     }
334     return s;
335   }
336 
337   // Return true if b is a successor of this block
338   bool has_successor(Block* b) const {
339     for (uint i = 0; i &lt; _num_succs; i++ ) {
340       if (non_connector_successor(i) == b) {
341         return true;
</pre>
<hr />
<pre>
483   Block* insert_anti_dependences(Block* LCA, Node* load, bool verify = false);
484   void verify_anti_dependences(Block* LCA, Node* load) const {
485     assert(LCA == get_block_for_node(load), &quot;should already be scheduled&quot;);
486     const_cast&lt;PhaseCFG*&gt;(this)-&gt;insert_anti_dependences(LCA, load, true);
487   }
488 
489   bool move_to_next(Block* bx, uint b_index);
490   void move_to_end(Block* bx, uint b_index);
491 
492   void insert_goto_at(uint block_no, uint succ_no);
493 
494   // Check for NeverBranch at block end.  This needs to become a GOTO to the
495   // true target.  NeverBranch are treated as a conditional branch that always
496   // goes the same direction for most of the optimizer and are used to give a
497   // fake exit path to infinite loops.  At this late stage they need to turn
498   // into Goto&#39;s so that when you enter the infinite loop you indeed hang.
499   void convert_NeverBranch_to_Goto(Block *b);
500 
501   CFGLoop* create_loop_tree();
502   bool is_dominator(Node* dom_node, Node* node);
<span class="line-modified">503   bool is_CFG(Node* n);</span>
<span class="line-added">504   bool is_control_proj_or_safepoint(Node* n);</span>
<span class="line-added">505   Block* find_block_for_node(Node* n);</span>
<span class="line-added">506   bool is_dominating_control(Node* dom_ctrl, Node* n);</span>
507   #ifndef PRODUCT
508   bool _trace_opto_pipelining;  // tracing flag
509   #endif
510 
511  public:
512   PhaseCFG(Arena* arena, RootNode* root, Matcher&amp; matcher);
513 
514   void set_latency_for_node(Node* node, int latency) {
515     _node_latency-&gt;at_put_grow(node-&gt;_idx, latency);
516   }
517 
518   uint get_latency_for_node(Node* node) {
519     return _node_latency-&gt;at_grow(node-&gt;_idx);
520   }
521 
522   // Get the outer most frequency
523   double get_outer_loop_frequency() const {
524     return _outer_loop_frequency;
525   }
526 
</pre>
</td>
</tr>
</table>
<center><a href="block.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="buildOopMap.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>