diff a/src/hotspot/share/opto/loopTransform.cpp b/src/hotspot/share/opto/loopTransform.cpp
--- a/src/hotspot/share/opto/loopTransform.cpp
+++ b/src/hotspot/share/opto/loopTransform.cpp
@@ -43,17 +43,17 @@
 
 //------------------------------is_loop_exit-----------------------------------
 // Given an IfNode, return the loop-exiting projection or NULL if both
 // arms remain in the loop.
 Node *IdealLoopTree::is_loop_exit(Node *iff) const {
-  if( iff->outcnt() != 2 ) return NULL; // Ignore partially dead tests
+  if (iff->outcnt() != 2) return NULL;  // Ignore partially dead tests
   PhaseIdealLoop *phase = _phase;
   // Test is an IfNode, has 2 projections.  If BOTH are in the loop
   // we need loop unswitching instead of peeling.
-  if( !is_member(phase->get_loop( iff->raw_out(0) )) )
+  if (!is_member(phase->get_loop(iff->raw_out(0))))
     return iff->raw_out(0);
-  if( !is_member(phase->get_loop( iff->raw_out(1) )) )
+  if (!is_member(phase->get_loop(iff->raw_out(1))))
     return iff->raw_out(1);
   return NULL;
 }
 
 
@@ -61,11 +61,11 @@
 
 
 //------------------------------record_for_igvn----------------------------
 // Put loop body on igvn work list
 void IdealLoopTree::record_for_igvn() {
-  for( uint i = 0; i < _body.size(); i++ ) {
+  for (uint i = 0; i < _body.size(); i++) {
     Node *n = _body.at(i);
     _phase->_igvn._worklist.push(n);
   }
   // put body of outer strip mined loop on igvn work list as well
   if (_head->is_CountedLoop() && _head->as_Loop()->is_strip_mined()) {
@@ -143,11 +143,13 @@
     IfNode *iff = n->as_If();
     if (iff->_fcnt != COUNT_UNKNOWN && iff->_prob != PROB_UNKNOWN) {
       Node *exit = is_loop_exit(iff);
       if (exit) {
         float exit_prob = iff->_prob;
-        if (exit->Opcode() == Op_IfFalse) exit_prob = 1.0 - exit_prob;
+        if (exit->Opcode() == Op_IfFalse) {
+          exit_prob = 1.0 - exit_prob;
+        }
         if (exit_prob > PROB_MIN) {
           float exit_cnt = iff->_fcnt * exit_prob;
           return exit_cnt;
         }
       }
@@ -200,11 +202,11 @@
     float loop_back_cnt = back_if->_fcnt * (back->Opcode() == Op_IfTrue ? back_if->_prob : (1 - back_if->_prob));
 
     // Now compute a loop exit count
     float loop_exit_cnt = 0.0f;
     if (_child == NULL) {
-      for( uint i = 0; i < _body.size(); i++ ) {
+      for (uint i = 0; i < _body.size(); i++) {
         Node *n = _body[i];
         loop_exit_cnt += compute_profile_trip_cnt_helper(n);
       }
     } else {
       ResourceMark rm;
@@ -282,10 +284,13 @@
   if (n1->is_Add() && n1->in(2)->is_Con()) return NULL;
   Node* inv1 = n1->in(inv1_idx);
   Node* n2 = n1->in(3 - inv1_idx);
   int inv2_idx = is_invariant_addition(n2, phase);
   if (!inv2_idx) return NULL;
+
+  if (!phase->may_require_nodes(10, 10)) return NULL;
+
   Node* x    = n2->in(3 - inv2_idx);
   Node* inv2 = n2->in(inv2_idx);
 
   bool neg_x    = n2->is_Sub() && inv2_idx == 1;
   bool neg_inv2 = n2->is_Sub() && inv2_idx == 2;
@@ -333,85 +338,111 @@
     Node *n = _body.at(i);
     for (int j = 0; j < 5; j++) {
       Node* nn = reassociate_add_sub(n, phase);
       if (nn == NULL) break;
       n = nn; // again
-    };
+    }
   }
 }
 
 //------------------------------policy_peeling---------------------------------
-// Return TRUE or FALSE if the loop should be peeled or not.  Peel if we can
-// make some loop-invariant test (usually a null-check) happen before the loop.
-bool IdealLoopTree::policy_peeling( PhaseIdealLoop *phase ) const {
-  Node *test = ((IdealLoopTree*)this)->tail();
-  int  body_size = ((IdealLoopTree*)this)->_body.size();
-  // Peeling does loop cloning which can result in O(N^2) node construction
-  if( body_size > 255 /* Prevent overflow for large body_size */
-      || (body_size * body_size + phase->C->live_nodes()) > phase->C->max_node_limit() ) {
-    return false;           // too large to safely clone
+// Return TRUE if the loop should be peeled, otherwise return FALSE. Peeling
+// is applicable if we can make a loop-invariant test (usually a null-check)
+// execute before we enter the loop. When TRUE, the estimated node budget is
+// also requested.
+bool IdealLoopTree::policy_peeling(PhaseIdealLoop *phase) {
+  uint estimate = estimate_peeling(phase);
+
+  return estimate == 0 ? false : phase->may_require_nodes(estimate);
+}
+
+// Perform actual policy and size estimate for the loop peeling transform, and
+// return the estimated loop size if peeling is applicable, otherwise return
+// zero. No node budget is allocated.
+uint IdealLoopTree::estimate_peeling(PhaseIdealLoop *phase) {
+
+  // If nodes are depleted, some transform has miscalculated its needs.
+  assert(!phase->exceeding_node_budget(), "sanity");
+
+  // Peeling does loop cloning which can result in O(N^2) node construction.
+  if (_body.size() > 255) {
+    return 0;   // Suppress too large body size.
   }
+  // Optimistic estimate that approximates loop body complexity via data and
+  // control flow fan-out (instead of using the more pessimistic: BodySize^2).
+  uint estimate = est_loop_clone_sz(2);
 
-  // check for vectorized loops, any peeling done was already applied
-  if (_head->is_CountedLoop() && _head->as_CountedLoop()->do_unroll_only()) return false;
+  if (phase->exceeding_node_budget(estimate)) {
+    return 0;   // Too large to safely clone.
+  }
 
-  if (_head->is_CountedLoop() && _head->as_CountedLoop()->trip_count() == 1) {
-    return false;
+  // Check for vectorized loops, any peeling done was already applied.
+  if (_head->is_CountedLoop()) {
+    CountedLoopNode* cl = _head->as_CountedLoop();
+    if (cl->is_unroll_only() || cl->trip_count() == 1) {
+      return 0;
+    }
   }
 
-  while( test != _head ) {      // Scan till run off top of loop
-    if( test->is_If() ) {       // Test?
+  Node* test = tail();
+
+  while (test != _head) {   // Scan till run off top of loop
+    if (test->is_If()) {    // Test?
       Node *ctrl = phase->get_ctrl(test->in(1));
-      if (ctrl->is_top())
-        return false;           // Found dead test on live IF?  No peeling!
-      // Standard IF only has one input value to check for loop invariance
-      assert(test->Opcode() == Op_If || test->Opcode() == Op_CountedLoopEnd || test->Opcode() == Op_RangeCheck, "Check this code when new subtype is added");
+      if (ctrl->is_top()) {
+        return 0;           // Found dead test on live IF?  No peeling!
+      }
+      // Standard IF only has one input value to check for loop invariance.
+      assert(test->Opcode() == Op_If ||
+             test->Opcode() == Op_CountedLoopEnd ||
+             test->Opcode() == Op_RangeCheck,
+             "Check this code when new subtype is added");
       // Condition is not a member of this loop?
-      if( !is_member(phase->get_loop(ctrl)) &&
-          is_loop_exit(test) )
-        return true;            // Found reason to peel!
+      if (!is_member(phase->get_loop(ctrl)) && is_loop_exit(test)) {
+        return estimate;    // Found reason to peel!
+      }
     }
-    // Walk up dominators to loop _head looking for test which is
-    // executed on every path thru loop.
+    // Walk up dominators to loop _head looking for test which is executed on
+    // every path through the loop.
     test = phase->idom(test);
   }
-  return false;
+  return 0;
 }
 
 //------------------------------peeled_dom_test_elim---------------------------
 // If we got the effect of peeling, either by actually peeling or by making
 // a pre-loop which must execute at least once, we can remove all
 // loop-invariant dominated tests in the main body.
-void PhaseIdealLoop::peeled_dom_test_elim( IdealLoopTree *loop, Node_List &old_new ) {
+void PhaseIdealLoop::peeled_dom_test_elim(IdealLoopTree *loop, Node_List &old_new) {
   bool progress = true;
-  while( progress ) {
+  while (progress) {
     progress = false;           // Reset for next iteration
     Node *prev = loop->_head->in(LoopNode::LoopBackControl);//loop->tail();
     Node *test = prev->in(0);
-    while( test != loop->_head ) { // Scan till run off top of loop
+    while (test != loop->_head) { // Scan till run off top of loop
 
       int p_op = prev->Opcode();
-      if( (p_op == Op_IfFalse || p_op == Op_IfTrue) &&
+      if ((p_op == Op_IfFalse || p_op == Op_IfTrue) &&
           test->is_If() &&      // Test?
           !test->in(1)->is_Con() && // And not already obvious?
           // Condition is not a member of this loop?
           !loop->is_member(get_loop(get_ctrl(test->in(1))))){
         // Walk loop body looking for instances of this test
-        for( uint i = 0; i < loop->_body.size(); i++ ) {
+        for (uint i = 0; i < loop->_body.size(); i++) {
           Node *n = loop->_body.at(i);
-          if( n->is_If() && n->in(1) == test->in(1) /*&& n != loop->tail()->in(0)*/ ) {
+          if (n->is_If() && n->in(1) == test->in(1) /*&& n != loop->tail()->in(0)*/) {
             // IfNode was dominated by version in peeled loop body
             progress = true;
-            dominated_by( old_new[prev->_idx], n );
+            dominated_by(old_new[prev->_idx], n);
           }
         }
       }
       prev = test;
       test = idom(test);
     } // End of scan tests in loop
 
-  } // End of while( progress )
+  } // End of while (progress)
 }
 
 //------------------------------do_peeling-------------------------------------
 // Peel the first iteration of the given loop.
 // Step 1: Clone the loop body.  The clone becomes the peeled iteration.
@@ -548,11 +579,11 @@
 //            region
 //              |
 //              v
 //             exit
 //
-void PhaseIdealLoop::do_peeling( IdealLoopTree *loop, Node_List &old_new ) {
+void PhaseIdealLoop::do_peeling(IdealLoopTree *loop, Node_List &old_new) {
 
   C->set_major_progress();
   // Peeling a 'main' loop in a pre/main/post situation obfuscates the
   // 'pre' loop from the main and the 'pre' can no longer have its
   // iterations adjusted.  Therefore, we need to declare this loop as
@@ -597,11 +628,11 @@
   head->skip_strip_mined()->set_req(LoopNode::EntryControl, new_entry);
   for (DUIterator_Fast jmax, j = head->fast_outs(jmax); j < jmax; j++) {
     Node* old = head->fast_out(j);
     if (old->in(0) == loop->_head && old->req() == 3 && old->is_Phi()) {
       Node* new_exit_value = old_new[old->in(LoopNode::LoopBackControl)->_idx];
-      if (!new_exit_value )     // Backedge value is ALSO loop invariant?
+      if (!new_exit_value)     // Backedge value is ALSO loop invariant?
         // Then loop body backedge value remains the same.
         new_exit_value = old->in(LoopNode::LoopBackControl);
       _igvn.hash_delete(old);
       old->set_req(LoopNode::EntryControl, new_exit_value);
     }
@@ -619,74 +650,73 @@
       _igvn.hash_delete(use);
       use->set_req(LoopNode::LoopBackControl, C->top());
     }
   }
 
-
   // Step 4: Correct dom-depth info.  Set to loop-head depth.
-  int dd = dom_depth(head);
-  set_idom(head, head->in(1), dd);
+
+  int dd = dom_depth(head->skip_strip_mined());
+  set_idom(head->skip_strip_mined(), head->skip_strip_mined()->in(LoopNode::EntryControl), dd);
   for (uint j3 = 0; j3 < loop->_body.size(); j3++) {
     Node *old = loop->_body.at(j3);
     Node *nnn = old_new[old->_idx];
-    if (!has_ctrl(nnn))
+    if (!has_ctrl(nnn)) {
       set_idom(nnn, idom(nnn), dd-1);
+    }
   }
 
   // Now force out all loop-invariant dominating tests.  The optimizer
   // finds some, but we _know_ they are all useless.
   peeled_dom_test_elim(loop,old_new);
 
   loop->record_for_igvn();
 }
 
-#define EMPTY_LOOP_SIZE 7 // number of nodes in an empty loop
-
 //------------------------------policy_maximally_unroll------------------------
-// Calculate exact loop trip count and return true if loop can be maximally
-// unrolled.
-bool IdealLoopTree::policy_maximally_unroll( PhaseIdealLoop *phase ) const {
-  CountedLoopNode *cl = _head->as_CountedLoop();
+// Calculate the exact  loop trip-count and return TRUE if loop can be fully,
+// i.e. maximally, unrolled, otherwise return FALSE. When TRUE, the estimated
+// node budget is also requested.
+bool IdealLoopTree::policy_maximally_unroll(PhaseIdealLoop* phase) const {
+  CountedLoopNode* cl = _head->as_CountedLoop();
   assert(cl->is_normal_loop(), "");
-  if (!cl->is_valid_counted_loop())
-    return false; // Malformed counted loop
-
+  if (!cl->is_valid_counted_loop()) {
+    return false;   // Malformed counted loop.
+  }
   if (!cl->has_exact_trip_count()) {
-    // Trip count is not exact.
-    return false;
+    return false;   // Trip count is not exact.
   }
 
   uint trip_count = cl->trip_count();
   // Note, max_juint is used to indicate unknown trip count.
   assert(trip_count > 1, "one iteration loop should be optimized out already");
-  assert(trip_count < max_juint, "exact trip_count should be less than max_uint.");
+  assert(trip_count < max_juint, "exact trip_count should be less than max_juint.");
 
-  // Real policy: if we maximally unroll, does it get too big?
-  // Allow the unrolled mess to get larger than standard loop
-  // size.  After all, it will no longer be a loop.
-  uint body_size    = _body.size();
+  // If nodes are depleted, some transform has miscalculated its needs.
+  assert(!phase->exceeding_node_budget(), "sanity");
+
+  // Allow the unrolled body to get larger than the standard loop size limit.
   uint unroll_limit = (uint)LoopUnrollLimit * 4;
-  assert( (intx)unroll_limit == LoopUnrollLimit * 4, "LoopUnrollLimit must fit in 32bits");
-  if (trip_count > unroll_limit || body_size > unroll_limit) {
+  assert((intx)unroll_limit == LoopUnrollLimit * 4, "LoopUnrollLimit must fit in 32bits");
+  if (trip_count > unroll_limit || _body.size() > unroll_limit) {
     return false;
   }
 
-  // Fully unroll a loop with few iterations regardless next
-  // conditions since following loop optimizations will split
-  // such loop anyway (pre-main-post).
-  if (trip_count <= 3)
-    return true;
+  uint new_body_size = est_loop_unroll_sz(trip_count);
 
-  // Take into account that after unroll conjoined heads and tails will fold,
-  // otherwise policy_unroll() may allow more unrolling than max unrolling.
-  uint new_body_size = EMPTY_LOOP_SIZE + (body_size - EMPTY_LOOP_SIZE) * trip_count;
-  uint tst_body_size = (new_body_size - EMPTY_LOOP_SIZE) / trip_count + EMPTY_LOOP_SIZE;
-  if (body_size != tst_body_size) // Check for int overflow
+  if (new_body_size == UINT_MAX) { // Check for bad estimate (overflow).
     return false;
-  if (new_body_size > unroll_limit ||
-      // Unrolling can result in a large amount of node construction
-      new_body_size >= phase->C->max_node_limit() - phase->C->live_nodes()) {
+  }
+
+  // Fully unroll a loop with few iterations, regardless of other conditions,
+  // since the following (general) loop optimizations will split such loop in
+  // any case (into pre-main-post).
+  if (trip_count <= 3) {
+    return phase->may_require_nodes(new_body_size);
+  }
+
+  // Reject if unrolling will result in too much node construction.
+  if (new_body_size > unroll_limit || phase->exceeding_node_budget(new_body_size)) {
     return false;
   }
 
   // Do not unroll a loop with String intrinsics code.
   // String intrinsics are large and have loops.
@@ -712,61 +742,67 @@
       }
 #endif
     } // switch
   }
 
-  return true; // Do maximally unroll
+  return phase->may_require_nodes(new_body_size);
 }
 
 
 //------------------------------policy_unroll----------------------------------
-// Return TRUE or FALSE if the loop should be unrolled or not.  Unroll if
-// the loop is a CountedLoop and the body is small enough.
+// Return TRUE or FALSE if the loop should be unrolled or not. Apply unroll if
+// the loop is  a counted loop and  the loop body is small  enough. When TRUE,
+// the estimated node budget is also requested.
 bool IdealLoopTree::policy_unroll(PhaseIdealLoop *phase) {
 
   CountedLoopNode *cl = _head->as_CountedLoop();
   assert(cl->is_normal_loop() || cl->is_main_loop(), "");
 
-  if (!cl->is_valid_counted_loop())
+  if (!cl->is_valid_counted_loop()) {
     return false; // Malformed counted loop
+  }
+
+  // If nodes are depleted, some transform has miscalculated its needs.
+  assert(!phase->exceeding_node_budget(), "sanity");
 
   // Protect against over-unrolling.
   // After split at least one iteration will be executed in pre-loop.
-  if (cl->trip_count() <= (uint)(cl->is_normal_loop() ? 2 : 1)) return false;
-
-  _local_loop_unroll_limit = LoopUnrollLimit;
+  if (cl->trip_count() <= (cl->is_normal_loop() ? 2u : 1u)) {
+    return false;
+  }
+  _local_loop_unroll_limit  = LoopUnrollLimit;
   _local_loop_unroll_factor = 4;
-  int future_unroll_ct = cl->unrolled_count() * 2;
+  int future_unroll_cnt = cl->unrolled_count() * 2;
   if (!cl->is_vectorized_loop()) {
-    if (future_unroll_ct > LoopMaxUnroll) return false;
+    if (future_unroll_cnt > LoopMaxUnroll) return false;
   } else {
     // obey user constraints on vector mapped loops with additional unrolling applied
     int unroll_constraint = (cl->slp_max_unroll()) ? cl->slp_max_unroll() : 1;
-    if ((future_unroll_ct / unroll_constraint) > LoopMaxUnroll) return false;
+    if ((future_unroll_cnt / unroll_constraint) > LoopMaxUnroll) return false;
   }
 
   // Check for initial stride being a small enough constant
-  if (abs(cl->stride_con()) > (1<<2)*future_unroll_ct) return false;
+  if (abs(cl->stride_con()) > (1<<2)*future_unroll_cnt) return false;
 
   // Don't unroll if the next round of unrolling would push us
   // over the expected trip count of the loop.  One is subtracted
   // from the expected trip count because the pre-loop normally
   // executes 1 iteration.
   if (UnrollLimitForProfileCheck > 0 &&
       cl->profile_trip_cnt() != COUNT_UNKNOWN &&
-      future_unroll_ct        > UnrollLimitForProfileCheck &&
-      (float)future_unroll_ct > cl->profile_trip_cnt() - 1.0) {
+      future_unroll_cnt        > UnrollLimitForProfileCheck &&
+      (float)future_unroll_cnt > cl->profile_trip_cnt() - 1.0) {
     return false;
   }
 
   // When unroll count is greater than LoopUnrollMin, don't unroll if:
   //   the residual iterations are more than 10% of the trip count
   //   and rounds of "unroll,optimize" are not making significant progress
   //   Progress defined as current size less than 20% larger than previous size.
   if (UseSuperWord && cl->node_count_before_unroll() > 0 &&
-      future_unroll_ct > LoopUnrollMin &&
-      (future_unroll_ct - 1) * (100 / LoopPercentProfileLimit) > cl->profile_trip_cnt() &&
+      future_unroll_cnt > LoopUnrollMin &&
+      (future_unroll_cnt - 1) * (100 / LoopPercentProfileLimit) > cl->profile_trip_cnt() &&
       1.2 * cl->node_count_before_unroll() < (double)_body.size()) {
     return false;
   }
 
   Node *init_n = cl->init_trip();
@@ -846,46 +882,54 @@
 
     // Only attempt slp analysis when user controls do not prohibit it
     if (LoopMaxUnroll > _local_loop_unroll_factor) {
       // Once policy_slp_analysis succeeds, mark the loop with the
       // maximal unroll factor so that we minimize analysis passes
-      if (future_unroll_ct >= _local_loop_unroll_factor) {
-        policy_unroll_slp_analysis(cl, phase, future_unroll_ct);
+      if (future_unroll_cnt >= _local_loop_unroll_factor) {
+        policy_unroll_slp_analysis(cl, phase, future_unroll_cnt);
       }
     }
   }
 
   int slp_max_unroll_factor = cl->slp_max_unroll();
   if ((LoopMaxUnroll < slp_max_unroll_factor) && FLAG_IS_DEFAULT(LoopMaxUnroll) && UseSubwordForMaxVector) {
     LoopMaxUnroll = slp_max_unroll_factor;
   }
+
+  uint estimate = est_loop_clone_sz(2);
+
   if (cl->has_passed_slp()) {
-    if (slp_max_unroll_factor >= future_unroll_ct) return true;
-    // Normal case: loop too big
-    return false;
+    if (slp_max_unroll_factor >= future_unroll_cnt) {
+      return phase->may_require_nodes(estimate);
+    }
+    return false; // Loop too big.
   }
 
   // Check for being too big
   if (body_size > (uint)_local_loop_unroll_limit) {
-    if ((cl->is_subword_loop() || xors_in_loop >= 4) && body_size < (uint)LoopUnrollLimit * 4) {
-      return true;
+    if ((cl->is_subword_loop() || xors_in_loop >= 4) && body_size < 4u * LoopUnrollLimit) {
+      return phase->may_require_nodes(estimate);
     }
-    // Normal case: loop too big
-    return false;
+    return false; // Loop too big.
   }
 
-  if (cl->do_unroll_only()) {
+  if (cl->is_unroll_only()) {
     if (TraceSuperWordLoopUnrollAnalysis) {
-      tty->print_cr("policy_unroll passed vector loop(vlen=%d,factor = %d)\n", slp_max_unroll_factor, future_unroll_ct);
+      tty->print_cr("policy_unroll passed vector loop(vlen=%d, factor=%d)\n",
+                    slp_max_unroll_factor, future_unroll_cnt);
     }
   }
 
   // Unroll once!  (Each trip will soon do double iterations)
-  return true;
+  return phase->may_require_nodes(estimate);
 }
 
-void IdealLoopTree::policy_unroll_slp_analysis(CountedLoopNode *cl, PhaseIdealLoop *phase, int future_unroll_ct) {
+void IdealLoopTree::policy_unroll_slp_analysis(CountedLoopNode *cl, PhaseIdealLoop *phase, int future_unroll_cnt) {
+
+  // If nodes are depleted, some transform has miscalculated its needs.
+  assert(!phase->exceeding_node_budget(), "sanity");
+
   // Enable this functionality target by target as needed
   if (SuperWordLoopUnrollAnalysis) {
     if (!cl->was_slp_analyzed()) {
       SuperWord sw(phase);
       sw.transform_loop(this, false);
@@ -896,11 +940,11 @@
       }
     }
 
     if (cl->has_passed_slp()) {
       int slp_max_unroll_factor = cl->slp_max_unroll();
-      if (slp_max_unroll_factor >= future_unroll_ct) {
+      if (slp_max_unroll_factor >= future_unroll_cnt) {
         int new_limit = cl->node_count_before_unroll() * slp_max_unroll_factor;
         if (new_limit > LoopUnrollLimit) {
           if (TraceSuperWordLoopUnrollAnalysis) {
             tty->print_cr("slp analysis unroll=%d, default limit=%d\n", new_limit, _local_loop_unroll_limit);
           }
@@ -915,134 +959,151 @@
 // Return TRUE or FALSE if the loop should be cache-line aligned.  Gather the
 // expression that does the alignment.  Note that only one array base can be
 // aligned in a loop (unless the VM guarantees mutual alignment).  Note that
 // if we vectorize short memory ops into longer memory ops, we may want to
 // increase alignment.
-bool IdealLoopTree::policy_align( PhaseIdealLoop *phase ) const {
+bool IdealLoopTree::policy_align(PhaseIdealLoop *phase) const {
   return false;
 }
 
 //------------------------------policy_range_check-----------------------------
-// Return TRUE or FALSE if the loop should be range-check-eliminated.
-// Actually we do iteration-splitting, a more powerful form of RCE.
-bool IdealLoopTree::policy_range_check( PhaseIdealLoop *phase ) const {
+// Return TRUE or FALSE if the loop should be range-check-eliminated or not.
+// When TRUE, the estimated node budget is also requested.
+//
+// We will actually perform iteration-splitting, a more powerful form of RCE.
+bool IdealLoopTree::policy_range_check(PhaseIdealLoop *phase) const {
   if (!RangeCheckElimination) return false;
 
+  // If nodes are depleted, some transform has miscalculated its needs.
+  assert(!phase->exceeding_node_budget(), "sanity");
+
   CountedLoopNode *cl = _head->as_CountedLoop();
-  // If we unrolled with no intention of doing RCE and we later
-  // changed our minds, we got no pre-loop.  Either we need to
-  // make a new pre-loop, or we gotta disallow RCE.
+  // If we unrolled  with no intention of doing RCE and we  later changed our
+  // minds, we got no pre-loop.  Either we need to make a new pre-loop, or we
+  // have to disallow RCE.
   if (cl->is_main_no_pre_loop()) return false; // Disallowed for now.
   Node *trip_counter = cl->phi();
 
   // check for vectorized loops, some opts are no longer needed
-  if (cl->do_unroll_only()) return false;
+  if (cl->is_unroll_only()) return false;
 
   // Check loop body for tests of trip-counter plus loop-invariant vs
   // loop-invariant.
   for (uint i = 0; i < _body.size(); i++) {
     Node *iff = _body[i];
     if (iff->Opcode() == Op_If ||
         iff->Opcode() == Op_RangeCheck) { // Test?
 
       // Comparing trip+off vs limit
       Node *bol = iff->in(1);
-      if (bol->req() != 2) continue; // dead constant test
+      if (bol->req() != 2) {
+        continue; // dead constant test
+      }
       if (!bol->is_Bool()) {
         assert(bol->Opcode() == Op_Conv2B, "predicate check only");
         continue;
       }
-      if (bol->as_Bool()->_test._test == BoolTest::ne)
+      if (bol->as_Bool()->_test._test == BoolTest::ne) {
         continue; // not RC
-
+      }
       Node *cmp = bol->in(1);
       Node *rc_exp = cmp->in(1);
       Node *limit = cmp->in(2);
 
       Node *limit_c = phase->get_ctrl(limit);
-      if( limit_c == phase->C->top() )
+      if (limit_c == phase->C->top()) {
         return false;           // Found dead test on live IF?  No RCE!
-      if( is_member(phase->get_loop(limit_c) ) ) {
+      }
+      if (is_member(phase->get_loop(limit_c))) {
         // Compare might have operands swapped; commute them
         rc_exp = cmp->in(2);
         limit  = cmp->in(1);
         limit_c = phase->get_ctrl(limit);
-        if( is_member(phase->get_loop(limit_c) ) )
+        if (is_member(phase->get_loop(limit_c))) {
           continue;             // Both inputs are loop varying; cannot RCE
+        }
       }
 
       if (!phase->is_scaled_iv_plus_offset(rc_exp, trip_counter, NULL, NULL)) {
         continue;
       }
-      // Yeah!  Found a test like 'trip+off vs limit'
-      // Test is an IfNode, has 2 projections.  If BOTH are in the loop
-      // we need loop unswitching instead of iteration splitting.
-      if( is_loop_exit(iff) )
-        return true;            // Found reason to split iterations
+      // Found a test like 'trip+off vs limit'. Test is an IfNode, has two (2)
+      // projections. If BOTH are in the loop we need loop unswitching instead
+      // of iteration splitting.
+      if (is_loop_exit(iff)) {
+        // Found valid reason to split iterations (if there is room).
+        // NOTE: Usually a gross overestimate.
+        return phase->may_require_nodes(est_loop_clone_sz(2));
+      }
     } // End of is IF
   }
 
   return false;
 }
 
 //------------------------------policy_peel_only-------------------------------
 // Return TRUE or FALSE if the loop should NEVER be RCE'd or aligned.  Useful
 // for unrolling loops with NO array accesses.
-bool IdealLoopTree::policy_peel_only( PhaseIdealLoop *phase ) const {
+bool IdealLoopTree::policy_peel_only(PhaseIdealLoop *phase) const {
+
+  // If nodes are depleted, some transform has miscalculated its needs.
+  assert(!phase->exceeding_node_budget(), "sanity");
+
   // check for vectorized loops, any peeling done was already applied
-  if (_head->is_CountedLoop() && _head->as_CountedLoop()->do_unroll_only()) return false;
+  if (_head->is_CountedLoop() && _head->as_CountedLoop()->is_unroll_only()) {
+    return false;
+  }
 
-  for( uint i = 0; i < _body.size(); i++ )
-    if( _body[i]->is_Mem() )
+  for (uint i = 0; i < _body.size(); i++) {
+    if (_body[i]->is_Mem()) {
       return false;
-
+    }
+  }
   // No memory accesses at all!
   return true;
 }
 
 //------------------------------clone_up_backedge_goo--------------------------
 // If Node n lives in the back_ctrl block and cannot float, we clone a private
 // version of n in preheader_ctrl block and return that, otherwise return n.
-Node *PhaseIdealLoop::clone_up_backedge_goo( Node *back_ctrl, Node *preheader_ctrl, Node *n, VectorSet &visited, Node_Stack &clones ) {
-  if( get_ctrl(n) != back_ctrl ) return n;
+Node *PhaseIdealLoop::clone_up_backedge_goo(Node *back_ctrl, Node *preheader_ctrl, Node *n, VectorSet &visited, Node_Stack &clones) {
+  if (get_ctrl(n) != back_ctrl) return n;
 
   // Only visit once
   if (visited.test_set(n->_idx)) {
     Node *x = clones.find(n->_idx);
-    if (x != NULL)
-      return x;
-    return n;
+    return (x != NULL) ? x : n;
   }
 
   Node *x = NULL;               // If required, a clone of 'n'
   // Check for 'n' being pinned in the backedge.
-  if( n->in(0) && n->in(0) == back_ctrl ) {
+  if (n->in(0) && n->in(0) == back_ctrl) {
     assert(clones.find(n->_idx) == NULL, "dead loop");
     x = n->clone();             // Clone a copy of 'n' to preheader
     clones.push(x, n->_idx);
-    x->set_req( 0, preheader_ctrl ); // Fix x's control input to preheader
+    x->set_req(0, preheader_ctrl); // Fix x's control input to preheader
   }
 
   // Recursive fixup any other input edges into x.
   // If there are no changes we can just return 'n', otherwise
   // we need to clone a private copy and change it.
-  for( uint i = 1; i < n->req(); i++ ) {
-    Node *g = clone_up_backedge_goo( back_ctrl, preheader_ctrl, n->in(i), visited, clones );
-    if( g != n->in(i) ) {
-      if( !x ) {
+  for (uint i = 1; i < n->req(); i++) {
+    Node *g = clone_up_backedge_goo(back_ctrl, preheader_ctrl, n->in(i), visited, clones);
+    if (g != n->in(i)) {
+      if (!x) {
         assert(clones.find(n->_idx) == NULL, "dead loop");
         x = n->clone();
         clones.push(x, n->_idx);
       }
       x->set_req(i, g);
     }
   }
-  if( x ) {                     // x can legally float to pre-header location
-    register_new_node( x, preheader_ctrl );
+  if (x) {                     // x can legally float to pre-header location
+    register_new_node(x, preheader_ctrl);
     return x;
   } else {                      // raise n to cover LCA of uses
-    set_ctrl( n, find_non_split_ctrl(back_ctrl->in(0)) );
+    set_ctrl(n, find_non_split_ctrl(back_ctrl->in(0)));
   }
   return n;
 }
 
 Node* PhaseIdealLoop::cast_incr_before_loop(Node* incr, Node* ctrl, Node* loop) {
@@ -1204,11 +1265,11 @@
   proj->set_req(0, new_iff);
   other_proj->set_req(0, new_iff);
   Node *frame = new ParmNode(C->start(), TypeFunc::FramePtr);
   register_new_node(frame, C->start());
   // It's impossible for the predicate to fail at runtime. Use an Halt node.
-  Node* halt = new HaltNode(other_proj, frame);
+  Node* halt = new HaltNode(other_proj, frame, "duplicated predicate failed which is impossible");
   C->root()->add_req(halt);
   new_iff->set_req(0, prev_proj);
 
   register_control(new_iff, outer_loop->_parent, prev_proj);
   register_control(proj, outer_loop->_parent, new_iff);
@@ -1242,11 +1303,11 @@
 
 //------------------------------insert_pre_post_loops--------------------------
 // Insert pre and post loops.  If peel_only is set, the pre-loop can not have
 // more iterations added.  It acts as a 'peel' only, no lower-bound RCE, no
 // alignment.  Useful to unroll loops that do no array accesses.
-void PhaseIdealLoop::insert_pre_post_loops( IdealLoopTree *loop, Node_List &old_new, bool peel_only ) {
+void PhaseIdealLoop::insert_pre_post_loops(IdealLoopTree *loop, Node_List &old_new, bool peel_only) {
 
 #ifndef PRODUCT
   if (TraceLoopOpts) {
     if (peel_only)
       tty->print("PeelMainPost ");
@@ -1257,13 +1318,13 @@
 #endif
   C->set_major_progress();
 
   // Find common pieces of the loop being guarded with pre & post loops
   CountedLoopNode *main_head = loop->_head->as_CountedLoop();
-  assert( main_head->is_normal_loop(), "" );
+  assert(main_head->is_normal_loop(), "");
   CountedLoopEndNode *main_end = main_head->loopexit();
-  assert( main_end->outcnt() == 2, "1 true, 1 false path only" );
+  assert(main_end->outcnt() == 2, "1 true, 1 false path only");
 
   Node *pre_header= main_head->in(LoopNode::EntryControl);
   Node *init      = main_head->init_trip();
   Node *incr      = main_end ->incr();
   Node *limit     = main_end ->limit();
@@ -1271,17 +1332,17 @@
   Node *cmp       = main_end ->cmp_node();
   BoolTest::mask b_test = main_end->test_trip();
 
   // Need only 1 user of 'bol' because I will be hacking the loop bounds.
   Node *bol = main_end->in(CountedLoopEndNode::TestValue);
-  if( bol->outcnt() != 1 ) {
+  if (bol->outcnt() != 1) {
     bol = bol->clone();
     register_new_node(bol,main_end->in(CountedLoopEndNode::TestControl));
     _igvn.replace_input_of(main_end, CountedLoopEndNode::TestValue, bol);
   }
   // Need only 1 user of 'cmp' because I will be hacking the loop bounds.
-  if( cmp->outcnt() != 1 ) {
+  if (cmp->outcnt() != 1) {
     cmp = cmp->clone();
     register_new_node(cmp,main_end->in(CountedLoopEndNode::TestControl));
     _igvn.replace_input_of(bol, 1, cmp);
   }
 
@@ -1312,41 +1373,41 @@
   // Reduce the pre-loop trip count.
   pre_end->_prob = PROB_FAIR;
 
   // Find the pre-loop normal exit.
   Node* pre_exit = pre_end->proj_out(false);
-  assert( pre_exit->Opcode() == Op_IfFalse, "" );
+  assert(pre_exit->Opcode() == Op_IfFalse, "");
   IfFalseNode *new_pre_exit = new IfFalseNode(pre_end);
-  _igvn.register_new_node_with_optimizer( new_pre_exit );
+  _igvn.register_new_node_with_optimizer(new_pre_exit);
   set_idom(new_pre_exit, pre_end, dd_main_head);
   set_loop(new_pre_exit, outer_loop->_parent);
 
   // Step B2: Build a zero-trip guard for the main-loop.  After leaving the
   // pre-loop, the main-loop may not execute at all.  Later in life this
   // zero-trip guard will become the minimum-trip guard when we unroll
   // the main-loop.
   Node *min_opaq = new Opaque1Node(C, limit);
-  Node *min_cmp  = new CmpINode( pre_incr, min_opaq );
-  Node *min_bol  = new BoolNode( min_cmp, b_test );
-  register_new_node( min_opaq, new_pre_exit );
-  register_new_node( min_cmp , new_pre_exit );
-  register_new_node( min_bol , new_pre_exit );
+  Node *min_cmp  = new CmpINode(pre_incr, min_opaq);
+  Node *min_bol  = new BoolNode(min_cmp, b_test);
+  register_new_node(min_opaq, new_pre_exit);
+  register_new_node(min_cmp , new_pre_exit);
+  register_new_node(min_bol , new_pre_exit);
 
   // Build the IfNode (assume the main-loop is executed always).
-  IfNode *min_iff = new IfNode( new_pre_exit, min_bol, PROB_ALWAYS, COUNT_UNKNOWN );
-  _igvn.register_new_node_with_optimizer( min_iff );
+  IfNode *min_iff = new IfNode(new_pre_exit, min_bol, PROB_ALWAYS, COUNT_UNKNOWN);
+  _igvn.register_new_node_with_optimizer(min_iff);
   set_idom(min_iff, new_pre_exit, dd_main_head);
   set_loop(min_iff, outer_loop->_parent);
 
   // Plug in the false-path, taken if we need to skip main-loop
-  _igvn.hash_delete( pre_exit );
+  _igvn.hash_delete(pre_exit);
   pre_exit->set_req(0, min_iff);
   set_idom(pre_exit, min_iff, dd_main_head);
   set_idom(pre_exit->unique_ctrl_out(), min_iff, dd_main_head);
   // Make the true-path, must enter the main loop
-  Node *min_taken = new IfTrueNode( min_iff );
-  _igvn.register_new_node_with_optimizer( min_taken );
+  Node *min_taken = new IfTrueNode(min_iff);
+  _igvn.register_new_node_with_optimizer(min_taken);
   set_idom(min_taken, min_iff, dd_main_head);
   set_loop(min_taken, outer_loop->_parent);
   // Plug in the true path
   _igvn.hash_delete(outer_main_head);
   outer_main_head->set_req(LoopNode::EntryControl, min_taken);
@@ -1357,18 +1418,18 @@
   Node_Stack clones(a, main_head->back_control()->outcnt());
   // Step B3: Make the fall-in values to the main-loop come from the
   // fall-out values of the pre-loop.
   for (DUIterator_Fast i2max, i2 = main_head->fast_outs(i2max); i2 < i2max; i2++) {
     Node* main_phi = main_head->fast_out(i2);
-    if( main_phi->is_Phi() && main_phi->in(0) == main_head && main_phi->outcnt() > 0 ) {
+    if (main_phi->is_Phi() && main_phi->in(0) == main_head && main_phi->outcnt() > 0) {
       Node *pre_phi = old_new[main_phi->_idx];
       Node *fallpre  = clone_up_backedge_goo(pre_head->back_control(),
                                              main_head->skip_strip_mined()->in(LoopNode::EntryControl),
                                              pre_phi->in(LoopNode::LoopBackControl),
                                              visited, clones);
       _igvn.hash_delete(main_phi);
-      main_phi->set_req( LoopNode::EntryControl, fallpre );
+      main_phi->set_req(LoopNode::EntryControl, fallpre);
     }
   }
 
   // Nodes inside the loop may be control dependent on a predicate
   // that was moved before the preloop. If the back branch of the main
@@ -1379,31 +1440,31 @@
   // the if branch that enters the loop, between the input induction
   // variable value and the induction variable Phi to preserve correct
   // dependencies.
 
   // CastII for the main loop:
-  Node* castii = cast_incr_before_loop( pre_incr, min_taken, main_head );
+  Node* castii = cast_incr_before_loop(pre_incr, min_taken, main_head);
   assert(castii != NULL, "no castII inserted");
   Node* opaque_castii = new Opaque1Node(C, castii);
   register_new_node(opaque_castii, outer_main_head->in(LoopNode::EntryControl));
   duplicate_predicates(pre_head, castii, opaque_castii, outer_loop, outer_main_head, dd_main_head);
 
   // Step B4: Shorten the pre-loop to run only 1 iteration (for now).
   // RCE and alignment may change this later.
   Node *cmp_end = pre_end->cmp_node();
-  assert( cmp_end->in(2) == limit, "" );
-  Node *pre_limit = new AddINode( init, stride );
+  assert(cmp_end->in(2) == limit, "");
+  Node *pre_limit = new AddINode(init, stride);
 
   // Save the original loop limit in this Opaque1 node for
   // use by range check elimination.
   Node *pre_opaq  = new Opaque1Node(C, pre_limit, limit);
 
-  register_new_node( pre_limit, pre_head->in(0) );
-  register_new_node( pre_opaq , pre_head->in(0) );
+  register_new_node(pre_limit, pre_head->in(0));
+  register_new_node(pre_opaq , pre_head->in(0));
 
   // Since no other users of pre-loop compare, I can hack limit directly
-  assert( cmp_end->outcnt() == 1, "no other users" );
+  assert(cmp_end->outcnt() == 1, "no other users");
   _igvn.hash_delete(cmp_end);
   cmp_end->set_req(2, peel_only ? pre_limit : pre_opaq);
 
   // Special case for not-equal loop bounds:
   // Change pre loop test, main loop test, and the
@@ -1419,28 +1480,30 @@
 
     BoolTest::mask new_test = (main_end->stride_con() > 0) ? BoolTest::lt : BoolTest::gt;
     // Modify pre loop end condition
     Node* pre_bol = pre_end->in(CountedLoopEndNode::TestValue)->as_Bool();
     BoolNode* new_bol0 = new BoolNode(pre_bol->in(1), new_test);
-    register_new_node( new_bol0, pre_head->in(0) );
+    register_new_node(new_bol0, pre_head->in(0));
     _igvn.replace_input_of(pre_end, CountedLoopEndNode::TestValue, new_bol0);
     // Modify main loop guard condition
     assert(min_iff->in(CountedLoopEndNode::TestValue) == min_bol, "guard okay");
     BoolNode* new_bol1 = new BoolNode(min_bol->in(1), new_test);
-    register_new_node( new_bol1, new_pre_exit );
+    register_new_node(new_bol1, new_pre_exit);
     _igvn.hash_delete(min_iff);
     min_iff->set_req(CountedLoopEndNode::TestValue, new_bol1);
     // Modify main loop end condition
     BoolNode* main_bol = main_end->in(CountedLoopEndNode::TestValue)->as_Bool();
     BoolNode* new_bol2 = new BoolNode(main_bol->in(1), new_test);
-    register_new_node( new_bol2, main_end->in(CountedLoopEndNode::TestControl) );
+    register_new_node(new_bol2, main_end->in(CountedLoopEndNode::TestControl));
     _igvn.replace_input_of(main_end, CountedLoopEndNode::TestValue, new_bol2);
   }
 
   // Flag main loop
   main_head->set_main_loop();
-  if( peel_only ) main_head->set_main_no_pre_loop();
+  if (peel_only) {
+    main_head->set_main_no_pre_loop();
+  }
 
   // Subtract a trip count for the pre-loop.
   main_head->set_trip_count(main_head->trip_count() - 1);
 
   // It's difficult to be precise about the trip-counts
@@ -1455,12 +1518,13 @@
   loop->record_for_igvn();
 }
 
 //------------------------------insert_vector_post_loop------------------------
 // Insert a copy of the atomic unrolled vectorized main loop as a post loop,
-// unroll_policy has already informed us that more unrolling is about to happen to
-// the main loop.  The resultant post loop will serve as a vectorized drain loop.
+// unroll_policy has  already informed  us that more  unrolling is  about to
+// happen  to the  main  loop.  The  resultant  post loop  will  serve as  a
+// vectorized drain loop.
 void PhaseIdealLoop::insert_vector_post_loop(IdealLoopTree *loop, Node_List &old_new) {
   if (!loop->_head->is_CountedLoop()) return;
 
   CountedLoopNode *cl = loop->_head->as_CountedLoop();
 
@@ -1476,10 +1540,14 @@
   if (cur_unroll != slp_max_unroll_factor) return;
 
   // we only ever process this one time
   if (cl->has_atomic_post_loop()) return;
 
+  if (!may_require_nodes(loop->est_loop_clone_sz(2))) {
+    return;
+  }
+
 #ifndef PRODUCT
   if (TraceLoopOpts) {
     tty->print("PostVector  ");
     loop->dump_head();
   }
@@ -1636,11 +1704,11 @@
   Node_Stack clones(a, main_head->back_control()->outcnt());
   // Step A3: Make the fall-in values to the post-loop come from the
   // fall-out values of the main-loop.
   for (DUIterator_Fast imax, i = main_head->fast_outs(imax); i < imax; i++) {
     Node* main_phi = main_head->fast_out(i);
-    if (main_phi->is_Phi() && main_phi->in(0) == main_head && main_phi->outcnt() >0) {
+    if (main_phi->is_Phi() && main_phi->in(0) == main_head && main_phi->outcnt() > 0) {
       Node *cur_phi = old_new[main_phi->_idx];
       Node *fallnew = clone_up_backedge_goo(main_head->back_control(),
                                             post_head->init_control(),
                                             main_phi->in(LoopNode::LoopBackControl),
                                             visited, clones);
@@ -1708,11 +1776,11 @@
   }
 }
 
 //------------------------------do_unroll--------------------------------------
 // Unroll the loop body one step - make each trip do 2 iterations.
-void PhaseIdealLoop::do_unroll( IdealLoopTree *loop, Node_List &old_new, bool adjust_min_trip ) {
+void PhaseIdealLoop::do_unroll(IdealLoopTree *loop, Node_List &old_new, bool adjust_min_trip) {
   assert(LoopUnrollLimit, "");
   CountedLoopNode *loop_head = loop->_head->as_CountedLoop();
   CountedLoopEndNode *loop_end = loop_head->loopexit();
 #ifndef PRODUCT
   if (PrintOpto && VerifyLoopOptimizations) {
@@ -1731,12 +1799,12 @@
     Arena* arena = Thread::current()->resource_area();
     Node_Stack stack(arena, C->live_nodes() >> 2);
     Node_List rpo_list;
     VectorSet visited(arena);
     visited.set(loop_head->_idx);
-    rpo( loop_head, stack, visited, rpo_list );
-    dump(loop, rpo_list.size(), rpo_list );
+    rpo(loop_head, stack, visited, rpo_list);
+    dump(loop, rpo_list.size(), rpo_list);
   }
 #endif
 
   // Remember loop node count before unrolling to detect
   // if rounds of unroll,optimize are making progress
@@ -1809,11 +1877,12 @@
     assert(opaq != NULL && opaq->in(1) == limit, "sanity");
 
     // Verify that policy_unroll result is still valid.
     const TypeInt* limit_type = _igvn.type(limit)->is_int();
     assert(stride_con > 0 && ((limit_type->_hi - stride_con) < limit_type->_hi) ||
-        stride_con < 0 && ((limit_type->_lo - stride_con) > limit_type->_lo), "sanity");
+           stride_con < 0 && ((limit_type->_lo - stride_con) > limit_type->_lo),
+           "sanity");
 
     if (limit->is_Con()) {
       // The check in policy_unroll and the assert above guarantee
       // no underflow if limit is constant.
       new_limit = _igvn.intcon(limit->get_int() - stride_con);
@@ -1827,12 +1896,12 @@
         // Otherwise reorg_offsets() optimization will create a separate
         // Opaque node for each use of trip-counter and as result
         // zero trip guard limit will be different from loop limit.
         assert(has_ctrl(opaq), "should have it");
         Node* opaq_ctrl = get_ctrl(opaq);
-        limit = new Opaque2Node( C, limit );
-        register_new_node( limit, opaq_ctrl );
+        limit = new Opaque2Node(C, limit);
+        register_new_node(limit, opaq_ctrl);
       }
       if ((stride_con > 0 && (java_subtract(limit_type->_lo, stride_con) < limit_type->_lo)) ||
           (stride_con < 0 && (java_subtract(limit_type->_hi, stride_con) > limit_type->_hi))) {
         // No underflow.
         new_limit = new SubINode(limit, stride);
@@ -1869,19 +1938,20 @@
         } else {
           old_limit = limit;
           adj_limit = new SubINode(limit, stride);
         }
         assert(old_limit != NULL && adj_limit != NULL, "");
-        register_new_node( adj_limit, ctrl ); // adjust amount
+        register_new_node(adj_limit, ctrl); // adjust amount
         Node* adj_cmp = new CmpINode(old_limit, adj_limit);
-        register_new_node( adj_cmp, ctrl );
+        register_new_node(adj_cmp, ctrl);
         Node* adj_bool = new BoolNode(adj_cmp, bt);
-        register_new_node( adj_bool, ctrl );
+        register_new_node(adj_bool, ctrl);
         new_limit = new CMoveINode(adj_bool, adj_limit, adj_max, TypeInt::INT);
       }
       register_new_node(new_limit, ctrl);
     }
+
     assert(new_limit != NULL, "");
     // Replace in loop test.
     assert(loop_end->in(1)->in(1) == cmp, "sanity");
     if (cmp->outcnt() == 1 && loop_end->in(1)->outcnt() == 1) {
       // Don't need to create new test since only one user.
@@ -1927,44 +1997,45 @@
 
   // Make backedges of the clone equal to backedges of the original.
   // Make the fall-in from the original come from the fall-out of the clone.
   for (DUIterator_Fast jmax, j = loop_head->fast_outs(jmax); j < jmax; j++) {
     Node* phi = loop_head->fast_out(j);
-    if( phi->is_Phi() && phi->in(0) == loop_head && phi->outcnt() > 0 ) {
+    if (phi->is_Phi() && phi->in(0) == loop_head && phi->outcnt() > 0) {
       Node *newphi = old_new[phi->_idx];
-      _igvn.hash_delete( phi );
-      _igvn.hash_delete( newphi );
+      _igvn.hash_delete(phi);
+      _igvn.hash_delete(newphi);
 
       phi   ->set_req(LoopNode::   EntryControl, newphi->in(LoopNode::LoopBackControl));
       newphi->set_req(LoopNode::LoopBackControl, phi   ->in(LoopNode::LoopBackControl));
       phi   ->set_req(LoopNode::LoopBackControl, C->top());
     }
   }
   Node *clone_head = old_new[loop_head->_idx];
-  _igvn.hash_delete( clone_head );
+  _igvn.hash_delete(clone_head);
   loop_head ->set_req(LoopNode::   EntryControl, clone_head->in(LoopNode::LoopBackControl));
   clone_head->set_req(LoopNode::LoopBackControl, loop_head ->in(LoopNode::LoopBackControl));
   loop_head ->set_req(LoopNode::LoopBackControl, C->top());
   loop->_head = clone_head;     // New loop header
 
   set_idom(loop_head,  loop_head ->in(LoopNode::EntryControl), dd);
   set_idom(clone_head, clone_head->in(LoopNode::EntryControl), dd);
 
   // Kill the clone's backedge
   Node *newcle = old_new[loop_end->_idx];
-  _igvn.hash_delete( newcle );
+  _igvn.hash_delete(newcle);
   Node *one = _igvn.intcon(1);
   set_ctrl(one, C->root());
   newcle->set_req(1, one);
   // Force clone into same loop body
   uint max = loop->_body.size();
-  for( uint k = 0; k < max; k++ ) {
+  for (uint k = 0; k < max; k++) {
     Node *old = loop->_body.at(k);
     Node *nnn = old_new[old->_idx];
     loop->_body.push(nnn);
-    if (!has_ctrl(old))
+    if (!has_ctrl(old)) {
       set_loop(nnn, loop);
+    }
   }
 
   loop->record_for_igvn();
   loop_head->clear_strip_mined();
 
@@ -1972,11 +2043,11 @@
   if (C->do_vector_loop() && (PrintOpto && (VerifyLoopOptimizations || TraceLoopOpts))) {
     tty->print("\nnew loop after unroll\n");       loop->dump_head();
     for (uint i = 0; i < loop->_body.size(); i++) {
       loop->_body.at(i)->dump();
     }
-    if(C->clone_map().is_debug()) {
+    if (C->clone_map().is_debug()) {
       tty->print("\nCloneMap\n");
       Dict* dict = C->clone_map().dict();
       DictI i(dict);
       tty->print_cr("Dict@%p[%d] = ", dict, dict->Size());
       for (int ii = 0; i.test(); ++i, ++ii) {
@@ -1988,16 +2059,15 @@
       }
       tty->print_cr(" ");
     }
   }
 #endif
-
 }
 
 //------------------------------do_maximally_unroll----------------------------
 
-void PhaseIdealLoop::do_maximally_unroll( IdealLoopTree *loop, Node_List &old_new ) {
+void PhaseIdealLoop::do_maximally_unroll(IdealLoopTree *loop, Node_List &old_new) {
   CountedLoopNode *cl = loop->_head->as_CountedLoop();
   assert(cl->has_exact_trip_count(), "trip count is not exact");
   assert(cl->trip_count() > 0, "");
 #ifndef PRODUCT
   if (TraceLoopOpts) {
@@ -2111,11 +2181,11 @@
 //    low_limit <= scale_con * I + offset  <  upper_limit
 // always holds true.  That is, either increase the number of iterations in
 // the pre-loop or the post-loop until the condition holds true in the main
 // loop.  Stride, scale, offset and limit are all loop invariant.  Further,
 // stride and scale are constants (offset and limit often are).
-void PhaseIdealLoop::add_constraint( int stride_con, int scale_con, Node *offset, Node *low_limit, Node *upper_limit, Node *pre_ctrl, Node **pre_limit, Node **main_limit ) {
+void PhaseIdealLoop::add_constraint(int stride_con, int scale_con, Node *offset, Node *low_limit, Node *upper_limit, Node *pre_ctrl, Node **pre_limit, Node **main_limit) {
   // For positive stride, the pre-loop limit always uses a MAX function
   // and the main loop a MIN function.  For negative stride these are
   // reversed.
 
   // Also for positive stride*scale the affine function is increasing, so the
@@ -2196,11 +2266,11 @@
     // in do_range_check() for stride > 0 and max() for < 0.
     Node *one  = _igvn.intcon(1);
     set_ctrl(one, C->root());
 
     Node *plus_one = new AddINode(offset, one);
-    register_new_node( plus_one, pre_ctrl );
+    register_new_node(plus_one, pre_ctrl);
     // Pass (-stride) to indicate pre_loop_cond = NOT(main_loop_cond);
     *pre_limit = adjust_limit((-stride_con), scale, plus_one, upper_limit, *pre_limit, pre_ctrl,
                               scale_con < -1 && stride_con > 0);
 
     if (low_limit->get_int() == -max_jint) {
@@ -2357,37 +2427,38 @@
   register_control(iffalse, _ltree_root, new_iff);
   ProjNode* iftrue = new IfTrueNode(new_iff);
   register_control(iftrue, loop->_parent, new_iff);
   Node *frame = new ParmNode(C->start(), TypeFunc::FramePtr);
   register_new_node(frame, C->start());
-  Node* halt = new HaltNode(iffalse, frame);
+  Node* halt = new HaltNode(iffalse, frame, "range check predicate failed which is impossible");
   register_control(halt, _ltree_root, iffalse);
   C->root()->add_req(halt);
   return iftrue;
 }
 
 //------------------------------do_range_check---------------------------------
 // Eliminate range-checks and other trip-counter vs loop-invariant tests.
-int PhaseIdealLoop::do_range_check( IdealLoopTree *loop, Node_List &old_new ) {
+int PhaseIdealLoop::do_range_check(IdealLoopTree *loop, Node_List &old_new) {
 #ifndef PRODUCT
   if (PrintOpto && VerifyLoopOptimizations) {
     tty->print("Range Check Elimination ");
     loop->dump_head();
   } else if (TraceLoopOpts) {
     tty->print("RangeCheck   ");
     loop->dump_head();
   }
 #endif
+
   assert(RangeCheckElimination, "");
   CountedLoopNode *cl = loop->_head->as_CountedLoop();
   // If we fail before trying to eliminate range checks, set multiversion state
   int closed_range_checks = 1;
 
   // protect against stride not being a constant
-  if (!cl->stride_is_con())
+  if (!cl->stride_is_con()) {
     return closed_range_checks;
-
+  }
   // Find the trip counter; we are iteration splitting based on it
   Node *trip_counter = cl->phi();
   // Find the main loop limit; we will trim it's iterations
   // to not ever trip end tests
   Node *main_limit = cl->limit();
@@ -2398,11 +2469,11 @@
   if (!is_canonical_loop_entry(cl)) {
     return closed_range_checks;
   }
 
   // Need to find the main-loop zero-trip guard
-  Node *ctrl  = cl->skip_predicates();
+  Node *ctrl = cl->skip_predicates();
   Node *iffm = ctrl->in(0);
   Node *opqzm = iffm->in(1)->in(1)->in(2);
   assert(opqzm->in(1) == main_limit, "do not understand situation");
 
   // Find the pre-loop limit; we will expand its iterations to
@@ -2416,24 +2487,25 @@
   assert(pre_end->loopnode()->is_pre_loop(), "");
   Node *pre_opaq1 = pre_end->limit();
   // Occasionally it's possible for a pre-loop Opaque1 node to be
   // optimized away and then another round of loop opts attempted.
   // We can not optimize this particular loop in that case.
-  if (pre_opaq1->Opcode() != Op_Opaque1)
+  if (pre_opaq1->Opcode() != Op_Opaque1) {
     return closed_range_checks;
+  }
   Opaque1Node *pre_opaq = (Opaque1Node*)pre_opaq1;
   Node *pre_limit = pre_opaq->in(1);
 
   // Where do we put new limit calculations
   Node *pre_ctrl = pre_end->loopnode()->in(LoopNode::EntryControl);
 
   // Ensure the original loop limit is available from the
   // pre-loop Opaque1 node.
   Node *orig_limit = pre_opaq->original_loop_limit();
-  if (orig_limit == NULL || _igvn.type(orig_limit) == Type::TOP)
+  if (orig_limit == NULL || _igvn.type(orig_limit) == Type::TOP) {
     return closed_range_checks;
-
+  }
   // Must know if its a count-up or count-down loop
 
   int stride_con = cl->stride_con();
   Node *zero = _igvn.intcon(0);
   Node *one  = _igvn.intcon(1);
@@ -2455,48 +2527,50 @@
   // the loop is in canonical form to multiversion.
   closed_range_checks = 0;
 
   Node* predicate_proj = cl->skip_strip_mined()->in(LoopNode::EntryControl);
   assert(predicate_proj->is_Proj() && predicate_proj->in(0)->is_If(), "if projection only");
+
   // Check loop body for tests of trip-counter plus loop-invariant vs loop-variant.
-  for( uint i = 0; i < loop->_body.size(); i++ ) {
+  for (uint i = 0; i < loop->_body.size(); i++) {
     Node *iff = loop->_body[i];
     if (iff->Opcode() == Op_If ||
         iff->Opcode() == Op_RangeCheck) { // Test?
       // Test is an IfNode, has 2 projections.  If BOTH are in the loop
       // we need loop unswitching instead of iteration splitting.
       closed_range_checks++;
       Node *exit = loop->is_loop_exit(iff);
-      if( !exit ) continue;
+      if (!exit) continue;
       int flip = (exit->Opcode() == Op_IfTrue) ? 1 : 0;
 
       // Get boolean condition to test
       Node *i1 = iff->in(1);
-      if( !i1->is_Bool() ) continue;
+      if (!i1->is_Bool()) continue;
       BoolNode *bol = i1->as_Bool();
       BoolTest b_test = bol->_test;
       // Flip sense of test if exit condition is flipped
-      if( flip )
+      if (flip) {
         b_test = b_test.negate();
-
+      }
       // Get compare
       Node *cmp = bol->in(1);
 
       // Look for trip_counter + offset vs limit
       Node *rc_exp = cmp->in(1);
       Node *limit  = cmp->in(2);
       int scale_con= 1;        // Assume trip counter not scaled
 
       Node *limit_c = get_ctrl(limit);
-      if( loop->is_member(get_loop(limit_c) ) ) {
+      if (loop->is_member(get_loop(limit_c))) {
         // Compare might have operands swapped; commute them
         b_test = b_test.commute();
         rc_exp = cmp->in(2);
         limit  = cmp->in(1);
         limit_c = get_ctrl(limit);
-        if( loop->is_member(get_loop(limit_c) ) )
+        if (loop->is_member(get_loop(limit_c))) {
           continue;             // Both inputs are loop varying; cannot RCE
+        }
       }
       // Here we know 'limit' is loop invariant
 
       // 'limit' maybe pinned below the zero trip test (probably from a
       // previous round of rce), in which case, it can't be used in the
@@ -2511,12 +2585,13 @@
       if (!is_scaled_iv_plus_offset(rc_exp, trip_counter, &scale_con, &offset)) {
         continue;
       }
 
       Node *offset_c = get_ctrl(offset);
-      if( loop->is_member( get_loop(offset_c) ) )
+      if (loop->is_member(get_loop(offset_c))) {
         continue;               // Offset is not really loop invariant
+      }
       // Here we know 'offset' is loop invariant.
 
       // As above for the 'limit', the 'offset' maybe pinned below the
       // zero trip test.
       if (is_dominator(ctrl, offset_c)) {
@@ -2534,14 +2609,14 @@
       // monotonically increases by stride_con, a constant.  Both (or either)
       // stride_con and scale_con can be negative which will flip about the
       // sense of the test.
 
       // Adjust pre and main loop limits to guard the correct iteration set
-      if( cmp->Opcode() == Op_CmpU ) {// Unsigned compare is really 2 tests
-        if( b_test._test == BoolTest::lt ) { // Range checks always use lt
+      if (cmp->Opcode() == Op_CmpU) { // Unsigned compare is really 2 tests
+        if (b_test._test == BoolTest::lt) { // Range checks always use lt
           // The underflow and overflow limits: 0 <= scale*I+offset < limit
-          add_constraint( stride_con, scale_con, offset, zero, limit, pre_ctrl, &pre_limit, &main_limit );
+          add_constraint(stride_con, scale_con, offset, zero, limit, pre_ctrl, &pre_limit, &main_limit);
           // (0-offset)/scale could be outside of loop iterations range.
           conditional_rc = true;
           Node* init = cl->init_trip();
           Node* opaque_init = new Opaque1Node(C, init);
           register_new_node(opaque_init, predicate_proj);
@@ -2564,33 +2639,33 @@
             tty->print_cr("missed RCE opportunity");
           }
           continue;             // In release mode, ignore it
         }
       } else {                  // Otherwise work on normal compares
-        switch( b_test._test ) {
+        switch(b_test._test) {
         case BoolTest::gt:
           // Fall into GE case
         case BoolTest::ge:
           // Convert (I*scale+offset) >= Limit to (I*(-scale)+(-offset)) <= -Limit
           scale_con = -scale_con;
-          offset = new SubINode( zero, offset );
-          register_new_node( offset, pre_ctrl );
-          limit  = new SubINode( zero, limit );
-          register_new_node( limit, pre_ctrl );
+          offset = new SubINode(zero, offset);
+          register_new_node(offset, pre_ctrl);
+          limit  = new SubINode(zero, limit);
+          register_new_node(limit, pre_ctrl);
           // Fall into LE case
         case BoolTest::le:
           if (b_test._test != BoolTest::gt) {
             // Convert X <= Y to X < Y+1
-            limit = new AddINode( limit, one );
-            register_new_node( limit, pre_ctrl );
+            limit = new AddINode(limit, one);
+            register_new_node(limit, pre_ctrl);
           }
           // Fall into LT case
         case BoolTest::lt:
           // The underflow and overflow limits: MIN_INT <= scale*I+offset < limit
           // Note: (MIN_INT+1 == -MAX_INT) is used instead of MIN_INT here
           // to avoid problem with scale == -1: MIN_INT/(-1) == MIN_INT.
-          add_constraint( stride_con, scale_con, offset, mini, limit, pre_ctrl, &pre_limit, &main_limit );
+          add_constraint(stride_con, scale_con, offset, mini, limit, pre_ctrl, &pre_limit, &main_limit);
           // ((MIN_INT+1)-offset)/scale could be outside of loop iterations range.
           // Note: negative offset is replaced with 0 but (MIN_INT+1)/scale could
           // still be outside of loop range.
           conditional_rc = true;
           break;
@@ -2602,11 +2677,11 @@
         }
       }
 
       // Kill the eliminated test
       C->set_major_progress();
-      Node *kill_con = _igvn.intcon( 1-flip );
+      Node *kill_con = _igvn.intcon(1-flip);
       set_ctrl(kill_con, C->root());
       _igvn.replace_input_of(iff, 1, kill_con);
       // Find surviving projection
       assert(iff->is_If(), "");
       ProjNode* dp = ((IfNode*)iff)->proj_out(1-flip);
@@ -2622,13 +2697,11 @@
         }
       }
       if (limit->Opcode() == Op_LoadRange) {
         closed_range_checks--;
       }
-
     } // End of is IF
-
   }
   if (predicate_proj != cl->skip_strip_mined()->in(LoopNode::EntryControl)) {
     _igvn.replace_input_of(cl->skip_strip_mined(), LoopNode::EntryControl, predicate_proj);
     set_idom(cl->skip_strip_mined(), predicate_proj, dom_depth(cl->skip_strip_mined()));
   }
@@ -2645,25 +2718,25 @@
   // need to round up based on stride.
   cl->set_nonexact_trip_count();
   Node *main_cle = cl->loopexit();
   Node *main_bol = main_cle->in(1);
   // Hacking loop bounds; need private copies of exit test
-  if( main_bol->outcnt() > 1 ) {// BoolNode shared?
-    main_bol = main_bol->clone();// Clone a private BoolNode
-    register_new_node( main_bol, main_cle->in(0) );
+  if (main_bol->outcnt() > 1) {     // BoolNode shared?
+    main_bol = main_bol->clone();   // Clone a private BoolNode
+    register_new_node(main_bol, main_cle->in(0));
     _igvn.replace_input_of(main_cle, 1, main_bol);
   }
   Node *main_cmp = main_bol->in(1);
-  if( main_cmp->outcnt() > 1 ) { // CmpNode shared?
-    main_cmp = main_cmp->clone();// Clone a private CmpNode
-    register_new_node( main_cmp, main_cle->in(0) );
+  if (main_cmp->outcnt() > 1) {     // CmpNode shared?
+    main_cmp = main_cmp->clone();   // Clone a private CmpNode
+    register_new_node(main_cmp, main_cle->in(0));
     _igvn.replace_input_of(main_bol, 1, main_cmp);
   }
   // Hack the now-private loop bounds
   _igvn.replace_input_of(main_cmp, 2, main_limit);
   // The OpaqueNode is unshared by design
-  assert( opqzm->outcnt() == 1, "cannot hack shared node" );
+  assert(opqzm->outcnt() == 1, "cannot hack shared node");
   _igvn.replace_input_of(opqzm, 1, main_limit);
 
   return closed_range_checks;
 }
 
@@ -2828,68 +2901,71 @@
 }
 
 //------------------------------DCE_loop_body----------------------------------
 // Remove simplistic dead code from loop body
 void IdealLoopTree::DCE_loop_body() {
-  for( uint i = 0; i < _body.size(); i++ )
-    if( _body.at(i)->outcnt() == 0 )
-      _body.map( i--, _body.pop() );
+  for (uint i = 0; i < _body.size(); i++) {
+    if (_body.at(i)->outcnt() == 0) {
+      _body.map(i, _body.pop());
+      i--; // Ensure we revisit the updated index.
+    }
+  }
 }
 
 
 //------------------------------adjust_loop_exit_prob--------------------------
 // Look for loop-exit tests with the 50/50 (or worse) guesses from the parsing stage.
 // Replace with a 1-in-10 exit guess.
-void IdealLoopTree::adjust_loop_exit_prob( PhaseIdealLoop *phase ) {
+void IdealLoopTree::adjust_loop_exit_prob(PhaseIdealLoop *phase) {
   Node *test = tail();
-  while( test != _head ) {
+  while (test != _head) {
     uint top = test->Opcode();
-    if( top == Op_IfTrue || top == Op_IfFalse ) {
+    if (top == Op_IfTrue || top == Op_IfFalse) {
       int test_con = ((ProjNode*)test)->_con;
       assert(top == (uint)(test_con? Op_IfTrue: Op_IfFalse), "sanity");
       IfNode *iff = test->in(0)->as_If();
-      if( iff->outcnt() == 2 ) {        // Ignore dead tests
+      if (iff->outcnt() == 2) {         // Ignore dead tests
         Node *bol = iff->in(1);
-        if( bol && bol->req() > 1 && bol->in(1) &&
-            ((bol->in(1)->Opcode() == Op_StorePConditional ) ||
-             (bol->in(1)->Opcode() == Op_StoreIConditional ) ||
-             (bol->in(1)->Opcode() == Op_StoreLConditional ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndExchangeB ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndExchangeS ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndExchangeI ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndExchangeL ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndExchangeP ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndExchangeN ) ||
-             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapB ) ||
-             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapS ) ||
-             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapI ) ||
-             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapL ) ||
-             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapP ) ||
-             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapN ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndSwapB ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndSwapS ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndSwapI ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndSwapL ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndSwapP ) ||
-             (bol->in(1)->Opcode() == Op_CompareAndSwapN ) ||
-             (bol->in(1)->Opcode() == Op_ShenandoahCompareAndExchangeP ) ||
-             (bol->in(1)->Opcode() == Op_ShenandoahCompareAndExchangeN ) ||
-             (bol->in(1)->Opcode() == Op_ShenandoahWeakCompareAndSwapP ) ||
-             (bol->in(1)->Opcode() == Op_ShenandoahWeakCompareAndSwapN ) ||
-             (bol->in(1)->Opcode() == Op_ShenandoahCompareAndSwapP ) ||
-             (bol->in(1)->Opcode() == Op_ShenandoahCompareAndSwapN )))
+        if (bol && bol->req() > 1 && bol->in(1) &&
+            ((bol->in(1)->Opcode() == Op_StorePConditional) ||
+             (bol->in(1)->Opcode() == Op_StoreIConditional) ||
+             (bol->in(1)->Opcode() == Op_StoreLConditional) ||
+             (bol->in(1)->Opcode() == Op_CompareAndExchangeB) ||
+             (bol->in(1)->Opcode() == Op_CompareAndExchangeS) ||
+             (bol->in(1)->Opcode() == Op_CompareAndExchangeI) ||
+             (bol->in(1)->Opcode() == Op_CompareAndExchangeL) ||
+             (bol->in(1)->Opcode() == Op_CompareAndExchangeP) ||
+             (bol->in(1)->Opcode() == Op_CompareAndExchangeN) ||
+             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapB) ||
+             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapS) ||
+             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapI) ||
+             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapL) ||
+             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapP) ||
+             (bol->in(1)->Opcode() == Op_WeakCompareAndSwapN) ||
+             (bol->in(1)->Opcode() == Op_CompareAndSwapB) ||
+             (bol->in(1)->Opcode() == Op_CompareAndSwapS) ||
+             (bol->in(1)->Opcode() == Op_CompareAndSwapI) ||
+             (bol->in(1)->Opcode() == Op_CompareAndSwapL) ||
+             (bol->in(1)->Opcode() == Op_CompareAndSwapP) ||
+             (bol->in(1)->Opcode() == Op_CompareAndSwapN) ||
+             (bol->in(1)->Opcode() == Op_ShenandoahCompareAndExchangeP) ||
+             (bol->in(1)->Opcode() == Op_ShenandoahCompareAndExchangeN) ||
+             (bol->in(1)->Opcode() == Op_ShenandoahWeakCompareAndSwapP) ||
+             (bol->in(1)->Opcode() == Op_ShenandoahWeakCompareAndSwapN) ||
+             (bol->in(1)->Opcode() == Op_ShenandoahCompareAndSwapP) ||
+             (bol->in(1)->Opcode() == Op_ShenandoahCompareAndSwapN)))
           return;               // Allocation loops RARELY take backedge
         // Find the OTHER exit path from the IF
         Node* ex = iff->proj_out(1-test_con);
         float p = iff->_prob;
-        if( !phase->is_member( this, ex ) && iff->_fcnt == COUNT_UNKNOWN ) {
-          if( top == Op_IfTrue ) {
-            if( p < (PROB_FAIR + PROB_UNLIKELY_MAG(3))) {
+        if (!phase->is_member(this, ex) && iff->_fcnt == COUNT_UNKNOWN) {
+          if (top == Op_IfTrue) {
+            if (p < (PROB_FAIR + PROB_UNLIKELY_MAG(3))) {
               iff->_prob = PROB_STATIC_FREQUENT;
             }
           } else {
-            if( p > (PROB_FAIR - PROB_UNLIKELY_MAG(3))) {
+            if (p > (PROB_FAIR - PROB_UNLIKELY_MAG(3))) {
               iff->_prob = PROB_STATIC_INFREQUENT;
             }
           }
         }
       }
@@ -2897,20 +2973,21 @@
     test = phase->idom(test);
   }
 }
 
 #ifdef ASSERT
-static CountedLoopNode* locate_pre_from_main(CountedLoopNode *cl) {
-  Node *ctrl  = cl->skip_predicates();
+static CountedLoopNode* locate_pre_from_main(CountedLoopNode* main_loop) {
+  assert(!main_loop->is_main_no_pre_loop(), "Does not have a pre loop");
+  Node* ctrl = main_loop->skip_predicates();
   assert(ctrl->Opcode() == Op_IfTrue || ctrl->Opcode() == Op_IfFalse, "");
-  Node *iffm = ctrl->in(0);
+  Node* iffm = ctrl->in(0);
   assert(iffm->Opcode() == Op_If, "");
-  Node *p_f = iffm->in(0);
+  Node* p_f = iffm->in(0);
   assert(p_f->Opcode() == Op_IfFalse, "");
-  CountedLoopEndNode *pre_end = p_f->in(0)->as_CountedLoopEnd();
-  assert(pre_end->loopnode()->is_pre_loop(), "");
-  return pre_end->loopnode();
+  CountedLoopNode* pre_loop = p_f->in(0)->as_CountedLoopEnd()->loopnode();
+  assert(pre_loop->is_pre_loop(), "No pre loop found");
+  return pre_loop;
 }
 #endif
 
 // Remove the main and post loops and make the pre loop execute all
 // iterations. Useful when the pre loop is found empty.
@@ -2932,11 +3009,11 @@
   if (!next_head->is_CountedLoop()) {
     return;
   }
 
   CountedLoopNode* main_head = next_head->as_CountedLoop();
-  if (!main_head->is_main_loop()) {
+  if (!main_head->is_main_loop() || main_head->is_main_no_pre_loop()) {
     return;
   }
 
   assert(locate_pre_from_main(main_head) == cl, "bad main loop");
   Node* main_iff = main_head->skip_predicates()->in(0);
@@ -2947,44 +3024,46 @@
   Node* main_cmp = main_iff->in(1)->in(1);
   assert(main_cmp->in(2)->Opcode() == Op_Opaque1, "main loop has no opaque node?");
   phase->_igvn.replace_input_of(main_cmp, 2, main_cmp->in(2)->in(1));
 }
 
-//------------------------------policy_do_remove_empty_loop--------------------
-// Micro-benchmark spamming.  Policy is to always remove empty loops.
-// The 'DO' part is to replace the trip counter with the value it will
-// have on the last iteration.  This will break the loop.
-bool IdealLoopTree::policy_do_remove_empty_loop( PhaseIdealLoop *phase ) {
+//------------------------------do_remove_empty_loop---------------------------
+// We always attempt remove empty loops.   The approach is to replace the trip
+// counter with the value it will have on the last iteration.  This will break
+// the loop.
+bool IdealLoopTree::do_remove_empty_loop(PhaseIdealLoop *phase) {
   // Minimum size must be empty loop
-  if (_body.size() > EMPTY_LOOP_SIZE)
+  if (_body.size() > EMPTY_LOOP_SIZE) {
     return false;
-
-  if (!_head->is_CountedLoop())
-    return false;     // Dead loop
+  }
+  if (!_head->is_CountedLoop()) {
+    return false;   // Dead loop
+  }
   CountedLoopNode *cl = _head->as_CountedLoop();
-  if (!cl->is_valid_counted_loop())
-    return false; // Malformed loop
-  if (!phase->is_member(this, phase->get_ctrl(cl->loopexit()->in(CountedLoopEndNode::TestValue))))
-    return false;             // Infinite loop
-
+  if (!cl->is_valid_counted_loop()) {
+    return false;   // Malformed loop
+  }
+  if (!phase->is_member(this, phase->get_ctrl(cl->loopexit()->in(CountedLoopEndNode::TestValue)))) {
+    return false;   // Infinite loop
+  }
   if (cl->is_pre_loop()) {
-    // If the loop we are removing is a pre-loop then the main and
-    // post loop can be removed as well
+    // If the loop we are removing is a pre-loop then the main and post loop
+    // can be removed as well.
     remove_main_post_loops(cl, phase);
   }
 
 #ifdef ASSERT
   // Ensure only one phi which is the iv.
   Node* iv = NULL;
   for (DUIterator_Fast imax, i = cl->fast_outs(imax); i < imax; i++) {
     Node* n = cl->fast_out(i);
     if (n->Opcode() == Op_Phi) {
-      assert(iv == NULL, "Too many phis" );
+      assert(iv == NULL, "Too many phis");
       iv = n;
     }
   }
-  assert(iv == cl->phi(), "Wrong phi" );
+  assert(iv == cl->phi(), "Wrong phi");
 #endif
 
   // main and post loops have explicitly created zero trip guard
   bool needs_guard = !cl->is_main_loop() && !cl->is_post_loop();
   if (needs_guard) {
@@ -3049,35 +3128,42 @@
   Node *exact_limit = phase->exact_limit(this);
   if (exact_limit != cl->limit()) {
     // We also need to replace the original limit to collapse loop exit.
     Node* cmp = cl->loopexit()->cmp_node();
     assert(cl->limit() == cmp->in(2), "sanity");
+    // Duplicate cmp node if it has other users
+    if (cmp->outcnt() > 1) {
+      cmp = cmp->clone();
+      cmp = phase->_igvn.register_new_node_with_optimizer(cmp);
+      BoolNode *bol = cl->loopexit()->in(CountedLoopEndNode::TestValue)->as_Bool();
+      phase->_igvn.replace_input_of(bol, 1, cmp); // put bol on worklist
+    }
     phase->_igvn._worklist.push(cmp->in(2)); // put limit on worklist
     phase->_igvn.replace_input_of(cmp, 2, exact_limit); // put cmp on worklist
   }
   // Note: the final value after increment should not overflow since
   // counted loop has limit check predicate.
-  Node *final = new SubINode( exact_limit, cl->stride() );
+  Node *final = new SubINode(exact_limit, cl->stride());
   phase->register_new_node(final,cl->in(LoopNode::EntryControl));
   phase->_igvn.replace_node(phi,final);
   phase->C->set_major_progress();
   return true;
 }
 
-//------------------------------policy_do_one_iteration_loop-------------------
+//------------------------------do_one_iteration_loop--------------------------
 // Convert one iteration loop into normal code.
-bool IdealLoopTree::policy_do_one_iteration_loop( PhaseIdealLoop *phase ) {
-  if (!_head->as_Loop()->is_valid_counted_loop())
+bool IdealLoopTree::do_one_iteration_loop(PhaseIdealLoop *phase) {
+  if (!_head->as_Loop()->is_valid_counted_loop()) {
     return false; // Only for counted loop
-
+  }
   CountedLoopNode *cl = _head->as_CountedLoop();
   if (!cl->has_exact_trip_count() || cl->trip_count() != 1) {
     return false;
   }
 
 #ifndef PRODUCT
-  if(TraceLoopOpts) {
+  if (TraceLoopOpts) {
     tty->print("OneIteration ");
     this->dump_head();
   }
 #endif
 
@@ -3094,37 +3180,36 @@
   return true;
 }
 
 //=============================================================================
 //------------------------------iteration_split_impl---------------------------
-bool IdealLoopTree::iteration_split_impl( PhaseIdealLoop *phase, Node_List &old_new ) {
+bool IdealLoopTree::iteration_split_impl(PhaseIdealLoop *phase, Node_List &old_new) {
   // Compute loop trip count if possible.
   compute_trip_count(phase);
 
   // Convert one iteration loop into normal code.
-  if (policy_do_one_iteration_loop(phase))
+  if (do_one_iteration_loop(phase)) {
     return true;
-
+  }
   // Check and remove empty loops (spam micro-benchmarks)
-  if (policy_do_remove_empty_loop(phase))
+  if (do_remove_empty_loop(phase)) {
     return true;  // Here we removed an empty loop
+  }
 
-  bool should_peel = policy_peeling(phase); // Should we peel?
-
-  bool should_unswitch = policy_unswitching(phase);
+  AutoNodeBudget node_budget(phase);
 
   // Non-counted loops may be peeled; exactly 1 iteration is peeled.
   // This removes loop-invariant tests (usually null checks).
   if (!_head->is_CountedLoop()) { // Non-counted loop
     if (PartialPeelLoop && phase->partial_peel(this, old_new)) {
       // Partial peel succeeded so terminate this round of loop opts
       return false;
     }
-    if (should_peel) {            // Should we peel?
+    if (policy_peeling(phase)) {    // Should we peel?
       if (PrintOpto) { tty->print_cr("should_peel"); }
-      phase->do_peeling(this,old_new);
-    } else if (should_unswitch) {
+      phase->do_peeling(this, old_new);
+    } else if (policy_unswitching(phase)) {
       phase->do_unswitching(this, old_new);
     }
     return true;
   }
   CountedLoopNode *cl = _head->as_CountedLoop();
@@ -3138,29 +3223,24 @@
   compute_profile_trip_cnt(phase);
 
   // Before attempting fancy unrolling, RCE or alignment, see if we want
   // to completely unroll this loop or do loop unswitching.
   if (cl->is_normal_loop()) {
-    if (should_unswitch) {
+    if (policy_unswitching(phase)) {
       phase->do_unswitching(this, old_new);
       return true;
     }
-    bool should_maximally_unroll =  policy_maximally_unroll(phase);
-    if (should_maximally_unroll) {
+    if (policy_maximally_unroll(phase)) {
       // Here we did some unrolling and peeling.  Eventually we will
       // completely unroll this loop and it will no longer be a loop.
-      phase->do_maximally_unroll(this,old_new);
+      phase->do_maximally_unroll(this, old_new);
       return true;
     }
   }
 
-  // Skip next optimizations if running low on nodes. Note that
-  // policy_unswitching and policy_maximally_unroll have this check.
-  int nodes_left = phase->C->max_node_limit() - phase->C->live_nodes();
-  if ((int)(2 * _body.size()) > nodes_left) {
-    return true;
-  }
+  uint est_peeling = estimate_peeling(phase);
+  bool should_peel = 0 < est_peeling;
 
   // Counted loops may be peeled, may need some iterations run up
   // front for RCE, and may want to align loop refs to a cache
   // line.  Thus we clone a full loop up front whose trip count is
   // at least 1 (if peeling), but may be several more.
@@ -3171,33 +3251,36 @@
 
   // A post-loop will finish any odd iterations (leftover after
   // unrolling), plus any needed for RCE purposes.
 
   bool should_unroll = policy_unroll(phase);
+  bool should_rce    = policy_range_check(phase);
+  // TODO: Remove align -- not used.
+  bool should_align  = policy_align(phase);
 
-  bool should_rce = policy_range_check(phase);
-
-  bool should_align = policy_align(phase);
-
-  // If not RCE'ing (iteration splitting) or Aligning, then we do not
-  // need a pre-loop.  We may still need to peel an initial iteration but
-  // we will not be needing an unknown number of pre-iterations.
+  // If not RCE'ing  (iteration splitting) or Aligning, then we  do not need a
+  // pre-loop.  We may still need to peel an initial iteration but we will not
+  // be needing an unknown number of pre-iterations.
   //
-  // Basically, if may_rce_align reports FALSE first time through,
-  // we will not be able to later do RCE or Aligning on this loop.
+  // Basically, if may_rce_align reports FALSE first time through, we will not
+  // be able to later do RCE or Aligning on this loop.
   bool may_rce_align = !policy_peel_only(phase) || should_rce || should_align;
 
   // If we have any of these conditions (RCE, alignment, unrolling) met, then
   // we switch to the pre-/main-/post-loop model.  This model also covers
   // peeling.
   if (should_rce || should_align || should_unroll) {
-    if (cl->is_normal_loop())  // Convert to 'pre/main/post' loops
-      phase->insert_pre_post_loops(this,old_new, !may_rce_align);
-
-    // Adjust the pre- and main-loop limits to let the pre and post loops run
-    // with full checks, but the main-loop with no checks.  Remove said
-    // checks from the main body.
+    if (cl->is_normal_loop()) { // Convert to 'pre/main/post' loops
+      uint estimate = est_loop_clone_sz(3);
+      if (!phase->may_require_nodes(estimate)) {
+        return false;
+      }
+      phase->insert_pre_post_loops(this, old_new, !may_rce_align);
+    }
+    // Adjust the pre- and main-loop limits to let the pre and  post loops run
+    // with full checks, but the main-loop with no checks.  Remove said checks
+    // from the main body.
     if (should_rce) {
       if (phase->do_range_check(this, old_new) != 0) {
         cl->mark_has_range_checks();
       }
     } else if (PostLoopMultiversioning) {
@@ -3221,63 +3304,63 @@
         phase->insert_vector_post_loop(this, old_new);
       }
       phase->do_unroll(this, old_new, true);
     }
 
-    // Adjust the pre-loop limits to align the main body
-    // iterations.
-    if (should_align)
+    // Adjust the pre-loop limits to align the main body iterations.
+    if (should_align) {
       Unimplemented();
-
+    }
   } else {                      // Else we have an unchanged counted loop
-    if (should_peel)           // Might want to peel but do nothing else
-      phase->do_peeling(this,old_new);
+    if (should_peel) {          // Might want to peel but do nothing else
+      if (phase->may_require_nodes(est_peeling)) {
+        phase->do_peeling(this, old_new);
+      }
+    }
   }
   return true;
 }
 
 
 //=============================================================================
 //------------------------------iteration_split--------------------------------
-bool IdealLoopTree::iteration_split( PhaseIdealLoop *phase, Node_List &old_new ) {
+bool IdealLoopTree::iteration_split(PhaseIdealLoop* phase, Node_List &old_new) {
   // Recursively iteration split nested loops
-  if (_child && !_child->iteration_split(phase, old_new))
+  if (_child && !_child->iteration_split(phase, old_new)) {
     return false;
+  }
 
   // Clean out prior deadwood
   DCE_loop_body();
 
-
   // Look for loop-exit tests with my 50/50 guesses from the Parsing stage.
   // Replace with a 1-in-10 exit guess.
-  if (_parent /*not the root loop*/ &&
-      !_irreducible &&
-      // Also ignore the occasional dead backedge
-      !tail()->is_top()) {
+  if (!is_root() && is_loop()) {
     adjust_loop_exit_prob(phase);
   }
 
-  // Gate unrolling, RCE and peeling efforts.
-  if (!_child &&                // If not an inner loop, do not split
-      !_irreducible &&
-      _allow_optimizations &&
-      !tail()->is_top()) {     // Also ignore the occasional dead backedge
+  // Unrolling, RCE and peeling efforts, iff innermost loop.
+  if (_allow_optimizations && is_innermost()) {
     if (!_has_call) {
-        if (!iteration_split_impl(phase, old_new)) {
-          return false;
-        }
-    } else if (policy_unswitching(phase)) {
-      phase->do_unswitching(this, old_new);
+      if (!iteration_split_impl(phase, old_new)) {
+        return false;
+      }
+    } else {
+      AutoNodeBudget node_budget(phase);
+      if (policy_unswitching(phase)) {
+        phase->do_unswitching(this, old_new);
+      }
     }
   }
 
   // Minor offset re-organization to remove loop-fallout uses of
   // trip counter when there was no major reshaping.
   phase->reorg_offsets(this);
 
-  if (_next && !_next->iteration_split(phase, old_new))
+  if (_next && !_next->iteration_split(phase, old_new)) {
     return false;
+  }
   return true;
 }
 
 
 //=============================================================================
@@ -3535,11 +3618,11 @@
 
 
 
 bool PhaseIdealLoop::intrinsify_fill(IdealLoopTree* lpt) {
   // Only for counted inner loops
-  if (!lpt->is_counted() || !lpt->is_inner()) {
+  if (!lpt->is_counted() || !lpt->is_innermost()) {
     return false;
   }
 
   // Must have constant stride
   CountedLoopNode* head = lpt->_head->as_CountedLoop();
