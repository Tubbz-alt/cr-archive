<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/doCall.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="divnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="escape.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/doCall.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 1998, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
 133       // We will retry the intrinsic if nothing had claimed it afterwards.
 134       if (cg-&gt;does_virtual_dispatch()) {
 135         cg_intrinsic = cg;
 136         cg = NULL;
 137       } else {
 138         return cg;
 139       }
 140     }
 141   }
 142 
 143   // Do method handle calls.
 144   // NOTE: This must happen before normal inlining logic below since
 145   // MethodHandle.invoke* are native methods which obviously don&#39;t
 146   // have bytecodes and so normal inlining fails.
 147   if (callee-&gt;is_method_handle_intrinsic()) {
 148     CallGenerator* cg = CallGenerator::for_method_handle_call(jvms, caller, callee, delayed_forbidden);
 149     assert(cg == NULL || !delayed_forbidden || !cg-&gt;is_late_inline() || cg-&gt;is_mh_late_inline(), &quot;unexpected CallGenerator&quot;);
 150     return cg;
 151   }
 152 
<span class="line-modified"> 153   // Do not inline strict fp into non-strict code, or the reverse</span>
<span class="line-modified"> 154   if (caller-&gt;is_strict() ^ callee-&gt;is_strict()) {</span>

 155     allow_inline = false;
 156   }
 157 
 158   // Attempt to inline...
 159   if (allow_inline) {
 160     // The profile data is only partly attributable to this caller,
 161     // scale back the call site information.
 162     float past_uses = jvms-&gt;method()-&gt;scale_count(site_count, prof_factor);
 163     // This is the number of times we expect the call code to be used.
 164     float expected_uses = past_uses;
 165 
 166     // Try inlining a bytecoded method:
 167     if (!call_does_dispatch) {
 168       InlineTree* ilt = InlineTree::find_subtree_from_root(this-&gt;ilt(), jvms-&gt;caller(), jvms-&gt;method());
 169       WarmCallInfo scratch_ci;
 170       bool should_delay = false;
 171       WarmCallInfo* ci = ilt-&gt;ok_to_inline(callee, jvms, profile, &amp;scratch_ci, should_delay);
 172       assert(ci != &amp;scratch_ci, &quot;do not let this pointer escape&quot;);
 173       bool allow_inline   = (ci != NULL &amp;&amp; !ci-&gt;is_cold());
 174       bool require_inline = (allow_inline &amp;&amp; ci-&gt;is_hot());
</pre>
<hr />
<pre>
 293       }
 294     }
 295 
 296     // If there is only one implementor of this interface then we
 297     // may be able to bind this invoke directly to the implementing
 298     // klass but we need both a dependence on the single interface
 299     // and on the method we bind to. Additionally since all we know
 300     // about the receiver type is that it&#39;s supposed to implement the
 301     // interface we have to insert a check that it&#39;s the class we
 302     // expect.  Interface types are not checked by the verifier so
 303     // they are roughly equivalent to Object.
 304     // The number of implementors for declared_interface is less or
 305     // equal to the number of implementors for target-&gt;holder() so
 306     // if number of implementors of target-&gt;holder() == 1 then
 307     // number of implementors for decl_interface is 0 or 1. If
 308     // it&#39;s 0 then no class implements decl_interface and there&#39;s
 309     // no point in inlining.
 310     if (call_does_dispatch &amp;&amp; bytecode == Bytecodes::_invokeinterface) {
 311       ciInstanceKlass* declared_interface =
 312           caller-&gt;get_declared_method_holder_at_bci(bci)-&gt;as_instance_klass();

 313 
<span class="line-modified"> 314       if (declared_interface-&gt;nof_implementors() == 1 &amp;&amp;</span>
 315           (!callee-&gt;is_default_method() || callee-&gt;is_overpass()) /* CHA doesn&#39;t support default methods yet */) {
<span class="line-modified"> 316         ciInstanceKlass* singleton = declared_interface-&gt;implementor();</span>

 317         ciMethod* cha_monomorphic_target =
 318             callee-&gt;find_monomorphic_target(caller-&gt;holder(), declared_interface, singleton);
 319 
 320         if (cha_monomorphic_target != NULL &amp;&amp;
 321             cha_monomorphic_target-&gt;holder() != env()-&gt;Object_klass()) { // subtype check against Object is useless
 322           ciKlass* holder = cha_monomorphic_target-&gt;holder();
 323 
 324           // Try to inline the method found by CHA. Inlined method is guarded by the type check.
 325           CallGenerator* hit_cg = call_generator(cha_monomorphic_target,
 326               vtable_index, !call_does_dispatch, jvms, allow_inline, prof_factor);
 327 
 328           // Deoptimize on type check fail. The interpreter will throw ICCE for us.
 329           CallGenerator* miss_cg = CallGenerator::for_uncommon_trap(callee,
 330               Deoptimization::Reason_class_check, Deoptimization::Action_none);
 331 
 332           CallGenerator* cg = CallGenerator::for_guarded_call(holder, miss_cg, hit_cg);
 333           if (hit_cg != NULL &amp;&amp; cg != NULL) {
 334             dependencies()-&gt;assert_unique_concrete_method(declared_interface, cha_monomorphic_target);
 335             return cg;
 336           }
</pre>
<hr />
<pre>
 683 
 684     // Round double result after a call from strict to non-strict code
 685     round_double_result(cg-&gt;method());
 686 
 687     ciType* rtype = cg-&gt;method()-&gt;return_type();
 688     ciType* ctype = declared_signature-&gt;return_type();
 689 
 690     if (Bytecodes::has_optional_appendix(iter().cur_bc_raw()) || is_signature_polymorphic) {
 691       // Be careful here with return types.
 692       if (ctype != rtype) {
 693         BasicType rt = rtype-&gt;basic_type();
 694         BasicType ct = ctype-&gt;basic_type();
 695         if (ct == T_VOID) {
 696           // It&#39;s OK for a method  to return a value that is discarded.
 697           // The discarding does not require any special action from the caller.
 698           // The Java code knows this, at VerifyType.isNullConversion.
 699           pop_node(rt);  // whatever it was, pop it
 700         } else if (rt == T_INT || is_subword_type(rt)) {
 701           // Nothing.  These cases are handled in lambda form bytecode.
 702           assert(ct == T_INT || is_subword_type(ct), &quot;must match: rt=%s, ct=%s&quot;, type2name(rt), type2name(ct));
<span class="line-modified"> 703         } else if (rt == T_OBJECT || rt == T_ARRAY) {</span>
<span class="line-modified"> 704           assert(ct == T_OBJECT || ct == T_ARRAY, &quot;rt=%s, ct=%s&quot;, type2name(rt), type2name(ct));</span>
 705           if (ctype-&gt;is_loaded()) {
 706             const TypeOopPtr* arg_type = TypeOopPtr::make_from_klass(rtype-&gt;as_klass());
 707             const Type*       sig_type = TypeOopPtr::make_from_klass(ctype-&gt;as_klass());
 708             if (arg_type != NULL &amp;&amp; !arg_type-&gt;higher_equal(sig_type)) {
 709               Node* retnode = pop();
 710               Node* cast_obj = _gvn.transform(new CheckCastPPNode(control(), retnode, sig_type));
 711               push(cast_obj);
 712             }
 713           }
 714         } else {
 715           assert(rt == ct, &quot;unexpected mismatch: rt=%s, ct=%s&quot;, type2name(rt), type2name(ct));
 716           // push a zero; it&#39;s better than getting an oop/int mismatch
 717           pop_node(rt);
 718           Node* retnode = zerocon(ct);
 719           push_node(ct, retnode);
 720         }
 721         // Now that the value is well-behaved, continue with the call-site type.
 722         rtype = ctype;
 723       }
 724     } else {
</pre>
<hr />
<pre>
 731              &quot;mismatched return types: rtype=%s, ctype=%s&quot;, rtype-&gt;name(), ctype-&gt;name());
 732     }
 733 
 734     // If the return type of the method is not loaded, assert that the
 735     // value we got is a null.  Otherwise, we need to recompile.
 736     if (!rtype-&gt;is_loaded()) {
 737       if (PrintOpto &amp;&amp; (Verbose || WizardMode)) {
 738         method()-&gt;print_name(); tty-&gt;print_cr(&quot; asserting nullness of result at bci: %d&quot;, bci());
 739         cg-&gt;method()-&gt;print_name(); tty-&gt;cr();
 740       }
 741       if (C-&gt;log() != NULL) {
 742         C-&gt;log()-&gt;elem(&quot;assert_null reason=&#39;return&#39; klass=&#39;%d&#39;&quot;,
 743                        C-&gt;log()-&gt;identify(rtype));
 744       }
 745       // If there is going to be a trap, put it at the next bytecode:
 746       set_bci(iter().next_bci());
 747       null_assert(peek());
 748       set_bci(iter().cur_bci()); // put it back
 749     }
 750     BasicType ct = ctype-&gt;basic_type();
<span class="line-modified"> 751     if (ct == T_OBJECT || ct == T_ARRAY) {</span>
 752       record_profiled_return_for_speculation();
 753     }
 754   }
 755 
 756   // Restart record of parsing work after possible inlining of call
 757 #ifndef PRODUCT
 758   parse_histogram()-&gt;set_initial_state(bc());
 759 #endif
 760 }
 761 
 762 //---------------------------catch_call_exceptions-----------------------------
 763 // Put a Catch and CatchProj nodes behind a just-created call.
 764 // Send their caught exceptions to the proper handler.
 765 // This may be used after a call to the rethrow VM stub,
 766 // when it is needed to process unloaded exception classes.
 767 void Parse::catch_call_exceptions(ciExceptionHandlerStream&amp; handlers) {
 768   // Exceptions are delivered through this channel:
 769   Node* i_o = this-&gt;i_o();
 770 
 771   // Add a CatchNode.
</pre>
<hr />
<pre>
1135     if (receiver_type == NULL || !receiver_type-&gt;higher_equal(mr_type)) {
1136       // Calling this method would include an implicit cast to its holder.
1137       // %%% Not yet implemented.  Would throw minor asserts at present.
1138       // %%% The most common wins are already gained by +UseUniqueSubclasses.
1139       // To fix, put the higher_equal check at the call of this routine,
1140       // and add a CheckCastPP to the receiver.
1141       if (TraceDependencies) {
1142         tty-&gt;print_cr(&quot;found unique CHA method, but could not cast up&quot;);
1143         tty-&gt;print(&quot;  method  = &quot;);
1144         cha_monomorphic_target-&gt;print();
1145         tty-&gt;cr();
1146       }
1147       if (log() != NULL) {
1148         log()-&gt;elem(&quot;missed_CHA_opportunity klass=&#39;%d&#39; method=&#39;%d&#39;&quot;,
1149                        log()-&gt;identify(klass),
1150                        log()-&gt;identify(cha_monomorphic_target));
1151       }
1152       cha_monomorphic_target = NULL;
1153     }
1154   }

1155   if (cha_monomorphic_target != NULL) {
1156     // Hardwiring a virtual.
<span class="line-modified">1157     // If we inlined because CHA revealed only a single target method,</span>
<span class="line-modified">1158     // then we are dependent on that target method not getting overridden</span>
<span class="line-modified">1159     // by dynamic class loading.  Be sure to test the &quot;static&quot; receiver</span>
<span class="line-modified">1160     // dest_method here, as opposed to the actual receiver, which may</span>
<span class="line-modified">1161     // falsely lead us to believe that the receiver is final or private.</span>
<span class="line-modified">1162     dependencies()-&gt;assert_unique_concrete_method(actual_receiver, cha_monomorphic_target);</span>




1163     return cha_monomorphic_target;
1164   }
1165 
1166   // If the type is exact, we can still bind the method w/o a vcall.
1167   // (This case comes after CHA so we can see how much extra work it does.)
1168   if (actual_receiver_is_exact) {
1169     // In case of evolution, there is a dependence on every inlined method, since each
1170     // such method can be changed when its class is redefined.
1171     ciMethod* exact_method = callee-&gt;resolve_invoke(calling_klass, actual_receiver);
1172     if (exact_method != NULL) {
1173       if (PrintOpto) {
1174         tty-&gt;print(&quot;  Calling method via exact type @%d --- &quot;, bci);
1175         exact_method-&gt;print_name();
1176         tty-&gt;cr();
1177       }
1178       return exact_method;
1179     }
1180   }
1181 
1182   return NULL;
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
 133       // We will retry the intrinsic if nothing had claimed it afterwards.
 134       if (cg-&gt;does_virtual_dispatch()) {
 135         cg_intrinsic = cg;
 136         cg = NULL;
 137       } else {
 138         return cg;
 139       }
 140     }
 141   }
 142 
 143   // Do method handle calls.
 144   // NOTE: This must happen before normal inlining logic below since
 145   // MethodHandle.invoke* are native methods which obviously don&#39;t
 146   // have bytecodes and so normal inlining fails.
 147   if (callee-&gt;is_method_handle_intrinsic()) {
 148     CallGenerator* cg = CallGenerator::for_method_handle_call(jvms, caller, callee, delayed_forbidden);
 149     assert(cg == NULL || !delayed_forbidden || !cg-&gt;is_late_inline() || cg-&gt;is_mh_late_inline(), &quot;unexpected CallGenerator&quot;);
 150     return cg;
 151   }
 152 
<span class="line-modified"> 153   // If explicit rounding is required, do not inline strict into non-strict code (or the reverse).</span>
<span class="line-modified"> 154   if (Matcher::strict_fp_requires_explicit_rounding &amp;&amp;</span>
<span class="line-added"> 155       caller-&gt;is_strict() != callee-&gt;is_strict()) {</span>
 156     allow_inline = false;
 157   }
 158 
 159   // Attempt to inline...
 160   if (allow_inline) {
 161     // The profile data is only partly attributable to this caller,
 162     // scale back the call site information.
 163     float past_uses = jvms-&gt;method()-&gt;scale_count(site_count, prof_factor);
 164     // This is the number of times we expect the call code to be used.
 165     float expected_uses = past_uses;
 166 
 167     // Try inlining a bytecoded method:
 168     if (!call_does_dispatch) {
 169       InlineTree* ilt = InlineTree::find_subtree_from_root(this-&gt;ilt(), jvms-&gt;caller(), jvms-&gt;method());
 170       WarmCallInfo scratch_ci;
 171       bool should_delay = false;
 172       WarmCallInfo* ci = ilt-&gt;ok_to_inline(callee, jvms, profile, &amp;scratch_ci, should_delay);
 173       assert(ci != &amp;scratch_ci, &quot;do not let this pointer escape&quot;);
 174       bool allow_inline   = (ci != NULL &amp;&amp; !ci-&gt;is_cold());
 175       bool require_inline = (allow_inline &amp;&amp; ci-&gt;is_hot());
</pre>
<hr />
<pre>
 294       }
 295     }
 296 
 297     // If there is only one implementor of this interface then we
 298     // may be able to bind this invoke directly to the implementing
 299     // klass but we need both a dependence on the single interface
 300     // and on the method we bind to. Additionally since all we know
 301     // about the receiver type is that it&#39;s supposed to implement the
 302     // interface we have to insert a check that it&#39;s the class we
 303     // expect.  Interface types are not checked by the verifier so
 304     // they are roughly equivalent to Object.
 305     // The number of implementors for declared_interface is less or
 306     // equal to the number of implementors for target-&gt;holder() so
 307     // if number of implementors of target-&gt;holder() == 1 then
 308     // number of implementors for decl_interface is 0 or 1. If
 309     // it&#39;s 0 then no class implements decl_interface and there&#39;s
 310     // no point in inlining.
 311     if (call_does_dispatch &amp;&amp; bytecode == Bytecodes::_invokeinterface) {
 312       ciInstanceKlass* declared_interface =
 313           caller-&gt;get_declared_method_holder_at_bci(bci)-&gt;as_instance_klass();
<span class="line-added"> 314       ciInstanceKlass* singleton = declared_interface-&gt;unique_implementor();</span>
 315 
<span class="line-modified"> 316       if (singleton != NULL &amp;&amp;</span>
 317           (!callee-&gt;is_default_method() || callee-&gt;is_overpass()) /* CHA doesn&#39;t support default methods yet */) {
<span class="line-modified"> 318         assert(singleton != declared_interface, &quot;not a unique implementor&quot;);</span>
<span class="line-added"> 319 </span>
 320         ciMethod* cha_monomorphic_target =
 321             callee-&gt;find_monomorphic_target(caller-&gt;holder(), declared_interface, singleton);
 322 
 323         if (cha_monomorphic_target != NULL &amp;&amp;
 324             cha_monomorphic_target-&gt;holder() != env()-&gt;Object_klass()) { // subtype check against Object is useless
 325           ciKlass* holder = cha_monomorphic_target-&gt;holder();
 326 
 327           // Try to inline the method found by CHA. Inlined method is guarded by the type check.
 328           CallGenerator* hit_cg = call_generator(cha_monomorphic_target,
 329               vtable_index, !call_does_dispatch, jvms, allow_inline, prof_factor);
 330 
 331           // Deoptimize on type check fail. The interpreter will throw ICCE for us.
 332           CallGenerator* miss_cg = CallGenerator::for_uncommon_trap(callee,
 333               Deoptimization::Reason_class_check, Deoptimization::Action_none);
 334 
 335           CallGenerator* cg = CallGenerator::for_guarded_call(holder, miss_cg, hit_cg);
 336           if (hit_cg != NULL &amp;&amp; cg != NULL) {
 337             dependencies()-&gt;assert_unique_concrete_method(declared_interface, cha_monomorphic_target);
 338             return cg;
 339           }
</pre>
<hr />
<pre>
 686 
 687     // Round double result after a call from strict to non-strict code
 688     round_double_result(cg-&gt;method());
 689 
 690     ciType* rtype = cg-&gt;method()-&gt;return_type();
 691     ciType* ctype = declared_signature-&gt;return_type();
 692 
 693     if (Bytecodes::has_optional_appendix(iter().cur_bc_raw()) || is_signature_polymorphic) {
 694       // Be careful here with return types.
 695       if (ctype != rtype) {
 696         BasicType rt = rtype-&gt;basic_type();
 697         BasicType ct = ctype-&gt;basic_type();
 698         if (ct == T_VOID) {
 699           // It&#39;s OK for a method  to return a value that is discarded.
 700           // The discarding does not require any special action from the caller.
 701           // The Java code knows this, at VerifyType.isNullConversion.
 702           pop_node(rt);  // whatever it was, pop it
 703         } else if (rt == T_INT || is_subword_type(rt)) {
 704           // Nothing.  These cases are handled in lambda form bytecode.
 705           assert(ct == T_INT || is_subword_type(ct), &quot;must match: rt=%s, ct=%s&quot;, type2name(rt), type2name(ct));
<span class="line-modified"> 706         } else if (is_reference_type(rt)) {</span>
<span class="line-modified"> 707           assert(is_reference_type(ct), &quot;rt=%s, ct=%s&quot;, type2name(rt), type2name(ct));</span>
 708           if (ctype-&gt;is_loaded()) {
 709             const TypeOopPtr* arg_type = TypeOopPtr::make_from_klass(rtype-&gt;as_klass());
 710             const Type*       sig_type = TypeOopPtr::make_from_klass(ctype-&gt;as_klass());
 711             if (arg_type != NULL &amp;&amp; !arg_type-&gt;higher_equal(sig_type)) {
 712               Node* retnode = pop();
 713               Node* cast_obj = _gvn.transform(new CheckCastPPNode(control(), retnode, sig_type));
 714               push(cast_obj);
 715             }
 716           }
 717         } else {
 718           assert(rt == ct, &quot;unexpected mismatch: rt=%s, ct=%s&quot;, type2name(rt), type2name(ct));
 719           // push a zero; it&#39;s better than getting an oop/int mismatch
 720           pop_node(rt);
 721           Node* retnode = zerocon(ct);
 722           push_node(ct, retnode);
 723         }
 724         // Now that the value is well-behaved, continue with the call-site type.
 725         rtype = ctype;
 726       }
 727     } else {
</pre>
<hr />
<pre>
 734              &quot;mismatched return types: rtype=%s, ctype=%s&quot;, rtype-&gt;name(), ctype-&gt;name());
 735     }
 736 
 737     // If the return type of the method is not loaded, assert that the
 738     // value we got is a null.  Otherwise, we need to recompile.
 739     if (!rtype-&gt;is_loaded()) {
 740       if (PrintOpto &amp;&amp; (Verbose || WizardMode)) {
 741         method()-&gt;print_name(); tty-&gt;print_cr(&quot; asserting nullness of result at bci: %d&quot;, bci());
 742         cg-&gt;method()-&gt;print_name(); tty-&gt;cr();
 743       }
 744       if (C-&gt;log() != NULL) {
 745         C-&gt;log()-&gt;elem(&quot;assert_null reason=&#39;return&#39; klass=&#39;%d&#39;&quot;,
 746                        C-&gt;log()-&gt;identify(rtype));
 747       }
 748       // If there is going to be a trap, put it at the next bytecode:
 749       set_bci(iter().next_bci());
 750       null_assert(peek());
 751       set_bci(iter().cur_bci()); // put it back
 752     }
 753     BasicType ct = ctype-&gt;basic_type();
<span class="line-modified"> 754     if (is_reference_type(ct)) {</span>
 755       record_profiled_return_for_speculation();
 756     }
 757   }
 758 
 759   // Restart record of parsing work after possible inlining of call
 760 #ifndef PRODUCT
 761   parse_histogram()-&gt;set_initial_state(bc());
 762 #endif
 763 }
 764 
 765 //---------------------------catch_call_exceptions-----------------------------
 766 // Put a Catch and CatchProj nodes behind a just-created call.
 767 // Send their caught exceptions to the proper handler.
 768 // This may be used after a call to the rethrow VM stub,
 769 // when it is needed to process unloaded exception classes.
 770 void Parse::catch_call_exceptions(ciExceptionHandlerStream&amp; handlers) {
 771   // Exceptions are delivered through this channel:
 772   Node* i_o = this-&gt;i_o();
 773 
 774   // Add a CatchNode.
</pre>
<hr />
<pre>
1138     if (receiver_type == NULL || !receiver_type-&gt;higher_equal(mr_type)) {
1139       // Calling this method would include an implicit cast to its holder.
1140       // %%% Not yet implemented.  Would throw minor asserts at present.
1141       // %%% The most common wins are already gained by +UseUniqueSubclasses.
1142       // To fix, put the higher_equal check at the call of this routine,
1143       // and add a CheckCastPP to the receiver.
1144       if (TraceDependencies) {
1145         tty-&gt;print_cr(&quot;found unique CHA method, but could not cast up&quot;);
1146         tty-&gt;print(&quot;  method  = &quot;);
1147         cha_monomorphic_target-&gt;print();
1148         tty-&gt;cr();
1149       }
1150       if (log() != NULL) {
1151         log()-&gt;elem(&quot;missed_CHA_opportunity klass=&#39;%d&#39; method=&#39;%d&#39;&quot;,
1152                        log()-&gt;identify(klass),
1153                        log()-&gt;identify(cha_monomorphic_target));
1154       }
1155       cha_monomorphic_target = NULL;
1156     }
1157   }
<span class="line-added">1158 </span>
1159   if (cha_monomorphic_target != NULL) {
1160     // Hardwiring a virtual.
<span class="line-modified">1161     assert(!callee-&gt;can_be_statically_bound(), &quot;should have been handled earlier&quot;);</span>
<span class="line-modified">1162     assert(!cha_monomorphic_target-&gt;is_abstract(), &quot;&quot;);</span>
<span class="line-modified">1163     if (!cha_monomorphic_target-&gt;can_be_statically_bound(actual_receiver)) {</span>
<span class="line-modified">1164       // If we inlined because CHA revealed only a single target method,</span>
<span class="line-modified">1165       // then we are dependent on that target method not getting overridden</span>
<span class="line-modified">1166       // by dynamic class loading.  Be sure to test the &quot;static&quot; receiver</span>
<span class="line-added">1167       // dest_method here, as opposed to the actual receiver, which may</span>
<span class="line-added">1168       // falsely lead us to believe that the receiver is final or private.</span>
<span class="line-added">1169       dependencies()-&gt;assert_unique_concrete_method(actual_receiver, cha_monomorphic_target);</span>
<span class="line-added">1170     }</span>
1171     return cha_monomorphic_target;
1172   }
1173 
1174   // If the type is exact, we can still bind the method w/o a vcall.
1175   // (This case comes after CHA so we can see how much extra work it does.)
1176   if (actual_receiver_is_exact) {
1177     // In case of evolution, there is a dependence on every inlined method, since each
1178     // such method can be changed when its class is redefined.
1179     ciMethod* exact_method = callee-&gt;resolve_invoke(calling_klass, actual_receiver);
1180     if (exact_method != NULL) {
1181       if (PrintOpto) {
1182         tty-&gt;print(&quot;  Calling method via exact type @%d --- &quot;, bci);
1183         exact_method-&gt;print_name();
1184         tty-&gt;cr();
1185       }
1186       return exact_method;
1187     }
1188   }
1189 
1190   return NULL;
</pre>
</td>
</tr>
</table>
<center><a href="divnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="escape.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>