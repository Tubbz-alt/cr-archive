<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/escape.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="doCall.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="escape.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/escape.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2005, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
 333     } else {
 334       assert((ptnode_adr(adr-&gt;_idx) == NULL ||
 335               ptnode_adr(adr-&gt;_idx)-&gt;as_Field()-&gt;is_oop()), &quot;sanity&quot;);
 336     }
 337 #endif
 338     add_local_var_and_edge(n, PointsToNode::NoEscape,
 339                            adr, delayed_worklist);
 340   }
 341 }
 342 
 343 // Populate Connection Graph with PointsTo nodes and create simple
 344 // connection graph edges.
 345 void ConnectionGraph::add_node_to_connection_graph(Node *n, Unique_Node_List *delayed_worklist) {
 346   assert(!_verify, &quot;this method should not be called for verification&quot;);
 347   PhaseGVN* igvn = _igvn;
 348   uint n_idx = n-&gt;_idx;
 349   PointsToNode* n_ptn = ptnode_adr(n_idx);
 350   if (n_ptn != NULL)
 351     return; // No need to redefine PointsTo node during first iteration.
 352 






 353   if (n-&gt;is_Call()) {
 354     // Arguments to allocation and locking don&#39;t escape.
 355     if (n-&gt;is_AbstractLock()) {
 356       // Put Lock and Unlock nodes on IGVN worklist to process them during
 357       // first IGVN optimization when escape information is still available.
 358       record_for_optimizer(n);
 359     } else if (n-&gt;is_Allocate()) {
 360       add_call_node(n-&gt;as_Call());
 361       record_for_optimizer(n);
 362     } else {
 363       if (n-&gt;is_CallStaticJava()) {
 364         const char* name = n-&gt;as_CallStaticJava()-&gt;_name;
 365         if (name != NULL &amp;&amp; strcmp(name, &quot;uncommon_trap&quot;) == 0)
 366           return; // Skip uncommon traps
 367       }
 368       // Don&#39;t mark as processed since call&#39;s arguments have to be processed.
 369       delayed_worklist-&gt;push(n);
 370       // Check if a call returns an object.
 371       if ((n-&gt;as_Call()-&gt;returns_pointer() &amp;&amp;
 372            n-&gt;as_Call()-&gt;proj_out_or_null(TypeFunc::Parms) != NULL) ||
 373           (n-&gt;is_CallStaticJava() &amp;&amp;
 374            n-&gt;as_CallStaticJava()-&gt;is_boxing_method())) {
 375         add_call_node(n-&gt;as_Call());
 376       }
 377     }
 378     return;
 379   }
 380   // Put this check here to process call arguments since some call nodes
 381   // point to phantom_obj.
 382   if (n_ptn == phantom_obj || n_ptn == null_obj)
 383     return; // Skip predefined nodes.
 384 
<span class="line-removed"> 385   int opcode = n-&gt;Opcode();</span>
<span class="line-removed"> 386   bool gc_handled = BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;escape_add_to_con_graph(this, igvn, delayed_worklist, n, opcode);</span>
<span class="line-removed"> 387   if (gc_handled) {</span>
<span class="line-removed"> 388     return; // Ignore node if already handled by GC.</span>
<span class="line-removed"> 389   }</span>
 390   switch (opcode) {
 391     case Op_AddP: {
 392       Node* base = get_addp_base(n);
 393       PointsToNode* ptn_base = ptnode_adr(base-&gt;_idx);
 394       // Field nodes are created for all field types. They are used in
 395       // adjust_scalar_replaceable_state() and split_unique_types().
 396       // Note, non-oop fields will have only base edges in Connection
 397       // Graph because such fields are not used for oop loads and stores.
 398       int offset = address_offset(n, igvn);
 399       add_field(n, PointsToNode::NoEscape, offset);
 400       if (ptn_base == NULL) {
 401         delayed_worklist-&gt;push(n); // Process it later.
 402       } else {
 403         n_ptn = ptnode_adr(n_idx);
 404         add_base(n_ptn-&gt;as_Field(), ptn_base);
 405       }
 406       break;
 407     }
 408     case Op_CastX2P: {
 409       map_ideal_node(n, phantom_obj);
</pre>
<hr />
<pre>
 972           // src or dst could be j.l.Object when other is basic type array:
 973           //
 974           //   arraycopy(char[],0,Object*,0,size);
 975           //   arraycopy(Object*,0,char[],0,size);
 976           //
 977           // Don&#39;t add edges in such cases.
 978           //
 979           bool arg_is_arraycopy_dest = src_has_oops &amp;&amp; is_arraycopy &amp;&amp;
 980                                        arg_has_oops &amp;&amp; (i &gt; TypeFunc::Parms);
 981 #ifdef ASSERT
 982           if (!(is_arraycopy ||
 983                 BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(call) ||
 984                 (call-&gt;as_CallLeaf()-&gt;_name != NULL &amp;&amp;
 985                  (strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;updateBytesCRC32&quot;) == 0 ||
 986                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;updateBytesCRC32C&quot;) == 0 ||
 987                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;updateBytesAdler32&quot;) == 0 ||
 988                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;aescrypt_encryptBlock&quot;) == 0 ||
 989                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;aescrypt_decryptBlock&quot;) == 0 ||
 990                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;cipherBlockChaining_encryptAESCrypt&quot;) == 0 ||
 991                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;cipherBlockChaining_decryptAESCrypt&quot;) == 0 ||


 992                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;counterMode_AESCrypt&quot;) == 0 ||
 993                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;ghash_processBlocks&quot;) == 0 ||
 994                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;encodeBlock&quot;) == 0 ||
 995                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha1_implCompress&quot;) == 0 ||
 996                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha1_implCompressMB&quot;) == 0 ||
 997                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha256_implCompress&quot;) == 0 ||
 998                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha256_implCompressMB&quot;) == 0 ||
 999                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha512_implCompress&quot;) == 0 ||
1000                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha512_implCompressMB&quot;) == 0 ||
1001                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;multiplyToLen&quot;) == 0 ||
1002                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;squareToLen&quot;) == 0 ||
1003                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;mulAdd&quot;) == 0 ||
1004                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;montgomery_multiply&quot;) == 0 ||
1005                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;montgomery_square&quot;) == 0 ||


1006                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;vectorizedMismatch&quot;) == 0)
1007                  ))) {
1008             call-&gt;dump();
1009             fatal(&quot;EA unexpected CallLeaf %s&quot;, call-&gt;as_CallLeaf()-&gt;_name);
1010           }
1011 #endif
1012           // Always process arraycopy&#39;s destination object since
1013           // we need to add all possible edges to references in
1014           // source object.
1015           if (arg_esc &gt;= PointsToNode::ArgEscape &amp;&amp;
1016               !arg_is_arraycopy_dest) {
1017             continue;
1018           }
1019           PointsToNode::EscapeState es = PointsToNode::ArgEscape;
1020           if (call-&gt;is_ArrayCopy()) {
1021             ArrayCopyNode* ac = call-&gt;as_ArrayCopy();
1022             if (ac-&gt;is_clonebasic() ||
1023                 ac-&gt;is_arraycopy_validated() ||
1024                 ac-&gt;is_copyof_validated() ||
1025                 ac-&gt;is_copyofrange_validated()) {
</pre>
<hr />
<pre>
1394           PointsToNode* e = i.get();
1395           if (e-&gt;is_Arraycopy()) {
1396             if (jobj == null_obj) // NULL object does not have field edges
1397               continue;
1398             // Add edge from arraycopy&#39;s destination java object to Arraycopy node.
1399             if (add_edge(jobj, e)) {
1400               new_edges++;
1401               jobj-&gt;set_arraycopy_dst();
1402             }
1403           }
1404         }
1405       }
1406     } else {
1407       // Added new edge to stored in field values.
1408       // Put on worklist all field&#39;s uses (loads) and
1409       // related field nodes (same base and offset).
1410       add_field_uses_to_worklist(use-&gt;as_Field());
1411     }
1412   }
1413   _worklist.clear();
<span class="line-modified">1414   _in_worklist.Reset();</span>
1415   return new_edges;
1416 }
1417 
1418 // Put on worklist all related field nodes.
1419 void ConnectionGraph::add_field_uses_to_worklist(FieldNode* field) {
1420   assert(field-&gt;is_oop(), &quot;sanity&quot;);
1421   int offset = field-&gt;offset();
1422   add_uses_to_worklist(field);
1423   // Loop over all bases of this field and push on worklist Field nodes
1424   // with the same offset and base (since they may reference the same field).
1425   for (BaseIterator i(field); i.has_next(); i.next()) {
1426     PointsToNode* base = i.get();
1427     add_fields_to_worklist(field, base);
1428     // Check if the base was source object of arraycopy and go over arraycopy&#39;s
1429     // destination objects since values stored to a field of source object are
1430     // accessable by uses (loads) of fields of destination objects.
1431     if (base-&gt;arraycopy_src()) {
1432       for (UseIterator j(base); j.has_next(); j.next()) {
1433         PointsToNode* arycp = j.get();
1434         if (arycp-&gt;is_Arraycopy()) {
</pre>
<hr />
<pre>
2093       }
2094     } else if (adr_type-&gt;isa_aryptr()) {
2095       if (offset == arrayOopDesc::length_offset_in_bytes()) {
2096         // Ignore array length load.
2097       } else if (find_second_addp(n, n-&gt;in(AddPNode::Base)) != NULL) {
2098         // Ignore first AddP.
2099       } else {
2100         const Type* elemtype = adr_type-&gt;isa_aryptr()-&gt;elem();
2101         bt = elemtype-&gt;array_element_basic_type();
2102       }
2103     } else if (adr_type-&gt;isa_rawptr() || adr_type-&gt;isa_klassptr()) {
2104       // Allocation initialization, ThreadLocal field access, unsafe access
2105       if (n-&gt;has_out_with(Op_StoreP, Op_LoadP, Op_StoreN, Op_LoadN) ||
2106           n-&gt;has_out_with(Op_GetAndSetP, Op_GetAndSetN, Op_CompareAndExchangeP, Op_CompareAndExchangeN) ||
2107           n-&gt;has_out_with(Op_CompareAndSwapP, Op_CompareAndSwapN, Op_WeakCompareAndSwapP, Op_WeakCompareAndSwapN) ||
2108           BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;escape_has_out_with_unsafe_object(n)) {
2109         bt = T_OBJECT;
2110       }
2111     }
2112   }
<span class="line-modified">2113   return (bt == T_OBJECT || bt == T_NARROWOOP || bt == T_ARRAY);</span>

2114 }
2115 
2116 // Returns unique pointed java object or NULL.
2117 JavaObjectNode* ConnectionGraph::unique_java_object(Node *n) {
2118   assert(!_collecting, &quot;should not call when contructed graph&quot;);
2119   // If the node was created after the escape computation we can&#39;t answer.
2120   uint idx = n-&gt;_idx;
2121   if (idx &gt;= nodes_size()) {
2122     return NULL;
2123   }
2124   PointsToNode* ptn = ptnode_adr(idx);



2125   if (ptn-&gt;is_JavaObject()) {
2126     return ptn-&gt;as_JavaObject();
2127   }
2128   assert(ptn-&gt;is_LocalVar(), &quot;sanity&quot;);
2129   // Check all java objects it points to.
2130   JavaObjectNode* jobj = NULL;
2131   for (EdgeIterator i(ptn); i.has_next(); i.next()) {
2132     PointsToNode* e = i.get();
2133     if (e-&gt;is_JavaObject()) {
2134       if (jobj == NULL) {
2135         jobj = e-&gt;as_JavaObject();
2136       } else if (jobj != e) {
2137         return NULL;
2138       }
2139     }
2140   }
2141   return jobj;
2142 }
2143 
2144 // Return true if this node points only to non-escaping allocations.
</pre>
<hr />
<pre>
2158     if (e-&gt;is_JavaObject()) {
2159       Node* n = e-&gt;ideal_node();
2160       if ((e-&gt;escape_state() != PointsToNode::NoEscape) ||
2161           !(n-&gt;is_Allocate() || n-&gt;is_CallStaticJava())) {
2162         return false;
2163       }
2164     }
2165   }
2166   return true;
2167 }
2168 
2169 // Return true if we know the node does not escape globally.
2170 bool ConnectionGraph::not_global_escape(Node *n) {
2171   assert(!_collecting, &quot;should not call during graph construction&quot;);
2172   // If the node was created after the escape computation we can&#39;t answer.
2173   uint idx = n-&gt;_idx;
2174   if (idx &gt;= nodes_size()) {
2175     return false;
2176   }
2177   PointsToNode* ptn = ptnode_adr(idx);



2178   PointsToNode::EscapeState es = ptn-&gt;escape_state();
2179   // If we have already computed a value, return it.
2180   if (es &gt;= PointsToNode::GlobalEscape)
2181     return false;
2182   if (ptn-&gt;is_JavaObject()) {
2183     return true; // (es &lt; PointsToNode::GlobalEscape);
2184   }
2185   assert(ptn-&gt;is_LocalVar(), &quot;sanity&quot;);
2186   // Check all java objects it points to.
2187   for (EdgeIterator i(ptn); i.has_next(); i.next()) {
2188     if (i.get()-&gt;escape_state() &gt;= PointsToNode::GlobalEscape)
2189       return false;
2190   }
2191   return true;
2192 }
2193 
2194 
2195 // Helper functions
2196 
2197 // Return true if this node points to specified node or nodes it points to.
</pre>
<hr />
<pre>
2329   //     AddP  ( base == top )
2330   //
2331   Node *base = addp-&gt;in(AddPNode::Base);
2332   if (base-&gt;uncast()-&gt;is_top()) { // The AddP case #3 and #6 and #9.
2333     base = addp-&gt;in(AddPNode::Address);
2334     while (base-&gt;is_AddP()) {
2335       // Case #6 (unsafe access) may have several chained AddP nodes.
2336       assert(base-&gt;in(AddPNode::Base)-&gt;uncast()-&gt;is_top(), &quot;expected unsafe access address only&quot;);
2337       base = base-&gt;in(AddPNode::Address);
2338     }
2339     if (base-&gt;Opcode() == Op_CheckCastPP &amp;&amp;
2340         base-&gt;bottom_type()-&gt;isa_rawptr() &amp;&amp;
2341         _igvn-&gt;type(base-&gt;in(1))-&gt;isa_oopptr()) {
2342       base = base-&gt;in(1); // Case #9
2343     } else {
2344       Node* uncast_base = base-&gt;uncast();
2345       int opcode = uncast_base-&gt;Opcode();
2346       assert(opcode == Op_ConP || opcode == Op_ThreadLocal ||
2347              opcode == Op_CastX2P || uncast_base-&gt;is_DecodeNarrowPtr() ||
2348              (uncast_base-&gt;is_Mem() &amp;&amp; (uncast_base-&gt;bottom_type()-&gt;isa_rawptr() != NULL)) ||
<span class="line-modified">2349              (uncast_base-&gt;is_Proj() &amp;&amp; uncast_base-&gt;in(0)-&gt;is_Allocate()) ||</span>
<span class="line-removed">2350              BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;escape_is_barrier_node(uncast_base), &quot;sanity&quot;);</span>
2351     }
2352   }
2353   return base;
2354 }
2355 
2356 Node* ConnectionGraph::find_second_addp(Node* addp, Node* n) {
2357   assert(addp-&gt;is_AddP() &amp;&amp; addp-&gt;outcnt() &gt; 0, &quot;Don&#39;t process dead nodes&quot;);
2358   Node* addp2 = addp-&gt;raw_out(0);
2359   if (addp-&gt;outcnt() == 1 &amp;&amp; addp2-&gt;is_AddP() &amp;&amp;
2360       addp2-&gt;in(AddPNode::Base) == n &amp;&amp;
2361       addp2-&gt;in(AddPNode::Address) == addp) {
2362     assert(addp-&gt;in(AddPNode::Base) == n, &quot;expecting the same base&quot;);
2363     //
2364     // Find array&#39;s offset to push it on worklist first and
2365     // as result process an array&#39;s element offset first (pushed second)
2366     // to avoid CastPP for the array&#39;s offset.
2367     // Otherwise the inserted CastPP (LocalVar) will point to what
2368     // the AddP (Field) points to. Which would be wrong since
2369     // the algorithm expects the CastPP has the same point as
2370     // as AddP&#39;s base CheckCastPP (LocalVar).
</pre>
<hr />
<pre>
2718       continue;  // don&#39;t search further for non-instance types
2719     // skip over a call which does not affect this memory slice
2720     if (result-&gt;is_Proj() &amp;&amp; result-&gt;as_Proj()-&gt;_con == TypeFunc::Memory) {
2721       Node *proj_in = result-&gt;in(0);
2722       if (proj_in-&gt;is_Allocate() &amp;&amp; proj_in-&gt;_idx == (uint)toop-&gt;instance_id()) {
2723         break;  // hit one of our sentinels
2724       } else if (proj_in-&gt;is_Call()) {
2725         // ArrayCopy node processed here as well
2726         CallNode *call = proj_in-&gt;as_Call();
2727         if (!call-&gt;may_modify(toop, igvn)) {
2728           result = call-&gt;in(TypeFunc::Memory);
2729         }
2730       } else if (proj_in-&gt;is_Initialize()) {
2731         AllocateNode* alloc = proj_in-&gt;as_Initialize()-&gt;allocation();
2732         // Stop if this is the initialization for the object instance which
2733         // which contains this memory slice, otherwise skip over it.
2734         if (alloc == NULL || alloc-&gt;_idx != (uint)toop-&gt;instance_id()) {
2735           result = proj_in-&gt;in(TypeFunc::Memory);
2736         }
2737       } else if (proj_in-&gt;is_MemBar()) {
<span class="line-modified">2738         if (proj_in-&gt;in(TypeFunc::Memory)-&gt;is_MergeMem() &amp;&amp;</span>
<span class="line-modified">2739             proj_in-&gt;in(TypeFunc::Memory)-&gt;as_MergeMem()-&gt;in(Compile::AliasIdxRaw)-&gt;is_Proj() &amp;&amp;</span>
<span class="line-modified">2740             proj_in-&gt;in(TypeFunc::Memory)-&gt;as_MergeMem()-&gt;in(Compile::AliasIdxRaw)-&gt;in(0)-&gt;is_ArrayCopy()) {</span>
<span class="line-modified">2741           // clone</span>
<span class="line-modified">2742           ArrayCopyNode* ac = proj_in-&gt;in(TypeFunc::Memory)-&gt;as_MergeMem()-&gt;in(Compile::AliasIdxRaw)-&gt;in(0)-&gt;as_ArrayCopy();</span>



2743           if (ac-&gt;may_modify(toop, igvn)) {
2744             break;
2745           }
2746         }
2747         result = proj_in-&gt;in(TypeFunc::Memory);
2748       }
2749     } else if (result-&gt;is_MergeMem()) {
2750       MergeMemNode *mmem = result-&gt;as_MergeMem();
2751       result = step_through_mergemem(mmem, alias_idx, toop);
2752       if (result == mmem-&gt;base_memory()) {
2753         // Didn&#39;t find instance memory, search through general slice recursively.
2754         result = mmem-&gt;memory_at(C-&gt;get_general_index(alias_idx));
2755         result = find_inst_mem(result, alias_idx, orig_phis);
2756         if (C-&gt;failing()) {
2757           return NULL;
2758         }
2759         mmem-&gt;set_memory_at(alias_idx, result);
2760       }
2761     } else if (result-&gt;is_Phi() &amp;&amp;
2762                C-&gt;get_alias_index(result-&gt;as_Phi()-&gt;adr_type()) != alias_idx) {
</pre>
<hr />
<pre>
3068           }
3069         }
3070       }
3071     } else if (n-&gt;is_AddP()) {
3072       JavaObjectNode* jobj = unique_java_object(get_addp_base(n));
3073       if (jobj == NULL || jobj == phantom_obj) {
3074 #ifdef ASSERT
3075         ptnode_adr(get_addp_base(n)-&gt;_idx)-&gt;dump();
3076         ptnode_adr(n-&gt;_idx)-&gt;dump();
3077         assert(jobj != NULL &amp;&amp; jobj != phantom_obj, &quot;escaped allocation&quot;);
3078 #endif
3079         _compile-&gt;record_failure(C2Compiler::retry_no_escape_analysis());
3080         return;
3081       }
3082       Node *base = get_map(jobj-&gt;idx());  // CheckCastPP node
3083       if (!split_AddP(n, base)) continue; // wrong type from dead path
3084     } else if (n-&gt;is_Phi() ||
3085                n-&gt;is_CheckCastPP() ||
3086                n-&gt;is_EncodeP() ||
3087                n-&gt;is_DecodeN() ||
<span class="line-removed">3088                BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;escape_is_barrier_node(n) ||</span>
3089                (n-&gt;is_ConstraintCast() &amp;&amp; n-&gt;Opcode() == Op_CastPP)) {
3090       if (visited.test_set(n-&gt;_idx)) {
3091         assert(n-&gt;is_Phi(), &quot;loops only through Phi&#39;s&quot;);
3092         continue;  // already processed
3093       }
3094       JavaObjectNode* jobj = unique_java_object(n);
3095       if (jobj == NULL || jobj == phantom_obj) {
3096 #ifdef ASSERT
3097         ptnode_adr(n-&gt;_idx)-&gt;dump();
3098         assert(jobj != NULL &amp;&amp; jobj != phantom_obj, &quot;escaped allocation&quot;);
3099 #endif
3100         _compile-&gt;record_failure(C2Compiler::retry_no_escape_analysis());
3101         return;
3102       } else {
3103         Node *val = get_map(jobj-&gt;idx());   // CheckCastPP node
3104         TypeNode *tn = n-&gt;as_Type();
3105         const TypeOopPtr* tinst = igvn-&gt;type(val)-&gt;isa_oopptr();
3106         assert(tinst != NULL &amp;&amp; tinst-&gt;is_known_instance() &amp;&amp;
3107                tinst-&gt;instance_id() == jobj-&gt;idx() , &quot;instance type expected.&quot;);
3108 
</pre>
<hr />
<pre>
3139     // push allocation&#39;s users on appropriate worklist
3140     for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
3141       Node *use = n-&gt;fast_out(i);
3142       if(use-&gt;is_Mem() &amp;&amp; use-&gt;in(MemNode::Address) == n) {
3143         // Load/store to instance&#39;s field
3144         memnode_worklist.append_if_missing(use);
3145       } else if (use-&gt;is_MemBar()) {
3146         if (use-&gt;in(TypeFunc::Memory) == n) { // Ignore precedent edge
3147           memnode_worklist.append_if_missing(use);
3148         }
3149       } else if (use-&gt;is_AddP() &amp;&amp; use-&gt;outcnt() &gt; 0) { // No dead nodes
3150         Node* addp2 = find_second_addp(use, n);
3151         if (addp2 != NULL) {
3152           alloc_worklist.append_if_missing(addp2);
3153         }
3154         alloc_worklist.append_if_missing(use);
3155       } else if (use-&gt;is_Phi() ||
3156                  use-&gt;is_CheckCastPP() ||
3157                  use-&gt;is_EncodeNarrowPtr() ||
3158                  use-&gt;is_DecodeNarrowPtr() ||
<span class="line-removed">3159                  BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;escape_is_barrier_node(use) ||</span>
3160                  (use-&gt;is_ConstraintCast() &amp;&amp; use-&gt;Opcode() == Op_CastPP)) {
3161         alloc_worklist.append_if_missing(use);
3162 #ifdef ASSERT
3163       } else if (use-&gt;is_Mem()) {
3164         assert(use-&gt;in(MemNode::Address) != n, &quot;EA: missing allocation reference path&quot;);
3165       } else if (use-&gt;is_MergeMem()) {
3166         assert(_mergemem_worklist.contains(use-&gt;as_MergeMem()), &quot;EA: missing MergeMem node in the worklist&quot;);
3167       } else if (use-&gt;is_SafePoint()) {
3168         // Look for MergeMem nodes for calls which reference unique allocation
3169         // (through CheckCastPP nodes) even for debug info.
3170         Node* m = use-&gt;in(TypeFunc::Memory);
3171         if (m-&gt;is_MergeMem()) {
3172           assert(_mergemem_worklist.contains(m-&gt;as_MergeMem()), &quot;EA: missing MergeMem node in the worklist&quot;);
3173         }
3174       } else if (use-&gt;Opcode() == Op_EncodeISOArray) {
3175         if (use-&gt;in(MemNode::Memory) == n || use-&gt;in(3) == n) {
3176           // EncodeISOArray overwrites destination array
3177           memnode_worklist.append_if_missing(use);
3178         }
3179       } else {
3180         uint op = use-&gt;Opcode();
3181         if ((op == Op_StrCompressedCopy || op == Op_StrInflatedCopy) &amp;&amp;
3182             (use-&gt;in(MemNode::Memory) == n)) {
3183           // They overwrite memory edge corresponding to destination array,
3184           memnode_worklist.append_if_missing(use);
3185         } else if (!(op == Op_CmpP || op == Op_Conv2B ||
3186               op == Op_CastP2X || op == Op_StoreCM ||
3187               op == Op_FastLock || op == Op_AryEq || op == Op_StrComp || op == Op_HasNegatives ||
3188               op == Op_StrCompressedCopy || op == Op_StrInflatedCopy ||
3189               op == Op_StrEquals || op == Op_StrIndexOf || op == Op_StrIndexOfChar ||

3190               BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(use))) {
3191           n-&gt;dump();
3192           use-&gt;dump();
3193           assert(false, &quot;EA: missing allocation reference path&quot;);
3194         }
3195 #endif
3196       }
3197     }
3198 
3199   }
3200 
3201   // Go over all ArrayCopy nodes and if one of the inputs has a unique
3202   // type, record it in the ArrayCopy node so we know what memory this
3203   // node uses/modified.
3204   for (int next = 0; next &lt; arraycopy_worklist.length(); next++) {
3205     ArrayCopyNode* ac = arraycopy_worklist.at(next);
3206     Node* dest = ac-&gt;in(ArrayCopyNode::Dest);
3207     if (dest-&gt;is_AddP()) {
3208       dest = get_addp_base(dest);
3209     }
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
 333     } else {
 334       assert((ptnode_adr(adr-&gt;_idx) == NULL ||
 335               ptnode_adr(adr-&gt;_idx)-&gt;as_Field()-&gt;is_oop()), &quot;sanity&quot;);
 336     }
 337 #endif
 338     add_local_var_and_edge(n, PointsToNode::NoEscape,
 339                            adr, delayed_worklist);
 340   }
 341 }
 342 
 343 // Populate Connection Graph with PointsTo nodes and create simple
 344 // connection graph edges.
 345 void ConnectionGraph::add_node_to_connection_graph(Node *n, Unique_Node_List *delayed_worklist) {
 346   assert(!_verify, &quot;this method should not be called for verification&quot;);
 347   PhaseGVN* igvn = _igvn;
 348   uint n_idx = n-&gt;_idx;
 349   PointsToNode* n_ptn = ptnode_adr(n_idx);
 350   if (n_ptn != NULL)
 351     return; // No need to redefine PointsTo node during first iteration.
 352 
<span class="line-added"> 353   int opcode = n-&gt;Opcode();</span>
<span class="line-added"> 354   bool gc_handled = BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;escape_add_to_con_graph(this, igvn, delayed_worklist, n, opcode);</span>
<span class="line-added"> 355   if (gc_handled) {</span>
<span class="line-added"> 356     return; // Ignore node if already handled by GC.</span>
<span class="line-added"> 357   }</span>
<span class="line-added"> 358 </span>
 359   if (n-&gt;is_Call()) {
 360     // Arguments to allocation and locking don&#39;t escape.
 361     if (n-&gt;is_AbstractLock()) {
 362       // Put Lock and Unlock nodes on IGVN worklist to process them during
 363       // first IGVN optimization when escape information is still available.
 364       record_for_optimizer(n);
 365     } else if (n-&gt;is_Allocate()) {
 366       add_call_node(n-&gt;as_Call());
 367       record_for_optimizer(n);
 368     } else {
 369       if (n-&gt;is_CallStaticJava()) {
 370         const char* name = n-&gt;as_CallStaticJava()-&gt;_name;
 371         if (name != NULL &amp;&amp; strcmp(name, &quot;uncommon_trap&quot;) == 0)
 372           return; // Skip uncommon traps
 373       }
 374       // Don&#39;t mark as processed since call&#39;s arguments have to be processed.
 375       delayed_worklist-&gt;push(n);
 376       // Check if a call returns an object.
 377       if ((n-&gt;as_Call()-&gt;returns_pointer() &amp;&amp;
 378            n-&gt;as_Call()-&gt;proj_out_or_null(TypeFunc::Parms) != NULL) ||
 379           (n-&gt;is_CallStaticJava() &amp;&amp;
 380            n-&gt;as_CallStaticJava()-&gt;is_boxing_method())) {
 381         add_call_node(n-&gt;as_Call());
 382       }
 383     }
 384     return;
 385   }
 386   // Put this check here to process call arguments since some call nodes
 387   // point to phantom_obj.
 388   if (n_ptn == phantom_obj || n_ptn == null_obj)
 389     return; // Skip predefined nodes.
 390 





 391   switch (opcode) {
 392     case Op_AddP: {
 393       Node* base = get_addp_base(n);
 394       PointsToNode* ptn_base = ptnode_adr(base-&gt;_idx);
 395       // Field nodes are created for all field types. They are used in
 396       // adjust_scalar_replaceable_state() and split_unique_types().
 397       // Note, non-oop fields will have only base edges in Connection
 398       // Graph because such fields are not used for oop loads and stores.
 399       int offset = address_offset(n, igvn);
 400       add_field(n, PointsToNode::NoEscape, offset);
 401       if (ptn_base == NULL) {
 402         delayed_worklist-&gt;push(n); // Process it later.
 403       } else {
 404         n_ptn = ptnode_adr(n_idx);
 405         add_base(n_ptn-&gt;as_Field(), ptn_base);
 406       }
 407       break;
 408     }
 409     case Op_CastX2P: {
 410       map_ideal_node(n, phantom_obj);
</pre>
<hr />
<pre>
 973           // src or dst could be j.l.Object when other is basic type array:
 974           //
 975           //   arraycopy(char[],0,Object*,0,size);
 976           //   arraycopy(Object*,0,char[],0,size);
 977           //
 978           // Don&#39;t add edges in such cases.
 979           //
 980           bool arg_is_arraycopy_dest = src_has_oops &amp;&amp; is_arraycopy &amp;&amp;
 981                                        arg_has_oops &amp;&amp; (i &gt; TypeFunc::Parms);
 982 #ifdef ASSERT
 983           if (!(is_arraycopy ||
 984                 BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(call) ||
 985                 (call-&gt;as_CallLeaf()-&gt;_name != NULL &amp;&amp;
 986                  (strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;updateBytesCRC32&quot;) == 0 ||
 987                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;updateBytesCRC32C&quot;) == 0 ||
 988                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;updateBytesAdler32&quot;) == 0 ||
 989                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;aescrypt_encryptBlock&quot;) == 0 ||
 990                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;aescrypt_decryptBlock&quot;) == 0 ||
 991                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;cipherBlockChaining_encryptAESCrypt&quot;) == 0 ||
 992                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;cipherBlockChaining_decryptAESCrypt&quot;) == 0 ||
<span class="line-added"> 993                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;electronicCodeBook_encryptAESCrypt&quot;) == 0 ||</span>
<span class="line-added"> 994                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;electronicCodeBook_decryptAESCrypt&quot;) == 0 ||</span>
 995                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;counterMode_AESCrypt&quot;) == 0 ||
 996                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;ghash_processBlocks&quot;) == 0 ||
 997                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;encodeBlock&quot;) == 0 ||
 998                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha1_implCompress&quot;) == 0 ||
 999                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha1_implCompressMB&quot;) == 0 ||
1000                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha256_implCompress&quot;) == 0 ||
1001                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha256_implCompressMB&quot;) == 0 ||
1002                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha512_implCompress&quot;) == 0 ||
1003                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;sha512_implCompressMB&quot;) == 0 ||
1004                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;multiplyToLen&quot;) == 0 ||
1005                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;squareToLen&quot;) == 0 ||
1006                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;mulAdd&quot;) == 0 ||
1007                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;montgomery_multiply&quot;) == 0 ||
1008                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;montgomery_square&quot;) == 0 ||
<span class="line-added">1009                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;bigIntegerRightShiftWorker&quot;) == 0 ||</span>
<span class="line-added">1010                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;bigIntegerLeftShiftWorker&quot;) == 0 ||</span>
1011                   strcmp(call-&gt;as_CallLeaf()-&gt;_name, &quot;vectorizedMismatch&quot;) == 0)
1012                  ))) {
1013             call-&gt;dump();
1014             fatal(&quot;EA unexpected CallLeaf %s&quot;, call-&gt;as_CallLeaf()-&gt;_name);
1015           }
1016 #endif
1017           // Always process arraycopy&#39;s destination object since
1018           // we need to add all possible edges to references in
1019           // source object.
1020           if (arg_esc &gt;= PointsToNode::ArgEscape &amp;&amp;
1021               !arg_is_arraycopy_dest) {
1022             continue;
1023           }
1024           PointsToNode::EscapeState es = PointsToNode::ArgEscape;
1025           if (call-&gt;is_ArrayCopy()) {
1026             ArrayCopyNode* ac = call-&gt;as_ArrayCopy();
1027             if (ac-&gt;is_clonebasic() ||
1028                 ac-&gt;is_arraycopy_validated() ||
1029                 ac-&gt;is_copyof_validated() ||
1030                 ac-&gt;is_copyofrange_validated()) {
</pre>
<hr />
<pre>
1399           PointsToNode* e = i.get();
1400           if (e-&gt;is_Arraycopy()) {
1401             if (jobj == null_obj) // NULL object does not have field edges
1402               continue;
1403             // Add edge from arraycopy&#39;s destination java object to Arraycopy node.
1404             if (add_edge(jobj, e)) {
1405               new_edges++;
1406               jobj-&gt;set_arraycopy_dst();
1407             }
1408           }
1409         }
1410       }
1411     } else {
1412       // Added new edge to stored in field values.
1413       // Put on worklist all field&#39;s uses (loads) and
1414       // related field nodes (same base and offset).
1415       add_field_uses_to_worklist(use-&gt;as_Field());
1416     }
1417   }
1418   _worklist.clear();
<span class="line-modified">1419   _in_worklist.reset();</span>
1420   return new_edges;
1421 }
1422 
1423 // Put on worklist all related field nodes.
1424 void ConnectionGraph::add_field_uses_to_worklist(FieldNode* field) {
1425   assert(field-&gt;is_oop(), &quot;sanity&quot;);
1426   int offset = field-&gt;offset();
1427   add_uses_to_worklist(field);
1428   // Loop over all bases of this field and push on worklist Field nodes
1429   // with the same offset and base (since they may reference the same field).
1430   for (BaseIterator i(field); i.has_next(); i.next()) {
1431     PointsToNode* base = i.get();
1432     add_fields_to_worklist(field, base);
1433     // Check if the base was source object of arraycopy and go over arraycopy&#39;s
1434     // destination objects since values stored to a field of source object are
1435     // accessable by uses (loads) of fields of destination objects.
1436     if (base-&gt;arraycopy_src()) {
1437       for (UseIterator j(base); j.has_next(); j.next()) {
1438         PointsToNode* arycp = j.get();
1439         if (arycp-&gt;is_Arraycopy()) {
</pre>
<hr />
<pre>
2098       }
2099     } else if (adr_type-&gt;isa_aryptr()) {
2100       if (offset == arrayOopDesc::length_offset_in_bytes()) {
2101         // Ignore array length load.
2102       } else if (find_second_addp(n, n-&gt;in(AddPNode::Base)) != NULL) {
2103         // Ignore first AddP.
2104       } else {
2105         const Type* elemtype = adr_type-&gt;isa_aryptr()-&gt;elem();
2106         bt = elemtype-&gt;array_element_basic_type();
2107       }
2108     } else if (adr_type-&gt;isa_rawptr() || adr_type-&gt;isa_klassptr()) {
2109       // Allocation initialization, ThreadLocal field access, unsafe access
2110       if (n-&gt;has_out_with(Op_StoreP, Op_LoadP, Op_StoreN, Op_LoadN) ||
2111           n-&gt;has_out_with(Op_GetAndSetP, Op_GetAndSetN, Op_CompareAndExchangeP, Op_CompareAndExchangeN) ||
2112           n-&gt;has_out_with(Op_CompareAndSwapP, Op_CompareAndSwapN, Op_WeakCompareAndSwapP, Op_WeakCompareAndSwapN) ||
2113           BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;escape_has_out_with_unsafe_object(n)) {
2114         bt = T_OBJECT;
2115       }
2116     }
2117   }
<span class="line-modified">2118   // Note: T_NARROWOOP is not classed as a real reference type</span>
<span class="line-added">2119   return (is_reference_type(bt) || bt == T_NARROWOOP);</span>
2120 }
2121 
2122 // Returns unique pointed java object or NULL.
2123 JavaObjectNode* ConnectionGraph::unique_java_object(Node *n) {
2124   assert(!_collecting, &quot;should not call when contructed graph&quot;);
2125   // If the node was created after the escape computation we can&#39;t answer.
2126   uint idx = n-&gt;_idx;
2127   if (idx &gt;= nodes_size()) {
2128     return NULL;
2129   }
2130   PointsToNode* ptn = ptnode_adr(idx);
<span class="line-added">2131   if (ptn == NULL) {</span>
<span class="line-added">2132     return NULL;</span>
<span class="line-added">2133   }</span>
2134   if (ptn-&gt;is_JavaObject()) {
2135     return ptn-&gt;as_JavaObject();
2136   }
2137   assert(ptn-&gt;is_LocalVar(), &quot;sanity&quot;);
2138   // Check all java objects it points to.
2139   JavaObjectNode* jobj = NULL;
2140   for (EdgeIterator i(ptn); i.has_next(); i.next()) {
2141     PointsToNode* e = i.get();
2142     if (e-&gt;is_JavaObject()) {
2143       if (jobj == NULL) {
2144         jobj = e-&gt;as_JavaObject();
2145       } else if (jobj != e) {
2146         return NULL;
2147       }
2148     }
2149   }
2150   return jobj;
2151 }
2152 
2153 // Return true if this node points only to non-escaping allocations.
</pre>
<hr />
<pre>
2167     if (e-&gt;is_JavaObject()) {
2168       Node* n = e-&gt;ideal_node();
2169       if ((e-&gt;escape_state() != PointsToNode::NoEscape) ||
2170           !(n-&gt;is_Allocate() || n-&gt;is_CallStaticJava())) {
2171         return false;
2172       }
2173     }
2174   }
2175   return true;
2176 }
2177 
2178 // Return true if we know the node does not escape globally.
2179 bool ConnectionGraph::not_global_escape(Node *n) {
2180   assert(!_collecting, &quot;should not call during graph construction&quot;);
2181   // If the node was created after the escape computation we can&#39;t answer.
2182   uint idx = n-&gt;_idx;
2183   if (idx &gt;= nodes_size()) {
2184     return false;
2185   }
2186   PointsToNode* ptn = ptnode_adr(idx);
<span class="line-added">2187   if (ptn == NULL) {</span>
<span class="line-added">2188     return false; // not in congraph (e.g. ConI)</span>
<span class="line-added">2189   }</span>
2190   PointsToNode::EscapeState es = ptn-&gt;escape_state();
2191   // If we have already computed a value, return it.
2192   if (es &gt;= PointsToNode::GlobalEscape)
2193     return false;
2194   if (ptn-&gt;is_JavaObject()) {
2195     return true; // (es &lt; PointsToNode::GlobalEscape);
2196   }
2197   assert(ptn-&gt;is_LocalVar(), &quot;sanity&quot;);
2198   // Check all java objects it points to.
2199   for (EdgeIterator i(ptn); i.has_next(); i.next()) {
2200     if (i.get()-&gt;escape_state() &gt;= PointsToNode::GlobalEscape)
2201       return false;
2202   }
2203   return true;
2204 }
2205 
2206 
2207 // Helper functions
2208 
2209 // Return true if this node points to specified node or nodes it points to.
</pre>
<hr />
<pre>
2341   //     AddP  ( base == top )
2342   //
2343   Node *base = addp-&gt;in(AddPNode::Base);
2344   if (base-&gt;uncast()-&gt;is_top()) { // The AddP case #3 and #6 and #9.
2345     base = addp-&gt;in(AddPNode::Address);
2346     while (base-&gt;is_AddP()) {
2347       // Case #6 (unsafe access) may have several chained AddP nodes.
2348       assert(base-&gt;in(AddPNode::Base)-&gt;uncast()-&gt;is_top(), &quot;expected unsafe access address only&quot;);
2349       base = base-&gt;in(AddPNode::Address);
2350     }
2351     if (base-&gt;Opcode() == Op_CheckCastPP &amp;&amp;
2352         base-&gt;bottom_type()-&gt;isa_rawptr() &amp;&amp;
2353         _igvn-&gt;type(base-&gt;in(1))-&gt;isa_oopptr()) {
2354       base = base-&gt;in(1); // Case #9
2355     } else {
2356       Node* uncast_base = base-&gt;uncast();
2357       int opcode = uncast_base-&gt;Opcode();
2358       assert(opcode == Op_ConP || opcode == Op_ThreadLocal ||
2359              opcode == Op_CastX2P || uncast_base-&gt;is_DecodeNarrowPtr() ||
2360              (uncast_base-&gt;is_Mem() &amp;&amp; (uncast_base-&gt;bottom_type()-&gt;isa_rawptr() != NULL)) ||
<span class="line-modified">2361              (uncast_base-&gt;is_Proj() &amp;&amp; uncast_base-&gt;in(0)-&gt;is_Allocate()), &quot;sanity&quot;);</span>

2362     }
2363   }
2364   return base;
2365 }
2366 
2367 Node* ConnectionGraph::find_second_addp(Node* addp, Node* n) {
2368   assert(addp-&gt;is_AddP() &amp;&amp; addp-&gt;outcnt() &gt; 0, &quot;Don&#39;t process dead nodes&quot;);
2369   Node* addp2 = addp-&gt;raw_out(0);
2370   if (addp-&gt;outcnt() == 1 &amp;&amp; addp2-&gt;is_AddP() &amp;&amp;
2371       addp2-&gt;in(AddPNode::Base) == n &amp;&amp;
2372       addp2-&gt;in(AddPNode::Address) == addp) {
2373     assert(addp-&gt;in(AddPNode::Base) == n, &quot;expecting the same base&quot;);
2374     //
2375     // Find array&#39;s offset to push it on worklist first and
2376     // as result process an array&#39;s element offset first (pushed second)
2377     // to avoid CastPP for the array&#39;s offset.
2378     // Otherwise the inserted CastPP (LocalVar) will point to what
2379     // the AddP (Field) points to. Which would be wrong since
2380     // the algorithm expects the CastPP has the same point as
2381     // as AddP&#39;s base CheckCastPP (LocalVar).
</pre>
<hr />
<pre>
2729       continue;  // don&#39;t search further for non-instance types
2730     // skip over a call which does not affect this memory slice
2731     if (result-&gt;is_Proj() &amp;&amp; result-&gt;as_Proj()-&gt;_con == TypeFunc::Memory) {
2732       Node *proj_in = result-&gt;in(0);
2733       if (proj_in-&gt;is_Allocate() &amp;&amp; proj_in-&gt;_idx == (uint)toop-&gt;instance_id()) {
2734         break;  // hit one of our sentinels
2735       } else if (proj_in-&gt;is_Call()) {
2736         // ArrayCopy node processed here as well
2737         CallNode *call = proj_in-&gt;as_Call();
2738         if (!call-&gt;may_modify(toop, igvn)) {
2739           result = call-&gt;in(TypeFunc::Memory);
2740         }
2741       } else if (proj_in-&gt;is_Initialize()) {
2742         AllocateNode* alloc = proj_in-&gt;as_Initialize()-&gt;allocation();
2743         // Stop if this is the initialization for the object instance which
2744         // which contains this memory slice, otherwise skip over it.
2745         if (alloc == NULL || alloc-&gt;_idx != (uint)toop-&gt;instance_id()) {
2746           result = proj_in-&gt;in(TypeFunc::Memory);
2747         }
2748       } else if (proj_in-&gt;is_MemBar()) {
<span class="line-modified">2749         // Check if there is an array copy for a clone</span>
<span class="line-modified">2750         // Step over GC barrier when ReduceInitialCardMarks is disabled</span>
<span class="line-modified">2751         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();</span>
<span class="line-modified">2752         Node* control_proj_ac = bs-&gt;step_over_gc_barrier(proj_in-&gt;in(0));</span>
<span class="line-modified">2753 </span>
<span class="line-added">2754         if (control_proj_ac-&gt;is_Proj() &amp;&amp; control_proj_ac-&gt;in(0)-&gt;is_ArrayCopy()) {</span>
<span class="line-added">2755           // Stop if it is a clone</span>
<span class="line-added">2756           ArrayCopyNode* ac = control_proj_ac-&gt;in(0)-&gt;as_ArrayCopy();</span>
2757           if (ac-&gt;may_modify(toop, igvn)) {
2758             break;
2759           }
2760         }
2761         result = proj_in-&gt;in(TypeFunc::Memory);
2762       }
2763     } else if (result-&gt;is_MergeMem()) {
2764       MergeMemNode *mmem = result-&gt;as_MergeMem();
2765       result = step_through_mergemem(mmem, alias_idx, toop);
2766       if (result == mmem-&gt;base_memory()) {
2767         // Didn&#39;t find instance memory, search through general slice recursively.
2768         result = mmem-&gt;memory_at(C-&gt;get_general_index(alias_idx));
2769         result = find_inst_mem(result, alias_idx, orig_phis);
2770         if (C-&gt;failing()) {
2771           return NULL;
2772         }
2773         mmem-&gt;set_memory_at(alias_idx, result);
2774       }
2775     } else if (result-&gt;is_Phi() &amp;&amp;
2776                C-&gt;get_alias_index(result-&gt;as_Phi()-&gt;adr_type()) != alias_idx) {
</pre>
<hr />
<pre>
3082           }
3083         }
3084       }
3085     } else if (n-&gt;is_AddP()) {
3086       JavaObjectNode* jobj = unique_java_object(get_addp_base(n));
3087       if (jobj == NULL || jobj == phantom_obj) {
3088 #ifdef ASSERT
3089         ptnode_adr(get_addp_base(n)-&gt;_idx)-&gt;dump();
3090         ptnode_adr(n-&gt;_idx)-&gt;dump();
3091         assert(jobj != NULL &amp;&amp; jobj != phantom_obj, &quot;escaped allocation&quot;);
3092 #endif
3093         _compile-&gt;record_failure(C2Compiler::retry_no_escape_analysis());
3094         return;
3095       }
3096       Node *base = get_map(jobj-&gt;idx());  // CheckCastPP node
3097       if (!split_AddP(n, base)) continue; // wrong type from dead path
3098     } else if (n-&gt;is_Phi() ||
3099                n-&gt;is_CheckCastPP() ||
3100                n-&gt;is_EncodeP() ||
3101                n-&gt;is_DecodeN() ||

3102                (n-&gt;is_ConstraintCast() &amp;&amp; n-&gt;Opcode() == Op_CastPP)) {
3103       if (visited.test_set(n-&gt;_idx)) {
3104         assert(n-&gt;is_Phi(), &quot;loops only through Phi&#39;s&quot;);
3105         continue;  // already processed
3106       }
3107       JavaObjectNode* jobj = unique_java_object(n);
3108       if (jobj == NULL || jobj == phantom_obj) {
3109 #ifdef ASSERT
3110         ptnode_adr(n-&gt;_idx)-&gt;dump();
3111         assert(jobj != NULL &amp;&amp; jobj != phantom_obj, &quot;escaped allocation&quot;);
3112 #endif
3113         _compile-&gt;record_failure(C2Compiler::retry_no_escape_analysis());
3114         return;
3115       } else {
3116         Node *val = get_map(jobj-&gt;idx());   // CheckCastPP node
3117         TypeNode *tn = n-&gt;as_Type();
3118         const TypeOopPtr* tinst = igvn-&gt;type(val)-&gt;isa_oopptr();
3119         assert(tinst != NULL &amp;&amp; tinst-&gt;is_known_instance() &amp;&amp;
3120                tinst-&gt;instance_id() == jobj-&gt;idx() , &quot;instance type expected.&quot;);
3121 
</pre>
<hr />
<pre>
3152     // push allocation&#39;s users on appropriate worklist
3153     for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
3154       Node *use = n-&gt;fast_out(i);
3155       if(use-&gt;is_Mem() &amp;&amp; use-&gt;in(MemNode::Address) == n) {
3156         // Load/store to instance&#39;s field
3157         memnode_worklist.append_if_missing(use);
3158       } else if (use-&gt;is_MemBar()) {
3159         if (use-&gt;in(TypeFunc::Memory) == n) { // Ignore precedent edge
3160           memnode_worklist.append_if_missing(use);
3161         }
3162       } else if (use-&gt;is_AddP() &amp;&amp; use-&gt;outcnt() &gt; 0) { // No dead nodes
3163         Node* addp2 = find_second_addp(use, n);
3164         if (addp2 != NULL) {
3165           alloc_worklist.append_if_missing(addp2);
3166         }
3167         alloc_worklist.append_if_missing(use);
3168       } else if (use-&gt;is_Phi() ||
3169                  use-&gt;is_CheckCastPP() ||
3170                  use-&gt;is_EncodeNarrowPtr() ||
3171                  use-&gt;is_DecodeNarrowPtr() ||

3172                  (use-&gt;is_ConstraintCast() &amp;&amp; use-&gt;Opcode() == Op_CastPP)) {
3173         alloc_worklist.append_if_missing(use);
3174 #ifdef ASSERT
3175       } else if (use-&gt;is_Mem()) {
3176         assert(use-&gt;in(MemNode::Address) != n, &quot;EA: missing allocation reference path&quot;);
3177       } else if (use-&gt;is_MergeMem()) {
3178         assert(_mergemem_worklist.contains(use-&gt;as_MergeMem()), &quot;EA: missing MergeMem node in the worklist&quot;);
3179       } else if (use-&gt;is_SafePoint()) {
3180         // Look for MergeMem nodes for calls which reference unique allocation
3181         // (through CheckCastPP nodes) even for debug info.
3182         Node* m = use-&gt;in(TypeFunc::Memory);
3183         if (m-&gt;is_MergeMem()) {
3184           assert(_mergemem_worklist.contains(m-&gt;as_MergeMem()), &quot;EA: missing MergeMem node in the worklist&quot;);
3185         }
3186       } else if (use-&gt;Opcode() == Op_EncodeISOArray) {
3187         if (use-&gt;in(MemNode::Memory) == n || use-&gt;in(3) == n) {
3188           // EncodeISOArray overwrites destination array
3189           memnode_worklist.append_if_missing(use);
3190         }
3191       } else {
3192         uint op = use-&gt;Opcode();
3193         if ((op == Op_StrCompressedCopy || op == Op_StrInflatedCopy) &amp;&amp;
3194             (use-&gt;in(MemNode::Memory) == n)) {
3195           // They overwrite memory edge corresponding to destination array,
3196           memnode_worklist.append_if_missing(use);
3197         } else if (!(op == Op_CmpP || op == Op_Conv2B ||
3198               op == Op_CastP2X || op == Op_StoreCM ||
3199               op == Op_FastLock || op == Op_AryEq || op == Op_StrComp || op == Op_HasNegatives ||
3200               op == Op_StrCompressedCopy || op == Op_StrInflatedCopy ||
3201               op == Op_StrEquals || op == Op_StrIndexOf || op == Op_StrIndexOfChar ||
<span class="line-added">3202               op == Op_SubTypeCheck ||</span>
3203               BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(use))) {
3204           n-&gt;dump();
3205           use-&gt;dump();
3206           assert(false, &quot;EA: missing allocation reference path&quot;);
3207         }
3208 #endif
3209       }
3210     }
3211 
3212   }
3213 
3214   // Go over all ArrayCopy nodes and if one of the inputs has a unique
3215   // type, record it in the ArrayCopy node so we know what memory this
3216   // node uses/modified.
3217   for (int next = 0; next &lt; arraycopy_worklist.length(); next++) {
3218     ArrayCopyNode* ac = arraycopy_worklist.at(next);
3219     Node* dest = ac-&gt;in(ArrayCopyNode::Dest);
3220     if (dest-&gt;is_AddP()) {
3221       dest = get_addp_base(dest);
3222     }
</pre>
</td>
</tr>
</table>
<center><a href="doCall.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="escape.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>