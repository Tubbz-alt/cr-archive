<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/compile.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="coalesce.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/compile.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 1997, 2018, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
  59 #include &quot;opto/mulnode.hpp&quot;
  60 #include &quot;opto/narrowptrnode.hpp&quot;
  61 #include &quot;opto/node.hpp&quot;
  62 #include &quot;opto/opcodes.hpp&quot;
  63 #include &quot;opto/output.hpp&quot;
  64 #include &quot;opto/parse.hpp&quot;
  65 #include &quot;opto/phaseX.hpp&quot;
  66 #include &quot;opto/rootnode.hpp&quot;
  67 #include &quot;opto/runtime.hpp&quot;
  68 #include &quot;opto/stringopts.hpp&quot;
  69 #include &quot;opto/type.hpp&quot;
  70 #include &quot;opto/vectornode.hpp&quot;
  71 #include &quot;runtime/arguments.hpp&quot;
  72 #include &quot;runtime/sharedRuntime.hpp&quot;
  73 #include &quot;runtime/signature.hpp&quot;
  74 #include &quot;runtime/stubRoutines.hpp&quot;
  75 #include &quot;runtime/timer.hpp&quot;
  76 #include &quot;utilities/align.hpp&quot;
  77 #include &quot;utilities/copy.hpp&quot;
  78 #include &quot;utilities/macros.hpp&quot;
<span class="line-removed">  79 #if INCLUDE_ZGC</span>
<span class="line-removed">  80 #include &quot;gc/z/c2/zBarrierSetC2.hpp&quot;</span>
<span class="line-removed">  81 #endif</span>
  82 
  83 
  84 // -------------------- Compile::mach_constant_base_node -----------------------
  85 // Constant table base node singleton.
  86 MachConstantBaseNode* Compile::mach_constant_base_node() {
  87   if (_mach_constant_base_node == NULL) {
  88     _mach_constant_base_node = new MachConstantBaseNode();
  89     _mach_constant_base_node-&gt;add_req(C-&gt;root());
  90   }
  91   return _mach_constant_base_node;
  92 }
  93 
  94 
  95 /// Support for intrinsics.
  96 
  97 // Return the index at which m must be inserted (or already exists).
  98 // The sort order is by the address of the ciMethod, with is_virtual as minor key.
  99 class IntrinsicDescPair {
 100  private:
 101   ciMethod* _m;
</pre>
<hr />
<pre>
 324     assert( next &lt; unique(), &quot;Unique useful nodes &lt; total nodes&quot;);
 325     Node *n  = useful.at(next);
 326     uint max = n-&gt;len();
 327     for( uint i = 0; i &lt; max; ++i ) {
 328       Node *m = n-&gt;in(i);
 329       if (not_a_node(m))  continue;
 330       useful.push(m);
 331     }
 332   }
 333 }
 334 
 335 // Update dead_node_list with any missing dead nodes using useful
 336 // list. Consider all non-useful nodes to be useless i.e., dead nodes.
 337 void Compile::update_dead_node_list(Unique_Node_List &amp;useful) {
 338   uint max_idx = unique();
 339   VectorSet&amp; useful_node_set = useful.member_set();
 340 
 341   for (uint node_idx = 0; node_idx &lt; max_idx; node_idx++) {
 342     // If node with index node_idx is not in useful set,
 343     // mark it as dead in dead node list.
<span class="line-modified"> 344     if (! useful_node_set.test(node_idx) ) {</span>
 345       record_dead_node(node_idx);
 346     }
 347   }
 348 }
 349 
 350 void Compile::remove_useless_late_inlines(GrowableArray&lt;CallGenerator*&gt;* inlines, Unique_Node_List &amp;useful) {
 351   int shift = 0;
 352   for (int i = 0; i &lt; inlines-&gt;length(); i++) {
 353     CallGenerator* cg = inlines-&gt;at(i);
 354     CallNode* call = cg-&gt;call_node();
 355     if (shift &gt; 0) {
 356       inlines-&gt;at_put(i-shift, cg);
 357     }
 358     if (!useful.member(call)) {
 359       shift++;
 360     }
 361   }
 362   inlines-&gt;trunc_to(inlines-&gt;length()-shift);
 363 }
 364 
</pre>
<hr />
<pre>
 448 //------------------------------CompileWrapper---------------------------------
 449 class CompileWrapper : public StackObj {
 450   Compile *const _compile;
 451  public:
 452   CompileWrapper(Compile* compile);
 453 
 454   ~CompileWrapper();
 455 };
 456 
 457 CompileWrapper::CompileWrapper(Compile* compile) : _compile(compile) {
 458   // the Compile* pointer is stored in the current ciEnv:
 459   ciEnv* env = compile-&gt;env();
 460   assert(env == ciEnv::current(), &quot;must already be a ciEnv active&quot;);
 461   assert(env-&gt;compiler_data() == NULL, &quot;compile already active?&quot;);
 462   env-&gt;set_compiler_data(compile);
 463   assert(compile == Compile::current(), &quot;sanity&quot;);
 464 
 465   compile-&gt;set_type_dict(NULL);
 466   compile-&gt;set_clone_map(new Dict(cmpkey, hashkey, _compile-&gt;comp_arena()));
 467   compile-&gt;clone_map().set_clone_idx(0);
<span class="line-removed"> 468   compile-&gt;set_type_hwm(NULL);</span>
 469   compile-&gt;set_type_last_size(0);
 470   compile-&gt;set_last_tf(NULL, NULL);
 471   compile-&gt;set_indexSet_arena(NULL);
 472   compile-&gt;set_indexSet_free_block_list(NULL);
 473   compile-&gt;init_type_arena();
 474   Type::Initialize(compile);
 475   _compile-&gt;set_scratch_buffer_blob(NULL);
 476   _compile-&gt;begin_method();
 477   _compile-&gt;clone_map().set_debug(_compile-&gt;has_method() &amp;&amp; _compile-&gt;directive()-&gt;CloneMapDebugOption);
 478 }
 479 CompileWrapper::~CompileWrapper() {
 480   _compile-&gt;end_method();
 481   if (_compile-&gt;scratch_buffer_blob() != NULL)
 482     BufferBlob::free(_compile-&gt;scratch_buffer_blob());
 483   _compile-&gt;env()-&gt;set_compiler_data(NULL);
 484 }
 485 
 486 
 487 //----------------------------print_compile_messages---------------------------
 488 void Compile::print_compile_messages() {
</pre>
<hr />
<pre>
 635                 : Phase(Compiler),
 636                   _compile_id(ci_env-&gt;compile_id()),
 637                   _save_argument_registers(false),
 638                   _subsume_loads(subsume_loads),
 639                   _do_escape_analysis(do_escape_analysis),
 640                   _eliminate_boxing(eliminate_boxing),
 641                   _method(target),
 642                   _entry_bci(osr_bci),
 643                   _stub_function(NULL),
 644                   _stub_name(NULL),
 645                   _stub_entry_point(NULL),
 646                   _max_node_limit(MaxNodeLimit),
 647                   _orig_pc_slot(0),
 648                   _orig_pc_slot_offset_in_bytes(0),
 649                   _inlining_progress(false),
 650                   _inlining_incrementally(false),
 651                   _do_cleanup(false),
 652                   _has_reserved_stack_access(target-&gt;has_reserved_stack_access()),
 653 #ifndef PRODUCT
 654                   _trace_opto_output(directive-&gt;TraceOptoOutputOption),

 655 #endif
 656                   _has_method_handle_invokes(false),

 657                   _comp_arena(mtCompiler),
 658                   _barrier_set_state(BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;create_barrier_state(comp_arena())),
 659                   _env(ci_env),
 660                   _directive(directive),
 661                   _log(ci_env-&gt;log()),
 662                   _failure_reason(NULL),
 663                   _congraph(NULL),
 664 #ifndef PRODUCT
 665                   _printer(IdealGraphPrinter::printer()),
 666 #endif
 667                   _dead_node_list(comp_arena()),
 668                   _dead_node_count(0),
 669                   _node_arena(mtCompiler),
 670                   _old_arena(mtCompiler),
 671                   _mach_constant_base_node(NULL),
 672                   _Compile_types(mtCompiler),
 673                   _initial_gvn(NULL),
 674                   _for_igvn(NULL),
 675                   _warm_calls(NULL),
 676                   _late_inlines(comp_arena(), 2, 0, NULL),
</pre>
<hr />
<pre>
 696 #endif
 697 {
 698   C = this;
 699 #ifndef PRODUCT
 700   if (_printer != NULL) {
 701     _printer-&gt;set_compile(this);
 702   }
 703 #endif
 704   CompileWrapper cw(this);
 705 
 706   if (CITimeVerbose) {
 707     tty-&gt;print(&quot; &quot;);
 708     target-&gt;holder()-&gt;name()-&gt;print();
 709     tty-&gt;print(&quot;.&quot;);
 710     target-&gt;print_short_name();
 711     tty-&gt;print(&quot;  &quot;);
 712   }
 713   TraceTime t1(&quot;Total compilation time&quot;, &amp;_t_totalCompilation, CITime, CITimeVerbose);
 714   TraceTime t2(NULL, &amp;_t_methodCompilation, CITime, false);
 715 
<span class="line-modified"> 716 #ifndef PRODUCT</span>
 717   bool print_opto_assembly = directive-&gt;PrintOptoAssemblyOption;
<span class="line-modified"> 718   if (!print_opto_assembly) {</span>
<span class="line-modified"> 719     bool print_assembly = directive-&gt;PrintAssemblyOption;</span>
<span class="line-modified"> 720     if (print_assembly &amp;&amp; !Disassembler::can_decode()) {</span>
<span class="line-modified"> 721       tty-&gt;print_cr(&quot;PrintAssembly request changed to PrintOptoAssembly&quot;);</span>
<span class="line-modified"> 722       print_opto_assembly = true;</span>
<span class="line-modified"> 723     }</span>
<span class="line-modified"> 724   }</span>
<span class="line-modified"> 725   set_print_assembly(print_opto_assembly);</span>



 726   set_parsed_irreducible_loop(false);
 727 
 728   if (directive-&gt;ReplayInlineOption) {
 729     _replay_inline_data = ciReplay::load_inline_data(method(), entry_bci(), ci_env-&gt;comp_level());
 730   }
 731 #endif
 732   set_print_inlining(directive-&gt;PrintInliningOption || PrintOptoInlining);
 733   set_print_intrinsics(directive-&gt;PrintIntrinsicsOption);
 734   set_has_irreducible_loop(true); // conservative until build_loop_tree() reset it
 735 
 736   if (ProfileTraps RTM_OPT_ONLY( || UseRTMLocking )) {
 737     // Make sure the method being compiled gets its own MDO,
 738     // so we can at least track the decompile_count().
 739     // Need MDO to record RTM code generation state.
 740     method()-&gt;ensure_method_data();
 741   }
 742 
 743   Init(::AliasLevel);
 744 
 745 
</pre>
<hr />
<pre>
 856     if (successes == 0)  break;
 857   }
 858 
 859   // Drain the list.
 860   Finish_Warm();
 861 #ifndef PRODUCT
 862   if (_printer &amp;&amp; _printer-&gt;should_print(1)) {
 863     _printer-&gt;print_inlining();
 864   }
 865 #endif
 866 
 867   if (failing())  return;
 868   NOT_PRODUCT( verify_graph_edges(); )
 869 
 870   // Now optimize
 871   Optimize();
 872   if (failing())  return;
 873   NOT_PRODUCT( verify_graph_edges(); )
 874 
 875 #ifndef PRODUCT
<span class="line-modified"> 876   if (PrintIdeal) {</span>
 877     ttyLocker ttyl;  // keep the following output all in one block
 878     // This output goes directly to the tty, not the compiler log.
 879     // To enable tools to match it up with the compilation activity,
 880     // be sure to tag this tty output with the compile ID.
 881     if (xtty != NULL) {
 882       xtty-&gt;head(&quot;ideal compile_id=&#39;%d&#39;%s&quot;, compile_id(),
 883                  is_osr_compilation()    ? &quot; compile_kind=&#39;osr&#39;&quot; :
 884                  &quot;&quot;);
 885     }
 886     root()-&gt;dump(9999);
 887     if (xtty != NULL) {
 888       xtty-&gt;tail(&quot;ideal&quot;);
 889     }
 890   }
 891 #endif
 892 
 893 #ifdef ASSERT
 894   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 895   bs-&gt;verify_gc_barriers(this, BarrierSetC2::BeforeCodeGen);
 896 #endif
</pre>
<hr />
<pre>
 966                   DirectiveSet* directive)
 967   : Phase(Compiler),
 968     _compile_id(0),
 969     _save_argument_registers(save_arg_registers),
 970     _subsume_loads(true),
 971     _do_escape_analysis(false),
 972     _eliminate_boxing(false),
 973     _method(NULL),
 974     _entry_bci(InvocationEntryBci),
 975     _stub_function(stub_function),
 976     _stub_name(stub_name),
 977     _stub_entry_point(NULL),
 978     _max_node_limit(MaxNodeLimit),
 979     _orig_pc_slot(0),
 980     _orig_pc_slot_offset_in_bytes(0),
 981     _inlining_progress(false),
 982     _inlining_incrementally(false),
 983     _has_reserved_stack_access(false),
 984 #ifndef PRODUCT
 985     _trace_opto_output(directive-&gt;TraceOptoOutputOption),

 986 #endif
 987     _has_method_handle_invokes(false),

 988     _comp_arena(mtCompiler),

 989     _env(ci_env),
 990     _directive(directive),
 991     _log(ci_env-&gt;log()),
 992     _failure_reason(NULL),
 993     _congraph(NULL),
 994 #ifndef PRODUCT
 995     _printer(NULL),
 996 #endif
 997     _dead_node_list(comp_arena()),
 998     _dead_node_count(0),
 999     _node_arena(mtCompiler),
1000     _old_arena(mtCompiler),
1001     _mach_constant_base_node(NULL),
1002     _Compile_types(mtCompiler),
1003     _initial_gvn(NULL),
1004     _for_igvn(NULL),
1005     _warm_calls(NULL),
1006     _number_of_mh_late_inlines(0),
1007     _print_inlining_stream(NULL),
1008     _print_inlining_list(NULL),
</pre>
<hr />
<pre>
1010     _print_inlining_output(NULL),
1011     _replay_inline_data(NULL),
1012     _java_calls(0),
1013     _inner_loops(0),
1014     _interpreter_frame_size(0),
1015     _node_bundling_limit(0),
1016     _node_bundling_base(NULL),
1017     _code_buffer(&quot;Compile::Fill_buffer&quot;),
1018 #ifndef PRODUCT
1019     _in_dump_cnt(0),
1020 #endif
1021     _allowed_reasons(0) {
1022   C = this;
1023 
1024   TraceTime t1(NULL, &amp;_t_totalCompilation, CITime, false);
1025   TraceTime t2(NULL, &amp;_t_stubCompilation, CITime, false);
1026 
1027 #ifndef PRODUCT
1028   set_print_assembly(PrintFrameConverterAssembly);
1029   set_parsed_irreducible_loop(false);


1030 #endif
1031   set_has_irreducible_loop(false); // no loops
1032 
1033   CompileWrapper cw(this);
1034   Init(/*AliasLevel=*/ 0);
1035   init_tf((*generator)());
1036 
1037   {
1038     // The following is a dummy for the sake of GraphKit::gen_stub
1039     Unique_Node_List for_igvn(comp_arena());
1040     set_for_igvn(&amp;for_igvn);  // not used, but some GraphKit guys push on this
1041     PhaseGVN gvn(Thread::current()-&gt;resource_area(),255);
1042     set_initial_gvn(&amp;gvn);    // not significant, but GraphKit guys use it pervasively
1043     gvn.transform_no_reclaim(top());
1044 
1045     GraphKit kit;
1046     kit.gen_stub(stub_function, stub_name, is_fancy_jump, pass_tls, return_pc);
1047   }
1048 
1049   NOT_PRODUCT( verify_graph_edges(); )
</pre>
<hr />
<pre>
1071                                                       _oop_map_set,
1072                                                       save_arg_registers);
1073       assert(rs != NULL &amp;&amp; rs-&gt;is_runtime_stub(), &quot;sanity check&quot;);
1074 
1075       _stub_entry_point = rs-&gt;entry_point();
1076     }
1077   }
1078 }
1079 
1080 //------------------------------Init-------------------------------------------
1081 // Prepare for a single compilation
1082 void Compile::Init(int aliaslevel) {
1083   _unique  = 0;
1084   _regalloc = NULL;
1085 
1086   _tf      = NULL;  // filled in later
1087   _top     = NULL;  // cached later
1088   _matcher = NULL;  // filled in later
1089   _cfg     = NULL;  // filled in later
1090 
<span class="line-modified">1091   set_24_bit_selection_and_mode(Use24BitFP, false);</span>
1092 
1093   _node_note_array = NULL;
1094   _default_node_notes = NULL;
1095   DEBUG_ONLY( _modified_nodes = NULL; ) // Used in Optimize()
1096 
1097   _immutable_memory = NULL; // filled in at first inquiry
1098 
1099   // Globally visible Nodes
1100   // First set TOP to NULL to give safe behavior during creation of RootNode
1101   set_cached_top_node(NULL);
1102   set_root(new RootNode());
1103   // Now that you have a Root to point to, create the real TOP
1104   set_cached_top_node( new ConNode(Type::TOP) );
1105   set_recent_alloc(NULL, NULL);
1106 
1107   // Create Debug Information Recorder to record scopes, oopmaps, etc.
1108   env()-&gt;set_oop_recorder(new OopRecorder(env()-&gt;arena()));
1109   env()-&gt;set_debug_info(new DebugInformationRecorder(env()-&gt;oop_recorder()));
1110   env()-&gt;set_dependencies(new Dependencies(env()));
1111 
</pre>
<hr />
<pre>
1148   set_age_code(has_method() &amp;&amp; method()-&gt;profile_aging());
1149   set_rtm_state(NoRTM); // No RTM lock eliding by default
1150   _max_node_limit = _directive-&gt;MaxNodeLimitOption;
1151 
1152 #if INCLUDE_RTM_OPT
1153   if (UseRTMLocking &amp;&amp; has_method() &amp;&amp; (method()-&gt;method_data_or_null() != NULL)) {
1154     int rtm_state = method()-&gt;method_data()-&gt;rtm_state();
1155     if (method_has_option(&quot;NoRTMLockEliding&quot;) || ((rtm_state &amp; NoRTM) != 0)) {
1156       // Don&#39;t generate RTM lock eliding code.
1157       set_rtm_state(NoRTM);
1158     } else if (method_has_option(&quot;UseRTMLockEliding&quot;) || ((rtm_state &amp; UseRTM) != 0) || !UseRTMDeopt) {
1159       // Generate RTM lock eliding code without abort ratio calculation code.
1160       set_rtm_state(UseRTM);
1161     } else if (UseRTMDeopt) {
1162       // Generate RTM lock eliding code and include abort ratio calculation
1163       // code if UseRTMDeopt is on.
1164       set_rtm_state(ProfileRTM);
1165     }
1166   }
1167 #endif



1168   if (debug_info()-&gt;recording_non_safepoints()) {
1169     set_node_note_array(new(comp_arena()) GrowableArray&lt;Node_Notes*&gt;
1170                         (comp_arena(), 8, 0, NULL));
1171     set_default_node_notes(Node_Notes::make(this));
1172   }
1173 
1174   // // -- Initialize types before each compile --
1175   // // Update cached type information
1176   // if( _method &amp;&amp; _method-&gt;constants() )
1177   //   Type::update_loaded_types(_method, _method-&gt;constants());
1178 
1179   // Init alias_type map.
1180   if (!_do_escape_analysis &amp;&amp; aliaslevel == 3)
1181     aliaslevel = 2;  // No unique types without escape analysis
1182   _AliasLevel = aliaslevel;
1183   const int grow_ats = 16;
1184   _max_alias_types = grow_ats;
1185   _alias_types   = NEW_ARENA_ARRAY(comp_arena(), AliasType*, grow_ats);
1186   AliasType* ats = NEW_ARENA_ARRAY(comp_arena(), AliasType,  grow_ats);
1187   Copy::zero_to_bytes(ats, sizeof(AliasType)*grow_ats);
</pre>
<hr />
<pre>
1449     }
1450   } else if( ta &amp;&amp; _AliasLevel &gt;= 2 ) {
1451     // For arrays indexed by constant indices, we flatten the alias
1452     // space to include all of the array body.  Only the header, klass
1453     // and array length can be accessed un-aliased.
1454     if( offset != Type::OffsetBot ) {
1455       if( ta-&gt;const_oop() ) { // MethodData* or Method*
1456         offset = Type::OffsetBot;   // Flatten constant access into array body
1457         tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),ta-&gt;ary(),ta-&gt;klass(),false,offset);
1458       } else if( offset == arrayOopDesc::length_offset_in_bytes() ) {
1459         // range is OK as-is.
1460         tj = ta = TypeAryPtr::RANGE;
1461       } else if( offset == oopDesc::klass_offset_in_bytes() ) {
1462         tj = TypeInstPtr::KLASS; // all klass loads look alike
1463         ta = TypeAryPtr::RANGE; // generic ignored junk
1464         ptr = TypePtr::BotPTR;
1465       } else if( offset == oopDesc::mark_offset_in_bytes() ) {
1466         tj = TypeInstPtr::MARK;
1467         ta = TypeAryPtr::RANGE; // generic ignored junk
1468         ptr = TypePtr::BotPTR;
<span class="line-removed">1469       } else if (BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;flatten_gc_alias_type(tj)) {</span>
<span class="line-removed">1470         ta = tj-&gt;isa_aryptr();</span>
1471       } else {                  // Random constant offset into array body
1472         offset = Type::OffsetBot;   // Flatten constant access into array body
1473         tj = ta = TypeAryPtr::make(ptr,ta-&gt;ary(),ta-&gt;klass(),false,offset);
1474       }
1475     }
1476     // Arrays of fixed size alias with arrays of unknown size.
1477     if (ta-&gt;size() != TypeInt::POS) {
1478       const TypeAry *tary = TypeAry::make(ta-&gt;elem(), TypeInt::POS);
1479       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,ta-&gt;klass(),false,offset);
1480     }
1481     // Arrays of known objects become arrays of unknown objects.
1482     if (ta-&gt;elem()-&gt;isa_narrowoop() &amp;&amp; ta-&gt;elem() != TypeNarrowOop::BOTTOM) {
1483       const TypeAry *tary = TypeAry::make(TypeNarrowOop::BOTTOM, ta-&gt;size());
1484       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,offset);
1485     }
1486     if (ta-&gt;elem()-&gt;isa_oopptr() &amp;&amp; ta-&gt;elem() != TypeInstPtr::BOTTOM) {
1487       const TypeAry *tary = TypeAry::make(TypeInstPtr::BOTTOM, ta-&gt;size());
1488       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,offset);
1489     }
1490     // Arrays of bytes and of booleans both use &#39;bastore&#39; and &#39;baload&#39; so
</pre>
<hr />
<pre>
1515         tj = to = TypeInstPtr::make(TypePtr::BotPTR,to-&gt;klass(),false,0,offset);
1516       }
1517     } else if( is_known_inst ) {
1518       tj = to; // Keep NotNull and klass_is_exact for instance type
1519     } else if( ptr == TypePtr::NotNull || to-&gt;klass_is_exact() ) {
1520       // During the 2nd round of IterGVN, NotNull castings are removed.
1521       // Make sure the Bottom and NotNull variants alias the same.
1522       // Also, make sure exact and non-exact variants alias the same.
1523       tj = to = TypeInstPtr::make(TypePtr::BotPTR,to-&gt;klass(),false,0,offset);
1524     }
1525     if (to-&gt;speculative() != NULL) {
1526       tj = to = TypeInstPtr::make(to-&gt;ptr(),to-&gt;klass(),to-&gt;klass_is_exact(),to-&gt;const_oop(),to-&gt;offset(), to-&gt;instance_id());
1527     }
1528     // Canonicalize the holder of this field
1529     if (offset &gt;= 0 &amp;&amp; offset &lt; instanceOopDesc::base_offset_in_bytes()) {
1530       // First handle header references such as a LoadKlassNode, even if the
1531       // object&#39;s klass is unloaded at compile time (4965979).
1532       if (!is_known_inst) { // Do it only for non-instance types
1533         tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()-&gt;Object_klass(), false, NULL, offset);
1534       }
<span class="line-removed">1535     } else if (BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;flatten_gc_alias_type(tj)) {</span>
<span class="line-removed">1536       to = tj-&gt;is_instptr();</span>
1537     } else if (offset &lt; 0 || offset &gt;= k-&gt;size_helper() * wordSize) {
1538       // Static fields are in the space above the normal instance
1539       // fields in the java.lang.Class instance.
1540       if (to-&gt;klass() != ciEnv::current()-&gt;Class_klass()) {
1541         to = NULL;
1542         tj = TypeOopPtr::BOTTOM;
1543         offset = tj-&gt;offset();
1544       }
1545     } else {
1546       ciInstanceKlass *canonical_holder = k-&gt;get_canonical_holder(offset);
1547       if (!k-&gt;equals(canonical_holder) || tj-&gt;offset() != offset) {
1548         if( is_known_inst ) {
1549           tj = to = TypeInstPtr::make(to-&gt;ptr(), canonical_holder, true, NULL, offset, to-&gt;instance_id());
1550         } else {
1551           tj = to = TypeInstPtr::make(to-&gt;ptr(), canonical_holder, false, NULL, offset);
1552         }
1553       }
1554     }
1555   }
1556 
</pre>
<hr />
<pre>
1615     case Type::AnyPtr:   tj = TypePtr::BOTTOM;      break;  // caller checks it
1616     default: ShouldNotReachHere();
1617     }
1618     break;
1619   case 2:                       // No collapsing at level 2; keep all splits
1620   case 3:                       // No collapsing at level 3; keep all splits
1621     break;
1622   default:
1623     Unimplemented();
1624   }
1625 
1626   offset = tj-&gt;offset();
1627   assert( offset != Type::OffsetTop, &quot;Offset has fallen from constant&quot; );
1628 
1629   assert( (offset != Type::OffsetBot &amp;&amp; tj-&gt;base() != Type::AryPtr) ||
1630           (offset == Type::OffsetBot &amp;&amp; tj-&gt;base() == Type::AryPtr) ||
1631           (offset == Type::OffsetBot &amp;&amp; tj == TypeOopPtr::BOTTOM) ||
1632           (offset == Type::OffsetBot &amp;&amp; tj == TypePtr::BOTTOM) ||
1633           (offset == oopDesc::mark_offset_in_bytes() &amp;&amp; tj-&gt;base() == Type::AryPtr) ||
1634           (offset == oopDesc::klass_offset_in_bytes() &amp;&amp; tj-&gt;base() == Type::AryPtr) ||
<span class="line-modified">1635           (offset == arrayOopDesc::length_offset_in_bytes() &amp;&amp; tj-&gt;base() == Type::AryPtr) ||</span>
<span class="line-removed">1636           (BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;verify_gc_alias_type(tj, offset)),</span>
1637           &quot;For oops, klasses, raw offset must be constant; for arrays the offset is never known&quot; );
1638   assert( tj-&gt;ptr() != TypePtr::TopPTR &amp;&amp;
1639           tj-&gt;ptr() != TypePtr::AnyNull &amp;&amp;
1640           tj-&gt;ptr() != TypePtr::Null, &quot;No imprecise addresses&quot; );
1641 //    assert( tj-&gt;ptr() != TypePtr::Constant ||
1642 //            tj-&gt;base() == Type::RawPtr ||
1643 //            tj-&gt;base() == Type::KlassPtr, &quot;No constant oop addresses&quot; );
1644 
1645   return tj;
1646 }
1647 
1648 void Compile::AliasType::Init(int i, const TypePtr* at) {

1649   _index = i;
1650   _adr_type = at;
1651   _field = NULL;
1652   _element = NULL;
1653   _is_rewritable = true; // default
1654   const TypeOopPtr *atoop = (at != NULL) ? at-&gt;isa_oopptr() : NULL;
1655   if (atoop != NULL &amp;&amp; atoop-&gt;is_known_instance()) {
1656     const TypeOopPtr *gt = atoop-&gt;cast_to_instance_id(TypeOopPtr::InstanceBot);
1657     _general_index = Compile::current()-&gt;get_alias_index(gt);
1658   } else {
1659     _general_index = 0;
1660   }
1661 }
1662 
1663 BasicType Compile::AliasType::basic_type() const {
1664   if (element() != NULL) {
1665     const Type* element = adr_type()-&gt;is_aryptr()-&gt;elem();
1666     return element-&gt;isa_narrowoop() ? T_OBJECT : element-&gt;array_element_basic_type();
1667   } if (field() != NULL) {
1668     return field()-&gt;layout_type();
</pre>
<hr />
<pre>
2169   return true;
2170 }
2171 
2172 // Remove edges from &quot;root&quot; to each SafePoint at a backward branch.
2173 // They were inserted during parsing (see add_safepoint()) to make
2174 // infinite loops without calls or exceptions visible to root, i.e.,
2175 // useful.
2176 void Compile::remove_root_to_sfpts_edges(PhaseIterGVN&amp; igvn) {
2177   Node *r = root();
2178   if (r != NULL) {
2179     for (uint i = r-&gt;req(); i &lt; r-&gt;len(); ++i) {
2180       Node *n = r-&gt;in(i);
2181       if (n != NULL &amp;&amp; n-&gt;is_SafePoint()) {
2182         r-&gt;rm_prec(i);
2183         if (n-&gt;outcnt() == 0) {
2184           igvn.remove_dead_node(n);
2185         }
2186         --i;
2187       }
2188     }





2189   }
2190 }
2191 
2192 //------------------------------Optimize---------------------------------------
2193 // Given a graph, optimize it.
2194 void Compile::Optimize() {
2195   TracePhase tp(&quot;optimizer&quot;, &amp;timers[_t_optimizer]);
2196 
2197 #ifndef PRODUCT
2198   if (_directive-&gt;BreakAtCompileOption) {
2199     BREAKPOINT;
2200   }
2201 
2202 #endif
2203 
<span class="line-removed">2204 #ifdef ASSERT</span>
2205   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();

2206   bs-&gt;verify_gc_barriers(this, BarrierSetC2::BeforeOptimize);
2207 #endif
2208 
2209   ResourceMark rm;
2210 
2211   print_inlining_reinit();
2212 
2213   NOT_PRODUCT( verify_graph_edges(); )
2214 
2215   print_method(PHASE_AFTER_PARSING);
2216 
2217  {
2218   // Iterative Global Value Numbering, including ideal transforms
2219   // Initialize IterGVN with types and values from parse-time GVN
2220   PhaseIterGVN igvn(initial_gvn());
2221 #ifdef ASSERT
2222   _modified_nodes = new (comp_arena()) Unique_Node_List(comp_arena());
2223 #endif
2224   {
2225     TracePhase tp(&quot;iterGVN&quot;, &amp;timers[_t_iterGVN]);
</pre>
<hr />
<pre>
2265 
2266   if (!failing() &amp;&amp; RenumberLiveNodes &amp;&amp; live_nodes() + NodeLimitFudgeFactor &lt; unique()) {
2267     Compile::TracePhase tp(&quot;&quot;, &amp;timers[_t_renumberLive]);
2268     initial_gvn()-&gt;replace_with(&amp;igvn);
2269     for_igvn()-&gt;clear();
2270     Unique_Node_List new_worklist(C-&gt;comp_arena());
2271     {
2272       ResourceMark rm;
2273       PhaseRenumberLive prl = PhaseRenumberLive(initial_gvn(), for_igvn(), &amp;new_worklist);
2274     }
2275     set_for_igvn(&amp;new_worklist);
2276     igvn = PhaseIterGVN(initial_gvn());
2277     igvn.optimize();
2278   }
2279 
2280   // Perform escape analysis
2281   if (_do_escape_analysis &amp;&amp; ConnectionGraph::has_candidates(this)) {
2282     if (has_loops()) {
2283       // Cleanup graph (remove dead nodes).
2284       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
<span class="line-modified">2285       PhaseIdealLoop::optimize(igvn, LoopOptsNone);</span>
2286       if (major_progress()) print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);
2287       if (failing())  return;
2288     }
2289     ConnectionGraph::do_analysis(this, &amp;igvn);
2290 
2291     if (failing())  return;
2292 
2293     // Optimize out fields loads from scalar replaceable allocations.
2294     igvn.optimize();
2295     print_method(PHASE_ITER_GVN_AFTER_EA, 2);
2296 
2297     if (failing())  return;
2298 
2299     if (congraph() != NULL &amp;&amp; macro_count() &gt; 0) {
2300       TracePhase tp(&quot;macroEliminate&quot;, &amp;timers[_t_macroEliminate]);
2301       PhaseMacroExpand mexp(igvn);
2302       mexp.eliminate_macro_nodes();
2303       igvn.set_delay_transform(false);
2304 
2305       igvn.optimize();
</pre>
<hr />
<pre>
2344   }
2345   if (failing())  return;
2346 
2347   // Conditional Constant Propagation;
2348   PhaseCCP ccp( &amp;igvn );
2349   assert( true, &quot;Break here to ccp.dump_nodes_and_types(_root,999,1)&quot;);
2350   {
2351     TracePhase tp(&quot;ccp&quot;, &amp;timers[_t_ccp]);
2352     ccp.do_transform();
2353   }
2354   print_method(PHASE_CPP1, 2);
2355 
2356   assert( true, &quot;Break here to ccp.dump_old2new_map()&quot;);
2357 
2358   // Iterative Global Value Numbering, including ideal transforms
2359   {
2360     TracePhase tp(&quot;iterGVN2&quot;, &amp;timers[_t_iterGVN2]);
2361     igvn = ccp;
2362     igvn.optimize();
2363   }
<span class="line-removed">2364 </span>
2365   print_method(PHASE_ITER_GVN2, 2);
2366 
2367   if (failing())  return;
2368 
2369   // Loop transforms on the ideal graph.  Range Check Elimination,
2370   // peeling, unrolling, etc.
2371   if (!optimize_loops(igvn, LoopOptsDefault)) {
2372     return;
2373   }
2374 
<span class="line-removed">2375 #if INCLUDE_ZGC</span>
<span class="line-removed">2376   if (UseZGC) {</span>
<span class="line-removed">2377     ZBarrierSetC2::find_dominating_barriers(igvn);</span>
<span class="line-removed">2378   }</span>
<span class="line-removed">2379 #endif</span>
<span class="line-removed">2380 </span>
2381   if (failing())  return;
2382 
2383   // Ensure that major progress is now clear
2384   C-&gt;clear_major_progress();
2385 
2386   {
2387     // Verify that all previous optimizations produced a valid graph
2388     // at least to this point, even if no loop optimizations were done.
2389     TracePhase tp(&quot;idealLoopVerify&quot;, &amp;timers[_t_idealLoopVerify]);
2390     PhaseIdealLoop::verify(igvn);
2391   }
2392 
2393   if (range_check_cast_count() &gt; 0) {
2394     // No more loop optimizations. Remove all range check dependent CastIINodes.
2395     C-&gt;remove_range_check_casts(igvn);
2396     igvn.optimize();
2397   }
2398 
2399 #ifdef ASSERT
<span class="line-modified">2400   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();</span>
<span class="line-removed">2401   bs-&gt;verify_gc_barriers(this, BarrierSetC2::BeforeExpand);</span>
2402 #endif
2403 
2404   {
2405     TracePhase tp(&quot;macroExpand&quot;, &amp;timers[_t_macroExpand]);
2406     PhaseMacroExpand  mex(igvn);
<span class="line-removed">2407     print_method(PHASE_BEFORE_MACRO_EXPANSION, 2);</span>
2408     if (mex.expand_macro_nodes()) {
2409       assert(failing(), &quot;must bail out w/ explicit message&quot;);
2410       return;
2411     }

2412   }
2413 
2414   {
2415     TracePhase tp(&quot;barrierExpand&quot;, &amp;timers[_t_barrierExpand]);
<span class="line-removed">2416     print_method(PHASE_BEFORE_BARRIER_EXPAND, 2);</span>
<span class="line-removed">2417     BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();</span>
2418     if (bs-&gt;expand_barriers(this, igvn)) {
2419       assert(failing(), &quot;must bail out w/ explicit message&quot;);
2420       return;
2421     }

2422   }
2423 
2424   if (opaque4_count() &gt; 0) {
2425     C-&gt;remove_opaque4_nodes(igvn);
2426     igvn.optimize();
2427   }
2428 
2429   DEBUG_ONLY( _modified_nodes = NULL; )
2430  } // (End scope of igvn; run destructor if necessary for asserts.)
2431 
2432  process_print_inlining();
2433  // A method with only infinite loops has no edges entering loops from root
2434  {
2435    TracePhase tp(&quot;graphReshape&quot;, &amp;timers[_t_graphReshaping]);
2436    if (final_graph_reshaping()) {
2437      assert(failing(), &quot;must bail out w/ explicit message&quot;);
2438      return;
2439    }
2440  }
2441 
</pre>
<hr />
<pre>
2448 void Compile::Code_Gen() {
2449   if (failing()) {
2450     return;
2451   }
2452 
2453   // Perform instruction selection.  You might think we could reclaim Matcher
2454   // memory PDQ, but actually the Matcher is used in generating spill code.
2455   // Internals of the Matcher (including some VectorSets) must remain live
2456   // for awhile - thus I cannot reclaim Matcher memory lest a VectorSet usage
2457   // set a bit in reclaimed memory.
2458 
2459   // In debug mode can dump m._nodes.dump() for mapping of ideal to machine
2460   // nodes.  Mapping is only valid at the root of each matched subtree.
2461   NOT_PRODUCT( verify_graph_edges(); )
2462 
2463   Matcher matcher;
2464   _matcher = &amp;matcher;
2465   {
2466     TracePhase tp(&quot;matcher&quot;, &amp;timers[_t_matcher]);
2467     matcher.match();



2468   }

2469   // In debug mode can dump m._nodes.dump() for mapping of ideal to machine
2470   // nodes.  Mapping is only valid at the root of each matched subtree.
2471   NOT_PRODUCT( verify_graph_edges(); )
2472 
2473   // If you have too many nodes, or if matching has failed, bail out
2474   check_node_count(0, &quot;out of nodes matching instructions&quot;);
2475   if (failing()) {
2476     return;
2477   }
2478 
2479   print_method(PHASE_MATCHING, 2);
2480 
2481   // Build a proper-looking CFG
2482   PhaseCFG cfg(node_arena(), root(), matcher);
2483   _cfg = &amp;cfg;
2484   {
2485     TracePhase tp(&quot;scheduler&quot;, &amp;timers[_t_scheduler]);
2486     bool success = cfg.do_global_code_motion();
2487     if (!success) {
2488       return;
</pre>
<hr />
<pre>
2535     TracePhase tp(&quot;postalloc_expand&quot;, &amp;timers[_t_postalloc_expand]);
2536     cfg.postalloc_expand(_regalloc);
2537   }
2538 
2539   // Convert Nodes to instruction bits in a buffer
2540   {
2541     TraceTime tp(&quot;output&quot;, &amp;timers[_t_output], CITime);
2542     Output();
2543   }
2544 
2545   print_method(PHASE_FINAL_CODE);
2546 
2547   // He&#39;s dead, Jim.
2548   _cfg     = (PhaseCFG*)((intptr_t)0xdeadbeef);
2549   _regalloc = (PhaseChaitin*)((intptr_t)0xdeadbeef);
2550 }
2551 
2552 
2553 //------------------------------dump_asm---------------------------------------
2554 // Dump formatted assembly
<span class="line-modified">2555 #ifndef PRODUCT</span>
<span class="line-modified">2556 void Compile::dump_asm(int *pcs, uint pc_limit) {</span>













2557   bool cut_short = false;
<span class="line-modified">2558   tty-&gt;print_cr(&quot;#&quot;);</span>
<span class="line-modified">2559   tty-&gt;print(&quot;#  &quot;);  _tf-&gt;dump();  tty-&gt;cr();</span>
<span class="line-modified">2560   tty-&gt;print_cr(&quot;#&quot;);</span>
2561 
2562   // For all blocks
2563   int pc = 0x0;                 // Program counter
2564   char starts_bundle = &#39; &#39;;
2565   _regalloc-&gt;dump_frame();
2566 
2567   Node *n = NULL;
2568   for (uint i = 0; i &lt; _cfg-&gt;number_of_blocks(); i++) {
2569     if (VMThread::should_terminate()) {
2570       cut_short = true;
2571       break;
2572     }
2573     Block* block = _cfg-&gt;get_block(i);
2574     if (block-&gt;is_connector() &amp;&amp; !Verbose) {
2575       continue;
2576     }
2577     n = block-&gt;head();
<span class="line-modified">2578     if (pcs &amp;&amp; n-&gt;_idx &lt; pc_limit) {</span>
<span class="line-modified">2579       tty-&gt;print(&quot;%3.3x   &quot;, pcs[n-&gt;_idx]);</span>
<span class="line-modified">2580     } else {</span>
<span class="line-removed">2581       tty-&gt;print(&quot;      &quot;);</span>
2582     }
<span class="line-modified">2583     block-&gt;dump_head(_cfg);</span>

2584     if (block-&gt;is_connector()) {
<span class="line-modified">2585       tty-&gt;print_cr(&quot;        # Empty connector block&quot;);</span>

2586     } else if (block-&gt;num_preds() == 2 &amp;&amp; block-&gt;pred(1)-&gt;is_CatchProj() &amp;&amp; block-&gt;pred(1)-&gt;as_CatchProj()-&gt;_con == CatchProjNode::fall_through_index) {
<span class="line-modified">2587       tty-&gt;print_cr(&quot;        # Block is sole successor of call&quot;);</span>

2588     }
2589 
2590     // For all instructions
2591     Node *delay = NULL;
2592     for (uint j = 0; j &lt; block-&gt;number_of_nodes(); j++) {
2593       if (VMThread::should_terminate()) {
2594         cut_short = true;
2595         break;
2596       }
2597       n = block-&gt;get_node(j);
2598       if (valid_bundle_info(n)) {
2599         Bundle* bundle = node_bundling(n);
2600         if (bundle-&gt;used_in_unconditional_delay()) {
2601           delay = n;
2602           continue;
2603         }
2604         if (bundle-&gt;starts_bundle()) {
2605           starts_bundle = &#39;+&#39;;
2606         }
2607       }
2608 
2609       if (WizardMode) {
2610         n-&gt;dump();
2611       }
2612 
2613       if( !n-&gt;is_Region() &amp;&amp;    // Dont print in the Assembly
2614           !n-&gt;is_Phi() &amp;&amp;       // a few noisely useless nodes
2615           !n-&gt;is_Proj() &amp;&amp;
2616           !n-&gt;is_MachTemp() &amp;&amp;
2617           !n-&gt;is_SafePointScalarObject() &amp;&amp;
2618           !n-&gt;is_Catch() &amp;&amp;     // Would be nice to print exception table targets
2619           !n-&gt;is_MergeMem() &amp;&amp;  // Not very interesting
2620           !n-&gt;is_top() &amp;&amp;       // Debug info table constants
2621           !(n-&gt;is_Con() &amp;&amp; !n-&gt;is_Mach())// Debug info table constants
2622           ) {
<span class="line-modified">2623         if (pcs &amp;&amp; n-&gt;_idx &lt; pc_limit)</span>
<span class="line-modified">2624           tty-&gt;print(&quot;%3.3x&quot;, pcs[n-&gt;_idx]);</span>
<span class="line-modified">2625         else</span>
<span class="line-modified">2626           tty-&gt;print(&quot;   &quot;);</span>
<span class="line-modified">2627         tty-&gt;print(&quot; %c &quot;, starts_bundle);</span>


2628         starts_bundle = &#39; &#39;;
<span class="line-modified">2629         tty-&gt;print(&quot;\t&quot;);</span>
<span class="line-modified">2630         n-&gt;format(_regalloc, tty);</span>
<span class="line-modified">2631         tty-&gt;cr();</span>
2632       }
2633 
2634       // If we have an instruction with a delay slot, and have seen a delay,
2635       // then back up and print it
2636       if (valid_bundle_info(n) &amp;&amp; node_bundling(n)-&gt;use_unconditional_delay()) {
<span class="line-modified">2637         assert(delay != NULL, &quot;no unconditional delay instruction&quot;);</span>

2638         if (WizardMode) delay-&gt;dump();
2639 
2640         if (node_bundling(delay)-&gt;starts_bundle())
2641           starts_bundle = &#39;+&#39;;
<span class="line-modified">2642         if (pcs &amp;&amp; n-&gt;_idx &lt; pc_limit)</span>
<span class="line-modified">2643           tty-&gt;print(&quot;%3.3x&quot;, pcs[n-&gt;_idx]);</span>
<span class="line-modified">2644         else</span>
<span class="line-modified">2645           tty-&gt;print(&quot;   &quot;);</span>
<span class="line-modified">2646         tty-&gt;print(&quot; %c &quot;, starts_bundle);</span>


2647         starts_bundle = &#39; &#39;;
<span class="line-modified">2648         tty-&gt;print(&quot;\t&quot;);</span>
<span class="line-modified">2649         delay-&gt;format(_regalloc, tty);</span>
<span class="line-modified">2650         tty-&gt;cr();</span>
2651         delay = NULL;
2652       }
2653 
2654       // Dump the exception table as well
2655       if( n-&gt;is_Catch() &amp;&amp; (Verbose || WizardMode) ) {
2656         // Print the exception table for this offset
2657         _handler_table.print_subtable_for(pc);
2658       }

2659     }
<span class="line-modified">2660 </span>
<span class="line-removed">2661     if (pcs &amp;&amp; n-&gt;_idx &lt; pc_limit)</span>
<span class="line-removed">2662       tty-&gt;print_cr(&quot;%3.3x&quot;, pcs[n-&gt;_idx]);</span>
<span class="line-removed">2663     else</span>
<span class="line-removed">2664       tty-&gt;cr();</span>
<span class="line-removed">2665 </span>
2666     assert(cut_short || delay == NULL, &quot;no unconditional delay branch&quot;);
<span class="line-removed">2667 </span>
2668   } // End of per-block dump
<span class="line-removed">2669   tty-&gt;cr();</span>
2670 
<span class="line-modified">2671   if (cut_short)  tty-&gt;print_cr(&quot;*** disassembly is cut short ***&quot;);</span>
2672 }
2673 #endif
2674 
2675 //------------------------------Final_Reshape_Counts---------------------------
2676 // This class defines counters to help identify when a method
2677 // may/must be executed using hardware with only 24-bit precision.
2678 struct Final_Reshape_Counts : public StackObj {
2679   int  _call_count;             // count non-inlined &#39;common&#39; calls
2680   int  _float_count;            // count float ops requiring 24-bit precision
2681   int  _double_count;           // count double ops requiring more precision
2682   int  _java_call_count;        // count non-inlined &#39;java&#39; calls
2683   int  _inner_loop_count;       // count loops which need alignment
2684   VectorSet _visited;           // Visitation flags
2685   Node_List _tests;             // Set of IfNodes &amp; PCTableNodes
2686 
2687   Final_Reshape_Counts() :
2688     _call_count(0), _float_count(0), _double_count(0),
2689     _java_call_count(0), _inner_loop_count(0),
2690     _visited( Thread::current()-&gt;resource_area() ) { }
2691 
</pre>
<hr />
<pre>
2783       break;
2784     }
2785     default:
2786       break;
2787     }
2788   }
2789 
2790 #ifdef ASSERT
2791   if( n-&gt;is_Mem() ) {
2792     int alias_idx = get_alias_index(n-&gt;as_Mem()-&gt;adr_type());
2793     assert( n-&gt;in(0) != NULL || alias_idx != Compile::AliasIdxRaw ||
2794             // oop will be recorded in oop map if load crosses safepoint
2795             n-&gt;is_Load() &amp;&amp; (n-&gt;as_Load()-&gt;bottom_type()-&gt;isa_oopptr() ||
2796                              LoadNode::is_immutable_value(n-&gt;in(MemNode::Address))),
2797             &quot;raw memory operations should have control edge&quot;);
2798   }
2799   if (n-&gt;is_MemBar()) {
2800     MemBarNode* mb = n-&gt;as_MemBar();
2801     if (mb-&gt;trailing_store() || mb-&gt;trailing_load_store()) {
2802       assert(mb-&gt;leading_membar()-&gt;trailing_membar() == mb, &quot;bad membar pair&quot;);
<span class="line-modified">2803       Node* mem = mb-&gt;in(MemBarNode::Precedent);</span>
2804       assert((mb-&gt;trailing_store() &amp;&amp; mem-&gt;is_Store() &amp;&amp; mem-&gt;as_Store()-&gt;is_release()) ||
2805              (mb-&gt;trailing_load_store() &amp;&amp; mem-&gt;is_LoadStore()), &quot;missing mem op&quot;);
2806     } else if (mb-&gt;leading()) {
2807       assert(mb-&gt;trailing_membar()-&gt;leading_membar() == mb, &quot;bad membar pair&quot;);
2808     }
2809   }
2810 #endif
2811   // Count FPU ops and common calls, implements item (3)
2812   bool gc_handled = BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;final_graph_reshaping(this, n, nop);
2813   if (!gc_handled) {
2814     final_graph_reshaping_main_switch(n, frc, nop);
2815   }
2816 
2817   // Collect CFG split points
2818   if (n-&gt;is_MultiBranch() &amp;&amp; !n-&gt;is_RangeCheck()) {
2819     frc._tests.push(n);
2820   }
2821 }
2822 
2823 void Compile::final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts&amp; frc, uint nop) {
</pre>
<hr />
<pre>
3053 #endif
3054     // platform dependent reshaping of the address expression
3055     reshape_address(n-&gt;as_AddP());
3056     break;
3057   }
3058 
3059   case Op_CastPP: {
3060     // Remove CastPP nodes to gain more freedom during scheduling but
3061     // keep the dependency they encode as control or precedence edges
3062     // (if control is set already) on memory operations. Some CastPP
3063     // nodes don&#39;t have a control (don&#39;t carry a dependency): skip
3064     // those.
3065     if (n-&gt;in(0) != NULL) {
3066       ResourceMark rm;
3067       Unique_Node_List wq;
3068       wq.push(n);
3069       for (uint next = 0; next &lt; wq.size(); ++next) {
3070         Node *m = wq.at(next);
3071         for (DUIterator_Fast imax, i = m-&gt;fast_outs(imax); i &lt; imax; i++) {
3072           Node* use = m-&gt;fast_out(i);
<span class="line-modified">3073           if (use-&gt;is_Mem() || use-&gt;is_EncodeNarrowPtr() || use-&gt;is_ShenandoahBarrier()) {</span>
3074             use-&gt;ensure_control_or_add_prec(n-&gt;in(0));
3075           } else {
3076             switch(use-&gt;Opcode()) {
3077             case Op_AddP:
3078             case Op_DecodeN:
3079             case Op_DecodeNKlass:
3080             case Op_CheckCastPP:
3081             case Op_CastPP:
3082               wq.push(use);
3083               break;
3084             }
3085           }
3086         }
3087       }
3088     }
3089     const bool is_LP64 = LP64_ONLY(true) NOT_LP64(false);
3090     if (is_LP64 &amp;&amp; n-&gt;in(1)-&gt;is_DecodeN() &amp;&amp; Matcher::gen_narrow_oop_implicit_null_checks()) {
3091       Node* in1 = n-&gt;in(1);
3092       const Type* t = n-&gt;bottom_type();
3093       Node* new_in1 = in1-&gt;clone();
</pre>
<hr />
<pre>
3433           m-&gt;disconnect_inputs(NULL, this);
3434         }
3435       }
3436     }
3437     break;
3438   }
3439   case Op_RangeCheck: {
3440     RangeCheckNode* rc = n-&gt;as_RangeCheck();
3441     Node* iff = new IfNode(rc-&gt;in(0), rc-&gt;in(1), rc-&gt;_prob, rc-&gt;_fcnt);
3442     n-&gt;subsume_by(iff, this);
3443     frc._tests.push(iff);
3444     break;
3445   }
3446   case Op_ConvI2L: {
3447     if (!Matcher::convi2l_type_required) {
3448       // Code generation on some platforms doesn&#39;t need accurate
3449       // ConvI2L types. Widening the type can help remove redundant
3450       // address computations.
3451       n-&gt;as_Type()-&gt;set_type(TypeLong::INT);
3452       ResourceMark rm;
<span class="line-modified">3453       Node_List wq;</span>
3454       wq.push(n);
3455       for (uint next = 0; next &lt; wq.size(); next++) {
3456         Node *m = wq.at(next);
3457 
3458         for(;;) {
3459           // Loop over all nodes with identical inputs edges as m
3460           Node* k = m-&gt;find_similar(m-&gt;Opcode());
3461           if (k == NULL) {
3462             break;
3463           }
3464           // Push their uses so we get a chance to remove node made
3465           // redundant
3466           for (DUIterator_Fast imax, i = k-&gt;fast_outs(imax); i &lt; imax; i++) {
3467             Node* u = k-&gt;fast_out(i);
<span class="line-removed">3468             assert(!wq.contains(u), &quot;shouldn&#39;t process one node several times&quot;);</span>
3469             if (u-&gt;Opcode() == Op_LShiftL ||
3470                 u-&gt;Opcode() == Op_AddL ||
3471                 u-&gt;Opcode() == Op_SubL ||
3472                 u-&gt;Opcode() == Op_AddP) {
3473               wq.push(u);
3474             }
3475           }
3476           // Replace all nodes with identical edges as m with m
3477           k-&gt;subsume_by(m, this);
3478         }
3479       }
3480     }
3481     break;
3482   }
3483   case Op_CmpUL: {
3484     if (!Matcher::has_match_rule(Op_CmpUL)) {
3485       // No support for unsigned long comparisons
3486       ConINode* sign_pos = new ConINode(TypeInt::make(BitsPerLong - 1));
3487       Node* sign_bit_mask = new RShiftLNode(n-&gt;in(1), sign_pos);
3488       Node* orl = new OrLNode(n-&gt;in(1), sign_bit_mask);
</pre>
<hr />
<pre>
3678         return true;            // Not all targets reachable!
3679       }
3680     }
3681     // Check that I actually visited all kids.  Unreached kids
3682     // must be infinite loops.
3683     for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++)
3684       if (!frc._visited.test(n-&gt;fast_out(j)-&gt;_idx)) {
3685         record_method_not_compilable(&quot;infinite loop&quot;);
3686         return true;            // Found unvisited kid; must be unreach
3687       }
3688 
3689     // Here so verification code in final_graph_reshaping_walk()
3690     // always see an OuterStripMinedLoopEnd
3691     if (n-&gt;is_OuterStripMinedLoopEnd()) {
3692       IfNode* init_iff = n-&gt;as_If();
3693       Node* iff = new IfNode(init_iff-&gt;in(0), init_iff-&gt;in(1), init_iff-&gt;_prob, init_iff-&gt;_fcnt);
3694       n-&gt;subsume_by(iff, this);
3695     }
3696   }
3697 

3698   // If original bytecodes contained a mixture of floats and doubles
3699   // check if the optimizer has made it homogenous, item (3).
<span class="line-modified">3700   if( Use24BitFPMode &amp;&amp; Use24BitFP &amp;&amp; UseSSE == 0 &amp;&amp;</span>
3701       frc.get_float_count() &gt; 32 &amp;&amp;
3702       frc.get_double_count() == 0 &amp;&amp;
3703       (10 * frc.get_call_count() &lt; frc.get_float_count()) ) {
<span class="line-modified">3704     set_24_bit_selection_and_mode( false,  true );</span>
3705   }

3706 
3707   set_java_calls(frc.get_java_call_count());
3708   set_inner_loops(frc.get_inner_loop_count());
3709 
3710   // No infinite loops, no reason to bail out.
3711   return false;
3712 }
3713 
3714 //-----------------------------too_many_traps----------------------------------
3715 // Report if there are too many traps at the current method and bci.
3716 // Return true if there was a trap, and/or PerMethodTrapLimit is exceeded.
3717 bool Compile::too_many_traps(ciMethod* method,
3718                              int bci,
3719                              Deoptimization::DeoptReason reason) {
3720   ciMethodData* md = method-&gt;method_data();
3721   if (md-&gt;is_empty()) {
3722     // Assume the trap has not occurred, or that it occurred only
3723     // because of a transient condition during start-up in the interpreter.
3724     return false;
3725   }
</pre>
<hr />
<pre>
3805   } else {
3806     // The coast is clear.
3807     return false;
3808   }
3809 }
3810 
3811 // Compute when not to trap. Used by matching trap based nodes and
3812 // NullCheck optimization.
3813 void Compile::set_allowed_deopt_reasons() {
3814   _allowed_reasons = 0;
3815   if (is_method_compilation()) {
3816     for (int rs = (int)Deoptimization::Reason_none+1; rs &lt; Compile::trapHistLength; rs++) {
3817       assert(rs &lt; BitsPerInt, &quot;recode bit map&quot;);
3818       if (!too_many_traps((Deoptimization::DeoptReason) rs)) {
3819         _allowed_reasons |= nth_bit(rs);
3820       }
3821     }
3822   }
3823 }
3824 
<span class="line-modified">3825 bool Compile::is_compiling_clinit_for(ciKlass* k) {</span>
<span class="line-modified">3826   ciMethod* root = method(); // the root method of compilation</span>
<span class="line-modified">3827   return root-&gt;is_static_initializer() &amp;&amp; root-&gt;holder() == k; // access in the context of clinit</span>

































3828 }
3829 
3830 #ifndef PRODUCT
3831 //------------------------------verify_graph_edges---------------------------
3832 // Walk the Graph and verify that there is a one-to-one correspondence
3833 // between Use-Def edges and Def-Use edges in the graph.
3834 void Compile::verify_graph_edges(bool no_dead_code) {
3835   if (VerifyGraphEdges) {
3836     ResourceArea *area = Thread::current()-&gt;resource_area();
3837     Unique_Node_List visited(area);
3838     // Call recursive graph walk to check edges
3839     _root-&gt;verify_edges(visited);
3840     if (no_dead_code) {
3841       // Now make sure that no visited node is used by an unvisited node.
3842       bool dead_nodes = false;
3843       Unique_Node_List checked(area);
3844       while (visited.size() &gt; 0) {
3845         Node* n = visited.pop();
3846         checked.push(n);
3847         for (uint i = 0; i &lt; n-&gt;outcnt(); i++) {
</pre>
<hr />
<pre>
4169     if (subk-&gt;is_subtype_of(superk)) {
4170       return SSC_always_true;   // (1) false path dead; no dynamic test needed
4171     }
4172     if (!(superelem-&gt;is_klass() &amp;&amp; superelem-&gt;as_klass()-&gt;is_interface()) &amp;&amp;
4173         !superk-&gt;is_subtype_of(subk)) {
4174       return SSC_always_false;
4175     }
4176   }
4177 
4178   // If casting to an instance klass, it must have no subtypes
4179   if (superk-&gt;is_interface()) {
4180     // Cannot trust interfaces yet.
4181     // %%% S.B. superk-&gt;nof_implementors() == 1
4182   } else if (superelem-&gt;is_instance_klass()) {
4183     ciInstanceKlass* ik = superelem-&gt;as_instance_klass();
4184     if (!ik-&gt;has_subklass() &amp;&amp; !ik-&gt;is_interface()) {
4185       if (!ik-&gt;is_final()) {
4186         // Add a dependency if there is a chance of a later subclass.
4187         dependencies()-&gt;assert_leaf_type(ik);
4188       }



4189       return SSC_easy_test;     // (3) caller can do a simple ptr comparison
4190     }
4191   } else {
4192     // A primitive array type has no subtypes.
4193     return SSC_easy_test;       // (3) caller can do a simple ptr comparison
4194   }
4195 
4196   return SSC_full_test;
4197 }
4198 
4199 Node* Compile::conv_I2X_index(PhaseGVN* phase, Node* idx, const TypeInt* sizetype, Node* ctrl) {
4200 #ifdef _LP64
4201   // The scaled index operand to AddP must be a clean 64-bit value.
4202   // Java allows a 32-bit int to be incremented to a negative
4203   // value, which appears in a 64-bit register as a large
4204   // positive number.  Using that large positive number as an
4205   // operand in pointer arithmetic has bad consequences.
4206   // On the other hand, 32-bit overflow is rare, and the possibility
4207   // can often be excluded, if we annotate the ConvI2L node with
4208   // a type assertion that its value is known to be a small positive
</pre>
<hr />
<pre>
4217 }
4218 
4219 // Convert integer value to a narrowed long type dependent on ctrl (for example, a range check)
4220 Node* Compile::constrained_convI2L(PhaseGVN* phase, Node* value, const TypeInt* itype, Node* ctrl) {
4221   if (ctrl != NULL) {
4222     // Express control dependency by a CastII node with a narrow type.
4223     value = new CastIINode(value, itype, false, true /* range check dependency */);
4224     // Make the CastII node dependent on the control input to prevent the narrowed ConvI2L
4225     // node from floating above the range check during loop optimizations. Otherwise, the
4226     // ConvI2L node may be eliminated independently of the range check, causing the data path
4227     // to become TOP while the control path is still there (although it&#39;s unreachable).
4228     value-&gt;set_req(0, ctrl);
4229     // Save CastII node to remove it after loop optimizations.
4230     phase-&gt;C-&gt;add_range_check_cast(value);
4231     value = phase-&gt;transform(value);
4232   }
4233   const TypeLong* ltype = TypeLong::make(itype-&gt;_lo, itype-&gt;_hi, itype-&gt;_widen);
4234   return phase-&gt;transform(new ConvI2LNode(value, ltype));
4235 }
4236 







4237 // The message about the current inlining is accumulated in
4238 // _print_inlining_stream and transfered into the _print_inlining_list
4239 // once we know whether inlining succeeds or not. For regular
4240 // inlining, messages are appended to the buffer pointed by
4241 // _print_inlining_idx in the _print_inlining_list. For late inlining,
4242 // a new buffer is added after _print_inlining_idx in the list. This
4243 // way we can update the inlining message for late inlining call site
4244 // when the inlining is attempted again.
4245 void Compile::print_inlining_init() {
4246   if (print_inlining() || print_intrinsics()) {


4247     _print_inlining_stream = new stringStream();





4248     _print_inlining_list = new (comp_arena())GrowableArray&lt;PrintInliningBuffer&gt;(comp_arena(), 1, 1, PrintInliningBuffer());
4249   }
4250 }
4251 
4252 void Compile::print_inlining_reinit() {
4253   if (print_inlining() || print_intrinsics()) {

4254     // Re allocate buffer when we change ResourceMark
4255     _print_inlining_stream = new stringStream();
4256   }
4257 }
4258 
4259 void Compile::print_inlining_reset() {
4260   _print_inlining_stream-&gt;reset();
4261 }
4262 
4263 void Compile::print_inlining_commit() {
4264   assert(print_inlining() || print_intrinsics(), &quot;PrintInlining off?&quot;);
4265   // Transfer the message from _print_inlining_stream to the current
4266   // _print_inlining_list buffer and clear _print_inlining_stream.
<span class="line-modified">4267   _print_inlining_list-&gt;at(_print_inlining_idx).ss()-&gt;write(_print_inlining_stream-&gt;as_string(), _print_inlining_stream-&gt;size());</span>
4268   print_inlining_reset();
4269 }
4270 
4271 void Compile::print_inlining_push() {
4272   // Add new buffer to the _print_inlining_list at current position
4273   _print_inlining_idx++;
4274   _print_inlining_list-&gt;insert_before(_print_inlining_idx, PrintInliningBuffer());
4275 }
4276 
4277 Compile::PrintInliningBuffer&amp; Compile::print_inlining_current() {
4278   return _print_inlining_list-&gt;at(_print_inlining_idx);
4279 }
4280 
4281 void Compile::print_inlining_update(CallGenerator* cg) {
4282   if (print_inlining() || print_intrinsics()) {
4283     if (!cg-&gt;is_late_inline()) {
4284       if (print_inlining_current().cg() != NULL) {
4285         print_inlining_push();
4286       }
4287       print_inlining_commit();
</pre>
<hr />
<pre>
4328 
4329 void Compile::process_print_inlining() {
4330   bool do_print_inlining = print_inlining() || print_intrinsics();
4331   if (do_print_inlining || log() != NULL) {
4332     // Print inlining message for candidates that we couldn&#39;t inline
4333     // for lack of space
4334     for (int i = 0; i &lt; _late_inlines.length(); i++) {
4335       CallGenerator* cg = _late_inlines.at(i);
4336       if (!cg-&gt;is_mh_late_inline()) {
4337         const char* msg = &quot;live nodes &gt; LiveNodeCountInliningCutoff&quot;;
4338         if (do_print_inlining) {
4339           cg-&gt;print_inlining_late(msg);
4340         }
4341         log_late_inline_failure(cg, msg);
4342       }
4343     }
4344   }
4345   if (do_print_inlining) {
4346     ResourceMark rm;
4347     stringStream ss;

4348     for (int i = 0; i &lt; _print_inlining_list-&gt;length(); i++) {
4349       ss.print(&quot;%s&quot;, _print_inlining_list-&gt;adr_at(i)-&gt;ss()-&gt;as_string());

4350     }





4351     size_t end = ss.size();
4352     _print_inlining_output = NEW_ARENA_ARRAY(comp_arena(), char, end+1);
4353     strncpy(_print_inlining_output, ss.base(), end+1);
4354     _print_inlining_output[end] = 0;
4355   }
4356 }
4357 
4358 void Compile::dump_print_inlining() {
4359   if (_print_inlining_output != NULL) {
4360     tty-&gt;print_raw(_print_inlining_output);
4361   }
4362 }
4363 
4364 void Compile::log_late_inline(CallGenerator* cg) {
4365   if (log() != NULL) {
4366     log()-&gt;head(&quot;late_inline method=&#39;%d&#39;  inline_id=&#39;&quot; JLONG_FORMAT &quot;&#39;&quot;, log()-&gt;identify(cg-&gt;method()),
4367                 cg-&gt;unique_id());
4368     JVMState* p = cg-&gt;call_node()-&gt;jvms();
4369     while (p != NULL) {
4370       log()-&gt;elem(&quot;jvms bci=&#39;%d&#39; method=&#39;%d&#39;&quot;, p-&gt;bci(), log()-&gt;identify(p-&gt;method()));
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
  59 #include &quot;opto/mulnode.hpp&quot;
  60 #include &quot;opto/narrowptrnode.hpp&quot;
  61 #include &quot;opto/node.hpp&quot;
  62 #include &quot;opto/opcodes.hpp&quot;
  63 #include &quot;opto/output.hpp&quot;
  64 #include &quot;opto/parse.hpp&quot;
  65 #include &quot;opto/phaseX.hpp&quot;
  66 #include &quot;opto/rootnode.hpp&quot;
  67 #include &quot;opto/runtime.hpp&quot;
  68 #include &quot;opto/stringopts.hpp&quot;
  69 #include &quot;opto/type.hpp&quot;
  70 #include &quot;opto/vectornode.hpp&quot;
  71 #include &quot;runtime/arguments.hpp&quot;
  72 #include &quot;runtime/sharedRuntime.hpp&quot;
  73 #include &quot;runtime/signature.hpp&quot;
  74 #include &quot;runtime/stubRoutines.hpp&quot;
  75 #include &quot;runtime/timer.hpp&quot;
  76 #include &quot;utilities/align.hpp&quot;
  77 #include &quot;utilities/copy.hpp&quot;
  78 #include &quot;utilities/macros.hpp&quot;



  79 
  80 
  81 // -------------------- Compile::mach_constant_base_node -----------------------
  82 // Constant table base node singleton.
  83 MachConstantBaseNode* Compile::mach_constant_base_node() {
  84   if (_mach_constant_base_node == NULL) {
  85     _mach_constant_base_node = new MachConstantBaseNode();
  86     _mach_constant_base_node-&gt;add_req(C-&gt;root());
  87   }
  88   return _mach_constant_base_node;
  89 }
  90 
  91 
  92 /// Support for intrinsics.
  93 
  94 // Return the index at which m must be inserted (or already exists).
  95 // The sort order is by the address of the ciMethod, with is_virtual as minor key.
  96 class IntrinsicDescPair {
  97  private:
  98   ciMethod* _m;
</pre>
<hr />
<pre>
 321     assert( next &lt; unique(), &quot;Unique useful nodes &lt; total nodes&quot;);
 322     Node *n  = useful.at(next);
 323     uint max = n-&gt;len();
 324     for( uint i = 0; i &lt; max; ++i ) {
 325       Node *m = n-&gt;in(i);
 326       if (not_a_node(m))  continue;
 327       useful.push(m);
 328     }
 329   }
 330 }
 331 
 332 // Update dead_node_list with any missing dead nodes using useful
 333 // list. Consider all non-useful nodes to be useless i.e., dead nodes.
 334 void Compile::update_dead_node_list(Unique_Node_List &amp;useful) {
 335   uint max_idx = unique();
 336   VectorSet&amp; useful_node_set = useful.member_set();
 337 
 338   for (uint node_idx = 0; node_idx &lt; max_idx; node_idx++) {
 339     // If node with index node_idx is not in useful set,
 340     // mark it as dead in dead node list.
<span class="line-modified"> 341     if (!useful_node_set.test(node_idx)) {</span>
 342       record_dead_node(node_idx);
 343     }
 344   }
 345 }
 346 
 347 void Compile::remove_useless_late_inlines(GrowableArray&lt;CallGenerator*&gt;* inlines, Unique_Node_List &amp;useful) {
 348   int shift = 0;
 349   for (int i = 0; i &lt; inlines-&gt;length(); i++) {
 350     CallGenerator* cg = inlines-&gt;at(i);
 351     CallNode* call = cg-&gt;call_node();
 352     if (shift &gt; 0) {
 353       inlines-&gt;at_put(i-shift, cg);
 354     }
 355     if (!useful.member(call)) {
 356       shift++;
 357     }
 358   }
 359   inlines-&gt;trunc_to(inlines-&gt;length()-shift);
 360 }
 361 
</pre>
<hr />
<pre>
 445 //------------------------------CompileWrapper---------------------------------
 446 class CompileWrapper : public StackObj {
 447   Compile *const _compile;
 448  public:
 449   CompileWrapper(Compile* compile);
 450 
 451   ~CompileWrapper();
 452 };
 453 
 454 CompileWrapper::CompileWrapper(Compile* compile) : _compile(compile) {
 455   // the Compile* pointer is stored in the current ciEnv:
 456   ciEnv* env = compile-&gt;env();
 457   assert(env == ciEnv::current(), &quot;must already be a ciEnv active&quot;);
 458   assert(env-&gt;compiler_data() == NULL, &quot;compile already active?&quot;);
 459   env-&gt;set_compiler_data(compile);
 460   assert(compile == Compile::current(), &quot;sanity&quot;);
 461 
 462   compile-&gt;set_type_dict(NULL);
 463   compile-&gt;set_clone_map(new Dict(cmpkey, hashkey, _compile-&gt;comp_arena()));
 464   compile-&gt;clone_map().set_clone_idx(0);

 465   compile-&gt;set_type_last_size(0);
 466   compile-&gt;set_last_tf(NULL, NULL);
 467   compile-&gt;set_indexSet_arena(NULL);
 468   compile-&gt;set_indexSet_free_block_list(NULL);
 469   compile-&gt;init_type_arena();
 470   Type::Initialize(compile);
 471   _compile-&gt;set_scratch_buffer_blob(NULL);
 472   _compile-&gt;begin_method();
 473   _compile-&gt;clone_map().set_debug(_compile-&gt;has_method() &amp;&amp; _compile-&gt;directive()-&gt;CloneMapDebugOption);
 474 }
 475 CompileWrapper::~CompileWrapper() {
 476   _compile-&gt;end_method();
 477   if (_compile-&gt;scratch_buffer_blob() != NULL)
 478     BufferBlob::free(_compile-&gt;scratch_buffer_blob());
 479   _compile-&gt;env()-&gt;set_compiler_data(NULL);
 480 }
 481 
 482 
 483 //----------------------------print_compile_messages---------------------------
 484 void Compile::print_compile_messages() {
</pre>
<hr />
<pre>
 631                 : Phase(Compiler),
 632                   _compile_id(ci_env-&gt;compile_id()),
 633                   _save_argument_registers(false),
 634                   _subsume_loads(subsume_loads),
 635                   _do_escape_analysis(do_escape_analysis),
 636                   _eliminate_boxing(eliminate_boxing),
 637                   _method(target),
 638                   _entry_bci(osr_bci),
 639                   _stub_function(NULL),
 640                   _stub_name(NULL),
 641                   _stub_entry_point(NULL),
 642                   _max_node_limit(MaxNodeLimit),
 643                   _orig_pc_slot(0),
 644                   _orig_pc_slot_offset_in_bytes(0),
 645                   _inlining_progress(false),
 646                   _inlining_incrementally(false),
 647                   _do_cleanup(false),
 648                   _has_reserved_stack_access(target-&gt;has_reserved_stack_access()),
 649 #ifndef PRODUCT
 650                   _trace_opto_output(directive-&gt;TraceOptoOutputOption),
<span class="line-added"> 651                   _print_ideal(directive-&gt;PrintIdealOption),</span>
 652 #endif
 653                   _has_method_handle_invokes(false),
<span class="line-added"> 654                   _clinit_barrier_on_entry(false),</span>
 655                   _comp_arena(mtCompiler),
 656                   _barrier_set_state(BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;create_barrier_state(comp_arena())),
 657                   _env(ci_env),
 658                   _directive(directive),
 659                   _log(ci_env-&gt;log()),
 660                   _failure_reason(NULL),
 661                   _congraph(NULL),
 662 #ifndef PRODUCT
 663                   _printer(IdealGraphPrinter::printer()),
 664 #endif
 665                   _dead_node_list(comp_arena()),
 666                   _dead_node_count(0),
 667                   _node_arena(mtCompiler),
 668                   _old_arena(mtCompiler),
 669                   _mach_constant_base_node(NULL),
 670                   _Compile_types(mtCompiler),
 671                   _initial_gvn(NULL),
 672                   _for_igvn(NULL),
 673                   _warm_calls(NULL),
 674                   _late_inlines(comp_arena(), 2, 0, NULL),
</pre>
<hr />
<pre>
 694 #endif
 695 {
 696   C = this;
 697 #ifndef PRODUCT
 698   if (_printer != NULL) {
 699     _printer-&gt;set_compile(this);
 700   }
 701 #endif
 702   CompileWrapper cw(this);
 703 
 704   if (CITimeVerbose) {
 705     tty-&gt;print(&quot; &quot;);
 706     target-&gt;holder()-&gt;name()-&gt;print();
 707     tty-&gt;print(&quot;.&quot;);
 708     target-&gt;print_short_name();
 709     tty-&gt;print(&quot;  &quot;);
 710   }
 711   TraceTime t1(&quot;Total compilation time&quot;, &amp;_t_totalCompilation, CITime, CITimeVerbose);
 712   TraceTime t2(NULL, &amp;_t_methodCompilation, CITime, false);
 713 
<span class="line-modified"> 714 #if defined(SUPPORT_ASSEMBLY) || defined(SUPPORT_ABSTRACT_ASSEMBLY)</span>
 715   bool print_opto_assembly = directive-&gt;PrintOptoAssemblyOption;
<span class="line-modified"> 716   // We can always print a disassembly, either abstract (hex dump) or</span>
<span class="line-modified"> 717   // with the help of a suitable hsdis library. Thus, we should not</span>
<span class="line-modified"> 718   // couple print_assembly and print_opto_assembly controls.</span>
<span class="line-modified"> 719   // But: always print opto and regular assembly on compile command &#39;print&#39;.</span>
<span class="line-modified"> 720   bool print_assembly = directive-&gt;PrintAssemblyOption;</span>
<span class="line-modified"> 721   set_print_assembly(print_opto_assembly || print_assembly);</span>
<span class="line-modified"> 722 #else</span>
<span class="line-modified"> 723   set_print_assembly(false); // must initialize.</span>
<span class="line-added"> 724 #endif</span>
<span class="line-added"> 725 </span>
<span class="line-added"> 726 #ifndef PRODUCT</span>
 727   set_parsed_irreducible_loop(false);
 728 
 729   if (directive-&gt;ReplayInlineOption) {
 730     _replay_inline_data = ciReplay::load_inline_data(method(), entry_bci(), ci_env-&gt;comp_level());
 731   }
 732 #endif
 733   set_print_inlining(directive-&gt;PrintInliningOption || PrintOptoInlining);
 734   set_print_intrinsics(directive-&gt;PrintIntrinsicsOption);
 735   set_has_irreducible_loop(true); // conservative until build_loop_tree() reset it
 736 
 737   if (ProfileTraps RTM_OPT_ONLY( || UseRTMLocking )) {
 738     // Make sure the method being compiled gets its own MDO,
 739     // so we can at least track the decompile_count().
 740     // Need MDO to record RTM code generation state.
 741     method()-&gt;ensure_method_data();
 742   }
 743 
 744   Init(::AliasLevel);
 745 
 746 
</pre>
<hr />
<pre>
 857     if (successes == 0)  break;
 858   }
 859 
 860   // Drain the list.
 861   Finish_Warm();
 862 #ifndef PRODUCT
 863   if (_printer &amp;&amp; _printer-&gt;should_print(1)) {
 864     _printer-&gt;print_inlining();
 865   }
 866 #endif
 867 
 868   if (failing())  return;
 869   NOT_PRODUCT( verify_graph_edges(); )
 870 
 871   // Now optimize
 872   Optimize();
 873   if (failing())  return;
 874   NOT_PRODUCT( verify_graph_edges(); )
 875 
 876 #ifndef PRODUCT
<span class="line-modified"> 877   if (print_ideal()) {</span>
 878     ttyLocker ttyl;  // keep the following output all in one block
 879     // This output goes directly to the tty, not the compiler log.
 880     // To enable tools to match it up with the compilation activity,
 881     // be sure to tag this tty output with the compile ID.
 882     if (xtty != NULL) {
 883       xtty-&gt;head(&quot;ideal compile_id=&#39;%d&#39;%s&quot;, compile_id(),
 884                  is_osr_compilation()    ? &quot; compile_kind=&#39;osr&#39;&quot; :
 885                  &quot;&quot;);
 886     }
 887     root()-&gt;dump(9999);
 888     if (xtty != NULL) {
 889       xtty-&gt;tail(&quot;ideal&quot;);
 890     }
 891   }
 892 #endif
 893 
 894 #ifdef ASSERT
 895   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 896   bs-&gt;verify_gc_barriers(this, BarrierSetC2::BeforeCodeGen);
 897 #endif
</pre>
<hr />
<pre>
 967                   DirectiveSet* directive)
 968   : Phase(Compiler),
 969     _compile_id(0),
 970     _save_argument_registers(save_arg_registers),
 971     _subsume_loads(true),
 972     _do_escape_analysis(false),
 973     _eliminate_boxing(false),
 974     _method(NULL),
 975     _entry_bci(InvocationEntryBci),
 976     _stub_function(stub_function),
 977     _stub_name(stub_name),
 978     _stub_entry_point(NULL),
 979     _max_node_limit(MaxNodeLimit),
 980     _orig_pc_slot(0),
 981     _orig_pc_slot_offset_in_bytes(0),
 982     _inlining_progress(false),
 983     _inlining_incrementally(false),
 984     _has_reserved_stack_access(false),
 985 #ifndef PRODUCT
 986     _trace_opto_output(directive-&gt;TraceOptoOutputOption),
<span class="line-added"> 987     _print_ideal(directive-&gt;PrintIdealOption),</span>
 988 #endif
 989     _has_method_handle_invokes(false),
<span class="line-added"> 990     _clinit_barrier_on_entry(false),</span>
 991     _comp_arena(mtCompiler),
<span class="line-added"> 992     _barrier_set_state(BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;create_barrier_state(comp_arena())),</span>
 993     _env(ci_env),
 994     _directive(directive),
 995     _log(ci_env-&gt;log()),
 996     _failure_reason(NULL),
 997     _congraph(NULL),
 998 #ifndef PRODUCT
 999     _printer(NULL),
1000 #endif
1001     _dead_node_list(comp_arena()),
1002     _dead_node_count(0),
1003     _node_arena(mtCompiler),
1004     _old_arena(mtCompiler),
1005     _mach_constant_base_node(NULL),
1006     _Compile_types(mtCompiler),
1007     _initial_gvn(NULL),
1008     _for_igvn(NULL),
1009     _warm_calls(NULL),
1010     _number_of_mh_late_inlines(0),
1011     _print_inlining_stream(NULL),
1012     _print_inlining_list(NULL),
</pre>
<hr />
<pre>
1014     _print_inlining_output(NULL),
1015     _replay_inline_data(NULL),
1016     _java_calls(0),
1017     _inner_loops(0),
1018     _interpreter_frame_size(0),
1019     _node_bundling_limit(0),
1020     _node_bundling_base(NULL),
1021     _code_buffer(&quot;Compile::Fill_buffer&quot;),
1022 #ifndef PRODUCT
1023     _in_dump_cnt(0),
1024 #endif
1025     _allowed_reasons(0) {
1026   C = this;
1027 
1028   TraceTime t1(NULL, &amp;_t_totalCompilation, CITime, false);
1029   TraceTime t2(NULL, &amp;_t_stubCompilation, CITime, false);
1030 
1031 #ifndef PRODUCT
1032   set_print_assembly(PrintFrameConverterAssembly);
1033   set_parsed_irreducible_loop(false);
<span class="line-added">1034 #else</span>
<span class="line-added">1035   set_print_assembly(false); // Must initialize.</span>
1036 #endif
1037   set_has_irreducible_loop(false); // no loops
1038 
1039   CompileWrapper cw(this);
1040   Init(/*AliasLevel=*/ 0);
1041   init_tf((*generator)());
1042 
1043   {
1044     // The following is a dummy for the sake of GraphKit::gen_stub
1045     Unique_Node_List for_igvn(comp_arena());
1046     set_for_igvn(&amp;for_igvn);  // not used, but some GraphKit guys push on this
1047     PhaseGVN gvn(Thread::current()-&gt;resource_area(),255);
1048     set_initial_gvn(&amp;gvn);    // not significant, but GraphKit guys use it pervasively
1049     gvn.transform_no_reclaim(top());
1050 
1051     GraphKit kit;
1052     kit.gen_stub(stub_function, stub_name, is_fancy_jump, pass_tls, return_pc);
1053   }
1054 
1055   NOT_PRODUCT( verify_graph_edges(); )
</pre>
<hr />
<pre>
1077                                                       _oop_map_set,
1078                                                       save_arg_registers);
1079       assert(rs != NULL &amp;&amp; rs-&gt;is_runtime_stub(), &quot;sanity check&quot;);
1080 
1081       _stub_entry_point = rs-&gt;entry_point();
1082     }
1083   }
1084 }
1085 
1086 //------------------------------Init-------------------------------------------
1087 // Prepare for a single compilation
1088 void Compile::Init(int aliaslevel) {
1089   _unique  = 0;
1090   _regalloc = NULL;
1091 
1092   _tf      = NULL;  // filled in later
1093   _top     = NULL;  // cached later
1094   _matcher = NULL;  // filled in later
1095   _cfg     = NULL;  // filled in later
1096 
<span class="line-modified">1097   IA32_ONLY( set_24_bit_selection_and_mode(true, false); )</span>
1098 
1099   _node_note_array = NULL;
1100   _default_node_notes = NULL;
1101   DEBUG_ONLY( _modified_nodes = NULL; ) // Used in Optimize()
1102 
1103   _immutable_memory = NULL; // filled in at first inquiry
1104 
1105   // Globally visible Nodes
1106   // First set TOP to NULL to give safe behavior during creation of RootNode
1107   set_cached_top_node(NULL);
1108   set_root(new RootNode());
1109   // Now that you have a Root to point to, create the real TOP
1110   set_cached_top_node( new ConNode(Type::TOP) );
1111   set_recent_alloc(NULL, NULL);
1112 
1113   // Create Debug Information Recorder to record scopes, oopmaps, etc.
1114   env()-&gt;set_oop_recorder(new OopRecorder(env()-&gt;arena()));
1115   env()-&gt;set_debug_info(new DebugInformationRecorder(env()-&gt;oop_recorder()));
1116   env()-&gt;set_dependencies(new Dependencies(env()));
1117 
</pre>
<hr />
<pre>
1154   set_age_code(has_method() &amp;&amp; method()-&gt;profile_aging());
1155   set_rtm_state(NoRTM); // No RTM lock eliding by default
1156   _max_node_limit = _directive-&gt;MaxNodeLimitOption;
1157 
1158 #if INCLUDE_RTM_OPT
1159   if (UseRTMLocking &amp;&amp; has_method() &amp;&amp; (method()-&gt;method_data_or_null() != NULL)) {
1160     int rtm_state = method()-&gt;method_data()-&gt;rtm_state();
1161     if (method_has_option(&quot;NoRTMLockEliding&quot;) || ((rtm_state &amp; NoRTM) != 0)) {
1162       // Don&#39;t generate RTM lock eliding code.
1163       set_rtm_state(NoRTM);
1164     } else if (method_has_option(&quot;UseRTMLockEliding&quot;) || ((rtm_state &amp; UseRTM) != 0) || !UseRTMDeopt) {
1165       // Generate RTM lock eliding code without abort ratio calculation code.
1166       set_rtm_state(UseRTM);
1167     } else if (UseRTMDeopt) {
1168       // Generate RTM lock eliding code and include abort ratio calculation
1169       // code if UseRTMDeopt is on.
1170       set_rtm_state(ProfileRTM);
1171     }
1172   }
1173 #endif
<span class="line-added">1174   if (VM_Version::supports_fast_class_init_checks() &amp;&amp; has_method() &amp;&amp; !is_osr_compilation() &amp;&amp; method()-&gt;needs_clinit_barrier()) {</span>
<span class="line-added">1175     set_clinit_barrier_on_entry(true);</span>
<span class="line-added">1176   }</span>
1177   if (debug_info()-&gt;recording_non_safepoints()) {
1178     set_node_note_array(new(comp_arena()) GrowableArray&lt;Node_Notes*&gt;
1179                         (comp_arena(), 8, 0, NULL));
1180     set_default_node_notes(Node_Notes::make(this));
1181   }
1182 
1183   // // -- Initialize types before each compile --
1184   // // Update cached type information
1185   // if( _method &amp;&amp; _method-&gt;constants() )
1186   //   Type::update_loaded_types(_method, _method-&gt;constants());
1187 
1188   // Init alias_type map.
1189   if (!_do_escape_analysis &amp;&amp; aliaslevel == 3)
1190     aliaslevel = 2;  // No unique types without escape analysis
1191   _AliasLevel = aliaslevel;
1192   const int grow_ats = 16;
1193   _max_alias_types = grow_ats;
1194   _alias_types   = NEW_ARENA_ARRAY(comp_arena(), AliasType*, grow_ats);
1195   AliasType* ats = NEW_ARENA_ARRAY(comp_arena(), AliasType,  grow_ats);
1196   Copy::zero_to_bytes(ats, sizeof(AliasType)*grow_ats);
</pre>
<hr />
<pre>
1458     }
1459   } else if( ta &amp;&amp; _AliasLevel &gt;= 2 ) {
1460     // For arrays indexed by constant indices, we flatten the alias
1461     // space to include all of the array body.  Only the header, klass
1462     // and array length can be accessed un-aliased.
1463     if( offset != Type::OffsetBot ) {
1464       if( ta-&gt;const_oop() ) { // MethodData* or Method*
1465         offset = Type::OffsetBot;   // Flatten constant access into array body
1466         tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),ta-&gt;ary(),ta-&gt;klass(),false,offset);
1467       } else if( offset == arrayOopDesc::length_offset_in_bytes() ) {
1468         // range is OK as-is.
1469         tj = ta = TypeAryPtr::RANGE;
1470       } else if( offset == oopDesc::klass_offset_in_bytes() ) {
1471         tj = TypeInstPtr::KLASS; // all klass loads look alike
1472         ta = TypeAryPtr::RANGE; // generic ignored junk
1473         ptr = TypePtr::BotPTR;
1474       } else if( offset == oopDesc::mark_offset_in_bytes() ) {
1475         tj = TypeInstPtr::MARK;
1476         ta = TypeAryPtr::RANGE; // generic ignored junk
1477         ptr = TypePtr::BotPTR;


1478       } else {                  // Random constant offset into array body
1479         offset = Type::OffsetBot;   // Flatten constant access into array body
1480         tj = ta = TypeAryPtr::make(ptr,ta-&gt;ary(),ta-&gt;klass(),false,offset);
1481       }
1482     }
1483     // Arrays of fixed size alias with arrays of unknown size.
1484     if (ta-&gt;size() != TypeInt::POS) {
1485       const TypeAry *tary = TypeAry::make(ta-&gt;elem(), TypeInt::POS);
1486       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,ta-&gt;klass(),false,offset);
1487     }
1488     // Arrays of known objects become arrays of unknown objects.
1489     if (ta-&gt;elem()-&gt;isa_narrowoop() &amp;&amp; ta-&gt;elem() != TypeNarrowOop::BOTTOM) {
1490       const TypeAry *tary = TypeAry::make(TypeNarrowOop::BOTTOM, ta-&gt;size());
1491       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,offset);
1492     }
1493     if (ta-&gt;elem()-&gt;isa_oopptr() &amp;&amp; ta-&gt;elem() != TypeInstPtr::BOTTOM) {
1494       const TypeAry *tary = TypeAry::make(TypeInstPtr::BOTTOM, ta-&gt;size());
1495       tj = ta = TypeAryPtr::make(ptr,ta-&gt;const_oop(),tary,NULL,false,offset);
1496     }
1497     // Arrays of bytes and of booleans both use &#39;bastore&#39; and &#39;baload&#39; so
</pre>
<hr />
<pre>
1522         tj = to = TypeInstPtr::make(TypePtr::BotPTR,to-&gt;klass(),false,0,offset);
1523       }
1524     } else if( is_known_inst ) {
1525       tj = to; // Keep NotNull and klass_is_exact for instance type
1526     } else if( ptr == TypePtr::NotNull || to-&gt;klass_is_exact() ) {
1527       // During the 2nd round of IterGVN, NotNull castings are removed.
1528       // Make sure the Bottom and NotNull variants alias the same.
1529       // Also, make sure exact and non-exact variants alias the same.
1530       tj = to = TypeInstPtr::make(TypePtr::BotPTR,to-&gt;klass(),false,0,offset);
1531     }
1532     if (to-&gt;speculative() != NULL) {
1533       tj = to = TypeInstPtr::make(to-&gt;ptr(),to-&gt;klass(),to-&gt;klass_is_exact(),to-&gt;const_oop(),to-&gt;offset(), to-&gt;instance_id());
1534     }
1535     // Canonicalize the holder of this field
1536     if (offset &gt;= 0 &amp;&amp; offset &lt; instanceOopDesc::base_offset_in_bytes()) {
1537       // First handle header references such as a LoadKlassNode, even if the
1538       // object&#39;s klass is unloaded at compile time (4965979).
1539       if (!is_known_inst) { // Do it only for non-instance types
1540         tj = to = TypeInstPtr::make(TypePtr::BotPTR, env()-&gt;Object_klass(), false, NULL, offset);
1541       }


1542     } else if (offset &lt; 0 || offset &gt;= k-&gt;size_helper() * wordSize) {
1543       // Static fields are in the space above the normal instance
1544       // fields in the java.lang.Class instance.
1545       if (to-&gt;klass() != ciEnv::current()-&gt;Class_klass()) {
1546         to = NULL;
1547         tj = TypeOopPtr::BOTTOM;
1548         offset = tj-&gt;offset();
1549       }
1550     } else {
1551       ciInstanceKlass *canonical_holder = k-&gt;get_canonical_holder(offset);
1552       if (!k-&gt;equals(canonical_holder) || tj-&gt;offset() != offset) {
1553         if( is_known_inst ) {
1554           tj = to = TypeInstPtr::make(to-&gt;ptr(), canonical_holder, true, NULL, offset, to-&gt;instance_id());
1555         } else {
1556           tj = to = TypeInstPtr::make(to-&gt;ptr(), canonical_holder, false, NULL, offset);
1557         }
1558       }
1559     }
1560   }
1561 
</pre>
<hr />
<pre>
1620     case Type::AnyPtr:   tj = TypePtr::BOTTOM;      break;  // caller checks it
1621     default: ShouldNotReachHere();
1622     }
1623     break;
1624   case 2:                       // No collapsing at level 2; keep all splits
1625   case 3:                       // No collapsing at level 3; keep all splits
1626     break;
1627   default:
1628     Unimplemented();
1629   }
1630 
1631   offset = tj-&gt;offset();
1632   assert( offset != Type::OffsetTop, &quot;Offset has fallen from constant&quot; );
1633 
1634   assert( (offset != Type::OffsetBot &amp;&amp; tj-&gt;base() != Type::AryPtr) ||
1635           (offset == Type::OffsetBot &amp;&amp; tj-&gt;base() == Type::AryPtr) ||
1636           (offset == Type::OffsetBot &amp;&amp; tj == TypeOopPtr::BOTTOM) ||
1637           (offset == Type::OffsetBot &amp;&amp; tj == TypePtr::BOTTOM) ||
1638           (offset == oopDesc::mark_offset_in_bytes() &amp;&amp; tj-&gt;base() == Type::AryPtr) ||
1639           (offset == oopDesc::klass_offset_in_bytes() &amp;&amp; tj-&gt;base() == Type::AryPtr) ||
<span class="line-modified">1640           (offset == arrayOopDesc::length_offset_in_bytes() &amp;&amp; tj-&gt;base() == Type::AryPtr),</span>

1641           &quot;For oops, klasses, raw offset must be constant; for arrays the offset is never known&quot; );
1642   assert( tj-&gt;ptr() != TypePtr::TopPTR &amp;&amp;
1643           tj-&gt;ptr() != TypePtr::AnyNull &amp;&amp;
1644           tj-&gt;ptr() != TypePtr::Null, &quot;No imprecise addresses&quot; );
1645 //    assert( tj-&gt;ptr() != TypePtr::Constant ||
1646 //            tj-&gt;base() == Type::RawPtr ||
1647 //            tj-&gt;base() == Type::KlassPtr, &quot;No constant oop addresses&quot; );
1648 
1649   return tj;
1650 }
1651 
1652 void Compile::AliasType::Init(int i, const TypePtr* at) {
<span class="line-added">1653   assert(AliasIdxTop &lt;= i &amp;&amp; i &lt; Compile::current()-&gt;_max_alias_types, &quot;Invalid alias index&quot;);</span>
1654   _index = i;
1655   _adr_type = at;
1656   _field = NULL;
1657   _element = NULL;
1658   _is_rewritable = true; // default
1659   const TypeOopPtr *atoop = (at != NULL) ? at-&gt;isa_oopptr() : NULL;
1660   if (atoop != NULL &amp;&amp; atoop-&gt;is_known_instance()) {
1661     const TypeOopPtr *gt = atoop-&gt;cast_to_instance_id(TypeOopPtr::InstanceBot);
1662     _general_index = Compile::current()-&gt;get_alias_index(gt);
1663   } else {
1664     _general_index = 0;
1665   }
1666 }
1667 
1668 BasicType Compile::AliasType::basic_type() const {
1669   if (element() != NULL) {
1670     const Type* element = adr_type()-&gt;is_aryptr()-&gt;elem();
1671     return element-&gt;isa_narrowoop() ? T_OBJECT : element-&gt;array_element_basic_type();
1672   } if (field() != NULL) {
1673     return field()-&gt;layout_type();
</pre>
<hr />
<pre>
2174   return true;
2175 }
2176 
2177 // Remove edges from &quot;root&quot; to each SafePoint at a backward branch.
2178 // They were inserted during parsing (see add_safepoint()) to make
2179 // infinite loops without calls or exceptions visible to root, i.e.,
2180 // useful.
2181 void Compile::remove_root_to_sfpts_edges(PhaseIterGVN&amp; igvn) {
2182   Node *r = root();
2183   if (r != NULL) {
2184     for (uint i = r-&gt;req(); i &lt; r-&gt;len(); ++i) {
2185       Node *n = r-&gt;in(i);
2186       if (n != NULL &amp;&amp; n-&gt;is_SafePoint()) {
2187         r-&gt;rm_prec(i);
2188         if (n-&gt;outcnt() == 0) {
2189           igvn.remove_dead_node(n);
2190         }
2191         --i;
2192       }
2193     }
<span class="line-added">2194     // Parsing may have added top inputs to the root node (Path</span>
<span class="line-added">2195     // leading to the Halt node proven dead). Make sure we get a</span>
<span class="line-added">2196     // chance to clean them up.</span>
<span class="line-added">2197     igvn._worklist.push(r);</span>
<span class="line-added">2198     igvn.optimize();</span>
2199   }
2200 }
2201 
2202 //------------------------------Optimize---------------------------------------
2203 // Given a graph, optimize it.
2204 void Compile::Optimize() {
2205   TracePhase tp(&quot;optimizer&quot;, &amp;timers[_t_optimizer]);
2206 
2207 #ifndef PRODUCT
2208   if (_directive-&gt;BreakAtCompileOption) {
2209     BREAKPOINT;
2210   }
2211 
2212 #endif
2213 

2214   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
<span class="line-added">2215 #ifdef ASSERT</span>
2216   bs-&gt;verify_gc_barriers(this, BarrierSetC2::BeforeOptimize);
2217 #endif
2218 
2219   ResourceMark rm;
2220 
2221   print_inlining_reinit();
2222 
2223   NOT_PRODUCT( verify_graph_edges(); )
2224 
2225   print_method(PHASE_AFTER_PARSING);
2226 
2227  {
2228   // Iterative Global Value Numbering, including ideal transforms
2229   // Initialize IterGVN with types and values from parse-time GVN
2230   PhaseIterGVN igvn(initial_gvn());
2231 #ifdef ASSERT
2232   _modified_nodes = new (comp_arena()) Unique_Node_List(comp_arena());
2233 #endif
2234   {
2235     TracePhase tp(&quot;iterGVN&quot;, &amp;timers[_t_iterGVN]);
</pre>
<hr />
<pre>
2275 
2276   if (!failing() &amp;&amp; RenumberLiveNodes &amp;&amp; live_nodes() + NodeLimitFudgeFactor &lt; unique()) {
2277     Compile::TracePhase tp(&quot;&quot;, &amp;timers[_t_renumberLive]);
2278     initial_gvn()-&gt;replace_with(&amp;igvn);
2279     for_igvn()-&gt;clear();
2280     Unique_Node_List new_worklist(C-&gt;comp_arena());
2281     {
2282       ResourceMark rm;
2283       PhaseRenumberLive prl = PhaseRenumberLive(initial_gvn(), for_igvn(), &amp;new_worklist);
2284     }
2285     set_for_igvn(&amp;new_worklist);
2286     igvn = PhaseIterGVN(initial_gvn());
2287     igvn.optimize();
2288   }
2289 
2290   // Perform escape analysis
2291   if (_do_escape_analysis &amp;&amp; ConnectionGraph::has_candidates(this)) {
2292     if (has_loops()) {
2293       // Cleanup graph (remove dead nodes).
2294       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
<span class="line-modified">2295       PhaseIdealLoop::optimize(igvn, LoopOptsMaxUnroll);</span>
2296       if (major_progress()) print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);
2297       if (failing())  return;
2298     }
2299     ConnectionGraph::do_analysis(this, &amp;igvn);
2300 
2301     if (failing())  return;
2302 
2303     // Optimize out fields loads from scalar replaceable allocations.
2304     igvn.optimize();
2305     print_method(PHASE_ITER_GVN_AFTER_EA, 2);
2306 
2307     if (failing())  return;
2308 
2309     if (congraph() != NULL &amp;&amp; macro_count() &gt; 0) {
2310       TracePhase tp(&quot;macroEliminate&quot;, &amp;timers[_t_macroEliminate]);
2311       PhaseMacroExpand mexp(igvn);
2312       mexp.eliminate_macro_nodes();
2313       igvn.set_delay_transform(false);
2314 
2315       igvn.optimize();
</pre>
<hr />
<pre>
2354   }
2355   if (failing())  return;
2356 
2357   // Conditional Constant Propagation;
2358   PhaseCCP ccp( &amp;igvn );
2359   assert( true, &quot;Break here to ccp.dump_nodes_and_types(_root,999,1)&quot;);
2360   {
2361     TracePhase tp(&quot;ccp&quot;, &amp;timers[_t_ccp]);
2362     ccp.do_transform();
2363   }
2364   print_method(PHASE_CPP1, 2);
2365 
2366   assert( true, &quot;Break here to ccp.dump_old2new_map()&quot;);
2367 
2368   // Iterative Global Value Numbering, including ideal transforms
2369   {
2370     TracePhase tp(&quot;iterGVN2&quot;, &amp;timers[_t_iterGVN2]);
2371     igvn = ccp;
2372     igvn.optimize();
2373   }

2374   print_method(PHASE_ITER_GVN2, 2);
2375 
2376   if (failing())  return;
2377 
2378   // Loop transforms on the ideal graph.  Range Check Elimination,
2379   // peeling, unrolling, etc.
2380   if (!optimize_loops(igvn, LoopOptsDefault)) {
2381     return;
2382   }
2383 






2384   if (failing())  return;
2385 
2386   // Ensure that major progress is now clear
2387   C-&gt;clear_major_progress();
2388 
2389   {
2390     // Verify that all previous optimizations produced a valid graph
2391     // at least to this point, even if no loop optimizations were done.
2392     TracePhase tp(&quot;idealLoopVerify&quot;, &amp;timers[_t_idealLoopVerify]);
2393     PhaseIdealLoop::verify(igvn);
2394   }
2395 
2396   if (range_check_cast_count() &gt; 0) {
2397     // No more loop optimizations. Remove all range check dependent CastIINodes.
2398     C-&gt;remove_range_check_casts(igvn);
2399     igvn.optimize();
2400   }
2401 
2402 #ifdef ASSERT
<span class="line-modified">2403   bs-&gt;verify_gc_barriers(this, BarrierSetC2::BeforeMacroExpand);</span>

2404 #endif
2405 
2406   {
2407     TracePhase tp(&quot;macroExpand&quot;, &amp;timers[_t_macroExpand]);
2408     PhaseMacroExpand  mex(igvn);

2409     if (mex.expand_macro_nodes()) {
2410       assert(failing(), &quot;must bail out w/ explicit message&quot;);
2411       return;
2412     }
<span class="line-added">2413     print_method(PHASE_MACRO_EXPANSION, 2);</span>
2414   }
2415 
2416   {
2417     TracePhase tp(&quot;barrierExpand&quot;, &amp;timers[_t_barrierExpand]);


2418     if (bs-&gt;expand_barriers(this, igvn)) {
2419       assert(failing(), &quot;must bail out w/ explicit message&quot;);
2420       return;
2421     }
<span class="line-added">2422     print_method(PHASE_BARRIER_EXPANSION, 2);</span>
2423   }
2424 
2425   if (opaque4_count() &gt; 0) {
2426     C-&gt;remove_opaque4_nodes(igvn);
2427     igvn.optimize();
2428   }
2429 
2430   DEBUG_ONLY( _modified_nodes = NULL; )
2431  } // (End scope of igvn; run destructor if necessary for asserts.)
2432 
2433  process_print_inlining();
2434  // A method with only infinite loops has no edges entering loops from root
2435  {
2436    TracePhase tp(&quot;graphReshape&quot;, &amp;timers[_t_graphReshaping]);
2437    if (final_graph_reshaping()) {
2438      assert(failing(), &quot;must bail out w/ explicit message&quot;);
2439      return;
2440    }
2441  }
2442 
</pre>
<hr />
<pre>
2449 void Compile::Code_Gen() {
2450   if (failing()) {
2451     return;
2452   }
2453 
2454   // Perform instruction selection.  You might think we could reclaim Matcher
2455   // memory PDQ, but actually the Matcher is used in generating spill code.
2456   // Internals of the Matcher (including some VectorSets) must remain live
2457   // for awhile - thus I cannot reclaim Matcher memory lest a VectorSet usage
2458   // set a bit in reclaimed memory.
2459 
2460   // In debug mode can dump m._nodes.dump() for mapping of ideal to machine
2461   // nodes.  Mapping is only valid at the root of each matched subtree.
2462   NOT_PRODUCT( verify_graph_edges(); )
2463 
2464   Matcher matcher;
2465   _matcher = &amp;matcher;
2466   {
2467     TracePhase tp(&quot;matcher&quot;, &amp;timers[_t_matcher]);
2468     matcher.match();
<span class="line-added">2469     if (failing()) {</span>
<span class="line-added">2470       return;</span>
<span class="line-added">2471     }</span>
2472   }
<span class="line-added">2473 </span>
2474   // In debug mode can dump m._nodes.dump() for mapping of ideal to machine
2475   // nodes.  Mapping is only valid at the root of each matched subtree.
2476   NOT_PRODUCT( verify_graph_edges(); )
2477 
2478   // If you have too many nodes, or if matching has failed, bail out
2479   check_node_count(0, &quot;out of nodes matching instructions&quot;);
2480   if (failing()) {
2481     return;
2482   }
2483 
2484   print_method(PHASE_MATCHING, 2);
2485 
2486   // Build a proper-looking CFG
2487   PhaseCFG cfg(node_arena(), root(), matcher);
2488   _cfg = &amp;cfg;
2489   {
2490     TracePhase tp(&quot;scheduler&quot;, &amp;timers[_t_scheduler]);
2491     bool success = cfg.do_global_code_motion();
2492     if (!success) {
2493       return;
</pre>
<hr />
<pre>
2540     TracePhase tp(&quot;postalloc_expand&quot;, &amp;timers[_t_postalloc_expand]);
2541     cfg.postalloc_expand(_regalloc);
2542   }
2543 
2544   // Convert Nodes to instruction bits in a buffer
2545   {
2546     TraceTime tp(&quot;output&quot;, &amp;timers[_t_output], CITime);
2547     Output();
2548   }
2549 
2550   print_method(PHASE_FINAL_CODE);
2551 
2552   // He&#39;s dead, Jim.
2553   _cfg     = (PhaseCFG*)((intptr_t)0xdeadbeef);
2554   _regalloc = (PhaseChaitin*)((intptr_t)0xdeadbeef);
2555 }
2556 
2557 
2558 //------------------------------dump_asm---------------------------------------
2559 // Dump formatted assembly
<span class="line-modified">2560 #if defined(SUPPORT_OPTO_ASSEMBLY)</span>
<span class="line-modified">2561 void Compile::dump_asm_on(outputStream* st, int* pcs, uint pc_limit) {</span>
<span class="line-added">2562 </span>
<span class="line-added">2563   int pc_digits = 3; // #chars required for pc</span>
<span class="line-added">2564   int sb_chars  = 3; // #chars for &quot;start bundle&quot; indicator</span>
<span class="line-added">2565   int tab_size  = 8;</span>
<span class="line-added">2566   if (pcs != NULL) {</span>
<span class="line-added">2567     int max_pc = 0;</span>
<span class="line-added">2568     for (uint i = 0; i &lt; pc_limit; i++) {</span>
<span class="line-added">2569       max_pc = (max_pc &lt; pcs[i]) ? pcs[i] : max_pc;</span>
<span class="line-added">2570     }</span>
<span class="line-added">2571     pc_digits  = ((max_pc &lt; 4096) ? 3 : ((max_pc &lt; 65536) ? 4 : ((max_pc &lt; 65536*256) ? 6 : 8))); // #chars required for pc</span>
<span class="line-added">2572   }</span>
<span class="line-added">2573   int prefix_len = ((pc_digits + sb_chars + tab_size - 1)/tab_size)*tab_size;</span>
<span class="line-added">2574 </span>
2575   bool cut_short = false;
<span class="line-modified">2576   st-&gt;print_cr(&quot;#&quot;);</span>
<span class="line-modified">2577   st-&gt;print(&quot;#  &quot;);  _tf-&gt;dump_on(st);  st-&gt;cr();</span>
<span class="line-modified">2578   st-&gt;print_cr(&quot;#&quot;);</span>
2579 
2580   // For all blocks
2581   int pc = 0x0;                 // Program counter
2582   char starts_bundle = &#39; &#39;;
2583   _regalloc-&gt;dump_frame();
2584 
2585   Node *n = NULL;
2586   for (uint i = 0; i &lt; _cfg-&gt;number_of_blocks(); i++) {
2587     if (VMThread::should_terminate()) {
2588       cut_short = true;
2589       break;
2590     }
2591     Block* block = _cfg-&gt;get_block(i);
2592     if (block-&gt;is_connector() &amp;&amp; !Verbose) {
2593       continue;
2594     }
2595     n = block-&gt;head();
<span class="line-modified">2596     if ((pcs != NULL) &amp;&amp; (n-&gt;_idx &lt; pc_limit)) {</span>
<span class="line-modified">2597       pc = pcs[n-&gt;_idx];</span>
<span class="line-modified">2598       st-&gt;print(&quot;%*.*x&quot;, pc_digits, pc_digits, pc);</span>

2599     }
<span class="line-modified">2600     st-&gt;fill_to(prefix_len);</span>
<span class="line-added">2601     block-&gt;dump_head(_cfg, st);</span>
2602     if (block-&gt;is_connector()) {
<span class="line-modified">2603       st-&gt;fill_to(prefix_len);</span>
<span class="line-added">2604       st-&gt;print_cr(&quot;# Empty connector block&quot;);</span>
2605     } else if (block-&gt;num_preds() == 2 &amp;&amp; block-&gt;pred(1)-&gt;is_CatchProj() &amp;&amp; block-&gt;pred(1)-&gt;as_CatchProj()-&gt;_con == CatchProjNode::fall_through_index) {
<span class="line-modified">2606       st-&gt;fill_to(prefix_len);</span>
<span class="line-added">2607       st-&gt;print_cr(&quot;# Block is sole successor of call&quot;);</span>
2608     }
2609 
2610     // For all instructions
2611     Node *delay = NULL;
2612     for (uint j = 0; j &lt; block-&gt;number_of_nodes(); j++) {
2613       if (VMThread::should_terminate()) {
2614         cut_short = true;
2615         break;
2616       }
2617       n = block-&gt;get_node(j);
2618       if (valid_bundle_info(n)) {
2619         Bundle* bundle = node_bundling(n);
2620         if (bundle-&gt;used_in_unconditional_delay()) {
2621           delay = n;
2622           continue;
2623         }
2624         if (bundle-&gt;starts_bundle()) {
2625           starts_bundle = &#39;+&#39;;
2626         }
2627       }
2628 
2629       if (WizardMode) {
2630         n-&gt;dump();
2631       }
2632 
2633       if( !n-&gt;is_Region() &amp;&amp;    // Dont print in the Assembly
2634           !n-&gt;is_Phi() &amp;&amp;       // a few noisely useless nodes
2635           !n-&gt;is_Proj() &amp;&amp;
2636           !n-&gt;is_MachTemp() &amp;&amp;
2637           !n-&gt;is_SafePointScalarObject() &amp;&amp;
2638           !n-&gt;is_Catch() &amp;&amp;     // Would be nice to print exception table targets
2639           !n-&gt;is_MergeMem() &amp;&amp;  // Not very interesting
2640           !n-&gt;is_top() &amp;&amp;       // Debug info table constants
2641           !(n-&gt;is_Con() &amp;&amp; !n-&gt;is_Mach())// Debug info table constants
2642           ) {
<span class="line-modified">2643         if ((pcs != NULL) &amp;&amp; (n-&gt;_idx &lt; pc_limit)) {</span>
<span class="line-modified">2644           pc = pcs[n-&gt;_idx];</span>
<span class="line-modified">2645           st-&gt;print(&quot;%*.*x&quot;, pc_digits, pc_digits, pc);</span>
<span class="line-modified">2646         } else {</span>
<span class="line-modified">2647           st-&gt;fill_to(pc_digits);</span>
<span class="line-added">2648         }</span>
<span class="line-added">2649         st-&gt;print(&quot; %c &quot;, starts_bundle);</span>
2650         starts_bundle = &#39; &#39;;
<span class="line-modified">2651         st-&gt;fill_to(prefix_len);</span>
<span class="line-modified">2652         n-&gt;format(_regalloc, st);</span>
<span class="line-modified">2653         st-&gt;cr();</span>
2654       }
2655 
2656       // If we have an instruction with a delay slot, and have seen a delay,
2657       // then back up and print it
2658       if (valid_bundle_info(n) &amp;&amp; node_bundling(n)-&gt;use_unconditional_delay()) {
<span class="line-modified">2659         // Coverity finding - Explicit null dereferenced.</span>
<span class="line-added">2660         guarantee(delay != NULL, &quot;no unconditional delay instruction&quot;);</span>
2661         if (WizardMode) delay-&gt;dump();
2662 
2663         if (node_bundling(delay)-&gt;starts_bundle())
2664           starts_bundle = &#39;+&#39;;
<span class="line-modified">2665         if ((pcs != NULL) &amp;&amp; (n-&gt;_idx &lt; pc_limit)) {</span>
<span class="line-modified">2666           pc = pcs[n-&gt;_idx];</span>
<span class="line-modified">2667           st-&gt;print(&quot;%*.*x&quot;, pc_digits, pc_digits, pc);</span>
<span class="line-modified">2668         } else {</span>
<span class="line-modified">2669           st-&gt;fill_to(pc_digits);</span>
<span class="line-added">2670         }</span>
<span class="line-added">2671         st-&gt;print(&quot; %c &quot;, starts_bundle);</span>
2672         starts_bundle = &#39; &#39;;
<span class="line-modified">2673         st-&gt;fill_to(prefix_len);</span>
<span class="line-modified">2674         delay-&gt;format(_regalloc, st);</span>
<span class="line-modified">2675         st-&gt;cr();</span>
2676         delay = NULL;
2677       }
2678 
2679       // Dump the exception table as well
2680       if( n-&gt;is_Catch() &amp;&amp; (Verbose || WizardMode) ) {
2681         // Print the exception table for this offset
2682         _handler_table.print_subtable_for(pc);
2683       }
<span class="line-added">2684       st-&gt;bol(); // Make sure we start on a new line</span>
2685     }
<span class="line-modified">2686     st-&gt;cr(); // one empty line between blocks</span>





2687     assert(cut_short || delay == NULL, &quot;no unconditional delay branch&quot;);

2688   } // End of per-block dump

2689 
<span class="line-modified">2690   if (cut_short)  st-&gt;print_cr(&quot;*** disassembly is cut short ***&quot;);</span>
2691 }
2692 #endif
2693 
2694 //------------------------------Final_Reshape_Counts---------------------------
2695 // This class defines counters to help identify when a method
2696 // may/must be executed using hardware with only 24-bit precision.
2697 struct Final_Reshape_Counts : public StackObj {
2698   int  _call_count;             // count non-inlined &#39;common&#39; calls
2699   int  _float_count;            // count float ops requiring 24-bit precision
2700   int  _double_count;           // count double ops requiring more precision
2701   int  _java_call_count;        // count non-inlined &#39;java&#39; calls
2702   int  _inner_loop_count;       // count loops which need alignment
2703   VectorSet _visited;           // Visitation flags
2704   Node_List _tests;             // Set of IfNodes &amp; PCTableNodes
2705 
2706   Final_Reshape_Counts() :
2707     _call_count(0), _float_count(0), _double_count(0),
2708     _java_call_count(0), _inner_loop_count(0),
2709     _visited( Thread::current()-&gt;resource_area() ) { }
2710 
</pre>
<hr />
<pre>
2802       break;
2803     }
2804     default:
2805       break;
2806     }
2807   }
2808 
2809 #ifdef ASSERT
2810   if( n-&gt;is_Mem() ) {
2811     int alias_idx = get_alias_index(n-&gt;as_Mem()-&gt;adr_type());
2812     assert( n-&gt;in(0) != NULL || alias_idx != Compile::AliasIdxRaw ||
2813             // oop will be recorded in oop map if load crosses safepoint
2814             n-&gt;is_Load() &amp;&amp; (n-&gt;as_Load()-&gt;bottom_type()-&gt;isa_oopptr() ||
2815                              LoadNode::is_immutable_value(n-&gt;in(MemNode::Address))),
2816             &quot;raw memory operations should have control edge&quot;);
2817   }
2818   if (n-&gt;is_MemBar()) {
2819     MemBarNode* mb = n-&gt;as_MemBar();
2820     if (mb-&gt;trailing_store() || mb-&gt;trailing_load_store()) {
2821       assert(mb-&gt;leading_membar()-&gt;trailing_membar() == mb, &quot;bad membar pair&quot;);
<span class="line-modified">2822       Node* mem = BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;step_over_gc_barrier(mb-&gt;in(MemBarNode::Precedent));</span>
2823       assert((mb-&gt;trailing_store() &amp;&amp; mem-&gt;is_Store() &amp;&amp; mem-&gt;as_Store()-&gt;is_release()) ||
2824              (mb-&gt;trailing_load_store() &amp;&amp; mem-&gt;is_LoadStore()), &quot;missing mem op&quot;);
2825     } else if (mb-&gt;leading()) {
2826       assert(mb-&gt;trailing_membar()-&gt;leading_membar() == mb, &quot;bad membar pair&quot;);
2827     }
2828   }
2829 #endif
2830   // Count FPU ops and common calls, implements item (3)
2831   bool gc_handled = BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;final_graph_reshaping(this, n, nop);
2832   if (!gc_handled) {
2833     final_graph_reshaping_main_switch(n, frc, nop);
2834   }
2835 
2836   // Collect CFG split points
2837   if (n-&gt;is_MultiBranch() &amp;&amp; !n-&gt;is_RangeCheck()) {
2838     frc._tests.push(n);
2839   }
2840 }
2841 
2842 void Compile::final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts&amp; frc, uint nop) {
</pre>
<hr />
<pre>
3072 #endif
3073     // platform dependent reshaping of the address expression
3074     reshape_address(n-&gt;as_AddP());
3075     break;
3076   }
3077 
3078   case Op_CastPP: {
3079     // Remove CastPP nodes to gain more freedom during scheduling but
3080     // keep the dependency they encode as control or precedence edges
3081     // (if control is set already) on memory operations. Some CastPP
3082     // nodes don&#39;t have a control (don&#39;t carry a dependency): skip
3083     // those.
3084     if (n-&gt;in(0) != NULL) {
3085       ResourceMark rm;
3086       Unique_Node_List wq;
3087       wq.push(n);
3088       for (uint next = 0; next &lt; wq.size(); ++next) {
3089         Node *m = wq.at(next);
3090         for (DUIterator_Fast imax, i = m-&gt;fast_outs(imax); i &lt; imax; i++) {
3091           Node* use = m-&gt;fast_out(i);
<span class="line-modified">3092           if (use-&gt;is_Mem() || use-&gt;is_EncodeNarrowPtr()) {</span>
3093             use-&gt;ensure_control_or_add_prec(n-&gt;in(0));
3094           } else {
3095             switch(use-&gt;Opcode()) {
3096             case Op_AddP:
3097             case Op_DecodeN:
3098             case Op_DecodeNKlass:
3099             case Op_CheckCastPP:
3100             case Op_CastPP:
3101               wq.push(use);
3102               break;
3103             }
3104           }
3105         }
3106       }
3107     }
3108     const bool is_LP64 = LP64_ONLY(true) NOT_LP64(false);
3109     if (is_LP64 &amp;&amp; n-&gt;in(1)-&gt;is_DecodeN() &amp;&amp; Matcher::gen_narrow_oop_implicit_null_checks()) {
3110       Node* in1 = n-&gt;in(1);
3111       const Type* t = n-&gt;bottom_type();
3112       Node* new_in1 = in1-&gt;clone();
</pre>
<hr />
<pre>
3452           m-&gt;disconnect_inputs(NULL, this);
3453         }
3454       }
3455     }
3456     break;
3457   }
3458   case Op_RangeCheck: {
3459     RangeCheckNode* rc = n-&gt;as_RangeCheck();
3460     Node* iff = new IfNode(rc-&gt;in(0), rc-&gt;in(1), rc-&gt;_prob, rc-&gt;_fcnt);
3461     n-&gt;subsume_by(iff, this);
3462     frc._tests.push(iff);
3463     break;
3464   }
3465   case Op_ConvI2L: {
3466     if (!Matcher::convi2l_type_required) {
3467       // Code generation on some platforms doesn&#39;t need accurate
3468       // ConvI2L types. Widening the type can help remove redundant
3469       // address computations.
3470       n-&gt;as_Type()-&gt;set_type(TypeLong::INT);
3471       ResourceMark rm;
<span class="line-modified">3472       Unique_Node_List wq;</span>
3473       wq.push(n);
3474       for (uint next = 0; next &lt; wq.size(); next++) {
3475         Node *m = wq.at(next);
3476 
3477         for(;;) {
3478           // Loop over all nodes with identical inputs edges as m
3479           Node* k = m-&gt;find_similar(m-&gt;Opcode());
3480           if (k == NULL) {
3481             break;
3482           }
3483           // Push their uses so we get a chance to remove node made
3484           // redundant
3485           for (DUIterator_Fast imax, i = k-&gt;fast_outs(imax); i &lt; imax; i++) {
3486             Node* u = k-&gt;fast_out(i);

3487             if (u-&gt;Opcode() == Op_LShiftL ||
3488                 u-&gt;Opcode() == Op_AddL ||
3489                 u-&gt;Opcode() == Op_SubL ||
3490                 u-&gt;Opcode() == Op_AddP) {
3491               wq.push(u);
3492             }
3493           }
3494           // Replace all nodes with identical edges as m with m
3495           k-&gt;subsume_by(m, this);
3496         }
3497       }
3498     }
3499     break;
3500   }
3501   case Op_CmpUL: {
3502     if (!Matcher::has_match_rule(Op_CmpUL)) {
3503       // No support for unsigned long comparisons
3504       ConINode* sign_pos = new ConINode(TypeInt::make(BitsPerLong - 1));
3505       Node* sign_bit_mask = new RShiftLNode(n-&gt;in(1), sign_pos);
3506       Node* orl = new OrLNode(n-&gt;in(1), sign_bit_mask);
</pre>
<hr />
<pre>
3696         return true;            // Not all targets reachable!
3697       }
3698     }
3699     // Check that I actually visited all kids.  Unreached kids
3700     // must be infinite loops.
3701     for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++)
3702       if (!frc._visited.test(n-&gt;fast_out(j)-&gt;_idx)) {
3703         record_method_not_compilable(&quot;infinite loop&quot;);
3704         return true;            // Found unvisited kid; must be unreach
3705       }
3706 
3707     // Here so verification code in final_graph_reshaping_walk()
3708     // always see an OuterStripMinedLoopEnd
3709     if (n-&gt;is_OuterStripMinedLoopEnd()) {
3710       IfNode* init_iff = n-&gt;as_If();
3711       Node* iff = new IfNode(init_iff-&gt;in(0), init_iff-&gt;in(1), init_iff-&gt;_prob, init_iff-&gt;_fcnt);
3712       n-&gt;subsume_by(iff, this);
3713     }
3714   }
3715 
<span class="line-added">3716 #ifdef IA32</span>
3717   // If original bytecodes contained a mixture of floats and doubles
3718   // check if the optimizer has made it homogenous, item (3).
<span class="line-modified">3719   if (UseSSE == 0 &amp;&amp;</span>
3720       frc.get_float_count() &gt; 32 &amp;&amp;
3721       frc.get_double_count() == 0 &amp;&amp;
3722       (10 * frc.get_call_count() &lt; frc.get_float_count()) ) {
<span class="line-modified">3723     set_24_bit_selection_and_mode(false, true);</span>
3724   }
<span class="line-added">3725 #endif // IA32</span>
3726 
3727   set_java_calls(frc.get_java_call_count());
3728   set_inner_loops(frc.get_inner_loop_count());
3729 
3730   // No infinite loops, no reason to bail out.
3731   return false;
3732 }
3733 
3734 //-----------------------------too_many_traps----------------------------------
3735 // Report if there are too many traps at the current method and bci.
3736 // Return true if there was a trap, and/or PerMethodTrapLimit is exceeded.
3737 bool Compile::too_many_traps(ciMethod* method,
3738                              int bci,
3739                              Deoptimization::DeoptReason reason) {
3740   ciMethodData* md = method-&gt;method_data();
3741   if (md-&gt;is_empty()) {
3742     // Assume the trap has not occurred, or that it occurred only
3743     // because of a transient condition during start-up in the interpreter.
3744     return false;
3745   }
</pre>
<hr />
<pre>
3825   } else {
3826     // The coast is clear.
3827     return false;
3828   }
3829 }
3830 
3831 // Compute when not to trap. Used by matching trap based nodes and
3832 // NullCheck optimization.
3833 void Compile::set_allowed_deopt_reasons() {
3834   _allowed_reasons = 0;
3835   if (is_method_compilation()) {
3836     for (int rs = (int)Deoptimization::Reason_none+1; rs &lt; Compile::trapHistLength; rs++) {
3837       assert(rs &lt; BitsPerInt, &quot;recode bit map&quot;);
3838       if (!too_many_traps((Deoptimization::DeoptReason) rs)) {
3839         _allowed_reasons |= nth_bit(rs);
3840       }
3841     }
3842   }
3843 }
3844 
<span class="line-modified">3845 bool Compile::needs_clinit_barrier(ciMethod* method, ciMethod* accessing_method) {</span>
<span class="line-modified">3846   return method-&gt;is_static() &amp;&amp; needs_clinit_barrier(method-&gt;holder(), accessing_method);</span>
<span class="line-modified">3847 }</span>
<span class="line-added">3848 </span>
<span class="line-added">3849 bool Compile::needs_clinit_barrier(ciField* field, ciMethod* accessing_method) {</span>
<span class="line-added">3850   return field-&gt;is_static() &amp;&amp; needs_clinit_barrier(field-&gt;holder(), accessing_method);</span>
<span class="line-added">3851 }</span>
<span class="line-added">3852 </span>
<span class="line-added">3853 bool Compile::needs_clinit_barrier(ciInstanceKlass* holder, ciMethod* accessing_method) {</span>
<span class="line-added">3854   if (holder-&gt;is_initialized()) {</span>
<span class="line-added">3855     return false;</span>
<span class="line-added">3856   }</span>
<span class="line-added">3857   if (holder-&gt;is_being_initialized()) {</span>
<span class="line-added">3858     if (accessing_method-&gt;holder() == holder) {</span>
<span class="line-added">3859       // Access inside a class. The barrier can be elided when access happens in &lt;clinit&gt;,</span>
<span class="line-added">3860       // &lt;init&gt;, or a static method. In all those cases, there was an initialization</span>
<span class="line-added">3861       // barrier on the holder klass passed.</span>
<span class="line-added">3862       if (accessing_method-&gt;is_static_initializer() ||</span>
<span class="line-added">3863           accessing_method-&gt;is_object_initializer() ||</span>
<span class="line-added">3864           accessing_method-&gt;is_static()) {</span>
<span class="line-added">3865         return false;</span>
<span class="line-added">3866       }</span>
<span class="line-added">3867     } else if (accessing_method-&gt;holder()-&gt;is_subclass_of(holder)) {</span>
<span class="line-added">3868       // Access from a subclass. The barrier can be elided only when access happens in &lt;clinit&gt;.</span>
<span class="line-added">3869       // In case of &lt;init&gt; or a static method, the barrier is on the subclass is not enough:</span>
<span class="line-added">3870       // child class can become fully initialized while its parent class is still being initialized.</span>
<span class="line-added">3871       if (accessing_method-&gt;is_static_initializer()) {</span>
<span class="line-added">3872         return false;</span>
<span class="line-added">3873       }</span>
<span class="line-added">3874     }</span>
<span class="line-added">3875     ciMethod* root = method(); // the root method of compilation</span>
<span class="line-added">3876     if (root != accessing_method) {</span>
<span class="line-added">3877       return needs_clinit_barrier(holder, root); // check access in the context of compilation root</span>
<span class="line-added">3878     }</span>
<span class="line-added">3879   }</span>
<span class="line-added">3880   return true;</span>
3881 }
3882 
3883 #ifndef PRODUCT
3884 //------------------------------verify_graph_edges---------------------------
3885 // Walk the Graph and verify that there is a one-to-one correspondence
3886 // between Use-Def edges and Def-Use edges in the graph.
3887 void Compile::verify_graph_edges(bool no_dead_code) {
3888   if (VerifyGraphEdges) {
3889     ResourceArea *area = Thread::current()-&gt;resource_area();
3890     Unique_Node_List visited(area);
3891     // Call recursive graph walk to check edges
3892     _root-&gt;verify_edges(visited);
3893     if (no_dead_code) {
3894       // Now make sure that no visited node is used by an unvisited node.
3895       bool dead_nodes = false;
3896       Unique_Node_List checked(area);
3897       while (visited.size() &gt; 0) {
3898         Node* n = visited.pop();
3899         checked.push(n);
3900         for (uint i = 0; i &lt; n-&gt;outcnt(); i++) {
</pre>
<hr />
<pre>
4222     if (subk-&gt;is_subtype_of(superk)) {
4223       return SSC_always_true;   // (1) false path dead; no dynamic test needed
4224     }
4225     if (!(superelem-&gt;is_klass() &amp;&amp; superelem-&gt;as_klass()-&gt;is_interface()) &amp;&amp;
4226         !superk-&gt;is_subtype_of(subk)) {
4227       return SSC_always_false;
4228     }
4229   }
4230 
4231   // If casting to an instance klass, it must have no subtypes
4232   if (superk-&gt;is_interface()) {
4233     // Cannot trust interfaces yet.
4234     // %%% S.B. superk-&gt;nof_implementors() == 1
4235   } else if (superelem-&gt;is_instance_klass()) {
4236     ciInstanceKlass* ik = superelem-&gt;as_instance_klass();
4237     if (!ik-&gt;has_subklass() &amp;&amp; !ik-&gt;is_interface()) {
4238       if (!ik-&gt;is_final()) {
4239         // Add a dependency if there is a chance of a later subclass.
4240         dependencies()-&gt;assert_leaf_type(ik);
4241       }
<span class="line-added">4242       if (ik-&gt;is_abstract()) {</span>
<span class="line-added">4243         return SSC_always_false;</span>
<span class="line-added">4244       }</span>
4245       return SSC_easy_test;     // (3) caller can do a simple ptr comparison
4246     }
4247   } else {
4248     // A primitive array type has no subtypes.
4249     return SSC_easy_test;       // (3) caller can do a simple ptr comparison
4250   }
4251 
4252   return SSC_full_test;
4253 }
4254 
4255 Node* Compile::conv_I2X_index(PhaseGVN* phase, Node* idx, const TypeInt* sizetype, Node* ctrl) {
4256 #ifdef _LP64
4257   // The scaled index operand to AddP must be a clean 64-bit value.
4258   // Java allows a 32-bit int to be incremented to a negative
4259   // value, which appears in a 64-bit register as a large
4260   // positive number.  Using that large positive number as an
4261   // operand in pointer arithmetic has bad consequences.
4262   // On the other hand, 32-bit overflow is rare, and the possibility
4263   // can often be excluded, if we annotate the ConvI2L node with
4264   // a type assertion that its value is known to be a small positive
</pre>
<hr />
<pre>
4273 }
4274 
4275 // Convert integer value to a narrowed long type dependent on ctrl (for example, a range check)
4276 Node* Compile::constrained_convI2L(PhaseGVN* phase, Node* value, const TypeInt* itype, Node* ctrl) {
4277   if (ctrl != NULL) {
4278     // Express control dependency by a CastII node with a narrow type.
4279     value = new CastIINode(value, itype, false, true /* range check dependency */);
4280     // Make the CastII node dependent on the control input to prevent the narrowed ConvI2L
4281     // node from floating above the range check during loop optimizations. Otherwise, the
4282     // ConvI2L node may be eliminated independently of the range check, causing the data path
4283     // to become TOP while the control path is still there (although it&#39;s unreachable).
4284     value-&gt;set_req(0, ctrl);
4285     // Save CastII node to remove it after loop optimizations.
4286     phase-&gt;C-&gt;add_range_check_cast(value);
4287     value = phase-&gt;transform(value);
4288   }
4289   const TypeLong* ltype = TypeLong::make(itype-&gt;_lo, itype-&gt;_hi, itype-&gt;_widen);
4290   return phase-&gt;transform(new ConvI2LNode(value, ltype));
4291 }
4292 
<span class="line-added">4293 void Compile::print_inlining_stream_free() {</span>
<span class="line-added">4294   if (_print_inlining_stream != NULL) {</span>
<span class="line-added">4295     _print_inlining_stream-&gt;~stringStream();</span>
<span class="line-added">4296     _print_inlining_stream = NULL;</span>
<span class="line-added">4297   }</span>
<span class="line-added">4298 }</span>
<span class="line-added">4299 </span>
4300 // The message about the current inlining is accumulated in
4301 // _print_inlining_stream and transfered into the _print_inlining_list
4302 // once we know whether inlining succeeds or not. For regular
4303 // inlining, messages are appended to the buffer pointed by
4304 // _print_inlining_idx in the _print_inlining_list. For late inlining,
4305 // a new buffer is added after _print_inlining_idx in the list. This
4306 // way we can update the inlining message for late inlining call site
4307 // when the inlining is attempted again.
4308 void Compile::print_inlining_init() {
4309   if (print_inlining() || print_intrinsics()) {
<span class="line-added">4310     // print_inlining_init is actually called several times.</span>
<span class="line-added">4311     print_inlining_stream_free();</span>
4312     _print_inlining_stream = new stringStream();
<span class="line-added">4313     // Watch out: The memory initialized by the constructor call PrintInliningBuffer()</span>
<span class="line-added">4314     // will be copied into the only initial element. The default destructor of</span>
<span class="line-added">4315     // PrintInliningBuffer will be called when leaving the scope here. If it</span>
<span class="line-added">4316     // would destuct the  enclosed stringStream _print_inlining_list[0]-&gt;_ss</span>
<span class="line-added">4317     // would be destructed, too!</span>
4318     _print_inlining_list = new (comp_arena())GrowableArray&lt;PrintInliningBuffer&gt;(comp_arena(), 1, 1, PrintInliningBuffer());
4319   }
4320 }
4321 
4322 void Compile::print_inlining_reinit() {
4323   if (print_inlining() || print_intrinsics()) {
<span class="line-added">4324     print_inlining_stream_free();</span>
4325     // Re allocate buffer when we change ResourceMark
4326     _print_inlining_stream = new stringStream();
4327   }
4328 }
4329 
4330 void Compile::print_inlining_reset() {
4331   _print_inlining_stream-&gt;reset();
4332 }
4333 
4334 void Compile::print_inlining_commit() {
4335   assert(print_inlining() || print_intrinsics(), &quot;PrintInlining off?&quot;);
4336   // Transfer the message from _print_inlining_stream to the current
4337   // _print_inlining_list buffer and clear _print_inlining_stream.
<span class="line-modified">4338   _print_inlining_list-&gt;at(_print_inlining_idx).ss()-&gt;write(_print_inlining_stream-&gt;base(), _print_inlining_stream-&gt;size());</span>
4339   print_inlining_reset();
4340 }
4341 
4342 void Compile::print_inlining_push() {
4343   // Add new buffer to the _print_inlining_list at current position
4344   _print_inlining_idx++;
4345   _print_inlining_list-&gt;insert_before(_print_inlining_idx, PrintInliningBuffer());
4346 }
4347 
4348 Compile::PrintInliningBuffer&amp; Compile::print_inlining_current() {
4349   return _print_inlining_list-&gt;at(_print_inlining_idx);
4350 }
4351 
4352 void Compile::print_inlining_update(CallGenerator* cg) {
4353   if (print_inlining() || print_intrinsics()) {
4354     if (!cg-&gt;is_late_inline()) {
4355       if (print_inlining_current().cg() != NULL) {
4356         print_inlining_push();
4357       }
4358       print_inlining_commit();
</pre>
<hr />
<pre>
4399 
4400 void Compile::process_print_inlining() {
4401   bool do_print_inlining = print_inlining() || print_intrinsics();
4402   if (do_print_inlining || log() != NULL) {
4403     // Print inlining message for candidates that we couldn&#39;t inline
4404     // for lack of space
4405     for (int i = 0; i &lt; _late_inlines.length(); i++) {
4406       CallGenerator* cg = _late_inlines.at(i);
4407       if (!cg-&gt;is_mh_late_inline()) {
4408         const char* msg = &quot;live nodes &gt; LiveNodeCountInliningCutoff&quot;;
4409         if (do_print_inlining) {
4410           cg-&gt;print_inlining_late(msg);
4411         }
4412         log_late_inline_failure(cg, msg);
4413       }
4414     }
4415   }
4416   if (do_print_inlining) {
4417     ResourceMark rm;
4418     stringStream ss;
<span class="line-added">4419     assert(_print_inlining_list != NULL, &quot;process_print_inlining should be called only once.&quot;);</span>
4420     for (int i = 0; i &lt; _print_inlining_list-&gt;length(); i++) {
4421       ss.print(&quot;%s&quot;, _print_inlining_list-&gt;adr_at(i)-&gt;ss()-&gt;as_string());
<span class="line-added">4422       _print_inlining_list-&gt;at(i).freeStream();</span>
4423     }
<span class="line-added">4424     // Reset _print_inlining_list, it only contains destructed objects.</span>
<span class="line-added">4425     // It is on the arena, so it will be freed when the arena is reset.</span>
<span class="line-added">4426     _print_inlining_list = NULL;</span>
<span class="line-added">4427     // _print_inlining_stream won&#39;t be used anymore, either.</span>
<span class="line-added">4428     print_inlining_stream_free();</span>
4429     size_t end = ss.size();
4430     _print_inlining_output = NEW_ARENA_ARRAY(comp_arena(), char, end+1);
4431     strncpy(_print_inlining_output, ss.base(), end+1);
4432     _print_inlining_output[end] = 0;
4433   }
4434 }
4435 
4436 void Compile::dump_print_inlining() {
4437   if (_print_inlining_output != NULL) {
4438     tty-&gt;print_raw(_print_inlining_output);
4439   }
4440 }
4441 
4442 void Compile::log_late_inline(CallGenerator* cg) {
4443   if (log() != NULL) {
4444     log()-&gt;head(&quot;late_inline method=&#39;%d&#39;  inline_id=&#39;&quot; JLONG_FORMAT &quot;&#39;&quot;, log()-&gt;identify(cg-&gt;method()),
4445                 cg-&gt;unique_id());
4446     JVMState* p = cg-&gt;call_node()-&gt;jvms();
4447     while (p != NULL) {
4448       log()-&gt;elem(&quot;jvms bci=&#39;%d&#39; method=&#39;%d&#39;&quot;, p-&gt;bci(), log()-&gt;identify(p-&gt;method()));
</pre>
</td>
</tr>
</table>
<center><a href="coalesce.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>