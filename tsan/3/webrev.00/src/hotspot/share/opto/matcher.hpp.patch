diff a/src/hotspot/share/opto/matcher.hpp b/src/hotspot/share/opto/matcher.hpp
--- a/src/hotspot/share/opto/matcher.hpp
+++ b/src/hotspot/share/opto/matcher.hpp
@@ -123,10 +123,12 @@
 
 #ifdef X86
   bool is_bmi_pattern(Node *n, Node *m);
 #endif
 
+  bool is_vshift_con_pattern(Node *n, Node *m);
+
   // Debug and profile information for nodes in old space:
   GrowableArray<Node_Notes*>* _old_node_note_array;
 
   // Node labeling iterator for instruction selection
   Node *Label_Root( const Node *n, State *svec, Node *control, const Node *mem );
@@ -311,11 +313,11 @@
   // should generate this one.
   static const bool match_rule_supported(int opcode);
 
   // identify extra cases that we might want to provide match rules for
   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
-  static const bool match_rule_supported_vector(int opcode, int vlen);
+  static const bool match_rule_supported_vector(int opcode, int vlen, BasicType bt);
 
   // Some microarchitectures have mask registers used on vectors
   static const bool has_predicated_vectors(void);
 
   // Some uarchs have different sized float register resources
@@ -485,22 +487,11 @@
   //
   // decode narrow_oop_reg, oop_reg // only 'shift'
   // [oop_reg + offset]
   // NullCheck oop_reg
   //
-  inline static bool gen_narrow_oop_implicit_null_checks() {
-    // Advice matcher to perform null checks on the narrow oop side.
-    // Implicit checks are not possible on the uncompressed oop side anyway
-    // (at least not for read accesses).
-    // Performs significantly better (especially on Power 6).
-    if (!os::zero_page_read_protected()) {
-      return true;
-    }
-    return Universe::narrow_oop_use_implicit_null_checks() &&
-           (narrow_oop_use_complex_address() ||
-            Universe::narrow_oop_base() != NULL);
-  }
+  static bool gen_narrow_oop_implicit_null_checks();
 
   // Is it better to copy float constants, or load them directly from memory?
   // Intel can load a float constant from a direct address, requiring no
   // extra registers.  Most RISCs will have to materialize an address into a
   // register first, so they may as well materialize the constant immediately.
@@ -515,16 +506,39 @@
 
   // Does the CPU require postalloc expand (see block.cpp for description of
   // postalloc expand)?
   static const bool require_postalloc_expand;
 
+  // Does the platform support generic vector operands?
+  // Requires cleanup after selection phase.
+  static const bool supports_generic_vector_operands;
+
+ private:
+  void do_postselect_cleanup();
+
+  void specialize_generic_vector_operands();
+  void specialize_mach_node(MachNode* m);
+  void specialize_temp_node(MachTempNode* tmp, MachNode* use, uint idx);
+  MachOper* specialize_vector_operand(MachNode* m, uint opnd_idx);
+  MachOper* specialize_vector_operand_helper(MachNode* m, uint opnd_idx, const TypeVect* vt);
+
+  static MachOper* specialize_generic_vector_operand(MachOper* generic_opnd, uint ideal_reg, bool is_temp);
+
+  static bool is_generic_reg2reg_move(MachNode* m);
+  static bool is_generic_vector(MachOper* opnd);
+
+  const RegMask* regmask_for_ideal_register(uint ideal_reg, Node* ret);
+
+  // Graph verification code
+  DEBUG_ONLY( bool verify_after_postselect_cleanup(); )
+
+ public:
   // Perform a platform dependent implicit null fixup.  This is needed
   // on windows95 to take care of some unusual register constraints.
   void pd_implicit_null_fixup(MachNode *load, uint idx);
 
-  // Advertise here if the CPU requires explicit rounding operations
-  // to implement the UseStrictFP mode.
+  // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
   static const bool strict_fp_requires_explicit_rounding;
 
   // Are floats conerted to double when stored to stack during deoptimization?
   static bool float_in_double();
   // Do ints take an entire long register or just half?
