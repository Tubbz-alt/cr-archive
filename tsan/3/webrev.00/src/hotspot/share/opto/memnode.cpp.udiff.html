<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/share/opto/memnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="matcher.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="memnode.hpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/memnode.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -1,7 +1,7 @@</span>
  /*
<span class="udiff-line-modified-removed">-  * Copyright (c) 1997, 2018, Oracle and/or its affiliates. All rights reserved.</span>
<span class="udiff-line-modified-added">+  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -42,17 +42,16 @@</span>
  #include &quot;opto/memnode.hpp&quot;
  #include &quot;opto/mulnode.hpp&quot;
  #include &quot;opto/narrowptrnode.hpp&quot;
  #include &quot;opto/phaseX.hpp&quot;
  #include &quot;opto/regmask.hpp&quot;
<span class="udiff-line-added">+ #include &quot;opto/rootnode.hpp&quot;</span>
  #include &quot;utilities/align.hpp&quot;
  #include &quot;utilities/copy.hpp&quot;
  #include &quot;utilities/macros.hpp&quot;
<span class="udiff-line-added">+ #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  #include &quot;utilities/vmError.hpp&quot;
<span class="udiff-line-removed">- #if INCLUDE_ZGC</span>
<span class="udiff-line-removed">- #include &quot;gc/z/c2/zBarrierSetC2.hpp&quot;</span>
<span class="udiff-line-removed">- #endif</span>
  
  // Portions of code courtesy of Clifford Click
  
  // Optimization - Graph Style
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -207,11 +206,11 @@</span>
    if (t_oop == NULL)
      return mchain;  // don&#39;t try to optimize non-oop types
    Node* result = optimize_simple_memory_chain(mchain, t_oop, load, phase);
    bool is_instance = t_oop-&gt;is_known_instance_field();
    PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
<span class="udiff-line-modified-removed">-   if (is_instance &amp;&amp; igvn != NULL  &amp;&amp; result-&gt;is_Phi()) {</span>
<span class="udiff-line-modified-added">+   if (is_instance &amp;&amp; igvn != NULL &amp;&amp; result-&gt;is_Phi()) {</span>
      PhiNode *mphi = result-&gt;as_Phi();
      assert(mphi-&gt;bottom_type() == Type::MEMORY, &quot;memory phi required&quot;);
      const TypePtr *t = mphi-&gt;adr_type();
      if (t == TypePtr::BOTTOM || t == TypeRawPtr::BOTTOM ||
          (t-&gt;isa_oopptr() &amp;&amp; !t-&gt;is_oopptr()-&gt;is_known_instance() &amp;&amp;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -326,10 +325,28 @@</span>
  
    Node *address = in(MemNode::Address);
    const Type *t_adr = phase-&gt;type(address);
    if (t_adr == Type::TOP)              return NodeSentinel; // caller will return NULL
  
<span class="udiff-line-added">+   if (can_reshape &amp;&amp; is_unsafe_access() &amp;&amp; (t_adr == TypePtr::NULL_PTR)) {</span>
<span class="udiff-line-added">+     // Unsafe off-heap access with zero address. Remove access and other control users</span>
<span class="udiff-line-added">+     // to not confuse optimizations and add a HaltNode to fail if this is ever executed.</span>
<span class="udiff-line-added">+     assert(ctl != NULL, &quot;unsafe accesses should be control dependent&quot;);</span>
<span class="udiff-line-added">+     for (DUIterator_Fast imax, i = ctl-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="udiff-line-added">+       Node* u = ctl-&gt;fast_out(i);</span>
<span class="udiff-line-added">+       if (u != ctl) {</span>
<span class="udiff-line-added">+         igvn-&gt;rehash_node_delayed(u);</span>
<span class="udiff-line-added">+         int nb = u-&gt;replace_edge(ctl, phase-&gt;C-&gt;top());</span>
<span class="udiff-line-added">+         --i, imax -= nb;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     Node* frame = igvn-&gt;transform(new ParmNode(phase-&gt;C-&gt;start(), TypeFunc::FramePtr));</span>
<span class="udiff-line-added">+     Node* halt = igvn-&gt;transform(new HaltNode(ctl, frame, &quot;unsafe off-heap access with zero address&quot;));</span>
<span class="udiff-line-added">+     phase-&gt;C-&gt;root()-&gt;add_req(halt);</span>
<span class="udiff-line-added">+     return this;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
    if (can_reshape &amp;&amp; igvn != NULL &amp;&amp;
        (igvn-&gt;_worklist.member(address) ||
         (igvn-&gt;_worklist.size() &gt; 0 &amp;&amp; t_adr != adr_type())) ) {
      // The address&#39;s base and type may change when the address is processed.
      // Delay this mem node transformation until the address is processed.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -718,13 +735,11 @@</span>
  //----------------------calculate_adr_type-------------------------------------
  // Helper function.  Notices when the given type of address hits top or bottom.
  // Also, asserts a cross-check of the type against the expected address type.
  const TypePtr* MemNode::calculate_adr_type(const Type* t, const TypePtr* cross_check) {
    if (t == Type::TOP)  return NULL; // does not touch memory any more?
<span class="udiff-line-modified-removed">-   #ifdef PRODUCT</span>
<span class="udiff-line-removed">-   cross_check = NULL;</span>
<span class="udiff-line-removed">-   #else</span>
<span class="udiff-line-modified-added">+   #ifdef ASSERT</span>
    if (!VerifyAliases || VMError::is_error_reported() || Node::in_dump())  cross_check = NULL;
    #endif
    const TypePtr* tp = t-&gt;isa_ptr();
    if (tp == NULL) {
      assert(cross_check == NULL || cross_check == TypePtr::BOTTOM, &quot;expected memory type must be wide&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -756,11 +771,11 @@</span>
  // Should LoadNode::Ideal() attempt to remove control edges?
  bool LoadNode::can_remove_control() const {
    return true;
  }
  uint LoadNode::size_of() const { return sizeof(*this); }
<span class="udiff-line-modified-removed">- uint LoadNode::cmp( const Node &amp;n ) const</span>
<span class="udiff-line-modified-added">+ bool LoadNode::cmp( const Node &amp;n ) const</span>
  { return !Type::cmp( _type, ((LoadNode&amp;)n)._type ); }
  const Type *LoadNode::bottom_type() const { return _type; }
  uint LoadNode::ideal_reg() const {
    return _type-&gt;ideal_reg();
  }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -790,11 +805,11 @@</span>
  #endif
  
  //----------------------------LoadNode::make-----------------------------------
  // Polymorphic factory method:
  Node *LoadNode::make(PhaseGVN&amp; gvn, Node *ctl, Node *mem, Node *adr, const TypePtr* adr_type, const Type *rt, BasicType bt, MemOrd mo,
<span class="udiff-line-modified-removed">-                      ControlDependency control_dependency, bool unaligned, bool mismatched, bool unsafe) {</span>
<span class="udiff-line-modified-added">+                      ControlDependency control_dependency, bool unaligned, bool mismatched, bool unsafe, uint8_t barrier_data) {</span>
    Compile* C = gvn.C;
  
    // sanity check the alias category against the created node type
    assert(!(adr_type-&gt;isa_oopptr() &amp;&amp;
             adr_type-&gt;offset() == oopDesc::klass_offset_in_bytes()),
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -841,20 +856,21 @@</span>
      load-&gt;set_mismatched_access();
    }
    if (unsafe) {
      load-&gt;set_unsafe_access();
    }
<span class="udiff-line-added">+   load-&gt;set_barrier_data(barrier_data);</span>
    if (load-&gt;Opcode() == Op_LoadN) {
      Node* ld = gvn.transform(load);
      return new DecodeNNode(ld, ld-&gt;bottom_type()-&gt;make_ptr());
    }
  
    return load;
  }
  
  LoadLNode* LoadLNode::make_atomic(Node* ctl, Node* mem, Node* adr, const TypePtr* adr_type, const Type* rt, MemOrd mo,
<span class="udiff-line-modified-removed">-                                   ControlDependency control_dependency, bool unaligned, bool mismatched, bool unsafe) {</span>
<span class="udiff-line-modified-added">+                                   ControlDependency control_dependency, bool unaligned, bool mismatched, bool unsafe, uint8_t barrier_data) {</span>
    bool require_atomic = true;
    LoadLNode* load = new LoadLNode(ctl, mem, adr, adr_type, rt-&gt;is_long(), mo, control_dependency, require_atomic);
    if (unaligned) {
      load-&gt;set_unaligned_access();
    }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -862,15 +878,16 @@</span>
      load-&gt;set_mismatched_access();
    }
    if (unsafe) {
      load-&gt;set_unsafe_access();
    }
<span class="udiff-line-added">+   load-&gt;set_barrier_data(barrier_data);</span>
    return load;
  }
  
  LoadDNode* LoadDNode::make_atomic(Node* ctl, Node* mem, Node* adr, const TypePtr* adr_type, const Type* rt, MemOrd mo,
<span class="udiff-line-modified-removed">-                                   ControlDependency control_dependency, bool unaligned, bool mismatched, bool unsafe) {</span>
<span class="udiff-line-modified-added">+                                   ControlDependency control_dependency, bool unaligned, bool mismatched, bool unsafe, uint8_t barrier_data) {</span>
    bool require_atomic = true;
    LoadDNode* load = new LoadDNode(ctl, mem, adr, adr_type, rt, mo, control_dependency, require_atomic);
    if (unaligned) {
      load-&gt;set_unaligned_access();
    }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -878,10 +895,11 @@</span>
      load-&gt;set_mismatched_access();
    }
    if (unsafe) {
      load-&gt;set_unsafe_access();
    }
<span class="udiff-line-added">+   load-&gt;set_barrier_data(barrier_data);</span>
    return load;
  }
  
  
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -906,18 +924,10 @@</span>
  
  // Is the value loaded previously stored by an arraycopy? If so return
  // a load node that reads from the source array so we may be able to
  // optimize out the ArrayCopy node later.
  Node* LoadNode::can_see_arraycopy_value(Node* st, PhaseGVN* phase) const {
<span class="udiff-line-removed">- #if INCLUDE_ZGC</span>
<span class="udiff-line-removed">-   if (UseZGC) {</span>
<span class="udiff-line-removed">-     if (bottom_type()-&gt;make_oopptr() != NULL) {</span>
<span class="udiff-line-removed">-       return NULL;</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-removed">- #endif</span>
<span class="udiff-line-removed">- </span>
    Node* ld_adr = in(MemNode::Address);
    intptr_t ld_off = 0;
    AllocateNode* ld_alloc = AllocateNode::Ideal_allocation(ld_adr, phase, ld_off);
    Node* ac = find_previous_arraycopy(phase, ld_alloc, st, true);
    if (ac != NULL) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -971,11 +981,11 @@</span>
  #endif
      ld-&gt;set_req(MemNode::Address, addp);
      ld-&gt;set_req(0, ctl);
      ld-&gt;set_req(MemNode::Memory, mem);
      // load depends on the tests that validate the arraycopy
<span class="udiff-line-modified-removed">-     ld-&gt;_control_dependency = Pinned;</span>
<span class="udiff-line-modified-added">+     ld-&gt;_control_dependency = UnknownControl;</span>
      return ld;
    }
    return NULL;
  }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1045,25 +1055,26 @@</span>
        Node* st_adr = st-&gt;in(MemNode::Address);
        if (!phase-&gt;eqv(st_adr, ld_adr)) {
          // Try harder before giving up. Unify base pointers with casts (e.g., raw/non-raw pointers).
          intptr_t st_off = 0;
          Node* st_base = AddPNode::Ideal_base_and_offset(st_adr, phase, st_off);
<span class="udiff-line-modified-removed">-         if (ld_base == NULL)                        return NULL;</span>
<span class="udiff-line-modified-removed">-         if (st_base == NULL)                        return NULL;</span>
<span class="udiff-line-modified-removed">-         if (ld_base-&gt;uncast() != st_base-&gt;uncast()) return NULL;</span>
<span class="udiff-line-modified-removed">-         if (ld_off != st_off)                       return NULL;</span>
<span class="udiff-line-modified-removed">-         if (ld_off == Type::OffsetBot)              return NULL;</span>
<span class="udiff-line-modified-added">+         if (ld_base == NULL)                                   return NULL;</span>
<span class="udiff-line-modified-added">+         if (st_base == NULL)                                   return NULL;</span>
<span class="udiff-line-modified-added">+         if (!ld_base-&gt;eqv_uncast(st_base, /*keep_deps=*/true)) return NULL;</span>
<span class="udiff-line-modified-added">+         if (ld_off != st_off)                                  return NULL;</span>
<span class="udiff-line-modified-added">+         if (ld_off == Type::OffsetBot)                         return NULL;</span>
          // Same base, same offset.
          // Possible improvement for arrays: check index value instead of absolute offset.
  
          // At this point we have proven something like this setup:
          //   B = &lt;&lt; base &gt;&gt;
          //   L =  LoadQ(AddP(Check/CastPP(B), #Off))
          //   S = StoreQ(AddP(             B , #Off), V)
          // (Actually, we haven&#39;t yet proven the Q&#39;s are the same.)
          // In other words, we are loading from a casted version of
          // the same pointer-and-offset that we stored to.
<span class="udiff-line-added">+         // Casted version may carry a dependency and it is respected.</span>
          // Thus, we are able to replace L by V.
        }
        // Now prove that we have a LoadQ matched to a StoreQ, for some Q.
        if (store_Opcode() != st-&gt;Opcode())
          return NULL;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1421,19 +1432,18 @@</span>
          }
        }
      }
    }
  
<span class="udiff-line-removed">-   bool load_boxed_phi = load_boxed_values &amp;&amp; base_is_phi &amp;&amp; (base-&gt;in(0) == mem-&gt;in(0));</span>
<span class="udiff-line-removed">- </span>
    // Split through Phi (see original code in loopopts.cpp).
    assert(C-&gt;have_alias_type(t_oop), &quot;instance should have alias type&quot;);
  
    // Do nothing here if Identity will find a value
    // (to avoid infinite chain of value phis generation).
<span class="udiff-line-modified-removed">-   if (!phase-&gt;eqv(this, phase-&gt;apply_identity(this)))</span>
<span class="udiff-line-modified-added">+   if (!phase-&gt;eqv(this, this-&gt;Identity(phase))) {</span>
      return NULL;
<span class="udiff-line-added">+   }</span>
  
    // Select Region to split through.
    Node* region;
    if (!base_is_phi) {
      assert(mem-&gt;is_Phi(), &quot;sanity&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1472,18 +1482,24 @@</span>
    PhaseIterGVN* igvn = phase-&gt;is_IterGVN();
    Node* phi = new PhiNode(region, this_type, NULL, mem-&gt;_idx, this_iid, this_index, this_offset);
    for (uint i = 1; i &lt; region-&gt;req(); i++) {
      Node* x;
      Node* the_clone = NULL;
<span class="udiff-line-modified-removed">-     if (region-&gt;in(i) == C-&gt;top()) {</span>
<span class="udiff-line-modified-added">+     Node* in = region-&gt;in(i);</span>
<span class="udiff-line-added">+     if (region-&gt;is_CountedLoop() &amp;&amp; region-&gt;as_Loop()-&gt;is_strip_mined() &amp;&amp; i == LoopNode::EntryControl &amp;&amp;</span>
<span class="udiff-line-added">+         in != NULL &amp;&amp; in-&gt;is_OuterStripMinedLoop()) {</span>
<span class="udiff-line-added">+       // No node should go in the outer strip mined loop</span>
<span class="udiff-line-added">+       in = in-&gt;in(LoopNode::EntryControl);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     if (in == NULL || in == C-&gt;top()) {</span>
        x = C-&gt;top();      // Dead path?  Use a dead data op
      } else {
        x = this-&gt;clone();        // Else clone up the data op
        the_clone = x;            // Remember for possible deletion.
        // Alter data node to use pre-phi inputs
        if (this-&gt;in(0) == region) {
<span class="udiff-line-modified-removed">-         x-&gt;set_req(0, region-&gt;in(i));</span>
<span class="udiff-line-modified-added">+         x-&gt;set_req(0, in);</span>
        } else {
          x-&gt;set_req(0, NULL);
        }
        if (mem-&gt;is_Phi() &amp;&amp; (mem-&gt;in(0) == region)) {
          x-&gt;set_req(Memory, mem-&gt;in(i)); // Use pre-Phi input for the clone.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1518,11 +1534,11 @@</span>
        igvn-&gt;set_type(x, t);
        // If x is a TypeNode, capture any more-precise type permanently into Node
        // otherwise it will be not updated during igvn-&gt;transform since
        // igvn-&gt;type(x) is set to x-&gt;Value() already.
        x-&gt;raise_bottom_type(t);
<span class="udiff-line-modified-removed">-       Node *y = igvn-&gt;apply_identity(x);</span>
<span class="udiff-line-modified-added">+       Node* y = x-&gt;Identity(igvn);</span>
        if (y != x) {
          x = y;
        } else {
          y = igvn-&gt;hash_find_insert(x);
          if (y) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1543,10 +1559,26 @@</span>
    // Record Phi
    igvn-&gt;register_new_node_with_optimizer(phi);
    return phi;
  }
  
<span class="udiff-line-added">+ AllocateNode* LoadNode::is_new_object_mark_load(PhaseGVN *phase) const {</span>
<span class="udiff-line-added">+   if (Opcode() == Op_LoadX) {</span>
<span class="udiff-line-added">+     Node* address = in(MemNode::Address);</span>
<span class="udiff-line-added">+     AllocateNode* alloc = AllocateNode::Ideal_allocation(address, phase);</span>
<span class="udiff-line-added">+     Node* mem = in(MemNode::Memory);</span>
<span class="udiff-line-added">+     if (alloc != NULL &amp;&amp; mem-&gt;is_Proj() &amp;&amp;</span>
<span class="udiff-line-added">+         mem-&gt;in(0) != NULL &amp;&amp;</span>
<span class="udiff-line-added">+         mem-&gt;in(0) == alloc-&gt;initialization() &amp;&amp;</span>
<span class="udiff-line-added">+         alloc-&gt;initialization()-&gt;proj_out_or_null(0) != NULL) {</span>
<span class="udiff-line-added">+       return alloc;</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   return NULL;</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
  //------------------------------Ideal------------------------------------------
  // If the load is from Field memory and the pointer is non-null, it might be possible to
  // zero out the control input.
  // If the offset is constant and the base is an object allocation,
  // try to hook me up to the exact initializing store.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1563,11 +1595,12 @@</span>
  
    // Skip up past a SafePoint control.  Cannot do this for Stores because
    // pointer stores &amp; cardmarks must stay on the same side of a SafePoint.
    if( ctrl != NULL &amp;&amp; ctrl-&gt;Opcode() == Op_SafePoint &amp;&amp;
        phase-&gt;C-&gt;get_alias_index(phase-&gt;type(address)-&gt;is_ptr()) != Compile::AliasIdxRaw  &amp;&amp;
<span class="udiff-line-modified-removed">-       !addr_mark ) {</span>
<span class="udiff-line-modified-added">+       !addr_mark &amp;&amp;</span>
<span class="udiff-line-added">+       (depends_only_on_test() || has_unknown_control_dependency())) {</span>
      ctrl = ctrl-&gt;in(0);
      set_req(MemNode::Control,ctrl);
      progress = true;
    }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1670,10 +1703,17 @@</span>
        set_req(MemNode::Memory, prev_mem);
        return this;
      }
    }
  
<span class="udiff-line-added">+   AllocateNode* alloc = is_new_object_mark_load(phase);</span>
<span class="udiff-line-added">+   if (alloc != NULL &amp;&amp; alloc-&gt;Opcode() == Op_Allocate &amp;&amp; UseBiasedLocking) {</span>
<span class="udiff-line-added">+     InitializeNode* init = alloc-&gt;initialization();</span>
<span class="udiff-line-added">+     Node* control = init-&gt;proj_out(0);</span>
<span class="udiff-line-added">+     return alloc-&gt;make_ideal_mark(phase, address, control, mem);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
    return progress ? this : NULL;
  }
  
  // Helper to recognize certain Klass fields which are invariant across
  // some group of array types (e.g., int[] or all T[] where T &lt; Object).
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1928,10 +1968,16 @@</span>
      if (mem-&gt;is_Parm() &amp;&amp; mem-&gt;in(0)-&gt;is_Start()) {
        assert(mem-&gt;as_Parm()-&gt;_con == TypeFunc::Memory, &quot;must be memory Parm&quot;);
        return Type::get_zero_type(_type-&gt;basic_type());
      }
    }
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   Node* alloc = is_new_object_mark_load(phase);</span>
<span class="udiff-line-added">+   if (alloc != NULL &amp;&amp; !(alloc-&gt;Opcode() == Op_Allocate &amp;&amp; UseBiasedLocking)) {</span>
<span class="udiff-line-added">+     return TypeX::make(markWord::prototype().value());</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
    return _type;
  }
  
  //------------------------------match_edge-------------------------------------
  // Do we Match on this edge index or not?  Match only the address.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2625,11 +2671,11 @@</span>
  }
  
  //------------------------------cmp--------------------------------------------
  // Do not common stores up together.  They generally have to be split
  // back up anyways, so do not bother.
<span class="udiff-line-modified-removed">- uint StoreNode::cmp( const Node &amp;n ) const {</span>
<span class="udiff-line-modified-added">+ bool StoreNode::cmp( const Node &amp;n ) const {</span>
    return (&amp;n == this);          // Always fail except on self
  }
  
  //------------------------------Ideal_masked_input-----------------------------
  // Check for a useless mask before a partial-word store
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2808,11 +2854,12 @@</span>
  //=============================================================================
  //----------------------------------LoadStoreNode------------------------------
  LoadStoreNode::LoadStoreNode( Node *c, Node *mem, Node *adr, Node *val, const TypePtr* at, const Type* rt, uint required )
    : Node(required),
      _type(rt),
<span class="udiff-line-modified-removed">-     _adr_type(at)</span>
<span class="udiff-line-modified-added">+     _adr_type(at),</span>
<span class="udiff-line-added">+     _barrier(0)</span>
  {
    init_req(MemNode::Control, c  );
    init_req(MemNode::Memory , mem);
    init_req(MemNode::Address, adr);
    init_req(MemNode::ValueIn, val);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3055,11 +3102,11 @@</span>
      init_req(TypeFunc::Parms, precedent);
  }
  
  //------------------------------cmp--------------------------------------------
  uint MemBarNode::hash() const { return NO_HASH; }
<span class="udiff-line-modified-removed">- uint MemBarNode::cmp( const Node &amp;n ) const {</span>
<span class="udiff-line-modified-added">+ bool MemBarNode::cmp( const Node &amp;n ) const {</span>
    return (&amp;n == this);          // Always fail except on self
  }
  
  //------------------------------make-------------------------------------------
  MemBarNode* MemBarNode::make(Compile* C, int opcode, int atp, Node* pn) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3102,20 +3149,10 @@</span>
    // Don&#39;t bother trying to transform a dead node
    if (in(0) &amp;&amp; in(0)-&gt;is_top()) {
      return NULL;
    }
  
<span class="udiff-line-removed">- #if INCLUDE_ZGC</span>
<span class="udiff-line-removed">-   if (UseZGC) {</span>
<span class="udiff-line-removed">-     if (req() == (Precedent+1) &amp;&amp; in(MemBarNode::Precedent)-&gt;in(0) != NULL &amp;&amp; in(MemBarNode::Precedent)-&gt;in(0)-&gt;is_LoadBarrier()) {</span>
<span class="udiff-line-removed">-       Node* load_node = in(MemBarNode::Precedent)-&gt;in(0)-&gt;in(LoadBarrierNode::Oop);</span>
<span class="udiff-line-removed">-       set_req(MemBarNode::Precedent, load_node);</span>
<span class="udiff-line-removed">-       return this;</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">-   }</span>
<span class="udiff-line-removed">- #endif</span>
<span class="udiff-line-removed">- </span>
    bool progress = false;
    // Eliminate volatile MemBars for scalar replaced objects.
    if (can_reshape &amp;&amp; req() == (Precedent+1)) {
      bool eliminate = false;
      int opc = Opcode();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3504,56 +3541,67 @@</span>
  // &quot;simple enough&quot; to be folded into an object initialization.
  // Attempts to prove that a store&#39;s initial value &#39;n&#39; can be captured
  // within the initialization without creating a vicious cycle, such as:
  //     { Foo p = new Foo(); p.next = p; }
  // True for constants and parameters and small combinations thereof.
<span class="udiff-line-modified-removed">- bool InitializeNode::detect_init_independence(Node* n, int&amp; count) {</span>
<span class="udiff-line-modified-removed">-   if (n == NULL)      return true;   // (can this really happen?)</span>
<span class="udiff-line-modified-removed">-   if (n-&gt;is_Proj())   n = n-&gt;in(0);</span>
<span class="udiff-line-modified-removed">-   if (n == this)      return false;  // found a cycle</span>
<span class="udiff-line-modified-removed">-   if (n-&gt;is_Con())    return true;</span>
<span class="udiff-line-modified-removed">-   if (n-&gt;is_Start())  return true;   // params, etc., are OK</span>
<span class="udiff-line-modified-removed">-   if (n-&gt;is_Root())   return true;   // even better</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-   Node* ctl = n-&gt;in(0);</span>
<span class="udiff-line-modified-removed">-   if (ctl != NULL &amp;&amp; !ctl-&gt;is_top()) {</span>
<span class="udiff-line-modified-removed">-     if (ctl-&gt;is_Proj())  ctl = ctl-&gt;in(0);</span>
<span class="udiff-line-modified-removed">-     if (ctl == this)  return false;</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-     // If we already know that the enclosing memory op is pinned right after</span>
<span class="udiff-line-modified-removed">-     // the init, then any control flow that the store has picked up</span>
<span class="udiff-line-modified-removed">-     // must have preceded the init, or else be equal to the init.</span>
<span class="udiff-line-modified-removed">-     // Even after loop optimizations (which might change control edges)</span>
<span class="udiff-line-modified-removed">-     // a store is never pinned *before* the availability of its inputs.</span>
<span class="udiff-line-modified-removed">-     if (!MemNode::all_controls_dominate(n, this))</span>
<span class="udiff-line-modified-removed">-       return false;                  // failed to prove a good control</span>
<span class="udiff-line-modified-removed">-   }</span>
<span class="udiff-line-modified-removed">- </span>
<span class="udiff-line-modified-removed">-   // Check data edges for possible dependencies on &#39;this&#39;.</span>
<span class="udiff-line-modified-removed">-   if ((count += 1) &gt; 20)  return false;  // complexity limit</span>
<span class="udiff-line-modified-removed">-   for (uint i = 1; i &lt; n-&gt;req(); i++) {</span>
<span class="udiff-line-modified-removed">-     Node* m = n-&gt;in(i);</span>
<span class="udiff-line-modified-removed">-     if (m == NULL || m == n || m-&gt;is_top())  continue;</span>
<span class="udiff-line-modified-removed">-     uint first_i = n-&gt;find_edge(m);</span>
<span class="udiff-line-modified-removed">-     if (i != first_i)  continue;  // process duplicate edge just once</span>
<span class="udiff-line-modified-removed">-     if (!detect_init_independence(m, count)) {</span>
<span class="udiff-line-modified-removed">-       return false;</span>
<span class="udiff-line-modified-added">+ bool InitializeNode::detect_init_independence(Node* value, PhaseGVN* phase) {</span>
<span class="udiff-line-modified-added">+   ResourceMark rm;</span>
<span class="udiff-line-modified-added">+   Unique_Node_List worklist;</span>
<span class="udiff-line-modified-added">+   worklist.push(value);</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+   uint complexity_limit = 20;</span>
<span class="udiff-line-modified-added">+   for (uint j = 0; j &lt; worklist.size(); j++) {</span>
<span class="udiff-line-modified-added">+     if (j &gt;= complexity_limit) {</span>
<span class="udiff-line-modified-added">+       return false;  // Bail out if processed too many nodes</span>
<span class="udiff-line-modified-added">+     }</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+     Node* n = worklist.at(j);</span>
<span class="udiff-line-modified-added">+     if (n == NULL)      continue;   // (can this really happen?)</span>
<span class="udiff-line-modified-added">+     if (n-&gt;is_Proj())   n = n-&gt;in(0);</span>
<span class="udiff-line-modified-added">+     if (n == this)      return false;  // found a cycle</span>
<span class="udiff-line-modified-added">+     if (n-&gt;is_Con())    continue;</span>
<span class="udiff-line-modified-added">+     if (n-&gt;is_Start())  continue;   // params, etc., are OK</span>
<span class="udiff-line-modified-added">+     if (n-&gt;is_Root())   continue;   // even better</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+     // There cannot be any dependency if &#39;n&#39; is a CFG node that dominates the current allocation</span>
<span class="udiff-line-modified-added">+     if (n-&gt;is_CFG() &amp;&amp; phase-&gt;is_dominator(n, allocation())) {</span>
<span class="udiff-line-modified-added">+       continue;</span>
<span class="udiff-line-modified-added">+     }</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+     Node* ctl = n-&gt;in(0);</span>
<span class="udiff-line-modified-added">+     if (ctl != NULL &amp;&amp; !ctl-&gt;is_top()) {</span>
<span class="udiff-line-modified-added">+       if (ctl-&gt;is_Proj())  ctl = ctl-&gt;in(0);</span>
<span class="udiff-line-modified-added">+       if (ctl == this)  return false;</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+       // If we already know that the enclosing memory op is pinned right after</span>
<span class="udiff-line-modified-added">+       // the init, then any control flow that the store has picked up</span>
<span class="udiff-line-added">+       // must have preceded the init, or else be equal to the init.</span>
<span class="udiff-line-added">+       // Even after loop optimizations (which might change control edges)</span>
<span class="udiff-line-added">+       // a store is never pinned *before* the availability of its inputs.</span>
<span class="udiff-line-added">+       if (!MemNode::all_controls_dominate(n, this))</span>
<span class="udiff-line-added">+         return false;                  // failed to prove a good control</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // Check data edges for possible dependencies on &#39;this&#39;.</span>
<span class="udiff-line-added">+     for (uint i = 1; i &lt; n-&gt;req(); i++) {</span>
<span class="udiff-line-added">+       Node* m = n-&gt;in(i);</span>
<span class="udiff-line-added">+       if (m == NULL || m == n || m-&gt;is_top())  continue;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+       // Only process data inputs once</span>
<span class="udiff-line-added">+       worklist.push(m);</span>
      }
    }
  
    return true;
  }
  
  // Here are all the checks a Store must pass before it can be moved into
  // an initialization.  Returns zero if a check fails.
  // On success, returns the (constant) offset to which the store applies,
  // within the initialized memory.
<span class="udiff-line-modified-removed">- intptr_t InitializeNode::can_capture_store(StoreNode* st, PhaseTransform* phase, bool can_reshape) {</span>
<span class="udiff-line-modified-added">+ intptr_t InitializeNode::can_capture_store(StoreNode* st, PhaseGVN* phase, bool can_reshape) {</span>
    const int FAIL = 0;
<span class="udiff-line-removed">-   if (st-&gt;is_unaligned_access()) {</span>
<span class="udiff-line-removed">-     return FAIL;</span>
<span class="udiff-line-removed">-   }</span>
    if (st-&gt;req() != MemNode::ValueIn + 1)
      return FAIL;                // an inscrutable StoreNode (card mark?)
    Node* ctl = st-&gt;in(MemNode::Control);
    if (!(ctl != NULL &amp;&amp; ctl-&gt;is_Proj() &amp;&amp; ctl-&gt;in(0) == this))
      return FAIL;                // must be unconditional after the initialization
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3565,13 +3613,17 @@</span>
    AllocateNode* alloc = AllocateNode::Ideal_allocation(adr, phase, offset);
    if (alloc == NULL)
      return FAIL;                // inscrutable address
    if (alloc != allocation())
      return FAIL;                // wrong allocation!  (store needs to float up)
<span class="udiff-line-added">+   int size_in_bytes = st-&gt;memory_size();</span>
<span class="udiff-line-added">+   if ((size_in_bytes != 0) &amp;&amp; (offset % size_in_bytes) != 0) {</span>
<span class="udiff-line-added">+     return FAIL;                // mismatched access</span>
<span class="udiff-line-added">+   }</span>
    Node* val = st-&gt;in(MemNode::ValueIn);
<span class="udiff-line-modified-removed">-   int complexity_count = 0;</span>
<span class="udiff-line-modified-removed">-   if (!detect_init_independence(val, complexity_count))</span>
<span class="udiff-line-modified-added">+ </span>
<span class="udiff-line-modified-added">+   if (!detect_init_independence(val, phase))</span>
      return FAIL;                // stored value must be &#39;simple enough&#39;
  
    // The Store can be captured only if nothing after the allocation
    // and before the Store is using the memory location that the store
    // overwrites.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3765,11 +3817,11 @@</span>
  //   rawstore2 = (StoreC alloc.Control alloc.Memory (+ rawoop 14) 2)
  //   init = (Initialize alloc.Control alloc.Memory rawoop
  //                      rawstore1 rawstore2)
  //
  Node* InitializeNode::capture_store(StoreNode* st, intptr_t start,
<span class="udiff-line-modified-removed">-                                     PhaseTransform* phase, bool can_reshape) {</span>
<span class="udiff-line-modified-added">+                                     PhaseGVN* phase, bool can_reshape) {</span>
    assert(stores_are_sane(phase), &quot;&quot;);
  
    if (start &lt; 0)  return NULL;
    assert(can_capture_store(st, phase, can_reshape) == start, &quot;sanity&quot;);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4123,11 +4175,11 @@</span>
  // Linearize the stores by ascending offset, to make memory
  // activity as coherent as possible.
  Node* InitializeNode::complete_stores(Node* rawctl, Node* rawmem, Node* rawptr,
                                        intptr_t header_size,
                                        Node* size_in_bytes,
<span class="udiff-line-modified-removed">-                                       PhaseGVN* phase) {</span>
<span class="udiff-line-modified-added">+                                       PhaseIterGVN* phase) {</span>
    assert(!is_complete(), &quot;not already complete&quot;);
    assert(stores_are_sane(phase), &quot;&quot;);
    assert(allocation() != NULL, &quot;must be present&quot;);
  
    remove_extra_zeroes();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4215,11 +4267,11 @@</span>
            do_zeroing = false;   // leave the hole, next time
        }
      }
  
      // Collect the store and move on:
<span class="udiff-line-modified-removed">-     st-&gt;set_req(MemNode::Memory, inits);</span>
<span class="udiff-line-modified-added">+     phase-&gt;replace_input_of(st, MemNode::Memory, inits);</span>
      inits = st;                 // put it on the linearized chain
      set_req(i, zmem);           // unhook from previous position
  
      if (zeroes_done == st_off)
        zeroes_done = next_init_off;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -4436,11 +4488,11 @@</span>
    return new MergeMemNode(mem);
  }
  
  //------------------------------cmp--------------------------------------------
  uint MergeMemNode::hash() const { return NO_HASH; }
<span class="udiff-line-modified-removed">- uint MergeMemNode::cmp( const Node &amp;n ) const {</span>
<span class="udiff-line-modified-added">+ bool MergeMemNode::cmp( const Node &amp;n ) const {</span>
    return (&amp;n == this);          // Always fail except on self
  }
  
  //------------------------------Identity---------------------------------------
  Node* MergeMemNode::Identity(PhaseGVN* phase) {
</pre>
<center><a href="matcher.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="memnode.hpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>