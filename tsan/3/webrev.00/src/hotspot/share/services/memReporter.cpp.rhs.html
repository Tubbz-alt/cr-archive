<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/services/memReporter.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2012, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 #include &quot;precompiled.hpp&quot;
 25 
 26 #include &quot;memory/allocation.hpp&quot;
 27 #include &quot;services/mallocTracker.hpp&quot;
 28 #include &quot;services/memReporter.hpp&quot;
<a name="1" id="anc1"></a><span class="line-added"> 29 #include &quot;services/threadStackTracker.hpp&quot;</span>
 30 #include &quot;services/virtualMemoryTracker.hpp&quot;
 31 #include &quot;utilities/globalDefinitions.hpp&quot;
 32 
 33 size_t MemReporterBase::reserved_total(const MallocMemory* malloc, const VirtualMemory* vm) const {
 34   return malloc-&gt;malloc_size() + malloc-&gt;arena_size() + vm-&gt;reserved();
 35 }
 36 
 37 size_t MemReporterBase::committed_total(const MallocMemory* malloc, const VirtualMemory* vm) const {
 38   return malloc-&gt;malloc_size() + malloc-&gt;arena_size() + vm-&gt;committed();
 39 }
 40 
 41 void MemReporterBase::print_total(size_t reserved, size_t committed) const {
 42   const char* scale = current_scale();
 43   output()-&gt;print(&quot;reserved=&quot; SIZE_FORMAT &quot;%s, committed=&quot; SIZE_FORMAT &quot;%s&quot;,
 44     amount_in_current_scale(reserved), scale, amount_in_current_scale(committed), scale);
 45 }
 46 
 47 void MemReporterBase::print_malloc(size_t amount, size_t count, MEMFLAGS flag) const {
 48   const char* scale = current_scale();
 49   outputStream* out = output();
<a name="2" id="anc2"></a><span class="line-added"> 50   const char* alloc_type = (flag == mtThreadStack) ? &quot;&quot; : &quot;malloc=&quot;;</span>
<span class="line-added"> 51 </span>
 52   if (flag != mtNone) {
<a name="3" id="anc3"></a><span class="line-modified"> 53     out-&gt;print(&quot;(%s&quot; SIZE_FORMAT &quot;%s type=%s&quot;, alloc_type,</span>
 54       amount_in_current_scale(amount), scale, NMTUtil::flag_to_name(flag));
 55   } else {
<a name="4" id="anc4"></a><span class="line-modified"> 56     out-&gt;print(&quot;(%s&quot; SIZE_FORMAT &quot;%s&quot;, alloc_type,</span>
 57       amount_in_current_scale(amount), scale);
 58   }
 59 
 60   if (count &gt; 0) {
 61     out-&gt;print(&quot; #&quot; SIZE_FORMAT &quot;&quot;, count);
 62   }
 63 
 64   out-&gt;print(&quot;)&quot;);
 65 }
 66 
 67 void MemReporterBase::print_virtual_memory(size_t reserved, size_t committed) const {
 68   const char* scale = current_scale();
 69   output()-&gt;print(&quot;(mmap: reserved=&quot; SIZE_FORMAT &quot;%s, committed=&quot; SIZE_FORMAT &quot;%s)&quot;,
 70     amount_in_current_scale(reserved), scale, amount_in_current_scale(committed), scale);
 71 }
 72 
 73 void MemReporterBase::print_malloc_line(size_t amount, size_t count) const {
 74   output()-&gt;print(&quot;%28s&quot;, &quot; &quot;);
 75   print_malloc(amount, count);
 76   output()-&gt;print_cr(&quot; &quot;);
 77 }
 78 
 79 void MemReporterBase::print_virtual_memory_line(size_t reserved, size_t committed) const {
 80   output()-&gt;print(&quot;%28s&quot;, &quot; &quot;);
 81   print_virtual_memory(reserved, committed);
 82   output()-&gt;print_cr(&quot; &quot;);
 83 }
 84 
 85 void MemReporterBase::print_arena_line(size_t amount, size_t count) const {
 86   const char* scale = current_scale();
 87   output()-&gt;print_cr(&quot;%27s (arena=&quot; SIZE_FORMAT &quot;%s #&quot; SIZE_FORMAT &quot;)&quot;, &quot; &quot;,
 88     amount_in_current_scale(amount), scale, count);
 89 }
 90 
 91 void MemReporterBase::print_virtual_memory_region(const char* type, address base, size_t size) const {
 92   const char* scale = current_scale();
 93   output()-&gt;print(&quot;[&quot; PTR_FORMAT &quot; - &quot; PTR_FORMAT &quot;] %s &quot; SIZE_FORMAT &quot;%s&quot;,
 94     p2i(base), p2i(base + size), type, amount_in_current_scale(size), scale);
 95 }
 96 
 97 
 98 void MemSummaryReporter::report() {
 99   const char* scale = current_scale();
100   outputStream* out = output();
101   size_t total_reserved_amount = _malloc_snapshot-&gt;total() +
102     _vm_snapshot-&gt;total_reserved();
103   size_t total_committed_amount = _malloc_snapshot-&gt;total() +
104     _vm_snapshot-&gt;total_committed();
105 
106   // Overall total
107   out-&gt;print_cr(&quot;\nNative Memory Tracking:\n&quot;);
108   out-&gt;print(&quot;Total: &quot;);
109   print_total(total_reserved_amount, total_committed_amount);
110   out-&gt;print(&quot;\n&quot;);
111 
112   // Summary by memory type
113   for (int index = 0; index &lt; mt_number_of_types; index ++) {
114     MEMFLAGS flag = NMTUtil::index_to_flag(index);
115     // thread stack is reported as part of thread category
116     if (flag == mtThreadStack) continue;
117     MallocMemory* malloc_memory = _malloc_snapshot-&gt;by_type(flag);
118     VirtualMemory* virtual_memory = _vm_snapshot-&gt;by_type(flag);
119 
120     report_summary_of_type(flag, malloc_memory, virtual_memory);
121   }
122 }
123 
124 void MemSummaryReporter::report_summary_of_type(MEMFLAGS flag,
125   MallocMemory*  malloc_memory, VirtualMemory* virtual_memory) {
126 
127   size_t reserved_amount  = reserved_total (malloc_memory, virtual_memory);
128   size_t committed_amount = committed_total(malloc_memory, virtual_memory);
129 
130   // Count thread&#39;s native stack in &quot;Thread&quot; category
131   if (flag == mtThread) {
<a name="5" id="anc5"></a><span class="line-modified">132     if (ThreadStackTracker::track_as_vm()) {</span>
<span class="line-modified">133       const VirtualMemory* thread_stack_usage =</span>
<span class="line-modified">134         (const VirtualMemory*)_vm_snapshot-&gt;by_type(mtThreadStack);</span>
<span class="line-modified">135       reserved_amount  += thread_stack_usage-&gt;reserved();</span>
<span class="line-added">136       committed_amount += thread_stack_usage-&gt;committed();</span>
<span class="line-added">137     } else {</span>
<span class="line-added">138       const MallocMemory* thread_stack_usage =</span>
<span class="line-added">139         (const MallocMemory*)_malloc_snapshot-&gt;by_type(mtThreadStack);</span>
<span class="line-added">140       reserved_amount += thread_stack_usage-&gt;malloc_size();</span>
<span class="line-added">141       committed_amount += thread_stack_usage-&gt;malloc_size();</span>
<span class="line-added">142     }</span>
143   } else if (flag == mtNMT) {
144     // Count malloc headers in &quot;NMT&quot; category
145     reserved_amount  += _malloc_snapshot-&gt;malloc_overhead()-&gt;size();
146     committed_amount += _malloc_snapshot-&gt;malloc_overhead()-&gt;size();
147   }
148 
149   if (amount_in_current_scale(reserved_amount) &gt; 0) {
150     outputStream* out   = output();
151     const char*   scale = current_scale();
152     out-&gt;print(&quot;-%26s (&quot;, NMTUtil::flag_to_name(flag));
153     print_total(reserved_amount, committed_amount);
154     out-&gt;print_cr(&quot;)&quot;);
155 
156     if (flag == mtClass) {
157       // report class count
158       out-&gt;print_cr(&quot;%27s (classes #&quot; SIZE_FORMAT &quot;)&quot;,
159         &quot; &quot;, (_instance_class_count + _array_class_count));
160       out-&gt;print_cr(&quot;%27s (  instance classes #&quot; SIZE_FORMAT &quot;, array classes #&quot; SIZE_FORMAT &quot;)&quot;,
161         &quot; &quot;, _instance_class_count, _array_class_count);
162     } else if (flag == mtThread) {
<a name="6" id="anc6"></a><span class="line-modified">163       if (ThreadStackTracker::track_as_vm()) {</span>
<span class="line-modified">164         const VirtualMemory* thread_stack_usage =</span>
<span class="line-modified">165          _vm_snapshot-&gt;by_type(mtThreadStack);</span>
<span class="line-modified">166         // report thread count</span>
<span class="line-modified">167         out-&gt;print_cr(&quot;%27s (thread #&quot; SIZE_FORMAT &quot;)&quot;, &quot; &quot;, ThreadStackTracker::thread_count());</span>
<span class="line-modified">168         out-&gt;print(&quot;%27s (stack: &quot;, &quot; &quot;);</span>
<span class="line-added">169         print_total(thread_stack_usage-&gt;reserved(), thread_stack_usage-&gt;committed());</span>
<span class="line-added">170       } else {</span>
<span class="line-added">171         MallocMemory* thread_stack_memory = _malloc_snapshot-&gt;by_type(mtThreadStack);</span>
<span class="line-added">172         const char* scale = current_scale();</span>
<span class="line-added">173         // report thread count</span>
<span class="line-added">174         assert(ThreadStackTracker::thread_count() == 0, &quot;Not used&quot;);</span>
<span class="line-added">175         out-&gt;print_cr(&quot;%27s (thread #&quot; SIZE_FORMAT &quot;)&quot;, &quot; &quot;, thread_stack_memory-&gt;malloc_count());</span>
<span class="line-added">176         out-&gt;print(&quot;%27s (Stack: &quot; SIZE_FORMAT &quot;%s&quot;, &quot; &quot;,</span>
<span class="line-added">177           amount_in_current_scale(thread_stack_memory-&gt;malloc_size()), scale);</span>
<span class="line-added">178       }</span>
179       out-&gt;print_cr(&quot;)&quot;);
180     }
181 
182      // report malloc&#39;d memory
183     if (amount_in_current_scale(malloc_memory-&gt;malloc_size()) &gt; 0) {
184       // We don&#39;t know how many arena chunks are in used, so don&#39;t report the count
185       size_t count = (flag == mtChunk) ? 0 : malloc_memory-&gt;malloc_count();
186       print_malloc_line(malloc_memory-&gt;malloc_size(), count);
187     }
188 
189     if (amount_in_current_scale(virtual_memory-&gt;reserved()) &gt; 0) {
190       print_virtual_memory_line(virtual_memory-&gt;reserved(), virtual_memory-&gt;committed());
191     }
192 
193     if (amount_in_current_scale(malloc_memory-&gt;arena_size()) &gt; 0) {
194       print_arena_line(malloc_memory-&gt;arena_size(), malloc_memory-&gt;arena_count());
195     }
196 
197     if (flag == mtNMT &amp;&amp;
198       amount_in_current_scale(_malloc_snapshot-&gt;malloc_overhead()-&gt;size()) &gt; 0) {
199       out-&gt;print_cr(&quot;%27s (tracking overhead=&quot; SIZE_FORMAT &quot;%s)&quot;, &quot; &quot;,
200         amount_in_current_scale(_malloc_snapshot-&gt;malloc_overhead()-&gt;size()), scale);
201     } else if (flag == mtClass) {
202       // Metadata information
203       report_metadata(Metaspace::NonClassType);
204       if (Metaspace::using_class_space()) {
205         report_metadata(Metaspace::ClassType);
206       }
207     }
208     out-&gt;print_cr(&quot; &quot;);
209   }
210 }
211 
212 void MemSummaryReporter::report_metadata(Metaspace::MetadataType type) const {
213   assert(type == Metaspace::NonClassType || type == Metaspace::ClassType,
214     &quot;Invalid metadata type&quot;);
215   const char* name = (type == Metaspace::NonClassType) ?
216     &quot;Metadata:   &quot; : &quot;Class space:&quot;;
217 
218   outputStream* out = output();
219   const char* scale = current_scale();
220   size_t committed   = MetaspaceUtils::committed_bytes(type);
221   size_t used = MetaspaceUtils::used_bytes(type);
222   size_t free = (MetaspaceUtils::capacity_bytes(type) - used)
223               + MetaspaceUtils::free_chunks_total_bytes(type)
224               + MetaspaceUtils::free_in_vs_bytes(type);
225 
226   assert(committed &gt;= used + free, &quot;Sanity&quot;);
227   size_t waste = committed - (used + free);
228 
229   out-&gt;print_cr(&quot;%27s (  %s)&quot;, &quot; &quot;, name);
230   out-&gt;print(&quot;%27s (    &quot;, &quot; &quot;);
231   print_total(MetaspaceUtils::reserved_bytes(type), committed);
232   out-&gt;print_cr(&quot;)&quot;);
233   out-&gt;print_cr(&quot;%27s (    used=&quot; SIZE_FORMAT &quot;%s)&quot;, &quot; &quot;, amount_in_current_scale(used), scale);
234   out-&gt;print_cr(&quot;%27s (    free=&quot; SIZE_FORMAT &quot;%s)&quot;, &quot; &quot;, amount_in_current_scale(free), scale);
235   out-&gt;print_cr(&quot;%27s (    waste=&quot; SIZE_FORMAT &quot;%s =%2.2f%%)&quot;, &quot; &quot;, amount_in_current_scale(waste),
236     scale, ((float)waste * 100)/committed);
237 }
238 
239 void MemDetailReporter::report_detail() {
240   // Start detail report
241   outputStream* out = output();
242   out-&gt;print_cr(&quot;Details:\n&quot;);
243 
244   report_malloc_sites();
245   report_virtual_memory_allocation_sites();
246 }
247 
248 void MemDetailReporter::report_malloc_sites() {
249   MallocSiteIterator         malloc_itr = _baseline.malloc_sites(MemBaseline::by_size);
250   if (malloc_itr.is_empty()) return;
251 
252   outputStream* out = output();
253 
254   const MallocSite* malloc_site;
255   while ((malloc_site = malloc_itr.next()) != NULL) {
256     // Don&#39;t report if size is too small
257     if (amount_in_current_scale(malloc_site-&gt;size()) == 0)
258       continue;
259 
260     const NativeCallStack* stack = malloc_site-&gt;call_stack();
261     stack-&gt;print_on(out);
262     out-&gt;print(&quot;%29s&quot;, &quot; &quot;);
263     MEMFLAGS flag = malloc_site-&gt;flag();
264     assert((flag &gt;= 0 &amp;&amp; flag &lt; (int)mt_number_of_types) &amp;&amp; flag != mtNone,
265       &quot;Must have a valid memory type&quot;);
266     print_malloc(malloc_site-&gt;size(), malloc_site-&gt;count(),flag);
267     out-&gt;print_cr(&quot;\n&quot;);
268   }
269 }
270 
271 void MemDetailReporter::report_virtual_memory_allocation_sites()  {
272   VirtualMemorySiteIterator  virtual_memory_itr =
273     _baseline.virtual_memory_sites(MemBaseline::by_size);
274 
275   if (virtual_memory_itr.is_empty()) return;
276 
277   outputStream* out = output();
278   const VirtualMemoryAllocationSite*  virtual_memory_site;
279 
280   while ((virtual_memory_site = virtual_memory_itr.next()) != NULL) {
281     // Don&#39;t report if size is too small
282     if (amount_in_current_scale(virtual_memory_site-&gt;reserved()) == 0)
283       continue;
284 
285     const NativeCallStack* stack = virtual_memory_site-&gt;call_stack();
286     stack-&gt;print_on(out);
287     out-&gt;print(&quot;%28s (&quot;, &quot; &quot;);
288     print_total(virtual_memory_site-&gt;reserved(), virtual_memory_site-&gt;committed());
289     MEMFLAGS flag = virtual_memory_site-&gt;flag();
290     if (flag != mtNone) {
291       out-&gt;print(&quot; Type=%s&quot;, NMTUtil::flag_to_name(flag));
292     }
293     out-&gt;print_cr(&quot;)\n&quot;);
294   }
295 }
296 
297 
298 void MemDetailReporter::report_virtual_memory_map() {
299   // Virtual memory map always in base address order
300   VirtualMemoryAllocationIterator itr = _baseline.virtual_memory_allocations();
301   const ReservedMemoryRegion* rgn;
302 
303   output()-&gt;print_cr(&quot;Virtual memory map:&quot;);
304   while ((rgn = itr.next()) != NULL) {
305     report_virtual_memory_region(rgn);
306   }
307 }
308 
309 void MemDetailReporter::report_virtual_memory_region(const ReservedMemoryRegion* reserved_rgn) {
310   assert(reserved_rgn != NULL, &quot;NULL pointer&quot;);
311 
312   // Don&#39;t report if size is too small
313   if (amount_in_current_scale(reserved_rgn-&gt;size()) == 0) return;
314 
315   outputStream* out = output();
316   const char* scale = current_scale();
317   const NativeCallStack*  stack = reserved_rgn-&gt;call_stack();
318   bool all_committed = reserved_rgn-&gt;size() == reserved_rgn-&gt;committed_size();
319   const char* region_type = (all_committed ? &quot;reserved and committed&quot; : &quot;reserved&quot;);
320   out-&gt;print_cr(&quot; &quot;);
321   print_virtual_memory_region(region_type, reserved_rgn-&gt;base(), reserved_rgn-&gt;size());
322   out-&gt;print(&quot; for %s&quot;, NMTUtil::flag_to_name(reserved_rgn-&gt;flag()));
323   if (stack-&gt;is_empty()) {
324     out-&gt;print_cr(&quot; &quot;);
325   } else {
326     out-&gt;print_cr(&quot; from&quot;);
327     stack-&gt;print_on(out, 4);
328   }
329 
330   if (all_committed) {
331     CommittedRegionIterator itr = reserved_rgn-&gt;iterate_committed_regions();
332     const CommittedMemoryRegion* committed_rgn = itr.next();
333     if (committed_rgn-&gt;size() == reserved_rgn-&gt;size() &amp;&amp; committed_rgn-&gt;call_stack()-&gt;equals(*stack)) {
334       // One region spanning the entire reserved region, with the same stack trace.
335       // Don&#39;t print this regions because the &quot;reserved and committed&quot; line above
336       // already indicates that the region is comitted.
337       assert(itr.next() == NULL, &quot;Unexpectedly more than one regions&quot;);
338       return;
339     }
340   }
341 
342   CommittedRegionIterator itr = reserved_rgn-&gt;iterate_committed_regions();
343   const CommittedMemoryRegion* committed_rgn;
344   while ((committed_rgn = itr.next()) != NULL) {
345     // Don&#39;t report if size is too small
346     if (amount_in_current_scale(committed_rgn-&gt;size()) == 0) continue;
347     stack = committed_rgn-&gt;call_stack();
348     out-&gt;print(&quot;\n\t&quot;);
349     print_virtual_memory_region(&quot;committed&quot;, committed_rgn-&gt;base(), committed_rgn-&gt;size());
350     if (stack-&gt;is_empty()) {
351       out-&gt;print_cr(&quot; &quot;);
352     } else {
353       out-&gt;print_cr(&quot; from&quot;);
354       stack-&gt;print_on(out, 12);
355     }
356   }
357 }
358 
359 void MemSummaryDiffReporter::report_diff() {
360   const char* scale = current_scale();
361   outputStream* out = output();
362   out-&gt;print_cr(&quot;\nNative Memory Tracking:\n&quot;);
363 
364   // Overall diff
365   out-&gt;print(&quot;Total: &quot;);
366   print_virtual_memory_diff(_current_baseline.total_reserved_memory(),
367     _current_baseline.total_committed_memory(), _early_baseline.total_reserved_memory(),
368     _early_baseline.total_committed_memory());
369 
370   out-&gt;print_cr(&quot;\n&quot;);
371 
372   // Summary diff by memory type
373   for (int index = 0; index &lt; mt_number_of_types; index ++) {
374     MEMFLAGS flag = NMTUtil::index_to_flag(index);
375     // thread stack is reported as part of thread category
376     if (flag == mtThreadStack) continue;
377     diff_summary_of_type(flag,
378       _early_baseline.malloc_memory(flag),
379       _early_baseline.virtual_memory(flag),
380       _early_baseline.metaspace_snapshot(),
381       _current_baseline.malloc_memory(flag),
382       _current_baseline.virtual_memory(flag),
383       _current_baseline.metaspace_snapshot());
384   }
385 }
386 
387 void MemSummaryDiffReporter::print_malloc_diff(size_t current_amount, size_t current_count,
388     size_t early_amount, size_t early_count, MEMFLAGS flags) const {
389   const char* scale = current_scale();
390   outputStream* out = output();
<a name="7" id="anc7"></a><span class="line-added">391   const char* alloc_type = (flags == mtThread) ? &quot;&quot; : &quot;malloc=&quot;;</span>
392 
<a name="8" id="anc8"></a><span class="line-modified">393   out-&gt;print(&quot;%s&quot; SIZE_FORMAT &quot;%s&quot;, alloc_type, amount_in_current_scale(current_amount), scale);</span>
<span class="line-modified">394   // Report type only if it is valid and not under &quot;thread&quot; category</span>
<span class="line-modified">395   if (flags != mtNone &amp;&amp; flags != mtThread) {</span>
396     out-&gt;print(&quot; type=%s&quot;, NMTUtil::flag_to_name(flags));
397   }
398 
399   long amount_diff = diff_in_current_scale(current_amount, early_amount);
400   if (amount_diff != 0) {
401     out-&gt;print(&quot; %+ld%s&quot;, amount_diff, scale);
402   }
403   if (current_count &gt; 0) {
404     out-&gt;print(&quot; #&quot; SIZE_FORMAT &quot;&quot;, current_count);
405     if (current_count != early_count) {
406       out-&gt;print(&quot; %+d&quot;, (int)(current_count - early_count));
407     }
408   }
409 }
410 
411 void MemSummaryDiffReporter::print_arena_diff(size_t current_amount, size_t current_count,
412   size_t early_amount, size_t early_count) const {
413   const char* scale = current_scale();
414   outputStream* out = output();
415   out-&gt;print(&quot;arena=&quot; SIZE_FORMAT &quot;%s&quot;, amount_in_current_scale(current_amount), scale);
416   if (diff_in_current_scale(current_amount, early_amount) != 0) {
417     out-&gt;print(&quot; %+ld&quot;, diff_in_current_scale(current_amount, early_amount));
418   }
419 
420   out-&gt;print(&quot; #&quot; SIZE_FORMAT &quot;&quot;, current_count);
421   if (current_count != early_count) {
422     out-&gt;print(&quot; %+d&quot;, (int)(current_count - early_count));
423   }
424 }
425 
426 void MemSummaryDiffReporter::print_virtual_memory_diff(size_t current_reserved, size_t current_committed,
427     size_t early_reserved, size_t early_committed) const {
428   const char* scale = current_scale();
429   outputStream* out = output();
430   out-&gt;print(&quot;reserved=&quot; SIZE_FORMAT &quot;%s&quot;, amount_in_current_scale(current_reserved), scale);
431   long reserved_diff = diff_in_current_scale(current_reserved, early_reserved);
432   if (reserved_diff != 0) {
433     out-&gt;print(&quot; %+ld%s&quot;, reserved_diff, scale);
434   }
435 
436   out-&gt;print(&quot;, committed=&quot; SIZE_FORMAT &quot;%s&quot;, amount_in_current_scale(current_committed), scale);
437   long committed_diff = diff_in_current_scale(current_committed, early_committed);
438   if (committed_diff != 0) {
439     out-&gt;print(&quot; %+ld%s&quot;, committed_diff, scale);
440   }
441 }
442 
443 
444 void MemSummaryDiffReporter::diff_summary_of_type(MEMFLAGS flag,
445   const MallocMemory* early_malloc, const VirtualMemory* early_vm,
446   const MetaspaceSnapshot* early_ms,
447   const MallocMemory* current_malloc, const VirtualMemory* current_vm,
448   const MetaspaceSnapshot* current_ms) const {
449 
450   outputStream* out = output();
451   const char* scale = current_scale();
452 
453   // Total reserved and committed memory in current baseline
454   size_t current_reserved_amount  = reserved_total (current_malloc, current_vm);
455   size_t current_committed_amount = committed_total(current_malloc, current_vm);
456 
457   // Total reserved and committed memory in early baseline
458   size_t early_reserved_amount  = reserved_total(early_malloc, early_vm);
459   size_t early_committed_amount = committed_total(early_malloc, early_vm);
460 
461   // Adjust virtual memory total
462   if (flag == mtThread) {
463     const VirtualMemory* early_thread_stack_usage =
464       _early_baseline.virtual_memory(mtThreadStack);
465     const VirtualMemory* current_thread_stack_usage =
466       _current_baseline.virtual_memory(mtThreadStack);
467 
468     early_reserved_amount  += early_thread_stack_usage-&gt;reserved();
469     early_committed_amount += early_thread_stack_usage-&gt;committed();
470 
471     current_reserved_amount  += current_thread_stack_usage-&gt;reserved();
472     current_committed_amount += current_thread_stack_usage-&gt;committed();
473   } else if (flag == mtNMT) {
474     early_reserved_amount  += _early_baseline.malloc_tracking_overhead();
475     early_committed_amount += _early_baseline.malloc_tracking_overhead();
476 
477     current_reserved_amount  += _current_baseline.malloc_tracking_overhead();
478     current_committed_amount += _current_baseline.malloc_tracking_overhead();
479   }
480 
481   if (amount_in_current_scale(current_reserved_amount) &gt; 0 ||
482       diff_in_current_scale(current_reserved_amount, early_reserved_amount) != 0) {
483 
484     // print summary line
485     out-&gt;print(&quot;-%26s (&quot;, NMTUtil::flag_to_name(flag));
486     print_virtual_memory_diff(current_reserved_amount, current_committed_amount,
487       early_reserved_amount, early_committed_amount);
488     out-&gt;print_cr(&quot;)&quot;);
489 
490     // detail lines
491     if (flag == mtClass) {
492       // report class count
493       out-&gt;print(&quot;%27s (classes #&quot; SIZE_FORMAT &quot;&quot;, &quot; &quot;, _current_baseline.class_count());
494       int class_count_diff = (int)(_current_baseline.class_count() -
495         _early_baseline.class_count());
496       if (_current_baseline.class_count() != _early_baseline.class_count()) {
497         out-&gt;print(&quot; %+d&quot;, (int)(_current_baseline.class_count() - _early_baseline.class_count()));
498       }
499       out-&gt;print_cr(&quot;)&quot;);
500 
501       out-&gt;print(&quot;%27s (  instance classes #&quot; SIZE_FORMAT, &quot; &quot;, _current_baseline.instance_class_count());
502       if (_current_baseline.instance_class_count() != _early_baseline.instance_class_count()) {
503         out-&gt;print(&quot; %+d&quot;, (int)(_current_baseline.instance_class_count() - _early_baseline.instance_class_count()));
504       }
505       out-&gt;print(&quot;, array classes #&quot; SIZE_FORMAT, _current_baseline.array_class_count());
506       if (_current_baseline.array_class_count() != _early_baseline.array_class_count()) {
507         out-&gt;print(&quot; %+d&quot;, (int)(_current_baseline.array_class_count() - _early_baseline.array_class_count()));
508       }
509       out-&gt;print_cr(&quot;)&quot;);
510 
511     } else if (flag == mtThread) {
512       // report thread count
513       out-&gt;print(&quot;%27s (thread #&quot; SIZE_FORMAT &quot;&quot;, &quot; &quot;, _current_baseline.thread_count());
514       int thread_count_diff = (int)(_current_baseline.thread_count() -
515           _early_baseline.thread_count());
516       if (thread_count_diff != 0) {
517         out-&gt;print(&quot; %+d&quot;, thread_count_diff);
518       }
519       out-&gt;print_cr(&quot;)&quot;);
520 
<a name="9" id="anc9"></a>





521       out-&gt;print(&quot;%27s (stack: &quot;, &quot; &quot;);
<a name="10" id="anc10"></a><span class="line-modified">522       if (ThreadStackTracker::track_as_vm()) {</span>
<span class="line-modified">523         // report thread stack</span>
<span class="line-added">524         const VirtualMemory* current_thread_stack =</span>
<span class="line-added">525           _current_baseline.virtual_memory(mtThreadStack);</span>
<span class="line-added">526         const VirtualMemory* early_thread_stack =</span>
<span class="line-added">527           _early_baseline.virtual_memory(mtThreadStack);</span>
<span class="line-added">528 </span>
<span class="line-added">529         print_virtual_memory_diff(current_thread_stack-&gt;reserved(), current_thread_stack-&gt;committed(),</span>
<span class="line-added">530           early_thread_stack-&gt;reserved(), early_thread_stack-&gt;committed());</span>
<span class="line-added">531       } else {</span>
<span class="line-added">532         const MallocMemory* current_thread_stack =</span>
<span class="line-added">533           _current_baseline.malloc_memory(mtThreadStack);</span>
<span class="line-added">534         const MallocMemory* early_thread_stack =</span>
<span class="line-added">535           _early_baseline.malloc_memory(mtThreadStack);</span>
<span class="line-added">536 </span>
<span class="line-added">537         print_malloc_diff(current_thread_stack-&gt;malloc_size(), current_thread_stack-&gt;malloc_count(),</span>
<span class="line-added">538           early_thread_stack-&gt;malloc_size(), early_thread_stack-&gt;malloc_count(), flag);</span>
<span class="line-added">539       }</span>
540       out-&gt;print_cr(&quot;)&quot;);
541     }
542 
543     // Report malloc&#39;d memory
544     size_t current_malloc_amount = current_malloc-&gt;malloc_size();
545     size_t early_malloc_amount   = early_malloc-&gt;malloc_size();
546     if (amount_in_current_scale(current_malloc_amount) &gt; 0 ||
547         diff_in_current_scale(current_malloc_amount, early_malloc_amount) != 0) {
548       out-&gt;print(&quot;%28s(&quot;, &quot; &quot;);
549       print_malloc_diff(current_malloc_amount, (flag == mtChunk) ? 0 : current_malloc-&gt;malloc_count(),
550         early_malloc_amount, early_malloc-&gt;malloc_count(), mtNone);
551       out-&gt;print_cr(&quot;)&quot;);
552     }
553 
554     // Report virtual memory
555     if (amount_in_current_scale(current_vm-&gt;reserved()) &gt; 0 ||
556         diff_in_current_scale(current_vm-&gt;reserved(), early_vm-&gt;reserved()) != 0) {
557       out-&gt;print(&quot;%27s (mmap: &quot;, &quot; &quot;);
558       print_virtual_memory_diff(current_vm-&gt;reserved(), current_vm-&gt;committed(),
559         early_vm-&gt;reserved(), early_vm-&gt;committed());
560       out-&gt;print_cr(&quot;)&quot;);
561     }
562 
563     // Report arena memory
564     if (amount_in_current_scale(current_malloc-&gt;arena_size()) &gt; 0 ||
565         diff_in_current_scale(current_malloc-&gt;arena_size(), early_malloc-&gt;arena_size()) != 0) {
566       out-&gt;print(&quot;%28s(&quot;, &quot; &quot;);
567       print_arena_diff(current_malloc-&gt;arena_size(), current_malloc-&gt;arena_count(),
568         early_malloc-&gt;arena_size(), early_malloc-&gt;arena_count());
569       out-&gt;print_cr(&quot;)&quot;);
570     }
571 
572     // Report native memory tracking overhead
573     if (flag == mtNMT) {
574       size_t current_tracking_overhead = amount_in_current_scale(_current_baseline.malloc_tracking_overhead());
575       size_t early_tracking_overhead   = amount_in_current_scale(_early_baseline.malloc_tracking_overhead());
576 
577       out-&gt;print(&quot;%27s (tracking overhead=&quot; SIZE_FORMAT &quot;%s&quot;, &quot; &quot;,
578         amount_in_current_scale(_current_baseline.malloc_tracking_overhead()), scale);
579 
580       long overhead_diff = diff_in_current_scale(_current_baseline.malloc_tracking_overhead(),
581            _early_baseline.malloc_tracking_overhead());
582       if (overhead_diff != 0) {
583         out-&gt;print(&quot; %+ld%s&quot;, overhead_diff, scale);
584       }
585       out-&gt;print_cr(&quot;)&quot;);
586     } else if (flag == mtClass) {
587       assert(current_ms != NULL &amp;&amp; early_ms != NULL, &quot;Sanity&quot;);
588       print_metaspace_diff(current_ms, early_ms);
589     }
590     out-&gt;print_cr(&quot; &quot;);
591   }
592 }
593 
594 void MemSummaryDiffReporter::print_metaspace_diff(const MetaspaceSnapshot* current_ms,
595                                                   const MetaspaceSnapshot* early_ms) const {
596   print_metaspace_diff(Metaspace::NonClassType, current_ms, early_ms);
597   if (Metaspace::using_class_space()) {
598     print_metaspace_diff(Metaspace::ClassType, current_ms, early_ms);
599   }
600 }
601 
602 void MemSummaryDiffReporter::print_metaspace_diff(Metaspace::MetadataType type,
603                                                   const MetaspaceSnapshot* current_ms,
604                                                   const MetaspaceSnapshot* early_ms) const {
605   const char* name = (type == Metaspace::NonClassType) ?
606     &quot;Metadata:   &quot; : &quot;Class space:&quot;;
607 
608   outputStream* out = output();
609   const char* scale = current_scale();
610 
611   out-&gt;print_cr(&quot;%27s (  %s)&quot;, &quot; &quot;, name);
612   out-&gt;print(&quot;%27s (    &quot;, &quot; &quot;);
613   print_virtual_memory_diff(current_ms-&gt;reserved_in_bytes(type),
614                             current_ms-&gt;committed_in_bytes(type),
615                             early_ms-&gt;reserved_in_bytes(type),
616                             early_ms-&gt;committed_in_bytes(type));
617   out-&gt;print_cr(&quot;)&quot;);
618 
619   long diff_used = diff_in_current_scale(current_ms-&gt;used_in_bytes(type),
620                                          early_ms-&gt;used_in_bytes(type));
621   long diff_free = diff_in_current_scale(current_ms-&gt;free_in_bytes(type),
622                                          early_ms-&gt;free_in_bytes(type));
623 
624   size_t current_waste = current_ms-&gt;committed_in_bytes(type)
625     - (current_ms-&gt;used_in_bytes(type) + current_ms-&gt;free_in_bytes(type));
626   size_t early_waste = early_ms-&gt;committed_in_bytes(type)
627     - (early_ms-&gt;used_in_bytes(type) + early_ms-&gt;free_in_bytes(type));
628   long diff_waste = diff_in_current_scale(current_waste, early_waste);
629 
630   // Diff used
631   out-&gt;print(&quot;%27s (    used=&quot; SIZE_FORMAT &quot;%s&quot;, &quot; &quot;,
632     amount_in_current_scale(current_ms-&gt;used_in_bytes(type)), scale);
633   if (diff_used != 0) {
634     out-&gt;print(&quot; %+ld%s&quot;, diff_used, scale);
635   }
636   out-&gt;print_cr(&quot;)&quot;);
637 
638   // Diff free
639   out-&gt;print(&quot;%27s (    free=&quot; SIZE_FORMAT &quot;%s&quot;, &quot; &quot;,
640     amount_in_current_scale(current_ms-&gt;free_in_bytes(type)), scale);
641   if (diff_free != 0) {
642     out-&gt;print(&quot; %+ld%s&quot;, diff_free, scale);
643   }
644   out-&gt;print_cr(&quot;)&quot;);
645 
646 
647   // Diff waste
648   out-&gt;print(&quot;%27s (    waste=&quot; SIZE_FORMAT &quot;%s =%2.2f%%&quot;, &quot; &quot;,
649     amount_in_current_scale(current_waste), scale,
650     ((float)current_waste * 100) / current_ms-&gt;committed_in_bytes(type));
651   if (diff_waste != 0) {
652     out-&gt;print(&quot; %+ld%s&quot;, diff_waste, scale);
653   }
654   out-&gt;print_cr(&quot;)&quot;);
655 }
656 
657 void MemDetailDiffReporter::report_diff() {
658   MemSummaryDiffReporter::report_diff();
659   diff_malloc_sites();
660   diff_virtual_memory_sites();
661 }
662 
663 void MemDetailDiffReporter::diff_malloc_sites() const {
664   MallocSiteIterator early_itr = _early_baseline.malloc_sites(MemBaseline::by_site_and_type);
665   MallocSiteIterator current_itr = _current_baseline.malloc_sites(MemBaseline::by_site_and_type);
666 
667   const MallocSite* early_site   = early_itr.next();
668   const MallocSite* current_site = current_itr.next();
669 
670   while (early_site != NULL || current_site != NULL) {
671     if (early_site == NULL) {
672       new_malloc_site(current_site);
673       current_site = current_itr.next();
674     } else if (current_site == NULL) {
675       old_malloc_site(early_site);
676       early_site = early_itr.next();
677     } else {
678       int compVal = current_site-&gt;call_stack()-&gt;compare(*early_site-&gt;call_stack());
679       if (compVal &lt; 0) {
680         new_malloc_site(current_site);
681         current_site = current_itr.next();
682       } else if (compVal &gt; 0) {
683         old_malloc_site(early_site);
684         early_site = early_itr.next();
685       } else {
686         diff_malloc_site(early_site, current_site);
687         early_site   = early_itr.next();
688         current_site = current_itr.next();
689       }
690     }
691   }
692 }
693 
694 void MemDetailDiffReporter::diff_virtual_memory_sites() const {
695   VirtualMemorySiteIterator early_itr = _early_baseline.virtual_memory_sites(MemBaseline::by_site);
696   VirtualMemorySiteIterator current_itr = _current_baseline.virtual_memory_sites(MemBaseline::by_site);
697 
698   const VirtualMemoryAllocationSite* early_site   = early_itr.next();
699   const VirtualMemoryAllocationSite* current_site = current_itr.next();
700 
701   while (early_site != NULL || current_site != NULL) {
702     if (early_site == NULL) {
703       new_virtual_memory_site(current_site);
704       current_site = current_itr.next();
705     } else if (current_site == NULL) {
706       old_virtual_memory_site(early_site);
707       early_site = early_itr.next();
708     } else {
709       int compVal = current_site-&gt;call_stack()-&gt;compare(*early_site-&gt;call_stack());
710       if (compVal &lt; 0) {
711         new_virtual_memory_site(current_site);
712         current_site = current_itr.next();
713       } else if (compVal &gt; 0) {
714         old_virtual_memory_site(early_site);
715         early_site = early_itr.next();
716       } else {
717         diff_virtual_memory_site(early_site, current_site);
718         early_site   = early_itr.next();
719         current_site = current_itr.next();
720       }
721     }
722   }
723 }
724 
725 
726 void MemDetailDiffReporter::new_malloc_site(const MallocSite* malloc_site) const {
727   diff_malloc_site(malloc_site-&gt;call_stack(), malloc_site-&gt;size(), malloc_site-&gt;count(),
728     0, 0, malloc_site-&gt;flag());
729 }
730 
731 void MemDetailDiffReporter::old_malloc_site(const MallocSite* malloc_site) const {
732   diff_malloc_site(malloc_site-&gt;call_stack(), 0, 0, malloc_site-&gt;size(),
733     malloc_site-&gt;count(), malloc_site-&gt;flag());
734 }
735 
736 void MemDetailDiffReporter::diff_malloc_site(const MallocSite* early,
737   const MallocSite* current)  const {
738   if (early-&gt;flag() != current-&gt;flag()) {
739     // If malloc site type changed, treat it as deallocation of old type and
740     // allocation of new type.
741     old_malloc_site(early);
742     new_malloc_site(current);
743   } else {
744     diff_malloc_site(current-&gt;call_stack(), current-&gt;size(), current-&gt;count(),
745       early-&gt;size(), early-&gt;count(), early-&gt;flag());
746   }
747 }
748 
749 void MemDetailDiffReporter::diff_malloc_site(const NativeCallStack* stack, size_t current_size,
750   size_t current_count, size_t early_size, size_t early_count, MEMFLAGS flags) const {
751   outputStream* out = output();
752 
753   assert(stack != NULL, &quot;NULL stack&quot;);
754 
755   if (diff_in_current_scale(current_size, early_size) == 0) {
756       return;
757   }
758 
759   stack-&gt;print_on(out);
760   out-&gt;print(&quot;%28s (&quot;, &quot; &quot;);
761   print_malloc_diff(current_size, current_count,
762     early_size, early_count, flags);
763 
764   out-&gt;print_cr(&quot;)\n&quot;);
765 }
766 
767 
768 void MemDetailDiffReporter::new_virtual_memory_site(const VirtualMemoryAllocationSite* site) const {
769   diff_virtual_memory_site(site-&gt;call_stack(), site-&gt;reserved(), site-&gt;committed(), 0, 0, site-&gt;flag());
770 }
771 
772 void MemDetailDiffReporter::old_virtual_memory_site(const VirtualMemoryAllocationSite* site) const {
773   diff_virtual_memory_site(site-&gt;call_stack(), 0, 0, site-&gt;reserved(), site-&gt;committed(), site-&gt;flag());
774 }
775 
776 void MemDetailDiffReporter::diff_virtual_memory_site(const VirtualMemoryAllocationSite* early,
777   const VirtualMemoryAllocationSite* current) const {
778   assert(early-&gt;flag() == current-&gt;flag(), &quot;Should be the same&quot;);
779   diff_virtual_memory_site(current-&gt;call_stack(), current-&gt;reserved(), current-&gt;committed(),
780     early-&gt;reserved(), early-&gt;committed(), current-&gt;flag());
781 }
782 
783 void MemDetailDiffReporter::diff_virtual_memory_site(const NativeCallStack* stack, size_t current_reserved,
784   size_t current_committed, size_t early_reserved, size_t early_committed, MEMFLAGS flag) const  {
785   outputStream* out = output();
786 
787   // no change
788   if (diff_in_current_scale(current_reserved, early_reserved) == 0 &amp;&amp;
789       diff_in_current_scale(current_committed, early_committed) == 0) {
790     return;
791   }
792 
793   stack-&gt;print_on(out);
794   out-&gt;print(&quot;%28s (mmap: &quot;, &quot; &quot;);
795   print_virtual_memory_diff(current_reserved, current_committed,
796     early_reserved, early_committed);
797 
798   if (flag != mtNone) {
799     out-&gt;print(&quot; Type=%s&quot;, NMTUtil::flag_to_name(flag));
800   }
801 
802   out-&gt;print_cr(&quot;)\n&quot;);
803  }
<a name="11" id="anc11"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="11" type="hidden" />
</body>
</html>