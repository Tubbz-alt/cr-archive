<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/services/memReporter.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2012, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 #include &quot;precompiled.hpp&quot;
 25 
 26 #include &quot;memory/allocation.hpp&quot;
 27 #include &quot;services/mallocTracker.hpp&quot;
 28 #include &quot;services/memReporter.hpp&quot;
 29 #include &quot;services/virtualMemoryTracker.hpp&quot;
 30 #include &quot;utilities/globalDefinitions.hpp&quot;
 31 
 32 size_t MemReporterBase::reserved_total(const MallocMemory* malloc, const VirtualMemory* vm) const {
 33   return malloc-&gt;malloc_size() + malloc-&gt;arena_size() + vm-&gt;reserved();
 34 }
 35 
 36 size_t MemReporterBase::committed_total(const MallocMemory* malloc, const VirtualMemory* vm) const {
 37   return malloc-&gt;malloc_size() + malloc-&gt;arena_size() + vm-&gt;committed();
 38 }
 39 
 40 void MemReporterBase::print_total(size_t reserved, size_t committed) const {
 41   const char* scale = current_scale();
 42   output()-&gt;print(&quot;reserved=&quot; SIZE_FORMAT &quot;%s, committed=&quot; SIZE_FORMAT &quot;%s&quot;,
 43     amount_in_current_scale(reserved), scale, amount_in_current_scale(committed), scale);
 44 }
 45 
 46 void MemReporterBase::print_malloc(size_t amount, size_t count, MEMFLAGS flag) const {
 47   const char* scale = current_scale();
 48   outputStream* out = output();
 49   if (flag != mtNone) {
 50     out-&gt;print(&quot;(malloc=&quot; SIZE_FORMAT &quot;%s type=%s&quot;,
 51       amount_in_current_scale(amount), scale, NMTUtil::flag_to_name(flag));
 52   } else {
 53     out-&gt;print(&quot;(malloc=&quot; SIZE_FORMAT &quot;%s&quot;,
 54       amount_in_current_scale(amount), scale);
 55   }
 56 
 57   if (count &gt; 0) {
 58     out-&gt;print(&quot; #&quot; SIZE_FORMAT &quot;&quot;, count);
 59   }
 60 
 61   out-&gt;print(&quot;)&quot;);
 62 }
 63 
 64 void MemReporterBase::print_virtual_memory(size_t reserved, size_t committed) const {
 65   const char* scale = current_scale();
 66   output()-&gt;print(&quot;(mmap: reserved=&quot; SIZE_FORMAT &quot;%s, committed=&quot; SIZE_FORMAT &quot;%s)&quot;,
 67     amount_in_current_scale(reserved), scale, amount_in_current_scale(committed), scale);
 68 }
 69 
 70 void MemReporterBase::print_malloc_line(size_t amount, size_t count) const {
 71   output()-&gt;print(&quot;%28s&quot;, &quot; &quot;);
 72   print_malloc(amount, count);
 73   output()-&gt;print_cr(&quot; &quot;);
 74 }
 75 
 76 void MemReporterBase::print_virtual_memory_line(size_t reserved, size_t committed) const {
 77   output()-&gt;print(&quot;%28s&quot;, &quot; &quot;);
 78   print_virtual_memory(reserved, committed);
 79   output()-&gt;print_cr(&quot; &quot;);
 80 }
 81 
 82 void MemReporterBase::print_arena_line(size_t amount, size_t count) const {
 83   const char* scale = current_scale();
 84   output()-&gt;print_cr(&quot;%27s (arena=&quot; SIZE_FORMAT &quot;%s #&quot; SIZE_FORMAT &quot;)&quot;, &quot; &quot;,
 85     amount_in_current_scale(amount), scale, count);
 86 }
 87 
 88 void MemReporterBase::print_virtual_memory_region(const char* type, address base, size_t size) const {
 89   const char* scale = current_scale();
 90   output()-&gt;print(&quot;[&quot; PTR_FORMAT &quot; - &quot; PTR_FORMAT &quot;] %s &quot; SIZE_FORMAT &quot;%s&quot;,
 91     p2i(base), p2i(base + size), type, amount_in_current_scale(size), scale);
 92 }
 93 
 94 
 95 void MemSummaryReporter::report() {
 96   const char* scale = current_scale();
 97   outputStream* out = output();
 98   size_t total_reserved_amount = _malloc_snapshot-&gt;total() +
 99     _vm_snapshot-&gt;total_reserved();
100   size_t total_committed_amount = _malloc_snapshot-&gt;total() +
101     _vm_snapshot-&gt;total_committed();
102 
103   // Overall total
104   out-&gt;print_cr(&quot;\nNative Memory Tracking:\n&quot;);
105   out-&gt;print(&quot;Total: &quot;);
106   print_total(total_reserved_amount, total_committed_amount);
107   out-&gt;print(&quot;\n&quot;);
108 
109   // Summary by memory type
110   for (int index = 0; index &lt; mt_number_of_types; index ++) {
111     MEMFLAGS flag = NMTUtil::index_to_flag(index);
112     // thread stack is reported as part of thread category
113     if (flag == mtThreadStack) continue;
114     MallocMemory* malloc_memory = _malloc_snapshot-&gt;by_type(flag);
115     VirtualMemory* virtual_memory = _vm_snapshot-&gt;by_type(flag);
116 
117     report_summary_of_type(flag, malloc_memory, virtual_memory);
118   }
119 }
120 
121 void MemSummaryReporter::report_summary_of_type(MEMFLAGS flag,
122   MallocMemory*  malloc_memory, VirtualMemory* virtual_memory) {
123 
124   size_t reserved_amount  = reserved_total (malloc_memory, virtual_memory);
125   size_t committed_amount = committed_total(malloc_memory, virtual_memory);
126 
127   // Count thread&#39;s native stack in &quot;Thread&quot; category
128   if (flag == mtThread) {
129     const VirtualMemory* thread_stack_usage =
130       (const VirtualMemory*)_vm_snapshot-&gt;by_type(mtThreadStack);
131     reserved_amount  += thread_stack_usage-&gt;reserved();
132     committed_amount += thread_stack_usage-&gt;committed();
133   } else if (flag == mtNMT) {
134     // Count malloc headers in &quot;NMT&quot; category
135     reserved_amount  += _malloc_snapshot-&gt;malloc_overhead()-&gt;size();
136     committed_amount += _malloc_snapshot-&gt;malloc_overhead()-&gt;size();
137   }
138 
139   if (amount_in_current_scale(reserved_amount) &gt; 0) {
140     outputStream* out   = output();
141     const char*   scale = current_scale();
142     out-&gt;print(&quot;-%26s (&quot;, NMTUtil::flag_to_name(flag));
143     print_total(reserved_amount, committed_amount);
144     out-&gt;print_cr(&quot;)&quot;);
145 
146     if (flag == mtClass) {
147       // report class count
148       out-&gt;print_cr(&quot;%27s (classes #&quot; SIZE_FORMAT &quot;)&quot;,
149         &quot; &quot;, (_instance_class_count + _array_class_count));
150       out-&gt;print_cr(&quot;%27s (  instance classes #&quot; SIZE_FORMAT &quot;, array classes #&quot; SIZE_FORMAT &quot;)&quot;,
151         &quot; &quot;, _instance_class_count, _array_class_count);
152     } else if (flag == mtThread) {
153       // report thread count
154       out-&gt;print_cr(&quot;%27s (thread #&quot; SIZE_FORMAT &quot;)&quot;, &quot; &quot;, _malloc_snapshot-&gt;thread_count());
155       const VirtualMemory* thread_stack_usage =
156        _vm_snapshot-&gt;by_type(mtThreadStack);
157       out-&gt;print(&quot;%27s (stack: &quot;, &quot; &quot;);
158       print_total(thread_stack_usage-&gt;reserved(), thread_stack_usage-&gt;committed());
159       out-&gt;print_cr(&quot;)&quot;);
160     }
161 
162      // report malloc&#39;d memory
163     if (amount_in_current_scale(malloc_memory-&gt;malloc_size()) &gt; 0) {
164       // We don&#39;t know how many arena chunks are in used, so don&#39;t report the count
165       size_t count = (flag == mtChunk) ? 0 : malloc_memory-&gt;malloc_count();
166       print_malloc_line(malloc_memory-&gt;malloc_size(), count);
167     }
168 
169     if (amount_in_current_scale(virtual_memory-&gt;reserved()) &gt; 0) {
170       print_virtual_memory_line(virtual_memory-&gt;reserved(), virtual_memory-&gt;committed());
171     }
172 
173     if (amount_in_current_scale(malloc_memory-&gt;arena_size()) &gt; 0) {
174       print_arena_line(malloc_memory-&gt;arena_size(), malloc_memory-&gt;arena_count());
175     }
176 
177     if (flag == mtNMT &amp;&amp;
178       amount_in_current_scale(_malloc_snapshot-&gt;malloc_overhead()-&gt;size()) &gt; 0) {
179       out-&gt;print_cr(&quot;%27s (tracking overhead=&quot; SIZE_FORMAT &quot;%s)&quot;, &quot; &quot;,
180         amount_in_current_scale(_malloc_snapshot-&gt;malloc_overhead()-&gt;size()), scale);
181     } else if (flag == mtClass) {
182       // Metadata information
183       report_metadata(Metaspace::NonClassType);
184       if (Metaspace::using_class_space()) {
185         report_metadata(Metaspace::ClassType);
186       }
187     }
188     out-&gt;print_cr(&quot; &quot;);
189   }
190 }
191 
192 void MemSummaryReporter::report_metadata(Metaspace::MetadataType type) const {
193   assert(type == Metaspace::NonClassType || type == Metaspace::ClassType,
194     &quot;Invalid metadata type&quot;);
195   const char* name = (type == Metaspace::NonClassType) ?
196     &quot;Metadata:   &quot; : &quot;Class space:&quot;;
197 
198   outputStream* out = output();
199   const char* scale = current_scale();
200   size_t committed   = MetaspaceUtils::committed_bytes(type);
201   size_t used = MetaspaceUtils::used_bytes(type);
202   size_t free = (MetaspaceUtils::capacity_bytes(type) - used)
203               + MetaspaceUtils::free_chunks_total_bytes(type)
204               + MetaspaceUtils::free_in_vs_bytes(type);
205 
206   assert(committed &gt;= used + free, &quot;Sanity&quot;);
207   size_t waste = committed - (used + free);
208 
209   out-&gt;print_cr(&quot;%27s (  %s)&quot;, &quot; &quot;, name);
210   out-&gt;print(&quot;%27s (    &quot;, &quot; &quot;);
211   print_total(MetaspaceUtils::reserved_bytes(type), committed);
212   out-&gt;print_cr(&quot;)&quot;);
213   out-&gt;print_cr(&quot;%27s (    used=&quot; SIZE_FORMAT &quot;%s)&quot;, &quot; &quot;, amount_in_current_scale(used), scale);
214   out-&gt;print_cr(&quot;%27s (    free=&quot; SIZE_FORMAT &quot;%s)&quot;, &quot; &quot;, amount_in_current_scale(free), scale);
215   out-&gt;print_cr(&quot;%27s (    waste=&quot; SIZE_FORMAT &quot;%s =%2.2f%%)&quot;, &quot; &quot;, amount_in_current_scale(waste),
216     scale, ((float)waste * 100)/committed);
217 }
218 
219 void MemDetailReporter::report_detail() {
220   // Start detail report
221   outputStream* out = output();
222   out-&gt;print_cr(&quot;Details:\n&quot;);
223 
224   report_malloc_sites();
225   report_virtual_memory_allocation_sites();
226 }
227 
228 void MemDetailReporter::report_malloc_sites() {
229   MallocSiteIterator         malloc_itr = _baseline.malloc_sites(MemBaseline::by_size);
230   if (malloc_itr.is_empty()) return;
231 
232   outputStream* out = output();
233 
234   const MallocSite* malloc_site;
235   while ((malloc_site = malloc_itr.next()) != NULL) {
236     // Don&#39;t report if size is too small
237     if (amount_in_current_scale(malloc_site-&gt;size()) == 0)
238       continue;
239 
240     const NativeCallStack* stack = malloc_site-&gt;call_stack();
241     stack-&gt;print_on(out);
242     out-&gt;print(&quot;%29s&quot;, &quot; &quot;);
243     MEMFLAGS flag = malloc_site-&gt;flag();
244     assert((flag &gt;= 0 &amp;&amp; flag &lt; (int)mt_number_of_types) &amp;&amp; flag != mtNone,
245       &quot;Must have a valid memory type&quot;);
246     print_malloc(malloc_site-&gt;size(), malloc_site-&gt;count(),flag);
247     out-&gt;print_cr(&quot;\n&quot;);
248   }
249 }
250 
251 void MemDetailReporter::report_virtual_memory_allocation_sites()  {
252   VirtualMemorySiteIterator  virtual_memory_itr =
253     _baseline.virtual_memory_sites(MemBaseline::by_size);
254 
255   if (virtual_memory_itr.is_empty()) return;
256 
257   outputStream* out = output();
258   const VirtualMemoryAllocationSite*  virtual_memory_site;
259 
260   while ((virtual_memory_site = virtual_memory_itr.next()) != NULL) {
261     // Don&#39;t report if size is too small
262     if (amount_in_current_scale(virtual_memory_site-&gt;reserved()) == 0)
263       continue;
264 
265     const NativeCallStack* stack = virtual_memory_site-&gt;call_stack();
266     stack-&gt;print_on(out);
267     out-&gt;print(&quot;%28s (&quot;, &quot; &quot;);
268     print_total(virtual_memory_site-&gt;reserved(), virtual_memory_site-&gt;committed());
269     MEMFLAGS flag = virtual_memory_site-&gt;flag();
270     if (flag != mtNone) {
271       out-&gt;print(&quot; Type=%s&quot;, NMTUtil::flag_to_name(flag));
272     }
273     out-&gt;print_cr(&quot;)\n&quot;);
274   }
275 }
276 
277 
278 void MemDetailReporter::report_virtual_memory_map() {
279   // Virtual memory map always in base address order
280   VirtualMemoryAllocationIterator itr = _baseline.virtual_memory_allocations();
281   const ReservedMemoryRegion* rgn;
282 
283   output()-&gt;print_cr(&quot;Virtual memory map:&quot;);
284   while ((rgn = itr.next()) != NULL) {
285     report_virtual_memory_region(rgn);
286   }
287 }
288 
289 void MemDetailReporter::report_virtual_memory_region(const ReservedMemoryRegion* reserved_rgn) {
290   assert(reserved_rgn != NULL, &quot;NULL pointer&quot;);
291 
292   // Don&#39;t report if size is too small
293   if (amount_in_current_scale(reserved_rgn-&gt;size()) == 0) return;
294 
295   outputStream* out = output();
296   const char* scale = current_scale();
297   const NativeCallStack*  stack = reserved_rgn-&gt;call_stack();
298   bool all_committed = reserved_rgn-&gt;size() == reserved_rgn-&gt;committed_size();
299   const char* region_type = (all_committed ? &quot;reserved and committed&quot; : &quot;reserved&quot;);
300   out-&gt;print_cr(&quot; &quot;);
301   print_virtual_memory_region(region_type, reserved_rgn-&gt;base(), reserved_rgn-&gt;size());
302   out-&gt;print(&quot; for %s&quot;, NMTUtil::flag_to_name(reserved_rgn-&gt;flag()));
303   if (stack-&gt;is_empty()) {
304     out-&gt;print_cr(&quot; &quot;);
305   } else {
306     out-&gt;print_cr(&quot; from&quot;);
307     stack-&gt;print_on(out, 4);
308   }
309 
310   if (all_committed) {
311     CommittedRegionIterator itr = reserved_rgn-&gt;iterate_committed_regions();
312     const CommittedMemoryRegion* committed_rgn = itr.next();
313     if (committed_rgn-&gt;size() == reserved_rgn-&gt;size() &amp;&amp; committed_rgn-&gt;call_stack()-&gt;equals(*stack)) {
314       // One region spanning the entire reserved region, with the same stack trace.
315       // Don&#39;t print this regions because the &quot;reserved and committed&quot; line above
316       // already indicates that the region is comitted.
317       assert(itr.next() == NULL, &quot;Unexpectedly more than one regions&quot;);
318       return;
319     }
320   }
321 
322   CommittedRegionIterator itr = reserved_rgn-&gt;iterate_committed_regions();
323   const CommittedMemoryRegion* committed_rgn;
324   while ((committed_rgn = itr.next()) != NULL) {
325     // Don&#39;t report if size is too small
326     if (amount_in_current_scale(committed_rgn-&gt;size()) == 0) continue;
327     stack = committed_rgn-&gt;call_stack();
328     out-&gt;print(&quot;\n\t&quot;);
329     print_virtual_memory_region(&quot;committed&quot;, committed_rgn-&gt;base(), committed_rgn-&gt;size());
330     if (stack-&gt;is_empty()) {
331       out-&gt;print_cr(&quot; &quot;);
332     } else {
333       out-&gt;print_cr(&quot; from&quot;);
334       stack-&gt;print_on(out, 12);
335     }
336   }
337 }
338 
339 void MemSummaryDiffReporter::report_diff() {
340   const char* scale = current_scale();
341   outputStream* out = output();
342   out-&gt;print_cr(&quot;\nNative Memory Tracking:\n&quot;);
343 
344   // Overall diff
345   out-&gt;print(&quot;Total: &quot;);
346   print_virtual_memory_diff(_current_baseline.total_reserved_memory(),
347     _current_baseline.total_committed_memory(), _early_baseline.total_reserved_memory(),
348     _early_baseline.total_committed_memory());
349 
350   out-&gt;print_cr(&quot;\n&quot;);
351 
352   // Summary diff by memory type
353   for (int index = 0; index &lt; mt_number_of_types; index ++) {
354     MEMFLAGS flag = NMTUtil::index_to_flag(index);
355     // thread stack is reported as part of thread category
356     if (flag == mtThreadStack) continue;
357     diff_summary_of_type(flag,
358       _early_baseline.malloc_memory(flag),
359       _early_baseline.virtual_memory(flag),
360       _early_baseline.metaspace_snapshot(),
361       _current_baseline.malloc_memory(flag),
362       _current_baseline.virtual_memory(flag),
363       _current_baseline.metaspace_snapshot());
364   }
365 }
366 
367 void MemSummaryDiffReporter::print_malloc_diff(size_t current_amount, size_t current_count,
368     size_t early_amount, size_t early_count, MEMFLAGS flags) const {
369   const char* scale = current_scale();
370   outputStream* out = output();
371 
372   out-&gt;print(&quot;malloc=&quot; SIZE_FORMAT &quot;%s&quot;, amount_in_current_scale(current_amount), scale);
373   // Report type only if it is valid
374   if (flags != mtNone) {
375     out-&gt;print(&quot; type=%s&quot;, NMTUtil::flag_to_name(flags));
376   }
377 
378   long amount_diff = diff_in_current_scale(current_amount, early_amount);
379   if (amount_diff != 0) {
380     out-&gt;print(&quot; %+ld%s&quot;, amount_diff, scale);
381   }
382   if (current_count &gt; 0) {
383     out-&gt;print(&quot; #&quot; SIZE_FORMAT &quot;&quot;, current_count);
384     if (current_count != early_count) {
385       out-&gt;print(&quot; %+d&quot;, (int)(current_count - early_count));
386     }
387   }
388 }
389 
390 void MemSummaryDiffReporter::print_arena_diff(size_t current_amount, size_t current_count,
391   size_t early_amount, size_t early_count) const {
392   const char* scale = current_scale();
393   outputStream* out = output();
394   out-&gt;print(&quot;arena=&quot; SIZE_FORMAT &quot;%s&quot;, amount_in_current_scale(current_amount), scale);
395   if (diff_in_current_scale(current_amount, early_amount) != 0) {
396     out-&gt;print(&quot; %+ld&quot;, diff_in_current_scale(current_amount, early_amount));
397   }
398 
399   out-&gt;print(&quot; #&quot; SIZE_FORMAT &quot;&quot;, current_count);
400   if (current_count != early_count) {
401     out-&gt;print(&quot; %+d&quot;, (int)(current_count - early_count));
402   }
403 }
404 
405 void MemSummaryDiffReporter::print_virtual_memory_diff(size_t current_reserved, size_t current_committed,
406     size_t early_reserved, size_t early_committed) const {
407   const char* scale = current_scale();
408   outputStream* out = output();
409   out-&gt;print(&quot;reserved=&quot; SIZE_FORMAT &quot;%s&quot;, amount_in_current_scale(current_reserved), scale);
410   long reserved_diff = diff_in_current_scale(current_reserved, early_reserved);
411   if (reserved_diff != 0) {
412     out-&gt;print(&quot; %+ld%s&quot;, reserved_diff, scale);
413   }
414 
415   out-&gt;print(&quot;, committed=&quot; SIZE_FORMAT &quot;%s&quot;, amount_in_current_scale(current_committed), scale);
416   long committed_diff = diff_in_current_scale(current_committed, early_committed);
417   if (committed_diff != 0) {
418     out-&gt;print(&quot; %+ld%s&quot;, committed_diff, scale);
419   }
420 }
421 
422 
423 void MemSummaryDiffReporter::diff_summary_of_type(MEMFLAGS flag,
424   const MallocMemory* early_malloc, const VirtualMemory* early_vm,
425   const MetaspaceSnapshot* early_ms,
426   const MallocMemory* current_malloc, const VirtualMemory* current_vm,
427   const MetaspaceSnapshot* current_ms) const {
428 
429   outputStream* out = output();
430   const char* scale = current_scale();
431 
432   // Total reserved and committed memory in current baseline
433   size_t current_reserved_amount  = reserved_total (current_malloc, current_vm);
434   size_t current_committed_amount = committed_total(current_malloc, current_vm);
435 
436   // Total reserved and committed memory in early baseline
437   size_t early_reserved_amount  = reserved_total(early_malloc, early_vm);
438   size_t early_committed_amount = committed_total(early_malloc, early_vm);
439 
440   // Adjust virtual memory total
441   if (flag == mtThread) {
442     const VirtualMemory* early_thread_stack_usage =
443       _early_baseline.virtual_memory(mtThreadStack);
444     const VirtualMemory* current_thread_stack_usage =
445       _current_baseline.virtual_memory(mtThreadStack);
446 
447     early_reserved_amount  += early_thread_stack_usage-&gt;reserved();
448     early_committed_amount += early_thread_stack_usage-&gt;committed();
449 
450     current_reserved_amount  += current_thread_stack_usage-&gt;reserved();
451     current_committed_amount += current_thread_stack_usage-&gt;committed();
452   } else if (flag == mtNMT) {
453     early_reserved_amount  += _early_baseline.malloc_tracking_overhead();
454     early_committed_amount += _early_baseline.malloc_tracking_overhead();
455 
456     current_reserved_amount  += _current_baseline.malloc_tracking_overhead();
457     current_committed_amount += _current_baseline.malloc_tracking_overhead();
458   }
459 
460   if (amount_in_current_scale(current_reserved_amount) &gt; 0 ||
461       diff_in_current_scale(current_reserved_amount, early_reserved_amount) != 0) {
462 
463     // print summary line
464     out-&gt;print(&quot;-%26s (&quot;, NMTUtil::flag_to_name(flag));
465     print_virtual_memory_diff(current_reserved_amount, current_committed_amount,
466       early_reserved_amount, early_committed_amount);
467     out-&gt;print_cr(&quot;)&quot;);
468 
469     // detail lines
470     if (flag == mtClass) {
471       // report class count
472       out-&gt;print(&quot;%27s (classes #&quot; SIZE_FORMAT &quot;&quot;, &quot; &quot;, _current_baseline.class_count());
473       int class_count_diff = (int)(_current_baseline.class_count() -
474         _early_baseline.class_count());
475       if (_current_baseline.class_count() != _early_baseline.class_count()) {
476         out-&gt;print(&quot; %+d&quot;, (int)(_current_baseline.class_count() - _early_baseline.class_count()));
477       }
478       out-&gt;print_cr(&quot;)&quot;);
479 
480       out-&gt;print(&quot;%27s (  instance classes #&quot; SIZE_FORMAT, &quot; &quot;, _current_baseline.instance_class_count());
481       if (_current_baseline.instance_class_count() != _early_baseline.instance_class_count()) {
482         out-&gt;print(&quot; %+d&quot;, (int)(_current_baseline.instance_class_count() - _early_baseline.instance_class_count()));
483       }
484       out-&gt;print(&quot;, array classes #&quot; SIZE_FORMAT, _current_baseline.array_class_count());
485       if (_current_baseline.array_class_count() != _early_baseline.array_class_count()) {
486         out-&gt;print(&quot; %+d&quot;, (int)(_current_baseline.array_class_count() - _early_baseline.array_class_count()));
487       }
488       out-&gt;print_cr(&quot;)&quot;);
489 
490     } else if (flag == mtThread) {
491       // report thread count
492       out-&gt;print(&quot;%27s (thread #&quot; SIZE_FORMAT &quot;&quot;, &quot; &quot;, _current_baseline.thread_count());
493       int thread_count_diff = (int)(_current_baseline.thread_count() -
494           _early_baseline.thread_count());
495       if (thread_count_diff != 0) {
496         out-&gt;print(&quot; %+d&quot;, thread_count_diff);
497       }
498       out-&gt;print_cr(&quot;)&quot;);
499 
500       // report thread stack
501       const VirtualMemory* current_thread_stack =
502           _current_baseline.virtual_memory(mtThreadStack);
503       const VirtualMemory* early_thread_stack =
504         _early_baseline.virtual_memory(mtThreadStack);
505 
506       out-&gt;print(&quot;%27s (stack: &quot;, &quot; &quot;);
507       print_virtual_memory_diff(current_thread_stack-&gt;reserved(), current_thread_stack-&gt;committed(),
508         early_thread_stack-&gt;reserved(), early_thread_stack-&gt;committed());
509       out-&gt;print_cr(&quot;)&quot;);
510     }
511 
512     // Report malloc&#39;d memory
513     size_t current_malloc_amount = current_malloc-&gt;malloc_size();
514     size_t early_malloc_amount   = early_malloc-&gt;malloc_size();
515     if (amount_in_current_scale(current_malloc_amount) &gt; 0 ||
516         diff_in_current_scale(current_malloc_amount, early_malloc_amount) != 0) {
517       out-&gt;print(&quot;%28s(&quot;, &quot; &quot;);
518       print_malloc_diff(current_malloc_amount, (flag == mtChunk) ? 0 : current_malloc-&gt;malloc_count(),
519         early_malloc_amount, early_malloc-&gt;malloc_count(), mtNone);
520       out-&gt;print_cr(&quot;)&quot;);
521     }
522 
523     // Report virtual memory
524     if (amount_in_current_scale(current_vm-&gt;reserved()) &gt; 0 ||
525         diff_in_current_scale(current_vm-&gt;reserved(), early_vm-&gt;reserved()) != 0) {
526       out-&gt;print(&quot;%27s (mmap: &quot;, &quot; &quot;);
527       print_virtual_memory_diff(current_vm-&gt;reserved(), current_vm-&gt;committed(),
528         early_vm-&gt;reserved(), early_vm-&gt;committed());
529       out-&gt;print_cr(&quot;)&quot;);
530     }
531 
532     // Report arena memory
533     if (amount_in_current_scale(current_malloc-&gt;arena_size()) &gt; 0 ||
534         diff_in_current_scale(current_malloc-&gt;arena_size(), early_malloc-&gt;arena_size()) != 0) {
535       out-&gt;print(&quot;%28s(&quot;, &quot; &quot;);
536       print_arena_diff(current_malloc-&gt;arena_size(), current_malloc-&gt;arena_count(),
537         early_malloc-&gt;arena_size(), early_malloc-&gt;arena_count());
538       out-&gt;print_cr(&quot;)&quot;);
539     }
540 
541     // Report native memory tracking overhead
542     if (flag == mtNMT) {
543       size_t current_tracking_overhead = amount_in_current_scale(_current_baseline.malloc_tracking_overhead());
544       size_t early_tracking_overhead   = amount_in_current_scale(_early_baseline.malloc_tracking_overhead());
545 
546       out-&gt;print(&quot;%27s (tracking overhead=&quot; SIZE_FORMAT &quot;%s&quot;, &quot; &quot;,
547         amount_in_current_scale(_current_baseline.malloc_tracking_overhead()), scale);
548 
549       long overhead_diff = diff_in_current_scale(_current_baseline.malloc_tracking_overhead(),
550            _early_baseline.malloc_tracking_overhead());
551       if (overhead_diff != 0) {
552         out-&gt;print(&quot; %+ld%s&quot;, overhead_diff, scale);
553       }
554       out-&gt;print_cr(&quot;)&quot;);
555     } else if (flag == mtClass) {
556       assert(current_ms != NULL &amp;&amp; early_ms != NULL, &quot;Sanity&quot;);
557       print_metaspace_diff(current_ms, early_ms);
558     }
559     out-&gt;print_cr(&quot; &quot;);
560   }
561 }
562 
563 void MemSummaryDiffReporter::print_metaspace_diff(const MetaspaceSnapshot* current_ms,
564                                                   const MetaspaceSnapshot* early_ms) const {
565   print_metaspace_diff(Metaspace::NonClassType, current_ms, early_ms);
566   if (Metaspace::using_class_space()) {
567     print_metaspace_diff(Metaspace::ClassType, current_ms, early_ms);
568   }
569 }
570 
571 void MemSummaryDiffReporter::print_metaspace_diff(Metaspace::MetadataType type,
572                                                   const MetaspaceSnapshot* current_ms,
573                                                   const MetaspaceSnapshot* early_ms) const {
574   const char* name = (type == Metaspace::NonClassType) ?
575     &quot;Metadata:   &quot; : &quot;Class space:&quot;;
576 
577   outputStream* out = output();
578   const char* scale = current_scale();
579 
580   out-&gt;print_cr(&quot;%27s (  %s)&quot;, &quot; &quot;, name);
581   out-&gt;print(&quot;%27s (    &quot;, &quot; &quot;);
582   print_virtual_memory_diff(current_ms-&gt;reserved_in_bytes(type),
583                             current_ms-&gt;committed_in_bytes(type),
584                             early_ms-&gt;reserved_in_bytes(type),
585                             early_ms-&gt;committed_in_bytes(type));
586   out-&gt;print_cr(&quot;)&quot;);
587 
588   long diff_used = diff_in_current_scale(current_ms-&gt;used_in_bytes(type),
589                                          early_ms-&gt;used_in_bytes(type));
590   long diff_free = diff_in_current_scale(current_ms-&gt;free_in_bytes(type),
591                                          early_ms-&gt;free_in_bytes(type));
592 
593   size_t current_waste = current_ms-&gt;committed_in_bytes(type)
594     - (current_ms-&gt;used_in_bytes(type) + current_ms-&gt;free_in_bytes(type));
595   size_t early_waste = early_ms-&gt;committed_in_bytes(type)
596     - (early_ms-&gt;used_in_bytes(type) + early_ms-&gt;free_in_bytes(type));
597   long diff_waste = diff_in_current_scale(current_waste, early_waste);
598 
599   // Diff used
600   out-&gt;print(&quot;%27s (    used=&quot; SIZE_FORMAT &quot;%s&quot;, &quot; &quot;,
601     amount_in_current_scale(current_ms-&gt;used_in_bytes(type)), scale);
602   if (diff_used != 0) {
603     out-&gt;print(&quot; %+ld%s&quot;, diff_used, scale);
604   }
605   out-&gt;print_cr(&quot;)&quot;);
606 
607   // Diff free
608   out-&gt;print(&quot;%27s (    free=&quot; SIZE_FORMAT &quot;%s&quot;, &quot; &quot;,
609     amount_in_current_scale(current_ms-&gt;free_in_bytes(type)), scale);
610   if (diff_free != 0) {
611     out-&gt;print(&quot; %+ld%s&quot;, diff_free, scale);
612   }
613   out-&gt;print_cr(&quot;)&quot;);
614 
615 
616   // Diff waste
617   out-&gt;print(&quot;%27s (    waste=&quot; SIZE_FORMAT &quot;%s =%2.2f%%&quot;, &quot; &quot;,
618     amount_in_current_scale(current_waste), scale,
619     ((float)current_waste * 100) / current_ms-&gt;committed_in_bytes(type));
620   if (diff_waste != 0) {
621     out-&gt;print(&quot; %+ld%s&quot;, diff_waste, scale);
622   }
623   out-&gt;print_cr(&quot;)&quot;);
624 }
625 
626 void MemDetailDiffReporter::report_diff() {
627   MemSummaryDiffReporter::report_diff();
628   diff_malloc_sites();
629   diff_virtual_memory_sites();
630 }
631 
632 void MemDetailDiffReporter::diff_malloc_sites() const {
633   MallocSiteIterator early_itr = _early_baseline.malloc_sites(MemBaseline::by_site_and_type);
634   MallocSiteIterator current_itr = _current_baseline.malloc_sites(MemBaseline::by_site_and_type);
635 
636   const MallocSite* early_site   = early_itr.next();
637   const MallocSite* current_site = current_itr.next();
638 
639   while (early_site != NULL || current_site != NULL) {
640     if (early_site == NULL) {
641       new_malloc_site(current_site);
642       current_site = current_itr.next();
643     } else if (current_site == NULL) {
644       old_malloc_site(early_site);
645       early_site = early_itr.next();
646     } else {
647       int compVal = current_site-&gt;call_stack()-&gt;compare(*early_site-&gt;call_stack());
648       if (compVal &lt; 0) {
649         new_malloc_site(current_site);
650         current_site = current_itr.next();
651       } else if (compVal &gt; 0) {
652         old_malloc_site(early_site);
653         early_site = early_itr.next();
654       } else {
655         diff_malloc_site(early_site, current_site);
656         early_site   = early_itr.next();
657         current_site = current_itr.next();
658       }
659     }
660   }
661 }
662 
663 void MemDetailDiffReporter::diff_virtual_memory_sites() const {
664   VirtualMemorySiteIterator early_itr = _early_baseline.virtual_memory_sites(MemBaseline::by_site);
665   VirtualMemorySiteIterator current_itr = _current_baseline.virtual_memory_sites(MemBaseline::by_site);
666 
667   const VirtualMemoryAllocationSite* early_site   = early_itr.next();
668   const VirtualMemoryAllocationSite* current_site = current_itr.next();
669 
670   while (early_site != NULL || current_site != NULL) {
671     if (early_site == NULL) {
672       new_virtual_memory_site(current_site);
673       current_site = current_itr.next();
674     } else if (current_site == NULL) {
675       old_virtual_memory_site(early_site);
676       early_site = early_itr.next();
677     } else {
678       int compVal = current_site-&gt;call_stack()-&gt;compare(*early_site-&gt;call_stack());
679       if (compVal &lt; 0) {
680         new_virtual_memory_site(current_site);
681         current_site = current_itr.next();
682       } else if (compVal &gt; 0) {
683         old_virtual_memory_site(early_site);
684         early_site = early_itr.next();
685       } else {
686         diff_virtual_memory_site(early_site, current_site);
687         early_site   = early_itr.next();
688         current_site = current_itr.next();
689       }
690     }
691   }
692 }
693 
694 
695 void MemDetailDiffReporter::new_malloc_site(const MallocSite* malloc_site) const {
696   diff_malloc_site(malloc_site-&gt;call_stack(), malloc_site-&gt;size(), malloc_site-&gt;count(),
697     0, 0, malloc_site-&gt;flag());
698 }
699 
700 void MemDetailDiffReporter::old_malloc_site(const MallocSite* malloc_site) const {
701   diff_malloc_site(malloc_site-&gt;call_stack(), 0, 0, malloc_site-&gt;size(),
702     malloc_site-&gt;count(), malloc_site-&gt;flag());
703 }
704 
705 void MemDetailDiffReporter::diff_malloc_site(const MallocSite* early,
706   const MallocSite* current)  const {
707   if (early-&gt;flag() != current-&gt;flag()) {
708     // If malloc site type changed, treat it as deallocation of old type and
709     // allocation of new type.
710     old_malloc_site(early);
711     new_malloc_site(current);
712   } else {
713     diff_malloc_site(current-&gt;call_stack(), current-&gt;size(), current-&gt;count(),
714       early-&gt;size(), early-&gt;count(), early-&gt;flag());
715   }
716 }
717 
718 void MemDetailDiffReporter::diff_malloc_site(const NativeCallStack* stack, size_t current_size,
719   size_t current_count, size_t early_size, size_t early_count, MEMFLAGS flags) const {
720   outputStream* out = output();
721 
722   assert(stack != NULL, &quot;NULL stack&quot;);
723 
724   if (diff_in_current_scale(current_size, early_size) == 0) {
725       return;
726   }
727 
728   stack-&gt;print_on(out);
729   out-&gt;print(&quot;%28s (&quot;, &quot; &quot;);
730   print_malloc_diff(current_size, current_count,
731     early_size, early_count, flags);
732 
733   out-&gt;print_cr(&quot;)\n&quot;);
734 }
735 
736 
737 void MemDetailDiffReporter::new_virtual_memory_site(const VirtualMemoryAllocationSite* site) const {
738   diff_virtual_memory_site(site-&gt;call_stack(), site-&gt;reserved(), site-&gt;committed(), 0, 0, site-&gt;flag());
739 }
740 
741 void MemDetailDiffReporter::old_virtual_memory_site(const VirtualMemoryAllocationSite* site) const {
742   diff_virtual_memory_site(site-&gt;call_stack(), 0, 0, site-&gt;reserved(), site-&gt;committed(), site-&gt;flag());
743 }
744 
745 void MemDetailDiffReporter::diff_virtual_memory_site(const VirtualMemoryAllocationSite* early,
746   const VirtualMemoryAllocationSite* current) const {
747   assert(early-&gt;flag() == current-&gt;flag(), &quot;Should be the same&quot;);
748   diff_virtual_memory_site(current-&gt;call_stack(), current-&gt;reserved(), current-&gt;committed(),
749     early-&gt;reserved(), early-&gt;committed(), current-&gt;flag());
750 }
751 
752 void MemDetailDiffReporter::diff_virtual_memory_site(const NativeCallStack* stack, size_t current_reserved,
753   size_t current_committed, size_t early_reserved, size_t early_committed, MEMFLAGS flag) const  {
754   outputStream* out = output();
755 
756   // no change
757   if (diff_in_current_scale(current_reserved, early_reserved) == 0 &amp;&amp;
758       diff_in_current_scale(current_committed, early_committed) == 0) {
759     return;
760   }
761 
762   stack-&gt;print_on(out);
763   out-&gt;print(&quot;%28s (mmap: &quot;, &quot; &quot;);
764   print_virtual_memory_diff(current_reserved, current_committed,
765     early_reserved, early_committed);
766 
767   if (flag != mtNone) {
768     out-&gt;print(&quot; Type=%s&quot;, NMTUtil::flag_to_name(flag));
769   }
770 
771   out-&gt;print_cr(&quot;)\n&quot;);
772  }
    </pre>
  </body>
</html>