diff a/src/hotspot/share/services/memTracker.hpp b/src/hotspot/share/services/memTracker.hpp
--- a/src/hotspot/share/services/memTracker.hpp
+++ b/src/hotspot/share/services/memTracker.hpp
@@ -57,15 +57,15 @@
   static inline void* record_malloc(void* mem_base, size_t size, MEMFLAGS flag,
     const NativeCallStack& stack, NMT_TrackingLevel level) { return mem_base; }
   static inline size_t malloc_header_size(NMT_TrackingLevel level) { return 0; }
   static inline size_t malloc_header_size(void* memblock) { return 0; }
   static inline void* malloc_base(void* memblock) { return memblock; }
-  static inline void* record_free(void* memblock) { return memblock; }
+  static inline void* record_free(void* memblock, NMT_TrackingLevel level) { return memblock; }
 
   static inline void record_new_arena(MEMFLAGS flag) { }
   static inline void record_arena_free(MEMFLAGS flag) { }
-  static inline void record_arena_size_change(int diff, MEMFLAGS flag) { }
+  static inline void record_arena_size_change(ssize_t diff, MEMFLAGS flag) { }
   static inline void record_virtual_memory_reserve(void* addr, size_t size, const NativeCallStack& stack,
                        MEMFLAGS flag = mtNone) { }
   static inline void record_virtual_memory_reserve_and_commit(void* addr, size_t size,
     const NativeCallStack& stack, MEMFLAGS flag = mtNone) { }
   static inline void record_virtual_memory_commit(void* addr, size_t size, const NativeCallStack& stack) { }
@@ -80,10 +80,11 @@
 #else
 
 #include "runtime/mutexLocker.hpp"
 #include "runtime/threadCritical.hpp"
 #include "services/mallocTracker.hpp"
+#include "services/threadStackTracker.hpp"
 #include "services/virtualMemoryTracker.hpp"
 
 extern volatile bool NMT_stack_walkable;
 
 #define CURRENT_PC ((MemTracker::tracking_level() == NMT_detail && NMT_stack_walkable) ? \
@@ -154,11 +155,14 @@
   // Transition the tracking level to specified level
   static bool transition_to(NMT_TrackingLevel level);
 
   static inline void* record_malloc(void* mem_base, size_t size, MEMFLAGS flag,
     const NativeCallStack& stack, NMT_TrackingLevel level) {
-    return MallocTracker::record_malloc(mem_base, size, flag, stack, level);
+    if (level != NMT_off) {
+      return MallocTracker::record_malloc(mem_base, size, flag, stack, level);
+    }
+    return mem_base;
   }
 
   static inline size_t malloc_header_size(NMT_TrackingLevel level) {
     return MallocTracker::malloc_header_size(level);
   }
@@ -174,11 +178,15 @@
   // of malloc tracking header if tracking is enabled.
   // Otherwise, it returns the same address.
   static void* malloc_base(void* memblock);
 
   // Record malloc free and return malloc base address
-  static inline void* record_free(void* memblock) {
+  static inline void* record_free(void* memblock, NMT_TrackingLevel level) {
+    // Never turned on
+    if (level == NMT_off || memblock == NULL) {
+      return memblock;
+    }
     return MallocTracker::record_free(memblock);
   }
 
 
   // Record creation of an arena
@@ -193,11 +201,11 @@
     MallocTracker::record_arena_free(flag);
   }
 
   // Record arena size change. Arena size is the size of all arena
   // chuncks that backing up the arena.
-  static inline void record_arena_size_change(int diff, MEMFLAGS flag) {
+  static inline void record_arena_size_change(ssize_t diff, MEMFLAGS flag) {
     if (tracking_level() < NMT_summary) return;
     MallocTracker::record_arena_size_change(diff, flag);
   }
 
   static inline void record_virtual_memory_reserve(void* addr, size_t size, const NativeCallStack& stack,
@@ -239,35 +247,23 @@
       if (tracking_level() < NMT_summary) return;
       VirtualMemoryTracker::set_reserved_region_type((address)addr, flag);
     }
   }
 
-#ifdef _AIX
-  // See JDK-8202772 - temporarily disable thread stack tracking on AIX.
-  static inline void record_thread_stack(void* addr, size_t size) {}
-  static inline void release_thread_stack(void* addr, size_t size) {}
-#else
-  static inline void record_thread_stack(void* addr, size_t size) {
+  static void record_thread_stack(void* addr, size_t size) {
     if (tracking_level() < NMT_summary) return;
     if (addr != NULL) {
-      // uses thread stack malloc slot for book keeping number of threads
-      MallocMemorySummary::record_malloc(0, mtThreadStack);
-      record_virtual_memory_reserve(addr, size, CALLER_PC, mtThreadStack);
+      ThreadStackTracker::new_thread_stack((address)addr, size, CALLER_PC);
     }
   }
 
   static inline void release_thread_stack(void* addr, size_t size) {
     if (tracking_level() < NMT_summary) return;
     if (addr != NULL) {
-      // uses thread stack malloc slot for book keeping number of threads
-      MallocMemorySummary::record_free(0, mtThreadStack);
-      ThreadCritical tc;
-      if (tracking_level() < NMT_summary) return;
-      VirtualMemoryTracker::remove_released_region((address)addr, size);
+      ThreadStackTracker::delete_thread_stack((address)addr, size);
     }
   }
-#endif
 
   // Query lock is used to synchronize the access to tracking data.
   // So far, it is only used by JCmd query, but it may be used by
   // other tools.
   static inline Mutex* query_lock() {
@@ -280,17 +276,11 @@
     if (tracking_level() >= NMT_summary) {
       report(true, output);  // just print summary for error case.
     }
    }
 
-  static void final_report(outputStream* output) {
-    NMT_TrackingLevel level = tracking_level();
-    if (level >= NMT_summary) {
-      report(level == NMT_summary, output);
-    }
-  }
-
+  static void final_report(outputStream* output);
 
   // Stored baseline
   static inline MemBaseline& get_baseline() {
     return _baseline;
   }
