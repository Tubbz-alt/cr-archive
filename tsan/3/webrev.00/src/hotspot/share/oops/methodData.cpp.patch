diff a/src/hotspot/share/oops/methodData.cpp b/src/hotspot/share/oops/methodData.cpp
--- a/src/hotspot/share/oops/methodData.cpp
+++ b/src/hotspot/share/oops/methodData.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -22,21 +22,21 @@
  *
  */
 
 #include "precompiled.hpp"
 #include "classfile/systemDictionary.hpp"
+#include "compiler/compilationPolicy.hpp"
 #include "compiler/compilerOracle.hpp"
 #include "interpreter/bytecode.hpp"
 #include "interpreter/bytecodeStream.hpp"
 #include "interpreter/linkResolver.hpp"
-#include "memory/heapInspection.hpp"
 #include "memory/metaspaceClosure.hpp"
 #include "memory/resourceArea.hpp"
 #include "oops/methodData.inline.hpp"
 #include "prims/jvmtiRedefineClasses.hpp"
 #include "runtime/arguments.hpp"
-#include "runtime/compilationPolicy.hpp"
+#include "runtime/atomic.hpp"
 #include "runtime/deoptimization.hpp"
 #include "runtime/handles.inline.hpp"
 #include "runtime/orderAccess.hpp"
 #include "runtime/safepointVerifiers.hpp"
 #include "utilities/align.hpp"
@@ -197,12 +197,12 @@
 
 int TypeStackSlotEntries::compute_cell_count(Symbol* signature, bool include_receiver, int max) {
   // Parameter profiling include the receiver
   int args_count = include_receiver ? 1 : 0;
   ResourceMark rm;
-  SignatureStream ss(signature);
-  args_count += ss.reference_parameter_count();
+  ReferenceArgumentCount rac(signature);
+  args_count += rac.count();
   args_count = MIN2(args_count, max);
   return args_count * per_arg_cell_count;
 }
 
 int TypeEntriesAtCall::compute_cell_count(BytecodeStream* stream) {
@@ -214,47 +214,43 @@
   int args_cell = 0;
   if (MethodData::profile_arguments_for_invoke(m, bci)) {
     args_cell = TypeStackSlotEntries::compute_cell_count(inv.signature(), false, TypeProfileArgsLimit);
   }
   int ret_cell = 0;
-  if (MethodData::profile_return_for_invoke(m, bci) && (inv.result_type() == T_OBJECT || inv.result_type() == T_ARRAY)) {
+  if (MethodData::profile_return_for_invoke(m, bci) && is_reference_type(inv.result_type())) {
     ret_cell = ReturnTypeEntry::static_cell_count();
   }
   int header_cell = 0;
   if (args_cell + ret_cell > 0) {
     header_cell = header_cell_count();
   }
 
   return header_cell + args_cell + ret_cell;
 }
 
-class ArgumentOffsetComputer : public SignatureInfo {
+class ArgumentOffsetComputer : public SignatureIterator {
 private:
   int _max;
+  int _offset;
   GrowableArray<int> _offsets;
 
-  void set(int size, BasicType type) { _size += size; }
-  void do_object(int begin, int end) {
-    if (_offsets.length() < _max) {
-      _offsets.push(_size);
+  friend class SignatureIterator;  // so do_parameters_on can call do_type
+  void do_type(BasicType type) {
+    if (is_reference_type(type) && _offsets.length() < _max) {
+      _offsets.push(_offset);
     }
-    SignatureInfo::do_object(begin, end);
-  }
-  void do_array (int begin, int end) {
-    if (_offsets.length() < _max) {
-      _offsets.push(_size);
-    }
-    SignatureInfo::do_array(begin, end);
+    _offset += parameter_type_word_count(type);
   }
 
-public:
+ public:
   ArgumentOffsetComputer(Symbol* signature, int max)
-    : SignatureInfo(signature), _max(max), _offsets(Thread::current(), max) {
+    : SignatureIterator(signature),
+      _max(max), _offset(0),
+      _offsets(Thread::current(), max) {
+    do_parameters_on(this);  // non-virtual template execution
   }
 
-  int total() { lazy_iterate_parameters(); return _size; }
-
   int off_at(int i) const { return _offsets.at(i); }
 };
 
 void TypeStackSlotEntries::post_initialize(Symbol* signature, bool has_receiver, bool include_receiver) {
   ResourceMark rm;
@@ -264,34 +260,33 @@
     set_stack_slot(0, 0);
     set_type(0, type_none());
     start += 1;
   }
   ArgumentOffsetComputer aos(signature, _number_of_entries-start);
-  aos.total();
   for (int i = start; i < _number_of_entries; i++) {
     set_stack_slot(i, aos.off_at(i-start) + (has_receiver ? 1 : 0));
     set_type(i, type_none());
   }
 }
 
 void CallTypeData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
   assert(Bytecodes::is_invoke(stream->code()), "should be invoke");
   Bytecode_invoke inv(stream->method(), stream->bci());
 
-  SignatureStream ss(inv.signature());
   if (has_arguments()) {
 #ifdef ASSERT
     ResourceMark rm;
-    int count = MIN2(ss.reference_parameter_count(), (int)TypeProfileArgsLimit);
+    ReferenceArgumentCount rac(inv.signature());
+    int count = MIN2(rac.count(), (int)TypeProfileArgsLimit);
     assert(count > 0, "room for args type but none found?");
     check_number_of_arguments(count);
 #endif
     _args.post_initialize(inv.signature(), inv.has_receiver(), false);
   }
 
   if (has_return()) {
-    assert(inv.result_type() == T_OBJECT || inv.result_type() == T_ARRAY, "room for a ret type but doesn't return obj?");
+    assert(is_reference_type(inv.result_type()), "room for a ret type but doesn't return obj?");
     _ret.post_initialize();
   }
 }
 
 void VirtualCallTypeData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
@@ -299,20 +294,20 @@
   Bytecode_invoke inv(stream->method(), stream->bci());
 
   if (has_arguments()) {
 #ifdef ASSERT
     ResourceMark rm;
-    SignatureStream ss(inv.signature());
-    int count = MIN2(ss.reference_parameter_count(), (int)TypeProfileArgsLimit);
+    ReferenceArgumentCount rac(inv.signature());
+    int count = MIN2(rac.count(), (int)TypeProfileArgsLimit);
     assert(count > 0, "room for args type but none found?");
     check_number_of_arguments(count);
 #endif
     _args.post_initialize(inv.signature(), inv.has_receiver(), false);
   }
 
   if (has_return()) {
-    assert(inv.result_type() == T_OBJECT || inv.result_type() == T_ARRAY, "room for a ret type but doesn't return obj?");
+    assert(is_reference_type(inv.result_type()), "room for a ret type but doesn't return obj?");
     _ret.post_initialize();
   }
 }
 
 void TypeStackSlotEntries::clean_weak_klass_links(bool always_clean) {
@@ -666,11 +661,11 @@
   }
   st->cr();
 }
 
 int ParametersTypeData::compute_cell_count(Method* m) {
-  if (!MethodData::profile_parameters_for_method(m)) {
+  if (!MethodData::profile_parameters_for_method(methodHandle(Thread::current(), m))) {
     return 0;
   }
   int max = TypeProfileParmsLimit == -1 ? INT_MAX : TypeProfileParmsLimit;
   int obj_args = TypeStackSlotEntries::compute_cell_count(m->signature(), !m->is_static(), max);
   if (obj_args > 0) {
@@ -707,11 +702,11 @@
 
 MethodData* MethodData::allocate(ClassLoaderData* loader_data, const methodHandle& method, TRAPS) {
   int size = MethodData::compute_allocation_size_in_words(method);
 
   return new (loader_data, size, MetaspaceObj::MethodDataType, THREAD)
-    MethodData(method(), size, THREAD);
+    MethodData(method, size, THREAD);
 }
 
 int MethodData::bytecode_cell_count(Bytecodes::Code code) {
   if (is_client_compilation_mode_vm()) {
     return no_profile_data;
@@ -844,10 +839,90 @@
     return false;
   }
   return false;
 }
 
+#if INCLUDE_JVMCI
+
+void* FailedSpeculation::operator new(size_t size, size_t fs_size) throw() {
+  return CHeapObj<mtCompiler>::operator new(fs_size, std::nothrow);
+}
+
+FailedSpeculation::FailedSpeculation(address speculation, int speculation_len) : _data_len(speculation_len), _next(NULL) {
+  memcpy(data(), speculation, speculation_len);
+}
+
+// A heuristic check to detect nmethods that outlive a failed speculations list.
+static void guarantee_failed_speculations_alive(nmethod* nm, FailedSpeculation** failed_speculations_address) {
+  jlong head = (jlong)(address) *failed_speculations_address;
+  if ((head & 0x1) == 0x1) {
+    stringStream st;
+    if (nm != NULL) {
+      st.print("%d", nm->compile_id());
+      Method* method = nm->method();
+      st.print_raw("{");
+      if (method != NULL) {
+        method->print_name(&st);
+      } else {
+        const char* jvmci_name = nm->jvmci_name();
+        if (jvmci_name != NULL) {
+          st.print_raw(jvmci_name);
+        }
+      }
+      st.print_raw("}");
+    } else {
+      st.print("<unknown>");
+    }
+    fatal("Adding to failed speculations list that appears to have been freed. Source: %s", st.as_string());
+  }
+}
+
+bool FailedSpeculation::add_failed_speculation(nmethod* nm, FailedSpeculation** failed_speculations_address, address speculation, int speculation_len) {
+  assert(failed_speculations_address != NULL, "must be");
+  size_t fs_size = sizeof(FailedSpeculation) + speculation_len;
+  FailedSpeculation* fs = new (fs_size) FailedSpeculation(speculation, speculation_len);
+  if (fs == NULL) {
+    // no memory -> ignore failed speculation
+    return false;
+  }
+
+  guarantee(is_aligned(fs, sizeof(FailedSpeculation*)), "FailedSpeculation objects must be pointer aligned");
+  guarantee_failed_speculations_alive(nm, failed_speculations_address);
+
+  FailedSpeculation** cursor = failed_speculations_address;
+  do {
+    if (*cursor == NULL) {
+      FailedSpeculation* old_fs = Atomic::cmpxchg(cursor, (FailedSpeculation*) NULL, fs);
+      if (old_fs == NULL) {
+        // Successfully appended fs to end of the list
+        return true;
+      }
+      cursor = old_fs->next_adr();
+    } else {
+      cursor = (*cursor)->next_adr();
+    }
+  } while (true);
+}
+
+void FailedSpeculation::free_failed_speculations(FailedSpeculation** failed_speculations_address) {
+  assert(failed_speculations_address != NULL, "must be");
+  FailedSpeculation* fs = *failed_speculations_address;
+  while (fs != NULL) {
+    FailedSpeculation* next = fs->next();
+    delete fs;
+    fs = next;
+  }
+
+  // Write an unaligned value to failed_speculations_address to denote
+  // that it is no longer a valid pointer. This is allows for the check
+  // in add_failed_speculation against adding to a freed failed
+  // speculations list.
+  long* head = (long*) failed_speculations_address;
+  (*head) = (*head) | 0x1;
+}
+#endif // INCLUDE_JVMCI
+
 int MethodData::compute_extra_data_count(int data_size, int empty_bc_count, bool needs_speculative_traps) {
 #if INCLUDE_JVMCI
   if (ProfileTraps) {
     // Assume that up to 30% of the possibly trapping BCIs with no MDP will need to allocate one.
     int extra_data_count = MIN2(empty_bc_count, MAX2(4, (empty_bc_count * 30) / 100));
@@ -1130,30 +1205,31 @@
   }
 }
 
 // Initialize the MethodData* corresponding to a given method.
 MethodData::MethodData(const methodHandle& method, int size, TRAPS)
-  : _extra_data_lock(Monitor::leaf, "MDO extra data lock"),
+  : _extra_data_lock(Mutex::leaf, "MDO extra data lock"),
     _parameters_type_data_di(parameters_uninitialized) {
   // Set the method back-pointer.
   _method = method();
   initialize();
 }
 
 void MethodData::initialize() {
+  Thread* thread = Thread::current();
   NoSafepointVerifier no_safepoint;  // init function atomic wrt GC
-  ResourceMark rm;
+  ResourceMark rm(thread);
 
   init();
   set_creation_mileage(mileage_of(method()));
 
   // Go through the bytecodes and allocate and initialize the
   // corresponding data cells.
   int data_size = 0;
   int empty_bc_count = 0;  // number of bytecodes lacking data
   _data[0] = 0;  // apparently not set below.
-  BytecodeStream stream(method());
+  BytecodeStream stream(methodHandle(thread, method()));
   Bytecodes::Code c;
   bool needs_speculative_traps = false;
   while ((c = stream.next()) >= 0) {
     int size_in_bytes = initialize_data(&stream, data_size);
     data_size += size_in_bytes;
@@ -1202,11 +1278,11 @@
   // least well-defined.
   _hint_di = first_di();
 
   post_initialize(&stream);
 
-  assert(object_size == compute_allocation_size_in_bytes(methodHandle(_method)), "MethodData: computed size != initialized size");
+  assert(object_size == compute_allocation_size_in_bytes(methodHandle(thread, _method)), "MethodData: computed size != initialized size");
   set_size(object_size);
 }
 
 void MethodData::init() {
   _invocation_counter.init();
@@ -1214,28 +1290,30 @@
   _invocation_counter_start = 0;
   _backedge_counter_start = 0;
 
   // Set per-method invoke- and backedge mask.
   double scale = 1.0;
-  CompilerOracle::has_option_value(_method, "CompileThresholdScaling", scale);
+  methodHandle mh(Thread::current(), _method);
+  CompilerOracle::has_option_value(mh, "CompileThresholdScaling", scale);
   _invoke_mask = right_n_bits(CompilerConfig::scaled_freq_log(Tier0InvokeNotifyFreqLog, scale)) << InvocationCounter::count_shift;
   _backedge_mask = right_n_bits(CompilerConfig::scaled_freq_log(Tier0BackedgeNotifyFreqLog, scale)) << InvocationCounter::count_shift;
 
   _tenure_traps = 0;
   _num_loops = 0;
   _num_blocks = 0;
   _would_profile = unknown;
 
 #if INCLUDE_JVMCI
   _jvmci_ir_size = 0;
+  _failed_speculations = NULL;
 #endif
 
 #if INCLUDE_RTM_OPT
   _rtm_state = NoRTM; // No RTM lock eliding by default
   if (UseRTMLocking &&
-      !CompilerOracle::has_option_string(_method, "NoRTMLockEliding")) {
-    if (CompilerOracle::has_option_string(_method, "UseRTMLockEliding") || !UseRTMDeopt) {
+      !CompilerOracle::has_option_string(mh, "NoRTMLockEliding")) {
+    if (CompilerOracle::has_option_string(mh, "UseRTMLockEliding") || !UseRTMDeopt) {
       // Generate RTM lock eliding code without abort ratio calculation code.
       _rtm_state = UseRTM;
     } else if (UseRTMDeopt) {
       // Generate RTM lock eliding code and include abort ratio calculation
       // code if UseRTMDeopt is on.
@@ -1330,11 +1408,11 @@
 ProfileData* MethodData::bci_to_extra_data_helper(int bci, Method* m, DataLayout*& dp, bool concurrent) {
   DataLayout* end = args_data_limit();
 
   for (;; dp = next_extra(dp)) {
     assert(dp < end, "moved past end of extra data");
-    // No need for "OrderAccess::load_acquire" ops,
+    // No need for "Atomic::load_acquire" ops,
     // since the data structure is monotonic.
     switch(dp->tag()) {
     case DataLayout::no_tag:
       return NULL;
     case DataLayout::arg_info_data_tag:
@@ -1465,11 +1543,11 @@
   st->print_cr("--- Extra data:");
   DataLayout* dp    = extra_data_base();
   DataLayout* end   = args_data_limit();
   for (;; dp = next_extra(dp)) {
     assert(dp < end, "moved past end of extra data");
-    // No need for "OrderAccess::load_acquire" ops,
+    // No need for "Atomic::load_acquire" ops,
     // since the data structure is monotonic.
     switch(dp->tag()) {
     case DataLayout::no_tag:
       continue;
     case DataLayout::bit_data_tag:
@@ -1490,20 +1568,10 @@
     data->print_data_on(st);
     if (dp >= end) return;
   }
 }
 
-#if INCLUDE_SERVICES
-// Size Statistics
-void MethodData::collect_statistics(KlassSizeStats *sz) const {
-  int n = sz->count(this);
-  sz->_method_data_bytes += n;
-  sz->_method_all_bytes += n;
-  sz->_rw_bytes += n;
-}
-#endif // INCLUDE_SERVICES
-
 // Verification
 
 void MethodData::verify_on(outputStream* st) {
   guarantee(is_methodData(), "object must be method data");
   // guarantee(m->is_perm(), "should be in permspace");
@@ -1524,15 +1592,18 @@
   return inv.is_invokedynamic() || inv.is_invokehandle();
 }
 
 bool MethodData::profile_unsafe(const methodHandle& m, int bci) {
   Bytecode_invoke inv(m , bci);
-  if (inv.is_invokevirtual() && inv.klass() == vmSymbols::jdk_internal_misc_Unsafe()) {
-    ResourceMark rm;
-    char* name = inv.name()->as_C_string();
-    if (!strncmp(name, "get", 3) || !strncmp(name, "put", 3)) {
-      return true;
+  if (inv.is_invokevirtual()) {
+    if (inv.klass() == vmSymbols::jdk_internal_misc_Unsafe() ||
+        inv.klass() == vmSymbols::sun_misc_Unsafe()) {
+      ResourceMark rm;
+      char* name = inv.name()->as_C_string();
+      if (!strncmp(name, "get", 3) || !strncmp(name, "put", 3)) {
+        return true;
+      }
     }
   }
   return false;
 }
 
