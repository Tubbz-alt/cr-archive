diff a/src/hotspot/share/runtime/vmThread.cpp b/src/hotspot/share/runtime/vmThread.cpp
--- a/src/hotspot/share/runtime/vmThread.cpp
+++ b/src/hotspot/share/runtime/vmThread.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -29,13 +29,15 @@
 #include "jfr/support/jfrThreadId.hpp"
 #include "logging/log.hpp"
 #include "logging/logStream.hpp"
 #include "logging/logConfiguration.hpp"
 #include "memory/resourceArea.hpp"
+#include "memory/universe.hpp"
 #include "oops/method.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/verifyOopClosure.hpp"
+#include "runtime/atomic.hpp"
 #include "runtime/handles.inline.hpp"
 #include "runtime/interfaceSupport.inline.hpp"
 #include "runtime/mutexLocker.hpp"
 #include "runtime/os.hpp"
 #include "runtime/safepoint.hpp"
@@ -46,21 +48,22 @@
 #include "utilities/dtrace.hpp"
 #include "utilities/events.hpp"
 #include "utilities/vmError.hpp"
 #include "utilities/xmlstream.hpp"
 
+VM_QueueHead VMOperationQueue::_queue_head[VMOperationQueue::nof_priorities];
+
 VMOperationQueue::VMOperationQueue() {
   // The queue is a circular doubled-linked list, which always contains
   // one element (i.e., one element means empty).
   for(int i = 0; i < nof_priorities; i++) {
     _queue_length[i] = 0;
     _queue_counter = 0;
-    _queue[i] = new VM_None("QueueHead");
+    _queue[i] = &_queue_head[i];
     _queue[i]->set_next(_queue[i]);
     _queue[i]->set_prev(_queue[i]);
   }
-  _drain_list = NULL;
 }
 
 
 bool VMOperationQueue::queue_empty(int prio) {
   // It is empty if there is exactly one element
@@ -77,16 +80,11 @@
   n->set_next(q->next());
   q->next()->set_prev(n);
   q->set_next(n);
 }
 
-void VMOperationQueue::queue_add_front(int prio, VM_Operation *op) {
-  _queue_length[prio]++;
-  insert(_queue[prio]->next(), op);
-}
-
-void VMOperationQueue::queue_add_back(int prio, VM_Operation *op) {
+void VMOperationQueue::queue_add(int prio, VM_Operation *op) {
   _queue_length[prio]++;
   insert(_queue[prio]->prev(), op);
 }
 
 
@@ -127,44 +125,21 @@
   assert(len == length, "drain lost some ops");
 #endif
   return r;
 }
 
-void VMOperationQueue::queue_oops_do(int queue, OopClosure* f) {
-  VM_Operation* cur = _queue[queue];
-  cur = cur->next();
-  while (cur != _queue[queue]) {
-    cur->oops_do(f);
-    cur = cur->next();
-  }
-}
-
-void VMOperationQueue::drain_list_oops_do(OopClosure* f) {
-  VM_Operation* cur = _drain_list;
-  while (cur != NULL) {
-    cur->oops_do(f);
-    cur = cur->next();
-  }
-}
-
 //-----------------------------------------------------------------
 // High-level interface
-bool VMOperationQueue::add(VM_Operation *op) {
+void VMOperationQueue::add(VM_Operation *op) {
 
   HOTSPOT_VMOPS_REQUEST(
                    (char *) op->name(), strlen(op->name()),
-                   op->evaluation_mode());
+                   op->evaluate_at_safepoint() ? 0 : 1);
 
   // Encapsulates VM queue policy. Currently, that
   // only involves putting them on the right list
-  if (op->evaluate_at_safepoint()) {
-    queue_add_back(SafepointPriority, op);
-    return true;
-  }
-
-  queue_add_back(MediumPriority, op);
-  return true;
+  queue_add(op->evaluate_at_safepoint() ? SafepointPriority : MediumPriority, op);
 }
 
 VM_Operation* VMOperationQueue::remove_next() {
   // Assuming VMOperation queue is two-level priority queue. If there are
   // more than two priorities, we need a different scheduling algorithm.
@@ -184,42 +159,35 @@
   }
 
   return queue_remove_front(queue_empty(high_prio) ? low_prio : high_prio);
 }
 
-void VMOperationQueue::oops_do(OopClosure* f) {
-  for(int i = 0; i < nof_priorities; i++) {
-    queue_oops_do(i, f);
-  }
-  drain_list_oops_do(f);
-}
-
 //------------------------------------------------------------------------------------------------------------------
 // Timeout machinery
 
 void VMOperationTimeoutTask::task() {
   assert(AbortVMOnVMOperationTimeout, "only if enabled");
   if (is_armed()) {
-    jlong delay = (os::javaTimeMillis() - _arm_time);
+    jlong delay = nanos_to_millis(os::javaTimeNanos() - _arm_time);
     if (delay > AbortVMOnVMOperationTimeoutDelay) {
       fatal("VM operation took too long: " JLONG_FORMAT " ms (timeout: " INTX_FORMAT " ms)",
             delay, AbortVMOnVMOperationTimeoutDelay);
     }
   }
 }
 
 bool VMOperationTimeoutTask::is_armed() {
-  return OrderAccess::load_acquire(&_armed) != 0;
+  return Atomic::load_acquire(&_armed) != 0;
 }
 
 void VMOperationTimeoutTask::arm() {
-  _arm_time = os::javaTimeMillis();
-  OrderAccess::release_store_fence(&_armed, 1);
+  _arm_time = os::javaTimeNanos();
+  Atomic::release_store_fence(&_armed, 1);
 }
 
 void VMOperationTimeoutTask::disarm() {
-  OrderAccess::release_store_fence(&_armed, 0);
+  Atomic::release_store_fence(&_armed, 0);
 }
 
 //------------------------------------------------------------------------------------------------------------------
 // Implementation of VMThread stuff
 
@@ -340,13 +308,13 @@
     // VM thread to enter any lock at Safepoint as long as its _owner is NULL.
     // If that happens after _terminate_lock->wait() has unset _owner
     // but before it actually drops the lock and waits, the notification below
     // may get lost and we will have a hang. To avoid this, we need to use
     // Mutex::lock_without_safepoint_check().
-    MutexLockerEx ml(_terminate_lock, Mutex::_no_safepoint_check_flag);
+    MonitorLocker ml(_terminate_lock, Mutex::_no_safepoint_check_flag);
     _terminated = true;
-    _terminate_lock->notify();
+    ml.notify();
   }
 
   // We are now racing with the VM termination being carried out in
   // another thread, so we don't "delete this". Numerous threads don't
   // get deleted when the VM terminates
@@ -357,13 +325,13 @@
 // Notify the VMThread that the last non-daemon JavaThread has terminated,
 // and wait until operation is performed.
 void VMThread::wait_for_vm_thread_exit() {
   assert(Thread::current()->is_Java_thread(), "Should be a JavaThread");
   assert(((JavaThread*)Thread::current())->is_terminated(), "Should be terminated");
-  { MutexLockerEx mu(VMOperationQueue_lock, Mutex::_no_safepoint_check_flag);
+  { MonitorLocker mu(VMOperationQueue_lock, Mutex::_no_safepoint_check_flag);
     _should_terminate = true;
-    VMOperationQueue_lock->notify();
+    mu.notify();
   }
 
   // Note: VM thread leaves at Safepoint. We are not stopped by Safepoint
   // because this thread has been removed from the threads list. But anything
   // that could get blocked by Safepoint should not be used after this point,
@@ -371,87 +339,93 @@
 
   // Wait until VM thread is terminated
   // Note: it should be OK to use Terminator_lock here. But this is called
   // at a very delicate time (VM shutdown) and we are operating in non- VM
   // thread at Safepoint. It's safer to not share lock with other threads.
-  { MutexLockerEx ml(_terminate_lock, Mutex::_no_safepoint_check_flag);
+  { MonitorLocker ml(_terminate_lock, Mutex::_no_safepoint_check_flag);
     while(!VMThread::is_terminated()) {
-        _terminate_lock->wait(Mutex::_no_safepoint_check_flag);
+      ml.wait();
     }
   }
 }
 
 static void post_vm_operation_event(EventExecuteVMOperation* event, VM_Operation* op) {
   assert(event != NULL, "invariant");
   assert(event->should_commit(), "invariant");
   assert(op != NULL, "invariant");
-  const bool is_concurrent = op->evaluate_concurrently();
   const bool evaluate_at_safepoint = op->evaluate_at_safepoint();
   event->set_operation(op->type());
   event->set_safepoint(evaluate_at_safepoint);
-  event->set_blocking(!is_concurrent);
-  // Only write caller thread information for non-concurrent vm operations.
-  // For concurrent vm operations, the thread id is set to 0 indicating thread is unknown.
-  // This is because the caller thread could have exited already.
-  event->set_caller(is_concurrent ? 0 : JFR_THREAD_ID(op->calling_thread()));
-  event->set_safepointId(evaluate_at_safepoint ? SafepointSynchronize::safepoint_counter() : 0);
+  event->set_blocking(true);
+  event->set_caller(JFR_THREAD_ID(op->calling_thread()));
+  event->set_safepointId(evaluate_at_safepoint ? SafepointSynchronize::safepoint_id() : 0);
   event->commit();
 }
 
 void VMThread::evaluate_operation(VM_Operation* op) {
   ResourceMark rm;
 
   {
     PerfTraceTime vm_op_timer(perf_accumulated_vm_operation_time());
     HOTSPOT_VMOPS_BEGIN(
                      (char *) op->name(), strlen(op->name()),
-                     op->evaluation_mode());
+                     op->evaluate_at_safepoint() ? 0 : 1);
 
     EventExecuteVMOperation event;
     op->evaluate();
     if (event.should_commit()) {
       post_vm_operation_event(&event, op);
     }
 
     HOTSPOT_VMOPS_END(
                      (char *) op->name(), strlen(op->name()),
-                     op->evaluation_mode());
+                     op->evaluate_at_safepoint() ? 0 : 1);
   }
 
-  // Last access of info in _cur_vm_operation!
-  bool c_heap_allocated = op->is_cheap_allocated();
-
   // Mark as completed
-  if (!op->evaluate_concurrently()) {
-    op->calling_thread()->increment_vm_operation_completed_count();
-  }
-  // It is unsafe to access the _cur_vm_operation after the 'increment_vm_operation_completed_count' call,
-  // since if it is stack allocated the calling thread might have deallocated
-  if (c_heap_allocated) {
-    delete _cur_vm_operation;
-  }
+  op->calling_thread()->increment_vm_operation_completed_count();
 }
 
 static VM_None    safepointALot_op("SafepointALot");
 static VM_Cleanup cleanup_op;
 
-VM_Operation* VMThread::no_op_safepoint(bool check_time) {
-  if (SafepointALot) {
-    return &safepointALot_op;
+class HandshakeALotClosure : public HandshakeClosure {
+ public:
+  HandshakeALotClosure() : HandshakeClosure("HandshakeALot") {}
+  void do_thread(Thread* thread) {
+#ifdef ASSERT
+    assert(thread->is_Java_thread(), "must be");
+    JavaThread* jt = (JavaThread*)thread;
+    jt->verify_states_for_handshake();
+#endif
   }
-  if (!SafepointSynchronize::is_cleanup_needed()) {
-    return NULL;
+};
+
+void VMThread::check_for_forced_cleanup() {
+  MonitorLocker mq(VMOperationQueue_lock,  Mutex::_no_safepoint_check_flag);
+  mq.notify();
+}
+
+VM_Operation* VMThread::no_op_safepoint() {
+  // Check for handshakes first since we may need to return a VMop.
+  if (HandshakeALot) {
+    HandshakeALotClosure hal_cl;
+    Handshake::execute(&hal_cl);
   }
-  if (check_time) {
-    long interval_ms = SafepointTracing::time_since_last_safepoint_ms();
-    bool max_time_exceeded = GuaranteedSafepointInterval != 0 &&
-                             (interval_ms > GuaranteedSafepointInterval);
-    if (!max_time_exceeded) {
-      return NULL;
-    }
+  // Check for a cleanup before SafepointALot to keep stats correct.
+  long interval_ms = SafepointTracing::time_since_last_safepoint_ms();
+  bool max_time_exceeded = GuaranteedSafepointInterval != 0 &&
+                           (interval_ms >= GuaranteedSafepointInterval);
+  if ((max_time_exceeded && SafepointSynchronize::is_cleanup_needed()) ||
+      SafepointSynchronize::is_forced_cleanup_needed()) {
+    return &cleanup_op;
+  }
+  if (SafepointALot) {
+    return &safepointALot_op;
   }
-  return &cleanup_op;
+  // Nothing to be done.
+  return NULL;
 }
 
 void VMThread::loop() {
   assert(_cur_vm_operation == NULL, "no current one should be executing");
 
@@ -461,51 +435,55 @@
     VM_Operation* safepoint_ops = NULL;
     //
     // Wait for VM operation
     //
     // use no_safepoint_check to get lock without attempting to "sneak"
-    { MutexLockerEx mu_queue(VMOperationQueue_lock,
+    { MonitorLocker mu_queue(VMOperationQueue_lock,
                              Mutex::_no_safepoint_check_flag);
 
       // Look for new operation
       assert(_cur_vm_operation == NULL, "no current one should be executing");
       _cur_vm_operation = _vm_queue->remove_next();
 
       // Stall time tracking code
-      if (PrintVMQWaitTime && _cur_vm_operation != NULL &&
-          !_cur_vm_operation->evaluate_concurrently()) {
-        long stall = os::javaTimeMillis() - _cur_vm_operation->timestamp();
+      if (PrintVMQWaitTime && _cur_vm_operation != NULL) {
+        jlong stall = nanos_to_millis(os::javaTimeNanos() - _cur_vm_operation->timestamp());
         if (stall > 0)
-          tty->print_cr("%s stall: %ld",  _cur_vm_operation->name(), stall);
+          tty->print_cr("%s stall: " JLONG_FORMAT,  _cur_vm_operation->name(), stall);
       }
 
       while (!should_terminate() && _cur_vm_operation == NULL) {
         // wait with a timeout to guarantee safepoints at regular intervals
-        bool timedout =
-          VMOperationQueue_lock->wait(Mutex::_no_safepoint_check_flag,
-                                      GuaranteedSafepointInterval);
+        // (if there is cleanup work to do)
+        (void)mu_queue.wait(GuaranteedSafepointInterval);
 
         // Support for self destruction
         if ((SelfDestructTimer != 0) && !VMError::is_error_reported() &&
             (os::elapsedTime() > (double)SelfDestructTimer * 60.0)) {
           tty->print_cr("VM self-destructed");
           exit(-1);
         }
 
-        if (timedout && (_cur_vm_operation = VMThread::no_op_safepoint(false)) != NULL) {
-          MutexUnlockerEx mul(VMOperationQueue_lock,
-                              Mutex::_no_safepoint_check_flag);
-          // Force a safepoint since we have not had one for at least
-          // 'GuaranteedSafepointInterval' milliseconds.  This will run all
-          // the clean-up processing that needs to be done regularly at a
-          // safepoint
-          SafepointSynchronize::begin();
-          #ifdef ASSERT
+        // If the queue contains a safepoint VM op,
+        // clean up will be done so we can skip this part.
+        if (!_vm_queue->peek_at_safepoint_priority()) {
+
+          // Have to unlock VMOperationQueue_lock just in case no_op_safepoint()
+          // has to do a handshake when HandshakeALot is enabled.
+          MutexUnlocker mul(VMOperationQueue_lock, Mutex::_no_safepoint_check_flag);
+          if ((_cur_vm_operation = VMThread::no_op_safepoint()) != NULL) {
+            // Force a safepoint since we have not had one for at least
+            // 'GuaranteedSafepointInterval' milliseconds and we need to clean
+            // something. This will run all the clean-up processing that needs
+            // to be done at a safepoint.
+            SafepointSynchronize::begin();
+            #ifdef ASSERT
             if (GCALotAtAllSafepoints) InterfaceSupport::check_gc_alot();
-          #endif
-          SafepointSynchronize::end();
-          _cur_vm_operation = NULL;
+            #endif
+            SafepointSynchronize::end();
+            _cur_vm_operation = NULL;
+          }
         }
         _cur_vm_operation = _vm_queue->remove_next();
 
         // If we are at a safepoint we will evaluate all the operations that
         // follow that also require a safepoint
@@ -529,12 +507,10 @@
       // If we are at a safepoint we will evaluate all the operations that
       // follow that also require a safepoint
       if (_cur_vm_operation->evaluate_at_safepoint()) {
         log_debug(vmthread)("Evaluating safepoint VM operation: %s", _cur_vm_operation->name());
 
-        _vm_queue->set_drain_list(safepoint_ops); // ensure ops can be scanned
-
         SafepointSynchronize::begin();
 
         if (_timeout_task != NULL) {
           _timeout_task->arm();
         }
@@ -544,15 +520,15 @@
         // the queue until there are none left
         do {
           _cur_vm_operation = safepoint_ops;
           if (_cur_vm_operation != NULL) {
             do {
+              EventMark em("Executing coalesced safepoint VM operation: %s", _cur_vm_operation->name());
               log_debug(vmthread)("Evaluating coalesced safepoint VM operation: %s", _cur_vm_operation->name());
               // evaluate_operation deletes the op object so we have
               // to grab the next op now
               VM_Operation* next = _cur_vm_operation->next();
-              _vm_queue->set_drain_list(next);
               evaluate_operation(_cur_vm_operation);
               _cur_vm_operation = next;
               _coalesced_count++;
             } while (_cur_vm_operation != NULL);
           }
@@ -566,20 +542,18 @@
           // that simply means the op will wait for the next major cycle of the
           // VMThread - just as it would if the GC thread lost the race for
           // the lock.
           if (_vm_queue->peek_at_safepoint_priority()) {
             // must hold lock while draining queue
-            MutexLockerEx mu_queue(VMOperationQueue_lock,
-                                     Mutex::_no_safepoint_check_flag);
+            MutexLocker mu_queue(VMOperationQueue_lock,
+                                 Mutex::_no_safepoint_check_flag);
             safepoint_ops = _vm_queue->drain_at_safepoint_priority();
           } else {
             safepoint_ops = NULL;
           }
         } while(safepoint_ops != NULL);
 
-        _vm_queue->set_drain_list(NULL);
-
         if (_timeout_task != NULL) {
           _timeout_task->disarm();
         }
 
         // Complete safepoint synchronization
@@ -606,25 +580,13 @@
         _cur_vm_operation = NULL;
       }
     }
 
     //
-    //  Notify (potential) waiting Java thread(s) - lock without safepoint
-    //  check so that sneaking is not possible
-    { MutexLockerEx mu(VMOperationRequest_lock,
-                       Mutex::_no_safepoint_check_flag);
-      VMOperationRequest_lock->notify_all();
-    }
-
-    //
-    // We want to make sure that we get to a safepoint regularly.
-    //
-    if ((_cur_vm_operation = VMThread::no_op_safepoint(false)) != NULL) {
-      HandleMark hm(VMThread::vm_thread());
-      SafepointSynchronize::begin();
-      SafepointSynchronize::end();
-      _cur_vm_operation = NULL;
+    //  Notify (potential) waiting Java thread(s)
+    { MonitorLocker mu(VMOperationRequest_lock, Mutex::_no_safepoint_check_flag);
+      mu.notify_all();
     }
   }
 }
 
 // A SkipGCALot object is used to elide the usual effect of gc-a-lot
@@ -656,65 +618,43 @@
   Thread* t = Thread::current();
 
   if (!t->is_VM_thread()) {
     SkipGCALot sgcalot(t);    // avoid re-entrant attempts to gc-a-lot
     // JavaThread or WatcherThread
-    bool concurrent = op->evaluate_concurrently();
-    // only blocking VM operations need to verify the caller's safepoint state:
-    if (!concurrent) {
-      t->check_for_valid_safepoint_state(true);
-    }
+    t->check_for_valid_safepoint_state();
 
     // New request from Java thread, evaluate prologue
     if (!op->doit_prologue()) {
       return;   // op was cancelled
     }
 
     // Setup VM_operations for execution
-    op->set_calling_thread(t, Thread::get_priority(t));
+    op->set_calling_thread(t);
 
-    // It does not make sense to execute the epilogue, if the VM operation object is getting
-    // deallocated by the VM thread.
-    bool execute_epilog = !op->is_cheap_allocated();
-    assert(!concurrent || op->is_cheap_allocated(), "concurrent => cheap_allocated");
-
-    // Get ticket number for non-concurrent VM operations
-    int ticket = 0;
-    if (!concurrent) {
-      ticket = t->vm_operation_ticket();
-    }
+    // Get ticket number for the VM operation
+    int ticket = t->vm_operation_ticket();
 
     // Add VM operation to list of waiting threads. We are guaranteed not to block while holding the
     // VMOperationQueue_lock, so we can block without a safepoint check. This allows vm operation requests
     // to be queued up during a safepoint synchronization.
     {
-      VMOperationQueue_lock->lock_without_safepoint_check();
+      MonitorLocker ml(VMOperationQueue_lock, Mutex::_no_safepoint_check_flag);
       log_debug(vmthread)("Adding VM operation: %s", op->name());
-      bool ok = _vm_queue->add(op);
-      op->set_timestamp(os::javaTimeMillis());
-      VMOperationQueue_lock->notify();
-      VMOperationQueue_lock->unlock();
-      // VM_Operation got skipped
-      if (!ok) {
-        assert(concurrent, "can only skip concurrent tasks");
-        if (op->is_cheap_allocated()) delete op;
-        return;
-      }
+      _vm_queue->add(op);
+      op->set_timestamp(os::javaTimeNanos());
+      ml.notify();
     }
-
-    if (!concurrent) {
-      // Wait for completion of request (non-concurrent)
+    {
+      // Wait for completion of request
       // Note: only a JavaThread triggers the safepoint check when locking
-      MutexLocker mu(VMOperationRequest_lock);
+      MonitorLocker ml(VMOperationRequest_lock,
+                       t->is_Java_thread() ? Mutex::_safepoint_check_flag : Mutex::_no_safepoint_check_flag);
       while(t->vm_operation_completed_count() < ticket) {
-        VMOperationRequest_lock->wait(!t->is_Java_thread());
+        ml.wait();
       }
     }
-
-    if (execute_epilog) {
-      op->doit_epilogue();
-    }
+    op->doit_epilogue();
   } else {
     // invoked by VM thread; usually nested VM operation
     assert(t->is_VM_thread(), "must be a VM thread");
     VM_Operation* prev_vm_operation = vm_operation();
     if (prev_vm_operation != NULL) {
@@ -722,11 +662,11 @@
       // does not allow nested scavenges or compiles.
       if (!prev_vm_operation->allow_nested_vm_operations()) {
         fatal("Nested VM operation %s requested by operation %s",
               op->name(), vm_operation()->name());
       }
-      op->set_calling_thread(prev_vm_operation->calling_thread(), prev_vm_operation->priority());
+      op->set_calling_thread(prev_vm_operation->calling_thread());
     }
 
     EventMark em("Executing %s VM operation: %s", prev_vm_operation ? "nested" : "", op->name());
 
     // Release all internal handles after operation is evaluated
@@ -739,48 +679,12 @@
       SafepointSynchronize::end();
     } else {
       op->evaluate();
     }
 
-    // Free memory if needed
-    if (op->is_cheap_allocated()) delete op;
-
     _cur_vm_operation = prev_vm_operation;
   }
 }
 
-
-void VMThread::oops_do(OopClosure* f, CodeBlobClosure* cf) {
-  Thread::oops_do(f, cf);
-  _vm_queue->oops_do(f);
-}
-
-//------------------------------------------------------------------------------------------------------------------
-#ifndef PRODUCT
-
-void VMOperationQueue::verify_queue(int prio) {
-  // Check that list is correctly linked
-  int length = _queue_length[prio];
-  VM_Operation *cur = _queue[prio];
-  int i;
-
-  // Check forward links
-  for(i = 0; i < length; i++) {
-    cur = cur->next();
-    assert(cur != _queue[prio], "list to short (forward)");
-  }
-  assert(cur->next() == _queue[prio], "list to long (forward)");
-
-  // Check backwards links
-  cur = _queue[prio];
-  for(i = 0; i < length; i++) {
-    cur = cur->prev();
-    assert(cur != _queue[prio], "list to short (backwards)");
-  }
-  assert(cur->prev() == _queue[prio], "list to long (backwards)");
-}
-
-#endif
-
 void VMThread::verify() {
   oops_do(&VerifyOopClosure::verify_oop, NULL);
 }
