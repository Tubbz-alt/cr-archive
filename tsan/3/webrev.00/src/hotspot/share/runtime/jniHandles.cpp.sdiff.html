<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/jniHandles.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="javaCalls.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="jniHandles.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/jniHandles.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 1998, 2018, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/shared/oopStorage.inline.hpp&quot;

 27 #include &quot;logging/log.hpp&quot;
 28 #include &quot;memory/iterator.hpp&quot;

 29 #include &quot;oops/access.inline.hpp&quot;
 30 #include &quot;oops/oop.inline.hpp&quot;
 31 #include &quot;runtime/handles.inline.hpp&quot;
 32 #include &quot;runtime/jniHandles.inline.hpp&quot;
 33 #include &quot;runtime/mutexLocker.hpp&quot;
 34 #include &quot;runtime/thread.inline.hpp&quot;
 35 #include &quot;utilities/align.hpp&quot;
 36 #include &quot;utilities/debug.hpp&quot;
 37 
<span class="line-modified"> 38 OopStorage* JNIHandles::_global_handles = NULL;</span>
<span class="line-modified"> 39 OopStorage* JNIHandles::_weak_global_handles = NULL;</span>

 40 
<span class="line-modified"> 41 OopStorage* JNIHandles::global_handles() {</span>
<span class="line-modified"> 42   assert(_global_handles != NULL, &quot;Uninitialized JNI global handles&quot;);</span>
<span class="line-removed"> 43   return _global_handles;</span>
 44 }
 45 
<span class="line-modified"> 46 OopStorage* JNIHandles::weak_global_handles() {</span>
<span class="line-modified"> 47   assert(_weak_global_handles != NULL, &quot;Uninitialized JNI weak global handles&quot;);</span>
<span class="line-modified"> 48   return _weak_global_handles;</span>




 49 }
 50 
 51 
 52 jobject JNIHandles::make_local(oop obj) {
 53   if (obj == NULL) {
 54     return NULL;                // ignore null handles
 55   } else {
 56     Thread* thread = Thread::current();
 57     assert(oopDesc::is_oop(obj), &quot;not an oop&quot;);
 58     assert(!current_thread_in_native(), &quot;must not be in native&quot;);
 59     return thread-&gt;active_handles()-&gt;allocate_handle(obj);
 60   }
 61 }
 62 
 63 
 64 // optimized versions
 65 
 66 jobject JNIHandles::make_local(Thread* thread, oop obj) {
 67   if (obj == NULL) {
 68     return NULL;                // ignore null handles
</pre>
<hr />
<pre>
 97     assert(alloc_failmode == AllocFailStrategy::RETURN_NULL, &quot;invariant&quot;);
 98   }
 99 }
100 
101 jobject JNIHandles::make_global(Handle obj, AllocFailType alloc_failmode) {
102   assert(!Universe::heap()-&gt;is_gc_active(), &quot;can&#39;t extend the root set during GC&quot;);
103   assert(!current_thread_in_native(), &quot;must not be in native&quot;);
104   jobject res = NULL;
105   if (!obj.is_null()) {
106     // ignore null handles
107     assert(oopDesc::is_oop(obj()), &quot;not an oop&quot;);
108     oop* ptr = global_handles()-&gt;allocate();
109     // Return NULL on allocation failure.
110     if (ptr != NULL) {
111       assert(*ptr == NULL, &quot;invariant&quot;);
112       NativeAccess&lt;&gt;::oop_store(ptr, obj());
113       res = reinterpret_cast&lt;jobject&gt;(ptr);
114     } else {
115       report_handle_allocation_failure(alloc_failmode, &quot;global&quot;);
116     }
<span class="line-removed">117   } else {</span>
<span class="line-removed">118     CHECK_UNHANDLED_OOPS_ONLY(Thread::current()-&gt;clear_unhandled_oops());</span>
119   }
120 
121   return res;
122 }
123 
124 
125 jobject JNIHandles::make_weak_global(Handle obj, AllocFailType alloc_failmode) {
126   assert(!Universe::heap()-&gt;is_gc_active(), &quot;can&#39;t extend the root set during GC&quot;);
127   assert(!current_thread_in_native(), &quot;must not be in native&quot;);
128   jobject res = NULL;
129   if (!obj.is_null()) {
130     // ignore null handles
131     assert(oopDesc::is_oop(obj()), &quot;not an oop&quot;);
132     oop* ptr = weak_global_handles()-&gt;allocate();
133     // Return NULL on allocation failure.
134     if (ptr != NULL) {
135       assert(*ptr == NULL, &quot;invariant&quot;);
136       NativeAccess&lt;ON_PHANTOM_OOP_REF&gt;::oop_store(ptr, obj());
137       char* tptr = reinterpret_cast&lt;char*&gt;(ptr) + weak_tag_value;
138       res = reinterpret_cast&lt;jobject&gt;(tptr);
139     } else {
140       report_handle_allocation_failure(alloc_failmode, &quot;weak global&quot;);
141     }
<span class="line-removed">142   } else {</span>
<span class="line-removed">143     CHECK_UNHANDLED_OOPS_ONLY(Thread::current()-&gt;clear_unhandled_oops());</span>
144   }
145   return res;
146 }
147 
148 // Resolve some erroneous cases to NULL, rather than treating them as
149 // possibly unchecked errors.  In particular, deleted handles are
150 // treated as NULL (though a deleted and later reallocated handle
151 // isn&#39;t detected).
152 oop JNIHandles::resolve_external_guard(jobject handle) {
153   oop result = NULL;
154   if (handle != NULL) {
155     result = resolve_impl&lt;DECORATORS_NONE, true /* external_guard */&gt;(handle);
156   }
157   return result;
158 }
159 
160 bool JNIHandles::is_global_weak_cleared(jweak handle) {
161   assert(handle != NULL, &quot;precondition&quot;);
162   assert(is_jweak(handle), &quot;not a weak handle&quot;);
163   oop* oop_ptr = jweak_ptr(handle);
</pre>
<hr />
<pre>
183     weak_global_handles()-&gt;release(oop_ptr);
184   }
185 }
186 
187 
188 void JNIHandles::oops_do(OopClosure* f) {
189   global_handles()-&gt;oops_do(f);
190 }
191 
192 
193 void JNIHandles::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* f) {
194   weak_global_handles()-&gt;weak_oops_do(is_alive, f);
195 }
196 
197 
198 void JNIHandles::weak_oops_do(OopClosure* f) {
199   weak_global_handles()-&gt;weak_oops_do(f);
200 }
201 
202 
<span class="line-removed">203 void JNIHandles::initialize() {</span>
<span class="line-removed">204   _global_handles = new OopStorage(&quot;JNI Global&quot;,</span>
<span class="line-removed">205                                    JNIGlobalAlloc_lock,</span>
<span class="line-removed">206                                    JNIGlobalActive_lock);</span>
<span class="line-removed">207   _weak_global_handles = new OopStorage(&quot;JNI Weak&quot;,</span>
<span class="line-removed">208                                         JNIWeakAlloc_lock,</span>
<span class="line-removed">209                                         JNIWeakActive_lock);</span>
<span class="line-removed">210 }</span>
<span class="line-removed">211 </span>
<span class="line-removed">212 </span>
213 inline bool is_storage_handle(const OopStorage* storage, const oop* ptr) {
214   return storage-&gt;allocation_status(ptr) == OopStorage::ALLOCATED_ENTRY;
215 }
216 
217 
218 jobjectRefType JNIHandles::handle_type(Thread* thread, jobject handle) {
219   assert(handle != NULL, &quot;precondition&quot;);
220   jobjectRefType result = JNIInvalidRefType;
221   if (is_jweak(handle)) {
222     if (is_storage_handle(weak_global_handles(), jweak_ptr(handle))) {
223       result = JNIWeakGlobalRefType;
224     }
225   } else {
226     switch (global_handles()-&gt;allocation_status(jobject_ptr(handle))) {
227     case OopStorage::ALLOCATED_ENTRY:
228       result = JNIGlobalRefType;
229       break;
230 
231     case OopStorage::UNALLOCATED_ENTRY:
232       break;                    // Invalid global handle
</pre>
<hr />
<pre>
292 size_t JNIHandles::global_handle_memory_usage() {
293   return global_handles()-&gt;total_memory_usage();
294 }
295 
296 size_t JNIHandles::weak_global_handle_memory_usage() {
297   return weak_global_handles()-&gt;total_memory_usage();
298 }
299 
300 
301 // We assume this is called at a safepoint: no lock is needed.
302 void JNIHandles::print_on(outputStream* st) {
303   assert(SafepointSynchronize::is_at_safepoint(), &quot;must be at safepoint&quot;);
304 
305   st-&gt;print_cr(&quot;JNI global refs: &quot; SIZE_FORMAT &quot;, weak refs: &quot; SIZE_FORMAT,
306                global_handles()-&gt;allocation_count(),
307                weak_global_handles()-&gt;allocation_count());
308   st-&gt;cr();
309   st-&gt;flush();
310 }
311 


312 class VerifyJNIHandles: public OopClosure {
313 public:
314   virtual void do_oop(oop* root) {
315     guarantee(oopDesc::is_oop_or_null(RawAccess&lt;&gt;::oop_load(root)), &quot;Invalid oop&quot;);
316   }
317   virtual void do_oop(narrowOop* root) { ShouldNotReachHere(); }
318 };
319 
320 void JNIHandles::verify() {
321   VerifyJNIHandles verify_handle;
322 
323   oops_do(&amp;verify_handle);
324   weak_oops_do(&amp;verify_handle);
325 }
326 
327 // This method is implemented here to avoid circular includes between
328 // jniHandles.hpp and thread.hpp.
329 bool JNIHandles::current_thread_in_native() {
330   Thread* thread = Thread::current();
331   return (thread-&gt;is_Java_thread() &amp;&amp;
332           JavaThread::current()-&gt;thread_state() == _thread_in_native);
333 }
334 
335 
<span class="line-removed">336 void jni_handles_init() {</span>
<span class="line-removed">337   JNIHandles::initialize();</span>
<span class="line-removed">338 }</span>
<span class="line-removed">339 </span>
<span class="line-removed">340 </span>
341 int             JNIHandleBlock::_blocks_allocated     = 0;
342 JNIHandleBlock* JNIHandleBlock::_block_free_list      = NULL;
343 #ifndef PRODUCT
344 JNIHandleBlock* JNIHandleBlock::_block_list           = NULL;
345 #endif
346 


















347 
348 #ifdef ASSERT
349 void JNIHandleBlock::zap() {
350   // Zap block values
351   _top = 0;
352   for (int index = 0; index &lt; block_size_in_oops; index++) {
353     // NOT using Access here; just bare clobbering to NULL, since the
354     // block no longer contains valid oops.
<span class="line-modified">355     _handles[index] = NULL;</span>
356   }
357 }
358 #endif // ASSERT
359 
360 JNIHandleBlock* JNIHandleBlock::allocate_block(Thread* thread)  {
361   assert(thread == NULL || thread == Thread::current(), &quot;sanity check&quot;);
362   JNIHandleBlock* block;
363   // Check the thread-local free list for a block so we don&#39;t
364   // have to acquire a mutex.
365   if (thread != NULL &amp;&amp; thread-&gt;free_handle_block() != NULL) {
366     block = thread-&gt;free_handle_block();
367     thread-&gt;set_free_handle_block(block-&gt;_next);
368   }
369   else {
370     // locking with safepoint checking introduces a potential deadlock:
371     // - we would hold JNIHandleBlockFreeList_lock and then Threads_lock
372     // - another would hold Threads_lock (jni_AttachCurrentThread) and then
373     //   JNIHandleBlockFreeList_lock (JNIHandleBlock::allocate_block)
<span class="line-modified">374     MutexLockerEx ml(JNIHandleBlockFreeList_lock,</span>
<span class="line-modified">375                      Mutex::_no_safepoint_check_flag);</span>
376     if (_block_free_list == NULL) {
377       // Allocate new block
378       block = new JNIHandleBlock();
379       _blocks_allocated++;
380       block-&gt;zap();
381       #ifndef PRODUCT
382       // Link new block to list of all allocated blocks
383       block-&gt;_block_list_link = _block_list;
384       _block_list = block;
385       #endif
386     } else {
387       // Get block from free list
388       block = _block_free_list;
389       _block_free_list = _block_free_list-&gt;_next;
390     }
391   }
392   block-&gt;_top = 0;
393   block-&gt;_next = NULL;
394   block-&gt;_pop_frame_link = NULL;
395   block-&gt;_planned_capacity = block_size_in_oops;
</pre>
<hr />
<pre>
410   // See for instance JavaThread::exit().
411   if (thread != NULL ) {
412     block-&gt;zap();
413     JNIHandleBlock* freelist = thread-&gt;free_handle_block();
414     block-&gt;_pop_frame_link = NULL;
415     thread-&gt;set_free_handle_block(block);
416 
417     // Add original freelist to end of chain
418     if ( freelist != NULL ) {
419       while ( block-&gt;_next != NULL ) block = block-&gt;_next;
420       block-&gt;_next = freelist;
421     }
422     block = NULL;
423   }
424   if (block != NULL) {
425     // Return blocks to free list
426     // locking with safepoint checking introduces a potential deadlock:
427     // - we would hold JNIHandleBlockFreeList_lock and then Threads_lock
428     // - another would hold Threads_lock (jni_AttachCurrentThread) and then
429     //   JNIHandleBlockFreeList_lock (JNIHandleBlock::allocate_block)
<span class="line-modified">430     MutexLockerEx ml(JNIHandleBlockFreeList_lock,</span>
<span class="line-modified">431                      Mutex::_no_safepoint_check_flag);</span>
432     while (block != NULL) {
433       block-&gt;zap();
434       JNIHandleBlock* next = block-&gt;_next;
435       block-&gt;_next = _block_free_list;
436       _block_free_list = block;
437       block = next;
438     }
439   }
440   if (pop_frame_link != NULL) {
441     // As a sanity check we release blocks pointed to by the pop_frame_link.
442     // This should never happen (only if PopLocalFrame is not called the
443     // correct number of times).
444     release_block(pop_frame_link, thread);
445   }
446 }
447 
448 
449 void JNIHandleBlock::oops_do(OopClosure* f) {
450   JNIHandleBlock* current_chain = this;
451   // Iterate over chain of blocks, followed by chains linked through the
452   // pop frame links.
453   while (current_chain != NULL) {
454     for (JNIHandleBlock* current = current_chain; current != NULL;
455          current = current-&gt;_next) {
456       assert(current == current_chain || current-&gt;pop_frame_link() == NULL,
457         &quot;only blocks first in chain should have pop frame link set&quot;);
458       for (int index = 0; index &lt; current-&gt;_top; index++) {
<span class="line-modified">459         oop* root = &amp;(current-&gt;_handles)[index];</span>
<span class="line-modified">460         oop value = *root;</span>
461         // traverse heap pointers only, not deleted handles or free list
462         // pointers
<span class="line-modified">463         if (value != NULL &amp;&amp; Universe::heap()-&gt;is_in_reserved(value)) {</span>

464           f-&gt;do_oop(root);
465         }
466       }
467       // the next handle block is valid only if current block is full
468       if (current-&gt;_top &lt; block_size_in_oops) {
469         break;
470       }
471     }
472     current_chain = current_chain-&gt;pop_frame_link();
473   }
474 }
475 
476 
477 jobject JNIHandleBlock::allocate_handle(oop obj) {
<span class="line-modified">478   assert(Universe::heap()-&gt;is_in_reserved(obj), &quot;sanity check&quot;);</span>
479   if (_top == 0) {
480     // This is the first allocation or the initial block got zapped when
481     // entering a native function. If we have any following blocks they are
482     // not valid anymore.
483     for (JNIHandleBlock* current = _next; current != NULL;
484          current = current-&gt;_next) {
485       assert(current-&gt;_last == NULL, &quot;only first block should have _last set&quot;);
486       assert(current-&gt;_free_list == NULL,
487              &quot;only first block should have _free_list set&quot;);
488       if (current-&gt;_top == 0) {
489         // All blocks after the first clear trailing block are already cleared.
490 #ifdef ASSERT
491         for (current = current-&gt;_next; current != NULL; current = current-&gt;_next) {
492           assert(current-&gt;_top == 0, &quot;trailing blocks must already be cleared&quot;);
493         }
494 #endif
495         break;
496       }
497       current-&gt;_top = 0;
498       current-&gt;zap();
499     }
500     // Clear initial block
501     _free_list = NULL;
502     _allocate_before_rebuild = 0;
503     _last = this;
504     zap();
505   }
506 
507   // Try last block
508   if (_last-&gt;_top &lt; block_size_in_oops) {
<span class="line-modified">509     oop* handle = &amp;(_last-&gt;_handles)[_last-&gt;_top++];</span>
510     NativeAccess&lt;IS_DEST_UNINITIALIZED&gt;::oop_store(handle, obj);
511     return (jobject) handle;
512   }
513 
514   // Try free list
515   if (_free_list != NULL) {
<span class="line-modified">516     oop* handle = _free_list;</span>
<span class="line-modified">517     _free_list = (oop*) *_free_list;</span>
518     NativeAccess&lt;IS_DEST_UNINITIALIZED&gt;::oop_store(handle, obj);
519     return (jobject) handle;
520   }
521   // Check if unused block follow last
522   if (_last-&gt;_next != NULL) {
523     // update last and retry
524     _last = _last-&gt;_next;
525     return allocate_handle(obj);
526   }
527 
528   // No space available, we have to rebuild free list or expand
529   if (_allocate_before_rebuild == 0) {
530       rebuild_free_list();        // updates _allocate_before_rebuild counter
531   } else {
532     // Append new block
533     Thread* thread = Thread::current();
534     Handle obj_handle(thread, obj);
535     // This can block, so we need to preserve obj across call.
536     _last-&gt;_next = JNIHandleBlock::allocate_block(thread);
537     _last = _last-&gt;_next;
538     _allocate_before_rebuild--;
539     obj = obj_handle();
540   }
541   return allocate_handle(obj);  // retry
542 }
543 
544 void JNIHandleBlock::rebuild_free_list() {
545   assert(_allocate_before_rebuild == 0 &amp;&amp; _free_list == NULL, &quot;just checking&quot;);
546   int free = 0;
547   int blocks = 0;
548   for (JNIHandleBlock* current = this; current != NULL; current = current-&gt;_next) {
549     for (int index = 0; index &lt; current-&gt;_top; index++) {
<span class="line-modified">550       oop* handle = &amp;(current-&gt;_handles)[index];</span>
<span class="line-modified">551       if (*handle == NULL) {</span>
552         // this handle was cleared out by a delete call, reuse it
<span class="line-modified">553         *handle = (oop) _free_list;</span>
554         _free_list = handle;
555         free++;
556       }
557     }
558     // we should not rebuild free list if there are unused handles at the end
559     assert(current-&gt;_top == block_size_in_oops, &quot;just checking&quot;);
560     blocks++;
561   }
562   // Heuristic: if more than half of the handles are free we rebuild next time
563   // as well, otherwise we append a corresponding number of new blocks before
564   // attempting a free list rebuild again.
565   int total = blocks * block_size_in_oops;
566   int extra = total - 2*free;
567   if (extra &gt; 0) {
568     // Not as many free handles as we would like - compute number of new blocks to append
569     _allocate_before_rebuild = (extra + block_size_in_oops - 1) / block_size_in_oops;
570   }
571 }
572 
573 
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/shared/oopStorage.inline.hpp&quot;
<span class="line-added"> 27 #include &quot;gc/shared/oopStorageSet.hpp&quot;</span>
 28 #include &quot;logging/log.hpp&quot;
 29 #include &quot;memory/iterator.hpp&quot;
<span class="line-added"> 30 #include &quot;memory/universe.hpp&quot;</span>
 31 #include &quot;oops/access.inline.hpp&quot;
 32 #include &quot;oops/oop.inline.hpp&quot;
 33 #include &quot;runtime/handles.inline.hpp&quot;
 34 #include &quot;runtime/jniHandles.inline.hpp&quot;
 35 #include &quot;runtime/mutexLocker.hpp&quot;
 36 #include &quot;runtime/thread.inline.hpp&quot;
 37 #include &quot;utilities/align.hpp&quot;
 38 #include &quot;utilities/debug.hpp&quot;
 39 
<span class="line-modified"> 40 static OopStorage* global_handles() {</span>
<span class="line-modified"> 41   return OopStorageSet::jni_global();</span>
<span class="line-added"> 42 }</span>
 43 
<span class="line-modified"> 44 static OopStorage* weak_global_handles() {</span>
<span class="line-modified"> 45   return OopStorageSet::jni_weak();</span>

 46 }
 47 
<span class="line-modified"> 48 // Serviceability agent support.</span>
<span class="line-modified"> 49 OopStorage* JNIHandles::_global_handles = NULL;</span>
<span class="line-modified"> 50 OopStorage* JNIHandles::_weak_global_handles = NULL;</span>
<span class="line-added"> 51 </span>
<span class="line-added"> 52 void jni_handles_init() {</span>
<span class="line-added"> 53   JNIHandles::_global_handles = global_handles();</span>
<span class="line-added"> 54   JNIHandles::_weak_global_handles = weak_global_handles();</span>
 55 }
 56 
 57 
 58 jobject JNIHandles::make_local(oop obj) {
 59   if (obj == NULL) {
 60     return NULL;                // ignore null handles
 61   } else {
 62     Thread* thread = Thread::current();
 63     assert(oopDesc::is_oop(obj), &quot;not an oop&quot;);
 64     assert(!current_thread_in_native(), &quot;must not be in native&quot;);
 65     return thread-&gt;active_handles()-&gt;allocate_handle(obj);
 66   }
 67 }
 68 
 69 
 70 // optimized versions
 71 
 72 jobject JNIHandles::make_local(Thread* thread, oop obj) {
 73   if (obj == NULL) {
 74     return NULL;                // ignore null handles
</pre>
<hr />
<pre>
103     assert(alloc_failmode == AllocFailStrategy::RETURN_NULL, &quot;invariant&quot;);
104   }
105 }
106 
107 jobject JNIHandles::make_global(Handle obj, AllocFailType alloc_failmode) {
108   assert(!Universe::heap()-&gt;is_gc_active(), &quot;can&#39;t extend the root set during GC&quot;);
109   assert(!current_thread_in_native(), &quot;must not be in native&quot;);
110   jobject res = NULL;
111   if (!obj.is_null()) {
112     // ignore null handles
113     assert(oopDesc::is_oop(obj()), &quot;not an oop&quot;);
114     oop* ptr = global_handles()-&gt;allocate();
115     // Return NULL on allocation failure.
116     if (ptr != NULL) {
117       assert(*ptr == NULL, &quot;invariant&quot;);
118       NativeAccess&lt;&gt;::oop_store(ptr, obj());
119       res = reinterpret_cast&lt;jobject&gt;(ptr);
120     } else {
121       report_handle_allocation_failure(alloc_failmode, &quot;global&quot;);
122     }


123   }
124 
125   return res;
126 }
127 
128 
129 jobject JNIHandles::make_weak_global(Handle obj, AllocFailType alloc_failmode) {
130   assert(!Universe::heap()-&gt;is_gc_active(), &quot;can&#39;t extend the root set during GC&quot;);
131   assert(!current_thread_in_native(), &quot;must not be in native&quot;);
132   jobject res = NULL;
133   if (!obj.is_null()) {
134     // ignore null handles
135     assert(oopDesc::is_oop(obj()), &quot;not an oop&quot;);
136     oop* ptr = weak_global_handles()-&gt;allocate();
137     // Return NULL on allocation failure.
138     if (ptr != NULL) {
139       assert(*ptr == NULL, &quot;invariant&quot;);
140       NativeAccess&lt;ON_PHANTOM_OOP_REF&gt;::oop_store(ptr, obj());
141       char* tptr = reinterpret_cast&lt;char*&gt;(ptr) + weak_tag_value;
142       res = reinterpret_cast&lt;jobject&gt;(tptr);
143     } else {
144       report_handle_allocation_failure(alloc_failmode, &quot;weak global&quot;);
145     }


146   }
147   return res;
148 }
149 
150 // Resolve some erroneous cases to NULL, rather than treating them as
151 // possibly unchecked errors.  In particular, deleted handles are
152 // treated as NULL (though a deleted and later reallocated handle
153 // isn&#39;t detected).
154 oop JNIHandles::resolve_external_guard(jobject handle) {
155   oop result = NULL;
156   if (handle != NULL) {
157     result = resolve_impl&lt;DECORATORS_NONE, true /* external_guard */&gt;(handle);
158   }
159   return result;
160 }
161 
162 bool JNIHandles::is_global_weak_cleared(jweak handle) {
163   assert(handle != NULL, &quot;precondition&quot;);
164   assert(is_jweak(handle), &quot;not a weak handle&quot;);
165   oop* oop_ptr = jweak_ptr(handle);
</pre>
<hr />
<pre>
185     weak_global_handles()-&gt;release(oop_ptr);
186   }
187 }
188 
189 
190 void JNIHandles::oops_do(OopClosure* f) {
191   global_handles()-&gt;oops_do(f);
192 }
193 
194 
195 void JNIHandles::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* f) {
196   weak_global_handles()-&gt;weak_oops_do(is_alive, f);
197 }
198 
199 
200 void JNIHandles::weak_oops_do(OopClosure* f) {
201   weak_global_handles()-&gt;weak_oops_do(f);
202 }
203 
204 










205 inline bool is_storage_handle(const OopStorage* storage, const oop* ptr) {
206   return storage-&gt;allocation_status(ptr) == OopStorage::ALLOCATED_ENTRY;
207 }
208 
209 
210 jobjectRefType JNIHandles::handle_type(Thread* thread, jobject handle) {
211   assert(handle != NULL, &quot;precondition&quot;);
212   jobjectRefType result = JNIInvalidRefType;
213   if (is_jweak(handle)) {
214     if (is_storage_handle(weak_global_handles(), jweak_ptr(handle))) {
215       result = JNIWeakGlobalRefType;
216     }
217   } else {
218     switch (global_handles()-&gt;allocation_status(jobject_ptr(handle))) {
219     case OopStorage::ALLOCATED_ENTRY:
220       result = JNIGlobalRefType;
221       break;
222 
223     case OopStorage::UNALLOCATED_ENTRY:
224       break;                    // Invalid global handle
</pre>
<hr />
<pre>
284 size_t JNIHandles::global_handle_memory_usage() {
285   return global_handles()-&gt;total_memory_usage();
286 }
287 
288 size_t JNIHandles::weak_global_handle_memory_usage() {
289   return weak_global_handles()-&gt;total_memory_usage();
290 }
291 
292 
293 // We assume this is called at a safepoint: no lock is needed.
294 void JNIHandles::print_on(outputStream* st) {
295   assert(SafepointSynchronize::is_at_safepoint(), &quot;must be at safepoint&quot;);
296 
297   st-&gt;print_cr(&quot;JNI global refs: &quot; SIZE_FORMAT &quot;, weak refs: &quot; SIZE_FORMAT,
298                global_handles()-&gt;allocation_count(),
299                weak_global_handles()-&gt;allocation_count());
300   st-&gt;cr();
301   st-&gt;flush();
302 }
303 
<span class="line-added">304 void JNIHandles::print() { print_on(tty); }</span>
<span class="line-added">305 </span>
306 class VerifyJNIHandles: public OopClosure {
307 public:
308   virtual void do_oop(oop* root) {
309     guarantee(oopDesc::is_oop_or_null(RawAccess&lt;&gt;::oop_load(root)), &quot;Invalid oop&quot;);
310   }
311   virtual void do_oop(narrowOop* root) { ShouldNotReachHere(); }
312 };
313 
314 void JNIHandles::verify() {
315   VerifyJNIHandles verify_handle;
316 
317   oops_do(&amp;verify_handle);
318   weak_oops_do(&amp;verify_handle);
319 }
320 
321 // This method is implemented here to avoid circular includes between
322 // jniHandles.hpp and thread.hpp.
323 bool JNIHandles::current_thread_in_native() {
324   Thread* thread = Thread::current();
325   return (thread-&gt;is_Java_thread() &amp;&amp;
326           JavaThread::current()-&gt;thread_state() == _thread_in_native);
327 }
328 
329 





330 int             JNIHandleBlock::_blocks_allocated     = 0;
331 JNIHandleBlock* JNIHandleBlock::_block_free_list      = NULL;
332 #ifndef PRODUCT
333 JNIHandleBlock* JNIHandleBlock::_block_list           = NULL;
334 #endif
335 
<span class="line-added">336 static inline bool is_tagged_free_list(uintptr_t value) {</span>
<span class="line-added">337   return (value &amp; 1u) != 0;</span>
<span class="line-added">338 }</span>
<span class="line-added">339 </span>
<span class="line-added">340 static inline uintptr_t tag_free_list(uintptr_t value) {</span>
<span class="line-added">341   return value | 1u;</span>
<span class="line-added">342 }</span>
<span class="line-added">343 </span>
<span class="line-added">344 static inline uintptr_t untag_free_list(uintptr_t value) {</span>
<span class="line-added">345   return value &amp; ~(uintptr_t)1u;</span>
<span class="line-added">346 }</span>
<span class="line-added">347 </span>
<span class="line-added">348 // There is a freelist of handles running through the JNIHandleBlock</span>
<span class="line-added">349 // with a tagged next pointer, distinguishing these next pointers from</span>
<span class="line-added">350 // oops. The freelist handling currently relies on the size of oops</span>
<span class="line-added">351 // being the same as a native pointer. If this ever changes, then</span>
<span class="line-added">352 // this freelist handling must change too.</span>
<span class="line-added">353 STATIC_ASSERT(sizeof(oop) == sizeof(uintptr_t));</span>
354 
355 #ifdef ASSERT
356 void JNIHandleBlock::zap() {
357   // Zap block values
358   _top = 0;
359   for (int index = 0; index &lt; block_size_in_oops; index++) {
360     // NOT using Access here; just bare clobbering to NULL, since the
361     // block no longer contains valid oops.
<span class="line-modified">362     _handles[index] = 0;</span>
363   }
364 }
365 #endif // ASSERT
366 
367 JNIHandleBlock* JNIHandleBlock::allocate_block(Thread* thread)  {
368   assert(thread == NULL || thread == Thread::current(), &quot;sanity check&quot;);
369   JNIHandleBlock* block;
370   // Check the thread-local free list for a block so we don&#39;t
371   // have to acquire a mutex.
372   if (thread != NULL &amp;&amp; thread-&gt;free_handle_block() != NULL) {
373     block = thread-&gt;free_handle_block();
374     thread-&gt;set_free_handle_block(block-&gt;_next);
375   }
376   else {
377     // locking with safepoint checking introduces a potential deadlock:
378     // - we would hold JNIHandleBlockFreeList_lock and then Threads_lock
379     // - another would hold Threads_lock (jni_AttachCurrentThread) and then
380     //   JNIHandleBlockFreeList_lock (JNIHandleBlock::allocate_block)
<span class="line-modified">381     MutexLocker ml(JNIHandleBlockFreeList_lock,</span>
<span class="line-modified">382                    Mutex::_no_safepoint_check_flag);</span>
383     if (_block_free_list == NULL) {
384       // Allocate new block
385       block = new JNIHandleBlock();
386       _blocks_allocated++;
387       block-&gt;zap();
388       #ifndef PRODUCT
389       // Link new block to list of all allocated blocks
390       block-&gt;_block_list_link = _block_list;
391       _block_list = block;
392       #endif
393     } else {
394       // Get block from free list
395       block = _block_free_list;
396       _block_free_list = _block_free_list-&gt;_next;
397     }
398   }
399   block-&gt;_top = 0;
400   block-&gt;_next = NULL;
401   block-&gt;_pop_frame_link = NULL;
402   block-&gt;_planned_capacity = block_size_in_oops;
</pre>
<hr />
<pre>
417   // See for instance JavaThread::exit().
418   if (thread != NULL ) {
419     block-&gt;zap();
420     JNIHandleBlock* freelist = thread-&gt;free_handle_block();
421     block-&gt;_pop_frame_link = NULL;
422     thread-&gt;set_free_handle_block(block);
423 
424     // Add original freelist to end of chain
425     if ( freelist != NULL ) {
426       while ( block-&gt;_next != NULL ) block = block-&gt;_next;
427       block-&gt;_next = freelist;
428     }
429     block = NULL;
430   }
431   if (block != NULL) {
432     // Return blocks to free list
433     // locking with safepoint checking introduces a potential deadlock:
434     // - we would hold JNIHandleBlockFreeList_lock and then Threads_lock
435     // - another would hold Threads_lock (jni_AttachCurrentThread) and then
436     //   JNIHandleBlockFreeList_lock (JNIHandleBlock::allocate_block)
<span class="line-modified">437     MutexLocker ml(JNIHandleBlockFreeList_lock,</span>
<span class="line-modified">438                    Mutex::_no_safepoint_check_flag);</span>
439     while (block != NULL) {
440       block-&gt;zap();
441       JNIHandleBlock* next = block-&gt;_next;
442       block-&gt;_next = _block_free_list;
443       _block_free_list = block;
444       block = next;
445     }
446   }
447   if (pop_frame_link != NULL) {
448     // As a sanity check we release blocks pointed to by the pop_frame_link.
449     // This should never happen (only if PopLocalFrame is not called the
450     // correct number of times).
451     release_block(pop_frame_link, thread);
452   }
453 }
454 
455 
456 void JNIHandleBlock::oops_do(OopClosure* f) {
457   JNIHandleBlock* current_chain = this;
458   // Iterate over chain of blocks, followed by chains linked through the
459   // pop frame links.
460   while (current_chain != NULL) {
461     for (JNIHandleBlock* current = current_chain; current != NULL;
462          current = current-&gt;_next) {
463       assert(current == current_chain || current-&gt;pop_frame_link() == NULL,
464         &quot;only blocks first in chain should have pop frame link set&quot;);
465       for (int index = 0; index &lt; current-&gt;_top; index++) {
<span class="line-modified">466         uintptr_t* addr = &amp;(current-&gt;_handles)[index];</span>
<span class="line-modified">467         uintptr_t value = *addr;</span>
468         // traverse heap pointers only, not deleted handles or free list
469         // pointers
<span class="line-modified">470         if (value != 0 &amp;&amp; !is_tagged_free_list(value)) {</span>
<span class="line-added">471           oop* root = (oop*)addr;</span>
472           f-&gt;do_oop(root);
473         }
474       }
475       // the next handle block is valid only if current block is full
476       if (current-&gt;_top &lt; block_size_in_oops) {
477         break;
478       }
479     }
480     current_chain = current_chain-&gt;pop_frame_link();
481   }
482 }
483 
484 
485 jobject JNIHandleBlock::allocate_handle(oop obj) {
<span class="line-modified">486   assert(Universe::heap()-&gt;is_in(obj), &quot;sanity check&quot;);</span>
487   if (_top == 0) {
488     // This is the first allocation or the initial block got zapped when
489     // entering a native function. If we have any following blocks they are
490     // not valid anymore.
491     for (JNIHandleBlock* current = _next; current != NULL;
492          current = current-&gt;_next) {
493       assert(current-&gt;_last == NULL, &quot;only first block should have _last set&quot;);
494       assert(current-&gt;_free_list == NULL,
495              &quot;only first block should have _free_list set&quot;);
496       if (current-&gt;_top == 0) {
497         // All blocks after the first clear trailing block are already cleared.
498 #ifdef ASSERT
499         for (current = current-&gt;_next; current != NULL; current = current-&gt;_next) {
500           assert(current-&gt;_top == 0, &quot;trailing blocks must already be cleared&quot;);
501         }
502 #endif
503         break;
504       }
505       current-&gt;_top = 0;
506       current-&gt;zap();
507     }
508     // Clear initial block
509     _free_list = NULL;
510     _allocate_before_rebuild = 0;
511     _last = this;
512     zap();
513   }
514 
515   // Try last block
516   if (_last-&gt;_top &lt; block_size_in_oops) {
<span class="line-modified">517     oop* handle = (oop*)&amp;(_last-&gt;_handles)[_last-&gt;_top++];</span>
518     NativeAccess&lt;IS_DEST_UNINITIALIZED&gt;::oop_store(handle, obj);
519     return (jobject) handle;
520   }
521 
522   // Try free list
523   if (_free_list != NULL) {
<span class="line-modified">524     oop* handle = (oop*)_free_list;</span>
<span class="line-modified">525     _free_list = (uintptr_t*) untag_free_list(*_free_list);</span>
526     NativeAccess&lt;IS_DEST_UNINITIALIZED&gt;::oop_store(handle, obj);
527     return (jobject) handle;
528   }
529   // Check if unused block follow last
530   if (_last-&gt;_next != NULL) {
531     // update last and retry
532     _last = _last-&gt;_next;
533     return allocate_handle(obj);
534   }
535 
536   // No space available, we have to rebuild free list or expand
537   if (_allocate_before_rebuild == 0) {
538       rebuild_free_list();        // updates _allocate_before_rebuild counter
539   } else {
540     // Append new block
541     Thread* thread = Thread::current();
542     Handle obj_handle(thread, obj);
543     // This can block, so we need to preserve obj across call.
544     _last-&gt;_next = JNIHandleBlock::allocate_block(thread);
545     _last = _last-&gt;_next;
546     _allocate_before_rebuild--;
547     obj = obj_handle();
548   }
549   return allocate_handle(obj);  // retry
550 }
551 
552 void JNIHandleBlock::rebuild_free_list() {
553   assert(_allocate_before_rebuild == 0 &amp;&amp; _free_list == NULL, &quot;just checking&quot;);
554   int free = 0;
555   int blocks = 0;
556   for (JNIHandleBlock* current = this; current != NULL; current = current-&gt;_next) {
557     for (int index = 0; index &lt; current-&gt;_top; index++) {
<span class="line-modified">558       uintptr_t* handle = &amp;(current-&gt;_handles)[index];</span>
<span class="line-modified">559       if (*handle == 0) {</span>
560         // this handle was cleared out by a delete call, reuse it
<span class="line-modified">561         *handle = _free_list == NULL ? 0 : tag_free_list((uintptr_t)_free_list);</span>
562         _free_list = handle;
563         free++;
564       }
565     }
566     // we should not rebuild free list if there are unused handles at the end
567     assert(current-&gt;_top == block_size_in_oops, &quot;just checking&quot;);
568     blocks++;
569   }
570   // Heuristic: if more than half of the handles are free we rebuild next time
571   // as well, otherwise we append a corresponding number of new blocks before
572   // attempting a free list rebuild again.
573   int total = blocks * block_size_in_oops;
574   int extra = total - 2*free;
575   if (extra &gt; 0) {
576     // Not as many free handles as we would like - compute number of new blocks to append
577     _allocate_before_rebuild = (extra + block_size_in_oops - 1) / block_size_in_oops;
578   }
579 }
580 
581 
</pre>
</td>
</tr>
</table>
<center><a href="javaCalls.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="jniHandles.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>