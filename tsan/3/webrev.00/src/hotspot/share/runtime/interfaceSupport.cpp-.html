<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/runtime/interfaceSupport.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2018, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/shared/collectedHeap.hpp&quot;
 27 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 28 #include &quot;logging/log.hpp&quot;
 29 #include &quot;memory/resourceArea.hpp&quot;
 30 #include &quot;runtime/atomic.hpp&quot;
 31 #include &quot;runtime/frame.inline.hpp&quot;
 32 #include &quot;runtime/handles.inline.hpp&quot;
 33 #include &quot;runtime/init.hpp&quot;
 34 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
 35 #include &quot;runtime/orderAccess.hpp&quot;
 36 #include &quot;runtime/os.inline.hpp&quot;
 37 #include &quot;runtime/thread.inline.hpp&quot;
 38 #include &quot;runtime/safepointVerifiers.hpp&quot;
 39 #include &quot;runtime/vframe.hpp&quot;
 40 #include &quot;runtime/vmThread.hpp&quot;
 41 #include &quot;utilities/preserveException.hpp&quot;
 42 
 43 // Implementation of InterfaceSupport
 44 
 45 #ifdef ASSERT
 46 VMEntryWrapper::VMEntryWrapper() {
 47   if (VerifyLastFrame) {
 48     InterfaceSupport::verify_last_frame();
 49   }
 50 }
 51 
 52 VMEntryWrapper::~VMEntryWrapper() {
 53   InterfaceSupport::check_gc_alot();
 54   if (WalkStackALot) {
 55     InterfaceSupport::walk_stack();
 56   }
 57 #ifdef COMPILER2
 58   // This option is not used by Compiler 1
 59   if (StressDerivedPointers) {
 60     InterfaceSupport::stress_derived_pointers();
 61   }
 62 #endif
 63   if (DeoptimizeALot || DeoptimizeRandom) {
 64     InterfaceSupport::deoptimizeAll();
 65   }
 66   if (ZombieALot) {
 67     InterfaceSupport::zombieAll();
 68   }
 69   // do verification AFTER potential deoptimization
 70   if (VerifyStack) {
 71     InterfaceSupport::verify_stack();
 72   }
 73 }
 74 
 75 long InterfaceSupport::_number_of_calls       = 0;
 76 long InterfaceSupport::_scavenge_alot_counter = 1;
 77 long InterfaceSupport::_fullgc_alot_counter   = 1;
 78 long InterfaceSupport::_fullgc_alot_invocation = 0;
 79 
 80 Histogram* RuntimeHistogram;
 81 
 82 RuntimeHistogramElement::RuntimeHistogramElement(const char* elementName) {
 83   static volatile int RuntimeHistogram_lock = 0;
 84   _name = elementName;
 85   uintx count = 0;
 86 
 87   while (Atomic::cmpxchg(1, &amp;RuntimeHistogram_lock, 0) != 0) {
 88     while (OrderAccess::load_acquire(&amp;RuntimeHistogram_lock) != 0) {
 89       count +=1;
 90       if ( (WarnOnStalledSpinLock &gt; 0)
 91         &amp;&amp; (count % WarnOnStalledSpinLock == 0)) {
 92         warning(&quot;RuntimeHistogram_lock seems to be stalled&quot;);
 93       }
 94     }
 95   }
 96 
 97   if (RuntimeHistogram == NULL) {
 98     RuntimeHistogram = new Histogram(&quot;VM Runtime Call Counts&quot;,200);
 99   }
100 
101   RuntimeHistogram-&gt;add_element(this);
102   Atomic::dec(&amp;RuntimeHistogram_lock);
103 }
104 
105 void InterfaceSupport::gc_alot() {
106   Thread *thread = Thread::current();
107   if (!thread-&gt;is_Java_thread()) return; // Avoid concurrent calls
108   // Check for new, not quite initialized thread. A thread in new mode cannot initiate a GC.
109   JavaThread *current_thread = (JavaThread *)thread;
110   if (current_thread-&gt;active_handles() == NULL) return;
111 
112   // Short-circuit any possible re-entrant gc-a-lot attempt
113   if (thread-&gt;skip_gcalot()) return;
114 
115   if (Threads::is_vm_complete()) {
116 
117     if (++_fullgc_alot_invocation &lt; FullGCALotStart) {
118       return;
119     }
120 
121     // Use this line if you want to block at a specific point,
122     // e.g. one number_of_calls/scavenge/gc before you got into problems
123     if (FullGCALot) _fullgc_alot_counter--;
124 
125     // Check if we should force a full gc
126     if (_fullgc_alot_counter == 0) {
127       // Release dummy so objects are forced to move
128       if (!Universe::release_fullgc_alot_dummy()) {
129         warning(&quot;FullGCALot: Unable to release more dummies at bottom of heap&quot;);
130       }
131       HandleMark hm(thread);
132       Universe::heap()-&gt;collect(GCCause::_full_gc_alot);
133       unsigned int invocations = Universe::heap()-&gt;total_full_collections();
134       // Compute new interval
135       if (FullGCALotInterval &gt; 1) {
136         _fullgc_alot_counter = 1+(long)((double)FullGCALotInterval*os::random()/(max_jint+1.0));
137         log_trace(gc)(&quot;Full gc no: %u\tInterval: %ld&quot;, invocations, _fullgc_alot_counter);
138       } else {
139         _fullgc_alot_counter = 1;
140       }
141       // Print progress message
142       if (invocations % 100 == 0) {
143         log_trace(gc)(&quot;Full gc no: %u&quot;, invocations);
144       }
145     } else {
146       if (ScavengeALot) _scavenge_alot_counter--;
147       // Check if we should force a scavenge
148       if (_scavenge_alot_counter == 0) {
149         HandleMark hm(thread);
150         Universe::heap()-&gt;collect(GCCause::_scavenge_alot);
151         unsigned int invocations = Universe::heap()-&gt;total_collections() - Universe::heap()-&gt;total_full_collections();
152         // Compute new interval
153         if (ScavengeALotInterval &gt; 1) {
154           _scavenge_alot_counter = 1+(long)((double)ScavengeALotInterval*os::random()/(max_jint+1.0));
155           log_trace(gc)(&quot;Scavenge no: %u\tInterval: %ld&quot;, invocations, _scavenge_alot_counter);
156         } else {
157           _scavenge_alot_counter = 1;
158         }
159         // Print progress message
160         if (invocations % 1000 == 0) {
161           log_trace(gc)(&quot;Scavenge no: %u&quot;, invocations);
162         }
163       }
164     }
165   }
166 }
167 
168 
169 vframe* vframe_array[50];
170 int walk_stack_counter = 0;
171 
172 void InterfaceSupport::walk_stack_from(vframe* start_vf) {
173   // walk
174   int i = 0;
175   for (vframe* f = start_vf; f; f = f-&gt;sender() ) {
176     if (i &lt; 50) vframe_array[i++] = f;
177   }
178 }
179 
180 
181 void InterfaceSupport::walk_stack() {
182   JavaThread* thread = JavaThread::current();
183   walk_stack_counter++;
184   if (!thread-&gt;has_last_Java_frame()) return;
185   ResourceMark rm(thread);
186   RegisterMap reg_map(thread);
187   walk_stack_from(thread-&gt;last_java_vframe(&amp;reg_map));
188 }
189 
190 // invocation counter for InterfaceSupport::deoptimizeAll/zombieAll functions
191 int deoptimizeAllCounter = 0;
192 int zombieAllCounter = 0;
193 
194 void InterfaceSupport::zombieAll() {
195   // This method is called by all threads when a thread make
196   // transition to VM state (for example, runtime calls).
197   // Divide number of calls by number of threads to avoid
198   // dependence of ZombieAll events frequency on number of threads.
199   int value = zombieAllCounter / Threads::number_of_threads();
200   if (is_init_completed() &amp;&amp; value &gt; ZombieALotInterval) {
201     zombieAllCounter = 0;
202     VM_ZombieAll op;
203     VMThread::execute(&amp;op);
204   }
205   zombieAllCounter++;
206 }
207 
208 void InterfaceSupport::deoptimizeAll() {
209   // This method is called by all threads when a thread make
210   // transition to VM state (for example, runtime calls).
211   // Divide number of calls by number of threads to avoid
212   // dependence of DeoptimizeAll events frequency on number of threads.
213   int value = deoptimizeAllCounter / Threads::number_of_threads();
214   if (is_init_completed()) {
215     if (DeoptimizeALot &amp;&amp; value &gt; DeoptimizeALotInterval) {
216       deoptimizeAllCounter = 0;
217       VM_DeoptimizeAll op;
218       VMThread::execute(&amp;op);
219     } else if (DeoptimizeRandom &amp;&amp; (value &amp; 0x1F) == (os::random() &amp; 0x1F)) {
220       VM_DeoptimizeAll op;
221       VMThread::execute(&amp;op);
222     }
223   }
224   deoptimizeAllCounter++;
225 }
226 
227 
228 void InterfaceSupport::stress_derived_pointers() {
229 #ifdef COMPILER2
230   JavaThread *thread = JavaThread::current();
231   if (!is_init_completed()) return;
232   ResourceMark rm(thread);
233   bool found = false;
234   for (StackFrameStream sfs(thread); !sfs.is_done() &amp;&amp; !found; sfs.next()) {
235     CodeBlob* cb = sfs.current()-&gt;cb();
236     if (cb != NULL &amp;&amp; cb-&gt;oop_maps() ) {
237       // Find oopmap for current method
238       const ImmutableOopMap* map = cb-&gt;oop_map_for_return_address(sfs.current()-&gt;pc());
239       assert(map != NULL, &quot;no oopmap found for pc&quot;);
240       found = map-&gt;has_derived_pointer();
241     }
242   }
243   if (found) {
244     // $$$ Not sure what to do here.
245     /*
246     Scavenge::invoke(0);
247     */
248   }
249 #endif
250 }
251 
252 
253 void InterfaceSupport::verify_stack() {
254   JavaThread* thread = JavaThread::current();
255   ResourceMark rm(thread);
256   // disabled because it throws warnings that oop maps should only be accessed
257   // in VM thread or during debugging
258 
259   if (!thread-&gt;has_pending_exception()) {
260     // verification does not work if there are pending exceptions
261     StackFrameStream sfs(thread);
262     CodeBlob* cb = sfs.current()-&gt;cb();
263       // In case of exceptions we might not have a runtime_stub on
264       // top of stack, hence, all callee-saved registers are not going
265       // to be setup correctly, hence, we cannot do stack verify
266     if (cb != NULL &amp;&amp; !(cb-&gt;is_runtime_stub() || cb-&gt;is_uncommon_trap_stub())) return;
267 
268     for (; !sfs.is_done(); sfs.next()) {
269       sfs.current()-&gt;verify(sfs.register_map());
270     }
271   }
272 }
273 
274 
275 void InterfaceSupport::verify_last_frame() {
276   JavaThread* thread = JavaThread::current();
277   ResourceMark rm(thread);
278   RegisterMap reg_map(thread);
279   frame fr = thread-&gt;last_frame();
280   fr.verify(&amp;reg_map);
281 }
282 
283 
284 #endif // ASSERT
285 
286 
287 void InterfaceSupport_init() {
288 #ifdef ASSERT
289   if (ScavengeALot || FullGCALot) {
290     srand(ScavengeALotInterval * FullGCALotInterval);
291   }
292 #endif
293 }
294 
295 #ifdef ASSERT
296 // JRT_LEAF rules:
297 // A JRT_LEAF method may not interfere with safepointing by
298 //   1) acquiring or blocking on a Mutex or JavaLock - checked
299 //   2) allocating heap memory - checked
300 //   3) executing a VM operation - checked
301 //   4) executing a system call (including malloc) that could block or grab a lock
302 //   5) invoking GC
303 //   6) reaching a safepoint
304 //   7) running too long
305 // Nor may any method it calls.
306 JRTLeafVerifier::JRTLeafVerifier()
307   : NoSafepointVerifier(true, JRTLeafVerifier::should_verify_GC())
308 {
309 }
310 
311 JRTLeafVerifier::~JRTLeafVerifier()
312 {
313 }
314 
315 bool JRTLeafVerifier::should_verify_GC() {
316   switch (JavaThread::current()-&gt;thread_state()) {
317   case _thread_in_Java:
318     // is in a leaf routine, there must be no safepoint.
319     return true;
320   case _thread_in_native:
321     // A native thread is not subject to safepoints.
322     // Even while it is in a leaf routine, GC is ok
323     return false;
324   default:
325     // Leaf routines cannot be called from other contexts.
326     ShouldNotReachHere();
327     return false;
328   }
329 }
330 #endif // ASSERT
    </pre>
  </body>
</html>