diff a/src/hotspot/share/runtime/biasedLocking.hpp b/src/hotspot/share/runtime/biasedLocking.hpp
--- a/src/hotspot/share/runtime/biasedLocking.hpp
+++ b/src/hotspot/share/runtime/biasedLocking.hpp
@@ -74,21 +74,21 @@
 // to occur quickly in the situations where the bias has been revoked.
 //
 // Revocation of the lock's bias is fairly straightforward. We want to
 // restore the object's header and stack-based BasicObjectLocks and
 // BasicLocks to the state they would have been in had the object been
-// locked by HotSpot's usual fast locking scheme. To do this, we bring
-// the system to a safepoint and walk the stack of the thread toward
-// which the lock is biased. We find all of the lock records on the
-// stack corresponding to this object, in particular the first /
-// "highest" record. We fill in the highest lock record with the
-// object's displaced header (which is a well-known value given that
-// we don't maintain an identity hash nor age bits for the object
-// while it's in the biased state) and all other lock records with 0,
-// the value for recursive locks. When the safepoint is released, the
-// formerly-biased thread and all other threads revert back to
-// HotSpot's CAS-based locking.
+// locked by HotSpot's usual fast locking scheme. To do this, we execute
+// a handshake with the JavaThread that biased the lock. Inside the
+// handshake we walk the biaser stack searching for all of the lock
+// records corresponding to this object, in particular the first / "highest"
+// record. We fill in the highest lock record with the object's displaced
+// header (which is a well-known value given that we don't maintain an
+// identity hash nor age bits for the object while it's in the biased
+// state) and all other lock records with 0, the value for recursive locks.
+// Alternatively, we can revoke the bias of an object inside a safepoint
+// if we are already in one and we detect that we need to perform a
+// revocation.
 //
 // This scheme can not handle transfers of biases of single objects
 // from thread to thread efficiently, but it can handle bulk transfers
 // of such biases, which is a usage pattern showing up in some
 // applications and benchmarks. We implement "bulk rebias" and "bulk
@@ -100,11 +100,11 @@
 // the object header and attempts to rebias the object with a CAS if
 // found, avoiding safepoints or bulk heap sweeps (the latter which
 // was used in a prior version of this algorithm and did not scale
 // well). If too many bias revocations persist, biasing is completely
 // disabled for the data type by resetting the prototype header to the
-// unbiased markOop. The fast-path locking code checks to see whether
+// unbiased markWord. The fast-path locking code checks to see whether
 // the instance's bias pattern differs from the prototype header's and
 // causes the bias to be revoked without reaching a safepoint or,
 // again, a bulk heap sweep.
 
 // Biased locking counters
@@ -113,76 +113,93 @@
   int _total_entry_count;
   int _biased_lock_entry_count;
   int _anonymously_biased_lock_entry_count;
   int _rebiased_lock_entry_count;
   int _revoked_lock_entry_count;
+  int _handshakes_count;
   int _fast_path_entry_count;
   int _slow_path_entry_count;
 
  public:
   BiasedLockingCounters() :
     _total_entry_count(0),
     _biased_lock_entry_count(0),
     _anonymously_biased_lock_entry_count(0),
     _rebiased_lock_entry_count(0),
     _revoked_lock_entry_count(0),
+    _handshakes_count(0),
     _fast_path_entry_count(0),
     _slow_path_entry_count(0) {}
 
-  int slow_path_entry_count(); // Compute this field if necessary
+  int slow_path_entry_count() const; // Compute this field if necessary
 
   int* total_entry_count_addr()                   { return &_total_entry_count; }
   int* biased_lock_entry_count_addr()             { return &_biased_lock_entry_count; }
   int* anonymously_biased_lock_entry_count_addr() { return &_anonymously_biased_lock_entry_count; }
   int* rebiased_lock_entry_count_addr()           { return &_rebiased_lock_entry_count; }
   int* revoked_lock_entry_count_addr()            { return &_revoked_lock_entry_count; }
+  int* handshakes_count_addr()                    { return &_handshakes_count; }
   int* fast_path_entry_count_addr()               { return &_fast_path_entry_count; }
   int* slow_path_entry_count_addr()               { return &_slow_path_entry_count; }
 
   bool nonzero() { return _total_entry_count > 0; }
 
-  void print_on(outputStream* st);
-  void print() { print_on(tty); }
+  void print_on(outputStream* st) const;
+  void print() const;
 };
 
 
 class BiasedLocking : AllStatic {
+friend class VM_BulkRevokeBias;
+friend class RevokeOneBias;
+
 private:
   static BiasedLockingCounters _counters;
 
 public:
   static int* total_entry_count_addr();
   static int* biased_lock_entry_count_addr();
   static int* anonymously_biased_lock_entry_count_addr();
   static int* rebiased_lock_entry_count_addr();
   static int* revoked_lock_entry_count_addr();
+  static int* handshakes_count_addr();
   static int* fast_path_entry_count_addr();
   static int* slow_path_entry_count_addr();
 
   enum Condition {
     NOT_BIASED = 1,
     BIAS_REVOKED = 2,
-    BIAS_REVOKED_AND_REBIASED = 3
+    NOT_REVOKED = 3
   };
 
+private:
+  static void single_revoke_at_safepoint(oop obj, bool is_bulk, JavaThread* requester, JavaThread** biaser);
+  static void bulk_revoke_at_safepoint(oop o, bool bulk_rebias, JavaThread* requester);
+  static Condition single_revoke_with_handshake(Handle obj, JavaThread *requester, JavaThread *biaser);
+  static void walk_stack_and_revoke(oop obj, JavaThread* biased_locker);
+
+public:
   // This initialization routine should only be called once and
   // schedules a PeriodicTask to turn on biased locking a few seconds
   // into the VM run to avoid startup time regressions
   static void init();
 
   // This provides a global switch for leaving biased locking disabled
   // for the first part of a run and enabling it later
   static bool enabled();
 
   // This should be called by JavaThreads to revoke the bias of an object
-  static Condition revoke_and_rebias(Handle obj, bool attempt_rebias, TRAPS);
+  static void revoke(Handle obj, TRAPS);
+
+  // This must only be called by a JavaThread to revoke the bias of an owned object.
+  static void revoke_own_lock(Handle obj, TRAPS);
 
-  // These do not allow rebiasing; they are used by deoptimization to
-  // ensure that monitors on the stack can be migrated
-  static void revoke(GrowableArray<Handle>* objs);
   static void revoke_at_safepoint(Handle obj);
-  static void revoke_at_safepoint(GrowableArray<Handle>* objs);
+
+  // These are used by deoptimization to ensure that monitors on the stack
+  // can be migrated
+  static void revoke(GrowableArray<Handle>* objs, JavaThread *biaser);
 
   static void print_counters() { _counters.print(); }
   static BiasedLockingCounters* counters() { return &_counters; }
 
   // These routines are GC-related and should not be called by end
