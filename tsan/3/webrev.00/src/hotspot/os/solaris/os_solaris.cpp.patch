diff a/src/hotspot/os/solaris/os_solaris.cpp b/src/hotspot/os/solaris/os_solaris.cpp
--- a/src/hotspot/os/solaris/os_solaris.cpp
+++ b/src/hotspot/os/solaris/os_solaris.cpp
@@ -31,12 +31,14 @@
 #include "code/vtableStubs.hpp"
 #include "compiler/compileBroker.hpp"
 #include "compiler/disassembler.hpp"
 #include "interpreter/interpreter.hpp"
 #include "logging/log.hpp"
+#include "logging/logStream.hpp"
 #include "memory/allocation.inline.hpp"
 #include "memory/filemap.hpp"
+#include "memory/universe.hpp"
 #include "oops/oop.inline.hpp"
 #include "os_share_solaris.hpp"
 #include "os_solaris.inline.hpp"
 #include "prims/jniFastGetField.hpp"
 #include "prims/jvm_misc.hpp"
@@ -261,12 +263,10 @@
   if (enabler) {
     enabler(-1, -1);
   }
 }
 
-static int _processors_online = 0;
-
 jint os::Solaris::_os_thread_limit = 0;
 volatile jint os::Solaris::_os_thread_count = 0;
 
 julong os::available_memory() {
   return Solaris::available_memory();
@@ -287,11 +287,10 @@
 static volatile hrtime_t max_hrtime = 0;
 
 
 void os::Solaris::initialize_system_info() {
   set_processor_count(sysconf(_SC_NPROCESSORS_CONF));
-  _processors_online = sysconf(_SC_NPROCESSORS_ONLN);
   _physical_memory = (julong)sysconf(_SC_PHYS_PAGES) *
                                      (julong)sysconf(_SC_PAGESIZE);
 }
 
 uint os::processor_id() {
@@ -316,150 +315,17 @@
   if (pset_bind(PS_QUERY, P_PID, pid, &pset) == 0) {
     uint_t pset_cpus;
     // Query the number of cpus available to us.
     if (pset_info(pset, NULL, &pset_cpus, NULL) == 0) {
       assert(pset_cpus > 0 && pset_cpus <= online_cpus, "sanity check");
-      _processors_online = pset_cpus;
       return pset_cpus;
     }
   }
   // Otherwise return number of online cpus
   return online_cpus;
 }
 
-static bool find_processors_in_pset(psetid_t        pset,
-                                    processorid_t** id_array,
-                                    uint_t*         id_length) {
-  bool result = false;
-  // Find the number of processors in the processor set.
-  if (pset_info(pset, NULL, id_length, NULL) == 0) {
-    // Make up an array to hold their ids.
-    *id_array = NEW_C_HEAP_ARRAY(processorid_t, *id_length, mtInternal);
-    // Fill in the array with their processor ids.
-    if (pset_info(pset, NULL, id_length, *id_array) == 0) {
-      result = true;
-    }
-  }
-  return result;
-}
-
-// Callers of find_processors_online() must tolerate imprecise results --
-// the system configuration can change asynchronously because of DR
-// or explicit psradm operations.
-//
-// We also need to take care that the loop (below) terminates as the
-// number of processors online can change between the _SC_NPROCESSORS_ONLN
-// request and the loop that builds the list of processor ids.   Unfortunately
-// there's no reliable way to determine the maximum valid processor id,
-// so we use a manifest constant, MAX_PROCESSOR_ID, instead.  See p_online
-// man pages, which claim the processor id set is "sparse, but
-// not too sparse".  MAX_PROCESSOR_ID is used to ensure that we eventually
-// exit the loop.
-//
-// In the future we'll be able to use sysconf(_SC_CPUID_MAX), but that's
-// not available on S8.0.
-
-static bool find_processors_online(processorid_t** id_array,
-                                   uint*           id_length) {
-  const processorid_t MAX_PROCESSOR_ID = 100000;
-  // Find the number of processors online.
-  *id_length = sysconf(_SC_NPROCESSORS_ONLN);
-  // Make up an array to hold their ids.
-  *id_array = NEW_C_HEAP_ARRAY(processorid_t, *id_length, mtInternal);
-  // Processors need not be numbered consecutively.
-  long found = 0;
-  processorid_t next = 0;
-  while (found < *id_length && next < MAX_PROCESSOR_ID) {
-    processor_info_t info;
-    if (processor_info(next, &info) == 0) {
-      // NB, PI_NOINTR processors are effectively online ...
-      if (info.pi_state == P_ONLINE || info.pi_state == P_NOINTR) {
-        (*id_array)[found] = next;
-        found += 1;
-      }
-    }
-    next += 1;
-  }
-  if (found < *id_length) {
-    // The loop above didn't identify the expected number of processors.
-    // We could always retry the operation, calling sysconf(_SC_NPROCESSORS_ONLN)
-    // and re-running the loop, above, but there's no guarantee of progress
-    // if the system configuration is in flux.  Instead, we just return what
-    // we've got.  Note that in the worst case find_processors_online() could
-    // return an empty set.  (As a fall-back in the case of the empty set we
-    // could just return the ID of the current processor).
-    *id_length = found;
-  }
-
-  return true;
-}
-
-static bool assign_distribution(processorid_t* id_array,
-                                uint           id_length,
-                                uint*          distribution,
-                                uint           distribution_length) {
-  // We assume we can assign processorid_t's to uint's.
-  assert(sizeof(processorid_t) == sizeof(uint),
-         "can't convert processorid_t to uint");
-  // Quick check to see if we won't succeed.
-  if (id_length < distribution_length) {
-    return false;
-  }
-  // Assign processor ids to the distribution.
-  // Try to shuffle processors to distribute work across boards,
-  // assuming 4 processors per board.
-  const uint processors_per_board = ProcessDistributionStride;
-  // Find the maximum processor id.
-  processorid_t max_id = 0;
-  for (uint m = 0; m < id_length; m += 1) {
-    max_id = MAX2(max_id, id_array[m]);
-  }
-  // The next id, to limit loops.
-  const processorid_t limit_id = max_id + 1;
-  // Make up markers for available processors.
-  bool* available_id = NEW_C_HEAP_ARRAY(bool, limit_id, mtInternal);
-  for (uint c = 0; c < limit_id; c += 1) {
-    available_id[c] = false;
-  }
-  for (uint a = 0; a < id_length; a += 1) {
-    available_id[id_array[a]] = true;
-  }
-  // Step by "boards", then by "slot", copying to "assigned".
-  // NEEDS_CLEANUP: The assignment of processors should be stateful,
-  //                remembering which processors have been assigned by
-  //                previous calls, etc., so as to distribute several
-  //                independent calls of this method.  What we'd like is
-  //                It would be nice to have an API that let us ask
-  //                how many processes are bound to a processor,
-  //                but we don't have that, either.
-  //                In the short term, "board" is static so that
-  //                subsequent distributions don't all start at board 0.
-  static uint board = 0;
-  uint assigned = 0;
-  // Until we've found enough processors ....
-  while (assigned < distribution_length) {
-    // ... find the next available processor in the board.
-    for (uint slot = 0; slot < processors_per_board; slot += 1) {
-      uint try_id = board * processors_per_board + slot;
-      if ((try_id < limit_id) && (available_id[try_id] == true)) {
-        distribution[assigned] = try_id;
-        available_id[try_id] = false;
-        assigned += 1;
-        break;
-      }
-    }
-    board += 1;
-    if (board * processors_per_board + 0 >= limit_id) {
-      board = 0;
-    }
-  }
-  if (available_id != NULL) {
-    FREE_C_HEAP_ARRAY(bool, available_id);
-  }
-  return true;
-}
-
 void os::set_native_thread_name(const char *name) {
   if (Solaris::_pthread_setname_np != NULL) {
     // Only the first 31 bytes of 'name' are processed by pthread_setname_np
     // but we explicitly copy into a size-limited buffer to avoid any
     // possible overflow.
@@ -468,37 +334,10 @@
     buf[sizeof(buf) - 1] = '\0';
     Solaris::_pthread_setname_np(pthread_self(), buf);
   }
 }
 
-bool os::distribute_processes(uint length, uint* distribution) {
-  bool result = false;
-  // Find the processor id's of all the available CPUs.
-  processorid_t* id_array  = NULL;
-  uint           id_length = 0;
-  // There are some races between querying information and using it,
-  // since processor sets can change dynamically.
-  psetid_t pset = PS_NONE;
-  // Are we running in a processor set?
-  if ((pset_bind(PS_QUERY, P_PID, P_MYID, &pset) == 0) && pset != PS_NONE) {
-    result = find_processors_in_pset(pset, &id_array, &id_length);
-  } else {
-    result = find_processors_online(&id_array, &id_length);
-  }
-  if (result == true) {
-    if (id_length >= length) {
-      result = assign_distribution(id_array, id_length, distribution, length);
-    } else {
-      result = false;
-    }
-  }
-  if (id_array != NULL) {
-    FREE_C_HEAP_ARRAY(processorid_t, id_array);
-  }
-  return result;
-}
-
 bool os::bind_to_processor(uint processor_id) {
   // We assume that a processorid_t can be stored in a uint.
   assert(sizeof(uint) == sizeof(processorid_t),
          "can't convert uint to processorid_t");
   int bind_result =
@@ -558,11 +397,11 @@
   // by the nulls included by the sizeof operator.
   const size_t bufsize =
     MAX3((size_t)MAXPATHLEN,  // For dll_dir & friends.
          sizeof(SYS_EXT_DIR) + sizeof("/lib/"), // invariant ld_library_path
          (size_t)MAXPATHLEN + sizeof(EXTENSIONS_DIR) + sizeof(SYS_EXT_DIR) + sizeof(EXTENSIONS_DIR)); // extensions dir
-  char *buf = (char *)NEW_C_HEAP_ARRAY(char, bufsize, mtInternal);
+  char *buf = NEW_C_HEAP_ARRAY(char, bufsize, mtInternal);
 
   // sysclasspath, java_home, dll_dir
   {
     char *pslash;
     os::jvm_path(buf, bufsize);
@@ -644,11 +483,11 @@
 
     // Struct size is more than sufficient for the path components obtained
     // through the dlinfo() call, so only add additional space for the path
     // components explicitly added here.
     size_t library_path_size = info->dls_size + strlen(common_path);
-    library_path = (char *)NEW_C_HEAP_ARRAY(char, library_path_size, mtInternal);
+    library_path = NEW_C_HEAP_ARRAY(char, library_path_size, mtInternal);
     library_path[0] = '\0';
 
     // Construct the desired Java library path from the linker's library
     // search path.
     //
@@ -990,10 +829,15 @@
     log_info(os, thread)("Thread started (tid: " UINTX_FORMAT ", attributes: %s). ",
       (uintx) tid, describe_thr_create_attributes(buf, sizeof(buf), stack_size, flags));
   } else {
     log_warning(os, thread)("Failed to start thread - thr_create failed (%s) for attributes: %s.",
       os::errno_name(status), describe_thr_create_attributes(buf, sizeof(buf), stack_size, flags));
+    // Log some OS information which might explain why creating the thread failed.
+    log_info(os, thread)("Number of threads approx. running in the VM: %d", Threads::number_of_threads());
+    LogStream st(Log(os, thread)::info());
+    os::Posix::print_rlimit_info(&st);
+    os::print_memory_info(&st);
   }
 
   if (status != 0) {
     thread->set_osthread(NULL);
     // Need to clean up stuff we've allocated so far
@@ -1178,11 +1022,11 @@
   const hrtime_t now = gethrtime();
   const hrtime_t prev = max_hrtime;
   if (now <= prev) {
     return prev;   // same or retrograde time;
   }
-  const hrtime_t obsv = Atomic::cmpxchg(now, &max_hrtime, prev);
+  const hrtime_t obsv = Atomic::cmpxchg(&max_hrtime, prev, now);
   assert(obsv >= prev, "invariant");   // Monotonicity
   // If the CAS succeeded then we're done and return "now".
   // If the CAS failed and the observed value "obsv" is >= now then
   // we should return "obsv".  If the CAS failed and now > obsv > prv then
   // some other thread raced this thread and installed a new value, in which case
@@ -1232,12 +1076,10 @@
     return true;
   }
 }
 
 bool os::supports_vtime() { return true; }
-bool os::enable_vtime() { return false; }
-bool os::vtime_enabled() { return false; }
 
 double os::elapsedVTime() {
   return (double)gethrvtime() / (double)hrtime_hz;
 }
 
@@ -1325,12 +1167,19 @@
 
   ::exit(1);
 }
 
 // Die immediately, no exit hook, no abort hook, no cleanup.
+// Dump a core file, if possible, for debugging.
 void os::die() {
-  ::abort(); // dump core (for debugging)
+  if (TestUnresponsiveErrorHandler && !CreateCoredumpOnCrash) {
+    // For TimeoutInErrorHandlingTest.java, we just kill the VM
+    // and don't take the time to generate a core file.
+    os::signal_raise(SIGKILL);
+  } else {
+    ::abort();
+  }
 }
 
 // DLL functions
 
 const char* os::dll_file_extension() { return ".so"; }
@@ -1504,27 +1353,45 @@
   if (get_loaded_modules_info(_print_dll_info_cb, (void *)st)) {
     st->print_cr("Error: Cannot print dynamic libraries.");
   }
 }
 
+static void change_endianness(Elf32_Half& val) {
+  unsigned char *ptr = (unsigned char *)&val;
+  unsigned char swp = ptr[0];
+  ptr[0] = ptr[1];
+  ptr[1] = swp;
+}
+
 // Loads .dll/.so and
 // in case of error it checks if .dll/.so was built for the
 // same architecture as Hotspot is running on
 
 void * os::dll_load(const char *filename, char *ebuf, int ebuflen) {
+  log_info(os)("attempting shared library load of %s", filename);
+
   void * result= ::dlopen(filename, RTLD_LAZY);
   if (result != NULL) {
     // Successful loading
+    Events::log(NULL, "Loaded shared library %s", filename);
+    log_info(os)("shared library load of %s was successful", filename);
     return result;
   }
 
   Elf32_Ehdr elf_head;
+  const char* error_report = ::dlerror();
+  if (error_report == NULL) {
+    error_report = "dlerror returned no error description";
+  }
+  if (ebuf != NULL && ebuflen > 0) {
+    ::strncpy(ebuf, error_report, ebuflen-1);
+    ebuf[ebuflen-1]='\0';
+  }
+
+  Events::log(NULL, "Loading shared library %s failed, %s", filename, error_report);
+  log_info(os)("shared library load of %s failed, %s", filename, error_report);
 
-  // Read system error message into ebuf
-  // It may or may not be overwritten below
-  ::strncpy(ebuf, ::dlerror(), ebuflen-1);
-  ebuf[ebuflen-1]='\0';
   int diag_msg_max_length=ebuflen-strlen(ebuf);
   char* diag_msg_buf=ebuf+strlen(ebuf);
 
   if (diag_msg_max_length==0) {
     // No more space in ebuf for additional diagnostics message
@@ -1547,29 +1414,44 @@
   if (failed_to_read_elf_head) {
     // file i/o error - report dlerror() msg
     return NULL;
   }
 
+  if (elf_head.e_ident[EI_DATA] != LITTLE_ENDIAN_ONLY(ELFDATA2LSB) BIG_ENDIAN_ONLY(ELFDATA2MSB)) {
+    // handle invalid/out of range endianness values
+    if (elf_head.e_ident[EI_DATA] == 0 || elf_head.e_ident[EI_DATA] > 2) {
+      return NULL;
+    }
+    change_endianness(elf_head.e_machine);
+  }
+
   typedef struct {
     Elf32_Half    code;         // Actual value as defined in elf.h
     Elf32_Half    compat_class; // Compatibility of archs at VM's sense
     unsigned char elf_class;    // 32 or 64 bit
     unsigned char endianess;    // MSB or LSB
     char*         name;         // String representation
   } arch_t;
 
+#ifndef EM_AARCH64
+  #define EM_AARCH64    183               /* ARM AARCH64 */
+#endif
+
   static const arch_t arch_array[]={
     {EM_386,         EM_386,     ELFCLASS32, ELFDATA2LSB, (char*)"IA 32"},
     {EM_486,         EM_386,     ELFCLASS32, ELFDATA2LSB, (char*)"IA 32"},
     {EM_IA_64,       EM_IA_64,   ELFCLASS64, ELFDATA2LSB, (char*)"IA 64"},
     {EM_X86_64,      EM_X86_64,  ELFCLASS64, ELFDATA2LSB, (char*)"AMD 64"},
     {EM_SPARC,       EM_SPARC,   ELFCLASS32, ELFDATA2MSB, (char*)"Sparc 32"},
     {EM_SPARC32PLUS, EM_SPARC,   ELFCLASS32, ELFDATA2MSB, (char*)"Sparc 32"},
     {EM_SPARCV9,     EM_SPARCV9, ELFCLASS64, ELFDATA2MSB, (char*)"Sparc v9 64"},
     {EM_PPC,         EM_PPC,     ELFCLASS32, ELFDATA2MSB, (char*)"Power PC 32"},
     {EM_PPC64,       EM_PPC64,   ELFCLASS64, ELFDATA2MSB, (char*)"Power PC 64"},
-    {EM_ARM,         EM_ARM,     ELFCLASS32, ELFDATA2LSB, (char*)"ARM 32"}
+    {EM_ARM,         EM_ARM,     ELFCLASS32, ELFDATA2LSB, (char*)"ARM"},
+    // we only support 64 bit z architecture
+    {EM_S390,        EM_S390,    ELFCLASS64, ELFDATA2MSB, (char*)"IBM System/390"},
+    {EM_AARCH64,     EM_AARCH64, ELFCLASS64, ELFDATA2LSB, (char*)"AARCH64"}
   };
 
 #if  (defined IA32)
   static  Elf32_Half running_arch_code=EM_386;
 #elif   (defined AMD64)
@@ -1589,11 +1471,11 @@
 #else
   #error Method os::dll_load requires that one of following is defined:\
        IA32, AMD64, IA64, __sparc, __powerpc__, ARM, ARM
 #endif
 
-  // Identify compatability class for VM's architecture and library's architecture
+  // Identify compatibility class for VM's architecture and library's architecture
   // Obtain string descriptions for architectures
 
   arch_t lib_arch={elf_head.e_machine,0,elf_head.e_ident[EI_CLASS], elf_head.e_ident[EI_DATA], NULL};
   int running_arch_index=-1;
 
@@ -1613,31 +1495,39 @@
     // Even though running architecture detection failed
     // we may still continue with reporting dlerror() message
     return NULL;
   }
 
+  if (lib_arch.compat_class != arch_array[running_arch_index].compat_class) {
+    if (lib_arch.name != NULL) {
+      ::snprintf(diag_msg_buf, diag_msg_max_length-1,
+                 " (Possible cause: can't load %s .so on a %s platform)",
+                 lib_arch.name, arch_array[running_arch_index].name);
+    } else {
+      ::snprintf(diag_msg_buf, diag_msg_max_length-1,
+                 " (Possible cause: can't load this .so (machine code=0x%x) on a %s platform)",
+                 lib_arch.code, arch_array[running_arch_index].name);
+    }
+    return NULL;
+  }
+
   if (lib_arch.endianess != arch_array[running_arch_index].endianess) {
     ::snprintf(diag_msg_buf, diag_msg_max_length-1," (Possible cause: endianness mismatch)");
     return NULL;
   }
 
-  if (lib_arch.elf_class != arch_array[running_arch_index].elf_class) {
-    ::snprintf(diag_msg_buf, diag_msg_max_length-1," (Possible cause: architecture word width mismatch)");
+  // ELF file class/capacity : 0 - invalid, 1 - 32bit, 2 - 64bit
+  if (lib_arch.elf_class > 2 || lib_arch.elf_class < 1) {
+    ::snprintf(diag_msg_buf, diag_msg_max_length-1, " (Possible cause: invalid ELF file class)");
     return NULL;
   }
 
-  if (lib_arch.compat_class != arch_array[running_arch_index].compat_class) {
-    if (lib_arch.name!=NULL) {
-      ::snprintf(diag_msg_buf, diag_msg_max_length-1,
-                 " (Possible cause: can't load %s-bit .so on a %s-bit platform)",
-                 lib_arch.name, arch_array[running_arch_index].name);
-    } else {
-      ::snprintf(diag_msg_buf, diag_msg_max_length-1,
-                 " (Possible cause: can't load this .so (machine code=0x%x) on a %s-bit platform)",
-                 lib_arch.code,
-                 arch_array[running_arch_index].name);
-    }
+  if (lib_arch.elf_class != arch_array[running_arch_index].elf_class) {
+    ::snprintf(diag_msg_buf, diag_msg_max_length-1,
+               " (Possible cause: architecture word width mismatch, can't load %d-bit .so on a %d-bit platform)",
+               (int) lib_arch.elf_class * 32, arch_array[running_arch_index].elf_class * 32);
+    return NULL;
   }
 
   return NULL;
 }
 
@@ -1692,10 +1582,12 @@
 
   os::Solaris::print_distro_info(st);
 
   os::Posix::print_uname_info(st);
 
+  os::Posix::print_uptime_info(st);
+
   os::Solaris::print_libversion_info(st);
 
   os::Posix::print_rlimit_info(st);
 
   os::Posix::print_load_average(st);
@@ -2018,10 +1910,11 @@
 
 void* os::signal(int signal_number, void* handler) {
   struct sigaction sigAct, oldSigAct;
   sigfillset(&(sigAct.sa_mask));
   sigAct.sa_flags = SA_RESTART & ~SA_RESETHAND;
+  sigAct.sa_flags |= SA_SIGINFO;
   sigAct.sa_handler = CAST_TO_FN_PTR(sa_handler_t, handler);
 
   if (sigaction(signal_number, &sigAct, &oldSigAct)) {
     // -1 means registration failed
     return (void *)-1;
@@ -2091,11 +1984,11 @@
 static int check_pending_signals() {
   int ret;
   while (true) {
     for (int i = 0; i < Sigexit + 1; i++) {
       jint n = pending_signals[i];
-      if (n > 0 && n == Atomic::cmpxchg(n - 1, &pending_signals[i], n)) {
+      if (n > 0 && n == Atomic::cmpxchg(&pending_signals[i], n, n - 1)) {
         return i;
       }
     }
     JavaThread *thread = JavaThread::current();
     ThreadBlockInVM tbivm(thread);
@@ -2179,11 +2072,11 @@
   int prot = exec ? PROT_READ|PROT_WRITE|PROT_EXEC : PROT_READ|PROT_WRITE;
   size_t size = bytes;
   char *res = Solaris::mmap_chunk(addr, size, MAP_PRIVATE|MAP_FIXED, prot);
   if (res != NULL) {
     if (UseNUMAInterleaving) {
-      numa_make_global(addr, bytes);
+        numa_make_global(addr, bytes);
     }
     return 0;
   }
 
   int err = errno;  // save errno from mmap() call in mmap_chunk()
@@ -2374,10 +2267,14 @@
     return 0;
   }
   return ids[os::random() % r];
 }
 
+int os::numa_get_group_id_for_address(const void* address) {
+  return 0;
+}
+
 // Request information about the page.
 bool os::get_page_info(char *start, page_info* info) {
   const uint_t info_types[] = { MEMINFO_VLGRP, MEMINFO_VPAGESIZE };
   uint64_t addr = (uintptr_t)start;
   uint64_t outdata[2];
@@ -2529,138 +2426,41 @@
 
 // Reserve memory at an arbitrary address, only if that area is
 // available (and not reserved for something else).
 
 char* os::pd_attempt_reserve_memory_at(size_t bytes, char* requested_addr) {
-  const int max_tries = 10;
-  char* base[max_tries];
-  size_t size[max_tries];
-
-  // Solaris adds a gap between mmap'ed regions.  The size of the gap
-  // is dependent on the requested size and the MMU.  Our initial gap
-  // value here is just a guess and will be corrected later.
-  bool had_top_overlap = false;
-  bool have_adjusted_gap = false;
-  size_t gap = 0x400000;
-
   // Assert only that the size is a multiple of the page size, since
   // that's all that mmap requires, and since that's all we really know
   // about at this low abstraction level.  If we need higher alignment,
   // we can either pass an alignment to this method or verify alignment
   // in one of the methods further up the call chain.  See bug 5044738.
   assert(bytes % os::vm_page_size() == 0, "reserving unexpected size block");
 
   // Since snv_84, Solaris attempts to honor the address hint - see 5003415.
-  // Give it a try, if the kernel honors the hint we can return immediately.
   char* addr = Solaris::anon_mmap(requested_addr, bytes, 0, false);
 
   volatile int err = errno;
   if (addr == requested_addr) {
     return addr;
-  } else if (addr != NULL) {
-    pd_unmap_memory(addr, bytes);
-  }
-
-  if (log_is_enabled(Warning, os)) {
-    char buf[256];
-    buf[0] = '\0';
-    if (addr == NULL) {
-      jio_snprintf(buf, sizeof(buf), ": %s", os::strerror(err));
-    }
-    log_info(os)("attempt_reserve_memory_at: couldn't reserve " SIZE_FORMAT " bytes at "
-            PTR_FORMAT ": reserve_memory_helper returned " PTR_FORMAT
-            "%s", bytes, requested_addr, addr, buf);
-  }
-
-  // Address hint method didn't work.  Fall back to the old method.
-  // In theory, once SNV becomes our oldest supported platform, this
-  // code will no longer be needed.
-  //
-  // Repeatedly allocate blocks until the block is allocated at the
-  // right spot. Give up after max_tries.
-  int i;
-  for (i = 0; i < max_tries; ++i) {
-    base[i] = reserve_memory(bytes);
-
-    if (base[i] != NULL) {
-      // Is this the block we wanted?
-      if (base[i] == requested_addr) {
-        size[i] = bytes;
-        break;
-      }
-
-      // check that the gap value is right
-      if (had_top_overlap && !have_adjusted_gap) {
-        size_t actual_gap = base[i-1] - base[i] - bytes;
-        if (gap != actual_gap) {
-          // adjust the gap value and retry the last 2 allocations
-          assert(i > 0, "gap adjustment code problem");
-          have_adjusted_gap = true;  // adjust the gap only once, just in case
-          gap = actual_gap;
-          log_info(os)("attempt_reserve_memory_at: adjusted gap to 0x%lx", gap);
-          unmap_memory(base[i], bytes);
-          unmap_memory(base[i-1], size[i-1]);
-          i-=2;
-          continue;
-        }
-      }
-
-      // Does this overlap the block we wanted? Give back the overlapped
-      // parts and try again.
-      //
-      // There is still a bug in this code: if top_overlap == bytes,
-      // the overlap is offset from requested region by the value of gap.
-      // In this case giving back the overlapped part will not work,
-      // because we'll give back the entire block at base[i] and
-      // therefore the subsequent allocation will not generate a new gap.
-      // This could be fixed with a new algorithm that used larger
-      // or variable size chunks to find the requested region -
-      // but such a change would introduce additional complications.
-      // It's rare enough that the planets align for this bug,
-      // so we'll just wait for a fix for 6204603/5003415 which
-      // will provide a mmap flag to allow us to avoid this business.
-
-      size_t top_overlap = requested_addr + (bytes + gap) - base[i];
-      if (top_overlap >= 0 && top_overlap < bytes) {
-        had_top_overlap = true;
-        unmap_memory(base[i], top_overlap);
-        base[i] += top_overlap;
-        size[i] = bytes - top_overlap;
-      } else {
-        size_t bottom_overlap = base[i] + bytes - requested_addr;
-        if (bottom_overlap >= 0 && bottom_overlap < bytes) {
-          if (bottom_overlap == 0) {
-            log_info(os)("attempt_reserve_memory_at: possible alignment bug");
-          }
-          unmap_memory(requested_addr, bottom_overlap);
-          size[i] = bytes - bottom_overlap;
-        } else {
-          size[i] = bytes;
-        }
-      }
-    }
   }
 
-  // Give back the unused reserved pieces.
-
-  for (int j = 0; j < i; ++j) {
-    if (base[j] != NULL) {
-      unmap_memory(base[j], size[j]);
-    }
+  if (addr != NULL) {
+    pd_unmap_memory(addr, bytes);
   }
 
-  return (i < max_tries) ? requested_addr : NULL;
+  return NULL;
 }
 
 bool os::pd_release_memory(char* addr, size_t bytes) {
   size_t size = bytes;
   return munmap(addr, size) == 0;
 }
 
 static bool solaris_mprotect(char* addr, size_t bytes, int prot) {
   assert(addr == (char*)align_down((uintptr_t)addr, os::vm_page_size()),
          "addr must be page aligned");
+  Events::log(NULL, "Protecting memory [" INTPTR_FORMAT "," INTPTR_FORMAT "] with protection modes %x", p2i(addr), p2i(addr+bytes), prot);
   int retVal = mprotect(addr, bytes, prot);
   return retVal == 0;
 }
 
 // Protect memory (Used to pass readonly pages through
@@ -3888,19 +3688,15 @@
   // We don't activate signal checker if libjsig is in place, we trust ourselves
   // and if UserSignalHandler is installed all bets are off.
   // Log that signal checking is off only if -verbose:jni is specified.
   if (CheckJNICalls) {
     if (libjsig_is_loaded) {
-      if (PrintJNIResolving) {
-        tty->print_cr("Info: libjsig is activated, all active signal checking is disabled");
-      }
+      log_debug(jni, resolve)("Info: libjsig is activated, all active signal checking is disabled");
       check_signals = false;
     }
     if (AllowUserSignalHandlers) {
-      if (PrintJNIResolving) {
-        tty->print_cr("Info: AllowUserSignalHandlers is activated, all active signal checking is disabled");
-      }
+      log_debug(jni, resolve)("Info: AllowUserSignalHandlers is activated, all active signal checking is disabled");
       check_signals = false;
     }
   }
 }
 
@@ -4220,17 +4016,19 @@
   return JNI_OK;
 }
 
 // Mark the polling page as unreadable
 void os::make_polling_page_unreadable(void) {
+  Events::log(NULL, "Protecting polling page " INTPTR_FORMAT " with PROT_NONE", p2i(_polling_page));
   if (mprotect((char *)_polling_page, page_size, PROT_NONE) != 0) {
     fatal("Could not disable polling page");
   }
 }
 
 // Mark the polling page as readable
 void os::make_polling_page_readable(void) {
+  Events::log(NULL, "Protecting polling page " INTPTR_FORMAT " with PROT_READ", p2i(_polling_page));
   if (mprotect((char *)_polling_page, page_size, PROT_READ) != 0) {
     fatal("Could not enable polling page");
   }
 }
 
@@ -4469,11 +4267,11 @@
 }
 
 void os::pause() {
   char filename[MAX_PATH];
   if (PauseAtStartupFile && PauseAtStartupFile[0]) {
-    jio_snprintf(filename, MAX_PATH, PauseAtStartupFile);
+    jio_snprintf(filename, MAX_PATH, "%s", PauseAtStartupFile);
   } else {
     jio_snprintf(filename, MAX_PATH, "./vm.paused.%d", current_process_id());
   }
 
   int fd = ::open(filename, O_WRONLY | O_CREAT | O_TRUNC, 0666);
@@ -4912,11 +4710,11 @@
   assert(_nParked == 0, "invariant");
 
   int v;
   for (;;) {
     v = _Event;
-    if (Atomic::cmpxchg(v-1, &_Event, v) == v) break;
+    if (Atomic::cmpxchg(&_Event, v, v-1) == v) break;
   }
   guarantee(v >= 0, "invariant");
   if (v == 0) {
     // Do this the hard way by blocking ...
     // See http://monaco.sfbay/detail.jsf?cr=5094058.
@@ -4950,11 +4748,11 @@
 
   guarantee(_nParked == 0, "invariant");
   int v;
   for (;;) {
     v = _Event;
-    if (Atomic::cmpxchg(v-1, &_Event, v) == v) break;
+    if (Atomic::cmpxchg(&_Event, v, v-1) == v) break;
   }
   guarantee(v >= 0, "invariant");
   if (v != 0) return OS_OK;
 
   int ret = OS_TIMEOUT;
@@ -4999,11 +4797,11 @@
   // that it will take two back-to-back park() calls for the owning
   // thread to block. This has the benefit of forcing a spurious return
   // from the first park() call after an unpark() call which will help
   // shake out uses of park() and unpark() without condition variables.
 
-  if (Atomic::xchg(1, &_Event) >= 0) return;
+  if (Atomic::xchg(&_Event, 1) >= 0) return;
 
   // If the thread associated with the event was parked, wake it.
   // Wait for the thread assoc with the PlatformEvent to vacate.
   int status = os::Solaris::mutex_lock(_mutex);
   assert_status(status == 0, status, "mutex_lock");
@@ -5098,17 +4896,17 @@
 
   // Optional fast-path check:
   // Return immediately if a permit is available.
   // We depend on Atomic::xchg() having full barrier semantics
   // since we are doing a lock-free update to _counter.
-  if (Atomic::xchg(0, &_counter) > 0) return;
+  if (Atomic::xchg(&_counter, 0) > 0) return;
 
   // Optional fast-exit: Check interrupt before trying to wait
   Thread* thread = Thread::current();
   assert(thread->is_Java_thread(), "Must be JavaThread");
   JavaThread *jt = (JavaThread *)thread;
-  if (Thread::is_interrupted(thread, false)) {
+  if (jt->is_interrupted(false)) {
     return;
   }
 
   // First, demultiplex/decode time arguments
   timespec absTime;
@@ -5127,14 +4925,16 @@
   // In particular a thread must never block on the Threads_lock while
   // holding the Parker:: mutex.  If safepoints are pending both the
   // the ThreadBlockInVM() CTOR and DTOR may grab Threads_lock.
   ThreadBlockInVM tbivm(jt);
 
+  // Can't access interrupt state now that we are _thread_blocked. If we've
+  // been interrupted since we checked above then _counter will be > 0.
+
   // Don't wait if cannot get lock since interference arises from
-  // unblocking.  Also. check interrupt before trying wait
-  if (Thread::is_interrupted(thread, false) ||
-      os::Solaris::mutex_trylock(_mutex) != 0) {
+  // unblocking.
+  if (os::Solaris::mutex_trylock(_mutex) != 0) {
     return;
   }
 
   int status;
 
@@ -5190,42 +4990,48 @@
     status = os::Solaris::cond_signal(_cond);
     assert(status == 0, "invariant");
   }
 }
 
-// Platform Monitor implementation
+// Platform Mutex/Monitor implementations
 
-os::PlatformMonitor::PlatformMonitor() {
-  int status = os::Solaris::cond_init(&_cond);
-  assert_status(status == 0, status, "cond_init");
-  status = os::Solaris::mutex_init(&_mutex);
+os::PlatformMutex::PlatformMutex() {
+  int status = os::Solaris::mutex_init(&_mutex);
   assert_status(status == 0, status, "mutex_init");
 }
 
-os::PlatformMonitor::~PlatformMonitor() {
-  int status = os::Solaris::cond_destroy(&_cond);
-  assert_status(status == 0, status, "cond_destroy");
-  status = os::Solaris::mutex_destroy(&_mutex);
+os::PlatformMutex::~PlatformMutex() {
+  int status = os::Solaris::mutex_destroy(&_mutex);
   assert_status(status == 0, status, "mutex_destroy");
 }
 
-void os::PlatformMonitor::lock() {
+void os::PlatformMutex::lock() {
   int status = os::Solaris::mutex_lock(&_mutex);
   assert_status(status == 0, status, "mutex_lock");
 }
 
-void os::PlatformMonitor::unlock() {
+void os::PlatformMutex::unlock() {
   int status = os::Solaris::mutex_unlock(&_mutex);
   assert_status(status == 0, status, "mutex_unlock");
 }
 
-bool os::PlatformMonitor::try_lock() {
+bool os::PlatformMutex::try_lock() {
   int status = os::Solaris::mutex_trylock(&_mutex);
   assert_status(status == 0 || status == EBUSY, status, "mutex_trylock");
   return status == 0;
 }
 
+os::PlatformMonitor::PlatformMonitor() {
+  int status = os::Solaris::cond_init(&_cond);
+  assert_status(status == 0, status, "cond_init");
+}
+
+os::PlatformMonitor::~PlatformMonitor() {
+  int status = os::Solaris::cond_destroy(&_cond);
+  assert_status(status == 0, status, "cond_destroy");
+}
+
 // Must already be locked
 int os::PlatformMonitor::wait(jlong millis) {
   assert(millis >= 0, "negative timeout");
   if (millis > 0) {
     timestruc_t abst;
@@ -5415,10 +5221,14 @@
                                               p, current_process_id());
 
   return strlen(buffer);
 }
 
+bool os::supports_map_sync() {
+  return false;
+}
+
 #ifndef PRODUCT
 void TestReserveMemorySpecial_test() {
   // No tests available for this platform
 }
 #endif
