<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/os/windows/os_windows.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 // Must be at least Windows Vista or Server 2008 to use InitOnceExecuteOnce
  26 #define _WIN32_WINNT 0x0600
  27 
  28 // no precompiled headers
  29 #include &quot;jvm.h&quot;
  30 #include &quot;classfile/classLoader.hpp&quot;
  31 #include &quot;classfile/systemDictionary.hpp&quot;
  32 #include &quot;classfile/vmSymbols.hpp&quot;
  33 #include &quot;code/icBuffer.hpp&quot;
  34 #include &quot;code/vtableStubs.hpp&quot;
  35 #include &quot;compiler/compileBroker.hpp&quot;
  36 #include &quot;compiler/disassembler.hpp&quot;
  37 #include &quot;interpreter/interpreter.hpp&quot;
  38 #include &quot;logging/log.hpp&quot;
  39 #include &quot;memory/allocation.inline.hpp&quot;
  40 #include &quot;memory/filemap.hpp&quot;
  41 #include &quot;oops/oop.inline.hpp&quot;
  42 #include &quot;os_share_windows.hpp&quot;
  43 #include &quot;os_windows.inline.hpp&quot;
  44 #include &quot;prims/jniFastGetField.hpp&quot;
  45 #include &quot;prims/jvm_misc.hpp&quot;
  46 #include &quot;runtime/arguments.hpp&quot;
  47 #include &quot;runtime/atomic.hpp&quot;
  48 #include &quot;runtime/extendedPC.hpp&quot;
  49 #include &quot;runtime/globals.hpp&quot;
  50 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  51 #include &quot;runtime/java.hpp&quot;
  52 #include &quot;runtime/javaCalls.hpp&quot;
  53 #include &quot;runtime/mutexLocker.hpp&quot;
  54 #include &quot;runtime/objectMonitor.hpp&quot;
  55 #include &quot;runtime/orderAccess.hpp&quot;
  56 #include &quot;runtime/osThread.hpp&quot;
  57 #include &quot;runtime/perfMemory.hpp&quot;
  58 #include &quot;runtime/sharedRuntime.hpp&quot;
  59 #include &quot;runtime/statSampler.hpp&quot;
  60 #include &quot;runtime/stubRoutines.hpp&quot;
  61 #include &quot;runtime/thread.inline.hpp&quot;
  62 #include &quot;runtime/threadCritical.hpp&quot;
  63 #include &quot;runtime/timer.hpp&quot;
  64 #include &quot;runtime/vm_version.hpp&quot;
  65 #include &quot;services/attachListener.hpp&quot;
  66 #include &quot;services/memTracker.hpp&quot;
  67 #include &quot;services/runtimeService.hpp&quot;
  68 #include &quot;utilities/align.hpp&quot;
  69 #include &quot;utilities/decoder.hpp&quot;
  70 #include &quot;utilities/defaultStream.hpp&quot;
  71 #include &quot;utilities/events.hpp&quot;
  72 #include &quot;utilities/growableArray.hpp&quot;
  73 #include &quot;utilities/macros.hpp&quot;
  74 #include &quot;utilities/vmError.hpp&quot;
  75 #include &quot;symbolengine.hpp&quot;
  76 #include &quot;windbghelp.hpp&quot;
  77 
  78 
  79 #ifdef _DEBUG
  80 #include &lt;crtdbg.h&gt;
  81 #endif
  82 
  83 
  84 #include &lt;windows.h&gt;
  85 #include &lt;sys/types.h&gt;
  86 #include &lt;sys/stat.h&gt;
  87 #include &lt;sys/timeb.h&gt;
  88 #include &lt;objidl.h&gt;
  89 #include &lt;shlobj.h&gt;
  90 
  91 #include &lt;malloc.h&gt;
  92 #include &lt;signal.h&gt;
  93 #include &lt;direct.h&gt;
  94 #include &lt;errno.h&gt;
  95 #include &lt;fcntl.h&gt;
  96 #include &lt;io.h&gt;
  97 #include &lt;process.h&gt;              // For _beginthreadex(), _endthreadex()
  98 #include &lt;imagehlp.h&gt;             // For os::dll_address_to_function_name
  99 // for enumerating dll libraries
 100 #include &lt;vdmdbg.h&gt;
 101 #include &lt;psapi.h&gt;
 102 #include &lt;mmsystem.h&gt;
 103 #include &lt;winsock2.h&gt;
 104 
 105 // for timer info max values which include all bits
 106 #define ALL_64_BITS CONST64(-1)
 107 
 108 // For DLL loading/load error detection
 109 // Values of PE COFF
 110 #define IMAGE_FILE_PTR_TO_SIGNATURE 0x3c
 111 #define IMAGE_FILE_SIGNATURE_LENGTH 4
 112 
 113 static HANDLE main_process;
 114 static HANDLE main_thread;
 115 static int    main_thread_id;
 116 
 117 static FILETIME process_creation_time;
 118 static FILETIME process_exit_time;
 119 static FILETIME process_user_time;
 120 static FILETIME process_kernel_time;
 121 
 122 #ifdef _M_AMD64
 123   #define __CPU__ amd64
 124 #else
 125   #define __CPU__ i486
 126 #endif
 127 
 128 #if INCLUDE_AOT
 129 PVOID  topLevelVectoredExceptionHandler = NULL;
 130 LONG WINAPI topLevelVectoredExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo);
 131 #endif
 132 
 133 // save DLL module handle, used by GetModuleFileName
 134 
 135 HINSTANCE vm_lib_handle;
 136 
 137 BOOL WINAPI DllMain(HINSTANCE hinst, DWORD reason, LPVOID reserved) {
 138   switch (reason) {
 139   case DLL_PROCESS_ATTACH:
 140     vm_lib_handle = hinst;
 141     if (ForceTimeHighResolution) {
 142       timeBeginPeriod(1L);
 143     }
 144     WindowsDbgHelp::pre_initialize();
 145     SymbolEngine::pre_initialize();
 146     break;
 147   case DLL_PROCESS_DETACH:
 148     if (ForceTimeHighResolution) {
 149       timeEndPeriod(1L);
 150     }
 151 #if INCLUDE_AOT
 152     if (topLevelVectoredExceptionHandler != NULL) {
 153       RemoveVectoredExceptionHandler(topLevelVectoredExceptionHandler);
 154       topLevelVectoredExceptionHandler = NULL;
 155     }
 156 #endif
 157     break;
 158   default:
 159     break;
 160   }
 161   return true;
 162 }
 163 
 164 static inline double fileTimeAsDouble(FILETIME* time) {
 165   const double high  = (double) ((unsigned int) ~0);
 166   const double split = 10000000.0;
 167   double result = (time-&gt;dwLowDateTime / split) +
 168                    time-&gt;dwHighDateTime * (high/split);
 169   return result;
 170 }
 171 
 172 // Implementation of os
 173 
 174 bool os::unsetenv(const char* name) {
 175   assert(name != NULL, &quot;Null pointer&quot;);
 176   return (SetEnvironmentVariable(name, NULL) == TRUE);
 177 }
 178 
 179 // No setuid programs under Windows.
 180 bool os::have_special_privileges() {
 181   return false;
 182 }
 183 
 184 
 185 // This method is  a periodic task to check for misbehaving JNI applications
 186 // under CheckJNI, we can add any periodic checks here.
 187 // For Windows at the moment does nothing
 188 void os::run_periodic_checks() {
 189   return;
 190 }
 191 
 192 // previous UnhandledExceptionFilter, if there is one
 193 static LPTOP_LEVEL_EXCEPTION_FILTER prev_uef_handler = NULL;
 194 
 195 LONG WINAPI Handle_FLT_Exception(struct _EXCEPTION_POINTERS* exceptionInfo);
 196 
 197 void os::init_system_properties_values() {
 198   // sysclasspath, java_home, dll_dir
 199   {
 200     char *home_path;
 201     char *dll_path;
 202     char *pslash;
 203     char *bin = &quot;\\bin&quot;;
 204     char home_dir[MAX_PATH + 1];
 205     char *alt_home_dir = ::getenv(&quot;_ALT_JAVA_HOME_DIR&quot;);
 206 
 207     if (alt_home_dir != NULL)  {
 208       strncpy(home_dir, alt_home_dir, MAX_PATH + 1);
 209       home_dir[MAX_PATH] = &#39;\0&#39;;
 210     } else {
 211       os::jvm_path(home_dir, sizeof(home_dir));
 212       // Found the full path to jvm.dll.
 213       // Now cut the path to &lt;java_home&gt;/jre if we can.
 214       *(strrchr(home_dir, &#39;\\&#39;)) = &#39;\0&#39;;  // get rid of \jvm.dll
 215       pslash = strrchr(home_dir, &#39;\\&#39;);
 216       if (pslash != NULL) {
 217         *pslash = &#39;\0&#39;;                   // get rid of \{client|server}
 218         pslash = strrchr(home_dir, &#39;\\&#39;);
 219         if (pslash != NULL) {
 220           *pslash = &#39;\0&#39;;                 // get rid of \bin
 221         }
 222       }
 223     }
 224 
 225     home_path = NEW_C_HEAP_ARRAY(char, strlen(home_dir) + 1, mtInternal);
 226     if (home_path == NULL) {
 227       return;
 228     }
 229     strcpy(home_path, home_dir);
 230     Arguments::set_java_home(home_path);
 231     FREE_C_HEAP_ARRAY(char, home_path);
 232 
 233     dll_path = NEW_C_HEAP_ARRAY(char, strlen(home_dir) + strlen(bin) + 1,
 234                                 mtInternal);
 235     if (dll_path == NULL) {
 236       return;
 237     }
 238     strcpy(dll_path, home_dir);
 239     strcat(dll_path, bin);
 240     Arguments::set_dll_dir(dll_path);
 241     FREE_C_HEAP_ARRAY(char, dll_path);
 242 
 243     if (!set_boot_path(&#39;\\&#39;, &#39;;&#39;)) {
 244       vm_exit_during_initialization(&quot;Failed setting boot class path.&quot;, NULL);
 245     }
 246   }
 247 
 248 // library_path
 249 #define EXT_DIR &quot;\\lib\\ext&quot;
 250 #define BIN_DIR &quot;\\bin&quot;
 251 #define PACKAGE_DIR &quot;\\Sun\\Java&quot;
 252   {
 253     // Win32 library search order (See the documentation for LoadLibrary):
 254     //
 255     // 1. The directory from which application is loaded.
 256     // 2. The system wide Java Extensions directory (Java only)
 257     // 3. System directory (GetSystemDirectory)
 258     // 4. Windows directory (GetWindowsDirectory)
 259     // 5. The PATH environment variable
 260     // 6. The current directory
 261 
 262     char *library_path;
 263     char tmp[MAX_PATH];
 264     char *path_str = ::getenv(&quot;PATH&quot;);
 265 
 266     library_path = NEW_C_HEAP_ARRAY(char, MAX_PATH * 5 + sizeof(PACKAGE_DIR) +
 267                                     sizeof(BIN_DIR) + (path_str ? strlen(path_str) : 0) + 10, mtInternal);
 268 
 269     library_path[0] = &#39;\0&#39;;
 270 
 271     GetModuleFileName(NULL, tmp, sizeof(tmp));
 272     *(strrchr(tmp, &#39;\\&#39;)) = &#39;\0&#39;;
 273     strcat(library_path, tmp);
 274 
 275     GetWindowsDirectory(tmp, sizeof(tmp));
 276     strcat(library_path, &quot;;&quot;);
 277     strcat(library_path, tmp);
 278     strcat(library_path, PACKAGE_DIR BIN_DIR);
 279 
 280     GetSystemDirectory(tmp, sizeof(tmp));
 281     strcat(library_path, &quot;;&quot;);
 282     strcat(library_path, tmp);
 283 
 284     GetWindowsDirectory(tmp, sizeof(tmp));
 285     strcat(library_path, &quot;;&quot;);
 286     strcat(library_path, tmp);
 287 
 288     if (path_str) {
 289       strcat(library_path, &quot;;&quot;);
 290       strcat(library_path, path_str);
 291     }
 292 
 293     strcat(library_path, &quot;;.&quot;);
 294 
 295     Arguments::set_library_path(library_path);
 296     FREE_C_HEAP_ARRAY(char, library_path);
 297   }
 298 
 299   // Default extensions directory
 300   {
 301     char path[MAX_PATH];
 302     char buf[2 * MAX_PATH + 2 * sizeof(EXT_DIR) + sizeof(PACKAGE_DIR) + 1];
 303     GetWindowsDirectory(path, MAX_PATH);
 304     sprintf(buf, &quot;%s%s;%s%s%s&quot;, Arguments::get_java_home(), EXT_DIR,
 305             path, PACKAGE_DIR, EXT_DIR);
 306     Arguments::set_ext_dirs(buf);
 307   }
 308   #undef EXT_DIR
 309   #undef BIN_DIR
 310   #undef PACKAGE_DIR
 311 
 312 #ifndef _WIN64
 313   // set our UnhandledExceptionFilter and save any previous one
 314   prev_uef_handler = SetUnhandledExceptionFilter(Handle_FLT_Exception);
 315 #endif
 316 
 317   // Done
 318   return;
 319 }
 320 
 321 void os::breakpoint() {
 322   DebugBreak();
 323 }
 324 
 325 // Invoked from the BREAKPOINT Macro
 326 extern &quot;C&quot; void breakpoint() {
 327   os::breakpoint();
 328 }
 329 
 330 // RtlCaptureStackBackTrace Windows API may not exist prior to Windows XP.
 331 // So far, this method is only used by Native Memory Tracking, which is
 332 // only supported on Windows XP or later.
 333 //
 334 int os::get_native_stack(address* stack, int frames, int toSkip) {
 335   int captured = RtlCaptureStackBackTrace(toSkip + 1, frames, (PVOID*)stack, NULL);
 336   for (int index = captured; index &lt; frames; index ++) {
 337     stack[index] = NULL;
 338   }
 339   return captured;
 340 }
 341 
 342 
 343 // os::current_stack_base()
 344 //
 345 //   Returns the base of the stack, which is the stack&#39;s
 346 //   starting address.  This function must be called
 347 //   while running on the stack of the thread being queried.
 348 
 349 address os::current_stack_base() {
 350   MEMORY_BASIC_INFORMATION minfo;
 351   address stack_bottom;
 352   size_t stack_size;
 353 
 354   VirtualQuery(&amp;minfo, &amp;minfo, sizeof(minfo));
 355   stack_bottom =  (address)minfo.AllocationBase;
 356   stack_size = minfo.RegionSize;
 357 
 358   // Add up the sizes of all the regions with the same
 359   // AllocationBase.
 360   while (1) {
 361     VirtualQuery(stack_bottom+stack_size, &amp;minfo, sizeof(minfo));
 362     if (stack_bottom == (address)minfo.AllocationBase) {
 363       stack_size += minfo.RegionSize;
 364     } else {
 365       break;
 366     }
 367   }
 368   return stack_bottom + stack_size;
 369 }
 370 
 371 size_t os::current_stack_size() {
 372   size_t sz;
 373   MEMORY_BASIC_INFORMATION minfo;
 374   VirtualQuery(&amp;minfo, &amp;minfo, sizeof(minfo));
 375   sz = (size_t)os::current_stack_base() - (size_t)minfo.AllocationBase;
 376   return sz;
 377 }
 378 
 379 bool os::committed_in_range(address start, size_t size, address&amp; committed_start, size_t&amp; committed_size) {
 380   MEMORY_BASIC_INFORMATION minfo;
 381   committed_start = NULL;
 382   committed_size = 0;
 383   address top = start + size;
 384   const address start_addr = start;
 385   while (start &lt; top) {
 386     VirtualQuery(start, &amp;minfo, sizeof(minfo));
 387     if ((minfo.State &amp; MEM_COMMIT) == 0) {  // not committed
 388       if (committed_start != NULL) {
 389         break;
 390       }
 391     } else {  // committed
 392       if (committed_start == NULL) {
 393         committed_start = start;
 394       }
 395       size_t offset = start - (address)minfo.BaseAddress;
 396       committed_size += minfo.RegionSize - offset;
 397     }
 398     start = (address)minfo.BaseAddress + minfo.RegionSize;
 399   }
 400 
 401   if (committed_start == NULL) {
 402     assert(committed_size == 0, &quot;Sanity&quot;);
 403     return false;
 404   } else {
 405     assert(committed_start &gt;= start_addr &amp;&amp; committed_start &lt; top, &quot;Out of range&quot;);
 406     // current region may go beyond the limit, trim to the limit
 407     committed_size = MIN2(committed_size, size_t(top - committed_start));
 408     return true;
 409   }
 410 }
 411 
 412 struct tm* os::localtime_pd(const time_t* clock, struct tm* res) {
 413   const struct tm* time_struct_ptr = localtime(clock);
 414   if (time_struct_ptr != NULL) {
 415     *res = *time_struct_ptr;
 416     return res;
 417   }
 418   return NULL;
 419 }
 420 
 421 struct tm* os::gmtime_pd(const time_t* clock, struct tm* res) {
 422   const struct tm* time_struct_ptr = gmtime(clock);
 423   if (time_struct_ptr != NULL) {
 424     *res = *time_struct_ptr;
 425     return res;
 426   }
 427   return NULL;
 428 }
 429 
 430 LONG WINAPI topLevelExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo);
 431 
 432 // Thread start routine for all newly created threads
 433 static unsigned __stdcall thread_native_entry(Thread* thread) {
 434 
 435   thread-&gt;record_stack_base_and_size();
 436 
 437   // Try to randomize the cache line index of hot stack frames.
 438   // This helps when threads of the same stack traces evict each other&#39;s
 439   // cache lines. The threads can be either from the same JVM instance, or
 440   // from different JVM instances. The benefit is especially true for
 441   // processors with hyperthreading technology.
 442   static int counter = 0;
 443   int pid = os::current_process_id();
 444   _alloca(((pid ^ counter++) &amp; 7) * 128);
 445 
 446   thread-&gt;initialize_thread_current();
 447 
 448   OSThread* osthr = thread-&gt;osthread();
 449   assert(osthr-&gt;get_state() == RUNNABLE, &quot;invalid os thread state&quot;);
 450 
 451   if (UseNUMA) {
 452     int lgrp_id = os::numa_get_group_id();
 453     if (lgrp_id != -1) {
 454       thread-&gt;set_lgrp_id(lgrp_id);
 455     }
 456   }
 457 
 458   // Diagnostic code to investigate JDK-6573254
 459   int res = 30115;  // non-java thread
 460   if (thread-&gt;is_Java_thread()) {
 461     res = 20115;    // java thread
 462   }
 463 
 464   log_info(os, thread)(&quot;Thread is alive (tid: &quot; UINTX_FORMAT &quot;).&quot;, os::current_thread_id());
 465 
 466   // Install a win32 structured exception handler around every thread created
 467   // by VM, so VM can generate error dump when an exception occurred in non-
 468   // Java thread (e.g. VM thread).
 469   __try {
 470     thread-&gt;call_run();
 471   } __except(topLevelExceptionFilter(
 472                                      (_EXCEPTION_POINTERS*)_exception_info())) {
 473     // Nothing to do.
 474   }
 475 
 476   // Note: at this point the thread object may already have deleted itself.
 477   // Do not dereference it from here on out.
 478 
 479   log_info(os, thread)(&quot;Thread finished (tid: &quot; UINTX_FORMAT &quot;).&quot;, os::current_thread_id());
 480 
 481   // One less thread is executing
 482   // When the VMThread gets here, the main thread may have already exited
 483   // which frees the CodeHeap containing the Atomic::add code
 484   if (thread != VMThread::vm_thread() &amp;&amp; VMThread::vm_thread() != NULL) {
 485     Atomic::dec(&amp;os::win32::_os_thread_count);
 486   }
 487 
 488   // Thread must not return from exit_process_or_thread(), but if it does,
 489   // let it proceed to exit normally
 490   return (unsigned)os::win32::exit_process_or_thread(os::win32::EPT_THREAD, res);
 491 }
 492 
 493 static OSThread* create_os_thread(Thread* thread, HANDLE thread_handle,
 494                                   int thread_id) {
 495   // Allocate the OSThread object
 496   OSThread* osthread = new OSThread(NULL, NULL);
 497   if (osthread == NULL) return NULL;
 498 
 499   // Initialize support for Java interrupts
 500   HANDLE interrupt_event = CreateEvent(NULL, true, false, NULL);
 501   if (interrupt_event == NULL) {
 502     delete osthread;
 503     return NULL;
 504   }
 505   osthread-&gt;set_interrupt_event(interrupt_event);
 506 
 507   // Store info on the Win32 thread into the OSThread
 508   osthread-&gt;set_thread_handle(thread_handle);
 509   osthread-&gt;set_thread_id(thread_id);
 510 
 511   if (UseNUMA) {
 512     int lgrp_id = os::numa_get_group_id();
 513     if (lgrp_id != -1) {
 514       thread-&gt;set_lgrp_id(lgrp_id);
 515     }
 516   }
 517 
 518   // Initial thread state is INITIALIZED, not SUSPENDED
 519   osthread-&gt;set_state(INITIALIZED);
 520 
 521   return osthread;
 522 }
 523 
 524 
 525 bool os::create_attached_thread(JavaThread* thread) {
 526 #ifdef ASSERT
 527   thread-&gt;verify_not_published();
 528 #endif
 529   HANDLE thread_h;
 530   if (!DuplicateHandle(main_process, GetCurrentThread(), GetCurrentProcess(),
 531                        &amp;thread_h, THREAD_ALL_ACCESS, false, 0)) {
 532     fatal(&quot;DuplicateHandle failed\n&quot;);
 533   }
 534   OSThread* osthread = create_os_thread(thread, thread_h,
 535                                         (int)current_thread_id());
 536   if (osthread == NULL) {
 537     return false;
 538   }
 539 
 540   // Initial thread state is RUNNABLE
 541   osthread-&gt;set_state(RUNNABLE);
 542 
 543   thread-&gt;set_osthread(osthread);
 544 
 545   log_info(os, thread)(&quot;Thread attached (tid: &quot; UINTX_FORMAT &quot;).&quot;,
 546     os::current_thread_id());
 547 
 548   return true;
 549 }
 550 
 551 bool os::create_main_thread(JavaThread* thread) {
 552 #ifdef ASSERT
 553   thread-&gt;verify_not_published();
 554 #endif
 555   if (_starting_thread == NULL) {
 556     _starting_thread = create_os_thread(thread, main_thread, main_thread_id);
 557     if (_starting_thread == NULL) {
 558       return false;
 559     }
 560   }
 561 
 562   // The primordial thread is runnable from the start)
 563   _starting_thread-&gt;set_state(RUNNABLE);
 564 
 565   thread-&gt;set_osthread(_starting_thread);
 566   return true;
 567 }
 568 
 569 // Helper function to trace _beginthreadex attributes,
 570 //  similar to os::Posix::describe_pthread_attr()
 571 static char* describe_beginthreadex_attributes(char* buf, size_t buflen,
 572                                                size_t stacksize, unsigned initflag) {
 573   stringStream ss(buf, buflen);
 574   if (stacksize == 0) {
 575     ss.print(&quot;stacksize: default, &quot;);
 576   } else {
 577     ss.print(&quot;stacksize: &quot; SIZE_FORMAT &quot;k, &quot;, stacksize / 1024);
 578   }
 579   ss.print(&quot;flags: &quot;);
 580   #define PRINT_FLAG(f) if (initflag &amp; f) ss.print( #f &quot; &quot;);
 581   #define ALL(X) \
 582     X(CREATE_SUSPENDED) \
 583     X(STACK_SIZE_PARAM_IS_A_RESERVATION)
 584   ALL(PRINT_FLAG)
 585   #undef ALL
 586   #undef PRINT_FLAG
 587   return buf;
 588 }
 589 
 590 // Allocate and initialize a new OSThread
 591 bool os::create_thread(Thread* thread, ThreadType thr_type,
 592                        size_t stack_size) {
 593   unsigned thread_id;
 594 
 595   // Allocate the OSThread object
 596   OSThread* osthread = new OSThread(NULL, NULL);
 597   if (osthread == NULL) {
 598     return false;
 599   }
 600 
 601   // Initialize support for Java interrupts
 602   HANDLE interrupt_event = CreateEvent(NULL, true, false, NULL);
 603   if (interrupt_event == NULL) {
 604     delete osthread;
 605     return false;
 606   }
 607   osthread-&gt;set_interrupt_event(interrupt_event);
 608   osthread-&gt;set_interrupted(false);
 609 
 610   thread-&gt;set_osthread(osthread);
 611 
 612   if (stack_size == 0) {
 613     switch (thr_type) {
 614     case os::java_thread:
 615       // Java threads use ThreadStackSize which default value can be changed with the flag -Xss
 616       if (JavaThread::stack_size_at_create() &gt; 0) {
 617         stack_size = JavaThread::stack_size_at_create();
 618       }
 619       break;
 620     case os::compiler_thread:
 621       if (CompilerThreadStackSize &gt; 0) {
 622         stack_size = (size_t)(CompilerThreadStackSize * K);
 623         break;
 624       } // else fall through:
 625         // use VMThreadStackSize if CompilerThreadStackSize is not defined
 626     case os::vm_thread:
 627     case os::pgc_thread:
 628     case os::cgc_thread:
 629     case os::watcher_thread:
 630       if (VMThreadStackSize &gt; 0) stack_size = (size_t)(VMThreadStackSize * K);
 631       break;
 632     }
 633   }
 634 
 635   // Create the Win32 thread
 636   //
 637   // Contrary to what MSDN document says, &quot;stack_size&quot; in _beginthreadex()
 638   // does not specify stack size. Instead, it specifies the size of
 639   // initially committed space. The stack size is determined by
 640   // PE header in the executable. If the committed &quot;stack_size&quot; is larger
 641   // than default value in the PE header, the stack is rounded up to the
 642   // nearest multiple of 1MB. For example if the launcher has default
 643   // stack size of 320k, specifying any size less than 320k does not
 644   // affect the actual stack size at all, it only affects the initial
 645   // commitment. On the other hand, specifying &#39;stack_size&#39; larger than
 646   // default value may cause significant increase in memory usage, because
 647   // not only the stack space will be rounded up to MB, but also the
 648   // entire space is committed upfront.
 649   //
 650   // Finally Windows XP added a new flag &#39;STACK_SIZE_PARAM_IS_A_RESERVATION&#39;
 651   // for CreateThread() that can treat &#39;stack_size&#39; as stack size. However we
 652   // are not supposed to call CreateThread() directly according to MSDN
 653   // document because JVM uses C runtime library. The good news is that the
 654   // flag appears to work with _beginthredex() as well.
 655 
 656   const unsigned initflag = CREATE_SUSPENDED | STACK_SIZE_PARAM_IS_A_RESERVATION;
 657   HANDLE thread_handle =
 658     (HANDLE)_beginthreadex(NULL,
 659                            (unsigned)stack_size,
 660                            (unsigned (__stdcall *)(void*)) thread_native_entry,
 661                            thread,
 662                            initflag,
 663                            &amp;thread_id);
 664 
 665   char buf[64];
 666   if (thread_handle != NULL) {
 667     log_info(os, thread)(&quot;Thread started (tid: %u, attributes: %s)&quot;,
 668       thread_id, describe_beginthreadex_attributes(buf, sizeof(buf), stack_size, initflag));
 669   } else {
 670     log_warning(os, thread)(&quot;Failed to start thread - _beginthreadex failed (%s) for attributes: %s.&quot;,
 671       os::errno_name(errno), describe_beginthreadex_attributes(buf, sizeof(buf), stack_size, initflag));
 672   }
 673 
 674   if (thread_handle == NULL) {
 675     // Need to clean up stuff we&#39;ve allocated so far
 676     CloseHandle(osthread-&gt;interrupt_event());
 677     thread-&gt;set_osthread(NULL);
 678     delete osthread;
 679     return false;
 680   }
 681 
 682   Atomic::inc(&amp;os::win32::_os_thread_count);
 683 
 684   // Store info on the Win32 thread into the OSThread
 685   osthread-&gt;set_thread_handle(thread_handle);
 686   osthread-&gt;set_thread_id(thread_id);
 687 
 688   // Initial thread state is INITIALIZED, not SUSPENDED
 689   osthread-&gt;set_state(INITIALIZED);
 690 
 691   // The thread is returned suspended (in state INITIALIZED), and is started higher up in the call chain
 692   return true;
 693 }
 694 
 695 
 696 // Free Win32 resources related to the OSThread
 697 void os::free_thread(OSThread* osthread) {
 698   assert(osthread != NULL, &quot;osthread not set&quot;);
 699 
 700   // We are told to free resources of the argument thread,
 701   // but we can only really operate on the current thread.
 702   assert(Thread::current()-&gt;osthread() == osthread,
 703          &quot;os::free_thread but not current thread&quot;);
 704 
 705   CloseHandle(osthread-&gt;thread_handle());
 706   CloseHandle(osthread-&gt;interrupt_event());
 707   delete osthread;
 708 }
 709 
 710 static jlong first_filetime;
 711 static jlong initial_performance_count;
 712 static jlong performance_frequency;
 713 
 714 
 715 jlong as_long(LARGE_INTEGER x) {
 716   jlong result = 0; // initialization to avoid warning
 717   set_high(&amp;result, x.HighPart);
 718   set_low(&amp;result, x.LowPart);
 719   return result;
 720 }
 721 
 722 
 723 jlong os::elapsed_counter() {
 724   LARGE_INTEGER count;
 725   QueryPerformanceCounter(&amp;count);
 726   return as_long(count) - initial_performance_count;
 727 }
 728 
 729 
 730 jlong os::elapsed_frequency() {
 731   return performance_frequency;
 732 }
 733 
 734 
 735 julong os::available_memory() {
 736   return win32::available_memory();
 737 }
 738 
 739 julong os::win32::available_memory() {
 740   // Use GlobalMemoryStatusEx() because GlobalMemoryStatus() may return incorrect
 741   // value if total memory is larger than 4GB
 742   MEMORYSTATUSEX ms;
 743   ms.dwLength = sizeof(ms);
 744   GlobalMemoryStatusEx(&amp;ms);
 745 
 746   return (julong)ms.ullAvailPhys;
 747 }
 748 
 749 julong os::physical_memory() {
 750   return win32::physical_memory();
 751 }
 752 
 753 bool os::has_allocatable_memory_limit(julong* limit) {
 754   MEMORYSTATUSEX ms;
 755   ms.dwLength = sizeof(ms);
 756   GlobalMemoryStatusEx(&amp;ms);
 757 #ifdef _LP64
 758   *limit = (julong)ms.ullAvailVirtual;
 759   return true;
 760 #else
 761   // Limit to 1400m because of the 2gb address space wall
 762   *limit = MIN2((julong)1400*M, (julong)ms.ullAvailVirtual);
 763   return true;
 764 #endif
 765 }
 766 
 767 int os::active_processor_count() {
 768   // User has overridden the number of active processors
 769   if (ActiveProcessorCount &gt; 0) {
 770     log_trace(os)(&quot;active_processor_count: &quot;
 771                   &quot;active processor count set by user : %d&quot;,
 772                   ActiveProcessorCount);
 773     return ActiveProcessorCount;
 774   }
 775 
 776   DWORD_PTR lpProcessAffinityMask = 0;
 777   DWORD_PTR lpSystemAffinityMask = 0;
 778   int proc_count = processor_count();
 779   if (proc_count &lt;= sizeof(UINT_PTR) * BitsPerByte &amp;&amp;
 780       GetProcessAffinityMask(GetCurrentProcess(), &amp;lpProcessAffinityMask, &amp;lpSystemAffinityMask)) {
 781     // Nof active processors is number of bits in process affinity mask
 782     int bitcount = 0;
 783     while (lpProcessAffinityMask != 0) {
 784       lpProcessAffinityMask = lpProcessAffinityMask &amp; (lpProcessAffinityMask-1);
 785       bitcount++;
 786     }
 787     return bitcount;
 788   } else {
 789     return proc_count;
 790   }
 791 }
 792 
 793 void os::set_native_thread_name(const char *name) {
 794 
 795   // See: http://msdn.microsoft.com/en-us/library/xcb2z8hs.aspx
 796   //
 797   // Note that unfortunately this only works if the process
 798   // is already attached to a debugger; debugger must observe
 799   // the exception below to show the correct name.
 800 
 801   // If there is no debugger attached skip raising the exception
 802   if (!IsDebuggerPresent()) {
 803     return;
 804   }
 805 
 806   const DWORD MS_VC_EXCEPTION = 0x406D1388;
 807   struct {
 808     DWORD dwType;     // must be 0x1000
 809     LPCSTR szName;    // pointer to name (in user addr space)
 810     DWORD dwThreadID; // thread ID (-1=caller thread)
 811     DWORD dwFlags;    // reserved for future use, must be zero
 812   } info;
 813 
 814   info.dwType = 0x1000;
 815   info.szName = name;
 816   info.dwThreadID = -1;
 817   info.dwFlags = 0;
 818 
 819   __try {
 820     RaiseException (MS_VC_EXCEPTION, 0, sizeof(info)/sizeof(DWORD), (const ULONG_PTR*)&amp;info );
 821   } __except(EXCEPTION_EXECUTE_HANDLER) {}
 822 }
 823 
 824 bool os::distribute_processes(uint length, uint* distribution) {
 825   // Not yet implemented.
 826   return false;
 827 }
 828 
 829 bool os::bind_to_processor(uint processor_id) {
 830   // Not yet implemented.
 831   return false;
 832 }
 833 
 834 void os::win32::initialize_performance_counter() {
 835   LARGE_INTEGER count;
 836   QueryPerformanceFrequency(&amp;count);
 837   performance_frequency = as_long(count);
 838   QueryPerformanceCounter(&amp;count);
 839   initial_performance_count = as_long(count);
 840 }
 841 
 842 
 843 double os::elapsedTime() {
 844   return (double) elapsed_counter() / (double) elapsed_frequency();
 845 }
 846 
 847 
 848 // Windows format:
 849 //   The FILETIME structure is a 64-bit value representing the number of 100-nanosecond intervals since January 1, 1601.
 850 // Java format:
 851 //   Java standards require the number of milliseconds since 1/1/1970
 852 
 853 // Constant offset - calculated using offset()
 854 static jlong  _offset   = 116444736000000000;
 855 // Fake time counter for reproducible results when debugging
 856 static jlong  fake_time = 0;
 857 
 858 #ifdef ASSERT
 859 // Just to be safe, recalculate the offset in debug mode
 860 static jlong _calculated_offset = 0;
 861 static int   _has_calculated_offset = 0;
 862 
 863 jlong offset() {
 864   if (_has_calculated_offset) return _calculated_offset;
 865   SYSTEMTIME java_origin;
 866   java_origin.wYear          = 1970;
 867   java_origin.wMonth         = 1;
 868   java_origin.wDayOfWeek     = 0; // ignored
 869   java_origin.wDay           = 1;
 870   java_origin.wHour          = 0;
 871   java_origin.wMinute        = 0;
 872   java_origin.wSecond        = 0;
 873   java_origin.wMilliseconds  = 0;
 874   FILETIME jot;
 875   if (!SystemTimeToFileTime(&amp;java_origin, &amp;jot)) {
 876     fatal(&quot;Error = %d\nWindows error&quot;, GetLastError());
 877   }
 878   _calculated_offset = jlong_from(jot.dwHighDateTime, jot.dwLowDateTime);
 879   _has_calculated_offset = 1;
 880   assert(_calculated_offset == _offset, &quot;Calculated and constant time offsets must be equal&quot;);
 881   return _calculated_offset;
 882 }
 883 #else
 884 jlong offset() {
 885   return _offset;
 886 }
 887 #endif
 888 
 889 jlong windows_to_java_time(FILETIME wt) {
 890   jlong a = jlong_from(wt.dwHighDateTime, wt.dwLowDateTime);
 891   return (a - offset()) / 10000;
 892 }
 893 
 894 // Returns time ticks in (10th of micro seconds)
 895 jlong windows_to_time_ticks(FILETIME wt) {
 896   jlong a = jlong_from(wt.dwHighDateTime, wt.dwLowDateTime);
 897   return (a - offset());
 898 }
 899 
 900 FILETIME java_to_windows_time(jlong l) {
 901   jlong a = (l * 10000) + offset();
 902   FILETIME result;
 903   result.dwHighDateTime = high(a);
 904   result.dwLowDateTime  = low(a);
 905   return result;
 906 }
 907 
 908 bool os::supports_vtime() { return true; }
 909 bool os::enable_vtime() { return false; }
 910 bool os::vtime_enabled() { return false; }
 911 
 912 double os::elapsedVTime() {
 913   FILETIME created;
 914   FILETIME exited;
 915   FILETIME kernel;
 916   FILETIME user;
 917   if (GetThreadTimes(GetCurrentThread(), &amp;created, &amp;exited, &amp;kernel, &amp;user) != 0) {
 918     // the resolution of windows_to_java_time() should be sufficient (ms)
 919     return (double) (windows_to_java_time(kernel) + windows_to_java_time(user)) / MILLIUNITS;
 920   } else {
 921     return elapsedTime();
 922   }
 923 }
 924 
 925 jlong os::javaTimeMillis() {
 926   FILETIME wt;
 927   GetSystemTimeAsFileTime(&amp;wt);
 928   return windows_to_java_time(wt);
 929 }
 930 
 931 void os::javaTimeSystemUTC(jlong &amp;seconds, jlong &amp;nanos) {
 932   FILETIME wt;
 933   GetSystemTimeAsFileTime(&amp;wt);
 934   jlong ticks = windows_to_time_ticks(wt); // 10th of micros
 935   jlong secs = jlong(ticks / 10000000); // 10000 * 1000
 936   seconds = secs;
 937   nanos = jlong(ticks - (secs*10000000)) * 100;
 938 }
 939 
 940 jlong os::javaTimeNanos() {
 941     LARGE_INTEGER current_count;
 942     QueryPerformanceCounter(&amp;current_count);
 943     double current = as_long(current_count);
 944     double freq = performance_frequency;
 945     jlong time = (jlong)((current/freq) * NANOSECS_PER_SEC);
 946     return time;
 947 }
 948 
 949 void os::javaTimeNanos_info(jvmtiTimerInfo *info_ptr) {
 950   jlong freq = performance_frequency;
 951   if (freq &lt; NANOSECS_PER_SEC) {
 952     // the performance counter is 64 bits and we will
 953     // be multiplying it -- so no wrap in 64 bits
 954     info_ptr-&gt;max_value = ALL_64_BITS;
 955   } else if (freq &gt; NANOSECS_PER_SEC) {
 956     // use the max value the counter can reach to
 957     // determine the max value which could be returned
 958     julong max_counter = (julong)ALL_64_BITS;
 959     info_ptr-&gt;max_value = (jlong)(max_counter / (freq / NANOSECS_PER_SEC));
 960   } else {
 961     // the performance counter is 64 bits and we will
 962     // be using it directly -- so no wrap in 64 bits
 963     info_ptr-&gt;max_value = ALL_64_BITS;
 964   }
 965 
 966   // using a counter, so no skipping
 967   info_ptr-&gt;may_skip_backward = false;
 968   info_ptr-&gt;may_skip_forward = false;
 969 
 970   info_ptr-&gt;kind = JVMTI_TIMER_ELAPSED;                // elapsed not CPU time
 971 }
 972 
 973 char* os::local_time_string(char *buf, size_t buflen) {
 974   SYSTEMTIME st;
 975   GetLocalTime(&amp;st);
 976   jio_snprintf(buf, buflen, &quot;%d-%02d-%02d %02d:%02d:%02d&quot;,
 977                st.wYear, st.wMonth, st.wDay, st.wHour, st.wMinute, st.wSecond);
 978   return buf;
 979 }
 980 
 981 bool os::getTimesSecs(double* process_real_time,
 982                       double* process_user_time,
 983                       double* process_system_time) {
 984   HANDLE h_process = GetCurrentProcess();
 985   FILETIME create_time, exit_time, kernel_time, user_time;
 986   BOOL result = GetProcessTimes(h_process,
 987                                 &amp;create_time,
 988                                 &amp;exit_time,
 989                                 &amp;kernel_time,
 990                                 &amp;user_time);
 991   if (result != 0) {
 992     FILETIME wt;
 993     GetSystemTimeAsFileTime(&amp;wt);
 994     jlong rtc_millis = windows_to_java_time(wt);
 995     *process_real_time = ((double) rtc_millis) / ((double) MILLIUNITS);
 996     *process_user_time =
 997       (double) jlong_from(user_time.dwHighDateTime, user_time.dwLowDateTime) / (10 * MICROUNITS);
 998     *process_system_time =
 999       (double) jlong_from(kernel_time.dwHighDateTime, kernel_time.dwLowDateTime) / (10 * MICROUNITS);
1000     return true;
1001   } else {
1002     return false;
1003   }
1004 }
1005 
1006 void os::shutdown() {
1007   // allow PerfMemory to attempt cleanup of any persistent resources
1008   perfMemory_exit();
1009 
1010   // flush buffered output, finish log files
1011   ostream_abort();
1012 
1013   // Check for abort hook
1014   abort_hook_t abort_hook = Arguments::abort_hook();
1015   if (abort_hook != NULL) {
1016     abort_hook();
1017   }
1018 }
1019 
1020 
1021 static HANDLE dumpFile = NULL;
1022 
1023 // Check if dump file can be created.
1024 void os::check_dump_limit(char* buffer, size_t buffsz) {
1025   bool status = true;
1026   if (!FLAG_IS_DEFAULT(CreateCoredumpOnCrash) &amp;&amp; !CreateCoredumpOnCrash) {
1027     jio_snprintf(buffer, buffsz, &quot;CreateCoredumpOnCrash is disabled from command line&quot;);
1028     status = false;
1029   }
1030 
1031 #ifndef ASSERT
1032   if (!os::win32::is_windows_server() &amp;&amp; FLAG_IS_DEFAULT(CreateCoredumpOnCrash)) {
1033     jio_snprintf(buffer, buffsz, &quot;Minidumps are not enabled by default on client versions of Windows&quot;);
1034     status = false;
1035   }
1036 #endif
1037 
1038   if (status) {
1039     const char* cwd = get_current_directory(NULL, 0);
1040     int pid = current_process_id();
1041     if (cwd != NULL) {
1042       jio_snprintf(buffer, buffsz, &quot;%s\\hs_err_pid%u.mdmp&quot;, cwd, pid);
1043     } else {
1044       jio_snprintf(buffer, buffsz, &quot;.\\hs_err_pid%u.mdmp&quot;, pid);
1045     }
1046 
1047     if (dumpFile == NULL &amp;&amp;
1048        (dumpFile = CreateFile(buffer, GENERIC_WRITE, 0, NULL, CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL, NULL))
1049                  == INVALID_HANDLE_VALUE) {
1050       jio_snprintf(buffer, buffsz, &quot;Failed to create minidump file (0x%x).&quot;, GetLastError());
1051       status = false;
1052     }
1053   }
1054   VMError::record_coredump_status(buffer, status);
1055 }
1056 
1057 void os::abort(bool dump_core, void* siginfo, const void* context) {
1058   EXCEPTION_POINTERS ep;
1059   MINIDUMP_EXCEPTION_INFORMATION mei;
1060   MINIDUMP_EXCEPTION_INFORMATION* pmei;
1061 
1062   HANDLE hProcess = GetCurrentProcess();
1063   DWORD processId = GetCurrentProcessId();
1064   MINIDUMP_TYPE dumpType;
1065 
1066   shutdown();
1067   if (!dump_core || dumpFile == NULL) {
1068     if (dumpFile != NULL) {
1069       CloseHandle(dumpFile);
1070     }
1071     win32::exit_process_or_thread(win32::EPT_PROCESS, 1);
1072   }
1073 
1074   dumpType = (MINIDUMP_TYPE)(MiniDumpWithFullMemory | MiniDumpWithHandleData |
1075     MiniDumpWithFullMemoryInfo | MiniDumpWithThreadInfo | MiniDumpWithUnloadedModules);
1076 
1077   if (siginfo != NULL &amp;&amp; context != NULL) {
1078     ep.ContextRecord = (PCONTEXT) context;
1079     ep.ExceptionRecord = (PEXCEPTION_RECORD) siginfo;
1080 
1081     mei.ThreadId = GetCurrentThreadId();
1082     mei.ExceptionPointers = &amp;ep;
1083     pmei = &amp;mei;
1084   } else {
1085     pmei = NULL;
1086   }
1087 
1088   // Older versions of dbghelp.dll (the one shipped with Win2003 for example) may not support all
1089   // the dump types we really want. If first call fails, lets fall back to just use MiniDumpWithFullMemory then.
1090   if (!WindowsDbgHelp::miniDumpWriteDump(hProcess, processId, dumpFile, dumpType, pmei, NULL, NULL) &amp;&amp;
1091       !WindowsDbgHelp::miniDumpWriteDump(hProcess, processId, dumpFile, (MINIDUMP_TYPE)MiniDumpWithFullMemory, pmei, NULL, NULL)) {
1092     jio_fprintf(stderr, &quot;Call to MiniDumpWriteDump() failed (Error 0x%x)\n&quot;, GetLastError());
1093   }
1094   CloseHandle(dumpFile);
1095   win32::exit_process_or_thread(win32::EPT_PROCESS, 1);
1096 }
1097 
1098 // Die immediately, no exit hook, no abort hook, no cleanup.
1099 void os::die() {
1100   win32::exit_process_or_thread(win32::EPT_PROCESS_DIE, -1);
1101 }
1102 
1103 // Directory routines copied from src/win32/native/java/io/dirent_md.c
1104 //  * dirent_md.c       1.15 00/02/02
1105 //
1106 // The declarations for DIR and struct dirent are in jvm_win32.h.
1107 
1108 // Caller must have already run dirname through JVM_NativePath, which removes
1109 // duplicate slashes and converts all instances of &#39;/&#39; into &#39;\\&#39;.
1110 
1111 DIR * os::opendir(const char *dirname) {
1112   assert(dirname != NULL, &quot;just checking&quot;);   // hotspot change
1113   DIR *dirp = (DIR *)malloc(sizeof(DIR), mtInternal);
1114   DWORD fattr;                                // hotspot change
1115   char alt_dirname[4] = { 0, 0, 0, 0 };
1116 
1117   if (dirp == 0) {
1118     errno = ENOMEM;
1119     return 0;
1120   }
1121 
1122   // Win32 accepts &quot;\&quot; in its POSIX stat(), but refuses to treat it
1123   // as a directory in FindFirstFile().  We detect this case here and
1124   // prepend the current drive name.
1125   //
1126   if (dirname[1] == &#39;\0&#39; &amp;&amp; dirname[0] == &#39;\\&#39;) {
1127     alt_dirname[0] = _getdrive() + &#39;A&#39; - 1;
1128     alt_dirname[1] = &#39;:&#39;;
1129     alt_dirname[2] = &#39;\\&#39;;
1130     alt_dirname[3] = &#39;\0&#39;;
1131     dirname = alt_dirname;
1132   }
1133 
1134   dirp-&gt;path = (char *)malloc(strlen(dirname) + 5, mtInternal);
1135   if (dirp-&gt;path == 0) {
1136     free(dirp);
1137     errno = ENOMEM;
1138     return 0;
1139   }
1140   strcpy(dirp-&gt;path, dirname);
1141 
1142   fattr = GetFileAttributes(dirp-&gt;path);
1143   if (fattr == 0xffffffff) {
1144     free(dirp-&gt;path);
1145     free(dirp);
1146     errno = ENOENT;
1147     return 0;
1148   } else if ((fattr &amp; FILE_ATTRIBUTE_DIRECTORY) == 0) {
1149     free(dirp-&gt;path);
1150     free(dirp);
1151     errno = ENOTDIR;
1152     return 0;
1153   }
1154 
1155   // Append &quot;*.*&quot;, or possibly &quot;\\*.*&quot;, to path
1156   if (dirp-&gt;path[1] == &#39;:&#39; &amp;&amp;
1157       (dirp-&gt;path[2] == &#39;\0&#39; ||
1158       (dirp-&gt;path[2] == &#39;\\&#39; &amp;&amp; dirp-&gt;path[3] == &#39;\0&#39;))) {
1159     // No &#39;\\&#39; needed for cases like &quot;Z:&quot; or &quot;Z:\&quot;
1160     strcat(dirp-&gt;path, &quot;*.*&quot;);
1161   } else {
1162     strcat(dirp-&gt;path, &quot;\\*.*&quot;);
1163   }
1164 
1165   dirp-&gt;handle = FindFirstFile(dirp-&gt;path, &amp;dirp-&gt;find_data);
1166   if (dirp-&gt;handle == INVALID_HANDLE_VALUE) {
1167     if (GetLastError() != ERROR_FILE_NOT_FOUND) {
1168       free(dirp-&gt;path);
1169       free(dirp);
1170       errno = EACCES;
1171       return 0;
1172     }
1173   }
1174   return dirp;
1175 }
1176 
1177 struct dirent * os::readdir(DIR *dirp) {
1178   assert(dirp != NULL, &quot;just checking&quot;);      // hotspot change
1179   if (dirp-&gt;handle == INVALID_HANDLE_VALUE) {
1180     return NULL;
1181   }
1182 
1183   strcpy(dirp-&gt;dirent.d_name, dirp-&gt;find_data.cFileName);
1184 
1185   if (!FindNextFile(dirp-&gt;handle, &amp;dirp-&gt;find_data)) {
1186     if (GetLastError() == ERROR_INVALID_HANDLE) {
1187       errno = EBADF;
1188       return NULL;
1189     }
1190     FindClose(dirp-&gt;handle);
1191     dirp-&gt;handle = INVALID_HANDLE_VALUE;
1192   }
1193 
1194   return &amp;dirp-&gt;dirent;
1195 }
1196 
1197 int os::closedir(DIR *dirp) {
1198   assert(dirp != NULL, &quot;just checking&quot;);      // hotspot change
1199   if (dirp-&gt;handle != INVALID_HANDLE_VALUE) {
1200     if (!FindClose(dirp-&gt;handle)) {
1201       errno = EBADF;
1202       return -1;
1203     }
1204     dirp-&gt;handle = INVALID_HANDLE_VALUE;
1205   }
1206   free(dirp-&gt;path);
1207   free(dirp);
1208   return 0;
1209 }
1210 
1211 // This must be hard coded because it&#39;s the system&#39;s temporary
1212 // directory not the java application&#39;s temp directory, ala java.io.tmpdir.
1213 const char* os::get_temp_directory() {
1214   static char path_buf[MAX_PATH];
1215   if (GetTempPath(MAX_PATH, path_buf) &gt; 0) {
1216     return path_buf;
1217   } else {
1218     path_buf[0] = &#39;\0&#39;;
1219     return path_buf;
1220   }
1221 }
1222 
1223 // Needs to be in os specific directory because windows requires another
1224 // header file &lt;direct.h&gt;
1225 const char* os::get_current_directory(char *buf, size_t buflen) {
1226   int n = static_cast&lt;int&gt;(buflen);
1227   if (buflen &gt; INT_MAX)  n = INT_MAX;
1228   return _getcwd(buf, n);
1229 }
1230 
1231 //-----------------------------------------------------------
1232 // Helper functions for fatal error handler
1233 #ifdef _WIN64
1234 // Helper routine which returns true if address in
1235 // within the NTDLL address space.
1236 //
1237 static bool _addr_in_ntdll(address addr) {
1238   HMODULE hmod;
1239   MODULEINFO minfo;
1240 
1241   hmod = GetModuleHandle(&quot;NTDLL.DLL&quot;);
1242   if (hmod == NULL) return false;
1243   if (!GetModuleInformation(GetCurrentProcess(), hmod,
1244                                           &amp;minfo, sizeof(MODULEINFO))) {
1245     return false;
1246   }
1247 
1248   if ((addr &gt;= minfo.lpBaseOfDll) &amp;&amp;
1249       (addr &lt; (address)((uintptr_t)minfo.lpBaseOfDll + (uintptr_t)minfo.SizeOfImage))) {
1250     return true;
1251   } else {
1252     return false;
1253   }
1254 }
1255 #endif
1256 
1257 struct _modinfo {
1258   address addr;
1259   char*   full_path;   // point to a char buffer
1260   int     buflen;      // size of the buffer
1261   address base_addr;
1262 };
1263 
1264 static int _locate_module_by_addr(const char * mod_fname, address base_addr,
1265                                   address top_address, void * param) {
1266   struct _modinfo *pmod = (struct _modinfo *)param;
1267   if (!pmod) return -1;
1268 
1269   if (base_addr   &lt;= pmod-&gt;addr &amp;&amp;
1270       top_address &gt; pmod-&gt;addr) {
1271     // if a buffer is provided, copy path name to the buffer
1272     if (pmod-&gt;full_path) {
1273       jio_snprintf(pmod-&gt;full_path, pmod-&gt;buflen, &quot;%s&quot;, mod_fname);
1274     }
1275     pmod-&gt;base_addr = base_addr;
1276     return 1;
1277   }
1278   return 0;
1279 }
1280 
1281 bool os::dll_address_to_library_name(address addr, char* buf,
1282                                      int buflen, int* offset) {
1283   // buf is not optional, but offset is optional
1284   assert(buf != NULL, &quot;sanity check&quot;);
1285 
1286 // NOTE: the reason we don&#39;t use SymGetModuleInfo() is it doesn&#39;t always
1287 //       return the full path to the DLL file, sometimes it returns path
1288 //       to the corresponding PDB file (debug info); sometimes it only
1289 //       returns partial path, which makes life painful.
1290 
1291   struct _modinfo mi;
1292   mi.addr      = addr;
1293   mi.full_path = buf;
1294   mi.buflen    = buflen;
1295   if (get_loaded_modules_info(_locate_module_by_addr, (void *)&amp;mi)) {
1296     // buf already contains path name
1297     if (offset) *offset = addr - mi.base_addr;
1298     return true;
1299   }
1300 
1301   buf[0] = &#39;\0&#39;;
1302   if (offset) *offset = -1;
1303   return false;
1304 }
1305 
1306 bool os::dll_address_to_function_name(address addr, char *buf,
1307                                       int buflen, int *offset,
1308                                       bool demangle) {
1309   // buf is not optional, but offset is optional
1310   assert(buf != NULL, &quot;sanity check&quot;);
1311 
1312   if (Decoder::decode(addr, buf, buflen, offset, demangle)) {
1313     return true;
1314   }
1315   if (offset != NULL)  *offset  = -1;
1316   buf[0] = &#39;\0&#39;;
1317   return false;
1318 }
1319 
1320 // save the start and end address of jvm.dll into param[0] and param[1]
1321 static int _locate_jvm_dll(const char* mod_fname, address base_addr,
1322                            address top_address, void * param) {
1323   if (!param) return -1;
1324 
1325   if (base_addr   &lt;= (address)_locate_jvm_dll &amp;&amp;
1326       top_address &gt; (address)_locate_jvm_dll) {
1327     ((address*)param)[0] = base_addr;
1328     ((address*)param)[1] = top_address;
1329     return 1;
1330   }
1331   return 0;
1332 }
1333 
1334 address vm_lib_location[2];    // start and end address of jvm.dll
1335 
1336 // check if addr is inside jvm.dll
1337 bool os::address_is_in_vm(address addr) {
1338   if (!vm_lib_location[0] || !vm_lib_location[1]) {
1339     if (!get_loaded_modules_info(_locate_jvm_dll, (void *)vm_lib_location)) {
1340       assert(false, &quot;Can&#39;t find jvm module.&quot;);
1341       return false;
1342     }
1343   }
1344 
1345   return (vm_lib_location[0] &lt;= addr) &amp;&amp; (addr &lt; vm_lib_location[1]);
1346 }
1347 
1348 // print module info; param is outputStream*
1349 static int _print_module(const char* fname, address base_address,
1350                          address top_address, void* param) {
1351   if (!param) return -1;
1352 
1353   outputStream* st = (outputStream*)param;
1354 
1355   st-&gt;print(PTR_FORMAT &quot; - &quot; PTR_FORMAT &quot; \t%s\n&quot;, base_address, top_address, fname);
1356   return 0;
1357 }
1358 
1359 // Loads .dll/.so and
1360 // in case of error it checks if .dll/.so was built for the
1361 // same architecture as Hotspot is running on
1362 void * os::dll_load(const char *name, char *ebuf, int ebuflen) {
1363   void * result = LoadLibrary(name);
1364   if (result != NULL) {
1365     // Recalculate pdb search path if a DLL was loaded successfully.
1366     SymbolEngine::recalc_search_path();
1367     return result;
1368   }
1369 
1370   DWORD errcode = GetLastError();
1371   if (errcode == ERROR_MOD_NOT_FOUND) {
1372     strncpy(ebuf, &quot;Can&#39;t find dependent libraries&quot;, ebuflen - 1);
1373     ebuf[ebuflen - 1] = &#39;\0&#39;;
1374     return NULL;
1375   }
1376 
1377   // Parsing dll below
1378   // If we can read dll-info and find that dll was built
1379   // for an architecture other than Hotspot is running in
1380   // - then print to buffer &quot;DLL was built for a different architecture&quot;
1381   // else call os::lasterror to obtain system error message
1382 
1383   // Read system error message into ebuf
1384   // It may or may not be overwritten below (in the for loop and just above)
1385   lasterror(ebuf, (size_t) ebuflen);
1386   ebuf[ebuflen - 1] = &#39;\0&#39;;
1387   int fd = ::open(name, O_RDONLY | O_BINARY, 0);
1388   if (fd &lt; 0) {
1389     return NULL;
1390   }
1391 
1392   uint32_t signature_offset;
1393   uint16_t lib_arch = 0;
1394   bool failed_to_get_lib_arch =
1395     ( // Go to position 3c in the dll
1396      (os::seek_to_file_offset(fd, IMAGE_FILE_PTR_TO_SIGNATURE) &lt; 0)
1397      ||
1398      // Read location of signature
1399      (sizeof(signature_offset) !=
1400      (os::read(fd, (void*)&amp;signature_offset, sizeof(signature_offset))))
1401      ||
1402      // Go to COFF File Header in dll
1403      // that is located after &quot;signature&quot; (4 bytes long)
1404      (os::seek_to_file_offset(fd,
1405      signature_offset + IMAGE_FILE_SIGNATURE_LENGTH) &lt; 0)
1406      ||
1407      // Read field that contains code of architecture
1408      // that dll was built for
1409      (sizeof(lib_arch) != (os::read(fd, (void*)&amp;lib_arch, sizeof(lib_arch))))
1410     );
1411 
1412   ::close(fd);
1413   if (failed_to_get_lib_arch) {
1414     // file i/o error - report os::lasterror(...) msg
1415     return NULL;
1416   }
1417 
1418   typedef struct {
1419     uint16_t arch_code;
1420     char* arch_name;
1421   } arch_t;
1422 
1423   static const arch_t arch_array[] = {
1424     {IMAGE_FILE_MACHINE_I386,      (char*)&quot;IA 32&quot;},
1425     {IMAGE_FILE_MACHINE_AMD64,     (char*)&quot;AMD 64&quot;}
1426   };
1427 #if (defined _M_AMD64)
1428   static const uint16_t running_arch = IMAGE_FILE_MACHINE_AMD64;
1429 #elif (defined _M_IX86)
1430   static const uint16_t running_arch = IMAGE_FILE_MACHINE_I386;
1431 #else
1432   #error Method os::dll_load requires that one of following \
1433          is defined :_M_AMD64 or _M_IX86
1434 #endif
1435 
1436 
1437   // Obtain a string for printf operation
1438   // lib_arch_str shall contain string what platform this .dll was built for
1439   // running_arch_str shall string contain what platform Hotspot was built for
1440   char *running_arch_str = NULL, *lib_arch_str = NULL;
1441   for (unsigned int i = 0; i &lt; ARRAY_SIZE(arch_array); i++) {
1442     if (lib_arch == arch_array[i].arch_code) {
1443       lib_arch_str = arch_array[i].arch_name;
1444     }
1445     if (running_arch == arch_array[i].arch_code) {
1446       running_arch_str = arch_array[i].arch_name;
1447     }
1448   }
1449 
1450   assert(running_arch_str,
1451          &quot;Didn&#39;t find running architecture code in arch_array&quot;);
1452 
1453   // If the architecture is right
1454   // but some other error took place - report os::lasterror(...) msg
1455   if (lib_arch == running_arch) {
1456     return NULL;
1457   }
1458 
1459   if (lib_arch_str != NULL) {
1460     ::_snprintf(ebuf, ebuflen - 1,
1461                 &quot;Can&#39;t load %s-bit .dll on a %s-bit platform&quot;,
1462                 lib_arch_str, running_arch_str);
1463   } else {
1464     // don&#39;t know what architecture this dll was build for
1465     ::_snprintf(ebuf, ebuflen - 1,
1466                 &quot;Can&#39;t load this .dll (machine code=0x%x) on a %s-bit platform&quot;,
1467                 lib_arch, running_arch_str);
1468   }
1469 
1470   return NULL;
1471 }
1472 
1473 void os::print_dll_info(outputStream *st) {
1474   st-&gt;print_cr(&quot;Dynamic libraries:&quot;);
1475   get_loaded_modules_info(_print_module, (void *)st);
1476 }
1477 
1478 int os::get_loaded_modules_info(os::LoadedModulesCallbackFunc callback, void *param) {
1479   HANDLE   hProcess;
1480 
1481 # define MAX_NUM_MODULES 128
1482   HMODULE     modules[MAX_NUM_MODULES];
1483   static char filename[MAX_PATH];
1484   int         result = 0;
1485 
1486   int pid = os::current_process_id();
1487   hProcess = OpenProcess(PROCESS_QUERY_INFORMATION | PROCESS_VM_READ,
1488                          FALSE, pid);
1489   if (hProcess == NULL) return 0;
1490 
1491   DWORD size_needed;
1492   if (!EnumProcessModules(hProcess, modules, sizeof(modules), &amp;size_needed)) {
1493     CloseHandle(hProcess);
1494     return 0;
1495   }
1496 
1497   // number of modules that are currently loaded
1498   int num_modules = size_needed / sizeof(HMODULE);
1499 
1500   for (int i = 0; i &lt; MIN2(num_modules, MAX_NUM_MODULES); i++) {
1501     // Get Full pathname:
1502     if (!GetModuleFileNameEx(hProcess, modules[i], filename, sizeof(filename))) {
1503       filename[0] = &#39;\0&#39;;
1504     }
1505 
1506     MODULEINFO modinfo;
1507     if (!GetModuleInformation(hProcess, modules[i], &amp;modinfo, sizeof(modinfo))) {
1508       modinfo.lpBaseOfDll = NULL;
1509       modinfo.SizeOfImage = 0;
1510     }
1511 
1512     // Invoke callback function
1513     result = callback(filename, (address)modinfo.lpBaseOfDll,
1514                       (address)((u8)modinfo.lpBaseOfDll + (u8)modinfo.SizeOfImage), param);
1515     if (result) break;
1516   }
1517 
1518   CloseHandle(hProcess);
1519   return result;
1520 }
1521 
1522 bool os::get_host_name(char* buf, size_t buflen) {
1523   DWORD size = (DWORD)buflen;
1524   return (GetComputerNameEx(ComputerNameDnsHostname, buf, &amp;size) == TRUE);
1525 }
1526 
1527 void os::get_summary_os_info(char* buf, size_t buflen) {
1528   stringStream sst(buf, buflen);
1529   os::win32::print_windows_version(&amp;sst);
1530   // chop off newline character
1531   char* nl = strchr(buf, &#39;\n&#39;);
1532   if (nl != NULL) *nl = &#39;\0&#39;;
1533 }
1534 
1535 int os::vsnprintf(char* buf, size_t len, const char* fmt, va_list args) {
1536 #if _MSC_VER &gt;= 1900
1537   // Starting with Visual Studio 2015, vsnprint is C99 compliant.
1538   int result = ::vsnprintf(buf, len, fmt, args);
1539   // If an encoding error occurred (result &lt; 0) then it&#39;s not clear
1540   // whether the buffer is NUL terminated, so ensure it is.
1541   if ((result &lt; 0) &amp;&amp; (len &gt; 0)) {
1542     buf[len - 1] = &#39;\0&#39;;
1543   }
1544   return result;
1545 #else
1546   // Before Visual Studio 2015, vsnprintf is not C99 compliant, so use
1547   // _vsnprintf, whose behavior seems to be *mostly* consistent across
1548   // versions.  However, when len == 0, avoid _vsnprintf too, and just
1549   // go straight to _vscprintf.  The output is going to be truncated in
1550   // that case, except in the unusual case of empty output.  More
1551   // importantly, the documentation for various versions of Visual Studio
1552   // are inconsistent about the behavior of _vsnprintf when len == 0,
1553   // including it possibly being an error.
1554   int result = -1;
1555   if (len &gt; 0) {
1556     result = _vsnprintf(buf, len, fmt, args);
1557     // If output (including NUL terminator) is truncated, the buffer
1558     // won&#39;t be NUL terminated.  Add the trailing NUL specified by C99.
1559     if ((result &lt; 0) || ((size_t)result &gt;= len)) {
1560       buf[len - 1] = &#39;\0&#39;;
1561     }
1562   }
1563   if (result &lt; 0) {
1564     result = _vscprintf(fmt, args);
1565   }
1566   return result;
1567 #endif // _MSC_VER dispatch
1568 }
1569 
1570 static inline time_t get_mtime(const char* filename) {
1571   struct stat st;
1572   int ret = os::stat(filename, &amp;st);
1573   assert(ret == 0, &quot;failed to stat() file &#39;%s&#39;: %s&quot;, filename, os::strerror(errno));
1574   return st.st_mtime;
1575 }
1576 
1577 int os::compare_file_modified_times(const char* file1, const char* file2) {
1578   time_t t1 = get_mtime(file1);
1579   time_t t2 = get_mtime(file2);
1580   return t1 - t2;
1581 }
1582 
1583 void os::print_os_info_brief(outputStream* st) {
1584   os::print_os_info(st);
1585 }
1586 
1587 void os::print_os_info(outputStream* st) {
1588 #ifdef ASSERT
1589   char buffer[1024];
1590   st-&gt;print(&quot;HostName: &quot;);
1591   if (get_host_name(buffer, sizeof(buffer))) {
1592     st-&gt;print(&quot;%s &quot;, buffer);
1593   } else {
1594     st-&gt;print(&quot;N/A &quot;);
1595   }
1596 #endif
1597   st-&gt;print(&quot;OS:&quot;);
1598   os::win32::print_windows_version(st);
1599 }
1600 
1601 void os::win32::print_windows_version(outputStream* st) {
1602   OSVERSIONINFOEX osvi;
1603   VS_FIXEDFILEINFO *file_info;
1604   TCHAR kernel32_path[MAX_PATH];
1605   UINT len, ret;
1606 
1607   // Use the GetVersionEx information to see if we&#39;re on a server or
1608   // workstation edition of Windows. Starting with Windows 8.1 we can&#39;t
1609   // trust the OS version information returned by this API.
1610   ZeroMemory(&amp;osvi, sizeof(OSVERSIONINFOEX));
1611   osvi.dwOSVersionInfoSize = sizeof(OSVERSIONINFOEX);
1612   if (!GetVersionEx((OSVERSIONINFO *)&amp;osvi)) {
1613     st-&gt;print_cr(&quot;Call to GetVersionEx failed&quot;);
1614     return;
1615   }
1616   bool is_workstation = (osvi.wProductType == VER_NT_WORKSTATION);
1617 
1618   // Get the full path to \Windows\System32\kernel32.dll and use that for
1619   // determining what version of Windows we&#39;re running on.
1620   len = MAX_PATH - (UINT)strlen(&quot;\\kernel32.dll&quot;) - 1;
1621   ret = GetSystemDirectory(kernel32_path, len);
1622   if (ret == 0 || ret &gt; len) {
1623     st-&gt;print_cr(&quot;Call to GetSystemDirectory failed&quot;);
1624     return;
1625   }
1626   strncat(kernel32_path, &quot;\\kernel32.dll&quot;, MAX_PATH - ret);
1627 
1628   DWORD version_size = GetFileVersionInfoSize(kernel32_path, NULL);
1629   if (version_size == 0) {
1630     st-&gt;print_cr(&quot;Call to GetFileVersionInfoSize failed&quot;);
1631     return;
1632   }
1633 
1634   LPTSTR version_info = (LPTSTR)os::malloc(version_size, mtInternal);
1635   if (version_info == NULL) {
1636     st-&gt;print_cr(&quot;Failed to allocate version_info&quot;);
1637     return;
1638   }
1639 
1640   if (!GetFileVersionInfo(kernel32_path, NULL, version_size, version_info)) {
1641     os::free(version_info);
1642     st-&gt;print_cr(&quot;Call to GetFileVersionInfo failed&quot;);
1643     return;
1644   }
1645 
1646   if (!VerQueryValue(version_info, TEXT(&quot;\\&quot;), (LPVOID*)&amp;file_info, &amp;len)) {
1647     os::free(version_info);
1648     st-&gt;print_cr(&quot;Call to VerQueryValue failed&quot;);
1649     return;
1650   }
1651 
1652   int major_version = HIWORD(file_info-&gt;dwProductVersionMS);
1653   int minor_version = LOWORD(file_info-&gt;dwProductVersionMS);
1654   int build_number = HIWORD(file_info-&gt;dwProductVersionLS);
1655   int build_minor = LOWORD(file_info-&gt;dwProductVersionLS);
1656   int os_vers = major_version * 1000 + minor_version;
1657   os::free(version_info);
1658 
1659   st-&gt;print(&quot; Windows &quot;);
1660   switch (os_vers) {
1661 
1662   case 6000:
1663     if (is_workstation) {
1664       st-&gt;print(&quot;Vista&quot;);
1665     } else {
1666       st-&gt;print(&quot;Server 2008&quot;);
1667     }
1668     break;
1669 
1670   case 6001:
1671     if (is_workstation) {
1672       st-&gt;print(&quot;7&quot;);
1673     } else {
1674       st-&gt;print(&quot;Server 2008 R2&quot;);
1675     }
1676     break;
1677 
1678   case 6002:
1679     if (is_workstation) {
1680       st-&gt;print(&quot;8&quot;);
1681     } else {
1682       st-&gt;print(&quot;Server 2012&quot;);
1683     }
1684     break;
1685 
1686   case 6003:
1687     if (is_workstation) {
1688       st-&gt;print(&quot;8.1&quot;);
1689     } else {
1690       st-&gt;print(&quot;Server 2012 R2&quot;);
1691     }
1692     break;
1693 
1694   case 10000:
1695     if (is_workstation) {
1696       st-&gt;print(&quot;10&quot;);
1697     } else {
1698       // distinguish Windows Server 2016 and 2019 by build number
1699       // Windows server 2019 GA 10/2018 build number is 17763
1700       if (build_number &gt; 17762) {
1701         st-&gt;print(&quot;Server 2019&quot;);
1702       } else {
1703         st-&gt;print(&quot;Server 2016&quot;);
1704       }
1705     }
1706     break;
1707 
1708   default:
1709     // Unrecognized windows, print out its major and minor versions
1710     st-&gt;print(&quot;%d.%d&quot;, major_version, minor_version);
1711     break;
1712   }
1713 
1714   // Retrieve SYSTEM_INFO from GetNativeSystemInfo call so that we could
1715   // find out whether we are running on 64 bit processor or not
1716   SYSTEM_INFO si;
1717   ZeroMemory(&amp;si, sizeof(SYSTEM_INFO));
1718   GetNativeSystemInfo(&amp;si);
1719   if (si.wProcessorArchitecture == PROCESSOR_ARCHITECTURE_AMD64) {
1720     st-&gt;print(&quot; , 64 bit&quot;);
1721   }
1722 
1723   st-&gt;print(&quot; Build %d&quot;, build_number);
1724   st-&gt;print(&quot; (%d.%d.%d.%d)&quot;, major_version, minor_version, build_number, build_minor);
1725   st-&gt;cr();
1726 }
1727 
1728 void os::pd_print_cpu_info(outputStream* st, char* buf, size_t buflen) {
1729   // Nothing to do for now.
1730 }
1731 
1732 void os::get_summary_cpu_info(char* buf, size_t buflen) {
1733   HKEY key;
1734   DWORD status = RegOpenKey(HKEY_LOCAL_MACHINE,
1735                &quot;HARDWARE\\DESCRIPTION\\System\\CentralProcessor\\0&quot;, &amp;key);
1736   if (status == ERROR_SUCCESS) {
1737     DWORD size = (DWORD)buflen;
1738     status = RegQueryValueEx(key, &quot;ProcessorNameString&quot;, NULL, NULL, (byte*)buf, &amp;size);
1739     if (status != ERROR_SUCCESS) {
1740         strncpy(buf, &quot;## __CPU__&quot;, buflen);
1741     }
1742     RegCloseKey(key);
1743   } else {
1744     // Put generic cpu info to return
1745     strncpy(buf, &quot;## __CPU__&quot;, buflen);
1746   }
1747 }
1748 
1749 void os::print_memory_info(outputStream* st) {
1750   st-&gt;print(&quot;Memory:&quot;);
1751   st-&gt;print(&quot; %dk page&quot;, os::vm_page_size()&gt;&gt;10);
1752 
1753   // Use GlobalMemoryStatusEx() because GlobalMemoryStatus() may return incorrect
1754   // value if total memory is larger than 4GB
1755   MEMORYSTATUSEX ms;
1756   ms.dwLength = sizeof(ms);
1757   int r1 = GlobalMemoryStatusEx(&amp;ms);
1758 
1759   if (r1 != 0) {
1760     st-&gt;print(&quot;, system-wide physical &quot; INT64_FORMAT &quot;M &quot;,
1761              (int64_t) ms.ullTotalPhys &gt;&gt; 20);
1762     st-&gt;print(&quot;(&quot; INT64_FORMAT &quot;M free)\n&quot;, (int64_t) ms.ullAvailPhys &gt;&gt; 20);
1763 
1764     st-&gt;print(&quot;TotalPageFile size &quot; INT64_FORMAT &quot;M &quot;,
1765              (int64_t) ms.ullTotalPageFile &gt;&gt; 20);
1766     st-&gt;print(&quot;(AvailPageFile size &quot; INT64_FORMAT &quot;M)&quot;,
1767              (int64_t) ms.ullAvailPageFile &gt;&gt; 20);
1768 
1769     // on 32bit Total/AvailVirtual are interesting (show us how close we get to 2-4 GB per process borders)
1770 #if defined(_M_IX86)
1771     st-&gt;print(&quot;, user-mode portion of virtual address-space &quot; INT64_FORMAT &quot;M &quot;,
1772              (int64_t) ms.ullTotalVirtual &gt;&gt; 20);
1773     st-&gt;print(&quot;(&quot; INT64_FORMAT &quot;M free)&quot;, (int64_t) ms.ullAvailVirtual &gt;&gt; 20);
1774 #endif
1775   } else {
1776     st-&gt;print(&quot;, GlobalMemoryStatusEx did not succeed so we miss some memory values.&quot;);
1777   }
1778 
1779   // extended memory statistics for a process
1780   PROCESS_MEMORY_COUNTERS_EX pmex;
1781   ZeroMemory(&amp;pmex, sizeof(PROCESS_MEMORY_COUNTERS_EX));
1782   pmex.cb = sizeof(pmex);
1783   int r2 = GetProcessMemoryInfo(GetCurrentProcess(), (PROCESS_MEMORY_COUNTERS*) &amp;pmex, sizeof(pmex));
1784 
1785   if (r2 != 0) {
1786     st-&gt;print(&quot;\ncurrent process WorkingSet (physical memory assigned to process): &quot; INT64_FORMAT &quot;M, &quot;,
1787              (int64_t) pmex.WorkingSetSize &gt;&gt; 20);
1788     st-&gt;print(&quot;peak: &quot; INT64_FORMAT &quot;M\n&quot;, (int64_t) pmex.PeakWorkingSetSize &gt;&gt; 20);
1789 
1790     st-&gt;print(&quot;current process commit charge (\&quot;private bytes\&quot;): &quot; INT64_FORMAT &quot;M, &quot;,
1791              (int64_t) pmex.PrivateUsage &gt;&gt; 20);
1792     st-&gt;print(&quot;peak: &quot; INT64_FORMAT &quot;M&quot;, (int64_t) pmex.PeakPagefileUsage &gt;&gt; 20);
1793   } else {
1794     st-&gt;print(&quot;\nGetProcessMemoryInfo did not succeed so we miss some memory values.&quot;);
1795   }
1796 
1797   st-&gt;cr();
1798 }
1799 
1800 bool os::signal_sent_by_kill(const void* siginfo) {
1801   // TODO: Is this possible?
1802   return false;
1803 }
1804 
1805 void os::print_siginfo(outputStream *st, const void* siginfo) {
1806   const EXCEPTION_RECORD* const er = (EXCEPTION_RECORD*)siginfo;
1807   st-&gt;print(&quot;siginfo:&quot;);
1808 
1809   char tmp[64];
1810   if (os::exception_name(er-&gt;ExceptionCode, tmp, sizeof(tmp)) == NULL) {
1811     strcpy(tmp, &quot;EXCEPTION_??&quot;);
1812   }
1813   st-&gt;print(&quot; %s (0x%x)&quot;, tmp, er-&gt;ExceptionCode);
1814 
1815   if ((er-&gt;ExceptionCode == EXCEPTION_ACCESS_VIOLATION ||
1816        er-&gt;ExceptionCode == EXCEPTION_IN_PAGE_ERROR) &amp;&amp;
1817        er-&gt;NumberParameters &gt;= 2) {
1818     switch (er-&gt;ExceptionInformation[0]) {
1819     case 0: st-&gt;print(&quot;, reading address&quot;); break;
1820     case 1: st-&gt;print(&quot;, writing address&quot;); break;
1821     case 8: st-&gt;print(&quot;, data execution prevention violation at address&quot;); break;
1822     default: st-&gt;print(&quot;, ExceptionInformation=&quot; INTPTR_FORMAT,
1823                        er-&gt;ExceptionInformation[0]);
1824     }
1825     st-&gt;print(&quot; &quot; INTPTR_FORMAT, er-&gt;ExceptionInformation[1]);
1826   } else {
1827     int num = er-&gt;NumberParameters;
1828     if (num &gt; 0) {
1829       st-&gt;print(&quot;, ExceptionInformation=&quot;);
1830       for (int i = 0; i &lt; num; i++) {
1831         st-&gt;print(INTPTR_FORMAT &quot; &quot;, er-&gt;ExceptionInformation[i]);
1832       }
1833     }
1834   }
1835   st-&gt;cr();
1836 }
1837 
1838 bool os::signal_thread(Thread* thread, int sig, const char* reason) {
1839   // TODO: Can we kill thread?
1840   return false;
1841 }
1842 
1843 void os::print_signal_handlers(outputStream* st, char* buf, size_t buflen) {
1844   // do nothing
1845 }
1846 
1847 static char saved_jvm_path[MAX_PATH] = {0};
1848 
1849 // Find the full path to the current module, jvm.dll
1850 void os::jvm_path(char *buf, jint buflen) {
1851   // Error checking.
1852   if (buflen &lt; MAX_PATH) {
1853     assert(false, &quot;must use a large-enough buffer&quot;);
1854     buf[0] = &#39;\0&#39;;
1855     return;
1856   }
1857   // Lazy resolve the path to current module.
1858   if (saved_jvm_path[0] != 0) {
1859     strcpy(buf, saved_jvm_path);
1860     return;
1861   }
1862 
1863   buf[0] = &#39;\0&#39;;
1864   if (Arguments::sun_java_launcher_is_altjvm()) {
1865     // Support for the java launcher&#39;s &#39;-XXaltjvm=&lt;path&gt;&#39; option. Check
1866     // for a JAVA_HOME environment variable and fix up the path so it
1867     // looks like jvm.dll is installed there (append a fake suffix
1868     // hotspot/jvm.dll).
1869     char* java_home_var = ::getenv(&quot;JAVA_HOME&quot;);
1870     if (java_home_var != NULL &amp;&amp; java_home_var[0] != 0 &amp;&amp;
1871         strlen(java_home_var) &lt; (size_t)buflen) {
1872       strncpy(buf, java_home_var, buflen);
1873 
1874       // determine if this is a legacy image or modules image
1875       // modules image doesn&#39;t have &quot;jre&quot; subdirectory
1876       size_t len = strlen(buf);
1877       char* jrebin_p = buf + len;
1878       jio_snprintf(jrebin_p, buflen-len, &quot;\\jre\\bin\\&quot;);
1879       if (0 != _access(buf, 0)) {
1880         jio_snprintf(jrebin_p, buflen-len, &quot;\\bin\\&quot;);
1881       }
1882       len = strlen(buf);
1883       jio_snprintf(buf + len, buflen-len, &quot;hotspot\\jvm.dll&quot;);
1884     }
1885   }
1886 
1887   if (buf[0] == &#39;\0&#39;) {
1888     GetModuleFileName(vm_lib_handle, buf, buflen);
1889   }
1890   strncpy(saved_jvm_path, buf, MAX_PATH);
1891   saved_jvm_path[MAX_PATH - 1] = &#39;\0&#39;;
1892 }
1893 
1894 
1895 void os::print_jni_name_prefix_on(outputStream* st, int args_size) {
1896 #ifndef _WIN64
1897   st-&gt;print(&quot;_&quot;);
1898 #endif
1899 }
1900 
1901 
1902 void os::print_jni_name_suffix_on(outputStream* st, int args_size) {
1903 #ifndef _WIN64
1904   st-&gt;print(&quot;@%d&quot;, args_size  * sizeof(int));
1905 #endif
1906 }
1907 
1908 // This method is a copy of JDK&#39;s sysGetLastErrorString
1909 // from src/windows/hpi/src/system_md.c
1910 
1911 size_t os::lasterror(char* buf, size_t len) {
1912   DWORD errval;
1913 
1914   if ((errval = GetLastError()) != 0) {
1915     // DOS error
1916     size_t n = (size_t)FormatMessage(
1917                                      FORMAT_MESSAGE_FROM_SYSTEM|FORMAT_MESSAGE_IGNORE_INSERTS,
1918                                      NULL,
1919                                      errval,
1920                                      0,
1921                                      buf,
1922                                      (DWORD)len,
1923                                      NULL);
1924     if (n &gt; 3) {
1925       // Drop final &#39;.&#39;, CR, LF
1926       if (buf[n - 1] == &#39;\n&#39;) n--;
1927       if (buf[n - 1] == &#39;\r&#39;) n--;
1928       if (buf[n - 1] == &#39;.&#39;) n--;
1929       buf[n] = &#39;\0&#39;;
1930     }
1931     return n;
1932   }
1933 
1934   if (errno != 0) {
1935     // C runtime error that has no corresponding DOS error code
1936     const char* s = os::strerror(errno);
1937     size_t n = strlen(s);
1938     if (n &gt;= len) n = len - 1;
1939     strncpy(buf, s, n);
1940     buf[n] = &#39;\0&#39;;
1941     return n;
1942   }
1943 
1944   return 0;
1945 }
1946 
1947 int os::get_last_error() {
1948   DWORD error = GetLastError();
1949   if (error == 0) {
1950     error = errno;
1951   }
1952   return (int)error;
1953 }
1954 
1955 // sun.misc.Signal
1956 // NOTE that this is a workaround for an apparent kernel bug where if
1957 // a signal handler for SIGBREAK is installed then that signal handler
1958 // takes priority over the console control handler for CTRL_CLOSE_EVENT.
1959 // See bug 4416763.
1960 static void (*sigbreakHandler)(int) = NULL;
1961 
1962 static void UserHandler(int sig, void *siginfo, void *context) {
1963   os::signal_notify(sig);
1964   // We need to reinstate the signal handler each time...
1965   os::signal(sig, (void*)UserHandler);
1966 }
1967 
1968 void* os::user_handler() {
1969   return (void*) UserHandler;
1970 }
1971 
1972 void* os::signal(int signal_number, void* handler) {
1973   if ((signal_number == SIGBREAK) &amp;&amp; (!ReduceSignalUsage)) {
1974     void (*oldHandler)(int) = sigbreakHandler;
1975     sigbreakHandler = (void (*)(int)) handler;
1976     return (void*) oldHandler;
1977   } else {
1978     return (void*)::signal(signal_number, (void (*)(int))handler);
1979   }
1980 }
1981 
1982 void os::signal_raise(int signal_number) {
1983   raise(signal_number);
1984 }
1985 
1986 // The Win32 C runtime library maps all console control events other than ^C
1987 // into SIGBREAK, which makes it impossible to distinguish ^BREAK from close,
1988 // logoff, and shutdown events.  We therefore install our own console handler
1989 // that raises SIGTERM for the latter cases.
1990 //
1991 static BOOL WINAPI consoleHandler(DWORD event) {
1992   switch (event) {
1993   case CTRL_C_EVENT:
1994     if (VMError::is_error_reported()) {
1995       // Ctrl-C is pressed during error reporting, likely because the error
1996       // handler fails to abort. Let VM die immediately.
1997       os::die();
1998     }
1999 
2000     os::signal_raise(SIGINT);
2001     return TRUE;
2002     break;
2003   case CTRL_BREAK_EVENT:
2004     if (sigbreakHandler != NULL) {
2005       (*sigbreakHandler)(SIGBREAK);
2006     }
2007     return TRUE;
2008     break;
2009   case CTRL_LOGOFF_EVENT: {
2010     // Don&#39;t terminate JVM if it is running in a non-interactive session,
2011     // such as a service process.
2012     USEROBJECTFLAGS flags;
2013     HANDLE handle = GetProcessWindowStation();
2014     if (handle != NULL &amp;&amp;
2015         GetUserObjectInformation(handle, UOI_FLAGS, &amp;flags,
2016         sizeof(USEROBJECTFLAGS), NULL)) {
2017       // If it is a non-interactive session, let next handler to deal
2018       // with it.
2019       if ((flags.dwFlags &amp; WSF_VISIBLE) == 0) {
2020         return FALSE;
2021       }
2022     }
2023   }
2024   case CTRL_CLOSE_EVENT:
2025   case CTRL_SHUTDOWN_EVENT:
2026     os::signal_raise(SIGTERM);
2027     return TRUE;
2028     break;
2029   default:
2030     break;
2031   }
2032   return FALSE;
2033 }
2034 
2035 // The following code is moved from os.cpp for making this
2036 // code platform specific, which it is by its very nature.
2037 
2038 // Return maximum OS signal used + 1 for internal use only
2039 // Used as exit signal for signal_thread
2040 int os::sigexitnum_pd() {
2041   return NSIG;
2042 }
2043 
2044 // a counter for each possible signal value, including signal_thread exit signal
2045 static volatile jint pending_signals[NSIG+1] = { 0 };
2046 static Semaphore* sig_sem = NULL;
2047 
2048 static void jdk_misc_signal_init() {
2049   // Initialize signal structures
2050   memset((void*)pending_signals, 0, sizeof(pending_signals));
2051 
2052   // Initialize signal semaphore
2053   sig_sem = new Semaphore();
2054 
2055   // Programs embedding the VM do not want it to attempt to receive
2056   // events like CTRL_LOGOFF_EVENT, which are used to implement the
2057   // shutdown hooks mechanism introduced in 1.3.  For example, when
2058   // the VM is run as part of a Windows NT service (i.e., a servlet
2059   // engine in a web server), the correct behavior is for any console
2060   // control handler to return FALSE, not TRUE, because the OS&#39;s
2061   // &quot;final&quot; handler for such events allows the process to continue if
2062   // it is a service (while terminating it if it is not a service).
2063   // To make this behavior uniform and the mechanism simpler, we
2064   // completely disable the VM&#39;s usage of these console events if -Xrs
2065   // (=ReduceSignalUsage) is specified.  This means, for example, that
2066   // the CTRL-BREAK thread dump mechanism is also disabled in this
2067   // case.  See bugs 4323062, 4345157, and related bugs.
2068 
2069   // Add a CTRL-C handler
2070   SetConsoleCtrlHandler(consoleHandler, TRUE);
2071 }
2072 
2073 void os::signal_notify(int sig) {
2074   if (sig_sem != NULL) {
2075     Atomic::inc(&amp;pending_signals[sig]);
2076     sig_sem-&gt;signal();
2077   } else {
2078     // Signal thread is not created with ReduceSignalUsage and jdk_misc_signal_init
2079     // initialization isn&#39;t called.
2080     assert(ReduceSignalUsage, &quot;signal semaphore should be created&quot;);
2081   }
2082 }
2083 
2084 static int check_pending_signals() {
2085   while (true) {
2086     for (int i = 0; i &lt; NSIG + 1; i++) {
2087       jint n = pending_signals[i];
2088       if (n &gt; 0 &amp;&amp; n == Atomic::cmpxchg(n - 1, &amp;pending_signals[i], n)) {
2089         return i;
2090       }
2091     }
2092     JavaThread *thread = JavaThread::current();
2093 
2094     ThreadBlockInVM tbivm(thread);
2095 
2096     bool threadIsSuspended;
2097     do {
2098       thread-&gt;set_suspend_equivalent();
2099       // cleared by handle_special_suspend_equivalent_condition() or java_suspend_self()
2100       sig_sem-&gt;wait();
2101 
2102       // were we externally suspended while we were waiting?
2103       threadIsSuspended = thread-&gt;handle_special_suspend_equivalent_condition();
2104       if (threadIsSuspended) {
2105         // The semaphore has been incremented, but while we were waiting
2106         // another thread suspended us. We don&#39;t want to continue running
2107         // while suspended because that would surprise the thread that
2108         // suspended us.
2109         sig_sem-&gt;signal();
2110 
2111         thread-&gt;java_suspend_self();
2112       }
2113     } while (threadIsSuspended);
2114   }
2115 }
2116 
2117 int os::signal_wait() {
2118   return check_pending_signals();
2119 }
2120 
2121 // Implicit OS exception handling
2122 
2123 LONG Handle_Exception(struct _EXCEPTION_POINTERS* exceptionInfo,
2124                       address handler) {
2125   JavaThread* thread = (JavaThread*) Thread::current_or_null();
2126   // Save pc in thread
2127 #ifdef _M_AMD64
2128   // Do not blow up if no thread info available.
2129   if (thread) {
2130     thread-&gt;set_saved_exception_pc((address)(DWORD_PTR)exceptionInfo-&gt;ContextRecord-&gt;Rip);
2131   }
2132   // Set pc to handler
2133   exceptionInfo-&gt;ContextRecord-&gt;Rip = (DWORD64)handler;
2134 #else
2135   // Do not blow up if no thread info available.
2136   if (thread) {
2137     thread-&gt;set_saved_exception_pc((address)(DWORD_PTR)exceptionInfo-&gt;ContextRecord-&gt;Eip);
2138   }
2139   // Set pc to handler
2140   exceptionInfo-&gt;ContextRecord-&gt;Eip = (DWORD)(DWORD_PTR)handler;
2141 #endif
2142 
2143   // Continue the execution
2144   return EXCEPTION_CONTINUE_EXECUTION;
2145 }
2146 
2147 
2148 // Used for PostMortemDump
2149 extern &quot;C&quot; void safepoints();
2150 extern &quot;C&quot; void find(int x);
2151 extern &quot;C&quot; void events();
2152 
2153 // According to Windows API documentation, an illegal instruction sequence should generate
2154 // the 0xC000001C exception code. However, real world experience shows that occasionnaly
2155 // the execution of an illegal instruction can generate the exception code 0xC000001E. This
2156 // seems to be an undocumented feature of Win NT 4.0 (and probably other Windows systems).
2157 
2158 #define EXCEPTION_ILLEGAL_INSTRUCTION_2 0xC000001E
2159 
2160 // From &quot;Execution Protection in the Windows Operating System&quot; draft 0.35
2161 // Once a system header becomes available, the &quot;real&quot; define should be
2162 // included or copied here.
2163 #define EXCEPTION_INFO_EXEC_VIOLATION 0x08
2164 
2165 // Windows Vista/2008 heap corruption check
2166 #define EXCEPTION_HEAP_CORRUPTION        0xC0000374
2167 
2168 // All Visual C++ exceptions thrown from code generated by the Microsoft Visual
2169 // C++ compiler contain this error code. Because this is a compiler-generated
2170 // error, the code is not listed in the Win32 API header files.
2171 // The code is actually a cryptic mnemonic device, with the initial &quot;E&quot;
2172 // standing for &quot;exception&quot; and the final 3 bytes (0x6D7363) representing the
2173 // ASCII values of &quot;msc&quot;.
2174 
2175 #define EXCEPTION_UNCAUGHT_CXX_EXCEPTION    0xE06D7363
2176 
2177 #define def_excpt(val) { #val, (val) }
2178 
2179 static const struct { char* name; uint number; } exceptlabels[] = {
2180     def_excpt(EXCEPTION_ACCESS_VIOLATION),
2181     def_excpt(EXCEPTION_DATATYPE_MISALIGNMENT),
2182     def_excpt(EXCEPTION_BREAKPOINT),
2183     def_excpt(EXCEPTION_SINGLE_STEP),
2184     def_excpt(EXCEPTION_ARRAY_BOUNDS_EXCEEDED),
2185     def_excpt(EXCEPTION_FLT_DENORMAL_OPERAND),
2186     def_excpt(EXCEPTION_FLT_DIVIDE_BY_ZERO),
2187     def_excpt(EXCEPTION_FLT_INEXACT_RESULT),
2188     def_excpt(EXCEPTION_FLT_INVALID_OPERATION),
2189     def_excpt(EXCEPTION_FLT_OVERFLOW),
2190     def_excpt(EXCEPTION_FLT_STACK_CHECK),
2191     def_excpt(EXCEPTION_FLT_UNDERFLOW),
2192     def_excpt(EXCEPTION_INT_DIVIDE_BY_ZERO),
2193     def_excpt(EXCEPTION_INT_OVERFLOW),
2194     def_excpt(EXCEPTION_PRIV_INSTRUCTION),
2195     def_excpt(EXCEPTION_IN_PAGE_ERROR),
2196     def_excpt(EXCEPTION_ILLEGAL_INSTRUCTION),
2197     def_excpt(EXCEPTION_ILLEGAL_INSTRUCTION_2),
2198     def_excpt(EXCEPTION_NONCONTINUABLE_EXCEPTION),
2199     def_excpt(EXCEPTION_STACK_OVERFLOW),
2200     def_excpt(EXCEPTION_INVALID_DISPOSITION),
2201     def_excpt(EXCEPTION_GUARD_PAGE),
2202     def_excpt(EXCEPTION_INVALID_HANDLE),
2203     def_excpt(EXCEPTION_UNCAUGHT_CXX_EXCEPTION),
2204     def_excpt(EXCEPTION_HEAP_CORRUPTION)
2205 };
2206 
2207 #undef def_excpt
2208 
2209 const char* os::exception_name(int exception_code, char *buf, size_t size) {
2210   uint code = static_cast&lt;uint&gt;(exception_code);
2211   for (uint i = 0; i &lt; ARRAY_SIZE(exceptlabels); ++i) {
2212     if (exceptlabels[i].number == code) {
2213       jio_snprintf(buf, size, &quot;%s&quot;, exceptlabels[i].name);
2214       return buf;
2215     }
2216   }
2217 
2218   return NULL;
2219 }
2220 
2221 //-----------------------------------------------------------------------------
2222 LONG Handle_IDiv_Exception(struct _EXCEPTION_POINTERS* exceptionInfo) {
2223   // handle exception caused by idiv; should only happen for -MinInt/-1
2224   // (division by zero is handled explicitly)
2225 #ifdef  _M_AMD64
2226   PCONTEXT ctx = exceptionInfo-&gt;ContextRecord;
2227   address pc = (address)ctx-&gt;Rip;
2228   assert(pc[0] &gt;= Assembler::REX &amp;&amp; pc[0] &lt;= Assembler::REX_WRXB &amp;&amp; pc[1] == 0xF7 || pc[0] == 0xF7, &quot;not an idiv opcode&quot;);
2229   assert(pc[0] &gt;= Assembler::REX &amp;&amp; pc[0] &lt;= Assembler::REX_WRXB &amp;&amp; (pc[2] &amp; ~0x7) == 0xF8 || (pc[1] &amp; ~0x7) == 0xF8, &quot;cannot handle non-register operands&quot;);
2230   if (pc[0] == 0xF7) {
2231     // set correct result values and continue after idiv instruction
2232     ctx-&gt;Rip = (DWORD64)pc + 2;        // idiv reg, reg  is 2 bytes
2233   } else {
2234     ctx-&gt;Rip = (DWORD64)pc + 3;        // REX idiv reg, reg  is 3 bytes
2235   }
2236   // Do not set ctx-&gt;Rax as it already contains the correct value (either 32 or 64 bit, depending on the operation)
2237   // this is the case because the exception only happens for -MinValue/-1 and -MinValue is always in rax because of the
2238   // idiv opcode (0xF7).
2239   ctx-&gt;Rdx = (DWORD)0;             // remainder
2240   // Continue the execution
2241 #else
2242   PCONTEXT ctx = exceptionInfo-&gt;ContextRecord;
2243   address pc = (address)ctx-&gt;Eip;
2244   assert(pc[0] == 0xF7, &quot;not an idiv opcode&quot;);
2245   assert((pc[1] &amp; ~0x7) == 0xF8, &quot;cannot handle non-register operands&quot;);
2246   assert(ctx-&gt;Eax == min_jint, &quot;unexpected idiv exception&quot;);
2247   // set correct result values and continue after idiv instruction
2248   ctx-&gt;Eip = (DWORD)pc + 2;        // idiv reg, reg  is 2 bytes
2249   ctx-&gt;Eax = (DWORD)min_jint;      // result
2250   ctx-&gt;Edx = (DWORD)0;             // remainder
2251   // Continue the execution
2252 #endif
2253   return EXCEPTION_CONTINUE_EXECUTION;
2254 }
2255 
2256 //-----------------------------------------------------------------------------
2257 LONG WINAPI Handle_FLT_Exception(struct _EXCEPTION_POINTERS* exceptionInfo) {
2258   PCONTEXT ctx = exceptionInfo-&gt;ContextRecord;
2259 #ifndef  _WIN64
2260   // handle exception caused by native method modifying control word
2261   DWORD exception_code = exceptionInfo-&gt;ExceptionRecord-&gt;ExceptionCode;
2262 
2263   switch (exception_code) {
2264   case EXCEPTION_FLT_DENORMAL_OPERAND:
2265   case EXCEPTION_FLT_DIVIDE_BY_ZERO:
2266   case EXCEPTION_FLT_INEXACT_RESULT:
2267   case EXCEPTION_FLT_INVALID_OPERATION:
2268   case EXCEPTION_FLT_OVERFLOW:
2269   case EXCEPTION_FLT_STACK_CHECK:
2270   case EXCEPTION_FLT_UNDERFLOW:
2271     jint fp_control_word = (* (jint*) StubRoutines::addr_fpu_cntrl_wrd_std());
2272     if (fp_control_word != ctx-&gt;FloatSave.ControlWord) {
2273       // Restore FPCW and mask out FLT exceptions
2274       ctx-&gt;FloatSave.ControlWord = fp_control_word | 0xffffffc0;
2275       // Mask out pending FLT exceptions
2276       ctx-&gt;FloatSave.StatusWord &amp;=  0xffffff00;
2277       return EXCEPTION_CONTINUE_EXECUTION;
2278     }
2279   }
2280 
2281   if (prev_uef_handler != NULL) {
2282     // We didn&#39;t handle this exception so pass it to the previous
2283     // UnhandledExceptionFilter.
2284     return (prev_uef_handler)(exceptionInfo);
2285   }
2286 #else // !_WIN64
2287   // On Windows, the mxcsr control bits are non-volatile across calls
2288   // See also CR 6192333
2289   //
2290   jint MxCsr = INITIAL_MXCSR;
2291   // we can&#39;t use StubRoutines::addr_mxcsr_std()
2292   // because in Win64 mxcsr is not saved there
2293   if (MxCsr != ctx-&gt;MxCsr) {
2294     ctx-&gt;MxCsr = MxCsr;
2295     return EXCEPTION_CONTINUE_EXECUTION;
2296   }
2297 #endif // !_WIN64
2298 
2299   return EXCEPTION_CONTINUE_SEARCH;
2300 }
2301 
2302 static inline void report_error(Thread* t, DWORD exception_code,
2303                                 address addr, void* siginfo, void* context) {
2304   VMError::report_and_die(t, exception_code, addr, siginfo, context);
2305 
2306   // If UseOsErrorReporting, this will return here and save the error file
2307   // somewhere where we can find it in the minidump.
2308 }
2309 
2310 bool os::win32::get_frame_at_stack_banging_point(JavaThread* thread,
2311         struct _EXCEPTION_POINTERS* exceptionInfo, address pc, frame* fr) {
2312   PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2313   address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2314   if (Interpreter::contains(pc)) {
2315     *fr = os::fetch_frame_from_context((void*)exceptionInfo-&gt;ContextRecord);
2316     if (!fr-&gt;is_first_java_frame()) {
2317       // get_frame_at_stack_banging_point() is only called when we
2318       // have well defined stacks so java_sender() calls do not need
2319       // to assert safe_for_sender() first.
2320       *fr = fr-&gt;java_sender();
2321     }
2322   } else {
2323     // more complex code with compiled code
2324     assert(!Interpreter::contains(pc), &quot;Interpreted methods should have been handled above&quot;);
2325     CodeBlob* cb = CodeCache::find_blob(pc);
2326     if (cb == NULL || !cb-&gt;is_nmethod() || cb-&gt;is_frame_complete_at(pc)) {
2327       // Not sure where the pc points to, fallback to default
2328       // stack overflow handling
2329       return false;
2330     } else {
2331       *fr = os::fetch_frame_from_context((void*)exceptionInfo-&gt;ContextRecord);
2332       // in compiled code, the stack banging is performed just after the return pc
2333       // has been pushed on the stack
2334       *fr = frame(fr-&gt;sp() + 1, fr-&gt;fp(), (address)*(fr-&gt;sp()));
2335       if (!fr-&gt;is_java_frame()) {
2336         // See java_sender() comment above.
2337         *fr = fr-&gt;java_sender();
2338       }
2339     }
2340   }
2341   assert(fr-&gt;is_java_frame(), &quot;Safety check&quot;);
2342   return true;
2343 }
2344 
2345 #if INCLUDE_AOT
2346 LONG WINAPI topLevelVectoredExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo) {
2347   PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2348   address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2349   address pc = (address) exceptionInfo-&gt;ContextRecord-&gt;Rip;
2350 
2351   // Handle the case where we get an implicit exception in AOT generated
2352   // code.  AOT DLL&#39;s loaded are not registered for structured exceptions.
2353   // If the exception occurred in the codeCache or AOT code, pass control
2354   // to our normal exception handler.
2355   CodeBlob* cb = CodeCache::find_blob(pc);
2356   if (cb != NULL) {
2357     return topLevelExceptionFilter(exceptionInfo);
2358   }
2359 
2360   return EXCEPTION_CONTINUE_SEARCH;
2361 }
2362 #endif
2363 
2364 //-----------------------------------------------------------------------------
2365 LONG WINAPI topLevelExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo) {
2366   if (InterceptOSException) return EXCEPTION_CONTINUE_SEARCH;
2367   DWORD exception_code = exceptionInfo-&gt;ExceptionRecord-&gt;ExceptionCode;
2368 #ifdef _M_AMD64
2369   address pc = (address) exceptionInfo-&gt;ContextRecord-&gt;Rip;
2370 #else
2371   address pc = (address) exceptionInfo-&gt;ContextRecord-&gt;Eip;
2372 #endif
2373   Thread* t = Thread::current_or_null_safe();
2374 
2375   // Handle SafeFetch32 and SafeFetchN exceptions.
2376   if (StubRoutines::is_safefetch_fault(pc)) {
2377     return Handle_Exception(exceptionInfo, StubRoutines::continuation_for_safefetch_fault(pc));
2378   }
2379 
2380 #ifndef _WIN64
2381   // Execution protection violation - win32 running on AMD64 only
2382   // Handled first to avoid misdiagnosis as a &quot;normal&quot; access violation;
2383   // This is safe to do because we have a new/unique ExceptionInformation
2384   // code for this condition.
2385   if (exception_code == EXCEPTION_ACCESS_VIOLATION) {
2386     PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2387     int exception_subcode = (int) exceptionRecord-&gt;ExceptionInformation[0];
2388     address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2389 
2390     if (exception_subcode == EXCEPTION_INFO_EXEC_VIOLATION) {
2391       int page_size = os::vm_page_size();
2392 
2393       // Make sure the pc and the faulting address are sane.
2394       //
2395       // If an instruction spans a page boundary, and the page containing
2396       // the beginning of the instruction is executable but the following
2397       // page is not, the pc and the faulting address might be slightly
2398       // different - we still want to unguard the 2nd page in this case.
2399       //
2400       // 15 bytes seems to be a (very) safe value for max instruction size.
2401       bool pc_is_near_addr =
2402         (pointer_delta((void*) addr, (void*) pc, sizeof(char)) &lt; 15);
2403       bool instr_spans_page_boundary =
2404         (align_down((intptr_t) pc ^ (intptr_t) addr,
2405                          (intptr_t) page_size) &gt; 0);
2406 
2407       if (pc == addr || (pc_is_near_addr &amp;&amp; instr_spans_page_boundary)) {
2408         static volatile address last_addr =
2409           (address) os::non_memory_address_word();
2410 
2411         // In conservative mode, don&#39;t unguard unless the address is in the VM
2412         if (UnguardOnExecutionViolation &gt; 0 &amp;&amp; addr != last_addr &amp;&amp;
2413             (UnguardOnExecutionViolation &gt; 1 || os::address_is_in_vm(addr))) {
2414 
2415           // Set memory to RWX and retry
2416           address page_start = align_down(addr, page_size);
2417           bool res = os::protect_memory((char*) page_start, page_size,
2418                                         os::MEM_PROT_RWX);
2419 
2420           log_debug(os)(&quot;Execution protection violation &quot;
2421                         &quot;at &quot; INTPTR_FORMAT
2422                         &quot;, unguarding &quot; INTPTR_FORMAT &quot;: %s&quot;, p2i(addr),
2423                         p2i(page_start), (res ? &quot;success&quot; : os::strerror(errno)));
2424 
2425           // Set last_addr so if we fault again at the same address, we don&#39;t
2426           // end up in an endless loop.
2427           //
2428           // There are two potential complications here.  Two threads trapping
2429           // at the same address at the same time could cause one of the
2430           // threads to think it already unguarded, and abort the VM.  Likely
2431           // very rare.
2432           //
2433           // The other race involves two threads alternately trapping at
2434           // different addresses and failing to unguard the page, resulting in
2435           // an endless loop.  This condition is probably even more unlikely
2436           // than the first.
2437           //
2438           // Although both cases could be avoided by using locks or thread
2439           // local last_addr, these solutions are unnecessary complication:
2440           // this handler is a best-effort safety net, not a complete solution.
2441           // It is disabled by default and should only be used as a workaround
2442           // in case we missed any no-execute-unsafe VM code.
2443 
2444           last_addr = addr;
2445 
2446           return EXCEPTION_CONTINUE_EXECUTION;
2447         }
2448       }
2449 
2450       // Last unguard failed or not unguarding
2451       tty-&gt;print_raw_cr(&quot;Execution protection violation&quot;);
2452       report_error(t, exception_code, addr, exceptionInfo-&gt;ExceptionRecord,
2453                    exceptionInfo-&gt;ContextRecord);
2454       return EXCEPTION_CONTINUE_SEARCH;
2455     }
2456   }
2457 #endif // _WIN64
2458 
2459   if ((exception_code == EXCEPTION_ACCESS_VIOLATION) &amp;&amp;
2460       VM_Version::is_cpuinfo_segv_addr(pc)) {
2461     // Verify that OS save/restore AVX registers.
2462     return Handle_Exception(exceptionInfo, VM_Version::cpuinfo_cont_addr());
2463   }
2464 
2465   if (t != NULL &amp;&amp; t-&gt;is_Java_thread()) {
2466     JavaThread* thread = (JavaThread*) t;
2467     bool in_java = thread-&gt;thread_state() == _thread_in_Java;
2468 
2469     // Handle potential stack overflows up front.
2470     if (exception_code == EXCEPTION_STACK_OVERFLOW) {
2471       if (thread-&gt;stack_guards_enabled()) {
2472         if (in_java) {
2473           frame fr;
2474           PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2475           address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2476           if (os::win32::get_frame_at_stack_banging_point(thread, exceptionInfo, pc, &amp;fr)) {
2477             assert(fr.is_java_frame(), &quot;Must be a Java frame&quot;);
2478             SharedRuntime::look_for_reserved_stack_annotated_method(thread, fr);
2479           }
2480         }
2481         // Yellow zone violation.  The o/s has unprotected the first yellow
2482         // zone page for us.  Note:  must call disable_stack_yellow_zone to
2483         // update the enabled status, even if the zone contains only one page.
2484         assert(thread-&gt;thread_state() != _thread_in_vm, &quot;Undersized StackShadowPages&quot;);
2485         thread-&gt;disable_stack_yellow_reserved_zone();
2486         // If not in java code, return and hope for the best.
2487         return in_java
2488             ? Handle_Exception(exceptionInfo, SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW))
2489             :  EXCEPTION_CONTINUE_EXECUTION;
2490       } else {
2491         // Fatal red zone violation.
2492         thread-&gt;disable_stack_red_zone();
2493         tty-&gt;print_raw_cr(&quot;An unrecoverable stack overflow has occurred.&quot;);
2494         report_error(t, exception_code, pc, exceptionInfo-&gt;ExceptionRecord,
2495                       exceptionInfo-&gt;ContextRecord);
2496         return EXCEPTION_CONTINUE_SEARCH;
2497       }
2498     } else if (exception_code == EXCEPTION_ACCESS_VIOLATION) {
2499       // Either stack overflow or null pointer exception.
2500       if (in_java) {
2501         PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2502         address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2503         address stack_end = thread-&gt;stack_end();
2504         if (addr &lt; stack_end &amp;&amp; addr &gt;= stack_end - os::vm_page_size()) {
2505           // Stack overflow.
2506           assert(!os::uses_stack_guard_pages(),
2507                  &quot;should be caught by red zone code above.&quot;);
2508           return Handle_Exception(exceptionInfo,
2509                                   SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::STACK_OVERFLOW));
2510         }
2511         // Check for safepoint polling and implicit null
2512         // We only expect null pointers in the stubs (vtable)
2513         // the rest are checked explicitly now.
2514         CodeBlob* cb = CodeCache::find_blob(pc);
2515         if (cb != NULL) {
2516           if (os::is_poll_address(addr)) {
2517             address stub = SharedRuntime::get_poll_stub(pc);
2518             return Handle_Exception(exceptionInfo, stub);
2519           }
2520         }
2521         {
2522 #ifdef _WIN64
2523           // If it&#39;s a legal stack address map the entire region in
2524           //
2525           PEXCEPTION_RECORD exceptionRecord = exceptionInfo-&gt;ExceptionRecord;
2526           address addr = (address) exceptionRecord-&gt;ExceptionInformation[1];
2527           if (addr &gt; thread-&gt;stack_reserved_zone_base() &amp;&amp; addr &lt; thread-&gt;stack_base()) {
2528             addr = (address)((uintptr_t)addr &amp;
2529                              (~((uintptr_t)os::vm_page_size() - (uintptr_t)1)));
2530             os::commit_memory((char *)addr, thread-&gt;stack_base() - addr,
2531                               !ExecMem);
2532             return EXCEPTION_CONTINUE_EXECUTION;
2533           } else
2534 #endif
2535           {
2536             // Null pointer exception.
2537             if (MacroAssembler::uses_implicit_null_check((void*)addr)) {
2538               address stub = SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_NULL);
2539               if (stub != NULL) return Handle_Exception(exceptionInfo, stub);
2540             }
2541             report_error(t, exception_code, pc, exceptionInfo-&gt;ExceptionRecord,
2542                          exceptionInfo-&gt;ContextRecord);
2543             return EXCEPTION_CONTINUE_SEARCH;
2544           }
2545         }
2546       }
2547 
2548 #ifdef _WIN64
2549       // Special care for fast JNI field accessors.
2550       // jni_fast_Get&lt;Primitive&gt;Field can trap at certain pc&#39;s if a GC kicks
2551       // in and the heap gets shrunk before the field access.
2552       if (exception_code == EXCEPTION_ACCESS_VIOLATION) {
2553         address addr = JNI_FastGetField::find_slowcase_pc(pc);
2554         if (addr != (address)-1) {
2555           return Handle_Exception(exceptionInfo, addr);
2556         }
2557       }
2558 #endif
2559 
2560       // Stack overflow or null pointer exception in native code.
2561       report_error(t, exception_code, pc, exceptionInfo-&gt;ExceptionRecord,
2562                    exceptionInfo-&gt;ContextRecord);
2563       return EXCEPTION_CONTINUE_SEARCH;
2564     } // /EXCEPTION_ACCESS_VIOLATION
2565     // - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
2566 
2567     if (exception_code == EXCEPTION_IN_PAGE_ERROR) {
2568       CompiledMethod* nm = NULL;
2569       JavaThread* thread = (JavaThread*)t;
2570       if (in_java) {
2571         CodeBlob* cb = CodeCache::find_blob_unsafe(pc);
2572         nm = (cb != NULL) ? cb-&gt;as_compiled_method_or_null() : NULL;
2573       }
2574       if ((thread-&gt;thread_state() == _thread_in_vm &amp;&amp;
2575           thread-&gt;doing_unsafe_access()) ||
2576           (nm != NULL &amp;&amp; nm-&gt;has_unsafe_access())) {
2577         return Handle_Exception(exceptionInfo, SharedRuntime::handle_unsafe_access(thread, (address)Assembler::locate_next_instruction(pc)));
2578       }
2579     }
2580 
2581     if (in_java) {
2582       switch (exception_code) {
2583       case EXCEPTION_INT_DIVIDE_BY_ZERO:
2584         return Handle_Exception(exceptionInfo, SharedRuntime::continuation_for_implicit_exception(thread, pc, SharedRuntime::IMPLICIT_DIVIDE_BY_ZERO));
2585 
2586       case EXCEPTION_INT_OVERFLOW:
2587         return Handle_IDiv_Exception(exceptionInfo);
2588 
2589       } // switch
2590     }
2591     if (((thread-&gt;thread_state() == _thread_in_Java) ||
2592          (thread-&gt;thread_state() == _thread_in_native)) &amp;&amp;
2593          exception_code != EXCEPTION_UNCAUGHT_CXX_EXCEPTION) {
2594       LONG result=Handle_FLT_Exception(exceptionInfo);
2595       if (result==EXCEPTION_CONTINUE_EXECUTION) return result;
2596     }
2597   }
2598 
2599   if (exception_code != EXCEPTION_BREAKPOINT) {
2600     report_error(t, exception_code, pc, exceptionInfo-&gt;ExceptionRecord,
2601                  exceptionInfo-&gt;ContextRecord);
2602   }
2603   return EXCEPTION_CONTINUE_SEARCH;
2604 }
2605 
2606 #ifndef _WIN64
2607 // Special care for fast JNI accessors.
2608 // jni_fast_Get&lt;Primitive&gt;Field can trap at certain pc&#39;s if a GC kicks in and
2609 // the heap gets shrunk before the field access.
2610 // Need to install our own structured exception handler since native code may
2611 // install its own.
2612 LONG WINAPI fastJNIAccessorExceptionFilter(struct _EXCEPTION_POINTERS* exceptionInfo) {
2613   DWORD exception_code = exceptionInfo-&gt;ExceptionRecord-&gt;ExceptionCode;
2614   if (exception_code == EXCEPTION_ACCESS_VIOLATION) {
2615     address pc = (address) exceptionInfo-&gt;ContextRecord-&gt;Eip;
2616     address addr = JNI_FastGetField::find_slowcase_pc(pc);
2617     if (addr != (address)-1) {
2618       return Handle_Exception(exceptionInfo, addr);
2619     }
2620   }
2621   return EXCEPTION_CONTINUE_SEARCH;
2622 }
2623 
2624 #define DEFINE_FAST_GETFIELD(Return, Fieldname, Result)                     \
2625   Return JNICALL jni_fast_Get##Result##Field_wrapper(JNIEnv *env,           \
2626                                                      jobject obj,           \
2627                                                      jfieldID fieldID) {    \
2628     __try {                                                                 \
2629       return (*JNI_FastGetField::jni_fast_Get##Result##Field_fp)(env,       \
2630                                                                  obj,       \
2631                                                                  fieldID);  \
2632     } __except(fastJNIAccessorExceptionFilter((_EXCEPTION_POINTERS*)        \
2633                                               _exception_info())) {         \
2634     }                                                                       \
2635     return 0;                                                               \
2636   }
2637 
2638 DEFINE_FAST_GETFIELD(jboolean, bool,   Boolean)
2639 DEFINE_FAST_GETFIELD(jbyte,    byte,   Byte)
2640 DEFINE_FAST_GETFIELD(jchar,    char,   Char)
2641 DEFINE_FAST_GETFIELD(jshort,   short,  Short)
2642 DEFINE_FAST_GETFIELD(jint,     int,    Int)
2643 DEFINE_FAST_GETFIELD(jlong,    long,   Long)
2644 DEFINE_FAST_GETFIELD(jfloat,   float,  Float)
2645 DEFINE_FAST_GETFIELD(jdouble,  double, Double)
2646 
2647 address os::win32::fast_jni_accessor_wrapper(BasicType type) {
2648   switch (type) {
2649   case T_BOOLEAN: return (address)jni_fast_GetBooleanField_wrapper;
2650   case T_BYTE:    return (address)jni_fast_GetByteField_wrapper;
2651   case T_CHAR:    return (address)jni_fast_GetCharField_wrapper;
2652   case T_SHORT:   return (address)jni_fast_GetShortField_wrapper;
2653   case T_INT:     return (address)jni_fast_GetIntField_wrapper;
2654   case T_LONG:    return (address)jni_fast_GetLongField_wrapper;
2655   case T_FLOAT:   return (address)jni_fast_GetFloatField_wrapper;
2656   case T_DOUBLE:  return (address)jni_fast_GetDoubleField_wrapper;
2657   default:        ShouldNotReachHere();
2658   }
2659   return (address)-1;
2660 }
2661 #endif
2662 
2663 // Virtual Memory
2664 
2665 int os::vm_page_size() { return os::win32::vm_page_size(); }
2666 int os::vm_allocation_granularity() {
2667   return os::win32::vm_allocation_granularity();
2668 }
2669 
2670 // Windows large page support is available on Windows 2003. In order to use
2671 // large page memory, the administrator must first assign additional privilege
2672 // to the user:
2673 //   + select Control Panel -&gt; Administrative Tools -&gt; Local Security Policy
2674 //   + select Local Policies -&gt; User Rights Assignment
2675 //   + double click &quot;Lock pages in memory&quot;, add users and/or groups
2676 //   + reboot
2677 // Note the above steps are needed for administrator as well, as administrators
2678 // by default do not have the privilege to lock pages in memory.
2679 //
2680 // Note about Windows 2003: although the API supports committing large page
2681 // memory on a page-by-page basis and VirtualAlloc() returns success under this
2682 // scenario, I found through experiment it only uses large page if the entire
2683 // memory region is reserved and committed in a single VirtualAlloc() call.
2684 // This makes Windows large page support more or less like Solaris ISM, in
2685 // that the entire heap must be committed upfront. This probably will change
2686 // in the future, if so the code below needs to be revisited.
2687 
2688 #ifndef MEM_LARGE_PAGES
2689   #define MEM_LARGE_PAGES 0x20000000
2690 #endif
2691 
2692 static HANDLE    _hProcess;
2693 static HANDLE    _hToken;
2694 
2695 // Container for NUMA node list info
2696 class NUMANodeListHolder {
2697  private:
2698   int *_numa_used_node_list;  // allocated below
2699   int _numa_used_node_count;
2700 
2701   void free_node_list() {
2702     if (_numa_used_node_list != NULL) {
2703       FREE_C_HEAP_ARRAY(int, _numa_used_node_list);
2704     }
2705   }
2706 
2707  public:
2708   NUMANodeListHolder() {
2709     _numa_used_node_count = 0;
2710     _numa_used_node_list = NULL;
2711     // do rest of initialization in build routine (after function pointers are set up)
2712   }
2713 
2714   ~NUMANodeListHolder() {
2715     free_node_list();
2716   }
2717 
2718   bool build() {
2719     DWORD_PTR proc_aff_mask;
2720     DWORD_PTR sys_aff_mask;
2721     if (!GetProcessAffinityMask(GetCurrentProcess(), &amp;proc_aff_mask, &amp;sys_aff_mask)) return false;
2722     ULONG highest_node_number;
2723     if (!GetNumaHighestNodeNumber(&amp;highest_node_number)) return false;
2724     free_node_list();
2725     _numa_used_node_list = NEW_C_HEAP_ARRAY(int, highest_node_number + 1, mtInternal);
2726     for (unsigned int i = 0; i &lt;= highest_node_number; i++) {
2727       ULONGLONG proc_mask_numa_node;
2728       if (!GetNumaNodeProcessorMask(i, &amp;proc_mask_numa_node)) return false;
2729       if ((proc_aff_mask &amp; proc_mask_numa_node)!=0) {
2730         _numa_used_node_list[_numa_used_node_count++] = i;
2731       }
2732     }
2733     return (_numa_used_node_count &gt; 1);
2734   }
2735 
2736   int get_count() { return _numa_used_node_count; }
2737   int get_node_list_entry(int n) {
2738     // for indexes out of range, returns -1
2739     return (n &lt; _numa_used_node_count ? _numa_used_node_list[n] : -1);
2740   }
2741 
2742 } numa_node_list_holder;
2743 
2744 
2745 
2746 static size_t _large_page_size = 0;
2747 
2748 static bool request_lock_memory_privilege() {
2749   _hProcess = OpenProcess(PROCESS_QUERY_INFORMATION, FALSE,
2750                           os::current_process_id());
2751 
2752   LUID luid;
2753   if (_hProcess != NULL &amp;&amp;
2754       OpenProcessToken(_hProcess, TOKEN_ADJUST_PRIVILEGES, &amp;_hToken) &amp;&amp;
2755       LookupPrivilegeValue(NULL, &quot;SeLockMemoryPrivilege&quot;, &amp;luid)) {
2756 
2757     TOKEN_PRIVILEGES tp;
2758     tp.PrivilegeCount = 1;
2759     tp.Privileges[0].Luid = luid;
2760     tp.Privileges[0].Attributes = SE_PRIVILEGE_ENABLED;
2761 
2762     // AdjustTokenPrivileges() may return TRUE even when it couldn&#39;t change the
2763     // privilege. Check GetLastError() too. See MSDN document.
2764     if (AdjustTokenPrivileges(_hToken, false, &amp;tp, sizeof(tp), NULL, NULL) &amp;&amp;
2765         (GetLastError() == ERROR_SUCCESS)) {
2766       return true;
2767     }
2768   }
2769 
2770   return false;
2771 }
2772 
2773 static void cleanup_after_large_page_init() {
2774   if (_hProcess) CloseHandle(_hProcess);
2775   _hProcess = NULL;
2776   if (_hToken) CloseHandle(_hToken);
2777   _hToken = NULL;
2778 }
2779 
2780 static bool numa_interleaving_init() {
2781   bool success = false;
2782   bool use_numa_interleaving_specified = !FLAG_IS_DEFAULT(UseNUMAInterleaving);
2783 
2784   // print a warning if UseNUMAInterleaving flag is specified on command line
2785   bool warn_on_failure = use_numa_interleaving_specified;
2786 #define WARN(msg) if (warn_on_failure) { warning(msg); }
2787 
2788   // NUMAInterleaveGranularity cannot be less than vm_allocation_granularity (or _large_page_size if using large pages)
2789   size_t min_interleave_granularity = UseLargePages ? _large_page_size : os::vm_allocation_granularity();
2790   NUMAInterleaveGranularity = align_up(NUMAInterleaveGranularity, min_interleave_granularity);
2791 
2792   if (numa_node_list_holder.build()) {
2793     if (log_is_enabled(Debug, os, cpu)) {
2794       Log(os, cpu) log;
2795       log.debug(&quot;NUMA UsedNodeCount=%d, namely &quot;, numa_node_list_holder.get_count());
2796       for (int i = 0; i &lt; numa_node_list_holder.get_count(); i++) {
2797         log.debug(&quot;  %d &quot;, numa_node_list_holder.get_node_list_entry(i));
2798       }
2799     }
2800     success = true;
2801   } else {
2802     WARN(&quot;Process does not cover multiple NUMA nodes.&quot;);
2803   }
2804   if (!success) {
2805     if (use_numa_interleaving_specified) WARN(&quot;...Ignoring UseNUMAInterleaving flag.&quot;);
2806   }
2807   return success;
2808 #undef WARN
2809 }
2810 
2811 // this routine is used whenever we need to reserve a contiguous VA range
2812 // but we need to make separate VirtualAlloc calls for each piece of the range
2813 // Reasons for doing this:
2814 //  * UseLargePagesIndividualAllocation was set (normally only needed on WS2003 but possible to be set otherwise)
2815 //  * UseNUMAInterleaving requires a separate node for each piece
2816 static char* allocate_pages_individually(size_t bytes, char* addr, DWORD flags,
2817                                          DWORD prot,
2818                                          bool should_inject_error = false) {
2819   char * p_buf;
2820   // note: at setup time we guaranteed that NUMAInterleaveGranularity was aligned up to a page size
2821   size_t page_size = UseLargePages ? _large_page_size : os::vm_allocation_granularity();
2822   size_t chunk_size = UseNUMAInterleaving ? NUMAInterleaveGranularity : page_size;
2823 
2824   // first reserve enough address space in advance since we want to be
2825   // able to break a single contiguous virtual address range into multiple
2826   // large page commits but WS2003 does not allow reserving large page space
2827   // so we just use 4K pages for reserve, this gives us a legal contiguous
2828   // address space. then we will deallocate that reservation, and re alloc
2829   // using large pages
2830   const size_t size_of_reserve = bytes + chunk_size;
2831   if (bytes &gt; size_of_reserve) {
2832     // Overflowed.
2833     return NULL;
2834   }
2835   p_buf = (char *) VirtualAlloc(addr,
2836                                 size_of_reserve,  // size of Reserve
2837                                 MEM_RESERVE,
2838                                 PAGE_READWRITE);
2839   // If reservation failed, return NULL
2840   if (p_buf == NULL) return NULL;
2841   MemTracker::record_virtual_memory_reserve((address)p_buf, size_of_reserve, CALLER_PC);
2842   os::release_memory(p_buf, bytes + chunk_size);
2843 
2844   // we still need to round up to a page boundary (in case we are using large pages)
2845   // but not to a chunk boundary (in case InterleavingGranularity doesn&#39;t align with page size)
2846   // instead we handle this in the bytes_to_rq computation below
2847   p_buf = align_up(p_buf, page_size);
2848 
2849   // now go through and allocate one chunk at a time until all bytes are
2850   // allocated
2851   size_t  bytes_remaining = bytes;
2852   // An overflow of align_up() would have been caught above
2853   // in the calculation of size_of_reserve.
2854   char * next_alloc_addr = p_buf;
2855   HANDLE hProc = GetCurrentProcess();
2856 
2857 #ifdef ASSERT
2858   // Variable for the failure injection
2859   int ran_num = os::random();
2860   size_t fail_after = ran_num % bytes;
2861 #endif
2862 
2863   int count=0;
2864   while (bytes_remaining) {
2865     // select bytes_to_rq to get to the next chunk_size boundary
2866 
2867     size_t bytes_to_rq = MIN2(bytes_remaining, chunk_size - ((size_t)next_alloc_addr % chunk_size));
2868     // Note allocate and commit
2869     char * p_new;
2870 
2871 #ifdef ASSERT
2872     bool inject_error_now = should_inject_error &amp;&amp; (bytes_remaining &lt;= fail_after);
2873 #else
2874     const bool inject_error_now = false;
2875 #endif
2876 
2877     if (inject_error_now) {
2878       p_new = NULL;
2879     } else {
2880       if (!UseNUMAInterleaving) {
2881         p_new = (char *) VirtualAlloc(next_alloc_addr,
2882                                       bytes_to_rq,
2883                                       flags,
2884                                       prot);
2885       } else {
2886         // get the next node to use from the used_node_list
2887         assert(numa_node_list_holder.get_count() &gt; 0, &quot;Multiple NUMA nodes expected&quot;);
2888         DWORD node = numa_node_list_holder.get_node_list_entry(count % numa_node_list_holder.get_count());
2889         p_new = (char *)VirtualAllocExNuma(hProc, next_alloc_addr, bytes_to_rq, flags, prot, node);
2890       }
2891     }
2892 
2893     if (p_new == NULL) {
2894       // Free any allocated pages
2895       if (next_alloc_addr &gt; p_buf) {
2896         // Some memory was committed so release it.
2897         size_t bytes_to_release = bytes - bytes_remaining;
2898         // NMT has yet to record any individual blocks, so it
2899         // need to create a dummy &#39;reserve&#39; record to match
2900         // the release.
2901         MemTracker::record_virtual_memory_reserve((address)p_buf,
2902                                                   bytes_to_release, CALLER_PC);
2903         os::release_memory(p_buf, bytes_to_release);
2904       }
2905 #ifdef ASSERT
2906       if (should_inject_error) {
2907         log_develop_debug(pagesize)(&quot;Reserving pages individually failed.&quot;);
2908       }
2909 #endif
2910       return NULL;
2911     }
2912 
2913     bytes_remaining -= bytes_to_rq;
2914     next_alloc_addr += bytes_to_rq;
2915     count++;
2916   }
2917   // Although the memory is allocated individually, it is returned as one.
2918   // NMT records it as one block.
2919   if ((flags &amp; MEM_COMMIT) != 0) {
2920     MemTracker::record_virtual_memory_reserve_and_commit((address)p_buf, bytes, CALLER_PC);
2921   } else {
2922     MemTracker::record_virtual_memory_reserve((address)p_buf, bytes, CALLER_PC);
2923   }
2924 
2925   // made it this far, success
2926   return p_buf;
2927 }
2928 
2929 
2930 
2931 void os::large_page_init() {
2932   if (!UseLargePages) return;
2933 
2934   // print a warning if any large page related flag is specified on command line
2935   bool warn_on_failure = !FLAG_IS_DEFAULT(UseLargePages) ||
2936                          !FLAG_IS_DEFAULT(LargePageSizeInBytes);
2937   bool success = false;
2938 
2939 #define WARN(msg) if (warn_on_failure) { warning(msg); }
2940   if (request_lock_memory_privilege()) {
2941     size_t s = GetLargePageMinimum();
2942     if (s) {
2943 #if defined(IA32) || defined(AMD64)
2944       if (s &gt; 4*M || LargePageSizeInBytes &gt; 4*M) {
2945         WARN(&quot;JVM cannot use large pages bigger than 4mb.&quot;);
2946       } else {
2947 #endif
2948         if (LargePageSizeInBytes &amp;&amp; LargePageSizeInBytes % s == 0) {
2949           _large_page_size = LargePageSizeInBytes;
2950         } else {
2951           _large_page_size = s;
2952         }
2953         success = true;
2954 #if defined(IA32) || defined(AMD64)
2955       }
2956 #endif
2957     } else {
2958       WARN(&quot;Large page is not supported by the processor.&quot;);
2959     }
2960   } else {
2961     WARN(&quot;JVM cannot use large page memory because it does not have enough privilege to lock pages in memory.&quot;);
2962   }
2963 #undef WARN
2964 
2965   const size_t default_page_size = (size_t) vm_page_size();
2966   if (success &amp;&amp; _large_page_size &gt; default_page_size) {
2967     _page_sizes[0] = _large_page_size;
2968     _page_sizes[1] = default_page_size;
2969     _page_sizes[2] = 0;
2970   }
2971 
2972   cleanup_after_large_page_init();
2973   UseLargePages = success;
2974 }
2975 
2976 int os::create_file_for_heap(const char* dir) {
2977 
2978   const char name_template[] = &quot;/jvmheap.XXXXXX&quot;;
2979 
2980   size_t fullname_len = strlen(dir) + strlen(name_template);
2981   char *fullname = (char*)os::malloc(fullname_len + 1, mtInternal);
2982   if (fullname == NULL) {
2983     vm_exit_during_initialization(err_msg(&quot;Malloc failed during creation of backing file for heap (%s)&quot;, os::strerror(errno)));
2984     return -1;
2985   }
2986   int n = snprintf(fullname, fullname_len + 1, &quot;%s%s&quot;, dir, name_template);
2987   assert((size_t)n == fullname_len, &quot;Unexpected number of characters in string&quot;);
2988 
2989   os::native_path(fullname);
2990 
2991   char *path = _mktemp(fullname);
2992   if (path == NULL) {
2993     warning(&quot;_mktemp could not create file name from template %s (%s)&quot;, fullname, os::strerror(errno));
2994     os::free(fullname);
2995     return -1;
2996   }
2997 
2998   int fd = _open(path, O_RDWR | O_CREAT | O_TEMPORARY | O_EXCL, S_IWRITE | S_IREAD);
2999 
3000   os::free(fullname);
3001   if (fd &lt; 0) {
3002     warning(&quot;Problem opening file for heap (%s)&quot;, os::strerror(errno));
3003     return -1;
3004   }
3005   return fd;
3006 }
3007 
3008 // If &#39;base&#39; is not NULL, function will return NULL if it cannot get &#39;base&#39;
3009 char* os::map_memory_to_file(char* base, size_t size, int fd) {
3010   assert(fd != -1, &quot;File descriptor is not valid&quot;);
3011 
3012   HANDLE fh = (HANDLE)_get_osfhandle(fd);
3013 #ifdef _LP64
3014   HANDLE fileMapping = CreateFileMapping(fh, NULL, PAGE_READWRITE,
3015     (DWORD)(size &gt;&gt; 32), (DWORD)(size &amp; 0xFFFFFFFF), NULL);
3016 #else
3017   HANDLE fileMapping = CreateFileMapping(fh, NULL, PAGE_READWRITE,
3018     0, (DWORD)size, NULL);
3019 #endif
3020   if (fileMapping == NULL) {
3021     if (GetLastError() == ERROR_DISK_FULL) {
3022       vm_exit_during_initialization(err_msg(&quot;Could not allocate sufficient disk space for Java heap&quot;));
3023     }
3024     else {
3025       vm_exit_during_initialization(err_msg(&quot;Error in mapping Java heap at the given filesystem directory&quot;));
3026     }
3027 
3028     return NULL;
3029   }
3030 
3031   LPVOID addr = MapViewOfFileEx(fileMapping, FILE_MAP_WRITE, 0, 0, size, base);
3032 
3033   CloseHandle(fileMapping);
3034 
3035   return (char*)addr;
3036 }
3037 
3038 char* os::replace_existing_mapping_with_file_mapping(char* base, size_t size, int fd) {
3039   assert(fd != -1, &quot;File descriptor is not valid&quot;);
3040   assert(base != NULL, &quot;Base address cannot be NULL&quot;);
3041 
3042   release_memory(base, size);
3043   return map_memory_to_file(base, size, fd);
3044 }
3045 
3046 // On win32, one cannot release just a part of reserved memory, it&#39;s an
3047 // all or nothing deal.  When we split a reservation, we must break the
3048 // reservation into two reservations.
3049 void os::pd_split_reserved_memory(char *base, size_t size, size_t split,
3050                                   bool realloc) {
3051   if (size &gt; 0) {
3052     release_memory(base, size);
3053     if (realloc) {
3054       reserve_memory(split, base);
3055     }
3056     if (size != split) {
3057       reserve_memory(size - split, base + split);
3058     }
3059   }
3060 }
3061 
3062 // Multiple threads can race in this code but it&#39;s not possible to unmap small sections of
3063 // virtual space to get requested alignment, like posix-like os&#39;s.
3064 // Windows prevents multiple thread from remapping over each other so this loop is thread-safe.
3065 char* os::reserve_memory_aligned(size_t size, size_t alignment, int file_desc) {
3066   assert((alignment &amp; (os::vm_allocation_granularity() - 1)) == 0,
3067          &quot;Alignment must be a multiple of allocation granularity (page size)&quot;);
3068   assert((size &amp; (alignment -1)) == 0, &quot;size must be &#39;alignment&#39; aligned&quot;);
3069 
3070   size_t extra_size = size + alignment;
3071   assert(extra_size &gt;= size, &quot;overflow, size is too large to allow alignment&quot;);
3072 
3073   char* aligned_base = NULL;
3074 
3075   do {
3076     char* extra_base = os::reserve_memory(extra_size, NULL, alignment, file_desc);
3077     if (extra_base == NULL) {
3078       return NULL;
3079     }
3080     // Do manual alignment
3081     aligned_base = align_up(extra_base, alignment);
3082 
3083     if (file_desc != -1) {
3084       os::unmap_memory(extra_base, extra_size);
3085     } else {
3086       os::release_memory(extra_base, extra_size);
3087     }
3088 
3089     aligned_base = os::reserve_memory(size, aligned_base, 0, file_desc);
3090 
3091   } while (aligned_base == NULL);
3092 
3093   return aligned_base;
3094 }
3095 
3096 char* os::pd_reserve_memory(size_t bytes, char* addr, size_t alignment_hint) {
3097   assert((size_t)addr % os::vm_allocation_granularity() == 0,
3098          &quot;reserve alignment&quot;);
3099   assert(bytes % os::vm_page_size() == 0, &quot;reserve page size&quot;);
3100   char* res;
3101   // note that if UseLargePages is on, all the areas that require interleaving
3102   // will go thru reserve_memory_special rather than thru here.
3103   bool use_individual = (UseNUMAInterleaving &amp;&amp; !UseLargePages);
3104   if (!use_individual) {
3105     res = (char*)VirtualAlloc(addr, bytes, MEM_RESERVE, PAGE_READWRITE);
3106   } else {
3107     elapsedTimer reserveTimer;
3108     if (Verbose &amp;&amp; PrintMiscellaneous) reserveTimer.start();
3109     // in numa interleaving, we have to allocate pages individually
3110     // (well really chunks of NUMAInterleaveGranularity size)
3111     res = allocate_pages_individually(bytes, addr, MEM_RESERVE, PAGE_READWRITE);
3112     if (res == NULL) {
3113       warning(&quot;NUMA page allocation failed&quot;);
3114     }
3115     if (Verbose &amp;&amp; PrintMiscellaneous) {
3116       reserveTimer.stop();
3117       tty-&gt;print_cr(&quot;reserve_memory of %Ix bytes took &quot; JLONG_FORMAT &quot; ms (&quot; JLONG_FORMAT &quot; ticks)&quot;, bytes,
3118                     reserveTimer.milliseconds(), reserveTimer.ticks());
3119     }
3120   }
3121   assert(res == NULL || addr == NULL || addr == res,
3122          &quot;Unexpected address from reserve.&quot;);
3123 
3124   return res;
3125 }
3126 
3127 // Reserve memory at an arbitrary address, only if that area is
3128 // available (and not reserved for something else).
3129 char* os::pd_attempt_reserve_memory_at(size_t bytes, char* requested_addr) {
3130   // Windows os::reserve_memory() fails of the requested address range is
3131   // not avilable.
3132   return reserve_memory(bytes, requested_addr);
3133 }
3134 
3135 char* os::pd_attempt_reserve_memory_at(size_t bytes, char* requested_addr, int file_desc) {
3136   assert(file_desc &gt;= 0, &quot;file_desc is not valid&quot;);
3137   return map_memory_to_file(requested_addr, bytes, file_desc);
3138 }
3139 
3140 size_t os::large_page_size() {
3141   return _large_page_size;
3142 }
3143 
3144 bool os::can_commit_large_page_memory() {
3145   // Windows only uses large page memory when the entire region is reserved
3146   // and committed in a single VirtualAlloc() call. This may change in the
3147   // future, but with Windows 2003 it&#39;s not possible to commit on demand.
3148   return false;
3149 }
3150 
3151 bool os::can_execute_large_page_memory() {
3152   return true;
3153 }
3154 
3155 char* os::reserve_memory_special(size_t bytes, size_t alignment, char* addr,
3156                                  bool exec) {
3157   assert(UseLargePages, &quot;only for large pages&quot;);
3158 
3159   if (!is_aligned(bytes, os::large_page_size()) || alignment &gt; os::large_page_size()) {
3160     return NULL; // Fallback to small pages.
3161   }
3162 
3163   const DWORD prot = exec ? PAGE_EXECUTE_READWRITE : PAGE_READWRITE;
3164   const DWORD flags = MEM_RESERVE | MEM_COMMIT | MEM_LARGE_PAGES;
3165 
3166   // with large pages, there are two cases where we need to use Individual Allocation
3167   // 1) the UseLargePagesIndividualAllocation flag is set (set by default on WS2003)
3168   // 2) NUMA Interleaving is enabled, in which case we use a different node for each page
3169   if (UseLargePagesIndividualAllocation || UseNUMAInterleaving) {
3170     log_debug(pagesize)(&quot;Reserving large pages individually.&quot;);
3171 
3172     char * p_buf = allocate_pages_individually(bytes, addr, flags, prot, LargePagesIndividualAllocationInjectError);
3173     if (p_buf == NULL) {
3174       // give an appropriate warning message
3175       if (UseNUMAInterleaving) {
3176         warning(&quot;NUMA large page allocation failed, UseLargePages flag ignored&quot;);
3177       }
3178       if (UseLargePagesIndividualAllocation) {
3179         warning(&quot;Individually allocated large pages failed, &quot;
3180                 &quot;use -XX:-UseLargePagesIndividualAllocation to turn off&quot;);
3181       }
3182       return NULL;
3183     }
3184 
3185     return p_buf;
3186 
3187   } else {
3188     log_debug(pagesize)(&quot;Reserving large pages in a single large chunk.&quot;);
3189 
3190     // normal policy just allocate it all at once
3191     DWORD flag = MEM_RESERVE | MEM_COMMIT | MEM_LARGE_PAGES;
3192     char * res = (char *)VirtualAlloc(addr, bytes, flag, prot);
3193     if (res != NULL) {
3194       MemTracker::record_virtual_memory_reserve_and_commit((address)res, bytes, CALLER_PC);
3195     }
3196 
3197     return res;
3198   }
3199 }
3200 
3201 bool os::release_memory_special(char* base, size_t bytes) {
3202   assert(base != NULL, &quot;Sanity check&quot;);
3203   return release_memory(base, bytes);
3204 }
3205 
3206 void os::print_statistics() {
3207 }
3208 
3209 static void warn_fail_commit_memory(char* addr, size_t bytes, bool exec) {
3210   int err = os::get_last_error();
3211   char buf[256];
3212   size_t buf_len = os::lasterror(buf, sizeof(buf));
3213   warning(&quot;INFO: os::commit_memory(&quot; PTR_FORMAT &quot;, &quot; SIZE_FORMAT
3214           &quot;, %d) failed; error=&#39;%s&#39; (DOS error/errno=%d)&quot;, addr, bytes,
3215           exec, buf_len != 0 ? buf : &quot;&lt;no_error_string&gt;&quot;, err);
3216 }
3217 
3218 bool os::pd_commit_memory(char* addr, size_t bytes, bool exec) {
3219   if (bytes == 0) {
3220     // Don&#39;t bother the OS with noops.
3221     return true;
3222   }
3223   assert((size_t) addr % os::vm_page_size() == 0, &quot;commit on page boundaries&quot;);
3224   assert(bytes % os::vm_page_size() == 0, &quot;commit in page-sized chunks&quot;);
3225   // Don&#39;t attempt to print anything if the OS call fails. We&#39;re
3226   // probably low on resources, so the print itself may cause crashes.
3227 
3228   // unless we have NUMAInterleaving enabled, the range of a commit
3229   // is always within a reserve covered by a single VirtualAlloc
3230   // in that case we can just do a single commit for the requested size
3231   if (!UseNUMAInterleaving) {
3232     if (VirtualAlloc(addr, bytes, MEM_COMMIT, PAGE_READWRITE) == NULL) {
3233       NOT_PRODUCT(warn_fail_commit_memory(addr, bytes, exec);)
3234       return false;
3235     }
3236     if (exec) {
3237       DWORD oldprot;
3238       // Windows doc says to use VirtualProtect to get execute permissions
3239       if (!VirtualProtect(addr, bytes, PAGE_EXECUTE_READWRITE, &amp;oldprot)) {
3240         NOT_PRODUCT(warn_fail_commit_memory(addr, bytes, exec);)
3241         return false;
3242       }
3243     }
3244     return true;
3245   } else {
3246 
3247     // when NUMAInterleaving is enabled, the commit might cover a range that
3248     // came from multiple VirtualAlloc reserves (using allocate_pages_individually).
3249     // VirtualQuery can help us determine that.  The RegionSize that VirtualQuery
3250     // returns represents the number of bytes that can be committed in one step.
3251     size_t bytes_remaining = bytes;
3252     char * next_alloc_addr = addr;
3253     while (bytes_remaining &gt; 0) {
3254       MEMORY_BASIC_INFORMATION alloc_info;
3255       VirtualQuery(next_alloc_addr, &amp;alloc_info, sizeof(alloc_info));
3256       size_t bytes_to_rq = MIN2(bytes_remaining, (size_t)alloc_info.RegionSize);
3257       if (VirtualAlloc(next_alloc_addr, bytes_to_rq, MEM_COMMIT,
3258                        PAGE_READWRITE) == NULL) {
3259         NOT_PRODUCT(warn_fail_commit_memory(next_alloc_addr, bytes_to_rq,
3260                                             exec);)
3261         return false;
3262       }
3263       if (exec) {
3264         DWORD oldprot;
3265         if (!VirtualProtect(next_alloc_addr, bytes_to_rq,
3266                             PAGE_EXECUTE_READWRITE, &amp;oldprot)) {
3267           NOT_PRODUCT(warn_fail_commit_memory(next_alloc_addr, bytes_to_rq,
3268                                               exec);)
3269           return false;
3270         }
3271       }
3272       bytes_remaining -= bytes_to_rq;
3273       next_alloc_addr += bytes_to_rq;
3274     }
3275   }
3276   // if we made it this far, return true
3277   return true;
3278 }
3279 
3280 bool os::pd_commit_memory(char* addr, size_t size, size_t alignment_hint,
3281                           bool exec) {
3282   // alignment_hint is ignored on this OS
3283   return pd_commit_memory(addr, size, exec);
3284 }
3285 
3286 void os::pd_commit_memory_or_exit(char* addr, size_t size, bool exec,
3287                                   const char* mesg) {
3288   assert(mesg != NULL, &quot;mesg must be specified&quot;);
3289   if (!pd_commit_memory(addr, size, exec)) {
3290     warn_fail_commit_memory(addr, size, exec);
3291     vm_exit_out_of_memory(size, OOM_MMAP_ERROR, &quot;%s&quot;, mesg);
3292   }
3293 }
3294 
3295 void os::pd_commit_memory_or_exit(char* addr, size_t size,
3296                                   size_t alignment_hint, bool exec,
3297                                   const char* mesg) {
3298   // alignment_hint is ignored on this OS
3299   pd_commit_memory_or_exit(addr, size, exec, mesg);
3300 }
3301 
3302 bool os::pd_uncommit_memory(char* addr, size_t bytes) {
3303   if (bytes == 0) {
3304     // Don&#39;t bother the OS with noops.
3305     return true;
3306   }
3307   assert((size_t) addr % os::vm_page_size() == 0, &quot;uncommit on page boundaries&quot;);
3308   assert(bytes % os::vm_page_size() == 0, &quot;uncommit in page-sized chunks&quot;);
3309   return (VirtualFree(addr, bytes, MEM_DECOMMIT) != 0);
3310 }
3311 
3312 bool os::pd_release_memory(char* addr, size_t bytes) {
3313   return VirtualFree(addr, 0, MEM_RELEASE) != 0;
3314 }
3315 
3316 bool os::pd_create_stack_guard_pages(char* addr, size_t size) {
3317   return os::commit_memory(addr, size, !ExecMem);
3318 }
3319 
3320 bool os::remove_stack_guard_pages(char* addr, size_t size) {
3321   return os::uncommit_memory(addr, size);
3322 }
3323 
3324 static bool protect_pages_individually(char* addr, size_t bytes, unsigned int p, DWORD *old_status) {
3325   uint count = 0;
3326   bool ret = false;
3327   size_t bytes_remaining = bytes;
3328   char * next_protect_addr = addr;
3329 
3330   // Use VirtualQuery() to get the chunk size.
3331   while (bytes_remaining) {
3332     MEMORY_BASIC_INFORMATION alloc_info;
3333     if (VirtualQuery(next_protect_addr, &amp;alloc_info, sizeof(alloc_info)) == 0) {
3334       return false;
3335     }
3336 
3337     size_t bytes_to_protect = MIN2(bytes_remaining, (size_t)alloc_info.RegionSize);
3338     // We used different API at allocate_pages_individually() based on UseNUMAInterleaving,
3339     // but we don&#39;t distinguish here as both cases are protected by same API.
3340     ret = VirtualProtect(next_protect_addr, bytes_to_protect, p, old_status) != 0;
3341     warning(&quot;Failed protecting pages individually for chunk #%u&quot;, count);
3342     if (!ret) {
3343       return false;
3344     }
3345 
3346     bytes_remaining -= bytes_to_protect;
3347     next_protect_addr += bytes_to_protect;
3348     count++;
3349   }
3350   return ret;
3351 }
3352 
3353 // Set protections specified
3354 bool os::protect_memory(char* addr, size_t bytes, ProtType prot,
3355                         bool is_committed) {
3356   unsigned int p = 0;
3357   switch (prot) {
3358   case MEM_PROT_NONE: p = PAGE_NOACCESS; break;
3359   case MEM_PROT_READ: p = PAGE_READONLY; break;
3360   case MEM_PROT_RW:   p = PAGE_READWRITE; break;
3361   case MEM_PROT_RWX:  p = PAGE_EXECUTE_READWRITE; break;
3362   default:
3363     ShouldNotReachHere();
3364   }
3365 
3366   DWORD old_status;
3367 
3368   // Strange enough, but on Win32 one can change protection only for committed
3369   // memory, not a big deal anyway, as bytes less or equal than 64K
3370   if (!is_committed) {
3371     commit_memory_or_exit(addr, bytes, prot == MEM_PROT_RWX,
3372                           &quot;cannot commit protection page&quot;);
3373   }
3374   // One cannot use os::guard_memory() here, as on Win32 guard page
3375   // have different (one-shot) semantics, from MSDN on PAGE_GUARD:
3376   //
3377   // Pages in the region become guard pages. Any attempt to access a guard page
3378   // causes the system to raise a STATUS_GUARD_PAGE exception and turn off
3379   // the guard page status. Guard pages thus act as a one-time access alarm.
3380   bool ret;
3381   if (UseNUMAInterleaving) {
3382     // If UseNUMAInterleaving is enabled, the pages may have been allocated a chunk at a time,
3383     // so we must protect the chunks individually.
3384     ret = protect_pages_individually(addr, bytes, p, &amp;old_status);
3385   } else {
3386     ret = VirtualProtect(addr, bytes, p, &amp;old_status) != 0;
3387   }
3388 #ifdef ASSERT
3389   if (!ret) {
3390     int err = os::get_last_error();
3391     char buf[256];
3392     size_t buf_len = os::lasterror(buf, sizeof(buf));
3393     warning(&quot;INFO: os::protect_memory(&quot; PTR_FORMAT &quot;, &quot; SIZE_FORMAT
3394           &quot;) failed; error=&#39;%s&#39; (DOS error/errno=%d)&quot;, addr, bytes,
3395           buf_len != 0 ? buf : &quot;&lt;no_error_string&gt;&quot;, err);
3396   }
3397 #endif
3398   return ret;
3399 }
3400 
3401 bool os::guard_memory(char* addr, size_t bytes) {
3402   DWORD old_status;
3403   return VirtualProtect(addr, bytes, PAGE_READWRITE | PAGE_GUARD, &amp;old_status) != 0;
3404 }
3405 
3406 bool os::unguard_memory(char* addr, size_t bytes) {
3407   DWORD old_status;
3408   return VirtualProtect(addr, bytes, PAGE_READWRITE, &amp;old_status) != 0;
3409 }
3410 
3411 void os::pd_realign_memory(char *addr, size_t bytes, size_t alignment_hint) { }
3412 void os::pd_free_memory(char *addr, size_t bytes, size_t alignment_hint) { }
3413 void os::numa_make_global(char *addr, size_t bytes)    { }
3414 void os::numa_make_local(char *addr, size_t bytes, int lgrp_hint)    { }
3415 bool os::numa_topology_changed()                       { return false; }
3416 size_t os::numa_get_groups_num()                       { return MAX2(numa_node_list_holder.get_count(), 1); }
3417 int os::numa_get_group_id()                            { return 0; }
3418 size_t os::numa_get_leaf_groups(int *ids, size_t size) {
3419   if (numa_node_list_holder.get_count() == 0 &amp;&amp; size &gt; 0) {
3420     // Provide an answer for UMA systems
3421     ids[0] = 0;
3422     return 1;
3423   } else {
3424     // check for size bigger than actual groups_num
3425     size = MIN2(size, numa_get_groups_num());
3426     for (int i = 0; i &lt; (int)size; i++) {
3427       ids[i] = numa_node_list_holder.get_node_list_entry(i);
3428     }
3429     return size;
3430   }
3431 }
3432 
3433 bool os::get_page_info(char *start, page_info* info) {
3434   return false;
3435 }
3436 
3437 char *os::scan_pages(char *start, char* end, page_info* page_expected,
3438                      page_info* page_found) {
3439   return end;
3440 }
3441 
3442 char* os::non_memory_address_word() {
3443   // Must never look like an address returned by reserve_memory,
3444   // even in its subfields (as defined by the CPU immediate fields,
3445   // if the CPU splits constants across multiple instructions).
3446   return (char*)-1;
3447 }
3448 
3449 #define MAX_ERROR_COUNT 100
3450 #define SYS_THREAD_ERROR 0xffffffffUL
3451 
3452 void os::pd_start_thread(Thread* thread) {
3453   DWORD ret = ResumeThread(thread-&gt;osthread()-&gt;thread_handle());
3454   // Returns previous suspend state:
3455   // 0:  Thread was not suspended
3456   // 1:  Thread is running now
3457   // &gt;1: Thread is still suspended.
3458   assert(ret != SYS_THREAD_ERROR, &quot;StartThread failed&quot;); // should propagate back
3459 }
3460 
3461 class HighResolutionInterval : public CHeapObj&lt;mtThread&gt; {
3462   // The default timer resolution seems to be 10 milliseconds.
3463   // (Where is this written down?)
3464   // If someone wants to sleep for only a fraction of the default,
3465   // then we set the timer resolution down to 1 millisecond for
3466   // the duration of their interval.
3467   // We carefully set the resolution back, since otherwise we
3468   // seem to incur an overhead (3%?) that we don&#39;t need.
3469   // CONSIDER: if ms is small, say 3, then we should run with a high resolution time.
3470   // Buf if ms is large, say 500, or 503, we should avoid the call to timeBeginPeriod().
3471   // Alternatively, we could compute the relative error (503/500 = .6%) and only use
3472   // timeBeginPeriod() if the relative error exceeded some threshold.
3473   // timeBeginPeriod() has been linked to problems with clock drift on win32 systems and
3474   // to decreased efficiency related to increased timer &quot;tick&quot; rates.  We want to minimize
3475   // (a) calls to timeBeginPeriod() and timeEndPeriod() and (b) time spent with high
3476   // resolution timers running.
3477  private:
3478   jlong resolution;
3479  public:
3480   HighResolutionInterval(jlong ms) {
3481     resolution = ms % 10L;
3482     if (resolution != 0) {
3483       MMRESULT result = timeBeginPeriod(1L);
3484     }
3485   }
3486   ~HighResolutionInterval() {
3487     if (resolution != 0) {
3488       MMRESULT result = timeEndPeriod(1L);
3489     }
3490     resolution = 0L;
3491   }
3492 };
3493 
3494 int os::sleep(Thread* thread, jlong ms, bool interruptable) {
3495   jlong limit = (jlong) MAXDWORD;
3496 
3497   while (ms &gt; limit) {
3498     int res;
3499     if ((res = sleep(thread, limit, interruptable)) != OS_TIMEOUT) {
3500       return res;
3501     }
3502     ms -= limit;
3503   }
3504 
3505   assert(thread == Thread::current(), &quot;thread consistency check&quot;);
3506   OSThread* osthread = thread-&gt;osthread();
3507   OSThreadWaitState osts(osthread, false /* not Object.wait() */);
3508   int result;
3509   if (interruptable) {
3510     assert(thread-&gt;is_Java_thread(), &quot;must be java thread&quot;);
3511     JavaThread *jt = (JavaThread *) thread;
3512     ThreadBlockInVM tbivm(jt);
3513 
3514     jt-&gt;set_suspend_equivalent();
3515     // cleared by handle_special_suspend_equivalent_condition() or
3516     // java_suspend_self() via check_and_wait_while_suspended()
3517 
3518     HANDLE events[1];
3519     events[0] = osthread-&gt;interrupt_event();
3520     HighResolutionInterval *phri=NULL;
3521     if (!ForceTimeHighResolution) {
3522       phri = new HighResolutionInterval(ms);
3523     }
3524     if (WaitForMultipleObjects(1, events, FALSE, (DWORD)ms) == WAIT_TIMEOUT) {
3525       result = OS_TIMEOUT;
3526     } else {
3527       ResetEvent(osthread-&gt;interrupt_event());
3528       osthread-&gt;set_interrupted(false);
3529       result = OS_INTRPT;
3530     }
3531     delete phri; //if it is NULL, harmless
3532 
3533     // were we externally suspended while we were waiting?
3534     jt-&gt;check_and_wait_while_suspended();
3535   } else {
3536     assert(!thread-&gt;is_Java_thread(), &quot;must not be java thread&quot;);
3537     Sleep((long) ms);
3538     result = OS_TIMEOUT;
3539   }
3540   return result;
3541 }
3542 
3543 // Short sleep, direct OS call.
3544 //
3545 // ms = 0, means allow others (if any) to run.
3546 //
3547 void os::naked_short_sleep(jlong ms) {
3548   assert(ms &lt; 1000, &quot;Un-interruptable sleep, short time use only&quot;);
3549   Sleep(ms);
3550 }
3551 
3552 void os::naked_short_nanosleep(jlong ns) {
3553   assert(ns &gt; -1 &amp;&amp; ns &lt; NANOUNITS, &quot;Un-interruptable sleep, short time use only&quot;);
3554   LARGE_INTEGER hundreds_nanos = { 0 };
3555   HANDLE wait_timer = ::CreateWaitableTimer(NULL /* attributes*/,
3556                                             true /* manual reset */,
3557                                             NULL /* name */ );
3558   if (wait_timer == NULL) {
3559     log_warning(os)(&quot;Failed to CreateWaitableTimer: %u&quot;, GetLastError());
3560     return;
3561   }
3562 
3563   // We need a minimum of one hundred nanos.
3564   ns = ns &gt; 100 ? ns : 100;
3565 
3566   // Round ns to the nearst hundred of nanos.
3567   // Negative values indicate relative time.
3568   hundreds_nanos.QuadPart = -((ns + 50) / 100);
3569 
3570   if (::SetWaitableTimer(wait_timer /* handle */,
3571                          &amp;hundreds_nanos /* due time */,
3572                          0 /* period */,
3573                          NULL /* comp func */,
3574                          NULL /* comp func args */,
3575                          FALSE /* resume */)) {
3576     DWORD res = ::WaitForSingleObject(wait_timer /* handle */, INFINITE /* timeout */);
3577     if (res != WAIT_OBJECT_0) {
3578       if (res == WAIT_FAILED) {
3579         log_warning(os)(&quot;Failed to WaitForSingleObject: %u&quot;, GetLastError());
3580       } else {
3581         log_warning(os)(&quot;Unexpected return from WaitForSingleObject: %s&quot;,
3582                         res == WAIT_ABANDONED ? &quot;WAIT_ABANDONED&quot; : &quot;WAIT_TIMEOUT&quot;);
3583       }
3584     }
3585   }
3586   ::CloseHandle(wait_timer /* handle */);
3587 }
3588 
3589 // Sleep forever; naked call to OS-specific sleep; use with CAUTION
3590 void os::infinite_sleep() {
3591   while (true) {    // sleep forever ...
3592     Sleep(100000);  // ... 100 seconds at a time
3593   }
3594 }
3595 
3596 typedef BOOL (WINAPI * STTSignature)(void);
3597 
3598 void os::naked_yield() {
3599   // Consider passing back the return value from SwitchToThread().
3600   SwitchToThread();
3601 }
3602 
3603 // Win32 only gives you access to seven real priorities at a time,
3604 // so we compress Java&#39;s ten down to seven.  It would be better
3605 // if we dynamically adjusted relative priorities.
3606 
3607 int os::java_to_os_priority[CriticalPriority + 1] = {
3608   THREAD_PRIORITY_IDLE,                         // 0  Entry should never be used
3609   THREAD_PRIORITY_LOWEST,                       // 1  MinPriority
3610   THREAD_PRIORITY_LOWEST,                       // 2
3611   THREAD_PRIORITY_BELOW_NORMAL,                 // 3
3612   THREAD_PRIORITY_BELOW_NORMAL,                 // 4
3613   THREAD_PRIORITY_NORMAL,                       // 5  NormPriority
3614   THREAD_PRIORITY_NORMAL,                       // 6
3615   THREAD_PRIORITY_ABOVE_NORMAL,                 // 7
3616   THREAD_PRIORITY_ABOVE_NORMAL,                 // 8
3617   THREAD_PRIORITY_HIGHEST,                      // 9  NearMaxPriority
3618   THREAD_PRIORITY_HIGHEST,                      // 10 MaxPriority
3619   THREAD_PRIORITY_HIGHEST                       // 11 CriticalPriority
3620 };
3621 
3622 int prio_policy1[CriticalPriority + 1] = {
3623   THREAD_PRIORITY_IDLE,                         // 0  Entry should never be used
3624   THREAD_PRIORITY_LOWEST,                       // 1  MinPriority
3625   THREAD_PRIORITY_LOWEST,                       // 2
3626   THREAD_PRIORITY_BELOW_NORMAL,                 // 3
3627   THREAD_PRIORITY_BELOW_NORMAL,                 // 4
3628   THREAD_PRIORITY_NORMAL,                       // 5  NormPriority
3629   THREAD_PRIORITY_ABOVE_NORMAL,                 // 6
3630   THREAD_PRIORITY_ABOVE_NORMAL,                 // 7
3631   THREAD_PRIORITY_HIGHEST,                      // 8
3632   THREAD_PRIORITY_HIGHEST,                      // 9  NearMaxPriority
3633   THREAD_PRIORITY_TIME_CRITICAL,                // 10 MaxPriority
3634   THREAD_PRIORITY_TIME_CRITICAL                 // 11 CriticalPriority
3635 };
3636 
3637 static int prio_init() {
3638   // If ThreadPriorityPolicy is 1, switch tables
3639   if (ThreadPriorityPolicy == 1) {
3640     int i;
3641     for (i = 0; i &lt; CriticalPriority + 1; i++) {
3642       os::java_to_os_priority[i] = prio_policy1[i];
3643     }
3644   }
3645   if (UseCriticalJavaThreadPriority) {
3646     os::java_to_os_priority[MaxPriority] = os::java_to_os_priority[CriticalPriority];
3647   }
3648   return 0;
3649 }
3650 
3651 OSReturn os::set_native_priority(Thread* thread, int priority) {
3652   if (!UseThreadPriorities) return OS_OK;
3653   bool ret = SetThreadPriority(thread-&gt;osthread()-&gt;thread_handle(), priority) != 0;
3654   return ret ? OS_OK : OS_ERR;
3655 }
3656 
3657 OSReturn os::get_native_priority(const Thread* const thread,
3658                                  int* priority_ptr) {
3659   if (!UseThreadPriorities) {
3660     *priority_ptr = java_to_os_priority[NormPriority];
3661     return OS_OK;
3662   }
3663   int os_prio = GetThreadPriority(thread-&gt;osthread()-&gt;thread_handle());
3664   if (os_prio == THREAD_PRIORITY_ERROR_RETURN) {
3665     assert(false, &quot;GetThreadPriority failed&quot;);
3666     return OS_ERR;
3667   }
3668   *priority_ptr = os_prio;
3669   return OS_OK;
3670 }
3671 
3672 void os::interrupt(Thread* thread) {
3673   debug_only(Thread::check_for_dangling_thread_pointer(thread);)
3674 
3675   OSThread* osthread = thread-&gt;osthread();
3676   osthread-&gt;set_interrupted(true);
3677   // More than one thread can get here with the same value of osthread,
3678   // resulting in multiple notifications.  We do, however, want the store
3679   // to interrupted() to be visible to other threads before we post
3680   // the interrupt event.
3681   OrderAccess::release();
3682   SetEvent(osthread-&gt;interrupt_event());
3683   // For JSR166:  unpark after setting status
3684   if (thread-&gt;is_Java_thread()) {
3685     ((JavaThread*)thread)-&gt;parker()-&gt;unpark();
3686   }
3687 
3688   ParkEvent * ev = thread-&gt;_ParkEvent;
3689   if (ev != NULL) ev-&gt;unpark();
3690 }
3691 
3692 
3693 bool os::is_interrupted(Thread* thread, bool clear_interrupted) {
3694   debug_only(Thread::check_for_dangling_thread_pointer(thread);)
3695 
3696   OSThread* osthread = thread-&gt;osthread();
3697   // There is no synchronization between the setting of the interrupt
3698   // and it being cleared here. It is critical - see 6535709 - that
3699   // we only clear the interrupt state, and reset the interrupt event,
3700   // if we are going to report that we were indeed interrupted - else
3701   // an interrupt can be &quot;lost&quot;, leading to spurious wakeups or lost wakeups
3702   // depending on the timing. By checking thread interrupt event to see
3703   // if the thread gets real interrupt thus prevent spurious wakeup.
3704   bool interrupted = osthread-&gt;interrupted() &amp;&amp; (WaitForSingleObject(osthread-&gt;interrupt_event(), 0) == WAIT_OBJECT_0);
3705   if (interrupted &amp;&amp; clear_interrupted) {
3706     osthread-&gt;set_interrupted(false);
3707     ResetEvent(osthread-&gt;interrupt_event());
3708   } // Otherwise leave the interrupted state alone
3709 
3710   return interrupted;
3711 }
3712 
3713 // GetCurrentThreadId() returns DWORD
3714 intx os::current_thread_id()  { return GetCurrentThreadId(); }
3715 
3716 static int _initial_pid = 0;
3717 
3718 int os::current_process_id() {
3719   return (_initial_pid ? _initial_pid : _getpid());
3720 }
3721 
3722 int    os::win32::_vm_page_size              = 0;
3723 int    os::win32::_vm_allocation_granularity = 0;
3724 int    os::win32::_processor_type            = 0;
3725 // Processor level is not available on non-NT systems, use vm_version instead
3726 int    os::win32::_processor_level           = 0;
3727 julong os::win32::_physical_memory           = 0;
3728 size_t os::win32::_default_stack_size        = 0;
3729 
3730 intx          os::win32::_os_thread_limit    = 0;
3731 volatile intx os::win32::_os_thread_count    = 0;
3732 
3733 bool   os::win32::_is_windows_server         = false;
3734 
3735 // 6573254
3736 // Currently, the bug is observed across all the supported Windows releases,
3737 // including the latest one (as of this writing - Windows Server 2012 R2)
3738 bool   os::win32::_has_exit_bug              = true;
3739 
3740 void os::win32::initialize_system_info() {
3741   SYSTEM_INFO si;
3742   GetSystemInfo(&amp;si);
3743   _vm_page_size    = si.dwPageSize;
3744   _vm_allocation_granularity = si.dwAllocationGranularity;
3745   _processor_type  = si.dwProcessorType;
3746   _processor_level = si.wProcessorLevel;
3747   set_processor_count(si.dwNumberOfProcessors);
3748 
3749   MEMORYSTATUSEX ms;
3750   ms.dwLength = sizeof(ms);
3751 
3752   // also returns dwAvailPhys (free physical memory bytes), dwTotalVirtual, dwAvailVirtual,
3753   // dwMemoryLoad (% of memory in use)
3754   GlobalMemoryStatusEx(&amp;ms);
3755   _physical_memory = ms.ullTotalPhys;
3756 
3757   if (FLAG_IS_DEFAULT(MaxRAM)) {
3758     // Adjust MaxRAM according to the maximum virtual address space available.
3759     FLAG_SET_DEFAULT(MaxRAM, MIN2(MaxRAM, (uint64_t) ms.ullTotalVirtual));
3760   }
3761 
3762   OSVERSIONINFOEX oi;
3763   oi.dwOSVersionInfoSize = sizeof(OSVERSIONINFOEX);
3764   GetVersionEx((OSVERSIONINFO*)&amp;oi);
3765   switch (oi.dwPlatformId) {
3766   case VER_PLATFORM_WIN32_NT:
3767     {
3768       int os_vers = oi.dwMajorVersion * 1000 + oi.dwMinorVersion;
3769       if (oi.wProductType == VER_NT_DOMAIN_CONTROLLER ||
3770           oi.wProductType == VER_NT_SERVER) {
3771         _is_windows_server = true;
3772       }
3773     }
3774     break;
3775   default: fatal(&quot;Unknown platform&quot;);
3776   }
3777 
3778   _default_stack_size = os::current_stack_size();
3779   assert(_default_stack_size &gt; (size_t) _vm_page_size, &quot;invalid stack size&quot;);
3780   assert((_default_stack_size &amp; (_vm_page_size - 1)) == 0,
3781          &quot;stack size not a multiple of page size&quot;);
3782 
3783   initialize_performance_counter();
3784 }
3785 
3786 
3787 HINSTANCE os::win32::load_Windows_dll(const char* name, char *ebuf,
3788                                       int ebuflen) {
3789   char path[MAX_PATH];
3790   DWORD size;
3791   DWORD pathLen = (DWORD)sizeof(path);
3792   HINSTANCE result = NULL;
3793 
3794   // only allow library name without path component
3795   assert(strchr(name, &#39;\\&#39;) == NULL, &quot;path not allowed&quot;);
3796   assert(strchr(name, &#39;:&#39;) == NULL, &quot;path not allowed&quot;);
3797   if (strchr(name, &#39;\\&#39;) != NULL || strchr(name, &#39;:&#39;) != NULL) {
3798     jio_snprintf(ebuf, ebuflen,
3799                  &quot;Invalid parameter while calling os::win32::load_windows_dll(): cannot take path: %s&quot;, name);
3800     return NULL;
3801   }
3802 
3803   // search system directory
3804   if ((size = GetSystemDirectory(path, pathLen)) &gt; 0) {
3805     if (size &gt;= pathLen) {
3806       return NULL; // truncated
3807     }
3808     if (jio_snprintf(path + size, pathLen - size, &quot;\\%s&quot;, name) == -1) {
3809       return NULL; // truncated
3810     }
3811     if ((result = (HINSTANCE)os::dll_load(path, ebuf, ebuflen)) != NULL) {
3812       return result;
3813     }
3814   }
3815 
3816   // try Windows directory
3817   if ((size = GetWindowsDirectory(path, pathLen)) &gt; 0) {
3818     if (size &gt;= pathLen) {
3819       return NULL; // truncated
3820     }
3821     if (jio_snprintf(path + size, pathLen - size, &quot;\\%s&quot;, name) == -1) {
3822       return NULL; // truncated
3823     }
3824     if ((result = (HINSTANCE)os::dll_load(path, ebuf, ebuflen)) != NULL) {
3825       return result;
3826     }
3827   }
3828 
3829   jio_snprintf(ebuf, ebuflen,
3830                &quot;os::win32::load_windows_dll() cannot load %s from system directories.&quot;, name);
3831   return NULL;
3832 }
3833 
3834 #define MAXIMUM_THREADS_TO_KEEP (16 * MAXIMUM_WAIT_OBJECTS)
3835 #define EXIT_TIMEOUT 300000 /* 5 minutes */
3836 
3837 static BOOL CALLBACK init_crit_sect_call(PINIT_ONCE, PVOID pcrit_sect, PVOID*) {
3838   InitializeCriticalSection((CRITICAL_SECTION*)pcrit_sect);
3839   return TRUE;
3840 }
3841 
3842 int os::win32::exit_process_or_thread(Ept what, int exit_code) {
3843   // Basic approach:
3844   //  - Each exiting thread registers its intent to exit and then does so.
3845   //  - A thread trying to terminate the process must wait for all
3846   //    threads currently exiting to complete their exit.
3847 
3848   if (os::win32::has_exit_bug()) {
3849     // The array holds handles of the threads that have started exiting by calling
3850     // _endthreadex().
3851     // Should be large enough to avoid blocking the exiting thread due to lack of
3852     // a free slot.
3853     static HANDLE handles[MAXIMUM_THREADS_TO_KEEP];
3854     static int handle_count = 0;
3855 
3856     static INIT_ONCE init_once_crit_sect = INIT_ONCE_STATIC_INIT;
3857     static CRITICAL_SECTION crit_sect;
3858     static volatile DWORD process_exiting = 0;
3859     int i, j;
3860     DWORD res;
3861     HANDLE hproc, hthr;
3862 
3863     // We only attempt to register threads until a process exiting
3864     // thread manages to set the process_exiting flag. Any threads
3865     // that come through here after the process_exiting flag is set
3866     // are unregistered and will be caught in the SuspendThread()
3867     // infinite loop below.
3868     bool registered = false;
3869 
3870     // The first thread that reached this point, initializes the critical section.
3871     if (!InitOnceExecuteOnce(&amp;init_once_crit_sect, init_crit_sect_call, &amp;crit_sect, NULL)) {
3872       warning(&quot;crit_sect initialization failed in %s: %d\n&quot;, __FILE__, __LINE__);
3873     } else if (OrderAccess::load_acquire(&amp;process_exiting) == 0) {
3874       if (what != EPT_THREAD) {
3875         // Atomically set process_exiting before the critical section
3876         // to increase the visibility between racing threads.
3877         Atomic::cmpxchg(GetCurrentThreadId(), &amp;process_exiting, (DWORD)0);
3878       }
3879       EnterCriticalSection(&amp;crit_sect);
3880 
3881       if (what == EPT_THREAD &amp;&amp; OrderAccess::load_acquire(&amp;process_exiting) == 0) {
3882         // Remove from the array those handles of the threads that have completed exiting.
3883         for (i = 0, j = 0; i &lt; handle_count; ++i) {
3884           res = WaitForSingleObject(handles[i], 0 /* don&#39;t wait */);
3885           if (res == WAIT_TIMEOUT) {
3886             handles[j++] = handles[i];
3887           } else {
3888             if (res == WAIT_FAILED) {
3889               warning(&quot;WaitForSingleObject failed (%u) in %s: %d\n&quot;,
3890                       GetLastError(), __FILE__, __LINE__);
3891             }
3892             // Don&#39;t keep the handle, if we failed waiting for it.
3893             CloseHandle(handles[i]);
3894           }
3895         }
3896 
3897         // If there&#39;s no free slot in the array of the kept handles, we&#39;ll have to
3898         // wait until at least one thread completes exiting.
3899         if ((handle_count = j) == MAXIMUM_THREADS_TO_KEEP) {
3900           // Raise the priority of the oldest exiting thread to increase its chances
3901           // to complete sooner.
3902           SetThreadPriority(handles[0], THREAD_PRIORITY_ABOVE_NORMAL);
3903           res = WaitForMultipleObjects(MAXIMUM_WAIT_OBJECTS, handles, FALSE, EXIT_TIMEOUT);
3904           if (res &gt;= WAIT_OBJECT_0 &amp;&amp; res &lt; (WAIT_OBJECT_0 + MAXIMUM_WAIT_OBJECTS)) {
3905             i = (res - WAIT_OBJECT_0);
3906             handle_count = MAXIMUM_THREADS_TO_KEEP - 1;
3907             for (; i &lt; handle_count; ++i) {
3908               handles[i] = handles[i + 1];
3909             }
3910           } else {
3911             warning(&quot;WaitForMultipleObjects %s (%u) in %s: %d\n&quot;,
3912                     (res == WAIT_FAILED ? &quot;failed&quot; : &quot;timed out&quot;),
3913                     GetLastError(), __FILE__, __LINE__);
3914             // Don&#39;t keep handles, if we failed waiting for them.
3915             for (i = 0; i &lt; MAXIMUM_THREADS_TO_KEEP; ++i) {
3916               CloseHandle(handles[i]);
3917             }
3918             handle_count = 0;
3919           }
3920         }
3921 
3922         // Store a duplicate of the current thread handle in the array of handles.
3923         hproc = GetCurrentProcess();
3924         hthr = GetCurrentThread();
3925         if (!DuplicateHandle(hproc, hthr, hproc, &amp;handles[handle_count],
3926                              0, FALSE, DUPLICATE_SAME_ACCESS)) {
3927           warning(&quot;DuplicateHandle failed (%u) in %s: %d\n&quot;,
3928                   GetLastError(), __FILE__, __LINE__);
3929 
3930           // We can&#39;t register this thread (no more handles) so this thread
3931           // may be racing with a thread that is calling exit(). If the thread
3932           // that is calling exit() has managed to set the process_exiting
3933           // flag, then this thread will be caught in the SuspendThread()
3934           // infinite loop below which closes that race. A small timing
3935           // window remains before the process_exiting flag is set, but it
3936           // is only exposed when we are out of handles.
3937         } else {
3938           ++handle_count;
3939           registered = true;
3940 
3941           // The current exiting thread has stored its handle in the array, and now
3942           // should leave the critical section before calling _endthreadex().
3943         }
3944 
3945       } else if (what != EPT_THREAD &amp;&amp; handle_count &gt; 0) {
3946         jlong start_time, finish_time, timeout_left;
3947         // Before ending the process, make sure all the threads that had called
3948         // _endthreadex() completed.
3949 
3950         // Set the priority level of the current thread to the same value as
3951         // the priority level of exiting threads.
3952         // This is to ensure it will be given a fair chance to execute if
3953         // the timeout expires.
3954         hthr = GetCurrentThread();
3955         SetThreadPriority(hthr, THREAD_PRIORITY_ABOVE_NORMAL);
3956         start_time = os::javaTimeNanos();
3957         finish_time = start_time + ((jlong)EXIT_TIMEOUT * 1000000L);
3958         for (i = 0; ; ) {
3959           int portion_count = handle_count - i;
3960           if (portion_count &gt; MAXIMUM_WAIT_OBJECTS) {
3961             portion_count = MAXIMUM_WAIT_OBJECTS;
3962           }
3963           for (j = 0; j &lt; portion_count; ++j) {
3964             SetThreadPriority(handles[i + j], THREAD_PRIORITY_ABOVE_NORMAL);
3965           }
3966           timeout_left = (finish_time - start_time) / 1000000L;
3967           if (timeout_left &lt; 0) {
3968             timeout_left = 0;
3969           }
3970           res = WaitForMultipleObjects(portion_count, handles + i, TRUE, timeout_left);
3971           if (res == WAIT_FAILED || res == WAIT_TIMEOUT) {
3972             warning(&quot;WaitForMultipleObjects %s (%u) in %s: %d\n&quot;,
3973                     (res == WAIT_FAILED ? &quot;failed&quot; : &quot;timed out&quot;),
3974                     GetLastError(), __FILE__, __LINE__);
3975             // Reset portion_count so we close the remaining
3976             // handles due to this error.
3977             portion_count = handle_count - i;
3978           }
3979           for (j = 0; j &lt; portion_count; ++j) {
3980             CloseHandle(handles[i + j]);
3981           }
3982           if ((i += portion_count) &gt;= handle_count) {
3983             break;
3984           }
3985           start_time = os::javaTimeNanos();
3986         }
3987         handle_count = 0;
3988       }
3989 
3990       LeaveCriticalSection(&amp;crit_sect);
3991     }
3992 
3993     if (!registered &amp;&amp;
3994         OrderAccess::load_acquire(&amp;process_exiting) != 0 &amp;&amp;
3995         process_exiting != GetCurrentThreadId()) {
3996       // Some other thread is about to call exit(), so we don&#39;t let
3997       // the current unregistered thread proceed to exit() or _endthreadex()
3998       while (true) {
3999         SuspendThread(GetCurrentThread());
4000         // Avoid busy-wait loop, if SuspendThread() failed.
4001         Sleep(EXIT_TIMEOUT);
4002       }
4003     }
4004   }
4005 
4006   // We are here if either
4007   // - there&#39;s no &#39;race at exit&#39; bug on this OS release;
4008   // - initialization of the critical section failed (unlikely);
4009   // - the current thread has registered itself and left the critical section;
4010   // - the process-exiting thread has raised the flag and left the critical section.
4011   if (what == EPT_THREAD) {
4012     _endthreadex((unsigned)exit_code);
4013   } else if (what == EPT_PROCESS) {
4014     ::exit(exit_code);
4015   } else {
4016     _exit(exit_code);
4017   }
4018 
4019   // Should not reach here
4020   return exit_code;
4021 }
4022 
4023 #undef EXIT_TIMEOUT
4024 
4025 void os::win32::setmode_streams() {
4026   _setmode(_fileno(stdin), _O_BINARY);
4027   _setmode(_fileno(stdout), _O_BINARY);
4028   _setmode(_fileno(stderr), _O_BINARY);
4029 }
4030 
4031 
4032 bool os::is_debugger_attached() {
4033   return IsDebuggerPresent() ? true : false;
4034 }
4035 
4036 
4037 void os::wait_for_keypress_at_exit(void) {
4038   if (PauseAtExit) {
4039     fprintf(stderr, &quot;Press any key to continue...\n&quot;);
4040     fgetc(stdin);
4041   }
4042 }
4043 
4044 
4045 bool os::message_box(const char* title, const char* message) {
4046   int result = MessageBox(NULL, message, title,
4047                           MB_YESNO | MB_ICONERROR | MB_SYSTEMMODAL | MB_DEFAULT_DESKTOP_ONLY);
4048   return result == IDYES;
4049 }
4050 
4051 #ifndef PRODUCT
4052 #ifndef _WIN64
4053 // Helpers to check whether NX protection is enabled
4054 int nx_exception_filter(_EXCEPTION_POINTERS *pex) {
4055   if (pex-&gt;ExceptionRecord-&gt;ExceptionCode == EXCEPTION_ACCESS_VIOLATION &amp;&amp;
4056       pex-&gt;ExceptionRecord-&gt;NumberParameters &gt; 0 &amp;&amp;
4057       pex-&gt;ExceptionRecord-&gt;ExceptionInformation[0] ==
4058       EXCEPTION_INFO_EXEC_VIOLATION) {
4059     return EXCEPTION_EXECUTE_HANDLER;
4060   }
4061   return EXCEPTION_CONTINUE_SEARCH;
4062 }
4063 
4064 void nx_check_protection() {
4065   // If NX is enabled we&#39;ll get an exception calling into code on the stack
4066   char code[] = { (char)0xC3 }; // ret
4067   void *code_ptr = (void *)code;
4068   __try {
4069     __asm call code_ptr
4070   } __except(nx_exception_filter((_EXCEPTION_POINTERS*)_exception_info())) {
4071     tty-&gt;print_raw_cr(&quot;NX protection detected.&quot;);
4072   }
4073 }
4074 #endif // _WIN64
4075 #endif // PRODUCT
4076 
4077 // This is called _before_ the global arguments have been parsed
4078 void os::init(void) {
4079   _initial_pid = _getpid();
4080 
4081   init_random(1234567);
4082 
4083   win32::initialize_system_info();
4084   win32::setmode_streams();
4085   init_page_sizes((size_t) win32::vm_page_size());
4086 
4087   // This may be overridden later when argument processing is done.
4088   FLAG_SET_ERGO(bool, UseLargePagesIndividualAllocation, false);
4089 
4090   // Initialize main_process and main_thread
4091   main_process = GetCurrentProcess();  // Remember main_process is a pseudo handle
4092   if (!DuplicateHandle(main_process, GetCurrentThread(), main_process,
4093                        &amp;main_thread, THREAD_ALL_ACCESS, false, 0)) {
4094     fatal(&quot;DuplicateHandle failed\n&quot;);
4095   }
4096   main_thread_id = (int) GetCurrentThreadId();
4097 
4098   // initialize fast thread access - only used for 32-bit
4099   win32::initialize_thread_ptr_offset();
4100 }
4101 
4102 // To install functions for atexit processing
4103 extern &quot;C&quot; {
4104   static void perfMemory_exit_helper() {
4105     perfMemory_exit();
4106   }
4107 }
4108 
4109 static jint initSock();
4110 
4111 // this is called _after_ the global arguments have been parsed
4112 jint os::init_2(void) {
4113 
4114   // This could be set any time but all platforms
4115   // have to set it the same so we have to mirror Solaris.
4116   DEBUG_ONLY(os::set_mutex_init_done();)
4117 
4118   // Setup Windows Exceptions
4119 
4120 #if INCLUDE_AOT
4121   // If AOT is enabled we need to install a vectored exception handler
4122   // in order to forward implicit exceptions from code in AOT
4123   // generated DLLs.  This is necessary since these DLLs are not
4124   // registered for structured exceptions like codecache methods are.
4125   if (UseAOT) {
4126     topLevelVectoredExceptionHandler = AddVectoredExceptionHandler( 1, topLevelVectoredExceptionFilter);
4127   }
4128 #endif
4129 
4130   // for debugging float code generation bugs
4131   if (ForceFloatExceptions) {
4132 #ifndef  _WIN64
4133     static long fp_control_word = 0;
4134     __asm { fstcw fp_control_word }
4135     // see Intel PPro Manual, Vol. 2, p 7-16
4136     const long precision = 0x20;
4137     const long underflow = 0x10;
4138     const long overflow  = 0x08;
4139     const long zero_div  = 0x04;
4140     const long denorm    = 0x02;
4141     const long invalid   = 0x01;
4142     fp_control_word |= invalid;
4143     __asm { fldcw fp_control_word }
4144 #endif
4145   }
4146 
4147   // If stack_commit_size is 0, windows will reserve the default size,
4148   // but only commit a small portion of it.
4149   size_t stack_commit_size = align_up(ThreadStackSize*K, os::vm_page_size());
4150   size_t default_reserve_size = os::win32::default_stack_size();
4151   size_t actual_reserve_size = stack_commit_size;
4152   if (stack_commit_size &lt; default_reserve_size) {
4153     // If stack_commit_size == 0, we want this too
4154     actual_reserve_size = default_reserve_size;
4155   }
4156 
4157   // Check minimum allowable stack size for thread creation and to initialize
4158   // the java system classes, including StackOverflowError - depends on page
4159   // size.  Add two 4K pages for compiler2 recursion in main thread.
4160   // Add in 4*BytesPerWord 4K pages to account for VM stack during
4161   // class initialization depending on 32 or 64 bit VM.
4162   size_t min_stack_allowed =
4163             (size_t)(JavaThread::stack_guard_zone_size() +
4164                      JavaThread::stack_shadow_zone_size() +
4165                      (4*BytesPerWord COMPILER2_PRESENT(+2)) * 4 * K);
4166 
4167   min_stack_allowed = align_up(min_stack_allowed, os::vm_page_size());
4168 
4169   if (actual_reserve_size &lt; min_stack_allowed) {
4170     tty-&gt;print_cr(&quot;\nThe Java thread stack size specified is too small. &quot;
4171                   &quot;Specify at least %dk&quot;,
4172                   min_stack_allowed / K);
4173     return JNI_ERR;
4174   }
4175 
4176   JavaThread::set_stack_size_at_create(stack_commit_size);
4177 
4178   // Calculate theoretical max. size of Threads to guard gainst artifical
4179   // out-of-memory situations, where all available address-space has been
4180   // reserved by thread stacks.
4181   assert(actual_reserve_size != 0, &quot;Must have a stack&quot;);
4182 
4183   // Calculate the thread limit when we should start doing Virtual Memory
4184   // banging. Currently when the threads will have used all but 200Mb of space.
4185   //
4186   // TODO: consider performing a similar calculation for commit size instead
4187   // as reserve size, since on a 64-bit platform we&#39;ll run into that more
4188   // often than running out of virtual memory space.  We can use the
4189   // lower value of the two calculations as the os_thread_limit.
4190   size_t max_address_space = ((size_t)1 &lt;&lt; (BitsPerWord - 1)) - (200 * K * K);
4191   win32::_os_thread_limit = (intx)(max_address_space / actual_reserve_size);
4192 
4193   // at exit methods are called in the reverse order of their registration.
4194   // there is no limit to the number of functions registered. atexit does
4195   // not set errno.
4196 
4197   if (PerfAllowAtExitRegistration) {
4198     // only register atexit functions if PerfAllowAtExitRegistration is set.
4199     // atexit functions can be delayed until process exit time, which
4200     // can be problematic for embedded VM situations. Embedded VMs should
4201     // call DestroyJavaVM() to assure that VM resources are released.
4202 
4203     // note: perfMemory_exit_helper atexit function may be removed in
4204     // the future if the appropriate cleanup code can be added to the
4205     // VM_Exit VMOperation&#39;s doit method.
4206     if (atexit(perfMemory_exit_helper) != 0) {
4207       warning(&quot;os::init_2 atexit(perfMemory_exit_helper) failed&quot;);
4208     }
4209   }
4210 
4211 #ifndef _WIN64
4212   // Print something if NX is enabled (win32 on AMD64)
4213   NOT_PRODUCT(if (PrintMiscellaneous &amp;&amp; Verbose) nx_check_protection());
4214 #endif
4215 
4216   // initialize thread priority policy
4217   prio_init();
4218 
4219   if (UseNUMA &amp;&amp; !ForceNUMA) {
4220     UseNUMA = false; // We don&#39;t fully support this yet
4221   }
4222 
4223   if (UseNUMAInterleaving) {
4224     // first check whether this Windows OS supports VirtualAllocExNuma, if not ignore this flag
4225     bool success = numa_interleaving_init();
4226     if (!success) UseNUMAInterleaving = false;
4227   }
4228 
4229   if (initSock() != JNI_OK) {
4230     return JNI_ERR;
4231   }
4232 
4233   SymbolEngine::recalc_search_path();
4234 
4235   // Initialize data for jdk.internal.misc.Signal
4236   if (!ReduceSignalUsage) {
4237     jdk_misc_signal_init();
4238   }
4239 
4240   return JNI_OK;
4241 }
4242 
4243 // Mark the polling page as unreadable
4244 void os::make_polling_page_unreadable(void) {
4245   DWORD old_status;
4246   if (!VirtualProtect((char *)_polling_page, os::vm_page_size(),
4247                       PAGE_NOACCESS, &amp;old_status)) {
4248     fatal(&quot;Could not disable polling page&quot;);
4249   }
4250 }
4251 
4252 // Mark the polling page as readable
4253 void os::make_polling_page_readable(void) {
4254   DWORD old_status;
4255   if (!VirtualProtect((char *)_polling_page, os::vm_page_size(),
4256                       PAGE_READONLY, &amp;old_status)) {
4257     fatal(&quot;Could not enable polling page&quot;);
4258   }
4259 }
4260 
4261 // combine the high and low DWORD into a ULONGLONG
4262 static ULONGLONG make_double_word(DWORD high_word, DWORD low_word) {
4263   ULONGLONG value = high_word;
4264   value &lt;&lt;= sizeof(high_word) * 8;
4265   value |= low_word;
4266   return value;
4267 }
4268 
4269 // Transfers data from WIN32_FILE_ATTRIBUTE_DATA structure to struct stat
4270 static void file_attribute_data_to_stat(struct stat* sbuf, WIN32_FILE_ATTRIBUTE_DATA file_data) {
4271   ::memset((void*)sbuf, 0, sizeof(struct stat));
4272   sbuf-&gt;st_size = (_off_t)make_double_word(file_data.nFileSizeHigh, file_data.nFileSizeLow);
4273   sbuf-&gt;st_mtime = make_double_word(file_data.ftLastWriteTime.dwHighDateTime,
4274                                   file_data.ftLastWriteTime.dwLowDateTime);
4275   sbuf-&gt;st_ctime = make_double_word(file_data.ftCreationTime.dwHighDateTime,
4276                                   file_data.ftCreationTime.dwLowDateTime);
4277   sbuf-&gt;st_atime = make_double_word(file_data.ftLastAccessTime.dwHighDateTime,
4278                                   file_data.ftLastAccessTime.dwLowDateTime);
4279   if ((file_data.dwFileAttributes &amp; FILE_ATTRIBUTE_DIRECTORY) != 0) {
4280     sbuf-&gt;st_mode |= S_IFDIR;
4281   } else {
4282     sbuf-&gt;st_mode |= S_IFREG;
4283   }
4284 }
4285 
4286 // The following function is adapted from java.base/windows/native/libjava/canonicalize_md.c
4287 // Creates an UNC path from a single byte path. Return buffer is
4288 // allocated in C heap and needs to be freed by the caller.
4289 // Returns NULL on error.
4290 static wchar_t* create_unc_path(const char* path, errno_t &amp;err) {
4291   wchar_t* wpath = NULL;
4292   size_t converted_chars = 0;
4293   size_t path_len = strlen(path) + 1; // includes the terminating NULL
4294   if (path[0] == &#39;\\&#39; &amp;&amp; path[1] == &#39;\\&#39;) {
4295     if (path[2] == &#39;?&#39; &amp;&amp; path[3] == &#39;\\&#39;){
4296       // if it already has a \\?\ don&#39;t do the prefix
4297       wpath = (wchar_t*)os::malloc(path_len * sizeof(wchar_t), mtInternal);
4298       if (wpath != NULL) {
4299         err = ::mbstowcs_s(&amp;converted_chars, wpath, path_len, path, path_len);
4300       } else {
4301         err = ENOMEM;
4302       }
4303     } else {
4304       // only UNC pathname includes double slashes here
4305       wpath = (wchar_t*)os::malloc((path_len + 7) * sizeof(wchar_t), mtInternal);
4306       if (wpath != NULL) {
4307         ::wcscpy(wpath, L&quot;\\\\?\\UNC\0&quot;);
4308         err = ::mbstowcs_s(&amp;converted_chars, &amp;wpath[7], path_len, path, path_len);
4309       } else {
4310         err = ENOMEM;
4311       }
4312     }
4313   } else {
4314     wpath = (wchar_t*)os::malloc((path_len + 4) * sizeof(wchar_t), mtInternal);
4315     if (wpath != NULL) {
4316       ::wcscpy(wpath, L&quot;\\\\?\\\0&quot;);
4317       err = ::mbstowcs_s(&amp;converted_chars, &amp;wpath[4], path_len, path, path_len);
4318     } else {
4319       err = ENOMEM;
4320     }
4321   }
4322   return wpath;
4323 }
4324 
4325 static void destroy_unc_path(wchar_t* wpath) {
4326   os::free(wpath);
4327 }
4328 
4329 int os::stat(const char *path, struct stat *sbuf) {
4330   char* pathbuf = (char*)os::strdup(path, mtInternal);
4331   if (pathbuf == NULL) {
4332     errno = ENOMEM;
4333     return -1;
4334   }
4335   os::native_path(pathbuf);
4336   int ret;
4337   WIN32_FILE_ATTRIBUTE_DATA file_data;
4338   // Not using stat() to avoid the problem described in JDK-6539723
4339   if (strlen(path) &lt; MAX_PATH) {
4340     BOOL bret = ::GetFileAttributesExA(pathbuf, GetFileExInfoStandard, &amp;file_data);
4341     if (!bret) {
4342       errno = ::GetLastError();
4343       ret = -1;
4344     }
4345     else {
4346       file_attribute_data_to_stat(sbuf, file_data);
4347       ret = 0;
4348     }
4349   } else {
4350     errno_t err = ERROR_SUCCESS;
4351     wchar_t* wpath = create_unc_path(pathbuf, err);
4352     if (err != ERROR_SUCCESS) {
4353       if (wpath != NULL) {
4354         destroy_unc_path(wpath);
4355       }
4356       os::free(pathbuf);
4357       errno = err;
4358       return -1;
4359     }
4360     BOOL bret = ::GetFileAttributesExW(wpath, GetFileExInfoStandard, &amp;file_data);
4361     if (!bret) {
4362       errno = ::GetLastError();
4363       ret = -1;
4364     } else {
4365       file_attribute_data_to_stat(sbuf, file_data);
4366       ret = 0;
4367     }
4368     destroy_unc_path(wpath);
4369   }
4370   os::free(pathbuf);
4371   return ret;
4372 }
4373 
4374 
4375 #define FT2INT64(ft) \
4376   ((jlong)((jlong)(ft).dwHighDateTime &lt;&lt; 32 | (julong)(ft).dwLowDateTime))
4377 
4378 
4379 // current_thread_cpu_time(bool) and thread_cpu_time(Thread*, bool)
4380 // are used by JVM M&amp;M and JVMTI to get user+sys or user CPU time
4381 // of a thread.
4382 //
4383 // current_thread_cpu_time() and thread_cpu_time(Thread*) returns
4384 // the fast estimate available on the platform.
4385 
4386 // current_thread_cpu_time() is not optimized for Windows yet
4387 jlong os::current_thread_cpu_time() {
4388   // return user + sys since the cost is the same
4389   return os::thread_cpu_time(Thread::current(), true /* user+sys */);
4390 }
4391 
4392 jlong os::thread_cpu_time(Thread* thread) {
4393   // consistent with what current_thread_cpu_time() returns.
4394   return os::thread_cpu_time(thread, true /* user+sys */);
4395 }
4396 
4397 jlong os::current_thread_cpu_time(bool user_sys_cpu_time) {
4398   return os::thread_cpu_time(Thread::current(), user_sys_cpu_time);
4399 }
4400 
4401 jlong os::thread_cpu_time(Thread* thread, bool user_sys_cpu_time) {
4402   // This code is copy from clasic VM -&gt; hpi::sysThreadCPUTime
4403   // If this function changes, os::is_thread_cpu_time_supported() should too
4404   FILETIME CreationTime;
4405   FILETIME ExitTime;
4406   FILETIME KernelTime;
4407   FILETIME UserTime;
4408 
4409   if (GetThreadTimes(thread-&gt;osthread()-&gt;thread_handle(), &amp;CreationTime,
4410                       &amp;ExitTime, &amp;KernelTime, &amp;UserTime) == 0) {
4411     return -1;
4412   } else if (user_sys_cpu_time) {
4413     return (FT2INT64(UserTime) + FT2INT64(KernelTime)) * 100;
4414   } else {
4415     return FT2INT64(UserTime) * 100;
4416   }
4417 }
4418 
4419 void os::current_thread_cpu_time_info(jvmtiTimerInfo *info_ptr) {
4420   info_ptr-&gt;max_value = ALL_64_BITS;        // the max value -- all 64 bits
4421   info_ptr-&gt;may_skip_backward = false;      // GetThreadTimes returns absolute time
4422   info_ptr-&gt;may_skip_forward = false;       // GetThreadTimes returns absolute time
4423   info_ptr-&gt;kind = JVMTI_TIMER_TOTAL_CPU;   // user+system time is returned
4424 }
4425 
4426 void os::thread_cpu_time_info(jvmtiTimerInfo *info_ptr) {
4427   info_ptr-&gt;max_value = ALL_64_BITS;        // the max value -- all 64 bits
4428   info_ptr-&gt;may_skip_backward = false;      // GetThreadTimes returns absolute time
4429   info_ptr-&gt;may_skip_forward = false;       // GetThreadTimes returns absolute time
4430   info_ptr-&gt;kind = JVMTI_TIMER_TOTAL_CPU;   // user+system time is returned
4431 }
4432 
4433 bool os::is_thread_cpu_time_supported() {
4434   // see os::thread_cpu_time
4435   FILETIME CreationTime;
4436   FILETIME ExitTime;
4437   FILETIME KernelTime;
4438   FILETIME UserTime;
4439 
4440   if (GetThreadTimes(GetCurrentThread(), &amp;CreationTime, &amp;ExitTime,
4441                       &amp;KernelTime, &amp;UserTime) == 0) {
4442     return false;
4443   } else {
4444     return true;
4445   }
4446 }
4447 
4448 // Windows does&#39;t provide a loadavg primitive so this is stubbed out for now.
4449 // It does have primitives (PDH API) to get CPU usage and run queue length.
4450 // &quot;\\Processor(_Total)\\% Processor Time&quot;, &quot;\\System\\Processor Queue Length&quot;
4451 // If we wanted to implement loadavg on Windows, we have a few options:
4452 //
4453 // a) Query CPU usage and run queue length and &quot;fake&quot; an answer by
4454 //    returning the CPU usage if it&#39;s under 100%, and the run queue
4455 //    length otherwise.  It turns out that querying is pretty slow
4456 //    on Windows, on the order of 200 microseconds on a fast machine.
4457 //    Note that on the Windows the CPU usage value is the % usage
4458 //    since the last time the API was called (and the first call
4459 //    returns 100%), so we&#39;d have to deal with that as well.
4460 //
4461 // b) Sample the &quot;fake&quot; answer using a sampling thread and store
4462 //    the answer in a global variable.  The call to loadavg would
4463 //    just return the value of the global, avoiding the slow query.
4464 //
4465 // c) Sample a better answer using exponential decay to smooth the
4466 //    value.  This is basically the algorithm used by UNIX kernels.
4467 //
4468 // Note that sampling thread starvation could affect both (b) and (c).
4469 int os::loadavg(double loadavg[], int nelem) {
4470   return -1;
4471 }
4472 
4473 
4474 // DontYieldALot=false by default: dutifully perform all yields as requested by JVM_Yield()
4475 bool os::dont_yield() {
4476   return DontYieldALot;
4477 }
4478 
4479 // This method is a slightly reworked copy of JDK&#39;s sysOpen
4480 // from src/windows/hpi/src/sys_api_md.c
4481 
4482 int os::open(const char *path, int oflag, int mode) {
4483   char* pathbuf = (char*)os::strdup(path, mtInternal);
4484   if (pathbuf == NULL) {
4485     errno = ENOMEM;
4486     return -1;
4487   }
4488   os::native_path(pathbuf);
4489   int ret;
4490   if (strlen(path) &lt; MAX_PATH) {
4491     ret = ::open(pathbuf, oflag | O_BINARY | O_NOINHERIT, mode);
4492   } else {
4493     errno_t err = ERROR_SUCCESS;
4494     wchar_t* wpath = create_unc_path(pathbuf, err);
4495     if (err != ERROR_SUCCESS) {
4496       if (wpath != NULL) {
4497         destroy_unc_path(wpath);
4498       }
4499       os::free(pathbuf);
4500       errno = err;
4501       return -1;
4502     }
4503     ret = ::_wopen(wpath, oflag | O_BINARY | O_NOINHERIT, mode);
4504     if (ret == -1) {
4505       errno = ::GetLastError();
4506     }
4507     destroy_unc_path(wpath);
4508   }
4509   os::free(pathbuf);
4510   return ret;
4511 }
4512 
4513 FILE* os::open(int fd, const char* mode) {
4514   return ::_fdopen(fd, mode);
4515 }
4516 
4517 // Is a (classpath) directory empty?
4518 bool os::dir_is_empty(const char* path) {
4519   char* search_path = (char*)os::malloc(strlen(path) + 3, mtInternal);
4520   if (search_path == NULL) {
4521     errno = ENOMEM;
4522     return false;
4523   }
4524   strcpy(search_path, path);
4525   os::native_path(search_path);
4526   // Append &quot;*&quot;, or possibly &quot;\\*&quot;, to path
4527   if (search_path[1] == &#39;:&#39; &amp;&amp;
4528        (search_path[2] == &#39;\0&#39; ||
4529          (search_path[2] == &#39;\\&#39; &amp;&amp; search_path[3] == &#39;\0&#39;))) {
4530     // No &#39;\\&#39; needed for cases like &quot;Z:&quot; or &quot;Z:\&quot;
4531     strcat(search_path, &quot;*&quot;);
4532   }
4533   else {
4534     strcat(search_path, &quot;\\*&quot;);
4535   }
4536   errno_t err = ERROR_SUCCESS;
4537   wchar_t* wpath = create_unc_path(search_path, err);
4538   if (err != ERROR_SUCCESS) {
4539     if (wpath != NULL) {
4540       destroy_unc_path(wpath);
4541     }
4542     os::free(search_path);
4543     errno = err;
4544     return false;
4545   }
4546   WIN32_FIND_DATAW fd;
4547   HANDLE f = ::FindFirstFileW(wpath, &amp;fd);
4548   destroy_unc_path(wpath);
4549   bool is_empty = true;
4550   if (f != INVALID_HANDLE_VALUE) {
4551     while (is_empty &amp;&amp; ::FindNextFileW(f, &amp;fd)) {
4552       // An empty directory contains only the current directory file
4553       // and the previous directory file.
4554       if ((wcscmp(fd.cFileName, L&quot;.&quot;) != 0) &amp;&amp;
4555           (wcscmp(fd.cFileName, L&quot;..&quot;) != 0)) {
4556         is_empty = false;
4557       }
4558     }
4559     FindClose(f);
4560   }
4561   os::free(search_path);
4562   return is_empty;
4563 }
4564 
4565 // create binary file, rewriting existing file if required
4566 int os::create_binary_file(const char* path, bool rewrite_existing) {
4567   int oflags = _O_CREAT | _O_WRONLY | _O_BINARY;
4568   if (!rewrite_existing) {
4569     oflags |= _O_EXCL;
4570   }
4571   return ::open(path, oflags, _S_IREAD | _S_IWRITE);
4572 }
4573 
4574 // return current position of file pointer
4575 jlong os::current_file_offset(int fd) {
4576   return (jlong)::_lseeki64(fd, (__int64)0L, SEEK_CUR);
4577 }
4578 
4579 // move file pointer to the specified offset
4580 jlong os::seek_to_file_offset(int fd, jlong offset) {
4581   return (jlong)::_lseeki64(fd, (__int64)offset, SEEK_SET);
4582 }
4583 
4584 
4585 jlong os::lseek(int fd, jlong offset, int whence) {
4586   return (jlong) ::_lseeki64(fd, offset, whence);
4587 }
4588 
4589 ssize_t os::read_at(int fd, void *buf, unsigned int nBytes, jlong offset) {
4590   OVERLAPPED ov;
4591   DWORD nread;
4592   BOOL result;
4593 
4594   ZeroMemory(&amp;ov, sizeof(ov));
4595   ov.Offset = (DWORD)offset;
4596   ov.OffsetHigh = (DWORD)(offset &gt;&gt; 32);
4597 
4598   HANDLE h = (HANDLE)::_get_osfhandle(fd);
4599 
4600   result = ReadFile(h, (LPVOID)buf, nBytes, &amp;nread, &amp;ov);
4601 
4602   return result ? nread : 0;
4603 }
4604 
4605 
4606 // This method is a slightly reworked copy of JDK&#39;s sysNativePath
4607 // from src/windows/hpi/src/path_md.c
4608 
4609 // Convert a pathname to native format.  On win32, this involves forcing all
4610 // separators to be &#39;\\&#39; rather than &#39;/&#39; (both are legal inputs, but Win95
4611 // sometimes rejects &#39;/&#39;) and removing redundant separators.  The input path is
4612 // assumed to have been converted into the character encoding used by the local
4613 // system.  Because this might be a double-byte encoding, care is taken to
4614 // treat double-byte lead characters correctly.
4615 //
4616 // This procedure modifies the given path in place, as the result is never
4617 // longer than the original.  There is no error return; this operation always
4618 // succeeds.
4619 char * os::native_path(char *path) {
4620   char *src = path, *dst = path, *end = path;
4621   char *colon = NULL;  // If a drive specifier is found, this will
4622                        // point to the colon following the drive letter
4623 
4624   // Assumption: &#39;/&#39;, &#39;\\&#39;, &#39;:&#39;, and drive letters are never lead bytes
4625   assert(((!::IsDBCSLeadByte(&#39;/&#39;)) &amp;&amp; (!::IsDBCSLeadByte(&#39;\\&#39;))
4626           &amp;&amp; (!::IsDBCSLeadByte(&#39;:&#39;))), &quot;Illegal lead byte&quot;);
4627 
4628   // Check for leading separators
4629 #define isfilesep(c) ((c) == &#39;/&#39; || (c) == &#39;\\&#39;)
4630   while (isfilesep(*src)) {
4631     src++;
4632   }
4633 
4634   if (::isalpha(*src) &amp;&amp; !::IsDBCSLeadByte(*src) &amp;&amp; src[1] == &#39;:&#39;) {
4635     // Remove leading separators if followed by drive specifier.  This
4636     // hack is necessary to support file URLs containing drive
4637     // specifiers (e.g., &quot;file://c:/path&quot;).  As a side effect,
4638     // &quot;/c:/path&quot; can be used as an alternative to &quot;c:/path&quot;.
4639     *dst++ = *src++;
4640     colon = dst;
4641     *dst++ = &#39;:&#39;;
4642     src++;
4643   } else {
4644     src = path;
4645     if (isfilesep(src[0]) &amp;&amp; isfilesep(src[1])) {
4646       // UNC pathname: Retain first separator; leave src pointed at
4647       // second separator so that further separators will be collapsed
4648       // into the second separator.  The result will be a pathname
4649       // beginning with &quot;\\\\&quot; followed (most likely) by a host name.
4650       src = dst = path + 1;
4651       path[0] = &#39;\\&#39;;     // Force first separator to &#39;\\&#39;
4652     }
4653   }
4654 
4655   end = dst;
4656 
4657   // Remove redundant separators from remainder of path, forcing all
4658   // separators to be &#39;\\&#39; rather than &#39;/&#39;. Also, single byte space
4659   // characters are removed from the end of the path because those
4660   // are not legal ending characters on this operating system.
4661   //
4662   while (*src != &#39;\0&#39;) {
4663     if (isfilesep(*src)) {
4664       *dst++ = &#39;\\&#39;; src++;
4665       while (isfilesep(*src)) src++;
4666       if (*src == &#39;\0&#39;) {
4667         // Check for trailing separator
4668         end = dst;
4669         if (colon == dst - 2) break;  // &quot;z:\\&quot;
4670         if (dst == path + 1) break;   // &quot;\\&quot;
4671         if (dst == path + 2 &amp;&amp; isfilesep(path[0])) {
4672           // &quot;\\\\&quot; is not collapsed to &quot;\\&quot; because &quot;\\\\&quot; marks the
4673           // beginning of a UNC pathname.  Even though it is not, by
4674           // itself, a valid UNC pathname, we leave it as is in order
4675           // to be consistent with the path canonicalizer as well
4676           // as the win32 APIs, which treat this case as an invalid
4677           // UNC pathname rather than as an alias for the root
4678           // directory of the current drive.
4679           break;
4680         }
4681         end = --dst;  // Path does not denote a root directory, so
4682                       // remove trailing separator
4683         break;
4684       }
4685       end = dst;
4686     } else {
4687       if (::IsDBCSLeadByte(*src)) {  // Copy a double-byte character
4688         *dst++ = *src++;
4689         if (*src) *dst++ = *src++;
4690         end = dst;
4691       } else {  // Copy a single-byte character
4692         char c = *src++;
4693         *dst++ = c;
4694         // Space is not a legal ending character
4695         if (c != &#39; &#39;) end = dst;
4696       }
4697     }
4698   }
4699 
4700   *end = &#39;\0&#39;;
4701 
4702   // For &quot;z:&quot;, add &quot;.&quot; to work around a bug in the C runtime library
4703   if (colon == dst - 1) {
4704     path[2] = &#39;.&#39;;
4705     path[3] = &#39;\0&#39;;
4706   }
4707 
4708   return path;
4709 }
4710 
4711 // This code is a copy of JDK&#39;s sysSetLength
4712 // from src/windows/hpi/src/sys_api_md.c
4713 
4714 int os::ftruncate(int fd, jlong length) {
4715   HANDLE h = (HANDLE)::_get_osfhandle(fd);
4716   long high = (long)(length &gt;&gt; 32);
4717   DWORD ret;
4718 
4719   if (h == (HANDLE)(-1)) {
4720     return -1;
4721   }
4722 
4723   ret = ::SetFilePointer(h, (long)(length), &amp;high, FILE_BEGIN);
4724   if ((ret == 0xFFFFFFFF) &amp;&amp; (::GetLastError() != NO_ERROR)) {
4725     return -1;
4726   }
4727 
4728   if (::SetEndOfFile(h) == FALSE) {
4729     return -1;
4730   }
4731 
4732   return 0;
4733 }
4734 
4735 int os::get_fileno(FILE* fp) {
4736   return _fileno(fp);
4737 }
4738 
4739 // This code is a copy of JDK&#39;s sysSync
4740 // from src/windows/hpi/src/sys_api_md.c
4741 // except for the legacy workaround for a bug in Win 98
4742 
4743 int os::fsync(int fd) {
4744   HANDLE handle = (HANDLE)::_get_osfhandle(fd);
4745 
4746   if ((!::FlushFileBuffers(handle)) &amp;&amp;
4747       (GetLastError() != ERROR_ACCESS_DENIED)) {
4748     // from winerror.h
4749     return -1;
4750   }
4751   return 0;
4752 }
4753 
4754 static int nonSeekAvailable(int, long *);
4755 static int stdinAvailable(int, long *);
4756 
4757 // This code is a copy of JDK&#39;s sysAvailable
4758 // from src/windows/hpi/src/sys_api_md.c
4759 
4760 int os::available(int fd, jlong *bytes) {
4761   jlong cur, end;
4762   struct _stati64 stbuf64;
4763 
4764   if (::_fstati64(fd, &amp;stbuf64) &gt;= 0) {
4765     int mode = stbuf64.st_mode;
4766     if (S_ISCHR(mode) || S_ISFIFO(mode)) {
4767       int ret;
4768       long lpbytes;
4769       if (fd == 0) {
4770         ret = stdinAvailable(fd, &amp;lpbytes);
4771       } else {
4772         ret = nonSeekAvailable(fd, &amp;lpbytes);
4773       }
4774       (*bytes) = (jlong)(lpbytes);
4775       return ret;
4776     }
4777     if ((cur = ::_lseeki64(fd, 0L, SEEK_CUR)) == -1) {
4778       return FALSE;
4779     } else if ((end = ::_lseeki64(fd, 0L, SEEK_END)) == -1) {
4780       return FALSE;
4781     } else if (::_lseeki64(fd, cur, SEEK_SET) == -1) {
4782       return FALSE;
4783     }
4784     *bytes = end - cur;
4785     return TRUE;
4786   } else {
4787     return FALSE;
4788   }
4789 }
4790 
4791 void os::flockfile(FILE* fp) {
4792   _lock_file(fp);
4793 }
4794 
4795 void os::funlockfile(FILE* fp) {
4796   _unlock_file(fp);
4797 }
4798 
4799 // This code is a copy of JDK&#39;s nonSeekAvailable
4800 // from src/windows/hpi/src/sys_api_md.c
4801 
4802 static int nonSeekAvailable(int fd, long *pbytes) {
4803   // This is used for available on non-seekable devices
4804   // (like both named and anonymous pipes, such as pipes
4805   //  connected to an exec&#39;d process).
4806   // Standard Input is a special case.
4807   HANDLE han;
4808 
4809   if ((han = (HANDLE) ::_get_osfhandle(fd)) == (HANDLE)(-1)) {
4810     return FALSE;
4811   }
4812 
4813   if (! ::PeekNamedPipe(han, NULL, 0, NULL, (LPDWORD)pbytes, NULL)) {
4814     // PeekNamedPipe fails when at EOF.  In that case we
4815     // simply make *pbytes = 0 which is consistent with the
4816     // behavior we get on Solaris when an fd is at EOF.
4817     // The only alternative is to raise an Exception,
4818     // which isn&#39;t really warranted.
4819     //
4820     if (::GetLastError() != ERROR_BROKEN_PIPE) {
4821       return FALSE;
4822     }
4823     *pbytes = 0;
4824   }
4825   return TRUE;
4826 }
4827 
4828 #define MAX_INPUT_EVENTS 2000
4829 
4830 // This code is a copy of JDK&#39;s stdinAvailable
4831 // from src/windows/hpi/src/sys_api_md.c
4832 
4833 static int stdinAvailable(int fd, long *pbytes) {
4834   HANDLE han;
4835   DWORD numEventsRead = 0;  // Number of events read from buffer
4836   DWORD numEvents = 0;      // Number of events in buffer
4837   DWORD i = 0;              // Loop index
4838   DWORD curLength = 0;      // Position marker
4839   DWORD actualLength = 0;   // Number of bytes readable
4840   BOOL error = FALSE;       // Error holder
4841   INPUT_RECORD *lpBuffer;   // Pointer to records of input events
4842 
4843   if ((han = ::GetStdHandle(STD_INPUT_HANDLE)) == INVALID_HANDLE_VALUE) {
4844     return FALSE;
4845   }
4846 
4847   // Construct an array of input records in the console buffer
4848   error = ::GetNumberOfConsoleInputEvents(han, &amp;numEvents);
4849   if (error == 0) {
4850     return nonSeekAvailable(fd, pbytes);
4851   }
4852 
4853   // lpBuffer must fit into 64K or else PeekConsoleInput fails
4854   if (numEvents &gt; MAX_INPUT_EVENTS) {
4855     numEvents = MAX_INPUT_EVENTS;
4856   }
4857 
4858   lpBuffer = (INPUT_RECORD *)os::malloc(numEvents * sizeof(INPUT_RECORD), mtInternal);
4859   if (lpBuffer == NULL) {
4860     return FALSE;
4861   }
4862 
4863   error = ::PeekConsoleInput(han, lpBuffer, numEvents, &amp;numEventsRead);
4864   if (error == 0) {
4865     os::free(lpBuffer);
4866     return FALSE;
4867   }
4868 
4869   // Examine input records for the number of bytes available
4870   for (i=0; i&lt;numEvents; i++) {
4871     if (lpBuffer[i].EventType == KEY_EVENT) {
4872 
4873       KEY_EVENT_RECORD *keyRecord = (KEY_EVENT_RECORD *)
4874                                       &amp;(lpBuffer[i].Event);
4875       if (keyRecord-&gt;bKeyDown == TRUE) {
4876         CHAR *keyPressed = (CHAR *) &amp;(keyRecord-&gt;uChar);
4877         curLength++;
4878         if (*keyPressed == &#39;\r&#39;) {
4879           actualLength = curLength;
4880         }
4881       }
4882     }
4883   }
4884 
4885   if (lpBuffer != NULL) {
4886     os::free(lpBuffer);
4887   }
4888 
4889   *pbytes = (long) actualLength;
4890   return TRUE;
4891 }
4892 
4893 // Map a block of memory.
4894 char* os::pd_map_memory(int fd, const char* file_name, size_t file_offset,
4895                         char *addr, size_t bytes, bool read_only,
4896                         bool allow_exec) {
4897   HANDLE hFile;
4898   char* base;
4899 
4900   hFile = CreateFile(file_name, GENERIC_READ, FILE_SHARE_READ, NULL,
4901                      OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL);
4902   if (hFile == NULL) {
4903     log_info(os)(&quot;CreateFile() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
4904     return NULL;
4905   }
4906 
4907   if (allow_exec) {
4908     // CreateFileMapping/MapViewOfFileEx can&#39;t map executable memory
4909     // unless it comes from a PE image (which the shared archive is not.)
4910     // Even VirtualProtect refuses to give execute access to mapped memory
4911     // that was not previously executable.
4912     //
4913     // Instead, stick the executable region in anonymous memory.  Yuck.
4914     // Penalty is that ~4 pages will not be shareable - in the future
4915     // we might consider DLLizing the shared archive with a proper PE
4916     // header so that mapping executable + sharing is possible.
4917 
4918     base = (char*) VirtualAlloc(addr, bytes, MEM_COMMIT | MEM_RESERVE,
4919                                 PAGE_READWRITE);
4920     if (base == NULL) {
4921       log_info(os)(&quot;VirtualAlloc() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
4922       CloseHandle(hFile);
4923       return NULL;
4924     }
4925 
4926     DWORD bytes_read;
4927     OVERLAPPED overlapped;
4928     overlapped.Offset = (DWORD)file_offset;
4929     overlapped.OffsetHigh = 0;
4930     overlapped.hEvent = NULL;
4931     // ReadFile guarantees that if the return value is true, the requested
4932     // number of bytes were read before returning.
4933     bool res = ReadFile(hFile, base, (DWORD)bytes, &amp;bytes_read, &amp;overlapped) != 0;
4934     if (!res) {
4935       log_info(os)(&quot;ReadFile() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
4936       release_memory(base, bytes);
4937       CloseHandle(hFile);
4938       return NULL;
4939     }
4940   } else {
4941     HANDLE hMap = CreateFileMapping(hFile, NULL, PAGE_WRITECOPY, 0, 0,
4942                                     NULL /* file_name */);
4943     if (hMap == NULL) {
4944       log_info(os)(&quot;CreateFileMapping() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
4945       CloseHandle(hFile);
4946       return NULL;
4947     }
4948 
4949     DWORD access = read_only ? FILE_MAP_READ : FILE_MAP_COPY;
4950     base = (char*)MapViewOfFileEx(hMap, access, 0, (DWORD)file_offset,
4951                                   (DWORD)bytes, addr);
4952     if (base == NULL) {
4953       log_info(os)(&quot;MapViewOfFileEx() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
4954       CloseHandle(hMap);
4955       CloseHandle(hFile);
4956       return NULL;
4957     }
4958 
4959     if (CloseHandle(hMap) == 0) {
4960       log_info(os)(&quot;CloseHandle(hMap) failed: GetLastError-&gt;%ld.&quot;, GetLastError());
4961       CloseHandle(hFile);
4962       return base;
4963     }
4964   }
4965 
4966   if (allow_exec) {
4967     DWORD old_protect;
4968     DWORD exec_access = read_only ? PAGE_EXECUTE_READ : PAGE_EXECUTE_READWRITE;
4969     bool res = VirtualProtect(base, bytes, exec_access, &amp;old_protect) != 0;
4970 
4971     if (!res) {
4972       log_info(os)(&quot;VirtualProtect() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
4973       // Don&#39;t consider this a hard error, on IA32 even if the
4974       // VirtualProtect fails, we should still be able to execute
4975       CloseHandle(hFile);
4976       return base;
4977     }
4978   }
4979 
4980   if (CloseHandle(hFile) == 0) {
4981     log_info(os)(&quot;CloseHandle(hFile) failed: GetLastError-&gt;%ld.&quot;, GetLastError());
4982     return base;
4983   }
4984 
4985   return base;
4986 }
4987 
4988 
4989 // Remap a block of memory.
4990 char* os::pd_remap_memory(int fd, const char* file_name, size_t file_offset,
4991                           char *addr, size_t bytes, bool read_only,
4992                           bool allow_exec) {
4993   // This OS does not allow existing memory maps to be remapped so we
4994   // have to unmap the memory before we remap it.
4995   if (!os::unmap_memory(addr, bytes)) {
4996     return NULL;
4997   }
4998 
4999   // There is a very small theoretical window between the unmap_memory()
5000   // call above and the map_memory() call below where a thread in native
5001   // code may be able to access an address that is no longer mapped.
5002 
5003   return os::map_memory(fd, file_name, file_offset, addr, bytes,
5004                         read_only, allow_exec);
5005 }
5006 
5007 
5008 // Unmap a block of memory.
5009 // Returns true=success, otherwise false.
5010 
5011 bool os::pd_unmap_memory(char* addr, size_t bytes) {
5012   MEMORY_BASIC_INFORMATION mem_info;
5013   if (VirtualQuery(addr, &amp;mem_info, sizeof(mem_info)) == 0) {
5014     log_info(os)(&quot;VirtualQuery() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5015     return false;
5016   }
5017 
5018   // Executable memory was not mapped using CreateFileMapping/MapViewOfFileEx.
5019   // Instead, executable region was allocated using VirtualAlloc(). See
5020   // pd_map_memory() above.
5021   //
5022   // The following flags should match the &#39;exec_access&#39; flages used for
5023   // VirtualProtect() in pd_map_memory().
5024   if (mem_info.Protect == PAGE_EXECUTE_READ ||
5025       mem_info.Protect == PAGE_EXECUTE_READWRITE) {
5026     return pd_release_memory(addr, bytes);
5027   }
5028 
5029   BOOL result = UnmapViewOfFile(addr);
5030   if (result == 0) {
5031     log_info(os)(&quot;UnmapViewOfFile() failed: GetLastError-&gt;%ld.&quot;, GetLastError());
5032     return false;
5033   }
5034   return true;
5035 }
5036 
5037 void os::pause() {
5038   char filename[MAX_PATH];
5039   if (PauseAtStartupFile &amp;&amp; PauseAtStartupFile[0]) {
5040     jio_snprintf(filename, MAX_PATH, PauseAtStartupFile);
5041   } else {
5042     jio_snprintf(filename, MAX_PATH, &quot;./vm.paused.%d&quot;, current_process_id());
5043   }
5044 
5045   int fd = ::open(filename, O_WRONLY | O_CREAT | O_TRUNC, 0666);
5046   if (fd != -1) {
5047     struct stat buf;
5048     ::close(fd);
5049     while (::stat(filename, &amp;buf) == 0) {
5050       Sleep(100);
5051     }
5052   } else {
5053     jio_fprintf(stderr,
5054                 &quot;Could not open pause file &#39;%s&#39;, continuing immediately.\n&quot;, filename);
5055   }
5056 }
5057 
5058 Thread* os::ThreadCrashProtection::_protected_thread = NULL;
5059 os::ThreadCrashProtection* os::ThreadCrashProtection::_crash_protection = NULL;
5060 volatile intptr_t os::ThreadCrashProtection::_crash_mux = 0;
5061 
5062 os::ThreadCrashProtection::ThreadCrashProtection() {
5063 }
5064 
5065 // See the caveats for this class in os_windows.hpp
5066 // Protects the callback call so that raised OS EXCEPTIONS causes a jump back
5067 // into this method and returns false. If no OS EXCEPTION was raised, returns
5068 // true.
5069 // The callback is supposed to provide the method that should be protected.
5070 //
5071 bool os::ThreadCrashProtection::call(os::CrashProtectionCallback&amp; cb) {
5072 
5073   Thread::muxAcquire(&amp;_crash_mux, &quot;CrashProtection&quot;);
5074 
5075   _protected_thread = Thread::current_or_null();
5076   assert(_protected_thread != NULL, &quot;Cannot crash protect a NULL thread&quot;);
5077 
5078   bool success = true;
5079   __try {
5080     _crash_protection = this;
5081     cb.call();
5082   } __except(EXCEPTION_EXECUTE_HANDLER) {
5083     // only for protection, nothing to do
5084     success = false;
5085   }
5086   _crash_protection = NULL;
5087   _protected_thread = NULL;
5088   Thread::muxRelease(&amp;_crash_mux);
5089   return success;
5090 }
5091 
5092 // An Event wraps a win32 &quot;CreateEvent&quot; kernel handle.
5093 //
5094 // We have a number of choices regarding &quot;CreateEvent&quot; win32 handle leakage:
5095 //
5096 // 1:  When a thread dies return the Event to the EventFreeList, clear the ParkHandle
5097 //     field, and call CloseHandle() on the win32 event handle.  Unpark() would
5098 //     need to be modified to tolerate finding a NULL (invalid) win32 event handle.
5099 //     In addition, an unpark() operation might fetch the handle field, but the
5100 //     event could recycle between the fetch and the SetEvent() operation.
5101 //     SetEvent() would either fail because the handle was invalid, or inadvertently work,
5102 //     as the win32 handle value had been recycled.  In an ideal world calling SetEvent()
5103 //     on an stale but recycled handle would be harmless, but in practice this might
5104 //     confuse other non-Sun code, so it&#39;s not a viable approach.
5105 //
5106 // 2:  Once a win32 event handle is associated with an Event, it remains associated
5107 //     with the Event.  The event handle is never closed.  This could be construed
5108 //     as handle leakage, but only up to the maximum # of threads that have been extant
5109 //     at any one time.  This shouldn&#39;t be an issue, as windows platforms typically
5110 //     permit a process to have hundreds of thousands of open handles.
5111 //
5112 // 3:  Same as (1), but periodically, at stop-the-world time, rundown the EventFreeList
5113 //     and release unused handles.
5114 //
5115 // 4:  Add a CRITICAL_SECTION to the Event to protect LD+SetEvent from LD;ST(null);CloseHandle.
5116 //     It&#39;s not clear, however, that we wouldn&#39;t be trading one type of leak for another.
5117 //
5118 // 5.  Use an RCU-like mechanism (Read-Copy Update).
5119 //     Or perhaps something similar to Maged Michael&#39;s &quot;Hazard pointers&quot;.
5120 //
5121 // We use (2).
5122 //
5123 // TODO-FIXME:
5124 // 1.  Reconcile Doug&#39;s JSR166 j.u.c park-unpark with the objectmonitor implementation.
5125 // 2.  Consider wrapping the WaitForSingleObject(Ex) calls in SEH try/finally blocks
5126 //     to recover from (or at least detect) the dreaded Windows 841176 bug.
5127 // 3.  Collapse the interrupt_event, the JSR166 parker event, and the objectmonitor ParkEvent
5128 //     into a single win32 CreateEvent() handle.
5129 //
5130 // Assumption:
5131 //    Only one parker can exist on an event, which is why we allocate
5132 //    them per-thread. Multiple unparkers can coexist.
5133 //
5134 // _Event transitions in park()
5135 //   -1 =&gt; -1 : illegal
5136 //    1 =&gt;  0 : pass - return immediately
5137 //    0 =&gt; -1 : block; then set _Event to 0 before returning
5138 //
5139 // _Event transitions in unpark()
5140 //    0 =&gt; 1 : just return
5141 //    1 =&gt; 1 : just return
5142 //   -1 =&gt; either 0 or 1; must signal target thread
5143 //         That is, we can safely transition _Event from -1 to either
5144 //         0 or 1.
5145 //
5146 // _Event serves as a restricted-range semaphore.
5147 //   -1 : thread is blocked, i.e. there is a waiter
5148 //    0 : neutral: thread is running or ready,
5149 //        could have been signaled after a wait started
5150 //    1 : signaled - thread is running or ready
5151 //
5152 // Another possible encoding of _Event would be with
5153 // explicit &quot;PARKED&quot; == 01b and &quot;SIGNALED&quot; == 10b bits.
5154 //
5155 
5156 int os::PlatformEvent::park(jlong Millis) {
5157   // Transitions for _Event:
5158   //   -1 =&gt; -1 : illegal
5159   //    1 =&gt;  0 : pass - return immediately
5160   //    0 =&gt; -1 : block; then set _Event to 0 before returning
5161 
5162   guarantee(_ParkHandle != NULL , &quot;Invariant&quot;);
5163   guarantee(Millis &gt; 0          , &quot;Invariant&quot;);
5164 
5165   // CONSIDER: defer assigning a CreateEvent() handle to the Event until
5166   // the initial park() operation.
5167   // Consider: use atomic decrement instead of CAS-loop
5168 
5169   int v;
5170   for (;;) {
5171     v = _Event;
5172     if (Atomic::cmpxchg(v-1, &amp;_Event, v) == v) break;
5173   }
5174   guarantee((v == 0) || (v == 1), &quot;invariant&quot;);
5175   if (v != 0) return OS_OK;
5176 
5177   // Do this the hard way by blocking ...
5178   // TODO: consider a brief spin here, gated on the success of recent
5179   // spin attempts by this thread.
5180   //
5181   // We decompose long timeouts into series of shorter timed waits.
5182   // Evidently large timo values passed in WaitForSingleObject() are problematic on some
5183   // versions of Windows.  See EventWait() for details.  This may be superstition.  Or not.
5184   // We trust the WAIT_TIMEOUT indication and don&#39;t track the elapsed wait time
5185   // with os::javaTimeNanos().  Furthermore, we assume that spurious returns from
5186   // ::WaitForSingleObject() caused by latent ::setEvent() operations will tend
5187   // to happen early in the wait interval.  Specifically, after a spurious wakeup (rv ==
5188   // WAIT_OBJECT_0 but _Event is still &lt; 0) we don&#39;t bother to recompute Millis to compensate
5189   // for the already waited time.  This policy does not admit any new outcomes.
5190   // In the future, however, we might want to track the accumulated wait time and
5191   // adjust Millis accordingly if we encounter a spurious wakeup.
5192 
5193   const int MAXTIMEOUT = 0x10000000;
5194   DWORD rv = WAIT_TIMEOUT;
5195   while (_Event &lt; 0 &amp;&amp; Millis &gt; 0) {
5196     DWORD prd = Millis;     // set prd = MAX (Millis, MAXTIMEOUT)
5197     if (Millis &gt; MAXTIMEOUT) {
5198       prd = MAXTIMEOUT;
5199     }
5200     rv = ::WaitForSingleObject(_ParkHandle, prd);
5201     assert(rv == WAIT_OBJECT_0 || rv == WAIT_TIMEOUT, &quot;WaitForSingleObject failed&quot;);
5202     if (rv == WAIT_TIMEOUT) {
5203       Millis -= prd;
5204     }
5205   }
5206   v = _Event;
5207   _Event = 0;
5208   // see comment at end of os::PlatformEvent::park() below:
5209   OrderAccess::fence();
5210   // If we encounter a nearly simultanous timeout expiry and unpark()
5211   // we return OS_OK indicating we awoke via unpark().
5212   // Implementor&#39;s license -- returning OS_TIMEOUT would be equally valid, however.
5213   return (v &gt;= 0) ? OS_OK : OS_TIMEOUT;
5214 }
5215 
5216 void os::PlatformEvent::park() {
5217   // Transitions for _Event:
5218   //   -1 =&gt; -1 : illegal
5219   //    1 =&gt;  0 : pass - return immediately
5220   //    0 =&gt; -1 : block; then set _Event to 0 before returning
5221 
5222   guarantee(_ParkHandle != NULL, &quot;Invariant&quot;);
5223   // Invariant: Only the thread associated with the Event/PlatformEvent
5224   // may call park().
5225   // Consider: use atomic decrement instead of CAS-loop
5226   int v;
5227   for (;;) {
5228     v = _Event;
5229     if (Atomic::cmpxchg(v-1, &amp;_Event, v) == v) break;
5230   }
5231   guarantee((v == 0) || (v == 1), &quot;invariant&quot;);
5232   if (v != 0) return;
5233 
5234   // Do this the hard way by blocking ...
5235   // TODO: consider a brief spin here, gated on the success of recent
5236   // spin attempts by this thread.
5237   while (_Event &lt; 0) {
5238     DWORD rv = ::WaitForSingleObject(_ParkHandle, INFINITE);
5239     assert(rv == WAIT_OBJECT_0, &quot;WaitForSingleObject failed&quot;);
5240   }
5241 
5242   // Usually we&#39;ll find _Event == 0 at this point, but as
5243   // an optional optimization we clear it, just in case can
5244   // multiple unpark() operations drove _Event up to 1.
5245   _Event = 0;
5246   OrderAccess::fence();
5247   guarantee(_Event &gt;= 0, &quot;invariant&quot;);
5248 }
5249 
5250 void os::PlatformEvent::unpark() {
5251   guarantee(_ParkHandle != NULL, &quot;Invariant&quot;);
5252 
5253   // Transitions for _Event:
5254   //    0 =&gt; 1 : just return
5255   //    1 =&gt; 1 : just return
5256   //   -1 =&gt; either 0 or 1; must signal target thread
5257   //         That is, we can safely transition _Event from -1 to either
5258   //         0 or 1.
5259   // See also: &quot;Semaphores in Plan 9&quot; by Mullender &amp; Cox
5260   //
5261   // Note: Forcing a transition from &quot;-1&quot; to &quot;1&quot; on an unpark() means
5262   // that it will take two back-to-back park() calls for the owning
5263   // thread to block. This has the benefit of forcing a spurious return
5264   // from the first park() call after an unpark() call which will help
5265   // shake out uses of park() and unpark() without condition variables.
5266 
5267   if (Atomic::xchg(1, &amp;_Event) &gt;= 0) return;
5268 
5269   ::SetEvent(_ParkHandle);
5270 }
5271 
5272 
5273 // JSR166
5274 // -------------------------------------------------------
5275 
5276 // The Windows implementation of Park is very straightforward: Basic
5277 // operations on Win32 Events turn out to have the right semantics to
5278 // use them directly. We opportunistically resuse the event inherited
5279 // from Monitor.
5280 
5281 void Parker::park(bool isAbsolute, jlong time) {
5282   guarantee(_ParkEvent != NULL, &quot;invariant&quot;);
5283   // First, demultiplex/decode time arguments
5284   if (time &lt; 0) { // don&#39;t wait
5285     return;
5286   } else if (time == 0 &amp;&amp; !isAbsolute) {
5287     time = INFINITE;
5288   } else if (isAbsolute) {
5289     time -= os::javaTimeMillis(); // convert to relative time
5290     if (time &lt;= 0) {  // already elapsed
5291       return;
5292     }
5293   } else { // relative
5294     time /= 1000000;  // Must coarsen from nanos to millis
5295     if (time == 0) {  // Wait for the minimal time unit if zero
5296       time = 1;
5297     }
5298   }
5299 
5300   JavaThread* thread = JavaThread::current();
5301 
5302   // Don&#39;t wait if interrupted or already triggered
5303   if (Thread::is_interrupted(thread, false) ||
5304       WaitForSingleObject(_ParkEvent, 0) == WAIT_OBJECT_0) {
5305     ResetEvent(_ParkEvent);
5306     return;
5307   } else {
5308     ThreadBlockInVM tbivm(thread);
5309     OSThreadWaitState osts(thread-&gt;osthread(), false /* not Object.wait() */);
5310     thread-&gt;set_suspend_equivalent();
5311 
5312     WaitForSingleObject(_ParkEvent, time);
5313     ResetEvent(_ParkEvent);
5314 
5315     // If externally suspended while waiting, re-suspend
5316     if (thread-&gt;handle_special_suspend_equivalent_condition()) {
5317       thread-&gt;java_suspend_self();
5318     }
5319   }
5320 }
5321 
5322 void Parker::unpark() {
5323   guarantee(_ParkEvent != NULL, &quot;invariant&quot;);
5324   SetEvent(_ParkEvent);
5325 }
5326 
5327 // Platform Monitor implementation
5328 
5329 // Must already be locked
5330 int os::PlatformMonitor::wait(jlong millis) {
5331   assert(millis &gt;= 0, &quot;negative timeout&quot;);
5332   int ret = OS_TIMEOUT;
5333   int status = SleepConditionVariableCS(&amp;_cond, &amp;_mutex,
5334                                         millis == 0 ? INFINITE : millis);
5335   if (status != 0) {
5336     ret = OS_OK;
5337   }
5338   #ifndef PRODUCT
5339   else {
5340     DWORD err = GetLastError();
5341     assert(err == ERROR_TIMEOUT, &quot;SleepConditionVariableCS: %ld:&quot;, err);
5342   }
5343   #endif
5344   return ret;
5345 }
5346 
5347 // Run the specified command in a separate process. Return its exit value,
5348 // or -1 on failure (e.g. can&#39;t create a new process).
5349 int os::fork_and_exec(char* cmd, bool use_vfork_if_available) {
5350   STARTUPINFO si;
5351   PROCESS_INFORMATION pi;
5352   DWORD exit_code;
5353 
5354   char * cmd_string;
5355   char * cmd_prefix = &quot;cmd /C &quot;;
5356   size_t len = strlen(cmd) + strlen(cmd_prefix) + 1;
5357   cmd_string = NEW_C_HEAP_ARRAY_RETURN_NULL(char, len, mtInternal);
5358   if (cmd_string == NULL) {
5359     return -1;
5360   }
5361   cmd_string[0] = &#39;\0&#39;;
5362   strcat(cmd_string, cmd_prefix);
5363   strcat(cmd_string, cmd);
5364 
5365   // now replace all &#39;\n&#39; with &#39;&amp;&#39;
5366   char * substring = cmd_string;
5367   while ((substring = strchr(substring, &#39;\n&#39;)) != NULL) {
5368     substring[0] = &#39;&amp;&#39;;
5369     substring++;
5370   }
5371   memset(&amp;si, 0, sizeof(si));
5372   si.cb = sizeof(si);
5373   memset(&amp;pi, 0, sizeof(pi));
5374   BOOL rslt = CreateProcess(NULL,   // executable name - use command line
5375                             cmd_string,    // command line
5376                             NULL,   // process security attribute
5377                             NULL,   // thread security attribute
5378                             TRUE,   // inherits system handles
5379                             0,      // no creation flags
5380                             NULL,   // use parent&#39;s environment block
5381                             NULL,   // use parent&#39;s starting directory
5382                             &amp;si,    // (in) startup information
5383                             &amp;pi);   // (out) process information
5384 
5385   if (rslt) {
5386     // Wait until child process exits.
5387     WaitForSingleObject(pi.hProcess, INFINITE);
5388 
5389     GetExitCodeProcess(pi.hProcess, &amp;exit_code);
5390 
5391     // Close process and thread handles.
5392     CloseHandle(pi.hProcess);
5393     CloseHandle(pi.hThread);
5394   } else {
5395     exit_code = -1;
5396   }
5397 
5398   FREE_C_HEAP_ARRAY(char, cmd_string);
5399   return (int)exit_code;
5400 }
5401 
5402 bool os::find(address addr, outputStream* st) {
5403   int offset = -1;
5404   bool result = false;
5405   char buf[256];
5406   if (os::dll_address_to_library_name(addr, buf, sizeof(buf), &amp;offset)) {
5407     st-&gt;print(PTR_FORMAT &quot; &quot;, addr);
5408     if (strlen(buf) &lt; sizeof(buf) - 1) {
5409       char* p = strrchr(buf, &#39;\\&#39;);
5410       if (p) {
5411         st-&gt;print(&quot;%s&quot;, p + 1);
5412       } else {
5413         st-&gt;print(&quot;%s&quot;, buf);
5414       }
5415     } else {
5416         // The library name is probably truncated. Let&#39;s omit the library name.
5417         // See also JDK-8147512.
5418     }
5419     if (os::dll_address_to_function_name(addr, buf, sizeof(buf), &amp;offset)) {
5420       st-&gt;print(&quot;::%s + 0x%x&quot;, buf, offset);
5421     }
5422     st-&gt;cr();
5423     result = true;
5424   }
5425   return result;
5426 }
5427 
5428 static jint initSock() {
5429   WSADATA wsadata;
5430 
5431   if (WSAStartup(MAKEWORD(2,2), &amp;wsadata) != 0) {
5432     jio_fprintf(stderr, &quot;Could not initialize Winsock (error: %d)\n&quot;,
5433                 ::GetLastError());
5434     return JNI_ERR;
5435   }
5436   return JNI_OK;
5437 }
5438 
5439 struct hostent* os::get_host_by_name(char* name) {
5440   return (struct hostent*)gethostbyname(name);
5441 }
5442 
5443 int os::socket_close(int fd) {
5444   return ::closesocket(fd);
5445 }
5446 
5447 int os::socket(int domain, int type, int protocol) {
5448   return ::socket(domain, type, protocol);
5449 }
5450 
5451 int os::connect(int fd, struct sockaddr* him, socklen_t len) {
5452   return ::connect(fd, him, len);
5453 }
5454 
5455 int os::recv(int fd, char* buf, size_t nBytes, uint flags) {
5456   return ::recv(fd, buf, (int)nBytes, flags);
5457 }
5458 
5459 int os::send(int fd, char* buf, size_t nBytes, uint flags) {
5460   return ::send(fd, buf, (int)nBytes, flags);
5461 }
5462 
5463 int os::raw_send(int fd, char* buf, size_t nBytes, uint flags) {
5464   return ::send(fd, buf, (int)nBytes, flags);
5465 }
5466 
5467 // WINDOWS CONTEXT Flags for THREAD_SAMPLING
5468 #if defined(IA32)
5469   #define sampling_context_flags (CONTEXT_FULL | CONTEXT_FLOATING_POINT | CONTEXT_EXTENDED_REGISTERS)
5470 #elif defined (AMD64)
5471   #define sampling_context_flags (CONTEXT_FULL | CONTEXT_FLOATING_POINT)
5472 #endif
5473 
5474 // returns true if thread could be suspended,
5475 // false otherwise
5476 static bool do_suspend(HANDLE* h) {
5477   if (h != NULL) {
5478     if (SuspendThread(*h) != ~0) {
5479       return true;
5480     }
5481   }
5482   return false;
5483 }
5484 
5485 // resume the thread
5486 // calling resume on an active thread is a no-op
5487 static void do_resume(HANDLE* h) {
5488   if (h != NULL) {
5489     ResumeThread(*h);
5490   }
5491 }
5492 
5493 // retrieve a suspend/resume context capable handle
5494 // from the tid. Caller validates handle return value.
5495 void get_thread_handle_for_extended_context(HANDLE* h,
5496                                             OSThread::thread_id_t tid) {
5497   if (h != NULL) {
5498     *h = OpenThread(THREAD_SUSPEND_RESUME | THREAD_GET_CONTEXT | THREAD_QUERY_INFORMATION, FALSE, tid);
5499   }
5500 }
5501 
5502 // Thread sampling implementation
5503 //
5504 void os::SuspendedThreadTask::internal_do_task() {
5505   CONTEXT    ctxt;
5506   HANDLE     h = NULL;
5507 
5508   // get context capable handle for thread
5509   get_thread_handle_for_extended_context(&amp;h, _thread-&gt;osthread()-&gt;thread_id());
5510 
5511   // sanity
5512   if (h == NULL || h == INVALID_HANDLE_VALUE) {
5513     return;
5514   }
5515 
5516   // suspend the thread
5517   if (do_suspend(&amp;h)) {
5518     ctxt.ContextFlags = sampling_context_flags;
5519     // get thread context
5520     GetThreadContext(h, &amp;ctxt);
5521     SuspendedThreadTaskContext context(_thread, &amp;ctxt);
5522     // pass context to Thread Sampling impl
5523     do_task(context);
5524     // resume thread
5525     do_resume(&amp;h);
5526   }
5527 
5528   // close handle
5529   CloseHandle(h);
5530 }
5531 
5532 bool os::start_debugging(char *buf, int buflen) {
5533   int len = (int)strlen(buf);
5534   char *p = &amp;buf[len];
5535 
5536   jio_snprintf(p, buflen-len,
5537              &quot;\n\n&quot;
5538              &quot;Do you want to debug the problem?\n\n&quot;
5539              &quot;To debug, attach Visual Studio to process %d; then switch to thread 0x%x\n&quot;
5540              &quot;Select &#39;Yes&#39; to launch Visual Studio automatically (PATH must include msdev)\n&quot;
5541              &quot;Otherwise, select &#39;No&#39; to abort...&quot;,
5542              os::current_process_id(), os::current_thread_id());
5543 
5544   bool yes = os::message_box(&quot;Unexpected Error&quot;, buf);
5545 
5546   if (yes) {
5547     // os::breakpoint() calls DebugBreak(), which causes a breakpoint
5548     // exception. If VM is running inside a debugger, the debugger will
5549     // catch the exception. Otherwise, the breakpoint exception will reach
5550     // the default windows exception handler, which can spawn a debugger and
5551     // automatically attach to the dying VM.
5552     os::breakpoint();
5553     yes = false;
5554   }
5555   return yes;
5556 }
5557 
5558 void* os::get_default_process_handle() {
5559   return (void*)GetModuleHandle(NULL);
5560 }
5561 
5562 // Builds a platform dependent Agent_OnLoad_&lt;lib_name&gt; function name
5563 // which is used to find statically linked in agents.
5564 // Additionally for windows, takes into account __stdcall names.
5565 // Parameters:
5566 //            sym_name: Symbol in library we are looking for
5567 //            lib_name: Name of library to look in, NULL for shared libs.
5568 //            is_absolute_path == true if lib_name is absolute path to agent
5569 //                                     such as &quot;C:/a/b/L.dll&quot;
5570 //            == false if only the base name of the library is passed in
5571 //               such as &quot;L&quot;
5572 char* os::build_agent_function_name(const char *sym_name, const char *lib_name,
5573                                     bool is_absolute_path) {
5574   char *agent_entry_name;
5575   size_t len;
5576   size_t name_len;
5577   size_t prefix_len = strlen(JNI_LIB_PREFIX);
5578   size_t suffix_len = strlen(JNI_LIB_SUFFIX);
5579   const char *start;
5580 
5581   if (lib_name != NULL) {
5582     len = name_len = strlen(lib_name);
5583     if (is_absolute_path) {
5584       // Need to strip path, prefix and suffix
5585       if ((start = strrchr(lib_name, *os::file_separator())) != NULL) {
5586         lib_name = ++start;
5587       } else {
5588         // Need to check for drive prefix
5589         if ((start = strchr(lib_name, &#39;:&#39;)) != NULL) {
5590           lib_name = ++start;
5591         }
5592       }
5593       if (len &lt;= (prefix_len + suffix_len)) {
5594         return NULL;
5595       }
5596       lib_name += prefix_len;
5597       name_len = strlen(lib_name) - suffix_len;
5598     }
5599   }
5600   len = (lib_name != NULL ? name_len : 0) + strlen(sym_name) + 2;
5601   agent_entry_name = NEW_C_HEAP_ARRAY_RETURN_NULL(char, len, mtThread);
5602   if (agent_entry_name == NULL) {
5603     return NULL;
5604   }
5605   if (lib_name != NULL) {
5606     const char *p = strrchr(sym_name, &#39;@&#39;);
5607     if (p != NULL &amp;&amp; p != sym_name) {
5608       // sym_name == _Agent_OnLoad@XX
5609       strncpy(agent_entry_name, sym_name, (p - sym_name));
5610       agent_entry_name[(p-sym_name)] = &#39;\0&#39;;
5611       // agent_entry_name == _Agent_OnLoad
5612       strcat(agent_entry_name, &quot;_&quot;);
5613       strncat(agent_entry_name, lib_name, name_len);
5614       strcat(agent_entry_name, p);
5615       // agent_entry_name == _Agent_OnLoad_lib_name@XX
5616     } else {
5617       strcpy(agent_entry_name, sym_name);
5618       strcat(agent_entry_name, &quot;_&quot;);
5619       strncat(agent_entry_name, lib_name, name_len);
5620     }
5621   } else {
5622     strcpy(agent_entry_name, sym_name);
5623   }
5624   return agent_entry_name;
5625 }
5626 
5627 #ifndef PRODUCT
5628 
5629 // test the code path in reserve_memory_special() that tries to allocate memory in a single
5630 // contiguous memory block at a particular address.
5631 // The test first tries to find a good approximate address to allocate at by using the same
5632 // method to allocate some memory at any address. The test then tries to allocate memory in
5633 // the vicinity (not directly after it to avoid possible by-chance use of that location)
5634 // This is of course only some dodgy assumption, there is no guarantee that the vicinity of
5635 // the previously allocated memory is available for allocation. The only actual failure
5636 // that is reported is when the test tries to allocate at a particular location but gets a
5637 // different valid one. A NULL return value at this point is not considered an error but may
5638 // be legitimate.
5639 void TestReserveMemorySpecial_test() {
5640   if (!UseLargePages) {
5641     return;
5642   }
5643   // save current value of globals
5644   bool old_use_large_pages_individual_allocation = UseLargePagesIndividualAllocation;
5645   bool old_use_numa_interleaving = UseNUMAInterleaving;
5646 
5647   // set globals to make sure we hit the correct code path
5648   UseLargePagesIndividualAllocation = UseNUMAInterleaving = false;
5649 
5650   // do an allocation at an address selected by the OS to get a good one.
5651   const size_t large_allocation_size = os::large_page_size() * 4;
5652   char* result = os::reserve_memory_special(large_allocation_size, os::large_page_size(), NULL, false);
5653   if (result == NULL) {
5654   } else {
5655     os::release_memory_special(result, large_allocation_size);
5656 
5657     // allocate another page within the recently allocated memory area which seems to be a good location. At least
5658     // we managed to get it once.
5659     const size_t expected_allocation_size = os::large_page_size();
5660     char* expected_location = result + os::large_page_size();
5661     char* actual_location = os::reserve_memory_special(expected_allocation_size, os::large_page_size(), expected_location, false);
5662     if (actual_location == NULL) {
5663     } else {
5664       // release memory
5665       os::release_memory_special(actual_location, expected_allocation_size);
5666       // only now check, after releasing any memory to avoid any leaks.
5667       assert(actual_location == expected_location,
5668              &quot;Failed to allocate memory at requested location &quot; PTR_FORMAT &quot; of size &quot; SIZE_FORMAT &quot;, is &quot; PTR_FORMAT &quot; instead&quot;,
5669              expected_location, expected_allocation_size, actual_location);
5670     }
5671   }
5672 
5673   // restore globals
5674   UseLargePagesIndividualAllocation = old_use_large_pages_individual_allocation;
5675   UseNUMAInterleaving = old_use_numa_interleaving;
5676 }
5677 #endif // PRODUCT
5678 
5679 /*
5680   All the defined signal names for Windows.
5681 
5682   NOTE that not all of these names are accepted by FindSignal!
5683 
5684   For various reasons some of these may be rejected at runtime.
5685 
5686   Here are the names currently accepted by a user of sun.misc.Signal with
5687   1.4.1 (ignoring potential interaction with use of chaining, etc):
5688 
5689      (LIST TBD)
5690 
5691 */
5692 int os::get_signal_number(const char* name) {
5693   static const struct {
5694     char* name;
5695     int   number;
5696   } siglabels [] =
5697     // derived from version 6.0 VC98/include/signal.h
5698   {&quot;ABRT&quot;,      SIGABRT,        // abnormal termination triggered by abort cl
5699   &quot;FPE&quot;,        SIGFPE,         // floating point exception
5700   &quot;SEGV&quot;,       SIGSEGV,        // segment violation
5701   &quot;INT&quot;,        SIGINT,         // interrupt
5702   &quot;TERM&quot;,       SIGTERM,        // software term signal from kill
5703   &quot;BREAK&quot;,      SIGBREAK,       // Ctrl-Break sequence
5704   &quot;ILL&quot;,        SIGILL};        // illegal instruction
5705   for (unsigned i = 0; i &lt; ARRAY_SIZE(siglabels); ++i) {
5706     if (strcmp(name, siglabels[i].name) == 0) {
5707       return siglabels[i].number;
5708     }
5709   }
5710   return -1;
5711 }
5712 
5713 // Fast current thread access
5714 
5715 int os::win32::_thread_ptr_offset = 0;
5716 
5717 static void call_wrapper_dummy() {}
5718 
5719 // We need to call the os_exception_wrapper once so that it sets
5720 // up the offset from FS of the thread pointer.
5721 void os::win32::initialize_thread_ptr_offset() {
5722   os::os_exception_wrapper((java_call_t)call_wrapper_dummy,
5723                            NULL, NULL, NULL, NULL);
5724 }
    </pre>
  </body>
</html>