<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.core.amd64/src/org/graalvm/compiler/core/amd64/AMD64ArithmeticLIRGenerator.java</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AMD64AddressNode.java.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../../index.html" target="_top">index</a> <a href="AMD64LIRGenerator.java.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.core.amd64/src/org/graalvm/compiler/core/amd64/AMD64ArithmeticLIRGenerator.java</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  40 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSD;
  41 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSS;
  42 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSX;
  43 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSXB;
  44 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSXD;
  45 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVZX;
  46 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVZXB;
  47 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.POPCNT;
  48 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.TEST;
  49 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.TESTB;
  50 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.TZCNT;
  51 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.ROL;
  52 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.ROR;
  53 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.SAR;
  54 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.SHL;
  55 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.SHR;
  56 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VADDSD;
  57 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VADDSS;
  58 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VDIVSD;
  59 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VDIVSS;


  60 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VMULSD;
  61 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VMULSS;
  62 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VORPD;
  63 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VORPS;
  64 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VSUBSD;
  65 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VSUBSS;
  66 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VXORPD;
  67 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VXORPS;
  68 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.BYTE;
  69 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.DWORD;
  70 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.PD;
  71 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.PS;
  72 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.QWORD;
  73 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.SD;
  74 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.SS;
  75 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.WORD;
  76 import static org.graalvm.compiler.core.common.GraalOptions.GeneratePIC;
  77 import static org.graalvm.compiler.lir.LIRValueUtil.asConstantValue;
  78 import static org.graalvm.compiler.lir.LIRValueUtil.asJavaConstant;
  79 import static org.graalvm.compiler.lir.LIRValueUtil.isConstantValue;
</pre>
<hr />
<pre>
 103 import org.graalvm.compiler.lir.LIRFrameState;
 104 import org.graalvm.compiler.lir.LIRValueUtil;
 105 import org.graalvm.compiler.lir.Variable;
 106 import org.graalvm.compiler.lir.amd64.AMD64AddressValue;
 107 import org.graalvm.compiler.lir.amd64.AMD64Arithmetic.FPDivRemOp;
 108 import org.graalvm.compiler.lir.amd64.AMD64ArithmeticLIRGeneratorTool;
 109 import org.graalvm.compiler.lir.amd64.AMD64Binary;
 110 import org.graalvm.compiler.lir.amd64.AMD64BinaryConsumer;
 111 import org.graalvm.compiler.lir.amd64.AMD64ClearRegisterOp;
 112 import org.graalvm.compiler.lir.amd64.AMD64MathCosOp;
 113 import org.graalvm.compiler.lir.amd64.AMD64MathExpOp;
 114 import org.graalvm.compiler.lir.amd64.AMD64MathLog10Op;
 115 import org.graalvm.compiler.lir.amd64.AMD64MathLogOp;
 116 import org.graalvm.compiler.lir.amd64.AMD64MathPowOp;
 117 import org.graalvm.compiler.lir.amd64.AMD64MathSinOp;
 118 import org.graalvm.compiler.lir.amd64.AMD64MathTanOp;
 119 import org.graalvm.compiler.lir.amd64.AMD64Move;
 120 import org.graalvm.compiler.lir.amd64.AMD64MulDivOp;
 121 import org.graalvm.compiler.lir.amd64.AMD64ShiftOp;
 122 import org.graalvm.compiler.lir.amd64.AMD64SignExtendOp;

 123 import org.graalvm.compiler.lir.amd64.AMD64Unary;
 124 import org.graalvm.compiler.lir.amd64.vector.AMD64VectorBinary;

 125 import org.graalvm.compiler.lir.amd64.vector.AMD64VectorBinary.AVXBinaryOp;
 126 import org.graalvm.compiler.lir.amd64.vector.AMD64VectorUnary;
 127 import org.graalvm.compiler.lir.gen.ArithmeticLIRGenerator;
 128 
 129 import jdk.vm.ci.amd64.AMD64;
 130 import jdk.vm.ci.amd64.AMD64.CPUFeature;
 131 import jdk.vm.ci.amd64.AMD64Kind;
 132 import jdk.vm.ci.code.CodeUtil;
 133 import jdk.vm.ci.code.Register;
 134 import jdk.vm.ci.code.RegisterValue;
 135 import jdk.vm.ci.code.TargetDescription;
 136 import jdk.vm.ci.meta.AllocatableValue;
 137 import jdk.vm.ci.meta.Constant;
 138 import jdk.vm.ci.meta.JavaConstant;
 139 import jdk.vm.ci.meta.JavaKind;
 140 import jdk.vm.ci.meta.PlatformKind;
 141 import jdk.vm.ci.meta.VMConstant;
 142 import jdk.vm.ci.meta.Value;
 143 import jdk.vm.ci.meta.ValueKind;
 144 
</pre>
<hr />
<pre>
 429                 return emitMulHigh(AMD64MOp.IMUL, DWORD, a, b);
 430             case QWORD:
 431                 return emitMulHigh(AMD64MOp.IMUL, QWORD, a, b);
 432             default:
 433                 throw GraalError.shouldNotReachHere();
 434         }
 435     }
 436 
 437     @Override
 438     public Value emitUMulHigh(Value a, Value b) {
 439         switch ((AMD64Kind) a.getPlatformKind()) {
 440             case DWORD:
 441                 return emitMulHigh(AMD64MOp.MUL, DWORD, a, b);
 442             case QWORD:
 443                 return emitMulHigh(AMD64MOp.MUL, QWORD, a, b);
 444             default:
 445                 throw GraalError.shouldNotReachHere();
 446         }
 447     }
 448 







 449     public Value emitBinaryMemory(AMD64RMOp op, OperandSize size, AllocatableValue a, AMD64AddressValue location, LIRFrameState state) {
 450         Variable result = getLIRGen().newVariable(LIRKind.combine(a));
 451         getLIRGen().append(new AMD64Binary.MemoryTwoOp(op, size, result, a, location, state));
 452         return result;
 453     }
 454 
 455     protected Value emitConvertMemoryOp(PlatformKind kind, AMD64RMOp op, OperandSize size, AMD64AddressValue address, LIRFrameState state) {
 456         Variable result = getLIRGen().newVariable(LIRKind.value(kind));
 457         getLIRGen().append(new AMD64Unary.MemoryOp(op, size, result, address, state));
 458         return result;
 459     }
 460 
 461     protected Value emitZeroExtendMemory(AMD64Kind memoryKind, int resultBits, AMD64AddressValue address, LIRFrameState state) {
 462         // Issue a zero extending load of the proper bit size and set the result to
 463         // the proper kind.
 464         Variable result = getLIRGen().newVariable(LIRKind.value(resultBits &lt;= 32 ? AMD64Kind.DWORD : AMD64Kind.QWORD));
 465         switch (memoryKind) {
 466             case BYTE:
 467                 getLIRGen().append(new AMD64Unary.MemoryOp(MOVZXB, DWORD, result, address, state));
 468                 break;
</pre>
<hr />
<pre>
 672             case DOUBLE:
 673                 if (isAvx) {
 674                     return emitBinary(resultKind, VXORPD, a, b);
 675                 } else {
 676                     return emitBinary(resultKind, SSEOp.XOR, PD, true, a, b);
 677                 }
 678             default:
 679                 throw GraalError.shouldNotReachHere();
 680         }
 681     }
 682 
 683     private Variable emitShift(AMD64Shift op, OperandSize size, Value a, Value b) {
 684         Variable result = getLIRGen().newVariable(LIRKind.combine(a, b).changeType(a.getPlatformKind()));
 685         AllocatableValue input = asAllocatable(a);
 686         if (isJavaConstant(b)) {
 687             JavaConstant c = asJavaConstant(b);
 688             if (c.asLong() == 1) {
 689                 getLIRGen().append(new AMD64Unary.MOp(op.m1Op, size, result, input));
 690             } else {
 691                 /*
<span class="line-modified"> 692                  * c is implicitly masked to 5 or 6 bits by the CPU, so casting it to (int) is</span>
<span class="line-removed"> 693                  * always correct, even without the NumUtil.is32bit() test.</span>
 694                  */
<span class="line-modified"> 695                 getLIRGen().append(new AMD64Binary.ConstOp(op.miOp, size, result, input, (int) c.asLong()));</span>
 696             }
 697         } else {
 698             getLIRGen().emitMove(RCX_I, b);
 699             getLIRGen().append(new AMD64ShiftOp(op.mcOp, size, result, input, RCX_I));
 700         }
 701         return result;
 702     }
 703 
 704     @Override
 705     public Variable emitShl(Value a, Value b) {
 706         switch ((AMD64Kind) a.getPlatformKind()) {
 707             case DWORD:
 708                 return emitShift(SHL, DWORD, a, b);
 709             case QWORD:
 710                 return emitShift(SHL, QWORD, a, b);
 711             default:
 712                 throw GraalError.shouldNotReachHere();
 713         }
 714     }
 715 
</pre>
<hr />
<pre>
 945 
 946     @Override
 947     public Variable emitBitScanForward(Value value) {
 948         Variable result = getLIRGen().newVariable(LIRKind.combine(value).changeType(AMD64Kind.DWORD));
 949         getLIRGen().append(new AMD64Unary.RMOp(BSF, QWORD, result, asAllocatable(value)));
 950         return result;
 951     }
 952 
 953     @Override
 954     public Variable emitBitScanReverse(Value value) {
 955         Variable result = getLIRGen().newVariable(LIRKind.combine(value).changeType(AMD64Kind.DWORD));
 956         assert ((AMD64Kind) value.getPlatformKind()).isInteger();
 957         if (value.getPlatformKind() == AMD64Kind.QWORD) {
 958             getLIRGen().append(new AMD64Unary.RMOp(BSR, QWORD, result, asAllocatable(value)));
 959         } else {
 960             getLIRGen().append(new AMD64Unary.RMOp(BSR, DWORD, result, asAllocatable(value)));
 961         }
 962         return result;
 963     }
 964 
















 965     @Override
 966     public Value emitCountLeadingZeros(Value value) {
 967         Variable result = getLIRGen().newVariable(LIRKind.combine(value).changeType(AMD64Kind.DWORD));
 968         assert ((AMD64Kind) value.getPlatformKind()).isInteger();
 969         if (value.getPlatformKind() == AMD64Kind.QWORD) {
 970             getLIRGen().append(new AMD64Unary.RMOp(LZCNT, QWORD, result, asAllocatable(value)));
 971         } else {
 972             getLIRGen().append(new AMD64Unary.RMOp(LZCNT, DWORD, result, asAllocatable(value)));
 973         }
 974         return result;
 975     }
 976 
 977     @Override
 978     public Value emitCountTrailingZeros(Value value) {
 979         Variable result = getLIRGen().newVariable(LIRKind.combine(value).changeType(AMD64Kind.DWORD));
 980         assert ((AMD64Kind) value.getPlatformKind()).isInteger();
 981         if (value.getPlatformKind() == AMD64Kind.QWORD) {
 982             getLIRGen().append(new AMD64Unary.RMOp(TZCNT, QWORD, result, asAllocatable(value)));
 983         } else {
 984             getLIRGen().append(new AMD64Unary.RMOp(TZCNT, DWORD, result, asAllocatable(value)));
</pre>
<hr />
<pre>
1262                 getLIRGen().append(new AMD64BinaryConsumer.Op(SSEOp.UCOMIS, PS, left, asAllocatable(right)));
1263                 return;
1264             case DOUBLE:
1265                 getLIRGen().append(new AMD64BinaryConsumer.Op(SSEOp.UCOMIS, PD, left, asAllocatable(right)));
1266                 return;
1267             default:
1268                 throw GraalError.shouldNotReachHere(&quot;unexpected kind: &quot; + cmpKind);
1269         }
1270 
1271         if (isConstantValue(right)) {
1272             Constant c = LIRValueUtil.asConstant(right);
1273             if (JavaConstant.isNull(c)) {
1274                 if (mustReplaceNullWithNullRegister(c)) {
1275                     getLIRGen().append(new AMD64BinaryConsumer.Op(AMD64RMOp.CMP, size, left, nullRegisterValue));
1276                 } else {
1277                     getLIRGen().append(new AMD64BinaryConsumer.Op(TEST, size, left, left));
1278                 }
1279                 return;
1280             } else if (c instanceof VMConstant) {
1281                 VMConstant vc = (VMConstant) c;
<span class="line-modified">1282                 if (size == DWORD &amp;&amp; !GeneratePIC.getValue(getOptions())) {</span>
1283                     getLIRGen().append(new AMD64BinaryConsumer.VMConstOp(CMP.getMIOpcode(DWORD, false), left, vc));
1284                 } else {
1285                     getLIRGen().append(new AMD64BinaryConsumer.DataOp(CMP.getRMOpcode(size), size, left, vc));
1286                 }
1287                 return;
1288             } else if (c instanceof JavaConstant) {
1289                 JavaConstant jc = (JavaConstant) c;
1290                 if (jc.isDefaultForKind()) {
1291                     AMD64RMOp op = size == BYTE ? TESTB : TEST;
1292                     getLIRGen().append(new AMD64BinaryConsumer.Op(op, size, left, left));
1293                     return;
1294                 } else if (NumUtil.is32bit(jc.asLong())) {
1295                     getLIRGen().append(new AMD64BinaryConsumer.ConstOp(CMP, size, left, (int) jc.asLong()));
1296                     return;
1297                 }
1298             }
1299         }
1300 
1301         // fallback: load, then compare
1302         getLIRGen().append(new AMD64BinaryConsumer.Op(CMP.getRMOpcode(size), size, left, asAllocatable(right)));
1303     }
1304 
1305     @Override
1306     public Value emitRound(Value value, RoundingMode mode) {
1307         Variable result = getLIRGen().newVariable(LIRKind.combine(value));
1308         assert ((AMD64Kind) value.getPlatformKind()).isXMM();
1309         if (value.getPlatformKind() == AMD64Kind.SINGLE) {
1310             getLIRGen().append(new AMD64Binary.RMIOp(AMD64RMIOp.ROUNDSS, OperandSize.PD, result, asAllocatable(value), mode.encoding));
1311         } else {
1312             getLIRGen().append(new AMD64Binary.RMIOp(AMD64RMIOp.ROUNDSD, OperandSize.PD, result, asAllocatable(value), mode.encoding));
1313         }
1314         return result;
1315     }
1316 
<span class="line-modified">1317     private boolean supportAVX() {</span>
1318         TargetDescription target = getLIRGen().target();
1319         return ((AMD64) target.arch).getFeatures().contains(CPUFeature.AVX);
1320     }
1321 
1322     private static AVXSize getRegisterSize(Value a) {
1323         AMD64Kind kind = (AMD64Kind) a.getPlatformKind();
1324         if (kind.isXMM()) {
1325             return AVXKind.getRegisterSize(kind);
1326         } else {
1327             return AVXSize.XMM;
1328         }
1329     }
1330 
<span class="line-modified">1331     private Variable emitBinary(LIRKind resultKind, VexRVMOp op, Value a, Value b) {</span>
1332         Variable result = getLIRGen().newVariable(resultKind);
<span class="line-modified">1333         getLIRGen().append(new AVXBinaryOp(op, getRegisterSize(result), result, asAllocatable(a), asAllocatable(b)));</span>




1334         return result;
1335     }
1336 
1337 }
</pre>
</td>
<td>
<hr />
<pre>
  40 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSD;
  41 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSS;
  42 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSX;
  43 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSXB;
  44 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVSXD;
  45 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVZX;
  46 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.MOVZXB;
  47 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.POPCNT;
  48 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.TEST;
  49 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.TESTB;
  50 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64RMOp.TZCNT;
  51 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.ROL;
  52 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.ROR;
  53 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.SAR;
  54 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.SHL;
  55 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64Shift.SHR;
  56 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VADDSD;
  57 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VADDSS;
  58 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VDIVSD;
  59 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VDIVSS;
<span class="line-added">  60 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VFMADD231SD;</span>
<span class="line-added">  61 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VFMADD231SS;</span>
  62 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VMULSD;
  63 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VMULSS;
  64 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VORPD;
  65 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VORPS;
  66 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VSUBSD;
  67 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VSUBSS;
  68 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VXORPD;
  69 import static org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp.VXORPS;
  70 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.BYTE;
  71 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.DWORD;
  72 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.PD;
  73 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.PS;
  74 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.QWORD;
  75 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.SD;
  76 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.SS;
  77 import static org.graalvm.compiler.asm.amd64.AMD64BaseAssembler.OperandSize.WORD;
  78 import static org.graalvm.compiler.core.common.GraalOptions.GeneratePIC;
  79 import static org.graalvm.compiler.lir.LIRValueUtil.asConstantValue;
  80 import static org.graalvm.compiler.lir.LIRValueUtil.asJavaConstant;
  81 import static org.graalvm.compiler.lir.LIRValueUtil.isConstantValue;
</pre>
<hr />
<pre>
 105 import org.graalvm.compiler.lir.LIRFrameState;
 106 import org.graalvm.compiler.lir.LIRValueUtil;
 107 import org.graalvm.compiler.lir.Variable;
 108 import org.graalvm.compiler.lir.amd64.AMD64AddressValue;
 109 import org.graalvm.compiler.lir.amd64.AMD64Arithmetic.FPDivRemOp;
 110 import org.graalvm.compiler.lir.amd64.AMD64ArithmeticLIRGeneratorTool;
 111 import org.graalvm.compiler.lir.amd64.AMD64Binary;
 112 import org.graalvm.compiler.lir.amd64.AMD64BinaryConsumer;
 113 import org.graalvm.compiler.lir.amd64.AMD64ClearRegisterOp;
 114 import org.graalvm.compiler.lir.amd64.AMD64MathCosOp;
 115 import org.graalvm.compiler.lir.amd64.AMD64MathExpOp;
 116 import org.graalvm.compiler.lir.amd64.AMD64MathLog10Op;
 117 import org.graalvm.compiler.lir.amd64.AMD64MathLogOp;
 118 import org.graalvm.compiler.lir.amd64.AMD64MathPowOp;
 119 import org.graalvm.compiler.lir.amd64.AMD64MathSinOp;
 120 import org.graalvm.compiler.lir.amd64.AMD64MathTanOp;
 121 import org.graalvm.compiler.lir.amd64.AMD64Move;
 122 import org.graalvm.compiler.lir.amd64.AMD64MulDivOp;
 123 import org.graalvm.compiler.lir.amd64.AMD64ShiftOp;
 124 import org.graalvm.compiler.lir.amd64.AMD64SignExtendOp;
<span class="line-added"> 125 import org.graalvm.compiler.lir.amd64.AMD64Ternary;</span>
 126 import org.graalvm.compiler.lir.amd64.AMD64Unary;
 127 import org.graalvm.compiler.lir.amd64.vector.AMD64VectorBinary;
<span class="line-added"> 128 import org.graalvm.compiler.lir.amd64.vector.AMD64VectorBinary.AVXBinaryConstFloatOp;</span>
 129 import org.graalvm.compiler.lir.amd64.vector.AMD64VectorBinary.AVXBinaryOp;
 130 import org.graalvm.compiler.lir.amd64.vector.AMD64VectorUnary;
 131 import org.graalvm.compiler.lir.gen.ArithmeticLIRGenerator;
 132 
 133 import jdk.vm.ci.amd64.AMD64;
 134 import jdk.vm.ci.amd64.AMD64.CPUFeature;
 135 import jdk.vm.ci.amd64.AMD64Kind;
 136 import jdk.vm.ci.code.CodeUtil;
 137 import jdk.vm.ci.code.Register;
 138 import jdk.vm.ci.code.RegisterValue;
 139 import jdk.vm.ci.code.TargetDescription;
 140 import jdk.vm.ci.meta.AllocatableValue;
 141 import jdk.vm.ci.meta.Constant;
 142 import jdk.vm.ci.meta.JavaConstant;
 143 import jdk.vm.ci.meta.JavaKind;
 144 import jdk.vm.ci.meta.PlatformKind;
 145 import jdk.vm.ci.meta.VMConstant;
 146 import jdk.vm.ci.meta.Value;
 147 import jdk.vm.ci.meta.ValueKind;
 148 
</pre>
<hr />
<pre>
 433                 return emitMulHigh(AMD64MOp.IMUL, DWORD, a, b);
 434             case QWORD:
 435                 return emitMulHigh(AMD64MOp.IMUL, QWORD, a, b);
 436             default:
 437                 throw GraalError.shouldNotReachHere();
 438         }
 439     }
 440 
 441     @Override
 442     public Value emitUMulHigh(Value a, Value b) {
 443         switch ((AMD64Kind) a.getPlatformKind()) {
 444             case DWORD:
 445                 return emitMulHigh(AMD64MOp.MUL, DWORD, a, b);
 446             case QWORD:
 447                 return emitMulHigh(AMD64MOp.MUL, QWORD, a, b);
 448             default:
 449                 throw GraalError.shouldNotReachHere();
 450         }
 451     }
 452 
<span class="line-added"> 453     public Value emitBinaryMemory(VexRVMOp op, OperandSize size, AllocatableValue a, AMD64AddressValue location, LIRFrameState state) {</span>
<span class="line-added"> 454         assert (size.isXmmType() &amp;&amp; supportAVX());</span>
<span class="line-added"> 455         Variable result = getLIRGen().newVariable(LIRKind.combine(a));</span>
<span class="line-added"> 456         getLIRGen().append(new AMD64VectorBinary.AVXBinaryMemoryOp(op, getRegisterSize(result), result, a, location, state));</span>
<span class="line-added"> 457         return result;</span>
<span class="line-added"> 458     }</span>
<span class="line-added"> 459 </span>
 460     public Value emitBinaryMemory(AMD64RMOp op, OperandSize size, AllocatableValue a, AMD64AddressValue location, LIRFrameState state) {
 461         Variable result = getLIRGen().newVariable(LIRKind.combine(a));
 462         getLIRGen().append(new AMD64Binary.MemoryTwoOp(op, size, result, a, location, state));
 463         return result;
 464     }
 465 
 466     protected Value emitConvertMemoryOp(PlatformKind kind, AMD64RMOp op, OperandSize size, AMD64AddressValue address, LIRFrameState state) {
 467         Variable result = getLIRGen().newVariable(LIRKind.value(kind));
 468         getLIRGen().append(new AMD64Unary.MemoryOp(op, size, result, address, state));
 469         return result;
 470     }
 471 
 472     protected Value emitZeroExtendMemory(AMD64Kind memoryKind, int resultBits, AMD64AddressValue address, LIRFrameState state) {
 473         // Issue a zero extending load of the proper bit size and set the result to
 474         // the proper kind.
 475         Variable result = getLIRGen().newVariable(LIRKind.value(resultBits &lt;= 32 ? AMD64Kind.DWORD : AMD64Kind.QWORD));
 476         switch (memoryKind) {
 477             case BYTE:
 478                 getLIRGen().append(new AMD64Unary.MemoryOp(MOVZXB, DWORD, result, address, state));
 479                 break;
</pre>
<hr />
<pre>
 683             case DOUBLE:
 684                 if (isAvx) {
 685                     return emitBinary(resultKind, VXORPD, a, b);
 686                 } else {
 687                     return emitBinary(resultKind, SSEOp.XOR, PD, true, a, b);
 688                 }
 689             default:
 690                 throw GraalError.shouldNotReachHere();
 691         }
 692     }
 693 
 694     private Variable emitShift(AMD64Shift op, OperandSize size, Value a, Value b) {
 695         Variable result = getLIRGen().newVariable(LIRKind.combine(a, b).changeType(a.getPlatformKind()));
 696         AllocatableValue input = asAllocatable(a);
 697         if (isJavaConstant(b)) {
 698             JavaConstant c = asJavaConstant(b);
 699             if (c.asLong() == 1) {
 700                 getLIRGen().append(new AMD64Unary.MOp(op.m1Op, size, result, input));
 701             } else {
 702                 /*
<span class="line-modified"> 703                  * c needs to be masked here, because shifts with immediate expect a byte.</span>

 704                  */
<span class="line-modified"> 705                 getLIRGen().append(new AMD64Binary.ConstOp(op.miOp, size, result, input, (byte) c.asLong()));</span>
 706             }
 707         } else {
 708             getLIRGen().emitMove(RCX_I, b);
 709             getLIRGen().append(new AMD64ShiftOp(op.mcOp, size, result, input, RCX_I));
 710         }
 711         return result;
 712     }
 713 
 714     @Override
 715     public Variable emitShl(Value a, Value b) {
 716         switch ((AMD64Kind) a.getPlatformKind()) {
 717             case DWORD:
 718                 return emitShift(SHL, DWORD, a, b);
 719             case QWORD:
 720                 return emitShift(SHL, QWORD, a, b);
 721             default:
 722                 throw GraalError.shouldNotReachHere();
 723         }
 724     }
 725 
</pre>
<hr />
<pre>
 955 
 956     @Override
 957     public Variable emitBitScanForward(Value value) {
 958         Variable result = getLIRGen().newVariable(LIRKind.combine(value).changeType(AMD64Kind.DWORD));
 959         getLIRGen().append(new AMD64Unary.RMOp(BSF, QWORD, result, asAllocatable(value)));
 960         return result;
 961     }
 962 
 963     @Override
 964     public Variable emitBitScanReverse(Value value) {
 965         Variable result = getLIRGen().newVariable(LIRKind.combine(value).changeType(AMD64Kind.DWORD));
 966         assert ((AMD64Kind) value.getPlatformKind()).isInteger();
 967         if (value.getPlatformKind() == AMD64Kind.QWORD) {
 968             getLIRGen().append(new AMD64Unary.RMOp(BSR, QWORD, result, asAllocatable(value)));
 969         } else {
 970             getLIRGen().append(new AMD64Unary.RMOp(BSR, DWORD, result, asAllocatable(value)));
 971         }
 972         return result;
 973     }
 974 
<span class="line-added"> 975     @Override</span>
<span class="line-added"> 976     public Variable emitFusedMultiplyAdd(Value a, Value b, Value c) {</span>
<span class="line-added"> 977         Variable result = getLIRGen().newVariable(LIRKind.combine(a, b, c));</span>
<span class="line-added"> 978         assert ((AMD64Kind) a.getPlatformKind()).isXMM() &amp;&amp; ((AMD64Kind) b.getPlatformKind()).isXMM() &amp;&amp; ((AMD64Kind) c.getPlatformKind()).isXMM();</span>
<span class="line-added"> 979         assert a.getPlatformKind().equals(b.getPlatformKind());</span>
<span class="line-added"> 980         assert b.getPlatformKind().equals(c.getPlatformKind());</span>
<span class="line-added"> 981 </span>
<span class="line-added"> 982         if (a.getPlatformKind() == AMD64Kind.DOUBLE) {</span>
<span class="line-added"> 983             getLIRGen().append(new AMD64Ternary.ThreeOp(VFMADD231SD, AVXSize.XMM, result, asAllocatable(c), asAllocatable(a), asAllocatable(b)));</span>
<span class="line-added"> 984         } else {</span>
<span class="line-added"> 985             assert a.getPlatformKind() == AMD64Kind.SINGLE;</span>
<span class="line-added"> 986             getLIRGen().append(new AMD64Ternary.ThreeOp(VFMADD231SS, AVXSize.XMM, result, asAllocatable(c), asAllocatable(a), asAllocatable(b)));</span>
<span class="line-added"> 987         }</span>
<span class="line-added"> 988         return result;</span>
<span class="line-added"> 989     }</span>
<span class="line-added"> 990 </span>
 991     @Override
 992     public Value emitCountLeadingZeros(Value value) {
 993         Variable result = getLIRGen().newVariable(LIRKind.combine(value).changeType(AMD64Kind.DWORD));
 994         assert ((AMD64Kind) value.getPlatformKind()).isInteger();
 995         if (value.getPlatformKind() == AMD64Kind.QWORD) {
 996             getLIRGen().append(new AMD64Unary.RMOp(LZCNT, QWORD, result, asAllocatable(value)));
 997         } else {
 998             getLIRGen().append(new AMD64Unary.RMOp(LZCNT, DWORD, result, asAllocatable(value)));
 999         }
1000         return result;
1001     }
1002 
1003     @Override
1004     public Value emitCountTrailingZeros(Value value) {
1005         Variable result = getLIRGen().newVariable(LIRKind.combine(value).changeType(AMD64Kind.DWORD));
1006         assert ((AMD64Kind) value.getPlatformKind()).isInteger();
1007         if (value.getPlatformKind() == AMD64Kind.QWORD) {
1008             getLIRGen().append(new AMD64Unary.RMOp(TZCNT, QWORD, result, asAllocatable(value)));
1009         } else {
1010             getLIRGen().append(new AMD64Unary.RMOp(TZCNT, DWORD, result, asAllocatable(value)));
</pre>
<hr />
<pre>
1288                 getLIRGen().append(new AMD64BinaryConsumer.Op(SSEOp.UCOMIS, PS, left, asAllocatable(right)));
1289                 return;
1290             case DOUBLE:
1291                 getLIRGen().append(new AMD64BinaryConsumer.Op(SSEOp.UCOMIS, PD, left, asAllocatable(right)));
1292                 return;
1293             default:
1294                 throw GraalError.shouldNotReachHere(&quot;unexpected kind: &quot; + cmpKind);
1295         }
1296 
1297         if (isConstantValue(right)) {
1298             Constant c = LIRValueUtil.asConstant(right);
1299             if (JavaConstant.isNull(c)) {
1300                 if (mustReplaceNullWithNullRegister(c)) {
1301                     getLIRGen().append(new AMD64BinaryConsumer.Op(AMD64RMOp.CMP, size, left, nullRegisterValue));
1302                 } else {
1303                     getLIRGen().append(new AMD64BinaryConsumer.Op(TEST, size, left, left));
1304                 }
1305                 return;
1306             } else if (c instanceof VMConstant) {
1307                 VMConstant vc = (VMConstant) c;
<span class="line-modified">1308                 if (size == DWORD &amp;&amp; !GeneratePIC.getValue(getOptions()) &amp;&amp; getLIRGen().target().inlineObjects) {</span>
1309                     getLIRGen().append(new AMD64BinaryConsumer.VMConstOp(CMP.getMIOpcode(DWORD, false), left, vc));
1310                 } else {
1311                     getLIRGen().append(new AMD64BinaryConsumer.DataOp(CMP.getRMOpcode(size), size, left, vc));
1312                 }
1313                 return;
1314             } else if (c instanceof JavaConstant) {
1315                 JavaConstant jc = (JavaConstant) c;
1316                 if (jc.isDefaultForKind()) {
1317                     AMD64RMOp op = size == BYTE ? TESTB : TEST;
1318                     getLIRGen().append(new AMD64BinaryConsumer.Op(op, size, left, left));
1319                     return;
1320                 } else if (NumUtil.is32bit(jc.asLong())) {
1321                     getLIRGen().append(new AMD64BinaryConsumer.ConstOp(CMP, size, left, (int) jc.asLong()));
1322                     return;
1323                 }
1324             }
1325         }
1326 
1327         // fallback: load, then compare
1328         getLIRGen().append(new AMD64BinaryConsumer.Op(CMP.getRMOpcode(size), size, left, asAllocatable(right)));
1329     }
1330 
1331     @Override
1332     public Value emitRound(Value value, RoundingMode mode) {
1333         Variable result = getLIRGen().newVariable(LIRKind.combine(value));
1334         assert ((AMD64Kind) value.getPlatformKind()).isXMM();
1335         if (value.getPlatformKind() == AMD64Kind.SINGLE) {
1336             getLIRGen().append(new AMD64Binary.RMIOp(AMD64RMIOp.ROUNDSS, OperandSize.PD, result, asAllocatable(value), mode.encoding));
1337         } else {
1338             getLIRGen().append(new AMD64Binary.RMIOp(AMD64RMIOp.ROUNDSD, OperandSize.PD, result, asAllocatable(value), mode.encoding));
1339         }
1340         return result;
1341     }
1342 
<span class="line-modified">1343     public boolean supportAVX() {</span>
1344         TargetDescription target = getLIRGen().target();
1345         return ((AMD64) target.arch).getFeatures().contains(CPUFeature.AVX);
1346     }
1347 
1348     private static AVXSize getRegisterSize(Value a) {
1349         AMD64Kind kind = (AMD64Kind) a.getPlatformKind();
1350         if (kind.isXMM()) {
1351             return AVXKind.getRegisterSize(kind);
1352         } else {
1353             return AVXSize.XMM;
1354         }
1355     }
1356 
<span class="line-modified">1357     protected Variable emitBinary(LIRKind resultKind, VexRVMOp op, Value a, Value b) {</span>
1358         Variable result = getLIRGen().newVariable(resultKind);
<span class="line-modified">1359         if (b instanceof ConstantValue &amp;&amp; (b.getPlatformKind() == AMD64Kind.SINGLE || b.getPlatformKind() == AMD64Kind.DOUBLE)) {</span>
<span class="line-added">1360             getLIRGen().append(new AVXBinaryConstFloatOp(op, getRegisterSize(result), result, asAllocatable(a), (ConstantValue) b));</span>
<span class="line-added">1361         } else {</span>
<span class="line-added">1362             getLIRGen().append(new AVXBinaryOp(op, getRegisterSize(result), result, asAllocatable(a), asAllocatable(b)));</span>
<span class="line-added">1363         }</span>
1364         return result;
1365     }
1366 
1367 }
</pre>
</td>
</tr>
</table>
<center><a href="AMD64AddressNode.java.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../../index.html" target="_top">index</a> <a href="AMD64LIRGenerator.java.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>