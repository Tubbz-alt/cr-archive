diff a/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.lir.amd64/src/org/graalvm/compiler/lir/amd64/AMD64ArrayEqualsOp.java b/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.lir.amd64/src/org/graalvm/compiler/lir/amd64/AMD64ArrayEqualsOp.java
--- a/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.lir.amd64/src/org/graalvm/compiler/lir/amd64/AMD64ArrayEqualsOp.java
+++ b/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.lir.amd64/src/org/graalvm/compiler/lir/amd64/AMD64ArrayEqualsOp.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2013, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2013, 2019, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -22,17 +22,18 @@
  */
 
 
 package org.graalvm.compiler.lir.amd64;
 
-import jdk.vm.ci.amd64.AMD64;
-import jdk.vm.ci.amd64.AMD64.CPUFeature;
-import jdk.vm.ci.amd64.AMD64Kind;
-import jdk.vm.ci.code.Register;
-import jdk.vm.ci.code.TargetDescription;
-import jdk.vm.ci.meta.JavaKind;
-import jdk.vm.ci.meta.Value;
+import static jdk.vm.ci.code.ValueUtil.asRegister;
+import static org.graalvm.compiler.asm.amd64.AMD64Assembler.AMD64BinaryArithmetic.XOR;
+import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.CONST;
+import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.ILLEGAL;
+import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.REG;
+
+import java.util.Objects;
+
 import org.graalvm.compiler.asm.Label;
 import org.graalvm.compiler.asm.amd64.AMD64Address;
 import org.graalvm.compiler.asm.amd64.AMD64Address.Scale;
 import org.graalvm.compiler.asm.amd64.AMD64Assembler;
 import org.graalvm.compiler.asm.amd64.AMD64Assembler.ConditionFlag;
@@ -41,19 +42,22 @@
 import org.graalvm.compiler.asm.amd64.AMD64MacroAssembler;
 import org.graalvm.compiler.asm.amd64.AVXKind;
 import org.graalvm.compiler.core.common.LIRKind;
 import org.graalvm.compiler.debug.GraalError;
 import org.graalvm.compiler.lir.LIRInstructionClass;
+import org.graalvm.compiler.lir.LIRValueUtil;
 import org.graalvm.compiler.lir.Opcode;
 import org.graalvm.compiler.lir.asm.CompilationResultBuilder;
 import org.graalvm.compiler.lir.gen.LIRGeneratorTool;
 
-import static jdk.vm.ci.code.ValueUtil.asRegister;
-import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.ILLEGAL;
-import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.REG;
-
-import java.util.Objects;
+import jdk.vm.ci.amd64.AMD64;
+import jdk.vm.ci.amd64.AMD64.CPUFeature;
+import jdk.vm.ci.amd64.AMD64Kind;
+import jdk.vm.ci.code.Register;
+import jdk.vm.ci.code.TargetDescription;
+import jdk.vm.ci.meta.JavaKind;
+import jdk.vm.ci.meta.Value;
 
 /**
  * Emits code which compares two arrays of the same length. If the CPU supports any vector
  * instructions specialized code is emitted to leverage these instructions.
  *
@@ -70,32 +74,31 @@
     private final int arrayBaseOffset1;
     private final int arrayBaseOffset2;
     private final Scale arrayIndexScale1;
     private final Scale arrayIndexScale2;
     private final AVXKind.AVXSize vectorSize;
-    private final int constantLength;
     private final boolean signExtend;
 
     @Def({REG}) private Value resultValue;
     @Alive({REG}) private Value array1Value;
     @Alive({REG}) private Value array2Value;
-    @Alive({REG}) private Value lengthValue;
-    @Temp({REG}) private Value temp1;
-    @Temp({REG}) private Value temp2;
+    @Alive({REG, CONST}) private Value lengthValue;
+    @Temp({REG, ILLEGAL}) private Value temp1;
+    @Temp({REG, ILLEGAL}) private Value temp2;
     @Temp({REG}) private Value temp3;
-    @Temp({REG}) private Value temp4;
+    @Temp({REG, ILLEGAL}) private Value temp4;
 
     @Temp({REG, ILLEGAL}) private Value temp5;
     @Temp({REG, ILLEGAL}) private Value tempXMM;
 
     @Temp({REG, ILLEGAL}) private Value vectorTemp1;
     @Temp({REG, ILLEGAL}) private Value vectorTemp2;
     @Temp({REG, ILLEGAL}) private Value vectorTemp3;
     @Temp({REG, ILLEGAL}) private Value vectorTemp4;
 
     public AMD64ArrayEqualsOp(LIRGeneratorTool tool, JavaKind kind1, JavaKind kind2, Value result, Value array1, Value array2, Value length,
-                    int constantLength, boolean directPointers, int maxVectorSize) {
+                    boolean directPointers, int maxVectorSize) {
         super(TYPE);
         this.kind1 = kind1;
         this.kind2 = kind2;
         this.signExtend = kind1 != JavaKind.Char && kind2 != JavaKind.Char;
 
@@ -104,24 +107,33 @@
         this.arrayBaseOffset1 = directPointers ? 0 : tool.getProviders().getMetaAccess().getArrayBaseOffset(kind1);
         this.arrayBaseOffset2 = directPointers ? 0 : tool.getProviders().getMetaAccess().getArrayBaseOffset(kind2);
         this.arrayIndexScale1 = Objects.requireNonNull(Scale.fromInt(tool.getProviders().getMetaAccess().getArrayIndexScale(kind1)));
         this.arrayIndexScale2 = Objects.requireNonNull(Scale.fromInt(tool.getProviders().getMetaAccess().getArrayIndexScale(kind2)));
         this.vectorSize = ((AMD64) tool.target().arch).getFeatures().contains(CPUFeature.AVX2) && (maxVectorSize < 0 || maxVectorSize >= 32) ? AVXKind.AVXSize.YMM : AVXKind.AVXSize.XMM;
-        this.constantLength = constantLength;
 
         this.resultValue = result;
         this.array1Value = array1;
         this.array2Value = array2;
         this.lengthValue = length;
 
         // Allocate some temporaries.
-        this.temp1 = tool.newVariable(LIRKind.unknownReference(tool.target().arch.getWordKind()));
-        this.temp2 = tool.newVariable(LIRKind.unknownReference(tool.target().arch.getWordKind()));
+        if (supportsSSE41(tool.target()) && canGenerateConstantLengthCompare(tool.target()) && !constantLengthCompareNeedsTmpArrayPointers()) {
+            this.temp1 = Value.ILLEGAL;
+            this.temp2 = Value.ILLEGAL;
+        } else {
+            this.temp1 = tool.newVariable(LIRKind.unknownReference(tool.target().arch.getWordKind()));
+            this.temp2 = tool.newVariable(LIRKind.unknownReference(tool.target().arch.getWordKind()));
+        }
         this.temp3 = tool.newVariable(LIRKind.value(tool.target().arch.getWordKind()));
-        this.temp4 = tool.newVariable(LIRKind.value(tool.target().arch.getWordKind()));
+        if (supportsSSE41(tool.target()) && canGenerateConstantLengthCompare(tool.target())) {
+            this.temp4 = Value.ILLEGAL;
+            this.temp5 = Value.ILLEGAL;
+        } else {
+            this.temp4 = tool.newVariable(LIRKind.value(tool.target().arch.getWordKind()));
+            this.temp5 = kind1.isNumericFloat() || kind1 != kind2 ? tool.newVariable(LIRKind.value(tool.target().arch.getWordKind())) : Value.ILLEGAL;
+        }
 
-        this.temp5 = kind1.isNumericFloat() || kind1 != kind2 ? tool.newVariable(LIRKind.value(tool.target().arch.getWordKind())) : Value.ILLEGAL;
         if (kind1 == JavaKind.Float) {
             this.tempXMM = tool.newVariable(LIRKind.value(AMD64Kind.SINGLE));
         } else if (kind1 == JavaKind.Double) {
             this.tempXMM = tool.newVariable(LIRKind.value(AMD64Kind.DOUBLE));
         } else {
@@ -149,34 +161,40 @@
             this.vectorTemp4 = Value.ILLEGAL;
         }
     }
 
     private boolean canGenerateConstantLengthCompare(TargetDescription target) {
-        return constantLength >= 0 && kind1.isNumericInteger() && (kind1 == kind2 || getElementsPerVector(AVXKind.AVXSize.XMM) <= constantLength) && supportsSSE41(target);
+        return LIRValueUtil.isJavaConstant(lengthValue) && kind1.isNumericInteger() && (kind1 == kind2 || getElementsPerVector(AVXKind.AVXSize.XMM) <= constantLength()) && supportsSSE41(target);
+    }
+
+    private int constantLength() {
+        return LIRValueUtil.asJavaConstant(lengthValue).asInt();
     }
 
     @Override
     public void emitCode(CompilationResultBuilder crb, AMD64MacroAssembler masm) {
         Register result = asRegister(resultValue);
-        Register array1 = asRegister(temp1);
-        Register array2 = asRegister(temp2);
 
         Label trueLabel = new Label();
         Label falseLabel = new Label();
         Label done = new Label();
 
-        // Load array base addresses.
-        masm.leaq(array1, new AMD64Address(asRegister(array1Value), arrayBaseOffset1));
-        masm.leaq(array2, new AMD64Address(asRegister(array2Value), arrayBaseOffset2));
-
         if (canGenerateConstantLengthCompare(crb.target)) {
-            emitConstantLengthArrayCompareBytes(crb, masm, array1, array2, asRegister(temp3), asRegister(temp4),
-                            new Register[]{asRegister(vectorTemp1), asRegister(vectorTemp2), asRegister(vectorTemp3), asRegister(vectorTemp4)}, falseLabel);
+            emitConstantLengthArrayCompareBytes(crb, masm, new Register[]{asRegister(vectorTemp1), asRegister(vectorTemp2), asRegister(vectorTemp3), asRegister(vectorTemp4)}, falseLabel);
         } else {
+            Register array1 = asRegister(temp1);
+            Register array2 = asRegister(temp2);
+            // Load array base addresses.
+            masm.leaq(array1, new AMD64Address(asRegister(array1Value), arrayBaseOffset1));
+            masm.leaq(array2, new AMD64Address(asRegister(array2Value), arrayBaseOffset2));
             Register length = asRegister(temp3);
             // Get array length.
-            masm.movl(length, asRegister(lengthValue));
+            if (LIRValueUtil.isJavaConstant(lengthValue)) {
+                masm.movl(length, constantLength());
+            } else {
+                masm.movl(length, asRegister(lengthValue));
+            }
             // copy
             masm.movl(result, length);
             emitArrayCompare(crb, masm, result, array1, array2, length, trueLabel, falseLabel);
         }
 
@@ -703,86 +721,96 @@
         masm.jccb(ConditionFlag.NotZero, loop);
         // Floats within the range are equal, revert change to the register index
         masm.subq(index, range);
     }
 
+    private boolean constantLengthCompareNeedsTmpArrayPointers() {
+        AVXKind.AVXSize vSize = vectorSize;
+        if (constantLength() < getElementsPerVector(vectorSize)) {
+            vSize = AVXKind.AVXSize.XMM;
+        }
+        int vectorCount = constantLength() & ~(2 * getElementsPerVector(vSize) - 1);
+        return vectorCount > 0;
+    }
+
     /**
      * Emits specialized assembly for checking equality of memory regions
      * {@code arrayPtr1[0..nBytes]} and {@code arrayPtr2[0..nBytes]}. If they match, execution
      * continues directly after the emitted code block, otherwise we jump to {@code noMatch}.
      */
     private void emitConstantLengthArrayCompareBytes(
                     CompilationResultBuilder crb,
                     AMD64MacroAssembler asm,
-                    Register arrayPtr1,
-                    Register arrayPtr2,
-                    Register tmp1,
-                    Register tmp2,
                     Register[] tmpVectors,
                     Label noMatch) {
-        if (constantLength == 0) {
+        if (constantLength() == 0) {
             // do nothing
             return;
         }
+        Register arrayPtr1 = asRegister(array1Value);
+        Register arrayPtr2 = asRegister(array2Value);
+        Register tmp = asRegister(temp3);
         AVXKind.AVXSize vSize = vectorSize;
-        if (constantLength < getElementsPerVector(vectorSize)) {
+        if (constantLength() < getElementsPerVector(vectorSize)) {
             vSize = AVXKind.AVXSize.XMM;
         }
         int elementsPerVector = getElementsPerVector(vSize);
-        if (elementsPerVector > constantLength) {
+        if (elementsPerVector > constantLength()) {
             assert kind1 == kind2;
-            int byteLength = constantLength << arrayIndexScale1.log2;
-            // array is shorter than any vector register, use regular CMP instructions
+            int byteLength = constantLength() << arrayIndexScale1.log2;
+            // array is shorter than any vector register, use regular XOR instructions
             int movSize = (byteLength < 2) ? 1 : ((byteLength < 4) ? 2 : ((byteLength < 8) ? 4 : 8));
-            emitMovBytes(asm, tmp1, new AMD64Address(arrayPtr1), movSize);
-            emitMovBytes(asm, tmp2, new AMD64Address(arrayPtr2), movSize);
-            emitCmpBytes(asm, tmp1, tmp2, movSize);
-            asm.jcc(AMD64Assembler.ConditionFlag.NotEqual, noMatch);
+            emitMovBytes(asm, tmp, new AMD64Address(arrayPtr1, arrayBaseOffset1), movSize);
+            emitXorBytes(asm, tmp, new AMD64Address(arrayPtr2, arrayBaseOffset2), movSize);
+            asm.jccb(AMD64Assembler.ConditionFlag.NotZero, noMatch);
             if (byteLength > movSize) {
-                emitMovBytes(asm, tmp1, new AMD64Address(arrayPtr1, byteLength - movSize), movSize);
-                emitMovBytes(asm, tmp2, new AMD64Address(arrayPtr2, byteLength - movSize), movSize);
-                emitCmpBytes(asm, tmp1, tmp2, movSize);
-                asm.jcc(AMD64Assembler.ConditionFlag.NotEqual, noMatch);
+                emitMovBytes(asm, tmp, new AMD64Address(arrayPtr1, arrayBaseOffset1 + byteLength - movSize), movSize);
+                emitXorBytes(asm, tmp, new AMD64Address(arrayPtr2, arrayBaseOffset2 + byteLength - movSize), movSize);
+                asm.jccb(AMD64Assembler.ConditionFlag.NotZero, noMatch);
             }
         } else {
             int elementsPerVectorLoop = 2 * elementsPerVector;
-            int tailCount = constantLength & (elementsPerVectorLoop - 1);
-            int vectorCount = constantLength & ~(elementsPerVectorLoop - 1);
+            int tailCount = constantLength() & (elementsPerVectorLoop - 1);
+            int vectorCount = constantLength() & ~(elementsPerVectorLoop - 1);
             int bytesPerVector = vSize.getBytes();
             if (vectorCount > 0) {
                 Label loopBegin = new Label();
-                asm.leaq(arrayPtr1, new AMD64Address(arrayPtr1, vectorCount << arrayIndexScale1.log2));
-                asm.leaq(arrayPtr2, new AMD64Address(arrayPtr2, vectorCount << arrayIndexScale2.log2));
-                asm.movq(tmp1, -vectorCount);
+                Register tmpArrayPtr1 = asRegister(temp1);
+                Register tmpArrayPtr2 = asRegister(temp2);
+                asm.leaq(tmpArrayPtr1, new AMD64Address(arrayPtr1, vectorCount << arrayIndexScale1.log2));
+                asm.leaq(tmpArrayPtr2, new AMD64Address(arrayPtr2, vectorCount << arrayIndexScale2.log2));
+                arrayPtr1 = tmpArrayPtr1;
+                arrayPtr2 = tmpArrayPtr2;
+                asm.movq(tmp, -vectorCount);
                 asm.align(crb.target.wordSize * 2);
                 asm.bind(loopBegin);
-                emitVectorLoad1(asm, tmpVectors[0], arrayPtr1, tmp1, 0, vSize);
-                emitVectorLoad2(asm, tmpVectors[1], arrayPtr2, tmp1, 0, vSize);
-                emitVectorLoad1(asm, tmpVectors[2], arrayPtr1, tmp1, scaleDisplacement1(bytesPerVector), vSize);
-                emitVectorLoad2(asm, tmpVectors[3], arrayPtr2, tmp1, scaleDisplacement2(bytesPerVector), vSize);
+                emitVectorLoad1(asm, tmpVectors[0], arrayPtr1, tmp, arrayBaseOffset1, vSize);
+                emitVectorLoad2(asm, tmpVectors[1], arrayPtr2, tmp, arrayBaseOffset2, vSize);
+                emitVectorLoad1(asm, tmpVectors[2], arrayPtr1, tmp, arrayBaseOffset1 + scaleDisplacement1(bytesPerVector), vSize);
+                emitVectorLoad2(asm, tmpVectors[3], arrayPtr2, tmp, arrayBaseOffset2 + scaleDisplacement2(bytesPerVector), vSize);
                 emitVectorXor(asm, tmpVectors[0], tmpVectors[1], vSize);
                 emitVectorXor(asm, tmpVectors[2], tmpVectors[3], vSize);
                 emitVectorTest(asm, tmpVectors[0], vSize);
-                asm.jcc(AMD64Assembler.ConditionFlag.NotZero, noMatch);
+                asm.jccb(AMD64Assembler.ConditionFlag.NotZero, noMatch);
                 emitVectorTest(asm, tmpVectors[2], vSize);
-                asm.jcc(AMD64Assembler.ConditionFlag.NotZero, noMatch);
-                asm.addq(tmp1, elementsPerVectorLoop);
-                asm.jcc(AMD64Assembler.ConditionFlag.NotZero, loopBegin);
+                asm.jccb(AMD64Assembler.ConditionFlag.NotZero, noMatch);
+                asm.addq(tmp, elementsPerVectorLoop);
+                asm.jccb(AMD64Assembler.ConditionFlag.NotZero, loopBegin);
             }
             if (tailCount > 0) {
-                emitVectorLoad1(asm, tmpVectors[0], arrayPtr1, (tailCount << arrayIndexScale1.log2) - scaleDisplacement1(bytesPerVector), vSize);
-                emitVectorLoad2(asm, tmpVectors[1], arrayPtr2, (tailCount << arrayIndexScale2.log2) - scaleDisplacement2(bytesPerVector), vSize);
+                emitVectorLoad1(asm, tmpVectors[0], arrayPtr1, arrayBaseOffset1 + (tailCount << arrayIndexScale1.log2) - scaleDisplacement1(bytesPerVector), vSize);
+                emitVectorLoad2(asm, tmpVectors[1], arrayPtr2, arrayBaseOffset2 + (tailCount << arrayIndexScale2.log2) - scaleDisplacement2(bytesPerVector), vSize);
                 emitVectorXor(asm, tmpVectors[0], tmpVectors[1], vSize);
                 if (tailCount > elementsPerVector) {
-                    emitVectorLoad1(asm, tmpVectors[2], arrayPtr1, 0, vSize);
-                    emitVectorLoad2(asm, tmpVectors[3], arrayPtr2, 0, vSize);
+                    emitVectorLoad1(asm, tmpVectors[2], arrayPtr1, arrayBaseOffset1, vSize);
+                    emitVectorLoad2(asm, tmpVectors[3], arrayPtr2, arrayBaseOffset2, vSize);
                     emitVectorXor(asm, tmpVectors[2], tmpVectors[3], vSize);
                     emitVectorTest(asm, tmpVectors[2], vSize);
-                    asm.jcc(AMD64Assembler.ConditionFlag.NotZero, noMatch);
+                    asm.jccb(AMD64Assembler.ConditionFlag.NotZero, noMatch);
                 }
                 emitVectorTest(asm, tmpVectors[0], vSize);
-                asm.jcc(AMD64Assembler.ConditionFlag.NotZero, noMatch);
+                asm.jccb(AMD64Assembler.ConditionFlag.NotZero, noMatch);
             }
         }
     }
 
     private void emitMovBytes(AMD64MacroAssembler asm, Register dst, AMD64Address src, int size) {
@@ -815,13 +843,30 @@
             default:
                 throw new IllegalStateException();
         }
     }
 
-    private static void emitCmpBytes(AMD64MacroAssembler asm, Register dst, Register src, int size) {
-        if (size < 8) {
-            asm.cmpl(dst, src);
-        } else {
-            asm.cmpq(dst, src);
+    private static void emitXorBytes(AMD64MacroAssembler asm, Register dst, AMD64Address src, int size) {
+        OperandSize opSize = getOperandSize(size);
+        XOR.getRMOpcode(opSize).emit(asm, opSize, dst, src);
+    }
+
+    private static OperandSize getOperandSize(int size) {
+        switch (size) {
+            case 1:
+                return OperandSize.BYTE;
+            case 2:
+                return OperandSize.WORD;
+            case 4:
+                return OperandSize.DWORD;
+            case 8:
+                return OperandSize.QWORD;
+            default:
+                throw new IllegalStateException();
         }
     }
+
+    @Override
+    public boolean needsClearUpperVectorRegisters() {
+        return true;
+    }
 }
