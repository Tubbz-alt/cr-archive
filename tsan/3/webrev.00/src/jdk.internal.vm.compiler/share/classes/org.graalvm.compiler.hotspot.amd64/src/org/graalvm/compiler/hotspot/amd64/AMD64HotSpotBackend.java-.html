<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.amd64/src/org/graalvm/compiler/hotspot/amd64/AMD64HotSpotBackend.java</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2012, 2018, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 
 25 package org.graalvm.compiler.hotspot.amd64;
 26 
 27 import static jdk.vm.ci.amd64.AMD64.r10;
 28 import static jdk.vm.ci.amd64.AMD64.rax;
 29 import static jdk.vm.ci.amd64.AMD64.rsp;
 30 import static jdk.vm.ci.code.ValueUtil.asRegister;
 31 import static org.graalvm.compiler.core.common.GraalOptions.CanOmitFrame;
 32 import static org.graalvm.compiler.core.common.GraalOptions.GeneratePIC;
 33 import static org.graalvm.compiler.core.common.GraalOptions.ZapStackOnMethodEntry;
 34 
 35 import jdk.internal.vm.compiler.collections.EconomicSet;
 36 import org.graalvm.compiler.asm.Assembler;
 37 import org.graalvm.compiler.asm.Label;
 38 import org.graalvm.compiler.asm.amd64.AMD64Address;
 39 import org.graalvm.compiler.asm.amd64.AMD64Assembler.ConditionFlag;
 40 import org.graalvm.compiler.asm.amd64.AMD64MacroAssembler;
 41 import org.graalvm.compiler.code.CompilationResult;
 42 import org.graalvm.compiler.core.amd64.AMD64NodeMatchRules;
 43 import org.graalvm.compiler.core.common.CompilationIdentifier;
 44 import org.graalvm.compiler.core.common.LIRKind;
 45 import org.graalvm.compiler.core.common.alloc.RegisterAllocationConfig;
 46 import org.graalvm.compiler.core.gen.LIRGenerationProvider;
 47 import org.graalvm.compiler.debug.DebugContext;
 48 import org.graalvm.compiler.hotspot.GraalHotSpotVMConfig;
 49 import org.graalvm.compiler.hotspot.HotSpotDataBuilder;
 50 import org.graalvm.compiler.hotspot.HotSpotGraalRuntimeProvider;
 51 import org.graalvm.compiler.hotspot.HotSpotHostBackend;
 52 import org.graalvm.compiler.hotspot.HotSpotLIRGenerationResult;
 53 import org.graalvm.compiler.hotspot.meta.HotSpotConstantLoadAction;
 54 import org.graalvm.compiler.hotspot.meta.HotSpotForeignCallsProvider;
 55 import org.graalvm.compiler.hotspot.meta.HotSpotProviders;
 56 import org.graalvm.compiler.hotspot.stubs.Stub;
 57 import org.graalvm.compiler.lir.LIR;
 58 import org.graalvm.compiler.lir.amd64.AMD64Call;
 59 import org.graalvm.compiler.lir.amd64.AMD64FrameMap;
 60 import org.graalvm.compiler.lir.amd64.AMD64FrameMapBuilder;
 61 import org.graalvm.compiler.lir.asm.CompilationResultBuilder;
 62 import org.graalvm.compiler.lir.asm.CompilationResultBuilderFactory;
 63 import org.graalvm.compiler.lir.asm.DataBuilder;
 64 import org.graalvm.compiler.lir.asm.FrameContext;
 65 import org.graalvm.compiler.lir.framemap.FrameMap;
 66 import org.graalvm.compiler.lir.framemap.FrameMapBuilder;
 67 import org.graalvm.compiler.lir.gen.LIRGenerationResult;
 68 import org.graalvm.compiler.lir.gen.LIRGeneratorTool;
 69 import org.graalvm.compiler.nodes.StructuredGraph;
 70 import org.graalvm.compiler.nodes.spi.NodeLIRBuilderTool;
 71 import org.graalvm.compiler.options.OptionValues;
 72 
 73 import jdk.vm.ci.amd64.AMD64;
 74 import jdk.vm.ci.amd64.AMD64Kind;
 75 import jdk.vm.ci.code.CallingConvention;
 76 import jdk.vm.ci.code.Register;
 77 import jdk.vm.ci.code.RegisterConfig;
 78 import jdk.vm.ci.code.StackSlot;
 79 import jdk.vm.ci.hotspot.HotSpotCallingConventionType;
 80 import jdk.vm.ci.hotspot.HotSpotSentinelConstant;
 81 import jdk.vm.ci.meta.JavaKind;
 82 import jdk.vm.ci.meta.JavaType;
 83 import jdk.vm.ci.meta.ResolvedJavaMethod;
 84 
 85 /**
 86  * HotSpot AMD64 specific backend.
 87  */
 88 public class AMD64HotSpotBackend extends HotSpotHostBackend implements LIRGenerationProvider {
 89 
 90     public AMD64HotSpotBackend(GraalHotSpotVMConfig config, HotSpotGraalRuntimeProvider runtime, HotSpotProviders providers) {
 91         super(config, runtime, providers);
 92     }
 93 
 94     private FrameMapBuilder newFrameMapBuilder(RegisterConfig registerConfig) {
 95         RegisterConfig registerConfigNonNull = registerConfig == null ? getCodeCache().getRegisterConfig() : registerConfig;
 96         FrameMap frameMap = new AMD64FrameMap(getCodeCache(), registerConfigNonNull, this);
 97         return new AMD64FrameMapBuilder(frameMap, getCodeCache(), registerConfigNonNull);
 98     }
 99 
100     @Override
101     public LIRGeneratorTool newLIRGenerator(LIRGenerationResult lirGenRes) {
102         return new AMD64HotSpotLIRGenerator(getProviders(), config, lirGenRes);
103     }
104 
105     @Override
106     public LIRGenerationResult newLIRGenerationResult(CompilationIdentifier compilationId, LIR lir, RegisterConfig registerConfig, StructuredGraph graph, Object stub) {
107         return new HotSpotLIRGenerationResult(compilationId, lir, newFrameMapBuilder(registerConfig), makeCallingConvention(graph, (Stub) stub), stub,
108                         config.requiresReservedStackCheck(graph.getMethods()));
109     }
110 
111     @Override
112     public NodeLIRBuilderTool newNodeLIRBuilder(StructuredGraph graph, LIRGeneratorTool lirGen) {
113         return new AMD64HotSpotNodeLIRBuilder(graph, lirGen, new AMD64NodeMatchRules(lirGen));
114     }
115 
116     @Override
117     protected void bangStackWithOffset(CompilationResultBuilder crb, int bangOffset) {
118         AMD64MacroAssembler asm = (AMD64MacroAssembler) crb.asm;
119         int pos = asm.position();
120         asm.movl(new AMD64Address(rsp, -bangOffset), AMD64.rax);
121         assert asm.position() - pos &gt;= PATCHED_VERIFIED_ENTRY_POINT_INSTRUCTION_SIZE;
122     }
123 
124     /**
125      * The size of the instruction used to patch the verified entry point of an nmethod when the
126      * nmethod is made non-entrant or a zombie (e.g. during deopt or class unloading). The first
127      * instruction emitted at an nmethod&#39;s verified entry point must be at least this length to
128      * ensure mt-safe patching.
129      */
130     public static final int PATCHED_VERIFIED_ENTRY_POINT_INSTRUCTION_SIZE = 5;
131 
132     /**
133      * Emits code at the verified entry point and return point(s) of a method.
134      */
135     class HotSpotFrameContext implements FrameContext {
136 
137         final boolean isStub;
138         final boolean omitFrame;
139 
140         HotSpotFrameContext(boolean isStub, boolean omitFrame) {
141             this.isStub = isStub;
142             this.omitFrame = omitFrame;
143         }
144 
145         @Override
146         public boolean hasFrame() {
147             return !omitFrame;
148         }
149 
150         @Override
151         public void enter(CompilationResultBuilder crb) {
152             FrameMap frameMap = crb.frameMap;
153             int frameSize = frameMap.frameSize();
154             AMD64MacroAssembler asm = (AMD64MacroAssembler) crb.asm;
155             if (omitFrame) {
156                 if (!isStub) {
157                     asm.nop(PATCHED_VERIFIED_ENTRY_POINT_INSTRUCTION_SIZE);
158                 }
159             } else {
160                 int verifiedEntryPointOffset = asm.position();
161                 if (!isStub) {
162                     emitStackOverflowCheck(crb);
163                     // assert asm.position() - verifiedEntryPointOffset &gt;=
164                     // PATCHED_VERIFIED_ENTRY_POINT_INSTRUCTION_SIZE;
165                 }
166                 if (!isStub &amp;&amp; asm.position() == verifiedEntryPointOffset) {
167                     asm.subqWide(rsp, frameSize);
168                     assert asm.position() - verifiedEntryPointOffset &gt;= PATCHED_VERIFIED_ENTRY_POINT_INSTRUCTION_SIZE;
169                 } else {
170                     asm.decrementq(rsp, frameSize);
171                 }
172                 if (ZapStackOnMethodEntry.getValue(crb.getOptions())) {
173                     final int intSize = 4;
174                     for (int i = 0; i &lt; frameSize / intSize; ++i) {
175                         asm.movl(new AMD64Address(rsp, i * intSize), 0xC1C1C1C1);
176                     }
177                 }
178                 assert frameMap.getRegisterConfig().getCalleeSaveRegisters() == null;
179             }
180         }
181 
182         @Override
183         public void leave(CompilationResultBuilder crb) {
184             if (!omitFrame) {
185                 AMD64MacroAssembler asm = (AMD64MacroAssembler) crb.asm;
186                 assert crb.frameMap.getRegisterConfig().getCalleeSaveRegisters() == null;
187 
188                 int frameSize = crb.frameMap.frameSize();
189                 asm.incrementq(rsp, frameSize);
190             }
191         }
192     }
193 
194     @Override
195     public CompilationResultBuilder newCompilationResultBuilder(LIRGenerationResult lirGenRen, FrameMap frameMap, CompilationResult compilationResult, CompilationResultBuilderFactory factory) {
196         // Omit the frame if the method:
197         // - has no spill slots or other slots allocated during register allocation
198         // - has no callee-saved registers
199         // - has no incoming arguments passed on the stack
200         // - has no deoptimization points
201         // - makes no foreign calls (which require an aligned stack)
202         HotSpotLIRGenerationResult gen = (HotSpotLIRGenerationResult) lirGenRen;
203         LIR lir = gen.getLIR();
204         assert gen.getDeoptimizationRescueSlot() == null || frameMap.frameNeedsAllocating() : &quot;method that can deoptimize must have a frame&quot;;
205         OptionValues options = lir.getOptions();
206         DebugContext debug = lir.getDebug();
207         boolean omitFrame = CanOmitFrame.getValue(options) &amp;&amp; !frameMap.frameNeedsAllocating() &amp;&amp; !lir.hasArgInCallerFrame() &amp;&amp; !gen.hasForeignCall();
208 
209         Stub stub = gen.getStub();
210         Assembler masm = new AMD64MacroAssembler(getTarget());
211         HotSpotFrameContext frameContext = new HotSpotFrameContext(stub != null, omitFrame);
212         DataBuilder dataBuilder = new HotSpotDataBuilder(getCodeCache().getTarget());
213         CompilationResultBuilder crb = factory.createBuilder(getCodeCache(), getForeignCalls(), frameMap, masm, dataBuilder, frameContext, options, debug, compilationResult, Register.None);
214         crb.setTotalFrameSize(frameMap.totalFrameSize());
215         crb.setMaxInterpreterFrameSize(gen.getMaxInterpreterFrameSize());
216         StackSlot deoptimizationRescueSlot = gen.getDeoptimizationRescueSlot();
217         if (deoptimizationRescueSlot != null &amp;&amp; stub == null) {
218             crb.compilationResult.setCustomStackAreaOffset(deoptimizationRescueSlot);
219         }
220 
221         if (stub != null) {
222             EconomicSet&lt;Register&gt; destroyedCallerRegisters = gatherDestroyedCallerRegisters(lir);
223             updateStub(stub, destroyedCallerRegisters, gen.getCalleeSaveInfo(), frameMap);
224         }
225 
226         return crb;
227     }
228 
229     @Override
230     public void emitCode(CompilationResultBuilder crb, LIR lir, ResolvedJavaMethod installedCodeOwner) {
231         AMD64MacroAssembler asm = (AMD64MacroAssembler) crb.asm;
232         FrameMap frameMap = crb.frameMap;
233         RegisterConfig regConfig = frameMap.getRegisterConfig();
234         Label verifiedEntry = new Label();
235 
236         // Emit the prefix
237         emitCodePrefix(installedCodeOwner, crb, asm, regConfig, verifiedEntry);
238 
239         // Emit code for the LIR
240         emitCodeBody(installedCodeOwner, crb, lir);
241 
242         // Emit the suffix
243         emitCodeSuffix(installedCodeOwner, crb, asm, frameMap);
244 
245         // Profile assembler instructions
246         profileInstructions(lir, crb);
247     }
248 
249     /**
250      * Emits the code prior to the verified entry point.
251      *
252      * @param installedCodeOwner see {@link LIRGenerationProvider#emitCode}
253      */
254     public void emitCodePrefix(ResolvedJavaMethod installedCodeOwner, CompilationResultBuilder crb, AMD64MacroAssembler asm, RegisterConfig regConfig, Label verifiedEntry) {
255         HotSpotProviders providers = getProviders();
256         if (installedCodeOwner != null &amp;&amp; !installedCodeOwner.isStatic()) {
257             crb.recordMark(config.MARKID_UNVERIFIED_ENTRY);
258             CallingConvention cc = regConfig.getCallingConvention(HotSpotCallingConventionType.JavaCallee, null, new JavaType[]{providers.getMetaAccess().lookupJavaType(Object.class)}, this);
259             Register inlineCacheKlass = rax; // see definition of IC_Klass in
260                                              // c1_LIRAssembler_x86.cpp
261             Register receiver = asRegister(cc.getArgument(0));
262             AMD64Address src = new AMD64Address(receiver, config.hubOffset);
263 
264             if (config.useCompressedClassPointers) {
265                 Register register = r10;
266                 AMD64HotSpotMove.decodeKlassPointer(crb, asm, register, providers.getRegisters().getHeapBaseRegister(), src, config);
267                 if (GeneratePIC.getValue(crb.getOptions())) {
268                     asm.movq(providers.getRegisters().getHeapBaseRegister(), asm.getPlaceholder(-1));
269                     crb.recordMark(config.MARKID_NARROW_OOP_BASE_ADDRESS);
270                 } else {
271                     if (config.narrowKlassBase != 0) {
272                         // The heap base register was destroyed above, so restore it
273                         asm.movq(providers.getRegisters().getHeapBaseRegister(), config.narrowOopBase);
274                     }
275                 }
276                 asm.cmpq(inlineCacheKlass, register);
277             } else {
278                 asm.cmpq(inlineCacheKlass, src);
279             }
280             AMD64Call.directConditionalJmp(crb, asm, getForeignCalls().lookupForeignCall(IC_MISS_HANDLER), ConditionFlag.NotEqual);
281         }
282 
283         asm.align(config.codeEntryAlignment);
284         crb.recordMark(config.MARKID_OSR_ENTRY);
285         asm.bind(verifiedEntry);
286         crb.recordMark(config.MARKID_VERIFIED_ENTRY);
287 
288         if (GeneratePIC.getValue(crb.getOptions())) {
289             // Check for method state
290             HotSpotFrameContext frameContext = (HotSpotFrameContext) crb.frameContext;
291             if (!frameContext.isStub) {
292                 crb.recordInlineDataInCodeWithNote(new HotSpotSentinelConstant(LIRKind.value(AMD64Kind.QWORD), JavaKind.Long), HotSpotConstantLoadAction.MAKE_NOT_ENTRANT);
293                 asm.movq(AMD64.rax, asm.getPlaceholder(-1));
294                 asm.testq(AMD64.rax, AMD64.rax);
295                 AMD64Call.directConditionalJmp(crb, asm, getForeignCalls().lookupForeignCall(WRONG_METHOD_HANDLER), ConditionFlag.NotZero);
296             }
297         }
298     }
299 
300     /**
301      * Emits the code which starts at the verified entry point.
302      *
303      * @param installedCodeOwner see {@link LIRGenerationProvider#emitCode}
304      */
305     public void emitCodeBody(ResolvedJavaMethod installedCodeOwner, CompilationResultBuilder crb, LIR lir) {
306         crb.emit(lir);
307     }
308 
309     /**
310      * @param installedCodeOwner see {@link LIRGenerationProvider#emitCode}
311      */
312     public void emitCodeSuffix(ResolvedJavaMethod installedCodeOwner, CompilationResultBuilder crb, AMD64MacroAssembler asm, FrameMap frameMap) {
313         HotSpotProviders providers = getProviders();
314         HotSpotFrameContext frameContext = (HotSpotFrameContext) crb.frameContext;
315         if (!frameContext.isStub) {
316             HotSpotForeignCallsProvider foreignCalls = providers.getForeignCalls();
317             crb.recordMark(config.MARKID_EXCEPTION_HANDLER_ENTRY);
318             AMD64Call.directCall(crb, asm, foreignCalls.lookupForeignCall(EXCEPTION_HANDLER), null, false, null);
319             crb.recordMark(config.MARKID_DEOPT_HANDLER_ENTRY);
320             AMD64Call.directCall(crb, asm, foreignCalls.lookupForeignCall(DEOPTIMIZATION_HANDLER), null, false, null);
321         } else {
322             // No need to emit the stubs for entries back into the method since
323             // it has no calls that can cause such &quot;return&quot; entries
324 
325             if (frameContext.omitFrame) {
326                 // Cannot access slots in caller&#39;s frame if my frame is omitted
327                 assert !frameMap.accessesCallerFrame();
328             }
329         }
330     }
331 
332     @Override
333     public RegisterAllocationConfig newRegisterAllocationConfig(RegisterConfig registerConfig, String[] allocationRestrictedTo) {
334         RegisterConfig registerConfigNonNull = registerConfig == null ? getCodeCache().getRegisterConfig() : registerConfig;
335         return new AMD64HotSpotRegisterAllocationConfig(registerConfigNonNull, allocationRestrictedTo);
336     }
337 
338     @Override
339     public EconomicSet&lt;Register&gt; translateToCallerRegisters(EconomicSet&lt;Register&gt; calleeRegisters) {
340         return calleeRegisters;
341     }
342 }
    </pre>
  </body>
</html>