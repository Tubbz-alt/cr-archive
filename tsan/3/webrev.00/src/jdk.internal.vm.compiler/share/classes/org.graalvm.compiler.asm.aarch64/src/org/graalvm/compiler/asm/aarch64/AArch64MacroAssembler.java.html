<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.asm.aarch64/src/org/graalvm/compiler/asm/aarch64/AArch64MacroAssembler.java</title>
    <link rel="stylesheet" href="../../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 2013, 2019, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  */
  23 
  24 
  25 
  26 package org.graalvm.compiler.asm.aarch64;
  27 
  28 import static jdk.vm.ci.aarch64.AArch64.CPU;
  29 import static jdk.vm.ci.aarch64.AArch64.rscratch1;
  30 import static jdk.vm.ci.aarch64.AArch64.rscratch2;
  31 import static jdk.vm.ci.aarch64.AArch64.sp;
  32 import static jdk.vm.ci.aarch64.AArch64.zr;
  33 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.BASE_REGISTER_ONLY;
  34 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.EXTENDED_REGISTER_OFFSET;
  35 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.IMMEDIATE_SCALED;
  36 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.IMMEDIATE_UNSCALED;
  37 import static org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode.REGISTER_OFFSET;
  38 import static org.graalvm.compiler.asm.aarch64.AArch64Assembler.Instruction.LDP;
  39 import static org.graalvm.compiler.asm.aarch64.AArch64Assembler.Instruction.STP;
  40 import static org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler.AddressGenerationPlan.WorkPlan.ADD_TO_BASE;
  41 import static org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler.AddressGenerationPlan.WorkPlan.ADD_TO_INDEX;
  42 import static org.graalvm.compiler.asm.aarch64.AArch64MacroAssembler.AddressGenerationPlan.WorkPlan.NO_WORK;
  43 
  44 import org.graalvm.compiler.asm.BranchTargetOutOfBoundsException;
  45 import org.graalvm.compiler.asm.Label;
  46 import org.graalvm.compiler.core.common.NumUtil;
  47 import org.graalvm.compiler.debug.GraalError;
  48 
  49 import jdk.vm.ci.aarch64.AArch64;
  50 import jdk.vm.ci.code.Register;
  51 import jdk.vm.ci.code.TargetDescription;
  52 
  53 public class AArch64MacroAssembler extends AArch64Assembler {
  54 
  55     private final ScratchRegister[] scratchRegister = new ScratchRegister[]{new ScratchRegister(rscratch1), new ScratchRegister(rscratch2)};
  56 
  57     // Points to the next free scratch register
  58     private int nextFreeScratchRegister = 0;
  59 
  60     // Last immediate ldr/str instruction, which is a candidate to be merged.
  61     private AArch64MemoryEncoding lastImmLoadStoreEncoding;
  62     private boolean isImmLoadStoreMerged = false;
  63 
  64     public AArch64MacroAssembler(TargetDescription target) {
  65         super(target);
  66     }
  67 
  68     public class ScratchRegister implements AutoCloseable {
  69         private final Register register;
  70 
  71         public ScratchRegister(Register register) {
  72             this.register = register;
  73         }
  74 
  75         public Register getRegister() {
  76             return register;
  77         }
  78 
  79         @Override
  80         public void close() {
  81             assert nextFreeScratchRegister &gt; 0 : &quot;Close called too often&quot;;
  82             nextFreeScratchRegister--;
  83         }
  84     }
  85 
  86     public ScratchRegister getScratchRegister() {
  87         return scratchRegister[nextFreeScratchRegister++];
  88     }
  89 
  90     @Override
  91     public void bind(Label l) {
  92         super.bind(l);
  93         // Clear last ldr/str instruction to prevent the labeled ldr/str being merged.
  94         lastImmLoadStoreEncoding = null;
  95     }
  96 
  97     private static class AArch64MemoryEncoding {
  98         private AArch64Address address;
  99         private Register result;
 100         private int sizeInBytes;
 101         private int position;
 102         private boolean isStore;
 103 
 104         AArch64MemoryEncoding(int sizeInBytes, Register result, AArch64Address address, boolean isStore, int position) {
 105             this.sizeInBytes = sizeInBytes;
 106             this.result = result;
 107             this.address = address;
 108             this.isStore = isStore;
 109             this.position = position;
 110             AArch64Address.AddressingMode addressingMode = address.getAddressingMode();
 111             assert addressingMode == IMMEDIATE_SCALED || addressingMode == IMMEDIATE_UNSCALED : &quot;Invalid address mode&quot; +
 112                             &quot;to merge: &quot; + addressingMode;
 113         }
 114 
 115         Register getBase() {
 116             return address.getBase();
 117         }
 118 
 119         int getOffset() {
 120             if (address.getAddressingMode() == IMMEDIATE_UNSCALED) {
 121                 return address.getImmediateRaw();
 122             }
 123             return address.getImmediate() * sizeInBytes;
 124         }
 125     }
 126 
 127     /**
 128      * Specifies what actions have to be taken to turn an arbitrary address of the form
 129      * {@code base + displacement [+ index [&lt;&lt; scale]]} into a valid AArch64Address.
 130      */
 131     public static class AddressGenerationPlan {
 132         public final WorkPlan workPlan;
 133         public final AArch64Address.AddressingMode addressingMode;
 134         public final boolean needsScratch;
 135 
 136         public enum WorkPlan {
 137             /**
 138              * Can be used as-is without extra work.
 139              */
 140             NO_WORK,
 141             /**
 142              * Add scaled displacement to index register.
 143              */
 144             ADD_TO_INDEX,
 145             /**
 146              * Add unscaled displacement to base register.
 147              */
 148             ADD_TO_BASE,
 149         }
 150 
 151         /**
 152          * @param workPlan Work necessary to generate a valid address.
 153          * @param addressingMode Addressing mode of generated address.
 154          * @param needsScratch True if generating address needs a scatch register, false otherwise.
 155          */
 156         public AddressGenerationPlan(WorkPlan workPlan, AArch64Address.AddressingMode addressingMode, boolean needsScratch) {
 157             this.workPlan = workPlan;
 158             this.addressingMode = addressingMode;
 159             this.needsScratch = needsScratch;
 160         }
 161     }
 162 
 163     /**
 164      * Generates an addressplan for an address of the form
 165      * {@code base + displacement [+ index [&lt;&lt; log2(transferSize)]]} with the index register and
 166      * scaling being optional.
 167      *
 168      * @param displacement an arbitrary displacement.
 169      * @param hasIndexRegister true if the address uses an index register, false otherwise. non null
 170      * @param transferSize the memory transfer size in bytes. The log2 of this specifies how much
 171      *            the index register is scaled. If 0 no scaling is assumed. Can be 0, 1, 2, 4 or 8.
 172      * @return AddressGenerationPlan that specifies the actions necessary to generate a valid
 173      *         AArch64Address for the given parameters.
 174      */
 175     public static AddressGenerationPlan generateAddressPlan(long displacement, boolean hasIndexRegister, int transferSize) {
 176         assert transferSize == 0 || transferSize == 1 || transferSize == 2 || transferSize == 4 || transferSize == 8;
 177         boolean indexScaled = transferSize != 0;
 178         int log2Scale = NumUtil.log2Ceil(transferSize);
 179         long scaledDisplacement = displacement &gt;&gt; log2Scale;
 180         boolean displacementScalable = indexScaled &amp;&amp; (displacement &amp; (transferSize - 1)) == 0;
 181         if (displacement == 0) {
 182             // register offset without any work beforehand.
 183             return new AddressGenerationPlan(NO_WORK, REGISTER_OFFSET, false);
 184         } else {
 185             if (hasIndexRegister) {
 186                 if (displacementScalable) {
 187                     boolean needsScratch = !isArithmeticImmediate(scaledDisplacement);
 188                     return new AddressGenerationPlan(ADD_TO_INDEX, REGISTER_OFFSET, needsScratch);
 189                 } else {
 190                     boolean needsScratch = !isArithmeticImmediate(displacement);
 191                     return new AddressGenerationPlan(ADD_TO_BASE, REGISTER_OFFSET, needsScratch);
 192                 }
 193             } else {
 194                 if (displacementScalable &amp;&amp; NumUtil.isUnsignedNbit(12, scaledDisplacement)) {
 195                     return new AddressGenerationPlan(NO_WORK, IMMEDIATE_SCALED, false);
 196                 } else if (NumUtil.isSignedNbit(9, displacement)) {
 197                     return new AddressGenerationPlan(NO_WORK, IMMEDIATE_UNSCALED, false);
 198                 } else {
 199                     boolean needsScratch = !isArithmeticImmediate(displacement);
 200                     return new AddressGenerationPlan(ADD_TO_BASE, REGISTER_OFFSET, needsScratch);
 201                 }
 202             }
 203         }
 204     }
 205 
 206     /**
 207      * Returns an AArch64Address pointing to
 208      * {@code base + displacement + index &lt;&lt; log2(transferSize)}.
 209      *
 210      * @param base general purpose register. May not be null or the zero register.
 211      * @param displacement arbitrary displacement added to base.
 212      * @param index general purpose register. May not be null or the stack pointer.
 213      * @param signExtendIndex if true consider index register a word register that should be
 214      *            sign-extended before being added.
 215      * @param transferSize the memory transfer size in bytes. The log2 of this specifies how much
 216      *            the index register is scaled. If 0 no scaling is assumed. Can be 0, 1, 2, 4 or 8.
 217      * @param additionalReg additional register used either as a scratch register or as part of the
 218      *            final address, depending on whether allowOverwrite is true or not. May not be null
 219      *            or stackpointer.
 220      * @param allowOverwrite if true allows to change value of base or index register to generate
 221      *            address.
 222      * @return AArch64Address pointing to memory at
 223      *         {@code base + displacement + index &lt;&lt; log2(transferSize)}.
 224      */
 225     public AArch64Address makeAddress(Register base, long displacement, Register index, boolean signExtendIndex, int transferSize, Register additionalReg, boolean allowOverwrite) {
 226         AddressGenerationPlan plan = generateAddressPlan(displacement, !index.equals(zr), transferSize);
 227         assert allowOverwrite || !zr.equals(additionalReg) || plan.workPlan == NO_WORK;
 228         assert !plan.needsScratch || !zr.equals(additionalReg);
 229         int log2Scale = NumUtil.log2Ceil(transferSize);
 230         long scaledDisplacement = displacement &gt;&gt; log2Scale;
 231         Register newIndex = index;
 232         Register newBase = base;
 233         int immediate;
 234         switch (plan.workPlan) {
 235             case NO_WORK:
 236                 if (plan.addressingMode == IMMEDIATE_SCALED) {
 237                     immediate = (int) scaledDisplacement;
 238                 } else {
 239                     immediate = (int) displacement;
 240                 }
 241                 break;
 242             case ADD_TO_INDEX:
 243                 newIndex = allowOverwrite ? index : additionalReg;
 244                 assert !newIndex.equals(sp) &amp;&amp; !newIndex.equals(zr);
 245                 if (plan.needsScratch) {
 246                     mov(additionalReg, scaledDisplacement);
 247                     add(signExtendIndex ? 32 : 64, newIndex, index, additionalReg);
 248                 } else {
 249                     add(signExtendIndex ? 32 : 64, newIndex, index, (int) scaledDisplacement);
 250                 }
 251                 immediate = 0;
 252                 break;
 253             case ADD_TO_BASE:
 254                 newBase = allowOverwrite ? base : additionalReg;
 255                 assert !newBase.equals(sp) &amp;&amp; !newBase.equals(zr);
 256                 if (plan.needsScratch) {
 257                     mov(additionalReg, displacement);
 258                     add(64, newBase, base, additionalReg);
 259                 } else {
 260                     add(64, newBase, base, (int) displacement);
 261                 }
 262                 immediate = 0;
 263                 break;
 264             default:
 265                 throw GraalError.shouldNotReachHere();
 266         }
 267         AArch64Address.AddressingMode addressingMode = plan.addressingMode;
 268         ExtendType extendType = null;
 269         if (addressingMode == REGISTER_OFFSET) {
 270             if (newIndex.equals(zr)) {
 271                 addressingMode = BASE_REGISTER_ONLY;
 272             } else if (signExtendIndex) {
 273                 addressingMode = EXTENDED_REGISTER_OFFSET;
 274                 extendType = ExtendType.SXTW;
 275             }
 276         }
 277         return AArch64Address.createAddress(addressingMode, newBase, newIndex, immediate, transferSize != 0, extendType);
 278     }
 279 
 280     /**
 281      * Returns an AArch64Address pointing to {@code base + displacement}. Specifies the memory
 282      * transfer size to allow some optimizations when building the address.
 283      *
 284      * @param base general purpose register. May not be null or the zero register.
 285      * @param displacement arbitrary displacement added to base.
 286      * @param transferSize the memory transfer size in bytes.
 287      * @param additionalReg additional register used either as a scratch register or as part of the
 288      *            final address, depending on whether allowOverwrite is true or not. May not be
 289      *            null, zero register or stackpointer.
 290      * @param allowOverwrite if true allows to change value of base or index register to generate
 291      *            address.
 292      * @return AArch64Address pointing to memory at {@code base + displacement}.
 293      */
 294     public AArch64Address makeAddress(Register base, long displacement, Register additionalReg, int transferSize, boolean allowOverwrite) {
 295         assert additionalReg.getRegisterCategory().equals(CPU);
 296         return makeAddress(base, displacement, zr, /* sign-extend */false, transferSize, additionalReg, allowOverwrite);
 297     }
 298 
 299     /**
 300      * Returns an AArch64Address pointing to {@code base + displacement}. Fails if address cannot be
 301      * represented without overwriting base register or using a scratch register.
 302      *
 303      * @param base general purpose register. May not be null or the zero register.
 304      * @param displacement arbitrary displacement added to base.
 305      * @param transferSize the memory transfer size in bytes. The log2 of this specifies how much
 306      *            the index register is scaled. If 0 no scaling is assumed. Can be 0, 1, 2, 4 or 8.
 307      * @return AArch64Address pointing to memory at {@code base + displacement}.
 308      */
 309     public AArch64Address makeAddress(Register base, long displacement, int transferSize) {
 310         return makeAddress(base, displacement, zr, /* signExtend */false, //
 311                         transferSize, zr, /* allowOverwrite */false);
 312     }
 313 
 314     /**
 315      * Loads memory address into register.
 316      *
 317      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 318      * @param address address whose value is loaded into dst. May not be null,
 319      *            {@link org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode#IMMEDIATE_POST_INDEXED
 320      *            POST_INDEXED} or
 321      *            {@link org.graalvm.compiler.asm.aarch64.AArch64Address.AddressingMode#IMMEDIATE_PRE_INDEXED
 322      *            IMMEDIATE_PRE_INDEXED}
 323      * @param transferSize the memory transfer size in bytes. The log2 of this specifies how much
 324      *            the index register is scaled. Can be 1, 2, 4 or 8.
 325      */
 326     public void loadAddress(Register dst, AArch64Address address, int transferSize) {
 327         assert transferSize == 1 || transferSize == 2 || transferSize == 4 || transferSize == 8;
 328         assert dst.getRegisterCategory().equals(CPU);
 329         int shiftAmt = NumUtil.log2Ceil(transferSize);
 330         switch (address.getAddressingMode()) {
 331             case IMMEDIATE_SCALED:
 332                 int scaledImmediate = address.getImmediateRaw() &lt;&lt; shiftAmt;
 333                 int lowerBits = scaledImmediate &amp; NumUtil.getNbitNumberInt(12);
 334                 int higherBits = scaledImmediate &amp; ~NumUtil.getNbitNumberInt(12);
 335                 boolean firstAdd = true;
 336                 if (lowerBits != 0) {
 337                     add(64, dst, address.getBase(), lowerBits);
 338                     firstAdd = false;
 339                 }
 340                 if (higherBits != 0) {
 341                     Register src = firstAdd ? address.getBase() : dst;
 342                     add(64, dst, src, higherBits);
 343                 }
 344                 break;
 345             case IMMEDIATE_UNSCALED:
 346                 int immediate = address.getImmediateRaw();
 347                 add(64, dst, address.getBase(), immediate);
 348                 break;
 349             case REGISTER_OFFSET:
 350                 add(64, dst, address.getBase(), address.getOffset(), ShiftType.LSL, address.isScaled() ? shiftAmt : 0);
 351                 break;
 352             case EXTENDED_REGISTER_OFFSET:
 353                 add(64, dst, address.getBase(), address.getOffset(), address.getExtendType(), address.isScaled() ? shiftAmt : 0);
 354                 break;
 355             case PC_LITERAL: {
 356                 addressOf(dst);
 357                 break;
 358             }
 359             case BASE_REGISTER_ONLY:
 360                 movx(dst, address.getBase());
 361                 break;
 362             default:
 363                 throw GraalError.shouldNotReachHere();
 364         }
 365     }
 366 
 367     private boolean tryMerge(int sizeInBytes, Register rt, AArch64Address address, boolean isStore) {
 368         isImmLoadStoreMerged = false;
 369         if (lastImmLoadStoreEncoding == null) {
 370             return false;
 371         }
 372 
 373         // Only immediate scaled/unscaled address can be merged.
 374         // Pre-index and post-index mode can&#39;t be merged.
 375         AArch64Address.AddressingMode addressMode = address.getAddressingMode();
 376         if (addressMode != IMMEDIATE_SCALED &amp;&amp; addressMode != IMMEDIATE_UNSCALED) {
 377             return false;
 378         }
 379 
 380         // Only the two adjacent ldrs/strs can be merged.
 381         int lastPosition = position() - 4;
 382         if (lastPosition &lt; 0 || lastPosition != lastImmLoadStoreEncoding.position) {
 383             return false;
 384         }
 385 
 386         if (isStore != lastImmLoadStoreEncoding.isStore) {
 387             return false;
 388         }
 389 
 390         // Only merge ldr/str with the same size of 32bits or 64bits.
 391         if (sizeInBytes != lastImmLoadStoreEncoding.sizeInBytes || (sizeInBytes != 4 &amp;&amp; sizeInBytes != 8)) {
 392             return false;
 393         }
 394 
 395         // Base register must be the same one.
 396         Register curBase = address.getBase();
 397         Register preBase = lastImmLoadStoreEncoding.getBase();
 398         if (!curBase.equals(preBase)) {
 399             return false;
 400         }
 401 
 402         // If the two ldrs have the same rt register, they can&#39;t be merged.
 403         // If the two ldrs have dependence, they can&#39;t be merged.
 404         Register curRt = rt;
 405         Register preRt = lastImmLoadStoreEncoding.result;
 406         if (!isStore &amp;&amp; (curRt.equals(preRt) || preRt.equals(curBase))) {
 407             return false;
 408         }
 409 
 410         // Offset checking. Offsets of the two ldrs/strs must be continuous.
 411         int curOffset = address.getImmediateRaw();
 412         if (addressMode == IMMEDIATE_SCALED) {
 413             curOffset = curOffset * sizeInBytes;
 414         }
 415         int preOffset = lastImmLoadStoreEncoding.getOffset();
 416         if (Math.abs(curOffset - preOffset) != sizeInBytes) {
 417             return false;
 418         }
 419 
 420         // Offset must be in ldp/stp instruction&#39;s range.
 421         int offset = curOffset &gt; preOffset ? preOffset : curOffset;
 422         int minOffset = -64 * sizeInBytes;
 423         int maxOffset = 63 * sizeInBytes;
 424         if (offset &lt; minOffset || offset &gt; maxOffset) {
 425             return false;
 426         }
 427 
 428         // Alignment checking.
 429         if (isFlagSet(AArch64.Flag.AvoidUnalignedAccesses)) {
 430             // AArch64 sp is 16-bytes aligned.
 431             if (curBase.equals(sp)) {
 432                 long pairMask = sizeInBytes * 2 - 1;
 433                 if ((offset &amp; pairMask) != 0) {
 434                     return false;
 435                 }
 436             } else {
 437                 // If base is not sp, we can&#39;t guarantee the access is aligned.
 438                 return false;
 439             }
 440         } else {
 441             // ldp/stp only supports sizeInBytes aligned offset.
 442             long mask = sizeInBytes - 1;
 443             if ((curOffset &amp; mask) != 0 || (preOffset &amp; mask) != 0) {
 444                 return false;
 445             }
 446         }
 447 
 448         // Merge two ldrs/strs to ldp/stp.
 449         Register rt1 = preRt;
 450         Register rt2 = curRt;
 451         if (curOffset &lt; preOffset) {
 452             rt1 = curRt;
 453             rt2 = preRt;
 454         }
 455         int immediate = offset / sizeInBytes;
 456         Instruction instruction = isStore ? STP : LDP;
 457         int size = sizeInBytes * Byte.SIZE;
 458         insertLdpStp(size, instruction, rt1, rt2, curBase, immediate, lastPosition);
 459         lastImmLoadStoreEncoding = null;
 460         isImmLoadStoreMerged = true;
 461         return true;
 462     }
 463 
 464     /**
 465      * Try to merge two continuous ldr/str to one ldp/stp. If this current ldr/str is not merged,
 466      * save it as the last ldr/str.
 467      */
 468     private boolean tryMergeLoadStore(int srcSize, Register rt, AArch64Address address, boolean isStore) {
 469         int sizeInBytes = srcSize / Byte.SIZE;
 470         if (tryMerge(sizeInBytes, rt, address, isStore)) {
 471             return true;
 472         }
 473 
 474         // Save last ldr/str if it is not merged.
 475         AArch64Address.AddressingMode addressMode = address.getAddressingMode();
 476         if (addressMode == IMMEDIATE_SCALED || addressMode == IMMEDIATE_UNSCALED) {
 477             if (addressMode == IMMEDIATE_UNSCALED) {
 478                 long mask = sizeInBytes - 1;
 479                 int offset = address.getImmediateRaw();
 480                 if ((offset &amp; mask) != 0) {
 481                     return false;
 482                 }
 483             }
 484             lastImmLoadStoreEncoding = new AArch64MemoryEncoding(sizeInBytes, rt, address, isStore, position());
 485         }
 486         return false;
 487     }
 488 
 489     public boolean isImmLoadStoreMerged() {
 490         return isImmLoadStoreMerged;
 491     }
 492 
 493     public void movx(Register dst, Register src) {
 494         mov(64, dst, src);
 495     }
 496 
 497     public void mov(int size, Register dst, Register src) {
 498         if (dst.equals(sp) || src.equals(sp)) {
 499             add(size, dst, src, 0);
 500         } else {
 501             or(size, dst, zr, src);
 502         }
 503     }
 504 
 505     /**
 506      * Generates a 64-bit immediate move code sequence.
 507      *
 508      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 509      * @param imm the value to move into the register
 510      * @param annotateImm Flag denoting if annotation should be added.
 511      */
 512     private void mov64(Register dst, long imm, boolean annotateImm) {
 513         // We have to move all non zero parts of the immediate in 16-bit chunks
 514         int numMovs = 0;
 515         int pos = position();
 516         boolean firstMove = true;
 517         for (int offset = 0; offset &lt; 64; offset += 16) {
 518             int chunk = (int) (imm &gt;&gt; offset) &amp; NumUtil.getNbitNumberInt(16);
 519             if (chunk == 0) {
 520                 continue;
 521             }
 522             if (firstMove) {
 523                 movz(64, dst, chunk, offset);
 524                 firstMove = false;
 525             } else {
 526                 movk(64, dst, chunk, offset);
 527             }
 528             ++numMovs;
 529         }
 530         assert !firstMove;
 531         if (annotateImm) {
 532             annotateImmediateMovSequence(pos, numMovs);
 533         }
 534     }
 535 
 536     /**
 537      * Loads immediate into register.
 538      *
 539      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 540      * @param imm immediate loaded into register.
 541      */
 542     public void mov(Register dst, long imm) {
 543         mov(dst, imm, false);
 544     }
 545 
 546     /**
 547      * Loads immediate into register.
 548      *
 549      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 550      * @param imm immediate loaded into register.
 551      * @param annotateImm Flag to signal of the immediate value should be annotated.
 552      */
 553     public void mov(Register dst, long imm, boolean annotateImm) {
 554         assert dst.getRegisterCategory().equals(CPU);
 555         if (imm == 0L) {
 556             movx(dst, zr);
 557         } else if (LogicalImmediateTable.isRepresentable(true, imm) != LogicalImmediateTable.Representable.NO) {
 558             or(64, dst, zr, imm);
 559         } else if (imm &gt;&gt; 32 == -1L &amp;&amp; (int) imm &lt; 0 &amp;&amp; LogicalImmediateTable.isRepresentable((int) imm) != LogicalImmediateTable.Representable.NO) {
 560             // If the higher 32-bit are 1s and the sign bit of the lower 32-bits is set *and* we can
 561             // represent the lower 32 bits as a logical immediate we can create the lower 32-bit and
 562             // then sign extend
 563             // them. This allows us to cover immediates like ~1L with 2 instructions.
 564             mov(dst, (int) imm);
 565             sxt(64, 32, dst, dst);
 566         } else {
 567             mov64(dst, imm, annotateImm);
 568         }
 569     }
 570 
 571     /**
 572      * Loads immediate into register.
 573      *
 574      * @param dst general purpose register. May not be null, zero-register or stackpointer.
 575      * @param imm immediate loaded into register.
 576      */
 577     public void mov(Register dst, int imm) {
 578         mov(dst, imm &amp; 0xFFFF_FFFFL);
 579     }
 580 
 581     /**
 582      * Generates a 48-bit immediate move code sequence. The immediate may later be updated by
 583      * HotSpot.
 584      *
 585      * In AArch64 mode the virtual address space is 48-bits in size, so we only need three
 586      * instructions to create a patchable instruction sequence that can reach anywhere.
 587      *
 588      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 589      * @param imm
 590      */
 591     public void movNativeAddress(Register dst, long imm) {
 592         movNativeAddress(dst, imm, false);
 593     }
 594 
 595     /**
 596      * Generates a 48-bit immediate move code sequence. The immediate may later be updated by
 597      * HotSpot.
 598      *
 599      * In AArch64 mode the virtual address space is 48-bits in size, so we only need three
 600      * instructions to create a patchable instruction sequence that can reach anywhere.
 601      *
 602      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 603      * @param imm The immediate address
 604      * @param annotateImm Flag to signal of the immediate value should be annotated.
 605      */
 606     public void movNativeAddress(Register dst, long imm, boolean annotateImm) {
 607         assert (imm &amp; 0xFFFF_0000_0000_0000L) == 0;
 608         // We have to move all non zero parts of the immediate in 16-bit chunks
 609         boolean firstMove = true;
 610         int pos = position();
 611         for (int offset = 0; offset &lt; 48; offset += 16) {
 612             int chunk = (int) (imm &gt;&gt; offset) &amp; NumUtil.getNbitNumberInt(16);
 613             if (firstMove) {
 614                 movz(64, dst, chunk, offset);
 615                 firstMove = false;
 616             } else {
 617                 movk(64, dst, chunk, offset);
 618             }
 619         }
 620         if (annotateImm) {
 621             annotateImmediateMovSequence(pos, 3);
 622         }
 623         assert !firstMove;
 624     }
 625 
 626     /**
 627      * Generates a 32-bit immediate move code sequence. The immediate may later be updated by
 628      * HotSpot.
 629      *
 630      * @param dst general purpose register. May not be null, stackpointer or zero-register.
 631      * @param imm
 632      */
 633     public void movNarrowAddress(Register dst, long imm) {
 634         assert (imm &amp; 0xFFFF_FFFF_0000_0000L) == 0;
 635         movz(64, dst, (int) (imm &gt;&gt;&gt; 16), 16);
 636         movk(64, dst, (int) (imm &amp; 0xffff), 0);
 637     }
 638 
 639     /**
 640      * @return Number of instructions necessary to load immediate into register.
 641      */
 642     public static int nrInstructionsToMoveImmediate(long imm) {
 643         if (imm == 0L || LogicalImmediateTable.isRepresentable(true, imm) != LogicalImmediateTable.Representable.NO) {
 644             return 1;
 645         }
 646         if (imm &gt;&gt; 32 == -1L &amp;&amp; (int) imm &lt; 0 &amp;&amp; LogicalImmediateTable.isRepresentable((int) imm) != LogicalImmediateTable.Representable.NO) {
 647             // If the higher 32-bit are 1s and the sign bit of the lower 32-bits is set *and* we can
 648             // represent the lower 32 bits as a logical immediate we can create the lower 32-bit and
 649             // then sign extend
 650             // them. This allows us to cover immediates like ~1L with 2 instructions.
 651             return 2;
 652         }
 653         int nrInstructions = 0;
 654         for (int offset = 0; offset &lt; 64; offset += 16) {
 655             int part = (int) (imm &gt;&gt; offset) &amp; NumUtil.getNbitNumberInt(16);
 656             if (part != 0) {
 657                 nrInstructions++;
 658             }
 659         }
 660         return nrInstructions;
 661     }
 662 
 663     /**
 664      * Loads a srcSize value from address into rt sign-extending it if necessary.
 665      *
 666      * @param targetSize size of target register in bits. Must be 32 or 64.
 667      * @param srcSize size of memory read in bits. Must be 8, 16 or 32 and smaller or equal to
 668      *            targetSize.
 669      * @param rt general purpose register. May not be null or stackpointer.
 670      * @param address all addressing modes allowed. May not be null.
 671      */
 672     @Override
 673     public void ldrs(int targetSize, int srcSize, Register rt, AArch64Address address) {
 674         assert targetSize == 32 || targetSize == 64;
 675         assert srcSize &lt;= targetSize;
 676         if (targetSize == srcSize) {
 677             ldr(srcSize, rt, address);
 678         } else {
 679             super.ldrs(targetSize, srcSize, rt, address);
 680         }
 681     }
 682 
 683     /**
 684      * Loads a srcSize value from address into rt zero-extending it if necessary.
 685      *
 686      * @param srcSize size of memory read in bits. Must be 8, 16 or 32 and smaller or equal to
 687      *            targetSize.
 688      * @param rt general purpose register. May not be null or stackpointer.
 689      * @param address all addressing modes allowed. May not be null.
 690      */
 691     @Override
 692     public void ldr(int srcSize, Register rt, AArch64Address address) {
 693         // Try to merge two adjacent loads into one ldp.
 694         if (!tryMergeLoadStore(srcSize, rt, address, false)) {
 695             super.ldr(srcSize, rt, address);
 696         }
 697     }
 698 
 699     /**
 700      * Stores register rt into memory pointed by address.
 701      *
 702      * @param destSize number of bits written to memory. Must be 8, 16, 32 or 64.
 703      * @param rt general purpose register. May not be null or stackpointer.
 704      * @param address all addressing modes allowed. May not be null.
 705      */
 706     @Override
 707     public void str(int destSize, Register rt, AArch64Address address) {
 708         // Try to merge two adjacent stores into one stp.
 709         if (!tryMergeLoadStore(destSize, rt, address, true)) {
 710             super.str(destSize, rt, address);
 711         }
 712     }
 713 
 714     /**
 715      * Conditional move. dst = src1 if condition else src2.
 716      *
 717      * @param size register size. Has to be 32 or 64.
 718      * @param result general purpose register. May not be null or the stackpointer.
 719      * @param trueValue general purpose register. May not be null or the stackpointer.
 720      * @param falseValue general purpose register. May not be null or the stackpointer.
 721      * @param cond any condition flag. May not be null.
 722      */
 723     public void cmov(int size, Register result, Register trueValue, Register falseValue, ConditionFlag cond) {
 724         super.csel(size, result, trueValue, falseValue, cond);
 725     }
 726 
 727     /**
 728      * Conditional set. dst = 1 if condition else 0.
 729      *
 730      * @param dst general purpose register. May not be null or stackpointer.
 731      * @param condition any condition. May not be null.
 732      */
 733     public void cset(int size, Register dst, ConditionFlag condition) {
 734         super.csinc(size, dst, zr, zr, condition.negate());
 735     }
 736 
 737     /**
 738      * dst = src1 + src2.
 739      *
 740      * @param size register size. Has to be 32 or 64.
 741      * @param dst general purpose register. May not be null.
 742      * @param src1 general purpose register. May not be null.
 743      * @param src2 general purpose register. May not be null or stackpointer.
 744      */
 745     public void add(int size, Register dst, Register src1, Register src2) {
 746         if (dst.equals(sp) || src1.equals(sp)) {
 747             super.add(size, dst, src1, src2, ExtendType.UXTX, 0);
 748         } else {
 749             super.add(size, dst, src1, src2, ShiftType.LSL, 0);
 750         }
 751     }
 752 
 753     /**
 754      * dst = src1 + src2 and sets condition flags.
 755      *
 756      * @param size register size. Has to be 32 or 64.
 757      * @param dst general purpose register. May not be null.
 758      * @param src1 general purpose register. May not be null.
 759      * @param src2 general purpose register. May not be null or stackpointer.
 760      */
 761     public void adds(int size, Register dst, Register src1, Register src2) {
 762         if (dst.equals(sp) || src1.equals(sp)) {
 763             super.adds(size, dst, src1, src2, ExtendType.UXTX, 0);
 764         } else {
 765             super.adds(size, dst, src1, src2, ShiftType.LSL, 0);
 766         }
 767     }
 768 
 769     /**
 770      * dst = src1 - src2 and sets condition flags.
 771      *
 772      * @param size register size. Has to be 32 or 64.
 773      * @param dst general purpose register. May not be null.
 774      * @param src1 general purpose register. May not be null.
 775      * @param src2 general purpose register. May not be null or stackpointer.
 776      */
 777     public void subs(int size, Register dst, Register src1, Register src2) {
 778         if (dst.equals(sp) || src1.equals(sp)) {
 779             super.subs(size, dst, src1, src2, ExtendType.UXTX, 0);
 780         } else {
 781             super.subs(size, dst, src1, src2, ShiftType.LSL, 0);
 782         }
 783     }
 784 
 785     /**
 786      * dst = src1 - src2.
 787      *
 788      * @param size register size. Has to be 32 or 64.
 789      * @param dst general purpose register. May not be null.
 790      * @param src1 general purpose register. May not be null.
 791      * @param src2 general purpose register. May not be null or stackpointer.
 792      */
 793     public void sub(int size, Register dst, Register src1, Register src2) {
 794         if (dst.equals(sp) || src1.equals(sp)) {
 795             super.sub(size, dst, src1, src2, ExtendType.UXTX, 0);
 796         } else {
 797             super.sub(size, dst, src1, src2, ShiftType.LSL, 0);
 798         }
 799     }
 800 
 801     /**
 802      * dst = src1 + shiftType(src2, shiftAmt &amp; (size - 1)).
 803      *
 804      * @param size register size. Has to be 32 or 64.
 805      * @param dst general purpose register. May not be null or stackpointer.
 806      * @param src1 general purpose register. May not be null or stackpointer.
 807      * @param src2 general purpose register. May not be null or stackpointer.
 808      * @param shiftType any type but ROR.
 809      * @param shiftAmt arbitrary shift amount.
 810      */
 811     @Override
 812     public void add(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
 813         int shift = clampShiftAmt(size, shiftAmt);
 814         super.add(size, dst, src1, src2, shiftType, shift);
 815     }
 816 
 817     /**
 818      * dst = src1 + shiftType(src2, shiftAmt &amp; (size-1)) and sets condition flags.
 819      *
 820      * @param size register size. Has to be 32 or 64.
 821      * @param dst general purpose register. May not be null or stackpointer.
 822      * @param src1 general purpose register. May not be null or stackpointer.
 823      * @param src2 general purpose register. May not be null or stackpointer.
 824      * @param shiftType any type but ROR.
 825      * @param shiftAmt arbitrary shift amount.
 826      */
 827     @Override
 828     public void sub(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
 829         int shift = clampShiftAmt(size, shiftAmt);
 830         super.sub(size, dst, src1, src2, shiftType, shift);
 831     }
 832 
 833     /**
 834      * dst = -src1.
 835      *
 836      * @param size register size. Has to be 32 or 64.
 837      * @param dst general purpose register. May not be null or stackpointer.
 838      * @param src general purpose register. May not be null or stackpointer.
 839      */
 840     public void neg(int size, Register dst, Register src) {
 841         sub(size, dst, zr, src);
 842     }
 843 
 844     /**
 845      * dst = src + immediate.
 846      *
 847      * @param size register size. Has to be 32 or 64.
 848      * @param dst general purpose register. May not be null or zero-register.
 849      * @param src general purpose register. May not be null or zero-register.
 850      * @param immediate 32-bit signed int
 851      */
 852     @Override
 853     public void add(int size, Register dst, Register src, int immediate) {
 854         assert (!dst.equals(zr) &amp;&amp; !src.equals(zr));
 855         if (immediate &lt; 0) {
 856             sub(size, dst, src, -immediate);
 857         } else if (isAimm(immediate)) {
 858             if (!(dst.equals(src) &amp;&amp; immediate == 0)) {
 859                 super.add(size, dst, src, immediate);
 860             }
 861         } else if (immediate &gt;= -(1 &lt;&lt; 24) &amp;&amp; immediate &lt; (1 &lt;&lt; 24)) {
 862             super.add(size, dst, src, immediate &amp; -(1 &lt;&lt; 12));
 863             super.add(size, dst, dst, immediate &amp; ((1 &lt;&lt; 12) - 1));
 864         } else {
 865             assert !dst.equals(src);
 866             mov(dst, immediate);
 867             add(size, src, dst, dst);
 868         }
 869     }
 870 
 871     /**
 872      * dst = src + immediate.
 873      *
 874      * @param size register size. Has to be 32 or 64.
 875      * @param dst general purpose register. May not be null or zero-register.
 876      * @param src general purpose register. May not be null or zero-register.
 877      * @param immediate 64-bit signed int
 878      */
 879     public void add(int size, Register dst, Register src, long immediate) {
 880         if (NumUtil.isInt(immediate)) {
 881             add(size, dst, src, (int) immediate);
 882         } else {
 883             assert (!dst.equals(zr) &amp;&amp; !src.equals(zr));
 884             assert !dst.equals(src);
 885             assert size == 64;
 886             mov(dst, immediate);
 887             add(size, src, dst, dst);
 888         }
 889     }
 890 
 891     /**
 892      * dst = src + aimm and sets condition flags.
 893      *
 894      * @param size register size. Has to be 32 or 64.
 895      * @param dst general purpose register. May not be null or stackpointer.
 896      * @param src general purpose register. May not be null or zero-register.
 897      * @param immediate arithmetic immediate.
 898      */
 899     @Override
 900     public void adds(int size, Register dst, Register src, int immediate) {
 901         assert (!dst.equals(sp) &amp;&amp; !src.equals(zr));
 902         if (immediate &lt; 0) {
 903             subs(size, dst, src, -immediate);
 904         } else if (!(dst.equals(src) &amp;&amp; immediate == 0)) {
 905             super.adds(size, dst, src, immediate);
 906         }
 907     }
 908 
 909     /**
 910      * dst = src - immediate.
 911      *
 912      * @param size register size. Has to be 32 or 64.
 913      * @param dst general purpose register. May not be null or zero-register.
 914      * @param src general purpose register. May not be null or zero-register.
 915      * @param immediate 32-bit signed int
 916      */
 917     @Override
 918     public void sub(int size, Register dst, Register src, int immediate) {
 919         assert (!dst.equals(zr) &amp;&amp; !src.equals(zr));
 920         if (immediate &lt; 0) {
 921             add(size, dst, src, -immediate);
 922         } else if (isAimm(immediate)) {
 923             if (!(dst.equals(src) &amp;&amp; immediate == 0)) {
 924                 super.sub(size, dst, src, immediate);
 925             }
 926         } else if (immediate &gt;= -(1 &lt;&lt; 24) &amp;&amp; immediate &lt; (1 &lt;&lt; 24)) {
 927             super.sub(size, dst, src, immediate &amp; -(1 &lt;&lt; 12));
 928             super.sub(size, dst, dst, immediate &amp; ((1 &lt;&lt; 12) - 1));
 929         } else {
 930             assert !dst.equals(src);
 931             mov(dst, immediate);
 932             sub(size, src, dst, dst);
 933         }
 934     }
 935 
 936     /**
 937      * dst = src - aimm and sets condition flags.
 938      *
 939      * @param size register size. Has to be 32 or 64.
 940      * @param dst general purpose register. May not be null or stackpointer.
 941      * @param src general purpose register. May not be null or zero-register.
 942      * @param immediate arithmetic immediate.
 943      */
 944     @Override
 945     public void subs(int size, Register dst, Register src, int immediate) {
 946         assert (!dst.equals(sp) &amp;&amp; !src.equals(zr));
 947         if (immediate &lt; 0) {
 948             adds(size, dst, src, -immediate);
 949         } else if (!dst.equals(src) || immediate != 0) {
 950             super.subs(size, dst, src, immediate);
 951         }
 952     }
 953 
 954     /**
 955      * dst = src1 * src2.
 956      *
 957      * @param size register size. Has to be 32 or 64.
 958      * @param dst general purpose register. May not be null or the stackpointer.
 959      * @param src1 general purpose register. May not be null or the stackpointer.
 960      * @param src2 general purpose register. May not be null or the stackpointer.
 961      */
 962     public void mul(int size, Register dst, Register src1, Register src2) {
 963         super.madd(size, dst, src1, src2, zr);
 964     }
 965 
 966     /**
 967      * dst = src3 + src1 * src2.
 968      *
 969      * @param size register size. Has to be 32 or 64.
 970      * @param dst general purpose register. May not be null or the stackpointer.
 971      * @param src1 general purpose register. May not be null or the stackpointer.
 972      * @param src2 general purpose register. May not be null or the stackpointer.
 973      * @param src3 general purpose register. May not be null or the stackpointer.
 974      */
 975     @Override
 976     public void madd(int size, Register dst, Register src1, Register src2, Register src3) {
 977         super.madd(size, dst, src1, src2, src3);
 978     }
 979 
 980     /**
 981      * dst = src3 - src1 * src2.
 982      *
 983      * @param size register size. Has to be 32 or 64.
 984      * @param dst general purpose register. May not be null or the stackpointer.
 985      * @param src1 general purpose register. May not be null or the stackpointer.
 986      * @param src2 general purpose register. May not be null or the stackpointer.
 987      * @param src3 general purpose register. May not be null or the stackpointer.
 988      */
 989     @Override
 990     public void msub(int size, Register dst, Register src1, Register src2, Register src3) {
 991         super.msub(size, dst, src1, src2, src3);
 992     }
 993 
 994     /**
 995      * dst = 0 - src1 * src2.
 996      *
 997      * @param size register size. Has to be 32 or 64.
 998      * @param dst general purpose register. May not be null or the stackpointer.
 999      * @param src1 general purpose register. May not be null or the stackpointer.
1000      * @param src2 general purpose register. May not be null or the stackpointer.
1001      */
1002     public void mneg(int size, Register dst, Register src1, Register src2) {
1003         super.msub(size, dst, src1, src2, zr);
1004     }
1005 
1006     /**
1007      * Unsigned multiply high. dst = (src1 * src2) &gt;&gt; size
1008      *
1009      * @param size register size. Has to be 32 or 64.
1010      * @param dst general purpose register. May not be null or the stackpointer.
1011      * @param src1 general purpose register. May not be null or the stackpointer.
1012      * @param src2 general purpose register. May not be null or the stackpointer.
1013      */
1014     public void umulh(int size, Register dst, Register src1, Register src2) {
1015         assert (!dst.equals(sp) &amp;&amp; !src1.equals(sp) &amp;&amp; !src2.equals(sp));
1016         assert size == 32 || size == 64;
1017         if (size == 64) {
1018             super.umulh(dst, src1, src2);
1019         } else {
1020             // xDst = wSrc1 * wSrc2
1021             super.umaddl(dst, src1, src2, zr);
1022             // xDst = xDst &gt;&gt; 32
1023             lshr(64, dst, dst, 32);
1024         }
1025     }
1026 
1027     /**
1028      * Signed multiply high. dst = (src1 * src2) &gt;&gt; size
1029      *
1030      * @param size register size. Has to be 32 or 64.
1031      * @param dst general purpose register. May not be null or the stackpointer.
1032      * @param src1 general purpose register. May not be null or the stackpointer.
1033      * @param src2 general purpose register. May not be null or the stackpointer.
1034      */
1035     public void smulh(int size, Register dst, Register src1, Register src2) {
1036         assert (!dst.equals(sp) &amp;&amp; !src1.equals(sp) &amp;&amp; !src2.equals(sp));
1037         assert size == 32 || size == 64;
1038         if (size == 64) {
1039             super.smulh(dst, src1, src2);
1040         } else {
1041             // xDst = wSrc1 * wSrc2
1042             super.smaddl(dst, src1, src2, zr);
1043             // xDst = xDst &gt;&gt; 32
1044             lshr(64, dst, dst, 32);
1045         }
1046     }
1047 
1048     /**
1049      * Signed multiply long. xDst = wSrc1 * wSrc2
1050      *
1051      * @param size destination register size. Has to be 64.
1052      * @param dst 64-bit general purpose register. May not be null or the stackpointer.
1053      * @param src1 32-bit general purpose register. May not be null or the stackpointer.
1054      * @param src2 32-bit general purpose register. May not be null or the stackpointer.
1055      */
1056     public void smull(int size, Register dst, Register src1, Register src2) {
1057         this.smaddl(size, dst, src1, src2, zr);
1058     }
1059 
1060     /**
1061      * Signed multiply-negate long. xDst = -(wSrc1 * wSrc2)
1062      *
1063      * @param size destination register size. Has to be 64.
1064      * @param dst 64-bit general purpose register. May not be null or the stackpointer.
1065      * @param src1 32-bit general purpose register. May not be null or the stackpointer.
1066      * @param src2 32-bit general purpose register. May not be null or the stackpointer.
1067      */
1068     public void smnegl(int size, Register dst, Register src1, Register src2) {
1069         this.smsubl(size, dst, src1, src2, zr);
1070     }
1071 
1072     /**
1073      * Signed multiply-add long. xDst = xSrc3 + (wSrc1 * wSrc2)
1074      *
1075      * @param size destination register size. Has to be 64.
1076      * @param dst 64-bit general purpose register. May not be null or the stackpointer.
1077      * @param src1 32-bit general purpose register. May not be null or the stackpointer.
1078      * @param src2 32-bit general purpose register. May not be null or the stackpointer.
1079      * @param src3 64-bit general purpose register. May not be null or the stackpointer.
1080      */
1081     public void smaddl(int size, Register dst, Register src1, Register src2, Register src3) {
1082         assert (!dst.equals(sp) &amp;&amp; !src1.equals(sp) &amp;&amp; !src2.equals(sp) &amp;&amp; !src3.equals(sp));
1083         assert size == 64;
1084         super.smaddl(dst, src1, src2, src3);
1085     }
1086 
1087     /**
1088      * Signed multiply-sub long. xDst = xSrc3 - (wSrc1 * wSrc2)
1089      *
1090      * @param size destination register size. Has to be 64.
1091      * @param dst 64-bit general purpose register. May not be null or the stackpointer.
1092      * @param src1 32-bit general purpose register. May not be null or the stackpointer.
1093      * @param src2 32-bit general purpose register. May not be null or the stackpointer.
1094      * @param src3 64-bit general purpose register. May not be null or the stackpointer.
1095      */
1096     public void smsubl(int size, Register dst, Register src1, Register src2, Register src3) {
1097         assert (!dst.equals(sp) &amp;&amp; !src1.equals(sp) &amp;&amp; !src2.equals(sp) &amp;&amp; !src3.equals(sp));
1098         assert size == 64;
1099         super.smsubl(dst, src1, src2, src3);
1100     }
1101 
1102     /**
1103      * dst = src1 % src2. Signed.
1104      *
1105      * @param size register size. Has to be 32 or 64.
1106      * @param dst general purpose register. May not be null or the stackpointer.
1107      * @param n numerator. General purpose register. May not be null or the stackpointer.
1108      * @param d denominator. General purpose register. Divisor May not be null or the stackpointer.
1109      */
1110     public void rem(int size, Register dst, Register n, Register d) {
1111         assert (!dst.equals(sp) &amp;&amp; !n.equals(sp) &amp;&amp; !d.equals(sp));
1112         // There is no irem or similar instruction. Instead we use the relation:
1113         // n % d = n - Floor(n / d) * d if nd &gt;= 0
1114         // n % d = n - Ceil(n / d) * d else
1115         // Which is equivalent to n - TruncatingDivision(n, d) * d
1116         super.sdiv(size, dst, n, d);
1117         super.msub(size, dst, dst, d, n);
1118     }
1119 
1120     /**
1121      * dst = src1 % src2. Unsigned.
1122      *
1123      * @param size register size. Has to be 32 or 64.
1124      * @param dst general purpose register. May not be null or the stackpointer.
1125      * @param n numerator. General purpose register. May not be null or the stackpointer.
1126      * @param d denominator. General purpose register. Divisor May not be null or the stackpointer.
1127      */
1128     public void urem(int size, Register dst, Register n, Register d) {
1129         // There is no irem or similar instruction. Instead we use the relation:
1130         // n % d = n - Floor(n / d) * d
1131         // Which is equivalent to n - TruncatingDivision(n, d) * d
1132         super.udiv(size, dst, n, d);
1133         super.msub(size, dst, dst, d, n);
1134     }
1135 
1136     /**
1137      * Add/subtract instruction encoding supports 12-bit immediate values.
1138      *
1139      * @param imm immediate value to be tested.
1140      * @return true if immediate can be used directly for arithmetic instructions (add/sub), false
1141      *         otherwise.
1142      */
1143     public static boolean isArithmeticImmediate(long imm) {
1144         // If we have a negative immediate we just use the opposite operator. I.e.: x - (-5) == x +
1145         // 5.
1146         return NumUtil.isInt(Math.abs(imm)) &amp;&amp; isAimm((int) Math.abs(imm));
1147     }
1148 
1149     /**
1150      * Compare instructions are add/subtract instructions and so support 12-bit immediate values.
1151      *
1152      * @param imm immediate value to be tested.
1153      * @return true if immediate can be used directly with comparison instructions, false otherwise.
1154      */
1155     public static boolean isComparisonImmediate(long imm) {
1156         return isArithmeticImmediate(imm);
1157     }
1158 
1159     /**
1160      * Move wide immediate instruction encoding supports 16-bit immediate values which can be
1161      * optionally-shifted by multiples of 16 (i.e. 0, 16, 32, 48).
1162      *
1163      * @return true if immediate can be moved directly into a register, false otherwise.
1164      */
1165     public static boolean isMovableImmediate(long imm) {
1166         // // Positions of first, respectively last set bit.
1167         // int start = Long.numberOfTrailingZeros(imm);
1168         // int end = 64 - Long.numberOfLeadingZeros(imm);
1169         // int length = end - start;
1170         // if (length &gt; 16) {
1171         // return false;
1172         // }
1173         // // We can shift the necessary part of the immediate (i.e. everything between the first
1174         // and
1175         // // last set bit) by as much as 16 - length around to arrive at a valid shift amount
1176         // int tolerance = 16 - length;
1177         // int prevMultiple = NumUtil.roundDown(start, 16);
1178         // int nextMultiple = NumUtil.roundUp(start, 16);
1179         // return start - prevMultiple &lt;= tolerance || nextMultiple - start &lt;= tolerance;
1180         /*
1181          * This is a bit optimistic because the constant could also be for an arithmetic instruction
1182          * which only supports 12-bits. That case needs to be handled in the backend.
1183          */
1184         return NumUtil.isInt(Math.abs(imm)) &amp;&amp; NumUtil.isUnsignedNbit(16, (int) Math.abs(imm));
1185     }
1186 
1187     /**
1188      * dst = src &lt;&lt; (shiftAmt &amp; (size - 1)).
1189      *
1190      * @param size register size. Has to be 32 or 64.
1191      * @param dst general purpose register. May not be null, stackpointer or zero-register.
1192      * @param src general purpose register. May not be null, stackpointer or zero-register.
1193      * @param shiftAmt amount by which src is shifted.
1194      */
1195     public void shl(int size, Register dst, Register src, long shiftAmt) {
1196         int shift = clampShiftAmt(size, shiftAmt);
1197         super.ubfm(size, dst, src, (size - shift) &amp; (size - 1), size - 1 - shift);
1198     }
1199 
1200     /**
1201      * dst = src1 &lt;&lt; (src2 &amp; (size - 1)).
1202      *
1203      * @param size register size. Has to be 32 or 64.
1204      * @param dst general purpose register. May not be null or stackpointer.
1205      * @param src general purpose register. May not be null or stackpointer.
1206      * @param shift general purpose register. May not be null or stackpointer.
1207      */
1208     public void shl(int size, Register dst, Register src, Register shift) {
1209         super.lsl(size, dst, src, shift);
1210     }
1211 
1212     /**
1213      * dst = src &gt;&gt;&gt; (shiftAmt &amp; (size - 1)).
1214      *
1215      * @param size register size. Has to be 32 or 64.
1216      * @param dst general purpose register. May not be null, stackpointer or zero-register.
1217      * @param src general purpose register. May not be null, stackpointer or zero-register.
1218      * @param shiftAmt amount by which src is shifted.
1219      */
1220     public void lshr(int size, Register dst, Register src, long shiftAmt) {
1221         int shift = clampShiftAmt(size, shiftAmt);
1222         super.ubfm(size, dst, src, shift, size - 1);
1223     }
1224 
1225     /**
1226      * dst = src1 &gt;&gt;&gt; (src2 &amp; (size - 1)).
1227      *
1228      * @param size register size. Has to be 32 or 64.
1229      * @param dst general purpose register. May not be null or stackpointer.
1230      * @param src general purpose register. May not be null or stackpointer.
1231      * @param shift general purpose register. May not be null or stackpointer.
1232      */
1233     public void lshr(int size, Register dst, Register src, Register shift) {
1234         super.lsr(size, dst, src, shift);
1235     }
1236 
1237     /**
1238      * dst = src &gt;&gt; (shiftAmt &amp; log2(size)).
1239      *
1240      * @param size register size. Has to be 32 or 64.
1241      * @param dst general purpose register. May not be null, stackpointer or zero-register.
1242      * @param src general purpose register. May not be null, stackpointer or zero-register.
1243      * @param shiftAmt amount by which src is shifted.
1244      */
1245     public void ashr(int size, Register dst, Register src, long shiftAmt) {
1246         int shift = clampShiftAmt(size, shiftAmt);
1247         super.sbfm(size, dst, src, shift, size - 1);
1248     }
1249 
1250     /**
1251      * dst = src1 &gt;&gt; (src2 &amp; log2(size)).
1252      *
1253      * @param size register size. Has to be 32 or 64.
1254      * @param dst general purpose register. May not be null or stackpointer.
1255      * @param src general purpose register. May not be null or stackpointer.
1256      * @param shift general purpose register. May not be null or stackpointer.
1257      */
1258     public void ashr(int size, Register dst, Register src, Register shift) {
1259         super.asr(size, dst, src, shift);
1260     }
1261 
1262     /**
1263      * Clamps shiftAmt into range 0 &lt;= shiftamt &lt; size according to JLS.
1264      *
1265      * @param size size of operation.
1266      * @param shiftAmt arbitrary shift amount.
1267      * @return value between 0 and size - 1 inclusive that is equivalent to shiftAmt according to
1268      *         JLS.
1269      */
1270     private static int clampShiftAmt(int size, long shiftAmt) {
1271         return (int) (shiftAmt &amp; (size - 1));
1272     }
1273 
1274     /**
1275      * dst = src1 &amp; src2.
1276      *
1277      * @param size register size. Has to be 32 or 64.
1278      * @param dst general purpose register. May not be null or stackpointer.
1279      * @param src1 general purpose register. May not be null or stackpointer.
1280      * @param src2 general purpose register. May not be null or stackpointer.
1281      */
1282     public void and(int size, Register dst, Register src1, Register src2) {
1283         super.and(size, dst, src1, src2, ShiftType.LSL, 0);
1284     }
1285 
1286     /**
1287      * dst = src1 ^ src2.
1288      *
1289      * @param size register size. Has to be 32 or 64.
1290      * @param dst general purpose register. May not be null or stackpointer.
1291      * @param src1 general purpose register. May not be null or stackpointer.
1292      * @param src2 general purpose register. May not be null or stackpointer.
1293      */
1294     public void eor(int size, Register dst, Register src1, Register src2) {
1295         super.eor(size, dst, src1, src2, ShiftType.LSL, 0);
1296     }
1297 
1298     /**
1299      * dst = src1 | src2.
1300      *
1301      * @param size register size. Has to be 32 or 64.
1302      * @param dst general purpose register. May not be null or stackpointer.
1303      * @param src1 general purpose register. May not be null or stackpointer.
1304      * @param src2 general purpose register. May not be null or stackpointer.
1305      */
1306     public void or(int size, Register dst, Register src1, Register src2) {
1307         super.orr(size, dst, src1, src2, ShiftType.LSL, 0);
1308     }
1309 
1310     /**
1311      * dst = src | bimm.
1312      *
1313      * @param size register size. Has to be 32 or 64.
1314      * @param dst general purpose register. May not be null or zero-register.
1315      * @param src general purpose register. May not be null or stack-pointer.
1316      * @param bimm logical immediate. See {@link AArch64Assembler.LogicalImmediateTable} for exact
1317      *            definition.
1318      */
1319     public void or(int size, Register dst, Register src, long bimm) {
1320         super.orr(size, dst, src, bimm);
1321     }
1322 
1323     /**
1324      * dst = ~src.
1325      *
1326      * @param size register size. Has to be 32 or 64.
1327      * @param dst general purpose register. May not be null or stackpointer.
1328      * @param src general purpose register. May not be null or stackpointer.
1329      */
1330     public void not(int size, Register dst, Register src) {
1331         super.orn(size, dst, zr, src, ShiftType.LSL, 0);
1332     }
1333 
1334     /**
1335      * dst = src1 &amp; shiftType(src2, imm).
1336      *
1337      * @param size register size. Has to be 32 or 64.
1338      * @param dst general purpose register. May not be null or stackpointer.
1339      * @param src1 general purpose register. May not be null or stackpointer.
1340      * @param src2 general purpose register. May not be null or stackpointer.
1341      * @param shiftType all types allowed, may not be null.
1342      * @param shiftAmt must be in range 0 to size - 1.
1343      */
1344     @Override
1345     public void and(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1346         super.and(size, dst, src1, src2, shiftType, shiftAmt);
1347     }
1348 
1349     /**
1350      * dst = src1 ^ shiftType(src2, imm).
1351      *
1352      * @param size register size. Has to be 32 or 64.
1353      * @param dst general purpose register. May not be null or stackpointer.
1354      * @param src1 general purpose register. May not be null or stackpointer.
1355      * @param src2 general purpose register. May not be null or stackpointer.
1356      * @param shiftType all types allowed, may not be null.
1357      * @param shiftAmt must be in range 0 to size - 1.
1358      */
1359     @Override
1360     public void eor(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1361         super.eor(size, dst, src1, src2, shiftType, shiftAmt);
1362     }
1363 
1364     /**
1365      * dst = src1 | shiftType(src2, imm).
1366      *
1367      * @param size register size. Has to be 32 or 64.
1368      * @param dst general purpose register. May not be null or stackpointer.
1369      * @param src1 general purpose register. May not be null or stackpointer.
1370      * @param src2 general purpose register. May not be null or stackpointer.
1371      * @param shiftType all types allowed, may not be null.
1372      * @param shiftAmt must be in range 0 to size - 1.
1373      */
1374     public void or(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1375         super.orr(size, dst, src1, src2, shiftType, shiftAmt);
1376     }
1377 
1378     /**
1379      * dst = src1 &amp; ~(shiftType(src2, imm)).
1380      *
1381      * @param size register size. Has to be 32 or 64.
1382      * @param dst general purpose register. May not be null or stackpointer.
1383      * @param src1 general purpose register. May not be null or stackpointer.
1384      * @param src2 general purpose register. May not be null or stackpointer.
1385      * @param shiftType all types allowed, may not be null.
1386      * @param shiftAmt must be in range 0 to size - 1.
1387      */
1388     @Override
1389     public void bic(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1390         super.bic(size, dst, src1, src2, shiftType, shiftAmt);
1391     }
1392 
1393     /**
1394      * dst = src1 ^ ~(shiftType(src2, imm)).
1395      *
1396      * @param size register size. Has to be 32 or 64.
1397      * @param dst general purpose register. May not be null or stackpointer.
1398      * @param src1 general purpose register. May not be null or stackpointer.
1399      * @param src2 general purpose register. May not be null or stackpointer.
1400      * @param shiftType all types allowed, may not be null.
1401      * @param shiftAmt must be in range 0 to size - 1.
1402      */
1403     @Override
1404     public void eon(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1405         super.eon(size, dst, src1, src2, shiftType, shiftAmt);
1406     }
1407 
1408     /**
1409      * dst = src1 | ~(shiftType(src2, imm)).
1410      *
1411      * @param size register size. Has to be 32 or 64.
1412      * @param dst general purpose register. May not be null or stackpointer.
1413      * @param src1 general purpose register. May not be null or stackpointer.
1414      * @param src2 general purpose register. May not be null or stackpointer.
1415      * @param shiftType all types allowed, may not be null.
1416      * @param shiftAmt must be in range 0 to size - 1.
1417      */
1418     @Override
1419     public void orn(int size, Register dst, Register src1, Register src2, ShiftType shiftType, int shiftAmt) {
1420         super.orn(size, dst, src1, src2, shiftType, shiftAmt);
1421     }
1422 
1423     /**
1424      * Sign-extend value from src into dst.
1425      *
1426      * @param destSize destination register size. Must be 32 or 64.
1427      * @param srcSize source register size. Must be smaller than destSize.
1428      * @param dst general purpose register. May not be null, stackpointer or zero-register.
1429      * @param src general purpose register. May not be null, stackpointer or zero-register.
1430      */
1431     public void sxt(int destSize, int srcSize, Register dst, Register src) {
1432         assert (srcSize &lt; destSize &amp;&amp; srcSize &gt; 0);
1433         super.sbfm(destSize, dst, src, 0, srcSize - 1);
1434     }
1435 
1436     /**
1437      * dst = src if condition else -src.
1438      *
1439      * @param size register size. Must be 32 or 64.
1440      * @param dst general purpose register. May not be null or the stackpointer.
1441      * @param src general purpose register. May not be null or the stackpointer.
1442      * @param condition any condition except AV or NV. May not be null.
1443      */
1444     public void csneg(int size, Register dst, Register src, ConditionFlag condition) {
1445         super.csneg(size, dst, src, src, condition.negate());
1446     }
1447 
1448     /**
1449      * @return True if the immediate can be used directly for logical 64-bit instructions.
1450      */
1451     public static boolean isLogicalImmediate(long imm) {
1452         return LogicalImmediateTable.isRepresentable(true, imm) != LogicalImmediateTable.Representable.NO;
1453     }
1454 
1455     /**
1456      * @return True if the immediate can be used directly for logical 32-bit instructions.
1457      */
1458     public static boolean isLogicalImmediate(int imm) {
1459         return LogicalImmediateTable.isRepresentable(imm) == LogicalImmediateTable.Representable.YES;
1460     }
1461 
1462     /* Float instructions */
1463 
1464     /**
1465      * Moves integer to float, float to integer, or float to float. Does not support integer to
1466      * integer moves.
1467      *
1468      * @param size register size. Has to be 32 or 64.
1469      * @param dst Either floating-point or general-purpose register. If general-purpose register may
1470      *            not be stackpointer or zero register. Cannot be null in any case.
1471      * @param src Either floating-point or general-purpose register. If general-purpose register may
1472      *            not be stackpointer. Cannot be null in any case.
1473      */
1474     @Override
1475     public void fmov(int size, Register dst, Register src) {
1476         assert !(dst.getRegisterCategory().equals(CPU) &amp;&amp; src.getRegisterCategory().equals(CPU)) : &quot;src and dst cannot both be integer registers.&quot;;
1477         if (dst.getRegisterCategory().equals(CPU)) {
1478             super.fmovFpu2Cpu(size, dst, src);
1479         } else if (src.getRegisterCategory().equals(CPU)) {
1480             super.fmovCpu2Fpu(size, dst, src);
1481         } else {
1482             super.fmov(size, dst, src);
1483         }
1484     }
1485 
1486     /**
1487      *
1488      * @param size register size. Has to be 32 or 64.
1489      * @param dst floating point register. May not be null.
1490      * @param imm immediate that is loaded into dst. If size is 32 only float immediates can be
1491      *            loaded, i.e. (float) imm == imm must be true. In all cases
1492      *            {@code isFloatImmediate}, respectively {@code #isDoubleImmediate} must be true
1493      *            depending on size.
1494      */
1495     @Override
1496     public void fmov(int size, Register dst, double imm) {
1497         if (imm == 0.0) {
1498             assert Double.doubleToRawLongBits(imm) == 0L : &quot;-0.0 is no valid immediate.&quot;;
1499             super.fmovCpu2Fpu(size, dst, zr);
1500         } else {
1501             super.fmov(size, dst, imm);
1502         }
1503     }
1504 
1505     /**
1506      *
1507      * @return true if immediate can be loaded directly into floating-point register, false
1508      *         otherwise.
1509      */
1510     public static boolean isDoubleImmediate(double imm) {
1511         return Double.doubleToRawLongBits(imm) == 0L || AArch64Assembler.isDoubleImmediate(imm);
1512     }
1513 
1514     /**
1515      *
1516      * @return true if immediate can be loaded directly into floating-point register, false
1517      *         otherwise.
1518      */
1519     public static boolean isFloatImmediate(float imm) {
1520         return Float.floatToRawIntBits(imm) == 0 || AArch64Assembler.isFloatImmediate(imm);
1521     }
1522 
1523     /**
1524      * Conditional move. dst = src1 if condition else src2.
1525      *
1526      * @param size register size.
1527      * @param result floating point register. May not be null.
1528      * @param trueValue floating point register. May not be null.
1529      * @param falseValue floating point register. May not be null.
1530      * @param condition every condition allowed. May not be null.
1531      */
1532     public void fcmov(int size, Register result, Register trueValue, Register falseValue, ConditionFlag condition) {
1533         super.fcsel(size, result, trueValue, falseValue, condition);
1534     }
1535 
1536     /**
1537      * dst = src1 % src2.
1538      *
1539      * @param size register size. Has to be 32 or 64.
1540      * @param dst floating-point register. May not be null.
1541      * @param n numerator. Floating-point register. May not be null.
1542      * @param d denominator. Floating-point register. May not be null.
1543      */
1544     public void frem(int size, Register dst, Register n, Register d) {
1545         // There is no frem instruction, instead we compute the remainder using the relation:
1546         // rem = n - Truncating(n / d) * d
1547         super.fdiv(size, dst, n, d);
1548         super.frintz(size, dst, dst);
1549         super.fmsub(size, dst, dst, d, n);
1550     }
1551 
1552     /**
1553      * dst = src1 * src2 + src3.
1554      *
1555      * @param size register size.
1556      * @param dst floating point register. May not be null.
1557      * @param src1 floating point register. May not be null.
1558      * @param src2 floating point register. May not be null.
1559      * @param src3 floating point register. May not be null.
1560      */
1561     @Override
1562     public void fmadd(int size, Register dst, Register src1, Register src2, Register src3) {
1563         super.fmadd(size, dst, src1, src2, src3);
1564     }
1565 
1566     /* Branches */
1567 
1568     /**
1569      * Compares x and y and sets condition flags.
1570      *
1571      * @param size register size. Has to be 32 or 64.
1572      * @param x general purpose register. May not be null or stackpointer.
1573      * @param y general purpose register. May not be null or stackpointer.
1574      */
1575     public void cmp(int size, Register x, Register y) {
1576         assert size == 32 || size == 64;
1577         super.subs(size, zr, x, y, ShiftType.LSL, 0);
1578     }
1579 
1580     /**
1581      * Compares x to y and sets condition flags.
1582      *
1583      * @param size register size. Has to be 32 or 64.
1584      * @param x general purpose register. May not be null or stackpointer.
1585      * @param y comparison immediate, {@link #isComparisonImmediate(long)} has to be true for it.
1586      */
1587     public void cmp(int size, Register x, int y) {
1588         assert size == 32 || size == 64;
1589         if (y &lt; 0) {
1590             super.adds(size, zr, x, -y);
1591         } else {
1592             super.subs(size, zr, x, y);
1593         }
1594     }
1595 
1596     /**
1597      * Sets condition flags according to result of x &amp; y.
1598      *
1599      * @param size register size. Has to be 32 or 64.
1600      * @param dst general purpose register. May not be null or stack-pointer.
1601      * @param x general purpose register. May not be null or stackpointer.
1602      * @param y general purpose register. May not be null or stackpointer.
1603      */
1604     public void ands(int size, Register dst, Register x, Register y) {
1605         super.ands(size, dst, x, y, ShiftType.LSL, 0);
1606     }
1607 
1608     /**
1609      * Sets overflow flag according to result of x * y.
1610      *
1611      * @param size register size. Has to be 32 or 64.
1612      * @param dst general purpose register. May not be null or stack-pointer.
1613      * @param x general purpose register. May not be null or stackpointer.
1614      * @param y general purpose register. May not be null or stackpointer.
1615      */
1616     public void mulvs(int size, Register dst, Register x, Register y) {
1617         try (ScratchRegister sc1 = getScratchRegister();
1618                         ScratchRegister sc2 = getScratchRegister()) {
1619             switch (size) {
1620                 case 64: {
1621                     // Be careful with registers: it&#39;s possible that x, y, and dst are the same
1622                     // register.
1623                     Register temp1 = sc1.getRegister();
1624                     Register temp2 = sc2.getRegister();
1625                     mul(64, temp1, x, y);     // Result bits 0..63
1626                     smulh(64, temp2, x, y);  // Result bits 64..127
1627                     // Top is pure sign ext
1628                     subs(64, zr, temp2, temp1, ShiftType.ASR, 63);
1629                     // Copy all 64 bits of the result into dst
1630                     mov(64, dst, temp1);
1631                     mov(temp1, 0x80000000);
1632                     // Develop 0 (EQ), or 0x80000000 (NE)
1633                     cmov(32, temp1, temp1, zr, ConditionFlag.NE);
1634                     cmp(32, temp1, 1);
1635                     // 0x80000000 - 1 =&gt; VS
1636                     break;
1637                 }
1638                 case 32: {
1639                     Register temp1 = sc1.getRegister();
1640                     smaddl(temp1, x, y, zr);
1641                     // Copy the low 32 bits of the result into dst
1642                     mov(32, dst, temp1);
1643                     subs(64, zr, temp1, temp1, ExtendType.SXTW, 0);
1644                     // NE =&gt; overflow
1645                     mov(temp1, 0x80000000);
1646                     // Develop 0 (EQ), or 0x80000000 (NE)
1647                     cmov(32, temp1, temp1, zr, ConditionFlag.NE);
1648                     cmp(32, temp1, 1);
1649                     // 0x80000000 - 1 =&gt; VS
1650                     break;
1651                 }
1652             }
1653         }
1654     }
1655 
1656     /**
1657      * When patching up Labels we have to know what kind of code to generate.
1658      */
1659     public enum PatchLabelKind {
1660         BRANCH_CONDITIONALLY(0x0),
1661         BRANCH_UNCONDITIONALLY(0x1),
1662         BRANCH_NONZERO(0x2),
1663         BRANCH_ZERO(0x3),
1664         BRANCH_BIT_NONZERO(0x4),
1665         BRANCH_BIT_ZERO(0x5),
1666         JUMP_ADDRESS(0x6),
1667         ADR(0x7);
1668 
1669         /**
1670          * Offset by which additional information for branch conditionally, branch zero and branch
1671          * non zero has to be shifted.
1672          */
1673         public static final int INFORMATION_OFFSET = 5;
1674 
1675         public final int encoding;
1676 
1677         PatchLabelKind(int encoding) {
1678             this.encoding = encoding;
1679         }
1680 
1681         /**
1682          * @return PatchLabelKind with given encoding.
1683          */
1684         private static PatchLabelKind fromEncoding(int encoding) {
1685             return values()[encoding &amp; NumUtil.getNbitNumberInt(INFORMATION_OFFSET)];
1686         }
1687 
1688     }
1689 
1690     public void adr(Register dst, Label label) {
1691         // TODO Handle case where offset is too large for a single jump instruction
1692         if (label.isBound()) {
1693             int offset = label.position() - position();
1694             super.adr(dst, offset);
1695         } else {
1696             label.addPatchAt(position(), this);
1697             // Encode condition flag so that we know how to patch the instruction later
1698             emitInt(PatchLabelKind.ADR.encoding | dst.encoding &lt;&lt; PatchLabelKind.INFORMATION_OFFSET);
1699         }
1700     }
1701 
1702     /**
1703      * Compare register and branch if non-zero.
1704      *
1705      * @param size Instruction size in bits. Should be either 32 or 64.
1706      * @param cmp general purpose register. May not be null, zero-register or stackpointer.
1707      * @param label Can only handle 21-bit word-aligned offsets for now. May be unbound. Non null.
1708      */
1709     public void cbnz(int size, Register cmp, Label label) {
1710         // TODO Handle case where offset is too large for a single jump instruction
1711         if (label.isBound()) {
1712             int offset = label.position() - position();
1713             super.cbnz(size, cmp, offset);
1714         } else {
1715             label.addPatchAt(position(), this);
1716             int regEncoding = cmp.encoding &lt;&lt; (PatchLabelKind.INFORMATION_OFFSET + 1);
1717             int sizeEncoding = (size == 64 ? 1 : 0) &lt;&lt; PatchLabelKind.INFORMATION_OFFSET;
1718             // Encode condition flag so that we know how to patch the instruction later
1719             emitInt(PatchLabelKind.BRANCH_NONZERO.encoding | regEncoding | sizeEncoding);
1720         }
1721     }
1722 
1723     /**
1724      * Compare register and branch if zero.
1725      *
1726      * @param size Instruction size in bits. Should be either 32 or 64.
1727      * @param cmp general purpose register. May not be null, zero-register or stackpointer.
1728      * @param label Can only handle 21-bit word-aligned offsets for now. May be unbound. Non null.
1729      */
1730     public void cbz(int size, Register cmp, Label label) {
1731         // TODO Handle case where offset is too large for a single jump instruction
1732         if (label.isBound()) {
1733             int offset = label.position() - position();
1734             super.cbz(size, cmp, offset);
1735         } else {
1736             label.addPatchAt(position(), this);
1737             int regEncoding = cmp.encoding &lt;&lt; (PatchLabelKind.INFORMATION_OFFSET + 1);
1738             int sizeEncoding = (size == 64 ? 1 : 0) &lt;&lt; PatchLabelKind.INFORMATION_OFFSET;
1739             // Encode condition flag so that we know how to patch the instruction later
1740             emitInt(PatchLabelKind.BRANCH_ZERO.encoding | regEncoding | sizeEncoding);
1741         }
1742     }
1743 
1744     /**
1745      * Test a single bit and branch if the bit is nonzero.
1746      *
1747      * @param cmp general purpose register. May not be null, zero-register or stackpointer.
1748      * @param uimm6 Unsigned 6-bit bit index.
1749      * @param label Can only handle 16-bit word-aligned offsets for now. May be unbound. Non null.
1750      */
1751     public void tbnz(Register cmp, int uimm6, Label label) {
1752         assert NumUtil.isUnsignedNbit(6, uimm6);
1753         if (label.isBound()) {
1754             int offset = label.position() - position();
1755             super.tbnz(cmp, uimm6, offset);
1756         } else {
1757             label.addPatchAt(position(), this);
1758             int indexEncoding = uimm6 &lt;&lt; PatchLabelKind.INFORMATION_OFFSET;
1759             int regEncoding = cmp.encoding &lt;&lt; (PatchLabelKind.INFORMATION_OFFSET + 6);
1760             emitInt(PatchLabelKind.BRANCH_BIT_NONZERO.encoding | indexEncoding | regEncoding);
1761         }
1762     }
1763 
1764     /**
1765      * Test a single bit and branch if the bit is zero.
1766      *
1767      * @param cmp general purpose register. May not be null, zero-register or stackpointer.
1768      * @param uimm6 Unsigned 6-bit bit index.
1769      * @param label Can only handle 16-bit word-aligned offsets for now. May be unbound. Non null.
1770      */
1771     public void tbz(Register cmp, int uimm6, Label label) {
1772         assert NumUtil.isUnsignedNbit(6, uimm6);
1773         if (label.isBound()) {
1774             int offset = label.position() - position();
1775             super.tbz(cmp, uimm6, offset);
1776         } else {
1777             label.addPatchAt(position(), this);
1778             int indexEncoding = uimm6 &lt;&lt; PatchLabelKind.INFORMATION_OFFSET;
1779             int regEncoding = cmp.encoding &lt;&lt; (PatchLabelKind.INFORMATION_OFFSET + 6);
1780             emitInt(PatchLabelKind.BRANCH_BIT_ZERO.encoding | indexEncoding | regEncoding);
1781         }
1782     }
1783 
1784     /**
1785      * Branches to label if condition is true.
1786      *
1787      * @param condition any condition value allowed. Non null.
1788      * @param label Can only handle 21-bit word-aligned offsets for now. May be unbound. Non null.
1789      */
1790     public void branchConditionally(ConditionFlag condition, Label label) {
1791         // TODO Handle case where offset is too large for a single jump instruction
1792         if (label.isBound()) {
1793             int offset = label.position() - position();
1794             super.b(condition, offset);
1795         } else {
1796             label.addPatchAt(position(), this);
1797             // Encode condition flag so that we know how to patch the instruction later
1798             emitInt(PatchLabelKind.BRANCH_CONDITIONALLY.encoding | condition.encoding &lt;&lt; PatchLabelKind.INFORMATION_OFFSET);
1799         }
1800     }
1801 
1802     /**
1803      * Branches if condition is true. Address of jump is patched up by HotSpot c++ code.
1804      *
1805      * @param condition any condition value allowed. Non null.
1806      */
1807     public void branchConditionally(ConditionFlag condition) {
1808         // Correct offset is fixed up by HotSpot later.
1809         super.b(condition, 0);
1810     }
1811 
1812     /**
1813      * Jumps to label.
1814      *
1815      * param label Can only handle signed 28-bit offsets. May be unbound. Non null.
1816      */
1817     @Override
1818     public void jmp(Label label) {
1819         // TODO Handle case where offset is too large for a single jump instruction
1820         if (label.isBound()) {
1821             int offset = label.position() - position();
1822             super.b(offset);
1823         } else {
1824             label.addPatchAt(position(), this);
1825             emitInt(PatchLabelKind.BRANCH_UNCONDITIONALLY.encoding);
1826         }
1827     }
1828 
1829     /**
1830      * Jump to address in dest.
1831      *
1832      * @param dest General purpose register. May not be null, zero-register or stackpointer.
1833      */
1834     public void jmp(Register dest) {
1835         super.br(dest);
1836     }
1837 
1838     /**
1839      * Immediate jump instruction fixed up by HotSpot c++ code.
1840      */
1841     public void jmp() {
1842         // Offset has to be fixed up by c++ code.
1843         super.b(0);
1844     }
1845 
1846     /**
1847      *
1848      * @return true if immediate offset can be used in a single branch instruction.
1849      */
1850     public static boolean isBranchImmediateOffset(long imm) {
1851         return NumUtil.isSignedNbit(28, imm);
1852     }
1853 
1854     /* system instructions */
1855 
1856     /**
1857      * Exception codes used when calling hlt instruction.
1858      */
1859     public enum AArch64ExceptionCode {
1860         NO_SWITCH_TARGET(0x0),
1861         BREAKPOINT(0x1);
1862 
1863         public final int encoding;
1864 
1865         AArch64ExceptionCode(int encoding) {
1866             this.encoding = encoding;
1867         }
1868     }
1869 
1870     /**
1871      * Halting mode software breakpoint: Enters halting mode debug state if enabled, else treated as
1872      * UNALLOCATED instruction.
1873      *
1874      * @param exceptionCode exception code specifying why halt was called. Non null.
1875      */
1876     public void hlt(AArch64ExceptionCode exceptionCode) {
1877         super.hlt(exceptionCode.encoding);
1878     }
1879 
1880     /**
1881      * Monitor mode software breakpoint: exception routed to a debug monitor executing in a higher
1882      * exception level.
1883      *
1884      * @param exceptionCode exception code specifying why break was called. Non null.
1885      */
1886     public void brk(AArch64ExceptionCode exceptionCode) {
1887         super.brk(exceptionCode.encoding);
1888     }
1889 
1890     public void pause() {
1891         super.hint(SystemHint.YIELD);
1892     }
1893 
1894     /**
1895      * Executes no-op instruction. No registers or flags are updated, except for PC.
1896      */
1897     public void nop() {
1898         super.hint(SystemHint.NOP);
1899     }
1900 
1901     /**
1902      * Consumption of Speculative Data Barrier. This is a memory barrier that controls speculative
1903      * execution and data value prediction.
1904      */
1905     public void csdb() {
1906         super.hint(SystemHint.CSDB);
1907     }
1908 
1909     /**
1910      * Same as {@link #nop()}.
1911      */
1912     @Override
1913     public void ensureUniquePC() {
1914         nop();
1915     }
1916 
1917     /**
1918      * Aligns PC.
1919      *
1920      * @param modulus Has to be positive multiple of 4.
1921      */
1922     @Override
1923     public void align(int modulus) {
1924         assert modulus &gt; 0 &amp;&amp; (modulus &amp; 0x3) == 0 : &quot;Modulus has to be a positive multiple of 4.&quot;;
1925         if (position() % modulus == 0) {
1926             return;
1927         }
1928         int offset = modulus - position() % modulus;
1929         for (int i = 0; i &lt; offset; i += 4) {
1930             nop();
1931         }
1932     }
1933 
1934     /**
1935      * Patches jump targets when label gets bound.
1936      */
1937     @Override
1938     protected void patchJumpTarget(int branch, int jumpTarget) {
1939         int instruction = getInt(branch);
1940         int branchOffset = jumpTarget - branch;
1941         PatchLabelKind type = PatchLabelKind.fromEncoding(instruction);
1942         switch (type) {
1943             case BRANCH_CONDITIONALLY:
1944                 ConditionFlag cf = ConditionFlag.fromEncoding(instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET);
1945                 super.b(cf, branchOffset, branch);
1946                 break;
1947             case BRANCH_UNCONDITIONALLY:
1948                 super.b(branchOffset, branch);
1949                 break;
1950             case JUMP_ADDRESS:
1951                 int offset = instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET;
1952                 emitInt(jumpTarget - offset, branch);
1953                 break;
1954             case BRANCH_NONZERO:
1955             case BRANCH_ZERO: {
1956                 int information = instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET;
1957                 int sizeEncoding = information &amp; 1;
1958                 int regEncoding = information &gt;&gt;&gt; 1;
1959                 Register reg = AArch64.cpuRegisters.get(regEncoding);
1960                 // 1 =&gt; 64; 0 =&gt; 32
1961                 int size = sizeEncoding * 32 + 32;
1962                 if (!NumUtil.isSignedNbit(21, branchOffset)) {
1963                     throw new BranchTargetOutOfBoundsException(true, &quot;Branch target %d out of bounds&quot;, branchOffset);
1964                 }
1965                 switch (type) {
1966                     case BRANCH_NONZERO:
1967                         super.cbnz(size, reg, branchOffset, branch);
1968                         break;
1969                     case BRANCH_ZERO:
1970                         super.cbz(size, reg, branchOffset, branch);
1971                         break;
1972                 }
1973                 break;
1974             }
1975             case BRANCH_BIT_NONZERO:
1976             case BRANCH_BIT_ZERO: {
1977                 int information = instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET;
1978                 int sizeEncoding = information &amp; NumUtil.getNbitNumberInt(6);
1979                 int regEncoding = information &gt;&gt;&gt; 6;
1980                 Register reg = AArch64.cpuRegisters.get(regEncoding);
1981                 if (!NumUtil.isSignedNbit(16, branchOffset)) {
1982                     throw new BranchTargetOutOfBoundsException(true, &quot;Branch target %d out of bounds&quot;, branchOffset);
1983                 }
1984                 switch (type) {
1985                     case BRANCH_BIT_NONZERO:
1986                         super.tbnz(reg, sizeEncoding, branchOffset, branch);
1987                         break;
1988                     case BRANCH_BIT_ZERO:
1989                         super.tbz(reg, sizeEncoding, branchOffset, branch);
1990                         break;
1991                 }
1992                 break;
1993             }
1994             case ADR: {
1995                 int information = instruction &gt;&gt;&gt; PatchLabelKind.INFORMATION_OFFSET;
1996                 int regEncoding = information;
1997                 Register reg = AArch64.cpuRegisters.get(regEncoding);
1998                 super.adr(reg, branchOffset, branch);
1999                 break;
2000             }
2001             default:
2002                 throw GraalError.shouldNotReachHere();
2003         }
2004     }
2005 
2006     /**
2007      * Generates an address of the form {@code base + displacement}.
2008      *
2009      * Does not change base register to fulfill this requirement. Will fail if displacement cannot
2010      * be represented directly as address.
2011      *
2012      * @param base general purpose register. May not be null or the zero register.
2013      * @param displacement arbitrary displacement added to base.
2014      * @return AArch64Address referencing memory at {@code base + displacement}.
2015      */
2016     @Override
2017     public AArch64Address makeAddress(Register base, int displacement) {
2018         return makeAddress(base, displacement, zr, /* signExtend */false, /* transferSize */0, //
2019                         zr, /* allowOverwrite */false);
2020     }
2021 
2022     @Override
2023     public AArch64Address getPlaceholder(int instructionStartPosition) {
2024         return AArch64Address.PLACEHOLDER;
2025     }
2026 
2027     public void addressOf(Register dst) {
2028         if (codePatchingAnnotationConsumer != null) {
2029             codePatchingAnnotationConsumer.accept(new AdrpAddMacroInstruction(position()));
2030         }
2031         super.adrp(dst);
2032         super.add(64, dst, dst, 0);
2033     }
2034 
2035     /**
2036      * Loads an address into Register d.
2037      *
2038      * @param d general purpose register. May not be null.
2039      * @param a AArch64Address the address of an operand.
2040      */
2041     public void lea(Register d, AArch64Address a) {
2042         a.lea(this, d);
2043     }
2044 
2045     /**
2046      * Count the set bits of src register.
2047      *
2048      * @param size src register size. Has to be 32 or 64.
2049      * @param dst general purpose register. Should not be null or zero-register.
2050      * @param src general purpose register. Should not be null.
2051      * @param vreg SIMD register. Should not be null.
2052      */
2053     public void popcnt(int size, Register dst, Register src, Register vreg) {
2054         assert 32 == size || 64 == size : &quot;Invalid data size&quot;;
2055         fmov(size, vreg, src);
2056         final int fixedSize = 64;
2057         cnt(fixedSize, vreg, vreg);
2058         addv(fixedSize, SIMDElementSize.Byte, vreg, vreg);
2059         umov(fixedSize, dst, 0, vreg);
2060     }
2061 
2062     public interface MacroInstruction {
2063         void patch(int codePos, int relative, byte[] code);
2064     }
2065 
2066     /**
2067      * Emits elf patchable adrp ldr sequence.
2068      */
2069     public void adrpLdr(int srcSize, Register result, AArch64Address a) {
2070         if (codePatchingAnnotationConsumer != null) {
2071             codePatchingAnnotationConsumer.accept(new AdrpLdrMacroInstruction(position()));
2072         }
2073         super.adrp(a.getBase());
2074         this.ldr(srcSize, result, a);
2075     }
2076 
2077     public static class AdrpLdrMacroInstruction extends CodeAnnotation implements MacroInstruction {
2078         public AdrpLdrMacroInstruction(int position) {
2079             super(position);
2080         }
2081 
2082         @Override
2083         public String toString() {
2084             return &quot;ADRP_LDR&quot;;
2085         }
2086 
2087         @Override
2088         public void patch(int codePos, int relative, byte[] code) {
2089             throw GraalError.unimplemented();
2090         }
2091     }
2092 
2093     public static class AdrpAddMacroInstruction extends CodeAnnotation implements MacroInstruction {
2094         public AdrpAddMacroInstruction(int position) {
2095             super(position);
2096         }
2097 
2098         @Override
2099         public String toString() {
2100             return &quot;ADRP_ADD&quot;;
2101         }
2102 
2103         @Override
2104         public void patch(int codePos, int relative, byte[] code) {
2105             throw GraalError.unimplemented();
2106         }
2107     }
2108 }
    </pre>
  </body>
</html>