<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New test/jdk/java/text/Normalizer/ICUBasicTest.java</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2019, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 /*
 24  * @test
 25  * @bug  4221795 8032446 8174270
 26  * @summary Confirm Normalizer&#39;s fundamental behavior. Imported from ICU4J 3.2&#39;s
 27  * src/com/ibm/icu/dev/test and modified.
 28  * @modules java.base/sun.text java.base/jdk.internal.icu.text
 29  * @library /java/text/testlib
 30  * @compile -XDignore.symbol.file ICUBasicTest.java
 31  * @run main/timeout=30 ICUBasicTest
 32  */
 33 
 34 /*
 35  *******************************************************************************
 36  * Copyright (C) 1996-2004, International Business Machines Corporation and    *
 37  * others. All Rights Reserved.                                                *
 38  *******************************************************************************
 39  */
 40 
 41 import sun.text.Normalizer;
 42 import jdk.internal.icu.text.NormalizerBase;
 43 
 44 import static java.text.Normalizer.Form.*;
 45 
 46 public class ICUBasicTest extends IntlTest {
 47 
 48     public static void main(String[] args) throws Exception {
 49         new ICUBasicTest().run(args);
 50     }
 51 
 52     /*
 53      * Normalization modes
 54      */
 55     private static final NormalizerBase.Mode NFCmode  = NormalizerBase.NFC;
 56     private static final NormalizerBase.Mode NFDmode  = NormalizerBase.NFD;
 57     private static final NormalizerBase.Mode NFKCmode = NormalizerBase.NFKC;
 58     private static final NormalizerBase.Mode NFKDmode = NormalizerBase.NFKD;
 59     private static final NormalizerBase.Mode NONEmode = NormalizerBase.NONE;
 60 
 61     /*
 62      * Normalization options
 63      */
 64 
 65     /* Normal Unicode versions */
 66     private static final int UNICODE_3_2_0  = Normalizer.UNICODE_3_2;
 67     private static final int UNICODE_LATEST = NormalizerBase.UNICODE_LATEST;
 68 
 69     /*
 70      * Special cases for UAX #15 bug
 71      * see Unicode Public Review Issue #29
 72      * at http://www.unicode.org/review/resolved-pri.html#pri29
 73      *
 74      * Note:
 75      *   PRI #29 is supported in Unicode 4.1.0. Therefore, expected results are
 76      *   different for earlier Unicode versions.
 77      */
 78     public void TestComposition() {
 79 
 80         final TestCompositionCase cases[] = new TestCompositionCase[] {
 81             new TestCompositionCase(NFC, UNICODE_3_2_0,
 82                 &quot;\u1100\u0300\u1161\u0327&quot;,
 83                 &quot;\u1100\u0300\u1161\u0327&quot;),
 84             new TestCompositionCase(NFC, UNICODE_LATEST,
 85                 &quot;\u1100\u0300\u1161\u0327&quot;,
 86                 &quot;\u1100\u0300\u1161\u0327&quot;),
 87 
 88             new TestCompositionCase(NFC, UNICODE_3_2_0,
 89                 &quot;\u1100\u0300\u1161\u0327\u11a8&quot;,
 90                 &quot;\u1100\u0300\u1161\u0327\u11a8&quot;),
 91             new TestCompositionCase(NFC, UNICODE_LATEST,
 92                 &quot;\u1100\u0300\u1161\u0327\u11a8&quot;,
 93                 &quot;\u1100\u0300\u1161\u0327\u11a8&quot;),
 94 
 95             new TestCompositionCase(NFC, UNICODE_3_2_0,
 96                 &quot;\uac00\u0300\u0327\u11a8&quot;,
 97                 &quot;\uac00\u0327\u0300\u11a8&quot;),
 98             new TestCompositionCase(NFC, UNICODE_LATEST,
 99                 &quot;\uac00\u0300\u0327\u11a8&quot;,
100                 &quot;\uac00\u0327\u0300\u11a8&quot;),
101 
102             new TestCompositionCase(NFC, UNICODE_3_2_0,
103                 &quot;\u0b47\u0300\u0b3e&quot;,
104                 &quot;\u0b47\u0300\u0b3e&quot;),
105             new TestCompositionCase(NFC, UNICODE_LATEST,
106                 &quot;\u0b47\u0300\u0b3e&quot;,
107                 &quot;\u0b47\u0300\u0b3e&quot;),
108         };
109 
110         String output;
111         int i, length;
112 
113         for (i=0; i&lt;cases.length; ++i) {
114             output = Normalizer.normalize(cases[i].input,
115                                           cases[i].form, cases[i].options);
116             if (!output.equals(cases[i].expect)) {
117                 errln(&quot;unexpected result for case &quot; + i + &quot;. Expected=&quot;
118                       + cases[i].expect + &quot;, Actual=&quot; + output);
119             } else if (verbose) {
120                 logln(&quot;expected result for case &quot; + i + &quot;. Expected=&quot;
121                       + cases[i].expect + &quot;, Actual=&quot; + output);
122             }
123         }
124     }
125 
126     private final static class TestCompositionCase {
127         public java.text.Normalizer.Form form;
128         public int options;
129         public String input, expect;
130 
131         TestCompositionCase(java.text.Normalizer.Form form,
132                             int options,
133                             String input,
134                             String expect) {
135             this.form    = form;
136             this.options = options;
137             this.input   = input;
138             this.expect  = expect;
139         }
140     }
141 
142     /*
143      * Added in order to detect a regression.
144      */
145     public void TestCombiningMarks() {
146         String src      = &quot;\u0f71\u0f72\u0f73\u0f74\u0f75&quot;;
147         String expected = &quot;\u0F71\u0F71\u0F71\u0F72\u0F72\u0F74\u0F74&quot;;
148         String result   = NormalizerBase.normalize(src, NFD);
149 
150         if (!expected.equals(result)) {
151             errln(&quot;Reordering of combining marks failed. Expected: &quot; +
152                   toHexString(expected) + &quot; Got: &quot;+ toHexString(result));
153         }
154     }
155 
156     /*
157      * Added in order to detect a regression.
158      */
159     public void TestBengali() throws Exception {
160         String input = &quot;\u09bc\u09be\u09cd\u09be&quot;;
161         String output=NormalizerBase.normalize(input, NFC);
162 
163         if (!input.equals(output)) {
164              errln(&quot;ERROR in NFC of string&quot;);
165         }
166         return;
167     }
168 
169 
170     /*
171      * Added in order to detect a regression.
172      */
173     /**
174      * Test for a problem found by Verisign.  Problem is that
175      * characters at the start of a string are not put in canonical
176      * order correctly by compose() if there is no starter.
177      */
178     public void TestVerisign() throws Exception {
179         String[] inputs = {
180             &quot;\u05b8\u05b9\u05b1\u0591\u05c3\u05b0\u05ac\u059f&quot;,
181             &quot;\u0592\u05b7\u05bc\u05a5\u05b0\u05c0\u05c4\u05ad&quot;
182         };
183         String[] outputs = {
184             &quot;\u05b1\u05b8\u05b9\u0591\u05c3\u05b0\u05ac\u059f&quot;,
185             &quot;\u05b0\u05b7\u05bc\u05a5\u0592\u05c0\u05ad\u05c4&quot;
186         };
187 
188         for (int i = 0; i &lt; inputs.length; ++i) {
189             String input = inputs[i];
190             String output = outputs[i];
191 
192             String result = NormalizerBase.normalize(input, NFD);
193             if (!result.equals(output)) {
194                 errln(&quot;FAIL input: &quot; + toHexString(input) + &quot;\n&quot; +
195                       &quot; decompose: &quot; + toHexString(result) + &quot;\n&quot; +
196                       &quot;  expected: &quot; + toHexString(output));
197             }
198 
199             result = NormalizerBase.normalize(input, NFC);
200             if (!result.equals(output)) {
201                 errln(&quot;FAIL input: &quot; + toHexString(input) + &quot;\n&quot; +
202                       &quot;   compose: &quot; + toHexString(result) + &quot;\n&quot; +
203                       &quot;  expected: &quot; + toHexString(output));
204             }
205         }
206     }
207 
208     /**
209      * Test for a problem that showed up just before ICU 1.6 release
210      * having to do with combining characters with an index of zero.
211      * Such characters do not participate in any canonical
212      * decompositions.  However, having an index of zero means that
213      * they all share one typeMask[] entry, that is, they all have to
214      * map to the same canonical class, which is not the case, in
215      * reality.
216      */
217     public void TestZeroIndex() throws Exception {
218         String[] DATA = {
219             // Expect col1 x COMPOSE_COMPAT =&gt; col2
220             // Expect col2 x DECOMP =&gt; col3
221             &quot;A\u0316\u0300&quot;, &quot;\u00C0\u0316&quot;, &quot;A\u0316\u0300&quot;,
222             &quot;A\u0300\u0316&quot;, &quot;\u00C0\u0316&quot;, &quot;A\u0316\u0300&quot;,
223             &quot;A\u0327\u0300&quot;, &quot;\u00C0\u0327&quot;, &quot;A\u0327\u0300&quot;,
224             &quot;c\u0321\u0327&quot;, &quot;c\u0321\u0327&quot;, &quot;c\u0321\u0327&quot;,
225             &quot;c\u0327\u0321&quot;, &quot;\u00E7\u0321&quot;, &quot;c\u0327\u0321&quot;,
226         };
227 
228         for (int i=0; i&lt;DATA.length; i+=3) {
229             String a = DATA[i];
230             String b = NormalizerBase.normalize(a, NFKC);
231             String exp = DATA[i+1];
232 
233             if (b.equals(exp)) {
234                 logln(&quot;Ok: &quot; + toHexString(a) + &quot; x COMPOSE_COMPAT =&gt; &quot; +
235                       toHexString(b));
236             } else {
237                 errln(&quot;FAIL: &quot; + toHexString(a) + &quot; x COMPOSE_COMPAT =&gt; &quot; +
238                       toHexString(b) + &quot;, expect &quot; + toHexString(exp));
239             }
240 
241             a = NormalizerBase.normalize(b, NFD);
242             exp = DATA[i+2];
243             if (a.equals(exp)) {
244                 logln(&quot;Ok: &quot; + toHexString(b) + &quot; x DECOMP =&gt; &quot; +
245                       toHexString(a));
246             } else {
247                 errln(&quot;FAIL: &quot; + toHexString(b) + &quot; x DECOMP =&gt; &quot; +
248                       toHexString(a) + &quot;, expect &quot; + toHexString(exp));
249             }
250         }
251     }
252 
253     /**
254      * Make sure characters in the CompositionExclusion.txt list do not get
255      * composed to.
256      */
257     public void TestCompositionExclusion() throws Exception {
258         // This list is generated from CompositionExclusion.txt.
259         // Update whenever the normalizer tables are updated.  Note
260         // that we test all characters listed, even those that can be
261         // derived from the Unicode DB and are therefore commented
262         // out.
263 
264         /*
265          * kyuka&#39;s note:
266          *   Original data seemed to be based on Unicode 3.0.0(the initial
267          *   Composition Exclusions list) and seemed to have some mistakes.
268          *   Updated in order to correct mistakes and to support Unicode 4.0.0.
269          *   And, this table can be used also for Unicode 3.2.0.
270          */
271         String[][] EXCLUDED_UNICODE_3_2_0 = {
272             {&quot;\u0340&quot;},
273             {&quot;\u0341&quot;},
274             {&quot;\u0343&quot;},
275             {&quot;\u0344&quot;},
276             {&quot;\u0374&quot;},
277             {&quot;\u037E&quot;},
278             {&quot;\u0387&quot;},
279             {&quot;\u0958&quot;},
280             {&quot;\u0959&quot;, &quot;\u095F&quot;},
281             {&quot;\u09DC&quot;},
282             {&quot;\u09DD&quot;},
283             {&quot;\u09DF&quot;},
284             {&quot;\u0A33&quot;},
285             {&quot;\u0A36&quot;},
286             {&quot;\u0A59&quot;, &quot;\u0A5B&quot;},
287             {&quot;\u0A5E&quot;},
288             {&quot;\u0B5C&quot;},
289             {&quot;\u0B5D&quot;},
290             {&quot;\u0F43&quot;},
291             {&quot;\u0F4D&quot;},
292             {&quot;\u0F52&quot;},
293             {&quot;\u0F57&quot;},
294             {&quot;\u0F5C&quot;},
295             {&quot;\u0F69&quot;},
296             {&quot;\u0F73&quot;},
297             {&quot;\u0F75&quot;},
298             {&quot;\u0F76&quot;},
299             {&quot;\u0F78&quot;},
300             {&quot;\u0F81&quot;},
301             {&quot;\u0F93&quot;},
302             {&quot;\u0F9D&quot;},
303             {&quot;\u0FA2&quot;},
304             {&quot;\u0FA7&quot;},
305             {&quot;\u0FAC&quot;},
306             {&quot;\u0FB9&quot;},
307             {&quot;\u1F71&quot;},
308             {&quot;\u1F73&quot;},
309             {&quot;\u1F75&quot;},
310             {&quot;\u1F77&quot;},
311             {&quot;\u1F79&quot;},
312             {&quot;\u1F7B&quot;},
313             {&quot;\u1F7D&quot;},
314             {&quot;\u1FBB&quot;},
315             {&quot;\u1FBE&quot;},
316             {&quot;\u1FC9&quot;},
317             {&quot;\u1FCB&quot;},
318             {&quot;\u1FD3&quot;},
319             {&quot;\u1FDB&quot;},
320             {&quot;\u1FE3&quot;},
321             {&quot;\u1FEB&quot;},
322             {&quot;\u1FEE&quot;},
323             {&quot;\u1FEF&quot;},
324             {&quot;\u1FF9&quot;},
325             {&quot;\u1FFB&quot;},
326             {&quot;\u1FFD&quot;},
327             {&quot;\u2000&quot;},
328             {&quot;\u2001&quot;},
329             {&quot;\u2126&quot;},
330             {&quot;\u212A&quot;},
331             {&quot;\u212B&quot;},
332             {&quot;\u2329&quot;},
333             {&quot;\u232A&quot;},
334             {&quot;\u2ADC&quot;},
335             {&quot;\uF900&quot;, &quot;\uFA0D&quot;},
336             {&quot;\uFA10&quot;},
337             {&quot;\uFA12&quot;},
338             {&quot;\uFA15&quot;, &quot;\uFA1E&quot;},
339             {&quot;\uFA20&quot;},
340             {&quot;\uFA22&quot;},
341             {&quot;\uFA25&quot;},
342             {&quot;\uFA26&quot;},
343             {&quot;\uFA2A&quot;, &quot;\uFA2D&quot;},
344             {&quot;\uFA30&quot;, &quot;\uFA6A&quot;},
345             {&quot;\uFB1D&quot;},
346             {&quot;\uFB1F&quot;},
347             {&quot;\uFB2A&quot;, &quot;\uFB36&quot;},
348             {&quot;\uFB38&quot;, &quot;\uFB3C&quot;},
349             {&quot;\uFB3E&quot;},
350             {&quot;\uFB40&quot;},
351             {&quot;\uFB41&quot;},
352             {&quot;\uFB43&quot;},
353             {&quot;\uFB44&quot;},
354             {&quot;\uFB46&quot;, &quot;\uFB4E&quot;},
355             {&quot;\uD834\uDD5E&quot;, &quot;\uD834\uDD64&quot;},
356             {&quot;\uD834\uDDBB&quot;, &quot;\uD834\uDDC0&quot;},
357             {&quot;\uD87E\uDC00&quot;, &quot;\uD87E\uDE1D&quot;}
358         };
359 
360         String[][] EXCLUDED_LATEST = {
361 
362         };
363 
364         for (int i = 0; i &lt; EXCLUDED_UNICODE_3_2_0.length; ++i) {
365             if (EXCLUDED_UNICODE_3_2_0[i].length == 1) {
366                 checkCompositionExclusion_320(EXCLUDED_UNICODE_3_2_0[i][0]);
367             } else {
368                 int from, to;
369                 from = Character.codePointAt(EXCLUDED_UNICODE_3_2_0[i][0], 0);
370                 to   = Character.codePointAt(EXCLUDED_UNICODE_3_2_0[i][1], 0);
371 
372                 for (int j = from; j &lt;= to; j++) {
373                     checkCompositionExclusion_320(String.valueOf(Character.toChars(j)));
374                 }
375             }
376         }
377     }
378 
379     private void checkCompositionExclusion_320(String s) throws Exception {
380         String a = String.valueOf(s);
381         String b = NormalizerBase.normalize(a, NFKD);
382         String c = NormalizerBase.normalize(b, NFC);
383 
384         if (c.equals(a)) {
385             errln(&quot;FAIL: &quot; + toHexString(a) + &quot; x DECOMP_COMPAT =&gt; &quot; +
386                   toHexString(b) + &quot; x COMPOSE =&gt; &quot; +
387                   toHexString(c) + &quot; for the latest Unicode&quot;);
388         } else if (verbose) {
389             logln(&quot;Ok: &quot; + toHexString(a) + &quot; x DECOMP_COMPAT =&gt; &quot; +
390                   toHexString(b) + &quot; x COMPOSE =&gt; &quot; +
391                   toHexString(c) + &quot; for the latest Unicode&quot;);
392         }
393 
394         b = NormalizerBase.normalize(a, NFKD, Normalizer.UNICODE_3_2);
395         c = NormalizerBase.normalize(b, NFC, Normalizer.UNICODE_3_2);
396         if (c.equals(a)) {
397             errln(&quot;FAIL: &quot; + toHexString(a) + &quot; x DECOMP_COMPAT =&gt; &quot; +
398                   toHexString(b) + &quot; x COMPOSE =&gt; &quot; +
399                   toHexString(c) + &quot; for Unicode 3.2.0&quot;);
400         } else if (verbose) {
401             logln(&quot;Ok: &quot; + toHexString(a) + &quot; x DECOMP_COMPAT =&gt; &quot; +
402                   toHexString(b) + &quot; x COMPOSE =&gt; &quot; +
403                   toHexString(c) + &quot; for Unicode 3.2.0&quot;);
404         }
405     }
406 
407     public void TestTibetan() throws Exception {
408         String[][] decomp = {
409             { &quot;\u0f77&quot;, &quot;\u0f77&quot;, &quot;\u0fb2\u0f71\u0f80&quot; }
410         };
411         String[][] compose = {
412             { &quot;\u0fb2\u0f71\u0f80&quot;, &quot;\u0fb2\u0f71\u0f80&quot;, &quot;\u0fb2\u0f71\u0f80&quot; }
413         };
414 
415         staticTest(NFD, decomp, 1);
416         staticTest(NFKD,decomp, 2);
417         staticTest(NFC, compose, 1);
418         staticTest(NFKC,compose, 2);
419     }
420 
421     public void TestExplodingBase() throws Exception{
422         // \u017f - Latin small letter long s
423         // \u0307 - combining dot above
424         // \u1e61 - Latin small letter s with dot above
425         // \u1e9b - Latin small letter long s with dot above
426         String[][] canon = {
427             // Input                Decomposed              Composed
428             { &quot;Tschu\u017f&quot;,        &quot;Tschu\u017f&quot;,          &quot;Tschu\u017f&quot;    },
429             { &quot;Tschu\u1e9b&quot;,        &quot;Tschu\u017f\u0307&quot;,    &quot;Tschu\u1e9b&quot;    },
430         };
431         String[][] compat = {
432             // Input                Decomposed              Composed
433             { &quot;\u017f&quot;,             &quot;s&quot;,                    &quot;s&quot;           },
434             { &quot;\u1e9b&quot;,             &quot;s\u0307&quot;,              &quot;\u1e61&quot;      },
435         };
436 
437         staticTest(NFD, canon,  1);
438         staticTest(NFC, canon,  2);
439         staticTest(NFKD, compat, 1);
440         staticTest(NFKC, compat, 2);
441     }
442 
443     private String[][] canonTests = {
444         // Input                Decomposed              Composed
445 
446         { &quot;cat&quot;,                &quot;cat&quot;,                  &quot;cat&quot;               },
447         { &quot;\u00e0ardvark&quot;,      &quot;a\u0300ardvark&quot;,       &quot;\u00e0ardvark&quot;,    },
448 
449         // D-dot_above
450         { &quot;\u1e0a&quot;,             &quot;D\u0307&quot;,              &quot;\u1e0a&quot;            },
451 
452         // D dot_above
453         { &quot;D\u0307&quot;,            &quot;D\u0307&quot;,              &quot;\u1e0a&quot;            },
454 
455         // D-dot_below dot_above
456         { &quot;\u1e0c\u0307&quot;,       &quot;D\u0323\u0307&quot;,        &quot;\u1e0c\u0307&quot;      },
457 
458         // D-dot_above dot_below
459         { &quot;\u1e0a\u0323&quot;,       &quot;D\u0323\u0307&quot;,        &quot;\u1e0c\u0307&quot;      },
460 
461         // D dot_below dot_above
462         { &quot;D\u0307\u0323&quot;,      &quot;D\u0323\u0307&quot;,        &quot;\u1e0c\u0307&quot;      },
463 
464         // D dot_below cedilla dot_above
465         { &quot;\u1e10\u0307\u0323&quot;, &quot;D\u0327\u0323\u0307&quot;,  &quot;\u1e10\u0323\u0307&quot;},
466 
467         // D dot_above ogonek dot_below
468         { &quot;D\u0307\u0328\u0323&quot;,&quot;D\u0328\u0323\u0307&quot;,  &quot;\u1e0c\u0328\u0307&quot;},
469 
470         // E-macron-grave
471         { &quot;\u1E14&quot;,             &quot;E\u0304\u0300&quot;,        &quot;\u1E14&quot;            },
472 
473         // E-macron + grave
474         { &quot;\u0112\u0300&quot;,       &quot;E\u0304\u0300&quot;,        &quot;\u1E14&quot;            },
475 
476         // E-grave + macron
477         { &quot;\u00c8\u0304&quot;,       &quot;E\u0300\u0304&quot;,        &quot;\u00c8\u0304&quot;      },
478 
479         // angstrom_sign
480         { &quot;\u212b&quot;,             &quot;A\u030a&quot;,              &quot;\u00c5&quot;            },
481 
482         // A-ring
483         { &quot;\u00c5&quot;,             &quot;A\u030a&quot;,              &quot;\u00c5&quot;            },
484         { &quot;\u00c4ffin&quot;,         &quot;A\u0308ffin&quot;,          &quot;\u00c4ffin&quot;        },
485         { &quot;\u00c4\uFB03n&quot;,      &quot;A\u0308\uFB03n&quot;,       &quot;\u00c4\uFB03n&quot;     },
486 
487         //updated with 3.0
488         { &quot;\u00fdffin&quot;,         &quot;y\u0301ffin&quot;,          &quot;\u00fdffin&quot;        },
489         { &quot;\u00fd\uFB03n&quot;,      &quot;y\u0301\uFB03n&quot;,       &quot;\u00fd\uFB03n&quot;     },
490 
491         { &quot;Henry IV&quot;,           &quot;Henry IV&quot;,             &quot;Henry IV&quot;          },
492         { &quot;Henry \u2163&quot;,       &quot;Henry \u2163&quot;,         &quot;Henry \u2163&quot;      },
493 
494         // ga(Zenkaku-Katakana)
495         { &quot;\u30AC&quot;,             &quot;\u30AB\u3099&quot;,         &quot;\u30AC&quot;            },
496 
497         // ka(Zenkaku-Katakana) + ten(Zenkaku)
498         { &quot;\u30AB\u3099&quot;,       &quot;\u30AB\u3099&quot;,         &quot;\u30AC&quot;            },
499 
500         // ka(Hankaku-Katakana) + ten(Hankaku-Katakana)
501         { &quot;\uFF76\uFF9E&quot;,       &quot;\uFF76\uFF9E&quot;,         &quot;\uFF76\uFF9E&quot;      },
502 
503         // ka(Zenkaku-Katakana) + ten(Hankaku)
504         { &quot;\u30AB\uFF9E&quot;,       &quot;\u30AB\uFF9E&quot;,         &quot;\u30AB\uFF9E&quot;      },
505         // ka(Hankaku-Katakana) + ten(Zenkaku)
506         { &quot;\uFF76\u3099&quot;,       &quot;\uFF76\u3099&quot;,         &quot;\uFF76\u3099&quot;      },
507 
508         { &quot;A\u0300\u0316&quot;, &quot;A\u0316\u0300&quot;, &quot;\u00C0\u0316&quot; },
509 
510         { &quot;\ud834\udd5e\ud834\udd57\ud834\udd65\ud834\udd5e&quot;,
511           &quot;\ud834\udd57\ud834\udd65\ud834\udd57\ud834\udd65\ud834\udd57\ud834\udd65&quot;,
512           &quot;\ud834\udd57\ud834\udd65\ud834\udd57\ud834\udd65\ud834\udd57\ud834\udd65&quot; },
513     };
514 
515     private String[][] compatTests = {
516         // Input                Decomposed              Composed
517 
518         { &quot;cat&quot;,                 &quot;cat&quot;,                     &quot;cat&quot;           },
519 
520         // Alef-Lamed vs. Alef, Lamed
521         { &quot;\uFB4f&quot;,             &quot;\u05D0\u05DC&quot;,         &quot;\u05D0\u05DC&quot;,     },
522 
523         { &quot;\u00C4ffin&quot;,         &quot;A\u0308ffin&quot;,          &quot;\u00C4ffin&quot;        },
524 
525         // ffi ligature -&gt; f + f + i
526         { &quot;\u00C4\uFB03n&quot;,      &quot;A\u0308ffin&quot;,          &quot;\u00C4ffin&quot;        },
527 
528         //updated for 3.0
529         { &quot;\u00fdffin&quot;,         &quot;y\u0301ffin&quot;,          &quot;\u00fdffin&quot;        },
530 
531         // ffi ligature -&gt; f + f + i
532         { &quot;\u00fd\uFB03n&quot;,      &quot;y\u0301ffin&quot;,          &quot;\u00fdffin&quot;        },
533 
534         { &quot;Henry IV&quot;,           &quot;Henry IV&quot;,             &quot;Henry IV&quot;          },
535         { &quot;Henry \u2163&quot;,       &quot;Henry IV&quot;,             &quot;Henry IV&quot;          },
536 
537         // ga(Zenkaku-Katakana)
538         { &quot;\u30AC&quot;,             &quot;\u30AB\u3099&quot;,         &quot;\u30AC&quot;            },
539 
540         // ka(Zenkaku-Katakana) + ten(Zenkaku)
541         { &quot;\u30AB\u3099&quot;,       &quot;\u30AB\u3099&quot;,         &quot;\u30AC&quot;            },
542 
543         // ka(Hankaku-Katakana) + ten(Zenkaku)
544         { &quot;\uFF76\u3099&quot;,       &quot;\u30AB\u3099&quot;,         &quot;\u30AC&quot;            },
545 
546         /* These two are broken in Unicode 2.1.2 but fixed in 2.1.5 and later*/
547         // ka(Hankaku-Katakana) + ten(Hankaku)
548         { &quot;\uFF76\uFF9E&quot;,       &quot;\u30AB\u3099&quot;,         &quot;\u30AC&quot;            },
549 
550         // ka(Zenkaku-Katakana) + ten(Hankaku)
551         { &quot;\u30AB\uFF9E&quot;,       &quot;\u30AB\u3099&quot;,         &quot;\u30AC&quot;            },
552     };
553 
554     public void TestNFD() throws Exception{
555         staticTest(NFD, canonTests, 1);
556     }
557 
558     public void TestNFC() throws Exception{
559         staticTest(NFC, canonTests, 2);
560     }
561 
562     public void TestNFKD() throws Exception{
563         staticTest(NFKD, compatTests, 1);
564     }
565 
566     public void TestNFKC() throws Exception{
567         staticTest(NFKC, compatTests, 2);
568     }
569 
570     private void staticTest(java.text.Normalizer.Form form,
571                             String[][] tests,
572                             int outCol) throws Exception {
573         for (int i = 0; i &lt; tests.length; i++) {
574             String input = tests[i][0];
575             logln(&quot;Normalizing &#39;&quot; + input + &quot;&#39; (&quot; + toHexString(input) + &quot;)&quot; );
576 
577             String expect =tests[i][outCol];
578             String output = java.text.Normalizer.normalize(input, form);
579 
580             if (!output.equals(expect)) {
581                 errln(&quot;FAIL: case &quot; + i
582                     + &quot; expected &#39;&quot; + expect + &quot;&#39; (&quot; + toHexString(expect) + &quot;)&quot;
583                     + &quot; but got &#39;&quot; + output + &quot;&#39; (&quot; + toHexString(output) + &quot;)&quot;
584 );
585             }
586         }
587     }
588 
589     // With Canonical decomposition, Hangul syllables should get decomposed
590     // into Jamo, but Jamo characters should not be decomposed into
591     // conjoining Jamo
592     private String[][] hangulCanon = {
593         // Input                Decomposed              Composed
594         { &quot;\ud4db&quot;,             &quot;\u1111\u1171\u11b6&quot;,   &quot;\ud4db&quot;        },
595         { &quot;\u1111\u1171\u11b6&quot;, &quot;\u1111\u1171\u11b6&quot;,   &quot;\ud4db&quot;        },
596     };
597 
598     public void TestHangulCompose() throws Exception{
599         logln(&quot;Canonical composition...&quot;);
600         staticTest(NFC, hangulCanon,  2);
601      }
602 
603     public void TestHangulDecomp() throws Exception{
604         logln(&quot;Canonical decomposition...&quot;);
605         staticTest(NFD, hangulCanon, 1);
606     }
607 
608 }
    </pre>
  </body>
</html>