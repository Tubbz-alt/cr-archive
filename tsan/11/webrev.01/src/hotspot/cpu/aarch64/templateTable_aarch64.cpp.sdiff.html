<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/templateTable_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center>&lt; prev <a href="../../../../index.html" target="_top">index</a> <a href="../x86/templateTable_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/templateTable_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2003, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
</pre>
<hr />
<pre>
 736   // sign extend index for use by indexed load
 737   // __ movl2ptr(index, index);
 738   // check index
 739   Register length = rscratch1;
 740   __ ldrw(length, Address(array, arrayOopDesc::length_offset_in_bytes()));
 741   __ cmpw(index, length);
 742   if (index != r1) {
 743     // ??? convention: move aberrant index into r1 for exception message
 744     assert(r1 != array, &quot;different registers&quot;);
 745     __ mov(r1, index);
 746   }
 747   Label ok;
 748   __ br(Assembler::LO, ok);
 749     // ??? convention: move array into r3 for exception message
 750   __ mov(r3, array);
 751   __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);
 752   __ br(rscratch1);
 753   __ bind(ok);
 754 }
 755 






























































 756 void TemplateTable::iaload()
 757 {
 758   transition(itos, itos);
 759   __ mov(r1, r0);
 760   __ pop_ptr(r0);
 761   // r0: array
 762   // r1: index
 763   index_check(r0, r1); // leaves index in r1, kills rscratch1
 764   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_INT) &gt;&gt; 2);
 765   __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);
 766 }
 767 
 768 void TemplateTable::laload()
 769 {
 770   transition(itos, ltos);
 771   __ mov(r1, r0);
 772   __ pop_ptr(r0);
 773   // r0: array
 774   // r1: index
 775   index_check(r0, r1); // leaves index in r1, kills rscratch1
</pre>
<hr />
<pre>
2361                                               Register off,
2362                                               Register flags,
2363                                               bool is_static = false) {
2364   assert_different_registers(cache, index, flags, off);
2365 
2366   ByteSize cp_base_offset = ConstantPoolCache::base_offset();
2367   // Field offset
2368   __ ldr(off, Address(cache, in_bytes(cp_base_offset +
2369                                           ConstantPoolCacheEntry::f2_offset())));
2370   // Flags
2371   __ ldrw(flags, Address(cache, in_bytes(cp_base_offset +
2372                                            ConstantPoolCacheEntry::flags_offset())));
2373 
2374   // klass overwrite register
2375   if (is_static) {
2376     __ ldr(obj, Address(cache, in_bytes(cp_base_offset +
2377                                         ConstantPoolCacheEntry::f1_offset())));
2378     const int mirror_offset = in_bytes(Klass::java_mirror_offset());
2379     __ ldr(obj, Address(obj, mirror_offset));
2380     __ resolve_oop_handle(obj);



















2381   }
2382 }
2383 
2384 void TemplateTable::load_invoke_cp_cache_entry(int byte_no,
2385                                                Register method,
2386                                                Register itable_index,
2387                                                Register flags,
2388                                                bool is_invokevirtual,
2389                                                bool is_invokevfinal, /*unused*/
2390                                                bool is_invokedynamic) {
2391   // setup registers
2392   const Register cache = rscratch2;
2393   const Register index = r4;
2394   assert_different_registers(method, flags);
2395   assert_different_registers(method, cache, index);
2396   assert_different_registers(itable_index, flags);
2397   assert_different_registers(itable_index, cache, index);
2398   // determine constant pool cache field offsets
2399   assert(is_invokevirtual == (byte_no == f2_byte), &quot;is_invokevirtual flag redundant&quot;);
2400   const int method_offset = in_bytes(
</pre>
<hr />
<pre>
2496 
2497   const Address field(obj, off);
2498 
2499   Label Done, notByte, notBool, notInt, notShort, notChar,
2500               notLong, notFloat, notObj, notDouble;
2501 
2502   // x86 uses a shift and mask or wings it with a shift plus assert
2503   // the mask is not needed. aarch64 just uses bitfield extract
2504   __ ubfxw(flags, raw_flags, ConstantPoolCacheEntry::tos_state_shift,
2505            ConstantPoolCacheEntry::tos_state_bits);
2506 
2507   assert(btos == 0, &quot;change code, btos != 0&quot;);
2508   __ cbnz(flags, notByte);
2509 
2510   // Don&#39;t rewrite getstatic, only getfield
2511   if (is_static) rc = may_not_rewrite;
2512 
2513   // btos
2514   __ access_load_at(T_BYTE, IN_HEAP, r0, field, noreg, noreg);
2515   __ push(btos);

2516   // Rewrite bytecode to be faster
2517   if (rc == may_rewrite) {
2518     patch_bytecode(Bytecodes::_fast_bgetfield, bc, r1);
2519   }
2520   __ b(Done);
2521 
2522   __ bind(notByte);
2523   __ cmp(flags, (u1)ztos);
2524   __ br(Assembler::NE, notBool);
2525 
2526   // ztos (same code as btos)
2527   __ access_load_at(T_BOOLEAN, IN_HEAP, r0, field, noreg, noreg);
2528   __ push(ztos);

2529   // Rewrite bytecode to be faster
2530   if (rc == may_rewrite) {
2531     // use btos rewriting, no truncating to t/f bit is needed for getfield.
2532     patch_bytecode(Bytecodes::_fast_bgetfield, bc, r1);
2533   }
2534   __ b(Done);
2535 
2536   __ bind(notBool);
2537   __ cmp(flags, (u1)atos);
2538   __ br(Assembler::NE, notObj);
2539   // atos
2540   do_oop_load(_masm, field, r0, IN_HEAP);
2541   __ push(atos);





2542   if (rc == may_rewrite) {
2543     patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
2544   }
2545   __ b(Done);
2546 
2547   __ bind(notObj);
2548   __ cmp(flags, (u1)itos);
2549   __ br(Assembler::NE, notInt);
2550   // itos
2551   __ access_load_at(T_INT, IN_HEAP, r0, field, noreg, noreg);
2552   __ push(itos);

2553   // Rewrite bytecode to be faster
2554   if (rc == may_rewrite) {
2555     patch_bytecode(Bytecodes::_fast_igetfield, bc, r1);
2556   }
2557   __ b(Done);
2558 
2559   __ bind(notInt);
2560   __ cmp(flags, (u1)ctos);
2561   __ br(Assembler::NE, notChar);
2562   // ctos
2563   __ access_load_at(T_CHAR, IN_HEAP, r0, field, noreg, noreg);
2564   __ push(ctos);

2565   // Rewrite bytecode to be faster
2566   if (rc == may_rewrite) {
2567     patch_bytecode(Bytecodes::_fast_cgetfield, bc, r1);
2568   }
2569   __ b(Done);
2570 
2571   __ bind(notChar);
2572   __ cmp(flags, (u1)stos);
2573   __ br(Assembler::NE, notShort);
2574   // stos
2575   __ access_load_at(T_SHORT, IN_HEAP, r0, field, noreg, noreg);
2576   __ push(stos);

2577   // Rewrite bytecode to be faster
2578   if (rc == may_rewrite) {
2579     patch_bytecode(Bytecodes::_fast_sgetfield, bc, r1);
2580   }
2581   __ b(Done);
2582 
2583   __ bind(notShort);
2584   __ cmp(flags, (u1)ltos);
2585   __ br(Assembler::NE, notLong);
2586   // ltos
2587   __ access_load_at(T_LONG, IN_HEAP, r0, field, noreg, noreg);
2588   __ push(ltos);

2589   // Rewrite bytecode to be faster
2590   if (rc == may_rewrite) {
2591     patch_bytecode(Bytecodes::_fast_lgetfield, bc, r1);
2592   }
2593   __ b(Done);
2594 
2595   __ bind(notLong);
2596   __ cmp(flags, (u1)ftos);
2597   __ br(Assembler::NE, notFloat);
2598   // ftos
2599   __ access_load_at(T_FLOAT, IN_HEAP, noreg /* ftos */, field, noreg, noreg);
2600   __ push(ftos);

2601   // Rewrite bytecode to be faster
2602   if (rc == may_rewrite) {
2603     patch_bytecode(Bytecodes::_fast_fgetfield, bc, r1);
2604   }
2605   __ b(Done);
2606 
2607   __ bind(notFloat);
2608 #ifdef ASSERT
2609   __ cmp(flags, (u1)dtos);
2610   __ br(Assembler::NE, notDouble);
2611 #endif
2612   // dtos
2613   __ access_load_at(T_DOUBLE, IN_HEAP, noreg /* ftos */, field, noreg, noreg);
2614   __ push(dtos);

2615   // Rewrite bytecode to be faster
2616   if (rc == may_rewrite) {
2617     patch_bytecode(Bytecodes::_fast_dgetfield, bc, r1);
2618   }
2619 #ifdef ASSERT
2620   __ b(Done);
2621 
2622   __ bind(notDouble);
2623   __ stop(&quot;Bad state&quot;);
2624 #endif
2625 
2626   __ bind(Done);
2627 
2628   Label notVolatile;
2629   __ tbz(raw_flags, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
2630   __ membar(MacroAssembler::LoadLoad | MacroAssembler::LoadStore);
2631   __ bind(notVolatile);
2632 }
2633 
2634 
</pre>
<hr />
<pre>
2702     __ get_cache_and_index_at_bcp(cache, index, 1);
2703     __ bind(L1);
2704   }
2705 }
2706 
2707 void TemplateTable::putfield_or_static(int byte_no, bool is_static, RewriteControl rc) {
2708   transition(vtos, vtos);
2709 
2710   const Register cache = r2;
2711   const Register index = r3;
2712   const Register obj   = r2;
2713   const Register off   = r19;
2714   const Register flags = r0;
2715   const Register bc    = r4;
2716 
2717   resolve_cache_and_index(byte_no, cache, index, sizeof(u2));
2718   jvmti_post_field_mod(cache, index, is_static);
2719   load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);
2720 
2721   Label Done;

2722   __ mov(r5, flags);
2723 
2724   {
2725     Label notVolatile;
2726     __ tbz(r5, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
2727     __ membar(MacroAssembler::StoreStore | MacroAssembler::LoadStore);
2728     __ bind(notVolatile);
2729   }
2730 
2731   // field address
2732   const Address field(obj, off);
2733 
2734   Label notByte, notBool, notInt, notShort, notChar,
2735         notLong, notFloat, notObj, notDouble;
2736 
2737   // x86 uses a shift and mask or wings it with a shift plus assert
2738   // the mask is not needed. aarch64 just uses bitfield extract
2739   __ ubfxw(flags, flags, ConstantPoolCacheEntry::tos_state_shift,  ConstantPoolCacheEntry::tos_state_bits);
2740 
2741   assert(btos == 0, &quot;change code, btos != 0&quot;);
2742   __ cbnz(flags, notByte);
2743 
2744   // Don&#39;t rewrite putstatic, only putfield
2745   if (is_static) rc = may_not_rewrite;
2746 
2747   // btos
2748   {
2749     __ pop(btos);
2750     if (!is_static) pop_and_check_object(obj);

2751     __ access_store_at(T_BYTE, IN_HEAP, field, r0, noreg, noreg);
2752     if (rc == may_rewrite) {
2753       patch_bytecode(Bytecodes::_fast_bputfield, bc, r1, true, byte_no);
2754     }
2755     __ b(Done);
2756   }
2757 
2758   __ bind(notByte);
2759   __ cmp(flags, (u1)ztos);
2760   __ br(Assembler::NE, notBool);
2761 
2762   // ztos
2763   {
2764     __ pop(ztos);
2765     if (!is_static) pop_and_check_object(obj);

2766     __ access_store_at(T_BOOLEAN, IN_HEAP, field, r0, noreg, noreg);
2767     if (rc == may_rewrite) {
2768       patch_bytecode(Bytecodes::_fast_zputfield, bc, r1, true, byte_no);
2769     }
2770     __ b(Done);
2771   }
2772 
2773   __ bind(notBool);
2774   __ cmp(flags, (u1)atos);
2775   __ br(Assembler::NE, notObj);
2776 
2777   // atos
2778   {
2779     __ pop(atos);
2780     if (!is_static) pop_and_check_object(obj);





2781     // Store into the field
2782     do_oop_store(_masm, field, r0, IN_HEAP);
2783     if (rc == may_rewrite) {
2784       patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);
2785     }
2786     __ b(Done);
2787   }
2788 
2789   __ bind(notObj);
2790   __ cmp(flags, (u1)itos);
2791   __ br(Assembler::NE, notInt);
2792 
2793   // itos
2794   {
2795     __ pop(itos);
2796     if (!is_static) pop_and_check_object(obj);

2797     __ access_store_at(T_INT, IN_HEAP, field, r0, noreg, noreg);
2798     if (rc == may_rewrite) {
2799       patch_bytecode(Bytecodes::_fast_iputfield, bc, r1, true, byte_no);
2800     }
2801     __ b(Done);
2802   }
2803 
2804   __ bind(notInt);
2805   __ cmp(flags, (u1)ctos);
2806   __ br(Assembler::NE, notChar);
2807 
2808   // ctos
2809   {
2810     __ pop(ctos);
2811     if (!is_static) pop_and_check_object(obj);

2812     __ access_store_at(T_CHAR, IN_HEAP, field, r0, noreg, noreg);
2813     if (rc == may_rewrite) {
2814       patch_bytecode(Bytecodes::_fast_cputfield, bc, r1, true, byte_no);
2815     }
2816     __ b(Done);
2817   }
2818 
2819   __ bind(notChar);
2820   __ cmp(flags, (u1)stos);
2821   __ br(Assembler::NE, notShort);
2822 
2823   // stos
2824   {
2825     __ pop(stos);
2826     if (!is_static) pop_and_check_object(obj);

2827     __ access_store_at(T_SHORT, IN_HEAP, field, r0, noreg, noreg);
2828     if (rc == may_rewrite) {
2829       patch_bytecode(Bytecodes::_fast_sputfield, bc, r1, true, byte_no);
2830     }
2831     __ b(Done);
2832   }
2833 
2834   __ bind(notShort);
2835   __ cmp(flags, (u1)ltos);
2836   __ br(Assembler::NE, notLong);
2837 
2838   // ltos
2839   {
2840     __ pop(ltos);
2841     if (!is_static) pop_and_check_object(obj);

2842     __ access_store_at(T_LONG, IN_HEAP, field, r0, noreg, noreg);
2843     if (rc == may_rewrite) {
2844       patch_bytecode(Bytecodes::_fast_lputfield, bc, r1, true, byte_no);
2845     }
2846     __ b(Done);
2847   }
2848 
2849   __ bind(notLong);
2850   __ cmp(flags, (u1)ftos);
2851   __ br(Assembler::NE, notFloat);
2852 
2853   // ftos
2854   {
2855     __ pop(ftos);
2856     if (!is_static) pop_and_check_object(obj);

2857     __ access_store_at(T_FLOAT, IN_HEAP, field, noreg /* ftos */, noreg, noreg);
2858     if (rc == may_rewrite) {
2859       patch_bytecode(Bytecodes::_fast_fputfield, bc, r1, true, byte_no);
2860     }
2861     __ b(Done);
2862   }
2863 
2864   __ bind(notFloat);
2865 #ifdef ASSERT
2866   __ cmp(flags, (u1)dtos);
2867   __ br(Assembler::NE, notDouble);
2868 #endif
2869 
2870   // dtos
2871   {
2872     __ pop(dtos);
2873     if (!is_static) pop_and_check_object(obj);

2874     __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg /* dtos */, noreg, noreg);
2875     if (rc == may_rewrite) {
2876       patch_bytecode(Bytecodes::_fast_dputfield, bc, r1, true, byte_no);
2877     }
2878   }
2879 
2880 #ifdef ASSERT
2881   __ b(Done);
2882 
2883   __ bind(notDouble);
2884   __ stop(&quot;Bad state&quot;);
2885 #endif
2886 
2887   __ bind(Done);
2888 
2889   {
2890     Label notVolatile;
2891     __ tbz(r5, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
2892     __ membar(MacroAssembler::StoreLoad | MacroAssembler::StoreStore);
2893     __ bind(notVolatile);
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   3  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
</pre>
<hr />
<pre>
 736   // sign extend index for use by indexed load
 737   // __ movl2ptr(index, index);
 738   // check index
 739   Register length = rscratch1;
 740   __ ldrw(length, Address(array, arrayOopDesc::length_offset_in_bytes()));
 741   __ cmpw(index, length);
 742   if (index != r1) {
 743     // ??? convention: move aberrant index into r1 for exception message
 744     assert(r1 != array, &quot;different registers&quot;);
 745     __ mov(r1, index);
 746   }
 747   Label ok;
 748   __ br(Assembler::LO, ok);
 749     // ??? convention: move array into r3 for exception message
 750   __ mov(r3, array);
 751   __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);
 752   __ br(rscratch1);
 753   __ bind(ok);
 754 }
 755 
<span class="line-added"> 756 #if INCLUDE_TSAN</span>
<span class="line-added"> 757 </span>
<span class="line-added"> 758 void TemplateTable::tsan_observe_get_or_put(const Address &amp;field,</span>
<span class="line-added"> 759                                             Register flags,</span>
<span class="line-added"> 760                                             TsanMemoryReadWriteFunction tsan_function,</span>
<span class="line-added"> 761                                             TosState tos) {</span>
<span class="line-added"> 762   assert(ThreadSanitizer, &quot;ThreadSanitizer should be set&quot;);</span>
<span class="line-added"> 763 </span>
<span class="line-added"> 764   TsanMemoryReleaseAcquireFunction releaseAcquireFunction =</span>
<span class="line-added"> 765       tsan_release_acquire_method(tsan_function);</span>
<span class="line-added"> 766 </span>
<span class="line-added"> 767   Label done, notAcquireRelease;</span>
<span class="line-added"> 768 </span>
<span class="line-added"> 769   // We could save some instructions by only saving the registers we need.</span>
<span class="line-added"> 770   __ pusha();</span>
<span class="line-added"> 771   // pusha() doesn&#39;t save v0, which tsan_function clobbers and the</span>
<span class="line-added"> 772   // interpreter still needs.</span>
<span class="line-added"> 773   // This really only needs to be done for some of the float/double accesses,</span>
<span class="line-added"> 774   // but it&#39;s here because it&#39;s cleaner.</span>
<span class="line-added"> 775   __ push_d(v0);</span>
<span class="line-added"> 776   // For volatile reads/writes use an acquire/release.</span>
<span class="line-added"> 777   // If a reference is annotated to be ignored, assume it&#39;s safe to</span>
<span class="line-added"> 778   // access the object it&#39;s referring to and create a happens-before relation</span>
<span class="line-added"> 779   // between the accesses to this reference.</span>
<span class="line-added"> 780   if (tos == atos) {</span>
<span class="line-added"> 781     int32_t acquire_release_mask = 1 &lt;&lt; ConstantPoolCacheEntry::is_volatile_shift |</span>
<span class="line-added"> 782       1 &lt;&lt; ConstantPoolCacheEntry::is_tsan_ignore_shift;</span>
<span class="line-added"> 783     __ mov(rscratch1, acquire_release_mask);</span>
<span class="line-added"> 784     __ tst(flags, rscratch1);</span>
<span class="line-added"> 785     __ br(Assembler::EQ, notAcquireRelease);</span>
<span class="line-added"> 786   } else {</span>
<span class="line-added"> 787     __ tbz(flags, ConstantPoolCacheEntry::is_volatile_shift, notAcquireRelease);</span>
<span class="line-added"> 788   }</span>
<span class="line-added"> 789 </span>
<span class="line-added"> 790   __ lea(c_rarg0, field);</span>
<span class="line-added"> 791   __ call_VM_leaf(CAST_FROM_FN_PTR(address, releaseAcquireFunction), c_rarg0);</span>
<span class="line-added"> 792   if (ThreadSanitizerJavaMemory) {</span>
<span class="line-added"> 793     __ b(done);</span>
<span class="line-added"> 794     __ bind(notAcquireRelease);</span>
<span class="line-added"> 795 </span>
<span class="line-added"> 796     // Ignore reads/writes to final fields. They can&#39;t be racy.</span>
<span class="line-added"> 797     __ tbnz(flags, ConstantPoolCacheEntry::is_final_shift, done);</span>
<span class="line-added"> 798 </span>
<span class="line-added"> 799     // Don&#39;t report races on tsan ignored fields.</span>
<span class="line-added"> 800     __ tbnz(flags, ConstantPoolCacheEntry::is_tsan_ignore_shift, done);</span>
<span class="line-added"> 801 </span>
<span class="line-added"> 802     __ lea(c_rarg0, field);</span>
<span class="line-added"> 803     __ get_method(c_rarg1);</span>
<span class="line-added"> 804     __ call_VM_leaf(CAST_FROM_FN_PTR(address, tsan_function),</span>
<span class="line-added"> 805                     c_rarg0 /* addr */, c_rarg1 /* method */, rbcp /* bcp */);</span>
<span class="line-added"> 806 </span>
<span class="line-added"> 807     __ bind(done);</span>
<span class="line-added"> 808   } else {</span>
<span class="line-added"> 809     __ bind(notAcquireRelease);</span>
<span class="line-added"> 810   }</span>
<span class="line-added"> 811   __ pop_d(v0);</span>
<span class="line-added"> 812   __ popa();</span>
<span class="line-added"> 813 }</span>
<span class="line-added"> 814 </span>
<span class="line-added"> 815 </span>
<span class="line-added"> 816 #endif</span>
<span class="line-added"> 817 </span>
 818 void TemplateTable::iaload()
 819 {
 820   transition(itos, itos);
 821   __ mov(r1, r0);
 822   __ pop_ptr(r0);
 823   // r0: array
 824   // r1: index
 825   index_check(r0, r1); // leaves index in r1, kills rscratch1
 826   __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_INT) &gt;&gt; 2);
 827   __ access_load_at(T_INT, IN_HEAP | IS_ARRAY, r0, Address(r0, r1, Address::uxtw(2)), noreg, noreg);
 828 }
 829 
 830 void TemplateTable::laload()
 831 {
 832   transition(itos, ltos);
 833   __ mov(r1, r0);
 834   __ pop_ptr(r0);
 835   // r0: array
 836   // r1: index
 837   index_check(r0, r1); // leaves index in r1, kills rscratch1
</pre>
<hr />
<pre>
2423                                               Register off,
2424                                               Register flags,
2425                                               bool is_static = false) {
2426   assert_different_registers(cache, index, flags, off);
2427 
2428   ByteSize cp_base_offset = ConstantPoolCache::base_offset();
2429   // Field offset
2430   __ ldr(off, Address(cache, in_bytes(cp_base_offset +
2431                                           ConstantPoolCacheEntry::f2_offset())));
2432   // Flags
2433   __ ldrw(flags, Address(cache, in_bytes(cp_base_offset +
2434                                            ConstantPoolCacheEntry::flags_offset())));
2435 
2436   // klass overwrite register
2437   if (is_static) {
2438     __ ldr(obj, Address(cache, in_bytes(cp_base_offset +
2439                                         ConstantPoolCacheEntry::f1_offset())));
2440     const int mirror_offset = in_bytes(Klass::java_mirror_offset());
2441     __ ldr(obj, Address(obj, mirror_offset));
2442     __ resolve_oop_handle(obj);
<span class="line-added">2443     TSAN_RUNTIME_ONLY(</span>
<span class="line-added">2444       // Draw a happens-before edge from the class&#39;s static initializer to</span>
<span class="line-added">2445       // this lookup.</span>
<span class="line-added">2446 </span>
<span class="line-added">2447       // java_lang_Class::_init_lock_offset may not have been initialized</span>
<span class="line-added">2448       // when generating code. It will be initialized at runtime though.</span>
<span class="line-added">2449       // So calculate its address and read from it at runtime.</span>
<span class="line-added">2450       __ pusha();</span>
<span class="line-added">2451       __ mov(c_rarg0, obj);</span>
<span class="line-added">2452       Address init_lock_offset_address((address) java_lang_Class::init_lock_offset_addr(),</span>
<span class="line-added">2453                                        relocInfo::none);</span>
<span class="line-added">2454       __ lea(rscratch1, init_lock_offset_address);</span>
<span class="line-added">2455       __ ldrw(rscratch1, Address(rscratch1, 0));</span>
<span class="line-added">2456       __ add(c_rarg0, c_rarg0, rscratch1);</span>
<span class="line-added">2457       __ call_VM_leaf(CAST_FROM_FN_PTR(address,</span>
<span class="line-added">2458                                        SharedRuntime::tsan_acquire),</span>
<span class="line-added">2459                                        c_rarg0);</span>
<span class="line-added">2460       __ popa();</span>
<span class="line-added">2461     );</span>
2462   }
2463 }
2464 
2465 void TemplateTable::load_invoke_cp_cache_entry(int byte_no,
2466                                                Register method,
2467                                                Register itable_index,
2468                                                Register flags,
2469                                                bool is_invokevirtual,
2470                                                bool is_invokevfinal, /*unused*/
2471                                                bool is_invokedynamic) {
2472   // setup registers
2473   const Register cache = rscratch2;
2474   const Register index = r4;
2475   assert_different_registers(method, flags);
2476   assert_different_registers(method, cache, index);
2477   assert_different_registers(itable_index, flags);
2478   assert_different_registers(itable_index, cache, index);
2479   // determine constant pool cache field offsets
2480   assert(is_invokevirtual == (byte_no == f2_byte), &quot;is_invokevirtual flag redundant&quot;);
2481   const int method_offset = in_bytes(
</pre>
<hr />
<pre>
2577 
2578   const Address field(obj, off);
2579 
2580   Label Done, notByte, notBool, notInt, notShort, notChar,
2581               notLong, notFloat, notObj, notDouble;
2582 
2583   // x86 uses a shift and mask or wings it with a shift plus assert
2584   // the mask is not needed. aarch64 just uses bitfield extract
2585   __ ubfxw(flags, raw_flags, ConstantPoolCacheEntry::tos_state_shift,
2586            ConstantPoolCacheEntry::tos_state_bits);
2587 
2588   assert(btos == 0, &quot;change code, btos != 0&quot;);
2589   __ cbnz(flags, notByte);
2590 
2591   // Don&#39;t rewrite getstatic, only getfield
2592   if (is_static) rc = may_not_rewrite;
2593 
2594   // btos
2595   __ access_load_at(T_BYTE, IN_HEAP, r0, field, noreg, noreg);
2596   __ push(btos);
<span class="line-added">2597   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read1, btos));</span>
2598   // Rewrite bytecode to be faster
2599   if (rc == may_rewrite) {
2600     patch_bytecode(Bytecodes::_fast_bgetfield, bc, r1);
2601   }
2602   __ b(Done);
2603 
2604   __ bind(notByte);
2605   __ cmp(flags, (u1)ztos);
2606   __ br(Assembler::NE, notBool);
2607 
2608   // ztos (same code as btos)
2609   __ access_load_at(T_BOOLEAN, IN_HEAP, r0, field, noreg, noreg);
2610   __ push(ztos);
<span class="line-added">2611   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read1, ztos));</span>
2612   // Rewrite bytecode to be faster
2613   if (rc == may_rewrite) {
2614     // use btos rewriting, no truncating to t/f bit is needed for getfield.
2615     patch_bytecode(Bytecodes::_fast_bgetfield, bc, r1);
2616   }
2617   __ b(Done);
2618 
2619   __ bind(notBool);
2620   __ cmp(flags, (u1)atos);
2621   __ br(Assembler::NE, notObj);
2622   // atos
2623   do_oop_load(_masm, field, r0, IN_HEAP);
2624   __ push(atos);
<span class="line-added">2625   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field,</span>
<span class="line-added">2626                                             raw_flags,</span>
<span class="line-added">2627                                             UseCompressedOops ? SharedRuntime::tsan_read4</span>
<span class="line-added">2628                                                               : SharedRuntime::tsan_read8,</span>
<span class="line-added">2629                                             atos));</span>
2630   if (rc == may_rewrite) {
2631     patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
2632   }
2633   __ b(Done);
2634 
2635   __ bind(notObj);
2636   __ cmp(flags, (u1)itos);
2637   __ br(Assembler::NE, notInt);
2638   // itos
2639   __ access_load_at(T_INT, IN_HEAP, r0, field, noreg, noreg);
2640   __ push(itos);
<span class="line-added">2641   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read4, itos));</span>
2642   // Rewrite bytecode to be faster
2643   if (rc == may_rewrite) {
2644     patch_bytecode(Bytecodes::_fast_igetfield, bc, r1);
2645   }
2646   __ b(Done);
2647 
2648   __ bind(notInt);
2649   __ cmp(flags, (u1)ctos);
2650   __ br(Assembler::NE, notChar);
2651   // ctos
2652   __ access_load_at(T_CHAR, IN_HEAP, r0, field, noreg, noreg);
2653   __ push(ctos);
<span class="line-added">2654   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read2, ctos));</span>
2655   // Rewrite bytecode to be faster
2656   if (rc == may_rewrite) {
2657     patch_bytecode(Bytecodes::_fast_cgetfield, bc, r1);
2658   }
2659   __ b(Done);
2660 
2661   __ bind(notChar);
2662   __ cmp(flags, (u1)stos);
2663   __ br(Assembler::NE, notShort);
2664   // stos
2665   __ access_load_at(T_SHORT, IN_HEAP, r0, field, noreg, noreg);
2666   __ push(stos);
<span class="line-added">2667   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read2, stos));</span>
2668   // Rewrite bytecode to be faster
2669   if (rc == may_rewrite) {
2670     patch_bytecode(Bytecodes::_fast_sgetfield, bc, r1);
2671   }
2672   __ b(Done);
2673 
2674   __ bind(notShort);
2675   __ cmp(flags, (u1)ltos);
2676   __ br(Assembler::NE, notLong);
2677   // ltos
2678   __ access_load_at(T_LONG, IN_HEAP, r0, field, noreg, noreg);
2679   __ push(ltos);
<span class="line-added">2680   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read8, ltos));</span>
2681   // Rewrite bytecode to be faster
2682   if (rc == may_rewrite) {
2683     patch_bytecode(Bytecodes::_fast_lgetfield, bc, r1);
2684   }
2685   __ b(Done);
2686 
2687   __ bind(notLong);
2688   __ cmp(flags, (u1)ftos);
2689   __ br(Assembler::NE, notFloat);
2690   // ftos
2691   __ access_load_at(T_FLOAT, IN_HEAP, noreg /* ftos */, field, noreg, noreg);
2692   __ push(ftos);
<span class="line-added">2693   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read4, ftos));</span>
2694   // Rewrite bytecode to be faster
2695   if (rc == may_rewrite) {
2696     patch_bytecode(Bytecodes::_fast_fgetfield, bc, r1);
2697   }
2698   __ b(Done);
2699 
2700   __ bind(notFloat);
2701 #ifdef ASSERT
2702   __ cmp(flags, (u1)dtos);
2703   __ br(Assembler::NE, notDouble);
2704 #endif
2705   // dtos
2706   __ access_load_at(T_DOUBLE, IN_HEAP, noreg /* ftos */, field, noreg, noreg);
2707   __ push(dtos);
<span class="line-added">2708   TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, raw_flags, SharedRuntime::tsan_read8, dtos));</span>
2709   // Rewrite bytecode to be faster
2710   if (rc == may_rewrite) {
2711     patch_bytecode(Bytecodes::_fast_dgetfield, bc, r1);
2712   }
2713 #ifdef ASSERT
2714   __ b(Done);
2715 
2716   __ bind(notDouble);
2717   __ stop(&quot;Bad state&quot;);
2718 #endif
2719 
2720   __ bind(Done);
2721 
2722   Label notVolatile;
2723   __ tbz(raw_flags, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
2724   __ membar(MacroAssembler::LoadLoad | MacroAssembler::LoadStore);
2725   __ bind(notVolatile);
2726 }
2727 
2728 
</pre>
<hr />
<pre>
2796     __ get_cache_and_index_at_bcp(cache, index, 1);
2797     __ bind(L1);
2798   }
2799 }
2800 
2801 void TemplateTable::putfield_or_static(int byte_no, bool is_static, RewriteControl rc) {
2802   transition(vtos, vtos);
2803 
2804   const Register cache = r2;
2805   const Register index = r3;
2806   const Register obj   = r2;
2807   const Register off   = r19;
2808   const Register flags = r0;
2809   const Register bc    = r4;
2810 
2811   resolve_cache_and_index(byte_no, cache, index, sizeof(u2));
2812   jvmti_post_field_mod(cache, index, is_static);
2813   load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);
2814 
2815   Label Done;
<span class="line-added">2816   // save raw flags in r5</span>
2817   __ mov(r5, flags);
2818 
2819   {
2820     Label notVolatile;
2821     __ tbz(r5, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
2822     __ membar(MacroAssembler::StoreStore | MacroAssembler::LoadStore);
2823     __ bind(notVolatile);
2824   }
2825 
2826   // field address
2827   const Address field(obj, off);
2828 
2829   Label notByte, notBool, notInt, notShort, notChar,
2830         notLong, notFloat, notObj, notDouble;
2831 
2832   // x86 uses a shift and mask or wings it with a shift plus assert
2833   // the mask is not needed. aarch64 just uses bitfield extract
2834   __ ubfxw(flags, flags, ConstantPoolCacheEntry::tos_state_shift,  ConstantPoolCacheEntry::tos_state_bits);
2835 
2836   assert(btos == 0, &quot;change code, btos != 0&quot;);
2837   __ cbnz(flags, notByte);
2838 
2839   // Don&#39;t rewrite putstatic, only putfield
2840   if (is_static) rc = may_not_rewrite;
2841 
2842   // btos
2843   {
2844     __ pop(btos);
2845     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2846     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write1, btos));</span>
2847     __ access_store_at(T_BYTE, IN_HEAP, field, r0, noreg, noreg);
2848     if (rc == may_rewrite) {
2849       patch_bytecode(Bytecodes::_fast_bputfield, bc, r1, true, byte_no);
2850     }
2851     __ b(Done);
2852   }
2853 
2854   __ bind(notByte);
2855   __ cmp(flags, (u1)ztos);
2856   __ br(Assembler::NE, notBool);
2857 
2858   // ztos
2859   {
2860     __ pop(ztos);
2861     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2862     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write1, ztos));</span>
2863     __ access_store_at(T_BOOLEAN, IN_HEAP, field, r0, noreg, noreg);
2864     if (rc == may_rewrite) {
2865       patch_bytecode(Bytecodes::_fast_zputfield, bc, r1, true, byte_no);
2866     }
2867     __ b(Done);
2868   }
2869 
2870   __ bind(notBool);
2871   __ cmp(flags, (u1)atos);
2872   __ br(Assembler::NE, notObj);
2873 
2874   // atos
2875   {
2876     __ pop(atos);
2877     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2878     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field,</span>
<span class="line-added">2879                                               r5,</span>
<span class="line-added">2880                                               UseCompressedOops ? SharedRuntime::tsan_write4</span>
<span class="line-added">2881                                                                 : SharedRuntime::tsan_write8,</span>
<span class="line-added">2882                                               atos));</span>
2883     // Store into the field
2884     do_oop_store(_masm, field, r0, IN_HEAP);
2885     if (rc == may_rewrite) {
2886       patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);
2887     }
2888     __ b(Done);
2889   }
2890 
2891   __ bind(notObj);
2892   __ cmp(flags, (u1)itos);
2893   __ br(Assembler::NE, notInt);
2894 
2895   // itos
2896   {
2897     __ pop(itos);
2898     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2899     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write4, itos));</span>
2900     __ access_store_at(T_INT, IN_HEAP, field, r0, noreg, noreg);
2901     if (rc == may_rewrite) {
2902       patch_bytecode(Bytecodes::_fast_iputfield, bc, r1, true, byte_no);
2903     }
2904     __ b(Done);
2905   }
2906 
2907   __ bind(notInt);
2908   __ cmp(flags, (u1)ctos);
2909   __ br(Assembler::NE, notChar);
2910 
2911   // ctos
2912   {
2913     __ pop(ctos);
2914     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2915     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write2, ctos));</span>
2916     __ access_store_at(T_CHAR, IN_HEAP, field, r0, noreg, noreg);
2917     if (rc == may_rewrite) {
2918       patch_bytecode(Bytecodes::_fast_cputfield, bc, r1, true, byte_no);
2919     }
2920     __ b(Done);
2921   }
2922 
2923   __ bind(notChar);
2924   __ cmp(flags, (u1)stos);
2925   __ br(Assembler::NE, notShort);
2926 
2927   // stos
2928   {
2929     __ pop(stos);
2930     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2931     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write2, stos));</span>
2932     __ access_store_at(T_SHORT, IN_HEAP, field, r0, noreg, noreg);
2933     if (rc == may_rewrite) {
2934       patch_bytecode(Bytecodes::_fast_sputfield, bc, r1, true, byte_no);
2935     }
2936     __ b(Done);
2937   }
2938 
2939   __ bind(notShort);
2940   __ cmp(flags, (u1)ltos);
2941   __ br(Assembler::NE, notLong);
2942 
2943   // ltos
2944   {
2945     __ pop(ltos);
2946     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2947     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write8, ltos));</span>
2948     __ access_store_at(T_LONG, IN_HEAP, field, r0, noreg, noreg);
2949     if (rc == may_rewrite) {
2950       patch_bytecode(Bytecodes::_fast_lputfield, bc, r1, true, byte_no);
2951     }
2952     __ b(Done);
2953   }
2954 
2955   __ bind(notLong);
2956   __ cmp(flags, (u1)ftos);
2957   __ br(Assembler::NE, notFloat);
2958 
2959   // ftos
2960   {
2961     __ pop(ftos);
2962     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2963     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write4, ftos));</span>
2964     __ access_store_at(T_FLOAT, IN_HEAP, field, noreg /* ftos */, noreg, noreg);
2965     if (rc == may_rewrite) {
2966       patch_bytecode(Bytecodes::_fast_fputfield, bc, r1, true, byte_no);
2967     }
2968     __ b(Done);
2969   }
2970 
2971   __ bind(notFloat);
2972 #ifdef ASSERT
2973   __ cmp(flags, (u1)dtos);
2974   __ br(Assembler::NE, notDouble);
2975 #endif
2976 
2977   // dtos
2978   {
2979     __ pop(dtos);
2980     if (!is_static) pop_and_check_object(obj);
<span class="line-added">2981     TSAN_RUNTIME_ONLY(tsan_observe_get_or_put(field, r5, SharedRuntime::tsan_write8, dtos));</span>
2982     __ access_store_at(T_DOUBLE, IN_HEAP, field, noreg /* dtos */, noreg, noreg);
2983     if (rc == may_rewrite) {
2984       patch_bytecode(Bytecodes::_fast_dputfield, bc, r1, true, byte_no);
2985     }
2986   }
2987 
2988 #ifdef ASSERT
2989   __ b(Done);
2990 
2991   __ bind(notDouble);
2992   __ stop(&quot;Bad state&quot;);
2993 #endif
2994 
2995   __ bind(Done);
2996 
2997   {
2998     Label notVolatile;
2999     __ tbz(r5, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
3000     __ membar(MacroAssembler::StoreLoad | MacroAssembler::StoreStore);
3001     __ bind(notVolatile);
</pre>
</td>
</tr>
</table>
<center>&lt; prev <a href="../../../../index.html" target="_top">index</a> <a href="../x86/templateTable_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>