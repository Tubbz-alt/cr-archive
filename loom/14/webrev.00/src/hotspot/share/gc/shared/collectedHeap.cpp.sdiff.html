<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shared/collectedHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="barrierSetNMethod.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="gcCause.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shared/collectedHeap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
218 
219   // Create the ring log
220   if (LogEvents) {
221     _gc_heap_log = new GCHeapLog();
222   } else {
223     _gc_heap_log = NULL;
224   }
225 }
226 
227 // This interface assumes that it&#39;s being called by the
228 // vm thread. It collects the heap assuming that the
229 // heap lock is already held and that we are executing in
230 // the context of the vm thread.
231 void CollectedHeap::collect_as_vm_thread(GCCause::Cause cause) {
232   assert(Thread::current()-&gt;is_VM_thread(), &quot;Precondition#1&quot;);
233   assert(Heap_lock-&gt;is_locked(), &quot;Precondition#2&quot;);
234   GCCauseSetter gcs(this, cause);
235   switch (cause) {
236     case GCCause::_heap_inspection:
237     case GCCause::_heap_dump:

238     case GCCause::_metadata_GC_threshold : {
239       HandleMark hm;
240       do_full_collection(false);        // don&#39;t clear all soft refs
241       break;
242     }
243     case GCCause::_archive_time_gc:
244     case GCCause::_metadata_GC_clear_soft_refs: {
245       HandleMark hm;
246       do_full_collection(true);         // do clear all soft refs
247       break;
248     }
249     default:
250       ShouldNotReachHere(); // Unexpected use of this function
251   }
252 }
253 
254 MetaWord* CollectedHeap::satisfy_failed_metadata_allocation(ClassLoaderData* loader_data,
255                                                             size_t word_size,
256                                                             Metaspace::MetadataType mdtype) {
257   uint loop_count = 0;
</pre>
<hr />
<pre>
347         // to the next iteration to get a full GC.
348         continue;
349       } else {
350         if (CheckJNICalls) {
351           fatal(&quot;Possible deadlock due to allocating while&quot;
352                 &quot; in jni critical section&quot;);
353         }
354         return;
355       }
356     }
357 
358     {  // Need lock to get self consistent gc_count&#39;s
359       MutexLocker ml(Heap_lock);
360       gc_count      = Universe::heap()-&gt;total_collections();
361       full_gc_count = Universe::heap()-&gt;total_full_collections();
362     }
363 
364     // Generate a VM operation
365     VM_CollectForCodeCacheAllocation op(gc_count,
366                                         full_gc_count,
<span class="line-modified">367                                         GCCause::_metadata_GC_threshold);</span>
368     VMThread::execute(&amp;op);
369 
370     // If GC was locked out, try again. Check before checking success because the
371     // prologue could have succeeded and the GC still have been locked out.
372     if (op.gc_locked()) {
373       continue;
374     }
375 
376     if (op.prologue_succeeded()) {
377       return;
378     }
379     loop_count++;
380     if ((QueuedAllocationWarningCount &gt; 0) &amp;&amp;
381         (loop_count % QueuedAllocationWarningCount == 0)) {
382       log_warning(gc, ergo)(&quot;collect_for_codecache() retries %d times&quot;, loop_count);
383     }
384   } while (true);  // Until a GC is done
385 }
386 
387 MemoryUsage CollectedHeap::memory_usage() {
</pre>
</td>
<td>
<hr />
<pre>
218 
219   // Create the ring log
220   if (LogEvents) {
221     _gc_heap_log = new GCHeapLog();
222   } else {
223     _gc_heap_log = NULL;
224   }
225 }
226 
227 // This interface assumes that it&#39;s being called by the
228 // vm thread. It collects the heap assuming that the
229 // heap lock is already held and that we are executing in
230 // the context of the vm thread.
231 void CollectedHeap::collect_as_vm_thread(GCCause::Cause cause) {
232   assert(Thread::current()-&gt;is_VM_thread(), &quot;Precondition#1&quot;);
233   assert(Heap_lock-&gt;is_locked(), &quot;Precondition#2&quot;);
234   GCCauseSetter gcs(this, cause);
235   switch (cause) {
236     case GCCause::_heap_inspection:
237     case GCCause::_heap_dump:
<span class="line-added">238     case GCCause::_codecache_GC_threshold:</span>
239     case GCCause::_metadata_GC_threshold : {
240       HandleMark hm;
241       do_full_collection(false);        // don&#39;t clear all soft refs
242       break;
243     }
244     case GCCause::_archive_time_gc:
245     case GCCause::_metadata_GC_clear_soft_refs: {
246       HandleMark hm;
247       do_full_collection(true);         // do clear all soft refs
248       break;
249     }
250     default:
251       ShouldNotReachHere(); // Unexpected use of this function
252   }
253 }
254 
255 MetaWord* CollectedHeap::satisfy_failed_metadata_allocation(ClassLoaderData* loader_data,
256                                                             size_t word_size,
257                                                             Metaspace::MetadataType mdtype) {
258   uint loop_count = 0;
</pre>
<hr />
<pre>
348         // to the next iteration to get a full GC.
349         continue;
350       } else {
351         if (CheckJNICalls) {
352           fatal(&quot;Possible deadlock due to allocating while&quot;
353                 &quot; in jni critical section&quot;);
354         }
355         return;
356       }
357     }
358 
359     {  // Need lock to get self consistent gc_count&#39;s
360       MutexLocker ml(Heap_lock);
361       gc_count      = Universe::heap()-&gt;total_collections();
362       full_gc_count = Universe::heap()-&gt;total_full_collections();
363     }
364 
365     // Generate a VM operation
366     VM_CollectForCodeCacheAllocation op(gc_count,
367                                         full_gc_count,
<span class="line-modified">368                                         GCCause::_codecache_GC_threshold);</span>
369     VMThread::execute(&amp;op);
370 
371     // If GC was locked out, try again. Check before checking success because the
372     // prologue could have succeeded and the GC still have been locked out.
373     if (op.gc_locked()) {
374       continue;
375     }
376 
377     if (op.prologue_succeeded()) {
378       return;
379     }
380     loop_count++;
381     if ((QueuedAllocationWarningCount &gt; 0) &amp;&amp;
382         (loop_count % QueuedAllocationWarningCount == 0)) {
383       log_warning(gc, ergo)(&quot;collect_for_codecache() retries %d times&quot;, loop_count);
384     }
385   } while (true);  // Until a GC is done
386 }
387 
388 MemoryUsage CollectedHeap::memory_usage() {
</pre>
</td>
</tr>
</table>
<center><a href="barrierSetNMethod.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="gcCause.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>