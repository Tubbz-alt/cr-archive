<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/gc/z/zCollectedHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  */
 23 
 24 #include &quot;precompiled.hpp&quot;
 25 #include &quot;gc/shared/gcHeapSummary.hpp&quot;
 26 #include &quot;gc/shared/suspendibleThreadSet.hpp&quot;
 27 #include &quot;gc/z/zCollectedHeap.hpp&quot;
 28 #include &quot;gc/z/zDirector.hpp&quot;
 29 #include &quot;gc/z/zDriver.hpp&quot;
 30 #include &quot;gc/z/zGlobals.hpp&quot;
 31 #include &quot;gc/z/zHeap.inline.hpp&quot;
 32 #include &quot;gc/z/zNMethod.hpp&quot;
 33 #include &quot;gc/z/zObjArrayAllocator.hpp&quot;
 34 #include &quot;gc/z/zOop.inline.hpp&quot;
 35 #include &quot;gc/z/zServiceability.hpp&quot;
 36 #include &quot;gc/z/zStat.hpp&quot;
 37 #include &quot;gc/z/zUtils.inline.hpp&quot;
 38 #include &quot;memory/iterator.hpp&quot;
 39 #include &quot;memory/universe.hpp&quot;
 40 #include &quot;runtime/mutexLocker.hpp&quot;
 41 #include &quot;utilities/align.hpp&quot;
 42 
 43 ZCollectedHeap* ZCollectedHeap::heap() {
 44   return named_heap&lt;ZCollectedHeap&gt;(CollectedHeap::Z);
 45 }
 46 
 47 ZCollectedHeap::ZCollectedHeap() :
 48     _soft_ref_policy(),
 49     _barrier_set(),
 50     _initialize(&amp;_barrier_set),
 51     _heap(),
 52     _director(new ZDirector()),
 53     _driver(new ZDriver()),
 54     _stat(new ZStat()),
 55     _runtime_workers() {}
 56 
 57 CollectedHeap::Name ZCollectedHeap::kind() const {
 58   return CollectedHeap::Z;
 59 }
 60 
 61 const char* ZCollectedHeap::name() const {
 62   return ZName;
 63 }
 64 
 65 jint ZCollectedHeap::initialize() {
 66   if (!_heap.is_initialized()) {
 67     return JNI_ENOMEM;
 68   }
 69 
 70   Universe::calculate_verify_data((HeapWord*)0, (HeapWord*)UINTPTR_MAX);
 71 
 72   return JNI_OK;
 73 }
 74 
 75 void ZCollectedHeap::initialize_serviceability() {
 76   _heap.serviceability_initialize();
 77 }
 78 
 79 class ZStopConcurrentGCThreadClosure : public ThreadClosure {
 80 public:
 81   virtual void do_thread(Thread* thread) {
 82     if (thread-&gt;is_ConcurrentGC_thread() &amp;&amp;
 83         !thread-&gt;is_GC_task_thread()) {
 84       static_cast&lt;ConcurrentGCThread*&gt;(thread)-&gt;stop();
 85     }
 86   }
 87 };
 88 
 89 void ZCollectedHeap::stop() {
 90   ZStopConcurrentGCThreadClosure cl;
 91   gc_threads_do(&amp;cl);
 92 }
 93 
 94 SoftRefPolicy* ZCollectedHeap::soft_ref_policy() {
 95   return &amp;_soft_ref_policy;
 96 }
 97 
 98 size_t ZCollectedHeap::max_capacity() const {
 99   return _heap.max_capacity();
100 }
101 
102 size_t ZCollectedHeap::capacity() const {
103   return _heap.capacity();
104 }
105 
106 size_t ZCollectedHeap::used() const {
107   return _heap.used();
108 }
109 
110 size_t ZCollectedHeap::unused() const {
111   return _heap.unused();
112 }
113 
114 bool ZCollectedHeap::is_maximal_no_gc() const {
115   // Not supported
116   ShouldNotReachHere();
117   return false;
118 }
119 
120 bool ZCollectedHeap::is_in(const void* p) const {
121   return _heap.is_in((uintptr_t)p);
122 }
123 
124 bool ZCollectedHeap::requires_barriers(oop obj) const {
125   return !_heap.is_allocating(cast_from_oop&lt;uintptr_t&gt;(obj));
126 }
127 
128 uint32_t ZCollectedHeap::hash_oop(oop obj) const {
129   return _heap.hash_oop(ZOop::to_address(obj));
130 }
131 
132 HeapWord* ZCollectedHeap::allocate_new_tlab(size_t min_size, size_t requested_size, size_t* actual_size) {
133   const size_t size_in_bytes = ZUtils::words_to_bytes(align_object_size(requested_size));
134   const uintptr_t addr = _heap.alloc_tlab(size_in_bytes);
135 
136   if (addr != 0) {
137     *actual_size = requested_size;
138   }
139 
140   return (HeapWord*)addr;
141 }
142 
143 oop ZCollectedHeap::array_allocate(Klass* klass, int size, int length, bool do_zero, TRAPS) {
144   if (!do_zero) {
145     return CollectedHeap::array_allocate(klass, size, length, false /* do_zero */, THREAD);
146   }
147 
148   ZObjArrayAllocator allocator(klass, size, length, THREAD);
149   return allocator.allocate();
150 }
151 
152 HeapWord* ZCollectedHeap::mem_allocate(size_t size, bool* gc_overhead_limit_was_exceeded) {
153   const size_t size_in_bytes = ZUtils::words_to_bytes(align_object_size(size));
154   return (HeapWord*)_heap.alloc_object(size_in_bytes);
155 }
156 
157 MetaWord* ZCollectedHeap::satisfy_failed_metadata_allocation(ClassLoaderData* loader_data,
158                                                              size_t size,
159                                                              Metaspace::MetadataType mdtype) {
160   MetaWord* result;
161 
162   // Start asynchronous GC
163   collect(GCCause::_metadata_GC_threshold);
164 
165   // Expand and retry allocation
166   result = loader_data-&gt;metaspace_non_null()-&gt;expand_and_allocate(size, mdtype);
167   if (result != NULL) {
168     return result;
169   }
170 
171   // Start synchronous GC
172   collect(GCCause::_metadata_GC_clear_soft_refs);
173 
174   // Retry allocation
175   result = loader_data-&gt;metaspace_non_null()-&gt;allocate(size, mdtype);
176   if (result != NULL) {
177     return result;
178   }
179 
180   // Expand and retry allocation
181   result = loader_data-&gt;metaspace_non_null()-&gt;expand_and_allocate(size, mdtype);
182   if (result != NULL) {
183     return result;
184   }
185 
186   // Out of memory
187   return NULL;
188 }
189 
190 void ZCollectedHeap::collect(GCCause::Cause cause) {
191   _driver-&gt;collect(cause);
192 }
193 
194 void ZCollectedHeap::collect_for_codecache() {
195   // Start synchronous GC
196   collect(GCCause::_codecache_GC_threshold);
197 }
198 
199 void ZCollectedHeap::collect_as_vm_thread(GCCause::Cause cause) {
200   // These collection requests are ignored since ZGC can&#39;t run a synchronous
201   // GC cycle from within the VM thread. This is considered benign, since the
202   // only GC causes coming in here should be heap dumper and heap inspector.
203   // However, neither the heap dumper nor the heap inspector really need a GC
204   // to happen, but the result of their heap iterations might in that case be
205   // less accurate since they might include objects that would otherwise have
206   // been collected by a GC.
207   assert(Thread::current()-&gt;is_VM_thread(), &quot;Should be the VM thread&quot;);
208   guarantee(cause == GCCause::_heap_dump ||
209             cause == GCCause::_heap_inspection, &quot;Invalid cause&quot;);
210 }
211 
212 void ZCollectedHeap::do_full_collection(bool clear_all_soft_refs) {
213   // Not supported
214   ShouldNotReachHere();
215 }
216 
217 bool ZCollectedHeap::supports_tlab_allocation() const {
218   return true;
219 }
220 
221 size_t ZCollectedHeap::tlab_capacity(Thread* ignored) const {
222   return _heap.tlab_capacity();
223 }
224 
225 size_t ZCollectedHeap::tlab_used(Thread* ignored) const {
226   return _heap.tlab_used();
227 }
228 
229 size_t ZCollectedHeap::max_tlab_size() const {
230   return _heap.max_tlab_size();
231 }
232 
233 size_t ZCollectedHeap::unsafe_max_tlab_alloc(Thread* ignored) const {
234   return _heap.unsafe_max_tlab_alloc();
235 }
236 
237 bool ZCollectedHeap::can_elide_tlab_store_barriers() const {
238   return false;
239 }
240 
241 bool ZCollectedHeap::can_elide_initializing_store_barrier(oop new_obj) {
242   // Not supported
243   ShouldNotReachHere();
244   return true;
245 }
246 
247 bool ZCollectedHeap::card_mark_must_follow_store() const {
248   // Not supported
249   ShouldNotReachHere();
250   return false;
251 }
252 
253 GrowableArray&lt;GCMemoryManager*&gt; ZCollectedHeap::memory_managers() {
254   return GrowableArray&lt;GCMemoryManager*&gt;(1, 1, _heap.serviceability_memory_manager());
255 }
256 
257 GrowableArray&lt;MemoryPool*&gt; ZCollectedHeap::memory_pools() {
258   return GrowableArray&lt;MemoryPool*&gt;(1, 1, _heap.serviceability_memory_pool());
259 }
260 
261 void ZCollectedHeap::object_iterate(ObjectClosure* cl) {
262   _heap.object_iterate(cl, true /* visit_weaks */);
263 }
264 
265 void ZCollectedHeap::keep_alive(oop obj) {
266   _heap.keep_alive(obj);
267 }
268 
269 void ZCollectedHeap::register_nmethod(nmethod* nm) {
270   ZNMethod::register_nmethod(nm);
271 }
272 
273 void ZCollectedHeap::unregister_nmethod(nmethod* nm) {
274   ZNMethod::unregister_nmethod(nm);
275 }
276 
277 void ZCollectedHeap::flush_nmethod(nmethod* nm) {
278   ZNMethod::flush_nmethod(nm);
279 }
280 
281 void ZCollectedHeap::verify_nmethod(nmethod* nm) {
282   // Does nothing
283 }
284 
285 WorkGang* ZCollectedHeap::get_safepoint_workers() {
286   return _runtime_workers.workers();
287 }
288 
289 jlong ZCollectedHeap::millis_since_last_gc() {
290   return ZStatCycle::time_since_last() / MILLIUNITS;
291 }
292 
293 void ZCollectedHeap::gc_threads_do(ThreadClosure* tc) const {
294   tc-&gt;do_thread(_director);
295   tc-&gt;do_thread(_driver);
296   tc-&gt;do_thread(_stat);
297   _heap.threads_do(tc);
298   _runtime_workers.threads_do(tc);
299 }
300 
301 VirtualSpaceSummary ZCollectedHeap::create_heap_space_summary() {
302   return VirtualSpaceSummary((HeapWord*)0, (HeapWord*)capacity(), (HeapWord*)max_capacity());
303 }
304 
305 void ZCollectedHeap::safepoint_synchronize_begin() {
306   SuspendibleThreadSet::synchronize();
307 }
308 
309 void ZCollectedHeap::safepoint_synchronize_end() {
310   SuspendibleThreadSet::desynchronize();
311 }
312 
313 void ZCollectedHeap::prepare_for_verify() {
314   // Does nothing
315 }
316 
317 void ZCollectedHeap::print_on(outputStream* st) const {
318   _heap.print_on(st);
319 }
320 
321 void ZCollectedHeap::print_on_error(outputStream* st) const {
322   st-&gt;print_cr(&quot;ZGC Globals:&quot;);
323   st-&gt;print_cr(&quot; GlobalPhase:       %u (%s)&quot;, ZGlobalPhase, ZGlobalPhaseToString());
324   st-&gt;print_cr(&quot; GlobalSeqNum:      %u&quot;, ZGlobalSeqNum);
325   st-&gt;print_cr(&quot; Offset Max:        &quot; SIZE_FORMAT &quot;%s (&quot; PTR_FORMAT &quot;)&quot;,
326                byte_size_in_exact_unit(ZAddressOffsetMax),
327                exact_unit_for_byte_size(ZAddressOffsetMax),
328                ZAddressOffsetMax);
329   st-&gt;print_cr(&quot; Page Size Small:   &quot; SIZE_FORMAT &quot;M&quot;, ZPageSizeSmall / M);
330   st-&gt;print_cr(&quot; Page Size Medium:  &quot; SIZE_FORMAT &quot;M&quot;, ZPageSizeMedium / M);
331   st-&gt;cr();
332   st-&gt;print_cr(&quot;ZGC Metadata Bits:&quot;);
333   st-&gt;print_cr(&quot; Good:              &quot; PTR_FORMAT, ZAddressGoodMask);
334   st-&gt;print_cr(&quot; Bad:               &quot; PTR_FORMAT, ZAddressBadMask);
335   st-&gt;print_cr(&quot; WeakBad:           &quot; PTR_FORMAT, ZAddressWeakBadMask);
336   st-&gt;print_cr(&quot; Marked:            &quot; PTR_FORMAT, ZAddressMetadataMarked);
337   st-&gt;print_cr(&quot; Remapped:          &quot; PTR_FORMAT, ZAddressMetadataRemapped);
338   st-&gt;cr();
339   CollectedHeap::print_on_error(st);
340 }
341 
342 void ZCollectedHeap::print_extended_on(outputStream* st) const {
343   _heap.print_extended_on(st);
344 }
345 
346 void ZCollectedHeap::print_tracing_info() const {
347   // Does nothing
348 }
349 
350 bool ZCollectedHeap::print_location(outputStream* st, void* addr) const {
351   return _heap.print_location(st, (uintptr_t)addr);
352 }
353 
354 void ZCollectedHeap::verify(VerifyOption option /* ignored */) {
355   _heap.verify();
356 }
357 
358 bool ZCollectedHeap::is_oop(oop object) const {
359   return _heap.is_oop(ZOop::to_address(object));
360 }
361 
362 bool ZCollectedHeap::supports_concurrent_gc_breakpoints() const {
363   return true;
364 }
    </pre>
  </body>
</html>