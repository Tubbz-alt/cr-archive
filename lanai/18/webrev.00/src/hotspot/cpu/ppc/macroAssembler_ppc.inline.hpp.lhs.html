<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/ppc/macroAssembler_ppc.inline.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2002, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2012, 2015 SAP SE. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #ifndef CPU_PPC_MACROASSEMBLER_PPC_INLINE_HPP
 27 #define CPU_PPC_MACROASSEMBLER_PPC_INLINE_HPP
 28 
 29 #include &quot;asm/assembler.inline.hpp&quot;
 30 #include &quot;asm/macroAssembler.hpp&quot;
 31 #include &quot;asm/codeBuffer.hpp&quot;
 32 #include &quot;code/codeCache.hpp&quot;
 33 #include &quot;gc/shared/barrierSet.hpp&quot;
 34 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
 35 #include &quot;oops/accessDecorators.hpp&quot;
 36 #include &quot;oops/compressedOops.hpp&quot;
 37 #include &quot;runtime/safepointMechanism.hpp&quot;
<a name="1" id="anc1"></a>
 38 
 39 inline bool MacroAssembler::is_ld_largeoffset(address a) {
 40   const int inst1 = *(int *)a;
 41   const int inst2 = *(int *)(a+4);
 42   return (is_ld(inst1)) ||
 43          (is_addis(inst1) &amp;&amp; is_ld(inst2) &amp;&amp; inv_ra_field(inst2) == inv_rt_field(inst1));
 44 }
 45 
 46 inline int MacroAssembler::get_ld_largeoffset_offset(address a) {
 47   assert(MacroAssembler::is_ld_largeoffset(a), &quot;must be ld with large offset&quot;);
 48 
 49   const int inst1 = *(int *)a;
 50   if (is_ld(inst1)) {
 51     return inv_d1_field(inst1);
 52   } else {
 53     const int inst2 = *(int *)(a+4);
 54     return (inv_d1_field(inst1) &lt;&lt; 16) + inv_d1_field(inst2);
 55   }
 56 }
 57 
 58 inline void MacroAssembler::round_to(Register r, int modulus) {
<a name="2" id="anc2"></a><span class="line-modified"> 59   assert(is_power_of_2_long((jlong)modulus), &quot;must be power of 2&quot;);</span>
 60   addi(r, r, modulus-1);
 61   clrrdi(r, r, log2_long((jlong)modulus));
 62 }
 63 
 64 // Move register if destination register and target register are different.
 65 inline void MacroAssembler::mr_if_needed(Register rd, Register rs) {
 66   if (rs != rd) mr(rd, rs);
 67 }
 68 inline void MacroAssembler::fmr_if_needed(FloatRegister rd, FloatRegister rs) {
 69   if (rs != rd) fmr(rd, rs);
 70 }
 71 inline void MacroAssembler::endgroup_if_needed(bool needed) {
 72   if (needed) {
 73     endgroup();
 74   }
 75 }
 76 
 77 inline void MacroAssembler::membar(int bits) {
 78   // Comment: Usage of elemental_membar(bits) is not recommended for Power 8.
 79   // If elemental_membar(bits) is used, disable optimization of acquire-release
 80   // (Matcher::post_membar_release where we use PPC64_ONLY(xop == Op_MemBarRelease ||))!
 81   if (bits &amp; StoreLoad) { sync(); }
 82   else if (bits) { lwsync(); }
 83 }
 84 inline void MacroAssembler::release() { membar(LoadStore | StoreStore); }
 85 inline void MacroAssembler::acquire() { membar(LoadLoad | LoadStore); }
 86 inline void MacroAssembler::fence()   { membar(LoadLoad | LoadStore | StoreLoad | StoreStore); }
 87 
 88 // Address of the global TOC.
 89 inline address MacroAssembler::global_toc() {
 90   return CodeCache::low_bound();
 91 }
 92 
 93 // Offset of given address to the global TOC.
 94 inline int MacroAssembler::offset_to_global_toc(const address addr) {
 95   intptr_t offset = (intptr_t)addr - (intptr_t)MacroAssembler::global_toc();
 96   assert(Assembler::is_uimm((long)offset, 31), &quot;must be in range&quot;);
 97   return (int)offset;
 98 }
 99 
100 // Address of current method&#39;s TOC.
101 inline address MacroAssembler::method_toc() {
102   return code()-&gt;consts()-&gt;start();
103 }
104 
105 // Offset of given address to current method&#39;s TOC.
106 inline int MacroAssembler::offset_to_method_toc(address addr) {
107   intptr_t offset = (intptr_t)addr - (intptr_t)method_toc();
108   assert(Assembler::is_uimm((long)offset, 31), &quot;must be in range&quot;);
109   return (int)offset;
110 }
111 
112 inline bool MacroAssembler::is_calculate_address_from_global_toc_at(address a, address bound) {
113   const address inst2_addr = a;
114   const int inst2 = *(int *) a;
115 
116   // The relocation points to the second instruction, the addi.
117   if (!is_addi(inst2)) return false;
118 
119   // The addi reads and writes the same register dst.
120   const int dst = inv_rt_field(inst2);
121   if (inv_ra_field(inst2) != dst) return false;
122 
123   // Now, find the preceding addis which writes to dst.
124   int inst1 = 0;
125   address inst1_addr = inst2_addr - BytesPerInstWord;
126   while (inst1_addr &gt;= bound) {
127     inst1 = *(int *) inst1_addr;
128     if (is_addis(inst1) &amp;&amp; inv_rt_field(inst1) == dst) {
129       // stop, found the addis which writes dst
130       break;
131     }
132     inst1_addr -= BytesPerInstWord;
133   }
134 
135   if (!(inst1 == 0 || inv_ra_field(inst1) == 29 /* R29 */)) return false;
136   return is_addis(inst1);
137 }
138 
139 #ifdef _LP64
140 // Detect narrow oop constants.
141 inline bool MacroAssembler::is_set_narrow_oop(address a, address bound) {
142   const address inst2_addr = a;
143   const int inst2 = *(int *)a;
144   // The relocation points to the second instruction, the ori.
145   if (!is_ori(inst2)) return false;
146 
147   // The ori reads and writes the same register dst.
148   const int dst = inv_rta_field(inst2);
149   if (inv_rs_field(inst2) != dst) return false;
150 
151   // Now, find the preceding addis which writes to dst.
152   int inst1 = 0;
153   address inst1_addr = inst2_addr - BytesPerInstWord;
154   while (inst1_addr &gt;= bound) {
155     inst1 = *(int *) inst1_addr;
156     if (is_lis(inst1) &amp;&amp; inv_rs_field(inst1) == dst) return true;
157     inst1_addr -= BytesPerInstWord;
158   }
159   return false;
160 }
161 #endif
162 
163 
164 inline bool MacroAssembler::is_load_const_at(address a) {
165   const int* p_inst = (int *) a;
166   bool b = is_lis(*p_inst++);
167   if (is_ori(*p_inst)) {
168     p_inst++;
169     b = b &amp;&amp; is_rldicr(*p_inst++); // TODO: could be made more precise: `sldi&#39;!
170     b = b &amp;&amp; is_oris(*p_inst++);
171     b = b &amp;&amp; is_ori(*p_inst);
172   } else if (is_lis(*p_inst)) {
173     p_inst++;
174     b = b &amp;&amp; is_ori(*p_inst++);
175     b = b &amp;&amp; is_ori(*p_inst);
176     // TODO: could enhance reliability by adding is_insrdi
177   } else return false;
178   return b;
179 }
180 
181 inline void MacroAssembler::set_oop_constant(jobject obj, Register d) {
182   set_oop(constant_oop_address(obj), d);
183 }
184 
185 inline void MacroAssembler::set_oop(AddressLiteral obj_addr, Register d) {
186   assert(obj_addr.rspec().type() == relocInfo::oop_type, &quot;must be an oop reloc&quot;);
187   load_const(d, obj_addr);
188 }
189 
190 inline void MacroAssembler::pd_patch_instruction(address branch, address target, const char* file, int line) {
191   jint&amp; stub_inst = *(jint*) branch;
192   stub_inst = patched_branch(target - branch, stub_inst, 0);
193 }
194 
195 // Relocation of conditional far branches.
196 inline bool MacroAssembler::is_bc_far_variant1_at(address instruction_addr) {
197   // Variant 1, the 1st instruction contains the destination address:
198   //
199   //    bcxx  DEST
200   //    nop
201   //
202   const int instruction_1 = *(int*)(instruction_addr);
203   const int instruction_2 = *(int*)(instruction_addr + 4);
204   return is_bcxx(instruction_1) &amp;&amp;
205          (inv_bd_field(instruction_1, (intptr_t)instruction_addr) != (intptr_t)(instruction_addr + 2*4)) &amp;&amp;
206          is_nop(instruction_2);
207 }
208 
209 // Relocation of conditional far branches.
210 inline bool MacroAssembler::is_bc_far_variant2_at(address instruction_addr) {
211   // Variant 2, the 2nd instruction contains the destination address:
212   //
213   //    b!cxx SKIP
214   //    bxx   DEST
215   //  SKIP:
216   //
217   const int instruction_1 = *(int*)(instruction_addr);
218   const int instruction_2 = *(int*)(instruction_addr + 4);
219   return is_bcxx(instruction_1) &amp;&amp;
220          (inv_bd_field(instruction_1, (intptr_t)instruction_addr) == (intptr_t)(instruction_addr + 2*4)) &amp;&amp;
221          is_bxx(instruction_2);
222 }
223 
224 // Relocation for conditional branches
225 inline bool MacroAssembler::is_bc_far_variant3_at(address instruction_addr) {
226   // Variant 3, far cond branch to the next instruction, already patched to nops:
227   //
228   //    nop
229   //    endgroup
230   //  SKIP/DEST:
231   //
232   const int instruction_1 = *(int*)(instruction_addr);
233   const int instruction_2 = *(int*)(instruction_addr + 4);
234   return is_nop(instruction_1) &amp;&amp;
235          is_endgroup(instruction_2);
236 }
237 
238 
239 // Convenience bc_far versions
240 inline void MacroAssembler::blt_far(ConditionRegister crx, Label&amp; L, int optimize) { MacroAssembler::bc_far(bcondCRbiIs1, bi0(crx, less), L, optimize); }
241 inline void MacroAssembler::bgt_far(ConditionRegister crx, Label&amp; L, int optimize) { MacroAssembler::bc_far(bcondCRbiIs1, bi0(crx, greater), L, optimize); }
242 inline void MacroAssembler::beq_far(ConditionRegister crx, Label&amp; L, int optimize) { MacroAssembler::bc_far(bcondCRbiIs1, bi0(crx, equal), L, optimize); }
243 inline void MacroAssembler::bso_far(ConditionRegister crx, Label&amp; L, int optimize) { MacroAssembler::bc_far(bcondCRbiIs1, bi0(crx, summary_overflow), L, optimize); }
244 inline void MacroAssembler::bge_far(ConditionRegister crx, Label&amp; L, int optimize) { MacroAssembler::bc_far(bcondCRbiIs0, bi0(crx, less), L, optimize); }
245 inline void MacroAssembler::ble_far(ConditionRegister crx, Label&amp; L, int optimize) { MacroAssembler::bc_far(bcondCRbiIs0, bi0(crx, greater), L, optimize); }
246 inline void MacroAssembler::bne_far(ConditionRegister crx, Label&amp; L, int optimize) { MacroAssembler::bc_far(bcondCRbiIs0, bi0(crx, equal), L, optimize); }
247 inline void MacroAssembler::bns_far(ConditionRegister crx, Label&amp; L, int optimize) { MacroAssembler::bc_far(bcondCRbiIs0, bi0(crx, summary_overflow), L, optimize); }
248 
249 inline address MacroAssembler::call_stub(Register function_entry) {
250   mtctr(function_entry);
251   bctrl();
252   return pc();
253 }
254 
255 inline void MacroAssembler::call_stub_and_return_to(Register function_entry, Register return_pc) {
256   assert_different_registers(function_entry, return_pc);
257   mtlr(return_pc);
258   mtctr(function_entry);
259   bctr();
260 }
261 
262 // Get the pc where the last emitted call will return to.
263 inline address MacroAssembler::last_calls_return_pc() {
264   return _last_calls_return_pc;
265 }
266 
267 // Read from the polling page, its address is already in a register.
268 inline void MacroAssembler::load_from_polling_page(Register polling_page_address, int offset) {
269   if (SafepointMechanism::uses_thread_local_poll() &amp;&amp; USE_POLL_BIT_ONLY) {
270     int encoding = SafepointMechanism::poll_bit();
271     tdi(traptoGreaterThanUnsigned | traptoEqual, polling_page_address, encoding);
272   } else {
273     ld(R0, offset, polling_page_address);
274   }
275 }
276 
277 // Trap-instruction-based checks.
278 
279 inline void MacroAssembler::trap_null_check(Register a, trap_to_bits cmp) {
280   assert(TrapBasedNullChecks, &quot;sanity&quot;);
281   tdi(cmp, a/*reg a*/, 0);
282 }
283 inline void MacroAssembler::trap_zombie_not_entrant() {
284   tdi(traptoUnconditional, 0/*reg 0*/, 1);
285 }
286 inline void MacroAssembler::trap_should_not_reach_here() {
287   tdi_unchecked(traptoUnconditional, 0/*reg 0*/, 2);
288 }
289 
290 inline void MacroAssembler::trap_ic_miss_check(Register a, Register b) {
291   td(traptoGreaterThanUnsigned | traptoLessThanUnsigned, a, b);
292 }
293 
294 // Do an explicit null check if access to a+offset will not raise a SIGSEGV.
295 // Either issue a trap instruction that raises SIGTRAP, or do a compare that
296 // branches to exception_entry.
297 // No support for compressed oops (base page of heap). Does not distinguish
298 // loads and stores.
299 inline void MacroAssembler::null_check_throw(Register a, int offset, Register temp_reg,
300                                              address exception_entry) {
301   if (!ImplicitNullChecks || needs_explicit_null_check(offset) || !os::zero_page_read_protected()) {
302     if (TrapBasedNullChecks) {
303       assert(UseSIGTRAP, &quot;sanity&quot;);
304       trap_null_check(a);
305     } else {
306       Label ok;
307       cmpdi(CCR0, a, 0);
308       bne(CCR0, ok);
309       load_const_optimized(temp_reg, exception_entry);
310       mtctr(temp_reg);
311       bctr();
312       bind(ok);
313     }
314   }
315 }
316 
317 inline void MacroAssembler::null_check(Register a, int offset, Label *Lis_null) {
318   if (!ImplicitNullChecks || needs_explicit_null_check(offset) || !os::zero_page_read_protected()) {
319     if (TrapBasedNullChecks) {
320       assert(UseSIGTRAP, &quot;sanity&quot;);
321       trap_null_check(a);
322     } else if (Lis_null){
323       Label ok;
324       cmpdi(CCR0, a, 0);
325       beq(CCR0, *Lis_null);
326     }
327   }
328 }
329 
330 inline void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators,
331                                             Register base, RegisterOrConstant ind_or_offs, Register val,
332                                             Register tmp1, Register tmp2, Register tmp3, bool needs_frame) {
333   assert((decorators &amp; ~(AS_RAW | IN_HEAP | IN_NATIVE | IS_ARRAY | IS_NOT_NULL |
334                          ON_UNKNOWN_OOP_REF)) == 0, &quot;unsupported decorator&quot;);
335   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
336   bool as_raw = (decorators &amp; AS_RAW) != 0;
337   decorators = AccessInternal::decorator_fixup(decorators);
338   if (as_raw) {
339     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type,
340                                       base, ind_or_offs, val,
341                                       tmp1, tmp2, tmp3, needs_frame);
342   } else {
343     bs-&gt;store_at(this, decorators, type,
344                  base, ind_or_offs, val,
345                  tmp1, tmp2, tmp3, needs_frame);
346   }
347 }
348 
349 inline void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators,
350                                            Register base, RegisterOrConstant ind_or_offs, Register dst,
351                                            Register tmp1, Register tmp2, bool needs_frame, Label *L_handle_null) {
352   assert((decorators &amp; ~(AS_RAW | IN_HEAP | IN_NATIVE | IS_ARRAY | IS_NOT_NULL |
353                          ON_PHANTOM_OOP_REF | ON_WEAK_OOP_REF)) == 0, &quot;unsupported decorator&quot;);
354   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
355   decorators = AccessInternal::decorator_fixup(decorators);
356   bool as_raw = (decorators &amp; AS_RAW) != 0;
357   if (as_raw) {
358     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type,
359                                      base, ind_or_offs, dst,
360                                      tmp1, tmp2, needs_frame, L_handle_null);
361   } else {
362     bs-&gt;load_at(this, decorators, type,
363                 base, ind_or_offs, dst,
364                 tmp1, tmp2, needs_frame, L_handle_null);
365   }
366 }
367 
368 inline void MacroAssembler::load_heap_oop(Register d, RegisterOrConstant offs, Register s1,
369                                           Register tmp1, Register tmp2,
370                                           bool needs_frame, DecoratorSet decorators, Label *L_handle_null) {
371   access_load_at(T_OBJECT, IN_HEAP | decorators, s1, offs, d, tmp1, tmp2, needs_frame, L_handle_null);
372 }
373 
374 inline void MacroAssembler::store_heap_oop(Register d, RegisterOrConstant offs, Register s1,
375                                            Register tmp1, Register tmp2, Register tmp3,
376                                            bool needs_frame, DecoratorSet decorators) {
377   access_store_at(T_OBJECT, IN_HEAP | decorators, s1, offs, d, tmp1, tmp2, tmp3, needs_frame);
378 }
379 
380 inline Register MacroAssembler::encode_heap_oop_not_null(Register d, Register src) {
381   Register current = (src != noreg) ? src : d; // Oop to be compressed is in d if no src provided.
382   if (CompressedOops::base_overlaps()) {
383     sub_const_optimized(d, current, CompressedOops::base(), R0);
384     current = d;
385   }
386   if (CompressedOops::shift() != 0) {
387     rldicl(d, current, 64-CompressedOops::shift(), 32);  // Clears the upper bits.
388     current = d;
389   }
390   return current; // Encoded oop is in this register.
391 }
392 
393 inline Register MacroAssembler::encode_heap_oop(Register d, Register src) {
394   if (CompressedOops::base() != NULL) {
395     if (VM_Version::has_isel()) {
396       cmpdi(CCR0, src, 0);
397       Register co = encode_heap_oop_not_null(d, src);
398       assert(co == d, &quot;sanity&quot;);
399       isel_0(d, CCR0, Assembler::equal);
400     } else {
401       Label isNull;
402       or_(d, src, src); // move and compare 0
403       beq(CCR0, isNull);
404       encode_heap_oop_not_null(d, src);
405       bind(isNull);
406     }
407     return d;
408   } else {
409     return encode_heap_oop_not_null(d, src);
410   }
411 }
412 
413 inline Register MacroAssembler::decode_heap_oop_not_null(Register d, Register src) {
414   if (CompressedOops::base_disjoint() &amp;&amp; src != noreg &amp;&amp; src != d &amp;&amp;
415       CompressedOops::shift() != 0) {
416     load_const_optimized(d, CompressedOops::base(), R0);
417     rldimi(d, src, CompressedOops::shift(), 32-CompressedOops::shift());
418     return d;
419   }
420 
421   Register current = (src != noreg) ? src : d; // Compressed oop is in d if no src provided.
422   if (CompressedOops::shift() != 0) {
423     sldi(d, current, CompressedOops::shift());
424     current = d;
425   }
426   if (CompressedOops::base() != NULL) {
427     add_const_optimized(d, current, CompressedOops::base(), R0);
428     current = d;
429   }
430   return current; // Decoded oop is in this register.
431 }
432 
433 inline void MacroAssembler::decode_heap_oop(Register d) {
434   Label isNull;
435   bool use_isel = false;
436   if (CompressedOops::base() != NULL) {
437     cmpwi(CCR0, d, 0);
438     if (VM_Version::has_isel()) {
439       use_isel = true;
440     } else {
441       beq(CCR0, isNull);
442     }
443   }
444   decode_heap_oop_not_null(d);
445   if (use_isel) {
446     isel_0(d, CCR0, Assembler::equal);
447   }
448   bind(isNull);
449 }
450 
451 // SIGTRAP-based range checks for arrays.
452 inline void MacroAssembler::trap_range_check_l(Register a, Register b) {
453   tw (traptoLessThanUnsigned,                  a/*reg a*/, b/*reg b*/);
454 }
455 inline void MacroAssembler::trap_range_check_l(Register a, int si16) {
456   twi(traptoLessThanUnsigned,                  a/*reg a*/, si16);
457 }
458 inline void MacroAssembler::trap_range_check_le(Register a, int si16) {
459   twi(traptoEqual | traptoLessThanUnsigned,    a/*reg a*/, si16);
460 }
461 inline void MacroAssembler::trap_range_check_g(Register a, int si16) {
462   twi(traptoGreaterThanUnsigned,               a/*reg a*/, si16);
463 }
464 inline void MacroAssembler::trap_range_check_ge(Register a, Register b) {
465   tw (traptoEqual | traptoGreaterThanUnsigned, a/*reg a*/, b/*reg b*/);
466 }
467 inline void MacroAssembler::trap_range_check_ge(Register a, int si16) {
468   twi(traptoEqual | traptoGreaterThanUnsigned, a/*reg a*/, si16);
469 }
470 
471 // unsigned integer multiplication 64*64 -&gt; 128 bits
472 inline void MacroAssembler::multiply64(Register dest_hi, Register dest_lo,
473                                        Register x, Register y) {
474   mulld(dest_lo, x, y);
475   mulhdu(dest_hi, x, y);
476 }
477 
478 #if defined(ABI_ELFv2)
479 inline address MacroAssembler::function_entry() { return pc(); }
480 #else
481 inline address MacroAssembler::function_entry() { return emit_fd(); }
482 #endif
483 
484 #endif // CPU_PPC_MACROASSEMBLER_PPC_INLINE_HPP
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>