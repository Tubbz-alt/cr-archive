<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/frame_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_globals_aarch64.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="gc/shenandoah/c1/shenandoahBarrierSetC1_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/frame_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
</pre>
<hr />
<pre>
 42 #include &quot;vmreg_aarch64.inline.hpp&quot;
 43 #ifdef COMPILER1
 44 #include &quot;c1/c1_Runtime1.hpp&quot;
 45 #include &quot;runtime/vframeArray.hpp&quot;
 46 #endif
 47 
 48 #ifdef ASSERT
 49 void RegisterMap::check_location_valid() {
 50 }
 51 #endif
 52 
 53 
 54 // Profiling/safepoint support
 55 
 56 bool frame::safe_for_sender(JavaThread *thread) {
 57   address   sp = (address)_sp;
 58   address   fp = (address)_fp;
 59   address   unextended_sp = (address)_unextended_sp;
 60 
 61   // consider stack guards when trying to determine &quot;safe&quot; stack pointers
<span class="line-removed"> 62   static size_t stack_guard_size = os::uses_stack_guard_pages() ?</span>
<span class="line-removed"> 63     (JavaThread::stack_red_zone_size() + JavaThread::stack_yellow_zone_size()) : 0;</span>
<span class="line-removed"> 64   size_t usable_stack_size = thread-&gt;stack_size() - stack_guard_size;</span>
<span class="line-removed"> 65 </span>
 66   // sp must be within the usable part of the stack (not in guards)
<span class="line-modified"> 67   bool sp_safe = (sp &lt; thread-&gt;stack_base()) &amp;&amp;</span>
<span class="line-removed"> 68                  (sp &gt;= thread-&gt;stack_base() - usable_stack_size);</span>
<span class="line-removed"> 69 </span>
<span class="line-removed"> 70 </span>
<span class="line-removed"> 71   if (!sp_safe) {</span>
 72     return false;
 73   }
 74 
 75   // When we are running interpreted code the machine stack pointer, SP, is
 76   // set low enough so that the Java expression stack can grow and shrink
 77   // without ever exceeding the machine stack bounds.  So, ESP &gt;= SP.
 78 
 79   // When we call out of an interpreted method, SP is incremented so that
 80   // the space between SP and ESP is removed.  The SP saved in the callee&#39;s
 81   // frame is the SP *before* this increment.  So, when we walk a stack of
 82   // interpreter frames the sender&#39;s SP saved in a frame might be less than
 83   // the SP at the point of call.
 84 
 85   // So unextended sp must be within the stack but we need not to check
 86   // that unextended sp &gt;= sp
<span class="line-modified"> 87 </span>
<span class="line-removed"> 88   bool unextended_sp_safe = (unextended_sp &lt; thread-&gt;stack_base());</span>
<span class="line-removed"> 89 </span>
<span class="line-removed"> 90   if (!unextended_sp_safe) {</span>
 91     return false;
 92   }
 93 
 94   // an fp must be within the stack and above (but not equal) sp
 95   // second evaluation on fp+ is added to handle situation where fp is -1
<span class="line-modified"> 96   bool fp_safe = (fp &lt; thread-&gt;stack_base() &amp;&amp; (fp &gt; sp) &amp;&amp; (((fp + (return_addr_offset * sizeof(void*))) &lt; thread-&gt;stack_base())));</span>

 97 
 98   // We know sp/unextended_sp are safe only fp is questionable here
 99 
100   // If the current frame is known to the code cache then we can attempt to
101   // to construct the sender and do some validation of it. This goes a long way
102   // toward eliminating issues when we get in frame construction code
103 
104   if (_cb != NULL ) {
105 
106     // First check if frame is complete and tester is reliable
107     // Unfortunately we can only check frame complete for runtime stubs and nmethod
108     // other generic buffer blobs are more problematic so we just assume they are
109     // ok. adapter blobs never have a frame complete and are never ok.
110 
111     if (!_cb-&gt;is_frame_complete_at(_pc)) {
112       if (_cb-&gt;is_nmethod() || _cb-&gt;is_adapter_blob() || _cb-&gt;is_runtime_stub()) {
113         return false;
114       }
115     }
116 
</pre>
<hr />
<pre>
138 
139       sender_pc = (address) this-&gt;fp()[return_addr_offset];
140       // for interpreted frames, the value below is the sender &quot;raw&quot; sp,
141       // which can be different from the sender unextended sp (the sp seen
142       // by the sender) because of current frame local variables
143       sender_sp = (intptr_t*) addr_at(sender_sp_offset);
144       sender_unextended_sp = (intptr_t*) this-&gt;fp()[interpreter_frame_sender_sp_offset];
145       saved_fp = (intptr_t*) this-&gt;fp()[link_offset];
146 
147     } else {
148       // must be some sort of compiled/runtime frame
149       // fp does not have to be safe (although it could be check for c1?)
150 
151       // check for a valid frame_size, otherwise we are unlikely to get a valid sender_pc
152       if (_cb-&gt;frame_size() &lt;= 0) {
153         return false;
154       }
155 
156       sender_sp = _unextended_sp + _cb-&gt;frame_size();
157       // Is sender_sp safe?
<span class="line-modified">158       if ((address)sender_sp &gt;= thread-&gt;stack_base()) {</span>
159         return false;
160       }
161       sender_unextended_sp = sender_sp;
162       sender_pc = (address) *(sender_sp-1);
163       // Note: frame::sender_sp_offset is only valid for compiled frame
164       saved_fp = (intptr_t*) *(sender_sp - frame::sender_sp_offset);
165     }
166 
167 
168     // If the potential sender is the interpreter then we can do some more checking
169     if (Interpreter::contains(sender_pc)) {
170 
171       // fp is always saved in a recognizable place in any code we generate. However
172       // only if the sender is interpreted/call_stub (c1 too?) are we certain that the saved fp
173       // is really a frame pointer.
174 
<span class="line-modified">175       bool saved_fp_safe = ((address)saved_fp &lt; thread-&gt;stack_base()) &amp;&amp; (saved_fp &gt; sender_sp);</span>
<span class="line-removed">176 </span>
<span class="line-removed">177       if (!saved_fp_safe) {</span>
178         return false;
179       }
180 
181       // construct the potential sender
182 
183       frame sender(sender_sp, sender_unextended_sp, saved_fp, sender_pc);
184 
185       return sender.is_interpreted_frame_valid(thread);
186 
187     }
188 
189     // We must always be able to find a recognizable pc
190     CodeBlob* sender_blob = CodeCache::find_blob_unsafe(sender_pc);
191     if (sender_pc == NULL ||  sender_blob == NULL) {
192       return false;
193     }
194 
195     // Could be a zombie method
196     if (sender_blob-&gt;is_zombie() || sender_blob-&gt;is_unloaded()) {
197       return false;
198     }
199 
200     // Could just be some random pointer within the codeBlob
201     if (!sender_blob-&gt;code_contains(sender_pc)) {
202       return false;
203     }
204 
205     // We should never be able to see an adapter if the current frame is something from code cache
206     if (sender_blob-&gt;is_adapter_blob()) {
207       return false;
208     }
209 
210     // Could be the call_stub
211     if (StubRoutines::returns_to_call_stub(sender_pc)) {
<span class="line-modified">212       bool saved_fp_safe = ((address)saved_fp &lt; thread-&gt;stack_base()) &amp;&amp; (saved_fp &gt; sender_sp);</span>
<span class="line-removed">213 </span>
<span class="line-removed">214       if (!saved_fp_safe) {</span>
215         return false;
216       }
217 
218       // construct the potential sender
219 
220       frame sender(sender_sp, sender_unextended_sp, saved_fp, sender_pc);
221 
222       // Validate the JavaCallWrapper an entry frame must have
223       address jcw = (address)sender.entry_frame_call_wrapper();
224 
<span class="line-modified">225       bool jcw_safe = (jcw &lt; thread-&gt;stack_base()) &amp;&amp; (jcw &gt; (address)sender.fp());</span>
<span class="line-removed">226 </span>
<span class="line-removed">227       return jcw_safe;</span>
228     }
229 
230     CompiledMethod* nm = sender_blob-&gt;as_compiled_method_or_null();
231     if (nm != NULL) {
232       if (nm-&gt;is_deopt_mh_entry(sender_pc) || nm-&gt;is_deopt_entry(sender_pc) ||
233           nm-&gt;method()-&gt;is_method_handle_intrinsic()) {
234         return false;
235       }
236     }
237 
238     // If the frame size is 0 something (or less) is bad because every nmethod has a non-zero frame size
239     // because the return address counts against the callee&#39;s frame.
240 
241     if (sender_blob-&gt;frame_size() &lt;= 0) {
242       assert(!sender_blob-&gt;is_compiled(), &quot;should count return address at least&quot;);
243       return false;
244     }
245 
246     // We should never be able to see anything here except an nmethod. If something in the
247     // code cache (current frame) is called by an entity within the code cache that entity
</pre>
<hr />
<pre>
548   // further because of local variables of the callee method inserted after
549   // method arguments
550   if (fp() - unextended_sp() &gt; 1024 + m-&gt;max_stack()*Interpreter::stackElementSize) {
551     return false;
552   }
553 
554   // validate bci/bcx
555 
556   address  bcp    = interpreter_frame_bcp();
557   if (m-&gt;validate_bci_from_bcp(bcp) &lt; 0) {
558     return false;
559   }
560 
561   // validate constantPoolCache*
562   ConstantPoolCache* cp = *interpreter_frame_cache_addr();
563   if (MetaspaceObj::is_valid(cp) == false) return false;
564 
565   // validate locals
566 
567   address locals =  (address) *interpreter_frame_locals_addr();
<span class="line-modified">568 </span>
<span class="line-removed">569   if (locals &gt; thread-&gt;stack_base() || locals &lt; (address) fp()) return false;</span>
<span class="line-removed">570 </span>
<span class="line-removed">571   // We&#39;d have to be pretty unlucky to be mislead at this point</span>
<span class="line-removed">572   return true;</span>
573 }
574 
575 BasicType frame::interpreter_frame_result(oop* oop_result, jvalue* value_result) {
576   assert(is_interpreted_frame(), &quot;interpreted frame expected&quot;);
577   Method* method = interpreter_frame_method();
578   BasicType type = method-&gt;result_type();
579 
580   intptr_t* tos_addr;
581   if (method-&gt;is_native()) {
582     // TODO : ensure AARCH64 does the same as Intel here i.e. push v0 then r0
583     // Prior to calling into the runtime to report the method_exit the possible
584     // return value is pushed to the native stack. If the result is a jfloat/jdouble
585     // then ST0 is saved before EAX/EDX. See the note in generate_native_result
586     tos_addr = (intptr_t*)sp();
587     if (type == T_FLOAT || type == T_DOUBLE) {
588       // This is times two because we do a push(ltos) after pushing XMM0
589       // and that takes two interpreter stack slots.
590       tos_addr += 2 * Interpreter::stackElementWords;
591     }
592   } else {
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
</pre>
<hr />
<pre>
 42 #include &quot;vmreg_aarch64.inline.hpp&quot;
 43 #ifdef COMPILER1
 44 #include &quot;c1/c1_Runtime1.hpp&quot;
 45 #include &quot;runtime/vframeArray.hpp&quot;
 46 #endif
 47 
 48 #ifdef ASSERT
 49 void RegisterMap::check_location_valid() {
 50 }
 51 #endif
 52 
 53 
 54 // Profiling/safepoint support
 55 
 56 bool frame::safe_for_sender(JavaThread *thread) {
 57   address   sp = (address)_sp;
 58   address   fp = (address)_fp;
 59   address   unextended_sp = (address)_unextended_sp;
 60 
 61   // consider stack guards when trying to determine &quot;safe&quot; stack pointers




 62   // sp must be within the usable part of the stack (not in guards)
<span class="line-modified"> 63   if (!thread-&gt;is_in_usable_stack(sp)) {</span>




 64     return false;
 65   }
 66 
 67   // When we are running interpreted code the machine stack pointer, SP, is
 68   // set low enough so that the Java expression stack can grow and shrink
 69   // without ever exceeding the machine stack bounds.  So, ESP &gt;= SP.
 70 
 71   // When we call out of an interpreted method, SP is incremented so that
 72   // the space between SP and ESP is removed.  The SP saved in the callee&#39;s
 73   // frame is the SP *before* this increment.  So, when we walk a stack of
 74   // interpreter frames the sender&#39;s SP saved in a frame might be less than
 75   // the SP at the point of call.
 76 
 77   // So unextended sp must be within the stack but we need not to check
 78   // that unextended sp &gt;= sp
<span class="line-modified"> 79   if (!thread-&gt;is_in_full_stack(unextended_sp)) {</span>



 80     return false;
 81   }
 82 
 83   // an fp must be within the stack and above (but not equal) sp
 84   // second evaluation on fp+ is added to handle situation where fp is -1
<span class="line-modified"> 85   bool fp_safe = thread-&gt;is_in_stack_range_excl(fp, sp) &amp;&amp;</span>
<span class="line-added"> 86                  thread-&gt;is_in_full_stack(fp + (return_addr_offset * sizeof(void*)));</span>
 87 
 88   // We know sp/unextended_sp are safe only fp is questionable here
 89 
 90   // If the current frame is known to the code cache then we can attempt to
 91   // to construct the sender and do some validation of it. This goes a long way
 92   // toward eliminating issues when we get in frame construction code
 93 
 94   if (_cb != NULL ) {
 95 
 96     // First check if frame is complete and tester is reliable
 97     // Unfortunately we can only check frame complete for runtime stubs and nmethod
 98     // other generic buffer blobs are more problematic so we just assume they are
 99     // ok. adapter blobs never have a frame complete and are never ok.
100 
101     if (!_cb-&gt;is_frame_complete_at(_pc)) {
102       if (_cb-&gt;is_nmethod() || _cb-&gt;is_adapter_blob() || _cb-&gt;is_runtime_stub()) {
103         return false;
104       }
105     }
106 
</pre>
<hr />
<pre>
128 
129       sender_pc = (address) this-&gt;fp()[return_addr_offset];
130       // for interpreted frames, the value below is the sender &quot;raw&quot; sp,
131       // which can be different from the sender unextended sp (the sp seen
132       // by the sender) because of current frame local variables
133       sender_sp = (intptr_t*) addr_at(sender_sp_offset);
134       sender_unextended_sp = (intptr_t*) this-&gt;fp()[interpreter_frame_sender_sp_offset];
135       saved_fp = (intptr_t*) this-&gt;fp()[link_offset];
136 
137     } else {
138       // must be some sort of compiled/runtime frame
139       // fp does not have to be safe (although it could be check for c1?)
140 
141       // check for a valid frame_size, otherwise we are unlikely to get a valid sender_pc
142       if (_cb-&gt;frame_size() &lt;= 0) {
143         return false;
144       }
145 
146       sender_sp = _unextended_sp + _cb-&gt;frame_size();
147       // Is sender_sp safe?
<span class="line-modified">148       if (!thread-&gt;is_in_full_stack((address)sender_sp)) {</span>
149         return false;
150       }
151       sender_unextended_sp = sender_sp;
152       sender_pc = (address) *(sender_sp-1);
153       // Note: frame::sender_sp_offset is only valid for compiled frame
154       saved_fp = (intptr_t*) *(sender_sp - frame::sender_sp_offset);
155     }
156 
157 
158     // If the potential sender is the interpreter then we can do some more checking
159     if (Interpreter::contains(sender_pc)) {
160 
161       // fp is always saved in a recognizable place in any code we generate. However
162       // only if the sender is interpreted/call_stub (c1 too?) are we certain that the saved fp
163       // is really a frame pointer.
164 
<span class="line-modified">165       if (!thread-&gt;is_in_stack_range_excl((address)saved_fp, (address)sender_sp)) {</span>


166         return false;
167       }
168 
169       // construct the potential sender
170 
171       frame sender(sender_sp, sender_unextended_sp, saved_fp, sender_pc);
172 
173       return sender.is_interpreted_frame_valid(thread);
174 
175     }
176 
177     // We must always be able to find a recognizable pc
178     CodeBlob* sender_blob = CodeCache::find_blob_unsafe(sender_pc);
179     if (sender_pc == NULL ||  sender_blob == NULL) {
180       return false;
181     }
182 
183     // Could be a zombie method
184     if (sender_blob-&gt;is_zombie() || sender_blob-&gt;is_unloaded()) {
185       return false;
186     }
187 
188     // Could just be some random pointer within the codeBlob
189     if (!sender_blob-&gt;code_contains(sender_pc)) {
190       return false;
191     }
192 
193     // We should never be able to see an adapter if the current frame is something from code cache
194     if (sender_blob-&gt;is_adapter_blob()) {
195       return false;
196     }
197 
198     // Could be the call_stub
199     if (StubRoutines::returns_to_call_stub(sender_pc)) {
<span class="line-modified">200       if (!thread-&gt;is_in_stack_range_excl((address)saved_fp, (address)sender_sp)) {</span>


201         return false;
202       }
203 
204       // construct the potential sender
205 
206       frame sender(sender_sp, sender_unextended_sp, saved_fp, sender_pc);
207 
208       // Validate the JavaCallWrapper an entry frame must have
209       address jcw = (address)sender.entry_frame_call_wrapper();
210 
<span class="line-modified">211       return thread-&gt;is_in_stack_range_excl(jcw, (address)sender.fp());</span>


212     }
213 
214     CompiledMethod* nm = sender_blob-&gt;as_compiled_method_or_null();
215     if (nm != NULL) {
216       if (nm-&gt;is_deopt_mh_entry(sender_pc) || nm-&gt;is_deopt_entry(sender_pc) ||
217           nm-&gt;method()-&gt;is_method_handle_intrinsic()) {
218         return false;
219       }
220     }
221 
222     // If the frame size is 0 something (or less) is bad because every nmethod has a non-zero frame size
223     // because the return address counts against the callee&#39;s frame.
224 
225     if (sender_blob-&gt;frame_size() &lt;= 0) {
226       assert(!sender_blob-&gt;is_compiled(), &quot;should count return address at least&quot;);
227       return false;
228     }
229 
230     // We should never be able to see anything here except an nmethod. If something in the
231     // code cache (current frame) is called by an entity within the code cache that entity
</pre>
<hr />
<pre>
532   // further because of local variables of the callee method inserted after
533   // method arguments
534   if (fp() - unextended_sp() &gt; 1024 + m-&gt;max_stack()*Interpreter::stackElementSize) {
535     return false;
536   }
537 
538   // validate bci/bcx
539 
540   address  bcp    = interpreter_frame_bcp();
541   if (m-&gt;validate_bci_from_bcp(bcp) &lt; 0) {
542     return false;
543   }
544 
545   // validate constantPoolCache*
546   ConstantPoolCache* cp = *interpreter_frame_cache_addr();
547   if (MetaspaceObj::is_valid(cp) == false) return false;
548 
549   // validate locals
550 
551   address locals =  (address) *interpreter_frame_locals_addr();
<span class="line-modified">552   return thread-&gt;is_in_stack_range_incl(locals, (address)fp());</span>




553 }
554 
555 BasicType frame::interpreter_frame_result(oop* oop_result, jvalue* value_result) {
556   assert(is_interpreted_frame(), &quot;interpreted frame expected&quot;);
557   Method* method = interpreter_frame_method();
558   BasicType type = method-&gt;result_type();
559 
560   intptr_t* tos_addr;
561   if (method-&gt;is_native()) {
562     // TODO : ensure AARCH64 does the same as Intel here i.e. push v0 then r0
563     // Prior to calling into the runtime to report the method_exit the possible
564     // return value is pushed to the native stack. If the result is a jfloat/jdouble
565     // then ST0 is saved before EAX/EDX. See the note in generate_native_result
566     tos_addr = (intptr_t*)sp();
567     if (type == T_FLOAT || type == T_DOUBLE) {
568       // This is times two because we do a push(ltos) after pushing XMM0
569       // and that takes two interpreter stack slots.
570       tos_addr += 2 * Interpreter::stackElementWords;
571     }
572   } else {
</pre>
</td>
</tr>
</table>
<center><a href="c1_globals_aarch64.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="gc/shenandoah/c1/shenandoahBarrierSetC1_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>