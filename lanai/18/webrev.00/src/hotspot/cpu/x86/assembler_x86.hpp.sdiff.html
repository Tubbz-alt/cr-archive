<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/assembler_x86.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="assembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Defs_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/assembler_x86.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #ifndef CPU_X86_ASSEMBLER_X86_HPP
  26 #define CPU_X86_ASSEMBLER_X86_HPP
  27 
  28 #include &quot;asm/register.hpp&quot;
  29 #include &quot;runtime/vm_version.hpp&quot;

  30 
  31 class BiasedLockingCounters;
  32 
  33 // Contains all the definitions needed for x86 assembly code generation.
  34 
  35 // Calling convention
  36 class Argument {
  37  public:
  38   enum {
  39 #ifdef _LP64
  40 #ifdef _WIN64
  41     n_int_register_parameters_c   = 4, // rcx, rdx, r8, r9 (c_rarg0, c_rarg1, ...)
  42     n_float_register_parameters_c = 4,  // xmm0 - xmm3 (c_farg0, c_farg1, ... )
  43 #else
  44     n_int_register_parameters_c   = 6, // rdi, rsi, rdx, rcx, r8, r9 (c_rarg0, c_rarg1, ...)
  45     n_float_register_parameters_c = 8,  // xmm0 - xmm7 (c_farg0, c_farg1, ... )
  46 #endif // _WIN64
  47     n_int_register_parameters_j   = 6, // j_rarg0, j_rarg1, ...
  48     n_float_register_parameters_j = 8  // j_farg0, j_farg1, ...
  49 #else
</pre>
<hr />
<pre>
 321 #endif // ASSERT
 322 
 323   // accessors
 324   bool        uses(Register reg) const { return _base == reg || _index == reg; }
 325   Register    base()             const { return _base;  }
 326   Register    index()            const { return _index; }
 327   XMMRegister xmmindex()         const { return _xmmindex; }
 328   ScaleFactor scale()            const { return _scale; }
 329   int         disp()             const { return _disp;  }
 330   bool        isxmmindex()       const { return _isxmmindex; }
 331 
 332   // Convert the raw encoding form into the form expected by the constructor for
 333   // Address.  An index of 4 (rsp) corresponds to having no index, so convert
 334   // that to noreg for the Address constructor.
 335   static Address make_raw(int base, int index, int scale, int disp, relocInfo::relocType disp_reloc);
 336 
 337   static Address make_array(ArrayAddress);
 338 
 339  private:
 340   bool base_needs_rex() const {
<span class="line-modified"> 341     return _base != noreg &amp;&amp; _base-&gt;encoding() &gt;= 8;</span>
 342   }
 343 
 344   bool index_needs_rex() const {
<span class="line-modified"> 345     return _index != noreg &amp;&amp;_index-&gt;encoding() &gt;= 8;</span>
 346   }
 347 
 348   bool xmmindex_needs_rex() const {
<span class="line-modified"> 349     return _xmmindex != xnoreg &amp;&amp; _xmmindex-&gt;encoding() &gt;= 8;</span>
 350   }
 351 
 352   relocInfo::relocType reloc() const { return _rspec.type(); }
 353 
 354   friend class Assembler;
 355   friend class MacroAssembler;
 356   friend class LIR_Assembler; // base/index/scale/disp
 357 };
 358 
 359 //
 360 // AddressLiteral has been split out from Address because operands of this type
 361 // need to be treated specially on 32bit vs. 64bit platforms. By splitting it out
 362 // the few instructions that need to deal with address literals are unique and the
 363 // MacroAssembler does not have to implement every instruction in the Assembler
 364 // in order to search for address literals that may need special handling depending
 365 // on the instruction and the platform. As small step on the way to merging i486/amd64
 366 // directories.
 367 //
 368 class AddressLiteral {
 369   friend class ArrayAddress;
</pre>
<hr />
<pre>
 641   // We could use a &quot;safe enough&quot; estimate (15), but just default to
 642   // instruction length guess from above.
 643   static unsigned int instr_maxlen() { return 4; }
 644 
 645   // NOTE: The general philopsophy of the declarations here is that 64bit versions
 646   // of instructions are freely declared without the need for wrapping them an ifdef.
 647   // (Some dangerous instructions are ifdef&#39;s out of inappropriate jvm&#39;s.)
 648   // In the .cpp file the implementations are wrapped so that they are dropped out
 649   // of the resulting jvm. This is done mostly to keep the footprint of MINIMAL
 650   // to the size it was prior to merging up the 32bit and 64bit assemblers.
 651   //
 652   // This does mean you&#39;ll get a linker/runtime error if you use a 64bit only instruction
 653   // in a 32bit vm. This is somewhat unfortunate but keeps the ifdef noise down.
 654 
 655 private:
 656 
 657   bool _legacy_mode_bw;
 658   bool _legacy_mode_dq;
 659   bool _legacy_mode_vl;
 660   bool _legacy_mode_vlbw;
<span class="line-modified"> 661   bool _is_managed;</span>
<span class="line-removed"> 662   bool _vector_masking;    // For stub code use only</span>
 663 
 664   class InstructionAttr *_attributes;
 665 
 666   // 64bit prefixes
<span class="line-modified"> 667   int prefix_and_encode(int reg_enc, bool byteinst = false);</span>
<span class="line-modified"> 668   int prefixq_and_encode(int reg_enc);</span>





 669 

 670   int prefix_and_encode(int dst_enc, int src_enc) {
 671     return prefix_and_encode(dst_enc, false, src_enc, false);
 672   }
 673   int prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte);
<span class="line-removed"> 674   int prefixq_and_encode(int dst_enc, int src_enc);</span>
 675 
<span class="line-modified"> 676   void prefix(Register reg);</span>
<span class="line-modified"> 677   void prefix(Register dst, Register src, Prefix p);</span>
<span class="line-modified"> 678   void prefix(Register dst, Address adr, Prefix p);</span>
<span class="line-modified"> 679   void prefix(Address adr);</span>
<span class="line-modified"> 680   void prefixq(Address adr);</span>
 681 
<span class="line-modified"> 682   void prefix(Address adr, Register reg,  bool byteinst = false);</span>
<span class="line-removed"> 683   void prefix(Address adr, XMMRegister reg);</span>
 684   void prefixq(Address adr, Register reg);
 685   void prefixq(Address adr, XMMRegister reg);
 686 
<span class="line-modified"> 687   void prefetch_prefix(Address src);</span>

 688 
 689   void rex_prefix(Address adr, XMMRegister xreg,
 690                   VexSimdPrefix pre, VexOpcode opc, bool rex_w);
 691   int  rex_prefix_and_encode(int dst_enc, int src_enc,
 692                              VexSimdPrefix pre, VexOpcode opc, bool rex_w);
 693 
 694   void vex_prefix(bool vex_r, bool vex_b, bool vex_x, int nds_enc, VexSimdPrefix pre, VexOpcode opc);
 695 
 696   void evex_prefix(bool vex_r, bool vex_b, bool vex_x, bool evex_r, bool evex_v,
 697                    int nds_enc, VexSimdPrefix pre, VexOpcode opc);
 698 
 699   void vex_prefix(Address adr, int nds_enc, int xreg_enc,
 700                   VexSimdPrefix pre, VexOpcode opc,
 701                   InstructionAttr *attributes);
 702 
 703   int  vex_prefix_and_encode(int dst_enc, int nds_enc, int src_enc,
 704                              VexSimdPrefix pre, VexOpcode opc,
 705                              InstructionAttr *attributes);
 706 
 707   void simd_prefix(XMMRegister xreg, XMMRegister nds, Address adr, VexSimdPrefix pre,
</pre>
<hr />
<pre>
 853   }
 854 
 855   // Decoding
 856   static address locate_operand(address inst, WhichOperand which);
 857   static address locate_next_instruction(address inst);
 858 
 859   // Utilities
 860   static bool is_polling_page_far() NOT_LP64({ return false;});
 861   static bool query_compressed_disp_byte(int disp, bool is_evex_inst, int vector_len,
 862                                          int cur_tuple_type, int in_size_in_bits, int cur_encoding);
 863 
 864   // Generic instructions
 865   // Does 32bit or 64bit as needed for the platform. In some sense these
 866   // belong in macro assembler but there is no need for both varieties to exist
 867 
 868   void init_attributes(void) {
 869     _legacy_mode_bw = (VM_Version::supports_avx512bw() == false);
 870     _legacy_mode_dq = (VM_Version::supports_avx512dq() == false);
 871     _legacy_mode_vl = (VM_Version::supports_avx512vl() == false);
 872     _legacy_mode_vlbw = (VM_Version::supports_avx512vlbw() == false);
<span class="line-modified"> 873     _is_managed = false;</span>
<span class="line-removed"> 874     _vector_masking = false;</span>
 875     _attributes = NULL;
 876   }
 877 
 878   void set_attributes(InstructionAttr *attributes) { _attributes = attributes; }
 879   void clear_attributes(void) { _attributes = NULL; }
 880 
<span class="line-modified"> 881   void set_managed(void) { _is_managed = true; }</span>
<span class="line-modified"> 882   void clear_managed(void) { _is_managed = false; }</span>
<span class="line-modified"> 883   bool is_managed(void) { return _is_managed; }</span>


 884 
 885   void lea(Register dst, Address src);
 886 
 887   void mov(Register dst, Register src);
 888 











 889   void pusha();
 890   void popa();
 891 
 892   void pushf();
 893   void popf();
 894 
 895   void push(int32_t imm32);
 896 
 897   void push(Register src);
 898 
 899   void pop(Register dst);
 900 
 901   // These are dummies to prevent surprise implicit conversions to Register
 902   void push(void* v);
 903   void pop(void* v);
 904 
 905   // These do register sized moves/scans
 906   void rep_mov();
 907   void rep_stos();
 908   void rep_stosb();
</pre>
<hr />
<pre>
2200   void vextractf32x4(XMMRegister dst, XMMRegister src, uint8_t imm8);
2201   void vextractf32x4(Address dst, XMMRegister src, uint8_t imm8);
2202   void vextractf64x2(XMMRegister dst, XMMRegister src, uint8_t imm8);
2203   void vextractf64x4(XMMRegister dst, XMMRegister src, uint8_t imm8);
2204   void vextractf64x4(Address dst, XMMRegister src, uint8_t imm8);
2205 
2206   // xmm/mem sourced byte/word/dword/qword replicate
2207   void vpbroadcastb(XMMRegister dst, XMMRegister src, int vector_len);
2208   void vpbroadcastb(XMMRegister dst, Address src, int vector_len);
2209   void vpbroadcastw(XMMRegister dst, XMMRegister src, int vector_len);
2210   void vpbroadcastw(XMMRegister dst, Address src, int vector_len);
2211   void vpbroadcastd(XMMRegister dst, XMMRegister src, int vector_len);
2212   void vpbroadcastd(XMMRegister dst, Address src, int vector_len);
2213   void vpbroadcastq(XMMRegister dst, XMMRegister src, int vector_len);
2214   void vpbroadcastq(XMMRegister dst, Address src, int vector_len);
2215 
2216   void evbroadcasti64x2(XMMRegister dst, XMMRegister src, int vector_len);
2217   void evbroadcasti64x2(XMMRegister dst, Address src, int vector_len);
2218 
2219   // scalar single/double precision replicate
<span class="line-modified">2220   void vpbroadcastss(XMMRegister dst, XMMRegister src, int vector_len);</span>
<span class="line-modified">2221   void vpbroadcastss(XMMRegister dst, Address src, int vector_len);</span>
<span class="line-modified">2222   void vpbroadcastsd(XMMRegister dst, XMMRegister src, int vector_len);</span>
<span class="line-modified">2223   void vpbroadcastsd(XMMRegister dst, Address src, int vector_len);</span>
2224 
2225   // gpr sourced byte/word/dword/qword replicate
2226   void evpbroadcastb(XMMRegister dst, Register src, int vector_len);
2227   void evpbroadcastw(XMMRegister dst, Register src, int vector_len);
2228   void evpbroadcastd(XMMRegister dst, Register src, int vector_len);
2229   void evpbroadcastq(XMMRegister dst, Register src, int vector_len);
2230 
2231   void evpgatherdd(XMMRegister dst, KRegister k1, Address src, int vector_len);
2232 
2233   // Carry-Less Multiplication Quadword
2234   void pclmulqdq(XMMRegister dst, XMMRegister src, int mask);
2235   void vpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask);
2236   void evpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask, int vector_len);
2237   // AVX instruction which is used to clear upper 128 bits of YMM registers and
2238   // to avoid transaction penalty between AVX and SSE states. There is no
2239   // penalty if legacy SSE instructions are encoded using VEX prefix because
2240   // they always clear upper 128 bits. It should be used before calling
2241   // runtime code and native libraries.
2242   void vzeroupper();
2243 
</pre>
<hr />
<pre>
2253   // They should be called only from corresponding MacroAssembler instructions.
2254   void andpd(XMMRegister dst, Address src);
2255   void andps(XMMRegister dst, Address src);
2256   void xorpd(XMMRegister dst, Address src);
2257   void xorps(XMMRegister dst, Address src);
2258 
2259 };
2260 
2261 // The Intel x86/Amd64 Assembler attributes: All fields enclosed here are to guide encoding level decisions.
2262 // Specific set functions are for specialized use, else defaults or whatever was supplied to object construction
2263 // are applied.
2264 class InstructionAttr {
2265 public:
2266   InstructionAttr(
2267     int vector_len,     // The length of vector to be applied in encoding - for both AVX and EVEX
2268     bool rex_vex_w,     // Width of data: if 32-bits or less, false, else if 64-bit or specially defined, true
2269     bool legacy_mode,   // Details if either this instruction is conditionally encoded to AVX or earlier if true else possibly EVEX
2270     bool no_reg_mask,   // when true, k0 is used when EVEX encoding is chosen, else embedded_opmask_register_specifier is used
2271     bool uses_vl)       // This instruction may have legacy constraints based on vector length for EVEX
2272     :
<span class="line-removed">2273       _avx_vector_len(vector_len),</span>
2274       _rex_vex_w(rex_vex_w),
<span class="line-modified">2275       _rex_vex_w_reverted(false),</span>
<span class="line-removed">2276       _legacy_mode(legacy_mode),</span>
2277       _no_reg_mask(no_reg_mask),
2278       _uses_vl(uses_vl),
<span class="line-modified">2279       _tuple_type(Assembler::EVEX_ETUP),</span>
<span class="line-removed">2280       _input_size_in_bits(Assembler::EVEX_NObit),</span>
2281       _is_evex_instruction(false),
<span class="line-removed">2282       _evex_encoding(0),</span>
2283       _is_clear_context(true),
2284       _is_extended_context(false),




2285       _embedded_opmask_register_specifier(0), // hard code k0
<span class="line-modified">2286       _current_assembler(NULL) {</span>
<span class="line-removed">2287     if (UseAVX &lt; 3) _legacy_mode = true;</span>
<span class="line-removed">2288   }</span>
2289 
2290   ~InstructionAttr() {
2291     if (_current_assembler != NULL) {
2292       _current_assembler-&gt;clear_attributes();
2293     }
2294     _current_assembler = NULL;
2295   }
2296 
2297 private:
<span class="line-removed">2298   int  _avx_vector_len;</span>
2299   bool _rex_vex_w;
<span class="line-removed">2300   bool _rex_vex_w_reverted;</span>
2301   bool _legacy_mode;
2302   bool _no_reg_mask;
2303   bool _uses_vl;
<span class="line-modified">2304   int  _tuple_type;</span>
<span class="line-removed">2305   int  _input_size_in_bits;</span>
2306   bool _is_evex_instruction;
<span class="line-removed">2307   int  _evex_encoding;</span>
2308   bool _is_clear_context;
2309   bool _is_extended_context;




2310   int _embedded_opmask_register_specifier;
2311 
2312   Assembler *_current_assembler;
2313 
2314 public:
2315   // query functions for field accessors
<span class="line-removed">2316   int  get_vector_len(void) const { return _avx_vector_len; }</span>
2317   bool is_rex_vex_w(void) const { return _rex_vex_w; }
<span class="line-removed">2318   bool is_rex_vex_w_reverted(void) { return _rex_vex_w_reverted; }</span>
2319   bool is_legacy_mode(void) const { return _legacy_mode; }
2320   bool is_no_reg_mask(void) const { return _no_reg_mask; }
2321   bool uses_vl(void) const { return _uses_vl; }





2322   int  get_tuple_type(void) const { return _tuple_type; }
2323   int  get_input_size(void) const { return _input_size_in_bits; }
<span class="line-removed">2324   int  is_evex_instruction(void) const { return _is_evex_instruction; }</span>
2325   int  get_evex_encoding(void) const { return _evex_encoding; }
<span class="line-modified">2326   bool is_clear_context(void) const { return _is_clear_context; }</span>
<span class="line-removed">2327   bool is_extended_context(void) const { return _is_extended_context; }</span>
<span class="line-removed">2328   int get_embedded_opmask_register_specifier(void) const { return _embedded_opmask_register_specifier; }</span>
2329 
2330   // Set the vector len manually
2331   void set_vector_len(int vector_len) { _avx_vector_len = vector_len; }
2332 
2333   // Set revert rex_vex_w for avx encoding
2334   void set_rex_vex_w_reverted(void) { _rex_vex_w_reverted = true; }
2335 
2336   // Set rex_vex_w based on state
2337   void set_rex_vex_w(bool state) { _rex_vex_w = state; }
2338 
2339   // Set the instruction to be encoded in AVX mode
2340   void set_is_legacy_mode(void) { _legacy_mode = true; }
2341 
2342   // Set the current instuction to be encoded as an EVEX instuction
2343   void set_is_evex_instruction(void) { _is_evex_instruction = true; }
2344 
2345   // Internal encoding data used in compressed immediate offset programming
2346   void set_evex_encoding(int value) { _evex_encoding = value; }
2347 
2348   // Set the Evex.Z field to be used to clear all non directed XMM/YMM/ZMM components
</pre>
</td>
<td>
<hr />
<pre>
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #ifndef CPU_X86_ASSEMBLER_X86_HPP
  26 #define CPU_X86_ASSEMBLER_X86_HPP
  27 
  28 #include &quot;asm/register.hpp&quot;
  29 #include &quot;runtime/vm_version.hpp&quot;
<span class="line-added">  30 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  31 
  32 class BiasedLockingCounters;
  33 
  34 // Contains all the definitions needed for x86 assembly code generation.
  35 
  36 // Calling convention
  37 class Argument {
  38  public:
  39   enum {
  40 #ifdef _LP64
  41 #ifdef _WIN64
  42     n_int_register_parameters_c   = 4, // rcx, rdx, r8, r9 (c_rarg0, c_rarg1, ...)
  43     n_float_register_parameters_c = 4,  // xmm0 - xmm3 (c_farg0, c_farg1, ... )
  44 #else
  45     n_int_register_parameters_c   = 6, // rdi, rsi, rdx, rcx, r8, r9 (c_rarg0, c_rarg1, ...)
  46     n_float_register_parameters_c = 8,  // xmm0 - xmm7 (c_farg0, c_farg1, ... )
  47 #endif // _WIN64
  48     n_int_register_parameters_j   = 6, // j_rarg0, j_rarg1, ...
  49     n_float_register_parameters_j = 8  // j_farg0, j_farg1, ...
  50 #else
</pre>
<hr />
<pre>
 322 #endif // ASSERT
 323 
 324   // accessors
 325   bool        uses(Register reg) const { return _base == reg || _index == reg; }
 326   Register    base()             const { return _base;  }
 327   Register    index()            const { return _index; }
 328   XMMRegister xmmindex()         const { return _xmmindex; }
 329   ScaleFactor scale()            const { return _scale; }
 330   int         disp()             const { return _disp;  }
 331   bool        isxmmindex()       const { return _isxmmindex; }
 332 
 333   // Convert the raw encoding form into the form expected by the constructor for
 334   // Address.  An index of 4 (rsp) corresponds to having no index, so convert
 335   // that to noreg for the Address constructor.
 336   static Address make_raw(int base, int index, int scale, int disp, relocInfo::relocType disp_reloc);
 337 
 338   static Address make_array(ArrayAddress);
 339 
 340  private:
 341   bool base_needs_rex() const {
<span class="line-modified"> 342     return _base-&gt;is_valid() &amp;&amp; _base-&gt;encoding() &gt;= 8;</span>
 343   }
 344 
 345   bool index_needs_rex() const {
<span class="line-modified"> 346     return _index-&gt;is_valid() &amp;&amp;_index-&gt;encoding() &gt;= 8;</span>
 347   }
 348 
 349   bool xmmindex_needs_rex() const {
<span class="line-modified"> 350     return _xmmindex-&gt;is_valid() &amp;&amp; _xmmindex-&gt;encoding() &gt;= 8;</span>
 351   }
 352 
 353   relocInfo::relocType reloc() const { return _rspec.type(); }
 354 
 355   friend class Assembler;
 356   friend class MacroAssembler;
 357   friend class LIR_Assembler; // base/index/scale/disp
 358 };
 359 
 360 //
 361 // AddressLiteral has been split out from Address because operands of this type
 362 // need to be treated specially on 32bit vs. 64bit platforms. By splitting it out
 363 // the few instructions that need to deal with address literals are unique and the
 364 // MacroAssembler does not have to implement every instruction in the Assembler
 365 // in order to search for address literals that may need special handling depending
 366 // on the instruction and the platform. As small step on the way to merging i486/amd64
 367 // directories.
 368 //
 369 class AddressLiteral {
 370   friend class ArrayAddress;
</pre>
<hr />
<pre>
 642   // We could use a &quot;safe enough&quot; estimate (15), but just default to
 643   // instruction length guess from above.
 644   static unsigned int instr_maxlen() { return 4; }
 645 
 646   // NOTE: The general philopsophy of the declarations here is that 64bit versions
 647   // of instructions are freely declared without the need for wrapping them an ifdef.
 648   // (Some dangerous instructions are ifdef&#39;s out of inappropriate jvm&#39;s.)
 649   // In the .cpp file the implementations are wrapped so that they are dropped out
 650   // of the resulting jvm. This is done mostly to keep the footprint of MINIMAL
 651   // to the size it was prior to merging up the 32bit and 64bit assemblers.
 652   //
 653   // This does mean you&#39;ll get a linker/runtime error if you use a 64bit only instruction
 654   // in a 32bit vm. This is somewhat unfortunate but keeps the ifdef noise down.
 655 
 656 private:
 657 
 658   bool _legacy_mode_bw;
 659   bool _legacy_mode_dq;
 660   bool _legacy_mode_vl;
 661   bool _legacy_mode_vlbw;
<span class="line-modified"> 662   NOT_LP64(bool _is_managed;)</span>

 663 
 664   class InstructionAttr *_attributes;
 665 
 666   // 64bit prefixes
<span class="line-modified"> 667   void prefix(Register reg);</span>
<span class="line-modified"> 668   void prefix(Register dst, Register src, Prefix p);</span>
<span class="line-added"> 669   void prefix(Register dst, Address adr, Prefix p);</span>
<span class="line-added"> 670 </span>
<span class="line-added"> 671   void prefix(Address adr);</span>
<span class="line-added"> 672   void prefix(Address adr, Register reg,  bool byteinst = false);</span>
<span class="line-added"> 673   void prefix(Address adr, XMMRegister reg);</span>
 674 
<span class="line-added"> 675   int prefix_and_encode(int reg_enc, bool byteinst = false);</span>
 676   int prefix_and_encode(int dst_enc, int src_enc) {
 677     return prefix_and_encode(dst_enc, false, src_enc, false);
 678   }
 679   int prefix_and_encode(int dst_enc, bool dst_is_byte, int src_enc, bool src_is_byte);

 680 
<span class="line-modified"> 681   // Some prefixq variants always emit exactly one prefix byte, so besides a</span>
<span class="line-modified"> 682   // prefix-emitting method we provide a method to get the prefix byte to emit,</span>
<span class="line-modified"> 683   // which can then be folded into a byte stream.</span>
<span class="line-modified"> 684   int8_t get_prefixq(Address adr);</span>
<span class="line-modified"> 685   int8_t get_prefixq(Address adr, Register reg);</span>
 686 
<span class="line-modified"> 687   void prefixq(Address adr);</span>

 688   void prefixq(Address adr, Register reg);
 689   void prefixq(Address adr, XMMRegister reg);
 690 
<span class="line-modified"> 691   int prefixq_and_encode(int reg_enc);</span>
<span class="line-added"> 692   int prefixq_and_encode(int dst_enc, int src_enc);</span>
 693 
 694   void rex_prefix(Address adr, XMMRegister xreg,
 695                   VexSimdPrefix pre, VexOpcode opc, bool rex_w);
 696   int  rex_prefix_and_encode(int dst_enc, int src_enc,
 697                              VexSimdPrefix pre, VexOpcode opc, bool rex_w);
 698 
 699   void vex_prefix(bool vex_r, bool vex_b, bool vex_x, int nds_enc, VexSimdPrefix pre, VexOpcode opc);
 700 
 701   void evex_prefix(bool vex_r, bool vex_b, bool vex_x, bool evex_r, bool evex_v,
 702                    int nds_enc, VexSimdPrefix pre, VexOpcode opc);
 703 
 704   void vex_prefix(Address adr, int nds_enc, int xreg_enc,
 705                   VexSimdPrefix pre, VexOpcode opc,
 706                   InstructionAttr *attributes);
 707 
 708   int  vex_prefix_and_encode(int dst_enc, int nds_enc, int src_enc,
 709                              VexSimdPrefix pre, VexOpcode opc,
 710                              InstructionAttr *attributes);
 711 
 712   void simd_prefix(XMMRegister xreg, XMMRegister nds, Address adr, VexSimdPrefix pre,
</pre>
<hr />
<pre>
 858   }
 859 
 860   // Decoding
 861   static address locate_operand(address inst, WhichOperand which);
 862   static address locate_next_instruction(address inst);
 863 
 864   // Utilities
 865   static bool is_polling_page_far() NOT_LP64({ return false;});
 866   static bool query_compressed_disp_byte(int disp, bool is_evex_inst, int vector_len,
 867                                          int cur_tuple_type, int in_size_in_bits, int cur_encoding);
 868 
 869   // Generic instructions
 870   // Does 32bit or 64bit as needed for the platform. In some sense these
 871   // belong in macro assembler but there is no need for both varieties to exist
 872 
 873   void init_attributes(void) {
 874     _legacy_mode_bw = (VM_Version::supports_avx512bw() == false);
 875     _legacy_mode_dq = (VM_Version::supports_avx512dq() == false);
 876     _legacy_mode_vl = (VM_Version::supports_avx512vl() == false);
 877     _legacy_mode_vlbw = (VM_Version::supports_avx512vlbw() == false);
<span class="line-modified"> 878     NOT_LP64(_is_managed = false;)</span>

 879     _attributes = NULL;
 880   }
 881 
 882   void set_attributes(InstructionAttr *attributes) { _attributes = attributes; }
 883   void clear_attributes(void) { _attributes = NULL; }
 884 
<span class="line-modified"> 885   void set_managed(void) { NOT_LP64(_is_managed = true;) }</span>
<span class="line-modified"> 886   void clear_managed(void) { NOT_LP64(_is_managed = false;) }</span>
<span class="line-modified"> 887   bool is_managed(void) {</span>
<span class="line-added"> 888     NOT_LP64(return _is_managed;)</span>
<span class="line-added"> 889     LP64_ONLY(return false;) }</span>
 890 
 891   void lea(Register dst, Address src);
 892 
 893   void mov(Register dst, Register src);
 894 
<span class="line-added"> 895 #ifdef _LP64</span>
<span class="line-added"> 896   // support caching the result of some routines</span>
<span class="line-added"> 897 </span>
<span class="line-added"> 898   // must be called before pusha(), popa(), vzeroupper() - checked with asserts</span>
<span class="line-added"> 899   static void precompute_instructions();</span>
<span class="line-added"> 900 </span>
<span class="line-added"> 901   void pusha_uncached();</span>
<span class="line-added"> 902   void popa_uncached();</span>
<span class="line-added"> 903 #endif</span>
<span class="line-added"> 904   void vzeroupper_uncached();</span>
<span class="line-added"> 905 </span>
 906   void pusha();
 907   void popa();
 908 
 909   void pushf();
 910   void popf();
 911 
 912   void push(int32_t imm32);
 913 
 914   void push(Register src);
 915 
 916   void pop(Register dst);
 917 
 918   // These are dummies to prevent surprise implicit conversions to Register
 919   void push(void* v);
 920   void pop(void* v);
 921 
 922   // These do register sized moves/scans
 923   void rep_mov();
 924   void rep_stos();
 925   void rep_stosb();
</pre>
<hr />
<pre>
2217   void vextractf32x4(XMMRegister dst, XMMRegister src, uint8_t imm8);
2218   void vextractf32x4(Address dst, XMMRegister src, uint8_t imm8);
2219   void vextractf64x2(XMMRegister dst, XMMRegister src, uint8_t imm8);
2220   void vextractf64x4(XMMRegister dst, XMMRegister src, uint8_t imm8);
2221   void vextractf64x4(Address dst, XMMRegister src, uint8_t imm8);
2222 
2223   // xmm/mem sourced byte/word/dword/qword replicate
2224   void vpbroadcastb(XMMRegister dst, XMMRegister src, int vector_len);
2225   void vpbroadcastb(XMMRegister dst, Address src, int vector_len);
2226   void vpbroadcastw(XMMRegister dst, XMMRegister src, int vector_len);
2227   void vpbroadcastw(XMMRegister dst, Address src, int vector_len);
2228   void vpbroadcastd(XMMRegister dst, XMMRegister src, int vector_len);
2229   void vpbroadcastd(XMMRegister dst, Address src, int vector_len);
2230   void vpbroadcastq(XMMRegister dst, XMMRegister src, int vector_len);
2231   void vpbroadcastq(XMMRegister dst, Address src, int vector_len);
2232 
2233   void evbroadcasti64x2(XMMRegister dst, XMMRegister src, int vector_len);
2234   void evbroadcasti64x2(XMMRegister dst, Address src, int vector_len);
2235 
2236   // scalar single/double precision replicate
<span class="line-modified">2237   void vbroadcastss(XMMRegister dst, XMMRegister src, int vector_len);</span>
<span class="line-modified">2238   void vbroadcastss(XMMRegister dst, Address src, int vector_len);</span>
<span class="line-modified">2239   void vbroadcastsd(XMMRegister dst, XMMRegister src, int vector_len);</span>
<span class="line-modified">2240   void vbroadcastsd(XMMRegister dst, Address src, int vector_len);</span>
2241 
2242   // gpr sourced byte/word/dword/qword replicate
2243   void evpbroadcastb(XMMRegister dst, Register src, int vector_len);
2244   void evpbroadcastw(XMMRegister dst, Register src, int vector_len);
2245   void evpbroadcastd(XMMRegister dst, Register src, int vector_len);
2246   void evpbroadcastq(XMMRegister dst, Register src, int vector_len);
2247 
2248   void evpgatherdd(XMMRegister dst, KRegister k1, Address src, int vector_len);
2249 
2250   // Carry-Less Multiplication Quadword
2251   void pclmulqdq(XMMRegister dst, XMMRegister src, int mask);
2252   void vpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask);
2253   void evpclmulqdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int mask, int vector_len);
2254   // AVX instruction which is used to clear upper 128 bits of YMM registers and
2255   // to avoid transaction penalty between AVX and SSE states. There is no
2256   // penalty if legacy SSE instructions are encoded using VEX prefix because
2257   // they always clear upper 128 bits. It should be used before calling
2258   // runtime code and native libraries.
2259   void vzeroupper();
2260 
</pre>
<hr />
<pre>
2270   // They should be called only from corresponding MacroAssembler instructions.
2271   void andpd(XMMRegister dst, Address src);
2272   void andps(XMMRegister dst, Address src);
2273   void xorpd(XMMRegister dst, Address src);
2274   void xorps(XMMRegister dst, Address src);
2275 
2276 };
2277 
2278 // The Intel x86/Amd64 Assembler attributes: All fields enclosed here are to guide encoding level decisions.
2279 // Specific set functions are for specialized use, else defaults or whatever was supplied to object construction
2280 // are applied.
2281 class InstructionAttr {
2282 public:
2283   InstructionAttr(
2284     int vector_len,     // The length of vector to be applied in encoding - for both AVX and EVEX
2285     bool rex_vex_w,     // Width of data: if 32-bits or less, false, else if 64-bit or specially defined, true
2286     bool legacy_mode,   // Details if either this instruction is conditionally encoded to AVX or earlier if true else possibly EVEX
2287     bool no_reg_mask,   // when true, k0 is used when EVEX encoding is chosen, else embedded_opmask_register_specifier is used
2288     bool uses_vl)       // This instruction may have legacy constraints based on vector length for EVEX
2289     :

2290       _rex_vex_w(rex_vex_w),
<span class="line-modified">2291       _legacy_mode(legacy_mode || UseAVX &lt; 3),</span>

2292       _no_reg_mask(no_reg_mask),
2293       _uses_vl(uses_vl),
<span class="line-modified">2294       _rex_vex_w_reverted(false),</span>

2295       _is_evex_instruction(false),

2296       _is_clear_context(true),
2297       _is_extended_context(false),
<span class="line-added">2298       _avx_vector_len(vector_len),</span>
<span class="line-added">2299       _tuple_type(Assembler::EVEX_ETUP),</span>
<span class="line-added">2300       _input_size_in_bits(Assembler::EVEX_NObit),</span>
<span class="line-added">2301       _evex_encoding(0),</span>
2302       _embedded_opmask_register_specifier(0), // hard code k0
<span class="line-modified">2303       _current_assembler(NULL) { }</span>


2304 
2305   ~InstructionAttr() {
2306     if (_current_assembler != NULL) {
2307       _current_assembler-&gt;clear_attributes();
2308     }
2309     _current_assembler = NULL;
2310   }
2311 
2312 private:

2313   bool _rex_vex_w;

2314   bool _legacy_mode;
2315   bool _no_reg_mask;
2316   bool _uses_vl;
<span class="line-modified">2317   bool _rex_vex_w_reverted;</span>

2318   bool _is_evex_instruction;

2319   bool _is_clear_context;
2320   bool _is_extended_context;
<span class="line-added">2321   int  _avx_vector_len;</span>
<span class="line-added">2322   int  _tuple_type;</span>
<span class="line-added">2323   int  _input_size_in_bits;</span>
<span class="line-added">2324   int  _evex_encoding;</span>
2325   int _embedded_opmask_register_specifier;
2326 
2327   Assembler *_current_assembler;
2328 
2329 public:
2330   // query functions for field accessors

2331   bool is_rex_vex_w(void) const { return _rex_vex_w; }

2332   bool is_legacy_mode(void) const { return _legacy_mode; }
2333   bool is_no_reg_mask(void) const { return _no_reg_mask; }
2334   bool uses_vl(void) const { return _uses_vl; }
<span class="line-added">2335   bool is_rex_vex_w_reverted(void) { return _rex_vex_w_reverted; }</span>
<span class="line-added">2336   bool is_evex_instruction(void) const { return _is_evex_instruction; }</span>
<span class="line-added">2337   bool is_clear_context(void) const { return _is_clear_context; }</span>
<span class="line-added">2338   bool is_extended_context(void) const { return _is_extended_context; }</span>
<span class="line-added">2339   int  get_vector_len(void) const { return _avx_vector_len; }</span>
2340   int  get_tuple_type(void) const { return _tuple_type; }
2341   int  get_input_size(void) const { return _input_size_in_bits; }

2342   int  get_evex_encoding(void) const { return _evex_encoding; }
<span class="line-modified">2343   int  get_embedded_opmask_register_specifier(void) const { return _embedded_opmask_register_specifier; }</span>


2344 
2345   // Set the vector len manually
2346   void set_vector_len(int vector_len) { _avx_vector_len = vector_len; }
2347 
2348   // Set revert rex_vex_w for avx encoding
2349   void set_rex_vex_w_reverted(void) { _rex_vex_w_reverted = true; }
2350 
2351   // Set rex_vex_w based on state
2352   void set_rex_vex_w(bool state) { _rex_vex_w = state; }
2353 
2354   // Set the instruction to be encoded in AVX mode
2355   void set_is_legacy_mode(void) { _legacy_mode = true; }
2356 
2357   // Set the current instuction to be encoded as an EVEX instuction
2358   void set_is_evex_instruction(void) { _is_evex_instruction = true; }
2359 
2360   // Internal encoding data used in compressed immediate offset programming
2361   void set_evex_encoding(int value) { _evex_encoding = value; }
2362 
2363   // Set the Evex.Z field to be used to clear all non directed XMM/YMM/ZMM components
</pre>
</td>
</tr>
</table>
<center><a href="assembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Defs_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>