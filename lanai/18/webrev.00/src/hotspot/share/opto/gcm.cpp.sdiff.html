<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/gcm.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="escape.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="graphKit.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/gcm.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  86     uint j = 0;
  87     if (pb-&gt;_num_succs != 1) {  // More then 1 successor?
  88       // Search for successor
  89       uint max = pb-&gt;number_of_nodes();
  90       assert( max &gt; 1, &quot;&quot; );
  91       uint start = max - pb-&gt;_num_succs;
  92       // Find which output path belongs to projection
  93       for (j = start; j &lt; max; j++) {
  94         if( pb-&gt;get_node(j) == in0 )
  95           break;
  96       }
  97       assert( j &lt; max, &quot;must find&quot; );
  98       // Change control to match head of successor basic block
  99       j -= start;
 100     }
 101     n-&gt;set_req(0, pb-&gt;_succs[j]-&gt;head());
 102   }
 103 }
 104 
 105 bool PhaseCFG::is_dominator(Node* dom_node, Node* node) {

 106   if (dom_node == node) {
 107     return true;
 108   }
<span class="line-modified"> 109   Block* d = get_block_for_node(dom_node);</span>
<span class="line-modified"> 110   Block* n = get_block_for_node(node);</span>


 111   if (d == n) {
 112     if (dom_node-&gt;is_block_start()) {
 113       return true;
 114     }
 115     if (node-&gt;is_block_start()) {
 116       return false;
 117     }
 118     if (dom_node-&gt;is_block_proj()) {
 119       return false;
 120     }
 121     if (node-&gt;is_block_proj()) {
 122       return true;
 123     }










 124 #ifdef ASSERT
<span class="line-modified"> 125     node-&gt;dump();</span>
<span class="line-modified"> 126     dom_node-&gt;dump();</span>




 127 #endif
<span class="line-modified"> 128     fatal(&quot;unhandled&quot;);</span>
 129     return false;
 130   }
 131   return d-&gt;dom_lca(n) == d;
 132 }
 133 







































 134 //------------------------------schedule_pinned_nodes--------------------------
 135 // Set the basic block for Nodes pinned into blocks
 136 void PhaseCFG::schedule_pinned_nodes(VectorSet &amp;visited) {
 137   // Allocate node stack of size C-&gt;live_nodes()+8 to avoid frequent realloc
<span class="line-modified"> 138   GrowableArray &lt;Node *&gt; spstack(C-&gt;live_nodes() + 8);</span>
 139   spstack.push(_root);
 140   while (spstack.is_nonempty()) {
 141     Node* node = spstack.pop();
 142     if (!visited.test_set(node-&gt;_idx)) { // Test node and flag it as visited
 143       if (node-&gt;pinned() &amp;&amp; !has_block(node)) {  // Pinned?  Nail it down!
 144         assert(node-&gt;in(0), &quot;pinned Node must have Control&quot;);
 145         // Before setting block replace block_proj control edge
 146         replace_block_proj_ctrl(node);
 147         Node* input = node-&gt;in(0);
 148         while (!input-&gt;is_block_start()) {
 149           input = input-&gt;in(0);
 150         }
 151         Block* block = get_block_for_node(input); // Basic block of controlling input
 152         schedule_node_into_block(node, block);
 153       }
 154 
 155       // If the node has precedence edges (added when CastPP nodes are
 156       // removed in final_graph_reshaping), fix the control of the
 157       // node to cover the precedence edges and remove the
 158       // dependencies.
 159       Node* n = NULL;
 160       for (uint i = node-&gt;len()-1; i &gt;= node-&gt;req(); i--) {
 161         Node* m = node-&gt;in(i);
 162         if (m == NULL) continue;
<span class="line-modified"> 163         // Skip the precedence edge if the test that guarded a CastPP:</span>
<span class="line-modified"> 164         // - was optimized out during escape analysis</span>
<span class="line-modified"> 165         // (OptimizePtrCompare): the CastPP&#39;s control isn&#39;t an end of</span>
<span class="line-removed"> 166         // block.</span>
<span class="line-removed"> 167         // - is moved in the branch of a dominating If: the control of</span>
<span class="line-removed"> 168         // the CastPP is then a Region.</span>
<span class="line-removed"> 169         if (m-&gt;is_block_proj() || m-&gt;is_block_start()) {</span>
 170           node-&gt;rm_prec(i);
 171           if (n == NULL) {
 172             n = m;
 173           } else {
 174             assert(is_dominator(n, m) || is_dominator(m, n), &quot;one must dominate the other&quot;);
 175             n = is_dominator(n, m) ? m : n;
 176           }



 177         }
 178       }
 179       if (n != NULL) {
 180         assert(node-&gt;in(0), &quot;control should have been set&quot;);
 181         assert(is_dominator(n, node-&gt;in(0)) || is_dominator(node-&gt;in(0), n), &quot;one must dominate the other&quot;);
 182         if (!is_dominator(n, node-&gt;in(0))) {
 183           node-&gt;set_req(0, n);
 184         }
 185       }
 186 
 187       // process all inputs that are non NULL
<span class="line-modified"> 188       for (int i = node-&gt;req() - 1; i &gt;= 0; --i) {</span>
 189         if (node-&gt;in(i) != NULL) {
 190           spstack.push(node-&gt;in(i));
 191         }
 192       }
 193     }
 194   }
 195 }
 196 
 197 #ifdef ASSERT
 198 // Assert that new input b2 is dominated by all previous inputs.
 199 // Check this by by seeing that it is dominated by b1, the deepest
 200 // input observed until b2.
 201 static void assert_dom(Block* b1, Block* b2, Node* n, const PhaseCFG* cfg) {
 202   if (b1 == NULL)  return;
 203   assert(b1-&gt;_dom_depth &lt; b2-&gt;_dom_depth, &quot;sanity&quot;);
 204   Block* tmp = b2;
 205   while (tmp != b1 &amp;&amp; tmp != NULL) {
 206     tmp = tmp-&gt;_idom;
 207   }
 208   if (tmp != b1) {
</pre>
<hr />
<pre>
 635         // Check for call into the runtime using the Java calling
 636         // convention (and from there into a wrapper); it has no
 637         // _method.  Can&#39;t do this optimization for Native calls because
 638         // they CAN write to Java memory.
 639         if (mstore-&gt;ideal_Opcode() == Op_CallStaticJava) {
 640           assert(mstore-&gt;is_MachSafePoint(), &quot;&quot;);
 641           MachSafePointNode* ms = (MachSafePointNode*) mstore;
 642           assert(ms-&gt;is_MachCallJava(), &quot;&quot;);
 643           MachCallJavaNode* mcj = (MachCallJavaNode*) ms;
 644           if (mcj-&gt;_method == NULL) {
 645             // These runtime calls do not write to Java visible memory
 646             // (other than Raw) and so do not require anti-dependence edges.
 647             continue;
 648           }
 649         }
 650         // Same for SafePoints: they read/write Raw but only read otherwise.
 651         // This is basically a workaround for SafePoints only defining control
 652         // instead of control + memory.
 653         if (mstore-&gt;ideal_Opcode() == Op_SafePoint)
 654           continue;
<span class="line-removed"> 655 </span>
<span class="line-removed"> 656         // Check if the store is a membar on which the load is control dependent.</span>
<span class="line-removed"> 657         // Inserting an anti-dependency between that membar and the load would</span>
<span class="line-removed"> 658         // create a cycle that causes local scheduling to fail.</span>
<span class="line-removed"> 659         if (mstore-&gt;isa_MachMemBar()) {</span>
<span class="line-removed"> 660           Node* dom = load-&gt;find_exact_control(load-&gt;in(0));</span>
<span class="line-removed"> 661           while (dom != NULL &amp;&amp; dom != dom-&gt;in(0) &amp;&amp; dom != mstore) {</span>
<span class="line-removed"> 662             dom = dom-&gt;in(0);</span>
<span class="line-removed"> 663           }</span>
<span class="line-removed"> 664           if (dom == mstore) {</span>
<span class="line-removed"> 665             continue;</span>
<span class="line-removed"> 666           }</span>
<span class="line-removed"> 667         }</span>
 668       } else {
 669         // Some raw memory, such as the load of &quot;top&quot; at an allocation,
 670         // can be control dependent on the previous safepoint. See
 671         // comments in GraphKit::allocate_heap() about control input.
 672         // Inserting an anti-dep between such a safepoint and a use
 673         // creates a cycle, and will cause a subsequent failure in
 674         // local scheduling.  (BugId 4919904)
 675         // (%%% How can a control input be a safepoint and not a projection??)
 676         if (mstore-&gt;ideal_Opcode() == Op_SafePoint &amp;&amp; load-&gt;in(0) == mstore)
 677           continue;
 678       }
 679     }
 680 
 681     // Identify a block that the current load must be above,
 682     // or else observe that &#39;store&#39; is all the way up in the
 683     // earliest legal block for &#39;load&#39;.  In the latter case,
 684     // immediately insert an anti-dependence edge.
 685     Block* store_block = get_block_for_node(store);
 686     assert(store_block != NULL, &quot;unused killing projections skipped above&quot;);
 687 
</pre>
<hr />
<pre>
1367     // Bailout without retry
1368     C-&gt;record_method_not_compilable(&quot;early schedule failed&quot;);
1369     return;
1370   }
1371 
1372   // Build Def-Use edges.
1373   // Compute the latency information (via backwards walk) for all the
1374   // instructions in the graph
1375   _node_latency = new GrowableArray&lt;uint&gt;(); // resource_area allocation
1376 
1377   if (C-&gt;do_scheduling()) {
1378     compute_latencies_backwards(visited, stack);
1379   }
1380 
1381   // Now schedule all codes as LATE as possible.  This is the LCA in the
1382   // dominator tree of all USES of a value.  Pick the block with the least
1383   // loop nesting depth that is lowest in the dominator tree.
1384   // ( visited.clear() called in schedule_late()-&gt;Node_Backward_Iterator() )
1385   schedule_late(visited, stack);
1386   if (C-&gt;failing()) {
<span class="line-removed">1387     // schedule_late fails only when graph is incorrect.</span>
<span class="line-removed">1388     assert(!VerifyGraphEdges, &quot;verification should have failed&quot;);</span>
1389     return;
1390   }
1391 
1392 #ifndef PRODUCT
1393   if (trace_opto_pipelining()) {
1394     tty-&gt;print(&quot;\n---- Detect implicit null checks ----\n&quot;);
1395   }
1396 #endif
1397 
1398   // Detect implicit-null-check opportunities.  Basically, find NULL checks
1399   // with suitable memory ops nearby.  Use the memory op to do the NULL check.
1400   // I can generate a memory op if there is not one nearby.
1401   if (C-&gt;is_method_compilation()) {
1402     // By reversing the loop direction we get a very minor gain on mpegaudio.
1403     // Feel free to revert to a forward loop for clarity.
1404     // for( int i=0; i &lt; (int)matcher._null_check_tests.size(); i+=2 ) {
1405     for (int i = _matcher._null_check_tests.size() - 2; i &gt;= 0; i -= 2) {
1406       Node* proj = _matcher._null_check_tests[i];
1407       Node* val  = _matcher._null_check_tests[i + 1];
1408       Block* block = get_block_for_node(proj);
</pre>
</td>
<td>
<hr />
<pre>
  86     uint j = 0;
  87     if (pb-&gt;_num_succs != 1) {  // More then 1 successor?
  88       // Search for successor
  89       uint max = pb-&gt;number_of_nodes();
  90       assert( max &gt; 1, &quot;&quot; );
  91       uint start = max - pb-&gt;_num_succs;
  92       // Find which output path belongs to projection
  93       for (j = start; j &lt; max; j++) {
  94         if( pb-&gt;get_node(j) == in0 )
  95           break;
  96       }
  97       assert( j &lt; max, &quot;must find&quot; );
  98       // Change control to match head of successor basic block
  99       j -= start;
 100     }
 101     n-&gt;set_req(0, pb-&gt;_succs[j]-&gt;head());
 102   }
 103 }
 104 
 105 bool PhaseCFG::is_dominator(Node* dom_node, Node* node) {
<span class="line-added"> 106   assert(is_CFG(node) &amp;&amp; is_CFG(dom_node), &quot;node and dom_node must be CFG nodes&quot;);</span>
 107   if (dom_node == node) {
 108     return true;
 109   }
<span class="line-modified"> 110   Block* d = find_block_for_node(dom_node);</span>
<span class="line-modified"> 111   Block* n = find_block_for_node(node);</span>
<span class="line-added"> 112   assert(n != NULL &amp;&amp; d != NULL, &quot;blocks must exist&quot;);</span>
<span class="line-added"> 113 </span>
 114   if (d == n) {
 115     if (dom_node-&gt;is_block_start()) {
 116       return true;
 117     }
 118     if (node-&gt;is_block_start()) {
 119       return false;
 120     }
 121     if (dom_node-&gt;is_block_proj()) {
 122       return false;
 123     }
 124     if (node-&gt;is_block_proj()) {
 125       return true;
 126     }
<span class="line-added"> 127 </span>
<span class="line-added"> 128     assert(is_control_proj_or_safepoint(node), &quot;node must be control projection or safepoint&quot;);</span>
<span class="line-added"> 129     assert(is_control_proj_or_safepoint(dom_node), &quot;dom_node must be control projection or safepoint&quot;);</span>
<span class="line-added"> 130 </span>
<span class="line-added"> 131     // Neither &#39;node&#39; nor &#39;dom_node&#39; is a block start or block projection.</span>
<span class="line-added"> 132     // Check if &#39;dom_node&#39; is above &#39;node&#39; in the control graph.</span>
<span class="line-added"> 133     if (is_dominating_control(dom_node, node)) {</span>
<span class="line-added"> 134       return true;</span>
<span class="line-added"> 135     }</span>
<span class="line-added"> 136 </span>
 137 #ifdef ASSERT
<span class="line-modified"> 138     // If &#39;dom_node&#39; does not dominate &#39;node&#39; then &#39;node&#39; has to dominate &#39;dom_node&#39;</span>
<span class="line-modified"> 139     if (!is_dominating_control(node, dom_node)) {</span>
<span class="line-added"> 140       node-&gt;dump();</span>
<span class="line-added"> 141       dom_node-&gt;dump();</span>
<span class="line-added"> 142       assert(false, &quot;neither dom_node nor node dominates the other&quot;);</span>
<span class="line-added"> 143     }</span>
 144 #endif
<span class="line-modified"> 145 </span>
 146     return false;
 147   }
 148   return d-&gt;dom_lca(n) == d;
 149 }
 150 
<span class="line-added"> 151 bool PhaseCFG::is_CFG(Node* n) {</span>
<span class="line-added"> 152   return n-&gt;is_block_proj() || n-&gt;is_block_start() || is_control_proj_or_safepoint(n);</span>
<span class="line-added"> 153 }</span>
<span class="line-added"> 154 </span>
<span class="line-added"> 155 bool PhaseCFG::is_control_proj_or_safepoint(Node* n) {</span>
<span class="line-added"> 156   bool result = (n-&gt;is_Mach() &amp;&amp; n-&gt;as_Mach()-&gt;ideal_Opcode() == Op_SafePoint) || (n-&gt;is_Proj() &amp;&amp; n-&gt;as_Proj()-&gt;bottom_type() == Type::CONTROL);</span>
<span class="line-added"> 157   assert(!result || (n-&gt;is_Mach() &amp;&amp; n-&gt;as_Mach()-&gt;ideal_Opcode() == Op_SafePoint)</span>
<span class="line-added"> 158           || (n-&gt;is_Proj() &amp;&amp; n-&gt;as_Proj()-&gt;_con == 0), &quot;If control projection, it must be projection 0&quot;);</span>
<span class="line-added"> 159   return result;</span>
<span class="line-added"> 160 }</span>
<span class="line-added"> 161 </span>
<span class="line-added"> 162 Block* PhaseCFG::find_block_for_node(Node* n) {</span>
<span class="line-added"> 163   if (n-&gt;is_block_start() || n-&gt;is_block_proj()) {</span>
<span class="line-added"> 164     return get_block_for_node(n);</span>
<span class="line-added"> 165   } else {</span>
<span class="line-added"> 166     // Walk the control graph up if &#39;n&#39; is not a block start nor a block projection. In this case &#39;n&#39; must be</span>
<span class="line-added"> 167     // an unmatched control projection or a not yet matched safepoint precedence edge in the middle of a block.</span>
<span class="line-added"> 168     assert(is_control_proj_or_safepoint(n), &quot;must be control projection or safepoint&quot;);</span>
<span class="line-added"> 169     Node* ctrl = n-&gt;in(0);</span>
<span class="line-added"> 170     while (!ctrl-&gt;is_block_start()) {</span>
<span class="line-added"> 171       ctrl = ctrl-&gt;in(0);</span>
<span class="line-added"> 172     }</span>
<span class="line-added"> 173     return get_block_for_node(ctrl);</span>
<span class="line-added"> 174   }</span>
<span class="line-added"> 175 }</span>
<span class="line-added"> 176 </span>
<span class="line-added"> 177 // Walk up the control graph from &#39;n&#39; and check if &#39;dom_ctrl&#39; is found.</span>
<span class="line-added"> 178 bool PhaseCFG::is_dominating_control(Node* dom_ctrl, Node* n) {</span>
<span class="line-added"> 179   Node* ctrl = n-&gt;in(0);</span>
<span class="line-added"> 180   while (!ctrl-&gt;is_block_start()) {</span>
<span class="line-added"> 181     if (ctrl == dom_ctrl) {</span>
<span class="line-added"> 182       return true;</span>
<span class="line-added"> 183     }</span>
<span class="line-added"> 184     ctrl = ctrl-&gt;in(0);</span>
<span class="line-added"> 185   }</span>
<span class="line-added"> 186   return false;</span>
<span class="line-added"> 187 }</span>
<span class="line-added"> 188 </span>
<span class="line-added"> 189 </span>
 190 //------------------------------schedule_pinned_nodes--------------------------
 191 // Set the basic block for Nodes pinned into blocks
 192 void PhaseCFG::schedule_pinned_nodes(VectorSet &amp;visited) {
 193   // Allocate node stack of size C-&gt;live_nodes()+8 to avoid frequent realloc
<span class="line-modified"> 194   GrowableArray &lt;Node*&gt; spstack(C-&gt;live_nodes() + 8);</span>
 195   spstack.push(_root);
 196   while (spstack.is_nonempty()) {
 197     Node* node = spstack.pop();
 198     if (!visited.test_set(node-&gt;_idx)) { // Test node and flag it as visited
 199       if (node-&gt;pinned() &amp;&amp; !has_block(node)) {  // Pinned?  Nail it down!
 200         assert(node-&gt;in(0), &quot;pinned Node must have Control&quot;);
 201         // Before setting block replace block_proj control edge
 202         replace_block_proj_ctrl(node);
 203         Node* input = node-&gt;in(0);
 204         while (!input-&gt;is_block_start()) {
 205           input = input-&gt;in(0);
 206         }
 207         Block* block = get_block_for_node(input); // Basic block of controlling input
 208         schedule_node_into_block(node, block);
 209       }
 210 
 211       // If the node has precedence edges (added when CastPP nodes are
 212       // removed in final_graph_reshaping), fix the control of the
 213       // node to cover the precedence edges and remove the
 214       // dependencies.
 215       Node* n = NULL;
 216       for (uint i = node-&gt;len()-1; i &gt;= node-&gt;req(); i--) {
 217         Node* m = node-&gt;in(i);
 218         if (m == NULL) continue;
<span class="line-modified"> 219 </span>
<span class="line-modified"> 220         // Only process precedence edges that are CFG nodes. Safepoints and control projections can be in the middle of a block</span>
<span class="line-modified"> 221         if (is_CFG(m)) {</span>




 222           node-&gt;rm_prec(i);
 223           if (n == NULL) {
 224             n = m;
 225           } else {
 226             assert(is_dominator(n, m) || is_dominator(m, n), &quot;one must dominate the other&quot;);
 227             n = is_dominator(n, m) ? m : n;
 228           }
<span class="line-added"> 229         } else {</span>
<span class="line-added"> 230           assert(node-&gt;is_Mach(), &quot;sanity&quot;);</span>
<span class="line-added"> 231           assert(node-&gt;as_Mach()-&gt;ideal_Opcode() == Op_StoreCM, &quot;must be StoreCM node&quot;);</span>
 232         }
 233       }
 234       if (n != NULL) {
 235         assert(node-&gt;in(0), &quot;control should have been set&quot;);
 236         assert(is_dominator(n, node-&gt;in(0)) || is_dominator(node-&gt;in(0), n), &quot;one must dominate the other&quot;);
 237         if (!is_dominator(n, node-&gt;in(0))) {
 238           node-&gt;set_req(0, n);
 239         }
 240       }
 241 
 242       // process all inputs that are non NULL
<span class="line-modified"> 243       for (int i = node-&gt;req()-1; i &gt;= 0; --i) {</span>
 244         if (node-&gt;in(i) != NULL) {
 245           spstack.push(node-&gt;in(i));
 246         }
 247       }
 248     }
 249   }
 250 }
 251 
 252 #ifdef ASSERT
 253 // Assert that new input b2 is dominated by all previous inputs.
 254 // Check this by by seeing that it is dominated by b1, the deepest
 255 // input observed until b2.
 256 static void assert_dom(Block* b1, Block* b2, Node* n, const PhaseCFG* cfg) {
 257   if (b1 == NULL)  return;
 258   assert(b1-&gt;_dom_depth &lt; b2-&gt;_dom_depth, &quot;sanity&quot;);
 259   Block* tmp = b2;
 260   while (tmp != b1 &amp;&amp; tmp != NULL) {
 261     tmp = tmp-&gt;_idom;
 262   }
 263   if (tmp != b1) {
</pre>
<hr />
<pre>
 690         // Check for call into the runtime using the Java calling
 691         // convention (and from there into a wrapper); it has no
 692         // _method.  Can&#39;t do this optimization for Native calls because
 693         // they CAN write to Java memory.
 694         if (mstore-&gt;ideal_Opcode() == Op_CallStaticJava) {
 695           assert(mstore-&gt;is_MachSafePoint(), &quot;&quot;);
 696           MachSafePointNode* ms = (MachSafePointNode*) mstore;
 697           assert(ms-&gt;is_MachCallJava(), &quot;&quot;);
 698           MachCallJavaNode* mcj = (MachCallJavaNode*) ms;
 699           if (mcj-&gt;_method == NULL) {
 700             // These runtime calls do not write to Java visible memory
 701             // (other than Raw) and so do not require anti-dependence edges.
 702             continue;
 703           }
 704         }
 705         // Same for SafePoints: they read/write Raw but only read otherwise.
 706         // This is basically a workaround for SafePoints only defining control
 707         // instead of control + memory.
 708         if (mstore-&gt;ideal_Opcode() == Op_SafePoint)
 709           continue;













 710       } else {
 711         // Some raw memory, such as the load of &quot;top&quot; at an allocation,
 712         // can be control dependent on the previous safepoint. See
 713         // comments in GraphKit::allocate_heap() about control input.
 714         // Inserting an anti-dep between such a safepoint and a use
 715         // creates a cycle, and will cause a subsequent failure in
 716         // local scheduling.  (BugId 4919904)
 717         // (%%% How can a control input be a safepoint and not a projection??)
 718         if (mstore-&gt;ideal_Opcode() == Op_SafePoint &amp;&amp; load-&gt;in(0) == mstore)
 719           continue;
 720       }
 721     }
 722 
 723     // Identify a block that the current load must be above,
 724     // or else observe that &#39;store&#39; is all the way up in the
 725     // earliest legal block for &#39;load&#39;.  In the latter case,
 726     // immediately insert an anti-dependence edge.
 727     Block* store_block = get_block_for_node(store);
 728     assert(store_block != NULL, &quot;unused killing projections skipped above&quot;);
 729 
</pre>
<hr />
<pre>
1409     // Bailout without retry
1410     C-&gt;record_method_not_compilable(&quot;early schedule failed&quot;);
1411     return;
1412   }
1413 
1414   // Build Def-Use edges.
1415   // Compute the latency information (via backwards walk) for all the
1416   // instructions in the graph
1417   _node_latency = new GrowableArray&lt;uint&gt;(); // resource_area allocation
1418 
1419   if (C-&gt;do_scheduling()) {
1420     compute_latencies_backwards(visited, stack);
1421   }
1422 
1423   // Now schedule all codes as LATE as possible.  This is the LCA in the
1424   // dominator tree of all USES of a value.  Pick the block with the least
1425   // loop nesting depth that is lowest in the dominator tree.
1426   // ( visited.clear() called in schedule_late()-&gt;Node_Backward_Iterator() )
1427   schedule_late(visited, stack);
1428   if (C-&gt;failing()) {


1429     return;
1430   }
1431 
1432 #ifndef PRODUCT
1433   if (trace_opto_pipelining()) {
1434     tty-&gt;print(&quot;\n---- Detect implicit null checks ----\n&quot;);
1435   }
1436 #endif
1437 
1438   // Detect implicit-null-check opportunities.  Basically, find NULL checks
1439   // with suitable memory ops nearby.  Use the memory op to do the NULL check.
1440   // I can generate a memory op if there is not one nearby.
1441   if (C-&gt;is_method_compilation()) {
1442     // By reversing the loop direction we get a very minor gain on mpegaudio.
1443     // Feel free to revert to a forward loop for clarity.
1444     // for( int i=0; i &lt; (int)matcher._null_check_tests.size(); i+=2 ) {
1445     for (int i = _matcher._null_check_tests.size() - 2; i &gt;= 0; i -= 2) {
1446       Node* proj = _matcher._null_check_tests[i];
1447       Node* val  = _matcher._null_check_tests[i + 1];
1448       Block* block = get_block_for_node(proj);
</pre>
</td>
</tr>
</table>
<center><a href="escape.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="graphKit.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>