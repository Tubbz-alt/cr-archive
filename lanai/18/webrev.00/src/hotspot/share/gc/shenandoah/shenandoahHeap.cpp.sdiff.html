<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/shenandoah/shenandoahHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="shenandoahFreeSet.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/shenandoah/shenandoahHeap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;memory/allocation.hpp&quot;
  27 #include &quot;memory/universe.hpp&quot;
  28 
  29 #include &quot;gc/shared/gcArguments.hpp&quot;
  30 #include &quot;gc/shared/gcTimer.hpp&quot;
  31 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
  32 #include &quot;gc/shared/locationPrinter.inline.hpp&quot;
  33 #include &quot;gc/shared/memAllocator.hpp&quot;
  34 #include &quot;gc/shared/oopStorageSet.hpp&quot;
  35 #include &quot;gc/shared/plab.hpp&quot;
  36 
<span class="line-removed">  37 #include &quot;gc/shenandoah/shenandoahAllocTracker.hpp&quot;</span>
  38 #include &quot;gc/shenandoah/shenandoahBarrierSet.hpp&quot;
  39 #include &quot;gc/shenandoah/shenandoahClosures.inline.hpp&quot;
  40 #include &quot;gc/shenandoah/shenandoahCollectionSet.hpp&quot;
  41 #include &quot;gc/shenandoah/shenandoahCollectorPolicy.hpp&quot;
  42 #include &quot;gc/shenandoah/shenandoahConcurrentMark.inline.hpp&quot;
  43 #include &quot;gc/shenandoah/shenandoahConcurrentRoots.hpp&quot;
  44 #include &quot;gc/shenandoah/shenandoahControlThread.hpp&quot;
  45 #include &quot;gc/shenandoah/shenandoahFreeSet.hpp&quot;
  46 #include &quot;gc/shenandoah/shenandoahPhaseTimings.hpp&quot;
  47 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
  48 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;
  49 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.hpp&quot;
  50 #include &quot;gc/shenandoah/shenandoahMarkCompact.hpp&quot;
  51 #include &quot;gc/shenandoah/shenandoahMarkingContext.inline.hpp&quot;
  52 #include &quot;gc/shenandoah/shenandoahMemoryPool.hpp&quot;
  53 #include &quot;gc/shenandoah/shenandoahMetrics.hpp&quot;
  54 #include &quot;gc/shenandoah/shenandoahMonitoringSupport.hpp&quot;
  55 #include &quot;gc/shenandoah/shenandoahNormalMode.hpp&quot;
  56 #include &quot;gc/shenandoah/shenandoahOopClosures.inline.hpp&quot;
  57 #include &quot;gc/shenandoah/shenandoahPacer.inline.hpp&quot;
</pre>
<hr />
<pre>
  63 #include &quot;gc/shenandoah/shenandoahTraversalMode.hpp&quot;
  64 #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
  65 #include &quot;gc/shenandoah/shenandoahVerifier.hpp&quot;
  66 #include &quot;gc/shenandoah/shenandoahCodeRoots.hpp&quot;
  67 #include &quot;gc/shenandoah/shenandoahVMOperations.hpp&quot;
  68 #include &quot;gc/shenandoah/shenandoahWorkGroup.hpp&quot;
  69 #include &quot;gc/shenandoah/shenandoahWorkerPolicy.hpp&quot;
  70 #if INCLUDE_JFR
  71 #include &quot;gc/shenandoah/shenandoahJfrSupport.hpp&quot;
  72 #endif
  73 
  74 #include &quot;memory/metaspace.hpp&quot;
  75 #include &quot;oops/compressedOops.inline.hpp&quot;
  76 #include &quot;runtime/atomic.hpp&quot;
  77 #include &quot;runtime/globals.hpp&quot;
  78 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  79 #include &quot;runtime/orderAccess.hpp&quot;
  80 #include &quot;runtime/safepointMechanism.hpp&quot;
  81 #include &quot;runtime/vmThread.hpp&quot;
  82 #include &quot;services/mallocTracker.hpp&quot;

  83 
  84 #ifdef ASSERT
  85 template &lt;class T&gt;
  86 void ShenandoahAssertToSpaceClosure::do_oop_work(T* p) {
  87   T o = RawAccess&lt;&gt;::oop_load(p);
  88   if (! CompressedOops::is_null(o)) {
  89     oop obj = CompressedOops::decode_not_null(o);
  90     shenandoah_assert_not_forwarded(p, obj);
  91   }
  92 }
  93 
  94 void ShenandoahAssertToSpaceClosure::do_oop(narrowOop* p) { do_oop_work(p); }
  95 void ShenandoahAssertToSpaceClosure::do_oop(oop* p)       { do_oop_work(p); }
  96 #endif
  97 
  98 class ShenandoahPretouchHeapTask : public AbstractGangTask {
  99 private:
 100   ShenandoahRegionIterator _regions;
 101   const size_t _page_size;
 102 public:
</pre>
<hr />
<pre>
 343 
 344   _liveness_cache = NEW_C_HEAP_ARRAY(jushort*, _max_workers, mtGC);
 345   for (uint worker = 0; worker &lt; _max_workers; worker++) {
 346     _liveness_cache[worker] = NEW_C_HEAP_ARRAY(jushort, _num_regions, mtGC);
 347     Copy::fill_to_bytes(_liveness_cache[worker], _num_regions * sizeof(jushort));
 348   }
 349 
 350   // There should probably be Shenandoah-specific options for these,
 351   // just as there are G1-specific options.
 352   {
 353     ShenandoahSATBMarkQueueSet&amp; satbqs = ShenandoahBarrierSet::satb_mark_queue_set();
 354     satbqs.set_process_completed_buffers_threshold(20); // G1SATBProcessCompletedThreshold
 355     satbqs.set_buffer_enqueue_threshold_percentage(60); // G1SATBBufferEnqueueingThresholdPercent
 356   }
 357 
 358   _monitoring_support = new ShenandoahMonitoringSupport(this);
 359   _phase_timings = new ShenandoahPhaseTimings();
 360   ShenandoahStringDedup::initialize();
 361   ShenandoahCodeRoots::initialize();
 362 
<span class="line-removed"> 363   if (ShenandoahAllocationTrace) {</span>
<span class="line-removed"> 364     _alloc_tracker = new ShenandoahAllocTracker();</span>
<span class="line-removed"> 365   }</span>
<span class="line-removed"> 366 </span>
 367   if (ShenandoahPacing) {
 368     _pacer = new ShenandoahPacer(this);
 369     _pacer-&gt;setup_for_idle();
 370   } else {
 371     _pacer = NULL;
 372   }
 373 
 374   _traversal_gc = strcmp(ShenandoahGCMode, &quot;traversal&quot;) == 0 ?
 375                   new ShenandoahTraversalGC(this, _num_regions) :
 376                   NULL;
 377 
 378   _control_thread = new ShenandoahControlThread();
 379 
 380   log_info(gc, init)(&quot;Initialize Shenandoah heap: &quot; SIZE_FORMAT &quot;%s initial, &quot; SIZE_FORMAT &quot;%s min, &quot; SIZE_FORMAT &quot;%s max&quot;,
 381                      byte_size_in_proper_unit(_initial_size),  proper_unit_for_byte_size(_initial_size),
 382                      byte_size_in_proper_unit(_minimum_size),  proper_unit_for_byte_size(_minimum_size),
 383                      byte_size_in_proper_unit(max_capacity()), proper_unit_for_byte_size(max_capacity())
 384   );
 385 
 386   log_info(gc, init)(&quot;Safepointing mechanism: %s&quot;,
</pre>
<hr />
<pre>
 431   _initial_size(0),
 432   _used(0),
 433   _committed(0),
 434   _bytes_allocated_since_gc_start(0),
 435   _max_workers(MAX2(ConcGCThreads, ParallelGCThreads)),
 436   _workers(NULL),
 437   _safepoint_workers(NULL),
 438   _heap_region_special(false),
 439   _num_regions(0),
 440   _regions(NULL),
 441   _update_refs_iterator(this),
 442   _control_thread(NULL),
 443   _shenandoah_policy(policy),
 444   _heuristics(NULL),
 445   _free_set(NULL),
 446   _scm(new ShenandoahConcurrentMark()),
 447   _traversal_gc(NULL),
 448   _full_gc(new ShenandoahMarkCompact()),
 449   _pacer(NULL),
 450   _verifier(NULL),
<span class="line-removed"> 451   _alloc_tracker(NULL),</span>
 452   _phase_timings(NULL),
 453   _monitoring_support(NULL),
 454   _memory_pool(NULL),
 455   _stw_memory_manager(&quot;Shenandoah Pauses&quot;, &quot;end of GC pause&quot;),
 456   _cycle_memory_manager(&quot;Shenandoah Cycles&quot;, &quot;end of GC cycle&quot;),
 457   _gc_timer(new (ResourceObj::C_HEAP, mtGC) ConcurrentGCTimer()),
 458   _soft_ref_policy(),
 459   _log_min_obj_alignment_in_bytes(LogMinObjAlignmentInBytes),
 460   _ref_processor(NULL),
 461   _marking_context(NULL),
 462   _bitmap_size(0),
 463   _bitmap_regions_per_slice(0),
 464   _bitmap_bytes_per_slice(0),
 465   _bitmap_region_special(false),
 466   _aux_bitmap_region_special(false),
 467   _liveness_cache(NULL),
 468   _collection_set(NULL)
 469 {
 470   log_info(gc, init)(&quot;GC threads: &quot; UINT32_FORMAT &quot; parallel, &quot; UINT32_FORMAT &quot; concurrent&quot;, ParallelGCThreads, ConcGCThreads);
 471   log_info(gc, init)(&quot;Reference processing: %s&quot;, ParallelRefProcEnabled ? &quot;parallel&quot; : &quot;serial&quot;);
 472 
 473   BarrierSet::set_barrier_set(new ShenandoahBarrierSet(this));
 474 
 475   _max_workers = MAX2(_max_workers, 1U);
 476   _workers = new ShenandoahWorkGang(&quot;Shenandoah GC Threads&quot;, _max_workers,
 477                             /* are_GC_task_threads */ true,
 478                             /* are_ConcurrentGC_threads */ true);
 479   if (_workers == NULL) {
 480     vm_exit_during_initialization(&quot;Failed necessary allocation.&quot;);
 481   } else {
 482     _workers-&gt;initialize_workers();
 483   }
 484 
<span class="line-modified"> 485   if (ShenandoahParallelSafepointThreads &gt; 1) {</span>
 486     _safepoint_workers = new ShenandoahWorkGang(&quot;Safepoint Cleanup Thread&quot;,
<span class="line-modified"> 487                                                 ShenandoahParallelSafepointThreads,</span>
 488                       /* are_GC_task_threads */ false,
 489                  /* are_ConcurrentGC_threads */ false);
 490     _safepoint_workers-&gt;initialize_workers();
 491   }
 492 }
 493 
 494 #ifdef _MSC_VER
 495 #pragma warning( pop )
 496 #endif
 497 
 498 class ShenandoahResetBitmapTask : public AbstractGangTask {
 499 private:
 500   ShenandoahRegionIterator _regions;
 501 
 502 public:
 503   ShenandoahResetBitmapTask() :
 504     AbstractGangTask(&quot;Parallel Reset Bitmap Task&quot;) {}
 505 
 506   void work(uint worker_id) {
 507     ShenandoahHeapRegion* region = _regions.next();
</pre>
<hr />
<pre>
 779     *actual_size = req.actual_size();
 780   } else {
 781     *actual_size = 0;
 782   }
 783   return res;
 784 }
 785 
 786 ShenandoahHeap* ShenandoahHeap::heap() {
 787   CollectedHeap* heap = Universe::heap();
 788   assert(heap != NULL, &quot;Unitialized access to ShenandoahHeap::heap()&quot;);
 789   assert(heap-&gt;kind() == CollectedHeap::Shenandoah, &quot;not a shenandoah heap&quot;);
 790   return (ShenandoahHeap*) heap;
 791 }
 792 
 793 ShenandoahHeap* ShenandoahHeap::heap_no_check() {
 794   CollectedHeap* heap = Universe::heap();
 795   return (ShenandoahHeap*) heap;
 796 }
 797 
 798 HeapWord* ShenandoahHeap::allocate_memory(ShenandoahAllocRequest&amp; req) {
<span class="line-removed"> 799   ShenandoahAllocTrace trace_alloc(req.size(), req.type());</span>
<span class="line-removed"> 800 </span>
 801   intptr_t pacer_epoch = 0;
 802   bool in_new_region = false;
 803   HeapWord* result = NULL;
 804 
 805   if (req.is_mutator_alloc()) {
 806     if (ShenandoahPacing) {
 807       pacer()-&gt;pace_for_alloc(req.size());
 808       pacer_epoch = pacer()-&gt;epoch();
 809     }
 810 
 811     if (!ShenandoahAllocFailureALot || !should_inject_alloc_failure()) {
 812       result = allocate_memory_under_lock(req, in_new_region);
 813     }
 814 
 815     // Allocation failed, block until control thread reacted, then retry allocation.
 816     //
 817     // It might happen that one of the threads requesting allocation would unblock
 818     // way later after GC happened, only to fail the second allocation, because
 819     // other threads have already depleted the free storage. In this case, a better
 820     // strategy is to try again, as long as GC makes progress.
</pre>
<hr />
<pre>
1184   if (lt.is_enabled()) {
1185     ResourceMark rm;
1186     LogStream ls(lt);
1187 
1188     phase_timings()-&gt;print_on(&amp;ls);
1189 
1190     ls.cr();
1191     ls.cr();
1192 
1193     shenandoah_policy()-&gt;print_gc_stats(&amp;ls);
1194 
1195     ls.cr();
1196     ls.cr();
1197 
1198     if (ShenandoahPacing) {
1199       pacer()-&gt;print_on(&amp;ls);
1200     }
1201 
1202     ls.cr();
1203     ls.cr();
<span class="line-removed">1204 </span>
<span class="line-removed">1205     if (ShenandoahAllocationTrace) {</span>
<span class="line-removed">1206       assert(alloc_tracker() != NULL, &quot;Must be&quot;);</span>
<span class="line-removed">1207       alloc_tracker()-&gt;print_on(&amp;ls);</span>
<span class="line-removed">1208     } else {</span>
<span class="line-removed">1209       ls.print_cr(&quot;  Allocation tracing is disabled, use -XX:+ShenandoahAllocationTrace to enable.&quot;);</span>
<span class="line-removed">1210     }</span>
1211   }
1212 }
1213 
1214 void ShenandoahHeap::verify(VerifyOption vo) {
1215   if (ShenandoahSafepoint::is_at_shenandoah_safepoint()) {
1216     if (ShenandoahVerify) {
1217       verifier()-&gt;verify_generic(vo);
1218     } else {
1219       // TODO: Consider allocating verification bitmaps on demand,
1220       // and turn this on unconditionally.
1221     }
1222   }
1223 }
1224 size_t ShenandoahHeap::tlab_capacity(Thread *thr) const {
1225   return _free_set-&gt;capacity();
1226 }
1227 
1228 class ObjectIterateScanRootClosure : public BasicOopIterateClosure {
1229 private:
1230   MarkBitMap* _bitmap;
1231   Stack&lt;oop,mtGC&gt;* _oop_stack;


1232 
1233   template &lt;class T&gt;
1234   void do_oop_work(T* p) {
1235     T o = RawAccess&lt;&gt;::oop_load(p);
1236     if (!CompressedOops::is_null(o)) {
1237       oop obj = CompressedOops::decode_not_null(o);
<span class="line-modified">1238       oop fwd = (oop) ShenandoahForwarding::get_forwardee_raw_unchecked(obj);</span>
<span class="line-modified">1239       if (fwd == NULL) {</span>
<span class="line-modified">1240         // There is an odd interaction with VM_HeapWalkOperation, see jvmtiTagMap.cpp.</span>
<span class="line-removed">1241         //</span>
<span class="line-removed">1242         // That operation walks the reachable objects on its own, storing the marking</span>
<span class="line-removed">1243         // wavefront in the object marks. When it is done, it calls the CollectedHeap</span>
<span class="line-removed">1244         // to iterate over all objects to clean up the mess. When it reaches here,</span>
<span class="line-removed">1245         // the Shenandoah fwdptr resolution code encounters the marked objects with</span>
<span class="line-removed">1246         // NULL forwardee. Trying to act on that would crash the VM. Or fail the</span>
<span class="line-removed">1247         // asserts, should we go for resolve_forwarded_pointer(obj).</span>
<span class="line-removed">1248         //</span>
<span class="line-removed">1249         // Therefore, we have to dodge it by doing the raw access to forwardee, and</span>
<span class="line-removed">1250         // assuming the object had no forwardee, if that thing is NULL.</span>
<span class="line-removed">1251       } else {</span>
<span class="line-removed">1252         obj = fwd;</span>
1253       }


1254       assert(oopDesc::is_oop(obj), &quot;must be a valid oop&quot;);
1255       if (!_bitmap-&gt;is_marked(obj)) {
1256         _bitmap-&gt;mark(obj);
1257         _oop_stack-&gt;push(obj);
1258       }
1259     }
1260   }
1261 public:
1262   ObjectIterateScanRootClosure(MarkBitMap* bitmap, Stack&lt;oop,mtGC&gt;* oop_stack) :
<span class="line-modified">1263     _bitmap(bitmap), _oop_stack(oop_stack) {}</span>

1264   void do_oop(oop* p)       { do_oop_work(p); }
1265   void do_oop(narrowOop* p) { do_oop_work(p); }
1266 };
1267 
1268 /*
1269  * This is public API, used in preparation of object_iterate().
1270  * Since we don&#39;t do linear scan of heap in object_iterate() (see comment below), we don&#39;t
1271  * need to make the heap parsable. For Shenandoah-internal linear heap scans that we can
1272  * control, we call SH::make_tlabs_parsable().
1273  */
1274 void ShenandoahHeap::ensure_parsability(bool retire_tlabs) {
1275   // No-op.
1276 }
1277 
1278 /*
1279  * Iterates objects in the heap. This is public API, used for, e.g., heap dumping.
1280  *
1281  * We cannot safely iterate objects by doing a linear scan at random points in time. Linear
1282  * scanning needs to deal with dead objects, which may have dead Klass* pointers (e.g.
1283  * calling oopDesc::size() would crash) or dangling reference fields (crashes) etc. Linear
</pre>
<hr />
<pre>
1289  * For all those reasons, we implement object iteration as a single marking traversal, reporting
1290  * objects as we mark+traverse through the heap, starting from GC roots. JVMTI IterateThroughHeap
1291  * is allowed to report dead objects, but is not required to do so.
1292  */
1293 void ShenandoahHeap::object_iterate(ObjectClosure* cl) {
1294   assert(SafepointSynchronize::is_at_safepoint(), &quot;safe iteration is only available during safepoints&quot;);
1295   if (!_aux_bitmap_region_special &amp;&amp; !os::commit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size(), false)) {
1296     log_warning(gc)(&quot;Could not commit native memory for auxiliary marking bitmap for heap iteration&quot;);
1297     return;
1298   }
1299 
1300   // Reset bitmap
1301   _aux_bit_map.clear();
1302 
1303   Stack&lt;oop,mtGC&gt; oop_stack;
1304 
1305   // First, we process GC roots according to current GC cycle. This populates the work stack with initial objects.
1306   ShenandoahHeapIterationRootScanner rp;
1307   ObjectIterateScanRootClosure oops(&amp;_aux_bit_map, &amp;oop_stack);
1308 
<span class="line-modified">1309   // When concurrent root is in progress, weak roots may contain dead oops, they should not be used</span>
<span class="line-removed">1310   // for root scanning.</span>
<span class="line-removed">1311   if (is_concurrent_root_in_progress()) {</span>
<span class="line-removed">1312     rp.strong_roots_do(&amp;oops);</span>
<span class="line-removed">1313   } else {</span>
<span class="line-removed">1314     rp.roots_do(&amp;oops);</span>
<span class="line-removed">1315   }</span>
1316 
1317   // Work through the oop stack to traverse heap.
1318   while (! oop_stack.is_empty()) {
1319     oop obj = oop_stack.pop();
1320     assert(oopDesc::is_oop(obj), &quot;must be a valid oop&quot;);
1321     cl-&gt;do_object(obj);
1322     obj-&gt;oop_iterate(&amp;oops);
1323   }
1324 
1325   assert(oop_stack.is_empty(), &quot;should be empty&quot;);
1326 
1327   if (!_aux_bitmap_region_special &amp;&amp; !os::uncommit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size())) {
1328     log_warning(gc)(&quot;Could not uncommit native memory for auxiliary marking bitmap for heap iteration&quot;);
1329   }
1330 }
1331 
1332 // Keep alive an object that was loaded with AS_NO_KEEPALIVE.
1333 void ShenandoahHeap::keep_alive(oop obj) {
1334   if (is_concurrent_mark_in_progress()) {
1335     ShenandoahBarrierSet::barrier_set()-&gt;enqueue(obj);
</pre>
<hr />
<pre>
1394   void heap_region_do(ShenandoahHeapRegion* r) {
1395     if (r-&gt;is_active()) {
1396       r-&gt;clear_live_data();
1397       _ctx-&gt;capture_top_at_mark_start(r);
1398     } else {
1399       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;region_number());
1400       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
1401              &quot;Region &quot; SIZE_FORMAT &quot; should already have correct TAMS&quot;, r-&gt;region_number());
1402     }
1403   }
1404 
1405   bool is_thread_safe() { return true; }
1406 };
1407 
1408 void ShenandoahHeap::op_init_mark() {
1409   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);
1410   assert(Thread::current()-&gt;is_VM_thread(), &quot;can only do this in VMThread&quot;);
1411 
1412   assert(marking_context()-&gt;is_bitmap_clear(), &quot;need clear marking bitmap&quot;);
1413   assert(!marking_context()-&gt;is_complete(), &quot;should not be complete&quot;);

1414 
1415   if (ShenandoahVerify) {
1416     verifier()-&gt;verify_before_concmark();
1417   }
1418 
1419   if (VerifyBeforeGC) {
1420     Universe::verify();
1421   }
1422 
1423   set_concurrent_mark_in_progress(true);
1424   // We need to reset all TLABs because we&#39;d lose marks on all objects allocated in them.
1425   {
1426     ShenandoahGCPhase phase(ShenandoahPhaseTimings::make_parsable);
1427     make_parsable(true);
1428   }
1429 
1430   {
1431     ShenandoahGCPhase phase(ShenandoahPhaseTimings::clear_liveness);
1432     ShenandoahClearLivenessClosure clc;
1433     parallel_heap_region_iterate(&amp;clc);
1434   }
1435 
1436   // Make above changes visible to worker threads
1437   OrderAccess::fence();
1438 
1439   concurrent_mark()-&gt;mark_roots(ShenandoahPhaseTimings::scan_roots);
1440 
1441   if (UseTLAB) {
1442     ShenandoahGCPhase phase(ShenandoahPhaseTimings::resize_tlabs);
1443     resize_tlabs();
1444   }
1445 
1446   if (ShenandoahPacing) {
1447     pacer()-&gt;setup_for_mark();
1448   }







1449 }
1450 
1451 void ShenandoahHeap::op_mark() {
1452   concurrent_mark()-&gt;mark_from_roots();
1453 }
1454 
1455 class ShenandoahCompleteLivenessClosure : public ShenandoahHeapRegionClosure {
1456 private:
1457   ShenandoahMarkingContext* const _ctx;
1458 public:
1459   ShenandoahCompleteLivenessClosure() : _ctx(ShenandoahHeap::heap()-&gt;complete_marking_context()) {}
1460 
1461   void heap_region_do(ShenandoahHeapRegion* r) {
1462     if (r-&gt;is_active()) {
1463       HeapWord *tams = _ctx-&gt;top_at_mark_start(r);
1464       HeapWord *top = r-&gt;top();
1465       if (top &gt; tams) {
1466         r-&gt;increase_live_data_alloc_words(pointer_delta(top, tams));
1467       }
1468     } else {
1469       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;region_number());
1470       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
1471              &quot;Region &quot; SIZE_FORMAT &quot; should have correct TAMS&quot;, r-&gt;region_number());
1472     }
1473   }
1474 
1475   bool is_thread_safe() { return true; }
1476 };
1477 
1478 void ShenandoahHeap::op_final_mark() {
1479   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);

1480 
1481   // It is critical that we
1482   // evacuate roots right after finishing marking, so that we don&#39;t
1483   // get unmarked objects in the roots.
1484 
1485   if (!cancelled_gc()) {
1486     concurrent_mark()-&gt;finish_mark_from_roots(/* full_gc = */ false);
1487 
1488     // Marking is completed, deactivate SATB barrier
1489     set_concurrent_mark_in_progress(false);
1490     mark_complete_marking_context();
1491 
1492     parallel_cleaning(false /* full gc*/);
1493 
<span class="line-removed">1494     if (has_forwarded_objects()) {</span>
<span class="line-removed">1495       // Degen may be caused by failed evacuation of roots</span>
<span class="line-removed">1496       if (is_degenerated_gc_in_progress()) {</span>
<span class="line-removed">1497         concurrent_mark()-&gt;update_roots(ShenandoahPhaseTimings::degen_gc_update_roots);</span>
<span class="line-removed">1498       } else {</span>
<span class="line-removed">1499         concurrent_mark()-&gt;update_thread_roots(ShenandoahPhaseTimings::update_roots);</span>
<span class="line-removed">1500       }</span>
<span class="line-removed">1501       set_has_forwarded_objects(false);</span>
<span class="line-removed">1502    }</span>
<span class="line-removed">1503 </span>
1504     if (ShenandoahVerify) {
1505       verifier()-&gt;verify_roots_no_forwarded();
1506     }
1507     // All allocations past TAMS are implicitly live, adjust the region data.
1508     // Bitmaps/TAMS are swapped at this point, so we need to poll complete bitmap.
1509     {
1510       ShenandoahGCPhase phase(ShenandoahPhaseTimings::complete_liveness);
1511       ShenandoahCompleteLivenessClosure cl;
1512       parallel_heap_region_iterate(&amp;cl);
1513     }
1514 
1515     // Force the threads to reacquire their TLABs outside the collection set.
1516     {
1517       ShenandoahGCPhase phase(ShenandoahPhaseTimings::retire_tlabs);
1518       make_parsable(true);
1519     }
1520 
1521     // We are about to select the collection set, make sure it knows about
1522     // current pinning status. Also, this allows trashing more regions that
1523     // now have their pinning status dropped.
</pre>
<hr />
<pre>
1541 
1542       heuristics()-&gt;choose_collection_set(_collection_set);
1543 
1544       _free_set-&gt;rebuild();
1545     }
1546 
1547     if (!is_degenerated_gc_in_progress()) {
1548       prepare_concurrent_roots();
1549       prepare_concurrent_unloading();
1550     }
1551 
1552     // If collection set has candidates, start evacuation.
1553     // Otherwise, bypass the rest of the cycle.
1554     if (!collection_set()-&gt;is_empty()) {
1555       ShenandoahGCPhase init_evac(ShenandoahPhaseTimings::init_evac);
1556 
1557       if (ShenandoahVerify) {
1558         verifier()-&gt;verify_before_evacuation();
1559       }
1560 







1561       set_evacuation_in_progress(true);
1562       // From here on, we need to update references.
1563       set_has_forwarded_objects(true);
1564 
1565       if (!is_degenerated_gc_in_progress()) {
1566         if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
1567           ShenandoahCodeRoots::arm_nmethods();
1568         }
1569         evacuate_and_update_roots();
1570       }
1571 
1572       if (ShenandoahPacing) {
1573         pacer()-&gt;setup_for_evac();
1574       }
1575 
1576       if (ShenandoahVerify) {
1577         ShenandoahRootVerifier::RootTypes types = ShenandoahRootVerifier::None;
1578         if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {
1579           types = ShenandoahRootVerifier::combine(ShenandoahRootVerifier::JNIHandleRoots, ShenandoahRootVerifier::WeakRoots);
1580           types = ShenandoahRootVerifier::combine(types, ShenandoahRootVerifier::CLDGRoots);
</pre>
<hr />
<pre>
1596         Universe::verify();
1597       }
1598     }
1599 
1600   } else {
1601     // If this cycle was updating references, we need to keep the has_forwarded_objects
1602     // flag on, for subsequent phases to deal with it.
1603     concurrent_mark()-&gt;cancel();
1604     set_concurrent_mark_in_progress(false);
1605 
1606     if (process_references()) {
1607       // Abandon reference processing right away: pre-cleaning must have failed.
1608       ReferenceProcessor *rp = ref_processor();
1609       rp-&gt;disable_discovery();
1610       rp-&gt;abandon_partial_discovery();
1611       rp-&gt;verify_no_references_recorded();
1612     }
1613   }
1614 }
1615 
<span class="line-removed">1616 void ShenandoahHeap::op_final_evac() {</span>
<span class="line-removed">1617   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);</span>
<span class="line-removed">1618 </span>
<span class="line-removed">1619   set_evacuation_in_progress(false);</span>
<span class="line-removed">1620 </span>
<span class="line-removed">1621   {</span>
<span class="line-removed">1622     ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_evac_retire_gclabs);</span>
<span class="line-removed">1623     retire_and_reset_gclabs();</span>
<span class="line-removed">1624   }</span>
<span class="line-removed">1625 </span>
<span class="line-removed">1626   if (ShenandoahVerify) {</span>
<span class="line-removed">1627     verifier()-&gt;verify_after_evacuation();</span>
<span class="line-removed">1628   }</span>
<span class="line-removed">1629 </span>
<span class="line-removed">1630   if (VerifyAfterGC) {</span>
<span class="line-removed">1631     Universe::verify();</span>
<span class="line-removed">1632   }</span>
<span class="line-removed">1633 }</span>
<span class="line-removed">1634 </span>
1635 void ShenandoahHeap::op_conc_evac() {
1636   ShenandoahEvacuationTask task(this, _collection_set, true);
1637   workers()-&gt;run_task(&amp;task);
1638 }
1639 
1640 void ShenandoahHeap::op_stw_evac() {
1641   ShenandoahEvacuationTask task(this, _collection_set, false);
1642   workers()-&gt;run_task(&amp;task);
1643 }
1644 
1645 void ShenandoahHeap::op_updaterefs() {
1646   update_heap_references(true);
1647 }
1648 
1649 void ShenandoahHeap::op_cleanup() {
1650   free_set()-&gt;recycle_trash();
1651 }
1652 
1653 class ShenandoahConcurrentRootsEvacUpdateTask : public AbstractGangTask {
1654 private:
</pre>
<hr />
<pre>
1796 void ShenandoahHeap::op_roots() {
1797   if (is_concurrent_root_in_progress()) {
1798     if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
1799       // Concurrent weak root processing
1800       ShenandoahConcurrentWeakRootsEvacUpdateTask task;
1801       workers()-&gt;run_task(&amp;task);
1802 
1803       _unloader.unload();
1804     }
1805 
1806     if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {
1807       ShenandoahConcurrentRootsEvacUpdateTask task(!ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
1808       workers()-&gt;run_task(&amp;task);
1809     }
1810   }
1811 
1812   set_concurrent_root_in_progress(false);
1813 }
1814 
1815 void ShenandoahHeap::op_reset() {



1816   reset_mark_bitmap();
1817 }
1818 
1819 void ShenandoahHeap::op_preclean() {



1820   concurrent_mark()-&gt;preclean_weak_refs();
1821 }
1822 
1823 void ShenandoahHeap::op_init_traversal() {
1824   traversal_gc()-&gt;init_traversal_collection();
1825 }
1826 
1827 void ShenandoahHeap::op_traversal() {
1828   traversal_gc()-&gt;concurrent_traversal_collection();
1829 }
1830 
1831 void ShenandoahHeap::op_final_traversal() {
1832   traversal_gc()-&gt;final_traversal_collection();
1833 }
1834 
1835 void ShenandoahHeap::op_full(GCCause::Cause cause) {
1836   ShenandoahMetricsSnapshot metrics;
1837   metrics.snap_before();
1838 
1839   full_gc()-&gt;do_it(cause);
</pre>
<hr />
<pre>
1903         cancel_gc(GCCause::_shenandoah_upgrade_to_full_gc);
1904         op_degenerated_fail();
1905         return;
1906       }
1907 
1908       op_reset();
1909 
1910       op_init_mark();
1911       if (cancelled_gc()) {
1912         op_degenerated_fail();
1913         return;
1914       }
1915 
1916     case _degenerated_mark:
1917       op_final_mark();
1918       if (cancelled_gc()) {
1919         op_degenerated_fail();
1920         return;
1921       }
1922 







1923       op_cleanup();
1924 
1925     case _degenerated_evac:
1926       // If heuristics thinks we should do the cycle, this flag would be set,
1927       // and we can do evacuation. Otherwise, it would be the shortcut cycle.
1928       if (is_evacuation_in_progress()) {
1929 
1930         // Degeneration under oom-evac protocol might have left some objects in
1931         // collection set un-evacuated. Restart evacuation from the beginning to
1932         // capture all objects. For all the objects that are already evacuated,
1933         // it would be a simple check, which is supposed to be fast. This is also
1934         // safe to do even without degeneration, as CSet iterator is at beginning
1935         // in preparation for evacuation anyway.
1936         //
1937         // Before doing that, we need to make sure we never had any cset-pinned
1938         // regions. This may happen if allocation failure happened when evacuating
1939         // the about-to-be-pinned object, oom-evac protocol left the object in
1940         // the collection set, and then the pin reached the cset region. If we continue
1941         // the cycle here, we would trash the cset and alive objects in it. To avoid
1942         // it, we fail degeneration right away and slide into Full GC to recover.
</pre>
<hr />
<pre>
2179                             ShenandoahPhaseTimings::purge_cldg);
2180     ClassLoaderDataGraph::purge();
2181   }
2182   // Resize and verify metaspace
2183   MetaspaceGC::compute_new_size();
2184   MetaspaceUtils::verify_metrics();
2185 }
2186 
2187 // Weak roots are either pre-evacuated (final mark) or updated (final updaterefs),
2188 // so they should not have forwarded oops.
2189 // However, we do need to &quot;null&quot; dead oops in the roots, if can not be done
2190 // in concurrent cycles.
2191 void ShenandoahHeap::stw_process_weak_roots(bool full_gc) {
2192   ShenandoahGCPhase root_phase(full_gc ?
2193                                ShenandoahPhaseTimings::full_gc_purge :
2194                                ShenandoahPhaseTimings::purge);
2195   uint num_workers = _workers-&gt;active_workers();
2196   ShenandoahPhaseTimings::Phase timing_phase = full_gc ?
2197                                                ShenandoahPhaseTimings::full_gc_purge_par :
2198                                                ShenandoahPhaseTimings::purge_par;
<span class="line-removed">2199   // Cleanup weak roots</span>
2200   ShenandoahGCPhase phase(timing_phase);
<span class="line-modified">2201   phase_timings()-&gt;record_workers_start(timing_phase);</span>


2202   if (has_forwarded_objects()) {
<span class="line-modified">2203     if (is_traversal_mode()) {</span>
<span class="line-modified">2204       ShenandoahForwardedIsAliveClosure is_alive;</span>
<span class="line-modified">2205       ShenandoahTraversalUpdateRefsClosure keep_alive;</span>
<span class="line-modified">2206       ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahForwardedIsAliveClosure, ShenandoahTraversalUpdateRefsClosure&gt;</span>
<span class="line-modified">2207         cleaning_task(&amp;is_alive, &amp;keep_alive, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());</span>
<span class="line-removed">2208       _workers-&gt;run_task(&amp;cleaning_task);</span>
<span class="line-removed">2209     } else {</span>
<span class="line-removed">2210       ShenandoahForwardedIsAliveClosure is_alive;</span>
<span class="line-removed">2211       ShenandoahUpdateRefsClosure keep_alive;</span>
<span class="line-removed">2212       ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahForwardedIsAliveClosure, ShenandoahUpdateRefsClosure&gt;</span>
<span class="line-removed">2213         cleaning_task(&amp;is_alive, &amp;keep_alive, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());</span>
<span class="line-removed">2214       _workers-&gt;run_task(&amp;cleaning_task);</span>
<span class="line-removed">2215     }</span>
2216   } else {
2217     ShenandoahIsAliveClosure is_alive;
2218 #ifdef ASSERT
2219     ShenandoahAssertNotForwardedClosure verify_cl;
2220     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahIsAliveClosure, ShenandoahAssertNotForwardedClosure&gt;
2221       cleaning_task(&amp;is_alive, &amp;verify_cl, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
2222 #else
2223     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahIsAliveClosure, DoNothingClosure&gt;
2224       cleaning_task(&amp;is_alive, &amp;do_nothing_cl, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
2225 #endif
2226     _workers-&gt;run_task(&amp;cleaning_task);
2227   }
<span class="line-removed">2228   phase_timings()-&gt;record_workers_end(timing_phase);</span>
2229 }
2230 
2231 void ShenandoahHeap::parallel_cleaning(bool full_gc) {
2232   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2233   stw_process_weak_roots(full_gc);
2234   if (!ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2235     stw_unload_classes(full_gc);
2236   }
2237 }
2238 
2239 void ShenandoahHeap::set_has_forwarded_objects(bool cond) {
2240   if (is_traversal_mode()) {
2241     set_gc_state_mask(HAS_FORWARDED | UPDATEREFS, cond);
2242   } else {
2243     set_gc_state_mask(HAS_FORWARDED, cond);
2244   }
2245 
2246 }
2247 
2248 void ShenandoahHeap::set_process_references(bool pr) {
</pre>
<hr />
<pre>
2365 
2366 void ShenandoahHeap::prepare_concurrent_unloading() {
2367   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2368   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2369     _unloader.prepare();
2370   }
2371 }
2372 
2373 void ShenandoahHeap::finish_concurrent_unloading() {
2374   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2375   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2376     _unloader.finish();
2377   }
2378 }
2379 
2380 #ifdef ASSERT
2381 void ShenandoahHeap::assert_gc_workers(uint nworkers) {
2382   assert(nworkers &gt; 0 &amp;&amp; nworkers &lt;= max_workers(), &quot;Sanity&quot;);
2383 
2384   if (ShenandoahSafepoint::is_at_shenandoah_safepoint()) {
<span class="line-modified">2385     if (UseDynamicNumberOfGCThreads ||</span>
<span class="line-removed">2386         (FLAG_IS_DEFAULT(ParallelGCThreads) &amp;&amp; ForceDynamicNumberOfGCThreads)) {</span>
2387       assert(nworkers &lt;= ParallelGCThreads, &quot;Cannot use more than it has&quot;);
2388     } else {
2389       // Use ParallelGCThreads inside safepoints
<span class="line-modified">2390       assert(nworkers == ParallelGCThreads, &quot;Use ParalleGCThreads within safepoints&quot;);</span>
2391     }
2392   } else {
<span class="line-modified">2393     if (UseDynamicNumberOfGCThreads ||</span>
<span class="line-removed">2394         (FLAG_IS_DEFAULT(ConcGCThreads) &amp;&amp; ForceDynamicNumberOfGCThreads)) {</span>
2395       assert(nworkers &lt;= ConcGCThreads, &quot;Cannot use more than it has&quot;);
2396     } else {
2397       // Use ConcGCThreads outside safepoints
2398       assert(nworkers == ConcGCThreads, &quot;Use ConcGCThreads outside safepoints&quot;);
2399     }
2400   }
2401 }
2402 #endif
2403 
2404 ShenandoahVerifier* ShenandoahHeap::verifier() {
2405   guarantee(ShenandoahVerify, &quot;Should be enabled&quot;);
2406   assert (_verifier != NULL, &quot;sanity&quot;);
2407   return _verifier;
2408 }
2409 
2410 template&lt;class T&gt;
2411 class ShenandoahUpdateHeapRefsTask : public AbstractGangTask {
2412 private:
2413   T cl;
2414   ShenandoahHeap* _heap;
</pre>
<hr />
<pre>
2422     _regions(regions),
2423     _concurrent(concurrent) {
2424   }
2425 
2426   void work(uint worker_id) {
2427     if (_concurrent) {
2428       ShenandoahConcurrentWorkerSession worker_session(worker_id);
2429       ShenandoahSuspendibleThreadSetJoiner stsj(ShenandoahSuspendibleWorkers);
2430       do_work();
2431     } else {
2432       ShenandoahParallelWorkerSession worker_session(worker_id);
2433       do_work();
2434     }
2435   }
2436 
2437 private:
2438   void do_work() {
2439     ShenandoahHeapRegion* r = _regions-&gt;next();
2440     ShenandoahMarkingContext* const ctx = _heap-&gt;complete_marking_context();
2441     while (r != NULL) {
<span class="line-modified">2442       HeapWord* top_at_start_ur = r-&gt;concurrent_iteration_safe_limit();</span>
<span class="line-modified">2443       assert (top_at_start_ur &gt;= r-&gt;bottom(), &quot;sanity&quot;);</span>
2444       if (r-&gt;is_active() &amp;&amp; !r-&gt;is_cset()) {
<span class="line-modified">2445         _heap-&gt;marked_object_oop_iterate(r, &amp;cl, top_at_start_ur);</span>
2446       }
2447       if (ShenandoahPacing) {
<span class="line-modified">2448         _heap-&gt;pacer()-&gt;report_updaterefs(pointer_delta(top_at_start_ur, r-&gt;bottom()));</span>
2449       }
2450       if (_heap-&gt;check_cancelled_gc_and_yield(_concurrent)) {
2451         return;
2452       }
2453       r = _regions-&gt;next();
2454     }
2455   }
2456 };
2457 
2458 void ShenandoahHeap::update_heap_references(bool concurrent) {
2459   ShenandoahUpdateHeapRefsTask&lt;ShenandoahUpdateHeapRefsClosure&gt; task(&amp;_update_refs_iterator, concurrent);
2460   workers()-&gt;run_task(&amp;task);
2461 }
2462 
2463 void ShenandoahHeap::op_init_updaterefs() {
2464   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;must be at safepoint&quot;);
2465 
2466   set_evacuation_in_progress(false);
2467 
2468   {
2469     ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_retire_gclabs);
2470     retire_and_reset_gclabs();
2471   }
2472 
2473   if (ShenandoahVerify) {
2474     if (!is_degenerated_gc_in_progress()) {
2475       verifier()-&gt;verify_roots_in_to_space_except(ShenandoahRootVerifier::ThreadRoots);
2476     }
2477     verifier()-&gt;verify_before_updaterefs();
2478   }
2479 
2480   set_update_refs_in_progress(true);
2481 
2482   {
2483     ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_prepare);
2484 
2485     make_parsable(true);
<span class="line-removed">2486     for (uint i = 0; i &lt; num_regions(); i++) {</span>
<span class="line-removed">2487       ShenandoahHeapRegion* r = get_region(i);</span>
<span class="line-removed">2488       r-&gt;set_concurrent_iteration_safe_limit(r-&gt;top());</span>
<span class="line-removed">2489     }</span>
2490 
2491     // Reset iterator.
2492     _update_refs_iterator.reset();
2493   }
2494 
2495   if (ShenandoahPacing) {
2496     pacer()-&gt;setup_for_updaterefs();
2497   }
2498 }
2499 
2500 void ShenandoahHeap::op_final_updaterefs() {
2501   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;must be at safepoint&quot;);
2502 
2503   finish_concurrent_unloading();
2504 
2505   // Check if there is left-over work, and finish it
2506   if (_update_refs_iterator.has_next()) {
2507     ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_finish_work);
2508 
2509     // Finish updating references where we left off.
</pre>
<hr />
<pre>
2659 void ShenandoahHeap::vmop_entry_init_mark() {
2660   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2661   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2662   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_mark_gross);
2663 
2664   try_inject_alloc_failure();
2665   VM_ShenandoahInitMark op;
2666   VMThread::execute(&amp;op); // jump to entry_init_mark() under safepoint
2667 }
2668 
2669 void ShenandoahHeap::vmop_entry_final_mark() {
2670   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2671   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2672   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_mark_gross);
2673 
2674   try_inject_alloc_failure();
2675   VM_ShenandoahFinalMarkStartEvac op;
2676   VMThread::execute(&amp;op); // jump to entry_final_mark under safepoint
2677 }
2678 
<span class="line-removed">2679 void ShenandoahHeap::vmop_entry_final_evac() {</span>
<span class="line-removed">2680   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());</span>
<span class="line-removed">2681   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);</span>
<span class="line-removed">2682   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_evac_gross);</span>
<span class="line-removed">2683 </span>
<span class="line-removed">2684   VM_ShenandoahFinalEvac op;</span>
<span class="line-removed">2685   VMThread::execute(&amp;op); // jump to entry_final_evac under safepoint</span>
<span class="line-removed">2686 }</span>
<span class="line-removed">2687 </span>
2688 void ShenandoahHeap::vmop_entry_init_updaterefs() {
2689   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2690   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2691   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_gross);
2692 
2693   try_inject_alloc_failure();
2694   VM_ShenandoahInitUpdateRefs op;
2695   VMThread::execute(&amp;op);
2696 }
2697 
2698 void ShenandoahHeap::vmop_entry_final_updaterefs() {
2699   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2700   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2701   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_gross);
2702 
2703   try_inject_alloc_failure();
2704   VM_ShenandoahFinalUpdateRefs op;
2705   VMThread::execute(&amp;op);
2706 }
2707 
</pre>
<hr />
<pre>
2755                               ShenandoahWorkerPolicy::calc_workers_for_init_marking(),
2756                               &quot;init marking&quot;);
2757 
2758   op_init_mark();
2759 }
2760 
2761 void ShenandoahHeap::entry_final_mark() {
2762   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2763   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_mark);
2764   const char* msg = final_mark_event_message();
2765   GCTraceTime(Info, gc) time(msg, gc_timer());
2766   EventMark em(&quot;%s&quot;, msg);
2767 
2768   ShenandoahWorkerScope scope(workers(),
2769                               ShenandoahWorkerPolicy::calc_workers_for_final_marking(),
2770                               &quot;final marking&quot;);
2771 
2772   op_final_mark();
2773 }
2774 
<span class="line-removed">2775 void ShenandoahHeap::entry_final_evac() {</span>
<span class="line-removed">2776   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);</span>
<span class="line-removed">2777   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_evac);</span>
<span class="line-removed">2778   static const char* msg = &quot;Pause Final Evac&quot;;</span>
<span class="line-removed">2779   GCTraceTime(Info, gc) time(msg, gc_timer());</span>
<span class="line-removed">2780   EventMark em(&quot;%s&quot;, msg);</span>
<span class="line-removed">2781 </span>
<span class="line-removed">2782   op_final_evac();</span>
<span class="line-removed">2783 }</span>
<span class="line-removed">2784 </span>
2785 void ShenandoahHeap::entry_init_updaterefs() {
2786   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2787   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs);
2788 
2789   static const char* msg = &quot;Pause Init Update Refs&quot;;
2790   GCTraceTime(Info, gc) time(msg, gc_timer());
2791   EventMark em(&quot;%s&quot;, msg);
2792 
2793   // No workers used in this phase, no setup required
2794 
2795   op_init_updaterefs();
2796 }
2797 
2798 void ShenandoahHeap::entry_final_updaterefs() {
2799   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2800   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs);
2801 
2802   static const char* msg = &quot;Pause Final Update Refs&quot;;
2803   GCTraceTime(Info, gc) time(msg, gc_timer());
2804   EventMark em(&quot;%s&quot;, msg);
</pre>
<hr />
<pre>
3062   _index = 0;
3063 }
3064 
3065 bool ShenandoahRegionIterator::has_next() const {
3066   return _index &lt; _heap-&gt;num_regions();
3067 }
3068 
3069 char ShenandoahHeap::gc_state() const {
3070   return _gc_state.raw_value();
3071 }
3072 
3073 void ShenandoahHeap::deduplicate_string(oop str) {
3074   assert(java_lang_String::is_instance(str), &quot;invariant&quot;);
3075 
3076   if (ShenandoahStringDedup::is_enabled()) {
3077     ShenandoahStringDedup::deduplicate(str);
3078   }
3079 }
3080 
3081 const char* ShenandoahHeap::init_mark_event_message() const {
<span class="line-modified">3082   bool update_refs = has_forwarded_objects();</span>

3083   bool proc_refs = process_references();
3084   bool unload_cls = unload_classes();
3085 
<span class="line-modified">3086   if (update_refs &amp;&amp; proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3087     return &quot;Pause Init Mark (update refs) (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3088   } else if (update_refs &amp;&amp; proc_refs) {</span>
<span class="line-removed">3089     return &quot;Pause Init Mark (update refs) (process weakrefs)&quot;;</span>
<span class="line-removed">3090   } else if (update_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3091     return &quot;Pause Init Mark (update refs) (unload classes)&quot;;</span>
<span class="line-removed">3092   } else if (proc_refs &amp;&amp; unload_cls) {</span>
3093     return &quot;Pause Init Mark (process weakrefs) (unload classes)&quot;;
<span class="line-removed">3094   } else if (update_refs) {</span>
<span class="line-removed">3095     return &quot;Pause Init Mark (update refs)&quot;;</span>
3096   } else if (proc_refs) {
3097     return &quot;Pause Init Mark (process weakrefs)&quot;;
3098   } else if (unload_cls) {
3099     return &quot;Pause Init Mark (unload classes)&quot;;
3100   } else {
3101     return &quot;Pause Init Mark&quot;;
3102   }
3103 }
3104 
3105 const char* ShenandoahHeap::final_mark_event_message() const {
<span class="line-modified">3106   bool update_refs = has_forwarded_objects();</span>

3107   bool proc_refs = process_references();
3108   bool unload_cls = unload_classes();
3109 
<span class="line-modified">3110   if (update_refs &amp;&amp; proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3111     return &quot;Pause Final Mark (update refs) (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3112   } else if (update_refs &amp;&amp; proc_refs) {</span>
<span class="line-removed">3113     return &quot;Pause Final Mark (update refs) (process weakrefs)&quot;;</span>
<span class="line-removed">3114   } else if (update_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3115     return &quot;Pause Final Mark (update refs) (unload classes)&quot;;</span>
<span class="line-removed">3116   } else if (proc_refs &amp;&amp; unload_cls) {</span>
3117     return &quot;Pause Final Mark (process weakrefs) (unload classes)&quot;;
<span class="line-removed">3118   } else if (update_refs) {</span>
<span class="line-removed">3119     return &quot;Pause Final Mark (update refs)&quot;;</span>
3120   } else if (proc_refs) {
3121     return &quot;Pause Final Mark (process weakrefs)&quot;;
3122   } else if (unload_cls) {
3123     return &quot;Pause Final Mark (unload classes)&quot;;
3124   } else {
3125     return &quot;Pause Final Mark&quot;;
3126   }
3127 }
3128 
3129 const char* ShenandoahHeap::conc_mark_event_message() const {
<span class="line-modified">3130   bool update_refs = has_forwarded_objects();</span>

3131   bool proc_refs = process_references();
3132   bool unload_cls = unload_classes();
3133 
<span class="line-modified">3134   if (update_refs &amp;&amp; proc_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3135     return &quot;Concurrent marking (update refs) (process weakrefs) (unload classes)&quot;;</span>
<span class="line-removed">3136   } else if (update_refs &amp;&amp; proc_refs) {</span>
<span class="line-removed">3137     return &quot;Concurrent marking (update refs) (process weakrefs)&quot;;</span>
<span class="line-removed">3138   } else if (update_refs &amp;&amp; unload_cls) {</span>
<span class="line-removed">3139     return &quot;Concurrent marking (update refs) (unload classes)&quot;;</span>
<span class="line-removed">3140   } else if (proc_refs &amp;&amp; unload_cls) {</span>
3141     return &quot;Concurrent marking (process weakrefs) (unload classes)&quot;;
<span class="line-removed">3142   } else if (update_refs) {</span>
<span class="line-removed">3143     return &quot;Concurrent marking (update refs)&quot;;</span>
3144   } else if (proc_refs) {
3145     return &quot;Concurrent marking (process weakrefs)&quot;;
3146   } else if (unload_cls) {
3147     return &quot;Concurrent marking (unload classes)&quot;;
3148   } else {
3149     return &quot;Concurrent marking&quot;;
3150   }
3151 }
3152 
3153 const char* ShenandoahHeap::init_traversal_event_message() const {
3154   bool proc_refs = process_references();
3155   bool unload_cls = unload_classes();
3156 
3157   if (proc_refs &amp;&amp; unload_cls) {
3158     return &quot;Pause Init Traversal (process weakrefs) (unload classes)&quot;;
3159   } else if (proc_refs) {
3160     return &quot;Pause Init Traversal (process weakrefs)&quot;;
3161   } else if (unload_cls) {
3162     return &quot;Pause Init Traversal (unload classes)&quot;;
3163   } else {
</pre>
</td>
<td>
<hr />
<pre>
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;memory/allocation.hpp&quot;
  27 #include &quot;memory/universe.hpp&quot;
  28 
  29 #include &quot;gc/shared/gcArguments.hpp&quot;
  30 #include &quot;gc/shared/gcTimer.hpp&quot;
  31 #include &quot;gc/shared/gcTraceTime.inline.hpp&quot;
  32 #include &quot;gc/shared/locationPrinter.inline.hpp&quot;
  33 #include &quot;gc/shared/memAllocator.hpp&quot;
  34 #include &quot;gc/shared/oopStorageSet.hpp&quot;
  35 #include &quot;gc/shared/plab.hpp&quot;
  36 

  37 #include &quot;gc/shenandoah/shenandoahBarrierSet.hpp&quot;
  38 #include &quot;gc/shenandoah/shenandoahClosures.inline.hpp&quot;
  39 #include &quot;gc/shenandoah/shenandoahCollectionSet.hpp&quot;
  40 #include &quot;gc/shenandoah/shenandoahCollectorPolicy.hpp&quot;
  41 #include &quot;gc/shenandoah/shenandoahConcurrentMark.inline.hpp&quot;
  42 #include &quot;gc/shenandoah/shenandoahConcurrentRoots.hpp&quot;
  43 #include &quot;gc/shenandoah/shenandoahControlThread.hpp&quot;
  44 #include &quot;gc/shenandoah/shenandoahFreeSet.hpp&quot;
  45 #include &quot;gc/shenandoah/shenandoahPhaseTimings.hpp&quot;
  46 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
  47 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;
  48 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.hpp&quot;
  49 #include &quot;gc/shenandoah/shenandoahMarkCompact.hpp&quot;
  50 #include &quot;gc/shenandoah/shenandoahMarkingContext.inline.hpp&quot;
  51 #include &quot;gc/shenandoah/shenandoahMemoryPool.hpp&quot;
  52 #include &quot;gc/shenandoah/shenandoahMetrics.hpp&quot;
  53 #include &quot;gc/shenandoah/shenandoahMonitoringSupport.hpp&quot;
  54 #include &quot;gc/shenandoah/shenandoahNormalMode.hpp&quot;
  55 #include &quot;gc/shenandoah/shenandoahOopClosures.inline.hpp&quot;
  56 #include &quot;gc/shenandoah/shenandoahPacer.inline.hpp&quot;
</pre>
<hr />
<pre>
  62 #include &quot;gc/shenandoah/shenandoahTraversalMode.hpp&quot;
  63 #include &quot;gc/shenandoah/shenandoahUtils.hpp&quot;
  64 #include &quot;gc/shenandoah/shenandoahVerifier.hpp&quot;
  65 #include &quot;gc/shenandoah/shenandoahCodeRoots.hpp&quot;
  66 #include &quot;gc/shenandoah/shenandoahVMOperations.hpp&quot;
  67 #include &quot;gc/shenandoah/shenandoahWorkGroup.hpp&quot;
  68 #include &quot;gc/shenandoah/shenandoahWorkerPolicy.hpp&quot;
  69 #if INCLUDE_JFR
  70 #include &quot;gc/shenandoah/shenandoahJfrSupport.hpp&quot;
  71 #endif
  72 
  73 #include &quot;memory/metaspace.hpp&quot;
  74 #include &quot;oops/compressedOops.inline.hpp&quot;
  75 #include &quot;runtime/atomic.hpp&quot;
  76 #include &quot;runtime/globals.hpp&quot;
  77 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  78 #include &quot;runtime/orderAccess.hpp&quot;
  79 #include &quot;runtime/safepointMechanism.hpp&quot;
  80 #include &quot;runtime/vmThread.hpp&quot;
  81 #include &quot;services/mallocTracker.hpp&quot;
<span class="line-added">  82 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  83 
  84 #ifdef ASSERT
  85 template &lt;class T&gt;
  86 void ShenandoahAssertToSpaceClosure::do_oop_work(T* p) {
  87   T o = RawAccess&lt;&gt;::oop_load(p);
  88   if (! CompressedOops::is_null(o)) {
  89     oop obj = CompressedOops::decode_not_null(o);
  90     shenandoah_assert_not_forwarded(p, obj);
  91   }
  92 }
  93 
  94 void ShenandoahAssertToSpaceClosure::do_oop(narrowOop* p) { do_oop_work(p); }
  95 void ShenandoahAssertToSpaceClosure::do_oop(oop* p)       { do_oop_work(p); }
  96 #endif
  97 
  98 class ShenandoahPretouchHeapTask : public AbstractGangTask {
  99 private:
 100   ShenandoahRegionIterator _regions;
 101   const size_t _page_size;
 102 public:
</pre>
<hr />
<pre>
 343 
 344   _liveness_cache = NEW_C_HEAP_ARRAY(jushort*, _max_workers, mtGC);
 345   for (uint worker = 0; worker &lt; _max_workers; worker++) {
 346     _liveness_cache[worker] = NEW_C_HEAP_ARRAY(jushort, _num_regions, mtGC);
 347     Copy::fill_to_bytes(_liveness_cache[worker], _num_regions * sizeof(jushort));
 348   }
 349 
 350   // There should probably be Shenandoah-specific options for these,
 351   // just as there are G1-specific options.
 352   {
 353     ShenandoahSATBMarkQueueSet&amp; satbqs = ShenandoahBarrierSet::satb_mark_queue_set();
 354     satbqs.set_process_completed_buffers_threshold(20); // G1SATBProcessCompletedThreshold
 355     satbqs.set_buffer_enqueue_threshold_percentage(60); // G1SATBBufferEnqueueingThresholdPercent
 356   }
 357 
 358   _monitoring_support = new ShenandoahMonitoringSupport(this);
 359   _phase_timings = new ShenandoahPhaseTimings();
 360   ShenandoahStringDedup::initialize();
 361   ShenandoahCodeRoots::initialize();
 362 




 363   if (ShenandoahPacing) {
 364     _pacer = new ShenandoahPacer(this);
 365     _pacer-&gt;setup_for_idle();
 366   } else {
 367     _pacer = NULL;
 368   }
 369 
 370   _traversal_gc = strcmp(ShenandoahGCMode, &quot;traversal&quot;) == 0 ?
 371                   new ShenandoahTraversalGC(this, _num_regions) :
 372                   NULL;
 373 
 374   _control_thread = new ShenandoahControlThread();
 375 
 376   log_info(gc, init)(&quot;Initialize Shenandoah heap: &quot; SIZE_FORMAT &quot;%s initial, &quot; SIZE_FORMAT &quot;%s min, &quot; SIZE_FORMAT &quot;%s max&quot;,
 377                      byte_size_in_proper_unit(_initial_size),  proper_unit_for_byte_size(_initial_size),
 378                      byte_size_in_proper_unit(_minimum_size),  proper_unit_for_byte_size(_minimum_size),
 379                      byte_size_in_proper_unit(max_capacity()), proper_unit_for_byte_size(max_capacity())
 380   );
 381 
 382   log_info(gc, init)(&quot;Safepointing mechanism: %s&quot;,
</pre>
<hr />
<pre>
 427   _initial_size(0),
 428   _used(0),
 429   _committed(0),
 430   _bytes_allocated_since_gc_start(0),
 431   _max_workers(MAX2(ConcGCThreads, ParallelGCThreads)),
 432   _workers(NULL),
 433   _safepoint_workers(NULL),
 434   _heap_region_special(false),
 435   _num_regions(0),
 436   _regions(NULL),
 437   _update_refs_iterator(this),
 438   _control_thread(NULL),
 439   _shenandoah_policy(policy),
 440   _heuristics(NULL),
 441   _free_set(NULL),
 442   _scm(new ShenandoahConcurrentMark()),
 443   _traversal_gc(NULL),
 444   _full_gc(new ShenandoahMarkCompact()),
 445   _pacer(NULL),
 446   _verifier(NULL),

 447   _phase_timings(NULL),
 448   _monitoring_support(NULL),
 449   _memory_pool(NULL),
 450   _stw_memory_manager(&quot;Shenandoah Pauses&quot;, &quot;end of GC pause&quot;),
 451   _cycle_memory_manager(&quot;Shenandoah Cycles&quot;, &quot;end of GC cycle&quot;),
 452   _gc_timer(new (ResourceObj::C_HEAP, mtGC) ConcurrentGCTimer()),
 453   _soft_ref_policy(),
 454   _log_min_obj_alignment_in_bytes(LogMinObjAlignmentInBytes),
 455   _ref_processor(NULL),
 456   _marking_context(NULL),
 457   _bitmap_size(0),
 458   _bitmap_regions_per_slice(0),
 459   _bitmap_bytes_per_slice(0),
 460   _bitmap_region_special(false),
 461   _aux_bitmap_region_special(false),
 462   _liveness_cache(NULL),
 463   _collection_set(NULL)
 464 {
 465   log_info(gc, init)(&quot;GC threads: &quot; UINT32_FORMAT &quot; parallel, &quot; UINT32_FORMAT &quot; concurrent&quot;, ParallelGCThreads, ConcGCThreads);
 466   log_info(gc, init)(&quot;Reference processing: %s&quot;, ParallelRefProcEnabled ? &quot;parallel&quot; : &quot;serial&quot;);
 467 
 468   BarrierSet::set_barrier_set(new ShenandoahBarrierSet(this));
 469 
 470   _max_workers = MAX2(_max_workers, 1U);
 471   _workers = new ShenandoahWorkGang(&quot;Shenandoah GC Threads&quot;, _max_workers,
 472                             /* are_GC_task_threads */ true,
 473                             /* are_ConcurrentGC_threads */ true);
 474   if (_workers == NULL) {
 475     vm_exit_during_initialization(&quot;Failed necessary allocation.&quot;);
 476   } else {
 477     _workers-&gt;initialize_workers();
 478   }
 479 
<span class="line-modified"> 480   if (ParallelGCThreads &gt; 1) {</span>
 481     _safepoint_workers = new ShenandoahWorkGang(&quot;Safepoint Cleanup Thread&quot;,
<span class="line-modified"> 482                                                 ParallelGCThreads,</span>
 483                       /* are_GC_task_threads */ false,
 484                  /* are_ConcurrentGC_threads */ false);
 485     _safepoint_workers-&gt;initialize_workers();
 486   }
 487 }
 488 
 489 #ifdef _MSC_VER
 490 #pragma warning( pop )
 491 #endif
 492 
 493 class ShenandoahResetBitmapTask : public AbstractGangTask {
 494 private:
 495   ShenandoahRegionIterator _regions;
 496 
 497 public:
 498   ShenandoahResetBitmapTask() :
 499     AbstractGangTask(&quot;Parallel Reset Bitmap Task&quot;) {}
 500 
 501   void work(uint worker_id) {
 502     ShenandoahHeapRegion* region = _regions.next();
</pre>
<hr />
<pre>
 774     *actual_size = req.actual_size();
 775   } else {
 776     *actual_size = 0;
 777   }
 778   return res;
 779 }
 780 
 781 ShenandoahHeap* ShenandoahHeap::heap() {
 782   CollectedHeap* heap = Universe::heap();
 783   assert(heap != NULL, &quot;Unitialized access to ShenandoahHeap::heap()&quot;);
 784   assert(heap-&gt;kind() == CollectedHeap::Shenandoah, &quot;not a shenandoah heap&quot;);
 785   return (ShenandoahHeap*) heap;
 786 }
 787 
 788 ShenandoahHeap* ShenandoahHeap::heap_no_check() {
 789   CollectedHeap* heap = Universe::heap();
 790   return (ShenandoahHeap*) heap;
 791 }
 792 
 793 HeapWord* ShenandoahHeap::allocate_memory(ShenandoahAllocRequest&amp; req) {


 794   intptr_t pacer_epoch = 0;
 795   bool in_new_region = false;
 796   HeapWord* result = NULL;
 797 
 798   if (req.is_mutator_alloc()) {
 799     if (ShenandoahPacing) {
 800       pacer()-&gt;pace_for_alloc(req.size());
 801       pacer_epoch = pacer()-&gt;epoch();
 802     }
 803 
 804     if (!ShenandoahAllocFailureALot || !should_inject_alloc_failure()) {
 805       result = allocate_memory_under_lock(req, in_new_region);
 806     }
 807 
 808     // Allocation failed, block until control thread reacted, then retry allocation.
 809     //
 810     // It might happen that one of the threads requesting allocation would unblock
 811     // way later after GC happened, only to fail the second allocation, because
 812     // other threads have already depleted the free storage. In this case, a better
 813     // strategy is to try again, as long as GC makes progress.
</pre>
<hr />
<pre>
1177   if (lt.is_enabled()) {
1178     ResourceMark rm;
1179     LogStream ls(lt);
1180 
1181     phase_timings()-&gt;print_on(&amp;ls);
1182 
1183     ls.cr();
1184     ls.cr();
1185 
1186     shenandoah_policy()-&gt;print_gc_stats(&amp;ls);
1187 
1188     ls.cr();
1189     ls.cr();
1190 
1191     if (ShenandoahPacing) {
1192       pacer()-&gt;print_on(&amp;ls);
1193     }
1194 
1195     ls.cr();
1196     ls.cr();







1197   }
1198 }
1199 
1200 void ShenandoahHeap::verify(VerifyOption vo) {
1201   if (ShenandoahSafepoint::is_at_shenandoah_safepoint()) {
1202     if (ShenandoahVerify) {
1203       verifier()-&gt;verify_generic(vo);
1204     } else {
1205       // TODO: Consider allocating verification bitmaps on demand,
1206       // and turn this on unconditionally.
1207     }
1208   }
1209 }
1210 size_t ShenandoahHeap::tlab_capacity(Thread *thr) const {
1211   return _free_set-&gt;capacity();
1212 }
1213 
1214 class ObjectIterateScanRootClosure : public BasicOopIterateClosure {
1215 private:
1216   MarkBitMap* _bitmap;
1217   Stack&lt;oop,mtGC&gt;* _oop_stack;
<span class="line-added">1218   ShenandoahHeap* const _heap;</span>
<span class="line-added">1219   ShenandoahMarkingContext* const _marking_context;</span>
1220 
1221   template &lt;class T&gt;
1222   void do_oop_work(T* p) {
1223     T o = RawAccess&lt;&gt;::oop_load(p);
1224     if (!CompressedOops::is_null(o)) {
1225       oop obj = CompressedOops::decode_not_null(o);
<span class="line-modified">1226       if (_heap-&gt;is_concurrent_root_in_progress() &amp;&amp; !_marking_context-&gt;is_marked(obj)) {</span>
<span class="line-modified">1227         // There may be dead oops in weak roots in concurrent root phase, do not touch them.</span>
<span class="line-modified">1228         return;</span>












1229       }
<span class="line-added">1230       obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);</span>
<span class="line-added">1231 </span>
1232       assert(oopDesc::is_oop(obj), &quot;must be a valid oop&quot;);
1233       if (!_bitmap-&gt;is_marked(obj)) {
1234         _bitmap-&gt;mark(obj);
1235         _oop_stack-&gt;push(obj);
1236       }
1237     }
1238   }
1239 public:
1240   ObjectIterateScanRootClosure(MarkBitMap* bitmap, Stack&lt;oop,mtGC&gt;* oop_stack) :
<span class="line-modified">1241     _bitmap(bitmap), _oop_stack(oop_stack), _heap(ShenandoahHeap::heap()),</span>
<span class="line-added">1242     _marking_context(_heap-&gt;marking_context()) {}</span>
1243   void do_oop(oop* p)       { do_oop_work(p); }
1244   void do_oop(narrowOop* p) { do_oop_work(p); }
1245 };
1246 
1247 /*
1248  * This is public API, used in preparation of object_iterate().
1249  * Since we don&#39;t do linear scan of heap in object_iterate() (see comment below), we don&#39;t
1250  * need to make the heap parsable. For Shenandoah-internal linear heap scans that we can
1251  * control, we call SH::make_tlabs_parsable().
1252  */
1253 void ShenandoahHeap::ensure_parsability(bool retire_tlabs) {
1254   // No-op.
1255 }
1256 
1257 /*
1258  * Iterates objects in the heap. This is public API, used for, e.g., heap dumping.
1259  *
1260  * We cannot safely iterate objects by doing a linear scan at random points in time. Linear
1261  * scanning needs to deal with dead objects, which may have dead Klass* pointers (e.g.
1262  * calling oopDesc::size() would crash) or dangling reference fields (crashes) etc. Linear
</pre>
<hr />
<pre>
1268  * For all those reasons, we implement object iteration as a single marking traversal, reporting
1269  * objects as we mark+traverse through the heap, starting from GC roots. JVMTI IterateThroughHeap
1270  * is allowed to report dead objects, but is not required to do so.
1271  */
1272 void ShenandoahHeap::object_iterate(ObjectClosure* cl) {
1273   assert(SafepointSynchronize::is_at_safepoint(), &quot;safe iteration is only available during safepoints&quot;);
1274   if (!_aux_bitmap_region_special &amp;&amp; !os::commit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size(), false)) {
1275     log_warning(gc)(&quot;Could not commit native memory for auxiliary marking bitmap for heap iteration&quot;);
1276     return;
1277   }
1278 
1279   // Reset bitmap
1280   _aux_bit_map.clear();
1281 
1282   Stack&lt;oop,mtGC&gt; oop_stack;
1283 
1284   // First, we process GC roots according to current GC cycle. This populates the work stack with initial objects.
1285   ShenandoahHeapIterationRootScanner rp;
1286   ObjectIterateScanRootClosure oops(&amp;_aux_bit_map, &amp;oop_stack);
1287 
<span class="line-modified">1288   rp.roots_do(&amp;oops);</span>






1289 
1290   // Work through the oop stack to traverse heap.
1291   while (! oop_stack.is_empty()) {
1292     oop obj = oop_stack.pop();
1293     assert(oopDesc::is_oop(obj), &quot;must be a valid oop&quot;);
1294     cl-&gt;do_object(obj);
1295     obj-&gt;oop_iterate(&amp;oops);
1296   }
1297 
1298   assert(oop_stack.is_empty(), &quot;should be empty&quot;);
1299 
1300   if (!_aux_bitmap_region_special &amp;&amp; !os::uncommit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size())) {
1301     log_warning(gc)(&quot;Could not uncommit native memory for auxiliary marking bitmap for heap iteration&quot;);
1302   }
1303 }
1304 
1305 // Keep alive an object that was loaded with AS_NO_KEEPALIVE.
1306 void ShenandoahHeap::keep_alive(oop obj) {
1307   if (is_concurrent_mark_in_progress()) {
1308     ShenandoahBarrierSet::barrier_set()-&gt;enqueue(obj);
</pre>
<hr />
<pre>
1367   void heap_region_do(ShenandoahHeapRegion* r) {
1368     if (r-&gt;is_active()) {
1369       r-&gt;clear_live_data();
1370       _ctx-&gt;capture_top_at_mark_start(r);
1371     } else {
1372       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;region_number());
1373       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
1374              &quot;Region &quot; SIZE_FORMAT &quot; should already have correct TAMS&quot;, r-&gt;region_number());
1375     }
1376   }
1377 
1378   bool is_thread_safe() { return true; }
1379 };
1380 
1381 void ShenandoahHeap::op_init_mark() {
1382   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);
1383   assert(Thread::current()-&gt;is_VM_thread(), &quot;can only do this in VMThread&quot;);
1384 
1385   assert(marking_context()-&gt;is_bitmap_clear(), &quot;need clear marking bitmap&quot;);
1386   assert(!marking_context()-&gt;is_complete(), &quot;should not be complete&quot;);
<span class="line-added">1387   assert(!has_forwarded_objects(), &quot;No forwarded objects on this path&quot;);</span>
1388 
1389   if (ShenandoahVerify) {
1390     verifier()-&gt;verify_before_concmark();
1391   }
1392 
1393   if (VerifyBeforeGC) {
1394     Universe::verify();
1395   }
1396 
1397   set_concurrent_mark_in_progress(true);
1398   // We need to reset all TLABs because we&#39;d lose marks on all objects allocated in them.
1399   {
1400     ShenandoahGCPhase phase(ShenandoahPhaseTimings::make_parsable);
1401     make_parsable(true);
1402   }
1403 
1404   {
1405     ShenandoahGCPhase phase(ShenandoahPhaseTimings::clear_liveness);
1406     ShenandoahClearLivenessClosure clc;
1407     parallel_heap_region_iterate(&amp;clc);
1408   }
1409 
1410   // Make above changes visible to worker threads
1411   OrderAccess::fence();
1412 
1413   concurrent_mark()-&gt;mark_roots(ShenandoahPhaseTimings::scan_roots);
1414 
1415   if (UseTLAB) {
1416     ShenandoahGCPhase phase(ShenandoahPhaseTimings::resize_tlabs);
1417     resize_tlabs();
1418   }
1419 
1420   if (ShenandoahPacing) {
1421     pacer()-&gt;setup_for_mark();
1422   }
<span class="line-added">1423 </span>
<span class="line-added">1424   // Arm nmethods for concurrent marking. When a nmethod is about to be executed,</span>
<span class="line-added">1425   // we need to make sure that all its metadata are marked. alternative is to remark</span>
<span class="line-added">1426   // thread roots at final mark pause, but it can be potential latency killer.</span>
<span class="line-added">1427   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {</span>
<span class="line-added">1428     ShenandoahCodeRoots::arm_nmethods();</span>
<span class="line-added">1429   }</span>
1430 }
1431 
1432 void ShenandoahHeap::op_mark() {
1433   concurrent_mark()-&gt;mark_from_roots();
1434 }
1435 
1436 class ShenandoahCompleteLivenessClosure : public ShenandoahHeapRegionClosure {
1437 private:
1438   ShenandoahMarkingContext* const _ctx;
1439 public:
1440   ShenandoahCompleteLivenessClosure() : _ctx(ShenandoahHeap::heap()-&gt;complete_marking_context()) {}
1441 
1442   void heap_region_do(ShenandoahHeapRegion* r) {
1443     if (r-&gt;is_active()) {
1444       HeapWord *tams = _ctx-&gt;top_at_mark_start(r);
1445       HeapWord *top = r-&gt;top();
1446       if (top &gt; tams) {
1447         r-&gt;increase_live_data_alloc_words(pointer_delta(top, tams));
1448       }
1449     } else {
1450       assert(!r-&gt;has_live(), &quot;Region &quot; SIZE_FORMAT &quot; should have no live data&quot;, r-&gt;region_number());
1451       assert(_ctx-&gt;top_at_mark_start(r) == r-&gt;top(),
1452              &quot;Region &quot; SIZE_FORMAT &quot; should have correct TAMS&quot;, r-&gt;region_number());
1453     }
1454   }
1455 
1456   bool is_thread_safe() { return true; }
1457 };
1458 
1459 void ShenandoahHeap::op_final_mark() {
1460   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;Should be at safepoint&quot;);
<span class="line-added">1461   assert(!has_forwarded_objects(), &quot;No forwarded objects on this path&quot;);</span>
1462 
1463   // It is critical that we
1464   // evacuate roots right after finishing marking, so that we don&#39;t
1465   // get unmarked objects in the roots.
1466 
1467   if (!cancelled_gc()) {
1468     concurrent_mark()-&gt;finish_mark_from_roots(/* full_gc = */ false);
1469 
1470     // Marking is completed, deactivate SATB barrier
1471     set_concurrent_mark_in_progress(false);
1472     mark_complete_marking_context();
1473 
1474     parallel_cleaning(false /* full gc*/);
1475 










1476     if (ShenandoahVerify) {
1477       verifier()-&gt;verify_roots_no_forwarded();
1478     }
1479     // All allocations past TAMS are implicitly live, adjust the region data.
1480     // Bitmaps/TAMS are swapped at this point, so we need to poll complete bitmap.
1481     {
1482       ShenandoahGCPhase phase(ShenandoahPhaseTimings::complete_liveness);
1483       ShenandoahCompleteLivenessClosure cl;
1484       parallel_heap_region_iterate(&amp;cl);
1485     }
1486 
1487     // Force the threads to reacquire their TLABs outside the collection set.
1488     {
1489       ShenandoahGCPhase phase(ShenandoahPhaseTimings::retire_tlabs);
1490       make_parsable(true);
1491     }
1492 
1493     // We are about to select the collection set, make sure it knows about
1494     // current pinning status. Also, this allows trashing more regions that
1495     // now have their pinning status dropped.
</pre>
<hr />
<pre>
1513 
1514       heuristics()-&gt;choose_collection_set(_collection_set);
1515 
1516       _free_set-&gt;rebuild();
1517     }
1518 
1519     if (!is_degenerated_gc_in_progress()) {
1520       prepare_concurrent_roots();
1521       prepare_concurrent_unloading();
1522     }
1523 
1524     // If collection set has candidates, start evacuation.
1525     // Otherwise, bypass the rest of the cycle.
1526     if (!collection_set()-&gt;is_empty()) {
1527       ShenandoahGCPhase init_evac(ShenandoahPhaseTimings::init_evac);
1528 
1529       if (ShenandoahVerify) {
1530         verifier()-&gt;verify_before_evacuation();
1531       }
1532 
<span class="line-added">1533       // Remember limit for updating refs. It&#39;s guaranteed that we get no from-space-refs written</span>
<span class="line-added">1534       // from here on.</span>
<span class="line-added">1535       for (uint i = 0; i &lt; num_regions(); i++) {</span>
<span class="line-added">1536         ShenandoahHeapRegion* r = get_region(i);</span>
<span class="line-added">1537         r-&gt;set_update_watermark(r-&gt;top());</span>
<span class="line-added">1538       }</span>
<span class="line-added">1539 </span>
1540       set_evacuation_in_progress(true);
1541       // From here on, we need to update references.
1542       set_has_forwarded_objects(true);
1543 
1544       if (!is_degenerated_gc_in_progress()) {
1545         if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
1546           ShenandoahCodeRoots::arm_nmethods();
1547         }
1548         evacuate_and_update_roots();
1549       }
1550 
1551       if (ShenandoahPacing) {
1552         pacer()-&gt;setup_for_evac();
1553       }
1554 
1555       if (ShenandoahVerify) {
1556         ShenandoahRootVerifier::RootTypes types = ShenandoahRootVerifier::None;
1557         if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {
1558           types = ShenandoahRootVerifier::combine(ShenandoahRootVerifier::JNIHandleRoots, ShenandoahRootVerifier::WeakRoots);
1559           types = ShenandoahRootVerifier::combine(types, ShenandoahRootVerifier::CLDGRoots);
</pre>
<hr />
<pre>
1575         Universe::verify();
1576       }
1577     }
1578 
1579   } else {
1580     // If this cycle was updating references, we need to keep the has_forwarded_objects
1581     // flag on, for subsequent phases to deal with it.
1582     concurrent_mark()-&gt;cancel();
1583     set_concurrent_mark_in_progress(false);
1584 
1585     if (process_references()) {
1586       // Abandon reference processing right away: pre-cleaning must have failed.
1587       ReferenceProcessor *rp = ref_processor();
1588       rp-&gt;disable_discovery();
1589       rp-&gt;abandon_partial_discovery();
1590       rp-&gt;verify_no_references_recorded();
1591     }
1592   }
1593 }
1594 



















1595 void ShenandoahHeap::op_conc_evac() {
1596   ShenandoahEvacuationTask task(this, _collection_set, true);
1597   workers()-&gt;run_task(&amp;task);
1598 }
1599 
1600 void ShenandoahHeap::op_stw_evac() {
1601   ShenandoahEvacuationTask task(this, _collection_set, false);
1602   workers()-&gt;run_task(&amp;task);
1603 }
1604 
1605 void ShenandoahHeap::op_updaterefs() {
1606   update_heap_references(true);
1607 }
1608 
1609 void ShenandoahHeap::op_cleanup() {
1610   free_set()-&gt;recycle_trash();
1611 }
1612 
1613 class ShenandoahConcurrentRootsEvacUpdateTask : public AbstractGangTask {
1614 private:
</pre>
<hr />
<pre>
1756 void ShenandoahHeap::op_roots() {
1757   if (is_concurrent_root_in_progress()) {
1758     if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
1759       // Concurrent weak root processing
1760       ShenandoahConcurrentWeakRootsEvacUpdateTask task;
1761       workers()-&gt;run_task(&amp;task);
1762 
1763       _unloader.unload();
1764     }
1765 
1766     if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {
1767       ShenandoahConcurrentRootsEvacUpdateTask task(!ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
1768       workers()-&gt;run_task(&amp;task);
1769     }
1770   }
1771 
1772   set_concurrent_root_in_progress(false);
1773 }
1774 
1775 void ShenandoahHeap::op_reset() {
<span class="line-added">1776   if (ShenandoahPacing) {</span>
<span class="line-added">1777     pacer()-&gt;setup_for_reset();</span>
<span class="line-added">1778   }</span>
1779   reset_mark_bitmap();
1780 }
1781 
1782 void ShenandoahHeap::op_preclean() {
<span class="line-added">1783   if (ShenandoahPacing) {</span>
<span class="line-added">1784     pacer()-&gt;setup_for_preclean();</span>
<span class="line-added">1785   }</span>
1786   concurrent_mark()-&gt;preclean_weak_refs();
1787 }
1788 
1789 void ShenandoahHeap::op_init_traversal() {
1790   traversal_gc()-&gt;init_traversal_collection();
1791 }
1792 
1793 void ShenandoahHeap::op_traversal() {
1794   traversal_gc()-&gt;concurrent_traversal_collection();
1795 }
1796 
1797 void ShenandoahHeap::op_final_traversal() {
1798   traversal_gc()-&gt;final_traversal_collection();
1799 }
1800 
1801 void ShenandoahHeap::op_full(GCCause::Cause cause) {
1802   ShenandoahMetricsSnapshot metrics;
1803   metrics.snap_before();
1804 
1805   full_gc()-&gt;do_it(cause);
</pre>
<hr />
<pre>
1869         cancel_gc(GCCause::_shenandoah_upgrade_to_full_gc);
1870         op_degenerated_fail();
1871         return;
1872       }
1873 
1874       op_reset();
1875 
1876       op_init_mark();
1877       if (cancelled_gc()) {
1878         op_degenerated_fail();
1879         return;
1880       }
1881 
1882     case _degenerated_mark:
1883       op_final_mark();
1884       if (cancelled_gc()) {
1885         op_degenerated_fail();
1886         return;
1887       }
1888 
<span class="line-added">1889       if (!has_forwarded_objects() &amp;&amp; ShenandoahConcurrentRoots::can_do_concurrent_class_unloading()) {</span>
<span class="line-added">1890         // Disarm nmethods that armed for concurrent mark. On normal cycle, it would</span>
<span class="line-added">1891         // be disarmed while conc-roots phase is running.</span>
<span class="line-added">1892         // TODO: Call op_conc_roots() here instead</span>
<span class="line-added">1893         ShenandoahCodeRoots::disarm_nmethods();</span>
<span class="line-added">1894       }</span>
<span class="line-added">1895 </span>
1896       op_cleanup();
1897 
1898     case _degenerated_evac:
1899       // If heuristics thinks we should do the cycle, this flag would be set,
1900       // and we can do evacuation. Otherwise, it would be the shortcut cycle.
1901       if (is_evacuation_in_progress()) {
1902 
1903         // Degeneration under oom-evac protocol might have left some objects in
1904         // collection set un-evacuated. Restart evacuation from the beginning to
1905         // capture all objects. For all the objects that are already evacuated,
1906         // it would be a simple check, which is supposed to be fast. This is also
1907         // safe to do even without degeneration, as CSet iterator is at beginning
1908         // in preparation for evacuation anyway.
1909         //
1910         // Before doing that, we need to make sure we never had any cset-pinned
1911         // regions. This may happen if allocation failure happened when evacuating
1912         // the about-to-be-pinned object, oom-evac protocol left the object in
1913         // the collection set, and then the pin reached the cset region. If we continue
1914         // the cycle here, we would trash the cset and alive objects in it. To avoid
1915         // it, we fail degeneration right away and slide into Full GC to recover.
</pre>
<hr />
<pre>
2152                             ShenandoahPhaseTimings::purge_cldg);
2153     ClassLoaderDataGraph::purge();
2154   }
2155   // Resize and verify metaspace
2156   MetaspaceGC::compute_new_size();
2157   MetaspaceUtils::verify_metrics();
2158 }
2159 
2160 // Weak roots are either pre-evacuated (final mark) or updated (final updaterefs),
2161 // so they should not have forwarded oops.
2162 // However, we do need to &quot;null&quot; dead oops in the roots, if can not be done
2163 // in concurrent cycles.
2164 void ShenandoahHeap::stw_process_weak_roots(bool full_gc) {
2165   ShenandoahGCPhase root_phase(full_gc ?
2166                                ShenandoahPhaseTimings::full_gc_purge :
2167                                ShenandoahPhaseTimings::purge);
2168   uint num_workers = _workers-&gt;active_workers();
2169   ShenandoahPhaseTimings::Phase timing_phase = full_gc ?
2170                                                ShenandoahPhaseTimings::full_gc_purge_par :
2171                                                ShenandoahPhaseTimings::purge_par;

2172   ShenandoahGCPhase phase(timing_phase);
<span class="line-modified">2173   ShenandoahGCWorkerPhase worker_phase(timing_phase);</span>
<span class="line-added">2174 </span>
<span class="line-added">2175   // Cleanup weak roots</span>
2176   if (has_forwarded_objects()) {
<span class="line-modified">2177     ShenandoahForwardedIsAliveClosure is_alive;</span>
<span class="line-modified">2178     ShenandoahUpdateRefsClosure keep_alive;</span>
<span class="line-modified">2179     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahForwardedIsAliveClosure, ShenandoahUpdateRefsClosure&gt;</span>
<span class="line-modified">2180       cleaning_task(&amp;is_alive, &amp;keep_alive, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());</span>
<span class="line-modified">2181     _workers-&gt;run_task(&amp;cleaning_task);</span>








2182   } else {
2183     ShenandoahIsAliveClosure is_alive;
2184 #ifdef ASSERT
2185     ShenandoahAssertNotForwardedClosure verify_cl;
2186     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahIsAliveClosure, ShenandoahAssertNotForwardedClosure&gt;
2187       cleaning_task(&amp;is_alive, &amp;verify_cl, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
2188 #else
2189     ShenandoahParallelWeakRootsCleaningTask&lt;ShenandoahIsAliveClosure, DoNothingClosure&gt;
2190       cleaning_task(&amp;is_alive, &amp;do_nothing_cl, num_workers, !ShenandoahConcurrentRoots::should_do_concurrent_class_unloading());
2191 #endif
2192     _workers-&gt;run_task(&amp;cleaning_task);
2193   }

2194 }
2195 
2196 void ShenandoahHeap::parallel_cleaning(bool full_gc) {
2197   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2198   stw_process_weak_roots(full_gc);
2199   if (!ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2200     stw_unload_classes(full_gc);
2201   }
2202 }
2203 
2204 void ShenandoahHeap::set_has_forwarded_objects(bool cond) {
2205   if (is_traversal_mode()) {
2206     set_gc_state_mask(HAS_FORWARDED | UPDATEREFS, cond);
2207   } else {
2208     set_gc_state_mask(HAS_FORWARDED, cond);
2209   }
2210 
2211 }
2212 
2213 void ShenandoahHeap::set_process_references(bool pr) {
</pre>
<hr />
<pre>
2330 
2331 void ShenandoahHeap::prepare_concurrent_unloading() {
2332   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2333   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2334     _unloader.prepare();
2335   }
2336 }
2337 
2338 void ShenandoahHeap::finish_concurrent_unloading() {
2339   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at a safepoint&quot;);
2340   if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {
2341     _unloader.finish();
2342   }
2343 }
2344 
2345 #ifdef ASSERT
2346 void ShenandoahHeap::assert_gc_workers(uint nworkers) {
2347   assert(nworkers &gt; 0 &amp;&amp; nworkers &lt;= max_workers(), &quot;Sanity&quot;);
2348 
2349   if (ShenandoahSafepoint::is_at_shenandoah_safepoint()) {
<span class="line-modified">2350     if (UseDynamicNumberOfGCThreads) {</span>

2351       assert(nworkers &lt;= ParallelGCThreads, &quot;Cannot use more than it has&quot;);
2352     } else {
2353       // Use ParallelGCThreads inside safepoints
<span class="line-modified">2354       assert(nworkers == ParallelGCThreads, &quot;Use ParallelGCThreads within safepoints&quot;);</span>
2355     }
2356   } else {
<span class="line-modified">2357     if (UseDynamicNumberOfGCThreads) {</span>

2358       assert(nworkers &lt;= ConcGCThreads, &quot;Cannot use more than it has&quot;);
2359     } else {
2360       // Use ConcGCThreads outside safepoints
2361       assert(nworkers == ConcGCThreads, &quot;Use ConcGCThreads outside safepoints&quot;);
2362     }
2363   }
2364 }
2365 #endif
2366 
2367 ShenandoahVerifier* ShenandoahHeap::verifier() {
2368   guarantee(ShenandoahVerify, &quot;Should be enabled&quot;);
2369   assert (_verifier != NULL, &quot;sanity&quot;);
2370   return _verifier;
2371 }
2372 
2373 template&lt;class T&gt;
2374 class ShenandoahUpdateHeapRefsTask : public AbstractGangTask {
2375 private:
2376   T cl;
2377   ShenandoahHeap* _heap;
</pre>
<hr />
<pre>
2385     _regions(regions),
2386     _concurrent(concurrent) {
2387   }
2388 
2389   void work(uint worker_id) {
2390     if (_concurrent) {
2391       ShenandoahConcurrentWorkerSession worker_session(worker_id);
2392       ShenandoahSuspendibleThreadSetJoiner stsj(ShenandoahSuspendibleWorkers);
2393       do_work();
2394     } else {
2395       ShenandoahParallelWorkerSession worker_session(worker_id);
2396       do_work();
2397     }
2398   }
2399 
2400 private:
2401   void do_work() {
2402     ShenandoahHeapRegion* r = _regions-&gt;next();
2403     ShenandoahMarkingContext* const ctx = _heap-&gt;complete_marking_context();
2404     while (r != NULL) {
<span class="line-modified">2405       HeapWord* update_watermark = r-&gt;get_update_watermark();</span>
<span class="line-modified">2406       assert (update_watermark &gt;= r-&gt;bottom(), &quot;sanity&quot;);</span>
2407       if (r-&gt;is_active() &amp;&amp; !r-&gt;is_cset()) {
<span class="line-modified">2408         _heap-&gt;marked_object_oop_iterate(r, &amp;cl, update_watermark);</span>
2409       }
2410       if (ShenandoahPacing) {
<span class="line-modified">2411         _heap-&gt;pacer()-&gt;report_updaterefs(pointer_delta(update_watermark, r-&gt;bottom()));</span>
2412       }
2413       if (_heap-&gt;check_cancelled_gc_and_yield(_concurrent)) {
2414         return;
2415       }
2416       r = _regions-&gt;next();
2417     }
2418   }
2419 };
2420 
2421 void ShenandoahHeap::update_heap_references(bool concurrent) {
2422   ShenandoahUpdateHeapRefsTask&lt;ShenandoahUpdateHeapRefsClosure&gt; task(&amp;_update_refs_iterator, concurrent);
2423   workers()-&gt;run_task(&amp;task);
2424 }
2425 
2426 void ShenandoahHeap::op_init_updaterefs() {
2427   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;must be at safepoint&quot;);
2428 
2429   set_evacuation_in_progress(false);
2430 
2431   {
2432     ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_retire_gclabs);
2433     retire_and_reset_gclabs();
2434   }
2435 
2436   if (ShenandoahVerify) {
2437     if (!is_degenerated_gc_in_progress()) {
2438       verifier()-&gt;verify_roots_in_to_space_except(ShenandoahRootVerifier::ThreadRoots);
2439     }
2440     verifier()-&gt;verify_before_updaterefs();
2441   }
2442 
2443   set_update_refs_in_progress(true);
2444 
2445   {
2446     ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_prepare);
2447 
2448     make_parsable(true);




2449 
2450     // Reset iterator.
2451     _update_refs_iterator.reset();
2452   }
2453 
2454   if (ShenandoahPacing) {
2455     pacer()-&gt;setup_for_updaterefs();
2456   }
2457 }
2458 
2459 void ShenandoahHeap::op_final_updaterefs() {
2460   assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), &quot;must be at safepoint&quot;);
2461 
2462   finish_concurrent_unloading();
2463 
2464   // Check if there is left-over work, and finish it
2465   if (_update_refs_iterator.has_next()) {
2466     ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_finish_work);
2467 
2468     // Finish updating references where we left off.
</pre>
<hr />
<pre>
2618 void ShenandoahHeap::vmop_entry_init_mark() {
2619   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2620   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2621   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_mark_gross);
2622 
2623   try_inject_alloc_failure();
2624   VM_ShenandoahInitMark op;
2625   VMThread::execute(&amp;op); // jump to entry_init_mark() under safepoint
2626 }
2627 
2628 void ShenandoahHeap::vmop_entry_final_mark() {
2629   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2630   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2631   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_mark_gross);
2632 
2633   try_inject_alloc_failure();
2634   VM_ShenandoahFinalMarkStartEvac op;
2635   VMThread::execute(&amp;op); // jump to entry_final_mark under safepoint
2636 }
2637 









2638 void ShenandoahHeap::vmop_entry_init_updaterefs() {
2639   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2640   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2641   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs_gross);
2642 
2643   try_inject_alloc_failure();
2644   VM_ShenandoahInitUpdateRefs op;
2645   VMThread::execute(&amp;op);
2646 }
2647 
2648 void ShenandoahHeap::vmop_entry_final_updaterefs() {
2649   TraceCollectorStats tcs(monitoring_support()-&gt;stw_collection_counters());
2650   ShenandoahGCPhase total(ShenandoahPhaseTimings::total_pause_gross);
2651   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs_gross);
2652 
2653   try_inject_alloc_failure();
2654   VM_ShenandoahFinalUpdateRefs op;
2655   VMThread::execute(&amp;op);
2656 }
2657 
</pre>
<hr />
<pre>
2705                               ShenandoahWorkerPolicy::calc_workers_for_init_marking(),
2706                               &quot;init marking&quot;);
2707 
2708   op_init_mark();
2709 }
2710 
2711 void ShenandoahHeap::entry_final_mark() {
2712   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2713   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_mark);
2714   const char* msg = final_mark_event_message();
2715   GCTraceTime(Info, gc) time(msg, gc_timer());
2716   EventMark em(&quot;%s&quot;, msg);
2717 
2718   ShenandoahWorkerScope scope(workers(),
2719                               ShenandoahWorkerPolicy::calc_workers_for_final_marking(),
2720                               &quot;final marking&quot;);
2721 
2722   op_final_mark();
2723 }
2724 










2725 void ShenandoahHeap::entry_init_updaterefs() {
2726   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2727   ShenandoahGCPhase phase(ShenandoahPhaseTimings::init_update_refs);
2728 
2729   static const char* msg = &quot;Pause Init Update Refs&quot;;
2730   GCTraceTime(Info, gc) time(msg, gc_timer());
2731   EventMark em(&quot;%s&quot;, msg);
2732 
2733   // No workers used in this phase, no setup required
2734 
2735   op_init_updaterefs();
2736 }
2737 
2738 void ShenandoahHeap::entry_final_updaterefs() {
2739   ShenandoahGCPhase total_phase(ShenandoahPhaseTimings::total_pause);
2740   ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_refs);
2741 
2742   static const char* msg = &quot;Pause Final Update Refs&quot;;
2743   GCTraceTime(Info, gc) time(msg, gc_timer());
2744   EventMark em(&quot;%s&quot;, msg);
</pre>
<hr />
<pre>
3002   _index = 0;
3003 }
3004 
3005 bool ShenandoahRegionIterator::has_next() const {
3006   return _index &lt; _heap-&gt;num_regions();
3007 }
3008 
3009 char ShenandoahHeap::gc_state() const {
3010   return _gc_state.raw_value();
3011 }
3012 
3013 void ShenandoahHeap::deduplicate_string(oop str) {
3014   assert(java_lang_String::is_instance(str), &quot;invariant&quot;);
3015 
3016   if (ShenandoahStringDedup::is_enabled()) {
3017     ShenandoahStringDedup::deduplicate(str);
3018   }
3019 }
3020 
3021 const char* ShenandoahHeap::init_mark_event_message() const {
<span class="line-modified">3022   assert(!has_forwarded_objects(), &quot;Should not have forwarded objects here&quot;);</span>
<span class="line-added">3023 </span>
3024   bool proc_refs = process_references();
3025   bool unload_cls = unload_classes();
3026 
<span class="line-modified">3027   if (proc_refs &amp;&amp; unload_cls) {</span>






3028     return &quot;Pause Init Mark (process weakrefs) (unload classes)&quot;;


3029   } else if (proc_refs) {
3030     return &quot;Pause Init Mark (process weakrefs)&quot;;
3031   } else if (unload_cls) {
3032     return &quot;Pause Init Mark (unload classes)&quot;;
3033   } else {
3034     return &quot;Pause Init Mark&quot;;
3035   }
3036 }
3037 
3038 const char* ShenandoahHeap::final_mark_event_message() const {
<span class="line-modified">3039   assert(!has_forwarded_objects(), &quot;Should not have forwarded objects here&quot;);</span>
<span class="line-added">3040 </span>
3041   bool proc_refs = process_references();
3042   bool unload_cls = unload_classes();
3043 
<span class="line-modified">3044   if (proc_refs &amp;&amp; unload_cls) {</span>






3045     return &quot;Pause Final Mark (process weakrefs) (unload classes)&quot;;


3046   } else if (proc_refs) {
3047     return &quot;Pause Final Mark (process weakrefs)&quot;;
3048   } else if (unload_cls) {
3049     return &quot;Pause Final Mark (unload classes)&quot;;
3050   } else {
3051     return &quot;Pause Final Mark&quot;;
3052   }
3053 }
3054 
3055 const char* ShenandoahHeap::conc_mark_event_message() const {
<span class="line-modified">3056   assert(!has_forwarded_objects(), &quot;Should not have forwarded objects here&quot;);</span>
<span class="line-added">3057 </span>
3058   bool proc_refs = process_references();
3059   bool unload_cls = unload_classes();
3060 
<span class="line-modified">3061   if (proc_refs &amp;&amp; unload_cls) {</span>






3062     return &quot;Concurrent marking (process weakrefs) (unload classes)&quot;;


3063   } else if (proc_refs) {
3064     return &quot;Concurrent marking (process weakrefs)&quot;;
3065   } else if (unload_cls) {
3066     return &quot;Concurrent marking (unload classes)&quot;;
3067   } else {
3068     return &quot;Concurrent marking&quot;;
3069   }
3070 }
3071 
3072 const char* ShenandoahHeap::init_traversal_event_message() const {
3073   bool proc_refs = process_references();
3074   bool unload_cls = unload_classes();
3075 
3076   if (proc_refs &amp;&amp; unload_cls) {
3077     return &quot;Pause Init Traversal (process weakrefs) (unload classes)&quot;;
3078   } else if (proc_refs) {
3079     return &quot;Pause Init Traversal (process weakrefs)&quot;;
3080   } else if (unload_cls) {
3081     return &quot;Pause Init Traversal (unload classes)&quot;;
3082   } else {
</pre>
</td>
</tr>
</table>
<center><a href="shenandoahFreeSet.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="shenandoahHeap.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>