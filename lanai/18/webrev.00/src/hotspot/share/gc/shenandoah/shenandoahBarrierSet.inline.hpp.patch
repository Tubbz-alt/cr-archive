diff a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
--- a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
+++ b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
@@ -47,10 +47,14 @@
   } else {
     return p;
   }
 }
 
+inline oop ShenandoahBarrierSet::resolve_forwarded_not_null_mutator(oop p) {
+  return ShenandoahForwarding::get_forwardee_mutator(p);
+}
+
 inline void ShenandoahBarrierSet::enqueue(oop obj) {
   shenandoah_assert_not_forwarded_if(NULL, obj, _heap->is_concurrent_traversal_in_progress());
   assert(_satb_mark_queue_set.is_active(), "only get here when SATB active");
 
   // Filter marked objects before hitting the SATB queues. The same predicate would
@@ -259,21 +263,22 @@
   return Raw::oop_arraycopy_in_heap(src_obj, src_offset_in_bytes, src_raw, dst_obj, dst_offset_in_bytes, dst_raw, length);
 }
 
 template <class T, bool HAS_FWD, bool EVAC, bool ENQUEUE>
 void ShenandoahBarrierSet::arraycopy_work(T* src, size_t count) {
+  assert(HAS_FWD == _heap->has_forwarded_objects(), "Forwarded object status is sane");
+
   Thread* thread = Thread::current();
   SATBMarkQueue& queue = ShenandoahThreadLocalData::satb_mark_queue(thread);
   ShenandoahMarkingContext* ctx = _heap->marking_context();
   const ShenandoahCollectionSet* const cset = _heap->collection_set();
   T* end = src + count;
   for (T* elem_ptr = src; elem_ptr < end; elem_ptr++) {
     T o = RawAccess<>::oop_load(elem_ptr);
     if (!CompressedOops::is_null(o)) {
       oop obj = CompressedOops::decode_not_null(o);
       if (HAS_FWD && cset->is_in(obj)) {
-        assert(_heap->has_forwarded_objects(), "only get here with forwarded objects");
         oop fwd = resolve_forwarded_not_null(obj);
         if (EVAC && obj == fwd) {
           fwd = _heap->evacuate_object(obj, thread);
         }
         assert(obj != fwd || _heap->cancelled_gc(), "must be forwarded");
@@ -287,31 +292,35 @@
   }
 }
 
 template <class T>
 void ShenandoahBarrierSet::arraycopy_pre_work(T* src, T* dst, size_t count) {
-  if (_heap->is_concurrent_mark_in_progress()) {
-    if (_heap->has_forwarded_objects()) {
-      arraycopy_work<T, true, false, true>(dst, count);
-    } else {
-      arraycopy_work<T, false, false, true>(dst, count);
-    }
+  if (_heap->is_concurrent_mark_in_progress() &&
+      !_heap->marking_context()->allocated_after_mark_start(reinterpret_cast<HeapWord*>(dst))) {
+    arraycopy_work<T, false, false, true>(dst, count);
   }
 
-  arraycopy_update_impl(src, count);
+  if (_heap->has_forwarded_objects()) {
+    arraycopy_update_impl(src, count);
+  }
 }
 
 void ShenandoahBarrierSet::arraycopy_pre(oop* src, oop* dst, size_t count) {
   arraycopy_pre_work(src, dst, count);
 }
 
 void ShenandoahBarrierSet::arraycopy_pre(narrowOop* src, narrowOop* dst, size_t count) {
   arraycopy_pre_work(src, dst, count);
 }
 
+inline bool ShenandoahBarrierSet::skip_bulk_update(HeapWord* dst) {
+  return dst >= _heap->heap_region_containing(dst)->get_update_watermark();
+}
+
 template <class T>
 void ShenandoahBarrierSet::arraycopy_update_impl(T* src, size_t count) {
+  if (skip_bulk_update(reinterpret_cast<HeapWord*>(src))) return;
   if (_heap->is_evacuation_in_progress()) {
     ShenandoahEvacOOMScope oom_evac;
     arraycopy_work<T, true, true, false>(src, count);
   } else if (_heap->is_concurrent_traversal_in_progress()){
     ShenandoahEvacOOMScope oom_evac;
