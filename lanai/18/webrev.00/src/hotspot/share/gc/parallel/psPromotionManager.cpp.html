<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/gc/parallel/psPromotionManager.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2002, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;classfile/javaClasses.inline.hpp&quot;
 27 #include &quot;gc/parallel/mutableSpace.hpp&quot;
 28 #include &quot;gc/parallel/parallelScavengeHeap.hpp&quot;
 29 #include &quot;gc/parallel/psOldGen.hpp&quot;
 30 #include &quot;gc/parallel/psPromotionManager.inline.hpp&quot;
 31 #include &quot;gc/parallel/psScavenge.inline.hpp&quot;
 32 #include &quot;gc/shared/gcTrace.hpp&quot;
 33 #include &quot;gc/shared/preservedMarks.inline.hpp&quot;
 34 #include &quot;gc/shared/taskqueue.inline.hpp&quot;
 35 #include &quot;logging/log.hpp&quot;
 36 #include &quot;logging/logStream.hpp&quot;
 37 #include &quot;memory/allocation.inline.hpp&quot;
 38 #include &quot;memory/iterator.inline.hpp&quot;
 39 #include &quot;memory/memRegion.hpp&quot;
 40 #include &quot;memory/padded.inline.hpp&quot;
 41 #include &quot;memory/resourceArea.hpp&quot;
 42 #include &quot;oops/access.inline.hpp&quot;
 43 #include &quot;oops/compressedOops.inline.hpp&quot;
 44 
 45 PaddedEnd&lt;PSPromotionManager&gt;* PSPromotionManager::_manager_array = NULL;
 46 PSPromotionManager::OopStarTaskQueueSet* PSPromotionManager::_stack_array_depth = NULL;
 47 PreservedMarksSet*             PSPromotionManager::_preserved_marks_set = NULL;
 48 PSOldGen*                      PSPromotionManager::_old_gen = NULL;
 49 MutableSpace*                  PSPromotionManager::_young_space = NULL;
 50 
 51 void PSPromotionManager::initialize() {
 52   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
 53 
 54   _old_gen = heap-&gt;old_gen();
 55   _young_space = heap-&gt;young_gen()-&gt;to_space();
 56 
 57   const uint promotion_manager_num = ParallelGCThreads + 1;
 58 
 59   // To prevent false sharing, we pad the PSPromotionManagers
 60   // and make sure that the first instance starts at a cache line.
 61   assert(_manager_array == NULL, &quot;Attempt to initialize twice&quot;);
 62   _manager_array = PaddedArray&lt;PSPromotionManager, mtGC&gt;::create_unfreeable(promotion_manager_num);
 63 
 64   _stack_array_depth = new OopStarTaskQueueSet(ParallelGCThreads);
 65 
 66   // Create and register the PSPromotionManager(s) for the worker threads.
 67   for(uint i=0; i&lt;ParallelGCThreads; i++) {
 68     stack_array_depth()-&gt;register_queue(i, _manager_array[i].claimed_stack_depth());
 69   }
 70   // The VMThread gets its own PSPromotionManager, which is not available
 71   // for work stealing.
 72 
 73   assert(_preserved_marks_set == NULL, &quot;Attempt to initialize twice&quot;);
 74   _preserved_marks_set = new PreservedMarksSet(true /* in_c_heap */);
 75   _preserved_marks_set-&gt;init(promotion_manager_num);
 76   for (uint i = 0; i &lt; promotion_manager_num; i += 1) {
 77     _manager_array[i].register_preserved_marks(_preserved_marks_set-&gt;get(i));
 78   }
 79 }
 80 
 81 // Helper functions to get around the circular dependency between
 82 // psScavenge.inline.hpp and psPromotionManager.inline.hpp.
 83 bool PSPromotionManager::should_scavenge(oop* p, bool check_to_space) {
 84   return PSScavenge::should_scavenge(p, check_to_space);
 85 }
 86 bool PSPromotionManager::should_scavenge(narrowOop* p, bool check_to_space) {
 87   return PSScavenge::should_scavenge(p, check_to_space);
 88 }
 89 
 90 PSPromotionManager* PSPromotionManager::gc_thread_promotion_manager(uint index) {
 91   assert(index &lt; ParallelGCThreads, &quot;index out of range&quot;);
 92   assert(_manager_array != NULL, &quot;Sanity&quot;);
 93   return &amp;_manager_array[index];
 94 }
 95 
 96 PSPromotionManager* PSPromotionManager::vm_thread_promotion_manager() {
 97   assert(_manager_array != NULL, &quot;Sanity&quot;);
 98   return &amp;_manager_array[ParallelGCThreads];
 99 }
100 
101 void PSPromotionManager::pre_scavenge() {
102   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
103 
104   _preserved_marks_set-&gt;assert_empty();
105   _young_space = heap-&gt;young_gen()-&gt;to_space();
106 
107   for(uint i=0; i&lt;ParallelGCThreads+1; i++) {
108     manager_array(i)-&gt;reset();
109   }
110 }
111 
112 bool PSPromotionManager::post_scavenge(YoungGCTracer&amp; gc_tracer) {
113   bool promotion_failure_occurred = false;
114 
115   TASKQUEUE_STATS_ONLY(print_taskqueue_stats());
116   for (uint i = 0; i &lt; ParallelGCThreads + 1; i++) {
117     PSPromotionManager* manager = manager_array(i);
118     assert(manager-&gt;claimed_stack_depth()-&gt;is_empty(), &quot;should be empty&quot;);
119     if (manager-&gt;_promotion_failed_info.has_failed()) {
120       gc_tracer.report_promotion_failed(manager-&gt;_promotion_failed_info);
121       promotion_failure_occurred = true;
122     }
123     manager-&gt;flush_labs();
124   }
125   if (!promotion_failure_occurred) {
126     // If there was no promotion failure, the preserved mark stacks
127     // should be empty.
128     _preserved_marks_set-&gt;assert_empty();
129   }
130   return promotion_failure_occurred;
131 }
132 
133 #if TASKQUEUE_STATS
134 void
135 PSPromotionManager::print_local_stats(outputStream* const out, uint i) const {
136   #define FMT &quot; &quot; SIZE_FORMAT_W(10)
137   out-&gt;print_cr(&quot;%3u&quot; FMT FMT FMT FMT, i, _masked_pushes, _masked_steals,
138                 _arrays_chunked, _array_chunks_processed);
139   #undef FMT
140 }
141 
142 static const char* const pm_stats_hdr[] = {
143   &quot;    --------masked-------     arrays      array&quot;,
144   &quot;thr       push      steal    chunked     chunks&quot;,
145   &quot;--- ---------- ---------- ---------- ----------&quot;
146 };
147 
148 void
149 PSPromotionManager::print_taskqueue_stats() {
150   if (!log_is_enabled(Trace, gc, task, stats)) {
151     return;
152   }
153   Log(gc, task, stats) log;
154   ResourceMark rm;
155   LogStream ls(log.trace());
156   outputStream* out = &amp;ls;
157   out-&gt;print_cr(&quot;== GC Tasks Stats, GC %3d&quot;,
158                 ParallelScavengeHeap::heap()-&gt;total_collections());
159 
160   TaskQueueStats totals;
161   out-&gt;print(&quot;thr &quot;); TaskQueueStats::print_header(1, out); out-&gt;cr();
162   out-&gt;print(&quot;--- &quot;); TaskQueueStats::print_header(2, out); out-&gt;cr();
163   for (uint i = 0; i &lt; ParallelGCThreads + 1; ++i) {
164     TaskQueueStats&amp; next = manager_array(i)-&gt;_claimed_stack_depth.stats;
165     out-&gt;print(&quot;%3d &quot;, i); next.print(out); out-&gt;cr();
166     totals += next;
167   }
168   out-&gt;print(&quot;tot &quot;); totals.print(out); out-&gt;cr();
169 
170   const uint hlines = sizeof(pm_stats_hdr) / sizeof(pm_stats_hdr[0]);
171   for (uint i = 0; i &lt; hlines; ++i) out-&gt;print_cr(&quot;%s&quot;, pm_stats_hdr[i]);
172   for (uint i = 0; i &lt; ParallelGCThreads + 1; ++i) {
173     manager_array(i)-&gt;print_local_stats(out, i);
174   }
175 }
176 
177 void
178 PSPromotionManager::reset_stats() {
179   claimed_stack_depth()-&gt;stats.reset();
180   _masked_pushes = _masked_steals = 0;
181   _arrays_chunked = _array_chunks_processed = 0;
182 }
183 #endif // TASKQUEUE_STATS
184 
185 PSPromotionManager::PSPromotionManager() {
186   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
187 
188   // We set the old lab&#39;s start array.
189   _old_lab.set_start_array(old_gen()-&gt;start_array());
190 
191   uint queue_size;
192   claimed_stack_depth()-&gt;initialize();
193   queue_size = claimed_stack_depth()-&gt;max_elems();
194 
195   _totally_drain = (ParallelGCThreads == 1) || (GCDrainStackTargetSize == 0);
196   if (_totally_drain) {
197     _target_stack_size = 0;
198   } else {
199     // don&#39;t let the target stack size to be more than 1/4 of the entries
200     _target_stack_size = (uint) MIN2((uint) GCDrainStackTargetSize,
201                                      (uint) (queue_size / 4));
202   }
203 
204   _array_chunk_size = ParGCArrayScanChunk;
205   // let&#39;s choose 1.5x the chunk size
206   _min_array_size_for_chunking = 3 * _array_chunk_size / 2;
207 
208   _preserved_marks = NULL;
209 
210   reset();
211 }
212 
213 void PSPromotionManager::reset() {
214   assert(stacks_empty(), &quot;reset of non-empty stack&quot;);
215 
216   // We need to get an assert in here to make sure the labs are always flushed.
217 
218   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
219 
220   // Do not prefill the LAB&#39;s, save heap wastage!
221   HeapWord* lab_base = young_space()-&gt;top();
222   _young_lab.initialize(MemRegion(lab_base, (size_t)0));
223   _young_gen_is_full = false;
224 
225   lab_base = old_gen()-&gt;object_space()-&gt;top();
226   _old_lab.initialize(MemRegion(lab_base, (size_t)0));
227   _old_gen_is_full = false;
228 
229   _promotion_failed_info.reset();
230 
231   TASKQUEUE_STATS_ONLY(reset_stats());
232 }
233 
234 void PSPromotionManager::register_preserved_marks(PreservedMarks* preserved_marks) {
235   assert(_preserved_marks == NULL, &quot;do not set it twice&quot;);
236   _preserved_marks = preserved_marks;
237 }
238 
239 void PSPromotionManager::restore_preserved_marks() {
240   _preserved_marks_set-&gt;restore(&amp;ParallelScavengeHeap::heap()-&gt;workers());
241 }
242 
243 void PSPromotionManager::drain_stacks_depth(bool totally_drain) {
244   totally_drain = totally_drain || _totally_drain;
245 
246 #ifdef ASSERT
247   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
248   MutableSpace* to_space = heap-&gt;young_gen()-&gt;to_space();
249   MutableSpace* old_space = heap-&gt;old_gen()-&gt;object_space();
250 #endif /* ASSERT */
251 
252   OopStarTaskQueue* const tq = claimed_stack_depth();
253   do {
254     StarTask p;
255 
256     // Drain overflow stack first, so other threads can steal from
257     // claimed stack while we work.
258     while (tq-&gt;pop_overflow(p)) {
259       process_popped_location_depth(p);
260     }
261 
262     if (totally_drain) {
263       while (tq-&gt;pop_local(p)) {
264         process_popped_location_depth(p);
265       }
266     } else {
267       while (tq-&gt;size() &gt; _target_stack_size &amp;&amp; tq-&gt;pop_local(p)) {
268         process_popped_location_depth(p);
269       }
270     }
271   } while ((totally_drain &amp;&amp; !tq-&gt;taskqueue_empty()) || !tq-&gt;overflow_empty());
272 
273   assert(!totally_drain || tq-&gt;taskqueue_empty(), &quot;Sanity&quot;);
274   assert(totally_drain || tq-&gt;size() &lt;= _target_stack_size, &quot;Sanity&quot;);
275   assert(tq-&gt;overflow_empty(), &quot;Sanity&quot;);
276 }
277 
278 void PSPromotionManager::flush_labs() {
279   assert(stacks_empty(), &quot;Attempt to flush lab with live stack&quot;);
280 
281   // If either promotion lab fills up, we can flush the
282   // lab but not refill it, so check first.
283   assert(!_young_lab.is_flushed() || _young_gen_is_full, &quot;Sanity&quot;);
284   if (!_young_lab.is_flushed())
285     _young_lab.flush();
286 
287   assert(!_old_lab.is_flushed() || _old_gen_is_full, &quot;Sanity&quot;);
288   if (!_old_lab.is_flushed())
289     _old_lab.flush();
290 
291   // Let PSScavenge know if we overflowed
292   if (_young_gen_is_full) {
293     PSScavenge::set_survivor_overflow(true);
294   }
295 }
296 
297 template &lt;class T&gt; void PSPromotionManager::process_array_chunk_work(
298                                                  oop obj,
299                                                  int start, int end) {
300   assert(start &lt;= end, &quot;invariant&quot;);
301   T* const base      = (T*)objArrayOop(obj)-&gt;base();
302   T* p               = base + start;
303   T* const chunk_end = base + end;
304   while (p &lt; chunk_end) {
305     if (PSScavenge::should_scavenge(p)) {
306       claim_or_forward_depth(p);
307     }
308     ++p;
309   }
310 }
311 
312 void PSPromotionManager::process_array_chunk(oop old) {
313   assert(PSChunkLargeArrays, &quot;invariant&quot;);
314   assert(old-&gt;is_objArray(), &quot;invariant&quot;);
315   assert(old-&gt;is_forwarded(), &quot;invariant&quot;);
316 
317   TASKQUEUE_STATS_ONLY(++_array_chunks_processed);
318 
319   oop const obj = old-&gt;forwardee();
320 
321   int start;
322   int const end = arrayOop(old)-&gt;length();
323   if (end &gt; (int) _min_array_size_for_chunking) {
324     // we&#39;ll chunk more
325     start = end - _array_chunk_size;
326     assert(start &gt; 0, &quot;invariant&quot;);
327     arrayOop(old)-&gt;set_length(start);
328     push_depth(mask_chunked_array_oop(old));
329     TASKQUEUE_STATS_ONLY(++_masked_pushes);
330   } else {
331     // this is the final chunk for this array
332     start = 0;
333     int const actual_length = arrayOop(obj)-&gt;length();
334     arrayOop(old)-&gt;set_length(actual_length);
335   }
336 
337   if (UseCompressedOops) {
338     process_array_chunk_work&lt;narrowOop&gt;(obj, start, end);
339   } else {
340     process_array_chunk_work&lt;oop&gt;(obj, start, end);
341   }
342 }
343 
344 oop PSPromotionManager::oop_promotion_failed(oop obj, markWord obj_mark) {
345   assert(_old_gen_is_full || PromotionFailureALot, &quot;Sanity&quot;);
346 
347   // Attempt to CAS in the header.
348   // This tests if the header is still the same as when
349   // this started.  If it is the same (i.e., no forwarding
350   // pointer has been installed), then this thread owns
351   // it.
352   if (obj-&gt;cas_forward_to(obj, obj_mark)) {
353     // We won any races, we &quot;own&quot; this object.
354     assert(obj == obj-&gt;forwardee(), &quot;Sanity&quot;);
355 
356     _promotion_failed_info.register_copy_failure(obj-&gt;size());
357 
358     push_contents(obj);
359 
360     _preserved_marks-&gt;push_if_necessary(obj, obj_mark);
361   }  else {
362     // We lost, someone else &quot;owns&quot; this object
363     guarantee(obj-&gt;is_forwarded(), &quot;Object must be forwarded if the cas failed.&quot;);
364 
365     // No unallocation to worry about.
366     obj = obj-&gt;forwardee();
367   }
368 
369   log_develop_trace(gc, scavenge)(&quot;{promotion-failure %s &quot; PTR_FORMAT &quot; (%d)}&quot;, obj-&gt;klass()-&gt;internal_name(), p2i(obj), obj-&gt;size());
370 
371   return obj;
372 }
    </pre>
  </body>
</html>