<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/memory/metaspaceShared.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="memRegion.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="metaspaceShared.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/memory/metaspaceShared.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 277   }
 278   if (_shared_rs.is_reserved()) {
 279     assert(shared_base == 0 || _shared_rs.base() == shared_base, &quot;should match&quot;);
 280   } else {
 281     // Get a mmap region anywhere if the SharedBaseAddress fails.
 282     _shared_rs = reserve_shared_space(cds_total);
 283   }
 284   if (!_shared_rs.is_reserved()) {
 285     vm_exit_during_initialization(&quot;Unable to reserve memory for shared space&quot;,
 286                                   err_msg(SIZE_FORMAT &quot; bytes.&quot;, cds_total));
 287   }
 288 
 289 #ifdef _LP64
 290   // During dump time, we allocate 4GB (UnscaledClassSpaceMax) of space and split it up:
 291   // + The upper 1 GB is used as the &quot;temporary compressed class space&quot; -- preload_classes()
 292   //   will store Klasses into this space.
 293   // + The lower 3 GB is used for the archive -- when preload_classes() is done,
 294   //   ArchiveCompactor will copy the class metadata into this space, first the RW parts,
 295   //   then the RO parts.
 296 
<span class="line-removed"> 297   assert(UseCompressedOops &amp;&amp; UseCompressedClassPointers,</span>
<span class="line-removed"> 298       &quot;UseCompressedOops and UseCompressedClassPointers must be set&quot;);</span>
<span class="line-removed"> 299 </span>
 300   size_t max_archive_size = align_down(cds_total * 3 / 4, reserve_alignment);
 301   ReservedSpace tmp_class_space = _shared_rs.last_part(max_archive_size);
 302   CompressedClassSpaceSize = align_down(tmp_class_space.size(), reserve_alignment);
 303   _shared_rs = _shared_rs.first_part(max_archive_size);
 304 
<span class="line-modified"> 305   // Set up compress class pointers.</span>
<span class="line-modified"> 306   CompressedKlassPointers::set_base((address)_shared_rs.base());</span>
<span class="line-modified"> 307   // Set narrow_klass_shift to be LogKlassAlignmentInBytes. This is consistent</span>
<span class="line-modified"> 308   // with AOT.</span>
<span class="line-modified"> 309   CompressedKlassPointers::set_shift(LogKlassAlignmentInBytes);</span>
<span class="line-modified"> 310   // Set the range of klass addresses to 4GB.</span>
<span class="line-modified"> 311   CompressedKlassPointers::set_range(cds_total);</span>
<span class="line-modified"> 312 </span>
<span class="line-modified"> 313   Metaspace::initialize_class_space(tmp_class_space);</span>

 314   log_info(cds)(&quot;narrow_klass_base = &quot; PTR_FORMAT &quot;, narrow_klass_shift = %d&quot;,
 315                 p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());
 316 
 317   log_info(cds)(&quot;Allocated temporary class space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 318                 CompressedClassSpaceSize, p2i(tmp_class_space.base()));
 319 #endif
 320 
 321   init_shared_dump_space(&amp;_mc_region);
 322   SharedBaseAddress = (size_t)_shared_rs.base();
 323   log_info(cds)(&quot;Allocated shared space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 324                 _shared_rs.size(), p2i(_shared_rs.base()));
 325 }
 326 
 327 // Called by universe_post_init()
 328 void MetaspaceShared::post_initialize(TRAPS) {
 329   if (UseSharedSpaces) {
 330     int size = FileMapInfo::get_number_of_shared_paths();
 331     if (size &gt; 0) {
 332       SystemDictionaryShared::allocate_shared_data_arrays(size, THREAD);
 333       if (!DynamicDumpSharedSpaces) {
</pre>
<hr />
<pre>
 448   soc-&gt;do_tag(objArrayOopDesc::base_offset_in_bytes());
 449   soc-&gt;do_tag(typeArrayOopDesc::base_offset_in_bytes(T_BYTE));
 450   soc-&gt;do_tag(sizeof(Symbol));
 451 
 452   // Dump/restore miscellaneous metadata.
 453   JavaClasses::serialize_offsets(soc);
 454   Universe::serialize(soc);
 455   soc-&gt;do_tag(--tag);
 456 
 457   // Dump/restore references to commonly used names and signatures.
 458   vmSymbols::serialize(soc);
 459   soc-&gt;do_tag(--tag);
 460 
 461   // Dump/restore the symbol/string/subgraph_info tables
 462   SymbolTable::serialize_shared_table_header(soc);
 463   StringTable::serialize_shared_table_header(soc);
 464   HeapShared::serialize_subgraph_info_table_header(soc);
 465   SystemDictionaryShared::serialize_dictionary_headers(soc);
 466 
 467   InstanceMirrorKlass::serialize_offsets(soc);



 468   soc-&gt;do_tag(--tag);
 469 
 470   serialize_cloned_cpp_vtptrs(soc);
 471   soc-&gt;do_tag(--tag);
 472 
 473   soc-&gt;do_tag(666);
 474 }
 475 
 476 address MetaspaceShared::i2i_entry_code_buffers(size_t total_size) {
 477   if (DumpSharedSpaces) {
 478     if (_i2i_entry_code_buffers == NULL) {
 479       _i2i_entry_code_buffers = (address)misc_code_space_alloc(total_size);
 480       _i2i_entry_code_buffers_size = total_size;
 481     }
 482   } else if (UseSharedSpaces) {
 483     assert(_i2i_entry_code_buffers != NULL, &quot;must already been initialized&quot;);
 484   } else {
 485     return NULL;
 486   }
 487 
</pre>
<hr />
<pre>
1357     }
1358     // NOTE: after this point, we shouldn&#39;t have any globals that can reach the old
1359     // objects.
1360 
1361     // We cannot use any of the objects in the heap anymore (except for the
1362     // shared strings) because their headers no longer point to valid Klasses.
1363   }
1364 
1365   static void iterate_roots(MetaspaceClosure* it) {
1366     GrowableArray&lt;Symbol*&gt;* symbols = _ssc-&gt;get_sorted_symbols();
1367     for (int i=0; i&lt;symbols-&gt;length(); i++) {
1368       it-&gt;push(symbols-&gt;adr_at(i));
1369     }
1370     if (_global_klass_objects != NULL) {
1371       // Need to fix up the pointers
1372       for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
1373         // NOTE -- this requires that the vtable is NOT yet patched, or else we are hosed.
1374         it-&gt;push(_global_klass_objects-&gt;adr_at(i));
1375       }
1376     }
<span class="line-modified">1377     FileMapInfo::metaspace_pointers_do(it);</span>
1378     SystemDictionaryShared::dumptime_classes_do(it);
1379     Universe::metaspace_pointers_do(it);
1380     SymbolTable::metaspace_pointers_do(it);
1381     vmSymbols::metaspace_pointers_do(it);
1382 
1383     it-&gt;finish();
1384   }
1385 
1386   static Klass* get_relocated_klass(Klass* orig_klass) {
1387     assert(DumpSharedSpaces, &quot;dump time only&quot;);
1388     address* pp = _new_loc_table-&gt;lookup((address)orig_klass);
1389     assert(pp != NULL, &quot;must be&quot;);
1390     Klass* klass = (Klass*)(*pp);
1391     assert(klass-&gt;is_klass(), &quot;must be&quot;);
1392     return klass;
1393   }
1394 };
1395 
1396 DumpAllocStats* ArchiveCompactor::_alloc_stats;
1397 SortedSymbolClosure* ArchiveCompactor::_ssc;
</pre>
<hr />
<pre>
1684   assert(DumpSharedSpaces, &quot;sanity&quot;);
1685   k = ArchiveCompactor::get_relocated_klass(k);
1686   if (is_final) {
1687     k = (Klass*)(address(k) + final_delta());
1688   }
1689   return k;
1690 }
1691 
1692 class LinkSharedClassesClosure : public KlassClosure {
1693   Thread* THREAD;
1694   bool    _made_progress;
1695  public:
1696   LinkSharedClassesClosure(Thread* thread) : THREAD(thread), _made_progress(false) {}
1697 
1698   void reset()               { _made_progress = false; }
1699   bool made_progress() const { return _made_progress; }
1700 
1701   void do_klass(Klass* k) {
1702     if (k-&gt;is_instance_klass()) {
1703       InstanceKlass* ik = InstanceKlass::cast(k);
<span class="line-modified">1704       // Link the class to cause the bytecodes to be rewritten and the</span>
<span class="line-modified">1705       // cpcache to be created. Class verification is done according</span>
<span class="line-modified">1706       // to -Xverify setting.</span>
<span class="line-modified">1707       _made_progress |= MetaspaceShared::try_link_class(ik, THREAD);</span>
<span class="line-modified">1708       guarantee(!HAS_PENDING_EXCEPTION, &quot;exception in link_class&quot;);</span>
<span class="line-modified">1709 </span>
<span class="line-modified">1710       ik-&gt;constants()-&gt;resolve_class_constants(THREAD);</span>
<span class="line-modified">1711     }</span>
<span class="line-removed">1712   }</span>
<span class="line-removed">1713 };</span>
<span class="line-removed">1714 </span>
<span class="line-removed">1715 class CheckSharedClassesClosure : public KlassClosure {</span>
<span class="line-removed">1716   bool    _made_progress;</span>
<span class="line-removed">1717  public:</span>
<span class="line-removed">1718   CheckSharedClassesClosure() : _made_progress(false) {}</span>
1719 
<span class="line-modified">1720   void reset()               { _made_progress = false; }</span>
<span class="line-modified">1721   bool made_progress() const { return _made_progress; }</span>
<span class="line-modified">1722   void do_klass(Klass* k) {</span>
<span class="line-modified">1723     if (k-&gt;is_instance_klass() &amp;&amp; InstanceKlass::cast(k)-&gt;check_sharing_error_state()) {</span>
<span class="line-modified">1724       _made_progress = true;</span>


1725     }
1726   }
1727 };
1728 
1729 void MetaspaceShared::link_and_cleanup_shared_classes(TRAPS) {
1730   // We need to iterate because verification may cause additional classes
1731   // to be loaded.
1732   LinkSharedClassesClosure link_closure(THREAD);
1733   do {
1734     link_closure.reset();
1735     ClassLoaderDataGraph::unlocked_loaded_classes_do(&amp;link_closure);
1736     guarantee(!HAS_PENDING_EXCEPTION, &quot;exception in link_class&quot;);
1737   } while (link_closure.made_progress());
<span class="line-removed">1738 </span>
<span class="line-removed">1739   if (_has_error_classes) {</span>
<span class="line-removed">1740     // Mark all classes whose super class or interfaces failed verification.</span>
<span class="line-removed">1741     CheckSharedClassesClosure check_closure;</span>
<span class="line-removed">1742     do {</span>
<span class="line-removed">1743       // Not completely sure if we need to do this iteratively. Anyway,</span>
<span class="line-removed">1744       // we should come here only if there are unverifiable classes, which</span>
<span class="line-removed">1745       // shouldn&#39;t happen in normal cases. So better safe than sorry.</span>
<span class="line-removed">1746       check_closure.reset();</span>
<span class="line-removed">1747       ClassLoaderDataGraph::unlocked_loaded_classes_do(&amp;check_closure);</span>
<span class="line-removed">1748     } while (check_closure.made_progress());</span>
<span class="line-removed">1749   }</span>
1750 }
1751 
1752 void MetaspaceShared::prepare_for_dumping() {
1753   Arguments::check_unsupported_dumping_properties();
1754   ClassLoader::initialize_shared_path();
1755 }
1756 
1757 // Preload classes from a list, populate the shared spaces and dump to a
1758 // file.
1759 void MetaspaceShared::preload_and_dump(TRAPS) {
1760   { TraceTime timer(&quot;Dump Shared Spaces&quot;, TRACETIME_LOG(Info, startuptime));
1761     ResourceMark rm(THREAD);
1762     char class_list_path_str[JVM_MAXPATHLEN];
1763     // Preload classes to be shared.
1764     const char* class_list_path;
1765     if (SharedClassListFile == NULL) {
1766       // Construct the path to the class list (in jre/lib)
1767       // Walk up two directories from the location of the VM and
1768       // optionally tack on &quot;lib&quot; (depending on platform)
1769       os::jvm_path(class_list_path_str, sizeof(class_list_path_str));
</pre>
<hr />
<pre>
1856       if (klass-&gt;is_instance_klass()) {
1857         InstanceKlass* ik = InstanceKlass::cast(klass);
1858 
1859         // Link the class to cause the bytecodes to be rewritten and the
1860         // cpcache to be created. The linking is done as soon as classes
1861         // are loaded in order that the related data structures (klass and
1862         // cpCache) are located together.
1863         try_link_class(ik, THREAD);
1864         guarantee(!HAS_PENDING_EXCEPTION, &quot;exception in link_class&quot;);
1865       }
1866 
1867       class_count++;
1868     }
1869   }
1870 
1871   return class_count;
1872 }
1873 
1874 // Returns true if the class&#39;s status has changed
1875 bool MetaspaceShared::try_link_class(InstanceKlass* ik, TRAPS) {
<span class="line-modified">1876   assert(DumpSharedSpaces, &quot;should only be called during dumping&quot;);</span>
<span class="line-modified">1877   if (ik-&gt;init_state() &lt; InstanceKlass::linked) {</span>

1878     bool saved = BytecodeVerificationLocal;
<span class="line-modified">1879     if (ik-&gt;loader_type() == 0 &amp;&amp; ik-&gt;class_loader() == NULL) {</span>
1880       // The verification decision is based on BytecodeVerificationRemote
1881       // for non-system classes. Since we are using the NULL classloader
1882       // to load non-system classes for customized class loaders during dumping,
1883       // we need to temporarily change BytecodeVerificationLocal to be the same as
1884       // BytecodeVerificationRemote. Note this can cause the parent system
1885       // classes also being verified. The extra overhead is acceptable during
1886       // dumping.
1887       BytecodeVerificationLocal = BytecodeVerificationRemote;
1888     }
1889     ik-&gt;link_class(THREAD);
1890     if (HAS_PENDING_EXCEPTION) {
1891       ResourceMark rm(THREAD);
1892       log_warning(cds)(&quot;Preload Warning: Verification failed for %s&quot;,
1893                     ik-&gt;external_name());
1894       CLEAR_PENDING_EXCEPTION;
<span class="line-modified">1895       ik-&gt;set_in_error_state();</span>
1896       _has_error_classes = true;
1897     }
1898     BytecodeVerificationLocal = saved;
1899     return true;
1900   } else {
1901     return false;
1902   }
1903 }
1904 
1905 #if INCLUDE_CDS_JAVA_HEAP
1906 void VM_PopulateDumpSharedSpace::dump_java_heap_objects() {
1907   // The closed and open archive heap space has maximum two regions.
1908   // See FileMapInfo::write_archive_heap_regions() for details.
1909   _closed_archive_heap_regions = new GrowableArray&lt;MemRegion&gt;(2);
1910   _open_archive_heap_regions = new GrowableArray&lt;MemRegion&gt;(2);
1911   HeapShared::archive_java_heap_objects(_closed_archive_heap_regions,
1912                                         _open_archive_heap_regions);
1913   ArchiveCompactor::OtherROAllocMark mark;
1914   HeapShared::write_subgraph_info_table();
1915 }
</pre>
<hr />
<pre>
2164     } else if (static_result == MAP_ARCHIVE_OTHER_FAILURE) {
2165       result = MAP_ARCHIVE_OTHER_FAILURE;
2166     } else {
2167       result = MAP_ARCHIVE_MMAP_FAILURE;
2168     }
2169   }
2170 
2171   if (result == MAP_ARCHIVE_SUCCESS) {
2172     if (!main_rs.is_reserved() &amp;&amp; class_space_rs.is_reserved()) {
2173       MemTracker::record_virtual_memory_type((address)class_space_rs.base(), mtClass);
2174     }
2175     SharedBaseAddress = (size_t)mapped_base_address;
2176     LP64_ONLY({
2177         if (Metaspace::using_class_space()) {
2178           assert(class_space_rs.is_reserved(), &quot;must be&quot;);
2179           char* cds_base = static_mapinfo-&gt;mapped_base();
2180           Metaspace::allocate_metaspace_compressed_klass_ptrs(class_space_rs, NULL, (address)cds_base);
2181           // map_heap_regions() compares the current narrow oop and klass encodings
2182           // with the archived ones, so it must be done after all encodings are determined.
2183           static_mapinfo-&gt;map_heap_regions();

2184         }
<span class="line-removed">2185         CompressedKlassPointers::set_range(CompressedClassSpaceSize);</span>
2186       });
2187   } else {
2188     unmap_archive(static_mapinfo);
2189     unmap_archive(dynamic_mapinfo);
2190     release_reserved_spaces(main_rs, archive_space_rs, class_space_rs);
2191   }
2192 
2193   return result;
2194 }
2195 
2196 char* MetaspaceShared::reserve_address_space_for_archives(FileMapInfo* static_mapinfo,
2197                                                           FileMapInfo* dynamic_mapinfo,
2198                                                           bool use_requested_addr,
2199                                                           ReservedSpace&amp; main_rs,
2200                                                           ReservedSpace&amp; archive_space_rs,
2201                                                           ReservedSpace&amp; class_space_rs) {
2202   const bool use_klass_space = NOT_LP64(false) LP64_ONLY(Metaspace::using_class_space());
2203   const size_t class_space_size = NOT_LP64(0) LP64_ONLY(Metaspace::compressed_class_space_size());
2204 
2205   if (use_klass_space) {
</pre>
</td>
<td>
<hr />
<pre>
 277   }
 278   if (_shared_rs.is_reserved()) {
 279     assert(shared_base == 0 || _shared_rs.base() == shared_base, &quot;should match&quot;);
 280   } else {
 281     // Get a mmap region anywhere if the SharedBaseAddress fails.
 282     _shared_rs = reserve_shared_space(cds_total);
 283   }
 284   if (!_shared_rs.is_reserved()) {
 285     vm_exit_during_initialization(&quot;Unable to reserve memory for shared space&quot;,
 286                                   err_msg(SIZE_FORMAT &quot; bytes.&quot;, cds_total));
 287   }
 288 
 289 #ifdef _LP64
 290   // During dump time, we allocate 4GB (UnscaledClassSpaceMax) of space and split it up:
 291   // + The upper 1 GB is used as the &quot;temporary compressed class space&quot; -- preload_classes()
 292   //   will store Klasses into this space.
 293   // + The lower 3 GB is used for the archive -- when preload_classes() is done,
 294   //   ArchiveCompactor will copy the class metadata into this space, first the RW parts,
 295   //   then the RO parts.
 296 



 297   size_t max_archive_size = align_down(cds_total * 3 / 4, reserve_alignment);
 298   ReservedSpace tmp_class_space = _shared_rs.last_part(max_archive_size);
 299   CompressedClassSpaceSize = align_down(tmp_class_space.size(), reserve_alignment);
 300   _shared_rs = _shared_rs.first_part(max_archive_size);
 301 
<span class="line-modified"> 302   if (UseCompressedClassPointers) {</span>
<span class="line-modified"> 303     // Set up compress class pointers.</span>
<span class="line-modified"> 304     CompressedKlassPointers::set_base((address)_shared_rs.base());</span>
<span class="line-modified"> 305     // Set narrow_klass_shift to be LogKlassAlignmentInBytes. This is consistent</span>
<span class="line-modified"> 306     // with AOT.</span>
<span class="line-modified"> 307     CompressedKlassPointers::set_shift(LogKlassAlignmentInBytes);</span>
<span class="line-modified"> 308     // Set the range of klass addresses to 4GB.</span>
<span class="line-modified"> 309     CompressedKlassPointers::set_range(cds_total);</span>
<span class="line-modified"> 310     Metaspace::initialize_class_space(tmp_class_space);</span>
<span class="line-added"> 311   }</span>
 312   log_info(cds)(&quot;narrow_klass_base = &quot; PTR_FORMAT &quot;, narrow_klass_shift = %d&quot;,
 313                 p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());
 314 
 315   log_info(cds)(&quot;Allocated temporary class space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 316                 CompressedClassSpaceSize, p2i(tmp_class_space.base()));
 317 #endif
 318 
 319   init_shared_dump_space(&amp;_mc_region);
 320   SharedBaseAddress = (size_t)_shared_rs.base();
 321   log_info(cds)(&quot;Allocated shared space: &quot; SIZE_FORMAT &quot; bytes at &quot; PTR_FORMAT,
 322                 _shared_rs.size(), p2i(_shared_rs.base()));
 323 }
 324 
 325 // Called by universe_post_init()
 326 void MetaspaceShared::post_initialize(TRAPS) {
 327   if (UseSharedSpaces) {
 328     int size = FileMapInfo::get_number_of_shared_paths();
 329     if (size &gt; 0) {
 330       SystemDictionaryShared::allocate_shared_data_arrays(size, THREAD);
 331       if (!DynamicDumpSharedSpaces) {
</pre>
<hr />
<pre>
 446   soc-&gt;do_tag(objArrayOopDesc::base_offset_in_bytes());
 447   soc-&gt;do_tag(typeArrayOopDesc::base_offset_in_bytes(T_BYTE));
 448   soc-&gt;do_tag(sizeof(Symbol));
 449 
 450   // Dump/restore miscellaneous metadata.
 451   JavaClasses::serialize_offsets(soc);
 452   Universe::serialize(soc);
 453   soc-&gt;do_tag(--tag);
 454 
 455   // Dump/restore references to commonly used names and signatures.
 456   vmSymbols::serialize(soc);
 457   soc-&gt;do_tag(--tag);
 458 
 459   // Dump/restore the symbol/string/subgraph_info tables
 460   SymbolTable::serialize_shared_table_header(soc);
 461   StringTable::serialize_shared_table_header(soc);
 462   HeapShared::serialize_subgraph_info_table_header(soc);
 463   SystemDictionaryShared::serialize_dictionary_headers(soc);
 464 
 465   InstanceMirrorKlass::serialize_offsets(soc);
<span class="line-added"> 466 </span>
<span class="line-added"> 467   // Dump/restore well known classes (pointers)</span>
<span class="line-added"> 468   SystemDictionaryShared::serialize_well_known_klasses(soc);</span>
 469   soc-&gt;do_tag(--tag);
 470 
 471   serialize_cloned_cpp_vtptrs(soc);
 472   soc-&gt;do_tag(--tag);
 473 
 474   soc-&gt;do_tag(666);
 475 }
 476 
 477 address MetaspaceShared::i2i_entry_code_buffers(size_t total_size) {
 478   if (DumpSharedSpaces) {
 479     if (_i2i_entry_code_buffers == NULL) {
 480       _i2i_entry_code_buffers = (address)misc_code_space_alloc(total_size);
 481       _i2i_entry_code_buffers_size = total_size;
 482     }
 483   } else if (UseSharedSpaces) {
 484     assert(_i2i_entry_code_buffers != NULL, &quot;must already been initialized&quot;);
 485   } else {
 486     return NULL;
 487   }
 488 
</pre>
<hr />
<pre>
1358     }
1359     // NOTE: after this point, we shouldn&#39;t have any globals that can reach the old
1360     // objects.
1361 
1362     // We cannot use any of the objects in the heap anymore (except for the
1363     // shared strings) because their headers no longer point to valid Klasses.
1364   }
1365 
1366   static void iterate_roots(MetaspaceClosure* it) {
1367     GrowableArray&lt;Symbol*&gt;* symbols = _ssc-&gt;get_sorted_symbols();
1368     for (int i=0; i&lt;symbols-&gt;length(); i++) {
1369       it-&gt;push(symbols-&gt;adr_at(i));
1370     }
1371     if (_global_klass_objects != NULL) {
1372       // Need to fix up the pointers
1373       for (int i = 0; i &lt; _global_klass_objects-&gt;length(); i++) {
1374         // NOTE -- this requires that the vtable is NOT yet patched, or else we are hosed.
1375         it-&gt;push(_global_klass_objects-&gt;adr_at(i));
1376       }
1377     }
<span class="line-modified">1378     FileMapInfo::metaspace_pointers_do(it, false);</span>
1379     SystemDictionaryShared::dumptime_classes_do(it);
1380     Universe::metaspace_pointers_do(it);
1381     SymbolTable::metaspace_pointers_do(it);
1382     vmSymbols::metaspace_pointers_do(it);
1383 
1384     it-&gt;finish();
1385   }
1386 
1387   static Klass* get_relocated_klass(Klass* orig_klass) {
1388     assert(DumpSharedSpaces, &quot;dump time only&quot;);
1389     address* pp = _new_loc_table-&gt;lookup((address)orig_klass);
1390     assert(pp != NULL, &quot;must be&quot;);
1391     Klass* klass = (Klass*)(*pp);
1392     assert(klass-&gt;is_klass(), &quot;must be&quot;);
1393     return klass;
1394   }
1395 };
1396 
1397 DumpAllocStats* ArchiveCompactor::_alloc_stats;
1398 SortedSymbolClosure* ArchiveCompactor::_ssc;
</pre>
<hr />
<pre>
1685   assert(DumpSharedSpaces, &quot;sanity&quot;);
1686   k = ArchiveCompactor::get_relocated_klass(k);
1687   if (is_final) {
1688     k = (Klass*)(address(k) + final_delta());
1689   }
1690   return k;
1691 }
1692 
1693 class LinkSharedClassesClosure : public KlassClosure {
1694   Thread* THREAD;
1695   bool    _made_progress;
1696  public:
1697   LinkSharedClassesClosure(Thread* thread) : THREAD(thread), _made_progress(false) {}
1698 
1699   void reset()               { _made_progress = false; }
1700   bool made_progress() const { return _made_progress; }
1701 
1702   void do_klass(Klass* k) {
1703     if (k-&gt;is_instance_klass()) {
1704       InstanceKlass* ik = InstanceKlass::cast(k);
<span class="line-modified">1705       // For dynamic CDS dump, only link classes loaded by the builtin class loaders.</span>
<span class="line-modified">1706       bool do_linking = DumpSharedSpaces ? true : !ik-&gt;is_shared_unregistered_class();</span>
<span class="line-modified">1707       if (do_linking) {</span>
<span class="line-modified">1708         // Link the class to cause the bytecodes to be rewritten and the</span>
<span class="line-modified">1709         // cpcache to be created. Class verification is done according</span>
<span class="line-modified">1710         // to -Xverify setting.</span>
<span class="line-modified">1711         _made_progress |= MetaspaceShared::try_link_class(ik, THREAD);</span>
<span class="line-modified">1712         guarantee(!HAS_PENDING_EXCEPTION, &quot;exception in link_class&quot;);</span>







1713 
<span class="line-modified">1714         if (DumpSharedSpaces) {</span>
<span class="line-modified">1715           // The following function is used to resolve all Strings in the statically</span>
<span class="line-modified">1716           // dumped classes to archive all the Strings. The archive heap is not supported</span>
<span class="line-modified">1717           // for the dynamic archive.</span>
<span class="line-modified">1718           ik-&gt;constants()-&gt;resolve_class_constants(THREAD);</span>
<span class="line-added">1719         }</span>
<span class="line-added">1720       }</span>
1721     }
1722   }
1723 };
1724 
1725 void MetaspaceShared::link_and_cleanup_shared_classes(TRAPS) {
1726   // We need to iterate because verification may cause additional classes
1727   // to be loaded.
1728   LinkSharedClassesClosure link_closure(THREAD);
1729   do {
1730     link_closure.reset();
1731     ClassLoaderDataGraph::unlocked_loaded_classes_do(&amp;link_closure);
1732     guarantee(!HAS_PENDING_EXCEPTION, &quot;exception in link_class&quot;);
1733   } while (link_closure.made_progress());












1734 }
1735 
1736 void MetaspaceShared::prepare_for_dumping() {
1737   Arguments::check_unsupported_dumping_properties();
1738   ClassLoader::initialize_shared_path();
1739 }
1740 
1741 // Preload classes from a list, populate the shared spaces and dump to a
1742 // file.
1743 void MetaspaceShared::preload_and_dump(TRAPS) {
1744   { TraceTime timer(&quot;Dump Shared Spaces&quot;, TRACETIME_LOG(Info, startuptime));
1745     ResourceMark rm(THREAD);
1746     char class_list_path_str[JVM_MAXPATHLEN];
1747     // Preload classes to be shared.
1748     const char* class_list_path;
1749     if (SharedClassListFile == NULL) {
1750       // Construct the path to the class list (in jre/lib)
1751       // Walk up two directories from the location of the VM and
1752       // optionally tack on &quot;lib&quot; (depending on platform)
1753       os::jvm_path(class_list_path_str, sizeof(class_list_path_str));
</pre>
<hr />
<pre>
1840       if (klass-&gt;is_instance_klass()) {
1841         InstanceKlass* ik = InstanceKlass::cast(klass);
1842 
1843         // Link the class to cause the bytecodes to be rewritten and the
1844         // cpcache to be created. The linking is done as soon as classes
1845         // are loaded in order that the related data structures (klass and
1846         // cpCache) are located together.
1847         try_link_class(ik, THREAD);
1848         guarantee(!HAS_PENDING_EXCEPTION, &quot;exception in link_class&quot;);
1849       }
1850 
1851       class_count++;
1852     }
1853   }
1854 
1855   return class_count;
1856 }
1857 
1858 // Returns true if the class&#39;s status has changed
1859 bool MetaspaceShared::try_link_class(InstanceKlass* ik, TRAPS) {
<span class="line-modified">1860   Arguments::assert_is_dumping_archive();</span>
<span class="line-modified">1861   if (ik-&gt;init_state() &lt; InstanceKlass::linked &amp;&amp;</span>
<span class="line-added">1862       !SystemDictionaryShared::has_class_failed_verification(ik)) {</span>
1863     bool saved = BytecodeVerificationLocal;
<span class="line-modified">1864     if (ik-&gt;is_shared_unregistered_class() &amp;&amp; ik-&gt;class_loader() == NULL) {</span>
1865       // The verification decision is based on BytecodeVerificationRemote
1866       // for non-system classes. Since we are using the NULL classloader
1867       // to load non-system classes for customized class loaders during dumping,
1868       // we need to temporarily change BytecodeVerificationLocal to be the same as
1869       // BytecodeVerificationRemote. Note this can cause the parent system
1870       // classes also being verified. The extra overhead is acceptable during
1871       // dumping.
1872       BytecodeVerificationLocal = BytecodeVerificationRemote;
1873     }
1874     ik-&gt;link_class(THREAD);
1875     if (HAS_PENDING_EXCEPTION) {
1876       ResourceMark rm(THREAD);
1877       log_warning(cds)(&quot;Preload Warning: Verification failed for %s&quot;,
1878                     ik-&gt;external_name());
1879       CLEAR_PENDING_EXCEPTION;
<span class="line-modified">1880       SystemDictionaryShared::set_class_has_failed_verification(ik);</span>
1881       _has_error_classes = true;
1882     }
1883     BytecodeVerificationLocal = saved;
1884     return true;
1885   } else {
1886     return false;
1887   }
1888 }
1889 
1890 #if INCLUDE_CDS_JAVA_HEAP
1891 void VM_PopulateDumpSharedSpace::dump_java_heap_objects() {
1892   // The closed and open archive heap space has maximum two regions.
1893   // See FileMapInfo::write_archive_heap_regions() for details.
1894   _closed_archive_heap_regions = new GrowableArray&lt;MemRegion&gt;(2);
1895   _open_archive_heap_regions = new GrowableArray&lt;MemRegion&gt;(2);
1896   HeapShared::archive_java_heap_objects(_closed_archive_heap_regions,
1897                                         _open_archive_heap_regions);
1898   ArchiveCompactor::OtherROAllocMark mark;
1899   HeapShared::write_subgraph_info_table();
1900 }
</pre>
<hr />
<pre>
2149     } else if (static_result == MAP_ARCHIVE_OTHER_FAILURE) {
2150       result = MAP_ARCHIVE_OTHER_FAILURE;
2151     } else {
2152       result = MAP_ARCHIVE_MMAP_FAILURE;
2153     }
2154   }
2155 
2156   if (result == MAP_ARCHIVE_SUCCESS) {
2157     if (!main_rs.is_reserved() &amp;&amp; class_space_rs.is_reserved()) {
2158       MemTracker::record_virtual_memory_type((address)class_space_rs.base(), mtClass);
2159     }
2160     SharedBaseAddress = (size_t)mapped_base_address;
2161     LP64_ONLY({
2162         if (Metaspace::using_class_space()) {
2163           assert(class_space_rs.is_reserved(), &quot;must be&quot;);
2164           char* cds_base = static_mapinfo-&gt;mapped_base();
2165           Metaspace::allocate_metaspace_compressed_klass_ptrs(class_space_rs, NULL, (address)cds_base);
2166           // map_heap_regions() compares the current narrow oop and klass encodings
2167           // with the archived ones, so it must be done after all encodings are determined.
2168           static_mapinfo-&gt;map_heap_regions();
<span class="line-added">2169           CompressedKlassPointers::set_range(CompressedClassSpaceSize);</span>
2170         }

2171       });
2172   } else {
2173     unmap_archive(static_mapinfo);
2174     unmap_archive(dynamic_mapinfo);
2175     release_reserved_spaces(main_rs, archive_space_rs, class_space_rs);
2176   }
2177 
2178   return result;
2179 }
2180 
2181 char* MetaspaceShared::reserve_address_space_for_archives(FileMapInfo* static_mapinfo,
2182                                                           FileMapInfo* dynamic_mapinfo,
2183                                                           bool use_requested_addr,
2184                                                           ReservedSpace&amp; main_rs,
2185                                                           ReservedSpace&amp; archive_space_rs,
2186                                                           ReservedSpace&amp; class_space_rs) {
2187   const bool use_klass_space = NOT_LP64(false) LP64_ONLY(Metaspace::using_class_space());
2188   const size_t class_space_size = NOT_LP64(0) LP64_ONLY(Metaspace::compressed_class_space_size());
2189 
2190   if (use_klass_space) {
</pre>
</td>
</tr>
</table>
<center><a href="memRegion.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="metaspaceShared.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>