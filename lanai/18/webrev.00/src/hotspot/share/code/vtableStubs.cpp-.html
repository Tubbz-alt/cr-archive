<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/code/vtableStubs.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;code/vtableStubs.hpp&quot;
 27 #include &quot;compiler/compileBroker.hpp&quot;
 28 #include &quot;compiler/disassembler.hpp&quot;
 29 #include &quot;logging/log.hpp&quot;
 30 #include &quot;memory/allocation.inline.hpp&quot;
 31 #include &quot;memory/resourceArea.hpp&quot;
 32 #include &quot;oops/instanceKlass.hpp&quot;
 33 #include &quot;oops/klassVtable.hpp&quot;
 34 #include &quot;oops/oop.inline.hpp&quot;
 35 #include &quot;prims/forte.hpp&quot;
 36 #include &quot;prims/jvmtiExport.hpp&quot;
 37 #include &quot;runtime/handles.inline.hpp&quot;
 38 #include &quot;runtime/mutexLocker.hpp&quot;
 39 #include &quot;runtime/sharedRuntime.hpp&quot;
 40 #include &quot;utilities/align.hpp&quot;
 41 #ifdef COMPILER2
 42 #include &quot;opto/matcher.hpp&quot;
 43 #endif
 44 
 45 // -----------------------------------------------------------------------------------------
 46 // Implementation of VtableStub
 47 
 48 address VtableStub::_chunk             = NULL;
 49 address VtableStub::_chunk_end         = NULL;
 50 VMReg   VtableStub::_receiver_location = VMRegImpl::Bad();
 51 
 52 
 53 void* VtableStub::operator new(size_t size, int code_size) throw() {
 54   assert_lock_strong(VtableStubs_lock);
 55   assert(size == sizeof(VtableStub), &quot;mismatched size&quot;);
 56   // compute real VtableStub size (rounded to nearest word)
 57   const int real_size = align_up(code_size + (int)sizeof(VtableStub), wordSize);
 58   // malloc them in chunks to minimize header overhead
 59   const int chunk_factor = 32;
 60   if (_chunk == NULL || _chunk + real_size &gt; _chunk_end) {
 61     const int bytes = chunk_factor * real_size + pd_code_alignment();
 62 
 63    // There is a dependency on the name of the blob in src/share/vm/prims/jvmtiCodeBlobEvents.cpp
 64    // If changing the name, update the other file accordingly.
 65     VtableBlob* blob = VtableBlob::create(&quot;vtable chunks&quot;, bytes);
 66     if (blob == NULL) {
 67       return NULL;
 68     }
 69     _chunk = blob-&gt;content_begin();
 70     _chunk_end = _chunk + bytes;
 71     Forte::register_stub(&quot;vtable stub&quot;, _chunk, _chunk_end);
 72     align_chunk();
 73   }
 74   assert(_chunk + real_size &lt;= _chunk_end, &quot;bad allocation&quot;);
 75   void* res = _chunk;
 76   _chunk += real_size;
 77   align_chunk();
 78  return res;
 79 }
 80 
 81 
 82 void VtableStub::print_on(outputStream* st) const {
 83   st-&gt;print(&quot;vtable stub (index = %d, receiver_location = &quot; INTX_FORMAT &quot;, code = [&quot; INTPTR_FORMAT &quot;, &quot; INTPTR_FORMAT &quot;])&quot;,
 84              index(), p2i(receiver_location()), p2i(code_begin()), p2i(code_end()));
 85 }
 86 
 87 void VtableStub::print() const { print_on(tty); }
 88 
 89 // -----------------------------------------------------------------------------------------
 90 // Implementation of VtableStubs
 91 //
 92 // For each hash value there&#39;s a linked list of vtable stubs (with that
 93 // hash value). Each list is anchored in a little hash _table, indexed
 94 // by that hash value.
 95 
 96 VtableStub* VtableStubs::_table[VtableStubs::N];
 97 int VtableStubs::_number_of_vtable_stubs = 0;
 98 int VtableStubs::_vtab_stub_size = 0;
 99 int VtableStubs::_itab_stub_size = 0;
100 
101 #if defined(PRODUCT)
102   // These values are good for the PRODUCT case (no tracing).
103   static const int first_vtableStub_size =  64;
104   static const int first_itableStub_size = 256;
105 #else
106   // These values are good for the non-PRODUCT case (when tracing can be switched on).
107   // To find out, run test workload with
108   //   -Xlog:vtablestubs=Trace -XX:+CountCompiledCalls -XX:+DebugVtables
109   // and use the reported &quot;estimate&quot; value.
110   // Here is a list of observed worst-case values:
111   //               vtable  itable
112   // aarch64:         460     324
113   // arm:               ?       ?
114   // ppc (linux, BE): 404     288
115   // ppc (linux, LE): 356     276
116   // ppc (AIX):       416     296
117   // s390x:           408     256
118   // Solaris-sparc:   792     348
119   // x86 (Linux):     670     309
120   // x86 (MacOS):     682     321
121   static const int first_vtableStub_size = 1024;
122   static const int first_itableStub_size =  512;
123 #endif
124 
125 
126 void VtableStubs::initialize() {
127   VtableStub::_receiver_location = SharedRuntime::name_for_receiver();
128   {
129     MutexLocker ml(VtableStubs_lock, Mutex::_no_safepoint_check_flag);
130     assert(_number_of_vtable_stubs == 0, &quot;potential performance bug: VtableStubs initialized more than once&quot;);
131     assert(is_power_of_2(N), &quot;N must be a power of 2&quot;);
132     for (int i = 0; i &lt; N; i++) {
133       _table[i] = NULL;
134     }
135   }
136 }
137 
138 
139 int VtableStubs::code_size_limit(bool is_vtable_stub) {
140   if (is_vtable_stub) {
141     return _vtab_stub_size &gt; 0 ? _vtab_stub_size : first_vtableStub_size;
142   } else { // itable stub
143     return _itab_stub_size &gt; 0 ? _itab_stub_size : first_itableStub_size;
144   }
145 }   // code_size_limit
146 
147 
148 void VtableStubs::check_and_set_size_limit(bool is_vtable_stub,
149                                            int  code_size,
150                                            int  padding) {
151   const char* name = is_vtable_stub ? &quot;vtable&quot; : &quot;itable&quot;;
152 
153   guarantee(code_size &lt;= code_size_limit(is_vtable_stub),
154             &quot;buffer overflow in %s stub, code_size is %d, limit is %d&quot;, name, code_size, code_size_limit(is_vtable_stub));
155 
156   if (is_vtable_stub) {
157     if (log_is_enabled(Trace, vtablestubs)) {
158       if ( (_vtab_stub_size &gt; 0) &amp;&amp; ((code_size + padding) &gt; _vtab_stub_size) ) {
159         log_trace(vtablestubs)(&quot;%s size estimate needed adjustment from %d to %d bytes&quot;,
160                                name, _vtab_stub_size, code_size + padding);
161       }
162     }
163     if ( (code_size + padding) &gt; _vtab_stub_size ) {
164       _vtab_stub_size = code_size + padding;
165     }
166   } else {  // itable stub
167     if (log_is_enabled(Trace, vtablestubs)) {
168       if ( (_itab_stub_size &gt; 0) &amp;&amp; ((code_size + padding) &gt; _itab_stub_size) ) {
169         log_trace(vtablestubs)(&quot;%s size estimate needed adjustment from %d to %d bytes&quot;,
170                                name, _itab_stub_size, code_size + padding);
171       }
172     }
173     if ( (code_size + padding) &gt; _itab_stub_size ) {
174       _itab_stub_size = code_size + padding;
175     }
176   }
177   return;
178 }   // check_and_set_size_limit
179 
180 
181 void VtableStubs::bookkeeping(MacroAssembler* masm, outputStream* out, VtableStub* s,
182                               address npe_addr, address ame_addr,   bool is_vtable_stub,
183                               int     index,    int     slop_bytes, int  index_dependent_slop) {
184   const char* name        = is_vtable_stub ? &quot;vtable&quot; : &quot;itable&quot;;
185   const int   stub_length = code_size_limit(is_vtable_stub);
186 
187   if (log_is_enabled(Trace, vtablestubs)) {
188     log_trace(vtablestubs)(&quot;%s #%d at &quot; PTR_FORMAT &quot;: size: %d, estimate: %d, slop area: %d&quot;,
189                            name, index, p2i(s-&gt;code_begin()),
190                            (int)(masm-&gt;pc() - s-&gt;code_begin()),
191                            stub_length,
192                            (int)(s-&gt;code_end() - masm-&gt;pc()));
193   }
194   guarantee(masm-&gt;pc() &lt;= s-&gt;code_end(), &quot;%s #%d: overflowed buffer, estimated len: %d, actual len: %d, overrun: %d&quot;,
195                                          name, index, stub_length,
196                                          (int)(masm-&gt;pc() - s-&gt;code_begin()),
197                                          (int)(masm-&gt;pc() - s-&gt;code_end()));
198   assert((masm-&gt;pc() + index_dependent_slop) &lt;= s-&gt;code_end(), &quot;%s #%d: spare space for 32-bit offset: required = %d, available = %d&quot;,
199                                          name, index, index_dependent_slop,
200                                          (int)(s-&gt;code_end() - masm-&gt;pc()));
201 
202   // After the first vtable/itable stub is generated, we have a much
203   // better estimate for the stub size. Remember/update this
204   // estimate after some sanity checks.
205   check_and_set_size_limit(is_vtable_stub, masm-&gt;offset(), slop_bytes);
206   s-&gt;set_exception_points(npe_addr, ame_addr);
207 }
208 
209 
210 address VtableStubs::find_stub(bool is_vtable_stub, int vtable_index) {
211   assert(vtable_index &gt;= 0, &quot;must be positive&quot;);
212 
213   VtableStub* s;
214   {
215     MutexLocker ml(VtableStubs_lock, Mutex::_no_safepoint_check_flag);
216     s = lookup(is_vtable_stub, vtable_index);
217     if (s == NULL) {
218       if (is_vtable_stub) {
219         s = create_vtable_stub(vtable_index);
220       } else {
221         s = create_itable_stub(vtable_index);
222       }
223 
224       // Creation of vtable or itable can fail if there is not enough free space in the code cache.
225       if (s == NULL) {
226         return NULL;
227       }
228 
229       enter(is_vtable_stub, vtable_index, s);
230       if (PrintAdapterHandlers) {
231         tty-&gt;print_cr(&quot;Decoding VtableStub %s[%d]@&quot; INTX_FORMAT,
232                       is_vtable_stub? &quot;vtbl&quot;: &quot;itbl&quot;, vtable_index, p2i(VtableStub::receiver_location()));
233         Disassembler::decode(s-&gt;code_begin(), s-&gt;code_end());
234       }
235       // Notify JVMTI about this stub. The event will be recorded by the enclosing
236       // JvmtiDynamicCodeEventCollector and posted when this thread has released
237       // all locks. Only post this event if a new state is not required. Creating a new state would
238       // cause a safepoint and the caller of this code has a NoSafepointVerifier.
239       if (JvmtiExport::should_post_dynamic_code_generated()) {
240         JvmtiExport::post_dynamic_code_generated_while_holding_locks(is_vtable_stub? &quot;vtable stub&quot;: &quot;itable stub&quot;,
241                                                                      s-&gt;code_begin(), s-&gt;code_end());
242       }
243     }
244   }
245   return s-&gt;entry_point();
246 }
247 
248 
249 inline uint VtableStubs::hash(bool is_vtable_stub, int vtable_index){
250   // Assumption: receiver_location &lt; 4 in most cases.
251   int hash = ((vtable_index &lt;&lt; 2) ^ VtableStub::receiver_location()-&gt;value()) + vtable_index;
252   return (is_vtable_stub ? ~hash : hash)  &amp; mask;
253 }
254 
255 
256 VtableStub* VtableStubs::lookup(bool is_vtable_stub, int vtable_index) {
257   assert_lock_strong(VtableStubs_lock);
258   unsigned hash = VtableStubs::hash(is_vtable_stub, vtable_index);
259   VtableStub* s = _table[hash];
260   while( s &amp;&amp; !s-&gt;matches(is_vtable_stub, vtable_index)) s = s-&gt;next();
261   return s;
262 }
263 
264 
265 void VtableStubs::enter(bool is_vtable_stub, int vtable_index, VtableStub* s) {
266   assert_lock_strong(VtableStubs_lock);
267   assert(s-&gt;matches(is_vtable_stub, vtable_index), &quot;bad vtable stub&quot;);
268   unsigned int h = VtableStubs::hash(is_vtable_stub, vtable_index);
269   // enter s at the beginning of the corresponding list
270   s-&gt;set_next(_table[h]);
271   _table[h] = s;
272   _number_of_vtable_stubs++;
273 }
274 
275 VtableStub* VtableStubs::entry_point(address pc) {
276   MutexLocker ml(VtableStubs_lock, Mutex::_no_safepoint_check_flag);
277   VtableStub* stub = (VtableStub*)(pc - VtableStub::entry_offset());
278   uint hash = VtableStubs::hash(stub-&gt;is_vtable_stub(), stub-&gt;index());
279   VtableStub* s;
280   for (s = _table[hash]; s != NULL &amp;&amp; s != stub; s = s-&gt;next()) {}
281   return (s == stub) ? s : NULL;
282 }
283 
284 bool VtableStubs::contains(address pc) {
285   // simple solution for now - we may want to use
286   // a faster way if this function is called often
287   return stub_containing(pc) != NULL;
288 }
289 
290 
291 VtableStub* VtableStubs::stub_containing(address pc) {
292   // Note: No locking needed since any change to the data structure
293   //       happens with an atomic store into it (we don&#39;t care about
294   //       consistency with the _number_of_vtable_stubs counter).
295   for (int i = 0; i &lt; N; i++) {
296     for (VtableStub* s = _table[i]; s != NULL; s = s-&gt;next()) {
297       if (s-&gt;contains(pc)) return s;
298     }
299   }
300   return NULL;
301 }
302 
303 void vtableStubs_init() {
304   VtableStubs::initialize();
305 }
306 
307 void VtableStubs::vtable_stub_do(void f(VtableStub*)) {
308     for (int i = 0; i &lt; N; i++) {
309         for (VtableStub* s = _table[i]; s != NULL; s = s-&gt;next()) {
310             f(s);
311         }
312     }
313 }
314 
315 
316 //-----------------------------------------------------------------------------------------------------
317 // Non-product code
318 #ifndef PRODUCT
319 
320 extern &quot;C&quot; void bad_compiled_vtable_index(JavaThread* thread, oop receiver, int index) {
321   ResourceMark rm;
322   HandleMark hm;
323   Klass* klass = receiver-&gt;klass();
324   InstanceKlass* ik = InstanceKlass::cast(klass);
325   klassVtable vt = ik-&gt;vtable();
326   ik-&gt;print();
327   fatal(&quot;bad compiled vtable dispatch: receiver &quot; INTPTR_FORMAT &quot;, &quot;
328         &quot;index %d (vtable length %d)&quot;,
329         p2i(receiver), index, vt.length());
330 }
331 
332 #endif // PRODUCT
    </pre>
  </body>
</html>