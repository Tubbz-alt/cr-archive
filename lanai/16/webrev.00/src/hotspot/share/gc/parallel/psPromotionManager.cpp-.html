<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/parallel/psPromotionManager.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2002, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;classfile/javaClasses.inline.hpp&quot;
 27 #include &quot;gc/parallel/mutableSpace.hpp&quot;
 28 #include &quot;gc/parallel/parallelScavengeHeap.hpp&quot;
 29 #include &quot;gc/parallel/psOldGen.hpp&quot;
 30 #include &quot;gc/parallel/psPromotionManager.inline.hpp&quot;
 31 #include &quot;gc/parallel/psScavenge.inline.hpp&quot;
 32 #include &quot;gc/shared/gcTrace.hpp&quot;
 33 #include &quot;gc/shared/preservedMarks.inline.hpp&quot;
 34 #include &quot;gc/shared/taskqueue.inline.hpp&quot;
 35 #include &quot;logging/log.hpp&quot;
 36 #include &quot;logging/logStream.hpp&quot;
 37 #include &quot;memory/allocation.inline.hpp&quot;
 38 #include &quot;memory/iterator.inline.hpp&quot;
 39 #include &quot;memory/memRegion.hpp&quot;
 40 #include &quot;memory/padded.inline.hpp&quot;
 41 #include &quot;memory/resourceArea.hpp&quot;
 42 #include &quot;oops/access.inline.hpp&quot;
 43 #include &quot;oops/compressedOops.inline.hpp&quot;
 44 
 45 PaddedEnd&lt;PSPromotionManager&gt;* PSPromotionManager::_manager_array = NULL;
 46 OopStarTaskQueueSet*           PSPromotionManager::_stack_array_depth = NULL;
 47 PreservedMarksSet*             PSPromotionManager::_preserved_marks_set = NULL;
 48 PSOldGen*                      PSPromotionManager::_old_gen = NULL;
 49 MutableSpace*                  PSPromotionManager::_young_space = NULL;
 50 
 51 void PSPromotionManager::initialize() {
 52   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
 53 
 54   _old_gen = heap-&gt;old_gen();
 55   _young_space = heap-&gt;young_gen()-&gt;to_space();
 56 
 57   const uint promotion_manager_num = ParallelGCThreads + 1;
 58 
 59   // To prevent false sharing, we pad the PSPromotionManagers
 60   // and make sure that the first instance starts at a cache line.
 61   assert(_manager_array == NULL, &quot;Attempt to initialize twice&quot;);
 62   _manager_array = PaddedArray&lt;PSPromotionManager, mtGC&gt;::create_unfreeable(promotion_manager_num);
 63   guarantee(_manager_array != NULL, &quot;Could not initialize promotion manager&quot;);
 64 
 65   _stack_array_depth = new OopStarTaskQueueSet(ParallelGCThreads);
 66   guarantee(_stack_array_depth != NULL, &quot;Could not initialize promotion manager&quot;);
 67 
 68   // Create and register the PSPromotionManager(s) for the worker threads.
 69   for(uint i=0; i&lt;ParallelGCThreads; i++) {
 70     stack_array_depth()-&gt;register_queue(i, _manager_array[i].claimed_stack_depth());
 71   }
 72   // The VMThread gets its own PSPromotionManager, which is not available
 73   // for work stealing.
 74 
 75   assert(_preserved_marks_set == NULL, &quot;Attempt to initialize twice&quot;);
 76   _preserved_marks_set = new PreservedMarksSet(true /* in_c_heap */);
 77   guarantee(_preserved_marks_set != NULL, &quot;Could not initialize preserved marks set&quot;);
 78   _preserved_marks_set-&gt;init(promotion_manager_num);
 79   for (uint i = 0; i &lt; promotion_manager_num; i += 1) {
 80     _manager_array[i].register_preserved_marks(_preserved_marks_set-&gt;get(i));
 81   }
 82 }
 83 
 84 // Helper functions to get around the circular dependency between
 85 // psScavenge.inline.hpp and psPromotionManager.inline.hpp.
 86 bool PSPromotionManager::should_scavenge(oop* p, bool check_to_space) {
 87   return PSScavenge::should_scavenge(p, check_to_space);
 88 }
 89 bool PSPromotionManager::should_scavenge(narrowOop* p, bool check_to_space) {
 90   return PSScavenge::should_scavenge(p, check_to_space);
 91 }
 92 
 93 PSPromotionManager* PSPromotionManager::gc_thread_promotion_manager(uint index) {
 94   assert(index &lt; ParallelGCThreads, &quot;index out of range&quot;);
 95   assert(_manager_array != NULL, &quot;Sanity&quot;);
 96   return &amp;_manager_array[index];
 97 }
 98 
 99 PSPromotionManager* PSPromotionManager::vm_thread_promotion_manager() {
100   assert(_manager_array != NULL, &quot;Sanity&quot;);
101   return &amp;_manager_array[ParallelGCThreads];
102 }
103 
104 void PSPromotionManager::pre_scavenge() {
105   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
106 
107   _preserved_marks_set-&gt;assert_empty();
108   _young_space = heap-&gt;young_gen()-&gt;to_space();
109 
110   for(uint i=0; i&lt;ParallelGCThreads+1; i++) {
111     manager_array(i)-&gt;reset();
112   }
113 }
114 
115 bool PSPromotionManager::post_scavenge(YoungGCTracer&amp; gc_tracer) {
116   bool promotion_failure_occurred = false;
117 
118   TASKQUEUE_STATS_ONLY(print_taskqueue_stats());
119   for (uint i = 0; i &lt; ParallelGCThreads + 1; i++) {
120     PSPromotionManager* manager = manager_array(i);
121     assert(manager-&gt;claimed_stack_depth()-&gt;is_empty(), &quot;should be empty&quot;);
122     if (manager-&gt;_promotion_failed_info.has_failed()) {
123       gc_tracer.report_promotion_failed(manager-&gt;_promotion_failed_info);
124       promotion_failure_occurred = true;
125     }
126     manager-&gt;flush_labs();
127   }
128   if (!promotion_failure_occurred) {
129     // If there was no promotion failure, the preserved mark stacks
130     // should be empty.
131     _preserved_marks_set-&gt;assert_empty();
132   }
133   return promotion_failure_occurred;
134 }
135 
136 #if TASKQUEUE_STATS
137 void
138 PSPromotionManager::print_local_stats(outputStream* const out, uint i) const {
139   #define FMT &quot; &quot; SIZE_FORMAT_W(10)
140   out-&gt;print_cr(&quot;%3u&quot; FMT FMT FMT FMT, i, _masked_pushes, _masked_steals,
141                 _arrays_chunked, _array_chunks_processed);
142   #undef FMT
143 }
144 
145 static const char* const pm_stats_hdr[] = {
146   &quot;    --------masked-------     arrays      array&quot;,
147   &quot;thr       push      steal    chunked     chunks&quot;,
148   &quot;--- ---------- ---------- ---------- ----------&quot;
149 };
150 
151 void
152 PSPromotionManager::print_taskqueue_stats() {
153   if (!log_is_enabled(Trace, gc, task, stats)) {
154     return;
155   }
156   Log(gc, task, stats) log;
157   ResourceMark rm;
158   LogStream ls(log.trace());
159   outputStream* out = &amp;ls;
160   out-&gt;print_cr(&quot;== GC Tasks Stats, GC %3d&quot;,
161                 ParallelScavengeHeap::heap()-&gt;total_collections());
162 
163   TaskQueueStats totals;
164   out-&gt;print(&quot;thr &quot;); TaskQueueStats::print_header(1, out); out-&gt;cr();
165   out-&gt;print(&quot;--- &quot;); TaskQueueStats::print_header(2, out); out-&gt;cr();
166   for (uint i = 0; i &lt; ParallelGCThreads + 1; ++i) {
167     TaskQueueStats&amp; next = manager_array(i)-&gt;_claimed_stack_depth.stats;
168     out-&gt;print(&quot;%3d &quot;, i); next.print(out); out-&gt;cr();
169     totals += next;
170   }
171   out-&gt;print(&quot;tot &quot;); totals.print(out); out-&gt;cr();
172 
173   const uint hlines = sizeof(pm_stats_hdr) / sizeof(pm_stats_hdr[0]);
174   for (uint i = 0; i &lt; hlines; ++i) out-&gt;print_cr(&quot;%s&quot;, pm_stats_hdr[i]);
175   for (uint i = 0; i &lt; ParallelGCThreads + 1; ++i) {
176     manager_array(i)-&gt;print_local_stats(out, i);
177   }
178 }
179 
180 void
181 PSPromotionManager::reset_stats() {
182   claimed_stack_depth()-&gt;stats.reset();
183   _masked_pushes = _masked_steals = 0;
184   _arrays_chunked = _array_chunks_processed = 0;
185 }
186 #endif // TASKQUEUE_STATS
187 
188 PSPromotionManager::PSPromotionManager() {
189   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
190 
191   // We set the old lab&#39;s start array.
192   _old_lab.set_start_array(old_gen()-&gt;start_array());
193 
194   uint queue_size;
195   claimed_stack_depth()-&gt;initialize();
196   queue_size = claimed_stack_depth()-&gt;max_elems();
197 
198   _totally_drain = (ParallelGCThreads == 1) || (GCDrainStackTargetSize == 0);
199   if (_totally_drain) {
200     _target_stack_size = 0;
201   } else {
202     // don&#39;t let the target stack size to be more than 1/4 of the entries
203     _target_stack_size = (uint) MIN2((uint) GCDrainStackTargetSize,
204                                      (uint) (queue_size / 4));
205   }
206 
207   _array_chunk_size = ParGCArrayScanChunk;
208   // let&#39;s choose 1.5x the chunk size
209   _min_array_size_for_chunking = 3 * _array_chunk_size / 2;
210 
211   _preserved_marks = NULL;
212 
213   reset();
214 }
215 
216 void PSPromotionManager::reset() {
217   assert(stacks_empty(), &quot;reset of non-empty stack&quot;);
218 
219   // We need to get an assert in here to make sure the labs are always flushed.
220 
221   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
222 
223   // Do not prefill the LAB&#39;s, save heap wastage!
224   HeapWord* lab_base = young_space()-&gt;top();
225   _young_lab.initialize(MemRegion(lab_base, (size_t)0));
226   _young_gen_is_full = false;
227 
228   lab_base = old_gen()-&gt;object_space()-&gt;top();
229   _old_lab.initialize(MemRegion(lab_base, (size_t)0));
230   _old_gen_is_full = false;
231 
232   _promotion_failed_info.reset();
233 
234   TASKQUEUE_STATS_ONLY(reset_stats());
235 }
236 
237 void PSPromotionManager::register_preserved_marks(PreservedMarks* preserved_marks) {
238   assert(_preserved_marks == NULL, &quot;do not set it twice&quot;);
239   _preserved_marks = preserved_marks;
240 }
241 
242 void PSPromotionManager::restore_preserved_marks() {
243   _preserved_marks_set-&gt;restore(&amp;ParallelScavengeHeap::heap()-&gt;workers());
244 }
245 
246 void PSPromotionManager::drain_stacks_depth(bool totally_drain) {
247   totally_drain = totally_drain || _totally_drain;
248 
249 #ifdef ASSERT
250   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
251   MutableSpace* to_space = heap-&gt;young_gen()-&gt;to_space();
252   MutableSpace* old_space = heap-&gt;old_gen()-&gt;object_space();
253 #endif /* ASSERT */
254 
255   OopStarTaskQueue* const tq = claimed_stack_depth();
256   do {
257     StarTask p;
258 
259     // Drain overflow stack first, so other threads can steal from
260     // claimed stack while we work.
261     while (tq-&gt;pop_overflow(p)) {
262       process_popped_location_depth(p);
263     }
264 
265     if (totally_drain) {
266       while (tq-&gt;pop_local(p)) {
267         process_popped_location_depth(p);
268       }
269     } else {
270       while (tq-&gt;size() &gt; _target_stack_size &amp;&amp; tq-&gt;pop_local(p)) {
271         process_popped_location_depth(p);
272       }
273     }
274   } while ((totally_drain &amp;&amp; !tq-&gt;taskqueue_empty()) || !tq-&gt;overflow_empty());
275 
276   assert(!totally_drain || tq-&gt;taskqueue_empty(), &quot;Sanity&quot;);
277   assert(totally_drain || tq-&gt;size() &lt;= _target_stack_size, &quot;Sanity&quot;);
278   assert(tq-&gt;overflow_empty(), &quot;Sanity&quot;);
279 }
280 
281 void PSPromotionManager::flush_labs() {
282   assert(stacks_empty(), &quot;Attempt to flush lab with live stack&quot;);
283 
284   // If either promotion lab fills up, we can flush the
285   // lab but not refill it, so check first.
286   assert(!_young_lab.is_flushed() || _young_gen_is_full, &quot;Sanity&quot;);
287   if (!_young_lab.is_flushed())
288     _young_lab.flush();
289 
290   assert(!_old_lab.is_flushed() || _old_gen_is_full, &quot;Sanity&quot;);
291   if (!_old_lab.is_flushed())
292     _old_lab.flush();
293 
294   // Let PSScavenge know if we overflowed
295   if (_young_gen_is_full) {
296     PSScavenge::set_survivor_overflow(true);
297   }
298 }
299 
300 template &lt;class T&gt; void PSPromotionManager::process_array_chunk_work(
301                                                  oop obj,
302                                                  int start, int end) {
303   assert(start &lt;= end, &quot;invariant&quot;);
304   T* const base      = (T*)objArrayOop(obj)-&gt;base();
305   T* p               = base + start;
306   T* const chunk_end = base + end;
307   while (p &lt; chunk_end) {
308     if (PSScavenge::should_scavenge(p)) {
309       claim_or_forward_depth(p);
310     }
311     ++p;
312   }
313 }
314 
315 void PSPromotionManager::process_array_chunk(oop old) {
316   assert(PSChunkLargeArrays, &quot;invariant&quot;);
317   assert(old-&gt;is_objArray(), &quot;invariant&quot;);
318   assert(old-&gt;is_forwarded(), &quot;invariant&quot;);
319 
320   TASKQUEUE_STATS_ONLY(++_array_chunks_processed);
321 
322   oop const obj = old-&gt;forwardee();
323 
324   int start;
325   int const end = arrayOop(old)-&gt;length();
326   if (end &gt; (int) _min_array_size_for_chunking) {
327     // we&#39;ll chunk more
328     start = end - _array_chunk_size;
329     assert(start &gt; 0, &quot;invariant&quot;);
330     arrayOop(old)-&gt;set_length(start);
331     push_depth(mask_chunked_array_oop(old));
332     TASKQUEUE_STATS_ONLY(++_masked_pushes);
333   } else {
334     // this is the final chunk for this array
335     start = 0;
336     int const actual_length = arrayOop(obj)-&gt;length();
337     arrayOop(old)-&gt;set_length(actual_length);
338   }
339 
340   if (UseCompressedOops) {
341     process_array_chunk_work&lt;narrowOop&gt;(obj, start, end);
342   } else {
343     process_array_chunk_work&lt;oop&gt;(obj, start, end);
344   }
345 }
346 
347 oop PSPromotionManager::oop_promotion_failed(oop obj, markWord obj_mark) {
348   assert(_old_gen_is_full || PromotionFailureALot, &quot;Sanity&quot;);
349 
350   // Attempt to CAS in the header.
351   // This tests if the header is still the same as when
352   // this started.  If it is the same (i.e., no forwarding
353   // pointer has been installed), then this thread owns
354   // it.
355   if (obj-&gt;cas_forward_to(obj, obj_mark)) {
356     // We won any races, we &quot;own&quot; this object.
357     assert(obj == obj-&gt;forwardee(), &quot;Sanity&quot;);
358 
359     _promotion_failed_info.register_copy_failure(obj-&gt;size());
360 
361     push_contents(obj);
362 
363     _preserved_marks-&gt;push_if_necessary(obj, obj_mark);
364   }  else {
365     // We lost, someone else &quot;owns&quot; this object
366     guarantee(obj-&gt;is_forwarded(), &quot;Object must be forwarded if the cas failed.&quot;);
367 
368     // No unallocation to worry about.
369     obj = obj-&gt;forwardee();
370   }
371 
372   log_develop_trace(gc, scavenge)(&quot;{promotion-failure %s &quot; PTR_FORMAT &quot; (%d)}&quot;, obj-&gt;klass()-&gt;internal_name(), p2i(obj), obj-&gt;size());
373 
374   return obj;
375 }
    </pre>
  </body>
</html>