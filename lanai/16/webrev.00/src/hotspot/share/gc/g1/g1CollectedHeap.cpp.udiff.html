<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/share/gc/g1/g1CollectedHeap.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1BiasedArray.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1CollectedHeap.hpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/g1CollectedHeap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -64,10 +64,11 @@</span>
  #include &quot;gc/g1/g1YoungRemSetSamplingThread.hpp&quot;
  #include &quot;gc/g1/g1VMOperations.hpp&quot;
  #include &quot;gc/g1/heapRegion.inline.hpp&quot;
  #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
  #include &quot;gc/g1/heapRegionSet.inline.hpp&quot;
<span class="udiff-line-added">+ #include &quot;gc/shared/concurrentGCBreakpoints.hpp&quot;</span>
  #include &quot;gc/shared/gcBehaviours.hpp&quot;
  #include &quot;gc/shared/gcHeapSummary.hpp&quot;
  #include &quot;gc/shared/gcId.hpp&quot;
  #include &quot;gc/shared/gcLocker.hpp&quot;
  #include &quot;gc/shared/gcTimer.hpp&quot;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1797,12 +1798,12 @@</span>
    _numa-&gt;set_region_info(HeapRegion::GrainBytes, page_size);
  
    // Create the G1ConcurrentMark data structure and thread.
    // (Must do this late, so that &quot;max_regions&quot; is defined.)
    _cm = new G1ConcurrentMark(this, prev_bitmap_storage, next_bitmap_storage);
<span class="udiff-line-modified-removed">-   if (_cm == NULL || !_cm-&gt;completed_initialization()) {</span>
<span class="udiff-line-modified-removed">-     vm_shutdown_during_initialization(&quot;Could not create/initialize G1ConcurrentMark&quot;);</span>
<span class="udiff-line-modified-added">+   if (!_cm-&gt;completed_initialization()) {</span>
<span class="udiff-line-modified-added">+     vm_shutdown_during_initialization(&quot;Could not initialize G1ConcurrentMark&quot;);</span>
      return JNI_ENOMEM;
    }
    _cm_thread = _cm-&gt;cm_thread();
  
    // Now expand into the initial heap size.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2001,10 +2002,11 @@</span>
  
  bool G1CollectedHeap::should_do_concurrent_full_gc(GCCause::Cause cause) {
    switch (cause) {
      case GCCause::_g1_humongous_allocation: return true;
      case GCCause::_g1_periodic_collection:  return G1PeriodicGCInvokesConcurrent;
<span class="udiff-line-added">+     case GCCause::_wb_breakpoint:           return true;</span>
      default:                                return is_user_requested_concurrent_full_gc(cause);
    }
  }
  
  bool G1CollectedHeap::should_upgrade_to_full_gc(GCCause::Cause cause) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2171,28 +2173,46 @@</span>
        gc_counter = total_collections();
        old_marking_started_after = _old_marking_cycles_started;
        old_marking_completed_after = _old_marking_cycles_completed;
      }
  
<span class="udiff-line-modified-removed">-     if (!GCCause::is_user_requested_gc(cause)) {</span>
<span class="udiff-line-modified-added">+     if (cause == GCCause::_wb_breakpoint) {</span>
<span class="udiff-line-added">+       if (op.gc_succeeded()) {</span>
<span class="udiff-line-added">+         LOG_COLLECT_CONCURRENTLY_COMPLETE(cause, true);</span>
<span class="udiff-line-added">+         return true;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+       // When _wb_breakpoint there can&#39;t be another cycle or deferred.</span>
<span class="udiff-line-added">+       assert(!op.cycle_already_in_progress(), &quot;invariant&quot;);</span>
<span class="udiff-line-added">+       assert(!op.whitebox_attached(), &quot;invariant&quot;);</span>
<span class="udiff-line-added">+       // Concurrent cycle attempt might have been cancelled by some other</span>
<span class="udiff-line-added">+       // collection, so retry.  Unlike other cases below, we want to retry</span>
<span class="udiff-line-added">+       // even if cancelled by a STW full collection, because we really want</span>
<span class="udiff-line-added">+       // to start a concurrent cycle.</span>
<span class="udiff-line-added">+       if (old_marking_started_before != old_marking_started_after) {</span>
<span class="udiff-line-added">+         LOG_COLLECT_CONCURRENTLY(cause, &quot;ignoring STW full GC&quot;);</span>
<span class="udiff-line-added">+         old_marking_started_before = old_marking_started_after;</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     } else if (!GCCause::is_user_requested_gc(cause)) {</span>
        // For an &quot;automatic&quot; (not user-requested) collection, we just need to
        // ensure that progress is made.
        //
        // Request is finished if any of
        // (1) the VMOp successfully performed a GC,
        // (2) a concurrent cycle was already in progress,
<span class="udiff-line-modified-removed">-       // (3) a new cycle was started (by this thread or some other), or</span>
<span class="udiff-line-modified-removed">-       // (4) a Full GC was performed.</span>
<span class="udiff-line-modified-removed">-       // Cases (3) and (4) are detected together by a change to</span>
<span class="udiff-line-modified-added">+       // (3) whitebox is controlling concurrent cycles,</span>
<span class="udiff-line-modified-added">+       // (4) a new cycle was started (by this thread or some other), or</span>
<span class="udiff-line-modified-added">+       // (5) a Full GC was performed.</span>
<span class="udiff-line-added">+       // Cases (4) and (5) are detected together by a change to</span>
        // _old_marking_cycles_started.
        //
<span class="udiff-line-modified-removed">-       // Note that (1) does not imply (3).  If we&#39;re still in the mixed</span>
<span class="udiff-line-modified-added">+       // Note that (1) does not imply (4).  If we&#39;re still in the mixed</span>
        // phase of an earlier concurrent collection, the request to make the
        // collection an initial-mark won&#39;t be honored.  If we don&#39;t check for
        // both conditions we&#39;ll spin doing back-to-back collections.
        if (op.gc_succeeded() ||
            op.cycle_already_in_progress() ||
<span class="udiff-line-added">+           op.whitebox_attached() ||</span>
            (old_marking_started_before != old_marking_started_after)) {
          LOG_COLLECT_CONCURRENTLY_COMPLETE(cause, true);
          return true;
        }
      } else {                    // User-requested GC.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2242,24 +2262,36 @@</span>
        // wait &amp;etc should have recognized as finishing this request.  This
        // differs from a non-user-request, where gc_succeeded does not imply
        // a new cycle was started.
        assert(!op.gc_succeeded(), &quot;invariant&quot;);
  
<span class="udiff-line-removed">-       // If VMOp failed because a cycle was already in progress, it is now</span>
<span class="udiff-line-removed">-       // complete.  But it didn&#39;t finish this user-requested GC, so try</span>
<span class="udiff-line-removed">-       // again.</span>
        if (op.cycle_already_in_progress()) {
<span class="udiff-line-added">+         // If VMOp failed because a cycle was already in progress, it</span>
<span class="udiff-line-added">+         // is now complete.  But it didn&#39;t finish this user-requested</span>
<span class="udiff-line-added">+         // GC, so try again.</span>
          LOG_COLLECT_CONCURRENTLY(cause, &quot;retry after in-progress&quot;);
          continue;
<span class="udiff-line-added">+       } else if (op.whitebox_attached()) {</span>
<span class="udiff-line-added">+         // If WhiteBox wants control, wait for notification of a state</span>
<span class="udiff-line-added">+         // change in the controller, then try again.  Don&#39;t wait for</span>
<span class="udiff-line-added">+         // release of control, since collections may complete while in</span>
<span class="udiff-line-added">+         // control.  Note: This won&#39;t recognize a STW full collection</span>
<span class="udiff-line-added">+         // while waiting; we can&#39;t wait on multiple monitors.</span>
<span class="udiff-line-added">+         LOG_COLLECT_CONCURRENTLY(cause, &quot;whitebox control stall&quot;);</span>
<span class="udiff-line-added">+         MonitorLocker ml(ConcurrentGCBreakpoints::monitor());</span>
<span class="udiff-line-added">+         if (ConcurrentGCBreakpoints::is_controlled()) {</span>
<span class="udiff-line-added">+           ml.wait();</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+         continue;</span>
        }
      }
  
      // Collection failed and should be retried.
      assert(op.transient_failure(), &quot;invariant&quot;);
  
<span class="udiff-line-removed">-     // If GCLocker is active, wait until clear before retrying.</span>
      if (GCLocker::is_active_and_needs_gc()) {
<span class="udiff-line-added">+       // If GCLocker is active, wait until clear before retrying.</span>
        LOG_COLLECT_CONCURRENTLY(cause, &quot;gc-locker stall&quot;);
        GCLocker::stall_until_clear();
      }
  
      LOG_COLLECT_CONCURRENTLY(cause, &quot;retry&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -2451,18 +2483,14 @@</span>
  
  void G1CollectedHeap::verify(VerifyOption vo) {
    _verifier-&gt;verify(vo);
  }
  
<span class="udiff-line-modified-removed">- bool G1CollectedHeap::supports_concurrent_phase_control() const {</span>
<span class="udiff-line-modified-added">+ bool G1CollectedHeap::supports_concurrent_gc_breakpoints() const {</span>
    return true;
  }
  
<span class="udiff-line-removed">- bool G1CollectedHeap::request_concurrent_phase(const char* phase) {</span>
<span class="udiff-line-removed">-   return _cm_thread-&gt;request_concurrent_phase(phase);</span>
<span class="udiff-line-removed">- }</span>
<span class="udiff-line-removed">- </span>
  bool G1CollectedHeap::is_heterogeneous_heap() const {
    return G1Arguments::is_heterogeneous_heap();
  }
  
  class PrintRegionClosure: public HeapRegionClosure {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -3176,10 +3204,11 @@</span>
      // thread(s) could be running concurrently with us. Make sure that anything
      // after this point does not assume that we are the only GC thread running.
      // Note: of course, the actual marking work will not start until the safepoint
      // itself is released in SuspendibleThreadSet::desynchronize().
      do_concurrent_mark();
<span class="udiff-line-added">+     ConcurrentGCBreakpoints::notify_idle_to_active();</span>
    }
  }
  
  void G1CollectedHeap::remove_self_forwarding_pointers(G1RedirtyCardsQueueSet* rdcqs) {
    G1ParRemoveSelfForwardPtrsTask rsfp_task(rdcqs);
</pre>
<center><a href="g1BiasedArray.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1CollectedHeap.hpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>