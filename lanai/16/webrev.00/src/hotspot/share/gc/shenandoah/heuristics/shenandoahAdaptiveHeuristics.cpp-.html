<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/shenandoah/heuristics/shenandoahAdaptiveHeuristics.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2018, 2019, Red Hat, Inc. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 
 27 #include &quot;gc/shenandoah/heuristics/shenandoahAdaptiveHeuristics.hpp&quot;
 28 #include &quot;gc/shenandoah/shenandoahCollectionSet.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahFreeSet.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;
 31 #include &quot;logging/log.hpp&quot;
 32 #include &quot;logging/logTag.hpp&quot;
 33 #include &quot;utilities/quickSort.hpp&quot;
 34 
 35 ShenandoahAdaptiveHeuristics::ShenandoahAdaptiveHeuristics() :
 36   ShenandoahHeuristics(),
 37   _cycle_gap_history(new TruncatedSeq(5)),
 38   _conc_mark_duration_history(new TruncatedSeq(5)),
 39   _conc_uprefs_duration_history(new TruncatedSeq(5)) {}
 40 
 41 ShenandoahAdaptiveHeuristics::~ShenandoahAdaptiveHeuristics() {}
 42 
 43 void ShenandoahAdaptiveHeuristics::choose_collection_set_from_regiondata(ShenandoahCollectionSet* cset,
 44                                                                          RegionData* data, size_t size,
 45                                                                          size_t actual_free) {
 46   size_t garbage_threshold = ShenandoahHeapRegion::region_size_bytes() * ShenandoahGarbageThreshold / 100;
 47 
 48   // The logic for cset selection in adaptive is as follows:
 49   //
 50   //   1. We cannot get cset larger than available free space. Otherwise we guarantee OOME
 51   //      during evacuation, and thus guarantee full GC. In practice, we also want to let
 52   //      application to allocate something. This is why we limit CSet to some fraction of
 53   //      available space. In non-overloaded heap, max_cset would contain all plausible candidates
 54   //      over garbage threshold.
 55   //
 56   //   2. We should not get cset too low so that free threshold would not be met right
 57   //      after the cycle. Otherwise we get back-to-back cycles for no reason if heap is
 58   //      too fragmented. In non-overloaded non-fragmented heap min_garbage would be around zero.
 59   //
 60   // Therefore, we start by sorting the regions by garbage. Then we unconditionally add the best candidates
 61   // before we meet min_garbage. Then we add all candidates that fit with a garbage threshold before
 62   // we hit max_cset. When max_cset is hit, we terminate the cset selection. Note that in this scheme,
 63   // ShenandoahGarbageThreshold is the soft threshold which would be ignored until min_garbage is hit.
 64 
 65   size_t capacity    = ShenandoahHeap::heap()-&gt;max_capacity();
 66   size_t free_target = capacity / 100 * ShenandoahMinFreeThreshold;
 67   size_t min_garbage = free_target &gt; actual_free ? (free_target - actual_free) : 0;
 68   size_t max_cset    = (size_t)((1.0 * capacity / 100 * ShenandoahEvacReserve) / ShenandoahEvacWaste);
 69 
 70   log_info(gc, ergo)(&quot;Adaptive CSet Selection. Target Free: &quot; SIZE_FORMAT &quot;%s, Actual Free: &quot;
 71                      SIZE_FORMAT &quot;%s, Max CSet: &quot; SIZE_FORMAT &quot;%s, Min Garbage: &quot; SIZE_FORMAT &quot;%s&quot;,
 72                      byte_size_in_proper_unit(free_target), proper_unit_for_byte_size(free_target),
 73                      byte_size_in_proper_unit(actual_free), proper_unit_for_byte_size(actual_free),
 74                      byte_size_in_proper_unit(max_cset),    proper_unit_for_byte_size(max_cset),
 75                      byte_size_in_proper_unit(min_garbage), proper_unit_for_byte_size(min_garbage));
 76 
 77   // Better select garbage-first regions
 78   QuickSort::sort&lt;RegionData&gt;(data, (int)size, compare_by_garbage, false);
 79 
 80   size_t cur_cset = 0;
 81   size_t cur_garbage = 0;
 82   _bytes_in_cset = 0;
 83 
 84   for (size_t idx = 0; idx &lt; size; idx++) {
 85     ShenandoahHeapRegion* r = data[idx]._region;
 86 
 87     size_t new_cset    = cur_cset + r-&gt;get_live_data_bytes();
 88     size_t new_garbage = cur_garbage + r-&gt;garbage();
 89 
 90     if (new_cset &gt; max_cset) {
 91       break;
 92     }
 93 
 94     if ((new_garbage &lt; min_garbage) || (r-&gt;garbage() &gt; garbage_threshold)) {
 95       cset-&gt;add_region(r);
 96       _bytes_in_cset += r-&gt;used();
 97       cur_cset = new_cset;
 98       cur_garbage = new_garbage;
 99     }
100   }
101 }
102 
103 void ShenandoahAdaptiveHeuristics::record_cycle_start() {
104   ShenandoahHeuristics::record_cycle_start();
105   double last_cycle_gap = (_cycle_start - _last_cycle_end);
106   _cycle_gap_history-&gt;add(last_cycle_gap);
107 }
108 
109 void ShenandoahAdaptiveHeuristics::record_phase_time(ShenandoahPhaseTimings::Phase phase, double secs) {
110   if (phase == ShenandoahPhaseTimings::conc_mark) {
111     _conc_mark_duration_history-&gt;add(secs);
112   } else if (phase == ShenandoahPhaseTimings::conc_update_refs) {
113     _conc_uprefs_duration_history-&gt;add(secs);
114   } // Else ignore
115 }
116 
117 bool ShenandoahAdaptiveHeuristics::should_start_gc() const {
118   ShenandoahHeap* heap = ShenandoahHeap::heap();
119   size_t capacity = heap-&gt;max_capacity();
120   size_t available = heap-&gt;free_set()-&gt;available();
121 
122   // Check if we are falling below the worst limit, time to trigger the GC, regardless of
123   // anything else.
124   size_t min_threshold = capacity / 100 * ShenandoahMinFreeThreshold;
125   if (available &lt; min_threshold) {
126     log_info(gc)(&quot;Trigger: Free (&quot; SIZE_FORMAT &quot;%s) is below minimum threshold (&quot; SIZE_FORMAT &quot;%s)&quot;,
127                  byte_size_in_proper_unit(available),     proper_unit_for_byte_size(available),
128                  byte_size_in_proper_unit(min_threshold), proper_unit_for_byte_size(min_threshold));
129     return true;
130   }
131 
132   // Check if are need to learn a bit about the application
133   const size_t max_learn = ShenandoahLearningSteps;
134   if (_gc_times_learned &lt; max_learn) {
135     size_t init_threshold = capacity / 100 * ShenandoahInitFreeThreshold;
136     if (available &lt; init_threshold) {
137       log_info(gc)(&quot;Trigger: Learning &quot; SIZE_FORMAT &quot; of &quot; SIZE_FORMAT &quot;. Free (&quot; SIZE_FORMAT &quot;%s) is below initial threshold (&quot; SIZE_FORMAT &quot;%s)&quot;,
138                    _gc_times_learned + 1, max_learn,
139                    byte_size_in_proper_unit(available),      proper_unit_for_byte_size(available),
140                    byte_size_in_proper_unit(init_threshold), proper_unit_for_byte_size(init_threshold));
141       return true;
142     }
143   }
144 
145   // Check if allocation headroom is still okay. This also factors in:
146   //   1. Some space to absorb allocation spikes
147   //   2. Accumulated penalties from Degenerated and Full GC
148 
149   size_t allocation_headroom = available;
150 
151   size_t spike_headroom = capacity / 100 * ShenandoahAllocSpikeFactor;
152   size_t penalties      = capacity / 100 * _gc_time_penalties;
153 
154   allocation_headroom -= MIN2(allocation_headroom, spike_headroom);
155   allocation_headroom -= MIN2(allocation_headroom, penalties);
156 
157   // TODO: Allocation rate is way too averaged to be useful during state changes
158 
159   double average_gc = _gc_time_history-&gt;avg();
160   double time_since_last = time_since_last_gc();
161   double allocation_rate = heap-&gt;bytes_allocated_since_gc_start() / time_since_last;
162 
163   if (average_gc &gt; allocation_headroom / allocation_rate) {
164     log_info(gc)(&quot;Trigger: Average GC time (%.2f ms) is above the time for allocation rate (%.0f %sB/s) to deplete free headroom (&quot; SIZE_FORMAT &quot;%s)&quot;,
165                  average_gc * 1000,
166                  byte_size_in_proper_unit(allocation_rate),     proper_unit_for_byte_size(allocation_rate),
167                  byte_size_in_proper_unit(allocation_headroom), proper_unit_for_byte_size(allocation_headroom));
168     log_info(gc, ergo)(&quot;Free headroom: &quot; SIZE_FORMAT &quot;%s (free) - &quot; SIZE_FORMAT &quot;%s (spike) - &quot; SIZE_FORMAT &quot;%s (penalties) = &quot; SIZE_FORMAT &quot;%s&quot;,
169                  byte_size_in_proper_unit(available),           proper_unit_for_byte_size(available),
170                  byte_size_in_proper_unit(spike_headroom),      proper_unit_for_byte_size(spike_headroom),
171                  byte_size_in_proper_unit(penalties),           proper_unit_for_byte_size(penalties),
172                  byte_size_in_proper_unit(allocation_headroom), proper_unit_for_byte_size(allocation_headroom));
173     return true;
174   }
175 
176   return ShenandoahHeuristics::should_start_gc();
177 }
178 
179 bool ShenandoahAdaptiveHeuristics::should_start_update_refs() {
180   if (! _update_refs_adaptive) {
181     return _update_refs_early;
182   }
183 
184   double cycle_gap_avg = _cycle_gap_history-&gt;avg();
185   double conc_mark_avg = _conc_mark_duration_history-&gt;avg();
186   double conc_uprefs_avg = _conc_uprefs_duration_history-&gt;avg();
187 
188   if (_update_refs_early) {
189     double threshold = ShenandoahMergeUpdateRefsMinGap / 100.0;
190     if (conc_mark_avg + conc_uprefs_avg &gt; cycle_gap_avg * threshold) {
191       _update_refs_early = false;
192     }
193   } else {
194     double threshold = ShenandoahMergeUpdateRefsMaxGap / 100.0;
195     if (conc_mark_avg + conc_uprefs_avg &lt; cycle_gap_avg * threshold) {
196       _update_refs_early = true;
197     }
198   }
199   return _update_refs_early;
200 }
201 
202 const char* ShenandoahAdaptiveHeuristics::name() {
203   return &quot;adaptive&quot;;
204 }
205 
206 bool ShenandoahAdaptiveHeuristics::is_diagnostic() {
207   return false;
208 }
209 
210 bool ShenandoahAdaptiveHeuristics::is_experimental() {
211   return false;
212 }
    </pre>
  </body>
</html>