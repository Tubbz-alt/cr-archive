<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/gc/shenandoah/shenandoahHeapRegion.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
    <script type="text/javascript" src="../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2013, 2019, Red Hat, Inc. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;memory/allocation.hpp&quot;
 27 #include &quot;gc/shenandoah/shenandoahHeapRegionSet.inline.hpp&quot;
 28 #include &quot;gc/shenandoah/shenandoahHeap.inline.hpp&quot;
 29 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;
 30 #include &quot;gc/shenandoah/shenandoahMarkingContext.inline.hpp&quot;
 31 #include &quot;gc/shenandoah/shenandoahTraversalGC.hpp&quot;
 32 #include &quot;gc/shared/space.inline.hpp&quot;
 33 #include &quot;jfr/jfrEvents.hpp&quot;
 34 #include &quot;memory/iterator.inline.hpp&quot;
 35 #include &quot;memory/resourceArea.hpp&quot;
 36 #include &quot;memory/universe.hpp&quot;
 37 #include &quot;oops/oop.inline.hpp&quot;
 38 #include &quot;runtime/atomic.hpp&quot;
 39 #include &quot;runtime/java.hpp&quot;
 40 #include &quot;runtime/mutexLocker.hpp&quot;
 41 #include &quot;runtime/os.hpp&quot;
 42 #include &quot;runtime/safepoint.hpp&quot;
 43 
 44 size_t ShenandoahHeapRegion::RegionCount = 0;
 45 size_t ShenandoahHeapRegion::RegionSizeBytes = 0;
 46 size_t ShenandoahHeapRegion::RegionSizeWords = 0;
 47 size_t ShenandoahHeapRegion::RegionSizeBytesShift = 0;
 48 size_t ShenandoahHeapRegion::RegionSizeWordsShift = 0;
 49 size_t ShenandoahHeapRegion::RegionSizeBytesMask = 0;
 50 size_t ShenandoahHeapRegion::RegionSizeWordsMask = 0;
 51 size_t ShenandoahHeapRegion::HumongousThresholdBytes = 0;
 52 size_t ShenandoahHeapRegion::HumongousThresholdWords = 0;
 53 size_t ShenandoahHeapRegion::MaxTLABSizeBytes = 0;
 54 size_t ShenandoahHeapRegion::MaxTLABSizeWords = 0;
 55 
 56 ShenandoahHeapRegion::PaddedAllocSeqNum ShenandoahHeapRegion::_alloc_seq_num;
 57 
 58 ShenandoahHeapRegion::ShenandoahHeapRegion(ShenandoahHeap* heap, HeapWord* start,
 59                                            size_t size_words, size_t index, bool committed) :
 60   _heap(heap),
 61   _reserved(MemRegion(start, size_words)),
 62   _region_number(index),
 63   _new_top(NULL),
 64   _empty_time(os::elapsedTime()),
 65   _state(committed ? _empty_committed : _empty_uncommitted),
 66   _tlab_allocs(0),
 67   _gclab_allocs(0),
 68   _shared_allocs(0),
 69   _seqnum_first_alloc_mutator(0),
 70   _seqnum_first_alloc_gc(0),
 71   _seqnum_last_alloc_mutator(0),
 72   _seqnum_last_alloc_gc(0),
 73   _live_data(0),
<a name="1" id="anc1"></a><span class="line-modified"> 74   _critical_pins(0),</span>
<span class="line-added"> 75   _update_watermark(start) {</span>
 76 
 77   ContiguousSpace::initialize(_reserved, true, committed);
 78 }
 79 
 80 size_t ShenandoahHeapRegion::region_number() const {
 81   return _region_number;
 82 }
 83 
 84 void ShenandoahHeapRegion::report_illegal_transition(const char *method) {
 85   ResourceMark rm;
 86   stringStream ss;
 87   ss.print(&quot;Illegal region state transition from \&quot;%s\&quot;, at %s\n  &quot;, region_state_to_string(_state), method);
 88   print_on(&amp;ss);
 89   fatal(&quot;%s&quot;, ss.as_string());
 90 }
 91 
 92 void ShenandoahHeapRegion::make_regular_allocation() {
 93   _heap-&gt;assert_heaplock_owned_by_current_thread();
 94 
 95   switch (_state) {
 96     case _empty_uncommitted:
 97       do_commit();
 98     case _empty_committed:
 99       set_state(_regular);
100     case _regular:
101     case _pinned:
102       return;
103     default:
104       report_illegal_transition(&quot;regular allocation&quot;);
105   }
106 }
107 
108 void ShenandoahHeapRegion::make_regular_bypass() {
109   _heap-&gt;assert_heaplock_owned_by_current_thread();
110   assert (_heap-&gt;is_full_gc_in_progress() || _heap-&gt;is_degenerated_gc_in_progress(),
111           &quot;only for full or degen GC&quot;);
112 
113   switch (_state) {
114     case _empty_uncommitted:
115       do_commit();
116     case _empty_committed:
117     case _cset:
118     case _humongous_start:
119     case _humongous_cont:
120       set_state(_regular);
121       return;
122     case _pinned_cset:
123       set_state(_pinned);
124       return;
125     case _regular:
126     case _pinned:
127       return;
128     default:
129       report_illegal_transition(&quot;regular bypass&quot;);
130   }
131 }
132 
133 void ShenandoahHeapRegion::make_humongous_start() {
134   _heap-&gt;assert_heaplock_owned_by_current_thread();
135   switch (_state) {
136     case _empty_uncommitted:
137       do_commit();
138     case _empty_committed:
139       set_state(_humongous_start);
140       return;
141     default:
142       report_illegal_transition(&quot;humongous start allocation&quot;);
143   }
144 }
145 
146 void ShenandoahHeapRegion::make_humongous_start_bypass() {
147   _heap-&gt;assert_heaplock_owned_by_current_thread();
148   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
149 
150   switch (_state) {
151     case _empty_committed:
152     case _regular:
153     case _humongous_start:
154     case _humongous_cont:
155       set_state(_humongous_start);
156       return;
157     default:
158       report_illegal_transition(&quot;humongous start bypass&quot;);
159   }
160 }
161 
162 void ShenandoahHeapRegion::make_humongous_cont() {
163   _heap-&gt;assert_heaplock_owned_by_current_thread();
164   switch (_state) {
165     case _empty_uncommitted:
166       do_commit();
167     case _empty_committed:
168      set_state(_humongous_cont);
169       return;
170     default:
171       report_illegal_transition(&quot;humongous continuation allocation&quot;);
172   }
173 }
174 
175 void ShenandoahHeapRegion::make_humongous_cont_bypass() {
176   _heap-&gt;assert_heaplock_owned_by_current_thread();
177   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
178 
179   switch (_state) {
180     case _empty_committed:
181     case _regular:
182     case _humongous_start:
183     case _humongous_cont:
184       set_state(_humongous_cont);
185       return;
186     default:
187       report_illegal_transition(&quot;humongous continuation bypass&quot;);
188   }
189 }
190 
191 void ShenandoahHeapRegion::make_pinned() {
192   _heap-&gt;assert_heaplock_owned_by_current_thread();
193   assert(pin_count() &gt; 0, &quot;Should have pins: &quot; SIZE_FORMAT, pin_count());
194 
195   switch (_state) {
196     case _regular:
197       set_state(_pinned);
198     case _pinned_cset:
199     case _pinned:
200       return;
201     case _humongous_start:
202       set_state(_pinned_humongous_start);
203     case _pinned_humongous_start:
204       return;
205     case _cset:
206       _state = _pinned_cset;
207       return;
208     default:
209       report_illegal_transition(&quot;pinning&quot;);
210   }
211 }
212 
213 void ShenandoahHeapRegion::make_unpinned() {
214   _heap-&gt;assert_heaplock_owned_by_current_thread();
215   assert(pin_count() == 0, &quot;Should not have pins: &quot; SIZE_FORMAT, pin_count());
216 
217   switch (_state) {
218     case _pinned:
219       set_state(_regular);
220       return;
221     case _regular:
222     case _humongous_start:
223       return;
224     case _pinned_cset:
225       set_state(_cset);
226       return;
227     case _pinned_humongous_start:
228       set_state(_humongous_start);
229       return;
230     default:
231       report_illegal_transition(&quot;unpinning&quot;);
232   }
233 }
234 
235 void ShenandoahHeapRegion::make_cset() {
236   _heap-&gt;assert_heaplock_owned_by_current_thread();
237   switch (_state) {
238     case _regular:
239       set_state(_cset);
240     case _cset:
241       return;
242     default:
243       report_illegal_transition(&quot;cset&quot;);
244   }
245 }
246 
247 void ShenandoahHeapRegion::make_trash() {
248   _heap-&gt;assert_heaplock_owned_by_current_thread();
249   switch (_state) {
250     case _cset:
251       // Reclaiming cset regions
252     case _humongous_start:
253     case _humongous_cont:
254       // Reclaiming humongous regions
255     case _regular:
256       // Immediate region reclaim
257       set_state(_trash);
258       return;
259     default:
260       report_illegal_transition(&quot;trashing&quot;);
261   }
262 }
263 
264 void ShenandoahHeapRegion::make_trash_immediate() {
265   make_trash();
266 
267   // On this path, we know there are no marked objects in the region,
268   // tell marking context about it to bypass bitmap resets.
269   _heap-&gt;complete_marking_context()-&gt;reset_top_bitmap(this);
270 }
271 
272 void ShenandoahHeapRegion::make_empty() {
273   _heap-&gt;assert_heaplock_owned_by_current_thread();
274   switch (_state) {
275     case _trash:
276       set_state(_empty_committed);
277       _empty_time = os::elapsedTime();
278       return;
279     default:
280       report_illegal_transition(&quot;emptying&quot;);
281   }
282 }
283 
284 void ShenandoahHeapRegion::make_uncommitted() {
285   _heap-&gt;assert_heaplock_owned_by_current_thread();
286   switch (_state) {
287     case _empty_committed:
288       do_uncommit();
289       set_state(_empty_uncommitted);
290       return;
291     default:
292       report_illegal_transition(&quot;uncommiting&quot;);
293   }
294 }
295 
296 void ShenandoahHeapRegion::make_committed_bypass() {
297   _heap-&gt;assert_heaplock_owned_by_current_thread();
298   assert (_heap-&gt;is_full_gc_in_progress(), &quot;only for full GC&quot;);
299 
300   switch (_state) {
301     case _empty_uncommitted:
302       do_commit();
303       set_state(_empty_committed);
304       return;
305     default:
306       report_illegal_transition(&quot;commit bypass&quot;);
307   }
308 }
309 
310 void ShenandoahHeapRegion::clear_live_data() {
311   Atomic::release_store_fence(&amp;_live_data, (size_t)0);
312 }
313 
314 void ShenandoahHeapRegion::reset_alloc_metadata() {
315   _tlab_allocs = 0;
316   _gclab_allocs = 0;
317   _shared_allocs = 0;
318   _seqnum_first_alloc_mutator = 0;
319   _seqnum_last_alloc_mutator = 0;
320   _seqnum_first_alloc_gc = 0;
321   _seqnum_last_alloc_gc = 0;
322 }
323 
324 void ShenandoahHeapRegion::reset_alloc_metadata_to_shared() {
325   if (used() &gt; 0) {
326     _tlab_allocs = 0;
327     _gclab_allocs = 0;
328     _shared_allocs = used() &gt;&gt; LogHeapWordSize;
329     uint64_t next = _alloc_seq_num.value++;
330     _seqnum_first_alloc_mutator = next;
331     _seqnum_last_alloc_mutator = next;
332     _seqnum_first_alloc_gc = 0;
333     _seqnum_last_alloc_gc = 0;
334   } else {
335     reset_alloc_metadata();
336   }
337 }
338 
339 size_t ShenandoahHeapRegion::get_shared_allocs() const {
340   return _shared_allocs * HeapWordSize;
341 }
342 
343 size_t ShenandoahHeapRegion::get_tlab_allocs() const {
344   return _tlab_allocs * HeapWordSize;
345 }
346 
347 size_t ShenandoahHeapRegion::get_gclab_allocs() const {
348   return _gclab_allocs * HeapWordSize;
349 }
350 
351 void ShenandoahHeapRegion::set_live_data(size_t s) {
352   assert(Thread::current()-&gt;is_VM_thread(), &quot;by VM thread&quot;);
353   _live_data = (s &gt;&gt; LogHeapWordSize);
354 }
355 
356 size_t ShenandoahHeapRegion::get_live_data_words() const {
357   return Atomic::load_acquire(&amp;_live_data);
358 }
359 
360 size_t ShenandoahHeapRegion::get_live_data_bytes() const {
361   return get_live_data_words() * HeapWordSize;
362 }
363 
364 bool ShenandoahHeapRegion::has_live() const {
365   return get_live_data_words() != 0;
366 }
367 
368 size_t ShenandoahHeapRegion::garbage() const {
369   assert(used() &gt;= get_live_data_bytes(), &quot;Live Data must be a subset of used() live: &quot; SIZE_FORMAT &quot; used: &quot; SIZE_FORMAT,
370          get_live_data_bytes(), used());
371 
372   size_t result = used() - get_live_data_bytes();
373   return result;
374 }
375 
376 void ShenandoahHeapRegion::print_on(outputStream* st) const {
377   st-&gt;print(&quot;|&quot;);
378   st-&gt;print(SIZE_FORMAT_W(5), this-&gt;_region_number);
379 
380   switch (_state) {
381     case _empty_uncommitted:
382       st-&gt;print(&quot;|EU &quot;);
383       break;
384     case _empty_committed:
385       st-&gt;print(&quot;|EC &quot;);
386       break;
387     case _regular:
388       st-&gt;print(&quot;|R  &quot;);
389       break;
390     case _humongous_start:
391       st-&gt;print(&quot;|H  &quot;);
392       break;
393     case _pinned_humongous_start:
394       st-&gt;print(&quot;|HP &quot;);
395       break;
396     case _humongous_cont:
397       st-&gt;print(&quot;|HC &quot;);
398       break;
399     case _cset:
400       st-&gt;print(&quot;|CS &quot;);
401       break;
402     case _trash:
403       st-&gt;print(&quot;|T  &quot;);
404       break;
405     case _pinned:
406       st-&gt;print(&quot;|P  &quot;);
407       break;
408     case _pinned_cset:
409       st-&gt;print(&quot;|CSP&quot;);
410       break;
411     default:
412       ShouldNotReachHere();
413   }
414   st-&gt;print(&quot;|BTE &quot; INTPTR_FORMAT_W(12) &quot;, &quot; INTPTR_FORMAT_W(12) &quot;, &quot; INTPTR_FORMAT_W(12),
415             p2i(bottom()), p2i(top()), p2i(end()));
416   st-&gt;print(&quot;|TAMS &quot; INTPTR_FORMAT_W(12),
417             p2i(_heap-&gt;marking_context()-&gt;top_at_mark_start(const_cast&lt;ShenandoahHeapRegion*&gt;(this))));
418   st-&gt;print(&quot;|U &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(used()),                proper_unit_for_byte_size(used()));
419   st-&gt;print(&quot;|T &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_tlab_allocs()),     proper_unit_for_byte_size(get_tlab_allocs()));
420   st-&gt;print(&quot;|G &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_gclab_allocs()),    proper_unit_for_byte_size(get_gclab_allocs()));
421   st-&gt;print(&quot;|S &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_shared_allocs()),   proper_unit_for_byte_size(get_shared_allocs()));
422   st-&gt;print(&quot;|L &quot; SIZE_FORMAT_W(5) &quot;%1s&quot;, byte_size_in_proper_unit(get_live_data_bytes()), proper_unit_for_byte_size(get_live_data_bytes()));
423   st-&gt;print(&quot;|CP &quot; SIZE_FORMAT_W(3), pin_count());
424   st-&gt;print(&quot;|SN &quot; UINT64_FORMAT_X_W(12) &quot;, &quot; UINT64_FORMAT_X_W(8) &quot;, &quot; UINT64_FORMAT_X_W(8) &quot;, &quot; UINT64_FORMAT_X_W(8),
425             seqnum_first_alloc_mutator(), seqnum_last_alloc_mutator(),
426             seqnum_first_alloc_gc(), seqnum_last_alloc_gc());
427   st-&gt;cr();
428 }
429 
430 void ShenandoahHeapRegion::oop_iterate(OopIterateClosure* blk) {
431   if (!is_active()) return;
432   if (is_humongous()) {
433     oop_iterate_humongous(blk);
434   } else {
435     oop_iterate_objects(blk);
436   }
437 }
438 
439 void ShenandoahHeapRegion::oop_iterate_objects(OopIterateClosure* blk) {
440   assert(! is_humongous(), &quot;no humongous region here&quot;);
441   HeapWord* obj_addr = bottom();
442   HeapWord* t = top();
443   // Could call objects iterate, but this is easier.
444   while (obj_addr &lt; t) {
445     oop obj = oop(obj_addr);
446     obj_addr += obj-&gt;oop_iterate_size(blk);
447   }
448 }
449 
450 void ShenandoahHeapRegion::oop_iterate_humongous(OopIterateClosure* blk) {
451   assert(is_humongous(), &quot;only humongous region here&quot;);
452   // Find head.
453   ShenandoahHeapRegion* r = humongous_start_region();
454   assert(r-&gt;is_humongous_start(), &quot;need humongous head here&quot;);
455   oop obj = oop(r-&gt;bottom());
456   obj-&gt;oop_iterate(blk, MemRegion(bottom(), top()));
457 }
458 
459 ShenandoahHeapRegion* ShenandoahHeapRegion::humongous_start_region() const {
460   assert(is_humongous(), &quot;Must be a part of the humongous region&quot;);
461   size_t reg_num = region_number();
462   ShenandoahHeapRegion* r = const_cast&lt;ShenandoahHeapRegion*&gt;(this);
463   while (!r-&gt;is_humongous_start()) {
464     assert(reg_num &gt; 0, &quot;Sanity&quot;);
465     reg_num --;
466     r = _heap-&gt;get_region(reg_num);
467     assert(r-&gt;is_humongous(), &quot;Must be a part of the humongous region&quot;);
468   }
469   assert(r-&gt;is_humongous_start(), &quot;Must be&quot;);
470   return r;
471 }
472 
473 void ShenandoahHeapRegion::recycle() {
474   ContiguousSpace::clear(false);
475   if (ZapUnusedHeapArea) {
476     ContiguousSpace::mangle_unused_area_complete();
477   }
478   clear_live_data();
479 
480   reset_alloc_metadata();
481 
482   _heap-&gt;marking_context()-&gt;reset_top_at_mark_start(this);
<a name="2" id="anc2"></a><span class="line-added">483   set_update_watermark(bottom());</span>
484 
485   make_empty();
486 }
487 
488 HeapWord* ShenandoahHeapRegion::block_start_const(const void* p) const {
489   assert(MemRegion(bottom(), end()).contains(p),
490          &quot;p (&quot; PTR_FORMAT &quot;) not in space [&quot; PTR_FORMAT &quot;, &quot; PTR_FORMAT &quot;)&quot;,
491          p2i(p), p2i(bottom()), p2i(end()));
492   if (p &gt;= top()) {
493     return top();
494   } else {
495     HeapWord* last = bottom();
496     HeapWord* cur = last;
497     while (cur &lt;= p) {
498       last = cur;
499       cur += oop(cur)-&gt;size();
500     }
501     shenandoah_assert_correct(NULL, oop(last));
502     return last;
503   }
504 }
505 
506 void ShenandoahHeapRegion::setup_sizes(size_t max_heap_size) {
507   // Absolute minimums we should not ever break.
508   static const size_t MIN_REGION_SIZE = 256*K;
509 
510   if (FLAG_IS_DEFAULT(ShenandoahMinRegionSize)) {
511     FLAG_SET_DEFAULT(ShenandoahMinRegionSize, MIN_REGION_SIZE);
512   }
513 
514   size_t region_size;
515   if (FLAG_IS_DEFAULT(ShenandoahHeapRegionSize)) {
516     if (ShenandoahMinRegionSize &gt; max_heap_size / MIN_NUM_REGIONS) {
517       err_msg message(&quot;Max heap size (&quot; SIZE_FORMAT &quot;%s) is too low to afford the minimum number &quot;
518                       &quot;of regions (&quot; SIZE_FORMAT &quot;) of minimum region size (&quot; SIZE_FORMAT &quot;%s).&quot;,
519                       byte_size_in_proper_unit(max_heap_size), proper_unit_for_byte_size(max_heap_size),
520                       MIN_NUM_REGIONS,
521                       byte_size_in_proper_unit(ShenandoahMinRegionSize), proper_unit_for_byte_size(ShenandoahMinRegionSize));
522       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
523     }
524     if (ShenandoahMinRegionSize &lt; MIN_REGION_SIZE) {
525       err_msg message(&quot;&quot; SIZE_FORMAT &quot;%s should not be lower than minimum region size (&quot; SIZE_FORMAT &quot;%s).&quot;,
526                       byte_size_in_proper_unit(ShenandoahMinRegionSize), proper_unit_for_byte_size(ShenandoahMinRegionSize),
527                       byte_size_in_proper_unit(MIN_REGION_SIZE),         proper_unit_for_byte_size(MIN_REGION_SIZE));
528       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
529     }
530     if (ShenandoahMinRegionSize &lt; MinTLABSize) {
531       err_msg message(&quot;&quot; SIZE_FORMAT &quot;%s should not be lower than TLAB size size (&quot; SIZE_FORMAT &quot;%s).&quot;,
532                       byte_size_in_proper_unit(ShenandoahMinRegionSize), proper_unit_for_byte_size(ShenandoahMinRegionSize),
533                       byte_size_in_proper_unit(MinTLABSize),             proper_unit_for_byte_size(MinTLABSize));
534       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize option&quot;, message);
535     }
536     if (ShenandoahMaxRegionSize &lt; MIN_REGION_SIZE) {
537       err_msg message(&quot;&quot; SIZE_FORMAT &quot;%s should not be lower than min region size (&quot; SIZE_FORMAT &quot;%s).&quot;,
538                       byte_size_in_proper_unit(ShenandoahMaxRegionSize), proper_unit_for_byte_size(ShenandoahMaxRegionSize),
539                       byte_size_in_proper_unit(MIN_REGION_SIZE),         proper_unit_for_byte_size(MIN_REGION_SIZE));
540       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMaxRegionSize option&quot;, message);
541     }
542     if (ShenandoahMinRegionSize &gt; ShenandoahMaxRegionSize) {
543       err_msg message(&quot;Minimum (&quot; SIZE_FORMAT &quot;%s) should be larger than maximum (&quot; SIZE_FORMAT &quot;%s).&quot;,
544                       byte_size_in_proper_unit(ShenandoahMinRegionSize), proper_unit_for_byte_size(ShenandoahMinRegionSize),
545                       byte_size_in_proper_unit(ShenandoahMaxRegionSize), proper_unit_for_byte_size(ShenandoahMaxRegionSize));
546       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahMinRegionSize or -XX:ShenandoahMaxRegionSize&quot;, message);
547     }
548 
549     // We rapidly expand to max_heap_size in most scenarios, so that is the measure
550     // for usual heap sizes. Do not depend on initial_heap_size here.
551     region_size = max_heap_size / ShenandoahTargetNumRegions;
552 
553     // Now make sure that we don&#39;t go over or under our limits.
554     region_size = MAX2(ShenandoahMinRegionSize, region_size);
555     region_size = MIN2(ShenandoahMaxRegionSize, region_size);
556 
557   } else {
558     if (ShenandoahHeapRegionSize &gt; max_heap_size / MIN_NUM_REGIONS) {
559       err_msg message(&quot;Max heap size (&quot; SIZE_FORMAT &quot;%s) is too low to afford the minimum number &quot;
560                               &quot;of regions (&quot; SIZE_FORMAT &quot;) of requested size (&quot; SIZE_FORMAT &quot;%s).&quot;,
561                       byte_size_in_proper_unit(max_heap_size), proper_unit_for_byte_size(max_heap_size),
562                       MIN_NUM_REGIONS,
563                       byte_size_in_proper_unit(ShenandoahHeapRegionSize), proper_unit_for_byte_size(ShenandoahHeapRegionSize));
564       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
565     }
566     if (ShenandoahHeapRegionSize &lt; ShenandoahMinRegionSize) {
567       err_msg message(&quot;Heap region size (&quot; SIZE_FORMAT &quot;%s) should be larger than min region size (&quot; SIZE_FORMAT &quot;%s).&quot;,
568                       byte_size_in_proper_unit(ShenandoahHeapRegionSize), proper_unit_for_byte_size(ShenandoahHeapRegionSize),
569                       byte_size_in_proper_unit(ShenandoahMinRegionSize),  proper_unit_for_byte_size(ShenandoahMinRegionSize));
570       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
571     }
572     if (ShenandoahHeapRegionSize &gt; ShenandoahMaxRegionSize) {
573       err_msg message(&quot;Heap region size (&quot; SIZE_FORMAT &quot;%s) should be lower than max region size (&quot; SIZE_FORMAT &quot;%s).&quot;,
574                       byte_size_in_proper_unit(ShenandoahHeapRegionSize), proper_unit_for_byte_size(ShenandoahHeapRegionSize),
575                       byte_size_in_proper_unit(ShenandoahMaxRegionSize),  proper_unit_for_byte_size(ShenandoahMaxRegionSize));
576       vm_exit_during_initialization(&quot;Invalid -XX:ShenandoahHeapRegionSize option&quot;, message);
577     }
578     region_size = ShenandoahHeapRegionSize;
579   }
580 
581   // Make sure region size is at least one large page, if enabled.
582   // Otherwise, uncommitting one region may falsely uncommit the adjacent
583   // regions too.
584   // Also see shenandoahArguments.cpp, where it handles UseLargePages.
585   if (UseLargePages &amp;&amp; ShenandoahUncommit) {
586     region_size = MAX2(region_size, os::large_page_size());
587   }
588 
589   int region_size_log = log2_long((jlong) region_size);
590   // Recalculate the region size to make sure it&#39;s a power of
591   // 2. This means that region_size is the largest power of 2 that&#39;s
592   // &lt;= what we&#39;ve calculated so far.
593   region_size = size_t(1) &lt;&lt; region_size_log;
594 
595   // Now, set up the globals.
596   guarantee(RegionSizeBytesShift == 0, &quot;we should only set it once&quot;);
597   RegionSizeBytesShift = (size_t)region_size_log;
598 
599   guarantee(RegionSizeWordsShift == 0, &quot;we should only set it once&quot;);
600   RegionSizeWordsShift = RegionSizeBytesShift - LogHeapWordSize;
601 
602   guarantee(RegionSizeBytes == 0, &quot;we should only set it once&quot;);
603   RegionSizeBytes = region_size;
604   RegionSizeWords = RegionSizeBytes &gt;&gt; LogHeapWordSize;
605   assert (RegionSizeWords*HeapWordSize == RegionSizeBytes, &quot;sanity&quot;);
606 
607   guarantee(RegionSizeWordsMask == 0, &quot;we should only set it once&quot;);
608   RegionSizeWordsMask = RegionSizeWords - 1;
609 
610   guarantee(RegionSizeBytesMask == 0, &quot;we should only set it once&quot;);
611   RegionSizeBytesMask = RegionSizeBytes - 1;
612 
613   guarantee(RegionCount == 0, &quot;we should only set it once&quot;);
614   RegionCount = max_heap_size / RegionSizeBytes;
615   guarantee(RegionCount &gt;= MIN_NUM_REGIONS, &quot;Should have at least minimum regions&quot;);
616 
617   guarantee(HumongousThresholdWords == 0, &quot;we should only set it once&quot;);
618   HumongousThresholdWords = RegionSizeWords * ShenandoahHumongousThreshold / 100;
619   HumongousThresholdWords = align_down(HumongousThresholdWords, MinObjAlignment);
620   assert (HumongousThresholdWords &lt;= RegionSizeWords, &quot;sanity&quot;);
621 
622   guarantee(HumongousThresholdBytes == 0, &quot;we should only set it once&quot;);
623   HumongousThresholdBytes = HumongousThresholdWords * HeapWordSize;
624   assert (HumongousThresholdBytes &lt;= RegionSizeBytes, &quot;sanity&quot;);
625 
626   // The rationale for trimming the TLAB sizes has to do with the raciness in
627   // TLAB allocation machinery. It may happen that TLAB sizing policy polls Shenandoah
628   // about next free size, gets the answer for region #N, goes away for a while, then
629   // tries to allocate in region #N, and fail because some other thread have claimed part
630   // of the region #N, and then the freeset allocation code has to retire the region #N,
631   // before moving the allocation to region #N+1.
632   //
633   // The worst case realizes when &quot;answer&quot; is &quot;region size&quot;, which means it could
634   // prematurely retire an entire region. Having smaller TLABs does not fix that
635   // completely, but reduces the probability of too wasteful region retirement.
636   // With current divisor, we will waste no more than 1/8 of region size in the worst
637   // case. This also has a secondary effect on collection set selection: even under
638   // the race, the regions would be at least 7/8 used, which allows relying on
639   // &quot;used&quot; - &quot;live&quot; for cset selection. Otherwise, we can get the fragmented region
640   // below the garbage threshold that would never be considered for collection.
641   //
642   // The whole thing is mitigated if Elastic TLABs are enabled.
643   //
644   guarantee(MaxTLABSizeWords == 0, &quot;we should only set it once&quot;);
645   MaxTLABSizeWords = MIN2(ShenandoahElasticTLAB ? RegionSizeWords : (RegionSizeWords / 8), HumongousThresholdWords);
646   MaxTLABSizeWords = align_down(MaxTLABSizeWords, MinObjAlignment);
647 
648   guarantee(MaxTLABSizeBytes == 0, &quot;we should only set it once&quot;);
649   MaxTLABSizeBytes = MaxTLABSizeWords * HeapWordSize;
650   assert (MaxTLABSizeBytes &gt; MinTLABSize, &quot;should be larger&quot;);
651 
652   log_info(gc, init)(&quot;Regions: &quot; SIZE_FORMAT &quot; x &quot; SIZE_FORMAT &quot;%s&quot;,
653                      RegionCount, byte_size_in_proper_unit(RegionSizeBytes), proper_unit_for_byte_size(RegionSizeBytes));
654   log_info(gc, init)(&quot;Humongous object threshold: &quot; SIZE_FORMAT &quot;%s&quot;,
655                      byte_size_in_proper_unit(HumongousThresholdBytes), proper_unit_for_byte_size(HumongousThresholdBytes));
656   log_info(gc, init)(&quot;Max TLAB size: &quot; SIZE_FORMAT &quot;%s&quot;,
657                      byte_size_in_proper_unit(MaxTLABSizeBytes), proper_unit_for_byte_size(MaxTLABSizeBytes));
658 }
659 
660 void ShenandoahHeapRegion::do_commit() {
661   if (!_heap-&gt;is_heap_region_special() &amp;&amp; !os::commit_memory((char *) _reserved.start(), _reserved.byte_size(), false)) {
662     report_java_out_of_memory(&quot;Unable to commit region&quot;);
663   }
664   if (!_heap-&gt;commit_bitmap_slice(this)) {
665     report_java_out_of_memory(&quot;Unable to commit bitmaps for region&quot;);
666   }
667   _heap-&gt;increase_committed(ShenandoahHeapRegion::region_size_bytes());
668 }
669 
670 void ShenandoahHeapRegion::do_uncommit() {
671   if (!_heap-&gt;is_heap_region_special() &amp;&amp; !os::uncommit_memory((char *) _reserved.start(), _reserved.byte_size())) {
672     report_java_out_of_memory(&quot;Unable to uncommit region&quot;);
673   }
674   if (!_heap-&gt;uncommit_bitmap_slice(this)) {
675     report_java_out_of_memory(&quot;Unable to uncommit bitmaps for region&quot;);
676   }
677   _heap-&gt;decrease_committed(ShenandoahHeapRegion::region_size_bytes());
678 }
679 
680 void ShenandoahHeapRegion::set_state(RegionState to) {
681   EventShenandoahHeapRegionStateChange evt;
682   if (evt.should_commit()){
683     evt.set_index((unsigned)region_number());
684     evt.set_start((uintptr_t)bottom());
685     evt.set_used(used());
686     evt.set_from(_state);
687     evt.set_to(to);
688     evt.commit();
689   }
690   _state = to;
691 }
692 
693 void ShenandoahHeapRegion::record_pin() {
694   Atomic::add(&amp;_critical_pins, (size_t)1);
695 }
696 
697 void ShenandoahHeapRegion::record_unpin() {
698   assert(pin_count() &gt; 0, &quot;Region &quot; SIZE_FORMAT &quot; should have non-zero pins&quot;, region_number());
699   Atomic::sub(&amp;_critical_pins, (size_t)1);
700 }
701 
702 size_t ShenandoahHeapRegion::pin_count() const {
703   return Atomic::load(&amp;_critical_pins);
704 }
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>