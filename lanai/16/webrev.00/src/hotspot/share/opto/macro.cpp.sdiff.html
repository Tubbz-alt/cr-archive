<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/macro.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="machnode.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/macro.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;compiler/compileLog.hpp&quot;
  27 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  28 #include &quot;libadt/vectset.hpp&quot;
  29 #include &quot;memory/universe.hpp&quot;
  30 #include &quot;opto/addnode.hpp&quot;
  31 #include &quot;opto/arraycopynode.hpp&quot;
  32 #include &quot;opto/callnode.hpp&quot;
  33 #include &quot;opto/castnode.hpp&quot;
  34 #include &quot;opto/cfgnode.hpp&quot;
  35 #include &quot;opto/compile.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;
  37 #include &quot;opto/graphKit.hpp&quot;

  38 #include &quot;opto/locknode.hpp&quot;
  39 #include &quot;opto/loopnode.hpp&quot;
  40 #include &quot;opto/macro.hpp&quot;
  41 #include &quot;opto/memnode.hpp&quot;
  42 #include &quot;opto/narrowptrnode.hpp&quot;
  43 #include &quot;opto/node.hpp&quot;
  44 #include &quot;opto/opaquenode.hpp&quot;
  45 #include &quot;opto/phaseX.hpp&quot;
  46 #include &quot;opto/rootnode.hpp&quot;
  47 #include &quot;opto/runtime.hpp&quot;
  48 #include &quot;opto/subnode.hpp&quot;

  49 #include &quot;opto/type.hpp&quot;
  50 #include &quot;runtime/sharedRuntime.hpp&quot;
  51 #include &quot;utilities/macros.hpp&quot;

  52 #if INCLUDE_G1GC
  53 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
  54 #endif // INCLUDE_G1GC
  55 #if INCLUDE_SHENANDOAHGC
  56 #include &quot;gc/shenandoah/c2/shenandoahBarrierSetC2.hpp&quot;
  57 #endif
  58 
  59 
  60 //
  61 // Replace any references to &quot;oldref&quot; in inputs to &quot;use&quot; with &quot;newref&quot;.
  62 // Returns the number of replacements made.
  63 //
  64 int PhaseMacroExpand::replace_input(Node *use, Node *oldref, Node *newref) {
  65   int nreplacements = 0;
  66   uint req = use-&gt;req();
  67   for (uint j = 0; j &lt; use-&gt;len(); j++) {
  68     Node *uin = use-&gt;in(j);
  69     if (uin == oldref) {
  70       if (j &lt; req)
  71         use-&gt;set_req(j, newref);
</pre>
<hr />
<pre>
1314     //   0 - can fit in TLAB
1315     //   1 - always too big or negative
1316     assert(tv &lt;= 1, &quot;0 or 1 if a constant&quot;);
1317     expand_fast_path = (tv == 0);
1318     initial_slow_test = NULL;
1319   } else {
1320     initial_slow_test = BoolNode::make_predicate(initial_slow_test, &amp;_igvn);
1321   }
1322 
1323   if (C-&gt;env()-&gt;dtrace_alloc_probes() ||
1324       (!UseTLAB &amp;&amp; !Universe::heap()-&gt;supports_inline_contig_alloc())) {
1325     // Force slow-path allocation
1326     expand_fast_path = false;
1327     initial_slow_test = NULL;
1328   }
1329 
1330   bool allocation_has_use = (alloc-&gt;result_cast() != NULL);
1331   if (!allocation_has_use) {
1332     InitializeNode* init = alloc-&gt;initialization();
1333     if (init != NULL) {
<span class="line-modified">1334       yank_initalize_node(init);</span>
<span class="line-removed">1335       assert(init-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);</span>
<span class="line-removed">1336       _igvn.remove_dead_node(init);</span>
1337     }
1338     if (expand_fast_path &amp;&amp; (initial_slow_test == NULL)) {
1339       // Remove allocation node and return.
1340       // Size is a non-negative constant -&gt; no initial check needed -&gt; directly to fast path.
1341       // Also, no usages -&gt; empty fast path -&gt; no fall out to slow path -&gt; nothing left.











1342       yank_alloc_node(alloc);
1343       return;
1344     }
1345   }
1346 
1347   enum { too_big_or_final_path = 1, need_gc_path = 2 };
1348   Node *slow_region = NULL;
1349   Node *toobig_false = ctrl;
1350 
1351   // generate the initial test if necessary
1352   if (initial_slow_test != NULL ) {
1353     assert (expand_fast_path, &quot;Only need test if there is a fast path&quot;);
1354     slow_region = new RegionNode(3);
1355 
1356     // Now make the initial failure test.  Usually a too-big test but
1357     // might be a TRUE for finalizers or a fancy class check for
1358     // newInstance0.
1359     IfNode *toobig_iff = new IfNode(ctrl, initial_slow_test, PROB_MIN, COUNT_UNKNOWN);
1360     transform_later(toobig_iff);
1361     // Plug the failing-too-big test into the slow-path region
</pre>
<hr />
<pre>
1559   // Plug slow-path into result merge point
1560   result_region-&gt;init_req( slow_result_path, ctrl);
1561   transform_later(result_region);
1562   if (allocation_has_use) {
1563     result_phi_rawoop-&gt;init_req(slow_result_path, slow_result);
1564     transform_later(result_phi_rawoop);
1565   }
1566   result_phi_rawmem-&gt;init_req(slow_result_path, _memproj_fallthrough);
1567   transform_later(result_phi_rawmem);
1568   transform_later(result_phi_i_o);
1569   // This completes all paths into the result merge point
1570 }
1571 
1572 // Remove alloc node that has no uses.
1573 void PhaseMacroExpand::yank_alloc_node(AllocateNode* alloc) {
1574   Node* ctrl = alloc-&gt;in(TypeFunc::Control);
1575   Node* mem  = alloc-&gt;in(TypeFunc::Memory);
1576   Node* i_o  = alloc-&gt;in(TypeFunc::I_O);
1577 
1578   extract_call_projections(alloc);










1579   if (_fallthroughcatchproj != NULL) {
1580     migrate_outs(_fallthroughcatchproj, ctrl);
1581     _igvn.remove_dead_node(_fallthroughcatchproj);
1582   }
1583   if (_catchallcatchproj != NULL) {
1584     _igvn.rehash_node_delayed(_catchallcatchproj);
1585     _catchallcatchproj-&gt;set_req(0, top());
1586   }
1587   if (_fallthroughproj != NULL) {
1588     Node* catchnode = _fallthroughproj-&gt;unique_ctrl_out();
1589     _igvn.remove_dead_node(catchnode);
1590     _igvn.remove_dead_node(_fallthroughproj);
1591   }
1592   if (_memproj_fallthrough != NULL) {
1593     migrate_outs(_memproj_fallthrough, mem);
1594     _igvn.remove_dead_node(_memproj_fallthrough);
1595   }
1596   if (_ioproj_fallthrough != NULL) {
1597     migrate_outs(_ioproj_fallthrough, i_o);
1598     _igvn.remove_dead_node(_ioproj_fallthrough);
1599   }
1600   if (_memproj_catchall != NULL) {
1601     _igvn.rehash_node_delayed(_memproj_catchall);
1602     _memproj_catchall-&gt;set_req(0, top());
1603   }
1604   if (_ioproj_catchall != NULL) {
1605     _igvn.rehash_node_delayed(_ioproj_catchall);
1606     _ioproj_catchall-&gt;set_req(0, top());
1607   }









1608   _igvn.remove_dead_node(alloc);
1609 }
1610 
1611 void PhaseMacroExpand::expand_initialize_membar(AllocateNode* alloc, InitializeNode* init,
1612                                                 Node*&amp; fast_oop_ctrl, Node*&amp; fast_oop_rawmem) {
1613   // If initialization is performed by an array copy, any required
1614   // MemBarStoreStore was already added. If the object does not
1615   // escape no need for a MemBarStoreStore. If the object does not
1616   // escape in its initializer and memory barrier (MemBarStoreStore or
1617   // stronger) is already added at exit of initializer, also no need
1618   // for a MemBarStoreStore. Otherwise we need a MemBarStoreStore
1619   // so that stores that initialize this object can&#39;t be reordered
1620   // with a subsequent store that makes this object accessible by
1621   // other threads.
1622   // Other threads include java threads and JVM internal threads
1623   // (for example concurrent GC threads). Current concurrent GC
1624   // implementation: G1 will not scan newly created object,
1625   // so it&#39;s safe to skip storestore barrier when allocation does
1626   // not escape.
1627   if (!alloc-&gt;does_not_escape_thread() &amp;&amp;
</pre>
<hr />
<pre>
1692 
1693     // Get base of thread-local storage area
1694     Node* thread = new ThreadLocalNode();
1695     transform_later(thread);
1696 
1697     call-&gt;init_req(TypeFunc::Parms + 0, thread);
1698     call-&gt;init_req(TypeFunc::Parms + 1, oop);
1699     call-&gt;init_req(TypeFunc::Control, ctrl);
1700     call-&gt;init_req(TypeFunc::I_O    , top()); // does no i/o
1701     call-&gt;init_req(TypeFunc::Memory , ctrl);
1702     call-&gt;init_req(TypeFunc::ReturnAdr, alloc-&gt;in(TypeFunc::ReturnAdr));
1703     call-&gt;init_req(TypeFunc::FramePtr, alloc-&gt;in(TypeFunc::FramePtr));
1704     transform_later(call);
1705     ctrl = new ProjNode(call, TypeFunc::Control);
1706     transform_later(ctrl);
1707     rawmem = new ProjNode(call, TypeFunc::Memory);
1708     transform_later(rawmem);
1709   }
1710 }
1711 
<span class="line-removed">1712 // Remove InitializeNode without use</span>
<span class="line-removed">1713 void PhaseMacroExpand::yank_initalize_node(InitializeNode* initnode) {</span>
<span class="line-removed">1714   assert(initnode-&gt;proj_out_or_null(TypeFunc::Parms) == NULL, &quot;No uses allowed&quot;);</span>
<span class="line-removed">1715 </span>
<span class="line-removed">1716   Node* ctrl_out  = initnode-&gt;proj_out_or_null(TypeFunc::Control);</span>
<span class="line-removed">1717   Node* mem_out   = initnode-&gt;proj_out_or_null(TypeFunc::Memory);</span>
<span class="line-removed">1718 </span>
<span class="line-removed">1719   // Move all uses of each to</span>
<span class="line-removed">1720   if (ctrl_out != NULL ) {</span>
<span class="line-removed">1721     migrate_outs(ctrl_out, initnode-&gt;in(TypeFunc::Control));</span>
<span class="line-removed">1722     _igvn.remove_dead_node(ctrl_out);</span>
<span class="line-removed">1723   }</span>
<span class="line-removed">1724 </span>
<span class="line-removed">1725   // Move all uses of each to</span>
<span class="line-removed">1726   if (mem_out != NULL ) {</span>
<span class="line-removed">1727     migrate_outs(mem_out, initnode-&gt;in(TypeFunc::Memory));</span>
<span class="line-removed">1728     _igvn.remove_dead_node(mem_out);</span>
<span class="line-removed">1729   }</span>
<span class="line-removed">1730 }</span>
<span class="line-removed">1731 </span>
1732 // Helper for PhaseMacroExpand::expand_allocate_common.
1733 // Initializes the newly-allocated storage.
1734 Node*
1735 PhaseMacroExpand::initialize_object(AllocateNode* alloc,
1736                                     Node* control, Node* rawmem, Node* object,
1737                                     Node* klass_node, Node* length,
1738                                     Node* size_in_bytes) {
1739   InitializeNode* init = alloc-&gt;initialization();
1740   // Store the klass &amp; mark bits
1741   Node* mark_node = alloc-&gt;make_ideal_mark(&amp;_igvn, object, control, rawmem);
1742   if (!mark_node-&gt;is_Con()) {
1743     transform_later(mark_node);
1744   }
1745   rawmem = make_store(control, rawmem, object, oopDesc::mark_offset_in_bytes(), mark_node, TypeX_X-&gt;basic_type());
1746 
1747   rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);
1748   int header_size = alloc-&gt;minimum_header_size();  // conservatively small
1749 
1750   // Array length
1751   if (length != NULL) {         // Arrays need length field
</pre>
<hr />
<pre>
2515   // No exceptions for unlocking
2516   // Capture slow path
2517   // disconnect fall-through projection from call and create a new one
2518   // hook up users of fall-through projection to region
2519   Node *slow_ctrl = _fallthroughproj-&gt;clone();
2520   transform_later(slow_ctrl);
2521   _igvn.hash_delete(_fallthroughproj);
2522   _fallthroughproj-&gt;disconnect_inputs(NULL, C);
2523   region-&gt;init_req(1, slow_ctrl);
2524   // region inputs are now complete
2525   transform_later(region);
2526   _igvn.replace_node(_fallthroughproj, region);
2527 
2528   Node *memproj = transform_later(new ProjNode(call, TypeFunc::Memory) );
2529   mem_phi-&gt;init_req(1, memproj );
2530   mem_phi-&gt;init_req(2, mem);
2531   transform_later(mem_phi);
2532   _igvn.replace_node(_memproj_fallthrough, mem_phi);
2533 }
2534 





































2535 //---------------------------eliminate_macro_nodes----------------------
2536 // Eliminate scalar replaced allocations and associated locks.
2537 void PhaseMacroExpand::eliminate_macro_nodes() {
2538   if (C-&gt;macro_count() == 0)
2539     return;
2540 
2541   // First, attempt to eliminate locks
2542   int cnt = C-&gt;macro_count();
2543   for (int i=0; i &lt; cnt; i++) {
2544     Node *n = C-&gt;macro_node(i);
2545     if (n-&gt;is_AbstractLock()) { // Lock and Unlock nodes
2546       // Before elimination mark all associated (same box and obj)
2547       // lock and unlock nodes.
2548       mark_eliminated_locking_nodes(n-&gt;as_AbstractLock());
2549     }
2550   }
2551   bool progress = true;
2552   while (progress) {
2553     progress = false;
2554     for (int i = C-&gt;macro_count(); i &gt; 0; i--) {
</pre>
<hr />
<pre>
2571       Node * n = C-&gt;macro_node(i-1);
2572       bool success = false;
2573       debug_only(int old_macro_count = C-&gt;macro_count(););
2574       switch (n-&gt;class_id()) {
2575       case Node::Class_Allocate:
2576       case Node::Class_AllocateArray:
2577         success = eliminate_allocate_node(n-&gt;as_Allocate());
2578         break;
2579       case Node::Class_CallStaticJava:
2580         success = eliminate_boxing_node(n-&gt;as_CallStaticJava());
2581         break;
2582       case Node::Class_Lock:
2583       case Node::Class_Unlock:
2584         assert(!n-&gt;as_AbstractLock()-&gt;is_eliminated(), &quot;sanity&quot;);
2585         _has_locks = true;
2586         break;
2587       case Node::Class_ArrayCopy:
2588         break;
2589       case Node::Class_OuterStripMinedLoop:
2590         break;


2591       default:
2592         assert(n-&gt;Opcode() == Op_LoopLimit ||
2593                n-&gt;Opcode() == Op_Opaque1   ||
2594                n-&gt;Opcode() == Op_Opaque2   ||
2595                n-&gt;Opcode() == Op_Opaque3   ||
2596                BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(n),
2597                &quot;unknown node type in macro list&quot;);
2598       }
2599       assert(success == (C-&gt;macro_count() &lt; old_macro_count), &quot;elimination reduces macro count&quot;);
2600       progress = progress || success;
2601     }
2602   }
2603 }
2604 
2605 //------------------------------expand_macro_nodes----------------------
2606 //  Returns true if a failure occurred.
2607 bool PhaseMacroExpand::expand_macro_nodes() {
2608   // Last attempt to eliminate macro nodes.
2609   eliminate_macro_nodes();
2610 
</pre>
<hr />
<pre>
2677     assert(n-&gt;is_macro(), &quot;only macro nodes expected here&quot;);
2678     if (_igvn.type(n) == Type::TOP || (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0)-&gt;is_top())) {
2679       // node is unreachable, so don&#39;t try to expand it
2680       C-&gt;remove_macro_node(n);
2681       continue;
2682     }
2683     debug_only(int old_macro_count = C-&gt;macro_count(););
2684     switch (n-&gt;class_id()) {
2685     case Node::Class_Lock:
2686       expand_lock_node(n-&gt;as_Lock());
2687       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);
2688       break;
2689     case Node::Class_Unlock:
2690       expand_unlock_node(n-&gt;as_Unlock());
2691       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);
2692       break;
2693     case Node::Class_ArrayCopy:
2694       expand_arraycopy_node(n-&gt;as_ArrayCopy());
2695       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);
2696       break;




2697     }
2698     if (C-&gt;failing())  return true;
2699   }
2700 
2701   // All nodes except Allocate nodes are expanded now. There could be
2702   // new optimization opportunities (such as folding newly created
2703   // load from a just allocated object). Run IGVN.
2704   _igvn.set_delay_transform(false);
2705   _igvn.optimize();
2706   if (C-&gt;failing())  return true;
2707 
2708   _igvn.set_delay_transform(true);
2709 
2710   // expand &quot;macro&quot; nodes
2711   // nodes are removed from the macro list as they are processed
2712   while (C-&gt;macro_count() &gt; 0) {
2713     int macro_count = C-&gt;macro_count();
2714     Node * n = C-&gt;macro_node(macro_count-1);
2715     assert(n-&gt;is_macro(), &quot;only macro nodes expected here&quot;);
2716     if (_igvn.type(n) == Type::TOP || (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0)-&gt;is_top())) {
</pre>
</td>
<td>
<hr />
<pre>
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;compiler/compileLog.hpp&quot;
  27 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  28 #include &quot;libadt/vectset.hpp&quot;
  29 #include &quot;memory/universe.hpp&quot;
  30 #include &quot;opto/addnode.hpp&quot;
  31 #include &quot;opto/arraycopynode.hpp&quot;
  32 #include &quot;opto/callnode.hpp&quot;
  33 #include &quot;opto/castnode.hpp&quot;
  34 #include &quot;opto/cfgnode.hpp&quot;
  35 #include &quot;opto/compile.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;
  37 #include &quot;opto/graphKit.hpp&quot;
<span class="line-added">  38 #include &quot;opto/intrinsicnode.hpp&quot;</span>
  39 #include &quot;opto/locknode.hpp&quot;
  40 #include &quot;opto/loopnode.hpp&quot;
  41 #include &quot;opto/macro.hpp&quot;
  42 #include &quot;opto/memnode.hpp&quot;
  43 #include &quot;opto/narrowptrnode.hpp&quot;
  44 #include &quot;opto/node.hpp&quot;
  45 #include &quot;opto/opaquenode.hpp&quot;
  46 #include &quot;opto/phaseX.hpp&quot;
  47 #include &quot;opto/rootnode.hpp&quot;
  48 #include &quot;opto/runtime.hpp&quot;
  49 #include &quot;opto/subnode.hpp&quot;
<span class="line-added">  50 #include &quot;opto/subtypenode.hpp&quot;</span>
  51 #include &quot;opto/type.hpp&quot;
  52 #include &quot;runtime/sharedRuntime.hpp&quot;
  53 #include &quot;utilities/macros.hpp&quot;
<span class="line-added">  54 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  55 #if INCLUDE_G1GC
  56 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
  57 #endif // INCLUDE_G1GC
  58 #if INCLUDE_SHENANDOAHGC
  59 #include &quot;gc/shenandoah/c2/shenandoahBarrierSetC2.hpp&quot;
  60 #endif
  61 
  62 
  63 //
  64 // Replace any references to &quot;oldref&quot; in inputs to &quot;use&quot; with &quot;newref&quot;.
  65 // Returns the number of replacements made.
  66 //
  67 int PhaseMacroExpand::replace_input(Node *use, Node *oldref, Node *newref) {
  68   int nreplacements = 0;
  69   uint req = use-&gt;req();
  70   for (uint j = 0; j &lt; use-&gt;len(); j++) {
  71     Node *uin = use-&gt;in(j);
  72     if (uin == oldref) {
  73       if (j &lt; req)
  74         use-&gt;set_req(j, newref);
</pre>
<hr />
<pre>
1317     //   0 - can fit in TLAB
1318     //   1 - always too big or negative
1319     assert(tv &lt;= 1, &quot;0 or 1 if a constant&quot;);
1320     expand_fast_path = (tv == 0);
1321     initial_slow_test = NULL;
1322   } else {
1323     initial_slow_test = BoolNode::make_predicate(initial_slow_test, &amp;_igvn);
1324   }
1325 
1326   if (C-&gt;env()-&gt;dtrace_alloc_probes() ||
1327       (!UseTLAB &amp;&amp; !Universe::heap()-&gt;supports_inline_contig_alloc())) {
1328     // Force slow-path allocation
1329     expand_fast_path = false;
1330     initial_slow_test = NULL;
1331   }
1332 
1333   bool allocation_has_use = (alloc-&gt;result_cast() != NULL);
1334   if (!allocation_has_use) {
1335     InitializeNode* init = alloc-&gt;initialization();
1336     if (init != NULL) {
<span class="line-modified">1337       init-&gt;remove(&amp;_igvn);</span>


1338     }
1339     if (expand_fast_path &amp;&amp; (initial_slow_test == NULL)) {
1340       // Remove allocation node and return.
1341       // Size is a non-negative constant -&gt; no initial check needed -&gt; directly to fast path.
1342       // Also, no usages -&gt; empty fast path -&gt; no fall out to slow path -&gt; nothing left.
<span class="line-added">1343 #ifndef PRODUCT</span>
<span class="line-added">1344       if (PrintEliminateAllocations) {</span>
<span class="line-added">1345         tty-&gt;print(&quot;NotUsed &quot;);</span>
<span class="line-added">1346         Node* res = alloc-&gt;proj_out_or_null(TypeFunc::Parms);</span>
<span class="line-added">1347         if (res != NULL) {</span>
<span class="line-added">1348           res-&gt;dump();</span>
<span class="line-added">1349         } else {</span>
<span class="line-added">1350           alloc-&gt;dump();</span>
<span class="line-added">1351         }</span>
<span class="line-added">1352       }</span>
<span class="line-added">1353 #endif</span>
1354       yank_alloc_node(alloc);
1355       return;
1356     }
1357   }
1358 
1359   enum { too_big_or_final_path = 1, need_gc_path = 2 };
1360   Node *slow_region = NULL;
1361   Node *toobig_false = ctrl;
1362 
1363   // generate the initial test if necessary
1364   if (initial_slow_test != NULL ) {
1365     assert (expand_fast_path, &quot;Only need test if there is a fast path&quot;);
1366     slow_region = new RegionNode(3);
1367 
1368     // Now make the initial failure test.  Usually a too-big test but
1369     // might be a TRUE for finalizers or a fancy class check for
1370     // newInstance0.
1371     IfNode *toobig_iff = new IfNode(ctrl, initial_slow_test, PROB_MIN, COUNT_UNKNOWN);
1372     transform_later(toobig_iff);
1373     // Plug the failing-too-big test into the slow-path region
</pre>
<hr />
<pre>
1571   // Plug slow-path into result merge point
1572   result_region-&gt;init_req( slow_result_path, ctrl);
1573   transform_later(result_region);
1574   if (allocation_has_use) {
1575     result_phi_rawoop-&gt;init_req(slow_result_path, slow_result);
1576     transform_later(result_phi_rawoop);
1577   }
1578   result_phi_rawmem-&gt;init_req(slow_result_path, _memproj_fallthrough);
1579   transform_later(result_phi_rawmem);
1580   transform_later(result_phi_i_o);
1581   // This completes all paths into the result merge point
1582 }
1583 
1584 // Remove alloc node that has no uses.
1585 void PhaseMacroExpand::yank_alloc_node(AllocateNode* alloc) {
1586   Node* ctrl = alloc-&gt;in(TypeFunc::Control);
1587   Node* mem  = alloc-&gt;in(TypeFunc::Memory);
1588   Node* i_o  = alloc-&gt;in(TypeFunc::I_O);
1589 
1590   extract_call_projections(alloc);
<span class="line-added">1591   if (_resproj != NULL) {</span>
<span class="line-added">1592     for (DUIterator_Fast imax, i = _resproj-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-added">1593       Node* use = _resproj-&gt;fast_out(i);</span>
<span class="line-added">1594       use-&gt;isa_MemBar()-&gt;remove(&amp;_igvn);</span>
<span class="line-added">1595       --imax;</span>
<span class="line-added">1596       --i; // back up iterator</span>
<span class="line-added">1597     }</span>
<span class="line-added">1598     assert(_resproj-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);</span>
<span class="line-added">1599     _igvn.remove_dead_node(_resproj);</span>
<span class="line-added">1600   }</span>
1601   if (_fallthroughcatchproj != NULL) {
1602     migrate_outs(_fallthroughcatchproj, ctrl);
1603     _igvn.remove_dead_node(_fallthroughcatchproj);
1604   }
1605   if (_catchallcatchproj != NULL) {
1606     _igvn.rehash_node_delayed(_catchallcatchproj);
1607     _catchallcatchproj-&gt;set_req(0, top());
1608   }
1609   if (_fallthroughproj != NULL) {
1610     Node* catchnode = _fallthroughproj-&gt;unique_ctrl_out();
1611     _igvn.remove_dead_node(catchnode);
1612     _igvn.remove_dead_node(_fallthroughproj);
1613   }
1614   if (_memproj_fallthrough != NULL) {
1615     migrate_outs(_memproj_fallthrough, mem);
1616     _igvn.remove_dead_node(_memproj_fallthrough);
1617   }
1618   if (_ioproj_fallthrough != NULL) {
1619     migrate_outs(_ioproj_fallthrough, i_o);
1620     _igvn.remove_dead_node(_ioproj_fallthrough);
1621   }
1622   if (_memproj_catchall != NULL) {
1623     _igvn.rehash_node_delayed(_memproj_catchall);
1624     _memproj_catchall-&gt;set_req(0, top());
1625   }
1626   if (_ioproj_catchall != NULL) {
1627     _igvn.rehash_node_delayed(_ioproj_catchall);
1628     _ioproj_catchall-&gt;set_req(0, top());
1629   }
<span class="line-added">1630 #ifndef PRODUCT</span>
<span class="line-added">1631   if (PrintEliminateAllocations) {</span>
<span class="line-added">1632     if (alloc-&gt;is_AllocateArray()) {</span>
<span class="line-added">1633       tty-&gt;print_cr(&quot;++++ Eliminated: %d AllocateArray&quot;, alloc-&gt;_idx);</span>
<span class="line-added">1634     } else {</span>
<span class="line-added">1635       tty-&gt;print_cr(&quot;++++ Eliminated: %d Allocate&quot;, alloc-&gt;_idx);</span>
<span class="line-added">1636     }</span>
<span class="line-added">1637   }</span>
<span class="line-added">1638 #endif</span>
1639   _igvn.remove_dead_node(alloc);
1640 }
1641 
1642 void PhaseMacroExpand::expand_initialize_membar(AllocateNode* alloc, InitializeNode* init,
1643                                                 Node*&amp; fast_oop_ctrl, Node*&amp; fast_oop_rawmem) {
1644   // If initialization is performed by an array copy, any required
1645   // MemBarStoreStore was already added. If the object does not
1646   // escape no need for a MemBarStoreStore. If the object does not
1647   // escape in its initializer and memory barrier (MemBarStoreStore or
1648   // stronger) is already added at exit of initializer, also no need
1649   // for a MemBarStoreStore. Otherwise we need a MemBarStoreStore
1650   // so that stores that initialize this object can&#39;t be reordered
1651   // with a subsequent store that makes this object accessible by
1652   // other threads.
1653   // Other threads include java threads and JVM internal threads
1654   // (for example concurrent GC threads). Current concurrent GC
1655   // implementation: G1 will not scan newly created object,
1656   // so it&#39;s safe to skip storestore barrier when allocation does
1657   // not escape.
1658   if (!alloc-&gt;does_not_escape_thread() &amp;&amp;
</pre>
<hr />
<pre>
1723 
1724     // Get base of thread-local storage area
1725     Node* thread = new ThreadLocalNode();
1726     transform_later(thread);
1727 
1728     call-&gt;init_req(TypeFunc::Parms + 0, thread);
1729     call-&gt;init_req(TypeFunc::Parms + 1, oop);
1730     call-&gt;init_req(TypeFunc::Control, ctrl);
1731     call-&gt;init_req(TypeFunc::I_O    , top()); // does no i/o
1732     call-&gt;init_req(TypeFunc::Memory , ctrl);
1733     call-&gt;init_req(TypeFunc::ReturnAdr, alloc-&gt;in(TypeFunc::ReturnAdr));
1734     call-&gt;init_req(TypeFunc::FramePtr, alloc-&gt;in(TypeFunc::FramePtr));
1735     transform_later(call);
1736     ctrl = new ProjNode(call, TypeFunc::Control);
1737     transform_later(ctrl);
1738     rawmem = new ProjNode(call, TypeFunc::Memory);
1739     transform_later(rawmem);
1740   }
1741 }
1742 




















1743 // Helper for PhaseMacroExpand::expand_allocate_common.
1744 // Initializes the newly-allocated storage.
1745 Node*
1746 PhaseMacroExpand::initialize_object(AllocateNode* alloc,
1747                                     Node* control, Node* rawmem, Node* object,
1748                                     Node* klass_node, Node* length,
1749                                     Node* size_in_bytes) {
1750   InitializeNode* init = alloc-&gt;initialization();
1751   // Store the klass &amp; mark bits
1752   Node* mark_node = alloc-&gt;make_ideal_mark(&amp;_igvn, object, control, rawmem);
1753   if (!mark_node-&gt;is_Con()) {
1754     transform_later(mark_node);
1755   }
1756   rawmem = make_store(control, rawmem, object, oopDesc::mark_offset_in_bytes(), mark_node, TypeX_X-&gt;basic_type());
1757 
1758   rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);
1759   int header_size = alloc-&gt;minimum_header_size();  // conservatively small
1760 
1761   // Array length
1762   if (length != NULL) {         // Arrays need length field
</pre>
<hr />
<pre>
2526   // No exceptions for unlocking
2527   // Capture slow path
2528   // disconnect fall-through projection from call and create a new one
2529   // hook up users of fall-through projection to region
2530   Node *slow_ctrl = _fallthroughproj-&gt;clone();
2531   transform_later(slow_ctrl);
2532   _igvn.hash_delete(_fallthroughproj);
2533   _fallthroughproj-&gt;disconnect_inputs(NULL, C);
2534   region-&gt;init_req(1, slow_ctrl);
2535   // region inputs are now complete
2536   transform_later(region);
2537   _igvn.replace_node(_fallthroughproj, region);
2538 
2539   Node *memproj = transform_later(new ProjNode(call, TypeFunc::Memory) );
2540   mem_phi-&gt;init_req(1, memproj );
2541   mem_phi-&gt;init_req(2, mem);
2542   transform_later(mem_phi);
2543   _igvn.replace_node(_memproj_fallthrough, mem_phi);
2544 }
2545 
<span class="line-added">2546 void PhaseMacroExpand::expand_subtypecheck_node(SubTypeCheckNode *check) {</span>
<span class="line-added">2547   assert(check-&gt;in(SubTypeCheckNode::Control) == NULL, &quot;should be pinned&quot;);</span>
<span class="line-added">2548   Node* bol = check-&gt;unique_out();</span>
<span class="line-added">2549   Node* obj_or_subklass = check-&gt;in(SubTypeCheckNode::ObjOrSubKlass);</span>
<span class="line-added">2550   Node* superklass = check-&gt;in(SubTypeCheckNode::SuperKlass);</span>
<span class="line-added">2551   assert(bol-&gt;is_Bool() &amp;&amp; bol-&gt;as_Bool()-&gt;_test._test == BoolTest::ne, &quot;unexpected bool node&quot;);</span>
<span class="line-added">2552 </span>
<span class="line-added">2553   for (DUIterator_Last imin, i = bol-&gt;last_outs(imin); i &gt;= imin; --i) {</span>
<span class="line-added">2554     Node* iff = bol-&gt;last_out(i);</span>
<span class="line-added">2555     assert(iff-&gt;is_If(), &quot;where&#39;s the if?&quot;);</span>
<span class="line-added">2556 </span>
<span class="line-added">2557     if (iff-&gt;in(0)-&gt;is_top()) {</span>
<span class="line-added">2558       _igvn.replace_input_of(iff, 1, C-&gt;top());</span>
<span class="line-added">2559       continue;</span>
<span class="line-added">2560     }</span>
<span class="line-added">2561 </span>
<span class="line-added">2562     Node* iftrue = iff-&gt;as_If()-&gt;proj_out(1);</span>
<span class="line-added">2563     Node* iffalse = iff-&gt;as_If()-&gt;proj_out(0);</span>
<span class="line-added">2564     Node* ctrl = iff-&gt;in(0);</span>
<span class="line-added">2565 </span>
<span class="line-added">2566     Node* subklass = NULL;</span>
<span class="line-added">2567     if (_igvn.type(obj_or_subklass)-&gt;isa_klassptr()) {</span>
<span class="line-added">2568       subklass = obj_or_subklass;</span>
<span class="line-added">2569     } else {</span>
<span class="line-added">2570       Node* k_adr = basic_plus_adr(obj_or_subklass, oopDesc::klass_offset_in_bytes());</span>
<span class="line-added">2571       subklass = _igvn.transform(LoadKlassNode::make(_igvn, NULL, C-&gt;immutable_memory(), k_adr, TypeInstPtr::KLASS));</span>
<span class="line-added">2572     }</span>
<span class="line-added">2573 </span>
<span class="line-added">2574     Node* not_subtype_ctrl = Phase::gen_subtype_check(subklass, superklass, &amp;ctrl, NULL, _igvn);</span>
<span class="line-added">2575 </span>
<span class="line-added">2576     _igvn.replace_input_of(iff, 0, C-&gt;top());</span>
<span class="line-added">2577     _igvn.replace_node(iftrue, not_subtype_ctrl);</span>
<span class="line-added">2578     _igvn.replace_node(iffalse, ctrl);</span>
<span class="line-added">2579   }</span>
<span class="line-added">2580   _igvn.replace_node(check, C-&gt;top());</span>
<span class="line-added">2581 }</span>
<span class="line-added">2582 </span>
2583 //---------------------------eliminate_macro_nodes----------------------
2584 // Eliminate scalar replaced allocations and associated locks.
2585 void PhaseMacroExpand::eliminate_macro_nodes() {
2586   if (C-&gt;macro_count() == 0)
2587     return;
2588 
2589   // First, attempt to eliminate locks
2590   int cnt = C-&gt;macro_count();
2591   for (int i=0; i &lt; cnt; i++) {
2592     Node *n = C-&gt;macro_node(i);
2593     if (n-&gt;is_AbstractLock()) { // Lock and Unlock nodes
2594       // Before elimination mark all associated (same box and obj)
2595       // lock and unlock nodes.
2596       mark_eliminated_locking_nodes(n-&gt;as_AbstractLock());
2597     }
2598   }
2599   bool progress = true;
2600   while (progress) {
2601     progress = false;
2602     for (int i = C-&gt;macro_count(); i &gt; 0; i--) {
</pre>
<hr />
<pre>
2619       Node * n = C-&gt;macro_node(i-1);
2620       bool success = false;
2621       debug_only(int old_macro_count = C-&gt;macro_count(););
2622       switch (n-&gt;class_id()) {
2623       case Node::Class_Allocate:
2624       case Node::Class_AllocateArray:
2625         success = eliminate_allocate_node(n-&gt;as_Allocate());
2626         break;
2627       case Node::Class_CallStaticJava:
2628         success = eliminate_boxing_node(n-&gt;as_CallStaticJava());
2629         break;
2630       case Node::Class_Lock:
2631       case Node::Class_Unlock:
2632         assert(!n-&gt;as_AbstractLock()-&gt;is_eliminated(), &quot;sanity&quot;);
2633         _has_locks = true;
2634         break;
2635       case Node::Class_ArrayCopy:
2636         break;
2637       case Node::Class_OuterStripMinedLoop:
2638         break;
<span class="line-added">2639       case Node::Class_SubTypeCheck:</span>
<span class="line-added">2640         break;</span>
2641       default:
2642         assert(n-&gt;Opcode() == Op_LoopLimit ||
2643                n-&gt;Opcode() == Op_Opaque1   ||
2644                n-&gt;Opcode() == Op_Opaque2   ||
2645                n-&gt;Opcode() == Op_Opaque3   ||
2646                BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;is_gc_barrier_node(n),
2647                &quot;unknown node type in macro list&quot;);
2648       }
2649       assert(success == (C-&gt;macro_count() &lt; old_macro_count), &quot;elimination reduces macro count&quot;);
2650       progress = progress || success;
2651     }
2652   }
2653 }
2654 
2655 //------------------------------expand_macro_nodes----------------------
2656 //  Returns true if a failure occurred.
2657 bool PhaseMacroExpand::expand_macro_nodes() {
2658   // Last attempt to eliminate macro nodes.
2659   eliminate_macro_nodes();
2660 
</pre>
<hr />
<pre>
2727     assert(n-&gt;is_macro(), &quot;only macro nodes expected here&quot;);
2728     if (_igvn.type(n) == Type::TOP || (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0)-&gt;is_top())) {
2729       // node is unreachable, so don&#39;t try to expand it
2730       C-&gt;remove_macro_node(n);
2731       continue;
2732     }
2733     debug_only(int old_macro_count = C-&gt;macro_count(););
2734     switch (n-&gt;class_id()) {
2735     case Node::Class_Lock:
2736       expand_lock_node(n-&gt;as_Lock());
2737       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);
2738       break;
2739     case Node::Class_Unlock:
2740       expand_unlock_node(n-&gt;as_Unlock());
2741       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);
2742       break;
2743     case Node::Class_ArrayCopy:
2744       expand_arraycopy_node(n-&gt;as_ArrayCopy());
2745       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);
2746       break;
<span class="line-added">2747     case Node::Class_SubTypeCheck:</span>
<span class="line-added">2748       expand_subtypecheck_node(n-&gt;as_SubTypeCheck());</span>
<span class="line-added">2749       assert(C-&gt;macro_count() == (old_macro_count - 1), &quot;expansion must have deleted one node from macro list&quot;);</span>
<span class="line-added">2750       break;</span>
2751     }
2752     if (C-&gt;failing())  return true;
2753   }
2754 
2755   // All nodes except Allocate nodes are expanded now. There could be
2756   // new optimization opportunities (such as folding newly created
2757   // load from a just allocated object). Run IGVN.
2758   _igvn.set_delay_transform(false);
2759   _igvn.optimize();
2760   if (C-&gt;failing())  return true;
2761 
2762   _igvn.set_delay_transform(true);
2763 
2764   // expand &quot;macro&quot; nodes
2765   // nodes are removed from the macro list as they are processed
2766   while (C-&gt;macro_count() &gt; 0) {
2767     int macro_count = C-&gt;macro_count();
2768     Node * n = C-&gt;macro_node(macro_count-1);
2769     assert(n-&gt;is_macro(), &quot;only macro nodes expected here&quot;);
2770     if (_igvn.type(n) == Type::TOP || (n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0)-&gt;is_top())) {
</pre>
</td>
</tr>
</table>
<center><a href="machnode.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>