<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/matcher.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="matcher.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="memnode.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/matcher.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
108 
109   // Map dense rule number to determine if this is an instruction chain rule
110   const uint _begin_inst_chain_rule;
111   const uint _end_inst_chain_rule;
112 
113   // We want to clone constants and possible CmpI-variants.
114   // If we do not clone CmpI, then we can have many instances of
115   // condition codes alive at once.  This is OK on some chips and
116   // bad on others.  Hence the machine-dependent table lookup.
117   const char *_must_clone;
118 
119   // Find shared Nodes, or Nodes that otherwise are Matcher roots
120   void find_shared( Node *n );
121   bool find_shared_visit(MStack&amp; mstack, Node* n, uint opcode, bool&amp; mem_op, int&amp; mem_addr_idx);
122   void find_shared_post_visit(Node* n, uint opcode);
123 
124 #ifdef X86
125   bool is_bmi_pattern(Node *n, Node *m);
126 #endif
127 


128   // Debug and profile information for nodes in old space:
129   GrowableArray&lt;Node_Notes*&gt;* _old_node_note_array;
130 
131   // Node labeling iterator for instruction selection
132   Node *Label_Root( const Node *n, State *svec, Node *control, const Node *mem );
133 
134   Node *transform( Node *dummy );
135 
136   Node_List _projection_list;        // For Machine nodes killing many values
137 
138   Node_Array _shared_nodes;
139 
140   debug_only(Node_Array _old2new_map;)   // Map roots of ideal-trees to machine-roots
141   debug_only(Node_Array _new2old_map;)   // Maps machine nodes back to ideal
142 
143   // Accessors for the inherited field PhaseTransform::_nodes:
144   void   grow_new_node_array(uint idx_limit) {
145     _nodes.map(idx_limit-1, NULL);
146   }
147   bool    has_new_node(const Node* n) const {
</pre>
<hr />
<pre>
500   // piece-by-piece.  Only happens when passing doubles into C code or when
501   // calling i2c adapters as the Java calling convention forces doubles to be
502   // aligned.
503   static const bool misaligned_doubles_ok;
504 
505   // Does the CPU require postalloc expand (see block.cpp for description of
506   // postalloc expand)?
507   static const bool require_postalloc_expand;
508 
509   // Does the platform support generic vector operands?
510   // Requires cleanup after selection phase.
511   static const bool supports_generic_vector_operands;
512 
513  private:
514   void do_postselect_cleanup();
515 
516   void specialize_generic_vector_operands();
517   void specialize_mach_node(MachNode* m);
518   void specialize_temp_node(MachTempNode* tmp, MachNode* use, uint idx);
519   MachOper* specialize_vector_operand(MachNode* m, uint opnd_idx);
<span class="line-modified">520   MachOper* specialize_vector_operand_helper(MachNode* m, uint opnd_idx, const Type* t);</span>
521 
522   static MachOper* specialize_generic_vector_operand(MachOper* generic_opnd, uint ideal_reg, bool is_temp);
523 
524   static bool is_generic_reg2reg_move(MachNode* m);
525   static bool is_generic_vector(MachOper* opnd);
526 
527   const RegMask* regmask_for_ideal_register(uint ideal_reg, Node* ret);
528 
529   // Graph verification code
530   DEBUG_ONLY( bool verify_after_postselect_cleanup(); )
531 
532  public:
533   // Perform a platform dependent implicit null fixup.  This is needed
534   // on windows95 to take care of some unusual register constraints.
535   void pd_implicit_null_fixup(MachNode *load, uint idx);
536 
<span class="line-modified">537   // Advertise here if the CPU requires explicit rounding operations</span>
<span class="line-removed">538   // to implement the UseStrictFP mode.</span>
539   static const bool strict_fp_requires_explicit_rounding;
540 
541   // Are floats conerted to double when stored to stack during deoptimization?
542   static bool float_in_double();
543   // Do ints take an entire long register or just half?
544   static const bool int_in_long;
545 
546   // Do the processor&#39;s shift instructions only use the low 5/6 bits
547   // of the count for 32/64 bit ints? If not we need to do the masking
548   // ourselves.
549   static const bool need_masked_shift_count;
550 
551   // Whether code generation need accurate ConvI2L types.
552   static const bool convi2l_type_required;
553 
554   // This routine is run whenever a graph fails to match.
555   // If it returns, the compiler should bailout to interpreter without error.
556   // In non-product mode, SoftMatchFailure is false to detect non-canonical
557   // graphs.  Print a message and exit.
558   static void soft_match_failure() {
</pre>
</td>
<td>
<hr />
<pre>
108 
109   // Map dense rule number to determine if this is an instruction chain rule
110   const uint _begin_inst_chain_rule;
111   const uint _end_inst_chain_rule;
112 
113   // We want to clone constants and possible CmpI-variants.
114   // If we do not clone CmpI, then we can have many instances of
115   // condition codes alive at once.  This is OK on some chips and
116   // bad on others.  Hence the machine-dependent table lookup.
117   const char *_must_clone;
118 
119   // Find shared Nodes, or Nodes that otherwise are Matcher roots
120   void find_shared( Node *n );
121   bool find_shared_visit(MStack&amp; mstack, Node* n, uint opcode, bool&amp; mem_op, int&amp; mem_addr_idx);
122   void find_shared_post_visit(Node* n, uint opcode);
123 
124 #ifdef X86
125   bool is_bmi_pattern(Node *n, Node *m);
126 #endif
127 
<span class="line-added">128   bool is_vshift_con_pattern(Node *n, Node *m);</span>
<span class="line-added">129 </span>
130   // Debug and profile information for nodes in old space:
131   GrowableArray&lt;Node_Notes*&gt;* _old_node_note_array;
132 
133   // Node labeling iterator for instruction selection
134   Node *Label_Root( const Node *n, State *svec, Node *control, const Node *mem );
135 
136   Node *transform( Node *dummy );
137 
138   Node_List _projection_list;        // For Machine nodes killing many values
139 
140   Node_Array _shared_nodes;
141 
142   debug_only(Node_Array _old2new_map;)   // Map roots of ideal-trees to machine-roots
143   debug_only(Node_Array _new2old_map;)   // Maps machine nodes back to ideal
144 
145   // Accessors for the inherited field PhaseTransform::_nodes:
146   void   grow_new_node_array(uint idx_limit) {
147     _nodes.map(idx_limit-1, NULL);
148   }
149   bool    has_new_node(const Node* n) const {
</pre>
<hr />
<pre>
502   // piece-by-piece.  Only happens when passing doubles into C code or when
503   // calling i2c adapters as the Java calling convention forces doubles to be
504   // aligned.
505   static const bool misaligned_doubles_ok;
506 
507   // Does the CPU require postalloc expand (see block.cpp for description of
508   // postalloc expand)?
509   static const bool require_postalloc_expand;
510 
511   // Does the platform support generic vector operands?
512   // Requires cleanup after selection phase.
513   static const bool supports_generic_vector_operands;
514 
515  private:
516   void do_postselect_cleanup();
517 
518   void specialize_generic_vector_operands();
519   void specialize_mach_node(MachNode* m);
520   void specialize_temp_node(MachTempNode* tmp, MachNode* use, uint idx);
521   MachOper* specialize_vector_operand(MachNode* m, uint opnd_idx);
<span class="line-modified">522   MachOper* specialize_vector_operand_helper(MachNode* m, uint opnd_idx, const TypeVect* vt);</span>
523 
524   static MachOper* specialize_generic_vector_operand(MachOper* generic_opnd, uint ideal_reg, bool is_temp);
525 
526   static bool is_generic_reg2reg_move(MachNode* m);
527   static bool is_generic_vector(MachOper* opnd);
528 
529   const RegMask* regmask_for_ideal_register(uint ideal_reg, Node* ret);
530 
531   // Graph verification code
532   DEBUG_ONLY( bool verify_after_postselect_cleanup(); )
533 
534  public:
535   // Perform a platform dependent implicit null fixup.  This is needed
536   // on windows95 to take care of some unusual register constraints.
537   void pd_implicit_null_fixup(MachNode *load, uint idx);
538 
<span class="line-modified">539   // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.</span>

540   static const bool strict_fp_requires_explicit_rounding;
541 
542   // Are floats conerted to double when stored to stack during deoptimization?
543   static bool float_in_double();
544   // Do ints take an entire long register or just half?
545   static const bool int_in_long;
546 
547   // Do the processor&#39;s shift instructions only use the low 5/6 bits
548   // of the count for 32/64 bit ints? If not we need to do the masking
549   // ourselves.
550   static const bool need_masked_shift_count;
551 
552   // Whether code generation need accurate ConvI2L types.
553   static const bool convi2l_type_required;
554 
555   // This routine is run whenever a graph fails to match.
556   // If it returns, the compiler should bailout to interpreter without error.
557   // In non-product mode, SoftMatchFailure is false to detect non-canonical
558   // graphs.  Print a message and exit.
559   static void soft_match_failure() {
</pre>
</td>
</tr>
</table>
<center><a href="matcher.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="memnode.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>