<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/graphKit.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="gcm.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="graphKit.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/graphKit.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;ci/ciUtilities.hpp&quot;
  27 #include &quot;compiler/compileLog.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  30 #include &quot;interpreter/interpreter.hpp&quot;
  31 #include &quot;memory/resourceArea.hpp&quot;
  32 #include &quot;opto/addnode.hpp&quot;
  33 #include &quot;opto/castnode.hpp&quot;
  34 #include &quot;opto/convertnode.hpp&quot;
  35 #include &quot;opto/graphKit.hpp&quot;
  36 #include &quot;opto/idealKit.hpp&quot;
  37 #include &quot;opto/intrinsicnode.hpp&quot;
  38 #include &quot;opto/locknode.hpp&quot;
  39 #include &quot;opto/machnode.hpp&quot;
  40 #include &quot;opto/opaquenode.hpp&quot;
  41 #include &quot;opto/parse.hpp&quot;
  42 #include &quot;opto/rootnode.hpp&quot;
  43 #include &quot;opto/runtime.hpp&quot;

  44 #include &quot;runtime/deoptimization.hpp&quot;
  45 #include &quot;runtime/sharedRuntime.hpp&quot;
  46 #include &quot;utilities/bitMap.inline.hpp&quot;

  47 
  48 //----------------------------GraphKit-----------------------------------------
  49 // Main utility constructor.
  50 GraphKit::GraphKit(JVMState* jvms)
  51   : Phase(Phase::Parser),
  52     _env(C-&gt;env()),
  53     _gvn(*C-&gt;initial_gvn()),
  54     _barrier_set(BarrierSet::barrier_set()-&gt;barrier_set_c2())
  55 {
  56   _exceptions = jvms-&gt;map()-&gt;next_exception();
  57   if (_exceptions != NULL)  jvms-&gt;map()-&gt;set_next_exception(NULL);
  58   set_jvms(jvms);
  59 }
  60 
  61 // Private constructor for parser.
  62 GraphKit::GraphKit()
  63   : Phase(Phase::Parser),
  64     _env(C-&gt;env()),
  65     _gvn(*C-&gt;initial_gvn()),
  66     _barrier_set(BarrierSet::barrier_set()-&gt;barrier_set_c2())
</pre>
<hr />
<pre>
2125 // Report the object that was just allocated.
2126 // It must be the case that there are no intervening safepoints.
2127 // We use this to determine if an object is so &quot;fresh&quot; that
2128 // it does not require card marks.
2129 Node* GraphKit::just_allocated_object(Node* current_control) {
2130   Node* ctrl = current_control;
2131   // Object::&lt;init&gt; is invoked after allocation, most of invoke nodes
2132   // will be reduced, but a region node is kept in parse time, we check
2133   // the pattern and skip the region node if it degraded to a copy.
2134   if (ctrl != NULL &amp;&amp; ctrl-&gt;is_Region() &amp;&amp; ctrl-&gt;req() == 2 &amp;&amp;
2135       ctrl-&gt;as_Region()-&gt;is_copy()) {
2136     ctrl = ctrl-&gt;as_Region()-&gt;is_copy();
2137   }
2138   if (C-&gt;recent_alloc_ctl() == ctrl) {
2139    return C-&gt;recent_alloc_obj();
2140   }
2141   return NULL;
2142 }
2143 
2144 
<span class="line-removed">2145 void GraphKit::round_double_arguments(ciMethod* dest_method) {</span>
<span class="line-removed">2146   // (Note:  TypeFunc::make has a cache that makes this fast.)</span>
<span class="line-removed">2147   const TypeFunc* tf    = TypeFunc::make(dest_method);</span>
<span class="line-removed">2148   int             nargs = tf-&gt;domain()-&gt;cnt() - TypeFunc::Parms;</span>
<span class="line-removed">2149   for (int j = 0; j &lt; nargs; j++) {</span>
<span class="line-removed">2150     const Type *targ = tf-&gt;domain()-&gt;field_at(j + TypeFunc::Parms);</span>
<span class="line-removed">2151     if( targ-&gt;basic_type() == T_DOUBLE ) {</span>
<span class="line-removed">2152       // If any parameters are doubles, they must be rounded before</span>
<span class="line-removed">2153       // the call, dstore_rounding does gvn.transform</span>
<span class="line-removed">2154       Node *arg = argument(j);</span>
<span class="line-removed">2155       arg = dstore_rounding(arg);</span>
<span class="line-removed">2156       set_argument(j, arg);</span>
<span class="line-removed">2157     }</span>
<span class="line-removed">2158   }</span>
<span class="line-removed">2159 }</span>
<span class="line-removed">2160 </span>
2161 /**
2162  * Record profiling data exact_kls for Node n with the type system so
2163  * that it can propagate it (speculation)
2164  *
2165  * @param n          node that the type applies to
2166  * @param exact_kls  type from profiling
2167  * @param maybe_null did profiling see null?
2168  *
2169  * @return           node with improved type
2170  */
2171 Node* GraphKit::record_profile_for_speculation(Node* n, ciKlass* exact_kls, ProfilePtrKind ptr_kind) {
2172   const Type* current_type = _gvn.type(n);
2173   assert(UseTypeSpeculation, &quot;type speculation must be on&quot;);
2174 
2175   const TypePtr* speculative = current_type-&gt;speculative();
2176 
2177   // Should the klass from the profile be recorded in the speculative type?
2178   if (current_type-&gt;would_improve_type(exact_kls, jvms()-&gt;depth())) {
2179     const TypeKlassPtr* tklass = TypeKlassPtr::make(exact_kls);
2180     const TypeOopPtr* xtype = tklass-&gt;as_instance_type();
</pre>
<hr />
<pre>
2306 
2307 /**
2308  * Record profiling data from return value profiling at an invoke with
2309  * the type system so that it can propagate it (speculation)
2310  */
2311 void GraphKit::record_profiled_return_for_speculation() {
2312   if (!UseTypeSpeculation) {
2313     return;
2314   }
2315   ProfilePtrKind ptr_kind = ProfileMaybeNull;
2316   ciKlass* better_type = NULL;
2317   if (method()-&gt;return_profiled_type(bci(), better_type, ptr_kind)) {
2318     // If profiling reports a single type for the return value,
2319     // feed it to the type system so it can propagate it as a
2320     // speculative type
2321     record_profile_for_speculation(stack(sp()-1), better_type, ptr_kind);
2322   }
2323 }
2324 
2325 void GraphKit::round_double_result(ciMethod* dest_method) {
<span class="line-modified">2326   // A non-strict method may return a double value which has an extended</span>
<span class="line-modified">2327   // exponent, but this must not be visible in a caller which is &#39;strict&#39;</span>
<span class="line-modified">2328   // If a strict caller invokes a non-strict callee, round a double result</span>












2329 
<span class="line-modified">2330   BasicType result_type = dest_method-&gt;return_type()-&gt;basic_type();</span>
<span class="line-modified">2331   assert( method() != NULL, &quot;must have caller context&quot;);</span>
<span class="line-modified">2332   if( result_type == T_DOUBLE &amp;&amp; method()-&gt;is_strict() &amp;&amp; !dest_method-&gt;is_strict() ) {</span>
<span class="line-modified">2333     // Destination method&#39;s return value is on top of stack</span>
<span class="line-modified">2334     // dstore_rounding() does gvn.transform</span>
<span class="line-modified">2335     Node *result = pop_pair();</span>
<span class="line-modified">2336     result = dstore_rounding(result);</span>
<span class="line-modified">2337     push_pair(result);</span>







2338   }
2339 }
2340 
2341 // rounding for strict float precision conformance
2342 Node* GraphKit::precision_rounding(Node* n) {
<span class="line-modified">2343   return UseStrictFP &amp;&amp; _method-&gt;flags().is_strict()</span>
<span class="line-modified">2344     &amp;&amp; UseSSE == 0 &amp;&amp; Matcher::strict_fp_requires_explicit_rounding</span>
<span class="line-modified">2345     ? _gvn.transform( new RoundFloatNode(0, n) )</span>
<span class="line-modified">2346     : n;</span>






2347 }
2348 
2349 // rounding for strict double precision conformance
2350 Node* GraphKit::dprecision_rounding(Node *n) {
<span class="line-modified">2351   return UseStrictFP &amp;&amp; _method-&gt;flags().is_strict()</span>
<span class="line-modified">2352     &amp;&amp; UseSSE &lt;= 1 &amp;&amp; Matcher::strict_fp_requires_explicit_rounding</span>
<span class="line-modified">2353     ? _gvn.transform( new RoundDoubleNode(0, n) )</span>
<span class="line-modified">2354     : n;</span>






2355 }
2356 
2357 // rounding for non-strict double stores
2358 Node* GraphKit::dstore_rounding(Node* n) {
<span class="line-modified">2359   return Matcher::strict_fp_requires_explicit_rounding</span>
<span class="line-modified">2360     &amp;&amp; UseSSE &lt;= 1</span>
<span class="line-modified">2361     ? _gvn.transform( new RoundDoubleNode(0, n) )</span>
<span class="line-modified">2362     : n;</span>






2363 }
2364 
2365 //=============================================================================
2366 // Generate a fast path/slow path idiom.  Graph looks like:
2367 // [foo] indicates that &#39;foo&#39; is a parameter
2368 //
2369 //              [in]     NULL
2370 //                 \    /
2371 //                  CmpP
2372 //                  Bool ne
2373 //                   If
2374 //                  /  \
2375 //              True    False-&lt;2&gt;
2376 //              / |
2377 //             /  cast_not_null
2378 //           Load  |    |   ^
2379 //        [fast_test]   |   |
2380 // gvn to   opt_test    |   |
2381 //          /    \      |  &lt;1&gt;
2382 //      True     False  |
</pre>
<hr />
<pre>
2584 
2585     if (excp != top()) {
2586       if (deoptimize) {
2587         // Deoptimize if an exception is caught. Don&#39;t construct exception state in this case.
2588         uncommon_trap(Deoptimization::Reason_unhandled,
2589                       Deoptimization::Action_none);
2590       } else {
2591         // Create an exception state also.
2592         // Use an exact type if the caller has a specific exception.
2593         const Type* ex_type = TypeOopPtr::make_from_klass_unique(ex_klass)-&gt;cast_to_ptr_type(TypePtr::NotNull);
2594         Node*       ex_oop  = new CreateExNode(ex_type, control(), i_o);
2595         add_exception_state(make_exception_state(_gvn.transform(ex_oop)));
2596       }
2597     }
2598   }
2599 
2600   // Get the no-exception control from the CatchNode.
2601   set_control(norm);
2602 }
2603 
<span class="line-modified">2604 static IfNode* gen_subtype_check_compare(Node* ctrl, Node* in1, Node* in2, BoolTest::mask test, float p, PhaseGVN* gvn, BasicType bt) {</span>
2605   Node* cmp = NULL;
2606   switch(bt) {
2607   case T_INT: cmp = new CmpINode(in1, in2); break;
2608   case T_ADDRESS: cmp = new CmpPNode(in1, in2); break;
2609   default: fatal(&quot;unexpected comparison type %s&quot;, type2name(bt));
2610   }
<span class="line-modified">2611   gvn-&gt;transform(cmp);</span>
<span class="line-modified">2612   Node* bol = gvn-&gt;transform(new BoolNode(cmp, test));</span>
2613   IfNode* iff = new IfNode(ctrl, bol, p, COUNT_UNKNOWN);
<span class="line-modified">2614   gvn-&gt;transform(iff);</span>
<span class="line-modified">2615   if (!bol-&gt;is_Con()) gvn-&gt;record_for_igvn(iff);</span>
2616   return iff;
2617 }
2618 
<span class="line-removed">2619 </span>
2620 //-------------------------------gen_subtype_check-----------------------------
2621 // Generate a subtyping check.  Takes as input the subtype and supertype.
2622 // Returns 2 values: sets the default control() to the true path and returns
2623 // the false path.  Only reads invariant memory; sets no (visible) memory.
2624 // The PartialSubtypeCheckNode sets the hidden 1-word cache in the encoding
2625 // but that&#39;s not exposed to the optimizer.  This call also doesn&#39;t take in an
2626 // Object; if you wish to check an Object you need to load the Object&#39;s class
2627 // prior to coming here.
<span class="line-modified">2628 Node* Phase::gen_subtype_check(Node* subklass, Node* superklass, Node** ctrl, MergeMemNode* mem, PhaseGVN* gvn) {</span>
<span class="line-modified">2629   Compile* C = gvn-&gt;C;</span>
<span class="line-removed">2630 </span>
2631   if ((*ctrl)-&gt;is_top()) {
2632     return C-&gt;top();
2633   }
2634 
2635   // Fast check for identical types, perhaps identical constants.
2636   // The types can even be identical non-constants, in cases
2637   // involving Array.newInstance, Object.clone, etc.
2638   if (subklass == superklass)
2639     return C-&gt;top();             // false path is dead; no test needed.
2640 
<span class="line-modified">2641   if (gvn-&gt;type(superklass)-&gt;singleton()) {</span>
<span class="line-modified">2642     ciKlass* superk = gvn-&gt;type(superklass)-&gt;is_klassptr()-&gt;klass();</span>
<span class="line-modified">2643     ciKlass* subk   = gvn-&gt;type(subklass)-&gt;is_klassptr()-&gt;klass();</span>
2644 
2645     // In the common case of an exact superklass, try to fold up the
2646     // test before generating code.  You may ask, why not just generate
2647     // the code and then let it fold up?  The answer is that the generated
2648     // code will necessarily include null checks, which do not always
2649     // completely fold away.  If they are also needless, then they turn
2650     // into a performance loss.  Example:
2651     //    Foo[] fa = blah(); Foo x = fa[0]; fa[1] = x;
2652     // Here, the type of &#39;fa&#39; is often exact, so the store check
2653     // of fa[1]=x will fold up, without testing the nullness of x.
2654     switch (C-&gt;static_subtype_check(superk, subk)) {
2655     case Compile::SSC_always_false:
2656       {
2657         Node* always_fail = *ctrl;
<span class="line-modified">2658         *ctrl = gvn-&gt;C-&gt;top();</span>
2659         return always_fail;
2660       }
2661     case Compile::SSC_always_true:
2662       return C-&gt;top();
2663     case Compile::SSC_easy_test:
2664       {
2665         // Just do a direct pointer compare and be done.
2666         IfNode* iff = gen_subtype_check_compare(*ctrl, subklass, superklass, BoolTest::eq, PROB_STATIC_FREQUENT, gvn, T_ADDRESS);
<span class="line-modified">2667         *ctrl = gvn-&gt;transform(new IfTrueNode(iff));</span>
<span class="line-modified">2668         return gvn-&gt;transform(new IfFalseNode(iff));</span>
2669       }
2670     case Compile::SSC_full_test:
2671       break;
2672     default:
2673       ShouldNotReachHere();
2674     }
2675   }
2676 
2677   // %%% Possible further optimization:  Even if the superklass is not exact,
2678   // if the subklass is the unique subtype of the superklass, the check
2679   // will always succeed.  We could leave a dependency behind to ensure this.
2680 
2681   // First load the super-klass&#39;s check-offset
<span class="line-modified">2682   Node *p1 = gvn-&gt;transform(new AddPNode(superklass, superklass, gvn-&gt;MakeConX(in_bytes(Klass::super_check_offset_offset()))));</span>
<span class="line-modified">2683   Node* m = mem-&gt;memory_at(C-&gt;get_alias_index(gvn-&gt;type(p1)-&gt;is_ptr()));</span>
<span class="line-modified">2684   Node *chk_off = gvn-&gt;transform(new LoadINode(NULL, m, p1, gvn-&gt;type(p1)-&gt;is_ptr(), TypeInt::INT, MemNode::unordered));</span>
2685   int cacheoff_con = in_bytes(Klass::secondary_super_cache_offset());
<span class="line-modified">2686   bool might_be_cache = (gvn-&gt;find_int_con(chk_off, cacheoff_con) == cacheoff_con);</span>
2687 
2688   // Load from the sub-klass&#39;s super-class display list, or a 1-word cache of
2689   // the secondary superclass list, or a failing value with a sentinel offset
2690   // if the super-klass is an interface or exceptionally deep in the Java
2691   // hierarchy and we have to scan the secondary superclass list the hard way.
2692   // Worst-case type is a little odd: NULL is allowed as a result (usually
2693   // klass loads can never produce a NULL).
2694   Node *chk_off_X = chk_off;
2695 #ifdef _LP64
<span class="line-modified">2696   chk_off_X = gvn-&gt;transform(new ConvI2LNode(chk_off_X));</span>
2697 #endif
<span class="line-modified">2698   Node *p2 = gvn-&gt;transform(new AddPNode(subklass,subklass,chk_off_X));</span>
2699   // For some types like interfaces the following loadKlass is from a 1-word
2700   // cache which is mutable so can&#39;t use immutable memory.  Other
2701   // types load from the super-class display table which is immutable.
<span class="line-modified">2702   m = mem-&gt;memory_at(C-&gt;get_alias_index(gvn-&gt;type(p2)-&gt;is_ptr()));</span>
<span class="line-modified">2703   Node *kmem = might_be_cache ? m : C-&gt;immutable_memory();</span>
<span class="line-modified">2704   Node *nkls = gvn-&gt;transform(LoadKlassNode::make(*gvn, NULL, kmem, p2, gvn-&gt;type(p2)-&gt;is_ptr(), TypeKlassPtr::OBJECT_OR_NULL));</span>







2705 
2706   // Compile speed common case: ARE a subtype and we canNOT fail
2707   if( superklass == nkls )
2708     return C-&gt;top();             // false path is dead; no test needed.
2709 
2710   // See if we get an immediate positive hit.  Happens roughly 83% of the
2711   // time.  Test to see if the value loaded just previously from the subklass
2712   // is exactly the superklass.
2713   IfNode *iff1 = gen_subtype_check_compare(*ctrl, superklass, nkls, BoolTest::eq, PROB_LIKELY(0.83f), gvn, T_ADDRESS);
<span class="line-modified">2714   Node *iftrue1 = gvn-&gt;transform( new IfTrueNode (iff1));</span>
<span class="line-modified">2715   *ctrl = gvn-&gt;transform(new IfFalseNode(iff1));</span>
2716 
2717   // Compile speed common case: Check for being deterministic right now.  If
2718   // chk_off is a constant and not equal to cacheoff then we are NOT a
2719   // subklass.  In this case we need exactly the 1 test above and we can
2720   // return those results immediately.
2721   if (!might_be_cache) {
2722     Node* not_subtype_ctrl = *ctrl;
2723     *ctrl = iftrue1; // We need exactly the 1 test above
2724     return not_subtype_ctrl;
2725   }
2726 
2727   // Gather the various success &amp; failures here
2728   RegionNode *r_ok_subtype = new RegionNode(4);
<span class="line-modified">2729   gvn-&gt;record_for_igvn(r_ok_subtype);</span>
2730   RegionNode *r_not_subtype = new RegionNode(3);
<span class="line-modified">2731   gvn-&gt;record_for_igvn(r_not_subtype);</span>
2732 
2733   r_ok_subtype-&gt;init_req(1, iftrue1);
2734 
2735   // Check for immediate negative hit.  Happens roughly 11% of the time (which
2736   // is roughly 63% of the remaining cases).  Test to see if the loaded
2737   // check-offset points into the subklass display list or the 1-element
2738   // cache.  If it points to the display (and NOT the cache) and the display
2739   // missed then it&#39;s not a subtype.
<span class="line-modified">2740   Node *cacheoff = gvn-&gt;intcon(cacheoff_con);</span>
2741   IfNode *iff2 = gen_subtype_check_compare(*ctrl, chk_off, cacheoff, BoolTest::ne, PROB_LIKELY(0.63f), gvn, T_INT);
<span class="line-modified">2742   r_not_subtype-&gt;init_req(1, gvn-&gt;transform(new IfTrueNode (iff2)));</span>
<span class="line-modified">2743   *ctrl = gvn-&gt;transform(new IfFalseNode(iff2));</span>
2744 
2745   // Check for self.  Very rare to get here, but it is taken 1/3 the time.
2746   // No performance impact (too rare) but allows sharing of secondary arrays
2747   // which has some footprint reduction.
2748   IfNode *iff3 = gen_subtype_check_compare(*ctrl, subklass, superklass, BoolTest::eq, PROB_LIKELY(0.36f), gvn, T_ADDRESS);
<span class="line-modified">2749   r_ok_subtype-&gt;init_req(2, gvn-&gt;transform(new IfTrueNode(iff3)));</span>
<span class="line-modified">2750   *ctrl = gvn-&gt;transform(new IfFalseNode(iff3));</span>
2751 
2752   // -- Roads not taken here: --
2753   // We could also have chosen to perform the self-check at the beginning
2754   // of this code sequence, as the assembler does.  This would not pay off
2755   // the same way, since the optimizer, unlike the assembler, can perform
2756   // static type analysis to fold away many successful self-checks.
2757   // Non-foldable self checks work better here in second position, because
2758   // the initial primary superclass check subsumes a self-check for most
2759   // types.  An exception would be a secondary type like array-of-interface,
2760   // which does not appear in its own primary supertype display.
2761   // Finally, we could have chosen to move the self-check into the
2762   // PartialSubtypeCheckNode, and from there out-of-line in a platform
2763   // dependent manner.  But it is worthwhile to have the check here,
2764   // where it can be perhaps be optimized.  The cost in code space is
2765   // small (register compare, branch).
2766 
2767   // Now do a linear scan of the secondary super-klass array.  Again, no real
2768   // performance impact (too rare) but it&#39;s gotta be done.
2769   // Since the code is rarely used, there is no penalty for moving it
2770   // out of line, and it can only improve I-cache density.
2771   // The decision to inline or out-of-line this final check is platform
2772   // dependent, and is found in the AD file definition of PartialSubtypeCheck.
<span class="line-modified">2773   Node* psc = gvn-&gt;transform(</span>
2774     new PartialSubtypeCheckNode(*ctrl, subklass, superklass));
2775 
<span class="line-modified">2776   IfNode *iff4 = gen_subtype_check_compare(*ctrl, psc, gvn-&gt;zerocon(T_OBJECT), BoolTest::ne, PROB_FAIR, gvn, T_ADDRESS);</span>
<span class="line-modified">2777   r_not_subtype-&gt;init_req(2, gvn-&gt;transform(new IfTrueNode (iff4)));</span>
<span class="line-modified">2778   r_ok_subtype -&gt;init_req(3, gvn-&gt;transform(new IfFalseNode(iff4)));</span>
2779 
2780   // Return false path; set default control to true path.
<span class="line-modified">2781   *ctrl = gvn-&gt;transform(r_ok_subtype);</span>
<span class="line-modified">2782   return gvn-&gt;transform(r_not_subtype);</span>






















2783 }
2784 
2785 // Profile-driven exact type check:
2786 Node* GraphKit::type_check_receiver(Node* receiver, ciKlass* klass,
2787                                     float prob,
2788                                     Node* *casted_receiver) {
2789   const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);
2790   Node* recv_klass = load_object_klass(receiver);
2791   Node* want_klass = makecon(tklass);
2792   Node* cmp = _gvn.transform( new CmpPNode(recv_klass, want_klass) );
2793   Node* bol = _gvn.transform( new BoolNode(cmp, BoolTest::eq) );
2794   IfNode* iff = create_and_xform_if(control(), bol, prob, COUNT_UNKNOWN);
2795   set_control( _gvn.transform( new IfTrueNode (iff) ));
2796   Node* fail = _gvn.transform( new IfFalseNode(iff) );
2797 
2798   const TypeOopPtr* recv_xtype = tklass-&gt;as_instance_type();
2799   assert(recv_xtype-&gt;klass_is_exact(), &quot;&quot;);
2800 
2801   // Subsume downstream occurrences of receiver with a cast to
2802   // recv_xtype, since now we know what the type will be.
2803   Node* cast = new CheckCastPPNode(control(), receiver, recv_xtype);
2804   (*casted_receiver) = _gvn.transform(cast);
2805   // (User must make the replace_in_map call.)
2806 
2807   return fail;
2808 }
2809 
2810 //------------------------------subtype_check_receiver-------------------------
2811 Node* GraphKit::subtype_check_receiver(Node* receiver, ciKlass* klass,
2812                                        Node** casted_receiver) {
2813   const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);
<span class="line-removed">2814   Node* recv_klass = load_object_klass(receiver);</span>
2815   Node* want_klass = makecon(tklass);
2816 
<span class="line-modified">2817   Node* slow_ctl = gen_subtype_check(recv_klass, want_klass);</span>
2818 
2819   // Cast receiver after successful check
2820   const TypeOopPtr* recv_type = tklass-&gt;cast_to_exactness(false)-&gt;is_klassptr()-&gt;as_instance_type();
2821   Node* cast = new CheckCastPPNode(control(), receiver, recv_type);
2822   (*casted_receiver) = _gvn.transform(cast);
2823 
2824   return slow_ctl;
2825 }
2826 
2827 //------------------------------seems_never_null-------------------------------
2828 // Use null_seen information if it is available from the profile.
2829 // If we see an unexpected null at a type check we record it and force a
2830 // recompile; the offending check will be recompiled to handle NULLs.
2831 // If we see several offending BCIs, then all checks in the
2832 // method will be recompiled.
2833 bool GraphKit::seems_never_null(Node* obj, ciProfileData* data, bool&amp; speculating) {
2834   speculating = !_gvn.type(obj)-&gt;speculative_maybe_null();
2835   Deoptimization::DeoptReason reason = Deoptimization::reason_null_check(speculating);
2836   if (UncommonNullCast               // Cutout for this technique
2837       &amp;&amp; obj != null()               // And not the -Xcomp stupid case?
</pre>
<hr />
<pre>
3062     }
3063   }
3064 
3065   if (!known_statically) {
3066     const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
3067     // We may not have profiling here or it may not help us. If we
3068     // have a speculative type use it to perform an exact cast.
3069     ciKlass* spec_obj_type = obj_type-&gt;speculative_type();
3070     if (spec_obj_type != NULL || (ProfileDynamicTypes &amp;&amp; data != NULL)) {
3071       Node* cast_obj = maybe_cast_profiled_receiver(not_null_obj, NULL, spec_obj_type, safe_for_replace);
3072       if (stopped()) {            // Profile disagrees with this path.
3073         set_control(null_ctl);    // Null is the only remaining possibility.
3074         return intcon(0);
3075       }
3076       if (cast_obj != NULL) {
3077         not_null_obj = cast_obj;
3078       }
3079     }
3080   }
3081 
<span class="line-removed">3082   // Load the object&#39;s klass</span>
<span class="line-removed">3083   Node* obj_klass = load_object_klass(not_null_obj);</span>
<span class="line-removed">3084 </span>
3085   // Generate the subtype check
<span class="line-modified">3086   Node* not_subtype_ctrl = gen_subtype_check(obj_klass, superklass);</span>
3087 
3088   // Plug in the success path to the general merge in slot 1.
3089   region-&gt;init_req(_obj_path, control());
3090   phi   -&gt;init_req(_obj_path, intcon(1));
3091 
3092   // Plug in the failing path to the general merge in slot 2.
3093   region-&gt;init_req(_fail_path, not_subtype_ctrl);
3094   phi   -&gt;init_req(_fail_path, intcon(0));
3095 
3096   // Return final merged results
3097   set_control( _gvn.transform(region) );
3098   record_for_igvn(region);
3099 
3100   // If we know the type check always succeeds then we don&#39;t use the
3101   // profiling data at this bytecode. Don&#39;t lose it, feed it to the
3102   // type system as a speculative type.
3103   if (safe_for_replace) {
3104     Node* casted_obj = record_profiled_receiver_for_speculation(obj);
3105     replace_in_map(obj, casted_obj);
3106   }
</pre>
<hr />
<pre>
3189     // The following optimization tries to statically cast the speculative type of the object
3190     // (for example obtained during profiling) to the type of the superklass and then do a
3191     // dynamic check that the type of the object is what we expect. To work correctly
3192     // for checkcast and aastore the type of superklass should be exact.
3193     const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
3194     // We may not have profiling here or it may not help us. If we have
3195     // a speculative type use it to perform an exact cast.
3196     ciKlass* spec_obj_type = obj_type-&gt;speculative_type();
3197     if (spec_obj_type != NULL || data != NULL) {
3198       cast_obj = maybe_cast_profiled_receiver(not_null_obj, tk-&gt;klass(), spec_obj_type, safe_for_replace);
3199       if (cast_obj != NULL) {
3200         if (failure_control != NULL) // failure is now impossible
3201           (*failure_control) = top();
3202         // adjust the type of the phi to the exact klass:
3203         phi-&gt;raise_bottom_type(_gvn.type(cast_obj)-&gt;meet_speculative(TypePtr::NULL_PTR));
3204       }
3205     }
3206   }
3207 
3208   if (cast_obj == NULL) {
<span class="line-removed">3209     // Load the object&#39;s klass</span>
<span class="line-removed">3210     Node* obj_klass = load_object_klass(not_null_obj);</span>
<span class="line-removed">3211 </span>
3212     // Generate the subtype check
<span class="line-modified">3213     Node* not_subtype_ctrl = gen_subtype_check( obj_klass, superklass );</span>
3214 
3215     // Plug in success path into the merge
3216     cast_obj = _gvn.transform(new CheckCastPPNode(control(), not_null_obj, toop));
3217     // Failure path ends in uncommon trap (or may be dead - failure impossible)
3218     if (failure_control == NULL) {
3219       if (not_subtype_ctrl != top()) { // If failure is possible
3220         PreserveJVMState pjvms(this);
3221         set_control(not_subtype_ctrl);
<span class="line-modified">3222         builtin_throw(Deoptimization::Reason_class_check, obj_klass);</span>
3223       }
3224     } else {
3225       (*failure_control) = not_subtype_ctrl;
3226     }
3227   }
3228 
3229   region-&gt;init_req(_obj_path, control());
3230   phi   -&gt;init_req(_obj_path, cast_obj);
3231 
3232   // A merge of NULL or Casted-NotNull obj
3233   Node* res = _gvn.transform(phi);
3234 
3235   // Note I do NOT always &#39;replace_in_map(obj,result)&#39; here.
3236   //  if( tk-&gt;klass()-&gt;can_be_primary_super()  )
3237     // This means that if I successfully store an Object into an array-of-String
3238     // I &#39;forget&#39; that the Object is really now known to be a String.  I have to
3239     // do this because we don&#39;t have true union types for interfaces - if I store
3240     // a Baz into an array-of-Interface and then tell the optimizer it&#39;s an
3241     // Interface, I forget that it&#39;s also a Baz and cannot do Baz-like field
3242     // references to it.  FIX THIS WHEN UNION TYPES APPEAR!
</pre>
<hr />
<pre>
3860   return NULL;
3861 }
3862 
3863 // Trace Allocate -&gt; Proj[Parm] -&gt; Initialize
3864 InitializeNode* AllocateNode::initialization() {
3865   ProjNode* rawoop = proj_out_or_null(AllocateNode::RawAddress);
3866   if (rawoop == NULL)  return NULL;
3867   for (DUIterator_Fast imax, i = rawoop-&gt;fast_outs(imax); i &lt; imax; i++) {
3868     Node* init = rawoop-&gt;fast_out(i);
3869     if (init-&gt;is_Initialize()) {
3870       assert(init-&gt;as_Initialize()-&gt;allocation() == this, &quot;2-way link&quot;);
3871       return init-&gt;as_Initialize();
3872     }
3873   }
3874   return NULL;
3875 }
3876 
3877 //----------------------------- loop predicates ---------------------------
3878 
3879 //------------------------------add_predicate_impl----------------------------
<span class="line-modified">3880 void GraphKit::add_predicate_impl(Deoptimization::DeoptReason reason, int nargs) {</span>
3881   // Too many traps seen?
3882   if (too_many_traps(reason)) {
3883 #ifdef ASSERT
3884     if (TraceLoopPredicate) {
3885       int tc = C-&gt;trap_count(reason);
3886       tty-&gt;print(&quot;too many traps=%s tcount=%d in &quot;,
3887                     Deoptimization::trap_reason_name(reason), tc);
3888       method()-&gt;print(); // which method has too many predicate traps
3889       tty-&gt;cr();
3890     }
3891 #endif
3892     // We cannot afford to take more traps here,
3893     // do not generate predicate.
3894     return;
3895   }
3896 
3897   Node *cont    = _gvn.intcon(1);
3898   Node* opq     = _gvn.transform(new Opaque1Node(C, cont));
3899   Node *bol     = _gvn.transform(new Conv2BNode(opq));
3900   IfNode* iff   = create_and_map_if(control(), bol, PROB_MAX, COUNT_UNKNOWN);
3901   Node* iffalse = _gvn.transform(new IfFalseNode(iff));
3902   C-&gt;add_predicate_opaq(opq);
3903   {
3904     PreserveJVMState pjvms(this);
3905     set_control(iffalse);
3906     inc_sp(nargs);
3907     uncommon_trap(reason, Deoptimization::Action_maybe_recompile);
3908   }
3909   Node* iftrue = _gvn.transform(new IfTrueNode(iff));
3910   set_control(iftrue);
3911 }
3912 
3913 //------------------------------add_predicate---------------------------------
<span class="line-modified">3914 void GraphKit::add_predicate(int nargs) {</span>



3915   if (UseLoopPredicate) {
<span class="line-modified">3916     add_predicate_impl(Deoptimization::Reason_predicate, nargs);</span>
3917   }
3918   if (UseProfiledLoopPredicate) {
<span class="line-modified">3919     add_predicate_impl(Deoptimization::Reason_profile_predicate, nargs);</span>
3920   }
3921   // loop&#39;s limit check predicate should be near the loop.
<span class="line-modified">3922   add_predicate_impl(Deoptimization::Reason_loop_limit_check, nargs);</span>
3923 }
3924 
3925 void GraphKit::sync_kit(IdealKit&amp; ideal) {
3926   set_all_memory(ideal.merged_memory());
3927   set_i_o(ideal.i_o());
3928   set_control(ideal.ctrl());
3929 }
3930 
3931 void GraphKit::final_sync(IdealKit&amp; ideal) {
3932   // Final sync IdealKit and graphKit.
3933   sync_kit(ideal);
3934 }
3935 
3936 Node* GraphKit::load_String_length(Node* str, bool set_ctrl) {
3937   Node* len = load_array_length(load_String_value(str, set_ctrl));
3938   Node* coder = load_String_coder(str, set_ctrl);
3939   // Divide length by 2 if coder is UTF16
3940   return _gvn.transform(new RShiftINode(len, coder));
3941 }
3942 
</pre>
<hr />
<pre>
4026   set_memory(res_mem, TypeAryPtr::BYTES);
4027   return str;
4028 }
4029 
4030 void GraphKit::inflate_string(Node* src, Node* dst, const TypeAryPtr* dst_type, Node* count) {
4031   assert(Matcher::match_rule_supported(Op_StrInflatedCopy), &quot;Intrinsic not supported&quot;);
4032   assert(dst_type == TypeAryPtr::BYTES || dst_type == TypeAryPtr::CHARS, &quot;invalid dest type&quot;);
4033   // Capture src and dst memory (see comment in &#39;compress_string&#39;).
4034   Node* mem = capture_memory(TypeAryPtr::BYTES, dst_type);
4035   StrInflatedCopyNode* str = new StrInflatedCopyNode(control(), mem, src, dst, count);
4036   set_memory(_gvn.transform(str), dst_type);
4037 }
4038 
4039 void GraphKit::inflate_string_slow(Node* src, Node* dst, Node* start, Node* count) {
4040   /**
4041    * int i_char = start;
4042    * for (int i_byte = 0; i_byte &lt; count; i_byte++) {
4043    *   dst[i_char++] = (char)(src[i_byte] &amp; 0xff);
4044    * }
4045    */
<span class="line-modified">4046   add_predicate();</span>
4047   RegionNode* head = new RegionNode(3);
4048   head-&gt;init_req(1, control());
4049   gvn().set_type(head, Type::CONTROL);
4050   record_for_igvn(head);
4051 
4052   Node* i_byte = new PhiNode(head, TypeInt::INT);
4053   i_byte-&gt;init_req(1, intcon(0));
4054   gvn().set_type(i_byte, TypeInt::INT);
4055   record_for_igvn(i_byte);
4056 
4057   Node* i_char = new PhiNode(head, TypeInt::INT);
4058   i_char-&gt;init_req(1, start);
4059   gvn().set_type(i_char, TypeInt::INT);
4060   record_for_igvn(i_char);
4061 
4062   Node* mem = PhiNode::make(head, memory(TypeAryPtr::BYTES), Type::MEMORY, TypeAryPtr::BYTES);
4063   gvn().set_type(mem, Type::MEMORY);
4064   record_for_igvn(mem);
4065   set_control(head);
4066   set_memory(mem, TypeAryPtr::BYTES);
</pre>
</td>
<td>
<hr />
<pre>
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;ci/ciUtilities.hpp&quot;
  27 #include &quot;compiler/compileLog.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  30 #include &quot;interpreter/interpreter.hpp&quot;
  31 #include &quot;memory/resourceArea.hpp&quot;
  32 #include &quot;opto/addnode.hpp&quot;
  33 #include &quot;opto/castnode.hpp&quot;
  34 #include &quot;opto/convertnode.hpp&quot;
  35 #include &quot;opto/graphKit.hpp&quot;
  36 #include &quot;opto/idealKit.hpp&quot;
  37 #include &quot;opto/intrinsicnode.hpp&quot;
  38 #include &quot;opto/locknode.hpp&quot;
  39 #include &quot;opto/machnode.hpp&quot;
  40 #include &quot;opto/opaquenode.hpp&quot;
  41 #include &quot;opto/parse.hpp&quot;
  42 #include &quot;opto/rootnode.hpp&quot;
  43 #include &quot;opto/runtime.hpp&quot;
<span class="line-added">  44 #include &quot;opto/subtypenode.hpp&quot;</span>
  45 #include &quot;runtime/deoptimization.hpp&quot;
  46 #include &quot;runtime/sharedRuntime.hpp&quot;
  47 #include &quot;utilities/bitMap.inline.hpp&quot;
<span class="line-added">  48 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  49 
  50 //----------------------------GraphKit-----------------------------------------
  51 // Main utility constructor.
  52 GraphKit::GraphKit(JVMState* jvms)
  53   : Phase(Phase::Parser),
  54     _env(C-&gt;env()),
  55     _gvn(*C-&gt;initial_gvn()),
  56     _barrier_set(BarrierSet::barrier_set()-&gt;barrier_set_c2())
  57 {
  58   _exceptions = jvms-&gt;map()-&gt;next_exception();
  59   if (_exceptions != NULL)  jvms-&gt;map()-&gt;set_next_exception(NULL);
  60   set_jvms(jvms);
  61 }
  62 
  63 // Private constructor for parser.
  64 GraphKit::GraphKit()
  65   : Phase(Phase::Parser),
  66     _env(C-&gt;env()),
  67     _gvn(*C-&gt;initial_gvn()),
  68     _barrier_set(BarrierSet::barrier_set()-&gt;barrier_set_c2())
</pre>
<hr />
<pre>
2127 // Report the object that was just allocated.
2128 // It must be the case that there are no intervening safepoints.
2129 // We use this to determine if an object is so &quot;fresh&quot; that
2130 // it does not require card marks.
2131 Node* GraphKit::just_allocated_object(Node* current_control) {
2132   Node* ctrl = current_control;
2133   // Object::&lt;init&gt; is invoked after allocation, most of invoke nodes
2134   // will be reduced, but a region node is kept in parse time, we check
2135   // the pattern and skip the region node if it degraded to a copy.
2136   if (ctrl != NULL &amp;&amp; ctrl-&gt;is_Region() &amp;&amp; ctrl-&gt;req() == 2 &amp;&amp;
2137       ctrl-&gt;as_Region()-&gt;is_copy()) {
2138     ctrl = ctrl-&gt;as_Region()-&gt;is_copy();
2139   }
2140   if (C-&gt;recent_alloc_ctl() == ctrl) {
2141    return C-&gt;recent_alloc_obj();
2142   }
2143   return NULL;
2144 }
2145 
2146 
















2147 /**
2148  * Record profiling data exact_kls for Node n with the type system so
2149  * that it can propagate it (speculation)
2150  *
2151  * @param n          node that the type applies to
2152  * @param exact_kls  type from profiling
2153  * @param maybe_null did profiling see null?
2154  *
2155  * @return           node with improved type
2156  */
2157 Node* GraphKit::record_profile_for_speculation(Node* n, ciKlass* exact_kls, ProfilePtrKind ptr_kind) {
2158   const Type* current_type = _gvn.type(n);
2159   assert(UseTypeSpeculation, &quot;type speculation must be on&quot;);
2160 
2161   const TypePtr* speculative = current_type-&gt;speculative();
2162 
2163   // Should the klass from the profile be recorded in the speculative type?
2164   if (current_type-&gt;would_improve_type(exact_kls, jvms()-&gt;depth())) {
2165     const TypeKlassPtr* tklass = TypeKlassPtr::make(exact_kls);
2166     const TypeOopPtr* xtype = tklass-&gt;as_instance_type();
</pre>
<hr />
<pre>
2292 
2293 /**
2294  * Record profiling data from return value profiling at an invoke with
2295  * the type system so that it can propagate it (speculation)
2296  */
2297 void GraphKit::record_profiled_return_for_speculation() {
2298   if (!UseTypeSpeculation) {
2299     return;
2300   }
2301   ProfilePtrKind ptr_kind = ProfileMaybeNull;
2302   ciKlass* better_type = NULL;
2303   if (method()-&gt;return_profiled_type(bci(), better_type, ptr_kind)) {
2304     // If profiling reports a single type for the return value,
2305     // feed it to the type system so it can propagate it as a
2306     // speculative type
2307     record_profile_for_speculation(stack(sp()-1), better_type, ptr_kind);
2308   }
2309 }
2310 
2311 void GraphKit::round_double_result(ciMethod* dest_method) {
<span class="line-modified">2312   if (Matcher::strict_fp_requires_explicit_rounding) {</span>
<span class="line-modified">2313     // If a strict caller invokes a non-strict callee, round a double result.</span>
<span class="line-modified">2314     // A non-strict method may return a double value which has an extended exponent,</span>
<span class="line-added">2315     // but this must not be visible in a caller which is strict.</span>
<span class="line-added">2316     BasicType result_type = dest_method-&gt;return_type()-&gt;basic_type();</span>
<span class="line-added">2317     assert(method() != NULL, &quot;must have caller context&quot;);</span>
<span class="line-added">2318     if( result_type == T_DOUBLE &amp;&amp; method()-&gt;is_strict() &amp;&amp; !dest_method-&gt;is_strict() ) {</span>
<span class="line-added">2319       // Destination method&#39;s return value is on top of stack</span>
<span class="line-added">2320       // dstore_rounding() does gvn.transform</span>
<span class="line-added">2321       Node *result = pop_pair();</span>
<span class="line-added">2322       result = dstore_rounding(result);</span>
<span class="line-added">2323       push_pair(result);</span>
<span class="line-added">2324     }</span>
<span class="line-added">2325   }</span>
<span class="line-added">2326 }</span>
2327 
<span class="line-modified">2328 void GraphKit::round_double_arguments(ciMethod* dest_method) {</span>
<span class="line-modified">2329   if (Matcher::strict_fp_requires_explicit_rounding) {</span>
<span class="line-modified">2330     // (Note:  TypeFunc::make has a cache that makes this fast.)</span>
<span class="line-modified">2331     const TypeFunc* tf    = TypeFunc::make(dest_method);</span>
<span class="line-modified">2332     int             nargs = tf-&gt;domain()-&gt;cnt() - TypeFunc::Parms;</span>
<span class="line-modified">2333     for (int j = 0; j &lt; nargs; j++) {</span>
<span class="line-modified">2334       const Type *targ = tf-&gt;domain()-&gt;field_at(j + TypeFunc::Parms);</span>
<span class="line-modified">2335       if (targ-&gt;basic_type() == T_DOUBLE) {</span>
<span class="line-added">2336         // If any parameters are doubles, they must be rounded before</span>
<span class="line-added">2337         // the call, dstore_rounding does gvn.transform</span>
<span class="line-added">2338         Node *arg = argument(j);</span>
<span class="line-added">2339         arg = dstore_rounding(arg);</span>
<span class="line-added">2340         set_argument(j, arg);</span>
<span class="line-added">2341       }</span>
<span class="line-added">2342     }</span>
2343   }
2344 }
2345 
2346 // rounding for strict float precision conformance
2347 Node* GraphKit::precision_rounding(Node* n) {
<span class="line-modified">2348   if (Matcher::strict_fp_requires_explicit_rounding) {</span>
<span class="line-modified">2349 #ifdef IA32</span>
<span class="line-modified">2350     if (_method-&gt;flags().is_strict() &amp;&amp; UseSSE == 0) {</span>
<span class="line-modified">2351       return _gvn.transform(new RoundFloatNode(0, n));</span>
<span class="line-added">2352     }</span>
<span class="line-added">2353 #else</span>
<span class="line-added">2354     Unimplemented();</span>
<span class="line-added">2355 #endif // IA32</span>
<span class="line-added">2356   }</span>
<span class="line-added">2357   return n;</span>
2358 }
2359 
2360 // rounding for strict double precision conformance
2361 Node* GraphKit::dprecision_rounding(Node *n) {
<span class="line-modified">2362   if (Matcher::strict_fp_requires_explicit_rounding) {</span>
<span class="line-modified">2363 #ifdef IA32</span>
<span class="line-modified">2364     if (_method-&gt;flags().is_strict() &amp;&amp; UseSSE &lt; 2) {</span>
<span class="line-modified">2365       return _gvn.transform(new RoundDoubleNode(0, n));</span>
<span class="line-added">2366     }</span>
<span class="line-added">2367 #else</span>
<span class="line-added">2368     Unimplemented();</span>
<span class="line-added">2369 #endif // IA32</span>
<span class="line-added">2370   }</span>
<span class="line-added">2371   return n;</span>
2372 }
2373 
2374 // rounding for non-strict double stores
2375 Node* GraphKit::dstore_rounding(Node* n) {
<span class="line-modified">2376   if (Matcher::strict_fp_requires_explicit_rounding) {</span>
<span class="line-modified">2377 #ifdef IA32</span>
<span class="line-modified">2378     if (UseSSE &lt; 2) {</span>
<span class="line-modified">2379       return _gvn.transform(new RoundDoubleNode(0, n));</span>
<span class="line-added">2380     }</span>
<span class="line-added">2381 #else</span>
<span class="line-added">2382     Unimplemented();</span>
<span class="line-added">2383 #endif // IA32</span>
<span class="line-added">2384   }</span>
<span class="line-added">2385   return n;</span>
2386 }
2387 
2388 //=============================================================================
2389 // Generate a fast path/slow path idiom.  Graph looks like:
2390 // [foo] indicates that &#39;foo&#39; is a parameter
2391 //
2392 //              [in]     NULL
2393 //                 \    /
2394 //                  CmpP
2395 //                  Bool ne
2396 //                   If
2397 //                  /  \
2398 //              True    False-&lt;2&gt;
2399 //              / |
2400 //             /  cast_not_null
2401 //           Load  |    |   ^
2402 //        [fast_test]   |   |
2403 // gvn to   opt_test    |   |
2404 //          /    \      |  &lt;1&gt;
2405 //      True     False  |
</pre>
<hr />
<pre>
2607 
2608     if (excp != top()) {
2609       if (deoptimize) {
2610         // Deoptimize if an exception is caught. Don&#39;t construct exception state in this case.
2611         uncommon_trap(Deoptimization::Reason_unhandled,
2612                       Deoptimization::Action_none);
2613       } else {
2614         // Create an exception state also.
2615         // Use an exact type if the caller has a specific exception.
2616         const Type* ex_type = TypeOopPtr::make_from_klass_unique(ex_klass)-&gt;cast_to_ptr_type(TypePtr::NotNull);
2617         Node*       ex_oop  = new CreateExNode(ex_type, control(), i_o);
2618         add_exception_state(make_exception_state(_gvn.transform(ex_oop)));
2619       }
2620     }
2621   }
2622 
2623   // Get the no-exception control from the CatchNode.
2624   set_control(norm);
2625 }
2626 
<span class="line-modified">2627 static IfNode* gen_subtype_check_compare(Node* ctrl, Node* in1, Node* in2, BoolTest::mask test, float p, PhaseGVN&amp; gvn, BasicType bt) {</span>
2628   Node* cmp = NULL;
2629   switch(bt) {
2630   case T_INT: cmp = new CmpINode(in1, in2); break;
2631   case T_ADDRESS: cmp = new CmpPNode(in1, in2); break;
2632   default: fatal(&quot;unexpected comparison type %s&quot;, type2name(bt));
2633   }
<span class="line-modified">2634   gvn.transform(cmp);</span>
<span class="line-modified">2635   Node* bol = gvn.transform(new BoolNode(cmp, test));</span>
2636   IfNode* iff = new IfNode(ctrl, bol, p, COUNT_UNKNOWN);
<span class="line-modified">2637   gvn.transform(iff);</span>
<span class="line-modified">2638   if (!bol-&gt;is_Con()) gvn.record_for_igvn(iff);</span>
2639   return iff;
2640 }
2641 

2642 //-------------------------------gen_subtype_check-----------------------------
2643 // Generate a subtyping check.  Takes as input the subtype and supertype.
2644 // Returns 2 values: sets the default control() to the true path and returns
2645 // the false path.  Only reads invariant memory; sets no (visible) memory.
2646 // The PartialSubtypeCheckNode sets the hidden 1-word cache in the encoding
2647 // but that&#39;s not exposed to the optimizer.  This call also doesn&#39;t take in an
2648 // Object; if you wish to check an Object you need to load the Object&#39;s class
2649 // prior to coming here.
<span class="line-modified">2650 Node* Phase::gen_subtype_check(Node* subklass, Node* superklass, Node** ctrl, Node* mem, PhaseGVN&amp; gvn) {</span>
<span class="line-modified">2651   Compile* C = gvn.C;</span>

2652   if ((*ctrl)-&gt;is_top()) {
2653     return C-&gt;top();
2654   }
2655 
2656   // Fast check for identical types, perhaps identical constants.
2657   // The types can even be identical non-constants, in cases
2658   // involving Array.newInstance, Object.clone, etc.
2659   if (subklass == superklass)
2660     return C-&gt;top();             // false path is dead; no test needed.
2661 
<span class="line-modified">2662   if (gvn.type(superklass)-&gt;singleton()) {</span>
<span class="line-modified">2663     ciKlass* superk = gvn.type(superklass)-&gt;is_klassptr()-&gt;klass();</span>
<span class="line-modified">2664     ciKlass* subk   = gvn.type(subklass)-&gt;is_klassptr()-&gt;klass();</span>
2665 
2666     // In the common case of an exact superklass, try to fold up the
2667     // test before generating code.  You may ask, why not just generate
2668     // the code and then let it fold up?  The answer is that the generated
2669     // code will necessarily include null checks, which do not always
2670     // completely fold away.  If they are also needless, then they turn
2671     // into a performance loss.  Example:
2672     //    Foo[] fa = blah(); Foo x = fa[0]; fa[1] = x;
2673     // Here, the type of &#39;fa&#39; is often exact, so the store check
2674     // of fa[1]=x will fold up, without testing the nullness of x.
2675     switch (C-&gt;static_subtype_check(superk, subk)) {
2676     case Compile::SSC_always_false:
2677       {
2678         Node* always_fail = *ctrl;
<span class="line-modified">2679         *ctrl = gvn.C-&gt;top();</span>
2680         return always_fail;
2681       }
2682     case Compile::SSC_always_true:
2683       return C-&gt;top();
2684     case Compile::SSC_easy_test:
2685       {
2686         // Just do a direct pointer compare and be done.
2687         IfNode* iff = gen_subtype_check_compare(*ctrl, subklass, superklass, BoolTest::eq, PROB_STATIC_FREQUENT, gvn, T_ADDRESS);
<span class="line-modified">2688         *ctrl = gvn.transform(new IfTrueNode(iff));</span>
<span class="line-modified">2689         return gvn.transform(new IfFalseNode(iff));</span>
2690       }
2691     case Compile::SSC_full_test:
2692       break;
2693     default:
2694       ShouldNotReachHere();
2695     }
2696   }
2697 
2698   // %%% Possible further optimization:  Even if the superklass is not exact,
2699   // if the subklass is the unique subtype of the superklass, the check
2700   // will always succeed.  We could leave a dependency behind to ensure this.
2701 
2702   // First load the super-klass&#39;s check-offset
<span class="line-modified">2703   Node *p1 = gvn.transform(new AddPNode(superklass, superklass, gvn.MakeConX(in_bytes(Klass::super_check_offset_offset()))));</span>
<span class="line-modified">2704   Node* m = C-&gt;immutable_memory();</span>
<span class="line-modified">2705   Node *chk_off = gvn.transform(new LoadINode(NULL, m, p1, gvn.type(p1)-&gt;is_ptr(), TypeInt::INT, MemNode::unordered));</span>
2706   int cacheoff_con = in_bytes(Klass::secondary_super_cache_offset());
<span class="line-modified">2707   bool might_be_cache = (gvn.find_int_con(chk_off, cacheoff_con) == cacheoff_con);</span>
2708 
2709   // Load from the sub-klass&#39;s super-class display list, or a 1-word cache of
2710   // the secondary superclass list, or a failing value with a sentinel offset
2711   // if the super-klass is an interface or exceptionally deep in the Java
2712   // hierarchy and we have to scan the secondary superclass list the hard way.
2713   // Worst-case type is a little odd: NULL is allowed as a result (usually
2714   // klass loads can never produce a NULL).
2715   Node *chk_off_X = chk_off;
2716 #ifdef _LP64
<span class="line-modified">2717   chk_off_X = gvn.transform(new ConvI2LNode(chk_off_X));</span>
2718 #endif
<span class="line-modified">2719   Node *p2 = gvn.transform(new AddPNode(subklass,subklass,chk_off_X));</span>
2720   // For some types like interfaces the following loadKlass is from a 1-word
2721   // cache which is mutable so can&#39;t use immutable memory.  Other
2722   // types load from the super-class display table which is immutable.
<span class="line-modified">2723   Node *kmem = C-&gt;immutable_memory();</span>
<span class="line-modified">2724   // secondary_super_cache is not immutable but can be treated as such because:</span>
<span class="line-modified">2725   // - no ideal node writes to it in a way that could cause an</span>
<span class="line-added">2726   //   incorrect/missed optimization of the following Load.</span>
<span class="line-added">2727   // - it&#39;s a cache so, worse case, not reading the latest value</span>
<span class="line-added">2728   //   wouldn&#39;t cause incorrect execution</span>
<span class="line-added">2729   if (might_be_cache &amp;&amp; mem != NULL) {</span>
<span class="line-added">2730     kmem = mem-&gt;is_MergeMem() ? mem-&gt;as_MergeMem()-&gt;memory_at(C-&gt;get_alias_index(gvn.type(p2)-&gt;is_ptr())) : mem;</span>
<span class="line-added">2731   }</span>
<span class="line-added">2732   Node *nkls = gvn.transform(LoadKlassNode::make(gvn, NULL, kmem, p2, gvn.type(p2)-&gt;is_ptr(), TypeKlassPtr::OBJECT_OR_NULL));</span>
2733 
2734   // Compile speed common case: ARE a subtype and we canNOT fail
2735   if( superklass == nkls )
2736     return C-&gt;top();             // false path is dead; no test needed.
2737 
2738   // See if we get an immediate positive hit.  Happens roughly 83% of the
2739   // time.  Test to see if the value loaded just previously from the subklass
2740   // is exactly the superklass.
2741   IfNode *iff1 = gen_subtype_check_compare(*ctrl, superklass, nkls, BoolTest::eq, PROB_LIKELY(0.83f), gvn, T_ADDRESS);
<span class="line-modified">2742   Node *iftrue1 = gvn.transform( new IfTrueNode (iff1));</span>
<span class="line-modified">2743   *ctrl = gvn.transform(new IfFalseNode(iff1));</span>
2744 
2745   // Compile speed common case: Check for being deterministic right now.  If
2746   // chk_off is a constant and not equal to cacheoff then we are NOT a
2747   // subklass.  In this case we need exactly the 1 test above and we can
2748   // return those results immediately.
2749   if (!might_be_cache) {
2750     Node* not_subtype_ctrl = *ctrl;
2751     *ctrl = iftrue1; // We need exactly the 1 test above
2752     return not_subtype_ctrl;
2753   }
2754 
2755   // Gather the various success &amp; failures here
2756   RegionNode *r_ok_subtype = new RegionNode(4);
<span class="line-modified">2757   gvn.record_for_igvn(r_ok_subtype);</span>
2758   RegionNode *r_not_subtype = new RegionNode(3);
<span class="line-modified">2759   gvn.record_for_igvn(r_not_subtype);</span>
2760 
2761   r_ok_subtype-&gt;init_req(1, iftrue1);
2762 
2763   // Check for immediate negative hit.  Happens roughly 11% of the time (which
2764   // is roughly 63% of the remaining cases).  Test to see if the loaded
2765   // check-offset points into the subklass display list or the 1-element
2766   // cache.  If it points to the display (and NOT the cache) and the display
2767   // missed then it&#39;s not a subtype.
<span class="line-modified">2768   Node *cacheoff = gvn.intcon(cacheoff_con);</span>
2769   IfNode *iff2 = gen_subtype_check_compare(*ctrl, chk_off, cacheoff, BoolTest::ne, PROB_LIKELY(0.63f), gvn, T_INT);
<span class="line-modified">2770   r_not_subtype-&gt;init_req(1, gvn.transform(new IfTrueNode (iff2)));</span>
<span class="line-modified">2771   *ctrl = gvn.transform(new IfFalseNode(iff2));</span>
2772 
2773   // Check for self.  Very rare to get here, but it is taken 1/3 the time.
2774   // No performance impact (too rare) but allows sharing of secondary arrays
2775   // which has some footprint reduction.
2776   IfNode *iff3 = gen_subtype_check_compare(*ctrl, subklass, superklass, BoolTest::eq, PROB_LIKELY(0.36f), gvn, T_ADDRESS);
<span class="line-modified">2777   r_ok_subtype-&gt;init_req(2, gvn.transform(new IfTrueNode(iff3)));</span>
<span class="line-modified">2778   *ctrl = gvn.transform(new IfFalseNode(iff3));</span>
2779 
2780   // -- Roads not taken here: --
2781   // We could also have chosen to perform the self-check at the beginning
2782   // of this code sequence, as the assembler does.  This would not pay off
2783   // the same way, since the optimizer, unlike the assembler, can perform
2784   // static type analysis to fold away many successful self-checks.
2785   // Non-foldable self checks work better here in second position, because
2786   // the initial primary superclass check subsumes a self-check for most
2787   // types.  An exception would be a secondary type like array-of-interface,
2788   // which does not appear in its own primary supertype display.
2789   // Finally, we could have chosen to move the self-check into the
2790   // PartialSubtypeCheckNode, and from there out-of-line in a platform
2791   // dependent manner.  But it is worthwhile to have the check here,
2792   // where it can be perhaps be optimized.  The cost in code space is
2793   // small (register compare, branch).
2794 
2795   // Now do a linear scan of the secondary super-klass array.  Again, no real
2796   // performance impact (too rare) but it&#39;s gotta be done.
2797   // Since the code is rarely used, there is no penalty for moving it
2798   // out of line, and it can only improve I-cache density.
2799   // The decision to inline or out-of-line this final check is platform
2800   // dependent, and is found in the AD file definition of PartialSubtypeCheck.
<span class="line-modified">2801   Node* psc = gvn.transform(</span>
2802     new PartialSubtypeCheckNode(*ctrl, subklass, superklass));
2803 
<span class="line-modified">2804   IfNode *iff4 = gen_subtype_check_compare(*ctrl, psc, gvn.zerocon(T_OBJECT), BoolTest::ne, PROB_FAIR, gvn, T_ADDRESS);</span>
<span class="line-modified">2805   r_not_subtype-&gt;init_req(2, gvn.transform(new IfTrueNode (iff4)));</span>
<span class="line-modified">2806   r_ok_subtype -&gt;init_req(3, gvn.transform(new IfFalseNode(iff4)));</span>
2807 
2808   // Return false path; set default control to true path.
<span class="line-modified">2809   *ctrl = gvn.transform(r_ok_subtype);</span>
<span class="line-modified">2810   return gvn.transform(r_not_subtype);</span>
<span class="line-added">2811 }</span>
<span class="line-added">2812 </span>
<span class="line-added">2813 Node* GraphKit::gen_subtype_check(Node* obj_or_subklass, Node* superklass) {</span>
<span class="line-added">2814   if (ExpandSubTypeCheckAtParseTime) {</span>
<span class="line-added">2815     MergeMemNode* mem = merged_memory();</span>
<span class="line-added">2816     Node* ctrl = control();</span>
<span class="line-added">2817     Node* subklass = obj_or_subklass;</span>
<span class="line-added">2818     if (!_gvn.type(obj_or_subklass)-&gt;isa_klassptr()) {</span>
<span class="line-added">2819       subklass = load_object_klass(obj_or_subklass);</span>
<span class="line-added">2820     }</span>
<span class="line-added">2821 </span>
<span class="line-added">2822     Node* n = Phase::gen_subtype_check(subklass, superklass, &amp;ctrl, mem, _gvn);</span>
<span class="line-added">2823     set_control(ctrl);</span>
<span class="line-added">2824     return n;</span>
<span class="line-added">2825   }</span>
<span class="line-added">2826 </span>
<span class="line-added">2827   const TypePtr* adr_type = TypeKlassPtr::make(TypePtr::NotNull, C-&gt;env()-&gt;Object_klass(), Type::OffsetBot);</span>
<span class="line-added">2828   Node* check = _gvn.transform(new SubTypeCheckNode(C, obj_or_subklass, superklass));</span>
<span class="line-added">2829   Node* bol = _gvn.transform(new BoolNode(check, BoolTest::eq));</span>
<span class="line-added">2830   IfNode* iff = create_and_xform_if(control(), bol, PROB_STATIC_FREQUENT, COUNT_UNKNOWN);</span>
<span class="line-added">2831   set_control(_gvn.transform(new IfTrueNode(iff)));</span>
<span class="line-added">2832   return _gvn.transform(new IfFalseNode(iff));</span>
2833 }
2834 
2835 // Profile-driven exact type check:
2836 Node* GraphKit::type_check_receiver(Node* receiver, ciKlass* klass,
2837                                     float prob,
2838                                     Node* *casted_receiver) {
2839   const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);
2840   Node* recv_klass = load_object_klass(receiver);
2841   Node* want_klass = makecon(tklass);
2842   Node* cmp = _gvn.transform( new CmpPNode(recv_klass, want_klass) );
2843   Node* bol = _gvn.transform( new BoolNode(cmp, BoolTest::eq) );
2844   IfNode* iff = create_and_xform_if(control(), bol, prob, COUNT_UNKNOWN);
2845   set_control( _gvn.transform( new IfTrueNode (iff) ));
2846   Node* fail = _gvn.transform( new IfFalseNode(iff) );
2847 
2848   const TypeOopPtr* recv_xtype = tklass-&gt;as_instance_type();
2849   assert(recv_xtype-&gt;klass_is_exact(), &quot;&quot;);
2850 
2851   // Subsume downstream occurrences of receiver with a cast to
2852   // recv_xtype, since now we know what the type will be.
2853   Node* cast = new CheckCastPPNode(control(), receiver, recv_xtype);
2854   (*casted_receiver) = _gvn.transform(cast);
2855   // (User must make the replace_in_map call.)
2856 
2857   return fail;
2858 }
2859 
2860 //------------------------------subtype_check_receiver-------------------------
2861 Node* GraphKit::subtype_check_receiver(Node* receiver, ciKlass* klass,
2862                                        Node** casted_receiver) {
2863   const TypeKlassPtr* tklass = TypeKlassPtr::make(klass);

2864   Node* want_klass = makecon(tklass);
2865 
<span class="line-modified">2866   Node* slow_ctl = gen_subtype_check(receiver, want_klass);</span>
2867 
2868   // Cast receiver after successful check
2869   const TypeOopPtr* recv_type = tklass-&gt;cast_to_exactness(false)-&gt;is_klassptr()-&gt;as_instance_type();
2870   Node* cast = new CheckCastPPNode(control(), receiver, recv_type);
2871   (*casted_receiver) = _gvn.transform(cast);
2872 
2873   return slow_ctl;
2874 }
2875 
2876 //------------------------------seems_never_null-------------------------------
2877 // Use null_seen information if it is available from the profile.
2878 // If we see an unexpected null at a type check we record it and force a
2879 // recompile; the offending check will be recompiled to handle NULLs.
2880 // If we see several offending BCIs, then all checks in the
2881 // method will be recompiled.
2882 bool GraphKit::seems_never_null(Node* obj, ciProfileData* data, bool&amp; speculating) {
2883   speculating = !_gvn.type(obj)-&gt;speculative_maybe_null();
2884   Deoptimization::DeoptReason reason = Deoptimization::reason_null_check(speculating);
2885   if (UncommonNullCast               // Cutout for this technique
2886       &amp;&amp; obj != null()               // And not the -Xcomp stupid case?
</pre>
<hr />
<pre>
3111     }
3112   }
3113 
3114   if (!known_statically) {
3115     const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
3116     // We may not have profiling here or it may not help us. If we
3117     // have a speculative type use it to perform an exact cast.
3118     ciKlass* spec_obj_type = obj_type-&gt;speculative_type();
3119     if (spec_obj_type != NULL || (ProfileDynamicTypes &amp;&amp; data != NULL)) {
3120       Node* cast_obj = maybe_cast_profiled_receiver(not_null_obj, NULL, spec_obj_type, safe_for_replace);
3121       if (stopped()) {            // Profile disagrees with this path.
3122         set_control(null_ctl);    // Null is the only remaining possibility.
3123         return intcon(0);
3124       }
3125       if (cast_obj != NULL) {
3126         not_null_obj = cast_obj;
3127       }
3128     }
3129   }
3130 



3131   // Generate the subtype check
<span class="line-modified">3132   Node* not_subtype_ctrl = gen_subtype_check(not_null_obj, superklass);</span>
3133 
3134   // Plug in the success path to the general merge in slot 1.
3135   region-&gt;init_req(_obj_path, control());
3136   phi   -&gt;init_req(_obj_path, intcon(1));
3137 
3138   // Plug in the failing path to the general merge in slot 2.
3139   region-&gt;init_req(_fail_path, not_subtype_ctrl);
3140   phi   -&gt;init_req(_fail_path, intcon(0));
3141 
3142   // Return final merged results
3143   set_control( _gvn.transform(region) );
3144   record_for_igvn(region);
3145 
3146   // If we know the type check always succeeds then we don&#39;t use the
3147   // profiling data at this bytecode. Don&#39;t lose it, feed it to the
3148   // type system as a speculative type.
3149   if (safe_for_replace) {
3150     Node* casted_obj = record_profiled_receiver_for_speculation(obj);
3151     replace_in_map(obj, casted_obj);
3152   }
</pre>
<hr />
<pre>
3235     // The following optimization tries to statically cast the speculative type of the object
3236     // (for example obtained during profiling) to the type of the superklass and then do a
3237     // dynamic check that the type of the object is what we expect. To work correctly
3238     // for checkcast and aastore the type of superklass should be exact.
3239     const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
3240     // We may not have profiling here or it may not help us. If we have
3241     // a speculative type use it to perform an exact cast.
3242     ciKlass* spec_obj_type = obj_type-&gt;speculative_type();
3243     if (spec_obj_type != NULL || data != NULL) {
3244       cast_obj = maybe_cast_profiled_receiver(not_null_obj, tk-&gt;klass(), spec_obj_type, safe_for_replace);
3245       if (cast_obj != NULL) {
3246         if (failure_control != NULL) // failure is now impossible
3247           (*failure_control) = top();
3248         // adjust the type of the phi to the exact klass:
3249         phi-&gt;raise_bottom_type(_gvn.type(cast_obj)-&gt;meet_speculative(TypePtr::NULL_PTR));
3250       }
3251     }
3252   }
3253 
3254   if (cast_obj == NULL) {



3255     // Generate the subtype check
<span class="line-modified">3256     Node* not_subtype_ctrl = gen_subtype_check(not_null_obj, superklass );</span>
3257 
3258     // Plug in success path into the merge
3259     cast_obj = _gvn.transform(new CheckCastPPNode(control(), not_null_obj, toop));
3260     // Failure path ends in uncommon trap (or may be dead - failure impossible)
3261     if (failure_control == NULL) {
3262       if (not_subtype_ctrl != top()) { // If failure is possible
3263         PreserveJVMState pjvms(this);
3264         set_control(not_subtype_ctrl);
<span class="line-modified">3265         builtin_throw(Deoptimization::Reason_class_check, load_object_klass(not_null_obj));</span>
3266       }
3267     } else {
3268       (*failure_control) = not_subtype_ctrl;
3269     }
3270   }
3271 
3272   region-&gt;init_req(_obj_path, control());
3273   phi   -&gt;init_req(_obj_path, cast_obj);
3274 
3275   // A merge of NULL or Casted-NotNull obj
3276   Node* res = _gvn.transform(phi);
3277 
3278   // Note I do NOT always &#39;replace_in_map(obj,result)&#39; here.
3279   //  if( tk-&gt;klass()-&gt;can_be_primary_super()  )
3280     // This means that if I successfully store an Object into an array-of-String
3281     // I &#39;forget&#39; that the Object is really now known to be a String.  I have to
3282     // do this because we don&#39;t have true union types for interfaces - if I store
3283     // a Baz into an array-of-Interface and then tell the optimizer it&#39;s an
3284     // Interface, I forget that it&#39;s also a Baz and cannot do Baz-like field
3285     // references to it.  FIX THIS WHEN UNION TYPES APPEAR!
</pre>
<hr />
<pre>
3903   return NULL;
3904 }
3905 
3906 // Trace Allocate -&gt; Proj[Parm] -&gt; Initialize
3907 InitializeNode* AllocateNode::initialization() {
3908   ProjNode* rawoop = proj_out_or_null(AllocateNode::RawAddress);
3909   if (rawoop == NULL)  return NULL;
3910   for (DUIterator_Fast imax, i = rawoop-&gt;fast_outs(imax); i &lt; imax; i++) {
3911     Node* init = rawoop-&gt;fast_out(i);
3912     if (init-&gt;is_Initialize()) {
3913       assert(init-&gt;as_Initialize()-&gt;allocation() == this, &quot;2-way link&quot;);
3914       return init-&gt;as_Initialize();
3915     }
3916   }
3917   return NULL;
3918 }
3919 
3920 //----------------------------- loop predicates ---------------------------
3921 
3922 //------------------------------add_predicate_impl----------------------------
<span class="line-modified">3923 void GraphKit::add_empty_predicate_impl(Deoptimization::DeoptReason reason, int nargs) {</span>
3924   // Too many traps seen?
3925   if (too_many_traps(reason)) {
3926 #ifdef ASSERT
3927     if (TraceLoopPredicate) {
3928       int tc = C-&gt;trap_count(reason);
3929       tty-&gt;print(&quot;too many traps=%s tcount=%d in &quot;,
3930                     Deoptimization::trap_reason_name(reason), tc);
3931       method()-&gt;print(); // which method has too many predicate traps
3932       tty-&gt;cr();
3933     }
3934 #endif
3935     // We cannot afford to take more traps here,
3936     // do not generate predicate.
3937     return;
3938   }
3939 
3940   Node *cont    = _gvn.intcon(1);
3941   Node* opq     = _gvn.transform(new Opaque1Node(C, cont));
3942   Node *bol     = _gvn.transform(new Conv2BNode(opq));
3943   IfNode* iff   = create_and_map_if(control(), bol, PROB_MAX, COUNT_UNKNOWN);
3944   Node* iffalse = _gvn.transform(new IfFalseNode(iff));
3945   C-&gt;add_predicate_opaq(opq);
3946   {
3947     PreserveJVMState pjvms(this);
3948     set_control(iffalse);
3949     inc_sp(nargs);
3950     uncommon_trap(reason, Deoptimization::Action_maybe_recompile);
3951   }
3952   Node* iftrue = _gvn.transform(new IfTrueNode(iff));
3953   set_control(iftrue);
3954 }
3955 
3956 //------------------------------add_predicate---------------------------------
<span class="line-modified">3957 void GraphKit::add_empty_predicates(int nargs) {</span>
<span class="line-added">3958   // These loop predicates remain empty. All concrete loop predicates are inserted above the corresponding</span>
<span class="line-added">3959   // empty loop predicate later by &#39;PhaseIdealLoop::create_new_if_for_predicate&#39;. All concrete loop predicates of</span>
<span class="line-added">3960   // a specific kind (normal, profile or limit check) share the same uncommon trap as the empty loop predicate.</span>
3961   if (UseLoopPredicate) {
<span class="line-modified">3962     add_empty_predicate_impl(Deoptimization::Reason_predicate, nargs);</span>
3963   }
3964   if (UseProfiledLoopPredicate) {
<span class="line-modified">3965     add_empty_predicate_impl(Deoptimization::Reason_profile_predicate, nargs);</span>
3966   }
3967   // loop&#39;s limit check predicate should be near the loop.
<span class="line-modified">3968   add_empty_predicate_impl(Deoptimization::Reason_loop_limit_check, nargs);</span>
3969 }
3970 
3971 void GraphKit::sync_kit(IdealKit&amp; ideal) {
3972   set_all_memory(ideal.merged_memory());
3973   set_i_o(ideal.i_o());
3974   set_control(ideal.ctrl());
3975 }
3976 
3977 void GraphKit::final_sync(IdealKit&amp; ideal) {
3978   // Final sync IdealKit and graphKit.
3979   sync_kit(ideal);
3980 }
3981 
3982 Node* GraphKit::load_String_length(Node* str, bool set_ctrl) {
3983   Node* len = load_array_length(load_String_value(str, set_ctrl));
3984   Node* coder = load_String_coder(str, set_ctrl);
3985   // Divide length by 2 if coder is UTF16
3986   return _gvn.transform(new RShiftINode(len, coder));
3987 }
3988 
</pre>
<hr />
<pre>
4072   set_memory(res_mem, TypeAryPtr::BYTES);
4073   return str;
4074 }
4075 
4076 void GraphKit::inflate_string(Node* src, Node* dst, const TypeAryPtr* dst_type, Node* count) {
4077   assert(Matcher::match_rule_supported(Op_StrInflatedCopy), &quot;Intrinsic not supported&quot;);
4078   assert(dst_type == TypeAryPtr::BYTES || dst_type == TypeAryPtr::CHARS, &quot;invalid dest type&quot;);
4079   // Capture src and dst memory (see comment in &#39;compress_string&#39;).
4080   Node* mem = capture_memory(TypeAryPtr::BYTES, dst_type);
4081   StrInflatedCopyNode* str = new StrInflatedCopyNode(control(), mem, src, dst, count);
4082   set_memory(_gvn.transform(str), dst_type);
4083 }
4084 
4085 void GraphKit::inflate_string_slow(Node* src, Node* dst, Node* start, Node* count) {
4086   /**
4087    * int i_char = start;
4088    * for (int i_byte = 0; i_byte &lt; count; i_byte++) {
4089    *   dst[i_char++] = (char)(src[i_byte] &amp; 0xff);
4090    * }
4091    */
<span class="line-modified">4092   add_empty_predicates();</span>
4093   RegionNode* head = new RegionNode(3);
4094   head-&gt;init_req(1, control());
4095   gvn().set_type(head, Type::CONTROL);
4096   record_for_igvn(head);
4097 
4098   Node* i_byte = new PhiNode(head, TypeInt::INT);
4099   i_byte-&gt;init_req(1, intcon(0));
4100   gvn().set_type(i_byte, TypeInt::INT);
4101   record_for_igvn(i_byte);
4102 
4103   Node* i_char = new PhiNode(head, TypeInt::INT);
4104   i_char-&gt;init_req(1, start);
4105   gvn().set_type(i_char, TypeInt::INT);
4106   record_for_igvn(i_char);
4107 
4108   Node* mem = PhiNode::make(head, memory(TypeAryPtr::BYTES), Type::MEMORY, TypeAryPtr::BYTES);
4109   gvn().set_type(mem, Type::MEMORY);
4110   record_for_igvn(mem);
4111   set_control(head);
4112   set_memory(mem, TypeAryPtr::BYTES);
</pre>
</td>
</tr>
</table>
<center><a href="gcm.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="graphKit.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>