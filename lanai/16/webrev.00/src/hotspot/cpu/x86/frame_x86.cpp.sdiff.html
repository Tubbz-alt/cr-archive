<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/frame_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_globals_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="gc/shenandoah/c1/shenandoahBarrierSetC1_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/frame_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 1997, 2018, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 40 #include &quot;runtime/stubRoutines.hpp&quot;
 41 #include &quot;vmreg_x86.inline.hpp&quot;
 42 #ifdef COMPILER1
 43 #include &quot;c1/c1_Runtime1.hpp&quot;
 44 #include &quot;runtime/vframeArray.hpp&quot;
 45 #endif
 46 
 47 #ifdef ASSERT
 48 void RegisterMap::check_location_valid() {
 49 }
 50 #endif
 51 
 52 // Profiling/safepoint support
 53 
 54 bool frame::safe_for_sender(JavaThread *thread) {
 55   address   sp = (address)_sp;
 56   address   fp = (address)_fp;
 57   address   unextended_sp = (address)_unextended_sp;
 58 
 59   // consider stack guards when trying to determine &quot;safe&quot; stack pointers
<span class="line-removed"> 60   static size_t stack_guard_size = os::uses_stack_guard_pages() ?</span>
<span class="line-removed"> 61     JavaThread::stack_red_zone_size() + JavaThread::stack_yellow_zone_size() : 0;</span>
<span class="line-removed"> 62   size_t usable_stack_size = thread-&gt;stack_size() - stack_guard_size;</span>
<span class="line-removed"> 63 </span>
 64   // sp must be within the usable part of the stack (not in guards)
<span class="line-modified"> 65   bool sp_safe = (sp &lt; thread-&gt;stack_base()) &amp;&amp;</span>
<span class="line-removed"> 66                  (sp &gt;= thread-&gt;stack_base() - usable_stack_size);</span>
<span class="line-removed"> 67 </span>
<span class="line-removed"> 68 </span>
<span class="line-removed"> 69   if (!sp_safe) {</span>
 70     return false;
 71   }
 72 
 73   // unextended sp must be within the stack and above or equal sp
<span class="line-modified"> 74   bool unextended_sp_safe = (unextended_sp &lt; thread-&gt;stack_base()) &amp;&amp;</span>
<span class="line-removed"> 75                             (unextended_sp &gt;= sp);</span>
<span class="line-removed"> 76 </span>
<span class="line-removed"> 77   if (!unextended_sp_safe) {</span>
 78     return false;
 79   }
 80 
 81   // an fp must be within the stack and above (but not equal) sp
 82   // second evaluation on fp+ is added to handle situation where fp is -1
<span class="line-modified"> 83   bool fp_safe = (fp &lt; thread-&gt;stack_base() &amp;&amp; (fp &gt; sp) &amp;&amp; (((fp + (return_addr_offset * sizeof(void*))) &lt; thread-&gt;stack_base())));</span>

 84 
 85   // We know sp/unextended_sp are safe only fp is questionable here
 86 
 87   // If the current frame is known to the code cache then we can attempt to
<span class="line-modified"> 88   // to construct the sender and do some validation of it. This goes a long way</span>
 89   // toward eliminating issues when we get in frame construction code
 90 
 91   if (_cb != NULL ) {
 92 
 93     // First check if frame is complete and tester is reliable
 94     // Unfortunately we can only check frame complete for runtime stubs and nmethod
 95     // other generic buffer blobs are more problematic so we just assume they are
 96     // ok. adapter blobs never have a frame complete and are never ok.
 97 
 98     if (!_cb-&gt;is_frame_complete_at(_pc)) {
 99       if (_cb-&gt;is_compiled() || _cb-&gt;is_adapter_blob() || _cb-&gt;is_runtime_stub()) {
100         return false;
101       }
102     }
103 
104     // Could just be some random pointer within the codeBlob
105     if (!_cb-&gt;code_contains(_pc)) {
106       return false;
107     }
108 
</pre>
<hr />
<pre>
125 
126       sender_pc = (address) this-&gt;fp()[return_addr_offset];
127       // for interpreted frames, the value below is the sender &quot;raw&quot; sp,
128       // which can be different from the sender unextended sp (the sp seen
129       // by the sender) because of current frame local variables
130       sender_sp = (intptr_t*) addr_at(sender_sp_offset);
131       sender_unextended_sp = (intptr_t*) this-&gt;fp()[interpreter_frame_sender_sp_offset];
132       saved_fp = (intptr_t*) this-&gt;fp()[link_offset];
133 
134     } else {
135       // must be some sort of compiled/runtime frame
136       // fp does not have to be safe (although it could be check for c1?)
137 
138       // check for a valid frame_size, otherwise we are unlikely to get a valid sender_pc
139       if (_cb-&gt;frame_size() &lt;= 0) {
140         return false;
141       }
142 
143       sender_sp = _unextended_sp + _cb-&gt;frame_size();
144       // Is sender_sp safe?
<span class="line-modified">145       if ((address)sender_sp &gt;= thread-&gt;stack_base()) {</span>
146         return false;
147       }
148       sender_unextended_sp = sender_sp;
149       // On Intel the return_address is always the word on the stack
150       sender_pc = (address) *(sender_sp-1);
151       // Note: frame::sender_sp_offset is only valid for compiled frame
152       saved_fp = (intptr_t*) *(sender_sp - frame::sender_sp_offset);
153     }
154 
155 
156     // If the potential sender is the interpreter then we can do some more checking
157     if (Interpreter::contains(sender_pc)) {
158 
159       // ebp is always saved in a recognizable place in any code we generate. However
160       // only if the sender is interpreted/call_stub (c1 too?) are we certain that the saved ebp
161       // is really a frame pointer.
162 
<span class="line-modified">163       bool saved_fp_safe = ((address)saved_fp &lt; thread-&gt;stack_base()) &amp;&amp; (saved_fp &gt; sender_sp);</span>
<span class="line-removed">164 </span>
<span class="line-removed">165       if (!saved_fp_safe) {</span>
166         return false;
167       }
168 
169       // construct the potential sender
170 
171       frame sender(sender_sp, sender_unextended_sp, saved_fp, sender_pc);
172 
173       return sender.is_interpreted_frame_valid(thread);
174 
175     }
176 
177     // We must always be able to find a recognizable pc
178     CodeBlob* sender_blob = CodeCache::find_blob_unsafe(sender_pc);
179     if (sender_pc == NULL ||  sender_blob == NULL) {
180       return false;
181     }
182 
183     // Could be a zombie method
184     if (sender_blob-&gt;is_zombie() || sender_blob-&gt;is_unloaded()) {
185       return false;
186     }
187 
188     // Could just be some random pointer within the codeBlob
189     if (!sender_blob-&gt;code_contains(sender_pc)) {
190       return false;
191     }
192 
193     // We should never be able to see an adapter if the current frame is something from code cache
194     if (sender_blob-&gt;is_adapter_blob()) {
195       return false;
196     }
197 
198     // Could be the call_stub
199     if (StubRoutines::returns_to_call_stub(sender_pc)) {
<span class="line-modified">200       bool saved_fp_safe = ((address)saved_fp &lt; thread-&gt;stack_base()) &amp;&amp; (saved_fp &gt; sender_sp);</span>
<span class="line-removed">201 </span>
<span class="line-removed">202       if (!saved_fp_safe) {</span>
203         return false;
204       }
205 
206       // construct the potential sender
207 
208       frame sender(sender_sp, sender_unextended_sp, saved_fp, sender_pc);
209 
210       // Validate the JavaCallWrapper an entry frame must have
211       address jcw = (address)sender.entry_frame_call_wrapper();
212 
<span class="line-modified">213       bool jcw_safe = (jcw &lt; thread-&gt;stack_base()) &amp;&amp; (jcw &gt; (address)sender.fp());</span>
<span class="line-removed">214 </span>
<span class="line-removed">215       return jcw_safe;</span>
216     }
217 
218     CompiledMethod* nm = sender_blob-&gt;as_compiled_method_or_null();
219     if (nm != NULL) {
220         if (nm-&gt;is_deopt_mh_entry(sender_pc) || nm-&gt;is_deopt_entry(sender_pc) ||
221             nm-&gt;method()-&gt;is_method_handle_intrinsic()) {
222             return false;
223         }
224     }
225 
226     // If the frame size is 0 something (or less) is bad because every nmethod has a non-zero frame size
227     // because the return address counts against the callee&#39;s frame.
228 
229     if (sender_blob-&gt;frame_size() &lt;= 0) {
230       assert(!sender_blob-&gt;is_compiled(), &quot;should count return address at least&quot;);
231       return false;
232     }
233 
234     // We should never be able to see anything here except an nmethod. If something in the
235     // code cache (current frame) is called by an entity within the code cache that entity
</pre>
<hr />
<pre>
535   // further because of local variables of the callee method inserted after
536   // method arguments
537   if (fp() - unextended_sp() &gt; 1024 + m-&gt;max_stack()*Interpreter::stackElementSize) {
538     return false;
539   }
540 
541   // validate bci/bcp
542 
543   address bcp = interpreter_frame_bcp();
544   if (m-&gt;validate_bci_from_bcp(bcp) &lt; 0) {
545     return false;
546   }
547 
548   // validate ConstantPoolCache*
549   ConstantPoolCache* cp = *interpreter_frame_cache_addr();
550   if (MetaspaceObj::is_valid(cp) == false) return false;
551 
552   // validate locals
553 
554   address locals =  (address) *interpreter_frame_locals_addr();
<span class="line-modified">555 </span>
<span class="line-removed">556   if (locals &gt; thread-&gt;stack_base() || locals &lt; (address) fp()) return false;</span>
<span class="line-removed">557 </span>
<span class="line-removed">558   // We&#39;d have to be pretty unlucky to be mislead at this point</span>
<span class="line-removed">559   return true;</span>
560 }
561 
562 BasicType frame::interpreter_frame_result(oop* oop_result, jvalue* value_result) {
563   assert(is_interpreted_frame(), &quot;interpreted frame expected&quot;);
564   Method* method = interpreter_frame_method();
565   BasicType type = method-&gt;result_type();
566 
567   intptr_t* tos_addr;
568   if (method-&gt;is_native()) {
569     // Prior to calling into the runtime to report the method_exit the possible
570     // return value is pushed to the native stack. If the result is a jfloat/jdouble
571     // then ST0 is saved before EAX/EDX. See the note in generate_native_result
572     tos_addr = (intptr_t*)sp();
573     if (type == T_FLOAT || type == T_DOUBLE) {
574     // QQQ seems like this code is equivalent on the two platforms
575 #ifdef AMD64
576       // This is times two because we do a push(ltos) after pushing XMM0
577       // and that takes two interpreter stack slots.
578       tos_addr += 2 * Interpreter::stackElementWords;
579 #else
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 40 #include &quot;runtime/stubRoutines.hpp&quot;
 41 #include &quot;vmreg_x86.inline.hpp&quot;
 42 #ifdef COMPILER1
 43 #include &quot;c1/c1_Runtime1.hpp&quot;
 44 #include &quot;runtime/vframeArray.hpp&quot;
 45 #endif
 46 
 47 #ifdef ASSERT
 48 void RegisterMap::check_location_valid() {
 49 }
 50 #endif
 51 
 52 // Profiling/safepoint support
 53 
 54 bool frame::safe_for_sender(JavaThread *thread) {
 55   address   sp = (address)_sp;
 56   address   fp = (address)_fp;
 57   address   unextended_sp = (address)_unextended_sp;
 58 
 59   // consider stack guards when trying to determine &quot;safe&quot; stack pointers




 60   // sp must be within the usable part of the stack (not in guards)
<span class="line-modified"> 61   if (!thread-&gt;is_in_usable_stack(sp)) {</span>




 62     return false;
 63   }
 64 
 65   // unextended sp must be within the stack and above or equal sp
<span class="line-modified"> 66   if (!thread-&gt;is_in_stack_range_incl(unextended_sp, sp)) {</span>



 67     return false;
 68   }
 69 
 70   // an fp must be within the stack and above (but not equal) sp
 71   // second evaluation on fp+ is added to handle situation where fp is -1
<span class="line-modified"> 72   bool fp_safe = thread-&gt;is_in_stack_range_excl(fp, sp) &amp;&amp;</span>
<span class="line-added"> 73                  thread-&gt;is_in_full_stack(fp + (return_addr_offset * sizeof(void*)));</span>
 74 
 75   // We know sp/unextended_sp are safe only fp is questionable here
 76 
 77   // If the current frame is known to the code cache then we can attempt to
<span class="line-modified"> 78   // construct the sender and do some validation of it. This goes a long way</span>
 79   // toward eliminating issues when we get in frame construction code
 80 
 81   if (_cb != NULL ) {
 82 
 83     // First check if frame is complete and tester is reliable
 84     // Unfortunately we can only check frame complete for runtime stubs and nmethod
 85     // other generic buffer blobs are more problematic so we just assume they are
 86     // ok. adapter blobs never have a frame complete and are never ok.
 87 
 88     if (!_cb-&gt;is_frame_complete_at(_pc)) {
 89       if (_cb-&gt;is_compiled() || _cb-&gt;is_adapter_blob() || _cb-&gt;is_runtime_stub()) {
 90         return false;
 91       }
 92     }
 93 
 94     // Could just be some random pointer within the codeBlob
 95     if (!_cb-&gt;code_contains(_pc)) {
 96       return false;
 97     }
 98 
</pre>
<hr />
<pre>
115 
116       sender_pc = (address) this-&gt;fp()[return_addr_offset];
117       // for interpreted frames, the value below is the sender &quot;raw&quot; sp,
118       // which can be different from the sender unextended sp (the sp seen
119       // by the sender) because of current frame local variables
120       sender_sp = (intptr_t*) addr_at(sender_sp_offset);
121       sender_unextended_sp = (intptr_t*) this-&gt;fp()[interpreter_frame_sender_sp_offset];
122       saved_fp = (intptr_t*) this-&gt;fp()[link_offset];
123 
124     } else {
125       // must be some sort of compiled/runtime frame
126       // fp does not have to be safe (although it could be check for c1?)
127 
128       // check for a valid frame_size, otherwise we are unlikely to get a valid sender_pc
129       if (_cb-&gt;frame_size() &lt;= 0) {
130         return false;
131       }
132 
133       sender_sp = _unextended_sp + _cb-&gt;frame_size();
134       // Is sender_sp safe?
<span class="line-modified">135       if (!thread-&gt;is_in_full_stack((address)sender_sp)) {</span>
136         return false;
137       }
138       sender_unextended_sp = sender_sp;
139       // On Intel the return_address is always the word on the stack
140       sender_pc = (address) *(sender_sp-1);
141       // Note: frame::sender_sp_offset is only valid for compiled frame
142       saved_fp = (intptr_t*) *(sender_sp - frame::sender_sp_offset);
143     }
144 
145 
146     // If the potential sender is the interpreter then we can do some more checking
147     if (Interpreter::contains(sender_pc)) {
148 
149       // ebp is always saved in a recognizable place in any code we generate. However
150       // only if the sender is interpreted/call_stub (c1 too?) are we certain that the saved ebp
151       // is really a frame pointer.
152 
<span class="line-modified">153       if (!thread-&gt;is_in_stack_range_excl((address)saved_fp, (address)sender_sp)) {</span>


154         return false;
155       }
156 
157       // construct the potential sender
158 
159       frame sender(sender_sp, sender_unextended_sp, saved_fp, sender_pc);
160 
161       return sender.is_interpreted_frame_valid(thread);
162 
163     }
164 
165     // We must always be able to find a recognizable pc
166     CodeBlob* sender_blob = CodeCache::find_blob_unsafe(sender_pc);
167     if (sender_pc == NULL ||  sender_blob == NULL) {
168       return false;
169     }
170 
171     // Could be a zombie method
172     if (sender_blob-&gt;is_zombie() || sender_blob-&gt;is_unloaded()) {
173       return false;
174     }
175 
176     // Could just be some random pointer within the codeBlob
177     if (!sender_blob-&gt;code_contains(sender_pc)) {
178       return false;
179     }
180 
181     // We should never be able to see an adapter if the current frame is something from code cache
182     if (sender_blob-&gt;is_adapter_blob()) {
183       return false;
184     }
185 
186     // Could be the call_stub
187     if (StubRoutines::returns_to_call_stub(sender_pc)) {
<span class="line-modified">188       if (!thread-&gt;is_in_stack_range_excl((address)saved_fp, (address)sender_sp)) {</span>


189         return false;
190       }
191 
192       // construct the potential sender
193 
194       frame sender(sender_sp, sender_unextended_sp, saved_fp, sender_pc);
195 
196       // Validate the JavaCallWrapper an entry frame must have
197       address jcw = (address)sender.entry_frame_call_wrapper();
198 
<span class="line-modified">199       return thread-&gt;is_in_stack_range_excl(jcw, (address)sender.fp());</span>


200     }
201 
202     CompiledMethod* nm = sender_blob-&gt;as_compiled_method_or_null();
203     if (nm != NULL) {
204         if (nm-&gt;is_deopt_mh_entry(sender_pc) || nm-&gt;is_deopt_entry(sender_pc) ||
205             nm-&gt;method()-&gt;is_method_handle_intrinsic()) {
206             return false;
207         }
208     }
209 
210     // If the frame size is 0 something (or less) is bad because every nmethod has a non-zero frame size
211     // because the return address counts against the callee&#39;s frame.
212 
213     if (sender_blob-&gt;frame_size() &lt;= 0) {
214       assert(!sender_blob-&gt;is_compiled(), &quot;should count return address at least&quot;);
215       return false;
216     }
217 
218     // We should never be able to see anything here except an nmethod. If something in the
219     // code cache (current frame) is called by an entity within the code cache that entity
</pre>
<hr />
<pre>
519   // further because of local variables of the callee method inserted after
520   // method arguments
521   if (fp() - unextended_sp() &gt; 1024 + m-&gt;max_stack()*Interpreter::stackElementSize) {
522     return false;
523   }
524 
525   // validate bci/bcp
526 
527   address bcp = interpreter_frame_bcp();
528   if (m-&gt;validate_bci_from_bcp(bcp) &lt; 0) {
529     return false;
530   }
531 
532   // validate ConstantPoolCache*
533   ConstantPoolCache* cp = *interpreter_frame_cache_addr();
534   if (MetaspaceObj::is_valid(cp) == false) return false;
535 
536   // validate locals
537 
538   address locals =  (address) *interpreter_frame_locals_addr();
<span class="line-modified">539   return thread-&gt;is_in_stack_range_incl(locals, (address)fp());</span>




540 }
541 
542 BasicType frame::interpreter_frame_result(oop* oop_result, jvalue* value_result) {
543   assert(is_interpreted_frame(), &quot;interpreted frame expected&quot;);
544   Method* method = interpreter_frame_method();
545   BasicType type = method-&gt;result_type();
546 
547   intptr_t* tos_addr;
548   if (method-&gt;is_native()) {
549     // Prior to calling into the runtime to report the method_exit the possible
550     // return value is pushed to the native stack. If the result is a jfloat/jdouble
551     // then ST0 is saved before EAX/EDX. See the note in generate_native_result
552     tos_addr = (intptr_t*)sp();
553     if (type == T_FLOAT || type == T_DOUBLE) {
554     // QQQ seems like this code is equivalent on the two platforms
555 #ifdef AMD64
556       // This is times two because we do a push(ltos) after pushing XMM0
557       // and that takes two interpreter stack slots.
558       tos_addr += 2 * Interpreter::stackElementWords;
559 #else
</pre>
</td>
</tr>
</table>
<center><a href="c1_globals_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="gc/shenandoah/c1/shenandoahBarrierSetC1_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>