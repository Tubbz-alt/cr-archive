<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/sparc/sparc.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroAssembler_sparc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="templateTable_sparc.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/sparc/sparc.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  985     __ mov(G1, G5);
  986     __ stx(G1, SP, STACK_BIAS + 0x80);
  987     __ stx(G1, SP, STACK_BIAS + 0x88);
  988     __ stx(G1, SP, STACK_BIAS + 0x90);
  989     __ stx(G1, SP, STACK_BIAS + 0x98);
  990     __ stx(G1, SP, STACK_BIAS + 0xA0);
  991     __ stx(G1, SP, STACK_BIAS + 0xA8);
  992   }
  993 #endif /*ASSERT*/
  994 }
  995 
  996 //=============================================================================
  997 // REQUIRED FUNCTIONALITY for encoding
  998 void emit_lo(CodeBuffer &amp;cbuf, int val) {  }
  999 void emit_hi(CodeBuffer &amp;cbuf, int val) {  }
 1000 
 1001 
 1002 //=============================================================================
 1003 const RegMask&amp; MachConstantBaseNode::_out_RegMask = PTR_REG_mask();
 1004 
<span class="line-modified"> 1005 int Compile::ConstantTable::calculate_table_base_offset() const {</span>
 1006   if (UseRDPCForConstantTableBase) {
 1007     // The table base offset might be less but then it fits into
 1008     // simm13 anyway and we are good (cf. MachConstantBaseNode::emit).
 1009     return Assembler::min_simm13();
 1010   } else {
 1011     int offset = -(size() / 2);
 1012     if (!Assembler::is_simm13(offset)) {
 1013       offset = Assembler::min_simm13();
 1014     }
 1015     return offset;
 1016   }
 1017 }
 1018 
 1019 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1020 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1021   ShouldNotReachHere();
 1022 }
 1023 
 1024 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1025   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1026   Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();</span>
 1027   MacroAssembler _masm(&amp;cbuf);
 1028 
 1029   Register r = as_Register(ra_-&gt;get_encode(this));
 1030   CodeSection* consts_section = __ code()-&gt;consts();
 1031   int consts_size = consts_section-&gt;align_at_start(consts_section-&gt;size());
 1032   assert(constant_table.size() == consts_size, &quot;must be: %d == %d&quot;, constant_table.size(), consts_size);
 1033 
 1034   if (UseRDPCForConstantTableBase) {
 1035     // For the following RDPC logic to work correctly the consts
 1036     // section must be allocated right before the insts section.  This
 1037     // assert checks for that.  The layout and the SECT_* constants
 1038     // are defined in src/share/vm/asm/codeBuffer.hpp.
 1039     assert(CodeBuffer::SECT_CONSTS + 1 == CodeBuffer::SECT_INSTS, &quot;must be&quot;);
 1040     int insts_offset = __ offset();
 1041 
 1042     // Layout:
 1043     //
 1044     // |----------- consts section ------------|----------- insts section -----------...
 1045     // |------ constant table -----|- padding -|------------------x----
 1046     //                                                            \ current PC (RDPC instruction)
</pre>
<hr />
<pre>
 1111     st-&gt;print(&quot;SET    &amp;constanttable,%s\t! constant table base&quot;, reg);
 1112   }
 1113 }
 1114 #endif
 1115 
 1116 
 1117 //=============================================================================
 1118 
 1119 #ifndef PRODUCT
 1120 void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
 1121   Compile* C = ra_-&gt;C;
 1122 
 1123   for (int i = 0; i &lt; OptoPrologueNops; i++) {
 1124     st-&gt;print_cr(&quot;NOP&quot;); st-&gt;print(&quot;\t&quot;);
 1125   }
 1126 
 1127   if( VerifyThread ) {
 1128     st-&gt;print_cr(&quot;Verify_Thread&quot;); st-&gt;print(&quot;\t&quot;);
 1129   }
 1130 
<span class="line-modified"> 1131   size_t framesize = C-&gt;frame_size_in_bytes();</span>
<span class="line-modified"> 1132   int bangsize = C-&gt;bang_size_in_bytes();</span>
 1133 
 1134   // Calls to C2R adapters often do not accept exceptional returns.
 1135   // We require that their callers must bang for them.  But be careful, because
 1136   // some VM calls (such as call site linkage) can use several kilobytes of
 1137   // stack.  But the stack safety zone should account for that.
 1138   // See bugs 4446381, 4468289, 4497237.
<span class="line-modified"> 1139   if (C-&gt;need_stack_bang(bangsize)) {</span>
 1140     st-&gt;print_cr(&quot;! stack bang (%d bytes)&quot;, bangsize); st-&gt;print(&quot;\t&quot;);
 1141   }
 1142 
 1143   if (Assembler::is_simm13(-framesize)) {
 1144     st-&gt;print   (&quot;SAVE   R_SP,-&quot; SIZE_FORMAT &quot;,R_SP&quot;,framesize);
 1145   } else {
 1146     st-&gt;print_cr(&quot;SETHI  R_SP,hi%%(-&quot; SIZE_FORMAT &quot;),R_G3&quot;,framesize); st-&gt;print(&quot;\t&quot;);
 1147     st-&gt;print_cr(&quot;ADD    R_G3,lo%%(-&quot; SIZE_FORMAT &quot;),R_G3&quot;,framesize); st-&gt;print(&quot;\t&quot;);
 1148     st-&gt;print   (&quot;SAVE   R_SP,R_G3,R_SP&quot;);
 1149   }
 1150 
 1151 }
 1152 #endif
 1153 
 1154 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1155   Compile* C = ra_-&gt;C;
 1156   MacroAssembler _masm(&amp;cbuf);
 1157 
 1158   for (int i = 0; i &lt; OptoPrologueNops; i++) {
 1159     __ nop();
 1160   }
 1161 
 1162   __ verify_thread();
 1163 
<span class="line-modified"> 1164   size_t framesize = C-&gt;frame_size_in_bytes();</span>
 1165   assert(framesize &gt;= 16*wordSize, &quot;must have room for reg. save area&quot;);
 1166   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
<span class="line-modified"> 1167   int bangsize = C-&gt;bang_size_in_bytes();</span>
 1168 
 1169   // Calls to C2R adapters often do not accept exceptional returns.
 1170   // We require that their callers must bang for them.  But be careful, because
 1171   // some VM calls (such as call site linkage) can use several kilobytes of
 1172   // stack.  But the stack safety zone should account for that.
 1173   // See bugs 4446381, 4468289, 4497237.
<span class="line-modified"> 1174   if (C-&gt;need_stack_bang(bangsize)) {</span>
 1175     __ generate_stack_overflow_check(bangsize);
 1176   }
 1177 
 1178   if (Assembler::is_simm13(-framesize)) {
 1179     __ save(SP, -framesize, SP);
 1180   } else {
 1181     __ sethi(-framesize &amp; ~0x3ff, G3);
 1182     __ add(G3, -framesize &amp; 0x3ff, G3);
 1183     __ save(SP, G3, SP);
 1184   }
<span class="line-modified"> 1185   C-&gt;set_frame_complete( __ offset() );</span>
 1186 
 1187   if (!UseRDPCForConstantTableBase &amp;&amp; C-&gt;has_mach_constant_base_node()) {
 1188     // NOTE: We set the table base offset here because users might be
 1189     // emitted before MachConstantBaseNode.
<span class="line-modified"> 1190     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();</span>
 1191     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1192   }
 1193 }
 1194 
 1195 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
 1196   return MachNode::size(ra_);
 1197 }
 1198 
 1199 int MachPrologNode::reloc() const {
 1200   return 10; // a large enough number
 1201 }
 1202 
 1203 //=============================================================================
 1204 #ifndef PRODUCT
 1205 void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
 1206   Compile* C = ra_-&gt;C;
 1207 
 1208   if(do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
 1209     if (SafepointMechanism::uses_global_page_poll()) {
 1210       st-&gt;print(&quot;SETHI  #PollAddr,L0\t! Load Polling address\n\t&quot;);
</pre>
<hr />
<pre>
 1553   st-&gt;print(&quot;LEA    [R_SP+#%d+BIAS],%s&quot;,offset,Matcher::regName[reg]);
 1554 }
 1555 #endif
 1556 
 1557 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1558   MacroAssembler _masm(&amp;cbuf);
 1559   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem()) + STACK_BIAS;
 1560   int reg = ra_-&gt;get_encode(this);
 1561 
 1562   if (Assembler::is_simm13(offset)) {
 1563      __ add(SP, offset, reg_to_register_object(reg));
 1564   } else {
 1565      __ set(offset, O7);
 1566      __ add(SP, O7, reg_to_register_object(reg));
 1567   }
 1568 }
 1569 
 1570 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1571   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
 1572   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
<span class="line-modified"> 1573   return ra_-&gt;C-&gt;scratch_emit_size(this);</span>
 1574 }
 1575 
 1576 //=============================================================================
 1577 #ifndef PRODUCT
 1578 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
 1579   st-&gt;print_cr(&quot;\nUEP:&quot;);
 1580   if (UseCompressedClassPointers) {
 1581     assert(Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
 1582     st-&gt;print_cr(&quot;\tLDUW   [R_O0 + oopDesc::klass_offset_in_bytes],R_G5\t! Inline cache check - compressed klass&quot;);
 1583     if (CompressedKlassPointers::base() != 0) {
 1584       st-&gt;print_cr(&quot;\tSET    CompressedKlassPointers::base,R_G6_heap_base&quot;);
 1585       if (CompressedKlassPointers::shift() != 0) {
 1586         st-&gt;print_cr(&quot;\tSLL    R_G5,CompressedKlassPointers::shift,R_G5&quot;);
 1587       }
 1588       st-&gt;print_cr(&quot;\tADD    R_G5,R_G6_heap_base,R_G5&quot;);
 1589       st-&gt;print_cr(&quot;\tSET    CompressedOops::ptrs_base,R_G6_heap_base&quot;);
 1590     } else {
 1591       st-&gt;print_cr(&quot;\tSLL    R_G5,CompressedKlassPointers::shift,R_G5&quot;);
 1592     }
 1593   } else {
</pre>
<hr />
<pre>
 1856   // return CompressedKlassPointers::base() == NULL;
 1857   return true;
 1858 }
 1859 
 1860 // Is it better to copy float constants, or load them directly from memory?
 1861 // Intel can load a float constant from a direct address, requiring no
 1862 // extra registers.  Most RISCs will have to materialize an address into a
 1863 // register first, so they would do better to copy the constant from stack.
 1864 const bool Matcher::rematerialize_float_constants = false;
 1865 
 1866 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1867 // needed.  Else we split the double into 2 integer pieces and move it
 1868 // piece-by-piece.  Only happens when passing doubles into C code as the
 1869 // Java calling convention forces doubles to be aligned.
 1870 const bool Matcher::misaligned_doubles_ok = true;
 1871 
 1872 // No-op on SPARC.
 1873 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1874 }
 1875 
<span class="line-modified"> 1876 // Advertise here if the CPU requires explicit rounding operations</span>
<span class="line-removed"> 1877 // to implement the UseStrictFP mode.</span>
 1878 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1879 
 1880 // Are floats converted to double when stored to stack during deoptimization?
 1881 // Sparc does not handle callee-save floats.
 1882 bool Matcher::float_in_double() { return false; }
 1883 
 1884 // Do ints take an entire long register or just half?
 1885 // Note that we if-def off of _LP64.
 1886 // The relevant question is how the int is callee-saved.  In _LP64
 1887 // the whole long is written but de-opt&#39;ing will have to extract
 1888 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1889 const bool Matcher::int_in_long = true;
 1890 
 1891 // Return whether or not this register is ever used as an argument.  This
 1892 // function is used on startup to build the trampoline stubs in generateOptoStub.
 1893 // Registers not mentioned will be killed by the VM call in the trampoline, and
 1894 // arguments in those registers not be available to the callee.
 1895 bool Matcher::can_be_java_arg( int reg ) {
 1896   // Standard sparc 6 args in registers
 1897   if( reg == R_I0_num ||
</pre>
<hr />
<pre>
 2410              ($src$$reg &lt;&lt; 0);
 2411     cbuf.insts()-&gt;emit_int32(op);
 2412   %}
 2413 
 2414   enc_class Set13( immI13 src, iRegI rd ) %{
 2415     emit3_simm13( cbuf, Assembler::arith_op, $rd$$reg, Assembler::or_op3, 0, $src$$constant );
 2416   %}
 2417 
 2418   enc_class SetHi22( immI src, iRegI rd ) %{
 2419     emit2_22( cbuf, Assembler::branch_op, $rd$$reg, Assembler::sethi_op2, $src$$constant );
 2420   %}
 2421 
 2422   enc_class Set32( immI src, iRegI rd ) %{
 2423     MacroAssembler _masm(&amp;cbuf);
 2424     __ set($src$$constant, reg_to_register_object($rd$$reg));
 2425   %}
 2426 
 2427   enc_class call_epilog %{
 2428     if( VerifyStackAtCalls ) {
 2429       MacroAssembler _masm(&amp;cbuf);
<span class="line-modified"> 2430       int framesize = ra_-&gt;C-&gt;frame_size_in_bytes();</span>
 2431       Register temp_reg = G3;
 2432       __ add(SP, framesize, temp_reg);
 2433       __ cmp(temp_reg, FP);
 2434       __ breakpoint_trap(Assembler::notEqual, Assembler::ptr_cc);
 2435     }
 2436   %}
 2437 
 2438   // Long values come back from native calls in O0:O1 in the 32-bit VM, copy the value
 2439   // to G1 so the register allocator will not have to deal with the misaligned register
 2440   // pair.
 2441   enc_class adjust_long_from_native_call %{
 2442   %}
 2443 
 2444   enc_class Java_To_Runtime (method meth) %{    // CALL Java_To_Runtime
 2445     // CALL directly to the runtime
 2446     // The user of this is responsible for ensuring that R_L7 is empty (killed).
 2447     emit_call_reloc(cbuf, $meth$$method, runtime_call_Relocation::spec(), /*preserve_g2=*/true);
 2448   %}
 2449 
 2450   enc_class preserve_SP %{
</pre>
<hr />
<pre>
 8838 //----------Branches---------------------------------------------------------
 8839 // Jump
 8840 // (compare &#39;operand indIndex&#39; and &#39;instruct addP_reg_reg&#39; above)
 8841 instruct jumpXtnd(iRegX switch_val, o7RegI table) %{
 8842   match(Jump switch_val);
 8843   effect(TEMP table);
 8844 
 8845   ins_cost(350);
 8846 
 8847   format %{  &quot;ADD    $constanttablebase, $constantoffset, O7\n\t&quot;
 8848              &quot;LD     [O7 + $switch_val], O7\n\t&quot;
 8849              &quot;JUMP   O7&quot; %}
 8850   ins_encode %{
 8851     // Calculate table address into a register.
 8852     Register table_reg;
 8853     Register label_reg = O7;
 8854     // If we are calculating the size of this instruction don&#39;t trust
 8855     // zero offsets because they might change when
 8856     // MachConstantBaseNode decides to optimize the constant table
 8857     // base.
<span class="line-modified"> 8858     if ((constant_offset() == 0) &amp;&amp; !Compile::current()-&gt;in_scratch_emit_size()) {</span>
 8859       table_reg = $constanttablebase;
 8860     } else {
 8861       table_reg = O7;
 8862       RegisterOrConstant con_offset = __ ensure_simm13_or_reg($constantoffset, O7);
 8863       __ add($constanttablebase, con_offset, table_reg);
 8864     }
 8865 
 8866     // Jump to base address + switch value
 8867     __ ld_ptr(table_reg, $switch_val$$Register, label_reg);
 8868     __ jmp(label_reg, G0);
 8869     __ delayed()-&gt;nop();
 8870   %}
 8871   ins_pipe(ialu_reg_reg);
 8872 %}
 8873 
 8874 // Direct Branch.  Use V8 version with longer range.
 8875 instruct branch(label labl) %{
 8876   match(Goto);
 8877   effect(USE labl);
 8878 
</pre>
</td>
<td>
<hr />
<pre>
  985     __ mov(G1, G5);
  986     __ stx(G1, SP, STACK_BIAS + 0x80);
  987     __ stx(G1, SP, STACK_BIAS + 0x88);
  988     __ stx(G1, SP, STACK_BIAS + 0x90);
  989     __ stx(G1, SP, STACK_BIAS + 0x98);
  990     __ stx(G1, SP, STACK_BIAS + 0xA0);
  991     __ stx(G1, SP, STACK_BIAS + 0xA8);
  992   }
  993 #endif /*ASSERT*/
  994 }
  995 
  996 //=============================================================================
  997 // REQUIRED FUNCTIONALITY for encoding
  998 void emit_lo(CodeBuffer &amp;cbuf, int val) {  }
  999 void emit_hi(CodeBuffer &amp;cbuf, int val) {  }
 1000 
 1001 
 1002 //=============================================================================
 1003 const RegMask&amp; MachConstantBaseNode::_out_RegMask = PTR_REG_mask();
 1004 
<span class="line-modified"> 1005 int ConstantTable::calculate_table_base_offset() const {</span>
 1006   if (UseRDPCForConstantTableBase) {
 1007     // The table base offset might be less but then it fits into
 1008     // simm13 anyway and we are good (cf. MachConstantBaseNode::emit).
 1009     return Assembler::min_simm13();
 1010   } else {
 1011     int offset = -(size() / 2);
 1012     if (!Assembler::is_simm13(offset)) {
 1013       offset = Assembler::min_simm13();
 1014     }
 1015     return offset;
 1016   }
 1017 }
 1018 
 1019 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1020 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1021   ShouldNotReachHere();
 1022 }
 1023 
 1024 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1025   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1026   ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();</span>
 1027   MacroAssembler _masm(&amp;cbuf);
 1028 
 1029   Register r = as_Register(ra_-&gt;get_encode(this));
 1030   CodeSection* consts_section = __ code()-&gt;consts();
 1031   int consts_size = consts_section-&gt;align_at_start(consts_section-&gt;size());
 1032   assert(constant_table.size() == consts_size, &quot;must be: %d == %d&quot;, constant_table.size(), consts_size);
 1033 
 1034   if (UseRDPCForConstantTableBase) {
 1035     // For the following RDPC logic to work correctly the consts
 1036     // section must be allocated right before the insts section.  This
 1037     // assert checks for that.  The layout and the SECT_* constants
 1038     // are defined in src/share/vm/asm/codeBuffer.hpp.
 1039     assert(CodeBuffer::SECT_CONSTS + 1 == CodeBuffer::SECT_INSTS, &quot;must be&quot;);
 1040     int insts_offset = __ offset();
 1041 
 1042     // Layout:
 1043     //
 1044     // |----------- consts section ------------|----------- insts section -----------...
 1045     // |------ constant table -----|- padding -|------------------x----
 1046     //                                                            \ current PC (RDPC instruction)
</pre>
<hr />
<pre>
 1111     st-&gt;print(&quot;SET    &amp;constanttable,%s\t! constant table base&quot;, reg);
 1112   }
 1113 }
 1114 #endif
 1115 
 1116 
 1117 //=============================================================================
 1118 
 1119 #ifndef PRODUCT
 1120 void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
 1121   Compile* C = ra_-&gt;C;
 1122 
 1123   for (int i = 0; i &lt; OptoPrologueNops; i++) {
 1124     st-&gt;print_cr(&quot;NOP&quot;); st-&gt;print(&quot;\t&quot;);
 1125   }
 1126 
 1127   if( VerifyThread ) {
 1128     st-&gt;print_cr(&quot;Verify_Thread&quot;); st-&gt;print(&quot;\t&quot;);
 1129   }
 1130 
<span class="line-modified"> 1131   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
<span class="line-modified"> 1132   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
 1133 
 1134   // Calls to C2R adapters often do not accept exceptional returns.
 1135   // We require that their callers must bang for them.  But be careful, because
 1136   // some VM calls (such as call site linkage) can use several kilobytes of
 1137   // stack.  But the stack safety zone should account for that.
 1138   // See bugs 4446381, 4468289, 4497237.
<span class="line-modified"> 1139   if (C-&gt;output()-&gt;need_stack_bang(bangsize)) {</span>
 1140     st-&gt;print_cr(&quot;! stack bang (%d bytes)&quot;, bangsize); st-&gt;print(&quot;\t&quot;);
 1141   }
 1142 
 1143   if (Assembler::is_simm13(-framesize)) {
 1144     st-&gt;print   (&quot;SAVE   R_SP,-&quot; SIZE_FORMAT &quot;,R_SP&quot;,framesize);
 1145   } else {
 1146     st-&gt;print_cr(&quot;SETHI  R_SP,hi%%(-&quot; SIZE_FORMAT &quot;),R_G3&quot;,framesize); st-&gt;print(&quot;\t&quot;);
 1147     st-&gt;print_cr(&quot;ADD    R_G3,lo%%(-&quot; SIZE_FORMAT &quot;),R_G3&quot;,framesize); st-&gt;print(&quot;\t&quot;);
 1148     st-&gt;print   (&quot;SAVE   R_SP,R_G3,R_SP&quot;);
 1149   }
 1150 
 1151 }
 1152 #endif
 1153 
 1154 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1155   Compile* C = ra_-&gt;C;
 1156   MacroAssembler _masm(&amp;cbuf);
 1157 
 1158   for (int i = 0; i &lt; OptoPrologueNops; i++) {
 1159     __ nop();
 1160   }
 1161 
 1162   __ verify_thread();
 1163 
<span class="line-modified"> 1164   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
 1165   assert(framesize &gt;= 16*wordSize, &quot;must have room for reg. save area&quot;);
 1166   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
<span class="line-modified"> 1167   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
 1168 
 1169   // Calls to C2R adapters often do not accept exceptional returns.
 1170   // We require that their callers must bang for them.  But be careful, because
 1171   // some VM calls (such as call site linkage) can use several kilobytes of
 1172   // stack.  But the stack safety zone should account for that.
 1173   // See bugs 4446381, 4468289, 4497237.
<span class="line-modified"> 1174   if (C-&gt;output()-&gt;need_stack_bang(bangsize)) {</span>
 1175     __ generate_stack_overflow_check(bangsize);
 1176   }
 1177 
 1178   if (Assembler::is_simm13(-framesize)) {
 1179     __ save(SP, -framesize, SP);
 1180   } else {
 1181     __ sethi(-framesize &amp; ~0x3ff, G3);
 1182     __ add(G3, -framesize &amp; 0x3ff, G3);
 1183     __ save(SP, G3, SP);
 1184   }
<span class="line-modified"> 1185   C-&gt;output()-&gt;set_frame_complete( __ offset() );</span>
 1186 
 1187   if (!UseRDPCForConstantTableBase &amp;&amp; C-&gt;has_mach_constant_base_node()) {
 1188     // NOTE: We set the table base offset here because users might be
 1189     // emitted before MachConstantBaseNode.
<span class="line-modified"> 1190     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();</span>
 1191     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1192   }
 1193 }
 1194 
 1195 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
 1196   return MachNode::size(ra_);
 1197 }
 1198 
 1199 int MachPrologNode::reloc() const {
 1200   return 10; // a large enough number
 1201 }
 1202 
 1203 //=============================================================================
 1204 #ifndef PRODUCT
 1205 void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
 1206   Compile* C = ra_-&gt;C;
 1207 
 1208   if(do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
 1209     if (SafepointMechanism::uses_global_page_poll()) {
 1210       st-&gt;print(&quot;SETHI  #PollAddr,L0\t! Load Polling address\n\t&quot;);
</pre>
<hr />
<pre>
 1553   st-&gt;print(&quot;LEA    [R_SP+#%d+BIAS],%s&quot;,offset,Matcher::regName[reg]);
 1554 }
 1555 #endif
 1556 
 1557 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1558   MacroAssembler _masm(&amp;cbuf);
 1559   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem()) + STACK_BIAS;
 1560   int reg = ra_-&gt;get_encode(this);
 1561 
 1562   if (Assembler::is_simm13(offset)) {
 1563      __ add(SP, offset, reg_to_register_object(reg));
 1564   } else {
 1565      __ set(offset, O7);
 1566      __ add(SP, O7, reg_to_register_object(reg));
 1567   }
 1568 }
 1569 
 1570 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1571   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
 1572   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
<span class="line-modified"> 1573   return ra_-&gt;C-&gt;output()-&gt;scratch_emit_size(this);</span>
 1574 }
 1575 
 1576 //=============================================================================
 1577 #ifndef PRODUCT
 1578 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
 1579   st-&gt;print_cr(&quot;\nUEP:&quot;);
 1580   if (UseCompressedClassPointers) {
 1581     assert(Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
 1582     st-&gt;print_cr(&quot;\tLDUW   [R_O0 + oopDesc::klass_offset_in_bytes],R_G5\t! Inline cache check - compressed klass&quot;);
 1583     if (CompressedKlassPointers::base() != 0) {
 1584       st-&gt;print_cr(&quot;\tSET    CompressedKlassPointers::base,R_G6_heap_base&quot;);
 1585       if (CompressedKlassPointers::shift() != 0) {
 1586         st-&gt;print_cr(&quot;\tSLL    R_G5,CompressedKlassPointers::shift,R_G5&quot;);
 1587       }
 1588       st-&gt;print_cr(&quot;\tADD    R_G5,R_G6_heap_base,R_G5&quot;);
 1589       st-&gt;print_cr(&quot;\tSET    CompressedOops::ptrs_base,R_G6_heap_base&quot;);
 1590     } else {
 1591       st-&gt;print_cr(&quot;\tSLL    R_G5,CompressedKlassPointers::shift,R_G5&quot;);
 1592     }
 1593   } else {
</pre>
<hr />
<pre>
 1856   // return CompressedKlassPointers::base() == NULL;
 1857   return true;
 1858 }
 1859 
 1860 // Is it better to copy float constants, or load them directly from memory?
 1861 // Intel can load a float constant from a direct address, requiring no
 1862 // extra registers.  Most RISCs will have to materialize an address into a
 1863 // register first, so they would do better to copy the constant from stack.
 1864 const bool Matcher::rematerialize_float_constants = false;
 1865 
 1866 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1867 // needed.  Else we split the double into 2 integer pieces and move it
 1868 // piece-by-piece.  Only happens when passing doubles into C code as the
 1869 // Java calling convention forces doubles to be aligned.
 1870 const bool Matcher::misaligned_doubles_ok = true;
 1871 
 1872 // No-op on SPARC.
 1873 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1874 }
 1875 
<span class="line-modified"> 1876 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.</span>

 1877 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1878 
 1879 // Are floats converted to double when stored to stack during deoptimization?
 1880 // Sparc does not handle callee-save floats.
 1881 bool Matcher::float_in_double() { return false; }
 1882 
 1883 // Do ints take an entire long register or just half?
 1884 // Note that we if-def off of _LP64.
 1885 // The relevant question is how the int is callee-saved.  In _LP64
 1886 // the whole long is written but de-opt&#39;ing will have to extract
 1887 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1888 const bool Matcher::int_in_long = true;
 1889 
 1890 // Return whether or not this register is ever used as an argument.  This
 1891 // function is used on startup to build the trampoline stubs in generateOptoStub.
 1892 // Registers not mentioned will be killed by the VM call in the trampoline, and
 1893 // arguments in those registers not be available to the callee.
 1894 bool Matcher::can_be_java_arg( int reg ) {
 1895   // Standard sparc 6 args in registers
 1896   if( reg == R_I0_num ||
</pre>
<hr />
<pre>
 2409              ($src$$reg &lt;&lt; 0);
 2410     cbuf.insts()-&gt;emit_int32(op);
 2411   %}
 2412 
 2413   enc_class Set13( immI13 src, iRegI rd ) %{
 2414     emit3_simm13( cbuf, Assembler::arith_op, $rd$$reg, Assembler::or_op3, 0, $src$$constant );
 2415   %}
 2416 
 2417   enc_class SetHi22( immI src, iRegI rd ) %{
 2418     emit2_22( cbuf, Assembler::branch_op, $rd$$reg, Assembler::sethi_op2, $src$$constant );
 2419   %}
 2420 
 2421   enc_class Set32( immI src, iRegI rd ) %{
 2422     MacroAssembler _masm(&amp;cbuf);
 2423     __ set($src$$constant, reg_to_register_object($rd$$reg));
 2424   %}
 2425 
 2426   enc_class call_epilog %{
 2427     if( VerifyStackAtCalls ) {
 2428       MacroAssembler _masm(&amp;cbuf);
<span class="line-modified"> 2429       int framesize = ra_-&gt;C-&gt;output()-&gt;frame_size_in_bytes();</span>
 2430       Register temp_reg = G3;
 2431       __ add(SP, framesize, temp_reg);
 2432       __ cmp(temp_reg, FP);
 2433       __ breakpoint_trap(Assembler::notEqual, Assembler::ptr_cc);
 2434     }
 2435   %}
 2436 
 2437   // Long values come back from native calls in O0:O1 in the 32-bit VM, copy the value
 2438   // to G1 so the register allocator will not have to deal with the misaligned register
 2439   // pair.
 2440   enc_class adjust_long_from_native_call %{
 2441   %}
 2442 
 2443   enc_class Java_To_Runtime (method meth) %{    // CALL Java_To_Runtime
 2444     // CALL directly to the runtime
 2445     // The user of this is responsible for ensuring that R_L7 is empty (killed).
 2446     emit_call_reloc(cbuf, $meth$$method, runtime_call_Relocation::spec(), /*preserve_g2=*/true);
 2447   %}
 2448 
 2449   enc_class preserve_SP %{
</pre>
<hr />
<pre>
 8837 //----------Branches---------------------------------------------------------
 8838 // Jump
 8839 // (compare &#39;operand indIndex&#39; and &#39;instruct addP_reg_reg&#39; above)
 8840 instruct jumpXtnd(iRegX switch_val, o7RegI table) %{
 8841   match(Jump switch_val);
 8842   effect(TEMP table);
 8843 
 8844   ins_cost(350);
 8845 
 8846   format %{  &quot;ADD    $constanttablebase, $constantoffset, O7\n\t&quot;
 8847              &quot;LD     [O7 + $switch_val], O7\n\t&quot;
 8848              &quot;JUMP   O7&quot; %}
 8849   ins_encode %{
 8850     // Calculate table address into a register.
 8851     Register table_reg;
 8852     Register label_reg = O7;
 8853     // If we are calculating the size of this instruction don&#39;t trust
 8854     // zero offsets because they might change when
 8855     // MachConstantBaseNode decides to optimize the constant table
 8856     // base.
<span class="line-modified"> 8857     if ((constant_offset() == 0) &amp;&amp; !Compile::current()-&gt;output()-&gt;in_scratch_emit_size()) {</span>
 8858       table_reg = $constanttablebase;
 8859     } else {
 8860       table_reg = O7;
 8861       RegisterOrConstant con_offset = __ ensure_simm13_or_reg($constantoffset, O7);
 8862       __ add($constanttablebase, con_offset, table_reg);
 8863     }
 8864 
 8865     // Jump to base address + switch value
 8866     __ ld_ptr(table_reg, $switch_val$$Register, label_reg);
 8867     __ jmp(label_reg, G0);
 8868     __ delayed()-&gt;nop();
 8869   %}
 8870   ins_pipe(ialu_reg_reg);
 8871 %}
 8872 
 8873 // Direct Branch.  Use V8 version with longer range.
 8874 instruct branch(label labl) %{
 8875   match(Goto);
 8876   effect(USE labl);
 8877 
</pre>
</td>
</tr>
</table>
<center><a href="macroAssembler_sparc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="templateTable_sparc.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>