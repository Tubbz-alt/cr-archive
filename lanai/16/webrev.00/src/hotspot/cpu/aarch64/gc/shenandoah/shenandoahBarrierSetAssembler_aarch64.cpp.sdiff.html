<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/gc/shenandoah/shenandoahBarrierSetAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
<body>
<center><a href="c1/shenandoahBarrierSetC1_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../index.html" target="_top">index</a> <a href="shenandoahBarrierSetAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/gc/shenandoah/shenandoahBarrierSetAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
564   __ mov(tmp2, ShenandoahHeap::in_cset_fast_test_addr());
565   __ lsr(tmp1, res, ShenandoahHeapRegion::region_size_bytes_shift_jint());
566   __ ldrb(tmp2, Address(tmp2, tmp1));
567   __ cbz(tmp2, *stub-&gt;continuation());
568 
569   // Check if object is already forwarded.
570   Label slow_path;
571   __ ldr(tmp1, Address(res, oopDesc::mark_offset_in_bytes()));
572   __ eon(tmp1, tmp1, zr);
573   __ ands(zr, tmp1, markWord::lock_mask_in_place);
574   __ br(Assembler::NE, slow_path);
575 
576   // Decode forwarded object.
577   __ orr(tmp1, tmp1, markWord::marked_value);
578   __ eon(res, tmp1, zr);
579   __ b(*stub-&gt;continuation());
580 
581   __ bind(slow_path);
582   ce-&gt;store_parameter(res, 0);
583   ce-&gt;store_parameter(addr, 1);
<span class="line-modified">584   __ far_call(RuntimeAddress(bs-&gt;load_reference_barrier_rt_code_blob()-&gt;code_begin()));</span>




585 
586   __ b(*stub-&gt;continuation());
587 }
588 
589 #undef __
590 
591 #define __ sasm-&gt;
592 
593 void ShenandoahBarrierSetAssembler::generate_c1_pre_barrier_runtime_stub(StubAssembler* sasm) {
594   __ prologue(&quot;shenandoah_pre_barrier&quot;, false);
595 
596   // arg0 : previous value of memory
597 
598   BarrierSet* bs = BarrierSet::barrier_set();
599 
600   const Register pre_val = r0;
601   const Register thread = rthread;
602   const Register tmp = rscratch1;
603 
604   Address queue_index(thread, in_bytes(ShenandoahThreadLocalData::satb_mark_queue_index_offset()));
</pre>
<hr />
<pre>
619   __ cbz(tmp, runtime);
620 
621   __ sub(tmp, tmp, wordSize);
622   __ str(tmp, queue_index);
623   __ ldr(rscratch2, buffer);
624   __ add(tmp, tmp, rscratch2);
625   __ load_parameter(0, rscratch2);
626   __ str(rscratch2, Address(tmp, 0));
627   __ b(done);
628 
629   __ bind(runtime);
630   __ push_call_clobbered_registers();
631   __ load_parameter(0, pre_val);
632   __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::write_ref_field_pre_entry), pre_val, thread);
633   __ pop_call_clobbered_registers();
634   __ bind(done);
635 
636   __ epilogue();
637 }
638 
<span class="line-modified">639 void ShenandoahBarrierSetAssembler::generate_c1_load_reference_barrier_runtime_stub(StubAssembler* sasm) {</span>
640   __ prologue(&quot;shenandoah_load_reference_barrier&quot;, false);
641   // arg0 : object to be resolved
642 
643   __ push_call_clobbered_registers();
644   __ load_parameter(0, r0);
645   __ load_parameter(1, r1);
<span class="line-modified">646   if (UseCompressedOops) {</span>


647     __ mov(lr, CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_narrow));
648   } else {
649     __ mov(lr, CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier));
650   }
651   __ blr(lr);
652   __ mov(rscratch1, r0);
653   __ pop_call_clobbered_registers();
654   __ mov(r0, rscratch1);
655 
656   __ epilogue();
657 }
658 
659 #undef __
660 
661 #endif // COMPILER1
662 
663 address ShenandoahBarrierSetAssembler::shenandoah_lrb() {
664   assert(_shenandoah_lrb != NULL, &quot;need load reference barrier stub&quot;);
665   return _shenandoah_lrb;
666 }
</pre>
</td>
<td>
<hr />
<pre>
564   __ mov(tmp2, ShenandoahHeap::in_cset_fast_test_addr());
565   __ lsr(tmp1, res, ShenandoahHeapRegion::region_size_bytes_shift_jint());
566   __ ldrb(tmp2, Address(tmp2, tmp1));
567   __ cbz(tmp2, *stub-&gt;continuation());
568 
569   // Check if object is already forwarded.
570   Label slow_path;
571   __ ldr(tmp1, Address(res, oopDesc::mark_offset_in_bytes()));
572   __ eon(tmp1, tmp1, zr);
573   __ ands(zr, tmp1, markWord::lock_mask_in_place);
574   __ br(Assembler::NE, slow_path);
575 
576   // Decode forwarded object.
577   __ orr(tmp1, tmp1, markWord::marked_value);
578   __ eon(res, tmp1, zr);
579   __ b(*stub-&gt;continuation());
580 
581   __ bind(slow_path);
582   ce-&gt;store_parameter(res, 0);
583   ce-&gt;store_parameter(addr, 1);
<span class="line-modified">584   if (stub-&gt;is_native()) {</span>
<span class="line-added">585     __ far_call(RuntimeAddress(bs-&gt;load_reference_barrier_native_rt_code_blob()-&gt;code_begin()));</span>
<span class="line-added">586   } else {</span>
<span class="line-added">587     __ far_call(RuntimeAddress(bs-&gt;load_reference_barrier_rt_code_blob()-&gt;code_begin()));</span>
<span class="line-added">588   }</span>
589 
590   __ b(*stub-&gt;continuation());
591 }
592 
593 #undef __
594 
595 #define __ sasm-&gt;
596 
597 void ShenandoahBarrierSetAssembler::generate_c1_pre_barrier_runtime_stub(StubAssembler* sasm) {
598   __ prologue(&quot;shenandoah_pre_barrier&quot;, false);
599 
600   // arg0 : previous value of memory
601 
602   BarrierSet* bs = BarrierSet::barrier_set();
603 
604   const Register pre_val = r0;
605   const Register thread = rthread;
606   const Register tmp = rscratch1;
607 
608   Address queue_index(thread, in_bytes(ShenandoahThreadLocalData::satb_mark_queue_index_offset()));
</pre>
<hr />
<pre>
623   __ cbz(tmp, runtime);
624 
625   __ sub(tmp, tmp, wordSize);
626   __ str(tmp, queue_index);
627   __ ldr(rscratch2, buffer);
628   __ add(tmp, tmp, rscratch2);
629   __ load_parameter(0, rscratch2);
630   __ str(rscratch2, Address(tmp, 0));
631   __ b(done);
632 
633   __ bind(runtime);
634   __ push_call_clobbered_registers();
635   __ load_parameter(0, pre_val);
636   __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::write_ref_field_pre_entry), pre_val, thread);
637   __ pop_call_clobbered_registers();
638   __ bind(done);
639 
640   __ epilogue();
641 }
642 
<span class="line-modified">643 void ShenandoahBarrierSetAssembler::generate_c1_load_reference_barrier_runtime_stub(StubAssembler* sasm, bool is_native) {</span>
644   __ prologue(&quot;shenandoah_load_reference_barrier&quot;, false);
645   // arg0 : object to be resolved
646 
647   __ push_call_clobbered_registers();
648   __ load_parameter(0, r0);
649   __ load_parameter(1, r1);
<span class="line-modified">650   if (is_native) {</span>
<span class="line-added">651     __ mov(lr, CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_native));</span>
<span class="line-added">652   } else if (UseCompressedOops) {</span>
653     __ mov(lr, CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_narrow));
654   } else {
655     __ mov(lr, CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier));
656   }
657   __ blr(lr);
658   __ mov(rscratch1, r0);
659   __ pop_call_clobbered_registers();
660   __ mov(r0, rscratch1);
661 
662   __ epilogue();
663 }
664 
665 #undef __
666 
667 #endif // COMPILER1
668 
669 address ShenandoahBarrierSetAssembler::shenandoah_lrb() {
670   assert(_shenandoah_lrb != NULL, &quot;need load reference barrier stub&quot;);
671   return _shenandoah_lrb;
672 }
</pre>
</td>
</tr>
</table>
<center><a href="c1/shenandoahBarrierSetC1_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../index.html" target="_top">index</a> <a href="shenandoahBarrierSetAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>