<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/arm/arm.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../aarch64/vm_version_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="assembler_arm_32.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/arm/arm.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  177   int ret_addr_offset = -1;
  178   if (rspec.type() == relocInfo::runtime_call_type) {
  179     __ call(target, rspec);
  180     ret_addr_offset = __ offset();
  181   } else {
  182     // scratches Rtemp
  183     ret_addr_offset = __ patchable_call(target, rspec, true);
  184   }
  185   assert(ret_addr_offset - call_site_offset == ret_addr_offset0, &quot;fix ret_addr_offset()&quot;);
  186 }
  187 
  188 //=============================================================================
  189 // REQUIRED FUNCTIONALITY for encoding
  190 void emit_lo(CodeBuffer &amp;cbuf, int val) {  }
  191 void emit_hi(CodeBuffer &amp;cbuf, int val) {  }
  192 
  193 
  194 //=============================================================================
  195 const RegMask&amp; MachConstantBaseNode::_out_RegMask = PTR_REG_mask();
  196 
<span class="line-modified">  197 int Compile::ConstantTable::calculate_table_base_offset() const {</span>
  198   int offset = -(size() / 2);
  199   // flds, fldd: 8-bit  offset multiplied by 4: +/- 1024
  200   // ldr, ldrb : 12-bit offset:                 +/- 4096
  201   if (!Assembler::is_simm10(offset)) {
  202     offset = Assembler::min_simm10();
  203   }
  204   return offset;
  205 }
  206 
  207 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
  208 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
  209   ShouldNotReachHere();
  210 }
  211 
  212 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
  213   Compile* C = ra_-&gt;C;
<span class="line-modified">  214   Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();</span>
  215   MacroAssembler _masm(&amp;cbuf);
  216 
  217   Register r = as_Register(ra_-&gt;get_encode(this));
  218   CodeSection* consts_section = __ code()-&gt;consts();
  219   int consts_size = consts_section-&gt;align_at_start(consts_section-&gt;size());
  220   assert(constant_table.size() == consts_size, &quot;must be: %d == %d&quot;, constant_table.size(), consts_size);
  221 
  222   // Materialize the constant table base.
  223   address baseaddr = consts_section-&gt;start() + -(constant_table.table_base_offset());
  224   RelocationHolder rspec = internal_word_Relocation::spec(baseaddr);
  225   __ mov_address(r, baseaddr, rspec);
  226 }
  227 
  228 uint MachConstantBaseNode::size(PhaseRegAlloc*) const {
  229   return 8;
  230 }
  231 
  232 #ifndef PRODUCT
  233 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
  234   char reg[128];
  235   ra_-&gt;dump_register(this, reg);
  236   st-&gt;print(&quot;MOV_SLOW    &amp;constanttable,%s\t! constant table base&quot;, reg);
  237 }
  238 #endif
  239 
  240 #ifndef PRODUCT
  241 void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  242   Compile* C = ra_-&gt;C;
  243 
  244   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  245     st-&gt;print_cr(&quot;NOP&quot;); st-&gt;print(&quot;\t&quot;);
  246   }
  247 
<span class="line-modified">  248   size_t framesize = C-&gt;frame_size_in_bytes();</span>
  249   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
<span class="line-modified">  250   int bangsize = C-&gt;bang_size_in_bytes();</span>
  251   // Remove two words for return addr and rbp,
  252   framesize -= 2*wordSize;
  253   bangsize -= 2*wordSize;
  254 
  255   // Calls to C2R adapters often do not accept exceptional returns.
  256   // We require that their callers must bang for them.  But be careful, because
  257   // some VM calls (such as call site linkage) can use several kilobytes of
  258   // stack.  But the stack safety zone should account for that.
  259   // See bugs 4446381, 4468289, 4497237.
<span class="line-modified">  260   if (C-&gt;need_stack_bang(bangsize)) {</span>
  261     st-&gt;print_cr(&quot;! stack bang (%d bytes)&quot;, bangsize); st-&gt;print(&quot;\t&quot;);
  262   }
  263   st-&gt;print_cr(&quot;PUSH   R_FP|R_LR_LR&quot;); st-&gt;print(&quot;\t&quot;);
  264   if (framesize != 0) {
  265     st-&gt;print   (&quot;SUB    R_SP, R_SP, &quot; SIZE_FORMAT,framesize);
  266   }
  267 }
  268 #endif
  269 
  270 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  271   Compile* C = ra_-&gt;C;
  272   MacroAssembler _masm(&amp;cbuf);
  273 
  274   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  275     __ nop();
  276   }
  277 
<span class="line-modified">  278   size_t framesize = C-&gt;frame_size_in_bytes();</span>
  279   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
<span class="line-modified">  280   int bangsize = C-&gt;bang_size_in_bytes();</span>
  281   // Remove two words for return addr and fp,
  282   framesize -= 2*wordSize;
  283   bangsize -= 2*wordSize;
  284 
  285   // Calls to C2R adapters often do not accept exceptional returns.
  286   // We require that their callers must bang for them.  But be careful, because
  287   // some VM calls (such as call site linkage) can use several kilobytes of
  288   // stack.  But the stack safety zone should account for that.
  289   // See bugs 4446381, 4468289, 4497237.
<span class="line-modified">  290   if (C-&gt;need_stack_bang(bangsize)) {</span>
  291     __ arm_stack_overflow_check(bangsize, Rtemp);
  292   }
  293 
  294   __ raw_push(FP, LR);
  295   if (framesize != 0) {
  296     __ sub_slow(SP, SP, framesize);
  297   }
  298 
  299   // offset from scratch buffer is not valid
  300   if (strcmp(cbuf.name(), &quot;Compile::Fill_buffer&quot;) == 0) {
<span class="line-modified">  301     C-&gt;set_frame_complete( __ offset() );</span>
  302   }
  303 
  304   if (C-&gt;has_mach_constant_base_node()) {
  305     // NOTE: We set the table base offset here because users might be
  306     // emitted before MachConstantBaseNode.
<span class="line-modified">  307     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();</span>
  308     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
  309   }
  310 }
  311 
  312 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
  313   return MachNode::size(ra_);
  314 }
  315 
  316 int MachPrologNode::reloc() const {
  317   return 10; // a large enough number
  318 }
  319 
  320 //=============================================================================
  321 #ifndef PRODUCT
  322 void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  323   Compile* C = ra_-&gt;C;
  324 
<span class="line-modified">  325   size_t framesize = C-&gt;frame_size_in_bytes();</span>
  326   framesize -= 2*wordSize;
  327 
  328   if (framesize != 0) {
  329     st-&gt;print(&quot;ADD    R_SP, R_SP, &quot; SIZE_FORMAT &quot;\n\t&quot;,framesize);
  330   }
  331   st-&gt;print(&quot;POP    R_FP|R_LR_LR&quot;);
  332 
  333   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
  334     st-&gt;print(&quot;\n\t&quot;);
  335     st-&gt;print(&quot;MOV    Rtemp, #PollAddr\t! Load Polling address\n\t&quot;);
  336     st-&gt;print(&quot;LDR    Rtemp,[Rtemp]\t!Poll for Safepointing&quot;);
  337   }
  338 }
  339 #endif
  340 
  341 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  342   MacroAssembler _masm(&amp;cbuf);
  343   Compile* C = ra_-&gt;C;
  344 
<span class="line-modified">  345   size_t framesize = C-&gt;frame_size_in_bytes();</span>
  346   framesize -= 2*wordSize;
  347   if (framesize != 0) {
  348     __ add_slow(SP, SP, framesize);
  349   }
  350   __ raw_pop(FP, LR);
  351 
  352   // If this does safepoint polling, then do it here
  353   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
  354     __ read_polling_page(Rtemp, relocInfo::poll_return_type);
  355   }
  356 }
  357 
  358 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  359   return MachNode::size(ra_);
  360 }
  361 
  362 int MachEpilogNode::reloc() const {
  363   return 16; // a large enough number
  364 }
  365 
</pre>
<hr />
<pre>
  810 }
  811 #endif
  812 
  813 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  814   MacroAssembler _masm(&amp;cbuf);
  815   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
  816   int reg = ra_-&gt;get_encode(this);
  817   Register dst = reg_to_register_object(reg);
  818 
  819   if (is_aimm(offset)) {
  820     __ add(dst, SP, offset);
  821   } else {
  822     __ mov_slow(dst, offset);
  823     __ add(dst, SP, dst);
  824   }
  825 }
  826 
  827 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
  828   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
  829   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
<span class="line-modified">  830   return ra_-&gt;C-&gt;scratch_emit_size(this);</span>
  831 }
  832 
  833 //=============================================================================
  834 #ifndef PRODUCT
  835 #define R_RTEMP &quot;R_R12&quot;
  836 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  837   st-&gt;print_cr(&quot;\nUEP:&quot;);
  838   if (UseCompressedClassPointers) {
  839     st-&gt;print_cr(&quot;\tLDR_w &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  840     st-&gt;print_cr(&quot;\tdecode_klass &quot; R_RTEMP);
  841   } else {
  842     st-&gt;print_cr(&quot;\tLDR   &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  843   }
  844   st-&gt;print_cr(&quot;\tCMP   &quot; R_RTEMP &quot;,R_R8&quot; );
  845   st-&gt;print   (&quot;\tB.NE  SharedRuntime::handle_ic_miss_stub&quot;);
  846 }
  847 #endif
  848 
  849 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  850   MacroAssembler _masm(&amp;cbuf);
</pre>
<hr />
<pre>
 1123   NOT_LP64(ShouldNotCallThis());
 1124   return true;
 1125 }
 1126 
 1127 // Is it better to copy float constants, or load them directly from memory?
 1128 // Intel can load a float constant from a direct address, requiring no
 1129 // extra registers.  Most RISCs will have to materialize an address into a
 1130 // register first, so they would do better to copy the constant from stack.
 1131 const bool Matcher::rematerialize_float_constants = false;
 1132 
 1133 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1134 // needed.  Else we split the double into 2 integer pieces and move it
 1135 // piece-by-piece.  Only happens when passing doubles into C code as the
 1136 // Java calling convention forces doubles to be aligned.
 1137 const bool Matcher::misaligned_doubles_ok = false;
 1138 
 1139 // No-op on ARM.
 1140 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1141 }
 1142 
<span class="line-modified"> 1143 // Advertise here if the CPU requires explicit rounding operations</span>
<span class="line-removed"> 1144 // to implement the UseStrictFP mode.</span>
 1145 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1146 
 1147 // Are floats converted to double when stored to stack during deoptimization?
 1148 // ARM does not handle callee-save floats.
 1149 bool Matcher::float_in_double() {
 1150   return false;
 1151 }
 1152 
 1153 // Do ints take an entire long register or just half?
 1154 // Note that we if-def off of _LP64.
 1155 // The relevant question is how the int is callee-saved.  In _LP64
 1156 // the whole long is written but de-opt&#39;ing will have to extract
 1157 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1158 #ifdef _LP64
 1159 const bool Matcher::int_in_long = true;
 1160 #else
 1161 const bool Matcher::int_in_long = false;
 1162 #endif
 1163 
 1164 // Return whether or not this register is ever used as an argument.  This
</pre>
<hr />
<pre>
10602   match(Set dst (LShiftVB src shift));
10603   size(4*1);
10604   ins_cost(DEFAULT_COST*1); // FIXME
10605   expand %{
10606     vsh8B_reg(dst, src, shift);
10607   %}
10608 %}
10609 
10610 instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{
10611   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10612   match(Set dst (LShiftVB src shift));
10613   size(4*1);
10614   ins_cost(DEFAULT_COST*1); // FIXME
10615   expand %{
10616     vsh16B_reg(dst, src, shift);
10617   %}
10618 %}
10619 
10620 instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{
10621   predicate(n-&gt;as_Vector()-&gt;length() == 8);
<span class="line-modified">10622   match(Set dst (LShiftVB src shift));</span>
10623   size(4);
10624   ins_cost(DEFAULT_COST); // FIXME
10625   format %{
10626     &quot;VSHL.I8 $dst.D,$src.D,$shift\t! logical left shift packed8B&quot;
10627   %}
10628   ins_encode %{
10629     bool quad = false;
10630     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10631              quad);
10632   %}
10633   ins_pipe( ialu_reg_reg ); // FIXME
10634 %}
10635 
10636 instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{
10637   predicate(n-&gt;as_Vector()-&gt;length() == 16);
<span class="line-modified">10638   match(Set dst (LShiftVB src shift));</span>
10639   size(4);
10640   ins_cost(DEFAULT_COST); // FIXME
10641   format %{
10642     &quot;VSHL.I8 $dst.Q,$src.Q,$shift\t! logical left shift packed16B&quot;
10643   %}
10644   ins_encode %{
10645     bool quad = true;
10646     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10647              quad);
10648   %}
10649   ins_pipe( ialu_reg_reg ); // FIXME
10650 %}
10651 
10652 // Shorts/Chars vector logical left/right shift
10653 instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{
10654   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10655   match(Set dst (LShiftVS src shift));
10656   match(Set dst (URShiftVS src shift));
10657   size(4*1);
10658   ins_cost(DEFAULT_COST*1); // FIXME
10659   expand %{
10660     vsh4S_reg(dst, src, shift);
10661   %}
10662 %}
10663 
10664 instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{
10665   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10666   match(Set dst (LShiftVS src shift));
10667   match(Set dst (URShiftVS src shift));
10668   size(4*1);
10669   ins_cost(DEFAULT_COST*1); // FIXME
10670   expand %{
10671     vsh8S_reg(dst, src, shift);
10672   %}
10673 %}
10674 
10675 instruct vsl4S_immI(vecD dst, vecD src, immI shift) %{
10676   predicate(n-&gt;as_Vector()-&gt;length() == 4);
<span class="line-modified">10677   match(Set dst (LShiftVS src shift));</span>
10678   size(4);
10679   ins_cost(DEFAULT_COST); // FIXME
10680   format %{
10681     &quot;VSHL.I16 $dst.D,$src.D,$shift\t! logical left shift packed4S&quot;
10682   %}
10683   ins_encode %{
10684     bool quad = false;
10685     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10686              quad);
10687   %}
10688   ins_pipe( ialu_reg_reg ); // FIXME
10689 %}
10690 
10691 instruct vsl8S_immI(vecX dst, vecX src, immI shift) %{
10692   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10693   match(Set dst (LShiftVS src shift));
10694   size(4);
10695   ins_cost(DEFAULT_COST); // FIXME
10696   format %{
10697     &quot;VSHL.I16 $dst.Q,$src.Q,$shift\t! logical left shift packed8S&quot;
</pre>
<hr />
<pre>
10712   size(4*1);
10713   ins_cost(DEFAULT_COST*1); // FIXME
10714   expand %{
10715     vsh2I_reg(dst, src, shift);
10716   %}
10717 %}
10718 
10719 instruct vsl4I_reg(vecX dst, vecX src, vecX shift) %{
10720   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10721   match(Set dst (LShiftVI src shift));
10722   match(Set dst (URShiftVI src shift));
10723   size(4*1);
10724   ins_cost(DEFAULT_COST*1); // FIXME
10725   expand %{
10726     vsh4I_reg(dst, src, shift);
10727   %}
10728 %}
10729 
10730 instruct vsl2I_immI(vecD dst, vecD src, immI shift) %{
10731   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10732   match(Set dst (LShiftVI src shift));</span>
10733   size(4);
10734   ins_cost(DEFAULT_COST); // FIXME
10735   format %{
10736     &quot;VSHL.I32 $dst.D,$src.D,$shift\t! logical left shift packed2I&quot;
10737   %}
10738   ins_encode %{
10739     bool quad = false;
10740     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10741              quad);
10742   %}
10743   ins_pipe( ialu_reg_reg ); // FIXME
10744 %}
10745 
10746 instruct vsl4I_immI(vecX dst, vecX src, immI shift) %{
10747   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10748   match(Set dst (LShiftVI src shift));</span>
10749   size(4);
10750   ins_cost(DEFAULT_COST); // FIXME
10751   format %{
10752     &quot;VSHL.I32 $dst.Q,$src.Q,$shift\t! logical left shift packed4I&quot;
10753   %}
10754   ins_encode %{
10755     bool quad = true;
10756     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10757              quad);
10758   %}
10759   ins_pipe( ialu_reg_reg ); // FIXME
10760 %}
10761 
10762 // Longs vector logical left/right shift
10763 instruct vsl2L_reg(vecX dst, vecX src, vecX shift) %{
10764   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10765   match(Set dst (LShiftVL src shift));
10766   match(Set dst (URShiftVL src shift));
10767   size(4*1);
10768   ins_cost(DEFAULT_COST*1); // FIXME
10769   expand %{
10770     vsh2L_reg(dst, src, shift);
10771   %}
10772 %}
10773 
10774 instruct vsl2L_immI(vecX dst, vecX src, immI shift) %{
10775   predicate(n-&gt;as_Vector()-&gt;length() == 2);
<span class="line-modified">10776   match(Set dst (LShiftVL src shift));</span>
10777   size(4);
10778   ins_cost(DEFAULT_COST); // FIXME
10779   format %{
10780     &quot;VSHL.I64 $dst.Q,$src.Q,$shift\t! logical left shift packed2L&quot;
10781   %}
10782   ins_encode %{
10783     bool quad = true;
10784     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10785              quad);
10786   %}
10787   ins_pipe( ialu_reg_reg ); // FIXME
10788 %}
10789 
10790 // ----------------------- LogicalRightShift -----------------------------------
10791 
10792 // Bytes/Shorts vector logical right shift produces incorrect Java result
10793 // for negative data because java code convert short value into int with
10794 // sign extension before a shift.
10795 
10796 // Chars vector logical right shift
10797 instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{
10798   predicate(n-&gt;as_Vector()-&gt;length() == 4);
<span class="line-modified">10799   match(Set dst (URShiftVS src shift));</span>
10800   size(4);
10801   ins_cost(DEFAULT_COST); // FIXME
10802   format %{
10803     &quot;VSHR.U16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
10804   %}
10805   ins_encode %{
10806     bool quad = false;
10807     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10808              quad);
10809   %}
10810   ins_pipe( ialu_reg_reg ); // FIXME
10811 %}
10812 
10813 instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{
10814   predicate(n-&gt;as_Vector()-&gt;length() == 8);
<span class="line-modified">10815   match(Set dst (URShiftVS src shift));</span>
10816   size(4);
10817   ins_cost(DEFAULT_COST); // FIXME
10818   format %{
10819     &quot;VSHR.U16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
10820   %}
10821   ins_encode %{
10822     bool quad = true;
10823     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10824              quad);
10825   %}
10826   ins_pipe( ialu_reg_reg ); // FIXME
10827 %}
10828 
10829 // Integers vector logical right shift
10830 instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{
10831   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10832   match(Set dst (URShiftVI src shift));</span>
10833   size(4);
10834   ins_cost(DEFAULT_COST); // FIXME
10835   format %{
10836     &quot;VSHR.U32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
10837   %}
10838   ins_encode %{
10839     bool quad = false;
10840     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10841              quad);
10842   %}
10843   ins_pipe( ialu_reg_reg ); // FIXME
10844 %}
10845 
10846 instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{
10847   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10848   match(Set dst (URShiftVI src shift));</span>
10849   size(4);
10850   ins_cost(DEFAULT_COST); // FIXME
10851   format %{
10852     &quot;VSHR.U32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
10853   %}
10854   ins_encode %{
10855     bool quad = true;
10856     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10857              quad);
10858   %}
10859   ins_pipe( ialu_reg_reg ); // FIXME
10860 %}
10861 
10862 // Longs vector logical right shift
10863 instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{
10864   predicate(n-&gt;as_Vector()-&gt;length() == 2);
<span class="line-modified">10865   match(Set dst (URShiftVL src shift));</span>
10866   size(4);
10867   ins_cost(DEFAULT_COST); // FIXME
10868   format %{
10869     &quot;VSHR.U64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
10870   %}
10871   ins_encode %{
10872     bool quad = true;
10873     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10874              quad);
10875   %}
10876   ins_pipe( ialu_reg_reg ); // FIXME
10877 %}
10878 
10879 // ------------------- ArithmeticRightShift -----------------------------------
10880 
10881 // Bytes vector arithmetic left/right shift based on sign
10882 instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{
10883   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10884   effect(DEF dst, USE src, USE shift);
10885   size(4);
</pre>
</td>
<td>
<hr />
<pre>
  177   int ret_addr_offset = -1;
  178   if (rspec.type() == relocInfo::runtime_call_type) {
  179     __ call(target, rspec);
  180     ret_addr_offset = __ offset();
  181   } else {
  182     // scratches Rtemp
  183     ret_addr_offset = __ patchable_call(target, rspec, true);
  184   }
  185   assert(ret_addr_offset - call_site_offset == ret_addr_offset0, &quot;fix ret_addr_offset()&quot;);
  186 }
  187 
  188 //=============================================================================
  189 // REQUIRED FUNCTIONALITY for encoding
  190 void emit_lo(CodeBuffer &amp;cbuf, int val) {  }
  191 void emit_hi(CodeBuffer &amp;cbuf, int val) {  }
  192 
  193 
  194 //=============================================================================
  195 const RegMask&amp; MachConstantBaseNode::_out_RegMask = PTR_REG_mask();
  196 
<span class="line-modified">  197 int ConstantTable::calculate_table_base_offset() const {</span>
  198   int offset = -(size() / 2);
  199   // flds, fldd: 8-bit  offset multiplied by 4: +/- 1024
  200   // ldr, ldrb : 12-bit offset:                 +/- 4096
  201   if (!Assembler::is_simm10(offset)) {
  202     offset = Assembler::min_simm10();
  203   }
  204   return offset;
  205 }
  206 
  207 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
  208 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
  209   ShouldNotReachHere();
  210 }
  211 
  212 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
  213   Compile* C = ra_-&gt;C;
<span class="line-modified">  214   ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();</span>
  215   MacroAssembler _masm(&amp;cbuf);
  216 
  217   Register r = as_Register(ra_-&gt;get_encode(this));
  218   CodeSection* consts_section = __ code()-&gt;consts();
  219   int consts_size = consts_section-&gt;align_at_start(consts_section-&gt;size());
  220   assert(constant_table.size() == consts_size, &quot;must be: %d == %d&quot;, constant_table.size(), consts_size);
  221 
  222   // Materialize the constant table base.
  223   address baseaddr = consts_section-&gt;start() + -(constant_table.table_base_offset());
  224   RelocationHolder rspec = internal_word_Relocation::spec(baseaddr);
  225   __ mov_address(r, baseaddr, rspec);
  226 }
  227 
  228 uint MachConstantBaseNode::size(PhaseRegAlloc*) const {
  229   return 8;
  230 }
  231 
  232 #ifndef PRODUCT
  233 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
  234   char reg[128];
  235   ra_-&gt;dump_register(this, reg);
  236   st-&gt;print(&quot;MOV_SLOW    &amp;constanttable,%s\t! constant table base&quot;, reg);
  237 }
  238 #endif
  239 
  240 #ifndef PRODUCT
  241 void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  242   Compile* C = ra_-&gt;C;
  243 
  244   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  245     st-&gt;print_cr(&quot;NOP&quot;); st-&gt;print(&quot;\t&quot;);
  246   }
  247 
<span class="line-modified">  248   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
  249   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
<span class="line-modified">  250   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
  251   // Remove two words for return addr and rbp,
  252   framesize -= 2*wordSize;
  253   bangsize -= 2*wordSize;
  254 
  255   // Calls to C2R adapters often do not accept exceptional returns.
  256   // We require that their callers must bang for them.  But be careful, because
  257   // some VM calls (such as call site linkage) can use several kilobytes of
  258   // stack.  But the stack safety zone should account for that.
  259   // See bugs 4446381, 4468289, 4497237.
<span class="line-modified">  260   if (C-&gt;output()-&gt;need_stack_bang(bangsize)) {</span>
  261     st-&gt;print_cr(&quot;! stack bang (%d bytes)&quot;, bangsize); st-&gt;print(&quot;\t&quot;);
  262   }
  263   st-&gt;print_cr(&quot;PUSH   R_FP|R_LR_LR&quot;); st-&gt;print(&quot;\t&quot;);
  264   if (framesize != 0) {
  265     st-&gt;print   (&quot;SUB    R_SP, R_SP, &quot; SIZE_FORMAT,framesize);
  266   }
  267 }
  268 #endif
  269 
  270 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  271   Compile* C = ra_-&gt;C;
  272   MacroAssembler _masm(&amp;cbuf);
  273 
  274   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  275     __ nop();
  276   }
  277 
<span class="line-modified">  278   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
  279   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
<span class="line-modified">  280   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
  281   // Remove two words for return addr and fp,
  282   framesize -= 2*wordSize;
  283   bangsize -= 2*wordSize;
  284 
  285   // Calls to C2R adapters often do not accept exceptional returns.
  286   // We require that their callers must bang for them.  But be careful, because
  287   // some VM calls (such as call site linkage) can use several kilobytes of
  288   // stack.  But the stack safety zone should account for that.
  289   // See bugs 4446381, 4468289, 4497237.
<span class="line-modified">  290   if (C-&gt;output()-&gt;need_stack_bang(bangsize)) {</span>
  291     __ arm_stack_overflow_check(bangsize, Rtemp);
  292   }
  293 
  294   __ raw_push(FP, LR);
  295   if (framesize != 0) {
  296     __ sub_slow(SP, SP, framesize);
  297   }
  298 
  299   // offset from scratch buffer is not valid
  300   if (strcmp(cbuf.name(), &quot;Compile::Fill_buffer&quot;) == 0) {
<span class="line-modified">  301     C-&gt;output()-&gt;set_frame_complete( __ offset() );</span>
  302   }
  303 
  304   if (C-&gt;has_mach_constant_base_node()) {
  305     // NOTE: We set the table base offset here because users might be
  306     // emitted before MachConstantBaseNode.
<span class="line-modified">  307     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();</span>
  308     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
  309   }
  310 }
  311 
  312 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
  313   return MachNode::size(ra_);
  314 }
  315 
  316 int MachPrologNode::reloc() const {
  317   return 10; // a large enough number
  318 }
  319 
  320 //=============================================================================
  321 #ifndef PRODUCT
  322 void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  323   Compile* C = ra_-&gt;C;
  324 
<span class="line-modified">  325   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
  326   framesize -= 2*wordSize;
  327 
  328   if (framesize != 0) {
  329     st-&gt;print(&quot;ADD    R_SP, R_SP, &quot; SIZE_FORMAT &quot;\n\t&quot;,framesize);
  330   }
  331   st-&gt;print(&quot;POP    R_FP|R_LR_LR&quot;);
  332 
  333   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
  334     st-&gt;print(&quot;\n\t&quot;);
  335     st-&gt;print(&quot;MOV    Rtemp, #PollAddr\t! Load Polling address\n\t&quot;);
  336     st-&gt;print(&quot;LDR    Rtemp,[Rtemp]\t!Poll for Safepointing&quot;);
  337   }
  338 }
  339 #endif
  340 
  341 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  342   MacroAssembler _masm(&amp;cbuf);
  343   Compile* C = ra_-&gt;C;
  344 
<span class="line-modified">  345   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
  346   framesize -= 2*wordSize;
  347   if (framesize != 0) {
  348     __ add_slow(SP, SP, framesize);
  349   }
  350   __ raw_pop(FP, LR);
  351 
  352   // If this does safepoint polling, then do it here
  353   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
  354     __ read_polling_page(Rtemp, relocInfo::poll_return_type);
  355   }
  356 }
  357 
  358 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  359   return MachNode::size(ra_);
  360 }
  361 
  362 int MachEpilogNode::reloc() const {
  363   return 16; // a large enough number
  364 }
  365 
</pre>
<hr />
<pre>
  810 }
  811 #endif
  812 
  813 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  814   MacroAssembler _masm(&amp;cbuf);
  815   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
  816   int reg = ra_-&gt;get_encode(this);
  817   Register dst = reg_to_register_object(reg);
  818 
  819   if (is_aimm(offset)) {
  820     __ add(dst, SP, offset);
  821   } else {
  822     __ mov_slow(dst, offset);
  823     __ add(dst, SP, dst);
  824   }
  825 }
  826 
  827 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
  828   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
  829   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
<span class="line-modified">  830   return ra_-&gt;C-&gt;output()-&gt;scratch_emit_size(this);</span>
  831 }
  832 
  833 //=============================================================================
  834 #ifndef PRODUCT
  835 #define R_RTEMP &quot;R_R12&quot;
  836 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  837   st-&gt;print_cr(&quot;\nUEP:&quot;);
  838   if (UseCompressedClassPointers) {
  839     st-&gt;print_cr(&quot;\tLDR_w &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  840     st-&gt;print_cr(&quot;\tdecode_klass &quot; R_RTEMP);
  841   } else {
  842     st-&gt;print_cr(&quot;\tLDR   &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  843   }
  844   st-&gt;print_cr(&quot;\tCMP   &quot; R_RTEMP &quot;,R_R8&quot; );
  845   st-&gt;print   (&quot;\tB.NE  SharedRuntime::handle_ic_miss_stub&quot;);
  846 }
  847 #endif
  848 
  849 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  850   MacroAssembler _masm(&amp;cbuf);
</pre>
<hr />
<pre>
 1123   NOT_LP64(ShouldNotCallThis());
 1124   return true;
 1125 }
 1126 
 1127 // Is it better to copy float constants, or load them directly from memory?
 1128 // Intel can load a float constant from a direct address, requiring no
 1129 // extra registers.  Most RISCs will have to materialize an address into a
 1130 // register first, so they would do better to copy the constant from stack.
 1131 const bool Matcher::rematerialize_float_constants = false;
 1132 
 1133 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1134 // needed.  Else we split the double into 2 integer pieces and move it
 1135 // piece-by-piece.  Only happens when passing doubles into C code as the
 1136 // Java calling convention forces doubles to be aligned.
 1137 const bool Matcher::misaligned_doubles_ok = false;
 1138 
 1139 // No-op on ARM.
 1140 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1141 }
 1142 
<span class="line-modified"> 1143 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.</span>

 1144 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1145 
 1146 // Are floats converted to double when stored to stack during deoptimization?
 1147 // ARM does not handle callee-save floats.
 1148 bool Matcher::float_in_double() {
 1149   return false;
 1150 }
 1151 
 1152 // Do ints take an entire long register or just half?
 1153 // Note that we if-def off of _LP64.
 1154 // The relevant question is how the int is callee-saved.  In _LP64
 1155 // the whole long is written but de-opt&#39;ing will have to extract
 1156 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1157 #ifdef _LP64
 1158 const bool Matcher::int_in_long = true;
 1159 #else
 1160 const bool Matcher::int_in_long = false;
 1161 #endif
 1162 
 1163 // Return whether or not this register is ever used as an argument.  This
</pre>
<hr />
<pre>
10601   match(Set dst (LShiftVB src shift));
10602   size(4*1);
10603   ins_cost(DEFAULT_COST*1); // FIXME
10604   expand %{
10605     vsh8B_reg(dst, src, shift);
10606   %}
10607 %}
10608 
10609 instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{
10610   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10611   match(Set dst (LShiftVB src shift));
10612   size(4*1);
10613   ins_cost(DEFAULT_COST*1); // FIXME
10614   expand %{
10615     vsh16B_reg(dst, src, shift);
10616   %}
10617 %}
10618 
10619 instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{
10620   predicate(n-&gt;as_Vector()-&gt;length() == 8);
<span class="line-modified">10621   match(Set dst (LShiftVB src (LShiftCntV shift)));</span>
10622   size(4);
10623   ins_cost(DEFAULT_COST); // FIXME
10624   format %{
10625     &quot;VSHL.I8 $dst.D,$src.D,$shift\t! logical left shift packed8B&quot;
10626   %}
10627   ins_encode %{
10628     bool quad = false;
10629     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10630              quad);
10631   %}
10632   ins_pipe( ialu_reg_reg ); // FIXME
10633 %}
10634 
10635 instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{
10636   predicate(n-&gt;as_Vector()-&gt;length() == 16);
<span class="line-modified">10637   match(Set dst (LShiftVB src (LShiftCntV shift)));</span>
10638   size(4);
10639   ins_cost(DEFAULT_COST); // FIXME
10640   format %{
10641     &quot;VSHL.I8 $dst.Q,$src.Q,$shift\t! logical left shift packed16B&quot;
10642   %}
10643   ins_encode %{
10644     bool quad = true;
10645     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10646              quad);
10647   %}
10648   ins_pipe( ialu_reg_reg ); // FIXME
10649 %}
10650 
10651 // Shorts/Chars vector logical left/right shift
10652 instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{
10653   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10654   match(Set dst (LShiftVS src shift));
10655   match(Set dst (URShiftVS src shift));
10656   size(4*1);
10657   ins_cost(DEFAULT_COST*1); // FIXME
10658   expand %{
10659     vsh4S_reg(dst, src, shift);
10660   %}
10661 %}
10662 
10663 instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{
10664   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10665   match(Set dst (LShiftVS src shift));
10666   match(Set dst (URShiftVS src shift));
10667   size(4*1);
10668   ins_cost(DEFAULT_COST*1); // FIXME
10669   expand %{
10670     vsh8S_reg(dst, src, shift);
10671   %}
10672 %}
10673 
10674 instruct vsl4S_immI(vecD dst, vecD src, immI shift) %{
10675   predicate(n-&gt;as_Vector()-&gt;length() == 4);
<span class="line-modified">10676   match(Set dst (LShiftVS src (LShiftCntV shift)));</span>
10677   size(4);
10678   ins_cost(DEFAULT_COST); // FIXME
10679   format %{
10680     &quot;VSHL.I16 $dst.D,$src.D,$shift\t! logical left shift packed4S&quot;
10681   %}
10682   ins_encode %{
10683     bool quad = false;
10684     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10685              quad);
10686   %}
10687   ins_pipe( ialu_reg_reg ); // FIXME
10688 %}
10689 
10690 instruct vsl8S_immI(vecX dst, vecX src, immI shift) %{
10691   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10692   match(Set dst (LShiftVS src shift));
10693   size(4);
10694   ins_cost(DEFAULT_COST); // FIXME
10695   format %{
10696     &quot;VSHL.I16 $dst.Q,$src.Q,$shift\t! logical left shift packed8S&quot;
</pre>
<hr />
<pre>
10711   size(4*1);
10712   ins_cost(DEFAULT_COST*1); // FIXME
10713   expand %{
10714     vsh2I_reg(dst, src, shift);
10715   %}
10716 %}
10717 
10718 instruct vsl4I_reg(vecX dst, vecX src, vecX shift) %{
10719   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10720   match(Set dst (LShiftVI src shift));
10721   match(Set dst (URShiftVI src shift));
10722   size(4*1);
10723   ins_cost(DEFAULT_COST*1); // FIXME
10724   expand %{
10725     vsh4I_reg(dst, src, shift);
10726   %}
10727 %}
10728 
10729 instruct vsl2I_immI(vecD dst, vecD src, immI shift) %{
10730   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10731   match(Set dst (LShiftVI src (LShiftCntV shift)));</span>
10732   size(4);
10733   ins_cost(DEFAULT_COST); // FIXME
10734   format %{
10735     &quot;VSHL.I32 $dst.D,$src.D,$shift\t! logical left shift packed2I&quot;
10736   %}
10737   ins_encode %{
10738     bool quad = false;
10739     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10740              quad);
10741   %}
10742   ins_pipe( ialu_reg_reg ); // FIXME
10743 %}
10744 
10745 instruct vsl4I_immI(vecX dst, vecX src, immI shift) %{
10746   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10747   match(Set dst (LShiftVI src (LShiftCntV shift)));</span>
10748   size(4);
10749   ins_cost(DEFAULT_COST); // FIXME
10750   format %{
10751     &quot;VSHL.I32 $dst.Q,$src.Q,$shift\t! logical left shift packed4I&quot;
10752   %}
10753   ins_encode %{
10754     bool quad = true;
10755     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10756              quad);
10757   %}
10758   ins_pipe( ialu_reg_reg ); // FIXME
10759 %}
10760 
10761 // Longs vector logical left/right shift
10762 instruct vsl2L_reg(vecX dst, vecX src, vecX shift) %{
10763   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10764   match(Set dst (LShiftVL src shift));
10765   match(Set dst (URShiftVL src shift));
10766   size(4*1);
10767   ins_cost(DEFAULT_COST*1); // FIXME
10768   expand %{
10769     vsh2L_reg(dst, src, shift);
10770   %}
10771 %}
10772 
10773 instruct vsl2L_immI(vecX dst, vecX src, immI shift) %{
10774   predicate(n-&gt;as_Vector()-&gt;length() == 2);
<span class="line-modified">10775   match(Set dst (LShiftVL src (LShiftCntV shift)));</span>
10776   size(4);
10777   ins_cost(DEFAULT_COST); // FIXME
10778   format %{
10779     &quot;VSHL.I64 $dst.Q,$src.Q,$shift\t! logical left shift packed2L&quot;
10780   %}
10781   ins_encode %{
10782     bool quad = true;
10783     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10784              quad);
10785   %}
10786   ins_pipe( ialu_reg_reg ); // FIXME
10787 %}
10788 
10789 // ----------------------- LogicalRightShift -----------------------------------
10790 
10791 // Bytes/Shorts vector logical right shift produces incorrect Java result
10792 // for negative data because java code convert short value into int with
10793 // sign extension before a shift.
10794 
10795 // Chars vector logical right shift
10796 instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{
10797   predicate(n-&gt;as_Vector()-&gt;length() == 4);
<span class="line-modified">10798   match(Set dst (URShiftVS src (RShiftCntV shift)));</span>
10799   size(4);
10800   ins_cost(DEFAULT_COST); // FIXME
10801   format %{
10802     &quot;VSHR.U16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
10803   %}
10804   ins_encode %{
10805     bool quad = false;
10806     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10807              quad);
10808   %}
10809   ins_pipe( ialu_reg_reg ); // FIXME
10810 %}
10811 
10812 instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{
10813   predicate(n-&gt;as_Vector()-&gt;length() == 8);
<span class="line-modified">10814   match(Set dst (URShiftVS src (RShiftCntV shift)));</span>
10815   size(4);
10816   ins_cost(DEFAULT_COST); // FIXME
10817   format %{
10818     &quot;VSHR.U16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
10819   %}
10820   ins_encode %{
10821     bool quad = true;
10822     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10823              quad);
10824   %}
10825   ins_pipe( ialu_reg_reg ); // FIXME
10826 %}
10827 
10828 // Integers vector logical right shift
10829 instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{
10830   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10831   match(Set dst (URShiftVI src (RShiftCntV shift)));</span>
10832   size(4);
10833   ins_cost(DEFAULT_COST); // FIXME
10834   format %{
10835     &quot;VSHR.U32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
10836   %}
10837   ins_encode %{
10838     bool quad = false;
10839     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10840              quad);
10841   %}
10842   ins_pipe( ialu_reg_reg ); // FIXME
10843 %}
10844 
10845 instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{
10846   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
<span class="line-modified">10847   match(Set dst (URShiftVI src (RShiftCntV shift)));</span>
10848   size(4);
10849   ins_cost(DEFAULT_COST); // FIXME
10850   format %{
10851     &quot;VSHR.U32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
10852   %}
10853   ins_encode %{
10854     bool quad = true;
10855     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10856              quad);
10857   %}
10858   ins_pipe( ialu_reg_reg ); // FIXME
10859 %}
10860 
10861 // Longs vector logical right shift
10862 instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{
10863   predicate(n-&gt;as_Vector()-&gt;length() == 2);
<span class="line-modified">10864   match(Set dst (URShiftVL src (RShiftCntV shift)));</span>
10865   size(4);
10866   ins_cost(DEFAULT_COST); // FIXME
10867   format %{
10868     &quot;VSHR.U64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
10869   %}
10870   ins_encode %{
10871     bool quad = true;
10872     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10873              quad);
10874   %}
10875   ins_pipe( ialu_reg_reg ); // FIXME
10876 %}
10877 
10878 // ------------------- ArithmeticRightShift -----------------------------------
10879 
10880 // Bytes vector arithmetic left/right shift based on sign
10881 instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{
10882   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10883   effect(DEF dst, USE src, USE shift);
10884   size(4);
</pre>
</td>
</tr>
</table>
<center><a href="../aarch64/vm_version_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="assembler_arm_32.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>