<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/arm/sharedRuntime_arm.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroAssembler_arm.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_arm.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/arm/sharedRuntime_arm.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/assembler.hpp&quot;
  27 #include &quot;assembler_arm.inline.hpp&quot;
  28 #include &quot;code/debugInfoRec.hpp&quot;
  29 #include &quot;code/icBuffer.hpp&quot;
  30 #include &quot;code/vtableStubs.hpp&quot;
  31 #include &quot;interpreter/interpreter.hpp&quot;
  32 #include &quot;logging/log.hpp&quot;
  33 #include &quot;memory/resourceArea.hpp&quot;
  34 #include &quot;oops/compiledICHolder.hpp&quot;
  35 #include &quot;oops/klass.inline.hpp&quot;
  36 #include &quot;runtime/sharedRuntime.hpp&quot;
  37 #include &quot;runtime/safepointMechanism.hpp&quot;
  38 #include &quot;runtime/vframeArray.hpp&quot;
  39 #include &quot;utilities/align.hpp&quot;

  40 #include &quot;vmreg_arm.inline.hpp&quot;
  41 #ifdef COMPILER1
  42 #include &quot;c1/c1_Runtime1.hpp&quot;
  43 #endif
  44 #ifdef COMPILER2
  45 #include &quot;opto/runtime.hpp&quot;
  46 #endif
  47 
  48 #define __ masm-&gt;
  49 
  50 class RegisterSaver {
  51 public:
  52 
  53   // Special registers:
  54   //              32-bit ARM     64-bit ARM
  55   //  Rthread:       R10            R28
  56   //  LR:            R14            R30
  57 
  58   // Rthread is callee saved in the C ABI and never changed by compiled code:
  59   // no need to save it.
</pre>
<hr />
<pre>
 116 
 117 
 118 
 119 
 120 OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm,
 121                                            int* total_frame_words,
 122                                            bool lr_saved) {
 123   *total_frame_words = reg_save_size;
 124 
 125   OopMapSet *oop_maps = new OopMapSet();
 126   OopMap* map = new OopMap(VMRegImpl::slots_per_word * (*total_frame_words), 0);
 127 
 128   if (lr_saved) {
 129     __ push(RegisterSet(FP));
 130   } else {
 131     __ push(RegisterSet(FP) | RegisterSet(LR));
 132   }
 133   __ push(SAVED_BASE_REGS);
 134   if (HaveVFP) {
 135     if (VM_Version::has_vfp3_32()) {
<span class="line-modified"> 136       __ fstmdbd(SP, FloatRegisterSet(D16, 16), writeback);</span>
 137     } else {
 138       if (FloatRegisterImpl::number_of_registers &gt; 32) {
 139         assert(FloatRegisterImpl::number_of_registers == 64, &quot;nb fp registers should be 64&quot;);
 140         __ sub(SP, SP, 32 * wordSize);
 141       }
 142     }
<span class="line-modified"> 143     __ fstmdbd(SP, FloatRegisterSet(D0, 16), writeback);</span>
 144   } else {
 145     __ sub(SP, SP, fpu_save_size * wordSize);
 146   }
 147 
 148   int i;
 149   int j=0;
 150   for (i = R0_offset; i &lt;= R9_offset; i++) {
 151     if (j == FP_REG_NUM) {
 152       // skip the FP register, managed below.
 153       j++;
 154     }
 155     map-&gt;set_callee_saved(VMRegImpl::stack2reg(i), as_Register(j)-&gt;as_VMReg());
 156     j++;
 157   }
 158   assert(j == R10-&gt;encoding(), &quot;must be&quot;);
 159 #if (FP_REG_NUM != 11)
 160   // add R11, if not managed as FP
 161   map-&gt;set_callee_saved(VMRegImpl::stack2reg(R11_offset), R11-&gt;as_VMReg());
 162 #endif
 163   map-&gt;set_callee_saved(VMRegImpl::stack2reg(R12_offset), R12-&gt;as_VMReg());
 164   map-&gt;set_callee_saved(VMRegImpl::stack2reg(R14_offset), R14-&gt;as_VMReg());
 165   if (HaveVFP) {
 166     for (i = 0; i &lt; (VM_Version::has_vfp3_32() ? 64 : 32); i+=2) {
 167       map-&gt;set_callee_saved(VMRegImpl::stack2reg(i), as_FloatRegister(i)-&gt;as_VMReg());
 168       map-&gt;set_callee_saved(VMRegImpl::stack2reg(i + 1), as_FloatRegister(i)-&gt;as_VMReg()-&gt;next());
 169     }
 170   }
 171 
 172   return map;
 173 }
 174 
 175 void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_lr) {
 176   if (HaveVFP) {
<span class="line-modified"> 177     __ fldmiad(SP, FloatRegisterSet(D0, 16), writeback);</span>
 178     if (VM_Version::has_vfp3_32()) {
<span class="line-modified"> 179       __ fldmiad(SP, FloatRegisterSet(D16, 16), writeback);</span>
 180     } else {
 181       if (FloatRegisterImpl::number_of_registers &gt; 32) {
 182         assert(FloatRegisterImpl::number_of_registers == 64, &quot;nb fp registers should be 64&quot;);
 183         __ add(SP, SP, 32 * wordSize);
 184       }
 185     }
 186   } else {
 187     __ add(SP, SP, fpu_save_size * wordSize);
 188   }
 189   __ pop(SAVED_BASE_REGS);
 190   if (restore_lr) {
 191     __ pop(RegisterSet(FP) | RegisterSet(LR));
 192   } else {
 193     __ pop(RegisterSet(FP));
 194   }
 195 }
 196 
 197 
 198 static void push_result_registers(MacroAssembler* masm, BasicType ret_type) {
 199 #ifdef __ABI_HARD__
</pre>
<hr />
<pre>
 204   }
 205 #endif // __ABI_HARD__
 206   __ raw_push(R0, R1);
 207 }
 208 
 209 static void pop_result_registers(MacroAssembler* masm, BasicType ret_type) {
 210 #ifdef __ABI_HARD__
 211   if (ret_type == T_DOUBLE || ret_type == T_FLOAT) {
 212     __ fldd(D0, Address(SP));
 213     __ add(SP, SP, 8);
 214     return;
 215   }
 216 #endif // __ABI_HARD__
 217   __ raw_pop(R0, R1);
 218 }
 219 
 220 static void push_param_registers(MacroAssembler* masm, int fp_regs_in_arguments) {
 221   // R1-R3 arguments need to be saved, but we push 4 registers for 8-byte alignment
 222   __ push(RegisterSet(R0, R3));
 223 
<span class="line-removed"> 224 #ifdef __ABI_HARD__</span>
 225   // preserve arguments
 226   // Likely not needed as the locking code won&#39;t probably modify volatile FP registers,
 227   // but there is no way to guarantee that
 228   if (fp_regs_in_arguments) {
 229     // convert fp_regs_in_arguments to a number of double registers
 230     int double_regs_num = (fp_regs_in_arguments + 1) &gt;&gt; 1;
<span class="line-modified"> 231     __ fstmdbd(SP, FloatRegisterSet(D0, double_regs_num), writeback);</span>
 232   }
<span class="line-removed"> 233 #endif // __ ABI_HARD__</span>
 234 }
 235 
 236 static void pop_param_registers(MacroAssembler* masm, int fp_regs_in_arguments) {
<span class="line-removed"> 237 #ifdef __ABI_HARD__</span>
 238   if (fp_regs_in_arguments) {
 239     int double_regs_num = (fp_regs_in_arguments + 1) &gt;&gt; 1;
<span class="line-modified"> 240     __ fldmiad(SP, FloatRegisterSet(D0, double_regs_num), writeback);</span>
 241   }
<span class="line-removed"> 242 #endif // __ABI_HARD__</span>
<span class="line-removed"> 243 </span>
 244   __ pop(RegisterSet(R0, R3));
 245 }
 246 
 247 
 248 
 249 // Is vector&#39;s size (in bytes) bigger than a size saved by default?
 250 // All vector registers are saved by default on ARM.
 251 bool SharedRuntime::is_wide_vector(int size) {
 252   return false;
 253 }
 254 
 255 size_t SharedRuntime::trampoline_size() {
 256   return 16;
 257 }
 258 
 259 void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {
 260   InlinedAddress dest(destination);
 261   __ indirect_jump(dest, Rtemp);
 262   __ bind_literal(dest);
 263 }
</pre>
<hr />
<pre>
 445       regs[i].set_bad();
 446       break;
 447     default:
 448       ShouldNotReachHere();
 449     }
 450   }
 451 
 452   if (slot &amp; 1) slot++;
 453   return slot;
 454 }
 455 
 456 static void patch_callers_callsite(MacroAssembler *masm) {
 457   Label skip;
 458 
 459   __ ldr(Rtemp, Address(Rmethod, Method::code_offset()));
 460   __ cbz(Rtemp, skip);
 461 
 462   // Pushing an even number of registers for stack alignment.
 463   // Selecting R9, which had to be saved anyway for some platforms.
 464   __ push(RegisterSet(R0, R3) | R9 | LR);

 465 
 466   __ mov(R0, Rmethod);
 467   __ mov(R1, LR);
 468   __ call(CAST_FROM_FN_PTR(address, SharedRuntime::fixup_callers_callsite));
 469 

 470   __ pop(RegisterSet(R0, R3) | R9 | LR);
 471 
 472   __ bind(skip);
 473 }
 474 
 475 void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm,
 476                                     int total_args_passed, int comp_args_on_stack,
 477                                     const BasicType *sig_bt, const VMRegPair *regs) {
 478   // TODO: ARM - May be can use ldm to load arguments
 479   const Register tmp = Rtemp; // avoid erasing R5_mh
 480 
 481   // Next assert may not be needed but safer. Extra analysis required
 482   // if this there is not enough free registers and we need to use R5 here.
 483   assert_different_registers(tmp, R5_mh);
 484 
 485   // 6243940 We might end up in handle_wrong_method if
 486   // the callee is deoptimized as we race thru here. If that
 487   // happens we don&#39;t want to take a safepoint because the
 488   // caller frame will look interpreted and arguments are now
 489   // &quot;compiled&quot; so it is much better to make this transition
</pre>
</td>
<td>
<hr />
<pre>
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;asm/assembler.hpp&quot;
  27 #include &quot;assembler_arm.inline.hpp&quot;
  28 #include &quot;code/debugInfoRec.hpp&quot;
  29 #include &quot;code/icBuffer.hpp&quot;
  30 #include &quot;code/vtableStubs.hpp&quot;
  31 #include &quot;interpreter/interpreter.hpp&quot;
  32 #include &quot;logging/log.hpp&quot;
  33 #include &quot;memory/resourceArea.hpp&quot;
  34 #include &quot;oops/compiledICHolder.hpp&quot;
  35 #include &quot;oops/klass.inline.hpp&quot;
  36 #include &quot;runtime/sharedRuntime.hpp&quot;
  37 #include &quot;runtime/safepointMechanism.hpp&quot;
  38 #include &quot;runtime/vframeArray.hpp&quot;
  39 #include &quot;utilities/align.hpp&quot;
<span class="line-added">  40 #include &quot;utilities/powerOfTwo.hpp&quot;</span>
  41 #include &quot;vmreg_arm.inline.hpp&quot;
  42 #ifdef COMPILER1
  43 #include &quot;c1/c1_Runtime1.hpp&quot;
  44 #endif
  45 #ifdef COMPILER2
  46 #include &quot;opto/runtime.hpp&quot;
  47 #endif
  48 
  49 #define __ masm-&gt;
  50 
  51 class RegisterSaver {
  52 public:
  53 
  54   // Special registers:
  55   //              32-bit ARM     64-bit ARM
  56   //  Rthread:       R10            R28
  57   //  LR:            R14            R30
  58 
  59   // Rthread is callee saved in the C ABI and never changed by compiled code:
  60   // no need to save it.
</pre>
<hr />
<pre>
 117 
 118 
 119 
 120 
 121 OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm,
 122                                            int* total_frame_words,
 123                                            bool lr_saved) {
 124   *total_frame_words = reg_save_size;
 125 
 126   OopMapSet *oop_maps = new OopMapSet();
 127   OopMap* map = new OopMap(VMRegImpl::slots_per_word * (*total_frame_words), 0);
 128 
 129   if (lr_saved) {
 130     __ push(RegisterSet(FP));
 131   } else {
 132     __ push(RegisterSet(FP) | RegisterSet(LR));
 133   }
 134   __ push(SAVED_BASE_REGS);
 135   if (HaveVFP) {
 136     if (VM_Version::has_vfp3_32()) {
<span class="line-modified"> 137       __ fpush(FloatRegisterSet(D16, 16));</span>
 138     } else {
 139       if (FloatRegisterImpl::number_of_registers &gt; 32) {
 140         assert(FloatRegisterImpl::number_of_registers == 64, &quot;nb fp registers should be 64&quot;);
 141         __ sub(SP, SP, 32 * wordSize);
 142       }
 143     }
<span class="line-modified"> 144     __ fpush(FloatRegisterSet(D0, 16));</span>
 145   } else {
 146     __ sub(SP, SP, fpu_save_size * wordSize);
 147   }
 148 
 149   int i;
 150   int j=0;
 151   for (i = R0_offset; i &lt;= R9_offset; i++) {
 152     if (j == FP_REG_NUM) {
 153       // skip the FP register, managed below.
 154       j++;
 155     }
 156     map-&gt;set_callee_saved(VMRegImpl::stack2reg(i), as_Register(j)-&gt;as_VMReg());
 157     j++;
 158   }
 159   assert(j == R10-&gt;encoding(), &quot;must be&quot;);
 160 #if (FP_REG_NUM != 11)
 161   // add R11, if not managed as FP
 162   map-&gt;set_callee_saved(VMRegImpl::stack2reg(R11_offset), R11-&gt;as_VMReg());
 163 #endif
 164   map-&gt;set_callee_saved(VMRegImpl::stack2reg(R12_offset), R12-&gt;as_VMReg());
 165   map-&gt;set_callee_saved(VMRegImpl::stack2reg(R14_offset), R14-&gt;as_VMReg());
 166   if (HaveVFP) {
 167     for (i = 0; i &lt; (VM_Version::has_vfp3_32() ? 64 : 32); i+=2) {
 168       map-&gt;set_callee_saved(VMRegImpl::stack2reg(i), as_FloatRegister(i)-&gt;as_VMReg());
 169       map-&gt;set_callee_saved(VMRegImpl::stack2reg(i + 1), as_FloatRegister(i)-&gt;as_VMReg()-&gt;next());
 170     }
 171   }
 172 
 173   return map;
 174 }
 175 
 176 void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_lr) {
 177   if (HaveVFP) {
<span class="line-modified"> 178     __ fpop(FloatRegisterSet(D0, 16));</span>
 179     if (VM_Version::has_vfp3_32()) {
<span class="line-modified"> 180       __ fpop(FloatRegisterSet(D16, 16));</span>
 181     } else {
 182       if (FloatRegisterImpl::number_of_registers &gt; 32) {
 183         assert(FloatRegisterImpl::number_of_registers == 64, &quot;nb fp registers should be 64&quot;);
 184         __ add(SP, SP, 32 * wordSize);
 185       }
 186     }
 187   } else {
 188     __ add(SP, SP, fpu_save_size * wordSize);
 189   }
 190   __ pop(SAVED_BASE_REGS);
 191   if (restore_lr) {
 192     __ pop(RegisterSet(FP) | RegisterSet(LR));
 193   } else {
 194     __ pop(RegisterSet(FP));
 195   }
 196 }
 197 
 198 
 199 static void push_result_registers(MacroAssembler* masm, BasicType ret_type) {
 200 #ifdef __ABI_HARD__
</pre>
<hr />
<pre>
 205   }
 206 #endif // __ABI_HARD__
 207   __ raw_push(R0, R1);
 208 }
 209 
 210 static void pop_result_registers(MacroAssembler* masm, BasicType ret_type) {
 211 #ifdef __ABI_HARD__
 212   if (ret_type == T_DOUBLE || ret_type == T_FLOAT) {
 213     __ fldd(D0, Address(SP));
 214     __ add(SP, SP, 8);
 215     return;
 216   }
 217 #endif // __ABI_HARD__
 218   __ raw_pop(R0, R1);
 219 }
 220 
 221 static void push_param_registers(MacroAssembler* masm, int fp_regs_in_arguments) {
 222   // R1-R3 arguments need to be saved, but we push 4 registers for 8-byte alignment
 223   __ push(RegisterSet(R0, R3));
 224 

 225   // preserve arguments
 226   // Likely not needed as the locking code won&#39;t probably modify volatile FP registers,
 227   // but there is no way to guarantee that
 228   if (fp_regs_in_arguments) {
 229     // convert fp_regs_in_arguments to a number of double registers
 230     int double_regs_num = (fp_regs_in_arguments + 1) &gt;&gt; 1;
<span class="line-modified"> 231     __ fpush_hardfp(FloatRegisterSet(D0, double_regs_num));</span>
 232   }

 233 }
 234 
 235 static void pop_param_registers(MacroAssembler* masm, int fp_regs_in_arguments) {

 236   if (fp_regs_in_arguments) {
 237     int double_regs_num = (fp_regs_in_arguments + 1) &gt;&gt; 1;
<span class="line-modified"> 238     __ fpop_hardfp(FloatRegisterSet(D0, double_regs_num));</span>
 239   }


 240   __ pop(RegisterSet(R0, R3));
 241 }
 242 
 243 
 244 
 245 // Is vector&#39;s size (in bytes) bigger than a size saved by default?
 246 // All vector registers are saved by default on ARM.
 247 bool SharedRuntime::is_wide_vector(int size) {
 248   return false;
 249 }
 250 
 251 size_t SharedRuntime::trampoline_size() {
 252   return 16;
 253 }
 254 
 255 void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {
 256   InlinedAddress dest(destination);
 257   __ indirect_jump(dest, Rtemp);
 258   __ bind_literal(dest);
 259 }
</pre>
<hr />
<pre>
 441       regs[i].set_bad();
 442       break;
 443     default:
 444       ShouldNotReachHere();
 445     }
 446   }
 447 
 448   if (slot &amp; 1) slot++;
 449   return slot;
 450 }
 451 
 452 static void patch_callers_callsite(MacroAssembler *masm) {
 453   Label skip;
 454 
 455   __ ldr(Rtemp, Address(Rmethod, Method::code_offset()));
 456   __ cbz(Rtemp, skip);
 457 
 458   // Pushing an even number of registers for stack alignment.
 459   // Selecting R9, which had to be saved anyway for some platforms.
 460   __ push(RegisterSet(R0, R3) | R9 | LR);
<span class="line-added"> 461   __ fpush_hardfp(FloatRegisterSet(D0, 8));</span>
 462 
 463   __ mov(R0, Rmethod);
 464   __ mov(R1, LR);
 465   __ call(CAST_FROM_FN_PTR(address, SharedRuntime::fixup_callers_callsite));
 466 
<span class="line-added"> 467   __ fpop_hardfp(FloatRegisterSet(D0, 8));</span>
 468   __ pop(RegisterSet(R0, R3) | R9 | LR);
 469 
 470   __ bind(skip);
 471 }
 472 
 473 void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm,
 474                                     int total_args_passed, int comp_args_on_stack,
 475                                     const BasicType *sig_bt, const VMRegPair *regs) {
 476   // TODO: ARM - May be can use ldm to load arguments
 477   const Register tmp = Rtemp; // avoid erasing R5_mh
 478 
 479   // Next assert may not be needed but safer. Extra analysis required
 480   // if this there is not enough free registers and we need to use R5 here.
 481   assert_different_registers(tmp, R5_mh);
 482 
 483   // 6243940 We might end up in handle_wrong_method if
 484   // the callee is deoptimized as we race thru here. If that
 485   // happens we don&#39;t want to take a safepoint because the
 486   // caller frame will look interpreted and arguments are now
 487   // &quot;compiled&quot; so it is much better to make this transition
</pre>
</td>
</tr>
</table>
<center><a href="macroAssembler_arm.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_arm.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>