<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/jdk.internal.vm.compiler/.mx.graal/sanitycheck.py</title>
    <link rel="stylesheet" href="../../../style.css" />
  </head>
  <body>
    <pre>
  1 # ----------------------------------------------------------------------------------------------------
  2 #
  3 # Copyright (c) 2007, 2012, Oracle and/or its affiliates. All rights reserved.
  4 # DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5 #
  6 # This code is free software; you can redistribute it and/or modify it
  7 # under the terms of the GNU General Public License version 2 only, as
  8 # published by the Free Software Foundation.
  9 #
 10 # This code is distributed in the hope that it will be useful, but WITHOUT
 11 # ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12 # FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13 # version 2 for more details (a copy is included in the LICENSE file that
 14 # accompanied this code).
 15 #
 16 # You should have received a copy of the GNU General Public License version
 17 # 2 along with this work; if not, write to the Free Software Foundation,
 18 # Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19 #
 20 # Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21 # or visit www.oracle.com if you need additional information or have any
 22 # questions.
 23 #
 24 # ----------------------------------------------------------------------------------------------------
 25 
 26 from outputparser import OutputParser, ValuesMatcher
 27 import re, mx, mx_graal, os, sys, StringIO, subprocess
 28 from os.path import isfile, join, exists
 29 
 30 gc = &#39;UseSerialGC&#39;
 31 
 32 dacapoSanityWarmup = {
 33     &#39;avrora&#39;:     [0, 0, 3, 6, 13],
 34     &#39;batik&#39;:      [0, 0, 5, 5, 20],
 35     &#39;eclipse&#39;:    [0, 0, 0, 0, 0],
 36     &#39;fop&#39;:        [4, 8, 10, 20, 30],
 37     &#39;h2&#39;:         [0, 0, 5, 5, 8],
 38     &#39;jython&#39;:     [0, 0, 5, 10, 13],
 39     &#39;luindex&#39;:    [0, 0, 5, 10, 10],
 40     &#39;lusearch&#39;:   [0, 4, 5, 5, 8],
 41     &#39;pmd&#39;:        [0, 0, 5, 10, 13],
 42     &#39;sunflow&#39;:    [0, 2, 5, 10, 15],
 43     &#39;tomcat&#39;:     [0, 0, 5, 10, 15],
 44     &#39;tradebeans&#39;: [0, 0, 5, 10, 13],
 45     &#39;tradesoap&#39;:  [0, 0, 5, 10, 15],
 46     &#39;xalan&#39;:      [0, 0, 5, 10, 18],
 47 }
 48 
 49 dacapoScalaSanityWarmup = {
 50     &#39;actors&#39;:     [0, 0, 2, 5, 5],
 51     &#39;apparat&#39;:    [0, 0, 2, 5, 5],
 52     &#39;factorie&#39;:   [0, 0, 2, 5, 5],
 53     &#39;kiama&#39;:      [0, 4, 3, 13, 15],
 54     &#39;scalac&#39;:     [0, 0, 5, 15, 20],
 55     &#39;scaladoc&#39;:   [0, 0, 5, 15, 15],
 56     &#39;scalap&#39;:     [0, 0, 5, 15, 20],
 57     &#39;scalariform&#39;:[0, 0, 6, 15, 20],
 58     &#39;scalatest&#39;:  [0, 0, 2, 10, 12],
 59     &#39;scalaxb&#39;:    [0, 0, 5, 15, 25],
 60 # (gdub) specs sometimes returns a non-zero value event though there is no apparent failure
 61     &#39;specs&#39;:      [0, 0, 0, 0, 0],
 62     &#39;tmt&#39;:        [0, 0, 3, 10, 12]
 63 }
 64 
 65 dacapoGateBuildLevels = {
 66     &#39;avrora&#39;:     [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 67     &#39;batik&#39;:      [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 68     # (lewurm): does not work with JDK8
 69     &#39;eclipse&#39;:    [],
 70     &#39;fop&#39;:        [&#39;fastdebug&#39;, &#39;debug&#39;],
 71     &#39;h2&#39;:         [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 72     &#39;jython&#39;:     [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 73     &#39;luindex&#39;:    [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 74     &#39;lusearch&#39;:   [&#39;product&#39;],
 75     &#39;pmd&#39;:        [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 76     &#39;sunflow&#39;:    [&#39;fastdebug&#39;, &#39;debug&#39;],
 77     &#39;tomcat&#39;:     [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 78     &#39;tradebeans&#39;: [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 79     # tradesoap is too unreliable for the gate, often crashing with concurrency problems:
 80     # http://sourceforge.net/p/dacapobench/bugs/99/
 81     &#39;tradesoap&#39;:  [],
 82     &#39;xalan&#39;:      [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 83 }
 84 
 85 dacapoScalaGateBuildLevels = {
 86     &#39;actors&#39;:     [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 87     &#39;apparat&#39;:    [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 88     &#39;factorie&#39;:   [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 89     &#39;kiama&#39;:      [&#39;fastdebug&#39;, &#39;debug&#39;],
 90     &#39;scalac&#39;:     [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 91     &#39;scaladoc&#39;:   [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 92     &#39;scalap&#39;:     [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 93     &#39;scalariform&#39;:[&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 94     &#39;scalatest&#39;:  [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 95     &#39;scalaxb&#39;:    [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 96     &#39;specs&#39;:      [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 97     &#39;tmt&#39;:        [&#39;product&#39;, &#39;fastdebug&#39;, &#39;debug&#39;],
 98 }
 99 
100 specjvm2008Names = [
101     &#39;startup.helloworld&#39;,
102     &#39;startup.compiler.compiler&#39;,
103     &#39;startup.compiler.sunflow&#39;,
104     &#39;startup.compress&#39;,
105     &#39;startup.crypto.aes&#39;,
106     &#39;startup.crypto.rsa&#39;,
107     &#39;startup.crypto.signverify&#39;,
108     &#39;startup.mpegaudio&#39;,
109     &#39;startup.scimark.fft&#39;,
110     &#39;startup.scimark.lu&#39;,
111     &#39;startup.scimark.monte_carlo&#39;,
112     &#39;startup.scimark.sor&#39;,
113     &#39;startup.scimark.sparse&#39;,
114     &#39;startup.serial&#39;,
115     &#39;startup.sunflow&#39;,
116     &#39;startup.xml.transform&#39;,
117     &#39;startup.xml.validation&#39;,
118     &#39;compiler.compiler&#39;,
119     &#39;compiler.sunflow&#39;,
120     &#39;compress&#39;,
121     &#39;crypto.aes&#39;,
122     &#39;crypto.rsa&#39;,
123     &#39;crypto.signverify&#39;,
124     &#39;derby&#39;,
125     &#39;mpegaudio&#39;,
126     &#39;scimark.fft.large&#39;,
127     &#39;scimark.lu.large&#39;,
128     &#39;scimark.sor.large&#39;,
129     &#39;scimark.sparse.large&#39;,
130     &#39;scimark.fft.small&#39;,
131     &#39;scimark.lu.small&#39;,
132     &#39;scimark.sor.small&#39;,
133     &#39;scimark.sparse.small&#39;,
134     &#39;scimark.monte_carlo&#39;,
135     &#39;serial&#39;,
136     &#39;sunflow&#39;,
137     &#39;xml.transform&#39;,
138     &#39;xml.validation&#39;
139 ]
140 
141 def _noneAsEmptyList(a):
142     if a is None:
143         return []
144     return a
145 
146 class SanityCheckLevel:
147     Fast, Gate, Normal, Extensive, Benchmark = range(5)
148 
149 def getSPECjbb2005(benchArgs=None):
150     benchArgs = [] if benchArgs is None else benchArgs
151 
152     specjbb2005 = mx.get_env(&#39;SPECJBB2005&#39;)
153     if specjbb2005 is None or not exists(join(specjbb2005, &#39;jbb.jar&#39;)):
154         mx.abort(&#39;Please set the SPECJBB2005 environment variable to a SPECjbb2005 directory&#39;)
155 
156     score = re.compile(r&quot;^Valid run, Score is  (?P&lt;score&gt;[0-9]+)$&quot;, re.MULTILINE)
157     error = re.compile(r&quot;VALIDATION ERROR&quot;)
158     success = re.compile(r&quot;^Valid run, Score is  [0-9]+$&quot;, re.MULTILINE)
159     matcher = ValuesMatcher(score, {&#39;group&#39; : &#39;SPECjbb2005&#39;, &#39;name&#39; : &#39;score&#39;, &#39;score&#39; : &#39;&lt;score&gt;&#39;})
160     classpath = [&#39;jbb.jar&#39;, &#39;check.jar&#39;]
161     return Test(&quot;SPECjbb2005&quot;, [&#39;spec.jbb.JBBmain&#39;, &#39;-propfile&#39;, &#39;SPECjbb.props&#39;] + benchArgs, [success], [error], [matcher], vmOpts=[&#39;-Xms3g&#39;, &#39;-XX:+&#39; + gc, &#39;-XX:-UseCompressedOops&#39;, &#39;-cp&#39;, os.pathsep.join(classpath)], defaultCwd=specjbb2005)
162 
163 def getSPECjbb2013(benchArgs=None):
164 
165     specjbb2013 = mx.get_env(&#39;SPECJBB2013&#39;)
166     if specjbb2013 is None or not exists(join(specjbb2013, &#39;specjbb2013.jar&#39;)):
167         mx.abort(&#39;Please set the SPECJBB2013 environment variable to a SPECjbb2013 directory&#39;)
168 
169     jops = re.compile(r&quot;^RUN RESULT: hbIR \(max attempted\) = [0-9]+, hbIR \(settled\) = [0-9]+, max-jOPS = (?P&lt;max&gt;[0-9]+), critical-jOPS = (?P&lt;critical&gt;[0-9]+)$&quot;, re.MULTILINE)
170     # error?
171     success = re.compile(r&quot;org.spec.jbb.controller: Run finished&quot;, re.MULTILINE)
172     matcherMax = ValuesMatcher(jops, {&#39;group&#39; : &#39;SPECjbb2013&#39;, &#39;name&#39; : &#39;max&#39;, &#39;score&#39; : &#39;&lt;max&gt;&#39;})
173     matcherCritical = ValuesMatcher(jops, {&#39;group&#39; : &#39;SPECjbb2013&#39;, &#39;name&#39; : &#39;critical&#39;, &#39;score&#39; : &#39;&lt;critical&gt;&#39;})
174     return Test(&quot;SPECjbb2013&quot;, [&#39;-jar&#39;, &#39;specjbb2013.jar&#39;, &#39;-m&#39;, &#39;composite&#39;] +
175                 _noneAsEmptyList(benchArgs), [success], [], [matcherCritical, matcherMax],
176                 vmOpts=[&#39;-Xmx6g&#39;, &#39;-Xms6g&#39;, &#39;-Xmn3g&#39;, &#39;-XX:+UseParallelOldGC&#39;, &#39;-XX:-UseAdaptiveSizePolicy&#39;, &#39;-XX:-UseBiasedLocking&#39;, &#39;-XX:-UseCompressedOops&#39;], defaultCwd=specjbb2013)
177 
178 def getSPECjbb2015(benchArgs=None):
179 
180     specjbb2015 = mx.get_env(&#39;SPECJBB2015&#39;)
181     if specjbb2015 is None or not exists(join(specjbb2015, &#39;specjbb2015.jar&#39;)):
182         mx.abort(&#39;Please set the SPECJBB2015 environment variable to a SPECjbb2015 directory&#39;)
183 
184     jops = re.compile(r&quot;^RUN RESULT: hbIR \(max attempted\) = [0-9]+, hbIR \(settled\) = [0-9]+, max-jOPS = (?P&lt;max&gt;[0-9]+), critical-jOPS = (?P&lt;critical&gt;[0-9]+)$&quot;, re.MULTILINE)
185     # error?
186     success = re.compile(r&quot;org.spec.jbb.controller: Run finished&quot;, re.MULTILINE)
187     matcherMax = ValuesMatcher(jops, {&#39;group&#39; : &#39;SPECjbb2015&#39;, &#39;name&#39; : &#39;max&#39;, &#39;score&#39; : &#39;&lt;max&gt;&#39;})
188     matcherCritical = ValuesMatcher(jops, {&#39;group&#39; : &#39;SPECjbb2015&#39;, &#39;name&#39; : &#39;critical&#39;, &#39;score&#39; : &#39;&lt;critical&gt;&#39;})
189     return Test(&quot;SPECjbb2015&quot;, [&#39;-jar&#39;, &#39;specjbb2015.jar&#39;, &#39;-m&#39;, &#39;composite&#39;] +
190                 _noneAsEmptyList(benchArgs), [success], [], [matcherCritical, matcherMax],
191                 vmOpts=[&#39;-Xmx6g&#39;, &#39;-Xms6g&#39;, &#39;-Xmn3g&#39;, &#39;-XX:+UseParallelOldGC&#39;, &#39;-XX:-UseAdaptiveSizePolicy&#39;, &#39;-XX:-UseBiasedLocking&#39;, &#39;-XX:-UseCompressedOops&#39;], defaultCwd=specjbb2015)
192 
193 def getSPECjvm2008(benchArgs=None):
194 
195     specjvm2008 = mx.get_env(&#39;SPECJVM2008&#39;)
196     if specjvm2008 is None or not exists(join(specjvm2008, &#39;SPECjvm2008.jar&#39;)):
197         mx.abort(&#39;Please set the SPECJVM2008 environment variable to a SPECjvm2008 directory&#39;)
198 
199     score = re.compile(r&quot;^(Score on|Noncompliant) (?P&lt;benchmark&gt;[a-zA-Z0-9\._]+)( result)?: (?P&lt;score&gt;[0-9]+((,|\.)[0-9]+)?)( SPECjvm2008 Base)? ops/m$&quot;, re.MULTILINE)
200     error = re.compile(r&quot;^Errors in benchmark: &quot;, re.MULTILINE)
201     # The &#39; ops/m&#39; at the end of the success string is important : it&#39;s how you can tell valid and invalid runs apart
202     success = re.compile(r&quot;^(Noncompliant c|C)omposite result: [0-9]+((,|\.)[0-9]+)?( SPECjvm2008 (Base|Peak))? ops/m$&quot;, re.MULTILINE)
203     matcher = ValuesMatcher(score, {&#39;group&#39; : &#39;SPECjvm2008&#39;, &#39;name&#39; : &#39;&lt;benchmark&gt;&#39;, &#39;score&#39; : &#39;&lt;score&gt;&#39;})
204 
205     return Test(&quot;SPECjvm2008&quot;, [&#39;-jar&#39;, &#39;SPECjvm2008.jar&#39;] + _noneAsEmptyList(benchArgs), [success], [error], [matcher], vmOpts=[&#39;-Xms3g&#39;, &#39;-XX:+&#39; + gc, &#39;-XX:-UseCompressedOops&#39;], defaultCwd=specjvm2008)
206 
207 def getDacapos(level=SanityCheckLevel.Normal, gateBuildLevel=None, dacapoArgs=None, extraVmArguments=None):
208     checks = []
209 
210     for (bench, ns) in dacapoSanityWarmup.items():
211         if ns[level] &gt; 0:
212             if gateBuildLevel is None or gateBuildLevel in dacapoGateBuildLevels[bench]:
213                 checks.append(getDacapo(bench, [&#39;-n&#39;, str(ns[level])] + _noneAsEmptyList(dacapoArgs), extraVmArguments=extraVmArguments))
214 
215     return checks
216 
217 def getDacapo(name, dacapoArgs=None, extraVmArguments=None):
218     dacapo = mx.get_env(&#39;DACAPO_CP&#39;)
219     if dacapo is None:
220         l = mx.library(&#39;DACAPO&#39;, False)
221         if l is not None:
222             dacapo = l.get_path(True)
223         else:
224             mx.abort(&#39;DaCapo 9.12 jar file must be specified with DACAPO_CP environment variable or as DACAPO library&#39;)
225 
226     if not isfile(dacapo) or not dacapo.endswith(&#39;.jar&#39;):
227         mx.abort(&#39;Specified DaCapo jar file does not exist or is not a jar file: &#39; + dacapo)
228 
229     dacapoSuccess = re.compile(r&quot;^===== DaCapo 9\.12 ([a-zA-Z0-9_]+) PASSED in ([0-9]+) msec =====&quot;, re.MULTILINE)
230     dacapoFail = re.compile(r&quot;^===== DaCapo 9\.12 ([a-zA-Z0-9_]+) FAILED (warmup|) =====&quot;, re.MULTILINE)
231     dacapoTime = re.compile(r&quot;===== DaCapo 9\.12 (?P&lt;benchmark&gt;[a-zA-Z0-9_]+) PASSED in (?P&lt;time&gt;[0-9]+) msec =====&quot;)
232     dacapoTime1 = re.compile(r&quot;===== DaCapo 9\.12 (?P&lt;benchmark&gt;[a-zA-Z0-9_]+) completed warmup 1 in (?P&lt;time&gt;[0-9]+) msec =====&quot;)
233 
234     dacapoMatcher = ValuesMatcher(dacapoTime, {&#39;group&#39; : &#39;DaCapo&#39;, &#39;name&#39; : &#39;&lt;benchmark&gt;&#39;, &#39;score&#39; : &#39;&lt;time&gt;&#39;})
235     dacapoMatcher1 = ValuesMatcher(dacapoTime1, {&#39;group&#39; : &#39;DaCapo-1stRun&#39;, &#39;name&#39; : &#39;&lt;benchmark&gt;&#39;, &#39;score&#39; : &#39;&lt;time&gt;&#39;})
236 
237     # Use ipv4 stack for dacapos; tomcat+solaris+ipv6_interface fails (see also: JDK-8072384)
238     return Test(&quot;DaCapo-&quot; + name, [&#39;-jar&#39;, mx._cygpathU2W(dacapo), name] + _noneAsEmptyList(dacapoArgs), [dacapoSuccess], [dacapoFail],
239                 [dacapoMatcher, dacapoMatcher1],
240                 [&#39;-Xms2g&#39;, &#39;-XX:+&#39; + gc, &#39;-XX:-UseCompressedOops&#39;, &quot;-Djava.net.preferIPv4Stack=true&quot;, &#39;-G:+ExitVMOnException&#39;] +
241                 _noneAsEmptyList(extraVmArguments))
242 
243 def getScalaDacapos(level=SanityCheckLevel.Normal, gateBuildLevel=None, dacapoArgs=None, extraVmArguments=None):
244     checks = []
245 
246     for (bench, ns) in dacapoScalaSanityWarmup.items():
247         if ns[level] &gt; 0:
248             if gateBuildLevel is None or gateBuildLevel in dacapoScalaGateBuildLevels[bench]:
249                 checks.append(getScalaDacapo(bench, [&#39;-n&#39;, str(ns[level])] + _noneAsEmptyList(dacapoArgs), extraVmArguments=extraVmArguments))
250 
251     return checks
252 
253 def getScalaDacapo(name, dacapoArgs=None, extraVmArguments=None):
254     dacapo = mx.get_env(&#39;DACAPO_SCALA_CP&#39;)
255     if dacapo is None:
256         l = mx.library(&#39;DACAPO_SCALA&#39;, False)
257         if l is not None:
258             dacapo = l.get_path(True)
259         else:
260             mx.abort(&#39;Scala DaCapo 0.1.0 jar file must be specified with DACAPO_SCALA_CP environment variable or as DACAPO_SCALA library&#39;)
261 
262     if not isfile(dacapo) or not dacapo.endswith(&#39;.jar&#39;):
263         mx.abort(&#39;Specified Scala DaCapo jar file does not exist or is not a jar file: &#39; + dacapo)
264 
265     dacapoSuccess = re.compile(r&quot;^===== DaCapo 0\.1\.0(-SNAPSHOT)? ([a-zA-Z0-9_]+) PASSED in ([0-9]+) msec =====&quot;, re.MULTILINE)
266     dacapoFail = re.compile(r&quot;^===== DaCapo 0\.1\.0(-SNAPSHOT)? ([a-zA-Z0-9_]+) FAILED (warmup|) =====&quot;, re.MULTILINE)
267     dacapoTime = re.compile(r&quot;===== DaCapo 0\.1\.0(-SNAPSHOT)? (?P&lt;benchmark&gt;[a-zA-Z0-9_]+) PASSED in (?P&lt;time&gt;[0-9]+) msec =====&quot;)
268 
269     dacapoMatcher = ValuesMatcher(dacapoTime, {&#39;group&#39; : &quot;Scala-DaCapo&quot;, &#39;name&#39; : &#39;&lt;benchmark&gt;&#39;, &#39;score&#39; : &#39;&lt;time&gt;&#39;})
270 
271     return Test(&quot;Scala-DaCapo-&quot; + name, [&#39;-jar&#39;, mx._cygpathU2W(dacapo), name] + _noneAsEmptyList(dacapoArgs), [dacapoSuccess], [dacapoFail], [dacapoMatcher], [&#39;-Xms2g&#39;, &#39;-XX:+&#39; + gc, &#39;-XX:-UseCompressedOops&#39;] + _noneAsEmptyList(extraVmArguments))
272 
273 def getBootstraps():
274     time = re.compile(r&quot;Bootstrapping Graal\.+ in (?P&lt;time&gt;[0-9]+) ms( \(compiled (?P&lt;methods&gt;[0-9]+) methods\))?&quot;)
275     scoreMatcher = ValuesMatcher(time, {&#39;group&#39; : &#39;Bootstrap&#39;, &#39;name&#39; : &#39;BootstrapTime&#39;, &#39;score&#39; : &#39;&lt;time&gt;&#39;})
276     methodMatcher = ValuesMatcher(time, {&#39;group&#39; : &#39;Bootstrap&#39;, &#39;name&#39; : &#39;BootstrapMethods&#39;, &#39;score&#39; : &#39;&lt;methods&gt;&#39;})
277     scoreMatcherBig = ValuesMatcher(time, {&#39;group&#39; : &#39;Bootstrap-bigHeap&#39;, &#39;name&#39; : &#39;BootstrapTime&#39;, &#39;score&#39; : &#39;&lt;time&gt;&#39;})
278     methodMatcherBig = ValuesMatcher(time, {&#39;group&#39; : &#39;Bootstrap-bigHeap&#39;, &#39;name&#39; : &#39;BootstrapMethods&#39;, &#39;score&#39; : &#39;&lt;methods&gt;&#39;})
279 
280     tests = []
281     tests.append(Test(&quot;Bootstrap&quot;, [&#39;-version&#39;], successREs=[time], scoreMatchers=[scoreMatcher, methodMatcher], ignoredVMs=[&#39;client&#39;, &#39;server&#39;], benchmarkCompilationRate=False))
282     tests.append(Test(&quot;Bootstrap-bigHeap&quot;, [&#39;-version&#39;], successREs=[time], scoreMatchers=[scoreMatcherBig, methodMatcherBig], vmOpts=[&#39;-Xms2g&#39;], ignoredVMs=[&#39;client&#39;, &#39;server&#39;], benchmarkCompilationRate=False))
283     return tests
284 
285 class CTWMode:
286     Full, NoInline = range(2)
287 
288 def getCTW(vm, mode):
289     time = re.compile(r&quot;CompileTheWorld : Done \([0-9]+ classes, [0-9]+ methods, (?P&lt;time&gt;[0-9]+) ms\)&quot;)
290     scoreMatcher = ValuesMatcher(time, {&#39;group&#39; : &#39;CompileTheWorld&#39;, &#39;name&#39; : &#39;CompileTime&#39;, &#39;score&#39; : &#39;&lt;time&gt;&#39;})
291 
292     jre = os.environ.get(&#39;JAVA_HOME&#39;)
293     if exists(join(jre, &#39;jre&#39;)):
294         jre = join(jre, &#39;jre&#39;)
295     rtjar = join(jre, &#39;lib&#39;, &#39;rt.jar&#39;)
296 
297 
298     args = [&#39;-XX:+CompileTheWorld&#39;, &#39;-Xbootclasspath/p:&#39; + rtjar]
299     if vm == &#39;jvmci&#39;:
300         args += [&#39;-XX:+BootstrapGraal&#39;]
301     if mode &gt;= CTWMode.NoInline:
302         if not mx_graal.isJVMCIEnabled(vm):
303             args.append(&#39;-XX:-Inline&#39;)
304         else:
305             args.append(&#39;-G:CompileTheWordConfig=-Inline&#39;)
306 
307     return Test(&quot;CompileTheWorld&quot;, args, successREs=[time], scoreMatchers=[scoreMatcher], benchmarkCompilationRate=False)
308 
309 
310 class Tee:
311     def __init__(self):
312         self.output = StringIO.StringIO()
313     def eat(self, line):
314         self.output.write(line)
315         sys.stdout.write(line)
316 
317 &quot;&quot;&quot;
318 Encapsulates a single program that is a sanity test and/or a benchmark.
319 &quot;&quot;&quot;
320 class Test:
321     def __init__(self, name, cmd, successREs=None, failureREs=None, scoreMatchers=None, vmOpts=None, defaultCwd=None, ignoredVMs=None, benchmarkCompilationRate=False):
322 
323         self.name = name
324         self.successREs = _noneAsEmptyList(successREs)
325         self.failureREs = _noneAsEmptyList(failureREs) + [re.compile(r&quot;Exception occurred in scope: &quot;)]
326         self.scoreMatchers = _noneAsEmptyList(scoreMatchers)
327         self.vmOpts = _noneAsEmptyList(vmOpts)
328         self.cmd = cmd
329         self.defaultCwd = defaultCwd
330         self.ignoredVMs = _noneAsEmptyList(ignoredVMs)
331         self.benchmarkCompilationRate = benchmarkCompilationRate
332         if benchmarkCompilationRate:
333             self.vmOpts = self.vmOpts + [&#39;-XX:+CITime&#39;]
334 
335     def __str__(self):
336         return self.name
337 
338     def test(self, vm, cwd=None, extraVmOpts=None, vmbuild=None):
339         &quot;&quot;&quot;
340         Run this program as a sanity test.
341         &quot;&quot;&quot;
342         if vm in self.ignoredVMs:
343             return True
344         if cwd is None:
345             cwd = self.defaultCwd
346         parser = OutputParser()
347         jvmError = re.compile(r&quot;(?P&lt;jvmerror&gt;([A-Z]:|/).*[/\\]hs_err_pid[0-9]+\.log)&quot;)
348         parser.addMatcher(ValuesMatcher(jvmError, {&#39;jvmError&#39; : &#39;&lt;jvmerror&gt;&#39;}))
349 
350         for successRE in self.successREs:
351             parser.addMatcher(ValuesMatcher(successRE, {&#39;passed&#39; : &#39;1&#39;}))
352         for failureRE in self.failureREs:
353             parser.addMatcher(ValuesMatcher(failureRE, {&#39;failed&#39; : &#39;1&#39;}))
354 
355         tee = Tee()
356         retcode = mx_graal.run_vm(self.vmOpts + _noneAsEmptyList(extraVmOpts) + self.cmd, vm, nonZeroIsFatal=False, out=tee.eat, err=subprocess.STDOUT, cwd=cwd, debugLevel=vmbuild)
357         output = tee.output.getvalue()
358         valueMaps = parser.parse(output)
359 
360         if len(valueMaps) == 0:
361             return False
362 
363         record = {}
364         for valueMap in valueMaps:
365             for key, value in valueMap.items():
366                 if record.has_key(key) and record[key] != value:
367                     mx.abort(&#39;Inconsistant values returned by test machers : &#39; + str(valueMaps))
368                 record[key] = value
369 
370         jvmErrorFile = record.get(&#39;jvmError&#39;)
371         if jvmErrorFile:
372             mx.log(&#39;/!\\JVM Error : dumping error log...&#39;)
373             with open(jvmErrorFile, &#39;rb&#39;) as fp:
374                 mx.log(fp.read())
375             os.unlink(jvmErrorFile)
376             return False
377 
378         if record.get(&#39;failed&#39;) == &#39;1&#39;:
379             return False
380 
381         return retcode == 0 and record.get(&#39;passed&#39;) == &#39;1&#39;
382 
383     def bench(self, vm, cwd=None, extraVmOpts=None, vmbuild=None):
384         &quot;&quot;&quot;
385         Run this program as a benchmark.
386         &quot;&quot;&quot;
387         if vm in self.ignoredVMs:
388             return {}
389         if cwd is None:
390             cwd = self.defaultCwd
391         parser = OutputParser()
392 
393         for successRE in self.successREs:
394             parser.addMatcher(ValuesMatcher(successRE, {&#39;passed&#39; : &#39;1&#39;}))
395         for failureRE in self.failureREs:
396             parser.addMatcher(ValuesMatcher(failureRE, {&#39;failed&#39; : &#39;1&#39;}))
397         for scoreMatcher in self.scoreMatchers:
398             parser.addMatcher(scoreMatcher)
399 
400         if self.benchmarkCompilationRate:
401             if vm == &#39;jvmci&#39;:
402                 bps = re.compile(r&quot;ParsedBytecodesPerSecond@final: (?P&lt;rate&gt;[0-9]+)&quot;)
403                 ibps = re.compile(r&quot;InlinedBytecodesPerSecond@final: (?P&lt;rate&gt;[0-9]+)&quot;)
404                 parser.addMatcher(ValuesMatcher(bps, {&#39;group&#39; : &#39;ParsedBytecodesPerSecond&#39;, &#39;name&#39; : self.name, &#39;score&#39; : &#39;&lt;rate&gt;&#39;}))
405                 parser.addMatcher(ValuesMatcher(ibps, {&#39;group&#39; : &#39;InlinedBytecodesPerSecond&#39;, &#39;name&#39; : self.name, &#39;score&#39; : &#39;&lt;rate&gt;&#39;}))
406             else:
407                 ibps = re.compile(r&quot;(?P&lt;compiler&gt;[\w]+) compilation speed: +(?P&lt;rate&gt;[0-9]+) bytes/s {standard&quot;)
408                 parser.addMatcher(ValuesMatcher(ibps, {&#39;group&#39; : &#39;InlinedBytecodesPerSecond&#39;, &#39;name&#39; : &#39;&lt;compiler&gt;:&#39; + self.name, &#39;score&#39; : &#39;&lt;rate&gt;&#39;}))
409 
410         startDelim = &#39;START: &#39; + self.name
411         endDelim = &#39;END: &#39; + self.name
412 
413         outputfile = os.environ.get(&#39;BENCH_OUTPUT&#39;, None)
414         if outputfile:
415             # Used only to debug output parsing
416             with open(outputfile) as fp:
417                 output = fp.read()
418                 start = output.find(startDelim)
419                 end = output.find(endDelim, start)
420                 if start == -1 and end == -1:
421                     return {}
422                 output = output[start + len(startDelim + os.linesep): end]
423                 mx.log(startDelim)
424                 mx.log(output)
425                 mx.log(endDelim)
426         else:
427             tee = Tee()
428             mx.log(startDelim)
429             if mx_graal.run_vm(self.vmOpts + _noneAsEmptyList(extraVmOpts) + self.cmd, vm, nonZeroIsFatal=False, out=tee.eat, err=subprocess.STDOUT, cwd=cwd, debugLevel=vmbuild) != 0:
430                 mx.abort(&quot;Benchmark failed (non-zero retcode)&quot;)
431             mx.log(endDelim)
432             output = tee.output.getvalue()
433 
434         groups = {}
435         passed = False
436         for valueMap in parser.parse(output):
437             assert (valueMap.has_key(&#39;name&#39;) and valueMap.has_key(&#39;score&#39;) and valueMap.has_key(&#39;group&#39;)) or valueMap.has_key(&#39;passed&#39;) or valueMap.has_key(&#39;failed&#39;), valueMap
438             if valueMap.get(&#39;failed&#39;) == &#39;1&#39;:
439                 mx.abort(&quot;Benchmark failed&quot;)
440             if valueMap.get(&#39;passed&#39;) == &#39;1&#39;:
441                 passed = True
442             groupName = valueMap.get(&#39;group&#39;)
443             if groupName:
444                 group = groups.setdefault(groupName, {})
445                 name = valueMap.get(&#39;name&#39;)
446                 score = valueMap.get(&#39;score&#39;)
447                 if name and score:
448                     group[name] = score
449 
450         if not passed:
451             mx.abort(&quot;Benchmark failed (not passed)&quot;)
452 
453         return groups
    </pre>
  </body>
</html>