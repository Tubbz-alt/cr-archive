diff a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
@@ -191,11 +191,11 @@
     __ push_reg(opr->as_register_lo());
   } else if (opr->is_stack()) {
     __ push_addr(frame_map()->address_for_slot(opr->single_stack_ix()));
   } else if (opr->is_constant()) {
     LIR_Const* const_opr = opr->as_constant_ptr();
-    if (const_opr->type() == T_OBJECT || const_opr->type() == T_VALUETYPE) {
+    if (const_opr->type() == T_OBJECT || const_opr->type() == T_INLINE_TYPE) {
       __ push_oop(const_opr->as_jobject());
     } else if (const_opr->type() == T_INT) {
       __ push_jint(const_opr->as_jint());
     } else {
       ShouldNotReachHere();
@@ -636,11 +636,11 @@
       __ movptr(dest->as_register_hi(), c->as_jint_hi());
 #endif // _LP64
       break;
     }
 
-    case T_VALUETYPE: // Fall through
+    case T_INLINE_TYPE: // Fall through
     case T_OBJECT: {
       if (patch_code != lir_patch_none) {
         jobject2reg_with_patching(dest->as_register(), info);
       } else {
         __ movoop(dest->as_register(), c->as_jobject());
@@ -727,11 +727,11 @@
 
     case T_ADDRESS:
       __ movptr(frame_map()->address_for_slot(dest->single_stack_ix()), c->as_jint_bits());
       break;
 
-    case T_VALUETYPE: // Fall through
+    case T_INLINE_TYPE: // Fall through
     case T_OBJECT:
       __ movoop(frame_map()->address_for_slot(dest->single_stack_ix()), c->as_jobject());
       break;
 
     case T_LONG:  // fall through
@@ -767,11 +767,11 @@
 
     case T_ADDRESS:
       __ movptr(as_Address(addr), c->as_jint_bits());
       break;
 
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_OBJECT:  // fall through
     case T_ARRAY:
       if (c->as_jobject() == NULL) {
         if (UseCompressedOops && !wide) {
           __ movl(as_Address(addr), (int32_t)NULL_WORD);
@@ -856,11 +856,11 @@
       move_regs(src->as_register_lo(), dest->as_register());
       return;
     }
 #endif
     assert(src->is_single_cpu(), "must match");
-    if (src->type() == T_OBJECT || src->type() == T_VALUETYPE) {
+    if (src->type() == T_OBJECT || src->type() == T_INLINE_TYPE) {
       __ verify_oop(src->as_register());
     }
     move_regs(src->as_register(), dest->as_register());
 
   } else if (dest->is_double_cpu()) {
@@ -1042,11 +1042,11 @@
       }
 #endif // _LP64
       break;
     }
 
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_ARRAY:   // fall through
     case T_OBJECT:  // fall through
       if (UseCompressedOops && !wide) {
         __ movl(as_Address(to_addr), compressed_src);
       } else {
@@ -1216,11 +1216,11 @@
 
   LIR_Address* addr = src->as_address_ptr();
   Address from_addr = as_Address(addr);
   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
 
-  if (addr->base()->type() == T_OBJECT || addr->base()->type() == T_VALUETYPE) {
+  if (addr->base()->type() == T_OBJECT || addr->base()->type() == T_INLINE_TYPE) {
     __ verify_oop(addr->base()->as_pointer_register());
   }
 
   switch (type) {
     case T_BOOLEAN: // fall through
@@ -1277,11 +1277,11 @@
 #endif // !LP64
       }
       break;
     }
 
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_OBJECT:  // fall through
     case T_ARRAY:   // fall through
       if (UseCompressedOops && !wide) {
         __ movl(dest->as_register(), from_addr);
       } else {
@@ -1664,11 +1664,11 @@
 
 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
   Register len =  op->len()->as_register();
   LP64_ONLY( __ movslq(len, len); )
 
-  if (UseSlowPath || op->type() == T_VALUETYPE ||
+  if (UseSlowPath || op->type() == T_INLINE_TYPE ||
       (!UseFastNewObjectArray && is_reference_type(op->type())) ||
       (!UseFastNewTypeArray   && !is_reference_type(op->type()))) {
     __ jmp(*op->stub()->entry());
   } else {
     Register tmp1 = op->tmp1()->as_register();
