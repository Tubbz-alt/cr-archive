<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="abstractInterpreter_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRGenerator_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 176 
 177 void LIR_Assembler::ffree(int i) {
 178   __ ffree(i);
 179 }
 180 #endif // !_LP64
 181 
 182 void LIR_Assembler::breakpoint() {
 183   __ int3();
 184 }
 185 
 186 void LIR_Assembler::push(LIR_Opr opr) {
 187   if (opr-&gt;is_single_cpu()) {
 188     __ push_reg(opr-&gt;as_register());
 189   } else if (opr-&gt;is_double_cpu()) {
 190     NOT_LP64(__ push_reg(opr-&gt;as_register_hi()));
 191     __ push_reg(opr-&gt;as_register_lo());
 192   } else if (opr-&gt;is_stack()) {
 193     __ push_addr(frame_map()-&gt;address_for_slot(opr-&gt;single_stack_ix()));
 194   } else if (opr-&gt;is_constant()) {
 195     LIR_Const* const_opr = opr-&gt;as_constant_ptr();
<span class="line-modified"> 196     if (const_opr-&gt;type() == T_OBJECT || const_opr-&gt;type() == T_VALUETYPE) {</span>
 197       __ push_oop(const_opr-&gt;as_jobject());
 198     } else if (const_opr-&gt;type() == T_INT) {
 199       __ push_jint(const_opr-&gt;as_jint());
 200     } else {
 201       ShouldNotReachHere();
 202     }
 203 
 204   } else {
 205     ShouldNotReachHere();
 206   }
 207 }
 208 
 209 void LIR_Assembler::pop(LIR_Opr opr) {
 210   if (opr-&gt;is_single_cpu()) {
 211     __ pop_reg(opr-&gt;as_register());
 212   } else {
 213     ShouldNotReachHere();
 214   }
 215 }
 216 
</pre>
<hr />
<pre>
 621       break;
 622     }
 623 
 624     case T_ADDRESS: {
 625       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 626       __ movptr(dest-&gt;as_register(), c-&gt;as_jint());
 627       break;
 628     }
 629 
 630     case T_LONG: {
 631       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 632 #ifdef _LP64
 633       __ movptr(dest-&gt;as_register_lo(), (intptr_t)c-&gt;as_jlong());
 634 #else
 635       __ movptr(dest-&gt;as_register_lo(), c-&gt;as_jint_lo());
 636       __ movptr(dest-&gt;as_register_hi(), c-&gt;as_jint_hi());
 637 #endif // _LP64
 638       break;
 639     }
 640 
<span class="line-modified"> 641     case T_VALUETYPE: // Fall through</span>
 642     case T_OBJECT: {
 643       if (patch_code != lir_patch_none) {
 644         jobject2reg_with_patching(dest-&gt;as_register(), info);
 645       } else {
 646         __ movoop(dest-&gt;as_register(), c-&gt;as_jobject());
 647       }
 648       break;
 649     }
 650 
 651     case T_METADATA: {
 652       if (patch_code != lir_patch_none) {
 653         klass2reg_with_patching(dest-&gt;as_register(), info);
 654       } else {
 655         __ mov_metadata(dest-&gt;as_register(), c-&gt;as_metadata());
 656       }
 657       break;
 658     }
 659 
 660     case T_FLOAT: {
 661       if (dest-&gt;is_single_xmm()) {
</pre>
<hr />
<pre>
 712     default:
 713       ShouldNotReachHere();
 714   }
 715 }
 716 
 717 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 718   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 719   assert(dest-&gt;is_stack(), &quot;should not call otherwise&quot;);
 720   LIR_Const* c = src-&gt;as_constant_ptr();
 721 
 722   switch (c-&gt;type()) {
 723     case T_INT:  // fall through
 724     case T_FLOAT:
 725       __ movl(frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()), c-&gt;as_jint_bits());
 726       break;
 727 
 728     case T_ADDRESS:
 729       __ movptr(frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()), c-&gt;as_jint_bits());
 730       break;
 731 
<span class="line-modified"> 732     case T_VALUETYPE: // Fall through</span>
 733     case T_OBJECT:
 734       __ movoop(frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()), c-&gt;as_jobject());
 735       break;
 736 
 737     case T_LONG:  // fall through
 738     case T_DOUBLE:
 739 #ifdef _LP64
 740       __ movptr(frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(),
 741                                             lo_word_offset_in_bytes), (intptr_t)c-&gt;as_jlong_bits());
 742 #else
 743       __ movptr(frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(),
 744                                               lo_word_offset_in_bytes), c-&gt;as_jint_lo_bits());
 745       __ movptr(frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(),
 746                                               hi_word_offset_in_bytes), c-&gt;as_jint_hi_bits());
 747 #endif // _LP64
 748       break;
 749 
 750     default:
 751       ShouldNotReachHere();
 752   }
 753 }
 754 
 755 void LIR_Assembler::const2mem(LIR_Opr src, LIR_Opr dest, BasicType type, CodeEmitInfo* info, bool wide) {
 756   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 757   assert(dest-&gt;is_address(), &quot;should not call otherwise&quot;);
 758   LIR_Const* c = src-&gt;as_constant_ptr();
 759   LIR_Address* addr = dest-&gt;as_address_ptr();
 760 
 761   int null_check_here = code_offset();
 762   switch (type) {
 763     case T_INT:    // fall through
 764     case T_FLOAT:
 765       __ movl(as_Address(addr), c-&gt;as_jint_bits());
 766       break;
 767 
 768     case T_ADDRESS:
 769       __ movptr(as_Address(addr), c-&gt;as_jint_bits());
 770       break;
 771 
<span class="line-modified"> 772     case T_VALUETYPE: // fall through</span>
 773     case T_OBJECT:  // fall through
 774     case T_ARRAY:
 775       if (c-&gt;as_jobject() == NULL) {
 776         if (UseCompressedOops &amp;&amp; !wide) {
 777           __ movl(as_Address(addr), (int32_t)NULL_WORD);
 778         } else {
 779 #ifdef _LP64
 780           __ xorptr(rscratch1, rscratch1);
 781           null_check_here = code_offset();
 782           __ movptr(as_Address(addr), rscratch1);
 783 #else
 784           __ movptr(as_Address(addr), NULL_WORD);
 785 #endif
 786         }
 787       } else {
 788         if (is_literal_address(addr)) {
 789           ShouldNotReachHere();
 790           __ movoop(as_Address(addr, noreg), c-&gt;as_jobject());
 791         } else {
 792 #ifdef _LP64
</pre>
<hr />
<pre>
 841   if (info != NULL) {
 842     add_debug_info_for_null_check(null_check_here, info);
 843   }
 844 }
 845 
 846 
 847 void LIR_Assembler::reg2reg(LIR_Opr src, LIR_Opr dest) {
 848   assert(src-&gt;is_register(), &quot;should not call otherwise&quot;);
 849   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
 850 
 851   // move between cpu-registers
 852   if (dest-&gt;is_single_cpu()) {
 853 #ifdef _LP64
 854     if (src-&gt;type() == T_LONG) {
 855       // Can do LONG -&gt; OBJECT
 856       move_regs(src-&gt;as_register_lo(), dest-&gt;as_register());
 857       return;
 858     }
 859 #endif
 860     assert(src-&gt;is_single_cpu(), &quot;must match&quot;);
<span class="line-modified"> 861     if (src-&gt;type() == T_OBJECT || src-&gt;type() == T_VALUETYPE) {</span>
 862       __ verify_oop(src-&gt;as_register());
 863     }
 864     move_regs(src-&gt;as_register(), dest-&gt;as_register());
 865 
 866   } else if (dest-&gt;is_double_cpu()) {
 867 #ifdef _LP64
 868     if (is_reference_type(src-&gt;type())) {
 869       // Surprising to me but we can see move of a long to t_object
 870       __ verify_oop(src-&gt;as_register());
 871       move_regs(src-&gt;as_register(), dest-&gt;as_register_lo());
 872       return;
 873     }
 874 #endif
 875     assert(src-&gt;is_double_cpu(), &quot;must match&quot;);
 876     Register f_lo = src-&gt;as_register_lo();
 877     Register f_hi = src-&gt;as_register_hi();
 878     Register t_lo = dest-&gt;as_register_lo();
 879     Register t_hi = dest-&gt;as_register_hi();
 880 #ifdef _LP64
 881     assert(f_hi == f_lo, &quot;must be same&quot;);
</pre>
<hr />
<pre>
1027       break;
1028     }
1029 
1030     case T_DOUBLE: {
1031 #ifdef _LP64
1032       assert(src-&gt;is_double_xmm(), &quot;not a double&quot;);
1033       __ movdbl(as_Address(to_addr), src-&gt;as_xmm_double_reg());
1034 #else
1035       if (src-&gt;is_double_xmm()) {
1036         __ movdbl(as_Address(to_addr), src-&gt;as_xmm_double_reg());
1037       } else {
1038         assert(src-&gt;is_double_fpu(), &quot;must be&quot;);
1039         assert(src-&gt;fpu_regnrLo() == 0, &quot;argument must be on TOS&quot;);
1040         if (pop_fpu_stack)      __ fstp_d(as_Address(to_addr));
1041         else                    __ fst_d (as_Address(to_addr));
1042       }
1043 #endif // _LP64
1044       break;
1045     }
1046 
<span class="line-modified">1047     case T_VALUETYPE: // fall through</span>
1048     case T_ARRAY:   // fall through
1049     case T_OBJECT:  // fall through
1050       if (UseCompressedOops &amp;&amp; !wide) {
1051         __ movl(as_Address(to_addr), compressed_src);
1052       } else {
1053         __ movptr(as_Address(to_addr), src-&gt;as_register());
1054       }
1055       break;
1056     case T_METADATA:
1057       // We get here to store a method pointer to the stack to pass to
1058       // a dtrace runtime call. This can&#39;t work on 64 bit with
1059       // compressed klass ptrs: T_METADATA can be a compressed klass
1060       // ptr or a 64 bit method pointer.
1061       LP64_ONLY(ShouldNotReachHere());
1062       __ movptr(as_Address(to_addr), src-&gt;as_register());
1063       break;
1064     case T_ADDRESS:
1065       __ movptr(as_Address(to_addr), src-&gt;as_register());
1066       break;
1067     case T_INT:
</pre>
<hr />
<pre>
1201     // push and pop the part at src + wordSize, adding wordSize for the previous push
1202     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 2 * wordSize));
1203     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 2 * wordSize));
1204     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 0));
1205 #endif // _LP64
1206 
1207   } else {
1208     ShouldNotReachHere();
1209   }
1210 }
1211 
1212 
1213 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
1214   assert(src-&gt;is_address(), &quot;should not call otherwise&quot;);
1215   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
1216 
1217   LIR_Address* addr = src-&gt;as_address_ptr();
1218   Address from_addr = as_Address(addr);
1219   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
1220 
<span class="line-modified">1221   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_VALUETYPE) {</span>
1222     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
1223   }
1224 
1225   switch (type) {
1226     case T_BOOLEAN: // fall through
1227     case T_BYTE:    // fall through
1228     case T_CHAR:    // fall through
1229     case T_SHORT:
1230       if (!VM_Version::is_P6() &amp;&amp; !from_addr.uses(dest-&gt;as_register())) {
1231         // on pre P6 processors we may get partial register stalls
1232         // so blow away the value of to_rinfo before loading a
1233         // partial word into it.  Do it here so that it precedes
1234         // the potential patch point below.
1235         __ xorptr(dest-&gt;as_register(), dest-&gt;as_register());
1236       }
1237       break;
1238    default:
1239      break;
1240   }
1241 
</pre>
<hr />
<pre>
1262 #endif // !LP64
1263       }
1264       break;
1265     }
1266 
1267     case T_DOUBLE: {
1268       if (dest-&gt;is_double_xmm()) {
1269         __ movdbl(dest-&gt;as_xmm_double_reg(), from_addr);
1270       } else {
1271 #ifndef _LP64
1272         assert(dest-&gt;is_double_fpu(), &quot;must be&quot;);
1273         assert(dest-&gt;fpu_regnrLo() == 0, &quot;dest must be TOS&quot;);
1274         __ fld_d(from_addr);
1275 #else
1276         ShouldNotReachHere();
1277 #endif // !LP64
1278       }
1279       break;
1280     }
1281 
<span class="line-modified">1282     case T_VALUETYPE: // fall through</span>
1283     case T_OBJECT:  // fall through
1284     case T_ARRAY:   // fall through
1285       if (UseCompressedOops &amp;&amp; !wide) {
1286         __ movl(dest-&gt;as_register(), from_addr);
1287       } else {
1288         __ movptr(dest-&gt;as_register(), from_addr);
1289       }
1290       break;
1291 
1292     case T_ADDRESS:
1293       if (UseCompressedClassPointers &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1294         __ movl(dest-&gt;as_register(), from_addr);
1295       } else {
1296         __ movptr(dest-&gt;as_register(), from_addr);
1297       }
1298       break;
1299     case T_INT:
1300       __ movl(dest-&gt;as_register(), from_addr);
1301       break;
1302 
</pre>
<hr />
<pre>
1649     add_debug_info_for_null_check_here(op-&gt;stub()-&gt;info());
1650     __ cmpb(Address(op-&gt;klass()-&gt;as_register(),
1651                     InstanceKlass::init_state_offset()),
1652                     InstanceKlass::fully_initialized);
1653     __ jcc(Assembler::notEqual, *op-&gt;stub()-&gt;entry());
1654   }
1655   __ allocate_object(op-&gt;obj()-&gt;as_register(),
1656                      op-&gt;tmp1()-&gt;as_register(),
1657                      op-&gt;tmp2()-&gt;as_register(),
1658                      op-&gt;header_size(),
1659                      op-&gt;object_size(),
1660                      op-&gt;klass()-&gt;as_register(),
1661                      *op-&gt;stub()-&gt;entry());
1662   __ bind(*op-&gt;stub()-&gt;continuation());
1663 }
1664 
1665 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
1666   Register len =  op-&gt;len()-&gt;as_register();
1667   LP64_ONLY( __ movslq(len, len); )
1668 
<span class="line-modified">1669   if (UseSlowPath || op-&gt;type() == T_VALUETYPE ||</span>
1670       (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||
1671       (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {
1672     __ jmp(*op-&gt;stub()-&gt;entry());
1673   } else {
1674     Register tmp1 = op-&gt;tmp1()-&gt;as_register();
1675     Register tmp2 = op-&gt;tmp2()-&gt;as_register();
1676     Register tmp3 = op-&gt;tmp3()-&gt;as_register();
1677     if (len == tmp1) {
1678       tmp1 = tmp3;
1679     } else if (len == tmp2) {
1680       tmp2 = tmp3;
1681     } else if (len == tmp3) {
1682       // everything is ok
1683     } else {
1684       __ mov(tmp3, len);
1685     }
1686     __ allocate_array(op-&gt;obj()-&gt;as_register(),
1687                       len,
1688                       tmp1,
1689                       tmp2,
</pre>
</td>
<td>
<hr />
<pre>
 176 
 177 void LIR_Assembler::ffree(int i) {
 178   __ ffree(i);
 179 }
 180 #endif // !_LP64
 181 
 182 void LIR_Assembler::breakpoint() {
 183   __ int3();
 184 }
 185 
 186 void LIR_Assembler::push(LIR_Opr opr) {
 187   if (opr-&gt;is_single_cpu()) {
 188     __ push_reg(opr-&gt;as_register());
 189   } else if (opr-&gt;is_double_cpu()) {
 190     NOT_LP64(__ push_reg(opr-&gt;as_register_hi()));
 191     __ push_reg(opr-&gt;as_register_lo());
 192   } else if (opr-&gt;is_stack()) {
 193     __ push_addr(frame_map()-&gt;address_for_slot(opr-&gt;single_stack_ix()));
 194   } else if (opr-&gt;is_constant()) {
 195     LIR_Const* const_opr = opr-&gt;as_constant_ptr();
<span class="line-modified"> 196     if (const_opr-&gt;type() == T_OBJECT || const_opr-&gt;type() == T_INLINE_TYPE) {</span>
 197       __ push_oop(const_opr-&gt;as_jobject());
 198     } else if (const_opr-&gt;type() == T_INT) {
 199       __ push_jint(const_opr-&gt;as_jint());
 200     } else {
 201       ShouldNotReachHere();
 202     }
 203 
 204   } else {
 205     ShouldNotReachHere();
 206   }
 207 }
 208 
 209 void LIR_Assembler::pop(LIR_Opr opr) {
 210   if (opr-&gt;is_single_cpu()) {
 211     __ pop_reg(opr-&gt;as_register());
 212   } else {
 213     ShouldNotReachHere();
 214   }
 215 }
 216 
</pre>
<hr />
<pre>
 621       break;
 622     }
 623 
 624     case T_ADDRESS: {
 625       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 626       __ movptr(dest-&gt;as_register(), c-&gt;as_jint());
 627       break;
 628     }
 629 
 630     case T_LONG: {
 631       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 632 #ifdef _LP64
 633       __ movptr(dest-&gt;as_register_lo(), (intptr_t)c-&gt;as_jlong());
 634 #else
 635       __ movptr(dest-&gt;as_register_lo(), c-&gt;as_jint_lo());
 636       __ movptr(dest-&gt;as_register_hi(), c-&gt;as_jint_hi());
 637 #endif // _LP64
 638       break;
 639     }
 640 
<span class="line-modified"> 641     case T_INLINE_TYPE: // Fall through</span>
 642     case T_OBJECT: {
 643       if (patch_code != lir_patch_none) {
 644         jobject2reg_with_patching(dest-&gt;as_register(), info);
 645       } else {
 646         __ movoop(dest-&gt;as_register(), c-&gt;as_jobject());
 647       }
 648       break;
 649     }
 650 
 651     case T_METADATA: {
 652       if (patch_code != lir_patch_none) {
 653         klass2reg_with_patching(dest-&gt;as_register(), info);
 654       } else {
 655         __ mov_metadata(dest-&gt;as_register(), c-&gt;as_metadata());
 656       }
 657       break;
 658     }
 659 
 660     case T_FLOAT: {
 661       if (dest-&gt;is_single_xmm()) {
</pre>
<hr />
<pre>
 712     default:
 713       ShouldNotReachHere();
 714   }
 715 }
 716 
 717 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 718   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 719   assert(dest-&gt;is_stack(), &quot;should not call otherwise&quot;);
 720   LIR_Const* c = src-&gt;as_constant_ptr();
 721 
 722   switch (c-&gt;type()) {
 723     case T_INT:  // fall through
 724     case T_FLOAT:
 725       __ movl(frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()), c-&gt;as_jint_bits());
 726       break;
 727 
 728     case T_ADDRESS:
 729       __ movptr(frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()), c-&gt;as_jint_bits());
 730       break;
 731 
<span class="line-modified"> 732     case T_INLINE_TYPE: // Fall through</span>
 733     case T_OBJECT:
 734       __ movoop(frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()), c-&gt;as_jobject());
 735       break;
 736 
 737     case T_LONG:  // fall through
 738     case T_DOUBLE:
 739 #ifdef _LP64
 740       __ movptr(frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(),
 741                                             lo_word_offset_in_bytes), (intptr_t)c-&gt;as_jlong_bits());
 742 #else
 743       __ movptr(frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(),
 744                                               lo_word_offset_in_bytes), c-&gt;as_jint_lo_bits());
 745       __ movptr(frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(),
 746                                               hi_word_offset_in_bytes), c-&gt;as_jint_hi_bits());
 747 #endif // _LP64
 748       break;
 749 
 750     default:
 751       ShouldNotReachHere();
 752   }
 753 }
 754 
 755 void LIR_Assembler::const2mem(LIR_Opr src, LIR_Opr dest, BasicType type, CodeEmitInfo* info, bool wide) {
 756   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 757   assert(dest-&gt;is_address(), &quot;should not call otherwise&quot;);
 758   LIR_Const* c = src-&gt;as_constant_ptr();
 759   LIR_Address* addr = dest-&gt;as_address_ptr();
 760 
 761   int null_check_here = code_offset();
 762   switch (type) {
 763     case T_INT:    // fall through
 764     case T_FLOAT:
 765       __ movl(as_Address(addr), c-&gt;as_jint_bits());
 766       break;
 767 
 768     case T_ADDRESS:
 769       __ movptr(as_Address(addr), c-&gt;as_jint_bits());
 770       break;
 771 
<span class="line-modified"> 772     case T_INLINE_TYPE: // fall through</span>
 773     case T_OBJECT:  // fall through
 774     case T_ARRAY:
 775       if (c-&gt;as_jobject() == NULL) {
 776         if (UseCompressedOops &amp;&amp; !wide) {
 777           __ movl(as_Address(addr), (int32_t)NULL_WORD);
 778         } else {
 779 #ifdef _LP64
 780           __ xorptr(rscratch1, rscratch1);
 781           null_check_here = code_offset();
 782           __ movptr(as_Address(addr), rscratch1);
 783 #else
 784           __ movptr(as_Address(addr), NULL_WORD);
 785 #endif
 786         }
 787       } else {
 788         if (is_literal_address(addr)) {
 789           ShouldNotReachHere();
 790           __ movoop(as_Address(addr, noreg), c-&gt;as_jobject());
 791         } else {
 792 #ifdef _LP64
</pre>
<hr />
<pre>
 841   if (info != NULL) {
 842     add_debug_info_for_null_check(null_check_here, info);
 843   }
 844 }
 845 
 846 
 847 void LIR_Assembler::reg2reg(LIR_Opr src, LIR_Opr dest) {
 848   assert(src-&gt;is_register(), &quot;should not call otherwise&quot;);
 849   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
 850 
 851   // move between cpu-registers
 852   if (dest-&gt;is_single_cpu()) {
 853 #ifdef _LP64
 854     if (src-&gt;type() == T_LONG) {
 855       // Can do LONG -&gt; OBJECT
 856       move_regs(src-&gt;as_register_lo(), dest-&gt;as_register());
 857       return;
 858     }
 859 #endif
 860     assert(src-&gt;is_single_cpu(), &quot;must match&quot;);
<span class="line-modified"> 861     if (src-&gt;type() == T_OBJECT || src-&gt;type() == T_INLINE_TYPE) {</span>
 862       __ verify_oop(src-&gt;as_register());
 863     }
 864     move_regs(src-&gt;as_register(), dest-&gt;as_register());
 865 
 866   } else if (dest-&gt;is_double_cpu()) {
 867 #ifdef _LP64
 868     if (is_reference_type(src-&gt;type())) {
 869       // Surprising to me but we can see move of a long to t_object
 870       __ verify_oop(src-&gt;as_register());
 871       move_regs(src-&gt;as_register(), dest-&gt;as_register_lo());
 872       return;
 873     }
 874 #endif
 875     assert(src-&gt;is_double_cpu(), &quot;must match&quot;);
 876     Register f_lo = src-&gt;as_register_lo();
 877     Register f_hi = src-&gt;as_register_hi();
 878     Register t_lo = dest-&gt;as_register_lo();
 879     Register t_hi = dest-&gt;as_register_hi();
 880 #ifdef _LP64
 881     assert(f_hi == f_lo, &quot;must be same&quot;);
</pre>
<hr />
<pre>
1027       break;
1028     }
1029 
1030     case T_DOUBLE: {
1031 #ifdef _LP64
1032       assert(src-&gt;is_double_xmm(), &quot;not a double&quot;);
1033       __ movdbl(as_Address(to_addr), src-&gt;as_xmm_double_reg());
1034 #else
1035       if (src-&gt;is_double_xmm()) {
1036         __ movdbl(as_Address(to_addr), src-&gt;as_xmm_double_reg());
1037       } else {
1038         assert(src-&gt;is_double_fpu(), &quot;must be&quot;);
1039         assert(src-&gt;fpu_regnrLo() == 0, &quot;argument must be on TOS&quot;);
1040         if (pop_fpu_stack)      __ fstp_d(as_Address(to_addr));
1041         else                    __ fst_d (as_Address(to_addr));
1042       }
1043 #endif // _LP64
1044       break;
1045     }
1046 
<span class="line-modified">1047     case T_INLINE_TYPE: // fall through</span>
1048     case T_ARRAY:   // fall through
1049     case T_OBJECT:  // fall through
1050       if (UseCompressedOops &amp;&amp; !wide) {
1051         __ movl(as_Address(to_addr), compressed_src);
1052       } else {
1053         __ movptr(as_Address(to_addr), src-&gt;as_register());
1054       }
1055       break;
1056     case T_METADATA:
1057       // We get here to store a method pointer to the stack to pass to
1058       // a dtrace runtime call. This can&#39;t work on 64 bit with
1059       // compressed klass ptrs: T_METADATA can be a compressed klass
1060       // ptr or a 64 bit method pointer.
1061       LP64_ONLY(ShouldNotReachHere());
1062       __ movptr(as_Address(to_addr), src-&gt;as_register());
1063       break;
1064     case T_ADDRESS:
1065       __ movptr(as_Address(to_addr), src-&gt;as_register());
1066       break;
1067     case T_INT:
</pre>
<hr />
<pre>
1201     // push and pop the part at src + wordSize, adding wordSize for the previous push
1202     __ pushl(frame_map()-&gt;address_for_slot(src -&gt;double_stack_ix(), 2 * wordSize));
1203     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 2 * wordSize));
1204     __ popl (frame_map()-&gt;address_for_slot(dest-&gt;double_stack_ix(), 0));
1205 #endif // _LP64
1206 
1207   } else {
1208     ShouldNotReachHere();
1209   }
1210 }
1211 
1212 
1213 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
1214   assert(src-&gt;is_address(), &quot;should not call otherwise&quot;);
1215   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
1216 
1217   LIR_Address* addr = src-&gt;as_address_ptr();
1218   Address from_addr = as_Address(addr);
1219   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
1220 
<span class="line-modified">1221   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_INLINE_TYPE) {</span>
1222     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
1223   }
1224 
1225   switch (type) {
1226     case T_BOOLEAN: // fall through
1227     case T_BYTE:    // fall through
1228     case T_CHAR:    // fall through
1229     case T_SHORT:
1230       if (!VM_Version::is_P6() &amp;&amp; !from_addr.uses(dest-&gt;as_register())) {
1231         // on pre P6 processors we may get partial register stalls
1232         // so blow away the value of to_rinfo before loading a
1233         // partial word into it.  Do it here so that it precedes
1234         // the potential patch point below.
1235         __ xorptr(dest-&gt;as_register(), dest-&gt;as_register());
1236       }
1237       break;
1238    default:
1239      break;
1240   }
1241 
</pre>
<hr />
<pre>
1262 #endif // !LP64
1263       }
1264       break;
1265     }
1266 
1267     case T_DOUBLE: {
1268       if (dest-&gt;is_double_xmm()) {
1269         __ movdbl(dest-&gt;as_xmm_double_reg(), from_addr);
1270       } else {
1271 #ifndef _LP64
1272         assert(dest-&gt;is_double_fpu(), &quot;must be&quot;);
1273         assert(dest-&gt;fpu_regnrLo() == 0, &quot;dest must be TOS&quot;);
1274         __ fld_d(from_addr);
1275 #else
1276         ShouldNotReachHere();
1277 #endif // !LP64
1278       }
1279       break;
1280     }
1281 
<span class="line-modified">1282     case T_INLINE_TYPE: // fall through</span>
1283     case T_OBJECT:  // fall through
1284     case T_ARRAY:   // fall through
1285       if (UseCompressedOops &amp;&amp; !wide) {
1286         __ movl(dest-&gt;as_register(), from_addr);
1287       } else {
1288         __ movptr(dest-&gt;as_register(), from_addr);
1289       }
1290       break;
1291 
1292     case T_ADDRESS:
1293       if (UseCompressedClassPointers &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1294         __ movl(dest-&gt;as_register(), from_addr);
1295       } else {
1296         __ movptr(dest-&gt;as_register(), from_addr);
1297       }
1298       break;
1299     case T_INT:
1300       __ movl(dest-&gt;as_register(), from_addr);
1301       break;
1302 
</pre>
<hr />
<pre>
1649     add_debug_info_for_null_check_here(op-&gt;stub()-&gt;info());
1650     __ cmpb(Address(op-&gt;klass()-&gt;as_register(),
1651                     InstanceKlass::init_state_offset()),
1652                     InstanceKlass::fully_initialized);
1653     __ jcc(Assembler::notEqual, *op-&gt;stub()-&gt;entry());
1654   }
1655   __ allocate_object(op-&gt;obj()-&gt;as_register(),
1656                      op-&gt;tmp1()-&gt;as_register(),
1657                      op-&gt;tmp2()-&gt;as_register(),
1658                      op-&gt;header_size(),
1659                      op-&gt;object_size(),
1660                      op-&gt;klass()-&gt;as_register(),
1661                      *op-&gt;stub()-&gt;entry());
1662   __ bind(*op-&gt;stub()-&gt;continuation());
1663 }
1664 
1665 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
1666   Register len =  op-&gt;len()-&gt;as_register();
1667   LP64_ONLY( __ movslq(len, len); )
1668 
<span class="line-modified">1669   if (UseSlowPath || op-&gt;type() == T_INLINE_TYPE ||</span>
1670       (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||
1671       (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {
1672     __ jmp(*op-&gt;stub()-&gt;entry());
1673   } else {
1674     Register tmp1 = op-&gt;tmp1()-&gt;as_register();
1675     Register tmp2 = op-&gt;tmp2()-&gt;as_register();
1676     Register tmp3 = op-&gt;tmp3()-&gt;as_register();
1677     if (len == tmp1) {
1678       tmp1 = tmp3;
1679     } else if (len == tmp2) {
1680       tmp2 = tmp3;
1681     } else if (len == tmp3) {
1682       // everything is ok
1683     } else {
1684       __ mov(tmp3, len);
1685     }
1686     __ allocate_array(op-&gt;obj()-&gt;as_register(),
1687                       len,
1688                       tmp1,
1689                       tmp2,
</pre>
</td>
</tr>
</table>
<center><a href="abstractInterpreter_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRGenerator_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>