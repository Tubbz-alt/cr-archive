<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/classfile/fieldLayoutBuilder.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2019, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;jvm.h&quot;
 27 #include &quot;classfile/classFileParser.hpp&quot;
 28 #include &quot;classfile/fieldLayoutBuilder.hpp&quot;
 29 #include &quot;memory/resourceArea.hpp&quot;
 30 #include &quot;oops/array.hpp&quot;
 31 #include &quot;oops/fieldStreams.inline.hpp&quot;
 32 #include &quot;oops/instanceMirrorKlass.hpp&quot;
 33 #include &quot;oops/klass.inline.hpp&quot;
 34 #include &quot;oops/valueKlass.inline.hpp&quot;
 35 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
 36 
 37 LayoutRawBlock::LayoutRawBlock(Kind kind, int size) :
 38   _next_block(NULL),
 39   _prev_block(NULL),
 40   _value_klass(NULL),
 41   _kind(kind),
 42   _offset(-1),
 43   _alignment(1),
 44   _size(size),
 45   _field_index(-1),
 46   _is_reference(false) {
 47   assert(kind == EMPTY || kind == RESERVED || kind == PADDING || kind == INHERITED,
 48          &quot;Otherwise, should use the constructor with a field index argument&quot;);
 49   assert(size &gt; 0, &quot;Sanity check&quot;);
 50 }
 51 
 52 
 53 LayoutRawBlock::LayoutRawBlock(int index, Kind kind, int size, int alignment, bool is_reference) :
 54  _next_block(NULL),
 55  _prev_block(NULL),
 56  _value_klass(NULL),
 57  _kind(kind),
 58  _offset(-1),
 59  _alignment(alignment),
 60  _size(size),
 61  _field_index(index),
 62  _is_reference(is_reference) {
 63   assert(kind == REGULAR || kind == INLINED || kind == INHERITED,
 64          &quot;Other kind do not have a field index&quot;);
 65   assert(size &gt; 0, &quot;Sanity check&quot;);
 66   assert(alignment &gt; 0, &quot;Sanity check&quot;);
 67 }
 68 
 69 bool LayoutRawBlock::fit(int size, int alignment) {
 70   int adjustment = 0;
 71   if ((_offset % alignment) != 0) {
 72     adjustment = alignment - (_offset % alignment);
 73   }
 74   return _size &gt;= size + adjustment;
 75 }
 76 
 77 FieldGroup::FieldGroup(int contended_group) :
 78   _next(NULL),
 79   _primitive_fields(NULL),
 80   _oop_fields(NULL),
 81   _inlined_fields(NULL),
 82   _contended_group(contended_group),  // -1 means no contended group, 0 means default contended group
 83   _oop_count(0) {}
 84 
 85 void FieldGroup::add_primitive_field(AllFieldStream fs, BasicType type) {
 86   int size = type2aelembytes(type);
 87   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size /* alignment == size for primitive types */, false);
 88   if (_primitive_fields == NULL) {
 89     _primitive_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
 90   }
 91   _primitive_fields-&gt;append(block);
 92 }
 93 
 94 void FieldGroup::add_oop_field(AllFieldStream fs) {
 95   int size = type2aelembytes(T_OBJECT);
 96   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size /* alignment == size for oops */, true);
 97   if (_oop_fields == NULL) {
 98     _oop_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
 99   }
100   _oop_fields-&gt;append(block);
101   _oop_count++;
102 }
103 
104 void FieldGroup::add_inlined_field(AllFieldStream fs, ValueKlass* vk) {
105   // _inlined_fields list might be merged with the _primitive_fields list in the future
106   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INLINED, vk-&gt;get_exact_size_in_bytes(), vk-&gt;get_alignment(), false);
107   block-&gt;set_value_klass(vk);
108   if (_inlined_fields == NULL) {
109     _inlined_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
110   }
111   _inlined_fields-&gt;append(block);
112 }
113 
114 void FieldGroup::sort_by_size() {
115   if (_primitive_fields != NULL) {
116     _primitive_fields-&gt;sort(LayoutRawBlock::compare_size_inverted);
117   }
118   if (_inlined_fields != NULL) {
119     _inlined_fields-&gt;sort(LayoutRawBlock::compare_size_inverted);
120   }
121 }
122 
123 FieldLayout::FieldLayout(Array&lt;u2&gt;* fields, ConstantPool* cp) :
124   _fields(fields),
125   _cp(cp),
126   _blocks(NULL),
127   _start(_blocks),
128   _last(_blocks) {}
129 
130 void FieldLayout::initialize_static_layout() {
131   _blocks = new LayoutRawBlock(LayoutRawBlock::EMPTY, INT_MAX);
132   _blocks-&gt;set_offset(0);
133   _last = _blocks;
134   _start = _blocks;
135   // Note: at this stage, InstanceMirrorKlass::offset_of_static_fields() could be zero, because
136   // during bootstrapping, the size of the java.lang.Class is still not known when layout
137   // of static field is computed. Field offsets are fixed later when the size is known
138   // (see java_lang_Class::fixup_mirror())
139   if (InstanceMirrorKlass::offset_of_static_fields() &gt; 0) {
140     insert(first_empty_block(), new LayoutRawBlock(LayoutRawBlock::RESERVED, InstanceMirrorKlass::offset_of_static_fields()));
141     _blocks-&gt;set_offset(0);
142   }
143 }
144 
145 void FieldLayout::initialize_instance_layout(const InstanceKlass* super_klass) {
146   if (super_klass == NULL) {
147     _blocks = new LayoutRawBlock(LayoutRawBlock::EMPTY, INT_MAX);
148     _blocks-&gt;set_offset(0);
149     _last = _blocks;
150     _start = _blocks;
151     insert(first_empty_block(), new LayoutRawBlock(LayoutRawBlock::RESERVED, instanceOopDesc::base_offset_in_bytes()));
152   } else {
153     bool has_fields = reconstruct_layout(super_klass);
154     fill_holes(super_klass);
155     if ((UseEmptySlotsInSupers &amp;&amp; !super_klass-&gt;has_contended_annotations()) || !has_fields) {
156       _start = _blocks; // Setting _start to _blocks instead of _last would allow subclasses
157       // to allocate fields in empty slots of their super classes
158     } else {
159       _start = _last;    // append fields at the end of the reconstructed layout
160     }
161   }
162 }
163 
164 LayoutRawBlock* FieldLayout::first_field_block() {
165   LayoutRawBlock* block = _blocks;
166   while (block != NULL
167          &amp;&amp; block-&gt;kind() != LayoutRawBlock::INHERITED
168          &amp;&amp; block-&gt;kind() != LayoutRawBlock::REGULAR
169          &amp;&amp; block-&gt;kind() != LayoutRawBlock::INLINED) {
170     block = block-&gt;next_block();
171   }
172   return block;
173 }
174 
175 // Insert a set of fields into a layout.
176 // For each field, search for an empty slot able to fit the field
177 // (satisfying both size and alignment requirements), if none is found,
178 // add the field at the end of the layout.
179 // Fields cannot be inserted before the block specified in the &quot;start&quot; argument
180 void FieldLayout::add(GrowableArray&lt;LayoutRawBlock*&gt;* list, LayoutRawBlock* start) {
181   if (list == NULL) return;
182   if (start == NULL) start = this-&gt;_start;
183   bool last_search_success = false;
184   int last_size = 0;
185   int last_alignment = 0;
186   for (int i = 0; i &lt; list-&gt;length(); i ++) {
187     LayoutRawBlock* b = list-&gt;at(i);
188     LayoutRawBlock* cursor = NULL;
189     LayoutRawBlock* candidate = NULL;
190     // if start is the last block, just append the field
191     if (start == last_block()) {
192       candidate = last_block();
193     }
194     // Before iterating over the layout to find an empty slot fitting the field&#39;s requirements,
195     // check if the previous field had the same requirements and if the search for a fitting slot
196     // was successful. If the requirements were the same but the search failed, a new search will
197     // fail the same way, so just append the field at the of the layout.
198     else  if (b-&gt;size() == last_size &amp;&amp; b-&gt;alignment() == last_alignment &amp;&amp; !last_search_success) {
199       candidate = last_block();
200     } else {
201       // Iterate over the layout to find an empty slot fitting the field&#39;s requirements
202       last_size = b-&gt;size();
203       last_alignment = b-&gt;alignment();
204       cursor = last_block()-&gt;prev_block();
205       assert(cursor != NULL, &quot;Sanity check&quot;);
206       last_search_success = true;
207 
208       while (cursor != start) {
209         if (cursor-&gt;kind() == LayoutRawBlock::EMPTY &amp;&amp; cursor-&gt;fit(b-&gt;size(), b-&gt;alignment())) {
210           if (candidate == NULL || cursor-&gt;size() &lt; candidate-&gt;size()) {
211             candidate = cursor;
212           }
213         }
214         cursor = cursor-&gt;prev_block();
215       }
216       if (candidate == NULL) {
217         candidate = last_block();
218         last_search_success = false;
219       }
220       assert(candidate != NULL, &quot;Candidate must not be null&quot;);
221       assert(candidate-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Candidate must be an empty block&quot;);
222       assert(candidate-&gt;fit(b-&gt;size(), b-&gt;alignment()), &quot;Candidate must be able to store the block&quot;);
223     }
224     insert_field_block(candidate, b);
225   }
226 }
227 
228 // Used for classes with hard coded field offsets, insert a field at the specified offset */
229 void FieldLayout::add_field_at_offset(LayoutRawBlock* block, int offset, LayoutRawBlock* start) {
230   assert(block != NULL, &quot;Sanity check&quot;);
231   block-&gt;set_offset(offset);
232   if (start == NULL) {
233     start = this-&gt;_start;
234   }
235   LayoutRawBlock* slot = start;
236   while (slot != NULL) {
237     if ((slot-&gt;offset() &lt;= block-&gt;offset() &amp;&amp; (slot-&gt;offset() + slot-&gt;size()) &gt; block-&gt;offset()) ||
238         slot == _last){
239       assert(slot-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Matching slot must be an empty slot&quot;);
240       assert(slot-&gt;size() &gt;= block-&gt;offset() + block-&gt;size() ,&quot;Matching slot must be big enough&quot;);
241       if (slot-&gt;offset() &lt; block-&gt;offset()) {
242         int adjustment = block-&gt;offset() - slot-&gt;offset();
243         LayoutRawBlock* adj = new LayoutRawBlock(LayoutRawBlock::EMPTY, adjustment);
244         insert(slot, adj);
245       }
246       insert(slot, block);
247       if (slot-&gt;size() == 0) {
248         remove(slot);
249       }
250       FieldInfo::from_field_array(_fields, block-&gt;field_index())-&gt;set_offset(block-&gt;offset());
251       return;
252     }
253     slot = slot-&gt;next_block();
254   }
255   fatal(&quot;Should have found a matching slot above, corrupted layout or invalid offset&quot;);
256 }
257 
258 // The allocation logic uses a best fit strategy: the set of fields is allocated
259 // in the first empty slot big enough to contain the whole set ((including padding
260 // to fit alignment constraints).
261 void FieldLayout::add_contiguously(GrowableArray&lt;LayoutRawBlock*&gt;* list, LayoutRawBlock* start) {
262   if (list == NULL) return;
263   if (start == NULL) {
264     start = _start;
265   }
266   // This code assumes that if the first block is well aligned, the following
267   // blocks would naturally be well aligned (no need for adjustment)
268   int size = 0;
269   for (int i = 0; i &lt; list-&gt;length(); i++) {
270     size += list-&gt;at(i)-&gt;size();
271   }
272 
273   LayoutRawBlock* candidate = NULL;
274   if (start == last_block()) {
275     candidate = last_block();
276   } else {
277     LayoutRawBlock* first = list-&gt;at(0);
278     candidate = last_block()-&gt;prev_block();
279     while (candidate-&gt;kind() != LayoutRawBlock::EMPTY || !candidate-&gt;fit(size, first-&gt;alignment())) {
280       if (candidate == start) {
281         candidate = last_block();
282         break;
283       }
284       candidate = candidate-&gt;prev_block();
285     }
286     assert(candidate != NULL, &quot;Candidate must not be null&quot;);
287     assert(candidate-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Candidate must be an empty block&quot;);
288     assert(candidate-&gt;fit(size, first-&gt;alignment()), &quot;Candidate must be able to store the whole contiguous block&quot;);
289   }
290 
291   for (int i = 0; i &lt; list-&gt;length(); i++) {
292     LayoutRawBlock* b = list-&gt;at(i);
293     insert_field_block(candidate, b);
294     assert((candidate-&gt;offset() % b-&gt;alignment() == 0), &quot;Contiguous blocks must be naturally well aligned&quot;);
295   }
296 }
297 
298 LayoutRawBlock* FieldLayout::insert_field_block(LayoutRawBlock* slot, LayoutRawBlock* block) {
299   assert(slot-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Blocks can only be inserted in empty blocks&quot;);
300   if (slot-&gt;offset() % block-&gt;alignment() != 0) {
301     int adjustment = block-&gt;alignment() - (slot-&gt;offset() % block-&gt;alignment());
302     LayoutRawBlock* adj = new LayoutRawBlock(LayoutRawBlock::EMPTY, adjustment);
303     insert(slot, adj);
304   }
305   insert(slot, block);
306   if (slot-&gt;size() == 0) {
307     remove(slot);
308   }
309   FieldInfo::from_field_array(_fields, block-&gt;field_index())-&gt;set_offset(block-&gt;offset());
310   return block;
311 }
312 
313 bool FieldLayout::reconstruct_layout(const InstanceKlass* ik) {
314   bool has_instance_fields = false;
315   GrowableArray&lt;LayoutRawBlock*&gt;* all_fields = new GrowableArray&lt;LayoutRawBlock*&gt;(32);
316   while (ik != NULL) {
317     for (AllFieldStream fs(ik-&gt;fields(), ik-&gt;constants()); !fs.done(); fs.next()) {
318       BasicType type = Signature::basic_type(fs.signature());
319       // distinction between static and non-static fields is missing
320       if (fs.access_flags().is_static()) continue;
321       has_instance_fields = true;
322       LayoutRawBlock* block;
<a name="1" id="anc1"></a><span class="line-modified">323       if (type == T_INLINE_TYPE) {</span>
324         ValueKlass* vk = ValueKlass::cast(ik-&gt;get_inline_type_field_klass(fs.index()));
325         block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED, vk-&gt;get_exact_size_in_bytes(),
326                                    vk-&gt;get_alignment(), false);
327 
328       } else {
329         int size = type2aelembytes(type);
330         // INHERITED blocks are marked as non-reference because oop_maps are handled by their holder class
331         block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED, size, size, false);
332       }
333       block-&gt;set_offset(fs.offset());
334       all_fields-&gt;append(block);
335     }
336     ik = ik-&gt;super() == NULL ? NULL : InstanceKlass::cast(ik-&gt;super());
337   }
338   all_fields-&gt;sort(LayoutRawBlock::compare_offset);
339   _blocks = new LayoutRawBlock(LayoutRawBlock::RESERVED, instanceOopDesc::base_offset_in_bytes());
340   _blocks-&gt;set_offset(0);
341   _last = _blocks;
342   for(int i = 0; i &lt; all_fields-&gt;length(); i++) {
343     LayoutRawBlock* b = all_fields-&gt;at(i);
344     _last-&gt;set_next_block(b);
345     b-&gt;set_prev_block(_last);
346     _last = b;
347   }
348   _start = _blocks;
349   return has_instance_fields;
350 }
351 
352 // Called during the reconstruction of a layout, after fields from super
353 // classes have been inserted. It fills unused slots between inserted fields
354 // with EMPTY blocks, so the regular field insertion methods would work.
355 // This method handles classes with @Contended annotations differently
356 // by inserting PADDING blocks instead of EMPTY block to prevent subclasses&#39;
357 // fields to interfere with contended fields/classes.
358 void FieldLayout::fill_holes(const InstanceKlass* super_klass) {
359   assert(_blocks != NULL, &quot;Sanity check&quot;);
360   assert(_blocks-&gt;offset() == 0, &quot;first block must be at offset zero&quot;);
361   LayoutRawBlock::Kind filling_type = super_klass-&gt;has_contended_annotations() ? LayoutRawBlock::PADDING: LayoutRawBlock::EMPTY;
362   LayoutRawBlock* b = _blocks;
363   while (b-&gt;next_block() != NULL) {
364     if (b-&gt;next_block()-&gt;offset() &gt; (b-&gt;offset() + b-&gt;size())) {
365       int size = b-&gt;next_block()-&gt;offset() - (b-&gt;offset() + b-&gt;size());
366       LayoutRawBlock* empty = new LayoutRawBlock(filling_type, size);
367       empty-&gt;set_offset(b-&gt;offset() + b-&gt;size());
368       empty-&gt;set_next_block(b-&gt;next_block());
369       b-&gt;next_block()-&gt;set_prev_block(empty);
370       b-&gt;set_next_block(empty);
371       empty-&gt;set_prev_block(b);
372     }
373     b = b-&gt;next_block();
374   }
375   assert(b-&gt;next_block() == NULL, &quot;Invariant at this point&quot;);
376   assert(b-&gt;kind() != LayoutRawBlock::EMPTY, &quot;Sanity check&quot;);
377   // If the super class has @Contended annotation, a padding block is
378   // inserted at the end to ensure that fields from the subclasses won&#39;t share
379   // the cache line of the last field of the contended class
380   if (super_klass-&gt;has_contended_annotations() &amp;&amp; ContendedPaddingWidth &gt; 0) {
381     LayoutRawBlock* p = new LayoutRawBlock(LayoutRawBlock::PADDING, ContendedPaddingWidth);
382     p-&gt;set_offset(b-&gt;offset() + b-&gt;size());
383     b-&gt;set_next_block(p);
384     p-&gt;set_prev_block(b);
385     b = p;
386   }
387   if (!UseEmptySlotsInSupers) {
388     // Add an empty slots to align fields of the subclass on a heapOopSize boundary
389     // in order to emulate the behavior of the previous algorithm
390     int align = (b-&gt;offset() + b-&gt;size()) % heapOopSize;
391     if (align != 0) {
392       int sz = heapOopSize - align;
393       LayoutRawBlock* p = new LayoutRawBlock(LayoutRawBlock::EMPTY, sz);
394       p-&gt;set_offset(b-&gt;offset() + b-&gt;size());
395       b-&gt;set_next_block(p);
396       p-&gt;set_prev_block(b);
397       b = p;
398     }
399   }
400   LayoutRawBlock* last = new LayoutRawBlock(LayoutRawBlock::EMPTY, INT_MAX);
401   last-&gt;set_offset(b-&gt;offset() + b-&gt;size());
402   assert(last-&gt;offset() &gt; 0, &quot;Sanity check&quot;);
403   b-&gt;set_next_block(last);
404   last-&gt;set_prev_block(b);
405   _last = last;
406 }
407 
408 LayoutRawBlock* FieldLayout::insert(LayoutRawBlock* slot, LayoutRawBlock* block) {
409   assert(slot-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Blocks can only be inserted in empty blocks&quot;);
410   assert(slot-&gt;offset() % block-&gt;alignment() == 0, &quot;Incompatible alignment&quot;);
411   block-&gt;set_offset(slot-&gt;offset());
412   slot-&gt;set_offset(slot-&gt;offset() + block-&gt;size());
413   assert((slot-&gt;size() - block-&gt;size()) &lt; slot-&gt;size(), &quot;underflow checking&quot;);
414   assert(slot-&gt;size() - block-&gt;size() &gt;= 0, &quot;no negative size allowed&quot;);
415   slot-&gt;set_size(slot-&gt;size() - block-&gt;size());
416   block-&gt;set_prev_block(slot-&gt;prev_block());
417   block-&gt;set_next_block(slot);
418   slot-&gt;set_prev_block(block);
419   if (block-&gt;prev_block() != NULL) {
420     block-&gt;prev_block()-&gt;set_next_block(block);
421   }
422   if (_blocks == slot) {
423     _blocks = block;
424   }
425   return block;
426 }
427 
428 void FieldLayout::remove(LayoutRawBlock* block) {
429   assert(block != NULL, &quot;Sanity check&quot;);
430   assert(block != _last, &quot;Sanity check&quot;);
431   if (_blocks == block) {
432     _blocks = block-&gt;next_block();
433     if (_blocks != NULL) {
434       _blocks-&gt;set_prev_block(NULL);
435     }
436   } else {
437     assert(block-&gt;prev_block() != NULL, &quot;_prev should be set for non-head blocks&quot;);
438     block-&gt;prev_block()-&gt;set_next_block(block-&gt;next_block());
439     block-&gt;next_block()-&gt;set_prev_block(block-&gt;prev_block());
440   }
441   if (block == _start) {
442     _start = block-&gt;prev_block();
443   }
444 }
445 
446 void FieldLayout::print(outputStream* output, bool is_static, const InstanceKlass* super) {
447   ResourceMark rm;
448   LayoutRawBlock* b = _blocks;
449   while(b != _last) {
450     switch(b-&gt;kind()) {
451     case LayoutRawBlock::REGULAR: {
452       FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
453       output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
454                        b-&gt;offset(),
455                        fi-&gt;name(_cp)-&gt;as_C_string(),
456                        fi-&gt;signature(_cp)-&gt;as_C_string(),
457                        b-&gt;size(),
458                        b-&gt;alignment(),
459                        &quot;REGULAR&quot;);
460       break;
461     }
462     case LayoutRawBlock::INLINED: {
463       FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
464       output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
465                        b-&gt;offset(),
466                        fi-&gt;name(_cp)-&gt;as_C_string(),
467                        fi-&gt;signature(_cp)-&gt;as_C_string(),
468                        b-&gt;size(),
469                        b-&gt;alignment(),
470                        &quot;INLINED&quot;);
471       break;
472     }
473     case LayoutRawBlock::RESERVED: {
474       output-&gt;print_cr(&quot; @%d %d/- %s&quot;,
475                        b-&gt;offset(),
476                        b-&gt;size(),
477                        &quot;RESERVED&quot;);
478       break;
479     }
480     case LayoutRawBlock::INHERITED: {
481       assert(!is_static, &quot;Static fields are not inherited in layouts&quot;);
482       assert(super != NULL, &quot;super klass must be provided to retrieve inherited fields info&quot;);
483       bool found = false;
484       const InstanceKlass* ik = super;
485       while (!found &amp;&amp; ik != NULL) {
486         for (AllFieldStream fs(ik-&gt;fields(), ik-&gt;constants()); !fs.done(); fs.next()) {
487           if (fs.offset() == b-&gt;offset()) {
488             output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
489                 b-&gt;offset(),
490                 fs.name()-&gt;as_C_string(),
491                 fs.signature()-&gt;as_C_string(),
492                 b-&gt;size(),
493                 b-&gt;size(), // so far, alignment constraint == size, will change with Valhalla
494                 &quot;INHERITED&quot;);
495             found = true;
496             break;
497           }
498         }
499         ik = ik-&gt;java_super();
500       }
501       break;
502     }
503     case LayoutRawBlock::EMPTY:
504       output-&gt;print_cr(&quot; @%d %d/1 %s&quot;,
505                        b-&gt;offset(),
506                        b-&gt;size(),
507                        &quot;EMPTY&quot;);
508       break;
509     case LayoutRawBlock::PADDING:
510       output-&gt;print_cr(&quot; @%d %d/1 %s&quot;,
511                        b-&gt;offset(),
512                        b-&gt;size(),
513                        &quot;PADDING&quot;);
514       break;
515     }
516     b = b-&gt;next_block();
517   }
518 }
519 
520 FieldLayoutBuilder::FieldLayoutBuilder(const Symbol* classname, const InstanceKlass* super_klass, ConstantPool* constant_pool,
521                                        Array&lt;u2&gt;* fields, bool is_contended, bool is_inline_type, ClassLoaderData* class_loader_data,
522                                        Handle protection_domain, FieldLayoutInfo* info) :
523   _classname(classname),
524   _super_klass(super_klass),
525   _constant_pool(constant_pool),
526   _fields(fields),
527   _info(info),
528   _root_group(NULL),
529   _contended_groups(GrowableArray&lt;FieldGroup*&gt;(8)),
530   _static_fields(NULL),
531   _layout(NULL),
532   _static_layout(NULL),
533   _class_loader_data(class_loader_data),
534   _protection_domain(protection_domain),
535   _nonstatic_oopmap_count(0),
536   _alignment(-1),
537   _first_field_offset(-1),
538   _exact_size_in_bytes(-1),
539   _has_nonstatic_fields(false),
540   _has_inline_type_fields(false),
541   _is_contended(is_contended),
542   _is_inline_type(is_inline_type),
543   _has_flattening_information(is_inline_type),
544   _has_nonatomic_values(false),
545   _atomic_field_count(0)
546  {}
547 
548 FieldGroup* FieldLayoutBuilder::get_or_create_contended_group(int g) {
549   assert(g &gt; 0, &quot;must only be called for named contended groups&quot;);
550   FieldGroup* fg = NULL;
551   for (int i = 0; i &lt; _contended_groups.length(); i++) {
552     fg = _contended_groups.at(i);
553     if (fg-&gt;contended_group() == g) return fg;
554   }
555   fg = new FieldGroup(g);
556   _contended_groups.append(fg);
557   return fg;
558 }
559 
560 void FieldLayoutBuilder::prologue() {
561   _layout = new FieldLayout(_fields, _constant_pool);
562   const InstanceKlass* super_klass = _super_klass;
563   _layout-&gt;initialize_instance_layout(super_klass);
564   if (super_klass != NULL) {
565     _has_nonstatic_fields = super_klass-&gt;has_nonstatic_fields();
566   }
567   _static_layout = new FieldLayout(_fields, _constant_pool);
568   _static_layout-&gt;initialize_static_layout();
569   _static_fields = new FieldGroup();
570   _root_group = new FieldGroup();
571 }
572 
573 // Field sorting for regular (non-inline) classes:
574 //   - fields are sorted in static and non-static fields
575 //   - non-static fields are also sorted according to their contention group
576 //     (support of the @Contended annotation)
577 //   - @Contended annotation is ignored for static fields
578 //   - field flattening decisions are taken in this method
579 void FieldLayoutBuilder::regular_field_sorting() {
580   for (AllFieldStream fs(_fields, _constant_pool); !fs.done(); fs.next()) {
581     FieldGroup* group = NULL;
582     if (fs.access_flags().is_static()) {
583       group = _static_fields;
584     } else {
585       _has_nonstatic_fields = true;
586       _atomic_field_count++;  // we might decrement this
587       if (fs.is_contended()) {
588         int g = fs.contended_group();
589         if (g == 0) {
590           group = new FieldGroup(true);
591           _contended_groups.append(group);
592         } else {
593           group = get_or_create_contended_group(g);
594         }
595       } else {
596         group = _root_group;
597       }
598     }
599     assert(group != NULL, &quot;invariant&quot;);
600     BasicType type = Signature::basic_type(fs.signature());
601     switch(type) {
602     case T_BYTE:
603     case T_CHAR:
604     case T_DOUBLE:
605     case T_FLOAT:
606     case T_INT:
607     case T_LONG:
608     case T_SHORT:
609     case T_BOOLEAN:
610       group-&gt;add_primitive_field(fs, type);
611       break;
612     case T_OBJECT:
613     case T_ARRAY:
614       if (group != _static_fields) _nonstatic_oopmap_count++;
615       group-&gt;add_oop_field(fs);
616       break;
<a name="2" id="anc2"></a><span class="line-modified">617     case T_INLINE_TYPE:</span>
618 //      fs.set_inline(true);
619       _has_inline_type_fields = true;
620       if (group == _static_fields) {
621         // static fields are never inlined
622         group-&gt;add_oop_field(fs);
623       } else {
624         _has_flattening_information = true;
625         // Flattening decision to be taken here
626         // This code assumes all verification already have been performed
627         // (field&#39;s type has been loaded and it is an inline klass)
628         Thread* THREAD = Thread::current();
629         Klass* klass =
630             SystemDictionary::resolve_inline_type_field_or_fail(&amp;fs,
631                                                                 Handle(THREAD, _class_loader_data-&gt;class_loader()),
632                                                                 _protection_domain, true, THREAD);
633         assert(klass != NULL, &quot;Sanity check&quot;);
634         ValueKlass* vk = ValueKlass::cast(klass);
635         bool too_big_to_flatten = (InlineFieldMaxFlatSize &gt;= 0 &amp;&amp;
636                                    (vk-&gt;size_helper() * HeapWordSize) &gt; InlineFieldMaxFlatSize);
637         bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();
638         bool too_volatile_to_flatten = fs.access_flags().is_volatile();
639         if (vk-&gt;is_naturally_atomic()) {
640           too_atomic_to_flatten = false;
641           //too_volatile_to_flatten = false; //FIXME
642           // volatile fields are currently never inlined, this could change in the future
643         }
644         if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {
645           group-&gt;add_inlined_field(fs, vk);
646           _nonstatic_oopmap_count += vk-&gt;nonstatic_oop_map_count();
647           fs.set_inlined(true);
648           if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note
649             _has_nonatomic_values = true;
650             _atomic_field_count--;  // every other field is atomic but this one
651           }
652         } else {
653           _nonstatic_oopmap_count++;
654           group-&gt;add_oop_field(fs);
655         }
656       }
657       break;
658     default:
659       fatal(&quot;Something wrong?&quot;);
660     }
661   }
662   _root_group-&gt;sort_by_size();
663   _static_fields-&gt;sort_by_size();
664   if (!_contended_groups.is_empty()) {
665     for (int i = 0; i &lt; _contended_groups.length(); i++) {
666       _contended_groups.at(i)-&gt;sort_by_size();
667     }
668   }
669 }
670 
671 /* Field sorting for inline classes:
672  *   - because inline classes are immutable, the @Contended annotation is ignored
673  *     when computing their layout (with only read operation, there&#39;s no false
674  *     sharing issue)
675  *   - this method also records the alignment of the field with the most
676  *     constraining alignment, this value is then used as the alignment
677  *     constraint when flattening this inline type into another container
678  *   - field flattening decisions are taken in this method (those decisions are
679  *     currently only based in the size of the fields to be inlined, the size
680  *     of the resulting instance is not considered)
681  */
682 void FieldLayoutBuilder::inline_class_field_sorting(TRAPS) {
683   assert(_is_inline_type, &quot;Should only be used for inline classes&quot;);
684   int alignment = 1;
685   for (AllFieldStream fs(_fields, _constant_pool); !fs.done(); fs.next()) {
686     FieldGroup* group = NULL;
687     int field_alignment = 1;
688     if (fs.access_flags().is_static()) {
689       group = _static_fields;
690     } else {
691       _has_nonstatic_fields = true;
692       _atomic_field_count++;  // we might decrement this
693       group = _root_group;
694     }
695     assert(group != NULL, &quot;invariant&quot;);
696     BasicType type = Signature::basic_type(fs.signature());
697     switch(type) {
698     case T_BYTE:
699     case T_CHAR:
700     case T_DOUBLE:
701     case T_FLOAT:
702     case T_INT:
703     case T_LONG:
704     case T_SHORT:
705     case T_BOOLEAN:
706       if (group != _static_fields) {
707         field_alignment = type2aelembytes(type); // alignment == size for primitive types
708       }
709       group-&gt;add_primitive_field(fs, type);
710       break;
711     case T_OBJECT:
712     case T_ARRAY:
713       if (group != _static_fields) {
714         _nonstatic_oopmap_count++;
715         field_alignment = type2aelembytes(type); // alignment == size for oops
716       }
717       group-&gt;add_oop_field(fs);
718       break;
<a name="3" id="anc3"></a><span class="line-modified">719     case T_INLINE_TYPE: {</span>
720 //      fs.set_inline(true);
721       _has_inline_type_fields = true;
722       if (group == _static_fields) {
723         // static fields are never inlined
724         group-&gt;add_oop_field(fs);
725       } else {
726         // Flattening decision to be taken here
727         // This code assumes all verifications have already been performed
728         // (field&#39;s type has been loaded and it is an inline klass)
729         Thread* THREAD = Thread::current();
730         Klass* klass =
731             SystemDictionary::resolve_inline_type_field_or_fail(&amp;fs,
732                 Handle(THREAD, _class_loader_data-&gt;class_loader()),
733                 _protection_domain, true, CHECK);
734         assert(klass != NULL, &quot;Sanity check&quot;);
735         ValueKlass* vk = ValueKlass::cast(klass);
736         bool too_big_to_flatten = (InlineFieldMaxFlatSize &gt;= 0 &amp;&amp;
737                                    (vk-&gt;size_helper() * HeapWordSize) &gt; InlineFieldMaxFlatSize);
738         bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();
739         bool too_volatile_to_flatten = fs.access_flags().is_volatile();
740         if (vk-&gt;is_naturally_atomic()) {
741           too_atomic_to_flatten = false;
742           //too_volatile_to_flatten = false; //FIXME
743           // volatile fields are currently never inlined, this could change in the future
744         }
745         if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {
746           group-&gt;add_inlined_field(fs, vk);
747           _nonstatic_oopmap_count += vk-&gt;nonstatic_oop_map_count();
748           field_alignment = vk-&gt;get_alignment();
749           fs.set_inlined(true);
750           if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note
751             _has_nonatomic_values = true;
752             _atomic_field_count--;  // every other field is atomic but this one
753           }
754         } else {
755           _nonstatic_oopmap_count++;
756           field_alignment = type2aelembytes(T_OBJECT);
757           group-&gt;add_oop_field(fs);
758         }
759       }
760       break;
761     }
762     default:
763       fatal(&quot;Unexpected BasicType&quot;);
764     }
765     if (!fs.access_flags().is_static() &amp;&amp; field_alignment &gt; alignment) alignment = field_alignment;
766   }
767   _alignment = alignment;
768   if (!_has_nonstatic_fields) {
769     // There are a number of fixes required throughout the type system and JIT
770     Exceptions::fthrow(THREAD_AND_LOCATION,
771                        vmSymbols::java_lang_ClassFormatError(),
772                        &quot;Value Types do not support zero instance size yet&quot;);
773     return;
774   }
775 }
776 
777 void FieldLayoutBuilder::insert_contended_padding(LayoutRawBlock* slot) {
778   if (ContendedPaddingWidth &gt; 0) {
779     LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, ContendedPaddingWidth);
780     _layout-&gt;insert(slot, padding);
781   }
782 }
783 
784 /* Computation of regular classes layout is an evolution of the previous default layout
785  * (FieldAllocationStyle 1):
786  *   - inlined fields are allocated first (because they have potentially the
787  *     least regular shapes, and are more likely to create empty slots between them,
788  *     which can then be used to allocation primitive or oop fields). Allocation is
789  *     performed from the biggest to the smallest field.
790  *   - then primitive fields (from the biggest to the smallest)
791  *   - then oop fields are allocated contiguously (to reduce the number of oopmaps
792  *     and reduce the work of the GC).
793  */
794 void FieldLayoutBuilder::compute_regular_layout() {
795   bool need_tail_padding = false;
796   prologue();
797   regular_field_sorting();
798   if (_is_contended) {
799     _layout-&gt;set_start(_layout-&gt;last_block());
800     // insertion is currently easy because the current strategy doesn&#39;t try to fill holes
801     // in super classes layouts =&gt; the _start block is by consequence the _last_block
802     insert_contended_padding(_layout-&gt;start());
803     need_tail_padding = true;
804   }
805   _layout-&gt;add(_root_group-&gt;inlined_fields());
806   _layout-&gt;add(_root_group-&gt;primitive_fields());
807   _layout-&gt;add(_root_group-&gt;oop_fields());
808 
809   if (!_contended_groups.is_empty()) {
810     for (int i = 0; i &lt; _contended_groups.length(); i++) {
811       FieldGroup* cg = _contended_groups.at(i);
812       LayoutRawBlock* start = _layout-&gt;last_block();
813       insert_contended_padding(start);
814       _layout-&gt;add(_root_group-&gt;inlined_fields());
815       _layout-&gt;add(cg-&gt;primitive_fields(), start);
816       _layout-&gt;add(cg-&gt;oop_fields(), start);
817       need_tail_padding = true;
818     }
819   }
820 
821   if (need_tail_padding) {
822     insert_contended_padding(_layout-&gt;last_block());
823   }
824   _static_layout-&gt;add(_static_fields-&gt;inlined_fields());
825   _static_layout-&gt;add_contiguously(_static_fields-&gt;oop_fields());
826   _static_layout-&gt;add(_static_fields-&gt;primitive_fields());
827 
828   epilogue();
829 }
830 
831 /* Computation of inline classes has a slightly different strategy than for
832  * regular classes. Regular classes have their oop fields allocated at the end
833  * of the layout to increase GC performances. Unfortunately, this strategy
834  * increases the number of empty slots inside an instance. Because the purpose
835  * of inline classes is to be embedded into other containers, it is critical
836  * to keep their size as small as possible. For this reason, the allocation
837  * strategy is:
838  *   - inlined fields are allocated first (because they have potentially the
839  *     least regular shapes, and are more likely to create empty slots between them,
840  *     which can then be used to allocation primitive or oop fields). Allocation is
841  *     performed from the biggest to the smallest field.
842  *   - then oop fields are allocated contiguously (to reduce the number of oopmaps
843  *     and reduce the work of the GC)
844  *   - then primitive fields (from the biggest to the smallest)
845  */
846 void FieldLayoutBuilder::compute_inline_class_layout(TRAPS) {
847   prologue();
848   inline_class_field_sorting(CHECK);
849   // Inline types are not polymorphic, so they cannot inherit fields.
850   // By consequence, at this stage, the layout must be composed of a RESERVED
851   // block, followed by an EMPTY block.
852   assert(_layout-&gt;start()-&gt;kind() == LayoutRawBlock::RESERVED, &quot;Unexpected&quot;);
853   assert(_layout-&gt;start()-&gt;next_block()-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Unexpected&quot;);
854   LayoutRawBlock* first_empty = _layout-&gt;start()-&gt;next_block();
855   if (first_empty-&gt;offset() % _alignment != 0) {
856     LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, _alignment - (first_empty-&gt;offset() % _alignment));
857     _layout-&gt;insert(first_empty, padding);
858     _layout-&gt;set_start(padding-&gt;next_block());
859   }
860 
861   _layout-&gt;add(_root_group-&gt;inlined_fields());
862   _layout-&gt;add(_root_group-&gt;oop_fields());
863   _layout-&gt;add(_root_group-&gt;primitive_fields());
864 
865   LayoutRawBlock* first_field = _layout-&gt;first_field_block();
866    if (first_field != NULL) {
867      _first_field_offset = _layout-&gt;first_field_block()-&gt;offset();
868      _exact_size_in_bytes = _layout-&gt;last_block()-&gt;offset() - _layout-&gt;first_field_block()-&gt;offset();
869    } else {
870      // special case for empty value types
871      _first_field_offset = _layout-&gt;blocks()-&gt;size();
872      _exact_size_in_bytes = 0;
873    }
874   _exact_size_in_bytes = _layout-&gt;last_block()-&gt;offset() - _layout-&gt;first_field_block()-&gt;offset();
875 
876   _static_layout-&gt;add(_static_fields-&gt;inlined_fields());
877   _static_layout-&gt;add_contiguously(_static_fields-&gt;oop_fields());
878   _static_layout-&gt;add(_static_fields-&gt;primitive_fields());
879 
880 
881   epilogue();
882 }
883 
884 void FieldLayoutBuilder::add_inlined_field_oopmap(OopMapBlocksBuilder* nonstatic_oop_maps,
885                 ValueKlass* vklass, int offset) {
886   int diff = offset - vklass-&gt;first_field_offset();
887   const OopMapBlock* map = vklass-&gt;start_of_nonstatic_oop_maps();
888   const OopMapBlock* last_map = map + vklass-&gt;nonstatic_oop_map_count();
889   while (map &lt; last_map) {
890     nonstatic_oop_maps-&gt;add(map-&gt;offset() + diff, map-&gt;count());
891     map++;
892   }
893 }
894 
895 void FieldLayoutBuilder::epilogue() {
896   // Computing oopmaps
897   int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass-&gt;nonstatic_oop_map_count();
898   int max_oop_map_count = super_oop_map_count + _nonstatic_oopmap_count;
899 
900   OopMapBlocksBuilder* nonstatic_oop_maps =
901       new OopMapBlocksBuilder(max_oop_map_count);
902   if (super_oop_map_count &gt; 0) {
903     nonstatic_oop_maps-&gt;initialize_inherited_blocks(_super_klass-&gt;start_of_nonstatic_oop_maps(),
904     _super_klass-&gt;nonstatic_oop_map_count());
905   }
906 
907   if (_root_group-&gt;oop_fields() != NULL) {
908     for (int i = 0; i &lt; _root_group-&gt;oop_fields()-&gt;length(); i++) {
909       LayoutRawBlock* b = _root_group-&gt;oop_fields()-&gt;at(i);
910       nonstatic_oop_maps-&gt;add(b-&gt;offset(), 1);
911     }
912   }
913 
914   GrowableArray&lt;LayoutRawBlock*&gt;* ff = _root_group-&gt;inlined_fields();
915   if (ff != NULL) {
916     for (int i = 0; i &lt; ff-&gt;length(); i++) {
917       LayoutRawBlock* f = ff-&gt;at(i);
918       ValueKlass* vk = f-&gt;value_klass();
919       assert(vk != NULL, &quot;Should have been initialized&quot;);
920       if (vk-&gt;contains_oops()) {
921         add_inlined_field_oopmap(nonstatic_oop_maps, vk, f-&gt;offset());
922       }
923     }
924   }
925 
926   if (!_contended_groups.is_empty()) {
927     for (int i = 0; i &lt; _contended_groups.length(); i++) {
928       FieldGroup* cg = _contended_groups.at(i);
929       if (cg-&gt;oop_count() &gt; 0) {
930         assert(cg-&gt;oop_fields() != NULL &amp;&amp; cg-&gt;oop_fields()-&gt;at(0) != NULL, &quot;oop_count &gt; 0 but no oop fields found&quot;);
931         nonstatic_oop_maps-&gt;add(cg-&gt;oop_fields()-&gt;at(0)-&gt;offset(), cg-&gt;oop_count());
932       }
933     }
934   }
935 
936   nonstatic_oop_maps-&gt;compact();
937 
938   int instance_end = align_up(_layout-&gt;last_block()-&gt;offset(), wordSize);
939   int static_fields_end = align_up(_static_layout-&gt;last_block()-&gt;offset(), wordSize);
940   int static_fields_size = (static_fields_end -
941       InstanceMirrorKlass::offset_of_static_fields()) / wordSize;
942   int nonstatic_field_end = align_up(_layout-&gt;last_block()-&gt;offset(), heapOopSize);
943 
944   // Pass back information needed for InstanceKlass creation
945 
946   _info-&gt;oop_map_blocks = nonstatic_oop_maps;
947   _info-&gt;_instance_size = align_object_size(instance_end / wordSize);
948   _info-&gt;_static_field_size = static_fields_size;
949   _info-&gt;_nonstatic_field_size = (nonstatic_field_end - instanceOopDesc::base_offset_in_bytes()) / heapOopSize;
950   _info-&gt;_has_nonstatic_fields = _has_nonstatic_fields;
951   _info-&gt;_has_inline_fields = _has_inline_type_fields;
952 
953   // An inline type is naturally atomic if it has just one field, and
954   // that field is simple enough.
955   _info-&gt;_is_naturally_atomic = (_is_inline_type &amp;&amp;
956                                  (_atomic_field_count &lt;= 1) &amp;&amp;
957                                  !_has_nonatomic_values &amp;&amp;
958                                  _contended_groups.is_empty());
959   // This may be too restrictive, since if all the fields fit in 64
960   // bits we could make the decision to align instances of this class
961   // to 64-bit boundaries, and load and store them as single words.
962   // And on machines which supported larger atomics we could similarly
963   // allow larger values to be atomic, if properly aligned.
964 
965 
966   if (PrintFieldLayout) {
967     ResourceMark rm;
968     tty-&gt;print_cr(&quot;Layout of class %s&quot;, _classname-&gt;as_C_string());
969     tty-&gt;print_cr(&quot;Instance fields:&quot;);
970     _layout-&gt;print(tty, false, _super_klass);
971     tty-&gt;print_cr(&quot;Static fields:&quot;);
972     _static_layout-&gt;print(tty, true, NULL);
973     tty-&gt;print_cr(&quot;Instance size = %d bytes&quot;, _info-&gt;_instance_size * wordSize);
974     if (_is_inline_type) {
975       tty-&gt;print_cr(&quot;First field offset = %d&quot;, _first_field_offset);
976       tty-&gt;print_cr(&quot;Alignment = %d bytes&quot;, _alignment);
977       tty-&gt;print_cr(&quot;Exact size = %d bytes&quot;, _exact_size_in_bytes);
978     }
979     tty-&gt;print_cr(&quot;---&quot;);
980   }
981 }
982 
983 void FieldLayoutBuilder::build_layout(TRAPS) {
984   if (_is_inline_type) {
985     compute_inline_class_layout(CHECK);
986   } else {
987     compute_regular_layout();
988   }
989 }
<a name="4" id="anc4"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="4" type="hidden" />
</body>
</html>