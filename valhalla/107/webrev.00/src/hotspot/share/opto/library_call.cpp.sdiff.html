<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/library_call.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="graphKit.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/library_call.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 624   case vmIntrinsics::_getCharsStringU:          return inline_string_getCharsU();
 625   case vmIntrinsics::_getCharStringU:           return inline_string_char_access(!is_store);
 626   case vmIntrinsics::_putCharStringU:           return inline_string_char_access( is_store);
 627 
 628   case vmIntrinsics::_compressStringC:
 629   case vmIntrinsics::_compressStringB:          return inline_string_copy( is_compress);
 630   case vmIntrinsics::_inflateStringC:
 631   case vmIntrinsics::_inflateStringB:           return inline_string_copy(!is_compress);
 632 
 633   case vmIntrinsics::_makePrivateBuffer:        return inline_unsafe_make_private_buffer();
 634   case vmIntrinsics::_finishPrivateBuffer:      return inline_unsafe_finish_private_buffer();
 635   case vmIntrinsics::_getReference:             return inline_unsafe_access(!is_store, T_OBJECT,   Relaxed, false);
 636   case vmIntrinsics::_getBoolean:               return inline_unsafe_access(!is_store, T_BOOLEAN,  Relaxed, false);
 637   case vmIntrinsics::_getByte:                  return inline_unsafe_access(!is_store, T_BYTE,     Relaxed, false);
 638   case vmIntrinsics::_getShort:                 return inline_unsafe_access(!is_store, T_SHORT,    Relaxed, false);
 639   case vmIntrinsics::_getChar:                  return inline_unsafe_access(!is_store, T_CHAR,     Relaxed, false);
 640   case vmIntrinsics::_getInt:                   return inline_unsafe_access(!is_store, T_INT,      Relaxed, false);
 641   case vmIntrinsics::_getLong:                  return inline_unsafe_access(!is_store, T_LONG,     Relaxed, false);
 642   case vmIntrinsics::_getFloat:                 return inline_unsafe_access(!is_store, T_FLOAT,    Relaxed, false);
 643   case vmIntrinsics::_getDouble:                return inline_unsafe_access(!is_store, T_DOUBLE,   Relaxed, false);
<span class="line-modified"> 644   case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_VALUETYPE,Relaxed, false);</span>
 645 
 646   case vmIntrinsics::_putReference:             return inline_unsafe_access( is_store, T_OBJECT,   Relaxed, false);
 647   case vmIntrinsics::_putBoolean:               return inline_unsafe_access( is_store, T_BOOLEAN,  Relaxed, false);
 648   case vmIntrinsics::_putByte:                  return inline_unsafe_access( is_store, T_BYTE,     Relaxed, false);
 649   case vmIntrinsics::_putShort:                 return inline_unsafe_access( is_store, T_SHORT,    Relaxed, false);
 650   case vmIntrinsics::_putChar:                  return inline_unsafe_access( is_store, T_CHAR,     Relaxed, false);
 651   case vmIntrinsics::_putInt:                   return inline_unsafe_access( is_store, T_INT,      Relaxed, false);
 652   case vmIntrinsics::_putLong:                  return inline_unsafe_access( is_store, T_LONG,     Relaxed, false);
 653   case vmIntrinsics::_putFloat:                 return inline_unsafe_access( is_store, T_FLOAT,    Relaxed, false);
 654   case vmIntrinsics::_putDouble:                return inline_unsafe_access( is_store, T_DOUBLE,   Relaxed, false);
<span class="line-modified"> 655   case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_VALUETYPE,Relaxed, false);</span>
 656 
 657   case vmIntrinsics::_getReferenceVolatile:     return inline_unsafe_access(!is_store, T_OBJECT,   Volatile, false);
 658   case vmIntrinsics::_getBooleanVolatile:       return inline_unsafe_access(!is_store, T_BOOLEAN,  Volatile, false);
 659   case vmIntrinsics::_getByteVolatile:          return inline_unsafe_access(!is_store, T_BYTE,     Volatile, false);
 660   case vmIntrinsics::_getShortVolatile:         return inline_unsafe_access(!is_store, T_SHORT,    Volatile, false);
 661   case vmIntrinsics::_getCharVolatile:          return inline_unsafe_access(!is_store, T_CHAR,     Volatile, false);
 662   case vmIntrinsics::_getIntVolatile:           return inline_unsafe_access(!is_store, T_INT,      Volatile, false);
 663   case vmIntrinsics::_getLongVolatile:          return inline_unsafe_access(!is_store, T_LONG,     Volatile, false);
 664   case vmIntrinsics::_getFloatVolatile:         return inline_unsafe_access(!is_store, T_FLOAT,    Volatile, false);
 665   case vmIntrinsics::_getDoubleVolatile:        return inline_unsafe_access(!is_store, T_DOUBLE,   Volatile, false);
 666 
 667   case vmIntrinsics::_putReferenceVolatile:     return inline_unsafe_access( is_store, T_OBJECT,   Volatile, false);
 668   case vmIntrinsics::_putBooleanVolatile:       return inline_unsafe_access( is_store, T_BOOLEAN,  Volatile, false);
 669   case vmIntrinsics::_putByteVolatile:          return inline_unsafe_access( is_store, T_BYTE,     Volatile, false);
 670   case vmIntrinsics::_putShortVolatile:         return inline_unsafe_access( is_store, T_SHORT,    Volatile, false);
 671   case vmIntrinsics::_putCharVolatile:          return inline_unsafe_access( is_store, T_CHAR,     Volatile, false);
 672   case vmIntrinsics::_putIntVolatile:           return inline_unsafe_access( is_store, T_INT,      Volatile, false);
 673   case vmIntrinsics::_putLongVolatile:          return inline_unsafe_access( is_store, T_LONG,     Volatile, false);
 674   case vmIntrinsics::_putFloatVolatile:         return inline_unsafe_access( is_store, T_FLOAT,    Volatile, false);
 675   case vmIntrinsics::_putDoubleVolatile:        return inline_unsafe_access( is_store, T_DOUBLE,   Volatile, false);
</pre>
<hr />
<pre>
2411   guarantee( is_store || kind != Release, &quot;Release accesses can be produced only for stores&quot;);
2412   assert(type != T_OBJECT || !unaligned, &quot;unaligned access not supported with object type&quot;);
2413 
2414   if (is_reference_type(type)) {
2415     decorators |= ON_UNKNOWN_OOP_REF;
2416   }
2417 
2418   if (unaligned) {
2419     decorators |= C2_UNALIGNED;
2420   }
2421 
2422 #ifndef PRODUCT
2423   {
2424     ResourceMark rm;
2425     // Check the signatures.
2426     ciSignature* sig = callee()-&gt;signature();
2427 #ifdef ASSERT
2428     if (!is_store) {
2429       // Object getReference(Object base, int/long offset), etc.
2430       BasicType rtype = sig-&gt;return_type()-&gt;basic_type();
<span class="line-modified">2431       assert(rtype == type || (rtype == T_OBJECT &amp;&amp; type == T_VALUETYPE), &quot;getter must return the expected value&quot;);</span>
<span class="line-modified">2432       assert(sig-&gt;count() == 2 || (type == T_VALUETYPE &amp;&amp; sig-&gt;count() == 3), &quot;oop getter has 2 or 3 arguments&quot;);</span>
2433       assert(sig-&gt;type_at(0)-&gt;basic_type() == T_OBJECT, &quot;getter base is object&quot;);
2434       assert(sig-&gt;type_at(1)-&gt;basic_type() == T_LONG, &quot;getter offset is correct&quot;);
2435     } else {
2436       // void putReference(Object base, int/long offset, Object x), etc.
2437       assert(sig-&gt;return_type()-&gt;basic_type() == T_VOID, &quot;putter must not return a value&quot;);
<span class="line-modified">2438       assert(sig-&gt;count() == 3 || (type == T_VALUETYPE &amp;&amp; sig-&gt;count() == 4), &quot;oop putter has 3 arguments&quot;);</span>
2439       assert(sig-&gt;type_at(0)-&gt;basic_type() == T_OBJECT, &quot;putter base is object&quot;);
2440       assert(sig-&gt;type_at(1)-&gt;basic_type() == T_LONG, &quot;putter offset is correct&quot;);
2441       BasicType vtype = sig-&gt;type_at(sig-&gt;count()-1)-&gt;basic_type();
<span class="line-modified">2442       assert(vtype == type || (type == T_VALUETYPE &amp;&amp; vtype == T_OBJECT), &quot;putter must accept the expected value&quot;);</span>
2443     }
2444 #endif // ASSERT
2445  }
2446 #endif //PRODUCT
2447 
2448   C-&gt;set_has_unsafe_access(true);  // Mark eventual nmethod as &quot;unsafe&quot;.
2449 
2450   Node* receiver = argument(0);  // type: oop
2451 
2452   // Build address expression.
2453   Node* adr;
2454   Node* heap_base_oop = top();
2455   Node* offset = top();
2456   Node* val;
2457 
2458   // The base is either a Java object or a value produced by Unsafe.staticFieldBase
2459   Node* base = argument(1);  // type: oop
2460   // The offset is a value produced by Unsafe.staticFieldOffset or Unsafe.objectFieldOffset
2461   offset = argument(2);  // type: long
2462   // We currently rely on the cookies produced by Unsafe.xxxFieldOffset
2463   // to be plain byte offsets, which are also the same as those accepted
2464   // by oopDesc::field_addr.
2465   assert(Unsafe_field_offset_to_byte_offset(11) == 11,
2466          &quot;fieldOffset must be byte-scaled&quot;);
2467 
2468   ciValueKlass* value_klass = NULL;
<span class="line-modified">2469   if (type == T_VALUETYPE) {</span>
2470     Node* cls = null_check(argument(4));
2471     if (stopped()) {
2472       return true;
2473     }
2474     Node* kls = load_klass_from_mirror(cls, false, NULL, 0);
2475     const TypeKlassPtr* kls_t = _gvn.type(kls)-&gt;isa_klassptr();
2476     if (!kls_t-&gt;klass_is_exact()) {
2477       return false;
2478     }
2479     ciKlass* klass = kls_t-&gt;klass();
2480     if (!klass-&gt;is_valuetype()) {
2481       return false;
2482     }
2483     value_klass = klass-&gt;as_value_klass();
2484   }
2485 
2486   receiver = null_check(receiver);
2487   if (stopped()) {
2488     return true;
2489   }
</pre>
<hr />
<pre>
2495       if (!vt-&gt;is_allocated(&amp;_gvn) || !_gvn.type(vt)-&gt;is_valuetype()-&gt;larval()) {
2496         return false;
2497       }
2498       base = vt-&gt;get_oop();
2499     } else {
2500       if (offset-&gt;is_Con()) {
2501         long off = find_long_con(offset, 0);
2502         ciValueKlass* vk = vt-&gt;type()-&gt;value_klass();
2503         if ((long)(int)off != off || !vk-&gt;contains_field_offset(off)) {
2504           return false;
2505         }
2506 
2507         ciField* f = vk-&gt;get_non_flattened_field_by_offset((int)off);
2508 
2509         if (f != NULL) {
2510           BasicType bt = f-&gt;layout_type();
2511           if (bt == T_ARRAY || bt == T_NARROWOOP) {
2512             bt = T_OBJECT;
2513           }
2514           if (bt == type) {
<span class="line-modified">2515             if (bt != T_VALUETYPE || f-&gt;type() == value_klass) {</span>
2516               set_result(vt-&gt;field_value_by_offset((int)off, false));
2517               return true;
2518             }
2519           }
2520         }
2521       }
2522       // Re-execute the unsafe access if allocation triggers deoptimization.
2523       PreserveReexecuteState preexecs(this);
2524       jvms()-&gt;set_should_reexecute(true);
2525       base = vt-&gt;buffer(this)-&gt;get_oop();
2526     }
2527   }
2528 
2529   // 32-bit machines ignore the high half!
2530   offset = ConvL2X(offset);
2531   adr = make_unsafe_address(base, offset, is_store ? ACCESS_WRITE : ACCESS_READ, type, kind == Relaxed);
2532 
2533   if (_gvn.type(base)-&gt;isa_ptr() == TypePtr::NULL_PTR) {
2534     if (type != T_OBJECT &amp;&amp; (value_klass == NULL || !value_klass-&gt;has_object_fields())) {
2535       decorators |= IN_NATIVE; // off-heap primitive access
2536     } else {
2537       return false; // off-heap oop accesses are not supported
2538     }
2539   } else {
2540     heap_base_oop = base; // on-heap or mixed access
2541   }
2542 
2543   // Can base be NULL? Otherwise, always on-heap access.
2544   bool can_access_non_heap = TypePtr::NULL_PTR-&gt;higher_equal(_gvn.type(base));
2545 
2546   if (!can_access_non_heap) {
2547     decorators |= IN_HEAP;
2548   }
2549 
<span class="line-modified">2550   val = is_store ? argument(4 + (type == T_VALUETYPE ? 1 : 0)) : NULL;</span>
2551 
2552   const TypePtr* adr_type = _gvn.type(adr)-&gt;isa_ptr();
2553   if (adr_type == TypePtr::NULL_PTR) {
2554     return false; // off-heap access with zero address
2555   }
2556 
2557   // Try to categorize the address.
2558   Compile::AliasType* alias_type = C-&gt;alias_type(adr_type);
2559   assert(alias_type-&gt;index() != Compile::AliasIdxBot, &quot;no bare pointers here&quot;);
2560 
2561   if (alias_type-&gt;adr_type() == TypeInstPtr::KLASS ||
2562       alias_type-&gt;adr_type() == TypeAryPtr::RANGE) {
2563     return false; // not supported
2564   }
2565 
2566   bool mismatched = false;
2567   BasicType bt = T_ILLEGAL;
2568   ciField* field = NULL;
2569   if (adr_type-&gt;isa_instptr()) {
2570     const TypeInstPtr* instptr = adr_type-&gt;is_instptr();
2571     ciInstanceKlass* k = instptr-&gt;klass()-&gt;as_instance_klass();
2572     int off = instptr-&gt;offset();
2573     if (instptr-&gt;const_oop() != NULL &amp;&amp;
2574         instptr-&gt;klass() == ciEnv::current()-&gt;Class_klass() &amp;&amp;
2575         instptr-&gt;offset() &gt;= (instptr-&gt;klass()-&gt;as_instance_klass()-&gt;size_helper() * wordSize)) {
2576       k = instptr-&gt;const_oop()-&gt;as_instance()-&gt;java_lang_Class_klass()-&gt;as_instance_klass();
2577       field = k-&gt;get_field_by_offset(off, true);
2578     } else {
2579       field = k-&gt;get_non_flattened_field_by_offset(off);
2580     }
2581     if (field != NULL) {
2582       bt = field-&gt;layout_type();
2583     }
<span class="line-modified">2584     assert(bt == alias_type-&gt;basic_type() || bt == T_VALUETYPE, &quot;should match&quot;);</span>
<span class="line-modified">2585     if (field != NULL &amp;&amp; bt == T_VALUETYPE &amp;&amp; !field-&gt;is_flattened()) {</span>
2586       bt = T_OBJECT;
2587     }
2588   } else {
2589     bt = alias_type-&gt;basic_type();
2590   }
2591 
2592   if (bt != T_ILLEGAL) {
2593     assert(alias_type-&gt;adr_type()-&gt;is_oopptr(), &quot;should be on-heap access&quot;);
2594     if (bt == T_BYTE &amp;&amp; adr_type-&gt;isa_aryptr()) {
2595       // Alias type doesn&#39;t differentiate between byte[] and boolean[]).
2596       // Use address type to get the element type.
2597       bt = adr_type-&gt;is_aryptr()-&gt;elem()-&gt;array_element_basic_type();
2598     }
2599     if (bt == T_ARRAY || bt == T_NARROWOOP) {
2600       // accessing an array field with getReference is not a mismatch
2601       bt = T_OBJECT;
2602     }
2603     if ((bt == T_OBJECT) != (type == T_OBJECT)) {
2604       // Don&#39;t intrinsify mismatched object accesses
2605       return false;
2606     }
2607     mismatched = (bt != type);
2608   } else if (alias_type-&gt;adr_type()-&gt;isa_oopptr()) {
2609     mismatched = true; // conservatively mark all &quot;wide&quot; on-heap accesses as mismatched
2610   }
2611 
<span class="line-modified">2612   if (type == T_VALUETYPE) {</span>
2613     if (adr_type-&gt;isa_instptr()) {
2614       if (field == NULL || field-&gt;type() != value_klass) {
2615         mismatched = true;
2616       }
2617     } else if (adr_type-&gt;isa_aryptr()) {
2618       const Type* elem = adr_type-&gt;is_aryptr()-&gt;elem();
2619       if (!elem-&gt;isa_valuetype()) {
2620         mismatched = true;
2621       } else if (elem-&gt;value_klass() != value_klass) {
2622         mismatched = true;
2623       }
2624     }
2625     if (is_store) {
2626       const Type* val_t = _gvn.type(val);
2627       if (!val_t-&gt;isa_valuetype() || val_t-&gt;value_klass() != value_klass) {
2628         return false;
2629       }
2630     }
2631   }
2632 
2633   assert(!mismatched || alias_type-&gt;adr_type()-&gt;is_oopptr(), &quot;off-heap access can&#39;t be mismatched&quot;);
2634 
2635   if (mismatched) {
2636     decorators |= C2_MISMATCHED;
2637   }
2638 
2639   // First guess at the value type.
2640   const Type *value_type = Type::get_const_basic_type(type);
2641 
2642   // Figure out the memory ordering.
2643   decorators |= mo_decorator_for_access_kind(kind);
2644 
2645   if (!is_store) {
2646     if (type == T_OBJECT) {
2647       const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);
2648       if (tjp != NULL) {
2649         value_type = tjp;
2650       }
<span class="line-modified">2651     } else if (type == T_VALUETYPE) {</span>
2652       value_type = NULL;
2653     }
2654   }
2655 
2656   // Heap pointers get a null-check from the interpreter,
2657   // as a courtesy.  However, this is not guaranteed by Unsafe,
2658   // and it is not possible to fully distinguish unintended nulls
2659   // from intended ones in this API.
2660 
2661   if (!is_store) {
2662     Node* p = NULL;
2663     // Try to constant fold a load from a constant field
2664 
2665     if (heap_base_oop != top() &amp;&amp; field != NULL &amp;&amp; field-&gt;is_constant() &amp;&amp; !mismatched) {
2666       // final or stable field
2667       p = make_constant_from_field(field, heap_base_oop);
2668     }
2669 
2670     if (p == NULL) { // Could not constant fold the load
<span class="line-modified">2671       if (type == T_VALUETYPE) {</span>
2672         if (adr_type-&gt;isa_instptr() &amp;&amp; !mismatched) {
2673           ciInstanceKlass* holder = adr_type-&gt;is_instptr()-&gt;klass()-&gt;as_instance_klass();
2674           int offset = adr_type-&gt;is_instptr()-&gt;offset();
2675           p = ValueTypeNode::make_from_flattened(this, value_klass, base, base, holder, offset, decorators);
2676         } else {
2677           p = ValueTypeNode::make_from_flattened(this, value_klass, base, adr, NULL, 0, decorators);
2678         }
2679       } else {
2680         p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);
2681       }
2682       // Normalize the value returned by getBoolean in the following cases
2683       if (type == T_BOOLEAN &amp;&amp;
2684           (mismatched ||
2685            heap_base_oop == top() ||                  // - heap_base_oop is NULL or
2686            (can_access_non_heap &amp;&amp; field == NULL))    // - heap_base_oop is potentially NULL
2687                                                       //   and the unsafe access is made to large offset
2688                                                       //   (i.e., larger than the maximum offset necessary for any
2689                                                       //   field access)
2690             ) {
2691           IdealKit ideal = IdealKit(this);
</pre>
<hr />
<pre>
2707     }
2708     if (field != NULL &amp;&amp; field-&gt;is_flattenable() &amp;&amp; !field-&gt;is_flattened()) {
2709       // Load a non-flattened but flattenable value type from memory
2710       if (value_type-&gt;value_klass()-&gt;is_scalarizable()) {
2711         p = ValueTypeNode::make_from_oop(this, p, value_type-&gt;value_klass());
2712       } else {
2713         p = null2default(p, value_type-&gt;value_klass());
2714       }
2715     }
2716     // The load node has the control of the preceding MemBarCPUOrder.  All
2717     // following nodes will have the control of the MemBarCPUOrder inserted at
2718     // the end of this method.  So, pushing the load onto the stack at a later
2719     // point is fine.
2720     set_result(p);
2721   } else {
2722     if (bt == T_ADDRESS) {
2723       // Repackage the long as a pointer.
2724       val = ConvL2X(val);
2725       val = gvn().transform(new CastX2PNode(val));
2726     }
<span class="line-modified">2727     if (type == T_VALUETYPE) {</span>
2728       if (adr_type-&gt;isa_instptr() &amp;&amp; !mismatched) {
2729         ciInstanceKlass* holder = adr_type-&gt;is_instptr()-&gt;klass()-&gt;as_instance_klass();
2730         int offset = adr_type-&gt;is_instptr()-&gt;offset();
2731         val-&gt;as_ValueType()-&gt;store_flattened(this, base, base, holder, offset, decorators);
2732       } else {
2733         val-&gt;as_ValueType()-&gt;store_flattened(this, base, adr, NULL, 0, decorators);
2734       }
2735     } else {
2736       access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);
2737     }
2738   }
2739 
2740   if (argument(1)-&gt;is_ValueType() &amp;&amp; is_store) {
2741     Node* value = ValueTypeNode::make_from_oop(this, base, _gvn.type(base)-&gt;value_klass());
2742     value = value-&gt;as_ValueType()-&gt;make_larval(this, false);
2743     replace_in_map(argument(1), value);
2744   }
2745 
2746   return true;
2747 }
</pre>
</td>
<td>
<hr />
<pre>
 624   case vmIntrinsics::_getCharsStringU:          return inline_string_getCharsU();
 625   case vmIntrinsics::_getCharStringU:           return inline_string_char_access(!is_store);
 626   case vmIntrinsics::_putCharStringU:           return inline_string_char_access( is_store);
 627 
 628   case vmIntrinsics::_compressStringC:
 629   case vmIntrinsics::_compressStringB:          return inline_string_copy( is_compress);
 630   case vmIntrinsics::_inflateStringC:
 631   case vmIntrinsics::_inflateStringB:           return inline_string_copy(!is_compress);
 632 
 633   case vmIntrinsics::_makePrivateBuffer:        return inline_unsafe_make_private_buffer();
 634   case vmIntrinsics::_finishPrivateBuffer:      return inline_unsafe_finish_private_buffer();
 635   case vmIntrinsics::_getReference:             return inline_unsafe_access(!is_store, T_OBJECT,   Relaxed, false);
 636   case vmIntrinsics::_getBoolean:               return inline_unsafe_access(!is_store, T_BOOLEAN,  Relaxed, false);
 637   case vmIntrinsics::_getByte:                  return inline_unsafe_access(!is_store, T_BYTE,     Relaxed, false);
 638   case vmIntrinsics::_getShort:                 return inline_unsafe_access(!is_store, T_SHORT,    Relaxed, false);
 639   case vmIntrinsics::_getChar:                  return inline_unsafe_access(!is_store, T_CHAR,     Relaxed, false);
 640   case vmIntrinsics::_getInt:                   return inline_unsafe_access(!is_store, T_INT,      Relaxed, false);
 641   case vmIntrinsics::_getLong:                  return inline_unsafe_access(!is_store, T_LONG,     Relaxed, false);
 642   case vmIntrinsics::_getFloat:                 return inline_unsafe_access(!is_store, T_FLOAT,    Relaxed, false);
 643   case vmIntrinsics::_getDouble:                return inline_unsafe_access(!is_store, T_DOUBLE,   Relaxed, false);
<span class="line-modified"> 644   case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_INLINE_TYPE,Relaxed, false);</span>
 645 
 646   case vmIntrinsics::_putReference:             return inline_unsafe_access( is_store, T_OBJECT,   Relaxed, false);
 647   case vmIntrinsics::_putBoolean:               return inline_unsafe_access( is_store, T_BOOLEAN,  Relaxed, false);
 648   case vmIntrinsics::_putByte:                  return inline_unsafe_access( is_store, T_BYTE,     Relaxed, false);
 649   case vmIntrinsics::_putShort:                 return inline_unsafe_access( is_store, T_SHORT,    Relaxed, false);
 650   case vmIntrinsics::_putChar:                  return inline_unsafe_access( is_store, T_CHAR,     Relaxed, false);
 651   case vmIntrinsics::_putInt:                   return inline_unsafe_access( is_store, T_INT,      Relaxed, false);
 652   case vmIntrinsics::_putLong:                  return inline_unsafe_access( is_store, T_LONG,     Relaxed, false);
 653   case vmIntrinsics::_putFloat:                 return inline_unsafe_access( is_store, T_FLOAT,    Relaxed, false);
 654   case vmIntrinsics::_putDouble:                return inline_unsafe_access( is_store, T_DOUBLE,   Relaxed, false);
<span class="line-modified"> 655   case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_INLINE_TYPE,Relaxed, false);</span>
 656 
 657   case vmIntrinsics::_getReferenceVolatile:     return inline_unsafe_access(!is_store, T_OBJECT,   Volatile, false);
 658   case vmIntrinsics::_getBooleanVolatile:       return inline_unsafe_access(!is_store, T_BOOLEAN,  Volatile, false);
 659   case vmIntrinsics::_getByteVolatile:          return inline_unsafe_access(!is_store, T_BYTE,     Volatile, false);
 660   case vmIntrinsics::_getShortVolatile:         return inline_unsafe_access(!is_store, T_SHORT,    Volatile, false);
 661   case vmIntrinsics::_getCharVolatile:          return inline_unsafe_access(!is_store, T_CHAR,     Volatile, false);
 662   case vmIntrinsics::_getIntVolatile:           return inline_unsafe_access(!is_store, T_INT,      Volatile, false);
 663   case vmIntrinsics::_getLongVolatile:          return inline_unsafe_access(!is_store, T_LONG,     Volatile, false);
 664   case vmIntrinsics::_getFloatVolatile:         return inline_unsafe_access(!is_store, T_FLOAT,    Volatile, false);
 665   case vmIntrinsics::_getDoubleVolatile:        return inline_unsafe_access(!is_store, T_DOUBLE,   Volatile, false);
 666 
 667   case vmIntrinsics::_putReferenceVolatile:     return inline_unsafe_access( is_store, T_OBJECT,   Volatile, false);
 668   case vmIntrinsics::_putBooleanVolatile:       return inline_unsafe_access( is_store, T_BOOLEAN,  Volatile, false);
 669   case vmIntrinsics::_putByteVolatile:          return inline_unsafe_access( is_store, T_BYTE,     Volatile, false);
 670   case vmIntrinsics::_putShortVolatile:         return inline_unsafe_access( is_store, T_SHORT,    Volatile, false);
 671   case vmIntrinsics::_putCharVolatile:          return inline_unsafe_access( is_store, T_CHAR,     Volatile, false);
 672   case vmIntrinsics::_putIntVolatile:           return inline_unsafe_access( is_store, T_INT,      Volatile, false);
 673   case vmIntrinsics::_putLongVolatile:          return inline_unsafe_access( is_store, T_LONG,     Volatile, false);
 674   case vmIntrinsics::_putFloatVolatile:         return inline_unsafe_access( is_store, T_FLOAT,    Volatile, false);
 675   case vmIntrinsics::_putDoubleVolatile:        return inline_unsafe_access( is_store, T_DOUBLE,   Volatile, false);
</pre>
<hr />
<pre>
2411   guarantee( is_store || kind != Release, &quot;Release accesses can be produced only for stores&quot;);
2412   assert(type != T_OBJECT || !unaligned, &quot;unaligned access not supported with object type&quot;);
2413 
2414   if (is_reference_type(type)) {
2415     decorators |= ON_UNKNOWN_OOP_REF;
2416   }
2417 
2418   if (unaligned) {
2419     decorators |= C2_UNALIGNED;
2420   }
2421 
2422 #ifndef PRODUCT
2423   {
2424     ResourceMark rm;
2425     // Check the signatures.
2426     ciSignature* sig = callee()-&gt;signature();
2427 #ifdef ASSERT
2428     if (!is_store) {
2429       // Object getReference(Object base, int/long offset), etc.
2430       BasicType rtype = sig-&gt;return_type()-&gt;basic_type();
<span class="line-modified">2431       assert(rtype == type || (rtype == T_OBJECT &amp;&amp; type == T_INLINE_TYPE), &quot;getter must return the expected value&quot;);</span>
<span class="line-modified">2432       assert(sig-&gt;count() == 2 || (type == T_INLINE_TYPE &amp;&amp; sig-&gt;count() == 3), &quot;oop getter has 2 or 3 arguments&quot;);</span>
2433       assert(sig-&gt;type_at(0)-&gt;basic_type() == T_OBJECT, &quot;getter base is object&quot;);
2434       assert(sig-&gt;type_at(1)-&gt;basic_type() == T_LONG, &quot;getter offset is correct&quot;);
2435     } else {
2436       // void putReference(Object base, int/long offset, Object x), etc.
2437       assert(sig-&gt;return_type()-&gt;basic_type() == T_VOID, &quot;putter must not return a value&quot;);
<span class="line-modified">2438       assert(sig-&gt;count() == 3 || (type == T_INLINE_TYPE &amp;&amp; sig-&gt;count() == 4), &quot;oop putter has 3 arguments&quot;);</span>
2439       assert(sig-&gt;type_at(0)-&gt;basic_type() == T_OBJECT, &quot;putter base is object&quot;);
2440       assert(sig-&gt;type_at(1)-&gt;basic_type() == T_LONG, &quot;putter offset is correct&quot;);
2441       BasicType vtype = sig-&gt;type_at(sig-&gt;count()-1)-&gt;basic_type();
<span class="line-modified">2442       assert(vtype == type || (type == T_INLINE_TYPE &amp;&amp; vtype == T_OBJECT), &quot;putter must accept the expected value&quot;);</span>
2443     }
2444 #endif // ASSERT
2445  }
2446 #endif //PRODUCT
2447 
2448   C-&gt;set_has_unsafe_access(true);  // Mark eventual nmethod as &quot;unsafe&quot;.
2449 
2450   Node* receiver = argument(0);  // type: oop
2451 
2452   // Build address expression.
2453   Node* adr;
2454   Node* heap_base_oop = top();
2455   Node* offset = top();
2456   Node* val;
2457 
2458   // The base is either a Java object or a value produced by Unsafe.staticFieldBase
2459   Node* base = argument(1);  // type: oop
2460   // The offset is a value produced by Unsafe.staticFieldOffset or Unsafe.objectFieldOffset
2461   offset = argument(2);  // type: long
2462   // We currently rely on the cookies produced by Unsafe.xxxFieldOffset
2463   // to be plain byte offsets, which are also the same as those accepted
2464   // by oopDesc::field_addr.
2465   assert(Unsafe_field_offset_to_byte_offset(11) == 11,
2466          &quot;fieldOffset must be byte-scaled&quot;);
2467 
2468   ciValueKlass* value_klass = NULL;
<span class="line-modified">2469   if (type == T_INLINE_TYPE) {</span>
2470     Node* cls = null_check(argument(4));
2471     if (stopped()) {
2472       return true;
2473     }
2474     Node* kls = load_klass_from_mirror(cls, false, NULL, 0);
2475     const TypeKlassPtr* kls_t = _gvn.type(kls)-&gt;isa_klassptr();
2476     if (!kls_t-&gt;klass_is_exact()) {
2477       return false;
2478     }
2479     ciKlass* klass = kls_t-&gt;klass();
2480     if (!klass-&gt;is_valuetype()) {
2481       return false;
2482     }
2483     value_klass = klass-&gt;as_value_klass();
2484   }
2485 
2486   receiver = null_check(receiver);
2487   if (stopped()) {
2488     return true;
2489   }
</pre>
<hr />
<pre>
2495       if (!vt-&gt;is_allocated(&amp;_gvn) || !_gvn.type(vt)-&gt;is_valuetype()-&gt;larval()) {
2496         return false;
2497       }
2498       base = vt-&gt;get_oop();
2499     } else {
2500       if (offset-&gt;is_Con()) {
2501         long off = find_long_con(offset, 0);
2502         ciValueKlass* vk = vt-&gt;type()-&gt;value_klass();
2503         if ((long)(int)off != off || !vk-&gt;contains_field_offset(off)) {
2504           return false;
2505         }
2506 
2507         ciField* f = vk-&gt;get_non_flattened_field_by_offset((int)off);
2508 
2509         if (f != NULL) {
2510           BasicType bt = f-&gt;layout_type();
2511           if (bt == T_ARRAY || bt == T_NARROWOOP) {
2512             bt = T_OBJECT;
2513           }
2514           if (bt == type) {
<span class="line-modified">2515             if (bt != T_INLINE_TYPE || f-&gt;type() == value_klass) {</span>
2516               set_result(vt-&gt;field_value_by_offset((int)off, false));
2517               return true;
2518             }
2519           }
2520         }
2521       }
2522       // Re-execute the unsafe access if allocation triggers deoptimization.
2523       PreserveReexecuteState preexecs(this);
2524       jvms()-&gt;set_should_reexecute(true);
2525       base = vt-&gt;buffer(this)-&gt;get_oop();
2526     }
2527   }
2528 
2529   // 32-bit machines ignore the high half!
2530   offset = ConvL2X(offset);
2531   adr = make_unsafe_address(base, offset, is_store ? ACCESS_WRITE : ACCESS_READ, type, kind == Relaxed);
2532 
2533   if (_gvn.type(base)-&gt;isa_ptr() == TypePtr::NULL_PTR) {
2534     if (type != T_OBJECT &amp;&amp; (value_klass == NULL || !value_klass-&gt;has_object_fields())) {
2535       decorators |= IN_NATIVE; // off-heap primitive access
2536     } else {
2537       return false; // off-heap oop accesses are not supported
2538     }
2539   } else {
2540     heap_base_oop = base; // on-heap or mixed access
2541   }
2542 
2543   // Can base be NULL? Otherwise, always on-heap access.
2544   bool can_access_non_heap = TypePtr::NULL_PTR-&gt;higher_equal(_gvn.type(base));
2545 
2546   if (!can_access_non_heap) {
2547     decorators |= IN_HEAP;
2548   }
2549 
<span class="line-modified">2550   val = is_store ? argument(4 + (type == T_INLINE_TYPE ? 1 : 0)) : NULL;</span>
2551 
2552   const TypePtr* adr_type = _gvn.type(adr)-&gt;isa_ptr();
2553   if (adr_type == TypePtr::NULL_PTR) {
2554     return false; // off-heap access with zero address
2555   }
2556 
2557   // Try to categorize the address.
2558   Compile::AliasType* alias_type = C-&gt;alias_type(adr_type);
2559   assert(alias_type-&gt;index() != Compile::AliasIdxBot, &quot;no bare pointers here&quot;);
2560 
2561   if (alias_type-&gt;adr_type() == TypeInstPtr::KLASS ||
2562       alias_type-&gt;adr_type() == TypeAryPtr::RANGE) {
2563     return false; // not supported
2564   }
2565 
2566   bool mismatched = false;
2567   BasicType bt = T_ILLEGAL;
2568   ciField* field = NULL;
2569   if (adr_type-&gt;isa_instptr()) {
2570     const TypeInstPtr* instptr = adr_type-&gt;is_instptr();
2571     ciInstanceKlass* k = instptr-&gt;klass()-&gt;as_instance_klass();
2572     int off = instptr-&gt;offset();
2573     if (instptr-&gt;const_oop() != NULL &amp;&amp;
2574         instptr-&gt;klass() == ciEnv::current()-&gt;Class_klass() &amp;&amp;
2575         instptr-&gt;offset() &gt;= (instptr-&gt;klass()-&gt;as_instance_klass()-&gt;size_helper() * wordSize)) {
2576       k = instptr-&gt;const_oop()-&gt;as_instance()-&gt;java_lang_Class_klass()-&gt;as_instance_klass();
2577       field = k-&gt;get_field_by_offset(off, true);
2578     } else {
2579       field = k-&gt;get_non_flattened_field_by_offset(off);
2580     }
2581     if (field != NULL) {
2582       bt = field-&gt;layout_type();
2583     }
<span class="line-modified">2584     assert(bt == alias_type-&gt;basic_type() || bt == T_INLINE_TYPE, &quot;should match&quot;);</span>
<span class="line-modified">2585     if (field != NULL &amp;&amp; bt == T_INLINE_TYPE &amp;&amp; !field-&gt;is_flattened()) {</span>
2586       bt = T_OBJECT;
2587     }
2588   } else {
2589     bt = alias_type-&gt;basic_type();
2590   }
2591 
2592   if (bt != T_ILLEGAL) {
2593     assert(alias_type-&gt;adr_type()-&gt;is_oopptr(), &quot;should be on-heap access&quot;);
2594     if (bt == T_BYTE &amp;&amp; adr_type-&gt;isa_aryptr()) {
2595       // Alias type doesn&#39;t differentiate between byte[] and boolean[]).
2596       // Use address type to get the element type.
2597       bt = adr_type-&gt;is_aryptr()-&gt;elem()-&gt;array_element_basic_type();
2598     }
2599     if (bt == T_ARRAY || bt == T_NARROWOOP) {
2600       // accessing an array field with getReference is not a mismatch
2601       bt = T_OBJECT;
2602     }
2603     if ((bt == T_OBJECT) != (type == T_OBJECT)) {
2604       // Don&#39;t intrinsify mismatched object accesses
2605       return false;
2606     }
2607     mismatched = (bt != type);
2608   } else if (alias_type-&gt;adr_type()-&gt;isa_oopptr()) {
2609     mismatched = true; // conservatively mark all &quot;wide&quot; on-heap accesses as mismatched
2610   }
2611 
<span class="line-modified">2612   if (type == T_INLINE_TYPE) {</span>
2613     if (adr_type-&gt;isa_instptr()) {
2614       if (field == NULL || field-&gt;type() != value_klass) {
2615         mismatched = true;
2616       }
2617     } else if (adr_type-&gt;isa_aryptr()) {
2618       const Type* elem = adr_type-&gt;is_aryptr()-&gt;elem();
2619       if (!elem-&gt;isa_valuetype()) {
2620         mismatched = true;
2621       } else if (elem-&gt;value_klass() != value_klass) {
2622         mismatched = true;
2623       }
2624     }
2625     if (is_store) {
2626       const Type* val_t = _gvn.type(val);
2627       if (!val_t-&gt;isa_valuetype() || val_t-&gt;value_klass() != value_klass) {
2628         return false;
2629       }
2630     }
2631   }
2632 
2633   assert(!mismatched || alias_type-&gt;adr_type()-&gt;is_oopptr(), &quot;off-heap access can&#39;t be mismatched&quot;);
2634 
2635   if (mismatched) {
2636     decorators |= C2_MISMATCHED;
2637   }
2638 
2639   // First guess at the value type.
2640   const Type *value_type = Type::get_const_basic_type(type);
2641 
2642   // Figure out the memory ordering.
2643   decorators |= mo_decorator_for_access_kind(kind);
2644 
2645   if (!is_store) {
2646     if (type == T_OBJECT) {
2647       const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);
2648       if (tjp != NULL) {
2649         value_type = tjp;
2650       }
<span class="line-modified">2651     } else if (type == T_INLINE_TYPE) {</span>
2652       value_type = NULL;
2653     }
2654   }
2655 
2656   // Heap pointers get a null-check from the interpreter,
2657   // as a courtesy.  However, this is not guaranteed by Unsafe,
2658   // and it is not possible to fully distinguish unintended nulls
2659   // from intended ones in this API.
2660 
2661   if (!is_store) {
2662     Node* p = NULL;
2663     // Try to constant fold a load from a constant field
2664 
2665     if (heap_base_oop != top() &amp;&amp; field != NULL &amp;&amp; field-&gt;is_constant() &amp;&amp; !mismatched) {
2666       // final or stable field
2667       p = make_constant_from_field(field, heap_base_oop);
2668     }
2669 
2670     if (p == NULL) { // Could not constant fold the load
<span class="line-modified">2671       if (type == T_INLINE_TYPE) {</span>
2672         if (adr_type-&gt;isa_instptr() &amp;&amp; !mismatched) {
2673           ciInstanceKlass* holder = adr_type-&gt;is_instptr()-&gt;klass()-&gt;as_instance_klass();
2674           int offset = adr_type-&gt;is_instptr()-&gt;offset();
2675           p = ValueTypeNode::make_from_flattened(this, value_klass, base, base, holder, offset, decorators);
2676         } else {
2677           p = ValueTypeNode::make_from_flattened(this, value_klass, base, adr, NULL, 0, decorators);
2678         }
2679       } else {
2680         p = access_load_at(heap_base_oop, adr, adr_type, value_type, type, decorators);
2681       }
2682       // Normalize the value returned by getBoolean in the following cases
2683       if (type == T_BOOLEAN &amp;&amp;
2684           (mismatched ||
2685            heap_base_oop == top() ||                  // - heap_base_oop is NULL or
2686            (can_access_non_heap &amp;&amp; field == NULL))    // - heap_base_oop is potentially NULL
2687                                                       //   and the unsafe access is made to large offset
2688                                                       //   (i.e., larger than the maximum offset necessary for any
2689                                                       //   field access)
2690             ) {
2691           IdealKit ideal = IdealKit(this);
</pre>
<hr />
<pre>
2707     }
2708     if (field != NULL &amp;&amp; field-&gt;is_flattenable() &amp;&amp; !field-&gt;is_flattened()) {
2709       // Load a non-flattened but flattenable value type from memory
2710       if (value_type-&gt;value_klass()-&gt;is_scalarizable()) {
2711         p = ValueTypeNode::make_from_oop(this, p, value_type-&gt;value_klass());
2712       } else {
2713         p = null2default(p, value_type-&gt;value_klass());
2714       }
2715     }
2716     // The load node has the control of the preceding MemBarCPUOrder.  All
2717     // following nodes will have the control of the MemBarCPUOrder inserted at
2718     // the end of this method.  So, pushing the load onto the stack at a later
2719     // point is fine.
2720     set_result(p);
2721   } else {
2722     if (bt == T_ADDRESS) {
2723       // Repackage the long as a pointer.
2724       val = ConvL2X(val);
2725       val = gvn().transform(new CastX2PNode(val));
2726     }
<span class="line-modified">2727     if (type == T_INLINE_TYPE) {</span>
2728       if (adr_type-&gt;isa_instptr() &amp;&amp; !mismatched) {
2729         ciInstanceKlass* holder = adr_type-&gt;is_instptr()-&gt;klass()-&gt;as_instance_klass();
2730         int offset = adr_type-&gt;is_instptr()-&gt;offset();
2731         val-&gt;as_ValueType()-&gt;store_flattened(this, base, base, holder, offset, decorators);
2732       } else {
2733         val-&gt;as_ValueType()-&gt;store_flattened(this, base, adr, NULL, 0, decorators);
2734       }
2735     } else {
2736       access_store_at(heap_base_oop, adr, adr_type, val, value_type, type, decorators);
2737     }
2738   }
2739 
2740   if (argument(1)-&gt;is_ValueType() &amp;&amp; is_store) {
2741     Node* value = ValueTypeNode::make_from_oop(this, base, _gvn.type(base)-&gt;value_klass());
2742     value = value-&gt;as_ValueType()-&gt;make_larval(this, false);
2743     replace_in_map(argument(1), value);
2744   }
2745 
2746   return true;
2747 }
</pre>
</td>
</tr>
</table>
<center><a href="graphKit.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>