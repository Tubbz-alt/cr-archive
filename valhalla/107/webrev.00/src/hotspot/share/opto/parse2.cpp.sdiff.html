<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/parse2.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="parse1.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="parse3.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/parse2.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  72 //---------------------------------array_load----------------------------------
  73 void Parse::array_load(BasicType bt) {
  74   const Type* elemtype = Type::TOP;
  75   Node* adr = array_addressing(bt, 0, elemtype);
  76   if (stopped())  return;     // guaranteed null or range check
  77 
  78   Node* idx = pop();
  79   Node* ary = pop();
  80 
  81   // Handle value type arrays
  82   const TypeOopPtr* elemptr = elemtype-&gt;make_oopptr();
  83   const TypeAryPtr* ary_t = _gvn.type(ary)-&gt;is_aryptr();
  84   if (elemtype-&gt;isa_valuetype() != NULL) {
  85     C-&gt;set_flattened_accesses();
  86     // Load from flattened value type array
  87     Node* vt = ValueTypeNode::make_from_flattened(this, elemtype-&gt;value_klass(), ary, adr);
  88     push(vt);
  89     return;
  90   } else if (elemptr != NULL &amp;&amp; elemptr-&gt;is_valuetypeptr() &amp;&amp; !elemptr-&gt;maybe_null()) {
  91     // Load from non-flattened but flattenable value type array (elements can never be null)
<span class="line-modified">  92     bt = T_VALUETYPE;</span>
  93   } else if (!ary_t-&gt;is_not_flat()) {
  94     // Cannot statically determine if array is flattened, emit runtime check
  95     assert(ValueArrayFlatten &amp;&amp; is_reference_type(bt) &amp;&amp; elemptr-&gt;can_be_value_type() &amp;&amp; !ary_t-&gt;klass_is_exact() &amp;&amp; !ary_t-&gt;is_not_null_free() &amp;&amp;
  96            (!elemptr-&gt;is_valuetypeptr() || elemptr-&gt;value_klass()-&gt;flatten_array()), &quot;array can&#39;t be flattened&quot;);
  97     IdealKit ideal(this);
  98     IdealVariable res(ideal);
  99     ideal.declarations_done();
 100     ideal.if_then(is_non_flattened_array(ary)); {
 101       // non-flattened
 102       assert(ideal.ctrl()-&gt;in(0)-&gt;as_If()-&gt;is_non_flattened_array_check(&amp;_gvn), &quot;Should be found&quot;);
 103       sync_kit(ideal);
 104       const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
 105       Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,
 106                                 IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
 107       ideal.sync_kit(this);
 108       ideal.set(res, ld);
 109     } ideal.else_(); {
 110       // flattened
 111       sync_kit(ideal);
 112       if (elemptr-&gt;is_valuetypeptr()) {
 113         // Element type is known, cast and load from flattened representation
 114         ciValueKlass* vk = elemptr-&gt;value_klass();
 115         assert(vk-&gt;flatten_array() &amp;&amp; elemptr-&gt;maybe_null(), &quot;must be a flattenable and nullable array&quot;);
 116         ciArrayKlass* array_klass = ciArrayKlass::make(vk);
 117         const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)-&gt;isa_aryptr();
 118         Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, arytype));
<span class="line-modified"> 119         Node* casted_adr = array_element_address(cast, idx, T_VALUETYPE, ary_t-&gt;size(), control());</span>
 120         // Re-execute flattened array load if buffering triggers deoptimization
 121         PreserveReexecuteState preexecs(this);
 122         jvms()-&gt;set_should_reexecute(true);
 123         inc_sp(2);
 124         Node* vt = ValueTypeNode::make_from_flattened(this, vk, cast, casted_adr)-&gt;buffer(this, false);
 125         ideal.set(res, vt);
 126         ideal.sync_kit(this);
 127       } else {
 128         // Element type is unknown, emit runtime call
 129         Node* kls = load_object_klass(ary);
 130         Node* k_adr = basic_plus_adr(kls, in_bytes(ArrayKlass::element_klass_offset()));
 131         Node* elem_klass = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS));
 132         Node* obj_size  = NULL;
 133         kill_dead_locals();
 134         // Re-execute flattened array load if buffering triggers deoptimization
 135         PreserveReexecuteState preexecs(this);
 136         jvms()-&gt;set_bci(_bci);
 137         jvms()-&gt;set_should_reexecute(true);
 138         inc_sp(2);
 139         Node* alloc_obj = new_instance(elem_klass, NULL, &amp;obj_size, /*deoptimize_on_exception=*/true);
</pre>
<hr />
<pre>
 143         alloc-&gt;initialization()-&gt;set_complete_with_arraycopy();
 144 
 145         // This membar keeps this access to an unknown flattened array
 146         // correctly ordered with other unknown and known flattened
 147         // array accesses.
 148         insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::VALUES));
 149 
 150         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 151         // Unknown value type might contain reference fields
 152         if (false &amp;&amp; !bs-&gt;array_copy_requires_gc_barriers(false, T_OBJECT, false, BarrierSetC2::Parsing)) {
 153           // FIXME 8230656 also merge changes from 8238759 in
 154           int base_off = sizeof(instanceOopDesc);
 155           Node* dst_base = basic_plus_adr(alloc_obj, base_off);
 156           Node* countx = obj_size;
 157           countx = _gvn.transform(new SubXNode(countx, MakeConX(base_off)));
 158           countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));
 159 
 160           assert(Klass::_lh_log2_element_size_shift == 0, &quot;use shift in place&quot;);
 161           Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));
 162           Node* elem_shift = make_load(NULL, lhp, TypeInt::INT, T_INT, MemNode::unordered);
<span class="line-modified"> 163           uint header = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE);</span>
 164           Node* base  = basic_plus_adr(ary, header);
 165           idx = Compile::conv_I2X_index(&amp;_gvn, idx, TypeInt::POS, control());
 166           Node* scale = _gvn.transform(new LShiftXNode(idx, elem_shift));
 167           Node* adr = basic_plus_adr(ary, base, scale);
 168 
 169           access_clone(adr, dst_base, countx, false);
 170         } else {
 171           ideal.sync_kit(this);
 172           ideal.make_leaf_call(OptoRuntime::load_unknown_value_Type(),
 173                                CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_value),
 174                                &quot;load_unknown_value&quot;,
 175                                ary, idx, alloc_obj);
 176           sync_kit(ideal);
 177         }
 178 
 179         // This makes sure no other thread sees a partially initialized buffered value
 180         insert_mem_bar_volatile(Op_MemBarStoreStore, Compile::AliasIdxRaw, alloc-&gt;proj_out_or_null(AllocateNode::RawAddress));
 181 
 182         // Same as MemBarCPUOrder above: keep this unknown flattened
 183         // array access correctly ordered with other flattened array
</pre>
<hr />
<pre>
 193         const Type* unknown_value = elemptr-&gt;is_instptr()-&gt;cast_to_flat_array();
 194         alloc_obj = _gvn.transform(new CheckCastPPNode(control(), alloc_obj, unknown_value));
 195 
 196         ideal.sync_kit(this);
 197         ideal.set(res, alloc_obj);
 198       }
 199     } ideal.end_if();
 200     sync_kit(ideal);
 201     Node* ld = _gvn.transform(ideal.value(res));
 202     ld = record_profile_for_speculation_at_array_load(ld);
 203     push_node(bt, ld);
 204     return;
 205   }
 206 
 207   if (elemtype == TypeInt::BOOL) {
 208     bt = T_BOOLEAN;
 209   }
 210   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
 211   Node* ld = access_load_at(ary, adr, adr_type, elemtype, bt,
 212                             IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
<span class="line-modified"> 213   if (bt == T_VALUETYPE) {</span>
 214     // Loading a non-flattened (but flattenable) value type from an array
 215     assert(!gvn().type(ld)-&gt;maybe_null(), &quot;value type array elements should never be null&quot;);
 216     if (elemptr-&gt;value_klass()-&gt;is_scalarizable()) {
 217       ld = ValueTypeNode::make_from_oop(this, ld, elemptr-&gt;value_klass());
 218     }
 219   }
 220   if (!ld-&gt;is_ValueType()) {
 221     ld = record_profile_for_speculation_at_array_load(ld);
 222   }
 223 
 224   push_node(bt, ld);
 225 }
 226 
 227 
 228 //--------------------------------array_store----------------------------------
 229 void Parse::array_store(BasicType bt) {
 230   const Type* elemtype = Type::TOP;
 231   Node* adr = array_addressing(bt, type2size[bt], elemtype);
 232   if (stopped())  return;     // guaranteed null or range check
 233   Node* cast_val = NULL;
</pre>
</td>
<td>
<hr />
<pre>
  72 //---------------------------------array_load----------------------------------
  73 void Parse::array_load(BasicType bt) {
  74   const Type* elemtype = Type::TOP;
  75   Node* adr = array_addressing(bt, 0, elemtype);
  76   if (stopped())  return;     // guaranteed null or range check
  77 
  78   Node* idx = pop();
  79   Node* ary = pop();
  80 
  81   // Handle value type arrays
  82   const TypeOopPtr* elemptr = elemtype-&gt;make_oopptr();
  83   const TypeAryPtr* ary_t = _gvn.type(ary)-&gt;is_aryptr();
  84   if (elemtype-&gt;isa_valuetype() != NULL) {
  85     C-&gt;set_flattened_accesses();
  86     // Load from flattened value type array
  87     Node* vt = ValueTypeNode::make_from_flattened(this, elemtype-&gt;value_klass(), ary, adr);
  88     push(vt);
  89     return;
  90   } else if (elemptr != NULL &amp;&amp; elemptr-&gt;is_valuetypeptr() &amp;&amp; !elemptr-&gt;maybe_null()) {
  91     // Load from non-flattened but flattenable value type array (elements can never be null)
<span class="line-modified">  92     bt = T_INLINE_TYPE;</span>
  93   } else if (!ary_t-&gt;is_not_flat()) {
  94     // Cannot statically determine if array is flattened, emit runtime check
  95     assert(ValueArrayFlatten &amp;&amp; is_reference_type(bt) &amp;&amp; elemptr-&gt;can_be_value_type() &amp;&amp; !ary_t-&gt;klass_is_exact() &amp;&amp; !ary_t-&gt;is_not_null_free() &amp;&amp;
  96            (!elemptr-&gt;is_valuetypeptr() || elemptr-&gt;value_klass()-&gt;flatten_array()), &quot;array can&#39;t be flattened&quot;);
  97     IdealKit ideal(this);
  98     IdealVariable res(ideal);
  99     ideal.declarations_done();
 100     ideal.if_then(is_non_flattened_array(ary)); {
 101       // non-flattened
 102       assert(ideal.ctrl()-&gt;in(0)-&gt;as_If()-&gt;is_non_flattened_array_check(&amp;_gvn), &quot;Should be found&quot;);
 103       sync_kit(ideal);
 104       const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
 105       Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,
 106                                 IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
 107       ideal.sync_kit(this);
 108       ideal.set(res, ld);
 109     } ideal.else_(); {
 110       // flattened
 111       sync_kit(ideal);
 112       if (elemptr-&gt;is_valuetypeptr()) {
 113         // Element type is known, cast and load from flattened representation
 114         ciValueKlass* vk = elemptr-&gt;value_klass();
 115         assert(vk-&gt;flatten_array() &amp;&amp; elemptr-&gt;maybe_null(), &quot;must be a flattenable and nullable array&quot;);
 116         ciArrayKlass* array_klass = ciArrayKlass::make(vk);
 117         const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)-&gt;isa_aryptr();
 118         Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, arytype));
<span class="line-modified"> 119         Node* casted_adr = array_element_address(cast, idx, T_INLINE_TYPE, ary_t-&gt;size(), control());</span>
 120         // Re-execute flattened array load if buffering triggers deoptimization
 121         PreserveReexecuteState preexecs(this);
 122         jvms()-&gt;set_should_reexecute(true);
 123         inc_sp(2);
 124         Node* vt = ValueTypeNode::make_from_flattened(this, vk, cast, casted_adr)-&gt;buffer(this, false);
 125         ideal.set(res, vt);
 126         ideal.sync_kit(this);
 127       } else {
 128         // Element type is unknown, emit runtime call
 129         Node* kls = load_object_klass(ary);
 130         Node* k_adr = basic_plus_adr(kls, in_bytes(ArrayKlass::element_klass_offset()));
 131         Node* elem_klass = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS));
 132         Node* obj_size  = NULL;
 133         kill_dead_locals();
 134         // Re-execute flattened array load if buffering triggers deoptimization
 135         PreserveReexecuteState preexecs(this);
 136         jvms()-&gt;set_bci(_bci);
 137         jvms()-&gt;set_should_reexecute(true);
 138         inc_sp(2);
 139         Node* alloc_obj = new_instance(elem_klass, NULL, &amp;obj_size, /*deoptimize_on_exception=*/true);
</pre>
<hr />
<pre>
 143         alloc-&gt;initialization()-&gt;set_complete_with_arraycopy();
 144 
 145         // This membar keeps this access to an unknown flattened array
 146         // correctly ordered with other unknown and known flattened
 147         // array accesses.
 148         insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::VALUES));
 149 
 150         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 151         // Unknown value type might contain reference fields
 152         if (false &amp;&amp; !bs-&gt;array_copy_requires_gc_barriers(false, T_OBJECT, false, BarrierSetC2::Parsing)) {
 153           // FIXME 8230656 also merge changes from 8238759 in
 154           int base_off = sizeof(instanceOopDesc);
 155           Node* dst_base = basic_plus_adr(alloc_obj, base_off);
 156           Node* countx = obj_size;
 157           countx = _gvn.transform(new SubXNode(countx, MakeConX(base_off)));
 158           countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));
 159 
 160           assert(Klass::_lh_log2_element_size_shift == 0, &quot;use shift in place&quot;);
 161           Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));
 162           Node* elem_shift = make_load(NULL, lhp, TypeInt::INT, T_INT, MemNode::unordered);
<span class="line-modified"> 163           uint header = arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE);</span>
 164           Node* base  = basic_plus_adr(ary, header);
 165           idx = Compile::conv_I2X_index(&amp;_gvn, idx, TypeInt::POS, control());
 166           Node* scale = _gvn.transform(new LShiftXNode(idx, elem_shift));
 167           Node* adr = basic_plus_adr(ary, base, scale);
 168 
 169           access_clone(adr, dst_base, countx, false);
 170         } else {
 171           ideal.sync_kit(this);
 172           ideal.make_leaf_call(OptoRuntime::load_unknown_value_Type(),
 173                                CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_value),
 174                                &quot;load_unknown_value&quot;,
 175                                ary, idx, alloc_obj);
 176           sync_kit(ideal);
 177         }
 178 
 179         // This makes sure no other thread sees a partially initialized buffered value
 180         insert_mem_bar_volatile(Op_MemBarStoreStore, Compile::AliasIdxRaw, alloc-&gt;proj_out_or_null(AllocateNode::RawAddress));
 181 
 182         // Same as MemBarCPUOrder above: keep this unknown flattened
 183         // array access correctly ordered with other flattened array
</pre>
<hr />
<pre>
 193         const Type* unknown_value = elemptr-&gt;is_instptr()-&gt;cast_to_flat_array();
 194         alloc_obj = _gvn.transform(new CheckCastPPNode(control(), alloc_obj, unknown_value));
 195 
 196         ideal.sync_kit(this);
 197         ideal.set(res, alloc_obj);
 198       }
 199     } ideal.end_if();
 200     sync_kit(ideal);
 201     Node* ld = _gvn.transform(ideal.value(res));
 202     ld = record_profile_for_speculation_at_array_load(ld);
 203     push_node(bt, ld);
 204     return;
 205   }
 206 
 207   if (elemtype == TypeInt::BOOL) {
 208     bt = T_BOOLEAN;
 209   }
 210   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
 211   Node* ld = access_load_at(ary, adr, adr_type, elemtype, bt,
 212                             IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
<span class="line-modified"> 213   if (bt == T_INLINE_TYPE) {</span>
 214     // Loading a non-flattened (but flattenable) value type from an array
 215     assert(!gvn().type(ld)-&gt;maybe_null(), &quot;value type array elements should never be null&quot;);
 216     if (elemptr-&gt;value_klass()-&gt;is_scalarizable()) {
 217       ld = ValueTypeNode::make_from_oop(this, ld, elemptr-&gt;value_klass());
 218     }
 219   }
 220   if (!ld-&gt;is_ValueType()) {
 221     ld = record_profile_for_speculation_at_array_load(ld);
 222   }
 223 
 224   push_node(bt, ld);
 225 }
 226 
 227 
 228 //--------------------------------array_store----------------------------------
 229 void Parse::array_store(BasicType bt) {
 230   const Type* elemtype = Type::TOP;
 231   Node* adr = array_addressing(bt, type2size[bt], elemtype);
 232   if (stopped())  return;     // guaranteed null or range check
 233   Node* cast_val = NULL;
</pre>
</td>
</tr>
</table>
<center><a href="parse1.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="parse3.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>