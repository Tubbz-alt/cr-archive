diff a/src/hotspot/cpu/aarch64/abstractInterpreter_aarch64.cpp b/src/hotspot/cpu/aarch64/abstractInterpreter_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/abstractInterpreter_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/abstractInterpreter_aarch64.cpp
@@ -46,11 +46,11 @@
     case T_VOID   : i = 6; break;
     case T_FLOAT  : i = 7; break;
     case T_DOUBLE : i = 8; break;
     case T_OBJECT : i = 9; break;
     case T_ARRAY  : i = 9; break;
-    case T_VALUETYPE : i = 10; break;
+    case T_INLINE_TYPE : i = 10; break;
     default       : ShouldNotReachHere();
   }
   assert(0 <= i && i < AbstractInterpreter::number_of_result_handlers,
          "index out of bounds");
   return i;
diff a/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
@@ -570,11 +570,11 @@
       assert(patch_code == lir_patch_none, "no patching handled here");
       __ mov(dest->as_register_lo(), (intptr_t)c->as_jlong());
       break;
     }
 
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_OBJECT: {
         if (patch_code != lir_patch_none) {
           jobject2reg_with_patching(dest->as_register(), info);
         } else {
           jobject2reg(c->as_jobject(), dest->as_register());
@@ -617,11 +617,11 @@
 }
 
 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
   LIR_Const* c = src->as_constant_ptr();
   switch (c->type()) {
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_OBJECT:
     {
       if (! c->as_jobject())
         __ str(zr, frame_map()->address_for_slot(dest->single_stack_ix()));
       else {
@@ -684,11 +684,11 @@
     break;
   case T_INT:
     assert(c->as_jint() == 0, "should be");
     insn = &Assembler::strw;
     break;
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_OBJECT:
   case T_ARRAY:
     // Non-null case is not handled on aarch64 but handled on x86
     // FIXME: do we need to add it here?
     assert(c->as_jobject() == 0, "should be");
@@ -727,11 +727,11 @@
       // Can do LONG -> OBJECT
       move_regs(src->as_register_lo(), dest->as_register());
       return;
     }
     assert(src->is_single_cpu(), "must match");
-    if (src->type() == T_OBJECT || src->type() == T_VALUETYPE) {
+    if (src->type() == T_OBJECT || src->type() == T_INLINE_TYPE) {
       __ verify_oop(src->as_register());
     }
     move_regs(src->as_register(), dest->as_register());
 
   } else if (dest->is_double_cpu()) {
@@ -821,11 +821,11 @@
     case T_DOUBLE: {
       __ strd(src->as_double_reg(), as_Address(to_addr));
       break;
     }
 
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_ARRAY:   // fall through
     case T_OBJECT:  // fall through
       if (UseCompressedOops && !wide) {
         __ strw(compressed_src, as_Address(to_addr, rscratch2));
       } else {
@@ -947,11 +947,11 @@
 
 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
   LIR_Address* addr = src->as_address_ptr();
   LIR_Address* from_addr = src->as_address_ptr();
 
-  if (addr->base()->type() == T_OBJECT || addr->base()->type() == T_VALUETYPE) {
+  if (addr->base()->type() == T_OBJECT || addr->base()->type() == T_INLINE_TYPE) {
     __ verify_oop(addr->base()->as_pointer_register());
   }
 
   if (patch_code != lir_patch_none) {
     deoptimize_trap(info);
@@ -971,11 +971,11 @@
     case T_DOUBLE: {
       __ ldrd(dest->as_double_reg(), as_Address(from_addr));
       break;
     }
 
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_ARRAY:   // fall through
     case T_OBJECT:  // fall through
       if (UseCompressedOops && !wide) {
         __ ldrw(dest->as_register(), as_Address(from_addr));
       } else {
@@ -1250,11 +1250,11 @@
 
 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
   Register len =  op->len()->as_register();
   __ uxtw(len, len);
 
-  if (UseSlowPath || op->type() == T_VALUETYPE ||
+  if (UseSlowPath || op->type() == T_INLINE_TYPE ||
       (!UseFastNewObjectArray && is_reference_type(op->type())) ||
       (!UseFastNewTypeArray   && !is_reference_type(op->type()))) {
     __ b(*op->stub()->entry());
   } else {
     Register tmp1 = op->tmp1()->as_register();
@@ -2127,11 +2127,11 @@
         imm = opr2->as_constant_ptr()->as_jint();
         break;
       case T_METADATA:
         imm = (intptr_t)(opr2->as_constant_ptr()->as_metadata());
         break;
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_OBJECT:
       case T_ARRAY:
         jobject2reg(opr2->as_constant_ptr()->as_jobject(), rscratch1);
         __ cmpoop(reg1, rscratch1);
         return;
@@ -2294,11 +2294,11 @@
         ShouldNotReachHere();
         break;
       }
       break;
     case T_LONG:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_ADDRESS:
     case T_OBJECT:
       switch (code) {
       case lir_shl:  __ lslv (dreg, lreg, count->as_register()); break;
       case lir_shr:  __ asrv (dreg, lreg, count->as_register()); break;
@@ -2331,11 +2331,11 @@
         break;
       }
       break;
     case T_LONG:
     case T_ADDRESS:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_OBJECT:
       switch (code) {
       case lir_shl:  __ lsl (dreg, lreg, count); break;
       case lir_shr:  __ asr (dreg, lreg, count); break;
       case lir_ushr: __ lsr (dreg, lreg, count); break;
@@ -3326,11 +3326,11 @@
     break;
   case T_LONG:
     xchg = &MacroAssembler::atomic_xchgal;
     add = &MacroAssembler::atomic_addal;
     break;
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_OBJECT:
   case T_ARRAY:
     if (UseCompressedOops) {
       xchg = &MacroAssembler::atomic_xchgalw;
       add = &MacroAssembler::atomic_addalw;
diff a/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
@@ -1233,11 +1233,11 @@
     BAILOUT("encountered unloaded_ciobjarrayklass due to out of memory error");
   }
 
   klass2reg_with_patching(klass_reg, obj, patching_info);
   if (x->is_never_null()) {
-    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_VALUETYPE, klass_reg, slow_path);
+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_INLINE_TYPE, klass_reg, slow_path);
   } else {
     __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);
   }
 
   LIR_Opr result = rlock_result(x);
diff a/src/hotspot/cpu/aarch64/frame_aarch64.cpp b/src/hotspot/cpu/aarch64/frame_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/frame_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/frame_aarch64.cpp
@@ -572,11 +572,11 @@
   } else {
     tos_addr = (intptr_t*)interpreter_frame_tos_address();
   }
 
   switch (type) {
-    case T_VALUETYPE :
+    case T_INLINE_TYPE :
     case T_OBJECT  :
     case T_ARRAY   : {
       oop obj;
       if (method->is_native()) {
         obj = cast_to_oop(at(interpreter_frame_oop_temp_offset));
diff a/src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp b/src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp
@@ -691,11 +691,11 @@
     Label skip;
     // Test if the return type is a value type
     ldr(rscratch1, Address(rfp, frame::interpreter_frame_method_offset * wordSize));
     ldr(rscratch1, Address(rscratch1, Method::const_offset()));
     ldrb(rscratch1, Address(rscratch1, ConstMethod::result_type_offset()));
-    cmpw(rscratch1, (u1) T_VALUETYPE);
+    cmpw(rscratch1, (u1) T_INLINE_TYPE);
     br(Assembler::NE, skip);
 
     // We are returning a value type, load its fields into registers
     // Load fields from a buffered value with a value class specific handler
 
diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
@@ -5420,11 +5420,11 @@
   bool done = true;
   bool mark_done = true;
   do {
     sig_index--;
     BasicType bt = sig->at(sig_index)._bt;
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       vt--;
     } else if (bt == T_VOID &&
                sig->at(sig_index-1)._bt != T_LONG &&
                sig->at(sig_index-1)._bt != T_DOUBLE) {
       vt++;
@@ -5499,11 +5499,11 @@
 
 // Pack fields back into a value type oop
 bool MacroAssembler::pack_value_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,
                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],
                                        int ret_off, int extra_stack_offset) {
-  assert(sig->at(sig_index)._bt == T_VALUETYPE, "should be at end delimiter");
+  assert(sig->at(sig_index)._bt == T_INLINE_TYPE, "should be at end delimiter");
   assert(to->is_valid(), "must be");
 
   if (reg_state[to->value()] == reg_written) {
     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
     return true; // Already written
@@ -5523,11 +5523,11 @@
       return false; // Not yet writable
     }
     val_obj = val_obj_tmp;
   }
 
-  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_VALUETYPE);
+  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_INLINE_TYPE);
   load_heap_oop(val_obj, Address(val_array, index));
 
   ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);
   VMRegPair from_pair;
   BasicType bt;
diff a/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp b/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
@@ -289,11 +289,11 @@
       assert((i + 1) < total_args_passed && sig_bt[i + 1] == T_VOID, "expecting half");
       // fall through
     case T_OBJECT:
     case T_ARRAY:
     case T_ADDRESS:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       if (int_args < Argument::n_int_register_parameters_j) {
         regs[i].set2(INT_ArgReg[int_args++]->as_VMReg());
       } else {
         regs[i].set2(VMRegImpl::stack2reg(stk_args));
         stk_args += 2;
@@ -373,11 +373,11 @@
     case T_OBJECT:
     case T_ARRAY:
     case T_ADDRESS:
       // Should T_METADATA be added to java_calling_convention as well ?
     case T_METADATA:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       if (int_args < SharedRuntime::java_return_convention_max_int) {
         regs[i].set2(INT_ArgReg[int_args]->as_VMReg());
         int_args ++;
       } else {
         return -1;
@@ -448,27 +448,27 @@
   if (InlineTypePassFieldsAsArgs) {
      for (int i = 0; i < sig_extended->length(); i++) {
        BasicType bt = sig_extended->at(i)._bt;
        if (SigEntry::is_reserved_entry(sig_extended, i)) {
          // Ignore reserved entry
-       } else if (bt == T_VALUETYPE) {
+       } else if (bt == T_INLINE_TYPE) {
          // In sig_extended, a value type argument starts with:
-         // T_VALUETYPE, followed by the types of the fields of the
+         // T_INLINE_TYPE, followed by the types of the fields of the
          // value type and T_VOID to mark the end of the value
          // type. Value types are flattened so, for instance, in the
          // case of a value type with an int field and a value type
          // field that itself has 2 fields, an int and a long:
-         // T_VALUETYPE T_INT T_VALUETYPE T_INT T_LONG T_VOID (second
-         // slot for the T_LONG) T_VOID (inner T_VALUETYPE) T_VOID
-         // (outer T_VALUETYPE)
+         // T_INLINE_TYPE T_INT T_INLINE_TYPE T_INT T_LONG T_VOID (second
+         // slot for the T_LONG) T_VOID (inner T_INLINE_TYPE) T_VOID
+         // (outer T_INLINE_TYPE)
          total_args_passed++;
          int vt = 1;
          do {
            i++;
            BasicType bt = sig_extended->at(i)._bt;
            BasicType prev_bt = sig_extended->at(i-1)._bt;
-           if (bt == T_VALUETYPE) {
+           if (bt == T_INLINE_TYPE) {
              vt++;
            } else if (bt == T_VOID &&
                       prev_bt != T_LONG &&
                       prev_bt != T_DOUBLE) {
              vt--;
@@ -486,11 +486,11 @@
 }
 
 
 static void gen_c2i_adapter_helper(MacroAssembler* masm, BasicType bt, const VMRegPair& reg_pair, int extraspace, const Address& to) {
 
-    assert(bt != T_VALUETYPE || !InlineTypePassFieldsAsArgs, "no inline type here");
+    assert(bt != T_INLINE_TYPE || !InlineTypePassFieldsAsArgs, "no inline type here");
 
     // Say 4 args:
     // i   st_off
     // 0   32 T_LONG
     // 1   24 T_VOID
@@ -562,11 +562,11 @@
   bool has_value_argument = false;
 
   if (InlineTypePassFieldsAsArgs) {
       // Is there an inline type argument?
      for (int i = 0; i < sig_extended->length() && !has_value_argument; i++) {
-       has_value_argument = (sig_extended->at(i)._bt == T_VALUETYPE);
+       has_value_argument = (sig_extended->at(i)._bt == T_INLINE_TYPE);
      }
      if (has_value_argument) {
       // There is at least a value type argument: we're coming from
       // compiled code so we have no buffers to back the value
       // types. Allocate the buffers here with a runtime call.
@@ -629,11 +629,11 @@
   for (int next_arg_comp = 0; next_arg_comp < total_args_passed; next_arg_comp++) {
     BasicType bt = sig_extended->at(next_arg_comp)._bt;
     // offset to start parameters
     int st_off   = (total_args_passed - next_arg_int - 1) * Interpreter::stackElementSize;
 
-    if (!InlineTypePassFieldsAsArgs || bt != T_VALUETYPE) {
+    if (!InlineTypePassFieldsAsArgs || bt != T_INLINE_TYPE) {
 
             if (SigEntry::is_reserved_entry(sig_extended, next_arg_comp)) {
                continue; // Ignore reserved entry
             }
 
@@ -649,11 +649,11 @@
              gen_c2i_adapter_helper(masm, bt, regs[next_arg_comp], extraspace, Address(sp, offset));
              next_arg_int ++;
    } else {
        ignored++;
       // get the buffer from the just allocated pool of buffers
-      int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_VALUETYPE);
+      int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_INLINE_TYPE);
       __ load_heap_oop(rscratch1, Address(r10, index));
       next_vt_arg++;
       next_arg_int++;
       int vt = 1;
       // write fields we get from compiled code in registers/stack
@@ -664,11 +664,11 @@
       // sig_extended contains a field offset in the buffer.
       do {
         next_arg_comp++;
         BasicType bt = sig_extended->at(next_arg_comp)._bt;
         BasicType prev_bt = sig_extended->at(next_arg_comp - 1)._bt;
-        if (bt == T_VALUETYPE) {
+        if (bt == T_INLINE_TYPE) {
           vt++;
           ignored++;
         } else if (bt == T_VOID && prev_bt != T_LONG && prev_bt != T_DOUBLE) {
           vt--;
           ignored++;
@@ -801,11 +801,11 @@
 
   // Now generate the shuffle code.
   for (int i = 0; i < total_args_passed; i++) {
     BasicType bt = sig->at(i)._bt;
 
-    assert(bt != T_VALUETYPE, "i2c adapter doesn't unpack value args");
+    assert(bt != T_INLINE_TYPE, "i2c adapter doesn't unpack value args");
     if (bt == T_VOID) {
       assert(i > 0 && (sig->at(i - 1)._bt == T_LONG || sig->at(i - 1)._bt == T_DOUBLE), "missing half");
       continue;
     }
 
@@ -1055,11 +1055,11 @@
       case T_LONG:
         assert((i + 1) < total_args_passed && sig_bt[i + 1] == T_VOID, "expecting half");
         // fall through
       case T_OBJECT:
       case T_ARRAY:
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_ADDRESS:
       case T_METADATA:
         if (int_args < Argument::n_int_register_parameters_c) {
           regs[i].set2(INT_ArgReg[int_args++]->as_VMReg());
         } else {
@@ -1907,11 +1907,11 @@
           }
 #endif
           int_args++;
           break;
         }
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_OBJECT:
         assert(!is_critical_native, "no oop arguments");
         object_move(masm, map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],
                     ((i == 0) && (!is_static)),
                     &receiver_offset);
@@ -2095,11 +2095,11 @@
   case T_DOUBLE :
   case T_FLOAT  :
     // Result is in v0 we'll save as needed
     break;
   case T_ARRAY:                 // Really a handle
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_OBJECT:                // Really a handle
       break; // can't de-handlize until after safepoint check
   case T_VOID: break;
   case T_LONG: break;
   default       : ShouldNotReachHere();
@@ -3340,11 +3340,11 @@
   int pack_fields_off = __ offset();
 
   int j = 1;
   for (int i = 0; i < sig_vk->length(); i++) {
     BasicType bt = sig_vk->at(i)._bt;
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       continue;
     }
     if (bt == T_VOID) {
       if (sig_vk->at(i-1)._bt == T_LONG ||
           sig_vk->at(i-1)._bt == T_DOUBLE) {
@@ -3387,11 +3387,11 @@
   int unpack_fields_off = __ offset();
 
   j = 1;
   for (int i = 0; i < sig_vk->length(); i++) {
     BasicType bt = sig_vk->at(i)._bt;
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       continue;
     }
     if (bt == T_VOID) {
       if (sig_vk->at(i-1)._bt == T_LONG ||
           sig_vk->at(i-1)._bt == T_DOUBLE) {
diff a/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/stubGenerator_aarch64.cpp
@@ -302,19 +302,19 @@
     // save current address for use by exception handling code
 
     return_address = __ pc();
 
     // store result depending on type (everything that is not
-    // T_OBJECT, T_VALUETYPE, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)
+    // T_OBJECT, T_INLINE_TYPE, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)
     // n.b. this assumes Java returns an integral result in r0
     // and a floating result in j_farg0
     __ ldr(j_rarg2, result);
     Label is_long, is_float, is_double, is_value, exit;
     __ ldr(j_rarg1, result_type);
     __ cmp(j_rarg1, (u1)T_OBJECT);
     __ br(Assembler::EQ, is_long);
-    __ cmp(j_rarg1, (u1)T_VALUETYPE);
+    __ cmp(j_rarg1, (u1)T_INLINE_TYPE);
     __ br(Assembler::EQ, is_value);
     __ cmp(j_rarg1, (u1)T_LONG);
     __ br(Assembler::EQ, is_long);
     __ cmp(j_rarg1, (u1)T_FLOAT);
     __ br(Assembler::EQ, is_float);
diff a/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/templateInterpreterGenerator_aarch64.cpp
@@ -557,11 +557,11 @@
   case T_INT    : __ uxtw(r0, r0);        break;  // FIXME: We almost certainly don't need this
   case T_LONG   : /* nothing to do */        break;
   case T_VOID   : /* nothing to do */        break;
   case T_FLOAT  : /* nothing to do */        break;
   case T_DOUBLE : /* nothing to do */        break;
-  case T_VALUETYPE: // fall through (value types are handled with oops)
+  case T_INLINE_TYPE: // fall through (value types are handled with oops)
   case T_OBJECT :
     // retrieve result from frame
     __ ldr(r0, Address(rfp, frame::interpreter_frame_oop_temp_offset*wordSize));
     // and verify it
     __ verify_oop(r0);
diff a/src/hotspot/cpu/x86/abstractInterpreter_x86.cpp b/src/hotspot/cpu/x86/abstractInterpreter_x86.cpp
--- a/src/hotspot/cpu/x86/abstractInterpreter_x86.cpp
+++ b/src/hotspot/cpu/x86/abstractInterpreter_x86.cpp
@@ -131,11 +131,11 @@
     case T_VOID   : i = 4; break;
     case T_FLOAT  : i = 5; break;  // have to treat float and double separately for SSE
     case T_DOUBLE : i = 6; break;
     case T_OBJECT : // fall through
     case T_ARRAY  : i = 7; break;
-    case T_VALUETYPE : i = 8; break;
+    case T_INLINE_TYPE : i = 8; break;
     default       : ShouldNotReachHere();
   }
   assert(0 <= i && i < AbstractInterpreter::number_of_result_handlers, "index out of bounds");
   return i;
 }
@@ -152,11 +152,11 @@
     case T_VOID   : i = 6; break;
     case T_FLOAT  : i = 7; break;
     case T_DOUBLE : i = 8; break;
     case T_OBJECT : i = 9; break;
     case T_ARRAY  : i = 9; break;
-    case T_VALUETYPE : i = 10; break;
+    case T_INLINE_TYPE : i = 10; break;
     default       : ShouldNotReachHere();
   }
   assert(0 <= i && i < AbstractInterpreter::number_of_result_handlers,
          "index out of bounds");
   return i;
diff a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
@@ -191,11 +191,11 @@
     __ push_reg(opr->as_register_lo());
   } else if (opr->is_stack()) {
     __ push_addr(frame_map()->address_for_slot(opr->single_stack_ix()));
   } else if (opr->is_constant()) {
     LIR_Const* const_opr = opr->as_constant_ptr();
-    if (const_opr->type() == T_OBJECT || const_opr->type() == T_VALUETYPE) {
+    if (const_opr->type() == T_OBJECT || const_opr->type() == T_INLINE_TYPE) {
       __ push_oop(const_opr->as_jobject());
     } else if (const_opr->type() == T_INT) {
       __ push_jint(const_opr->as_jint());
     } else {
       ShouldNotReachHere();
@@ -636,11 +636,11 @@
       __ movptr(dest->as_register_hi(), c->as_jint_hi());
 #endif // _LP64
       break;
     }
 
-    case T_VALUETYPE: // Fall through
+    case T_INLINE_TYPE: // Fall through
     case T_OBJECT: {
       if (patch_code != lir_patch_none) {
         jobject2reg_with_patching(dest->as_register(), info);
       } else {
         __ movoop(dest->as_register(), c->as_jobject());
@@ -727,11 +727,11 @@
 
     case T_ADDRESS:
       __ movptr(frame_map()->address_for_slot(dest->single_stack_ix()), c->as_jint_bits());
       break;
 
-    case T_VALUETYPE: // Fall through
+    case T_INLINE_TYPE: // Fall through
     case T_OBJECT:
       __ movoop(frame_map()->address_for_slot(dest->single_stack_ix()), c->as_jobject());
       break;
 
     case T_LONG:  // fall through
@@ -767,11 +767,11 @@
 
     case T_ADDRESS:
       __ movptr(as_Address(addr), c->as_jint_bits());
       break;
 
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_OBJECT:  // fall through
     case T_ARRAY:
       if (c->as_jobject() == NULL) {
         if (UseCompressedOops && !wide) {
           __ movl(as_Address(addr), (int32_t)NULL_WORD);
@@ -856,11 +856,11 @@
       move_regs(src->as_register_lo(), dest->as_register());
       return;
     }
 #endif
     assert(src->is_single_cpu(), "must match");
-    if (src->type() == T_OBJECT || src->type() == T_VALUETYPE) {
+    if (src->type() == T_OBJECT || src->type() == T_INLINE_TYPE) {
       __ verify_oop(src->as_register());
     }
     move_regs(src->as_register(), dest->as_register());
 
   } else if (dest->is_double_cpu()) {
@@ -1042,11 +1042,11 @@
       }
 #endif // _LP64
       break;
     }
 
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_ARRAY:   // fall through
     case T_OBJECT:  // fall through
       if (UseCompressedOops && !wide) {
         __ movl(as_Address(to_addr), compressed_src);
       } else {
@@ -1216,11 +1216,11 @@
 
   LIR_Address* addr = src->as_address_ptr();
   Address from_addr = as_Address(addr);
   Register tmp_load_klass = LP64_ONLY(rscratch1) NOT_LP64(noreg);
 
-  if (addr->base()->type() == T_OBJECT || addr->base()->type() == T_VALUETYPE) {
+  if (addr->base()->type() == T_OBJECT || addr->base()->type() == T_INLINE_TYPE) {
     __ verify_oop(addr->base()->as_pointer_register());
   }
 
   switch (type) {
     case T_BOOLEAN: // fall through
@@ -1277,11 +1277,11 @@
 #endif // !LP64
       }
       break;
     }
 
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_OBJECT:  // fall through
     case T_ARRAY:   // fall through
       if (UseCompressedOops && !wide) {
         __ movl(dest->as_register(), from_addr);
       } else {
@@ -1664,11 +1664,11 @@
 
 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
   Register len =  op->len()->as_register();
   LP64_ONLY( __ movslq(len, len); )
 
-  if (UseSlowPath || op->type() == T_VALUETYPE ||
+  if (UseSlowPath || op->type() == T_INLINE_TYPE ||
       (!UseFastNewObjectArray && is_reference_type(op->type())) ||
       (!UseFastNewTypeArray   && !is_reference_type(op->type()))) {
     __ jmp(*op->stub()->entry());
   } else {
     Register tmp1 = op->tmp1()->as_register();
diff a/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp b/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
@@ -1364,11 +1364,11 @@
   if (obj == ciEnv::unloaded_ciobjarrayklass()) {
     BAILOUT("encountered unloaded_ciobjarrayklass due to out of memory error");
   }
   klass2reg_with_patching(klass_reg, obj, patching_info);
   if (x->is_never_null()) {
-    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_VALUETYPE, klass_reg, slow_path);
+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_INLINE_TYPE, klass_reg, slow_path);
   } else {
     __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);
   }
 
   LIR_Opr result = rlock_result(x);
diff a/src/hotspot/cpu/x86/frame_x86.cpp b/src/hotspot/cpu/x86/frame_x86.cpp
--- a/src/hotspot/cpu/x86/frame_x86.cpp
+++ b/src/hotspot/cpu/x86/frame_x86.cpp
@@ -602,11 +602,11 @@
     tos_addr = (intptr_t*)interpreter_frame_tos_address();
   }
 
   switch (type) {
     case T_OBJECT  :
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_ARRAY   : {
       oop obj;
       if (method->is_native()) {
         obj = cast_to_oop(at(interpreter_frame_oop_temp_offset));
       } else {
diff a/src/hotspot/cpu/x86/gc/shared/barrierSetAssembler_x86.cpp b/src/hotspot/cpu/x86/gc/shared/barrierSetAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/gc/shared/barrierSetAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/gc/shared/barrierSetAssembler_x86.cpp
@@ -42,11 +42,11 @@
   bool in_heap = (decorators & IN_HEAP) != 0;
   bool in_native = (decorators & IN_NATIVE) != 0;
   bool is_not_null = (decorators & IS_NOT_NULL) != 0;
   bool atomic = (decorators & MO_RELAXED) != 0;
 
-  assert(type != T_VALUETYPE, "Not supported yet");
+  assert(type != T_INLINE_TYPE, "Not supported yet");
   switch (type) {
   case T_OBJECT:
   case T_ARRAY: {
     if (in_heap) {
 #ifdef _LP64
@@ -108,11 +108,11 @@
   bool in_heap = (decorators & IN_HEAP) != 0;
   bool in_native = (decorators & IN_NATIVE) != 0;
   bool is_not_null = (decorators & IS_NOT_NULL) != 0;
   bool atomic = (decorators & MO_RELAXED) != 0;
 
-  assert(type != T_VALUETYPE, "Not supported yet");
+  assert(type != T_INLINE_TYPE, "Not supported yet");
   switch (type) {
   case T_OBJECT:
   case T_ARRAY: {
     if (in_heap) {
       if (val == noreg) {
diff a/src/hotspot/cpu/x86/gc/z/zBarrierSetAssembler_x86.cpp b/src/hotspot/cpu/x86/gc/z/zBarrierSetAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/gc/z/zBarrierSetAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/gc/z/zBarrierSetAssembler_x86.cpp
@@ -196,11 +196,11 @@
                                     Register tmp1,
                                     Register tmp2,
                                     Register tmp3) {
   BLOCK_COMMENT("ZBarrierSetAssembler::store_at {");
 
-  assert(type != T_VALUETYPE, "Not supported yet");
+  assert(type != T_INLINE_TYPE, "Not supported yet");
   // Verify oop store
   if (is_reference_type(type)) {
     // Note that src could be noreg, which means we
     // are storing null and can skip verification.
     if (src != noreg) {
diff a/src/hotspot/cpu/x86/interp_masm_x86.cpp b/src/hotspot/cpu/x86/interp_masm_x86.cpp
--- a/src/hotspot/cpu/x86/interp_masm_x86.cpp
+++ b/src/hotspot/cpu/x86/interp_masm_x86.cpp
@@ -1158,11 +1158,11 @@
     Label skip;
     // Test if the return type is an inline type
     movptr(rdi, Address(rbp, frame::interpreter_frame_method_offset * wordSize));
     movptr(rdi, Address(rdi, Method::const_offset()));
     load_unsigned_byte(rdi, Address(rdi, ConstMethod::result_type_offset()));
-    cmpl(rdi, T_VALUETYPE);
+    cmpl(rdi, T_INLINE_TYPE);
     jcc(Assembler::notEqual, skip);
 
     // We are returning a value type, load its fields into registers
 #ifndef _LP64
     super_call_VM_leaf(StubRoutines::load_value_type_fields_in_regs());
diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -4711,11 +4711,11 @@
   // (lh >> _lh_log2_element_size_shift) & _lh_log2_element_size_mask;
   shrl(rcx, Klass::_lh_log2_element_size_shift);
   andl(rcx, Klass::_lh_log2_element_size_mask);
   shlptr(index); // index << rcx
 
-  lea(data, Address(array, index, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_VALUETYPE)));
+  lea(data, Address(array, index, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE)));
 }
 
 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
   if ((decorators & (ACCESS_READ | ACCESS_WRITE)) == 0) {
@@ -5358,11 +5358,11 @@
   bool done = true;
   bool mark_done = true;
   do {
     sig_index--;
     BasicType bt = sig->at(sig_index)._bt;
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       vt--;
     } else if (bt == T_VOID &&
                sig->at(sig_index-1)._bt != T_LONG &&
                sig->at(sig_index-1)._bt != T_DOUBLE) {
       vt++;
@@ -5432,11 +5432,11 @@
 
 // Pack fields back into a value type oop
 bool MacroAssembler::pack_value_helper(const GrowableArray<SigEntry>* sig, int& sig_index, int vtarg_index,
                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int& from_index, RegState reg_state[],
                                        int ret_off, int extra_stack_offset) {
-  assert(sig->at(sig_index)._bt == T_VALUETYPE, "should be at end delimiter");
+  assert(sig->at(sig_index)._bt == T_INLINE_TYPE, "should be at end delimiter");
   assert(to->is_valid(), "must be");
 
   if (reg_state[to->value()] == reg_written) {
     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);
     return true; // Already written
@@ -5456,11 +5456,11 @@
       return false; // Not yet writable
     }
     val_obj = val_obj_tmp;
   }
 
-  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_VALUETYPE);
+  int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_INLINE_TYPE);
   load_heap_oop(val_obj, Address(val_array, index));
 
   ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);
   VMRegPair from_pair;
   BasicType bt;
diff a/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp b/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
--- a/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
+++ b/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
@@ -464,11 +464,11 @@
     case T_BYTE:
     case T_BOOLEAN:
     case T_INT:
     case T_ARRAY:
     case T_OBJECT:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_ADDRESS:
       if( reg_arg0 == 9999 )  {
         reg_arg0 = i;
         regs[i].set1(rcx->as_VMReg());
       } else if( reg_arg1 == 9999 )  {
@@ -1020,11 +1020,11 @@
     case T_FLOAT:
     case T_BYTE:
     case T_SHORT:
     case T_INT:
     case T_OBJECT:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_ARRAY:
     case T_ADDRESS:
     case T_METADATA:
       regs[i].set1(VMRegImpl::stack2reg(stack++));
       break;
@@ -1302,11 +1302,11 @@
           } else {
             __ movl(reg, Address(rsp, offset));
           }
           break;
         case T_OBJECT:
-        case T_VALUETYPE:
+        case T_INLINE_TYPE:
         default: ShouldNotReachHere();
       }
     } else if (in_regs[i].first()->is_XMMRegister()) {
       if (in_sig_bt[i] == T_FLOAT) {
         int slot = handle_index++ * VMRegImpl::slots_per_word + arg_save_area;
@@ -2020,11 +2020,11 @@
 
           unpack_array_argument(masm, in_arg, in_elem_bt[i], out_regs[c_arg + 1], out_regs[c_arg]);
           c_arg++;
           break;
         }
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_OBJECT:
         assert(!is_critical_native, "no oop arguments");
         object_move(masm, map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],
                     ((i == 0) && (!is_static)),
                     &receiver_offset);
@@ -2203,11 +2203,11 @@
   case T_DOUBLE :
   case T_FLOAT  :
     // Result is in st0 we'll save as needed
     break;
   case T_ARRAY:                 // Really a handle
-  case T_VALUETYPE:             // Really a handle
+  case T_INLINE_TYPE:           // Really a handle
   case T_OBJECT:                // Really a handle
       break; // can't de-handlize until after safepoint check
   case T_VOID: break;
   case T_LONG: break;
   default       : ShouldNotReachHere();
diff a/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp b/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
--- a/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
+++ b/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
@@ -492,11 +492,11 @@
       assert((i + 1) < total_args_passed && sig_bt[i + 1] == T_VOID, "expecting half");
       // fall through
     case T_OBJECT:
     case T_ARRAY:
     case T_ADDRESS:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       if (int_args < Argument::n_int_register_parameters_j) {
         regs[i].set2(INT_ArgReg[int_args++]->as_VMReg());
       } else {
         regs[i].set2(VMRegImpl::stack2reg(stk_args));
         stk_args += 2;
@@ -571,11 +571,11 @@
       break;
     case T_LONG:
       assert(sig_bt[i + 1] == T_VOID, "expecting half");
       // fall through
     case T_OBJECT:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_ARRAY:
     case T_ADDRESS:
     case T_METADATA:
       if (int_args < Argument::n_int_register_parameters_j+1) {
         regs[i].set2(INT_ArgReg[int_args]->as_VMReg());
@@ -661,27 +661,27 @@
   if (InlineTypePassFieldsAsArgs) {
     for (int i = 0; i < sig_extended->length(); i++) {
       BasicType bt = sig_extended->at(i)._bt;
       if (SigEntry::is_reserved_entry(sig_extended, i)) {
         // Ignore reserved entry
-      } else if (bt == T_VALUETYPE) {
+      } else if (bt == T_INLINE_TYPE) {
         // In sig_extended, a value type argument starts with:
-        // T_VALUETYPE, followed by the types of the fields of the
+        // T_INLINE_TYPE, followed by the types of the fields of the
         // value type and T_VOID to mark the end of the value
         // type. Value types are flattened so, for instance, in the
         // case of a value type with an int field and a value type
         // field that itself has 2 fields, an int and a long:
-        // T_VALUETYPE T_INT T_VALUETYPE T_INT T_LONG T_VOID (second
-        // slot for the T_LONG) T_VOID (inner T_VALUETYPE) T_VOID
-        // (outer T_VALUETYPE)
+        // T_INLINE_TYPE T_INT T_INLINE_TYPE T_INT T_LONG T_VOID (second
+        // slot for the T_LONG) T_VOID (inner T_INLINE_TYPE) T_VOID
+        // (outer T_INLINE_TYPE)
         total_args_passed++;
         int vt = 1;
         do {
           i++;
           BasicType bt = sig_extended->at(i)._bt;
           BasicType prev_bt = sig_extended->at(i-1)._bt;
-          if (bt == T_VALUETYPE) {
+          if (bt == T_INLINE_TYPE) {
             vt++;
           } else if (bt == T_VOID &&
                      prev_bt != T_LONG &&
                      prev_bt != T_DOUBLE) {
             vt--;
@@ -704,11 +704,11 @@
                                    size_t size_in_bytes,
                                    const VMRegPair& reg_pair,
                                    const Address& to,
                                    int extraspace,
                                    bool is_oop) {
-  assert(bt != T_VALUETYPE || !InlineTypePassFieldsAsArgs, "no inline type here");
+  assert(bt != T_INLINE_TYPE || !InlineTypePassFieldsAsArgs, "no inline type here");
   if (bt == T_VOID) {
     assert(prev_bt == T_LONG || prev_bt == T_DOUBLE, "missing half");
     return;
   }
 
@@ -781,11 +781,11 @@
 
   if (InlineTypePassFieldsAsArgs) {
     // Is there an inline type argument?
     bool has_value_argument = false;
     for (int i = 0; i < sig_extended->length() && !has_value_argument; i++) {
-      has_value_argument = (sig_extended->at(i)._bt == T_VALUETYPE);
+      has_value_argument = (sig_extended->at(i)._bt == T_INLINE_TYPE);
     }
     if (has_value_argument) {
       // There is at least a value type argument: we're coming from
       // compiled code so we have no buffers to back the value
       // types. Allocate the buffers here with a runtime call.
@@ -844,25 +844,25 @@
 
   // Now write the args into the outgoing interpreter space
 
   // next_arg_comp is the next argument from the compiler point of
   // view (value type fields are passed in registers/on the stack). In
-  // sig_extended, a value type argument starts with: T_VALUETYPE,
+  // sig_extended, a value type argument starts with: T_INLINE_TYPE,
   // followed by the types of the fields of the value type and T_VOID
   // to mark the end of the value type. ignored counts the number of
-  // T_VALUETYPE/T_VOID. next_vt_arg is the next value type argument:
+  // T_INLINE_TYPE/T_VOID. next_vt_arg is the next value type argument:
   // used to get the buffer for that argument from the pool of buffers
   // we allocated above and want to pass to the
   // interpreter. next_arg_int is the next argument from the
   // interpreter point of view (value types are passed by reference).
   for (int next_arg_comp = 0, ignored = 0, next_vt_arg = 0, next_arg_int = 0;
        next_arg_comp < sig_extended->length(); next_arg_comp++) {
     assert(ignored <= next_arg_comp, "shouldn't skip over more slots than there are arguments");
     assert(next_arg_int <= total_args_passed, "more arguments for the interpreter than expected?");
     BasicType bt = sig_extended->at(next_arg_comp)._bt;
     int st_off = (total_args_passed - next_arg_int) * Interpreter::stackElementSize;
-    if (!InlineTypePassFieldsAsArgs || bt != T_VALUETYPE) {
+    if (!InlineTypePassFieldsAsArgs || bt != T_INLINE_TYPE) {
       if (SigEntry::is_reserved_entry(sig_extended, next_arg_comp)) {
         continue; // Ignore reserved entry
       }
       int next_off = st_off - Interpreter::stackElementSize;
       const int offset = (bt == T_LONG || bt == T_DOUBLE) ? next_off : st_off;
@@ -879,11 +879,11 @@
       }
 #endif /* ASSERT */
     } else {
       ignored++;
       // get the buffer from the just allocated pool of buffers
-      int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_VALUETYPE);
+      int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + next_vt_arg * type2aelembytes(T_INLINE_TYPE);
       __ load_heap_oop(r14, Address(rscratch2, index));
       next_vt_arg++; next_arg_int++;
       int vt = 1;
       // write fields we get from compiled code in registers/stack
       // slots to the buffer: we know we are done with that value type
@@ -893,11 +893,11 @@
       // sig_extended contains a field offset in the buffer.
       do {
         next_arg_comp++;
         BasicType bt = sig_extended->at(next_arg_comp)._bt;
         BasicType prev_bt = sig_extended->at(next_arg_comp-1)._bt;
-        if (bt == T_VALUETYPE) {
+        if (bt == T_INLINE_TYPE) {
           vt++;
           ignored++;
         } else if (bt == T_VOID &&
                    prev_bt != T_LONG &&
                    prev_bt != T_DOUBLE) {
@@ -1049,11 +1049,11 @@
 
   // Now generate the shuffle code.  Pick up all register args and move the
   // rest through the floating point stack top.
   for (int i = 0; i < total_args_passed; i++) {
     BasicType bt = sig->at(i)._bt;
-    assert(bt != T_VALUETYPE, "i2c adapter doesn't unpack value args");
+    assert(bt != T_INLINE_TYPE, "i2c adapter doesn't unpack value args");
     if (bt == T_VOID) {
       // Longs and doubles are passed in native word order, but misaligned
       // in the 32-bit build.
       BasicType prev_bt = (i > 0) ? sig->at(i-1)._bt : T_ILLEGAL;
       assert(i > 0 && (prev_bt == T_LONG || prev_bt == T_DOUBLE), "missing half");
@@ -1320,11 +1320,11 @@
       case T_LONG:
         assert((i + 1) < total_args_passed && sig_bt[i + 1] == T_VOID, "expecting half");
         // fall through
       case T_OBJECT:
       case T_ARRAY:
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_ADDRESS:
       case T_METADATA:
         if (int_args < Argument::n_int_register_parameters_c) {
           regs[i].set2(INT_ArgReg[int_args++]->as_VMReg());
 #ifdef _WIN64
@@ -1705,11 +1705,11 @@
         case T_ARRAY:
         case T_LONG:
           // handled above
           break;
         case T_OBJECT:
-        case T_VALUETYPE:
+        case T_INLINE_TYPE:
         default: ShouldNotReachHere();
       }
     } else if (in_regs[i].first()->is_XMMRegister()) {
       if (in_sig_bt[i] == T_FLOAT) {
         int offset = slot * VMRegImpl::stack_slot_size;
@@ -2619,11 +2619,11 @@
             freg_destroyed[out_regs[c_arg].first()->as_XMMRegister()->encoding()] = true;
           }
 #endif
           break;
         }
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_OBJECT:
         assert(!is_critical_native, "no oop arguments");
         object_move(masm, map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],
                     ((i == 0) && (!is_static)),
                     &receiver_offset);
@@ -2820,11 +2820,11 @@
   case T_DOUBLE :
   case T_FLOAT  :
     // Result is in xmm0 we'll save as needed
     break;
   case T_ARRAY:                 // Really a handle
-  case T_VALUETYPE:             // Really a handle
+  case T_INLINE_TYPE:           // Really a handle
   case T_OBJECT:                // Really a handle
       break; // can't de-handlize until after safepoint check
   case T_VOID: break;
   case T_LONG: break;
   default       : ShouldNotReachHere();
@@ -4347,11 +4347,11 @@
   int pack_fields_off = __ offset();
 
   int j = 1;
   for (int i = 0; i < sig_vk->length(); i++) {
     BasicType bt = sig_vk->at(i)._bt;
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       continue;
     }
     if (bt == T_VOID) {
       if (sig_vk->at(i-1)._bt == T_LONG ||
           sig_vk->at(i-1)._bt == T_DOUBLE) {
@@ -4387,11 +4387,11 @@
   int unpack_fields_off = __ offset();
 
   j = 1;
   for (int i = 0; i < sig_vk->length(); i++) {
     BasicType bt = sig_vk->at(i)._bt;
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       continue;
     }
     if (bt == T_VOID) {
       if (sig_vk->at(i-1)._bt == T_LONG ||
           sig_vk->at(i-1)._bt == T_DOUBLE) {
diff a/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp b/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
--- a/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
+++ b/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
@@ -334,17 +334,17 @@
 
     BLOCK_COMMENT("call_stub_return_address:");
     return_address = __ pc();
 
     // store result depending on type (everything that is not
-    // T_OBJECT, T_VALUETYPE, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)
+    // T_OBJECT, T_INLINE_TYPE, T_LONG, T_FLOAT or T_DOUBLE is treated as T_INT)
     __ movptr(r13, result);
     Label is_long, is_float, is_double, is_value, exit;
     __ movl(rbx, result_type);
     __ cmpl(rbx, T_OBJECT);
     __ jcc(Assembler::equal, is_long);
-    __ cmpl(rbx, T_VALUETYPE);
+    __ cmpl(rbx, T_INLINE_TYPE);
     __ jcc(Assembler::equal, is_value);
     __ cmpl(rbx, T_LONG);
     __ jcc(Assembler::equal, is_long);
     __ cmpl(rbx, T_FLOAT);
     __ jcc(Assembler::equal, is_float);
diff a/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp b/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
--- a/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
+++ b/src/hotspot/cpu/x86/templateInterpreterGenerator_x86.cpp
@@ -350,11 +350,11 @@
 #else
   case T_FLOAT  : /* nothing to do */        break;
   case T_DOUBLE : /* nothing to do */        break;
 #endif // _LP64
 
-  case T_VALUETYPE: // fall through (value types are handled with oops)
+  case T_INLINE_TYPE: // fall through (inline types are handled with oops)
   case T_OBJECT :
     // retrieve result from frame
     __ movptr(rax, Address(rbp, frame::interpreter_frame_oop_temp_offset*wordSize));
     // and verify it
     __ verify_oop(rax);
diff a/src/hotspot/share/asm/macroAssembler_common.cpp b/src/hotspot/share/asm/macroAssembler_common.cpp
--- a/src/hotspot/share/asm/macroAssembler_common.cpp
+++ b/src/hotspot/share/asm/macroAssembler_common.cpp
@@ -77,11 +77,11 @@
     } else {
       int vt = 1;
       do {
         sig_index++;
         BasicType bt = sig_cc->at(sig_index)._bt;
-        if (bt == T_VALUETYPE) {
+        if (bt == T_INLINE_TYPE) {
           vt++;
         } else if (bt == T_VOID &&
                    sig_cc->at(sig_index-1)._bt != T_LONG &&
                    sig_cc->at(sig_index-1)._bt != T_DOUBLE) {
           vt--;
diff a/src/hotspot/share/c1/c1_FrameMap.cpp b/src/hotspot/share/c1/c1_FrameMap.cpp
--- a/src/hotspot/share/c1/c1_FrameMap.cpp
+++ b/src/hotspot/share/c1/c1_FrameMap.cpp
@@ -39,11 +39,11 @@
   if (!method->is_static()) sta->append(T_OBJECT);
   // add remaining arguments
   for (int i = 0; i < sig->count(); i++) {
     ciType* type = sig->type_at(i);
     BasicType t = type->basic_type();
-    if (t == T_ARRAY || t == T_VALUETYPE) {
+    if (t == T_ARRAY || t == T_INLINE_TYPE) {
       t = T_OBJECT;
     }
     sta->append(t);
   }
   // done
diff a/src/hotspot/share/c1/c1_LIR.cpp b/src/hotspot/share/c1/c1_LIR.cpp
--- a/src/hotspot/share/c1/c1_LIR.cpp
+++ b/src/hotspot/share/c1/c1_LIR.cpp
@@ -91,11 +91,11 @@
 //---------------------------------------------------
 
 char LIR_OprDesc::type_char(BasicType t) {
   switch (t) {
     case T_ARRAY:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       t = T_OBJECT;
     case T_BOOLEAN:
     case T_CHAR:
     case T_FLOAT:
     case T_DOUBLE:
@@ -150,11 +150,11 @@
     case T_INT:
     case T_ADDRESS:
     case T_OBJECT:
     case T_METADATA:
     case T_ARRAY:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       assert((kindfield == cpu_register || kindfield == stack_value) &&
              size_field() == single_size, "must match");
       break;
 
     case T_ILLEGAL:
@@ -1057,11 +1057,11 @@
         }
         return true;
       }
     } else if (is_method_handle_invoke()) {
       BasicType bt = method()->return_type()->basic_type();
-      if (bt == T_OBJECT || bt == T_VALUETYPE) {
+      if (bt == T_OBJECT || bt == T_INLINE_TYPE) {
         // A value type might be returned from the call but we don't know its
         // type. Either we get a buffered value (and nothing needs to be done)
         // or one of the values being returned is the klass of the value type
         // (RAX on x64, with LSB set to 1) and we need to allocate a value
         // type instance of that type and initialize it with other values being
diff a/src/hotspot/share/c1/c1_LIR.hpp b/src/hotspot/share/c1/c1_LIR.hpp
--- a/src/hotspot/share/c1/c1_LIR.hpp
+++ b/src/hotspot/share/c1/c1_LIR.hpp
@@ -314,11 +314,11 @@
       case T_BYTE:
       case T_SHORT:
       case T_INT:
       case T_ADDRESS:
       case T_OBJECT:
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_ARRAY:
       case T_METADATA:
         return single_size;
         break;
 
@@ -465,11 +465,11 @@
   case T_INT:      return LIR_OprDesc::int_type;
   case T_LONG:     return LIR_OprDesc::long_type;
   case T_FLOAT:    return LIR_OprDesc::float_type;
   case T_DOUBLE:   return LIR_OprDesc::double_type;
   case T_OBJECT:
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_ARRAY:    return LIR_OprDesc::object_type;
   case T_ADDRESS:  return LIR_OprDesc::address_type;
   case T_METADATA: return LIR_OprDesc::metadata_type;
   case T_ILLEGAL:  // fall through
   default: ShouldNotReachHere(); return LIR_OprDesc::unknown_type;
@@ -651,11 +651,11 @@
 
   static LIR_Opr virtual_register(int index, BasicType type) {
     LIR_Opr res;
     switch (type) {
       case T_OBJECT: // fall through
-      case T_VALUETYPE: // fall through
+      case T_INLINE_TYPE: // fall through
       case T_ARRAY:
         res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift)  |
                                             LIR_OprDesc::object_type  |
                                             LIR_OprDesc::cpu_register |
                                             LIR_OprDesc::single_size  |
@@ -757,11 +757,11 @@
   // the index is platform independent; a double stack useing indeces 2 and 3 has always
   // index 2.
   static LIR_Opr stack(int index, BasicType type) {
     LIR_Opr res;
     switch (type) {
-      case T_VALUETYPE: // fall through
+      case T_INLINE_TYPE: // fall through
       case T_OBJECT: // fall through
       case T_ARRAY:
         res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |
                                   LIR_OprDesc::object_type           |
                                   LIR_OprDesc::stack_value           |
diff a/src/hotspot/share/c1/c1_LIRGenerator.cpp b/src/hotspot/share/c1/c1_LIRGenerator.cpp
--- a/src/hotspot/share/c1/c1_LIRGenerator.cpp
+++ b/src/hotspot/share/c1/c1_LIRGenerator.cpp
@@ -3143,11 +3143,11 @@
   if (loc->is_register()) {
     param->load_item_force(loc);
   } else {
     LIR_Address* addr = loc->as_address_ptr();
     param->load_for_store(addr->type());
-    assert(addr->type() != T_VALUETYPE, "not supported yet");
+    assert(addr->type() != T_INLINE_TYPE, "not supported yet");
     if (addr->type() == T_OBJECT) {
       __ move_wide(param->result(), addr);
     } else {
       if (addr->type() == T_LONG || addr->type() == T_DOUBLE) {
         __ unaligned_move(param->result(), addr);
diff a/src/hotspot/share/c1/c1_ValueType.cpp b/src/hotspot/share/c1/c1_ValueType.cpp
--- a/src/hotspot/share/c1/c1_ValueType.cpp
+++ b/src/hotspot/share/c1/c1_ValueType.cpp
@@ -133,11 +133,11 @@
     case T_LONG   : return longType;
     case T_FLOAT  : return floatType;
     case T_DOUBLE : return doubleType;
     case T_ARRAY  : return arrayType;
     case T_OBJECT : return objectType;
-    case T_VALUETYPE: return objectType;
+    case T_INLINE_TYPE: return objectType;
     case T_ADDRESS: return addressType;
     case T_ILLEGAL: return illegalType;
     default       : ShouldNotReachHere();
                     return illegalType;
   }
@@ -153,11 +153,11 @@
     case T_INT    : return new IntConstant   (value.as_int   ());
     case T_LONG   : return new LongConstant  (value.as_long  ());
     case T_FLOAT  : return new FloatConstant (value.as_float ());
     case T_DOUBLE : return new DoubleConstant(value.as_double());
     case T_ARRAY  : // fall through (ciConstant doesn't have an array accessor)
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_OBJECT : {
       // TODO: Common the code with GraphBuilder::load_constant?
       ciObject* obj = value.as_object();
       if (obj->is_null_object())
         return objectNull;
diff a/src/hotspot/share/ci/ciConstant.cpp b/src/hotspot/share/ci/ciConstant.cpp
--- a/src/hotspot/share/ci/ciConstant.cpp
+++ b/src/hotspot/share/ci/ciConstant.cpp
@@ -54,11 +54,11 @@
     tty->print("%f", _value._float);
     break;
   case T_DOUBLE:
     tty->print("%lf", _value._double);
     break;
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   default:
     if (is_reference_type(basic_type())) {
       _value._object->print();
     } else {
       tty->print("ILLEGAL");
diff a/src/hotspot/share/ci/ciInstance.cpp b/src/hotspot/share/ci/ciInstance.cpp
--- a/src/hotspot/share/ci/ciInstance.cpp
+++ b/src/hotspot/share/ci/ciInstance.cpp
@@ -68,11 +68,11 @@
     case T_BOOLEAN: return ciConstant(field_btype, obj->bool_field(offset));
     case T_INT:     return ciConstant(field_btype, obj->int_field(offset));
     case T_FLOAT:   return ciConstant(obj->float_field(offset));
     case T_DOUBLE:  return ciConstant(obj->double_field(offset));
     case T_LONG:    return ciConstant(obj->long_field(offset));
-    case T_VALUETYPE:  // fall through
+    case T_INLINE_TYPE:  // fall through
     case T_OBJECT:  // fall through
     case T_ARRAY: {
       oop o = obj->obj_field(offset);
 
       // A field will be "constant" if it is known always to be
diff a/src/hotspot/share/ci/ciInstanceKlass.cpp b/src/hotspot/share/ci/ciInstanceKlass.cpp
--- a/src/hotspot/share/ci/ciInstanceKlass.cpp
+++ b/src/hotspot/share/ci/ciInstanceKlass.cpp
@@ -809,11 +809,11 @@
       } else {
         ShouldNotReachHere();
       }
       break;
     }
-    case T_VALUETYPE: {
+    case T_INLINE_TYPE: {
       ResetNoHandleMark rnhm;
       Thread* THREAD = Thread::current();
       SignatureStream ss(fd->signature(), false);
       Symbol* name = ss.as_symbol();
       assert(!HAS_PENDING_EXCEPTION, "can resolve klass?");
diff a/src/hotspot/share/ci/ciMethod.cpp b/src/hotspot/share/ci/ciMethod.cpp
--- a/src/hotspot/share/ci/ciMethod.cpp
+++ b/src/hotspot/share/ci/ciMethod.cpp
@@ -1485,11 +1485,11 @@
 // ------------------------------------------------------------------
 
 static BasicType erase_to_word_type(BasicType bt) {
   if (is_subword_type(bt))   return T_INT;
   if (is_reference_type(bt)) return T_OBJECT;
-  if (bt == T_VALUETYPE)   return T_OBJECT;
+  if (bt == T_INLINE_TYPE)   return T_OBJECT;
   return bt;
 }
 
 static bool basic_types_match(ciType* t1, ciType* t2) {
   if (t1 == t2)  return true;
diff a/src/hotspot/share/ci/ciObjectFactory.cpp b/src/hotspot/share/ci/ciObjectFactory.cpp
--- a/src/hotspot/share/ci/ciObjectFactory.cpp
+++ b/src/hotspot/share/ci/ciObjectFactory.cpp
@@ -501,11 +501,11 @@
     SignatureStream ss(name->get_symbol(), false);
     int dimension = ss.skip_array_prefix();  // skip all '['s
     BasicType element_type = ss.type();
     assert(element_type != T_ARRAY, "unsuccessful decomposition");
     ciKlass* element_klass = NULL;
-    if (element_type == T_OBJECT || element_type == T_VALUETYPE) {
+    if (element_type == T_OBJECT || element_type == T_INLINE_TYPE) {
       ciEnv *env = CURRENT_THREAD_ENV;
       ciSymbol* ci_name = env->get_symbol(ss.as_symbol());
       element_klass =
         env->get_klass_by_name(accessing_klass, ci_name, false)->as_instance_klass();
     } else {
diff a/src/hotspot/share/ci/ciReplay.cpp b/src/hotspot/share/ci/ciReplay.cpp
--- a/src/hotspot/share/ci/ciReplay.cpp
+++ b/src/hotspot/share/ci/ciReplay.cpp
@@ -796,11 +796,11 @@
     ValueTypeFieldInitializer(oop vt, CompileReplay* replay)
   : _vt(vt), _replay(replay) {}
 
     void do_field(fieldDescriptor* fd) {
       BasicType bt = fd->field_type();
-      const char* string_value = bt != T_VALUETYPE ? _replay->parse_escaped_string() : NULL;
+      const char* string_value = bt != T_INLINE_TYPE ? _replay->parse_escaped_string() : NULL;
       switch (bt) {
       case T_BYTE: {
         int value = atoi(string_value);
         _vt->byte_field_put(fd->offset(), value);
         break;
@@ -849,11 +849,11 @@
         Thread* THREAD = Thread::current();
         bool res = _replay->process_staticfield_reference(string_value, _vt, fd, THREAD);
         assert(res, "should succeed for arrays & objects");
         break;
       }
-      case T_VALUETYPE: {
+      case T_INLINE_TYPE: {
         ValueKlass* vk = ValueKlass::cast(fd->field_holder()->get_inline_type_field_klass(fd->index()));
         if (fd->is_inlined()) {
           int field_offset = fd->offset() - vk->first_field_offset();
           oop obj = (oop)(cast_from_oop<address>(_vt) + field_offset);
           ValueTypeFieldInitializer init_fields(obj, _replay);
diff a/src/hotspot/share/ci/ciSignature.cpp b/src/hotspot/share/ci/ciSignature.cpp
--- a/src/hotspot/share/ci/ciSignature.cpp
+++ b/src/hotspot/share/ci/ciSignature.cpp
@@ -60,11 +60,11 @@
       type = ciType::make(ss.type());
     } else {
       ciSymbol* klass_name = env->get_symbol(ss.as_symbol());
       type = env->get_klass_by_name_impl(_accessing_klass, cpool, klass_name, false);
     }
-    if (type->is_valuetype() && ss.type() == T_VALUETYPE) {
+    if (type->is_valuetype() && ss.type() == T_INLINE_TYPE) {
       type = env->make_never_null_wrapper(type);
     }
     _types->append(type);
     if (ss.at_return_type()) {
       // Done processing the return type; do not add it into the count.
diff a/src/hotspot/share/ci/ciType.cpp b/src/hotspot/share/ci/ciType.cpp
--- a/src/hotspot/share/ci/ciType.cpp
+++ b/src/hotspot/share/ci/ciType.cpp
@@ -44,11 +44,11 @@
   assert(basic_type >= T_BOOLEAN && basic_type <= T_CONFLICT, "range check");
   _basic_type = basic_type;
 }
 
 ciType::ciType(Klass* k) : ciMetadata(k) {
-  _basic_type = k->is_array_klass() ? T_ARRAY : (k->is_inline_klass() ? T_VALUETYPE : T_OBJECT);
+  _basic_type = k->is_array_klass() ? T_ARRAY : (k->is_inline_klass() ? T_INLINE_TYPE : T_OBJECT);
 }
 
 
 // ------------------------------------------------------------------
 // ciType::is_subtype_of
@@ -103,11 +103,11 @@
 
 // ------------------------------------------------------------------
 // ciType::box_klass
 //
 ciKlass* ciType::box_klass() {
-  assert(basic_type() != T_VALUETYPE, "value type boxing not yet supported");
+  assert(basic_type() != T_INLINE_TYPE, "value type boxing not yet supported");
   if (!is_primitive_type())  return this->as_klass();  // reference types are "self boxing"
 
   // Void is "boxed" with a null.
   if (basic_type() == T_VOID)  return NULL;
 
diff a/src/hotspot/share/ci/ciValueArrayKlass.cpp b/src/hotspot/share/ci/ciValueArrayKlass.cpp
--- a/src/hotspot/share/ci/ciValueArrayKlass.cpp
+++ b/src/hotspot/share/ci/ciValueArrayKlass.cpp
@@ -56,11 +56,11 @@
 }
 
 ciValueArrayKlass::ciValueArrayKlass(ciSymbol* array_name,
                                      ciValueKlass* base_element_klass,
                                      int dimension)
-  : ciArrayKlass(array_name, dimension, T_VALUETYPE) {
+  : ciArrayKlass(array_name, dimension, T_INLINE_TYPE) {
   _base_element_klass = base_element_klass;
   _element_klass = base_element_klass;
 }
 
 // ------------------------------------------------------------------
diff a/src/hotspot/share/ci/ciValueKlass.hpp b/src/hotspot/share/ci/ciValueKlass.hpp
--- a/src/hotspot/share/ci/ciValueKlass.hpp
+++ b/src/hotspot/share/ci/ciValueKlass.hpp
@@ -50,11 +50,11 @@
   ciValueKlass(Klass* h_k) : ciInstanceKlass(h_k), _declared_nonstatic_fields(NULL) {
     assert(is_final(), "ValueKlass must be final");
   };
 
   ciValueKlass(ciSymbol* name, jobject loader, jobject protection_domain) :
-    ciInstanceKlass(name, loader, protection_domain, T_VALUETYPE) {}
+    ciInstanceKlass(name, loader, protection_domain, T_INLINE_TYPE) {}
 
   int compute_nonstatic_fields();
   const char* type_string() { return "ciValueKlass"; }
 
 public:
diff a/src/hotspot/share/classfile/bytecodeAssembler.cpp b/src/hotspot/share/classfile/bytecodeAssembler.cpp
--- a/src/hotspot/share/classfile/bytecodeAssembler.cpp
+++ b/src/hotspot/share/classfile/bytecodeAssembler.cpp
@@ -184,11 +184,11 @@
     case T_SHORT:
     case T_INT:     iload(index); break;
     case T_FLOAT:   fload(index); break;
     case T_DOUBLE:  dload(index); break;
     case T_LONG:    lload(index); break;
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     default:
       if (is_reference_type(bt)) {
                     aload(index);
                     break;
       }
@@ -254,11 +254,11 @@
     case T_SHORT:
     case T_INT:     ireturn(); break;
     case T_FLOAT:   freturn(); break;
     case T_DOUBLE:  dreturn(); break;
     case T_LONG:    lreturn(); break;
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_VOID:    _return(); break;
     default:
       if (is_reference_type(bt)) {
                     areturn();
                     break;
diff a/src/hotspot/share/classfile/classFileParser.cpp b/src/hotspot/share/classfile/classFileParser.cpp
--- a/src/hotspot/share/classfile/classFileParser.cpp
+++ b/src/hotspot/share/classfile/classFileParser.cpp
@@ -1544,11 +1544,11 @@
   NONSTATIC_SHORT,     // T_SHORT       =  9,
   NONSTATIC_WORD,      // T_INT         = 10,
   NONSTATIC_DOUBLE,    // T_LONG        = 11,
   NONSTATIC_OOP,       // T_OBJECT      = 12,
   NONSTATIC_OOP,       // T_ARRAY       = 13,
-  NONSTATIC_OOP,       // T_VALUETYPE   = 14,
+  NONSTATIC_OOP,       // T_INLINE_TYPE = 14,
   BAD_ALLOCATION_TYPE, // T_VOID        = 15,
   BAD_ALLOCATION_TYPE, // T_ADDRESS     = 16,
   BAD_ALLOCATION_TYPE, // T_NARROWOOP   = 17,
   BAD_ALLOCATION_TYPE, // T_METADATA    = 18,
   BAD_ALLOCATION_TYPE, // T_NARROWKLASS = 19,
@@ -1565,11 +1565,11 @@
   STATIC_SHORT,        // T_SHORT       =  9,
   STATIC_WORD,         // T_INT         = 10,
   STATIC_DOUBLE,       // T_LONG        = 11,
   STATIC_OOP,          // T_OBJECT      = 12,
   STATIC_OOP,          // T_ARRAY       = 13,
-  STATIC_OOP,          // T_VALUETYPE   = 14,
+  STATIC_OOP,          // T_INLINE_TYPE = 14,
   BAD_ALLOCATION_TYPE, // T_VOID        = 15,
   BAD_ALLOCATION_TYPE, // T_ADDRESS     = 16,
   BAD_ALLOCATION_TYPE, // T_NARROWOOP   = 17,
   BAD_ALLOCATION_TYPE, // T_METADATA    = 18,
   BAD_ALLOCATION_TYPE, // T_NARROWKLASS = 19,
@@ -1751,11 +1751,11 @@
                       signature_index,
                       constantvalue_index);
     const BasicType type = cp->basic_type_for_signature_at(signature_index);
 
     // Remember how many oops we encountered and compute allocation type
-    const FieldAllocationType atype = fac->update(is_static, type, type == T_VALUETYPE);
+    const FieldAllocationType atype = fac->update(is_static, type, type == T_INLINE_TYPE);
     field->set_allocation_type(atype);
 
     // After field is initialized with type, we can augment it with aux info
     if (parsed_annotations.has_any_annotations()) {
       parsed_annotations.apply_to(field);
@@ -7280,11 +7280,11 @@
   assert(_fac != NULL, "invariant");
   assert(_parsed_annotations != NULL, "invariant");
 
 
   for (AllFieldStream fs(_fields, cp); !fs.done(); fs.next()) {
-    if (Signature::basic_type(fs.signature()) == T_VALUETYPE  && !fs.access_flags().is_static()) {
+    if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE  && !fs.access_flags().is_static()) {
       // Pre-load inline class
       Klass* klass = SystemDictionary::resolve_inline_type_field_or_fail(&fs,
           Handle(THREAD, _loader_data->class_loader()),
           _protection_domain, true, CHECK);
       assert(klass != NULL, "Sanity check");
diff a/src/hotspot/share/classfile/fieldLayoutBuilder.cpp b/src/hotspot/share/classfile/fieldLayoutBuilder.cpp
--- a/src/hotspot/share/classfile/fieldLayoutBuilder.cpp
+++ b/src/hotspot/share/classfile/fieldLayoutBuilder.cpp
@@ -318,11 +318,11 @@
       BasicType type = Signature::basic_type(fs.signature());
       // distinction between static and non-static fields is missing
       if (fs.access_flags().is_static()) continue;
       has_instance_fields = true;
       LayoutRawBlock* block;
-      if (type == T_VALUETYPE) {
+      if (type == T_INLINE_TYPE) {
         ValueKlass* vk = ValueKlass::cast(ik->get_inline_type_field_klass(fs.index()));
         block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED, vk->get_exact_size_in_bytes(),
                                    vk->get_alignment(), false);
 
       } else {
@@ -612,11 +612,11 @@
     case T_OBJECT:
     case T_ARRAY:
       if (group != _static_fields) _nonstatic_oopmap_count++;
       group->add_oop_field(fs);
       break;
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
 //      fs.set_inline(true);
       _has_inline_type_fields = true;
       if (group == _static_fields) {
         // static fields are never inlined
         group->add_oop_field(fs);
@@ -714,11 +714,11 @@
         _nonstatic_oopmap_count++;
         field_alignment = type2aelembytes(type); // alignment == size for oops
       }
       group->add_oop_field(fs);
       break;
-    case T_VALUETYPE: {
+    case T_INLINE_TYPE: {
 //      fs.set_inline(true);
       _has_inline_type_fields = true;
       if (group == _static_fields) {
         // static fields are never inlined
         group->add_oop_field(fs);
diff a/src/hotspot/share/classfile/javaClasses.cpp b/src/hotspot/share/classfile/javaClasses.cpp
--- a/src/hotspot/share/classfile/javaClasses.cpp
+++ b/src/hotspot/share/classfile/javaClasses.cpp
@@ -1128,11 +1128,11 @@
         _m()->short_field_put(fd->offset(), 0);
         break;
       case T_BOOLEAN:
         _m()->bool_field_put(fd->offset(), false);
         break;
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_ARRAY:
       case T_OBJECT: {
         // It might be useful to cache the String field, but
         // for now just clear out any reference field
         oop o = _m()->obj_field(fd->offset());
diff a/src/hotspot/share/classfile/stackMapFrame.cpp b/src/hotspot/share/classfile/stackMapFrame.cpp
--- a/src/hotspot/share/classfile/stackMapFrame.cpp
+++ b/src/hotspot/share/classfile/stackMapFrame.cpp
@@ -98,22 +98,22 @@
   _locals_size = init_local_num;
 
   switch (ss.type()) {
     case T_OBJECT:
     case T_ARRAY:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     {
       Symbol* sig = ss.as_symbol();
       if (!sig->is_permanent()) {
         // Create another symbol to save as signature stream unreferences
         // this symbol.
         Symbol *sig_copy =
           verifier()->create_temporary_symbol(sig);
         assert(sig_copy == sig, "symbols don't match");
         sig = sig_copy;
       }
-      if (ss.type() == T_VALUETYPE) {
+      if (ss.type() == T_INLINE_TYPE) {
         return VerificationType::inline_type(sig);
       }
       return VerificationType::reference_type(sig);
     }
     case T_INT:     return VerificationType::integer_type();
diff a/src/hotspot/share/classfile/systemDictionary.cpp b/src/hotspot/share/classfile/systemDictionary.cpp
--- a/src/hotspot/share/classfile/systemDictionary.cpp
+++ b/src/hotspot/share/classfile/systemDictionary.cpp
@@ -1086,11 +1086,11 @@
     // dimension and object_key in FieldArrayInfo are assigned as a
     // side-effect of this call
     SignatureStream ss(class_name, false);
     int ndims = ss.skip_array_prefix();  // skip all '['s
     BasicType t = ss.type();
-    if (t != T_OBJECT && t != T_VALUETYPE) {
+    if (t != T_OBJECT && t != T_INLINE_TYPE) {
       k = Universe::typeArrayKlassObj(t);
     } else {
       k = SystemDictionary::find(ss.as_symbol(), class_loader, protection_domain, THREAD);
     }
     if (k != NULL) {
@@ -1485,11 +1485,11 @@
   }
 
 
   if (ik->has_inline_type_fields()) {
     for (AllFieldStream fs(ik->fields(), ik->constants()); !fs.done(); fs.next()) {
-      if (Signature::basic_type(fs.signature()) == T_VALUETYPE) {
+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {
         if (!fs.access_flags().is_static()) {
           // Pre-load inline class
           Klass* real_k = SystemDictionary::resolve_inline_type_field_or_fail(&fs,
             class_loader, protection_domain, true, CHECK_NULL);
           Klass* k = ik->get_inline_type_field_klass_or_null(fs.index());
@@ -1608,11 +1608,11 @@
     }
   }
 
   if (klass->has_inline_type_fields()) {
     for (AllFieldStream fs(klass->fields(), klass->constants()); !fs.done(); fs.next()) {
-      if (Signature::basic_type(fs.signature()) == T_VALUETYPE) {
+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {
         if (!fs.access_flags().is_static()) {
           Klass* real_k = SystemDictionary::resolve_inline_type_field_or_fail(&fs,
             Handle(THREAD, loader_data->class_loader()), domain, true, CHECK);
           Klass* k = klass->get_inline_type_field_klass_or_null(fs.index());
           assert(real_k == k, "oops, the app has substituted a different version of k!");
@@ -2436,11 +2436,11 @@
     // For array classes, their Klass*s are not kept in the
     // constraint table. The element Klass*s are.
     SignatureStream ss(class_name, false);
     int ndims = ss.skip_array_prefix();  // skip all '['s
     BasicType t = ss.type();
-    if (t != T_OBJECT && t != T_VALUETYPE) {
+    if (t != T_OBJECT && t != T_INLINE_TYPE) {
       klass = Universe::typeArrayKlassObj(t);
     } else {
       MutexLocker mu(THREAD, SystemDictionary_lock);
       klass = constraints()->find_constrained_klass(ss.as_symbol(), class_loader);
     }
diff a/src/hotspot/share/classfile/verificationType.cpp b/src/hotspot/share/classfile/verificationType.cpp
--- a/src/hotspot/share/classfile/verificationType.cpp
+++ b/src/hotspot/share/classfile/verificationType.cpp
@@ -212,17 +212,17 @@
     case T_LONG:    return VerificationType(Long);
     case T_FLOAT:   return VerificationType(Float);
     case T_DOUBLE:  return VerificationType(Double);
     case T_ARRAY:
     case T_OBJECT:
-    case T_VALUETYPE: {
+    case T_INLINE_TYPE: {
       guarantee(ss.is_reference(), "unchecked verifier input?");
       Symbol* component = ss.as_symbol();
       // Create another symbol to save as signature stream unreferences this symbol.
       Symbol* component_copy = context->create_temporary_symbol(component);
       assert(component_copy == component, "symbols don't match");
-      return (ss.type() == T_VALUETYPE) ?
+      return (ss.type() == T_INLINE_TYPE) ?
         VerificationType::inline_type(component_copy) :
         VerificationType::reference_type(component_copy);
    }
    default:
      // Met an invalid type signature, e.g. [X
diff a/src/hotspot/share/classfile/verifier.hpp b/src/hotspot/share/classfile/verifier.hpp
--- a/src/hotspot/share/classfile/verifier.hpp
+++ b/src/hotspot/share/classfile/verifier.hpp
@@ -499,11 +499,11 @@
         Symbol* name_copy = create_temporary_symbol(name);
         assert(name_copy == name, "symbols don't match");
         *inference_type = VerificationType::reference_type(name_copy);
         return 1;
       }
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       {
         Symbol* vname = sig_type->as_symbol();
         // Create another symbol to save as signature stream unreferences this symbol.
         Symbol* vname_copy = create_temporary_symbol(vname);
         assert(vname_copy == vname, "symbols don't match");
diff a/src/hotspot/share/gc/g1/c2/g1BarrierSetC2.cpp b/src/hotspot/share/gc/g1/c2/g1BarrierSetC2.cpp
--- a/src/hotspot/share/gc/g1/c2/g1BarrierSetC2.cpp
+++ b/src/hotspot/share/gc/g1/c2/g1BarrierSetC2.cpp
@@ -205,11 +205,11 @@
     assert(pre_val != NULL, "must be loaded already");
     // Nothing to be done if pre_val is null.
     if (pre_val->bottom_type() == TypePtr::NULL_PTR) return;
     assert(pre_val->bottom_type()->basic_type() == T_OBJECT, "or we shouldn't be here");
   }
-  assert(bt == T_OBJECT || bt == T_VALUETYPE, "or we shouldn't be here");
+  assert(bt == T_OBJECT || bt == T_INLINE_TYPE, "or we shouldn't be here");
 
   IdealKit ideal(kit, true);
 
   Node* tls = __ thread(); // ThreadLocalStorage
 
diff a/src/hotspot/share/interpreter/interpreterRuntime.cpp b/src/hotspot/share/interpreter/interpreterRuntime.cpp
--- a/src/hotspot/share/interpreter/interpreterRuntime.cpp
+++ b/src/hotspot/share/interpreter/interpreterRuntime.cpp
@@ -288,11 +288,11 @@
   case T_LONG:
     instance()->long_field_put(offset, (jlong)*((long long*)addr));
     break;
   case T_OBJECT:
   case T_ARRAY:
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
     fatal("Should not be handled with this method");
     break;
   default:
     fatal("Unsupported BasicType");
   }
@@ -349,11 +349,11 @@
   // Updating the field specified in arguments
   if (field_type == T_ARRAY || field_type == T_OBJECT) {
     oop aoop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
     assert(aoop == NULL || oopDesc::is_oop(aoop),"argument must be a reference type");
     new_value_h()->obj_field_put(field_offset, aoop);
-  } else if (field_type == T_VALUETYPE) {
+  } else if (field_type == T_INLINE_TYPE) {
     if (cp_entry->is_inlined()) {
       oop vt_oop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
       assert(vt_oop != NULL && oopDesc::is_oop(vt_oop) && vt_oop->is_inline_type(),"argument must be an inline type");
       ValueKlass* field_vk = ValueKlass::cast(vklass->get_inline_type_field_klass(field_index));
       assert(vt_oop != NULL && field_vk == vt_oop->klass(), "Must match");
@@ -364,11 +364,11 @@
         THROW_(vmSymbols::java_lang_NullPointerException(), return_offset);
       }
       assert(voop == NULL || oopDesc::is_oop(voop),"checking argument");
       new_value_h()->obj_field_put(field_offset, voop);
     }
-  } else { // not T_OBJECT nor T_ARRAY nor T_VALUETYPE
+  } else { // not T_OBJECT nor T_ARRAY nor T_INLINE_TYPE
     intptr_t* addr = f.interpreter_frame_expression_stack_at(tos_idx);
     copy_primitive_argument(addr, new_value_h, field_offset, field_type);
   }
 
   // returning result
diff a/src/hotspot/share/interpreter/templateInterpreterGenerator.cpp b/src/hotspot/share/interpreter/templateInterpreterGenerator.cpp
--- a/src/hotspot/share/interpreter/templateInterpreterGenerator.cpp
+++ b/src/hotspot/share/interpreter/templateInterpreterGenerator.cpp
@@ -51,11 +51,11 @@
   T_LONG   ,
   T_VOID   ,
   T_FLOAT  ,
   T_DOUBLE ,
   T_OBJECT ,
-  T_VALUETYPE
+  T_INLINE_TYPE
 };
 
 void TemplateInterpreterGenerator::generate_all() {
   { CodeletMark cm(_masm, "slow signature handler");
     AbstractInterpreter::_slow_signature_handler = generate_slow_signature_handler();
diff a/src/hotspot/share/jvmci/jvmciCompilerToVM.hpp b/src/hotspot/share/jvmci/jvmciCompilerToVM.hpp
--- a/src/hotspot/share/jvmci/jvmciCompilerToVM.hpp
+++ b/src/hotspot/share/jvmci/jvmciCompilerToVM.hpp
@@ -151,11 +151,11 @@
 
  private:
   friend class SignatureIterator;  // so do_parameters_on can call do_type
   void do_type(BasicType type) {
     if (is_reference_type(type)) {
-      (type == T_VALUETYPE) ? _jca->push_oop(next_arg(T_VALUETYPE)) : _jca->push_oop(next_arg(T_OBJECT));
+      (type == T_INLINE_TYPE) ? _jca->push_oop(next_arg(T_INLINE_TYPE)) : _jca->push_oop(next_arg(T_OBJECT));
       return;
     }
     Handle arg = next_arg(type);
     int box_offset = java_lang_boxing_object::value_offset(type);
     switch (type) {
diff a/src/hotspot/share/memory/heapInspection.cpp b/src/hotspot/share/memory/heapInspection.cpp
--- a/src/hotspot/share/memory/heapInspection.cpp
+++ b/src/hotspot/share/memory/heapInspection.cpp
@@ -526,11 +526,11 @@
   const Symbol* signature() { return _signature; }
   const int offset() { return _offset; }
   const int index() { return _index; }
   const InstanceKlass* holder() { return _holder; }
   const AccessFlags& access_flags() { return _access_flags; }
-  const bool is_inline_type() { return Signature::basic_type(_signature) == T_VALUETYPE; }
+  const bool is_inline_type() { return Signature::basic_type(_signature) == T_INLINE_TYPE; }
 };
 
 static int compare_offset(FieldDesc* f1, FieldDesc* f2) {
    return f1->offset() > f2->offset() ? 1 : -1;
 }
diff a/src/hotspot/share/oops/arrayOop.hpp b/src/hotspot/share/oops/arrayOop.hpp
--- a/src/hotspot/share/oops/arrayOop.hpp
+++ b/src/hotspot/share/oops/arrayOop.hpp
@@ -63,11 +63,11 @@
 
   // Check whether an element of a typeArrayOop with the given type must be
   // aligned 0 mod 8.  The typeArrayOop itself must be aligned at least this
   // strongly.
   static bool element_type_should_be_aligned(BasicType type) {
-    return type == T_DOUBLE || type == T_LONG || type == T_VALUETYPE;
+    return type == T_DOUBLE || type == T_LONG || type == T_INLINE_TYPE;
   }
 
  public:
   // The _length field is not declared in C++.  It is allocated after the
   // declared nonstatic fields in arrayOopDesc if not compressed, otherwise
diff a/src/hotspot/share/oops/instanceKlass.cpp b/src/hotspot/share/oops/instanceKlass.cpp
--- a/src/hotspot/share/oops/instanceKlass.cpp
+++ b/src/hotspot/share/oops/instanceKlass.cpp
@@ -154,11 +154,11 @@
     }
   }
   return false;
 }
 
-bool InstanceKlass::field_is_inline_type(int index) const { return Signature::basic_type(field(index)->signature(constants())) == T_VALUETYPE; }
+bool InstanceKlass::field_is_inline_type(int index) const { return Signature::basic_type(field(index)->signature(constants())) == T_INLINE_TYPE; }
 
 // private: called to verify that k is a static member of this nest.
 // We know that k is an instance class in the same package and hence the
 // same classloader.
 bool InstanceKlass::has_nest_member(InstanceKlass* k, TRAPS) const {
@@ -1004,11 +1004,11 @@
       for (SignatureStream ss(m->signature()); !ss.is_done(); ss.next()) {
         if (ss.is_reference()) {
           if (ss.is_array()) {
             ss.skip_array_prefix();
           }
-          if (ss.type() == T_VALUETYPE) {
+          if (ss.type() == T_INLINE_TYPE) {
             Symbol* symb = ss.as_symbol();
 
             oop loader = class_loader();
             oop protection_domain = this->protection_domain();
             Klass* klass = SystemDictionary::resolve_or_fail(symb,
@@ -1257,11 +1257,11 @@
 
   // Step 8
   // Initialize classes of inline fields
   {
     for (AllFieldStream fs(this); !fs.done(); fs.next()) {
-      if (Signature::basic_type(fs.signature()) == T_VALUETYPE) {
+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {
         Klass* klass = get_inline_type_field_klass_or_null(fs.index());
         if (fs.access_flags().is_static() && klass == NULL) {
           klass = SystemDictionary::resolve_or_fail(field_signature(fs.index())->fundamental_name(THREAD),
               Handle(THREAD, class_loader()),
               Handle(THREAD, protection_domain()),
@@ -2663,11 +2663,11 @@
     array_klasses()->remove_unshareable_info();
   }
 
   if (has_inline_type_fields()) {
     for (AllFieldStream fs(fields(), constants()); !fs.done(); fs.next()) {
-      if (Signature::basic_type(fs.signature()) == T_VALUETYPE) {
+      if (Signature::basic_type(fs.signature()) == T_INLINE_TYPE) {
         reset_inline_type_field_klass(fs.index());
       }
     }
   }
 
diff a/src/hotspot/share/oops/klass.hpp b/src/hotspot/share/oops/klass.hpp
--- a/src/hotspot/share/oops/klass.hpp
+++ b/src/hotspot/share/oops/klass.hpp
@@ -415,11 +415,11 @@
     return hsize;
   }
   static BasicType layout_helper_element_type(jint lh) {
     assert(lh < (jint)_lh_neutral_value, "must be array");
     int btvalue = (lh >> _lh_element_type_shift) & _lh_element_type_mask;
-    assert((btvalue >= T_BOOLEAN && btvalue <= T_OBJECT) || btvalue == T_VALUETYPE, "sanity");
+    assert((btvalue >= T_BOOLEAN && btvalue <= T_OBJECT) || btvalue == T_INLINE_TYPE, "sanity");
     return (BasicType) btvalue;
   }
 
   // Want a pattern to quickly diff against layout header in register
   // find something less clever!
@@ -436,11 +436,11 @@
   }
 
   static int layout_helper_log2_element_size(jint lh) {
     assert(lh < (jint)_lh_neutral_value, "must be array");
     int l2esz = (lh >> _lh_log2_element_size_shift) & _lh_log2_element_size_mask;
-    assert(layout_helper_element_type(lh) == T_VALUETYPE || l2esz <= LogBytesPerLong,
+    assert(layout_helper_element_type(lh) == T_INLINE_TYPE || l2esz <= LogBytesPerLong,
            "sanity. l2esz: 0x%x for lh: 0x%x", (uint)l2esz, (uint)lh);
     return l2esz;
   }
   static jint array_layout_helper(jint tag, bool null_free, int hsize, BasicType etype, int log2_esize) {
     return (tag        << _lh_array_tag_shift)
diff a/src/hotspot/share/oops/valueArrayKlass.cpp b/src/hotspot/share/oops/valueArrayKlass.cpp
--- a/src/hotspot/share/oops/valueArrayKlass.cpp
+++ b/src/hotspot/share/oops/valueArrayKlass.cpp
@@ -158,11 +158,11 @@
   int length = *last_size;
   return allocate(length, THREAD);
 }
 
 jint ValueArrayKlass::array_layout_helper(ValueKlass* vk) {
-  BasicType etype = T_VALUETYPE;
+  BasicType etype = T_INLINE_TYPE;
   int esize = upper_log2(vk->raw_value_byte_size());
   int hsize = arrayOopDesc::base_offset_in_bytes(etype);
 
   int lh = Klass::array_layout_helper(_lh_array_tag_vt_value, true, hsize, etype, esize);
 
@@ -190,11 +190,11 @@
 // nof bytes = "max_jint * HeapWord" since the "oopDesc::oop_iterate_size"
 // returns "int" HeapWords, need fix for JDK-4718400 and JDK-8233189
 jint ValueArrayKlass::max_elements() const {
   // Check the max number of heap words limit first (because of int32_t in oopDesc_oop_size() etc)
   size_t max_size = max_jint;
-  max_size -= arrayOopDesc::header_size(T_VALUETYPE);
+  max_size -= arrayOopDesc::header_size(T_INLINE_TYPE);
   max_size = align_down(max_size, MinObjAlignment);
   max_size <<= LogHeapWordSize;                                  // convert to max payload size in bytes
   max_size >>= layout_helper_log2_element_size(_layout_helper);  // divide by element size (in bytes) = max elements
   // Within int32_t heap words, still can't exceed Java array element limit
   if (max_size > max_jint) {
diff a/src/hotspot/share/oops/valueArrayOop.inline.hpp b/src/hotspot/share/oops/valueArrayOop.inline.hpp
--- a/src/hotspot/share/oops/valueArrayOop.inline.hpp
+++ b/src/hotspot/share/oops/valueArrayOop.inline.hpp
@@ -30,11 +30,11 @@
 #include "oops/valueArrayOop.hpp"
 #include "oops/valueKlass.inline.hpp"
 #include "oops/oop.inline.hpp"
 #include "runtime/globals.hpp"
 
-inline void* valueArrayOopDesc::base() const { return arrayOopDesc::base(T_VALUETYPE); }
+inline void* valueArrayOopDesc::base() const { return arrayOopDesc::base(T_INLINE_TYPE); }
 
 inline void* valueArrayOopDesc::value_at_addr(int index, jint lh) const {
   assert(is_within_bounds(index), "index out of bounds");
 
   address addr = (address) base();
diff a/src/hotspot/share/oops/valueKlass.cpp b/src/hotspot/share/oops/valueKlass.cpp
--- a/src/hotspot/share/oops/valueKlass.cpp
+++ b/src/hotspot/share/oops/valueKlass.cpp
@@ -106,11 +106,11 @@
       continue;
     } else if (fs.offset() > last_offset) {
       BasicType type = Signature::basic_type(fs.signature());
       if (is_java_primitive(type)) {
         last_tsz = type2aelembytes(type);
-      } else if (type == T_VALUETYPE) {
+      } else if (type == T_INLINE_TYPE) {
         // Not just primitives. Layout aligns embedded value, so use jlong aligned it is
         return heapOopAlignedSize;
       } else {
         guarantee(0, "Unknown type %d", type);
       }
@@ -276,34 +276,34 @@
 // the offset of each field in the inline type: i2c and c2i adapters
 // need that to load or store fields. Finally, the list of fields is
 // sorted in order of increasing offsets: the adapters and the
 // compiled code need to agree upon the order of fields.
 //
-// The list of basic types that is returned starts with a T_VALUETYPE
-// and ends with an extra T_VOID. T_VALUETYPE/T_VOID pairs are used as
+// The list of basic types that is returned starts with a T_INLINE_TYPE
+// and ends with an extra T_VOID. T_INLINE_TYPE/T_VOID pairs are used as
 // delimiters. Every entry between the two is a field of the value
 // type. If there's an embedded inline type in the list, it also starts
-// with a T_VALUETYPE and ends with a T_VOID. This is so we can
+// with a T_INLINE_TYPE and ends with a T_VOID. This is so we can
 // generate a unique fingerprint for the method's adapters and we can
 // generate the list of basic types from the interpreter point of view
 // (value types passed as reference: iterate on the list until a
-// T_VALUETYPE, drop everything until and including the closing
+// T_INLINE_TYPE, drop everything until and including the closing
 // T_VOID) or the compiler point of view (each field of the value
-// types is an argument: drop all T_VALUETYPE/T_VOID from the list).
+// types is an argument: drop all T_INLINE_TYPE/T_VOID from the list).
 int ValueKlass::collect_fields(GrowableArray<SigEntry>* sig, int base_off) {
   int count = 0;
-  SigEntry::add_entry(sig, T_VALUETYPE, base_off);
+  SigEntry::add_entry(sig, T_INLINE_TYPE, base_off);
   for (AllFieldStream fs(this); !fs.done(); fs.next()) {
     if (fs.access_flags().is_static()) continue;
     int offset = base_off + fs.offset() - (base_off > 0 ? first_field_offset() : 0);
     if (fs.is_inlined()) {
       // Resolve klass of inlined field and recursively collect fields
       Klass* vk = get_inline_type_field_klass(fs.index());
       count += ValueKlass::cast(vk)->collect_fields(sig, offset);
     } else {
       BasicType bt = Signature::basic_type(fs.signature());
-      if (bt == T_VALUETYPE) {
+      if (bt == T_INLINE_TYPE) {
         bt = T_OBJECT;
       }
       SigEntry::add_entry(sig, bt, offset);
       count += type2size[bt];
     }
@@ -311,11 +311,11 @@
   int offset = base_off + size_helper()*HeapWordSize - (base_off > 0 ? first_field_offset() : 0);
   SigEntry::add_entry(sig, T_VOID, offset);
   if (base_off == 0) {
     sig->sort(SigEntry::compare);
   }
-  assert(sig->at(0)._bt == T_VALUETYPE && sig->at(sig->length()-1)._bt == T_VOID, "broken structure");
+  assert(sig->at(0)._bt == T_INLINE_TYPE && sig->at(sig->length()-1)._bt == T_VOID, "broken structure");
   return count;
 }
 
 void ValueKlass::initialize_calling_convention(TRAPS) {
   // Because the pack and unpack handler addresses need to be loadable from generated code,
@@ -416,11 +416,11 @@
       oop v = *(oop*)loc;
       assert(v == NULL || oopDesc::is_oop(v), "not an oop?");
       assert(Universe::heap()->is_in_or_null(v), "must be heap pointer");
       handles.push(Handle(thread, v));
     }
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       continue;
     }
     if (bt == T_VOID &&
         sig_vk->at(i-1)._bt != T_LONG &&
         sig_vk->at(i-1)._bt != T_DOUBLE) {
@@ -444,11 +444,11 @@
     if (bt == T_OBJECT || bt == T_ARRAY) {
       VMRegPair pair = regs->at(j);
       address loc = reg_map.location(pair.first());
       *(oop*)loc = handles.at(k++)();
     }
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       continue;
     }
     if (bt == T_VOID &&
         sig_vk->at(i-1)._bt != T_LONG &&
         sig_vk->at(i-1)._bt != T_DOUBLE) {
@@ -468,11 +468,11 @@
 
   int j = 1;
   int k = 0;
   for (int i = 0; i < sig_vk->length(); i++) {
     BasicType bt = sig_vk->at(i)._bt;
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       continue;
     }
     if (bt == T_VOID) {
       if (sig_vk->at(i-1)._bt == T_LONG ||
           sig_vk->at(i-1)._bt == T_DOUBLE) {
diff a/src/hotspot/share/opto/arraycopynode.cpp b/src/hotspot/share/opto/arraycopynode.cpp
--- a/src/hotspot/share/opto/arraycopynode.cpp
+++ b/src/hotspot/share/opto/arraycopynode.cpp
@@ -268,35 +268,35 @@
     }
 
     BasicType src_elem  = ary_src->klass()->as_array_klass()->element_type()->basic_type();
     BasicType dest_elem = ary_dest->klass()->as_array_klass()->element_type()->basic_type();
     if (src_elem  == T_ARRAY ||
-        (src_elem == T_VALUETYPE && ary_src->klass()->is_obj_array_klass())) {
+        (src_elem == T_INLINE_TYPE && ary_src->klass()->is_obj_array_klass())) {
       src_elem  = T_OBJECT;
     }
     if (dest_elem == T_ARRAY ||
-        (dest_elem == T_VALUETYPE && ary_dest->klass()->is_obj_array_klass())) {
+        (dest_elem == T_INLINE_TYPE && ary_dest->klass()->is_obj_array_klass())) {
       dest_elem = T_OBJECT;
     }
 
     if (src_elem != dest_elem || dest_elem == T_VOID) {
       // We don't know if arguments are arrays of the same type
       return false;
     }
 
     BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();
     if (bs->array_copy_requires_gc_barriers(is_alloc_tightly_coupled(), dest_elem, false, BarrierSetC2::Optimization) ||
-        (src_elem == T_VALUETYPE && ary_src->elem()->value_klass()->contains_oops() &&
+        (src_elem == T_INLINE_TYPE && ary_src->elem()->value_klass()->contains_oops() &&
          bs->array_copy_requires_gc_barriers(is_alloc_tightly_coupled(), T_OBJECT, false, BarrierSetC2::Optimization))) {
       // It's an object array copy but we can't emit the card marking that is needed
       return false;
     }
 
     value_type = ary_src->elem();
 
     uint shift  = exact_log2(type2aelembytes(dest_elem));
-    if (dest_elem == T_VALUETYPE) {
+    if (dest_elem == T_INLINE_TYPE) {
       ciValueArrayKlass* vak = ary_src->klass()->as_value_array_klass();
       shift = vak->log2_element_size();
     }
     uint header = arrayOopDesc::base_offset_in_bytes(dest_elem);
 
@@ -331,17 +331,17 @@
     adr_src  = phase->transform(new AddPNode(base_src, base_src, src_offset));
     adr_dest = phase->transform(new AddPNode(base_dest, base_dest, dest_offset));
 
     BasicType elem = ary_src->klass()->as_array_klass()->element_type()->basic_type();
     if (elem == T_ARRAY ||
-        (elem == T_VALUETYPE && ary_src->klass()->is_obj_array_klass())) {
+        (elem == T_INLINE_TYPE && ary_src->klass()->is_obj_array_klass())) {
       elem = T_OBJECT;
     }
 
     BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();
     if (bs->array_copy_requires_gc_barriers(true, elem, true, BarrierSetC2::Optimization) ||
-        (elem == T_VALUETYPE && ary_src->elem()->value_klass()->contains_oops() &&
+        (elem == T_INLINE_TYPE && ary_src->elem()->value_klass()->contains_oops() &&
          bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Optimization))) {
       return false;
     }
 
     // The address is offseted to an aligned address where a raw copy would start.
@@ -397,21 +397,21 @@
                          Node* adr_dest,
                          BasicType copy_type,
                          const Type* value_type) {
   BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();
   Node* ctl = kit.control();
-  if (copy_type == T_VALUETYPE) {
+  if (copy_type == T_INLINE_TYPE) {
     ciValueArrayKlass* vak = atp_src->klass()->as_value_array_klass();
     ciValueKlass* vk = vak->element_klass()->as_value_klass();
     for (int j = 0; j < vk->nof_nonstatic_fields(); j++) {
       ciField* field = vk->nonstatic_field_at(j);
       int off_in_vt = field->offset() - vk->first_field_offset();
       Node* off  = kit.MakeConX(off_in_vt + i * vak->element_byte_size());
       ciType* ft = field->type();
       BasicType bt = type2field[ft->basic_type()];
       assert(!field->is_flattened(), "flattened field encountered");
-      if (bt == T_VALUETYPE) {
+      if (bt == T_INLINE_TYPE) {
         bt = T_OBJECT;
       }
       const Type* rt = Type::get_const_type(ft);
       const TypePtr* adr_type = atp_src->with_field_offset(off_in_vt)->add_offset(Type::OffsetBot);
       assert(!bs->array_copy_requires_gc_barriers(is_alloc_tightly_coupled(), bt, false, BarrierSetC2::Optimization), "GC barriers required");
@@ -536,11 +536,11 @@
       const Type* src_type = phase->type(src);
       const TypeAryPtr* ary_src = src_type->isa_aryptr();
       BasicType elem = ary_src != NULL ? ary_src->klass()->as_array_klass()->element_type()->basic_type() : T_CONFLICT;
       BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();
       assert(!is_clonebasic() || bs->array_copy_requires_gc_barriers(true, T_OBJECT, true, BarrierSetC2::Optimization) ||
-             (ary_src != NULL && elem == T_VALUETYPE && ary_src->klass()->is_obj_array_klass()), "added control for clone?");
+             (ary_src != NULL && elem == T_INLINE_TYPE && ary_src->klass()->is_obj_array_klass()), "added control for clone?");
 #endif
       assert(!is_clonebasic() || UseShenandoahGC, "added control for clone?");
       phase->record_for_igvn(this);
       return false;
     }
diff a/src/hotspot/share/opto/doCall.cpp b/src/hotspot/share/opto/doCall.cpp
--- a/src/hotspot/share/opto/doCall.cpp
+++ b/src/hotspot/share/opto/doCall.cpp
@@ -713,11 +713,11 @@
           assert(is_reference_type(ct), "rt=%s, ct=%s", type2name(rt), type2name(ct));
           if (ctype->is_loaded()) {
             const TypeOopPtr* arg_type = TypeOopPtr::make_from_klass(rtype->as_klass());
             const Type*       sig_type = TypeOopPtr::make_from_klass(ctype->as_klass());
             if (declared_signature->returns_never_null()) {
-              assert(ct == T_VALUETYPE, "should be a value type");
+              assert(ct == T_INLINE_TYPE, "should be a value type");
               sig_type = sig_type->join_speculative(TypePtr::NOTNULL);
             }
             if (arg_type != NULL && !arg_type->higher_equal(sig_type) && !peek()->is_ValueType()) {
               Node* retnode = pop();
               Node* cast_obj = _gvn.transform(new CheckCastPPNode(control(), retnode, sig_type));
@@ -742,16 +742,16 @@
       // the accessing class).
       assert(!rtype->is_loaded() || !ctype->is_loaded() || rtype == ctype,
              "mismatched return types: rtype=%s, ctype=%s", rtype->name(), ctype->name());
     }
 
-    if (rtype->basic_type() == T_VALUETYPE && !peek()->is_ValueType()) {
+    if (rtype->basic_type() == T_INLINE_TYPE && !peek()->is_ValueType()) {
       Node* retnode = pop();
       if (!gvn().type(retnode)->maybe_null() && rtype->as_value_klass()->is_scalarizable()) {
         retnode = ValueTypeNode::make_from_oop(this, retnode, rtype->as_value_klass());
       }
-      push_node(T_VALUETYPE, retnode);
+      push_node(T_INLINE_TYPE, retnode);
     }
 
     // If the return type of the method is not loaded, assert that the
     // value we got is a null.  Otherwise, we need to recompile.
     if (!rtype->is_loaded()) {
diff a/src/hotspot/share/opto/graphKit.cpp b/src/hotspot/share/opto/graphKit.cpp
--- a/src/hotspot/share/opto/graphKit.cpp
+++ b/src/hotspot/share/opto/graphKit.cpp
@@ -1223,11 +1223,11 @@
   // Construct NULL check
   Node *chk = NULL;
   switch(type) {
     case T_LONG   : chk = new CmpLNode(value, _gvn.zerocon(T_LONG)); break;
     case T_INT    : chk = new CmpINode(value, _gvn.intcon(0)); break;
-    case T_VALUETYPE : // fall through
+    case T_INLINE_TYPE : // fall through
     case T_ARRAY  : // fall through
       type = T_OBJECT;  // simplify further tests
     case T_OBJECT : {
       const Type *t = _gvn.type( value );
 
@@ -1550,11 +1550,11 @@
   } else {
     ld = LoadNode::make(_gvn, ctl, mem, adr, adr_type, t, bt, mo, control_dependency, unaligned, mismatched, unsafe, barrier_data);
   }
   ld = _gvn.transform(ld);
 
-  if (((bt == T_OBJECT || bt == T_VALUETYPE) && C->do_escape_analysis()) || C->eliminate_boxing()) {
+  if (((bt == T_OBJECT || bt == T_INLINE_TYPE) && C->do_escape_analysis()) || C->eliminate_boxing()) {
     // Improve graph before escape analysis and boxing elimination.
     record_for_igvn(ld);
   }
   return ld;
 }
@@ -1776,11 +1776,11 @@
 
 //-------------------------load_array_element-------------------------
 Node* GraphKit::load_array_element(Node* ctl, Node* ary, Node* idx, const TypeAryPtr* arytype) {
   const Type* elemtype = arytype->elem();
   BasicType elembt = elemtype->array_element_basic_type();
-  assert(elembt != T_VALUETYPE, "value types are not supported by this method");
+  assert(elembt != T_INLINE_TYPE, "value types are not supported by this method");
   Node* adr = array_element_address(ary, idx, elembt, arytype->size());
   if (elembt == T_NARROWOOP) {
     elembt = T_OBJECT; // To satisfy switch in LoadNode::make()
   }
   Node* ld = make_load(ctl, adr, elemtype, elembt, arytype, MemNode::unordered);
diff a/src/hotspot/share/opto/library_call.cpp b/src/hotspot/share/opto/library_call.cpp
--- a/src/hotspot/share/opto/library_call.cpp
+++ b/src/hotspot/share/opto/library_call.cpp
@@ -639,22 +639,22 @@
   case vmIntrinsics::_getChar:                  return inline_unsafe_access(!is_store, T_CHAR,     Relaxed, false);
   case vmIntrinsics::_getInt:                   return inline_unsafe_access(!is_store, T_INT,      Relaxed, false);
   case vmIntrinsics::_getLong:                  return inline_unsafe_access(!is_store, T_LONG,     Relaxed, false);
   case vmIntrinsics::_getFloat:                 return inline_unsafe_access(!is_store, T_FLOAT,    Relaxed, false);
   case vmIntrinsics::_getDouble:                return inline_unsafe_access(!is_store, T_DOUBLE,   Relaxed, false);
-  case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_VALUETYPE,Relaxed, false);
+  case vmIntrinsics::_getValue:                 return inline_unsafe_access(!is_store, T_INLINE_TYPE,Relaxed, false);
 
   case vmIntrinsics::_putReference:             return inline_unsafe_access( is_store, T_OBJECT,   Relaxed, false);
   case vmIntrinsics::_putBoolean:               return inline_unsafe_access( is_store, T_BOOLEAN,  Relaxed, false);
   case vmIntrinsics::_putByte:                  return inline_unsafe_access( is_store, T_BYTE,     Relaxed, false);
   case vmIntrinsics::_putShort:                 return inline_unsafe_access( is_store, T_SHORT,    Relaxed, false);
   case vmIntrinsics::_putChar:                  return inline_unsafe_access( is_store, T_CHAR,     Relaxed, false);
   case vmIntrinsics::_putInt:                   return inline_unsafe_access( is_store, T_INT,      Relaxed, false);
   case vmIntrinsics::_putLong:                  return inline_unsafe_access( is_store, T_LONG,     Relaxed, false);
   case vmIntrinsics::_putFloat:                 return inline_unsafe_access( is_store, T_FLOAT,    Relaxed, false);
   case vmIntrinsics::_putDouble:                return inline_unsafe_access( is_store, T_DOUBLE,   Relaxed, false);
-  case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_VALUETYPE,Relaxed, false);
+  case vmIntrinsics::_putValue:                 return inline_unsafe_access( is_store, T_INLINE_TYPE,Relaxed, false);
 
   case vmIntrinsics::_getReferenceVolatile:     return inline_unsafe_access(!is_store, T_OBJECT,   Volatile, false);
   case vmIntrinsics::_getBooleanVolatile:       return inline_unsafe_access(!is_store, T_BOOLEAN,  Volatile, false);
   case vmIntrinsics::_getByteVolatile:          return inline_unsafe_access(!is_store, T_BYTE,     Volatile, false);
   case vmIntrinsics::_getShortVolatile:         return inline_unsafe_access(!is_store, T_SHORT,    Volatile, false);
@@ -2426,22 +2426,22 @@
     ciSignature* sig = callee()->signature();
 #ifdef ASSERT
     if (!is_store) {
       // Object getReference(Object base, int/long offset), etc.
       BasicType rtype = sig->return_type()->basic_type();
-      assert(rtype == type || (rtype == T_OBJECT && type == T_VALUETYPE), "getter must return the expected value");
-      assert(sig->count() == 2 || (type == T_VALUETYPE && sig->count() == 3), "oop getter has 2 or 3 arguments");
+      assert(rtype == type || (rtype == T_OBJECT && type == T_INLINE_TYPE), "getter must return the expected value");
+      assert(sig->count() == 2 || (type == T_INLINE_TYPE && sig->count() == 3), "oop getter has 2 or 3 arguments");
       assert(sig->type_at(0)->basic_type() == T_OBJECT, "getter base is object");
       assert(sig->type_at(1)->basic_type() == T_LONG, "getter offset is correct");
     } else {
       // void putReference(Object base, int/long offset, Object x), etc.
       assert(sig->return_type()->basic_type() == T_VOID, "putter must not return a value");
-      assert(sig->count() == 3 || (type == T_VALUETYPE && sig->count() == 4), "oop putter has 3 arguments");
+      assert(sig->count() == 3 || (type == T_INLINE_TYPE && sig->count() == 4), "oop putter has 3 arguments");
       assert(sig->type_at(0)->basic_type() == T_OBJECT, "putter base is object");
       assert(sig->type_at(1)->basic_type() == T_LONG, "putter offset is correct");
       BasicType vtype = sig->type_at(sig->count()-1)->basic_type();
-      assert(vtype == type || (type == T_VALUETYPE && vtype == T_OBJECT), "putter must accept the expected value");
+      assert(vtype == type || (type == T_INLINE_TYPE && vtype == T_OBJECT), "putter must accept the expected value");
     }
 #endif // ASSERT
  }
 #endif //PRODUCT
 
@@ -2464,11 +2464,11 @@
   // by oopDesc::field_addr.
   assert(Unsafe_field_offset_to_byte_offset(11) == 11,
          "fieldOffset must be byte-scaled");
 
   ciValueKlass* value_klass = NULL;
-  if (type == T_VALUETYPE) {
+  if (type == T_INLINE_TYPE) {
     Node* cls = null_check(argument(4));
     if (stopped()) {
       return true;
     }
     Node* kls = load_klass_from_mirror(cls, false, NULL, 0);
@@ -2510,11 +2510,11 @@
           BasicType bt = f->layout_type();
           if (bt == T_ARRAY || bt == T_NARROWOOP) {
             bt = T_OBJECT;
           }
           if (bt == type) {
-            if (bt != T_VALUETYPE || f->type() == value_klass) {
+            if (bt != T_INLINE_TYPE || f->type() == value_klass) {
               set_result(vt->field_value_by_offset((int)off, false));
               return true;
             }
           }
         }
@@ -2545,11 +2545,11 @@
 
   if (!can_access_non_heap) {
     decorators |= IN_HEAP;
   }
 
-  val = is_store ? argument(4 + (type == T_VALUETYPE ? 1 : 0)) : NULL;
+  val = is_store ? argument(4 + (type == T_INLINE_TYPE ? 1 : 0)) : NULL;
 
   const TypePtr* adr_type = _gvn.type(adr)->isa_ptr();
   if (adr_type == TypePtr::NULL_PTR) {
     return false; // off-heap access with zero address
   }
@@ -2579,12 +2579,12 @@
       field = k->get_non_flattened_field_by_offset(off);
     }
     if (field != NULL) {
       bt = field->layout_type();
     }
-    assert(bt == alias_type->basic_type() || bt == T_VALUETYPE, "should match");
-    if (field != NULL && bt == T_VALUETYPE && !field->is_flattened()) {
+    assert(bt == alias_type->basic_type() || bt == T_INLINE_TYPE, "should match");
+    if (field != NULL && bt == T_INLINE_TYPE && !field->is_flattened()) {
       bt = T_OBJECT;
     }
   } else {
     bt = alias_type->basic_type();
   }
@@ -2607,11 +2607,11 @@
     mismatched = (bt != type);
   } else if (alias_type->adr_type()->isa_oopptr()) {
     mismatched = true; // conservatively mark all "wide" on-heap accesses as mismatched
   }
 
-  if (type == T_VALUETYPE) {
+  if (type == T_INLINE_TYPE) {
     if (adr_type->isa_instptr()) {
       if (field == NULL || field->type() != value_klass) {
         mismatched = true;
       }
     } else if (adr_type->isa_aryptr()) {
@@ -2646,11 +2646,11 @@
     if (type == T_OBJECT) {
       const TypeOopPtr* tjp = sharpen_unsafe_type(alias_type, adr_type);
       if (tjp != NULL) {
         value_type = tjp;
       }
-    } else if (type == T_VALUETYPE) {
+    } else if (type == T_INLINE_TYPE) {
       value_type = NULL;
     }
   }
 
   // Heap pointers get a null-check from the interpreter,
@@ -2666,11 +2666,11 @@
       // final or stable field
       p = make_constant_from_field(field, heap_base_oop);
     }
 
     if (p == NULL) { // Could not constant fold the load
-      if (type == T_VALUETYPE) {
+      if (type == T_INLINE_TYPE) {
         if (adr_type->isa_instptr() && !mismatched) {
           ciInstanceKlass* holder = adr_type->is_instptr()->klass()->as_instance_klass();
           int offset = adr_type->is_instptr()->offset();
           p = ValueTypeNode::make_from_flattened(this, value_klass, base, base, holder, offset, decorators);
         } else {
@@ -2722,11 +2722,11 @@
     if (bt == T_ADDRESS) {
       // Repackage the long as a pointer.
       val = ConvL2X(val);
       val = gvn().transform(new CastX2PNode(val));
     }
-    if (type == T_VALUETYPE) {
+    if (type == T_INLINE_TYPE) {
       if (adr_type->isa_instptr() && !mismatched) {
         ciInstanceKlass* holder = adr_type->is_instptr()->klass()->as_instance_klass();
         int offset = adr_type->is_instptr()->offset();
         val->as_ValueType()->store_flattened(this, base, base, holder, offset, decorators);
       } else {
diff a/src/hotspot/share/opto/macro.cpp b/src/hotspot/share/opto/macro.cpp
--- a/src/hotspot/share/opto/macro.cpp
+++ b/src/hotspot/share/opto/macro.cpp
@@ -800,11 +800,11 @@
       nfields = alloc->in(AllocateNode::ALength)->find_int_con(-1);
       assert(klass->is_array_klass() && nfields >= 0, "must be an array klass.");
       elem_type = klass->as_array_klass()->element_type();
       basic_elem_type = elem_type->basic_type();
       if (elem_type->is_valuetype() && !klass->is_value_array_klass()) {
-        assert(basic_elem_type == T_VALUETYPE, "unexpected element basic type");
+        assert(basic_elem_type == T_INLINE_TYPE, "unexpected element basic type");
         basic_elem_type = T_OBJECT;
       }
       array_base = arrayOopDesc::base_offset_in_bytes(basic_elem_type);
       element_size = type2aelembytes(basic_elem_type);
       if (klass->is_value_array_klass()) {
@@ -1046,11 +1046,11 @@
         }
         _igvn._worklist.push(ac);
       } else if (use->is_ValueType()) {
         assert(use->isa_ValueType()->get_oop() == res, "unexpected value type use");
          _igvn.rehash_node_delayed(use);
-        use->isa_ValueType()->set_oop(_igvn.zerocon(T_VALUETYPE));
+        use->isa_ValueType()->set_oop(_igvn.zerocon(T_INLINE_TYPE));
       } else if (use->is_Store()) {
         _igvn.replace_node(use, use->in(MemNode::Memory));
       } else {
         eliminate_gc_barrier(use);
       }
diff a/src/hotspot/share/opto/macroArrayCopy.cpp b/src/hotspot/share/opto/macroArrayCopy.cpp
--- a/src/hotspot/share/opto/macroArrayCopy.cpp
+++ b/src/hotspot/share/opto/macroArrayCopy.cpp
@@ -835,11 +835,11 @@
 
   // operate on this memory slice:
   Node* mem = merge_mem->memory_at(alias_idx); // memory slice to operate on
 
   // scaling and rounding of indexes:
-  assert(basic_elem_type != T_VALUETYPE, "should have been converted to a basic type copy");
+  assert(basic_elem_type != T_INLINE_TYPE, "should have been converted to a basic type copy");
   int scale = exact_log2(type2aelembytes(basic_elem_type));
   int abase = arrayOopDesc::base_offset_in_bytes(basic_elem_type);
   int clear_low = (-1 << scale) & (BytesPerInt  - 1);
   int bump_bit  = (-1 << scale) & BytesPerInt;
 
@@ -1204,11 +1204,11 @@
     const TypeAryPtr* top_dest = dest_type->isa_aryptr();
     BasicType dest_elem = T_OBJECT;
     if (top_dest != NULL && top_dest->klass() != NULL) {
       dest_elem = top_dest->klass()->as_array_klass()->element_type()->basic_type();
     }
-    if (dest_elem == T_ARRAY || (dest_elem == T_VALUETYPE && top_dest->klass()->is_obj_array_klass())) {
+    if (dest_elem == T_ARRAY || (dest_elem == T_INLINE_TYPE && top_dest->klass()->is_obj_array_klass())) {
       dest_elem = T_OBJECT;
     }
 
     Node* mem = ac->in(TypeFunc::Memory);
     merge_mem = MergeMemNode::make(mem);
@@ -1217,15 +1217,15 @@
     AllocateArrayNode* alloc = NULL;
     if (ac->is_alloc_tightly_coupled()) {
       alloc = AllocateArrayNode::Ideal_array_allocation(dest, &_igvn);
       assert(alloc != NULL, "expect alloc");
     }
-    assert(dest_elem != T_VALUETYPE || alloc != NULL, "unsupported");
+    assert(dest_elem != T_INLINE_TYPE || alloc != NULL, "unsupported");
     Node* dest_length = (alloc != NULL) ? alloc->in(AllocateNode::ALength) : NULL;
 
     const TypePtr* adr_type = NULL;
-    if (dest_elem == T_VALUETYPE) {
+    if (dest_elem == T_INLINE_TYPE) {
       adr_type = adjust_parameters_for_vt(top_dest, src_offset, dest_offset, length, dest_elem, dest_length);
     } else {
       adr_type = dest_type->is_oopptr()->add_offset(Type::OffsetBot);
       if (ac->_dest_type != TypeOopPtr::BOTTOM) {
         adr_type = ac->_dest_type->add_offset(Type::OffsetBot)->is_ptr();
@@ -1270,21 +1270,21 @@
   if (top_src != NULL && top_src->klass() != NULL) {
     src_elem = top_src->klass()->as_array_klass()->element_type()->basic_type();
   }
   if (src_elem == T_ARRAY) {
     src_elem = T_OBJECT;
-  } else if (src_elem == T_VALUETYPE && top_src->klass()->is_obj_array_klass()) {
+  } else if (src_elem == T_INLINE_TYPE && top_src->klass()->is_obj_array_klass()) {
     if (top_src->klass_is_exact()) {
       src_elem = T_OBJECT;
     } else {
       assert(!top_src->klass()->is_valuetype(), "klass should be exact");
       src_elem = T_CONFLICT; // either flattened or not
     }
   }
   if (dest_elem == T_ARRAY) {
     dest_elem = T_OBJECT;
-  } else if (dest_elem == T_VALUETYPE && top_dest->klass()->is_obj_array_klass()) {
+  } else if (dest_elem == T_INLINE_TYPE && top_dest->klass()->is_obj_array_klass()) {
     if (top_dest->klass_is_exact()) {
       dest_elem = T_OBJECT;
     } else {
       assert(!top_dest->klass()->is_valuetype(), "klass should be exact");
       dest_elem = T_CONFLICT; // either flattened or not
@@ -1363,11 +1363,11 @@
   // (7) src_offset + length must not exceed length of src.
   // (8) dest_offset + length must not exceed length of dest.
   // (9) each element of an oop array must be assignable
 
   Node* mem = ac->in(TypeFunc::Memory);
-  if (dest_elem == T_VALUETYPE) {
+  if (dest_elem == T_INLINE_TYPE) {
     // copy modifies more than 1 slice
     insert_mem_bar(&ctrl, &mem, Op_MemBarCPUOrder);
   }
 
   merge_mem = MergeMemNode::make(mem);
@@ -1425,11 +1425,11 @@
   // This is where the memory effects are placed:
   const TypePtr* adr_type = NULL;
 
   Node* dest_length = alloc != NULL ? alloc->in(AllocateNode::ALength) : NULL;
 
-  if (dest_elem == T_VALUETYPE) {
+  if (dest_elem == T_INLINE_TYPE) {
     adr_type = adjust_parameters_for_vt(top_dest, src_offset, dest_offset, length, dest_elem, dest_length);
   } else if (ac->_dest_type != TypeOopPtr::BOTTOM) {
     adr_type = ac->_dest_type->add_offset(Type::OffsetBot)->is_ptr();
   } else {
     adr_type = TypeAryPtr::get_array_body_type(dest_elem);
diff a/src/hotspot/share/opto/memnode.cpp b/src/hotspot/share/opto/memnode.cpp
--- a/src/hotspot/share/opto/memnode.cpp
+++ b/src/hotspot/share/opto/memnode.cpp
@@ -831,11 +831,11 @@
   case T_SHORT:   load = new LoadSNode (ctl, mem, adr, adr_type, rt->is_int(),  mo, control_dependency); break;
   case T_LONG:    load = new LoadLNode (ctl, mem, adr, adr_type, rt->is_long(), mo, control_dependency); break;
   case T_FLOAT:   load = new LoadFNode (ctl, mem, adr, adr_type, rt,            mo, control_dependency); break;
   case T_DOUBLE:  load = new LoadDNode (ctl, mem, adr, adr_type, rt,            mo, control_dependency); break;
   case T_ADDRESS: load = new LoadPNode (ctl, mem, adr, adr_type, rt->is_ptr(),  mo, control_dependency); break;
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_OBJECT:
 #ifdef _LP64
     if (adr->bottom_type()->is_ptr_to_narrowoop()) {
       load = new LoadNNode(ctl, mem, adr, adr_type, rt->make_narrowoop(), mo, control_dependency);
     } else
@@ -1093,11 +1093,11 @@
         (ld_off >= st->in(0)->as_Allocate()->minimum_header_size())) {
       // return a zero value for the load's basic type
       // (This is one of the few places where a generic PhaseTransform
       // can create new nodes.  Think of it as lazily manifesting
       // virtually pre-existing constants.)
-      assert(memory_type() != T_VALUETYPE, "should not be used for value types");
+      assert(memory_type() != T_INLINE_TYPE, "should not be used for value types");
       Node* default_value = ld_alloc->in(AllocateNode::DefaultValue);
       if (default_value != NULL) {
         return default_value;
       }
       assert(ld_alloc->in(AllocateNode::RawDefaultValue) == NULL, "default value may not be null");
@@ -2538,11 +2538,11 @@
   case T_LONG:    return new StoreLNode(ctl, mem, adr, adr_type, val, mo);
   case T_FLOAT:   return new StoreFNode(ctl, mem, adr, adr_type, val, mo);
   case T_DOUBLE:  return new StoreDNode(ctl, mem, adr, adr_type, val, mo);
   case T_METADATA:
   case T_ADDRESS:
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_OBJECT:
 #ifdef _LP64
     if (adr->bottom_type()->is_ptr_to_narrowoop()) {
       val = gvn.transform(new EncodePNode(val, val->bottom_type()->make_narrowoop()));
       return new StoreNNode(ctl, mem, adr, adr_type, val, mo);
diff a/src/hotspot/share/opto/parse1.cpp b/src/hotspot/share/opto/parse1.cpp
--- a/src/hotspot/share/opto/parse1.cpp
+++ b/src/hotspot/share/opto/parse1.cpp
@@ -122,11 +122,11 @@
   Node *l = NULL;
   switch (bt) {                // Signature is flattened
   case T_INT:     l = new LoadINode(ctl, mem, adr, TypeRawPtr::BOTTOM, TypeInt::INT,        MemNode::unordered); break;
   case T_FLOAT:   l = new LoadFNode(ctl, mem, adr, TypeRawPtr::BOTTOM, Type::FLOAT,         MemNode::unordered); break;
   case T_ADDRESS: l = new LoadPNode(ctl, mem, adr, TypeRawPtr::BOTTOM, TypeRawPtr::BOTTOM,  MemNode::unordered); break;
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_OBJECT:  l = new LoadPNode(ctl, mem, adr, TypeRawPtr::BOTTOM, TypeInstPtr::BOTTOM, MemNode::unordered); break;
   case T_LONG:
   case T_DOUBLE: {
     // Since arguments are in reverse order, the argument address 'adr'
     // refers to the back half of the long/double.  Recompute adr.
diff a/src/hotspot/share/opto/parse2.cpp b/src/hotspot/share/opto/parse2.cpp
--- a/src/hotspot/share/opto/parse2.cpp
+++ b/src/hotspot/share/opto/parse2.cpp
@@ -87,11 +87,11 @@
     Node* vt = ValueTypeNode::make_from_flattened(this, elemtype->value_klass(), ary, adr);
     push(vt);
     return;
   } else if (elemptr != NULL && elemptr->is_valuetypeptr() && !elemptr->maybe_null()) {
     // Load from non-flattened but flattenable value type array (elements can never be null)
-    bt = T_VALUETYPE;
+    bt = T_INLINE_TYPE;
   } else if (!ary_t->is_not_flat()) {
     // Cannot statically determine if array is flattened, emit runtime check
     assert(ValueArrayFlatten && is_reference_type(bt) && elemptr->can_be_value_type() && !ary_t->klass_is_exact() && !ary_t->is_not_null_free() &&
            (!elemptr->is_valuetypeptr() || elemptr->value_klass()->flatten_array()), "array can't be flattened");
     IdealKit ideal(this);
@@ -114,11 +114,11 @@
         ciValueKlass* vk = elemptr->value_klass();
         assert(vk->flatten_array() && elemptr->maybe_null(), "must be a flattenable and nullable array");
         ciArrayKlass* array_klass = ciArrayKlass::make(vk);
         const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)->isa_aryptr();
         Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, arytype));
-        Node* casted_adr = array_element_address(cast, idx, T_VALUETYPE, ary_t->size(), control());
+        Node* casted_adr = array_element_address(cast, idx, T_INLINE_TYPE, ary_t->size(), control());
         // Re-execute flattened array load if buffering triggers deoptimization
         PreserveReexecuteState preexecs(this);
         jvms()->set_should_reexecute(true);
         inc_sp(2);
         Node* vt = ValueTypeNode::make_from_flattened(this, vk, cast, casted_adr)->buffer(this, false);
@@ -158,11 +158,11 @@
           countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));
 
           assert(Klass::_lh_log2_element_size_shift == 0, "use shift in place");
           Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));
           Node* elem_shift = make_load(NULL, lhp, TypeInt::INT, T_INT, MemNode::unordered);
-          uint header = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE);
+          uint header = arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE);
           Node* base  = basic_plus_adr(ary, header);
           idx = Compile::conv_I2X_index(&_gvn, idx, TypeInt::POS, control());
           Node* scale = _gvn.transform(new LShiftXNode(idx, elem_shift));
           Node* adr = basic_plus_adr(ary, base, scale);
 
@@ -208,11 +208,11 @@
     bt = T_BOOLEAN;
   }
   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
   Node* ld = access_load_at(ary, adr, adr_type, elemtype, bt,
                             IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
-  if (bt == T_VALUETYPE) {
+  if (bt == T_INLINE_TYPE) {
     // Loading a non-flattened (but flattenable) value type from an array
     assert(!gvn().type(ld)->maybe_null(), "value type array elements should never be null");
     if (elemptr->value_klass()->is_scalarizable()) {
       ld = ValueTypeNode::make_from_oop(this, ld, elemptr->value_klass());
     }
diff a/src/hotspot/share/opto/parse3.cpp b/src/hotspot/share/opto/parse3.cpp
--- a/src/hotspot/share/opto/parse3.cpp
+++ b/src/hotspot/share/opto/parse3.cpp
@@ -172,11 +172,11 @@
         type = TypeOopPtr::make_from_constant(con)->isa_oopptr();
       }
       assert(type != NULL, "field singleton type must be consistent");
     } else {
       type = TypeOopPtr::make_from_klass(field_klass->as_klass());
-      if (bt == T_VALUETYPE && field->is_static() && flattenable) {
+      if (bt == T_INLINE_TYPE && field->is_static() && flattenable) {
         // Check if static value type field is already initialized
         assert(!flattened, "static fields should not be flattened");
         ciInstance* mirror = field->holder()->java_mirror();
         ciObject* val = mirror->field_value(field).as_object();
         if (!val->is_null_object()) {
diff a/src/hotspot/share/opto/parseHelper.cpp b/src/hotspot/share/opto/parseHelper.cpp
--- a/src/hotspot/share/opto/parseHelper.cpp
+++ b/src/hotspot/share/opto/parseHelper.cpp
@@ -380,11 +380,11 @@
     val = val->as_ValueType()->buffer(this);
   }
 
   // Clone the value type node and set the new field value
   ValueTypeNode* new_vt = holder->clone()->as_ValueType();
-  new_vt->set_oop(_gvn.zerocon(T_VALUETYPE));
+  new_vt->set_oop(_gvn.zerocon(T_INLINE_TYPE));
   gvn().set_type(new_vt, new_vt->bottom_type());
   new_vt->set_field_value_by_offset(field->offset(), val);
   Node* res = new_vt;
 
   if (!holder_klass->is_scalarizable()) {
diff a/src/hotspot/share/opto/type.cpp b/src/hotspot/share/opto/type.cpp
--- a/src/hotspot/share/opto/type.cpp
+++ b/src/hotspot/share/opto/type.cpp
@@ -126,11 +126,11 @@
   { Bad,             T_ILLEGAL,    "vectord:",      false, Op_VecD,              relocInfo::none          },  // VectorD
   { Bad,             T_ILLEGAL,    "vectorx:",      false, Op_VecX,              relocInfo::none          },  // VectorX
   { Bad,             T_ILLEGAL,    "vectory:",      false, Op_VecY,              relocInfo::none          },  // VectorY
   { Bad,             T_ILLEGAL,    "vectorz:",      false, Op_VecZ,              relocInfo::none          },  // VectorZ
 #endif
-  { Bad,             T_VALUETYPE,  "value:",        false, Node::NotAMachineReg, relocInfo::none          },  // ValueType
+  { Bad,             T_INLINE_TYPE, "value:",       false, Node::NotAMachineReg, relocInfo::none          },  // ValueType
   { Bad,             T_ADDRESS,    "anyptr:",       false, Op_RegP,              relocInfo::none          },  // AnyPtr
   { Bad,             T_ADDRESS,    "rawptr:",       false, Op_RegP,              relocInfo::none          },  // RawPtr
   { Bad,             T_OBJECT,     "oop:",          true,  Op_RegP,              relocInfo::oop_type      },  // OopPtr
   { Bad,             T_OBJECT,     "inst:",         true,  Op_RegP,              relocInfo::oop_type      },  // InstPtr
   { Bad,             T_OBJECT,     "ary:",          true,  Op_RegP,              relocInfo::oop_type      },  // AryPtr
@@ -257,11 +257,11 @@
 
   case T_ADDRESS:
     assert(type->is_return_address(), "");
     return TypeRawPtr::make((address)(intptr_t)type->as_return_address()->bci());
 
-  case T_VALUETYPE: {
+  case T_INLINE_TYPE: {
     bool is_never_null = type->is_never_null();
     ciValueKlass* vk = type->unwrap()->as_value_klass();
     if (vk->is_scalarizable() && is_never_null) {
       return TypeValueType::make(vk);
     } else {
@@ -295,11 +295,11 @@
     case T_INT:      return TypeInt::make(constant.as_int());
     case T_LONG:     return TypeLong::make(constant.as_long());
     case T_FLOAT:    return TypeF::make(constant.as_float());
     case T_DOUBLE:   return TypeD::make(constant.as_double());
     case T_ARRAY:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
     case T_OBJECT: {
         const Type* con_type = NULL;
         ciObject* oop_constant = constant.as_object();
         if (oop_constant->is_null_object()) {
           con_type = Type::get_zero_type(T_OBJECT);
@@ -333,18 +333,18 @@
 static ciConstant check_mismatched_access(ciConstant con, BasicType loadbt, bool is_unsigned) {
   BasicType conbt = con.basic_type();
   switch (conbt) {
     case T_BOOLEAN: conbt = T_BYTE;   break;
     case T_ARRAY:   conbt = T_OBJECT; break;
-    case T_VALUETYPE: conbt = T_OBJECT; break;
+    case T_INLINE_TYPE: conbt = T_OBJECT; break;
     default:                          break;
   }
   switch (loadbt) {
     case T_BOOLEAN:   loadbt = T_BYTE;   break;
     case T_NARROWOOP: loadbt = T_OBJECT; break;
     case T_ARRAY:     loadbt = T_OBJECT; break;
-    case T_VALUETYPE: loadbt = T_OBJECT; break;
+    case T_INLINE_TYPE: loadbt = T_OBJECT; break;
     case T_ADDRESS:   loadbt = T_OBJECT; break;
     default:                             break;
   }
   if (conbt == loadbt) {
     if (is_unsigned && conbt == T_BYTE) {
@@ -637,11 +637,11 @@
   TypeAryPtr::VALUES  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeValueType::BOTTOM,TypeInt::POS), NULL, false,  Offset::bottom);
 
   // Nobody should ask _array_body_type[T_NARROWOOP]. Use NULL as assert.
   TypeAryPtr::_array_body_type[T_NARROWOOP] = NULL;
   TypeAryPtr::_array_body_type[T_OBJECT]  = TypeAryPtr::OOPS;
-  TypeAryPtr::_array_body_type[T_VALUETYPE] = TypeAryPtr::OOPS;
+  TypeAryPtr::_array_body_type[T_INLINE_TYPE] = TypeAryPtr::OOPS;
   TypeAryPtr::_array_body_type[T_ARRAY]   = TypeAryPtr::OOPS; // arrays are stored in oop arrays
   TypeAryPtr::_array_body_type[T_BYTE]    = TypeAryPtr::BYTES;
   TypeAryPtr::_array_body_type[T_BOOLEAN] = TypeAryPtr::BYTES;  // boolean[] is a byte array
   TypeAryPtr::_array_body_type[T_SHORT]   = TypeAryPtr::SHORTS;
   TypeAryPtr::_array_body_type[T_CHAR]    = TypeAryPtr::CHARS;
@@ -688,11 +688,11 @@
   _const_basic_type[T_LONG]        = TypeLong::LONG;
   _const_basic_type[T_FLOAT]       = Type::FLOAT;
   _const_basic_type[T_DOUBLE]      = Type::DOUBLE;
   _const_basic_type[T_OBJECT]      = TypeInstPtr::BOTTOM;
   _const_basic_type[T_ARRAY]       = TypeInstPtr::BOTTOM; // there is no separate bottom for arrays
-  _const_basic_type[T_VALUETYPE]   = TypeInstPtr::BOTTOM;
+  _const_basic_type[T_INLINE_TYPE] = TypeInstPtr::BOTTOM;
   _const_basic_type[T_VOID]        = TypePtr::NULL_PTR;   // reflection represents void this way
   _const_basic_type[T_ADDRESS]     = TypeRawPtr::BOTTOM;  // both interpreter return addresses & random raw ptrs
   _const_basic_type[T_CONFLICT]    = Type::BOTTOM;        // why not?
 
   _zero_type[T_NARROWOOP]   = TypeNarrowOop::NULL_PTR;
@@ -705,11 +705,11 @@
   _zero_type[T_LONG]        = TypeLong::ZERO;
   _zero_type[T_FLOAT]       = TypeF::ZERO;
   _zero_type[T_DOUBLE]      = TypeD::ZERO;
   _zero_type[T_OBJECT]      = TypePtr::NULL_PTR;
   _zero_type[T_ARRAY]       = TypePtr::NULL_PTR; // null array is null oop
-  _zero_type[T_VALUETYPE]   = TypePtr::NULL_PTR;
+  _zero_type[T_INLINE_TYPE] = TypePtr::NULL_PTR;
   _zero_type[T_ADDRESS]     = TypePtr::NULL_PTR; // raw pointers use the same null
   _zero_type[T_VOID]        = Type::TOP;         // the only void value is no value at all
 
   // get_zero_type() should not happen for T_CONFLICT
   _zero_type[T_CONFLICT]= NULL;
@@ -1999,11 +1999,11 @@
   case T_BYTE:
   case T_SHORT:
   case T_INT:
     field_array[TypeFunc::Parms] = get_const_type(return_type);
     break;
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
     if (ret_vt_fields) {
       uint pos = TypeFunc::Parms;
       field_array[pos] = TypePtr::BOTTOM;
       pos++;
       ExtendedSignature sig = ExtendedSignature(NULL, SigEntryFilter());
@@ -2072,11 +2072,11 @@
     case T_CHAR:
     case T_BYTE:
     case T_SHORT:
       field_array[pos++] = TypeInt::INT;
       break;
-    case T_VALUETYPE: {
+    case T_INLINE_TYPE: {
       bool never_null = sig->is_never_null_at(i);
       if (vt_fields_as_args && type->as_value_klass()->can_be_passed_as_fields() && never_null) {
         is_flattened = true;
         collect_value_fields(type->as_value_klass(), field_array, pos, sig_cc);
       } else {
@@ -3254,11 +3254,11 @@
         ciValueKlass* vk = klass()->as_value_array_klass()->element_klass()->as_value_klass();
         int foffset = field_offset.get() + vk->first_field_offset();
         ciField* field = vk->get_field_by_offset(foffset, false);
         assert(field != NULL, "missing field");
         BasicType bt = field->layout_type();
-        _is_ptr_to_narrowoop = (bt == T_OBJECT || bt == T_ARRAY || T_VALUETYPE);
+        _is_ptr_to_narrowoop = (bt == T_OBJECT || bt == T_ARRAY || T_INLINE_TYPE);
       }
     } else if (klass()->is_instance_klass()) {
       if (this->isa_klassptr()) {
         // Perm objects don't use compressed references
       } else if (_offset == Offset::bottom || _offset == Offset::top) {
@@ -3278,11 +3278,11 @@
           assert(o != NULL, "must be constant");
           ciInstanceKlass* ik = o->as_instance()->java_lang_Class_klass()->as_instance_klass();
           BasicType basic_elem_type;
           if (ik->is_valuetype() && this->offset() == ik->as_value_klass()->default_value_offset()) {
             // Special hidden field that contains the oop of the default value type
-            basic_elem_type = T_VALUETYPE;
+            basic_elem_type = T_INLINE_TYPE;
           } else {
             ciField* field = ik->get_field_by_offset(this->offset(), true);
             assert(field != NULL, "missing field");
             basic_elem_type = field->layout_type();
           }
diff a/src/hotspot/share/opto/valuetypenode.cpp b/src/hotspot/share/opto/valuetypenode.cpp
--- a/src/hotspot/share/opto/valuetypenode.cpp
+++ b/src/hotspot/share/opto/valuetypenode.cpp
@@ -493,11 +493,11 @@
   return vt;
 }
 
 ValueTypeNode* ValueTypeNode::make_uninitialized(PhaseGVN& gvn, ciValueKlass* vk) {
   // Create a new ValueTypeNode with uninitialized values and NULL oop
-  Node* oop = vk->is_empty() ? default_oop(gvn, vk) : gvn.zerocon(T_VALUETYPE);
+  Node* oop = vk->is_empty() ? default_oop(gvn, vk) : gvn.zerocon(T_INLINE_TYPE);
   return new ValueTypeNode(vk, oop);
 }
 
 Node* ValueTypeNode::default_oop(PhaseGVN& gvn, ciValueKlass* vk) {
   // Returns the constant oop of the default value type allocation
diff a/src/hotspot/share/prims/jni.cpp b/src/hotspot/share/prims/jni.cpp
--- a/src/hotspot/share/prims/jni.cpp
+++ b/src/hotspot/share/prims/jni.cpp
@@ -894,11 +894,11 @@
     case T_FLOAT:       push_float((jfloat) va_arg(_ap, jdouble)); break;
     case T_DOUBLE:      push_double(va_arg(_ap, jdouble)); break;
 
     case T_ARRAY:
     case T_OBJECT:
-    case T_VALUETYPE:   push_object(va_arg(_ap, jobject)); break;
+    case T_INLINE_TYPE: push_object(va_arg(_ap, jobject)); break;
     default:            ShouldNotReachHere();
     }
   }
 
  public:
@@ -931,11 +931,11 @@
     case T_LONG:        push_long((_ap++)->j); break;
     case T_FLOAT:       push_float((_ap++)->f); break;
     case T_DOUBLE:      push_double((_ap++)->d); break;
     case T_ARRAY:
     case T_OBJECT:
-    case T_VALUETYPE:   push_object((_ap++)->l); break;
+    case T_INLINE_TYPE: push_object((_ap++)->l); break;
     default:            ShouldNotReachHere();
     }
   }
 
  public:
@@ -1085,11 +1085,11 @@
     obj = JNIHandles::make_local(env, i);
     JavaValue jvalue(T_VOID);
     JNI_ArgumentPusherArray ap(methodID, args);
     jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
   } else {
-    JavaValue jvalue(T_VALUETYPE);
+    JavaValue jvalue(T_INLINE_TYPE);
     JNI_ArgumentPusherArray ap(methodID, args);
     jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);
     obj = jvalue.get_jobject();
   }
   return obj;
@@ -1119,11 +1119,11 @@
     obj = JNIHandles::make_local(env, i);
     JavaValue jvalue(T_VOID);
     JNI_ArgumentPusherVaArg ap(methodID, args);
     jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
   } else {
-    JavaValue jvalue(T_VALUETYPE);
+    JavaValue jvalue(T_INLINE_TYPE);
     JNI_ArgumentPusherVaArg ap(methodID, args);
     jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);
     obj = jvalue.get_jobject();
   }
   return obj;
@@ -1158,11 +1158,11 @@
     jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
     va_end(args);
   } else {
     va_list args;
     va_start(args, methodID);
-    JavaValue jvalue(T_VALUETYPE);
+    JavaValue jvalue(T_INLINE_TYPE);
     JNI_ArgumentPusherVaArg ap(methodID, args);
     jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);
     va_end(args);
     obj = jvalue.get_jobject();
   }
diff a/src/hotspot/share/prims/jniCheck.cpp b/src/hotspot/share/prims/jniCheck.cpp
--- a/src/hotspot/share/prims/jniCheck.cpp
+++ b/src/hotspot/share/prims/jniCheck.cpp
@@ -277,11 +277,11 @@
   /* check for proper field type */
   if (!id->find_local_field(&fd))
     ReportJNIFatalError(thr, fatal_static_field_not_found);
   if ((fd.field_type() != ftype) &&
       !(fd.field_type() == T_ARRAY && ftype == T_OBJECT) &&
-      !(fd.field_type() == T_VALUETYPE && ftype == T_OBJECT)) {
+      !(fd.field_type() == T_INLINE_TYPE && ftype == T_OBJECT)) {
     ReportJNIFatalError(thr, fatal_static_field_mismatch);
   }
 }
 
 static inline void
@@ -315,11 +315,11 @@
                                                               false, &fd))
     ReportJNIFatalError(thr, fatal_instance_field_not_found);
 
   if ((fd.field_type() != ftype) &&
       !(fd.field_type() == T_ARRAY && ftype == T_OBJECT) &&
-      !(fd.field_type() == T_VALUETYPE && ftype == T_OBJECT)) {
+      !(fd.field_type() == T_INLINE_TYPE && ftype == T_OBJECT)) {
     ReportJNIFatalError(thr, fatal_instance_field_mismatch);
   }
 }
 
 static inline void
diff a/src/hotspot/share/prims/jvmtiImpl.cpp b/src/hotspot/share/prims/jvmtiImpl.cpp
--- a/src/hotspot/share/prims/jvmtiImpl.cpp
+++ b/src/hotspot/share/prims/jvmtiImpl.cpp
@@ -579,11 +579,11 @@
   case T_CHAR:
   case T_BOOLEAN:
     slot_type = T_INT;
     break;
   case T_ARRAY:
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
     slot_type = T_OBJECT;
     break;
   default:
     break;
   };
@@ -699,11 +699,11 @@
 
       // If we are updating an oop then get the oop from the handle
       // since the handle will be long gone by the time the deopt
       // happens. The oop stored in the deferred local will be
       // gc'd on its own.
-      if (_type == T_OBJECT || _type == T_VALUETYPE) {
+      if (_type == T_OBJECT || _type == T_INLINE_TYPE) {
         _value.l = cast_from_oop<jobject>(JNIHandles::resolve_external_guard(_value.l));
       }
       // Re-read the vframe so we can see that it is deoptimized
       // [ Only need because of assert in update_local() ]
       _jvf = get_java_vframe();
@@ -717,11 +717,11 @@
       case T_INT:    locals->set_int_at   (_index, _value.i); break;
       case T_LONG:   locals->set_long_at  (_index, _value.j); break;
       case T_FLOAT:  locals->set_float_at (_index, _value.f); break;
       case T_DOUBLE: locals->set_double_at(_index, _value.d); break;
       case T_OBJECT:
-      case T_VALUETYPE: {
+      case T_INLINE_TYPE: {
         Handle ob_h(Thread::current(), JNIHandles::resolve_external_guard(_value.l));
         locals->set_obj_at (_index, ob_h);
         break;
       }
       default: ShouldNotReachHere();
@@ -739,11 +739,11 @@
         case T_INT:    _value.i = locals->int_at   (_index);   break;
         case T_LONG:   _value.j = locals->long_at  (_index);   break;
         case T_FLOAT:  _value.f = locals->float_at (_index);   break;
         case T_DOUBLE: _value.d = locals->double_at(_index);   break;
         case T_OBJECT:
-        case T_VALUETYPE: {
+        case T_INLINE_TYPE: {
           // Wrap the oop to be returned in a local JNI handle since
           // oops_do() no longer applies after doit() is finished.
           oop obj = locals->obj_at(_index)();
           _value.l = JNIHandles::make_local(_calling_thread, obj);
           break;
diff a/src/hotspot/share/runtime/deoptimization.cpp b/src/hotspot/share/runtime/deoptimization.cpp
--- a/src/hotspot/share/runtime/deoptimization.cpp
+++ b/src/hotspot/share/runtime/deoptimization.cpp
@@ -1279,18 +1279,18 @@
     for (AllFieldStream fs(ik); !fs.done(); fs.next()) {
       if (!fs.access_flags().is_static() && (!skip_internal || !fs.access_flags().is_internal())) {
         ReassignedField field;
         field._offset = fs.offset();
         field._type = Signature::basic_type(fs.signature());
-        if (field._type == T_VALUETYPE) {
+        if (field._type == T_INLINE_TYPE) {
           field._type = T_OBJECT;
         }
         if (fs.is_inlined()) {
           // Resolve klass of flattened value type field
           Klass* vk = klass->get_inline_type_field_klass(fs.index());
           field._klass = ValueKlass::cast(vk);
-          field._type = T_VALUETYPE;
+          field._type = T_INLINE_TYPE;
         }
         fields->append(field);
       }
     }
     ik = ik->superklass();
@@ -1307,11 +1307,11 @@
       case T_ARRAY:
         assert(value->type() == T_OBJECT, "Agreement.");
         obj->obj_field_put(offset, value->get_obj()());
         break;
 
-      case T_VALUETYPE: {
+      case T_INLINE_TYPE: {
         // Recursively re-assign flattened value type fields
         InstanceKlass* vk = fields->at(i)._klass;
         assert(vk != NULL, "must be resolved");
         offset -= ValueKlass::cast(vk)->first_field_offset(); // Adjust offset to omit oop header
         svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);
@@ -1396,11 +1396,11 @@
 // restore fields of an eliminated value type array
 void Deoptimization::reassign_value_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, valueArrayOop obj, ValueArrayKlass* vak, TRAPS) {
   ValueKlass* vk = vak->element_klass();
   assert(vk->flatten_array(), "should only be used for flattened value type arrays");
   // Adjust offset to omit oop header
-  int base_offset = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE) - ValueKlass::cast(vk)->first_field_offset();
+  int base_offset = arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE) - ValueKlass::cast(vk)->first_field_offset();
   // Initialize all elements of the flattened value type array
   for (int i = 0; i < sv->field_size(); i++) {
     ScopeValue* val = sv->field_at(i);
     int offset = base_offset + (i << Klass::layout_helper_log2_element_size(vak->layout_helper()));
     reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, false /* skip_internal */, offset, CHECK);
diff a/src/hotspot/share/runtime/fieldDescriptor.cpp b/src/hotspot/share/runtime/fieldDescriptor.cpp
--- a/src/hotspot/share/runtime/fieldDescriptor.cpp
+++ b/src/hotspot/share/runtime/fieldDescriptor.cpp
@@ -148,11 +148,11 @@
 
 void fieldDescriptor::print() const { print_on(tty); }
 
 void fieldDescriptor::print_on_for(outputStream* st, oop obj) {
   BasicType ft = field_type();
-  if (ft != T_VALUETYPE) {
+  if (ft != T_INLINE_TYPE) {
     print_on(st);
   }
   jint as_int = 0;
   switch (ft) {
     case T_BYTE:
@@ -188,11 +188,11 @@
       break;
     case T_BOOLEAN:
       as_int = obj->bool_field(offset());
       st->print(" %s", obj->bool_field(offset()) ? "true" : "false");
       break;
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       if (is_inlined()) {
         // Print fields of inlined fields (recursively)
         ValueKlass* vk = ValueKlass::cast(field_holder()->get_inline_type_field_klass(index()));
         int field_offset = offset() - vk->first_field_offset();
         obj = (oop)(cast_from_oop<address>(obj) + field_offset);
diff a/src/hotspot/share/runtime/fieldDescriptor.inline.hpp b/src/hotspot/share/runtime/fieldDescriptor.inline.hpp
--- a/src/hotspot/share/runtime/fieldDescriptor.inline.hpp
+++ b/src/hotspot/share/runtime/fieldDescriptor.inline.hpp
@@ -78,8 +78,8 @@
 inline BasicType fieldDescriptor::field_type() const {
   return Signature::basic_type(signature());
 }
 
 inline bool fieldDescriptor::is_inlined()  const  { return field()->is_inlined(); }
-inline bool fieldDescriptor::is_inline_type() const { return Signature::basic_type(field()->signature(_cp())) == T_VALUETYPE; }
+inline bool fieldDescriptor::is_inline_type() const { return Signature::basic_type(field()->signature(_cp())) == T_INLINE_TYPE; }
 
 #endif // SHARE_RUNTIME_FIELDDESCRIPTOR_INLINE_HPP
diff a/src/hotspot/share/runtime/javaCalls.cpp b/src/hotspot/share/runtime/javaCalls.cpp
--- a/src/hotspot/share/runtime/javaCalls.cpp
+++ b/src/hotspot/share/runtime/javaCalls.cpp
@@ -160,21 +160,21 @@
     case T_SHORT    : // fall through
     case T_INT      : // fall through
 #ifndef _LP64
     case T_OBJECT   : // fall through
     case T_ARRAY    : // fall through
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
 #endif
     case T_BYTE     : // fall through
     case T_VOID     : return T_INT;
     case T_LONG     : return T_LONG;
     case T_FLOAT    : return T_FLOAT;
     case T_DOUBLE   : return T_DOUBLE;
 #ifdef _LP64
     case T_ARRAY    : // fall through
     case T_OBJECT   : return T_OBJECT;
-    case T_VALUETYPE: return T_VALUETYPE;
+    case T_INLINE_TYPE: return T_INLINE_TYPE;
 #endif
     default:
       ShouldNotReachHere();
       return T_ILLEGAL;
   }
@@ -440,11 +440,11 @@
     }
   }
 #endif
 
   jobject value_buffer = NULL;
-  if (InlineTypeReturnedAsFields && result->get_type() == T_VALUETYPE) {
+  if (InlineTypeReturnedAsFields && result->get_type() == T_INLINE_TYPE) {
     // Pre allocate buffered value in case the result is returned
     // flattened by compiled code
     ValueKlass* vk = method->returned_value_type(thread);
     if (vk->can_be_returned_as_fields()) {
       oop instance = vk->allocate_instance(CHECK);
@@ -625,11 +625,11 @@
     case T_LONG:
     case T_DOUBLE:
       check_double_word(); break;
     case T_ARRAY:
     case T_OBJECT:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       check_reference(); break;
     default:
       ShouldNotReachHere();
     }
   }
diff a/src/hotspot/share/runtime/reflection.cpp b/src/hotspot/share/runtime/reflection.cpp
--- a/src/hotspot/share/runtime/reflection.cpp
+++ b/src/hotspot/share/runtime/reflection.cpp
@@ -1180,11 +1180,11 @@
   oop return_type_mirror = java_lang_reflect_Method::return_type(method_mirror);
   BasicType rtype;
   if (java_lang_Class::is_primitive(return_type_mirror)) {
     rtype = basic_type_mirror_to_basic_type(return_type_mirror, CHECK_NULL);
   } else if (java_lang_Class::as_Klass(return_type_mirror)->is_inline_klass()) {
-    rtype = T_VALUETYPE;
+    rtype = T_INLINE_TYPE;
   } else {
     rtype = T_OBJECT;
   }
 
   InstanceKlass* klass = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));
@@ -1224,11 +1224,11 @@
     Handle no_receiver; // null instead of receiver
     BasicType rtype;
     if (klass->is_hidden()) {
       rtype = T_OBJECT;
     } else {
-      rtype = T_VALUETYPE;
+      rtype = T_INLINE_TYPE;
     }
     return invoke(klass, method, no_receiver, override, ptypes, rtype, args, false, CHECK_NULL);
   }
 
   // main branch of code creates a non-inline object:
diff a/src/hotspot/share/runtime/safepoint.cpp b/src/hotspot/share/runtime/safepoint.cpp
--- a/src/hotspot/share/runtime/safepoint.cpp
+++ b/src/hotspot/share/runtime/safepoint.cpp
@@ -1052,11 +1052,11 @@
     if (return_oop && InlineTypeReturnedAsFields) {
       SignatureStream ss(method->signature());
       while (!ss.at_return_type()) {
         ss.next();
       }
-      if (ss.type() == T_VALUETYPE) {
+      if (ss.type() == T_INLINE_TYPE) {
         // Check if value type is returned as fields
         vk = ValueKlass::returned_value_klass(map);
         if (vk != NULL) {
           // We're at a safepoint at the return of a method that returns
           // multiple values. We must make sure we preserve the oop values
diff a/src/hotspot/share/runtime/sharedRuntime.cpp b/src/hotspot/share/runtime/sharedRuntime.cpp
--- a/src/hotspot/share/runtime/sharedRuntime.cpp
+++ b/src/hotspot/share/runtime/sharedRuntime.cpp
@@ -2370,13 +2370,13 @@
           // They are all promoted to T_INT in the calling convention
           return T_INT;
         }
       }
 
-      case T_VALUETYPE: {
+      case T_INLINE_TYPE: {
         // If inline types are passed as fields, return 'in' to differentiate
-        // between a T_VALUETYPE and a T_OBJECT in the signature.
+        // between a T_INLINE_TYPE and a T_OBJECT in the signature.
         return InlineTypePassFieldsAsArgs ? in : adapter_encoding(T_OBJECT, false);
       }
 
       case T_OBJECT:
       case T_ARRAY:
@@ -2429,11 +2429,11 @@
       int value = 0;
       for (int byte = 0; byte < _basic_types_per_int; byte++) {
         int bt = 0;
         if (sig_index < total_args_passed) {
           BasicType sbt = sig->at(sig_index++)._bt;
-          if (InlineTypePassFieldsAsArgs && sbt == T_VALUETYPE) {
+          if (InlineTypePassFieldsAsArgs && sbt == T_INLINE_TYPE) {
             // Found start of inline type in signature
             vt_count++;
             if (sig_index == 1 && has_ro_adapter) {
               // With a ro_adapter, replace receiver value type delimiter by T_VOID to prevent matching
               // with other adapters that have the same value type as first argument and no receiver.
@@ -2754,11 +2754,11 @@
       SigEntry::add_entry(sig_cc, T_OBJECT);
     }
   }
   Thread* THREAD = Thread::current();
   for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {
-    if (ss.type() == T_VALUETYPE) {
+    if (ss.type() == T_INLINE_TYPE) {
       ValueKlass* vk = ss.as_value_klass(holder);
       if (vk->can_be_passed_as_fields()) {
         sig_cc->appendAll(vk->extended_sig());
       } else {
         SigEntry::add_entry(sig_cc, T_OBJECT);
@@ -2841,11 +2841,11 @@
     }
     SigEntry::add_entry(_sig, T_OBJECT);
   }
   for (SignatureStream ss(_method->signature()); !ss.at_return_type(); ss.next()) {
     BasicType bt = ss.type();
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       if (ss.as_value_klass(_method->method_holder())->can_be_passed_as_fields()) {
         _num_value_args++;
       }
       bt = T_OBJECT;
     }
@@ -3601,11 +3601,11 @@
   allocate_receiver &= !callee->is_static() && holder->is_inline_klass();
   if (allocate_receiver) {
     nb_slots++;
   }
   for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {
-    if (ss.type() == T_VALUETYPE) {
+    if (ss.type() == T_INLINE_TYPE) {
       nb_slots++;
     }
   }
   objArrayOop array_oop = oopFactory::new_objectArray(nb_slots, CHECK_NULL);
   objArrayHandle array(THREAD, array_oop);
@@ -3615,11 +3615,11 @@
     oop res = vk->allocate_instance(CHECK_NULL);
     array->obj_at_put(i, res);
     i++;
   }
   for (SignatureStream ss(callee->signature()); !ss.at_return_type(); ss.next()) {
-    if (ss.type() == T_VALUETYPE) {
+    if (ss.type() == T_INLINE_TYPE) {
       ValueKlass* vk = ss.as_value_klass(holder);
       oop res = vk->allocate_instance(CHECK_NULL);
       array->obj_at_put(i, res);
       i++;
     }
@@ -3681,11 +3681,11 @@
   }
 
   int j = 1;
   for (int i = 0; i < sig_vk->length(); i++) {
     BasicType bt = sig_vk->at(i)._bt;
-    if (bt == T_VALUETYPE) {
+    if (bt == T_INLINE_TYPE) {
       continue;
     }
     if (bt == T_VOID) {
       if (sig_vk->at(i-1)._bt == T_LONG ||
           sig_vk->at(i-1)._bt == T_DOUBLE) {
diff a/src/hotspot/share/runtime/signature.cpp b/src/hotspot/share/runtime/signature.cpp
--- a/src/hotspot/share/runtime/signature.cpp
+++ b/src/hotspot/share/runtime/signature.cpp
@@ -216,11 +216,11 @@
   int end = _end;
   int limit = _limit;
   const u1* tem;
   switch (type) {
   case T_OBJECT:
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
     tem = (const u1*) memchr(&base[end], JVM_SIGNATURE_ENDCLASS, limit - end);
     return (tem == NULL ? limit : tem + 1 - base);
 
   case T_ARRAY:
     while ((end < limit) && ((char)base[end] == JVM_SIGNATURE_ARRAY)) { end++; }
@@ -576,11 +576,11 @@
   }
 }
 
 // Inserts a reserved argument at position 'i'
 void SigEntry::insert_reserved_entry(GrowableArray<SigEntry>* sig, int i, BasicType bt) {
-  if (bt == T_OBJECT || bt == T_ARRAY || bt == T_VALUETYPE) {
+  if (bt == T_OBJECT || bt == T_ARRAY || bt == T_INLINE_TYPE) {
     // Treat this as INT to not confuse the GC
     bt = T_INT;
   } else if (bt == T_LONG || bt == T_DOUBLE) {
     // Longs and doubles take two stack slots
     sig->insert_before(i, SigEntry(T_VOID, SigEntry::ReservedOffset));
@@ -593,11 +593,11 @@
   return sig->at(i)._offset == SigEntry::ReservedOffset;
 }
 
 // Returns true if the argument at index 'i' is not a value type delimiter
 bool SigEntry::skip_value_delimiters(const GrowableArray<SigEntry>* sig, int i) {
-  return (sig->at(i)._bt != T_VALUETYPE &&
+  return (sig->at(i)._bt != T_INLINE_TYPE &&
           (sig->at(i)._bt != T_VOID || sig->at(i-1)._bt == T_LONG || sig->at(i-1)._bt == T_DOUBLE));
 }
 
 // Fill basic type array from signature array
 int SigEntry::fill_sig_bt(const GrowableArray<SigEntry>* sig, BasicType* sig_bt) {
@@ -617,11 +617,11 @@
   char* sig_str = NEW_RESOURCE_ARRAY(char, 2*length + 3);
   int idx = 0;
   sig_str[idx++] = '(';
   for (int i = 0; i < length; i++) {
     BasicType bt = sig->at(i)._bt;
-    if (bt == T_VALUETYPE || bt == T_VOID) {
+    if (bt == T_INLINE_TYPE || bt == T_VOID) {
       // Ignore
     } else {
       if (bt == T_ARRAY) {
         bt = T_OBJECT; // We don't know the element type, treat as Object
       }
diff a/src/hotspot/share/runtime/signature.hpp b/src/hotspot/share/runtime/signature.hpp
--- a/src/hotspot/share/runtime/signature.hpp
+++ b/src/hotspot/share/runtime/signature.hpp
@@ -272,11 +272,11 @@
     case T_INT:     type_name("jint"    ); break;
     case T_LONG:    type_name("jlong"   ); break;
     case T_VOID:    type_name("void"    ); break;
     case T_ARRAY:
     case T_OBJECT:
-    case T_VALUETYPE:  type_name("jobject" ); break;
+    case T_INLINE_TYPE:  type_name("jobject" ); break;
     default: ShouldNotReachHere();
     }
   }
 
  public:
@@ -406,11 +406,11 @@
       pass_long();   _jni_offset += jni_offset; _offset += 2;
       break;
     }
     case T_ARRAY:
     case T_OBJECT:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       pass_object(); _jni_offset++; _offset++;
       break;
     default:
       ShouldNotReachHere();
     }
@@ -594,20 +594,20 @@
     if (e1->_offset != e2->_offset) {
       return e1->_offset - e2->_offset;
     }
     assert((e1->_bt == T_LONG && (e2->_bt == T_LONG || e2->_bt == T_VOID)) ||
            (e1->_bt == T_DOUBLE && (e2->_bt == T_DOUBLE || e2->_bt == T_VOID)) ||
-           e1->_bt == T_VALUETYPE || e2->_bt == T_VALUETYPE || e1->_bt == T_VOID || e2->_bt == T_VOID, "bad bt");
+           e1->_bt == T_INLINE_TYPE || e2->_bt == T_INLINE_TYPE || e1->_bt == T_VOID || e2->_bt == T_VOID, "bad bt");
     if (e1->_bt == e2->_bt) {
-      assert(e1->_bt == T_VALUETYPE || e1->_bt == T_VOID, "only ones with duplicate offsets");
+      assert(e1->_bt == T_INLINE_TYPE || e1->_bt == T_VOID, "only ones with duplicate offsets");
       return 0;
     }
     if (e1->_bt == T_VOID ||
-        e2->_bt == T_VALUETYPE) {
+        e2->_bt == T_INLINE_TYPE) {
       return 1;
     }
-    if (e1->_bt == T_VALUETYPE ||
+    if (e1->_bt == T_INLINE_TYPE ||
         e2->_bt == T_VOID) {
       return -1;
     }
     ShouldNotReachHere();
     return 0;
@@ -622,11 +622,11 @@
   static bool next_is_reserved(ExtendedSignature& sig, BasicType& bt, bool can_be_void = false);
 };
 
 class SigEntryFilter {
 public:
-  bool operator()(const SigEntry& entry) { return entry._bt != T_VALUETYPE && entry._bt != T_VOID; }
+  bool operator()(const SigEntry& entry) { return entry._bt != T_INLINE_TYPE && entry._bt != T_VOID; }
 };
 
 // Specialized SignatureStream: used for invoking SystemDictionary to either find
 //                              or resolve the underlying type when iterating over a
 //                              Java descriptor (or parts of it).
diff a/src/hotspot/share/runtime/signature_cc.hpp b/src/hotspot/share/runtime/signature_cc.hpp
--- a/src/hotspot/share/runtime/signature_cc.hpp
+++ b/src/hotspot/share/runtime/signature_cc.hpp
@@ -37,21 +37,21 @@
   int _vt;
   DEBUG_ONLY(bool _finished);
 public:
   ScalarizedValueArgsStream(const GrowableArray<SigEntry>* sig_cc, int sig_cc_index, VMRegPair* regs_cc, int regs_cc_count, int regs_cc_index) :
     _sig_cc(sig_cc), _sig_cc_index(sig_cc_index), _regs_cc(regs_cc), _regs_cc_count(regs_cc_count), _regs_cc_index(regs_cc_index) {
-    assert(_sig_cc->at(_sig_cc_index)._bt == T_VALUETYPE, "should be at end delimiter");
+    assert(_sig_cc->at(_sig_cc_index)._bt == T_INLINE_TYPE, "should be at end delimiter");
     _vt = 1;
     DEBUG_ONLY(_finished = false);
   }
 
   bool next(VMRegPair& pair, BasicType& bt) {
     assert(!_finished, "sanity");
     do {
       _sig_cc_index++;
       bt = _sig_cc->at(_sig_cc_index)._bt;
-      if (bt == T_VALUETYPE) {
+      if (bt == T_INLINE_TYPE) {
         _vt++;
       } else if (bt == T_VOID &&
                  _sig_cc->at(_sig_cc_index-1)._bt != T_LONG &&
                  _sig_cc->at(_sig_cc_index-1)._bt != T_DOUBLE) {
         _vt--;
diff a/src/hotspot/share/runtime/stubRoutines.cpp b/src/hotspot/share/runtime/stubRoutines.cpp
--- a/src/hotspot/share/runtime/stubRoutines.cpp
+++ b/src/hotspot/share/runtime/stubRoutines.cpp
@@ -518,11 +518,11 @@
     if (!aligned) RETURN_STUB(jint_fill);
     RETURN_STUB(arrayof_jint_fill);
   case T_DOUBLE:
   case T_LONG:
   case T_ARRAY:
-  case T_VALUETYPE:
+  case T_INLINE_TYPE:
   case T_OBJECT:
   case T_NARROWOOP:
   case T_NARROWKLASS:
   case T_ADDRESS:
     // Currently unsupported
diff a/src/hotspot/share/runtime/vframe_hp.cpp b/src/hotspot/share/runtime/vframe_hp.cpp
--- a/src/hotspot/share/runtime/vframe_hp.cpp
+++ b/src/hotspot/share/runtime/vframe_hp.cpp
@@ -386,11 +386,11 @@
       break;
     case T_LONG:
       locals->set_long_at(index, value.j);
       break;
     case T_OBJECT:
-    case T_VALUETYPE:
+    case T_INLINE_TYPE:
       {
         Handle obj(Thread::current(), (oop)value.l);
         locals->set_obj_at(index, obj);
       }
       break;
diff a/src/hotspot/share/utilities/globalDefinitions.cpp b/src/hotspot/share/utilities/globalDefinitions.cpp
--- a/src/hotspot/share/utilities/globalDefinitions.cpp
+++ b/src/hotspot/share/utilities/globalDefinitions.cpp
@@ -126,11 +126,11 @@
       case T_INT:
       case T_FLOAT:
       case T_DOUBLE:
       case T_LONG:
       case T_OBJECT:
-      case T_VALUETYPE:
+      case T_INLINE_TYPE:
       case T_ADDRESS:     // random raw pointer
       case T_METADATA:    // metadata pointer
       case T_NARROWOOP:   // compressed pointer
       case T_NARROWKLASS: // compressed klass pointer
       case T_CONFLICT:    // might as well support a bottom type
@@ -192,11 +192,11 @@
     BytesPerHeapOop    = BytesPerWord;
     BitsPerHeapOop     = BitsPerWord;
   }
   _type2aelembytes[T_OBJECT] = heapOopSize;
   _type2aelembytes[T_ARRAY]  = heapOopSize;
-  _type2aelembytes[T_VALUETYPE]  = heapOopSize;
+  _type2aelembytes[T_INLINE_TYPE]  = heapOopSize;
 }
 
 
 // Map BasicType to signature character
 char type2char_tab[T_CONFLICT+1] = {
@@ -258,11 +258,11 @@
   T_SHORT,                 // T_SHORT    =  9,
   T_INT,                   // T_INT      = 10,
   T_LONG,                  // T_LONG     = 11,
   T_OBJECT,                // T_OBJECT   = 12,
   T_OBJECT,                // T_ARRAY    = 13,
-  T_VALUETYPE,             // T_VALUETYPE = 14,
+  T_INLINE_TYPE,           // T_INLINE_TYPE = 14,
   T_VOID,                  // T_VOID     = 15,
   T_ADDRESS,               // T_ADDRESS  = 16,
   T_NARROWOOP,             // T_NARROWOOP= 17,
   T_METADATA,              // T_METADATA = 18,
   T_NARROWKLASS,           // T_NARROWKLASS = 19,
@@ -283,11 +283,11 @@
   T_INT,     // T_SHORT    =  9,
   T_INT,     // T_INT      = 10,
   T_LONG,    // T_LONG     = 11,
   T_OBJECT,  // T_OBJECT   = 12,
   T_OBJECT,  // T_ARRAY    = 13,
-  T_OBJECT,  // T_VALUETYPE = 14,
+  T_OBJECT,  // T_INLINE_TYPE = 14,
   T_VOID,    // T_VOID     = 15,
   T_ADDRESS, // T_ADDRESS  = 16,
   T_NARROWOOP, // T_NARROWOOP  = 17,
   T_METADATA,  // T_METADATA   = 18,
   T_NARROWKLASS, // T_NARROWKLASS  = 19,
@@ -308,11 +308,11 @@
   T_SHORT_aelem_bytes,       // T_SHORT    =  9,
   T_INT_aelem_bytes,         // T_INT      = 10,
   T_LONG_aelem_bytes,        // T_LONG     = 11,
   T_OBJECT_aelem_bytes,      // T_OBJECT   = 12,
   T_ARRAY_aelem_bytes,       // T_ARRAY    = 13,
-  T_VALUETYPE_aelem_bytes,   // T_VALUETYPE = 14,
+  T_INLINE_TYPE_aelem_bytes,   // T_INLINE_TYPE = 14,
   0,                         // T_VOID     = 15,
   T_OBJECT_aelem_bytes,      // T_ADDRESS  = 16,
   T_NARROWOOP_aelem_bytes,   // T_NARROWOOP= 17,
   T_OBJECT_aelem_bytes,      // T_METADATA = 18,
   T_NARROWKLASS_aelem_bytes, // T_NARROWKLASS= 19,
diff a/src/hotspot/share/utilities/globalDefinitions.hpp b/src/hotspot/share/utilities/globalDefinitions.hpp
--- a/src/hotspot/share/utilities/globalDefinitions.hpp
+++ b/src/hotspot/share/utilities/globalDefinitions.hpp
@@ -623,11 +623,11 @@
   // T_ADDRESS, T_METADATA, T_NARROWOOP, T_NARROWKLASS describe
   // internal references within the JVM as if they were Java
   // types in their own right.
   T_OBJECT      = 12,
   T_ARRAY       = 13,
-  T_VALUETYPE   = 14,
+  T_INLINE_TYPE = 14,
   T_VOID        = 15,
   T_ADDRESS     = 16,
   T_NARROWOOP   = 17,
   T_METADATA    = 18,
   T_NARROWKLASS = 19,
@@ -644,11 +644,11 @@
     F(JVM_SIGNATURE_SHORT,   T_SHORT,   N)      \
     F(JVM_SIGNATURE_INT,     T_INT,     N)      \
     F(JVM_SIGNATURE_LONG,    T_LONG,    N)      \
     F(JVM_SIGNATURE_CLASS,   T_OBJECT,  N)      \
     F(JVM_SIGNATURE_ARRAY,   T_ARRAY,   N)      \
-    F(JVM_SIGNATURE_INLINE_TYPE, T_VALUETYPE, N) \
+    F(JVM_SIGNATURE_INLINE_TYPE, T_INLINE_TYPE, N) \
     F(JVM_SIGNATURE_VOID,    T_VOID,    N)      \
     /*end*/
 
 inline bool is_java_type(BasicType t) {
   return T_BOOLEAN <= t && t <= T_VOID;
@@ -670,11 +670,11 @@
 inline bool is_double_word_type(BasicType t) {
   return (t == T_DOUBLE || t == T_LONG);
 }
 
 inline bool is_reference_type(BasicType t) {
-  return (t == T_OBJECT || t == T_ARRAY || t == T_VALUETYPE);
+  return (t == T_OBJECT || t == T_ARRAY || t == T_INLINE_TYPE);
 }
 
 extern char type2char_tab[T_CONFLICT+1];     // Map a BasicType to a jchar
 inline char type2char(BasicType t) { return (uint)t < T_CONFLICT+1 ? type2char_tab[t] : 0; }
 extern int type2size[T_CONFLICT+1];         // Map BasicType to result stack elements
@@ -700,11 +700,11 @@
   T_OBJECT_size      = 1,
   T_ARRAY_size       = 1,
   T_NARROWOOP_size   = 1,
   T_NARROWKLASS_size = 1,
   T_VOID_size        = 0,
-  T_VALUETYPE_size   = 1
+  T_INLINE_TYPE_size = 1
 };
 
 // this works on valid parameter types but not T_VOID, T_CONFLICT, etc.
 inline int parameter_type_word_count(BasicType t) {
   if (is_double_word_type(t))  return 2;
@@ -730,15 +730,15 @@
   T_INT_aelem_bytes         = 4,
   T_LONG_aelem_bytes        = 8,
 #ifdef _LP64
   T_OBJECT_aelem_bytes      = 8,
   T_ARRAY_aelem_bytes       = 8,
-  T_VALUETYPE_aelem_bytes   = 8,
+  T_INLINE_TYPE_aelem_bytes = 8,
 #else
   T_OBJECT_aelem_bytes      = 4,
   T_ARRAY_aelem_bytes       = 4,
-  T_VALUETYPE_aelem_bytes   = 4,
+  T_INLINE_TYPE_aelem_bytes = 4,
 #endif
   T_NARROWOOP_aelem_bytes   = 4,
   T_NARROWKLASS_aelem_bytes = 4,
   T_VOID_aelem_bytes        = 0
 };
@@ -838,11 +838,11 @@
     case T_INT    : return itos;
     case T_LONG   : return ltos;
     case T_FLOAT  : return ftos;
     case T_DOUBLE : return dtos;
     case T_VOID   : return vtos;
-    case T_VALUETYPE: // fall through
+    case T_INLINE_TYPE: // fall through
     case T_ARRAY  :   // fall through
     case T_OBJECT : return atos;
     default       : return ilgl;
   }
 }
