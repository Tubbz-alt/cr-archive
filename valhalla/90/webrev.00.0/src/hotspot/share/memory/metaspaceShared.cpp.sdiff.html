<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/memory/metaspaceShared.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="heapInspection.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../oops/constantPool.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/memory/metaspaceShared.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 444     int size = FileMapInfo::get_number_of_shared_paths();
 445     if (size &gt; 0) {
 446       SystemDictionaryShared::allocate_shared_data_arrays(size, THREAD);
 447       if (!DynamicDumpSharedSpaces) {
 448         FileMapInfo* info;
 449         if (FileMapInfo::dynamic_info() == NULL) {
 450           info = FileMapInfo::current_info();
 451         } else {
 452           info = FileMapInfo::dynamic_info();
 453         }
 454         ClassLoaderExt::init_paths_start_index(info-&gt;app_class_paths_start_index());
 455         ClassLoaderExt::init_app_module_paths_start_index(info-&gt;app_module_paths_start_index());
 456       }
 457     }
 458   }
 459 }
 460 
 461 static GrowableArray&lt;Handle&gt;* _extra_interned_strings = NULL;
 462 
 463 void MetaspaceShared::read_extra_data(const char* filename, TRAPS) {
<span class="line-modified"> 464   _extra_interned_strings = new (ResourceObj::C_HEAP, mtInternal)GrowableArray&lt;Handle&gt;(10000, true);</span>
 465 
 466   HashtableTextDump reader(filename);
 467   reader.check_version(&quot;VERSION: 1.0&quot;);
 468 
 469   while (reader.remain() &gt; 0) {
 470     int utf8_length;
 471     int prefix_type = reader.scan_prefix(&amp;utf8_length);
 472     ResourceMark rm(THREAD);
 473     if (utf8_length == 0x7fffffff) {
 474       // buf_len will overflown 32-bit value.
 475       vm_exit_during_initialization(err_msg(&quot;string length too large: %d&quot;, utf8_length));
 476     }
 477     int buf_len = utf8_length+1;
 478     char* utf8_buffer = NEW_RESOURCE_ARRAY(char, buf_len);
 479     reader.get_utf8(utf8_buffer, utf8_length);
 480     utf8_buffer[utf8_length] = &#39;\0&#39;;
 481 
 482     if (prefix_type == HashtableTextDump::SymbolPrefix) {
 483       SymbolTable::new_permanent_symbol(utf8_buffer);
 484     } else{
</pre>
<hr />
<pre>
1641     address valid_old_base = patch_base;
1642     address valid_old_end  = patch_end;
1643 
1644     // after patching, the pointers must point inside this range
1645     // (the requested location of the archive, as mapped at runtime).
1646     address valid_new_base = (address)MetaspaceShared::requested_base_address();
1647     address valid_new_end  = valid_new_base + size;
1648 
1649     log_debug(cds)(&quot;Relocating archive from [&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ] to &quot;
1650                    &quot;[&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ]&quot;, p2i(patch_base), p2i(patch_end),
1651                    p2i(valid_new_base), p2i(valid_new_end));
1652 
1653     SharedDataRelocator&lt;true&gt; patcher((address*)patch_base, (address*)patch_end, valid_old_base, valid_old_end,
1654                                       valid_new_base, valid_new_end, addr_delta, ptrmap);
1655     ptrmap-&gt;iterate(&amp;patcher);
1656     ArchivePtrMarker::compact(patcher.max_non_null_offset());
1657   }
1658 }
1659 
1660 void VM_PopulateDumpSharedSpace::doit() {

1661   CHeapBitMap ptrmap;
1662   MetaspaceShared::initialize_ptr_marker(&amp;ptrmap);
1663 
1664   // We should no longer allocate anything from the metaspace, so that:
1665   //
1666   // (1) Metaspace::allocate might trigger GC if we have run out of
1667   //     committed metaspace, but we can&#39;t GC because we&#39;re running
1668   //     in the VM thread.
1669   // (2) ArchiveCompactor needs to work with a stable set of MetaspaceObjs.
1670   Metaspace::freeze();
1671   DEBUG_ONLY(SystemDictionaryShared::NoClassLoadingMark nclm);
1672 
1673   Thread* THREAD = VMThread::vm_thread();
1674 
1675   FileMapInfo::check_nonempty_dir_in_shared_path_table();
1676 
1677   NOT_PRODUCT(SystemDictionary::verify();)
1678   // The following guarantee is meant to ensure that no loader constraints
1679   // exist yet, since the constraints table is not shared.  This becomes
1680   // more important now that we don&#39;t re-initialize vtables/itables for
</pre>
<hr />
<pre>
1959     log_info(cds)(&quot;Shared spaces: preloaded %d classes&quot;, class_count);
1960 
1961     if (SharedArchiveConfigFile) {
1962       log_info(cds)(&quot;Reading extra data from %s ...&quot;, SharedArchiveConfigFile);
1963       read_extra_data(SharedArchiveConfigFile, THREAD);
1964     }
1965     log_info(cds)(&quot;Reading extra data: done.&quot;);
1966 
1967     HeapShared::init_subgraph_entry_fields(THREAD);
1968 
1969     // Rewrite and link classes
1970     log_info(cds)(&quot;Rewriting and linking classes ...&quot;);
1971 
1972     // Link any classes which got missed. This would happen if we have loaded classes that
1973     // were not explicitly specified in the classlist. E.g., if an interface implemented by class K
1974     // fails verification, all other interfaces that were not specified in the classlist but
1975     // are implemented by K are not verified.
1976     link_and_cleanup_shared_classes(CATCH);
1977     log_info(cds)(&quot;Rewriting and linking classes: done&quot;);
1978 
<span class="line-modified">1979     if (HeapShared::is_heap_object_archiving_allowed()) {</span>
<span class="line-modified">1980       // Avoid fragmentation while archiving heap objects.</span>
<span class="line-removed">1981       Universe::heap()-&gt;soft_ref_policy()-&gt;set_should_clear_all_soft_refs(true);</span>
<span class="line-removed">1982       Universe::heap()-&gt;collect(GCCause::_archive_time_gc);</span>
<span class="line-removed">1983       Universe::heap()-&gt;soft_ref_policy()-&gt;set_should_clear_all_soft_refs(false);</span>
<span class="line-removed">1984     }</span>
<span class="line-removed">1985 </span>
1986     VM_PopulateDumpSharedSpace op;
1987     VMThread::execute(&amp;op);
1988   }
1989 }
1990 
1991 
1992 int MetaspaceShared::preload_classes(const char* class_list_path, TRAPS) {
1993   ClassListParser parser(class_list_path);
1994   int class_count = 0;
1995 
1996   while (parser.parse_one_line()) {
1997     Klass* klass = parser.load_current_class(THREAD);
1998     if (HAS_PENDING_EXCEPTION) {
1999       if (klass == NULL &amp;&amp;
2000           (PENDING_EXCEPTION-&gt;klass()-&gt;name() == vmSymbols::java_lang_ClassNotFoundException())) {
2001         // print a warning only when the pending exception is class not found
2002         log_warning(cds)(&quot;Preload Warning: Cannot find %s&quot;, parser.current_class_name());
2003       }
2004       CLEAR_PENDING_EXCEPTION;
2005     }
</pre>
<hr />
<pre>
2505 
2506   // Complex case: two spaces adjacent to each other, both to be addressable
2507   //  with narrow class pointers.
2508   // We reserve the whole range spanning both spaces, then split that range up.
2509 
2510   const size_t class_space_alignment = Metaspace::reserve_alignment();
2511 
2512   // To simplify matters, lets assume that metaspace alignment will always be
2513   //  equal or a multiple of archive alignment.
2514   assert(is_power_of_2(class_space_alignment) &amp;&amp;
2515                        is_power_of_2(archive_space_alignment) &amp;&amp;
2516                        class_space_alignment &gt;= archive_space_alignment,
2517                        &quot;Sanity&quot;);
2518 
2519   const size_t class_space_size = CompressedClassSpaceSize;
2520   assert(CompressedClassSpaceSize &gt; 0 &amp;&amp;
2521          is_aligned(CompressedClassSpaceSize, class_space_alignment),
2522          &quot;CompressedClassSpaceSize malformed: &quot;
2523          SIZE_FORMAT, CompressedClassSpaceSize);
2524 
<span class="line-modified">2525   const size_t ccs_begin_offset = align_up(archive_space_size,</span>
<span class="line-modified">2526                                            class_space_alignment);</span>
2527   const size_t gap_size = ccs_begin_offset - archive_space_size;
2528 
2529   const size_t total_range_size =
2530       align_up(archive_space_size + gap_size + class_space_size,
2531                os::vm_allocation_granularity());
2532 
2533   ReservedSpace total_rs;
2534   if (base_address != NULL) {
2535     // Reserve at the given archive base address, or not at all.
2536     total_rs = ReservedSpace(total_range_size, archive_space_alignment,
2537                              false /* bool large */, (char*) base_address);
2538   } else {
2539     // Reserve at any address, but leave it up to the platform to choose a good one.
2540     total_rs = Metaspace::reserve_address_space_for_compressed_classes(total_range_size);
2541   }
2542 
2543   if (!total_rs.is_reserved()) {
2544     return NULL;
2545   }
2546 
</pre>
</td>
<td>
<hr />
<pre>
 444     int size = FileMapInfo::get_number_of_shared_paths();
 445     if (size &gt; 0) {
 446       SystemDictionaryShared::allocate_shared_data_arrays(size, THREAD);
 447       if (!DynamicDumpSharedSpaces) {
 448         FileMapInfo* info;
 449         if (FileMapInfo::dynamic_info() == NULL) {
 450           info = FileMapInfo::current_info();
 451         } else {
 452           info = FileMapInfo::dynamic_info();
 453         }
 454         ClassLoaderExt::init_paths_start_index(info-&gt;app_class_paths_start_index());
 455         ClassLoaderExt::init_app_module_paths_start_index(info-&gt;app_module_paths_start_index());
 456       }
 457     }
 458   }
 459 }
 460 
 461 static GrowableArray&lt;Handle&gt;* _extra_interned_strings = NULL;
 462 
 463 void MetaspaceShared::read_extra_data(const char* filename, TRAPS) {
<span class="line-modified"> 464   _extra_interned_strings = new (ResourceObj::C_HEAP, mtClassShared) GrowableArray&lt;Handle&gt;(10000, mtClassShared);</span>
 465 
 466   HashtableTextDump reader(filename);
 467   reader.check_version(&quot;VERSION: 1.0&quot;);
 468 
 469   while (reader.remain() &gt; 0) {
 470     int utf8_length;
 471     int prefix_type = reader.scan_prefix(&amp;utf8_length);
 472     ResourceMark rm(THREAD);
 473     if (utf8_length == 0x7fffffff) {
 474       // buf_len will overflown 32-bit value.
 475       vm_exit_during_initialization(err_msg(&quot;string length too large: %d&quot;, utf8_length));
 476     }
 477     int buf_len = utf8_length+1;
 478     char* utf8_buffer = NEW_RESOURCE_ARRAY(char, buf_len);
 479     reader.get_utf8(utf8_buffer, utf8_length);
 480     utf8_buffer[utf8_length] = &#39;\0&#39;;
 481 
 482     if (prefix_type == HashtableTextDump::SymbolPrefix) {
 483       SymbolTable::new_permanent_symbol(utf8_buffer);
 484     } else{
</pre>
<hr />
<pre>
1641     address valid_old_base = patch_base;
1642     address valid_old_end  = patch_end;
1643 
1644     // after patching, the pointers must point inside this range
1645     // (the requested location of the archive, as mapped at runtime).
1646     address valid_new_base = (address)MetaspaceShared::requested_base_address();
1647     address valid_new_end  = valid_new_base + size;
1648 
1649     log_debug(cds)(&quot;Relocating archive from [&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ] to &quot;
1650                    &quot;[&quot; INTPTR_FORMAT &quot; - &quot; INTPTR_FORMAT &quot; ]&quot;, p2i(patch_base), p2i(patch_end),
1651                    p2i(valid_new_base), p2i(valid_new_end));
1652 
1653     SharedDataRelocator&lt;true&gt; patcher((address*)patch_base, (address*)patch_end, valid_old_base, valid_old_end,
1654                                       valid_new_base, valid_new_end, addr_delta, ptrmap);
1655     ptrmap-&gt;iterate(&amp;patcher);
1656     ArchivePtrMarker::compact(patcher.max_non_null_offset());
1657   }
1658 }
1659 
1660 void VM_PopulateDumpSharedSpace::doit() {
<span class="line-added">1661   HeapShared::run_full_gc_in_vm_thread();</span>
1662   CHeapBitMap ptrmap;
1663   MetaspaceShared::initialize_ptr_marker(&amp;ptrmap);
1664 
1665   // We should no longer allocate anything from the metaspace, so that:
1666   //
1667   // (1) Metaspace::allocate might trigger GC if we have run out of
1668   //     committed metaspace, but we can&#39;t GC because we&#39;re running
1669   //     in the VM thread.
1670   // (2) ArchiveCompactor needs to work with a stable set of MetaspaceObjs.
1671   Metaspace::freeze();
1672   DEBUG_ONLY(SystemDictionaryShared::NoClassLoadingMark nclm);
1673 
1674   Thread* THREAD = VMThread::vm_thread();
1675 
1676   FileMapInfo::check_nonempty_dir_in_shared_path_table();
1677 
1678   NOT_PRODUCT(SystemDictionary::verify();)
1679   // The following guarantee is meant to ensure that no loader constraints
1680   // exist yet, since the constraints table is not shared.  This becomes
1681   // more important now that we don&#39;t re-initialize vtables/itables for
</pre>
<hr />
<pre>
1960     log_info(cds)(&quot;Shared spaces: preloaded %d classes&quot;, class_count);
1961 
1962     if (SharedArchiveConfigFile) {
1963       log_info(cds)(&quot;Reading extra data from %s ...&quot;, SharedArchiveConfigFile);
1964       read_extra_data(SharedArchiveConfigFile, THREAD);
1965     }
1966     log_info(cds)(&quot;Reading extra data: done.&quot;);
1967 
1968     HeapShared::init_subgraph_entry_fields(THREAD);
1969 
1970     // Rewrite and link classes
1971     log_info(cds)(&quot;Rewriting and linking classes ...&quot;);
1972 
1973     // Link any classes which got missed. This would happen if we have loaded classes that
1974     // were not explicitly specified in the classlist. E.g., if an interface implemented by class K
1975     // fails verification, all other interfaces that were not specified in the classlist but
1976     // are implemented by K are not verified.
1977     link_and_cleanup_shared_classes(CATCH);
1978     log_info(cds)(&quot;Rewriting and linking classes: done&quot;);
1979 
<span class="line-modified">1980     VM_PopulateDumpSharedSpace op;</span>
<span class="line-modified">1981     MutexLocker ml(THREAD, HeapShared::is_heap_object_archiving_allowed() ?</span>





1982                    Heap_lock : NULL);     // needed by HeapShared::run_gc()
1983     VMThread::execute(&amp;op);
1984   }
1985 }
1986 
1987 
1988 int MetaspaceShared::preload_classes(const char* class_list_path, TRAPS) {
1989   ClassListParser parser(class_list_path);
1990   int class_count = 0;
1991 
1992   while (parser.parse_one_line()) {
1993     Klass* klass = parser.load_current_class(THREAD);
1994     if (HAS_PENDING_EXCEPTION) {
1995       if (klass == NULL &amp;&amp;
1996           (PENDING_EXCEPTION-&gt;klass()-&gt;name() == vmSymbols::java_lang_ClassNotFoundException())) {
1997         // print a warning only when the pending exception is class not found
1998         log_warning(cds)(&quot;Preload Warning: Cannot find %s&quot;, parser.current_class_name());
1999       }
2000       CLEAR_PENDING_EXCEPTION;
2001     }
</pre>
<hr />
<pre>
2501 
2502   // Complex case: two spaces adjacent to each other, both to be addressable
2503   //  with narrow class pointers.
2504   // We reserve the whole range spanning both spaces, then split that range up.
2505 
2506   const size_t class_space_alignment = Metaspace::reserve_alignment();
2507 
2508   // To simplify matters, lets assume that metaspace alignment will always be
2509   //  equal or a multiple of archive alignment.
2510   assert(is_power_of_2(class_space_alignment) &amp;&amp;
2511                        is_power_of_2(archive_space_alignment) &amp;&amp;
2512                        class_space_alignment &gt;= archive_space_alignment,
2513                        &quot;Sanity&quot;);
2514 
2515   const size_t class_space_size = CompressedClassSpaceSize;
2516   assert(CompressedClassSpaceSize &gt; 0 &amp;&amp;
2517          is_aligned(CompressedClassSpaceSize, class_space_alignment),
2518          &quot;CompressedClassSpaceSize malformed: &quot;
2519          SIZE_FORMAT, CompressedClassSpaceSize);
2520 
<span class="line-modified">2521   const size_t ccs_begin_offset = align_up(base_address + archive_space_size,</span>
<span class="line-modified">2522                                            class_space_alignment) - base_address;</span>
2523   const size_t gap_size = ccs_begin_offset - archive_space_size;
2524 
2525   const size_t total_range_size =
2526       align_up(archive_space_size + gap_size + class_space_size,
2527                os::vm_allocation_granularity());
2528 
2529   ReservedSpace total_rs;
2530   if (base_address != NULL) {
2531     // Reserve at the given archive base address, or not at all.
2532     total_rs = ReservedSpace(total_range_size, archive_space_alignment,
2533                              false /* bool large */, (char*) base_address);
2534   } else {
2535     // Reserve at any address, but leave it up to the platform to choose a good one.
2536     total_rs = Metaspace::reserve_address_space_for_compressed_classes(total_range_size);
2537   }
2538 
2539   if (!total_rs.is_reserved()) {
2540     return NULL;
2541   }
2542 
</pre>
</td>
</tr>
</table>
<center><a href="heapInspection.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../oops/constantPool.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>