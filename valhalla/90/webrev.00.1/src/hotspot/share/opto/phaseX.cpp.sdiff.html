<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/phaseX.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="parse2.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../prims/jvmtiCodeBlobEvents.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/phaseX.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1177     }
1178   }
1179   NOT_PRODUCT(verify_PhaseIterGVN();)
1180 }
1181 
1182 
1183 /**
1184  * Register a new node with the optimizer.  Update the types array, the def-use
1185  * info.  Put on worklist.
1186  */
1187 Node* PhaseIterGVN::register_new_node_with_optimizer(Node* n, Node* orig) {
1188   set_type_bottom(n);
1189   _worklist.push(n);
1190   if (orig != NULL)  C-&gt;copy_node_notes_to(n, orig);
1191   return n;
1192 }
1193 
1194 //------------------------------transform--------------------------------------
1195 // Non-recursive: idealize Node &#39;n&#39; with respect to its inputs and its value
1196 Node *PhaseIterGVN::transform( Node *n ) {
<span class="line-removed">1197   if (_delay_transform) {</span>
<span class="line-removed">1198     // Register the node but don&#39;t optimize for now</span>
<span class="line-removed">1199     register_new_node_with_optimizer(n);</span>
<span class="line-removed">1200     return n;</span>
<span class="line-removed">1201   }</span>
<span class="line-removed">1202 </span>
1203   // If brand new node, make space in type array, and give it a type.
1204   ensure_type_or_null(n);
1205   if (type_or_null(n) == NULL) {
1206     set_type_bottom(n);
1207   }
1208 






1209   return transform_old(n);
1210 }
1211 
1212 Node *PhaseIterGVN::transform_old(Node* n) {
1213   DEBUG_ONLY(uint loop_count = 0;);
1214   NOT_PRODUCT(set_transforms());
1215 
1216   // Remove &#39;n&#39; from hash table in case it gets modified
1217   _table.hash_delete(n);
1218   if (VerifyIterativeGVN) {
1219    assert(!_table.find_index(n-&gt;_idx), &quot;found duplicate entry in table&quot;);
1220   }
1221 
1222   // Apply the Ideal call in a loop until it no longer applies
1223   Node* k = n;
1224   DEBUG_ONLY(dead_loop_check(k);)
1225   DEBUG_ONLY(bool is_new = (k-&gt;outcnt() == 0);)
1226   C-&gt;remove_modified_node(k);
1227   Node* i = apply_ideal(k, /*can_reshape=*/true);
1228   assert(i != k || is_new || i-&gt;outcnt() &gt; 0, &quot;don&#39;t return dead nodes&quot;);
</pre>
<hr />
<pre>
1409       // root is usually dead. However, sometimes reshaping walk makes
1410       // it reachable by adding use edges. So, we will NOT count Con nodes
1411       // as dead to be conservative about the dead node count at any
1412       // given time.
1413       if (!dead-&gt;is_Con()) {
1414         C-&gt;record_dead_node(dead-&gt;_idx);
1415       }
1416       if (dead-&gt;is_macro()) {
1417         C-&gt;remove_macro_node(dead);
1418       }
1419       if (dead-&gt;is_expensive()) {
1420         C-&gt;remove_expensive_node(dead);
1421       }
1422       CastIINode* cast = dead-&gt;isa_CastII();
1423       if (cast != NULL &amp;&amp; cast-&gt;has_range_check()) {
1424         C-&gt;remove_range_check_cast(cast);
1425       }
1426       if (dead-&gt;Opcode() == Op_Opaque4) {
1427         C-&gt;remove_opaque4_node(dead);
1428       }



1429       BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
1430       bs-&gt;unregister_potential_barrier_node(dead);
1431     }
1432   } // while (_stack.is_nonempty())
1433 }
1434 
1435 //------------------------------subsume_node-----------------------------------
1436 // Remove users from node &#39;old&#39; and add them to node &#39;nn&#39;.
1437 void PhaseIterGVN::subsume_node( Node *old, Node *nn ) {
1438   if (old-&gt;Opcode() == Op_SafePoint) {
1439     old-&gt;as_SafePoint()-&gt;disconnect_from_root(this);
1440   }
1441   assert( old != hash_find(old), &quot;should already been removed&quot; );
1442   assert( old != C-&gt;top(), &quot;cannot subsume top node&quot;);
1443   // Copy debug or profile information to the new version:
1444   C-&gt;copy_node_notes_to(nn, old);
1445   // Move users of node &#39;old&#39; to node &#39;nn&#39;
1446   for (DUIterator_Last imin, i = old-&gt;last_outs(imin); i &gt;= imin; ) {
1447     Node* use = old-&gt;last_out(i);  // for each use...
1448     // use might need re-hashing (but it won&#39;t if it&#39;s a new node)
</pre>
<hr />
<pre>
1473     }
1474   }
1475 
1476   // Smash all inputs to &#39;old&#39;, isolating him completely
1477   Node *temp = new Node(1);
1478   temp-&gt;init_req(0,nn);     // Add a use to nn to prevent him from dying
1479   remove_dead_node( old );
1480   temp-&gt;del_req(0);         // Yank bogus edge
1481 #ifndef PRODUCT
1482   if( VerifyIterativeGVN ) {
1483     for ( int i = 0; i &lt; _verify_window_size; i++ ) {
1484       if ( _verify_window[i] == old )
1485         _verify_window[i] = nn;
1486     }
1487   }
1488 #endif
1489   _worklist.remove(temp);   // this can be necessary
1490   temp-&gt;destruct();         // reuse the _idx of this little guy
1491 }
1492 













1493 //------------------------------add_users_to_worklist--------------------------
1494 void PhaseIterGVN::add_users_to_worklist0( Node *n ) {
1495   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
1496     _worklist.push(n-&gt;fast_out(i));  // Push on worklist
1497   }
1498 }
1499 
1500 // Return counted loop Phi if as a counted loop exit condition, cmp
1501 // compares the the induction variable with n
1502 static PhiNode* countedloop_phi_from_cmp(CmpINode* cmp, Node* n) {
1503   for (DUIterator_Fast imax, i = cmp-&gt;fast_outs(imax); i &lt; imax; i++) {
1504     Node* bol = cmp-&gt;fast_out(i);
1505     for (DUIterator_Fast i2max, i2 = bol-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1506       Node* iff = bol-&gt;fast_out(i2);
1507       if (iff-&gt;is_CountedLoopEnd()) {
1508         CountedLoopEndNode* cle = iff-&gt;as_CountedLoopEnd();
1509         if (cle-&gt;limit() == n) {
1510           PhiNode* phi = cle-&gt;phi();
1511           if (phi != NULL) {
1512             return phi;
</pre>
<hr />
<pre>
1618     // If changed AddP inputs, check Stores for loop invariant
1619     if( use_op == Op_AddP ) {
1620       for (DUIterator_Fast i2max, i2 = use-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1621         Node* u = use-&gt;fast_out(i2);
1622         if (u-&gt;is_Mem())
1623           _worklist.push(u);
1624       }
1625     }
1626     // If changed initialization activity, check dependent Stores
1627     if (use_op == Op_Allocate || use_op == Op_AllocateArray) {
1628       InitializeNode* init = use-&gt;as_Allocate()-&gt;initialization();
1629       if (init != NULL) {
1630         Node* imem = init-&gt;proj_out_or_null(TypeFunc::Memory);
1631         if (imem != NULL)  add_users_to_worklist0(imem);
1632       }
1633     }
1634     if (use_op == Op_Initialize) {
1635       Node* imem = use-&gt;as_Initialize()-&gt;proj_out_or_null(TypeFunc::Memory);
1636       if (imem != NULL)  add_users_to_worklist0(imem);
1637     }








1638     // Loading the java mirror from a Klass requires two loads and the type
1639     // of the mirror load depends on the type of &#39;n&#39;. See LoadNode::Value().
1640     //   LoadBarrier?(LoadP(LoadP(AddP(foo:Klass, #java_mirror))))
1641     BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
1642     bool has_load_barrier_nodes = bs-&gt;has_load_barrier_nodes();
1643 
1644     if (use_op == Op_LoadP &amp;&amp; use-&gt;bottom_type()-&gt;isa_rawptr()) {
1645       for (DUIterator_Fast i2max, i2 = use-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1646         Node* u = use-&gt;fast_out(i2);
1647         const Type* ut = u-&gt;bottom_type();
1648         if (u-&gt;Opcode() == Op_LoadP &amp;&amp; ut-&gt;isa_instptr()) {
1649           if (has_load_barrier_nodes) {
1650             // Search for load barriers behind the load
1651             for (DUIterator_Fast i3max, i3 = u-&gt;fast_outs(i3max); i3 &lt; i3max; i3++) {
1652               Node* b = u-&gt;fast_out(i3);
1653               if (bs-&gt;is_gc_barrier_node(b)) {
1654                 _worklist.push(b);
1655               }
1656             }
1657           }
1658           _worklist.push(u);
1659         }
1660       }
1661     }











1662   }
1663 }
1664 
1665 /**
1666  * Remove the speculative part of all types that we know of
1667  */
1668 void PhaseIterGVN::remove_speculative_types()  {
1669   assert(UseTypeSpeculation, &quot;speculation is off&quot;);
1670   for (uint i = 0; i &lt; _types.Size(); i++)  {
1671     const Type* t = _types.fast_lookup(i);
1672     if (t != NULL) {
1673       _types.map(i, t-&gt;remove_speculative());
1674     }
1675   }
1676   _table.check_no_speculative_types();
1677 }
1678 
1679 //=============================================================================
1680 #ifndef PRODUCT
1681 uint PhaseCCP::_total_invokes   = 0;
</pre>
<hr />
<pre>
1780         if (m_op == Op_AddI || m_op == Op_SubI) {
1781           for (DUIterator_Fast i2max, i2 = m-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1782             Node* p = m-&gt;fast_out(i2); // Propagate changes to uses
1783             if (p-&gt;Opcode() == Op_CmpU) {
1784               // Got a CmpU which might need the new type information from node n.
1785               if(p-&gt;bottom_type() != type(p)) { // If not already bottomed out
1786                 worklist.push(p); // Propagate change to user
1787               }
1788             }
1789           }
1790         }
1791         // If n is used in a counted loop exit condition then the type
1792         // of the counted loop&#39;s Phi depends on the type of n. See
1793         // PhiNode::Value().
1794         if (m_op == Op_CmpI) {
1795           PhiNode* phi = countedloop_phi_from_cmp((CmpINode*)m, n);
1796           if (phi != NULL) {
1797             worklist.push(phi);
1798           }
1799         }








1800         // Loading the java mirror from a Klass requires two loads and the type
1801         // of the mirror load depends on the type of &#39;n&#39;. See LoadNode::Value().
1802         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
1803         bool has_load_barrier_nodes = bs-&gt;has_load_barrier_nodes();
1804 
1805         if (m_op == Op_LoadP &amp;&amp; m-&gt;bottom_type()-&gt;isa_rawptr()) {
1806           for (DUIterator_Fast i2max, i2 = m-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1807             Node* u = m-&gt;fast_out(i2);
1808             const Type* ut = u-&gt;bottom_type();
1809             if (u-&gt;Opcode() == Op_LoadP &amp;&amp; ut-&gt;isa_instptr() &amp;&amp; ut != type(u)) {
1810               if (has_load_barrier_nodes) {
1811                 // Search for load barriers behind the load
1812                 for (DUIterator_Fast i3max, i3 = u-&gt;fast_outs(i3max); i3 &lt; i3max; i3++) {
1813                   Node* b = u-&gt;fast_out(i3);
1814                   if (bs-&gt;is_gc_barrier_node(b)) {
1815                     worklist.push(b);
1816                   }
1817                 }
1818               }
1819               worklist.push(u);
</pre>
</td>
<td>
<hr />
<pre>
1177     }
1178   }
1179   NOT_PRODUCT(verify_PhaseIterGVN();)
1180 }
1181 
1182 
1183 /**
1184  * Register a new node with the optimizer.  Update the types array, the def-use
1185  * info.  Put on worklist.
1186  */
1187 Node* PhaseIterGVN::register_new_node_with_optimizer(Node* n, Node* orig) {
1188   set_type_bottom(n);
1189   _worklist.push(n);
1190   if (orig != NULL)  C-&gt;copy_node_notes_to(n, orig);
1191   return n;
1192 }
1193 
1194 //------------------------------transform--------------------------------------
1195 // Non-recursive: idealize Node &#39;n&#39; with respect to its inputs and its value
1196 Node *PhaseIterGVN::transform( Node *n ) {






1197   // If brand new node, make space in type array, and give it a type.
1198   ensure_type_or_null(n);
1199   if (type_or_null(n) == NULL) {
1200     set_type_bottom(n);
1201   }
1202 
<span class="line-added">1203   if (_delay_transform) {</span>
<span class="line-added">1204     // Add the node to the worklist but don&#39;t optimize for now</span>
<span class="line-added">1205     _worklist.push(n);</span>
<span class="line-added">1206     return n;</span>
<span class="line-added">1207   }</span>
<span class="line-added">1208 </span>
1209   return transform_old(n);
1210 }
1211 
1212 Node *PhaseIterGVN::transform_old(Node* n) {
1213   DEBUG_ONLY(uint loop_count = 0;);
1214   NOT_PRODUCT(set_transforms());
1215 
1216   // Remove &#39;n&#39; from hash table in case it gets modified
1217   _table.hash_delete(n);
1218   if (VerifyIterativeGVN) {
1219    assert(!_table.find_index(n-&gt;_idx), &quot;found duplicate entry in table&quot;);
1220   }
1221 
1222   // Apply the Ideal call in a loop until it no longer applies
1223   Node* k = n;
1224   DEBUG_ONLY(dead_loop_check(k);)
1225   DEBUG_ONLY(bool is_new = (k-&gt;outcnt() == 0);)
1226   C-&gt;remove_modified_node(k);
1227   Node* i = apply_ideal(k, /*can_reshape=*/true);
1228   assert(i != k || is_new || i-&gt;outcnt() &gt; 0, &quot;don&#39;t return dead nodes&quot;);
</pre>
<hr />
<pre>
1409       // root is usually dead. However, sometimes reshaping walk makes
1410       // it reachable by adding use edges. So, we will NOT count Con nodes
1411       // as dead to be conservative about the dead node count at any
1412       // given time.
1413       if (!dead-&gt;is_Con()) {
1414         C-&gt;record_dead_node(dead-&gt;_idx);
1415       }
1416       if (dead-&gt;is_macro()) {
1417         C-&gt;remove_macro_node(dead);
1418       }
1419       if (dead-&gt;is_expensive()) {
1420         C-&gt;remove_expensive_node(dead);
1421       }
1422       CastIINode* cast = dead-&gt;isa_CastII();
1423       if (cast != NULL &amp;&amp; cast-&gt;has_range_check()) {
1424         C-&gt;remove_range_check_cast(cast);
1425       }
1426       if (dead-&gt;Opcode() == Op_Opaque4) {
1427         C-&gt;remove_opaque4_node(dead);
1428       }
<span class="line-added">1429       if (dead-&gt;is_ValueTypeBase()) {</span>
<span class="line-added">1430         C-&gt;remove_value_type(dead);</span>
<span class="line-added">1431       }</span>
1432       BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
1433       bs-&gt;unregister_potential_barrier_node(dead);
1434     }
1435   } // while (_stack.is_nonempty())
1436 }
1437 
1438 //------------------------------subsume_node-----------------------------------
1439 // Remove users from node &#39;old&#39; and add them to node &#39;nn&#39;.
1440 void PhaseIterGVN::subsume_node( Node *old, Node *nn ) {
1441   if (old-&gt;Opcode() == Op_SafePoint) {
1442     old-&gt;as_SafePoint()-&gt;disconnect_from_root(this);
1443   }
1444   assert( old != hash_find(old), &quot;should already been removed&quot; );
1445   assert( old != C-&gt;top(), &quot;cannot subsume top node&quot;);
1446   // Copy debug or profile information to the new version:
1447   C-&gt;copy_node_notes_to(nn, old);
1448   // Move users of node &#39;old&#39; to node &#39;nn&#39;
1449   for (DUIterator_Last imin, i = old-&gt;last_outs(imin); i &gt;= imin; ) {
1450     Node* use = old-&gt;last_out(i);  // for each use...
1451     // use might need re-hashing (but it won&#39;t if it&#39;s a new node)
</pre>
<hr />
<pre>
1476     }
1477   }
1478 
1479   // Smash all inputs to &#39;old&#39;, isolating him completely
1480   Node *temp = new Node(1);
1481   temp-&gt;init_req(0,nn);     // Add a use to nn to prevent him from dying
1482   remove_dead_node( old );
1483   temp-&gt;del_req(0);         // Yank bogus edge
1484 #ifndef PRODUCT
1485   if( VerifyIterativeGVN ) {
1486     for ( int i = 0; i &lt; _verify_window_size; i++ ) {
1487       if ( _verify_window[i] == old )
1488         _verify_window[i] = nn;
1489     }
1490   }
1491 #endif
1492   _worklist.remove(temp);   // this can be necessary
1493   temp-&gt;destruct();         // reuse the _idx of this little guy
1494 }
1495 
<span class="line-added">1496 void PhaseIterGVN::replace_in_uses(Node* n, Node* m) {</span>
<span class="line-added">1497   assert(n != NULL, &quot;sanity&quot;);</span>
<span class="line-added">1498   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-added">1499     Node* u = n-&gt;fast_out(i);</span>
<span class="line-added">1500     if (u != n) {</span>
<span class="line-added">1501       rehash_node_delayed(u);</span>
<span class="line-added">1502       int nb = u-&gt;replace_edge(n, m);</span>
<span class="line-added">1503       --i, imax -= nb;</span>
<span class="line-added">1504     }</span>
<span class="line-added">1505   }</span>
<span class="line-added">1506   assert(n-&gt;outcnt() == 0, &quot;all uses must be deleted&quot;);</span>
<span class="line-added">1507 }</span>
<span class="line-added">1508 </span>
1509 //------------------------------add_users_to_worklist--------------------------
1510 void PhaseIterGVN::add_users_to_worklist0( Node *n ) {
1511   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
1512     _worklist.push(n-&gt;fast_out(i));  // Push on worklist
1513   }
1514 }
1515 
1516 // Return counted loop Phi if as a counted loop exit condition, cmp
1517 // compares the the induction variable with n
1518 static PhiNode* countedloop_phi_from_cmp(CmpINode* cmp, Node* n) {
1519   for (DUIterator_Fast imax, i = cmp-&gt;fast_outs(imax); i &lt; imax; i++) {
1520     Node* bol = cmp-&gt;fast_out(i);
1521     for (DUIterator_Fast i2max, i2 = bol-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1522       Node* iff = bol-&gt;fast_out(i2);
1523       if (iff-&gt;is_CountedLoopEnd()) {
1524         CountedLoopEndNode* cle = iff-&gt;as_CountedLoopEnd();
1525         if (cle-&gt;limit() == n) {
1526           PhiNode* phi = cle-&gt;phi();
1527           if (phi != NULL) {
1528             return phi;
</pre>
<hr />
<pre>
1634     // If changed AddP inputs, check Stores for loop invariant
1635     if( use_op == Op_AddP ) {
1636       for (DUIterator_Fast i2max, i2 = use-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1637         Node* u = use-&gt;fast_out(i2);
1638         if (u-&gt;is_Mem())
1639           _worklist.push(u);
1640       }
1641     }
1642     // If changed initialization activity, check dependent Stores
1643     if (use_op == Op_Allocate || use_op == Op_AllocateArray) {
1644       InitializeNode* init = use-&gt;as_Allocate()-&gt;initialization();
1645       if (init != NULL) {
1646         Node* imem = init-&gt;proj_out_or_null(TypeFunc::Memory);
1647         if (imem != NULL)  add_users_to_worklist0(imem);
1648       }
1649     }
1650     if (use_op == Op_Initialize) {
1651       Node* imem = use-&gt;as_Initialize()-&gt;proj_out_or_null(TypeFunc::Memory);
1652       if (imem != NULL)  add_users_to_worklist0(imem);
1653     }
<span class="line-added">1654     if (use_op == Op_CastP2X) {</span>
<span class="line-added">1655       for (DUIterator_Fast i2max, i2 = use-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {</span>
<span class="line-added">1656         Node* u = use-&gt;fast_out(i2);</span>
<span class="line-added">1657         if (u-&gt;Opcode() == Op_AndX) {</span>
<span class="line-added">1658           _worklist.push(u);</span>
<span class="line-added">1659         }</span>
<span class="line-added">1660       }</span>
<span class="line-added">1661     }</span>
1662     // Loading the java mirror from a Klass requires two loads and the type
1663     // of the mirror load depends on the type of &#39;n&#39;. See LoadNode::Value().
1664     //   LoadBarrier?(LoadP(LoadP(AddP(foo:Klass, #java_mirror))))
1665     BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
1666     bool has_load_barrier_nodes = bs-&gt;has_load_barrier_nodes();
1667 
1668     if (use_op == Op_LoadP &amp;&amp; use-&gt;bottom_type()-&gt;isa_rawptr()) {
1669       for (DUIterator_Fast i2max, i2 = use-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1670         Node* u = use-&gt;fast_out(i2);
1671         const Type* ut = u-&gt;bottom_type();
1672         if (u-&gt;Opcode() == Op_LoadP &amp;&amp; ut-&gt;isa_instptr()) {
1673           if (has_load_barrier_nodes) {
1674             // Search for load barriers behind the load
1675             for (DUIterator_Fast i3max, i3 = u-&gt;fast_outs(i3max); i3 &lt; i3max; i3++) {
1676               Node* b = u-&gt;fast_out(i3);
1677               if (bs-&gt;is_gc_barrier_node(b)) {
1678                 _worklist.push(b);
1679               }
1680             }
1681           }
1682           _worklist.push(u);
1683         }
1684       }
1685     }
<span class="line-added">1686 </span>
<span class="line-added">1687     // Give CallStaticJavaNode::remove_useless_allocation a chance to run</span>
<span class="line-added">1688     if (use-&gt;is_Region()) {</span>
<span class="line-added">1689       Node* c = use;</span>
<span class="line-added">1690       do {</span>
<span class="line-added">1691         c = c-&gt;unique_ctrl_out();</span>
<span class="line-added">1692       } while (c != NULL &amp;&amp; c-&gt;is_Region());</span>
<span class="line-added">1693       if (c != NULL &amp;&amp; c-&gt;is_CallStaticJava() &amp;&amp; c-&gt;as_CallStaticJava()-&gt;uncommon_trap_request() != 0) {</span>
<span class="line-added">1694         _worklist.push(c);</span>
<span class="line-added">1695       }</span>
<span class="line-added">1696     }</span>
1697   }
1698 }
1699 
1700 /**
1701  * Remove the speculative part of all types that we know of
1702  */
1703 void PhaseIterGVN::remove_speculative_types()  {
1704   assert(UseTypeSpeculation, &quot;speculation is off&quot;);
1705   for (uint i = 0; i &lt; _types.Size(); i++)  {
1706     const Type* t = _types.fast_lookup(i);
1707     if (t != NULL) {
1708       _types.map(i, t-&gt;remove_speculative());
1709     }
1710   }
1711   _table.check_no_speculative_types();
1712 }
1713 
1714 //=============================================================================
1715 #ifndef PRODUCT
1716 uint PhaseCCP::_total_invokes   = 0;
</pre>
<hr />
<pre>
1815         if (m_op == Op_AddI || m_op == Op_SubI) {
1816           for (DUIterator_Fast i2max, i2 = m-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1817             Node* p = m-&gt;fast_out(i2); // Propagate changes to uses
1818             if (p-&gt;Opcode() == Op_CmpU) {
1819               // Got a CmpU which might need the new type information from node n.
1820               if(p-&gt;bottom_type() != type(p)) { // If not already bottomed out
1821                 worklist.push(p); // Propagate change to user
1822               }
1823             }
1824           }
1825         }
1826         // If n is used in a counted loop exit condition then the type
1827         // of the counted loop&#39;s Phi depends on the type of n. See
1828         // PhiNode::Value().
1829         if (m_op == Op_CmpI) {
1830           PhiNode* phi = countedloop_phi_from_cmp((CmpINode*)m, n);
1831           if (phi != NULL) {
1832             worklist.push(phi);
1833           }
1834         }
<span class="line-added">1835         if (m_op == Op_CastP2X) {</span>
<span class="line-added">1836           for (DUIterator_Fast i2max, i2 = m-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {</span>
<span class="line-added">1837             Node* u = m-&gt;fast_out(i2);</span>
<span class="line-added">1838             if (u-&gt;Opcode() == Op_AndX) {</span>
<span class="line-added">1839               worklist.push(u);</span>
<span class="line-added">1840             }</span>
<span class="line-added">1841           }</span>
<span class="line-added">1842         }</span>
1843         // Loading the java mirror from a Klass requires two loads and the type
1844         // of the mirror load depends on the type of &#39;n&#39;. See LoadNode::Value().
1845         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
1846         bool has_load_barrier_nodes = bs-&gt;has_load_barrier_nodes();
1847 
1848         if (m_op == Op_LoadP &amp;&amp; m-&gt;bottom_type()-&gt;isa_rawptr()) {
1849           for (DUIterator_Fast i2max, i2 = m-&gt;fast_outs(i2max); i2 &lt; i2max; i2++) {
1850             Node* u = m-&gt;fast_out(i2);
1851             const Type* ut = u-&gt;bottom_type();
1852             if (u-&gt;Opcode() == Op_LoadP &amp;&amp; ut-&gt;isa_instptr() &amp;&amp; ut != type(u)) {
1853               if (has_load_barrier_nodes) {
1854                 // Search for load barriers behind the load
1855                 for (DUIterator_Fast i3max, i3 = u-&gt;fast_outs(i3max); i3 &lt; i3max; i3++) {
1856                   Node* b = u-&gt;fast_out(i3);
1857                   if (bs-&gt;is_gc_barrier_node(b)) {
1858                     worklist.push(b);
1859                   }
1860                 }
1861               }
1862               worklist.push(u);
</pre>
</td>
</tr>
</table>
<center><a href="parse2.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../prims/jvmtiCodeBlobEvents.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>