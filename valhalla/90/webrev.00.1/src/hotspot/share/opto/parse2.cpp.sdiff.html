<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/parse2.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="output.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="phaseX.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/parse2.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;ci/ciMethodData.hpp&quot;
  27 #include &quot;classfile/systemDictionary.hpp&quot;
  28 #include &quot;classfile/vmSymbols.hpp&quot;
  29 #include &quot;compiler/compileLog.hpp&quot;
  30 #include &quot;interpreter/linkResolver.hpp&quot;
  31 #include &quot;memory/resourceArea.hpp&quot;
  32 #include &quot;memory/universe.hpp&quot;
  33 #include &quot;oops/oop.inline.hpp&quot;
  34 #include &quot;opto/addnode.hpp&quot;
  35 #include &quot;opto/castnode.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;
  37 #include &quot;opto/divnode.hpp&quot;
  38 #include &quot;opto/idealGraphPrinter.hpp&quot;

  39 #include &quot;opto/matcher.hpp&quot;
  40 #include &quot;opto/memnode.hpp&quot;
  41 #include &quot;opto/mulnode.hpp&quot;
  42 #include &quot;opto/opaquenode.hpp&quot;
  43 #include &quot;opto/parse.hpp&quot;
  44 #include &quot;opto/runtime.hpp&quot;

  45 #include &quot;runtime/deoptimization.hpp&quot;
  46 #include &quot;runtime/sharedRuntime.hpp&quot;
  47 
  48 #ifndef PRODUCT
  49 extern int explicit_null_checks_inserted,
  50            explicit_null_checks_elided;
  51 #endif
  52 

















  53 //---------------------------------array_load----------------------------------
  54 void Parse::array_load(BasicType bt) {
  55   const Type* elemtype = Type::TOP;
<span class="line-removed">  56   bool big_val = bt == T_DOUBLE || bt == T_LONG;</span>
  57   Node* adr = array_addressing(bt, 0, elemtype);
  58   if (stopped())  return;     // guaranteed null or range check
  59 
<span class="line-modified">  60   pop();                      // index (already used)</span>
<span class="line-modified">  61   Node* array = pop();        // the array itself</span>






























































































































  62 
  63   if (elemtype == TypeInt::BOOL) {
  64     bt = T_BOOLEAN;
  65   }
  66   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
<span class="line-modified">  67 </span>
<span class="line-removed">  68   Node* ld = access_load_at(array, adr, adr_type, elemtype, bt,</span>
  69                             IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
<span class="line-modified">  70   if (big_val) {</span>
<span class="line-modified">  71     push_pair(ld);</span>
<span class="line-modified">  72   } else {</span>
<span class="line-modified">  73     push(ld);</span>


  74   }





  75 }
  76 
  77 
  78 //--------------------------------array_store----------------------------------
  79 void Parse::array_store(BasicType bt) {
  80   const Type* elemtype = Type::TOP;
<span class="line-modified">  81   bool big_val = bt == T_DOUBLE || bt == T_LONG;</span>
<span class="line-removed">  82   Node* adr = array_addressing(bt, big_val ? 2 : 1, elemtype);</span>
  83   if (stopped())  return;     // guaranteed null or range check

  84   if (bt == T_OBJECT) {
<span class="line-modified">  85     array_store_check();</span>

  86   }
<span class="line-modified">  87   Node* val;                  // Oop to store</span>
<span class="line-modified">  88   if (big_val) {</span>
<span class="line-modified">  89     val = pop_pair();</span>
<span class="line-modified">  90   } else {</span>
<span class="line-modified">  91     val = pop();</span>
<span class="line-modified">  92   }</span>
<span class="line-removed">  93   pop();                      // index (already used)</span>
<span class="line-removed">  94   Node* array = pop();        // the array itself</span>
  95 
  96   if (elemtype == TypeInt::BOOL) {
  97     bt = T_BOOLEAN;
<span class="line-modified">  98   }</span>
<span class="line-modified">  99   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);</span>

























 100 
<span class="line-modified"> 101   access_store_at(array, adr, adr_type, val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY);</span>





















































































































 102 }
 103 
 104 
 105 //------------------------------array_addressing-------------------------------
 106 // Pull array and index from the stack.  Compute pointer-to-element.
 107 Node* Parse::array_addressing(BasicType type, int vals, const Type*&amp; elemtype) {
 108   Node *idx   = peek(0+vals);   // Get from stack without popping
 109   Node *ary   = peek(1+vals);   // in case of exception
 110 
 111   // Null check the array base, with correct stack contents
 112   ary = null_check(ary, T_ARRAY);
 113   // Compile-time detect of null-exception?
 114   if (stopped())  return top();
 115 
 116   const TypeAryPtr* arytype  = _gvn.type(ary)-&gt;is_aryptr();
 117   const TypeInt*    sizetype = arytype-&gt;size();
 118   elemtype = arytype-&gt;elem();
 119 
 120   if (UseUniqueSubclasses) {
 121     const Type* el = elemtype-&gt;make_ptr();
</pre>
<hr />
<pre>
 181       if (C-&gt;allow_range_check_smearing()) {
 182         // Do not use builtin_throw, since range checks are sometimes
 183         // made more stringent by an optimistic transformation.
 184         // This creates &quot;tentative&quot; range checks at this point,
 185         // which are not guaranteed to throw exceptions.
 186         // See IfNode::Ideal, is_range_check, adjust_check.
 187         uncommon_trap(Deoptimization::Reason_range_check,
 188                       Deoptimization::Action_make_not_entrant,
 189                       NULL, &quot;range_check&quot;);
 190       } else {
 191         // If we have already recompiled with the range-check-widening
 192         // heroic optimization turned off, then we must really be throwing
 193         // range check exceptions.
 194         builtin_throw(Deoptimization::Reason_range_check, idx);
 195       }
 196     }
 197   }
 198   // Check for always knowing you are throwing a range-check exception
 199   if (stopped())  return top();
 200 
























































































































 201   // Make array address computation control dependent to prevent it
 202   // from floating above the range check during loop optimizations.
 203   Node* ptr = array_element_address(ary, idx, type, sizetype, control());
 204   assert(ptr != top(), &quot;top should go hand-in-hand with stopped&quot;);
 205 
 206   return ptr;
 207 }
 208 
 209 
 210 // returns IfNode
 211 IfNode* Parse::jump_if_fork_int(Node* a, Node* b, BoolTest::mask mask, float prob, float cnt) {
 212   Node   *cmp = _gvn.transform(new CmpINode(a, b)); // two cases: shiftcount &gt; 32 and shiftcount &lt;= 32
 213   Node   *tst = _gvn.transform(new BoolNode(cmp, mask));
 214   IfNode *iff = create_and_map_if(control(), tst, prob, cnt);
 215   return iff;
 216 }
 217 
 218 // return Region node
 219 Node* Parse::jump_if_join(Node* iffalse, Node* iftrue) {
 220   Node *region  = new RegionNode(3); // 2 results
</pre>
<hr />
<pre>
1469 
1470   // Sanity check the probability value
1471   assert(prob &gt; 0.0f,&quot;Bad probability in Parser&quot;);
1472  // Need xform to put node in hash table
1473   IfNode *iff = create_and_xform_if( control(), tst, prob, cnt );
1474   assert(iff-&gt;_prob &gt; 0.0f,&quot;Optimizer made bad probability in parser&quot;);
1475   // True branch
1476   { PreserveJVMState pjvms(this);
1477     Node* iftrue  = _gvn.transform( new IfTrueNode (iff) );
1478     set_control(iftrue);
1479 
1480     if (stopped()) {            // Path is dead?
1481       NOT_PRODUCT(explicit_null_checks_elided++);
1482       if (C-&gt;eliminate_boxing()) {
1483         // Mark the successor block as parsed
1484         branch_block-&gt;next_path_num();
1485       }
1486     } else {                    // Path is live.
1487       // Update method data
1488       profile_taken_branch(target_bci);
<span class="line-modified">1489       adjust_map_after_if(btest, c, prob, branch_block, next_block);</span>
1490       if (!stopped()) {
1491         merge(target_bci);
1492       }
1493     }
1494   }
1495 
1496   // False branch
1497   Node* iffalse = _gvn.transform( new IfFalseNode(iff) );
1498   set_control(iffalse);
1499 
1500   if (stopped()) {              // Path is dead?
1501     NOT_PRODUCT(explicit_null_checks_elided++);
1502     if (C-&gt;eliminate_boxing()) {
1503       // Mark the successor block as parsed
1504       next_block-&gt;next_path_num();
1505     }
1506   } else  {                     // Path is live.
1507     // Update method data
1508     profile_not_taken_branch();
<span class="line-modified">1509     adjust_map_after_if(BoolTest(btest).negate(), c, 1.0-prob,</span>
<span class="line-removed">1510                         next_block, branch_block);</span>
1511   }
1512 }
1513 
1514 //------------------------------------do_if------------------------------------
<span class="line-modified">1515 void Parse::do_if(BoolTest::mask btest, Node* c) {</span>
1516   int target_bci = iter().get_dest();
1517 
1518   Block* branch_block = successor_for_bci(target_bci);
1519   Block* next_block   = successor_for_bci(iter().next_bci());
1520 
1521   float cnt;
1522   float prob = branch_prediction(cnt, btest, target_bci, c);
1523   float untaken_prob = 1.0 - prob;
1524 
1525   if (prob == PROB_UNKNOWN) {
1526     if (PrintOpto &amp;&amp; Verbose) {
1527       tty-&gt;print_cr(&quot;Never-taken edge stops compilation at bci %d&quot;, bci());
1528     }
1529     repush_if_args(); // to gather stats on loop
1530     // We need to mark this branch as taken so that if we recompile we will
1531     // see that it is possible. In the tiered system the interpreter doesn&#39;t
1532     // do profiling and by the time we get to the lower tier from the interpreter
1533     // the path may be cold again. Make sure it doesn&#39;t look untaken
1534     profile_taken_branch(target_bci, !ProfileInterpreter);
1535     uncommon_trap(Deoptimization::Reason_unreached,
</pre>
<hr />
<pre>
1584   }
1585 
1586   // Generate real control flow
1587   float true_prob = (taken_if_true ? prob : untaken_prob);
1588   IfNode* iff = create_and_map_if(control(), tst, true_prob, cnt);
1589   assert(iff-&gt;_prob &gt; 0.0f,&quot;Optimizer made bad probability in parser&quot;);
1590   Node* taken_branch   = new IfTrueNode(iff);
1591   Node* untaken_branch = new IfFalseNode(iff);
1592   if (!taken_if_true) {  // Finish conversion to canonical form
1593     Node* tmp      = taken_branch;
1594     taken_branch   = untaken_branch;
1595     untaken_branch = tmp;
1596   }
1597 
1598   // Branch is taken:
1599   { PreserveJVMState pjvms(this);
1600     taken_branch = _gvn.transform(taken_branch);
1601     set_control(taken_branch);
1602 
1603     if (stopped()) {
<span class="line-modified">1604       if (C-&gt;eliminate_boxing()) {</span>
<span class="line-modified">1605         // Mark the successor block as parsed</span>
1606         branch_block-&gt;next_path_num();
1607       }
1608     } else {
1609       // Update method data
1610       profile_taken_branch(target_bci);
<span class="line-modified">1611       adjust_map_after_if(taken_btest, c, prob, branch_block, next_block);</span>
1612       if (!stopped()) {
<span class="line-modified">1613         merge(target_bci);</span>








1614       }
1615     }
1616   }
1617 
1618   untaken_branch = _gvn.transform(untaken_branch);
1619   set_control(untaken_branch);
1620 
1621   // Branch not taken.
<span class="line-modified">1622   if (stopped()) {</span>
1623     if (C-&gt;eliminate_boxing()) {
<span class="line-modified">1624       // Mark the successor block as parsed</span>
1625       next_block-&gt;next_path_num();
1626     }
1627   } else {
1628     // Update method data
1629     profile_not_taken_branch();
<span class="line-modified">1630     adjust_map_after_if(untaken_btest, c, untaken_prob,</span>
<span class="line-modified">1631                         next_block, branch_block);</span>











































































































































































































1632   }
1633 }
1634 
1635 bool Parse::path_is_suitable_for_uncommon_trap(float prob) const {
1636   // Don&#39;t want to speculate on uncommon traps when running with -Xcomp
1637   if (!UseInterpreter) {
1638     return false;
1639   }
1640   return (seems_never_taken(prob) &amp;&amp; seems_stable_comparison());
1641 }
1642 
1643 void Parse::maybe_add_predicate_after_if(Block* path) {
1644   if (path-&gt;is_SEL_head() &amp;&amp; path-&gt;preds_parsed() == 0) {
1645     // Add predicates at bci of if dominating the loop so traps can be
1646     // recorded on the if&#39;s profile data
1647     int bc_depth = repush_if_args();
1648     add_empty_predicates();
1649     dec_sp(bc_depth);
1650     path-&gt;set_has_predicates();
1651   }
1652 }
1653 
1654 
1655 //----------------------------adjust_map_after_if------------------------------
1656 // Adjust the JVM state to reflect the result of taking this path.
1657 // Basically, it means inspecting the CmpNode controlling this
1658 // branch, seeing how it constrains a tested value, and then
1659 // deciding if it&#39;s worth our while to encode this constraint
1660 // as graph nodes in the current abstract interpretation map.
<span class="line-modified">1661 void Parse::adjust_map_after_if(BoolTest::mask btest, Node* c, float prob,</span>
<span class="line-removed">1662                                 Block* path, Block* other_path) {</span>
1663   if (!c-&gt;is_Cmp()) {
1664     maybe_add_predicate_after_if(path);
1665     return;
1666   }
1667 
1668   if (stopped() || btest == BoolTest::illegal) {
1669     return;                             // nothing to do
1670   }
1671 
1672   bool is_fallthrough = (path == successor_for_bci(iter().next_bci()));
1673 
1674   if (path_is_suitable_for_uncommon_trap(prob)) {
1675     repush_if_args();
1676     uncommon_trap(Deoptimization::Reason_unstable_if,
1677                   Deoptimization::Action_reinterpret,
1678                   NULL,
1679                   (is_fallthrough ? &quot;taken always&quot; : &quot;taken never&quot;));
1680     return;
1681   }
1682 
</pre>
<hr />
<pre>
1852   if (c-&gt;Opcode() == Op_CmpP &amp;&amp;
1853       (c-&gt;in(1)-&gt;Opcode() == Op_LoadKlass || c-&gt;in(1)-&gt;Opcode() == Op_DecodeNKlass) &amp;&amp;
1854       c-&gt;in(2)-&gt;is_Con()) {
1855     Node* load_klass = NULL;
1856     Node* decode = NULL;
1857     if (c-&gt;in(1)-&gt;Opcode() == Op_DecodeNKlass) {
1858       decode = c-&gt;in(1);
1859       load_klass = c-&gt;in(1)-&gt;in(1);
1860     } else {
1861       load_klass = c-&gt;in(1);
1862     }
1863     if (load_klass-&gt;in(2)-&gt;is_AddP()) {
1864       Node* addp = load_klass-&gt;in(2);
1865       Node* obj = addp-&gt;in(AddPNode::Address);
1866       const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
1867       if (obj_type-&gt;speculative_type_not_null() != NULL) {
1868         ciKlass* k = obj_type-&gt;speculative_type();
1869         inc_sp(2);
1870         obj = maybe_cast_profiled_obj(obj, k);
1871         dec_sp(2);




1872         // Make the CmpP use the casted obj
1873         addp = basic_plus_adr(obj, addp-&gt;in(AddPNode::Offset));
1874         load_klass = load_klass-&gt;clone();
1875         load_klass-&gt;set_req(2, addp);
1876         load_klass = _gvn.transform(load_klass);
1877         if (decode != NULL) {
1878           decode = decode-&gt;clone();
1879           decode-&gt;set_req(1, load_klass);
1880           load_klass = _gvn.transform(decode);
1881         }
1882         c = c-&gt;clone();
1883         c-&gt;set_req(1, load_klass);
1884         c = _gvn.transform(c);
1885       }
1886     }
1887   }
1888   return c;
1889 }
1890 
1891 //------------------------------do_one_bytecode--------------------------------
</pre>
<hr />
<pre>
2699     // See if we can get some profile data and hand it off to the next block
2700     Block *target_block = block()-&gt;successor_for_bci(target_bci);
2701     if (target_block-&gt;pred_count() != 1)  break;
2702     ciMethodData* methodData = method()-&gt;method_data();
2703     if (!methodData-&gt;is_mature())  break;
2704     ciProfileData* data = methodData-&gt;bci_to_data(bci());
2705     assert(data != NULL &amp;&amp; data-&gt;is_JumpData(), &quot;need JumpData for taken branch&quot;);
2706     int taken = ((ciJumpData*)data)-&gt;taken();
2707     taken = method()-&gt;scale_count(taken);
2708     target_block-&gt;set_count(taken);
2709     break;
2710   }
2711 
2712   case Bytecodes::_ifnull:    btest = BoolTest::eq; goto handle_if_null;
2713   case Bytecodes::_ifnonnull: btest = BoolTest::ne; goto handle_if_null;
2714   handle_if_null:
2715     // If this is a backwards branch in the bytecodes, add Safepoint
2716     maybe_add_safepoint(iter().get_dest());
2717     a = null();
2718     b = pop();
<span class="line-modified">2719     if (!_gvn.type(b)-&gt;speculative_maybe_null() &amp;&amp;</span>
<span class="line-modified">2720         !too_many_traps(Deoptimization::Reason_speculate_null_check)) {</span>
<span class="line-modified">2721       inc_sp(1);</span>
<span class="line-modified">2722       Node* null_ctl = top();</span>
<span class="line-modified">2723       b = null_check_oop(b, &amp;null_ctl, true, true, true);</span>
<span class="line-modified">2724       assert(null_ctl-&gt;is_top(), &quot;no null control here&quot;);</span>
<span class="line-modified">2725       dec_sp(1);</span>
<span class="line-modified">2726     } else if (_gvn.type(b)-&gt;speculative_always_null() &amp;&amp;</span>
<span class="line-modified">2727                !too_many_traps(Deoptimization::Reason_speculate_null_assert)) {</span>
<span class="line-modified">2728       inc_sp(1);</span>
<span class="line-modified">2729       b = null_assert(b);</span>
<span class="line-modified">2730       dec_sp(1);</span>
<span class="line-modified">2731     }</span>
<span class="line-modified">2732     c = _gvn.transform( new CmpPNode(b, a) );</span>





2733     do_ifnull(btest, c);
2734     break;
2735 
2736   case Bytecodes::_if_acmpeq: btest = BoolTest::eq; goto handle_if_acmp;
2737   case Bytecodes::_if_acmpne: btest = BoolTest::ne; goto handle_if_acmp;
2738   handle_if_acmp:
2739     // If this is a backwards branch in the bytecodes, add Safepoint
2740     maybe_add_safepoint(iter().get_dest());
2741     a = pop();
2742     b = pop();
<span class="line-modified">2743     c = _gvn.transform( new CmpPNode(b, a) );</span>
<span class="line-removed">2744     c = optimize_cmp_with_klass(c);</span>
<span class="line-removed">2745     do_if(btest, c);</span>
2746     break;
2747 
2748   case Bytecodes::_ifeq: btest = BoolTest::eq; goto handle_ifxx;
2749   case Bytecodes::_ifne: btest = BoolTest::ne; goto handle_ifxx;
2750   case Bytecodes::_iflt: btest = BoolTest::lt; goto handle_ifxx;
2751   case Bytecodes::_ifle: btest = BoolTest::le; goto handle_ifxx;
2752   case Bytecodes::_ifgt: btest = BoolTest::gt; goto handle_ifxx;
2753   case Bytecodes::_ifge: btest = BoolTest::ge; goto handle_ifxx;
2754   handle_ifxx:
2755     // If this is a backwards branch in the bytecodes, add Safepoint
2756     maybe_add_safepoint(iter().get_dest());
2757     a = _gvn.intcon(0);
2758     b = pop();
2759     c = _gvn.transform( new CmpINode(b, a) );
2760     do_if(btest, c);
2761     break;
2762 
2763   case Bytecodes::_if_icmpeq: btest = BoolTest::eq; goto handle_if_icmp;
2764   case Bytecodes::_if_icmpne: btest = BoolTest::ne; goto handle_if_icmp;
2765   case Bytecodes::_if_icmplt: btest = BoolTest::lt; goto handle_if_icmp;
</pre>
<hr />
<pre>
2780     break;
2781 
2782   case Bytecodes::_lookupswitch:
2783     do_lookupswitch();
2784     break;
2785 
2786   case Bytecodes::_invokestatic:
2787   case Bytecodes::_invokedynamic:
2788   case Bytecodes::_invokespecial:
2789   case Bytecodes::_invokevirtual:
2790   case Bytecodes::_invokeinterface:
2791     do_call();
2792     break;
2793   case Bytecodes::_checkcast:
2794     do_checkcast();
2795     break;
2796   case Bytecodes::_instanceof:
2797     do_instanceof();
2798     break;
2799   case Bytecodes::_anewarray:
<span class="line-modified">2800     do_anewarray();</span>
2801     break;
2802   case Bytecodes::_newarray:
2803     do_newarray((BasicType)iter().get_index());
2804     break;
2805   case Bytecodes::_multianewarray:
2806     do_multianewarray();
2807     break;
2808   case Bytecodes::_new:
2809     do_new();
2810     break;






2811 
2812   case Bytecodes::_jsr:
2813   case Bytecodes::_jsr_w:
2814     do_jsr();
2815     break;
2816 
2817   case Bytecodes::_ret:
2818     do_ret();
2819     break;
2820 
2821 
2822   case Bytecodes::_monitorenter:
2823     do_monitor_enter();
2824     break;
2825 
2826   case Bytecodes::_monitorexit:
2827     do_monitor_exit();
2828     break;
2829 
2830   case Bytecodes::_breakpoint:
</pre>
</td>
<td>
<hr />
<pre>
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;ci/ciMethodData.hpp&quot;
  27 #include &quot;classfile/systemDictionary.hpp&quot;
  28 #include &quot;classfile/vmSymbols.hpp&quot;
  29 #include &quot;compiler/compileLog.hpp&quot;
  30 #include &quot;interpreter/linkResolver.hpp&quot;
  31 #include &quot;memory/resourceArea.hpp&quot;
  32 #include &quot;memory/universe.hpp&quot;
  33 #include &quot;oops/oop.inline.hpp&quot;
  34 #include &quot;opto/addnode.hpp&quot;
  35 #include &quot;opto/castnode.hpp&quot;
  36 #include &quot;opto/convertnode.hpp&quot;
  37 #include &quot;opto/divnode.hpp&quot;
  38 #include &quot;opto/idealGraphPrinter.hpp&quot;
<span class="line-added">  39 #include &quot;opto/idealKit.hpp&quot;</span>
  40 #include &quot;opto/matcher.hpp&quot;
  41 #include &quot;opto/memnode.hpp&quot;
  42 #include &quot;opto/mulnode.hpp&quot;
  43 #include &quot;opto/opaquenode.hpp&quot;
  44 #include &quot;opto/parse.hpp&quot;
  45 #include &quot;opto/runtime.hpp&quot;
<span class="line-added">  46 #include &quot;opto/valuetypenode.hpp&quot;</span>
  47 #include &quot;runtime/deoptimization.hpp&quot;
  48 #include &quot;runtime/sharedRuntime.hpp&quot;
  49 
  50 #ifndef PRODUCT
  51 extern int explicit_null_checks_inserted,
  52            explicit_null_checks_elided;
  53 #endif
  54 
<span class="line-added">  55 Node* Parse::record_profile_for_speculation_at_array_load(Node* ld) {</span>
<span class="line-added">  56   // Feed unused profile data to type speculation</span>
<span class="line-added">  57   if (UseTypeSpeculation &amp;&amp; UseArrayLoadStoreProfile) {</span>
<span class="line-added">  58     ciKlass* array_type = NULL;</span>
<span class="line-added">  59     ciKlass* element_type = NULL;</span>
<span class="line-added">  60     ProfilePtrKind element_ptr = ProfileMaybeNull;</span>
<span class="line-added">  61     bool flat_array = true;</span>
<span class="line-added">  62     bool null_free_array = true;</span>
<span class="line-added">  63     method()-&gt;array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);</span>
<span class="line-added">  64     if (element_type != NULL || element_ptr != ProfileMaybeNull) {</span>
<span class="line-added">  65       ld = record_profile_for_speculation(ld, element_type, element_ptr);</span>
<span class="line-added">  66     }</span>
<span class="line-added">  67   }</span>
<span class="line-added">  68   return ld;</span>
<span class="line-added">  69 }</span>
<span class="line-added">  70 </span>
<span class="line-added">  71 </span>
  72 //---------------------------------array_load----------------------------------
  73 void Parse::array_load(BasicType bt) {
  74   const Type* elemtype = Type::TOP;

  75   Node* adr = array_addressing(bt, 0, elemtype);
  76   if (stopped())  return;     // guaranteed null or range check
  77 
<span class="line-modified">  78   Node* idx = pop();</span>
<span class="line-modified">  79   Node* ary = pop();</span>
<span class="line-added">  80 </span>
<span class="line-added">  81   // Handle value type arrays</span>
<span class="line-added">  82   const TypeOopPtr* elemptr = elemtype-&gt;make_oopptr();</span>
<span class="line-added">  83   const TypeAryPtr* ary_t = _gvn.type(ary)-&gt;is_aryptr();</span>
<span class="line-added">  84   if (elemtype-&gt;isa_valuetype() != NULL) {</span>
<span class="line-added">  85     C-&gt;set_flattened_accesses();</span>
<span class="line-added">  86     // Load from flattened value type array</span>
<span class="line-added">  87     Node* vt = ValueTypeNode::make_from_flattened(this, elemtype-&gt;value_klass(), ary, adr);</span>
<span class="line-added">  88     push(vt);</span>
<span class="line-added">  89     return;</span>
<span class="line-added">  90   } else if (elemptr != NULL &amp;&amp; elemptr-&gt;is_valuetypeptr() &amp;&amp; !elemptr-&gt;maybe_null()) {</span>
<span class="line-added">  91     // Load from non-flattened but flattenable value type array (elements can never be null)</span>
<span class="line-added">  92     bt = T_VALUETYPE;</span>
<span class="line-added">  93   } else if (!ary_t-&gt;is_not_flat()) {</span>
<span class="line-added">  94     // Cannot statically determine if array is flattened, emit runtime check</span>
<span class="line-added">  95     assert(ValueArrayFlatten &amp;&amp; is_reference_type(bt) &amp;&amp; elemptr-&gt;can_be_value_type() &amp;&amp; !ary_t-&gt;klass_is_exact() &amp;&amp; !ary_t-&gt;is_not_null_free() &amp;&amp;</span>
<span class="line-added">  96            (!elemptr-&gt;is_valuetypeptr() || elemptr-&gt;value_klass()-&gt;flatten_array()), &quot;array can&#39;t be flattened&quot;);</span>
<span class="line-added">  97     IdealKit ideal(this);</span>
<span class="line-added">  98     IdealVariable res(ideal);</span>
<span class="line-added">  99     ideal.declarations_done();</span>
<span class="line-added"> 100     ideal.if_then(is_non_flattened_array(ary)); {</span>
<span class="line-added"> 101       // non-flattened</span>
<span class="line-added"> 102       assert(ideal.ctrl()-&gt;in(0)-&gt;as_If()-&gt;is_non_flattened_array_check(&amp;_gvn), &quot;Should be found&quot;);</span>
<span class="line-added"> 103       sync_kit(ideal);</span>
<span class="line-added"> 104       const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);</span>
<span class="line-added"> 105       Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,</span>
<span class="line-added"> 106                                 IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);</span>
<span class="line-added"> 107       ideal.sync_kit(this);</span>
<span class="line-added"> 108       ideal.set(res, ld);</span>
<span class="line-added"> 109     } ideal.else_(); {</span>
<span class="line-added"> 110       // flattened</span>
<span class="line-added"> 111       sync_kit(ideal);</span>
<span class="line-added"> 112       if (elemptr-&gt;is_valuetypeptr()) {</span>
<span class="line-added"> 113         // Element type is known, cast and load from flattened representation</span>
<span class="line-added"> 114         ciValueKlass* vk = elemptr-&gt;value_klass();</span>
<span class="line-added"> 115         assert(vk-&gt;flatten_array() &amp;&amp; elemptr-&gt;maybe_null(), &quot;must be a flattenable and nullable array&quot;);</span>
<span class="line-added"> 116         ciArrayKlass* array_klass = ciArrayKlass::make(vk);</span>
<span class="line-added"> 117         const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)-&gt;isa_aryptr();</span>
<span class="line-added"> 118         Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, arytype));</span>
<span class="line-added"> 119         Node* casted_adr = array_element_address(cast, idx, T_VALUETYPE, ary_t-&gt;size(), control());</span>
<span class="line-added"> 120         // Re-execute flattened array load if buffering triggers deoptimization</span>
<span class="line-added"> 121         PreserveReexecuteState preexecs(this);</span>
<span class="line-added"> 122         jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added"> 123         inc_sp(2);</span>
<span class="line-added"> 124         Node* vt = ValueTypeNode::make_from_flattened(this, vk, cast, casted_adr)-&gt;buffer(this, false);</span>
<span class="line-added"> 125         ideal.set(res, vt);</span>
<span class="line-added"> 126         ideal.sync_kit(this);</span>
<span class="line-added"> 127       } else {</span>
<span class="line-added"> 128         // Element type is unknown, emit runtime call</span>
<span class="line-added"> 129         Node* kls = load_object_klass(ary);</span>
<span class="line-added"> 130         Node* k_adr = basic_plus_adr(kls, in_bytes(ArrayKlass::element_klass_offset()));</span>
<span class="line-added"> 131         Node* elem_klass = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS));</span>
<span class="line-added"> 132         Node* obj_size  = NULL;</span>
<span class="line-added"> 133         kill_dead_locals();</span>
<span class="line-added"> 134         // Re-execute flattened array load if buffering triggers deoptimization</span>
<span class="line-added"> 135         PreserveReexecuteState preexecs(this);</span>
<span class="line-added"> 136         jvms()-&gt;set_bci(_bci);</span>
<span class="line-added"> 137         jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added"> 138         inc_sp(2);</span>
<span class="line-added"> 139         Node* alloc_obj = new_instance(elem_klass, NULL, &amp;obj_size, /*deoptimize_on_exception=*/true);</span>
<span class="line-added"> 140 </span>
<span class="line-added"> 141         AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_obj, &amp;_gvn);</span>
<span class="line-added"> 142         assert(alloc-&gt;maybe_set_complete(&amp;_gvn), &quot;&quot;);</span>
<span class="line-added"> 143         alloc-&gt;initialization()-&gt;set_complete_with_arraycopy();</span>
<span class="line-added"> 144 </span>
<span class="line-added"> 145         // This membar keeps this access to an unknown flattened array</span>
<span class="line-added"> 146         // correctly ordered with other unknown and known flattened</span>
<span class="line-added"> 147         // array accesses.</span>
<span class="line-added"> 148         insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::VALUES));</span>
<span class="line-added"> 149 </span>
<span class="line-added"> 150         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();</span>
<span class="line-added"> 151         // Unknown value type might contain reference fields</span>
<span class="line-added"> 152         if (false &amp;&amp; !bs-&gt;array_copy_requires_gc_barriers(false, T_OBJECT, false, BarrierSetC2::Parsing)) {</span>
<span class="line-added"> 153           // FIXME 8230656 also merge changes from 8238759 in</span>
<span class="line-added"> 154           int base_off = sizeof(instanceOopDesc);</span>
<span class="line-added"> 155           Node* dst_base = basic_plus_adr(alloc_obj, base_off);</span>
<span class="line-added"> 156           Node* countx = obj_size;</span>
<span class="line-added"> 157           countx = _gvn.transform(new SubXNode(countx, MakeConX(base_off)));</span>
<span class="line-added"> 158           countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));</span>
<span class="line-added"> 159 </span>
<span class="line-added"> 160           assert(Klass::_lh_log2_element_size_shift == 0, &quot;use shift in place&quot;);</span>
<span class="line-added"> 161           Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));</span>
<span class="line-added"> 162           Node* elem_shift = make_load(NULL, lhp, TypeInt::INT, T_INT, MemNode::unordered);</span>
<span class="line-added"> 163           uint header = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE);</span>
<span class="line-added"> 164           Node* base  = basic_plus_adr(ary, header);</span>
<span class="line-added"> 165           idx = Compile::conv_I2X_index(&amp;_gvn, idx, TypeInt::POS, control());</span>
<span class="line-added"> 166           Node* scale = _gvn.transform(new LShiftXNode(idx, elem_shift));</span>
<span class="line-added"> 167           Node* adr = basic_plus_adr(ary, base, scale);</span>
<span class="line-added"> 168 </span>
<span class="line-added"> 169           access_clone(adr, dst_base, countx, false);</span>
<span class="line-added"> 170         } else {</span>
<span class="line-added"> 171           ideal.sync_kit(this);</span>
<span class="line-added"> 172           ideal.make_leaf_call(OptoRuntime::load_unknown_value_Type(),</span>
<span class="line-added"> 173                                CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_value),</span>
<span class="line-added"> 174                                &quot;load_unknown_value&quot;,</span>
<span class="line-added"> 175                                ary, idx, alloc_obj);</span>
<span class="line-added"> 176           sync_kit(ideal);</span>
<span class="line-added"> 177         }</span>
<span class="line-added"> 178 </span>
<span class="line-added"> 179         // This makes sure no other thread sees a partially initialized buffered value</span>
<span class="line-added"> 180         insert_mem_bar_volatile(Op_MemBarStoreStore, Compile::AliasIdxRaw, alloc-&gt;proj_out_or_null(AllocateNode::RawAddress));</span>
<span class="line-added"> 181 </span>
<span class="line-added"> 182         // Same as MemBarCPUOrder above: keep this unknown flattened</span>
<span class="line-added"> 183         // array access correctly ordered with other flattened array</span>
<span class="line-added"> 184         // access</span>
<span class="line-added"> 185         insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::VALUES));</span>
<span class="line-added"> 186 </span>
<span class="line-added"> 187         // Prevent any use of the newly allocated value before it is</span>
<span class="line-added"> 188         // fully initialized</span>
<span class="line-added"> 189         alloc_obj = new CastPPNode(alloc_obj, _gvn.type(alloc_obj), true);</span>
<span class="line-added"> 190         alloc_obj-&gt;set_req(0, control());</span>
<span class="line-added"> 191         alloc_obj = _gvn.transform(alloc_obj);</span>
<span class="line-added"> 192 </span>
<span class="line-added"> 193         const Type* unknown_value = elemptr-&gt;is_instptr()-&gt;cast_to_flat_array();</span>
<span class="line-added"> 194         alloc_obj = _gvn.transform(new CheckCastPPNode(control(), alloc_obj, unknown_value));</span>
<span class="line-added"> 195 </span>
<span class="line-added"> 196         ideal.sync_kit(this);</span>
<span class="line-added"> 197         ideal.set(res, alloc_obj);</span>
<span class="line-added"> 198       }</span>
<span class="line-added"> 199     } ideal.end_if();</span>
<span class="line-added"> 200     sync_kit(ideal);</span>
<span class="line-added"> 201     Node* ld = _gvn.transform(ideal.value(res));</span>
<span class="line-added"> 202     ld = record_profile_for_speculation_at_array_load(ld);</span>
<span class="line-added"> 203     push_node(bt, ld);</span>
<span class="line-added"> 204     return;</span>
<span class="line-added"> 205   }</span>
 206 
 207   if (elemtype == TypeInt::BOOL) {
 208     bt = T_BOOLEAN;
 209   }
 210   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);
<span class="line-modified"> 211   Node* ld = access_load_at(ary, adr, adr_type, elemtype, bt,</span>

 212                             IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);
<span class="line-modified"> 213   if (bt == T_VALUETYPE) {</span>
<span class="line-modified"> 214     // Loading a non-flattened (but flattenable) value type from an array</span>
<span class="line-modified"> 215     assert(!gvn().type(ld)-&gt;maybe_null(), &quot;value type array elements should never be null&quot;);</span>
<span class="line-modified"> 216     if (elemptr-&gt;value_klass()-&gt;is_scalarizable()) {</span>
<span class="line-added"> 217       ld = ValueTypeNode::make_from_oop(this, ld, elemptr-&gt;value_klass());</span>
<span class="line-added"> 218     }</span>
 219   }
<span class="line-added"> 220   if (!ld-&gt;is_ValueType()) {</span>
<span class="line-added"> 221     ld = record_profile_for_speculation_at_array_load(ld);</span>
<span class="line-added"> 222   }</span>
<span class="line-added"> 223 </span>
<span class="line-added"> 224   push_node(bt, ld);</span>
 225 }
 226 
 227 
 228 //--------------------------------array_store----------------------------------
 229 void Parse::array_store(BasicType bt) {
 230   const Type* elemtype = Type::TOP;
<span class="line-modified"> 231   Node* adr = array_addressing(bt, type2size[bt], elemtype);</span>

 232   if (stopped())  return;     // guaranteed null or range check
<span class="line-added"> 233   Node* cast_val = NULL;</span>
 234   if (bt == T_OBJECT) {
<span class="line-modified"> 235     cast_val = array_store_check();</span>
<span class="line-added"> 236     if (stopped()) return;</span>
 237   }
<span class="line-modified"> 238   Node* val = pop_node(bt); // Value to store</span>
<span class="line-modified"> 239   Node* idx = pop();        // Index in the array</span>
<span class="line-modified"> 240   Node* ary = pop();        // The array itself</span>
<span class="line-modified"> 241 </span>
<span class="line-modified"> 242   const TypeAryPtr* ary_t = _gvn.type(ary)-&gt;is_aryptr();</span>
<span class="line-modified"> 243   const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);</span>


 244 
 245   if (elemtype == TypeInt::BOOL) {
 246     bt = T_BOOLEAN;
<span class="line-modified"> 247   } else if (bt == T_OBJECT) {</span>
<span class="line-modified"> 248     elemtype = elemtype-&gt;make_oopptr();</span>
<span class="line-added"> 249     const Type* tval = _gvn.type(cast_val);</span>
<span class="line-added"> 250     // We may have lost type information for &#39;val&#39; here due to the casts</span>
<span class="line-added"> 251     // emitted by the array_store_check code (see JDK-6312651)</span>
<span class="line-added"> 252     // TODO Remove this code once JDK-6312651 is in.</span>
<span class="line-added"> 253     const Type* tval_init = _gvn.type(val);</span>
<span class="line-added"> 254     bool can_be_value_type = tval-&gt;isa_valuetype() || (tval != TypePtr::NULL_PTR &amp;&amp; tval_init-&gt;is_oopptr()-&gt;can_be_value_type() &amp;&amp; tval-&gt;is_oopptr()-&gt;can_be_value_type());</span>
<span class="line-added"> 255     bool not_flattenable = !can_be_value_type || ((tval_init-&gt;is_valuetypeptr() || tval_init-&gt;isa_valuetype()) &amp;&amp; !tval_init-&gt;value_klass()-&gt;flatten_array());</span>
<span class="line-added"> 256 </span>
<span class="line-added"> 257     if (!ary_t-&gt;is_not_null_free() &amp;&amp; !can_be_value_type &amp;&amp; (!tval-&gt;maybe_null() || !tval_init-&gt;maybe_null())) {</span>
<span class="line-added"> 258       // Storing a non-inline-type, mark array as not null-free.</span>
<span class="line-added"> 259       // This is only legal for non-null stores because the array_store_check passes for null.</span>
<span class="line-added"> 260       ary_t = ary_t-&gt;cast_to_not_null_free();</span>
<span class="line-added"> 261       Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));</span>
<span class="line-added"> 262       replace_in_map(ary, cast);</span>
<span class="line-added"> 263       ary = cast;</span>
<span class="line-added"> 264     } else if (!ary_t-&gt;is_not_flat() &amp;&amp; not_flattenable) {</span>
<span class="line-added"> 265       // Storing a non-flattenable value, mark array as not flat.</span>
<span class="line-added"> 266       ary_t = ary_t-&gt;cast_to_not_flat();</span>
<span class="line-added"> 267       if (tval != TypePtr::NULL_PTR) {</span>
<span class="line-added"> 268         // For NULL, this transformation is only valid after the null guard below</span>
<span class="line-added"> 269         Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));</span>
<span class="line-added"> 270         replace_in_map(ary, cast);</span>
<span class="line-added"> 271         ary = cast;</span>
<span class="line-added"> 272       }</span>
<span class="line-added"> 273     }</span>
 274 
<span class="line-modified"> 275     if (ary_t-&gt;elem()-&gt;isa_valuetype() != NULL) {</span>
<span class="line-added"> 276       // Store to flattened value type array</span>
<span class="line-added"> 277       C-&gt;set_flattened_accesses();</span>
<span class="line-added"> 278       if (!cast_val-&gt;is_ValueType()) {</span>
<span class="line-added"> 279         inc_sp(3);</span>
<span class="line-added"> 280         cast_val = null_check(cast_val);</span>
<span class="line-added"> 281         if (stopped()) return;</span>
<span class="line-added"> 282         dec_sp(3);</span>
<span class="line-added"> 283         cast_val = ValueTypeNode::make_from_oop(this, cast_val, ary_t-&gt;elem()-&gt;value_klass());</span>
<span class="line-added"> 284       }</span>
<span class="line-added"> 285       // Re-execute flattened array store if buffering triggers deoptimization</span>
<span class="line-added"> 286       PreserveReexecuteState preexecs(this);</span>
<span class="line-added"> 287       inc_sp(3);</span>
<span class="line-added"> 288       jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added"> 289       cast_val-&gt;as_ValueType()-&gt;store_flattened(this, ary, adr, NULL, 0, MO_UNORDERED | IN_HEAP | IS_ARRAY);</span>
<span class="line-added"> 290       return;</span>
<span class="line-added"> 291     } else if (elemtype-&gt;is_valuetypeptr() &amp;&amp; !elemtype-&gt;maybe_null()) {</span>
<span class="line-added"> 292       // Store to non-flattened but flattenable value type array (elements can never be null)</span>
<span class="line-added"> 293       if (!cast_val-&gt;is_ValueType() &amp;&amp; tval-&gt;maybe_null()) {</span>
<span class="line-added"> 294         inc_sp(3);</span>
<span class="line-added"> 295         cast_val = null_check(cast_val);</span>
<span class="line-added"> 296         if (stopped()) return;</span>
<span class="line-added"> 297         dec_sp(3);</span>
<span class="line-added"> 298       }</span>
<span class="line-added"> 299     } else if (!ary_t-&gt;is_not_flat()) {</span>
<span class="line-added"> 300       // Array might be flattened, emit runtime checks</span>
<span class="line-added"> 301       assert(ValueArrayFlatten &amp;&amp; !not_flattenable &amp;&amp; elemtype-&gt;is_oopptr()-&gt;can_be_value_type() &amp;&amp;</span>
<span class="line-added"> 302              !ary_t-&gt;klass_is_exact() &amp;&amp; !ary_t-&gt;is_not_null_free(), &quot;array can&#39;t be flattened&quot;);</span>
<span class="line-added"> 303       IdealKit ideal(this);</span>
<span class="line-added"> 304       ideal.if_then(is_non_flattened_array(ary)); {</span>
<span class="line-added"> 305         // non-flattened</span>
<span class="line-added"> 306         assert(ideal.ctrl()-&gt;in(0)-&gt;as_If()-&gt;is_non_flattened_array_check(&amp;_gvn), &quot;Should be found&quot;);</span>
<span class="line-added"> 307         sync_kit(ideal);</span>
<span class="line-added"> 308         gen_value_array_null_guard(ary, cast_val, 3);</span>
<span class="line-added"> 309         inc_sp(3);</span>
<span class="line-added"> 310         access_store_at(ary, adr, adr_type, cast_val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY, false);</span>
<span class="line-added"> 311         dec_sp(3);</span>
<span class="line-added"> 312         ideal.sync_kit(this);</span>
<span class="line-added"> 313       } ideal.else_(); {</span>
<span class="line-added"> 314         Node* val = cast_val;</span>
<span class="line-added"> 315         // flattened</span>
<span class="line-added"> 316         if (!val-&gt;is_ValueType() &amp;&amp; tval-&gt;maybe_null()) {</span>
<span class="line-added"> 317           // Add null check</span>
<span class="line-added"> 318           sync_kit(ideal);</span>
<span class="line-added"> 319           Node* null_ctl = top();</span>
<span class="line-added"> 320           val = null_check_oop(val, &amp;null_ctl);</span>
<span class="line-added"> 321           if (null_ctl != top()) {</span>
<span class="line-added"> 322             PreserveJVMState pjvms(this);</span>
<span class="line-added"> 323             inc_sp(3);</span>
<span class="line-added"> 324             set_control(null_ctl);</span>
<span class="line-added"> 325             uncommon_trap(Deoptimization::Reason_null_check, Deoptimization::Action_none);</span>
<span class="line-added"> 326             dec_sp(3);</span>
<span class="line-added"> 327           }</span>
<span class="line-added"> 328           ideal.sync_kit(this);</span>
<span class="line-added"> 329         }</span>
<span class="line-added"> 330         // Try to determine the value klass</span>
<span class="line-added"> 331         ciValueKlass* vk = NULL;</span>
<span class="line-added"> 332         if (tval-&gt;isa_valuetype() || tval-&gt;is_valuetypeptr()) {</span>
<span class="line-added"> 333           vk = tval-&gt;value_klass();</span>
<span class="line-added"> 334         } else if (tval_init-&gt;isa_valuetype() || tval_init-&gt;is_valuetypeptr()) {</span>
<span class="line-added"> 335           vk = tval_init-&gt;value_klass();</span>
<span class="line-added"> 336         } else if (elemtype-&gt;is_valuetypeptr()) {</span>
<span class="line-added"> 337           vk = elemtype-&gt;value_klass();</span>
<span class="line-added"> 338         }</span>
<span class="line-added"> 339         Node* casted_ary = ary;</span>
<span class="line-added"> 340         if (vk != NULL &amp;&amp; !stopped()) {</span>
<span class="line-added"> 341           // Element type is known, cast and store to flattened representation</span>
<span class="line-added"> 342           sync_kit(ideal);</span>
<span class="line-added"> 343           assert(vk-&gt;flatten_array() &amp;&amp; elemtype-&gt;maybe_null(), &quot;must be a flattenable and nullable array&quot;);</span>
<span class="line-added"> 344           ciArrayKlass* array_klass = ciArrayKlass::make(vk);</span>
<span class="line-added"> 345           const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)-&gt;isa_aryptr();</span>
<span class="line-added"> 346           casted_ary = _gvn.transform(new CheckCastPPNode(control(), casted_ary, arytype));</span>
<span class="line-added"> 347           Node* casted_adr = array_element_address(casted_ary, idx, T_OBJECT, arytype-&gt;size(), control());</span>
<span class="line-added"> 348           if (!val-&gt;is_ValueType()) {</span>
<span class="line-added"> 349             assert(!gvn().type(val)-&gt;maybe_null(), &quot;value type array elements should never be null&quot;);</span>
<span class="line-added"> 350             val = ValueTypeNode::make_from_oop(this, val, vk);</span>
<span class="line-added"> 351           }</span>
<span class="line-added"> 352           // Re-execute flattened array store if buffering triggers deoptimization</span>
<span class="line-added"> 353           PreserveReexecuteState preexecs(this);</span>
<span class="line-added"> 354           inc_sp(3);</span>
<span class="line-added"> 355           jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added"> 356           val-&gt;as_ValueType()-&gt;store_flattened(this, casted_ary, casted_adr, NULL, 0, MO_UNORDERED | IN_HEAP | IS_ARRAY);</span>
<span class="line-added"> 357           ideal.sync_kit(this);</span>
<span class="line-added"> 358         } else if (!ideal.ctrl()-&gt;is_top()) {</span>
<span class="line-added"> 359           // Element type is unknown, emit runtime call</span>
<span class="line-added"> 360           sync_kit(ideal);</span>
<span class="line-added"> 361 </span>
<span class="line-added"> 362           // This membar keeps this access to an unknown flattened</span>
<span class="line-added"> 363           // array correctly ordered with other unknown and known</span>
<span class="line-added"> 364           // flattened array accesses.</span>
<span class="line-added"> 365           insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::VALUES));</span>
<span class="line-added"> 366           ideal.sync_kit(this);</span>
<span class="line-added"> 367 </span>
<span class="line-added"> 368           ideal.make_leaf_call(OptoRuntime::store_unknown_value_Type(),</span>
<span class="line-added"> 369                                CAST_FROM_FN_PTR(address, OptoRuntime::store_unknown_value),</span>
<span class="line-added"> 370                                &quot;store_unknown_value&quot;,</span>
<span class="line-added"> 371                                val, casted_ary, idx);</span>
<span class="line-added"> 372 </span>
<span class="line-added"> 373           sync_kit(ideal);</span>
<span class="line-added"> 374           // Same as MemBarCPUOrder above: keep this unknown</span>
<span class="line-added"> 375           // flattened array access correctly ordered with other</span>
<span class="line-added"> 376           // flattened array accesses.</span>
<span class="line-added"> 377           insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::VALUES));</span>
<span class="line-added"> 378           ideal.sync_kit(this);</span>
<span class="line-added"> 379         }</span>
<span class="line-added"> 380       }</span>
<span class="line-added"> 381       ideal.end_if();</span>
<span class="line-added"> 382       sync_kit(ideal);</span>
<span class="line-added"> 383       return;</span>
<span class="line-added"> 384     } else if (!ary_t-&gt;is_not_null_free()) {</span>
<span class="line-added"> 385       // Array is not flattened but may be null free</span>
<span class="line-added"> 386       assert(elemtype-&gt;is_oopptr()-&gt;can_be_value_type() &amp;&amp; !ary_t-&gt;klass_is_exact(), &quot;array can&#39;t be null free&quot;);</span>
<span class="line-added"> 387       ary = gen_value_array_null_guard(ary, cast_val, 3, true);</span>
<span class="line-added"> 388     }</span>
<span class="line-added"> 389   }</span>
<span class="line-added"> 390   inc_sp(3);</span>
<span class="line-added"> 391   access_store_at(ary, adr, adr_type, val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY);</span>
<span class="line-added"> 392   dec_sp(3);</span>
 393 }
 394 
 395 
 396 //------------------------------array_addressing-------------------------------
 397 // Pull array and index from the stack.  Compute pointer-to-element.
 398 Node* Parse::array_addressing(BasicType type, int vals, const Type*&amp; elemtype) {
 399   Node *idx   = peek(0+vals);   // Get from stack without popping
 400   Node *ary   = peek(1+vals);   // in case of exception
 401 
 402   // Null check the array base, with correct stack contents
 403   ary = null_check(ary, T_ARRAY);
 404   // Compile-time detect of null-exception?
 405   if (stopped())  return top();
 406 
 407   const TypeAryPtr* arytype  = _gvn.type(ary)-&gt;is_aryptr();
 408   const TypeInt*    sizetype = arytype-&gt;size();
 409   elemtype = arytype-&gt;elem();
 410 
 411   if (UseUniqueSubclasses) {
 412     const Type* el = elemtype-&gt;make_ptr();
</pre>
<hr />
<pre>
 472       if (C-&gt;allow_range_check_smearing()) {
 473         // Do not use builtin_throw, since range checks are sometimes
 474         // made more stringent by an optimistic transformation.
 475         // This creates &quot;tentative&quot; range checks at this point,
 476         // which are not guaranteed to throw exceptions.
 477         // See IfNode::Ideal, is_range_check, adjust_check.
 478         uncommon_trap(Deoptimization::Reason_range_check,
 479                       Deoptimization::Action_make_not_entrant,
 480                       NULL, &quot;range_check&quot;);
 481       } else {
 482         // If we have already recompiled with the range-check-widening
 483         // heroic optimization turned off, then we must really be throwing
 484         // range check exceptions.
 485         builtin_throw(Deoptimization::Reason_range_check, idx);
 486       }
 487     }
 488   }
 489   // Check for always knowing you are throwing a range-check exception
 490   if (stopped())  return top();
 491 
<span class="line-added"> 492   // This could be an access to a value array. We can&#39;t tell if it&#39;s</span>
<span class="line-added"> 493   // flat or not. Speculating it&#39;s not leads to a much simpler graph</span>
<span class="line-added"> 494   // shape. Check profiling.</span>
<span class="line-added"> 495   // For aastore, by the time we&#39;re here, the array store check should</span>
<span class="line-added"> 496   // have already taken advantage of profiling to cast the array to an</span>
<span class="line-added"> 497   // exact type reported by profiling</span>
<span class="line-added"> 498   const TypeOopPtr* elemptr = elemtype-&gt;make_oopptr();</span>
<span class="line-added"> 499   if (elemtype-&gt;isa_valuetype() == NULL &amp;&amp;</span>
<span class="line-added"> 500       (elemptr == NULL || !elemptr-&gt;is_valuetypeptr() || elemptr-&gt;maybe_null()) &amp;&amp;</span>
<span class="line-added"> 501       !arytype-&gt;is_not_flat()) {</span>
<span class="line-added"> 502     assert(is_reference_type(type), &quot;Only references&quot;);</span>
<span class="line-added"> 503     // First check the speculative type</span>
<span class="line-added"> 504     Deoptimization::DeoptReason reason = Deoptimization::Reason_speculate_class_check;</span>
<span class="line-added"> 505     ciKlass* array_type = arytype-&gt;speculative_type();</span>
<span class="line-added"> 506     if (too_many_traps_or_recompiles(reason) || array_type == NULL) {</span>
<span class="line-added"> 507       // No speculative type, check profile data at this bci</span>
<span class="line-added"> 508       array_type = NULL;</span>
<span class="line-added"> 509       reason = Deoptimization::Reason_class_check;</span>
<span class="line-added"> 510       if (UseArrayLoadStoreProfile &amp;&amp; !too_many_traps_or_recompiles(reason)) {</span>
<span class="line-added"> 511         ciKlass* element_type = NULL;</span>
<span class="line-added"> 512         ProfilePtrKind element_ptr = ProfileMaybeNull;</span>
<span class="line-added"> 513         bool flat_array = true;</span>
<span class="line-added"> 514         bool null_free_array = true;</span>
<span class="line-added"> 515         method()-&gt;array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);</span>
<span class="line-added"> 516       }</span>
<span class="line-added"> 517     }</span>
<span class="line-added"> 518     if (array_type != NULL) {</span>
<span class="line-added"> 519       // Speculate that this array has the exact type reported by profile data</span>
<span class="line-added"> 520       Node* better_ary = NULL;</span>
<span class="line-added"> 521       Node* slow_ctl = type_check_receiver(ary, array_type, 1.0, &amp;better_ary);</span>
<span class="line-added"> 522       { PreserveJVMState pjvms(this);</span>
<span class="line-added"> 523         set_control(slow_ctl);</span>
<span class="line-added"> 524         uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);</span>
<span class="line-added"> 525       }</span>
<span class="line-added"> 526       replace_in_map(ary, better_ary);</span>
<span class="line-added"> 527       ary = better_ary;</span>
<span class="line-added"> 528       arytype  = _gvn.type(ary)-&gt;is_aryptr();</span>
<span class="line-added"> 529       elemtype = arytype-&gt;elem();</span>
<span class="line-added"> 530     }</span>
<span class="line-added"> 531   } else if (UseTypeSpeculation &amp;&amp; UseArrayLoadStoreProfile) {</span>
<span class="line-added"> 532     // No need to speculate: feed profile data at this bci for the</span>
<span class="line-added"> 533     // array to type speculation</span>
<span class="line-added"> 534     ciKlass* array_type = NULL;</span>
<span class="line-added"> 535     ciKlass* element_type = NULL;</span>
<span class="line-added"> 536     ProfilePtrKind element_ptr = ProfileMaybeNull;</span>
<span class="line-added"> 537     bool flat_array = true;</span>
<span class="line-added"> 538     bool null_free_array = true;</span>
<span class="line-added"> 539     method()-&gt;array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);</span>
<span class="line-added"> 540     if (array_type != NULL) {</span>
<span class="line-added"> 541       record_profile_for_speculation(ary, array_type, ProfileMaybeNull);</span>
<span class="line-added"> 542     }</span>
<span class="line-added"> 543   }</span>
<span class="line-added"> 544 </span>
<span class="line-added"> 545   // We have no exact array type from profile data. Check profile data</span>
<span class="line-added"> 546   // for a non null free or non flat array. Non null free implies non</span>
<span class="line-added"> 547   // flat so check this one first. Speculating on a non null free</span>
<span class="line-added"> 548   // array doesn&#39;t help aaload but could be profitable for a</span>
<span class="line-added"> 549   // subsequent aastore.</span>
<span class="line-added"> 550   elemptr = elemtype-&gt;make_oopptr();</span>
<span class="line-added"> 551   if (!arytype-&gt;is_not_null_free() &amp;&amp;</span>
<span class="line-added"> 552       elemtype-&gt;isa_valuetype() == NULL &amp;&amp;</span>
<span class="line-added"> 553       (elemptr == NULL || !elemptr-&gt;is_valuetypeptr()) &amp;&amp;</span>
<span class="line-added"> 554       UseArrayLoadStoreProfile) {</span>
<span class="line-added"> 555     assert(is_reference_type(type), &quot;&quot;);</span>
<span class="line-added"> 556     bool null_free_array = true;</span>
<span class="line-added"> 557     Deoptimization::DeoptReason reason = Deoptimization::Reason_none;</span>
<span class="line-added"> 558     if (arytype-&gt;speculative() != NULL &amp;&amp;</span>
<span class="line-added"> 559         arytype-&gt;speculative()-&gt;is_aryptr()-&gt;is_not_null_free() &amp;&amp;</span>
<span class="line-added"> 560         !too_many_traps_or_recompiles(Deoptimization::Reason_speculate_class_check)) {</span>
<span class="line-added"> 561       null_free_array = false;</span>
<span class="line-added"> 562       reason = Deoptimization::Reason_speculate_class_check;</span>
<span class="line-added"> 563     } else if (!too_many_traps_or_recompiles(Deoptimization::Reason_class_check)) {</span>
<span class="line-added"> 564       ciKlass* array_type = NULL;</span>
<span class="line-added"> 565       ciKlass* element_type = NULL;</span>
<span class="line-added"> 566       ProfilePtrKind element_ptr = ProfileMaybeNull;</span>
<span class="line-added"> 567       bool flat_array = true;</span>
<span class="line-added"> 568       method()-&gt;array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);</span>
<span class="line-added"> 569       reason = Deoptimization::Reason_class_check;</span>
<span class="line-added"> 570     }</span>
<span class="line-added"> 571     if (!null_free_array) {</span>
<span class="line-added"> 572       { // Deoptimize if null-free array</span>
<span class="line-added"> 573         BuildCutout unless(this, is_nullable_array(ary), PROB_MAX);</span>
<span class="line-added"> 574         uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);</span>
<span class="line-added"> 575       }</span>
<span class="line-added"> 576       Node* better_ary = _gvn.transform(new CheckCastPPNode(control(), ary, arytype-&gt;cast_to_not_null_free()));</span>
<span class="line-added"> 577       replace_in_map(ary, better_ary);</span>
<span class="line-added"> 578       ary = better_ary;</span>
<span class="line-added"> 579       arytype = _gvn.type(ary)-&gt;is_aryptr();</span>
<span class="line-added"> 580     }</span>
<span class="line-added"> 581   }</span>
<span class="line-added"> 582 </span>
<span class="line-added"> 583   if (!arytype-&gt;is_not_flat() &amp;&amp; elemtype-&gt;isa_valuetype() == NULL) {</span>
<span class="line-added"> 584     assert(is_reference_type(type), &quot;&quot;);</span>
<span class="line-added"> 585     bool flat_array = true;</span>
<span class="line-added"> 586     Deoptimization::DeoptReason reason = Deoptimization::Reason_none;</span>
<span class="line-added"> 587     if (arytype-&gt;speculative() != NULL &amp;&amp;</span>
<span class="line-added"> 588         arytype-&gt;speculative()-&gt;is_aryptr()-&gt;is_not_flat() &amp;&amp;</span>
<span class="line-added"> 589         !too_many_traps_or_recompiles(Deoptimization::Reason_speculate_class_check)) {</span>
<span class="line-added"> 590       flat_array = false;</span>
<span class="line-added"> 591       reason = Deoptimization::Reason_speculate_class_check;</span>
<span class="line-added"> 592     } else if (UseArrayLoadStoreProfile &amp;&amp; !too_many_traps_or_recompiles(reason)) {</span>
<span class="line-added"> 593       ciKlass* array_type = NULL;</span>
<span class="line-added"> 594       ciKlass* element_type = NULL;</span>
<span class="line-added"> 595       ProfilePtrKind element_ptr = ProfileMaybeNull;</span>
<span class="line-added"> 596       bool null_free_array = true;</span>
<span class="line-added"> 597       method()-&gt;array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);</span>
<span class="line-added"> 598       reason = Deoptimization::Reason_class_check;</span>
<span class="line-added"> 599     }</span>
<span class="line-added"> 600     if (!flat_array) {</span>
<span class="line-added"> 601       { // Deoptimize if flat array</span>
<span class="line-added"> 602         BuildCutout unless(this, is_non_flattened_array(ary), PROB_MAX);</span>
<span class="line-added"> 603         uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);</span>
<span class="line-added"> 604       }</span>
<span class="line-added"> 605       Node* better_ary = _gvn.transform(new CheckCastPPNode(control(), ary, arytype-&gt;cast_to_not_flat()));</span>
<span class="line-added"> 606       replace_in_map(ary, better_ary);</span>
<span class="line-added"> 607       ary = better_ary;</span>
<span class="line-added"> 608       arytype = _gvn.type(ary)-&gt;is_aryptr();</span>
<span class="line-added"> 609     }</span>
<span class="line-added"> 610   }</span>
<span class="line-added"> 611 </span>
 612   // Make array address computation control dependent to prevent it
 613   // from floating above the range check during loop optimizations.
 614   Node* ptr = array_element_address(ary, idx, type, sizetype, control());
 615   assert(ptr != top(), &quot;top should go hand-in-hand with stopped&quot;);
 616 
 617   return ptr;
 618 }
 619 
 620 
 621 // returns IfNode
 622 IfNode* Parse::jump_if_fork_int(Node* a, Node* b, BoolTest::mask mask, float prob, float cnt) {
 623   Node   *cmp = _gvn.transform(new CmpINode(a, b)); // two cases: shiftcount &gt; 32 and shiftcount &lt;= 32
 624   Node   *tst = _gvn.transform(new BoolNode(cmp, mask));
 625   IfNode *iff = create_and_map_if(control(), tst, prob, cnt);
 626   return iff;
 627 }
 628 
 629 // return Region node
 630 Node* Parse::jump_if_join(Node* iffalse, Node* iftrue) {
 631   Node *region  = new RegionNode(3); // 2 results
</pre>
<hr />
<pre>
1880 
1881   // Sanity check the probability value
1882   assert(prob &gt; 0.0f,&quot;Bad probability in Parser&quot;);
1883  // Need xform to put node in hash table
1884   IfNode *iff = create_and_xform_if( control(), tst, prob, cnt );
1885   assert(iff-&gt;_prob &gt; 0.0f,&quot;Optimizer made bad probability in parser&quot;);
1886   // True branch
1887   { PreserveJVMState pjvms(this);
1888     Node* iftrue  = _gvn.transform( new IfTrueNode (iff) );
1889     set_control(iftrue);
1890 
1891     if (stopped()) {            // Path is dead?
1892       NOT_PRODUCT(explicit_null_checks_elided++);
1893       if (C-&gt;eliminate_boxing()) {
1894         // Mark the successor block as parsed
1895         branch_block-&gt;next_path_num();
1896       }
1897     } else {                    // Path is live.
1898       // Update method data
1899       profile_taken_branch(target_bci);
<span class="line-modified">1900       adjust_map_after_if(btest, c, prob, branch_block);</span>
1901       if (!stopped()) {
1902         merge(target_bci);
1903       }
1904     }
1905   }
1906 
1907   // False branch
1908   Node* iffalse = _gvn.transform( new IfFalseNode(iff) );
1909   set_control(iffalse);
1910 
1911   if (stopped()) {              // Path is dead?
1912     NOT_PRODUCT(explicit_null_checks_elided++);
1913     if (C-&gt;eliminate_boxing()) {
1914       // Mark the successor block as parsed
1915       next_block-&gt;next_path_num();
1916     }
1917   } else  {                     // Path is live.
1918     // Update method data
1919     profile_not_taken_branch();
<span class="line-modified">1920     adjust_map_after_if(BoolTest(btest).negate(), c, 1.0-prob, next_block);</span>

1921   }
1922 }
1923 
1924 //------------------------------------do_if------------------------------------
<span class="line-modified">1925 void Parse::do_if(BoolTest::mask btest, Node* c, bool new_path, Node** ctrl_taken) {</span>
1926   int target_bci = iter().get_dest();
1927 
1928   Block* branch_block = successor_for_bci(target_bci);
1929   Block* next_block   = successor_for_bci(iter().next_bci());
1930 
1931   float cnt;
1932   float prob = branch_prediction(cnt, btest, target_bci, c);
1933   float untaken_prob = 1.0 - prob;
1934 
1935   if (prob == PROB_UNKNOWN) {
1936     if (PrintOpto &amp;&amp; Verbose) {
1937       tty-&gt;print_cr(&quot;Never-taken edge stops compilation at bci %d&quot;, bci());
1938     }
1939     repush_if_args(); // to gather stats on loop
1940     // We need to mark this branch as taken so that if we recompile we will
1941     // see that it is possible. In the tiered system the interpreter doesn&#39;t
1942     // do profiling and by the time we get to the lower tier from the interpreter
1943     // the path may be cold again. Make sure it doesn&#39;t look untaken
1944     profile_taken_branch(target_bci, !ProfileInterpreter);
1945     uncommon_trap(Deoptimization::Reason_unreached,
</pre>
<hr />
<pre>
1994   }
1995 
1996   // Generate real control flow
1997   float true_prob = (taken_if_true ? prob : untaken_prob);
1998   IfNode* iff = create_and_map_if(control(), tst, true_prob, cnt);
1999   assert(iff-&gt;_prob &gt; 0.0f,&quot;Optimizer made bad probability in parser&quot;);
2000   Node* taken_branch   = new IfTrueNode(iff);
2001   Node* untaken_branch = new IfFalseNode(iff);
2002   if (!taken_if_true) {  // Finish conversion to canonical form
2003     Node* tmp      = taken_branch;
2004     taken_branch   = untaken_branch;
2005     untaken_branch = tmp;
2006   }
2007 
2008   // Branch is taken:
2009   { PreserveJVMState pjvms(this);
2010     taken_branch = _gvn.transform(taken_branch);
2011     set_control(taken_branch);
2012 
2013     if (stopped()) {
<span class="line-modified">2014       if (C-&gt;eliminate_boxing() &amp;&amp; !new_path) {</span>
<span class="line-modified">2015         // Mark the successor block as parsed (if we haven&#39;t created a new path)</span>
2016         branch_block-&gt;next_path_num();
2017       }
2018     } else {
2019       // Update method data
2020       profile_taken_branch(target_bci);
<span class="line-modified">2021       adjust_map_after_if(taken_btest, c, prob, branch_block);</span>
2022       if (!stopped()) {
<span class="line-modified">2023         if (new_path) {</span>
<span class="line-added">2024           // Merge by using a new path</span>
<span class="line-added">2025           merge_new_path(target_bci);</span>
<span class="line-added">2026         } else if (ctrl_taken != NULL) {</span>
<span class="line-added">2027           // Don&#39;t merge but save taken branch to be wired by caller</span>
<span class="line-added">2028           *ctrl_taken = control();</span>
<span class="line-added">2029         } else {</span>
<span class="line-added">2030           merge(target_bci);</span>
<span class="line-added">2031         }</span>
2032       }
2033     }
2034   }
2035 
2036   untaken_branch = _gvn.transform(untaken_branch);
2037   set_control(untaken_branch);
2038 
2039   // Branch not taken.
<span class="line-modified">2040   if (stopped() &amp;&amp; ctrl_taken == NULL) {</span>
2041     if (C-&gt;eliminate_boxing()) {
<span class="line-modified">2042       // Mark the successor block as parsed (if caller does not re-wire control flow)</span>
2043       next_block-&gt;next_path_num();
2044     }
2045   } else {
2046     // Update method data
2047     profile_not_taken_branch();
<span class="line-modified">2048     adjust_map_after_if(untaken_btest, c, untaken_prob, next_block);</span>
<span class="line-modified">2049   }</span>
<span class="line-added">2050 }</span>
<span class="line-added">2051 </span>
<span class="line-added">2052 void Parse::do_acmp(BoolTest::mask btest, Node* a, Node* b) {</span>
<span class="line-added">2053   ciMethod* subst_method = ciEnv::current()-&gt;ValueBootstrapMethods_klass()-&gt;find_method(ciSymbol::isSubstitutable_name(), ciSymbol::object_object_boolean_signature());</span>
<span class="line-added">2054   // If current method is ValueBootstrapMethods::isSubstitutable(),</span>
<span class="line-added">2055   // compile the acmp as a regular pointer comparison otherwise we</span>
<span class="line-added">2056   // could call ValueBootstrapMethods::isSubstitutable() back</span>
<span class="line-added">2057   if (!EnableValhalla || (method() == subst_method)) {</span>
<span class="line-added">2058     Node* cmp = CmpP(a, b);</span>
<span class="line-added">2059     cmp = optimize_cmp_with_klass(cmp);</span>
<span class="line-added">2060     do_if(btest, cmp);</span>
<span class="line-added">2061     return;</span>
<span class="line-added">2062   }</span>
<span class="line-added">2063 </span>
<span class="line-added">2064   // Allocate value type operands and re-execute on deoptimization</span>
<span class="line-added">2065   if (a-&gt;is_ValueType()) {</span>
<span class="line-added">2066     PreserveReexecuteState preexecs(this);</span>
<span class="line-added">2067     inc_sp(2);</span>
<span class="line-added">2068     jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added">2069     a = a-&gt;as_ValueType()-&gt;buffer(this)-&gt;get_oop();</span>
<span class="line-added">2070   }</span>
<span class="line-added">2071   if (b-&gt;is_ValueType()) {</span>
<span class="line-added">2072     PreserveReexecuteState preexecs(this);</span>
<span class="line-added">2073     inc_sp(2);</span>
<span class="line-added">2074     jvms()-&gt;set_should_reexecute(true);</span>
<span class="line-added">2075     b = b-&gt;as_ValueType()-&gt;buffer(this)-&gt;get_oop();</span>
<span class="line-added">2076   }</span>
<span class="line-added">2077 </span>
<span class="line-added">2078   // First, do a normal pointer comparison</span>
<span class="line-added">2079   const TypeOopPtr* ta = _gvn.type(a)-&gt;isa_oopptr();</span>
<span class="line-added">2080   const TypeOopPtr* tb = _gvn.type(b)-&gt;isa_oopptr();</span>
<span class="line-added">2081   Node* cmp = CmpP(a, b);</span>
<span class="line-added">2082   cmp = optimize_cmp_with_klass(cmp);</span>
<span class="line-added">2083   if (ta == NULL || !ta-&gt;can_be_value_type() ||</span>
<span class="line-added">2084       tb == NULL || !tb-&gt;can_be_value_type()) {</span>
<span class="line-added">2085     // This is sufficient, if one of the operands can&#39;t be a value type</span>
<span class="line-added">2086     do_if(btest, cmp);</span>
<span class="line-added">2087     return;</span>
<span class="line-added">2088   }</span>
<span class="line-added">2089   Node* eq_region = NULL;</span>
<span class="line-added">2090   if (btest == BoolTest::eq) {</span>
<span class="line-added">2091     do_if(btest, cmp, true);</span>
<span class="line-added">2092     if (stopped()) {</span>
<span class="line-added">2093       return;</span>
<span class="line-added">2094     }</span>
<span class="line-added">2095   } else {</span>
<span class="line-added">2096     assert(btest == BoolTest::ne, &quot;only eq or ne&quot;);</span>
<span class="line-added">2097     Node* is_not_equal = NULL;</span>
<span class="line-added">2098     eq_region = new RegionNode(3);</span>
<span class="line-added">2099     {</span>
<span class="line-added">2100       PreserveJVMState pjvms(this);</span>
<span class="line-added">2101       do_if(btest, cmp, false, &amp;is_not_equal);</span>
<span class="line-added">2102       if (!stopped()) {</span>
<span class="line-added">2103         eq_region-&gt;init_req(1, control());</span>
<span class="line-added">2104       }</span>
<span class="line-added">2105     }</span>
<span class="line-added">2106     if (is_not_equal == NULL || is_not_equal-&gt;is_top()) {</span>
<span class="line-added">2107       record_for_igvn(eq_region);</span>
<span class="line-added">2108       set_control(_gvn.transform(eq_region));</span>
<span class="line-added">2109       return;</span>
<span class="line-added">2110     }</span>
<span class="line-added">2111     set_control(is_not_equal);</span>
<span class="line-added">2112   }</span>
<span class="line-added">2113 </span>
<span class="line-added">2114   // Pointers are not equal, check if first operand is non-null</span>
<span class="line-added">2115   Node* ne_region = new RegionNode(6);</span>
<span class="line-added">2116   inc_sp(2);</span>
<span class="line-added">2117   Node* null_ctl = top();</span>
<span class="line-added">2118   Node* not_null_a = null_check_oop(a, &amp;null_ctl, !too_many_traps(Deoptimization::Reason_null_check), false, false);</span>
<span class="line-added">2119   dec_sp(2);</span>
<span class="line-added">2120   ne_region-&gt;init_req(1, null_ctl);</span>
<span class="line-added">2121   if (stopped()) {</span>
<span class="line-added">2122     record_for_igvn(ne_region);</span>
<span class="line-added">2123     set_control(_gvn.transform(ne_region));</span>
<span class="line-added">2124     if (btest == BoolTest::ne) {</span>
<span class="line-added">2125       {</span>
<span class="line-added">2126         PreserveJVMState pjvms(this);</span>
<span class="line-added">2127         int target_bci = iter().get_dest();</span>
<span class="line-added">2128         merge(target_bci);</span>
<span class="line-added">2129       }</span>
<span class="line-added">2130       record_for_igvn(eq_region);</span>
<span class="line-added">2131       set_control(_gvn.transform(eq_region));</span>
<span class="line-added">2132     }</span>
<span class="line-added">2133     return;</span>
<span class="line-added">2134   }</span>
<span class="line-added">2135 </span>
<span class="line-added">2136   // First operand is non-null, check if it is a value type</span>
<span class="line-added">2137   Node* is_value = is_value_type(not_null_a);</span>
<span class="line-added">2138   IfNode* is_value_iff = create_and_map_if(control(), is_value, PROB_FAIR, COUNT_UNKNOWN);</span>
<span class="line-added">2139   Node* not_value = _gvn.transform(new IfFalseNode(is_value_iff));</span>
<span class="line-added">2140   ne_region-&gt;init_req(2, not_value);</span>
<span class="line-added">2141   set_control(_gvn.transform(new IfTrueNode(is_value_iff)));</span>
<span class="line-added">2142 </span>
<span class="line-added">2143   // The first operand is a value type, check if the second operand is non-null</span>
<span class="line-added">2144   inc_sp(2);</span>
<span class="line-added">2145   null_ctl = top();</span>
<span class="line-added">2146   Node* not_null_b = null_check_oop(b, &amp;null_ctl, !too_many_traps(Deoptimization::Reason_null_check), false, false);</span>
<span class="line-added">2147   dec_sp(2);</span>
<span class="line-added">2148   ne_region-&gt;init_req(3, null_ctl);</span>
<span class="line-added">2149   if (stopped()) {</span>
<span class="line-added">2150     record_for_igvn(ne_region);</span>
<span class="line-added">2151     set_control(_gvn.transform(ne_region));</span>
<span class="line-added">2152     if (btest == BoolTest::ne) {</span>
<span class="line-added">2153       {</span>
<span class="line-added">2154         PreserveJVMState pjvms(this);</span>
<span class="line-added">2155         int target_bci = iter().get_dest();</span>
<span class="line-added">2156         merge(target_bci);</span>
<span class="line-added">2157       }</span>
<span class="line-added">2158       record_for_igvn(eq_region);</span>
<span class="line-added">2159       set_control(_gvn.transform(eq_region));</span>
<span class="line-added">2160     }</span>
<span class="line-added">2161     return;</span>
<span class="line-added">2162   }</span>
<span class="line-added">2163 </span>
<span class="line-added">2164   // Check if both operands are of the same class.</span>
<span class="line-added">2165   Node* kls_a = load_object_klass(not_null_a);</span>
<span class="line-added">2166   Node* kls_b = load_object_klass(not_null_b);</span>
<span class="line-added">2167   Node* kls_cmp = CmpP(kls_a, kls_b);</span>
<span class="line-added">2168   Node* kls_bol = _gvn.transform(new BoolNode(kls_cmp, BoolTest::ne));</span>
<span class="line-added">2169   IfNode* kls_iff = create_and_map_if(control(), kls_bol, PROB_FAIR, COUNT_UNKNOWN);</span>
<span class="line-added">2170   Node* kls_ne = _gvn.transform(new IfTrueNode(kls_iff));</span>
<span class="line-added">2171   set_control(_gvn.transform(new IfFalseNode(kls_iff)));</span>
<span class="line-added">2172   ne_region-&gt;init_req(4, kls_ne);</span>
<span class="line-added">2173 </span>
<span class="line-added">2174   if (stopped()) {</span>
<span class="line-added">2175     record_for_igvn(ne_region);</span>
<span class="line-added">2176     set_control(_gvn.transform(ne_region));</span>
<span class="line-added">2177     if (btest == BoolTest::ne) {</span>
<span class="line-added">2178       {</span>
<span class="line-added">2179         PreserveJVMState pjvms(this);</span>
<span class="line-added">2180         int target_bci = iter().get_dest();</span>
<span class="line-added">2181         merge(target_bci);</span>
<span class="line-added">2182       }</span>
<span class="line-added">2183       record_for_igvn(eq_region);</span>
<span class="line-added">2184       set_control(_gvn.transform(eq_region));</span>
<span class="line-added">2185     }</span>
<span class="line-added">2186     return;</span>
<span class="line-added">2187   }</span>
<span class="line-added">2188 </span>
<span class="line-added">2189   // Both operands are values types of the same class, we need to perform a</span>
<span class="line-added">2190   // substitutability test. Delegate to ValueBootstrapMethods::isSubstitutable().</span>
<span class="line-added">2191   Node* ne_io_phi = PhiNode::make(ne_region, i_o());</span>
<span class="line-added">2192   Node* mem = reset_memory();</span>
<span class="line-added">2193   Node* ne_mem_phi = PhiNode::make(ne_region, mem);</span>
<span class="line-added">2194 </span>
<span class="line-added">2195   Node* eq_io_phi = NULL;</span>
<span class="line-added">2196   Node* eq_mem_phi = NULL;</span>
<span class="line-added">2197   if (eq_region != NULL) {</span>
<span class="line-added">2198     eq_io_phi = PhiNode::make(eq_region, i_o());</span>
<span class="line-added">2199     eq_mem_phi = PhiNode::make(eq_region, mem);</span>
<span class="line-added">2200   }</span>
<span class="line-added">2201 </span>
<span class="line-added">2202   set_all_memory(mem);</span>
<span class="line-added">2203 </span>
<span class="line-added">2204   kill_dead_locals();</span>
<span class="line-added">2205   CallStaticJavaNode *call = new CallStaticJavaNode(C, TypeFunc::make(subst_method), SharedRuntime::get_resolve_static_call_stub(), subst_method, bci());</span>
<span class="line-added">2206   call-&gt;set_override_symbolic_info(true);</span>
<span class="line-added">2207   call-&gt;init_req(TypeFunc::Parms, not_null_a);</span>
<span class="line-added">2208   call-&gt;init_req(TypeFunc::Parms+1, not_null_b);</span>
<span class="line-added">2209   inc_sp(2);</span>
<span class="line-added">2210   set_edges_for_java_call(call, false, false);</span>
<span class="line-added">2211   Node* ret = set_results_for_java_call(call, false, true);</span>
<span class="line-added">2212   dec_sp(2);</span>
<span class="line-added">2213 </span>
<span class="line-added">2214   // Test the return value of ValueBootstrapMethods::isSubstitutable()</span>
<span class="line-added">2215   Node* subst_cmp = _gvn.transform(new CmpINode(ret, intcon(1)));</span>
<span class="line-added">2216   Node* ctl = C-&gt;top();</span>
<span class="line-added">2217   if (btest == BoolTest::eq) {</span>
<span class="line-added">2218     PreserveJVMState pjvms(this);</span>
<span class="line-added">2219     do_if(btest, subst_cmp);</span>
<span class="line-added">2220     if (!stopped()) {</span>
<span class="line-added">2221       ctl = control();</span>
<span class="line-added">2222     }</span>
<span class="line-added">2223   } else {</span>
<span class="line-added">2224     assert(btest == BoolTest::ne, &quot;only eq or ne&quot;);</span>
<span class="line-added">2225     PreserveJVMState pjvms(this);</span>
<span class="line-added">2226     do_if(btest, subst_cmp, false, &amp;ctl);</span>
<span class="line-added">2227     if (!stopped()) {</span>
<span class="line-added">2228       eq_region-&gt;init_req(2, control());</span>
<span class="line-added">2229       eq_io_phi-&gt;init_req(2, i_o());</span>
<span class="line-added">2230       eq_mem_phi-&gt;init_req(2, reset_memory());</span>
<span class="line-added">2231     }</span>
<span class="line-added">2232   }</span>
<span class="line-added">2233   ne_region-&gt;init_req(5, ctl);</span>
<span class="line-added">2234   ne_io_phi-&gt;init_req(5, i_o());</span>
<span class="line-added">2235   ne_mem_phi-&gt;init_req(5, reset_memory());</span>
<span class="line-added">2236 </span>
<span class="line-added">2237   record_for_igvn(ne_region);</span>
<span class="line-added">2238   set_control(_gvn.transform(ne_region));</span>
<span class="line-added">2239   set_i_o(_gvn.transform(ne_io_phi));</span>
<span class="line-added">2240   set_all_memory(_gvn.transform(ne_mem_phi));</span>
<span class="line-added">2241 </span>
<span class="line-added">2242   if (btest == BoolTest::ne) {</span>
<span class="line-added">2243     {</span>
<span class="line-added">2244       PreserveJVMState pjvms(this);</span>
<span class="line-added">2245       int target_bci = iter().get_dest();</span>
<span class="line-added">2246       merge(target_bci);</span>
<span class="line-added">2247     }</span>
<span class="line-added">2248 </span>
<span class="line-added">2249     record_for_igvn(eq_region);</span>
<span class="line-added">2250     set_control(_gvn.transform(eq_region));</span>
<span class="line-added">2251     set_i_o(_gvn.transform(eq_io_phi));</span>
<span class="line-added">2252     set_all_memory(_gvn.transform(eq_mem_phi));</span>
2253   }
2254 }
2255 
2256 bool Parse::path_is_suitable_for_uncommon_trap(float prob) const {
2257   // Don&#39;t want to speculate on uncommon traps when running with -Xcomp
2258   if (!UseInterpreter) {
2259     return false;
2260   }
2261   return (seems_never_taken(prob) &amp;&amp; seems_stable_comparison());
2262 }
2263 
2264 void Parse::maybe_add_predicate_after_if(Block* path) {
2265   if (path-&gt;is_SEL_head() &amp;&amp; path-&gt;preds_parsed() == 0) {
2266     // Add predicates at bci of if dominating the loop so traps can be
2267     // recorded on the if&#39;s profile data
2268     int bc_depth = repush_if_args();
2269     add_empty_predicates();
2270     dec_sp(bc_depth);
2271     path-&gt;set_has_predicates();
2272   }
2273 }
2274 
2275 
2276 //----------------------------adjust_map_after_if------------------------------
2277 // Adjust the JVM state to reflect the result of taking this path.
2278 // Basically, it means inspecting the CmpNode controlling this
2279 // branch, seeing how it constrains a tested value, and then
2280 // deciding if it&#39;s worth our while to encode this constraint
2281 // as graph nodes in the current abstract interpretation map.
<span class="line-modified">2282 void Parse::adjust_map_after_if(BoolTest::mask btest, Node* c, float prob, Block* path) {</span>

2283   if (!c-&gt;is_Cmp()) {
2284     maybe_add_predicate_after_if(path);
2285     return;
2286   }
2287 
2288   if (stopped() || btest == BoolTest::illegal) {
2289     return;                             // nothing to do
2290   }
2291 
2292   bool is_fallthrough = (path == successor_for_bci(iter().next_bci()));
2293 
2294   if (path_is_suitable_for_uncommon_trap(prob)) {
2295     repush_if_args();
2296     uncommon_trap(Deoptimization::Reason_unstable_if,
2297                   Deoptimization::Action_reinterpret,
2298                   NULL,
2299                   (is_fallthrough ? &quot;taken always&quot; : &quot;taken never&quot;));
2300     return;
2301   }
2302 
</pre>
<hr />
<pre>
2472   if (c-&gt;Opcode() == Op_CmpP &amp;&amp;
2473       (c-&gt;in(1)-&gt;Opcode() == Op_LoadKlass || c-&gt;in(1)-&gt;Opcode() == Op_DecodeNKlass) &amp;&amp;
2474       c-&gt;in(2)-&gt;is_Con()) {
2475     Node* load_klass = NULL;
2476     Node* decode = NULL;
2477     if (c-&gt;in(1)-&gt;Opcode() == Op_DecodeNKlass) {
2478       decode = c-&gt;in(1);
2479       load_klass = c-&gt;in(1)-&gt;in(1);
2480     } else {
2481       load_klass = c-&gt;in(1);
2482     }
2483     if (load_klass-&gt;in(2)-&gt;is_AddP()) {
2484       Node* addp = load_klass-&gt;in(2);
2485       Node* obj = addp-&gt;in(AddPNode::Address);
2486       const TypeOopPtr* obj_type = _gvn.type(obj)-&gt;is_oopptr();
2487       if (obj_type-&gt;speculative_type_not_null() != NULL) {
2488         ciKlass* k = obj_type-&gt;speculative_type();
2489         inc_sp(2);
2490         obj = maybe_cast_profiled_obj(obj, k);
2491         dec_sp(2);
<span class="line-added">2492         if (obj-&gt;is_ValueType()) {</span>
<span class="line-added">2493           assert(obj-&gt;as_ValueType()-&gt;is_allocated(&amp;_gvn), &quot;must be allocated&quot;);</span>
<span class="line-added">2494           obj = obj-&gt;as_ValueType()-&gt;get_oop();</span>
<span class="line-added">2495         }</span>
2496         // Make the CmpP use the casted obj
2497         addp = basic_plus_adr(obj, addp-&gt;in(AddPNode::Offset));
2498         load_klass = load_klass-&gt;clone();
2499         load_klass-&gt;set_req(2, addp);
2500         load_klass = _gvn.transform(load_klass);
2501         if (decode != NULL) {
2502           decode = decode-&gt;clone();
2503           decode-&gt;set_req(1, load_klass);
2504           load_klass = _gvn.transform(decode);
2505         }
2506         c = c-&gt;clone();
2507         c-&gt;set_req(1, load_klass);
2508         c = _gvn.transform(c);
2509       }
2510     }
2511   }
2512   return c;
2513 }
2514 
2515 //------------------------------do_one_bytecode--------------------------------
</pre>
<hr />
<pre>
3323     // See if we can get some profile data and hand it off to the next block
3324     Block *target_block = block()-&gt;successor_for_bci(target_bci);
3325     if (target_block-&gt;pred_count() != 1)  break;
3326     ciMethodData* methodData = method()-&gt;method_data();
3327     if (!methodData-&gt;is_mature())  break;
3328     ciProfileData* data = methodData-&gt;bci_to_data(bci());
3329     assert(data != NULL &amp;&amp; data-&gt;is_JumpData(), &quot;need JumpData for taken branch&quot;);
3330     int taken = ((ciJumpData*)data)-&gt;taken();
3331     taken = method()-&gt;scale_count(taken);
3332     target_block-&gt;set_count(taken);
3333     break;
3334   }
3335 
3336   case Bytecodes::_ifnull:    btest = BoolTest::eq; goto handle_if_null;
3337   case Bytecodes::_ifnonnull: btest = BoolTest::ne; goto handle_if_null;
3338   handle_if_null:
3339     // If this is a backwards branch in the bytecodes, add Safepoint
3340     maybe_add_safepoint(iter().get_dest());
3341     a = null();
3342     b = pop();
<span class="line-modified">3343     if (b-&gt;is_ValueType()) {</span>
<span class="line-modified">3344       // Return constant false because &#39;b&#39; is always non-null</span>
<span class="line-modified">3345       c = _gvn.makecon(TypeInt::CC_GT);</span>
<span class="line-modified">3346     } else {</span>
<span class="line-modified">3347       if (!_gvn.type(b)-&gt;speculative_maybe_null() &amp;&amp;</span>
<span class="line-modified">3348           !too_many_traps(Deoptimization::Reason_speculate_null_check)) {</span>
<span class="line-modified">3349         inc_sp(1);</span>
<span class="line-modified">3350         Node* null_ctl = top();</span>
<span class="line-modified">3351         b = null_check_oop(b, &amp;null_ctl, true, true, true);</span>
<span class="line-modified">3352         assert(null_ctl-&gt;is_top(), &quot;no null control here&quot;);</span>
<span class="line-modified">3353         dec_sp(1);</span>
<span class="line-modified">3354       } else if (_gvn.type(b)-&gt;speculative_always_null() &amp;&amp;</span>
<span class="line-modified">3355                  !too_many_traps(Deoptimization::Reason_speculate_null_assert)) {</span>
<span class="line-modified">3356         inc_sp(1);</span>
<span class="line-added">3357         b = null_assert(b);</span>
<span class="line-added">3358         dec_sp(1);</span>
<span class="line-added">3359       }</span>
<span class="line-added">3360       c = _gvn.transform( new CmpPNode(b, a) );</span>
<span class="line-added">3361     }</span>
3362     do_ifnull(btest, c);
3363     break;
3364 
3365   case Bytecodes::_if_acmpeq: btest = BoolTest::eq; goto handle_if_acmp;
3366   case Bytecodes::_if_acmpne: btest = BoolTest::ne; goto handle_if_acmp;
3367   handle_if_acmp:
3368     // If this is a backwards branch in the bytecodes, add Safepoint
3369     maybe_add_safepoint(iter().get_dest());
3370     a = pop();
3371     b = pop();
<span class="line-modified">3372     do_acmp(btest, a, b);</span>


3373     break;
3374 
3375   case Bytecodes::_ifeq: btest = BoolTest::eq; goto handle_ifxx;
3376   case Bytecodes::_ifne: btest = BoolTest::ne; goto handle_ifxx;
3377   case Bytecodes::_iflt: btest = BoolTest::lt; goto handle_ifxx;
3378   case Bytecodes::_ifle: btest = BoolTest::le; goto handle_ifxx;
3379   case Bytecodes::_ifgt: btest = BoolTest::gt; goto handle_ifxx;
3380   case Bytecodes::_ifge: btest = BoolTest::ge; goto handle_ifxx;
3381   handle_ifxx:
3382     // If this is a backwards branch in the bytecodes, add Safepoint
3383     maybe_add_safepoint(iter().get_dest());
3384     a = _gvn.intcon(0);
3385     b = pop();
3386     c = _gvn.transform( new CmpINode(b, a) );
3387     do_if(btest, c);
3388     break;
3389 
3390   case Bytecodes::_if_icmpeq: btest = BoolTest::eq; goto handle_if_icmp;
3391   case Bytecodes::_if_icmpne: btest = BoolTest::ne; goto handle_if_icmp;
3392   case Bytecodes::_if_icmplt: btest = BoolTest::lt; goto handle_if_icmp;
</pre>
<hr />
<pre>
3407     break;
3408 
3409   case Bytecodes::_lookupswitch:
3410     do_lookupswitch();
3411     break;
3412 
3413   case Bytecodes::_invokestatic:
3414   case Bytecodes::_invokedynamic:
3415   case Bytecodes::_invokespecial:
3416   case Bytecodes::_invokevirtual:
3417   case Bytecodes::_invokeinterface:
3418     do_call();
3419     break;
3420   case Bytecodes::_checkcast:
3421     do_checkcast();
3422     break;
3423   case Bytecodes::_instanceof:
3424     do_instanceof();
3425     break;
3426   case Bytecodes::_anewarray:
<span class="line-modified">3427     do_newarray();</span>
3428     break;
3429   case Bytecodes::_newarray:
3430     do_newarray((BasicType)iter().get_index());
3431     break;
3432   case Bytecodes::_multianewarray:
3433     do_multianewarray();
3434     break;
3435   case Bytecodes::_new:
3436     do_new();
3437     break;
<span class="line-added">3438   case Bytecodes::_defaultvalue:</span>
<span class="line-added">3439     do_defaultvalue();</span>
<span class="line-added">3440     break;</span>
<span class="line-added">3441   case Bytecodes::_withfield:</span>
<span class="line-added">3442     do_withfield();</span>
<span class="line-added">3443     break;</span>
3444 
3445   case Bytecodes::_jsr:
3446   case Bytecodes::_jsr_w:
3447     do_jsr();
3448     break;
3449 
3450   case Bytecodes::_ret:
3451     do_ret();
3452     break;
3453 
3454 
3455   case Bytecodes::_monitorenter:
3456     do_monitor_enter();
3457     break;
3458 
3459   case Bytecodes::_monitorexit:
3460     do_monitor_exit();
3461     break;
3462 
3463   case Bytecodes::_breakpoint:
</pre>
</td>
</tr>
</table>
<center><a href="output.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="phaseX.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>