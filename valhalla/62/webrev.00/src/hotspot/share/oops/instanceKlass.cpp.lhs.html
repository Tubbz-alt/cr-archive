<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/oops/instanceKlass.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;jvm.h&quot;
  27 #include &quot;aot/aotLoader.hpp&quot;
  28 #include &quot;classfile/classFileParser.hpp&quot;
  29 #include &quot;classfile/classFileStream.hpp&quot;
  30 #include &quot;classfile/classLoader.hpp&quot;
  31 #include &quot;classfile/classLoaderData.inline.hpp&quot;
  32 #include &quot;classfile/javaClasses.hpp&quot;
  33 #include &quot;classfile/moduleEntry.hpp&quot;
  34 #include &quot;classfile/symbolTable.hpp&quot;
  35 #include &quot;classfile/systemDictionary.hpp&quot;
  36 #include &quot;classfile/systemDictionaryShared.hpp&quot;
  37 #include &quot;classfile/verifier.hpp&quot;
  38 #include &quot;classfile/vmSymbols.hpp&quot;
  39 #include &quot;code/dependencyContext.hpp&quot;
  40 #include &quot;compiler/compileBroker.hpp&quot;
  41 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  42 #include &quot;interpreter/oopMapCache.hpp&quot;
  43 #include &quot;interpreter/rewriter.hpp&quot;
  44 #include &quot;jvmtifiles/jvmti.h&quot;
  45 #include &quot;logging/log.hpp&quot;
  46 #include &quot;logging/logMessage.hpp&quot;
  47 #include &quot;logging/logStream.hpp&quot;
  48 #include &quot;memory/allocation.inline.hpp&quot;
  49 #include &quot;memory/iterator.inline.hpp&quot;
  50 #include &quot;memory/metadataFactory.hpp&quot;
  51 #include &quot;memory/metaspaceClosure.hpp&quot;
  52 #include &quot;memory/metaspaceShared.hpp&quot;
  53 #include &quot;memory/oopFactory.hpp&quot;
  54 #include &quot;memory/resourceArea.hpp&quot;
  55 #include &quot;memory/universe.hpp&quot;
  56 #include &quot;oops/fieldStreams.inline.hpp&quot;
  57 #include &quot;oops/constantPool.hpp&quot;
  58 #include &quot;oops/instanceClassLoaderKlass.hpp&quot;
  59 #include &quot;oops/instanceKlass.inline.hpp&quot;
  60 #include &quot;oops/instanceMirrorKlass.hpp&quot;
  61 #include &quot;oops/instanceOop.hpp&quot;
  62 #include &quot;oops/klass.inline.hpp&quot;
  63 #include &quot;oops/method.hpp&quot;
  64 #include &quot;oops/oop.inline.hpp&quot;
  65 #include &quot;oops/recordComponent.hpp&quot;
  66 #include &quot;oops/symbol.hpp&quot;
  67 #include &quot;oops/valueKlass.hpp&quot;
  68 #include &quot;prims/jvmtiExport.hpp&quot;
  69 #include &quot;prims/jvmtiRedefineClasses.hpp&quot;
  70 #include &quot;prims/jvmtiThreadState.hpp&quot;
  71 #include &quot;prims/methodComparator.hpp&quot;
  72 #include &quot;runtime/atomic.hpp&quot;
  73 #include &quot;runtime/biasedLocking.hpp&quot;
  74 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  75 #include &quot;runtime/handles.inline.hpp&quot;
  76 #include &quot;runtime/javaCalls.hpp&quot;
  77 #include &quot;runtime/mutexLocker.hpp&quot;
  78 #include &quot;runtime/orderAccess.hpp&quot;
  79 #include &quot;runtime/thread.inline.hpp&quot;
  80 #include &quot;services/classLoadingService.hpp&quot;
  81 #include &quot;services/threadService.hpp&quot;
  82 #include &quot;utilities/dtrace.hpp&quot;
  83 #include &quot;utilities/events.hpp&quot;
  84 #include &quot;utilities/macros.hpp&quot;
  85 #include &quot;utilities/stringUtils.hpp&quot;
  86 #ifdef COMPILER1
  87 #include &quot;c1/c1_Compiler.hpp&quot;
  88 #endif
  89 #if INCLUDE_JFR
  90 #include &quot;jfr/jfrEvents.hpp&quot;
  91 #endif
  92 
  93 
  94 #ifdef DTRACE_ENABLED
  95 
  96 
  97 #define HOTSPOT_CLASS_INITIALIZATION_required HOTSPOT_CLASS_INITIALIZATION_REQUIRED
  98 #define HOTSPOT_CLASS_INITIALIZATION_recursive HOTSPOT_CLASS_INITIALIZATION_RECURSIVE
  99 #define HOTSPOT_CLASS_INITIALIZATION_concurrent HOTSPOT_CLASS_INITIALIZATION_CONCURRENT
 100 #define HOTSPOT_CLASS_INITIALIZATION_erroneous HOTSPOT_CLASS_INITIALIZATION_ERRONEOUS
 101 #define HOTSPOT_CLASS_INITIALIZATION_super__failed HOTSPOT_CLASS_INITIALIZATION_SUPER_FAILED
 102 #define HOTSPOT_CLASS_INITIALIZATION_clinit HOTSPOT_CLASS_INITIALIZATION_CLINIT
 103 #define HOTSPOT_CLASS_INITIALIZATION_error HOTSPOT_CLASS_INITIALIZATION_ERROR
 104 #define HOTSPOT_CLASS_INITIALIZATION_end HOTSPOT_CLASS_INITIALIZATION_END
 105 #define DTRACE_CLASSINIT_PROBE(type, thread_type)                \
 106   {                                                              \
 107     char* data = NULL;                                           \
 108     int len = 0;                                                 \
 109     Symbol* clss_name = name();                                  \
 110     if (clss_name != NULL) {                                     \
 111       data = (char*)clss_name-&gt;bytes();                          \
 112       len = clss_name-&gt;utf8_length();                            \
 113     }                                                            \
 114     HOTSPOT_CLASS_INITIALIZATION_##type(                         \
 115       data, len, (void*)class_loader(), thread_type);            \
 116   }
 117 
 118 #define DTRACE_CLASSINIT_PROBE_WAIT(type, thread_type, wait)     \
 119   {                                                              \
 120     char* data = NULL;                                           \
 121     int len = 0;                                                 \
 122     Symbol* clss_name = name();                                  \
 123     if (clss_name != NULL) {                                     \
 124       data = (char*)clss_name-&gt;bytes();                          \
 125       len = clss_name-&gt;utf8_length();                            \
 126     }                                                            \
 127     HOTSPOT_CLASS_INITIALIZATION_##type(                         \
 128       data, len, (void*)class_loader(), thread_type, wait);      \
 129   }
 130 
 131 #else //  ndef DTRACE_ENABLED
 132 
 133 #define DTRACE_CLASSINIT_PROBE(type, thread_type)
 134 #define DTRACE_CLASSINIT_PROBE_WAIT(type, thread_type, wait)
 135 
 136 #endif //  ndef DTRACE_ENABLED
 137 
 138 static inline bool is_class_loader(const Symbol* class_name,
 139                                    const ClassFileParser&amp; parser) {
 140   assert(class_name != NULL, &quot;invariant&quot;);
 141 
 142   if (class_name == vmSymbols::java_lang_ClassLoader()) {
 143     return true;
 144   }
 145 
 146   if (SystemDictionary::ClassLoader_klass_loaded()) {
 147     const Klass* const super_klass = parser.super_klass();
 148     if (super_klass != NULL) {
 149       if (super_klass-&gt;is_subtype_of(SystemDictionary::ClassLoader_klass())) {
 150         return true;
 151       }
 152     }
 153   }
 154   return false;
 155 }
 156 
 157 // called to verify that k is a member of this nest
 158 bool InstanceKlass::has_nest_member(InstanceKlass* k, TRAPS) const {
 159   if (_nest_members == NULL || _nest_members == Universe::the_empty_short_array()) {
 160     if (log_is_enabled(Trace, class, nestmates)) {
 161       ResourceMark rm(THREAD);
 162       log_trace(class, nestmates)(&quot;Checked nest membership of %s in non-nest-host class %s&quot;,
 163                                   k-&gt;external_name(), this-&gt;external_name());
 164     }
 165     return false;
 166   }
 167 
 168   if (log_is_enabled(Trace, class, nestmates)) {
 169     ResourceMark rm(THREAD);
 170     log_trace(class, nestmates)(&quot;Checking nest membership of %s in %s&quot;,
 171                                 k-&gt;external_name(), this-&gt;external_name());
 172   }
 173 
 174   // Check for a resolved cp entry , else fall back to a name check.
 175   // We don&#39;t want to resolve any class other than the one being checked.
 176   for (int i = 0; i &lt; _nest_members-&gt;length(); i++) {
 177     int cp_index = _nest_members-&gt;at(i);
 178     if (_constants-&gt;tag_at(cp_index).is_klass()) {
 179       Klass* k2 = _constants-&gt;klass_at(cp_index, CHECK_false);
 180       if (k2 == k) {
 181         log_trace(class, nestmates)(&quot;- class is listed at nest_members[%d] =&gt; cp[%d]&quot;, i, cp_index);
 182         return true;
 183       }
 184     }
 185     else {
 186       Symbol* name = _constants-&gt;klass_name_at(cp_index);
 187       if (name == k-&gt;name()) {
 188         log_trace(class, nestmates)(&quot;- Found it at nest_members[%d] =&gt; cp[%d]&quot;, i, cp_index);
 189 
 190         // Names match so check actual klass - this may trigger class loading if
 191         // it doesn&#39;t match (though that should be impossible). But to be safe we
 192         // have to check for a compiler thread executing here.
 193         if (!THREAD-&gt;can_call_java() &amp;&amp; !_constants-&gt;tag_at(cp_index).is_klass()) {
 194           log_trace(class, nestmates)(&quot;- validation required resolution in an unsuitable thread&quot;);
 195           return false;
 196         }
 197 
 198         Klass* k2 = _constants-&gt;klass_at(cp_index, CHECK_false);
 199         if (k2 == k) {
 200           log_trace(class, nestmates)(&quot;- class is listed as a nest member&quot;);
 201           return true;
 202         }
 203         else {
 204           // same name but different klass!
 205           log_trace(class, nestmates)(&quot; - klass comparison failed!&quot;);
 206           // can&#39;t have two names the same, so we&#39;re done
 207           return false;
 208         }
 209       }
 210     }
 211   }
 212   log_trace(class, nestmates)(&quot;- class is NOT a nest member!&quot;);
 213   return false;
 214 }
 215 
 216 // Return nest-host class, resolving, validating and saving it if needed.
 217 // In cases where this is called from a thread that can not do classloading
 218 // (such as a native JIT thread) then we simply return NULL, which in turn
 219 // causes the access check to return false. Such code will retry the access
 220 // from a more suitable environment later.
 221 InstanceKlass* InstanceKlass::nest_host(Symbol* validationException, TRAPS) {
 222   InstanceKlass* nest_host_k = _nest_host;
 223   if (nest_host_k == NULL) {
 224     // need to resolve and save our nest-host class. This could be attempted
 225     // concurrently but as the result is idempotent and we don&#39;t use the class
 226     // then we do not need any synchronization beyond what is implicitly used
 227     // during class loading.
 228     if (_nest_host_index != 0) { // we have a real nest_host
 229       // Before trying to resolve check if we&#39;re in a suitable context
 230       if (!THREAD-&gt;can_call_java() &amp;&amp; !_constants-&gt;tag_at(_nest_host_index).is_klass()) {
 231         if (log_is_enabled(Trace, class, nestmates)) {
 232           ResourceMark rm(THREAD);
 233           log_trace(class, nestmates)(&quot;Rejected resolution of nest-host of %s in unsuitable thread&quot;,
 234                                       this-&gt;external_name());
 235         }
 236         return NULL;
 237       }
 238 
 239       if (log_is_enabled(Trace, class, nestmates)) {
 240         ResourceMark rm(THREAD);
 241         log_trace(class, nestmates)(&quot;Resolving nest-host of %s using cp entry for %s&quot;,
 242                                     this-&gt;external_name(),
 243                                     _constants-&gt;klass_name_at(_nest_host_index)-&gt;as_C_string());
 244       }
 245 
 246       Klass* k = _constants-&gt;klass_at(_nest_host_index, THREAD);
 247       if (HAS_PENDING_EXCEPTION) {
 248         Handle exc_h = Handle(THREAD, PENDING_EXCEPTION);
 249         if (exc_h-&gt;is_a(SystemDictionary::NoClassDefFoundError_klass())) {
 250           // throw a new CDNFE with the original as its cause, and a clear msg
 251           ResourceMark rm(THREAD);
 252           char buf[200];
 253           CLEAR_PENDING_EXCEPTION;
 254           jio_snprintf(buf, sizeof(buf),
 255                        &quot;Unable to load nest-host class (%s) of %s&quot;,
 256                        _constants-&gt;klass_name_at(_nest_host_index)-&gt;as_C_string(),
 257                        this-&gt;external_name());
 258           log_trace(class, nestmates)(&quot;%s - NoClassDefFoundError&quot;, buf);
 259           THROW_MSG_CAUSE_NULL(vmSymbols::java_lang_NoClassDefFoundError(), buf, exc_h);
 260         }
 261         // All other exceptions pass through (OOME, StackOverflowError, LinkageErrors etc).
 262         return NULL;
 263       }
 264 
 265       // A valid nest-host is an instance class in the current package that lists this
 266       // class as a nest member. If any of these conditions are not met we post the
 267       // requested exception type (if any) and return NULL
 268 
 269       const char* error = NULL;
 270 
 271       // JVMS 5.4.4 indicates package check comes first
 272       if (is_same_class_package(k)) {
 273 
 274         // Now check actual membership. We can&#39;t be a member if our &quot;host&quot; is
 275         // not an instance class.
 276         if (k-&gt;is_instance_klass()) {
 277           nest_host_k = InstanceKlass::cast(k);
 278 
 279           bool is_member = nest_host_k-&gt;has_nest_member(this, CHECK_NULL);
 280           if (is_member) {
 281             // save resolved nest-host value
 282             _nest_host = nest_host_k;
 283 
 284             if (log_is_enabled(Trace, class, nestmates)) {
 285               ResourceMark rm(THREAD);
 286               log_trace(class, nestmates)(&quot;Resolved nest-host of %s to %s&quot;,
 287                                           this-&gt;external_name(), k-&gt;external_name());
 288             }
 289             return nest_host_k;
 290           }
 291         }
 292         error = &quot;current type is not listed as a nest member&quot;;
 293       } else {
 294         error = &quot;types are in different packages&quot;;
 295       }
 296 
 297       if (log_is_enabled(Trace, class, nestmates)) {
 298         ResourceMark rm(THREAD);
 299         log_trace(class, nestmates)
 300           (&quot;Type %s (loader: %s) is not a nest member of &quot;
 301            &quot;resolved type %s (loader: %s): %s&quot;,
 302            this-&gt;external_name(),
 303            this-&gt;class_loader_data()-&gt;loader_name_and_id(),
 304            k-&gt;external_name(),
 305            k-&gt;class_loader_data()-&gt;loader_name_and_id(),
 306            error);
 307       }
 308 
 309       if (validationException != NULL &amp;&amp; THREAD-&gt;can_call_java()) {
 310         ResourceMark rm(THREAD);
 311         Exceptions::fthrow(THREAD_AND_LOCATION,
 312                            validationException,
 313                            &quot;Type %s (loader: %s) is not a nest member of %s (loader: %s): %s&quot;,
 314                            this-&gt;external_name(),
 315                            this-&gt;class_loader_data()-&gt;loader_name_and_id(),
 316                            k-&gt;external_name(),
 317                            k-&gt;class_loader_data()-&gt;loader_name_and_id(),
 318                            error
 319                            );
 320       }
 321       return NULL;
 322     } else {
 323       if (log_is_enabled(Trace, class, nestmates)) {
 324         ResourceMark rm(THREAD);
 325         log_trace(class, nestmates)(&quot;Type %s is not part of a nest: setting nest-host to self&quot;,
 326                                     this-&gt;external_name());
 327       }
 328       // save resolved nest-host value
 329       return (_nest_host = this);
 330     }
 331   }
 332   return nest_host_k;
 333 }
 334 
 335 // check if &#39;this&#39; and k are nestmates (same nest_host), or k is our nest_host,
 336 // or we are k&#39;s nest_host - all of which is covered by comparing the two
 337 // resolved_nest_hosts
 338 bool InstanceKlass::has_nestmate_access_to(InstanceKlass* k, TRAPS) {
 339 
 340   assert(this != k, &quot;this should be handled by higher-level code&quot;);
 341 
 342   // Per JVMS 5.4.4 we first resolve and validate the current class, then
 343   // the target class k. Resolution exceptions will be passed on by upper
 344   // layers. IncompatibleClassChangeErrors from membership validation failures
 345   // will also be passed through.
 346 
 347   Symbol* icce = vmSymbols::java_lang_IncompatibleClassChangeError();
 348   InstanceKlass* cur_host = nest_host(icce, CHECK_false);
 349   if (cur_host == NULL) {
 350     return false;
 351   }
 352 
 353   Klass* k_nest_host = k-&gt;nest_host(icce, CHECK_false);
 354   if (k_nest_host == NULL) {
 355     return false;
 356   }
 357 
 358   bool access = (cur_host == k_nest_host);
 359 
 360   if (log_is_enabled(Trace, class, nestmates)) {
 361     ResourceMark rm(THREAD);
 362     log_trace(class, nestmates)(&quot;Class %s does %shave nestmate access to %s&quot;,
 363                                 this-&gt;external_name(),
 364                                 access ? &quot;&quot; : &quot;NOT &quot;,
 365                                 k-&gt;external_name());
 366   }
 367 
 368   return access;
 369 }
 370 
 371 InstanceKlass* InstanceKlass::allocate_instance_klass(const ClassFileParser&amp; parser, TRAPS) {
 372   const int size = InstanceKlass::size(parser.vtable_size(),
 373                                        parser.itable_size(),
 374                                        nonstatic_oop_map_size(parser.total_oop_map_count()),
 375                                        parser.is_interface(),
 376                                        parser.is_unsafe_anonymous(),
 377                                        should_store_fingerprint(parser.is_unsafe_anonymous()),
 378                                        parser.has_flattenable_fields() ? parser.java_fields_count() : 0,
<a name="1" id="anc1"></a><span class="line-modified"> 379                                        parser.is_value_type());</span>
 380 
 381   const Symbol* const class_name = parser.class_name();
 382   assert(class_name != NULL, &quot;invariant&quot;);
 383   ClassLoaderData* loader_data = parser.loader_data();
 384   assert(loader_data != NULL, &quot;invariant&quot;);
 385 
 386   InstanceKlass* ik;
 387 
 388   // Allocation
 389   if (REF_NONE == parser.reference_type()) {
 390     if (class_name == vmSymbols::java_lang_Class()) {
 391       // mirror
 392       ik = new (loader_data, size, THREAD) InstanceMirrorKlass(parser);
 393     } else if (is_class_loader(class_name, parser)) {
 394       // class loader
 395       ik = new (loader_data, size, THREAD) InstanceClassLoaderKlass(parser);
<a name="2" id="anc2"></a><span class="line-modified"> 396     } else if (parser.is_value_type()) {</span>
<span class="line-modified"> 397       // value type</span>
 398       ik = new (loader_data, size, THREAD) ValueKlass(parser);
 399     } else {
 400       // normal
 401       ik = new (loader_data, size, THREAD) InstanceKlass(parser, InstanceKlass::_misc_kind_other);
 402     }
 403   } else {
 404     // reference
 405     ik = new (loader_data, size, THREAD) InstanceRefKlass(parser);
 406   }
 407 
 408   // Check for pending exception before adding to the loader data and incrementing
 409   // class count.  Can get OOM here.
 410   if (HAS_PENDING_EXCEPTION) {
 411     return NULL;
 412   }
 413 
 414 #ifdef ASSERT
 415   assert(ik-&gt;size() == size, &quot;&quot;);
 416   ik-&gt;bounds_check((address) ik-&gt;start_of_vtable(), false, size);
 417   ik-&gt;bounds_check((address) ik-&gt;start_of_itable(), false, size);
 418   ik-&gt;bounds_check((address) ik-&gt;end_of_itable(), true, size);
 419   ik-&gt;bounds_check((address) ik-&gt;end_of_nonstatic_oop_maps(), true, size);
 420 #endif //ASSERT
 421   return ik;
 422 }
 423 
 424 #ifndef PRODUCT
 425 bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {
 426   const char* bad = NULL;
 427   address end = NULL;
 428   if (addr &lt; (address)this) {
 429     bad = &quot;before&quot;;
 430   } else if (addr == (address)this) {
 431     if (edge_ok)  return true;
 432     bad = &quot;just before&quot;;
 433   } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes &lt; 0 ? size() : size_in_bytes))) {
 434     if (edge_ok)  return true;
 435     bad = &quot;just after&quot;;
 436   } else if (addr &gt; end) {
 437     bad = &quot;after&quot;;
 438   } else {
 439     return true;
 440   }
 441   tty-&gt;print_cr(&quot;%s object bounds: &quot; INTPTR_FORMAT &quot; [&quot; INTPTR_FORMAT &quot;..&quot; INTPTR_FORMAT &quot;]&quot;,
 442       bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);
 443   Verbose = WizardMode = true; this-&gt;print(); //@@
 444   return false;
 445 }
 446 #endif //PRODUCT
 447 
 448 // copy method ordering from resource area to Metaspace
 449 void InstanceKlass::copy_method_ordering(const intArray* m, TRAPS) {
 450   if (m != NULL) {
 451     // allocate a new array and copy contents (memcpy?)
 452     _method_ordering = MetadataFactory::new_array&lt;int&gt;(class_loader_data(), m-&gt;length(), CHECK);
 453     for (int i = 0; i &lt; m-&gt;length(); i++) {
 454       _method_ordering-&gt;at_put(i, m-&gt;at(i));
 455     }
 456   } else {
 457     _method_ordering = Universe::the_empty_int_array();
 458   }
 459 }
 460 
 461 // create a new array of vtable_indices for default methods
 462 Array&lt;int&gt;* InstanceKlass::create_new_default_vtable_indices(int len, TRAPS) {
 463   Array&lt;int&gt;* vtable_indices = MetadataFactory::new_array&lt;int&gt;(class_loader_data(), len, CHECK_NULL);
 464   assert(default_vtable_indices() == NULL, &quot;only create once&quot;);
 465   set_default_vtable_indices(vtable_indices);
 466   return vtable_indices;
 467 }
 468 
 469 InstanceKlass::InstanceKlass(const ClassFileParser&amp; parser, unsigned kind, KlassID id) :
 470   Klass(id),
 471   _nest_members(NULL),
 472   _nest_host_index(0),
 473   _nest_host(NULL),
 474   _record_components(NULL),
 475   _static_field_size(parser.static_field_size()),
 476   _nonstatic_oop_map_size(nonstatic_oop_map_size(parser.total_oop_map_count())),
 477   _itable_len(parser.itable_size()),
 478   _init_thread(NULL),
 479   _init_state(allocated),
 480   _reference_type(parser.reference_type()),
 481   _value_field_klasses(NULL),
 482   _adr_valueklass_fixed_block(NULL)
 483 {
 484   set_vtable_length(parser.vtable_size());
 485   set_kind(kind);
 486   set_access_flags(parser.access_flags());
 487   set_is_unsafe_anonymous(parser.is_unsafe_anonymous());
 488   set_layout_helper(Klass::instance_layout_helper(parser.layout_size(),
 489                                                     false));
 490     if (parser.has_flattenable_fields()) {
<a name="3" id="anc3"></a><span class="line-modified"> 491       set_has_value_fields();</span>
 492     }
 493     _java_fields_count = parser.java_fields_count();
 494 
 495     assert(NULL == _methods, &quot;underlying memory not zeroed?&quot;);
 496     assert(is_instance_klass(), &quot;is layout incorrect?&quot;);
 497     assert(size_helper() == parser.layout_size(), &quot;incorrect size_helper?&quot;);
 498 
 499   if (Arguments::is_dumping_archive()) {
 500       SystemDictionaryShared::init_dumptime_info(this);
 501     }
 502 
 503   // Set biased locking bit for all instances of this class; it will be
 504   // cleared if revocation occurs too often for this type
 505   if (UseBiasedLocking &amp;&amp; BiasedLocking::enabled()) {
 506     set_prototype_header(markWord::biased_locking_prototype());
 507   }
<a name="4" id="anc4"></a><span class="line-modified"> 508   if (has_value_fields()) {</span>
 509     _value_field_klasses = (const Klass**) adr_value_fields_klasses();
 510   }
 511 }
 512 
 513 void InstanceKlass::deallocate_methods(ClassLoaderData* loader_data,
 514                                        Array&lt;Method*&gt;* methods) {
 515   if (methods != NULL &amp;&amp; methods != Universe::the_empty_method_array() &amp;&amp;
 516       !methods-&gt;is_shared()) {
 517     for (int i = 0; i &lt; methods-&gt;length(); i++) {
 518       Method* method = methods-&gt;at(i);
 519       if (method == NULL) continue;  // maybe null if error processing
 520       // Only want to delete methods that are not executing for RedefineClasses.
 521       // The previous version will point to them so they&#39;re not totally dangling
 522       assert (!method-&gt;on_stack(), &quot;shouldn&#39;t be called with methods on stack&quot;);
 523       MetadataFactory::free_metadata(loader_data, method);
 524     }
 525     MetadataFactory::free_array&lt;Method*&gt;(loader_data, methods);
 526   }
 527 }
 528 
 529 void InstanceKlass::deallocate_interfaces(ClassLoaderData* loader_data,
 530                                           const Klass* super_klass,
 531                                           Array&lt;InstanceKlass*&gt;* local_interfaces,
 532                                           Array&lt;InstanceKlass*&gt;* transitive_interfaces) {
 533   // Only deallocate transitive interfaces if not empty, same as super class
 534   // or same as local interfaces.  See code in parseClassFile.
 535   Array&lt;InstanceKlass*&gt;* ti = transitive_interfaces;
 536   if (ti != Universe::the_empty_instance_klass_array() &amp;&amp; ti != local_interfaces) {
 537     // check that the interfaces don&#39;t come from super class
 538     Array&lt;InstanceKlass*&gt;* sti = (super_klass == NULL) ? NULL :
 539                     InstanceKlass::cast(super_klass)-&gt;transitive_interfaces();
 540     if (ti != sti &amp;&amp; ti != NULL &amp;&amp; !ti-&gt;is_shared() &amp;&amp;
 541         ti != Universe::the_single_IdentityObject_klass_array()) {
 542       MetadataFactory::free_array&lt;InstanceKlass*&gt;(loader_data, ti);
 543     }
 544   }
 545 
 546   // local interfaces can be empty
 547   if (local_interfaces != Universe::the_empty_instance_klass_array() &amp;&amp;
 548       local_interfaces != NULL &amp;&amp; !local_interfaces-&gt;is_shared() &amp;&amp;
 549       local_interfaces != Universe::the_single_IdentityObject_klass_array()) {
 550     MetadataFactory::free_array&lt;InstanceKlass*&gt;(loader_data, local_interfaces);
 551   }
 552 }
 553 
 554 void InstanceKlass::deallocate_record_components(ClassLoaderData* loader_data,
 555                                                  Array&lt;RecordComponent*&gt;* record_components) {
 556   if (record_components != NULL &amp;&amp; !record_components-&gt;is_shared()) {
 557     for (int i = 0; i &lt; record_components-&gt;length(); i++) {
 558       RecordComponent* record_component = record_components-&gt;at(i);
 559       MetadataFactory::free_metadata(loader_data, record_component);
 560     }
 561     MetadataFactory::free_array&lt;RecordComponent*&gt;(loader_data, record_components);
 562   }
 563 }
 564 
 565 // This function deallocates the metadata and C heap pointers that the
 566 // InstanceKlass points to.
 567 void InstanceKlass::deallocate_contents(ClassLoaderData* loader_data) {
 568 
 569   // Orphan the mirror first, CMS thinks it&#39;s still live.
 570   if (java_mirror() != NULL) {
 571     java_lang_Class::set_klass(java_mirror(), NULL);
 572   }
 573 
 574   // Also remove mirror from handles
 575   loader_data-&gt;remove_handle(_java_mirror);
 576 
 577   // Need to take this class off the class loader data list.
 578   loader_data-&gt;remove_class(this);
 579 
 580   // The array_klass for this class is created later, after error handling.
 581   // For class redefinition, we keep the original class so this scratch class
 582   // doesn&#39;t have an array class.  Either way, assert that there is nothing
 583   // to deallocate.
 584   assert(array_klasses() == NULL, &quot;array classes shouldn&#39;t be created for this class yet&quot;);
 585 
 586   // Release C heap allocated data that this might point to, which includes
 587   // reference counting symbol names.
 588   release_C_heap_structures();
 589 
 590   deallocate_methods(loader_data, methods());
 591   set_methods(NULL);
 592 
 593   deallocate_record_components(loader_data, record_components());
 594   set_record_components(NULL);
 595 
 596   if (method_ordering() != NULL &amp;&amp;
 597       method_ordering() != Universe::the_empty_int_array() &amp;&amp;
 598       !method_ordering()-&gt;is_shared()) {
 599     MetadataFactory::free_array&lt;int&gt;(loader_data, method_ordering());
 600   }
 601   set_method_ordering(NULL);
 602 
 603   // default methods can be empty
 604   if (default_methods() != NULL &amp;&amp;
 605       default_methods() != Universe::the_empty_method_array() &amp;&amp;
 606       !default_methods()-&gt;is_shared()) {
 607     MetadataFactory::free_array&lt;Method*&gt;(loader_data, default_methods());
 608   }
 609   // Do NOT deallocate the default methods, they are owned by superinterfaces.
 610   set_default_methods(NULL);
 611 
 612   // default methods vtable indices can be empty
 613   if (default_vtable_indices() != NULL &amp;&amp;
 614       !default_vtable_indices()-&gt;is_shared()) {
 615     MetadataFactory::free_array&lt;int&gt;(loader_data, default_vtable_indices());
 616   }
 617   set_default_vtable_indices(NULL);
 618 
 619 
 620   // This array is in Klass, but remove it with the InstanceKlass since
 621   // this place would be the only caller and it can share memory with transitive
 622   // interfaces.
 623   if (secondary_supers() != NULL &amp;&amp;
 624       secondary_supers() != Universe::the_empty_klass_array() &amp;&amp;
 625       // see comments in compute_secondary_supers about the following cast
 626       (address)(secondary_supers()) != (address)(transitive_interfaces()) &amp;&amp;
 627       !secondary_supers()-&gt;is_shared()) {
 628     MetadataFactory::free_array&lt;Klass*&gt;(loader_data, secondary_supers());
 629   }
 630   set_secondary_supers(NULL);
 631 
 632   deallocate_interfaces(loader_data, super(), local_interfaces(), transitive_interfaces());
 633   set_transitive_interfaces(NULL);
 634   set_local_interfaces(NULL);
 635 
 636   if (fields() != NULL &amp;&amp; !fields()-&gt;is_shared()) {
 637     MetadataFactory::free_array&lt;jushort&gt;(loader_data, fields());
 638   }
 639   set_fields(NULL, 0);
 640 
 641   // If a method from a redefined class is using this constant pool, don&#39;t
 642   // delete it, yet.  The new class&#39;s previous version will point to this.
 643   if (constants() != NULL) {
 644     assert (!constants()-&gt;on_stack(), &quot;shouldn&#39;t be called if anything is onstack&quot;);
 645     if (!constants()-&gt;is_shared()) {
 646       MetadataFactory::free_metadata(loader_data, constants());
 647     }
 648     // Delete any cached resolution errors for the constant pool
 649     SystemDictionary::delete_resolution_error(constants());
 650 
 651     set_constants(NULL);
 652   }
 653 
 654   if (inner_classes() != NULL &amp;&amp;
 655       inner_classes() != Universe::the_empty_short_array() &amp;&amp;
 656       !inner_classes()-&gt;is_shared()) {
 657     MetadataFactory::free_array&lt;jushort&gt;(loader_data, inner_classes());
 658   }
 659   set_inner_classes(NULL);
 660 
 661   if (nest_members() != NULL &amp;&amp;
 662       nest_members() != Universe::the_empty_short_array() &amp;&amp;
 663       !nest_members()-&gt;is_shared()) {
 664     MetadataFactory::free_array&lt;jushort&gt;(loader_data, nest_members());
 665   }
 666   set_nest_members(NULL);
 667 
 668   // We should deallocate the Annotations instance if it&#39;s not in shared spaces.
 669   if (annotations() != NULL &amp;&amp; !annotations()-&gt;is_shared()) {
 670     MetadataFactory::free_metadata(loader_data, annotations());
 671   }
 672   set_annotations(NULL);
 673 
 674   if (Arguments::is_dumping_archive()) {
 675     SystemDictionaryShared::remove_dumptime_info(this);
 676   }
 677 }
 678 
 679 bool InstanceKlass::should_be_initialized() const {
 680   return !is_initialized();
 681 }
 682 
 683 klassItable InstanceKlass::itable() const {
 684   return klassItable(const_cast&lt;InstanceKlass*&gt;(this));
 685 }
 686 
 687 void InstanceKlass::eager_initialize(Thread *thread) {
 688   if (!EagerInitialization) return;
 689 
 690   if (this-&gt;is_not_initialized()) {
 691     // abort if the the class has a class initializer
 692     if (this-&gt;class_initializer() != NULL) return;
 693 
 694     // abort if it is java.lang.Object (initialization is handled in genesis)
 695     Klass* super_klass = super();
 696     if (super_klass == NULL) return;
 697 
 698     // abort if the super class should be initialized
 699     if (!InstanceKlass::cast(super_klass)-&gt;is_initialized()) return;
 700 
 701     // call body to expose the this pointer
 702     eager_initialize_impl();
 703   }
 704 }
 705 
 706 // JVMTI spec thinks there are signers and protection domain in the
 707 // instanceKlass.  These accessors pretend these fields are there.
 708 // The hprof specification also thinks these fields are in InstanceKlass.
 709 oop InstanceKlass::protection_domain() const {
 710   // return the protection_domain from the mirror
 711   return java_lang_Class::protection_domain(java_mirror());
 712 }
 713 
 714 // To remove these from requires an incompatible change and CCC request.
 715 objArrayOop InstanceKlass::signers() const {
 716   // return the signers from the mirror
 717   return java_lang_Class::signers(java_mirror());
 718 }
 719 
 720 oop InstanceKlass::init_lock() const {
 721   // return the init lock from the mirror
 722   oop lock = java_lang_Class::init_lock(java_mirror());
 723   // Prevent reordering with any access of initialization state
 724   OrderAccess::loadload();
 725   assert((oop)lock != NULL || !is_not_initialized(), // initialized or in_error state
 726          &quot;only fully initialized state can have a null lock&quot;);
 727   return lock;
 728 }
 729 
 730 // Set the initialization lock to null so the object can be GC&#39;ed.  Any racing
 731 // threads to get this lock will see a null lock and will not lock.
 732 // That&#39;s okay because they all check for initialized state after getting
 733 // the lock and return.
 734 void InstanceKlass::fence_and_clear_init_lock() {
 735   // make sure previous stores are all done, notably the init_state.
 736   OrderAccess::storestore();
 737   java_lang_Class::set_init_lock(java_mirror(), NULL);
 738   assert(!is_not_initialized(), &quot;class must be initialized now&quot;);
 739 }
 740 
 741 void InstanceKlass::eager_initialize_impl() {
 742   EXCEPTION_MARK;
 743   HandleMark hm(THREAD);
 744   Handle h_init_lock(THREAD, init_lock());
 745   ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);
 746 
 747   // abort if someone beat us to the initialization
 748   if (!is_not_initialized()) return;  // note: not equivalent to is_initialized()
 749 
 750   ClassState old_state = init_state();
 751   link_class_impl(THREAD);
 752   if (HAS_PENDING_EXCEPTION) {
 753     CLEAR_PENDING_EXCEPTION;
 754     // Abort if linking the class throws an exception.
 755 
 756     // Use a test to avoid redundantly resetting the state if there&#39;s
 757     // no change.  Set_init_state() asserts that state changes make
 758     // progress, whereas here we might just be spinning in place.
 759     if (old_state != _init_state)
 760       set_init_state(old_state);
 761   } else {
 762     // linking successfull, mark class as initialized
 763     set_init_state(fully_initialized);
 764     fence_and_clear_init_lock();
 765     // trace
 766     if (log_is_enabled(Info, class, init)) {
 767       ResourceMark rm(THREAD);
 768       log_info(class, init)(&quot;[Initialized %s without side effects]&quot;, external_name());
 769     }
 770   }
 771 }
 772 
 773 
 774 // See &quot;The Virtual Machine Specification&quot; section 2.16.5 for a detailed explanation of the class initialization
 775 // process. The step comments refers to the procedure described in that section.
 776 // Note: implementation moved to static method to expose the this pointer.
 777 void InstanceKlass::initialize(TRAPS) {
 778   if (this-&gt;should_be_initialized()) {
 779     initialize_impl(CHECK);
 780     // Note: at this point the class may be initialized
 781     //       OR it may be in the state of being initialized
 782     //       in case of recursive initialization!
 783   } else {
 784     assert(is_initialized(), &quot;sanity check&quot;);
 785   }
 786 }
 787 
 788 
 789 bool InstanceKlass::verify_code(TRAPS) {
 790   // 1) Verify the bytecodes
 791   return Verifier::verify(this, should_verify_class(), THREAD);
 792 }
 793 
 794 void InstanceKlass::link_class(TRAPS) {
 795   assert(is_loaded(), &quot;must be loaded&quot;);
 796   if (!is_linked()) {
 797     link_class_impl(CHECK);
 798   }
 799 }
 800 
 801 // Called to verify that a class can link during initialization, without
 802 // throwing a VerifyError.
 803 bool InstanceKlass::link_class_or_fail(TRAPS) {
 804   assert(is_loaded(), &quot;must be loaded&quot;);
 805   if (!is_linked()) {
 806     link_class_impl(CHECK_false);
 807   }
 808   return is_linked();
 809 }
 810 
 811 bool InstanceKlass::link_class_impl(TRAPS) {
 812   if (DumpSharedSpaces &amp;&amp; SystemDictionaryShared::has_class_failed_verification(this)) {
 813     // This is for CDS dumping phase only -- we use the in_error_state to indicate that
 814     // the class has failed verification. Throwing the NoClassDefFoundError here is just
 815     // a convenient way to stop repeat attempts to verify the same (bad) class.
 816     //
 817     // Note that the NoClassDefFoundError is not part of the JLS, and should not be thrown
 818     // if we are executing Java code. This is not a problem for CDS dumping phase since
 819     // it doesn&#39;t execute any Java code.
 820     ResourceMark rm(THREAD);
 821     Exceptions::fthrow(THREAD_AND_LOCATION,
 822                        vmSymbols::java_lang_NoClassDefFoundError(),
 823                        &quot;Class %s, or one of its supertypes, failed class initialization&quot;,
 824                        external_name());
 825     return false;
 826   }
 827   // return if already verified
 828   if (is_linked()) {
 829     return true;
 830   }
 831 
 832   // Timing
 833   // timer handles recursion
 834   assert(THREAD-&gt;is_Java_thread(), &quot;non-JavaThread in link_class_impl&quot;);
 835   JavaThread* jt = (JavaThread*)THREAD;
 836 
 837   // link super class before linking this class
 838   Klass* super_klass = super();
 839   if (super_klass != NULL) {
 840     if (super_klass-&gt;is_interface()) {  // check if super class is an interface
 841       ResourceMark rm(THREAD);
 842       Exceptions::fthrow(
 843         THREAD_AND_LOCATION,
 844         vmSymbols::java_lang_IncompatibleClassChangeError(),
 845         &quot;class %s has interface %s as super class&quot;,
 846         external_name(),
 847         super_klass-&gt;external_name()
 848       );
 849       return false;
 850     }
 851 
 852     InstanceKlass* ik_super = InstanceKlass::cast(super_klass);
 853     ik_super-&gt;link_class_impl(CHECK_false);
 854   }
 855 
 856   // link all interfaces implemented by this class before linking this class
 857   Array&lt;InstanceKlass*&gt;* interfaces = local_interfaces();
 858   int num_interfaces = interfaces-&gt;length();
 859   for (int index = 0; index &lt; num_interfaces; index++) {
 860     InstanceKlass* interk = interfaces-&gt;at(index);
 861     interk-&gt;link_class_impl(CHECK_false);
 862   }
 863 
 864 
<a name="5" id="anc5"></a><span class="line-modified"> 865   // If a class declares a method that uses a value class as an argument</span>
<span class="line-modified"> 866   // type or return value type, this value class must be loaded during the</span>
<span class="line-modified"> 867   // linking of this class because size and properties of the value class</span>
<span class="line-modified"> 868   // must be known in order to be able to perform value type optimizations.</span>
 869   // The implementation below is an approximation of this rule, the code
 870   // iterates over all methods of the current class (including overridden
 871   // methods), not only the methods declared by this class. This
 872   // approximation makes the code simpler, and doesn&#39;t change the semantic
 873   // because classes declaring methods overridden by the current class are
 874   // linked (and have performed their own pre-loading) before the linking
 875   // of the current class.
<a name="6" id="anc6"></a><span class="line-removed"> 876   // This is also the moment to detect potential mismatch between the</span>
<span class="line-removed"> 877   // ValueTypes attribute and the kind of the class effectively loaded.</span>
 878 
 879 
 880   // Note:
<a name="7" id="anc7"></a><span class="line-modified"> 881   // Value class types used for flattenable fields are loaded during</span>
 882   // the loading phase (see ClassFileParser::post_process_parsed_stream()).
<a name="8" id="anc8"></a><span class="line-modified"> 883   // Value class types used as element types for array creation</span>
 884   // are not pre-loaded. Their loading is triggered by either anewarray
 885   // or multianewarray bytecodes.
 886 
 887   // Could it be possible to do the following processing only if the
<a name="9" id="anc9"></a><span class="line-modified"> 888   // class uses value types?</span>
 889   {
 890     ResourceMark rm(THREAD);
 891     for (int i = 0; i &lt; methods()-&gt;length(); i++) {
 892       Method* m = methods()-&gt;at(i);
 893       for (SignatureStream ss(m-&gt;signature()); !ss.is_done(); ss.next()) {
 894         if (ss.is_reference()) {
 895           if (ss.is_array()) {
 896             ss.skip_array_prefix();
 897           }
 898           if (ss.type() == T_VALUETYPE) {
 899             Symbol* symb = ss.as_symbol();
 900 
 901             oop loader = class_loader();
 902             oop protection_domain = this-&gt;protection_domain();
 903             Klass* klass = SystemDictionary::resolve_or_fail(symb,
 904                                                              Handle(THREAD, loader), Handle(THREAD, protection_domain), true,
 905                                                              CHECK_false);
 906             if (klass == NULL) {
 907               THROW_(vmSymbols::java_lang_LinkageError(), false);
 908             }
 909             if (!klass-&gt;is_value()) {
 910               Exceptions::fthrow(
 911                 THREAD_AND_LOCATION,
 912                 vmSymbols::java_lang_IncompatibleClassChangeError(),
 913                 &quot;class %s is not an inline type&quot;,
 914                 klass-&gt;external_name());
 915             }
 916           }
 917         }
 918       }
 919     }
 920   }
 921 
 922   // in case the class is linked in the process of linking its superclasses
 923   if (is_linked()) {
 924     return true;
 925   }
 926 
 927   // trace only the link time for this klass that includes
 928   // the verification time
 929   PerfClassTraceTime vmtimer(ClassLoader::perf_class_link_time(),
 930                              ClassLoader::perf_class_link_selftime(),
 931                              ClassLoader::perf_classes_linked(),
 932                              jt-&gt;get_thread_stat()-&gt;perf_recursion_counts_addr(),
 933                              jt-&gt;get_thread_stat()-&gt;perf_timers_addr(),
 934                              PerfClassTraceTime::CLASS_LINK);
 935 
 936   // verification &amp; rewriting
 937   {
 938     HandleMark hm(THREAD);
 939     Handle h_init_lock(THREAD, init_lock());
 940     ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);
 941     // rewritten will have been set if loader constraint error found
 942     // on an earlier link attempt
 943     // don&#39;t verify or rewrite if already rewritten
 944     //
 945 
 946     if (!is_linked()) {
 947       if (!is_rewritten()) {
 948         {
 949           bool verify_ok = verify_code(THREAD);
 950           if (!verify_ok) {
 951             return false;
 952           }
 953         }
 954 
 955         // Just in case a side-effect of verify linked this class already
 956         // (which can sometimes happen since the verifier loads classes
 957         // using custom class loaders, which are free to initialize things)
 958         if (is_linked()) {
 959           return true;
 960         }
 961 
 962         // also sets rewritten
 963         rewrite_class(CHECK_false);
 964       } else if (is_shared()) {
 965         SystemDictionaryShared::check_verification_constraints(this, CHECK_false);
 966       }
 967 
 968       // relocate jsrs and link methods after they are all rewritten
 969       link_methods(CHECK_false);
 970 
 971       // Initialize the vtable and interface table after
 972       // methods have been rewritten since rewrite may
 973       // fabricate new Method*s.
 974       // also does loader constraint checking
 975       //
 976       // initialize_vtable and initialize_itable need to be rerun for
 977       // a shared class if the class is not loaded by the NULL classloader.
 978       ClassLoaderData * loader_data = class_loader_data();
 979       if (!(is_shared() &amp;&amp;
 980             loader_data-&gt;is_the_null_class_loader_data())) {
 981         vtable().initialize_vtable(true, CHECK_false);
 982         itable().initialize_itable(true, CHECK_false);
 983       }
 984 #ifdef ASSERT
 985       else {
 986         vtable().verify(tty, true);
 987         // In case itable verification is ever added.
 988         // itable().verify(tty, true);
 989       }
 990 #endif
 991 
 992       set_init_state(linked);
 993       if (JvmtiExport::should_post_class_prepare()) {
 994         Thread *thread = THREAD;
 995         assert(thread-&gt;is_Java_thread(), &quot;thread-&gt;is_Java_thread()&quot;);
 996         JvmtiExport::post_class_prepare((JavaThread *) thread, this);
 997       }
 998     }
 999   }
1000   return true;
1001 }
1002 
1003 // Rewrite the byte codes of all of the methods of a class.
1004 // The rewriter must be called exactly once. Rewriting must happen after
1005 // verification but before the first method of the class is executed.
1006 void InstanceKlass::rewrite_class(TRAPS) {
1007   assert(is_loaded(), &quot;must be loaded&quot;);
1008   if (is_rewritten()) {
1009     assert(is_shared(), &quot;rewriting an unshared class?&quot;);
1010     return;
1011   }
1012   Rewriter::rewrite(this, CHECK);
1013   set_rewritten();
1014 }
1015 
1016 // Now relocate and link method entry points after class is rewritten.
1017 // This is outside is_rewritten flag. In case of an exception, it can be
1018 // executed more than once.
1019 void InstanceKlass::link_methods(TRAPS) {
1020   int len = methods()-&gt;length();
1021   for (int i = len-1; i &gt;= 0; i--) {
1022     methodHandle m(THREAD, methods()-&gt;at(i));
1023 
1024     // Set up method entry points for compiler and interpreter    .
1025     m-&gt;link_method(m, CHECK);
1026   }
1027 }
1028 
1029 // Eagerly initialize superinterfaces that declare default methods (concrete instance: any access)
1030 void InstanceKlass::initialize_super_interfaces(TRAPS) {
1031   assert (has_nonstatic_concrete_methods(), &quot;caller should have checked this&quot;);
1032   for (int i = 0; i &lt; local_interfaces()-&gt;length(); ++i) {
1033     InstanceKlass* ik = local_interfaces()-&gt;at(i);
1034 
1035     // Initialization is depth first search ie. we start with top of the inheritance tree
1036     // has_nonstatic_concrete_methods drives searching superinterfaces since it
1037     // means has_nonstatic_concrete_methods in its superinterface hierarchy
1038     if (ik-&gt;has_nonstatic_concrete_methods()) {
1039       ik-&gt;initialize_super_interfaces(CHECK);
1040     }
1041 
1042     // Only initialize() interfaces that &quot;declare&quot; concrete methods.
1043     if (ik-&gt;should_be_initialized() &amp;&amp; ik-&gt;declares_nonstatic_concrete_methods()) {
1044       ik-&gt;initialize(CHECK);
1045     }
1046   }
1047 }
1048 
1049 void InstanceKlass::initialize_impl(TRAPS) {
1050   HandleMark hm(THREAD);
1051 
1052   // Make sure klass is linked (verified) before initialization
1053   // A class could already be verified, since it has been reflected upon.
1054   link_class(CHECK);
1055 
1056   DTRACE_CLASSINIT_PROBE(required, -1);
1057 
1058   bool wait = false;
1059 
1060   assert(THREAD-&gt;is_Java_thread(), &quot;non-JavaThread in initialize_impl&quot;);
1061   JavaThread* jt = (JavaThread*)THREAD;
1062 
1063   // refer to the JVM book page 47 for description of steps
1064   // Step 1
1065   {
1066     Handle h_init_lock(THREAD, init_lock());
1067     ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);
1068 
1069     // Step 2
1070     // If we were to use wait() instead of waitInterruptibly() then
1071     // we might end up throwing IE from link/symbol resolution sites
1072     // that aren&#39;t expected to throw.  This would wreak havoc.  See 6320309.
1073     while (is_being_initialized() &amp;&amp; !is_reentrant_initialization(jt)) {
1074       wait = true;
1075       jt-&gt;set_class_to_be_initialized(this);
1076       ol.wait_uninterruptibly(jt);
1077       jt-&gt;set_class_to_be_initialized(NULL);
1078     }
1079 
1080     // Step 3
1081     if (is_being_initialized() &amp;&amp; is_reentrant_initialization(jt)) {
1082       DTRACE_CLASSINIT_PROBE_WAIT(recursive, -1, wait);
1083       return;
1084     }
1085 
1086     // Step 4
1087     if (is_initialized()) {
1088       DTRACE_CLASSINIT_PROBE_WAIT(concurrent, -1, wait);
1089       return;
1090     }
1091 
1092     // Step 5
1093     if (is_in_error_state()) {
1094       DTRACE_CLASSINIT_PROBE_WAIT(erroneous, -1, wait);
1095       ResourceMark rm(THREAD);
1096       const char* desc = &quot;Could not initialize class &quot;;
1097       const char* className = external_name();
1098       size_t msglen = strlen(desc) + strlen(className) + 1;
1099       char* message = NEW_RESOURCE_ARRAY(char, msglen);
1100       if (NULL == message) {
1101         // Out of memory: can&#39;t create detailed error message
1102           THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), className);
1103       } else {
1104         jio_snprintf(message, msglen, &quot;%s%s&quot;, desc, className);
1105           THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), message);
1106       }
1107     }
1108 
1109     // Step 6
1110     set_init_state(being_initialized);
1111     set_init_thread(jt);
1112   }
1113 
1114   // Step 7
1115   // Next, if C is a class rather than an interface, initialize it&#39;s super class and super
1116   // interfaces.
1117   if (!is_interface()) {
1118     Klass* super_klass = super();
1119     if (super_klass != NULL &amp;&amp; super_klass-&gt;should_be_initialized()) {
1120       super_klass-&gt;initialize(THREAD);
1121     }
1122     // If C implements any interface that declares a non-static, concrete method,
1123     // the initialization of C triggers initialization of its super interfaces.
1124     // Only need to recurse if has_nonstatic_concrete_methods which includes declaring and
1125     // having a superinterface that declares, non-static, concrete methods
1126     if (!HAS_PENDING_EXCEPTION &amp;&amp; has_nonstatic_concrete_methods()) {
1127       initialize_super_interfaces(THREAD);
1128     }
1129 
1130     // If any exceptions, complete abruptly, throwing the same exception as above.
1131     if (HAS_PENDING_EXCEPTION) {
1132       Handle e(THREAD, PENDING_EXCEPTION);
1133       CLEAR_PENDING_EXCEPTION;
1134       {
1135         EXCEPTION_MARK;
1136         // Locks object, set state, and notify all waiting threads
1137         set_initialization_state_and_notify(initialization_error, THREAD);
1138         CLEAR_PENDING_EXCEPTION;
1139       }
1140       DTRACE_CLASSINIT_PROBE_WAIT(super__failed, -1, wait);
1141       THROW_OOP(e());
1142     }
1143   }
1144 
1145   // Step 8
1146   // Initialize classes of flattenable fields
1147   {
1148     for (AllFieldStream fs(this); !fs.done(); fs.next()) {
1149       if (fs.is_flattenable()) {
1150         Klass* klass = this-&gt;get_value_field_klass_or_null(fs.index());
1151         if (klass == NULL) {
1152           assert(fs.access_flags().is_static() &amp;&amp; fs.access_flags().is_flattenable(),
1153               &quot;Otherwise should have been pre-loaded&quot;);
1154           klass = SystemDictionary::resolve_or_fail(field_signature(fs.index())-&gt;fundamental_name(THREAD),
1155               Handle(THREAD, class_loader()),
1156               Handle(THREAD, protection_domain()),
1157               true, CHECK);
1158           if (klass == NULL) {
1159             THROW(vmSymbols::java_lang_NoClassDefFoundError());
1160           }
1161           if (!klass-&gt;is_value()) {
1162             THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
1163           }
1164           this-&gt;set_value_field_klass(fs.index(), klass);
1165         }
1166         InstanceKlass::cast(klass)-&gt;initialize(CHECK);
1167         if (fs.access_flags().is_static()) {
1168           if (java_mirror()-&gt;obj_field(fs.offset()) == NULL) {
1169             java_mirror()-&gt;obj_field_put(fs.offset(), ValueKlass::cast(klass)-&gt;default_value());
1170           }
1171         }
1172       }
1173     }
1174   }
1175 
1176 
1177   // Look for aot compiled methods for this klass, including class initializer.
1178   AOTLoader::load_for_klass(this, THREAD);
1179 
1180   // Step 9
1181   {
1182     DTRACE_CLASSINIT_PROBE_WAIT(clinit, -1, wait);
1183     // Timer includes any side effects of class initialization (resolution,
1184     // etc), but not recursive entry into call_class_initializer().
1185     PerfClassTraceTime timer(ClassLoader::perf_class_init_time(),
1186                              ClassLoader::perf_class_init_selftime(),
1187                              ClassLoader::perf_classes_inited(),
1188                              jt-&gt;get_thread_stat()-&gt;perf_recursion_counts_addr(),
1189                              jt-&gt;get_thread_stat()-&gt;perf_timers_addr(),
1190                              PerfClassTraceTime::CLASS_CLINIT);
1191     call_class_initializer(THREAD);
1192   }
1193 
1194   // Step 10
1195   if (!HAS_PENDING_EXCEPTION) {
1196     set_initialization_state_and_notify(fully_initialized, CHECK);
1197     {
1198       debug_only(vtable().verify(tty, true);)
1199     }
1200   }
1201   else {
1202     // Step 11 and 12
1203     Handle e(THREAD, PENDING_EXCEPTION);
1204     CLEAR_PENDING_EXCEPTION;
1205     // JVMTI has already reported the pending exception
1206     // JVMTI internal flag reset is needed in order to report ExceptionInInitializerError
1207     JvmtiExport::clear_detected_exception(jt);
1208     {
1209       EXCEPTION_MARK;
1210       set_initialization_state_and_notify(initialization_error, THREAD);
1211       CLEAR_PENDING_EXCEPTION;   // ignore any exception thrown, class initialization error is thrown below
1212       // JVMTI has already reported the pending exception
1213       // JVMTI internal flag reset is needed in order to report ExceptionInInitializerError
1214       JvmtiExport::clear_detected_exception(jt);
1215     }
1216     DTRACE_CLASSINIT_PROBE_WAIT(error, -1, wait);
1217     if (e-&gt;is_a(SystemDictionary::Error_klass())) {
1218       THROW_OOP(e());
1219     } else {
1220       JavaCallArguments args(e);
1221       THROW_ARG(vmSymbols::java_lang_ExceptionInInitializerError(),
1222                 vmSymbols::throwable_void_signature(),
1223                 &amp;args);
1224     }
1225   }
1226   DTRACE_CLASSINIT_PROBE_WAIT(end, -1, wait);
1227 }
1228 
1229 
1230 void InstanceKlass::set_initialization_state_and_notify(ClassState state, TRAPS) {
1231   Handle h_init_lock(THREAD, init_lock());
1232   if (h_init_lock() != NULL) {
1233     ObjectLocker ol(h_init_lock, THREAD);
1234     set_init_thread(NULL); // reset _init_thread before changing _init_state
1235     set_init_state(state);
1236     fence_and_clear_init_lock();
1237     ol.notify_all(CHECK);
1238   } else {
1239     assert(h_init_lock() != NULL, &quot;The initialization state should never be set twice&quot;);
1240     set_init_thread(NULL); // reset _init_thread before changing _init_state
1241     set_init_state(state);
1242   }
1243 }
1244 
1245 Klass* InstanceKlass::implementor() const {
1246   Klass* volatile* k = adr_implementor();
1247   if (k == NULL) {
1248     return NULL;
1249   } else {
1250     // This load races with inserts, and therefore needs acquire.
1251     Klass* kls = Atomic::load_acquire(k);
1252     if (kls != NULL &amp;&amp; !kls-&gt;is_loader_alive()) {
1253       return NULL;  // don&#39;t return unloaded class
1254     } else {
1255       return kls;
1256     }
1257   }
1258 }
1259 
1260 
1261 void InstanceKlass::set_implementor(Klass* k) {
1262   assert_locked_or_safepoint(Compile_lock);
1263   assert(is_interface(), &quot;not interface&quot;);
1264   Klass* volatile* addr = adr_implementor();
1265   assert(addr != NULL, &quot;null addr&quot;);
1266   if (addr != NULL) {
1267     Atomic::release_store(addr, k);
1268   }
1269 }
1270 
1271 int  InstanceKlass::nof_implementors() const {
1272   Klass* k = implementor();
1273   if (k == NULL) {
1274     return 0;
1275   } else if (k != this) {
1276     return 1;
1277   } else {
1278     return 2;
1279   }
1280 }
1281 
1282 // The embedded _implementor field can only record one implementor.
1283 // When there are more than one implementors, the _implementor field
1284 // is set to the interface Klass* itself. Following are the possible
1285 // values for the _implementor field:
1286 //   NULL                  - no implementor
1287 //   implementor Klass*    - one implementor
1288 //   self                  - more than one implementor
1289 //
1290 // The _implementor field only exists for interfaces.
1291 void InstanceKlass::add_implementor(Klass* k) {
1292   if (Universe::is_fully_initialized()) {
1293     assert_lock_strong(Compile_lock);
1294   }
1295   assert(is_interface(), &quot;not interface&quot;);
1296   // Filter out my subinterfaces.
1297   // (Note: Interfaces are never on the subklass list.)
1298   if (InstanceKlass::cast(k)-&gt;is_interface()) return;
1299 
1300   // Filter out subclasses whose supers already implement me.
1301   // (Note: CHA must walk subclasses of direct implementors
1302   // in order to locate indirect implementors.)
1303   Klass* sk = k-&gt;super();
1304   if (sk != NULL &amp;&amp; InstanceKlass::cast(sk)-&gt;implements_interface(this))
1305     // We only need to check one immediate superclass, since the
1306     // implements_interface query looks at transitive_interfaces.
1307     // Any supers of the super have the same (or fewer) transitive_interfaces.
1308     return;
1309 
1310   Klass* ik = implementor();
1311   if (ik == NULL) {
1312     set_implementor(k);
1313   } else if (ik != this &amp;&amp; ik != k) {
1314     // There is already an implementor. Use itself as an indicator of
1315     // more than one implementors.
1316     set_implementor(this);
1317   }
1318 
1319   // The implementor also implements the transitive_interfaces
1320   for (int index = 0; index &lt; local_interfaces()-&gt;length(); index++) {
1321     InstanceKlass::cast(local_interfaces()-&gt;at(index))-&gt;add_implementor(k);
1322   }
1323 }
1324 
1325 void InstanceKlass::init_implementor() {
1326   if (is_interface()) {
1327     set_implementor(NULL);
1328   }
1329 }
1330 
1331 
1332 void InstanceKlass::process_interfaces(Thread *thread) {
1333   // link this class into the implementors list of every interface it implements
1334   for (int i = local_interfaces()-&gt;length() - 1; i &gt;= 0; i--) {
1335     assert(local_interfaces()-&gt;at(i)-&gt;is_klass(), &quot;must be a klass&quot;);
1336     InstanceKlass* interf = InstanceKlass::cast(local_interfaces()-&gt;at(i));
1337     assert(interf-&gt;is_interface(), &quot;expected interface&quot;);
1338     interf-&gt;add_implementor(this);
1339   }
1340 }
1341 
1342 bool InstanceKlass::can_be_primary_super_slow() const {
1343   if (is_interface())
1344     return false;
1345   else
1346     return Klass::can_be_primary_super_slow();
1347 }
1348 
1349 GrowableArray&lt;Klass*&gt;* InstanceKlass::compute_secondary_supers(int num_extra_slots,
1350                                                                Array&lt;InstanceKlass*&gt;* transitive_interfaces) {
1351   // The secondaries are the implemented interfaces.
1352   Array&lt;InstanceKlass*&gt;* interfaces = transitive_interfaces;
1353   int num_secondaries = num_extra_slots + interfaces-&gt;length();
1354   if (num_secondaries == 0) {
1355     // Must share this for correct bootstrapping!
1356     set_secondary_supers(Universe::the_empty_klass_array());
1357     return NULL;
1358   } else if (num_extra_slots == 0) {
1359     // The secondary super list is exactly the same as the transitive interfaces, so
1360     // let&#39;s use it instead of making a copy.
1361     // Redefine classes has to be careful not to delete this!
1362     // We need the cast because Array&lt;Klass*&gt; is NOT a supertype of Array&lt;InstanceKlass*&gt;,
1363     // (but it&#39;s safe to do here because we won&#39;t write into _secondary_supers from this point on).
1364     set_secondary_supers((Array&lt;Klass*&gt;*)(address)interfaces);
1365     return NULL;
1366   } else {
1367     // Copy transitive interfaces to a temporary growable array to be constructed
1368     // into the secondary super list with extra slots.
1369     GrowableArray&lt;Klass*&gt;* secondaries = new GrowableArray&lt;Klass*&gt;(interfaces-&gt;length());
1370     for (int i = 0; i &lt; interfaces-&gt;length(); i++) {
1371       secondaries-&gt;push(interfaces-&gt;at(i));
1372     }
1373     return secondaries;
1374   }
1375 }
1376 
1377 bool InstanceKlass::implements_interface(Klass* k) const {
1378   if (this == k) return true;
1379   assert(k-&gt;is_interface(), &quot;should be an interface class&quot;);
1380   for (int i = 0; i &lt; transitive_interfaces()-&gt;length(); i++) {
1381     if (transitive_interfaces()-&gt;at(i) == k) {
1382       return true;
1383     }
1384   }
1385   return false;
1386 }
1387 
1388 bool InstanceKlass::is_same_or_direct_interface(Klass *k) const {
1389   // Verify direct super interface
1390   if (this == k) return true;
1391   assert(k-&gt;is_interface(), &quot;should be an interface class&quot;);
1392   for (int i = 0; i &lt; local_interfaces()-&gt;length(); i++) {
1393     if (local_interfaces()-&gt;at(i) == k) {
1394       return true;
1395     }
1396   }
1397   return false;
1398 }
1399 
1400 objArrayOop InstanceKlass::allocate_objArray(int n, int length, TRAPS) {
1401   check_array_allocation_length(length, arrayOopDesc::max_array_length(T_OBJECT), CHECK_NULL);
1402   int size = objArrayOopDesc::object_size(length);
1403   Klass* ak = array_klass(n, CHECK_NULL);
1404   objArrayOop o = (objArrayOop)Universe::heap()-&gt;array_allocate(ak, size, length,
1405                                                                 /* do_zero */ true, CHECK_NULL);
1406   return o;
1407 }
1408 
1409 instanceOop InstanceKlass::register_finalizer(instanceOop i, TRAPS) {
1410   if (TraceFinalizerRegistration) {
1411     tty-&gt;print(&quot;Registered &quot;);
1412     i-&gt;print_value_on(tty);
1413     tty-&gt;print_cr(&quot; (&quot; INTPTR_FORMAT &quot;) as finalizable&quot;, p2i(i));
1414   }
1415   instanceHandle h_i(THREAD, i);
1416   // Pass the handle as argument, JavaCalls::call expects oop as jobjects
1417   JavaValue result(T_VOID);
1418   JavaCallArguments args(h_i);
1419   methodHandle mh (THREAD, Universe::finalizer_register_method());
1420   JavaCalls::call(&amp;result, mh, &amp;args, CHECK_NULL);
1421   return h_i();
1422 }
1423 
1424 instanceOop InstanceKlass::allocate_instance(TRAPS) {
1425   bool has_finalizer_flag = has_finalizer(); // Query before possible GC
1426   int size = size_helper();  // Query before forming handle.
1427 
1428   instanceOop i;
1429 
1430   i = (instanceOop)Universe::heap()-&gt;obj_allocate(this, size, CHECK_NULL);
1431   if (has_finalizer_flag &amp;&amp; !RegisterFinalizersAtInit) {
1432     i = register_finalizer(i, CHECK_NULL);
1433   }
1434   return i;
1435 }
1436 
1437 instanceHandle InstanceKlass::allocate_instance_handle(TRAPS) {
1438   return instanceHandle(THREAD, allocate_instance(THREAD));
1439 }
1440 
1441 void InstanceKlass::check_valid_for_instantiation(bool throwError, TRAPS) {
1442   if (is_interface() || is_abstract()) {
1443     ResourceMark rm(THREAD);
1444     THROW_MSG(throwError ? vmSymbols::java_lang_InstantiationError()
1445               : vmSymbols::java_lang_InstantiationException(), external_name());
1446   }
1447   if (this == SystemDictionary::Class_klass()) {
1448     ResourceMark rm(THREAD);
1449     THROW_MSG(throwError ? vmSymbols::java_lang_IllegalAccessError()
1450               : vmSymbols::java_lang_IllegalAccessException(), external_name());
1451   }
1452 }
1453 
1454 Klass* InstanceKlass::array_klass_impl(bool or_null, int n, TRAPS) {
1455   // Need load-acquire for lock-free read
1456   if (array_klasses_acquire() == NULL) {
1457     if (or_null) return NULL;
1458 
1459     ResourceMark rm(THREAD);
1460     JavaThread *jt = (JavaThread *)THREAD;
1461     {
1462       // Atomic creation of array_klasses
1463       MutexLocker ma(THREAD, MultiArray_lock);
1464 
1465       // Check if update has already taken place
1466       if (array_klasses() == NULL) {
1467         Klass*    k = ObjArrayKlass::allocate_objArray_klass(1, this, CHECK_NULL);
1468         // use &#39;release&#39; to pair with lock-free load
1469         release_set_array_klasses(k);
1470       }
1471     }
1472   }
1473   // _this will always be set at this point
1474   ObjArrayKlass* oak = (ObjArrayKlass*)array_klasses();
1475   if (or_null) {
1476     return oak-&gt;array_klass_or_null(n);
1477   }
1478   return oak-&gt;array_klass(n, THREAD);
1479 }
1480 
1481 Klass* InstanceKlass::array_klass_impl(bool or_null, TRAPS) {
1482   return array_klass_impl(or_null, 1, THREAD);
1483 }
1484 
1485 static int call_class_initializer_counter = 0;   // for debugging
1486 
1487 Method* InstanceKlass::class_initializer() const {
1488   Method* clinit = find_method(
1489       vmSymbols::class_initializer_name(), vmSymbols::void_method_signature());
1490   if (clinit != NULL &amp;&amp; clinit-&gt;is_class_initializer()) {
1491     return clinit;
1492   }
1493   return NULL;
1494 }
1495 
1496 void InstanceKlass::call_class_initializer(TRAPS) {
1497   if (ReplayCompiles &amp;&amp;
1498       (ReplaySuppressInitializers == 1 ||
1499        (ReplaySuppressInitializers &gt;= 2 &amp;&amp; class_loader() != NULL))) {
1500     // Hide the existence of the initializer for the purpose of replaying the compile
1501     return;
1502   }
1503 
1504   methodHandle h_method(THREAD, class_initializer());
1505   assert(!is_initialized(), &quot;we cannot initialize twice&quot;);
1506   LogTarget(Info, class, init) lt;
1507   if (lt.is_enabled()) {
1508     ResourceMark rm(THREAD);
1509     LogStream ls(lt);
1510     ls.print(&quot;%d Initializing &quot;, call_class_initializer_counter++);
1511     name()-&gt;print_value_on(&amp;ls);
1512     ls.print_cr(&quot;%s (&quot; INTPTR_FORMAT &quot;)&quot;, h_method() == NULL ? &quot;(no method)&quot; : &quot;&quot;, p2i(this));
1513   }
1514   if (h_method() != NULL) {
1515     JavaCallArguments args; // No arguments
1516     JavaValue result(T_VOID);
1517     JavaCalls::call(&amp;result, h_method, &amp;args, CHECK); // Static call (no args)
1518   }
1519 }
1520 
1521 
1522 void InstanceKlass::mask_for(const methodHandle&amp; method, int bci,
1523   InterpreterOopMap* entry_for) {
1524   // Lazily create the _oop_map_cache at first request
1525   // Lock-free access requires load_acquire.
1526   OopMapCache* oop_map_cache = Atomic::load_acquire(&amp;_oop_map_cache);
1527   if (oop_map_cache == NULL) {
1528     MutexLocker x(OopMapCacheAlloc_lock,  Mutex::_no_safepoint_check_flag);
1529     // Check if _oop_map_cache was allocated while we were waiting for this lock
1530     if ((oop_map_cache = _oop_map_cache) == NULL) {
1531       oop_map_cache = new OopMapCache();
1532       // Ensure _oop_map_cache is stable, since it is examined without a lock
1533       Atomic::release_store(&amp;_oop_map_cache, oop_map_cache);
1534     }
1535   }
1536   // _oop_map_cache is constant after init; lookup below does its own locking.
1537   oop_map_cache-&gt;lookup(method, bci, entry_for);
1538 }
1539 
1540 bool InstanceKlass::find_local_field(Symbol* name, Symbol* sig, fieldDescriptor* fd) const {
1541   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
1542     Symbol* f_name = fs.name();
1543     Symbol* f_sig  = fs.signature();
1544     if (f_name == name &amp;&amp; f_sig == sig) {
1545       fd-&gt;reinitialize(const_cast&lt;InstanceKlass*&gt;(this), fs.index());
1546       return true;
1547     }
1548   }
1549   return false;
1550 }
1551 
1552 
1553 Klass* InstanceKlass::find_interface_field(Symbol* name, Symbol* sig, fieldDescriptor* fd) const {
1554   const int n = local_interfaces()-&gt;length();
1555   for (int i = 0; i &lt; n; i++) {
1556     Klass* intf1 = local_interfaces()-&gt;at(i);
1557     assert(intf1-&gt;is_interface(), &quot;just checking type&quot;);
1558     // search for field in current interface
1559     if (InstanceKlass::cast(intf1)-&gt;find_local_field(name, sig, fd)) {
1560       assert(fd-&gt;is_static(), &quot;interface field must be static&quot;);
1561       return intf1;
1562     }
1563     // search for field in direct superinterfaces
1564     Klass* intf2 = InstanceKlass::cast(intf1)-&gt;find_interface_field(name, sig, fd);
1565     if (intf2 != NULL) return intf2;
1566   }
1567   // otherwise field lookup fails
1568   return NULL;
1569 }
1570 
1571 
1572 Klass* InstanceKlass::find_field(Symbol* name, Symbol* sig, fieldDescriptor* fd) const {
1573   // search order according to newest JVM spec (5.4.3.2, p.167).
1574   // 1) search for field in current klass
1575   if (find_local_field(name, sig, fd)) {
1576     return const_cast&lt;InstanceKlass*&gt;(this);
1577   }
1578   // 2) search for field recursively in direct superinterfaces
1579   { Klass* intf = find_interface_field(name, sig, fd);
1580     if (intf != NULL) return intf;
1581   }
1582   // 3) apply field lookup recursively if superclass exists
1583   { Klass* supr = super();
1584     if (supr != NULL) return InstanceKlass::cast(supr)-&gt;find_field(name, sig, fd);
1585   }
1586   // 4) otherwise field lookup fails
1587   return NULL;
1588 }
1589 
1590 
1591 Klass* InstanceKlass::find_field(Symbol* name, Symbol* sig, bool is_static, fieldDescriptor* fd) const {
1592   // search order according to newest JVM spec (5.4.3.2, p.167).
1593   // 1) search for field in current klass
1594   if (find_local_field(name, sig, fd)) {
1595     if (fd-&gt;is_static() == is_static) return const_cast&lt;InstanceKlass*&gt;(this);
1596   }
1597   // 2) search for field recursively in direct superinterfaces
1598   if (is_static) {
1599     Klass* intf = find_interface_field(name, sig, fd);
1600     if (intf != NULL) return intf;
1601   }
1602   // 3) apply field lookup recursively if superclass exists
1603   { Klass* supr = super();
1604     if (supr != NULL) return InstanceKlass::cast(supr)-&gt;find_field(name, sig, is_static, fd);
1605   }
1606   // 4) otherwise field lookup fails
1607   return NULL;
1608 }
1609 
1610 bool InstanceKlass::contains_field_offset(int offset) {
1611   if (this-&gt;is_value()) {
1612     ValueKlass* vk = ValueKlass::cast(this);
1613     return offset &gt;= vk-&gt;first_field_offset() &amp;&amp; offset &lt; (vk-&gt;first_field_offset() + vk-&gt;get_exact_size_in_bytes());
1614   } else {
1615     fieldDescriptor fd;
1616     return find_field_from_offset(offset, false, &amp;fd);
1617   }
1618 }
1619 
1620 bool InstanceKlass::find_local_field_from_offset(int offset, bool is_static, fieldDescriptor* fd) const {
1621   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
1622     if (fs.offset() == offset) {
1623       fd-&gt;reinitialize(const_cast&lt;InstanceKlass*&gt;(this), fs.index());
1624       if (fd-&gt;is_static() == is_static) return true;
1625     }
1626   }
1627   return false;
1628 }
1629 
1630 
1631 bool InstanceKlass::find_field_from_offset(int offset, bool is_static, fieldDescriptor* fd) const {
1632   Klass* klass = const_cast&lt;InstanceKlass*&gt;(this);
1633   while (klass != NULL) {
1634     if (InstanceKlass::cast(klass)-&gt;find_local_field_from_offset(offset, is_static, fd)) {
1635       return true;
1636     }
1637     klass = klass-&gt;super();
1638   }
1639   return false;
1640 }
1641 
1642 
1643 void InstanceKlass::methods_do(void f(Method* method)) {
1644   // Methods aren&#39;t stable until they are loaded.  This can be read outside
1645   // a lock through the ClassLoaderData for profiling
1646   if (!is_loaded()) {
1647     return;
1648   }
1649 
1650   int len = methods()-&gt;length();
1651   for (int index = 0; index &lt; len; index++) {
1652     Method* m = methods()-&gt;at(index);
1653     assert(m-&gt;is_method(), &quot;must be method&quot;);
1654     f(m);
1655   }
1656 }
1657 
1658 
1659 void InstanceKlass::do_local_static_fields(FieldClosure* cl) {
1660   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
1661     if (fs.access_flags().is_static()) {
1662       fieldDescriptor&amp; fd = fs.field_descriptor();
1663       cl-&gt;do_field(&amp;fd);
1664     }
1665   }
1666 }
1667 
1668 
1669 void InstanceKlass::do_local_static_fields(void f(fieldDescriptor*, Handle, TRAPS), Handle mirror, TRAPS) {
1670   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
1671     if (fs.access_flags().is_static()) {
1672       fieldDescriptor&amp; fd = fs.field_descriptor();
1673       f(&amp;fd, mirror, CHECK);
1674     }
1675   }
1676 }
1677 
1678 
1679 static int compare_fields_by_offset(int* a, int* b) {
1680   return a[0] - b[0];
1681 }
1682 
1683 void InstanceKlass::do_nonstatic_fields(FieldClosure* cl) {
1684   InstanceKlass* super = superklass();
1685   if (super != NULL) {
1686     super-&gt;do_nonstatic_fields(cl);
1687   }
1688   fieldDescriptor fd;
1689   int length = java_fields_count();
1690   // In DebugInfo nonstatic fields are sorted by offset.
1691   int* fields_sorted = NEW_C_HEAP_ARRAY(int, 2*(length+1), mtClass);
1692   int j = 0;
1693   for (int i = 0; i &lt; length; i += 1) {
1694     fd.reinitialize(this, i);
1695     if (!fd.is_static()) {
1696       fields_sorted[j + 0] = fd.offset();
1697       fields_sorted[j + 1] = i;
1698       j += 2;
1699     }
1700   }
1701   if (j &gt; 0) {
1702     length = j;
1703     // _sort_Fn is defined in growableArray.hpp.
1704     qsort(fields_sorted, length/2, 2*sizeof(int), (_sort_Fn)compare_fields_by_offset);
1705     for (int i = 0; i &lt; length; i += 2) {
1706       fd.reinitialize(this, fields_sorted[i + 1]);
1707       assert(!fd.is_static() &amp;&amp; fd.offset() == fields_sorted[i], &quot;only nonstatic fields&quot;);
1708       cl-&gt;do_field(&amp;fd);
1709     }
1710   }
1711   FREE_C_HEAP_ARRAY(int, fields_sorted);
1712 }
1713 
1714 
1715 void InstanceKlass::array_klasses_do(void f(Klass* k)) {
1716   if (array_klasses() != NULL)
1717     ArrayKlass::cast(array_klasses())-&gt;array_klasses_do(f);
1718 }
1719 
1720 #ifdef ASSERT
1721 static int linear_search(const Array&lt;Method*&gt;* methods,
1722                          const Symbol* name,
1723                          const Symbol* signature) {
1724   const int len = methods-&gt;length();
1725   for (int index = 0; index &lt; len; index++) {
1726     const Method* const m = methods-&gt;at(index);
1727     assert(m-&gt;is_method(), &quot;must be method&quot;);
1728     if (m-&gt;signature() == signature &amp;&amp; m-&gt;name() == name) {
1729        return index;
1730     }
1731   }
1732   return -1;
1733 }
1734 #endif
1735 
1736 bool InstanceKlass::_disable_method_binary_search = false;
1737 
1738 NOINLINE int linear_search(const Array&lt;Method*&gt;* methods, const Symbol* name) {
1739   int len = methods-&gt;length();
1740   int l = 0;
1741   int h = len - 1;
1742   while (l &lt;= h) {
1743     Method* m = methods-&gt;at(l);
1744     if (m-&gt;name() == name) {
1745       return l;
1746     }
1747     l++;
1748   }
1749   return -1;
1750 }
1751 
1752 inline int InstanceKlass::quick_search(const Array&lt;Method*&gt;* methods, const Symbol* name) {
1753   if (_disable_method_binary_search) {
1754     assert(DynamicDumpSharedSpaces, &quot;must be&quot;);
1755     // At the final stage of dynamic dumping, the methods array may not be sorted
1756     // by ascending addresses of their names, so we can&#39;t use binary search anymore.
1757     // However, methods with the same name are still laid out consecutively inside the
1758     // methods array, so let&#39;s look for the first one that matches.
1759     return linear_search(methods, name);
1760   }
1761 
1762   int len = methods-&gt;length();
1763   int l = 0;
1764   int h = len - 1;
1765 
1766   // methods are sorted by ascending addresses of their names, so do binary search
1767   while (l &lt;= h) {
1768     int mid = (l + h) &gt;&gt; 1;
1769     Method* m = methods-&gt;at(mid);
1770     assert(m-&gt;is_method(), &quot;must be method&quot;);
1771     int res = m-&gt;name()-&gt;fast_compare(name);
1772     if (res == 0) {
1773       return mid;
1774     } else if (res &lt; 0) {
1775       l = mid + 1;
1776     } else {
1777       h = mid - 1;
1778     }
1779   }
1780   return -1;
1781 }
1782 
1783 // find_method looks up the name/signature in the local methods array
1784 Method* InstanceKlass::find_method(const Symbol* name,
1785                                    const Symbol* signature) const {
1786   return find_method_impl(name, signature, find_overpass, find_static, find_private);
1787 }
1788 
1789 Method* InstanceKlass::find_method_impl(const Symbol* name,
1790                                         const Symbol* signature,
1791                                         OverpassLookupMode overpass_mode,
1792                                         StaticLookupMode static_mode,
1793                                         PrivateLookupMode private_mode) const {
1794   return InstanceKlass::find_method_impl(methods(),
1795                                          name,
1796                                          signature,
1797                                          overpass_mode,
1798                                          static_mode,
1799                                          private_mode);
1800 }
1801 
1802 // find_instance_method looks up the name/signature in the local methods array
1803 // and skips over static methods
1804 Method* InstanceKlass::find_instance_method(const Array&lt;Method*&gt;* methods,
1805                                             const Symbol* name,
1806                                             const Symbol* signature,
1807                                             PrivateLookupMode private_mode) {
1808   Method* const meth = InstanceKlass::find_method_impl(methods,
1809                                                  name,
1810                                                  signature,
1811                                                  find_overpass,
1812                                                  skip_static,
1813                                                  private_mode);
1814   assert(((meth == NULL) || !meth-&gt;is_static()),
1815     &quot;find_instance_method should have skipped statics&quot;);
1816   return meth;
1817 }
1818 
1819 // find_instance_method looks up the name/signature in the local methods array
1820 // and skips over static methods
1821 Method* InstanceKlass::find_instance_method(const Symbol* name,
1822                                             const Symbol* signature,
1823                                             PrivateLookupMode private_mode) const {
1824   return InstanceKlass::find_instance_method(methods(), name, signature, private_mode);
1825 }
1826 
1827 // Find looks up the name/signature in the local methods array
1828 // and filters on the overpass, static and private flags
1829 // This returns the first one found
1830 // note that the local methods array can have up to one overpass, one static
1831 // and one instance (private or not) with the same name/signature
1832 Method* InstanceKlass::find_local_method(const Symbol* name,
1833                                          const Symbol* signature,
1834                                          OverpassLookupMode overpass_mode,
1835                                          StaticLookupMode static_mode,
1836                                          PrivateLookupMode private_mode) const {
1837   return InstanceKlass::find_method_impl(methods(),
1838                                          name,
1839                                          signature,
1840                                          overpass_mode,
1841                                          static_mode,
1842                                          private_mode);
1843 }
1844 
1845 // Find looks up the name/signature in the local methods array
1846 // and filters on the overpass, static and private flags
1847 // This returns the first one found
1848 // note that the local methods array can have up to one overpass, one static
1849 // and one instance (private or not) with the same name/signature
1850 Method* InstanceKlass::find_local_method(const Array&lt;Method*&gt;* methods,
1851                                          const Symbol* name,
1852                                          const Symbol* signature,
1853                                          OverpassLookupMode overpass_mode,
1854                                          StaticLookupMode static_mode,
1855                                          PrivateLookupMode private_mode) {
1856   return InstanceKlass::find_method_impl(methods,
1857                                          name,
1858                                          signature,
1859                                          overpass_mode,
1860                                          static_mode,
1861                                          private_mode);
1862 }
1863 
1864 Method* InstanceKlass::find_method(const Array&lt;Method*&gt;* methods,
1865                                    const Symbol* name,
1866                                    const Symbol* signature) {
1867   return InstanceKlass::find_method_impl(methods,
1868                                          name,
1869                                          signature,
1870                                          find_overpass,
1871                                          find_static,
1872                                          find_private);
1873 }
1874 
1875 Method* InstanceKlass::find_method_impl(const Array&lt;Method*&gt;* methods,
1876                                         const Symbol* name,
1877                                         const Symbol* signature,
1878                                         OverpassLookupMode overpass_mode,
1879                                         StaticLookupMode static_mode,
1880                                         PrivateLookupMode private_mode) {
1881   int hit = find_method_index(methods, name, signature, overpass_mode, static_mode, private_mode);
1882   return hit &gt;= 0 ? methods-&gt;at(hit): NULL;
1883 }
1884 
1885 // true if method matches signature and conforms to skipping_X conditions.
1886 static bool method_matches(const Method* m,
1887                            const Symbol* signature,
1888                            bool skipping_overpass,
1889                            bool skipping_static,
1890                            bool skipping_private) {
1891   return ((m-&gt;signature() == signature) &amp;&amp;
1892     (!skipping_overpass || !m-&gt;is_overpass()) &amp;&amp;
1893     (!skipping_static || !m-&gt;is_static()) &amp;&amp;
1894     (!skipping_private || !m-&gt;is_private()));
1895 }
1896 
1897 // Used directly for default_methods to find the index into the
1898 // default_vtable_indices, and indirectly by find_method
1899 // find_method_index looks in the local methods array to return the index
1900 // of the matching name/signature. If, overpass methods are being ignored,
1901 // the search continues to find a potential non-overpass match.  This capability
1902 // is important during method resolution to prefer a static method, for example,
1903 // over an overpass method.
1904 // There is the possibility in any _method&#39;s array to have the same name/signature
1905 // for a static method, an overpass method and a local instance method
1906 // To correctly catch a given method, the search criteria may need
1907 // to explicitly skip the other two. For local instance methods, it
1908 // is often necessary to skip private methods
1909 int InstanceKlass::find_method_index(const Array&lt;Method*&gt;* methods,
1910                                      const Symbol* name,
1911                                      const Symbol* signature,
1912                                      OverpassLookupMode overpass_mode,
1913                                      StaticLookupMode static_mode,
1914                                      PrivateLookupMode private_mode) {
1915   const bool skipping_overpass = (overpass_mode == skip_overpass);
1916   const bool skipping_static = (static_mode == skip_static);
1917   const bool skipping_private = (private_mode == skip_private);
1918   const int hit = quick_search(methods, name);
1919   if (hit != -1) {
1920     const Method* const m = methods-&gt;at(hit);
1921 
1922     // Do linear search to find matching signature.  First, quick check
1923     // for common case, ignoring overpasses if requested.
1924     if (method_matches(m, signature, skipping_overpass, skipping_static, skipping_private)) {
1925       return hit;
1926     }
1927 
1928     // search downwards through overloaded methods
1929     int i;
1930     for (i = hit - 1; i &gt;= 0; --i) {
1931         const Method* const m = methods-&gt;at(i);
1932         assert(m-&gt;is_method(), &quot;must be method&quot;);
1933         if (m-&gt;name() != name) {
1934           break;
1935         }
1936         if (method_matches(m, signature, skipping_overpass, skipping_static, skipping_private)) {
1937           return i;
1938         }
1939     }
1940     // search upwards
1941     for (i = hit + 1; i &lt; methods-&gt;length(); ++i) {
1942         const Method* const m = methods-&gt;at(i);
1943         assert(m-&gt;is_method(), &quot;must be method&quot;);
1944         if (m-&gt;name() != name) {
1945           break;
1946         }
1947         if (method_matches(m, signature, skipping_overpass, skipping_static, skipping_private)) {
1948           return i;
1949         }
1950     }
1951     // not found
1952 #ifdef ASSERT
1953     const int index = (skipping_overpass || skipping_static || skipping_private) ? -1 :
1954       linear_search(methods, name, signature);
1955     assert(-1 == index, &quot;binary search should have found entry %d&quot;, index);
1956 #endif
1957   }
1958   return -1;
1959 }
1960 
1961 int InstanceKlass::find_method_by_name(const Symbol* name, int* end) const {
1962   return find_method_by_name(methods(), name, end);
1963 }
1964 
1965 int InstanceKlass::find_method_by_name(const Array&lt;Method*&gt;* methods,
1966                                        const Symbol* name,
1967                                        int* end_ptr) {
1968   assert(end_ptr != NULL, &quot;just checking&quot;);
1969   int start = quick_search(methods, name);
1970   int end = start + 1;
1971   if (start != -1) {
1972     while (start - 1 &gt;= 0 &amp;&amp; (methods-&gt;at(start - 1))-&gt;name() == name) --start;
1973     while (end &lt; methods-&gt;length() &amp;&amp; (methods-&gt;at(end))-&gt;name() == name) ++end;
1974     *end_ptr = end;
1975     return start;
1976   }
1977   return -1;
1978 }
1979 
1980 // uncached_lookup_method searches both the local class methods array and all
1981 // superclasses methods arrays, skipping any overpass methods in superclasses,
1982 // and possibly skipping private methods.
1983 Method* InstanceKlass::uncached_lookup_method(const Symbol* name,
1984                                               const Symbol* signature,
1985                                               OverpassLookupMode overpass_mode,
1986                                               PrivateLookupMode private_mode) const {
1987   OverpassLookupMode overpass_local_mode = overpass_mode;
1988   const Klass* klass = this;
1989   while (klass != NULL) {
1990     Method* const method = InstanceKlass::cast(klass)-&gt;find_method_impl(name,
1991                                                                         signature,
1992                                                                         overpass_local_mode,
1993                                                                         find_static,
1994                                                                         private_mode);
1995     if (method != NULL) {
1996       return method;
1997     }
1998     if (name == vmSymbols::object_initializer_name()) {
1999       break;  // &lt;init&gt; is never inherited, not even as a static factory
2000     }
2001     klass = klass-&gt;super();
2002     overpass_local_mode = skip_overpass;   // Always ignore overpass methods in superclasses
2003   }
2004   return NULL;
2005 }
2006 
2007 #ifdef ASSERT
2008 // search through class hierarchy and return true if this class or
2009 // one of the superclasses was redefined
2010 bool InstanceKlass::has_redefined_this_or_super() const {
2011   const Klass* klass = this;
2012   while (klass != NULL) {
2013     if (InstanceKlass::cast(klass)-&gt;has_been_redefined()) {
2014       return true;
2015     }
2016     klass = klass-&gt;super();
2017   }
2018   return false;
2019 }
2020 #endif
2021 
2022 // lookup a method in the default methods list then in all transitive interfaces
2023 // Do NOT return private or static methods
2024 Method* InstanceKlass::lookup_method_in_ordered_interfaces(Symbol* name,
2025                                                          Symbol* signature) const {
2026   Method* m = NULL;
2027   if (default_methods() != NULL) {
2028     m = find_method(default_methods(), name, signature);
2029   }
2030   // Look up interfaces
2031   if (m == NULL) {
2032     m = lookup_method_in_all_interfaces(name, signature, find_defaults);
2033   }
2034   return m;
2035 }
2036 
2037 // lookup a method in all the interfaces that this class implements
2038 // Do NOT return private or static methods, new in JDK8 which are not externally visible
2039 // They should only be found in the initial InterfaceMethodRef
2040 Method* InstanceKlass::lookup_method_in_all_interfaces(Symbol* name,
2041                                                        Symbol* signature,
2042                                                        DefaultsLookupMode defaults_mode) const {
2043   Array&lt;InstanceKlass*&gt;* all_ifs = transitive_interfaces();
2044   int num_ifs = all_ifs-&gt;length();
2045   InstanceKlass *ik = NULL;
2046   for (int i = 0; i &lt; num_ifs; i++) {
2047     ik = all_ifs-&gt;at(i);
2048     Method* m = ik-&gt;lookup_method(name, signature);
2049     if (m != NULL &amp;&amp; m-&gt;is_public() &amp;&amp; !m-&gt;is_static() &amp;&amp;
2050         ((defaults_mode != skip_defaults) || !m-&gt;is_default_method())) {
2051       return m;
2052     }
2053   }
2054   return NULL;
2055 }
2056 
2057 /* jni_id_for_impl for jfieldIds only */
2058 JNIid* InstanceKlass::jni_id_for_impl(int offset) {
2059   MutexLocker ml(JfieldIdCreation_lock);
2060   // Retry lookup after we got the lock
2061   JNIid* probe = jni_ids() == NULL ? NULL : jni_ids()-&gt;find(offset);
2062   if (probe == NULL) {
2063     // Slow case, allocate new static field identifier
2064     probe = new JNIid(this, offset, jni_ids());
2065     set_jni_ids(probe);
2066   }
2067   return probe;
2068 }
2069 
2070 
2071 /* jni_id_for for jfieldIds only */
2072 JNIid* InstanceKlass::jni_id_for(int offset) {
2073   JNIid* probe = jni_ids() == NULL ? NULL : jni_ids()-&gt;find(offset);
2074   if (probe == NULL) {
2075     probe = jni_id_for_impl(offset);
2076   }
2077   return probe;
2078 }
2079 
2080 u2 InstanceKlass::enclosing_method_data(int offset) const {
2081   const Array&lt;jushort&gt;* const inner_class_list = inner_classes();
2082   if (inner_class_list == NULL) {
2083     return 0;
2084   }
2085   const int length = inner_class_list-&gt;length();
2086   if (length % inner_class_next_offset == 0) {
2087     return 0;
2088   }
2089   const int index = length - enclosing_method_attribute_size;
2090   assert(offset &lt; enclosing_method_attribute_size, &quot;invalid offset&quot;);
2091   return inner_class_list-&gt;at(index + offset);
2092 }
2093 
2094 void InstanceKlass::set_enclosing_method_indices(u2 class_index,
2095                                                  u2 method_index) {
2096   Array&lt;jushort&gt;* inner_class_list = inner_classes();
2097   assert (inner_class_list != NULL, &quot;_inner_classes list is not set up&quot;);
2098   int length = inner_class_list-&gt;length();
2099   if (length % inner_class_next_offset == enclosing_method_attribute_size) {
2100     int index = length - enclosing_method_attribute_size;
2101     inner_class_list-&gt;at_put(
2102       index + enclosing_method_class_index_offset, class_index);
2103     inner_class_list-&gt;at_put(
2104       index + enclosing_method_method_index_offset, method_index);
2105   }
2106 }
2107 
2108 // Lookup or create a jmethodID.
2109 // This code is called by the VMThread and JavaThreads so the
2110 // locking has to be done very carefully to avoid deadlocks
2111 // and/or other cache consistency problems.
2112 //
2113 jmethodID InstanceKlass::get_jmethod_id(const methodHandle&amp; method_h) {
2114   size_t idnum = (size_t)method_h-&gt;method_idnum();
2115   jmethodID* jmeths = methods_jmethod_ids_acquire();
2116   size_t length = 0;
2117   jmethodID id = NULL;
2118 
2119   // We use a double-check locking idiom here because this cache is
2120   // performance sensitive. In the normal system, this cache only
2121   // transitions from NULL to non-NULL which is safe because we use
2122   // release_set_methods_jmethod_ids() to advertise the new cache.
2123   // A partially constructed cache should never be seen by a racing
2124   // thread. We also use release_store() to save a new jmethodID
2125   // in the cache so a partially constructed jmethodID should never be
2126   // seen either. Cache reads of existing jmethodIDs proceed without a
2127   // lock, but cache writes of a new jmethodID requires uniqueness and
2128   // creation of the cache itself requires no leaks so a lock is
2129   // generally acquired in those two cases.
2130   //
2131   // If the RedefineClasses() API has been used, then this cache can
2132   // grow and we&#39;ll have transitions from non-NULL to bigger non-NULL.
2133   // Cache creation requires no leaks and we require safety between all
2134   // cache accesses and freeing of the old cache so a lock is generally
2135   // acquired when the RedefineClasses() API has been used.
2136 
2137   if (jmeths != NULL) {
2138     // the cache already exists
2139     if (!idnum_can_increment()) {
2140       // the cache can&#39;t grow so we can just get the current values
2141       get_jmethod_id_length_value(jmeths, idnum, &amp;length, &amp;id);
2142     } else {
2143       // cache can grow so we have to be more careful
2144       if (Threads::number_of_threads() == 0 ||
2145           SafepointSynchronize::is_at_safepoint()) {
2146         // we&#39;re single threaded or at a safepoint - no locking needed
2147         get_jmethod_id_length_value(jmeths, idnum, &amp;length, &amp;id);
2148       } else {
2149         MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);
2150         get_jmethod_id_length_value(jmeths, idnum, &amp;length, &amp;id);
2151       }
2152     }
2153   }
2154   // implied else:
2155   // we need to allocate a cache so default length and id values are good
2156 
2157   if (jmeths == NULL ||   // no cache yet
2158       length &lt;= idnum ||  // cache is too short
2159       id == NULL) {       // cache doesn&#39;t contain entry
2160 
2161     // This function can be called by the VMThread so we have to do all
2162     // things that might block on a safepoint before grabbing the lock.
2163     // Otherwise, we can deadlock with the VMThread or have a cache
2164     // consistency issue. These vars keep track of what we might have
2165     // to free after the lock is dropped.
2166     jmethodID  to_dealloc_id     = NULL;
2167     jmethodID* to_dealloc_jmeths = NULL;
2168 
2169     // may not allocate new_jmeths or use it if we allocate it
2170     jmethodID* new_jmeths = NULL;
2171     if (length &lt;= idnum) {
2172       // allocate a new cache that might be used
2173       size_t size = MAX2(idnum+1, (size_t)idnum_allocated_count());
2174       new_jmeths = NEW_C_HEAP_ARRAY(jmethodID, size+1, mtClass);
2175       memset(new_jmeths, 0, (size+1)*sizeof(jmethodID));
2176       // cache size is stored in element[0], other elements offset by one
2177       new_jmeths[0] = (jmethodID)size;
2178     }
2179 
2180     // allocate a new jmethodID that might be used
2181     jmethodID new_id = NULL;
2182     if (method_h-&gt;is_old() &amp;&amp; !method_h-&gt;is_obsolete()) {
2183       // The method passed in is old (but not obsolete), we need to use the current version
2184       Method* current_method = method_with_idnum((int)idnum);
2185       assert(current_method != NULL, &quot;old and but not obsolete, so should exist&quot;);
2186       new_id = Method::make_jmethod_id(class_loader_data(), current_method);
2187     } else {
2188       // It is the current version of the method or an obsolete method,
2189       // use the version passed in
2190       new_id = Method::make_jmethod_id(class_loader_data(), method_h());
2191     }
2192 
2193     if (Threads::number_of_threads() == 0 ||
2194         SafepointSynchronize::is_at_safepoint()) {
2195       // we&#39;re single threaded or at a safepoint - no locking needed
2196       id = get_jmethod_id_fetch_or_update(idnum, new_id, new_jmeths,
2197                                           &amp;to_dealloc_id, &amp;to_dealloc_jmeths);
2198     } else {
2199       MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);
2200       id = get_jmethod_id_fetch_or_update(idnum, new_id, new_jmeths,
2201                                           &amp;to_dealloc_id, &amp;to_dealloc_jmeths);
2202     }
2203 
2204     // The lock has been dropped so we can free resources.
2205     // Free up either the old cache or the new cache if we allocated one.
2206     if (to_dealloc_jmeths != NULL) {
2207       FreeHeap(to_dealloc_jmeths);
2208     }
2209     // free up the new ID since it wasn&#39;t needed
2210     if (to_dealloc_id != NULL) {
2211       Method::destroy_jmethod_id(class_loader_data(), to_dealloc_id);
2212     }
2213   }
2214   return id;
2215 }
2216 
2217 // Figure out how many jmethodIDs haven&#39;t been allocated, and make
2218 // sure space for them is pre-allocated.  This makes getting all
2219 // method ids much, much faster with classes with more than 8
2220 // methods, and has a *substantial* effect on performance with jvmti
2221 // code that loads all jmethodIDs for all classes.
2222 void InstanceKlass::ensure_space_for_methodids(int start_offset) {
2223   int new_jmeths = 0;
2224   int length = methods()-&gt;length();
2225   for (int index = start_offset; index &lt; length; index++) {
2226     Method* m = methods()-&gt;at(index);
2227     jmethodID id = m-&gt;find_jmethod_id_or_null();
2228     if (id == NULL) {
2229       new_jmeths++;
2230     }
2231   }
2232   if (new_jmeths != 0) {
2233     Method::ensure_jmethod_ids(class_loader_data(), new_jmeths);
2234   }
2235 }
2236 
2237 // Common code to fetch the jmethodID from the cache or update the
2238 // cache with the new jmethodID. This function should never do anything
2239 // that causes the caller to go to a safepoint or we can deadlock with
2240 // the VMThread or have cache consistency issues.
2241 //
2242 jmethodID InstanceKlass::get_jmethod_id_fetch_or_update(
2243             size_t idnum, jmethodID new_id,
2244             jmethodID* new_jmeths, jmethodID* to_dealloc_id_p,
2245             jmethodID** to_dealloc_jmeths_p) {
2246   assert(new_id != NULL, &quot;sanity check&quot;);
2247   assert(to_dealloc_id_p != NULL, &quot;sanity check&quot;);
2248   assert(to_dealloc_jmeths_p != NULL, &quot;sanity check&quot;);
2249   assert(Threads::number_of_threads() == 0 ||
2250          SafepointSynchronize::is_at_safepoint() ||
2251          JmethodIdCreation_lock-&gt;owned_by_self(), &quot;sanity check&quot;);
2252 
2253   // reacquire the cache - we are locked, single threaded or at a safepoint
2254   jmethodID* jmeths = methods_jmethod_ids_acquire();
2255   jmethodID  id     = NULL;
2256   size_t     length = 0;
2257 
2258   if (jmeths == NULL ||                         // no cache yet
2259       (length = (size_t)jmeths[0]) &lt;= idnum) {  // cache is too short
2260     if (jmeths != NULL) {
2261       // copy any existing entries from the old cache
2262       for (size_t index = 0; index &lt; length; index++) {
2263         new_jmeths[index+1] = jmeths[index+1];
2264       }
2265       *to_dealloc_jmeths_p = jmeths;  // save old cache for later delete
2266     }
2267     release_set_methods_jmethod_ids(jmeths = new_jmeths);
2268   } else {
2269     // fetch jmethodID (if any) from the existing cache
2270     id = jmeths[idnum+1];
2271     *to_dealloc_jmeths_p = new_jmeths;  // save new cache for later delete
2272   }
2273   if (id == NULL) {
2274     // No matching jmethodID in the existing cache or we have a new
2275     // cache or we just grew the cache. This cache write is done here
2276     // by the first thread to win the foot race because a jmethodID
2277     // needs to be unique once it is generally available.
2278     id = new_id;
2279 
2280     // The jmethodID cache can be read while unlocked so we have to
2281     // make sure the new jmethodID is complete before installing it
2282     // in the cache.
2283     Atomic::release_store(&amp;jmeths[idnum+1], id);
2284   } else {
2285     *to_dealloc_id_p = new_id; // save new id for later delete
2286   }
2287   return id;
2288 }
2289 
2290 
2291 // Common code to get the jmethodID cache length and the jmethodID
2292 // value at index idnum if there is one.
2293 //
2294 void InstanceKlass::get_jmethod_id_length_value(jmethodID* cache,
2295        size_t idnum, size_t *length_p, jmethodID* id_p) {
2296   assert(cache != NULL, &quot;sanity check&quot;);
2297   assert(length_p != NULL, &quot;sanity check&quot;);
2298   assert(id_p != NULL, &quot;sanity check&quot;);
2299 
2300   // cache size is stored in element[0], other elements offset by one
2301   *length_p = (size_t)cache[0];
2302   if (*length_p &lt;= idnum) {  // cache is too short
2303     *id_p = NULL;
2304   } else {
2305     *id_p = cache[idnum+1];  // fetch jmethodID (if any)
2306   }
2307 }
2308 
2309 
2310 // Lookup a jmethodID, NULL if not found.  Do no blocking, no allocations, no handles
2311 jmethodID InstanceKlass::jmethod_id_or_null(Method* method) {
2312   size_t idnum = (size_t)method-&gt;method_idnum();
2313   jmethodID* jmeths = methods_jmethod_ids_acquire();
2314   size_t length;                                // length assigned as debugging crumb
2315   jmethodID id = NULL;
2316   if (jmeths != NULL &amp;&amp;                         // If there is a cache
2317       (length = (size_t)jmeths[0]) &gt; idnum) {   // and if it is long enough,
2318     id = jmeths[idnum+1];                       // Look up the id (may be NULL)
2319   }
2320   return id;
2321 }
2322 
2323 inline DependencyContext InstanceKlass::dependencies() {
2324   DependencyContext dep_context(&amp;_dep_context, &amp;_dep_context_last_cleaned);
2325   return dep_context;
2326 }
2327 
2328 int InstanceKlass::mark_dependent_nmethods(KlassDepChange&amp; changes) {
2329   return dependencies().mark_dependent_nmethods(changes);
2330 }
2331 
2332 void InstanceKlass::add_dependent_nmethod(nmethod* nm) {
2333   dependencies().add_dependent_nmethod(nm);
2334 }
2335 
2336 void InstanceKlass::remove_dependent_nmethod(nmethod* nm) {
2337   dependencies().remove_dependent_nmethod(nm);
2338 }
2339 
2340 void InstanceKlass::clean_dependency_context() {
2341   dependencies().clean_unloading_dependents();
2342 }
2343 
2344 #ifndef PRODUCT
2345 void InstanceKlass::print_dependent_nmethods(bool verbose) {
2346   dependencies().print_dependent_nmethods(verbose);
2347 }
2348 
2349 bool InstanceKlass::is_dependent_nmethod(nmethod* nm) {
2350   return dependencies().is_dependent_nmethod(nm);
2351 }
2352 #endif //PRODUCT
2353 
2354 void InstanceKlass::clean_weak_instanceklass_links() {
2355   clean_implementors_list();
2356   clean_method_data();
2357 }
2358 
2359 void InstanceKlass::clean_implementors_list() {
2360   assert(is_loader_alive(), &quot;this klass should be live&quot;);
2361   if (is_interface()) {
2362     assert (ClassUnloading, &quot;only called for ClassUnloading&quot;);
2363     for (;;) {
2364       // Use load_acquire due to competing with inserts
2365       Klass* impl = Atomic::load_acquire(adr_implementor());
2366       if (impl != NULL &amp;&amp; !impl-&gt;is_loader_alive()) {
2367         // NULL this field, might be an unloaded klass or NULL
2368         Klass* volatile* klass = adr_implementor();
2369         if (Atomic::cmpxchg(klass, impl, (Klass*)NULL) == impl) {
2370           // Successfully unlinking implementor.
2371           if (log_is_enabled(Trace, class, unload)) {
2372             ResourceMark rm;
2373             log_trace(class, unload)(&quot;unlinking class (implementor): %s&quot;, impl-&gt;external_name());
2374           }
2375           return;
2376         }
2377       } else {
2378         return;
2379       }
2380     }
2381   }
2382 }
2383 
2384 void InstanceKlass::clean_method_data() {
2385   for (int m = 0; m &lt; methods()-&gt;length(); m++) {
2386     MethodData* mdo = methods()-&gt;at(m)-&gt;method_data();
2387     if (mdo != NULL) {
2388       MutexLocker ml(SafepointSynchronize::is_at_safepoint() ? NULL : mdo-&gt;extra_data_lock());
2389       mdo-&gt;clean_method_data(/*always_clean*/false);
2390     }
2391   }
2392 }
2393 
2394 bool InstanceKlass::supers_have_passed_fingerprint_checks() {
2395   if (java_super() != NULL &amp;&amp; !java_super()-&gt;has_passed_fingerprint_check()) {
2396     ResourceMark rm;
2397     log_trace(class, fingerprint)(&quot;%s : super %s not fingerprinted&quot;, external_name(), java_super()-&gt;external_name());
2398     return false;
2399   }
2400 
2401   Array&lt;InstanceKlass*&gt;* local_interfaces = this-&gt;local_interfaces();
2402   if (local_interfaces != NULL) {
2403     int length = local_interfaces-&gt;length();
2404     for (int i = 0; i &lt; length; i++) {
2405       InstanceKlass* intf = local_interfaces-&gt;at(i);
2406       if (!intf-&gt;has_passed_fingerprint_check()) {
2407         ResourceMark rm;
2408         log_trace(class, fingerprint)(&quot;%s : interface %s not fingerprinted&quot;, external_name(), intf-&gt;external_name());
2409         return false;
2410       }
2411     }
2412   }
2413 
2414   return true;
2415 }
2416 
2417 bool InstanceKlass::should_store_fingerprint(bool is_unsafe_anonymous) {
2418 #if INCLUDE_AOT
2419   // We store the fingerprint into the InstanceKlass only in the following 2 cases:
2420   if (CalculateClassFingerprint) {
2421     // (1) We are running AOT to generate a shared library.
2422     return true;
2423   }
2424   if (Arguments::is_dumping_archive()) {
2425     // (2) We are running -Xshare:dump or -XX:ArchiveClassesAtExit to create a shared archive
2426     return true;
2427   }
2428   if (UseAOT &amp;&amp; is_unsafe_anonymous) {
2429     // (3) We are using AOT code from a shared library and see an unsafe anonymous class
2430     return true;
2431   }
2432 #endif
2433 
2434   // In all other cases we might set the _misc_has_passed_fingerprint_check bit,
2435   // but do not store the 64-bit fingerprint to save space.
2436   return false;
2437 }
2438 
2439 bool InstanceKlass::has_stored_fingerprint() const {
2440 #if INCLUDE_AOT
2441   return should_store_fingerprint() || is_shared();
2442 #else
2443   return false;
2444 #endif
2445 }
2446 
2447 uint64_t InstanceKlass::get_stored_fingerprint() const {
2448   address adr = adr_fingerprint();
2449   if (adr != NULL) {
2450     return (uint64_t)Bytes::get_native_u8(adr); // adr may not be 64-bit aligned
2451   }
2452   return 0;
2453 }
2454 
2455 void InstanceKlass::store_fingerprint(uint64_t fingerprint) {
2456   address adr = adr_fingerprint();
2457   if (adr != NULL) {
2458     Bytes::put_native_u8(adr, (u8)fingerprint); // adr may not be 64-bit aligned
2459 
2460     ResourceMark rm;
2461     log_trace(class, fingerprint)(&quot;stored as &quot; PTR64_FORMAT &quot; for class %s&quot;, fingerprint, external_name());
2462   }
2463 }
2464 
2465 void InstanceKlass::metaspace_pointers_do(MetaspaceClosure* it) {
2466   Klass::metaspace_pointers_do(it);
2467 
2468   if (log_is_enabled(Trace, cds)) {
2469     ResourceMark rm;
2470     log_trace(cds)(&quot;Iter(InstanceKlass): %p (%s)&quot;, this, external_name());
2471   }
2472 
2473   it-&gt;push(&amp;_annotations);
2474   it-&gt;push((Klass**)&amp;_array_klasses);
2475   it-&gt;push(&amp;_constants);
2476   it-&gt;push(&amp;_inner_classes);
2477   it-&gt;push(&amp;_array_name);
2478 #if INCLUDE_JVMTI
2479   it-&gt;push(&amp;_previous_versions);
2480 #endif
2481   it-&gt;push(&amp;_methods);
2482   it-&gt;push(&amp;_default_methods);
2483   it-&gt;push(&amp;_local_interfaces);
2484   it-&gt;push(&amp;_transitive_interfaces);
2485   it-&gt;push(&amp;_method_ordering);
2486   it-&gt;push(&amp;_default_vtable_indices);
2487   it-&gt;push(&amp;_fields);
2488 
2489   if (itable_length() &gt; 0) {
2490     itableOffsetEntry* ioe = (itableOffsetEntry*)start_of_itable();
2491     int method_table_offset_in_words = ioe-&gt;offset()/wordSize;
2492     int nof_interfaces = (method_table_offset_in_words - itable_offset_in_words())
2493                          / itableOffsetEntry::size();
2494 
2495     for (int i = 0; i &lt; nof_interfaces; i ++, ioe ++) {
2496       if (ioe-&gt;interface_klass() != NULL) {
2497         it-&gt;push(ioe-&gt;interface_klass_addr());
2498         itableMethodEntry* ime = ioe-&gt;first_method_entry(this);
2499         int n = klassItable::method_count_for_interface(ioe-&gt;interface_klass());
2500         for (int index = 0; index &lt; n; index ++) {
2501           it-&gt;push(ime[index].method_addr());
2502         }
2503       }
2504     }
2505   }
2506 
2507   it-&gt;push(&amp;_nest_members);
2508   it-&gt;push(&amp;_record_components);
2509 }
2510 
2511 void InstanceKlass::remove_unshareable_info() {
2512   Klass::remove_unshareable_info();
2513 
2514   if (SystemDictionaryShared::has_class_failed_verification(this)) {
2515     // Classes are attempted to link during dumping and may fail,
2516     // but these classes are still in the dictionary and class list in CLD.
2517     // If the class has failed verification, there is nothing else to remove.
2518     return;
2519   }
2520 
2521   // Reset to the &#39;allocated&#39; state to prevent any premature accessing to
2522   // a shared class at runtime while the class is still being loaded and
2523   // restored. A class&#39; init_state is set to &#39;loaded&#39; at runtime when it&#39;s
2524   // being added to class hierarchy (see SystemDictionary:::add_to_hierarchy()).
2525   _init_state = allocated;
2526 
2527   { // Otherwise this needs to take out the Compile_lock.
2528     assert(SafepointSynchronize::is_at_safepoint(), &quot;only called at safepoint&quot;);
2529     init_implementor();
2530   }
2531 
2532   constants()-&gt;remove_unshareable_info();
2533 
2534   for (int i = 0; i &lt; methods()-&gt;length(); i++) {
2535     Method* m = methods()-&gt;at(i);
2536     m-&gt;remove_unshareable_info();
2537   }
2538 
2539   // do array classes also.
2540   if (array_klasses() != NULL) {
2541     array_klasses()-&gt;remove_unshareable_info();
2542   }
2543 
2544   // These are not allocated from metaspace. They are safe to set to NULL.
2545   _source_debug_extension = NULL;
2546   _dep_context = NULL;
2547   _osr_nmethods_head = NULL;
2548 #if INCLUDE_JVMTI
2549   _breakpoints = NULL;
2550   _previous_versions = NULL;
2551   _cached_class_file = NULL;
2552   _jvmti_cached_class_field_map = NULL;
2553 #endif
2554 
2555   _init_thread = NULL;
2556   _methods_jmethod_ids = NULL;
2557   _jni_ids = NULL;
2558   _oop_map_cache = NULL;
2559   // clear _nest_host to ensure re-load at runtime
2560   _nest_host = NULL;
2561   _package_entry = NULL;
2562   _dep_context_last_cleaned = 0;
2563 }
2564 
2565 void InstanceKlass::remove_java_mirror() {
2566   Klass::remove_java_mirror();
2567 
2568   // do array classes also.
2569   if (array_klasses() != NULL) {
2570     array_klasses()-&gt;remove_java_mirror();
2571   }
2572 }
2573 
2574 void InstanceKlass::restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain,
2575                                              PackageEntry* pkg_entry, TRAPS) {
2576   // SystemDictionary::add_to_hierarchy() sets the init_state to loaded
2577   // before the InstanceKlass is added to the SystemDictionary. Make
2578   // sure the current state is &lt;loaded.
2579   assert(!is_loaded(), &quot;invalid init state&quot;);
2580   set_package(loader_data, pkg_entry, CHECK);
2581   Klass::restore_unshareable_info(loader_data, protection_domain, CHECK);
2582 
2583   if (is_value()) {
2584     ValueKlass::cast(this)-&gt;initialize_calling_convention(CHECK);
2585   }
2586 
2587   Array&lt;Method*&gt;* methods = this-&gt;methods();
2588   int num_methods = methods-&gt;length();
2589   for (int index = 0; index &lt; num_methods; ++index) {
2590     methods-&gt;at(index)-&gt;restore_unshareable_info(CHECK);
2591   }
2592   if (JvmtiExport::has_redefined_a_class()) {
2593     // Reinitialize vtable because RedefineClasses may have changed some
2594     // entries in this vtable for super classes so the CDS vtable might
2595     // point to old or obsolete entries.  RedefineClasses doesn&#39;t fix up
2596     // vtables in the shared system dictionary, only the main one.
2597     // It also redefines the itable too so fix that too.
2598     vtable().initialize_vtable(false, CHECK);
2599     itable().initialize_itable(false, CHECK);
2600   }
2601 
2602   // restore constant pool resolved references
2603   constants()-&gt;restore_unshareable_info(CHECK);
2604 
2605   if (array_klasses() != NULL) {
2606     // Array classes have null protection domain.
2607     // --&gt; see ArrayKlass::complete_create_array_klass()
2608     ArrayKlass::cast(array_klasses())-&gt;restore_unshareable_info(ClassLoaderData::the_null_class_loader_data(), Handle(), CHECK);
2609   }
2610 
2611   // Initialize current biased locking state.
2612   if (UseBiasedLocking &amp;&amp; BiasedLocking::enabled() &amp;&amp; !is_value()) {
2613     set_prototype_header(markWord::biased_locking_prototype());
2614   }
2615 }
2616 
2617 void InstanceKlass::set_shared_class_loader_type(s2 loader_type) {
2618   switch (loader_type) {
2619   case ClassLoader::BOOT_LOADER:
2620     _misc_flags |= _misc_is_shared_boot_class;
2621     break;
2622   case ClassLoader::PLATFORM_LOADER:
2623     _misc_flags |= _misc_is_shared_platform_class;
2624     break;
2625   case ClassLoader::APP_LOADER:
2626     _misc_flags |= _misc_is_shared_app_class;
2627     break;
2628   default:
2629     ShouldNotReachHere();
2630     break;
2631   }
2632 }
2633 
2634 #if INCLUDE_JVMTI
2635 static void clear_all_breakpoints(Method* m) {
2636   m-&gt;clear_all_breakpoints();
2637 }
2638 #endif
2639 
2640 void InstanceKlass::unload_class(InstanceKlass* ik) {
2641   // Release dependencies.
2642   ik-&gt;dependencies().remove_all_dependents();
2643 
2644   // notify the debugger
2645   if (JvmtiExport::should_post_class_unload()) {
2646     JvmtiExport::post_class_unload(ik);
2647   }
2648 
2649   // notify ClassLoadingService of class unload
2650   ClassLoadingService::notify_class_unloaded(ik);
2651 
2652   if (Arguments::is_dumping_archive()) {
2653     SystemDictionaryShared::remove_dumptime_info(ik);
2654   }
2655 
2656   if (log_is_enabled(Info, class, unload)) {
2657     ResourceMark rm;
2658     log_info(class, unload)(&quot;unloading class %s &quot; INTPTR_FORMAT, ik-&gt;external_name(), p2i(ik));
2659   }
2660 
2661   Events::log_class_unloading(Thread::current(), ik);
2662 
2663 #if INCLUDE_JFR
2664   assert(ik != NULL, &quot;invariant&quot;);
2665   EventClassUnload event;
2666   event.set_unloadedClass(ik);
2667   event.set_definingClassLoader(ik-&gt;class_loader_data());
2668   event.commit();
2669 #endif
2670 }
2671 
2672 static void method_release_C_heap_structures(Method* m) {
2673   m-&gt;release_C_heap_structures();
2674 }
2675 
2676 void InstanceKlass::release_C_heap_structures(InstanceKlass* ik) {
2677   // Clean up C heap
2678   ik-&gt;release_C_heap_structures();
2679   ik-&gt;constants()-&gt;release_C_heap_structures();
2680 
2681   // Deallocate and call destructors for MDO mutexes
2682   ik-&gt;methods_do(method_release_C_heap_structures);
2683 
2684 }
2685 
2686 void InstanceKlass::release_C_heap_structures() {
2687   // Can&#39;t release the constant pool here because the constant pool can be
2688   // deallocated separately from the InstanceKlass for default methods and
2689   // redefine classes.
2690 
2691   // Deallocate oop map cache
2692   if (_oop_map_cache != NULL) {
2693     delete _oop_map_cache;
2694     _oop_map_cache = NULL;
2695   }
2696 
2697   // Deallocate JNI identifiers for jfieldIDs
2698   JNIid::deallocate(jni_ids());
2699   set_jni_ids(NULL);
2700 
2701   jmethodID* jmeths = methods_jmethod_ids_acquire();
2702   if (jmeths != (jmethodID*)NULL) {
2703     release_set_methods_jmethod_ids(NULL);
2704     FreeHeap(jmeths);
2705   }
2706 
2707   assert(_dep_context == NULL,
2708          &quot;dependencies should already be cleaned&quot;);
2709 
2710 #if INCLUDE_JVMTI
2711   // Deallocate breakpoint records
2712   if (breakpoints() != 0x0) {
2713     methods_do(clear_all_breakpoints);
2714     assert(breakpoints() == 0x0, &quot;should have cleared breakpoints&quot;);
2715   }
2716 
2717   // deallocate the cached class file
2718   if (_cached_class_file != NULL) {
2719     os::free(_cached_class_file);
2720     _cached_class_file = NULL;
2721   }
2722 #endif
2723 
2724   // Decrement symbol reference counts associated with the unloaded class.
2725   if (_name != NULL) _name-&gt;decrement_refcount();
2726   // unreference array name derived from this class name (arrays of an unloaded
2727   // class can&#39;t be referenced anymore).
2728   if (_array_name != NULL)  _array_name-&gt;decrement_refcount();
<a name="10" id="anc10"></a><span class="line-modified">2729   if (_value_types != NULL) {</span>
<span class="line-modified">2730     for (int i = 0; i &lt; _value_types-&gt;length(); i++) {</span>
<span class="line-modified">2731       Symbol* s = _value_types-&gt;at(i)._class_name;</span>
2732       if (s != NULL) {
2733         s-&gt;decrement_refcount();
2734       }
2735     }
2736   }
2737   FREE_C_HEAP_ARRAY(char, _source_debug_extension);
2738 }
2739 
2740 void InstanceKlass::set_source_debug_extension(const char* array, int length) {
2741   if (array == NULL) {
2742     _source_debug_extension = NULL;
2743   } else {
2744     // Adding one to the attribute length in order to store a null terminator
2745     // character could cause an overflow because the attribute length is
2746     // already coded with an u4 in the classfile, but in practice, it&#39;s
2747     // unlikely to happen.
2748     assert((length+1) &gt; length, &quot;Overflow checking&quot;);
2749     char* sde = NEW_C_HEAP_ARRAY(char, (length + 1), mtClass);
2750     for (int i = 0; i &lt; length; i++) {
2751       sde[i] = array[i];
2752     }
2753     sde[length] = &#39;\0&#39;;
2754     _source_debug_extension = sde;
2755   }
2756 }
2757 
2758 const char* InstanceKlass::signature_name() const {
2759   int hash_len = 0;
2760   char hash_buf[40];
2761 
2762   // If this is an unsafe anonymous class, append a hash to make the name unique
2763   if (is_unsafe_anonymous()) {
2764     intptr_t hash = (java_mirror() != NULL) ? java_mirror()-&gt;identity_hash() : 0;
2765     jio_snprintf(hash_buf, sizeof(hash_buf), &quot;/&quot; UINTX_FORMAT, (uintx)hash);
2766     hash_len = (int)strlen(hash_buf);
2767   }
2768 
2769   // Get the internal name as a c string
2770   const char* src = (const char*) (name()-&gt;as_C_string());
2771   const int src_length = (int)strlen(src);
2772 
2773   char* dest = NEW_RESOURCE_ARRAY(char, src_length + hash_len + 3);
2774 
2775   // Add L or Q as type indicator
2776   int dest_index = 0;
2777   dest[dest_index++] = is_value() ? JVM_SIGNATURE_VALUETYPE : JVM_SIGNATURE_CLASS;
2778 
2779   // Add the actual class name
2780   for (int src_index = 0; src_index &lt; src_length; ) {
2781     dest[dest_index++] = src[src_index++];
2782   }
2783 
2784   // If we have a hash, append it
2785   for (int hash_index = 0; hash_index &lt; hash_len; ) {
2786     dest[dest_index++] = hash_buf[hash_index++];
2787   }
2788 
2789   // Add the semicolon and the NULL
2790   dest[dest_index++] = JVM_SIGNATURE_ENDCLASS;
2791   dest[dest_index] = &#39;\0&#39;;
2792   return dest;
2793 }
2794 
2795 ModuleEntry* InstanceKlass::module() const {
2796   // For an unsafe anonymous class return the host class&#39; module
2797   if (is_unsafe_anonymous()) {
2798     assert(unsafe_anonymous_host() != NULL, &quot;unsafe anonymous class must have a host class&quot;);
2799     return unsafe_anonymous_host()-&gt;module();
2800   }
2801 
2802   // Class is in a named package
2803   if (!in_unnamed_package()) {
2804     return _package_entry-&gt;module();
2805   }
2806 
2807   // Class is in an unnamed package, return its loader&#39;s unnamed module
2808   return class_loader_data()-&gt;unnamed_module();
2809 }
2810 
2811 void InstanceKlass::set_package(ClassLoaderData* loader_data, PackageEntry* pkg_entry, TRAPS) {
2812 
2813   // ensure java/ packages only loaded by boot or platform builtin loaders
2814   check_prohibited_package(name(), loader_data, CHECK);
2815 
2816   TempNewSymbol pkg_name = pkg_entry != NULL ? pkg_entry-&gt;name() : ClassLoader::package_from_class_name(name());
2817 
2818   if (pkg_name != NULL &amp;&amp; loader_data != NULL) {
2819 
2820     // Find in class loader&#39;s package entry table.
2821     _package_entry = pkg_entry != NULL ? pkg_entry : loader_data-&gt;packages()-&gt;lookup_only(pkg_name);
2822 
2823     // If the package name is not found in the loader&#39;s package
2824     // entry table, it is an indication that the package has not
2825     // been defined. Consider it defined within the unnamed module.
2826     if (_package_entry == NULL) {
2827 
2828       if (!ModuleEntryTable::javabase_defined()) {
2829         // Before java.base is defined during bootstrapping, define all packages in
2830         // the java.base module.  If a non-java.base package is erroneously placed
2831         // in the java.base module it will be caught later when java.base
2832         // is defined by ModuleEntryTable::verify_javabase_packages check.
2833         assert(ModuleEntryTable::javabase_moduleEntry() != NULL, JAVA_BASE_NAME &quot; module is NULL&quot;);
2834         _package_entry = loader_data-&gt;packages()-&gt;lookup(pkg_name, ModuleEntryTable::javabase_moduleEntry());
2835       } else {
2836         assert(loader_data-&gt;unnamed_module() != NULL, &quot;unnamed module is NULL&quot;);
2837         _package_entry = loader_data-&gt;packages()-&gt;lookup(pkg_name,
2838                                                          loader_data-&gt;unnamed_module());
2839       }
2840 
2841       // A package should have been successfully created
2842       DEBUG_ONLY(ResourceMark rm(THREAD));
2843       assert(_package_entry != NULL, &quot;Package entry for class %s not found, loader %s&quot;,
2844              name()-&gt;as_C_string(), loader_data-&gt;loader_name_and_id());
2845     }
2846 
2847     if (log_is_enabled(Debug, module)) {
2848       ResourceMark rm(THREAD);
2849       ModuleEntry* m = _package_entry-&gt;module();
2850       log_trace(module)(&quot;Setting package: class: %s, package: %s, loader: %s, module: %s&quot;,
2851                         external_name(),
2852                         pkg_name-&gt;as_C_string(),
2853                         loader_data-&gt;loader_name_and_id(),
2854                         (m-&gt;is_named() ? m-&gt;name()-&gt;as_C_string() : UNNAMED_MODULE));
2855     }
2856   } else {
2857     ResourceMark rm(THREAD);
2858     log_trace(module)(&quot;Setting package: class: %s, package: unnamed, loader: %s, module: %s&quot;,
2859                       external_name(),
2860                       (loader_data != NULL) ? loader_data-&gt;loader_name_and_id() : &quot;NULL&quot;,
2861                       UNNAMED_MODULE);
2862   }
2863 }
2864 
2865 
2866 // different versions of is_same_class_package
2867 
2868 bool InstanceKlass::is_same_class_package(const Klass* class2) const {
2869   oop classloader1 = this-&gt;class_loader();
2870   PackageEntry* classpkg1 = this-&gt;package();
2871   if (class2-&gt;is_objArray_klass()) {
2872     class2 = ObjArrayKlass::cast(class2)-&gt;bottom_klass();
2873   }
2874 
2875   oop classloader2;
2876   PackageEntry* classpkg2;
2877   if (class2-&gt;is_instance_klass()) {
2878     classloader2 = class2-&gt;class_loader();
2879     classpkg2 = class2-&gt;package();
2880   } else {
2881     assert(class2-&gt;is_typeArray_klass(), &quot;should be type array&quot;);
2882     classloader2 = NULL;
2883     classpkg2 = NULL;
2884   }
2885 
2886   // Same package is determined by comparing class loader
2887   // and package entries. Both must be the same. This rule
2888   // applies even to classes that are defined in the unnamed
2889   // package, they still must have the same class loader.
2890   if ((classloader1 == classloader2) &amp;&amp; (classpkg1 == classpkg2)) {
2891     return true;
2892   }
2893 
2894   return false;
2895 }
2896 
2897 // return true if this class and other_class are in the same package. Classloader
2898 // and classname information is enough to determine a class&#39;s package
2899 bool InstanceKlass::is_same_class_package(oop other_class_loader,
2900                                           const Symbol* other_class_name) const {
2901   if (class_loader() != other_class_loader) {
2902     return false;
2903   }
2904   if (name()-&gt;fast_compare(other_class_name) == 0) {
2905      return true;
2906   }
2907 
2908   {
2909     ResourceMark rm;
2910 
2911     bool bad_class_name = false;
2912     TempNewSymbol other_pkg = ClassLoader::package_from_class_name(other_class_name, &amp;bad_class_name);
2913     if (bad_class_name) {
2914       return false;
2915     }
2916     // Check that package_from_class_name() returns NULL, not &quot;&quot;, if there is no package.
2917     assert(other_pkg == NULL || other_pkg-&gt;utf8_length() &gt; 0, &quot;package name is empty string&quot;);
2918 
2919     const Symbol* const this_package_name =
2920       this-&gt;package() != NULL ? this-&gt;package()-&gt;name() : NULL;
2921 
2922     if (this_package_name == NULL || other_pkg == NULL) {
2923       // One of the two doesn&#39;t have a package.  Only return true if the other
2924       // one also doesn&#39;t have a package.
2925       return this_package_name == other_pkg;
2926     }
2927 
2928     // Check if package is identical
2929     return this_package_name-&gt;fast_compare(other_pkg) == 0;
2930   }
2931 }
2932 
2933 // Returns true iff super_method can be overridden by a method in targetclassname
2934 // See JLS 3rd edition 8.4.6.1
2935 // Assumes name-signature match
2936 // &quot;this&quot; is InstanceKlass of super_method which must exist
2937 // note that the InstanceKlass of the method in the targetclassname has not always been created yet
2938 bool InstanceKlass::is_override(const methodHandle&amp; super_method, Handle targetclassloader, Symbol* targetclassname, TRAPS) {
2939    // Private methods can not be overridden
2940    if (super_method-&gt;is_private()) {
2941      return false;
2942    }
2943    // If super method is accessible, then override
2944    if ((super_method-&gt;is_protected()) ||
2945        (super_method-&gt;is_public())) {
2946      return true;
2947    }
2948    // Package-private methods are not inherited outside of package
2949    assert(super_method-&gt;is_package_private(), &quot;must be package private&quot;);
2950    return(is_same_class_package(targetclassloader(), targetclassname));
2951 }
2952 
2953 // Only boot and platform class loaders can define classes in &quot;java/&quot; packages.
2954 void InstanceKlass::check_prohibited_package(Symbol* class_name,
2955                                              ClassLoaderData* loader_data,
2956                                              TRAPS) {
2957   if (!loader_data-&gt;is_boot_class_loader_data() &amp;&amp;
2958       !loader_data-&gt;is_platform_class_loader_data() &amp;&amp;
2959       class_name != NULL) {
2960     ResourceMark rm(THREAD);
2961     char* name = class_name-&gt;as_C_string();
2962     if (strncmp(name, JAVAPKG, JAVAPKG_LEN) == 0 &amp;&amp; name[JAVAPKG_LEN] == &#39;/&#39;) {
2963       TempNewSymbol pkg_name = ClassLoader::package_from_class_name(class_name);
2964       assert(pkg_name != NULL, &quot;Error in parsing package name starting with &#39;java/&#39;&quot;);
2965       name = pkg_name-&gt;as_C_string();
2966       const char* class_loader_name = loader_data-&gt;loader_name_and_id();
2967       StringUtils::replace_no_expand(name, &quot;/&quot;, &quot;.&quot;);
2968       const char* msg_text1 = &quot;Class loader (instance of): &quot;;
2969       const char* msg_text2 = &quot; tried to load prohibited package name: &quot;;
2970       size_t len = strlen(msg_text1) + strlen(class_loader_name) + strlen(msg_text2) + strlen(name) + 1;
2971       char* message = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, char, len);
2972       jio_snprintf(message, len, &quot;%s%s%s%s&quot;, msg_text1, class_loader_name, msg_text2, name);
2973       THROW_MSG(vmSymbols::java_lang_SecurityException(), message);
2974     }
2975   }
2976   return;
2977 }
2978 
2979 bool InstanceKlass::find_inner_classes_attr(int* ooff, int* noff, TRAPS) const {
2980   constantPoolHandle i_cp(THREAD, constants());
2981   for (InnerClassesIterator iter(this); !iter.done(); iter.next()) {
2982     int ioff = iter.inner_class_info_index();
2983     if (ioff != 0) {
2984       // Check to see if the name matches the class we&#39;re looking for
2985       // before attempting to find the class.
2986       if (i_cp-&gt;klass_name_at_matches(this, ioff)) {
2987         Klass* inner_klass = i_cp-&gt;klass_at(ioff, CHECK_false);
2988         if (this == inner_klass) {
2989           *ooff = iter.outer_class_info_index();
2990           *noff = iter.inner_name_index();
2991           return true;
2992         }
2993       }
2994     }
2995   }
2996   return false;
2997 }
2998 
2999 InstanceKlass* InstanceKlass::compute_enclosing_class(bool* inner_is_member, TRAPS) const {
3000   InstanceKlass* outer_klass = NULL;
3001   *inner_is_member = false;
3002   int ooff = 0, noff = 0;
3003   bool has_inner_classes_attr = find_inner_classes_attr(&amp;ooff, &amp;noff, THREAD);
3004   if (has_inner_classes_attr) {
3005     constantPoolHandle i_cp(THREAD, constants());
3006     if (ooff != 0) {
3007       Klass* ok = i_cp-&gt;klass_at(ooff, CHECK_NULL);
3008       outer_klass = InstanceKlass::cast(ok);
3009       *inner_is_member = true;
3010     }
3011     if (NULL == outer_klass) {
3012       // It may be unsafe anonymous; try for that.
3013       int encl_method_class_idx = enclosing_method_class_index();
3014       if (encl_method_class_idx != 0) {
3015         Klass* ok = i_cp-&gt;klass_at(encl_method_class_idx, CHECK_NULL);
3016         outer_klass = InstanceKlass::cast(ok);
3017         *inner_is_member = false;
3018       }
3019     }
3020   }
3021 
3022   // If no inner class attribute found for this class.
3023   if (NULL == outer_klass) return NULL;
3024 
3025   // Throws an exception if outer klass has not declared k as an inner klass
3026   // We need evidence that each klass knows about the other, or else
3027   // the system could allow a spoof of an inner class to gain access rights.
3028   Reflection::check_for_inner_class(outer_klass, this, *inner_is_member, CHECK_NULL);
3029   return outer_klass;
3030 }
3031 
3032 jint InstanceKlass::compute_modifier_flags(TRAPS) const {
3033   jint access = access_flags().as_int();
3034 
3035   // But check if it happens to be member class.
3036   InnerClassesIterator iter(this);
3037   for (; !iter.done(); iter.next()) {
3038     int ioff = iter.inner_class_info_index();
3039     // Inner class attribute can be zero, skip it.
3040     // Strange but true:  JVM spec. allows null inner class refs.
3041     if (ioff == 0) continue;
3042 
3043     // only look at classes that are already loaded
3044     // since we are looking for the flags for our self.
3045     Symbol* inner_name = constants()-&gt;klass_name_at(ioff);
3046     if (name() == inner_name) {
3047       // This is really a member class.
3048       access = iter.inner_access_flags();
3049       break;
3050     }
3051   }
3052   // Remember to strip ACC_SUPER bit
3053   return (access &amp; (~JVM_ACC_SUPER)) &amp; JVM_ACC_WRITTEN_FLAGS;
3054 }
3055 
3056 jint InstanceKlass::jvmti_class_status() const {
3057   jint result = 0;
3058 
3059   if (is_linked()) {
3060     result |= JVMTI_CLASS_STATUS_VERIFIED | JVMTI_CLASS_STATUS_PREPARED;
3061   }
3062 
3063   if (is_initialized()) {
3064     assert(is_linked(), &quot;Class status is not consistent&quot;);
3065     result |= JVMTI_CLASS_STATUS_INITIALIZED;
3066   }
3067   if (is_in_error_state()) {
3068     result |= JVMTI_CLASS_STATUS_ERROR;
3069   }
3070   return result;
3071 }
3072 
3073 Method* InstanceKlass::method_at_itable(Klass* holder, int index, TRAPS) {
3074   itableOffsetEntry* ioe = (itableOffsetEntry*)start_of_itable();
3075   int method_table_offset_in_words = ioe-&gt;offset()/wordSize;
3076   int nof_interfaces = (method_table_offset_in_words - itable_offset_in_words())
3077                        / itableOffsetEntry::size();
3078 
3079   for (int cnt = 0 ; ; cnt ++, ioe ++) {
3080     // If the interface isn&#39;t implemented by the receiver class,
3081     // the VM should throw IncompatibleClassChangeError.
3082     if (cnt &gt;= nof_interfaces) {
3083       ResourceMark rm(THREAD);
3084       stringStream ss;
3085       bool same_module = (module() == holder-&gt;module());
3086       ss.print(&quot;Receiver class %s does not implement &quot;
3087                &quot;the interface %s defining the method to be called &quot;
3088                &quot;(%s%s%s)&quot;,
3089                external_name(), holder-&gt;external_name(),
3090                (same_module) ? joint_in_module_of_loader(holder) : class_in_module_of_loader(),
3091                (same_module) ? &quot;&quot; : &quot;; &quot;,
3092                (same_module) ? &quot;&quot; : holder-&gt;class_in_module_of_loader());
3093       THROW_MSG_NULL(vmSymbols::java_lang_IncompatibleClassChangeError(), ss.as_string());
3094     }
3095 
3096     Klass* ik = ioe-&gt;interface_klass();
3097     if (ik == holder) break;
3098   }
3099 
3100   itableMethodEntry* ime = ioe-&gt;first_method_entry(this);
3101   Method* m = ime[index].method();
3102   if (m == NULL) {
3103     THROW_NULL(vmSymbols::java_lang_AbstractMethodError());
3104   }
3105   return m;
3106 }
3107 
3108 
3109 #if INCLUDE_JVMTI
3110 // update default_methods for redefineclasses for methods that are
3111 // not yet in the vtable due to concurrent subclass define and superinterface
3112 // redefinition
3113 // Note: those in the vtable, should have been updated via adjust_method_entries
3114 void InstanceKlass::adjust_default_methods(bool* trace_name_printed) {
3115   // search the default_methods for uses of either obsolete or EMCP methods
3116   if (default_methods() != NULL) {
3117     for (int index = 0; index &lt; default_methods()-&gt;length(); index ++) {
3118       Method* old_method = default_methods()-&gt;at(index);
3119       if (old_method == NULL || !old_method-&gt;is_old()) {
3120         continue; // skip uninteresting entries
3121       }
3122       assert(!old_method-&gt;is_deleted(), &quot;default methods may not be deleted&quot;);
3123       Method* new_method = old_method-&gt;get_new_method();
3124       default_methods()-&gt;at_put(index, new_method);
3125 
3126       if (log_is_enabled(Info, redefine, class, update)) {
3127         ResourceMark rm;
3128         if (!(*trace_name_printed)) {
3129           log_info(redefine, class, update)
3130             (&quot;adjust: klassname=%s default methods from name=%s&quot;,
3131              external_name(), old_method-&gt;method_holder()-&gt;external_name());
3132           *trace_name_printed = true;
3133         }
3134         log_debug(redefine, class, update, vtables)
3135           (&quot;default method update: %s(%s) &quot;,
3136            new_method-&gt;name()-&gt;as_C_string(), new_method-&gt;signature()-&gt;as_C_string());
3137       }
3138     }
3139   }
3140 }
3141 #endif // INCLUDE_JVMTI
3142 
3143 // On-stack replacement stuff
3144 void InstanceKlass::add_osr_nmethod(nmethod* n) {
3145   assert_lock_strong(CompiledMethod_lock);
3146 #ifndef PRODUCT
3147   if (TieredCompilation) {
3148       nmethod * prev = lookup_osr_nmethod(n-&gt;method(), n-&gt;osr_entry_bci(), n-&gt;comp_level(), true);
3149       assert(prev == NULL || !prev-&gt;is_in_use(),
3150       &quot;redundunt OSR recompilation detected. memory leak in CodeCache!&quot;);
3151   }
3152 #endif
3153   // only one compilation can be active
3154   {
3155     assert(n-&gt;is_osr_method(), &quot;wrong kind of nmethod&quot;);
3156     n-&gt;set_osr_link(osr_nmethods_head());
3157     set_osr_nmethods_head(n);
3158     // Raise the highest osr level if necessary
3159     if (TieredCompilation) {
3160       Method* m = n-&gt;method();
3161       m-&gt;set_highest_osr_comp_level(MAX2(m-&gt;highest_osr_comp_level(), n-&gt;comp_level()));
3162     }
3163   }
3164 
3165   // Get rid of the osr methods for the same bci that have lower levels.
3166   if (TieredCompilation) {
3167     for (int l = CompLevel_limited_profile; l &lt; n-&gt;comp_level(); l++) {
3168       nmethod *inv = lookup_osr_nmethod(n-&gt;method(), n-&gt;osr_entry_bci(), l, true);
3169       if (inv != NULL &amp;&amp; inv-&gt;is_in_use()) {
3170         inv-&gt;make_not_entrant();
3171       }
3172     }
3173   }
3174 }
3175 
3176 // Remove osr nmethod from the list. Return true if found and removed.
3177 bool InstanceKlass::remove_osr_nmethod(nmethod* n) {
3178   // This is a short non-blocking critical region, so the no safepoint check is ok.
3179   MutexLocker ml(CompiledMethod_lock-&gt;owned_by_self() ? NULL : CompiledMethod_lock
3180                  , Mutex::_no_safepoint_check_flag);
3181   assert(n-&gt;is_osr_method(), &quot;wrong kind of nmethod&quot;);
3182   nmethod* last = NULL;
3183   nmethod* cur  = osr_nmethods_head();
3184   int max_level = CompLevel_none;  // Find the max comp level excluding n
3185   Method* m = n-&gt;method();
3186   // Search for match
3187   bool found = false;
3188   while(cur != NULL &amp;&amp; cur != n) {
3189     if (TieredCompilation &amp;&amp; m == cur-&gt;method()) {
3190       // Find max level before n
3191       max_level = MAX2(max_level, cur-&gt;comp_level());
3192     }
3193     last = cur;
3194     cur = cur-&gt;osr_link();
3195   }
3196   nmethod* next = NULL;
3197   if (cur == n) {
3198     found = true;
3199     next = cur-&gt;osr_link();
3200     if (last == NULL) {
3201       // Remove first element
3202       set_osr_nmethods_head(next);
3203     } else {
3204       last-&gt;set_osr_link(next);
3205     }
3206   }
3207   n-&gt;set_osr_link(NULL);
3208   if (TieredCompilation) {
3209     cur = next;
3210     while (cur != NULL) {
3211       // Find max level after n
3212       if (m == cur-&gt;method()) {
3213         max_level = MAX2(max_level, cur-&gt;comp_level());
3214       }
3215       cur = cur-&gt;osr_link();
3216     }
3217     m-&gt;set_highest_osr_comp_level(max_level);
3218   }
3219   return found;
3220 }
3221 
3222 int InstanceKlass::mark_osr_nmethods(const Method* m) {
3223   MutexLocker ml(CompiledMethod_lock-&gt;owned_by_self() ? NULL : CompiledMethod_lock,
3224                  Mutex::_no_safepoint_check_flag);
3225   nmethod* osr = osr_nmethods_head();
3226   int found = 0;
3227   while (osr != NULL) {
3228     assert(osr-&gt;is_osr_method(), &quot;wrong kind of nmethod found in chain&quot;);
3229     if (osr-&gt;method() == m) {
3230       osr-&gt;mark_for_deoptimization();
3231       found++;
3232     }
3233     osr = osr-&gt;osr_link();
3234   }
3235   return found;
3236 }
3237 
3238 nmethod* InstanceKlass::lookup_osr_nmethod(const Method* m, int bci, int comp_level, bool match_level) const {
3239   MutexLocker ml(CompiledMethod_lock-&gt;owned_by_self() ? NULL : CompiledMethod_lock,
3240                  Mutex::_no_safepoint_check_flag);
3241   nmethod* osr = osr_nmethods_head();
3242   nmethod* best = NULL;
3243   while (osr != NULL) {
3244     assert(osr-&gt;is_osr_method(), &quot;wrong kind of nmethod found in chain&quot;);
3245     // There can be a time when a c1 osr method exists but we are waiting
3246     // for a c2 version. When c2 completes its osr nmethod we will trash
3247     // the c1 version and only be able to find the c2 version. However
3248     // while we overflow in the c1 code at back branches we don&#39;t want to
3249     // try and switch to the same code as we are already running
3250 
3251     if (osr-&gt;method() == m &amp;&amp;
3252         (bci == InvocationEntryBci || osr-&gt;osr_entry_bci() == bci)) {
3253       if (match_level) {
3254         if (osr-&gt;comp_level() == comp_level) {
3255           // Found a match - return it.
3256           return osr;
3257         }
3258       } else {
3259         if (best == NULL || (osr-&gt;comp_level() &gt; best-&gt;comp_level())) {
3260           if (osr-&gt;comp_level() == CompLevel_highest_tier) {
3261             // Found the best possible - return it.
3262             return osr;
3263           }
3264           best = osr;
3265         }
3266       }
3267     }
3268     osr = osr-&gt;osr_link();
3269   }
3270 
3271   assert(match_level == false || best == NULL, &quot;shouldn&#39;t pick up anything if match_level is set&quot;);
3272   if (best != NULL &amp;&amp; best-&gt;comp_level() &gt;= comp_level) {
3273     return best;
3274   }
3275   return NULL;
3276 }
3277 
3278 // -----------------------------------------------------------------------------------------------------
3279 // Printing
3280 
3281 #ifndef PRODUCT
3282 
3283 #define BULLET  &quot; - &quot;
3284 
3285 static const char* state_names[] = {
3286   &quot;allocated&quot;, &quot;loaded&quot;, &quot;linked&quot;, &quot;being_initialized&quot;, &quot;fully_initialized&quot;, &quot;initialization_error&quot;
3287 };
3288 
3289 static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {
3290   ResourceMark rm;
3291   int* forward_refs = NEW_RESOURCE_ARRAY(int, len);
3292   for (int i = 0; i &lt; len; i++)  forward_refs[i] = 0;
3293   for (int i = 0; i &lt; len; i++) {
3294     intptr_t e = start[i];
3295     st-&gt;print(&quot;%d : &quot; INTPTR_FORMAT, i, e);
3296     if (forward_refs[i] != 0) {
3297       int from = forward_refs[i];
3298       int off = (int) start[from];
3299       st-&gt;print(&quot; (offset %d &lt;= [%d])&quot;, off, from);
3300     }
3301     if (MetaspaceObj::is_valid((Metadata*)e)) {
3302       st-&gt;print(&quot; &quot;);
3303       ((Metadata*)e)-&gt;print_value_on(st);
3304     } else if (self != NULL &amp;&amp; e &gt; 0 &amp;&amp; e &lt; 0x10000) {
3305       address location = self + e;
3306       int index = (int)((intptr_t*)location - start);
3307       st-&gt;print(&quot; (offset %d =&gt; [%d])&quot;, (int)e, index);
3308       if (index &gt;= 0 &amp;&amp; index &lt; len)
3309         forward_refs[index] = i;
3310     }
3311     st-&gt;cr();
3312   }
3313 }
3314 
3315 static void print_vtable(vtableEntry* start, int len, outputStream* st) {
3316   return print_vtable(NULL, reinterpret_cast&lt;intptr_t*&gt;(start), len, st);
3317 }
3318 
3319 template&lt;typename T&gt;
3320  static void print_array_on(outputStream* st, Array&lt;T&gt;* array) {
3321    if (array == NULL) { st-&gt;print_cr(&quot;NULL&quot;); return; }
3322    array-&gt;print_value_on(st); st-&gt;cr();
3323    if (Verbose || WizardMode) {
3324      for (int i = 0; i &lt; array-&gt;length(); i++) {
3325        st-&gt;print(&quot;%d : &quot;, i); array-&gt;at(i)-&gt;print_value_on(st); st-&gt;cr();
3326      }
3327    }
3328  }
3329 
3330 static void print_array_on(outputStream* st, Array&lt;int&gt;* array) {
3331   if (array == NULL) { st-&gt;print_cr(&quot;NULL&quot;); return; }
3332   array-&gt;print_value_on(st); st-&gt;cr();
3333   if (Verbose || WizardMode) {
3334     for (int i = 0; i &lt; array-&gt;length(); i++) {
3335       st-&gt;print(&quot;%d : %d&quot;, i, array-&gt;at(i)); st-&gt;cr();
3336     }
3337   }
3338 }
3339 
3340 void InstanceKlass::print_on(outputStream* st) const {
3341   assert(is_klass(), &quot;must be klass&quot;);
3342   Klass::print_on(st);
3343 
3344   st-&gt;print(BULLET&quot;instance size:     %d&quot;, size_helper());                        st-&gt;cr();
3345   st-&gt;print(BULLET&quot;klass size:        %d&quot;, size());                               st-&gt;cr();
3346   st-&gt;print(BULLET&quot;access:            &quot;); access_flags().print_on(st);            st-&gt;cr();
3347   st-&gt;print(BULLET&quot;misc flags:        0x%x&quot;, _misc_flags);                        st-&gt;cr();
3348   st-&gt;print(BULLET&quot;state:             &quot;); st-&gt;print_cr(&quot;%s&quot;, state_names[_init_state]);
3349   st-&gt;print(BULLET&quot;name:              &quot;); name()-&gt;print_value_on(st);             st-&gt;cr();
3350   st-&gt;print(BULLET&quot;super:             &quot;); Metadata::print_value_on_maybe_null(st, super()); st-&gt;cr();
3351   st-&gt;print(BULLET&quot;sub:               &quot;);
3352   Klass* sub = subklass();
3353   int n;
3354   for (n = 0; sub != NULL; n++, sub = sub-&gt;next_sibling()) {
3355     if (n &lt; MaxSubklassPrintSize) {
3356       sub-&gt;print_value_on(st);
3357       st-&gt;print(&quot;   &quot;);
3358     }
3359   }
3360   if (n &gt;= MaxSubklassPrintSize) st-&gt;print(&quot;(&quot; INTX_FORMAT &quot; more klasses...)&quot;, n - MaxSubklassPrintSize);
3361   st-&gt;cr();
3362 
3363   if (is_interface()) {
3364     st-&gt;print_cr(BULLET&quot;nof implementors:  %d&quot;, nof_implementors());
3365     if (nof_implementors() == 1) {
3366       st-&gt;print_cr(BULLET&quot;implementor:    &quot;);
3367       st-&gt;print(&quot;   &quot;);
3368       implementor()-&gt;print_value_on(st);
3369       st-&gt;cr();
3370     }
3371   }
3372 
3373   st-&gt;print(BULLET&quot;arrays:            &quot;); Metadata::print_value_on_maybe_null(st, array_klasses()); st-&gt;cr();
3374   st-&gt;print(BULLET&quot;methods:           &quot;); print_array_on(st, methods());
3375   st-&gt;print(BULLET&quot;method ordering:   &quot;); print_array_on(st, method_ordering());
3376   st-&gt;print(BULLET&quot;default_methods:   &quot;); print_array_on(st, default_methods());
3377   if (default_vtable_indices() != NULL) {
3378     st-&gt;print(BULLET&quot;default vtable indices:   &quot;); print_array_on(st, default_vtable_indices());
3379   }
3380   st-&gt;print(BULLET&quot;local interfaces:  &quot;); print_array_on(st, local_interfaces());
3381   st-&gt;print(BULLET&quot;trans. interfaces: &quot;); print_array_on(st, transitive_interfaces());
3382   st-&gt;print(BULLET&quot;constants:         &quot;); constants()-&gt;print_value_on(st);         st-&gt;cr();
3383   if (class_loader_data() != NULL) {
3384     st-&gt;print(BULLET&quot;class loader data:  &quot;);
3385     class_loader_data()-&gt;print_value_on(st);
3386     st-&gt;cr();
3387   }
3388   st-&gt;print(BULLET&quot;unsafe anonymous host class:        &quot;); Metadata::print_value_on_maybe_null(st, unsafe_anonymous_host()); st-&gt;cr();
3389   if (source_file_name() != NULL) {
3390     st-&gt;print(BULLET&quot;source file:       &quot;);
3391     source_file_name()-&gt;print_value_on(st);
3392     st-&gt;cr();
3393   }
3394   if (source_debug_extension() != NULL) {
3395     st-&gt;print(BULLET&quot;source debug extension:       &quot;);
3396     st-&gt;print(&quot;%s&quot;, source_debug_extension());
3397     st-&gt;cr();
3398   }
3399   st-&gt;print(BULLET&quot;class annotations:       &quot;); class_annotations()-&gt;print_value_on(st); st-&gt;cr();
3400   st-&gt;print(BULLET&quot;class type annotations:  &quot;); class_type_annotations()-&gt;print_value_on(st); st-&gt;cr();
3401   st-&gt;print(BULLET&quot;field annotations:       &quot;); fields_annotations()-&gt;print_value_on(st); st-&gt;cr();
3402   st-&gt;print(BULLET&quot;field type annotations:  &quot;); fields_type_annotations()-&gt;print_value_on(st); st-&gt;cr();
3403   {
3404     bool have_pv = false;
3405     // previous versions are linked together through the InstanceKlass
3406     for (InstanceKlass* pv_node = previous_versions();
3407          pv_node != NULL;
3408          pv_node = pv_node-&gt;previous_versions()) {
3409       if (!have_pv)
3410         st-&gt;print(BULLET&quot;previous version:  &quot;);
3411       have_pv = true;
3412       pv_node-&gt;constants()-&gt;print_value_on(st);
3413     }
3414     if (have_pv) st-&gt;cr();
3415   }
3416 
3417   if (generic_signature() != NULL) {
3418     st-&gt;print(BULLET&quot;generic signature: &quot;);
3419     generic_signature()-&gt;print_value_on(st);
3420     st-&gt;cr();
3421   }
3422   st-&gt;print(BULLET&quot;inner classes:     &quot;); inner_classes()-&gt;print_value_on(st);     st-&gt;cr();
3423   st-&gt;print(BULLET&quot;nest members:     &quot;); nest_members()-&gt;print_value_on(st);     st-&gt;cr();
3424   if (record_components() != NULL) {
3425     st-&gt;print(BULLET&quot;record components:     &quot;); record_components()-&gt;print_value_on(st);     st-&gt;cr();
3426   }
3427   if (java_mirror() != NULL) {
3428     st-&gt;print(BULLET&quot;java mirror:       &quot;);
3429     java_mirror()-&gt;print_value_on(st);
3430     st-&gt;cr();
3431   } else {
3432     st-&gt;print_cr(BULLET&quot;java mirror:       NULL&quot;);
3433   }
3434   st-&gt;print(BULLET&quot;vtable length      %d  (start addr: &quot; INTPTR_FORMAT &quot;)&quot;, vtable_length(), p2i(start_of_vtable())); st-&gt;cr();
3435   if (vtable_length() &gt; 0 &amp;&amp; (Verbose || WizardMode))  print_vtable(start_of_vtable(), vtable_length(), st);
3436   st-&gt;print(BULLET&quot;itable length      %d (start addr: &quot; INTPTR_FORMAT &quot;)&quot;, itable_length(), p2i(start_of_itable())); st-&gt;cr();
3437   if (itable_length() &gt; 0 &amp;&amp; (Verbose || WizardMode))  print_vtable(NULL, start_of_itable(), itable_length(), st);
3438   st-&gt;print_cr(BULLET&quot;---- static fields (%d words):&quot;, static_field_size());
3439   FieldPrinter print_static_field(st);
3440   ((InstanceKlass*)this)-&gt;do_local_static_fields(&amp;print_static_field);
3441   st-&gt;print_cr(BULLET&quot;---- non-static fields (%d words):&quot;, nonstatic_field_size());
3442   FieldPrinter print_nonstatic_field(st);
3443   InstanceKlass* ik = const_cast&lt;InstanceKlass*&gt;(this);
3444   ik-&gt;do_nonstatic_fields(&amp;print_nonstatic_field);
3445 
3446   st-&gt;print(BULLET&quot;non-static oop maps: &quot;);
3447   OopMapBlock* map     = start_of_nonstatic_oop_maps();
3448   OopMapBlock* end_map = map + nonstatic_oop_map_count();
3449   while (map &lt; end_map) {
3450     st-&gt;print(&quot;%d-%d &quot;, map-&gt;offset(), map-&gt;offset() + heapOopSize*(map-&gt;count() - 1));
3451     map++;
3452   }
3453   st-&gt;cr();
3454 }
3455 
3456 #endif //PRODUCT
3457 
3458 void InstanceKlass::print_value_on(outputStream* st) const {
3459   assert(is_klass(), &quot;must be klass&quot;);
3460   if (Verbose || WizardMode)  access_flags().print_on(st);
3461   name()-&gt;print_value_on(st);
3462 }
3463 
3464 #ifndef PRODUCT
3465 
3466 void FieldPrinter::do_field(fieldDescriptor* fd) {
3467   _st-&gt;print(BULLET);
3468    if (_obj == NULL) {
3469      fd-&gt;print_on(_st);
3470      _st-&gt;cr();
3471    } else {
3472      fd-&gt;print_on_for(_st, _obj);
3473      _st-&gt;cr();
3474    }
3475 }
3476 
3477 
3478 void InstanceKlass::oop_print_on(oop obj, outputStream* st) {
3479   Klass::oop_print_on(obj, st);
3480 
3481   if (this == SystemDictionary::String_klass()) {
3482     typeArrayOop value  = java_lang_String::value(obj);
3483     juint        length = java_lang_String::length(obj);
3484     if (value != NULL &amp;&amp;
3485         value-&gt;is_typeArray() &amp;&amp;
3486         length &lt;= (juint) value-&gt;length()) {
3487       st-&gt;print(BULLET&quot;string: &quot;);
3488       java_lang_String::print(obj, st);
3489       st-&gt;cr();
3490       if (!WizardMode)  return;  // that is enough
3491     }
3492   }
3493 
3494   st-&gt;print_cr(BULLET&quot;---- fields (total size %d words):&quot;, oop_size(obj));
3495   FieldPrinter print_field(st, obj);
3496   do_nonstatic_fields(&amp;print_field);
3497 
3498   if (this == SystemDictionary::Class_klass()) {
3499     st-&gt;print(BULLET&quot;signature: &quot;);
3500     java_lang_Class::print_signature(obj, st);
3501     st-&gt;cr();
3502     Klass* mirrored_klass = java_lang_Class::as_Klass(obj);
3503     st-&gt;print(BULLET&quot;fake entry for mirror: &quot;);
3504     Metadata::print_value_on_maybe_null(st, mirrored_klass);
3505     st-&gt;cr();
3506     Klass* array_klass = java_lang_Class::array_klass_acquire(obj);
3507     st-&gt;print(BULLET&quot;fake entry for array: &quot;);
3508     Metadata::print_value_on_maybe_null(st, array_klass);
3509     st-&gt;cr();
3510     st-&gt;print_cr(BULLET&quot;fake entry for oop_size: %d&quot;, java_lang_Class::oop_size(obj));
3511     st-&gt;print_cr(BULLET&quot;fake entry for static_oop_field_count: %d&quot;, java_lang_Class::static_oop_field_count(obj));
3512     Klass* real_klass = java_lang_Class::as_Klass(obj);
3513     if (real_klass != NULL &amp;&amp; real_klass-&gt;is_instance_klass()) {
3514       InstanceKlass::cast(real_klass)-&gt;do_local_static_fields(&amp;print_field);
3515     }
3516   } else if (this == SystemDictionary::MethodType_klass()) {
3517     st-&gt;print(BULLET&quot;signature: &quot;);
3518     java_lang_invoke_MethodType::print_signature(obj, st);
3519     st-&gt;cr();
3520   }
3521 }
3522 
3523 bool InstanceKlass::verify_itable_index(int i) {
3524   int method_count = klassItable::method_count_for_interface(this);
3525   assert(i &gt;= 0 &amp;&amp; i &lt; method_count, &quot;index out of bounds&quot;);
3526   return true;
3527 }
3528 
3529 #endif //PRODUCT
3530 
3531 void InstanceKlass::oop_print_value_on(oop obj, outputStream* st) {
3532   st-&gt;print(&quot;a &quot;);
3533   name()-&gt;print_value_on(st);
3534   obj-&gt;print_address_on(st);
3535   if (this == SystemDictionary::String_klass()
3536       &amp;&amp; java_lang_String::value(obj) != NULL) {
3537     ResourceMark rm;
3538     int len = java_lang_String::length(obj);
3539     int plen = (len &lt; 24 ? len : 12);
3540     char* str = java_lang_String::as_utf8_string(obj, 0, plen);
3541     st-&gt;print(&quot; = \&quot;%s\&quot;&quot;, str);
3542     if (len &gt; plen)
3543       st-&gt;print(&quot;...[%d]&quot;, len);
3544   } else if (this == SystemDictionary::Class_klass()) {
3545     Klass* k = java_lang_Class::as_Klass(obj);
3546     st-&gt;print(&quot; = &quot;);
3547     if (k != NULL) {
3548       k-&gt;print_value_on(st);
3549     } else {
3550       const char* tname = type2name(java_lang_Class::primitive_type(obj));
3551       st-&gt;print(&quot;%s&quot;, tname ? tname : &quot;type?&quot;);
3552     }
3553   } else if (this == SystemDictionary::MethodType_klass()) {
3554     st-&gt;print(&quot; = &quot;);
3555     java_lang_invoke_MethodType::print_signature(obj, st);
3556   } else if (java_lang_boxing_object::is_instance(obj)) {
3557     st-&gt;print(&quot; = &quot;);
3558     java_lang_boxing_object::print(obj, st);
3559   } else if (this == SystemDictionary::LambdaForm_klass()) {
3560     oop vmentry = java_lang_invoke_LambdaForm::vmentry(obj);
3561     if (vmentry != NULL) {
3562       st-&gt;print(&quot; =&gt; &quot;);
3563       vmentry-&gt;print_value_on(st);
3564     }
3565   } else if (this == SystemDictionary::MemberName_klass()) {
3566     Metadata* vmtarget = java_lang_invoke_MemberName::vmtarget(obj);
3567     if (vmtarget != NULL) {
3568       st-&gt;print(&quot; = &quot;);
3569       vmtarget-&gt;print_value_on(st);
3570     } else {
3571       java_lang_invoke_MemberName::clazz(obj)-&gt;print_value_on(st);
3572       st-&gt;print(&quot;.&quot;);
3573       java_lang_invoke_MemberName::name(obj)-&gt;print_value_on(st);
3574     }
3575   }
3576 }
3577 
3578 const char* InstanceKlass::internal_name() const {
3579   return external_name();
3580 }
3581 
3582 void InstanceKlass::print_class_load_logging(ClassLoaderData* loader_data,
3583                                              const char* module_name,
3584                                              const ClassFileStream* cfs) const {
3585   if (!log_is_enabled(Info, class, load)) {
3586     return;
3587   }
3588 
3589   ResourceMark rm;
3590   LogMessage(class, load) msg;
3591   stringStream info_stream;
3592 
3593   // Name and class hierarchy info
3594   info_stream.print(&quot;%s&quot;, external_name());
3595 
3596   // Source
3597   if (cfs != NULL) {
3598     if (cfs-&gt;source() != NULL) {
3599       if (module_name != NULL) {
3600         // When the boot loader created the stream, it didn&#39;t know the module name
3601         // yet. Let&#39;s format it now.
3602         if (cfs-&gt;from_boot_loader_modules_image()) {
3603           info_stream.print(&quot; source: jrt:/%s&quot;, module_name);
3604         } else {
3605           info_stream.print(&quot; source: %s&quot;, cfs-&gt;source());
3606         }
3607       } else {
3608         info_stream.print(&quot; source: %s&quot;, cfs-&gt;source());
3609       }
3610     } else if (loader_data == ClassLoaderData::the_null_class_loader_data()) {
3611       Thread* THREAD = Thread::current();
3612       Klass* caller =
3613             THREAD-&gt;is_Java_thread()
3614                 ? ((JavaThread*)THREAD)-&gt;security_get_caller_class(1)
3615                 : NULL;
3616       // caller can be NULL, for example, during a JVMTI VM_Init hook
3617       if (caller != NULL) {
3618         info_stream.print(&quot; source: instance of %s&quot;, caller-&gt;external_name());
3619       } else {
3620         // source is unknown
3621       }
3622     } else {
3623       oop class_loader = loader_data-&gt;class_loader();
3624       info_stream.print(&quot; source: %s&quot;, class_loader-&gt;klass()-&gt;external_name());
3625     }
3626   } else {
3627     assert(this-&gt;is_shared(), &quot;must be&quot;);
3628     if (MetaspaceShared::is_shared_dynamic((void*)this)) {
3629       info_stream.print(&quot; source: shared objects file (top)&quot;);
3630     } else {
3631       info_stream.print(&quot; source: shared objects file&quot;);
3632     }
3633   }
3634 
3635   msg.info(&quot;%s&quot;, info_stream.as_string());
3636 
3637   if (log_is_enabled(Debug, class, load)) {
3638     stringStream debug_stream;
3639 
3640     // Class hierarchy info
3641     debug_stream.print(&quot; klass: &quot; INTPTR_FORMAT &quot; super: &quot; INTPTR_FORMAT,
3642                        p2i(this),  p2i(superklass()));
3643 
3644     // Interfaces
3645     if (local_interfaces() != NULL &amp;&amp; local_interfaces()-&gt;length() &gt; 0) {
3646       debug_stream.print(&quot; interfaces:&quot;);
3647       int length = local_interfaces()-&gt;length();
3648       for (int i = 0; i &lt; length; i++) {
3649         debug_stream.print(&quot; &quot; INTPTR_FORMAT,
3650                            p2i(InstanceKlass::cast(local_interfaces()-&gt;at(i))));
3651       }
3652     }
3653 
3654     // Class loader
3655     debug_stream.print(&quot; loader: [&quot;);
3656     loader_data-&gt;print_value_on(&amp;debug_stream);
3657     debug_stream.print(&quot;]&quot;);
3658 
3659     // Classfile checksum
3660     if (cfs) {
3661       debug_stream.print(&quot; bytes: %d checksum: %08x&quot;,
3662                          cfs-&gt;length(),
3663                          ClassLoader::crc32(0, (const char*)cfs-&gt;buffer(),
3664                          cfs-&gt;length()));
3665     }
3666 
3667     msg.debug(&quot;%s&quot;, debug_stream.as_string());
3668   }
3669 }
3670 
3671 // Verification
3672 
3673 class VerifyFieldClosure: public BasicOopIterateClosure {
3674  protected:
3675   template &lt;class T&gt; void do_oop_work(T* p) {
3676     oop obj = RawAccess&lt;&gt;::oop_load(p);
3677     if (!oopDesc::is_oop_or_null(obj)) {
3678       tty-&gt;print_cr(&quot;Failed: &quot; PTR_FORMAT &quot; -&gt; &quot; PTR_FORMAT, p2i(p), p2i(obj));
3679       Universe::print_on(tty);
3680       guarantee(false, &quot;boom&quot;);
3681     }
3682   }
3683  public:
3684   virtual void do_oop(oop* p)       { VerifyFieldClosure::do_oop_work(p); }
3685   virtual void do_oop(narrowOop* p) { VerifyFieldClosure::do_oop_work(p); }
3686 };
3687 
3688 void InstanceKlass::verify_on(outputStream* st) {
3689 #ifndef PRODUCT
3690   // Avoid redundant verifies, this really should be in product.
3691   if (_verify_count == Universe::verify_count()) return;
3692   _verify_count = Universe::verify_count();
3693 #endif
3694 
3695   // Verify Klass
3696   Klass::verify_on(st);
3697 
3698   // Verify that klass is present in ClassLoaderData
3699   guarantee(class_loader_data()-&gt;contains_klass(this),
3700             &quot;this class isn&#39;t found in class loader data&quot;);
3701 
3702   // Verify vtables
3703   if (is_linked()) {
3704     // $$$ This used to be done only for m/s collections.  Doing it
3705     // always seemed a valid generalization.  (DLD -- 6/00)
3706     vtable().verify(st);
3707   }
3708 
3709   // Verify first subklass
3710   if (subklass() != NULL) {
3711     guarantee(subklass()-&gt;is_klass(), &quot;should be klass&quot;);
3712   }
3713 
3714   // Verify siblings
3715   Klass* super = this-&gt;super();
3716   Klass* sib = next_sibling();
3717   if (sib != NULL) {
3718     if (sib == this) {
3719       fatal(&quot;subclass points to itself &quot; PTR_FORMAT, p2i(sib));
3720     }
3721 
3722     guarantee(sib-&gt;is_klass(), &quot;should be klass&quot;);
3723     guarantee(sib-&gt;super() == super, &quot;siblings should have same superklass&quot;);
3724   }
3725 
3726   // Verify local interfaces
3727   if (local_interfaces()) {
3728     Array&lt;InstanceKlass*&gt;* local_interfaces = this-&gt;local_interfaces();
3729     for (int j = 0; j &lt; local_interfaces-&gt;length(); j++) {
3730       InstanceKlass* e = local_interfaces-&gt;at(j);
3731       guarantee(e-&gt;is_klass() &amp;&amp; e-&gt;is_interface(), &quot;invalid local interface&quot;);
3732     }
3733   }
3734 
3735   // Verify transitive interfaces
3736   if (transitive_interfaces() != NULL) {
3737     Array&lt;InstanceKlass*&gt;* transitive_interfaces = this-&gt;transitive_interfaces();
3738     for (int j = 0; j &lt; transitive_interfaces-&gt;length(); j++) {
3739       InstanceKlass* e = transitive_interfaces-&gt;at(j);
3740       guarantee(e-&gt;is_klass() &amp;&amp; e-&gt;is_interface(), &quot;invalid transitive interface&quot;);
3741     }
3742   }
3743 
3744   // Verify methods
3745   if (methods() != NULL) {
3746     Array&lt;Method*&gt;* methods = this-&gt;methods();
3747     for (int j = 0; j &lt; methods-&gt;length(); j++) {
3748       guarantee(methods-&gt;at(j)-&gt;is_method(), &quot;non-method in methods array&quot;);
3749     }
3750     for (int j = 0; j &lt; methods-&gt;length() - 1; j++) {
3751       Method* m1 = methods-&gt;at(j);
3752       Method* m2 = methods-&gt;at(j + 1);
3753       guarantee(m1-&gt;name()-&gt;fast_compare(m2-&gt;name()) &lt;= 0, &quot;methods not sorted correctly&quot;);
3754     }
3755   }
3756 
3757   // Verify method ordering
3758   if (method_ordering() != NULL) {
3759     Array&lt;int&gt;* method_ordering = this-&gt;method_ordering();
3760     int length = method_ordering-&gt;length();
3761     if (JvmtiExport::can_maintain_original_method_order() ||
3762         ((UseSharedSpaces || Arguments::is_dumping_archive()) &amp;&amp; length != 0)) {
3763       guarantee(length == methods()-&gt;length(), &quot;invalid method ordering length&quot;);
3764       jlong sum = 0;
3765       for (int j = 0; j &lt; length; j++) {
3766         int original_index = method_ordering-&gt;at(j);
3767         guarantee(original_index &gt;= 0, &quot;invalid method ordering index&quot;);
3768         guarantee(original_index &lt; length, &quot;invalid method ordering index&quot;);
3769         sum += original_index;
3770       }
3771       // Verify sum of indices 0,1,...,length-1
3772       guarantee(sum == ((jlong)length*(length-1))/2, &quot;invalid method ordering sum&quot;);
3773     } else {
3774       guarantee(length == 0, &quot;invalid method ordering length&quot;);
3775     }
3776   }
3777 
3778   // Verify default methods
3779   if (default_methods() != NULL) {
3780     Array&lt;Method*&gt;* methods = this-&gt;default_methods();
3781     for (int j = 0; j &lt; methods-&gt;length(); j++) {
3782       guarantee(methods-&gt;at(j)-&gt;is_method(), &quot;non-method in methods array&quot;);
3783     }
3784     for (int j = 0; j &lt; methods-&gt;length() - 1; j++) {
3785       Method* m1 = methods-&gt;at(j);
3786       Method* m2 = methods-&gt;at(j + 1);
3787       guarantee(m1-&gt;name()-&gt;fast_compare(m2-&gt;name()) &lt;= 0, &quot;methods not sorted correctly&quot;);
3788     }
3789   }
3790 
3791   // Verify JNI static field identifiers
3792   if (jni_ids() != NULL) {
3793     jni_ids()-&gt;verify(this);
3794   }
3795 
3796   // Verify other fields
3797   if (array_klasses() != NULL) {
3798     guarantee(array_klasses()-&gt;is_klass(), &quot;should be klass&quot;);
3799   }
3800   if (constants() != NULL) {
3801     guarantee(constants()-&gt;is_constantPool(), &quot;should be constant pool&quot;);
3802   }
3803   const Klass* anonymous_host = unsafe_anonymous_host();
3804   if (anonymous_host != NULL) {
3805     guarantee(anonymous_host-&gt;is_klass(), &quot;should be klass&quot;);
3806   }
3807 }
3808 
3809 void InstanceKlass::oop_verify_on(oop obj, outputStream* st) {
3810   Klass::oop_verify_on(obj, st);
3811   VerifyFieldClosure blk;
3812   obj-&gt;oop_iterate(&amp;blk);
3813 }
3814 
3815 
3816 // JNIid class for jfieldIDs only
3817 // Note to reviewers:
3818 // These JNI functions are just moved over to column 1 and not changed
3819 // in the compressed oops workspace.
3820 JNIid::JNIid(Klass* holder, int offset, JNIid* next) {
3821   _holder = holder;
3822   _offset = offset;
3823   _next = next;
3824   debug_only(_is_static_field_id = false;)
3825 }
3826 
3827 
3828 JNIid* JNIid::find(int offset) {
3829   JNIid* current = this;
3830   while (current != NULL) {
3831     if (current-&gt;offset() == offset) return current;
3832     current = current-&gt;next();
3833   }
3834   return NULL;
3835 }
3836 
3837 void JNIid::deallocate(JNIid* current) {
3838   while (current != NULL) {
3839     JNIid* next = current-&gt;next();
3840     delete current;
3841     current = next;
3842   }
3843 }
3844 
3845 
3846 void JNIid::verify(Klass* holder) {
3847   int first_field_offset  = InstanceMirrorKlass::offset_of_static_fields();
3848   int end_field_offset;
3849   end_field_offset = first_field_offset + (InstanceKlass::cast(holder)-&gt;static_field_size() * wordSize);
3850 
3851   JNIid* current = this;
3852   while (current != NULL) {
3853     guarantee(current-&gt;holder() == holder, &quot;Invalid klass in JNIid&quot;);
3854 #ifdef ASSERT
3855     int o = current-&gt;offset();
3856     if (current-&gt;is_static_field_id()) {
3857       guarantee(o &gt;= first_field_offset  &amp;&amp; o &lt; end_field_offset,  &quot;Invalid static field offset in JNIid&quot;);
3858     }
3859 #endif
3860     current = current-&gt;next();
3861   }
3862 }
3863 
3864 void InstanceKlass::set_init_state(ClassState state) {
3865 #ifdef ASSERT
3866   bool good_state = is_shared() ? (_init_state &lt;= state)
3867                                                : (_init_state &lt; state);
3868   assert(good_state || state == allocated, &quot;illegal state transition&quot;);
3869 #endif
3870   assert(_init_thread == NULL, &quot;should be cleared before state change&quot;);
3871   _init_state = (u1)state;
3872 }
3873 
3874 #if INCLUDE_JVMTI
3875 
3876 // RedefineClasses() support for previous versions
3877 
3878 // Globally, there is at least one previous version of a class to walk
3879 // during class unloading, which is saved because old methods in the class
3880 // are still running.   Otherwise the previous version list is cleaned up.
3881 bool InstanceKlass::_has_previous_versions = false;
3882 
3883 // Returns true if there are previous versions of a class for class
3884 // unloading only. Also resets the flag to false. purge_previous_version
3885 // will set the flag to true if there are any left, i.e., if there&#39;s any
3886 // work to do for next time. This is to avoid the expensive code cache
3887 // walk in CLDG::clean_deallocate_lists().
3888 bool InstanceKlass::has_previous_versions_and_reset() {
3889   bool ret = _has_previous_versions;
3890   log_trace(redefine, class, iklass, purge)(&quot;Class unloading: has_previous_versions = %s&quot;,
3891      ret ? &quot;true&quot; : &quot;false&quot;);
3892   _has_previous_versions = false;
3893   return ret;
3894 }
3895 
3896 // Purge previous versions before adding new previous versions of the class and
3897 // during class unloading.
3898 void InstanceKlass::purge_previous_version_list() {
3899   assert(SafepointSynchronize::is_at_safepoint(), &quot;only called at safepoint&quot;);
3900   assert(has_been_redefined(), &quot;Should only be called for main class&quot;);
3901 
3902   // Quick exit.
3903   if (previous_versions() == NULL) {
3904     return;
3905   }
3906 
3907   // This klass has previous versions so see what we can cleanup
3908   // while it is safe to do so.
3909 
3910   int deleted_count = 0;    // leave debugging breadcrumbs
3911   int live_count = 0;
3912   ClassLoaderData* loader_data = class_loader_data();
3913   assert(loader_data != NULL, &quot;should never be null&quot;);
3914 
3915   ResourceMark rm;
3916   log_trace(redefine, class, iklass, purge)(&quot;%s: previous versions&quot;, external_name());
3917 
3918   // previous versions are linked together through the InstanceKlass
3919   InstanceKlass* pv_node = previous_versions();
3920   InstanceKlass* last = this;
3921   int version = 0;
3922 
3923   // check the previous versions list
3924   for (; pv_node != NULL; ) {
3925 
3926     ConstantPool* pvcp = pv_node-&gt;constants();
3927     assert(pvcp != NULL, &quot;cp ref was unexpectedly cleared&quot;);
3928 
3929     if (!pvcp-&gt;on_stack()) {
3930       // If the constant pool isn&#39;t on stack, none of the methods
3931       // are executing.  Unlink this previous_version.
3932       // The previous version InstanceKlass is on the ClassLoaderData deallocate list
3933       // so will be deallocated during the next phase of class unloading.
3934       log_trace(redefine, class, iklass, purge)
3935         (&quot;previous version &quot; INTPTR_FORMAT &quot; is dead.&quot;, p2i(pv_node));
3936       // For debugging purposes.
3937       pv_node-&gt;set_is_scratch_class();
3938       // Unlink from previous version list.
3939       assert(pv_node-&gt;class_loader_data() == loader_data, &quot;wrong loader_data&quot;);
3940       InstanceKlass* next = pv_node-&gt;previous_versions();
3941       pv_node-&gt;link_previous_versions(NULL);   // point next to NULL
3942       last-&gt;link_previous_versions(next);
3943       // Add to the deallocate list after unlinking
3944       loader_data-&gt;add_to_deallocate_list(pv_node);
3945       pv_node = next;
3946       deleted_count++;
3947       version++;
3948       continue;
3949     } else {
3950       log_trace(redefine, class, iklass, purge)(&quot;previous version &quot; INTPTR_FORMAT &quot; is alive&quot;, p2i(pv_node));
3951       assert(pvcp-&gt;pool_holder() != NULL, &quot;Constant pool with no holder&quot;);
3952       guarantee (!loader_data-&gt;is_unloading(), &quot;unloaded classes can&#39;t be on the stack&quot;);
3953       live_count++;
3954       // found a previous version for next time we do class unloading
3955       _has_previous_versions = true;
3956     }
3957 
3958     // At least one method is live in this previous version.
3959     // Reset dead EMCP methods not to get breakpoints.
3960     // All methods are deallocated when all of the methods for this class are no
3961     // longer running.
3962     Array&lt;Method*&gt;* method_refs = pv_node-&gt;methods();
3963     if (method_refs != NULL) {
3964       log_trace(redefine, class, iklass, purge)(&quot;previous methods length=%d&quot;, method_refs-&gt;length());
3965       for (int j = 0; j &lt; method_refs-&gt;length(); j++) {
3966         Method* method = method_refs-&gt;at(j);
3967 
3968         if (!method-&gt;on_stack()) {
3969           // no breakpoints for non-running methods
3970           if (method-&gt;is_running_emcp()) {
3971             method-&gt;set_running_emcp(false);
3972           }
3973         } else {
3974           assert (method-&gt;is_obsolete() || method-&gt;is_running_emcp(),
3975                   &quot;emcp method cannot run after emcp bit is cleared&quot;);
3976           log_trace(redefine, class, iklass, purge)
3977             (&quot;purge: %s(%s): prev method @%d in version @%d is alive&quot;,
3978              method-&gt;name()-&gt;as_C_string(), method-&gt;signature()-&gt;as_C_string(), j, version);
3979         }
3980       }
3981     }
3982     // next previous version
3983     last = pv_node;
3984     pv_node = pv_node-&gt;previous_versions();
3985     version++;
3986   }
3987   log_trace(redefine, class, iklass, purge)
3988     (&quot;previous version stats: live=%d, deleted=%d&quot;, live_count, deleted_count);
3989 }
3990 
3991 void InstanceKlass::mark_newly_obsolete_methods(Array&lt;Method*&gt;* old_methods,
3992                                                 int emcp_method_count) {
3993   int obsolete_method_count = old_methods-&gt;length() - emcp_method_count;
3994 
3995   if (emcp_method_count != 0 &amp;&amp; obsolete_method_count != 0 &amp;&amp;
3996       _previous_versions != NULL) {
3997     // We have a mix of obsolete and EMCP methods so we have to
3998     // clear out any matching EMCP method entries the hard way.
3999     int local_count = 0;
4000     for (int i = 0; i &lt; old_methods-&gt;length(); i++) {
4001       Method* old_method = old_methods-&gt;at(i);
4002       if (old_method-&gt;is_obsolete()) {
4003         // only obsolete methods are interesting
4004         Symbol* m_name = old_method-&gt;name();
4005         Symbol* m_signature = old_method-&gt;signature();
4006 
4007         // previous versions are linked together through the InstanceKlass
4008         int j = 0;
4009         for (InstanceKlass* prev_version = _previous_versions;
4010              prev_version != NULL;
4011              prev_version = prev_version-&gt;previous_versions(), j++) {
4012 
4013           Array&lt;Method*&gt;* method_refs = prev_version-&gt;methods();
4014           for (int k = 0; k &lt; method_refs-&gt;length(); k++) {
4015             Method* method = method_refs-&gt;at(k);
4016 
4017             if (!method-&gt;is_obsolete() &amp;&amp;
4018                 method-&gt;name() == m_name &amp;&amp;
4019                 method-&gt;signature() == m_signature) {
4020               // The current RedefineClasses() call has made all EMCP
4021               // versions of this method obsolete so mark it as obsolete
4022               log_trace(redefine, class, iklass, add)
4023                 (&quot;%s(%s): flush obsolete method @%d in version @%d&quot;,
4024                  m_name-&gt;as_C_string(), m_signature-&gt;as_C_string(), k, j);
4025 
4026               method-&gt;set_is_obsolete();
4027               break;
4028             }
4029           }
4030 
4031           // The previous loop may not find a matching EMCP method, but
4032           // that doesn&#39;t mean that we can optimize and not go any
4033           // further back in the PreviousVersion generations. The EMCP
4034           // method for this generation could have already been made obsolete,
4035           // but there still may be an older EMCP method that has not
4036           // been made obsolete.
4037         }
4038 
4039         if (++local_count &gt;= obsolete_method_count) {
4040           // no more obsolete methods so bail out now
4041           break;
4042         }
4043       }
4044     }
4045   }
4046 }
4047 
4048 // Save the scratch_class as the previous version if any of the methods are running.
4049 // The previous_versions are used to set breakpoints in EMCP methods and they are
4050 // also used to clean MethodData links to redefined methods that are no longer running.
4051 void InstanceKlass::add_previous_version(InstanceKlass* scratch_class,
4052                                          int emcp_method_count) {
4053   assert(Thread::current()-&gt;is_VM_thread(),
4054          &quot;only VMThread can add previous versions&quot;);
4055 
4056   ResourceMark rm;
4057   log_trace(redefine, class, iklass, add)
4058     (&quot;adding previous version ref for %s, EMCP_cnt=%d&quot;, scratch_class-&gt;external_name(), emcp_method_count);
4059 
4060   // Clean out old previous versions for this class
4061   purge_previous_version_list();
4062 
4063   // Mark newly obsolete methods in remaining previous versions.  An EMCP method from
4064   // a previous redefinition may be made obsolete by this redefinition.
4065   Array&lt;Method*&gt;* old_methods = scratch_class-&gt;methods();
4066   mark_newly_obsolete_methods(old_methods, emcp_method_count);
4067 
4068   // If the constant pool for this previous version of the class
4069   // is not marked as being on the stack, then none of the methods
4070   // in this previous version of the class are on the stack so
4071   // we don&#39;t need to add this as a previous version.
4072   ConstantPool* cp_ref = scratch_class-&gt;constants();
4073   if (!cp_ref-&gt;on_stack()) {
4074     log_trace(redefine, class, iklass, add)(&quot;scratch class not added; no methods are running&quot;);
4075     // For debugging purposes.
4076     scratch_class-&gt;set_is_scratch_class();
4077     scratch_class-&gt;class_loader_data()-&gt;add_to_deallocate_list(scratch_class);
4078     return;
4079   }
4080 
4081   if (emcp_method_count != 0) {
4082     // At least one method is still running, check for EMCP methods
4083     for (int i = 0; i &lt; old_methods-&gt;length(); i++) {
4084       Method* old_method = old_methods-&gt;at(i);
4085       if (!old_method-&gt;is_obsolete() &amp;&amp; old_method-&gt;on_stack()) {
4086         // if EMCP method (not obsolete) is on the stack, mark as EMCP so that
4087         // we can add breakpoints for it.
4088 
4089         // We set the method-&gt;on_stack bit during safepoints for class redefinition
4090         // and use this bit to set the is_running_emcp bit.
4091         // After the safepoint, the on_stack bit is cleared and the running emcp
4092         // method may exit.   If so, we would set a breakpoint in a method that
4093         // is never reached, but this won&#39;t be noticeable to the programmer.
4094         old_method-&gt;set_running_emcp(true);
4095         log_trace(redefine, class, iklass, add)
4096           (&quot;EMCP method %s is on_stack &quot; INTPTR_FORMAT, old_method-&gt;name_and_sig_as_C_string(), p2i(old_method));
4097       } else if (!old_method-&gt;is_obsolete()) {
4098         log_trace(redefine, class, iklass, add)
4099           (&quot;EMCP method %s is NOT on_stack &quot; INTPTR_FORMAT, old_method-&gt;name_and_sig_as_C_string(), p2i(old_method));
4100       }
4101     }
4102   }
4103 
4104   // Add previous version if any methods are still running.
4105   // Set has_previous_version flag for processing during class unloading.
4106   _has_previous_versions = true;
4107   log_trace(redefine, class, iklass, add) (&quot;scratch class added; one of its methods is on_stack.&quot;);
4108   assert(scratch_class-&gt;previous_versions() == NULL, &quot;shouldn&#39;t have a previous version&quot;);
4109   scratch_class-&gt;link_previous_versions(previous_versions());
4110   link_previous_versions(scratch_class);
4111 } // end add_previous_version()
4112 
4113 #endif // INCLUDE_JVMTI
4114 
4115 Method* InstanceKlass::method_with_idnum(int idnum) {
4116   Method* m = NULL;
4117   if (idnum &lt; methods()-&gt;length()) {
4118     m = methods()-&gt;at(idnum);
4119   }
4120   if (m == NULL || m-&gt;method_idnum() != idnum) {
4121     for (int index = 0; index &lt; methods()-&gt;length(); ++index) {
4122       m = methods()-&gt;at(index);
4123       if (m-&gt;method_idnum() == idnum) {
4124         return m;
4125       }
4126     }
4127     // None found, return null for the caller to handle.
4128     return NULL;
4129   }
4130   return m;
4131 }
4132 
4133 
4134 Method* InstanceKlass::method_with_orig_idnum(int idnum) {
4135   if (idnum &gt;= methods()-&gt;length()) {
4136     return NULL;
4137   }
4138   Method* m = methods()-&gt;at(idnum);
4139   if (m != NULL &amp;&amp; m-&gt;orig_method_idnum() == idnum) {
4140     return m;
4141   }
4142   // Obsolete method idnum does not match the original idnum
4143   for (int index = 0; index &lt; methods()-&gt;length(); ++index) {
4144     m = methods()-&gt;at(index);
4145     if (m-&gt;orig_method_idnum() == idnum) {
4146       return m;
4147     }
4148   }
4149   // None found, return null for the caller to handle.
4150   return NULL;
4151 }
4152 
4153 
4154 Method* InstanceKlass::method_with_orig_idnum(int idnum, int version) {
4155   InstanceKlass* holder = get_klass_version(version);
4156   if (holder == NULL) {
4157     return NULL; // The version of klass is gone, no method is found
4158   }
4159   Method* method = holder-&gt;method_with_orig_idnum(idnum);
4160   return method;
4161 }
4162 
4163 #if INCLUDE_JVMTI
4164 JvmtiCachedClassFileData* InstanceKlass::get_cached_class_file() {
4165   return _cached_class_file;
4166 }
4167 
4168 jint InstanceKlass::get_cached_class_file_len() {
4169   return VM_RedefineClasses::get_cached_class_file_len(_cached_class_file);
4170 }
4171 
4172 unsigned char * InstanceKlass::get_cached_class_file_bytes() {
4173   return VM_RedefineClasses::get_cached_class_file_bytes(_cached_class_file);
4174 }
4175 #endif
4176 
4177 #define THROW_DVT_ERROR(s) \
4178   Exceptions::fthrow(THREAD_AND_LOCATION, vmSymbols::java_lang_IncompatibleClassChangeError(), \
4179       &quot;ValueCapableClass class &#39;%s&#39; %s&quot;, external_name(),(s)); \
4180       return
<a name="11" id="anc11"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="11" type="hidden" />
</body>
</html>