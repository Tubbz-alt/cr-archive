<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/classfile/fieldLayoutBuilder.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (c) 2019, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;jvm.h&quot;
  27 #include &quot;classfile/classFileParser.hpp&quot;
  28 #include &quot;classfile/fieldLayoutBuilder.hpp&quot;
  29 #include &quot;memory/resourceArea.hpp&quot;
  30 #include &quot;oops/array.hpp&quot;
  31 #include &quot;oops/fieldStreams.inline.hpp&quot;
  32 #include &quot;oops/instanceMirrorKlass.hpp&quot;
  33 #include &quot;oops/klass.inline.hpp&quot;
  34 #include &quot;oops/valueKlass.inline.hpp&quot;
  35 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  36 
  37 LayoutRawBlock::LayoutRawBlock(Kind kind, int size) :
  38   _next_block(NULL),
  39   _prev_block(NULL),
  40   _value_klass(NULL),
  41   _kind(kind),
  42   _offset(-1),
  43   _alignment(1),
  44   _size(size),
  45   _field_index(-1),
  46   _is_reference(false) {
  47   assert(kind == EMPTY || kind == RESERVED || kind == PADDING || kind == INHERITED,
  48          &quot;Otherwise, should use the constructor with a field index argument&quot;);
  49   assert(size &gt; 0, &quot;Sanity check&quot;);
  50 }
  51 
  52 
  53 LayoutRawBlock::LayoutRawBlock(int index, Kind kind, int size, int alignment, bool is_reference) :
  54  _next_block(NULL),
  55  _prev_block(NULL),
  56  _value_klass(NULL),
  57  _kind(kind),
  58  _offset(-1),
  59  _alignment(alignment),
  60  _size(size),
  61  _field_index(index),
  62  _is_reference(is_reference) {
  63   assert(kind == REGULAR || kind == FLATTENED || kind == INHERITED,
  64          &quot;Other kind do not have a field index&quot;);
  65   assert(size &gt; 0, &quot;Sanity check&quot;);
  66   assert(alignment &gt; 0, &quot;Sanity check&quot;);
  67 }
  68 
  69 bool LayoutRawBlock::fit(int size, int alignment) {
  70   int adjustment = 0;
  71   if ((_offset % alignment) != 0) {
  72     adjustment = alignment - (_offset % alignment);
  73   }
  74   return _size &gt;= size + adjustment;
  75 }
  76 
  77 FieldGroup::FieldGroup(int contended_group) :
  78   _next(NULL),
  79   _primitive_fields(NULL),
  80   _oop_fields(NULL),
  81   _flattened_fields(NULL),
  82   _contended_group(contended_group),  // -1 means no contended group, 0 means default contended group
  83   _oop_count(0) {}
  84 
  85 void FieldGroup::add_primitive_field(AllFieldStream fs, BasicType type) {
  86   int size = type2aelembytes(type);
  87   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size /* alignment == size for primitive types */, false);
  88   if (_primitive_fields == NULL) {
  89     _primitive_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
  90   }
  91   _primitive_fields-&gt;append(block);
  92 }
  93 
  94 void FieldGroup::add_oop_field(AllFieldStream fs) {
  95   int size = type2aelembytes(T_OBJECT);
  96   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::REGULAR, size, size /* alignment == size for oops */, true);
  97   if (_oop_fields == NULL) {
  98     _oop_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
  99   }
 100   _oop_fields-&gt;append(block);
 101   _oop_count++;
 102 }
 103 
 104 void FieldGroup::add_flattened_field(AllFieldStream fs, ValueKlass* vk) {
 105   // _flattened_fields list might be merged with the _primitive_fields list in the future
 106   LayoutRawBlock* block = new LayoutRawBlock(fs.index(), LayoutRawBlock::FLATTENED, vk-&gt;get_exact_size_in_bytes(), vk-&gt;get_alignment(), false);
 107   block-&gt;set_value_klass(vk);
 108   if (_flattened_fields == NULL) {
 109     _flattened_fields = new(ResourceObj::RESOURCE_AREA, mtInternal) GrowableArray&lt;LayoutRawBlock*&gt;(INITIAL_LIST_SIZE);
 110   }
 111   _flattened_fields-&gt;append(block);
 112 }
 113 
 114 void FieldGroup::sort_by_size() {
 115   if (_primitive_fields != NULL) {
 116     _primitive_fields-&gt;sort(LayoutRawBlock::compare_size_inverted);
 117   }
 118   if (_flattened_fields != NULL) {
 119     _flattened_fields-&gt;sort(LayoutRawBlock::compare_size_inverted);
 120   }
 121 }
 122 
 123 FieldLayout::FieldLayout(Array&lt;u2&gt;* fields, ConstantPool* cp) :
 124   _fields(fields),
 125   _cp(cp),
 126   _blocks(NULL),
 127   _start(_blocks),
 128   _last(_blocks) {}
 129 
 130 void FieldLayout::initialize_static_layout() {
 131   _blocks = new LayoutRawBlock(LayoutRawBlock::EMPTY, INT_MAX);
 132   _blocks-&gt;set_offset(0);
 133   _last = _blocks;
 134   _start = _blocks;
 135   // Note: at this stage, InstanceMirrorKlass::offset_of_static_fields() could be zero, because
 136   // during bootstrapping, the size of the java.lang.Class is still not known when layout
 137   // of static field is computed. Field offsets are fixed later when the size is known
 138   // (see java_lang_Class::fixup_mirror())
 139   if (InstanceMirrorKlass::offset_of_static_fields() &gt; 0) {
 140     insert(first_empty_block(), new LayoutRawBlock(LayoutRawBlock::RESERVED, InstanceMirrorKlass::offset_of_static_fields()));
 141     _blocks-&gt;set_offset(0);
 142   }
 143 }
 144 
 145 void FieldLayout::initialize_instance_layout(const InstanceKlass* super_klass) {
 146   if (super_klass == NULL) {
 147     _blocks = new LayoutRawBlock(LayoutRawBlock::EMPTY, INT_MAX);
 148     _blocks-&gt;set_offset(0);
 149     _last = _blocks;
 150     _start = _blocks;
 151     insert(first_empty_block(), new LayoutRawBlock(LayoutRawBlock::RESERVED, instanceOopDesc::base_offset_in_bytes()));
 152   } else {
 153     bool has_fields = reconstruct_layout(super_klass);
 154     fill_holes(super_klass);
 155     if ((UseEmptySlotsInSupers &amp;&amp; !super_klass-&gt;has_contended_annotations()) || !has_fields) {
 156       _start = _blocks; // Setting _start to _blocks instead of _last would allow subclasses
 157       // to allocate fields in empty slots of their super classes
 158     } else {
 159       _start = _last;    // append fields at the end of the reconstructed layout
 160     }
 161   }
 162 }
 163 
 164 LayoutRawBlock* FieldLayout::first_field_block() {
 165   LayoutRawBlock* block = _blocks;
 166   while (block != NULL
 167          &amp;&amp; block-&gt;kind() != LayoutRawBlock::INHERITED
 168          &amp;&amp; block-&gt;kind() != LayoutRawBlock::REGULAR
 169          &amp;&amp; block-&gt;kind() != LayoutRawBlock::FLATTENED) {
 170     block = block-&gt;next_block();
 171   }
 172   return block;
 173 }
 174 
 175 // Insert a set of fields into a layout.
 176 // For each field, search for an empty slot able to fit the field
 177 // (satisfying both size and alignment requirements), if none is found,
 178 // add the field at the end of the layout.
 179 // Fields cannot be inserted before the block specified in the &quot;start&quot; argument
 180 void FieldLayout::add(GrowableArray&lt;LayoutRawBlock*&gt;* list, LayoutRawBlock* start) {
 181   if (list == NULL) return;
 182   if (start == NULL) start = this-&gt;_start;
 183   bool last_search_success = false;
 184   int last_size = 0;
 185   int last_alignment = 0;
 186   for (int i = 0; i &lt; list-&gt;length(); i ++) {
 187     LayoutRawBlock* b = list-&gt;at(i);
 188     LayoutRawBlock* cursor = NULL;
 189     LayoutRawBlock* candidate = NULL;
 190     // if start is the last block, just append the field
 191     if (start == last_block()) {
 192       candidate = last_block();
 193     }
 194     // Before iterating over the layout to find an empty slot fitting the field&#39;s requirements,
 195     // check if the previous field had the same requirements and if the search for a fitting slot
 196     // was successful. If the requirements were the same but the search failed, a new search will
 197     // fail the same way, so just append the field at the of the layout.
 198     else  if (b-&gt;size() == last_size &amp;&amp; b-&gt;alignment() == last_alignment &amp;&amp; !last_search_success) {
 199       candidate = last_block();
 200     } else {
 201       // Iterate over the layout to find an empty slot fitting the field&#39;s requirements
 202       last_size = b-&gt;size();
 203       last_alignment = b-&gt;alignment();
 204       cursor = last_block()-&gt;prev_block();
 205       assert(cursor != NULL, &quot;Sanity check&quot;);
 206       last_search_success = true;
 207 
 208       while (cursor != start) {
 209         if (cursor-&gt;kind() == LayoutRawBlock::EMPTY &amp;&amp; cursor-&gt;fit(b-&gt;size(), b-&gt;alignment())) {
 210           if (candidate == NULL || cursor-&gt;size() &lt; candidate-&gt;size()) {
 211             candidate = cursor;
 212           }
 213         }
 214         cursor = cursor-&gt;prev_block();
 215       }
 216       if (candidate == NULL) {
 217         candidate = last_block();
 218         last_search_success = false;
 219       }
 220       assert(candidate != NULL, &quot;Candidate must not be null&quot;);
 221       assert(candidate-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Candidate must be an empty block&quot;);
 222       assert(candidate-&gt;fit(b-&gt;size(), b-&gt;alignment()), &quot;Candidate must be able to store the block&quot;);
 223     }
 224     insert_field_block(candidate, b);
 225   }
 226 }
 227 
 228 // Used for classes with hard coded field offsets, insert a field at the specified offset */
 229 void FieldLayout::add_field_at_offset(LayoutRawBlock* block, int offset, LayoutRawBlock* start) {
 230   assert(block != NULL, &quot;Sanity check&quot;);
 231   block-&gt;set_offset(offset);
 232   if (start == NULL) {
 233     start = this-&gt;_start;
 234   }
 235   LayoutRawBlock* slot = start;
 236   while (slot != NULL) {
 237     if ((slot-&gt;offset() &lt;= block-&gt;offset() &amp;&amp; (slot-&gt;offset() + slot-&gt;size()) &gt; block-&gt;offset()) ||
 238         slot == _last){
 239       assert(slot-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Matching slot must be an empty slot&quot;);
 240       assert(slot-&gt;size() &gt;= block-&gt;offset() + block-&gt;size() ,&quot;Matching slot must be big enough&quot;);
 241       if (slot-&gt;offset() &lt; block-&gt;offset()) {
 242         int adjustment = block-&gt;offset() - slot-&gt;offset();
 243         LayoutRawBlock* adj = new LayoutRawBlock(LayoutRawBlock::EMPTY, adjustment);
 244         insert(slot, adj);
 245       }
 246       insert(slot, block);
 247       if (slot-&gt;size() == 0) {
 248         remove(slot);
 249       }
 250       FieldInfo::from_field_array(_fields, block-&gt;field_index())-&gt;set_offset(block-&gt;offset());
 251       return;
 252     }
 253     slot = slot-&gt;next_block();
 254   }
 255   fatal(&quot;Should have found a matching slot above, corrupted layout or invalid offset&quot;);
 256 }
 257 
 258 // The allocation logic uses a best fit strategy: the set of fields is allocated
 259 // in the first empty slot big enough to contain the whole set ((including padding
 260 // to fit alignment constraints).
 261 void FieldLayout::add_contiguously(GrowableArray&lt;LayoutRawBlock*&gt;* list, LayoutRawBlock* start) {
 262   if (list == NULL) return;
 263   if (start == NULL) {
 264     start = _start;
 265   }
 266   // This code assumes that if the first block is well aligned, the following
 267   // blocks would naturally be well aligned (no need for adjustment)
 268   int size = 0;
 269   for (int i = 0; i &lt; list-&gt;length(); i++) {
 270     size += list-&gt;at(i)-&gt;size();
 271   }
 272 
 273   LayoutRawBlock* candidate = NULL;
 274   if (start == last_block()) {
 275     candidate = last_block();
 276   } else {
 277     LayoutRawBlock* first = list-&gt;at(0);
 278     candidate = last_block()-&gt;prev_block();
 279     while (candidate-&gt;kind() != LayoutRawBlock::EMPTY || !candidate-&gt;fit(size, first-&gt;alignment())) {
 280       if (candidate == start) {
 281         candidate = last_block();
 282         break;
 283       }
 284       candidate = candidate-&gt;prev_block();
 285     }
 286     assert(candidate != NULL, &quot;Candidate must not be null&quot;);
 287     assert(candidate-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Candidate must be an empty block&quot;);
 288     assert(candidate-&gt;fit(size, first-&gt;alignment()), &quot;Candidate must be able to store the whole contiguous block&quot;);
 289   }
 290 
 291   for (int i = 0; i &lt; list-&gt;length(); i++) {
 292     LayoutRawBlock* b = list-&gt;at(i);
 293     insert_field_block(candidate, b);
 294     assert((candidate-&gt;offset() % b-&gt;alignment() == 0), &quot;Contiguous blocks must be naturally well aligned&quot;);
 295   }
 296 }
 297 
 298 LayoutRawBlock* FieldLayout::insert_field_block(LayoutRawBlock* slot, LayoutRawBlock* block) {
 299   assert(slot-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Blocks can only be inserted in empty blocks&quot;);
 300   if (slot-&gt;offset() % block-&gt;alignment() != 0) {
 301     int adjustment = block-&gt;alignment() - (slot-&gt;offset() % block-&gt;alignment());
 302     LayoutRawBlock* adj = new LayoutRawBlock(LayoutRawBlock::EMPTY, adjustment);
 303     insert(slot, adj);
 304   }
 305   insert(slot, block);
 306   if (slot-&gt;size() == 0) {
 307     remove(slot);
 308   }
 309   FieldInfo::from_field_array(_fields, block-&gt;field_index())-&gt;set_offset(block-&gt;offset());
 310   return block;
 311 }
 312 
 313 bool FieldLayout::reconstruct_layout(const InstanceKlass* ik) {
 314   bool has_instance_fields = false;
 315   GrowableArray&lt;LayoutRawBlock*&gt;* all_fields = new GrowableArray&lt;LayoutRawBlock*&gt;(32);
 316   while (ik != NULL) {
 317     for (AllFieldStream fs(ik-&gt;fields(), ik-&gt;constants()); !fs.done(); fs.next()) {
 318       BasicType type = Signature::basic_type(fs.signature());
 319       // distinction between static and non-static fields is missing
 320       if (fs.access_flags().is_static()) continue;
 321       has_instance_fields = true;
 322       LayoutRawBlock* block;
 323       if (type == T_VALUETYPE) {
 324         ValueKlass* vk = ValueKlass::cast(ik-&gt;get_value_field_klass(fs.index()));
 325         block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED, vk-&gt;get_exact_size_in_bytes(),
 326                                    vk-&gt;get_alignment(), false);
 327 
 328       } else {
 329         int size = type2aelembytes(type);
 330         // INHERITED blocks are marked as non-reference because oop_maps are handled by their holder class
 331         block = new LayoutRawBlock(fs.index(), LayoutRawBlock::INHERITED, size, size, false);
 332       }
 333       block-&gt;set_offset(fs.offset());
 334       all_fields-&gt;append(block);
 335     }
 336     ik = ik-&gt;super() == NULL ? NULL : InstanceKlass::cast(ik-&gt;super());
 337   }
 338   all_fields-&gt;sort(LayoutRawBlock::compare_offset);
 339   _blocks = new LayoutRawBlock(LayoutRawBlock::RESERVED, instanceOopDesc::base_offset_in_bytes());
 340   _blocks-&gt;set_offset(0);
 341   _last = _blocks;
 342   for(int i = 0; i &lt; all_fields-&gt;length(); i++) {
 343     LayoutRawBlock* b = all_fields-&gt;at(i);
 344     _last-&gt;set_next_block(b);
 345     b-&gt;set_prev_block(_last);
 346     _last = b;
 347   }
 348   _start = _blocks;
 349   return has_instance_fields;
 350 }
 351 
 352 // Called during the reconstruction of a layout, after fields from super
 353 // classes have been inserted. It fills unused slots between inserted fields
 354 // with EMPTY blocks, so the regular field insertion methods would work.
 355 // This method handles classes with @Contended annotations differently
 356 // by inserting PADDING blocks instead of EMPTY block to prevent subclasses&#39;
 357 // fields to interfere with contended fields/classes.
 358 void FieldLayout::fill_holes(const InstanceKlass* super_klass) {
 359   assert(_blocks != NULL, &quot;Sanity check&quot;);
 360   assert(_blocks-&gt;offset() == 0, &quot;first block must be at offset zero&quot;);
 361   LayoutRawBlock::Kind filling_type = super_klass-&gt;has_contended_annotations() ? LayoutRawBlock::PADDING: LayoutRawBlock::EMPTY;
 362   LayoutRawBlock* b = _blocks;
 363   while (b-&gt;next_block() != NULL) {
 364     if (b-&gt;next_block()-&gt;offset() &gt; (b-&gt;offset() + b-&gt;size())) {
 365       int size = b-&gt;next_block()-&gt;offset() - (b-&gt;offset() + b-&gt;size());
 366       LayoutRawBlock* empty = new LayoutRawBlock(filling_type, size);
 367       empty-&gt;set_offset(b-&gt;offset() + b-&gt;size());
 368       empty-&gt;set_next_block(b-&gt;next_block());
 369       b-&gt;next_block()-&gt;set_prev_block(empty);
 370       b-&gt;set_next_block(empty);
 371       empty-&gt;set_prev_block(b);
 372     }
 373     b = b-&gt;next_block();
 374   }
 375   assert(b-&gt;next_block() == NULL, &quot;Invariant at this point&quot;);
 376   assert(b-&gt;kind() != LayoutRawBlock::EMPTY, &quot;Sanity check&quot;);
 377   // If the super class has @Contended annotation, a padding block is
 378   // inserted at the end to ensure that fields from the subclasses won&#39;t share
 379   // the cache line of the last field of the contended class
 380   if (super_klass-&gt;has_contended_annotations() &amp;&amp; ContendedPaddingWidth &gt; 0) {
 381     LayoutRawBlock* p = new LayoutRawBlock(LayoutRawBlock::PADDING, ContendedPaddingWidth);
 382     p-&gt;set_offset(b-&gt;offset() + b-&gt;size());
 383     b-&gt;set_next_block(p);
 384     p-&gt;set_prev_block(b);
 385     b = p;
 386   }
 387   if (!UseEmptySlotsInSupers) {
 388     // Add an empty slots to align fields of the subclass on a heapOopSize boundary
 389     // in order to emulate the behavior of the previous algorithm
 390     int align = (b-&gt;offset() + b-&gt;size()) % heapOopSize;
 391     if (align != 0) {
 392       int sz = heapOopSize - align;
 393       LayoutRawBlock* p = new LayoutRawBlock(LayoutRawBlock::EMPTY, sz);
 394       p-&gt;set_offset(b-&gt;offset() + b-&gt;size());
 395       b-&gt;set_next_block(p);
 396       p-&gt;set_prev_block(b);
 397       b = p;
 398     }
 399   }
 400   LayoutRawBlock* last = new LayoutRawBlock(LayoutRawBlock::EMPTY, INT_MAX);
 401   last-&gt;set_offset(b-&gt;offset() + b-&gt;size());
 402   assert(last-&gt;offset() &gt; 0, &quot;Sanity check&quot;);
 403   b-&gt;set_next_block(last);
 404   last-&gt;set_prev_block(b);
 405   _last = last;
 406 }
 407 
 408 LayoutRawBlock* FieldLayout::insert(LayoutRawBlock* slot, LayoutRawBlock* block) {
 409   assert(slot-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Blocks can only be inserted in empty blocks&quot;);
 410   assert(slot-&gt;offset() % block-&gt;alignment() == 0, &quot;Incompatible alignment&quot;);
 411   block-&gt;set_offset(slot-&gt;offset());
 412   slot-&gt;set_offset(slot-&gt;offset() + block-&gt;size());
 413   assert((slot-&gt;size() - block-&gt;size()) &lt; slot-&gt;size(), &quot;underflow checking&quot;);
 414   assert(slot-&gt;size() - block-&gt;size() &gt;= 0, &quot;no negative size allowed&quot;);
 415   slot-&gt;set_size(slot-&gt;size() - block-&gt;size());
 416   block-&gt;set_prev_block(slot-&gt;prev_block());
 417   block-&gt;set_next_block(slot);
 418   slot-&gt;set_prev_block(block);
 419   if (block-&gt;prev_block() != NULL) {
 420     block-&gt;prev_block()-&gt;set_next_block(block);
 421   }
 422   if (_blocks == slot) {
 423     _blocks = block;
 424   }
 425   return block;
 426 }
 427 
 428 void FieldLayout::remove(LayoutRawBlock* block) {
 429   assert(block != NULL, &quot;Sanity check&quot;);
 430   assert(block != _last, &quot;Sanity check&quot;);
 431   if (_blocks == block) {
 432     _blocks = block-&gt;next_block();
 433     if (_blocks != NULL) {
 434       _blocks-&gt;set_prev_block(NULL);
 435     }
 436   } else {
 437     assert(block-&gt;prev_block() != NULL, &quot;_prev should be set for non-head blocks&quot;);
 438     block-&gt;prev_block()-&gt;set_next_block(block-&gt;next_block());
 439     block-&gt;next_block()-&gt;set_prev_block(block-&gt;prev_block());
 440   }
 441   if (block == _start) {
 442     _start = block-&gt;prev_block();
 443   }
 444 }
 445 
 446 void FieldLayout::print(outputStream* output, bool is_static, const InstanceKlass* super) {
 447   ResourceMark rm;
 448   LayoutRawBlock* b = _blocks;
 449   while(b != _last) {
 450     switch(b-&gt;kind()) {
 451     case LayoutRawBlock::REGULAR: {
 452       FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
 453       output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
 454                        b-&gt;offset(),
 455                        fi-&gt;name(_cp)-&gt;as_C_string(),
 456                        fi-&gt;signature(_cp)-&gt;as_C_string(),
 457                        b-&gt;size(),
 458                        b-&gt;alignment(),
 459                        &quot;REGULAR&quot;);
 460       break;
 461     }
 462     case LayoutRawBlock::FLATTENED: {
 463       FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
 464       output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
 465                        b-&gt;offset(),
 466                        fi-&gt;name(_cp)-&gt;as_C_string(),
 467                        fi-&gt;signature(_cp)-&gt;as_C_string(),
 468                        b-&gt;size(),
 469                        b-&gt;alignment(),
 470                        &quot;FLATTENED&quot;);
 471       break;
 472     }
 473     case LayoutRawBlock::RESERVED: {
 474       output-&gt;print_cr(&quot; @%d %d/- %s&quot;,
 475                        b-&gt;offset(),
 476                        b-&gt;size(),
 477                        &quot;RESERVED&quot;);
 478       break;
 479     }
 480     case LayoutRawBlock::INHERITED: {
 481       assert(!is_static, &quot;Static fields are not inherited in layouts&quot;);
 482       assert(super != NULL, &quot;super klass must be provided to retrieve inherited fields info&quot;);
 483       bool found = false;
 484       const InstanceKlass* ik = super;
 485       while (!found &amp;&amp; ik != NULL) {
 486         for (AllFieldStream fs(ik-&gt;fields(), ik-&gt;constants()); !fs.done(); fs.next()) {
 487           if (fs.offset() == b-&gt;offset()) {
 488             output-&gt;print_cr(&quot; @%d \&quot;%s\&quot; %s %d/%d %s&quot;,
 489                 b-&gt;offset(),
 490                 fs.name()-&gt;as_C_string(),
 491                 fs.signature()-&gt;as_C_string(),
 492                 b-&gt;size(),
 493                 b-&gt;size(), // so far, alignment constraint == size, will change with Valhalla
 494                 &quot;INHERITED&quot;);
 495             found = true;
 496             break;
 497           }
 498         }
 499         ik = ik-&gt;java_super();
 500       }
 501       break;
 502     }
 503     case LayoutRawBlock::EMPTY:
 504       output-&gt;print_cr(&quot; @%d %d/1 %s&quot;,
 505                        b-&gt;offset(),
 506                        b-&gt;size(),
 507                        &quot;EMPTY&quot;);
 508       break;
 509     case LayoutRawBlock::PADDING:
 510       output-&gt;print_cr(&quot; @%d %d/1 %s&quot;,
 511                        b-&gt;offset(),
 512                        b-&gt;size(),
 513                        &quot;PADDING&quot;);
 514       break;
 515     }
 516     b = b-&gt;next_block();
 517   }
 518 }
 519 
 520 FieldLayoutBuilder::FieldLayoutBuilder(const Symbol* classname, const InstanceKlass* super_klass, ConstantPool* constant_pool,
 521                                        Array&lt;u2&gt;* fields, bool is_contended, bool is_value_type, ClassLoaderData* class_loader_data,
 522                                        Handle protection_domain, FieldLayoutInfo* info) :
 523   _classname(classname),
 524   _super_klass(super_klass),
 525   _constant_pool(constant_pool),
 526   _fields(fields),
 527   _info(info),
 528   _root_group(NULL),
 529   _contended_groups(GrowableArray&lt;FieldGroup*&gt;(8)),
 530   _static_fields(NULL),
 531   _layout(NULL),
 532   _static_layout(NULL),
 533   _class_loader_data(class_loader_data),
 534   _protection_domain(protection_domain),
 535   _nonstatic_oopmap_count(0),
 536   _alignment(-1),
 537   _first_field_offset(-1),
 538   _exact_size_in_bytes(-1),
 539   _has_nonstatic_fields(false),
 540   _is_contended(is_contended),
 541   _is_value_type(is_value_type),
<a name="1" id="anc1"></a><span class="line-modified"> 542   _has_flattening_information(is_value_type),</span>
<span class="line-added"> 543   _has_nonatomic_values(false),</span>
<span class="line-added"> 544   _atomic_field_count(0)</span>
<span class="line-added"> 545  {}</span>
 546 
 547 FieldGroup* FieldLayoutBuilder::get_or_create_contended_group(int g) {
 548   assert(g &gt; 0, &quot;must only be called for named contended groups&quot;);
 549   FieldGroup* fg = NULL;
 550   for (int i = 0; i &lt; _contended_groups.length(); i++) {
 551     fg = _contended_groups.at(i);
 552     if (fg-&gt;contended_group() == g) return fg;
 553   }
 554   fg = new FieldGroup(g);
 555   _contended_groups.append(fg);
 556   return fg;
 557 }
 558 
 559 void FieldLayoutBuilder::prologue() {
 560   _layout = new FieldLayout(_fields, _constant_pool);
 561   const InstanceKlass* super_klass = _super_klass;
 562   _layout-&gt;initialize_instance_layout(super_klass);
 563   if (super_klass != NULL) {
 564     _has_nonstatic_fields = super_klass-&gt;has_nonstatic_fields();
 565   }
 566   _static_layout = new FieldLayout(_fields, _constant_pool);
 567   _static_layout-&gt;initialize_static_layout();
 568   _static_fields = new FieldGroup();
 569   _root_group = new FieldGroup();
 570 }
 571 
 572 // Field sorting for regular (non-inline) classes:
 573 //   - fields are sorted in static and non-static fields
 574 //   - non-static fields are also sorted according to their contention group
 575 //     (support of the @Contended annotation)
 576 //   - @Contended annotation is ignored for static fields
 577 //   - field flattening decisions are taken in this method
 578 void FieldLayoutBuilder::regular_field_sorting() {
 579   for (AllFieldStream fs(_fields, _constant_pool); !fs.done(); fs.next()) {
 580     FieldGroup* group = NULL;
 581     if (fs.access_flags().is_static()) {
 582       group = _static_fields;
 583     } else {
 584       _has_nonstatic_fields = true;
<a name="2" id="anc2"></a><span class="line-added"> 585       _atomic_field_count++;  // we might decrement this</span>
 586       if (fs.is_contended()) {
 587         int g = fs.contended_group();
 588         if (g == 0) {
 589           group = new FieldGroup(true);
 590           _contended_groups.append(group);
 591         } else {
 592           group = get_or_create_contended_group(g);
 593         }
 594       } else {
 595         group = _root_group;
 596       }
 597     }
 598     assert(group != NULL, &quot;invariant&quot;);
 599     BasicType type = Signature::basic_type(fs.signature());
 600     switch(type) {
 601     case T_BYTE:
 602     case T_CHAR:
 603     case T_DOUBLE:
 604     case T_FLOAT:
 605     case T_INT:
 606     case T_LONG:
 607     case T_SHORT:
 608     case T_BOOLEAN:
 609       group-&gt;add_primitive_field(fs, type);
 610       break;
 611     case T_OBJECT:
 612     case T_ARRAY:
 613       if (group != _static_fields) _nonstatic_oopmap_count++;
 614       group-&gt;add_oop_field(fs);
 615       break;
 616     case T_VALUETYPE:
 617       if (group == _static_fields) {
 618         // static fields are never flattened
 619         group-&gt;add_oop_field(fs);
 620       } else {
 621         _has_flattening_information = true;
 622         // Flattening decision to be taken here
 623         // This code assumes all verification have been performed before
 624         // (field is a flattenable field, field&#39;s type has been loaded
 625         // and it is an inline klass
 626         Thread* THREAD = Thread::current();
 627         Klass* klass =
 628             SystemDictionary::resolve_flattenable_field_or_fail(&amp;fs,
 629                                                                 Handle(THREAD, _class_loader_data-&gt;class_loader()),
 630                                                                 _protection_domain, true, THREAD);
 631         assert(klass != NULL, &quot;Sanity check&quot;);
 632         ValueKlass* vk = ValueKlass::cast(klass);
<a name="3" id="anc3"></a><span class="line-modified"> 633         bool too_big_to_flatten = (ValueFieldMaxFlatSize &gt;= 0 &amp;&amp;</span>
<span class="line-modified"> 634                                    (vk-&gt;size_helper() * HeapWordSize) &gt; ValueFieldMaxFlatSize);</span>
<span class="line-modified"> 635         bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();</span>
<span class="line-modified"> 636         bool too_volatile_to_flatten = fs.access_flags().is_volatile();</span>
<span class="line-modified"> 637         if (vk-&gt;is_naturally_atomic()) {</span>
<span class="line-added"> 638           too_atomic_to_flatten = false;</span>
<span class="line-added"> 639           //too_volatile_to_flatten = false; //FIXME</span>
<span class="line-added"> 640           // volatile fields are currently never flattened, this could change in the future</span>
<span class="line-added"> 641         }</span>
<span class="line-added"> 642         if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {</span>
 643           group-&gt;add_flattened_field(fs, vk);
 644           _nonstatic_oopmap_count += vk-&gt;nonstatic_oop_map_count();
 645           fs.set_flattened(true);
<a name="4" id="anc4"></a><span class="line-added"> 646           if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note</span>
<span class="line-added"> 647             _has_nonatomic_values = true;</span>
<span class="line-added"> 648             _atomic_field_count--;  // every other field is atomic but this one</span>
<span class="line-added"> 649           }</span>
 650         } else {
 651           _nonstatic_oopmap_count++;
 652           group-&gt;add_oop_field(fs);
 653         }
 654       }
 655       break;
 656     default:
 657       fatal(&quot;Something wrong?&quot;);
 658     }
 659   }
 660   _root_group-&gt;sort_by_size();
 661   _static_fields-&gt;sort_by_size();
 662   if (!_contended_groups.is_empty()) {
 663     for (int i = 0; i &lt; _contended_groups.length(); i++) {
 664       _contended_groups.at(i)-&gt;sort_by_size();
 665     }
 666   }
 667 }
 668 
 669 /* Field sorting for inline classes:
 670  *   - because inline classes are immutable, the @Contended annotation is ignored
 671  *     when computing their layout (with only read operation, there&#39;s no false
 672  *     sharing issue)
 673  *   - this method also records the alignment of the field with the most
 674  *     constraining alignment, this value is then used as the alignment
 675  *     constraint when flattening this inline type into another container
 676  *   - field flattening decisions are taken in this method (those decisions are
 677  *     currently only based in the size of the fields to be flattened, the size
 678  *     of the resulting instance is not considered)
 679  */
 680 void FieldLayoutBuilder::inline_class_field_sorting(TRAPS) {
 681   assert(_is_value_type, &quot;Should only be used for inline classes&quot;);
 682   int alignment = 1;
 683   for (AllFieldStream fs(_fields, _constant_pool); !fs.done(); fs.next()) {
 684     FieldGroup* group = NULL;
 685     int field_alignment = 1;
 686     if (fs.access_flags().is_static()) {
 687       group = _static_fields;
 688     } else {
 689       _has_nonstatic_fields = true;
<a name="5" id="anc5"></a><span class="line-added"> 690       _atomic_field_count++;  // we might decrement this</span>
 691       group = _root_group;
 692     }
 693     assert(group != NULL, &quot;invariant&quot;);
 694     BasicType type = Signature::basic_type(fs.signature());
 695     switch(type) {
 696     case T_BYTE:
 697     case T_CHAR:
 698     case T_DOUBLE:
 699     case T_FLOAT:
 700     case T_INT:
 701     case T_LONG:
 702     case T_SHORT:
 703     case T_BOOLEAN:
 704       if (group != _static_fields) {
 705         field_alignment = type2aelembytes(type); // alignment == size for primitive types
 706       }
 707       group-&gt;add_primitive_field(fs, type);
 708       break;
 709     case T_OBJECT:
 710     case T_ARRAY:
 711       if (group != _static_fields) {
 712         _nonstatic_oopmap_count++;
 713         field_alignment = type2aelembytes(type); // alignment == size for oops
 714       }
 715       group-&gt;add_oop_field(fs);
 716       break;
 717     case T_VALUETYPE: {
 718       if (group == _static_fields) {
 719         // static fields are never flattened
 720         group-&gt;add_oop_field(fs);
 721       } else {
 722         // Flattening decision to be taken here
 723         // This code assumes all verifications have been performed before
 724         // (field is a flattenable field, field&#39;s type has been loaded
 725         // and it is an inline klass
 726         Thread* THREAD = Thread::current();
 727         Klass* klass =
 728             SystemDictionary::resolve_flattenable_field_or_fail(&amp;fs,
 729                 Handle(THREAD, _class_loader_data-&gt;class_loader()),
 730                 _protection_domain, true, CHECK);
 731         assert(klass != NULL, &quot;Sanity check&quot;);
 732         ValueKlass* vk = ValueKlass::cast(klass);
<a name="6" id="anc6"></a><span class="line-modified"> 733         bool too_big_to_flatten = (ValueFieldMaxFlatSize &gt;= 0 &amp;&amp;</span>
<span class="line-modified"> 734                                    (vk-&gt;size_helper() * HeapWordSize) &gt; ValueFieldMaxFlatSize);</span>
<span class="line-modified"> 735         bool too_atomic_to_flatten = vk-&gt;is_declared_atomic();</span>
<span class="line-added"> 736         bool too_volatile_to_flatten = fs.access_flags().is_volatile();</span>
<span class="line-added"> 737         if (vk-&gt;is_naturally_atomic()) {</span>
<span class="line-added"> 738           too_atomic_to_flatten = false;</span>
<span class="line-added"> 739           //too_volatile_to_flatten = false; //FIXME</span>
<span class="line-added"> 740           // volatile fields are currently never flattened, this could change in the future</span>
<span class="line-added"> 741         }</span>
<span class="line-added"> 742         if (!(too_big_to_flatten | too_atomic_to_flatten | too_volatile_to_flatten)) {</span>
 743           group-&gt;add_flattened_field(fs, vk);
 744           _nonstatic_oopmap_count += vk-&gt;nonstatic_oop_map_count();
 745           field_alignment = vk-&gt;get_alignment();
 746           fs.set_flattened(true);
<a name="7" id="anc7"></a><span class="line-added"> 747           if (!vk-&gt;is_atomic()) {  // flat and non-atomic: take note</span>
<span class="line-added"> 748             _has_nonatomic_values = true;</span>
<span class="line-added"> 749             _atomic_field_count--;  // every other field is atomic but this one</span>
<span class="line-added"> 750           }</span>
 751         } else {
 752           _nonstatic_oopmap_count++;
 753           field_alignment = type2aelembytes(T_OBJECT);
 754           group-&gt;add_oop_field(fs);
 755         }
 756       }
 757       break;
 758     }
 759     default:
 760       fatal(&quot;Unexpected BasicType&quot;);
 761     }
 762     if (!fs.access_flags().is_static() &amp;&amp; field_alignment &gt; alignment) alignment = field_alignment;
 763   }
 764   _alignment = alignment;
 765   if (!_has_nonstatic_fields) {
 766     // There are a number of fixes required throughout the type system and JIT
 767     Exceptions::fthrow(THREAD_AND_LOCATION,
 768                        vmSymbols::java_lang_ClassFormatError(),
 769                        &quot;Value Types do not support zero instance size yet&quot;);
 770     return;
 771   }
 772 }
 773 
 774 void FieldLayoutBuilder::insert_contended_padding(LayoutRawBlock* slot) {
 775   if (ContendedPaddingWidth &gt; 0) {
 776     LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, ContendedPaddingWidth);
 777     _layout-&gt;insert(slot, padding);
 778   }
 779 }
 780 
 781 /* Computation of regular classes layout is an evolution of the previous default layout
 782  * (FieldAllocationStyle 1):
 783  *   - flattened fields are allocated first (because they have potentially the
 784  *     least regular shapes, and are more likely to create empty slots between them,
 785  *     which can then be used to allocation primitive or oop fields). Allocation is
 786  *     performed from the biggest to the smallest flattened field.
 787  *   - then primitive fields (from the biggest to the smallest)
 788  *   - then oop fields are allocated contiguously (to reduce the number of oopmaps
 789  *     and reduce the work of the GC).
 790  */
 791 void FieldLayoutBuilder::compute_regular_layout() {
 792   bool need_tail_padding = false;
 793   prologue();
 794   regular_field_sorting();
 795   if (_is_contended) {
 796     _layout-&gt;set_start(_layout-&gt;last_block());
 797     // insertion is currently easy because the current strategy doesn&#39;t try to fill holes
 798     // in super classes layouts =&gt; the _start block is by consequence the _last_block
 799     insert_contended_padding(_layout-&gt;start());
 800     need_tail_padding = true;
 801   }
 802   _layout-&gt;add(_root_group-&gt;flattened_fields());
 803   _layout-&gt;add(_root_group-&gt;primitive_fields());
 804   _layout-&gt;add(_root_group-&gt;oop_fields());
 805 
 806   if (!_contended_groups.is_empty()) {
 807     for (int i = 0; i &lt; _contended_groups.length(); i++) {
 808       FieldGroup* cg = _contended_groups.at(i);
 809       LayoutRawBlock* start = _layout-&gt;last_block();
 810       insert_contended_padding(start);
 811       _layout-&gt;add(_root_group-&gt;flattened_fields());
 812       _layout-&gt;add(cg-&gt;primitive_fields(), start);
 813       _layout-&gt;add(cg-&gt;oop_fields(), start);
 814       need_tail_padding = true;
 815     }
 816   }
 817 
 818   if (need_tail_padding) {
 819     insert_contended_padding(_layout-&gt;last_block());
 820   }
 821   _static_layout-&gt;add(_static_fields-&gt;flattened_fields());
 822   _static_layout-&gt;add_contiguously(_static_fields-&gt;oop_fields());
 823   _static_layout-&gt;add(_static_fields-&gt;primitive_fields());
 824 
 825   epilogue();
 826 }
 827 
 828 /* Computation of inline classes has a slightly different strategy than for
 829  * regular classes. Regular classes have their oop fields allocated at the end
 830  * of the layout to increase GC performances. Unfortunately, this strategy
 831  * increases the number of empty slots inside an instance. Because the purpose
 832  * of inline classes is to be embedded into other containers, it is critical
 833  * to keep their size as small as possible. For this reason, the allocation
 834  * strategy is:
 835  *   - flattened fields are allocated first (because they have potentially the
 836  *     least regular shapes, and are more likely to create empty slots between them,
 837  *     which can then be used to allocation primitive or oop fields). Allocation is
 838  *     performed from the biggest to the smallest flattened field.
 839  *   - then oop fields are allocated contiguously (to reduce the number of oopmaps
 840  *     and reduce the work of the GC)
 841  *   - then primitive fields (from the biggest to the smallest)
 842  */
 843 void FieldLayoutBuilder::compute_inline_class_layout(TRAPS) {
 844   prologue();
 845   inline_class_field_sorting(CHECK);
 846   // Inline types are not polymorphic, so they cannot inherit fields.
 847   // By consequence, at this stage, the layout must be composed of a RESERVED
 848   // block, followed by an EMPTY block.
 849   assert(_layout-&gt;start()-&gt;kind() == LayoutRawBlock::RESERVED, &quot;Unexpected&quot;);
 850   assert(_layout-&gt;start()-&gt;next_block()-&gt;kind() == LayoutRawBlock::EMPTY, &quot;Unexpected&quot;);
 851   LayoutRawBlock* first_empty = _layout-&gt;start()-&gt;next_block();
 852   if (first_empty-&gt;offset() % _alignment != 0) {
 853     LayoutRawBlock* padding = new LayoutRawBlock(LayoutRawBlock::PADDING, _alignment - (first_empty-&gt;offset() % _alignment));
 854     _layout-&gt;insert(first_empty, padding);
 855     _layout-&gt;set_start(padding-&gt;next_block());
 856   }
 857 
 858   _layout-&gt;add(_root_group-&gt;flattened_fields());
 859   _layout-&gt;add(_root_group-&gt;oop_fields());
 860   _layout-&gt;add(_root_group-&gt;primitive_fields());
 861 
 862   LayoutRawBlock* first_field = _layout-&gt;first_field_block();
 863    if (first_field != NULL) {
 864      _first_field_offset = _layout-&gt;first_field_block()-&gt;offset();
 865      _exact_size_in_bytes = _layout-&gt;last_block()-&gt;offset() - _layout-&gt;first_field_block()-&gt;offset();
 866    } else {
 867      // special case for empty value types
 868      _first_field_offset = _layout-&gt;blocks()-&gt;size();
 869      _exact_size_in_bytes = 0;
 870    }
 871   _exact_size_in_bytes = _layout-&gt;last_block()-&gt;offset() - _layout-&gt;first_field_block()-&gt;offset();
 872 
 873   _static_layout-&gt;add(_static_fields-&gt;flattened_fields());
 874   _static_layout-&gt;add_contiguously(_static_fields-&gt;oop_fields());
 875   _static_layout-&gt;add(_static_fields-&gt;primitive_fields());
 876 
 877 
 878   epilogue();
 879 }
 880 
 881 // Compute layout of the java/lang/ref/Reference class according
 882 // to the hard coded offsets of its fields
 883 void FieldLayoutBuilder::compute_java_lang_ref_Reference_layout() {
 884   prologue();
 885   regular_field_sorting();
 886 
 887   assert(_contended_groups.is_empty(), &quot;java.lang.Reference has no @Contended annotations&quot;);
 888   assert(_root_group-&gt;primitive_fields() == NULL, &quot;java.lang.Reference has no nonstatic primitive fields&quot;);
 889   int field_count = 0;
 890   int offset = -1;
 891   for (int i = 0; i &lt; _root_group-&gt;oop_fields()-&gt;length(); i++) {
 892     LayoutRawBlock* b = _root_group-&gt;oop_fields()-&gt;at(i);
 893     FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
 894     if (fi-&gt;name(_constant_pool)-&gt;equals(&quot;referent&quot;)) {
 895       offset = java_lang_ref_Reference::referent_offset;
 896     } else if (fi-&gt;name(_constant_pool)-&gt;equals(&quot;queue&quot;)) {
 897       offset = java_lang_ref_Reference::queue_offset;
 898     } else if (fi-&gt;name(_constant_pool)-&gt;equals(&quot;next&quot;)) {
 899       offset = java_lang_ref_Reference::next_offset;
 900     } else if (fi-&gt;name(_constant_pool)-&gt;equals(&quot;discovered&quot;)) {
 901       offset = java_lang_ref_Reference::discovered_offset;
 902     }
 903     assert(offset != -1, &quot;Unknown field&quot;);
 904     _layout-&gt;add_field_at_offset(b, offset);
 905     field_count++;
 906   }
 907   assert(field_count == 4, &quot;Wrong number of fields in java.lang.ref.Reference&quot;);
 908 
 909   _static_layout-&gt;add_contiguously(this-&gt;_static_fields-&gt;oop_fields());
 910   _static_layout-&gt;add(this-&gt;_static_fields-&gt;primitive_fields());
 911 
 912   epilogue();
 913 }
 914 
 915 // Compute layout of the boxing class according
 916 // to the hard coded offsets of their fields
 917 void FieldLayoutBuilder::compute_boxing_class_layout() {
 918   prologue();
 919   regular_field_sorting();
 920 
 921   assert(_contended_groups.is_empty(), &quot;Boxing classes have no @Contended annotations&quot;);
 922   assert(_root_group-&gt;oop_fields() == NULL, &quot;Boxing classes have no nonstatic oops fields&quot;);
 923   int field_count = 0;
 924   int offset = -1;
 925   for (int i = 0; i &lt; _root_group-&gt;primitive_fields()-&gt;length(); i++) {
 926     LayoutRawBlock* b = _root_group-&gt;primitive_fields()-&gt;at(i);
 927     FieldInfo* fi = FieldInfo::from_field_array(_fields, b-&gt;field_index());
 928     assert(fi-&gt;name(_constant_pool)-&gt;equals(&quot;value&quot;), &quot;Boxing classes have a single nonstatic field named &#39;value&#39;&quot;);
 929     BasicType type = Signature::basic_type(fi-&gt;signature(_constant_pool));
 930     offset = java_lang_boxing_object::value_offset_in_bytes(type);
 931     assert(offset != -1, &quot;Unknown field&quot;);
 932     _layout-&gt;add_field_at_offset(b, offset);
 933     field_count++;
 934   }
 935   assert(field_count == 1, &quot;Wrong number of fields for a boxing class&quot;);
 936 
 937   _static_layout-&gt;add_contiguously(this-&gt;_static_fields-&gt;oop_fields());
 938   _static_layout-&gt;add(this-&gt;_static_fields-&gt;primitive_fields());
 939 
 940   epilogue();
 941 }
 942 
 943 void FieldLayoutBuilder::add_flattened_field_oopmap(OopMapBlocksBuilder* nonstatic_oop_maps,
 944                 ValueKlass* vklass, int offset) {
 945   int diff = offset - vklass-&gt;first_field_offset();
 946   const OopMapBlock* map = vklass-&gt;start_of_nonstatic_oop_maps();
 947   const OopMapBlock* last_map = map + vklass-&gt;nonstatic_oop_map_count();
 948   while (map &lt; last_map) {
 949     nonstatic_oop_maps-&gt;add(map-&gt;offset() + diff, map-&gt;count());
 950     map++;
 951   }
 952 }
 953 
 954 void FieldLayoutBuilder::epilogue() {
 955   // Computing oopmaps
 956   int super_oop_map_count = (_super_klass == NULL) ? 0 :_super_klass-&gt;nonstatic_oop_map_count();
 957   int max_oop_map_count = super_oop_map_count + _nonstatic_oopmap_count;
 958 
 959   OopMapBlocksBuilder* nonstatic_oop_maps =
 960       new OopMapBlocksBuilder(max_oop_map_count);
 961   if (super_oop_map_count &gt; 0) {
 962     nonstatic_oop_maps-&gt;initialize_inherited_blocks(_super_klass-&gt;start_of_nonstatic_oop_maps(),
 963     _super_klass-&gt;nonstatic_oop_map_count());
 964   }
 965 
 966   if (_root_group-&gt;oop_fields() != NULL) {
 967     for (int i = 0; i &lt; _root_group-&gt;oop_fields()-&gt;length(); i++) {
 968       LayoutRawBlock* b = _root_group-&gt;oop_fields()-&gt;at(i);
 969       nonstatic_oop_maps-&gt;add(b-&gt;offset(), 1);
 970     }
 971   }
 972 
 973   GrowableArray&lt;LayoutRawBlock*&gt;* ff = _root_group-&gt;flattened_fields();
 974   if (ff != NULL) {
 975     for (int i = 0; i &lt; ff-&gt;length(); i++) {
 976       LayoutRawBlock* f = ff-&gt;at(i);
 977       ValueKlass* vk = f-&gt;value_klass();
 978       assert(vk != NULL, &quot;Should have been initialized&quot;);
 979       if (vk-&gt;contains_oops()) {
 980         add_flattened_field_oopmap(nonstatic_oop_maps, vk, f-&gt;offset());
 981       }
 982     }
 983   }
 984 
 985   if (!_contended_groups.is_empty()) {
 986     for (int i = 0; i &lt; _contended_groups.length(); i++) {
 987       FieldGroup* cg = _contended_groups.at(i);
 988       if (cg-&gt;oop_count() &gt; 0) {
 989         assert(cg-&gt;oop_fields() != NULL &amp;&amp; cg-&gt;oop_fields()-&gt;at(0) != NULL, &quot;oop_count &gt; 0 but no oop fields found&quot;);
 990         nonstatic_oop_maps-&gt;add(cg-&gt;oop_fields()-&gt;at(0)-&gt;offset(), cg-&gt;oop_count());
 991       }
 992     }
 993   }
 994 
 995   nonstatic_oop_maps-&gt;compact();
 996 
 997   int instance_end = align_up(_layout-&gt;last_block()-&gt;offset(), wordSize);
 998   int static_fields_end = align_up(_static_layout-&gt;last_block()-&gt;offset(), wordSize);
 999   int static_fields_size = (static_fields_end -
1000       InstanceMirrorKlass::offset_of_static_fields()) / wordSize;
1001   int nonstatic_field_end = align_up(_layout-&gt;last_block()-&gt;offset(), heapOopSize);
1002 
1003   // Pass back information needed for InstanceKlass creation
1004 
1005   _info-&gt;oop_map_blocks = nonstatic_oop_maps;
1006   _info-&gt;_instance_size = align_object_size(instance_end / wordSize);
1007   _info-&gt;_static_field_size = static_fields_size;
1008   _info-&gt;_nonstatic_field_size = (nonstatic_field_end - instanceOopDesc::base_offset_in_bytes()) / heapOopSize;
1009   _info-&gt;_has_nonstatic_fields = _has_nonstatic_fields;
1010 
<a name="8" id="anc8"></a><span class="line-added">1011   // A value type is naturally atomic if it has just one field, and</span>
<span class="line-added">1012   // that field is simple enough.</span>
<span class="line-added">1013   _info-&gt;_is_naturally_atomic = (_is_value_type &amp;&amp;</span>
<span class="line-added">1014                                  (_atomic_field_count &lt;= 1) &amp;&amp;</span>
<span class="line-added">1015                                  !_has_nonatomic_values &amp;&amp;</span>
<span class="line-added">1016                                  _contended_groups.is_empty());</span>
<span class="line-added">1017   // This may be too restrictive, since if all the fields fit in 64</span>
<span class="line-added">1018   // bits we could make the decision to align instances of this class</span>
<span class="line-added">1019   // to 64-bit boundaries, and load and store them as single words.</span>
<span class="line-added">1020   // And on machines which supported larger atomics we could similarly</span>
<span class="line-added">1021   // allow larger values to be atomic, if properly aligned.</span>
<span class="line-added">1022 </span>
<span class="line-added">1023 </span>
1024   if (PrintFieldLayout) {
1025     ResourceMark rm;
1026     tty-&gt;print_cr(&quot;Layout of class %s&quot;, _classname-&gt;as_C_string());
1027     tty-&gt;print_cr(&quot;Instance fields:&quot;);
1028     _layout-&gt;print(tty, false, _super_klass);
1029     tty-&gt;print_cr(&quot;Static fields:&quot;);
1030     _static_layout-&gt;print(tty, true, NULL);
1031     tty-&gt;print_cr(&quot;Instance size = %d bytes&quot;, _info-&gt;_instance_size * wordSize);
1032     if (_is_value_type) {
1033       tty-&gt;print_cr(&quot;First field offset = %d&quot;, _first_field_offset);
1034       tty-&gt;print_cr(&quot;Alignment = %d bytes&quot;, _alignment);
1035       tty-&gt;print_cr(&quot;Exact size = %d bytes&quot;, _exact_size_in_bytes);
1036     }
1037     tty-&gt;print_cr(&quot;---&quot;);
1038   }
1039 }
1040 
1041 void FieldLayoutBuilder::build_layout(TRAPS) {
1042   if (_classname == vmSymbols::java_lang_ref_Reference()) {
1043     compute_java_lang_ref_Reference_layout();
1044   } else if (_classname == vmSymbols::java_lang_Boolean() ||
1045              _classname == vmSymbols::java_lang_Character() ||
1046              _classname == vmSymbols::java_lang_Float() ||
1047              _classname == vmSymbols::java_lang_Double() ||
1048              _classname == vmSymbols::java_lang_Byte() ||
1049              _classname == vmSymbols::java_lang_Short() ||
1050              _classname == vmSymbols::java_lang_Integer() ||
1051              _classname == vmSymbols::java_lang_Long()) {
1052       compute_boxing_class_layout();
1053   } else if (_is_value_type) {
1054     compute_inline_class_layout(CHECK);
1055   } else {
1056     compute_regular_layout();
1057   }
1058 }
<a name="9" id="anc9"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="9" type="hidden" />
</body>
</html>