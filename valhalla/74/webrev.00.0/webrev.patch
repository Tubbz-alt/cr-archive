diff a/.hgtags b/.hgtags
--- a/.hgtags
+++ b/.hgtags
@@ -638,5 +638,7 @@
 7cc27caabe6e342151e8baf549beb07a9c755ec2 jdk-15+19
 46bca5e5e6fb26efd07245d26fe96a9c3260f51e jdk-15+20
 12b55fad80f30d24b1f8fdb3b947ea6465ef9518 jdk-15+21
 7223c6d610343fd8323af9d07d501e01fa1a7696 jdk-15+22
 f143729ca00ec14a98ea5c7f73acba88da97746e jdk-15+23
+497fd9f9129c4928fd5a876dd55e0daf6298b511 jdk-15+24
+58833044988772ca06c97ab2f142474a8627af80 jdk-15+25
diff a/make/autoconf/hotspot.m4 b/make/autoconf/hotspot.m4
--- a/make/autoconf/hotspot.m4
+++ b/make/autoconf/hotspot.m4
@@ -112,44 +112,10 @@
   AC_SUBST(JVM_VARIANTS)
   AC_SUBST(VALID_JVM_VARIANTS)
   AC_SUBST(JVM_VARIANT_MAIN)
 ])
 
-###############################################################################
-# Check if gtest should be built
-#
-AC_DEFUN_ONCE([HOTSPOT_ENABLE_DISABLE_GTEST],
-[
-  GTEST_AVAILABLE=true
-
-  AC_MSG_CHECKING([if Hotspot gtest test source is present])
-  if test -e "${TOPDIR}/test/hotspot/gtest"; then
-    AC_MSG_RESULT([yes])
-  else
-    AC_MSG_RESULT([no, cannot build gtest])
-    GTEST_AVAILABLE=false
-  fi
-
-  # On solaris, we also must have the libstlport.so.1 library, setup in
-  # LIB_SETUP_LIBRARIES.
-  if test "x$OPENJDK_TARGET_OS" = "xsolaris"; then
-    AC_MSG_CHECKING([if the libstlport.so.1 library is present])
-    if test "x$STLPORT_LIB" != "x"; then
-      AC_MSG_RESULT([yes])
-    else
-      AC_MSG_RESULT([no, cannot build gtest])
-      GTEST_AVAILABLE=false
-    fi
-  fi
-
-  UTIL_ARG_ENABLE(NAME: hotspot-gtest, DEFAULT: auto,
-      RESULT: BUILD_GTEST, AVAILABLE: $GTEST_AVAILABLE,
-      DEFAULT_DESC: [enabled if possible to build],
-      DESC: [enable building of the Hotspot unit tests])
-  AC_SUBST(BUILD_GTEST)
-])
-
 ###############################################################################
 # Misc hotspot setup that does not fit elsewhere.
 #
 AC_DEFUN_ONCE([HOTSPOT_SETUP_MISC],
 [
@@ -175,6 +141,9 @@
     HOTSPOT_TARGET_CPU_DEFINE="ARM32"
   fi
 
   # --with-cpu-port is no longer supported
   UTIL_DEPRECATED_ARG_WITH(with-cpu-port)
+
+  # in jdk15 hotspot-gtest was replaced with --with-gtest
+  UTIL_DEPRECATED_ARG_ENABLE(hotspot-gtest)
 ])
diff a/make/conf/jib-profiles.js b/make/conf/jib-profiles.js
--- a/make/conf/jib-profiles.js
+++ b/make/conf/jib-profiles.js
@@ -237,12 +237,12 @@
     common.build_id = getBuildId(input);
     common.build_number = input.build_number != null ? input.build_number : "0";
 
     // List of the main profile names used for iteration
     common.main_profile_names = [
-        "linux-x64", "linux-x86", "macosx-x64", "solaris-x64",
-        "solaris-sparcv9", "windows-x64", "windows-x86",
+        "linux-x64", "linux-x86", "macosx-x64",
+        "windows-x64", "windows-x86",
         "linux-aarch64", "linux-arm32", "linux-ppc64le", "linux-s390x"
     ];
 
     // These are the base setttings for all the main build profiles.
     common.main_profile_base = {
@@ -402,11 +402,11 @@
     var profiles = {
 
         "linux-x64": {
             target_os: "linux",
             target_cpu: "x64",
-            dependencies: ["devkit", "graphviz", "pandoc", "graalunit_lib"],
+            dependencies: ["devkit", "gtest", "graphviz", "pandoc", "graalunit_lib"],
             configure_args: concat(common.configure_args_64bit,
                 "--enable-full-docs", "--with-zlib=system",
                 (isWsl(input) ? [ "--host=x86_64-unknown-linux-gnu",
                     "--build=x86_64-unknown-linux-gnu" ] : [])),
             default_make_targets: ["docs-bundles"],
@@ -414,59 +414,43 @@
 
         "linux-x86": {
             target_os: "linux",
             target_cpu: "x86",
             build_cpu: "x64",
-            dependencies: ["devkit"],
+            dependencies: ["devkit", "gtest"],
             configure_args: concat(common.configure_args_32bit,
                 "--with-jvm-variants=minimal,server", "--with-zlib=system"),
         },
 
         "macosx-x64": {
             target_os: "macosx",
             target_cpu: "x64",
-            dependencies: ["devkit", "pandoc", "graalunit_lib"],
+            dependencies: ["devkit", "gtest", "pandoc", "graalunit_lib"],
             configure_args: concat(common.configure_args_64bit, "--with-zlib=system",
                 "--with-macosx-version-max=10.9.0"),
         },
 
-        "solaris-x64": {
-            target_os: "solaris",
-            target_cpu: "x64",
-            dependencies: ["devkit", "cups"],
-            configure_args: concat(common.configure_args_64bit,
-                "--with-zlib=system", "--enable-dtrace", "--enable-deprecated-ports=yes"),
-        },
-
-        "solaris-sparcv9": {
-            target_os: "solaris",
-            target_cpu: "sparcv9",
-            dependencies: ["devkit", "cups"],
-            configure_args: concat(common.configure_args_64bit,
-                "--with-zlib=system", "--enable-dtrace", "--enable-deprecated-ports=yes"),
-        },
-
         "windows-x64": {
             target_os: "windows",
             target_cpu: "x64",
-            dependencies: ["devkit", "pandoc", "graalunit_lib"],
+            dependencies: ["devkit", "gtest", "pandoc", "graalunit_lib"],
             configure_args: concat(common.configure_args_64bit),
         },
 
         "windows-x86": {
             target_os: "windows",
             target_cpu: "x86",
             build_cpu: "x64",
-            dependencies: ["devkit"],
+            dependencies: ["devkit", "gtest"],
             configure_args: concat(common.configure_args_32bit),
         },
 
         "linux-aarch64": {
             target_os: "linux",
             target_cpu: "aarch64",
             build_cpu: "x64",
-            dependencies: ["devkit", "build_devkit", "pandoc"],
+            dependencies: ["devkit", "gtest", "build_devkit", "pandoc"],
             configure_args: [
                 "--openjdk-target=aarch64-linux-gnu",
 		"--disable-jvm-feature-jvmci",
 		"--disable-jvm-feature-graal",
 		"--disable-jvm-feature-aot",
@@ -475,33 +459,33 @@
 
         "linux-arm32": {
             target_os: "linux",
             target_cpu: "arm",
             build_cpu: "x64",
-            dependencies: ["devkit", "build_devkit"],
+            dependencies: ["devkit", "gtest", "build_devkit"],
             configure_args: [
                 "--openjdk-target=arm-linux-gnueabihf", "--with-freetype=bundled",
                 "--with-abi-profile=arm-vfp-hflt", "--disable-warnings-as-errors"
             ],
         },
 
         "linux-ppc64le": {
             target_os: "linux",
             target_cpu: "ppc64le",
             build_cpu: "x64",
-            dependencies: ["devkit", "build_devkit"],
+            dependencies: ["devkit", "gtest", "build_devkit"],
             configure_args: [
                 "--openjdk-target=ppc64le-linux-gnu", "--with-freetype=bundled",
                 "--disable-warnings-as-errors"
             ],
         },
 
         "linux-s390x": {
             target_os: "linux",
             target_cpu: "s390x",
             build_cpu: "x64",
-            dependencies: ["devkit", "build_devkit"],
+            dependencies: ["devkit", "gtest", "build_devkit"],
             configure_args: [
                 "--openjdk-target=s390x-linux-gnu", "--with-freetype=bundled",
                 "--disable-warnings-as-errors"
             ],
         },
@@ -531,11 +515,11 @@
         dependencies: [ "ant" ],
         environment: {
             "ANT_HOME": input.get("ant", "home_path")
         }
     };
-    [ "linux-x64", "macosx-x64", "solaris-sparcv9", "solaris-x64", "windows-x64"]
+    [ "linux-x64", "macosx-x64", "windows-x64"]
         .forEach(function (name) {
             var maketestName = name + "-testmake";
             profiles[maketestName] = concatObjects(profiles[name], testmakeBase);
             profiles[maketestName].default_make_targets = [ "test-make" ];
         });
@@ -552,11 +536,11 @@
     // Profiles for building the zero jvm variant. These are used for verification.
     var zeroProfiles = {
         "linux-x64-zero": {
             target_os: "linux",
             target_cpu: "x64",
-            dependencies: ["devkit"],
+            dependencies: ["devkit", "gtest"],
             configure_args: concat(common.configure_args_64bit, [
                 "--with-zlib=system",
                 "--with-jvm-variants=zero",
                 "--enable-libffi-bundling"
             ])
@@ -564,11 +548,11 @@
 
         "linux-x86-zero": {
             target_os: "linux",
             target_cpu: "x86",
             build_cpu: "x64",
-            dependencies: ["devkit"],
+            dependencies: ["devkit", "gtest"],
             configure_args:  concat(common.configure_args_32bit, [
                 "--with-zlib=system",
                 "--with-jvm-variants=zero",
                 "--enable-libffi-bundling"
             ])
@@ -587,11 +571,11 @@
     // verfication of this build configuration.
     var noPchProfiles = {
         "linux-x64-debug-nopch": {
             target_os: "linux",
             target_cpu: "x64",
-            dependencies: ["devkit"],
+            dependencies: ["devkit", "gtest"],
             configure_args: concat(common.configure_args_64bit,
                 "--with-zlib=system", "--disable-precompiled-headers"),
         },
     };
     profiles = concatObjects(profiles, noPchProfiles);
@@ -605,11 +589,11 @@
     });
 
     // Bootcycle profiles runs the build with itself as the boot jdk. This can
     // be done in two ways. Either using the builtin bootcycle target in the
     // build system. Or by supplying the main jdk build as bootjdk to configure.
-    [ "linux-x64", "macosx-x64", "solaris-sparcv9", "windows-x64"]
+    [ "linux-x64", "macosx-x64", "windows-x64" ]
         .forEach(function (name) {
             var bootcycleName = name + "-bootcycle";
             var bootcyclePrebuiltName = name + "-bootcycle-prebuilt";
             // The base bootcycle profile just changes the default target
             // compared to the base profile
@@ -632,11 +616,11 @@
             delete profiles[bootcyclePrebuiltName].dependencies[bootJdkIndex];
             profiles[bootcyclePrebuiltName].default_make_targets = [ "product-images" ];
         });
 
     // JCov profiles build JCov-instrumented JDK image based on images provided through dependencies.
-    [ "linux-aarch64", "linux-x64", "macosx-x64", "solaris-sparcv9", "windows-x64"]
+    [ "linux-aarch64", "linux-x64", "macosx-x64", "windows-x64" ]
         .forEach(function (name) {
             var jcovName = name + "-jcov";
             profiles[jcovName] = clone(common.main_profile_base);
             profiles[jcovName].target_os = profiles[name].target_os
             profiles[jcovName].target_cpu = profiles[name].target_cpu
@@ -661,16 +645,10 @@
         },
         "macosx-x64": {
             platform: "osx-x64",
             jdk_subdir: "jdk-" + data.version +  ".jdk/Contents/Home",
         },
-        "solaris-x64": {
-            platform: "solaris-x64",
-        },
-        "solaris-sparcv9": {
-            platform: "solaris-sparcv9",
-        },
         "windows-x64": {
             platform: "windows-x64",
             jdk_suffix: "zip",
         },
         "windows-x86": {
@@ -793,11 +771,11 @@
             delete profiles[cmpBaselineName].artifacts;
         });
     });
 
     // Artifacts of JCov profiles
-    [ "linux-aarch64", "linux-x64", "macosx-x64", "solaris-sparcv9", "windows-x64"]
+    [ "linux-aarch64", "linux-x64", "macosx-x64", "windows-x64" ]
         .forEach(function (name) {
             var o = artifactData[name]
             var jdk_subdir = (o.jdk_subdir != null ? o.jdk_subdir : "jdk-" + data.version);
             var jdk_suffix = (o.jdk_suffix != null ? o.jdk_suffix : "tar.gz");
             var pf = o.platform
@@ -982,12 +960,10 @@
 var getJibProfilesDependencies = function (input, common) {
 
     var devkit_platform_revisions = {
         linux_x64: "gcc9.2.0-OL6.4+1.0",
         macosx_x64: "Xcode10.1-MacOSX10.14+1.0",
-        solaris_x64: "SS12u4-Solaris11u1+1.0",
-        solaris_sparcv9: "SS12u6-Solaris11u3+1.0",
         windows_x64: "VS2019-16.5.3+1.0",
         linux_aarch64: "gcc9.2.0-OL7.6+1.0",
         linux_arm: "gcc8.2.0-Fedora27+1.0",
         linux_ppc64le: "gcc8.2.0-Fedora27+1.0",
         linux_s390x: "gcc8.2.0-Fedora27+1.0"
@@ -1038,15 +1014,10 @@
                 + boot_jdk_platform + "_bin" + boot_jdk_ext,
             configure_args: "--with-boot-jdk=" + common.boot_jdk_home,
             environment_path: common.boot_jdk_home + "/bin"
         }
     }
-    if (input.build_cpu == 'sparcv9') {
-        boot_jdk.file = "bundles/openjdk/GPL/" + boot_jdk_platform
-            + "/openjdk-" + common.boot_jdk_version + "_"
-            + boot_jdk_platform + "_bin" + boot_jdk_ext;
-    }
 
     var dependencies = {
         boot_jdk: boot_jdk,
 
         devkit: {
@@ -1175,10 +1146,16 @@
             revision: "619_Apr_12_2018",
             module: "graalunit-lib",
             configure_args: "--with-graalunit-lib=" + input.get("graalunit_lib", "install_path"),
             environment_name: "GRAALUNIT_LIB"
         },
+
+        gtest: {
+            organization: common.organization,
+            ext: "tar.gz",
+            revision: "1.8.1"
+        },
     };
 
     return dependencies;
 };
 
diff a/make/data/jdwp/jdwp.spec b/make/data/jdwp/jdwp.spec
--- a/make/data/jdwp/jdwp.spec
+++ b/make/data/jdwp/jdwp.spec
@@ -459,20 +459,13 @@
         "All breakpoints in the redefined classes are cleared."
         "If resetting of stack frames is desired, the "
         "<a href=\"#JDWP_StackFrame_PopFrames\">PopFrames</a> command can be used "
         "to pop frames with obsolete methods."
         "<p>"
-        "Unless the canUnrestrictedlyRedefineClasses capability is present the following "
-        "redefinitions are restricted: "
-        "<ul>"
-        "<li>changing the schema (the fields)</li>"
-        "<li>changing the hierarchy (superclasses, interfaces)</li>"
-        "<li>deleting a method</li>"
-        "<li>changing class modifiers</li>"
-        "<li>changing method modifiers</li>"
-        "<li>changing the <code>NestHost</code>, <code>NestMembers</code>, or <code>Record</code> class attributes</li>"
-        "</ul>"
+        "Unless the canUnrestrictedlyRedefineClasses capability is present "
+        "the redefinition must follow the restrictions described in "
+        "<a href=\"../jvmti.html#RedefineClasses\">JVM TI RedefineClasses</a>."
         "<p>"
         "Requires canRedefineClasses capability - see "
         "<a href=\"#JDWP_VirtualMachine_CapabilitiesNew\">CapabilitiesNew</a>. "
         "In addition to the canRedefineClasses capability, the target VM must "
         "have the canAddMethod capability to add methods when redefining classes, "
diff a/make/modules/java.base/gensrc/GensrcVarHandles.gmk b/make/modules/java.base/gensrc/GensrcVarHandles.gmk
--- a/make/modules/java.base/gensrc/GensrcVarHandles.gmk
+++ b/make/modules/java.base/gensrc/GensrcVarHandles.gmk
@@ -168,18 +168,18 @@
 endef
 
 ################################################################################
 
 ################################################################################
-# Setup a rule for generating a VarHandleMemoryAddress java class
+# Setup a rule for generating a memory access var handle helper classes
 # Param 1 - Variable declaration prefix
 # Param 2 - Type with first letter capitalized
-define GenerateVarHandleMemoryAddress
+define GenerateVarHandleMemoryAccess
 
   $1_Type := $2
 
-  $1_FILENAME := $(VARHANDLES_GENSRC_DIR)/VarHandleMemoryAddressAs$$($1_Type)s.java
+  $1_FILENAME := $(VARHANDLES_GENSRC_DIR)/MemoryAccessVarHandle$$($1_Type)Helper.java
 
   ifeq ($$($1_Type), Byte)
     $1_type := byte
     $1_BoxType := $$($1_Type)
 
@@ -256,11 +256,11 @@
 
     $1_ARGS += -KCAS
     $1_ARGS += -KfloatingPoint
   endif
 
-  $$($1_FILENAME): $(VARHANDLES_SRC_DIR)/X-VarHandleMemoryAddressView.java.template $(BUILD_TOOLS_JDK)
+  $$($1_FILENAME): $(VARHANDLES_SRC_DIR)/X-VarHandleMemoryAccess.java.template $(BUILD_TOOLS_JDK)
 	$$(call MakeDir, $$(@D))
 	$(RM) $$@
 	$(TOOL_SPP) -nel -K$$($1_type) \
 	    -Dtype=$$($1_type) -DType=$$($1_Type) -DBoxType=$$($1_BoxType) \
 	    -DrawType=$$($1_rawType) -DRawType=$$($1_RawType) -DRawBoxType=$$($1_RawBoxType) \
@@ -282,8 +282,8 @@
   $(eval $(call GenerateVarHandleByteArray,VAR_HANDLE_BYTE_ARRAY_$t,$t)))
 
 # List the types to generate source for, with capitalized first letter
 VARHANDLES_MEMORY_ADDRESS_TYPES := Byte Short Char Int Long Float Double
 $(foreach t, $(VARHANDLES_MEMORY_ADDRESS_TYPES), \
-  $(eval $(call GenerateVarHandleMemoryAddress,VAR_HANDLE_MEMORY_ADDRESS_$t,$t)))
+  $(eval $(call GenerateVarHandleMemoryAccess,VAR_HANDLE_MEMORY_ADDRESS_$t,$t)))
 
 TARGETS += $(GENSRC_VARHANDLES)
diff a/src/hotspot/cpu/aarch64/aarch64.ad b/src/hotspot/cpu/aarch64/aarch64.ad
--- a/src/hotspot/cpu/aarch64/aarch64.ad
+++ b/src/hotspot/cpu/aarch64/aarch64.ad
@@ -1359,21 +1359,16 @@
 
   // helper to determine the maximum number of Phi nodes we may need to
   // traverse when searching from a card mark membar for the merge mem
   // feeding a trailing membar or vice versa
 
-// predicates controlling emit of ldr<x>/ldar<x> and associated dmb
+// predicates controlling emit of ldr<x>/ldar<x>
 
 bool unnecessary_acquire(const Node *barrier)
 {
   assert(barrier->is_MemBar(), "expecting a membar");
 
-  if (UseBarriersForVolatile) {
-    // we need to plant a dmb
-    return false;
-  }
-
   MemBarNode* mb = barrier->as_MemBar();
 
   if (mb->trailing_load()) {
     return true;
   }
@@ -1388,30 +1383,19 @@
 }
 
 bool needs_acquiring_load(const Node *n)
 {
   assert(n->is_Load(), "expecting a load");
-  if (UseBarriersForVolatile) {
-    // we use a normal load and a dmb
-    return false;
-  }
-
-  LoadNode *ld = n->as_Load();
 
   return ld->is_acquire();
 }
 
 bool unnecessary_release(const Node *n)
 {
   assert((n->is_MemBar() &&
-	  n->Opcode() == Op_MemBarRelease),
-	 "expecting a release membar");
-
-  if (UseBarriersForVolatile) {
-    // we need to plant a dmb
-    return false;
-  }
+          n->Opcode() == Op_MemBarRelease),
+         "expecting a release membar");
 
   MemBarNode *barrier = n->as_MemBar();
   if (!barrier->leading()) {
     return false;
   } else {
@@ -1435,15 +1419,10 @@
 }
 
 bool unnecessary_volatile(const Node *n)
 {
   // assert n->is_MemBar();
-  if (UseBarriersForVolatile) {
-    // we need to plant a dmb
-    return false;
-  }
-
   MemBarNode *mbvol = n->as_MemBar();
 
   bool release = mbvol->trailing_store();
   assert(!release || (mbvol->in(MemBarNode::Precedent)->is_Store() && mbvol->in(MemBarNode::Precedent)->as_Store()->is_release()), "");
 #ifdef ASSERT
@@ -1456,21 +1435,15 @@
 #endif
 
   return release;
 }
 
-// predicates controlling emit of str<x>/stlr<x> and associated dmbs
+// predicates controlling emit of str<x>/stlr<x>
 
 bool needs_releasing_store(const Node *n)
 {
   // assert n->is_Store();
-  if (UseBarriersForVolatile) {
-    // we use a normal store and dmb combination
-    return false;
-  }
-
-  StoreNode *st = n->as_Store();
 
   return st->trailing_membar() != NULL;
 }
 
 // predicate controlling translation of CAS
@@ -1478,14 +1451,10 @@
 // returns true if CAS needs to use an acquiring load otherwise false
 
 bool needs_acquiring_load_exclusive(const Node *n)
 {
   assert(is_CAS(n->Opcode(), true), "expecting a compare and swap");
-  if (UseBarriersForVolatile) {
-    return false;
-  }
-
   LoadStoreNode* ldst = n->as_LoadStore();
   if (is_CAS(n->Opcode(), false)) {
     assert(ldst->trailing_membar() != NULL, "expected trailing membar");
   } else {
     return ldst->trailing_membar() != NULL;
diff a/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
@@ -1449,11 +1449,10 @@
   // volatile accesses forms a sequentially-consistent set of
   // operations when combined with STLR and LDAR.  Without a leading
   // membar it's possible for a simple Dekker test to fail if loads
   // use LD;DMB but stores use STLR.  This can happen if C2 compiles
   // the stores in one method and C1 compiles the loads in another.
-  if (! UseBarriersForVolatile) {
+  if (!is_c1_or_interpreter_only()) {
     __ membar();
   }
-
   __ volatile_load_mem_reg(address, result, info);
 }
diff a/src/hotspot/cpu/aarch64/globals_aarch64.hpp b/src/hotspot/cpu/aarch64/globals_aarch64.hpp
--- a/src/hotspot/cpu/aarch64/globals_aarch64.hpp
+++ b/src/hotspot/cpu/aarch64/globals_aarch64.hpp
@@ -86,13 +86,10 @@
                    range, \
                    constraint) \
                                                                         \
   product(bool, NearCpool, true,                                        \
          "constant pool is close to instructions")                      \
-                                                                        \
-  product(bool, UseBarriersForVolatile, false,                          \
-          "Use memory barriers to implement volatile accesses")         \
   product(bool, UseNeon, false,                                         \
           "Use Neon for CRC32 computation")                             \
   product(bool, UseCRC32, false,                                        \
           "Use CRC32 instructions for CRC32 computation")               \
   product(bool, UseSIMDForMemoryOps, false,                             \
diff a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2003, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
@@ -1167,45 +1167,45 @@
 
   if (EnableValhalla) {
     Label is_null_into_value_array_npe, store_null;
 
     // No way to store null in flat array
-    __ test_null_free_array_oop(r3, r8, is_null_into_value_array_npe); 
+    __ test_null_free_array_oop(r3, r8, is_null_into_value_array_npe);
     __ b(store_null);
 
     __ bind(is_null_into_value_array_npe);
     __ b(ExternalAddress(Interpreter::_throw_NullPointerException_entry));
 
     __ bind(store_null);
   }
 
   // Store a NULL
-  do_oop_store(_masm, element_address, noreg, IS_ARRAY); 
+  do_oop_store(_masm, element_address, noreg, IS_ARRAY);
   __ b(done);
 
-  if (EnableValhalla) { 
+  if (EnableValhalla) {
      Label is_type_ok;
 
     // store non-null value
     __ bind(is_flat_array);
 
     // Simplistic type check...
     // r0 - value, r2 - index, r3 - array.
 
     // Profile the not-null value's klass.
-    // Load value class 
+    // Load value class
      __ load_klass(r1, r0);
      __ profile_typecheck(r2, r1, r0); // blows r2, and r0
 
     // flat value array needs exact type match
     // is "r8 == r0" (value subclass == array element superclass)
 
     // Move element klass into r0
 
      __ load_klass(r0, r3);
 
-     __ ldr(r0, Address(r0, ArrayKlass::element_klass_offset())); 
+     __ ldr(r0, Address(r0, ArrayKlass::element_klass_offset()));
      __ cmp(r0, r1);
      __ br(Assembler::EQ, is_type_ok);
 
      __ profile_typecheck_failed(r2);
      __ b(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));
@@ -1213,11 +1213,11 @@
      __ bind(is_type_ok);
 
     // Reload from TOS to be safe, because of profile_typecheck that blows r2 and r0.
     // FIXME: Should we really do it?
      __ ldr(r1, at_tos());  // value
-     __ mov(r2, r3); // array, ldr(r2, at_tos_p2()); 
+     __ mov(r2, r3); // array, ldr(r2, at_tos_p2());
      __ ldr(r3, at_tos_p1()); // index
      __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::value_array_store), r1, r2, r3);
   }
 
 
@@ -2396,11 +2396,11 @@
   // since compiled code callers expect the result to already be narrowed.
   if (state == itos) {
     __ narrow(r0);
   }
 
-  __ remove_activation(state); 
+  __ remove_activation(state);
   __ ret(lr);
 }
 
 // ----------------------------------------------------------------------------
 // Volatile variables demand their effects be made known to all CPU's
@@ -2605,11 +2605,11 @@
   // volatile accesses forms a sequentially-consistent set of
   // operations when combined with STLR and LDAR.  Without a leading
   // membar it's possible for a simple Dekker test to fail if loads
   // use LDR;DMB but stores use STLR.  This can happen if C2 compiles
   // the stores in one method and we interpret the loads in another.
-  if (! UseBarriersForVolatile) {
+  if (!is_c1_or_interpreter_only()){
     Label notVolatile;
     __ tbz(raw_flags, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
     __ membar(MacroAssembler::AnyAny);
     __ bind(notVolatile);
   }
@@ -2659,11 +2659,11 @@
   if (!EnableValhalla) {
     do_oop_load(_masm, field, r0, IN_HEAP);
     __ push(atos);
     if (rc == may_rewrite) {
       patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
-    }  
+    }
     __ b(Done);
   } else { // Valhalla
 
     if (is_static) {
       __ load_heap_oop(r0, field);
@@ -2706,15 +2706,15 @@
           __ push(atos);
           __ b(rewriteFlattenable);
         __ bind(isFlattened);
           __ ldr(r10, Address(cache, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset())));
           __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
-          call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), obj, raw_flags, r10); 
+          call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), obj, raw_flags, r10);
           __ verify_oop(r0);
           __ push(atos);
       __ bind(rewriteFlattenable);
-      if (rc == may_rewrite) { 
+      if (rc == may_rewrite) {
          patch_bytecode(Bytecodes::_fast_qgetfield, bc, r1);
       }
       __ b(Done);
     }
   }
@@ -2908,11 +2908,11 @@
   const Address field(obj, off);
 
   Label notByte, notBool, notInt, notShort, notChar,
         notLong, notFloat, notObj, notDouble;
 
-  __ mov(flags2, flags); 
+  __ mov(flags2, flags);
 
   // x86 uses a shift and mask or wings it with a shift plus assert
   // the mask is not needed. aarch64 just uses bitfield extract
   __ ubfxw(flags, flags, ConstantPoolCacheEntry::tos_state_shift,  ConstantPoolCacheEntry::tos_state_bits);
 
@@ -2969,22 +2969,22 @@
       if (is_static) {
         Label notFlattenable;
          __ test_field_is_not_flattenable(flags2, r8 /* temp */, notFlattenable);
          __ null_check(r0);
          __ bind(notFlattenable);
-         do_oop_store(_masm, field, r0, IN_HEAP); 
+         do_oop_store(_masm, field, r0, IN_HEAP);
          __ b(Done);
       } else {
         Label isFlattenable, isFlattened, notBuffered, notBuffered2, rewriteNotFlattenable, rewriteFlattenable;
         __ test_field_is_flattenable(flags2, r8 /*temp*/, isFlattenable);
         // Not flattenable case, covers not flattenable values and objects
         pop_and_check_object(obj);
         // Store into the field
         do_oop_store(_masm, field, r0, IN_HEAP);
         __ bind(rewriteNotFlattenable);
         if (rc == may_rewrite) {
-          patch_bytecode(Bytecodes::_fast_aputfield, bc, r19, true, byte_no); 
+          patch_bytecode(Bytecodes::_fast_aputfield, bc, r19, true, byte_no);
         }
         __ b(Done);
         // Implementation of the flattenable semantic
         __ bind(isFlattenable);
         __ null_check(r0);
@@ -3219,13 +3219,13 @@
   // field address
   const Address field(r2, r1);
 
   // access field
   switch (bytecode()) {
-  case Bytecodes::_fast_qputfield: //fall through 
+  case Bytecodes::_fast_qputfield: //fall through
    {
-      Label isFlattened, done; 
+      Label isFlattened, done;
       __ null_check(r0);
       __ test_field_is_flattened(r3, r8 /* temp */, isFlattened);
       // No Flattened case
       do_oop_store(_masm, field, r0, IN_HEAP);
       __ b(done);
@@ -3316,31 +3316,31 @@
   // volatile accesses forms a sequentially-consistent set of
   // operations when combined with STLR and LDAR.  Without a leading
   // membar it's possible for a simple Dekker test to fail if loads
   // use LDR;DMB but stores use STLR.  This can happen if C2 compiles
   // the stores in one method and we interpret the loads in another.
-  if (! UseBarriersForVolatile) {
+  if (!is_c1_or_interpreter_only()) {
     Label notVolatile;
     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
     __ membar(MacroAssembler::AnyAny);
     __ bind(notVolatile);
   }
 
   // access field
   switch (bytecode()) {
-  case Bytecodes::_fast_qgetfield: 
+  case Bytecodes::_fast_qgetfield:
     {
        Label isFlattened, isInitialized, Done;
        // FIXME: We don't need to reload registers multiple times, but stay close to x86 code
-       __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset()))); 
+       __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
        __ test_field_is_flattened(r9, r8 /* temp */, isFlattened);
         // Non-flattened field case
         __ mov(r9, r0);
         __ load_heap_oop(r0, field);
         __ cbnz(r0, isInitialized);
           __ mov(r0, r9);
-          __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset()))); 
+          __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
           __ andw(r9, r9, ConstantPoolCacheEntry::field_index_mask);
           __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_instance_value_field), r0, r9);
         __ bind(isInitialized);
         __ verify_oop(r0);
         __ b(Done);
@@ -3404,11 +3404,11 @@
   // volatile accesses forms a sequentially-consistent set of
   // operations when combined with STLR and LDAR.  Without a leading
   // membar it's possible for a simple Dekker test to fail if loads
   // use LDR;DMB but stores use STLR.  This can happen if C2 compiles
   // the stores in one method and we interpret the loads in another.
-  if (! UseBarriersForVolatile) {
+  if (!is_c1_or_interpreter_only()) {
     Label notVolatile;
     __ ldrw(r3, Address(r2, in_bytes(ConstantPoolCache::base_offset() +
                                      ConstantPoolCacheEntry::flags_offset())));
     __ tbz(r3, ConstantPoolCacheEntry::is_volatile_shift, notVolatile);
     __ membar(MacroAssembler::AnyAny);
@@ -3923,11 +3923,11 @@
   transition(vtos, atos);
   resolve_cache_and_index(f2_byte, c_rarg1 /*cache*/, c_rarg2 /*index*/, sizeof(u2));
 
   // n.b. unlike x86 cache is now rcpool plus the indexed offset
   // so using rcpool to meet shared code expectations
- 
+
   call_VM(r1, CAST_FROM_FN_PTR(address, InterpreterRuntime::withfield), rcpool);
   __ verify_oop(r1);
   __ add(esp, esp, r0);
   __ mov(r0, r1);
 }
@@ -4014,11 +4014,11 @@
   if (EnableValhalla) {
     // Get cpool & tags index
     __ get_cpool_and_tags(r2, r3); // r2=cpool, r3=tags array
     __ get_unsigned_2_byte_index_at_bcp(r19, 1); // r19=index
      // See if bytecode has already been quicked
-    __ add(rscratch1, r3, Array<u1>::base_offset_in_bytes());
+    __ add(rscratch1, r3, Array<u1>::base_offset_in_bytes());
     __ lea(r1, Address(rscratch1, r19));
     __ ldarb(r1, r1); 
     // See if CP entry is a Q-descriptor
     __ andr (r1, r1, JVM_CONSTANT_QDescBit);
     __ cmp(r1, (u1) JVM_CONSTANT_QDescBit);
diff a/src/hotspot/cpu/ppc/globals_ppc.hpp b/src/hotspot/cpu/ppc/globals_ppc.hpp
--- a/src/hotspot/cpu/ppc/globals_ppc.hpp
+++ b/src/hotspot/cpu/ppc/globals_ppc.hpp
@@ -148,13 +148,10 @@
   product(bool, UseSIGTRAP, true,                                           \
           "Allow trap instructions that make use of SIGTRAP. Use this to "  \
           "switch off all optimizations requiring SIGTRAP.")                \
   product(bool, TrapBasedICMissChecks, true,                                \
           "Raise and handle SIGTRAP if inline cache miss detected.")        \
-  product(bool, TrapBasedNotEntrantChecks, true,                            \
-          "Raise and handle SIGTRAP if calling not entrant or zombie"       \
-          " method.")                                                       \
   product(bool, TraceTraps, false, "Trace all traps the signal handler"     \
           "handles.")                                                       \
                                                                             \
   product(bool, ZapMemory, false, "Write 0x0101... to empty memory."        \
           " Use this to ease debugging.")                                   \
diff a/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp b/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
--- a/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
+++ b/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
@@ -488,11 +488,11 @@
   Label index_ok;
   lwa(R0, arrayOopDesc::length_offset_in_bytes(), result);
   sldi(R0, R0, LogBytesPerHeapOop);
   cmpd(CCR0, tmp, R0);
   blt(CCR0, index_ok);
-  stop("resolved reference index out of bounds", 0x09256);
+  stop("resolved reference index out of bounds");
   bind(index_ok);
 #endif
   // Add in the index.
   add(result, tmp, result);
   load_heap_oop(result, arrayOopDesc::base_offset_in_bytes(T_OBJECT), result, tmp, R0, false, 0, L_handle_null);
@@ -1141,11 +1141,11 @@
 
   save_interpreter_state(Rscratch2);
 #ifdef ASSERT
   ld(Rscratch1, _ijava_state_neg(top_frame_sp), Rscratch2); // Rscratch2 contains fp
   cmpd(CCR0, R21_sender_SP, Rscratch1);
-  asm_assert_eq("top_frame_sp incorrect", 0x951);
+  asm_assert_eq("top_frame_sp incorrect");
 #endif
 
   bctr();
 }
 
@@ -2249,11 +2249,11 @@
   {
     Label Lok;
     subf(R0, R1_SP, scratch);
     cmpdi(CCR0, R0, frame::abi_reg_args_size + frame::ijava_state_size);
     bge(CCR0, Lok);
-    stop("frame too small (restore istate)", 0x5432);
+    stop("frame too small (restore istate)");
     bind(Lok);
   }
 #endif
 }
 
diff a/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp b/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
@@ -975,11 +975,11 @@
 address ShenandoahBarrierSetAssembler::generate_shenandoah_lrb(StubCodeGenerator* cgen) {
   __ align(CodeEntryAlignment);
   StubCodeMark mark(cgen, "StubRoutines", "shenandoah_lrb");
   address start = __ pc();
 
-  Label resolve_oop, slow_path;
+  Label slow_path;
 
   // We use RDI, which also serves as argument register for slow call.
   // RAX always holds the src object ptr, except after the slow call,
   // then it holds the result. R8/RBX is used as temporary register.
 
@@ -993,28 +993,10 @@
   __ mov(tmp1, rax);
   __ shrptr(tmp1, ShenandoahHeapRegion::region_size_bytes_shift_jint());
   __ movptr(tmp2, (intptr_t) ShenandoahHeap::in_cset_fast_test_addr());
   __ movbool(tmp2, Address(tmp2, tmp1, Address::times_1));
   __ testbool(tmp2);
-  __ jccb(Assembler::notZero, resolve_oop);
-  __ pop(tmp2);
-  __ pop(tmp1);
-  __ ret(0);
-
-  // Test if object is already resolved.
-  __ bind(resolve_oop);
-  __ movptr(tmp2, Address(rax, oopDesc::mark_offset_in_bytes()));
-  // Test if both lowest bits are set. We trick it by negating the bits
-  // then test for both bits clear.
-  __ notptr(tmp2);
-  __ testb(tmp2, markWord::marked_value);
-  __ jccb(Assembler::notZero, slow_path);
-  // Clear both lower bits. It's still inverted, so set them, and then invert back.
-  __ orptr(tmp2, markWord::marked_value);
-  __ notptr(tmp2);
-  // At this point, tmp2 contains the decoded forwarding pointer.
-  __ mov(rax, tmp2);
 
   __ pop(tmp2);
   __ pop(tmp1);
   __ ret(0);
 
diff a/src/hotspot/cpu/x86/methodHandles_x86.cpp b/src/hotspot/cpu/x86/methodHandles_x86.cpp
--- a/src/hotspot/cpu/x86/methodHandles_x86.cpp
+++ b/src/hotspot/cpu/x86/methodHandles_x86.cpp
@@ -504,10 +504,11 @@
   tty->print_cr("MH %s %s=" PTR_FORMAT " sp=" PTR_FORMAT,
                 adaptername, mh_reg_name,
                 p2i(mh), p2i(entry_sp));
 
   if (Verbose) {
+    ResourceMark rm;
     tty->print_cr("Registers:");
     const int saved_regs_count = RegisterImpl::number_of_registers;
     for (int i = 0; i < saved_regs_count; i++) {
       Register r = as_Register(i);
       // The registers are stored in reverse order on the stack (by pusha).
@@ -529,16 +530,15 @@
       }
     }
     tty->cr();
 
     {
-     // dumping last frame with frame::describe
+      // dumping last frame with frame::describe
 
       JavaThread* p = JavaThread::active();
 
-      ResourceMark rm;
-      PRESERVE_EXCEPTION_MARK; // may not be needed by safer and unexpensive here
+      PRESERVE_EXCEPTION_MARK; // may not be needed but safer and inexpensive here
       FrameValues values;
 
       // Note: We want to allow trace_method_handle from any call site.
       // While trace_method_handle creates a frame, it may be entered
       // without a PC on the stack top (e.g. not just after a call).
@@ -583,12 +583,13 @@
       values.print(p);
     }
     if (has_mh && oopDesc::is_oop(mh)) {
       mh->print();
       if (java_lang_invoke_MethodHandle::is_instance(mh)) {
-        if (java_lang_invoke_MethodHandle::form_offset_in_bytes() != 0)
+        if (java_lang_invoke_MethodHandle::form_offset_in_bytes() != 0) {
           java_lang_invoke_MethodHandle::form(mh)->print();
+        }
       }
     }
   }
 }
 
diff a/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp b/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
--- a/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
+++ b/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
@@ -1048,12 +1048,12 @@
 // A simple move of integer like type
 static void simple_move32(MacroAssembler* masm, VMRegPair src, VMRegPair dst) {
   if (src.first()->is_stack()) {
     if (dst.first()->is_stack()) {
       // stack to stack
-      // __ ld(FP, reg2offset(src.first()) + STACK_BIAS, L5);
-      // __ st(L5, SP, reg2offset(dst.first()) + STACK_BIAS);
+      // __ ld(FP, reg2offset(src.first()), L5);
+      // __ st(L5, SP, reg2offset(dst.first()));
       __ movl2ptr(rax, Address(rbp, reg2offset_in(src.first())));
       __ movptr(Address(rsp, reg2offset_out(dst.first())), rax);
     } else {
       // stack to reg
       __ movl2ptr(dst.first()->as_Register(),  Address(rbp, reg2offset_in(src.first())));
diff a/src/hotspot/share/adlc/formssel.cpp b/src/hotspot/share/adlc/formssel.cpp
--- a/src/hotspot/share/adlc/formssel.cpp
+++ b/src/hotspot/share/adlc/formssel.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -1043,14 +1043,10 @@
     const char  *result   = NULL;
     const char  *name     = NULL;
     const char  *opType   = NULL;
     while (_matrule->base_operand(position, globals, result, name, opType)) {
       if ( strcmp(opType,"ConP") == 0 ) {
-#ifdef SPARC
-        reloc_entries += 2; // 1 for sethi + 1 for setlo
-#else
-        ++reloc_entries;
 #endif
       }
       ++position;
     }
   }
@@ -1081,16 +1077,10 @@
   // and require relocatable addresses for access
   // !!!!!
   // Check for any component being an immediate float or double.
   Form::DataType data_type = is_chain_of_constant(globals);
   if( data_type==idealD || data_type==idealF ) {
-#ifdef SPARC
-    // sparc required more relocation entries for floating constants
-    // (expires 9/98)
-    reloc_entries += 6;
-#else
-    reloc_entries++;
 #endif
   }
 
   return reloc_entries;
 }
diff a/src/hotspot/share/c1/c1_FrameMap.cpp b/src/hotspot/share/c1/c1_FrameMap.cpp
--- a/src/hotspot/share/c1/c1_FrameMap.cpp
+++ b/src/hotspot/share/c1/c1_FrameMap.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -80,11 +80,11 @@
     LIR_Opr opr = map_to_opr(t, regs + i, outgoing);
     args->append(opr);
     if (opr->is_address()) {
       LIR_Address* addr = opr->as_address_ptr();
       assert(addr->disp() == (int)addr->disp(), "out of range value");
-      out_preserve = MAX2(out_preserve, (intptr_t)(addr->disp() - STACK_BIAS) / 4);
+      out_preserve = MAX2(out_preserve, (intptr_t)addr->disp() / 4);
     }
     i += type2size[t];
   }
   assert(args->length() == signature->length(), "size mismatch");
   out_preserve += SharedRuntime::out_preserve_stack_slots();
@@ -131,11 +131,11 @@
     // values are passed in cpu registers, but the sizes must match.
     assert(type2size[opr->type()] == type2size[t], "type mismatch");
     args->append(opr);
     if (opr->is_address()) {
       LIR_Address* addr = opr->as_address_ptr();
-      out_preserve = MAX2(out_preserve, (intptr_t)(addr->disp() - STACK_BIAS) / 4);
+      out_preserve = MAX2(out_preserve, (intptr_t)addr->disp() / 4);
     }
     i += type2size[t];
   }
   assert(args->length() == signature->length(), "size mismatch");
   out_preserve += SharedRuntime::out_preserve_stack_slots();
@@ -172,11 +172,11 @@
   int java_index = 0;
   for (int i = 0; i < _incoming_arguments->length(); i++) {
     LIR_Opr opr = _incoming_arguments->at(i);
     if (opr->is_address()) {
       LIR_Address* address = opr->as_address_ptr();
-      _argument_locations->at_put(java_index, address->disp() - STACK_BIAS);
+      _argument_locations->at_put(java_index, address->disp());
       _incoming_arguments->args()->at_put(i, LIR_OprFact::stack(java_index, as_BasicType(as_ValueType(address->type()))));
     }
     java_index += type2size[opr->type()];
   }
 
diff a/src/hotspot/share/c1/c1_GraphBuilder.cpp b/src/hotspot/share/c1/c1_GraphBuilder.cpp
--- a/src/hotspot/share/c1/c1_GraphBuilder.cpp
+++ b/src/hotspot/share/c1/c1_GraphBuilder.cpp
@@ -2319,27 +2319,10 @@
     code == Bytecodes::_invokeinterface;
   Values* args = state()->pop_arguments(target->arg_size_no_receiver() + patching_appendix_arg);
   Value recv = has_receiver ? apop() : NULL;
   int vtable_index = Method::invalid_vtable_index;
 
-#ifdef SPARC
-  // Currently only supported on Sparc.
-  // The UseInlineCaches only controls dispatch to invokevirtuals for
-  // loaded classes which we weren't able to statically bind.
-  if (!UseInlineCaches && target->is_loaded() && code == Bytecodes::_invokevirtual
-      && !target->can_be_statically_bound()) {
-    // Find a vtable index if one is available
-    // For arrays, callee_holder is Object. Resolving the call with
-    // Object would allow an illegal call to finalize() on an
-    // array. We use holder instead: illegal calls to finalize() won't
-    // be compiled as vtable calls (IC call resolution will catch the
-    // illegal call) and the few legal calls on array types won't be
-    // either.
-    vtable_index = target->resolve_vtable_index(calling_klass, holder);
-  }
-#endif
-
   // A null check is required here (when there is a receiver) for any of the following cases
   // - invokespecial, always need a null check.
   // - invokevirtual, when the target is final and loaded. Calls to final targets will become optimized
   //   and require null checking. If the target is loaded a null check is emitted here.
   //   If the target isn't loaded the null check must happen after the call resolution. We achieve that
diff a/src/hotspot/share/c1/c1_LIR.cpp b/src/hotspot/share/c1/c1_LIR.cpp
--- a/src/hotspot/share/c1/c1_LIR.cpp
+++ b/src/hotspot/share/c1/c1_LIR.cpp
@@ -490,12 +490,10 @@
     case lir_return:         // input always valid, result and info always invalid
     case lir_leal:           // input and result always valid, info always invalid
     case lir_monaddr:        // input and result always valid, info always invalid
     case lir_null_check:     // input and info always valid, result always invalid
     case lir_move:           // input and result always valid, may have info
-    case lir_pack64:         // input and result always valid
-    case lir_unpack64:       // input and result always valid
     {
       assert(op->as_Op1() != NULL, "must be");
       LIR_Op1* op1 = (LIR_Op1*)op;
 
       if (op1->_info)                  do_info(op1->_info);
@@ -1817,12 +1815,10 @@
      case lir_throw:                 s = "throw";         break;
      case lir_unwind:                s = "unwind";        break;
      case lir_convert:               s = "convert";       break;
      case lir_alloc_object:          s = "alloc_obj";     break;
      case lir_monaddr:               s = "mon_addr";      break;
-     case lir_pack64:                s = "pack64";        break;
-     case lir_unpack64:              s = "unpack64";      break;
      // LIR_Op2
      case lir_cmp:                   s = "cmp";           break;
      case lir_cmp_l2i:               s = "cmp_l2i";       break;
      case lir_ucmp_fd2i:             s = "ucomp_fd2i";    break;
      case lir_cmp_fd2i:              s = "comp_fd2i";     break;
diff a/src/hotspot/share/c1/c1_LIR.hpp b/src/hotspot/share/c1/c1_LIR.hpp
--- a/src/hotspot/share/c1/c1_LIR.hpp
+++ b/src/hotspot/share/c1/c1_LIR.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -919,12 +919,10 @@
       , lir_convert
       , lir_alloc_object
       , lir_monaddr
       , lir_roundfp
       , lir_safepoint
-      , lir_pack64
-      , lir_unpack64
       , lir_unwind
   , end_op1
   , begin_op2
       , lir_cmp
       , lir_cmp_l2i
@@ -2212,13 +2210,10 @@
 
   void logical_and (LIR_Opr left, LIR_Opr right, LIR_Opr dst) { append(new LIR_Op2(lir_logic_and,  left, right, dst)); }
   void logical_or  (LIR_Opr left, LIR_Opr right, LIR_Opr dst) { append(new LIR_Op2(lir_logic_or,   left, right, dst)); }
   void logical_xor (LIR_Opr left, LIR_Opr right, LIR_Opr dst) { append(new LIR_Op2(lir_logic_xor,  left, right, dst)); }
 
-  void   pack64(LIR_Opr src, LIR_Opr dst) { append(new LIR_Op1(lir_pack64,   src, dst, T_LONG, lir_patch_none, NULL)); }
-  void unpack64(LIR_Opr src, LIR_Opr dst) { append(new LIR_Op1(lir_unpack64, src, dst, T_LONG, lir_patch_none, NULL)); }
-
   void null_check(LIR_Opr opr, CodeEmitInfo* info, bool deoptimize_on_null = false);
   void throw_exception(LIR_Opr exceptionPC, LIR_Opr exceptionOop, CodeEmitInfo* info) {
     append(new LIR_Op2(lir_throw, exceptionPC, exceptionOop, LIR_OprFact::illegalOpr, info));
   }
   void unwind_exception(LIR_Opr exceptionOop) {
diff a/src/hotspot/share/c1/c1_LIRAssembler.cpp b/src/hotspot/share/c1/c1_LIRAssembler.cpp
--- a/src/hotspot/share/c1/c1_LIRAssembler.cpp
+++ b/src/hotspot/share/c1/c1_LIRAssembler.cpp
@@ -580,20 +580,10 @@
 
     case lir_monaddr:
       monitor_address(op->in_opr()->as_constant_ptr()->as_jint(), op->result_opr());
       break;
 
-#ifdef SPARC
-    case lir_pack64:
-      pack64(op->in_opr(), op->result_opr());
-      break;
-
-    case lir_unpack64:
-      unpack64(op->in_opr(), op->result_opr());
-      break;
-#endif
-
     case lir_unwind:
       unwind_op(op->in_opr());
       break;
 
     default:
@@ -971,14 +961,10 @@
       if (v.is_oop()) {
         VMReg r = v.reg();
         if (!r->is_stack()) {
           stringStream st;
           st.print("bad oop %s at %d", r->as_Register()->name(), _masm->offset());
-#ifdef SPARC
-          _masm->_verify_oop(r->as_Register(), os::strdup(st.as_string(), mtCompiler), __FILE__, __LINE__);
-#else
-          _masm->verify_oop(r->as_Register());
 #endif
         } else {
           _masm->verify_stack_oop(r->reg2stack() * VMRegImpl::stack_slot_size);
         }
       }
diff a/src/hotspot/share/c1/c1_LinearScan.cpp b/src/hotspot/share/c1/c1_LinearScan.cpp
--- a/src/hotspot/share/c1/c1_LinearScan.cpp
+++ b/src/hotspot/share/c1/c1_LinearScan.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -2127,15 +2127,15 @@
         }
 
 #ifdef _LP64
         return LIR_OprFact::double_cpu(assigned_reg, assigned_reg);
 #else
-#if defined(SPARC) || defined(PPC32)
+#if defined(PPC32)
         return LIR_OprFact::double_cpu(assigned_regHi, assigned_reg);
 #else
         return LIR_OprFact::double_cpu(assigned_reg, assigned_regHi);
-#endif // SPARC
+#endif // PPC32
 #endif // LP64
       }
 
 #ifndef __SOFTFP__
       case T_FLOAT: {
@@ -2171,16 +2171,11 @@
           assert(interval->assigned_regHi() == any_reg, "must not have hi register (double xmm values are stored in one register)");
           return LIR_OprFact::double_xmm(assigned_reg - pd_first_xmm_reg);
         }
 #endif // X86
 
-#ifdef SPARC
-        assert(assigned_reg >= pd_first_fpu_reg && assigned_reg <= pd_last_fpu_reg, "no fpu register");
-        assert(interval->assigned_regHi() >= pd_first_fpu_reg && interval->assigned_regHi() <= pd_last_fpu_reg, "no fpu register");
-        assert(assigned_reg % 2 == 0 && assigned_reg + 1 == interval->assigned_regHi(), "must be sequential and even");
-        LIR_Opr result = LIR_OprFact::double_fpu(interval->assigned_regHi() - pd_first_fpu_reg, assigned_reg - pd_first_fpu_reg);
-#elif defined(ARM32)
+#if defined(ARM32)
         assert(assigned_reg >= pd_first_fpu_reg && assigned_reg <= pd_last_fpu_reg, "no fpu register");
         assert(interval->assigned_regHi() >= pd_first_fpu_reg && interval->assigned_regHi() <= pd_last_fpu_reg, "no fpu register");
         assert(assigned_reg % 2 == 0 && assigned_reg + 1 == interval->assigned_regHi(), "must be sequential and even");
         LIR_Opr result = LIR_OprFact::double_fpu(assigned_reg - pd_first_fpu_reg, interval->assigned_regHi() - pd_first_fpu_reg);
 #else
@@ -2776,13 +2771,10 @@
       assert(opr->fpu_regnrLo() == opr->fpu_regnrHi(), "assumed in calculation (only fpu_regnrLo is used)");
 #endif
 #ifdef AMD64
       assert(false, "FPU not used on x86-64");
 #endif
-#ifdef SPARC
-      assert(opr->fpu_regnrLo() == opr->fpu_regnrHi() + 1, "assumed in calculation (only fpu_regnrHi is used)");
-#endif
 #ifdef ARM32
       assert(opr->fpu_regnrHi() == opr->fpu_regnrLo() + 1, "assumed in calculation (only fpu_regnrLo is used)");
 #endif
 #ifdef PPC32
       assert(opr->fpu_regnrLo() == opr->fpu_regnrHi(), "assumed in calculation (only fpu_regnrHi is used)");
diff a/src/hotspot/share/c1/c1_Runtime1.cpp b/src/hotspot/share/c1/c1_Runtime1.cpp
--- a/src/hotspot/share/c1/c1_Runtime1.cpp
+++ b/src/hotspot/share/c1/c1_Runtime1.cpp
@@ -250,11 +250,11 @@
   case dtrace_object_alloc_id:
   case slow_subtype_check_id:
   case fpu2long_stub_id:
   case unwind_exception_id:
   case counter_overflow_id:
-#if defined(SPARC) || defined(PPC32)
+#if defined(PPC32)
   case handle_exception_nofpu_id:  // Unused on sparc
 #endif
     expect_oop_map = false;
     break;
   default:
@@ -1256,11 +1256,11 @@
           }
         } else {
           ShouldNotReachHere();
         }
 
-#if defined(SPARC) || defined(PPC32)
+#if defined(PPC32)
         if (load_klass_or_mirror_patch_id ||
             stub_id == Runtime1::load_appendix_patching_id) {
           // Update the location in the nmethod with the proper
           // metadata.  When the code was generated, a NULL was stuffed
           // in the metadata table and that table needs to be update to
@@ -1347,17 +1347,10 @@
             // the reloc info so that it will get updated during
             // future GCs.
             RelocIterator iter(nm, (address)instr_pc, (address)(instr_pc + 1));
             relocInfo::change_reloc_info_for_address(&iter, (address) instr_pc,
                                                      relocInfo::none, rtype);
-#ifdef SPARC
-            // Sparc takes two relocations for an metadata so update the second one.
-            address instr_pc2 = instr_pc + NativeMovConstReg::add_offset;
-            RelocIterator iter2(nm, instr_pc2, instr_pc2 + 1);
-            relocInfo::change_reloc_info_for_address(&iter2, (address) instr_pc2,
-                                                     relocInfo::none, rtype);
-#endif
 #ifdef PPC32
           { address instr_pc2 = instr_pc + NativeMovConstReg::lo_offset;
             RelocIterator iter2(nm, instr_pc2, instr_pc2 + 1);
             relocInfo::change_reloc_info_for_address(&iter2, (address) instr_pc2,
                                                      relocInfo::none, rtype);
diff a/src/hotspot/share/classfile/classListParser.cpp b/src/hotspot/share/classfile/classListParser.cpp
--- a/src/hotspot/share/classfile/classListParser.cpp
+++ b/src/hotspot/share/classfile/classListParser.cpp
@@ -280,11 +280,11 @@
 }
 
 // This function is used for loading classes for customized class loaders
 // during archive dumping.
 InstanceKlass* ClassListParser::load_class_from_source(Symbol* class_name, TRAPS) {
-#if !(defined(_LP64) && (defined(LINUX)|| defined(SOLARIS) || defined(__APPLE__)))
+#if !(defined(_LP64) && (defined(LINUX) || defined(__APPLE__)))
   // The only supported platforms are: (1) Linux/64-bit and (2) Solaris/64-bit and
   // (3) MacOSX/64-bit
   // This #if condition should be in sync with the areCustomLoadersSupportedForCDS
   // method in test/lib/jdk/test/lib/Platform.java.
   error("AppCDS custom class loaders not supported on this platform");
diff a/src/hotspot/share/classfile/javaClasses.cpp b/src/hotspot/share/classfile/javaClasses.cpp
--- a/src/hotspot/share/classfile/javaClasses.cpp
+++ b/src/hotspot/share/classfile/javaClasses.cpp
@@ -286,12 +286,11 @@
   {
     ResourceMark rm;
     char* expected = UNICODE::as_utf8(unicode, length);
     char* actual = as_utf8_string(h_obj());
     if (strcmp(expected, actual) != 0) {
-      tty->print_cr("Unicode conversion failure: %s --> %s", expected, actual);
-      ShouldNotReachHere();
+      fatal("Unicode conversion failure: %s --> %s", expected, actual);
     }
   }
 #endif
 
   return h_obj;
@@ -324,23 +323,20 @@
       UTF8::convert_to_unicode(utf8_str, value(h_obj())->char_at_addr(0), length);
     }
   }
 
 #ifdef ASSERT
-  // This check is too strict because the input string is not necessarily valid UTF8.
+  // This check is too strict when the input string is not a valid UTF8.
   // For example, it may be created with arbitrary content via jni_NewStringUTF.
-  /*
-  {
+  if (UTF8::is_legal_utf8((const unsigned char*)utf8_str, (int)strlen(utf8_str), false)) {
     ResourceMark rm;
     const char* expected = utf8_str;
     char* actual = as_utf8_string(h_obj());
     if (strcmp(expected, actual) != 0) {
-      tty->print_cr("String conversion failure: %s --> %s", expected, actual);
-      ShouldNotReachHere();
+      fatal("String conversion failure: %s --> %s", expected, actual);
     }
   }
-  */
 #endif
 
   return h_obj;
 }
 
@@ -376,12 +372,11 @@
   {
     ResourceMark rm;
     const char* expected = symbol->as_utf8();
     char* actual = as_utf8_string(h_obj());
     if (strncmp(expected, actual, utf8_len) != 0) {
-      tty->print_cr("Symbol conversion failure: %s --> %s", expected, actual);
-      ShouldNotReachHere();
+      fatal("Symbol conversion failure: %s --> %s", expected, actual);
     }
   }
 #endif
 
   return h_obj;
diff a/src/hotspot/share/classfile/systemDictionary.cpp b/src/hotspot/share/classfile/systemDictionary.cpp
--- a/src/hotspot/share/classfile/systemDictionary.cpp
+++ b/src/hotspot/share/classfile/systemDictionary.cpp
@@ -85,10 +85,11 @@
 #include "runtime/signature.hpp"
 #include "services/classLoadingService.hpp"
 #include "services/diagnosticCommand.hpp"
 #include "services/threadService.hpp"
 #include "utilities/macros.hpp"
+#include "utilities/utf8.hpp"
 #if INCLUDE_CDS
 #include "classfile/systemDictionaryShared.hpp"
 #endif
 #if INCLUDE_JFR
 #include "jfr/jfr.hpp"
@@ -233,10 +234,31 @@
 }
 
 // ----------------------------------------------------------------------------
 // Resolving of classes
 
+Symbol* SystemDictionary::class_name_symbol(const char* name, Symbol* exception, TRAPS) {
+  if (name == NULL) {
+    THROW_MSG_0(exception, "No class name given");
+  }
+  if ((int)strlen(name) > Symbol::max_length()) {
+    // It's impossible to create this class;  the name cannot fit
+    // into the constant pool.
+    Exceptions::fthrow(THREAD_AND_LOCATION, exception,
+                       "Class name exceeds maximum length of %d: %s",
+                       Symbol::max_length(),
+                       name);
+    return NULL;
+  }
+  // Callers should ensure that the name is never an illegal UTF8 string.
+  assert(UTF8::is_legal_utf8((const unsigned char*)name, (int)strlen(name), false),
+         "Class name is not a valid utf8 string.");
+
+  // Make a new symbol for the class name.
+  return SymbolTable::new_symbol(name);
+}
+
 // Forwards to resolve_or_null
 
 Klass* SystemDictionary::resolve_or_fail(Symbol* class_name, Handle class_loader, Handle protection_domain, bool throw_error, TRAPS) {
   Klass* klass = resolve_or_null(class_name, class_loader, protection_domain, THREAD);
   if (HAS_PENDING_EXCEPTION || klass == NULL) {
diff a/src/hotspot/share/classfile/systemDictionary.hpp b/src/hotspot/share/classfile/systemDictionary.hpp
--- a/src/hotspot/share/classfile/systemDictionary.hpp
+++ b/src/hotspot/share/classfile/systemDictionary.hpp
@@ -677,10 +677,13 @@
   static bool is_nonpublic_Object_method(Method* m) {
     assert(m != NULL, "Unexpected NULL Method*");
     return !m->is_public() && m->method_holder() == SystemDictionary::Object_klass();
   }
 
+  // Return Symbol or throw exception if name given is can not be a valid Symbol.
+  static Symbol* class_name_symbol(const char* name, Symbol* exception, TRAPS);
+
 protected:
   // Setup link to hierarchy
   static void add_to_hierarchy(InstanceKlass* k, TRAPS);
 
   // Basic find on loaded classes
diff a/src/hotspot/share/compiler/oopMap.cpp b/src/hotspot/share/compiler/oopMap.cpp
--- a/src/hotspot/share/compiler/oopMap.cpp
+++ b/src/hotspot/share/compiler/oopMap.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -314,12 +314,11 @@
         oop_fn->do_oop(loc);
       } else if ( omv.type() == OopMapValue::narrowoop_value ) {
         narrowOop *nl = (narrowOop*)loc;
 #ifndef VM_LITTLE_ENDIAN
         VMReg vmReg = omv.reg();
-        // Don't do this on SPARC float registers as they can be individually addressed
-        if (!vmReg->is_stack() SPARC_ONLY(&& !vmReg->is_FloatRegister())) {
+        if (!vmReg->is_stack()) {
           // compressed oops in registers only take up 4 bytes of an
           // 8 byte register but they are in the wrong part of the
           // word so adjust loc to point at the right place.
           nl = (narrowOop*)((address)nl + 4);
         }
diff a/src/hotspot/share/gc/parallel/psPromotionManager.cpp b/src/hotspot/share/gc/parallel/psPromotionManager.cpp
--- a/src/hotspot/share/gc/parallel/psPromotionManager.cpp
+++ b/src/hotspot/share/gc/parallel/psPromotionManager.cpp
@@ -42,11 +42,11 @@
 #include "oops/access.inline.hpp"
 #include "oops/compressedOops.inline.hpp"
 #include "oops/valueArrayKlass.inline.hpp"
 
 PaddedEnd<PSPromotionManager>* PSPromotionManager::_manager_array = NULL;
-PSPromotionManager::OopStarTaskQueueSet* PSPromotionManager::_stack_array_depth = NULL;
+PSPromotionManager::PSScannerTasksQueueSet* PSPromotionManager::_stack_array_depth = NULL;
 PreservedMarksSet*             PSPromotionManager::_preserved_marks_set = NULL;
 PSOldGen*                      PSPromotionManager::_old_gen = NULL;
 MutableSpace*                  PSPromotionManager::_young_space = NULL;
 
 void PSPromotionManager::initialize() {
@@ -60,11 +60,11 @@
   // To prevent false sharing, we pad the PSPromotionManagers
   // and make sure that the first instance starts at a cache line.
   assert(_manager_array == NULL, "Attempt to initialize twice");
   _manager_array = PaddedArray<PSPromotionManager, mtGC>::create_unfreeable(promotion_manager_num);
 
-  _stack_array_depth = new OopStarTaskQueueSet(ParallelGCThreads);
+  _stack_array_depth = new PSScannerTasksQueueSet(ParallelGCThreads);
 
   // Create and register the PSPromotionManager(s) for the worker threads.
   for(uint i=0; i<ParallelGCThreads; i++) {
     stack_array_depth()->register_queue(i, _manager_array[i].claimed_stack_depth());
   }
@@ -133,17 +133,18 @@
 
 #if TASKQUEUE_STATS
 void
 PSPromotionManager::print_local_stats(outputStream* const out, uint i) const {
   #define FMT " " SIZE_FORMAT_W(10)
-  out->print_cr("%3u" FMT FMT FMT FMT, i, _masked_pushes, _masked_steals,
+  out->print_cr("%3u" FMT FMT FMT FMT,
+                i, _array_chunk_pushes, _array_chunk_steals,
                 _arrays_chunked, _array_chunks_processed);
   #undef FMT
 }
 
 static const char* const pm_stats_hdr[] = {
-  "    --------masked-------     arrays      array",
+  "    ----partial array----     arrays      array",
   "thr       push      steal    chunked     chunks",
   "--- ---------- ---------- ---------- ----------"
 };
 
 void
@@ -176,11 +177,11 @@
 }
 
 void
 PSPromotionManager::reset_stats() {
   claimed_stack_depth()->stats.reset();
-  _masked_pushes = _masked_steals = 0;
+  _array_chunk_pushes = _array_chunk_steals = 0;
   _arrays_chunked = _array_chunks_processed = 0;
 }
 #endif // TASKQUEUE_STATS
 
 PSPromotionManager::PSPromotionManager() {
@@ -248,27 +249,27 @@
   ParallelScavengeHeap* heap = ParallelScavengeHeap::heap();
   MutableSpace* to_space = heap->young_gen()->to_space();
   MutableSpace* old_space = heap->old_gen()->object_space();
 #endif /* ASSERT */
 
-  OopStarTaskQueue* const tq = claimed_stack_depth();
+  PSScannerTasksQueue* const tq = claimed_stack_depth();
   do {
-    StarTask p;
+    ScannerTask task;
 
     // Drain overflow stack first, so other threads can steal from
     // claimed stack while we work.
-    while (tq->pop_overflow(p)) {
-      process_popped_location_depth(p);
+    while (tq->pop_overflow(task)) {
+      process_popped_location_depth(task);
     }
 
     if (totally_drain) {
-      while (tq->pop_local(p)) {
-        process_popped_location_depth(p);
+      while (tq->pop_local(task)) {
+        process_popped_location_depth(task);
       }
     } else {
-      while (tq->size() > _target_stack_size && tq->pop_local(p)) {
-        process_popped_location_depth(p);
+      while (tq->size() > _target_stack_size && tq->pop_local(task)) {
+        process_popped_location_depth(task);
       }
     }
   } while ((totally_drain && !tq->taskqueue_empty()) || !tq->overflow_empty());
 
   assert(!totally_drain || tq->taskqueue_empty(), "Sanity");
@@ -308,12 +309,14 @@
     }
     ++p;
   }
 }
 
-void PSPromotionManager::process_array_chunk(oop old) {
+void PSPromotionManager::process_array_chunk(PartialArrayScanTask task) {
   assert(PSChunkLargeArrays, "invariant");
+
+  oop old = task.to_source_array();
   assert(old->is_objArray(), "invariant");
   assert(old->is_forwarded(), "invariant");
 
   TASKQUEUE_STATS_ONLY(++_array_chunks_processed);
 
@@ -324,12 +327,12 @@
   if (end > (int) _min_array_size_for_chunking) {
     // we'll chunk more
     start = end - _array_chunk_size;
     assert(start > 0, "invariant");
     arrayOop(old)->set_length(start);
-    push_depth(mask_chunked_array_oop(old));
-    TASKQUEUE_STATS_ONLY(++_masked_pushes);
+    push_depth(ScannerTask(PartialArrayScanTask(old)));
+    TASKQUEUE_STATS_ONLY(++_array_chunk_pushes);
   } else {
     // this is the final chunk for this array
     start = 0;
     int const actual_length = arrayOop(obj)->length();
     arrayOop(old)->set_length(actual_length);
diff a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
--- a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
+++ b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
@@ -921,13 +921,20 @@
   Node* old_ctrl = ctrl;
   PhaseIterGVN& igvn = phase->igvn();
 
   Node* raw_val        = new CastP2XNode(old_ctrl, val);
   Node* cset_idx       = new URShiftXNode(raw_val, igvn.intcon(ShenandoahHeapRegion::region_size_bytes_shift_jint()));
-  Node* cset_addr      = igvn.makecon(TypeRawPtr::make(ShenandoahHeap::in_cset_fast_test_addr()));
-  Node* cset_load_addr = new AddPNode(phase->C->top(), cset_addr, cset_idx);
-  Node* cset_load      = new LoadBNode(old_ctrl, raw_mem, cset_load_addr,
+
+  // Figure out the target cset address with raw pointer math.
+  // This avoids matching AddP+LoadB that would emit inefficient code.
+  // See JDK-8245465.
+  Node* cset_addr_ptr  = igvn.makecon(TypeRawPtr::make(ShenandoahHeap::in_cset_fast_test_addr()));
+  Node* cset_addr      = new CastP2XNode(old_ctrl, cset_addr_ptr);
+  Node* cset_load_addr = new AddXNode(cset_addr, cset_idx);
+  Node* cset_load_ptr  = new CastX2PNode(cset_load_addr);
+
+  Node* cset_load      = new LoadBNode(old_ctrl, raw_mem, cset_load_ptr,
                                        DEBUG_ONLY(phase->C->get_adr_type(Compile::AliasIdxRaw)) NOT_DEBUG(NULL),
                                        TypeInt::BYTE, MemNode::unordered);
   Node* cset_cmp       = new CmpINode(cset_load, igvn.zerocon(T_INT));
   Node* cset_bool      = new BoolNode(cset_cmp, BoolTest::ne);
 
@@ -938,15 +945,17 @@
   IdealLoopTree *loop = phase->get_loop(old_ctrl);
   phase->register_control(cset_iff,      loop, old_ctrl);
   phase->register_control(ctrl,          loop, cset_iff);
   phase->register_control(not_cset_ctrl, loop, cset_iff);
 
-  phase->set_ctrl(cset_addr, phase->C->root());
+  phase->set_ctrl(cset_addr_ptr, phase->C->root());
 
   phase->register_new_node(raw_val,        old_ctrl);
   phase->register_new_node(cset_idx,       old_ctrl);
+  phase->register_new_node(cset_addr,      old_ctrl);
   phase->register_new_node(cset_load_addr, old_ctrl);
+  phase->register_new_node(cset_load_ptr,  old_ctrl);
   phase->register_new_node(cset_load,      old_ctrl);
   phase->register_new_node(cset_cmp,       old_ctrl);
   phase->register_new_node(cset_bool,      old_ctrl);
 }
 
diff a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
--- a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
+++ b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
@@ -27,10 +27,11 @@
 
 #include "gc/shared/barrierSet.hpp"
 #include "gc/shenandoah/shenandoahAsserts.hpp"
 #include "gc/shenandoah/shenandoahBarrierSet.hpp"
 #include "gc/shenandoah/shenandoahCollectionSet.inline.hpp"
+#include "gc/shenandoah/shenandoahEvacOOMHandler.inline.hpp"
 #include "gc/shenandoah/shenandoahForwarding.inline.hpp"
 #include "gc/shenandoah/shenandoahHeap.inline.hpp"
 #include "gc/shenandoah/shenandoahHeapRegion.hpp"
 #include "gc/shenandoah/shenandoahMarkingContext.inline.hpp"
 #include "gc/shenandoah/shenandoahThreadLocalData.hpp"
@@ -60,12 +61,13 @@
 
   oop fwd = resolve_forwarded_not_null_mutator(obj);
   if (obj == fwd) {
     assert(_heap->is_evacuation_in_progress(),
            "evac should be in progress");
-    ShenandoahEvacOOMScope scope;
-    fwd = _heap->evacuate_object(obj, Thread::current());
+    Thread* const t = Thread::current();
+    ShenandoahEvacOOMScope scope(t);
+    fwd = _heap->evacuate_object(obj, t);
   }
 
   if (load_addr != NULL && fwd != obj) {
     // Since we are here and we know the load address, update the reference.
     ShenandoahHeap::cas_oop(fwd, load_addr, obj);
diff a/src/hotspot/share/interpreter/abstractInterpreter.hpp b/src/hotspot/share/interpreter/abstractInterpreter.hpp
--- a/src/hotspot/share/interpreter/abstractInterpreter.hpp
+++ b/src/hotspot/share/interpreter/abstractInterpreter.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -239,11 +239,11 @@
   static int expr_index_at(int i) {
     return stackElementWords * i;
   }
 
   static int expr_offset_in_bytes(int i) {
-#if !defined(ZERO) && (defined(PPC) || defined(S390) || defined(SPARC))
+#if !defined(ZERO) && (defined(PPC) || defined(S390))
     return stackElementSize * i + wordSize;  // both point to one word past TOS
 #else
     return stackElementSize * i;
 #endif
   }
diff a/src/hotspot/share/jvmci/jvmciCompiler.cpp b/src/hotspot/share/jvmci/jvmciCompiler.cpp
--- a/src/hotspot/share/jvmci/jvmciCompiler.cpp
+++ b/src/hotspot/share/jvmci/jvmciCompiler.cpp
@@ -40,10 +40,11 @@
   _instance = this;
 }
 
 // Initialization
 void JVMCICompiler::initialize() {
+  assert(!is_c1_or_interpreter_only(), "JVMCI is launched, it's not c1/interpreter only mode");
   if (!UseCompiler || !EnableJVMCI || !UseJVMCICompiler || !should_perform_init()) {
     return;
   }
 
   set_state(initialized);
diff a/src/hotspot/share/jvmci/vmStructs_jvmci.cpp b/src/hotspot/share/jvmci/vmStructs_jvmci.cpp
--- a/src/hotspot/share/jvmci/vmStructs_jvmci.cpp
+++ b/src/hotspot/share/jvmci/vmStructs_jvmci.cpp
@@ -379,11 +379,10 @@
     declare_type(ConstantPool, Metadata)                                  \
 
 #define VM_INT_CONSTANTS(declare_constant, declare_constant_with_value, declare_preprocessor_constant) \
   declare_preprocessor_constant("ASSERT", DEBUG_ONLY(1) NOT_DEBUG(0))     \
   declare_preprocessor_constant("FIELDINFO_TAG_SIZE", FIELDINFO_TAG_SIZE) \
-  declare_preprocessor_constant("STACK_BIAS", STACK_BIAS)                 \
                                                                           \
   declare_constant(CompLevel_none)                                        \
   declare_constant(CompLevel_simple)                                      \
   declare_constant(CompLevel_limited_profile)                             \
   declare_constant(CompLevel_full_profile)                                \
@@ -725,12 +724,11 @@
   declare_constant(VM_Version::CPU_SHA1)                \
   declare_constant(VM_Version::CPU_SHA2)                \
   declare_constant(VM_Version::CPU_CRC32)               \
   declare_constant(VM_Version::CPU_LSE)                 \
   declare_constant(VM_Version::CPU_STXR_PREFETCH)       \
-  declare_constant(VM_Version::CPU_A53MAC)              \
-  declare_constant(VM_Version::CPU_DMB_ATOMICS)
+  declare_constant(VM_Version::CPU_A53MAC)
 
 #endif
 
 
 #ifdef X86
@@ -791,65 +789,10 @@
   declare_preprocessor_constant("VM_Version::CPU_AVX512_VBMI2", CPU_AVX512_VBMI2) \
   declare_preprocessor_constant("VM_Version::CPU_AVX512_VBMI", CPU_AVX512_VBMI)
 
 #endif
 
-
-#ifdef SPARC
-
-#define VM_STRUCTS_CPU(nonstatic_field, static_field, unchecked_nonstatic_field, volatile_nonstatic_field, nonproduct_nonstatic_field, c2_nonstatic_field, unchecked_c1_static_field, unchecked_c2_static_field) \
-  volatile_nonstatic_field(JavaFrameAnchor, _flags, int)
-
-#define VM_INT_CONSTANTS_CPU(declare_constant, declare_preprocessor_constant, declare_c1_constant, declare_c2_constant, declare_c2_preprocessor_constant) \
-  declare_constant(VM_Version::ISA_V9)                  \
-  declare_constant(VM_Version::ISA_POPC)                \
-  declare_constant(VM_Version::ISA_VIS1)                \
-  declare_constant(VM_Version::ISA_VIS2)                \
-  declare_constant(VM_Version::ISA_BLK_INIT)            \
-  declare_constant(VM_Version::ISA_FMAF)                \
-  declare_constant(VM_Version::ISA_VIS3)                \
-  declare_constant(VM_Version::ISA_HPC)                 \
-  declare_constant(VM_Version::ISA_IMA)                 \
-  declare_constant(VM_Version::ISA_AES)                 \
-  declare_constant(VM_Version::ISA_DES)                 \
-  declare_constant(VM_Version::ISA_KASUMI)              \
-  declare_constant(VM_Version::ISA_CAMELLIA)            \
-  declare_constant(VM_Version::ISA_MD5)                 \
-  declare_constant(VM_Version::ISA_SHA1)                \
-  declare_constant(VM_Version::ISA_SHA256)              \
-  declare_constant(VM_Version::ISA_SHA512)              \
-  declare_constant(VM_Version::ISA_MPMUL)               \
-  declare_constant(VM_Version::ISA_MONT)                \
-  declare_constant(VM_Version::ISA_PAUSE)               \
-  declare_constant(VM_Version::ISA_CBCOND)              \
-  declare_constant(VM_Version::ISA_CRC32C)              \
-  declare_constant(VM_Version::ISA_VIS3B)               \
-  declare_constant(VM_Version::ISA_ADI)                 \
-  declare_constant(VM_Version::ISA_SPARC5)              \
-  declare_constant(VM_Version::ISA_MWAIT)               \
-  declare_constant(VM_Version::ISA_XMPMUL)              \
-  declare_constant(VM_Version::ISA_XMONT)               \
-  declare_constant(VM_Version::ISA_PAUSE_NSEC)          \
-  declare_constant(VM_Version::ISA_VAMASK)              \
-  declare_constant(VM_Version::ISA_SPARC6)              \
-  declare_constant(VM_Version::ISA_DICTUNP)             \
-  declare_constant(VM_Version::ISA_FPCMPSHL)            \
-  declare_constant(VM_Version::ISA_RLE)                 \
-  declare_constant(VM_Version::ISA_SHA3)                \
-  declare_constant(VM_Version::ISA_VIS3C)               \
-  declare_constant(VM_Version::ISA_SPARC5B)             \
-  declare_constant(VM_Version::ISA_MME)                 \
-  declare_constant(VM_Version::CPU_FAST_IDIV)           \
-  declare_constant(VM_Version::CPU_FAST_RDPC)           \
-  declare_constant(VM_Version::CPU_FAST_BIS)            \
-  declare_constant(VM_Version::CPU_FAST_LD)             \
-  declare_constant(VM_Version::CPU_FAST_CMOVE)          \
-  declare_constant(VM_Version::CPU_FAST_IND_BR)         \
-  declare_constant(VM_Version::CPU_BLK_ZEROING)
-#endif
-
-
 /*
  * Dummy defines for architectures that don't use these.
  */
 #ifndef VM_STRUCTS_CPU
 #define VM_STRUCTS_CPU(nonstatic_field, static_field, unchecked_nonstatic_field, volatile_nonstatic_field, nonproduct_nonstatic_field, c2_nonstatic_field, unchecked_c1_static_field, unchecked_c2_static_field)
diff a/src/hotspot/share/memory/dynamicArchive.cpp b/src/hotspot/share/memory/dynamicArchive.cpp
--- a/src/hotspot/share/memory/dynamicArchive.cpp
+++ b/src/hotspot/share/memory/dynamicArchive.cpp
@@ -67,11 +67,11 @@
   static intx _buffer_to_target_delta;
 
   DumpRegion* _current_dump_space;
 
   static size_t reserve_alignment() {
-    return Metaspace::reserve_alignment();
+    return os::vm_allocation_granularity();
   }
 
   static const int _total_dump_regions = 3;
   int _num_dump_regions_used;
 
@@ -736,11 +736,11 @@
   return align_up(total, reserve_alignment());
 }
 
 address DynamicArchiveBuilder::reserve_space_and_init_buffer_to_target_delta() {
   size_t total = estimate_archive_size();
-  ReservedSpace rs = MetaspaceShared::reserve_shared_space(total);
+  ReservedSpace rs(total);
   if (!rs.is_reserved()) {
     log_error(cds, dynamic)("Failed to reserve %d bytes of output buffer.", (int)total);
     vm_direct_exit(0);
   }
 
diff a/src/hotspot/share/memory/metaspaceClosure.hpp b/src/hotspot/share/memory/metaspaceClosure.hpp
--- a/src/hotspot/share/memory/metaspaceClosure.hpp
+++ b/src/hotspot/share/memory/metaspaceClosure.hpp
@@ -266,10 +266,11 @@
   virtual bool do_ref(Ref* ref, bool read_only) = 0;
 
   // When you do:
   //     void MyType::metaspace_pointers_do(MetaspaceClosure* it) {
   //       it->push(_my_field)
+  //     }
   //
   // C++ will try to match the "most specific" template function. This one will
   // will be matched if possible (if mpp is an Array<> of any pointer type).
   template <typename T> void push(Array<T*>** mpp, Writability w = _default) {
     push_impl(new PointerArrayRef<T>(mpp, w));
diff a/src/hotspot/share/memory/metaspaceShared.cpp b/src/hotspot/share/memory/metaspaceShared.cpp
--- a/src/hotspot/share/memory/metaspaceShared.cpp
+++ b/src/hotspot/share/memory/metaspaceShared.cpp
@@ -69,10 +69,11 @@
 #include "runtime/timerTrace.hpp"
 #include "runtime/vmThread.hpp"
 #include "runtime/vmOperations.hpp"
 #include "utilities/align.hpp"
 #include "utilities/bitMap.inline.hpp"
+#include "utilities/ostream.hpp"
 #include "utilities/defaultStream.hpp"
 #include "utilities/hashtable.inline.hpp"
 #if INCLUDE_G1GC
 #include "gc/g1/g1CollectedHeap.hpp"
 #endif
@@ -191,11 +192,11 @@
   _end = _rs->end();
 }
 
 void DumpRegion::pack(DumpRegion* next) {
   assert(!is_packed(), "sanity");
-  _end = (char*)align_up(_top, Metaspace::reserve_alignment());
+  _end = (char*)align_up(_top, MetaspaceShared::reserved_space_alignment());
   _is_packed = true;
   if (next != NULL) {
     next->_rs = _rs;
     next->_vs = _vs;
     next->_base = next->_top = this->_end;
@@ -237,104 +238,162 @@
 
 char* MetaspaceShared::read_only_space_alloc(size_t num_bytes) {
   return _ro_region.allocate(num_bytes);
 }
 
-// When reserving an address range using ReservedSpace, we need an alignment that satisfies both:
-// os::vm_allocation_granularity() -- so that we can sub-divide this range into multiple mmap regions,
-//                                    while keeping the first range at offset 0 of this range.
-// Metaspace::reserve_alignment()  -- so we can pass the region to
-//                                    Metaspace::allocate_metaspace_compressed_klass_ptrs.
-size_t MetaspaceShared::reserved_space_alignment() {
-  size_t os_align = os::vm_allocation_granularity();
-  size_t ms_align = Metaspace::reserve_alignment();
-  if (os_align >= ms_align) {
-    assert(os_align % ms_align == 0, "must be a multiple");
-    return os_align;
-  } else {
-    assert(ms_align % os_align == 0, "must be a multiple");
-    return ms_align;
-  }
-}
+size_t MetaspaceShared::reserved_space_alignment() { return os::vm_allocation_granularity(); }
 
-ReservedSpace MetaspaceShared::reserve_shared_space(size_t size, char* requested_address) {
-  return Metaspace::reserve_space(size, reserved_space_alignment(),
-                                  requested_address, requested_address != NULL);
+#ifdef _LP64
+// Check SharedBaseAddress for validity. At this point, os::init() must
+//  have been ran.
+static void check_SharedBaseAddress() {
+  SharedBaseAddress = align_up(SharedBaseAddress,
+                               MetaspaceShared::reserved_space_alignment());
+  if (!CompressedKlassPointers::is_valid_base((address)SharedBaseAddress)) {
+    log_warning(cds)("SharedBaseAddress=" PTR_FORMAT " is invalid for this "
+                     "platform, option will be ignored.",
+                     p2i((address)SharedBaseAddress));
+    SharedBaseAddress = Arguments::default_SharedBaseAddress();
+  }
 }
+#endif
 
 void MetaspaceShared::initialize_dumptime_shared_and_meta_spaces() {
   assert(DumpSharedSpaces, "should be called for dump time only");
-  const size_t reserve_alignment = reserved_space_alignment();
+
+#ifdef _LP64
+  check_SharedBaseAddress();
+#endif
+
+  const size_t reserve_alignment = MetaspaceShared::reserved_space_alignment();
   char* shared_base = (char*)align_up((char*)SharedBaseAddress, reserve_alignment);
 
 #ifdef _LP64
-  // On 64-bit VM, the heap and class space layout will be the same as if
-  // you're running in -Xshare:on mode:
-  //
-  //                              +-- SharedBaseAddress (default = 0x800000000)
-  //                              v
-  // +-..---------+---------+ ... +----+----+----+--------------------+
-  // |    Heap    | Archive |     | MC | RW | RO |    class space     |
-  // +-..---------+---------+ ... +----+----+----+--------------------+
-  // |<--   MaxHeapSize  -->|     |<-- UnscaledClassSpaceMax = 4GB -->|
-  //
+  assert(CompressedKlassPointers::is_valid_base((address)shared_base), "Sanity");
+  // On 64-bit VM we reserve a 4G range and, if UseCompressedClassPointers=1,
+  //  will use that to house both the archives and the ccs. See below for
+  //  details.
   const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);
   const size_t cds_total = align_down(UnscaledClassSpaceMax, reserve_alignment);
 #else
-  // We don't support archives larger than 256MB on 32-bit due to limited virtual address space.
+  // We don't support archives larger than 256MB on 32-bit due to limited
+  //  virtual address space.
   size_t cds_total = align_down(256*M, reserve_alignment);
 #endif
 
+  // Whether to use SharedBaseAddress as attach address.
   bool use_requested_base = true;
+
+  if (shared_base == NULL) {
+    use_requested_base = false;
+  }
+
   if (ArchiveRelocationMode == 1) {
     log_info(cds)("ArchiveRelocationMode == 1: always allocate class space at an alternative address");
     use_requested_base = false;
   }
 
   // First try to reserve the space at the specified SharedBaseAddress.
   assert(!_shared_rs.is_reserved(), "must be");
   if (use_requested_base) {
-    _shared_rs = reserve_shared_space(cds_total, shared_base);
+    _shared_rs = ReservedSpace(cds_total, reserve_alignment,
+                               false /* large */, (char*)shared_base);
+    if (_shared_rs.is_reserved()) {
+      assert(_shared_rs.base() == shared_base, "should match");
+    } else {
+      log_info(cds)("dumptime space reservation: failed to map at "
+                    "SharedBaseAddress " PTR_FORMAT, p2i(shared_base));
+    }
   }
-  if (_shared_rs.is_reserved()) {
-    assert(shared_base == 0 || _shared_rs.base() == shared_base, "should match");
-  } else {
-    // Get a mmap region anywhere if the SharedBaseAddress fails.
-    _shared_rs = reserve_shared_space(cds_total);
+  if (!_shared_rs.is_reserved()) {
+    // Get a reserved space anywhere if attaching at the SharedBaseAddress
+    //  fails:
+    if (UseCompressedClassPointers) {
+      // If we need to reserve class space as well, let the platform handle
+      //  the reservation.
+      LP64_ONLY(_shared_rs =
+                Metaspace::reserve_address_space_for_compressed_classes(cds_total);)
+      NOT_LP64(ShouldNotReachHere();)
+    } else {
+      // anywhere is fine.
+      _shared_rs = ReservedSpace(cds_total, reserve_alignment,
+                                 false /* large */, (char*)NULL);
+    }
   }
+
   if (!_shared_rs.is_reserved()) {
     vm_exit_during_initialization("Unable to reserve memory for shared space",
                                   err_msg(SIZE_FORMAT " bytes.", cds_total));
   }
 
 #ifdef _LP64
-  // During dump time, we allocate 4GB (UnscaledClassSpaceMax) of space and split it up:
-  // + The upper 1 GB is used as the "temporary compressed class space" -- preload_classes()
-  //   will store Klasses into this space.
-  // + The lower 3 GB is used for the archive -- when preload_classes() is done,
-  //   ArchiveCompactor will copy the class metadata into this space, first the RW parts,
-  //   then the RO parts.
-
-  size_t max_archive_size = align_down(cds_total * 3 / 4, reserve_alignment);
-  ReservedSpace tmp_class_space = _shared_rs.last_part(max_archive_size);
-  CompressedClassSpaceSize = align_down(tmp_class_space.size(), reserve_alignment);
-  _shared_rs = _shared_rs.first_part(max_archive_size);
 
   if (UseCompressedClassPointers) {
-    // Set up compress class pointers.
-    CompressedKlassPointers::set_base((address)_shared_rs.base());
-    // Set narrow_klass_shift to be LogKlassAlignmentInBytes. This is consistent
-    // with AOT.
-    CompressedKlassPointers::set_shift(LogKlassAlignmentInBytes);
-    // Set the range of klass addresses to 4GB.
-    CompressedKlassPointers::set_range(cds_total);
+
+    assert(CompressedKlassPointers::is_valid_base((address)_shared_rs.base()), "Sanity");
+
+    // On 64-bit VM, if UseCompressedClassPointers=1, the compressed class space
+    //  must be allocated near the cds such as that the compressed Klass pointer
+    //  encoding can be used to en/decode pointers from both cds and ccs. Since
+    //  Metaspace cannot do this (it knows nothing about cds), we do it for
+    //  Metaspace here and pass it the space to use for ccs.
+    //
+    // We do this by reserving space for the ccs behind the archives. Note
+    //  however that ccs follows a different alignment
+    //  (Metaspace::reserve_alignment), so there may be a gap between ccs and
+    //  cds.
+    // We use a similar layout at runtime, see reserve_address_space_for_archives().
+    //
+    //                              +-- SharedBaseAddress (default = 0x800000000)
+    //                              v
+    // +-..---------+---------+ ... +----+----+----+--------+-----------------+
+    // |    Heap    | Archive |     | MC | RW | RO | [gap]  |    class space  |
+    // +-..---------+---------+ ... +----+----+----+--------+-----------------+
+    // |<--   MaxHeapSize  -->|     |<-- UnscaledClassSpaceMax = 4GB -->|
+    //
+    // Note: ccs must follow the archives, and the archives must start at the
+    //  encoding base. However, the exact placement of ccs does not matter as
+    //  long as it it resides in the encoding range of CompressedKlassPointers
+    //  and comes after the archive.
+    //
+    // We do this by splitting up the allocated 4G into 3G of archive space,
+    //  followed by 1G for the ccs:
+    // + The upper 1 GB is used as the "temporary compressed class space"
+    //   -- preload_classes() will store Klasses into this space.
+    // + The lower 3 GB is used for the archive -- when preload_classes()
+    //   is done, ArchiveCompactor will copy the class metadata into this
+    //   space, first the RW parts, then the RO parts.
+
+    // Starting address of ccs must be aligned to Metaspace::reserve_alignment()...
+    size_t class_space_size = align_down(_shared_rs.size() / 4, Metaspace::reserve_alignment());
+    address class_space_start = (address)align_down(_shared_rs.end() - class_space_size, Metaspace::reserve_alignment());
+    size_t archive_size = class_space_start - (address)_shared_rs.base();
+
+    ReservedSpace tmp_class_space = _shared_rs.last_part(archive_size);
+    _shared_rs = _shared_rs.first_part(archive_size);
+
+    // ... as does the size of ccs.
+    tmp_class_space = tmp_class_space.first_part(class_space_size);
+    CompressedClassSpaceSize = class_space_size;
+
+    // Let Metaspace initialize ccs
     Metaspace::initialize_class_space(tmp_class_space);
+
+    // and set up CompressedKlassPointers encoding.
+    CompressedKlassPointers::initialize((address)_shared_rs.base(), cds_total);
+
+    log_info(cds)("narrow_klass_base = " PTR_FORMAT ", narrow_klass_shift = %d",
+                  p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());
+
+    log_info(cds)("Allocated temporary class space: " SIZE_FORMAT " bytes at " PTR_FORMAT,
+                  CompressedClassSpaceSize, p2i(tmp_class_space.base()));
+
+    assert(_shared_rs.end() == tmp_class_space.base() &&
+           is_aligned(_shared_rs.base(), MetaspaceShared::reserved_space_alignment()) &&
+           is_aligned(tmp_class_space.base(), Metaspace::reserve_alignment()) &&
+           is_aligned(tmp_class_space.size(), Metaspace::reserve_alignment()), "Sanity");
   }
-  log_info(cds)("narrow_klass_base = " PTR_FORMAT ", narrow_klass_shift = %d",
-                p2i(CompressedKlassPointers::base()), CompressedKlassPointers::shift());
-
-  log_info(cds)("Allocated temporary class space: " SIZE_FORMAT " bytes at " PTR_FORMAT,
                 CompressedClassSpaceSize, p2i(tmp_class_space.base()));
 #endif
 
   init_shared_dump_space(&_mc_region);
   SharedBaseAddress = (size_t)_shared_rs.base();
@@ -1164,10 +1223,12 @@
   }
   static int compare_symbols_by_address(Symbol** a, Symbol** b) {
     if (a[0] < b[0]) {
       return -1;
     } else if (a[0] == b[0]) {
+      ResourceMark rm;
+      log_warning(cds)("Duplicated symbol %s unexpected", (*a)->as_C_string());
       return 0;
     } else {
       return 1;
     }
   }
@@ -2091,10 +2152,11 @@
 }
 
 void MetaspaceShared::initialize_runtime_shared_and_meta_spaces() {
   assert(UseSharedSpaces, "Must be called when UseSharedSpaces is enabled");
   MapArchiveResult result = MAP_ARCHIVE_OTHER_FAILURE;
+
   FileMapInfo* static_mapinfo = open_static_archive();
   FileMapInfo* dynamic_mapinfo = NULL;
 
   if (static_mapinfo != NULL) {
     dynamic_mapinfo = open_dynamic_archive();
@@ -2167,11 +2229,12 @@
 //  false = map at an alternative address picked by OS.
 MapArchiveResult MetaspaceShared::map_archives(FileMapInfo* static_mapinfo, FileMapInfo* dynamic_mapinfo,
                                                bool use_requested_addr) {
   PRODUCT_ONLY(if (ArchiveRelocationMode == 1 && use_requested_addr) {
       // For product build only -- this is for benchmarking the cost of doing relocation.
-      // For debug builds, the check is done in FileMapInfo::map_regions for better test coverage.
+      // For debug builds, the check is done below, after reserving the space, for better test coverage
+      // (see comment below).
       log_info(cds)("ArchiveRelocationMode == 1: always map archive(s) at an alternative address");
       return MAP_ARCHIVE_MMAP_FAILURE;
     });
 
   if (ArchiveRelocationMode == 2 && !use_requested_addr) {
@@ -2183,30 +2246,75 @@
     // Ensure that the OS won't be able to allocate new memory spaces between the two
     // archives, or else it would mess up the simple comparision in MetaspaceObj::is_shared().
     assert(static_mapinfo->mapping_end_offset() == dynamic_mapinfo->mapping_base_offset(), "no gap");
   }
 
-  ReservedSpace main_rs, archive_space_rs, class_space_rs;
+  ReservedSpace archive_space_rs, class_space_rs;
   MapArchiveResult result = MAP_ARCHIVE_OTHER_FAILURE;
   char* mapped_base_address = reserve_address_space_for_archives(static_mapinfo, dynamic_mapinfo,
-                                                                 use_requested_addr, main_rs, archive_space_rs,
+                                                                 use_requested_addr, archive_space_rs,
                                                                  class_space_rs);
   if (mapped_base_address == NULL) {
     result = MAP_ARCHIVE_MMAP_FAILURE;
   } else {
+
+#ifdef ASSERT
+    // Some sanity checks after reserving address spaces for archives
+    //  and class space.
+    assert(archive_space_rs.is_reserved(), "Sanity");
+    if (Metaspace::using_class_space()) {
+      // Class space must closely follow the archive space. Both spaces
+      //  must be aligned correctly.
+      assert(class_space_rs.is_reserved(),
+             "A class space should have been reserved");
+      assert(class_space_rs.base() >= archive_space_rs.end(),
+             "class space should follow the cds archive space");
+      assert(is_aligned(archive_space_rs.base(),
+                        MetaspaceShared::reserved_space_alignment()),
+             "Archive space misaligned");
+      assert(is_aligned(class_space_rs.base(),
+                        Metaspace::reserve_alignment()),
+             "class space misaligned");
+    }
+#endif // ASSERT
+
     log_debug(cds)("Reserved archive_space_rs     [" INTPTR_FORMAT " - " INTPTR_FORMAT "] (" SIZE_FORMAT ") bytes",
                    p2i(archive_space_rs.base()), p2i(archive_space_rs.end()), archive_space_rs.size());
     log_debug(cds)("Reserved class_space_rs [" INTPTR_FORMAT " - " INTPTR_FORMAT "] (" SIZE_FORMAT ") bytes",
                    p2i(class_space_rs.base()), p2i(class_space_rs.end()), class_space_rs.size());
+
+    if (MetaspaceShared::use_windows_memory_mapping()) {
+      // We have now reserved address space for the archives, and will map in
+      //  the archive files into this space.
+      //
+      // Special handling for Windows: on Windows we cannot map a file view
+      //  into an existing memory mapping. So, we unmap the address range we
+      //  just reserved again, which will make it available for mapping the
+      //  archives.
+      // Reserving this range has not been for naught however since it makes
+      //  us reasonably sure the address range is available.
+      //
+      // But still it may fail, since between unmapping the range and mapping
+      //  in the archive someone else may grab the address space. Therefore
+      //  there is a fallback in FileMap::map_region() where we just read in
+      //  the archive files sequentially instead of mapping it in. We couple
+      //  this with use_requested_addr, since we're going to patch all the
+      //  pointers anyway so there's no benefit to mmap.
+      if (use_requested_addr) {
+        log_info(cds)("Windows mmap workaround: releasing archive space.");
+        archive_space_rs.release();
+      }
+    }
     MapArchiveResult static_result = map_archive(static_mapinfo, mapped_base_address, archive_space_rs);
     MapArchiveResult dynamic_result = (static_result == MAP_ARCHIVE_SUCCESS) ?
                                      map_archive(dynamic_mapinfo, mapped_base_address, archive_space_rs) : MAP_ARCHIVE_OTHER_FAILURE;
 
     DEBUG_ONLY(if (ArchiveRelocationMode == 1 && use_requested_addr) {
-      // This is for simulating mmap failures at the requested address. In debug builds, we do it
-      // here (after all archives have possibly been mapped), so we can thoroughly test the code for
-      // failure handling (releasing all allocated resource, etc).
+      // This is for simulating mmap failures at the requested address. In
+      //  debug builds, we do it here (after all archives have possibly been
+      //  mapped), so we can thoroughly test the code for failure handling
+      //  (releasing all allocated resource, etc).
       log_info(cds)("ArchiveRelocationMode == 1: always map archive(s) at an alternative address");
       if (static_result == MAP_ARCHIVE_SUCCESS) {
         static_result = MAP_ARCHIVE_MMAP_FAILURE;
       }
       if (dynamic_result == MAP_ARCHIVE_SUCCESS) {
@@ -2235,125 +2343,207 @@
       result = MAP_ARCHIVE_MMAP_FAILURE;
     }
   }
 
   if (result == MAP_ARCHIVE_SUCCESS) {
-    if (!main_rs.is_reserved() && class_space_rs.is_reserved()) {
-      MemTracker::record_virtual_memory_type((address)class_space_rs.base(), mtClass);
-    }
     SharedBaseAddress = (size_t)mapped_base_address;
     LP64_ONLY({
         if (Metaspace::using_class_space()) {
-          assert(class_space_rs.is_reserved(), "must be");
-          char* cds_base = static_mapinfo->mapped_base();
-          Metaspace::allocate_metaspace_compressed_klass_ptrs(class_space_rs, NULL, (address)cds_base);
+          // Set up ccs in metaspace.
+          Metaspace::initialize_class_space(class_space_rs);
+
+          // Set up compressed Klass pointer encoding: the encoding range must
+          //  cover both archive and class space.
+          address cds_base = (address)static_mapinfo->mapped_base();
+          address ccs_end = (address)class_space_rs.end();
+          CompressedKlassPointers::initialize(cds_base, ccs_end - cds_base);
+
           // map_heap_regions() compares the current narrow oop and klass encodings
           // with the archived ones, so it must be done after all encodings are determined.
           static_mapinfo->map_heap_regions();
-          CompressedKlassPointers::set_range(CompressedClassSpaceSize);
         }
       });
   } else {
     unmap_archive(static_mapinfo);
     unmap_archive(dynamic_mapinfo);
-    release_reserved_spaces(main_rs, archive_space_rs, class_space_rs);
+    release_reserved_spaces(archive_space_rs, class_space_rs);
   }
 
   return result;
 }
 
+
+// This will reserve two address spaces suitable to house Klass structures, one
+//  for the cds archives (static archive and optionally dynamic archive) and
+//  optionally one move for ccs.
+//
+// Since both spaces must fall within the compressed class pointer encoding
+//  range, they are allocated close to each other.
+//
+// Space for archives will be reserved first, followed by a potential gap,
+//  followed by the space for ccs:
+//
+// +-- Base address             A        B                     End
+// |                            |        |                      |
+// v                            v        v                      v
+// +-------------+--------------+        +----------------------+
+// | static arc  | [dyn. arch]  | [gap]  | compr. class space   |
+// +-------------+--------------+        +----------------------+
+//
+// (The gap may result from different alignment requirements between metaspace
+//  and CDS)
+//
+// If UseCompressedClassPointers is disabled, only one address space will be
+//  reserved:
+//
+// +-- Base address             End
+// |                            |
+// v                            v
+// +-------------+--------------+
+// | static arc  | [dyn. arch]  |
+// +-------------+--------------+
+//
+// Base address: If use_archive_base_addr address is true, the Base address is
+//  determined by the address stored in the static archive. If
+//  use_archive_base_addr address is false, this base address is determined
+//  by the platform.
+//
+// If UseCompressedClassPointers=1, the range encompassing both spaces will be
+//  suitable to en/decode narrow Klass pointers: the base will be valid for
+//  encoding, the range [Base, End) not surpass KlassEncodingMetaspaceMax.
+//
+// Return:
+//
+// - On success:
+//    - archive_space_rs will be reserved and large enough to host static and
+//      if needed dynamic archive: [Base, A).
+//      archive_space_rs.base and size will be aligned to CDS reserve
+//      granularity.
+//    - class_space_rs: If UseCompressedClassPointers=1, class_space_rs will
+//      be reserved. Its start address will be aligned to metaspace reserve
+//      alignment, which may differ from CDS alignment. It will follow the cds
+//      archive space, close enough such that narrow class pointer encoding
+//      covers both spaces.
+//      If UseCompressedClassPointers=0, class_space_rs remains unreserved.
+// - On error: NULL is returned and the spaces remain unreserved.
 char* MetaspaceShared::reserve_address_space_for_archives(FileMapInfo* static_mapinfo,
                                                           FileMapInfo* dynamic_mapinfo,
-                                                          bool use_requested_addr,
-                                                          ReservedSpace& main_rs,
+                                                          bool use_archive_base_addr,
                                                           ReservedSpace& archive_space_rs,
                                                           ReservedSpace& class_space_rs) {
-  const bool use_klass_space = NOT_LP64(false) LP64_ONLY(Metaspace::using_class_space());
-  const size_t class_space_size = NOT_LP64(0) LP64_ONLY(Metaspace::compressed_class_space_size());
-
-  if (use_klass_space) {
-    assert(class_space_size > 0, "CompressedClassSpaceSize must have been validated");
-  }
-  if (use_requested_addr && !is_aligned(static_mapinfo->requested_base_address(), reserved_space_alignment())) {
-    return NULL;
+
+  address const base_address = (address) (use_archive_base_addr ? static_mapinfo->requested_base_address() : NULL);
   }
 
   // Size and requested location of the archive_space_rs (for both static and dynamic archives)
-  size_t base_offset = static_mapinfo->mapping_base_offset();
-  size_t end_offset  = (dynamic_mapinfo == NULL) ? static_mapinfo->mapping_end_offset() : dynamic_mapinfo->mapping_end_offset();
-  assert(base_offset == 0, "must be");
-  assert(is_aligned(end_offset,  os::vm_allocation_granularity()), "must be");
-  assert(is_aligned(base_offset, os::vm_allocation_granularity()), "must be");
-
-  // In case reserved_space_alignment() != os::vm_allocation_granularity()
-  assert((size_t)os::vm_allocation_granularity() <= reserved_space_alignment(), "must be");
-  end_offset = align_up(end_offset, reserved_space_alignment());
-
-  size_t archive_space_size = end_offset - base_offset;
-
-  // Special handling for Windows because it cannot mmap into a reserved space:
-  //    use_requested_addr: We just map each region individually, and give up if any one of them fails.
-  //   !use_requested_addr: We reserve the space first, and then os::read in all the regions (instead of mmap).
-  //                        We're going to patch all the pointers anyway so there's no benefit for mmap.
-
-  if (use_requested_addr) {
-    char* archive_space_base = static_mapinfo->requested_base_address() + base_offset;
-    char* archive_space_end  = archive_space_base + archive_space_size;
-    if (!MetaspaceShared::use_windows_memory_mapping()) {
-      archive_space_rs = reserve_shared_space(archive_space_size, archive_space_base);
-      if (!archive_space_rs.is_reserved()) {
-        return NULL;
-      }
-    }
-    if (use_klass_space) {
-      // Make sure we can map the klass space immediately following the archive_space space
-      // Don't call reserve_shared_space here as that may try to enforce platform-specific
-      // alignment rules which only apply to the archive base address
-      char* class_space_base = archive_space_end;
-      class_space_rs = ReservedSpace(class_space_size, reserved_space_alignment(),
-                                     false /* large_pages */, class_space_base);
-      if (!class_space_rs.is_reserved()) {
-        return NULL;
-      }
-    }
-    return static_mapinfo->requested_base_address();
-  } else {
-    if (use_klass_space) {
-      main_rs = reserve_shared_space(archive_space_size + class_space_size);
-      if (main_rs.is_reserved()) {
-        archive_space_rs = main_rs.first_part(archive_space_size, reserved_space_alignment(), /*split=*/true);
-        class_space_rs = main_rs.last_part(archive_space_size);
-      }
-    } else {
-      main_rs = reserve_shared_space(archive_space_size);
-      archive_space_rs = main_rs;
+  assert(static_mapinfo->mapping_base_offset() == 0, "Must be");
+  size_t archive_end_offset  = (dynamic_mapinfo == NULL) ? static_mapinfo->mapping_end_offset() : dynamic_mapinfo->mapping_end_offset();
+  size_t archive_space_size = align_up(archive_end_offset, archive_space_alignment);
+
+  // If a base address is given, it must have valid alignment and be suitable as encoding base.
+  if (base_address != NULL) {
+    assert(is_aligned(base_address, archive_space_alignment),
+           "Archive base address invalid: " PTR_FORMAT ".", p2i(base_address));
+    if (Metaspace::using_class_space()) {
+      assert(CompressedKlassPointers::is_valid_base(base_address),
+             "Archive base address invalid: " PTR_FORMAT ".", p2i(base_address));
     }
+  }
+
+  if (!Metaspace::using_class_space()) {
+    // Get the simple case out of the way first:
+    // no compressed class space, simple allocation.
+    archive_space_rs = ReservedSpace(archive_space_size, archive_space_alignment,
+                                     false /* bool large */, (char*)base_address);
     if (archive_space_rs.is_reserved()) {
+      assert(base_address == NULL ||
+             (address)archive_space_rs.base() == base_address, "Sanity");
       return archive_space_rs.base();
-    } else {
-      return NULL;
+    }
+    return NULL;
+  }
+
+#ifdef _LP64
+
+  // Complex case: two spaces adjacent to each other, both to be addressable
+  //  with narrow class pointers.
+  // We reserve the whole range spanning both spaces, then split that range up.
+
+  const size_t class_space_alignment = Metaspace::reserve_alignment();
+
+  // To simplify matters, lets assume that metaspace alignment will always be
+  //  equal or a multiple of archive alignment.
+  assert(is_power_of_2(class_space_alignment) &&
+                       is_power_of_2(archive_space_alignment) &&
+                       class_space_alignment >= archive_space_alignment,
+                       "Sanity");
+
+  const size_t class_space_size = CompressedClassSpaceSize;
+  assert(CompressedClassSpaceSize > 0 &&
+         is_aligned(CompressedClassSpaceSize, class_space_alignment),
+         "CompressedClassSpaceSize malformed: "
+         SIZE_FORMAT, CompressedClassSpaceSize);
+
+  const size_t ccs_begin_offset = align_up(archive_space_size,
+                                           class_space_alignment);
+  const size_t gap_size = ccs_begin_offset - archive_space_size;
+
+  const size_t total_range_size =
+      align_up(archive_space_size + gap_size + class_space_size,
+               os::vm_allocation_granularity());
+
+  ReservedSpace total_rs;
+  if (base_address != NULL) {
+    // Reserve at the given archive base address, or not at all.
+    total_rs = ReservedSpace(total_range_size, archive_space_alignment,
+                             false /* bool large */, (char*) base_address);
+  } else {
+    // Reserve at any address, but leave it up to the platform to choose a good one.
     }
   }
+
+  if (!total_rs.is_reserved()) {
+    return NULL;
+  }
+
+  // Paranoid checks:
+  assert(base_address == NULL || (address)total_rs.base() == base_address,
+         "Sanity (" PTR_FORMAT " vs " PTR_FORMAT ")", p2i(base_address), p2i(total_rs.base()));
+  assert(is_aligned(total_rs.base(), archive_space_alignment), "Sanity");
+  assert(total_rs.size() == total_range_size, "Sanity");
+  assert(CompressedKlassPointers::is_valid_base((address)total_rs.base()), "Sanity");
+
+  // Now split up the space into ccs and cds archive. For simplicity, just leave
+  //  the gap reserved at the end of the archive space.
+  archive_space_rs = total_rs.first_part(ccs_begin_offset,
+                                         (size_t)os::vm_allocation_granularity(),
+                                         /*split=*/true);
+  class_space_rs = total_rs.last_part(ccs_begin_offset);
+
+  assert(is_aligned(archive_space_rs.base(), archive_space_alignment), "Sanity");
+  assert(is_aligned(archive_space_rs.size(), archive_space_alignment), "Sanity");
+  assert(is_aligned(class_space_rs.base(), class_space_alignment), "Sanity");
+  assert(is_aligned(class_space_rs.size(), class_space_alignment), "Sanity");
+
+  return archive_space_rs.base();
+
+#else
+  ShouldNotReachHere();
+  return NULL;
+#endif
+
 }
 
-void MetaspaceShared::release_reserved_spaces(ReservedSpace& main_rs,
-                                              ReservedSpace& archive_space_rs,
+void MetaspaceShared::release_reserved_spaces(ReservedSpace& archive_space_rs,
                                               ReservedSpace& class_space_rs) {
-  if (main_rs.is_reserved()) {
-    assert(main_rs.contains(archive_space_rs.base()), "must be");
-    assert(main_rs.contains(class_space_rs.base()), "must be");
-    log_debug(cds)("Released shared space (archive+classes) " INTPTR_FORMAT, p2i(main_rs.base()));
-    main_rs.release();
-  } else {
-    if (archive_space_rs.is_reserved()) {
-      log_debug(cds)("Released shared space (archive) " INTPTR_FORMAT, p2i(archive_space_rs.base()));
-      archive_space_rs.release();
-    }
-    if (class_space_rs.is_reserved()) {
-      log_debug(cds)("Released shared space (classes) " INTPTR_FORMAT, p2i(class_space_rs.base()));
-      class_space_rs.release();
-    }
+  if (archive_space_rs.is_reserved()) {
+    log_debug(cds)("Released shared space (archive) " INTPTR_FORMAT, p2i(archive_space_rs.base()));
+    archive_space_rs.release();
+  }
+  if (class_space_rs.is_reserved()) {
+    log_debug(cds)("Released shared space (classes) " INTPTR_FORMAT, p2i(class_space_rs.base()));
+    class_space_rs.release();
   }
 }
 
 static int archive_regions[]  = {MetaspaceShared::mc,
                                  MetaspaceShared::rw,
@@ -2494,5 +2684,33 @@
 // Arguments::default_SharedBaseAddress() without runtime relocation.
 intx MetaspaceShared::final_delta() {
   return intx(Arguments::default_SharedBaseAddress())  // We want the archive to be mapped to here at runtime
        - intx(SharedBaseAddress);                      // .. but the archive is mapped at here at dump time
 }
+
+void MetaspaceShared::print_on(outputStream* st) {
+  if (UseSharedSpaces || DumpSharedSpaces) {
+    st->print("CDS archive(s) mapped at: ");
+    address base;
+    address top;
+    if (UseSharedSpaces) { // Runtime
+      base = (address)MetaspaceObj::shared_metaspace_base();
+      address static_top = (address)_shared_metaspace_static_top;
+      top = (address)MetaspaceObj::shared_metaspace_top();
+      st->print("[" PTR_FORMAT "-" PTR_FORMAT "-" PTR_FORMAT "), ", p2i(base), p2i(static_top), p2i(top));
+    } else if (DumpSharedSpaces) { // Dump Time
+      base = (address)_shared_rs.base();
+      top = (address)_shared_rs.end();
+      st->print("[" PTR_FORMAT "-" PTR_FORMAT "), ", p2i(base), p2i(top));
+    }
+    st->print("size " SIZE_FORMAT ", ", top - base);
+    st->print("SharedBaseAddress: " PTR_FORMAT ", ArchiveRelocationMode: %d.", SharedBaseAddress, (int)ArchiveRelocationMode);
+  } else {
+    st->print("CDS disabled.");
+  }
+  st->cr();
+}
+
+
+
+
+
diff a/src/hotspot/share/memory/universe.cpp b/src/hotspot/share/memory/universe.cpp
--- a/src/hotspot/share/memory/universe.cpp
+++ b/src/hotspot/share/memory/universe.cpp
@@ -737,16 +737,12 @@
 }
 
 jint Universe::initialize_heap() {
   assert(_collectedHeap == NULL, "Heap already created");
   _collectedHeap = GCConfig::arguments()->create_heap();
-  jint status = _collectedHeap->initialize();
-
-  if (status == JNI_OK) {
-    log_info(gc)("Using %s", _collectedHeap->name());
-  }
-
+
+  log_info(gc)("Using %s", _collectedHeap->name());
   return status;
 }
 
 void Universe::initialize_tlab() {
   ThreadLocalAllocBuffer::set_max_size(Universe::heap()->max_tlab_size());
diff a/src/hotspot/share/oops/instanceKlass.cpp b/src/hotspot/share/oops/instanceKlass.cpp
--- a/src/hotspot/share/oops/instanceKlass.cpp
+++ b/src/hotspot/share/oops/instanceKlass.cpp
@@ -3230,13 +3230,13 @@
 // On-stack replacement stuff
 void InstanceKlass::add_osr_nmethod(nmethod* n) {
   assert_lock_strong(CompiledMethod_lock);
 #ifndef PRODUCT
   if (TieredCompilation) {
-      nmethod * prev = lookup_osr_nmethod(n->method(), n->osr_entry_bci(), n->comp_level(), true);
-      assert(prev == NULL || !prev->is_in_use(),
-      "redundunt OSR recompilation detected. memory leak in CodeCache!");
+    nmethod* prev = lookup_osr_nmethod(n->method(), n->osr_entry_bci(), n->comp_level(), true);
+    assert(prev == NULL || !prev->is_in_use() COMPILER2_PRESENT(|| StressRecompilation),
+           "redundant OSR recompilation detected. memory leak in CodeCache!");
   }
 #endif
   // only one compilation can be active
   {
     assert(n->is_osr_method(), "wrong kind of nmethod");
diff a/src/hotspot/share/oops/klass.cpp b/src/hotspot/share/oops/klass.cpp
--- a/src/hotspot/share/oops/klass.cpp
+++ b/src/hotspot/share/oops/klass.cpp
@@ -772,10 +772,11 @@
   st->cr();
 }
 
 #define BULLET  " - "
 
+// Caller needs ResourceMark
 void Klass::oop_print_on(oop obj, outputStream* st) {
   // print title
   st->print_cr("%s ", internal_name());
   obj->print_address_on(st);
 
diff a/src/hotspot/share/oops/oopsHierarchy.hpp b/src/hotspot/share/oops/oopsHierarchy.hpp
--- a/src/hotspot/share/oops/oopsHierarchy.hpp
+++ b/src/hotspot/share/oops/oopsHierarchy.hpp
@@ -79,40 +79,32 @@
   oopDesc* _o;
 
   void register_oop();
   void unregister_oop();
 
-public:
-  void set_obj(const void* p)         {
-    _o = (oopDesc*)p;
+  void register_if_checking() {
     if (CheckUnhandledOops) register_oop();
   }
 
-  oop()                               { set_obj(NULL); }
-  oop(const oop& o)                   { set_obj(o.obj()); }
-  oop(const volatile oop& o)          { set_obj(o.obj()); }
-  oop(const void* p)                  { set_obj(p); }
-  ~oop()                              {
+public:
+  oop()              : _o(NULL)        { register_if_checking(); }
+  oop(const oop& o)  : _o(o._o)        { register_if_checking(); }
+  oop(const void* p) : _o((oopDesc*)p) { register_if_checking(); }
+  ~oop() {
     if (CheckUnhandledOops) unregister_oop();
   }
 
-  oopDesc* obj()  const volatile      { return _o; }
+  oopDesc* obj() const                 { return _o; }
+  oopDesc* operator->() const          { return _o; }
+  operator oopDesc* () const           { return _o; }
 
-  // General access
-  oopDesc*  operator->() const        { return obj(); }
-  bool operator==(const oop o) const  { return obj() == o.obj(); }
-  bool operator==(void *p) const      { return obj() == p; }
-  bool operator!=(const volatile oop o) const { return obj() != o.obj(); }
-  bool operator!=(void *p) const      { return obj() != p; }
+  bool operator==(const oop& o) const  { return _o == o._o; }
+  bool operator==(void *p) const       { return _o == p; }
+  bool operator!=(const oop& o) const  { return _o != o._o; }
+  bool operator!=(void *p) const       { return _o != p; }
 
-  // Assignment
-  oop& operator=(const oop& o)                            { _o = o.obj(); return *this; }
-  volatile oop& operator=(const oop& o) volatile          { _o = o.obj(); return *this; }
-  volatile oop& operator=(const volatile oop& o) volatile { _o = o.obj(); return *this; }
-
-  // Explict user conversions
-  operator oopDesc* () const volatile { return obj(); }
+  oop& operator=(const oop& o)        { _o = o._o; return *this; }
 };
 
 template<>
 struct PrimitiveConversions::Translate<oop> : public TrueType {
   typedef oop Value;
@@ -127,27 +119,18 @@
    class type##Oop : public oop {                                          \
      public:                                                               \
        type##Oop() : oop() {}                                              \
        type##Oop(const type##Oop& o) : oop(o) {}                           \
        type##Oop(const oop& o) : oop(o) {}                                 \
-       type##Oop(const volatile oop& o) : oop(o) {}                        \
        type##Oop(const void* p) : oop(p) {}                                \
        operator type##OopDesc* () const { return (type##OopDesc*)obj(); }  \
        type##OopDesc* operator->() const {                                 \
             return (type##OopDesc*)obj();                                  \
        }                                                                   \
        type##Oop& operator=(const type##Oop& o) {                          \
             oop::operator=(o);                                             \
             return *this;                                                  \
-       }                                                                   \
-       volatile type##Oop& operator=(const type##Oop& o) volatile {        \
-            (void)const_cast<oop&>(oop::operator=(o));                     \
-            return *this;                                                  \
-       }                                                                   \
-       volatile type##Oop& operator=(const volatile type##Oop& o) volatile {\
-            (void)const_cast<oop&>(oop::operator=(o));                     \
-            return *this;                                                  \
        }                                                                   \
    };                                                                      \
                                                                            \
    template<>                                                              \
    struct PrimitiveConversions::Translate<type##Oop> : public TrueType {   \
diff a/src/hotspot/share/opto/addnode.cpp b/src/hotspot/share/opto/addnode.cpp
--- a/src/hotspot/share/opto/addnode.cpp
+++ b/src/hotspot/share/opto/addnode.cpp
@@ -27,10 +27,11 @@
 #include "opto/addnode.hpp"
 #include "opto/castnode.hpp"
 #include "opto/cfgnode.hpp"
 #include "opto/connode.hpp"
 #include "opto/machnode.hpp"
+#include "opto/movenode.hpp"
 #include "opto/mulnode.hpp"
 #include "opto/phaseX.hpp"
 #include "opto/subnode.hpp"
 
 // Portions of code courtesy of Clifford Click
@@ -842,10 +843,99 @@
 
   // Otherwise just OR them bits.
   return TypeLong::make( r0->get_con() ^ r1->get_con() );
 }
 
+
+Node* MaxNode::build_min_max(Node* a, Node* b, bool is_max, bool is_unsigned, const Type* t, PhaseGVN& gvn) {
+  bool is_int = gvn.type(a)->isa_int();
+  assert(is_int || gvn.type(a)->isa_long(), "int or long inputs");
+  assert(is_int == (gvn.type(b)->isa_int() != NULL), "inconsistent inputs");
+  if (!is_unsigned) {
+    if (is_max) {
+      if (is_int) {
+        Node* res =  gvn.transform(new MaxINode(a, b));
+        assert(gvn.type(res)->is_int()->_lo >= t->is_int()->_lo && gvn.type(res)->is_int()->_hi <= t->is_int()->_hi, "type doesn't match");
+        return res;
+      } else {
+        Node* cmp = gvn.transform(new CmpLNode(a, b));
+        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+        return gvn.transform(new CMoveLNode(bol, a, b, t->is_long()));
+      }
+    } else {
+      if (is_int) {
+        Node* res =  gvn.transform(new MinINode(a, b));
+        assert(gvn.type(res)->is_int()->_lo >= t->is_int()->_lo && gvn.type(res)->is_int()->_hi <= t->is_int()->_hi, "type doesn't match");
+        return res;
+      } else {
+        Node* cmp = gvn.transform(new CmpLNode(b, a));
+        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+        return gvn.transform(new CMoveLNode(bol, a, b, t->is_long()));
+      }
+    }
+  } else {
+    if (is_max) {
+      if (is_int) {
+        Node* cmp = gvn.transform(new CmpUNode(a, b));
+        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+        return gvn.transform(new CMoveINode(bol, a, b, t->is_int()));
+      } else {
+        Node* cmp = gvn.transform(new CmpULNode(a, b));
+        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+        return gvn.transform(new CMoveLNode(bol, a, b, t->is_long()));
+      }
+    } else {
+      if (is_int) {
+        Node* cmp = gvn.transform(new CmpUNode(b, a));
+        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+        return gvn.transform(new CMoveINode(bol, a, b, t->is_int()));
+      } else {
+        Node* cmp = gvn.transform(new CmpULNode(b, a));
+        Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+        return gvn.transform(new CMoveLNode(bol, a, b, t->is_long()));
+      }
+    }
+  }
+}
+
+Node* MaxNode::build_min_max_diff_with_zero(Node* a, Node* b, bool is_max, const Type* t, PhaseGVN& gvn) {
+  bool is_int = gvn.type(a)->isa_int();
+  assert(is_int || gvn.type(a)->isa_long(), "int or long inputs");
+  assert(is_int == (gvn.type(b)->isa_int() != NULL), "inconsistent inputs");
+  Node* zero = NULL;
+  if (is_int) {
+    zero = gvn.intcon(0);
+  } else {
+    zero = gvn.longcon(0);
+  }
+  if (is_max) {
+    if (is_int) {
+      Node* cmp = gvn.transform(new CmpINode(a, b));
+      Node* sub = gvn.transform(new SubINode(a, b));
+      Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+      return gvn.transform(new CMoveINode(bol, sub, zero, t->is_int()));
+    } else {
+      Node* cmp = gvn.transform(new CmpLNode(a, b));
+      Node* sub = gvn.transform(new SubLNode(a, b));
+      Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+      return gvn.transform(new CMoveLNode(bol, sub, zero, t->is_long()));
+    }
+  } else {
+    if (is_int) {
+      Node* cmp = gvn.transform(new CmpINode(b, a));
+      Node* sub = gvn.transform(new SubINode(a, b));
+      Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+      return gvn.transform(new CMoveINode(bol, sub, zero, t->is_int()));
+    } else {
+      Node* cmp = gvn.transform(new CmpLNode(b, a));
+      Node* sub = gvn.transform(new SubLNode(a, b));
+      Node* bol = gvn.transform(new BoolNode(cmp, BoolTest::lt));
+      return gvn.transform(new CMoveLNode(bol, sub, zero, t->is_long()));
+    }
+  }
+}
+
 //=============================================================================
 //------------------------------add_ring---------------------------------------
 // Supplied function returns the sum of the inputs.
 const Type *MaxINode::add_ring( const Type *t0, const Type *t1 ) const {
   const TypeInt *r0 = t0->is_int(); // Handy access
diff a/src/hotspot/share/opto/c2_globals.hpp b/src/hotspot/share/opto/c2_globals.hpp
--- a/src/hotspot/share/opto/c2_globals.hpp
+++ b/src/hotspot/share/opto/c2_globals.hpp
@@ -359,13 +359,10 @@
                                                                             \
   /* Set BranchOnRegister == false. See 4965987. */                         \
   product(bool, BranchOnRegister, false,                                    \
           "Use Sparc V9 branch-on-register opcodes")                        \
                                                                             \
-  develop(bool, SparcV9RegsHiBitsZero, true,                                \
-          "Assume Sparc V9 I&L registers on V8+ systems are zero-extended") \
-                                                                            \
   product(bool, UseRDPCForConstantTableBase, false,                         \
           "Use Sparc RDPC instruction for the constant table base.")        \
                                                                             \
   notproduct(bool, PrintIdealGraph, false,                                  \
           "Print ideal graph to XML file / network interface. "             \
diff a/src/hotspot/share/opto/c2compiler.cpp b/src/hotspot/share/opto/c2compiler.cpp
--- a/src/hotspot/share/opto/c2compiler.cpp
+++ b/src/hotspot/share/opto/c2compiler.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -82,10 +82,11 @@
   HandleMark handle_mark(thread);
   return OptoRuntime::generate(thread->env());
 }
 
 void C2Compiler::initialize() {
+  assert(!is_c1_or_interpreter_only(), "C2 compiler is launched, it's not c1/interpreter only mode");
   // The first compiler thread that gets here will initialize the
   // small amount of global state (and runtime stubs) that C2 needs.
 
   // There is a race possible once at startup and then we're fine
 
diff a/src/hotspot/share/opto/chaitin.cpp b/src/hotspot/share/opto/chaitin.cpp
--- a/src/hotspot/share/opto/chaitin.cpp
+++ b/src/hotspot/share/opto/chaitin.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -867,24 +867,20 @@
           // IA64     1     1     1          1    1         50          41
           // SPARC    2     2     2          2    2         48 (24)     52 (26)
           // SPARCV9  2     2     2          2    2         48 (24)     52 (26)
           // AMD64    1     1     1          1    1         14          15
           // -----------------------------------------------------
-#if defined(SPARC)
-          lrg.set_reg_pressure(2);  // use for v9 as well
-#else
-          lrg.set_reg_pressure(1);  // normally one value per register
 #endif
           if( n_type->isa_oop_ptr() ) {
             lrg._is_oop = 1;
           }
           break;
         case Op_RegL:           // Check for long or double
         case Op_RegD:
           lrg.set_num_regs(2);
           // Define platform specific register pressure
-#if defined(SPARC) || defined(ARM32)
+#if defined(ARM32)
           lrg.set_reg_pressure(2);
 #elif defined(IA32)
           if( ireg == Op_RegL ) {
             lrg.set_reg_pressure(2);
           } else {
@@ -907,14 +903,10 @@
         case Op_RegI:
         case Op_RegN:
         case Op_RegFlags:
         case 0:                 // not an ideal register
           lrg.set_num_regs(1);
-#ifdef SPARC
-          lrg.set_reg_pressure(2);
-#else
-          lrg.set_reg_pressure(1);
 #endif
           break;
         case Op_VecS:
           assert(Matcher::vector_size_supported(T_BYTE,4), "sanity");
           assert(RegMask::num_registers(Op_VecS) == RegMask::SlotsPerVecS, "sanity");
@@ -1484,14 +1476,10 @@
       lrg->clear_to_sets();
     }
 
     // Check if a color is available and if so pick the color
     OptoReg::Name reg = choose_color( *lrg, chunk );
-#ifdef SPARC
-    debug_only(lrg->compute_set_mask_size());
-    assert(lrg->num_regs() < 2 || lrg->is_bound() || is_even(reg-1), "allocate all doubles aligned");
-#endif
 
     //---------------
     // If we fail to color and the AllStack flag is set, trigger
     // a chunk-rollover event
     if(!OptoReg::is_valid(OptoReg::add(reg,-chunk)) && is_allstack) {
diff a/src/hotspot/share/opto/generateOptoStub.cpp b/src/hotspot/share/opto/generateOptoStub.cpp
--- a/src/hotspot/share/opto/generateOptoStub.cpp
+++ b/src/hotspot/share/opto/generateOptoStub.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1999, 2016, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1999, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -90,25 +90,18 @@
 
   Node* adr_last_Java_pc = basic_plus_adr(top(),
                                             thread,
                                             in_bytes(JavaThread::frame_anchor_offset()) +
                                             in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
-#if defined(SPARC)
-  Node* adr_flags = basic_plus_adr(top(),
-                                   thread,
-                                   in_bytes(JavaThread::frame_anchor_offset()) +
-                                   in_bytes(JavaFrameAnchor::flags_offset()));
-#endif /* defined(SPARC) */
-
 
   // Drop in the last_Java_sp.  last_Java_fp is not touched.
   // Always do this after the other "last_Java_frame" fields are set since
   // as soon as last_Java_sp != NULL the has_last_Java_frame is true and
   // users will look at the other fields.
   //
   Node *adr_sp = basic_plus_adr(top(), thread, in_bytes(JavaThread::last_Java_sp_offset()));
-  Node *last_sp = basic_plus_adr(top(), frameptr(), (intptr_t) STACK_BIAS);
+  Node *last_sp = frameptr();
   store_to_memory(NULL, adr_sp, last_sp, T_ADDRESS, NoAlias, MemNode::unordered);
 
   // Set _thread_in_native
   // The order of stores into TLS is critical!  Setting _thread_in_native MUST
   // be last, because a GC is allowed at any time after setting it and the GC
@@ -227,15 +220,12 @@
 
   //-----------------------------
 
   // Clear last_Java_sp
   store_to_memory(NULL, adr_sp, null(), T_ADDRESS, NoAlias, MemNode::unordered);
-  // Clear last_Java_pc and (optionally)_flags
+  // Clear last_Java_pc
   store_to_memory(NULL, adr_last_Java_pc, null(), T_ADDRESS, NoAlias, MemNode::unordered);
-#if defined(SPARC)
-  store_to_memory(NULL, adr_flags, intcon(0), T_INT, NoAlias, MemNode::unordered);
-#endif /* defined(SPARC) */
 #if (defined(IA64) && !defined(AIX))
   Node* adr_last_Java_fp = basic_plus_adr(top(), thread, in_bytes(JavaThread::last_Java_fp_offset()));
   store_to_memory(NULL, adr_last_Java_fp, null(), T_ADDRESS, NoAlias, MemNode::unordered);
 #endif
 
diff a/src/hotspot/share/opto/loopnode.hpp b/src/hotspot/share/opto/loopnode.hpp
--- a/src/hotspot/share/opto/loopnode.hpp
+++ b/src/hotspot/share/opto/loopnode.hpp
@@ -1031,13 +1031,20 @@
 
   // True if the method has at least 1 irreducible loop
   bool _has_irreducible_loops;
 
   // Per-Node transform
-  virtual Node* transform(Node* n) { return 0; }
+  virtual Node* transform(Node* n) { return NULL; }
+
+  Node* loop_exit_control(Node* x, IdealLoopTree* loop);
+  Node* loop_exit_test(Node* back_control, IdealLoopTree* loop, Node*& incr, Node*& limit, BoolTest::mask& bt, float& cl_prob);
+  Node* loop_iv_incr(Node* incr, Node* x, IdealLoopTree* loop, Node*& phi_incr);
+  Node* loop_iv_stride(Node* incr, IdealLoopTree* loop, Node*& xphi);
+  PhiNode* loop_iv_phi(Node* xphi, Node* phi_incr, Node* x, IdealLoopTree* loop);
 
   bool is_counted_loop(Node* n, IdealLoopTree* &loop);
+  IdealLoopTree* insert_outer_loop(IdealLoopTree* loop, LoopNode* outer_l, Node* outer_ift);
   IdealLoopTree* create_outer_strip_mined_loop(BoolNode *test, Node *cmp, Node *init_control,
                                                IdealLoopTree* loop, float cl_prob, float le_fcnt,
                                                Node*& entry_control, Node*& iffalse);
 
   Node* exact_limit( IdealLoopTree *loop );
@@ -1137,11 +1144,11 @@
 
   // Create a new if above the uncommon_trap_if_pattern for the predicate to be promoted
   ProjNode* create_new_if_for_predicate(ProjNode* cont_proj, Node* new_entry, Deoptimization::DeoptReason reason,
                                         int opcode, bool if_cont_is_true_proj = true);
 
-  void register_control(Node* n, IdealLoopTree *loop, Node* pred);
+  void register_control(Node* n, IdealLoopTree *loop, Node* pred, bool update_body = true);
 
   static Node* skip_all_loop_predicates(Node* entry);
   static Node* skip_loop_predicates(Node* entry);
 
   // Find a good location to insert a predicate
diff a/src/hotspot/share/opto/loopopts.cpp b/src/hotspot/share/opto/loopopts.cpp
--- a/src/hotspot/share/opto/loopopts.cpp
+++ b/src/hotspot/share/opto/loopopts.cpp
@@ -2273,20 +2273,26 @@
           uint uses_found = 0;
           if( useuse->in(0) == use ) {
             useuse->set_req(0, r);
             uses_found++;
             if( useuse->is_CFG() ) {
-              assert( dom_depth(useuse) > dd_r, "" );
+              // This is not a dom_depth > dd_r because when new
+              // control flow is constructed by a loop opt, a node and
+              // its dominator can end up at the same dom_depth
+              assert(dom_depth(useuse) >= dd_r, "");
               set_idom(useuse, r, dom_depth(useuse));
             }
           }
           for( uint k = 1; k < useuse->req(); k++ ) {
             if( useuse->in(k) == use ) {
               useuse->set_req(k, r);
               uses_found++;
               if (useuse->is_Loop() && k == LoopNode::EntryControl) {
-                assert(dom_depth(useuse) > dd_r , "");
+                // This is not a dom_depth > dd_r because when new
+                // control flow is constructed by a loop opt, a node
+                // and its dominator can end up at the same dom_depth
+                assert(dom_depth(useuse) >= dd_r , "");
                 set_idom(useuse, r, dom_depth(useuse));
               }
             }
           }
           l -= uses_found;    // we deleted 1 or more copies of this edge
diff a/src/hotspot/share/opto/output.cpp b/src/hotspot/share/opto/output.cpp
--- a/src/hotspot/share/opto/output.cpp
+++ b/src/hotspot/share/opto/output.cpp
@@ -846,18 +846,10 @@
       // jsr/ret return address which must be restored into a the full
       // width 64-bit stack slot.
       array->append(new_loc_value( C->regalloc(), regnum, Location::lng ));
     }
 #else //_LP64
-#ifdef SPARC
-    if (t->base() == Type::Long && OptoReg::is_reg(regnum)) {
-      // For SPARC we have to swap high and low words for
-      // long values stored in a single-register (g0-g7).
-      array->append(new_loc_value( C->regalloc(),              regnum   , Location::normal ));
-      array->append(new_loc_value( C->regalloc(), OptoReg::add(regnum,1), Location::normal ));
-    } else
-#endif //SPARC
     if( t->base() == Type::DoubleBot || t->base() == Type::DoubleCon || t->base() == Type::Long ) {
       // Repack the double/long as two jints.
       // The convention the interpreter uses is that the second local
       // holds the first raw word of the native double representation.
       // This is actually reasonable, since locals and stack arrays
diff a/src/hotspot/share/opto/subnode.hpp b/src/hotspot/share/opto/subnode.hpp
--- a/src/hotspot/share/opto/subnode.hpp
+++ b/src/hotspot/share/opto/subnode.hpp
@@ -309,11 +309,11 @@
   // Try to optimize signed integer comparison
   Node* fold_cmpI(PhaseGVN* phase, SubNode* cmp, Node* cmp1, int cmp_op,
                   int cmp1_op, const TypeInt* cmp2_type);
 public:
   const BoolTest _test;
-  BoolNode( Node *cc, BoolTest::mask t): Node(0,cc), _test(t) {
+  BoolNode(Node *cc, BoolTest::mask t): Node(NULL,cc), _test(t) {
     init_class_id(Class_Bool);
   }
   // Convert an arbitrary int value to a Bool or other suitable predicate.
   static Node* make_predicate(Node* test_value, PhaseGVN* phase);
   // Convert self back to an integer value.
diff a/src/hotspot/share/opto/type.cpp b/src/hotspot/share/opto/type.cpp
--- a/src/hotspot/share/opto/type.cpp
+++ b/src/hotspot/share/opto/type.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -107,17 +107,11 @@
   { Bad,             T_NARROWOOP,  "narrowoop:",    false, Op_RegN,              relocInfo::none          },  // NarrowOop
   { Bad,             T_NARROWKLASS,"narrowklass:",  false, Op_RegN,              relocInfo::none          },  // NarrowKlass
   { Bad,             T_ILLEGAL,    "tuple:",        false, Node::NotAMachineReg, relocInfo::none          },  // Tuple
   { Bad,             T_ARRAY,      "array:",        false, Node::NotAMachineReg, relocInfo::none          },  // Array
 
-#ifdef SPARC
-  { Bad,             T_ILLEGAL,    "vectors:",      false, 0,                    relocInfo::none          },  // VectorS
-  { Bad,             T_ILLEGAL,    "vectord:",      false, Op_RegD,              relocInfo::none          },  // VectorD
-  { Bad,             T_ILLEGAL,    "vectorx:",      false, 0,                    relocInfo::none          },  // VectorX
-  { Bad,             T_ILLEGAL,    "vectory:",      false, 0,                    relocInfo::none          },  // VectorY
-  { Bad,             T_ILLEGAL,    "vectorz:",      false, 0,                    relocInfo::none          },  // VectorZ
-#elif defined(PPC64)
+#if defined(PPC64)
   { Bad,             T_ILLEGAL,    "vectors:",      false, 0,                    relocInfo::none          },  // VectorS
   { Bad,             T_ILLEGAL,    "vectord:",      false, Op_RegL,              relocInfo::none          },  // VectorD
   { Bad,             T_ILLEGAL,    "vectorx:",      false, Op_VecX,              relocInfo::none          },  // VectorX
   { Bad,             T_ILLEGAL,    "vectory:",      false, 0,                    relocInfo::none          },  // VectorY
   { Bad,             T_ILLEGAL,    "vectorz:",      false, 0,                    relocInfo::none          },  // VectorZ
diff a/src/hotspot/share/precompiled/precompiled.hpp b/src/hotspot/share/precompiled/precompiled.hpp
--- a/src/hotspot/share/precompiled/precompiled.hpp
+++ b/src/hotspot/share/precompiled/precompiled.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2010, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2010, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -20,12 +20,12 @@
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  *
  */
 
-// Precompiled headers are turned off for Solaris Studio,
-// or if the user passes --disable-precompiled-headers to configure.
+// Precompiled headers are turned off if the user passes
+// --disable-precompiled-headers to configure.
 
 #ifndef DONT_USE_PRECOMPILED_HEADER
 
 // These header files are included in at least 130 C++ files, as of
 // measurements made in November 2018. This list excludes files named
diff a/src/hotspot/share/prims/jni.cpp b/src/hotspot/share/prims/jni.cpp
--- a/src/hotspot/share/prims/jni.cpp
+++ b/src/hotspot/share/prims/jni.cpp
@@ -316,27 +316,15 @@
     env, (char*) name, loaderRef, (char*) buf, bufLen);
 
   jclass cls = NULL;
   DT_RETURN_MARK(DefineClass, jclass, (const jclass&)cls);
 
-  TempNewSymbol class_name = NULL;
-  // Since exceptions can be thrown, class initialization can take place
-  // if name is NULL no check for class name in .class stream has to be made.
-  if (name != NULL) {
-    const int str_len = (int)strlen(name);
-    if (str_len > Symbol::max_length()) {
-      // It's impossible to create this class;  the name cannot fit
-      // into the constant pool.
-      Exceptions::fthrow(THREAD_AND_LOCATION,
-                         vmSymbols::java_lang_NoClassDefFoundError(),
-                         "Class name exceeds maximum length of %d: %s",
-                         Symbol::max_length(),
-                         name);
-      return 0;
-    }
-    class_name = SymbolTable::new_symbol(name);
-  }
+  // Class resolution will get the class name from the .class stream if the name is null.
+  TempNewSymbol class_name = name == NULL ? NULL :
+    SystemDictionary::class_name_symbol(name, vmSymbols::java_lang_NoClassDefFoundError(),
+                                        CHECK_NULL);
+
   ResourceMark rm(THREAD);
   ClassFileStream st((u1*)buf, bufLen, NULL, ClassFileStream::verify);
   Handle class_loader (THREAD, JNIHandles::resolve(loaderRef));
 
   if (UsePerfData && !class_loader.is_null()) {
@@ -374,23 +362,14 @@
   HOTSPOT_JNI_FINDCLASS_ENTRY(env, (char *)name);
 
   jclass result = NULL;
   DT_RETURN_MARK(FindClass, jclass, (const jclass&)result);
 
-  // Sanity check the name:  it cannot be null or larger than the maximum size
-  // name we can fit in the constant pool.
-  if (name == NULL) {
-    THROW_MSG_0(vmSymbols::java_lang_NoClassDefFoundError(), "No class name given");
-  }
-  if ((int)strlen(name) > Symbol::max_length()) {
-    Exceptions::fthrow(THREAD_AND_LOCATION,
-                       vmSymbols::java_lang_NoClassDefFoundError(),
-                       "Class name exceeds maximum length of %d: %s",
-                       Symbol::max_length(),
-                       name);
-    return 0;
-  }
+  // This should be ClassNotFoundException imo.
+  TempNewSymbol class_name =
+    SystemDictionary::class_name_symbol(name, vmSymbols::java_lang_NoClassDefFoundError(),
+                                        CHECK_NULL);
 
   //%note jni_3
   Handle protection_domain;
   // Find calling class
   Klass* k = thread->security_get_caller_class(0);
@@ -418,12 +397,11 @@
     } else {
       loader = Handle(THREAD, k->class_loader());
     }
   }
 
-  TempNewSymbol sym = SymbolTable::new_symbol(name);
-  result = find_class_from_class_loader(env, sym, true, loader,
+  result = find_class_from_class_loader(env, class_name, true, loader,
                                         protection_domain, true, thread);
 
   if (log_is_enabled(Debug, class, resolve) && result != NULL) {
     trace_class_resolution(java_lang_Class::as_Klass(JNIHandles::resolve_non_null(result)));
   }
diff a/src/hotspot/share/prims/jniCheck.cpp b/src/hotspot/share/prims/jniCheck.cpp
--- a/src/hotspot/share/prims/jniCheck.cpp
+++ b/src/hotspot/share/prims/jniCheck.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -41,10 +41,11 @@
 #include "runtime/handles.inline.hpp"
 #include "runtime/interfaceSupport.inline.hpp"
 #include "runtime/jfieldIDWorkaround.hpp"
 #include "runtime/jniHandles.inline.hpp"
 #include "runtime/thread.inline.hpp"
+#include "utilities/utf8.hpp"
 
 // Complain every extra number of unplanned local refs
 #define CHECK_JNI_LOCAL_REF_CAP_WARN_THRESHOLD 32
 
 // Heap objects are allowed to be directly referenced only in VM code,
@@ -132,10 +133,12 @@
 static const char * fatal_null_object = "Null object passed to JNI";
 static const char * fatal_wrong_field = "Wrong field ID passed to JNI";
 static const char * fatal_instance_field_not_found = "Instance field not found in JNI get/set field operations";
 static const char * fatal_instance_field_mismatch = "Field type (instance) mismatch in JNI get/set field operations";
 static const char * fatal_non_string = "JNI string operation received a non-string";
+static const char * fatal_non_utf8_class_name1 = "JNI class name is not a valid UTF8 string \"";
+static const char * fatal_non_utf8_class_name2 = "\"";
 
 
 // When in VM state:
 static void ReportJNIWarning(JavaThread* thr, const char *msg) {
   tty->print_cr("WARNING in native method: %s", msg);
@@ -489,10 +492,17 @@
     char msg[JVM_MAXPATHLEN];
     jio_snprintf(msg, JVM_MAXPATHLEN, "%s%s%s",
                  warn_bad_class_descriptor1, name, warn_bad_class_descriptor2);
     ReportJNIWarning(thr, msg);
   }
+
+  // Verify that the class name given is a valid utf8 string
+  if (!UTF8::is_legal_utf8((const unsigned char*)name, (int)strlen(name), false)) {
+    char msg[JVM_MAXPATHLEN];
+    jio_snprintf(msg, JVM_MAXPATHLEN, "%s%s%s", fatal_non_utf8_class_name1, name, fatal_non_utf8_class_name2);
+    ReportJNIFatalError(thr, msg);
+  }
 }
 
 Klass* jniCheck::validate_class(JavaThread* thr, jclass clazz, bool allow_primitive) {
   ASSERT_OOPS_ALLOWED;
   oop mirror = jniCheck::validate_handle(thr, clazz);
diff a/src/hotspot/share/prims/jvm.cpp b/src/hotspot/share/prims/jvm.cpp
--- a/src/hotspot/share/prims/jvm.cpp
+++ b/src/hotspot/share/prims/jvm.cpp
@@ -810,16 +810,17 @@
 // FindClassFromBootLoader is exported to the launcher for windows.
 JVM_ENTRY(jclass, JVM_FindClassFromBootLoader(JNIEnv* env,
                                               const char* name))
   JVMWrapper("JVM_FindClassFromBootLoader");
 
-  // Java libraries should ensure that name is never null...
+  // Java libraries should ensure that name is never null or illegal.
   if (name == NULL || (int)strlen(name) > Symbol::max_length()) {
     // It's impossible to create this class;  the name cannot fit
     // into the constant pool.
     return NULL;
   }
+  assert(UTF8::is_legal_utf8((const unsigned char*)name, (int)strlen(name), false), "illegal UTF name");
 
   TempNewSymbol h_name = SymbolTable::new_symbol(name);
   Klass* k = SystemDictionary::resolve_or_null(h_name, CHECK_NULL);
   if (k == NULL) {
     return NULL;
@@ -834,17 +835,13 @@
 // Find a class with this name in this loader, using the caller's protection domain.
 JVM_ENTRY(jclass, JVM_FindClassFromCaller(JNIEnv* env, const char* name,
                                           jboolean init, jobject loader,
                                           jclass caller))
   JVMWrapper("JVM_FindClassFromCaller throws ClassNotFoundException");
-  // Java libraries should ensure that name is never null...
-  if (name == NULL || (int)strlen(name) > Symbol::max_length()) {
-    // It's impossible to create this class;  the name cannot fit
-    // into the constant pool.
-    THROW_MSG_0(vmSymbols::java_lang_ClassNotFoundException(), name);
-  }
-
+
+  TempNewSymbol h_name =
+       SystemDictionary::class_name_symbol(name, vmSymbols::java_lang_ClassNotFoundException(),
   TempNewSymbol h_name = SymbolTable::new_symbol(name);
 
   oop loader_oop = JNIHandles::resolve(loader);
   oop from_class = JNIHandles::resolve(caller);
   oop protection_domain = NULL;
@@ -870,24 +867,13 @@
 
 // Currently only called from the old verifier.
 JVM_ENTRY(jclass, JVM_FindClassFromClass(JNIEnv *env, const char *name,
                                          jboolean init, jclass from))
   JVMWrapper("JVM_FindClassFromClass");
-  if (name == NULL) {
-    THROW_MSG_0(vmSymbols::java_lang_NoClassDefFoundError(), "No class name given");
-  }
-  if ((int)strlen(name) > Symbol::max_length()) {
-    // It's impossible to create this class;  the name cannot fit
-    // into the constant pool.
-    Exceptions::fthrow(THREAD_AND_LOCATION,
-                       vmSymbols::java_lang_NoClassDefFoundError(),
-                       "Class name exceeds maximum length of %d: %s",
-                       Symbol::max_length(),
-                       name);
-    return 0;
-  }
-  TempNewSymbol h_name = SymbolTable::new_symbol(name);
+  TempNewSymbol h_name =
+       SystemDictionary::class_name_symbol(name, vmSymbols::java_lang_ClassNotFoundException(),
+                                           CHECK_NULL);
   oop from_class_oop = JNIHandles::resolve(from);
   Klass* from_class = (from_class_oop == NULL)
                            ? (Klass*)NULL
                            : java_lang_Class::as_Klass(from_class_oop);
   oop class_loader = NULL;
@@ -949,27 +935,14 @@
 
   if (UsePerfData) {
     ClassLoader::perf_app_classfile_bytes_read()->inc(len);
   }
 
-  // Since exceptions can be thrown, class initialization can take place
-  // if name is NULL no check for class name in .class stream has to be made.
-  TempNewSymbol class_name = NULL;
-  if (name != NULL) {
-    const int str_len = (int)strlen(name);
-    if (str_len > Symbol::max_length()) {
-      // It's impossible to create this class;  the name cannot fit
-      // into the constant pool.
-      Exceptions::fthrow(THREAD_AND_LOCATION,
-                         vmSymbols::java_lang_NoClassDefFoundError(),
-                         "Class name exceeds maximum length of %d: %s",
-                         Symbol::max_length(),
-                         name);
-      return 0;
-    }
-    class_name = SymbolTable::new_symbol(name, str_len);
-  }
+  // Class resolution will get the class name from the .class stream if the name is null.
+  TempNewSymbol class_name = name == NULL ? NULL :
+       SystemDictionary::class_name_symbol(name, vmSymbols::java_lang_NoClassDefFoundError(),
+                                           CHECK_NULL);
 
   ResourceMark rm(THREAD);
   ClassFileStream st((u1*)buf, len, source, ClassFileStream::verify);
   Handle class_loader (THREAD, JNIHandles::resolve(loader));
   if (UsePerfData) {
@@ -1054,28 +1027,14 @@
       THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(),
                   err_msg("invalid flag 0x%x", flags));
     }
   }
 
-
-  // Since exceptions can be thrown, class initialization can take place
-  // if name is NULL no check for class name in .class stream has to be made.
-  TempNewSymbol class_name = NULL;
-  if (name != NULL) {
-    const int str_len = (int)strlen(name);
-    if (str_len > Symbol::max_length()) {
-      // It's impossible to create this class;  the name cannot fit
-      // into the constant pool.
-      Exceptions::fthrow(THREAD_AND_LOCATION,
-                         vmSymbols::java_lang_NoClassDefFoundError(),
-                         "Class name exceeds maximum length of %d: %s",
-                         Symbol::max_length(),
-                         name);
-      return 0;
-    }
-    class_name = SymbolTable::new_symbol(name, str_len);
-  }
+  // Class resolution will get the class name from the .class stream if the name is null.
+  TempNewSymbol class_name = name == NULL ? NULL :
+       SystemDictionary::class_name_symbol(name, vmSymbols::java_lang_NoClassDefFoundError(),
+                                           CHECK_NULL);
 
   Handle protection_domain (THREAD, JNIHandles::resolve(pd));
   const char* source = is_nestmate ? host_class->external_name() : "__JVM_LookupDefineClass__";
   ClassFileStream st((u1*)buf, len, source, ClassFileStream::verify);
 
diff a/src/hotspot/share/runtime/arguments.cpp b/src/hotspot/share/runtime/arguments.cpp
--- a/src/hotspot/share/runtime/arguments.cpp
+++ b/src/hotspot/share/runtime/arguments.cpp
@@ -558,10 +558,14 @@
 #ifndef X86
   { "UseSSE",                        JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
 #endif // !X86
   { "UseAdaptiveGCBoundary",         JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
   { "MonitorBound",                  JDK_Version::jdk(14),     JDK_Version::jdk(15), JDK_Version::jdk(16) },
+#ifdef AARCH64
+  { "UseBarriersForVolatile",        JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
+#endif
+  { "UseLWPSynchronization",         JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },
 
 #ifdef TEST_VERIFY_SPECIAL_JVM_FLAGS
   // These entries will generate build errors.  Their purpose is to test the macros.
   { "dep > obs",                    JDK_Version::jdk(9), JDK_Version::jdk(8), JDK_Version::undefined() },
   { "dep > exp ",                   JDK_Version::jdk(9), JDK_Version::undefined(), JDK_Version::jdk(8) },
@@ -597,11 +601,10 @@
   { NULL, NULL}
 };
 
 // NOTE: A compatibility request will be necessary for each alias to be removed.
 static AliasedLoggingFlag const aliased_logging_flags[] = {
-  { "PrintCompressedOopsMode",   LogLevel::Info,  true,  LOG_TAGS(gc, heap, coops) },
   { "PrintSharedSpaces",         LogLevel::Info,  true,  LOG_TAGS(cds) },
   { "TraceBiasedLocking",        LogLevel::Info,  true,  LOG_TAGS(biasedlocking) },
   { "TraceClassLoading",         LogLevel::Info,  true,  LOG_TAGS(class, load) },
   { "TraceClassLoadingPreorder", LogLevel::Debug, true,  LOG_TAGS(class, preorder) },
   { "TraceClassPaths",           LogLevel::Info,  true,  LOG_TAGS(class, path) },
@@ -2139,11 +2142,11 @@
   status = CompilerConfig::check_args_consistency(status);
 #if INCLUDE_JVMCI
   if (status && EnableJVMCI) {
     PropertyList_unique_add(&_system_properties, "jdk.internal.vm.ci.enabled", "true",
         AddProperty, UnwriteableProperty, InternalProperty);
-    if (!create_numbered_property("jdk.module.addmods", "jdk.internal.vm.ci", addmods_count++)) {
+    if (!create_numbered_module_property("jdk.module.addmods", "jdk.internal.vm.ci", addmods_count++)) {
       return false;
     }
   }
 #endif
 
@@ -2213,24 +2216,32 @@
     }
   }
   return false;
 }
 
-bool Arguments::create_property(const char* prop_name, const char* prop_value, PropertyInternal internal) {
+bool Arguments::create_module_property(const char* prop_name, const char* prop_value, PropertyInternal internal) {
+  assert(is_internal_module_property(prop_name) ||
+         strcmp(prop_name, "jdk.module.illegalAccess") == 0, "unknown module property: '%s'", prop_name);
   size_t prop_len = strlen(prop_name) + strlen(prop_value) + 2;
   char* property = AllocateHeap(prop_len, mtArguments);
   int ret = jio_snprintf(property, prop_len, "%s=%s", prop_name, prop_value);
   if (ret < 0 || ret >= (int)prop_len) {
     FreeHeap(property);
     return false;
   }
-  bool added = add_property(property, UnwriteableProperty, internal);
+  // These are not strictly writeable properties as they cannot be set via -Dprop=val. But that
+  // is enforced by checking is_internal_module_property(). We need the property to be writeable so
+  // that multiple occurrences of the associated flag just causes the existing property value to be
+  // replaced ("last option wins"). Otherwise we would need to keep track of the flags and only convert
+  // to a property after we have finished flag processing.
+  bool added = add_property(property, WriteableProperty, internal);
   FreeHeap(property);
   return added;
 }
 
-bool Arguments::create_numbered_property(const char* prop_base_name, const char* prop_value, unsigned int count) {
+bool Arguments::create_numbered_module_property(const char* prop_base_name, const char* prop_value, unsigned int count) {
+  assert(is_internal_module_property(prop_base_name), "unknown module property: '%s'", prop_base_name);
   const unsigned int props_count_limit = 1000;
   const int max_digits = 3;
   const int extra_symbols_count = 3; // includes '.', '=', '\0'
 
   // Make sure count is < props_count_limit. Otherwise, memory allocation will be too small.
@@ -2388,11 +2399,11 @@
       memcpy(module_name, patch_mod_tail, module_len);
       *(module_name + module_len) = '\0';
       // The path piece begins one past the module_equal sign
       add_patch_mod_prefix(module_name, module_equal + 1, patch_mod_javabase);
       FREE_C_HEAP_ARRAY(char, module_name);
-      if (!create_numbered_property("jdk.module.patch", patch_mod_tail, patch_mod_count++)) {
+      if (!create_numbered_module_property("jdk.module.patch", patch_mod_tail, patch_mod_count++)) {
         return JNI_ENOMEM;
       }
     } else {
       return JNI_ENOMEM;
     }
@@ -2533,45 +2544,45 @@
         }
 #endif // !INCLUDE_JVMTI
         add_init_library(name, options);
       }
     } else if (match_option(option, "--add-reads=", &tail)) {
-      if (!create_numbered_property("jdk.module.addreads", tail, addreads_count++)) {
+      if (!create_numbered_module_property("jdk.module.addreads", tail, addreads_count++)) {
         return JNI_ENOMEM;
       }
     } else if (match_option(option, "--add-exports=", &tail)) {
-      if (!create_numbered_property("jdk.module.addexports", tail, addexports_count++)) {
+      if (!create_numbered_module_property("jdk.module.addexports", tail, addexports_count++)) {
         return JNI_ENOMEM;
       }
     } else if (match_option(option, "--add-opens=", &tail)) {
-      if (!create_numbered_property("jdk.module.addopens", tail, addopens_count++)) {
+      if (!create_numbered_module_property("jdk.module.addopens", tail, addopens_count++)) {
         return JNI_ENOMEM;
       }
     } else if (match_option(option, "--add-modules=", &tail)) {
-      if (!create_numbered_property("jdk.module.addmods", tail, addmods_count++)) {
+      if (!create_numbered_module_property("jdk.module.addmods", tail, addmods_count++)) {
         return JNI_ENOMEM;
       }
     } else if (match_option(option, "--limit-modules=", &tail)) {
-      if (!create_property("jdk.module.limitmods", tail, InternalProperty)) {
+      if (!create_module_property("jdk.module.limitmods", tail, InternalProperty)) {
         return JNI_ENOMEM;
       }
     } else if (match_option(option, "--module-path=", &tail)) {
-      if (!create_property("jdk.module.path", tail, ExternalProperty)) {
+      if (!create_module_property("jdk.module.path", tail, ExternalProperty)) {
         return JNI_ENOMEM;
       }
     } else if (match_option(option, "--upgrade-module-path=", &tail)) {
-      if (!create_property("jdk.module.upgrade.path", tail, ExternalProperty)) {
+      if (!create_module_property("jdk.module.upgrade.path", tail, ExternalProperty)) {
         return JNI_ENOMEM;
       }
     } else if (match_option(option, "--patch-module=", &tail)) {
       // --patch-module=<module>=<file>(<pathsep><file>)*
       int res = process_patch_mod_option(tail, patch_mod_javabase);
       if (res != JNI_OK) {
         return res;
       }
     } else if (match_option(option, "--illegal-access=", &tail)) {
-      if (!create_property("jdk.module.illegalAccess", tail, ExternalProperty)) {
+      if (!create_module_property("jdk.module.illegalAccess", tail, ExternalProperty)) {
         return JNI_ENOMEM;
       }
     // -agentlib and -agentpath
     } else if (match_option(option, "-agentlib:", &tail) ||
           (is_absolute_path = match_option(option, "-agentpath:", &tail))) {
@@ -2611,11 +2622,11 @@
         size_t length = strlen(tail) + 1;
         char *options = NEW_C_HEAP_ARRAY(char, length, mtArguments);
         jio_snprintf(options, length, "%s", tail);
         add_instrument_agent("instrument", options, false);
         // java agents need module java.instrument
-        if (!create_numbered_property("jdk.module.addmods", "java.instrument", addmods_count++)) {
+        if (!create_numbered_module_property("jdk.module.addmods", "java.instrument", addmods_count++)) {
           return JNI_ENOMEM;
         }
       }
 #endif // !INCLUDE_JVMTI
     // --enable_preview
@@ -2792,11 +2803,11 @@
 #if INCLUDE_MANAGEMENT
         if (FLAG_SET_CMDLINE(ManagementServer, true) != JVMFlag::SUCCESS) {
           return JNI_EINVAL;
         }
         // management agent in module jdk.management.agent
-        if (!create_numbered_property("jdk.module.addmods", "jdk.management.agent", addmods_count++)) {
+        if (!create_numbered_module_property("jdk.module.addmods", "jdk.management.agent", addmods_count++)) {
           return JNI_ENOMEM;
         }
 #else
         jio_fprintf(defaultStream::output_stream(),
           "-Dcom.sun.management is not supported in this VM.\n");
@@ -3071,11 +3082,23 @@
       return JNI_ERR;
     }
   }
 
   if (EnableValhalla) {
-    if (!create_property("valhalla.enableValhalla", "true", InternalProperty)) {
+    // create_property("valhalla.enableValhalla", "true", InternalProperty)
+    const char* prop_name = "valhalla.enableValhalla";
+    const char* prop_value = "true";
+    const size_t prop_len = strlen(prop_name) + strlen(prop_value) + 2;
+    char* property = AllocateHeap(prop_len, mtArguments);
+    int ret = jio_snprintf(property, prop_len, "%s=%s", prop_name, prop_value);
+    if (ret < 0 || ret >= (int)prop_len) {
+      FreeHeap(property);
+      return JNI_ENOMEM;
+    }
+    bool added = add_property(property, UnwriteableProperty, InternalProperty);
+    FreeHeap(property);
+    if (!added) {
       return JNI_ENOMEM;
     }
   }
 
   // PrintSharedArchiveAndExit will turn on
@@ -4330,18 +4353,19 @@
                                         PropertyAppendable append, PropertyWriteable writeable,
                                         PropertyInternal internal) {
   if (plist == NULL)
     return;
 
-  // If property key exist then update with new value.
+  // If property key exists and is writeable, then update with new value.
+  // Trying to update a non-writeable property is silently ignored.
   SystemProperty* prop;
   for (prop = *plist; prop != NULL; prop = prop->next()) {
     if (strcmp(k, prop->key()) == 0) {
       if (append == AppendProperty) {
-        prop->append_value(v);
+        prop->append_writeable_value(v);
       } else {
-        prop->set_value(v);
+        prop->set_writeable_value(v);
       }
       return;
     }
   }
 
diff a/src/hotspot/share/runtime/deoptimization.cpp b/src/hotspot/share/runtime/deoptimization.cpp
--- a/src/hotspot/share/runtime/deoptimization.cpp
+++ b/src/hotspot/share/runtime/deoptimization.cpp
@@ -1125,27 +1125,13 @@
       *((jshort *) check_alignment_get_addr(obj, index, 2)) = (jshort) *((jint *) &val);
       break;
     case 4:
       *((jint *) check_alignment_get_addr(obj, index, 4)) = (jint) *((jint *) &val);
       break;
-    case 8: {
-#ifdef _LP64
-        jlong res = (jlong) *((jlong *) &val);
-#else
-#ifdef SPARC
-      // For SPARC we have to swap high and low words.
-      jlong v = (jlong) *((jlong *) &val);
-      jlong res = 0;
-      res |= ((v & (jlong) 0xffffffff) << 32);
-      res |= ((v >> 32) & (jlong) 0xffffffff);
-#else
-      jlong res = (jlong) *((jlong *) &val);
-#endif // SPARC
-#endif
-      *((jlong *) check_alignment_get_addr(obj, index, 8)) = res;
+    case 8:
+      *((jlong *) check_alignment_get_addr(obj, index, 8)) = (jlong) *((jlong *) &val);
       break;
-  }
     default:
       ShouldNotReachHere();
   }
 }
 #endif // INCLUDE_JVMCI
@@ -1163,17 +1149,12 @@
       assert(value->type() == T_INT, "Agreement.");
       StackValue* low =
         StackValue::create_stack_value(fr, reg_map, sv->field_at(++i));
 #ifdef _LP64
       jlong res = (jlong)low->get_int();
-#else
-#ifdef SPARC
-      // For SPARC we have to swap high and low words.
-      jlong res = jlong_from((jint)low->get_int(), (jint)value->get_int());
 #else
       jlong res = jlong_from((jint)value->get_int(), (jint)low->get_int());
-#endif //SPARC
 #endif
       obj->long_at_put(index, res);
       break;
     }
 
@@ -1197,17 +1178,12 @@
 
       if (big_value) {
         StackValue* low = StackValue::create_stack_value(fr, reg_map, sv->field_at(++i));
   #ifdef _LP64
         jlong res = (jlong)low->get_int();
-  #else
-  #ifdef SPARC
-        // For SPARC we have to swap high and low words.
-        jlong res = jlong_from((jint)low->get_int(), (jint)value->get_int());
   #else
         jlong res = jlong_from((jint)value->get_int(), (jint)low->get_int());
-  #endif //SPARC
   #endif
         obj->int_at_put(index, (jint)*((jint*)&res));
         obj->int_at_put(++index, (jint)*(((jint*)&res) + 1));
       } else {
         val = value->get_int();
@@ -1369,17 +1345,12 @@
       case T_LONG: case T_DOUBLE: {
         assert(value->type() == T_INT, "Agreement.");
         StackValue* low = StackValue::create_stack_value(fr, reg_map, sv->field_at(++svIndex));
 #ifdef _LP64
         jlong res = (jlong)low->get_int();
-#else
-#ifdef SPARC
-        // For SPARC we have to swap high and low words.
-        jlong res = jlong_from((jint)low->get_int(), (jint)value->get_int());
 #else
         jlong res = jlong_from((jint)value->get_int(), (jint)low->get_int());
-#endif //SPARC
 #endif
         obj->long_field_put(offset, res);
         break;
       }
 
diff a/src/hotspot/share/runtime/frame.cpp b/src/hotspot/share/runtime/frame.cpp
--- a/src/hotspot/share/runtime/frame.cpp
+++ b/src/hotspot/share/runtime/frame.cpp
@@ -1078,13 +1078,10 @@
 }
 
 
 void frame::oops_do_internal(OopClosure* f, CodeBlobClosure* cf, RegisterMap* map, bool use_interpreter_oop_map_cache) {
 #ifndef PRODUCT
-#if defined(__SUNPRO_CC) && __SUNPRO_CC >= 0x5140
-#pragma error_messages(off, SEC_NULL_PTR_DEREF)
-#endif
   // simulate GC crash here to dump java thread in error report
   if (CrashGCForDumpingJavaThread) {
     char *t = NULL;
     *t = 'c';
   }
diff a/src/hotspot/share/runtime/globals.hpp b/src/hotspot/share/runtime/globals.hpp
--- a/src/hotspot/share/runtime/globals.hpp
+++ b/src/hotspot/share/runtime/globals.hpp
@@ -407,11 +407,11 @@
                                                                             \
   product(bool, TraceSuspendWaitFailures, false,                            \
           "Trace external suspend wait failures")                           \
                                                                             \
   product(bool, MaxFDLimit, true,                                           \
-          "Bump the number of file descriptors to maximum in Solaris")      \
+          "Bump the number of file descriptors to maximum (Unix only)")     \
                                                                             \
   diagnostic(bool, LogEvents, true,                                         \
           "Enable the various ring buffer event logs")                      \
                                                                             \
   diagnostic(uintx, LogEventsBufferEntries, 20,                             \
@@ -677,22 +677,14 @@
           "registering as parallel capable")                                \
                                                                             \
   product_pd(bool, DontYieldALot,                                           \
           "Throw away obvious excess yield calls")                          \
                                                                             \
-  develop(bool, UseDetachedThreads, true,                                   \
-          "Use detached threads that are recycled upon termination "        \
-          "(for Solaris only)")                                             \
-                                                                            \
   experimental(bool, DisablePrimordialThreadGuardPages, false,              \
                "Disable the use of stack guard pages if the JVM is loaded " \
                "on the primordial process thread")                          \
                                                                             \
-  product(bool, UseLWPSynchronization, true,                                \
-          "Use LWP-based instead of libthread-based synchronization "       \
-          "(SPARC only)")                                                   \
-                                                                            \
   experimental(intx, MonitorUsedDeflationThreshold, 90,                     \
                 "Percentage of used monitors before triggering cleanup "    \
                 "safepoint which deflates monitors (0 is off). "            \
                 "The check is performed on GuaranteedSafepointInterval.")   \
                 range(0, 100)                                               \
@@ -702,14 +694,10 @@
                                                                             \
   product(bool, FilterSpuriousWakeups, true,                                \
           "When true prevents OS-level spurious, or premature, wakeups "    \
           "from Object.wait (Ignored for Windows)")                         \
                                                                             \
-  develop(bool, UsePthreads, false,                                         \
-          "Use pthread-based instead of libthread-based synchronization "   \
-          "(SPARC only)")                                                   \
-                                                                            \
   product(bool, ReduceSignalUsage, false,                                   \
           "Reduce the use of OS signals in Java and/or the VM")             \
                                                                             \
   develop(bool, LoadLineNumberTables, true,                                 \
           "Tell whether the class file parser loads line number tables")    \
@@ -721,15 +709,15 @@
           "Tell whether the class file parser loads local variable type"    \
           "tables")                                                         \
                                                                             \
   product(bool, AllowUserSignalHandlers, false,                             \
           "Do not complain if the application installs signal handlers "    \
-          "(Solaris & Linux only)")                                         \
+          "(Unix only)")                                                    \
                                                                             \
   product(bool, UseSignalChaining, true,                                    \
           "Use signal-chaining to invoke signal handlers installed "        \
-          "by the application (Solaris & Linux only)")                      \
+          "by the application (Unix only)")                                 \
                                                                             \
   product(bool, RestoreMXCSROnJNICalls, false,                              \
           "Restore MXCSR when returning from JNI calls")                    \
                                                                             \
   product(bool, CheckJNICalls, false,                                       \
@@ -1823,14 +1811,12 @@
   product_pd(bool, UseThreadPriorities,  "Use native thread priorities")    \
                                                                             \
   product(intx, ThreadPriorityPolicy, 0,                                    \
           "0 : Normal.                                                     "\
           "    VM chooses priorities that are appropriate for normal       "\
-          "    applications. On Solaris NORM_PRIORITY and above are mapped "\
-          "    to normal native priority. Java priorities below "           \
-          "    NORM_PRIORITY map to lower native priority values. On       "\
-          "    Windows applications are allowed to use higher native       "\
+          "    applications.                                               "\
+          "    On Windows applications are allowed to use higher native    "\
           "    priorities. However, with ThreadPriorityPolicy=0, VM will   "\
           "    not use the highest possible native priority,               "\
           "    THREAD_PRIORITY_TIME_CRITICAL, as it may interfere with     "\
           "    system threads. On Linux thread priorities are ignored      "\
           "    because the OS does not support static priority in          "\
@@ -1851,11 +1837,10 @@
                                                                             \
   product(intx, CompilerThreadPriority, -1,                                 \
           "The native priority at which compiler threads should run "       \
           "(-1 means no change)")                                           \
           range(min_jint, max_jint)                                         \
-          constraint(CompilerThreadPriorityConstraintFunc, AfterErgo)       \
                                                                             \
   product(intx, VMThreadPriority, -1,                                       \
           "The native priority at which the VM thread should run "          \
           "(-1 means no change)")                                           \
           range(-1, 127)                                                    \
@@ -2389,12 +2374,11 @@
            "(1) always map at alternative address; "                        \
            "(2) always map at preferred address, and if unsuccessful, "     \
            "do not map the archive")                                        \
            range(0, 2)                                                      \
                                                                             \
-  experimental(size_t, ArrayAllocatorMallocLimit,                           \
-          SOLARIS_ONLY(64*K) NOT_SOLARIS((size_t)-1),                       \
+  experimental(size_t, ArrayAllocatorMallocLimit, (size_t)-1,               \
           "Allocation less than this value will be allocated "              \
           "using malloc. Larger allocations will use mmap.")                \
                                                                             \
   experimental(bool, AlwaysAtomicAccesses, false,                           \
           "Accesses to all variables should always be atomic")              \
diff a/src/hotspot/share/runtime/init.cpp b/src/hotspot/share/runtime/init.cpp
--- a/src/hotspot/share/runtime/init.cpp
+++ b/src/hotspot/share/runtime/init.cpp
@@ -153,16 +153,10 @@
     return JNI_ERR;
   }
   stubRoutines_init2(); // note: StubRoutines need 2-phase init
   MethodHandles::generate_adapters();
 
-#if INCLUDE_NMT
-  // Solaris stack is walkable only after stubRoutines are set up.
-  // On Other platforms, the stack is always walkable.
-  NMT_stack_walkable = true;
-#endif // INCLUDE_NMT
-
   // All the flags that get adjusted by VM_Version_init and os::init_2
   // have been set so dump the flags now.
   if (PrintFlagsFinal || PrintFlagsRanges) {
     JVMFlag::printFlags(tty, false, PrintFlagsRanges);
   }
diff a/src/hotspot/share/runtime/thread.cpp b/src/hotspot/share/runtime/thread.cpp
--- a/src/hotspot/share/runtime/thread.cpp
+++ b/src/hotspot/share/runtime/thread.cpp
@@ -350,16 +350,10 @@
   // If possible, refrain from doing anything which may crash or assert since
   // quite probably those crash dumps will be useless.
   set_stack_base(os::current_stack_base());
   set_stack_size(os::current_stack_size());
 
-#ifdef SOLARIS
-  if (os::is_primordial_thread()) {
-    os::Solaris::correct_stack_boundaries_for_primordial_thread(this);
-  }
-#endif
-
   // Set stack limits after thread is initialized.
   if (is_Java_thread()) {
     ((JavaThread*) this)->set_stack_overflow_limit();
     ((JavaThread*) this)->set_reserved_stack_activation(stack_base());
   }
@@ -1671,11 +1665,11 @@
   if (JVMCICounterSize > 0) {
     resize_counters(0, (int) JVMCICounterSize);
   }
 #endif // INCLUDE_JVMCI
   _reserved_stack_activation = NULL;  // stack base not known yet
-  (void)const_cast<oop&>(_exception_oop = oop(NULL));
+  set_exception_oop(oop());
   _exception_pc  = 0;
   _exception_handler_pc = 0;
   _is_method_handle_return = 0;
   _jvmti_thread_state= NULL;
   _should_post_on_exceptions_flag = JNI_FALSE;
@@ -2258,10 +2252,17 @@
   }
 
   return false;
 }
 
+oop JavaThread::exception_oop() const {
+  return Atomic::load(&_exception_oop);
+}
+
+void JavaThread::set_exception_oop(oop o) {
+  Atomic::store(&_exception_oop, o);
+}
 
 void JavaThread::add_monitor_chunk(MonitorChunk* chunk) {
   chunk->set_next(monitor_chunks());
   set_monitor_chunks(chunk);
 }
diff a/src/hotspot/share/runtime/thread.hpp b/src/hotspot/share/runtime/thread.hpp
--- a/src/hotspot/share/runtime/thread.hpp
+++ b/src/hotspot/share/runtime/thread.hpp
@@ -1578,16 +1578,16 @@
   virtual bool in_retryable_allocation() const    { return _in_retryable_allocation; }
   void set_in_retryable_allocation(bool b)        { _in_retryable_allocation = b; }
 #endif // INCLUDE_JVMCI
 
   // Exception handling for compiled methods
-  oop      exception_oop() const                 { return _exception_oop; }
+  oop      exception_oop() const;
   address  exception_pc() const                  { return _exception_pc; }
   address  exception_handler_pc() const          { return _exception_handler_pc; }
   bool     is_method_handle_return() const       { return _is_method_handle_return == 1; }
 
-  void set_exception_oop(oop o)                  { (void)const_cast<oop&>(_exception_oop = o); }
+  void set_exception_oop(oop o);
   void set_exception_pc(address a)               { _exception_pc = a; }
   void set_exception_handler_pc(address a)       { _exception_handler_pc = a; }
   void set_is_method_handle_return(bool value)   { _is_method_handle_return = value ? 1 : 0; }
 
   void clear_exception_oop_and_pc() {
diff a/src/hotspot/share/runtime/vmStructs.cpp b/src/hotspot/share/runtime/vmStructs.cpp
--- a/src/hotspot/share/runtime/vmStructs.cpp
+++ b/src/hotspot/share/runtime/vmStructs.cpp
@@ -2037,16 +2037,10 @@
   /* Useful globals */                                                    \
   /******************/                                                    \
                                                                           \
   declare_preprocessor_constant("ASSERT", DEBUG_ONLY(1) NOT_DEBUG(0))     \
                                                                           \
-  /**************/                                                        \
-  /* Stack bias */                                                        \
-  /**************/                                                        \
-                                                                          \
-  declare_preprocessor_constant("STACK_BIAS", STACK_BIAS)                 \
-                                                                          \
   /****************/                                                      \
   /* Object sizes */                                                      \
   /****************/                                                      \
                                                                           \
   declare_constant(oopSize)                                               \
diff a/src/hotspot/share/utilities/globalDefinitions.hpp b/src/hotspot/share/utilities/globalDefinitions.hpp
--- a/src/hotspot/share/utilities/globalDefinitions.hpp
+++ b/src/hotspot/share/utilities/globalDefinitions.hpp
@@ -802,19 +802,10 @@
  jshort get_jshort() const { return (jshort) (_value.i);}
 
 };
 
 
-#define STACK_BIAS      0
-// V9 Sparc CPU's running in 64 Bit mode use a stack bias of 7ff
-// in order to extend the reach of the stack pointer.
-#if defined(SPARC) && defined(_LP64)
-#undef STACK_BIAS
-#define STACK_BIAS      0x7ff
-#endif
-
-
 // TosState describes the top-of-stack state before and after the execution of
 // a bytecode or method. The top-of-stack value may be cached in one or more CPU
 // registers. The TosState corresponds to the 'machine representation' of this cached
 // value. There's 4 states corresponding to the JAVA types int, long, float & double
 // as well as a 5th state in case the top-of-stack value is actually on the top
diff a/src/java.base/share/classes/java/lang/System.java b/src/java.base/share/classes/java/lang/System.java
--- a/src/java.base/share/classes/java/lang/System.java
+++ b/src/java.base/share/classes/java/lang/System.java
@@ -2284,10 +2284,14 @@
 
             public long stringConcatInitialCoder() {
                 return StringConcatHelper.initialCoder();
             }
 
+            public long stringConcatMix(long lengthCoder, String constant) {
+                return StringConcatHelper.mix(lengthCoder, constant);
+            }
+
             public Object classData(Class<?> c) {
                 return c.getClassData();
             }
         });
     }
diff a/src/java.base/share/classes/java/lang/invoke/MethodHandles.java b/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
--- a/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
+++ b/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
@@ -4636,11 +4636,11 @@
             }
             return ~zeroPos;
         }
     }
 
-    private static boolean permuteArgumentChecks(int[] reorder, MethodType newType, MethodType oldType) {
+    static boolean permuteArgumentChecks(int[] reorder, MethodType newType, MethodType oldType) {
         if (newType.returnType() != oldType.returnType())
             throw newIllegalArgumentException("return types do not match",
                     oldType, newType);
         if (reorder.length == oldType.parameterCount()) {
             int limit = newType.parameterCount();
diff a/src/java.base/share/classes/java/lang/invoke/VarHandles.java b/src/java.base/share/classes/java/lang/invoke/VarHandles.java
--- a/src/java.base/share/classes/java/lang/invoke/VarHandles.java
+++ b/src/java.base/share/classes/java/lang/invoke/VarHandles.java
@@ -25,18 +25,26 @@
 
 package java.lang.invoke;
 
 import sun.invoke.util.Wrapper;
 
+import java.lang.reflect.Constructor;
 import java.lang.reflect.Field;
+import java.lang.reflect.Method;
 import java.lang.reflect.Modifier;
 import java.nio.ByteOrder;
+import java.util.ArrayList;
+import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
+import java.util.stream.Stream;
 
 import static java.lang.invoke.MethodHandleStatics.UNSAFE;
+import static java.lang.invoke.MethodHandleStatics.VAR_HANDLE_IDENTITY_ADAPT;
+import static java.lang.invoke.MethodHandleStatics.newIllegalArgumentException;
 
 final class VarHandles {
 
     static ClassValue<ConcurrentMap<Integer, MethodHandle>> ADDRESS_FACTORIES = new ClassValue<>() {
         @Override
@@ -48,58 +56,58 @@
     static VarHandle makeFieldHandle(MemberName f, Class<?> refc, Class<?> type, boolean isWriteAllowedOnFinalFields) {
         if (!f.isStatic()) {
             long foffset = MethodHandleNatives.objectFieldOffset(f);
             if (!type.isPrimitive()) {
                 if (f.isFlattened()) {
-                    return f.isFinal() && !isWriteAllowedOnFinalFields
+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                         ? new VarHandleValues.FieldInstanceReadOnly(refc, foffset, type)
-                        : new VarHandleValues.FieldInstanceReadWrite(refc, foffset, type);
+                        : new VarHandleValues.FieldInstanceReadWrite(refc, foffset, type));
                 } else {
-                    return f.isFinal() && !isWriteAllowedOnFinalFields
+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleReferences.FieldInstanceReadOnly(refc, foffset, type)
-                       : new VarHandleReferences.FieldInstanceReadWrite(refc, foffset, type);
+                       : new VarHandleReferences.FieldInstanceReadWrite(refc, foffset, type));
                 }
             }
             else if (type == boolean.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleBooleans.FieldInstanceReadOnly(refc, foffset)
-                       : new VarHandleBooleans.FieldInstanceReadWrite(refc, foffset);
+                       : new VarHandleBooleans.FieldInstanceReadWrite(refc, foffset));
             }
             else if (type == byte.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleBytes.FieldInstanceReadOnly(refc, foffset)
-                       : new VarHandleBytes.FieldInstanceReadWrite(refc, foffset);
+                       : new VarHandleBytes.FieldInstanceReadWrite(refc, foffset));
             }
             else if (type == short.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleShorts.FieldInstanceReadOnly(refc, foffset)
-                       : new VarHandleShorts.FieldInstanceReadWrite(refc, foffset);
+                       : new VarHandleShorts.FieldInstanceReadWrite(refc, foffset));
             }
             else if (type == char.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleChars.FieldInstanceReadOnly(refc, foffset)
-                       : new VarHandleChars.FieldInstanceReadWrite(refc, foffset);
+                       : new VarHandleChars.FieldInstanceReadWrite(refc, foffset));
             }
             else if (type == int.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleInts.FieldInstanceReadOnly(refc, foffset)
-                       : new VarHandleInts.FieldInstanceReadWrite(refc, foffset);
+                       : new VarHandleInts.FieldInstanceReadWrite(refc, foffset));
             }
             else if (type == long.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleLongs.FieldInstanceReadOnly(refc, foffset)
-                       : new VarHandleLongs.FieldInstanceReadWrite(refc, foffset);
+                       : new VarHandleLongs.FieldInstanceReadWrite(refc, foffset));
             }
             else if (type == float.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleFloats.FieldInstanceReadOnly(refc, foffset)
-                       : new VarHandleFloats.FieldInstanceReadWrite(refc, foffset);
+                       : new VarHandleFloats.FieldInstanceReadWrite(refc, foffset));
             }
             else if (type == double.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleDoubles.FieldInstanceReadOnly(refc, foffset)
-                       : new VarHandleDoubles.FieldInstanceReadWrite(refc, foffset);
+                       : new VarHandleDoubles.FieldInstanceReadWrite(refc, foffset));
             }
             else {
                 throw new UnsupportedOperationException();
             }
         }
@@ -115,58 +123,58 @@
 
             Object base = MethodHandleNatives.staticFieldBase(f);
             long foffset = MethodHandleNatives.staticFieldOffset(f);
             if (!type.isPrimitive()) {
                 if (f.isFlattened()) {
-                    return f.isFinal() && !isWriteAllowedOnFinalFields
+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                             ? new VarHandleValues.FieldStaticReadOnly(refc, foffset, type)
-                            : new VarHandleValues.FieldStaticReadWrite(refc, foffset, type);
+                            : new VarHandleValues.FieldStaticReadWrite(refc, foffset, type));
                 } else {
                     return f.isFinal() && !isWriteAllowedOnFinalFields
                             ? new VarHandleReferences.FieldStaticReadOnly(base, foffset, type)
                             : new VarHandleReferences.FieldStaticReadWrite(base, foffset, type);
                 }
             }
             else if (type == boolean.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleBooleans.FieldStaticReadOnly(base, foffset)
-                       : new VarHandleBooleans.FieldStaticReadWrite(base, foffset);
+                       : new VarHandleBooleans.FieldStaticReadWrite(base, foffset));
             }
             else if (type == byte.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleBytes.FieldStaticReadOnly(base, foffset)
-                       : new VarHandleBytes.FieldStaticReadWrite(base, foffset);
+                       : new VarHandleBytes.FieldStaticReadWrite(base, foffset));
             }
             else if (type == short.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleShorts.FieldStaticReadOnly(base, foffset)
-                       : new VarHandleShorts.FieldStaticReadWrite(base, foffset);
+                       : new VarHandleShorts.FieldStaticReadWrite(base, foffset));
             }
             else if (type == char.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleChars.FieldStaticReadOnly(base, foffset)
-                       : new VarHandleChars.FieldStaticReadWrite(base, foffset);
+                       : new VarHandleChars.FieldStaticReadWrite(base, foffset));
             }
             else if (type == int.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleInts.FieldStaticReadOnly(base, foffset)
-                       : new VarHandleInts.FieldStaticReadWrite(base, foffset);
+                       : new VarHandleInts.FieldStaticReadWrite(base, foffset));
             }
             else if (type == long.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleLongs.FieldStaticReadOnly(base, foffset)
-                       : new VarHandleLongs.FieldStaticReadWrite(base, foffset);
+                       : new VarHandleLongs.FieldStaticReadWrite(base, foffset));
             }
             else if (type == float.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleFloats.FieldStaticReadOnly(base, foffset)
-                       : new VarHandleFloats.FieldStaticReadWrite(base, foffset);
+                       : new VarHandleFloats.FieldStaticReadWrite(base, foffset));
             }
             else if (type == double.class) {
-                return f.isFinal() && !isWriteAllowedOnFinalFields
+                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleDoubles.FieldStaticReadOnly(base, foffset)
-                       : new VarHandleDoubles.FieldStaticReadWrite(base, foffset);
+                       : new VarHandleDoubles.FieldStaticReadWrite(base, foffset));
             }
             else {
                 throw new UnsupportedOperationException();
             }
         }
@@ -217,37 +225,37 @@
         if (!componentType.isPrimitive()) {
             // the redundant componentType.isValue() check is there to
             // minimize the performance impact to non-value array.
             // It should be removed when Unsafe::isFlattenedArray is intrinsified.
 
-            return componentType.isInlineClass() && UNSAFE.isFlattenedArray(arrayClass)
+            return maybeAdapt(componentType.isInlineClass() && UNSAFE.isFlattenedArray(arrayClass)
                 ? new VarHandleValues.Array(aoffset, ashift, arrayClass)
-                : new VarHandleReferences.Array(aoffset, ashift, arrayClass);
+                : new VarHandleReferences.Array(aoffset, ashift, arrayClass));
         }
         else if (componentType == boolean.class) {
-            return new VarHandleBooleans.Array(aoffset, ashift);
+            return maybeAdapt(new VarHandleBooleans.Array(aoffset, ashift));
         }
         else if (componentType == byte.class) {
-            return new VarHandleBytes.Array(aoffset, ashift);
+            return maybeAdapt(new VarHandleBytes.Array(aoffset, ashift));
         }
         else if (componentType == short.class) {
-            return new VarHandleShorts.Array(aoffset, ashift);
+            return maybeAdapt(new VarHandleShorts.Array(aoffset, ashift));
         }
         else if (componentType == char.class) {
-            return new VarHandleChars.Array(aoffset, ashift);
+            return maybeAdapt(new VarHandleChars.Array(aoffset, ashift));
         }
         else if (componentType == int.class) {
-            return new VarHandleInts.Array(aoffset, ashift);
+            return maybeAdapt(new VarHandleInts.Array(aoffset, ashift));
         }
         else if (componentType == long.class) {
-            return new VarHandleLongs.Array(aoffset, ashift);
+            return maybeAdapt(new VarHandleLongs.Array(aoffset, ashift));
         }
         else if (componentType == float.class) {
-            return new VarHandleFloats.Array(aoffset, ashift);
+            return maybeAdapt(new VarHandleFloats.Array(aoffset, ashift));
         }
         else if (componentType == double.class) {
-            return new VarHandleDoubles.Array(aoffset, ashift);
+            return maybeAdapt(new VarHandleDoubles.Array(aoffset, ashift));
         }
         else {
             throw new UnsupportedOperationException();
         }
     }
@@ -258,26 +266,26 @@
             throw new IllegalArgumentException("not an array: " + viewArrayClass);
 
         Class<?> viewComponentType = viewArrayClass.getComponentType();
 
         if (viewComponentType == long.class) {
-            return new VarHandleByteArrayAsLongs.ArrayHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsLongs.ArrayHandle(be));
         }
         else if (viewComponentType == int.class) {
-            return new VarHandleByteArrayAsInts.ArrayHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsInts.ArrayHandle(be));
         }
         else if (viewComponentType == short.class) {
-            return new VarHandleByteArrayAsShorts.ArrayHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsShorts.ArrayHandle(be));
         }
         else if (viewComponentType == char.class) {
-            return new VarHandleByteArrayAsChars.ArrayHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsChars.ArrayHandle(be));
         }
         else if (viewComponentType == double.class) {
-            return new VarHandleByteArrayAsDoubles.ArrayHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsDoubles.ArrayHandle(be));
         }
         else if (viewComponentType == float.class) {
-            return new VarHandleByteArrayAsFloats.ArrayHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsFloats.ArrayHandle(be));
         }
 
         throw new UnsupportedOperationException();
     }
 
@@ -287,26 +295,26 @@
             throw new IllegalArgumentException("not an array: " + viewArrayClass);
 
         Class<?> viewComponentType = viewArrayClass.getComponentType();
 
         if (viewComponentType == long.class) {
-            return new VarHandleByteArrayAsLongs.ByteBufferHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsLongs.ByteBufferHandle(be));
         }
         else if (viewComponentType == int.class) {
-            return new VarHandleByteArrayAsInts.ByteBufferHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsInts.ByteBufferHandle(be));
         }
         else if (viewComponentType == short.class) {
-            return new VarHandleByteArrayAsShorts.ByteBufferHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsShorts.ByteBufferHandle(be));
         }
         else if (viewComponentType == char.class) {
-            return new VarHandleByteArrayAsChars.ByteBufferHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsChars.ByteBufferHandle(be));
         }
         else if (viewComponentType == double.class) {
-            return new VarHandleByteArrayAsDoubles.ByteBufferHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsDoubles.ByteBufferHandle(be));
         }
         else if (viewComponentType == float.class) {
-            return new VarHandleByteArrayAsFloats.ByteBufferHandle(be);
+            return maybeAdapt(new VarHandleByteArrayAsFloats.ByteBufferHandle(be));
         }
 
         throw new UnsupportedOperationException();
     }
 
@@ -335,20 +343,261 @@
         long size = Wrapper.forPrimitiveType(carrier).bitWidth() / 8;
         boolean be = byteOrder == ByteOrder.BIG_ENDIAN;
 
         Map<Integer, MethodHandle> carrierFactory = ADDRESS_FACTORIES.get(carrier);
         MethodHandle fac = carrierFactory.computeIfAbsent(strides.length,
-                dims -> new AddressVarHandleGenerator(carrier, dims)
+                dims -> new MemoryAccessVarHandleGenerator(carrier, dims)
                             .generateHandleFactory());
 
         try {
-            return (VarHandle)fac.invoke(be, size, offset, alignmentMask, strides);
+            return maybeAdapt((VarHandle)fac.invoke(be, size, offset, alignmentMask, strides));
         } catch (Throwable ex) {
             throw new IllegalStateException(ex);
         }
     }
 
+    private static VarHandle maybeAdapt(VarHandle target) {
+        if (!VAR_HANDLE_IDENTITY_ADAPT) return target;
+        target = filterValue(target,
+                        MethodHandles.identity(target.varType()), MethodHandles.identity(target.varType()));
+        MethodType mtype = target.accessModeType(VarHandle.AccessMode.GET).dropParameterTypes(0, 1);
+        for (int i = 0 ; i < mtype.parameterCount() ; i++) {
+            target = filterCoordinates(target, i, MethodHandles.identity(mtype.parameterType(i)));
+        }
+        return target;
+    }
+
+    public static VarHandle filterValue(VarHandle target, MethodHandle filterToTarget, MethodHandle filterFromTarget) {
+        Objects.nonNull(target);
+        Objects.nonNull(filterToTarget);
+        Objects.nonNull(filterFromTarget);
+        //check that from/to filters do not throw checked exceptions
+        noCheckedExceptions(filterToTarget);
+        noCheckedExceptions(filterFromTarget);
+
+        //check that from/to filters have right signatures
+        if (filterFromTarget.type().parameterCount() != 1) {
+            throw newIllegalArgumentException("filterFromTarget filter type has wrong arity", filterFromTarget.type());
+        } else if (filterToTarget.type().parameterCount() != 1) {
+            throw newIllegalArgumentException("filterToTarget filter type has wrong arity", filterFromTarget.type());
+        } else if (filterFromTarget.type().parameterType(0) != filterToTarget.type().returnType() ||
+                filterToTarget.type().parameterType(0) != filterFromTarget.type().returnType()) {
+            throw newIllegalArgumentException("filterFromTarget and filterToTarget filter types do not match", filterFromTarget.type(), filterToTarget.type());
+        } else if (target.varType() != filterFromTarget.type().parameterType(0)) {
+            throw newIllegalArgumentException("filterFromTarget filter type does not match target var handle type", filterFromTarget.type(), target.varType());
+        } else if (target.varType() != filterToTarget.type().returnType()) {
+            throw newIllegalArgumentException("filterFromTarget filter type does not match target var handle type", filterToTarget.type(), target.varType());
+        }
+
+        return new IndirectVarHandle(target, filterFromTarget.type().returnType(), target.coordinateTypes().toArray(new Class<?>[0]),
+                (mode, modeHandle) -> {
+                    int lastParameterPos = modeHandle.type().parameterCount() - 1;
+                    return switch (mode.at) {
+                        case GET -> MethodHandles.filterReturnValue(modeHandle, filterFromTarget);
+                        case SET -> MethodHandles.filterArgument(modeHandle, lastParameterPos, filterToTarget);
+                        case GET_AND_UPDATE -> {
+                            MethodHandle adapter = MethodHandles.filterReturnValue(modeHandle, filterFromTarget);
+                            yield MethodHandles.filterArgument(adapter, lastParameterPos, filterToTarget);
+                        }
+                        case COMPARE_AND_EXCHANGE -> {
+                            MethodHandle adapter = MethodHandles.filterReturnValue(modeHandle, filterFromTarget);
+                            adapter = MethodHandles.filterArgument(adapter, lastParameterPos, filterToTarget);
+                            yield MethodHandles.filterArgument(adapter, lastParameterPos - 1, filterToTarget);
+                        }
+                        case COMPARE_AND_SET -> {
+                            MethodHandle adapter = MethodHandles.filterArgument(modeHandle, lastParameterPos, filterToTarget);
+                            yield MethodHandles.filterArgument(adapter, lastParameterPos - 1, filterToTarget);
+                        }
+                    };
+                });
+    }
+
+    public static VarHandle filterCoordinates(VarHandle target, int pos, MethodHandle... filters) {
+        Objects.nonNull(target);
+        Objects.nonNull(filters);
+
+        List<Class<?>> targetCoordinates = target.coordinateTypes();
+        if (pos < 0 || pos >= targetCoordinates.size()) {
+            throw newIllegalArgumentException("Invalid position " + pos + " for coordinate types", targetCoordinates);
+        } else if (pos + filters.length > targetCoordinates.size()) {
+            throw new IllegalArgumentException("Too many filters");
+        }
+
+        if (filters.length == 0) return target;
+
+        List<Class<?>> newCoordinates = new ArrayList<>(targetCoordinates);
+        for (int i = 0 ; i < filters.length ; i++) {
+            noCheckedExceptions(filters[i]);
+            MethodType filterType = filters[i].type();
+            if (filterType.parameterCount() != 1) {
+                throw newIllegalArgumentException("Invalid filter type " + filterType);
+            } else if (newCoordinates.get(pos + i) != filterType.returnType()) {
+                throw newIllegalArgumentException("Invalid filter type " + filterType + " for coordinate type " + newCoordinates.get(i));
+            }
+            newCoordinates.set(pos + i, filters[i].type().parameterType(0));
+        }
+
+        return new IndirectVarHandle(target, target.varType(), newCoordinates.toArray(new Class<?>[0]),
+                (mode, modeHandle) -> MethodHandles.filterArguments(modeHandle, 1 + pos, filters));
+    }
+
+    public static VarHandle insertCoordinates(VarHandle target, int pos, Object... values) {
+        Objects.nonNull(target);
+        Objects.nonNull(values);
+
+        List<Class<?>> targetCoordinates = target.coordinateTypes();
+        if (pos < 0 || pos >= targetCoordinates.size()) {
+            throw newIllegalArgumentException("Invalid position " + pos + " for coordinate types", targetCoordinates);
+        } else if (pos + values.length > targetCoordinates.size()) {
+            throw new IllegalArgumentException("Too many values");
+        }
+
+        if (values.length == 0) return target;
+
+        List<Class<?>> newCoordinates = new ArrayList<>(targetCoordinates);
+        for (int i = 0 ; i < values.length ; i++) {
+            Class<?> pt = newCoordinates.get(pos);
+            if (pt.isPrimitive()) {
+                Wrapper w = Wrapper.forPrimitiveType(pt);
+                w.convert(values[i], pt);
+            } else {
+                pt.cast(values[i]);
+            }
+            newCoordinates.remove(pos);
+        }
+
+        return new IndirectVarHandle(target, target.varType(), newCoordinates.toArray(new Class<?>[0]),
+                (mode, modeHandle) -> MethodHandles.insertArguments(modeHandle, 1 + pos, values));
+    }
+
+    public static VarHandle permuteCoordinates(VarHandle target, List<Class<?>> newCoordinates, int... reorder) {
+        Objects.nonNull(target);
+        Objects.nonNull(newCoordinates);
+        Objects.nonNull(reorder);
+
+        List<Class<?>> targetCoordinates = target.coordinateTypes();
+        MethodHandles.permuteArgumentChecks(reorder,
+                MethodType.methodType(void.class, newCoordinates),
+                MethodType.methodType(void.class, targetCoordinates));
+
+        return new IndirectVarHandle(target, target.varType(), newCoordinates.toArray(new Class<?>[0]),
+                (mode, modeHandle) ->
+                        MethodHandles.permuteArguments(modeHandle,
+                                methodTypeFor(mode.at, modeHandle.type(), targetCoordinates, newCoordinates),
+                                reorderArrayFor(mode.at, newCoordinates, reorder)));
+    }
+
+    private static int numTrailingArgs(VarHandle.AccessType at) {
+        return switch (at) {
+            case GET -> 0;
+            case GET_AND_UPDATE, SET -> 1;
+            case COMPARE_AND_SET, COMPARE_AND_EXCHANGE -> 2;
+        };
+    }
+
+    private static int[] reorderArrayFor(VarHandle.AccessType at, List<Class<?>> newCoordinates, int[] reorder) {
+        int numTrailingArgs = numTrailingArgs(at);
+        int[] adjustedReorder = new int[reorder.length + 1 + numTrailingArgs];
+        adjustedReorder[0] = 0;
+        for (int i = 0 ; i < reorder.length ; i++) {
+            adjustedReorder[i + 1] = reorder[i] + 1;
+        }
+        for (int i = 0 ; i < numTrailingArgs ; i++) {
+            adjustedReorder[i + reorder.length + 1] = i + newCoordinates.size() + 1;
+        }
+        return adjustedReorder;
+    }
+
+    private static MethodType methodTypeFor(VarHandle.AccessType at, MethodType oldType, List<Class<?>> oldCoordinates, List<Class<?>> newCoordinates) {
+        int numTrailingArgs = numTrailingArgs(at);
+        MethodType adjustedType = MethodType.methodType(oldType.returnType(), oldType.parameterType(0));
+        adjustedType = adjustedType.appendParameterTypes(newCoordinates);
+        for (int i = 0 ; i < numTrailingArgs ; i++) {
+            adjustedType = adjustedType.appendParameterTypes(oldType.parameterType(1 + oldCoordinates.size() + i));
+        }
+        return adjustedType;
+    }
+
+    public static VarHandle collectCoordinates(VarHandle target, int pos, MethodHandle filter) {
+        Objects.nonNull(target);
+        Objects.nonNull(filter);
+        noCheckedExceptions(filter);
+
+        List<Class<?>> targetCoordinates = target.coordinateTypes();
+        if (pos < 0 || pos >= targetCoordinates.size()) {
+            throw newIllegalArgumentException("Invalid position " + pos + " for coordinate types", targetCoordinates);
+        } else if (filter.type().returnType() == void.class) {
+            throw newIllegalArgumentException("Invalid filter type " + filter.type() + " ; filter cannot be void");
+        } else if (filter.type().returnType() != targetCoordinates.get(pos)) {
+            throw newIllegalArgumentException("Invalid filter type " + filter.type() + " for coordinate type " + targetCoordinates.get(pos));
+        }
+
+        List<Class<?>> newCoordinates = new ArrayList<>(targetCoordinates);
+        newCoordinates.remove(pos);
+        newCoordinates.addAll(pos, filter.type().parameterList());
+
+        return new IndirectVarHandle(target, target.varType(), newCoordinates.toArray(new Class<?>[0]),
+                (mode, modeHandle) -> MethodHandles.collectArguments(modeHandle, 1 + pos, filter));
+    }
+
+    public static VarHandle dropCoordinates(VarHandle target, int pos, Class<?>... valueTypes) {
+        Objects.nonNull(target);
+        Objects.nonNull(valueTypes);
+
+        List<Class<?>> targetCoordinates = target.coordinateTypes();
+        if (pos < 0 || pos > targetCoordinates.size()) {
+            throw newIllegalArgumentException("Invalid position " + pos + " for coordinate types", targetCoordinates);
+        }
+
+        if (valueTypes.length == 0) return target;
+
+        List<Class<?>> newCoordinates = new ArrayList<>(targetCoordinates);
+        newCoordinates.addAll(pos, List.of(valueTypes));
+
+        return new IndirectVarHandle(target, target.varType(), newCoordinates.toArray(new Class<?>[0]),
+                (mode, modeHandle) -> MethodHandles.dropArguments(modeHandle, 1 + pos, valueTypes));
+    }
+
+    private static void noCheckedExceptions(MethodHandle handle) {
+        if (handle instanceof DirectMethodHandle) {
+            DirectMethodHandle directHandle = (DirectMethodHandle)handle;
+            MethodHandleInfo info = MethodHandles.Lookup.IMPL_LOOKUP.revealDirect(directHandle);
+            Class<?>[] exceptionTypes = switch (info.getReferenceKind()) {
+                case MethodHandleInfo.REF_invokeInterface, MethodHandleInfo.REF_invokeSpecial,
+                        MethodHandleInfo.REF_invokeStatic, MethodHandleInfo.REF_invokeVirtual ->
+                        info.reflectAs(Method.class, MethodHandles.Lookup.IMPL_LOOKUP).getExceptionTypes();
+                case MethodHandleInfo.REF_newInvokeSpecial ->
+                        info.reflectAs(Constructor.class, MethodHandles.Lookup.IMPL_LOOKUP).getExceptionTypes();
+                case MethodHandleInfo.REF_getField, MethodHandleInfo.REF_getStatic,
+                        MethodHandleInfo.REF_putField, MethodHandleInfo.REF_putStatic -> null;
+                default -> throw new AssertionError("Cannot get here");
+            };
+            if (exceptionTypes != null) {
+                if (Stream.of(exceptionTypes).anyMatch(VarHandles::isCheckedException)) {
+                    throw newIllegalArgumentException("Cannot adapt a var handle with a method handle which throws checked exceptions");
+                }
+            }
+        } else if (handle instanceof DelegatingMethodHandle) {
+            noCheckedExceptions(((DelegatingMethodHandle)handle).getTarget());
+        } else {
+            //bound
+            BoundMethodHandle boundHandle = (BoundMethodHandle)handle;
+            for (int i = 0 ; i < boundHandle.fieldCount() ; i++) {
+                Object arg = boundHandle.arg(i);
+                if (arg instanceof MethodHandle){
+                    noCheckedExceptions((MethodHandle) arg);
+                }
+            }
+        }
+    }
+
+    private static boolean isCheckedException(Class<?> clazz) {
+        return Throwable.class.isAssignableFrom(clazz) &&
+                !RuntimeException.class.isAssignableFrom(clazz) &&
+                !Error.class.isAssignableFrom(clazz);
+    }
+
 //    /**
 //     * A helper program to generate the VarHandleGuards class with a set of
 //     * static guard methods each of which corresponds to a particular shape and
 //     * performs a type check of the symbolic type descriptor with the VarHandle
 //     * type descriptor before linking/invoking to the underlying operation as
@@ -381,11 +630,11 @@
 //
 //        static final String GUARD_METHOD_TEMPLATE =
 //                "@ForceInline\n" +
 //                "@LambdaForm.Compiled\n" +
 //                "final static <METHOD> throws Throwable {\n" +
-//                "    if (handle.vform.methodType_table[ad.type] == ad.symbolicMethodType) {\n" +
+//                "    if (handle.isDirect() && handle.vform.methodType_table[ad.type] == ad.symbolicMethodType) {\n" +
 //                "        <RESULT_ERASED>MethodHandle.linkToStatic(<LINK_TO_STATIC_ARGS>);<RETURN_ERASED>\n" +
 //                "    }\n" +
 //                "    else {\n" +
 //                "        MethodHandle mh = handle.getMethodHandle(ad.mode);\n" +
 //                "        <RETURN>mh.asType(ad.symbolicMethodTypeInvoker).invokeBasic(<LINK_TO_INVOKER_ARGS>);\n" +
@@ -394,14 +643,14 @@
 //
 //        static final String GUARD_METHOD_TEMPLATE_V =
 //                "@ForceInline\n" +
 //                "@LambdaForm.Compiled\n" +
 //                "final static <METHOD> throws Throwable {\n" +
-//                "    if (handle.vform.methodType_table[ad.type] == ad.symbolicMethodType) {\n" +
+//                "    if (handle.isDirect() && handle.vform.methodType_table[ad.type] == ad.symbolicMethodType) {\n" +
 //                "        MethodHandle.linkToStatic(<LINK_TO_STATIC_ARGS>);\n" +
 //                "    }\n" +
-//                "    else if (handle.vform.getMethodType_V(ad.type) == ad.symbolicMethodType) {\n" +
+//                "    else if (handle.isDirect() && handle.vform.getMethodType_V(ad.type) == ad.symbolicMethodType) {\n" +
 //                "        MethodHandle.linkToStatic(<LINK_TO_STATIC_ARGS>);\n" +
 //                "    }\n" +
 //                "    else {\n" +
 //                "        MethodHandle mh = handle.getMethodHandle(ad.mode);\n" +
 //                "        mh.asType(ad.symbolicMethodTypeInvoker).invokeBasic(<LINK_TO_INVOKER_ARGS>);\n" +
diff a/src/java.base/share/classes/java/lang/invoke/X-VarHandle.java.template b/src/java.base/share/classes/java/lang/invoke/X-VarHandle.java.template
--- a/src/java.base/share/classes/java/lang/invoke/X-VarHandle.java.template
+++ b/src/java.base/share/classes/java/lang/invoke/X-VarHandle.java.template
@@ -75,29 +75,33 @@
                 receiverType, fieldOffset, {#if[Object]?fieldType:$type$.class}).getName();
             return Optional.of(VarHandleDesc.ofField(receiverTypeRef.get(), name, fieldTypeRef.get()));
         }
 
         @ForceInline
-        static $type$ get(FieldInstanceReadOnly handle, Object holder) {
+        static $type$ get(VarHandle ob, Object holder) {
+            FieldInstanceReadOnly handle = (FieldInstanceReadOnly)ob;
             return UNSAFE.get$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                  handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
-        static $type$ getVolatile(FieldInstanceReadOnly handle, Object holder) {
+        static $type$ getVolatile(VarHandle ob, Object holder) {
+            FieldInstanceReadOnly handle = (FieldInstanceReadOnly)ob;
             return UNSAFE.get$Type$Volatile(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                  handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
-        static $type$ getOpaque(FieldInstanceReadOnly handle, Object holder) {
+        static $type$ getOpaque(VarHandle ob, Object holder) {
+            FieldInstanceReadOnly handle = (FieldInstanceReadOnly)ob;
             return UNSAFE.get$Type$Opaque(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                  handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
-        static $type$ getAcquire(FieldInstanceReadOnly handle, Object holder) {
+        static $type$ getAcquire(VarHandle ob, Object holder) {
+            FieldInstanceReadOnly handle = (FieldInstanceReadOnly)ob;
             return UNSAFE.get$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                  handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         static final VarForm FORM = new VarForm(FieldInstanceReadOnly.class, Object.class, $type$.class);
@@ -116,207 +120,234 @@
             return handle.fieldType.cast(value);
         }
 #end[Object]
 
         @ForceInline
-        static void set(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static void set(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             UNSAFE.put$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                              handle.fieldOffset{#if[Value]?, handle.fieldType},
                              {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static void setVolatile(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static void setVolatile(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             UNSAFE.put$Type$Volatile(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                      handle.fieldOffset{#if[Value]?, handle.fieldType},
                                      {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static void setOpaque(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static void setOpaque(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             UNSAFE.put$Type$Opaque(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                    handle.fieldOffset{#if[Value]?, handle.fieldType},
                                    {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static void setRelease(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static void setRelease(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             UNSAFE.put$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                     handle.fieldOffset{#if[Value]?, handle.fieldType},
                                     {#if[Object]?checkCast(handle, value):value});
         }
 #if[CAS]
 
         @ForceInline
-        static boolean compareAndSet(FieldInstanceReadWrite handle, Object holder, $type$ expected, $type$ value) {
+        static boolean compareAndSet(VarHandle ob, Object holder, $type$ expected, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.compareAndSet$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ compareAndExchange(FieldInstanceReadWrite handle, Object holder, $type$ expected, $type$ value) {
+        static $type$ compareAndExchange(VarHandle ob, Object holder, $type$ expected, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ compareAndExchangeAcquire(FieldInstanceReadWrite handle, Object holder, $type$ expected, $type$ value) {
+        static $type$ compareAndExchangeAcquire(VarHandle ob, Object holder, $type$ expected, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ compareAndExchangeRelease(FieldInstanceReadWrite handle, Object holder, $type$ expected, $type$ value) {
+        static $type$ compareAndExchangeRelease(VarHandle ob, Object holder, $type$ expected, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetPlain(FieldInstanceReadWrite handle, Object holder, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetPlain(VarHandle ob, Object holder, $type$ expected, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Plain(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSet(FieldInstanceReadWrite handle, Object holder, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSet(VarHandle ob, Object holder, $type$ expected, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetAcquire(FieldInstanceReadWrite handle, Object holder, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetAcquire(VarHandle ob, Object holder, $type$ expected, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetRelease(FieldInstanceReadWrite handle, Object holder, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetRelease(VarHandle ob, Object holder, $type$ expected, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSet(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndSet(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndSet$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                           handle.fieldOffset{#if[Value]?, handle.fieldType},
                                           {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSetAcquire(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndSetAcquire(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndSet$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                           handle.fieldOffset{#if[Value]?, handle.fieldType},
                                           {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSetRelease(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndSetRelease(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndSet$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                           handle.fieldOffset{#if[Value]?, handle.fieldType},
                                           {#if[Object]?checkCast(handle, value):value});
         }
 #end[CAS]
 #if[AtomicAdd]
 
         @ForceInline
-        static $type$ getAndAdd(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndAdd(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndAdd$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndAddAcquire(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndAddAcquire(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndAdd$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndAddRelease(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndAddRelease(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndAdd$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
 #end[AtomicAdd]
 #if[Bitwise]
 
         @ForceInline
-        static $type$ getAndBitwiseOr(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseOr(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseOr$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseOrRelease(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseOrRelease(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseOr$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseOrAcquire(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseOrAcquire(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseOr$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAnd(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseAnd(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseAnd$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAndRelease(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseAndRelease(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseAnd$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAndAcquire(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseAndAcquire(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseAnd$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXor(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseXor(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseXor$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXorRelease(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseXorRelease(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseXor$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXorAcquire(FieldInstanceReadWrite handle, Object holder, $type$ value) {
+        static $type$ getAndBitwiseXorAcquire(VarHandle ob, Object holder, $type$ value) {
+            FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndBitwiseXor$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
                                        handle.fieldOffset,
                                        value);
         }
 #end[Bitwise]
@@ -365,29 +396,33 @@
         final MethodType accessModeTypeUncached(AccessMode accessMode) {
             return accessMode.at.accessModeType(null, {#if[Object]?fieldType:$type$.class});
         }
 
         @ForceInline
-        static $type$ get(FieldStaticReadOnly handle) {
+        static $type$ get(VarHandle ob) {
+            FieldStaticReadOnly handle = (FieldStaticReadOnly)ob;
             return UNSAFE.get$Type$(handle.base,
                                  handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
-        static $type$ getVolatile(FieldStaticReadOnly handle) {
+        static $type$ getVolatile(VarHandle ob) {
+            FieldStaticReadOnly handle = (FieldStaticReadOnly)ob;
             return UNSAFE.get$Type$Volatile(handle.base,
                                  handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
-        static $type$ getOpaque(FieldStaticReadOnly handle) {
+        static $type$ getOpaque(VarHandle ob) {
+            FieldStaticReadOnly handle = (FieldStaticReadOnly)ob;
             return UNSAFE.get$Type$Opaque(handle.base,
                                  handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
-        static $type$ getAcquire(FieldStaticReadOnly handle) {
+        static $type$ getAcquire(VarHandle ob) {
+            FieldStaticReadOnly handle = (FieldStaticReadOnly)ob;
             return UNSAFE.get$Type$Acquire(handle.base,
                                  handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         static final VarForm FORM = new VarForm(FieldStaticReadOnly.class, null, $type$.class);
@@ -405,207 +440,234 @@
             return handle.fieldType.cast(value);
         }
 #end[Object]
 
         @ForceInline
-        static void set(FieldStaticReadWrite handle, $type$ value) {
+        static void set(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             UNSAFE.put$Type$(handle.base,
                              handle.fieldOffset{#if[Value]?, handle.fieldType},
                              {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static void setVolatile(FieldStaticReadWrite handle, $type$ value) {
+        static void setVolatile(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             UNSAFE.put$Type$Volatile(handle.base,
                                      handle.fieldOffset{#if[Value]?, handle.fieldType},
                                      {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static void setOpaque(FieldStaticReadWrite handle, $type$ value) {
+        static void setOpaque(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             UNSAFE.put$Type$Opaque(handle.base,
                                    handle.fieldOffset{#if[Value]?, handle.fieldType},
                                    {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static void setRelease(FieldStaticReadWrite handle, $type$ value) {
+        static void setRelease(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             UNSAFE.put$Type$Release(handle.base,
                                     handle.fieldOffset{#if[Value]?, handle.fieldType},
                                     {#if[Object]?checkCast(handle, value):value});
         }
 #if[CAS]
 
         @ForceInline
-        static boolean compareAndSet(FieldStaticReadWrite handle, $type$ expected, $type$ value) {
+        static boolean compareAndSet(VarHandle ob, $type$ expected, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.compareAndSet$Type$(handle.base,
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
 
         @ForceInline
-        static $type$ compareAndExchange(FieldStaticReadWrite handle, $type$ expected, $type$ value) {
+        static $type$ compareAndExchange(VarHandle ob, $type$ expected, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$(handle.base,
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ compareAndExchangeAcquire(FieldStaticReadWrite handle, $type$ expected, $type$ value) {
+        static $type$ compareAndExchangeAcquire(VarHandle ob, $type$ expected, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$Acquire(handle.base,
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ compareAndExchangeRelease(FieldStaticReadWrite handle, $type$ expected, $type$ value) {
+        static $type$ compareAndExchangeRelease(VarHandle ob, $type$ expected, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$Release(handle.base,
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetPlain(FieldStaticReadWrite handle, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetPlain(VarHandle ob, $type$ expected, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Plain(handle.base,
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSet(FieldStaticReadWrite handle, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSet(VarHandle ob, $type$ expected, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$(handle.base,
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetAcquire(FieldStaticReadWrite handle, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetAcquire(VarHandle ob, $type$ expected, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Acquire(handle.base,
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetRelease(FieldStaticReadWrite handle, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetRelease(VarHandle ob, $type$ expected, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Release(handle.base,
                                                handle.fieldOffset{#if[Object]?, handle.fieldType},
                                                {#if[Object]?checkCast(handle, expected):expected},
                                                {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSet(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndSet(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndSet$Type$(handle.base,
                                           handle.fieldOffset{#if[Value]?, handle.fieldType},
                                           {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSetAcquire(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndSetAcquire(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndSet$Type$Acquire(handle.base,
                                           handle.fieldOffset{#if[Value]?, handle.fieldType},
                                           {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSetRelease(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndSetRelease(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndSet$Type$Release(handle.base,
                                           handle.fieldOffset{#if[Value]?, handle.fieldType},
                                           {#if[Object]?checkCast(handle, value):value});
         }
 #end[CAS]
 #if[AtomicAdd]
 
         @ForceInline
-        static $type$ getAndAdd(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndAdd(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndAdd$Type$(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndAddAcquire(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndAddAcquire(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndAdd$Type$Acquire(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndAddRelease(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndAddRelease(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndAdd$Type$Release(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 #end[AtomicAdd]
 #if[Bitwise]
 
         @ForceInline
-        static $type$ getAndBitwiseOr(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseOr(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseOr$Type$(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseOrRelease(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseOrRelease(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseOr$Type$Release(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseOrAcquire(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseOrAcquire(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseOr$Type$Acquire(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAnd(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseAnd(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseAnd$Type$(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAndRelease(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseAndRelease(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseAnd$Type$Release(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAndAcquire(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseAndAcquire(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseAnd$Type$Acquire(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXor(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseXor(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseXor$Type$(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXorRelease(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseXorRelease(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseXor$Type$Release(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXorAcquire(FieldStaticReadWrite handle, $type$ value) {
+        static $type$ getAndBitwiseXorAcquire(VarHandle ob, $type$ value) {
+            FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndBitwiseXor$Type$Acquire(handle.base,
                                        handle.fieldOffset,
                                        value);
         }
 #end[Bitwise]
@@ -678,21 +740,23 @@
             }
         }
 #end[Object]
 
         @ForceInline
-        static $type$ get(Array handle, Object oarray, int index) {
+        static $type$ get(VarHandle ob, Object oarray, int index) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
             return array[index];
         }
 
         @ForceInline
-        static void set(Array handle, Object oarray, int index, $type$ value) {
+        static void set(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -706,11 +770,12 @@
 #end[Reference]
             array[index] = {#if[Object]?runtimeTypeCheck(handle, array, value):value};
         }
 
         @ForceInline
-        static $type$ getVolatile(Array handle, Object oarray, int index) {
+        static $type$ getVolatile(VarHandle ob, Object oarray, int index) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -724,11 +789,12 @@
             return UNSAFE.get$Type$Volatile(array,
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType});
         }
 
         @ForceInline
-        static void setVolatile(Array handle, Object oarray, int index, $type$ value) {
+        static void setVolatile(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -744,11 +810,12 @@
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static $type$ getOpaque(Array handle, Object oarray, int index) {
+        static $type$ getOpaque(VarHandle ob, Object oarray, int index) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -762,11 +829,12 @@
             return UNSAFE.get$Type$Opaque(array,
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType});
         }
 
         @ForceInline
-        static void setOpaque(Array handle, Object oarray, int index, $type$ value) {
+        static void setOpaque(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -782,11 +850,12 @@
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static $type$ getAcquire(Array handle, Object oarray, int index) {
+        static $type$ getAcquire(VarHandle ob, Object oarray, int index) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -800,11 +869,12 @@
             return UNSAFE.get$Type$Acquire(array,
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType});
         }
 
         @ForceInline
-        static void setRelease(Array handle, Object oarray, int index, $type$ value) {
+        static void setRelease(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -821,11 +891,12 @@
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 #if[CAS]
 
         @ForceInline
-        static boolean compareAndSet(Array handle, Object oarray, int index, $type$ expected, $type$ value) {
+        static boolean compareAndSet(VarHandle ob, Object oarray, int index, $type$ expected, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -841,11 +912,12 @@
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static $type$ compareAndExchange(Array handle, Object oarray, int index, $type$ expected, $type$ value) {
+        static $type$ compareAndExchange(VarHandle ob, Object oarray, int index, $type$ expected, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -861,11 +933,12 @@
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static $type$ compareAndExchangeAcquire(Array handle, Object oarray, int index, $type$ expected, $type$ value) {
+        static $type$ compareAndExchangeAcquire(VarHandle ob, Object oarray, int index, $type$ expected, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -881,11 +954,12 @@
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static $type$ compareAndExchangeRelease(Array handle, Object oarray, int index, $type$ expected, $type$ value) {
+        static $type$ compareAndExchangeRelease(VarHandle ob, Object oarray, int index, $type$ expected, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -901,11 +975,12 @@
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetPlain(Array handle, Object oarray, int index, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetPlain(VarHandle ob, Object oarray, int index, $type$ expected, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -921,11 +996,12 @@
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSet(Array handle, Object oarray, int index, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSet(VarHandle ob, Object oarray, int index, $type$ expected, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -941,11 +1017,12 @@
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetAcquire(Array handle, Object oarray, int index, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetAcquire(VarHandle ob, Object oarray, int index, $type$ expected, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -961,11 +1038,12 @@
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static boolean weakCompareAndSetRelease(Array handle, Object oarray, int index, $type$ expected, $type$ value) {
+        static boolean weakCompareAndSetRelease(VarHandle ob, Object oarray, int index, $type$ expected, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -981,11 +1059,12 @@
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSet(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndSet(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -1000,11 +1079,12 @@
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSetAcquire(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndSetAcquire(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -1019,11 +1099,12 @@
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
-        static $type$ getAndSetRelease(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndSetRelease(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
@@ -1040,101 +1121,113 @@
         }
 #end[CAS]
 #if[AtomicAdd]
 
         @ForceInline
-        static $type$ getAndAdd(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndAdd(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndAdd$Type$(array,
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                     value);
         }
 
         @ForceInline
-        static $type$ getAndAddAcquire(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndAddAcquire(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndAdd$Type$Acquire(array,
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                     value);
         }
 
         @ForceInline
-        static $type$ getAndAddRelease(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndAddRelease(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndAdd$Type$Release(array,
                     (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                     value);
         }
 #end[AtomicAdd]
 #if[Bitwise]
 
         @ForceInline
-        static $type$ getAndBitwiseOr(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseOr(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseOr$Type$(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseOrRelease(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseOrRelease(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseOr$Type$Release(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseOrAcquire(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseOrAcquire(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseOr$Type$Acquire(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAnd(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseAnd(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseAnd$Type$(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAndRelease(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseAndRelease(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseAnd$Type$Release(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseAndAcquire(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseAndAcquire(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseAnd$Type$Acquire(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXor(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseXor(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseXor$Type$(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXorRelease(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseXorRelease(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseXor$Type$Release(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
 
         @ForceInline
-        static $type$ getAndBitwiseXorAcquire(Array handle, Object oarray, int index, $type$ value) {
+        static $type$ getAndBitwiseXorAcquire(VarHandle ob, Object oarray, int index, $type$ value) {
+            Array handle = (Array)ob;
             $type$[] array = ($type$[]) oarray;
             return UNSAFE.getAndBitwiseXor$Type$Acquire(array,
                                        (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
                                        value);
         }
diff a/src/java.base/share/classes/module-info.java b/src/java.base/share/classes/module-info.java
--- a/src/java.base/share/classes/module-info.java
+++ b/src/java.base/share/classes/module-info.java
@@ -226,10 +226,11 @@
     exports jdk.internal.vm to
         jdk.internal.jvmstat,
         jdk.management.agent;
     exports jdk.internal.vm.annotation to
         jdk.internal.vm.ci,
+        jdk.incubator.foreign,
         jdk.unsupported;
     exports jdk.internal.util.jar to
         jdk.jartool;
     exports jdk.internal.util.xml to
         jdk.jfr;
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
@@ -2900,11 +2900,11 @@
                             types.findDescriptorType(s).getParameterTypes().length() > 0 &&
                             types.findDescriptorType(s).getParameterTypes().length() ==
                             types.findDescriptorType(t).getParameterTypes().length()) {
                         potentiallyAmbiguous = true;
                     } else {
-                        break;
+                        return;
                     }
                 }
                 args1 = args1.tail;
                 args2 = args2.tail;
             }
diff a/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotVMConfig.java b/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotVMConfig.java
--- a/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotVMConfig.java
+++ b/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotVMConfig.java
@@ -56,12 +56,10 @@
         String arch = Services.getSavedProperty("os.arch");
         switch (arch) {
             case "x86_64":
                 return "amd64";
 
-            case "sparcv9":
-                return "sparc";
             default:
                 return arch;
         }
     }
 
diff a/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.test/src/org/graalvm/compiler/hotspot/test/CheckGraalIntrinsics.java b/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.test/src/org/graalvm/compiler/hotspot/test/CheckGraalIntrinsics.java
--- a/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.test/src/org/graalvm/compiler/hotspot/test/CheckGraalIntrinsics.java
+++ b/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.test/src/org/graalvm/compiler/hotspot/test/CheckGraalIntrinsics.java
@@ -59,11 +59,10 @@
 import jdk.vm.ci.hotspot.VMIntrinsicMethod;
 import jdk.vm.ci.meta.MetaAccessProvider;
 import jdk.vm.ci.meta.MetaUtil;
 import jdk.vm.ci.meta.MethodHandleAccessProvider.IntrinsicMethod;
 import jdk.vm.ci.meta.ResolvedJavaMethod;
-import jdk.vm.ci.sparc.SPARC;
 
 /**
  * Checks the intrinsics implemented by Graal against the set of intrinsics declared by HotSpot. The
  * purpose of this test is to detect when new intrinsics are added to HotSpot and process them
  * appropriately in Graal. This will be achieved by working through {@link #toBeInvestigated} and
@@ -371,14 +370,10 @@
             }
             if (!config.useFMAIntrinsics) {
                 add(ignore,
                                 "java/lang/Math.fma(DDD)D",
                                 "java/lang/Math.fma(FFF)F");
-            } else if (arch instanceof SPARC) {
-                add(toBeInvestigated,
-                                "java/lang/Math.fma(DDD)D",
-                                "java/lang/Math.fma(FFF)F");
             }
         }
 
         if (isJDK10OrHigher()) {
             add(toBeInvestigated,
diff a/test/hotspot/jtreg/ProblemList.txt b/test/hotspot/jtreg/ProblemList.txt
--- a/test/hotspot/jtreg/ProblemList.txt
+++ b/test/hotspot/jtreg/ProblemList.txt
@@ -27,14 +27,14 @@
 # they may fail due to known reason. The reason (CR#) must be mandatory specified.
 #
 # List items are testnames followed by labels, all MUST BE commented
 #   as to why they are here and use a label:
 #     generic-all   Problems on all platforms
-#     generic-ARCH  Where ARCH is one of: sparc, sparcv9, x64, i586, etc.
-#     OSNAME-all    Where OSNAME is one of: solaris, linux, windows, macosx, aix
-#     OSNAME-ARCH   Specific on to one OSNAME and ARCH, e.g. solaris-amd64
-#     OSNAME-REV    Specific on to one OSNAME and REV, e.g. solaris-5.8
+#     generic-ARCH  Where ARCH is one of: x64, i586, ppc64, ppc64le, s390x etc.
+#     OSNAME-all    Where OSNAME is one of: linux, windows, macosx, aix
+#     OSNAME-ARCH   Specific on to one OSNAME and ARCH, e.g. macosx-x64
+#     OSNAME-REV    Specific on to one OSNAME and REV, e.g. macosx-10.7.4
 #
 # More than one label is allowed but must be on the same line.
 #
 #############################################################################
 
@@ -48,13 +48,10 @@
 compiler/jvmci/compilerToVM/GetFlagValueTest.java 8204459 generic-all
 compiler/jvmci/compilerToVM/GetResolvedJavaTypeTest.java 8158860 generic-all
 compiler/jvmci/compilerToVM/InvalidateInstalledCodeTest.java 8163894 generic-all
 compiler/tiered/LevelTransitionTest.java 8067651 generic-all
 
-compiler/types/correctness/CorrectnessTest.java 8225620 solaris-sparcv9
-compiler/types/correctness/OffTest.java         8225620 solaris-sparcv9
-
 compiler/c2/Test6852078.java 8194310 generic-all
 
 compiler/cpuflags/TestAESIntrinsicsOnSupportedConfig.java 8190680 generic-all
 
 compiler/runtime/Test8168712.java 8211769,8211771 generic-ppc64,generic-ppc64le,linux-s390x
@@ -171,12 +168,10 @@
 # :hotspot_runtime
 
 runtime/jni/terminatedThread/TestTerminatedThread.java 8219652 aix-ppc64
 runtime/ReservedStack/ReservedStackTest.java 8231031 generic-all
 
-runtime/cds/appcds/SignedJar.java 8245264 generic-all
-
 # Valhalla TODO:
 runtime/CompressedOops/CompressedClassPointers.java 8210258 generic-all
 runtime/RedefineTests/RedefineLeak.java 8205032 generic-all
 runtime/SharedArchiveFile/BootAppendTests.java 8210258 generic-all
 runtime/SharedArchiveFile/CdsDifferentCompactStrings.java 8210258 generic-all
@@ -206,11 +201,10 @@
 serviceability/sa/TestInstanceKlassSizeForInterface.java 8230664 linux-ppc64le,linux-ppc64
 serviceability/sa/TestRevPtrsForInvokeDynamic.java 8241235 generic-all
 
 serviceability/jvmti/HeapMonitor/MyPackage/HeapMonitorStatIntervalTest.java 8214032 generic-all
 serviceability/jvmti/HeapMonitor/MyPackage/HeapMonitorStatArrayCorrectnessTest.java 8224150 generic-all
-serviceability/jvmti/HiddenClass/P/Q/HiddenClassSigTest.java 8244571 generic-all
 
 # Valhalla TODO:
 serviceability/sa/ClhsdbCDSCore.java 8190936 generic-all
 serviceability/sa/ClhsdbCDSJstackPrintAll.java 8190936 generic-all
 serviceability/sa/ClhsdbFindPC.java 8190936 generic-all
diff a/test/jdk/TEST.groups b/test/jdk/TEST.groups
--- a/test/jdk/TEST.groups
+++ b/test/jdk/TEST.groups
@@ -205,11 +205,10 @@
     java/security
 
 jdk_security2 = \
     javax/crypto \
     javax/xml/crypto \
-    com/oracle/security/ucrypto \
     com/sun/crypto
 
 jdk_security3 = \
     javax/security  \
     -javax/security/auth/kerberos \
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeBoolean.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeBoolean.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeBoolean.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeBoolean.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeBoolean
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeBoolean
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeBoolean
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeBoolean
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeBoolean
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeByte.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeByte.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeByte.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeByte.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeByte
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeByte
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeByte
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeByte
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeByte
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeChar.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeChar.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeChar.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeChar.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeChar
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeChar
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeChar
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeChar
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeChar
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeDouble.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeDouble.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeDouble.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeDouble.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeDouble
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeDouble
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeDouble
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeDouble
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeDouble
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeFloat.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeFloat.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeFloat.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeFloat.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeFloat
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeFloat
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeFloat
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeFloat
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeFloat
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeInt.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeInt.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeInt.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeInt.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeInt
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeInt
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeInt
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeInt
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeInt
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeLong.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeLong.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeLong.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeLong.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeLong
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeLong
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeLong
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeLong
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeLong
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeShort.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeShort.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeShort.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeShort.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeShort
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeShort
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeShort
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeShort
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeShort
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeString.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeString.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeString.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeString.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -25,11 +25,13 @@
 
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeString
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodTypeString
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeString
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodTypeString
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeString
  */
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
diff a/test/jdk/java/lang/invoke/VarHandles/X-VarHandleTestMethodType.java.template b/test/jdk/java/lang/invoke/VarHandles/X-VarHandleTestMethodType.java.template
--- a/test/jdk/java/lang/invoke/VarHandles/X-VarHandleTestMethodType.java.template
+++ b/test/jdk/java/lang/invoke/VarHandles/X-VarHandleTestMethodType.java.template
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2015, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2015, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -33,11 +33,13 @@
 #else[Value]
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodType$Type$
- * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodType$Type$
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodType$Type$
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodType$Type$
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodType$Type$
  */
 #end[Value]
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
