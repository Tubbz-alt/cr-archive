<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt;
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   MemBarNode* mb = barrier-&gt;as_MemBar();
 1371 
 1372   if (mb-&gt;trailing_load()) {
 1373     return true;
 1374   }
 1375 
 1376   if (mb-&gt;trailing_load_store()) {
 1377     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1378     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1379     return is_CAS(load_store-&gt;Opcode(), true);
 1380   }
 1381 
 1382   return false;
 1383 }
 1384 
 1385 bool needs_acquiring_load(const Node *n)
 1386 {
 1387   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1388   LoadNode *ld = n-&gt;as_Load();
 1389   return ld-&gt;is_acquire();
 1390 }
 1391 
 1392 bool unnecessary_release(const Node *n)
 1393 {
 1394   assert((n-&gt;is_MemBar() &amp;&amp;
 1395           n-&gt;Opcode() == Op_MemBarRelease),
 1396          &quot;expecting a release membar&quot;);
 1397 
 1398   MemBarNode *barrier = n-&gt;as_MemBar();
 1399   if (!barrier-&gt;leading()) {
 1400     return false;
 1401   } else {
 1402     Node* trailing = barrier-&gt;trailing_membar();
 1403     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1404     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1405     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1406 
 1407     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1408     if (mem-&gt;is_Store()) {
 1409       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1410       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1411       return true;
 1412     } else {
 1413       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1415       return is_CAS(mem-&gt;Opcode(), true);
 1416     }
 1417   }
 1418   return false;
 1419 }
 1420 
 1421 bool unnecessary_volatile(const Node *n)
 1422 {
 1423   // assert n-&gt;is_MemBar();
 1424   MemBarNode *mbvol = n-&gt;as_MemBar();
 1425 
 1426   bool release = mbvol-&gt;trailing_store();
 1427   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1428 #ifdef ASSERT
 1429   if (release) {
 1430     Node* leading = mbvol-&gt;leading_membar();
 1431     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1432     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1433     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1434   }
 1435 #endif
 1436 
 1437   return release;
 1438 }
 1439 
 1440 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt;
 1441 
 1442 bool needs_releasing_store(const Node *n)
 1443 {
 1444   // assert n-&gt;is_Store();
 1445   StoreNode *st = n-&gt;as_Store();
 1446   return st-&gt;trailing_membar() != NULL;
 1447 }
 1448 
 1449 // predicate controlling translation of CAS
 1450 //
 1451 // returns true if CAS needs to use an acquiring load otherwise false
 1452 
 1453 bool needs_acquiring_load_exclusive(const Node *n)
 1454 {
 1455   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1456   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1457   if (is_CAS(n-&gt;Opcode(), false)) {
 1458     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1459   } else {
 1460     return ldst-&gt;trailing_membar() != NULL;
 1461   }
 1462 
 1463   // so we can just return true here
 1464   return true;
 1465 }
 1466 
 1467 #define __ _masm.
 1468 
 1469 // advance declarations for helper functions to convert register
 1470 // indices to register objects
 1471 
 1472 // the ad file has to provide implementations of certain methods
 1473 // expected by the generic code
 1474 //
 1475 // REQUIRED FUNCTIONALITY
 1476 
 1477 //=============================================================================
 1478 
 1479 // !!!!! Special hack to get all types of calls to specify the byte offset
 1480 //       from the start of the call to the point where the return address
 1481 //       will point.
 1482 
 1483 int MachCallStaticJavaNode::ret_addr_offset()
 1484 {
 1485   // call should be a simple bl
 1486   int off = 4;
 1487   return off;
 1488 }
 1489 
 1490 int MachCallDynamicJavaNode::ret_addr_offset()
 1491 {
 1492   return 16; // movz, movk, movk, bl
 1493 }
 1494 
 1495 int MachCallRuntimeNode::ret_addr_offset() {
 1496   // for generated stubs the call will be
 1497   //   far_call(addr)
 1498   // for real runtime callouts it will be six instructions
 1499   // see aarch64_enc_java_to_runtime
 1500   //   adr(rscratch2, retaddr)
 1501   //   lea(rscratch1, RuntimeAddress(addr)
 1502   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1503   //   blr(rscratch1)
 1504   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1505   if (cb) {
 1506     return MacroAssembler::far_branch_size();
 1507   } else {
 1508     return 6 * NativeInstruction::instruction_size;
 1509   }
 1510 }
 1511 
 1512 // Indicate if the safepoint node needs the polling page as an input
 1513 
 1514 // the shared code plants the oop data at the start of the generated
 1515 // code for the safepoint node and that needs ot be at the load
 1516 // instruction itself. so we cannot plant a mov of the safepoint poll
 1517 // address followed by a load. setting this to true means the mov is
 1518 // scheduled as a prior instruction. that&#39;s better for scheduling
 1519 // anyway.
 1520 
 1521 bool SafePointNode::needs_polling_address_input()
 1522 {
 1523   return true;
 1524 }
 1525 
 1526 //=============================================================================
 1527 
 1528 #ifndef PRODUCT
 1529 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1530   st-&gt;print(&quot;BREAKPOINT&quot;);
 1531 }
 1532 #endif
 1533 
 1534 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1535   C2_MacroAssembler _masm(&amp;cbuf);
 1536   __ brk(0);
 1537 }
 1538 
 1539 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1540   return MachNode::size(ra_);
 1541 }
 1542 
 1543 //=============================================================================
 1544 
 1545 #ifndef PRODUCT
 1546   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1547     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1548   }
 1549 #endif
 1550 
 1551   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1552     C2_MacroAssembler _masm(&amp;cbuf);
 1553     for (int i = 0; i &lt; _count; i++) {
 1554       __ nop();
 1555     }
 1556   }
 1557 
 1558   uint MachNopNode::size(PhaseRegAlloc*) const {
 1559     return _count * NativeInstruction::instruction_size;
 1560   }
 1561 
 1562 //=============================================================================
 1563 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1564 
 1565 int ConstantTable::calculate_table_base_offset() const {
 1566   return 0;  // absolute addressing, no offset
 1567 }
 1568 
 1569 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1570 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1571   ShouldNotReachHere();
 1572 }
 1573 
 1574 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1575   // Empty encoding
 1576 }
 1577 
 1578 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1579   return 0;
 1580 }
 1581 
 1582 #ifndef PRODUCT
 1583 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1584   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1585 }
 1586 #endif
 1587 
 1588 #ifndef PRODUCT
 1589 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1590   Compile* C = ra_-&gt;C;
 1591 
 1592   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1593 
 1594   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1595     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1596 
 1597   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1598     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1599     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1600     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1601   } else {
 1602     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1603     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1604     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1605     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1606   }
 1607   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {
 1608     st-&gt;print(&quot;\n\t&quot;);
 1609     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);
 1610     st-&gt;print(&quot;dmb ishld\n\t&quot;);
 1611     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);
 1612     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);
 1613     st-&gt;print(&quot;b.eq skip&quot;);
 1614     st-&gt;print(&quot;\n\t&quot;);
 1615     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);
 1616     st-&gt;print(&quot;b skip\n\t&quot;);
 1617     st-&gt;print(&quot;guard: int\n\t&quot;);
 1618     st-&gt;print(&quot;\n\t&quot;);
 1619     st-&gt;print(&quot;skip:\n\t&quot;);
 1620   }
 1621 }
 1622 #endif
 1623 
 1624 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1625   Compile* C = ra_-&gt;C;
 1626   C2_MacroAssembler _masm(&amp;cbuf);
 1627 
 1628   __ verified_entry(C, 0);
 1629   __ bind(*_verified_entry);
 1630   // n.b. frame size includes space for return pc and rfp
 1631   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();
 1632   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1633 
 1634   // insert a nop at the start of the prolog so we can patch in a
 1635   // branch if we need to invalidate the method later
 1636   __ nop();
 1637 
 1638   if (C-&gt;clinit_barrier_on_entry()) {
 1639     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1640 
 1641     Label L_skip_barrier;
 1642 
 1643     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1644     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1645     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1646     __ bind(L_skip_barrier);
 1647   }
 1648 
 1649   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
 1650   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1651     __ generate_stack_overflow_check(bangsize);
 1652 
 1653   __ build_frame(framesize);
 1654 
 1655   if (C-&gt;stub_function() == NULL) {
 1656     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 1657     bs-&gt;nmethod_entry_barrier(&amp;_masm);
 1658   }
 1659 
 1660   if (VerifyStackAtCalls) {
 1661     Unimplemented();
 1662   }
 1663 
 1664   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1665 
 1666   if (C-&gt;has_mach_constant_base_node()) {
 1667     // NOTE: We set the table base offset here because users might be
 1668     // emitted before MachConstantBaseNode.
 1669     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1670     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1671   }
 1672 }
 1673 
 1674 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1675 {
 1676   return MachNode::size(ra_); // too many variables; just compute it
 1677                               // the hard way
 1678 }
 1679 
 1680 int MachPrologNode::reloc() const
 1681 {
 1682   return 0;
 1683 }
 1684 
 1685 //=============================================================================
 1686 
 1687 #ifndef PRODUCT
 1688 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1689   Compile* C = ra_-&gt;C;
 1690   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1691 
 1692   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1693 
 1694   if (framesize == 0) {
 1695     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1696   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1697     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1698     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1699   } else {
 1700     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1701     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1702     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1703   }
 1704 
 1705   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1706     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1707     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1708     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1709   }
 1710 }
 1711 #endif
 1712 
 1713 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1714   Compile* C = ra_-&gt;C;
 1715   C2_MacroAssembler _masm(&amp;cbuf);
 1716   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1717 
 1718   __ remove_frame(framesize);
 1719 
 1720   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1721     __ reserved_stack_check();
 1722   }
 1723 
 1724   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1725     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1726   }
 1727 }
 1728 
 1729 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1730   // Variable size. Determine dynamically.
 1731   return MachNode::size(ra_);
 1732 }
 1733 
 1734 int MachEpilogNode::reloc() const {
 1735   // Return number of relocatable values contained in this instruction.
 1736   return 1; // 1 for polling page.
 1737 }
 1738 
 1739 const Pipeline * MachEpilogNode::pipeline() const {
 1740   return MachNode::pipeline_class();
 1741 }
 1742 
 1743 //=============================================================================
 1744 
 1745 // Figure out which register class each belongs in: rc_int, rc_float or
 1746 // rc_stack.
 1747 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1748 
 1749 static enum RC rc_class(OptoReg::Name reg) {
 1750 
 1751   if (reg == OptoReg::Bad) {
 1752     return rc_bad;
 1753   }
 1754 
 1755   // we have 30 int registers * 2 halves
 1756   // (rscratch1 and rscratch2 are omitted)
 1757   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1758 
 1759   if (reg &lt; slots_of_int_registers) {
 1760     return rc_int;
 1761   }
 1762 
 1763   // we have 32 float register * 4 halves
 1764   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1765     return rc_float;
 1766   }
 1767 
 1768   // Between float regs &amp; stack is the flags regs.
 1769   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1770 
 1771   return rc_stack;
 1772 }
 1773 
 1774 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1775   Compile* C = ra_-&gt;C;
 1776 
 1777   // Get registers to move.
 1778   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1779   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1780   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1781   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1782 
 1783   enum RC src_hi_rc = rc_class(src_hi);
 1784   enum RC src_lo_rc = rc_class(src_lo);
 1785   enum RC dst_hi_rc = rc_class(dst_hi);
 1786   enum RC dst_lo_rc = rc_class(dst_lo);
 1787 
 1788   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1789 
 1790   if (src_hi != OptoReg::Bad) {
 1791     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1792            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1793            &quot;expected aligned-adjacent pairs&quot;);
 1794   }
 1795 
 1796   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1797     return 0;            // Self copy, no move.
 1798   }
 1799 
 1800   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1801               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1802   int src_offset = ra_-&gt;reg2offset(src_lo);
 1803   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1804 
 1805   if (bottom_type()-&gt;isa_vect() != NULL) {
 1806     uint ireg = ideal_reg();
 1807     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1808     if (cbuf) {
 1809       C2_MacroAssembler _masm(cbuf);
 1810       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1811       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1812         // stack-&gt;stack
 1813         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1814         if (ireg == Op_VecD) {
 1815           __ unspill(rscratch1, true, src_offset);
 1816           __ spill(rscratch1, true, dst_offset);
 1817         } else {
 1818           __ spill_copy128(src_offset, dst_offset);
 1819         }
 1820       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1821         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1822                ireg == Op_VecD ? __ T8B : __ T16B,
 1823                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1824       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1825         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1826                        ireg == Op_VecD ? __ D : __ Q,
 1827                        ra_-&gt;reg2offset(dst_lo));
 1828       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1829         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1830                        ireg == Op_VecD ? __ D : __ Q,
 1831                        ra_-&gt;reg2offset(src_lo));
 1832       } else {
 1833         ShouldNotReachHere();
 1834       }
 1835     }
 1836   } else if (cbuf) {
 1837     C2_MacroAssembler _masm(cbuf);
 1838     switch (src_lo_rc) {
 1839     case rc_int:
 1840       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1841         if (is64) {
 1842             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1843                    as_Register(Matcher::_regEncode[src_lo]));
 1844         } else {
 1845             C2_MacroAssembler _masm(cbuf);
 1846             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1847                     as_Register(Matcher::_regEncode[src_lo]));
 1848         }
 1849       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1850         if (is64) {
 1851             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1852                      as_Register(Matcher::_regEncode[src_lo]));
 1853         } else {
 1854             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         }
 1857       } else {                    // gpr --&gt; stack spill
 1858         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1859         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1860       }
 1861       break;
 1862     case rc_float:
 1863       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1864         if (is64) {
 1865             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1866                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1867         } else {
 1868             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         }
 1871       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1872           if (cbuf) {
 1873             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1874                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1875         } else {
 1876             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         }
 1879       } else {                    // fpr --&gt; stack spill
 1880         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1881         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1882                  is64 ? __ D : __ S, dst_offset);
 1883       }
 1884       break;
 1885     case rc_stack:
 1886       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1887         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1888       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1889         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1890                    is64 ? __ D : __ S, src_offset);
 1891       } else {                    // stack --&gt; stack copy
 1892         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1893         __ unspill(rscratch1, is64, src_offset);
 1894         __ spill(rscratch1, is64, dst_offset);
 1895       }
 1896       break;
 1897     default:
 1898       assert(false, &quot;bad rc_class for spill&quot;);
 1899       ShouldNotReachHere();
 1900     }
 1901   }
 1902 
 1903   if (st) {
 1904     st-&gt;print(&quot;spill &quot;);
 1905     if (src_lo_rc == rc_stack) {
 1906       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1907     } else {
 1908       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1909     }
 1910     if (dst_lo_rc == rc_stack) {
 1911       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1912     } else {
 1913       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1914     }
 1915     if (bottom_type()-&gt;isa_vect() != NULL) {
 1916       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1917     } else {
 1918       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1919     }
 1920   }
 1921 
 1922   return 0;
 1923 
 1924 }
 1925 
 1926 #ifndef PRODUCT
 1927 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1928   if (!ra_)
 1929     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1930   else
 1931     implementation(NULL, ra_, false, st);
 1932 }
 1933 #endif
 1934 
 1935 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1936   implementation(&amp;cbuf, ra_, false, NULL);
 1937 }
 1938 
 1939 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1940   return MachNode::size(ra_);
 1941 }
 1942 
 1943 //=============================================================================
 1944 
 1945 #ifndef PRODUCT
 1946 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1947   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1948   int reg = ra_-&gt;get_reg_first(this);
 1949   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1950             Matcher::regName[reg], offset);
 1951 }
 1952 #endif
 1953 
 1954 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1955   C2_MacroAssembler _masm(&amp;cbuf);
 1956 
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg    = ra_-&gt;get_encode(this);
 1959 
 1960   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1961     __ add(as_Register(reg), sp, offset);
 1962   } else {
 1963     ShouldNotReachHere();
 1964   }
 1965 }
 1966 
 1967 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1968   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1969   return 4;
 1970 }
 1971 
 1972 ///=============================================================================
 1973 #ifndef PRODUCT
 1974 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1975 {
 1976   st-&gt;print_cr(&quot;# MachVEPNode&quot;);
 1977   if (!_verified) {
 1978     st-&gt;print_cr(&quot;\t load_class&quot;);
 1979   } else {
 1980     st-&gt;print_cr(&quot;\t unpack_value_arg&quot;);
 1981   }
 1982 }
 1983 #endif
 1984 
 1985 void MachVEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1986 {
 1987   MacroAssembler _masm(&amp;cbuf);
 1988 
 1989   if (!_verified) {
 1990     Label skip;
 1991     __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 1992     __ br(Assembler::EQ, skip);
 1993       __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 1994     __ bind(skip);
 1995 
 1996   } else {
 1997     // Unpack value type args passed as oop and then jump to
 1998     // the verified entry point (skipping the unverified entry).
 1999     __ unpack_value_args(ra_-&gt;C, _receiver_only);
 2000     __ b(*_verified_entry);
 2001   }
 2002 }
 2003 
 2004 
 2005 uint MachVEPNode::size(PhaseRegAlloc* ra_) const
 2006 {
 2007   return MachNode::size(ra_); // too many variables; just compute it the hard way
 2008 }
 2009 
 2010 
 2011 //=============================================================================
 2012 #ifndef PRODUCT
 2013 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 2014 {
 2015   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 2016   if (UseCompressedClassPointers) {
 2017     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2018     if (CompressedKlassPointers::shift() != 0) {
 2019       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 2020     }
 2021   } else {
 2022    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2023   }
 2024   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 2025   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2026 }
 2027 #endif
 2028 
 2029 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2030 {
 2031   // This is the unverified entry point.
 2032   C2_MacroAssembler _masm(&amp;cbuf);
 2033   Label skip;
 2034 
 2035   // UseCompressedClassPointers logic are inside cmp_klass
 2036   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2037 
 2038   // TODO
 2039   // can we avoid this skip and still use a reloc?
 2040   __ br(Assembler::EQ, skip);
 2041   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2042   __ bind(skip);
 2043 }
 2044 
 2045 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2046 {
 2047   return MachNode::size(ra_);
 2048 }
 2049 
 2050 // REQUIRED EMIT CODE
 2051 
 2052 //=============================================================================
 2053 
 2054 // Emit exception handler code.
 2055 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2056 {
 2057   // mov rscratch1 #exception_blob_entry_point
 2058   // br rscratch1
 2059   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2060   // That&#39;s why we must use the macroassembler to generate a handler.
 2061   C2_MacroAssembler _masm(&amp;cbuf);
 2062   address base = __ start_a_stub(size_exception_handler());
 2063   if (base == NULL) {
 2064     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2065     return 0;  // CodeBuffer::expand failed
 2066   }
 2067   int offset = __ offset();
 2068   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2069   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2070   __ end_a_stub();
 2071   return offset;
 2072 }
 2073 
 2074 // Emit deopt handler code.
 2075 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2076 {
 2077   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2078   // That&#39;s why we must use the macroassembler to generate a handler.
 2079   C2_MacroAssembler _masm(&amp;cbuf);
 2080   address base = __ start_a_stub(size_deopt_handler());
 2081   if (base == NULL) {
 2082     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2083     return 0;  // CodeBuffer::expand failed
 2084   }
 2085   int offset = __ offset();
 2086 
 2087   __ adr(lr, __ pc());
 2088   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2089 
 2090   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2091   __ end_a_stub();
 2092   return offset;
 2093 }
 2094 
 2095 // REQUIRED MATCHER CODE
 2096 
 2097 //=============================================================================
 2098 
 2099 const bool Matcher::match_rule_supported(int opcode) {
 2100   if (!has_match_rule(opcode))
 2101     return false;
 2102 
 2103   bool ret_value = true;
 2104   switch (opcode) {
 2105     case Op_CacheWB:
 2106     case Op_CacheWBPreSync:
 2107     case Op_CacheWBPostSync:
 2108       if (!VM_Version::supports_data_cache_line_flush()) {
 2109         ret_value = false;
 2110       }
 2111       break;
 2112   }
 2113 
 2114   return ret_value; // Per default match rules are supported.
 2115 }
 2116 
 2117 // Identify extra cases that we might want to provide match rules for vector nodes and
 2118 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2119 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2120   if (!match_rule_supported(opcode)) {
 2121     return false;
 2122   }
 2123 
 2124   // Special cases which require vector length
 2125   switch (opcode) {
 2126     case Op_MulAddVS2VI: {
 2127       if (vlen != 4) {
 2128         return false;
 2129       }
 2130       break;
 2131     }
 2132   }
 2133 
 2134   return true; // Per default match rules are supported.
 2135 }
 2136 
 2137 const bool Matcher::has_predicated_vectors(void) {
 2138   return false;
 2139 }
 2140 
 2141 const int Matcher::float_pressure(int default_pressure_threshold) {
 2142   return default_pressure_threshold;
 2143 }
 2144 
 2145 int Matcher::regnum_to_fpu_offset(int regnum)
 2146 {
 2147   Unimplemented();
 2148   return 0;
 2149 }
 2150 
 2151 // Is this branch offset short enough that a short branch can be used?
 2152 //
 2153 // NOTE: If the platform does not provide any short branch variants, then
 2154 //       this method should return false for offset 0.
 2155 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2156   // The passed offset is relative to address of the branch.
 2157 
 2158   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2159 }
 2160 
 2161 const bool Matcher::isSimpleConstant64(jlong value) {
 2162   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2163   // Probably always true, even if a temp register is required.
 2164   return true;
 2165 }
 2166 
 2167 // true just means we have fast l2f conversion
 2168 const bool Matcher::convL2FSupported(void) {
 2169   return true;
 2170 }
 2171 
 2172 // Vector width in bytes.
 2173 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2174   int size = MIN2(16,(int)MaxVectorSize);
 2175   // Minimum 2 values in vector
 2176   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2177   // But never &lt; 4
 2178   if (size &lt; 4) size = 0;
 2179   return size;
 2180 }
 2181 
 2182 // Limits on vector size (number of elements) loaded into vector.
 2183 const int Matcher::max_vector_size(const BasicType bt) {
 2184   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2185 }
 2186 const int Matcher::min_vector_size(const BasicType bt) {
 2187 //  For the moment limit the vector size to 8 bytes
 2188     int size = 8 / type2aelembytes(bt);
 2189     if (size &lt; 2) size = 2;
 2190     return size;
 2191 }
 2192 
 2193 // Vector ideal reg.
 2194 const uint Matcher::vector_ideal_reg(int len) {
 2195   switch(len) {
 2196     case  8: return Op_VecD;
 2197     case 16: return Op_VecX;
 2198   }
 2199   ShouldNotReachHere();
 2200   return 0;
 2201 }
 2202 
 2203 // AES support not yet implemented
 2204 const bool Matcher::pass_original_key_for_aes() {
 2205   return false;
 2206 }
 2207 
 2208 // aarch64 supports misaligned vectors store/load.
 2209 const bool Matcher::misaligned_vectors_ok() {
 2210   return true;
 2211 }
 2212 
 2213 // false =&gt; size gets scaled to BytesPerLong, ok.
 2214 const bool Matcher::init_array_count_is_in_bytes = false;
 2215 
 2216 // Use conditional move (CMOVL)
 2217 const int Matcher::long_cmove_cost() {
 2218   // long cmoves are no more expensive than int cmoves
 2219   return 0;
 2220 }
 2221 
 2222 const int Matcher::float_cmove_cost() {
 2223   // float cmoves are no more expensive than int cmoves
 2224   return 0;
 2225 }
 2226 
 2227 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2228 const bool Matcher::require_postalloc_expand = false;
 2229 
 2230 // Do we need to mask the count passed to shift instructions or does
 2231 // the cpu only look at the lower 5/6 bits anyway?
 2232 const bool Matcher::need_masked_shift_count = false;
 2233 
 2234 // No support for generic vector operands.
 2235 const bool Matcher::supports_generic_vector_operands  = false;
 2236 
 2237 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2238   ShouldNotReachHere(); // generic vector operands not supported
 2239   return NULL;
 2240 }
 2241 
 2242 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2243   ShouldNotReachHere();  // generic vector operands not supported
 2244   return false;
 2245 }
 2246 
 2247 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2248   ShouldNotReachHere();  // generic vector operands not supported
 2249   return false;
 2250 }
 2251 
 2252 // This affects two different things:
 2253 //  - how Decode nodes are matched
 2254 //  - how ImplicitNullCheck opportunities are recognized
 2255 // If true, the matcher will try to remove all Decodes and match them
 2256 // (as operands) into nodes. NullChecks are not prepared to deal with
 2257 // Decodes by final_graph_reshaping().
 2258 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2259 // for a NullCheck. The matcher matches the Decode node into a register.
 2260 // Implicit_null_check optimization moves the Decode along with the
 2261 // memory operation back up before the NullCheck.
 2262 bool Matcher::narrow_oop_use_complex_address() {
 2263   return CompressedOops::shift() == 0;
 2264 }
 2265 
 2266 bool Matcher::narrow_klass_use_complex_address() {
 2267 // TODO
 2268 // decide whether we need to set this to true
 2269   return false;
 2270 }
 2271 
 2272 bool Matcher::const_oop_prefer_decode() {
 2273   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2274   return CompressedOops::base() == NULL;
 2275 }
 2276 
 2277 bool Matcher::const_klass_prefer_decode() {
 2278   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2279   return CompressedKlassPointers::base() == NULL;
 2280 }
 2281 
 2282 // Is it better to copy float constants, or load them directly from
 2283 // memory?  Intel can load a float constant from a direct address,
 2284 // requiring no extra registers.  Most RISCs will have to materialize
 2285 // an address into a register first, so they would do better to copy
 2286 // the constant from stack.
 2287 const bool Matcher::rematerialize_float_constants = false;
 2288 
 2289 // If CPU can load and store mis-aligned doubles directly then no
 2290 // fixup is needed.  Else we split the double into 2 integer pieces
 2291 // and move it piece-by-piece.  Only happens when passing doubles into
 2292 // C code as the Java calling convention forces doubles to be aligned.
 2293 const bool Matcher::misaligned_doubles_ok = true;
 2294 
 2295 // No-op on amd64
 2296 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2297   Unimplemented();
 2298 }
 2299 
 2300 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2301 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2302 
 2303 // Are floats converted to double when stored to stack during
 2304 // deoptimization?
 2305 bool Matcher::float_in_double() { return false; }
 2306 
 2307 // Do ints take an entire long register or just half?
 2308 // The relevant question is how the int is callee-saved:
 2309 // the whole long is written but de-opt&#39;ing will have to extract
 2310 // the relevant 32 bits.
 2311 const bool Matcher::int_in_long = true;
 2312 
 2313 // Return whether or not this register is ever used as an argument.
 2314 // This function is used on startup to build the trampoline stubs in
 2315 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2316 // call in the trampoline, and arguments in those registers not be
 2317 // available to the callee.
 2318 bool Matcher::can_be_java_arg(int reg)
 2319 {
 2320   return
 2321     reg ==  R0_num || reg == R0_H_num ||
 2322     reg ==  R1_num || reg == R1_H_num ||
 2323     reg ==  R2_num || reg == R2_H_num ||
 2324     reg ==  R3_num || reg == R3_H_num ||
 2325     reg ==  R4_num || reg == R4_H_num ||
 2326     reg ==  R5_num || reg == R5_H_num ||
 2327     reg ==  R6_num || reg == R6_H_num ||
 2328     reg ==  R7_num || reg == R7_H_num ||
 2329     reg ==  V0_num || reg == V0_H_num ||
 2330     reg ==  V1_num || reg == V1_H_num ||
 2331     reg ==  V2_num || reg == V2_H_num ||
 2332     reg ==  V3_num || reg == V3_H_num ||
 2333     reg ==  V4_num || reg == V4_H_num ||
 2334     reg ==  V5_num || reg == V5_H_num ||
 2335     reg ==  V6_num || reg == V6_H_num ||
 2336     reg ==  V7_num || reg == V7_H_num;
 2337 }
 2338 
 2339 bool Matcher::is_spillable_arg(int reg)
 2340 {
 2341   return can_be_java_arg(reg);
 2342 }
 2343 
 2344 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2345   return false;
 2346 }
 2347 
 2348 RegMask Matcher::divI_proj_mask() {
 2349   ShouldNotReachHere();
 2350   return RegMask();
 2351 }
 2352 
 2353 // Register for MODI projection of divmodI.
 2354 RegMask Matcher::modI_proj_mask() {
 2355   ShouldNotReachHere();
 2356   return RegMask();
 2357 }
 2358 
 2359 // Register for DIVL projection of divmodL.
 2360 RegMask Matcher::divL_proj_mask() {
 2361   ShouldNotReachHere();
 2362   return RegMask();
 2363 }
 2364 
 2365 // Register for MODL projection of divmodL.
 2366 RegMask Matcher::modL_proj_mask() {
 2367   ShouldNotReachHere();
 2368   return RegMask();
 2369 }
 2370 
 2371 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2372   return FP_REG_mask();
 2373 }
 2374 
 2375 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2376   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2377     Node* u = addp-&gt;fast_out(i);
 2378     if (u-&gt;is_Mem()) {
 2379       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2380       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2381       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2382         return false;
 2383       }
 2384     }
 2385   }
 2386   return true;
 2387 }
 2388 
 2389 const bool Matcher::convi2l_type_required = false;
 2390 
 2391 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2392 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2393   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2394     mstack.push(m, Visit);           // m = ShiftCntV
 2395     return true;
 2396   }
 2397   return false;
 2398 }
 2399 
 2400 // Should the Matcher clone shifts on addressing modes, expecting them
 2401 // to be subsumed into complex addressing expressions or compute them
 2402 // into registers?
 2403 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2404   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2405     return true;
 2406   }
 2407 
 2408   Node *off = m-&gt;in(AddPNode::Offset);
 2409   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2410       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2411       // Are there other uses besides address expressions?
 2412       !is_visited(off)) {
 2413     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2414     mstack.push(off-&gt;in(2), Visit);
 2415     Node *conv = off-&gt;in(1);
 2416     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2417         // Are there other uses besides address expressions?
 2418         !is_visited(conv)) {
 2419       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2420       mstack.push(conv-&gt;in(1), Pre_Visit);
 2421     } else {
 2422       mstack.push(conv, Pre_Visit);
 2423     }
 2424     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2425     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2426     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2427     return true;
 2428   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2429              // Are there other uses besides address expressions?
 2430              !is_visited(off)) {
 2431     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2432     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2433     mstack.push(off-&gt;in(1), Pre_Visit);
 2434     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2435     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2436     return true;
 2437   }
 2438   return false;
 2439 }
 2440 
 2441 void Compile::reshape_address(AddPNode* addp) {
 2442 }
 2443 
 2444 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2445   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2446   {                                                                     \
 2447     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2448     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2449     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2450     __ INSN(REG, as_Register(BASE));                                    \
 2451   }
 2452 
 2453 
 2454 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2455   {
 2456     Address::extend scale;
 2457 
 2458     // Hooboy, this is fugly.  We need a way to communicate to the
 2459     // encoder that the index needs to be sign extended, so we have to
 2460     // enumerate all the cases.
 2461     switch (opcode) {
 2462     case INDINDEXSCALEDI2L:
 2463     case INDINDEXSCALEDI2LN:
 2464     case INDINDEXI2L:
 2465     case INDINDEXI2LN:
 2466       scale = Address::sxtw(size);
 2467       break;
 2468     default:
 2469       scale = Address::lsl(size);
 2470     }
 2471 
 2472     if (index == -1) {
 2473       return Address(base, disp);
 2474     } else {
 2475       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2476       return Address(base, as_Register(index), scale);
 2477     }
 2478   }
 2479 
 2480 
 2481 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2482 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2483 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2484 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2485                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2486 
 2487   // Used for all non-volatile memory accesses.  The use of
 2488   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2489   // offsets is something of a kludge.
 2490   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2491                         Register reg, int opcode,
 2492                         Register base, int index, int scale, int disp,
 2493                         int size_in_memory)
 2494   {
 2495     Address addr = mem2address(opcode, base, index, scale, disp);
 2496     if (addr.getMode() == Address::base_plus_offset) {
 2497       /* If we get an out-of-range offset it is a bug in the compiler,
 2498          so we assert here. */
 2499       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2500              &quot;c2 compiler bug&quot;);
 2501       /* Fix up any out-of-range offsets. */
 2502       assert_different_registers(rscratch1, base);
 2503       assert_different_registers(rscratch1, reg);
 2504       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2505     }
 2506     (masm.*insn)(reg, addr);
 2507   }
 2508 
 2509   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2510                         FloatRegister reg, int opcode,
 2511                         Register base, int index, int size, int disp,
 2512                         int size_in_memory)
 2513   {
 2514     Address::extend scale;
 2515 
 2516     switch (opcode) {
 2517     case INDINDEXSCALEDI2L:
 2518     case INDINDEXSCALEDI2LN:
 2519       scale = Address::sxtw(size);
 2520       break;
 2521     default:
 2522       scale = Address::lsl(size);
 2523     }
 2524 
 2525     if (index == -1) {
 2526       /* If we get an out-of-range offset it is a bug in the compiler,
 2527          so we assert here. */
 2528       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2529       /* Fix up any out-of-range offsets. */
 2530       assert_different_registers(rscratch1, base);
 2531       Address addr = Address(base, disp);
 2532       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2533       (masm.*insn)(reg, addr);
 2534     } else {
 2535       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2536       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2537     }
 2538   }
 2539 
 2540   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2541                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2542                         int opcode, Register base, int index, int size, int disp)
 2543   {
 2544     if (index == -1) {
 2545       (masm.*insn)(reg, T, Address(base, disp));
 2546     } else {
 2547       assert(disp == 0, &quot;unsupported address mode&quot;);
 2548       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2549     }
 2550   }
 2551 
 2552 %}
 2553 
 2554 
 2555 
 2556 //----------ENCODING BLOCK-----------------------------------------------------
 2557 // This block specifies the encoding classes used by the compiler to
 2558 // output byte streams.  Encoding classes are parameterized macros
 2559 // used by Machine Instruction Nodes in order to generate the bit
 2560 // encoding of the instruction.  Operands specify their base encoding
 2561 // interface with the interface keyword.  There are currently
 2562 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2563 // COND_INTER.  REG_INTER causes an operand to generate a function
 2564 // which returns its register number when queried.  CONST_INTER causes
 2565 // an operand to generate a function which returns the value of the
 2566 // constant when queried.  MEMORY_INTER causes an operand to generate
 2567 // four functions which return the Base Register, the Index Register,
 2568 // the Scale Value, and the Offset Value of the operand when queried.
 2569 // COND_INTER causes an operand to generate six functions which return
 2570 // the encoding code (ie - encoding bits for the instruction)
 2571 // associated with each basic boolean condition for a conditional
 2572 // instruction.
 2573 //
 2574 // Instructions specify two basic values for encoding.  Again, a
 2575 // function is available to check if the constant displacement is an
 2576 // oop. They use the ins_encode keyword to specify their encoding
 2577 // classes (which must be a sequence of enc_class names, and their
 2578 // parameters, specified in the encoding block), and they use the
 2579 // opcode keyword to specify, in order, their primary, secondary, and
 2580 // tertiary opcode.  Only the opcode sections which a particular
 2581 // instruction needs for encoding need to be specified.
 2582 encode %{
 2583   // Build emit functions for each basic byte or larger field in the
 2584   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2585   // from C++ code in the enc_class source block.  Emit functions will
 2586   // live in the main source block for now.  In future, we can
 2587   // generalize this by adding a syntax that specifies the sizes of
 2588   // fields in an order, so that the adlc can build the emit functions
 2589   // automagically
 2590 
 2591   // catch all for unimplemented encodings
 2592   enc_class enc_unimplemented %{
 2593     C2_MacroAssembler _masm(&amp;cbuf);
 2594     __ unimplemented(&quot;C2 catch all&quot;);
 2595   %}
 2596 
 2597   // BEGIN Non-volatile memory access
 2598 
 2599   // This encoding class is generated automatically from ad_encode.m4.
 2600   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2601   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2602     Register dst_reg = as_Register($dst$$reg);
 2603     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2604                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2605   %}
 2606 
 2607   // This encoding class is generated automatically from ad_encode.m4.
 2608   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2609   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2610     Register dst_reg = as_Register($dst$$reg);
 2611     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2612                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2613   %}
 2614 
 2615   // This encoding class is generated automatically from ad_encode.m4.
 2616   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2617   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2618     Register dst_reg = as_Register($dst$$reg);
 2619     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2620                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2621   %}
 2622 
 2623   // This encoding class is generated automatically from ad_encode.m4.
 2624   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2625   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2626     Register dst_reg = as_Register($dst$$reg);
 2627     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2628                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2629   %}
 2630 
 2631   // This encoding class is generated automatically from ad_encode.m4.
 2632   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2633   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2634     Register dst_reg = as_Register($dst$$reg);
 2635     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2636                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2637   %}
 2638 
 2639   // This encoding class is generated automatically from ad_encode.m4.
 2640   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2641   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2642     Register dst_reg = as_Register($dst$$reg);
 2643     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2644                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2645   %}
 2646 
 2647   // This encoding class is generated automatically from ad_encode.m4.
 2648   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2649   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2650     Register dst_reg = as_Register($dst$$reg);
 2651     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2652                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2653   %}
 2654 
 2655   // This encoding class is generated automatically from ad_encode.m4.
 2656   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2657   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2658     Register dst_reg = as_Register($dst$$reg);
 2659     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2660                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2661   %}
 2662 
 2663   // This encoding class is generated automatically from ad_encode.m4.
 2664   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2665   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2666     Register dst_reg = as_Register($dst$$reg);
 2667     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2668                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2669   %}
 2670 
 2671   // This encoding class is generated automatically from ad_encode.m4.
 2672   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2673   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2674     Register dst_reg = as_Register($dst$$reg);
 2675     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2676                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2677   %}
 2678 
 2679   // This encoding class is generated automatically from ad_encode.m4.
 2680   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2681   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2682     Register dst_reg = as_Register($dst$$reg);
 2683     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2684                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2685   %}
 2686 
 2687   // This encoding class is generated automatically from ad_encode.m4.
 2688   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2689   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2690     Register dst_reg = as_Register($dst$$reg);
 2691     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2692                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2693   %}
 2694 
 2695   // This encoding class is generated automatically from ad_encode.m4.
 2696   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2697   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2698     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2699     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2700                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2701   %}
 2702 
 2703   // This encoding class is generated automatically from ad_encode.m4.
 2704   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2705   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2706     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2707     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2708                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2709   %}
 2710 
 2711   // This encoding class is generated automatically from ad_encode.m4.
 2712   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2713   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2714     Register src_reg = as_Register($src$$reg);
 2715     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2716                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2717   %}
 2718 
 2719   // This encoding class is generated automatically from ad_encode.m4.
 2720   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2721   enc_class aarch64_enc_strb0(memory1 mem) %{
 2722     C2_MacroAssembler _masm(&amp;cbuf);
 2723     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2724                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2725   %}
 2726 
 2727   // This encoding class is generated automatically from ad_encode.m4.
 2728   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2729   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2730     Register src_reg = as_Register($src$$reg);
 2731     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2732                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2733   %}
 2734 
 2735   // This encoding class is generated automatically from ad_encode.m4.
 2736   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2737   enc_class aarch64_enc_strh0(memory2 mem) %{
 2738     C2_MacroAssembler _masm(&amp;cbuf);
 2739     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2740                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2741   %}
 2742 
 2743   // This encoding class is generated automatically from ad_encode.m4.
 2744   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2745   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2746     Register src_reg = as_Register($src$$reg);
 2747     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2748                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2749   %}
 2750 
 2751   // This encoding class is generated automatically from ad_encode.m4.
 2752   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2753   enc_class aarch64_enc_strw0(memory4 mem) %{
 2754     C2_MacroAssembler _masm(&amp;cbuf);
 2755     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2756                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2757   %}
 2758 
 2759   // This encoding class is generated automatically from ad_encode.m4.
 2760   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2761   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2762     Register src_reg = as_Register($src$$reg);
 2763     // we sometimes get asked to store the stack pointer into the
 2764     // current thread -- we cannot do that directly on AArch64
 2765     if (src_reg == r31_sp) {
 2766       C2_MacroAssembler _masm(&amp;cbuf);
 2767       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2768       __ mov(rscratch2, sp);
 2769       src_reg = rscratch2;
 2770     }
 2771     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2772                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2773   %}
 2774 
 2775   // This encoding class is generated automatically from ad_encode.m4.
 2776   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2777   enc_class aarch64_enc_str0(memory8 mem) %{
 2778     C2_MacroAssembler _masm(&amp;cbuf);
 2779     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2780                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2781   %}
 2782 
 2783   // This encoding class is generated automatically from ad_encode.m4.
 2784   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2785   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2786     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2787     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2788                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2789   %}
 2790 
 2791   // This encoding class is generated automatically from ad_encode.m4.
 2792   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2793   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2794     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2795     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2796                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2797   %}
 2798 
 2799   // This encoding class is generated automatically from ad_encode.m4.
 2800   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2801   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2802     C2_MacroAssembler _masm(&amp;cbuf);
 2803     address con = (address)$src$$constant;
 2804     // need to do this the hard way until we can manage relocs
 2805     // for 32 bit constants
 2806     __ movoop(rscratch2, (jobject)con);
 2807     if (con) __ encode_heap_oop_not_null(rscratch2);
 2808     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2809                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2810   %}
 2811 
 2812   // This encoding class is generated automatically from ad_encode.m4.
 2813   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2814   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2815     C2_MacroAssembler _masm(&amp;cbuf);
 2816     address con = (address)$src$$constant;
 2817     // need to do this the hard way until we can manage relocs
 2818     // for 32 bit constants
 2819     __ movoop(rscratch2, (jobject)con);
 2820     __ encode_klass_not_null(rscratch2);
 2821     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2822                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2823   %}
 2824 
 2825   // This encoding class is generated automatically from ad_encode.m4.
 2826   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2827   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2828       C2_MacroAssembler _masm(&amp;cbuf);
 2829       __ membar(Assembler::StoreStore);
 2830       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2831                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2832   %}
 2833 
 2834   // END Non-volatile memory access
 2835 
 2836   // Vector loads and stores
 2837   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2838     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2839     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2840        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2841   %}
 2842 
 2843   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2844     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2845     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2846        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2847   %}
 2848 
 2849   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2850     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2851     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2852        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2853   %}
 2854 
 2855   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2856     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2857     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2858        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2859   %}
 2860 
 2861   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2862     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2863     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2864        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2865   %}
 2866 
 2867   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2868     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2869     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2870        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2871   %}
 2872 
 2873   // volatile loads and stores
 2874 
 2875   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2876     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2877                  rscratch1, stlrb);
 2878   %}
 2879 
 2880   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2881     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2882                  rscratch1, stlrh);
 2883   %}
 2884 
 2885   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2886     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2887                  rscratch1, stlrw);
 2888   %}
 2889 
 2890 
 2891   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2892     Register dst_reg = as_Register($dst$$reg);
 2893     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2894              rscratch1, ldarb);
 2895     __ sxtbw(dst_reg, dst_reg);
 2896   %}
 2897 
 2898   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2899     Register dst_reg = as_Register($dst$$reg);
 2900     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2901              rscratch1, ldarb);
 2902     __ sxtb(dst_reg, dst_reg);
 2903   %}
 2904 
 2905   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2906     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2907              rscratch1, ldarb);
 2908   %}
 2909 
 2910   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2911     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2912              rscratch1, ldarb);
 2913   %}
 2914 
 2915   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2916     Register dst_reg = as_Register($dst$$reg);
 2917     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2918              rscratch1, ldarh);
 2919     __ sxthw(dst_reg, dst_reg);
 2920   %}
 2921 
 2922   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2923     Register dst_reg = as_Register($dst$$reg);
 2924     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2925              rscratch1, ldarh);
 2926     __ sxth(dst_reg, dst_reg);
 2927   %}
 2928 
 2929   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2930     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2931              rscratch1, ldarh);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2935     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2936              rscratch1, ldarh);
 2937   %}
 2938 
 2939   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2940     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2941              rscratch1, ldarw);
 2942   %}
 2943 
 2944   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2945     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2946              rscratch1, ldarw);
 2947   %}
 2948 
 2949   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2950     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2951              rscratch1, ldar);
 2952   %}
 2953 
 2954   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2955     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2956              rscratch1, ldarw);
 2957     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2958   %}
 2959 
 2960   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2961     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2962              rscratch1, ldar);
 2963     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2964   %}
 2965 
 2966   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2967     Register src_reg = as_Register($src$$reg);
 2968     // we sometimes get asked to store the stack pointer into the
 2969     // current thread -- we cannot do that directly on AArch64
 2970     if (src_reg == r31_sp) {
 2971       C2_MacroAssembler _masm(&amp;cbuf);
 2972       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2973       __ mov(rscratch2, sp);
 2974       src_reg = rscratch2;
 2975     }
 2976     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2977                  rscratch1, stlr);
 2978   %}
 2979 
 2980   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2981     {
 2982       C2_MacroAssembler _masm(&amp;cbuf);
 2983       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2984       __ fmovs(rscratch2, src_reg);
 2985     }
 2986     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2987                  rscratch1, stlrw);
 2988   %}
 2989 
 2990   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2991     {
 2992       C2_MacroAssembler _masm(&amp;cbuf);
 2993       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2994       __ fmovd(rscratch2, src_reg);
 2995     }
 2996     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2997                  rscratch1, stlr);
 2998   %}
 2999 
 3000   // synchronized read/update encodings
 3001 
 3002   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 3003     C2_MacroAssembler _masm(&amp;cbuf);
 3004     Register dst_reg = as_Register($dst$$reg);
 3005     Register base = as_Register($mem$$base);
 3006     int index = $mem$$index;
 3007     int scale = $mem$$scale;
 3008     int disp = $mem$$disp;
 3009     if (index == -1) {
 3010        if (disp != 0) {
 3011         __ lea(rscratch1, Address(base, disp));
 3012         __ ldaxr(dst_reg, rscratch1);
 3013       } else {
 3014         // TODO
 3015         // should we ever get anything other than this case?
 3016         __ ldaxr(dst_reg, base);
 3017       }
 3018     } else {
 3019       Register index_reg = as_Register(index);
 3020       if (disp == 0) {
 3021         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 3022         __ ldaxr(dst_reg, rscratch1);
 3023       } else {
 3024         __ lea(rscratch1, Address(base, disp));
 3025         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3026         __ ldaxr(dst_reg, rscratch1);
 3027       }
 3028     }
 3029   %}
 3030 
 3031   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3032     C2_MacroAssembler _masm(&amp;cbuf);
 3033     Register src_reg = as_Register($src$$reg);
 3034     Register base = as_Register($mem$$base);
 3035     int index = $mem$$index;
 3036     int scale = $mem$$scale;
 3037     int disp = $mem$$disp;
 3038     if (index == -1) {
 3039        if (disp != 0) {
 3040         __ lea(rscratch2, Address(base, disp));
 3041         __ stlxr(rscratch1, src_reg, rscratch2);
 3042       } else {
 3043         // TODO
 3044         // should we ever get anything other than this case?
 3045         __ stlxr(rscratch1, src_reg, base);
 3046       }
 3047     } else {
 3048       Register index_reg = as_Register(index);
 3049       if (disp == 0) {
 3050         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3051         __ stlxr(rscratch1, src_reg, rscratch2);
 3052       } else {
 3053         __ lea(rscratch2, Address(base, disp));
 3054         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3055         __ stlxr(rscratch1, src_reg, rscratch2);
 3056       }
 3057     }
 3058     __ cmpw(rscratch1, zr);
 3059   %}
 3060 
 3061   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3062     C2_MacroAssembler _masm(&amp;cbuf);
 3063     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3064     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3065                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3066                /*weak*/ false, noreg);
 3067   %}
 3068 
 3069   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3070     C2_MacroAssembler _masm(&amp;cbuf);
 3071     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3072     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3073                Assembler::word, /*acquire*/ false, /*release*/ true,
 3074                /*weak*/ false, noreg);
 3075   %}
 3076 
 3077   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3078     C2_MacroAssembler _masm(&amp;cbuf);
 3079     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3080     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3081                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3082                /*weak*/ false, noreg);
 3083   %}
 3084 
 3085   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3086     C2_MacroAssembler _masm(&amp;cbuf);
 3087     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3088     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3089                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3090                /*weak*/ false, noreg);
 3091   %}
 3092 
 3093 
 3094   // The only difference between aarch64_enc_cmpxchg and
 3095   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3096   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3097   // lock.
 3098   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3099     C2_MacroAssembler _masm(&amp;cbuf);
 3100     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3101     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3102                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3103                /*weak*/ false, noreg);
 3104   %}
 3105 
 3106   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3107     C2_MacroAssembler _masm(&amp;cbuf);
 3108     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3109     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3110                Assembler::word, /*acquire*/ true, /*release*/ true,
 3111                /*weak*/ false, noreg);
 3112   %}
 3113 
 3114   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3115     C2_MacroAssembler _masm(&amp;cbuf);
 3116     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3117     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3118                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3119                /*weak*/ false, noreg);
 3120   %}
 3121 
 3122   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3123     C2_MacroAssembler _masm(&amp;cbuf);
 3124     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3125     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3126                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3127                /*weak*/ false, noreg);
 3128   %}
 3129 
 3130   // auxiliary used for CompareAndSwapX to set result register
 3131   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3132     C2_MacroAssembler _masm(&amp;cbuf);
 3133     Register res_reg = as_Register($res$$reg);
 3134     __ cset(res_reg, Assembler::EQ);
 3135   %}
 3136 
 3137   // prefetch encodings
 3138 
 3139   enc_class aarch64_enc_prefetchw(memory mem) %{
 3140     C2_MacroAssembler _masm(&amp;cbuf);
 3141     Register base = as_Register($mem$$base);
 3142     int index = $mem$$index;
 3143     int scale = $mem$$scale;
 3144     int disp = $mem$$disp;
 3145     if (index == -1) {
 3146       __ prfm(Address(base, disp), PSTL1KEEP);
 3147     } else {
 3148       Register index_reg = as_Register(index);
 3149       if (disp == 0) {
 3150         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3151       } else {
 3152         __ lea(rscratch1, Address(base, disp));
 3153 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3154       }
 3155     }
 3156   %}
 3157 
 3158   /// mov envcodings
 3159 
 3160   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3161     C2_MacroAssembler _masm(&amp;cbuf);
 3162     u_int32_t con = (u_int32_t)$src$$constant;
 3163     Register dst_reg = as_Register($dst$$reg);
 3164     if (con == 0) {
 3165       __ movw(dst_reg, zr);
 3166     } else {
 3167       __ movw(dst_reg, con);
 3168     }
 3169   %}
 3170 
 3171   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3172     C2_MacroAssembler _masm(&amp;cbuf);
 3173     Register dst_reg = as_Register($dst$$reg);
 3174     u_int64_t con = (u_int64_t)$src$$constant;
 3175     if (con == 0) {
 3176       __ mov(dst_reg, zr);
 3177     } else {
 3178       __ mov(dst_reg, con);
 3179     }
 3180   %}
 3181 
 3182   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3183     C2_MacroAssembler _masm(&amp;cbuf);
 3184     Register dst_reg = as_Register($dst$$reg);
 3185     address con = (address)$src$$constant;
 3186     if (con == NULL || con == (address)1) {
 3187       ShouldNotReachHere();
 3188     } else {
 3189       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3190       if (rtype == relocInfo::oop_type) {
 3191         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3192       } else if (rtype == relocInfo::metadata_type) {
 3193         __ mov_metadata(dst_reg, (Metadata*)con);
 3194       } else {
 3195         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3196         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3197           __ mov(dst_reg, con);
 3198         } else {
 3199           unsigned long offset;
 3200           __ adrp(dst_reg, con, offset);
 3201           __ add(dst_reg, dst_reg, offset);
 3202         }
 3203       }
 3204     }
 3205   %}
 3206 
 3207   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3208     C2_MacroAssembler _masm(&amp;cbuf);
 3209     Register dst_reg = as_Register($dst$$reg);
 3210     __ mov(dst_reg, zr);
 3211   %}
 3212 
 3213   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3214     C2_MacroAssembler _masm(&amp;cbuf);
 3215     Register dst_reg = as_Register($dst$$reg);
 3216     __ mov(dst_reg, (u_int64_t)1);
 3217   %}
 3218 
 3219   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3220     C2_MacroAssembler _masm(&amp;cbuf);
 3221     __ load_byte_map_base($dst$$Register);
 3222   %}
 3223 
 3224   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3225     C2_MacroAssembler _masm(&amp;cbuf);
 3226     Register dst_reg = as_Register($dst$$reg);
 3227     address con = (address)$src$$constant;
 3228     if (con == NULL) {
 3229       ShouldNotReachHere();
 3230     } else {
 3231       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3232       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3233       __ set_narrow_oop(dst_reg, (jobject)con);
 3234     }
 3235   %}
 3236 
 3237   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3238     C2_MacroAssembler _masm(&amp;cbuf);
 3239     Register dst_reg = as_Register($dst$$reg);
 3240     __ mov(dst_reg, zr);
 3241   %}
 3242 
 3243   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3244     C2_MacroAssembler _masm(&amp;cbuf);
 3245     Register dst_reg = as_Register($dst$$reg);
 3246     address con = (address)$src$$constant;
 3247     if (con == NULL) {
 3248       ShouldNotReachHere();
 3249     } else {
 3250       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3251       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3252       __ set_narrow_klass(dst_reg, (Klass *)con);
 3253     }
 3254   %}
 3255 
 3256   // arithmetic encodings
 3257 
 3258   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3259     C2_MacroAssembler _masm(&amp;cbuf);
 3260     Register dst_reg = as_Register($dst$$reg);
 3261     Register src_reg = as_Register($src1$$reg);
 3262     int32_t con = (int32_t)$src2$$constant;
 3263     // add has primary == 0, subtract has primary == 1
 3264     if ($primary) { con = -con; }
 3265     if (con &lt; 0) {
 3266       __ subw(dst_reg, src_reg, -con);
 3267     } else {
 3268       __ addw(dst_reg, src_reg, con);
 3269     }
 3270   %}
 3271 
 3272   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3273     C2_MacroAssembler _masm(&amp;cbuf);
 3274     Register dst_reg = as_Register($dst$$reg);
 3275     Register src_reg = as_Register($src1$$reg);
 3276     int32_t con = (int32_t)$src2$$constant;
 3277     // add has primary == 0, subtract has primary == 1
 3278     if ($primary) { con = -con; }
 3279     if (con &lt; 0) {
 3280       __ sub(dst_reg, src_reg, -con);
 3281     } else {
 3282       __ add(dst_reg, src_reg, con);
 3283     }
 3284   %}
 3285 
 3286   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3287     C2_MacroAssembler _masm(&amp;cbuf);
 3288    Register dst_reg = as_Register($dst$$reg);
 3289    Register src1_reg = as_Register($src1$$reg);
 3290    Register src2_reg = as_Register($src2$$reg);
 3291     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3292   %}
 3293 
 3294   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3295     C2_MacroAssembler _masm(&amp;cbuf);
 3296    Register dst_reg = as_Register($dst$$reg);
 3297    Register src1_reg = as_Register($src1$$reg);
 3298    Register src2_reg = as_Register($src2$$reg);
 3299     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3300   %}
 3301 
 3302   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3303     C2_MacroAssembler _masm(&amp;cbuf);
 3304    Register dst_reg = as_Register($dst$$reg);
 3305    Register src1_reg = as_Register($src1$$reg);
 3306    Register src2_reg = as_Register($src2$$reg);
 3307     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3308   %}
 3309 
 3310   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3311     C2_MacroAssembler _masm(&amp;cbuf);
 3312    Register dst_reg = as_Register($dst$$reg);
 3313    Register src1_reg = as_Register($src1$$reg);
 3314    Register src2_reg = as_Register($src2$$reg);
 3315     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3316   %}
 3317 
 3318   // compare instruction encodings
 3319 
 3320   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3321     C2_MacroAssembler _masm(&amp;cbuf);
 3322     Register reg1 = as_Register($src1$$reg);
 3323     Register reg2 = as_Register($src2$$reg);
 3324     __ cmpw(reg1, reg2);
 3325   %}
 3326 
 3327   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3328     C2_MacroAssembler _masm(&amp;cbuf);
 3329     Register reg = as_Register($src1$$reg);
 3330     int32_t val = $src2$$constant;
 3331     if (val &gt;= 0) {
 3332       __ subsw(zr, reg, val);
 3333     } else {
 3334       __ addsw(zr, reg, -val);
 3335     }
 3336   %}
 3337 
 3338   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3339     C2_MacroAssembler _masm(&amp;cbuf);
 3340     Register reg1 = as_Register($src1$$reg);
 3341     u_int32_t val = (u_int32_t)$src2$$constant;
 3342     __ movw(rscratch1, val);
 3343     __ cmpw(reg1, rscratch1);
 3344   %}
 3345 
 3346   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3347     C2_MacroAssembler _masm(&amp;cbuf);
 3348     Register reg1 = as_Register($src1$$reg);
 3349     Register reg2 = as_Register($src2$$reg);
 3350     __ cmp(reg1, reg2);
 3351   %}
 3352 
 3353   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3354     C2_MacroAssembler _masm(&amp;cbuf);
 3355     Register reg = as_Register($src1$$reg);
 3356     int64_t val = $src2$$constant;
 3357     if (val &gt;= 0) {
 3358       __ subs(zr, reg, val);
 3359     } else if (val != -val) {
 3360       __ adds(zr, reg, -val);
 3361     } else {
 3362     // aargh, Long.MIN_VALUE is a special case
 3363       __ orr(rscratch1, zr, (u_int64_t)val);
 3364       __ subs(zr, reg, rscratch1);
 3365     }
 3366   %}
 3367 
 3368   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3369     C2_MacroAssembler _masm(&amp;cbuf);
 3370     Register reg1 = as_Register($src1$$reg);
 3371     u_int64_t val = (u_int64_t)$src2$$constant;
 3372     __ mov(rscratch1, val);
 3373     __ cmp(reg1, rscratch1);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3377     C2_MacroAssembler _masm(&amp;cbuf);
 3378     Register reg1 = as_Register($src1$$reg);
 3379     Register reg2 = as_Register($src2$$reg);
 3380     __ cmp(reg1, reg2);
 3381   %}
 3382 
 3383   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3384     C2_MacroAssembler _masm(&amp;cbuf);
 3385     Register reg1 = as_Register($src1$$reg);
 3386     Register reg2 = as_Register($src2$$reg);
 3387     __ cmpw(reg1, reg2);
 3388   %}
 3389 
 3390   enc_class aarch64_enc_testp(iRegP src) %{
 3391     C2_MacroAssembler _masm(&amp;cbuf);
 3392     Register reg = as_Register($src$$reg);
 3393     __ cmp(reg, zr);
 3394   %}
 3395 
 3396   enc_class aarch64_enc_testn(iRegN src) %{
 3397     C2_MacroAssembler _masm(&amp;cbuf);
 3398     Register reg = as_Register($src$$reg);
 3399     __ cmpw(reg, zr);
 3400   %}
 3401 
 3402   enc_class aarch64_enc_b(label lbl) %{
 3403     C2_MacroAssembler _masm(&amp;cbuf);
 3404     Label *L = $lbl$$label;
 3405     __ b(*L);
 3406   %}
 3407 
 3408   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3409     C2_MacroAssembler _masm(&amp;cbuf);
 3410     Label *L = $lbl$$label;
 3411     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3412   %}
 3413 
 3414   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3415     C2_MacroAssembler _masm(&amp;cbuf);
 3416     Label *L = $lbl$$label;
 3417     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3418   %}
 3419 
 3420   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3421   %{
 3422      Register sub_reg = as_Register($sub$$reg);
 3423      Register super_reg = as_Register($super$$reg);
 3424      Register temp_reg = as_Register($temp$$reg);
 3425      Register result_reg = as_Register($result$$reg);
 3426 
 3427      Label miss;
 3428      C2_MacroAssembler _masm(&amp;cbuf);
 3429      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3430                                      NULL, &amp;miss,
 3431                                      /*set_cond_codes:*/ true);
 3432      if ($primary) {
 3433        __ mov(result_reg, zr);
 3434      }
 3435      __ bind(miss);
 3436   %}
 3437 
 3438   enc_class aarch64_enc_java_static_call(method meth) %{
 3439     C2_MacroAssembler _masm(&amp;cbuf);
 3440 
 3441     address addr = (address)$meth$$method;
 3442     address call;
 3443     if (!_method) {
 3444       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3445       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3446     } else {
 3447       int method_index = resolved_method_index(cbuf);
 3448       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3449                                                   : static_call_Relocation::spec(method_index);
 3450       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3451 
 3452       // Emit stub for static call
 3453       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3454       if (stub == NULL) {
 3455         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3456         return;
 3457       }
 3458     }
 3459     if (call == NULL) {
 3460       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3461       return;
 3462     }
 3463   %}
 3464 
 3465   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3466     C2_MacroAssembler _masm(&amp;cbuf);
 3467     int method_index = resolved_method_index(cbuf);
 3468     address call = __ ic_call((address)$meth$$method, method_index);
 3469     if (call == NULL) {
 3470       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3471       return;
 3472     }
 3473   %}
 3474 
 3475   enc_class aarch64_enc_call_epilog() %{
 3476     C2_MacroAssembler _masm(&amp;cbuf);
 3477     if (VerifyStackAtCalls) {
 3478       // Check that stack depth is unchanged: find majik cookie on stack
 3479       __ call_Unimplemented();
 3480     }
 3481   %}
 3482 
 3483   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3484     C2_MacroAssembler _masm(&amp;cbuf);
 3485 
 3486     // some calls to generated routines (arraycopy code) are scheduled
 3487     // by C2 as runtime calls. if so we can call them using a br (they
 3488     // will be in a reachable segment) otherwise we have to use a blr
 3489     // which loads the absolute address into a register.
 3490     address entry = (address)$meth$$method;
 3491     CodeBlob *cb = CodeCache::find_blob(entry);
 3492     if (cb) {
 3493       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3494       if (call == NULL) {
 3495         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3496         return;
 3497       }
 3498     } else {
 3499       Label retaddr;
 3500       __ adr(rscratch2, retaddr);
 3501       __ lea(rscratch1, RuntimeAddress(entry));
 3502       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3503       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3504       __ blr(rscratch1);
 3505       __ bind(retaddr);
 3506       __ add(sp, sp, 2 * wordSize);
 3507     }
 3508   %}
 3509 
 3510   enc_class aarch64_enc_rethrow() %{
 3511     C2_MacroAssembler _masm(&amp;cbuf);
 3512     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3513   %}
 3514 
 3515   enc_class aarch64_enc_ret() %{
 3516     C2_MacroAssembler _masm(&amp;cbuf);
 3517     __ ret(lr);
 3518   %}
 3519 
 3520   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3521     C2_MacroAssembler _masm(&amp;cbuf);
 3522     Register target_reg = as_Register($jump_target$$reg);
 3523     __ br(target_reg);
 3524   %}
 3525 
 3526   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3527     C2_MacroAssembler _masm(&amp;cbuf);
 3528     Register target_reg = as_Register($jump_target$$reg);
 3529     // exception oop should be in r0
 3530     // ret addr has been popped into lr
 3531     // callee expects it in r3
 3532     __ mov(r3, lr);
 3533     __ br(target_reg);
 3534   %}
 3535 
 3536   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3537     C2_MacroAssembler _masm(&amp;cbuf);
 3538     Register oop = as_Register($object$$reg);
 3539     Register box = as_Register($box$$reg);
 3540     Register disp_hdr = as_Register($tmp$$reg);
 3541     Register tmp = as_Register($tmp2$$reg);
 3542     Label cont;
 3543     Label object_has_monitor;
 3544     Label cas_failed;
 3545 
 3546     assert_different_registers(oop, box, tmp, disp_hdr);
 3547 
 3548     // Load markWord from object into displaced_header.
 3549     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3550 
 3551     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3552       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3553     }
 3554 
 3555     // Check for existing monitor
 3556     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3557 
 3558     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3559     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3560 
 3561     // Initialize the box. (Must happen before we update the object mark!)
 3562     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3563 
 3564     // Compare object markWord with an unlocked value (tmp) and if
 3565     // equal exchange the stack address of our box with object markWord.
 3566     // On failure disp_hdr contains the possibly locked markWord.
 3567     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3568                /*release*/ true, /*weak*/ false, disp_hdr);
 3569     __ br(Assembler::EQ, cont);
 3570 
 3571     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3572 
 3573     // If the compare-and-exchange succeeded, then we found an unlocked
 3574     // object, will have now locked it will continue at label cont
 3575 
 3576     __ bind(cas_failed);
 3577     // We did not see an unlocked object so try the fast recursive case.
 3578 
 3579     // Check if the owner is self by comparing the value in the
 3580     // markWord of object (disp_hdr) with the stack pointer.
 3581     __ mov(rscratch1, sp);
 3582     __ sub(disp_hdr, disp_hdr, rscratch1);
 3583     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3584     // If condition is true we are cont and hence we can store 0 as the
 3585     // displaced header in the box, which indicates that it is a recursive lock.
 3586     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3587     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3588 
 3589     __ b(cont);
 3590 
 3591     // Handle existing monitor.
 3592     __ bind(object_has_monitor);
 3593 
 3594     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3595     // otherwise m-&gt;owner may contain a thread or a stack address.
 3596     //
 3597     // Try to CAS m-&gt;owner from NULL to current thread.
 3598     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3599     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3600                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3601 
 3602     // Store a non-null value into the box to avoid looking like a re-entrant
 3603     // lock. The fast-path monitor unlock code checks for
 3604     // markWord::monitor_value so use markWord::unused_mark which has the
 3605     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3606     __ mov(tmp, (address)markWord::unused_mark().value());
 3607     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3608 
 3609     __ bind(cont);
 3610     // flag == EQ indicates success
 3611     // flag == NE indicates failure
 3612   %}
 3613 
 3614   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3615     C2_MacroAssembler _masm(&amp;cbuf);
 3616     Register oop = as_Register($object$$reg);
 3617     Register box = as_Register($box$$reg);
 3618     Register disp_hdr = as_Register($tmp$$reg);
 3619     Register tmp = as_Register($tmp2$$reg);
 3620     Label cont;
 3621     Label object_has_monitor;
 3622 
 3623     assert_different_registers(oop, box, tmp, disp_hdr);
 3624 
 3625     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3626       __ biased_locking_exit(oop, tmp, cont);
 3627     }
 3628 
 3629     // Find the lock address and load the displaced header from the stack.
 3630     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3631 
 3632     // If the displaced header is 0, we have a recursive unlock.
 3633     __ cmp(disp_hdr, zr);
 3634     __ br(Assembler::EQ, cont);
 3635 
 3636     // Handle existing monitor.
 3637     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3638     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3639 
 3640     // Check if it is still a light weight lock, this is is true if we
 3641     // see the stack address of the basicLock in the markWord of the
 3642     // object.
 3643 
 3644     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3645                /*release*/ true, /*weak*/ false, tmp);
 3646     __ b(cont);
 3647 
 3648     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3649 
 3650     // Handle existing monitor.
 3651     __ bind(object_has_monitor);
 3652     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3653     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3654     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3655     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3656     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3657     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3658     __ cmp(rscratch1, zr); // Sets flags for result
 3659     __ br(Assembler::NE, cont);
 3660 
 3661     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3662     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3663     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3664     __ cmp(rscratch1, zr); // Sets flags for result
 3665     __ cbnz(rscratch1, cont);
 3666     // need a release store here
 3667     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3668     __ stlr(zr, tmp); // set unowned
 3669 
 3670     __ bind(cont);
 3671     // flag == EQ indicates success
 3672     // flag == NE indicates failure
 3673   %}
 3674 
 3675 %}
 3676 
 3677 //----------FRAME--------------------------------------------------------------
 3678 // Definition of frame structure and management information.
 3679 //
 3680 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3681 //                             |   (to get allocators register number
 3682 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3683 //  r   CALLER     |        |
 3684 //  o     |        +--------+      pad to even-align allocators stack-slot
 3685 //  w     V        |  pad0  |        numbers; owned by CALLER
 3686 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3687 //  h     ^        |   in   |  5
 3688 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3689 //  |     |        |        |  3
 3690 //  |     |        +--------+
 3691 //  V     |        | old out|      Empty on Intel, window on Sparc
 3692 //        |    old |preserve|      Must be even aligned.
 3693 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3694 //        |        |   in   |  3   area for Intel ret address
 3695 //     Owned by    |preserve|      Empty on Sparc.
 3696 //       SELF      +--------+
 3697 //        |        |  pad2  |  2   pad to align old SP
 3698 //        |        +--------+  1
 3699 //        |        | locks  |  0
 3700 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3701 //        |        |  pad1  | 11   pad to align new SP
 3702 //        |        +--------+
 3703 //        |        |        | 10
 3704 //        |        | spills |  9   spills
 3705 //        V        |        |  8   (pad0 slot for callee)
 3706 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3707 //        ^        |  out   |  7
 3708 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3709 //     Owned by    +--------+
 3710 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3711 //        |    new |preserve|      Must be even-aligned.
 3712 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3713 //        |        |        |
 3714 //
 3715 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3716 //         known from SELF&#39;s arguments and the Java calling convention.
 3717 //         Region 6-7 is determined per call site.
 3718 // Note 2: If the calling convention leaves holes in the incoming argument
 3719 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3720 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3721 //         incoming area, as the Java calling convention is completely under
 3722 //         the control of the AD file.  Doubles can be sorted and packed to
 3723 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3724 //         varargs C calling conventions.
 3725 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3726 //         even aligned with pad0 as needed.
 3727 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3728 //           (the latter is true on Intel but is it false on AArch64?)
 3729 //         region 6-11 is even aligned; it may be padded out more so that
 3730 //         the region from SP to FP meets the minimum stack alignment.
 3731 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3732 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3733 //         SP meets the minimum alignment.
 3734 
 3735 frame %{
 3736   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3737   stack_direction(TOWARDS_LOW);
 3738 
 3739   // These three registers define part of the calling convention
 3740   // between compiled code and the interpreter.
 3741 
 3742   // Inline Cache Register or methodOop for I2C.
 3743   inline_cache_reg(R12);
 3744 
 3745   // Method Oop Register when calling interpreter.
 3746   interpreter_method_oop_reg(R12);
 3747 
 3748   // Number of stack slots consumed by locking an object
 3749   sync_stack_slots(2);
 3750 
 3751   // Compiled code&#39;s Frame Pointer
 3752   frame_pointer(R31);
 3753 
 3754   // Interpreter stores its frame pointer in a register which is
 3755   // stored to the stack by I2CAdaptors.
 3756   // I2CAdaptors convert from interpreted java to compiled java.
 3757   interpreter_frame_pointer(R29);
 3758 
 3759   // Stack alignment requirement
 3760   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3761 
 3762   // Number of stack slots between incoming argument block and the start of
 3763   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3764   // EPILOG must remove this many slots. aarch64 needs two slots for
 3765   // return address and fp.
 3766   // TODO think this is correct but check
 3767   in_preserve_stack_slots(4);
 3768 
 3769   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3770   // for calls to C.  Supports the var-args backing area for register parms.
 3771   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3772 
 3773   // The after-PROLOG location of the return address.  Location of
 3774   // return address specifies a type (REG or STACK) and a number
 3775   // representing the register number (i.e. - use a register name) or
 3776   // stack slot.
 3777   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3778   // Otherwise, it is above the locks and verification slot and alignment word
 3779   // TODO this may well be correct but need to check why that - 2 is there
 3780   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3781   // which folds in the space used for monitors
 3782   return_addr(STACK - 2 +
 3783               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3784                         Compile::current()-&gt;fixed_slots()),
 3785                        stack_alignment_in_slots()));
 3786 
 3787   // Body of function which returns an integer array locating
 3788   // arguments either in registers or in stack slots.  Passed an array
 3789   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3790   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3791   // arguments for a CALLEE.  Incoming stack arguments are
 3792   // automatically biased by the preserve_stack_slots field above.
 3793 
 3794   calling_convention
 3795   %{
 3796     // No difference between ingoing/outgoing just pass false
 3797     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3798   %}
 3799 
 3800   c_calling_convention
 3801   %{
 3802     // This is obviously always outgoing
 3803     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3804   %}
 3805 
 3806   // Location of compiled Java return values.  Same as C for now.
 3807   return_value
 3808   %{
 3809     // TODO do we allow ideal_reg == Op_RegN???
 3810     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3811            &quot;only return normal values&quot;);
 3812 
 3813     static const int lo[Op_RegL + 1] = { // enum name
 3814       0,                                 // Op_Node
 3815       0,                                 // Op_Set
 3816       R0_num,                            // Op_RegN
 3817       R0_num,                            // Op_RegI
 3818       R0_num,                            // Op_RegP
 3819       V0_num,                            // Op_RegF
 3820       V0_num,                            // Op_RegD
 3821       R0_num                             // Op_RegL
 3822     };
 3823 
 3824     static const int hi[Op_RegL + 1] = { // enum name
 3825       0,                                 // Op_Node
 3826       0,                                 // Op_Set
 3827       OptoReg::Bad,                      // Op_RegN
 3828       OptoReg::Bad,                      // Op_RegI
 3829       R0_H_num,                          // Op_RegP
 3830       OptoReg::Bad,                      // Op_RegF
 3831       V0_H_num,                          // Op_RegD
 3832       R0_H_num                           // Op_RegL
 3833     };
 3834 
 3835     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3836   %}
 3837 %}
 3838 
 3839 //----------ATTRIBUTES---------------------------------------------------------
 3840 //----------Operand Attributes-------------------------------------------------
 3841 op_attrib op_cost(1);        // Required cost attribute
 3842 
 3843 //----------Instruction Attributes---------------------------------------------
 3844 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3845 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3846 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3847                                 // a non-matching short branch variant
 3848                                 // of some long branch?
 3849 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3850                                 // be a power of 2) specifies the
 3851                                 // alignment that some part of the
 3852                                 // instruction (not necessarily the
 3853                                 // start) requires.  If &gt; 1, a
 3854                                 // compute_padding() function must be
 3855                                 // provided for the instruction
 3856 
 3857 //----------OPERANDS-----------------------------------------------------------
 3858 // Operand definitions must precede instruction definitions for correct parsing
 3859 // in the ADLC because operands constitute user defined types which are used in
 3860 // instruction definitions.
 3861 
 3862 //----------Simple Operands----------------------------------------------------
 3863 
 3864 // Integer operands 32 bit
 3865 // 32 bit immediate
 3866 operand immI()
 3867 %{
 3868   match(ConI);
 3869 
 3870   op_cost(0);
 3871   format %{ %}
 3872   interface(CONST_INTER);
 3873 %}
 3874 
 3875 // 32 bit zero
 3876 operand immI0()
 3877 %{
 3878   predicate(n-&gt;get_int() == 0);
 3879   match(ConI);
 3880 
 3881   op_cost(0);
 3882   format %{ %}
 3883   interface(CONST_INTER);
 3884 %}
 3885 
 3886 // 32 bit unit increment
 3887 operand immI_1()
 3888 %{
 3889   predicate(n-&gt;get_int() == 1);
 3890   match(ConI);
 3891 
 3892   op_cost(0);
 3893   format %{ %}
 3894   interface(CONST_INTER);
 3895 %}
 3896 
 3897 // 32 bit unit decrement
 3898 operand immI_M1()
 3899 %{
 3900   predicate(n-&gt;get_int() == -1);
 3901   match(ConI);
 3902 
 3903   op_cost(0);
 3904   format %{ %}
 3905   interface(CONST_INTER);
 3906 %}
 3907 
 3908 // Shift values for add/sub extension shift
 3909 operand immIExt()
 3910 %{
 3911   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3912   match(ConI);
 3913 
 3914   op_cost(0);
 3915   format %{ %}
 3916   interface(CONST_INTER);
 3917 %}
 3918 
 3919 operand immI_le_4()
 3920 %{
 3921   predicate(n-&gt;get_int() &lt;= 4);
 3922   match(ConI);
 3923 
 3924   op_cost(0);
 3925   format %{ %}
 3926   interface(CONST_INTER);
 3927 %}
 3928 
 3929 operand immI_31()
 3930 %{
 3931   predicate(n-&gt;get_int() == 31);
 3932   match(ConI);
 3933 
 3934   op_cost(0);
 3935   format %{ %}
 3936   interface(CONST_INTER);
 3937 %}
 3938 
 3939 operand immI_8()
 3940 %{
 3941   predicate(n-&gt;get_int() == 8);
 3942   match(ConI);
 3943 
 3944   op_cost(0);
 3945   format %{ %}
 3946   interface(CONST_INTER);
 3947 %}
 3948 
 3949 operand immI_16()
 3950 %{
 3951   predicate(n-&gt;get_int() == 16);
 3952   match(ConI);
 3953 
 3954   op_cost(0);
 3955   format %{ %}
 3956   interface(CONST_INTER);
 3957 %}
 3958 
 3959 operand immI_24()
 3960 %{
 3961   predicate(n-&gt;get_int() == 24);
 3962   match(ConI);
 3963 
 3964   op_cost(0);
 3965   format %{ %}
 3966   interface(CONST_INTER);
 3967 %}
 3968 
 3969 operand immI_32()
 3970 %{
 3971   predicate(n-&gt;get_int() == 32);
 3972   match(ConI);
 3973 
 3974   op_cost(0);
 3975   format %{ %}
 3976   interface(CONST_INTER);
 3977 %}
 3978 
 3979 operand immI_48()
 3980 %{
 3981   predicate(n-&gt;get_int() == 48);
 3982   match(ConI);
 3983 
 3984   op_cost(0);
 3985   format %{ %}
 3986   interface(CONST_INTER);
 3987 %}
 3988 
 3989 operand immI_56()
 3990 %{
 3991   predicate(n-&gt;get_int() == 56);
 3992   match(ConI);
 3993 
 3994   op_cost(0);
 3995   format %{ %}
 3996   interface(CONST_INTER);
 3997 %}
 3998 
 3999 operand immI_63()
 4000 %{
 4001   predicate(n-&gt;get_int() == 63);
 4002   match(ConI);
 4003 
 4004   op_cost(0);
 4005   format %{ %}
 4006   interface(CONST_INTER);
 4007 %}
 4008 
 4009 operand immI_64()
 4010 %{
 4011   predicate(n-&gt;get_int() == 64);
 4012   match(ConI);
 4013 
 4014   op_cost(0);
 4015   format %{ %}
 4016   interface(CONST_INTER);
 4017 %}
 4018 
 4019 operand immI_255()
 4020 %{
 4021   predicate(n-&gt;get_int() == 255);
 4022   match(ConI);
 4023 
 4024   op_cost(0);
 4025   format %{ %}
 4026   interface(CONST_INTER);
 4027 %}
 4028 
 4029 operand immI_65535()
 4030 %{
 4031   predicate(n-&gt;get_int() == 65535);
 4032   match(ConI);
 4033 
 4034   op_cost(0);
 4035   format %{ %}
 4036   interface(CONST_INTER);
 4037 %}
 4038 
 4039 operand immL_255()
 4040 %{
 4041   predicate(n-&gt;get_long() == 255L);
 4042   match(ConL);
 4043 
 4044   op_cost(0);
 4045   format %{ %}
 4046   interface(CONST_INTER);
 4047 %}
 4048 
 4049 operand immL_65535()
 4050 %{
 4051   predicate(n-&gt;get_long() == 65535L);
 4052   match(ConL);
 4053 
 4054   op_cost(0);
 4055   format %{ %}
 4056   interface(CONST_INTER);
 4057 %}
 4058 
 4059 operand immL_4294967295()
 4060 %{
 4061   predicate(n-&gt;get_long() == 4294967295L);
 4062   match(ConL);
 4063 
 4064   op_cost(0);
 4065   format %{ %}
 4066   interface(CONST_INTER);
 4067 %}
 4068 
 4069 operand immL_bitmask()
 4070 %{
 4071   predicate((n-&gt;get_long() != 0)
 4072             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4073             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4074   match(ConL);
 4075 
 4076   op_cost(0);
 4077   format %{ %}
 4078   interface(CONST_INTER);
 4079 %}
 4080 
 4081 operand immI_bitmask()
 4082 %{
 4083   predicate((n-&gt;get_int() != 0)
 4084             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4085             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4086   match(ConI);
 4087 
 4088   op_cost(0);
 4089   format %{ %}
 4090   interface(CONST_INTER);
 4091 %}
 4092 
 4093 // Scale values for scaled offset addressing modes (up to long but not quad)
 4094 operand immIScale()
 4095 %{
 4096   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4097   match(ConI);
 4098 
 4099   op_cost(0);
 4100   format %{ %}
 4101   interface(CONST_INTER);
 4102 %}
 4103 
 4104 // 26 bit signed offset -- for pc-relative branches
 4105 operand immI26()
 4106 %{
 4107   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4108   match(ConI);
 4109 
 4110   op_cost(0);
 4111   format %{ %}
 4112   interface(CONST_INTER);
 4113 %}
 4114 
 4115 // 19 bit signed offset -- for pc-relative loads
 4116 operand immI19()
 4117 %{
 4118   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4119   match(ConI);
 4120 
 4121   op_cost(0);
 4122   format %{ %}
 4123   interface(CONST_INTER);
 4124 %}
 4125 
 4126 // 12 bit unsigned offset -- for base plus immediate loads
 4127 operand immIU12()
 4128 %{
 4129   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4130   match(ConI);
 4131 
 4132   op_cost(0);
 4133   format %{ %}
 4134   interface(CONST_INTER);
 4135 %}
 4136 
 4137 operand immLU12()
 4138 %{
 4139   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4140   match(ConL);
 4141 
 4142   op_cost(0);
 4143   format %{ %}
 4144   interface(CONST_INTER);
 4145 %}
 4146 
 4147 // Offset for scaled or unscaled immediate loads and stores
 4148 operand immIOffset()
 4149 %{
 4150   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4151   match(ConI);
 4152 
 4153   op_cost(0);
 4154   format %{ %}
 4155   interface(CONST_INTER);
 4156 %}
 4157 
 4158 operand immIOffset1()
 4159 %{
 4160   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4161   match(ConI);
 4162 
 4163   op_cost(0);
 4164   format %{ %}
 4165   interface(CONST_INTER);
 4166 %}
 4167 
 4168 operand immIOffset2()
 4169 %{
 4170   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4171   match(ConI);
 4172 
 4173   op_cost(0);
 4174   format %{ %}
 4175   interface(CONST_INTER);
 4176 %}
 4177 
 4178 operand immIOffset4()
 4179 %{
 4180   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4181   match(ConI);
 4182 
 4183   op_cost(0);
 4184   format %{ %}
 4185   interface(CONST_INTER);
 4186 %}
 4187 
 4188 operand immIOffset8()
 4189 %{
 4190   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4191   match(ConI);
 4192 
 4193   op_cost(0);
 4194   format %{ %}
 4195   interface(CONST_INTER);
 4196 %}
 4197 
 4198 operand immIOffset16()
 4199 %{
 4200   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4201   match(ConI);
 4202 
 4203   op_cost(0);
 4204   format %{ %}
 4205   interface(CONST_INTER);
 4206 %}
 4207 
 4208 operand immLoffset()
 4209 %{
 4210   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4211   match(ConL);
 4212 
 4213   op_cost(0);
 4214   format %{ %}
 4215   interface(CONST_INTER);
 4216 %}
 4217 
 4218 operand immLoffset1()
 4219 %{
 4220   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4221   match(ConL);
 4222 
 4223   op_cost(0);
 4224   format %{ %}
 4225   interface(CONST_INTER);
 4226 %}
 4227 
 4228 operand immLoffset2()
 4229 %{
 4230   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4231   match(ConL);
 4232 
 4233   op_cost(0);
 4234   format %{ %}
 4235   interface(CONST_INTER);
 4236 %}
 4237 
 4238 operand immLoffset4()
 4239 %{
 4240   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4241   match(ConL);
 4242 
 4243   op_cost(0);
 4244   format %{ %}
 4245   interface(CONST_INTER);
 4246 %}
 4247 
 4248 operand immLoffset8()
 4249 %{
 4250   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4251   match(ConL);
 4252 
 4253   op_cost(0);
 4254   format %{ %}
 4255   interface(CONST_INTER);
 4256 %}
 4257 
 4258 operand immLoffset16()
 4259 %{
 4260   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4261   match(ConL);
 4262 
 4263   op_cost(0);
 4264   format %{ %}
 4265   interface(CONST_INTER);
 4266 %}
 4267 
 4268 // 32 bit integer valid for add sub immediate
 4269 operand immIAddSub()
 4270 %{
 4271   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4272   match(ConI);
 4273   op_cost(0);
 4274   format %{ %}
 4275   interface(CONST_INTER);
 4276 %}
 4277 
 4278 // 32 bit unsigned integer valid for logical immediate
 4279 // TODO -- check this is right when e.g the mask is 0x80000000
 4280 operand immILog()
 4281 %{
 4282   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4283   match(ConI);
 4284 
 4285   op_cost(0);
 4286   format %{ %}
 4287   interface(CONST_INTER);
 4288 %}
 4289 
 4290 // Integer operands 64 bit
 4291 // 64 bit immediate
 4292 operand immL()
 4293 %{
 4294   match(ConL);
 4295 
 4296   op_cost(0);
 4297   format %{ %}
 4298   interface(CONST_INTER);
 4299 %}
 4300 
 4301 // 64 bit zero
 4302 operand immL0()
 4303 %{
 4304   predicate(n-&gt;get_long() == 0);
 4305   match(ConL);
 4306 
 4307   op_cost(0);
 4308   format %{ %}
 4309   interface(CONST_INTER);
 4310 %}
 4311 
 4312 // 64 bit unit increment
 4313 operand immL_1()
 4314 %{
 4315   predicate(n-&gt;get_long() == 1);
 4316   match(ConL);
 4317 
 4318   op_cost(0);
 4319   format %{ %}
 4320   interface(CONST_INTER);
 4321 %}
 4322 
 4323 // 64 bit unit decrement
 4324 operand immL_M1()
 4325 %{
 4326   predicate(n-&gt;get_long() == -1);
 4327   match(ConL);
 4328 
 4329   op_cost(0);
 4330   format %{ %}
 4331   interface(CONST_INTER);
 4332 %}
 4333 
 4334 // 32 bit offset of pc in thread anchor
 4335 
 4336 operand immL_pc_off()
 4337 %{
 4338   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4339                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4340   match(ConL);
 4341 
 4342   op_cost(0);
 4343   format %{ %}
 4344   interface(CONST_INTER);
 4345 %}
 4346 
 4347 // 64 bit integer valid for add sub immediate
 4348 operand immLAddSub()
 4349 %{
 4350   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4351   match(ConL);
 4352   op_cost(0);
 4353   format %{ %}
 4354   interface(CONST_INTER);
 4355 %}
 4356 
 4357 // 64 bit integer valid for logical immediate
 4358 operand immLLog()
 4359 %{
 4360   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4361   match(ConL);
 4362   op_cost(0);
 4363   format %{ %}
 4364   interface(CONST_INTER);
 4365 %}
 4366 
 4367 // Long Immediate: low 32-bit mask
 4368 operand immL_32bits()
 4369 %{
 4370   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4371   match(ConL);
 4372   op_cost(0);
 4373   format %{ %}
 4374   interface(CONST_INTER);
 4375 %}
 4376 
 4377 // Pointer operands
 4378 // Pointer Immediate
 4379 operand immP()
 4380 %{
 4381   match(ConP);
 4382 
 4383   op_cost(0);
 4384   format %{ %}
 4385   interface(CONST_INTER);
 4386 %}
 4387 
 4388 // NULL Pointer Immediate
 4389 operand immP0()
 4390 %{
 4391   predicate(n-&gt;get_ptr() == 0);
 4392   match(ConP);
 4393 
 4394   op_cost(0);
 4395   format %{ %}
 4396   interface(CONST_INTER);
 4397 %}
 4398 
 4399 // Pointer Immediate One
 4400 // this is used in object initialization (initial object header)
 4401 operand immP_1()
 4402 %{
 4403   predicate(n-&gt;get_ptr() == 1);
 4404   match(ConP);
 4405 
 4406   op_cost(0);
 4407   format %{ %}
 4408   interface(CONST_INTER);
 4409 %}
 4410 
 4411 // Card Table Byte Map Base
 4412 operand immByteMapBase()
 4413 %{
 4414   // Get base of card map
 4415   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4416             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4417   match(ConP);
 4418 
 4419   op_cost(0);
 4420   format %{ %}
 4421   interface(CONST_INTER);
 4422 %}
 4423 
 4424 // Pointer Immediate Minus One
 4425 // this is used when we want to write the current PC to the thread anchor
 4426 operand immP_M1()
 4427 %{
 4428   predicate(n-&gt;get_ptr() == -1);
 4429   match(ConP);
 4430 
 4431   op_cost(0);
 4432   format %{ %}
 4433   interface(CONST_INTER);
 4434 %}
 4435 
 4436 // Pointer Immediate Minus Two
 4437 // this is used when we want to write the current PC to the thread anchor
 4438 operand immP_M2()
 4439 %{
 4440   predicate(n-&gt;get_ptr() == -2);
 4441   match(ConP);
 4442 
 4443   op_cost(0);
 4444   format %{ %}
 4445   interface(CONST_INTER);
 4446 %}
 4447 
 4448 // Float and Double operands
 4449 // Double Immediate
 4450 operand immD()
 4451 %{
 4452   match(ConD);
 4453   op_cost(0);
 4454   format %{ %}
 4455   interface(CONST_INTER);
 4456 %}
 4457 
 4458 // Double Immediate: +0.0d
 4459 operand immD0()
 4460 %{
 4461   predicate(jlong_cast(n-&gt;getd()) == 0);
 4462   match(ConD);
 4463 
 4464   op_cost(0);
 4465   format %{ %}
 4466   interface(CONST_INTER);
 4467 %}
 4468 
 4469 // constant &#39;double +0.0&#39;.
 4470 operand immDPacked()
 4471 %{
 4472   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4473   match(ConD);
 4474   op_cost(0);
 4475   format %{ %}
 4476   interface(CONST_INTER);
 4477 %}
 4478 
 4479 // Float Immediate
 4480 operand immF()
 4481 %{
 4482   match(ConF);
 4483   op_cost(0);
 4484   format %{ %}
 4485   interface(CONST_INTER);
 4486 %}
 4487 
 4488 // Float Immediate: +0.0f.
 4489 operand immF0()
 4490 %{
 4491   predicate(jint_cast(n-&gt;getf()) == 0);
 4492   match(ConF);
 4493 
 4494   op_cost(0);
 4495   format %{ %}
 4496   interface(CONST_INTER);
 4497 %}
 4498 
 4499 //
 4500 operand immFPacked()
 4501 %{
 4502   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4503   match(ConF);
 4504   op_cost(0);
 4505   format %{ %}
 4506   interface(CONST_INTER);
 4507 %}
 4508 
 4509 // Narrow pointer operands
 4510 // Narrow Pointer Immediate
 4511 operand immN()
 4512 %{
 4513   match(ConN);
 4514 
 4515   op_cost(0);
 4516   format %{ %}
 4517   interface(CONST_INTER);
 4518 %}
 4519 
 4520 // Narrow NULL Pointer Immediate
 4521 operand immN0()
 4522 %{
 4523   predicate(n-&gt;get_narrowcon() == 0);
 4524   match(ConN);
 4525 
 4526   op_cost(0);
 4527   format %{ %}
 4528   interface(CONST_INTER);
 4529 %}
 4530 
 4531 operand immNKlass()
 4532 %{
 4533   match(ConNKlass);
 4534 
 4535   op_cost(0);
 4536   format %{ %}
 4537   interface(CONST_INTER);
 4538 %}
 4539 
 4540 // Integer 32 bit Register Operands
 4541 // Integer 32 bitRegister (excludes SP)
 4542 operand iRegI()
 4543 %{
 4544   constraint(ALLOC_IN_RC(any_reg32));
 4545   match(RegI);
 4546   match(iRegINoSp);
 4547   op_cost(0);
 4548   format %{ %}
 4549   interface(REG_INTER);
 4550 %}
 4551 
 4552 // Integer 32 bit Register not Special
 4553 operand iRegINoSp()
 4554 %{
 4555   constraint(ALLOC_IN_RC(no_special_reg32));
 4556   match(RegI);
 4557   op_cost(0);
 4558   format %{ %}
 4559   interface(REG_INTER);
 4560 %}
 4561 
 4562 // Integer 64 bit Register Operands
 4563 // Integer 64 bit Register (includes SP)
 4564 operand iRegL()
 4565 %{
 4566   constraint(ALLOC_IN_RC(any_reg));
 4567   match(RegL);
 4568   match(iRegLNoSp);
 4569   op_cost(0);
 4570   format %{ %}
 4571   interface(REG_INTER);
 4572 %}
 4573 
 4574 // Integer 64 bit Register not Special
 4575 operand iRegLNoSp()
 4576 %{
 4577   constraint(ALLOC_IN_RC(no_special_reg));
 4578   match(RegL);
 4579   match(iRegL_R0);
 4580   format %{ %}
 4581   interface(REG_INTER);
 4582 %}
 4583 
 4584 // Pointer Register Operands
 4585 // Pointer Register
 4586 operand iRegP()
 4587 %{
 4588   constraint(ALLOC_IN_RC(ptr_reg));
 4589   match(RegP);
 4590   match(iRegPNoSp);
 4591   match(iRegP_R0);
 4592   //match(iRegP_R2);
 4593   //match(iRegP_R4);
 4594   //match(iRegP_R5);
 4595   match(thread_RegP);
 4596   op_cost(0);
 4597   format %{ %}
 4598   interface(REG_INTER);
 4599 %}
 4600 
 4601 // Pointer 64 bit Register not Special
 4602 operand iRegPNoSp()
 4603 %{
 4604   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4605   match(RegP);
 4606   // match(iRegP);
 4607   // match(iRegP_R0);
 4608   // match(iRegP_R2);
 4609   // match(iRegP_R4);
 4610   // match(iRegP_R5);
 4611   // match(thread_RegP);
 4612   op_cost(0);
 4613   format %{ %}
 4614   interface(REG_INTER);
 4615 %}
 4616 
 4617 // Pointer 64 bit Register R0 only
 4618 operand iRegP_R0()
 4619 %{
 4620   constraint(ALLOC_IN_RC(r0_reg));
 4621   match(RegP);
 4622   // match(iRegP);
 4623   match(iRegPNoSp);
 4624   op_cost(0);
 4625   format %{ %}
 4626   interface(REG_INTER);
 4627 %}
 4628 
 4629 // Pointer 64 bit Register R1 only
 4630 operand iRegP_R1()
 4631 %{
 4632   constraint(ALLOC_IN_RC(r1_reg));
 4633   match(RegP);
 4634   // match(iRegP);
 4635   match(iRegPNoSp);
 4636   op_cost(0);
 4637   format %{ %}
 4638   interface(REG_INTER);
 4639 %}
 4640 
 4641 // Pointer 64 bit Register R2 only
 4642 operand iRegP_R2()
 4643 %{
 4644   constraint(ALLOC_IN_RC(r2_reg));
 4645   match(RegP);
 4646   // match(iRegP);
 4647   match(iRegPNoSp);
 4648   op_cost(0);
 4649   format %{ %}
 4650   interface(REG_INTER);
 4651 %}
 4652 
 4653 // Pointer 64 bit Register R3 only
 4654 operand iRegP_R3()
 4655 %{
 4656   constraint(ALLOC_IN_RC(r3_reg));
 4657   match(RegP);
 4658   // match(iRegP);
 4659   match(iRegPNoSp);
 4660   op_cost(0);
 4661   format %{ %}
 4662   interface(REG_INTER);
 4663 %}
 4664 
 4665 // Pointer 64 bit Register R4 only
 4666 operand iRegP_R4()
 4667 %{
 4668   constraint(ALLOC_IN_RC(r4_reg));
 4669   match(RegP);
 4670   // match(iRegP);
 4671   match(iRegPNoSp);
 4672   op_cost(0);
 4673   format %{ %}
 4674   interface(REG_INTER);
 4675 %}
 4676 
 4677 // Pointer 64 bit Register R5 only
 4678 operand iRegP_R5()
 4679 %{
 4680   constraint(ALLOC_IN_RC(r5_reg));
 4681   match(RegP);
 4682   // match(iRegP);
 4683   match(iRegPNoSp);
 4684   op_cost(0);
 4685   format %{ %}
 4686   interface(REG_INTER);
 4687 %}
 4688 
 4689 // Pointer 64 bit Register R10 only
 4690 operand iRegP_R10()
 4691 %{
 4692   constraint(ALLOC_IN_RC(r10_reg));
 4693   match(RegP);
 4694   // match(iRegP);
 4695   match(iRegPNoSp);
 4696   op_cost(0);
 4697   format %{ %}
 4698   interface(REG_INTER);
 4699 %}
 4700 
 4701 // Long 64 bit Register R0 only
 4702 operand iRegL_R0()
 4703 %{
 4704   constraint(ALLOC_IN_RC(r0_reg));
 4705   match(RegL);
 4706   match(iRegLNoSp);
 4707   op_cost(0);
 4708   format %{ %}
 4709   interface(REG_INTER);
 4710 %}
 4711 
 4712 // Long 64 bit Register R2 only
 4713 operand iRegL_R2()
 4714 %{
 4715   constraint(ALLOC_IN_RC(r2_reg));
 4716   match(RegL);
 4717   match(iRegLNoSp);
 4718   op_cost(0);
 4719   format %{ %}
 4720   interface(REG_INTER);
 4721 %}
 4722 
 4723 // Long 64 bit Register R3 only
 4724 operand iRegL_R3()
 4725 %{
 4726   constraint(ALLOC_IN_RC(r3_reg));
 4727   match(RegL);
 4728   match(iRegLNoSp);
 4729   op_cost(0);
 4730   format %{ %}
 4731   interface(REG_INTER);
 4732 %}
 4733 
 4734 // Long 64 bit Register R11 only
 4735 operand iRegL_R11()
 4736 %{
 4737   constraint(ALLOC_IN_RC(r11_reg));
 4738   match(RegL);
 4739   match(iRegLNoSp);
 4740   op_cost(0);
 4741   format %{ %}
 4742   interface(REG_INTER);
 4743 %}
 4744 
 4745 // Pointer 64 bit Register FP only
 4746 operand iRegP_FP()
 4747 %{
 4748   constraint(ALLOC_IN_RC(fp_reg));
 4749   match(RegP);
 4750   // match(iRegP);
 4751   op_cost(0);
 4752   format %{ %}
 4753   interface(REG_INTER);
 4754 %}
 4755 
 4756 // Register R0 only
 4757 operand iRegI_R0()
 4758 %{
 4759   constraint(ALLOC_IN_RC(int_r0_reg));
 4760   match(RegI);
 4761   match(iRegINoSp);
 4762   op_cost(0);
 4763   format %{ %}
 4764   interface(REG_INTER);
 4765 %}
 4766 
 4767 // Register R2 only
 4768 operand iRegI_R2()
 4769 %{
 4770   constraint(ALLOC_IN_RC(int_r2_reg));
 4771   match(RegI);
 4772   match(iRegINoSp);
 4773   op_cost(0);
 4774   format %{ %}
 4775   interface(REG_INTER);
 4776 %}
 4777 
 4778 // Register R3 only
 4779 operand iRegI_R3()
 4780 %{
 4781   constraint(ALLOC_IN_RC(int_r3_reg));
 4782   match(RegI);
 4783   match(iRegINoSp);
 4784   op_cost(0);
 4785   format %{ %}
 4786   interface(REG_INTER);
 4787 %}
 4788 
 4789 
 4790 // Register R4 only
 4791 operand iRegI_R4()
 4792 %{
 4793   constraint(ALLOC_IN_RC(int_r4_reg));
 4794   match(RegI);
 4795   match(iRegINoSp);
 4796   op_cost(0);
 4797   format %{ %}
 4798   interface(REG_INTER);
 4799 %}
 4800 
 4801 
 4802 // Pointer Register Operands
 4803 // Narrow Pointer Register
 4804 operand iRegN()
 4805 %{
 4806   constraint(ALLOC_IN_RC(any_reg32));
 4807   match(RegN);
 4808   match(iRegNNoSp);
 4809   op_cost(0);
 4810   format %{ %}
 4811   interface(REG_INTER);
 4812 %}
 4813 
 4814 operand iRegN_R0()
 4815 %{
 4816   constraint(ALLOC_IN_RC(r0_reg));
 4817   match(iRegN);
 4818   op_cost(0);
 4819   format %{ %}
 4820   interface(REG_INTER);
 4821 %}
 4822 
 4823 operand iRegN_R2()
 4824 %{
 4825   constraint(ALLOC_IN_RC(r2_reg));
 4826   match(iRegN);
 4827   op_cost(0);
 4828   format %{ %}
 4829   interface(REG_INTER);
 4830 %}
 4831 
 4832 operand iRegN_R3()
 4833 %{
 4834   constraint(ALLOC_IN_RC(r3_reg));
 4835   match(iRegN);
 4836   op_cost(0);
 4837   format %{ %}
 4838   interface(REG_INTER);
 4839 %}
 4840 
 4841 // Integer 64 bit Register not Special
 4842 operand iRegNNoSp()
 4843 %{
 4844   constraint(ALLOC_IN_RC(no_special_reg32));
 4845   match(RegN);
 4846   op_cost(0);
 4847   format %{ %}
 4848   interface(REG_INTER);
 4849 %}
 4850 
 4851 // heap base register -- used for encoding immN0
 4852 
 4853 operand iRegIHeapbase()
 4854 %{
 4855   constraint(ALLOC_IN_RC(heapbase_reg));
 4856   match(RegI);
 4857   op_cost(0);
 4858   format %{ %}
 4859   interface(REG_INTER);
 4860 %}
 4861 
 4862 // Float Register
 4863 // Float register operands
 4864 operand vRegF()
 4865 %{
 4866   constraint(ALLOC_IN_RC(float_reg));
 4867   match(RegF);
 4868 
 4869   op_cost(0);
 4870   format %{ %}
 4871   interface(REG_INTER);
 4872 %}
 4873 
 4874 // Double Register
 4875 // Double register operands
 4876 operand vRegD()
 4877 %{
 4878   constraint(ALLOC_IN_RC(double_reg));
 4879   match(RegD);
 4880 
 4881   op_cost(0);
 4882   format %{ %}
 4883   interface(REG_INTER);
 4884 %}
 4885 
 4886 operand vecD()
 4887 %{
 4888   constraint(ALLOC_IN_RC(vectord_reg));
 4889   match(VecD);
 4890 
 4891   op_cost(0);
 4892   format %{ %}
 4893   interface(REG_INTER);
 4894 %}
 4895 
 4896 operand vecX()
 4897 %{
 4898   constraint(ALLOC_IN_RC(vectorx_reg));
 4899   match(VecX);
 4900 
 4901   op_cost(0);
 4902   format %{ %}
 4903   interface(REG_INTER);
 4904 %}
 4905 
 4906 operand vRegD_V0()
 4907 %{
 4908   constraint(ALLOC_IN_RC(v0_reg));
 4909   match(RegD);
 4910   op_cost(0);
 4911   format %{ %}
 4912   interface(REG_INTER);
 4913 %}
 4914 
 4915 operand vRegD_V1()
 4916 %{
 4917   constraint(ALLOC_IN_RC(v1_reg));
 4918   match(RegD);
 4919   op_cost(0);
 4920   format %{ %}
 4921   interface(REG_INTER);
 4922 %}
 4923 
 4924 operand vRegD_V2()
 4925 %{
 4926   constraint(ALLOC_IN_RC(v2_reg));
 4927   match(RegD);
 4928   op_cost(0);
 4929   format %{ %}
 4930   interface(REG_INTER);
 4931 %}
 4932 
 4933 operand vRegD_V3()
 4934 %{
 4935   constraint(ALLOC_IN_RC(v3_reg));
 4936   match(RegD);
 4937   op_cost(0);
 4938   format %{ %}
 4939   interface(REG_INTER);
 4940 %}
 4941 
 4942 operand vRegD_V4()
 4943 %{
 4944   constraint(ALLOC_IN_RC(v4_reg));
 4945   match(RegD);
 4946   op_cost(0);
 4947   format %{ %}
 4948   interface(REG_INTER);
 4949 %}
 4950 
 4951 operand vRegD_V5()
 4952 %{
 4953   constraint(ALLOC_IN_RC(v5_reg));
 4954   match(RegD);
 4955   op_cost(0);
 4956   format %{ %}
 4957   interface(REG_INTER);
 4958 %}
 4959 
 4960 operand vRegD_V6()
 4961 %{
 4962   constraint(ALLOC_IN_RC(v6_reg));
 4963   match(RegD);
 4964   op_cost(0);
 4965   format %{ %}
 4966   interface(REG_INTER);
 4967 %}
 4968 
 4969 operand vRegD_V7()
 4970 %{
 4971   constraint(ALLOC_IN_RC(v7_reg));
 4972   match(RegD);
 4973   op_cost(0);
 4974   format %{ %}
 4975   interface(REG_INTER);
 4976 %}
 4977 
 4978 operand vRegD_V8()
 4979 %{
 4980   constraint(ALLOC_IN_RC(v8_reg));
 4981   match(RegD);
 4982   op_cost(0);
 4983   format %{ %}
 4984   interface(REG_INTER);
 4985 %}
 4986 
 4987 operand vRegD_V9()
 4988 %{
 4989   constraint(ALLOC_IN_RC(v9_reg));
 4990   match(RegD);
 4991   op_cost(0);
 4992   format %{ %}
 4993   interface(REG_INTER);
 4994 %}
 4995 
 4996 operand vRegD_V10()
 4997 %{
 4998   constraint(ALLOC_IN_RC(v10_reg));
 4999   match(RegD);
 5000   op_cost(0);
 5001   format %{ %}
 5002   interface(REG_INTER);
 5003 %}
 5004 
 5005 operand vRegD_V11()
 5006 %{
 5007   constraint(ALLOC_IN_RC(v11_reg));
 5008   match(RegD);
 5009   op_cost(0);
 5010   format %{ %}
 5011   interface(REG_INTER);
 5012 %}
 5013 
 5014 operand vRegD_V12()
 5015 %{
 5016   constraint(ALLOC_IN_RC(v12_reg));
 5017   match(RegD);
 5018   op_cost(0);
 5019   format %{ %}
 5020   interface(REG_INTER);
 5021 %}
 5022 
 5023 operand vRegD_V13()
 5024 %{
 5025   constraint(ALLOC_IN_RC(v13_reg));
 5026   match(RegD);
 5027   op_cost(0);
 5028   format %{ %}
 5029   interface(REG_INTER);
 5030 %}
 5031 
 5032 operand vRegD_V14()
 5033 %{
 5034   constraint(ALLOC_IN_RC(v14_reg));
 5035   match(RegD);
 5036   op_cost(0);
 5037   format %{ %}
 5038   interface(REG_INTER);
 5039 %}
 5040 
 5041 operand vRegD_V15()
 5042 %{
 5043   constraint(ALLOC_IN_RC(v15_reg));
 5044   match(RegD);
 5045   op_cost(0);
 5046   format %{ %}
 5047   interface(REG_INTER);
 5048 %}
 5049 
 5050 operand vRegD_V16()
 5051 %{
 5052   constraint(ALLOC_IN_RC(v16_reg));
 5053   match(RegD);
 5054   op_cost(0);
 5055   format %{ %}
 5056   interface(REG_INTER);
 5057 %}
 5058 
 5059 operand vRegD_V17()
 5060 %{
 5061   constraint(ALLOC_IN_RC(v17_reg));
 5062   match(RegD);
 5063   op_cost(0);
 5064   format %{ %}
 5065   interface(REG_INTER);
 5066 %}
 5067 
 5068 operand vRegD_V18()
 5069 %{
 5070   constraint(ALLOC_IN_RC(v18_reg));
 5071   match(RegD);
 5072   op_cost(0);
 5073   format %{ %}
 5074   interface(REG_INTER);
 5075 %}
 5076 
 5077 operand vRegD_V19()
 5078 %{
 5079   constraint(ALLOC_IN_RC(v19_reg));
 5080   match(RegD);
 5081   op_cost(0);
 5082   format %{ %}
 5083   interface(REG_INTER);
 5084 %}
 5085 
 5086 operand vRegD_V20()
 5087 %{
 5088   constraint(ALLOC_IN_RC(v20_reg));
 5089   match(RegD);
 5090   op_cost(0);
 5091   format %{ %}
 5092   interface(REG_INTER);
 5093 %}
 5094 
 5095 operand vRegD_V21()
 5096 %{
 5097   constraint(ALLOC_IN_RC(v21_reg));
 5098   match(RegD);
 5099   op_cost(0);
 5100   format %{ %}
 5101   interface(REG_INTER);
 5102 %}
 5103 
 5104 operand vRegD_V22()
 5105 %{
 5106   constraint(ALLOC_IN_RC(v22_reg));
 5107   match(RegD);
 5108   op_cost(0);
 5109   format %{ %}
 5110   interface(REG_INTER);
 5111 %}
 5112 
 5113 operand vRegD_V23()
 5114 %{
 5115   constraint(ALLOC_IN_RC(v23_reg));
 5116   match(RegD);
 5117   op_cost(0);
 5118   format %{ %}
 5119   interface(REG_INTER);
 5120 %}
 5121 
 5122 operand vRegD_V24()
 5123 %{
 5124   constraint(ALLOC_IN_RC(v24_reg));
 5125   match(RegD);
 5126   op_cost(0);
 5127   format %{ %}
 5128   interface(REG_INTER);
 5129 %}
 5130 
 5131 operand vRegD_V25()
 5132 %{
 5133   constraint(ALLOC_IN_RC(v25_reg));
 5134   match(RegD);
 5135   op_cost(0);
 5136   format %{ %}
 5137   interface(REG_INTER);
 5138 %}
 5139 
 5140 operand vRegD_V26()
 5141 %{
 5142   constraint(ALLOC_IN_RC(v26_reg));
 5143   match(RegD);
 5144   op_cost(0);
 5145   format %{ %}
 5146   interface(REG_INTER);
 5147 %}
 5148 
 5149 operand vRegD_V27()
 5150 %{
 5151   constraint(ALLOC_IN_RC(v27_reg));
 5152   match(RegD);
 5153   op_cost(0);
 5154   format %{ %}
 5155   interface(REG_INTER);
 5156 %}
 5157 
 5158 operand vRegD_V28()
 5159 %{
 5160   constraint(ALLOC_IN_RC(v28_reg));
 5161   match(RegD);
 5162   op_cost(0);
 5163   format %{ %}
 5164   interface(REG_INTER);
 5165 %}
 5166 
 5167 operand vRegD_V29()
 5168 %{
 5169   constraint(ALLOC_IN_RC(v29_reg));
 5170   match(RegD);
 5171   op_cost(0);
 5172   format %{ %}
 5173   interface(REG_INTER);
 5174 %}
 5175 
 5176 operand vRegD_V30()
 5177 %{
 5178   constraint(ALLOC_IN_RC(v30_reg));
 5179   match(RegD);
 5180   op_cost(0);
 5181   format %{ %}
 5182   interface(REG_INTER);
 5183 %}
 5184 
 5185 operand vRegD_V31()
 5186 %{
 5187   constraint(ALLOC_IN_RC(v31_reg));
 5188   match(RegD);
 5189   op_cost(0);
 5190   format %{ %}
 5191   interface(REG_INTER);
 5192 %}
 5193 
 5194 // Flags register, used as output of signed compare instructions
 5195 
 5196 // note that on AArch64 we also use this register as the output for
 5197 // for floating point compare instructions (CmpF CmpD). this ensures
 5198 // that ordered inequality tests use GT, GE, LT or LE none of which
 5199 // pass through cases where the result is unordered i.e. one or both
 5200 // inputs to the compare is a NaN. this means that the ideal code can
 5201 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5202 // (where the comparison should always fail). EQ and NE tests are
 5203 // always generated in ideal code so that unordered folds into the NE
 5204 // case, matching the behaviour of AArch64 NE.
 5205 //
 5206 // This differs from x86 where the outputs of FP compares use a
 5207 // special FP flags registers and where compares based on this
 5208 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5209 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5210 // to explicitly handle the unordered case in branches. x86 also has
 5211 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5212 
 5213 operand rFlagsReg()
 5214 %{
 5215   constraint(ALLOC_IN_RC(int_flags));
 5216   match(RegFlags);
 5217 
 5218   op_cost(0);
 5219   format %{ &quot;RFLAGS&quot; %}
 5220   interface(REG_INTER);
 5221 %}
 5222 
 5223 // Flags register, used as output of unsigned compare instructions
 5224 operand rFlagsRegU()
 5225 %{
 5226   constraint(ALLOC_IN_RC(int_flags));
 5227   match(RegFlags);
 5228 
 5229   op_cost(0);
 5230   format %{ &quot;RFLAGSU&quot; %}
 5231   interface(REG_INTER);
 5232 %}
 5233 
 5234 // Special Registers
 5235 
 5236 // Method Register
 5237 operand inline_cache_RegP(iRegP reg)
 5238 %{
 5239   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5240   match(reg);
 5241   match(iRegPNoSp);
 5242   op_cost(0);
 5243   format %{ %}
 5244   interface(REG_INTER);
 5245 %}
 5246 
 5247 operand interpreter_method_oop_RegP(iRegP reg)
 5248 %{
 5249   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5250   match(reg);
 5251   match(iRegPNoSp);
 5252   op_cost(0);
 5253   format %{ %}
 5254   interface(REG_INTER);
 5255 %}
 5256 
 5257 // Thread Register
 5258 operand thread_RegP(iRegP reg)
 5259 %{
 5260   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5261   match(reg);
 5262   op_cost(0);
 5263   format %{ %}
 5264   interface(REG_INTER);
 5265 %}
 5266 
 5267 operand lr_RegP(iRegP reg)
 5268 %{
 5269   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5270   match(reg);
 5271   op_cost(0);
 5272   format %{ %}
 5273   interface(REG_INTER);
 5274 %}
 5275 
 5276 //----------Memory Operands----------------------------------------------------
 5277 
 5278 operand indirect(iRegP reg)
 5279 %{
 5280   constraint(ALLOC_IN_RC(ptr_reg));
 5281   match(reg);
 5282   op_cost(0);
 5283   format %{ &quot;[$reg]&quot; %}
 5284   interface(MEMORY_INTER) %{
 5285     base($reg);
 5286     index(0xffffffff);
 5287     scale(0x0);
 5288     disp(0x0);
 5289   %}
 5290 %}
 5291 
 5292 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5293 %{
 5294   constraint(ALLOC_IN_RC(ptr_reg));
 5295   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5296   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5297   op_cost(0);
 5298   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5299   interface(MEMORY_INTER) %{
 5300     base($reg);
 5301     index($ireg);
 5302     scale($scale);
 5303     disp(0x0);
 5304   %}
 5305 %}
 5306 
 5307 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5308 %{
 5309   constraint(ALLOC_IN_RC(ptr_reg));
 5310   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5311   match(AddP reg (LShiftL lreg scale));
 5312   op_cost(0);
 5313   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5314   interface(MEMORY_INTER) %{
 5315     base($reg);
 5316     index($lreg);
 5317     scale($scale);
 5318     disp(0x0);
 5319   %}
 5320 %}
 5321 
 5322 operand indIndexI2L(iRegP reg, iRegI ireg)
 5323 %{
 5324   constraint(ALLOC_IN_RC(ptr_reg));
 5325   match(AddP reg (ConvI2L ireg));
 5326   op_cost(0);
 5327   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5328   interface(MEMORY_INTER) %{
 5329     base($reg);
 5330     index($ireg);
 5331     scale(0x0);
 5332     disp(0x0);
 5333   %}
 5334 %}
 5335 
 5336 operand indIndex(iRegP reg, iRegL lreg)
 5337 %{
 5338   constraint(ALLOC_IN_RC(ptr_reg));
 5339   match(AddP reg lreg);
 5340   op_cost(0);
 5341   format %{ &quot;$reg, $lreg&quot; %}
 5342   interface(MEMORY_INTER) %{
 5343     base($reg);
 5344     index($lreg);
 5345     scale(0x0);
 5346     disp(0x0);
 5347   %}
 5348 %}
 5349 
 5350 operand indOffI(iRegP reg, immIOffset off)
 5351 %{
 5352   constraint(ALLOC_IN_RC(ptr_reg));
 5353   match(AddP reg off);
 5354   op_cost(0);
 5355   format %{ &quot;[$reg, $off]&quot; %}
 5356   interface(MEMORY_INTER) %{
 5357     base($reg);
 5358     index(0xffffffff);
 5359     scale(0x0);
 5360     disp($off);
 5361   %}
 5362 %}
 5363 
 5364 operand indOffI1(iRegP reg, immIOffset1 off)
 5365 %{
 5366   constraint(ALLOC_IN_RC(ptr_reg));
 5367   match(AddP reg off);
 5368   op_cost(0);
 5369   format %{ &quot;[$reg, $off]&quot; %}
 5370   interface(MEMORY_INTER) %{
 5371     base($reg);
 5372     index(0xffffffff);
 5373     scale(0x0);
 5374     disp($off);
 5375   %}
 5376 %}
 5377 
 5378 operand indOffI2(iRegP reg, immIOffset2 off)
 5379 %{
 5380   constraint(ALLOC_IN_RC(ptr_reg));
 5381   match(AddP reg off);
 5382   op_cost(0);
 5383   format %{ &quot;[$reg, $off]&quot; %}
 5384   interface(MEMORY_INTER) %{
 5385     base($reg);
 5386     index(0xffffffff);
 5387     scale(0x0);
 5388     disp($off);
 5389   %}
 5390 %}
 5391 
 5392 operand indOffI4(iRegP reg, immIOffset4 off)
 5393 %{
 5394   constraint(ALLOC_IN_RC(ptr_reg));
 5395   match(AddP reg off);
 5396   op_cost(0);
 5397   format %{ &quot;[$reg, $off]&quot; %}
 5398   interface(MEMORY_INTER) %{
 5399     base($reg);
 5400     index(0xffffffff);
 5401     scale(0x0);
 5402     disp($off);
 5403   %}
 5404 %}
 5405 
 5406 operand indOffI8(iRegP reg, immIOffset8 off)
 5407 %{
 5408   constraint(ALLOC_IN_RC(ptr_reg));
 5409   match(AddP reg off);
 5410   op_cost(0);
 5411   format %{ &quot;[$reg, $off]&quot; %}
 5412   interface(MEMORY_INTER) %{
 5413     base($reg);
 5414     index(0xffffffff);
 5415     scale(0x0);
 5416     disp($off);
 5417   %}
 5418 %}
 5419 
 5420 operand indOffI16(iRegP reg, immIOffset16 off)
 5421 %{
 5422   constraint(ALLOC_IN_RC(ptr_reg));
 5423   match(AddP reg off);
 5424   op_cost(0);
 5425   format %{ &quot;[$reg, $off]&quot; %}
 5426   interface(MEMORY_INTER) %{
 5427     base($reg);
 5428     index(0xffffffff);
 5429     scale(0x0);
 5430     disp($off);
 5431   %}
 5432 %}
 5433 
 5434 operand indOffL(iRegP reg, immLoffset off)
 5435 %{
 5436   constraint(ALLOC_IN_RC(ptr_reg));
 5437   match(AddP reg off);
 5438   op_cost(0);
 5439   format %{ &quot;[$reg, $off]&quot; %}
 5440   interface(MEMORY_INTER) %{
 5441     base($reg);
 5442     index(0xffffffff);
 5443     scale(0x0);
 5444     disp($off);
 5445   %}
 5446 %}
 5447 
 5448 operand indOffL1(iRegP reg, immLoffset1 off)
 5449 %{
 5450   constraint(ALLOC_IN_RC(ptr_reg));
 5451   match(AddP reg off);
 5452   op_cost(0);
 5453   format %{ &quot;[$reg, $off]&quot; %}
 5454   interface(MEMORY_INTER) %{
 5455     base($reg);
 5456     index(0xffffffff);
 5457     scale(0x0);
 5458     disp($off);
 5459   %}
 5460 %}
 5461 
 5462 operand indOffL2(iRegP reg, immLoffset2 off)
 5463 %{
 5464   constraint(ALLOC_IN_RC(ptr_reg));
 5465   match(AddP reg off);
 5466   op_cost(0);
 5467   format %{ &quot;[$reg, $off]&quot; %}
 5468   interface(MEMORY_INTER) %{
 5469     base($reg);
 5470     index(0xffffffff);
 5471     scale(0x0);
 5472     disp($off);
 5473   %}
 5474 %}
 5475 
 5476 operand indOffL4(iRegP reg, immLoffset4 off)
 5477 %{
 5478   constraint(ALLOC_IN_RC(ptr_reg));
 5479   match(AddP reg off);
 5480   op_cost(0);
 5481   format %{ &quot;[$reg, $off]&quot; %}
 5482   interface(MEMORY_INTER) %{
 5483     base($reg);
 5484     index(0xffffffff);
 5485     scale(0x0);
 5486     disp($off);
 5487   %}
 5488 %}
 5489 
 5490 operand indOffL8(iRegP reg, immLoffset8 off)
 5491 %{
 5492   constraint(ALLOC_IN_RC(ptr_reg));
 5493   match(AddP reg off);
 5494   op_cost(0);
 5495   format %{ &quot;[$reg, $off]&quot; %}
 5496   interface(MEMORY_INTER) %{
 5497     base($reg);
 5498     index(0xffffffff);
 5499     scale(0x0);
 5500     disp($off);
 5501   %}
 5502 %}
 5503 
 5504 operand indOffL16(iRegP reg, immLoffset16 off)
 5505 %{
 5506   constraint(ALLOC_IN_RC(ptr_reg));
 5507   match(AddP reg off);
 5508   op_cost(0);
 5509   format %{ &quot;[$reg, $off]&quot; %}
 5510   interface(MEMORY_INTER) %{
 5511     base($reg);
 5512     index(0xffffffff);
 5513     scale(0x0);
 5514     disp($off);
 5515   %}
 5516 %}
 5517 
 5518 operand indirectN(iRegN reg)
 5519 %{
 5520   predicate(CompressedOops::shift() == 0);
 5521   constraint(ALLOC_IN_RC(ptr_reg));
 5522   match(DecodeN reg);
 5523   op_cost(0);
 5524   format %{ &quot;[$reg]\t# narrow&quot; %}
 5525   interface(MEMORY_INTER) %{
 5526     base($reg);
 5527     index(0xffffffff);
 5528     scale(0x0);
 5529     disp(0x0);
 5530   %}
 5531 %}
 5532 
 5533 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5534 %{
 5535   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5536   constraint(ALLOC_IN_RC(ptr_reg));
 5537   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5538   op_cost(0);
 5539   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5540   interface(MEMORY_INTER) %{
 5541     base($reg);
 5542     index($ireg);
 5543     scale($scale);
 5544     disp(0x0);
 5545   %}
 5546 %}
 5547 
 5548 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5549 %{
 5550   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5551   constraint(ALLOC_IN_RC(ptr_reg));
 5552   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5553   op_cost(0);
 5554   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5555   interface(MEMORY_INTER) %{
 5556     base($reg);
 5557     index($lreg);
 5558     scale($scale);
 5559     disp(0x0);
 5560   %}
 5561 %}
 5562 
 5563 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5564 %{
 5565   predicate(CompressedOops::shift() == 0);
 5566   constraint(ALLOC_IN_RC(ptr_reg));
 5567   match(AddP (DecodeN reg) (ConvI2L ireg));
 5568   op_cost(0);
 5569   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5570   interface(MEMORY_INTER) %{
 5571     base($reg);
 5572     index($ireg);
 5573     scale(0x0);
 5574     disp(0x0);
 5575   %}
 5576 %}
 5577 
 5578 operand indIndexN(iRegN reg, iRegL lreg)
 5579 %{
 5580   predicate(CompressedOops::shift() == 0);
 5581   constraint(ALLOC_IN_RC(ptr_reg));
 5582   match(AddP (DecodeN reg) lreg);
 5583   op_cost(0);
 5584   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5585   interface(MEMORY_INTER) %{
 5586     base($reg);
 5587     index($lreg);
 5588     scale(0x0);
 5589     disp(0x0);
 5590   %}
 5591 %}
 5592 
 5593 operand indOffIN(iRegN reg, immIOffset off)
 5594 %{
 5595   predicate(CompressedOops::shift() == 0);
 5596   constraint(ALLOC_IN_RC(ptr_reg));
 5597   match(AddP (DecodeN reg) off);
 5598   op_cost(0);
 5599   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5600   interface(MEMORY_INTER) %{
 5601     base($reg);
 5602     index(0xffffffff);
 5603     scale(0x0);
 5604     disp($off);
 5605   %}
 5606 %}
 5607 
 5608 operand indOffLN(iRegN reg, immLoffset off)
 5609 %{
 5610   predicate(CompressedOops::shift() == 0);
 5611   constraint(ALLOC_IN_RC(ptr_reg));
 5612   match(AddP (DecodeN reg) off);
 5613   op_cost(0);
 5614   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5615   interface(MEMORY_INTER) %{
 5616     base($reg);
 5617     index(0xffffffff);
 5618     scale(0x0);
 5619     disp($off);
 5620   %}
 5621 %}
 5622 
 5623 
 5624 
 5625 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5626 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5627 %{
 5628   constraint(ALLOC_IN_RC(ptr_reg));
 5629   match(AddP reg off);
 5630   op_cost(0);
 5631   format %{ &quot;[$reg, $off]&quot; %}
 5632   interface(MEMORY_INTER) %{
 5633     base($reg);
 5634     index(0xffffffff);
 5635     scale(0x0);
 5636     disp($off);
 5637   %}
 5638 %}
 5639 
 5640 //----------Special Memory Operands--------------------------------------------
 5641 // Stack Slot Operand - This operand is used for loading and storing temporary
 5642 //                      values on the stack where a match requires a value to
 5643 //                      flow through memory.
 5644 operand stackSlotP(sRegP reg)
 5645 %{
 5646   constraint(ALLOC_IN_RC(stack_slots));
 5647   op_cost(100);
 5648   // No match rule because this operand is only generated in matching
 5649   // match(RegP);
 5650   format %{ &quot;[$reg]&quot; %}
 5651   interface(MEMORY_INTER) %{
 5652     base(0x1e);  // RSP
 5653     index(0x0);  // No Index
 5654     scale(0x0);  // No Scale
 5655     disp($reg);  // Stack Offset
 5656   %}
 5657 %}
 5658 
 5659 operand stackSlotI(sRegI reg)
 5660 %{
 5661   constraint(ALLOC_IN_RC(stack_slots));
 5662   // No match rule because this operand is only generated in matching
 5663   // match(RegI);
 5664   format %{ &quot;[$reg]&quot; %}
 5665   interface(MEMORY_INTER) %{
 5666     base(0x1e);  // RSP
 5667     index(0x0);  // No Index
 5668     scale(0x0);  // No Scale
 5669     disp($reg);  // Stack Offset
 5670   %}
 5671 %}
 5672 
 5673 operand stackSlotF(sRegF reg)
 5674 %{
 5675   constraint(ALLOC_IN_RC(stack_slots));
 5676   // No match rule because this operand is only generated in matching
 5677   // match(RegF);
 5678   format %{ &quot;[$reg]&quot; %}
 5679   interface(MEMORY_INTER) %{
 5680     base(0x1e);  // RSP
 5681     index(0x0);  // No Index
 5682     scale(0x0);  // No Scale
 5683     disp($reg);  // Stack Offset
 5684   %}
 5685 %}
 5686 
 5687 operand stackSlotD(sRegD reg)
 5688 %{
 5689   constraint(ALLOC_IN_RC(stack_slots));
 5690   // No match rule because this operand is only generated in matching
 5691   // match(RegD);
 5692   format %{ &quot;[$reg]&quot; %}
 5693   interface(MEMORY_INTER) %{
 5694     base(0x1e);  // RSP
 5695     index(0x0);  // No Index
 5696     scale(0x0);  // No Scale
 5697     disp($reg);  // Stack Offset
 5698   %}
 5699 %}
 5700 
 5701 operand stackSlotL(sRegL reg)
 5702 %{
 5703   constraint(ALLOC_IN_RC(stack_slots));
 5704   // No match rule because this operand is only generated in matching
 5705   // match(RegL);
 5706   format %{ &quot;[$reg]&quot; %}
 5707   interface(MEMORY_INTER) %{
 5708     base(0x1e);  // RSP
 5709     index(0x0);  // No Index
 5710     scale(0x0);  // No Scale
 5711     disp($reg);  // Stack Offset
 5712   %}
 5713 %}
 5714 
 5715 // Operands for expressing Control Flow
 5716 // NOTE: Label is a predefined operand which should not be redefined in
 5717 //       the AD file. It is generically handled within the ADLC.
 5718 
 5719 //----------Conditional Branch Operands----------------------------------------
 5720 // Comparison Op  - This is the operation of the comparison, and is limited to
 5721 //                  the following set of codes:
 5722 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5723 //
 5724 // Other attributes of the comparison, such as unsignedness, are specified
 5725 // by the comparison instruction that sets a condition code flags register.
 5726 // That result is represented by a flags operand whose subtype is appropriate
 5727 // to the unsignedness (etc.) of the comparison.
 5728 //
 5729 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5730 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5731 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5732 
 5733 // used for signed integral comparisons and fp comparisons
 5734 
 5735 operand cmpOp()
 5736 %{
 5737   match(Bool);
 5738 
 5739   format %{ &quot;&quot; %}
 5740   interface(COND_INTER) %{
 5741     equal(0x0, &quot;eq&quot;);
 5742     not_equal(0x1, &quot;ne&quot;);
 5743     less(0xb, &quot;lt&quot;);
 5744     greater_equal(0xa, &quot;ge&quot;);
 5745     less_equal(0xd, &quot;le&quot;);
 5746     greater(0xc, &quot;gt&quot;);
 5747     overflow(0x6, &quot;vs&quot;);
 5748     no_overflow(0x7, &quot;vc&quot;);
 5749   %}
 5750 %}
 5751 
 5752 // used for unsigned integral comparisons
 5753 
 5754 operand cmpOpU()
 5755 %{
 5756   match(Bool);
 5757 
 5758   format %{ &quot;&quot; %}
 5759   interface(COND_INTER) %{
 5760     equal(0x0, &quot;eq&quot;);
 5761     not_equal(0x1, &quot;ne&quot;);
 5762     less(0x3, &quot;lo&quot;);
 5763     greater_equal(0x2, &quot;hs&quot;);
 5764     less_equal(0x9, &quot;ls&quot;);
 5765     greater(0x8, &quot;hi&quot;);
 5766     overflow(0x6, &quot;vs&quot;);
 5767     no_overflow(0x7, &quot;vc&quot;);
 5768   %}
 5769 %}
 5770 
 5771 // used for certain integral comparisons which can be
 5772 // converted to cbxx or tbxx instructions
 5773 
 5774 operand cmpOpEqNe()
 5775 %{
 5776   match(Bool);
 5777   op_cost(0);
 5778   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5779             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5780 
 5781   format %{ &quot;&quot; %}
 5782   interface(COND_INTER) %{
 5783     equal(0x0, &quot;eq&quot;);
 5784     not_equal(0x1, &quot;ne&quot;);
 5785     less(0xb, &quot;lt&quot;);
 5786     greater_equal(0xa, &quot;ge&quot;);
 5787     less_equal(0xd, &quot;le&quot;);
 5788     greater(0xc, &quot;gt&quot;);
 5789     overflow(0x6, &quot;vs&quot;);
 5790     no_overflow(0x7, &quot;vc&quot;);
 5791   %}
 5792 %}
 5793 
 5794 // used for certain integral comparisons which can be
 5795 // converted to cbxx or tbxx instructions
 5796 
 5797 operand cmpOpLtGe()
 5798 %{
 5799   match(Bool);
 5800   op_cost(0);
 5801 
 5802   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5803             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5804 
 5805   format %{ &quot;&quot; %}
 5806   interface(COND_INTER) %{
 5807     equal(0x0, &quot;eq&quot;);
 5808     not_equal(0x1, &quot;ne&quot;);
 5809     less(0xb, &quot;lt&quot;);
 5810     greater_equal(0xa, &quot;ge&quot;);
 5811     less_equal(0xd, &quot;le&quot;);
 5812     greater(0xc, &quot;gt&quot;);
 5813     overflow(0x6, &quot;vs&quot;);
 5814     no_overflow(0x7, &quot;vc&quot;);
 5815   %}
 5816 %}
 5817 
 5818 // used for certain unsigned integral comparisons which can be
 5819 // converted to cbxx or tbxx instructions
 5820 
 5821 operand cmpOpUEqNeLtGe()
 5822 %{
 5823   match(Bool);
 5824   op_cost(0);
 5825 
 5826   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5827             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5828             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5829             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5830 
 5831   format %{ &quot;&quot; %}
 5832   interface(COND_INTER) %{
 5833     equal(0x0, &quot;eq&quot;);
 5834     not_equal(0x1, &quot;ne&quot;);
 5835     less(0xb, &quot;lt&quot;);
 5836     greater_equal(0xa, &quot;ge&quot;);
 5837     less_equal(0xd, &quot;le&quot;);
 5838     greater(0xc, &quot;gt&quot;);
 5839     overflow(0x6, &quot;vs&quot;);
 5840     no_overflow(0x7, &quot;vc&quot;);
 5841   %}
 5842 %}
 5843 
 5844 // Special operand allowing long args to int ops to be truncated for free
 5845 
 5846 operand iRegL2I(iRegL reg) %{
 5847 
 5848   op_cost(0);
 5849 
 5850   match(ConvL2I reg);
 5851 
 5852   format %{ &quot;l2i($reg)&quot; %}
 5853 
 5854   interface(REG_INTER)
 5855 %}
 5856 
 5857 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5858 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5859 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5860 
 5861 //----------OPERAND CLASSES----------------------------------------------------
 5862 // Operand Classes are groups of operands that are used as to simplify
 5863 // instruction definitions by not requiring the AD writer to specify
 5864 // separate instructions for every form of operand when the
 5865 // instruction accepts multiple operand types with the same basic
 5866 // encoding and format. The classic case of this is memory operands.
 5867 
 5868 // memory is used to define read/write location for load/store
 5869 // instruction defs. we can turn a memory op into an Address
 5870 
 5871 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5872                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5873 
 5874 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5875                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5876 
 5877 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5878                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5879 
 5880 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5881                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5882 
 5883 // All of the memory operands. For the pipeline description.
 5884 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5885                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5886                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5887 
 5888 
 5889 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5890 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5891 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5892 // can be elided because the 32-bit instruction will just employ the
 5893 // lower 32 bits anyway.
 5894 //
 5895 // n.b. this does not elide all L2I conversions. if the truncated
 5896 // value is consumed by more than one operation then the ConvL2I
 5897 // cannot be bundled into the consuming nodes so an l2i gets planted
 5898 // (actually a movw $dst $src) and the downstream instructions consume
 5899 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5900 // movw is actually redundant but its not too costly.
 5901 
 5902 opclass iRegIorL2I(iRegI, iRegL2I);
 5903 
 5904 //----------PIPELINE-----------------------------------------------------------
 5905 // Rules which define the behavior of the target architectures pipeline.
 5906 
 5907 // For specific pipelines, eg A53, define the stages of that pipeline
 5908 //pipe_desc(ISS, EX1, EX2, WR);
 5909 #define ISS S0
 5910 #define EX1 S1
 5911 #define EX2 S2
 5912 #define WR  S3
 5913 
 5914 // Integer ALU reg operation
 5915 pipeline %{
 5916 
 5917 attributes %{
 5918   // ARM instructions are of fixed length
 5919   fixed_size_instructions;        // Fixed size instructions TODO does
 5920   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5921   // ARM instructions come in 32-bit word units
 5922   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5923   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5924   instruction_fetch_units = 1;       // of 64 bytes
 5925 
 5926   // List of nop instructions
 5927   nops( MachNop );
 5928 %}
 5929 
 5930 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5931 // or description. we do use pipeline classes to introduce fixed
 5932 // latencies
 5933 
 5934 //----------RESOURCES----------------------------------------------------------
 5935 // Resources are the functional units available to the machine
 5936 
 5937 resources( INS0, INS1, INS01 = INS0 | INS1,
 5938            ALU0, ALU1, ALU = ALU0 | ALU1,
 5939            MAC,
 5940            DIV,
 5941            BRANCH,
 5942            LDST,
 5943            NEON_FP);
 5944 
 5945 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5946 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5947 
 5948 // Define the pipeline as a generic 6 stage pipeline
 5949 pipe_desc(S0, S1, S2, S3, S4, S5);
 5950 
 5951 //----------PIPELINE CLASSES---------------------------------------------------
 5952 // Pipeline Classes describe the stages in which input and output are
 5953 // referenced by the hardware pipeline.
 5954 
 5955 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5956 %{
 5957   single_instruction;
 5958   src1   : S1(read);
 5959   src2   : S2(read);
 5960   dst    : S5(write);
 5961   INS01  : ISS;
 5962   NEON_FP : S5;
 5963 %}
 5964 
 5965 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5966 %{
 5967   single_instruction;
 5968   src1   : S1(read);
 5969   src2   : S2(read);
 5970   dst    : S5(write);
 5971   INS01  : ISS;
 5972   NEON_FP : S5;
 5973 %}
 5974 
 5975 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5976 %{
 5977   single_instruction;
 5978   src    : S1(read);
 5979   dst    : S5(write);
 5980   INS01  : ISS;
 5981   NEON_FP : S5;
 5982 %}
 5983 
 5984 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5985 %{
 5986   single_instruction;
 5987   src    : S1(read);
 5988   dst    : S5(write);
 5989   INS01  : ISS;
 5990   NEON_FP : S5;
 5991 %}
 5992 
 5993 pipe_class fp_d2f(vRegF dst, vRegD src)
 5994 %{
 5995   single_instruction;
 5996   src    : S1(read);
 5997   dst    : S5(write);
 5998   INS01  : ISS;
 5999   NEON_FP : S5;
 6000 %}
 6001 
 6002 pipe_class fp_f2d(vRegD dst, vRegF src)
 6003 %{
 6004   single_instruction;
 6005   src    : S1(read);
 6006   dst    : S5(write);
 6007   INS01  : ISS;
 6008   NEON_FP : S5;
 6009 %}
 6010 
 6011 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 6012 %{
 6013   single_instruction;
 6014   src    : S1(read);
 6015   dst    : S5(write);
 6016   INS01  : ISS;
 6017   NEON_FP : S5;
 6018 %}
 6019 
 6020 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6021 %{
 6022   single_instruction;
 6023   src    : S1(read);
 6024   dst    : S5(write);
 6025   INS01  : ISS;
 6026   NEON_FP : S5;
 6027 %}
 6028 
 6029 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6030 %{
 6031   single_instruction;
 6032   src    : S1(read);
 6033   dst    : S5(write);
 6034   INS01  : ISS;
 6035   NEON_FP : S5;
 6036 %}
 6037 
 6038 pipe_class fp_l2f(vRegF dst, iRegL src)
 6039 %{
 6040   single_instruction;
 6041   src    : S1(read);
 6042   dst    : S5(write);
 6043   INS01  : ISS;
 6044   NEON_FP : S5;
 6045 %}
 6046 
 6047 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6048 %{
 6049   single_instruction;
 6050   src    : S1(read);
 6051   dst    : S5(write);
 6052   INS01  : ISS;
 6053   NEON_FP : S5;
 6054 %}
 6055 
 6056 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6057 %{
 6058   single_instruction;
 6059   src    : S1(read);
 6060   dst    : S5(write);
 6061   INS01  : ISS;
 6062   NEON_FP : S5;
 6063 %}
 6064 
 6065 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6066 %{
 6067   single_instruction;
 6068   src    : S1(read);
 6069   dst    : S5(write);
 6070   INS01  : ISS;
 6071   NEON_FP : S5;
 6072 %}
 6073 
 6074 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6075 %{
 6076   single_instruction;
 6077   src    : S1(read);
 6078   dst    : S5(write);
 6079   INS01  : ISS;
 6080   NEON_FP : S5;
 6081 %}
 6082 
 6083 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6084 %{
 6085   single_instruction;
 6086   src1   : S1(read);
 6087   src2   : S2(read);
 6088   dst    : S5(write);
 6089   INS0   : ISS;
 6090   NEON_FP : S5;
 6091 %}
 6092 
 6093 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6094 %{
 6095   single_instruction;
 6096   src1   : S1(read);
 6097   src2   : S2(read);
 6098   dst    : S5(write);
 6099   INS0   : ISS;
 6100   NEON_FP : S5;
 6101 %}
 6102 
 6103 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6104 %{
 6105   single_instruction;
 6106   cr     : S1(read);
 6107   src1   : S1(read);
 6108   src2   : S1(read);
 6109   dst    : S3(write);
 6110   INS01  : ISS;
 6111   NEON_FP : S3;
 6112 %}
 6113 
 6114 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6115 %{
 6116   single_instruction;
 6117   cr     : S1(read);
 6118   src1   : S1(read);
 6119   src2   : S1(read);
 6120   dst    : S3(write);
 6121   INS01  : ISS;
 6122   NEON_FP : S3;
 6123 %}
 6124 
 6125 pipe_class fp_imm_s(vRegF dst)
 6126 %{
 6127   single_instruction;
 6128   dst    : S3(write);
 6129   INS01  : ISS;
 6130   NEON_FP : S3;
 6131 %}
 6132 
 6133 pipe_class fp_imm_d(vRegD dst)
 6134 %{
 6135   single_instruction;
 6136   dst    : S3(write);
 6137   INS01  : ISS;
 6138   NEON_FP : S3;
 6139 %}
 6140 
 6141 pipe_class fp_load_constant_s(vRegF dst)
 6142 %{
 6143   single_instruction;
 6144   dst    : S4(write);
 6145   INS01  : ISS;
 6146   NEON_FP : S4;
 6147 %}
 6148 
 6149 pipe_class fp_load_constant_d(vRegD dst)
 6150 %{
 6151   single_instruction;
 6152   dst    : S4(write);
 6153   INS01  : ISS;
 6154   NEON_FP : S4;
 6155 %}
 6156 
 6157 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6158 %{
 6159   single_instruction;
 6160   dst    : S5(write);
 6161   src1   : S1(read);
 6162   src2   : S1(read);
 6163   INS01  : ISS;
 6164   NEON_FP : S5;
 6165 %}
 6166 
 6167 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6168 %{
 6169   single_instruction;
 6170   dst    : S5(write);
 6171   src1   : S1(read);
 6172   src2   : S1(read);
 6173   INS0   : ISS;
 6174   NEON_FP : S5;
 6175 %}
 6176 
 6177 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6178 %{
 6179   single_instruction;
 6180   dst    : S5(write);
 6181   src1   : S1(read);
 6182   src2   : S1(read);
 6183   dst    : S1(read);
 6184   INS01  : ISS;
 6185   NEON_FP : S5;
 6186 %}
 6187 
 6188 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6189 %{
 6190   single_instruction;
 6191   dst    : S5(write);
 6192   src1   : S1(read);
 6193   src2   : S1(read);
 6194   dst    : S1(read);
 6195   INS0   : ISS;
 6196   NEON_FP : S5;
 6197 %}
 6198 
 6199 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6200 %{
 6201   single_instruction;
 6202   dst    : S4(write);
 6203   src1   : S2(read);
 6204   src2   : S2(read);
 6205   INS01  : ISS;
 6206   NEON_FP : S4;
 6207 %}
 6208 
 6209 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6210 %{
 6211   single_instruction;
 6212   dst    : S4(write);
 6213   src1   : S2(read);
 6214   src2   : S2(read);
 6215   INS0   : ISS;
 6216   NEON_FP : S4;
 6217 %}
 6218 
 6219 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6220 %{
 6221   single_instruction;
 6222   dst    : S3(write);
 6223   src1   : S2(read);
 6224   src2   : S2(read);
 6225   INS01  : ISS;
 6226   NEON_FP : S3;
 6227 %}
 6228 
 6229 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6230 %{
 6231   single_instruction;
 6232   dst    : S3(write);
 6233   src1   : S2(read);
 6234   src2   : S2(read);
 6235   INS0   : ISS;
 6236   NEON_FP : S3;
 6237 %}
 6238 
 6239 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6240 %{
 6241   single_instruction;
 6242   dst    : S3(write);
 6243   src    : S1(read);
 6244   shift  : S1(read);
 6245   INS01  : ISS;
 6246   NEON_FP : S3;
 6247 %}
 6248 
 6249 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6250 %{
 6251   single_instruction;
 6252   dst    : S3(write);
 6253   src    : S1(read);
 6254   shift  : S1(read);
 6255   INS0   : ISS;
 6256   NEON_FP : S3;
 6257 %}
 6258 
 6259 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6260 %{
 6261   single_instruction;
 6262   dst    : S3(write);
 6263   src    : S1(read);
 6264   INS01  : ISS;
 6265   NEON_FP : S3;
 6266 %}
 6267 
 6268 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6269 %{
 6270   single_instruction;
 6271   dst    : S3(write);
 6272   src    : S1(read);
 6273   INS0   : ISS;
 6274   NEON_FP : S3;
 6275 %}
 6276 
 6277 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6278 %{
 6279   single_instruction;
 6280   dst    : S5(write);
 6281   src1   : S1(read);
 6282   src2   : S1(read);
 6283   INS01  : ISS;
 6284   NEON_FP : S5;
 6285 %}
 6286 
 6287 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6288 %{
 6289   single_instruction;
 6290   dst    : S5(write);
 6291   src1   : S1(read);
 6292   src2   : S1(read);
 6293   INS0   : ISS;
 6294   NEON_FP : S5;
 6295 %}
 6296 
 6297 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6298 %{
 6299   single_instruction;
 6300   dst    : S5(write);
 6301   src1   : S1(read);
 6302   src2   : S1(read);
 6303   INS0   : ISS;
 6304   NEON_FP : S5;
 6305 %}
 6306 
 6307 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6308 %{
 6309   single_instruction;
 6310   dst    : S5(write);
 6311   src1   : S1(read);
 6312   src2   : S1(read);
 6313   INS0   : ISS;
 6314   NEON_FP : S5;
 6315 %}
 6316 
 6317 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6318 %{
 6319   single_instruction;
 6320   dst    : S5(write);
 6321   src    : S1(read);
 6322   INS0   : ISS;
 6323   NEON_FP : S5;
 6324 %}
 6325 
 6326 pipe_class vunop_fp64(vecD dst, vecD src)
 6327 %{
 6328   single_instruction;
 6329   dst    : S5(write);
 6330   src    : S1(read);
 6331   INS01  : ISS;
 6332   NEON_FP : S5;
 6333 %}
 6334 
 6335 pipe_class vunop_fp128(vecX dst, vecX src)
 6336 %{
 6337   single_instruction;
 6338   dst    : S5(write);
 6339   src    : S1(read);
 6340   INS0   : ISS;
 6341   NEON_FP : S5;
 6342 %}
 6343 
 6344 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6345 %{
 6346   single_instruction;
 6347   dst    : S3(write);
 6348   src    : S1(read);
 6349   INS01  : ISS;
 6350   NEON_FP : S3;
 6351 %}
 6352 
 6353 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6354 %{
 6355   single_instruction;
 6356   dst    : S3(write);
 6357   src    : S1(read);
 6358   INS01  : ISS;
 6359   NEON_FP : S3;
 6360 %}
 6361 
 6362 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6363 %{
 6364   single_instruction;
 6365   dst    : S3(write);
 6366   src    : S1(read);
 6367   INS01  : ISS;
 6368   NEON_FP : S3;
 6369 %}
 6370 
 6371 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6372 %{
 6373   single_instruction;
 6374   dst    : S3(write);
 6375   src    : S1(read);
 6376   INS01  : ISS;
 6377   NEON_FP : S3;
 6378 %}
 6379 
 6380 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6381 %{
 6382   single_instruction;
 6383   dst    : S3(write);
 6384   src    : S1(read);
 6385   INS01  : ISS;
 6386   NEON_FP : S3;
 6387 %}
 6388 
 6389 pipe_class vmovi_reg_imm64(vecD dst)
 6390 %{
 6391   single_instruction;
 6392   dst    : S3(write);
 6393   INS01  : ISS;
 6394   NEON_FP : S3;
 6395 %}
 6396 
 6397 pipe_class vmovi_reg_imm128(vecX dst)
 6398 %{
 6399   single_instruction;
 6400   dst    : S3(write);
 6401   INS0   : ISS;
 6402   NEON_FP : S3;
 6403 %}
 6404 
 6405 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6406 %{
 6407   single_instruction;
 6408   dst    : S5(write);
 6409   mem    : ISS(read);
 6410   INS01  : ISS;
 6411   NEON_FP : S3;
 6412 %}
 6413 
 6414 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6415 %{
 6416   single_instruction;
 6417   dst    : S5(write);
 6418   mem    : ISS(read);
 6419   INS01  : ISS;
 6420   NEON_FP : S3;
 6421 %}
 6422 
 6423 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6424 %{
 6425   single_instruction;
 6426   mem    : ISS(read);
 6427   src    : S2(read);
 6428   INS01  : ISS;
 6429   NEON_FP : S3;
 6430 %}
 6431 
 6432 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6433 %{
 6434   single_instruction;
 6435   mem    : ISS(read);
 6436   src    : S2(read);
 6437   INS01  : ISS;
 6438   NEON_FP : S3;
 6439 %}
 6440 
 6441 //------- Integer ALU operations --------------------------
 6442 
 6443 // Integer ALU reg-reg operation
 6444 // Operands needed in EX1, result generated in EX2
 6445 // Eg.  ADD     x0, x1, x2
 6446 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6447 %{
 6448   single_instruction;
 6449   dst    : EX2(write);
 6450   src1   : EX1(read);
 6451   src2   : EX1(read);
 6452   INS01  : ISS; // Dual issue as instruction 0 or 1
 6453   ALU    : EX2;
 6454 %}
 6455 
 6456 // Integer ALU reg-reg operation with constant shift
 6457 // Shifted register must be available in LATE_ISS instead of EX1
 6458 // Eg.  ADD     x0, x1, x2, LSL #2
 6459 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6460 %{
 6461   single_instruction;
 6462   dst    : EX2(write);
 6463   src1   : EX1(read);
 6464   src2   : ISS(read);
 6465   INS01  : ISS;
 6466   ALU    : EX2;
 6467 %}
 6468 
 6469 // Integer ALU reg operation with constant shift
 6470 // Eg.  LSL     x0, x1, #shift
 6471 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6472 %{
 6473   single_instruction;
 6474   dst    : EX2(write);
 6475   src1   : ISS(read);
 6476   INS01  : ISS;
 6477   ALU    : EX2;
 6478 %}
 6479 
 6480 // Integer ALU reg-reg operation with variable shift
 6481 // Both operands must be available in LATE_ISS instead of EX1
 6482 // Result is available in EX1 instead of EX2
 6483 // Eg.  LSLV    x0, x1, x2
 6484 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6485 %{
 6486   single_instruction;
 6487   dst    : EX1(write);
 6488   src1   : ISS(read);
 6489   src2   : ISS(read);
 6490   INS01  : ISS;
 6491   ALU    : EX1;
 6492 %}
 6493 
 6494 // Integer ALU reg-reg operation with extract
 6495 // As for _vshift above, but result generated in EX2
 6496 // Eg.  EXTR    x0, x1, x2, #N
 6497 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6498 %{
 6499   single_instruction;
 6500   dst    : EX2(write);
 6501   src1   : ISS(read);
 6502   src2   : ISS(read);
 6503   INS1   : ISS; // Can only dual issue as Instruction 1
 6504   ALU    : EX1;
 6505 %}
 6506 
 6507 // Integer ALU reg operation
 6508 // Eg.  NEG     x0, x1
 6509 pipe_class ialu_reg(iRegI dst, iRegI src)
 6510 %{
 6511   single_instruction;
 6512   dst    : EX2(write);
 6513   src    : EX1(read);
 6514   INS01  : ISS;
 6515   ALU    : EX2;
 6516 %}
 6517 
 6518 // Integer ALU reg mmediate operation
 6519 // Eg.  ADD     x0, x1, #N
 6520 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6521 %{
 6522   single_instruction;
 6523   dst    : EX2(write);
 6524   src1   : EX1(read);
 6525   INS01  : ISS;
 6526   ALU    : EX2;
 6527 %}
 6528 
 6529 // Integer ALU immediate operation (no source operands)
 6530 // Eg.  MOV     x0, #N
 6531 pipe_class ialu_imm(iRegI dst)
 6532 %{
 6533   single_instruction;
 6534   dst    : EX1(write);
 6535   INS01  : ISS;
 6536   ALU    : EX1;
 6537 %}
 6538 
 6539 //------- Compare operation -------------------------------
 6540 
 6541 // Compare reg-reg
 6542 // Eg.  CMP     x0, x1
 6543 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6544 %{
 6545   single_instruction;
 6546 //  fixed_latency(16);
 6547   cr     : EX2(write);
 6548   op1    : EX1(read);
 6549   op2    : EX1(read);
 6550   INS01  : ISS;
 6551   ALU    : EX2;
 6552 %}
 6553 
 6554 // Compare reg-reg
 6555 // Eg.  CMP     x0, #N
 6556 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6557 %{
 6558   single_instruction;
 6559 //  fixed_latency(16);
 6560   cr     : EX2(write);
 6561   op1    : EX1(read);
 6562   INS01  : ISS;
 6563   ALU    : EX2;
 6564 %}
 6565 
 6566 //------- Conditional instructions ------------------------
 6567 
 6568 // Conditional no operands
 6569 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6570 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6571 %{
 6572   single_instruction;
 6573   cr     : EX1(read);
 6574   dst    : EX2(write);
 6575   INS01  : ISS;
 6576   ALU    : EX2;
 6577 %}
 6578 
 6579 // Conditional 2 operand
 6580 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6581 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6582 %{
 6583   single_instruction;
 6584   cr     : EX1(read);
 6585   src1   : EX1(read);
 6586   src2   : EX1(read);
 6587   dst    : EX2(write);
 6588   INS01  : ISS;
 6589   ALU    : EX2;
 6590 %}
 6591 
 6592 // Conditional 2 operand
 6593 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6594 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6595 %{
 6596   single_instruction;
 6597   cr     : EX1(read);
 6598   src    : EX1(read);
 6599   dst    : EX2(write);
 6600   INS01  : ISS;
 6601   ALU    : EX2;
 6602 %}
 6603 
 6604 //------- Multiply pipeline operations --------------------
 6605 
 6606 // Multiply reg-reg
 6607 // Eg.  MUL     w0, w1, w2
 6608 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6609 %{
 6610   single_instruction;
 6611   dst    : WR(write);
 6612   src1   : ISS(read);
 6613   src2   : ISS(read);
 6614   INS01  : ISS;
 6615   MAC    : WR;
 6616 %}
 6617 
 6618 // Multiply accumulate
 6619 // Eg.  MADD    w0, w1, w2, w3
 6620 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6621 %{
 6622   single_instruction;
 6623   dst    : WR(write);
 6624   src1   : ISS(read);
 6625   src2   : ISS(read);
 6626   src3   : ISS(read);
 6627   INS01  : ISS;
 6628   MAC    : WR;
 6629 %}
 6630 
 6631 // Eg.  MUL     w0, w1, w2
 6632 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6633 %{
 6634   single_instruction;
 6635   fixed_latency(3); // Maximum latency for 64 bit mul
 6636   dst    : WR(write);
 6637   src1   : ISS(read);
 6638   src2   : ISS(read);
 6639   INS01  : ISS;
 6640   MAC    : WR;
 6641 %}
 6642 
 6643 // Multiply accumulate
 6644 // Eg.  MADD    w0, w1, w2, w3
 6645 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6646 %{
 6647   single_instruction;
 6648   fixed_latency(3); // Maximum latency for 64 bit mul
 6649   dst    : WR(write);
 6650   src1   : ISS(read);
 6651   src2   : ISS(read);
 6652   src3   : ISS(read);
 6653   INS01  : ISS;
 6654   MAC    : WR;
 6655 %}
 6656 
 6657 //------- Divide pipeline operations --------------------
 6658 
 6659 // Eg.  SDIV    w0, w1, w2
 6660 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6661 %{
 6662   single_instruction;
 6663   fixed_latency(8); // Maximum latency for 32 bit divide
 6664   dst    : WR(write);
 6665   src1   : ISS(read);
 6666   src2   : ISS(read);
 6667   INS0   : ISS; // Can only dual issue as instruction 0
 6668   DIV    : WR;
 6669 %}
 6670 
 6671 // Eg.  SDIV    x0, x1, x2
 6672 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6673 %{
 6674   single_instruction;
 6675   fixed_latency(16); // Maximum latency for 64 bit divide
 6676   dst    : WR(write);
 6677   src1   : ISS(read);
 6678   src2   : ISS(read);
 6679   INS0   : ISS; // Can only dual issue as instruction 0
 6680   DIV    : WR;
 6681 %}
 6682 
 6683 //------- Load pipeline operations ------------------------
 6684 
 6685 // Load - prefetch
 6686 // Eg.  PFRM    &lt;mem&gt;
 6687 pipe_class iload_prefetch(memory mem)
 6688 %{
 6689   single_instruction;
 6690   mem    : ISS(read);
 6691   INS01  : ISS;
 6692   LDST   : WR;
 6693 %}
 6694 
 6695 // Load - reg, mem
 6696 // Eg.  LDR     x0, &lt;mem&gt;
 6697 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6698 %{
 6699   single_instruction;
 6700   dst    : WR(write);
 6701   mem    : ISS(read);
 6702   INS01  : ISS;
 6703   LDST   : WR;
 6704 %}
 6705 
 6706 // Load - reg, reg
 6707 // Eg.  LDR     x0, [sp, x1]
 6708 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6709 %{
 6710   single_instruction;
 6711   dst    : WR(write);
 6712   src    : ISS(read);
 6713   INS01  : ISS;
 6714   LDST   : WR;
 6715 %}
 6716 
 6717 //------- Store pipeline operations -----------------------
 6718 
 6719 // Store - zr, mem
 6720 // Eg.  STR     zr, &lt;mem&gt;
 6721 pipe_class istore_mem(memory mem)
 6722 %{
 6723   single_instruction;
 6724   mem    : ISS(read);
 6725   INS01  : ISS;
 6726   LDST   : WR;
 6727 %}
 6728 
 6729 // Store - reg, mem
 6730 // Eg.  STR     x0, &lt;mem&gt;
 6731 pipe_class istore_reg_mem(iRegI src, memory mem)
 6732 %{
 6733   single_instruction;
 6734   mem    : ISS(read);
 6735   src    : EX2(read);
 6736   INS01  : ISS;
 6737   LDST   : WR;
 6738 %}
 6739 
 6740 // Store - reg, reg
 6741 // Eg. STR      x0, [sp, x1]
 6742 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6743 %{
 6744   single_instruction;
 6745   dst    : ISS(read);
 6746   src    : EX2(read);
 6747   INS01  : ISS;
 6748   LDST   : WR;
 6749 %}
 6750 
 6751 //------- Store pipeline operations -----------------------
 6752 
 6753 // Branch
 6754 pipe_class pipe_branch()
 6755 %{
 6756   single_instruction;
 6757   INS01  : ISS;
 6758   BRANCH : EX1;
 6759 %}
 6760 
 6761 // Conditional branch
 6762 pipe_class pipe_branch_cond(rFlagsReg cr)
 6763 %{
 6764   single_instruction;
 6765   cr     : EX1(read);
 6766   INS01  : ISS;
 6767   BRANCH : EX1;
 6768 %}
 6769 
 6770 // Compare &amp; Branch
 6771 // EG.  CBZ/CBNZ
 6772 pipe_class pipe_cmp_branch(iRegI op1)
 6773 %{
 6774   single_instruction;
 6775   op1    : EX1(read);
 6776   INS01  : ISS;
 6777   BRANCH : EX1;
 6778 %}
 6779 
 6780 //------- Synchronisation operations ----------------------
 6781 
 6782 // Any operation requiring serialization.
 6783 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6784 pipe_class pipe_serial()
 6785 %{
 6786   single_instruction;
 6787   force_serialization;
 6788   fixed_latency(16);
 6789   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6790   LDST   : WR;
 6791 %}
 6792 
 6793 // Generic big/slow expanded idiom - also serialized
 6794 pipe_class pipe_slow()
 6795 %{
 6796   instruction_count(10);
 6797   multiple_bundles;
 6798   force_serialization;
 6799   fixed_latency(16);
 6800   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6801   LDST   : WR;
 6802 %}
 6803 
 6804 // Empty pipeline class
 6805 pipe_class pipe_class_empty()
 6806 %{
 6807   single_instruction;
 6808   fixed_latency(0);
 6809 %}
 6810 
 6811 // Default pipeline class.
 6812 pipe_class pipe_class_default()
 6813 %{
 6814   single_instruction;
 6815   fixed_latency(2);
 6816 %}
 6817 
 6818 // Pipeline class for compares.
 6819 pipe_class pipe_class_compare()
 6820 %{
 6821   single_instruction;
 6822   fixed_latency(16);
 6823 %}
 6824 
 6825 // Pipeline class for memory operations.
 6826 pipe_class pipe_class_memory()
 6827 %{
 6828   single_instruction;
 6829   fixed_latency(16);
 6830 %}
 6831 
 6832 // Pipeline class for call.
 6833 pipe_class pipe_class_call()
 6834 %{
 6835   single_instruction;
 6836   fixed_latency(100);
 6837 %}
 6838 
 6839 // Define the class for the Nop node.
 6840 define %{
 6841    MachNop = pipe_class_empty;
 6842 %}
 6843 
 6844 %}
 6845 //----------INSTRUCTIONS-------------------------------------------------------
 6846 //
 6847 // match      -- States which machine-independent subtree may be replaced
 6848 //               by this instruction.
 6849 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6850 //               selection to identify a minimum cost tree of machine
 6851 //               instructions that matches a tree of machine-independent
 6852 //               instructions.
 6853 // format     -- A string providing the disassembly for this instruction.
 6854 //               The value of an instruction&#39;s operand may be inserted
 6855 //               by referring to it with a &#39;$&#39; prefix.
 6856 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6857 //               to within an encode class as $primary, $secondary, and $tertiary
 6858 //               rrspectively.  The primary opcode is commonly used to
 6859 //               indicate the type of machine instruction, while secondary
 6860 //               and tertiary are often used for prefix options or addressing
 6861 //               modes.
 6862 // ins_encode -- A list of encode classes with parameters. The encode class
 6863 //               name must have been defined in an &#39;enc_class&#39; specification
 6864 //               in the encode section of the architecture description.
 6865 
 6866 // ============================================================================
 6867 // Memory (Load/Store) Instructions
 6868 
 6869 // Load Instructions
 6870 
 6871 // Load Byte (8 bit signed)
 6872 instruct loadB(iRegINoSp dst, memory1 mem)
 6873 %{
 6874   match(Set dst (LoadB mem));
 6875   predicate(!needs_acquiring_load(n));
 6876 
 6877   ins_cost(4 * INSN_COST);
 6878   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6879 
 6880   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6881 
 6882   ins_pipe(iload_reg_mem);
 6883 %}
 6884 
 6885 // Load Byte (8 bit signed) into long
 6886 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6887 %{
 6888   match(Set dst (ConvI2L (LoadB mem)));
 6889   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6890 
 6891   ins_cost(4 * INSN_COST);
 6892   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6893 
 6894   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6895 
 6896   ins_pipe(iload_reg_mem);
 6897 %}
 6898 
 6899 // Load Byte (8 bit unsigned)
 6900 instruct loadUB(iRegINoSp dst, memory1 mem)
 6901 %{
 6902   match(Set dst (LoadUB mem));
 6903   predicate(!needs_acquiring_load(n));
 6904 
 6905   ins_cost(4 * INSN_COST);
 6906   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6907 
 6908   ins_encode(aarch64_enc_ldrb(dst, mem));
 6909 
 6910   ins_pipe(iload_reg_mem);
 6911 %}
 6912 
 6913 // Load Byte (8 bit unsigned) into long
 6914 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6915 %{
 6916   match(Set dst (ConvI2L (LoadUB mem)));
 6917   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6918 
 6919   ins_cost(4 * INSN_COST);
 6920   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6921 
 6922   ins_encode(aarch64_enc_ldrb(dst, mem));
 6923 
 6924   ins_pipe(iload_reg_mem);
 6925 %}
 6926 
 6927 // Load Short (16 bit signed)
 6928 instruct loadS(iRegINoSp dst, memory2 mem)
 6929 %{
 6930   match(Set dst (LoadS mem));
 6931   predicate(!needs_acquiring_load(n));
 6932 
 6933   ins_cost(4 * INSN_COST);
 6934   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6935 
 6936   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6937 
 6938   ins_pipe(iload_reg_mem);
 6939 %}
 6940 
 6941 // Load Short (16 bit signed) into long
 6942 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6943 %{
 6944   match(Set dst (ConvI2L (LoadS mem)));
 6945   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6946 
 6947   ins_cost(4 * INSN_COST);
 6948   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6949 
 6950   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6951 
 6952   ins_pipe(iload_reg_mem);
 6953 %}
 6954 
 6955 // Load Char (16 bit unsigned)
 6956 instruct loadUS(iRegINoSp dst, memory2 mem)
 6957 %{
 6958   match(Set dst (LoadUS mem));
 6959   predicate(!needs_acquiring_load(n));
 6960 
 6961   ins_cost(4 * INSN_COST);
 6962   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6963 
 6964   ins_encode(aarch64_enc_ldrh(dst, mem));
 6965 
 6966   ins_pipe(iload_reg_mem);
 6967 %}
 6968 
 6969 // Load Short/Char (16 bit unsigned) into long
 6970 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6971 %{
 6972   match(Set dst (ConvI2L (LoadUS mem)));
 6973   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6974 
 6975   ins_cost(4 * INSN_COST);
 6976   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6977 
 6978   ins_encode(aarch64_enc_ldrh(dst, mem));
 6979 
 6980   ins_pipe(iload_reg_mem);
 6981 %}
 6982 
 6983 // Load Integer (32 bit signed)
 6984 instruct loadI(iRegINoSp dst, memory4 mem)
 6985 %{
 6986   match(Set dst (LoadI mem));
 6987   predicate(!needs_acquiring_load(n));
 6988 
 6989   ins_cost(4 * INSN_COST);
 6990   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6991 
 6992   ins_encode(aarch64_enc_ldrw(dst, mem));
 6993 
 6994   ins_pipe(iload_reg_mem);
 6995 %}
 6996 
 6997 // Load Integer (32 bit signed) into long
 6998 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6999 %{
 7000   match(Set dst (ConvI2L (LoadI mem)));
 7001   predicate(!needs_acquiring_load(n-&gt;in(1)));
 7002 
 7003   ins_cost(4 * INSN_COST);
 7004   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 7005 
 7006   ins_encode(aarch64_enc_ldrsw(dst, mem));
 7007 
 7008   ins_pipe(iload_reg_mem);
 7009 %}
 7010 
 7011 // Load Integer (32 bit unsigned) into long
 7012 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 7013 %{
 7014   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7015   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 7016 
 7017   ins_cost(4 * INSN_COST);
 7018   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7019 
 7020   ins_encode(aarch64_enc_ldrw(dst, mem));
 7021 
 7022   ins_pipe(iload_reg_mem);
 7023 %}
 7024 
 7025 // Load Long (64 bit signed)
 7026 instruct loadL(iRegLNoSp dst, memory8 mem)
 7027 %{
 7028   match(Set dst (LoadL mem));
 7029   predicate(!needs_acquiring_load(n));
 7030 
 7031   ins_cost(4 * INSN_COST);
 7032   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7033 
 7034   ins_encode(aarch64_enc_ldr(dst, mem));
 7035 
 7036   ins_pipe(iload_reg_mem);
 7037 %}
 7038 
 7039 // Load Range
 7040 instruct loadRange(iRegINoSp dst, memory4 mem)
 7041 %{
 7042   match(Set dst (LoadRange mem));
 7043 
 7044   ins_cost(4 * INSN_COST);
 7045   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7046 
 7047   ins_encode(aarch64_enc_ldrw(dst, mem));
 7048 
 7049   ins_pipe(iload_reg_mem);
 7050 %}
 7051 
 7052 // Load Pointer
 7053 instruct loadP(iRegPNoSp dst, memory8 mem)
 7054 %{
 7055   match(Set dst (LoadP mem));
 7056   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7057 
 7058   ins_cost(4 * INSN_COST);
 7059   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7060 
 7061   ins_encode(aarch64_enc_ldr(dst, mem));
 7062 
 7063   ins_pipe(iload_reg_mem);
 7064 %}
 7065 
 7066 // Load Compressed Pointer
 7067 instruct loadN(iRegNNoSp dst, memory4 mem)
 7068 %{
 7069   match(Set dst (LoadN mem));
 7070   predicate(!needs_acquiring_load(n));
 7071 
 7072   ins_cost(4 * INSN_COST);
 7073   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7074 
 7075   ins_encode(aarch64_enc_ldrw(dst, mem));
 7076 
 7077   ins_pipe(iload_reg_mem);
 7078 %}
 7079 
 7080 // Load Klass Pointer
 7081 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7082 %{
 7083   match(Set dst (LoadKlass mem));
 7084   predicate(!needs_acquiring_load(n));
 7085 
 7086   ins_cost(4 * INSN_COST);
 7087   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7088 
 7089   ins_encode(aarch64_enc_ldr(dst, mem));
 7090 
 7091   ins_pipe(iload_reg_mem);
 7092 %}
 7093 
 7094 // Load Narrow Klass Pointer
 7095 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7096 %{
 7097   match(Set dst (LoadNKlass mem));
 7098   predicate(!needs_acquiring_load(n));
 7099 
 7100   ins_cost(4 * INSN_COST);
 7101   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7102 
 7103   ins_encode(aarch64_enc_ldrw(dst, mem));
 7104 
 7105   ins_pipe(iload_reg_mem);
 7106 %}
 7107 
 7108 // Load Float
 7109 instruct loadF(vRegF dst, memory4 mem)
 7110 %{
 7111   match(Set dst (LoadF mem));
 7112   predicate(!needs_acquiring_load(n));
 7113 
 7114   ins_cost(4 * INSN_COST);
 7115   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7116 
 7117   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7118 
 7119   ins_pipe(pipe_class_memory);
 7120 %}
 7121 
 7122 // Load Double
 7123 instruct loadD(vRegD dst, memory8 mem)
 7124 %{
 7125   match(Set dst (LoadD mem));
 7126   predicate(!needs_acquiring_load(n));
 7127 
 7128   ins_cost(4 * INSN_COST);
 7129   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7130 
 7131   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7132 
 7133   ins_pipe(pipe_class_memory);
 7134 %}
 7135 
 7136 
 7137 // Load Int Constant
 7138 instruct loadConI(iRegINoSp dst, immI src)
 7139 %{
 7140   match(Set dst src);
 7141 
 7142   ins_cost(INSN_COST);
 7143   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7144 
 7145   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7146 
 7147   ins_pipe(ialu_imm);
 7148 %}
 7149 
 7150 // Load Long Constant
 7151 instruct loadConL(iRegLNoSp dst, immL src)
 7152 %{
 7153   match(Set dst src);
 7154 
 7155   ins_cost(INSN_COST);
 7156   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7157 
 7158   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7159 
 7160   ins_pipe(ialu_imm);
 7161 %}
 7162 
 7163 // Load Pointer Constant
 7164 
 7165 instruct loadConP(iRegPNoSp dst, immP con)
 7166 %{
 7167   match(Set dst con);
 7168 
 7169   ins_cost(INSN_COST * 4);
 7170   format %{
 7171     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7172   %}
 7173 
 7174   ins_encode(aarch64_enc_mov_p(dst, con));
 7175 
 7176   ins_pipe(ialu_imm);
 7177 %}
 7178 
 7179 // Load Null Pointer Constant
 7180 
 7181 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7182 %{
 7183   match(Set dst con);
 7184 
 7185   ins_cost(INSN_COST);
 7186   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7187 
 7188   ins_encode(aarch64_enc_mov_p0(dst, con));
 7189 
 7190   ins_pipe(ialu_imm);
 7191 %}
 7192 
 7193 // Load Pointer Constant One
 7194 
 7195 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7196 %{
 7197   match(Set dst con);
 7198 
 7199   ins_cost(INSN_COST);
 7200   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7201 
 7202   ins_encode(aarch64_enc_mov_p1(dst, con));
 7203 
 7204   ins_pipe(ialu_imm);
 7205 %}
 7206 
 7207 // Load Byte Map Base Constant
 7208 
 7209 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7210 %{
 7211   match(Set dst con);
 7212 
 7213   ins_cost(INSN_COST);
 7214   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7215 
 7216   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7217 
 7218   ins_pipe(ialu_imm);
 7219 %}
 7220 
 7221 // Load Narrow Pointer Constant
 7222 
 7223 instruct loadConN(iRegNNoSp dst, immN con)
 7224 %{
 7225   match(Set dst con);
 7226 
 7227   ins_cost(INSN_COST * 4);
 7228   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7229 
 7230   ins_encode(aarch64_enc_mov_n(dst, con));
 7231 
 7232   ins_pipe(ialu_imm);
 7233 %}
 7234 
 7235 // Load Narrow Null Pointer Constant
 7236 
 7237 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7238 %{
 7239   match(Set dst con);
 7240 
 7241   ins_cost(INSN_COST);
 7242   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7243 
 7244   ins_encode(aarch64_enc_mov_n0(dst, con));
 7245 
 7246   ins_pipe(ialu_imm);
 7247 %}
 7248 
 7249 // Load Narrow Klass Constant
 7250 
 7251 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7252 %{
 7253   match(Set dst con);
 7254 
 7255   ins_cost(INSN_COST);
 7256   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7257 
 7258   ins_encode(aarch64_enc_mov_nk(dst, con));
 7259 
 7260   ins_pipe(ialu_imm);
 7261 %}
 7262 
 7263 // Load Packed Float Constant
 7264 
 7265 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7266   match(Set dst con);
 7267   ins_cost(INSN_COST * 4);
 7268   format %{ &quot;fmovs  $dst, $con&quot;%}
 7269   ins_encode %{
 7270     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7271   %}
 7272 
 7273   ins_pipe(fp_imm_s);
 7274 %}
 7275 
 7276 // Load Float Constant
 7277 
 7278 instruct loadConF(vRegF dst, immF con) %{
 7279   match(Set dst con);
 7280 
 7281   ins_cost(INSN_COST * 4);
 7282 
 7283   format %{
 7284     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7285   %}
 7286 
 7287   ins_encode %{
 7288     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7289   %}
 7290 
 7291   ins_pipe(fp_load_constant_s);
 7292 %}
 7293 
 7294 // Load Packed Double Constant
 7295 
 7296 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7297   match(Set dst con);
 7298   ins_cost(INSN_COST);
 7299   format %{ &quot;fmovd  $dst, $con&quot;%}
 7300   ins_encode %{
 7301     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7302   %}
 7303 
 7304   ins_pipe(fp_imm_d);
 7305 %}
 7306 
 7307 // Load Double Constant
 7308 
 7309 instruct loadConD(vRegD dst, immD con) %{
 7310   match(Set dst con);
 7311 
 7312   ins_cost(INSN_COST * 5);
 7313   format %{
 7314     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7315   %}
 7316 
 7317   ins_encode %{
 7318     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7319   %}
 7320 
 7321   ins_pipe(fp_load_constant_d);
 7322 %}
 7323 
 7324 // Store Instructions
 7325 
 7326 // Store CMS card-mark Immediate
 7327 instruct storeimmCM0(immI0 zero, memory1 mem)
 7328 %{
 7329   match(Set mem (StoreCM mem zero));
 7330 
 7331   ins_cost(INSN_COST);
 7332   format %{ &quot;storestore (elided)\n\t&quot;
 7333             &quot;strb zr, $mem\t# byte&quot; %}
 7334 
 7335   ins_encode(aarch64_enc_strb0(mem));
 7336 
 7337   ins_pipe(istore_mem);
 7338 %}
 7339 
 7340 // Store CMS card-mark Immediate with intervening StoreStore
 7341 // needed when using CMS with no conditional card marking
 7342 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7343 %{
 7344   match(Set mem (StoreCM mem zero));
 7345 
 7346   ins_cost(INSN_COST * 2);
 7347   format %{ &quot;storestore\n\t&quot;
 7348             &quot;dmb ishst&quot;
 7349             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7350 
 7351   ins_encode(aarch64_enc_strb0_ordered(mem));
 7352 
 7353   ins_pipe(istore_mem);
 7354 %}
 7355 
 7356 // Store Byte
 7357 instruct storeB(iRegIorL2I src, memory1 mem)
 7358 %{
 7359   match(Set mem (StoreB mem src));
 7360   predicate(!needs_releasing_store(n));
 7361 
 7362   ins_cost(INSN_COST);
 7363   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7364 
 7365   ins_encode(aarch64_enc_strb(src, mem));
 7366 
 7367   ins_pipe(istore_reg_mem);
 7368 %}
 7369 
 7370 
 7371 instruct storeimmB0(immI0 zero, memory1 mem)
 7372 %{
 7373   match(Set mem (StoreB mem zero));
 7374   predicate(!needs_releasing_store(n));
 7375 
 7376   ins_cost(INSN_COST);
 7377   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7378 
 7379   ins_encode(aarch64_enc_strb0(mem));
 7380 
 7381   ins_pipe(istore_mem);
 7382 %}
 7383 
 7384 // Store Char/Short
 7385 instruct storeC(iRegIorL2I src, memory2 mem)
 7386 %{
 7387   match(Set mem (StoreC mem src));
 7388   predicate(!needs_releasing_store(n));
 7389 
 7390   ins_cost(INSN_COST);
 7391   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7392 
 7393   ins_encode(aarch64_enc_strh(src, mem));
 7394 
 7395   ins_pipe(istore_reg_mem);
 7396 %}
 7397 
 7398 instruct storeimmC0(immI0 zero, memory2 mem)
 7399 %{
 7400   match(Set mem (StoreC mem zero));
 7401   predicate(!needs_releasing_store(n));
 7402 
 7403   ins_cost(INSN_COST);
 7404   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7405 
 7406   ins_encode(aarch64_enc_strh0(mem));
 7407 
 7408   ins_pipe(istore_mem);
 7409 %}
 7410 
 7411 // Store Integer
 7412 
 7413 instruct storeI(iRegIorL2I src, memory4 mem)
 7414 %{
 7415   match(Set mem(StoreI mem src));
 7416   predicate(!needs_releasing_store(n));
 7417 
 7418   ins_cost(INSN_COST);
 7419   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7420 
 7421   ins_encode(aarch64_enc_strw(src, mem));
 7422 
 7423   ins_pipe(istore_reg_mem);
 7424 %}
 7425 
 7426 instruct storeimmI0(immI0 zero, memory4 mem)
 7427 %{
 7428   match(Set mem(StoreI mem zero));
 7429   predicate(!needs_releasing_store(n));
 7430 
 7431   ins_cost(INSN_COST);
 7432   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7433 
 7434   ins_encode(aarch64_enc_strw0(mem));
 7435 
 7436   ins_pipe(istore_mem);
 7437 %}
 7438 
 7439 // Store Long (64 bit signed)
 7440 instruct storeL(iRegL src, memory8 mem)
 7441 %{
 7442   match(Set mem (StoreL mem src));
 7443   predicate(!needs_releasing_store(n));
 7444 
 7445   ins_cost(INSN_COST);
 7446   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7447 
 7448   ins_encode(aarch64_enc_str(src, mem));
 7449 
 7450   ins_pipe(istore_reg_mem);
 7451 %}
 7452 
 7453 // Store Long (64 bit signed)
 7454 instruct storeimmL0(immL0 zero, memory8 mem)
 7455 %{
 7456   match(Set mem (StoreL mem zero));
 7457   predicate(!needs_releasing_store(n));
 7458 
 7459   ins_cost(INSN_COST);
 7460   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7461 
 7462   ins_encode(aarch64_enc_str0(mem));
 7463 
 7464   ins_pipe(istore_mem);
 7465 %}
 7466 
 7467 // Store Pointer
 7468 instruct storeP(iRegP src, memory8 mem)
 7469 %{
 7470   match(Set mem (StoreP mem src));
 7471   predicate(!needs_releasing_store(n));
 7472 
 7473   ins_cost(INSN_COST);
 7474   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7475 
 7476   ins_encode(aarch64_enc_str(src, mem));
 7477 
 7478   ins_pipe(istore_reg_mem);
 7479 %}
 7480 
 7481 // Store Pointer
 7482 instruct storeimmP0(immP0 zero, memory8 mem)
 7483 %{
 7484   match(Set mem (StoreP mem zero));
 7485   predicate(!needs_releasing_store(n));
 7486 
 7487   ins_cost(INSN_COST);
 7488   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7489 
 7490   ins_encode(aarch64_enc_str0(mem));
 7491 
 7492   ins_pipe(istore_mem);
 7493 %}
 7494 
 7495 // Store Compressed Pointer
 7496 instruct storeN(iRegN src, memory4 mem)
 7497 %{
 7498   match(Set mem (StoreN mem src));
 7499   predicate(!needs_releasing_store(n));
 7500 
 7501   ins_cost(INSN_COST);
 7502   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7503 
 7504   ins_encode(aarch64_enc_strw(src, mem));
 7505 
 7506   ins_pipe(istore_reg_mem);
 7507 %}
 7508 
 7509 instruct storeImmN0(immN0 zero, memory4 mem)
 7510 %{
 7511   match(Set mem (StoreN mem zero));
 7512   predicate(!needs_releasing_store(n));
 7513 
 7514   ins_cost(INSN_COST);
 7515   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7516 
 7517   ins_encode(aarch64_enc_strw0(mem));
 7518 
 7519   ins_pipe(istore_mem);
 7520 %}
 7521 
 7522 // Store Float
 7523 instruct storeF(vRegF src, memory4 mem)
 7524 %{
 7525   match(Set mem (StoreF mem src));
 7526   predicate(!needs_releasing_store(n));
 7527 
 7528   ins_cost(INSN_COST);
 7529   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7530 
 7531   ins_encode( aarch64_enc_strs(src, mem) );
 7532 
 7533   ins_pipe(pipe_class_memory);
 7534 %}
 7535 
 7536 // TODO
 7537 // implement storeImmF0 and storeFImmPacked
 7538 
 7539 // Store Double
 7540 instruct storeD(vRegD src, memory8 mem)
 7541 %{
 7542   match(Set mem (StoreD mem src));
 7543   predicate(!needs_releasing_store(n));
 7544 
 7545   ins_cost(INSN_COST);
 7546   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7547 
 7548   ins_encode( aarch64_enc_strd(src, mem) );
 7549 
 7550   ins_pipe(pipe_class_memory);
 7551 %}
 7552 
 7553 // Store Compressed Klass Pointer
 7554 instruct storeNKlass(iRegN src, memory4 mem)
 7555 %{
 7556   predicate(!needs_releasing_store(n));
 7557   match(Set mem (StoreNKlass mem src));
 7558 
 7559   ins_cost(INSN_COST);
 7560   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7561 
 7562   ins_encode(aarch64_enc_strw(src, mem));
 7563 
 7564   ins_pipe(istore_reg_mem);
 7565 %}
 7566 
 7567 // TODO
 7568 // implement storeImmD0 and storeDImmPacked
 7569 
 7570 // prefetch instructions
 7571 // Must be safe to execute with invalid address (cannot fault).
 7572 
 7573 instruct prefetchalloc( memory8 mem ) %{
 7574   match(PrefetchAllocation mem);
 7575 
 7576   ins_cost(INSN_COST);
 7577   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7578 
 7579   ins_encode( aarch64_enc_prefetchw(mem) );
 7580 
 7581   ins_pipe(iload_prefetch);
 7582 %}
 7583 
 7584 //  ---------------- volatile loads and stores ----------------
 7585 
 7586 // Load Byte (8 bit signed)
 7587 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7588 %{
 7589   match(Set dst (LoadB mem));
 7590 
 7591   ins_cost(VOLATILE_REF_COST);
 7592   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7593 
 7594   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7595 
 7596   ins_pipe(pipe_serial);
 7597 %}
 7598 
 7599 // Load Byte (8 bit signed) into long
 7600 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7601 %{
 7602   match(Set dst (ConvI2L (LoadB mem)));
 7603 
 7604   ins_cost(VOLATILE_REF_COST);
 7605   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7606 
 7607   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7608 
 7609   ins_pipe(pipe_serial);
 7610 %}
 7611 
 7612 // Load Byte (8 bit unsigned)
 7613 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7614 %{
 7615   match(Set dst (LoadUB mem));
 7616 
 7617   ins_cost(VOLATILE_REF_COST);
 7618   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7619 
 7620   ins_encode(aarch64_enc_ldarb(dst, mem));
 7621 
 7622   ins_pipe(pipe_serial);
 7623 %}
 7624 
 7625 // Load Byte (8 bit unsigned) into long
 7626 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7627 %{
 7628   match(Set dst (ConvI2L (LoadUB mem)));
 7629 
 7630   ins_cost(VOLATILE_REF_COST);
 7631   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7632 
 7633   ins_encode(aarch64_enc_ldarb(dst, mem));
 7634 
 7635   ins_pipe(pipe_serial);
 7636 %}
 7637 
 7638 // Load Short (16 bit signed)
 7639 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7640 %{
 7641   match(Set dst (LoadS mem));
 7642 
 7643   ins_cost(VOLATILE_REF_COST);
 7644   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7645 
 7646   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7647 
 7648   ins_pipe(pipe_serial);
 7649 %}
 7650 
 7651 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7652 %{
 7653   match(Set dst (LoadUS mem));
 7654 
 7655   ins_cost(VOLATILE_REF_COST);
 7656   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7657 
 7658   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7659 
 7660   ins_pipe(pipe_serial);
 7661 %}
 7662 
 7663 // Load Short/Char (16 bit unsigned) into long
 7664 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7665 %{
 7666   match(Set dst (ConvI2L (LoadUS mem)));
 7667 
 7668   ins_cost(VOLATILE_REF_COST);
 7669   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7670 
 7671   ins_encode(aarch64_enc_ldarh(dst, mem));
 7672 
 7673   ins_pipe(pipe_serial);
 7674 %}
 7675 
 7676 // Load Short/Char (16 bit signed) into long
 7677 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7678 %{
 7679   match(Set dst (ConvI2L (LoadS mem)));
 7680 
 7681   ins_cost(VOLATILE_REF_COST);
 7682   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7683 
 7684   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7685 
 7686   ins_pipe(pipe_serial);
 7687 %}
 7688 
 7689 // Load Integer (32 bit signed)
 7690 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7691 %{
 7692   match(Set dst (LoadI mem));
 7693 
 7694   ins_cost(VOLATILE_REF_COST);
 7695   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7696 
 7697   ins_encode(aarch64_enc_ldarw(dst, mem));
 7698 
 7699   ins_pipe(pipe_serial);
 7700 %}
 7701 
 7702 // Load Integer (32 bit unsigned) into long
 7703 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7704 %{
 7705   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7706 
 7707   ins_cost(VOLATILE_REF_COST);
 7708   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7709 
 7710   ins_encode(aarch64_enc_ldarw(dst, mem));
 7711 
 7712   ins_pipe(pipe_serial);
 7713 %}
 7714 
 7715 // Load Long (64 bit signed)
 7716 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7717 %{
 7718   match(Set dst (LoadL mem));
 7719 
 7720   ins_cost(VOLATILE_REF_COST);
 7721   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7722 
 7723   ins_encode(aarch64_enc_ldar(dst, mem));
 7724 
 7725   ins_pipe(pipe_serial);
 7726 %}
 7727 
 7728 // Load Pointer
 7729 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7730 %{
 7731   match(Set dst (LoadP mem));
 7732   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7733 
 7734   ins_cost(VOLATILE_REF_COST);
 7735   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7736 
 7737   ins_encode(aarch64_enc_ldar(dst, mem));
 7738 
 7739   ins_pipe(pipe_serial);
 7740 %}
 7741 
 7742 // Load Compressed Pointer
 7743 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7744 %{
 7745   match(Set dst (LoadN mem));
 7746 
 7747   ins_cost(VOLATILE_REF_COST);
 7748   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7749 
 7750   ins_encode(aarch64_enc_ldarw(dst, mem));
 7751 
 7752   ins_pipe(pipe_serial);
 7753 %}
 7754 
 7755 // Load Float
 7756 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7757 %{
 7758   match(Set dst (LoadF mem));
 7759 
 7760   ins_cost(VOLATILE_REF_COST);
 7761   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7762 
 7763   ins_encode( aarch64_enc_fldars(dst, mem) );
 7764 
 7765   ins_pipe(pipe_serial);
 7766 %}
 7767 
 7768 // Load Double
 7769 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7770 %{
 7771   match(Set dst (LoadD mem));
 7772 
 7773   ins_cost(VOLATILE_REF_COST);
 7774   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7775 
 7776   ins_encode( aarch64_enc_fldard(dst, mem) );
 7777 
 7778   ins_pipe(pipe_serial);
 7779 %}
 7780 
 7781 // Store Byte
 7782 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7783 %{
 7784   match(Set mem (StoreB mem src));
 7785 
 7786   ins_cost(VOLATILE_REF_COST);
 7787   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7788 
 7789   ins_encode(aarch64_enc_stlrb(src, mem));
 7790 
 7791   ins_pipe(pipe_class_memory);
 7792 %}
 7793 
 7794 // Store Char/Short
 7795 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7796 %{
 7797   match(Set mem (StoreC mem src));
 7798 
 7799   ins_cost(VOLATILE_REF_COST);
 7800   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7801 
 7802   ins_encode(aarch64_enc_stlrh(src, mem));
 7803 
 7804   ins_pipe(pipe_class_memory);
 7805 %}
 7806 
 7807 // Store Integer
 7808 
 7809 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7810 %{
 7811   match(Set mem(StoreI mem src));
 7812 
 7813   ins_cost(VOLATILE_REF_COST);
 7814   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7815 
 7816   ins_encode(aarch64_enc_stlrw(src, mem));
 7817 
 7818   ins_pipe(pipe_class_memory);
 7819 %}
 7820 
 7821 // Store Long (64 bit signed)
 7822 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7823 %{
 7824   match(Set mem (StoreL mem src));
 7825 
 7826   ins_cost(VOLATILE_REF_COST);
 7827   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7828 
 7829   ins_encode(aarch64_enc_stlr(src, mem));
 7830 
 7831   ins_pipe(pipe_class_memory);
 7832 %}
 7833 
 7834 // Store Pointer
 7835 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7836 %{
 7837   match(Set mem (StoreP mem src));
 7838 
 7839   ins_cost(VOLATILE_REF_COST);
 7840   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7841 
 7842   ins_encode(aarch64_enc_stlr(src, mem));
 7843 
 7844   ins_pipe(pipe_class_memory);
 7845 %}
 7846 
 7847 // Store Compressed Pointer
 7848 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7849 %{
 7850   match(Set mem (StoreN mem src));
 7851 
 7852   ins_cost(VOLATILE_REF_COST);
 7853   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7854 
 7855   ins_encode(aarch64_enc_stlrw(src, mem));
 7856 
 7857   ins_pipe(pipe_class_memory);
 7858 %}
 7859 
 7860 // Store Float
 7861 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7862 %{
 7863   match(Set mem (StoreF mem src));
 7864 
 7865   ins_cost(VOLATILE_REF_COST);
 7866   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7867 
 7868   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7869 
 7870   ins_pipe(pipe_class_memory);
 7871 %}
 7872 
 7873 // TODO
 7874 // implement storeImmF0 and storeFImmPacked
 7875 
 7876 // Store Double
 7877 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7878 %{
 7879   match(Set mem (StoreD mem src));
 7880 
 7881   ins_cost(VOLATILE_REF_COST);
 7882   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7883 
 7884   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7885 
 7886   ins_pipe(pipe_class_memory);
 7887 %}
 7888 
 7889 //  ---------------- end of volatile loads and stores ----------------
 7890 
 7891 instruct cacheWB(indirect addr)
 7892 %{
 7893   predicate(VM_Version::supports_data_cache_line_flush());
 7894   match(CacheWB addr);
 7895 
 7896   ins_cost(100);
 7897   format %{&quot;cache wb $addr&quot; %}
 7898   ins_encode %{
 7899     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7900     assert($addr$$disp == 0, &quot;should be&quot;);
 7901     __ cache_wb(Address($addr$$base$$Register, 0));
 7902   %}
 7903   ins_pipe(pipe_slow); // XXX
 7904 %}
 7905 
 7906 instruct cacheWBPreSync()
 7907 %{
 7908   predicate(VM_Version::supports_data_cache_line_flush());
 7909   match(CacheWBPreSync);
 7910 
 7911   ins_cost(100);
 7912   format %{&quot;cache wb presync&quot; %}
 7913   ins_encode %{
 7914     __ cache_wbsync(true);
 7915   %}
 7916   ins_pipe(pipe_slow); // XXX
 7917 %}
 7918 
 7919 instruct cacheWBPostSync()
 7920 %{
 7921   predicate(VM_Version::supports_data_cache_line_flush());
 7922   match(CacheWBPostSync);
 7923 
 7924   ins_cost(100);
 7925   format %{&quot;cache wb postsync&quot; %}
 7926   ins_encode %{
 7927     __ cache_wbsync(false);
 7928   %}
 7929   ins_pipe(pipe_slow); // XXX
 7930 %}
 7931 
 7932 // ============================================================================
 7933 // BSWAP Instructions
 7934 
 7935 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7936   match(Set dst (ReverseBytesI src));
 7937 
 7938   ins_cost(INSN_COST);
 7939   format %{ &quot;revw  $dst, $src&quot; %}
 7940 
 7941   ins_encode %{
 7942     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7943   %}
 7944 
 7945   ins_pipe(ialu_reg);
 7946 %}
 7947 
 7948 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7949   match(Set dst (ReverseBytesL src));
 7950 
 7951   ins_cost(INSN_COST);
 7952   format %{ &quot;rev  $dst, $src&quot; %}
 7953 
 7954   ins_encode %{
 7955     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7956   %}
 7957 
 7958   ins_pipe(ialu_reg);
 7959 %}
 7960 
 7961 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7962   match(Set dst (ReverseBytesUS src));
 7963 
 7964   ins_cost(INSN_COST);
 7965   format %{ &quot;rev16w  $dst, $src&quot; %}
 7966 
 7967   ins_encode %{
 7968     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7969   %}
 7970 
 7971   ins_pipe(ialu_reg);
 7972 %}
 7973 
 7974 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7975   match(Set dst (ReverseBytesS src));
 7976 
 7977   ins_cost(INSN_COST);
 7978   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7979             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7980 
 7981   ins_encode %{
 7982     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7983     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7984   %}
 7985 
 7986   ins_pipe(ialu_reg);
 7987 %}
 7988 
 7989 // ============================================================================
 7990 // Zero Count Instructions
 7991 
 7992 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7993   match(Set dst (CountLeadingZerosI src));
 7994 
 7995   ins_cost(INSN_COST);
 7996   format %{ &quot;clzw  $dst, $src&quot; %}
 7997   ins_encode %{
 7998     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7999   %}
 8000 
 8001   ins_pipe(ialu_reg);
 8002 %}
 8003 
 8004 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 8005   match(Set dst (CountLeadingZerosL src));
 8006 
 8007   ins_cost(INSN_COST);
 8008   format %{ &quot;clz   $dst, $src&quot; %}
 8009   ins_encode %{
 8010     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 8011   %}
 8012 
 8013   ins_pipe(ialu_reg);
 8014 %}
 8015 
 8016 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8017   match(Set dst (CountTrailingZerosI src));
 8018 
 8019   ins_cost(INSN_COST * 2);
 8020   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8021             &quot;clzw   $dst, $dst&quot; %}
 8022   ins_encode %{
 8023     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8024     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8025   %}
 8026 
 8027   ins_pipe(ialu_reg);
 8028 %}
 8029 
 8030 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8031   match(Set dst (CountTrailingZerosL src));
 8032 
 8033   ins_cost(INSN_COST * 2);
 8034   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8035             &quot;clz    $dst, $dst&quot; %}
 8036   ins_encode %{
 8037     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8038     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8039   %}
 8040 
 8041   ins_pipe(ialu_reg);
 8042 %}
 8043 
 8044 //---------- Population Count Instructions -------------------------------------
 8045 //
 8046 
 8047 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8048   predicate(UsePopCountInstruction);
 8049   match(Set dst (PopCountI src));
 8050   effect(TEMP tmp);
 8051   ins_cost(INSN_COST * 13);
 8052 
 8053   format %{ &quot;movw   $src, $src\n\t&quot;
 8054             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8055             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8056             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8057             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8058   ins_encode %{
 8059     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8060     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8061     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8062     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8063     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8064   %}
 8065 
 8066   ins_pipe(pipe_class_default);
 8067 %}
 8068 
 8069 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8070   predicate(UsePopCountInstruction);
 8071   match(Set dst (PopCountI (LoadI mem)));
 8072   effect(TEMP tmp);
 8073   ins_cost(INSN_COST * 13);
 8074 
 8075   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8076             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8077             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8078             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8079   ins_encode %{
 8080     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8081     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8082               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8083     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8084     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8085     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8086   %}
 8087 
 8088   ins_pipe(pipe_class_default);
 8089 %}
 8090 
 8091 // Note: Long.bitCount(long) returns an int.
 8092 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8093   predicate(UsePopCountInstruction);
 8094   match(Set dst (PopCountL src));
 8095   effect(TEMP tmp);
 8096   ins_cost(INSN_COST * 13);
 8097 
 8098   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8099             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8100             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8101             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8102   ins_encode %{
 8103     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8104     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8105     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8106     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8107   %}
 8108 
 8109   ins_pipe(pipe_class_default);
 8110 %}
 8111 
 8112 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8113   predicate(UsePopCountInstruction);
 8114   match(Set dst (PopCountL (LoadL mem)));
 8115   effect(TEMP tmp);
 8116   ins_cost(INSN_COST * 13);
 8117 
 8118   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8119             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8120             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8121             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8122   ins_encode %{
 8123     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8124     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8125               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8126     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8127     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8128     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8129   %}
 8130 
 8131   ins_pipe(pipe_class_default);
 8132 %}
 8133 
 8134 // ============================================================================
 8135 // MemBar Instruction
 8136 
 8137 instruct load_fence() %{
 8138   match(LoadFence);
 8139   ins_cost(VOLATILE_REF_COST);
 8140 
 8141   format %{ &quot;load_fence&quot; %}
 8142 
 8143   ins_encode %{
 8144     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8145   %}
 8146   ins_pipe(pipe_serial);
 8147 %}
 8148 
 8149 instruct unnecessary_membar_acquire() %{
 8150   predicate(unnecessary_acquire(n));
 8151   match(MemBarAcquire);
 8152   ins_cost(0);
 8153 
 8154   format %{ &quot;membar_acquire (elided)&quot; %}
 8155 
 8156   ins_encode %{
 8157     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8158   %}
 8159 
 8160   ins_pipe(pipe_class_empty);
 8161 %}
 8162 
 8163 instruct membar_acquire() %{
 8164   match(MemBarAcquire);
 8165   ins_cost(VOLATILE_REF_COST);
 8166 
 8167   format %{ &quot;membar_acquire\n\t&quot;
 8168             &quot;dmb ish&quot; %}
 8169 
 8170   ins_encode %{
 8171     __ block_comment(&quot;membar_acquire&quot;);
 8172     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8173   %}
 8174 
 8175   ins_pipe(pipe_serial);
 8176 %}
 8177 
 8178 
 8179 instruct membar_acquire_lock() %{
 8180   match(MemBarAcquireLock);
 8181   ins_cost(VOLATILE_REF_COST);
 8182 
 8183   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8184 
 8185   ins_encode %{
 8186     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8187   %}
 8188 
 8189   ins_pipe(pipe_serial);
 8190 %}
 8191 
 8192 instruct store_fence() %{
 8193   match(StoreFence);
 8194   ins_cost(VOLATILE_REF_COST);
 8195 
 8196   format %{ &quot;store_fence&quot; %}
 8197 
 8198   ins_encode %{
 8199     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8200   %}
 8201   ins_pipe(pipe_serial);
 8202 %}
 8203 
 8204 instruct unnecessary_membar_release() %{
 8205   predicate(unnecessary_release(n));
 8206   match(MemBarRelease);
 8207   ins_cost(0);
 8208 
 8209   format %{ &quot;membar_release (elided)&quot; %}
 8210 
 8211   ins_encode %{
 8212     __ block_comment(&quot;membar_release (elided)&quot;);
 8213   %}
 8214   ins_pipe(pipe_serial);
 8215 %}
 8216 
 8217 instruct membar_release() %{
 8218   match(MemBarRelease);
 8219   ins_cost(VOLATILE_REF_COST);
 8220 
 8221   format %{ &quot;membar_release\n\t&quot;
 8222             &quot;dmb ish&quot; %}
 8223 
 8224   ins_encode %{
 8225     __ block_comment(&quot;membar_release&quot;);
 8226     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8227   %}
 8228   ins_pipe(pipe_serial);
 8229 %}
 8230 
 8231 instruct membar_storestore() %{
 8232   match(MemBarStoreStore);
 8233   ins_cost(VOLATILE_REF_COST);
 8234 
 8235   format %{ &quot;MEMBAR-store-store&quot; %}
 8236 
 8237   ins_encode %{
 8238     __ membar(Assembler::StoreStore);
 8239   %}
 8240   ins_pipe(pipe_serial);
 8241 %}
 8242 
 8243 instruct membar_release_lock() %{
 8244   match(MemBarReleaseLock);
 8245   ins_cost(VOLATILE_REF_COST);
 8246 
 8247   format %{ &quot;membar_release_lock (elided)&quot; %}
 8248 
 8249   ins_encode %{
 8250     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8251   %}
 8252 
 8253   ins_pipe(pipe_serial);
 8254 %}
 8255 
 8256 instruct unnecessary_membar_volatile() %{
 8257   predicate(unnecessary_volatile(n));
 8258   match(MemBarVolatile);
 8259   ins_cost(0);
 8260 
 8261   format %{ &quot;membar_volatile (elided)&quot; %}
 8262 
 8263   ins_encode %{
 8264     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8265   %}
 8266 
 8267   ins_pipe(pipe_serial);
 8268 %}
 8269 
 8270 instruct membar_volatile() %{
 8271   match(MemBarVolatile);
 8272   ins_cost(VOLATILE_REF_COST*100);
 8273 
 8274   format %{ &quot;membar_volatile\n\t&quot;
 8275              &quot;dmb ish&quot;%}
 8276 
 8277   ins_encode %{
 8278     __ block_comment(&quot;membar_volatile&quot;);
 8279     __ membar(Assembler::StoreLoad);
 8280   %}
 8281 
 8282   ins_pipe(pipe_serial);
 8283 %}
 8284 
 8285 // ============================================================================
 8286 // Cast/Convert Instructions
 8287 
 8288 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8289   match(Set dst (CastX2P src));
 8290 
 8291   ins_cost(INSN_COST);
 8292   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8293 
 8294   ins_encode %{
 8295     if ($dst$$reg != $src$$reg) {
 8296       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8297     }
 8298   %}
 8299 
 8300   ins_pipe(ialu_reg);
 8301 %}
 8302 
 8303 instruct castN2X(iRegLNoSp dst, iRegN src) %{
 8304   match(Set dst (CastP2X src));
 8305 
 8306   ins_cost(INSN_COST);
 8307   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8308 
 8309   ins_encode %{
 8310     if ($dst$$reg != $src$$reg) {
 8311       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8312     }
 8313   %}
 8314 
 8315   ins_pipe(ialu_reg);
 8316 %}
 8317 
 8318 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8319   match(Set dst (CastP2X src));
 8320 
 8321   ins_cost(INSN_COST);
 8322   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8323 
 8324   ins_encode %{
 8325     if ($dst$$reg != $src$$reg) {
 8326       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8327     }
 8328   %}
 8329 
 8330   ins_pipe(ialu_reg);
 8331 %}
 8332 
 8333 instruct castN2I(iRegINoSp dst, iRegN src) %{
 8334   match(Set dst (CastN2I src));
 8335 
 8336   ins_cost(INSN_COST);
 8337   format %{ &quot;movw $dst, $src\t# compressed ptr -&gt; int&quot; %}
 8338 
 8339   ins_encode %{
 8340     if ($dst$$reg != $src$$reg) {
 8341       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8342     }
 8343   %}
 8344 
 8345   ins_pipe(ialu_reg);
 8346 %}
 8347 
 8348 instruct castI2N(iRegNNoSp dst, iRegI src) %{
 8349   match(Set dst (CastI2N src));
 8350 
 8351   ins_cost(INSN_COST);
 8352   format %{ &quot;movw $dst, $src\t# int -&gt; compressed ptr&quot; %}
 8353 
 8354   ins_encode %{
 8355     if ($dst$$reg != $src$$reg) {
 8356       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8357     }
 8358   %}
 8359 
 8360   ins_pipe(ialu_reg);
 8361 %}
 8362 
 8363 
 8364 // Convert oop into int for vectors alignment masking
 8365 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8366   match(Set dst (ConvL2I (CastP2X src)));
 8367 
 8368   ins_cost(INSN_COST);
 8369   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8370   ins_encode %{
 8371     __ movw($dst$$Register, $src$$Register);
 8372   %}
 8373 
 8374   ins_pipe(ialu_reg);
 8375 %}
 8376 
 8377 // Convert compressed oop into int for vectors alignment masking
 8378 // in case of 32bit oops (heap &lt; 4Gb).
 8379 instruct convN2I(iRegINoSp dst, iRegN src)
 8380 %{
 8381   predicate(CompressedOops::shift() == 0);
 8382   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8383 
 8384   ins_cost(INSN_COST);
 8385   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8386   ins_encode %{
 8387     __ movw($dst$$Register, $src$$Register);
 8388   %}
 8389 
 8390   ins_pipe(ialu_reg);
 8391 %}
 8392 
 8393 
 8394 // Convert oop pointer into compressed form
 8395 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8396   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8397   match(Set dst (EncodeP src));
 8398   effect(KILL cr);
 8399   ins_cost(INSN_COST * 3);
 8400   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8401   ins_encode %{
 8402     Register s = $src$$Register;
 8403     Register d = $dst$$Register;
 8404     __ encode_heap_oop(d, s);
 8405   %}
 8406   ins_pipe(ialu_reg);
 8407 %}
 8408 
 8409 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8410   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8411   match(Set dst (EncodeP src));
 8412   ins_cost(INSN_COST * 3);
 8413   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8414   ins_encode %{
 8415     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8416   %}
 8417   ins_pipe(ialu_reg);
 8418 %}
 8419 
 8420 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8421   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8422             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8423   match(Set dst (DecodeN src));
 8424   ins_cost(INSN_COST * 3);
 8425   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8426   ins_encode %{
 8427     Register s = $src$$Register;
 8428     Register d = $dst$$Register;
 8429     __ decode_heap_oop(d, s);
 8430   %}
 8431   ins_pipe(ialu_reg);
 8432 %}
 8433 
 8434 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8435   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8436             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8437   match(Set dst (DecodeN src));
 8438   ins_cost(INSN_COST * 3);
 8439   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8440   ins_encode %{
 8441     Register s = $src$$Register;
 8442     Register d = $dst$$Register;
 8443     __ decode_heap_oop_not_null(d, s);
 8444   %}
 8445   ins_pipe(ialu_reg);
 8446 %}
 8447 
 8448 // n.b. AArch64 implementations of encode_klass_not_null and
 8449 // decode_klass_not_null do not modify the flags register so, unlike
 8450 // Intel, we don&#39;t kill CR as a side effect here
 8451 
 8452 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8453   match(Set dst (EncodePKlass src));
 8454 
 8455   ins_cost(INSN_COST * 3);
 8456   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8457 
 8458   ins_encode %{
 8459     Register src_reg = as_Register($src$$reg);
 8460     Register dst_reg = as_Register($dst$$reg);
 8461     __ encode_klass_not_null(dst_reg, src_reg);
 8462   %}
 8463 
 8464    ins_pipe(ialu_reg);
 8465 %}
 8466 
 8467 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8468   match(Set dst (DecodeNKlass src));
 8469 
 8470   ins_cost(INSN_COST * 3);
 8471   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8472 
 8473   ins_encode %{
 8474     Register src_reg = as_Register($src$$reg);
 8475     Register dst_reg = as_Register($dst$$reg);
 8476     if (dst_reg != src_reg) {
 8477       __ decode_klass_not_null(dst_reg, src_reg);
 8478     } else {
 8479       __ decode_klass_not_null(dst_reg);
 8480     }
 8481   %}
 8482 
 8483    ins_pipe(ialu_reg);
 8484 %}
 8485 
 8486 instruct checkCastPP(iRegPNoSp dst)
 8487 %{
 8488   match(Set dst (CheckCastPP dst));
 8489 
 8490   size(0);
 8491   format %{ &quot;# checkcastPP of $dst&quot; %}
 8492   ins_encode(/* empty encoding */);
 8493   ins_pipe(pipe_class_empty);
 8494 %}
 8495 
 8496 instruct castPP(iRegPNoSp dst)
 8497 %{
 8498   match(Set dst (CastPP dst));
 8499 
 8500   size(0);
 8501   format %{ &quot;# castPP of $dst&quot; %}
 8502   ins_encode(/* empty encoding */);
 8503   ins_pipe(pipe_class_empty);
 8504 %}
 8505 
 8506 instruct castII(iRegI dst)
 8507 %{
 8508   match(Set dst (CastII dst));
 8509 
 8510   size(0);
 8511   format %{ &quot;# castII of $dst&quot; %}
 8512   ins_encode(/* empty encoding */);
 8513   ins_cost(0);
 8514   ins_pipe(pipe_class_empty);
 8515 %}
 8516 
 8517 // ============================================================================
 8518 // Atomic operation instructions
 8519 //
 8520 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8521 // Store{PIL}Conditional instructions using a normal load for the
 8522 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8523 //
 8524 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8525 // pair to lock object allocations from Eden space when not using
 8526 // TLABs.
 8527 //
 8528 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8529 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8530 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8531 // only for 64-bit.
 8532 //
 8533 // We implement LoadPLocked and StorePLocked instructions using,
 8534 // respectively the AArch64 hw load-exclusive and store-conditional
 8535 // instructions. Whereas we must implement each of
 8536 // Store{IL}Conditional using a CAS which employs a pair of
 8537 // instructions comprising a load-exclusive followed by a
 8538 // store-conditional.
 8539 
 8540 
 8541 // Locked-load (linked load) of the current heap-top
 8542 // used when updating the eden heap top
 8543 // implemented using ldaxr on AArch64
 8544 
 8545 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8546 %{
 8547   match(Set dst (LoadPLocked mem));
 8548 
 8549   ins_cost(VOLATILE_REF_COST);
 8550 
 8551   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8552 
 8553   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8554 
 8555   ins_pipe(pipe_serial);
 8556 %}
 8557 
 8558 // Conditional-store of the updated heap-top.
 8559 // Used during allocation of the shared heap.
 8560 // Sets flag (EQ) on success.
 8561 // implemented using stlxr on AArch64.
 8562 
 8563 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8564 %{
 8565   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8566 
 8567   ins_cost(VOLATILE_REF_COST);
 8568 
 8569  // TODO
 8570  // do we need to do a store-conditional release or can we just use a
 8571  // plain store-conditional?
 8572 
 8573   format %{
 8574     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8575     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8576   %}
 8577 
 8578   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8579 
 8580   ins_pipe(pipe_serial);
 8581 %}
 8582 
 8583 
 8584 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8585 // when attempting to rebias a lock towards the current thread.  We
 8586 // must use the acquire form of cmpxchg in order to guarantee acquire
 8587 // semantics in this case.
 8588 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8589 %{
 8590   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8591 
 8592   ins_cost(VOLATILE_REF_COST);
 8593 
 8594   format %{
 8595     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8596     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8597   %}
 8598 
 8599   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8600 
 8601   ins_pipe(pipe_slow);
 8602 %}
 8603 
 8604 // storeIConditional also has acquire semantics, for no better reason
 8605 // than matching storeLConditional.  At the time of writing this
 8606 // comment storeIConditional was not used anywhere by AArch64.
 8607 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8608 %{
 8609   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8610 
 8611   ins_cost(VOLATILE_REF_COST);
 8612 
 8613   format %{
 8614     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8615     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8616   %}
 8617 
 8618   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8619 
 8620   ins_pipe(pipe_slow);
 8621 %}
 8622 
 8623 // standard CompareAndSwapX when we are using barriers
 8624 // these have higher priority than the rules selected by a predicate
 8625 
 8626 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8627 // can&#39;t match them
 8628 
 8629 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8630 
 8631   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8632   ins_cost(2 * VOLATILE_REF_COST);
 8633 
 8634   effect(KILL cr);
 8635 
 8636   format %{
 8637     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8638     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8639   %}
 8640 
 8641   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8642             aarch64_enc_cset_eq(res));
 8643 
 8644   ins_pipe(pipe_slow);
 8645 %}
 8646 
 8647 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8648 
 8649   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8650   ins_cost(2 * VOLATILE_REF_COST);
 8651 
 8652   effect(KILL cr);
 8653 
 8654   format %{
 8655     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8656     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8657   %}
 8658 
 8659   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8660             aarch64_enc_cset_eq(res));
 8661 
 8662   ins_pipe(pipe_slow);
 8663 %}
 8664 
 8665 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8666 
 8667   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8668   ins_cost(2 * VOLATILE_REF_COST);
 8669 
 8670   effect(KILL cr);
 8671 
 8672  format %{
 8673     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8674     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8675  %}
 8676 
 8677  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8678             aarch64_enc_cset_eq(res));
 8679 
 8680   ins_pipe(pipe_slow);
 8681 %}
 8682 
 8683 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8684 
 8685   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8686   ins_cost(2 * VOLATILE_REF_COST);
 8687 
 8688   effect(KILL cr);
 8689 
 8690  format %{
 8691     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8692     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8693  %}
 8694 
 8695  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8696             aarch64_enc_cset_eq(res));
 8697 
 8698   ins_pipe(pipe_slow);
 8699 %}
 8700 
 8701 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8702 
 8703   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8704   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8705   ins_cost(2 * VOLATILE_REF_COST);
 8706 
 8707   effect(KILL cr);
 8708 
 8709  format %{
 8710     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8711     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8712  %}
 8713 
 8714  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8715             aarch64_enc_cset_eq(res));
 8716 
 8717   ins_pipe(pipe_slow);
 8718 %}
 8719 
 8720 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8721 
 8722   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8723   ins_cost(2 * VOLATILE_REF_COST);
 8724 
 8725   effect(KILL cr);
 8726 
 8727  format %{
 8728     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8729     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8730  %}
 8731 
 8732  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8733             aarch64_enc_cset_eq(res));
 8734 
 8735   ins_pipe(pipe_slow);
 8736 %}
 8737 
 8738 // alternative CompareAndSwapX when we are eliding barriers
 8739 
 8740 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8741 
 8742   predicate(needs_acquiring_load_exclusive(n));
 8743   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8744   ins_cost(VOLATILE_REF_COST);
 8745 
 8746   effect(KILL cr);
 8747 
 8748   format %{
 8749     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8750     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8751   %}
 8752 
 8753   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8754             aarch64_enc_cset_eq(res));
 8755 
 8756   ins_pipe(pipe_slow);
 8757 %}
 8758 
 8759 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8760 
 8761   predicate(needs_acquiring_load_exclusive(n));
 8762   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8763   ins_cost(VOLATILE_REF_COST);
 8764 
 8765   effect(KILL cr);
 8766 
 8767   format %{
 8768     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8769     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8770   %}
 8771 
 8772   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8773             aarch64_enc_cset_eq(res));
 8774 
 8775   ins_pipe(pipe_slow);
 8776 %}
 8777 
 8778 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8779 
 8780   predicate(needs_acquiring_load_exclusive(n));
 8781   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8782   ins_cost(VOLATILE_REF_COST);
 8783 
 8784   effect(KILL cr);
 8785 
 8786  format %{
 8787     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8788     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8789  %}
 8790 
 8791  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8792             aarch64_enc_cset_eq(res));
 8793 
 8794   ins_pipe(pipe_slow);
 8795 %}
 8796 
 8797 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8798 
 8799   predicate(needs_acquiring_load_exclusive(n));
 8800   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8801   ins_cost(VOLATILE_REF_COST);
 8802 
 8803   effect(KILL cr);
 8804 
 8805  format %{
 8806     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8807     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8808  %}
 8809 
 8810  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8811             aarch64_enc_cset_eq(res));
 8812 
 8813   ins_pipe(pipe_slow);
 8814 %}
 8815 
 8816 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8817 
 8818   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8819   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8820   ins_cost(VOLATILE_REF_COST);
 8821 
 8822   effect(KILL cr);
 8823 
 8824  format %{
 8825     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8826     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8827  %}
 8828 
 8829  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8830             aarch64_enc_cset_eq(res));
 8831 
 8832   ins_pipe(pipe_slow);
 8833 %}
 8834 
 8835 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8836 
 8837   predicate(needs_acquiring_load_exclusive(n));
 8838   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8839   ins_cost(VOLATILE_REF_COST);
 8840 
 8841   effect(KILL cr);
 8842 
 8843  format %{
 8844     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8845     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8846  %}
 8847 
 8848  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8849             aarch64_enc_cset_eq(res));
 8850 
 8851   ins_pipe(pipe_slow);
 8852 %}
 8853 
 8854 
 8855 // ---------------------------------------------------------------------
 8856 
 8857 
 8858 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8859 
 8860 // Sundry CAS operations.  Note that release is always true,
 8861 // regardless of the memory ordering of the CAS.  This is because we
 8862 // need the volatile case to be sequentially consistent but there is
 8863 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8864 // can&#39;t check the type of memory ordering here, so we always emit a
 8865 // STLXR.
 8866 
 8867 // This section is generated from aarch64_ad_cas.m4
 8868 
 8869 
 8870 
 8871 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8872   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8873   ins_cost(2 * VOLATILE_REF_COST);
 8874   effect(TEMP_DEF res, KILL cr);
 8875   format %{
 8876     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8877   %}
 8878   ins_encode %{
 8879     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8880                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8881                /*weak*/ false, $res$$Register);
 8882     __ sxtbw($res$$Register, $res$$Register);
 8883   %}
 8884   ins_pipe(pipe_slow);
 8885 %}
 8886 
 8887 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8888   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8889   ins_cost(2 * VOLATILE_REF_COST);
 8890   effect(TEMP_DEF res, KILL cr);
 8891   format %{
 8892     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8893   %}
 8894   ins_encode %{
 8895     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8896                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8897                /*weak*/ false, $res$$Register);
 8898     __ sxthw($res$$Register, $res$$Register);
 8899   %}
 8900   ins_pipe(pipe_slow);
 8901 %}
 8902 
 8903 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8904   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8905   ins_cost(2 * VOLATILE_REF_COST);
 8906   effect(TEMP_DEF res, KILL cr);
 8907   format %{
 8908     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8909   %}
 8910   ins_encode %{
 8911     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8912                Assembler::word, /*acquire*/ false, /*release*/ true,
 8913                /*weak*/ false, $res$$Register);
 8914   %}
 8915   ins_pipe(pipe_slow);
 8916 %}
 8917 
 8918 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8919   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8920   ins_cost(2 * VOLATILE_REF_COST);
 8921   effect(TEMP_DEF res, KILL cr);
 8922   format %{
 8923     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8924   %}
 8925   ins_encode %{
 8926     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8927                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8928                /*weak*/ false, $res$$Register);
 8929   %}
 8930   ins_pipe(pipe_slow);
 8931 %}
 8932 
 8933 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8934   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8935   ins_cost(2 * VOLATILE_REF_COST);
 8936   effect(TEMP_DEF res, KILL cr);
 8937   format %{
 8938     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8939   %}
 8940   ins_encode %{
 8941     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8942                Assembler::word, /*acquire*/ false, /*release*/ true,
 8943                /*weak*/ false, $res$$Register);
 8944   %}
 8945   ins_pipe(pipe_slow);
 8946 %}
 8947 
 8948 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8949   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8950   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8951   ins_cost(2 * VOLATILE_REF_COST);
 8952   effect(TEMP_DEF res, KILL cr);
 8953   format %{
 8954     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8955   %}
 8956   ins_encode %{
 8957     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8958                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8959                /*weak*/ false, $res$$Register);
 8960   %}
 8961   ins_pipe(pipe_slow);
 8962 %}
 8963 
 8964 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8965   predicate(needs_acquiring_load_exclusive(n));
 8966   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8967   ins_cost(VOLATILE_REF_COST);
 8968   effect(TEMP_DEF res, KILL cr);
 8969   format %{
 8970     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8971   %}
 8972   ins_encode %{
 8973     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8974                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8975                /*weak*/ false, $res$$Register);
 8976     __ sxtbw($res$$Register, $res$$Register);
 8977   %}
 8978   ins_pipe(pipe_slow);
 8979 %}
 8980 
 8981 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8982   predicate(needs_acquiring_load_exclusive(n));
 8983   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8984   ins_cost(VOLATILE_REF_COST);
 8985   effect(TEMP_DEF res, KILL cr);
 8986   format %{
 8987     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8988   %}
 8989   ins_encode %{
 8990     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8991                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8992                /*weak*/ false, $res$$Register);
 8993     __ sxthw($res$$Register, $res$$Register);
 8994   %}
 8995   ins_pipe(pipe_slow);
 8996 %}
 8997 
 8998 
 8999 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9000   predicate(needs_acquiring_load_exclusive(n));
 9001   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 9002   ins_cost(VOLATILE_REF_COST);
 9003   effect(TEMP_DEF res, KILL cr);
 9004   format %{
 9005     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9006   %}
 9007   ins_encode %{
 9008     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9009                Assembler::word, /*acquire*/ true, /*release*/ true,
 9010                /*weak*/ false, $res$$Register);
 9011   %}
 9012   ins_pipe(pipe_slow);
 9013 %}
 9014 
 9015 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9016   predicate(needs_acquiring_load_exclusive(n));
 9017   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 9018   ins_cost(VOLATILE_REF_COST);
 9019   effect(TEMP_DEF res, KILL cr);
 9020   format %{
 9021     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9022   %}
 9023   ins_encode %{
 9024     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9025                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9026                /*weak*/ false, $res$$Register);
 9027   %}
 9028   ins_pipe(pipe_slow);
 9029 %}
 9030 
 9031 
 9032 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9033   predicate(needs_acquiring_load_exclusive(n));
 9034   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 9035   ins_cost(VOLATILE_REF_COST);
 9036   effect(TEMP_DEF res, KILL cr);
 9037   format %{
 9038     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9039   %}
 9040   ins_encode %{
 9041     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9042                Assembler::word, /*acquire*/ true, /*release*/ true,
 9043                /*weak*/ false, $res$$Register);
 9044   %}
 9045   ins_pipe(pipe_slow);
 9046 %}
 9047 
 9048 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9049   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9050   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9051   ins_cost(VOLATILE_REF_COST);
 9052   effect(TEMP_DEF res, KILL cr);
 9053   format %{
 9054     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9055   %}
 9056   ins_encode %{
 9057     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9058                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9059                /*weak*/ false, $res$$Register);
 9060   %}
 9061   ins_pipe(pipe_slow);
 9062 %}
 9063 
 9064 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9065   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9066   ins_cost(2 * VOLATILE_REF_COST);
 9067   effect(KILL cr);
 9068   format %{
 9069     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9070     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9071   %}
 9072   ins_encode %{
 9073     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9074                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9075                /*weak*/ true, noreg);
 9076     __ csetw($res$$Register, Assembler::EQ);
 9077   %}
 9078   ins_pipe(pipe_slow);
 9079 %}
 9080 
 9081 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9082   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9083   ins_cost(2 * VOLATILE_REF_COST);
 9084   effect(KILL cr);
 9085   format %{
 9086     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9087     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9088   %}
 9089   ins_encode %{
 9090     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9091                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9092                /*weak*/ true, noreg);
 9093     __ csetw($res$$Register, Assembler::EQ);
 9094   %}
 9095   ins_pipe(pipe_slow);
 9096 %}
 9097 
 9098 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9099   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9100   ins_cost(2 * VOLATILE_REF_COST);
 9101   effect(KILL cr);
 9102   format %{
 9103     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9104     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9105   %}
 9106   ins_encode %{
 9107     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9108                Assembler::word, /*acquire*/ false, /*release*/ true,
 9109                /*weak*/ true, noreg);
 9110     __ csetw($res$$Register, Assembler::EQ);
 9111   %}
 9112   ins_pipe(pipe_slow);
 9113 %}
 9114 
 9115 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9116   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9117   ins_cost(2 * VOLATILE_REF_COST);
 9118   effect(KILL cr);
 9119   format %{
 9120     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9121     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9122   %}
 9123   ins_encode %{
 9124     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9125                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9126                /*weak*/ true, noreg);
 9127     __ csetw($res$$Register, Assembler::EQ);
 9128   %}
 9129   ins_pipe(pipe_slow);
 9130 %}
 9131 
 9132 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9133   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9134   ins_cost(2 * VOLATILE_REF_COST);
 9135   effect(KILL cr);
 9136   format %{
 9137     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9138     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9139   %}
 9140   ins_encode %{
 9141     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9142                Assembler::word, /*acquire*/ false, /*release*/ true,
 9143                /*weak*/ true, noreg);
 9144     __ csetw($res$$Register, Assembler::EQ);
 9145   %}
 9146   ins_pipe(pipe_slow);
 9147 %}
 9148 
 9149 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9150   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9151   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9152   ins_cost(2 * VOLATILE_REF_COST);
 9153   effect(KILL cr);
 9154   format %{
 9155     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9156     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9157   %}
 9158   ins_encode %{
 9159     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9160                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9161                /*weak*/ true, noreg);
 9162     __ csetw($res$$Register, Assembler::EQ);
 9163   %}
 9164   ins_pipe(pipe_slow);
 9165 %}
 9166 
 9167 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9168   predicate(needs_acquiring_load_exclusive(n));
 9169   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9170   ins_cost(VOLATILE_REF_COST);
 9171   effect(KILL cr);
 9172   format %{
 9173     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9174     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9175   %}
 9176   ins_encode %{
 9177     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9178                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9179                /*weak*/ true, noreg);
 9180     __ csetw($res$$Register, Assembler::EQ);
 9181   %}
 9182   ins_pipe(pipe_slow);
 9183 %}
 9184 
 9185 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9186   predicate(needs_acquiring_load_exclusive(n));
 9187   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9188   ins_cost(VOLATILE_REF_COST);
 9189   effect(KILL cr);
 9190   format %{
 9191     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9192     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9193   %}
 9194   ins_encode %{
 9195     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9196                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9197                /*weak*/ true, noreg);
 9198     __ csetw($res$$Register, Assembler::EQ);
 9199   %}
 9200   ins_pipe(pipe_slow);
 9201 %}
 9202 
 9203 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9204   predicate(needs_acquiring_load_exclusive(n));
 9205   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9206   ins_cost(VOLATILE_REF_COST);
 9207   effect(KILL cr);
 9208   format %{
 9209     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9210     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9211   %}
 9212   ins_encode %{
 9213     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9214                Assembler::word, /*acquire*/ true, /*release*/ true,
 9215                /*weak*/ true, noreg);
 9216     __ csetw($res$$Register, Assembler::EQ);
 9217   %}
 9218   ins_pipe(pipe_slow);
 9219 %}
 9220 
 9221 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9222   predicate(needs_acquiring_load_exclusive(n));
 9223   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9224   ins_cost(VOLATILE_REF_COST);
 9225   effect(KILL cr);
 9226   format %{
 9227     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9228     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9229   %}
 9230   ins_encode %{
 9231     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9232                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9233                /*weak*/ true, noreg);
 9234     __ csetw($res$$Register, Assembler::EQ);
 9235   %}
 9236   ins_pipe(pipe_slow);
 9237 %}
 9238 
 9239 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9240   predicate(needs_acquiring_load_exclusive(n));
 9241   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9242   ins_cost(VOLATILE_REF_COST);
 9243   effect(KILL cr);
 9244   format %{
 9245     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9246     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9247   %}
 9248   ins_encode %{
 9249     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9250                Assembler::word, /*acquire*/ true, /*release*/ true,
 9251                /*weak*/ true, noreg);
 9252     __ csetw($res$$Register, Assembler::EQ);
 9253   %}
 9254   ins_pipe(pipe_slow);
 9255 %}
 9256 
 9257 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9258   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9259   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9260   ins_cost(VOLATILE_REF_COST);
 9261   effect(KILL cr);
 9262   format %{
 9263     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9264     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9265   %}
 9266   ins_encode %{
 9267     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9268                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9269                /*weak*/ true, noreg);
 9270     __ csetw($res$$Register, Assembler::EQ);
 9271   %}
 9272   ins_pipe(pipe_slow);
 9273 %}
 9274 
 9275 // END This section of the file is automatically generated. Do not edit --------------
 9276 // ---------------------------------------------------------------------
 9277 
 9278 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9279   match(Set prev (GetAndSetI mem newv));
 9280   ins_cost(2 * VOLATILE_REF_COST);
 9281   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9282   ins_encode %{
 9283     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9284   %}
 9285   ins_pipe(pipe_serial);
 9286 %}
 9287 
 9288 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9289   match(Set prev (GetAndSetL mem newv));
 9290   ins_cost(2 * VOLATILE_REF_COST);
 9291   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9292   ins_encode %{
 9293     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9294   %}
 9295   ins_pipe(pipe_serial);
 9296 %}
 9297 
 9298 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9299   match(Set prev (GetAndSetN mem newv));
 9300   ins_cost(2 * VOLATILE_REF_COST);
 9301   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9302   ins_encode %{
 9303     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9304   %}
 9305   ins_pipe(pipe_serial);
 9306 %}
 9307 
 9308 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9309   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9310   match(Set prev (GetAndSetP mem newv));
 9311   ins_cost(2 * VOLATILE_REF_COST);
 9312   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9313   ins_encode %{
 9314     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9315   %}
 9316   ins_pipe(pipe_serial);
 9317 %}
 9318 
 9319 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9320   predicate(needs_acquiring_load_exclusive(n));
 9321   match(Set prev (GetAndSetI mem newv));
 9322   ins_cost(VOLATILE_REF_COST);
 9323   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9324   ins_encode %{
 9325     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9326   %}
 9327   ins_pipe(pipe_serial);
 9328 %}
 9329 
 9330 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9331   predicate(needs_acquiring_load_exclusive(n));
 9332   match(Set prev (GetAndSetL mem newv));
 9333   ins_cost(VOLATILE_REF_COST);
 9334   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9335   ins_encode %{
 9336     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9337   %}
 9338   ins_pipe(pipe_serial);
 9339 %}
 9340 
 9341 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9342   predicate(needs_acquiring_load_exclusive(n));
 9343   match(Set prev (GetAndSetN mem newv));
 9344   ins_cost(VOLATILE_REF_COST);
 9345   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9346   ins_encode %{
 9347     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9348   %}
 9349   ins_pipe(pipe_serial);
 9350 %}
 9351 
 9352 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9353   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9354   match(Set prev (GetAndSetP mem newv));
 9355   ins_cost(VOLATILE_REF_COST);
 9356   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9357   ins_encode %{
 9358     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9359   %}
 9360   ins_pipe(pipe_serial);
 9361 %}
 9362 
 9363 
 9364 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9365   match(Set newval (GetAndAddL mem incr));
 9366   ins_cost(2 * VOLATILE_REF_COST + 1);
 9367   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9368   ins_encode %{
 9369     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9370   %}
 9371   ins_pipe(pipe_serial);
 9372 %}
 9373 
 9374 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9375   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9376   match(Set dummy (GetAndAddL mem incr));
 9377   ins_cost(2 * VOLATILE_REF_COST);
 9378   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9379   ins_encode %{
 9380     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9381   %}
 9382   ins_pipe(pipe_serial);
 9383 %}
 9384 
 9385 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9386   match(Set newval (GetAndAddL mem incr));
 9387   ins_cost(2 * VOLATILE_REF_COST + 1);
 9388   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9389   ins_encode %{
 9390     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9391   %}
 9392   ins_pipe(pipe_serial);
 9393 %}
 9394 
 9395 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9396   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9397   match(Set dummy (GetAndAddL mem incr));
 9398   ins_cost(2 * VOLATILE_REF_COST);
 9399   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9400   ins_encode %{
 9401     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9402   %}
 9403   ins_pipe(pipe_serial);
 9404 %}
 9405 
 9406 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9407   match(Set newval (GetAndAddI mem incr));
 9408   ins_cost(2 * VOLATILE_REF_COST + 1);
 9409   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9410   ins_encode %{
 9411     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9412   %}
 9413   ins_pipe(pipe_serial);
 9414 %}
 9415 
 9416 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9417   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9418   match(Set dummy (GetAndAddI mem incr));
 9419   ins_cost(2 * VOLATILE_REF_COST);
 9420   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9421   ins_encode %{
 9422     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9423   %}
 9424   ins_pipe(pipe_serial);
 9425 %}
 9426 
 9427 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9428   match(Set newval (GetAndAddI mem incr));
 9429   ins_cost(2 * VOLATILE_REF_COST + 1);
 9430   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9431   ins_encode %{
 9432     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9433   %}
 9434   ins_pipe(pipe_serial);
 9435 %}
 9436 
 9437 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9438   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9439   match(Set dummy (GetAndAddI mem incr));
 9440   ins_cost(2 * VOLATILE_REF_COST);
 9441   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9442   ins_encode %{
 9443     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9444   %}
 9445   ins_pipe(pipe_serial);
 9446 %}
 9447 
 9448 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9449   predicate(needs_acquiring_load_exclusive(n));
 9450   match(Set newval (GetAndAddL mem incr));
 9451   ins_cost(VOLATILE_REF_COST + 1);
 9452   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9453   ins_encode %{
 9454     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9455   %}
 9456   ins_pipe(pipe_serial);
 9457 %}
 9458 
 9459 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9460   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9461   match(Set dummy (GetAndAddL mem incr));
 9462   ins_cost(VOLATILE_REF_COST);
 9463   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9464   ins_encode %{
 9465     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9466   %}
 9467   ins_pipe(pipe_serial);
 9468 %}
 9469 
 9470 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9471   predicate(needs_acquiring_load_exclusive(n));
 9472   match(Set newval (GetAndAddL mem incr));
 9473   ins_cost(VOLATILE_REF_COST + 1);
 9474   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9475   ins_encode %{
 9476     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9477   %}
 9478   ins_pipe(pipe_serial);
 9479 %}
 9480 
 9481 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9482   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9483   match(Set dummy (GetAndAddL mem incr));
 9484   ins_cost(VOLATILE_REF_COST);
 9485   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9486   ins_encode %{
 9487     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9488   %}
 9489   ins_pipe(pipe_serial);
 9490 %}
 9491 
 9492 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9493   predicate(needs_acquiring_load_exclusive(n));
 9494   match(Set newval (GetAndAddI mem incr));
 9495   ins_cost(VOLATILE_REF_COST + 1);
 9496   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9497   ins_encode %{
 9498     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9499   %}
 9500   ins_pipe(pipe_serial);
 9501 %}
 9502 
 9503 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9504   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9505   match(Set dummy (GetAndAddI mem incr));
 9506   ins_cost(VOLATILE_REF_COST);
 9507   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9508   ins_encode %{
 9509     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9510   %}
 9511   ins_pipe(pipe_serial);
 9512 %}
 9513 
 9514 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9515   predicate(needs_acquiring_load_exclusive(n));
 9516   match(Set newval (GetAndAddI mem incr));
 9517   ins_cost(VOLATILE_REF_COST + 1);
 9518   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9519   ins_encode %{
 9520     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9521   %}
 9522   ins_pipe(pipe_serial);
 9523 %}
 9524 
 9525 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9526   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9527   match(Set dummy (GetAndAddI mem incr));
 9528   ins_cost(VOLATILE_REF_COST);
 9529   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9530   ins_encode %{
 9531     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9532   %}
 9533   ins_pipe(pipe_serial);
 9534 %}
 9535 
 9536 // Manifest a CmpL result in an integer register.
 9537 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9538 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9539 %{
 9540   match(Set dst (CmpL3 src1 src2));
 9541   effect(KILL flags);
 9542 
 9543   ins_cost(INSN_COST * 6);
 9544   format %{
 9545       &quot;cmp $src1, $src2&quot;
 9546       &quot;csetw $dst, ne&quot;
 9547       &quot;cnegw $dst, lt&quot;
 9548   %}
 9549   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9550   ins_encode %{
 9551     __ cmp($src1$$Register, $src2$$Register);
 9552     __ csetw($dst$$Register, Assembler::NE);
 9553     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9554   %}
 9555 
 9556   ins_pipe(pipe_class_default);
 9557 %}
 9558 
 9559 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9560 %{
 9561   match(Set dst (CmpL3 src1 src2));
 9562   effect(KILL flags);
 9563 
 9564   ins_cost(INSN_COST * 6);
 9565   format %{
 9566       &quot;cmp $src1, $src2&quot;
 9567       &quot;csetw $dst, ne&quot;
 9568       &quot;cnegw $dst, lt&quot;
 9569   %}
 9570   ins_encode %{
 9571     int32_t con = (int32_t)$src2$$constant;
 9572      if (con &lt; 0) {
 9573       __ adds(zr, $src1$$Register, -con);
 9574     } else {
 9575       __ subs(zr, $src1$$Register, con);
 9576     }
 9577     __ csetw($dst$$Register, Assembler::NE);
 9578     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9579   %}
 9580 
 9581   ins_pipe(pipe_class_default);
 9582 %}
 9583 
 9584 // ============================================================================
 9585 // Conditional Move Instructions
 9586 
 9587 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9588 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9589 // define an op class which merged both inputs and use it to type the
 9590 // argument to a single rule. unfortunatelyt his fails because the
 9591 // opclass does not live up to the COND_INTER interface of its
 9592 // component operands. When the generic code tries to negate the
 9593 // operand it ends up running the generci Machoper::negate method
 9594 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9595 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9596 
 9597 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9598   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9599 
 9600   ins_cost(INSN_COST * 2);
 9601   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9602 
 9603   ins_encode %{
 9604     __ cselw(as_Register($dst$$reg),
 9605              as_Register($src2$$reg),
 9606              as_Register($src1$$reg),
 9607              (Assembler::Condition)$cmp$$cmpcode);
 9608   %}
 9609 
 9610   ins_pipe(icond_reg_reg);
 9611 %}
 9612 
 9613 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9614   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9615 
 9616   ins_cost(INSN_COST * 2);
 9617   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9618 
 9619   ins_encode %{
 9620     __ cselw(as_Register($dst$$reg),
 9621              as_Register($src2$$reg),
 9622              as_Register($src1$$reg),
 9623              (Assembler::Condition)$cmp$$cmpcode);
 9624   %}
 9625 
 9626   ins_pipe(icond_reg_reg);
 9627 %}
 9628 
 9629 // special cases where one arg is zero
 9630 
 9631 // n.b. this is selected in preference to the rule above because it
 9632 // avoids loading constant 0 into a source register
 9633 
 9634 // TODO
 9635 // we ought only to be able to cull one of these variants as the ideal
 9636 // transforms ought always to order the zero consistently (to left/right?)
 9637 
 9638 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9639   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9640 
 9641   ins_cost(INSN_COST * 2);
 9642   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9643 
 9644   ins_encode %{
 9645     __ cselw(as_Register($dst$$reg),
 9646              as_Register($src$$reg),
 9647              zr,
 9648              (Assembler::Condition)$cmp$$cmpcode);
 9649   %}
 9650 
 9651   ins_pipe(icond_reg);
 9652 %}
 9653 
 9654 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9655   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9656 
 9657   ins_cost(INSN_COST * 2);
 9658   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9659 
 9660   ins_encode %{
 9661     __ cselw(as_Register($dst$$reg),
 9662              as_Register($src$$reg),
 9663              zr,
 9664              (Assembler::Condition)$cmp$$cmpcode);
 9665   %}
 9666 
 9667   ins_pipe(icond_reg);
 9668 %}
 9669 
 9670 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9671   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9672 
 9673   ins_cost(INSN_COST * 2);
 9674   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9675 
 9676   ins_encode %{
 9677     __ cselw(as_Register($dst$$reg),
 9678              zr,
 9679              as_Register($src$$reg),
 9680              (Assembler::Condition)$cmp$$cmpcode);
 9681   %}
 9682 
 9683   ins_pipe(icond_reg);
 9684 %}
 9685 
 9686 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9687   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9688 
 9689   ins_cost(INSN_COST * 2);
 9690   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9691 
 9692   ins_encode %{
 9693     __ cselw(as_Register($dst$$reg),
 9694              zr,
 9695              as_Register($src$$reg),
 9696              (Assembler::Condition)$cmp$$cmpcode);
 9697   %}
 9698 
 9699   ins_pipe(icond_reg);
 9700 %}
 9701 
 9702 // special case for creating a boolean 0 or 1
 9703 
 9704 // n.b. this is selected in preference to the rule above because it
 9705 // avoids loading constants 0 and 1 into a source register
 9706 
 9707 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9708   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9709 
 9710   ins_cost(INSN_COST * 2);
 9711   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9712 
 9713   ins_encode %{
 9714     // equivalently
 9715     // cset(as_Register($dst$$reg),
 9716     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9717     __ csincw(as_Register($dst$$reg),
 9718              zr,
 9719              zr,
 9720              (Assembler::Condition)$cmp$$cmpcode);
 9721   %}
 9722 
 9723   ins_pipe(icond_none);
 9724 %}
 9725 
 9726 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9727   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9728 
 9729   ins_cost(INSN_COST * 2);
 9730   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9731 
 9732   ins_encode %{
 9733     // equivalently
 9734     // cset(as_Register($dst$$reg),
 9735     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9736     __ csincw(as_Register($dst$$reg),
 9737              zr,
 9738              zr,
 9739              (Assembler::Condition)$cmp$$cmpcode);
 9740   %}
 9741 
 9742   ins_pipe(icond_none);
 9743 %}
 9744 
 9745 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9746   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9747 
 9748   ins_cost(INSN_COST * 2);
 9749   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9750 
 9751   ins_encode %{
 9752     __ csel(as_Register($dst$$reg),
 9753             as_Register($src2$$reg),
 9754             as_Register($src1$$reg),
 9755             (Assembler::Condition)$cmp$$cmpcode);
 9756   %}
 9757 
 9758   ins_pipe(icond_reg_reg);
 9759 %}
 9760 
 9761 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9762   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9763 
 9764   ins_cost(INSN_COST * 2);
 9765   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9766 
 9767   ins_encode %{
 9768     __ csel(as_Register($dst$$reg),
 9769             as_Register($src2$$reg),
 9770             as_Register($src1$$reg),
 9771             (Assembler::Condition)$cmp$$cmpcode);
 9772   %}
 9773 
 9774   ins_pipe(icond_reg_reg);
 9775 %}
 9776 
 9777 // special cases where one arg is zero
 9778 
 9779 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9780   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9781 
 9782   ins_cost(INSN_COST * 2);
 9783   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9784 
 9785   ins_encode %{
 9786     __ csel(as_Register($dst$$reg),
 9787             zr,
 9788             as_Register($src$$reg),
 9789             (Assembler::Condition)$cmp$$cmpcode);
 9790   %}
 9791 
 9792   ins_pipe(icond_reg);
 9793 %}
 9794 
 9795 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9796   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9797 
 9798   ins_cost(INSN_COST * 2);
 9799   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9800 
 9801   ins_encode %{
 9802     __ csel(as_Register($dst$$reg),
 9803             zr,
 9804             as_Register($src$$reg),
 9805             (Assembler::Condition)$cmp$$cmpcode);
 9806   %}
 9807 
 9808   ins_pipe(icond_reg);
 9809 %}
 9810 
 9811 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9812   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9813 
 9814   ins_cost(INSN_COST * 2);
 9815   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9816 
 9817   ins_encode %{
 9818     __ csel(as_Register($dst$$reg),
 9819             as_Register($src$$reg),
 9820             zr,
 9821             (Assembler::Condition)$cmp$$cmpcode);
 9822   %}
 9823 
 9824   ins_pipe(icond_reg);
 9825 %}
 9826 
 9827 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9828   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9829 
 9830   ins_cost(INSN_COST * 2);
 9831   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9832 
 9833   ins_encode %{
 9834     __ csel(as_Register($dst$$reg),
 9835             as_Register($src$$reg),
 9836             zr,
 9837             (Assembler::Condition)$cmp$$cmpcode);
 9838   %}
 9839 
 9840   ins_pipe(icond_reg);
 9841 %}
 9842 
 9843 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9844   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9845 
 9846   ins_cost(INSN_COST * 2);
 9847   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9848 
 9849   ins_encode %{
 9850     __ csel(as_Register($dst$$reg),
 9851             as_Register($src2$$reg),
 9852             as_Register($src1$$reg),
 9853             (Assembler::Condition)$cmp$$cmpcode);
 9854   %}
 9855 
 9856   ins_pipe(icond_reg_reg);
 9857 %}
 9858 
 9859 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9860   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9861 
 9862   ins_cost(INSN_COST * 2);
 9863   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9864 
 9865   ins_encode %{
 9866     __ csel(as_Register($dst$$reg),
 9867             as_Register($src2$$reg),
 9868             as_Register($src1$$reg),
 9869             (Assembler::Condition)$cmp$$cmpcode);
 9870   %}
 9871 
 9872   ins_pipe(icond_reg_reg);
 9873 %}
 9874 
 9875 // special cases where one arg is zero
 9876 
 9877 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9878   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9879 
 9880   ins_cost(INSN_COST * 2);
 9881   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9882 
 9883   ins_encode %{
 9884     __ csel(as_Register($dst$$reg),
 9885             zr,
 9886             as_Register($src$$reg),
 9887             (Assembler::Condition)$cmp$$cmpcode);
 9888   %}
 9889 
 9890   ins_pipe(icond_reg);
 9891 %}
 9892 
 9893 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9894   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9895 
 9896   ins_cost(INSN_COST * 2);
 9897   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9898 
 9899   ins_encode %{
 9900     __ csel(as_Register($dst$$reg),
 9901             zr,
 9902             as_Register($src$$reg),
 9903             (Assembler::Condition)$cmp$$cmpcode);
 9904   %}
 9905 
 9906   ins_pipe(icond_reg);
 9907 %}
 9908 
 9909 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9910   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9911 
 9912   ins_cost(INSN_COST * 2);
 9913   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9914 
 9915   ins_encode %{
 9916     __ csel(as_Register($dst$$reg),
 9917             as_Register($src$$reg),
 9918             zr,
 9919             (Assembler::Condition)$cmp$$cmpcode);
 9920   %}
 9921 
 9922   ins_pipe(icond_reg);
 9923 %}
 9924 
 9925 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9926   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9927 
 9928   ins_cost(INSN_COST * 2);
 9929   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9930 
 9931   ins_encode %{
 9932     __ csel(as_Register($dst$$reg),
 9933             as_Register($src$$reg),
 9934             zr,
 9935             (Assembler::Condition)$cmp$$cmpcode);
 9936   %}
 9937 
 9938   ins_pipe(icond_reg);
 9939 %}
 9940 
 9941 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9942   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9943 
 9944   ins_cost(INSN_COST * 2);
 9945   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9946 
 9947   ins_encode %{
 9948     __ cselw(as_Register($dst$$reg),
 9949              as_Register($src2$$reg),
 9950              as_Register($src1$$reg),
 9951              (Assembler::Condition)$cmp$$cmpcode);
 9952   %}
 9953 
 9954   ins_pipe(icond_reg_reg);
 9955 %}
 9956 
 9957 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9958   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9959 
 9960   ins_cost(INSN_COST * 2);
 9961   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9962 
 9963   ins_encode %{
 9964     __ cselw(as_Register($dst$$reg),
 9965              as_Register($src2$$reg),
 9966              as_Register($src1$$reg),
 9967              (Assembler::Condition)$cmp$$cmpcode);
 9968   %}
 9969 
 9970   ins_pipe(icond_reg_reg);
 9971 %}
 9972 
 9973 // special cases where one arg is zero
 9974 
 9975 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9976   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9977 
 9978   ins_cost(INSN_COST * 2);
 9979   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9980 
 9981   ins_encode %{
 9982     __ cselw(as_Register($dst$$reg),
 9983              zr,
 9984              as_Register($src$$reg),
 9985              (Assembler::Condition)$cmp$$cmpcode);
 9986   %}
 9987 
 9988   ins_pipe(icond_reg);
 9989 %}
 9990 
 9991 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9992   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9993 
 9994   ins_cost(INSN_COST * 2);
 9995   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9996 
 9997   ins_encode %{
 9998     __ cselw(as_Register($dst$$reg),
 9999              zr,
10000              as_Register($src$$reg),
10001              (Assembler::Condition)$cmp$$cmpcode);
10002   %}
10003 
10004   ins_pipe(icond_reg);
10005 %}
10006 
10007 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10008   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10009 
10010   ins_cost(INSN_COST * 2);
10011   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
10012 
10013   ins_encode %{
10014     __ cselw(as_Register($dst$$reg),
10015              as_Register($src$$reg),
10016              zr,
10017              (Assembler::Condition)$cmp$$cmpcode);
10018   %}
10019 
10020   ins_pipe(icond_reg);
10021 %}
10022 
10023 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10024   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10025 
10026   ins_cost(INSN_COST * 2);
10027   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
10028 
10029   ins_encode %{
10030     __ cselw(as_Register($dst$$reg),
10031              as_Register($src$$reg),
10032              zr,
10033              (Assembler::Condition)$cmp$$cmpcode);
10034   %}
10035 
10036   ins_pipe(icond_reg);
10037 %}
10038 
10039 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10040 %{
10041   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10042 
10043   ins_cost(INSN_COST * 3);
10044 
10045   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10046   ins_encode %{
10047     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10048     __ fcsels(as_FloatRegister($dst$$reg),
10049               as_FloatRegister($src2$$reg),
10050               as_FloatRegister($src1$$reg),
10051               cond);
10052   %}
10053 
10054   ins_pipe(fp_cond_reg_reg_s);
10055 %}
10056 
10057 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10058 %{
10059   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10060 
10061   ins_cost(INSN_COST * 3);
10062 
10063   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10064   ins_encode %{
10065     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10066     __ fcsels(as_FloatRegister($dst$$reg),
10067               as_FloatRegister($src2$$reg),
10068               as_FloatRegister($src1$$reg),
10069               cond);
10070   %}
10071 
10072   ins_pipe(fp_cond_reg_reg_s);
10073 %}
10074 
10075 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10076 %{
10077   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10078 
10079   ins_cost(INSN_COST * 3);
10080 
10081   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10082   ins_encode %{
10083     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10084     __ fcseld(as_FloatRegister($dst$$reg),
10085               as_FloatRegister($src2$$reg),
10086               as_FloatRegister($src1$$reg),
10087               cond);
10088   %}
10089 
10090   ins_pipe(fp_cond_reg_reg_d);
10091 %}
10092 
10093 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10094 %{
10095   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10096 
10097   ins_cost(INSN_COST * 3);
10098 
10099   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10100   ins_encode %{
10101     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10102     __ fcseld(as_FloatRegister($dst$$reg),
10103               as_FloatRegister($src2$$reg),
10104               as_FloatRegister($src1$$reg),
10105               cond);
10106   %}
10107 
10108   ins_pipe(fp_cond_reg_reg_d);
10109 %}
10110 
10111 // ============================================================================
10112 // Arithmetic Instructions
10113 //
10114 
10115 // Integer Addition
10116 
10117 // TODO
10118 // these currently employ operations which do not set CR and hence are
10119 // not flagged as killing CR but we would like to isolate the cases
10120 // where we want to set flags from those where we don&#39;t. need to work
10121 // out how to do that.
10122 
10123 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10124   match(Set dst (AddI src1 src2));
10125 
10126   ins_cost(INSN_COST);
10127   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10128 
10129   ins_encode %{
10130     __ addw(as_Register($dst$$reg),
10131             as_Register($src1$$reg),
10132             as_Register($src2$$reg));
10133   %}
10134 
10135   ins_pipe(ialu_reg_reg);
10136 %}
10137 
10138 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10139   match(Set dst (AddI src1 src2));
10140 
10141   ins_cost(INSN_COST);
10142   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10143 
10144   // use opcode to indicate that this is an add not a sub
10145   opcode(0x0);
10146 
10147   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10148 
10149   ins_pipe(ialu_reg_imm);
10150 %}
10151 
10152 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10153   match(Set dst (AddI (ConvL2I src1) src2));
10154 
10155   ins_cost(INSN_COST);
10156   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10157 
10158   // use opcode to indicate that this is an add not a sub
10159   opcode(0x0);
10160 
10161   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10162 
10163   ins_pipe(ialu_reg_imm);
10164 %}
10165 
10166 // Pointer Addition
10167 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10168   match(Set dst (AddP src1 src2));
10169 
10170   ins_cost(INSN_COST);
10171   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10172 
10173   ins_encode %{
10174     __ add(as_Register($dst$$reg),
10175            as_Register($src1$$reg),
10176            as_Register($src2$$reg));
10177   %}
10178 
10179   ins_pipe(ialu_reg_reg);
10180 %}
10181 
10182 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10183   match(Set dst (AddP src1 (ConvI2L src2)));
10184 
10185   ins_cost(1.9 * INSN_COST);
10186   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10187 
10188   ins_encode %{
10189     __ add(as_Register($dst$$reg),
10190            as_Register($src1$$reg),
10191            as_Register($src2$$reg), ext::sxtw);
10192   %}
10193 
10194   ins_pipe(ialu_reg_reg);
10195 %}
10196 
10197 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10198   match(Set dst (AddP src1 (LShiftL src2 scale)));
10199 
10200   ins_cost(1.9 * INSN_COST);
10201   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10202 
10203   ins_encode %{
10204     __ lea(as_Register($dst$$reg),
10205            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10206                    Address::lsl($scale$$constant)));
10207   %}
10208 
10209   ins_pipe(ialu_reg_reg_shift);
10210 %}
10211 
10212 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10213   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10214 
10215   ins_cost(1.9 * INSN_COST);
10216   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10217 
10218   ins_encode %{
10219     __ lea(as_Register($dst$$reg),
10220            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10221                    Address::sxtw($scale$$constant)));
10222   %}
10223 
10224   ins_pipe(ialu_reg_reg_shift);
10225 %}
10226 
10227 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10228   match(Set dst (LShiftL (ConvI2L src) scale));
10229 
10230   ins_cost(INSN_COST);
10231   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10232 
10233   ins_encode %{
10234     __ sbfiz(as_Register($dst$$reg),
10235           as_Register($src$$reg),
10236           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10237   %}
10238 
10239   ins_pipe(ialu_reg_shift);
10240 %}
10241 
10242 // Pointer Immediate Addition
10243 // n.b. this needs to be more expensive than using an indirect memory
10244 // operand
10245 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10246   match(Set dst (AddP src1 src2));
10247 
10248   ins_cost(INSN_COST);
10249   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10250 
10251   // use opcode to indicate that this is an add not a sub
10252   opcode(0x0);
10253 
10254   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10255 
10256   ins_pipe(ialu_reg_imm);
10257 %}
10258 
10259 // Long Addition
10260 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10261 
10262   match(Set dst (AddL src1 src2));
10263 
10264   ins_cost(INSN_COST);
10265   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10266 
10267   ins_encode %{
10268     __ add(as_Register($dst$$reg),
10269            as_Register($src1$$reg),
10270            as_Register($src2$$reg));
10271   %}
10272 
10273   ins_pipe(ialu_reg_reg);
10274 %}
10275 
10276 // No constant pool entries requiredLong Immediate Addition.
10277 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10278   match(Set dst (AddL src1 src2));
10279 
10280   ins_cost(INSN_COST);
10281   format %{ &quot;add $dst, $src1, $src2&quot; %}
10282 
10283   // use opcode to indicate that this is an add not a sub
10284   opcode(0x0);
10285 
10286   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10287 
10288   ins_pipe(ialu_reg_imm);
10289 %}
10290 
10291 // Integer Subtraction
10292 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10293   match(Set dst (SubI src1 src2));
10294 
10295   ins_cost(INSN_COST);
10296   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10297 
10298   ins_encode %{
10299     __ subw(as_Register($dst$$reg),
10300             as_Register($src1$$reg),
10301             as_Register($src2$$reg));
10302   %}
10303 
10304   ins_pipe(ialu_reg_reg);
10305 %}
10306 
10307 // Immediate Subtraction
10308 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10309   match(Set dst (SubI src1 src2));
10310 
10311   ins_cost(INSN_COST);
10312   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10313 
10314   // use opcode to indicate that this is a sub not an add
10315   opcode(0x1);
10316 
10317   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10318 
10319   ins_pipe(ialu_reg_imm);
10320 %}
10321 
10322 // Long Subtraction
10323 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10324 
10325   match(Set dst (SubL src1 src2));
10326 
10327   ins_cost(INSN_COST);
10328   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10329 
10330   ins_encode %{
10331     __ sub(as_Register($dst$$reg),
10332            as_Register($src1$$reg),
10333            as_Register($src2$$reg));
10334   %}
10335 
10336   ins_pipe(ialu_reg_reg);
10337 %}
10338 
10339 // No constant pool entries requiredLong Immediate Subtraction.
10340 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10341   match(Set dst (SubL src1 src2));
10342 
10343   ins_cost(INSN_COST);
10344   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10345 
10346   // use opcode to indicate that this is a sub not an add
10347   opcode(0x1);
10348 
10349   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10350 
10351   ins_pipe(ialu_reg_imm);
10352 %}
10353 
10354 // Integer Negation (special case for sub)
10355 
10356 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10357   match(Set dst (SubI zero src));
10358 
10359   ins_cost(INSN_COST);
10360   format %{ &quot;negw $dst, $src\t# int&quot; %}
10361 
10362   ins_encode %{
10363     __ negw(as_Register($dst$$reg),
10364             as_Register($src$$reg));
10365   %}
10366 
10367   ins_pipe(ialu_reg);
10368 %}
10369 
10370 // Long Negation
10371 
10372 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10373   match(Set dst (SubL zero src));
10374 
10375   ins_cost(INSN_COST);
10376   format %{ &quot;neg $dst, $src\t# long&quot; %}
10377 
10378   ins_encode %{
10379     __ neg(as_Register($dst$$reg),
10380            as_Register($src$$reg));
10381   %}
10382 
10383   ins_pipe(ialu_reg);
10384 %}
10385 
10386 // Integer Multiply
10387 
10388 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10389   match(Set dst (MulI src1 src2));
10390 
10391   ins_cost(INSN_COST * 3);
10392   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10393 
10394   ins_encode %{
10395     __ mulw(as_Register($dst$$reg),
10396             as_Register($src1$$reg),
10397             as_Register($src2$$reg));
10398   %}
10399 
10400   ins_pipe(imul_reg_reg);
10401 %}
10402 
10403 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10404   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10405 
10406   ins_cost(INSN_COST * 3);
10407   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10408 
10409   ins_encode %{
10410     __ smull(as_Register($dst$$reg),
10411              as_Register($src1$$reg),
10412              as_Register($src2$$reg));
10413   %}
10414 
10415   ins_pipe(imul_reg_reg);
10416 %}
10417 
10418 // Long Multiply
10419 
10420 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10421   match(Set dst (MulL src1 src2));
10422 
10423   ins_cost(INSN_COST * 5);
10424   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10425 
10426   ins_encode %{
10427     __ mul(as_Register($dst$$reg),
10428            as_Register($src1$$reg),
10429            as_Register($src2$$reg));
10430   %}
10431 
10432   ins_pipe(lmul_reg_reg);
10433 %}
10434 
10435 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10436 %{
10437   match(Set dst (MulHiL src1 src2));
10438 
10439   ins_cost(INSN_COST * 7);
10440   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10441 
10442   ins_encode %{
10443     __ smulh(as_Register($dst$$reg),
10444              as_Register($src1$$reg),
10445              as_Register($src2$$reg));
10446   %}
10447 
10448   ins_pipe(lmul_reg_reg);
10449 %}
10450 
10451 // Combined Integer Multiply &amp; Add/Sub
10452 
10453 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10454   match(Set dst (AddI src3 (MulI src1 src2)));
10455 
10456   ins_cost(INSN_COST * 3);
10457   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10458 
10459   ins_encode %{
10460     __ maddw(as_Register($dst$$reg),
10461              as_Register($src1$$reg),
10462              as_Register($src2$$reg),
10463              as_Register($src3$$reg));
10464   %}
10465 
10466   ins_pipe(imac_reg_reg);
10467 %}
10468 
10469 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10470   match(Set dst (SubI src3 (MulI src1 src2)));
10471 
10472   ins_cost(INSN_COST * 3);
10473   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10474 
10475   ins_encode %{
10476     __ msubw(as_Register($dst$$reg),
10477              as_Register($src1$$reg),
10478              as_Register($src2$$reg),
10479              as_Register($src3$$reg));
10480   %}
10481 
10482   ins_pipe(imac_reg_reg);
10483 %}
10484 
10485 // Combined Integer Multiply &amp; Neg
10486 
10487 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10488   match(Set dst (MulI (SubI zero src1) src2));
10489   match(Set dst (MulI src1 (SubI zero src2)));
10490 
10491   ins_cost(INSN_COST * 3);
10492   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10493 
10494   ins_encode %{
10495     __ mnegw(as_Register($dst$$reg),
10496              as_Register($src1$$reg),
10497              as_Register($src2$$reg));
10498   %}
10499 
10500   ins_pipe(imac_reg_reg);
10501 %}
10502 
10503 // Combined Long Multiply &amp; Add/Sub
10504 
10505 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10506   match(Set dst (AddL src3 (MulL src1 src2)));
10507 
10508   ins_cost(INSN_COST * 5);
10509   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10510 
10511   ins_encode %{
10512     __ madd(as_Register($dst$$reg),
10513             as_Register($src1$$reg),
10514             as_Register($src2$$reg),
10515             as_Register($src3$$reg));
10516   %}
10517 
10518   ins_pipe(lmac_reg_reg);
10519 %}
10520 
10521 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10522   match(Set dst (SubL src3 (MulL src1 src2)));
10523 
10524   ins_cost(INSN_COST * 5);
10525   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10526 
10527   ins_encode %{
10528     __ msub(as_Register($dst$$reg),
10529             as_Register($src1$$reg),
10530             as_Register($src2$$reg),
10531             as_Register($src3$$reg));
10532   %}
10533 
10534   ins_pipe(lmac_reg_reg);
10535 %}
10536 
10537 // Combined Long Multiply &amp; Neg
10538 
10539 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10540   match(Set dst (MulL (SubL zero src1) src2));
10541   match(Set dst (MulL src1 (SubL zero src2)));
10542 
10543   ins_cost(INSN_COST * 5);
10544   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10545 
10546   ins_encode %{
10547     __ mneg(as_Register($dst$$reg),
10548             as_Register($src1$$reg),
10549             as_Register($src2$$reg));
10550   %}
10551 
10552   ins_pipe(lmac_reg_reg);
10553 %}
10554 
10555 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10556 
10557 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10558   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10559 
10560   ins_cost(INSN_COST * 3);
10561   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10562 
10563   ins_encode %{
10564     __ smaddl(as_Register($dst$$reg),
10565               as_Register($src1$$reg),
10566               as_Register($src2$$reg),
10567               as_Register($src3$$reg));
10568   %}
10569 
10570   ins_pipe(imac_reg_reg);
10571 %}
10572 
10573 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10574   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10575 
10576   ins_cost(INSN_COST * 3);
10577   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10578 
10579   ins_encode %{
10580     __ smsubl(as_Register($dst$$reg),
10581               as_Register($src1$$reg),
10582               as_Register($src2$$reg),
10583               as_Register($src3$$reg));
10584   %}
10585 
10586   ins_pipe(imac_reg_reg);
10587 %}
10588 
10589 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10590   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10591   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10592 
10593   ins_cost(INSN_COST * 3);
10594   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10595 
10596   ins_encode %{
10597     __ smnegl(as_Register($dst$$reg),
10598               as_Register($src1$$reg),
10599               as_Register($src2$$reg));
10600   %}
10601 
10602   ins_pipe(imac_reg_reg);
10603 %}
10604 
10605 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10606 
10607 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10608   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10609 
10610   ins_cost(INSN_COST * 5);
10611   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10612             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10613 
10614   ins_encode %{
10615     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10616     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10617 
10618   ins_pipe(imac_reg_reg);
10619 %}
10620 
10621 // Integer Divide
10622 
10623 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10624   match(Set dst (DivI src1 src2));
10625 
10626   ins_cost(INSN_COST * 19);
10627   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10628 
10629   ins_encode(aarch64_enc_divw(dst, src1, src2));
10630   ins_pipe(idiv_reg_reg);
10631 %}
10632 
10633 // Long Divide
10634 
10635 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10636   match(Set dst (DivL src1 src2));
10637 
10638   ins_cost(INSN_COST * 35);
10639   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10640 
10641   ins_encode(aarch64_enc_div(dst, src1, src2));
10642   ins_pipe(ldiv_reg_reg);
10643 %}
10644 
10645 // Integer Remainder
10646 
10647 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10648   match(Set dst (ModI src1 src2));
10649 
10650   ins_cost(INSN_COST * 22);
10651   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10652             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10653 
10654   ins_encode(aarch64_enc_modw(dst, src1, src2));
10655   ins_pipe(idiv_reg_reg);
10656 %}
10657 
10658 // Long Remainder
10659 
10660 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10661   match(Set dst (ModL src1 src2));
10662 
10663   ins_cost(INSN_COST * 38);
10664   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10665             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10666 
10667   ins_encode(aarch64_enc_mod(dst, src1, src2));
10668   ins_pipe(ldiv_reg_reg);
10669 %}
10670 
10671 // Integer Shifts
10672 
10673 // Shift Left Register
10674 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10675   match(Set dst (LShiftI src1 src2));
10676 
10677   ins_cost(INSN_COST * 2);
10678   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10679 
10680   ins_encode %{
10681     __ lslvw(as_Register($dst$$reg),
10682              as_Register($src1$$reg),
10683              as_Register($src2$$reg));
10684   %}
10685 
10686   ins_pipe(ialu_reg_reg_vshift);
10687 %}
10688 
10689 // Shift Left Immediate
10690 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10691   match(Set dst (LShiftI src1 src2));
10692 
10693   ins_cost(INSN_COST);
10694   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10695 
10696   ins_encode %{
10697     __ lslw(as_Register($dst$$reg),
10698             as_Register($src1$$reg),
10699             $src2$$constant &amp; 0x1f);
10700   %}
10701 
10702   ins_pipe(ialu_reg_shift);
10703 %}
10704 
10705 // Shift Right Logical Register
10706 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10707   match(Set dst (URShiftI src1 src2));
10708 
10709   ins_cost(INSN_COST * 2);
10710   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10711 
10712   ins_encode %{
10713     __ lsrvw(as_Register($dst$$reg),
10714              as_Register($src1$$reg),
10715              as_Register($src2$$reg));
10716   %}
10717 
10718   ins_pipe(ialu_reg_reg_vshift);
10719 %}
10720 
10721 // Shift Right Logical Immediate
10722 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10723   match(Set dst (URShiftI src1 src2));
10724 
10725   ins_cost(INSN_COST);
10726   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10727 
10728   ins_encode %{
10729     __ lsrw(as_Register($dst$$reg),
10730             as_Register($src1$$reg),
10731             $src2$$constant &amp; 0x1f);
10732   %}
10733 
10734   ins_pipe(ialu_reg_shift);
10735 %}
10736 
10737 // Shift Right Arithmetic Register
10738 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10739   match(Set dst (RShiftI src1 src2));
10740 
10741   ins_cost(INSN_COST * 2);
10742   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10743 
10744   ins_encode %{
10745     __ asrvw(as_Register($dst$$reg),
10746              as_Register($src1$$reg),
10747              as_Register($src2$$reg));
10748   %}
10749 
10750   ins_pipe(ialu_reg_reg_vshift);
10751 %}
10752 
10753 // Shift Right Arithmetic Immediate
10754 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10755   match(Set dst (RShiftI src1 src2));
10756 
10757   ins_cost(INSN_COST);
10758   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10759 
10760   ins_encode %{
10761     __ asrw(as_Register($dst$$reg),
10762             as_Register($src1$$reg),
10763             $src2$$constant &amp; 0x1f);
10764   %}
10765 
10766   ins_pipe(ialu_reg_shift);
10767 %}
10768 
10769 // Combined Int Mask and Right Shift (using UBFM)
10770 // TODO
10771 
10772 // Long Shifts
10773 
10774 // Shift Left Register
10775 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10776   match(Set dst (LShiftL src1 src2));
10777 
10778   ins_cost(INSN_COST * 2);
10779   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10780 
10781   ins_encode %{
10782     __ lslv(as_Register($dst$$reg),
10783             as_Register($src1$$reg),
10784             as_Register($src2$$reg));
10785   %}
10786 
10787   ins_pipe(ialu_reg_reg_vshift);
10788 %}
10789 
10790 // Shift Left Immediate
10791 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10792   match(Set dst (LShiftL src1 src2));
10793 
10794   ins_cost(INSN_COST);
10795   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10796 
10797   ins_encode %{
10798     __ lsl(as_Register($dst$$reg),
10799             as_Register($src1$$reg),
10800             $src2$$constant &amp; 0x3f);
10801   %}
10802 
10803   ins_pipe(ialu_reg_shift);
10804 %}
10805 
10806 // Shift Right Logical Register
10807 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10808   match(Set dst (URShiftL src1 src2));
10809 
10810   ins_cost(INSN_COST * 2);
10811   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10812 
10813   ins_encode %{
10814     __ lsrv(as_Register($dst$$reg),
10815             as_Register($src1$$reg),
10816             as_Register($src2$$reg));
10817   %}
10818 
10819   ins_pipe(ialu_reg_reg_vshift);
10820 %}
10821 
10822 // Shift Right Logical Immediate
10823 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10824   match(Set dst (URShiftL src1 src2));
10825 
10826   ins_cost(INSN_COST);
10827   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10828 
10829   ins_encode %{
10830     __ lsr(as_Register($dst$$reg),
10831            as_Register($src1$$reg),
10832            $src2$$constant &amp; 0x3f);
10833   %}
10834 
10835   ins_pipe(ialu_reg_shift);
10836 %}
10837 
10838 // A special-case pattern for card table stores.
10839 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10840   match(Set dst (URShiftL (CastP2X src1) src2));
10841 
10842   ins_cost(INSN_COST);
10843   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10844 
10845   ins_encode %{
10846     __ lsr(as_Register($dst$$reg),
10847            as_Register($src1$$reg),
10848            $src2$$constant &amp; 0x3f);
10849   %}
10850 
10851   ins_pipe(ialu_reg_shift);
10852 %}
10853 
10854 // Shift Right Arithmetic Register
10855 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10856   match(Set dst (RShiftL src1 src2));
10857 
10858   ins_cost(INSN_COST * 2);
10859   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10860 
10861   ins_encode %{
10862     __ asrv(as_Register($dst$$reg),
10863             as_Register($src1$$reg),
10864             as_Register($src2$$reg));
10865   %}
10866 
10867   ins_pipe(ialu_reg_reg_vshift);
10868 %}
10869 
10870 // Shift Right Arithmetic Immediate
10871 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10872   match(Set dst (RShiftL src1 src2));
10873 
10874   ins_cost(INSN_COST);
10875   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10876 
10877   ins_encode %{
10878     __ asr(as_Register($dst$$reg),
10879            as_Register($src1$$reg),
10880            $src2$$constant &amp; 0x3f);
10881   %}
10882 
10883   ins_pipe(ialu_reg_shift);
10884 %}
10885 
10886 // BEGIN This section of the file is automatically generated. Do not edit --------------
10887 
10888 instruct regL_not_reg(iRegLNoSp dst,
10889                          iRegL src1, immL_M1 m1,
10890                          rFlagsReg cr) %{
10891   match(Set dst (XorL src1 m1));
10892   ins_cost(INSN_COST);
10893   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10894 
10895   ins_encode %{
10896     __ eon(as_Register($dst$$reg),
10897               as_Register($src1$$reg),
10898               zr,
10899               Assembler::LSL, 0);
10900   %}
10901 
10902   ins_pipe(ialu_reg);
10903 %}
10904 instruct regI_not_reg(iRegINoSp dst,
10905                          iRegIorL2I src1, immI_M1 m1,
10906                          rFlagsReg cr) %{
10907   match(Set dst (XorI src1 m1));
10908   ins_cost(INSN_COST);
10909   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10910 
10911   ins_encode %{
10912     __ eonw(as_Register($dst$$reg),
10913               as_Register($src1$$reg),
10914               zr,
10915               Assembler::LSL, 0);
10916   %}
10917 
10918   ins_pipe(ialu_reg);
10919 %}
10920 
10921 instruct AndI_reg_not_reg(iRegINoSp dst,
10922                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10923                          rFlagsReg cr) %{
10924   match(Set dst (AndI src1 (XorI src2 m1)));
10925   ins_cost(INSN_COST);
10926   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10927 
10928   ins_encode %{
10929     __ bicw(as_Register($dst$$reg),
10930               as_Register($src1$$reg),
10931               as_Register($src2$$reg),
10932               Assembler::LSL, 0);
10933   %}
10934 
10935   ins_pipe(ialu_reg_reg);
10936 %}
10937 
10938 instruct AndL_reg_not_reg(iRegLNoSp dst,
10939                          iRegL src1, iRegL src2, immL_M1 m1,
10940                          rFlagsReg cr) %{
10941   match(Set dst (AndL src1 (XorL src2 m1)));
10942   ins_cost(INSN_COST);
10943   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10944 
10945   ins_encode %{
10946     __ bic(as_Register($dst$$reg),
10947               as_Register($src1$$reg),
10948               as_Register($src2$$reg),
10949               Assembler::LSL, 0);
10950   %}
10951 
10952   ins_pipe(ialu_reg_reg);
10953 %}
10954 
10955 instruct OrI_reg_not_reg(iRegINoSp dst,
10956                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10957                          rFlagsReg cr) %{
10958   match(Set dst (OrI src1 (XorI src2 m1)));
10959   ins_cost(INSN_COST);
10960   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10961 
10962   ins_encode %{
10963     __ ornw(as_Register($dst$$reg),
10964               as_Register($src1$$reg),
10965               as_Register($src2$$reg),
10966               Assembler::LSL, 0);
10967   %}
10968 
10969   ins_pipe(ialu_reg_reg);
10970 %}
10971 
10972 instruct OrL_reg_not_reg(iRegLNoSp dst,
10973                          iRegL src1, iRegL src2, immL_M1 m1,
10974                          rFlagsReg cr) %{
10975   match(Set dst (OrL src1 (XorL src2 m1)));
10976   ins_cost(INSN_COST);
10977   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10978 
10979   ins_encode %{
10980     __ orn(as_Register($dst$$reg),
10981               as_Register($src1$$reg),
10982               as_Register($src2$$reg),
10983               Assembler::LSL, 0);
10984   %}
10985 
10986   ins_pipe(ialu_reg_reg);
10987 %}
10988 
10989 instruct XorI_reg_not_reg(iRegINoSp dst,
10990                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10991                          rFlagsReg cr) %{
10992   match(Set dst (XorI m1 (XorI src2 src1)));
10993   ins_cost(INSN_COST);
10994   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10995 
10996   ins_encode %{
10997     __ eonw(as_Register($dst$$reg),
10998               as_Register($src1$$reg),
10999               as_Register($src2$$reg),
11000               Assembler::LSL, 0);
11001   %}
11002 
11003   ins_pipe(ialu_reg_reg);
11004 %}
11005 
11006 instruct XorL_reg_not_reg(iRegLNoSp dst,
11007                          iRegL src1, iRegL src2, immL_M1 m1,
11008                          rFlagsReg cr) %{
11009   match(Set dst (XorL m1 (XorL src2 src1)));
11010   ins_cost(INSN_COST);
11011   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11012 
11013   ins_encode %{
11014     __ eon(as_Register($dst$$reg),
11015               as_Register($src1$$reg),
11016               as_Register($src2$$reg),
11017               Assembler::LSL, 0);
11018   %}
11019 
11020   ins_pipe(ialu_reg_reg);
11021 %}
11022 
11023 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11024                          iRegIorL2I src1, iRegIorL2I src2,
11025                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11026   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11027   ins_cost(1.9 * INSN_COST);
11028   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11029 
11030   ins_encode %{
11031     __ bicw(as_Register($dst$$reg),
11032               as_Register($src1$$reg),
11033               as_Register($src2$$reg),
11034               Assembler::LSR,
11035               $src3$$constant &amp; 0x1f);
11036   %}
11037 
11038   ins_pipe(ialu_reg_reg_shift);
11039 %}
11040 
11041 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11042                          iRegL src1, iRegL src2,
11043                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11044   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11045   ins_cost(1.9 * INSN_COST);
11046   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11047 
11048   ins_encode %{
11049     __ bic(as_Register($dst$$reg),
11050               as_Register($src1$$reg),
11051               as_Register($src2$$reg),
11052               Assembler::LSR,
11053               $src3$$constant &amp; 0x3f);
11054   %}
11055 
11056   ins_pipe(ialu_reg_reg_shift);
11057 %}
11058 
11059 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11060                          iRegIorL2I src1, iRegIorL2I src2,
11061                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11062   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11063   ins_cost(1.9 * INSN_COST);
11064   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11065 
11066   ins_encode %{
11067     __ bicw(as_Register($dst$$reg),
11068               as_Register($src1$$reg),
11069               as_Register($src2$$reg),
11070               Assembler::ASR,
11071               $src3$$constant &amp; 0x1f);
11072   %}
11073 
11074   ins_pipe(ialu_reg_reg_shift);
11075 %}
11076 
11077 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11078                          iRegL src1, iRegL src2,
11079                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11080   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11081   ins_cost(1.9 * INSN_COST);
11082   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11083 
11084   ins_encode %{
11085     __ bic(as_Register($dst$$reg),
11086               as_Register($src1$$reg),
11087               as_Register($src2$$reg),
11088               Assembler::ASR,
11089               $src3$$constant &amp; 0x3f);
11090   %}
11091 
11092   ins_pipe(ialu_reg_reg_shift);
11093 %}
11094 
11095 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11096                          iRegIorL2I src1, iRegIorL2I src2,
11097                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11098   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11099   ins_cost(1.9 * INSN_COST);
11100   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11101 
11102   ins_encode %{
11103     __ bicw(as_Register($dst$$reg),
11104               as_Register($src1$$reg),
11105               as_Register($src2$$reg),
11106               Assembler::LSL,
11107               $src3$$constant &amp; 0x1f);
11108   %}
11109 
11110   ins_pipe(ialu_reg_reg_shift);
11111 %}
11112 
11113 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11114                          iRegL src1, iRegL src2,
11115                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11116   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11117   ins_cost(1.9 * INSN_COST);
11118   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11119 
11120   ins_encode %{
11121     __ bic(as_Register($dst$$reg),
11122               as_Register($src1$$reg),
11123               as_Register($src2$$reg),
11124               Assembler::LSL,
11125               $src3$$constant &amp; 0x3f);
11126   %}
11127 
11128   ins_pipe(ialu_reg_reg_shift);
11129 %}
11130 
11131 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11132                          iRegIorL2I src1, iRegIorL2I src2,
11133                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11134   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11135   ins_cost(1.9 * INSN_COST);
11136   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11137 
11138   ins_encode %{
11139     __ eonw(as_Register($dst$$reg),
11140               as_Register($src1$$reg),
11141               as_Register($src2$$reg),
11142               Assembler::LSR,
11143               $src3$$constant &amp; 0x1f);
11144   %}
11145 
11146   ins_pipe(ialu_reg_reg_shift);
11147 %}
11148 
11149 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11150                          iRegL src1, iRegL src2,
11151                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11152   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11153   ins_cost(1.9 * INSN_COST);
11154   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11155 
11156   ins_encode %{
11157     __ eon(as_Register($dst$$reg),
11158               as_Register($src1$$reg),
11159               as_Register($src2$$reg),
11160               Assembler::LSR,
11161               $src3$$constant &amp; 0x3f);
11162   %}
11163 
11164   ins_pipe(ialu_reg_reg_shift);
11165 %}
11166 
11167 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11168                          iRegIorL2I src1, iRegIorL2I src2,
11169                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11170   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11171   ins_cost(1.9 * INSN_COST);
11172   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11173 
11174   ins_encode %{
11175     __ eonw(as_Register($dst$$reg),
11176               as_Register($src1$$reg),
11177               as_Register($src2$$reg),
11178               Assembler::ASR,
11179               $src3$$constant &amp; 0x1f);
11180   %}
11181 
11182   ins_pipe(ialu_reg_reg_shift);
11183 %}
11184 
11185 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11186                          iRegL src1, iRegL src2,
11187                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11188   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11189   ins_cost(1.9 * INSN_COST);
11190   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11191 
11192   ins_encode %{
11193     __ eon(as_Register($dst$$reg),
11194               as_Register($src1$$reg),
11195               as_Register($src2$$reg),
11196               Assembler::ASR,
11197               $src3$$constant &amp; 0x3f);
11198   %}
11199 
11200   ins_pipe(ialu_reg_reg_shift);
11201 %}
11202 
11203 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11204                          iRegIorL2I src1, iRegIorL2I src2,
11205                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11206   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11207   ins_cost(1.9 * INSN_COST);
11208   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11209 
11210   ins_encode %{
11211     __ eonw(as_Register($dst$$reg),
11212               as_Register($src1$$reg),
11213               as_Register($src2$$reg),
11214               Assembler::LSL,
11215               $src3$$constant &amp; 0x1f);
11216   %}
11217 
11218   ins_pipe(ialu_reg_reg_shift);
11219 %}
11220 
11221 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11222                          iRegL src1, iRegL src2,
11223                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11224   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11225   ins_cost(1.9 * INSN_COST);
11226   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11227 
11228   ins_encode %{
11229     __ eon(as_Register($dst$$reg),
11230               as_Register($src1$$reg),
11231               as_Register($src2$$reg),
11232               Assembler::LSL,
11233               $src3$$constant &amp; 0x3f);
11234   %}
11235 
11236   ins_pipe(ialu_reg_reg_shift);
11237 %}
11238 
11239 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11240                          iRegIorL2I src1, iRegIorL2I src2,
11241                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11242   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11243   ins_cost(1.9 * INSN_COST);
11244   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11245 
11246   ins_encode %{
11247     __ ornw(as_Register($dst$$reg),
11248               as_Register($src1$$reg),
11249               as_Register($src2$$reg),
11250               Assembler::LSR,
11251               $src3$$constant &amp; 0x1f);
11252   %}
11253 
11254   ins_pipe(ialu_reg_reg_shift);
11255 %}
11256 
11257 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11258                          iRegL src1, iRegL src2,
11259                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11260   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11261   ins_cost(1.9 * INSN_COST);
11262   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11263 
11264   ins_encode %{
11265     __ orn(as_Register($dst$$reg),
11266               as_Register($src1$$reg),
11267               as_Register($src2$$reg),
11268               Assembler::LSR,
11269               $src3$$constant &amp; 0x3f);
11270   %}
11271 
11272   ins_pipe(ialu_reg_reg_shift);
11273 %}
11274 
11275 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11276                          iRegIorL2I src1, iRegIorL2I src2,
11277                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11278   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11279   ins_cost(1.9 * INSN_COST);
11280   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11281 
11282   ins_encode %{
11283     __ ornw(as_Register($dst$$reg),
11284               as_Register($src1$$reg),
11285               as_Register($src2$$reg),
11286               Assembler::ASR,
11287               $src3$$constant &amp; 0x1f);
11288   %}
11289 
11290   ins_pipe(ialu_reg_reg_shift);
11291 %}
11292 
11293 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11294                          iRegL src1, iRegL src2,
11295                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11296   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11297   ins_cost(1.9 * INSN_COST);
11298   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11299 
11300   ins_encode %{
11301     __ orn(as_Register($dst$$reg),
11302               as_Register($src1$$reg),
11303               as_Register($src2$$reg),
11304               Assembler::ASR,
11305               $src3$$constant &amp; 0x3f);
11306   %}
11307 
11308   ins_pipe(ialu_reg_reg_shift);
11309 %}
11310 
11311 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11312                          iRegIorL2I src1, iRegIorL2I src2,
11313                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11314   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11315   ins_cost(1.9 * INSN_COST);
11316   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11317 
11318   ins_encode %{
11319     __ ornw(as_Register($dst$$reg),
11320               as_Register($src1$$reg),
11321               as_Register($src2$$reg),
11322               Assembler::LSL,
11323               $src3$$constant &amp; 0x1f);
11324   %}
11325 
11326   ins_pipe(ialu_reg_reg_shift);
11327 %}
11328 
11329 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11330                          iRegL src1, iRegL src2,
11331                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11332   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11333   ins_cost(1.9 * INSN_COST);
11334   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11335 
11336   ins_encode %{
11337     __ orn(as_Register($dst$$reg),
11338               as_Register($src1$$reg),
11339               as_Register($src2$$reg),
11340               Assembler::LSL,
11341               $src3$$constant &amp; 0x3f);
11342   %}
11343 
11344   ins_pipe(ialu_reg_reg_shift);
11345 %}
11346 
11347 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11348                          iRegIorL2I src1, iRegIorL2I src2,
11349                          immI src3, rFlagsReg cr) %{
11350   match(Set dst (AndI src1 (URShiftI src2 src3)));
11351 
11352   ins_cost(1.9 * INSN_COST);
11353   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11354 
11355   ins_encode %{
11356     __ andw(as_Register($dst$$reg),
11357               as_Register($src1$$reg),
11358               as_Register($src2$$reg),
11359               Assembler::LSR,
11360               $src3$$constant &amp; 0x1f);
11361   %}
11362 
11363   ins_pipe(ialu_reg_reg_shift);
11364 %}
11365 
11366 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11367                          iRegL src1, iRegL src2,
11368                          immI src3, rFlagsReg cr) %{
11369   match(Set dst (AndL src1 (URShiftL src2 src3)));
11370 
11371   ins_cost(1.9 * INSN_COST);
11372   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11373 
11374   ins_encode %{
11375     __ andr(as_Register($dst$$reg),
11376               as_Register($src1$$reg),
11377               as_Register($src2$$reg),
11378               Assembler::LSR,
11379               $src3$$constant &amp; 0x3f);
11380   %}
11381 
11382   ins_pipe(ialu_reg_reg_shift);
11383 %}
11384 
11385 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11386                          iRegIorL2I src1, iRegIorL2I src2,
11387                          immI src3, rFlagsReg cr) %{
11388   match(Set dst (AndI src1 (RShiftI src2 src3)));
11389 
11390   ins_cost(1.9 * INSN_COST);
11391   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11392 
11393   ins_encode %{
11394     __ andw(as_Register($dst$$reg),
11395               as_Register($src1$$reg),
11396               as_Register($src2$$reg),
11397               Assembler::ASR,
11398               $src3$$constant &amp; 0x1f);
11399   %}
11400 
11401   ins_pipe(ialu_reg_reg_shift);
11402 %}
11403 
11404 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11405                          iRegL src1, iRegL src2,
11406                          immI src3, rFlagsReg cr) %{
11407   match(Set dst (AndL src1 (RShiftL src2 src3)));
11408 
11409   ins_cost(1.9 * INSN_COST);
11410   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11411 
11412   ins_encode %{
11413     __ andr(as_Register($dst$$reg),
11414               as_Register($src1$$reg),
11415               as_Register($src2$$reg),
11416               Assembler::ASR,
11417               $src3$$constant &amp; 0x3f);
11418   %}
11419 
11420   ins_pipe(ialu_reg_reg_shift);
11421 %}
11422 
11423 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11424                          iRegIorL2I src1, iRegIorL2I src2,
11425                          immI src3, rFlagsReg cr) %{
11426   match(Set dst (AndI src1 (LShiftI src2 src3)));
11427 
11428   ins_cost(1.9 * INSN_COST);
11429   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11430 
11431   ins_encode %{
11432     __ andw(as_Register($dst$$reg),
11433               as_Register($src1$$reg),
11434               as_Register($src2$$reg),
11435               Assembler::LSL,
11436               $src3$$constant &amp; 0x1f);
11437   %}
11438 
11439   ins_pipe(ialu_reg_reg_shift);
11440 %}
11441 
11442 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11443                          iRegL src1, iRegL src2,
11444                          immI src3, rFlagsReg cr) %{
11445   match(Set dst (AndL src1 (LShiftL src2 src3)));
11446 
11447   ins_cost(1.9 * INSN_COST);
11448   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11449 
11450   ins_encode %{
11451     __ andr(as_Register($dst$$reg),
11452               as_Register($src1$$reg),
11453               as_Register($src2$$reg),
11454               Assembler::LSL,
11455               $src3$$constant &amp; 0x3f);
11456   %}
11457 
11458   ins_pipe(ialu_reg_reg_shift);
11459 %}
11460 
11461 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11462                          iRegIorL2I src1, iRegIorL2I src2,
11463                          immI src3, rFlagsReg cr) %{
11464   match(Set dst (XorI src1 (URShiftI src2 src3)));
11465 
11466   ins_cost(1.9 * INSN_COST);
11467   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11468 
11469   ins_encode %{
11470     __ eorw(as_Register($dst$$reg),
11471               as_Register($src1$$reg),
11472               as_Register($src2$$reg),
11473               Assembler::LSR,
11474               $src3$$constant &amp; 0x1f);
11475   %}
11476 
11477   ins_pipe(ialu_reg_reg_shift);
11478 %}
11479 
11480 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11481                          iRegL src1, iRegL src2,
11482                          immI src3, rFlagsReg cr) %{
11483   match(Set dst (XorL src1 (URShiftL src2 src3)));
11484 
11485   ins_cost(1.9 * INSN_COST);
11486   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11487 
11488   ins_encode %{
11489     __ eor(as_Register($dst$$reg),
11490               as_Register($src1$$reg),
11491               as_Register($src2$$reg),
11492               Assembler::LSR,
11493               $src3$$constant &amp; 0x3f);
11494   %}
11495 
11496   ins_pipe(ialu_reg_reg_shift);
11497 %}
11498 
11499 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11500                          iRegIorL2I src1, iRegIorL2I src2,
11501                          immI src3, rFlagsReg cr) %{
11502   match(Set dst (XorI src1 (RShiftI src2 src3)));
11503 
11504   ins_cost(1.9 * INSN_COST);
11505   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11506 
11507   ins_encode %{
11508     __ eorw(as_Register($dst$$reg),
11509               as_Register($src1$$reg),
11510               as_Register($src2$$reg),
11511               Assembler::ASR,
11512               $src3$$constant &amp; 0x1f);
11513   %}
11514 
11515   ins_pipe(ialu_reg_reg_shift);
11516 %}
11517 
11518 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11519                          iRegL src1, iRegL src2,
11520                          immI src3, rFlagsReg cr) %{
11521   match(Set dst (XorL src1 (RShiftL src2 src3)));
11522 
11523   ins_cost(1.9 * INSN_COST);
11524   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11525 
11526   ins_encode %{
11527     __ eor(as_Register($dst$$reg),
11528               as_Register($src1$$reg),
11529               as_Register($src2$$reg),
11530               Assembler::ASR,
11531               $src3$$constant &amp; 0x3f);
11532   %}
11533 
11534   ins_pipe(ialu_reg_reg_shift);
11535 %}
11536 
11537 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11538                          iRegIorL2I src1, iRegIorL2I src2,
11539                          immI src3, rFlagsReg cr) %{
11540   match(Set dst (XorI src1 (LShiftI src2 src3)));
11541 
11542   ins_cost(1.9 * INSN_COST);
11543   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11544 
11545   ins_encode %{
11546     __ eorw(as_Register($dst$$reg),
11547               as_Register($src1$$reg),
11548               as_Register($src2$$reg),
11549               Assembler::LSL,
11550               $src3$$constant &amp; 0x1f);
11551   %}
11552 
11553   ins_pipe(ialu_reg_reg_shift);
11554 %}
11555 
11556 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11557                          iRegL src1, iRegL src2,
11558                          immI src3, rFlagsReg cr) %{
11559   match(Set dst (XorL src1 (LShiftL src2 src3)));
11560 
11561   ins_cost(1.9 * INSN_COST);
11562   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11563 
11564   ins_encode %{
11565     __ eor(as_Register($dst$$reg),
11566               as_Register($src1$$reg),
11567               as_Register($src2$$reg),
11568               Assembler::LSL,
11569               $src3$$constant &amp; 0x3f);
11570   %}
11571 
11572   ins_pipe(ialu_reg_reg_shift);
11573 %}
11574 
11575 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11576                          iRegIorL2I src1, iRegIorL2I src2,
11577                          immI src3, rFlagsReg cr) %{
11578   match(Set dst (OrI src1 (URShiftI src2 src3)));
11579 
11580   ins_cost(1.9 * INSN_COST);
11581   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11582 
11583   ins_encode %{
11584     __ orrw(as_Register($dst$$reg),
11585               as_Register($src1$$reg),
11586               as_Register($src2$$reg),
11587               Assembler::LSR,
11588               $src3$$constant &amp; 0x1f);
11589   %}
11590 
11591   ins_pipe(ialu_reg_reg_shift);
11592 %}
11593 
11594 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11595                          iRegL src1, iRegL src2,
11596                          immI src3, rFlagsReg cr) %{
11597   match(Set dst (OrL src1 (URShiftL src2 src3)));
11598 
11599   ins_cost(1.9 * INSN_COST);
11600   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11601 
11602   ins_encode %{
11603     __ orr(as_Register($dst$$reg),
11604               as_Register($src1$$reg),
11605               as_Register($src2$$reg),
11606               Assembler::LSR,
11607               $src3$$constant &amp; 0x3f);
11608   %}
11609 
11610   ins_pipe(ialu_reg_reg_shift);
11611 %}
11612 
11613 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11614                          iRegIorL2I src1, iRegIorL2I src2,
11615                          immI src3, rFlagsReg cr) %{
11616   match(Set dst (OrI src1 (RShiftI src2 src3)));
11617 
11618   ins_cost(1.9 * INSN_COST);
11619   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11620 
11621   ins_encode %{
11622     __ orrw(as_Register($dst$$reg),
11623               as_Register($src1$$reg),
11624               as_Register($src2$$reg),
11625               Assembler::ASR,
11626               $src3$$constant &amp; 0x1f);
11627   %}
11628 
11629   ins_pipe(ialu_reg_reg_shift);
11630 %}
11631 
11632 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11633                          iRegL src1, iRegL src2,
11634                          immI src3, rFlagsReg cr) %{
11635   match(Set dst (OrL src1 (RShiftL src2 src3)));
11636 
11637   ins_cost(1.9 * INSN_COST);
11638   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11639 
11640   ins_encode %{
11641     __ orr(as_Register($dst$$reg),
11642               as_Register($src1$$reg),
11643               as_Register($src2$$reg),
11644               Assembler::ASR,
11645               $src3$$constant &amp; 0x3f);
11646   %}
11647 
11648   ins_pipe(ialu_reg_reg_shift);
11649 %}
11650 
11651 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11652                          iRegIorL2I src1, iRegIorL2I src2,
11653                          immI src3, rFlagsReg cr) %{
11654   match(Set dst (OrI src1 (LShiftI src2 src3)));
11655 
11656   ins_cost(1.9 * INSN_COST);
11657   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11658 
11659   ins_encode %{
11660     __ orrw(as_Register($dst$$reg),
11661               as_Register($src1$$reg),
11662               as_Register($src2$$reg),
11663               Assembler::LSL,
11664               $src3$$constant &amp; 0x1f);
11665   %}
11666 
11667   ins_pipe(ialu_reg_reg_shift);
11668 %}
11669 
11670 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11671                          iRegL src1, iRegL src2,
11672                          immI src3, rFlagsReg cr) %{
11673   match(Set dst (OrL src1 (LShiftL src2 src3)));
11674 
11675   ins_cost(1.9 * INSN_COST);
11676   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11677 
11678   ins_encode %{
11679     __ orr(as_Register($dst$$reg),
11680               as_Register($src1$$reg),
11681               as_Register($src2$$reg),
11682               Assembler::LSL,
11683               $src3$$constant &amp; 0x3f);
11684   %}
11685 
11686   ins_pipe(ialu_reg_reg_shift);
11687 %}
11688 
11689 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11690                          iRegIorL2I src1, iRegIorL2I src2,
11691                          immI src3, rFlagsReg cr) %{
11692   match(Set dst (AddI src1 (URShiftI src2 src3)));
11693 
11694   ins_cost(1.9 * INSN_COST);
11695   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11696 
11697   ins_encode %{
11698     __ addw(as_Register($dst$$reg),
11699               as_Register($src1$$reg),
11700               as_Register($src2$$reg),
11701               Assembler::LSR,
11702               $src3$$constant &amp; 0x1f);
11703   %}
11704 
11705   ins_pipe(ialu_reg_reg_shift);
11706 %}
11707 
11708 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11709                          iRegL src1, iRegL src2,
11710                          immI src3, rFlagsReg cr) %{
11711   match(Set dst (AddL src1 (URShiftL src2 src3)));
11712 
11713   ins_cost(1.9 * INSN_COST);
11714   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11715 
11716   ins_encode %{
11717     __ add(as_Register($dst$$reg),
11718               as_Register($src1$$reg),
11719               as_Register($src2$$reg),
11720               Assembler::LSR,
11721               $src3$$constant &amp; 0x3f);
11722   %}
11723 
11724   ins_pipe(ialu_reg_reg_shift);
11725 %}
11726 
11727 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11728                          iRegIorL2I src1, iRegIorL2I src2,
11729                          immI src3, rFlagsReg cr) %{
11730   match(Set dst (AddI src1 (RShiftI src2 src3)));
11731 
11732   ins_cost(1.9 * INSN_COST);
11733   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11734 
11735   ins_encode %{
11736     __ addw(as_Register($dst$$reg),
11737               as_Register($src1$$reg),
11738               as_Register($src2$$reg),
11739               Assembler::ASR,
11740               $src3$$constant &amp; 0x1f);
11741   %}
11742 
11743   ins_pipe(ialu_reg_reg_shift);
11744 %}
11745 
11746 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11747                          iRegL src1, iRegL src2,
11748                          immI src3, rFlagsReg cr) %{
11749   match(Set dst (AddL src1 (RShiftL src2 src3)));
11750 
11751   ins_cost(1.9 * INSN_COST);
11752   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11753 
11754   ins_encode %{
11755     __ add(as_Register($dst$$reg),
11756               as_Register($src1$$reg),
11757               as_Register($src2$$reg),
11758               Assembler::ASR,
11759               $src3$$constant &amp; 0x3f);
11760   %}
11761 
11762   ins_pipe(ialu_reg_reg_shift);
11763 %}
11764 
11765 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11766                          iRegIorL2I src1, iRegIorL2I src2,
11767                          immI src3, rFlagsReg cr) %{
11768   match(Set dst (AddI src1 (LShiftI src2 src3)));
11769 
11770   ins_cost(1.9 * INSN_COST);
11771   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11772 
11773   ins_encode %{
11774     __ addw(as_Register($dst$$reg),
11775               as_Register($src1$$reg),
11776               as_Register($src2$$reg),
11777               Assembler::LSL,
11778               $src3$$constant &amp; 0x1f);
11779   %}
11780 
11781   ins_pipe(ialu_reg_reg_shift);
11782 %}
11783 
11784 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11785                          iRegL src1, iRegL src2,
11786                          immI src3, rFlagsReg cr) %{
11787   match(Set dst (AddL src1 (LShiftL src2 src3)));
11788 
11789   ins_cost(1.9 * INSN_COST);
11790   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11791 
11792   ins_encode %{
11793     __ add(as_Register($dst$$reg),
11794               as_Register($src1$$reg),
11795               as_Register($src2$$reg),
11796               Assembler::LSL,
11797               $src3$$constant &amp; 0x3f);
11798   %}
11799 
11800   ins_pipe(ialu_reg_reg_shift);
11801 %}
11802 
11803 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11804                          iRegIorL2I src1, iRegIorL2I src2,
11805                          immI src3, rFlagsReg cr) %{
11806   match(Set dst (SubI src1 (URShiftI src2 src3)));
11807 
11808   ins_cost(1.9 * INSN_COST);
11809   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11810 
11811   ins_encode %{
11812     __ subw(as_Register($dst$$reg),
11813               as_Register($src1$$reg),
11814               as_Register($src2$$reg),
11815               Assembler::LSR,
11816               $src3$$constant &amp; 0x1f);
11817   %}
11818 
11819   ins_pipe(ialu_reg_reg_shift);
11820 %}
11821 
11822 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11823                          iRegL src1, iRegL src2,
11824                          immI src3, rFlagsReg cr) %{
11825   match(Set dst (SubL src1 (URShiftL src2 src3)));
11826 
11827   ins_cost(1.9 * INSN_COST);
11828   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11829 
11830   ins_encode %{
11831     __ sub(as_Register($dst$$reg),
11832               as_Register($src1$$reg),
11833               as_Register($src2$$reg),
11834               Assembler::LSR,
11835               $src3$$constant &amp; 0x3f);
11836   %}
11837 
11838   ins_pipe(ialu_reg_reg_shift);
11839 %}
11840 
11841 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11842                          iRegIorL2I src1, iRegIorL2I src2,
11843                          immI src3, rFlagsReg cr) %{
11844   match(Set dst (SubI src1 (RShiftI src2 src3)));
11845 
11846   ins_cost(1.9 * INSN_COST);
11847   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11848 
11849   ins_encode %{
11850     __ subw(as_Register($dst$$reg),
11851               as_Register($src1$$reg),
11852               as_Register($src2$$reg),
11853               Assembler::ASR,
11854               $src3$$constant &amp; 0x1f);
11855   %}
11856 
11857   ins_pipe(ialu_reg_reg_shift);
11858 %}
11859 
11860 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11861                          iRegL src1, iRegL src2,
11862                          immI src3, rFlagsReg cr) %{
11863   match(Set dst (SubL src1 (RShiftL src2 src3)));
11864 
11865   ins_cost(1.9 * INSN_COST);
11866   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11867 
11868   ins_encode %{
11869     __ sub(as_Register($dst$$reg),
11870               as_Register($src1$$reg),
11871               as_Register($src2$$reg),
11872               Assembler::ASR,
11873               $src3$$constant &amp; 0x3f);
11874   %}
11875 
11876   ins_pipe(ialu_reg_reg_shift);
11877 %}
11878 
11879 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11880                          iRegIorL2I src1, iRegIorL2I src2,
11881                          immI src3, rFlagsReg cr) %{
11882   match(Set dst (SubI src1 (LShiftI src2 src3)));
11883 
11884   ins_cost(1.9 * INSN_COST);
11885   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11886 
11887   ins_encode %{
11888     __ subw(as_Register($dst$$reg),
11889               as_Register($src1$$reg),
11890               as_Register($src2$$reg),
11891               Assembler::LSL,
11892               $src3$$constant &amp; 0x1f);
11893   %}
11894 
11895   ins_pipe(ialu_reg_reg_shift);
11896 %}
11897 
11898 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11899                          iRegL src1, iRegL src2,
11900                          immI src3, rFlagsReg cr) %{
11901   match(Set dst (SubL src1 (LShiftL src2 src3)));
11902 
11903   ins_cost(1.9 * INSN_COST);
11904   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11905 
11906   ins_encode %{
11907     __ sub(as_Register($dst$$reg),
11908               as_Register($src1$$reg),
11909               as_Register($src2$$reg),
11910               Assembler::LSL,
11911               $src3$$constant &amp; 0x3f);
11912   %}
11913 
11914   ins_pipe(ialu_reg_reg_shift);
11915 %}
11916 
11917 
11918 
11919 // Shift Left followed by Shift Right.
11920 // This idiom is used by the compiler for the i2b bytecode etc.
11921 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11922 %{
11923   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11924   ins_cost(INSN_COST * 2);
11925   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11926   ins_encode %{
11927     int lshift = $lshift_count$$constant &amp; 63;
11928     int rshift = $rshift_count$$constant &amp; 63;
11929     int s = 63 - lshift;
11930     int r = (rshift - lshift) &amp; 63;
11931     __ sbfm(as_Register($dst$$reg),
11932             as_Register($src$$reg),
11933             r, s);
11934   %}
11935 
11936   ins_pipe(ialu_reg_shift);
11937 %}
11938 
11939 // Shift Left followed by Shift Right.
11940 // This idiom is used by the compiler for the i2b bytecode etc.
11941 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11942 %{
11943   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11944   ins_cost(INSN_COST * 2);
11945   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11946   ins_encode %{
11947     int lshift = $lshift_count$$constant &amp; 31;
11948     int rshift = $rshift_count$$constant &amp; 31;
11949     int s = 31 - lshift;
11950     int r = (rshift - lshift) &amp; 31;
11951     __ sbfmw(as_Register($dst$$reg),
11952             as_Register($src$$reg),
11953             r, s);
11954   %}
11955 
11956   ins_pipe(ialu_reg_shift);
11957 %}
11958 
11959 // Shift Left followed by Shift Right.
11960 // This idiom is used by the compiler for the i2b bytecode etc.
11961 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11962 %{
11963   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11964   ins_cost(INSN_COST * 2);
11965   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11966   ins_encode %{
11967     int lshift = $lshift_count$$constant &amp; 63;
11968     int rshift = $rshift_count$$constant &amp; 63;
11969     int s = 63 - lshift;
11970     int r = (rshift - lshift) &amp; 63;
11971     __ ubfm(as_Register($dst$$reg),
11972             as_Register($src$$reg),
11973             r, s);
11974   %}
11975 
11976   ins_pipe(ialu_reg_shift);
11977 %}
11978 
11979 // Shift Left followed by Shift Right.
11980 // This idiom is used by the compiler for the i2b bytecode etc.
11981 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11982 %{
11983   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11984   ins_cost(INSN_COST * 2);
11985   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11986   ins_encode %{
11987     int lshift = $lshift_count$$constant &amp; 31;
11988     int rshift = $rshift_count$$constant &amp; 31;
11989     int s = 31 - lshift;
11990     int r = (rshift - lshift) &amp; 31;
11991     __ ubfmw(as_Register($dst$$reg),
11992             as_Register($src$$reg),
11993             r, s);
11994   %}
11995 
11996   ins_pipe(ialu_reg_shift);
11997 %}
11998 // Bitfield extract with shift &amp; mask
11999 
12000 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12001 %{
12002   match(Set dst (AndI (URShiftI src rshift) mask));
12003   // Make sure we are not going to exceed what ubfxw can do.
12004   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12005 
12006   ins_cost(INSN_COST);
12007   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12008   ins_encode %{
12009     int rshift = $rshift$$constant &amp; 31;
12010     long mask = $mask$$constant;
12011     int width = exact_log2(mask+1);
12012     __ ubfxw(as_Register($dst$$reg),
12013             as_Register($src$$reg), rshift, width);
12014   %}
12015   ins_pipe(ialu_reg_shift);
12016 %}
12017 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12018 %{
12019   match(Set dst (AndL (URShiftL src rshift) mask));
12020   // Make sure we are not going to exceed what ubfx can do.
12021   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12022 
12023   ins_cost(INSN_COST);
12024   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12025   ins_encode %{
12026     int rshift = $rshift$$constant &amp; 63;
12027     long mask = $mask$$constant;
12028     int width = exact_log2_long(mask+1);
12029     __ ubfx(as_Register($dst$$reg),
12030             as_Register($src$$reg), rshift, width);
12031   %}
12032   ins_pipe(ialu_reg_shift);
12033 %}
12034 
12035 // We can use ubfx when extending an And with a mask when we know mask
12036 // is positive.  We know that because immI_bitmask guarantees it.
12037 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12038 %{
12039   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12040   // Make sure we are not going to exceed what ubfxw can do.
12041   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12042 
12043   ins_cost(INSN_COST * 2);
12044   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12045   ins_encode %{
12046     int rshift = $rshift$$constant &amp; 31;
12047     long mask = $mask$$constant;
12048     int width = exact_log2(mask+1);
12049     __ ubfx(as_Register($dst$$reg),
12050             as_Register($src$$reg), rshift, width);
12051   %}
12052   ins_pipe(ialu_reg_shift);
12053 %}
12054 
12055 // We can use ubfiz when masking by a positive number and then left shifting the result.
12056 // We know that the mask is positive because immI_bitmask guarantees it.
12057 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12058 %{
12059   match(Set dst (LShiftI (AndI src mask) lshift));
12060   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12061 
12062   ins_cost(INSN_COST);
12063   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12064   ins_encode %{
12065     int lshift = $lshift$$constant &amp; 31;
12066     long mask = $mask$$constant;
12067     int width = exact_log2(mask+1);
12068     __ ubfizw(as_Register($dst$$reg),
12069           as_Register($src$$reg), lshift, width);
12070   %}
12071   ins_pipe(ialu_reg_shift);
12072 %}
12073 // We can use ubfiz when masking by a positive number and then left shifting the result.
12074 // We know that the mask is positive because immL_bitmask guarantees it.
12075 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12076 %{
12077   match(Set dst (LShiftL (AndL src mask) lshift));
12078   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12079 
12080   ins_cost(INSN_COST);
12081   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12082   ins_encode %{
12083     int lshift = $lshift$$constant &amp; 63;
12084     long mask = $mask$$constant;
12085     int width = exact_log2_long(mask+1);
12086     __ ubfiz(as_Register($dst$$reg),
12087           as_Register($src$$reg), lshift, width);
12088   %}
12089   ins_pipe(ialu_reg_shift);
12090 %}
12091 
12092 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12093 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12094 %{
12095   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12096   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12097 
12098   ins_cost(INSN_COST);
12099   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12100   ins_encode %{
12101     int lshift = $lshift$$constant &amp; 63;
12102     long mask = $mask$$constant;
12103     int width = exact_log2(mask+1);
12104     __ ubfiz(as_Register($dst$$reg),
12105              as_Register($src$$reg), lshift, width);
12106   %}
12107   ins_pipe(ialu_reg_shift);
12108 %}
12109 
12110 // Rotations
12111 
12112 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12113 %{
12114   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12115   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12116 
12117   ins_cost(INSN_COST);
12118   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12119 
12120   ins_encode %{
12121     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12122             $rshift$$constant &amp; 63);
12123   %}
12124   ins_pipe(ialu_reg_reg_extr);
12125 %}
12126 
12127 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12128 %{
12129   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12130   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12131 
12132   ins_cost(INSN_COST);
12133   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12134 
12135   ins_encode %{
12136     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12137             $rshift$$constant &amp; 31);
12138   %}
12139   ins_pipe(ialu_reg_reg_extr);
12140 %}
12141 
12142 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12143 %{
12144   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12145   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12146 
12147   ins_cost(INSN_COST);
12148   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12149 
12150   ins_encode %{
12151     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12152             $rshift$$constant &amp; 63);
12153   %}
12154   ins_pipe(ialu_reg_reg_extr);
12155 %}
12156 
12157 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12158 %{
12159   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12160   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12161 
12162   ins_cost(INSN_COST);
12163   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12164 
12165   ins_encode %{
12166     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12167             $rshift$$constant &amp; 31);
12168   %}
12169   ins_pipe(ialu_reg_reg_extr);
12170 %}
12171 
12172 
12173 // rol expander
12174 
12175 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12176 %{
12177   effect(DEF dst, USE src, USE shift);
12178 
12179   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12180   ins_cost(INSN_COST * 3);
12181   ins_encode %{
12182     __ subw(rscratch1, zr, as_Register($shift$$reg));
12183     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12184             rscratch1);
12185     %}
12186   ins_pipe(ialu_reg_reg_vshift);
12187 %}
12188 
12189 // rol expander
12190 
12191 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12192 %{
12193   effect(DEF dst, USE src, USE shift);
12194 
12195   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12196   ins_cost(INSN_COST * 3);
12197   ins_encode %{
12198     __ subw(rscratch1, zr, as_Register($shift$$reg));
12199     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12200             rscratch1);
12201     %}
12202   ins_pipe(ialu_reg_reg_vshift);
12203 %}
12204 
12205 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12206 %{
12207   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12208 
12209   expand %{
12210     rolL_rReg(dst, src, shift, cr);
12211   %}
12212 %}
12213 
12214 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12215 %{
12216   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12217 
12218   expand %{
12219     rolL_rReg(dst, src, shift, cr);
12220   %}
12221 %}
12222 
12223 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12224 %{
12225   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12226 
12227   expand %{
12228     rolI_rReg(dst, src, shift, cr);
12229   %}
12230 %}
12231 
12232 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12233 %{
12234   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12235 
12236   expand %{
12237     rolI_rReg(dst, src, shift, cr);
12238   %}
12239 %}
12240 
12241 // ror expander
12242 
12243 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12244 %{
12245   effect(DEF dst, USE src, USE shift);
12246 
12247   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12248   ins_cost(INSN_COST);
12249   ins_encode %{
12250     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12251             as_Register($shift$$reg));
12252     %}
12253   ins_pipe(ialu_reg_reg_vshift);
12254 %}
12255 
12256 // ror expander
12257 
12258 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12259 %{
12260   effect(DEF dst, USE src, USE shift);
12261 
12262   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12263   ins_cost(INSN_COST);
12264   ins_encode %{
12265     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12266             as_Register($shift$$reg));
12267     %}
12268   ins_pipe(ialu_reg_reg_vshift);
12269 %}
12270 
12271 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12272 %{
12273   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12274 
12275   expand %{
12276     rorL_rReg(dst, src, shift, cr);
12277   %}
12278 %}
12279 
12280 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12281 %{
12282   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12283 
12284   expand %{
12285     rorL_rReg(dst, src, shift, cr);
12286   %}
12287 %}
12288 
12289 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12290 %{
12291   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12292 
12293   expand %{
12294     rorI_rReg(dst, src, shift, cr);
12295   %}
12296 %}
12297 
12298 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12299 %{
12300   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12301 
12302   expand %{
12303     rorI_rReg(dst, src, shift, cr);
12304   %}
12305 %}
12306 
12307 // Add/subtract (extended)
12308 
12309 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12310 %{
12311   match(Set dst (AddL src1 (ConvI2L src2)));
12312   ins_cost(INSN_COST);
12313   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12314 
12315    ins_encode %{
12316      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12317             as_Register($src2$$reg), ext::sxtw);
12318    %}
12319   ins_pipe(ialu_reg_reg);
12320 %};
12321 
12322 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12323 %{
12324   match(Set dst (SubL src1 (ConvI2L src2)));
12325   ins_cost(INSN_COST);
12326   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12327 
12328    ins_encode %{
12329      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12330             as_Register($src2$$reg), ext::sxtw);
12331    %}
12332   ins_pipe(ialu_reg_reg);
12333 %};
12334 
12335 
12336 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12337 %{
12338   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12339   ins_cost(INSN_COST);
12340   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12341 
12342    ins_encode %{
12343      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12344             as_Register($src2$$reg), ext::sxth);
12345    %}
12346   ins_pipe(ialu_reg_reg);
12347 %}
12348 
12349 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12350 %{
12351   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12352   ins_cost(INSN_COST);
12353   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12354 
12355    ins_encode %{
12356      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12357             as_Register($src2$$reg), ext::sxtb);
12358    %}
12359   ins_pipe(ialu_reg_reg);
12360 %}
12361 
12362 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12363 %{
12364   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12365   ins_cost(INSN_COST);
12366   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12367 
12368    ins_encode %{
12369      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12370             as_Register($src2$$reg), ext::uxtb);
12371    %}
12372   ins_pipe(ialu_reg_reg);
12373 %}
12374 
12375 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12376 %{
12377   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12378   ins_cost(INSN_COST);
12379   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12380 
12381    ins_encode %{
12382      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12383             as_Register($src2$$reg), ext::sxth);
12384    %}
12385   ins_pipe(ialu_reg_reg);
12386 %}
12387 
12388 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12389 %{
12390   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12391   ins_cost(INSN_COST);
12392   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12393 
12394    ins_encode %{
12395      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12396             as_Register($src2$$reg), ext::sxtw);
12397    %}
12398   ins_pipe(ialu_reg_reg);
12399 %}
12400 
12401 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12402 %{
12403   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12404   ins_cost(INSN_COST);
12405   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12406 
12407    ins_encode %{
12408      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12409             as_Register($src2$$reg), ext::sxtb);
12410    %}
12411   ins_pipe(ialu_reg_reg);
12412 %}
12413 
12414 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12415 %{
12416   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12417   ins_cost(INSN_COST);
12418   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12419 
12420    ins_encode %{
12421      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12422             as_Register($src2$$reg), ext::uxtb);
12423    %}
12424   ins_pipe(ialu_reg_reg);
12425 %}
12426 
12427 
12428 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12429 %{
12430   match(Set dst (AddI src1 (AndI src2 mask)));
12431   ins_cost(INSN_COST);
12432   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12433 
12434    ins_encode %{
12435      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12436             as_Register($src2$$reg), ext::uxtb);
12437    %}
12438   ins_pipe(ialu_reg_reg);
12439 %}
12440 
12441 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12442 %{
12443   match(Set dst (AddI src1 (AndI src2 mask)));
12444   ins_cost(INSN_COST);
12445   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12446 
12447    ins_encode %{
12448      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12449             as_Register($src2$$reg), ext::uxth);
12450    %}
12451   ins_pipe(ialu_reg_reg);
12452 %}
12453 
12454 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12455 %{
12456   match(Set dst (AddL src1 (AndL src2 mask)));
12457   ins_cost(INSN_COST);
12458   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12459 
12460    ins_encode %{
12461      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12462             as_Register($src2$$reg), ext::uxtb);
12463    %}
12464   ins_pipe(ialu_reg_reg);
12465 %}
12466 
12467 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12468 %{
12469   match(Set dst (AddL src1 (AndL src2 mask)));
12470   ins_cost(INSN_COST);
12471   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12472 
12473    ins_encode %{
12474      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12475             as_Register($src2$$reg), ext::uxth);
12476    %}
12477   ins_pipe(ialu_reg_reg);
12478 %}
12479 
12480 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12481 %{
12482   match(Set dst (AddL src1 (AndL src2 mask)));
12483   ins_cost(INSN_COST);
12484   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12485 
12486    ins_encode %{
12487      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12488             as_Register($src2$$reg), ext::uxtw);
12489    %}
12490   ins_pipe(ialu_reg_reg);
12491 %}
12492 
12493 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12494 %{
12495   match(Set dst (SubI src1 (AndI src2 mask)));
12496   ins_cost(INSN_COST);
12497   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12498 
12499    ins_encode %{
12500      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12501             as_Register($src2$$reg), ext::uxtb);
12502    %}
12503   ins_pipe(ialu_reg_reg);
12504 %}
12505 
12506 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12507 %{
12508   match(Set dst (SubI src1 (AndI src2 mask)));
12509   ins_cost(INSN_COST);
12510   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12511 
12512    ins_encode %{
12513      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12514             as_Register($src2$$reg), ext::uxth);
12515    %}
12516   ins_pipe(ialu_reg_reg);
12517 %}
12518 
12519 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12520 %{
12521   match(Set dst (SubL src1 (AndL src2 mask)));
12522   ins_cost(INSN_COST);
12523   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12524 
12525    ins_encode %{
12526      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12527             as_Register($src2$$reg), ext::uxtb);
12528    %}
12529   ins_pipe(ialu_reg_reg);
12530 %}
12531 
12532 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12533 %{
12534   match(Set dst (SubL src1 (AndL src2 mask)));
12535   ins_cost(INSN_COST);
12536   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12537 
12538    ins_encode %{
12539      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12540             as_Register($src2$$reg), ext::uxth);
12541    %}
12542   ins_pipe(ialu_reg_reg);
12543 %}
12544 
12545 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12546 %{
12547   match(Set dst (SubL src1 (AndL src2 mask)));
12548   ins_cost(INSN_COST);
12549   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12550 
12551    ins_encode %{
12552      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12553             as_Register($src2$$reg), ext::uxtw);
12554    %}
12555   ins_pipe(ialu_reg_reg);
12556 %}
12557 
12558 
12559 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12560 %{
12561   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12562   ins_cost(1.9 * INSN_COST);
12563   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12564 
12565    ins_encode %{
12566      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12567             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12568    %}
12569   ins_pipe(ialu_reg_reg_shift);
12570 %}
12571 
12572 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12573 %{
12574   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12575   ins_cost(1.9 * INSN_COST);
12576   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12577 
12578    ins_encode %{
12579      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12580             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12581    %}
12582   ins_pipe(ialu_reg_reg_shift);
12583 %}
12584 
12585 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12586 %{
12587   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12588   ins_cost(1.9 * INSN_COST);
12589   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12590 
12591    ins_encode %{
12592      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12593             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12594    %}
12595   ins_pipe(ialu_reg_reg_shift);
12596 %}
12597 
12598 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12599 %{
12600   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12601   ins_cost(1.9 * INSN_COST);
12602   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12603 
12604    ins_encode %{
12605      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12606             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12607    %}
12608   ins_pipe(ialu_reg_reg_shift);
12609 %}
12610 
12611 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12612 %{
12613   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12614   ins_cost(1.9 * INSN_COST);
12615   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12616 
12617    ins_encode %{
12618      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12619             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12620    %}
12621   ins_pipe(ialu_reg_reg_shift);
12622 %}
12623 
12624 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12625 %{
12626   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12627   ins_cost(1.9 * INSN_COST);
12628   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12629 
12630    ins_encode %{
12631      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12632             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12633    %}
12634   ins_pipe(ialu_reg_reg_shift);
12635 %}
12636 
12637 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12638 %{
12639   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12640   ins_cost(1.9 * INSN_COST);
12641   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12642 
12643    ins_encode %{
12644      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12645             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12646    %}
12647   ins_pipe(ialu_reg_reg_shift);
12648 %}
12649 
12650 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12651 %{
12652   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12653   ins_cost(1.9 * INSN_COST);
12654   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12655 
12656    ins_encode %{
12657      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12658             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12659    %}
12660   ins_pipe(ialu_reg_reg_shift);
12661 %}
12662 
12663 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12664 %{
12665   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12666   ins_cost(1.9 * INSN_COST);
12667   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12668 
12669    ins_encode %{
12670      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12671             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12672    %}
12673   ins_pipe(ialu_reg_reg_shift);
12674 %}
12675 
12676 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12677 %{
12678   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12679   ins_cost(1.9 * INSN_COST);
12680   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12681 
12682    ins_encode %{
12683      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12684             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12685    %}
12686   ins_pipe(ialu_reg_reg_shift);
12687 %}
12688 
12689 
12690 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12691 %{
12692   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12693   ins_cost(1.9 * INSN_COST);
12694   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12695 
12696    ins_encode %{
12697      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12698             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12699    %}
12700   ins_pipe(ialu_reg_reg_shift);
12701 %};
12702 
12703 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12704 %{
12705   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12706   ins_cost(1.9 * INSN_COST);
12707   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12708 
12709    ins_encode %{
12710      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12711             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12712    %}
12713   ins_pipe(ialu_reg_reg_shift);
12714 %};
12715 
12716 
12717 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12718 %{
12719   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12720   ins_cost(1.9 * INSN_COST);
12721   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12722 
12723    ins_encode %{
12724      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12725             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12726    %}
12727   ins_pipe(ialu_reg_reg_shift);
12728 %}
12729 
12730 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12731 %{
12732   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12733   ins_cost(1.9 * INSN_COST);
12734   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12735 
12736    ins_encode %{
12737      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12738             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12739    %}
12740   ins_pipe(ialu_reg_reg_shift);
12741 %}
12742 
12743 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12744 %{
12745   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12746   ins_cost(1.9 * INSN_COST);
12747   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12748 
12749    ins_encode %{
12750      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12751             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12752    %}
12753   ins_pipe(ialu_reg_reg_shift);
12754 %}
12755 
12756 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12757 %{
12758   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12759   ins_cost(1.9 * INSN_COST);
12760   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12761 
12762    ins_encode %{
12763      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12764             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12765    %}
12766   ins_pipe(ialu_reg_reg_shift);
12767 %}
12768 
12769 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12770 %{
12771   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12772   ins_cost(1.9 * INSN_COST);
12773   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12774 
12775    ins_encode %{
12776      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12777             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12778    %}
12779   ins_pipe(ialu_reg_reg_shift);
12780 %}
12781 
12782 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12783 %{
12784   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12785   ins_cost(1.9 * INSN_COST);
12786   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12787 
12788    ins_encode %{
12789      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12790             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12791    %}
12792   ins_pipe(ialu_reg_reg_shift);
12793 %}
12794 
12795 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12796 %{
12797   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12798   ins_cost(1.9 * INSN_COST);
12799   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12800 
12801    ins_encode %{
12802      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12803             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12804    %}
12805   ins_pipe(ialu_reg_reg_shift);
12806 %}
12807 
12808 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12809 %{
12810   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12811   ins_cost(1.9 * INSN_COST);
12812   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12813 
12814    ins_encode %{
12815      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12816             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12817    %}
12818   ins_pipe(ialu_reg_reg_shift);
12819 %}
12820 
12821 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12822 %{
12823   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12824   ins_cost(1.9 * INSN_COST);
12825   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12826 
12827    ins_encode %{
12828      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12829             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12830    %}
12831   ins_pipe(ialu_reg_reg_shift);
12832 %}
12833 
12834 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12835 %{
12836   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12837   ins_cost(1.9 * INSN_COST);
12838   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12839 
12840    ins_encode %{
12841      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12842             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12843    %}
12844   ins_pipe(ialu_reg_reg_shift);
12845 %}
12846 // END This section of the file is automatically generated. Do not edit --------------
12847 
12848 // ============================================================================
12849 // Floating Point Arithmetic Instructions
12850 
12851 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12852   match(Set dst (AddF src1 src2));
12853 
12854   ins_cost(INSN_COST * 5);
12855   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12856 
12857   ins_encode %{
12858     __ fadds(as_FloatRegister($dst$$reg),
12859              as_FloatRegister($src1$$reg),
12860              as_FloatRegister($src2$$reg));
12861   %}
12862 
12863   ins_pipe(fp_dop_reg_reg_s);
12864 %}
12865 
12866 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12867   match(Set dst (AddD src1 src2));
12868 
12869   ins_cost(INSN_COST * 5);
12870   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12871 
12872   ins_encode %{
12873     __ faddd(as_FloatRegister($dst$$reg),
12874              as_FloatRegister($src1$$reg),
12875              as_FloatRegister($src2$$reg));
12876   %}
12877 
12878   ins_pipe(fp_dop_reg_reg_d);
12879 %}
12880 
12881 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12882   match(Set dst (SubF src1 src2));
12883 
12884   ins_cost(INSN_COST * 5);
12885   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12886 
12887   ins_encode %{
12888     __ fsubs(as_FloatRegister($dst$$reg),
12889              as_FloatRegister($src1$$reg),
12890              as_FloatRegister($src2$$reg));
12891   %}
12892 
12893   ins_pipe(fp_dop_reg_reg_s);
12894 %}
12895 
12896 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12897   match(Set dst (SubD src1 src2));
12898 
12899   ins_cost(INSN_COST * 5);
12900   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12901 
12902   ins_encode %{
12903     __ fsubd(as_FloatRegister($dst$$reg),
12904              as_FloatRegister($src1$$reg),
12905              as_FloatRegister($src2$$reg));
12906   %}
12907 
12908   ins_pipe(fp_dop_reg_reg_d);
12909 %}
12910 
12911 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12912   match(Set dst (MulF src1 src2));
12913 
12914   ins_cost(INSN_COST * 6);
12915   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12916 
12917   ins_encode %{
12918     __ fmuls(as_FloatRegister($dst$$reg),
12919              as_FloatRegister($src1$$reg),
12920              as_FloatRegister($src2$$reg));
12921   %}
12922 
12923   ins_pipe(fp_dop_reg_reg_s);
12924 %}
12925 
12926 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12927   match(Set dst (MulD src1 src2));
12928 
12929   ins_cost(INSN_COST * 6);
12930   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12931 
12932   ins_encode %{
12933     __ fmuld(as_FloatRegister($dst$$reg),
12934              as_FloatRegister($src1$$reg),
12935              as_FloatRegister($src2$$reg));
12936   %}
12937 
12938   ins_pipe(fp_dop_reg_reg_d);
12939 %}
12940 
12941 // src1 * src2 + src3
12942 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12943   predicate(UseFMA);
12944   match(Set dst (FmaF src3 (Binary src1 src2)));
12945 
12946   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12947 
12948   ins_encode %{
12949     __ fmadds(as_FloatRegister($dst$$reg),
12950              as_FloatRegister($src1$$reg),
12951              as_FloatRegister($src2$$reg),
12952              as_FloatRegister($src3$$reg));
12953   %}
12954 
12955   ins_pipe(pipe_class_default);
12956 %}
12957 
12958 // src1 * src2 + src3
12959 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12960   predicate(UseFMA);
12961   match(Set dst (FmaD src3 (Binary src1 src2)));
12962 
12963   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12964 
12965   ins_encode %{
12966     __ fmaddd(as_FloatRegister($dst$$reg),
12967              as_FloatRegister($src1$$reg),
12968              as_FloatRegister($src2$$reg),
12969              as_FloatRegister($src3$$reg));
12970   %}
12971 
12972   ins_pipe(pipe_class_default);
12973 %}
12974 
12975 // -src1 * src2 + src3
12976 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12977   predicate(UseFMA);
12978   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12979   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12980 
12981   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12982 
12983   ins_encode %{
12984     __ fmsubs(as_FloatRegister($dst$$reg),
12985               as_FloatRegister($src1$$reg),
12986               as_FloatRegister($src2$$reg),
12987               as_FloatRegister($src3$$reg));
12988   %}
12989 
12990   ins_pipe(pipe_class_default);
12991 %}
12992 
12993 // -src1 * src2 + src3
12994 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12995   predicate(UseFMA);
12996   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12997   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12998 
12999   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13000 
13001   ins_encode %{
13002     __ fmsubd(as_FloatRegister($dst$$reg),
13003               as_FloatRegister($src1$$reg),
13004               as_FloatRegister($src2$$reg),
13005               as_FloatRegister($src3$$reg));
13006   %}
13007 
13008   ins_pipe(pipe_class_default);
13009 %}
13010 
13011 // -src1 * src2 - src3
13012 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13013   predicate(UseFMA);
13014   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13015   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13016 
13017   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13018 
13019   ins_encode %{
13020     __ fnmadds(as_FloatRegister($dst$$reg),
13021                as_FloatRegister($src1$$reg),
13022                as_FloatRegister($src2$$reg),
13023                as_FloatRegister($src3$$reg));
13024   %}
13025 
13026   ins_pipe(pipe_class_default);
13027 %}
13028 
13029 // -src1 * src2 - src3
13030 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13031   predicate(UseFMA);
13032   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13033   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13034 
13035   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13036 
13037   ins_encode %{
13038     __ fnmaddd(as_FloatRegister($dst$$reg),
13039                as_FloatRegister($src1$$reg),
13040                as_FloatRegister($src2$$reg),
13041                as_FloatRegister($src3$$reg));
13042   %}
13043 
13044   ins_pipe(pipe_class_default);
13045 %}
13046 
13047 // src1 * src2 - src3
13048 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13049   predicate(UseFMA);
13050   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13051 
13052   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13053 
13054   ins_encode %{
13055     __ fnmsubs(as_FloatRegister($dst$$reg),
13056                as_FloatRegister($src1$$reg),
13057                as_FloatRegister($src2$$reg),
13058                as_FloatRegister($src3$$reg));
13059   %}
13060 
13061   ins_pipe(pipe_class_default);
13062 %}
13063 
13064 // src1 * src2 - src3
13065 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13066   predicate(UseFMA);
13067   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13068 
13069   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13070 
13071   ins_encode %{
13072   // n.b. insn name should be fnmsubd
13073     __ fnmsub(as_FloatRegister($dst$$reg),
13074               as_FloatRegister($src1$$reg),
13075               as_FloatRegister($src2$$reg),
13076               as_FloatRegister($src3$$reg));
13077   %}
13078 
13079   ins_pipe(pipe_class_default);
13080 %}
13081 
13082 
13083 // Math.max(FF)F
13084 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13085   match(Set dst (MaxF src1 src2));
13086 
13087   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13088   ins_encode %{
13089     __ fmaxs(as_FloatRegister($dst$$reg),
13090              as_FloatRegister($src1$$reg),
13091              as_FloatRegister($src2$$reg));
13092   %}
13093 
13094   ins_pipe(fp_dop_reg_reg_s);
13095 %}
13096 
13097 // Math.min(FF)F
13098 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13099   match(Set dst (MinF src1 src2));
13100 
13101   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13102   ins_encode %{
13103     __ fmins(as_FloatRegister($dst$$reg),
13104              as_FloatRegister($src1$$reg),
13105              as_FloatRegister($src2$$reg));
13106   %}
13107 
13108   ins_pipe(fp_dop_reg_reg_s);
13109 %}
13110 
13111 // Math.max(DD)D
13112 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13113   match(Set dst (MaxD src1 src2));
13114 
13115   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13116   ins_encode %{
13117     __ fmaxd(as_FloatRegister($dst$$reg),
13118              as_FloatRegister($src1$$reg),
13119              as_FloatRegister($src2$$reg));
13120   %}
13121 
13122   ins_pipe(fp_dop_reg_reg_d);
13123 %}
13124 
13125 // Math.min(DD)D
13126 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13127   match(Set dst (MinD src1 src2));
13128 
13129   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13130   ins_encode %{
13131     __ fmind(as_FloatRegister($dst$$reg),
13132              as_FloatRegister($src1$$reg),
13133              as_FloatRegister($src2$$reg));
13134   %}
13135 
13136   ins_pipe(fp_dop_reg_reg_d);
13137 %}
13138 
13139 
13140 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13141   match(Set dst (DivF src1  src2));
13142 
13143   ins_cost(INSN_COST * 18);
13144   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13145 
13146   ins_encode %{
13147     __ fdivs(as_FloatRegister($dst$$reg),
13148              as_FloatRegister($src1$$reg),
13149              as_FloatRegister($src2$$reg));
13150   %}
13151 
13152   ins_pipe(fp_div_s);
13153 %}
13154 
13155 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13156   match(Set dst (DivD src1  src2));
13157 
13158   ins_cost(INSN_COST * 32);
13159   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13160 
13161   ins_encode %{
13162     __ fdivd(as_FloatRegister($dst$$reg),
13163              as_FloatRegister($src1$$reg),
13164              as_FloatRegister($src2$$reg));
13165   %}
13166 
13167   ins_pipe(fp_div_d);
13168 %}
13169 
13170 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13171   match(Set dst (NegF src));
13172 
13173   ins_cost(INSN_COST * 3);
13174   format %{ &quot;fneg   $dst, $src&quot; %}
13175 
13176   ins_encode %{
13177     __ fnegs(as_FloatRegister($dst$$reg),
13178              as_FloatRegister($src$$reg));
13179   %}
13180 
13181   ins_pipe(fp_uop_s);
13182 %}
13183 
13184 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13185   match(Set dst (NegD src));
13186 
13187   ins_cost(INSN_COST * 3);
13188   format %{ &quot;fnegd   $dst, $src&quot; %}
13189 
13190   ins_encode %{
13191     __ fnegd(as_FloatRegister($dst$$reg),
13192              as_FloatRegister($src$$reg));
13193   %}
13194 
13195   ins_pipe(fp_uop_d);
13196 %}
13197 
13198 instruct absF_reg(vRegF dst, vRegF src) %{
13199   match(Set dst (AbsF src));
13200 
13201   ins_cost(INSN_COST * 3);
13202   format %{ &quot;fabss   $dst, $src&quot; %}
13203   ins_encode %{
13204     __ fabss(as_FloatRegister($dst$$reg),
13205              as_FloatRegister($src$$reg));
13206   %}
13207 
13208   ins_pipe(fp_uop_s);
13209 %}
13210 
13211 instruct absD_reg(vRegD dst, vRegD src) %{
13212   match(Set dst (AbsD src));
13213 
13214   ins_cost(INSN_COST * 3);
13215   format %{ &quot;fabsd   $dst, $src&quot; %}
13216   ins_encode %{
13217     __ fabsd(as_FloatRegister($dst$$reg),
13218              as_FloatRegister($src$$reg));
13219   %}
13220 
13221   ins_pipe(fp_uop_d);
13222 %}
13223 
13224 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13225   match(Set dst (SqrtD src));
13226 
13227   ins_cost(INSN_COST * 50);
13228   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13229   ins_encode %{
13230     __ fsqrtd(as_FloatRegister($dst$$reg),
13231              as_FloatRegister($src$$reg));
13232   %}
13233 
13234   ins_pipe(fp_div_s);
13235 %}
13236 
13237 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13238   match(Set dst (SqrtF src));
13239 
13240   ins_cost(INSN_COST * 50);
13241   format %{ &quot;fsqrts  $dst, $src&quot; %}
13242   ins_encode %{
13243     __ fsqrts(as_FloatRegister($dst$$reg),
13244              as_FloatRegister($src$$reg));
13245   %}
13246 
13247   ins_pipe(fp_div_d);
13248 %}
13249 
13250 // Math.rint, floor, ceil
13251 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13252   match(Set dst (RoundDoubleMode src rmode));
13253   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13254   ins_encode %{
13255     switch ($rmode$$constant) {
13256       case RoundDoubleModeNode::rmode_rint:
13257         __ frintnd(as_FloatRegister($dst$$reg),
13258                    as_FloatRegister($src$$reg));
13259         break;
13260       case RoundDoubleModeNode::rmode_floor:
13261         __ frintmd(as_FloatRegister($dst$$reg),
13262                    as_FloatRegister($src$$reg));
13263         break;
13264       case RoundDoubleModeNode::rmode_ceil:
13265         __ frintpd(as_FloatRegister($dst$$reg),
13266                    as_FloatRegister($src$$reg));
13267         break;
13268     }
13269   %}
13270   ins_pipe(fp_uop_d);
13271 %}
13272 
13273 // ============================================================================
13274 // Logical Instructions
13275 
13276 // Integer Logical Instructions
13277 
13278 // And Instructions
13279 
13280 
13281 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13282   match(Set dst (AndI src1 src2));
13283 
13284   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13285 
13286   ins_cost(INSN_COST);
13287   ins_encode %{
13288     __ andw(as_Register($dst$$reg),
13289             as_Register($src1$$reg),
13290             as_Register($src2$$reg));
13291   %}
13292 
13293   ins_pipe(ialu_reg_reg);
13294 %}
13295 
13296 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13297   match(Set dst (AndI src1 src2));
13298 
13299   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13300 
13301   ins_cost(INSN_COST);
13302   ins_encode %{
13303     __ andw(as_Register($dst$$reg),
13304             as_Register($src1$$reg),
13305             (unsigned long)($src2$$constant));
13306   %}
13307 
13308   ins_pipe(ialu_reg_imm);
13309 %}
13310 
13311 // Or Instructions
13312 
13313 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13314   match(Set dst (OrI src1 src2));
13315 
13316   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13317 
13318   ins_cost(INSN_COST);
13319   ins_encode %{
13320     __ orrw(as_Register($dst$$reg),
13321             as_Register($src1$$reg),
13322             as_Register($src2$$reg));
13323   %}
13324 
13325   ins_pipe(ialu_reg_reg);
13326 %}
13327 
13328 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13329   match(Set dst (OrI src1 src2));
13330 
13331   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13332 
13333   ins_cost(INSN_COST);
13334   ins_encode %{
13335     __ orrw(as_Register($dst$$reg),
13336             as_Register($src1$$reg),
13337             (unsigned long)($src2$$constant));
13338   %}
13339 
13340   ins_pipe(ialu_reg_imm);
13341 %}
13342 
13343 // Xor Instructions
13344 
13345 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13346   match(Set dst (XorI src1 src2));
13347 
13348   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13349 
13350   ins_cost(INSN_COST);
13351   ins_encode %{
13352     __ eorw(as_Register($dst$$reg),
13353             as_Register($src1$$reg),
13354             as_Register($src2$$reg));
13355   %}
13356 
13357   ins_pipe(ialu_reg_reg);
13358 %}
13359 
13360 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13361   match(Set dst (XorI src1 src2));
13362 
13363   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13364 
13365   ins_cost(INSN_COST);
13366   ins_encode %{
13367     __ eorw(as_Register($dst$$reg),
13368             as_Register($src1$$reg),
13369             (unsigned long)($src2$$constant));
13370   %}
13371 
13372   ins_pipe(ialu_reg_imm);
13373 %}
13374 
13375 // Long Logical Instructions
13376 // TODO
13377 
13378 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13379   match(Set dst (AndL src1 src2));
13380 
13381   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13382 
13383   ins_cost(INSN_COST);
13384   ins_encode %{
13385     __ andr(as_Register($dst$$reg),
13386             as_Register($src1$$reg),
13387             as_Register($src2$$reg));
13388   %}
13389 
13390   ins_pipe(ialu_reg_reg);
13391 %}
13392 
13393 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13394   match(Set dst (AndL src1 src2));
13395 
13396   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13397 
13398   ins_cost(INSN_COST);
13399   ins_encode %{
13400     __ andr(as_Register($dst$$reg),
13401             as_Register($src1$$reg),
13402             (unsigned long)($src2$$constant));
13403   %}
13404 
13405   ins_pipe(ialu_reg_imm);
13406 %}
13407 
13408 // Or Instructions
13409 
13410 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13411   match(Set dst (OrL src1 src2));
13412 
13413   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13414 
13415   ins_cost(INSN_COST);
13416   ins_encode %{
13417     __ orr(as_Register($dst$$reg),
13418            as_Register($src1$$reg),
13419            as_Register($src2$$reg));
13420   %}
13421 
13422   ins_pipe(ialu_reg_reg);
13423 %}
13424 
13425 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13426   match(Set dst (OrL src1 src2));
13427 
13428   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13429 
13430   ins_cost(INSN_COST);
13431   ins_encode %{
13432     __ orr(as_Register($dst$$reg),
13433            as_Register($src1$$reg),
13434            (unsigned long)($src2$$constant));
13435   %}
13436 
13437   ins_pipe(ialu_reg_imm);
13438 %}
13439 
13440 // Xor Instructions
13441 
13442 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13443   match(Set dst (XorL src1 src2));
13444 
13445   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13446 
13447   ins_cost(INSN_COST);
13448   ins_encode %{
13449     __ eor(as_Register($dst$$reg),
13450            as_Register($src1$$reg),
13451            as_Register($src2$$reg));
13452   %}
13453 
13454   ins_pipe(ialu_reg_reg);
13455 %}
13456 
13457 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13458   match(Set dst (XorL src1 src2));
13459 
13460   ins_cost(INSN_COST);
13461   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13462 
13463   ins_encode %{
13464     __ eor(as_Register($dst$$reg),
13465            as_Register($src1$$reg),
13466            (unsigned long)($src2$$constant));
13467   %}
13468 
13469   ins_pipe(ialu_reg_imm);
13470 %}
13471 
13472 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13473 %{
13474   match(Set dst (ConvI2L src));
13475 
13476   ins_cost(INSN_COST);
13477   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13478   ins_encode %{
13479     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13480   %}
13481   ins_pipe(ialu_reg_shift);
13482 %}
13483 
13484 // this pattern occurs in bigmath arithmetic
13485 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13486 %{
13487   match(Set dst (AndL (ConvI2L src) mask));
13488 
13489   ins_cost(INSN_COST);
13490   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13491   ins_encode %{
13492     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13493   %}
13494 
13495   ins_pipe(ialu_reg_shift);
13496 %}
13497 
13498 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13499   match(Set dst (ConvL2I src));
13500 
13501   ins_cost(INSN_COST);
13502   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13503 
13504   ins_encode %{
13505     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13506   %}
13507 
13508   ins_pipe(ialu_reg);
13509 %}
13510 
13511 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13512 %{
13513   match(Set dst (Conv2B src));
13514   effect(KILL cr);
13515 
13516   format %{
13517     &quot;cmpw $src, zr\n\t&quot;
13518     &quot;cset $dst, ne&quot;
13519   %}
13520 
13521   ins_encode %{
13522     __ cmpw(as_Register($src$$reg), zr);
13523     __ cset(as_Register($dst$$reg), Assembler::NE);
13524   %}
13525 
13526   ins_pipe(ialu_reg);
13527 %}
13528 
13529 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13530 %{
13531   match(Set dst (Conv2B src));
13532   effect(KILL cr);
13533 
13534   format %{
13535     &quot;cmp  $src, zr\n\t&quot;
13536     &quot;cset $dst, ne&quot;
13537   %}
13538 
13539   ins_encode %{
13540     __ cmp(as_Register($src$$reg), zr);
13541     __ cset(as_Register($dst$$reg), Assembler::NE);
13542   %}
13543 
13544   ins_pipe(ialu_reg);
13545 %}
13546 
13547 instruct convD2F_reg(vRegF dst, vRegD src) %{
13548   match(Set dst (ConvD2F src));
13549 
13550   ins_cost(INSN_COST * 5);
13551   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13552 
13553   ins_encode %{
13554     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13555   %}
13556 
13557   ins_pipe(fp_d2f);
13558 %}
13559 
13560 instruct convF2D_reg(vRegD dst, vRegF src) %{
13561   match(Set dst (ConvF2D src));
13562 
13563   ins_cost(INSN_COST * 5);
13564   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13565 
13566   ins_encode %{
13567     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13568   %}
13569 
13570   ins_pipe(fp_f2d);
13571 %}
13572 
13573 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13574   match(Set dst (ConvF2I src));
13575 
13576   ins_cost(INSN_COST * 5);
13577   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13578 
13579   ins_encode %{
13580     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13581   %}
13582 
13583   ins_pipe(fp_f2i);
13584 %}
13585 
13586 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13587   match(Set dst (ConvF2L src));
13588 
13589   ins_cost(INSN_COST * 5);
13590   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13591 
13592   ins_encode %{
13593     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13594   %}
13595 
13596   ins_pipe(fp_f2l);
13597 %}
13598 
13599 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13600   match(Set dst (ConvI2F src));
13601 
13602   ins_cost(INSN_COST * 5);
13603   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13604 
13605   ins_encode %{
13606     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13607   %}
13608 
13609   ins_pipe(fp_i2f);
13610 %}
13611 
13612 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13613   match(Set dst (ConvL2F src));
13614 
13615   ins_cost(INSN_COST * 5);
13616   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13617 
13618   ins_encode %{
13619     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13620   %}
13621 
13622   ins_pipe(fp_l2f);
13623 %}
13624 
13625 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13626   match(Set dst (ConvD2I src));
13627 
13628   ins_cost(INSN_COST * 5);
13629   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13630 
13631   ins_encode %{
13632     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13633   %}
13634 
13635   ins_pipe(fp_d2i);
13636 %}
13637 
13638 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13639   match(Set dst (ConvD2L src));
13640 
13641   ins_cost(INSN_COST * 5);
13642   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13643 
13644   ins_encode %{
13645     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13646   %}
13647 
13648   ins_pipe(fp_d2l);
13649 %}
13650 
13651 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13652   match(Set dst (ConvI2D src));
13653 
13654   ins_cost(INSN_COST * 5);
13655   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13656 
13657   ins_encode %{
13658     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13659   %}
13660 
13661   ins_pipe(fp_i2d);
13662 %}
13663 
13664 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13665   match(Set dst (ConvL2D src));
13666 
13667   ins_cost(INSN_COST * 5);
13668   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13669 
13670   ins_encode %{
13671     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13672   %}
13673 
13674   ins_pipe(fp_l2d);
13675 %}
13676 
13677 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13678 
13679 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13680 
13681   match(Set dst (MoveF2I src));
13682 
13683   effect(DEF dst, USE src);
13684 
13685   ins_cost(4 * INSN_COST);
13686 
13687   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13688 
13689   ins_encode %{
13690     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13691   %}
13692 
13693   ins_pipe(iload_reg_reg);
13694 
13695 %}
13696 
13697 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13698 
13699   match(Set dst (MoveI2F src));
13700 
13701   effect(DEF dst, USE src);
13702 
13703   ins_cost(4 * INSN_COST);
13704 
13705   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13706 
13707   ins_encode %{
13708     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13709   %}
13710 
13711   ins_pipe(pipe_class_memory);
13712 
13713 %}
13714 
13715 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13716 
13717   match(Set dst (MoveD2L src));
13718 
13719   effect(DEF dst, USE src);
13720 
13721   ins_cost(4 * INSN_COST);
13722 
13723   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13724 
13725   ins_encode %{
13726     __ ldr($dst$$Register, Address(sp, $src$$disp));
13727   %}
13728 
13729   ins_pipe(iload_reg_reg);
13730 
13731 %}
13732 
13733 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13734 
13735   match(Set dst (MoveL2D src));
13736 
13737   effect(DEF dst, USE src);
13738 
13739   ins_cost(4 * INSN_COST);
13740 
13741   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13742 
13743   ins_encode %{
13744     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13745   %}
13746 
13747   ins_pipe(pipe_class_memory);
13748 
13749 %}
13750 
13751 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13752 
13753   match(Set dst (MoveF2I src));
13754 
13755   effect(DEF dst, USE src);
13756 
13757   ins_cost(INSN_COST);
13758 
13759   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13760 
13761   ins_encode %{
13762     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13763   %}
13764 
13765   ins_pipe(pipe_class_memory);
13766 
13767 %}
13768 
13769 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13770 
13771   match(Set dst (MoveI2F src));
13772 
13773   effect(DEF dst, USE src);
13774 
13775   ins_cost(INSN_COST);
13776 
13777   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13778 
13779   ins_encode %{
13780     __ strw($src$$Register, Address(sp, $dst$$disp));
13781   %}
13782 
13783   ins_pipe(istore_reg_reg);
13784 
13785 %}
13786 
13787 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13788 
13789   match(Set dst (MoveD2L src));
13790 
13791   effect(DEF dst, USE src);
13792 
13793   ins_cost(INSN_COST);
13794 
13795   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13796 
13797   ins_encode %{
13798     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13799   %}
13800 
13801   ins_pipe(pipe_class_memory);
13802 
13803 %}
13804 
13805 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13806 
13807   match(Set dst (MoveL2D src));
13808 
13809   effect(DEF dst, USE src);
13810 
13811   ins_cost(INSN_COST);
13812 
13813   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13814 
13815   ins_encode %{
13816     __ str($src$$Register, Address(sp, $dst$$disp));
13817   %}
13818 
13819   ins_pipe(istore_reg_reg);
13820 
13821 %}
13822 
13823 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13824 
13825   match(Set dst (MoveF2I src));
13826 
13827   effect(DEF dst, USE src);
13828 
13829   ins_cost(INSN_COST);
13830 
13831   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13832 
13833   ins_encode %{
13834     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13835   %}
13836 
13837   ins_pipe(fp_f2i);
13838 
13839 %}
13840 
13841 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13842 
13843   match(Set dst (MoveI2F src));
13844 
13845   effect(DEF dst, USE src);
13846 
13847   ins_cost(INSN_COST);
13848 
13849   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13850 
13851   ins_encode %{
13852     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13853   %}
13854 
13855   ins_pipe(fp_i2f);
13856 
13857 %}
13858 
13859 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13860 
13861   match(Set dst (MoveD2L src));
13862 
13863   effect(DEF dst, USE src);
13864 
13865   ins_cost(INSN_COST);
13866 
13867   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13868 
13869   ins_encode %{
13870     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13871   %}
13872 
13873   ins_pipe(fp_d2l);
13874 
13875 %}
13876 
13877 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13878 
13879   match(Set dst (MoveL2D src));
13880 
13881   effect(DEF dst, USE src);
13882 
13883   ins_cost(INSN_COST);
13884 
13885   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13886 
13887   ins_encode %{
13888     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13889   %}
13890 
13891   ins_pipe(fp_l2d);
13892 
13893 %}
13894 
13895 // ============================================================================
13896 // clearing of an array
13897 
13898 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)
13899 %{
13900   match(Set dummy (ClearArray (Binary cnt base) val));
13901   effect(USE_KILL cnt, USE_KILL base);
13902 
13903   ins_cost(4 * INSN_COST);
13904   format %{ &quot;ClearArray $cnt, $base, $val&quot; %}
13905 
13906   ins_encode %{
13907     __ fill_words($base$$Register, $cnt$$Register, $val$$Register);
13908   %}
13909 
13910   ins_pipe(pipe_class_memory);
13911 %}
13912 
13913 // ============================================================================
13914 // Overflow Math Instructions
13915 
13916 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13917 %{
13918   match(Set cr (OverflowAddI op1 op2));
13919 
13920   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13921   ins_cost(INSN_COST);
13922   ins_encode %{
13923     __ cmnw($op1$$Register, $op2$$Register);
13924   %}
13925 
13926   ins_pipe(icmp_reg_reg);
13927 %}
13928 
13929 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13930 %{
13931   match(Set cr (OverflowAddI op1 op2));
13932 
13933   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13934   ins_cost(INSN_COST);
13935   ins_encode %{
13936     __ cmnw($op1$$Register, $op2$$constant);
13937   %}
13938 
13939   ins_pipe(icmp_reg_imm);
13940 %}
13941 
13942 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13943 %{
13944   match(Set cr (OverflowAddL op1 op2));
13945 
13946   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13947   ins_cost(INSN_COST);
13948   ins_encode %{
13949     __ cmn($op1$$Register, $op2$$Register);
13950   %}
13951 
13952   ins_pipe(icmp_reg_reg);
13953 %}
13954 
13955 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13956 %{
13957   match(Set cr (OverflowAddL op1 op2));
13958 
13959   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13960   ins_cost(INSN_COST);
13961   ins_encode %{
13962     __ cmn($op1$$Register, $op2$$constant);
13963   %}
13964 
13965   ins_pipe(icmp_reg_imm);
13966 %}
13967 
13968 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13969 %{
13970   match(Set cr (OverflowSubI op1 op2));
13971 
13972   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13973   ins_cost(INSN_COST);
13974   ins_encode %{
13975     __ cmpw($op1$$Register, $op2$$Register);
13976   %}
13977 
13978   ins_pipe(icmp_reg_reg);
13979 %}
13980 
13981 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13982 %{
13983   match(Set cr (OverflowSubI op1 op2));
13984 
13985   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13986   ins_cost(INSN_COST);
13987   ins_encode %{
13988     __ cmpw($op1$$Register, $op2$$constant);
13989   %}
13990 
13991   ins_pipe(icmp_reg_imm);
13992 %}
13993 
13994 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13995 %{
13996   match(Set cr (OverflowSubL op1 op2));
13997 
13998   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
13999   ins_cost(INSN_COST);
14000   ins_encode %{
14001     __ cmp($op1$$Register, $op2$$Register);
14002   %}
14003 
14004   ins_pipe(icmp_reg_reg);
14005 %}
14006 
14007 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14008 %{
14009   match(Set cr (OverflowSubL op1 op2));
14010 
14011   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14012   ins_cost(INSN_COST);
14013   ins_encode %{
14014     __ subs(zr, $op1$$Register, $op2$$constant);
14015   %}
14016 
14017   ins_pipe(icmp_reg_imm);
14018 %}
14019 
14020 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14021 %{
14022   match(Set cr (OverflowSubI zero op1));
14023 
14024   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14025   ins_cost(INSN_COST);
14026   ins_encode %{
14027     __ cmpw(zr, $op1$$Register);
14028   %}
14029 
14030   ins_pipe(icmp_reg_imm);
14031 %}
14032 
14033 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14034 %{
14035   match(Set cr (OverflowSubL zero op1));
14036 
14037   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14038   ins_cost(INSN_COST);
14039   ins_encode %{
14040     __ cmp(zr, $op1$$Register);
14041   %}
14042 
14043   ins_pipe(icmp_reg_imm);
14044 %}
14045 
14046 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14047 %{
14048   match(Set cr (OverflowMulI op1 op2));
14049 
14050   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14051             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14052             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14053             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14054             &quot;cmpw  rscratch1, #1&quot; %}
14055   ins_cost(5 * INSN_COST);
14056   ins_encode %{
14057     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14058     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14059     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14060     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14061     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14062   %}
14063 
14064   ins_pipe(pipe_slow);
14065 %}
14066 
14067 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14068 %{
14069   match(If cmp (OverflowMulI op1 op2));
14070   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14071             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14072   effect(USE labl, KILL cr);
14073 
14074   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14075             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14076             &quot;b$cmp   $labl&quot; %}
14077   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14078   ins_encode %{
14079     Label* L = $labl$$label;
14080     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14081     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14082     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14083     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14084   %}
14085 
14086   ins_pipe(pipe_serial);
14087 %}
14088 
14089 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14090 %{
14091   match(Set cr (OverflowMulL op1 op2));
14092 
14093   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14094             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14095             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14096             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14097             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14098             &quot;cmpw  rscratch1, #1&quot; %}
14099   ins_cost(6 * INSN_COST);
14100   ins_encode %{
14101     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14102     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14103     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14104     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14105     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14106     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14107   %}
14108 
14109   ins_pipe(pipe_slow);
14110 %}
14111 
14112 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14113 %{
14114   match(If cmp (OverflowMulL op1 op2));
14115   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14116             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14117   effect(USE labl, KILL cr);
14118 
14119   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14120             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14121             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14122             &quot;b$cmp $labl&quot; %}
14123   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14124   ins_encode %{
14125     Label* L = $labl$$label;
14126     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14127     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14128     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14129     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14130     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14131   %}
14132 
14133   ins_pipe(pipe_serial);
14134 %}
14135 
14136 // ============================================================================
14137 // Compare Instructions
14138 
14139 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14140 %{
14141   match(Set cr (CmpI op1 op2));
14142 
14143   effect(DEF cr, USE op1, USE op2);
14144 
14145   ins_cost(INSN_COST);
14146   format %{ &quot;cmpw  $op1, $op2&quot; %}
14147 
14148   ins_encode(aarch64_enc_cmpw(op1, op2));
14149 
14150   ins_pipe(icmp_reg_reg);
14151 %}
14152 
14153 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14154 %{
14155   match(Set cr (CmpI op1 zero));
14156 
14157   effect(DEF cr, USE op1);
14158 
14159   ins_cost(INSN_COST);
14160   format %{ &quot;cmpw $op1, 0&quot; %}
14161 
14162   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14163 
14164   ins_pipe(icmp_reg_imm);
14165 %}
14166 
14167 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14168 %{
14169   match(Set cr (CmpI op1 op2));
14170 
14171   effect(DEF cr, USE op1);
14172 
14173   ins_cost(INSN_COST);
14174   format %{ &quot;cmpw  $op1, $op2&quot; %}
14175 
14176   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14177 
14178   ins_pipe(icmp_reg_imm);
14179 %}
14180 
14181 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14182 %{
14183   match(Set cr (CmpI op1 op2));
14184 
14185   effect(DEF cr, USE op1);
14186 
14187   ins_cost(INSN_COST * 2);
14188   format %{ &quot;cmpw  $op1, $op2&quot; %}
14189 
14190   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14191 
14192   ins_pipe(icmp_reg_imm);
14193 %}
14194 
14195 // Unsigned compare Instructions; really, same as signed compare
14196 // except it should only be used to feed an If or a CMovI which takes a
14197 // cmpOpU.
14198 
14199 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14200 %{
14201   match(Set cr (CmpU op1 op2));
14202 
14203   effect(DEF cr, USE op1, USE op2);
14204 
14205   ins_cost(INSN_COST);
14206   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14207 
14208   ins_encode(aarch64_enc_cmpw(op1, op2));
14209 
14210   ins_pipe(icmp_reg_reg);
14211 %}
14212 
14213 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14214 %{
14215   match(Set cr (CmpU op1 zero));
14216 
14217   effect(DEF cr, USE op1);
14218 
14219   ins_cost(INSN_COST);
14220   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14221 
14222   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14223 
14224   ins_pipe(icmp_reg_imm);
14225 %}
14226 
14227 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14228 %{
14229   match(Set cr (CmpU op1 op2));
14230 
14231   effect(DEF cr, USE op1);
14232 
14233   ins_cost(INSN_COST);
14234   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14235 
14236   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14237 
14238   ins_pipe(icmp_reg_imm);
14239 %}
14240 
14241 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14242 %{
14243   match(Set cr (CmpU op1 op2));
14244 
14245   effect(DEF cr, USE op1);
14246 
14247   ins_cost(INSN_COST * 2);
14248   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14249 
14250   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14251 
14252   ins_pipe(icmp_reg_imm);
14253 %}
14254 
14255 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14256 %{
14257   match(Set cr (CmpL op1 op2));
14258 
14259   effect(DEF cr, USE op1, USE op2);
14260 
14261   ins_cost(INSN_COST);
14262   format %{ &quot;cmp  $op1, $op2&quot; %}
14263 
14264   ins_encode(aarch64_enc_cmp(op1, op2));
14265 
14266   ins_pipe(icmp_reg_reg);
14267 %}
14268 
14269 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14270 %{
14271   match(Set cr (CmpL op1 zero));
14272 
14273   effect(DEF cr, USE op1);
14274 
14275   ins_cost(INSN_COST);
14276   format %{ &quot;tst  $op1&quot; %}
14277 
14278   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14279 
14280   ins_pipe(icmp_reg_imm);
14281 %}
14282 
14283 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14284 %{
14285   match(Set cr (CmpL op1 op2));
14286 
14287   effect(DEF cr, USE op1);
14288 
14289   ins_cost(INSN_COST);
14290   format %{ &quot;cmp  $op1, $op2&quot; %}
14291 
14292   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14293 
14294   ins_pipe(icmp_reg_imm);
14295 %}
14296 
14297 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14298 %{
14299   match(Set cr (CmpL op1 op2));
14300 
14301   effect(DEF cr, USE op1);
14302 
14303   ins_cost(INSN_COST * 2);
14304   format %{ &quot;cmp  $op1, $op2&quot; %}
14305 
14306   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14307 
14308   ins_pipe(icmp_reg_imm);
14309 %}
14310 
14311 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14312 %{
14313   match(Set cr (CmpUL op1 op2));
14314 
14315   effect(DEF cr, USE op1, USE op2);
14316 
14317   ins_cost(INSN_COST);
14318   format %{ &quot;cmp  $op1, $op2&quot; %}
14319 
14320   ins_encode(aarch64_enc_cmp(op1, op2));
14321 
14322   ins_pipe(icmp_reg_reg);
14323 %}
14324 
14325 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14326 %{
14327   match(Set cr (CmpUL op1 zero));
14328 
14329   effect(DEF cr, USE op1);
14330 
14331   ins_cost(INSN_COST);
14332   format %{ &quot;tst  $op1&quot; %}
14333 
14334   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14335 
14336   ins_pipe(icmp_reg_imm);
14337 %}
14338 
14339 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14340 %{
14341   match(Set cr (CmpUL op1 op2));
14342 
14343   effect(DEF cr, USE op1);
14344 
14345   ins_cost(INSN_COST);
14346   format %{ &quot;cmp  $op1, $op2&quot; %}
14347 
14348   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14349 
14350   ins_pipe(icmp_reg_imm);
14351 %}
14352 
14353 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14354 %{
14355   match(Set cr (CmpUL op1 op2));
14356 
14357   effect(DEF cr, USE op1);
14358 
14359   ins_cost(INSN_COST * 2);
14360   format %{ &quot;cmp  $op1, $op2&quot; %}
14361 
14362   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14363 
14364   ins_pipe(icmp_reg_imm);
14365 %}
14366 
14367 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14368 %{
14369   match(Set cr (CmpP op1 op2));
14370 
14371   effect(DEF cr, USE op1, USE op2);
14372 
14373   ins_cost(INSN_COST);
14374   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14375 
14376   ins_encode(aarch64_enc_cmpp(op1, op2));
14377 
14378   ins_pipe(icmp_reg_reg);
14379 %}
14380 
14381 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14382 %{
14383   match(Set cr (CmpN op1 op2));
14384 
14385   effect(DEF cr, USE op1, USE op2);
14386 
14387   ins_cost(INSN_COST);
14388   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14389 
14390   ins_encode(aarch64_enc_cmpn(op1, op2));
14391 
14392   ins_pipe(icmp_reg_reg);
14393 %}
14394 
14395 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14396 %{
14397   match(Set cr (CmpP op1 zero));
14398 
14399   effect(DEF cr, USE op1, USE zero);
14400 
14401   ins_cost(INSN_COST);
14402   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14403 
14404   ins_encode(aarch64_enc_testp(op1));
14405 
14406   ins_pipe(icmp_reg_imm);
14407 %}
14408 
14409 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14410 %{
14411   match(Set cr (CmpN op1 zero));
14412 
14413   effect(DEF cr, USE op1, USE zero);
14414 
14415   ins_cost(INSN_COST);
14416   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14417 
14418   ins_encode(aarch64_enc_testn(op1));
14419 
14420   ins_pipe(icmp_reg_imm);
14421 %}
14422 
14423 // FP comparisons
14424 //
14425 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14426 // using normal cmpOp. See declaration of rFlagsReg for details.
14427 
14428 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14429 %{
14430   match(Set cr (CmpF src1 src2));
14431 
14432   ins_cost(3 * INSN_COST);
14433   format %{ &quot;fcmps $src1, $src2&quot; %}
14434 
14435   ins_encode %{
14436     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14437   %}
14438 
14439   ins_pipe(pipe_class_compare);
14440 %}
14441 
14442 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14443 %{
14444   match(Set cr (CmpF src1 src2));
14445 
14446   ins_cost(3 * INSN_COST);
14447   format %{ &quot;fcmps $src1, 0.0&quot; %}
14448 
14449   ins_encode %{
14450     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14451   %}
14452 
14453   ins_pipe(pipe_class_compare);
14454 %}
14455 // FROM HERE
14456 
14457 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14458 %{
14459   match(Set cr (CmpD src1 src2));
14460 
14461   ins_cost(3 * INSN_COST);
14462   format %{ &quot;fcmpd $src1, $src2&quot; %}
14463 
14464   ins_encode %{
14465     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14466   %}
14467 
14468   ins_pipe(pipe_class_compare);
14469 %}
14470 
14471 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14472 %{
14473   match(Set cr (CmpD src1 src2));
14474 
14475   ins_cost(3 * INSN_COST);
14476   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14477 
14478   ins_encode %{
14479     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14480   %}
14481 
14482   ins_pipe(pipe_class_compare);
14483 %}
14484 
14485 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14486 %{
14487   match(Set dst (CmpF3 src1 src2));
14488   effect(KILL cr);
14489 
14490   ins_cost(5 * INSN_COST);
14491   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14492             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14493             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14494   %}
14495 
14496   ins_encode %{
14497     Label done;
14498     FloatRegister s1 = as_FloatRegister($src1$$reg);
14499     FloatRegister s2 = as_FloatRegister($src2$$reg);
14500     Register d = as_Register($dst$$reg);
14501     __ fcmps(s1, s2);
14502     // installs 0 if EQ else -1
14503     __ csinvw(d, zr, zr, Assembler::EQ);
14504     // keeps -1 if less or unordered else installs 1
14505     __ csnegw(d, d, d, Assembler::LT);
14506     __ bind(done);
14507   %}
14508 
14509   ins_pipe(pipe_class_default);
14510 
14511 %}
14512 
14513 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14514 %{
14515   match(Set dst (CmpD3 src1 src2));
14516   effect(KILL cr);
14517 
14518   ins_cost(5 * INSN_COST);
14519   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14520             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14521             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14522   %}
14523 
14524   ins_encode %{
14525     Label done;
14526     FloatRegister s1 = as_FloatRegister($src1$$reg);
14527     FloatRegister s2 = as_FloatRegister($src2$$reg);
14528     Register d = as_Register($dst$$reg);
14529     __ fcmpd(s1, s2);
14530     // installs 0 if EQ else -1
14531     __ csinvw(d, zr, zr, Assembler::EQ);
14532     // keeps -1 if less or unordered else installs 1
14533     __ csnegw(d, d, d, Assembler::LT);
14534     __ bind(done);
14535   %}
14536   ins_pipe(pipe_class_default);
14537 
14538 %}
14539 
14540 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14541 %{
14542   match(Set dst (CmpF3 src1 zero));
14543   effect(KILL cr);
14544 
14545   ins_cost(5 * INSN_COST);
14546   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14547             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14548             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14549   %}
14550 
14551   ins_encode %{
14552     Label done;
14553     FloatRegister s1 = as_FloatRegister($src1$$reg);
14554     Register d = as_Register($dst$$reg);
14555     __ fcmps(s1, 0.0);
14556     // installs 0 if EQ else -1
14557     __ csinvw(d, zr, zr, Assembler::EQ);
14558     // keeps -1 if less or unordered else installs 1
14559     __ csnegw(d, d, d, Assembler::LT);
14560     __ bind(done);
14561   %}
14562 
14563   ins_pipe(pipe_class_default);
14564 
14565 %}
14566 
14567 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14568 %{
14569   match(Set dst (CmpD3 src1 zero));
14570   effect(KILL cr);
14571 
14572   ins_cost(5 * INSN_COST);
14573   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14574             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14575             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14576   %}
14577 
14578   ins_encode %{
14579     Label done;
14580     FloatRegister s1 = as_FloatRegister($src1$$reg);
14581     Register d = as_Register($dst$$reg);
14582     __ fcmpd(s1, 0.0);
14583     // installs 0 if EQ else -1
14584     __ csinvw(d, zr, zr, Assembler::EQ);
14585     // keeps -1 if less or unordered else installs 1
14586     __ csnegw(d, d, d, Assembler::LT);
14587     __ bind(done);
14588   %}
14589   ins_pipe(pipe_class_default);
14590 
14591 %}
14592 
14593 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14594 %{
14595   match(Set dst (CmpLTMask p q));
14596   effect(KILL cr);
14597 
14598   ins_cost(3 * INSN_COST);
14599 
14600   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14601             &quot;csetw $dst, lt\n\t&quot;
14602             &quot;subw $dst, zr, $dst&quot;
14603   %}
14604 
14605   ins_encode %{
14606     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14607     __ csetw(as_Register($dst$$reg), Assembler::LT);
14608     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14609   %}
14610 
14611   ins_pipe(ialu_reg_reg);
14612 %}
14613 
14614 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14615 %{
14616   match(Set dst (CmpLTMask src zero));
14617   effect(KILL cr);
14618 
14619   ins_cost(INSN_COST);
14620 
14621   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14622 
14623   ins_encode %{
14624     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14625   %}
14626 
14627   ins_pipe(ialu_reg_shift);
14628 %}
14629 
14630 // ============================================================================
14631 // Max and Min
14632 
14633 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14634 %{
14635   effect( DEF dst, USE src1, USE src2, USE cr );
14636 
14637   ins_cost(INSN_COST * 2);
14638   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14639 
14640   ins_encode %{
14641     __ cselw(as_Register($dst$$reg),
14642              as_Register($src1$$reg),
14643              as_Register($src2$$reg),
14644              Assembler::LT);
14645   %}
14646 
14647   ins_pipe(icond_reg_reg);
14648 %}
14649 
14650 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14651 %{
14652   match(Set dst (MinI src1 src2));
14653   ins_cost(INSN_COST * 3);
14654 
14655   expand %{
14656     rFlagsReg cr;
14657     compI_reg_reg(cr, src1, src2);
14658     cmovI_reg_reg_lt(dst, src1, src2, cr);
14659   %}
14660 
14661 %}
14662 // FROM HERE
14663 
14664 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14665 %{
14666   effect( DEF dst, USE src1, USE src2, USE cr );
14667 
14668   ins_cost(INSN_COST * 2);
14669   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14670 
14671   ins_encode %{
14672     __ cselw(as_Register($dst$$reg),
14673              as_Register($src1$$reg),
14674              as_Register($src2$$reg),
14675              Assembler::GT);
14676   %}
14677 
14678   ins_pipe(icond_reg_reg);
14679 %}
14680 
14681 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14682 %{
14683   match(Set dst (MaxI src1 src2));
14684   ins_cost(INSN_COST * 3);
14685   expand %{
14686     rFlagsReg cr;
14687     compI_reg_reg(cr, src1, src2);
14688     cmovI_reg_reg_gt(dst, src1, src2, cr);
14689   %}
14690 %}
14691 
14692 // ============================================================================
14693 // Branch Instructions
14694 
14695 // Direct Branch.
14696 instruct branch(label lbl)
14697 %{
14698   match(Goto);
14699 
14700   effect(USE lbl);
14701 
14702   ins_cost(BRANCH_COST);
14703   format %{ &quot;b  $lbl&quot; %}
14704 
14705   ins_encode(aarch64_enc_b(lbl));
14706 
14707   ins_pipe(pipe_branch);
14708 %}
14709 
14710 // Conditional Near Branch
14711 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14712 %{
14713   // Same match rule as `branchConFar&#39;.
14714   match(If cmp cr);
14715 
14716   effect(USE lbl);
14717 
14718   ins_cost(BRANCH_COST);
14719   // If set to 1 this indicates that the current instruction is a
14720   // short variant of a long branch. This avoids using this
14721   // instruction in first-pass matching. It will then only be used in
14722   // the `Shorten_branches&#39; pass.
14723   // ins_short_branch(1);
14724   format %{ &quot;b$cmp  $lbl&quot; %}
14725 
14726   ins_encode(aarch64_enc_br_con(cmp, lbl));
14727 
14728   ins_pipe(pipe_branch_cond);
14729 %}
14730 
14731 // Conditional Near Branch Unsigned
14732 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14733 %{
14734   // Same match rule as `branchConFar&#39;.
14735   match(If cmp cr);
14736 
14737   effect(USE lbl);
14738 
14739   ins_cost(BRANCH_COST);
14740   // If set to 1 this indicates that the current instruction is a
14741   // short variant of a long branch. This avoids using this
14742   // instruction in first-pass matching. It will then only be used in
14743   // the `Shorten_branches&#39; pass.
14744   // ins_short_branch(1);
14745   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14746 
14747   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14748 
14749   ins_pipe(pipe_branch_cond);
14750 %}
14751 
14752 // Make use of CBZ and CBNZ.  These instructions, as well as being
14753 // shorter than (cmp; branch), have the additional benefit of not
14754 // killing the flags.
14755 
14756 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14757   match(If cmp (CmpI op1 op2));
14758   effect(USE labl);
14759 
14760   ins_cost(BRANCH_COST);
14761   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14762   ins_encode %{
14763     Label* L = $labl$$label;
14764     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14765     if (cond == Assembler::EQ)
14766       __ cbzw($op1$$Register, *L);
14767     else
14768       __ cbnzw($op1$$Register, *L);
14769   %}
14770   ins_pipe(pipe_cmp_branch);
14771 %}
14772 
14773 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14774   match(If cmp (CmpL op1 op2));
14775   effect(USE labl);
14776 
14777   ins_cost(BRANCH_COST);
14778   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14779   ins_encode %{
14780     Label* L = $labl$$label;
14781     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14782     if (cond == Assembler::EQ)
14783       __ cbz($op1$$Register, *L);
14784     else
14785       __ cbnz($op1$$Register, *L);
14786   %}
14787   ins_pipe(pipe_cmp_branch);
14788 %}
14789 
14790 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14791   match(If cmp (CmpP op1 op2));
14792   effect(USE labl);
14793 
14794   ins_cost(BRANCH_COST);
14795   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14796   ins_encode %{
14797     Label* L = $labl$$label;
14798     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14799     if (cond == Assembler::EQ)
14800       __ cbz($op1$$Register, *L);
14801     else
14802       __ cbnz($op1$$Register, *L);
14803   %}
14804   ins_pipe(pipe_cmp_branch);
14805 %}
14806 
14807 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14808   match(If cmp (CmpN op1 op2));
14809   effect(USE labl);
14810 
14811   ins_cost(BRANCH_COST);
14812   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14813   ins_encode %{
14814     Label* L = $labl$$label;
14815     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14816     if (cond == Assembler::EQ)
14817       __ cbzw($op1$$Register, *L);
14818     else
14819       __ cbnzw($op1$$Register, *L);
14820   %}
14821   ins_pipe(pipe_cmp_branch);
14822 %}
14823 
14824 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14825   match(If cmp (CmpP (DecodeN oop) zero));
14826   effect(USE labl);
14827 
14828   ins_cost(BRANCH_COST);
14829   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14830   ins_encode %{
14831     Label* L = $labl$$label;
14832     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14833     if (cond == Assembler::EQ)
14834       __ cbzw($oop$$Register, *L);
14835     else
14836       __ cbnzw($oop$$Register, *L);
14837   %}
14838   ins_pipe(pipe_cmp_branch);
14839 %}
14840 
14841 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14842   match(If cmp (CmpU op1 op2));
14843   effect(USE labl);
14844 
14845   ins_cost(BRANCH_COST);
14846   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14847   ins_encode %{
14848     Label* L = $labl$$label;
14849     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14850     if (cond == Assembler::EQ || cond == Assembler::LS)
14851       __ cbzw($op1$$Register, *L);
14852     else
14853       __ cbnzw($op1$$Register, *L);
14854   %}
14855   ins_pipe(pipe_cmp_branch);
14856 %}
14857 
14858 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14859   match(If cmp (CmpUL op1 op2));
14860   effect(USE labl);
14861 
14862   ins_cost(BRANCH_COST);
14863   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14864   ins_encode %{
14865     Label* L = $labl$$label;
14866     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14867     if (cond == Assembler::EQ || cond == Assembler::LS)
14868       __ cbz($op1$$Register, *L);
14869     else
14870       __ cbnz($op1$$Register, *L);
14871   %}
14872   ins_pipe(pipe_cmp_branch);
14873 %}
14874 
14875 // Test bit and Branch
14876 
14877 // Patterns for short (&lt; 32KiB) variants
14878 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14879   match(If cmp (CmpL op1 op2));
14880   effect(USE labl);
14881 
14882   ins_cost(BRANCH_COST);
14883   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14884   ins_encode %{
14885     Label* L = $labl$$label;
14886     Assembler::Condition cond =
14887       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14888     __ tbr(cond, $op1$$Register, 63, *L);
14889   %}
14890   ins_pipe(pipe_cmp_branch);
14891   ins_short_branch(1);
14892 %}
14893 
14894 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14895   match(If cmp (CmpI op1 op2));
14896   effect(USE labl);
14897 
14898   ins_cost(BRANCH_COST);
14899   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14900   ins_encode %{
14901     Label* L = $labl$$label;
14902     Assembler::Condition cond =
14903       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14904     __ tbr(cond, $op1$$Register, 31, *L);
14905   %}
14906   ins_pipe(pipe_cmp_branch);
14907   ins_short_branch(1);
14908 %}
14909 
14910 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14911   match(If cmp (CmpL (AndL op1 op2) op3));
14912   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14913   effect(USE labl);
14914 
14915   ins_cost(BRANCH_COST);
14916   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14917   ins_encode %{
14918     Label* L = $labl$$label;
14919     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14920     int bit = exact_log2_long($op2$$constant);
14921     __ tbr(cond, $op1$$Register, bit, *L);
14922   %}
14923   ins_pipe(pipe_cmp_branch);
14924   ins_short_branch(1);
14925 %}
14926 
14927 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14928   match(If cmp (CmpI (AndI op1 op2) op3));
14929   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14930   effect(USE labl);
14931 
14932   ins_cost(BRANCH_COST);
14933   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14934   ins_encode %{
14935     Label* L = $labl$$label;
14936     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14937     int bit = exact_log2((juint)$op2$$constant);
14938     __ tbr(cond, $op1$$Register, bit, *L);
14939   %}
14940   ins_pipe(pipe_cmp_branch);
14941   ins_short_branch(1);
14942 %}
14943 
14944 // And far variants
14945 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14946   match(If cmp (CmpL op1 op2));
14947   effect(USE labl);
14948 
14949   ins_cost(BRANCH_COST);
14950   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14951   ins_encode %{
14952     Label* L = $labl$$label;
14953     Assembler::Condition cond =
14954       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14955     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14956   %}
14957   ins_pipe(pipe_cmp_branch);
14958 %}
14959 
14960 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14961   match(If cmp (CmpI op1 op2));
14962   effect(USE labl);
14963 
14964   ins_cost(BRANCH_COST);
14965   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14966   ins_encode %{
14967     Label* L = $labl$$label;
14968     Assembler::Condition cond =
14969       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14970     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14971   %}
14972   ins_pipe(pipe_cmp_branch);
14973 %}
14974 
14975 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14976   match(If cmp (CmpL (AndL op1 op2) op3));
14977   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14978   effect(USE labl);
14979 
14980   ins_cost(BRANCH_COST);
14981   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14982   ins_encode %{
14983     Label* L = $labl$$label;
14984     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14985     int bit = exact_log2_long($op2$$constant);
14986     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14987   %}
14988   ins_pipe(pipe_cmp_branch);
14989 %}
14990 
14991 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14992   match(If cmp (CmpI (AndI op1 op2) op3));
14993   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14994   effect(USE labl);
14995 
14996   ins_cost(BRANCH_COST);
14997   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14998   ins_encode %{
14999     Label* L = $labl$$label;
15000     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15001     int bit = exact_log2((juint)$op2$$constant);
15002     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15003   %}
15004   ins_pipe(pipe_cmp_branch);
15005 %}
15006 
15007 // Test bits
15008 
15009 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15010   match(Set cr (CmpL (AndL op1 op2) op3));
15011   predicate(Assembler::operand_valid_for_logical_immediate
15012             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15013 
15014   ins_cost(INSN_COST);
15015   format %{ &quot;tst $op1, $op2 # long&quot; %}
15016   ins_encode %{
15017     __ tst($op1$$Register, $op2$$constant);
15018   %}
15019   ins_pipe(ialu_reg_reg);
15020 %}
15021 
15022 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15023   match(Set cr (CmpI (AndI op1 op2) op3));
15024   predicate(Assembler::operand_valid_for_logical_immediate
15025             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15026 
15027   ins_cost(INSN_COST);
15028   format %{ &quot;tst $op1, $op2 # int&quot; %}
15029   ins_encode %{
15030     __ tstw($op1$$Register, $op2$$constant);
15031   %}
15032   ins_pipe(ialu_reg_reg);
15033 %}
15034 
15035 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15036   match(Set cr (CmpL (AndL op1 op2) op3));
15037 
15038   ins_cost(INSN_COST);
15039   format %{ &quot;tst $op1, $op2 # long&quot; %}
15040   ins_encode %{
15041     __ tst($op1$$Register, $op2$$Register);
15042   %}
15043   ins_pipe(ialu_reg_reg);
15044 %}
15045 
15046 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15047   match(Set cr (CmpI (AndI op1 op2) op3));
15048 
15049   ins_cost(INSN_COST);
15050   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15051   ins_encode %{
15052     __ tstw($op1$$Register, $op2$$Register);
15053   %}
15054   ins_pipe(ialu_reg_reg);
15055 %}
15056 
15057 
15058 // Conditional Far Branch
15059 // Conditional Far Branch Unsigned
15060 // TODO: fixme
15061 
15062 // counted loop end branch near
15063 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15064 %{
15065   match(CountedLoopEnd cmp cr);
15066 
15067   effect(USE lbl);
15068 
15069   ins_cost(BRANCH_COST);
15070   // short variant.
15071   // ins_short_branch(1);
15072   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15073 
15074   ins_encode(aarch64_enc_br_con(cmp, lbl));
15075 
15076   ins_pipe(pipe_branch);
15077 %}
15078 
15079 // counted loop end branch near Unsigned
15080 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15081 %{
15082   match(CountedLoopEnd cmp cr);
15083 
15084   effect(USE lbl);
15085 
15086   ins_cost(BRANCH_COST);
15087   // short variant.
15088   // ins_short_branch(1);
15089   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15090 
15091   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15092 
15093   ins_pipe(pipe_branch);
15094 %}
15095 
15096 // counted loop end branch far
15097 // counted loop end branch far unsigned
15098 // TODO: fixme
15099 
15100 // ============================================================================
15101 // inlined locking and unlocking
15102 
15103 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15104 %{
15105   match(Set cr (FastLock object box));
15106   effect(TEMP tmp, TEMP tmp2);
15107 
15108   // TODO
15109   // identify correct cost
15110   ins_cost(5 * INSN_COST);
15111   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15112 
15113   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15114 
15115   ins_pipe(pipe_serial);
15116 %}
15117 
15118 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15119 %{
15120   match(Set cr (FastUnlock object box));
15121   effect(TEMP tmp, TEMP tmp2);
15122 
15123   ins_cost(5 * INSN_COST);
15124   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15125 
15126   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15127 
15128   ins_pipe(pipe_serial);
15129 %}
15130 
15131 
15132 // ============================================================================
15133 // Safepoint Instructions
15134 
15135 // TODO
15136 // provide a near and far version of this code
15137 
15138 instruct safePoint(rFlagsReg cr, iRegP poll)
15139 %{
15140   match(SafePoint poll);
15141   effect(KILL cr);
15142 
15143   format %{
15144     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15145   %}
15146   ins_encode %{
15147     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15148   %}
15149   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15150 %}
15151 
15152 
15153 // ============================================================================
15154 // Procedure Call/Return Instructions
15155 
15156 // Call Java Static Instruction
15157 
15158 instruct CallStaticJavaDirect(method meth)
15159 %{
15160   match(CallStaticJava);
15161 
15162   effect(USE meth);
15163 
15164   ins_cost(CALL_COST);
15165 
15166   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15167 
15168   ins_encode( aarch64_enc_java_static_call(meth),
15169               aarch64_enc_call_epilog );
15170 
15171   ins_pipe(pipe_class_call);
15172 %}
15173 
15174 // TO HERE
15175 
15176 // Call Java Dynamic Instruction
15177 instruct CallDynamicJavaDirect(method meth)
15178 %{
15179   match(CallDynamicJava);
15180 
15181   effect(USE meth);
15182 
15183   ins_cost(CALL_COST);
15184 
15185   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15186 
15187   ins_encode( aarch64_enc_java_dynamic_call(meth),
15188                aarch64_enc_call_epilog );
15189 
15190   ins_pipe(pipe_class_call);
15191 %}
15192 
15193 // Call Runtime Instruction
15194 
15195 instruct CallRuntimeDirect(method meth)
15196 %{
15197   match(CallRuntime);
15198 
15199   effect(USE meth);
15200 
15201   ins_cost(CALL_COST);
15202 
15203   format %{ &quot;CALL, runtime $meth&quot; %}
15204 
15205   ins_encode( aarch64_enc_java_to_runtime(meth) );
15206 
15207   ins_pipe(pipe_class_call);
15208 %}
15209 
15210 // Call Runtime Instruction
15211 
15212 instruct CallLeafDirect(method meth)
15213 %{
15214   match(CallLeaf);
15215 
15216   effect(USE meth);
15217 
15218   ins_cost(CALL_COST);
15219 
15220   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15221 
15222   ins_encode( aarch64_enc_java_to_runtime(meth) );
15223 
15224   ins_pipe(pipe_class_call);
15225 %}
15226 
15227 // Call Runtime Instruction
15228 
15229 instruct CallLeafNoFPDirect(method meth)
15230 %{
15231   match(CallLeafNoFP);
15232 
15233   effect(USE meth);
15234 
15235   ins_cost(CALL_COST);
15236 
15237   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15238 
15239   ins_encode( aarch64_enc_java_to_runtime(meth) );
15240 
15241   ins_pipe(pipe_class_call);
15242 %}
15243 
15244 // Tail Call; Jump from runtime stub to Java code.
15245 // Also known as an &#39;interprocedural jump&#39;.
15246 // Target of jump will eventually return to caller.
15247 // TailJump below removes the return address.
15248 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15249 %{
15250   match(TailCall jump_target method_oop);
15251 
15252   ins_cost(CALL_COST);
15253 
15254   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15255 
15256   ins_encode(aarch64_enc_tail_call(jump_target));
15257 
15258   ins_pipe(pipe_class_call);
15259 %}
15260 
15261 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15262 %{
15263   match(TailJump jump_target ex_oop);
15264 
15265   ins_cost(CALL_COST);
15266 
15267   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15268 
15269   ins_encode(aarch64_enc_tail_jmp(jump_target));
15270 
15271   ins_pipe(pipe_class_call);
15272 %}
15273 
15274 // Create exception oop: created by stack-crawling runtime code.
15275 // Created exception is now available to this handler, and is setup
15276 // just prior to jumping to this handler. No code emitted.
15277 // TODO check
15278 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15279 instruct CreateException(iRegP_R0 ex_oop)
15280 %{
15281   match(Set ex_oop (CreateEx));
15282 
15283   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15284 
15285   size(0);
15286 
15287   ins_encode( /*empty*/ );
15288 
15289   ins_pipe(pipe_class_empty);
15290 %}
15291 
15292 // Rethrow exception: The exception oop will come in the first
15293 // argument position. Then JUMP (not call) to the rethrow stub code.
15294 instruct RethrowException() %{
15295   match(Rethrow);
15296   ins_cost(CALL_COST);
15297 
15298   format %{ &quot;b rethrow_stub&quot; %}
15299 
15300   ins_encode( aarch64_enc_rethrow() );
15301 
15302   ins_pipe(pipe_class_call);
15303 %}
15304 
15305 
15306 // Return Instruction
15307 // epilog node loads ret address into lr as part of frame pop
15308 instruct Ret()
15309 %{
15310   match(Return);
15311 
15312   format %{ &quot;ret\t// return register&quot; %}
15313 
15314   ins_encode( aarch64_enc_ret() );
15315 
15316   ins_pipe(pipe_branch);
15317 %}
15318 
15319 // Die now.
15320 instruct ShouldNotReachHere() %{
15321   match(Halt);
15322 
15323   ins_cost(CALL_COST);
15324   format %{ &quot;ShouldNotReachHere&quot; %}
15325 
15326   ins_encode %{
15327     if (is_reachable()) {
15328       __ dcps1(0xdead + 1);
15329     }
15330   %}
15331 
15332   ins_pipe(pipe_class_default);
15333 %}
15334 
15335 // ============================================================================
15336 // Partial Subtype Check
15337 //
15338 // superklass array for an instance of the superklass.  Set a hidden
15339 // internal cache on a hit (cache is checked with exposed code in
15340 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15341 // encoding ALSO sets flags.
15342 
15343 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15344 %{
15345   match(Set result (PartialSubtypeCheck sub super));
15346   effect(KILL cr, KILL temp);
15347 
15348   ins_cost(1100);  // slightly larger than the next version
15349   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15350 
15351   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15352 
15353   opcode(0x1); // Force zero of result reg on hit
15354 
15355   ins_pipe(pipe_class_memory);
15356 %}
15357 
15358 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15359 %{
15360   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15361   effect(KILL temp, KILL result);
15362 
15363   ins_cost(1100);  // slightly larger than the next version
15364   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15365 
15366   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15367 
15368   opcode(0x0); // Don&#39;t zero result reg on hit
15369 
15370   ins_pipe(pipe_class_memory);
15371 %}
15372 
15373 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15374                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15375 %{
15376   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15377   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15378   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15379 
15380   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15381   ins_encode %{
15382     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15383     __ string_compare($str1$$Register, $str2$$Register,
15384                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15385                       $tmp1$$Register, $tmp2$$Register,
15386                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15387   %}
15388   ins_pipe(pipe_class_memory);
15389 %}
15390 
15391 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15392                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15393 %{
15394   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15395   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15396   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15397 
15398   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15399   ins_encode %{
15400     __ string_compare($str1$$Register, $str2$$Register,
15401                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15402                       $tmp1$$Register, $tmp2$$Register,
15403                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15404   %}
15405   ins_pipe(pipe_class_memory);
15406 %}
15407 
15408 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15409                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15410                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15411 %{
15412   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15413   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15414   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15415          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15416 
15417   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15418   ins_encode %{
15419     __ string_compare($str1$$Register, $str2$$Register,
15420                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15421                       $tmp1$$Register, $tmp2$$Register,
15422                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15423                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15424   %}
15425   ins_pipe(pipe_class_memory);
15426 %}
15427 
15428 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15429                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15430                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15431 %{
15432   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15433   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15434   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15435          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15436 
15437   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15438   ins_encode %{
15439     __ string_compare($str1$$Register, $str2$$Register,
15440                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15441                       $tmp1$$Register, $tmp2$$Register,
15442                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15443                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15444   %}
15445   ins_pipe(pipe_class_memory);
15446 %}
15447 
15448 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15449        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15450        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15451 %{
15452   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15453   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15454   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15455          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15456   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15457 
15458   ins_encode %{
15459     __ string_indexof($str1$$Register, $str2$$Register,
15460                       $cnt1$$Register, $cnt2$$Register,
15461                       $tmp1$$Register, $tmp2$$Register,
15462                       $tmp3$$Register, $tmp4$$Register,
15463                       $tmp5$$Register, $tmp6$$Register,
15464                       -1, $result$$Register, StrIntrinsicNode::UU);
15465   %}
15466   ins_pipe(pipe_class_memory);
15467 %}
15468 
15469 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15470        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15471        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15472 %{
15473   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15474   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15475   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15476          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15477   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15478 
15479   ins_encode %{
15480     __ string_indexof($str1$$Register, $str2$$Register,
15481                       $cnt1$$Register, $cnt2$$Register,
15482                       $tmp1$$Register, $tmp2$$Register,
15483                       $tmp3$$Register, $tmp4$$Register,
15484                       $tmp5$$Register, $tmp6$$Register,
15485                       -1, $result$$Register, StrIntrinsicNode::LL);
15486   %}
15487   ins_pipe(pipe_class_memory);
15488 %}
15489 
15490 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15491        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15492        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15493 %{
15494   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15495   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15496   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15497          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15498   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15499 
15500   ins_encode %{
15501     __ string_indexof($str1$$Register, $str2$$Register,
15502                       $cnt1$$Register, $cnt2$$Register,
15503                       $tmp1$$Register, $tmp2$$Register,
15504                       $tmp3$$Register, $tmp4$$Register,
15505                       $tmp5$$Register, $tmp6$$Register,
15506                       -1, $result$$Register, StrIntrinsicNode::UL);
15507   %}
15508   ins_pipe(pipe_class_memory);
15509 %}
15510 
15511 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15512                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15513                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15514 %{
15515   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15516   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15517   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15518          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15519   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15520 
15521   ins_encode %{
15522     int icnt2 = (int)$int_cnt2$$constant;
15523     __ string_indexof($str1$$Register, $str2$$Register,
15524                       $cnt1$$Register, zr,
15525                       $tmp1$$Register, $tmp2$$Register,
15526                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15527                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15528   %}
15529   ins_pipe(pipe_class_memory);
15530 %}
15531 
15532 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15533                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15534                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15535 %{
15536   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15537   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15538   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15539          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15540   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15541 
15542   ins_encode %{
15543     int icnt2 = (int)$int_cnt2$$constant;
15544     __ string_indexof($str1$$Register, $str2$$Register,
15545                       $cnt1$$Register, zr,
15546                       $tmp1$$Register, $tmp2$$Register,
15547                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15548                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15549   %}
15550   ins_pipe(pipe_class_memory);
15551 %}
15552 
15553 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15554                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15555                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15556 %{
15557   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15558   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15559   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15560          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15561   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15562 
15563   ins_encode %{
15564     int icnt2 = (int)$int_cnt2$$constant;
15565     __ string_indexof($str1$$Register, $str2$$Register,
15566                       $cnt1$$Register, zr,
15567                       $tmp1$$Register, $tmp2$$Register,
15568                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15569                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15570   %}
15571   ins_pipe(pipe_class_memory);
15572 %}
15573 
15574 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15575                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15576                               iRegINoSp tmp3, rFlagsReg cr)
15577 %{
15578   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15579   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15580          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15581 
15582   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15583 
15584   ins_encode %{
15585     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15586                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15587                            $tmp3$$Register);
15588   %}
15589   ins_pipe(pipe_class_memory);
15590 %}
15591 
15592 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15593                         iRegI_R0 result, rFlagsReg cr)
15594 %{
15595   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15596   match(Set result (StrEquals (Binary str1 str2) cnt));
15597   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15598 
15599   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15600   ins_encode %{
15601     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15602     __ string_equals($str1$$Register, $str2$$Register,
15603                      $result$$Register, $cnt$$Register, 1);
15604   %}
15605   ins_pipe(pipe_class_memory);
15606 %}
15607 
15608 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15609                         iRegI_R0 result, rFlagsReg cr)
15610 %{
15611   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15612   match(Set result (StrEquals (Binary str1 str2) cnt));
15613   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15614 
15615   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15616   ins_encode %{
15617     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15618     __ string_equals($str1$$Register, $str2$$Register,
15619                      $result$$Register, $cnt$$Register, 2);
15620   %}
15621   ins_pipe(pipe_class_memory);
15622 %}
15623 
15624 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15625                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15626                        iRegP_R10 tmp, rFlagsReg cr)
15627 %{
15628   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15629   match(Set result (AryEq ary1 ary2));
15630   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15631 
15632   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15633   ins_encode %{
15634     __ arrays_equals($ary1$$Register, $ary2$$Register,
15635                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15636                      $result$$Register, $tmp$$Register, 1);
15637     %}
15638   ins_pipe(pipe_class_memory);
15639 %}
15640 
15641 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15642                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15643                        iRegP_R10 tmp, rFlagsReg cr)
15644 %{
15645   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15646   match(Set result (AryEq ary1 ary2));
15647   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15648 
15649   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15650   ins_encode %{
15651     __ arrays_equals($ary1$$Register, $ary2$$Register,
15652                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15653                      $result$$Register, $tmp$$Register, 2);
15654   %}
15655   ins_pipe(pipe_class_memory);
15656 %}
15657 
15658 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15659 %{
15660   match(Set result (HasNegatives ary1 len));
15661   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15662   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15663   ins_encode %{
15664     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15665   %}
15666   ins_pipe( pipe_slow );
15667 %}
15668 
15669 // fast char[] to byte[] compression
15670 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15671                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15672                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15673                          iRegI_R0 result, rFlagsReg cr)
15674 %{
15675   match(Set result (StrCompressedCopy src (Binary dst len)));
15676   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15677 
15678   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15679   ins_encode %{
15680     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15681                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15682                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15683                            $result$$Register);
15684   %}
15685   ins_pipe( pipe_slow );
15686 %}
15687 
15688 // fast byte[] to char[] inflation
15689 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15690                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15691 %{
15692   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15693   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15694 
15695   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15696   ins_encode %{
15697     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15698                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15699   %}
15700   ins_pipe(pipe_class_memory);
15701 %}
15702 
15703 // encode char[] to byte[] in ISO_8859_1
15704 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15705                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15706                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15707                           iRegI_R0 result, rFlagsReg cr)
15708 %{
15709   match(Set result (EncodeISOArray src (Binary dst len)));
15710   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15711          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15712 
15713   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15714   ins_encode %{
15715     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15716          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15717          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15718   %}
15719   ins_pipe( pipe_class_memory );
15720 %}
15721 
15722 // ============================================================================
15723 // This name is KNOWN by the ADLC and cannot be changed.
15724 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15725 // for this guy.
15726 instruct tlsLoadP(thread_RegP dst)
15727 %{
15728   match(Set dst (ThreadLocal));
15729 
15730   ins_cost(0);
15731 
15732   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15733 
15734   size(0);
15735 
15736   ins_encode( /*empty*/ );
15737 
15738   ins_pipe(pipe_class_empty);
15739 %}
15740 
15741 // ====================VECTOR INSTRUCTIONS=====================================
15742 
15743 // Load vector (32 bits)
15744 instruct loadV4(vecD dst, vmem4 mem)
15745 %{
15746   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15747   match(Set dst (LoadVector mem));
15748   ins_cost(4 * INSN_COST);
15749   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15750   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15751   ins_pipe(vload_reg_mem64);
15752 %}
15753 
15754 // Load vector (64 bits)
15755 instruct loadV8(vecD dst, vmem8 mem)
15756 %{
15757   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15758   match(Set dst (LoadVector mem));
15759   ins_cost(4 * INSN_COST);
15760   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15761   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15762   ins_pipe(vload_reg_mem64);
15763 %}
15764 
15765 // Load Vector (128 bits)
15766 instruct loadV16(vecX dst, vmem16 mem)
15767 %{
15768   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15769   match(Set dst (LoadVector mem));
15770   ins_cost(4 * INSN_COST);
15771   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15772   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15773   ins_pipe(vload_reg_mem128);
15774 %}
15775 
15776 // Store Vector (32 bits)
15777 instruct storeV4(vecD src, vmem4 mem)
15778 %{
15779   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15780   match(Set mem (StoreVector mem src));
15781   ins_cost(4 * INSN_COST);
15782   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15783   ins_encode( aarch64_enc_strvS(src, mem) );
15784   ins_pipe(vstore_reg_mem64);
15785 %}
15786 
15787 // Store Vector (64 bits)
15788 instruct storeV8(vecD src, vmem8 mem)
15789 %{
15790   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15791   match(Set mem (StoreVector mem src));
15792   ins_cost(4 * INSN_COST);
15793   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15794   ins_encode( aarch64_enc_strvD(src, mem) );
15795   ins_pipe(vstore_reg_mem64);
15796 %}
15797 
15798 // Store Vector (128 bits)
15799 instruct storeV16(vecX src, vmem16 mem)
15800 %{
15801   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15802   match(Set mem (StoreVector mem src));
15803   ins_cost(4 * INSN_COST);
15804   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15805   ins_encode( aarch64_enc_strvQ(src, mem) );
15806   ins_pipe(vstore_reg_mem128);
15807 %}
15808 
15809 instruct replicate8B(vecD dst, iRegIorL2I src)
15810 %{
15811   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15812             n-&gt;as_Vector()-&gt;length() == 8);
15813   match(Set dst (ReplicateB src));
15814   ins_cost(INSN_COST);
15815   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15816   ins_encode %{
15817     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15818   %}
15819   ins_pipe(vdup_reg_reg64);
15820 %}
15821 
15822 instruct replicate16B(vecX dst, iRegIorL2I src)
15823 %{
15824   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15825   match(Set dst (ReplicateB src));
15826   ins_cost(INSN_COST);
15827   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15828   ins_encode %{
15829     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15830   %}
15831   ins_pipe(vdup_reg_reg128);
15832 %}
15833 
15834 instruct replicate8B_imm(vecD dst, immI con)
15835 %{
15836   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15837             n-&gt;as_Vector()-&gt;length() == 8);
15838   match(Set dst (ReplicateB con));
15839   ins_cost(INSN_COST);
15840   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15841   ins_encode %{
15842     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15843   %}
15844   ins_pipe(vmovi_reg_imm64);
15845 %}
15846 
15847 instruct replicate16B_imm(vecX dst, immI con)
15848 %{
15849   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15850   match(Set dst (ReplicateB con));
15851   ins_cost(INSN_COST);
15852   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15853   ins_encode %{
15854     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15855   %}
15856   ins_pipe(vmovi_reg_imm128);
15857 %}
15858 
15859 instruct replicate4S(vecD dst, iRegIorL2I src)
15860 %{
15861   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15862             n-&gt;as_Vector()-&gt;length() == 4);
15863   match(Set dst (ReplicateS src));
15864   ins_cost(INSN_COST);
15865   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15866   ins_encode %{
15867     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15868   %}
15869   ins_pipe(vdup_reg_reg64);
15870 %}
15871 
15872 instruct replicate8S(vecX dst, iRegIorL2I src)
15873 %{
15874   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15875   match(Set dst (ReplicateS src));
15876   ins_cost(INSN_COST);
15877   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15878   ins_encode %{
15879     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15880   %}
15881   ins_pipe(vdup_reg_reg128);
15882 %}
15883 
15884 instruct replicate4S_imm(vecD dst, immI con)
15885 %{
15886   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15887             n-&gt;as_Vector()-&gt;length() == 4);
15888   match(Set dst (ReplicateS con));
15889   ins_cost(INSN_COST);
15890   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15891   ins_encode %{
15892     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15893   %}
15894   ins_pipe(vmovi_reg_imm64);
15895 %}
15896 
15897 instruct replicate8S_imm(vecX dst, immI con)
15898 %{
15899   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15900   match(Set dst (ReplicateS con));
15901   ins_cost(INSN_COST);
15902   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15903   ins_encode %{
15904     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15905   %}
15906   ins_pipe(vmovi_reg_imm128);
15907 %}
15908 
15909 instruct replicate2I(vecD dst, iRegIorL2I src)
15910 %{
15911   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15912   match(Set dst (ReplicateI src));
15913   ins_cost(INSN_COST);
15914   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15915   ins_encode %{
15916     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15917   %}
15918   ins_pipe(vdup_reg_reg64);
15919 %}
15920 
15921 instruct replicate4I(vecX dst, iRegIorL2I src)
15922 %{
15923   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15924   match(Set dst (ReplicateI src));
15925   ins_cost(INSN_COST);
15926   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15927   ins_encode %{
15928     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15929   %}
15930   ins_pipe(vdup_reg_reg128);
15931 %}
15932 
15933 instruct replicate2I_imm(vecD dst, immI con)
15934 %{
15935   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15936   match(Set dst (ReplicateI con));
15937   ins_cost(INSN_COST);
15938   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15939   ins_encode %{
15940     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15941   %}
15942   ins_pipe(vmovi_reg_imm64);
15943 %}
15944 
15945 instruct replicate4I_imm(vecX dst, immI con)
15946 %{
15947   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15948   match(Set dst (ReplicateI con));
15949   ins_cost(INSN_COST);
15950   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15951   ins_encode %{
15952     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15953   %}
15954   ins_pipe(vmovi_reg_imm128);
15955 %}
15956 
15957 instruct replicate2L(vecX dst, iRegL src)
15958 %{
15959   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15960   match(Set dst (ReplicateL src));
15961   ins_cost(INSN_COST);
15962   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15963   ins_encode %{
15964     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15965   %}
15966   ins_pipe(vdup_reg_reg128);
15967 %}
15968 
15969 instruct replicate2L_zero(vecX dst, immI0 zero)
15970 %{
15971   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15972   match(Set dst (ReplicateI zero));
15973   ins_cost(INSN_COST);
15974   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15975   ins_encode %{
15976     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15977            as_FloatRegister($dst$$reg),
15978            as_FloatRegister($dst$$reg));
15979   %}
15980   ins_pipe(vmovi_reg_imm128);
15981 %}
15982 
15983 instruct replicate2F(vecD dst, vRegF src)
15984 %{
15985   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15986   match(Set dst (ReplicateF src));
15987   ins_cost(INSN_COST);
15988   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15989   ins_encode %{
15990     __ dup(as_FloatRegister($dst$$reg), __ T2S,
15991            as_FloatRegister($src$$reg));
15992   %}
15993   ins_pipe(vdup_reg_freg64);
15994 %}
15995 
15996 instruct replicate4F(vecX dst, vRegF src)
15997 %{
15998   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15999   match(Set dst (ReplicateF src));
16000   ins_cost(INSN_COST);
16001   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16002   ins_encode %{
16003     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16004            as_FloatRegister($src$$reg));
16005   %}
16006   ins_pipe(vdup_reg_freg128);
16007 %}
16008 
16009 instruct replicate2D(vecX dst, vRegD src)
16010 %{
16011   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16012   match(Set dst (ReplicateD src));
16013   ins_cost(INSN_COST);
16014   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16015   ins_encode %{
16016     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16017            as_FloatRegister($src$$reg));
16018   %}
16019   ins_pipe(vdup_reg_dreg128);
16020 %}
16021 
16022 // ====================REDUCTION ARITHMETIC====================================
16023 
16024 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
16025 %{
16026   match(Set dst (AddReductionVI isrc vsrc));
16027   ins_cost(INSN_COST);
16028   effect(TEMP tmp, TEMP tmp2);
16029   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16030             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16031             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16032             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16033   %}
16034   ins_encode %{
16035     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16036     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16037     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16038     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16039   %}
16040   ins_pipe(pipe_class_default);
16041 %}
16042 
16043 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16044 %{
16045   match(Set dst (AddReductionVI isrc vsrc));
16046   ins_cost(INSN_COST);
16047   effect(TEMP vtmp, TEMP itmp);
16048   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16049             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16050             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16051   %}
16052   ins_encode %{
16053     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16054             as_FloatRegister($vsrc$$reg));
16055     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16056     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16057   %}
16058   ins_pipe(pipe_class_default);
16059 %}
16060 
16061 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16062 %{
16063   match(Set dst (MulReductionVI isrc vsrc));
16064   ins_cost(INSN_COST);
16065   effect(TEMP tmp, TEMP dst);
16066   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16067             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16068             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16069             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16070   %}
16071   ins_encode %{
16072     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16073     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16074     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16075     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16076   %}
16077   ins_pipe(pipe_class_default);
16078 %}
16079 
16080 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16081 %{
16082   match(Set dst (MulReductionVI isrc vsrc));
16083   ins_cost(INSN_COST);
16084   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16085   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16086             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16087             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16088             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16089             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16090             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16091   %}
16092   ins_encode %{
16093     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16094            as_FloatRegister($vsrc$$reg), 0, 1);
16095     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16096             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16097     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16098     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16099     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16100     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16101   %}
16102   ins_pipe(pipe_class_default);
16103 %}
16104 
16105 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16106 %{
16107   match(Set dst (AddReductionVF fsrc vsrc));
16108   ins_cost(INSN_COST);
16109   effect(TEMP tmp, TEMP dst);
16110   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16111             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16112             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16113   %}
16114   ins_encode %{
16115     __ fadds(as_FloatRegister($dst$$reg),
16116              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16117     __ ins(as_FloatRegister($tmp$$reg), __ S,
16118            as_FloatRegister($vsrc$$reg), 0, 1);
16119     __ fadds(as_FloatRegister($dst$$reg),
16120              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16121   %}
16122   ins_pipe(pipe_class_default);
16123 %}
16124 
16125 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16126 %{
16127   match(Set dst (AddReductionVF fsrc vsrc));
16128   ins_cost(INSN_COST);
16129   effect(TEMP tmp, TEMP dst);
16130   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16131             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16132             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16133             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16134             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16135             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16136             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16137   %}
16138   ins_encode %{
16139     __ fadds(as_FloatRegister($dst$$reg),
16140              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16141     __ ins(as_FloatRegister($tmp$$reg), __ S,
16142            as_FloatRegister($vsrc$$reg), 0, 1);
16143     __ fadds(as_FloatRegister($dst$$reg),
16144              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16145     __ ins(as_FloatRegister($tmp$$reg), __ S,
16146            as_FloatRegister($vsrc$$reg), 0, 2);
16147     __ fadds(as_FloatRegister($dst$$reg),
16148              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16149     __ ins(as_FloatRegister($tmp$$reg), __ S,
16150            as_FloatRegister($vsrc$$reg), 0, 3);
16151     __ fadds(as_FloatRegister($dst$$reg),
16152              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16153   %}
16154   ins_pipe(pipe_class_default);
16155 %}
16156 
16157 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16158 %{
16159   match(Set dst (MulReductionVF fsrc vsrc));
16160   ins_cost(INSN_COST);
16161   effect(TEMP tmp, TEMP dst);
16162   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16163             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16164             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16165   %}
16166   ins_encode %{
16167     __ fmuls(as_FloatRegister($dst$$reg),
16168              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16169     __ ins(as_FloatRegister($tmp$$reg), __ S,
16170            as_FloatRegister($vsrc$$reg), 0, 1);
16171     __ fmuls(as_FloatRegister($dst$$reg),
16172              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16173   %}
16174   ins_pipe(pipe_class_default);
16175 %}
16176 
16177 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16178 %{
16179   match(Set dst (MulReductionVF fsrc vsrc));
16180   ins_cost(INSN_COST);
16181   effect(TEMP tmp, TEMP dst);
16182   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16183             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16184             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16185             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16186             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16187             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16188             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16189   %}
16190   ins_encode %{
16191     __ fmuls(as_FloatRegister($dst$$reg),
16192              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16193     __ ins(as_FloatRegister($tmp$$reg), __ S,
16194            as_FloatRegister($vsrc$$reg), 0, 1);
16195     __ fmuls(as_FloatRegister($dst$$reg),
16196              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16197     __ ins(as_FloatRegister($tmp$$reg), __ S,
16198            as_FloatRegister($vsrc$$reg), 0, 2);
16199     __ fmuls(as_FloatRegister($dst$$reg),
16200              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16201     __ ins(as_FloatRegister($tmp$$reg), __ S,
16202            as_FloatRegister($vsrc$$reg), 0, 3);
16203     __ fmuls(as_FloatRegister($dst$$reg),
16204              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16205   %}
16206   ins_pipe(pipe_class_default);
16207 %}
16208 
16209 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16210 %{
16211   match(Set dst (AddReductionVD dsrc vsrc));
16212   ins_cost(INSN_COST);
16213   effect(TEMP tmp, TEMP dst);
16214   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16215             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16216             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16217   %}
16218   ins_encode %{
16219     __ faddd(as_FloatRegister($dst$$reg),
16220              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16221     __ ins(as_FloatRegister($tmp$$reg), __ D,
16222            as_FloatRegister($vsrc$$reg), 0, 1);
16223     __ faddd(as_FloatRegister($dst$$reg),
16224              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16225   %}
16226   ins_pipe(pipe_class_default);
16227 %}
16228 
16229 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16230 %{
16231   match(Set dst (MulReductionVD dsrc vsrc));
16232   ins_cost(INSN_COST);
16233   effect(TEMP tmp, TEMP dst);
16234   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16235             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16236             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16237   %}
16238   ins_encode %{
16239     __ fmuld(as_FloatRegister($dst$$reg),
16240              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16241     __ ins(as_FloatRegister($tmp$$reg), __ D,
16242            as_FloatRegister($vsrc$$reg), 0, 1);
16243     __ fmuld(as_FloatRegister($dst$$reg),
16244              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16245   %}
16246   ins_pipe(pipe_class_default);
16247 %}
16248 
16249 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16250   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16251   match(Set dst (MaxReductionV fsrc vsrc));
16252   ins_cost(INSN_COST);
16253   effect(TEMP_DEF dst, TEMP tmp);
16254   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16255             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16256             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16257   ins_encode %{
16258     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16259     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16260     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16261   %}
16262   ins_pipe(pipe_class_default);
16263 %}
16264 
16265 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16266   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16267   match(Set dst (MaxReductionV fsrc vsrc));
16268   ins_cost(INSN_COST);
16269   effect(TEMP_DEF dst);
16270   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16271             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16272   ins_encode %{
16273     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16274     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16275   %}
16276   ins_pipe(pipe_class_default);
16277 %}
16278 
16279 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16280   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16281   match(Set dst (MaxReductionV dsrc vsrc));
16282   ins_cost(INSN_COST);
16283   effect(TEMP_DEF dst, TEMP tmp);
16284   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16285             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16286             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16287   ins_encode %{
16288     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16289     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16290     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16291   %}
16292   ins_pipe(pipe_class_default);
16293 %}
16294 
16295 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16296   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16297   match(Set dst (MinReductionV fsrc vsrc));
16298   ins_cost(INSN_COST);
16299   effect(TEMP_DEF dst, TEMP tmp);
16300   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16301             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16302             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16303   ins_encode %{
16304     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16305     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16306     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16307   %}
16308   ins_pipe(pipe_class_default);
16309 %}
16310 
16311 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16312   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16313   match(Set dst (MinReductionV fsrc vsrc));
16314   ins_cost(INSN_COST);
16315   effect(TEMP_DEF dst);
16316   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16317             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16318   ins_encode %{
16319     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16320     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16321   %}
16322   ins_pipe(pipe_class_default);
16323 %}
16324 
16325 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16326   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16327   match(Set dst (MinReductionV dsrc vsrc));
16328   ins_cost(INSN_COST);
16329   effect(TEMP_DEF dst, TEMP tmp);
16330   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16331             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16332             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16333   ins_encode %{
16334     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16335     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16336     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16337   %}
16338   ins_pipe(pipe_class_default);
16339 %}
16340 
16341 // ====================VECTOR ARITHMETIC=======================================
16342 
16343 // --------------------------------- ADD --------------------------------------
16344 
16345 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16346 %{
16347   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16348             n-&gt;as_Vector()-&gt;length() == 8);
16349   match(Set dst (AddVB src1 src2));
16350   ins_cost(INSN_COST);
16351   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16352   ins_encode %{
16353     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16354             as_FloatRegister($src1$$reg),
16355             as_FloatRegister($src2$$reg));
16356   %}
16357   ins_pipe(vdop64);
16358 %}
16359 
16360 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16361 %{
16362   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16363   match(Set dst (AddVB src1 src2));
16364   ins_cost(INSN_COST);
16365   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16366   ins_encode %{
16367     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16368             as_FloatRegister($src1$$reg),
16369             as_FloatRegister($src2$$reg));
16370   %}
16371   ins_pipe(vdop128);
16372 %}
16373 
16374 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16375 %{
16376   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16377             n-&gt;as_Vector()-&gt;length() == 4);
16378   match(Set dst (AddVS src1 src2));
16379   ins_cost(INSN_COST);
16380   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16381   ins_encode %{
16382     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16383             as_FloatRegister($src1$$reg),
16384             as_FloatRegister($src2$$reg));
16385   %}
16386   ins_pipe(vdop64);
16387 %}
16388 
16389 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16390 %{
16391   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16392   match(Set dst (AddVS src1 src2));
16393   ins_cost(INSN_COST);
16394   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16395   ins_encode %{
16396     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16397             as_FloatRegister($src1$$reg),
16398             as_FloatRegister($src2$$reg));
16399   %}
16400   ins_pipe(vdop128);
16401 %}
16402 
16403 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16404 %{
16405   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16406   match(Set dst (AddVI src1 src2));
16407   ins_cost(INSN_COST);
16408   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16409   ins_encode %{
16410     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16411             as_FloatRegister($src1$$reg),
16412             as_FloatRegister($src2$$reg));
16413   %}
16414   ins_pipe(vdop64);
16415 %}
16416 
16417 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16418 %{
16419   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16420   match(Set dst (AddVI src1 src2));
16421   ins_cost(INSN_COST);
16422   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16423   ins_encode %{
16424     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16425             as_FloatRegister($src1$$reg),
16426             as_FloatRegister($src2$$reg));
16427   %}
16428   ins_pipe(vdop128);
16429 %}
16430 
16431 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16432 %{
16433   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16434   match(Set dst (AddVL src1 src2));
16435   ins_cost(INSN_COST);
16436   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16437   ins_encode %{
16438     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16439             as_FloatRegister($src1$$reg),
16440             as_FloatRegister($src2$$reg));
16441   %}
16442   ins_pipe(vdop128);
16443 %}
16444 
16445 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16446 %{
16447   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16448   match(Set dst (AddVF src1 src2));
16449   ins_cost(INSN_COST);
16450   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16451   ins_encode %{
16452     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16453             as_FloatRegister($src1$$reg),
16454             as_FloatRegister($src2$$reg));
16455   %}
16456   ins_pipe(vdop_fp64);
16457 %}
16458 
16459 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16460 %{
16461   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16462   match(Set dst (AddVF src1 src2));
16463   ins_cost(INSN_COST);
16464   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16465   ins_encode %{
16466     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16467             as_FloatRegister($src1$$reg),
16468             as_FloatRegister($src2$$reg));
16469   %}
16470   ins_pipe(vdop_fp128);
16471 %}
16472 
16473 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16474 %{
16475   match(Set dst (AddVD src1 src2));
16476   ins_cost(INSN_COST);
16477   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16478   ins_encode %{
16479     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16480             as_FloatRegister($src1$$reg),
16481             as_FloatRegister($src2$$reg));
16482   %}
16483   ins_pipe(vdop_fp128);
16484 %}
16485 
16486 // --------------------------------- SUB --------------------------------------
16487 
16488 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16489 %{
16490   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16491             n-&gt;as_Vector()-&gt;length() == 8);
16492   match(Set dst (SubVB src1 src2));
16493   ins_cost(INSN_COST);
16494   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16495   ins_encode %{
16496     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16497             as_FloatRegister($src1$$reg),
16498             as_FloatRegister($src2$$reg));
16499   %}
16500   ins_pipe(vdop64);
16501 %}
16502 
16503 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16504 %{
16505   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16506   match(Set dst (SubVB src1 src2));
16507   ins_cost(INSN_COST);
16508   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16509   ins_encode %{
16510     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16511             as_FloatRegister($src1$$reg),
16512             as_FloatRegister($src2$$reg));
16513   %}
16514   ins_pipe(vdop128);
16515 %}
16516 
16517 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16518 %{
16519   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16520             n-&gt;as_Vector()-&gt;length() == 4);
16521   match(Set dst (SubVS src1 src2));
16522   ins_cost(INSN_COST);
16523   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16524   ins_encode %{
16525     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16526             as_FloatRegister($src1$$reg),
16527             as_FloatRegister($src2$$reg));
16528   %}
16529   ins_pipe(vdop64);
16530 %}
16531 
16532 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16533 %{
16534   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16535   match(Set dst (SubVS src1 src2));
16536   ins_cost(INSN_COST);
16537   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16538   ins_encode %{
16539     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16540             as_FloatRegister($src1$$reg),
16541             as_FloatRegister($src2$$reg));
16542   %}
16543   ins_pipe(vdop128);
16544 %}
16545 
16546 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16547 %{
16548   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16549   match(Set dst (SubVI src1 src2));
16550   ins_cost(INSN_COST);
16551   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16552   ins_encode %{
16553     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16554             as_FloatRegister($src1$$reg),
16555             as_FloatRegister($src2$$reg));
16556   %}
16557   ins_pipe(vdop64);
16558 %}
16559 
16560 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16561 %{
16562   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16563   match(Set dst (SubVI src1 src2));
16564   ins_cost(INSN_COST);
16565   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16566   ins_encode %{
16567     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16568             as_FloatRegister($src1$$reg),
16569             as_FloatRegister($src2$$reg));
16570   %}
16571   ins_pipe(vdop128);
16572 %}
16573 
16574 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16575 %{
16576   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16577   match(Set dst (SubVL src1 src2));
16578   ins_cost(INSN_COST);
16579   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16580   ins_encode %{
16581     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16582             as_FloatRegister($src1$$reg),
16583             as_FloatRegister($src2$$reg));
16584   %}
16585   ins_pipe(vdop128);
16586 %}
16587 
16588 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16589 %{
16590   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16591   match(Set dst (SubVF src1 src2));
16592   ins_cost(INSN_COST);
16593   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16594   ins_encode %{
16595     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16596             as_FloatRegister($src1$$reg),
16597             as_FloatRegister($src2$$reg));
16598   %}
16599   ins_pipe(vdop_fp64);
16600 %}
16601 
16602 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16603 %{
16604   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16605   match(Set dst (SubVF src1 src2));
16606   ins_cost(INSN_COST);
16607   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16608   ins_encode %{
16609     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16610             as_FloatRegister($src1$$reg),
16611             as_FloatRegister($src2$$reg));
16612   %}
16613   ins_pipe(vdop_fp128);
16614 %}
16615 
16616 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16617 %{
16618   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16619   match(Set dst (SubVD src1 src2));
16620   ins_cost(INSN_COST);
16621   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16622   ins_encode %{
16623     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16624             as_FloatRegister($src1$$reg),
16625             as_FloatRegister($src2$$reg));
16626   %}
16627   ins_pipe(vdop_fp128);
16628 %}
16629 
16630 // --------------------------------- MUL --------------------------------------
16631 
16632 instruct vmul8B(vecD dst, vecD src1, vecD src2)
16633 %{
16634   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16635             n-&gt;as_Vector()-&gt;length() == 8);
16636   match(Set dst (MulVB src1 src2));
16637   ins_cost(INSN_COST);
16638   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16639   ins_encode %{
16640     __ mulv(as_FloatRegister($dst$$reg), __ T8B,
16641             as_FloatRegister($src1$$reg),
16642             as_FloatRegister($src2$$reg));
16643   %}
16644   ins_pipe(vmul64);
16645 %}
16646 
16647 instruct vmul16B(vecX dst, vecX src1, vecX src2)
16648 %{
16649   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16650   match(Set dst (MulVB src1 src2));
16651   ins_cost(INSN_COST);
16652   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16653   ins_encode %{
16654     __ mulv(as_FloatRegister($dst$$reg), __ T16B,
16655             as_FloatRegister($src1$$reg),
16656             as_FloatRegister($src2$$reg));
16657   %}
16658   ins_pipe(vmul128);
16659 %}
16660 
16661 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16662 %{
16663   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16664             n-&gt;as_Vector()-&gt;length() == 4);
16665   match(Set dst (MulVS src1 src2));
16666   ins_cost(INSN_COST);
16667   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16668   ins_encode %{
16669     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16670             as_FloatRegister($src1$$reg),
16671             as_FloatRegister($src2$$reg));
16672   %}
16673   ins_pipe(vmul64);
16674 %}
16675 
16676 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16677 %{
16678   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16679   match(Set dst (MulVS src1 src2));
16680   ins_cost(INSN_COST);
16681   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16682   ins_encode %{
16683     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16684             as_FloatRegister($src1$$reg),
16685             as_FloatRegister($src2$$reg));
16686   %}
16687   ins_pipe(vmul128);
16688 %}
16689 
16690 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16691 %{
16692   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16693   match(Set dst (MulVI src1 src2));
16694   ins_cost(INSN_COST);
16695   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16696   ins_encode %{
16697     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16698             as_FloatRegister($src1$$reg),
16699             as_FloatRegister($src2$$reg));
16700   %}
16701   ins_pipe(vmul64);
16702 %}
16703 
16704 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16705 %{
16706   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16707   match(Set dst (MulVI src1 src2));
16708   ins_cost(INSN_COST);
16709   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16710   ins_encode %{
16711     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16712             as_FloatRegister($src1$$reg),
16713             as_FloatRegister($src2$$reg));
16714   %}
16715   ins_pipe(vmul128);
16716 %}
16717 
16718 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16719 %{
16720   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16721   match(Set dst (MulVF src1 src2));
16722   ins_cost(INSN_COST);
16723   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16724   ins_encode %{
16725     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16726             as_FloatRegister($src1$$reg),
16727             as_FloatRegister($src2$$reg));
16728   %}
16729   ins_pipe(vmuldiv_fp64);
16730 %}
16731 
16732 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16733 %{
16734   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16735   match(Set dst (MulVF src1 src2));
16736   ins_cost(INSN_COST);
16737   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16738   ins_encode %{
16739     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16740             as_FloatRegister($src1$$reg),
16741             as_FloatRegister($src2$$reg));
16742   %}
16743   ins_pipe(vmuldiv_fp128);
16744 %}
16745 
16746 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16747 %{
16748   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16749   match(Set dst (MulVD src1 src2));
16750   ins_cost(INSN_COST);
16751   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16752   ins_encode %{
16753     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16754             as_FloatRegister($src1$$reg),
16755             as_FloatRegister($src2$$reg));
16756   %}
16757   ins_pipe(vmuldiv_fp128);
16758 %}
16759 
16760 // --------------------------------- MLA --------------------------------------
16761 
16762 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16763 %{
16764   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16765             n-&gt;as_Vector()-&gt;length() == 4);
16766   match(Set dst (AddVS dst (MulVS src1 src2)));
16767   ins_cost(INSN_COST);
16768   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16769   ins_encode %{
16770     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16771             as_FloatRegister($src1$$reg),
16772             as_FloatRegister($src2$$reg));
16773   %}
16774   ins_pipe(vmla64);
16775 %}
16776 
16777 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16778 %{
16779   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16780   match(Set dst (AddVS dst (MulVS src1 src2)));
16781   ins_cost(INSN_COST);
16782   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16783   ins_encode %{
16784     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16785             as_FloatRegister($src1$$reg),
16786             as_FloatRegister($src2$$reg));
16787   %}
16788   ins_pipe(vmla128);
16789 %}
16790 
16791 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16792 %{
16793   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16794   match(Set dst (AddVI dst (MulVI src1 src2)));
16795   ins_cost(INSN_COST);
16796   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16797   ins_encode %{
16798     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16799             as_FloatRegister($src1$$reg),
16800             as_FloatRegister($src2$$reg));
16801   %}
16802   ins_pipe(vmla64);
16803 %}
16804 
16805 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16806 %{
16807   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16808   match(Set dst (AddVI dst (MulVI src1 src2)));
16809   ins_cost(INSN_COST);
16810   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16811   ins_encode %{
16812     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16813             as_FloatRegister($src1$$reg),
16814             as_FloatRegister($src2$$reg));
16815   %}
16816   ins_pipe(vmla128);
16817 %}
16818 
16819 // dst + src1 * src2
16820 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16821   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16822   match(Set dst (FmaVF  dst (Binary src1 src2)));
16823   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16824   ins_cost(INSN_COST);
16825   ins_encode %{
16826     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16827             as_FloatRegister($src1$$reg),
16828             as_FloatRegister($src2$$reg));
16829   %}
16830   ins_pipe(vmuldiv_fp64);
16831 %}
16832 
16833 // dst + src1 * src2
16834 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16835   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16836   match(Set dst (FmaVF  dst (Binary src1 src2)));
16837   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16838   ins_cost(INSN_COST);
16839   ins_encode %{
16840     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16841             as_FloatRegister($src1$$reg),
16842             as_FloatRegister($src2$$reg));
16843   %}
16844   ins_pipe(vmuldiv_fp128);
16845 %}
16846 
16847 // dst + src1 * src2
16848 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16849   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16850   match(Set dst (FmaVD  dst (Binary src1 src2)));
16851   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16852   ins_cost(INSN_COST);
16853   ins_encode %{
16854     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16855             as_FloatRegister($src1$$reg),
16856             as_FloatRegister($src2$$reg));
16857   %}
16858   ins_pipe(vmuldiv_fp128);
16859 %}
16860 
16861 // --------------------------------- MLS --------------------------------------
16862 
16863 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16864 %{
16865   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16866             n-&gt;as_Vector()-&gt;length() == 4);
16867   match(Set dst (SubVS dst (MulVS src1 src2)));
16868   ins_cost(INSN_COST);
16869   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16870   ins_encode %{
16871     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16872             as_FloatRegister($src1$$reg),
16873             as_FloatRegister($src2$$reg));
16874   %}
16875   ins_pipe(vmla64);
16876 %}
16877 
16878 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16879 %{
16880   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16881   match(Set dst (SubVS dst (MulVS src1 src2)));
16882   ins_cost(INSN_COST);
16883   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16884   ins_encode %{
16885     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16886             as_FloatRegister($src1$$reg),
16887             as_FloatRegister($src2$$reg));
16888   %}
16889   ins_pipe(vmla128);
16890 %}
16891 
16892 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16893 %{
16894   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16895   match(Set dst (SubVI dst (MulVI src1 src2)));
16896   ins_cost(INSN_COST);
16897   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16898   ins_encode %{
16899     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16900             as_FloatRegister($src1$$reg),
16901             as_FloatRegister($src2$$reg));
16902   %}
16903   ins_pipe(vmla64);
16904 %}
16905 
16906 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16907 %{
16908   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16909   match(Set dst (SubVI dst (MulVI src1 src2)));
16910   ins_cost(INSN_COST);
16911   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16912   ins_encode %{
16913     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16914             as_FloatRegister($src1$$reg),
16915             as_FloatRegister($src2$$reg));
16916   %}
16917   ins_pipe(vmla128);
16918 %}
16919 
16920 // dst - src1 * src2
16921 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16922   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16923   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16924   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16925   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16926   ins_cost(INSN_COST);
16927   ins_encode %{
16928     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16929             as_FloatRegister($src1$$reg),
16930             as_FloatRegister($src2$$reg));
16931   %}
16932   ins_pipe(vmuldiv_fp64);
16933 %}
16934 
16935 // dst - src1 * src2
16936 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16937   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16938   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16939   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16940   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16941   ins_cost(INSN_COST);
16942   ins_encode %{
16943     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16944             as_FloatRegister($src1$$reg),
16945             as_FloatRegister($src2$$reg));
16946   %}
16947   ins_pipe(vmuldiv_fp128);
16948 %}
16949 
16950 // dst - src1 * src2
16951 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16952   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16953   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16954   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16955   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16956   ins_cost(INSN_COST);
16957   ins_encode %{
16958     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16959             as_FloatRegister($src1$$reg),
16960             as_FloatRegister($src2$$reg));
16961   %}
16962   ins_pipe(vmuldiv_fp128);
16963 %}
16964 
16965 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16966 
16967 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16968   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16969   match(Set dst (MulAddVS2VI src1 src2));
16970   ins_cost(INSN_COST);
16971   effect(TEMP_DEF dst, TEMP tmp);
16972   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16973             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16974             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16975   ins_encode %{
16976     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16977               as_FloatRegister($src1$$reg),
16978               as_FloatRegister($src2$$reg));
16979     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16980               as_FloatRegister($src1$$reg),
16981               as_FloatRegister($src2$$reg));
16982     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16983              as_FloatRegister($tmp$$reg),
16984              as_FloatRegister($dst$$reg));
16985   %}
16986   ins_pipe(vmuldiv_fp128);
16987 %}
16988 
16989 // --------------------------------- DIV --------------------------------------
16990 
16991 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16992 %{
16993   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16994   match(Set dst (DivVF src1 src2));
16995   ins_cost(INSN_COST);
16996   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16997   ins_encode %{
16998     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16999             as_FloatRegister($src1$$reg),
17000             as_FloatRegister($src2$$reg));
17001   %}
17002   ins_pipe(vmuldiv_fp64);
17003 %}
17004 
17005 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17006 %{
17007   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17008   match(Set dst (DivVF src1 src2));
17009   ins_cost(INSN_COST);
17010   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17011   ins_encode %{
17012     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17013             as_FloatRegister($src1$$reg),
17014             as_FloatRegister($src2$$reg));
17015   %}
17016   ins_pipe(vmuldiv_fp128);
17017 %}
17018 
17019 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17020 %{
17021   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17022   match(Set dst (DivVD src1 src2));
17023   ins_cost(INSN_COST);
17024   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17025   ins_encode %{
17026     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17027             as_FloatRegister($src1$$reg),
17028             as_FloatRegister($src2$$reg));
17029   %}
17030   ins_pipe(vmuldiv_fp128);
17031 %}
17032 
17033 // --------------------------------- SQRT -------------------------------------
17034 
17035 instruct vsqrt2F(vecD dst, vecD src)
17036 %{
17037   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17038   match(Set dst (SqrtVF src));
17039   format %{ &quot;fsqrt  $dst, $src\t# vector (2F)&quot; %}
17040   ins_encode %{
17041     __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17042   %}
17043   ins_pipe(vunop_fp64);
17044 %}
17045 
17046 instruct vsqrt4F(vecX dst, vecX src)
17047 %{
17048   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17049   match(Set dst (SqrtVF src));
17050   format %{ &quot;fsqrt  $dst, $src\t# vector (4F)&quot; %}
17051   ins_encode %{
17052     __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17053   %}
17054   ins_pipe(vsqrt_fp128);
17055 %}
17056 
17057 instruct vsqrt2D(vecX dst, vecX src)
17058 %{
17059   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17060   match(Set dst (SqrtVD src));
17061   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17062   ins_encode %{
17063     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17064              as_FloatRegister($src$$reg));
17065   %}
17066   ins_pipe(vsqrt_fp128);
17067 %}
17068 
17069 // --------------------------------- ABS --------------------------------------
17070 
17071 instruct vabs2F(vecD dst, vecD src)
17072 %{
17073   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17074   match(Set dst (AbsVF src));
17075   ins_cost(INSN_COST * 3);
17076   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17077   ins_encode %{
17078     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17079             as_FloatRegister($src$$reg));
17080   %}
17081   ins_pipe(vunop_fp64);
17082 %}
17083 
17084 instruct vabs4F(vecX dst, vecX src)
17085 %{
17086   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17087   match(Set dst (AbsVF src));
17088   ins_cost(INSN_COST * 3);
17089   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17090   ins_encode %{
17091     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17092             as_FloatRegister($src$$reg));
17093   %}
17094   ins_pipe(vunop_fp128);
17095 %}
17096 
17097 instruct vabs2D(vecX dst, vecX src)
17098 %{
17099   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17100   match(Set dst (AbsVD src));
17101   ins_cost(INSN_COST * 3);
17102   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17103   ins_encode %{
17104     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17105             as_FloatRegister($src$$reg));
17106   %}
17107   ins_pipe(vunop_fp128);
17108 %}
17109 
17110 // --------------------------------- NEG --------------------------------------
17111 
17112 instruct vneg2F(vecD dst, vecD src)
17113 %{
17114   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17115   match(Set dst (NegVF src));
17116   ins_cost(INSN_COST * 3);
17117   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17118   ins_encode %{
17119     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17120             as_FloatRegister($src$$reg));
17121   %}
17122   ins_pipe(vunop_fp64);
17123 %}
17124 
17125 instruct vneg4F(vecX dst, vecX src)
17126 %{
17127   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17128   match(Set dst (NegVF src));
17129   ins_cost(INSN_COST * 3);
17130   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17131   ins_encode %{
17132     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17133             as_FloatRegister($src$$reg));
17134   %}
17135   ins_pipe(vunop_fp128);
17136 %}
17137 
17138 instruct vneg2D(vecX dst, vecX src)
17139 %{
17140   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17141   match(Set dst (NegVD src));
17142   ins_cost(INSN_COST * 3);
17143   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17144   ins_encode %{
17145     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17146             as_FloatRegister($src$$reg));
17147   %}
17148   ins_pipe(vunop_fp128);
17149 %}
17150 
17151 // --------------------------------- AND --------------------------------------
17152 
17153 instruct vand8B(vecD dst, vecD src1, vecD src2)
17154 %{
17155   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17156             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17157   match(Set dst (AndV src1 src2));
17158   ins_cost(INSN_COST);
17159   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17160   ins_encode %{
17161     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17162             as_FloatRegister($src1$$reg),
17163             as_FloatRegister($src2$$reg));
17164   %}
17165   ins_pipe(vlogical64);
17166 %}
17167 
17168 instruct vand16B(vecX dst, vecX src1, vecX src2)
17169 %{
17170   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17171   match(Set dst (AndV src1 src2));
17172   ins_cost(INSN_COST);
17173   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17174   ins_encode %{
17175     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17176             as_FloatRegister($src1$$reg),
17177             as_FloatRegister($src2$$reg));
17178   %}
17179   ins_pipe(vlogical128);
17180 %}
17181 
17182 // --------------------------------- OR ---------------------------------------
17183 
17184 instruct vor8B(vecD dst, vecD src1, vecD src2)
17185 %{
17186   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17187             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17188   match(Set dst (OrV src1 src2));
17189   ins_cost(INSN_COST);
17190   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17191   ins_encode %{
17192     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17193             as_FloatRegister($src1$$reg),
17194             as_FloatRegister($src2$$reg));
17195   %}
17196   ins_pipe(vlogical64);
17197 %}
17198 
17199 instruct vor16B(vecX dst, vecX src1, vecX src2)
17200 %{
17201   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17202   match(Set dst (OrV src1 src2));
17203   ins_cost(INSN_COST);
17204   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17205   ins_encode %{
17206     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17207             as_FloatRegister($src1$$reg),
17208             as_FloatRegister($src2$$reg));
17209   %}
17210   ins_pipe(vlogical128);
17211 %}
17212 
17213 // --------------------------------- XOR --------------------------------------
17214 
17215 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17216 %{
17217   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17218             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17219   match(Set dst (XorV src1 src2));
17220   ins_cost(INSN_COST);
17221   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17222   ins_encode %{
17223     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17224             as_FloatRegister($src1$$reg),
17225             as_FloatRegister($src2$$reg));
17226   %}
17227   ins_pipe(vlogical64);
17228 %}
17229 
17230 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17231 %{
17232   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17233   match(Set dst (XorV src1 src2));
17234   ins_cost(INSN_COST);
17235   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17236   ins_encode %{
17237     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17238             as_FloatRegister($src1$$reg),
17239             as_FloatRegister($src2$$reg));
17240   %}
17241   ins_pipe(vlogical128);
17242 %}
17243 
17244 // ------------------------------ Shift ---------------------------------------
17245 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17246   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17247   match(Set dst (LShiftCntV cnt));
17248   match(Set dst (RShiftCntV cnt));
17249   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17250   ins_encode %{
17251     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17252   %}
17253   ins_pipe(vdup_reg_reg64);
17254 %}
17255 
17256 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17257   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17258   match(Set dst (LShiftCntV cnt));
17259   match(Set dst (RShiftCntV cnt));
17260   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17261   ins_encode %{
17262     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17263   %}
17264   ins_pipe(vdup_reg_reg128);
17265 %}
17266 
17267 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17268   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17269             n-&gt;as_Vector()-&gt;length() == 8);
17270   match(Set dst (LShiftVB src shift));
17271   ins_cost(INSN_COST);
17272   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17273   ins_encode %{
17274     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17275             as_FloatRegister($src$$reg),
17276             as_FloatRegister($shift$$reg));
17277   %}
17278   ins_pipe(vshift64);
17279 %}
17280 
17281 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17282   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17283   match(Set dst (LShiftVB src shift));
17284   ins_cost(INSN_COST);
17285   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17286   ins_encode %{
17287     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17288             as_FloatRegister($src$$reg),
17289             as_FloatRegister($shift$$reg));
17290   %}
17291   ins_pipe(vshift128);
17292 %}
17293 
17294 // Right shifts with vector shift count on aarch64 SIMD are implemented
17295 // as left shift by negative shift count.
17296 // There are two cases for vector shift count.
17297 //
17298 // Case 1: The vector shift count is from replication.
17299 //        |            |
17300 //    LoadVector  RShiftCntV
17301 //        |       /
17302 //     RShiftVI
17303 // Note: In inner loop, multiple neg instructions are used, which can be
17304 // moved to outer loop and merge into one neg instruction.
17305 //
17306 // Case 2: The vector shift count is from loading.
17307 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17308 // panama/vectorIntrinsics(JEP 338: Vector API).
17309 //        |            |
17310 //    LoadVector  LoadVector
17311 //        |       /
17312 //     RShiftVI
17313 //
17314 
17315 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17316   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17317             n-&gt;as_Vector()-&gt;length() == 8);
17318   match(Set dst (RShiftVB src shift));
17319   ins_cost(INSN_COST);
17320   effect(TEMP tmp);
17321   format %{ &quot;negr  $tmp,$shift\t&quot;
17322             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17323   ins_encode %{
17324     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17325             as_FloatRegister($shift$$reg));
17326     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17327             as_FloatRegister($src$$reg),
17328             as_FloatRegister($tmp$$reg));
17329   %}
17330   ins_pipe(vshift64);
17331 %}
17332 
17333 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17334   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17335   match(Set dst (RShiftVB src shift));
17336   ins_cost(INSN_COST);
17337   effect(TEMP tmp);
17338   format %{ &quot;negr  $tmp,$shift\t&quot;
17339             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17340   ins_encode %{
17341     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17342             as_FloatRegister($shift$$reg));
17343     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17344             as_FloatRegister($src$$reg),
17345             as_FloatRegister($tmp$$reg));
17346   %}
17347   ins_pipe(vshift128);
17348 %}
17349 
17350 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17351   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17352             n-&gt;as_Vector()-&gt;length() == 8);
17353   match(Set dst (URShiftVB src shift));
17354   ins_cost(INSN_COST);
17355   effect(TEMP tmp);
17356   format %{ &quot;negr  $tmp,$shift\t&quot;
17357             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17358   ins_encode %{
17359     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17360             as_FloatRegister($shift$$reg));
17361     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17362             as_FloatRegister($src$$reg),
17363             as_FloatRegister($tmp$$reg));
17364   %}
17365   ins_pipe(vshift64);
17366 %}
17367 
17368 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17369   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17370   match(Set dst (URShiftVB src shift));
17371   ins_cost(INSN_COST);
17372   effect(TEMP tmp);
17373   format %{ &quot;negr  $tmp,$shift\t&quot;
17374             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17375   ins_encode %{
17376     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17377             as_FloatRegister($shift$$reg));
17378     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17379             as_FloatRegister($src$$reg),
17380             as_FloatRegister($tmp$$reg));
17381   %}
17382   ins_pipe(vshift128);
17383 %}
17384 
17385 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17386   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17387             n-&gt;as_Vector()-&gt;length() == 8);
17388   match(Set dst (LShiftVB src (LShiftCntV shift)));
17389   ins_cost(INSN_COST);
17390   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17391   ins_encode %{
17392     int sh = (int)$shift$$constant;
17393     if (sh &gt;= 8) {
17394       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17395              as_FloatRegister($src$$reg),
17396              as_FloatRegister($src$$reg));
17397     } else {
17398       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17399              as_FloatRegister($src$$reg), sh);
17400     }
17401   %}
17402   ins_pipe(vshift64_imm);
17403 %}
17404 
17405 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17406   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17407   match(Set dst (LShiftVB src (LShiftCntV shift)));
17408   ins_cost(INSN_COST);
17409   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17410   ins_encode %{
17411     int sh = (int)$shift$$constant;
17412     if (sh &gt;= 8) {
17413       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17414              as_FloatRegister($src$$reg),
17415              as_FloatRegister($src$$reg));
17416     } else {
17417       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17418              as_FloatRegister($src$$reg), sh);
17419     }
17420   %}
17421   ins_pipe(vshift128_imm);
17422 %}
17423 
17424 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17425   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17426             n-&gt;as_Vector()-&gt;length() == 8);
17427   match(Set dst (RShiftVB src (RShiftCntV shift)));
17428   ins_cost(INSN_COST);
17429   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17430   ins_encode %{
17431     int sh = (int)$shift$$constant;
17432     if (sh &gt;= 8) sh = 7;
17433     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17434            as_FloatRegister($src$$reg), sh);
17435   %}
17436   ins_pipe(vshift64_imm);
17437 %}
17438 
17439 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17440   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17441   match(Set dst (RShiftVB src (RShiftCntV shift)));
17442   ins_cost(INSN_COST);
17443   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17444   ins_encode %{
17445     int sh = (int)$shift$$constant;
17446     if (sh &gt;= 8) sh = 7;
17447     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17448            as_FloatRegister($src$$reg), sh);
17449   %}
17450   ins_pipe(vshift128_imm);
17451 %}
17452 
17453 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17454   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17455             n-&gt;as_Vector()-&gt;length() == 8);
17456   match(Set dst (URShiftVB src (RShiftCntV shift)));
17457   ins_cost(INSN_COST);
17458   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17459   ins_encode %{
17460     int sh = (int)$shift$$constant;
17461     if (sh &gt;= 8) {
17462       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17463              as_FloatRegister($src$$reg),
17464              as_FloatRegister($src$$reg));
17465     } else {
17466       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17467              as_FloatRegister($src$$reg), sh);
17468     }
17469   %}
17470   ins_pipe(vshift64_imm);
17471 %}
17472 
17473 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17474   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17475   match(Set dst (URShiftVB src (RShiftCntV shift)));
17476   ins_cost(INSN_COST);
17477   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17478   ins_encode %{
17479     int sh = (int)$shift$$constant;
17480     if (sh &gt;= 8) {
17481       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17482              as_FloatRegister($src$$reg),
17483              as_FloatRegister($src$$reg));
17484     } else {
17485       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17486              as_FloatRegister($src$$reg), sh);
17487     }
17488   %}
17489   ins_pipe(vshift128_imm);
17490 %}
17491 
17492 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17493   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17494             n-&gt;as_Vector()-&gt;length() == 4);
17495   match(Set dst (LShiftVS src shift));
17496   ins_cost(INSN_COST);
17497   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17498   ins_encode %{
17499     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17500             as_FloatRegister($src$$reg),
17501             as_FloatRegister($shift$$reg));
17502   %}
17503   ins_pipe(vshift64);
17504 %}
17505 
17506 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17507   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17508   match(Set dst (LShiftVS src shift));
17509   ins_cost(INSN_COST);
17510   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17511   ins_encode %{
17512     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17513             as_FloatRegister($src$$reg),
17514             as_FloatRegister($shift$$reg));
17515   %}
17516   ins_pipe(vshift128);
17517 %}
17518 
17519 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17520   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17521             n-&gt;as_Vector()-&gt;length() == 4);
17522   match(Set dst (RShiftVS src shift));
17523   ins_cost(INSN_COST);
17524   effect(TEMP tmp);
17525   format %{ &quot;negr  $tmp,$shift\t&quot;
17526             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17527   ins_encode %{
17528     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17529             as_FloatRegister($shift$$reg));
17530     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17531             as_FloatRegister($src$$reg),
17532             as_FloatRegister($tmp$$reg));
17533   %}
17534   ins_pipe(vshift64);
17535 %}
17536 
17537 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17538   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17539   match(Set dst (RShiftVS src shift));
17540   ins_cost(INSN_COST);
17541   effect(TEMP tmp);
17542   format %{ &quot;negr  $tmp,$shift\t&quot;
17543             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17544   ins_encode %{
17545     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17546             as_FloatRegister($shift$$reg));
17547     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17548             as_FloatRegister($src$$reg),
17549             as_FloatRegister($tmp$$reg));
17550   %}
17551   ins_pipe(vshift128);
17552 %}
17553 
17554 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17555   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17556             n-&gt;as_Vector()-&gt;length() == 4);
17557   match(Set dst (URShiftVS src shift));
17558   ins_cost(INSN_COST);
17559   effect(TEMP tmp);
17560   format %{ &quot;negr  $tmp,$shift\t&quot;
17561             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17562   ins_encode %{
17563     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17564             as_FloatRegister($shift$$reg));
17565     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17566             as_FloatRegister($src$$reg),
17567             as_FloatRegister($tmp$$reg));
17568   %}
17569   ins_pipe(vshift64);
17570 %}
17571 
17572 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17573   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17574   match(Set dst (URShiftVS src shift));
17575   ins_cost(INSN_COST);
17576   effect(TEMP tmp);
17577   format %{ &quot;negr  $tmp,$shift\t&quot;
17578             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17579   ins_encode %{
17580     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17581             as_FloatRegister($shift$$reg));
17582     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17583             as_FloatRegister($src$$reg),
17584             as_FloatRegister($tmp$$reg));
17585   %}
17586   ins_pipe(vshift128);
17587 %}
17588 
17589 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17590   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17591             n-&gt;as_Vector()-&gt;length() == 4);
17592   match(Set dst (LShiftVS src (LShiftCntV shift)));
17593   ins_cost(INSN_COST);
17594   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17595   ins_encode %{
17596     int sh = (int)$shift$$constant;
17597     if (sh &gt;= 16) {
17598       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17599              as_FloatRegister($src$$reg),
17600              as_FloatRegister($src$$reg));
17601     } else {
17602       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17603              as_FloatRegister($src$$reg), sh);
17604     }
17605   %}
17606   ins_pipe(vshift64_imm);
17607 %}
17608 
17609 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17610   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17611   match(Set dst (LShiftVS src (LShiftCntV shift)));
17612   ins_cost(INSN_COST);
17613   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17614   ins_encode %{
17615     int sh = (int)$shift$$constant;
17616     if (sh &gt;= 16) {
17617       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17618              as_FloatRegister($src$$reg),
17619              as_FloatRegister($src$$reg));
17620     } else {
17621       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17622              as_FloatRegister($src$$reg), sh);
17623     }
17624   %}
17625   ins_pipe(vshift128_imm);
17626 %}
17627 
17628 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17629   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17630             n-&gt;as_Vector()-&gt;length() == 4);
17631   match(Set dst (RShiftVS src (RShiftCntV shift)));
17632   ins_cost(INSN_COST);
17633   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17634   ins_encode %{
17635     int sh = (int)$shift$$constant;
17636     if (sh &gt;= 16) sh = 15;
17637     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17638            as_FloatRegister($src$$reg), sh);
17639   %}
17640   ins_pipe(vshift64_imm);
17641 %}
17642 
17643 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17644   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17645   match(Set dst (RShiftVS src (RShiftCntV shift)));
17646   ins_cost(INSN_COST);
17647   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17648   ins_encode %{
17649     int sh = (int)$shift$$constant;
17650     if (sh &gt;= 16) sh = 15;
17651     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17652            as_FloatRegister($src$$reg), sh);
17653   %}
17654   ins_pipe(vshift128_imm);
17655 %}
17656 
17657 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17658   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17659             n-&gt;as_Vector()-&gt;length() == 4);
17660   match(Set dst (URShiftVS src (RShiftCntV shift)));
17661   ins_cost(INSN_COST);
17662   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17663   ins_encode %{
17664     int sh = (int)$shift$$constant;
17665     if (sh &gt;= 16) {
17666       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17667              as_FloatRegister($src$$reg),
17668              as_FloatRegister($src$$reg));
17669     } else {
17670       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17671              as_FloatRegister($src$$reg), sh);
17672     }
17673   %}
17674   ins_pipe(vshift64_imm);
17675 %}
17676 
17677 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17678   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17679   match(Set dst (URShiftVS src (RShiftCntV shift)));
17680   ins_cost(INSN_COST);
17681   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17682   ins_encode %{
17683     int sh = (int)$shift$$constant;
17684     if (sh &gt;= 16) {
17685       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17686              as_FloatRegister($src$$reg),
17687              as_FloatRegister($src$$reg));
17688     } else {
17689       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17690              as_FloatRegister($src$$reg), sh);
17691     }
17692   %}
17693   ins_pipe(vshift128_imm);
17694 %}
17695 
17696 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17697   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17698   match(Set dst (LShiftVI src shift));
17699   ins_cost(INSN_COST);
17700   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17701   ins_encode %{
17702     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17703             as_FloatRegister($src$$reg),
17704             as_FloatRegister($shift$$reg));
17705   %}
17706   ins_pipe(vshift64);
17707 %}
17708 
17709 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17710   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17711   match(Set dst (LShiftVI src shift));
17712   ins_cost(INSN_COST);
17713   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17714   ins_encode %{
17715     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17716             as_FloatRegister($src$$reg),
17717             as_FloatRegister($shift$$reg));
17718   %}
17719   ins_pipe(vshift128);
17720 %}
17721 
17722 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17723   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17724   match(Set dst (RShiftVI src shift));
17725   ins_cost(INSN_COST);
17726   effect(TEMP tmp);
17727   format %{ &quot;negr  $tmp,$shift\t&quot;
17728             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17729   ins_encode %{
17730     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17731             as_FloatRegister($shift$$reg));
17732     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17733             as_FloatRegister($src$$reg),
17734             as_FloatRegister($tmp$$reg));
17735   %}
17736   ins_pipe(vshift64);
17737 %}
17738 
17739 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17740   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17741   match(Set dst (RShiftVI src shift));
17742   ins_cost(INSN_COST);
17743   effect(TEMP tmp);
17744   format %{ &quot;negr  $tmp,$shift\t&quot;
17745             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17746   ins_encode %{
17747     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17748             as_FloatRegister($shift$$reg));
17749     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17750             as_FloatRegister($src$$reg),
17751             as_FloatRegister($tmp$$reg));
17752   %}
17753   ins_pipe(vshift128);
17754 %}
17755 
17756 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17757   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17758   match(Set dst (URShiftVI src shift));
17759   ins_cost(INSN_COST);
17760   effect(TEMP tmp);
17761   format %{ &quot;negr  $tmp,$shift\t&quot;
17762             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17763   ins_encode %{
17764     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17765             as_FloatRegister($shift$$reg));
17766     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17767             as_FloatRegister($src$$reg),
17768             as_FloatRegister($tmp$$reg));
17769   %}
17770   ins_pipe(vshift64);
17771 %}
17772 
17773 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17774   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17775   match(Set dst (URShiftVI src shift));
17776   ins_cost(INSN_COST);
17777   effect(TEMP tmp);
17778   format %{ &quot;negr  $tmp,$shift\t&quot;
17779             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17780   ins_encode %{
17781     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17782             as_FloatRegister($shift$$reg));
17783     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17784             as_FloatRegister($src$$reg),
17785             as_FloatRegister($tmp$$reg));
17786   %}
17787   ins_pipe(vshift128);
17788 %}
17789 
17790 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17791   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17792   match(Set dst (LShiftVI src (LShiftCntV shift)));
17793   ins_cost(INSN_COST);
17794   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17795   ins_encode %{
17796     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17797            as_FloatRegister($src$$reg),
17798            (int)$shift$$constant);
17799   %}
17800   ins_pipe(vshift64_imm);
17801 %}
17802 
17803 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17804   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17805   match(Set dst (LShiftVI src (LShiftCntV shift)));
17806   ins_cost(INSN_COST);
17807   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17808   ins_encode %{
17809     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17810            as_FloatRegister($src$$reg),
17811            (int)$shift$$constant);
17812   %}
17813   ins_pipe(vshift128_imm);
17814 %}
17815 
17816 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17817   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17818   match(Set dst (RShiftVI src (RShiftCntV shift)));
17819   ins_cost(INSN_COST);
17820   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17821   ins_encode %{
17822     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17823             as_FloatRegister($src$$reg),
17824             (int)$shift$$constant);
17825   %}
17826   ins_pipe(vshift64_imm);
17827 %}
17828 
17829 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17830   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17831   match(Set dst (RShiftVI src (RShiftCntV shift)));
17832   ins_cost(INSN_COST);
17833   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17834   ins_encode %{
17835     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17836             as_FloatRegister($src$$reg),
17837             (int)$shift$$constant);
17838   %}
17839   ins_pipe(vshift128_imm);
17840 %}
17841 
17842 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17843   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17844   match(Set dst (URShiftVI src (RShiftCntV shift)));
17845   ins_cost(INSN_COST);
17846   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17847   ins_encode %{
17848     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17849             as_FloatRegister($src$$reg),
17850             (int)$shift$$constant);
17851   %}
17852   ins_pipe(vshift64_imm);
17853 %}
17854 
17855 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17856   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17857   match(Set dst (URShiftVI src (RShiftCntV shift)));
17858   ins_cost(INSN_COST);
17859   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17860   ins_encode %{
17861     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17862             as_FloatRegister($src$$reg),
17863             (int)$shift$$constant);
17864   %}
17865   ins_pipe(vshift128_imm);
17866 %}
17867 
17868 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17869   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17870   match(Set dst (LShiftVL src shift));
17871   ins_cost(INSN_COST);
17872   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17873   ins_encode %{
17874     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17875             as_FloatRegister($src$$reg),
17876             as_FloatRegister($shift$$reg));
17877   %}
17878   ins_pipe(vshift128);
17879 %}
17880 
17881 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17882   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17883   match(Set dst (RShiftVL src shift));
17884   ins_cost(INSN_COST);
17885   effect(TEMP tmp);
17886   format %{ &quot;negr  $tmp,$shift\t&quot;
17887             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17888   ins_encode %{
17889     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17890             as_FloatRegister($shift$$reg));
17891     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17892             as_FloatRegister($src$$reg),
17893             as_FloatRegister($tmp$$reg));
17894   %}
17895   ins_pipe(vshift128);
17896 %}
17897 
17898 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17899   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17900   match(Set dst (URShiftVL src shift));
17901   ins_cost(INSN_COST);
17902   effect(TEMP tmp);
17903   format %{ &quot;negr  $tmp,$shift\t&quot;
17904             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17905   ins_encode %{
17906     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17907             as_FloatRegister($shift$$reg));
17908     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17909             as_FloatRegister($src$$reg),
17910             as_FloatRegister($tmp$$reg));
17911   %}
17912   ins_pipe(vshift128);
17913 %}
17914 
17915 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17916   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17917   match(Set dst (LShiftVL src (LShiftCntV shift)));
17918   ins_cost(INSN_COST);
17919   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17920   ins_encode %{
17921     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17922            as_FloatRegister($src$$reg),
17923            (int)$shift$$constant);
17924   %}
17925   ins_pipe(vshift128_imm);
17926 %}
17927 
17928 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17929   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17930   match(Set dst (RShiftVL src (RShiftCntV shift)));
17931   ins_cost(INSN_COST);
17932   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17933   ins_encode %{
17934     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17935             as_FloatRegister($src$$reg),
17936             (int)$shift$$constant);
17937   %}
17938   ins_pipe(vshift128_imm);
17939 %}
17940 
17941 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17942   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17943   match(Set dst (URShiftVL src (RShiftCntV shift)));
17944   ins_cost(INSN_COST);
17945   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17946   ins_encode %{
17947     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17948             as_FloatRegister($src$$reg),
17949             (int)$shift$$constant);
17950   %}
17951   ins_pipe(vshift128_imm);
17952 %}
17953 
17954 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17955 %{
17956   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17957   match(Set dst (MaxV src1 src2));
17958   ins_cost(INSN_COST);
17959   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17960   ins_encode %{
17961     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17962             as_FloatRegister($src1$$reg),
17963             as_FloatRegister($src2$$reg));
17964   %}
17965   ins_pipe(vdop_fp64);
17966 %}
17967 
17968 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17969 %{
17970   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17971   match(Set dst (MaxV src1 src2));
17972   ins_cost(INSN_COST);
17973   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17974   ins_encode %{
17975     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17976             as_FloatRegister($src1$$reg),
17977             as_FloatRegister($src2$$reg));
17978   %}
17979   ins_pipe(vdop_fp128);
17980 %}
17981 
17982 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17983 %{
17984   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17985   match(Set dst (MaxV src1 src2));
17986   ins_cost(INSN_COST);
17987   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17988   ins_encode %{
17989     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17990             as_FloatRegister($src1$$reg),
17991             as_FloatRegister($src2$$reg));
17992   %}
17993   ins_pipe(vdop_fp128);
17994 %}
17995 
17996 instruct vmin2F(vecD dst, vecD src1, vecD src2)
17997 %{
17998   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17999   match(Set dst (MinV src1 src2));
18000   ins_cost(INSN_COST);
18001   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18002   ins_encode %{
18003     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18004             as_FloatRegister($src1$$reg),
18005             as_FloatRegister($src2$$reg));
18006   %}
18007   ins_pipe(vdop_fp64);
18008 %}
18009 
18010 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18011 %{
18012   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18013   match(Set dst (MinV src1 src2));
18014   ins_cost(INSN_COST);
18015   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18016   ins_encode %{
18017     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18018             as_FloatRegister($src1$$reg),
18019             as_FloatRegister($src2$$reg));
18020   %}
18021   ins_pipe(vdop_fp128);
18022 %}
18023 
18024 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18025 %{
18026   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18027   match(Set dst (MinV src1 src2));
18028   ins_cost(INSN_COST);
18029   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18030   ins_encode %{
18031     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18032             as_FloatRegister($src1$$reg),
18033             as_FloatRegister($src2$$reg));
18034   %}
18035   ins_pipe(vdop_fp128);
18036 %}
18037 
18038 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18039   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18040   match(Set dst (RoundDoubleModeV src rmode));
18041   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18042   ins_encode %{
18043     switch ($rmode$$constant) {
18044       case RoundDoubleModeNode::rmode_rint:
18045         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18046                   as_FloatRegister($src$$reg));
18047         break;
18048       case RoundDoubleModeNode::rmode_floor:
18049         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18050                   as_FloatRegister($src$$reg));
18051         break;
18052       case RoundDoubleModeNode::rmode_ceil:
18053         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18054                   as_FloatRegister($src$$reg));
18055         break;
18056     }
18057   %}
18058   ins_pipe(vdop_fp128);
18059 %}
18060 
18061 instruct vpopcount4I(vecX dst, vecX src) %{
18062   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18063   match(Set dst (PopCountVI src));
18064   format %{
18065     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18066     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18067     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18068   %}
18069   ins_encode %{
18070      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18071             as_FloatRegister($src$$reg));
18072      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18073                as_FloatRegister($dst$$reg));
18074      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18075                as_FloatRegister($dst$$reg));
18076   %}
18077   ins_pipe(pipe_class_default);
18078 %}
18079 
18080 instruct vpopcount2I(vecD dst, vecD src) %{
18081   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18082   match(Set dst (PopCountVI src));
18083   format %{
18084     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18085     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18086     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18087   %}
18088   ins_encode %{
18089      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18090             as_FloatRegister($src$$reg));
18091      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18092                as_FloatRegister($dst$$reg));
18093      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18094                as_FloatRegister($dst$$reg));
18095   %}
18096   ins_pipe(pipe_class_default);
18097 %}
18098 
18099 //----------PEEPHOLE RULES-----------------------------------------------------
18100 // These must follow all instruction definitions as they use the names
18101 // defined in the instructions definitions.
18102 //
18103 // peepmatch ( root_instr_name [preceding_instruction]* );
18104 //
18105 // peepconstraint %{
18106 // (instruction_number.operand_name relational_op instruction_number.operand_name
18107 //  [, ...] );
18108 // // instruction numbers are zero-based using left to right order in peepmatch
18109 //
18110 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18111 // // provide an instruction_number.operand_name for each operand that appears
18112 // // in the replacement instruction&#39;s match rule
18113 //
18114 // ---------VM FLAGS---------------------------------------------------------
18115 //
18116 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18117 //
18118 // Each peephole rule is given an identifying number starting with zero and
18119 // increasing by one in the order seen by the parser.  An individual peephole
18120 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18121 // on the command-line.
18122 //
18123 // ---------CURRENT LIMITATIONS----------------------------------------------
18124 //
18125 // Only match adjacent instructions in same basic block
18126 // Only equality constraints
18127 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18128 // Only one replacement instruction
18129 //
18130 // ---------EXAMPLE----------------------------------------------------------
18131 //
18132 // // pertinent parts of existing instructions in architecture description
18133 // instruct movI(iRegINoSp dst, iRegI src)
18134 // %{
18135 //   match(Set dst (CopyI src));
18136 // %}
18137 //
18138 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18139 // %{
18140 //   match(Set dst (AddI dst src));
18141 //   effect(KILL cr);
18142 // %}
18143 //
18144 // // Change (inc mov) to lea
18145 // peephole %{
18146 //   // increment preceeded by register-register move
18147 //   peepmatch ( incI_iReg movI );
18148 //   // require that the destination register of the increment
18149 //   // match the destination register of the move
18150 //   peepconstraint ( 0.dst == 1.dst );
18151 //   // construct a replacement instruction that sets
18152 //   // the destination to ( move&#39;s source register + one )
18153 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18154 // %}
18155 //
18156 
18157 // Implementation no longer uses movX instructions since
18158 // machine-independent system no longer uses CopyX nodes.
18159 //
18160 // peephole
18161 // %{
18162 //   peepmatch (incI_iReg movI);
18163 //   peepconstraint (0.dst == 1.dst);
18164 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18165 // %}
18166 
18167 // peephole
18168 // %{
18169 //   peepmatch (decI_iReg movI);
18170 //   peepconstraint (0.dst == 1.dst);
18171 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18172 // %}
18173 
18174 // peephole
18175 // %{
18176 //   peepmatch (addI_iReg_imm movI);
18177 //   peepconstraint (0.dst == 1.dst);
18178 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18179 // %}
18180 
18181 // peephole
18182 // %{
18183 //   peepmatch (incL_iReg movL);
18184 //   peepconstraint (0.dst == 1.dst);
18185 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18186 // %}
18187 
18188 // peephole
18189 // %{
18190 //   peepmatch (decL_iReg movL);
18191 //   peepconstraint (0.dst == 1.dst);
18192 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18193 // %}
18194 
18195 // peephole
18196 // %{
18197 //   peepmatch (addL_iReg_imm movL);
18198 //   peepconstraint (0.dst == 1.dst);
18199 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18200 // %}
18201 
18202 // peephole
18203 // %{
18204 //   peepmatch (addP_iReg_imm movP);
18205 //   peepconstraint (0.dst == 1.dst);
18206 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18207 // %}
18208 
18209 // // Change load of spilled value to only a spill
18210 // instruct storeI(memory mem, iRegI src)
18211 // %{
18212 //   match(Set mem (StoreI mem src));
18213 // %}
18214 //
18215 // instruct loadI(iRegINoSp dst, memory mem)
18216 // %{
18217 //   match(Set dst (LoadI mem));
18218 // %}
18219 //
18220 
18221 //----------SMARTSPILL RULES---------------------------------------------------
18222 // These must follow all instruction definitions as they use the names
18223 // defined in the instructions definitions.
18224 
18225 // Local Variables:
18226 // mode: c++
18227 // End:
    </pre>
  </body>
</html>