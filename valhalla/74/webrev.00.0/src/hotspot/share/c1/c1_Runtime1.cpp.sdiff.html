<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/c1/c1_Runtime1.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LinearScan.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../classfile/classListParser.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/c1/c1_Runtime1.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 235                                                  CodeOffsets::frame_never_safe,
 236                                                  frame_size,
 237                                                  oop_maps,
 238                                                  must_gc_arguments);
 239   assert(blob != NULL, &quot;blob must exist&quot;);
 240   return blob;
 241 }
 242 
 243 void Runtime1::generate_blob_for(BufferBlob* buffer_blob, StubID id) {
 244   assert(0 &lt;= id &amp;&amp; id &lt; number_of_ids, &quot;illegal stub id&quot;);
 245   bool expect_oop_map = true;
 246 #ifdef ASSERT
 247   // Make sure that stubs that need oopmaps have them
 248   switch (id) {
 249     // These stubs don&#39;t need to have an oopmap
 250   case dtrace_object_alloc_id:
 251   case slow_subtype_check_id:
 252   case fpu2long_stub_id:
 253   case unwind_exception_id:
 254   case counter_overflow_id:
<span class="line-modified"> 255 #if defined(SPARC) || defined(PPC32)</span>
 256   case handle_exception_nofpu_id:  // Unused on sparc
 257 #endif
 258     expect_oop_map = false;
 259     break;
 260   default:
 261     break;
 262   }
 263 #endif
 264   StubIDStubAssemblerCodeGenClosure cl(id);
 265   CodeBlob* blob = generate_blob(buffer_blob, id, name_for(id), expect_oop_map, &amp;cl);
 266   // install blob
 267   _blobs[id] = blob;
 268 }
 269 
 270 void Runtime1::initialize(BufferBlob* blob) {
 271   // platform-dependent initialization
 272   initialize_pd();
 273   // generate stubs
 274   for (int id = 0; id &lt; number_of_ids; id++) generate_blob_for(blob, (StubID)id);
 275   // printing
</pre>
<hr />
<pre>
1241             }
1242 
1243             if (TracePatching) {
1244               Disassembler::decode(copy_buff, copy_buff + *byte_count, tty);
1245             }
1246           }
1247         } else if (stub_id == Runtime1::load_appendix_patching_id) {
1248           NativeMovConstReg* n_copy = nativeMovConstReg_at(copy_buff);
1249           assert(n_copy-&gt;data() == 0 ||
1250                  n_copy-&gt;data() == (intptr_t)Universe::non_oop_word(),
1251                  &quot;illegal init value&quot;);
1252           n_copy-&gt;set_data(cast_from_oop&lt;intx&gt;(appendix()));
1253 
1254           if (TracePatching) {
1255             Disassembler::decode(copy_buff, copy_buff + *byte_count, tty);
1256           }
1257         } else {
1258           ShouldNotReachHere();
1259         }
1260 
<span class="line-modified">1261 #if defined(SPARC) || defined(PPC32)</span>
1262         if (load_klass_or_mirror_patch_id ||
1263             stub_id == Runtime1::load_appendix_patching_id) {
1264           // Update the location in the nmethod with the proper
1265           // metadata.  When the code was generated, a NULL was stuffed
1266           // in the metadata table and that table needs to be update to
1267           // have the right value.  On intel the value is kept
1268           // directly in the instruction instead of in the metadata
1269           // table, so set_data above effectively updated the value.
1270           nmethod* nm = CodeCache::find_nmethod(instr_pc);
1271           assert(nm != NULL, &quot;invalid nmethod_pc&quot;);
1272           RelocIterator mds(nm, copy_buff, copy_buff + 1);
1273           bool found = false;
1274           while (mds.next() &amp;&amp; !found) {
1275             if (mds.type() == relocInfo::oop_type) {
1276               assert(stub_id == Runtime1::load_mirror_patching_id ||
1277                      stub_id == Runtime1::load_appendix_patching_id, &quot;wrong stub id&quot;);
1278               oop_Relocation* r = mds.oop_reloc();
1279               oop* oop_adr = r-&gt;oop_addr();
1280               *oop_adr = stub_id == Runtime1::load_mirror_patching_id ? mirror() : appendix();
1281               r-&gt;fix_oop_relocation();
</pre>
<hr />
<pre>
1332           }
1333           ICache::invalidate_range(instr_pc, *byte_count);
1334           NativeGeneralJump::replace_mt_safe(instr_pc, copy_buff);
1335 
1336           if (load_klass_or_mirror_patch_id ||
1337               stub_id == Runtime1::load_appendix_patching_id) {
1338             relocInfo::relocType rtype =
1339               (stub_id == Runtime1::load_klass_patching_id) ?
1340                                    relocInfo::metadata_type :
1341                                    relocInfo::oop_type;
1342             // update relocInfo to metadata
1343             nmethod* nm = CodeCache::find_nmethod(instr_pc);
1344             assert(nm != NULL, &quot;invalid nmethod_pc&quot;);
1345 
1346             // The old patch site is now a move instruction so update
1347             // the reloc info so that it will get updated during
1348             // future GCs.
1349             RelocIterator iter(nm, (address)instr_pc, (address)(instr_pc + 1));
1350             relocInfo::change_reloc_info_for_address(&amp;iter, (address) instr_pc,
1351                                                      relocInfo::none, rtype);
<span class="line-removed">1352 #ifdef SPARC</span>
<span class="line-removed">1353             // Sparc takes two relocations for an metadata so update the second one.</span>
<span class="line-removed">1354             address instr_pc2 = instr_pc + NativeMovConstReg::add_offset;</span>
<span class="line-removed">1355             RelocIterator iter2(nm, instr_pc2, instr_pc2 + 1);</span>
<span class="line-removed">1356             relocInfo::change_reloc_info_for_address(&amp;iter2, (address) instr_pc2,</span>
<span class="line-removed">1357                                                      relocInfo::none, rtype);</span>
<span class="line-removed">1358 #endif</span>
1359 #ifdef PPC32
1360           { address instr_pc2 = instr_pc + NativeMovConstReg::lo_offset;
1361             RelocIterator iter2(nm, instr_pc2, instr_pc2 + 1);
1362             relocInfo::change_reloc_info_for_address(&amp;iter2, (address) instr_pc2,
1363                                                      relocInfo::none, rtype);
1364           }
1365 #endif
1366           }
1367 
1368         } else {
1369           ICache::invalidate_range(copy_buff, *byte_count);
1370           NativeGeneralJump::insert_unconditional(instr_pc, being_initialized_entry);
1371         }
1372       }
1373     }
1374   }
1375 
1376   // If we are patching in a non-perm oop, make sure the nmethod
1377   // is on the right list.
1378   {
</pre>
</td>
<td>
<hr />
<pre>
 235                                                  CodeOffsets::frame_never_safe,
 236                                                  frame_size,
 237                                                  oop_maps,
 238                                                  must_gc_arguments);
 239   assert(blob != NULL, &quot;blob must exist&quot;);
 240   return blob;
 241 }
 242 
 243 void Runtime1::generate_blob_for(BufferBlob* buffer_blob, StubID id) {
 244   assert(0 &lt;= id &amp;&amp; id &lt; number_of_ids, &quot;illegal stub id&quot;);
 245   bool expect_oop_map = true;
 246 #ifdef ASSERT
 247   // Make sure that stubs that need oopmaps have them
 248   switch (id) {
 249     // These stubs don&#39;t need to have an oopmap
 250   case dtrace_object_alloc_id:
 251   case slow_subtype_check_id:
 252   case fpu2long_stub_id:
 253   case unwind_exception_id:
 254   case counter_overflow_id:
<span class="line-modified"> 255 #if defined(PPC32)</span>
 256   case handle_exception_nofpu_id:  // Unused on sparc
 257 #endif
 258     expect_oop_map = false;
 259     break;
 260   default:
 261     break;
 262   }
 263 #endif
 264   StubIDStubAssemblerCodeGenClosure cl(id);
 265   CodeBlob* blob = generate_blob(buffer_blob, id, name_for(id), expect_oop_map, &amp;cl);
 266   // install blob
 267   _blobs[id] = blob;
 268 }
 269 
 270 void Runtime1::initialize(BufferBlob* blob) {
 271   // platform-dependent initialization
 272   initialize_pd();
 273   // generate stubs
 274   for (int id = 0; id &lt; number_of_ids; id++) generate_blob_for(blob, (StubID)id);
 275   // printing
</pre>
<hr />
<pre>
1241             }
1242 
1243             if (TracePatching) {
1244               Disassembler::decode(copy_buff, copy_buff + *byte_count, tty);
1245             }
1246           }
1247         } else if (stub_id == Runtime1::load_appendix_patching_id) {
1248           NativeMovConstReg* n_copy = nativeMovConstReg_at(copy_buff);
1249           assert(n_copy-&gt;data() == 0 ||
1250                  n_copy-&gt;data() == (intptr_t)Universe::non_oop_word(),
1251                  &quot;illegal init value&quot;);
1252           n_copy-&gt;set_data(cast_from_oop&lt;intx&gt;(appendix()));
1253 
1254           if (TracePatching) {
1255             Disassembler::decode(copy_buff, copy_buff + *byte_count, tty);
1256           }
1257         } else {
1258           ShouldNotReachHere();
1259         }
1260 
<span class="line-modified">1261 #if defined(PPC32)</span>
1262         if (load_klass_or_mirror_patch_id ||
1263             stub_id == Runtime1::load_appendix_patching_id) {
1264           // Update the location in the nmethod with the proper
1265           // metadata.  When the code was generated, a NULL was stuffed
1266           // in the metadata table and that table needs to be update to
1267           // have the right value.  On intel the value is kept
1268           // directly in the instruction instead of in the metadata
1269           // table, so set_data above effectively updated the value.
1270           nmethod* nm = CodeCache::find_nmethod(instr_pc);
1271           assert(nm != NULL, &quot;invalid nmethod_pc&quot;);
1272           RelocIterator mds(nm, copy_buff, copy_buff + 1);
1273           bool found = false;
1274           while (mds.next() &amp;&amp; !found) {
1275             if (mds.type() == relocInfo::oop_type) {
1276               assert(stub_id == Runtime1::load_mirror_patching_id ||
1277                      stub_id == Runtime1::load_appendix_patching_id, &quot;wrong stub id&quot;);
1278               oop_Relocation* r = mds.oop_reloc();
1279               oop* oop_adr = r-&gt;oop_addr();
1280               *oop_adr = stub_id == Runtime1::load_mirror_patching_id ? mirror() : appendix();
1281               r-&gt;fix_oop_relocation();
</pre>
<hr />
<pre>
1332           }
1333           ICache::invalidate_range(instr_pc, *byte_count);
1334           NativeGeneralJump::replace_mt_safe(instr_pc, copy_buff);
1335 
1336           if (load_klass_or_mirror_patch_id ||
1337               stub_id == Runtime1::load_appendix_patching_id) {
1338             relocInfo::relocType rtype =
1339               (stub_id == Runtime1::load_klass_patching_id) ?
1340                                    relocInfo::metadata_type :
1341                                    relocInfo::oop_type;
1342             // update relocInfo to metadata
1343             nmethod* nm = CodeCache::find_nmethod(instr_pc);
1344             assert(nm != NULL, &quot;invalid nmethod_pc&quot;);
1345 
1346             // The old patch site is now a move instruction so update
1347             // the reloc info so that it will get updated during
1348             // future GCs.
1349             RelocIterator iter(nm, (address)instr_pc, (address)(instr_pc + 1));
1350             relocInfo::change_reloc_info_for_address(&amp;iter, (address) instr_pc,
1351                                                      relocInfo::none, rtype);







1352 #ifdef PPC32
1353           { address instr_pc2 = instr_pc + NativeMovConstReg::lo_offset;
1354             RelocIterator iter2(nm, instr_pc2, instr_pc2 + 1);
1355             relocInfo::change_reloc_info_for_address(&amp;iter2, (address) instr_pc2,
1356                                                      relocInfo::none, rtype);
1357           }
1358 #endif
1359           }
1360 
1361         } else {
1362           ICache::invalidate_range(copy_buff, *byte_count);
1363           NativeGeneralJump::insert_unconditional(instr_pc, being_initialized_entry);
1364         }
1365       }
1366     }
1367   }
1368 
1369   // If we are patching in a non-perm oop, make sure the nmethod
1370   // is on the right list.
1371   {
</pre>
</td>
</tr>
</table>
<center><a href="c1_LinearScan.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="../classfile/classListParser.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>