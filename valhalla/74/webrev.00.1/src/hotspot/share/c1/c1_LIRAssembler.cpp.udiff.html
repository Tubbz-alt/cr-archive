<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff src/hotspot/share/c1/c1_LIRAssembler.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIR.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LinearScan.cpp.udiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/c1/c1_LIRAssembler.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -29,12 +29,14 @@</span>
  #include &quot;c1/c1_InstructionPrinter.hpp&quot;
  #include &quot;c1/c1_LIRAssembler.hpp&quot;
  #include &quot;c1/c1_MacroAssembler.hpp&quot;
  #include &quot;c1/c1_ValueStack.hpp&quot;
  #include &quot;ci/ciInstance.hpp&quot;
<span class="udiff-line-added">+ #include &quot;ci/ciValueKlass.hpp&quot;</span>
  #include &quot;gc/shared/barrierSet.hpp&quot;
  #include &quot;runtime/os.hpp&quot;
<span class="udiff-line-added">+ #include &quot;runtime/sharedRuntime.hpp&quot;</span>
  
  void LIR_Assembler::patching_epilog(PatchingStub* patch, LIR_PatchCode patch_code, Register obj, CodeEmitInfo* info) {
    // We must have enough patching space so that call can be inserted.
    // We cannot use fat nops here, since the concurrent code rewrite may transiently
    // create the illegal instruction sequence.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -57,10 +59,11 @@</span>
          ShouldNotReachHere();
      }
    } else if (patch-&gt;id() == PatchingStub::load_klass_id) {
      switch (code) {
        case Bytecodes::_new:
<span class="udiff-line-added">+       case Bytecodes::_defaultvalue:</span>
        case Bytecodes::_anewarray:
        case Bytecodes::_multianewarray:
        case Bytecodes::_instanceof:
        case Bytecodes::_checkcast:
          break;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -113,10 +116,11 @@</span>
  
  LIR_Assembler::~LIR_Assembler() {
    // The unwind handler label may be unnbound if this destructor is invoked because of a bail-out.
    // Reset it here to avoid an assertion.
    _unwind_handler_entry.reset();
<span class="udiff-line-added">+   _verified_value_entry.reset();</span>
  }
  
  
  void LIR_Assembler::check_codespace() {
    CodeSection* cs = _masm-&gt;code_section();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -334,13 +338,13 @@</span>
      compilation()-&gt;add_exception_handlers_for_pco(pc_offset, info-&gt;exception_handlers());
    }
  }
  
  
<span class="udiff-line-modified-removed">- void LIR_Assembler::add_call_info(int pc_offset, CodeEmitInfo* cinfo) {</span>
<span class="udiff-line-modified-added">+ void LIR_Assembler::add_call_info(int pc_offset, CodeEmitInfo* cinfo, bool maybe_return_as_fields) {</span>
    flush_debug_info(pc_offset);
<span class="udiff-line-modified-removed">-   cinfo-&gt;record_debug_info(compilation()-&gt;debug_info_recorder(), pc_offset);</span>
<span class="udiff-line-modified-added">+   cinfo-&gt;record_debug_info(compilation()-&gt;debug_info_recorder(), pc_offset, maybe_return_as_fields);</span>
    if (cinfo-&gt;exception_handlers() != NULL) {
      compilation()-&gt;add_exception_handlers_for_pco(pc_offset, cinfo-&gt;exception_handlers());
    }
  }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -479,10 +483,16 @@</span>
    // Record if this method has MethodHandle invokes.
    if (op-&gt;is_method_handle_invoke()) {
      compilation()-&gt;set_has_method_handle_invokes(true);
    }
  
<span class="udiff-line-added">+   ciValueKlass* vk;</span>
<span class="udiff-line-added">+   if (op-&gt;maybe_return_as_fields(&amp;vk)) {</span>
<span class="udiff-line-added">+     int offset = store_value_type_fields_to_buf(vk);</span>
<span class="udiff-line-added">+     add_call_info(offset, op-&gt;info(), true);</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ </span>
  #if defined(IA32) &amp;&amp; defined(TIERED)
    // C2 leave fpu stack dirty clean it
    if (UseSSE &lt; 2) {
      int i;
      for ( i = 1; i &lt;= 7 ; i++ ) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -580,10 +590,145 @@</span>
        Unimplemented();
        break;
    }
  }
  
<span class="udiff-line-added">+ void LIR_Assembler::add_scalarized_entry_info(int pc_offset) {</span>
<span class="udiff-line-added">+   flush_debug_info(pc_offset);</span>
<span class="udiff-line-added">+   DebugInformationRecorder* debug_info = compilation()-&gt;debug_info_recorder();</span>
<span class="udiff-line-added">+   // The VEP and VVEP(RO) of a C1-compiled method call buffer_value_args_xxx()</span>
<span class="udiff-line-added">+   // before doing any argument shuffling. This call may cause GC. When GC happens,</span>
<span class="udiff-line-added">+   // all the parameters are still as passed by the caller, so we just use</span>
<span class="udiff-line-added">+   // map-&gt;set_include_argument_oops() inside frame::sender_for_compiled_frame(RegisterMap* map).</span>
<span class="udiff-line-added">+   // There&#39;s no need to build a GC map here.</span>
<span class="udiff-line-added">+   OopMap* oop_map = new OopMap(0, 0);</span>
<span class="udiff-line-added">+   debug_info-&gt;add_safepoint(pc_offset, oop_map);</span>
<span class="udiff-line-added">+   DebugToken* locvals = debug_info-&gt;create_scope_values(NULL); // FIXME is this needed (for Java debugging to work properly??)</span>
<span class="udiff-line-added">+   DebugToken* expvals = debug_info-&gt;create_scope_values(NULL); // FIXME is this needed (for Java debugging to work properly??)</span>
<span class="udiff-line-added">+   DebugToken* monvals = debug_info-&gt;create_monitor_values(NULL); // FIXME: need testing with synchronized method</span>
<span class="udiff-line-added">+   bool reexecute = false;</span>
<span class="udiff-line-added">+   bool return_oop = false; // This flag will be ignored since it used only for C2 with escape analysis.</span>
<span class="udiff-line-added">+   bool rethrow_exception = false;</span>
<span class="udiff-line-added">+   bool is_method_handle_invoke = false;</span>
<span class="udiff-line-added">+   debug_info-&gt;describe_scope(pc_offset, methodHandle(), method(), 0, reexecute, rethrow_exception, is_method_handle_invoke, return_oop, false, locvals, expvals, monvals);</span>
<span class="udiff-line-added">+   debug_info-&gt;end_safepoint(pc_offset);</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ // The entries points of C1-compiled methods can have the following types:</span>
<span class="udiff-line-added">+ // (1) Methods with no value args</span>
<span class="udiff-line-added">+ // (2) Methods with value receiver but no value args</span>
<span class="udiff-line-added">+ //     VVEP_RO is the same as VVEP</span>
<span class="udiff-line-added">+ // (3) Methods with non-value receiver and some value args</span>
<span class="udiff-line-added">+ //     VVEP_RO is the same as VEP</span>
<span class="udiff-line-added">+ // (4) Methods with value receiver and other value args</span>
<span class="udiff-line-added">+ //     Separate VEP, VVEP and VVEP_RO</span>
<span class="udiff-line-added">+ //</span>
<span class="udiff-line-added">+ // (1)               (2)                 (3)                    (4)</span>
<span class="udiff-line-added">+ // UEP/UVEP:         VEP:                UEP:                   UEP:</span>
<span class="udiff-line-added">+ //   check_icache      pack receiver       check_icache           check_icache</span>
<span class="udiff-line-added">+ // VEP/VVEP/VVEP_RO    jump to VVEP      VEP/VVEP_RO:           VVEP_RO:</span>
<span class="udiff-line-added">+ //   body            UEP/UVEP:             pack value args        pack value args (except receiver)</span>
<span class="udiff-line-added">+ //                     check_icache        jump to VVEP           jump to VVEP</span>
<span class="udiff-line-added">+ //                   VVEP/VVEP_RO        UVEP:                  VEP:</span>
<span class="udiff-line-added">+ //                     body                check_icache           pack all value args</span>
<span class="udiff-line-added">+ //                                       VVEP:                    jump to VVEP</span>
<span class="udiff-line-added">+ //                                         body                 UVEP:</span>
<span class="udiff-line-added">+ //                                                                check_icache</span>
<span class="udiff-line-added">+ //                                                              VVEP:</span>
<span class="udiff-line-added">+ //                                                                body</span>
<span class="udiff-line-added">+ void LIR_Assembler::emit_std_entries() {</span>
<span class="udiff-line-added">+   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, _masm-&gt;offset());</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+   _masm-&gt;align(CodeEntryAlignment);</span>
<span class="udiff-line-added">+   const CompiledEntrySignature* ces = compilation()-&gt;compiled_entry_signature();</span>
<span class="udiff-line-added">+   if (ces-&gt;has_scalarized_args()) {</span>
<span class="udiff-line-added">+     assert(InlineTypePassFieldsAsArgs &amp;&amp; method()-&gt;get_Method()-&gt;has_scalarized_args(), &quot;must be&quot;);</span>
<span class="udiff-line-added">+     CodeOffsets::Entries ro_entry_type = ces-&gt;c1_value_ro_entry_type();</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // UEP: check icache and fall-through</span>
<span class="udiff-line-added">+     if (ro_entry_type != CodeOffsets::Verified_Value_Entry) {</span>
<span class="udiff-line-added">+       offsets()-&gt;set_value(CodeOffsets::Entry, _masm-&gt;offset());</span>
<span class="udiff-line-added">+       if (needs_icache(method())) {</span>
<span class="udiff-line-added">+         check_icache();</span>
<span class="udiff-line-added">+       }</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // VVEP_RO: pack all value parameters, except the receiver</span>
<span class="udiff-line-added">+     if (ro_entry_type == CodeOffsets::Verified_Value_Entry_RO) {</span>
<span class="udiff-line-added">+       emit_std_entry(CodeOffsets::Verified_Value_Entry_RO, ces);</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // VEP: pack all value parameters</span>
<span class="udiff-line-added">+     _masm-&gt;align(CodeEntryAlignment);</span>
<span class="udiff-line-added">+     emit_std_entry(CodeOffsets::Verified_Entry, ces);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // UVEP: check icache and fall-through</span>
<span class="udiff-line-added">+     _masm-&gt;align(CodeEntryAlignment);</span>
<span class="udiff-line-added">+     offsets()-&gt;set_value(CodeOffsets::Value_Entry, _masm-&gt;offset());</span>
<span class="udiff-line-added">+     if (ro_entry_type == CodeOffsets::Verified_Value_Entry) {</span>
<span class="udiff-line-added">+       // Special case if we have VVEP == VVEP(RO):</span>
<span class="udiff-line-added">+       // this means UVEP (called by C1) == UEP (called by C2).</span>
<span class="udiff-line-added">+       offsets()-&gt;set_value(CodeOffsets::Entry, _masm-&gt;offset());</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     if (needs_icache(method())) {</span>
<span class="udiff-line-added">+       check_icache();</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // VVEP: all value parameters are passed as refs - no packing.</span>
<span class="udiff-line-added">+     emit_std_entry(CodeOffsets::Verified_Value_Entry, NULL);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     if (ro_entry_type != CodeOffsets::Verified_Value_Entry_RO) {</span>
<span class="udiff-line-added">+       // The VVEP(RO) is the same as VEP or VVEP</span>
<span class="udiff-line-added">+       assert(ro_entry_type == CodeOffsets::Verified_Entry ||</span>
<span class="udiff-line-added">+              ro_entry_type == CodeOffsets::Verified_Value_Entry, &quot;must be&quot;);</span>
<span class="udiff-line-added">+       offsets()-&gt;set_value(CodeOffsets::Verified_Value_Entry_RO,</span>
<span class="udiff-line-added">+                            offsets()-&gt;value(ro_entry_type));</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+   } else {</span>
<span class="udiff-line-added">+     // All 3 entries are the same (no value-type packing)</span>
<span class="udiff-line-added">+     offsets()-&gt;set_value(CodeOffsets::Entry, _masm-&gt;offset());</span>
<span class="udiff-line-added">+     offsets()-&gt;set_value(CodeOffsets::Value_Entry, _masm-&gt;offset());</span>
<span class="udiff-line-added">+     if (needs_icache(method())) {</span>
<span class="udiff-line-added">+       check_icache();</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     emit_std_entry(CodeOffsets::Verified_Value_Entry, NULL);</span>
<span class="udiff-line-added">+     offsets()-&gt;set_value(CodeOffsets::Verified_Entry, offsets()-&gt;value(CodeOffsets::Verified_Value_Entry));</span>
<span class="udiff-line-added">+     offsets()-&gt;set_value(CodeOffsets::Verified_Value_Entry_RO, offsets()-&gt;value(CodeOffsets::Verified_Value_Entry));</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ void LIR_Assembler::emit_std_entry(CodeOffsets::Entries entry, const CompiledEntrySignature* ces) {</span>
<span class="udiff-line-added">+   offsets()-&gt;set_value(entry, _masm-&gt;offset());</span>
<span class="udiff-line-added">+   _masm-&gt;verified_entry();</span>
<span class="udiff-line-added">+   switch (entry) {</span>
<span class="udiff-line-added">+   case CodeOffsets::Verified_Entry: {</span>
<span class="udiff-line-added">+     if (needs_clinit_barrier_on_entry(method())) {</span>
<span class="udiff-line-added">+       clinit_barrier(method());</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     int rt_call_offset = _masm-&gt;verified_entry(ces, initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()-&gt;sp_offset_for_orig_pc()), _verified_value_entry);</span>
<span class="udiff-line-added">+     add_scalarized_entry_info(rt_call_offset);</span>
<span class="udiff-line-added">+     break;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   case CodeOffsets::Verified_Value_Entry_RO: {</span>
<span class="udiff-line-added">+     assert(!needs_clinit_barrier_on_entry(method()), &quot;can&#39;t be static&quot;);</span>
<span class="udiff-line-added">+     int rt_call_offset = _masm-&gt;verified_value_ro_entry(ces, initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()-&gt;sp_offset_for_orig_pc()), _verified_value_entry);</span>
<span class="udiff-line-added">+     add_scalarized_entry_info(rt_call_offset);</span>
<span class="udiff-line-added">+     break;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   case CodeOffsets::Verified_Value_Entry: {</span>
<span class="udiff-line-added">+     if (needs_clinit_barrier_on_entry(method())) {</span>
<span class="udiff-line-added">+       clinit_barrier(method());</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+     build_frame();</span>
<span class="udiff-line-added">+     offsets()-&gt;set_value(CodeOffsets::Frame_Complete, _masm-&gt;offset());</span>
<span class="udiff-line-added">+     break;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+   default:</span>
<span class="udiff-line-added">+     ShouldNotReachHere();</span>
<span class="udiff-line-added">+     break;</span>
<span class="udiff-line-added">+   }</span>
<span class="udiff-line-added">+ }</span>
  
  void LIR_Assembler::emit_op0(LIR_Op0* op) {
    switch (op-&gt;code()) {
      case lir_nop:
        assert(op-&gt;info() == NULL, &quot;not supported&quot;);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -593,23 +738,11 @@</span>
      case lir_label:
        Unimplemented();
        break;
  
      case lir_std_entry:
<span class="udiff-line-modified-removed">-       // init offsets</span>
<span class="udiff-line-removed">-       offsets()-&gt;set_value(CodeOffsets::OSR_Entry, _masm-&gt;offset());</span>
<span class="udiff-line-removed">-       _masm-&gt;align(CodeEntryAlignment);</span>
<span class="udiff-line-removed">-       if (needs_icache(compilation()-&gt;method())) {</span>
<span class="udiff-line-removed">-         check_icache();</span>
<span class="udiff-line-removed">-       }</span>
<span class="udiff-line-removed">-       offsets()-&gt;set_value(CodeOffsets::Verified_Entry, _masm-&gt;offset());</span>
<span class="udiff-line-removed">-       _masm-&gt;verified_entry();</span>
<span class="udiff-line-removed">-       if (needs_clinit_barrier_on_entry(compilation()-&gt;method())) {</span>
<span class="udiff-line-removed">-         clinit_barrier(compilation()-&gt;method());</span>
<span class="udiff-line-removed">-       }</span>
<span class="udiff-line-removed">-       build_frame();</span>
<span class="udiff-line-removed">-       offsets()-&gt;set_value(CodeOffsets::Frame_Complete, _masm-&gt;offset());</span>
<span class="udiff-line-modified-added">+       emit_std_entries();</span>
        break;
  
      case lir_osr_entry:
        offsets()-&gt;set_value(CodeOffsets::OSR_Entry, _masm-&gt;offset());
        osr_entry();
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -659,10 +792,14 @@</span>
  
      case lir_on_spin_wait:
        on_spin_wait();
        break;
  
<span class="udiff-line-added">+     case lir_check_orig_pc:</span>
<span class="udiff-line-added">+       check_orig_pc();</span>
<span class="udiff-line-added">+       break;</span>
<span class="udiff-line-added">+ </span>
      default:
        ShouldNotReachHere();
        break;
    }
  }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -752,11 +889,12 @@</span>
    }
  }
  
  
  void LIR_Assembler::build_frame() {
<span class="udiff-line-modified-removed">-   _masm-&gt;build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());</span>
<span class="udiff-line-modified-added">+   _masm-&gt;build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()-&gt;sp_offset_for_orig_pc()),</span>
<span class="udiff-line-added">+                      needs_stack_repair(), method()-&gt;has_scalarized_args(), &amp;_verified_value_entry);</span>
  }
  
  
  void LIR_Assembler::roundfp_op(LIR_Opr src, LIR_Opr tmp, LIR_Opr dest, bool pop_fpu_stack) {
    assert(strict_fp_requires_explicit_rounding, &quot;not required&quot;);
</pre>
<center><a href="c1_LIR.hpp.udiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LinearScan.cpp.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>