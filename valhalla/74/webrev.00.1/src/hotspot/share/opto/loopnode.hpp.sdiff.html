<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/loopnode.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="generateOptoStub.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="loopopts.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/loopnode.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  59   virtual uint size_of() const { return sizeof(*this); }
  60 protected:
  61   uint _loop_flags;
  62   // Names for flag bitfields
  63   enum { Normal=0, Pre=1, Main=2, Post=3, PreMainPostFlagsMask=3,
  64          MainHasNoPreLoop=4,
  65          HasExactTripCount=8,
  66          InnerLoop=16,
  67          PartialPeelLoop=32,
  68          PartialPeelFailed=64,
  69          HasReductions=128,
  70          WasSlpAnalyzed=256,
  71          PassedSlpAnalysis=512,
  72          DoUnrollOnly=1024,
  73          VectorizedLoop=2048,
  74          HasAtomicPostLoop=4096,
  75          HasRangeChecks=8192,
  76          IsMultiversioned=16384,
  77          StripMined=32768,
  78          SubwordLoop=65536,
<span class="line-modified">  79          ProfileTripFailed=131072};</span>

  80   char _unswitch_count;
  81   enum { _unswitch_max=3 };
  82   char _postloop_flags;
  83   enum { LoopNotRCEChecked = 0, LoopRCEChecked = 1, RCEPostLoop = 2 };
  84 
  85   // Expected trip count from profile data
  86   float _profile_trip_cnt;
  87 
  88 public:
  89   // Names for edge indices
  90   enum { Self=0, EntryControl, LoopBackControl };
  91 
  92   bool is_inner_loop() const { return _loop_flags &amp; InnerLoop; }
  93   void set_inner_loop() { _loop_flags |= InnerLoop; }
  94 
  95   bool range_checks_present() const { return _loop_flags &amp; HasRangeChecks; }
  96   bool is_multiversioned() const { return _loop_flags &amp; IsMultiversioned; }
  97   bool is_vectorized_loop() const { return _loop_flags &amp; VectorizedLoop; }
  98   bool is_partial_peel_loop() const { return _loop_flags &amp; PartialPeelLoop; }
  99   void set_partial_peel_loop() { _loop_flags |= PartialPeelLoop; }
 100   bool partial_peel_has_failed() const { return _loop_flags &amp; PartialPeelFailed; }
 101   bool is_strip_mined() const { return _loop_flags &amp; StripMined; }
 102   bool is_profile_trip_failed() const { return _loop_flags &amp; ProfileTripFailed; }
 103   bool is_subword_loop() const { return _loop_flags &amp; SubwordLoop; }

 104 
 105   void mark_partial_peel_failed() { _loop_flags |= PartialPeelFailed; }
 106   void mark_has_reductions() { _loop_flags |= HasReductions; }
 107   void mark_was_slp() { _loop_flags |= WasSlpAnalyzed; }
 108   void mark_passed_slp() { _loop_flags |= PassedSlpAnalysis; }
 109   void mark_do_unroll_only() { _loop_flags |= DoUnrollOnly; }
 110   void mark_loop_vectorized() { _loop_flags |= VectorizedLoop; }
 111   void mark_has_atomic_post_loop() { _loop_flags |= HasAtomicPostLoop; }
 112   void mark_has_range_checks() { _loop_flags |=  HasRangeChecks; }
 113   void mark_is_multiversioned() { _loop_flags |= IsMultiversioned; }
 114   void mark_strip_mined() { _loop_flags |= StripMined; }
 115   void clear_strip_mined() { _loop_flags &amp;= ~StripMined; }
 116   void mark_profile_trip_failed() { _loop_flags |= ProfileTripFailed; }
 117   void mark_subword_loop() { _loop_flags |= SubwordLoop; }

 118 
 119   int unswitch_max() { return _unswitch_max; }
 120   int unswitch_count() { return _unswitch_count; }
 121 
 122   int has_been_range_checked() const { return _postloop_flags &amp; LoopRCEChecked; }
 123   void set_has_been_range_checked() { _postloop_flags |= LoopRCEChecked; }
 124   int is_rce_post_loop() const { return _postloop_flags &amp; RCEPostLoop; }
 125   void set_is_rce_post_loop() { _postloop_flags |= RCEPostLoop; }
 126 
 127   void set_unswitch_count(int val) {
 128     assert (val &lt;= unswitch_max(), &quot;too many unswitches&quot;);
 129     _unswitch_count = val;
 130   }
 131 
 132   void set_profile_trip_cnt(float ptc) { _profile_trip_cnt = ptc; }
 133   float profile_trip_cnt()             { return _profile_trip_cnt; }
 134 
 135   LoopNode(Node *entry, Node *backedge)
 136     : RegionNode(3), _loop_flags(0), _unswitch_count(0),
 137       _postloop_flags(0), _profile_trip_cnt(COUNT_UNKNOWN)  {
</pre>
<hr />
<pre>
1211                                         Node_List &amp;old_new,
1212                                         int opcode,
1213                                         CloneLoopMode mode);
1214 
1215   // Clone a loop and return the clone head (clone_loop_head).
1216   // Added nodes include int(1), int(0) - disconnected, If, IfTrue, IfFalse,
1217   // This routine was created for usage in CountedLoopReserveKit.
1218   //
1219   //    int(1) -&gt; If -&gt; IfTrue -&gt; original_loop_head
1220   //              |
1221   //              V
1222   //           IfFalse -&gt; clone_loop_head (returned by function pointer)
1223   //
1224   LoopNode* create_reserve_version_of_loop(IdealLoopTree *loop, CountedLoopReserveKit* lk);
1225   // Clone loop with an invariant test (that does not exit) and
1226   // insert a clone of the test that selects which version to
1227   // execute.
1228   void do_unswitching (IdealLoopTree *loop, Node_List &amp;old_new);
1229 
1230   // Find candidate &quot;if&quot; for unswitching
<span class="line-modified">1231   IfNode* find_unswitching_candidate(const IdealLoopTree *loop) const;</span>
1232 
1233   // Range Check Elimination uses this function!
1234   // Constrain the main loop iterations so the affine function:
1235   //    low_limit &lt;= scale_con * I + offset  &lt;  upper_limit
1236   // always holds true.  That is, either increase the number of iterations in
1237   // the pre-loop or the post-loop until the condition holds true in the main
1238   // loop.  Scale_con, offset and limit are all loop invariant.
1239   void add_constraint( int stride_con, int scale_con, Node *offset, Node *low_limit, Node *upper_limit, Node *pre_ctrl, Node **pre_limit, Node **main_limit );
1240   // Helper function for add_constraint().
1241   Node* adjust_limit(int stride_con, Node * scale, Node *offset, Node *rc_limit, Node *loop_limit, Node *pre_ctrl, bool round_up);
1242 
1243   // Partially peel loop up through last_peel node.
1244   bool partial_peel( IdealLoopTree *loop, Node_List &amp;old_new );
1245 
1246   // Create a scheduled list of nodes control dependent on ctrl set.
1247   void scheduled_nodelist( IdealLoopTree *loop, VectorSet&amp; ctrl, Node_List &amp;sched );
1248   // Has a use in the vector set
1249   bool has_use_in_set( Node* n, VectorSet&amp; vset );
1250   // Has use internal to the vector set (ie. not in a phi at the loop head)
1251   bool has_use_internal_to_set( Node* n, VectorSet&amp; vset, IdealLoopTree *loop );
</pre>
<hr />
<pre>
1333   bool match_fill_loop(IdealLoopTree* lpt, Node*&amp; store, Node*&amp; store_value,
1334                        Node*&amp; shift, Node*&amp; offset);
1335 
1336 private:
1337   // Return a type based on condition control flow
1338   const TypeInt* filtered_type( Node *n, Node* n_ctrl);
1339   const TypeInt* filtered_type( Node *n ) { return filtered_type(n, NULL); }
1340  // Helpers for filtered type
1341   const TypeInt* filtered_type_from_dominators( Node* val, Node *val_ctrl);
1342 
1343   // Helper functions
1344   Node *spinup( Node *iff, Node *new_false, Node *new_true, Node *region, Node *phi, small_cache *cache );
1345   Node *find_use_block( Node *use, Node *def, Node *old_false, Node *new_false, Node *old_true, Node *new_true );
1346   void handle_use( Node *use, Node *def, small_cache *cache, Node *region_dom, Node *new_false, Node *new_true, Node *old_false, Node *old_true );
1347   bool split_up( Node *n, Node *blk1, Node *blk2 );
1348   void sink_use( Node *use, Node *post_loop );
1349   Node *place_near_use( Node *useblock ) const;
1350   Node* try_move_store_before_loop(Node* n, Node *n_ctrl);
1351   void try_move_store_after_loop(Node* n);
1352   bool identical_backtoback_ifs(Node *n);

1353   bool can_split_if(Node *n_ctrl);
1354 
1355   // Determine if a method is too big for a/another round of split-if, based on
1356   // a magic (approximate) ratio derived from the equally magic constant 35000,
1357   // previously used for this purpose (but without relating to the node limit).
1358   bool must_throttle_split_if() {
1359     uint threshold = C-&gt;max_node_limit() * 2 / 5;
1360     return C-&gt;live_nodes() &gt; threshold;
1361   }
1362 
1363   // A simplistic node request tracking mechanism, where
1364   //   = UINT_MAX   Request not valid or made final.
1365   //   &lt; UINT_MAX   Nodes currently requested (estimate).
1366   uint _nodes_required;
1367 
1368   enum { REQUIRE_MIN = 70 };
1369 
1370   uint nodes_required() const { return _nodes_required; }
1371 
1372   // Given the _currently_  available number of nodes, check  whether there is
</pre>
</td>
<td>
<hr />
<pre>
  59   virtual uint size_of() const { return sizeof(*this); }
  60 protected:
  61   uint _loop_flags;
  62   // Names for flag bitfields
  63   enum { Normal=0, Pre=1, Main=2, Post=3, PreMainPostFlagsMask=3,
  64          MainHasNoPreLoop=4,
  65          HasExactTripCount=8,
  66          InnerLoop=16,
  67          PartialPeelLoop=32,
  68          PartialPeelFailed=64,
  69          HasReductions=128,
  70          WasSlpAnalyzed=256,
  71          PassedSlpAnalysis=512,
  72          DoUnrollOnly=1024,
  73          VectorizedLoop=2048,
  74          HasAtomicPostLoop=4096,
  75          HasRangeChecks=8192,
  76          IsMultiversioned=16384,
  77          StripMined=32768,
  78          SubwordLoop=65536,
<span class="line-modified">  79          ProfileTripFailed=131072,</span>
<span class="line-added">  80          FlattenedArrays=262144};</span>
  81   char _unswitch_count;
  82   enum { _unswitch_max=3 };
  83   char _postloop_flags;
  84   enum { LoopNotRCEChecked = 0, LoopRCEChecked = 1, RCEPostLoop = 2 };
  85 
  86   // Expected trip count from profile data
  87   float _profile_trip_cnt;
  88 
  89 public:
  90   // Names for edge indices
  91   enum { Self=0, EntryControl, LoopBackControl };
  92 
  93   bool is_inner_loop() const { return _loop_flags &amp; InnerLoop; }
  94   void set_inner_loop() { _loop_flags |= InnerLoop; }
  95 
  96   bool range_checks_present() const { return _loop_flags &amp; HasRangeChecks; }
  97   bool is_multiversioned() const { return _loop_flags &amp; IsMultiversioned; }
  98   bool is_vectorized_loop() const { return _loop_flags &amp; VectorizedLoop; }
  99   bool is_partial_peel_loop() const { return _loop_flags &amp; PartialPeelLoop; }
 100   void set_partial_peel_loop() { _loop_flags |= PartialPeelLoop; }
 101   bool partial_peel_has_failed() const { return _loop_flags &amp; PartialPeelFailed; }
 102   bool is_strip_mined() const { return _loop_flags &amp; StripMined; }
 103   bool is_profile_trip_failed() const { return _loop_flags &amp; ProfileTripFailed; }
 104   bool is_subword_loop() const { return _loop_flags &amp; SubwordLoop; }
<span class="line-added"> 105   bool is_flattened_arrays() const { return _loop_flags &amp; FlattenedArrays; }</span>
 106 
 107   void mark_partial_peel_failed() { _loop_flags |= PartialPeelFailed; }
 108   void mark_has_reductions() { _loop_flags |= HasReductions; }
 109   void mark_was_slp() { _loop_flags |= WasSlpAnalyzed; }
 110   void mark_passed_slp() { _loop_flags |= PassedSlpAnalysis; }
 111   void mark_do_unroll_only() { _loop_flags |= DoUnrollOnly; }
 112   void mark_loop_vectorized() { _loop_flags |= VectorizedLoop; }
 113   void mark_has_atomic_post_loop() { _loop_flags |= HasAtomicPostLoop; }
 114   void mark_has_range_checks() { _loop_flags |=  HasRangeChecks; }
 115   void mark_is_multiversioned() { _loop_flags |= IsMultiversioned; }
 116   void mark_strip_mined() { _loop_flags |= StripMined; }
 117   void clear_strip_mined() { _loop_flags &amp;= ~StripMined; }
 118   void mark_profile_trip_failed() { _loop_flags |= ProfileTripFailed; }
 119   void mark_subword_loop() { _loop_flags |= SubwordLoop; }
<span class="line-added"> 120   void mark_flattened_arrays() { _loop_flags |= FlattenedArrays; }</span>
 121 
 122   int unswitch_max() { return _unswitch_max; }
 123   int unswitch_count() { return _unswitch_count; }
 124 
 125   int has_been_range_checked() const { return _postloop_flags &amp; LoopRCEChecked; }
 126   void set_has_been_range_checked() { _postloop_flags |= LoopRCEChecked; }
 127   int is_rce_post_loop() const { return _postloop_flags &amp; RCEPostLoop; }
 128   void set_is_rce_post_loop() { _postloop_flags |= RCEPostLoop; }
 129 
 130   void set_unswitch_count(int val) {
 131     assert (val &lt;= unswitch_max(), &quot;too many unswitches&quot;);
 132     _unswitch_count = val;
 133   }
 134 
 135   void set_profile_trip_cnt(float ptc) { _profile_trip_cnt = ptc; }
 136   float profile_trip_cnt()             { return _profile_trip_cnt; }
 137 
 138   LoopNode(Node *entry, Node *backedge)
 139     : RegionNode(3), _loop_flags(0), _unswitch_count(0),
 140       _postloop_flags(0), _profile_trip_cnt(COUNT_UNKNOWN)  {
</pre>
<hr />
<pre>
1214                                         Node_List &amp;old_new,
1215                                         int opcode,
1216                                         CloneLoopMode mode);
1217 
1218   // Clone a loop and return the clone head (clone_loop_head).
1219   // Added nodes include int(1), int(0) - disconnected, If, IfTrue, IfFalse,
1220   // This routine was created for usage in CountedLoopReserveKit.
1221   //
1222   //    int(1) -&gt; If -&gt; IfTrue -&gt; original_loop_head
1223   //              |
1224   //              V
1225   //           IfFalse -&gt; clone_loop_head (returned by function pointer)
1226   //
1227   LoopNode* create_reserve_version_of_loop(IdealLoopTree *loop, CountedLoopReserveKit* lk);
1228   // Clone loop with an invariant test (that does not exit) and
1229   // insert a clone of the test that selects which version to
1230   // execute.
1231   void do_unswitching (IdealLoopTree *loop, Node_List &amp;old_new);
1232 
1233   // Find candidate &quot;if&quot; for unswitching
<span class="line-modified">1234   IfNode* find_unswitching_candidate(const IdealLoopTree *loop, Node_List&amp; unswitch_iffs) const;</span>
1235 
1236   // Range Check Elimination uses this function!
1237   // Constrain the main loop iterations so the affine function:
1238   //    low_limit &lt;= scale_con * I + offset  &lt;  upper_limit
1239   // always holds true.  That is, either increase the number of iterations in
1240   // the pre-loop or the post-loop until the condition holds true in the main
1241   // loop.  Scale_con, offset and limit are all loop invariant.
1242   void add_constraint( int stride_con, int scale_con, Node *offset, Node *low_limit, Node *upper_limit, Node *pre_ctrl, Node **pre_limit, Node **main_limit );
1243   // Helper function for add_constraint().
1244   Node* adjust_limit(int stride_con, Node * scale, Node *offset, Node *rc_limit, Node *loop_limit, Node *pre_ctrl, bool round_up);
1245 
1246   // Partially peel loop up through last_peel node.
1247   bool partial_peel( IdealLoopTree *loop, Node_List &amp;old_new );
1248 
1249   // Create a scheduled list of nodes control dependent on ctrl set.
1250   void scheduled_nodelist( IdealLoopTree *loop, VectorSet&amp; ctrl, Node_List &amp;sched );
1251   // Has a use in the vector set
1252   bool has_use_in_set( Node* n, VectorSet&amp; vset );
1253   // Has use internal to the vector set (ie. not in a phi at the loop head)
1254   bool has_use_internal_to_set( Node* n, VectorSet&amp; vset, IdealLoopTree *loop );
</pre>
<hr />
<pre>
1336   bool match_fill_loop(IdealLoopTree* lpt, Node*&amp; store, Node*&amp; store_value,
1337                        Node*&amp; shift, Node*&amp; offset);
1338 
1339 private:
1340   // Return a type based on condition control flow
1341   const TypeInt* filtered_type( Node *n, Node* n_ctrl);
1342   const TypeInt* filtered_type( Node *n ) { return filtered_type(n, NULL); }
1343  // Helpers for filtered type
1344   const TypeInt* filtered_type_from_dominators( Node* val, Node *val_ctrl);
1345 
1346   // Helper functions
1347   Node *spinup( Node *iff, Node *new_false, Node *new_true, Node *region, Node *phi, small_cache *cache );
1348   Node *find_use_block( Node *use, Node *def, Node *old_false, Node *new_false, Node *old_true, Node *new_true );
1349   void handle_use( Node *use, Node *def, small_cache *cache, Node *region_dom, Node *new_false, Node *new_true, Node *old_false, Node *old_true );
1350   bool split_up( Node *n, Node *blk1, Node *blk2 );
1351   void sink_use( Node *use, Node *post_loop );
1352   Node *place_near_use( Node *useblock ) const;
1353   Node* try_move_store_before_loop(Node* n, Node *n_ctrl);
1354   void try_move_store_after_loop(Node* n);
1355   bool identical_backtoback_ifs(Node *n);
<span class="line-added">1356   bool flatten_array_element_type_check(Node *n);</span>
1357   bool can_split_if(Node *n_ctrl);
1358 
1359   // Determine if a method is too big for a/another round of split-if, based on
1360   // a magic (approximate) ratio derived from the equally magic constant 35000,
1361   // previously used for this purpose (but without relating to the node limit).
1362   bool must_throttle_split_if() {
1363     uint threshold = C-&gt;max_node_limit() * 2 / 5;
1364     return C-&gt;live_nodes() &gt; threshold;
1365   }
1366 
1367   // A simplistic node request tracking mechanism, where
1368   //   = UINT_MAX   Request not valid or made final.
1369   //   &lt; UINT_MAX   Nodes currently requested (estimate).
1370   uint _nodes_required;
1371 
1372   enum { REQUIRE_MIN = 70 };
1373 
1374   uint nodes_required() const { return _nodes_required; }
1375 
1376   // Given the _currently_  available number of nodes, check  whether there is
</pre>
</td>
</tr>
</table>
<center><a href="generateOptoStub.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="loopopts.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>