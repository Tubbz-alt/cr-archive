diff a/.hgtags b/.hgtags
--- a/.hgtags
+++ b/.hgtags
@@ -487,10 +487,11 @@
 758deedaae8406ae60147486107a54e9864aa7b0 jdk-11+13
 3595bd343b65f8c37818ebe6a4c343ddeb1a5f88 jdk-11+14
 a11c1cb542bbd1671d25b85efe7d09b983c48525 jdk-11+15
 02934b0d661b82b7fe1052a04998d2091352e08d jdk-11+16
 64e4b1686141e57a681936a8283983341484676e jdk-11+17
+d2aa5d494481a1039a092d70efa1f5c9826c5b77 lw1_0
 e1b3def126240d5433902f3cb0e91a4c27f6db50 jdk-11+18
 36ca515343e00b021dcfc902e986d26ec994a2e5 jdk-11+19
 95aad0c785e497f1bade3955c4e4a677b629fa9d jdk-12+0
 9816d7cc655e53ba081f938b656e31971b8f097a jdk-11+20
 14708e1acdc3974f4539027cbbcfa6d69f83cf51 jdk-11+21
@@ -509,10 +510,11 @@
 ef57958c7c511162da8d9a75f0b977f0f7ac464e jdk-12+7
 76072a077ee1d815152d45d1692c4b36c53c5c49 jdk-11+28
 492b366f8e5784cc4927c2c98f9b8a3f16c067eb jdk-12+8
 31b159f30fb281016c5f0c103552809aeda84063 jdk-12+9
 8f594f75e0547d4ca16649cb3501659e3155e81b jdk-12+10
+6132641c6ff61b7b8f3f10b9cd385aafadbd72ef lworld_stable
 f0f5d23449d31f1b3580c8a73313918cafeaefd7 jdk-12+11
 15094d12a632f452a2064318a4e416d0c7a9ce0c jdk-12+12
 511a9946f83e3e3c7b9dbe1840367063fb39b4e1 jdk-12+13
 8897e41b327c0a5601c6ba2bba5d07f15a3ffc91 jdk-12+14
 8897e41b327c0a5601c6ba2bba5d07f15a3ffc91 jdk-12+14
@@ -565,10 +567,14 @@
 22b3b7983adab54e318f75aeb94471f7a4429c1e jdk-14+0
 22b3b7983adab54e318f75aeb94471f7a4429c1e jdk-13+25
 2f4e214781a1d597ed36bf5a36f20928c6c82996 jdk-14+1
 0692b67f54621991ba7afbf23e55b788f3555e69 jdk-13+26
 43627549a488b7d0b4df8fad436e36233df89877 jdk-14+2
+6132641c6ff61b7b8f3f10b9cd385aafadbd72ef lworld_stable
+2b098533f1e52d7d541121409b745d9420886945 lworld_stable
+2b098533f1e52d7d541121409b745d9420886945 lworld_stable
+7c637fd25e7d6fccdab1098bedd48ed195a86cc7 lworld_stable
 b7f68ddec66f996ae3aad03291d129ca9f02482d jdk-13+27
 e64383344f144217c36196c3c8a2df8f588a2af3 jdk-14+3
 1e95931e7d8fa7e3899340a9c7cb28dbea50c10c jdk-13+28
 19d0b382f0869f72d4381b54fa129f1c74b6e766 jdk-14+4
 3081f39a3d30d63b112098386ac2bb027c2b7223 jdk-13+29
diff a/make/autoconf/hotspot.m4 b/make/autoconf/hotspot.m4
--- a/make/autoconf/hotspot.m4
+++ b/make/autoconf/hotspot.m4
@@ -24,10 +24,13 @@
 #
 
 # All valid JVM variants
 VALID_JVM_VARIANTS="server client minimal core zero custom"
 
+# Valhalla temporarily disabled
+VALHALLA_TEMP=false
+
 ###############################################################################
 # Check if the specified JVM variant should be built. To be used in shell if
 # constructs, like this:
 # if HOTSPOT_CHECK_JVM_VARIANT(server); then
 #
diff a/make/conf/jib-profiles.js b/make/conf/jib-profiles.js
--- a/make/conf/jib-profiles.js
+++ b/make/conf/jib-profiles.js
@@ -1346,10 +1346,11 @@
             preString = version_numbers.get("DEFAULT_PROMOTED_VERSION_PRE");
         }
         args = concat(args, "--with-version-pre=" + preString,
                      "--with-version-opt=" + optString);
     } else {
+        args = concat(args, "--with-version-pre=lworld2ea");
         args = concat(args, "--with-version-opt=" + common.build_id);
     }
     return args;
 }
 
diff a/make/data/jdwp/jdwp.spec b/make/data/jdwp/jdwp.spec
--- a/make/data/jdwp/jdwp.spec
+++ b/make/data/jdwp/jdwp.spec
@@ -3242,10 +3242,11 @@
 (ConstantSet Tag
     (Constant ARRAY = '[' "'[' - an array object (objectID size). ")
     (Constant BYTE = 'B' "'B' - a byte value (1 byte).")
     (Constant CHAR = 'C' "'C' - a character value (2 bytes).")
     (Constant OBJECT = 'L' "'L' - an object (objectID size).")
+    (Constant INLINE_OBJECT = 'Q' "'Q' - an inline object (objectID size).")
     (Constant FLOAT = 'F' "'F' - a float value (4 bytes).")
     (Constant DOUBLE = 'D' "'D' - a double value (8 bytes).")
     (Constant INT = 'I' "'I' - an int value (4 bytes).")
     (Constant LONG = 'J' "'J' - a long value (8 bytes).")
     (Constant SHORT = 'S' "'S' - a short value (2 bytes).")
diff a/make/modules/java.base/gensrc/GensrcVarHandles.gmk b/make/modules/java.base/gensrc/GensrcVarHandles.gmk
--- a/make/modules/java.base/gensrc/GensrcVarHandles.gmk
+++ b/make/modules/java.base/gensrc/GensrcVarHandles.gmk
@@ -50,13 +50,23 @@
 
   ifneq ($$(findstring $$($1_Type), Byte Short Char), )
     $1_ARGS += -KShorterThanInt
   endif
 
+  ifeq ($$($1_Type), Reference)
+    $1_ARGS += -KReference
+  endif
+
+  ifeq ($$($1_Type), Value)
+    $1_ARGS += -KValue
+  endif
+
   $$($1_FILENAME): $(VARHANDLES_SRC_DIR)/X-VarHandle.java.template $(BUILD_TOOLS_JDK)
         ifeq ($$($1_Type), Reference)
 	  $$(eval $1_type := Object)
+        else ifeq ($$($1_Type), Value)
+	  $$(eval $1_type := Object)
         else
 	  $$(eval $1_type := $$$$(shell $(TR) '[:upper:]' '[:lower:]' <<< $$$$($1_Type)))
         endif
 	$$(call MakeDir, $$(@D))
 	$(RM) $$@
@@ -260,11 +270,11 @@
 endef
 
 ################################################################################
 
 # List the types to generate source for, with capitalized first letter
-VARHANDLES_TYPES := Boolean Byte Short Char Int Long Float Double Reference
+VARHANDLES_TYPES := Boolean Byte Short Char Int Long Float Double Reference Value
 $(foreach t, $(VARHANDLES_TYPES), \
   $(eval $(call GenerateVarHandle,VAR_HANDLE_$t,$t)))
 
 # List the types to generate source for, with capitalized first letter
 VARHANDLES_BYTE_ARRAY_TYPES := Short Char Int Long Float Double
diff a/src/hotspot/cpu/aarch64/aarch64.ad b/src/hotspot/cpu/aarch64/aarch64.ad
--- a/src/hotspot/cpu/aarch64/aarch64.ad
+++ b/src/hotspot/cpu/aarch64/aarch64.ad
@@ -1623,10 +1623,12 @@
 
 void MachPrologNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
   Compile* C = ra_->C;
   C2_MacroAssembler _masm(&cbuf);
 
+  __ verified_entry(C, 0);
+  __ bind(*_verified_entry);
   // n.b. frame size includes space for return pc and rfp
   const long framesize = C->output()->frame_size_in_bytes();
   assert(framesize%(2*wordSize) == 0, "must preserve 2*wordSize alignment");
 
   // insert a nop at the start of the prolog so we can patch in a
@@ -1965,12 +1967,50 @@
 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
   // BoxLockNode is not a MachNode, so we can't just call MachNode::size(ra_).
   return 4;
 }
 
-//=============================================================================
+///=============================================================================
+#ifndef PRODUCT
+void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
+{
+  st->print_cr("# MachVEPNode");
+  if (!_verified) {
+    st->print_cr("\t load_class");
+  } else {
+    st->print_cr("\t unpack_value_arg");
+  }
+}
+#endif
+
+void MachVEPNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const
+{
+  MacroAssembler _masm(&cbuf);
+
+  if (!_verified) {
+    Label skip;
+    __ cmp_klass(j_rarg0, rscratch2, rscratch1);
+    __ br(Assembler::EQ, skip);
+      __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
+    __ bind(skip);
+
+  } else {
+    // Unpack value type args passed as oop and then jump to
+    // the verified entry point (skipping the unverified entry).
+    __ unpack_value_args(ra_->C, _receiver_only);
+    __ b(*_verified_entry);
+  }
+}
+
+
+uint MachVEPNode::size(PhaseRegAlloc* ra_) const
+{
+  return MachNode::size(ra_); // too many variables; just compute it the hard way
+}
 
+
+//=============================================================================
 #ifndef PRODUCT
 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 {
   st->print_cr("# MachUEPNode");
   if (UseCompressedClassPointers) {
@@ -1988,13 +2028,15 @@
 
 void MachUEPNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const
 {
   // This is the unverified entry point.
   C2_MacroAssembler _masm(&cbuf);
+  Label skip;
 
+  // UseCompressedClassPointers logic are inside cmp_klass
   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
-  Label skip;
+
   // TODO
   // can we avoid this skip and still use a reloc?
   __ br(Assembler::EQ, skip);
   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
   __ bind(skip);
@@ -2397,11 +2439,10 @@
 }
 
 void Compile::reshape_address(AddPNode* addp) {
 }
 
-
 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
   C2_MacroAssembler _masm(&cbuf);                                       \
   {                                                                     \
     guarantee(INDEX == -1, "mode not permitted for volatile");          \
     guarantee(DISP == 0, "mode not permitted for volatile");            \
@@ -8257,10 +8298,25 @@
   %}
 
   ins_pipe(ialu_reg);
 %}
 
+instruct castN2X(iRegLNoSp dst, iRegN src) %{
+  match(Set dst (CastP2X src));
+
+  ins_cost(INSN_COST);
+  format %{ "mov $dst, $src\t# ptr -> long" %}
+
+  ins_encode %{
+    if ($dst$$reg != $src$$reg) {
+      __ mov(as_Register($dst$$reg), as_Register($src$$reg));
+    }
+  %}
+
+  ins_pipe(ialu_reg);
+%}
+
 instruct castP2X(iRegLNoSp dst, iRegP src) %{
   match(Set dst (CastP2X src));
 
   ins_cost(INSN_COST);
   format %{ "mov $dst, $src\t# ptr -> long" %}
@@ -8272,10 +8328,41 @@
   %}
 
   ins_pipe(ialu_reg);
 %}
 
+instruct castN2I(iRegINoSp dst, iRegN src) %{
+  match(Set dst (CastN2I src));
+
+  ins_cost(INSN_COST);
+  format %{ "movw $dst, $src\t# compressed ptr -> int" %}
+
+  ins_encode %{
+    if ($dst$$reg != $src$$reg) {
+      __ movw(as_Register($dst$$reg), as_Register($src$$reg));
+    }
+  %}
+
+  ins_pipe(ialu_reg);
+%}
+
+instruct castI2N(iRegNNoSp dst, iRegI src) %{
+  match(Set dst (CastI2N src));
+
+  ins_cost(INSN_COST);
+  format %{ "movw $dst, $src\t# int -> compressed ptr" %}
+
+  ins_encode %{
+    if ($dst$$reg != $src$$reg) {
+      __ movw(as_Register($dst$$reg), as_Register($src$$reg));
+    }
+  %}
+
+  ins_pipe(ialu_reg);
+%}
+
+
 // Convert oop into int for vectors alignment masking
 instruct convP2I(iRegINoSp dst, iRegP src) %{
   match(Set dst (ConvL2I (CastP2X src)));
 
   ins_cost(INSN_COST);
@@ -13806,37 +13893,20 @@
 %}
 
 // ============================================================================
 // clearing of an array
 
-instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
+instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)
 %{
-  match(Set dummy (ClearArray cnt base));
+  match(Set dummy (ClearArray (Binary cnt base) val));
   effect(USE_KILL cnt, USE_KILL base);
 
   ins_cost(4 * INSN_COST);
-  format %{ "ClearArray $cnt, $base" %}
-
-  ins_encode %{
-    __ zero_words($base$$Register, $cnt$$Register);
-  %}
-
-  ins_pipe(pipe_class_memory);
-%}
-
-instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
-%{
-  predicate((u_int64_t)n->in(2)->get_long()
-            < (u_int64_t)(BlockZeroingLowLimit >> LogBytesPerWord));
-  match(Set dummy (ClearArray cnt base));
-  effect(USE_KILL base);
-
-  ins_cost(4 * INSN_COST);
-  format %{ "ClearArray $cnt, $base" %}
+  format %{ "ClearArray $cnt, $base, $val" %}
 
   ins_encode %{
-    __ zero_words($base$$Register, (u_int64_t)$cnt$$constant);
+    __ fill_words($base$$Register, $cnt$$Register, $val$$Register);
   %}
 
   ins_pipe(pipe_class_memory);
 %}
 
diff a/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp b/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/c1_LIRGenerator_aarch64.cpp
@@ -33,10 +33,11 @@
 #include "c1/c1_Runtime1.hpp"
 #include "c1/c1_ValueStack.hpp"
 #include "ci/ciArray.hpp"
 #include "ci/ciObjArrayKlass.hpp"
 #include "ci/ciTypeArrayKlass.hpp"
+#include "ci/ciValueKlass.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "runtime/stubRoutines.hpp"
 #include "utilities/powerOfTwo.hpp"
 #include "vmreg_aarch64.inline.hpp"
 
@@ -100,10 +101,16 @@
   set_vreg_flag(reg, LIRGenerator::byte_reg);
   return reg;
 }
 
 
+void LIRGenerator::init_temps_for_substitutability_check(LIR_Opr& tmp1, LIR_Opr& tmp2) {
+  tmp1 = new_register(T_INT);
+  tmp2 = LIR_OprFact::illegalOpr;
+}
+
+
 //--------- loading items into registers --------------------------------
 
 
 bool LIRGenerator::can_store_as_constant(Value v, BasicType type) const {
   if (v->type()->as_IntConstant() != NULL) {
@@ -331,23 +338,29 @@
 
   // "lock" stores the address of the monitor stack slot, so this is not an oop
   LIR_Opr lock = new_register(T_INT);
   // Need a scratch register for biased locking
   LIR_Opr scratch = LIR_OprFact::illegalOpr;
-  if (UseBiasedLocking) {
+  if (UseBiasedLocking || x->maybe_valuetype()) {
     scratch = new_register(T_INT);
   }
 
   CodeEmitInfo* info_for_exception = NULL;
   if (x->needs_null_check()) {
     info_for_exception = state_for(x);
   }
+
+  CodeStub* throw_imse_stub =
+      x->maybe_valuetype() ?
+      new SimpleExceptionStub(Runtime1::throw_illegal_monitor_state_exception_id, LIR_OprFact::illegalOpr, state_for(x)) :
+      NULL;
+
   // this CodeEmitInfo must not have the xhandlers because here the
   // object is already locked (xhandlers expect object to be unlocked)
   CodeEmitInfo* info = state_for(x, x->state(), true);
   monitor_enter(obj.result(), lock, syncTempOpr(), scratch,
-                        x->monitor_no(), info_for_exception, info);
+                        x->monitor_no(), info_for_exception, info, throw_imse_stub);
 }
 
 
 void LIRGenerator::do_MonitorExit(MonitorExit* x) {
   assert(x->is_pinned(),"");
@@ -1151,10 +1164,26 @@
                        FrameMap::r3_metadata_opr, info);
   LIR_Opr result = rlock_result(x);
   __ move(reg, result);
 }
 
+void LIRGenerator::do_NewValueTypeInstance  (NewValueTypeInstance* x) {
+  // Mapping to do_NewInstance (same code)
+  CodeEmitInfo* info = state_for(x, x->state());
+  x->set_to_object_type();
+  LIR_Opr reg = result_register_for(x->type());
+  new_instance(reg, x->klass(), x->is_unresolved(),
+             FrameMap::r2_oop_opr,
+             FrameMap::r5_oop_opr,
+             FrameMap::r4_oop_opr,
+             LIR_OprFact::illegalOpr,
+             FrameMap::r3_metadata_opr, info);
+  LIR_Opr result = rlock_result(x);
+  __ move(reg, result);
+
+}
+
 void LIRGenerator::do_NewTypeArray(NewTypeArray* x) {
   CodeEmitInfo* info = state_for(x, x->state());
 
   LIRItem length(x->length(), this);
   length.load_item_force(FrameMap::r19_opr);
@@ -1196,17 +1225,22 @@
   LIR_Opr klass_reg = FrameMap::r3_metadata_opr;
 
   length.load_item_force(FrameMap::r19_opr);
   LIR_Opr len = length.result();
 
-  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info);
-  ciKlass* obj = (ciKlass*) ciObjArrayKlass::make(x->klass());
+  ciKlass* obj = (ciKlass*) x->exact_type();
+  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, x->is_never_null());
   if (obj == ciEnv::unloaded_ciobjarrayklass()) {
     BAILOUT("encountered unloaded_ciobjarrayklass due to out of memory error");
   }
+
   klass2reg_with_patching(klass_reg, obj, patching_info);
-  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);
+  if (x->is_never_null()) {
+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_VALUETYPE, klass_reg, slow_path);
+  } else {
+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);
+  }
 
   LIR_Opr result = rlock_result(x);
   __ move(reg, result);
 }
 
@@ -1278,10 +1312,13 @@
 
   // info for exceptions
   CodeEmitInfo* info_for_exception =
       (x->needs_exception_state() ? state_for(x) :
                                     state_for(x, x->state_before(), true /*ignore_xhandler*/));
+  if (x->is_never_null()) {
+    __ null_check(obj.result(), new CodeEmitInfo(info_for_exception));
+  }
 
   CodeStub* stub;
   if (x->is_incompatible_class_change_check()) {
     assert(patching_info == NULL, "can't patch this");
     stub = new SimpleExceptionStub(Runtime1::throw_incompatible_class_change_error_id, LIR_OprFact::illegalOpr, info_for_exception);
@@ -1296,14 +1333,17 @@
   LIR_Opr reg = rlock_result(x);
   LIR_Opr tmp3 = LIR_OprFact::illegalOpr;
   if (!x->klass()->is_loaded() || UseCompressedClassPointers) {
     tmp3 = new_register(objectType);
   }
+
+
   __ checkcast(reg, obj.result(), x->klass(),
                new_register(objectType), new_register(objectType), tmp3,
                x->direct_compare(), info_for_exception, patching_info, stub,
-               x->profiled_method(), x->profiled_bci());
+               x->profiled_method(), x->profiled_bci(), x->is_never_null());
+
 }
 
 void LIRGenerator::do_InstanceOf(InstanceOf* x) {
   LIRItem obj(x->obj(), this);
 
diff a/src/hotspot/cpu/aarch64/globals_aarch64.hpp b/src/hotspot/cpu/aarch64/globals_aarch64.hpp
--- a/src/hotspot/cpu/aarch64/globals_aarch64.hpp
+++ b/src/hotspot/cpu/aarch64/globals_aarch64.hpp
@@ -62,10 +62,13 @@
 define_pd_global(bool, RewriteBytecodes,     true);
 define_pd_global(bool, RewriteFrequentPairs, true);
 
 define_pd_global(bool, PreserveFramePointer, false);
 
+define_pd_global(bool, InlineTypePassFieldsAsArgs, false);
+define_pd_global(bool, InlineTypeReturnedAsFields, false);
+
 define_pd_global(uintx, TypeProfileLevel, 111);
 
 define_pd_global(bool, CompactStrings, true);
 
 // Clear short arrays bigger than one word in an arch-specific way
diff a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/templateTable_aarch64.cpp
@@ -146,11 +146,11 @@
 static void do_oop_store(InterpreterMacroAssembler* _masm,
                          Address dst,
                          Register val,
                          DecoratorSet decorators) {
   assert(val == noreg || val == r0, "parameter is just for looks");
-  __ store_heap_oop(dst, val, r10, r1, decorators);
+  __ store_heap_oop(dst, val, r10, r1, noreg, decorators);
 }
 
 static void do_oop_load(InterpreterMacroAssembler* _masm,
                         Address src,
                         Register dst,
@@ -169,10 +169,11 @@
 {
   if (!RewriteBytecodes)  return;
   Label L_patch_done;
 
   switch (bc) {
+  case Bytecodes::_fast_qputfield:
   case Bytecodes::_fast_aputfield:
   case Bytecodes::_fast_bputfield:
   case Bytecodes::_fast_zputfield:
   case Bytecodes::_fast_cputfield:
   case Bytecodes::_fast_dputfield:
@@ -744,14 +745,14 @@
     assert(r1 != array, "different registers");
     __ mov(r1, index);
   }
   Label ok;
   __ br(Assembler::LO, ok);
-    // ??? convention: move array into r3 for exception message
-  __ mov(r3, array);
-  __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);
-  __ br(rscratch1);
+  // ??? convention: move array into r3 for exception message
+   __ mov(r3, array);
+   __ mov(rscratch1, Interpreter::_throw_ArrayIndexOutOfBoundsException_entry);
+   __ br(rscratch1);
   __ bind(ok);
 }
 
 void TemplateTable::iaload()
 {
@@ -807,15 +808,25 @@
   __ mov(r1, r0);
   __ pop_ptr(r0);
   // r0: array
   // r1: index
   index_check(r0, r1); // leaves index in r1, kills rscratch1
-  __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);
-  do_oop_load(_masm,
-              Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)),
-              r0,
-              IS_ARRAY);
+  if (ValueArrayFlatten) {
+    Label is_flat_array, done;
+
+    __ test_flattened_array_oop(r0, r8 /*temp*/, is_flat_array);
+    __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);
+    do_oop_load(_masm, Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)), r0, IS_ARRAY);
+
+    __ b(done);
+    __ bind(is_flat_array);
+    __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::value_array_load), r0, r1);
+    __ bind(done);
+  } else {
+    __ add(r1, r1, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);
+    do_oop_load(_masm, Address(r0, r1, Address::uxtw(LogBytesPerHeapOop)), r0, IS_ARRAY);
+  }
 }
 
 void TemplateTable::baload()
 {
   transition(itos, itos);
@@ -1108,46 +1119,109 @@
   __ ldr(r3, at_tos_p2()); // array
 
   Address element_address(r3, r4, Address::uxtw(LogBytesPerHeapOop));
 
   index_check(r3, r2);     // kills r1
+
+  // FIXME: Could we remove the line below?
   __ add(r4, r2, arrayOopDesc::base_offset_in_bytes(T_OBJECT) >> LogBytesPerHeapOop);
 
   // do array store check - check for NULL value first
   __ cbz(r0, is_null);
 
+  Label  is_flat_array;
+  if (ValueArrayFlatten) {
+    __ test_flattened_array_oop(r3, r8 /*temp*/, is_flat_array);
+  }
+
   // Move subklass into r1
   __ load_klass(r1, r0);
+
   // Move superklass into r0
   __ load_klass(r0, r3);
-  __ ldr(r0, Address(r0,
-                     ObjArrayKlass::element_klass_offset()));
+  __ ldr(r0, Address(r0, ObjArrayKlass::element_klass_offset()));
   // Compress array + index*oopSize + 12 into a single register.  Frees r2.
 
   // Generate subtype check.  Blows r2, r5
   // Superklass in r0.  Subklass in r1.
+
   __ gen_subtype_check(r1, ok_is_subtype);
 
   // Come here on failure
   // object is at TOS
   __ b(Interpreter::_throw_ArrayStoreException_entry);
 
+
   // Come here on success
   __ bind(ok_is_subtype);
 
+
   // Get the value we will store
   __ ldr(r0, at_tos());
   // Now store using the appropriate barrier
   do_oop_store(_masm, element_address, r0, IS_ARRAY);
   __ b(done);
 
   // Have a NULL in r0, r3=array, r2=index.  Store NULL at ary[idx]
   __ bind(is_null);
   __ profile_null_seen(r2);
 
+  if (EnableValhalla) {
+    Label is_null_into_value_array_npe, store_null;
+
+    // No way to store null in flat array
+    __ test_null_free_array_oop(r3, r8, is_null_into_value_array_npe);
+    __ b(store_null);
+
+    __ bind(is_null_into_value_array_npe);
+    __ b(ExternalAddress(Interpreter::_throw_NullPointerException_entry));
+
+    __ bind(store_null);
+  }
+
   // Store a NULL
   do_oop_store(_masm, element_address, noreg, IS_ARRAY);
+  __ b(done);
+
+  if (EnableValhalla) {
+     Label is_type_ok;
+
+    // store non-null value
+    __ bind(is_flat_array);
+
+    // Simplistic type check...
+    // r0 - value, r2 - index, r3 - array.
+
+    // Profile the not-null value's klass.
+    // Load value class
+     __ load_klass(r1, r0);
+     __ profile_typecheck(r2, r1, r0); // blows r2, and r0
+
+    // flat value array needs exact type match
+    // is "r8 == r0" (value subclass == array element superclass)
+
+    // Move element klass into r0
+
+     __ load_klass(r0, r3);
+
+     __ ldr(r0, Address(r0, ArrayKlass::element_klass_offset()));
+     __ cmp(r0, r1);
+     __ br(Assembler::EQ, is_type_ok);
+
+     __ profile_typecheck_failed(r2);
+     __ b(ExternalAddress(Interpreter::_throw_ArrayStoreException_entry));
+
+     __ bind(is_type_ok);
+
+    // Reload from TOS to be safe, because of profile_typecheck that blows r2 and r0.
+    // FIXME: Should we really do it?
+     __ ldr(r1, at_tos());  // value
+     __ mov(r2, r3); // array, ldr(r2, at_tos_p2());
+     __ ldr(r3, at_tos_p1()); // index
+     __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::value_array_store), r1, r2, r3);
+  }
+
 
   // Pop stack arguments
   __ bind(done);
   __ add(esp, esp, 3 * Interpreter::stackElementSize);
 }
@@ -2014,23 +2088,69 @@
   branch(false, false);
   __ bind(not_taken);
   __ profile_not_taken_branch(r0);
 }
 
-void TemplateTable::if_acmp(Condition cc)
-{
+void TemplateTable::if_acmp(Condition cc) {
   transition(atos, vtos);
   // assume branch is more often taken than not (loops use backward branches)
-  Label not_taken;
+  Label taken, not_taken;
   __ pop_ptr(r1);
+
+  Register is_value_mask = rscratch1;
+  __ mov(is_value_mask, markWord::always_locked_pattern);
+
+  if (EnableValhalla) {
+    __ cmp(r1, r0);
+    __ br(Assembler::EQ, (cc == equal) ? taken : not_taken);
+
+    // might be substitutable, test if either r0 or r1 is null
+    __ andr(r2, r0, r1);
+    __ cbz(r2, (cc == equal) ? not_taken : taken);
+
+    // and both are values ?
+    __ ldr(r2, Address(r1, oopDesc::mark_offset_in_bytes()));
+    __ andr(r2, r2, is_value_mask);
+    __ ldr(r4, Address(r0, oopDesc::mark_offset_in_bytes()));
+    __ andr(r4, r4, is_value_mask);
+    __ andr(r2, r2, r4);
+    __ cmp(r2,  is_value_mask);
+    __ br(Assembler::NE, (cc == equal) ? not_taken : taken);
+
+    // same value klass ?
+    __ load_metadata(r2, r1);
+    __ load_metadata(r4, r0);
+    __ cmp(r2, r4);
+    __ br(Assembler::NE, (cc == equal) ? not_taken : taken);
+
+    // Know both are the same type, let's test for substitutability...
+    if (cc == equal) {
+      invoke_is_substitutable(r0, r1, taken, not_taken);
+    } else {
+      invoke_is_substitutable(r0, r1, not_taken, taken);
+    }
+    __ stop("Not reachable");
+  }
+
   __ cmpoop(r1, r0);
   __ br(j_not(cc), not_taken);
+  __ bind(taken);
   branch(false, false);
   __ bind(not_taken);
   __ profile_not_taken_branch(r0);
 }
 
+void TemplateTable::invoke_is_substitutable(Register aobj, Register bobj,
+                                            Label& is_subst, Label& not_subst) {
+
+  __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::is_substitutable), aobj, bobj);
+  // Restored... r0 answer, jmp to outcome...
+  __ cbz(r0, not_subst);
+  __ b(is_subst);
+}
+
+
 void TemplateTable::ret() {
   transition(vtos, vtos);
   // We might be moving to a safepoint.  The thread which calls
   // Interpreter::notice_safepoints() will effectively flush its cache
   // when it makes a system call, but we need to do something to
@@ -2499,12 +2619,11 @@
   Label Done, notByte, notBool, notInt, notShort, notChar,
               notLong, notFloat, notObj, notDouble;
 
   // x86 uses a shift and mask or wings it with a shift plus assert
   // the mask is not needed. aarch64 just uses bitfield extract
-  __ ubfxw(flags, raw_flags, ConstantPoolCacheEntry::tos_state_shift,
-           ConstantPoolCacheEntry::tos_state_bits);
+  __ ubfxw(flags, raw_flags, ConstantPoolCacheEntry::tos_state_shift, ConstantPoolCacheEntry::tos_state_bits);
 
   assert(btos == 0, "change code, btos != 0");
   __ cbnz(flags, notByte);
 
   // Don't rewrite getstatic, only getfield
@@ -2535,16 +2654,72 @@
 
   __ bind(notBool);
   __ cmp(flags, (u1)atos);
   __ br(Assembler::NE, notObj);
   // atos
-  do_oop_load(_masm, field, r0, IN_HEAP);
-  __ push(atos);
-  if (rc == may_rewrite) {
-    patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
+  if (!EnableValhalla) {
+    do_oop_load(_masm, field, r0, IN_HEAP);
+    __ push(atos);
+    if (rc == may_rewrite) {
+      patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
+    }
+    __ b(Done);
+  } else { // Valhalla
+
+    if (is_static) {
+      __ load_heap_oop(r0, field);
+      Label isFlattenable, isUninitialized;
+      // Issue below if the static field has not been initialized yet
+      __ test_field_is_flattenable(raw_flags, r8 /*temp*/, isFlattenable);
+        // Not flattenable case
+        __ push(atos);
+        __ b(Done);
+      // Flattenable case, must not return null even if uninitialized
+      __ bind(isFlattenable);
+        __ cbz(r0, isUninitialized);
+          __ push(atos);
+          __ b(Done);
+        __ bind(isUninitialized);
+          __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
+          __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_static_value_field), obj, raw_flags);
+          __ verify_oop(r0);
+          __ push(atos);
+          __ b(Done);
+    } else {
+      Label isFlattened, isInitialized, isFlattenable, rewriteFlattenable;
+        __ test_field_is_flattenable(raw_flags, r8 /*temp*/, isFlattenable);
+        // Non-flattenable field case, also covers the object case
+        __ load_heap_oop(r0, field);
+        __ push(atos);
+        if (rc == may_rewrite) {
+          patch_bytecode(Bytecodes::_fast_agetfield, bc, r1);
+        }
+        __ b(Done);
+      __ bind(isFlattenable);
+        __ test_field_is_flattened(raw_flags, r8 /* temp */, isFlattened);
+         // Non-flattened field case
+          __ load_heap_oop(r0, field);
+          __ cbnz(r0, isInitialized);
+            __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
+            __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_instance_value_field), obj, raw_flags);
+          __ bind(isInitialized);
+          __ verify_oop(r0);
+          __ push(atos);
+          __ b(rewriteFlattenable);
+        __ bind(isFlattened);
+          __ ldr(r10, Address(cache, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset())));
+          __ andw(raw_flags, raw_flags, ConstantPoolCacheEntry::field_index_mask);
+          call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), obj, raw_flags, r10);
+          __ verify_oop(r0);
+          __ push(atos);
+      __ bind(rewriteFlattenable);
+      if (rc == may_rewrite) {
+         patch_bytecode(Bytecodes::_fast_qgetfield, bc, r1);
+      }
+      __ b(Done);
+    }
   }
-  __ b(Done);
 
   __ bind(notObj);
   __ cmp(flags, (u1)itos);
   __ br(Assembler::NE, notInt);
   // itos
@@ -2710,10 +2885,11 @@
   const Register cache = r2;
   const Register index = r3;
   const Register obj   = r2;
   const Register off   = r19;
   const Register flags = r0;
+  const Register flags2 = r6;
   const Register bc    = r4;
 
   resolve_cache_and_index(byte_no, cache, index, sizeof(u2));
   jvmti_post_field_mod(cache, index, is_static);
   load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);
@@ -2732,10 +2908,12 @@
   const Address field(obj, off);
 
   Label notByte, notBool, notInt, notShort, notChar,
         notLong, notFloat, notObj, notDouble;
 
+  __ mov(flags2, flags);
+
   // x86 uses a shift and mask or wings it with a shift plus assert
   // the mask is not needed. aarch64 just uses bitfield extract
   __ ubfxw(flags, flags, ConstantPoolCacheEntry::tos_state_shift,  ConstantPoolCacheEntry::tos_state_bits);
 
   assert(btos == 0, "change code, btos != 0");
@@ -2774,18 +2952,60 @@
   __ cmp(flags, (u1)atos);
   __ br(Assembler::NE, notObj);
 
   // atos
   {
-    __ pop(atos);
-    if (!is_static) pop_and_check_object(obj);
-    // Store into the field
-    do_oop_store(_masm, field, r0, IN_HEAP);
-    if (rc == may_rewrite) {
-      patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);
-    }
-    __ b(Done);
+     if (!EnableValhalla) {
+      __ pop(atos);
+      if (!is_static) pop_and_check_object(obj);
+      // Store into the field
+      do_oop_store(_masm, field, r0, IN_HEAP);
+      if (rc == may_rewrite) {
+        patch_bytecode(Bytecodes::_fast_aputfield, bc, r1, true, byte_no);
+      }
+      __ b(Done);
+     } else { // Valhalla
+
+      __ pop(atos);
+      if (is_static) {
+        Label notFlattenable;
+         __ test_field_is_not_flattenable(flags2, r8 /* temp */, notFlattenable);
+         __ null_check(r0);
+         __ bind(notFlattenable);
+         do_oop_store(_masm, field, r0, IN_HEAP);
+         __ b(Done);
+      } else {
+        Label isFlattenable, isFlattened, notBuffered, notBuffered2, rewriteNotFlattenable, rewriteFlattenable;
+        __ test_field_is_flattenable(flags2, r8 /*temp*/, isFlattenable);
+        // Not flattenable case, covers not flattenable values and objects
+        pop_and_check_object(obj);
+        // Store into the field
+        do_oop_store(_masm, field, r0, IN_HEAP);
+        __ bind(rewriteNotFlattenable);
+        if (rc == may_rewrite) {
+          patch_bytecode(Bytecodes::_fast_aputfield, bc, r19, true, byte_no);
+        }
+        __ b(Done);
+        // Implementation of the flattenable semantic
+        __ bind(isFlattenable);
+        __ null_check(r0);
+        __ test_field_is_flattened(flags2, r8 /*temp*/, isFlattened);
+        // Not flattened case
+        pop_and_check_object(obj);
+        // Store into the field
+        do_oop_store(_masm, field, r0, IN_HEAP);
+        __ b(rewriteFlattenable);
+        __ bind(isFlattened);
+        pop_and_check_object(obj);
+        call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::write_flattened_value), r0, off, obj);
+        __ bind(rewriteFlattenable);
+        if (rc == may_rewrite) {
+          patch_bytecode(Bytecodes::_fast_qputfield, bc, r19, true, byte_no);
+        }
+        __ b(Done);
+      }
+     }  // Valhalla
   }
 
   __ bind(notObj);
   __ cmp(flags, (u1)itos);
   __ br(Assembler::NE, notInt);
@@ -2921,10 +3141,11 @@
     __ push_ptr(r19);                 // put the object pointer back on tos
     // Save tos values before call_VM() clobbers them. Since we have
     // to do it for every data type, we use the saved values as the
     // jvalue object.
     switch (bytecode()) {          // load values into the jvalue object
+    case Bytecodes::_fast_qputfield: //fall through
     case Bytecodes::_fast_aputfield: __ push_ptr(r0); break;
     case Bytecodes::_fast_bputfield: // fall through
     case Bytecodes::_fast_zputfield: // fall through
     case Bytecodes::_fast_sputfield: // fall through
     case Bytecodes::_fast_cputfield: // fall through
@@ -2947,10 +3168,11 @@
                CAST_FROM_FN_PTR(address,
                                 InterpreterRuntime::post_field_modification),
                r19, c_rarg2, c_rarg3);
 
     switch (bytecode()) {             // restore tos values
+    case Bytecodes::_fast_qputfield: //fall through
     case Bytecodes::_fast_aputfield: __ pop_ptr(r0); break;
     case Bytecodes::_fast_bputfield: // fall through
     case Bytecodes::_fast_zputfield: // fall through
     case Bytecodes::_fast_sputfield: // fall through
     case Bytecodes::_fast_cputfield: // fall through
@@ -2997,10 +3219,23 @@
   // field address
   const Address field(r2, r1);
 
   // access field
   switch (bytecode()) {
+  case Bytecodes::_fast_qputfield: //fall through
+   {
+      Label isFlattened, done;
+      __ null_check(r0);
+      __ test_field_is_flattened(r3, r8 /* temp */, isFlattened);
+      // No Flattened case
+      do_oop_store(_masm, field, r0, IN_HEAP);
+      __ b(done);
+      __ bind(isFlattened);
+      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::write_flattened_value), r0, r1, r2);
+      __ bind(done);
+    }
+    break;
   case Bytecodes::_fast_aputfield:
     do_oop_store(_masm, field, r0, IN_HEAP);
     break;
   case Bytecodes::_fast_lputfield:
     __ access_store_at(T_LONG, IN_HEAP, field, r0, noreg, noreg);
@@ -3090,10 +3325,36 @@
     __ bind(notVolatile);
   }
 
   // access field
   switch (bytecode()) {
+  case Bytecodes::_fast_qgetfield:
+    {
+       Label isFlattened, isInitialized, Done;
+       // FIXME: We don't need to reload registers multiple times, but stay close to x86 code
+       __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
+       __ test_field_is_flattened(r9, r8 /* temp */, isFlattened);
+        // Non-flattened field case
+        __ mov(r9, r0);
+        __ load_heap_oop(r0, field);
+        __ cbnz(r0, isInitialized);
+          __ mov(r0, r9);
+          __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
+          __ andw(r9, r9, ConstantPoolCacheEntry::field_index_mask);
+          __ call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::uninitialized_instance_value_field), r0, r9);
+        __ bind(isInitialized);
+        __ verify_oop(r0);
+        __ b(Done);
+      __ bind(isFlattened);
+        __ ldrw(r9, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::flags_offset())));
+        __ andw(r9, r9, ConstantPoolCacheEntry::field_index_mask);
+        __ ldr(r3, Address(r2, in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset())));
+        call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field), r0, r9, r3);
+        __ verify_oop(r0);
+      __ bind(Done);
+    }
+    break;
   case Bytecodes::_fast_agetfield:
     do_oop_load(_masm, field, r0, IN_HEAP);
     __ verify_oop(r0);
     break;
   case Bytecodes::_fast_lgetfield:
@@ -3645,10 +3906,34 @@
   __ bind(done);
   // Must prevent reordering of stores for object initialization with stores that publish the new object.
   __ membar(Assembler::StoreStore);
 }
 
+void TemplateTable::defaultvalue() {
+  transition(vtos, atos);
+  __ get_unsigned_2_byte_index_at_bcp(c_rarg2, 1);
+  __ get_constant_pool(c_rarg1);
+  call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::defaultvalue),
+          c_rarg1, c_rarg2);
+  __ verify_oop(r0);
+  // Must prevent reordering of stores for object initialization with stores that publish the new object.
+  __ membar(Assembler::StoreStore);
+}
+
+void TemplateTable::withfield() {
+  transition(vtos, atos);
+  resolve_cache_and_index(f2_byte, c_rarg1 /*cache*/, c_rarg2 /*index*/, sizeof(u2));
+
+  // n.b. unlike x86 cache is now rcpool plus the indexed offset
+  // so using rcpool to meet shared code expectations
+
+  call_VM(r1, CAST_FROM_FN_PTR(address, InterpreterRuntime::withfield), rcpool);
+  __ verify_oop(r1);
+  __ add(esp, esp, r0);
+  __ mov(r0, r1);
+}
+
 void TemplateTable::newarray() {
   transition(itos, atos);
   __ load_unsigned_byte(c_rarg1, at_bcp(1));
   __ mov(c_rarg2, r0);
   call_VM(r0, CAST_FROM_FN_PTR(address, InterpreterRuntime::newarray),
@@ -3716,16 +4001,31 @@
 
   // Come here on success
   __ bind(ok_is_subtype);
   __ mov(r0, r3); // Restore object in r3
 
+  __ b(done);
+  __ bind(is_null);
+
   // Collect counts on whether this test sees NULLs a lot or not.
   if (ProfileInterpreter) {
-    __ b(done);
-    __ bind(is_null);
-    __ profile_null_seen(r2);
-  } else {
+    __ profile_null_seen(r2);
+  }
+
+  if (EnableValhalla) {
+    // Get cpool & tags index
+    __ get_cpool_and_tags(r2, r3); // r2=cpool, r3=tags array
+    __ get_unsigned_2_byte_index_at_bcp(r19, 1); // r19=index
+     // See if bytecode has already been quicked
+    __ add(rscratch1, r3, Array<u1>::base_offset_in_bytes());
+    __ lea(r1, Address(rscratch1, r19));
+    __ ldarb(r1, r1);
+    // See if CP entry is a Q-descriptor
+    __ andr (r1, r1, JVM_CONSTANT_QDescBit);
+    __ cmp(r1, (u1) JVM_CONSTANT_QDescBit);
+    __ br(Assembler::NE, done);
+    __ b(ExternalAddress(Interpreter::_throw_NullPointerException_entry));
     __ bind(is_null);   // same as 'done'
   }
   __ bind(done);
 }
 
diff a/src/hotspot/cpu/ppc/globals_ppc.hpp b/src/hotspot/cpu/ppc/globals_ppc.hpp
--- a/src/hotspot/cpu/ppc/globals_ppc.hpp
+++ b/src/hotspot/cpu/ppc/globals_ppc.hpp
@@ -65,10 +65,13 @@
 define_pd_global(bool, RewriteBytecodes,      true);
 define_pd_global(bool, RewriteFrequentPairs,  true);
 
 define_pd_global(bool, PreserveFramePointer,  false);
 
+define_pd_global(bool, InlineTypePassFieldsAsArgs, false);
+define_pd_global(bool, InlineTypeReturnedAsFields, false);
+
 define_pd_global(uintx, TypeProfileLevel, 111);
 
 define_pd_global(bool, CompactStrings, true);
 
 // 2x unrolled loop is shorter with more than 9 HeapWords.
diff a/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp b/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
--- a/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
+++ b/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
@@ -1876,11 +1876,11 @@
       if (MethodData::profile_return()) {
         // We're right after the type profile for the last
         // argument. tmp1 is the number of cells left in the
         // CallTypeData/VirtualCallTypeData to reach its end. Non null
         // if there's a return to profile.
-        assert(ReturnTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(),
+        assert(SingleTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(),
                "can't move past ret type");
         sldi(tmp1, tmp1, exact_log2(DataLayout::cell_size));
         add(R28_mdx, tmp1, R28_mdx);
       }
     } else {
@@ -1917,11 +1917,11 @@
       cmpwi(CCR1, tmp2, vmIntrinsics::_compiledLambdaForm);
       cror(CCR0, Assembler::equal, CCR1, Assembler::equal);
       bne(CCR0, profile_continue);
     }
 
-    profile_obj_type(ret, R28_mdx, -in_bytes(ReturnTypeEntry::size()), tmp1, tmp2);
+    profile_obj_type(ret, R28_mdx, -in_bytes(SingleTypeEntry::size()), tmp1, tmp2);
 
     align(32, 12);
     bind(profile_continue);
   }
 }
diff a/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp b/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
@@ -551,11 +551,11 @@
     __ pop_IU_state();
   }
 }
 
 void ShenandoahBarrierSetAssembler::store_at(MacroAssembler* masm, DecoratorSet decorators, BasicType type,
-              Address dst, Register val, Register tmp1, Register tmp2) {
+              Address dst, Register val, Register tmp1, Register tmp2, Register tmp3) {
 
   bool on_oop = is_reference_type(type);
   bool in_heap = (decorators & IN_HEAP) != 0;
   bool as_normal = (decorators & AS_NORMAL) != 0;
   if (on_oop && in_heap) {
@@ -589,18 +589,18 @@
                                    tmp3  /* tmp */,
                                    val != noreg /* tosca_live */,
                                    false /* expand_call */);
     }
     if (val == noreg) {
-      BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg);
+      BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg, noreg);
     } else {
       storeval_barrier(masm, val, tmp3);
-      BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg);
+      BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg, noreg);
     }
     NOT_LP64(imasm->restore_bcp());
   } else {
-    BarrierSetAssembler::store_at(masm, decorators, type, dst, val, tmp1, tmp2);
+    BarrierSetAssembler::store_at(masm, decorators, type, dst, val, tmp1, tmp2, tmp3);
   }
 }
 
 void ShenandoahBarrierSetAssembler::try_resolve_jobject_in_native(MacroAssembler* masm, Register jni_env,
                                                                   Register obj, Register tmp, Label& slowpath) {
diff a/src/hotspot/cpu/x86/methodHandles_x86.cpp b/src/hotspot/cpu/x86/methodHandles_x86.cpp
--- a/src/hotspot/cpu/x86/methodHandles_x86.cpp
+++ b/src/hotspot/cpu/x86/methodHandles_x86.cpp
@@ -146,11 +146,15 @@
     __ jccb(Assembler::zero, run_compiled_code);
     __ jmp(Address(method, Method::interpreter_entry_offset()));
     __ BIND(run_compiled_code);
   }
 
-  const ByteSize entry_offset = for_compiler_entry ? Method::from_compiled_offset() :
+  // The following jump might pass a value type argument that was erased to Object as oop to a
+  // callee that expects value type arguments to be passed as fields. We need to call the compiled
+  // value entry (_code->value_entry_point() or _adapter->c2i_value_entry()) which will take care
+  // of translating between the calling conventions.
+  const ByteSize entry_offset = for_compiler_entry ? Method::from_compiled_value_offset() :
                                                      Method::from_interpreted_offset();
   __ jmp(Address(method, entry_offset));
 
   __ bind(L_no_such_method);
   __ jump(RuntimeAddress(StubRoutines::throw_AbstractMethodError_entry()));
diff a/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp b/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
--- a/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
+++ b/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
@@ -464,10 +464,11 @@
     case T_BYTE:
     case T_BOOLEAN:
     case T_INT:
     case T_ARRAY:
     case T_OBJECT:
+    case T_VALUETYPE:
     case T_ADDRESS:
       if( reg_arg0 == 9999 )  {
         reg_arg0 = i;
         regs[i].set1(rcx->as_VMReg());
       } else if( reg_arg1 == 9999 )  {
@@ -514,10 +515,19 @@
 
   // return value can be odd number of VMRegImpl stack slots make multiple of 2
   return align_up(stack, 2);
 }
 
+const uint SharedRuntime::java_return_convention_max_int = 1;
+const uint SharedRuntime::java_return_convention_max_float = 1;
+int SharedRuntime::java_return_convention(const BasicType *sig_bt,
+                                          VMRegPair *regs,
+                                          int total_args_passed) {
+  Unimplemented();
+  return 0;
+}
+
 // Patch the callers callsite with entry to compiled code if it exists.
 static void patch_callers_callsite(MacroAssembler *masm) {
   Label L;
   __ cmpptr(Address(rbx, in_bytes(Method::code_offset())), (int32_t)NULL_WORD);
   __ jcc(Assembler::equal, L);
@@ -575,15 +585,17 @@
   int next_off = st_off - Interpreter::stackElementSize;
   __ movdbl(Address(rsp, next_off), r);
 }
 
 static void gen_c2i_adapter(MacroAssembler *masm,
-                            int total_args_passed,
-                            int comp_args_on_stack,
-                            const BasicType *sig_bt,
+                            const GrowableArray<SigEntry>& sig_extended,
                             const VMRegPair *regs,
-                            Label& skip_fixup) {
+                            Label& skip_fixup,
+                            address start,
+                            OopMapSet*& oop_maps,
+                            int& frame_complete,
+                            int& frame_size_in_words) {
   // Before we get into the guts of the C2I adapter, see if we should be here
   // at all.  We've come from compiled code and are attempting to jump to the
   // interpreter, which means the caller made a static call to get here
   // (vcalls always get a compiled target if there is one).  Check for a
   // compiled target.  If there is one, we need to patch the caller's call.
@@ -601,29 +613,29 @@
 #endif /* COMPILER2 */
 
   // Since all args are passed on the stack, total_args_passed * interpreter_
   // stack_element_size  is the
   // space we need.
-  int extraspace = total_args_passed * Interpreter::stackElementSize;
+  int extraspace = sig_extended.length() * Interpreter::stackElementSize;
 
   // Get return address
   __ pop(rax);
 
   // set senderSP value
   __ movptr(rsi, rsp);
 
   __ subptr(rsp, extraspace);
 
   // Now write the args into the outgoing interpreter space
-  for (int i = 0; i < total_args_passed; i++) {
-    if (sig_bt[i] == T_VOID) {
-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), "missing half");
+  for (int i = 0; i < sig_extended.length(); i++) {
+    if (sig_extended.at(i)._bt == T_VOID) {
+      assert(i > 0 && (sig_extended.at(i-1)._bt == T_LONG || sig_extended.at(i-1)._bt == T_DOUBLE), "missing half");
       continue;
     }
 
     // st_off points to lowest address on stack.
-    int st_off = ((total_args_passed - 1) - i) * Interpreter::stackElementSize;
+    int st_off = ((sig_extended.length() - 1) - i) * Interpreter::stackElementSize;
     int next_off = st_off - Interpreter::stackElementSize;
 
     // Say 4 args:
     // i   st_off
     // 0   12 T_LONG
@@ -669,11 +681,11 @@
       } else {
         // long/double in gpr
         NOT_LP64(ShouldNotReachHere());
         // Two VMRegs can be T_OBJECT, T_ADDRESS, T_DOUBLE, T_LONG
         // T_DOUBLE and T_LONG use two slots in the interpreter
-        if ( sig_bt[i] == T_LONG || sig_bt[i] == T_DOUBLE) {
+        if (sig_extended.at(i)._bt == T_LONG || sig_extended.at(i)._bt == T_DOUBLE) {
           // long/double in gpr
 #ifdef ASSERT
           // Overwrite the unused slot with known junk
           LP64_ONLY(__ mov64(rax, CONST64(0xdeadffffdeadaaab)));
           __ movptr(Address(rsp, st_off), rax);
@@ -686,11 +698,11 @@
     } else {
       assert(r_1->is_XMMRegister(), "");
       if (!r_2->is_valid()) {
         __ movflt(Address(rsp, st_off), r_1->as_XMMRegister());
       } else {
-        assert(sig_bt[i] == T_DOUBLE || sig_bt[i] == T_LONG, "wrong type");
+        assert(sig_extended.at(i)._bt == T_DOUBLE || sig_extended.at(i)._bt == T_LONG, "wrong type");
         move_c2i_double(masm, r_1->as_XMMRegister(), st_off);
       }
     }
   }
 
@@ -719,14 +731,14 @@
   __ jcc(Assembler::below, L_ok);
   __ bind(L_fail);
 }
 
 void SharedRuntime::gen_i2c_adapter(MacroAssembler *masm,
-                                    int total_args_passed,
-                                    int comp_args_on_stack,
+                                    int comp_args_on_stack,
                                     const BasicType *sig_bt,
                                     const VMRegPair *regs) {
+
   // Note: rsi contains the senderSP on entry. We must preserve it since
   // we may do a i2c -> c2i transition if we lose a race where compiled
   // code goes non-entrant while we get args ready.
 
   // Adapters can be frameless because they do not require the caller
@@ -811,24 +823,24 @@
   // Pre-load the register-jump target early, to schedule it better.
   __ movptr(rdi, Address(rbx, in_bytes(Method::from_compiled_offset())));
 
   // Now generate the shuffle code.  Pick up all register args and move the
   // rest through the floating point stack top.
-  for (int i = 0; i < total_args_passed; i++) {
-    if (sig_bt[i] == T_VOID) {
+  for (int i = 0; i < sig_extended.length(); i++) {
+    if (sig_extended.at(i)._bt == T_VOID) {
       // Longs and doubles are passed in native word order, but misaligned
       // in the 32-bit build.
-      assert(i > 0 && (sig_bt[i-1] == T_LONG || sig_bt[i-1] == T_DOUBLE), "missing half");
+      assert(i > 0 && (sig_extended.at(i-1)._bt == T_LONG || sig_extended.at(i-1)._bt == T_DOUBLE), "missing half");
       continue;
     }
 
     // Pick up 0, 1 or 2 words from SP+offset.
 
     assert(!regs[i].second()->is_valid() || regs[i].first()->next() == regs[i].second(),
             "scrambled load targets?");
     // Load in argument order going down.
-    int ld_off = (total_args_passed - i) * Interpreter::stackElementSize;
+    int ld_off = (sig_extended.length() - i) * Interpreter::stackElementSize;
     // Point to interpreter value (vs. tag)
     int next_off = ld_off - Interpreter::stackElementSize;
     //
     //
     //
@@ -865,11 +877,11 @@
         //
         // Interpreter local[n] == MSW, local[n+1] == LSW however locals
         // are accessed as negative so LSW is at LOW address
 
         // ld_off is MSW so get LSW
-        const int offset = (NOT_LP64(true ||) sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?
+        const int offset = (NOT_LP64(true ||) sig_extended.at(i)._bt==T_LONG||sig_extended.at(i)._bt==T_DOUBLE)?
                            next_off : ld_off;
         __ movptr(rsi, Address(saved_sp, offset));
         __ movptr(Address(rsp, st_off), rsi);
 #ifndef _LP64
         __ movptr(rsi, Address(saved_sp, ld_off));
@@ -883,11 +895,11 @@
         //
         // We are using two VMRegs. This can be either T_OBJECT, T_ADDRESS, T_LONG, or T_DOUBLE
         // the interpreter allocates two slots but only uses one for thr T_LONG or T_DOUBLE case
         // So we must adjust where to pick up the data to match the interpreter.
 
-        const int offset = (NOT_LP64(true ||) sig_bt[i]==T_LONG||sig_bt[i]==T_DOUBLE)?
+        const int offset = (NOT_LP64(true ||) sig_extended.at(i)._bt==T_LONG||sig_extended.at(i)._bt==T_DOUBLE)?
                            next_off : ld_off;
 
         // this can be a misaligned move
         __ movptr(r, Address(saved_sp, offset));
 #ifndef _LP64
@@ -931,18 +943,18 @@
   __ jmp(rdi);
 }
 
 // ---------------------------------------------------------------
 AdapterHandlerEntry* SharedRuntime::generate_i2c2i_adapters(MacroAssembler *masm,
-                                                            int total_args_passed,
-                                                            int comp_args_on_stack,
+                                                            int comp_args_on_stack,
                                                             const BasicType *sig_bt,
                                                             const VMRegPair *regs,
-                                                            AdapterFingerPrint* fingerprint) {
+                                                            AdapterFingerPrint* fingerprint,
+                                                            AdapterBlob*& new_adapter) {
   address i2c_entry = __ pc();
 
-  gen_i2c_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs);
+  gen_i2c_adapter(masm, comp_args_on_stack, sig_extended, regs);
 
   // -------------------------------------------------------------------------
   // Generate a C2I adapter.  On entry we know rbx, holds the Method* during calls
   // to the interpreter.  The args start out packed in the compiled layout.  They
   // need to be unpacked into the interpreter layout.  This will almost always
@@ -978,13 +990,17 @@
   address c2i_entry = __ pc();
 
   BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();
   bs->c2i_entry_barrier(masm);
 
-  gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);
+  OopMapSet* oop_maps = NULL;
+  int frame_complete = CodeOffsets::frame_never_safe;
+  int frame_size_in_words = 0;
+  gen_c2i_adapter(masm, sig_extended, regs, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words);
 
   __ flush();
+  new_adapter = AdapterBlob::create(masm->code(), frame_complete, frame_size_in_words, oop_maps);
   return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry);
 }
 
 int SharedRuntime::c_calling_convention(const BasicType *sig_bt,
                                          VMRegPair *regs,
@@ -1004,10 +1020,11 @@
     case T_FLOAT:
     case T_BYTE:
     case T_SHORT:
     case T_INT:
     case T_OBJECT:
+    case T_VALUETYPE:
     case T_ARRAY:
     case T_ADDRESS:
     case T_METADATA:
       regs[i].set1(VMRegImpl::stack2reg(stack++));
       break;
@@ -1285,10 +1302,11 @@
           } else {
             __ movl(reg, Address(rsp, offset));
           }
           break;
         case T_OBJECT:
+        case T_VALUETYPE:
         default: ShouldNotReachHere();
       }
     } else if (in_regs[i].first()->is_XMMRegister()) {
       if (in_sig_bt[i] == T_FLOAT) {
         int slot = handle_index++ * VMRegImpl::slots_per_word + arg_save_area;
@@ -2002,10 +2020,11 @@
 
           unpack_array_argument(masm, in_arg, in_elem_bt[i], out_regs[c_arg + 1], out_regs[c_arg]);
           c_arg++;
           break;
         }
+      case T_VALUETYPE:
       case T_OBJECT:
         assert(!is_critical_native, "no oop arguments");
         object_move(masm, map, oop_handle_offset, stack_slots, in_regs[i], out_regs[c_arg],
                     ((i == 0) && (!is_static)),
                     &receiver_offset);
@@ -2184,10 +2203,11 @@
   case T_DOUBLE :
   case T_FLOAT  :
     // Result is in st0 we'll save as needed
     break;
   case T_ARRAY:                 // Really a handle
+  case T_VALUETYPE:             // Really a handle
   case T_OBJECT:                // Really a handle
       break; // can't de-handlize until after safepoint check
   case T_VOID: break;
   case T_LONG: break;
   default       : ShouldNotReachHere();
@@ -3302,5 +3322,10 @@
 
   // return the  blob
   // frame_size_words or bytes??
   return RuntimeStub::new_runtime_stub(name, &buffer, frame_complete, frame_size_words, oop_maps, true);
 }
+
+BufferedValueTypeBlob* SharedRuntime::generate_buffered_value_type_adapter(const ValueKlass* vk) {
+  Unimplemented();
+  return NULL;
+}
diff a/src/hotspot/share/adlc/formssel.cpp b/src/hotspot/share/adlc/formssel.cpp
--- a/src/hotspot/share/adlc/formssel.cpp
+++ b/src/hotspot/share/adlc/formssel.cpp
@@ -761,10 +761,11 @@
 // Expected use is for pointer vs oop determination for LoadP
 bool InstructForm::captures_bottom_type(FormDict &globals) const {
   if (_matrule && _matrule->_rChild &&
       (!strcmp(_matrule->_rChild->_opType,"CastPP")       ||  // new result type
        !strcmp(_matrule->_rChild->_opType,"CastX2P")      ||  // new result type
+       !strcmp(_matrule->_rChild->_opType,"CastI2N")      ||  // new result type
        !strcmp(_matrule->_rChild->_opType,"DecodeN")      ||
        !strcmp(_matrule->_rChild->_opType,"EncodeP")      ||
        !strcmp(_matrule->_rChild->_opType,"DecodeNKlass") ||
        !strcmp(_matrule->_rChild->_opType,"EncodePKlass") ||
        !strcmp(_matrule->_rChild->_opType,"LoadN")        ||
@@ -785,11 +786,11 @@
   if (needs_base_oop_edge(globals)) return true;
 
   if (is_vector()) return true;
   if (is_mach_constant()) return true;
 
-  return  false;
+  return false;
 }
 
 
 // Access instr_cost attribute or return NULL.
 const char* InstructForm::cost() {
@@ -875,11 +876,12 @@
   if( strcmp(_matrule->_opType,"Return"    )==0 ||
       strcmp(_matrule->_opType,"Rethrow"   )==0 ||
       strcmp(_matrule->_opType,"TailCall"  )==0 ||
       strcmp(_matrule->_opType,"TailJump"  )==0 ||
       strcmp(_matrule->_opType,"SafePoint" )==0 ||
-      strcmp(_matrule->_opType,"Halt"      )==0 )
+      strcmp(_matrule->_opType,"Halt"      )==0 ||
+      strcmp(_matrule->_opType,"CallLeafNoFP")==0)
     return AdlcVMDeps::Parms;   // Skip the machine-state edges
 
   if( _matrule->_rChild &&
       ( strcmp(_matrule->_rChild->_opType,"AryEq"     )==0 ||
         strcmp(_matrule->_rChild->_opType,"StrComp"   )==0 ||
diff a/src/hotspot/share/c1/c1_FrameMap.cpp b/src/hotspot/share/c1/c1_FrameMap.cpp
--- a/src/hotspot/share/c1/c1_FrameMap.cpp
+++ b/src/hotspot/share/c1/c1_FrameMap.cpp
@@ -39,11 +39,11 @@
   if (!method->is_static()) sta->append(T_OBJECT);
   // add remaining arguments
   for (int i = 0; i < sig->count(); i++) {
     ciType* type = sig->type_at(i);
     BasicType t = type->basic_type();
-    if (t == T_ARRAY) {
+    if (t == T_ARRAY || t == T_VALUETYPE) {
       t = T_OBJECT;
     }
     sta->append(t);
   }
   // done
@@ -181,18 +181,19 @@
   }
 
 }
 
 
-bool FrameMap::finalize_frame(int nof_slots) {
+bool FrameMap::finalize_frame(int nof_slots, bool needs_stack_repair) {
   assert(nof_slots >= 0, "must be positive");
   assert(_num_spills == -1, "can only be set once");
   _num_spills = nof_slots;
   assert(_framesize == -1, "should only be calculated once");
   _framesize =  align_up(in_bytes(sp_offset_for_monitor_base(0)) +
                          _num_monitors * (int)sizeof(BasicObjectLock) +
-                         (int)sizeof(intptr_t) +                        // offset of deopt orig pc
+                         (int)sizeof(intptr_t) +                             // offset of deopt orig pc
+                         (needs_stack_repair ? (int)sizeof(intptr_t) : 0) +  // stack increment value
                          frame_pad_in_bytes,
                          StackAlignmentInBytes) / 4;
   int java_index = 0;
   for (int i = 0; i < _incoming_arguments->length(); i++) {
     LIR_Opr opr = _incoming_arguments->at(i);
diff a/src/hotspot/share/c1/c1_GraphBuilder.cpp b/src/hotspot/share/c1/c1_GraphBuilder.cpp
--- a/src/hotspot/share/c1/c1_GraphBuilder.cpp
+++ b/src/hotspot/share/c1/c1_GraphBuilder.cpp
@@ -31,10 +31,11 @@
 #include "ci/ciCallSite.hpp"
 #include "ci/ciField.hpp"
 #include "ci/ciKlass.hpp"
 #include "ci/ciMemberName.hpp"
 #include "ci/ciUtilities.inline.hpp"
+#include "ci/ciValueKlass.hpp"
 #include "compiler/compilationPolicy.hpp"
 #include "compiler/compileBroker.hpp"
 #include "compiler/compilerEvent.hpp"
 #include "interpreter/bytecode.hpp"
 #include "jfr/jfrEvents.hpp"
@@ -654,10 +655,21 @@
     } else {
       _fields.at(index)->kill();
     }
   }
 
+  // Record this newly allocated object
+  void new_instance(NewValueTypeInstance* object) {
+    int index = _newobjects.length();
+    _newobjects.append(object);
+    if (_fields.at_grow(index, NULL) == NULL) {
+      _fields.at_put(index, new FieldBuffer());
+    } else {
+      _fields.at(index)->kill();
+    }
+  }
+
   void store_value(Value value) {
     int index = _newobjects.find(value);
     if (index != -1) {
       // stored a newly allocated object into another object.
       // Assume we've lost track of it as separate slice of memory.
@@ -969,38 +981,80 @@
     } else if (index == scope_data()->jsr_return_address_local()) {
       scope_data()->set_jsr_return_address_local(-1);
     }
   }
 
+  x->set_local_index(index);
   state->store_local(index, round_fp(x));
 }
 
 
 void GraphBuilder::load_indexed(BasicType type) {
   // In case of in block code motion in range check elimination
-  ValueStack* state_before = copy_state_indexed_access();
+  ValueStack* state_before = NULL;
+  int array_idx = state()->stack_size() - 2;
+  if (type == T_OBJECT && state()->stack_at(array_idx)->maybe_flattened_array()) {
+    // Save the entire state and re-execute on deopt when accessing flattened arrays
+    state_before = copy_state_before();
+    state_before->set_should_reexecute(true);
+  } else {
+    state_before = copy_state_indexed_access();
+  }
   compilation()->set_has_access_indexed(true);
   Value index = ipop();
   Value array = apop();
   Value length = NULL;
   if (CSEArrayLength ||
       (array->as_AccessField() && array->as_AccessField()->field()->is_constant()) ||
       (array->as_NewArray() && array->as_NewArray()->length() && array->as_NewArray()->length()->type()->is_constant())) {
     length = append(new ArrayLength(array, state_before));
   }
-  push(as_ValueType(type), append(new LoadIndexed(array, index, length, type, state_before)));
+
+  LoadIndexed* load_indexed = NULL;
+  Instruction* result = NULL;
+  if (array->is_loaded_flattened_array()) {
+    ciType* array_type = array->declared_type();
+    ciValueKlass* elem_klass = array_type->as_value_array_klass()->element_klass()->as_value_klass();
+    NewValueTypeInstance* new_instance = new NewValueTypeInstance(elem_klass, state_before, false);
+    _memory->new_instance(new_instance);
+    apush(append_split(new_instance));
+    load_indexed = new LoadIndexed(array, index, length, type, state_before);
+    load_indexed->set_vt(new_instance);
+  } else {
+    load_indexed = new LoadIndexed(array, index, length, type, state_before);
+  }
+  if (profile_array_accesses() && is_reference_type(type)) {
+    compilation()->set_would_profile(true);
+    load_indexed->set_should_profile(true);
+    load_indexed->set_profiled_method(method());
+    load_indexed->set_profiled_bci(bci());
+  }
+  result = append(load_indexed);
+  assert(!(profile_array_accesses() && is_reference_type(type)) || load_indexed == result, "should not be optimized out");
+  if (!array->is_loaded_flattened_array()) {
+    push(as_ValueType(type), result);
+  }
 }
 
 
 void GraphBuilder::store_indexed(BasicType type) {
   // In case of in block code motion in range check elimination
-  ValueStack* state_before = copy_state_indexed_access();
+  ValueStack* state_before = NULL;
+  int array_idx = state()->stack_size() - 3;
+  if (type == T_OBJECT && state()->stack_at(array_idx)->maybe_flattened_array()) {
+    // Save the entire state and re-execute on deopt when accessing flattened arrays
+    state_before = copy_state_before();
+    state_before->set_should_reexecute(true);
+  } else {
+    state_before = copy_state_indexed_access();
+  }
   compilation()->set_has_access_indexed(true);
   Value value = pop(as_ValueType(type));
   Value index = ipop();
   Value array = apop();
   Value length = NULL;
+  value->set_escaped();
   if (CSEArrayLength ||
       (array->as_AccessField() && array->as_AccessField()->field()->is_constant()) ||
       (array->as_NewArray() && array->as_NewArray()->length() && array->as_NewArray()->length()->type()->is_constant())) {
     length = append(new ArrayLength(array, state_before));
   }
@@ -1014,24 +1068,22 @@
       value = append(new LogicOp(Bytecodes::_iand, value, mask));
     }
   } else if (type == T_BYTE) {
     check_boolean = true;
   }
-  StoreIndexed* result = new StoreIndexed(array, index, length, type, value, state_before, check_boolean);
-  append(result);
-  _memory->store_value(value);
-
-  if (type == T_OBJECT && is_profiling()) {
+
+  StoreIndexed* store_indexed = new StoreIndexed(array, index, length, type, value, state_before, check_boolean);
     // Note that we'd collect profile data in this method if we wanted it.
     compilation()->set_would_profile(true);
-
-    if (profile_checkcasts()) {
-      result->set_profiled_method(method());
-      result->set_profiled_bci(bci());
-      result->set_should_profile(true);
-    }
+    store_indexed->set_should_profile(true);
+    store_indexed->set_profiled_method(method());
+    store_indexed->set_profiled_bci(bci());
   }
+  Instruction* result = append(store_indexed);
+  assert(!store_indexed->should_profile() || store_indexed == result, "should not be optimized out");
+  _memory->store_value(value);
+
 }
 
 
 void GraphBuilder::stack_op(Bytecodes::Code code) {
   switch (code) {
@@ -1222,13 +1274,39 @@
 
 void GraphBuilder::if_node(Value x, If::Condition cond, Value y, ValueStack* state_before) {
   BlockBegin* tsux = block_at(stream()->get_dest());
   BlockBegin* fsux = block_at(stream()->next_bci());
   bool is_bb = tsux->bci() < stream()->cur_bci() || fsux->bci() < stream()->cur_bci();
+
+  bool subst_check = false;
+  if (EnableValhalla && (stream()->cur_bc() == Bytecodes::_if_acmpeq || stream()->cur_bc() == Bytecodes::_if_acmpne) &&
+      method() != ciEnv::current()->ValueBootstrapMethods_klass()->find_method(ciSymbol::isSubstitutable_name(), ciSymbol::object_object_boolean_signature())) {
+    // If current method is ValueBootstrapMethods::isSubstitutable(),
+    // compile the acmp as a regular pointer comparison otherwise we
+    // could call ValueBootstrapMethods::isSubstitutable() back
+    ValueType* left_vt = x->type();
+    ValueType* right_vt = y->type();
+    if (left_vt->is_object()) {
+      assert(right_vt->is_object(), "must be");
+      ciKlass* left_klass = x->as_loaded_klass_or_null();
+      ciKlass* right_klass = y->as_loaded_klass_or_null();
+
+      if (left_klass == NULL || right_klass == NULL) {
+        // The klass is still unloaded, or came from a Phi node. Go slow case;
+        subst_check = true;
+      } else if (left_klass->can_be_value_klass() || right_klass->can_be_value_klass()) {
+        // Either operand may be a value object, but we're not sure. Go slow case;
+        subst_check = true;
+      } else {
+        // No need to do substitutability check
+      }
+    }
+  }
+
   // In case of loop invariant code motion or predicate insertion
   // before the body of a loop the state is needed
-  Instruction *i = append(new If(x, cond, false, y, tsux, fsux, (is_bb || compilation()->is_optimistic()) ? state_before : NULL, is_bb));
+  Instruction *i = append(new If(x, cond, false, y, tsux, fsux, (is_bb || compilation()->is_optimistic() || subst_check) ? state_before : NULL, is_bb, subst_check));
 
   assert(i->as_Goto() == NULL ||
          (i->as_Goto()->sux_at(0) == tsux  && i->as_Goto()->is_safepoint() == tsux->bci() < stream()->cur_bci()) ||
          (i->as_Goto()->sux_at(0) == fsux  && i->as_Goto()->is_safepoint() == fsux->bci() < stream()->cur_bci()),
          "safepoint state of Goto returned by canonicalizer incorrect");
@@ -1475,11 +1553,11 @@
     call_register_finalizer();
   }
 
   // The conditions for a memory barrier are described in Parse::do_exits().
   bool need_mem_bar = false;
-  if (method()->name() == ciSymbol::object_initializer_name() &&
+  if (method()->is_object_constructor() &&
        (scope()->wrote_final() ||
          (AlwaysSafeConstructors && scope()->wrote_fields()) ||
          (support_IRIW_for_not_multiple_copy_atomic_cpu && scope()->wrote_volatile()))) {
     need_mem_bar = true;
   }
@@ -1626,16 +1704,31 @@
     default:
       return new Constant(value);
   }
 }
 
+void GraphBuilder::copy_value_content(ciValueKlass* vk, Value src, int src_off, Value dest, int dest_off,
+    ValueStack* state_before, bool needs_patching) {
+  src->set_escaped();
+  for (int i = 0; i < vk->nof_nonstatic_fields(); i++) {
+    ciField* inner_field = vk->nonstatic_field_at(i);
+    assert(!inner_field->is_flattened(), "the iteration over nested fields is handled by the loop itself");
+    int off = inner_field->offset() - vk->first_field_offset();
+    LoadField* load = new LoadField(src, src_off + off, inner_field, false, state_before, needs_patching);
+    Value replacement = append(load);
+    StoreField* store = new StoreField(dest, dest_off + off, inner_field, replacement, false, state_before, needs_patching);
+    append(store);
+  }
+}
+
 void GraphBuilder::access_field(Bytecodes::Code code) {
   bool will_link;
   ciField* field = stream()->get_field(will_link);
   ciInstanceKlass* holder = field->holder();
   BasicType field_type = field->type()->basic_type();
   ValueType* type = as_ValueType(field_type);
+
   // call will_link again to determine if the field is valid.
   const bool needs_patching = !holder->is_loaded() ||
                               !field->will_link(method(), code) ||
                               PatchALot;
 
@@ -1654,15 +1747,15 @@
     } else {
       obj = new Constant(new InstanceConstant(holder->java_mirror()));
     }
   }
 
-  if (field->is_final() && (code == Bytecodes::_putfield)) {
+  if (field->is_final() && (code == Bytecodes::_putfield || code == Bytecodes::_withfield)) {
     scope()->set_wrote_final();
   }
 
-  if (code == Bytecodes::_putfield) {
+  if (code == Bytecodes::_putfield || code == Bytecodes::_withfield) {
     scope()->set_wrote_fields();
     if (field->is_volatile()) {
       scope()->set_wrote_volatile();
     }
   }
@@ -1682,17 +1775,22 @@
         push(type, append(constant));
       } else {
         if (state_before == NULL) {
           state_before = copy_state_for_exception();
         }
-        push(type, append(new LoadField(append(obj), offset, field, true,
-                                        state_before, needs_patching)));
+        LoadField* load_field = new LoadField(append(obj), offset, field, true,
+                                        state_before, needs_patching);
+        if (field->is_flattenable()) {
+          load_field->set_never_null(true);
+        }
+        push(type, append(load_field));
       }
       break;
     }
     case Bytecodes::_putstatic: {
       Value val = pop(type);
+      val->set_escaped();
       if (state_before == NULL) {
         state_before = copy_state_for_exception();
       }
       if (field->type()->basic_type() == T_BOOLEAN) {
         Value mask = append(new Constant(new IntConstant(1)));
@@ -1702,13 +1800,18 @@
       break;
     }
     case Bytecodes::_getfield: {
       // Check for compile-time constants, i.e., trusted final non-static fields.
       Value constant = NULL;
+      if (state_before == NULL && field->is_flattened()) {
+        // Save the entire state and re-execute on deopt when accessing flattened fields
+        assert(Interpreter::bytecode_should_reexecute(code), "should reexecute");
+        state_before = copy_state_before();
+      }
       obj = apop();
       ObjectType* obj_type = obj->type()->as_ObjectType();
-      if (field->is_constant() && obj_type->is_constant() && !PatchALot) {
+      if (field->is_constant() && !field->is_flattened() && obj_type->is_constant() && !PatchALot) {
         ciObject* const_oop = obj_type->constant_value();
         if (!const_oop->is_null_object() && const_oop->is_loaded()) {
           ciConstant field_value = field->constant_value_of(const_oop);
           if (field_value.is_valid()) {
             constant = make_constant(field_value, field);
@@ -1727,61 +1830,197 @@
         push(type, append(constant));
       } else {
         if (state_before == NULL) {
           state_before = copy_state_for_exception();
         }
-        LoadField* load = new LoadField(obj, offset, field, false, state_before, needs_patching);
-        Value replacement = !needs_patching ? _memory->load(load) : load;
-        if (replacement != load) {
-          assert(replacement->is_linked() || !replacement->can_be_linked(), "should already by linked");
-          // Writing an (integer) value to a boolean, byte, char or short field includes an implicit narrowing
-          // conversion. Emit an explicit conversion here to get the correct field value after the write.
-          BasicType bt = field->type()->basic_type();
-          switch (bt) {
-          case T_BOOLEAN:
-          case T_BYTE:
-            replacement = append(new Convert(Bytecodes::_i2b, replacement, as_ValueType(bt)));
-            break;
-          case T_CHAR:
-            replacement = append(new Convert(Bytecodes::_i2c, replacement, as_ValueType(bt)));
-            break;
-          case T_SHORT:
-            replacement = append(new Convert(Bytecodes::_i2s, replacement, as_ValueType(bt)));
-            break;
-          default:
-            break;
+        if (!field->is_flattened()) {
+          LoadField* load = new LoadField(obj, offset, field, false, state_before, needs_patching);
+          Value replacement = !needs_patching ? _memory->load(load) : load;
+          if (replacement != load) {
+            assert(replacement->is_linked() || !replacement->can_be_linked(), "should already by linked");
+            // Writing an (integer) value to a boolean, byte, char or short field includes an implicit narrowing
+            // conversion. Emit an explicit conversion here to get the correct field value after the write.
+            BasicType bt = field->type()->basic_type();
+            switch (bt) {
+            case T_BOOLEAN:
+            case T_BYTE:
+              replacement = append(new Convert(Bytecodes::_i2b, replacement, as_ValueType(bt)));
+              break;
+            case T_CHAR:
+              replacement = append(new Convert(Bytecodes::_i2c, replacement, as_ValueType(bt)));
+              break;
+            case T_SHORT:
+              replacement = append(new Convert(Bytecodes::_i2s, replacement, as_ValueType(bt)));
+              break;
+            default:
+              break;
+            }
+            push(type, replacement);
+          } else {
+            push(type, append(load));
           }
-          push(type, replacement);
-        } else {
-          push(type, append(load));
+        } else { // flattened field, not optimized solution: re-instantiate the flattened value
+          assert(field->type()->is_valuetype(), "Sanity check");
+          ciValueKlass* value_klass = field->type()->as_value_klass();
+          int flattening_offset = field->offset() - value_klass->first_field_offset();
+          assert(field->type()->is_valuetype(), "Sanity check");
+          scope()->set_wrote_final();
+          scope()->set_wrote_fields();
+          NewValueTypeInstance* new_instance = new NewValueTypeInstance(value_klass, state_before, false);
+          _memory->new_instance(new_instance);
+          apush(append_split(new_instance));
+          copy_value_content(value_klass, obj, field->offset(), new_instance, value_klass->first_field_offset(),
+                       state_before, needs_patching);
         }
       }
       break;
     }
+    case Bytecodes::_withfield:
     case Bytecodes::_putfield: {
       Value val = pop(type);
+      val->set_escaped();
       obj = apop();
       if (state_before == NULL) {
         state_before = copy_state_for_exception();
       }
       if (field->type()->basic_type() == T_BOOLEAN) {
         Value mask = append(new Constant(new IntConstant(1)));
         val = append(new LogicOp(Bytecodes::_iand, val, mask));
       }
-      StoreField* store = new StoreField(obj, offset, field, val, false, state_before, needs_patching);
-      if (!needs_patching) store = _memory->store(store);
-      if (store != NULL) {
-        append(store);
+
+      if (!field->is_flattened()) {
+        StoreField* store = new StoreField(obj, offset, field, val, false, state_before, needs_patching);
+        if (!needs_patching) store = _memory->store(store);
+        if (store != NULL) {
+          append(store);
+        }
+      } else {
+        assert(field->type()->is_valuetype(), "Sanity check");
+        ciValueKlass* value_klass = field->type()->as_value_klass();
+        int flattening_offset = field->offset() - value_klass->first_field_offset();
+        copy_value_content(value_klass, val, value_klass->first_field_offset(), obj, field->offset(),
+                   state_before, needs_patching);
       }
       break;
     }
     default:
       ShouldNotReachHere();
       break;
   }
 }
 
+// Baseline version of withfield, allocate every time
+void GraphBuilder::withfield(int field_index)
+{
+  bool will_link;
+  ciField* field_modify = stream()->get_field(will_link);
+  ciInstanceKlass* holder = field_modify->holder();
+  BasicType field_type = field_modify->type()->basic_type();
+  ValueType* type = as_ValueType(field_type);
+
+  // call will_link again to determine if the field is valid.
+  const bool needs_patching = !holder->is_loaded() ||
+                              !field_modify->will_link(method(), Bytecodes::_withfield) ||
+                              PatchALot;
+
+
+  scope()->set_wrote_final();
+  scope()->set_wrote_fields();
+
+  const int offset = !needs_patching ? field_modify->offset() : -1;
+
+  if (!holder->is_loaded()
+      || needs_patching /* FIXME: 8228634 - field_modify->will_link() may incorrectly return false */
+      ) {
+    ValueStack* state_before = copy_state_before();
+    Value val = pop(type);
+    Value obj = apop();
+    apush(append_split(new WithField(state_before)));
+    return;
+  }
+  ValueStack* state_before = copy_state_before();
+
+  Value val = pop(type);
+  Value obj = apop();
+
+  if (!needs_patching && obj->is_optimizable_for_withfield()) {
+    int astore_index;
+    ciBytecodeStream s(method());
+    s.force_bci(bci());
+    s.next();
+    switch (s.cur_bc()) {
+    case Bytecodes::_astore:    astore_index = s.get_index(); break;
+    case Bytecodes::_astore_0:  astore_index = 0; break;
+    case Bytecodes::_astore_1:  astore_index = 1; break;
+    case Bytecodes::_astore_2:  astore_index = 2; break;
+    case Bytecodes::_astore_3:  astore_index = 3; break;
+    default: astore_index = -1;
+    }
+
+    if (astore_index >= 0 && obj == state()->local_at(astore_index)) {
+      // We have a sequence like this, where we load a value object from a local slot,
+      // and overwrite the same local slot with a modified copy of the value object.
+      //      defaultvalue #1 // class compiler/valhalla/valuetypes/MyValue1
+      //      astore 9
+      //      ...
+      //      iload_0
+      //      aload 9
+      //      swap
+      //      withfield #7 // Field x:I
+      //      astore 9
+      // If this object was created by defaultvalue, and has not escaped, and is not stored
+      // in any other local slots, we can effectively treat the withfield/astore
+      // sequence as a single putfield bytecode.
+      push(objectType, obj);
+      push(type, val);
+      access_field(Bytecodes::_withfield);
+      stream()->next(); // skip the next astore/astore_n bytecode.
+      return;
+    }
+  }
+
+  assert(holder->is_valuetype(), "must be a value klass");
+  // Save the entire state and re-execute on deopt when executing withfield
+  state_before->set_should_reexecute(true);
+  NewValueTypeInstance* new_instance = new NewValueTypeInstance(holder->as_value_klass(), state_before, false);
+  _memory->new_instance(new_instance);
+  apush(append_split(new_instance));
+
+  for (int i = 0; i < holder->nof_nonstatic_fields(); i++) {
+    ciField* field = holder->nonstatic_field_at(i);
+    int off = field->offset();
+
+    if (field->offset() != offset) {
+      if (field->is_flattened()) {
+        assert(field->type()->is_valuetype(), "Sanity check");
+        assert(field->type()->is_valuetype(), "Only value types can be flattened");
+        ciValueKlass* vk = field->type()->as_value_klass();
+        copy_value_content(vk, obj, off, new_instance, vk->first_field_offset(), state_before, needs_patching);
+      } else {
+        // Only load those fields who are not modified
+        LoadField* load = new LoadField(obj, off, field, false, state_before, needs_patching);
+        Value replacement = append(load);
+        StoreField* store = new StoreField(new_instance, off, field, replacement, false, state_before, needs_patching);
+        append(store);
+      }
+    }
+  }
+
+  // Field to modify
+  if (field_modify->type()->basic_type() == T_BOOLEAN) {
+    Value mask = append(new Constant(new IntConstant(1)));
+    val = append(new LogicOp(Bytecodes::_iand, val, mask));
+  }
+  if (field_modify->is_flattened()) {
+    assert(field_modify->type()->is_valuetype(), "Only value types can be flattened");
+    ciValueKlass* vk = field_modify->type()->as_value_klass();
+    copy_value_content(vk, val, vk->first_field_offset(), new_instance, field_modify->offset(), state_before, needs_patching);
+  } else {
+    StoreField* store = new StoreField(new_instance, offset, field_modify, val, false, state_before, needs_patching);
+    append(store);
+  }
+}
 
 Dependencies* GraphBuilder::dependency_recorder() const {
   assert(DeoptC1, "need debug information");
   return compilation()->dependency_recorder();
 }
@@ -1863,11 +2102,11 @@
       log->elem("call method='%d' instr='%s'",
                 log->identify(target),
                 Bytecodes::name(code));
 
   // invoke-special-super
-  if (bc_raw == Bytecodes::_invokespecial && !target->is_object_initializer()) {
+  if (bc_raw == Bytecodes::_invokespecial && !target->is_object_constructor()) {
     ciInstanceKlass* sender_klass =
           calling_klass->is_unsafe_anonymous() ? calling_klass->unsafe_anonymous_host() :
                                                  calling_klass;
     if (sender_klass->is_interface()) {
       int index = state()->stack_size() - (target->arg_size_no_receiver() + 1);
@@ -2118,11 +2357,19 @@
         profile_call(target, recv, target_klass, collect_args_for_profiling(args, NULL, false), false);
       }
     }
   }
 
-  Invoke* result = new Invoke(code, result_type, recv, args, vtable_index, target, state_before);
+  if (recv != NULL) {
+    recv->set_escaped();
+  }
+  for (int i=0; i<args->length(); i++) {
+    args->at(0)->set_escaped();
+  }
+
+  Invoke* result = new Invoke(code, result_type, recv, args, vtable_index, target, state_before,
+                              declared_signature->returns_never_null());
   // push result
   append_split(result);
 
   if (result_type != voidType) {
     if (method()->is_strict()) {
@@ -2140,27 +2387,39 @@
 void GraphBuilder::new_instance(int klass_index) {
   ValueStack* state_before = copy_state_exhandling();
   bool will_link;
   ciKlass* klass = stream()->get_klass(will_link);
   assert(klass->is_instance_klass(), "must be an instance klass");
+  assert(!klass->is_valuetype(), "must not be a value klass");
   NewInstance* new_instance = new NewInstance(klass->as_instance_klass(), state_before, stream()->is_unresolved_klass());
   _memory->new_instance(new_instance);
   apush(append_split(new_instance));
 }
 
+void GraphBuilder::default_value(int klass_index) {
+  bool will_link;
+  ciValueKlass* vk = stream()->get_klass(will_link)->as_value_klass();
+  if (!stream()->is_unresolved_klass()) {
+    apush(append(new Constant(new InstanceConstant(vk->default_value_instance()))));
+  } else {
+    ValueStack* state_before = copy_state_before();
+    apush(append_split(new DefaultValue(state_before)));
+  }
+}
 
 void GraphBuilder::new_type_array() {
   ValueStack* state_before = copy_state_exhandling();
   apush(append_split(new NewTypeArray(ipop(), (BasicType)stream()->get_index(), state_before)));
 }
 
 
 void GraphBuilder::new_object_array() {
   bool will_link;
   ciKlass* klass = stream()->get_klass(will_link);
+  bool never_null = stream()->is_klass_never_null();
   ValueStack* state_before = !klass->is_loaded() || PatchALot ? copy_state_before() : copy_state_exhandling();
-  NewArray* n = new NewObjectArray(klass, ipop(), state_before);
+  NewArray* n = new NewObjectArray(klass, ipop(), state_before, never_null);
   apush(append_split(n));
 }
 
 
 bool GraphBuilder::direct_compare(ciKlass* k) {
@@ -2181,12 +2440,13 @@
 
 
 void GraphBuilder::check_cast(int klass_index) {
   bool will_link;
   ciKlass* klass = stream()->get_klass(will_link);
+  bool never_null = stream()->is_klass_never_null();
   ValueStack* state_before = !klass->is_loaded() || PatchALot ? copy_state_before() : copy_state_for_exception();
-  CheckCast* c = new CheckCast(klass, apop(), state_before);
+  CheckCast* c = new CheckCast(klass, apop(), state_before, never_null);
   apush(append_split(c));
   c->set_direct_compare(direct_compare(klass));
 
   if (is_profiling()) {
     // Note that we'd collect profile data in this method if we wanted it.
@@ -2221,13 +2481,32 @@
   }
 }
 
 
 void GraphBuilder::monitorenter(Value x, int bci) {
+  bool maybe_valuetype = false;
+  if (bci == InvocationEntryBci) {
+    // Called by GraphBuilder::inline_sync_entry.
+#ifdef ASSERT
+    ciType* obj_type = x->declared_type();
+    assert(obj_type == NULL || !obj_type->is_valuetype(), "valuetypes cannot have synchronized methods");
+#endif
+  } else {
+    // We are compiling a monitorenter bytecode
+    if (EnableValhalla) {
+      ciType* obj_type = x->declared_type();
+      if (obj_type == NULL || obj_type->as_klass()->can_be_value_klass()) {
+        // If we're (possibly) locking on a valuetype, check for markWord::always_locked_pattern
+        // and throw IMSE. (obj_type is null for Phi nodes, so let's just be conservative).
+        maybe_valuetype = true;
+      }
+    }
+  }
+
   // save state before locking in case of deoptimization after a NullPointerException
   ValueStack* state_before = copy_state_for_exception_with_bci(bci);
-  append_with_bci(new MonitorEnter(x, state()->lock(x), state_before), bci);
+  append_with_bci(new MonitorEnter(x, state()->lock(x), state_before, maybe_valuetype), bci);
   kill_all();
 }
 
 
 void GraphBuilder::monitorexit(Value x, int bci) {
@@ -2885,10 +3164,12 @@
       case Bytecodes::_multianewarray : new_multi_array(s.cur_bcp()[3]); break;
       case Bytecodes::_ifnull         : if_null(objectType, If::eql); break;
       case Bytecodes::_ifnonnull      : if_null(objectType, If::neq); break;
       case Bytecodes::_goto_w         : _goto(s.cur_bci(), s.get_far_dest()); break;
       case Bytecodes::_jsr_w          : jsr(s.get_far_dest()); break;
+      case Bytecodes::_defaultvalue   : default_value(s.get_index_u2()); break;
+      case Bytecodes::_withfield      : withfield(s.get_index_u2()); break;
       case Bytecodes::_breakpoint     : BAILOUT_("concurrent setting of breakpoint", NULL);
       default                         : ShouldNotReachHere(); break;
     }
 
     if (log != NULL)
@@ -3170,11 +3451,12 @@
 
   // Set up locals for receiver
   int idx = 0;
   if (!method()->is_static()) {
     // we should always see the receiver
-    state->store_local(idx, new Local(method()->holder(), objectType, idx, true));
+    state->store_local(idx, new Local(method()->holder(), objectType, idx,
+             /*receiver*/ true, /*never_null*/ method()->holder()->is_value_array_klass()));
     idx = 1;
   }
 
   // Set up locals for incoming arguments
   ciSignature* sig = method()->signature();
@@ -3182,11 +3464,11 @@
     ciType* type = sig->type_at(i);
     BasicType basic_type = type->basic_type();
     // don't allow T_ARRAY to propagate into locals types
     if (is_reference_type(basic_type)) basic_type = T_OBJECT;
     ValueType* vt = as_ValueType(basic_type);
-    state->store_local(idx, new Local(type, vt, idx, false));
+    state->store_local(idx, new Local(type, vt, idx, false, sig->is_never_null_at(i)));
     idx += type->size();
   }
 
   // lock synchronized method
   if (method()->is_synchronized()) {
diff a/src/hotspot/share/c1/c1_LIR.cpp b/src/hotspot/share/c1/c1_LIR.cpp
--- a/src/hotspot/share/c1/c1_LIR.cpp
+++ b/src/hotspot/share/c1/c1_LIR.cpp
@@ -26,10 +26,11 @@
 #include "c1/c1_InstructionPrinter.hpp"
 #include "c1/c1_LIR.hpp"
 #include "c1/c1_LIRAssembler.hpp"
 #include "c1/c1_ValueStack.hpp"
 #include "ci/ciInstance.hpp"
+#include "ci/ciValueKlass.hpp"
 #include "runtime/sharedRuntime.hpp"
 
 Register LIR_OprDesc::as_register() const {
   return FrameMap::cpu_rnr2reg(cpu_regnr());
 }
@@ -90,10 +91,11 @@
 //---------------------------------------------------
 
 char LIR_OprDesc::type_char(BasicType t) {
   switch (t) {
     case T_ARRAY:
+    case T_VALUETYPE:
       t = T_OBJECT;
     case T_BOOLEAN:
     case T_CHAR:
     case T_FLOAT:
     case T_DOUBLE:
@@ -148,10 +150,11 @@
     case T_INT:
     case T_ADDRESS:
     case T_OBJECT:
     case T_METADATA:
     case T_ARRAY:
+    case T_VALUETYPE:
       assert((kindfield == cpu_register || kindfield == stack_value) &&
              size_field() == single_size, "must match");
       break;
 
     case T_ILLEGAL:
@@ -294,11 +297,11 @@
 
 
 LIR_OpTypeCheck::LIR_OpTypeCheck(LIR_Code code, LIR_Opr result, LIR_Opr object, ciKlass* klass,
                                  LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3,
                                  bool fast_check, CodeEmitInfo* info_for_exception, CodeEmitInfo* info_for_patch,
-                                 CodeStub* stub)
+                                 CodeStub* stub, bool need_null_check)
 
   : LIR_Op(code, result, NULL)
   , _object(object)
   , _array(LIR_OprFact::illegalOpr)
   , _klass(klass)
@@ -310,10 +313,11 @@
   , _info_for_exception(info_for_exception)
   , _stub(stub)
   , _profiled_method(NULL)
   , _profiled_bci(-1)
   , _should_profile(false)
+  , _need_null_check(need_null_check)
 {
   if (code == lir_checkcast) {
     assert(info_for_exception != NULL, "checkcast throws exceptions");
   } else if (code == lir_instanceof) {
     assert(info_for_exception == NULL, "instanceof throws no exceptions");
@@ -337,19 +341,51 @@
   , _info_for_exception(info_for_exception)
   , _stub(NULL)
   , _profiled_method(NULL)
   , _profiled_bci(-1)
   , _should_profile(false)
+  , _need_null_check(true)
 {
   if (code == lir_store_check) {
     _stub = new ArrayStoreExceptionStub(object, info_for_exception);
     assert(info_for_exception != NULL, "store_check throws exceptions");
   } else {
     ShouldNotReachHere();
   }
 }
 
+LIR_OpFlattenedArrayCheck::LIR_OpFlattenedArrayCheck(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub)
+  : LIR_Op(lir_flattened_array_check, LIR_OprFact::illegalOpr, NULL)
+  , _array(array)
+  , _value(value)
+  , _tmp(tmp)
+  , _stub(stub) {}
+
+
+LIR_OpNullFreeArrayCheck::LIR_OpNullFreeArrayCheck(LIR_Opr array, LIR_Opr tmp)
+  : LIR_Op(lir_null_free_array_check, LIR_OprFact::illegalOpr, NULL)
+  , _array(array)
+  , _tmp(tmp) {}
+
+
+LIR_OpSubstitutabilityCheck::LIR_OpSubstitutabilityCheck(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,
+                                                         LIR_Opr tmp1, LIR_Opr tmp2,
+                                                         ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,
+                                                         CodeEmitInfo* info, CodeStub* stub)
+  : LIR_Op(lir_substitutability_check, result, info)
+  , _left(left)
+  , _right(right)
+  , _equal_result(equal_result)
+  , _not_equal_result(not_equal_result)
+  , _tmp1(tmp1)
+  , _tmp2(tmp2)
+  , _left_klass(left_klass)
+  , _right_klass(right_klass)
+  , _left_klass_op(left_klass_op)
+  , _right_klass_op(right_klass_op)
+  , _stub(stub) {}
+
 
 LIR_OpArrayCopy::LIR_OpArrayCopy(LIR_Opr src, LIR_Opr src_pos, LIR_Opr dst, LIR_Opr dst_pos, LIR_Opr length,
                                  LIR_Opr tmp, ciArrayKlass* expected_type, int flags, CodeEmitInfo* info)
   : LIR_Op(lir_arraycopy, LIR_OprFact::illegalOpr, info)
   , _src(src)
@@ -413,10 +449,11 @@
     case lir_membar_release:           // result and info always invalid
     case lir_membar_loadload:          // result and info always invalid
     case lir_membar_storestore:        // result and info always invalid
     case lir_membar_loadstore:         // result and info always invalid
     case lir_membar_storeload:         // result and info always invalid
+    case lir_check_orig_pc:            // result and info always invalid
     case lir_on_spin_wait:
     {
       assert(op->as_Op0() != NULL, "must be");
       assert(op->_info == NULL, "info not used by this instruction");
       assert(op->_result->is_illegal(), "not used");
@@ -793,10 +830,11 @@
 
       if (opLock->_scratch->is_valid())           do_temp(opLock->_scratch);
       assert(opLock->_result->is_illegal(), "unused");
 
       do_stub(opLock->_stub);
+      do_stub(opLock->_throw_imse_stub);
 
       break;
     }
 
 
@@ -829,10 +867,55 @@
       if (opTypeCheck->_result->is_valid())       do_output(opTypeCheck->_result);
                                                   do_stub(opTypeCheck->_stub);
       break;
     }
 
+// LIR_OpFlattenedArrayCheck
+    case lir_flattened_array_check: {
+      assert(op->as_OpFlattenedArrayCheck() != NULL, "must be");
+      LIR_OpFlattenedArrayCheck* opFlattenedArrayCheck = (LIR_OpFlattenedArrayCheck*)op;
+
+      if (opFlattenedArrayCheck->_array->is_valid()) do_input(opFlattenedArrayCheck->_array);
+      if (opFlattenedArrayCheck->_value->is_valid()) do_input(opFlattenedArrayCheck->_value);
+      if (opFlattenedArrayCheck->_tmp->is_valid())   do_temp(opFlattenedArrayCheck->_tmp);
+                                                     do_stub(opFlattenedArrayCheck->_stub);
+
+      break;
+    }
+
+// LIR_OpNullFreeArrayCheck
+    case lir_null_free_array_check: {
+      assert(op->as_OpNullFreeArrayCheck() != NULL, "must be");
+      LIR_OpNullFreeArrayCheck* opNullFreeArrayCheck = (LIR_OpNullFreeArrayCheck*)op;
+
+      if (opNullFreeArrayCheck->_array->is_valid()) do_input(opNullFreeArrayCheck->_array);
+      if (opNullFreeArrayCheck->_tmp->is_valid())   do_temp(opNullFreeArrayCheck->_tmp);
+      break;
+    }
+
+// LIR_OpSubstitutabilityCheck
+    case lir_substitutability_check: {
+      assert(op->as_OpSubstitutabilityCheck() != NULL, "must be");
+      LIR_OpSubstitutabilityCheck* opSubstitutabilityCheck = (LIR_OpSubstitutabilityCheck*)op;
+                                                                do_input(opSubstitutabilityCheck->_left);
+                                                                do_temp (opSubstitutabilityCheck->_left);
+                                                                do_input(opSubstitutabilityCheck->_right);
+                                                                do_temp (opSubstitutabilityCheck->_right);
+                                                                do_input(opSubstitutabilityCheck->_equal_result);
+                                                                do_temp (opSubstitutabilityCheck->_equal_result);
+                                                                do_input(opSubstitutabilityCheck->_not_equal_result);
+                                                                do_temp (opSubstitutabilityCheck->_not_equal_result);
+      if (opSubstitutabilityCheck->_tmp1->is_valid())           do_temp(opSubstitutabilityCheck->_tmp1);
+      if (opSubstitutabilityCheck->_tmp2->is_valid())           do_temp(opSubstitutabilityCheck->_tmp2);
+      if (opSubstitutabilityCheck->_left_klass_op->is_valid())  do_temp(opSubstitutabilityCheck->_left_klass_op);
+      if (opSubstitutabilityCheck->_right_klass_op->is_valid()) do_temp(opSubstitutabilityCheck->_right_klass_op);
+      if (opSubstitutabilityCheck->_result->is_valid())         do_output(opSubstitutabilityCheck->_result);
+                                                                do_info(opSubstitutabilityCheck->_info);
+                                                                do_stub(opSubstitutabilityCheck->_stub);
+      break;
+    }
+
 // LIR_OpCompareAndSwap
     case lir_cas_long:
     case lir_cas_obj:
     case lir_cas_int: {
       assert(op->as_OpCompareAndSwap() != NULL, "must be");
@@ -956,10 +1039,49 @@
 
 void LIR_OpJavaCall::emit_code(LIR_Assembler* masm) {
   masm->emit_call(this);
 }
 
+bool LIR_OpJavaCall::maybe_return_as_fields(ciValueKlass** vk_ret) const {
+  if (InlineTypeReturnedAsFields) {
+    if (method()->signature()->maybe_returns_never_null()) {
+      ciType* return_type = method()->return_type();
+      if (return_type->is_valuetype()) {
+        ciValueKlass* vk = return_type->as_value_klass();
+        if (vk->can_be_returned_as_fields()) {
+          if (vk_ret != NULL) {
+            *vk_ret = vk;
+          }
+          return true;
+        }
+      } else {
+        assert(return_type->is_instance_klass() && !return_type->as_instance_klass()->is_loaded(), "must be");
+        if (vk_ret != NULL) {
+          *vk_ret = NULL;
+        }
+        return true;
+      }
+    } else if (is_method_handle_invoke()) {
+      BasicType bt = method()->return_type()->basic_type();
+      if (bt == T_OBJECT || bt == T_VALUETYPE) {
+        // A value type might be returned from the call but we don't know its
+        // type. Either we get a buffered value (and nothing needs to be done)
+        // or one of the values being returned is the klass of the value type
+        // (RAX on x64, with LSB set to 1) and we need to allocate a value
+        // type instance of that type and initialize it with other values being
+        // returned (in other registers).
+        // type.
+        if (vk_ret != NULL) {
+          *vk_ret = NULL;
+        }
+        return true;
+      }
+    }
+  }
+  return false;
+}
+
 void LIR_OpRTCall::emit_code(LIR_Assembler* masm) {
   masm->emit_rtcall(this);
 }
 
 void LIR_OpLabel::emit_code(LIR_Assembler* masm) {
@@ -1016,10 +1138,28 @@
   if (stub()) {
     masm->append_code_stub(stub());
   }
 }
 
+void LIR_OpFlattenedArrayCheck::emit_code(LIR_Assembler* masm) {
+  masm->emit_opFlattenedArrayCheck(this);
+  if (stub() != NULL) {
+    masm->append_code_stub(stub());
+  }
+}
+
+void LIR_OpNullFreeArrayCheck::emit_code(LIR_Assembler* masm) {
+  masm->emit_opNullFreeArrayCheck(this);
+}
+
+void LIR_OpSubstitutabilityCheck::emit_code(LIR_Assembler* masm) {
+  masm->emit_opSubstitutabilityCheck(this);
+  if (stub() != NULL) {
+    masm->append_code_stub(stub());
+  }
+}
+
 void LIR_OpCompareAndSwap::emit_code(LIR_Assembler* masm) {
   masm->emit_compare_and_swap(this);
 }
 
 void LIR_Op3::emit_code(LIR_Assembler* masm) {
@@ -1029,10 +1169,13 @@
 void LIR_OpLock::emit_code(LIR_Assembler* masm) {
   masm->emit_lock(this);
   if (stub()) {
     masm->append_code_stub(stub());
   }
+  if (throw_imse_stub()) {
+    masm->append_code_stub(throw_imse_stub());
+  }
 }
 
 #ifdef ASSERT
 void LIR_OpAssert::emit_code(LIR_Assembler* masm) {
   masm->emit_assert(this);
@@ -1330,19 +1473,20 @@
                      left,
                      right,
                      dst));
 }
 
-void LIR_List::lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info) {
+void LIR_List::lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info, CodeStub* throw_imse_stub) {
   append(new LIR_OpLock(
                     lir_lock,
                     hdr,
                     obj,
                     lock,
                     scratch,
                     stub,
-                    info));
+                    info,
+                    throw_imse_stub));
 }
 
 void LIR_List::unlock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub) {
   append(new LIR_OpLock(
                     lir_unlock,
@@ -1363,13 +1507,17 @@
 
 
 void LIR_List::checkcast (LIR_Opr result, LIR_Opr object, ciKlass* klass,
                           LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3, bool fast_check,
                           CodeEmitInfo* info_for_exception, CodeEmitInfo* info_for_patch, CodeStub* stub,
-                          ciMethod* profiled_method, int profiled_bci) {
+                          ciMethod* profiled_method, int profiled_bci, bool is_never_null) {
+  // If klass is non-nullable,  LIRGenerator::do_CheckCast has already performed null-check
+  // on the object.
+  bool need_null_check = !is_never_null;
   LIR_OpTypeCheck* c = new LIR_OpTypeCheck(lir_checkcast, result, object, klass,
-                                           tmp1, tmp2, tmp3, fast_check, info_for_exception, info_for_patch, stub);
+                                           tmp1, tmp2, tmp3, fast_check, info_for_exception, info_for_patch, stub,
+                                           need_null_check);
   if (profiled_method != NULL) {
     c->set_profiled_method(profiled_method);
     c->set_profiled_bci(profiled_bci);
     c->set_should_profile(true);
   }
@@ -1387,10 +1535,11 @@
 }
 
 
 void LIR_List::store_check(LIR_Opr object, LIR_Opr array, LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3,
                            CodeEmitInfo* info_for_exception, ciMethod* profiled_method, int profiled_bci) {
+  // FIXME -- if the types of the array and/or the object are known statically, we can avoid loading the klass
   LIR_OpTypeCheck* c = new LIR_OpTypeCheck(lir_store_check, object, array, tmp1, tmp2, tmp3, info_for_exception);
   if (profiled_method != NULL) {
     c->set_profiled_method(profiled_method);
     c->set_profiled_bci(profiled_bci);
     c->set_should_profile(true);
@@ -1408,10 +1557,31 @@
     // Emit an implicit null check
     append(new LIR_Op1(lir_null_check, opr, info));
   }
 }
 
+void LIR_List::check_flattened_array(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub) {
+  LIR_OpFlattenedArrayCheck* c = new LIR_OpFlattenedArrayCheck(array, value, tmp, stub);
+  append(c);
+}
+
+void LIR_List::check_null_free_array(LIR_Opr array, LIR_Opr tmp) {
+  LIR_OpNullFreeArrayCheck* c = new LIR_OpNullFreeArrayCheck(array, tmp);
+  append(c);
+}
+
+void LIR_List::substitutability_check(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,
+                                      LIR_Opr tmp1, LIR_Opr tmp2,
+                                      ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,
+                                      CodeEmitInfo* info, CodeStub* stub) {
+  LIR_OpSubstitutabilityCheck* c = new LIR_OpSubstitutabilityCheck(result, left, right, equal_result, not_equal_result,
+                                                                   tmp1, tmp2,
+                                                                   left_klass, right_klass, left_klass_op, right_klass_op,
+                                                                   info, stub);
+  append(c);
+}
+
 void LIR_List::cas_long(LIR_Opr addr, LIR_Opr cmp_value, LIR_Opr new_value,
                         LIR_Opr t1, LIR_Opr t2, LIR_Opr result) {
   append(new LIR_OpCompareAndSwap(lir_cas_long, addr, cmp_value, new_value, t1, t2, result));
 }
 
@@ -1625,10 +1795,11 @@
      case lir_std_entry:             s = "std_entry";     break;
      case lir_osr_entry:             s = "osr_entry";     break;
      case lir_fpop_raw:              s = "fpop_raw";      break;
      case lir_breakpoint:            s = "breakpoint";    break;
      case lir_get_thread:            s = "get_thread";    break;
+     case lir_check_orig_pc:         s = "check_orig_pc"; break;
      // LIR_Op1
      case lir_fxch:                  s = "fxch";          break;
      case lir_fld:                   s = "fld";           break;
      case lir_push:                  s = "push";          break;
      case lir_pop:                   s = "pop";           break;
@@ -1693,10 +1864,16 @@
      case lir_delay_slot:            s = "delay";         break;
      // LIR_OpTypeCheck
      case lir_instanceof:            s = "instanceof";    break;
      case lir_checkcast:             s = "checkcast";     break;
      case lir_store_check:           s = "store_check";   break;
+     // LIR_OpFlattenedArrayCheck
+     case lir_flattened_array_check: s = "flattened_array_check"; break;
+     // LIR_OpNullFreeArrayCheck
+     case lir_null_free_array_check: s = "null_free_array_check"; break;
+     // LIR_OpSubstitutabilityCheck
+     case lir_substitutability_check: s = "substitutability_check"; break;
      // LIR_OpCompareAndSwap
      case lir_cas_long:              s = "cas_long";      break;
      case lir_cas_obj:               s = "cas_obj";      break;
      case lir_cas_int:               s = "cas_int";      break;
      // LIR_OpProfileCall
@@ -1938,10 +2115,40 @@
   tmp3()->print(out);                    out->print(" ");
   result_opr()->print(out);              out->print(" ");
   if (info_for_exception() != NULL) out->print(" [bci:%d]", info_for_exception()->stack()->bci());
 }
 
+void LIR_OpFlattenedArrayCheck::print_instr(outputStream* out) const {
+  array()->print(out);                   out->print(" ");
+  value()->print(out);                   out->print(" ");
+  tmp()->print(out);                     out->print(" ");
+  if (stub() != NULL) {
+    out->print("[label:" INTPTR_FORMAT "]", p2i(stub()->entry()));
+  }
+}
+
+void LIR_OpNullFreeArrayCheck::print_instr(outputStream* out) const {
+  array()->print(out);                   out->print(" ");
+  tmp()->print(out);                     out->print(" ");
+}
+
+void LIR_OpSubstitutabilityCheck::print_instr(outputStream* out) const {
+  result_opr()->print(out);              out->print(" ");
+  left()->print(out);                    out->print(" ");
+  right()->print(out);                   out->print(" ");
+  equal_result()->print(out);            out->print(" ");
+  not_equal_result()->print(out);        out->print(" ");
+  tmp1()->print(out);                    out->print(" ");
+  tmp2()->print(out);                    out->print(" ");
+  left_klass()->print(out);              out->print(" ");
+  right_klass()->print(out);             out->print(" ");
+  left_klass_op()->print(out);           out->print(" ");
+  right_klass_op()->print(out);          out->print(" ");
+  if (stub() != NULL) {
+    out->print("[label:" INTPTR_FORMAT "]", p2i(stub()->entry()));
+  }
+}
 
 // LIR_Op3
 void LIR_Op3::print_instr(outputStream* out) const {
   in_opr1()->print(out);    out->print(" ");
   in_opr2()->print(out);    out->print(" ");
diff a/src/hotspot/share/c1/c1_LIR.hpp b/src/hotspot/share/c1/c1_LIR.hpp
--- a/src/hotspot/share/c1/c1_LIR.hpp
+++ b/src/hotspot/share/c1/c1_LIR.hpp
@@ -314,10 +314,11 @@
       case T_BYTE:
       case T_SHORT:
       case T_INT:
       case T_ADDRESS:
       case T_OBJECT:
+      case T_VALUETYPE:
       case T_ARRAY:
       case T_METADATA:
         return single_size;
         break;
 
@@ -464,10 +465,11 @@
   case T_INT:      return LIR_OprDesc::int_type;
   case T_LONG:     return LIR_OprDesc::long_type;
   case T_FLOAT:    return LIR_OprDesc::float_type;
   case T_DOUBLE:   return LIR_OprDesc::double_type;
   case T_OBJECT:
+  case T_VALUETYPE:
   case T_ARRAY:    return LIR_OprDesc::object_type;
   case T_ADDRESS:  return LIR_OprDesc::address_type;
   case T_METADATA: return LIR_OprDesc::metadata_type;
   case T_ILLEGAL:  // fall through
   default: ShouldNotReachHere(); return LIR_OprDesc::unknown_type;
@@ -649,10 +651,11 @@
 
   static LIR_Opr virtual_register(int index, BasicType type) {
     LIR_Opr res;
     switch (type) {
       case T_OBJECT: // fall through
+      case T_VALUETYPE: // fall through
       case T_ARRAY:
         res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift)  |
                                             LIR_OprDesc::object_type  |
                                             LIR_OprDesc::cpu_register |
                                             LIR_OprDesc::single_size  |
@@ -754,10 +757,11 @@
   // the index is platform independent; a double stack useing indeces 2 and 3 has always
   // index 2.
   static LIR_Opr stack(int index, BasicType type) {
     LIR_Opr res;
     switch (type) {
+      case T_VALUETYPE: // fall through
       case T_OBJECT: // fall through
       case T_ARRAY:
         res = (LIR_Opr)(intptr_t)((index << LIR_OprDesc::data_shift) |
                                   LIR_OprDesc::object_type           |
                                   LIR_OprDesc::stack_value           |
@@ -866,10 +870,13 @@
 class      LIR_OpRTCall;
 class    LIR_OpArrayCopy;
 class    LIR_OpUpdateCRC32;
 class    LIR_OpLock;
 class    LIR_OpTypeCheck;
+class    LIR_OpFlattenedArrayCheck;
+class    LIR_OpNullFreeArrayCheck;
+class    LIR_OpSubstitutabilityCheck;
 class    LIR_OpCompareAndSwap;
 class    LIR_OpProfileCall;
 class    LIR_OpProfileType;
 #ifdef ASSERT
 class    LIR_OpAssert;
@@ -894,10 +901,11 @@
       , lir_membar_storestore
       , lir_membar_loadstore
       , lir_membar_storeload
       , lir_get_thread
       , lir_on_spin_wait
+      , lir_check_orig_pc
   , end_op0
   , begin_op1
       , lir_fxch
       , lir_fld
       , lir_push
@@ -973,10 +981,19 @@
   , begin_opTypeCheck
     , lir_instanceof
     , lir_checkcast
     , lir_store_check
   , end_opTypeCheck
+  , begin_opFlattenedArrayCheck
+    , lir_flattened_array_check
+  , end_opFlattenedArrayCheck
+  , begin_opNullFreeArrayCheck
+    , lir_null_free_array_check
+  , end_opNullFreeArrayCheck
+  , begin_opSubstitutabilityCheck
+    , lir_substitutability_check
+  , end_opSubstitutabilityCheck
   , begin_opCompareAndSwap
     , lir_cas_long
     , lir_cas_obj
     , lir_cas_int
   , end_opCompareAndSwap
@@ -1123,10 +1140,13 @@
   virtual LIR_Op2* as_Op2() { return NULL; }
   virtual LIR_Op3* as_Op3() { return NULL; }
   virtual LIR_OpArrayCopy* as_OpArrayCopy() { return NULL; }
   virtual LIR_OpUpdateCRC32* as_OpUpdateCRC32() { return NULL; }
   virtual LIR_OpTypeCheck* as_OpTypeCheck() { return NULL; }
+  virtual LIR_OpFlattenedArrayCheck* as_OpFlattenedArrayCheck() { return NULL; }
+  virtual LIR_OpNullFreeArrayCheck* as_OpNullFreeArrayCheck() { return NULL; }
+  virtual LIR_OpSubstitutabilityCheck* as_OpSubstitutabilityCheck() { return NULL; }
   virtual LIR_OpCompareAndSwap* as_OpCompareAndSwap() { return NULL; }
   virtual LIR_OpProfileCall* as_OpProfileCall() { return NULL; }
   virtual LIR_OpProfileType* as_OpProfileType() { return NULL; }
 #ifdef ASSERT
   virtual LIR_OpAssert* as_OpAssert() { return NULL; }
@@ -1203,10 +1223,12 @@
   }
 
   virtual void emit_code(LIR_Assembler* masm);
   virtual LIR_OpJavaCall* as_OpJavaCall() { return this; }
   virtual void print_instr(outputStream* out) const PRODUCT_RETURN;
+
+  bool maybe_return_as_fields(ciValueKlass** vk = NULL) const;
 };
 
 // --------------------------------------------------
 // LIR_OpLabel
 // --------------------------------------------------
@@ -1254,11 +1276,14 @@
     type_check             = 1 << 7,
     overlapping            = 1 << 8,
     unaligned              = 1 << 9,
     src_objarray           = 1 << 10,
     dst_objarray           = 1 << 11,
-    all_flags              = (1 << 12) - 1
+    always_slow_path       = 1 << 12,
+    src_valuetype_check    = 1 << 13,
+    dst_valuetype_check    = 1 << 14,
+    all_flags              = (1 << 15) - 1
   };
 
   LIR_OpArrayCopy(LIR_Opr src, LIR_Opr src_pos, LIR_Opr dst, LIR_Opr dst_pos, LIR_Opr length, LIR_Opr tmp,
                   ciArrayKlass* expected_type, int flags, CodeEmitInfo* info);
 
@@ -1547,15 +1572,16 @@
   CodeEmitInfo* _info_for_exception;
   CodeStub*     _stub;
   ciMethod*     _profiled_method;
   int           _profiled_bci;
   bool          _should_profile;
+  bool          _need_null_check;
 
 public:
   LIR_OpTypeCheck(LIR_Code code, LIR_Opr result, LIR_Opr object, ciKlass* klass,
                   LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3, bool fast_check,
-                  CodeEmitInfo* info_for_exception, CodeEmitInfo* info_for_patch, CodeStub* stub);
+                  CodeEmitInfo* info_for_exception, CodeEmitInfo* info_for_patch, CodeStub* stub, bool need_null_check = true);
   LIR_OpTypeCheck(LIR_Code code, LIR_Opr object, LIR_Opr array,
                   LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3, CodeEmitInfo* info_for_exception);
 
   LIR_Opr object() const                         { return _object;         }
   LIR_Opr array() const                          { assert(code() == lir_store_check, "not valid"); return _array;         }
@@ -1573,17 +1599,93 @@
   void set_profiled_bci(int bci)                 { _profiled_bci = bci;       }
   void set_should_profile(bool b)                { _should_profile = b;       }
   ciMethod* profiled_method() const              { return _profiled_method;   }
   int       profiled_bci() const                 { return _profiled_bci;      }
   bool      should_profile() const               { return _should_profile;    }
-
+  bool      need_null_check() const              { return _need_null_check;   }
   virtual bool is_patching() { return _info_for_patch != NULL; }
   virtual void emit_code(LIR_Assembler* masm);
   virtual LIR_OpTypeCheck* as_OpTypeCheck() { return this; }
   void print_instr(outputStream* out) const PRODUCT_RETURN;
 };
 
+// LIR_OpFlattenedArrayCheck
+class LIR_OpFlattenedArrayCheck: public LIR_Op {
+ friend class LIR_OpVisitState;
+
+ private:
+  LIR_Opr       _array;
+  LIR_Opr       _value;
+  LIR_Opr       _tmp;
+  CodeStub*     _stub;
+public:
+  LIR_OpFlattenedArrayCheck(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub);
+  LIR_Opr array() const                          { return _array;         }
+  LIR_Opr value() const                          { return _value;         }
+  LIR_Opr tmp() const                            { return _tmp;           }
+  CodeStub* stub() const                         { return _stub;          }
+
+  virtual void emit_code(LIR_Assembler* masm);
+  virtual LIR_OpFlattenedArrayCheck* as_OpFlattenedArrayCheck() { return this; }
+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;
+};
+
+// LIR_OpNullFreeArrayCheck
+class LIR_OpNullFreeArrayCheck: public LIR_Op {
+ friend class LIR_OpVisitState;
+
+ private:
+  LIR_Opr       _array;
+  LIR_Opr       _tmp;
+public:
+  LIR_OpNullFreeArrayCheck(LIR_Opr array, LIR_Opr tmp);
+  LIR_Opr array() const                          { return _array;         }
+  LIR_Opr tmp() const                            { return _tmp;           }
+
+  virtual void emit_code(LIR_Assembler* masm);
+  virtual LIR_OpNullFreeArrayCheck* as_OpNullFreeArrayCheck() { return this; }
+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;
+};
+
+class LIR_OpSubstitutabilityCheck: public LIR_Op {
+ friend class LIR_OpVisitState;
+
+ private:
+  LIR_Opr       _left;
+  LIR_Opr       _right;
+  LIR_Opr       _equal_result;
+  LIR_Opr       _not_equal_result;
+  LIR_Opr       _tmp1;
+  LIR_Opr       _tmp2;
+  ciKlass*      _left_klass;
+  ciKlass*      _right_klass;
+  LIR_Opr       _left_klass_op;
+  LIR_Opr       _right_klass_op;
+  CodeStub*     _stub;
+public:
+  LIR_OpSubstitutabilityCheck(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,
+                              LIR_Opr tmp1, LIR_Opr tmp2,
+                              ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,
+                              CodeEmitInfo* info, CodeStub* stub);
+
+  LIR_Opr left() const             { return _left; }
+  LIR_Opr right() const            { return _right; }
+  LIR_Opr equal_result() const     { return _equal_result; }
+  LIR_Opr not_equal_result() const { return _not_equal_result; }
+  LIR_Opr tmp1() const             { return _tmp1; }
+  LIR_Opr tmp2() const             { return _tmp2; }
+  ciKlass* left_klass() const      { return _left_klass; }
+  ciKlass* right_klass() const     { return _right_klass; }
+  LIR_Opr left_klass_op() const    { return _left_klass_op; }
+  LIR_Opr right_klass_op() const   { return _right_klass_op; }
+  CodeStub* stub() const           { return _stub; }
+
+  virtual void emit_code(LIR_Assembler* masm);
+  virtual LIR_OpSubstitutabilityCheck* as_OpSubstitutabilityCheck() { return this; }
+  virtual void print_instr(outputStream* out) const PRODUCT_RETURN;
+};
+
 // LIR_Op2
 class LIR_Op2: public LIR_Op {
  friend class LIR_OpVisitState;
 
   int  _fpu_stack_size; // for sin/cos implementation on Intel
@@ -1772,24 +1874,27 @@
   LIR_Opr _hdr;
   LIR_Opr _obj;
   LIR_Opr _lock;
   LIR_Opr _scratch;
   CodeStub* _stub;
+  CodeStub* _throw_imse_stub;
  public:
-  LIR_OpLock(LIR_Code code, LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info)
+  LIR_OpLock(LIR_Code code, LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info, CodeStub* throw_imse_stub=NULL)
     : LIR_Op(code, LIR_OprFact::illegalOpr, info)
     , _hdr(hdr)
     , _obj(obj)
     , _lock(lock)
     , _scratch(scratch)
-    , _stub(stub)                      {}
+    , _stub(stub)
+    , _throw_imse_stub(throw_imse_stub)                    {}
 
   LIR_Opr hdr_opr() const                        { return _hdr; }
   LIR_Opr obj_opr() const                        { return _obj; }
   LIR_Opr lock_opr() const                       { return _lock; }
   LIR_Opr scratch_opr() const                    { return _scratch; }
   CodeStub* stub() const                         { return _stub; }
+  CodeStub* throw_imse_stub() const              { return _throw_imse_stub; }
 
   virtual void emit_code(LIR_Assembler* masm);
   virtual LIR_OpLock* as_OpLock() { return this; }
   void print_instr(outputStream* out) const PRODUCT_RETURN;
 };
@@ -2215,25 +2320,31 @@
     append(new LIR_OpRTCall(routine, tmp, result, arguments, info));
   }
 
   void load_stack_address_monitor(int monitor_ix, LIR_Opr dst)  { append(new LIR_Op1(lir_monaddr, LIR_OprFact::intConst(monitor_ix), dst)); }
   void unlock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub);
-  void lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info);
+  void lock_object(LIR_Opr hdr, LIR_Opr obj, LIR_Opr lock, LIR_Opr scratch, CodeStub* stub, CodeEmitInfo* info, CodeStub* throw_imse_stub=NULL);
 
   void breakpoint()                                                  { append(new LIR_Op0(lir_breakpoint)); }
 
   void arraycopy(LIR_Opr src, LIR_Opr src_pos, LIR_Opr dst, LIR_Opr dst_pos, LIR_Opr length, LIR_Opr tmp, ciArrayKlass* expected_type, int flags, CodeEmitInfo* info) { append(new LIR_OpArrayCopy(src, src_pos, dst, dst_pos, length, tmp, expected_type, flags, info)); }
 
   void update_crc32(LIR_Opr crc, LIR_Opr val, LIR_Opr res)  { append(new LIR_OpUpdateCRC32(crc, val, res)); }
 
   void instanceof(LIR_Opr result, LIR_Opr object, ciKlass* klass, LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3, bool fast_check, CodeEmitInfo* info_for_patch, ciMethod* profiled_method, int profiled_bci);
   void store_check(LIR_Opr object, LIR_Opr array, LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3, CodeEmitInfo* info_for_exception, ciMethod* profiled_method, int profiled_bci);
+  void check_flattened_array(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub);
+  void check_null_free_array(LIR_Opr array, LIR_Opr tmp);
+  void substitutability_check(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,
+                              LIR_Opr tmp1, LIR_Opr tmp2,
+                              ciKlass* left_klass, ciKlass* right_klass, LIR_Opr left_klass_op, LIR_Opr right_klass_op,
+                              CodeEmitInfo* info, CodeStub* stub);
 
   void checkcast (LIR_Opr result, LIR_Opr object, ciKlass* klass,
                   LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3, bool fast_check,
                   CodeEmitInfo* info_for_exception, CodeEmitInfo* info_for_patch, CodeStub* stub,
-                  ciMethod* profiled_method, int profiled_bci);
+                  ciMethod* profiled_method, int profiled_bci, bool is_never_null);
   // MethodData* profiling
   void profile_call(ciMethod* method, int bci, ciMethod* callee, LIR_Opr mdo, LIR_Opr recv, LIR_Opr t1, ciKlass* cha_klass) {
     append(new LIR_OpProfileCall(method, bci, callee, mdo, recv, t1, cha_klass));
   }
   void profile_type(LIR_Address* mdp, LIR_Opr obj, ciKlass* exact_klass, intptr_t current_klass, LIR_Opr tmp, bool not_null, bool no_conflict) {
diff a/src/hotspot/share/c1/c1_LIRAssembler.cpp b/src/hotspot/share/c1/c1_LIRAssembler.cpp
--- a/src/hotspot/share/c1/c1_LIRAssembler.cpp
+++ b/src/hotspot/share/c1/c1_LIRAssembler.cpp
@@ -29,12 +29,14 @@
 #include "c1/c1_InstructionPrinter.hpp"
 #include "c1/c1_LIRAssembler.hpp"
 #include "c1/c1_MacroAssembler.hpp"
 #include "c1/c1_ValueStack.hpp"
 #include "ci/ciInstance.hpp"
+#include "ci/ciValueKlass.hpp"
 #include "gc/shared/barrierSet.hpp"
 #include "runtime/os.hpp"
+#include "runtime/sharedRuntime.hpp"
 
 void LIR_Assembler::patching_epilog(PatchingStub* patch, LIR_PatchCode patch_code, Register obj, CodeEmitInfo* info) {
   // We must have enough patching space so that call can be inserted.
   // We cannot use fat nops here, since the concurrent code rewrite may transiently
   // create the illegal instruction sequence.
@@ -57,10 +59,11 @@
         ShouldNotReachHere();
     }
   } else if (patch->id() == PatchingStub::load_klass_id) {
     switch (code) {
       case Bytecodes::_new:
+      case Bytecodes::_defaultvalue:
       case Bytecodes::_anewarray:
       case Bytecodes::_multianewarray:
       case Bytecodes::_instanceof:
       case Bytecodes::_checkcast:
         break;
@@ -113,10 +116,11 @@
 
 LIR_Assembler::~LIR_Assembler() {
   // The unwind handler label may be unnbound if this destructor is invoked because of a bail-out.
   // Reset it here to avoid an assertion.
   _unwind_handler_entry.reset();
+  _verified_value_entry.reset();
 }
 
 
 void LIR_Assembler::check_codespace() {
   CodeSection* cs = _masm->code_section();
@@ -334,13 +338,13 @@
     compilation()->add_exception_handlers_for_pco(pc_offset, info->exception_handlers());
   }
 }
 
 
-void LIR_Assembler::add_call_info(int pc_offset, CodeEmitInfo* cinfo) {
+void LIR_Assembler::add_call_info(int pc_offset, CodeEmitInfo* cinfo, bool maybe_return_as_fields) {
   flush_debug_info(pc_offset);
-  cinfo->record_debug_info(compilation()->debug_info_recorder(), pc_offset);
+  cinfo->record_debug_info(compilation()->debug_info_recorder(), pc_offset, maybe_return_as_fields);
   if (cinfo->exception_handlers() != NULL) {
     compilation()->add_exception_handlers_for_pco(pc_offset, cinfo->exception_handlers());
   }
 }
 
@@ -479,10 +483,16 @@
   // Record if this method has MethodHandle invokes.
   if (op->is_method_handle_invoke()) {
     compilation()->set_has_method_handle_invokes(true);
   }
 
+  ciValueKlass* vk;
+  if (op->maybe_return_as_fields(&vk)) {
+    int offset = store_value_type_fields_to_buf(vk);
+    add_call_info(offset, op->info(), true);
+  }
+
 #if defined(IA32) && defined(TIERED)
   // C2 leave fpu stack dirty clean it
   if (UseSSE < 2) {
     int i;
     for ( i = 1; i <= 7 ; i++ ) {
@@ -580,10 +590,145 @@
       Unimplemented();
       break;
   }
 }
 
+void LIR_Assembler::add_scalarized_entry_info(int pc_offset) {
+  flush_debug_info(pc_offset);
+  DebugInformationRecorder* debug_info = compilation()->debug_info_recorder();
+  // The VEP and VVEP(RO) of a C1-compiled method call buffer_value_args_xxx()
+  // before doing any argument shuffling. This call may cause GC. When GC happens,
+  // all the parameters are still as passed by the caller, so we just use
+  // map->set_include_argument_oops() inside frame::sender_for_compiled_frame(RegisterMap* map).
+  // There's no need to build a GC map here.
+  OopMap* oop_map = new OopMap(0, 0);
+  debug_info->add_safepoint(pc_offset, oop_map);
+  DebugToken* locvals = debug_info->create_scope_values(NULL); // FIXME is this needed (for Java debugging to work properly??)
+  DebugToken* expvals = debug_info->create_scope_values(NULL); // FIXME is this needed (for Java debugging to work properly??)
+  DebugToken* monvals = debug_info->create_monitor_values(NULL); // FIXME: need testing with synchronized method
+  bool reexecute = false;
+  bool return_oop = false; // This flag will be ignored since it used only for C2 with escape analysis.
+  bool rethrow_exception = false;
+  bool is_method_handle_invoke = false;
+  debug_info->describe_scope(pc_offset, methodHandle(), method(), 0, reexecute, rethrow_exception, is_method_handle_invoke, return_oop, false, locvals, expvals, monvals);
+  debug_info->end_safepoint(pc_offset);
+}
+
+// The entries points of C1-compiled methods can have the following types:
+// (1) Methods with no value args
+// (2) Methods with value receiver but no value args
+//     VVEP_RO is the same as VVEP
+// (3) Methods with non-value receiver and some value args
+//     VVEP_RO is the same as VEP
+// (4) Methods with value receiver and other value args
+//     Separate VEP, VVEP and VVEP_RO
+//
+// (1)               (2)                 (3)                    (4)
+// UEP/UVEP:         VEP:                UEP:                   UEP:
+//   check_icache      pack receiver       check_icache           check_icache
+// VEP/VVEP/VVEP_RO    jump to VVEP      VEP/VVEP_RO:           VVEP_RO:
+//   body            UEP/UVEP:             pack value args        pack value args (except receiver)
+//                     check_icache        jump to VVEP           jump to VVEP
+//                   VVEP/VVEP_RO        UVEP:                  VEP:
+//                     body                check_icache           pack all value args
+//                                       VVEP:                    jump to VVEP
+//                                         body                 UVEP:
+//                                                                check_icache
+//                                                              VVEP:
+//                                                                body
+void LIR_Assembler::emit_std_entries() {
+  offsets()->set_value(CodeOffsets::OSR_Entry, _masm->offset());
+
+  _masm->align(CodeEntryAlignment);
+  const CompiledEntrySignature* ces = compilation()->compiled_entry_signature();
+  if (ces->has_scalarized_args()) {
+    assert(InlineTypePassFieldsAsArgs && method()->get_Method()->has_scalarized_args(), "must be");
+    CodeOffsets::Entries ro_entry_type = ces->c1_value_ro_entry_type();
+
+    // UEP: check icache and fall-through
+    if (ro_entry_type != CodeOffsets::Verified_Value_Entry) {
+      offsets()->set_value(CodeOffsets::Entry, _masm->offset());
+      if (needs_icache(method())) {
+        check_icache();
+      }
+    }
+
+    // VVEP_RO: pack all value parameters, except the receiver
+    if (ro_entry_type == CodeOffsets::Verified_Value_Entry_RO) {
+      emit_std_entry(CodeOffsets::Verified_Value_Entry_RO, ces);
+    }
+
+    // VEP: pack all value parameters
+    _masm->align(CodeEntryAlignment);
+    emit_std_entry(CodeOffsets::Verified_Entry, ces);
+
+    // UVEP: check icache and fall-through
+    _masm->align(CodeEntryAlignment);
+    offsets()->set_value(CodeOffsets::Value_Entry, _masm->offset());
+    if (ro_entry_type == CodeOffsets::Verified_Value_Entry) {
+      // Special case if we have VVEP == VVEP(RO):
+      // this means UVEP (called by C1) == UEP (called by C2).
+      offsets()->set_value(CodeOffsets::Entry, _masm->offset());
+    }
+    if (needs_icache(method())) {
+      check_icache();
+    }
+
+    // VVEP: all value parameters are passed as refs - no packing.
+    emit_std_entry(CodeOffsets::Verified_Value_Entry, NULL);
+
+    if (ro_entry_type != CodeOffsets::Verified_Value_Entry_RO) {
+      // The VVEP(RO) is the same as VEP or VVEP
+      assert(ro_entry_type == CodeOffsets::Verified_Entry ||
+             ro_entry_type == CodeOffsets::Verified_Value_Entry, "must be");
+      offsets()->set_value(CodeOffsets::Verified_Value_Entry_RO,
+                           offsets()->value(ro_entry_type));
+    }
+  } else {
+    // All 3 entries are the same (no value-type packing)
+    offsets()->set_value(CodeOffsets::Entry, _masm->offset());
+    offsets()->set_value(CodeOffsets::Value_Entry, _masm->offset());
+    if (needs_icache(method())) {
+      check_icache();
+    }
+    emit_std_entry(CodeOffsets::Verified_Value_Entry, NULL);
+    offsets()->set_value(CodeOffsets::Verified_Entry, offsets()->value(CodeOffsets::Verified_Value_Entry));
+    offsets()->set_value(CodeOffsets::Verified_Value_Entry_RO, offsets()->value(CodeOffsets::Verified_Value_Entry));
+  }
+}
+
+void LIR_Assembler::emit_std_entry(CodeOffsets::Entries entry, const CompiledEntrySignature* ces) {
+  offsets()->set_value(entry, _masm->offset());
+  _masm->verified_entry();
+  switch (entry) {
+  case CodeOffsets::Verified_Entry: {
+    if (needs_clinit_barrier_on_entry(method())) {
+      clinit_barrier(method());
+    }
+    int rt_call_offset = _masm->verified_entry(ces, initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()->sp_offset_for_orig_pc()), _verified_value_entry);
+    add_scalarized_entry_info(rt_call_offset);
+    break;
+  }
+  case CodeOffsets::Verified_Value_Entry_RO: {
+    assert(!needs_clinit_barrier_on_entry(method()), "can't be static");
+    int rt_call_offset = _masm->verified_value_ro_entry(ces, initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()->sp_offset_for_orig_pc()), _verified_value_entry);
+    add_scalarized_entry_info(rt_call_offset);
+    break;
+  }
+  case CodeOffsets::Verified_Value_Entry: {
+    if (needs_clinit_barrier_on_entry(method())) {
+      clinit_barrier(method());
+    }
+    build_frame();
+    offsets()->set_value(CodeOffsets::Frame_Complete, _masm->offset());
+    break;
+  }
+  default:
+    ShouldNotReachHere();
+    break;
+  }
+}
 
 void LIR_Assembler::emit_op0(LIR_Op0* op) {
   switch (op->code()) {
     case lir_nop:
       assert(op->info() == NULL, "not supported");
@@ -593,23 +738,11 @@
     case lir_label:
       Unimplemented();
       break;
 
     case lir_std_entry:
-      // init offsets
-      offsets()->set_value(CodeOffsets::OSR_Entry, _masm->offset());
-      _masm->align(CodeEntryAlignment);
-      if (needs_icache(compilation()->method())) {
-        check_icache();
-      }
-      offsets()->set_value(CodeOffsets::Verified_Entry, _masm->offset());
-      _masm->verified_entry();
-      if (needs_clinit_barrier_on_entry(compilation()->method())) {
-        clinit_barrier(compilation()->method());
-      }
-      build_frame();
-      offsets()->set_value(CodeOffsets::Frame_Complete, _masm->offset());
+      emit_std_entries();
       break;
 
     case lir_osr_entry:
       offsets()->set_value(CodeOffsets::OSR_Entry, _masm->offset());
       osr_entry();
@@ -659,10 +792,14 @@
 
     case lir_on_spin_wait:
       on_spin_wait();
       break;
 
+    case lir_check_orig_pc:
+      check_orig_pc();
+      break;
+
     default:
       ShouldNotReachHere();
       break;
   }
 }
@@ -752,11 +889,12 @@
   }
 }
 
 
 void LIR_Assembler::build_frame() {
-  _masm->build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());
+  _masm->build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), in_bytes(frame_map()->sp_offset_for_orig_pc()),
+                     needs_stack_repair(), method()->has_scalarized_args(), &_verified_value_entry);
 }
 
 
 void LIR_Assembler::roundfp_op(LIR_Opr src, LIR_Opr tmp, LIR_Opr dest, bool pop_fpu_stack) {
   assert(strict_fp_requires_explicit_rounding, "not required");
diff a/src/hotspot/share/c1/c1_LinearScan.cpp b/src/hotspot/share/c1/c1_LinearScan.cpp
--- a/src/hotspot/share/c1/c1_LinearScan.cpp
+++ b/src/hotspot/share/c1/c1_LinearScan.cpp
@@ -59,13 +59,13 @@
 
 #endif
 
 // Map BasicType to spill size in 32-bit words, matching VMReg's notion of words
 #ifdef _LP64
-static int type2spill_size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2,  1, 2, 1, -1};
+static int type2spill_size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 2,  1, 2, 1, 2, -1};
 #else
-static int type2spill_size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, -1, 1, 1, -1};
+static int type2spill_size[T_CONFLICT+1]={ -1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, -1, 1, 1, 1, -1};
 #endif
 
 
 // Implementation of LinearScan
 
@@ -256,11 +256,11 @@
     it->assign_reg(spill);
   }
 }
 
 void LinearScan::propagate_spill_slots() {
-  if (!frame_map()->finalize_frame(max_spills())) {
+  if (!frame_map()->finalize_frame(max_spills(), compilation()->needs_stack_repair())) {
     bailout("frame too large");
   }
 }
 
 // create a new interval with a predefined reg_num
@@ -2939,11 +2939,11 @@
     for (int i = 0; i < nof_locks; i++) {
       monitors->append(location_for_monitor_index(lock_offset + i));
     }
   }
 
-  return new IRScopeDebugInfo(cur_scope, cur_state->bci(), locals, expressions, monitors, caller_debug_info);
+  return new IRScopeDebugInfo(cur_scope, cur_state->bci(), locals, expressions, monitors, caller_debug_info, cur_state->should_reexecute());
 }
 
 
 void LinearScan::compute_debug_info(CodeEmitInfo* info, int op_id) {
   TRACE_LINEAR_SCAN(3, tty->print_cr("creating debug information at op_id %d", op_id));
diff a/src/hotspot/share/c1/c1_Runtime1.cpp b/src/hotspot/share/c1/c1_Runtime1.cpp
--- a/src/hotspot/share/c1/c1_Runtime1.cpp
+++ b/src/hotspot/share/c1/c1_Runtime1.cpp
@@ -53,10 +53,12 @@
 #include "memory/universe.hpp"
 #include "oops/access.inline.hpp"
 #include "oops/objArrayOop.inline.hpp"
 #include "oops/objArrayKlass.hpp"
 #include "oops/oop.inline.hpp"
+#include "oops/valueArrayKlass.hpp"
+#include "oops/valueArrayOop.inline.hpp"
 #include "runtime/atomic.hpp"
 #include "runtime/biasedLocking.hpp"
 #include "runtime/fieldDescriptor.inline.hpp"
 #include "runtime/frame.inline.hpp"
 #include "runtime/handles.inline.hpp"
@@ -117,21 +119,28 @@
 int Runtime1::_arraycopy_slowcase_cnt = 0;
 int Runtime1::_arraycopy_checkcast_cnt = 0;
 int Runtime1::_arraycopy_checkcast_attempt_cnt = 0;
 int Runtime1::_new_type_array_slowcase_cnt = 0;
 int Runtime1::_new_object_array_slowcase_cnt = 0;
+int Runtime1::_new_value_array_slowcase_cnt = 0;
 int Runtime1::_new_instance_slowcase_cnt = 0;
 int Runtime1::_new_multi_array_slowcase_cnt = 0;
+int Runtime1::_load_flattened_array_slowcase_cnt = 0;
+int Runtime1::_store_flattened_array_slowcase_cnt = 0;
+int Runtime1::_substitutability_check_slowcase_cnt = 0;
+int Runtime1::_buffer_value_args_slowcase_cnt = 0;
+int Runtime1::_buffer_value_args_no_receiver_slowcase_cnt = 0;
 int Runtime1::_monitorenter_slowcase_cnt = 0;
 int Runtime1::_monitorexit_slowcase_cnt = 0;
 int Runtime1::_patch_code_slowcase_cnt = 0;
 int Runtime1::_throw_range_check_exception_count = 0;
 int Runtime1::_throw_index_exception_count = 0;
 int Runtime1::_throw_div0_exception_count = 0;
 int Runtime1::_throw_null_pointer_exception_count = 0;
 int Runtime1::_throw_class_cast_exception_count = 0;
 int Runtime1::_throw_incompatible_class_change_error_count = 0;
+int Runtime1::_throw_illegal_monitor_state_exception_count = 0;
 int Runtime1::_throw_array_store_exception_count = 0;
 int Runtime1::_throw_count = 0;
 
 static int _byte_arraycopy_stub_cnt = 0;
 static int _short_arraycopy_stub_cnt = 0;
@@ -391,21 +400,43 @@
   // Note: no handle for klass needed since they are not used
   //       anymore after new_objArray() and no GC can happen before.
   //       (This may have to change if this code changes!)
   assert(array_klass->is_klass(), "not a class");
   Handle holder(THREAD, array_klass->klass_holder()); // keep the klass alive
-  Klass* elem_klass = ObjArrayKlass::cast(array_klass)->element_klass();
+  Klass* elem_klass = ArrayKlass::cast(array_klass)->element_klass();
   objArrayOop obj = oopFactory::new_objArray(elem_klass, length, CHECK);
   thread->set_vm_result(obj);
   // This is pretty rare but this runtime patch is stressful to deoptimization
   // if we deoptimize here so force a deopt to stress the path.
   if (DeoptimizeALot) {
     deopt_caller();
   }
 JRT_END
 
 
+JRT_ENTRY(void, Runtime1::new_value_array(JavaThread* thread, Klass* array_klass, jint length))
+  NOT_PRODUCT(_new_value_array_slowcase_cnt++;)
+
+  // Note: no handle for klass needed since they are not used
+  //       anymore after new_objArray() and no GC can happen before.
+  //       (This may have to change if this code changes!)
+  assert(array_klass->is_klass(), "not a class");
+  Handle holder(THREAD, array_klass->klass_holder()); // keep the klass alive
+  Klass* elem_klass = ArrayKlass::cast(array_klass)->element_klass();
+  assert(elem_klass->is_value(), "must be");
+  // Logically creates elements, ensure klass init
+  elem_klass->initialize(CHECK);
+  arrayOop obj = oopFactory::new_valueArray(elem_klass, length, CHECK);
+  thread->set_vm_result(obj);
+  // This is pretty rare but this runtime patch is stressful to deoptimization
+  // if we deoptimize here so force a deopt to stress the path.
+  if (DeoptimizeALot) {
+    deopt_caller();
+  }
+JRT_END
+
+
 JRT_ENTRY(void, Runtime1::new_multi_array(JavaThread* thread, Klass* klass, int rank, jint* dims))
   NOT_PRODUCT(_new_multi_array_slowcase_cnt++;)
 
   assert(klass->is_klass(), "not a class");
   assert(rank >= 1, "rank must be nonzero");
@@ -413,10 +444,87 @@
   oop obj = ArrayKlass::cast(klass)->multi_allocate(rank, dims, CHECK);
   thread->set_vm_result(obj);
 JRT_END
 
 
+static void profile_flat_array(JavaThread* thread) {
+  ResourceMark rm(thread);
+  vframeStream vfst(thread, true);
+  assert(!vfst.at_end(), "Java frame must exist");
+  int bci = vfst.bci();
+  Method* method = vfst.method();
+  MethodData* md = method->method_data();
+  if (md != NULL) {
+    ProfileData* data = md->bci_to_data(bci);
+    assert(data != NULL && data->is_ArrayLoadStoreData(), "incorrect profiling entry");
+    ArrayLoadStoreData* load_store = (ArrayLoadStoreData*)data;
+    load_store->set_flat_array();
+  }
+}
+
+JRT_ENTRY(void, Runtime1::load_flattened_array(JavaThread* thread, valueArrayOopDesc* array, int index))
+  assert(array->klass()->is_valueArray_klass(), "should not be called");
+  profile_flat_array(thread);
+
+  NOT_PRODUCT(_load_flattened_array_slowcase_cnt++;)
+  assert(array->length() > 0 && index < array->length(), "already checked");
+  valueArrayHandle vah(thread, array);
+  oop obj = valueArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK);
+  thread->set_vm_result(obj);
+JRT_END
+
+
+JRT_ENTRY(void, Runtime1::store_flattened_array(JavaThread* thread, valueArrayOopDesc* array, int index, oopDesc* value))
+  if (array->klass()->is_valueArray_klass()) {
+    profile_flat_array(thread);
+  }
+
+  NOT_PRODUCT(_store_flattened_array_slowcase_cnt++;)
+  if (value == NULL) {
+    assert(array->klass()->is_valueArray_klass() || array->klass()->is_null_free_array_klass(), "should not be called");
+    SharedRuntime::throw_and_post_jvmti_exception(thread, vmSymbols::java_lang_NullPointerException());
+  } else {
+    assert(array->klass()->is_valueArray_klass(), "should not be called");
+    array->value_copy_to_index(value, index);
+  }
+JRT_END
+
+
+JRT_ENTRY(int, Runtime1::substitutability_check(JavaThread* thread, oopDesc* left, oopDesc* right))
+  NOT_PRODUCT(_substitutability_check_slowcase_cnt++;)
+  JavaCallArguments args;
+  args.push_oop(Handle(THREAD, left));
+  args.push_oop(Handle(THREAD, right));
+  JavaValue result(T_BOOLEAN);
+  JavaCalls::call_static(&result,
+                         SystemDictionary::ValueBootstrapMethods_klass(),
+                         vmSymbols::isSubstitutable_name(),
+                         vmSymbols::object_object_boolean_signature(),
+                         &args, CHECK_0);
+  return result.get_jboolean() ? 1 : 0;
+JRT_END
+
+
+extern "C" void ps();
+
+void Runtime1::buffer_value_args_impl(JavaThread* thread, Method* m, bool allocate_receiver) {
+  Thread* THREAD = thread;
+  methodHandle method(thread, m); // We are inside the verified_entry or verified_value_ro_entry of this method.
+  oop obj = SharedRuntime::allocate_value_types_impl(thread, method, allocate_receiver, CHECK);
+  thread->set_vm_result(obj);
+}
+
+JRT_ENTRY(void, Runtime1::buffer_value_args(JavaThread* thread, Method* method))
+  NOT_PRODUCT(_buffer_value_args_slowcase_cnt++;)
+  buffer_value_args_impl(thread, method, true);
+JRT_END
+
+JRT_ENTRY(void, Runtime1::buffer_value_args_no_receiver(JavaThread* thread, Method* method))
+  NOT_PRODUCT(_buffer_value_args_no_receiver_slowcase_cnt++;)
+  buffer_value_args_impl(thread, method, false);
+JRT_END
+
 JRT_ENTRY(void, Runtime1::unimplemented_entry(JavaThread* thread, StubID id))
   tty->print_cr("Runtime1::entry_for(%d) returned unimplemented entry point", id);
 JRT_END
 
 
@@ -698,10 +806,17 @@
   ResourceMark rm(thread);
   SharedRuntime::throw_and_post_jvmti_exception(thread, vmSymbols::java_lang_IncompatibleClassChangeError());
 JRT_END
 
 
+JRT_ENTRY(void, Runtime1::throw_illegal_monitor_state_exception(JavaThread* thread))
+  NOT_PRODUCT(_throw_illegal_monitor_state_exception_count++;)
+  ResourceMark rm(thread);
+  SharedRuntime::throw_and_post_jvmti_exception(thread, vmSymbols::java_lang_IllegalMonitorStateException());
+JRT_END
+
+
 JRT_BLOCK_ENTRY(void, Runtime1::monitorenter(JavaThread* thread, oopDesc* obj, BasicObjectLock* lock))
   NOT_PRODUCT(_monitorenter_slowcase_cnt++;)
   if (!UseFastLocking) {
     lock->set_obj(obj);
   }
@@ -942,13 +1057,22 @@
       case Bytecodes::_new:
         { Bytecode_new bnew(caller_method(), caller_method->bcp_from(bci));
           k = caller_method->constants()->klass_at(bnew.index(), CHECK);
         }
         break;
+      case Bytecodes::_defaultvalue:
+        { Bytecode_defaultvalue bdefaultvalue(caller_method(), caller_method->bcp_from(bci));
+          k = caller_method->constants()->klass_at(bdefaultvalue.index(), CHECK);
+        }
+        break;
       case Bytecodes::_multianewarray:
         { Bytecode_multianewarray mna(caller_method(), caller_method->bcp_from(bci));
           k = caller_method->constants()->klass_at(mna.index(), CHECK);
+          if (k->name()->is_Q_array_signature()) {
+            // Logically creates elements, ensure klass init
+            k->initialize(CHECK);
+          }
         }
         break;
       case Bytecodes::_instanceof:
         { Bytecode_instanceof io(caller_method(), caller_method->bcp_from(bci));
           k = caller_method->constants()->klass_at(io.index(), CHECK);
@@ -1459,22 +1583,30 @@
   tty->print_cr(" _arraycopy_checkcast_cnt:        %d", _arraycopy_checkcast_cnt);
   tty->print_cr(" _arraycopy_checkcast_attempt_cnt:%d", _arraycopy_checkcast_attempt_cnt);
 
   tty->print_cr(" _new_type_array_slowcase_cnt:    %d", _new_type_array_slowcase_cnt);
   tty->print_cr(" _new_object_array_slowcase_cnt:  %d", _new_object_array_slowcase_cnt);
+  tty->print_cr(" _new_value_array_slowcase_cnt:   %d", _new_value_array_slowcase_cnt);
   tty->print_cr(" _new_instance_slowcase_cnt:      %d", _new_instance_slowcase_cnt);
   tty->print_cr(" _new_multi_array_slowcase_cnt:   %d", _new_multi_array_slowcase_cnt);
+  tty->print_cr(" _load_flattened_array_slowcase_cnt:   %d", _load_flattened_array_slowcase_cnt);
+  tty->print_cr(" _store_flattened_array_slowcase_cnt:  %d", _store_flattened_array_slowcase_cnt);
+  tty->print_cr(" _substitutability_check_slowcase_cnt: %d", _substitutability_check_slowcase_cnt);
+  tty->print_cr(" _buffer_value_args_slowcase_cnt:%d", _buffer_value_args_slowcase_cnt);
+  tty->print_cr(" _buffer_value_args_no_receiver_slowcase_cnt:%d", _buffer_value_args_no_receiver_slowcase_cnt);
+
   tty->print_cr(" _monitorenter_slowcase_cnt:      %d", _monitorenter_slowcase_cnt);
   tty->print_cr(" _monitorexit_slowcase_cnt:       %d", _monitorexit_slowcase_cnt);
   tty->print_cr(" _patch_code_slowcase_cnt:        %d", _patch_code_slowcase_cnt);
 
   tty->print_cr(" _throw_range_check_exception_count:            %d:", _throw_range_check_exception_count);
   tty->print_cr(" _throw_index_exception_count:                  %d:", _throw_index_exception_count);
   tty->print_cr(" _throw_div0_exception_count:                   %d:", _throw_div0_exception_count);
   tty->print_cr(" _throw_null_pointer_exception_count:           %d:", _throw_null_pointer_exception_count);
   tty->print_cr(" _throw_class_cast_exception_count:             %d:", _throw_class_cast_exception_count);
   tty->print_cr(" _throw_incompatible_class_change_error_count:  %d:", _throw_incompatible_class_change_error_count);
+  tty->print_cr(" _throw_illegal_monitor_state_exception_count:  %d:", _throw_illegal_monitor_state_exception_count);
   tty->print_cr(" _throw_array_store_exception_count:            %d:", _throw_array_store_exception_count);
   tty->print_cr(" _throw_count:                                  %d:", _throw_count);
 
   SharedRuntime::print_ic_miss_histogram();
   tty->cr();
diff a/src/hotspot/share/classfile/classListParser.cpp b/src/hotspot/share/classfile/classListParser.cpp
--- a/src/hotspot/share/classfile/classListParser.cpp
+++ b/src/hotspot/share/classfile/classListParser.cpp
@@ -29,10 +29,11 @@
 #include "classfile/classLoaderExt.hpp"
 #include "classfile/javaClasses.inline.hpp"
 #include "classfile/symbolTable.hpp"
 #include "classfile/systemDictionary.hpp"
 #include "classfile/systemDictionaryShared.hpp"
+#include "classfile/vmSymbols.hpp"
 #include "logging/log.hpp"
 #include "logging/logTag.hpp"
 #include "memory/metaspaceShared.hpp"
 #include "memory/resourceArea.hpp"
 #include "runtime/handles.inline.hpp"
@@ -302,15 +303,41 @@
   }
 
   InstanceKlass* k = ClassLoaderExt::load_class(class_name, _source, CHECK_NULL);
 
   if (k != NULL) {
-    if (k->local_interfaces()->length() != _interfaces->length()) {
+    int actual_num_interfaces = k->local_interfaces()->length();
+    int specified_num_interfaces = _interfaces->length();
+    int expected_num_interfaces, i;
+
+    bool identity_object_implemented = false;
+    bool identity_object_specified = false;
+    for (i = 0; i < actual_num_interfaces; i++) {
+      if (k->local_interfaces()->at(i) == SystemDictionary::IdentityObject_klass()) {
+        identity_object_implemented = true;
+        break;
+      }
+    }
+    for (i = 0; i < specified_num_interfaces; i++) {
+      if (lookup_class_by_id(_interfaces->at(i)) == SystemDictionary::IdentityObject_klass()) {
+        identity_object_specified = true;
+        break;
+      }
+    }
+
+    expected_num_interfaces = actual_num_interfaces;
+    if (identity_object_implemented  && !identity_object_specified) {
+      // Backwards compatibility -- older classlists do not know about
+      // java.lang.IdentityObject.
+      expected_num_interfaces--;
+    }
+
+    if (specified_num_interfaces != expected_num_interfaces) {
       print_specified_interfaces();
       print_actual_interfaces(k);
       error("The number of interfaces (%d) specified in class list does not match the class file (%d)",
-            _interfaces->length(), k->local_interfaces()->length());
+            specified_num_interfaces, expected_num_interfaces);
     }
 
     bool added = SystemDictionaryShared::add_unregistered_class(k, CHECK_NULL);
     if (!added) {
       // We allow only a single unregistered class for each unique name.
@@ -437,10 +464,16 @@
 InstanceKlass* ClassListParser::lookup_interface_for_current_class(Symbol* interface_name) {
   if (!is_loading_from_source()) {
     return NULL;
   }
 
+  if (interface_name == vmSymbols::java_lang_IdentityObject()) {
+    // Backwards compatibility -- older classlists do not know about
+    // java.lang.IdentityObject.
+    return SystemDictionary::IdentityObject_klass();
+  }
+
   const int n = _interfaces->length();
   if (n == 0) {
     error("Class %s implements the interface %s, but no interface has been specified in the input line",
           _class_name, interface_name->as_klass_external_name());
     ShouldNotReachHere();
diff a/src/hotspot/share/classfile/javaClasses.cpp b/src/hotspot/share/classfile/javaClasses.cpp
--- a/src/hotspot/share/classfile/javaClasses.cpp
+++ b/src/hotspot/share/classfile/javaClasses.cpp
@@ -42,18 +42,20 @@
 #include "memory/oopFactory.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
 #include "oops/fieldStreams.inline.hpp"
 #include "oops/instanceKlass.hpp"
-#include "oops/instanceMirrorKlass.hpp"
+#include "oops/instanceMirrorKlass.inline.hpp"
 #include "oops/klass.hpp"
 #include "oops/method.inline.hpp"
 #include "oops/objArrayOop.inline.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/symbol.hpp"
 #include "oops/recordComponent.hpp"
 #include "oops/typeArrayOop.inline.hpp"
+#include "oops/valueArrayKlass.hpp"
+#include "oops/valueKlass.inline.hpp"
 #include "prims/jvmtiExport.hpp"
 #include "prims/resolvedMethodTable.hpp"
 #include "runtime/fieldDescriptor.inline.hpp"
 #include "runtime/frame.inline.hpp"
 #include "runtime/handles.inline.hpp"
@@ -977,11 +979,16 @@
 
     java_lang_Class::set_static_oop_field_count(mirror(), mk->compute_static_oop_field_count(mirror()));
 
     // It might also have a component mirror.  This mirror must already exist.
     if (k->is_array_klass()) {
-      if (k->is_typeArray_klass()) {
+      if (k->is_valueArray_klass()) {
+        Klass* element_klass = (Klass*) ValueArrayKlass::cast(k)->element_klass();
+        assert(element_klass->is_value(), "Must be value type component");
+        ValueKlass* vk = ValueKlass::cast(InstanceKlass::cast(element_klass));
+        comp_mirror = Handle(THREAD, vk->java_mirror());
+      } else if (k->is_typeArray_klass()) {
         BasicType type = TypeArrayKlass::cast(k)->element_type();
         comp_mirror = Handle(THREAD, Universe::java_mirror(type));
       } else {
         assert(k->is_objArray_klass(), "Must be");
         Klass* element_klass = ObjArrayKlass::cast(k)->element_klass();
@@ -1024,10 +1031,27 @@
     if (comp_mirror() != NULL) {
       // Set after k->java_mirror() is published, because compiled code running
       // concurrently doesn't expect a k to have a null java_mirror.
       release_set_array_klass(comp_mirror(), k);
     }
+
+    if (k->is_value()) {
+      InstanceKlass* super = k->java_super();
+      set_val_type_mirror(mirror(), mirror());
+
+      // if the supertype is a restricted abstract class
+      if (super != SystemDictionary::Object_klass()) {
+        assert(super->access_flags().is_abstract(), "must be an abstract class");
+        oop ref_type_oop = super->java_mirror();
+        // set the reference projection type
+        set_ref_type_mirror(mirror(), ref_type_oop);
+
+        // set the value and reference projection types
+        set_val_type_mirror(ref_type_oop, mirror());
+        set_ref_type_mirror(ref_type_oop, ref_type_oop);
+      }
+    }
   } else {
     assert(fixup_mirror_list() != NULL, "fixup_mirror_list not initialized");
     fixup_mirror_list()->push(k);
   }
 }
@@ -1180,10 +1204,16 @@
       k->set_java_mirror_handle(NULL);
       return NULL;
     }
   }
 
+  if (k->is_value()) {
+    // Values have a val type mirror and a ref type mirror. Don't handle this for now. TODO:CDS
+    k->set_java_mirror_handle(NULL);
+    return NULL;
+  }
+
   // Now start archiving the mirror object
   oop archived_mirror = HeapShared::archive_heap_object(mirror, THREAD);
   if (archived_mirror == NULL) {
     return NULL;
   }
@@ -1471,10 +1501,30 @@
 void java_lang_Class::set_source_file(oop java_class, oop source_file) {
   assert(_source_file_offset != 0, "must be set");
   java_class->obj_field_put(_source_file_offset, source_file);
 }
 
+oop java_lang_Class::val_type_mirror(oop java_class) {
+  assert(_val_type_mirror_offset != 0, "must be set");
+  return java_class->obj_field(_val_type_mirror_offset);
+}
+
+void java_lang_Class::set_val_type_mirror(oop java_class, oop mirror) {
+  assert(_val_type_mirror_offset != 0, "must be set");
+  java_class->obj_field_put(_val_type_mirror_offset, mirror);
+}
+
+oop java_lang_Class::ref_type_mirror(oop java_class) {
+  assert(_ref_type_mirror_offset != 0, "must be set");
+  return java_class->obj_field(_ref_type_mirror_offset);
+}
+
+void java_lang_Class::set_ref_type_mirror(oop java_class, oop mirror) {
+  assert(_ref_type_mirror_offset != 0, "must be set");
+  java_class->obj_field_put(_ref_type_mirror_offset, mirror);
+}
+
 oop java_lang_Class::create_basic_type_mirror(const char* basic_type_name, BasicType type, TRAPS) {
   // This should be improved by adding a field at the Java level or by
   // introducing a new VM klass (see comment in ClassFileParser)
   oop java_class = InstanceMirrorKlass::cast(SystemDictionary::Class_klass())->allocate_instance(NULL, CHECK_NULL);
   if (type != T_VOID) {
@@ -1507,22 +1557,30 @@
 
 void java_lang_Class::print_signature(oop java_class, outputStream* st) {
   assert(java_lang_Class::is_instance(java_class), "must be a Class object");
   Symbol* name = NULL;
   bool is_instance = false;
+  bool is_value = false;
   if (is_primitive(java_class)) {
     name = vmSymbols::type_signature(primitive_type(java_class));
   } else {
     Klass* k = as_Klass(java_class);
     is_instance = k->is_instance_klass();
+    is_value = k->is_value();
     name = k->name();
   }
   if (name == NULL) {
     st->print("<null>");
     return;
   }
-  if (is_instance)  st->print("L");
+  if (is_instance)  {
+    if (is_value) {
+      st->print("Q");
+    } else {
+      st->print("L");
+    }
+  }
   st->write((char*) name->base(), (int) name->utf8_length());
   if (is_instance)  st->print(";");
 }
 
 Symbol* java_lang_Class::as_signature(oop java_class, bool intern_if_not_found) {
@@ -1540,11 +1598,11 @@
       name = k->name();
       name->increment_refcount();
     } else {
       ResourceMark rm;
       const char* sigstr = k->signature_name();
-      int         siglen = (int) strlen(sigstr);
+      int siglen = (int) strlen(sigstr);
       if (!intern_if_not_found) {
         name = SymbolTable::probe(sigstr, siglen);
       } else {
         name = SymbolTable::new_symbol(sigstr, siglen);
       }
@@ -1625,10 +1683,12 @@
   macro(classRedefinedCount_offset, k, "classRedefinedCount", int_signature,         false); \
   macro(_class_loader_offset,       k, "classLoader",         classloader_signature, false); \
   macro(_component_mirror_offset,   k, "componentType",       class_signature,       false); \
   macro(_module_offset,             k, "module",              module_signature,      false); \
   macro(_name_offset,               k, "name",                string_signature,      false); \
+  macro(_val_type_mirror_offset,    k, "valType",             class_signature,       false); \
+  macro(_ref_type_mirror_offset,    k, "refType",             class_signature,       false); \
   macro(_classData_offset,          k, "classData",           object_signature,      false);
 
 void java_lang_Class::compute_offsets() {
   if (offsets_computed) {
     return;
@@ -2500,12 +2560,12 @@
     }
     if (!skip_throwableInit_check) {
       assert(skip_fillInStackTrace_check, "logic error in backtrace filtering");
 
       // skip <init> methods of the exception class and superclasses
-      // This is simlar to classic VM.
-      if (method->name() == vmSymbols::object_initializer_name() &&
+      // This is similar to classic VM (before HotSpot).
+      if (method->is_object_constructor() &&
           throwable->is_a(method->method_holder())) {
         continue;
       } else {
         // there are none or we've seen them all - either way stop checking
         skip_throwableInit_check = true;
@@ -3822,11 +3882,11 @@
   return method == NULL ? NULL : java_lang_invoke_ResolvedMethodName::vmtarget(method);
 }
 
 bool java_lang_invoke_MemberName::is_method(oop mname) {
   assert(is_instance(mname), "must be MemberName");
-  return (flags(mname) & (MN_IS_METHOD | MN_IS_CONSTRUCTOR)) > 0;
+  return (flags(mname) & (MN_IS_METHOD | MN_IS_OBJECT_CONSTRUCTOR)) > 0;
 }
 
 void java_lang_invoke_MemberName::set_method(oop mname, oop resolved_method) {
   assert(is_instance(mname), "wrong type");
   mname->obj_field_put(_method_offset, resolved_method);
@@ -4328,10 +4388,12 @@
 int java_lang_Class::_static_oop_field_count_offset;
 int java_lang_Class::_class_loader_offset;
 int java_lang_Class::_module_offset;
 int java_lang_Class::_protection_domain_offset;
 int java_lang_Class::_component_mirror_offset;
+int java_lang_Class::_val_type_mirror_offset;
+int java_lang_Class::_ref_type_mirror_offset;
 int java_lang_Class::_init_lock_offset;
 int java_lang_Class::_signers_offset;
 int java_lang_Class::_name_offset;
 int java_lang_Class::_source_file_offset;
 int java_lang_Class::_classData_offset;
@@ -4423,10 +4485,15 @@
 int java_lang_reflect_RecordComponent::type_offset;
 int java_lang_reflect_RecordComponent::accessor_offset;
 int java_lang_reflect_RecordComponent::signature_offset;
 int java_lang_reflect_RecordComponent::annotations_offset;
 int java_lang_reflect_RecordComponent::typeAnnotations_offset;
+int jdk_internal_vm_jni_SubElementSelector::_arrayElementType_offset;
+int jdk_internal_vm_jni_SubElementSelector::_subElementType_offset;
+int jdk_internal_vm_jni_SubElementSelector::_offset_offset;
+int jdk_internal_vm_jni_SubElementSelector::_isFlattened_offset;
+int jdk_internal_vm_jni_SubElementSelector::_isFlattenable_offset;
 
 
 
 #define STACKTRACEELEMENT_FIELDS_DO(macro) \
   macro(declaringClassObject_offset,  k, "declaringClassObject", class_signature, false); \
@@ -4728,10 +4795,73 @@
   BYTE_CACHE_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
 }
 #endif
 #undef BYTE_CACHE_FIELDS_DO
 
+#define SUBELEMENT_SELECTOR_FIELDS_DO(macro) \
+  macro(_arrayElementType_offset,  k, "arrayElementType", class_signature, false); \
+  macro(_subElementType_offset,    k, "subElementType",   class_signature, false); \
+  macro(_offset_offset,            k, "offset",           int_signature,   false); \
+  macro(_isFlattened_offset,       k, "isFlattened",      bool_signature,  false); \
+  macro(_isFlattenable_offset,     k, "isFlattenable",    bool_signature,  false);
+
+void jdk_internal_vm_jni_SubElementSelector::compute_offsets() {
+  InstanceKlass* k = SystemDictionary::jdk_internal_vm_jni_SubElementSelector_klass();
+  SUBELEMENT_SELECTOR_FIELDS_DO(FIELD_COMPUTE_OFFSET);
+}
+
+#if INCLUDE_CDS
+void jdk_internal_vm_jni_SubElementSelector::serialize_offsets(SerializeClosure* f) {
+  SUBELEMENT_SELECTOR_FIELDS_DO(FIELD_SERIALIZE_OFFSET);
+}
+#endif
+#undef SUBELEMENT_SELECTOR_FIELDS_DO
+
+Symbol* jdk_internal_vm_jni_SubElementSelector::symbol() {
+  return vmSymbols::jdk_internal_vm_jni_SubElementSelector();
+}
+
+oop jdk_internal_vm_jni_SubElementSelector::getArrayElementType(oop obj) {
+  return obj->obj_field(_arrayElementType_offset);
+}
+
+void jdk_internal_vm_jni_SubElementSelector::setArrayElementType(oop obj, oop type) {
+  obj->obj_field_put(_arrayElementType_offset, type);
+}
+
+oop jdk_internal_vm_jni_SubElementSelector::getSubElementType(oop obj) {
+  return obj->obj_field(_subElementType_offset);
+}
+
+void jdk_internal_vm_jni_SubElementSelector::setSubElementType(oop obj, oop type) {
+  obj->obj_field_put(_subElementType_offset, type);
+}
+
+int jdk_internal_vm_jni_SubElementSelector::getOffset(oop obj) {
+  return obj->int_field(_offset_offset);
+}
+
+void jdk_internal_vm_jni_SubElementSelector::setOffset(oop obj, int offset) {
+  obj->int_field_put(_offset_offset, offset);
+}
+
+bool jdk_internal_vm_jni_SubElementSelector::getIsFlattened(oop obj) {
+  return obj->bool_field(_isFlattened_offset);
+}
+
+void jdk_internal_vm_jni_SubElementSelector::setIsFlattened(oop obj, bool b) {
+  obj->bool_field_put(_isFlattened_offset, b);
+}
+
+bool jdk_internal_vm_jni_SubElementSelector::getIsFlattenable(oop obj) {
+  return obj->bool_field(_isFlattenable_offset);
+}
+
+void jdk_internal_vm_jni_SubElementSelector::setIsFlattenable(oop obj, bool b) {
+  obj->bool_field_put(_isFlattenable_offset, b);
+}
+
 jbyte java_lang_Byte::value(oop obj) {
    jvalue v;
    java_lang_boxing_object::get_value(obj, &v);
    return v.b;
 }
diff a/src/hotspot/share/classfile/systemDictionary.cpp b/src/hotspot/share/classfile/systemDictionary.cpp
--- a/src/hotspot/share/classfile/systemDictionary.cpp
+++ b/src/hotspot/share/classfile/systemDictionary.cpp
@@ -58,28 +58,31 @@
 #include "memory/metaspaceClosure.hpp"
 #include "memory/oopFactory.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
 #include "oops/access.inline.hpp"
+#include "oops/fieldStreams.inline.hpp"
 #include "oops/instanceKlass.hpp"
 #include "oops/instanceRefKlass.hpp"
 #include "oops/klass.inline.hpp"
 #include "oops/method.inline.hpp"
 #include "oops/methodData.hpp"
 #include "oops/objArrayKlass.hpp"
 #include "oops/objArrayOop.inline.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/symbol.hpp"
 #include "oops/typeArrayKlass.hpp"
+#include "oops/valueKlass.hpp"
 #include "prims/jvmtiExport.hpp"
 #include "prims/methodHandles.hpp"
 #include "runtime/arguments.hpp"
 #include "runtime/biasedLocking.hpp"
 #include "runtime/handles.inline.hpp"
 #include "runtime/java.hpp"
 #include "runtime/javaCalls.hpp"
 #include "runtime/mutexLocker.hpp"
+#include "runtime/os.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "runtime/signature.hpp"
 #include "services/classLoadingService.hpp"
 #include "services/diagnosticCommand.hpp"
 #include "services/threadService.hpp"
@@ -319,11 +322,11 @@
                                                                        Handle protection_domain,
                                                                        TRAPS) {
   assert(class_name != NULL && !Signature::is_array(class_name), "must be");
   if (Signature::has_envelope(class_name)) {
     ResourceMark rm(THREAD);
-    // Ignore wrapping L and ;.
+    // Ignore wrapping L and ;. (and Q and ; for value types);
     TempNewSymbol name = SymbolTable::new_symbol(class_name->as_C_string() + 1,
                                                  class_name->utf8_length() - 2);
     return resolve_instance_class_or_null(name, class_loader, protection_domain, THREAD);
   } else {
     return resolve_instance_class_or_null(class_name, class_loader, protection_domain, THREAD);
@@ -360,11 +363,10 @@
     k = TypeArrayKlass::cast(k)->array_klass(ndims, CHECK_NULL);
   }
   return k;
 }
 
-
 // Must be called for any super-class or super-interface resolution
 // during class definition to allow class circularity checking
 // super-interface callers:
 //    parse_interfaces - for defineClass & jvmtiRedefineClasses
 // super-class callers:
@@ -504,10 +506,55 @@
   }
 
   return superk;
 }
 
+Klass* SystemDictionary::resolve_flattenable_field_or_fail(AllFieldStream* fs,
+                                                           Handle class_loader,
+                                                           Handle protection_domain,
+                                                           bool throw_error,
+                                                           TRAPS) {
+  Symbol* class_name = fs->signature()->fundamental_name(THREAD);
+  class_loader = Handle(THREAD, java_lang_ClassLoader::non_reflection_class_loader(class_loader()));
+  ClassLoaderData* loader_data = class_loader_data(class_loader);
+  unsigned int p_hash = placeholders()->compute_hash(class_name);
+  int p_index = placeholders()->hash_to_index(p_hash);
+  bool throw_circularity_error = false;
+  PlaceholderEntry* oldprobe;
+
+  {
+    MutexLocker mu(THREAD, SystemDictionary_lock);
+    oldprobe = placeholders()->get_entry(p_index, p_hash, class_name, loader_data);
+    if (oldprobe != NULL &&
+      oldprobe->check_seen_thread(THREAD, PlaceholderTable::FLATTENABLE_FIELD)) {
+      throw_circularity_error = true;
+
+    } else {
+      placeholders()->find_and_add(p_index, p_hash, class_name, loader_data,
+                                   PlaceholderTable::FLATTENABLE_FIELD, NULL, THREAD);
+    }
+  }
+
+  Klass* klass = NULL;
+  if (!throw_circularity_error) {
+    klass = SystemDictionary::resolve_or_fail(class_name, class_loader,
+                                               protection_domain, true, THREAD);
+  } else {
+    ResourceMark rm(THREAD);
+    THROW_MSG_NULL(vmSymbols::java_lang_ClassCircularityError(), class_name->as_C_string());
+  }
+
+  {
+    MutexLocker mu(THREAD, SystemDictionary_lock);
+    placeholders()->find_and_remove(p_index, p_hash, class_name, loader_data,
+                                    PlaceholderTable::FLATTENABLE_FIELD, THREAD);
+  }
+
+  class_name->decrement_refcount();
+  return klass;
+}
+
 void SystemDictionary::validate_protection_domain(InstanceKlass* klass,
                                                   Handle class_loader,
                                                   Handle protection_domain,
                                                   TRAPS) {
   // Now we have to call back to java to check if the initating class has access
@@ -1031,11 +1078,11 @@
     // dimension and object_key in FieldArrayInfo are assigned as a
     // side-effect of this call
     SignatureStream ss(class_name, false);
     int ndims = ss.skip_array_prefix();  // skip all '['s
     BasicType t = ss.type();
-    if (t != T_OBJECT) {
+    if (t != T_OBJECT && t != T_VALUETYPE) {
       k = Universe::typeArrayKlassObj(t);
     } else {
       k = SystemDictionary::find(ss.as_symbol(), class_loader, protection_domain, THREAD);
     }
     if (k != NULL) {
@@ -2302,11 +2349,11 @@
     // For array classes, their Klass*s are not kept in the
     // constraint table. The element Klass*s are.
     SignatureStream ss(class_name, false);
     int ndims = ss.skip_array_prefix();  // skip all '['s
     BasicType t = ss.type();
-    if (t != T_OBJECT) {
+    if (t != T_OBJECT && t != T_VALUETYPE) {
       klass = Universe::typeArrayKlassObj(t);
     } else {
       MutexLocker mu(THREAD, SystemDictionary_lock);
       klass = constraints()->find_constrained_klass(ss.as_symbol(), class_loader);
     }
diff a/src/hotspot/share/classfile/systemDictionary.hpp b/src/hotspot/share/classfile/systemDictionary.hpp
--- a/src/hotspot/share/classfile/systemDictionary.hpp
+++ b/src/hotspot/share/classfile/systemDictionary.hpp
@@ -121,10 +121,11 @@
 //
 
 class BootstrapInfo;
 class ClassFileStream;
 class Dictionary;
+class AllFieldStream;
 class PlaceholderTable;
 class LoaderConstraintTable;
 template <MEMFLAGS F> class HashtableBucket;
 class ResolutionErrorTable;
 class SymbolPropertyTable;
@@ -147,10 +148,11 @@
 // of the VM start-up sequence.
 //
 #define WK_KLASSES_DO(do_klass)                                                                                 \
   /* well-known classes */                                                                                      \
   do_klass(Object_klass,                                java_lang_Object                                      ) \
+  do_klass(IdentityObject_klass,                        java_lang_IdentityObject                              ) \
   do_klass(String_klass,                                java_lang_String                                      ) \
   do_klass(Class_klass,                                 java_lang_Class                                       ) \
   do_klass(Cloneable_klass,                             java_lang_Cloneable                                   ) \
   do_klass(ClassLoader_klass,                           java_lang_ClassLoader                                 ) \
   do_klass(Serializable_klass,                          java_io_Serializable                                  ) \
@@ -217,10 +219,11 @@
   do_klass(BootstrapMethodError_klass,                  java_lang_BootstrapMethodError                        ) \
   do_klass(CallSite_klass,                              java_lang_invoke_CallSite                             ) \
   do_klass(Context_klass,                               java_lang_invoke_MethodHandleNatives_CallSiteContext  ) \
   do_klass(ConstantCallSite_klass,                      java_lang_invoke_ConstantCallSite                     ) \
   do_klass(MutableCallSite_klass,                       java_lang_invoke_MutableCallSite                      ) \
+  do_klass(ValueBootstrapMethods_klass,                 java_lang_invoke_ValueBootstrapMethods                ) \
   do_klass(VolatileCallSite_klass,                      java_lang_invoke_VolatileCallSite                     ) \
   /* Note: MethodHandle must be first, and VolatileCallSite last in group */                                    \
                                                                                                                 \
   do_klass(AssertionStatusDirectives_klass,             java_lang_AssertionStatusDirectives                   ) \
   do_klass(StringBuffer_klass,                          java_lang_StringBuffer                                ) \
@@ -263,10 +266,11 @@
   do_klass(Long_klass,                                  java_lang_Long                                        ) \
                                                                                                                 \
   /* force inline of iterators */                                                                               \
   do_klass(Iterator_klass,                              java_util_Iterator                                    ) \
                                                                                                                 \
+  do_klass(jdk_internal_vm_jni_SubElementSelector_klass, jdk_internal_vm_jni_SubElementSelector               ) \
   /* support for records */                                                                                     \
   do_klass(RecordComponent_klass,                       java_lang_reflect_RecordComponent                     ) \
                                                                                                                 \
   /*end*/
 
@@ -316,10 +320,16 @@
                                               Handle class_loader,
                                               Handle protection_domain,
                                               bool is_superclass,
                                               TRAPS);
 
+  static Klass* resolve_flattenable_field_or_fail(AllFieldStream* fs,
+                                                  Handle class_loader,
+                                                  Handle protection_domain,
+                                                  bool throw_error,
+                                                  TRAPS);
+
   // Parse new stream. This won't update the dictionary or class
   // hierarchy, simply parse the stream. Used by JVMTI RedefineClasses
   // and by Unsafe_DefineAnonymousClass and jvm_lookup_define_class.
   static InstanceKlass* parse_stream(Symbol* class_name,
                                      Handle class_loader,
@@ -410,10 +420,11 @@
     assert(k != NULL, "klass not loaded");
     return k;
   }
 
   static bool resolve_wk_klass(WKID id, TRAPS);
+  static InstanceKlass* check_klass_ValhallaClasses(InstanceKlass* k) { return k; }
   static void resolve_wk_klasses_until(WKID limit_id, WKID &start_id, TRAPS);
   static void resolve_wk_klasses_through(WKID end_id, WKID &start_id, TRAPS) {
     int limit = (int)end_id + 1;
     resolve_wk_klasses_until((WKID) limit, start_id, THREAD);
   }
diff a/src/hotspot/share/compiler/oopMap.cpp b/src/hotspot/share/compiler/oopMap.cpp
--- a/src/hotspot/share/compiler/oopMap.cpp
+++ b/src/hotspot/share/compiler/oopMap.cpp
@@ -31,10 +31,11 @@
 #include "gc/shared/collectedHeap.hpp"
 #include "memory/allocation.inline.hpp"
 #include "memory/iterator.hpp"
 #include "memory/resourceArea.hpp"
 #include "memory/universe.hpp"
+#include "oops/valueKlass.hpp"
 #include "oops/compressedOops.hpp"
 #include "runtime/frame.inline.hpp"
 #include "runtime/handles.inline.hpp"
 #include "runtime/signature.hpp"
 #include "utilities/align.hpp"
diff a/src/hotspot/share/gc/parallel/psPromotionManager.cpp b/src/hotspot/share/gc/parallel/psPromotionManager.cpp
--- a/src/hotspot/share/gc/parallel/psPromotionManager.cpp
+++ b/src/hotspot/share/gc/parallel/psPromotionManager.cpp
@@ -39,10 +39,11 @@
 #include "memory/memRegion.hpp"
 #include "memory/padded.inline.hpp"
 #include "memory/resourceArea.hpp"
 #include "oops/access.inline.hpp"
 #include "oops/compressedOops.inline.hpp"
+#include "oops/valueArrayKlass.inline.hpp"
 
 PaddedEnd<PSPromotionManager>* PSPromotionManager::_manager_array = NULL;
 PSPromotionManager::PSScannerTasksQueueSet* PSPromotionManager::_stack_array_depth = NULL;
 PreservedMarksSet*             PSPromotionManager::_preserved_marks_set = NULL;
 PSOldGen*                      PSPromotionManager::_old_gen = NULL;
diff a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
--- a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
+++ b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
@@ -457,11 +457,11 @@
           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
       };
 
       if (call->is_call_to_arraycopystub()) {
         Node* dest = NULL;
-        const TypeTuple* args = n->as_Call()->_tf->domain();
+        const TypeTuple* args = n->as_Call()->_tf->domain_sig();
         for (uint i = TypeFunc::Parms, j = 0; i < args->cnt(); i++) {
           if (args->field_at(i)->isa_ptr()) {
             j++;
             if (j == 2) {
               dest = n->in(i);
@@ -576,11 +576,11 @@
       for (; i < others_len; i++) {
         if (others[i].opcode == n->Opcode()) {
           break;
         }
       }
-      uint stop = n->is_Call() ? n->as_Call()->tf()->domain()->cnt() : n->req();
+      uint stop = n->is_Call() ? n->as_Call()->tf()->domain_sig()->cnt() : n->req();
       if (i != others_len) {
         const uint inputs_len = sizeof(others[0].inputs) / sizeof(others[0].inputs[0]);
         for (uint j = 0; j < inputs_len; j++) {
           int pos = others[i].inputs[j].pos;
           if (pos == -1) {
@@ -796,22 +796,21 @@
           }
         }
       }
     } else {
       if (c->is_Call() && c->as_Call()->adr_type() != NULL) {
-        CallProjections projs;
-        c->as_Call()->extract_projections(&projs, true, false);
-        if (projs.fallthrough_memproj != NULL) {
-          if (projs.fallthrough_memproj->adr_type() == TypePtr::BOTTOM) {
-            if (projs.catchall_memproj == NULL) {
-              mem = projs.fallthrough_memproj;
+        CallProjections* projs = c->as_Call()->extract_projections(true, false);
+        if (projs->fallthrough_memproj != NULL) {
+          if (projs->fallthrough_memproj->adr_type() == TypePtr::BOTTOM) {
+            if (projs->catchall_memproj == NULL) {
+              mem = projs->fallthrough_memproj;
             } else {
-              if (phase->is_dominator(projs.fallthrough_catchproj, ctrl)) {
-                mem = projs.fallthrough_memproj;
+              if (phase->is_dominator(projs->fallthrough_catchproj, ctrl)) {
+                mem = projs->fallthrough_memproj;
               } else {
-                assert(phase->is_dominator(projs.catchall_catchproj, ctrl), "one proj must dominate barrier");
-                mem = projs.catchall_memproj;
+                assert(phase->is_dominator(projs->catchall_catchproj, ctrl), "one proj must dominate barrier");
+                mem = projs->catchall_memproj;
               }
             }
           }
         } else {
           Node* proj = c->as_Call()->proj_out(TypeFunc::Memory);
@@ -1049,11 +1048,11 @@
       }
     }
   }
 }
 
-static Node* create_phis_on_call_return(Node* ctrl, Node* c, Node* n, Node* n_clone, const CallProjections& projs, PhaseIdealLoop* phase) {
+static Node* create_phis_on_call_return(Node* ctrl, Node* c, Node* n, Node* n_clone, const CallProjections* projs, PhaseIdealLoop* phase) {
   Node* region = NULL;
   while (c != ctrl) {
     if (c->is_Region()) {
       region = c;
     }
@@ -1061,13 +1060,13 @@
   }
   assert(region != NULL, "");
   Node* phi = new PhiNode(region, n->bottom_type());
   for (uint j = 1; j < region->req(); j++) {
     Node* in = region->in(j);
-    if (phase->is_dominator(projs.fallthrough_catchproj, in)) {
+    if (phase->is_dominator(projs->fallthrough_catchproj, in)) {
       phi->init_req(j, n);
-    } else if (phase->is_dominator(projs.catchall_catchproj, in)) {
+    } else if (phase->is_dominator(projs->catchall_catchproj, in)) {
       phi->init_req(j, n_clone);
     } else {
       phi->init_req(j, create_phis_on_call_return(ctrl, in, n, n_clone, projs, phase));
     }
   }
@@ -1181,19 +1180,17 @@
             stack.pop();
           }
         } while(stack.size() > 0);
         continue;
       }
-      CallProjections projs;
-      call->extract_projections(&projs, false, false);
-
+      CallProjections* projs = call->extract_projections(false, false);
 #ifdef ASSERT
       VectorSet cloned(Thread::current()->resource_area());
 #endif
       Node* lrb_clone = lrb->clone();
-      phase->register_new_node(lrb_clone, projs.catchall_catchproj);
-      phase->set_ctrl(lrb, projs.fallthrough_catchproj);
+      phase->register_new_node(lrb_clone, projs->catchall_catchproj);
+      phase->set_ctrl(lrb, projs->fallthrough_catchproj);
 
       stack.push(lrb, 0);
       clones.push(lrb_clone);
 
       do {
@@ -1211,42 +1208,42 @@
         uint idx = stack.index();
         Node* n_clone = clones.at(clones.size()-1);
         if (idx < n->outcnt()) {
           Node* u = n->raw_out(idx);
           Node* c = phase->ctrl_or_self(u);
-          if (phase->is_dominator(call, c) && phase->is_dominator(c, projs.fallthrough_proj)) {
+          if (phase->is_dominator(call, c) && phase->is_dominator(c, projs->fallthrough_proj)) {
             stack.set_index(idx+1);
             assert(!u->is_CFG(), "");
             stack.push(u, 0);
             assert(!cloned.test_set(u->_idx), "only one clone");
             Node* u_clone = u->clone();
             int nb = u_clone->replace_edge(n, n_clone);
             assert(nb > 0, "should have replaced some uses");
-            phase->register_new_node(u_clone, projs.catchall_catchproj);
+            phase->register_new_node(u_clone, projs->catchall_catchproj);
             clones.push(u_clone);
-            phase->set_ctrl(u, projs.fallthrough_catchproj);
+            phase->set_ctrl(u, projs->fallthrough_catchproj);
           } else {
             bool replaced = false;
             if (u->is_Phi()) {
               for (uint k = 1; k < u->req(); k++) {
                 if (u->in(k) == n) {
-                  if (phase->is_dominator(projs.catchall_catchproj, u->in(0)->in(k))) {
+                  if (phase->is_dominator(projs->catchall_catchproj, u->in(0)->in(k))) {
                     phase->igvn().replace_input_of(u, k, n_clone);
                     replaced = true;
-                  } else if (!phase->is_dominator(projs.fallthrough_catchproj, u->in(0)->in(k))) {
+                  } else if (!phase->is_dominator(projs->fallthrough_catchproj, u->in(0)->in(k))) {
                     phase->igvn().replace_input_of(u, k, create_phis_on_call_return(ctrl, u->in(0)->in(k), n, n_clone, projs, phase));
                     replaced = true;
                   }
                 }
               }
             } else {
-              if (phase->is_dominator(projs.catchall_catchproj, c)) {
+              if (phase->is_dominator(projs->catchall_catchproj, c)) {
                 phase->igvn().rehash_node_delayed(u);
                 int nb = u->replace_edge(n, n_clone);
                 assert(nb > 0, "should have replaced some uses");
                 replaced = true;
-              } else if (!phase->is_dominator(projs.fallthrough_catchproj, c)) {
+              } else if (!phase->is_dominator(projs->fallthrough_catchproj, c)) {
                 if (u->is_If()) {
                   // Can't break If/Bool/Cmp chain
                   assert(n->is_Bool(), "unexpected If shape");
                   assert(stack.node_at(stack.size()-2)->is_Cmp(), "unexpected If shape");
                   assert(n_clone->is_Bool(), "unexpected clone");
@@ -2397,18 +2394,17 @@
 Node* MemoryGraphFixer::get_ctrl(Node* n) const {
   Node* c = _phase->get_ctrl(n);
   if (n->is_Proj() && n->in(0) != NULL && n->in(0)->is_Call()) {
     assert(c == n->in(0), "");
     CallNode* call = c->as_Call();
-    CallProjections projs;
-    call->extract_projections(&projs, true, false);
-    if (projs.catchall_memproj != NULL) {
-      if (projs.fallthrough_memproj == n) {
-        c = projs.fallthrough_catchproj;
+    CallProjections* projs = call->extract_projections(true, false);
+    if (projs->catchall_memproj != NULL) {
+      if (projs->fallthrough_memproj == n) {
+        c = projs->fallthrough_catchproj;
       } else {
-        assert(projs.catchall_memproj == n, "");
-        c = projs.catchall_catchproj;
+        assert(projs->catchall_memproj == n, "");
+        c = projs->catchall_catchproj;
       }
     }
   }
   return c;
 }
diff a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
--- a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
+++ b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
@@ -266,18 +266,18 @@
   Raw::clone(src, dst, size);
 }
 
 template <DecoratorSet decorators, typename BarrierSetT>
 template <typename T>
-bool ShenandoahBarrierSet::AccessBarrier<decorators, BarrierSetT>::oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
+void ShenandoahBarrierSet::AccessBarrier<decorators, BarrierSetT>::oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
                                                                                          arrayOop dst_obj, size_t dst_offset_in_bytes, T* dst_raw,
                                                                                          size_t length) {
   ShenandoahBarrierSet* bs = ShenandoahBarrierSet::barrier_set();
   bs->arraycopy_barrier(arrayOopDesc::obj_offset_to_raw(src_obj, src_offset_in_bytes, src_raw),
                         arrayOopDesc::obj_offset_to_raw(dst_obj, dst_offset_in_bytes, dst_raw),
                         length);
-  return Raw::oop_arraycopy_in_heap(src_obj, src_offset_in_bytes, src_raw, dst_obj, dst_offset_in_bytes, dst_raw, length);
+  Raw::oop_arraycopy_in_heap(src_obj, src_offset_in_bytes, src_raw, dst_obj, dst_offset_in_bytes, dst_raw, length);
 }
 
 template <class T, bool HAS_FWD, bool EVAC, bool ENQUEUE>
 void ShenandoahBarrierSet::arraycopy_work(T* src, size_t count) {
   assert(HAS_FWD == _heap->has_forwarded_objects(), "Forwarded object status is sane");
diff a/src/hotspot/share/interpreter/abstractInterpreter.hpp b/src/hotspot/share/interpreter/abstractInterpreter.hpp
--- a/src/hotspot/share/interpreter/abstractInterpreter.hpp
+++ b/src/hotspot/share/interpreter/abstractInterpreter.hpp
@@ -100,11 +100,11 @@
     else
       return vmIntrinsics::_none;
   }
 
   enum SomeConstants {
-    number_of_result_handlers = 10                              // number of result handlers for native calls
+    number_of_result_handlers = 11                              // number of result handlers for native calls
   };
 
  protected:
   static StubQueue* _code;                                      // the interpreter code (codelets)
 
diff a/src/hotspot/share/jvmci/jvmciCompiler.cpp b/src/hotspot/share/jvmci/jvmciCompiler.cpp
--- a/src/hotspot/share/jvmci/jvmciCompiler.cpp
+++ b/src/hotspot/share/jvmci/jvmciCompiler.cpp
@@ -67,11 +67,14 @@
   Array<Method*>* objectMethods = SystemDictionary::Object_klass()->methods();
   // Initialize compile queue with a selected set of methods.
   int len = objectMethods->length();
   for (int i = 0; i < len; i++) {
     methodHandle mh(THREAD, objectMethods->at(i));
-    if (!mh->is_native() && !mh->is_static() && !mh->is_initializer()) {
+    if (!mh->is_native() &&
+        !mh->is_static() &&
+        !mh->is_object_constructor() &&
+        !mh->is_class_initializer()) {
       ResourceMark rm;
       int hot_count = 10; // TODO: what's the appropriate value?
       CompileBroker::compile_method(mh, InvocationEntryBci, CompLevel_full_optimization, mh, hot_count, CompileTask::Reason_Bootstrap, THREAD);
     }
   }
diff a/src/hotspot/share/jvmci/vmStructs_jvmci.cpp b/src/hotspot/share/jvmci/vmStructs_jvmci.cpp
--- a/src/hotspot/share/jvmci/vmStructs_jvmci.cpp
+++ b/src/hotspot/share/jvmci/vmStructs_jvmci.cpp
@@ -156,11 +156,11 @@
                                                                                                                                      \
   nonstatic_field(InstanceKlass,               _fields,                                       Array<u2>*)                            \
   nonstatic_field(InstanceKlass,               _constants,                                    ConstantPool*)                         \
   nonstatic_field(InstanceKlass,               _init_state,                                   u1)                                    \
   nonstatic_field(InstanceKlass,               _init_thread,                                  Thread*)                               \
-  nonstatic_field(InstanceKlass,               _misc_flags,                                   u2)                                    \
+  nonstatic_field(InstanceKlass,               _misc_flags,                                   u4)                                    \
   nonstatic_field(InstanceKlass,               _annotations,                                  Annotations*)                          \
                                                                                                                                      \
   volatile_nonstatic_field(JavaFrameAnchor,    _last_Java_sp,                                 intptr_t*)                             \
   volatile_nonstatic_field(JavaFrameAnchor,    _last_Java_pc,                                 address)                               \
                                                                                                                                      \
@@ -503,10 +503,11 @@
   declare_constant(DataLayout::arg_info_data_tag)                         \
   declare_constant(DataLayout::call_type_data_tag)                        \
   declare_constant(DataLayout::virtual_call_type_data_tag)                \
   declare_constant(DataLayout::parameters_type_data_tag)                  \
   declare_constant(DataLayout::speculative_trap_data_tag)                 \
+  declare_constant(DataLayout::array_load_store_data_tag)                 \
                                                                           \
   declare_constant(Deoptimization::Unpack_deopt)                          \
   declare_constant(Deoptimization::Unpack_exception)                      \
   declare_constant(Deoptimization::Unpack_uncommon_trap)                  \
   declare_constant(Deoptimization::Unpack_reexecute)                      \
diff a/src/hotspot/share/memory/dynamicArchive.cpp b/src/hotspot/share/memory/dynamicArchive.cpp
--- a/src/hotspot/share/memory/dynamicArchive.cpp
+++ b/src/hotspot/share/memory/dynamicArchive.cpp
@@ -259,16 +259,30 @@
 
       return true; // keep recursing until every object is visited exactly once.
     }
 
     virtual void push_special(SpecialRef type, Ref* ref, intptr_t* p) {
-      assert(type == _method_entry_ref, "only special type allowed for now");
+      // TODO:CDS - JDK-8234693 will consolidate this with an almost identical method in metaspaceShared.cpp
+      assert_valid(type);
       address obj = ref->obj();
       address new_obj = _builder->get_new_loc(ref);
       size_t offset = pointer_delta(p, obj,  sizeof(u1));
       intptr_t* new_p = (intptr_t*)(new_obj + offset);
-      assert(*p == *new_p, "must be a copy");
+      switch (type) {
+      case _method_entry_ref:
+        assert(*p == *new_p, "must be a copy");
+        break;
+      case _internal_pointer_ref:
+        {
+          size_t off = pointer_delta(*((address*)p), obj, sizeof(u1));
+          assert(0 <= intx(off) && intx(off) < ref->size() * BytesPerWord, "must point to internal address");
+          *((address*)new_p) = new_obj + off;
+        }
+        break;
+      default:
+        ShouldNotReachHere();
+      }
       ArchivePtrMarker::mark_pointer((address*)new_p);
     }
   };
 
   class EmbeddedRefUpdater: public MetaspaceClosure {
@@ -786,11 +800,11 @@
 }
 
 size_t DynamicArchiveBuilder::estimate_trampoline_size() {
   size_t total = 0;
   size_t each_method_bytes =
-    align_up(SharedRuntime::trampoline_size(), BytesPerWord) +
+    align_up(SharedRuntime::trampoline_size(), BytesPerWord) * 3 +
     align_up(sizeof(AdapterHandlerEntry*), BytesPerWord);
 
   for (int i = 0; i < _klasses->length(); i++) {
     InstanceKlass* ik = _klasses->at(i);
     Array<Method*>* methods = ik->methods();
@@ -809,15 +823,27 @@
   for (int i = 0; i < _klasses->length(); i++) {
     InstanceKlass* ik = _klasses->at(i);
     Array<Method*>* methods = ik->methods();
     for (int j = 0; j < methods->length(); j++) {
       Method* m = methods->at(j);
+
+      // TODO:CDS - JDK-8234693 will consolidate this with Method::unlink()
       address c2i_entry_trampoline = (address)p;
       p += SharedRuntime::trampoline_size();
       assert(p >= mc_space->base() && p <= mc_space->top(), "must be");
       m->set_from_compiled_entry(to_target(c2i_entry_trampoline));
 
+      address c2i_value_ro_entry_trampoline = (address)p;
+      p += SharedRuntime::trampoline_size();
+      assert(p >= mc_space->base() && p <= mc_space->top(), "must be");
+      m->set_from_compiled_value_ro_entry(to_target(c2i_value_ro_entry_trampoline));
+
+      address c2i_value_entry_trampoline = (address)p;
+      p +=  SharedRuntime::trampoline_size();
+      assert(p >= mc_space->base() && p <= mc_space->top(), "must be");
+      m->set_from_compiled_value_entry(to_target(c2i_value_entry_trampoline));
+
       AdapterHandlerEntry** adapter_trampoline =(AdapterHandlerEntry**)p;
       p += sizeof(AdapterHandlerEntry*);
       assert(p >= mc_space->base() && p <= mc_space->top(), "must be");
       *adapter_trampoline = NULL;
       m->set_adapter_trampoline(to_target(adapter_trampoline));
diff a/src/hotspot/share/memory/metaspaceClosure.hpp b/src/hotspot/share/memory/metaspaceClosure.hpp
--- a/src/hotspot/share/memory/metaspaceClosure.hpp
+++ b/src/hotspot/share/memory/metaspaceClosure.hpp
@@ -75,11 +75,15 @@
     _not_writable,
     _default
   };
 
   enum SpecialRef {
-    _method_entry_ref
+    // A field that points to a method entry. E.g., Method::_i2i_entry
+    _method_entry_ref,
+
+    // A field that points to a location inside the current object.
+    _internal_pointer_ref,
   };
 
   // class MetaspaceClosure::Ref --
   //
   // MetaspaceClosure can be viewed as a very simple type of copying garbage
@@ -283,17 +287,25 @@
   template <class T> void push(T** mpp, Writability w = _default) {
     push_impl(new ObjectRef<T>(mpp, w));
   }
 
   template <class T> void push_method_entry(T** mpp, intptr_t* p) {
-    push_special(_method_entry_ref, new ObjectRef<T>(mpp, _default), (intptr_t*)p);
+    push_special(_method_entry_ref, new ObjectRef<T>(mpp, _default), p);
+  }
+
+  template <class T> void push_internal_pointer(T** mpp, intptr_t* p) {
+    push_special(_internal_pointer_ref, new ObjectRef<T>(mpp, _default), p);
   }
 
   // This is for tagging special pointers that are not a reference to MetaspaceObj. It's currently
   // used to mark the method entry points in Method/ConstMethod.
   virtual void push_special(SpecialRef type, Ref* obj, intptr_t* p) {
-    assert(type == _method_entry_ref, "only special type allowed for now");
+    assert_valid(type);
+  }
+
+  static void assert_valid(SpecialRef type) {
+    assert(type == _method_entry_ref || type == _internal_pointer_ref, "only special types allowed for now");
   }
 };
 
 // This is a special MetaspaceClosure that visits each unique MetaspaceObj once.
 class UniqueMetaspaceClosure : public MetaspaceClosure {
diff a/src/hotspot/share/memory/metaspaceShared.cpp b/src/hotspot/share/memory/metaspaceShared.cpp
--- a/src/hotspot/share/memory/metaspaceShared.cpp
+++ b/src/hotspot/share/memory/metaspaceShared.cpp
@@ -57,10 +57,12 @@
 #include "oops/methodData.hpp"
 #include "oops/objArrayKlass.hpp"
 #include "oops/objArrayOop.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/typeArrayKlass.hpp"
+#include "oops/valueArrayKlass.hpp"
+#include "oops/valueKlass.hpp"
 #include "prims/jvmtiRedefineClasses.hpp"
 #include "runtime/handles.inline.hpp"
 #include "runtime/os.hpp"
 #include "runtime/safepointVerifiers.hpp"
 #include "runtime/signature.hpp"
@@ -729,17 +731,19 @@
 //                  into our own tables.
 
 // Currently, the archive contain ONLY the following types of objects that have C++ vtables.
 #define CPP_VTABLE_PATCH_TYPES_DO(f) \
   f(ConstantPool) \
-  f(InstanceKlass) \
+  f(InstanceClassLoaderKlass) \
   f(InstanceClassLoaderKlass) \
   f(InstanceMirrorKlass) \
   f(InstanceRefKlass) \
   f(Method) \
   f(ObjArrayKlass) \
-  f(TypeArrayKlass)
+  f(TypeArrayKlass) \
+  f(ValueArrayKlass) \
+  f(ValueKlass)
 
 class CppVtableInfo {
   intptr_t _vtable_size;
   intptr_t _cloned_vtable[1];
 public:
@@ -923,11 +927,13 @@
     break;
   case MetaspaceObj::ClassType:
     {
       Klass* k = (Klass*)obj;
       assert(k->is_klass(), "must be");
-      if (k->is_instance_klass()) {
+      if (k->is_value()) {
+        kind = ValueKlass_Kind;
+      } else if (k->is_instance_klass()) {
         InstanceKlass* ik = InstanceKlass::cast(k);
         if (ik->is_class_loader_instance_klass()) {
           kind = InstanceClassLoaderKlass_Kind;
         } else if (ik->is_reference_instance_klass()) {
           kind = InstanceRefKlass_Kind;
@@ -1351,16 +1357,30 @@
       RefRelocator refer;
       ref->metaspace_pointers_do_at(&refer, new_loc);
       return true; // recurse into ref.obj()
     }
     virtual void push_special(SpecialRef type, Ref* ref, intptr_t* p) {
-      assert(type == _method_entry_ref, "only special type allowed for now");
+      assert_valid(type);
+
       address obj = ref->obj();
       address new_obj = get_new_loc(ref);
       size_t offset = pointer_delta(p, obj,  sizeof(u1));
       intptr_t* new_p = (intptr_t*)(new_obj + offset);
-      assert(*p == *new_p, "must be a copy");
+      switch (type) {
+      case _method_entry_ref:
+        assert(*p == *new_p, "must be a copy");
+        break;
+      case _internal_pointer_ref:
+        {
+          size_t off = pointer_delta(*((address*)p), obj, sizeof(u1));
+          assert(0 <= intx(off) && intx(off) < ref->size() * BytesPerWord, "must point to internal address");
+          *((address*)new_p) = new_obj + off;
+        }
+        break;
+      default:
+        ShouldNotReachHere();
+      }
       ArchivePtrMarker::mark_pointer((address*)new_p);
     }
   };
 
   // Relocate a reference to point to its shallow copy
diff a/src/hotspot/share/memory/universe.cpp b/src/hotspot/share/memory/universe.cpp
--- a/src/hotspot/share/memory/universe.cpp
+++ b/src/hotspot/share/memory/universe.cpp
@@ -114,10 +114,11 @@
 LatestMethodCache* Universe::_finalizer_register_cache = NULL;
 LatestMethodCache* Universe::_loader_addClass_cache    = NULL;
 LatestMethodCache* Universe::_throw_illegal_access_error_cache = NULL;
 LatestMethodCache* Universe::_throw_no_such_method_error_cache = NULL;
 LatestMethodCache* Universe::_do_stack_walk_cache     = NULL;
+LatestMethodCache* Universe::_is_substitutable_cache  = NULL;
 oop Universe::_out_of_memory_error_java_heap          = NULL;
 oop Universe::_out_of_memory_error_metaspace          = NULL;
 oop Universe::_out_of_memory_error_class_metaspace    = NULL;
 oop Universe::_out_of_memory_error_array_size         = NULL;
 oop Universe::_out_of_memory_error_gc_overhead_limit  = NULL;
@@ -136,10 +137,11 @@
 
 Array<int>* Universe::_the_empty_int_array            = NULL;
 Array<u2>* Universe::_the_empty_short_array           = NULL;
 Array<Klass*>* Universe::_the_empty_klass_array     = NULL;
 Array<InstanceKlass*>* Universe::_the_empty_instance_klass_array  = NULL;
+Array<InstanceKlass*>* Universe::_the_single_IdentityObject_klass_array = NULL;
 Array<Method*>* Universe::_the_empty_method_array   = NULL;
 
 // These variables are guarded by FullGCALot_lock.
 debug_only(objArrayOop Universe::_fullgc_alot_dummy_array = NULL;)
 debug_only(int Universe::_fullgc_alot_dummy_next      = 0;)
@@ -222,16 +224,18 @@
   it->push(&_the_empty_short_array);
   it->push(&_the_empty_klass_array);
   it->push(&_the_empty_instance_klass_array);
   it->push(&_the_empty_method_array);
   it->push(&_the_array_interfaces_array);
+  it->push(&_the_single_IdentityObject_klass_array);
 
   _finalizer_register_cache->metaspace_pointers_do(it);
   _loader_addClass_cache->metaspace_pointers_do(it);
   _throw_illegal_access_error_cache->metaspace_pointers_do(it);
   _throw_no_such_method_error_cache->metaspace_pointers_do(it);
   _do_stack_walk_cache->metaspace_pointers_do(it);
+  _is_substitutable_cache->metaspace_pointers_do(it);
 }
 
 #define ASSERT_MIRROR_NULL(m) \
   assert(m == NULL, "archived mirrors should be NULL");
 
@@ -259,15 +263,17 @@
   f->do_ptr((void**)&_the_empty_int_array);
   f->do_ptr((void**)&_the_empty_short_array);
   f->do_ptr((void**)&_the_empty_method_array);
   f->do_ptr((void**)&_the_empty_klass_array);
   f->do_ptr((void**)&_the_empty_instance_klass_array);
+  f->do_ptr((void**)&_the_single_IdentityObject_klass_array);
   _finalizer_register_cache->serialize(f);
   _loader_addClass_cache->serialize(f);
   _throw_illegal_access_error_cache->serialize(f);
   _throw_no_such_method_error_cache->serialize(f);
   _do_stack_walk_cache->serialize(f);
+  _is_substitutable_cache->serialize(f);
 }
 
 void Universe::check_alignment(uintx size, uintx alignment, const char* name) {
   if (size < alignment || size % alignment != 0) {
     vm_exit_during_initialization(
@@ -311,11 +317,11 @@
           _typeArrayKlassObjs[i] = TypeArrayKlass::create_klass((BasicType)i, CHECK);
         }
 
         ClassLoaderData* null_cld = ClassLoaderData::the_null_class_loader_data();
 
-        _the_array_interfaces_array     = MetadataFactory::new_array<Klass*>(null_cld, 2, NULL, CHECK);
+        _the_array_interfaces_array     = MetadataFactory::new_array<Klass*>(null_cld, 3, NULL, CHECK);
         _the_empty_int_array            = MetadataFactory::new_array<int>(null_cld, 0, CHECK);
         _the_empty_short_array          = MetadataFactory::new_array<u2>(null_cld, 0, CHECK);
         _the_empty_method_array         = MetadataFactory::new_array<Method*>(null_cld, 0, CHECK);
         _the_empty_klass_array          = MetadataFactory::new_array<Klass*>(null_cld, 0, CHECK);
         _the_empty_instance_klass_array = MetadataFactory::new_array<InstanceKlass*>(null_cld, 0, CHECK);
@@ -336,16 +342,22 @@
       // Verify shared interfaces array.
       assert(_the_array_interfaces_array->at(0) ==
              SystemDictionary::Cloneable_klass(), "u3");
       assert(_the_array_interfaces_array->at(1) ==
              SystemDictionary::Serializable_klass(), "u3");
+      assert(_the_array_interfaces_array->at(2) ==
+                   SystemDictionary::IdentityObject_klass(), "u3");
+
+      assert(_the_single_IdentityObject_klass_array->at(0) ==
+          SystemDictionary::IdentityObject_klass(), "u3");
     } else
 #endif
     {
       // Set up shared interfaces array.  (Do this before supers are set up.)
       _the_array_interfaces_array->at_put(0, SystemDictionary::Cloneable_klass());
       _the_array_interfaces_array->at_put(1, SystemDictionary::Serializable_klass());
+      _the_array_interfaces_array->at_put(2, SystemDictionary::IdentityObject_klass());
     }
 
     initialize_basic_type_klass(boolArrayKlassObj(), CHECK);
     initialize_basic_type_klass(charArrayKlassObj(), CHECK);
     initialize_basic_type_klass(floatArrayKlassObj(), CHECK);
@@ -463,10 +475,18 @@
     _mirrors[T_VOID]    = _void_mirror;
   //_mirrors[T_OBJECT]  = _object_klass->java_mirror();
   //_mirrors[T_ARRAY]   = _object_klass->java_mirror();
 }
 
+void Universe::initialize_the_single_IdentityObject_klass_array(InstanceKlass* ik, TRAPS) {
+    assert(_the_single_IdentityObject_klass_array == NULL, "Must not be initialized twice");
+    assert(ik->name() == vmSymbols::java_lang_IdentityObject(), "Must be");
+    Array<InstanceKlass*>* array = MetadataFactory::new_array<InstanceKlass*>(ik->class_loader_data(), 1, NULL, CHECK);
+    array->at_put(0, ik);
+    _the_single_IdentityObject_klass_array = array;
+  }
+
 void Universe::fixup_mirrors(TRAPS) {
   // Bootstrap problem: all classes gets a mirror (java.lang.Class instance) assigned eagerly,
   // but we cannot do that for classes created before java.lang.Class is loaded. Here we simply
   // walk over permanent objects created so far (mostly classes) and fixup their mirrors. Note
   // that the number of objects allocated at this point is very small.
@@ -659,11 +679,10 @@
   }
 
   Universe::initialize_tlab();
 
   Metaspace::global_initialize();
-
   // Initialize performance counters for metaspaces
   MetaspaceCounters::initialize_performance_counters();
   CompressedClassSpaceCounters::initialize_performance_counters();
 
   AOTLoader::universe_init();
@@ -682,10 +701,11 @@
   Universe::_finalizer_register_cache = new LatestMethodCache();
   Universe::_loader_addClass_cache    = new LatestMethodCache();
   Universe::_throw_illegal_access_error_cache = new LatestMethodCache();
   Universe::_throw_no_such_method_error_cache = new LatestMethodCache();
   Universe::_do_stack_walk_cache = new LatestMethodCache();
+  Universe::_is_substitutable_cache = new LatestMethodCache();
 
 #if INCLUDE_CDS
   if (UseSharedSpaces) {
     // Read the data structures supporting the shared spaces (shared
     // system dictionary, symbol table, etc.).  After that, access to
@@ -833,10 +853,17 @@
   // Set up method for stack walking
   initialize_known_method(_do_stack_walk_cache,
                           SystemDictionary::AbstractStackWalker_klass(),
                           "doStackWalk",
                           vmSymbols::doStackWalk_signature(), false, CHECK);
+
+  // Set up substitutability testing
+  ResourceMark rm;
+  initialize_known_method(_is_substitutable_cache,
+                          SystemDictionary::ValueBootstrapMethods_klass(),
+                          vmSymbols::isSubstitutable_name()->as_C_string(),
+                          vmSymbols::object_object_boolean_signature(), true, CHECK);
 }
 
 void universe2_init() {
   EXCEPTION_MARK;
   Universe::genesis(CATCH);
diff a/src/hotspot/share/oops/instanceKlass.cpp b/src/hotspot/share/oops/instanceKlass.cpp
--- a/src/hotspot/share/oops/instanceKlass.cpp
+++ b/src/hotspot/share/oops/instanceKlass.cpp
@@ -63,10 +63,11 @@
 #include "oops/klass.inline.hpp"
 #include "oops/method.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/recordComponent.hpp"
 #include "oops/symbol.hpp"
+#include "oops/valueKlass.hpp"
 #include "prims/jvmtiExport.hpp"
 #include "prims/jvmtiRedefineClasses.hpp"
 #include "prims/jvmtiThreadState.hpp"
 #include "prims/methodComparator.hpp"
 #include "runtime/atomic.hpp"
@@ -420,11 +421,13 @@
   const int size = InstanceKlass::size(parser.vtable_size(),
                                        parser.itable_size(),
                                        nonstatic_oop_map_size(parser.total_oop_map_count()),
                                        parser.is_interface(),
                                        parser.is_unsafe_anonymous(),
-                                       should_store_fingerprint(is_hidden_or_anonymous));
+                                       should_store_fingerprint(is_hidden_or_anonymous),
+                                       parser.has_flattenable_fields() ? parser.java_fields_count() : 0,
+                                       parser.is_inline_type());
 
   const Symbol* const class_name = parser.class_name();
   assert(class_name != NULL, "invariant");
   ClassLoaderData* loader_data = parser.loader_data();
   assert(loader_data != NULL, "invariant");
@@ -434,14 +437,16 @@
   // Allocation
   if (REF_NONE == parser.reference_type()) {
     if (class_name == vmSymbols::java_lang_Class()) {
       // mirror
       ik = new (loader_data, size, THREAD) InstanceMirrorKlass(parser);
-    }
-    else if (is_class_loader(class_name, parser)) {
+    } else if (is_class_loader(class_name, parser)) {
       // class loader
       ik = new (loader_data, size, THREAD) InstanceClassLoaderKlass(parser);
+    } else if (parser.is_inline_type()) {
+      // inline type
+      ik = new (loader_data, size, THREAD) ValueKlass(parser);
     } else {
       // normal
       ik = new (loader_data, size, THREAD) InstanceKlass(parser, InstanceKlass::_kind_other);
     }
   } else {
@@ -453,13 +458,43 @@
   // class count.  Can get OOM here.
   if (HAS_PENDING_EXCEPTION) {
     return NULL;
   }
 
+#ifdef ASSERT
+  assert(ik->size() == size, "");
+  ik->bounds_check((address) ik->start_of_vtable(), false, size);
+  ik->bounds_check((address) ik->start_of_itable(), false, size);
+  ik->bounds_check((address) ik->end_of_itable(), true, size);
+  ik->bounds_check((address) ik->end_of_nonstatic_oop_maps(), true, size);
+#endif //ASSERT
   return ik;
 }
 
+#ifndef PRODUCT
+bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {
+  const char* bad = NULL;
+  address end = NULL;
+  if (addr < (address)this) {
+    bad = "before";
+  } else if (addr == (address)this) {
+    if (edge_ok)  return true;
+    bad = "just before";
+  } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes < 0 ? size() : size_in_bytes))) {
+    if (edge_ok)  return true;
+    bad = "just after";
+  } else if (addr > end) {
+    bad = "after";
+  } else {
+    return true;
+  }
+  tty->print_cr("%s object bounds: " INTPTR_FORMAT " [" INTPTR_FORMAT ".." INTPTR_FORMAT "]",
+      bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);
+  Verbose = WizardMode = true; this->print(); //@@
+  return false;
+}
+#endif //PRODUCT
 
 // copy method ordering from resource area to Metaspace
 void InstanceKlass::copy_method_ordering(const intArray* m, TRAPS) {
   if (m != NULL) {
     // allocate a new array and copy contents (memcpy?)
@@ -489,29 +524,38 @@
   _nonstatic_oop_map_size(nonstatic_oop_map_size(parser.total_oop_map_count())),
   _itable_len(parser.itable_size()),
   _nest_host_index(0),
   _init_state(allocated),
   _reference_type(parser.reference_type()),
-  _init_thread(NULL)
+  _init_thread(NULL),
+  _value_field_klasses(NULL),
+  _adr_valueklass_fixed_block(NULL)
 {
   set_vtable_length(parser.vtable_size());
   set_kind(kind);
   set_access_flags(parser.access_flags());
   if (parser.is_hidden()) set_is_hidden();
   set_is_unsafe_anonymous(parser.is_unsafe_anonymous());
   set_layout_helper(Klass::instance_layout_helper(parser.layout_size(),
                                                     false));
+    if (parser.has_flattenable_fields()) {
+      set_has_inline_fields();
+    }
+    _java_fields_count = parser.java_fields_count();
 
-  assert(NULL == _methods, "underlying memory not zeroed?");
-  assert(is_instance_klass(), "is layout incorrect?");
-  assert(size_helper() == parser.layout_size(), "incorrect size_helper?");
+    assert(NULL == _methods, "underlying memory not zeroed?");
+    assert(is_instance_klass(), "is layout incorrect?");
+    assert(size_helper() == parser.layout_size(), "incorrect size_helper?");
 
   // Set biased locking bit for all instances of this class; it will be
   // cleared if revocation occurs too often for this type
   if (UseBiasedLocking && BiasedLocking::enabled()) {
     set_prototype_header(markWord::biased_locking_prototype());
   }
+  if (has_inline_fields()) {
+    _value_field_klasses = (const Klass**) adr_value_fields_klasses();
+  }
 }
 
 void InstanceKlass::deallocate_methods(ClassLoaderData* loader_data,
                                        Array<Method*>* methods) {
   if (methods != NULL && methods != Universe::the_empty_method_array() &&
@@ -537,18 +581,20 @@
   Array<InstanceKlass*>* ti = transitive_interfaces;
   if (ti != Universe::the_empty_instance_klass_array() && ti != local_interfaces) {
     // check that the interfaces don't come from super class
     Array<InstanceKlass*>* sti = (super_klass == NULL) ? NULL :
                     InstanceKlass::cast(super_klass)->transitive_interfaces();
-    if (ti != sti && ti != NULL && !ti->is_shared()) {
+    if (ti != sti && ti != NULL && !ti->is_shared() &&
+        ti != Universe::the_single_IdentityObject_klass_array()) {
       MetadataFactory::free_array<InstanceKlass*>(loader_data, ti);
     }
   }
 
   // local interfaces can be empty
   if (local_interfaces != Universe::the_empty_instance_klass_array() &&
-      local_interfaces != NULL && !local_interfaces->is_shared()) {
+      local_interfaces != NULL && !local_interfaces->is_shared() &&
+      local_interfaces != Universe::the_single_IdentityObject_klass_array()) {
     MetadataFactory::free_array<InstanceKlass*>(loader_data, local_interfaces);
   }
 }
 
 void InstanceKlass::deallocate_record_components(ClassLoaderData* loader_data,
@@ -859,10 +905,66 @@
   for (int index = 0; index < num_interfaces; index++) {
     InstanceKlass* interk = interfaces->at(index);
     interk->link_class_impl(CHECK_false);
   }
 
+
+  // If a class declares a method that uses an inline class as an argument
+  // type or return inline type, this inline class must be loaded during the
+  // linking of this class because size and properties of the inline class
+  // must be known in order to be able to perform inline type optimizations.
+  // The implementation below is an approximation of this rule, the code
+  // iterates over all methods of the current class (including overridden
+  // methods), not only the methods declared by this class. This
+  // approximation makes the code simpler, and doesn't change the semantic
+  // because classes declaring methods overridden by the current class are
+  // linked (and have performed their own pre-loading) before the linking
+  // of the current class.
+
+
+  // Note:
+  // Inline class types used for flattenable fields are loaded during
+  // the loading phase (see ClassFileParser::post_process_parsed_stream()).
+  // Inline class types used as element types for array creation
+  // are not pre-loaded. Their loading is triggered by either anewarray
+  // or multianewarray bytecodes.
+
+  // Could it be possible to do the following processing only if the
+  // class uses inline types?
+  {
+    ResourceMark rm(THREAD);
+    for (int i = 0; i < methods()->length(); i++) {
+      Method* m = methods()->at(i);
+      for (SignatureStream ss(m->signature()); !ss.is_done(); ss.next()) {
+        if (ss.is_reference()) {
+          if (ss.is_array()) {
+            ss.skip_array_prefix();
+          }
+          if (ss.type() == T_VALUETYPE) {
+            Symbol* symb = ss.as_symbol();
+
+            oop loader = class_loader();
+            oop protection_domain = this->protection_domain();
+            Klass* klass = SystemDictionary::resolve_or_fail(symb,
+                                                             Handle(THREAD, loader), Handle(THREAD, protection_domain), true,
+                                                             CHECK_false);
+            if (klass == NULL) {
+              THROW_(vmSymbols::java_lang_LinkageError(), false);
+            }
+            if (!klass->is_value()) {
+              Exceptions::fthrow(
+                THREAD_AND_LOCATION,
+                vmSymbols::java_lang_IncompatibleClassChangeError(),
+                "class %s is not an inline type",
+                klass->external_name());
+            }
+          }
+        }
+      }
+    }
+  }
+
   // in case the class is linked in the process of linking its superclasses
   if (is_linked()) {
     return true;
   }
 
@@ -930,10 +1032,11 @@
 #ifdef ASSERT
       vtable().verify(tty, true);
       // In case itable verification is ever added.
       // itable().verify(tty, true);
 #endif
+
       set_init_state(linked);
       if (JvmtiExport::should_post_class_prepare()) {
         Thread *thread = THREAD;
         assert(thread->is_Java_thread(), "thread->is_Java_thread()");
         JvmtiExport::post_class_prepare((JavaThread *) thread, this);
@@ -1083,15 +1186,46 @@
       DTRACE_CLASSINIT_PROBE_WAIT(super__failed, -1, wait);
       THROW_OOP(e());
     }
   }
 
+  // Step 8
+  // Initialize classes of flattenable fields
+  {
+    for (AllFieldStream fs(this); !fs.done(); fs.next()) {
+      if (fs.is_flattenable()) {
+        Klass* klass = this->get_value_field_klass_or_null(fs.index());
+        if (klass == NULL) {
+          assert(fs.access_flags().is_static() && fs.access_flags().is_flattenable(),
+              "Otherwise should have been pre-loaded");
+          klass = SystemDictionary::resolve_or_fail(field_signature(fs.index())->fundamental_name(THREAD),
+              Handle(THREAD, class_loader()),
+              Handle(THREAD, protection_domain()),
+              true, CHECK);
+          if (klass == NULL) {
+            THROW(vmSymbols::java_lang_NoClassDefFoundError());
+          }
+          if (!klass->is_value()) {
+            THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
+          }
+          this->set_value_field_klass(fs.index(), klass);
+        }
+        InstanceKlass::cast(klass)->initialize(CHECK);
+        if (fs.access_flags().is_static()) {
+          if (java_mirror()->obj_field(fs.offset()) == NULL) {
+            java_mirror()->obj_field_put(fs.offset(), ValueKlass::cast(klass)->default_value());
+          }
+        }
+      }
+    }
+  }
+
 
   // Look for aot compiled methods for this klass, including class initializer.
   AOTLoader::load_for_klass(this, THREAD);
 
-  // Step 8
+  // Step 9
   {
     DTRACE_CLASSINIT_PROBE_WAIT(clinit, -1, wait);
     // Timer includes any side effects of class initialization (resolution,
     // etc), but not recursive entry into call_class_initializer().
     PerfClassTraceTime timer(ClassLoader::perf_class_init_time(),
@@ -1101,19 +1235,19 @@
                              jt->get_thread_stat()->perf_timers_addr(),
                              PerfClassTraceTime::CLASS_CLINIT);
     call_class_initializer(THREAD);
   }
 
-  // Step 9
+  // Step 10
   if (!HAS_PENDING_EXCEPTION) {
     set_initialization_state_and_notify(fully_initialized, CHECK);
     {
       debug_only(vtable().verify(tty, true);)
     }
   }
   else {
-    // Step 10 and 11
+    // Step 11 and 12
     Handle e(THREAD, PENDING_EXCEPTION);
     CLEAR_PENDING_EXCEPTION;
     // JVMTI has already reported the pending exception
     // JVMTI internal flag reset is needed in order to report ExceptionInInitializerError
     JvmtiExport::clear_detected_exception(jt);
@@ -1397,11 +1531,11 @@
 static int call_class_initializer_counter = 0;   // for debugging
 
 Method* InstanceKlass::class_initializer() const {
   Method* clinit = find_method(
       vmSymbols::class_initializer_name(), vmSymbols::void_method_signature());
-  if (clinit != NULL && clinit->has_valid_initializer_flags()) {
+  if (clinit != NULL && clinit->is_class_initializer()) {
     return clinit;
   }
   return NULL;
 }
 
@@ -1435,11 +1569,11 @@
   InterpreterOopMap* entry_for) {
   // Lazily create the _oop_map_cache at first request
   // Lock-free access requires load_acquire.
   OopMapCache* oop_map_cache = Atomic::load_acquire(&_oop_map_cache);
   if (oop_map_cache == NULL) {
-    MutexLocker x(OopMapCacheAlloc_lock);
+    MutexLocker x(OopMapCacheAlloc_lock,  Mutex::_no_safepoint_check_flag);
     // Check if _oop_map_cache was allocated while we were waiting for this lock
     if ((oop_map_cache = _oop_map_cache) == NULL) {
       oop_map_cache = new OopMapCache();
       // Ensure _oop_map_cache is stable, since it is examined without a lock
       Atomic::release_store(&_oop_map_cache, oop_map_cache);
@@ -1447,15 +1581,10 @@
   }
   // _oop_map_cache is constant after init; lookup below does its own locking.
   oop_map_cache->lookup(method, bci, entry_for);
 }
 
-bool InstanceKlass::contains_field_offset(int offset) {
-  fieldDescriptor fd;
-  return find_field_from_offset(offset, false, &fd);
-}
-
 bool InstanceKlass::find_local_field(Symbol* name, Symbol* sig, fieldDescriptor* fd) const {
   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
     Symbol* f_name = fs.name();
     Symbol* f_sig  = fs.signature();
     if (f_name == name && f_sig == sig) {
@@ -1522,10 +1651,19 @@
   }
   // 4) otherwise field lookup fails
   return NULL;
 }
 
+bool InstanceKlass::contains_field_offset(int offset) {
+  if (this->is_value()) {
+    ValueKlass* vk = ValueKlass::cast(this);
+    return offset >= vk->first_field_offset() && offset < (vk->first_field_offset() + vk->get_exact_size_in_bytes());
+  } else {
+    fieldDescriptor fd;
+    return find_field_from_offset(offset, false, &fd);
+  }
+}
 
 bool InstanceKlass::find_local_field_from_offset(int offset, bool is_static, fieldDescriptor* fd) const {
   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
     if (fs.offset() == offset) {
       fd->reinitialize(const_cast<InstanceKlass*>(this), fs.index());
@@ -1906,10 +2044,13 @@
                                                                         find_static,
                                                                         private_mode);
     if (method != NULL) {
       return method;
     }
+    if (name == vmSymbols::object_initializer_name()) {
+      break;  // <init> is never inherited, not even as a static factory
+    }
     klass = klass->super();
     overpass_local_mode = skip_overpass;   // Always ignore overpass methods in superclasses
   }
   return NULL;
 }
@@ -2487,10 +2628,14 @@
   // sure the current state is <loaded.
   assert(!is_loaded(), "invalid init state");
   set_package(loader_data, pkg_entry, CHECK);
   Klass::restore_unshareable_info(loader_data, protection_domain, CHECK);
 
+  if (is_value()) {
+    ValueKlass::cast(this)->initialize_calling_convention(CHECK);
+  }
+
   Array<Method*>* methods = this->methods();
   int num_methods = methods->length();
   for (int index = 0; index < num_methods; ++index) {
     methods->at(index)->restore_unshareable_info(CHECK);
   }
@@ -2512,11 +2657,11 @@
     // --> see ArrayKlass::complete_create_array_klass()
     array_klasses()->restore_unshareable_info(ClassLoaderData::the_null_class_loader_data(), Handle(), CHECK);
   }
 
   // Initialize current biased locking state.
-  if (UseBiasedLocking && BiasedLocking::enabled()) {
+  if (UseBiasedLocking && BiasedLocking::enabled() && !is_value()) {
     set_prototype_header(markWord::biased_locking_prototype());
   }
 }
 
 void InstanceKlass::set_shared_class_loader_type(s2 loader_type) {
@@ -2664,13 +2809,13 @@
   const char* src = (const char*) (name()->as_C_string());
   const int src_length = (int)strlen(src);
 
   char* dest = NEW_RESOURCE_ARRAY(char, src_length + hash_len + 3);
 
-  // Add L as type indicator
+  // Add L or Q as type indicator
   int dest_index = 0;
-  dest[dest_index++] = JVM_SIGNATURE_CLASS;
+  dest[dest_index++] = is_value() ? JVM_SIGNATURE_VALUETYPE : JVM_SIGNATURE_CLASS;
 
   // Add the actual class name
   for (int src_index = 0; src_index < src_length; ) {
     dest[dest_index++] = src[src_index++];
   }
@@ -3226,33 +3371,69 @@
 
 static const char* state_names[] = {
   "allocated", "loaded", "linked", "being_initialized", "fully_initialized", "initialization_error"
 };
 
-static void print_vtable(intptr_t* start, int len, outputStream* st) {
+static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {
+  ResourceMark rm;
+  int* forward_refs = NEW_RESOURCE_ARRAY(int, len);
+  for (int i = 0; i < len; i++)  forward_refs[i] = 0;
   for (int i = 0; i < len; i++) {
     intptr_t e = start[i];
     st->print("%d : " INTPTR_FORMAT, i, e);
+    if (forward_refs[i] != 0) {
+      int from = forward_refs[i];
+      int off = (int) start[from];
+      st->print(" (offset %d <= [%d])", off, from);
+    }
     if (MetaspaceObj::is_valid((Metadata*)e)) {
       st->print(" ");
       ((Metadata*)e)->print_value_on(st);
+    } else if (self != NULL && e > 0 && e < 0x10000) {
+      address location = self + e;
+      int index = (int)((intptr_t*)location - start);
+      st->print(" (offset %d => [%d])", (int)e, index);
+      if (index >= 0 && index < len)
+        forward_refs[index] = i;
     }
     st->cr();
   }
 }
 
 static void print_vtable(vtableEntry* start, int len, outputStream* st) {
-  return print_vtable(reinterpret_cast<intptr_t*>(start), len, st);
+  return print_vtable(NULL, reinterpret_cast<intptr_t*>(start), len, st);
+}
+
+template<typename T>
+ static void print_array_on(outputStream* st, Array<T>* array) {
+   if (array == NULL) { st->print_cr("NULL"); return; }
+   array->print_value_on(st); st->cr();
+   if (Verbose || WizardMode) {
+     for (int i = 0; i < array->length(); i++) {
+       st->print("%d : ", i); array->at(i)->print_value_on(st); st->cr();
+     }
+   }
+ }
+
+static void print_array_on(outputStream* st, Array<int>* array) {
+  if (array == NULL) { st->print_cr("NULL"); return; }
+  array->print_value_on(st); st->cr();
+  if (Verbose || WizardMode) {
+    for (int i = 0; i < array->length(); i++) {
+      st->print("%d : %d", i, array->at(i)); st->cr();
+    }
+  }
 }
 
 void InstanceKlass::print_on(outputStream* st) const {
   assert(is_klass(), "must be klass");
   Klass::print_on(st);
 
   st->print(BULLET"instance size:     %d", size_helper());                        st->cr();
   st->print(BULLET"klass size:        %d", size());                               st->cr();
   st->print(BULLET"access:            "); access_flags().print_on(st);            st->cr();
+  st->print(BULLET"misc flags:        0x%x", _misc_flags);                        st->cr();
   st->print(BULLET"state:             "); st->print_cr("%s", state_names[_init_state]);
   st->print(BULLET"name:              "); name()->print_value_on(st);             st->cr();
   st->print(BULLET"super:             "); Metadata::print_value_on_maybe_null(st, super()); st->cr();
   st->print(BULLET"sub:               ");
   Klass* sub = subklass();
@@ -3275,30 +3456,18 @@
       st->cr();
     }
   }
 
   st->print(BULLET"arrays:            "); Metadata::print_value_on_maybe_null(st, array_klasses()); st->cr();
-  st->print(BULLET"methods:           "); methods()->print_value_on(st);                  st->cr();
-  if (Verbose || WizardMode) {
-    Array<Method*>* method_array = methods();
-    for (int i = 0; i < method_array->length(); i++) {
-      st->print("%d : ", i); method_array->at(i)->print_value(); st->cr();
-    }
-  }
-  st->print(BULLET"method ordering:   "); method_ordering()->print_value_on(st);      st->cr();
-  st->print(BULLET"default_methods:   "); default_methods()->print_value_on(st);      st->cr();
-  if (Verbose && default_methods() != NULL) {
-    Array<Method*>* method_array = default_methods();
-    for (int i = 0; i < method_array->length(); i++) {
-      st->print("%d : ", i); method_array->at(i)->print_value(); st->cr();
-    }
-  }
+  st->print(BULLET"methods:           "); print_array_on(st, methods());
+  st->print(BULLET"method ordering:   "); print_array_on(st, method_ordering());
+  st->print(BULLET"default_methods:   "); print_array_on(st, default_methods());
   if (default_vtable_indices() != NULL) {
-    st->print(BULLET"default vtable indices:   "); default_vtable_indices()->print_value_on(st);       st->cr();
+    st->print(BULLET"default vtable indices:   "); print_array_on(st, default_vtable_indices());
   }
-  st->print(BULLET"local interfaces:  "); local_interfaces()->print_value_on(st);      st->cr();
-  st->print(BULLET"trans. interfaces: "); transitive_interfaces()->print_value_on(st); st->cr();
+  st->print(BULLET"local interfaces:  "); print_array_on(st, local_interfaces());
+  st->print(BULLET"trans. interfaces: "); print_array_on(st, transitive_interfaces());
   st->print(BULLET"constants:         "); constants()->print_value_on(st);         st->cr();
   if (class_loader_data() != NULL) {
     st->print(BULLET"class loader data:  ");
     class_loader_data()->print_value_on(st);
     st->cr();
@@ -3350,11 +3519,11 @@
     st->print_cr(BULLET"java mirror:       NULL");
   }
   st->print(BULLET"vtable length      %d  (start addr: " INTPTR_FORMAT ")", vtable_length(), p2i(start_of_vtable())); st->cr();
   if (vtable_length() > 0 && (Verbose || WizardMode))  print_vtable(start_of_vtable(), vtable_length(), st);
   st->print(BULLET"itable length      %d (start addr: " INTPTR_FORMAT ")", itable_length(), p2i(start_of_itable())); st->cr();
-  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(start_of_itable(), itable_length(), st);
+  if (itable_length() > 0 && (Verbose || WizardMode))  print_vtable(NULL, start_of_itable(), itable_length(), st);
   st->print_cr(BULLET"---- static fields (%d words):", static_field_size());
   FieldPrinter print_static_field(st);
   ((InstanceKlass*)this)->do_local_static_fields(&print_static_field);
   st->print_cr(BULLET"---- non-static fields (%d words):", nonstatic_field_size());
   FieldPrinter print_nonstatic_field(st);
@@ -4086,5 +4255,10 @@
 
 unsigned char * InstanceKlass::get_cached_class_file_bytes() {
   return VM_RedefineClasses::get_cached_class_file_bytes(_cached_class_file);
 }
 #endif
+
+#define THROW_DVT_ERROR(s) \
+  Exceptions::fthrow(THREAD_AND_LOCATION, vmSymbols::java_lang_IncompatibleClassChangeError(), \
+      "ValueCapableClass class '%s' %s", external_name(),(s)); \
+      return
diff a/src/hotspot/share/oops/klass.cpp b/src/hotspot/share/oops/klass.cpp
--- a/src/hotspot/share/oops/klass.cpp
+++ b/src/hotspot/share/oops/klass.cpp
@@ -212,11 +212,11 @@
   // Note that T_ARRAY is not allowed here.
   int  hsize = arrayOopDesc::base_offset_in_bytes(etype);
   int  esize = type2aelembytes(etype);
   bool isobj = (etype == T_OBJECT);
   int  tag   =  isobj ? _lh_array_tag_obj_value : _lh_array_tag_type_value;
-  int lh = array_layout_helper(tag, hsize, etype, exact_log2(esize));
+  int lh = array_layout_helper(tag, false, hsize, etype, exact_log2(esize));
 
   assert(lh < (int)_lh_neutral_value, "must look like an array layout");
   assert(layout_helper_is_array(lh), "correct kind");
   assert(layout_helper_is_objArray(lh) == isobj, "correct kind");
   assert(layout_helper_is_typeArray(lh) == !isobj, "correct kind");
diff a/src/hotspot/share/oops/oopsHierarchy.hpp b/src/hotspot/share/oops/oopsHierarchy.hpp
--- a/src/hotspot/share/oops/oopsHierarchy.hpp
+++ b/src/hotspot/share/oops/oopsHierarchy.hpp
@@ -45,10 +45,11 @@
 typedef class oopDesc*                    oop;
 typedef class   instanceOopDesc*            instanceOop;
 typedef class   arrayOopDesc*               arrayOop;
 typedef class     objArrayOopDesc*            objArrayOop;
 typedef class     typeArrayOopDesc*           typeArrayOop;
+typedef class     valueArrayOopDesc*          valueArrayOop;
 
 #else
 
 // When CHECK_UNHANDLED_OOPS is defined, an "oop" is a class with a
 // carefully chosen set of constructors and conversion operators to go
@@ -142,10 +143,11 @@
 
 DEF_OOP(instance);
 DEF_OOP(array);
 DEF_OOP(objArray);
 DEF_OOP(typeArray);
+DEF_OOP(valueArray);
 
 #endif // CHECK_UNHANDLED_OOPS
 
 // For CHECK_UNHANDLED_OOPS, it is ambiguous C++ behavior to have the oop
 // structure contain explicit user defined conversions of both numerical
@@ -175,10 +177,12 @@
 class Klass;
 class   InstanceKlass;
 class     InstanceMirrorKlass;
 class     InstanceClassLoaderKlass;
 class     InstanceRefKlass;
+class     ValueKlass;
 class   ArrayKlass;
 class     ObjArrayKlass;
 class     TypeArrayKlass;
+class     ValueArrayKlass;
 
 #endif // SHARE_OOPS_OOPSHIERARCHY_HPP
diff a/src/hotspot/share/opto/addnode.cpp b/src/hotspot/share/opto/addnode.cpp
--- a/src/hotspot/share/opto/addnode.cpp
+++ b/src/hotspot/share/opto/addnode.cpp
@@ -654,10 +654,16 @@
   const TypeX *tx = t->is_intptr_t();
   intptr_t txoffset = Type::OffsetBot;
   if (tx->is_con()) {   // Left input is an add of a constant?
     txoffset = tx->get_con();
   }
+  if (tp->isa_aryptr()) {
+    // In the case of a flattened value type array, each field has its
+    // own slice so we need to extract the field being accessed from
+    // the address computation
+    return tp->is_aryptr()->add_field_offset_and_offset(txoffset);
+  }
   return tp->add_offset(txoffset);
 }
 
 //------------------------------Value------------------------------------------
 const Type* AddPNode::Value(PhaseGVN* phase) const {
@@ -674,10 +680,16 @@
   // Add 'em
   intptr_t p2offset = Type::OffsetBot;
   if (p2->is_con()) {   // Left input is an add of a constant?
     p2offset = p2->get_con();
   }
+  if (p1->isa_aryptr()) {
+    // In the case of a flattened value type array, each field has its
+    // own slice so we need to extract the field being accessed from
+    // the address computation
+    return p1->is_aryptr()->add_field_offset_and_offset(p2offset);
+  }
   return p1->add_offset(p2offset);
 }
 
 //------------------------Ideal_base_and_offset--------------------------------
 // Split an oop pointer into a base and offset.
diff a/src/hotspot/share/opto/c2_globals.hpp b/src/hotspot/share/opto/c2_globals.hpp
--- a/src/hotspot/share/opto/c2_globals.hpp
+++ b/src/hotspot/share/opto/c2_globals.hpp
@@ -776,9 +776,12 @@
           range(0, max_juint)                                               \
                                                                             \
   product(bool, UseProfiledLoopPredicate, true,                             \
           "Move predicates out of loops based on profiling data")           \
                                                                             \
+  product(bool, UseArrayLoadStoreProfile, false,                            \
+          "Take advantage of profiling at array load/store")                \
+                                                                            \
   diagnostic(bool, ExpandSubTypeCheckAtParseTime, false,                    \
           "Do not use subtype check macro node")                            \
 
 #endif // SHARE_OPTO_C2_GLOBALS_HPP
diff a/src/hotspot/share/opto/c2compiler.cpp b/src/hotspot/share/opto/c2compiler.cpp
--- a/src/hotspot/share/opto/c2compiler.cpp
+++ b/src/hotspot/share/opto/c2compiler.cpp
@@ -497,28 +497,32 @@
   case vmIntrinsics::_indexOfU_char:
   case vmIntrinsics::_toBytesStringU:
   case vmIntrinsics::_getCharsStringU:
   case vmIntrinsics::_getCharStringU:
   case vmIntrinsics::_putCharStringU:
+  case vmIntrinsics::_makePrivateBuffer:
+  case vmIntrinsics::_finishPrivateBuffer:
   case vmIntrinsics::_getReference:
   case vmIntrinsics::_getBoolean:
   case vmIntrinsics::_getByte:
   case vmIntrinsics::_getShort:
   case vmIntrinsics::_getChar:
   case vmIntrinsics::_getInt:
   case vmIntrinsics::_getLong:
   case vmIntrinsics::_getFloat:
   case vmIntrinsics::_getDouble:
+  case vmIntrinsics::_getValue:
   case vmIntrinsics::_putReference:
   case vmIntrinsics::_putBoolean:
   case vmIntrinsics::_putByte:
   case vmIntrinsics::_putShort:
   case vmIntrinsics::_putChar:
   case vmIntrinsics::_putInt:
   case vmIntrinsics::_putLong:
   case vmIntrinsics::_putFloat:
   case vmIntrinsics::_putDouble:
+  case vmIntrinsics::_putValue:
   case vmIntrinsics::_getReferenceVolatile:
   case vmIntrinsics::_getBooleanVolatile:
   case vmIntrinsics::_getByteVolatile:
   case vmIntrinsics::_getShortVolatile:
   case vmIntrinsics::_getCharVolatile:
diff a/src/hotspot/share/opto/chaitin.cpp b/src/hotspot/share/opto/chaitin.cpp
--- a/src/hotspot/share/opto/chaitin.cpp
+++ b/src/hotspot/share/opto/chaitin.cpp
@@ -1662,14 +1662,14 @@
   // NOTE: we use TypePtr instead of TypeOopPtr because we can have
   // pointers derived from NULL!  These are always along paths that
   // can't happen at run-time but the optimizer cannot deduce it so
   // we have to handle it gracefully.
   assert(!derived->bottom_type()->isa_narrowoop() ||
-          derived->bottom_type()->make_ptr()->is_ptr()->_offset == 0, "sanity");
+         derived->bottom_type()->make_ptr()->is_ptr()->offset() == 0, "sanity");
   const TypePtr *tj = derived->bottom_type()->isa_ptr();
   // If its an OOP with a non-zero offset, then it is derived.
-  if( tj == NULL || tj->_offset == 0 ) {
+  if (tj == NULL || tj->offset() == 0) {
     derived_base_map[derived->_idx] = derived;
     return derived;
   }
   // Derived is NULL+offset?  Base is NULL!
   if( derived->is_Con() ) {
@@ -1831,13 +1831,13 @@
           // Find reaching DEF for base and derived values
           // This works because we are still in SSA during this call.
           Node *derived = lrgs(neighbor)._def;
           const TypePtr *tj = derived->bottom_type()->isa_ptr();
           assert(!derived->bottom_type()->isa_narrowoop() ||
-                  derived->bottom_type()->make_ptr()->is_ptr()->_offset == 0, "sanity");
+                 derived->bottom_type()->make_ptr()->is_ptr()->offset() == 0, "sanity");
           // If its an OOP with a non-zero offset, then it is derived.
-          if( tj && tj->_offset != 0 && tj->isa_oop_ptr() ) {
+          if (tj && tj->offset() != 0 && tj->isa_oop_ptr()) {
             Node *base = find_base_for_derived(derived_base_map, derived, maxlrg);
             assert(base->_idx < _lrg_map.size(), "");
             // Add reaching DEFs of derived pointer and base pointer as a
             // pair of inputs
             n->add_req(derived);
@@ -2123,11 +2123,11 @@
   }
 }
 
 void PhaseChaitin::dump_frame() const {
   const char *fp = OptoReg::regname(OptoReg::c_frame_pointer);
-  const TypeTuple *domain = C->tf()->domain();
+  const TypeTuple *domain = C->tf()->domain_cc();
   const int        argcnt = domain->cnt() - TypeFunc::Parms;
 
   // Incoming arguments in registers dump
   for( int k = 0; k < argcnt; k++ ) {
     OptoReg::Name parmreg = _matcher._parm_regs[k].first();
@@ -2160,10 +2160,15 @@
     for( j = 0; j < argcnt; j++) {
       if( _matcher._parm_regs[j].first() == reg ||
           _matcher._parm_regs[j].second() == reg ) {
         tty->print("parm %d: ",j);
         domain->field_at(j + TypeFunc::Parms)->dump();
+        if (!C->FIRST_STACK_mask().Member(reg)) {
+          // Reserved entry in the argument stack area that is not used because
+          // it may hold the return address (see Matcher::init_first_stack_mask()).
+          tty->print(" [RESERVED] ");
+        }
         tty->cr();
         break;
       }
     }
     if( j >= argcnt )
diff a/src/hotspot/share/opto/generateOptoStub.cpp b/src/hotspot/share/opto/generateOptoStub.cpp
--- a/src/hotspot/share/opto/generateOptoStub.cpp
+++ b/src/hotspot/share/opto/generateOptoStub.cpp
@@ -45,12 +45,12 @@
                         int is_fancy_jump,
                         bool pass_tls,
                         bool return_pc) {
   ResourceMark rm;
 
-  const TypeTuple *jdomain = C->tf()->domain();
-  const TypeTuple *jrange  = C->tf()->range();
+  const TypeTuple *jdomain = C->tf()->domain_sig();
+  const TypeTuple *jrange  = C->tf()->range_sig();
 
   // The procedure start
   StartNode* start = new StartNode(root(), jdomain);
   _gvn.set_type_bottom(start);
 
@@ -274,11 +274,11 @@
     ret = new ReturnNode(TypeFunc::Parms, if_null,
                          i_o(),
                          exit_memory,
                          frameptr(),
                          returnadr());
-    if (C->tf()->range()->cnt() > TypeFunc::Parms)
+    if (C->tf()->range_sig()->cnt() > TypeFunc::Parms)
       ret->add_req( map()->in(TypeFunc::Parms) );
     break;
   case 1:    // This is a fancy tail-call jump.  Jump to computed address.
     // Jump to new callee; leave old return address alone.
     ret = new TailCallNode(if_null,
diff a/src/hotspot/share/opto/loopnode.hpp b/src/hotspot/share/opto/loopnode.hpp
--- a/src/hotspot/share/opto/loopnode.hpp
+++ b/src/hotspot/share/opto/loopnode.hpp
@@ -74,11 +74,12 @@
          HasAtomicPostLoop=4096,
          HasRangeChecks=8192,
          IsMultiversioned=16384,
          StripMined=32768,
          SubwordLoop=65536,
-         ProfileTripFailed=131072};
+         ProfileTripFailed=131072,
+         FlattenedArrays=262144};
   char _unswitch_count;
   enum { _unswitch_max=3 };
   char _postloop_flags;
   enum { LoopNotRCEChecked = 0, LoopRCEChecked = 1, RCEPostLoop = 2 };
 
@@ -99,10 +100,11 @@
   void set_partial_peel_loop() { _loop_flags |= PartialPeelLoop; }
   bool partial_peel_has_failed() const { return _loop_flags & PartialPeelFailed; }
   bool is_strip_mined() const { return _loop_flags & StripMined; }
   bool is_profile_trip_failed() const { return _loop_flags & ProfileTripFailed; }
   bool is_subword_loop() const { return _loop_flags & SubwordLoop; }
+  bool is_flattened_arrays() const { return _loop_flags & FlattenedArrays; }
 
   void mark_partial_peel_failed() { _loop_flags |= PartialPeelFailed; }
   void mark_has_reductions() { _loop_flags |= HasReductions; }
   void mark_was_slp() { _loop_flags |= WasSlpAnalyzed; }
   void mark_passed_slp() { _loop_flags |= PassedSlpAnalysis; }
@@ -113,10 +115,11 @@
   void mark_is_multiversioned() { _loop_flags |= IsMultiversioned; }
   void mark_strip_mined() { _loop_flags |= StripMined; }
   void clear_strip_mined() { _loop_flags &= ~StripMined; }
   void mark_profile_trip_failed() { _loop_flags |= ProfileTripFailed; }
   void mark_subword_loop() { _loop_flags |= SubwordLoop; }
+  void mark_flattened_arrays() { _loop_flags |= FlattenedArrays; }
 
   int unswitch_max() { return _unswitch_max; }
   int unswitch_count() { return _unswitch_count; }
 
   int has_been_range_checked() const { return _postloop_flags & LoopRCEChecked; }
@@ -1226,11 +1229,11 @@
   // insert a clone of the test that selects which version to
   // execute.
   void do_unswitching (IdealLoopTree *loop, Node_List &old_new);
 
   // Find candidate "if" for unswitching
-  IfNode* find_unswitching_candidate(const IdealLoopTree *loop) const;
+  IfNode* find_unswitching_candidate(const IdealLoopTree *loop, Node_List& unswitch_iffs) const;
 
   // Range Check Elimination uses this function!
   // Constrain the main loop iterations so the affine function:
   //    low_limit <= scale_con * I + offset  <  upper_limit
   // always holds true.  That is, either increase the number of iterations in
@@ -1348,10 +1351,11 @@
   void sink_use( Node *use, Node *post_loop );
   Node *place_near_use( Node *useblock ) const;
   Node* try_move_store_before_loop(Node* n, Node *n_ctrl);
   void try_move_store_after_loop(Node* n);
   bool identical_backtoback_ifs(Node *n);
+  bool flatten_array_element_type_check(Node *n);
   bool can_split_if(Node *n_ctrl);
 
   // Determine if a method is too big for a/another round of split-if, based on
   // a magic (approximate) ratio derived from the equally magic constant 35000,
   // previously used for this purpose (but without relating to the node limit).
diff a/src/hotspot/share/opto/loopopts.cpp b/src/hotspot/share/opto/loopopts.cpp
--- a/src/hotspot/share/opto/loopopts.cpp
+++ b/src/hotspot/share/opto/loopopts.cpp
@@ -39,10 +39,11 @@
 #include "opto/movenode.hpp"
 #include "opto/opaquenode.hpp"
 #include "opto/rootnode.hpp"
 #include "opto/subnode.hpp"
 #include "opto/subtypenode.hpp"
+#include "opto/valuetypenode.hpp"
 #include "utilities/macros.hpp"
 
 //=============================================================================
 //------------------------------split_thru_phi---------------------------------
 // Split Node 'n' through merge point if there is enough win.
@@ -59,10 +60,16 @@
   if (n->Opcode() == Op_CastII && n->as_CastII()->has_range_check() &&
       region->is_CountedLoop() && n->in(1) == region->as_CountedLoop()->phi()) {
     return NULL;
   }
 
+  // Value types should not be split through Phis because they cannot be merged
+  // through Phi nodes but each value input needs to be merged individually.
+  if (n->is_ValueType()) {
+    return NULL;
+  }
+
   int wins = 0;
   assert(!n->is_CFG(), "");
   assert(region->is_Region(), "");
 
   const Type* type = n->bottom_type();
@@ -1201,16 +1208,116 @@
   }
 
   return out_le;
 }
 
+bool PhaseIdealLoop::flatten_array_element_type_check(Node *n) {
+  // If the CmpP is a subtype check for a value that has just been
+  // loaded from an array, the subtype checks guarantees the value
+  // can't be stored in a flattened array and the load of the value
+  // happens with a flattened array check then: push the type check
+  // through the phi of the flattened array check. This needs special
+  // logic because the subtype check's input is not a phi but a
+  // LoadKlass that must first be cloned through the phi.
+  if (n->Opcode() != Op_CmpP) {
+    return false;
+  }
+
+  Node* klassptr = n->in(1);
+  Node* klasscon = n->in(2);
+
+  if (klassptr->is_DecodeNarrowPtr()) {
+    klassptr = klassptr->in(1);
+  }
+
+  if (klassptr->Opcode() != Op_LoadKlass && klassptr->Opcode() != Op_LoadNKlass) {
+    return false;
+  }
+
+  if (!klasscon->is_Con()) {
+    return false;
+  }
+
+  Node* addr = klassptr->in(MemNode::Address);
+
+  if (!addr->is_AddP()) {
+    return false;
+  }
+
+  intptr_t offset;
+  Node* obj = AddPNode::Ideal_base_and_offset(addr, &_igvn, offset);
+
+  if (obj == NULL) {
+    return false;
+  }
+
+  assert(obj != NULL && addr->in(AddPNode::Base) == addr->in(AddPNode::Address), "malformed AddP?");
+  if (obj->Opcode() == Op_CastPP) {
+    obj = obj->in(1);
+  }
+
+  if (!obj->is_Phi()) {
+    return false;
+  }
+
+  Node* region = obj->in(0);
+
+  Node* phi = PhiNode::make_blank(region, n->in(1));
+  for (uint i = 1; i < region->req(); i++) {
+    Node* in = obj->in(i);
+    Node* ctrl = get_ctrl(in);
+    if (addr->in(AddPNode::Base) != obj) {
+      Node* cast = addr->in(AddPNode::Base);
+      assert(cast->Opcode() == Op_CastPP && cast->in(0) != NULL, "inconsistent subgraph");
+      Node* cast_clone = cast->clone();
+      cast_clone->set_req(0, region->in(i));
+      cast_clone->set_req(1, in);
+      register_new_node(cast_clone, region->in(i));
+      _igvn.set_type(cast_clone, cast_clone->Value(&_igvn));
+      in = cast_clone;
+    }
+    Node* addr_clone = addr->clone();
+    addr_clone->set_req(AddPNode::Base, in);
+    addr_clone->set_req(AddPNode::Address, in);
+    register_new_node(addr_clone, ctrl);
+    _igvn.set_type(addr_clone, addr_clone->Value(&_igvn));
+    Node* klassptr_clone = klassptr->clone();
+    klassptr_clone->set_req(2, addr_clone);
+    register_new_node(klassptr_clone, ctrl);
+    _igvn.set_type(klassptr_clone, klassptr_clone->Value(&_igvn));
+    if (klassptr != n->in(1)) {
+      Node* decode = n->in(1);
+      assert(decode->is_DecodeNarrowPtr(), "inconcistent subgraph");
+      Node* decode_clone = decode->clone();
+      decode_clone->set_req(1, klassptr_clone);
+      register_new_node(decode_clone, ctrl);
+      _igvn.set_type(decode_clone, decode_clone->Value(&_igvn));
+      klassptr_clone = decode_clone;
+    }
+    phi->set_req(i, klassptr_clone);
+  }
+  register_new_node(phi, region);
+  Node* orig = n->in(1);
+  _igvn.replace_input_of(n, 1, phi);
+  split_if_with_blocks_post(n);
+  if (n->outcnt() != 0) {
+    _igvn.replace_input_of(n, 1, orig);
+    _igvn.remove_dead_node(phi);
+  }
+  return true;
+}
+
 //------------------------------split_if_with_blocks_post----------------------
 // Do the real work in a non-recursive function.  CFG hackery wants to be
 // in the post-order, so it can dirty the I-DOM info and not use the dirtied
 // info.
 void PhaseIdealLoop::split_if_with_blocks_post(Node *n) {
 
+  if (flatten_array_element_type_check(n)) {
+    return;
+  }
+
   // Cloning Cmp through Phi's involves the split-if transform.
   // FastLock is not used by an If
   if (n->is_Cmp() && !n->is_FastLock()) {
     Node *n_ctrl = get_ctrl(n);
     // Determine if the Node has inputs from some local Phi.
@@ -1471,10 +1578,16 @@
     }
   }
 
   try_move_store_after_loop(n);
 
+  // Remove multiple allocations of the same value type
+  if (n->is_ValueType()) {
+    n->as_ValueType()->remove_redundant_allocations(&_igvn, this);
+    return; // n is now dead
+  }
+
   // Check for Opaque2's who's loop has disappeared - who's input is in the
   // same loop nest as their output.  Remove 'em, they are no longer useful.
   if( n_op == Op_Opaque2 &&
       n->in(1) != NULL &&
       get_loop(get_ctrl(n)) == get_loop(get_ctrl(n->in(1))) ) {
diff a/src/hotspot/share/opto/output.cpp b/src/hotspot/share/opto/output.cpp
--- a/src/hotspot/share/opto/output.cpp
+++ b/src/hotspot/share/opto/output.cpp
@@ -239,16 +239,23 @@
     _code_offsets(),
     _node_bundling_limit(0),
     _node_bundling_base(NULL),
     _orig_pc_slot(0),
     _orig_pc_slot_offset_in_bytes(0),
+    _sp_inc_slot(0),
+    _sp_inc_slot_offset_in_bytes(0),
     _buf_sizes(),
     _block(NULL),
     _index(0) {
   C->set_output(this);
   if (C->stub_name() == NULL) {
-    _orig_pc_slot = C->fixed_slots() - (sizeof(address) / VMRegImpl::stack_slot_size);
+    int fixed_slots = C->fixed_slots();
+    if (C->needs_stack_repair()) {
+      fixed_slots -= 2;
+      _sp_inc_slot = fixed_slots;
+    }
+    _orig_pc_slot = fixed_slots - (sizeof(address) / VMRegImpl::stack_slot_size);
   }
 }
 
 PhaseOutput::~PhaseOutput() {
   C->set_output(NULL);
@@ -283,28 +290,38 @@
   Block *broot = C->cfg()->get_root_block();
 
   const StartNode *start = entry->head()->as_Start();
 
   // Replace StartNode with prolog
-  MachPrologNode *prolog = new MachPrologNode();
+  Label verified_entry;
+  MachPrologNode* prolog = new MachPrologNode(&verified_entry);
   entry->map_node(prolog, 0);
   C->cfg()->map_node_to_block(prolog, entry);
   C->cfg()->unmap_node_from_block(start); // start is no longer in any block
 
   // Virtual methods need an unverified entry point
-
-  if( C->is_osr_compilation() ) {
-    if( PoisonOSREntry ) {
+  if (C->is_osr_compilation()) {
+    if (PoisonOSREntry) {
       // TODO: Should use a ShouldNotReachHereNode...
       C->cfg()->insert( broot, 0, new MachBreakpointNode() );
     }
   } else {
-    if( C->method() && !C->method()->flags().is_static() ) {
-      // Insert unvalidated entry point
-      C->cfg()->insert( broot, 0, new MachUEPNode() );
+    if (C->method()) {
+      if (C->method()->has_scalarized_args()) {
+        // Add entry point to unpack all value type arguments
+        C->cfg()->insert(broot, 0, new MachVEPNode(&verified_entry, /* verified */ true, /* receiver_only */ false));
+        if (!C->method()->is_static()) {
+          // Add verified/unverified entry points to only unpack value type receiver at interface calls
+          C->cfg()->insert(broot, 0, new MachVEPNode(&verified_entry, /* verified */ false, /* receiver_only */ false));
+          C->cfg()->insert(broot, 0, new MachVEPNode(&verified_entry, /* verified */ true,  /* receiver_only */ true));
+          C->cfg()->insert(broot, 0, new MachVEPNode(&verified_entry, /* verified */ false, /* receiver_only */ true));
+        }
+      } else if (!C->method()->is_static()) {
+        // Insert unvalidated entry point
+        C->cfg()->insert(broot, 0, new MachUEPNode());
+      }
     }
-
   }
 
   // Break before main entry point
   if ((C->method() && C->directive()->BreakAtExecuteOption) ||
       (OptoBreakpoint && C->is_method_compilation())       ||
@@ -340,10 +357,35 @@
   // Must be done before ScheduleAndBundle due to SPARC delay slots
   uint* blk_starts = NEW_RESOURCE_ARRAY(uint, C->cfg()->number_of_blocks() + 1);
   blk_starts[0] = 0;
   shorten_branches(blk_starts);
 
+  if (!C->is_osr_compilation() && C->has_scalarized_args()) {
+    // Compute the offsets of the entry points required by the value type calling convention
+    if (!C->method()->is_static()) {
+      // We have entries at the beginning of the method, implemented by the first 4 nodes.
+      // Entry                     (unverified) @ offset 0
+      // Verified_Value_Entry_RO
+      // Value_Entry               (unverified)
+      // Verified_Value_Entry
+      uint offset = 0;
+      _code_offsets.set_value(CodeOffsets::Entry, offset);
+
+      offset += ((MachVEPNode*)broot->get_node(0))->size(C->regalloc());
+      _code_offsets.set_value(CodeOffsets::Verified_Value_Entry_RO, offset);
+
+      offset += ((MachVEPNode*)broot->get_node(1))->size(C->regalloc());
+      _code_offsets.set_value(CodeOffsets::Value_Entry, offset);
+
+      offset += ((MachVEPNode*)broot->get_node(2))->size(C->regalloc());
+      _code_offsets.set_value(CodeOffsets::Verified_Value_Entry, offset);
+    } else {
+      _code_offsets.set_value(CodeOffsets::Entry, -1); // will be patched later
+      _code_offsets.set_value(CodeOffsets::Verified_Value_Entry, 0);
+    }
+  }
+
   ScheduleAndBundle();
   if (C->failing()) {
     return;
   }
 
@@ -497,11 +539,13 @@
           reloc_size += CallStubImpl::reloc_call_trampoline();
 
           MachCallNode *mcall = mach->as_MachCall();
           // This destination address is NOT PC-relative
 
-          mcall->method_set((intptr_t)mcall->entry_point());
+          if (mcall->entry_point() != NULL) {
+            mcall->method_set((intptr_t)mcall->entry_point());
+          }
 
           if (mcall->is_MachCallJava() && mcall->as_MachCallJava()->_method) {
             stub_size  += CompiledStaticCall::to_interp_stub_size();
             reloc_size += CompiledStaticCall::reloc_to_interp_stub();
 #if INCLUDE_AOT
@@ -930,10 +974,11 @@
   MachCallNode      *mcall;
 
   int safepoint_pc_offset = current_offset;
   bool is_method_handle_invoke = false;
   bool return_oop = false;
+  bool return_vt = false;
 
   // Add the safepoint in the DebugInfoRecorder
   if( !mach->is_MachCall() ) {
     mcall = NULL;
     C->debug_info()->add_safepoint(safepoint_pc_offset, sfn->_oop_map);
@@ -947,13 +992,16 @@
         is_method_handle_invoke = true;
       }
     }
 
     // Check if a call returns an object.
-    if (mcall->returns_pointer()) {
+    if (mcall->returns_pointer() || mcall->returns_vt()) {
       return_oop = true;
     }
+    if (mcall->returns_vt()) {
+      return_vt = true;
+    }
     safepoint_pc_offset += mcall->ret_addr_offset();
     C->debug_info()->add_safepoint(safepoint_pc_offset, mcall->_oop_map);
   }
 
   // Loop over the JVMState list to add scope information
@@ -1064,11 +1112,11 @@
     assert(jvms->bci() >= InvocationEntryBci && jvms->bci() <= 0x10000, "must be a valid or entry BCI");
     assert(!jvms->should_reexecute() || depth == max_depth, "reexecute allowed only for the youngest");
     // Now we can describe the scope.
     methodHandle null_mh;
     bool rethrow_exception = false;
-    C->debug_info()->describe_scope(safepoint_pc_offset, null_mh, scope_method, jvms->bci(), jvms->should_reexecute(), rethrow_exception, is_method_handle_invoke, return_oop, locvals, expvals, monvals);
+    C->debug_info()->describe_scope(safepoint_pc_offset, null_mh, scope_method, jvms->bci(), jvms->should_reexecute(), rethrow_exception, is_method_handle_invoke, return_oop, return_vt, locvals, expvals, monvals);
   } // End jvms loop
 
   // Mark the end of the scope set.
   C->debug_info()->end_safepoint(safepoint_pc_offset);
 }
@@ -1169,10 +1217,14 @@
 
   // Compute the byte offset where we can store the deopt pc.
   if (C->fixed_slots() != 0) {
     _orig_pc_slot_offset_in_bytes = C->regalloc()->reg2offset(OptoReg::stack2reg(_orig_pc_slot));
   }
+  if (C->needs_stack_repair()) {
+    // Compute the byte offset of the stack increment value
+    _sp_inc_slot_offset_in_bytes = C->regalloc()->reg2offset(OptoReg::stack2reg(_sp_inc_slot));
+  }
 
   // Compute prolog code size
   _method_size = 0;
   _frame_slots = OptoReg::reg2stack(C->matcher()->_old_SP) + C->regalloc()->_framesize;
 #if defined(IA64) && !defined(AIX)
@@ -1445,12 +1497,14 @@
 
         // Remember the start of the last call in a basic block
         if (is_mcall) {
           MachCallNode *mcall = mach->as_MachCall();
 
-          // This destination address is NOT PC-relative
-          mcall->method_set((intptr_t)mcall->entry_point());
+          if (mcall->entry_point() != NULL) {
+            // This destination address is NOT PC-relative
+            mcall->method_set((intptr_t)mcall->entry_point());
+          }
 
           // Save the return address
           call_returns[block->_pre_order] = current_offset + mcall->ret_addr_offset();
 
           if (mcall->is_MachCallLeaf()) {
@@ -3168,10 +3222,16 @@
     }
 
     ResourceMark rm;
     _scratch_const_size = const_size;
     int size = C2Compiler::initial_code_buffer_size(const_size);
+#ifdef ASSERT
+    if (C->has_scalarized_args()) {
+      // Oop verification for loading object fields from scalarized value types in the new entry point requires lots of space
+      size += 5120;
+    }
+#endif
     blob = BufferBlob::create("Compile::scratch_buffer", size);
     // Record the buffer blob for next time.
     set_scratch_buffer_blob(blob);
     // Have we run out of code space?
     if (scratch_buffer_blob() == NULL) {
@@ -3232,18 +3292,30 @@
   if (is_branch) {
     MacroAssembler masm(&buf);
     masm.bind(fakeL);
     n->as_MachBranch()->save_label(&saveL, &save_bnum);
     n->as_MachBranch()->label_set(&fakeL, 0);
+  } else if (n->is_MachProlog()) {
+    saveL = ((MachPrologNode*)n)->_verified_entry;
+    ((MachPrologNode*)n)->_verified_entry = &fakeL;
+  } else if (n->is_MachVEP()) {
+    saveL = ((MachVEPNode*)n)->_verified_entry;
+    ((MachVEPNode*)n)->_verified_entry = &fakeL;
   }
   n->emit(buf, C->regalloc());
 
   // Emitting into the scratch buffer should not fail
   assert (!C->failing(), "Must not have pending failure. Reason is: %s", C->failure_reason());
 
-  if (is_branch) // Restore label.
+  // Restore label.
+  if (is_branch) {
     n->as_MachBranch()->label_set(saveL, save_bnum);
+  } else if (n->is_MachProlog()) {
+    ((MachPrologNode*)n)->_verified_entry = saveL;
+  } else if (n->is_MachVEP()) {
+    ((MachVEPNode*)n)->_verified_entry = saveL;
+  }
 
   // End scratch_emit_size section.
   set_in_scratch_emit_size(false);
 
   return buf.insts_size();
@@ -3282,26 +3354,35 @@
     if (C->is_osr_compilation()) {
       _code_offsets.set_value(CodeOffsets::Verified_Entry, 0);
       _code_offsets.set_value(CodeOffsets::OSR_Entry, _first_block_size);
     } else {
       _code_offsets.set_value(CodeOffsets::Verified_Entry, _first_block_size);
+      if (_code_offsets.value(CodeOffsets::Verified_Value_Entry) == -1) {
+        _code_offsets.set_value(CodeOffsets::Verified_Value_Entry, _first_block_size);
+      }
+      if (_code_offsets.value(CodeOffsets::Verified_Value_Entry_RO) == -1) {
+        _code_offsets.set_value(CodeOffsets::Verified_Value_Entry_RO, _first_block_size);
+      }
+      if (_code_offsets.value(CodeOffsets::Entry) == -1) {
+        _code_offsets.set_value(CodeOffsets::Entry, _first_block_size);
+      }
       _code_offsets.set_value(CodeOffsets::OSR_Entry, 0);
     }
 
     C->env()->register_method(target,
-                                     entry_bci,
-                                     &_code_offsets,
-                                     _orig_pc_slot_offset_in_bytes,
-                                     code_buffer(),
-                                     frame_size_in_words(),
-                                     oop_map_set(),
-                                     &_handler_table,
-                                     inc_table(),
-                                     compiler,
-                                     has_unsafe_access,
-                                     SharedRuntime::is_wide_vector(C->max_vector_size()),
-                                     C->rtm_state());
+                              entry_bci,
+                              &_code_offsets,
+                              _orig_pc_slot_offset_in_bytes,
+                              code_buffer(),
+                              frame_size_in_words(),
+                              _oop_map_set,
+                              &_handler_table,
+                              &_inc_table,
+                              compiler,
+                              has_unsafe_access,
+                              SharedRuntime::is_wide_vector(C->max_vector_size()),
+                              C->rtm_state());
 
     if (C->log() != NULL) { // Print code cache state into compiler log
       C->log()->code_cache_state();
     }
   }
diff a/src/hotspot/share/opto/subnode.hpp b/src/hotspot/share/opto/subnode.hpp
--- a/src/hotspot/share/opto/subnode.hpp
+++ b/src/hotspot/share/opto/subnode.hpp
@@ -193,11 +193,14 @@
 // Compare 2 long values, returning condition codes (-1, 0 or 1).
 class CmpLNode : public CmpNode {
 public:
   CmpLNode( Node *in1, Node *in2 ) : CmpNode(in1,in2) {}
   virtual int    Opcode() const;
+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);
+  virtual const Type* Value(PhaseGVN* phase) const;
   virtual const Type *sub( const Type *, const Type * ) const;
+  bool is_double_null_check(PhaseGVN* phase, Node*& a, Node*& b) const;
 };
 
 //------------------------------CmpULNode---------------------------------------
 // Compare 2 unsigned long values, returning condition codes (-1, 0 or 1).
 class CmpULNode : public CmpNode {
diff a/src/hotspot/share/opto/type.cpp b/src/hotspot/share/opto/type.cpp
--- a/src/hotspot/share/opto/type.cpp
+++ b/src/hotspot/share/opto/type.cpp
@@ -21,12 +21,14 @@
  * questions.
  *
  */
 
 #include "precompiled.hpp"
+#include "ci/ciField.hpp"
 #include "ci/ciMethodData.hpp"
 #include "ci/ciTypeFlow.hpp"
+#include "ci/ciValueKlass.hpp"
 #include "classfile/symbolTable.hpp"
 #include "classfile/systemDictionary.hpp"
 #include "compiler/compileLog.hpp"
 #include "libadt/dict.hpp"
 #include "memory/oopFactory.hpp"
@@ -45,10 +47,56 @@
 
 // Optimization - Graph Style
 
 // Dictionary of types shared among compilations.
 Dict* Type::_shared_type_dict = NULL;
+const Type::Offset Type::Offset::top(Type::OffsetTop);
+const Type::Offset Type::Offset::bottom(Type::OffsetBot);
+
+const Type::Offset Type::Offset::meet(const Type::Offset other) const {
+  // Either is 'TOP' offset?  Return the other offset!
+  int offset = other._offset;
+  if (_offset == OffsetTop) return Offset(offset);
+  if (offset == OffsetTop) return Offset(_offset);
+  // If either is different, return 'BOTTOM' offset
+  if (_offset != offset) return bottom;
+  return Offset(_offset);
+}
+
+const Type::Offset Type::Offset::dual() const {
+  if (_offset == OffsetTop) return bottom;// Map 'TOP' into 'BOTTOM'
+  if (_offset == OffsetBot) return top;// Map 'BOTTOM' into 'TOP'
+  return Offset(_offset);               // Map everything else into self
+}
+
+const Type::Offset Type::Offset::add(intptr_t offset) const {
+  // Adding to 'TOP' offset?  Return 'TOP'!
+  if (_offset == OffsetTop || offset == OffsetTop) return top;
+  // Adding to 'BOTTOM' offset?  Return 'BOTTOM'!
+  if (_offset == OffsetBot || offset == OffsetBot) return bottom;
+  // Addition overflows or "accidentally" equals to OffsetTop? Return 'BOTTOM'!
+  offset += (intptr_t)_offset;
+  if (offset != (int)offset || offset == OffsetTop) return bottom;
+
+  // assert( _offset >= 0 && _offset+offset >= 0, "" );
+  // It is possible to construct a negative offset during PhaseCCP
+
+  return Offset((int)offset);        // Sum valid offsets
+}
+
+void Type::Offset::dump2(outputStream *st) const {
+  if (_offset == 0) {
+    return;
+  } else if (_offset == OffsetTop) {
+    st->print("+top");
+  }
+  else if (_offset == OffsetBot) {
+    st->print("+bot");
+  } else if (_offset) {
+    st->print("+%d", _offset);
+  }
+}
 
 // Array which maps compiler types to Basic Types
 const Type::TypeInfo Type::_type_info[Type::lastype] = {
   { Bad,             T_ILLEGAL,    "bad",           false, Node::NotAMachineReg, relocInfo::none          },  // Bad
   { Control,         T_ILLEGAL,    "control",       false, 0,                    relocInfo::none          },  // Control
@@ -78,10 +126,11 @@
   { Bad,             T_ILLEGAL,    "vectord:",      false, Op_VecD,              relocInfo::none          },  // VectorD
   { Bad,             T_ILLEGAL,    "vectorx:",      false, Op_VecX,              relocInfo::none          },  // VectorX
   { Bad,             T_ILLEGAL,    "vectory:",      false, Op_VecY,              relocInfo::none          },  // VectorY
   { Bad,             T_ILLEGAL,    "vectorz:",      false, Op_VecZ,              relocInfo::none          },  // VectorZ
 #endif
+  { Bad,             T_VALUETYPE,  "value:",        false, Node::NotAMachineReg, relocInfo::none          },  // ValueType
   { Bad,             T_ADDRESS,    "anyptr:",       false, Op_RegP,              relocInfo::none          },  // AnyPtr
   { Bad,             T_ADDRESS,    "rawptr:",       false, Op_RegP,              relocInfo::none          },  // RawPtr
   { Bad,             T_OBJECT,     "oop:",          true,  Op_RegP,              relocInfo::oop_type      },  // OopPtr
   { Bad,             T_OBJECT,     "inst:",         true,  Op_RegP,              relocInfo::oop_type      },  // InstPtr
   { Bad,             T_OBJECT,     "ary:",          true,  Op_RegP,              relocInfo::oop_type      },  // AryPtr
@@ -208,10 +257,20 @@
 
   case T_ADDRESS:
     assert(type->is_return_address(), "");
     return TypeRawPtr::make((address)(intptr_t)type->as_return_address()->bci());
 
+  case T_VALUETYPE: {
+    bool is_never_null = type->is_never_null();
+    ciValueKlass* vk = type->unwrap()->as_value_klass();
+    if (vk->is_scalarizable() && is_never_null) {
+      return TypeValueType::make(vk);
+    } else {
+      return TypeOopPtr::make_from_klass(vk)->join_speculative(is_never_null ? TypePtr::NOTNULL : TypePtr::BOTTOM);
+    }
+  }
+
   default:
     // make sure we did not mix up the cases:
     assert(type != ciTypeFlow::StateVector::bottom_type(), "");
     assert(type != ciTypeFlow::StateVector::top_type(), "");
     assert(type != ciTypeFlow::StateVector::null_type(), "");
@@ -236,10 +295,11 @@
     case T_INT:      return TypeInt::make(constant.as_int());
     case T_LONG:     return TypeLong::make(constant.as_long());
     case T_FLOAT:    return TypeF::make(constant.as_float());
     case T_DOUBLE:   return TypeD::make(constant.as_double());
     case T_ARRAY:
+    case T_VALUETYPE:
     case T_OBJECT: {
         const Type* con_type = NULL;
         ciObject* oop_constant = constant.as_object();
         if (oop_constant->is_null_object()) {
           con_type = Type::get_zero_type(T_OBJECT);
@@ -273,16 +333,18 @@
 static ciConstant check_mismatched_access(ciConstant con, BasicType loadbt, bool is_unsigned) {
   BasicType conbt = con.basic_type();
   switch (conbt) {
     case T_BOOLEAN: conbt = T_BYTE;   break;
     case T_ARRAY:   conbt = T_OBJECT; break;
+    case T_VALUETYPE: conbt = T_OBJECT; break;
     default:                          break;
   }
   switch (loadbt) {
     case T_BOOLEAN:   loadbt = T_BYTE;   break;
     case T_NARROWOOP: loadbt = T_OBJECT; break;
     case T_ARRAY:     loadbt = T_OBJECT; break;
+    case T_VALUETYPE: loadbt = T_OBJECT; break;
     case T_ADDRESS:   loadbt = T_OBJECT; break;
     default:                             break;
   }
   if (conbt == loadbt) {
     if (is_unsigned && conbt == T_BYTE) {
@@ -506,13 +568,13 @@
   const Type **floop =(const Type**)shared_type_arena->Amalloc_4(2*sizeof(Type*));
   floop[0] = Type::CONTROL;
   floop[1] = TypeInt::INT;
   TypeTuple::LOOPBODY = TypeTuple::make( 2, floop );
 
-  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, 0);
-  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, OffsetBot);
-  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, OffsetBot);
+  TypePtr::NULL_PTR= TypePtr::make(AnyPtr, TypePtr::Null, Offset(0));
+  TypePtr::NOTNULL = TypePtr::make(AnyPtr, TypePtr::NotNull, Offset::bottom);
+  TypePtr::BOTTOM  = TypePtr::make(AnyPtr, TypePtr::BotPTR, Offset::bottom);
 
   TypeRawPtr::BOTTOM = TypeRawPtr::make( TypePtr::BotPTR );
   TypeRawPtr::NOTNULL= TypeRawPtr::make( TypePtr::NotNull );
 
   const Type **fmembar = TypeTuple::fields(0);
@@ -525,16 +587,18 @@
 
   TypeInstPtr::NOTNULL = TypeInstPtr::make(TypePtr::NotNull, current->env()->Object_klass());
   TypeInstPtr::BOTTOM  = TypeInstPtr::make(TypePtr::BotPTR,  current->env()->Object_klass());
   TypeInstPtr::MIRROR  = TypeInstPtr::make(TypePtr::NotNull, current->env()->Class_klass());
   TypeInstPtr::MARK    = TypeInstPtr::make(TypePtr::BotPTR,  current->env()->Object_klass(),
-                                           false, 0, oopDesc::mark_offset_in_bytes());
+                                           false, 0, Offset(oopDesc::mark_offset_in_bytes()), false);
   TypeInstPtr::KLASS   = TypeInstPtr::make(TypePtr::BotPTR,  current->env()->Object_klass(),
-                                           false, 0, oopDesc::klass_offset_in_bytes());
-  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, OffsetBot, TypeOopPtr::InstanceBot);
+                                           false, 0, Offset(oopDesc::klass_offset_in_bytes()), false);
+  TypeOopPtr::BOTTOM  = TypeOopPtr::make(TypePtr::BotPTR, Offset::bottom, TypeOopPtr::InstanceBot);
+
+  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, NULL, Offset::bottom);
 
-  TypeMetadataPtr::BOTTOM = TypeMetadataPtr::make(TypePtr::BotPTR, NULL, OffsetBot);
+  TypeValueType::BOTTOM = TypeValueType::make(NULL);
 
   TypeNarrowOop::NULL_PTR = TypeNarrowOop::make( TypePtr::NULL_PTR );
   TypeNarrowOop::BOTTOM   = TypeNarrowOop::make( TypeInstPtr::BOTTOM );
 
   TypeNarrowKlass::NULL_PTR = TypeNarrowKlass::make( TypePtr::NULL_PTR );
@@ -547,47 +611,49 @@
   mreg2type[Op_RegF] = Type::FLOAT;
   mreg2type[Op_RegD] = Type::DOUBLE;
   mreg2type[Op_RegL] = TypeLong::LONG;
   mreg2type[Op_RegFlags] = TypeInt::CC;
 
-  TypeAryPtr::RANGE   = TypeAryPtr::make( TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), NULL /* current->env()->Object_klass() */, false, arrayOopDesc::length_offset_in_bytes());
+  TypeAryPtr::RANGE   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::BOTTOM,TypeInt::POS), NULL /* current->env()->Object_klass() */, false, Offset(arrayOopDesc::length_offset_in_bytes()));
 
-  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), NULL /*ciArrayKlass::make(o)*/,  false,  Type::OffsetBot);
+  TypeAryPtr::NARROWOOPS = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeNarrowOop::BOTTOM, TypeInt::POS), NULL /*ciArrayKlass::make(o)*/,  false,  Offset::bottom);
 
 #ifdef _LP64
   if (UseCompressedOops) {
     assert(TypeAryPtr::NARROWOOPS->is_ptr_to_narrowoop(), "array of narrow oops must be ptr to narrow oop");
     TypeAryPtr::OOPS  = TypeAryPtr::NARROWOOPS;
   } else
 #endif
   {
     // There is no shared klass for Object[].  See note in TypeAryPtr::klass().
-    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), NULL /*ciArrayKlass::make(o)*/,  false,  Type::OffsetBot);
+    TypeAryPtr::OOPS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInstPtr::BOTTOM,TypeInt::POS), NULL /*ciArrayKlass::make(o)*/,  false,  Offset::bottom);
   }
-  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Type::OffsetBot);
-  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Type::OffsetBot);
-  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Type::OffsetBot);
-  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Type::OffsetBot);
-  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Type::OffsetBot);
-  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Type::OffsetBot);
-  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Type::OffsetBot);
+  TypeAryPtr::BYTES   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::BYTE      ,TypeInt::POS), ciTypeArrayKlass::make(T_BYTE),   true,  Offset::bottom);
+  TypeAryPtr::SHORTS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::SHORT     ,TypeInt::POS), ciTypeArrayKlass::make(T_SHORT),  true,  Offset::bottom);
+  TypeAryPtr::CHARS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::CHAR      ,TypeInt::POS), ciTypeArrayKlass::make(T_CHAR),   true,  Offset::bottom);
+  TypeAryPtr::INTS    = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeInt::INT       ,TypeInt::POS), ciTypeArrayKlass::make(T_INT),    true,  Offset::bottom);
+  TypeAryPtr::LONGS   = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeLong::LONG     ,TypeInt::POS), ciTypeArrayKlass::make(T_LONG),   true,  Offset::bottom);
+  TypeAryPtr::FLOATS  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::FLOAT        ,TypeInt::POS), ciTypeArrayKlass::make(T_FLOAT),  true,  Offset::bottom);
+  TypeAryPtr::DOUBLES = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(Type::DOUBLE       ,TypeInt::POS), ciTypeArrayKlass::make(T_DOUBLE), true,  Offset::bottom);
+  TypeAryPtr::VALUES  = TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(TypeValueType::BOTTOM,TypeInt::POS), NULL, false,  Offset::bottom);
 
   // Nobody should ask _array_body_type[T_NARROWOOP]. Use NULL as assert.
   TypeAryPtr::_array_body_type[T_NARROWOOP] = NULL;
   TypeAryPtr::_array_body_type[T_OBJECT]  = TypeAryPtr::OOPS;
+  TypeAryPtr::_array_body_type[T_VALUETYPE] = TypeAryPtr::OOPS;
   TypeAryPtr::_array_body_type[T_ARRAY]   = TypeAryPtr::OOPS; // arrays are stored in oop arrays
   TypeAryPtr::_array_body_type[T_BYTE]    = TypeAryPtr::BYTES;
   TypeAryPtr::_array_body_type[T_BOOLEAN] = TypeAryPtr::BYTES;  // boolean[] is a byte array
   TypeAryPtr::_array_body_type[T_SHORT]   = TypeAryPtr::SHORTS;
   TypeAryPtr::_array_body_type[T_CHAR]    = TypeAryPtr::CHARS;
   TypeAryPtr::_array_body_type[T_INT]     = TypeAryPtr::INTS;
   TypeAryPtr::_array_body_type[T_LONG]    = TypeAryPtr::LONGS;
   TypeAryPtr::_array_body_type[T_FLOAT]   = TypeAryPtr::FLOATS;
   TypeAryPtr::_array_body_type[T_DOUBLE]  = TypeAryPtr::DOUBLES;
 
-  TypeKlassPtr::OBJECT = TypeKlassPtr::make( TypePtr::NotNull, current->env()->Object_klass(), 0 );
-  TypeKlassPtr::OBJECT_OR_NULL = TypeKlassPtr::make( TypePtr::BotPTR, current->env()->Object_klass(), 0 );
+  TypeKlassPtr::OBJECT = TypeKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), Offset(0), false);
+  TypeKlassPtr::OBJECT_OR_NULL = TypeKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), Offset(0), false);
 
   const Type **fi2c = TypeTuple::fields(2);
   fi2c[TypeFunc::Parms+0] = TypeInstPtr::BOTTOM; // Method*
   fi2c[TypeFunc::Parms+1] = TypeRawPtr::BOTTOM; // argument pointer
   TypeTuple::START_I2C = TypeTuple::make(TypeFunc::Parms+2, fi2c);
@@ -622,10 +688,11 @@
   _const_basic_type[T_LONG]        = TypeLong::LONG;
   _const_basic_type[T_FLOAT]       = Type::FLOAT;
   _const_basic_type[T_DOUBLE]      = Type::DOUBLE;
   _const_basic_type[T_OBJECT]      = TypeInstPtr::BOTTOM;
   _const_basic_type[T_ARRAY]       = TypeInstPtr::BOTTOM; // there is no separate bottom for arrays
+  _const_basic_type[T_VALUETYPE]   = TypeInstPtr::BOTTOM;
   _const_basic_type[T_VOID]        = TypePtr::NULL_PTR;   // reflection represents void this way
   _const_basic_type[T_ADDRESS]     = TypeRawPtr::BOTTOM;  // both interpreter return addresses & random raw ptrs
   _const_basic_type[T_CONFLICT]    = Type::BOTTOM;        // why not?
 
   _zero_type[T_NARROWOOP]   = TypeNarrowOop::NULL_PTR;
@@ -638,10 +705,11 @@
   _zero_type[T_LONG]        = TypeLong::ZERO;
   _zero_type[T_FLOAT]       = TypeF::ZERO;
   _zero_type[T_DOUBLE]      = TypeD::ZERO;
   _zero_type[T_OBJECT]      = TypePtr::NULL_PTR;
   _zero_type[T_ARRAY]       = TypePtr::NULL_PTR; // null array is null oop
+  _zero_type[T_VALUETYPE]   = TypePtr::NULL_PTR;
   _zero_type[T_ADDRESS]     = TypePtr::NULL_PTR; // raw pointers use the same null
   _zero_type[T_VOID]        = Type::TOP;         // the only void value is no value at all
 
   // get_zero_type() should not happen for T_CONFLICT
   _zero_type[T_CONFLICT]= NULL;
@@ -813,11 +881,11 @@
 
   // Interface meet Oop is Not Symmetric:
   // Interface:AnyNull meet Oop:AnyNull == Interface:AnyNull
   // Interface:NotNull meet Oop:NotNull == java/lang/Object:NotNull
 
-  if( !interface_vs_oop(t) && (t2t != t->_dual || t2this != this->_dual) ) {
+  if( !interface_vs_oop(t) && (t2t != t->_dual || t2this != this->_dual)) {
     tty->print_cr("=== Meet Not Symmetric ===");
     tty->print("t   =                   ");              t->dump(); tty->cr();
     tty->print("this=                   ");                 dump(); tty->cr();
     tty->print("mt=(t meet this)=       ");             mt->dump(); tty->cr();
 
@@ -917,10 +985,13 @@
     return t->xmeet(this);
 
   case NarrowKlass:
     return t->xmeet(this);
 
+  case ValueType:
+    return t->xmeet(this);
+
   case Bad:                     // Type check
   default:                      // Bogus type not in lattice
     typerr(t);
     return Type::BOTTOM;
 
@@ -984,10 +1055,11 @@
   Bad,          // VectorS - handled in v-call
   Bad,          // VectorD - handled in v-call
   Bad,          // VectorX - handled in v-call
   Bad,          // VectorY - handled in v-call
   Bad,          // VectorZ - handled in v-call
+  Bad,          // ValueType - handled in v-call
 
   Bad,          // AnyPtr - handled in v-call
   Bad,          // RawPtr - handled in v-call
   Bad,          // OopPtr - handled in v-call
   Bad,          // InstPtr - handled in v-call
@@ -1879,16 +1951,38 @@
 const TypeTuple *TypeTuple::INT_PAIR;
 const TypeTuple *TypeTuple::LONG_PAIR;
 const TypeTuple *TypeTuple::INT_CC_PAIR;
 const TypeTuple *TypeTuple::LONG_CC_PAIR;
 
+static void collect_value_fields(ciValueKlass* vk, const Type** field_array, uint& pos, ExtendedSignature& sig_cc) {
+  for (int j = 0; j < vk->nof_nonstatic_fields(); j++) {
+    ciField* field = vk->nonstatic_field_at(j);
+    BasicType bt = field->type()->basic_type();
+    const Type* ft = Type::get_const_type(field->type());
+    field_array[pos++] = ft;
+    if (type2size[bt] == 2) {
+      field_array[pos++] = Type::HALF;
+    }
+    // Skip reserved arguments
+    while (SigEntry::next_is_reserved(sig_cc, bt)) {
+      field_array[pos++] = Type::get_const_basic_type(bt);
+      if (type2size[bt] == 2) {
+        field_array[pos++] = Type::HALF;
+      }
+    }
+  }
+}
 
 //------------------------------make-------------------------------------------
 // Make a TypeTuple from the range of a method signature
-const TypeTuple *TypeTuple::make_range(ciSignature* sig) {
+const TypeTuple *TypeTuple::make_range(ciSignature* sig, bool ret_vt_fields) {
   ciType* return_type = sig->return_type();
   uint arg_cnt = return_type->size();
+  if (ret_vt_fields) {
+    arg_cnt = return_type->as_value_klass()->value_arg_slots() + 1;
+  }
+
   const Type **field_array = fields(arg_cnt);
   switch (return_type->basic_type()) {
   case T_LONG:
     field_array[TypeFunc::Parms]   = TypeLong::LONG;
     field_array[TypeFunc::Parms+1] = Type::HALF;
@@ -1905,38 +1999,63 @@
   case T_BYTE:
   case T_SHORT:
   case T_INT:
     field_array[TypeFunc::Parms] = get_const_type(return_type);
     break;
+  case T_VALUETYPE:
+    if (ret_vt_fields) {
+      uint pos = TypeFunc::Parms;
+      field_array[pos] = TypePtr::BOTTOM;
+      pos++;
+      ExtendedSignature sig = ExtendedSignature(NULL, SigEntryFilter());
+      collect_value_fields(return_type->as_value_klass(), field_array, pos, sig);
+    } else {
+      field_array[TypeFunc::Parms] = get_const_type(return_type)->join_speculative(sig->returns_never_null() ? TypePtr::NOTNULL : TypePtr::BOTTOM);
+    }
+    break;
   case T_VOID:
     break;
   default:
     ShouldNotReachHere();
   }
   return (TypeTuple*)(new TypeTuple(TypeFunc::Parms + arg_cnt, field_array))->hashcons();
 }
 
 // Make a TypeTuple from the domain of a method signature
-const TypeTuple *TypeTuple::make_domain(ciInstanceKlass* recv, ciSignature* sig) {
-  uint arg_cnt = sig->size();
+const TypeTuple *TypeTuple::make_domain(ciMethod* method, bool vt_fields_as_args) {
+  ciSignature* sig = method->signature();
+  ExtendedSignature sig_cc = ExtendedSignature(vt_fields_as_args ? method->get_sig_cc() : NULL, SigEntryFilter());
+
+  uint arg_cnt = sig->size() + (method->is_static() ? 0 : 1);
+  if (vt_fields_as_args) {
+    for (arg_cnt = 0; !sig_cc.at_end(); ++sig_cc) {
+      arg_cnt += type2size[(*sig_cc)._bt];
+    }
+    sig_cc = ExtendedSignature(method->get_sig_cc(), SigEntryFilter());
+  }
 
   uint pos = TypeFunc::Parms;
-  const Type **field_array;
-  if (recv != NULL) {
-    arg_cnt++;
-    field_array = fields(arg_cnt);
-    // Use get_const_type here because it respects UseUniqueSubclasses:
-    field_array[pos++] = get_const_type(recv)->join_speculative(TypePtr::NOTNULL);
-  } else {
-    field_array = fields(arg_cnt);
+  const Type** field_array = fields(arg_cnt);
+  if (!method->is_static()) {
+    ciInstanceKlass* recv = method->holder();
+    if (vt_fields_as_args && recv->is_valuetype() && recv->as_value_klass()->is_scalarizable()) {
+      collect_value_fields(recv->as_value_klass(), field_array, pos, sig_cc);
+    } else {
+      field_array[pos++] = get_const_type(recv)->join_speculative(TypePtr::NOTNULL);
+      if (vt_fields_as_args) {
+        ++sig_cc;
+      }
+    }
   }
 
   int i = 0;
   while (pos < TypeFunc::Parms + arg_cnt) {
     ciType* type = sig->type_at(i);
+    BasicType bt = type->basic_type();
+    bool is_flattened = false;
 
-    switch (type->basic_type()) {
+    switch (bt) {
     case T_LONG:
       field_array[pos++] = TypeLong::LONG;
       field_array[pos++] = Type::HALF;
       break;
     case T_DOUBLE:
@@ -1953,15 +2072,33 @@
     case T_CHAR:
     case T_BYTE:
     case T_SHORT:
       field_array[pos++] = TypeInt::INT;
       break;
+    case T_VALUETYPE: {
+      bool never_null = sig->is_never_null_at(i);
+      if (vt_fields_as_args && type->as_value_klass()->is_scalarizable() && never_null) {
+        is_flattened = true;
+        collect_value_fields(type->as_value_klass(), field_array, pos, sig_cc);
+      } else {
+        field_array[pos++] = get_const_type(type)->join_speculative(never_null ? TypePtr::NOTNULL : TypePtr::BOTTOM);
+      }
+      break;
+    }
     default:
       ShouldNotReachHere();
     }
+    // Skip reserved arguments
+    while (!is_flattened && SigEntry::next_is_reserved(sig_cc, bt)) {
+      field_array[pos++] = Type::get_const_basic_type(bt);
+      if (type2size[bt] == 2) {
+        field_array[pos++] = Type::HALF;
+      }
+    }
     i++;
   }
+  assert(pos == TypeFunc::Parms + arg_cnt, "wrong number of arguments");
 
   return (TypeTuple*)(new TypeTuple(TypeFunc::Parms + arg_cnt, field_array))->hashcons();
 }
 
 const TypeTuple *TypeTuple::make( uint cnt, const Type **fields ) {
@@ -2092,16 +2229,17 @@
   else
     return size;
 }
 
 //------------------------------make-------------------------------------------
-const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable) {
+const TypeAry* TypeAry::make(const Type* elem, const TypeInt* size, bool stable,
+                             bool not_flat, bool not_null_free) {
   if (UseCompressedOops && elem->isa_oopptr()) {
     elem = elem->make_narrowoop();
   }
   size = normalize_array_size(size);
-  return (TypeAry*)(new TypeAry(elem,size,stable))->hashcons();
+  return (TypeAry*)(new TypeAry(elem, size, stable, not_flat, not_null_free))->hashcons();
 }
 
 //------------------------------meet-------------------------------------------
 // Compute the MEET of two types.  It returns a new Type object.
 const Type *TypeAry::xmeet( const Type *t ) const {
@@ -2119,11 +2257,13 @@
 
   case Array: {                 // Meeting 2 arrays?
     const TypeAry *a = t->is_ary();
     return TypeAry::make(_elem->meet_speculative(a->_elem),
                          _size->xmeet(a->_size)->is_int(),
-                         _stable && a->_stable);
+                         _stable && a->_stable,
+                         _not_flat && a->_not_flat,
+                         _not_null_free && a->_not_null_free);
   }
   case Top:
     break;
   }
   return this;                  // Return the double constant
@@ -2132,20 +2272,23 @@
 //------------------------------xdual------------------------------------------
 // Dual: compute field-by-field dual
 const Type *TypeAry::xdual() const {
   const TypeInt* size_dual = _size->dual()->is_int();
   size_dual = normalize_array_size(size_dual);
-  return new TypeAry(_elem->dual(), size_dual, !_stable);
+  return new TypeAry(_elem->dual(), size_dual, !_stable, !_not_flat, !_not_null_free);
 }
 
 //------------------------------eq---------------------------------------------
 // Structural equality check for Type representations
 bool TypeAry::eq( const Type *t ) const {
   const TypeAry *a = (const TypeAry*)t;
   return _elem == a->_elem &&
     _stable == a->_stable &&
-    _size == a->_size;
+    _size == a->_size &&
+    _not_flat == a->_not_flat &&
+    _not_null_free == a->_not_null_free;
+
 }
 
 //------------------------------hash-------------------------------------------
 // Type-specific hashing function.
 int TypeAry::hash(void) const {
@@ -2154,18 +2297,18 @@
 
 /**
  * Return same type without a speculative part in the element
  */
 const Type* TypeAry::remove_speculative() const {
-  return make(_elem->remove_speculative(), _size, _stable);
+  return make(_elem->remove_speculative(), _size, _stable, _not_flat, _not_null_free);
 }
 
 /**
  * Return same type with cleaned up speculative part of element
  */
 const Type* TypeAry::cleanup_speculative() const {
-  return make(_elem->cleanup_speculative(), _size, _stable);
+  return make(_elem->cleanup_speculative(), _size, _stable, _not_flat, _not_null_free);
 }
 
 /**
  * Return same type but with a different inline depth (used for speculation)
  *
@@ -2195,10 +2338,14 @@
 
 //------------------------------dump2------------------------------------------
 #ifndef PRODUCT
 void TypeAry::dump2( Dict &d, uint depth, outputStream *st ) const {
   if (_stable)  st->print("stable:");
+  if (Verbose) {
+    if (_not_flat) st->print("not flat:");
+    if (_not_null_free) st->print("not null free:");
+  }
   _elem->dump2(d, depth, st);
   st->print("[");
   _size->dump2(d, depth, st);
   st->print("]");
 }
@@ -2249,10 +2396,134 @@
   if (tap)
     return tap->ary()->ary_must_be_exact();
   return false;
 }
 
+//==============================TypeValueType=======================================
+
+const TypeValueType *TypeValueType::BOTTOM;
+
+//------------------------------make-------------------------------------------
+const TypeValueType* TypeValueType::make(ciValueKlass* vk, bool larval) {
+  return (TypeValueType*)(new TypeValueType(vk, larval))->hashcons();
+}
+
+//------------------------------meet-------------------------------------------
+// Compute the MEET of two types.  It returns a new Type object.
+const Type* TypeValueType::xmeet(const Type* t) const {
+  // Perform a fast test for common case; meeting the same types together.
+  if(this == t) return this;  // Meeting same type-rep?
+
+  // Current "this->_base" is ValueType
+  switch (t->base()) {          // switch on original type
+
+  case Int:
+  case Long:
+  case FloatTop:
+  case FloatCon:
+  case FloatBot:
+  case DoubleTop:
+  case DoubleCon:
+  case DoubleBot:
+  case NarrowKlass:
+  case Bottom:
+    return Type::BOTTOM;
+
+  case OopPtr:
+  case MetadataPtr:
+  case KlassPtr:
+  case RawPtr:
+    return TypePtr::BOTTOM;
+
+  case Top:
+    return this;
+
+  case NarrowOop: {
+    const Type* res = t->make_ptr()->xmeet(this);
+    if (res->isa_ptr()) {
+      return res->make_narrowoop();
+    }
+    return res;
+  }
+
+  case AryPtr:
+  case InstPtr: {
+    return t->xmeet(this);
+  }
+
+  case ValueType: {
+    // All value types inherit from Object
+    const TypeValueType* other = t->is_valuetype();
+    if (_vk == NULL) {
+      return this;
+    } else if (other->_vk == NULL) {
+      return other;
+    } else if (_vk == other->_vk) {
+      if (_larval == other->_larval ||
+          !_larval) {
+        return this;
+      } else {
+        return t;
+      }
+    }
+    return TypeInstPtr::NOTNULL;
+  }
+
+  default:                      // All else is a mistake
+    typerr(t);
+
+  }
+  return this;
+}
+
+//------------------------------xdual------------------------------------------
+const Type* TypeValueType::xdual() const {
+  return this;
+}
+
+//------------------------------eq---------------------------------------------
+// Structural equality check for Type representations
+bool TypeValueType::eq(const Type* t) const {
+  const TypeValueType* vt = t->is_valuetype();
+  return (_vk == vt->value_klass() && _larval == vt->larval());
+}
+
+//------------------------------hash-------------------------------------------
+// Type-specific hashing function.
+int TypeValueType::hash(void) const {
+  return (intptr_t)_vk;
+}
+
+//------------------------------singleton--------------------------------------
+// TRUE if Type is a singleton type, FALSE otherwise. Singletons are simple constants.
+bool TypeValueType::singleton(void) const {
+  return false;
+}
+
+//------------------------------empty------------------------------------------
+// TRUE if Type is a type with no values, FALSE otherwise.
+bool TypeValueType::empty(void) const {
+  return false;
+}
+
+//------------------------------dump2------------------------------------------
+#ifndef PRODUCT
+void TypeValueType::dump2(Dict &d, uint depth, outputStream* st) const {
+  if (_vk == NULL) {
+    st->print("BOTTOM valuetype");
+    return;
+  }
+  int count = _vk->nof_declared_nonstatic_fields();
+  st->print("valuetype[%d]:{", count);
+  st->print("%s", count != 0 ? _vk->declared_nonstatic_field_at(0)->type()->name() : "empty");
+  for (int i = 1; i < count; ++i) {
+    st->print(", %s", _vk->declared_nonstatic_field_at(i)->type()->name());
+  }
+  st->print("}%s", _larval?" : larval":"");
+}
+#endif
+
 //==============================TypeVect=======================================
 // Convenience common pre-built types.
 const TypeVect *TypeVect::VECTS = NULL; //  32-bit vectors
 const TypeVect *TypeVect::VECTD = NULL; //  64-bit vectors
 const TypeVect *TypeVect::VECTX = NULL; // 128-bit vectors
@@ -2390,11 +2661,11 @@
   { /* NotNull */ NotNull,   NotNull,   NotNull,  BotPTR, NotNull, BotPTR,},
   { /* BotPTR  */ BotPTR,    BotPTR,    BotPTR,   BotPTR, BotPTR,  BotPTR,}
 };
 
 //------------------------------make-------------------------------------------
-const TypePtr *TypePtr::make(TYPES t, enum PTR ptr, int offset, const TypePtr* speculative, int inline_depth) {
+const TypePtr* TypePtr::make(TYPES t, enum PTR ptr, Offset offset, const TypePtr* speculative, int inline_depth) {
   return (TypePtr*)(new TypePtr(t,ptr,offset, speculative, inline_depth))->hashcons();
 }
 
 //------------------------------cast_to_ptr_type-------------------------------
 const Type *TypePtr::cast_to_ptr_type(PTR ptr) const {
@@ -2404,11 +2675,11 @@
 }
 
 //------------------------------get_con----------------------------------------
 intptr_t TypePtr::get_con() const {
   assert( _ptr == Null, "" );
-  return _offset;
+  return offset();
 }
 
 //------------------------------meet-------------------------------------------
 // Compute the MEET of two types.  It returns a new Type object.
 const Type *TypePtr::xmeet(const Type *t) const {
@@ -2473,24 +2744,17 @@
   }
   return this;
 }
 
 //------------------------------meet_offset------------------------------------
-int TypePtr::meet_offset( int offset ) const {
-  // Either is 'TOP' offset?  Return the other offset!
-  if( _offset == OffsetTop ) return offset;
-  if( offset == OffsetTop ) return _offset;
-  // If either is different, return 'BOTTOM' offset
-  if( _offset != offset ) return OffsetBot;
-  return _offset;
+Type::Offset TypePtr::meet_offset(int offset) const {
+  return _offset.meet(Offset(offset));
 }
 
 //------------------------------dual_offset------------------------------------
-int TypePtr::dual_offset( ) const {
-  if( _offset == OffsetTop ) return OffsetBot;// Map 'TOP' into 'BOTTOM'
-  if( _offset == OffsetBot ) return OffsetTop;// Map 'BOTTOM' into 'TOP'
-  return _offset;               // Map everything else into self
+Type::Offset TypePtr::dual_offset() const {
+  return _offset.dual();
 }
 
 //------------------------------xdual------------------------------------------
 // Dual: compute field-by-field dual
 const TypePtr::PTR TypePtr::ptr_dual[TypePtr::lastPTR] = {
@@ -2499,23 +2763,12 @@
 const Type *TypePtr::xdual() const {
   return new TypePtr(AnyPtr, dual_ptr(), dual_offset(), dual_speculative(), dual_inline_depth());
 }
 
 //------------------------------xadd_offset------------------------------------
-int TypePtr::xadd_offset( intptr_t offset ) const {
-  // Adding to 'TOP' offset?  Return 'TOP'!
-  if( _offset == OffsetTop || offset == OffsetTop ) return OffsetTop;
-  // Adding to 'BOTTOM' offset?  Return 'BOTTOM'!
-  if( _offset == OffsetBot || offset == OffsetBot ) return OffsetBot;
-  // Addition overflows or "accidentally" equals to OffsetTop? Return 'BOTTOM'!
-  offset += (intptr_t)_offset;
-  if (offset != (int)offset || offset == OffsetTop) return OffsetBot;
-
-  // assert( _offset >= 0 && _offset+offset >= 0, "" );
-  // It is possible to construct a negative offset during PhaseCCP
-
-  return (int)offset;        // Sum valid offsets
+Type::Offset TypePtr::xadd_offset(intptr_t offset) const {
+  return _offset.add(offset);
 }
 
 //------------------------------add_offset-------------------------------------
 const TypePtr *TypePtr::add_offset( intptr_t offset ) const {
   return make(AnyPtr, _ptr, xadd_offset(offset), _speculative, _inline_depth);
@@ -2523,17 +2776,17 @@
 
 //------------------------------eq---------------------------------------------
 // Structural equality check for Type representations
 bool TypePtr::eq( const Type *t ) const {
   const TypePtr *a = (const TypePtr*)t;
-  return _ptr == a->ptr() && _offset == a->offset() && eq_speculative(a) && _inline_depth == a->_inline_depth;
+  return _ptr == a->ptr() && _offset == a->_offset && eq_speculative(a) && _inline_depth == a->_inline_depth;
 }
 
 //------------------------------hash-------------------------------------------
 // Type-specific hashing function.
 int TypePtr::hash(void) const {
-  return java_add(java_add((jint)_ptr, (jint)_offset), java_add((jint)hash_speculative(), (jint)_inline_depth));
+  return java_add(java_add((jint)_ptr, (jint)offset()), java_add((jint)hash_speculative(), (jint)_inline_depth));
 ;
 }
 
 /**
  * Return same type without a speculative part
@@ -2789,13 +3042,11 @@
 
 #ifndef PRODUCT
 void TypePtr::dump2( Dict &d, uint depth, outputStream *st ) const {
   if( _ptr == Null ) st->print("NULL");
   else st->print("%s *", ptr_msg[_ptr]);
-  if( _offset == OffsetTop ) st->print("+top");
-  else if( _offset == OffsetBot ) st->print("+bot");
-  else if( _offset ) st->print("+%d", _offset);
+  _offset.dump2(st);
   dump_inline_depth(st);
   dump_speculative(st);
 }
 
 /**
@@ -2826,15 +3077,15 @@
 //------------------------------singleton--------------------------------------
 // TRUE if Type is a singleton type, FALSE otherwise.   Singletons are simple
 // constants
 bool TypePtr::singleton(void) const {
   // TopPTR, Null, AnyNull, Constant are all singletons
-  return (_offset != OffsetBot) && !below_centerline(_ptr);
+  return (_offset != Offset::bottom) && !below_centerline(_ptr);
 }
 
 bool TypePtr::empty(void) const {
-  return (_offset == OffsetTop) || above_centerline(_ptr);
+  return (_offset == Offset::top) || above_centerline(_ptr);
 }
 
 //=============================================================================
 // Convenience common pre-built types.
 const TypeRawPtr *TypeRawPtr::BOTTOM;
@@ -2972,63 +3223,76 @@
 //=============================================================================
 // Convenience common pre-built type.
 const TypeOopPtr *TypeOopPtr::BOTTOM;
 
 //------------------------------TypeOopPtr-------------------------------------
-TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, int offset,
+TypeOopPtr::TypeOopPtr(TYPES t, PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset offset, Offset field_offset,
                        int instance_id, const TypePtr* speculative, int inline_depth)
   : TypePtr(t, ptr, offset, speculative, inline_depth),
     _const_oop(o), _klass(k),
     _klass_is_exact(xk),
     _is_ptr_to_narrowoop(false),
     _is_ptr_to_narrowklass(false),
     _is_ptr_to_boxed_value(false),
     _instance_id(instance_id) {
   if (Compile::current()->eliminate_boxing() && (t == InstPtr) &&
-      (offset > 0) && xk && (k != 0) && k->is_instance_klass()) {
-    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset);
+      (offset.get() > 0) && xk && (k != 0) && k->is_instance_klass()) {
+    _is_ptr_to_boxed_value = k->as_instance_klass()->is_boxed_value_offset(offset.get());
   }
 #ifdef _LP64
-  if (_offset > 0 || _offset == Type::OffsetTop || _offset == Type::OffsetBot) {
-    if (_offset == oopDesc::klass_offset_in_bytes()) {
+  if (this->offset() > 0 || this->offset() == Type::OffsetTop || this->offset() == Type::OffsetBot) {
+    if (this->offset() == oopDesc::klass_offset_in_bytes()) {
       _is_ptr_to_narrowklass = UseCompressedClassPointers;
     } else if (klass() == NULL) {
       // Array with unknown body type
       assert(this->isa_aryptr(), "only arrays without klass");
       _is_ptr_to_narrowoop = UseCompressedOops;
-    } else if (this->isa_aryptr()) {
-      _is_ptr_to_narrowoop = (UseCompressedOops && klass()->is_obj_array_klass() &&
-                             _offset != arrayOopDesc::length_offset_in_bytes());
+    } else if (UseCompressedOops && this->isa_aryptr() && this->offset() != arrayOopDesc::length_offset_in_bytes()) {
+      if (klass()->is_obj_array_klass()) {
+        _is_ptr_to_narrowoop = true;
+      } else if (klass()->is_value_array_klass() && field_offset != Offset::top && field_offset != Offset::bottom) {
+        // Check if the field of the value type array element contains oops
+        ciValueKlass* vk = klass()->as_value_array_klass()->element_klass()->as_value_klass();
+        int foffset = field_offset.get() + vk->first_field_offset();
+        ciField* field = vk->get_field_by_offset(foffset, false);
+        assert(field != NULL, "missing field");
+        BasicType bt = field->layout_type();
+        _is_ptr_to_narrowoop = (bt == T_OBJECT || bt == T_ARRAY || T_VALUETYPE);
+      }
     } else if (klass()->is_instance_klass()) {
-      ciInstanceKlass* ik = klass()->as_instance_klass();
-      ciField* field = NULL;
       if (this->isa_klassptr()) {
         // Perm objects don't use compressed references
-      } else if (_offset == OffsetBot || _offset == OffsetTop) {
+      } else if (_offset == Offset::bottom || _offset == Offset::top) {
         // unsafe access
         _is_ptr_to_narrowoop = UseCompressedOops;
       } else { // exclude unsafe ops
         assert(this->isa_instptr(), "must be an instance ptr.");
-
-        if (klass() == ciEnv::current()->Class_klass() &&
-            (_offset == java_lang_Class::klass_offset_in_bytes() ||
+        if (klass() == ciEnv::current()->Class_klass() &&
+            (this->offset() == java_lang_Class::klass_offset_in_bytes() ||
              _offset == java_lang_Class::array_klass_offset_in_bytes())) {
           // Special hidden fields from the Class.
           assert(this->isa_instptr(), "must be an instance ptr.");
           _is_ptr_to_narrowoop = false;
         } else if (klass() == ciEnv::current()->Class_klass() &&
-                   _offset >= InstanceMirrorKlass::offset_of_static_fields()) {
+                   this->offset() >= InstanceMirrorKlass::offset_of_static_fields()) {
           // Static fields
           assert(o != NULL, "must be constant");
-          ciInstanceKlass* k = o->as_instance()->java_lang_Class_klass()->as_instance_klass();
-          ciField* field = k->get_field_by_offset(_offset, true);
-          assert(field != NULL, "missing field");
-          BasicType basic_elem_type = field->layout_type();
+          ciInstanceKlass* ik = o->as_instance()->java_lang_Class_klass()->as_instance_klass();
+          BasicType basic_elem_type;
+          if (ik->is_valuetype() && this->offset() == ik->as_value_klass()->default_value_offset()) {
+            // Special hidden field that contains the oop of the default value type
+            basic_elem_type = T_VALUETYPE;
+          } else {
+            ciField* field = ik->get_field_by_offset(this->offset(), true);
+            assert(field != NULL, "missing field");
+            basic_elem_type = field->layout_type();
+          }
           _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(basic_elem_type);
         } else {
           // Instance fields which contains a compressed oop references.
-          field = ik->get_field_by_offset(_offset, false);
+          ciInstanceKlass* ik = klass()->as_instance_klass();
+          ciField* field = ik->get_field_by_offset(this->offset(), false);
           if (field != NULL) {
             BasicType basic_elem_type = field->layout_type();
             _is_ptr_to_narrowoop = UseCompressedOops && is_reference_type(basic_elem_type);
           } else if (klass()->equals(ciEnv::current()->Object_klass())) {
             // Compile::find_alias_type() cast exactness on all types to verify
@@ -3044,17 +3308,17 @@
   }
 #endif
 }
 
 //------------------------------make-------------------------------------------
-const TypeOopPtr *TypeOopPtr::make(PTR ptr, int offset, int instance_id,
-                                     const TypePtr* speculative, int inline_depth) {
+const TypeOopPtr *TypeOopPtr::make(PTR ptr, Offset offset, int instance_id,
+                                   const TypePtr* speculative, int inline_depth) {
   assert(ptr != Constant, "no constant generic pointers");
   ciKlass*  k = Compile::current()->env()->Object_klass();
   bool      xk = false;
   ciObject* o = NULL;
-  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, xk, o, offset, instance_id, speculative, inline_depth))->hashcons();
+  return (TypeOopPtr*)(new TypeOopPtr(OopPtr, ptr, k, xk, o, offset, Offset::bottom, instance_id, speculative, inline_depth))->hashcons();
 }
 
 
 //------------------------------cast_to_ptr_type-------------------------------
 const Type *TypeOopPtr::cast_to_ptr_type(PTR ptr) const {
@@ -3085,11 +3349,11 @@
   ciKlass* k = klass();
   bool    xk = klass_is_exact();
   if (k == NULL)
     return TypeKlassPtr::OBJECT;
   else
-    return TypeKlassPtr::make(xk? Constant: NotNull, k, 0);
+    return TypeKlassPtr::make(xk? Constant: NotNull, k, Offset(0), isa_instptr() && is_instptr()->flat_array());
 }
 
 //------------------------------meet-------------------------------------------
 // Compute the MEET of two types.  It returns a new Type object.
 const Type *TypeOopPtr::xmeet_helper(const Type *t) const {
@@ -3123,11 +3387,11 @@
     return TypePtr::BOTTOM;     // Oop meet raw is not well defined
 
   case AnyPtr: {
     // Found an AnyPtr type vs self-OopPtr type
     const TypePtr *tp = t->is_ptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     const TypePtr* speculative = xmeet_speculative(tp);
     int depth = meet_inline_depth(tp->inline_depth());
     switch (tp->ptr()) {
     case Null:
@@ -3165,17 +3429,17 @@
 //------------------------------xdual------------------------------------------
 // Dual of a pure heap pointer.  No relevant klass or oop information.
 const Type *TypeOopPtr::xdual() const {
   assert(klass() == Compile::current()->env()->Object_klass(), "no klasses here");
   assert(const_oop() == NULL,             "no constants here");
-  return new TypeOopPtr(_base, dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());
+  return new TypeOopPtr(_base, dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), Offset::bottom, dual_instance_id(), dual_speculative(), dual_inline_depth());
 }
 
 //--------------------------make_from_klass_common-----------------------------
 // Computes the element-type given a klass.
 const TypeOopPtr* TypeOopPtr::make_from_klass_common(ciKlass *klass, bool klass_change, bool try_for_exact) {
-  if (klass->is_instance_klass()) {
+  if (klass->is_instance_klass() || klass->is_valuetype()) {
     Compile* C = Compile::current();
     Dependencies* deps = C->dependencies();
     assert((deps != NULL) == (C->method() != NULL && C->method()->code_size() > 0), "sanity");
     // Element is an instance
     bool klass_is_exact = false;
@@ -3199,28 +3463,46 @@
           deps->assert_leaf_type(ik);
           klass_is_exact = true;
         }
       }
     }
-    return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, 0);
+    return TypeInstPtr::make(TypePtr::BotPTR, klass, klass_is_exact, NULL, Offset(0), klass->flatten_array());
   } else if (klass->is_obj_array_klass()) {
-    // Element is an object array. Recursively call ourself.
-    const TypeOopPtr *etype = TypeOopPtr::make_from_klass_common(klass->as_obj_array_klass()->element_klass(), false, try_for_exact);
+    // Element is an object or value array. Recursively call ourself.
+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), /* klass_change= */ false, try_for_exact);
+    if (etype->is_valuetypeptr()) {
+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();
+    }
+    // Determine null-free/flattened properties
+    const TypeOopPtr* exact_etype = etype;
+    if (etype->can_be_value_type()) {
+      // Use exact type if element can be a value type
+      exact_etype = TypeOopPtr::make_from_klass_common(klass->as_array_klass()->element_klass(), /* klass_change= */ true, /* try_for_exact= */ true);
+    }
+    bool not_null_free = !exact_etype->can_be_value_type();
+    bool not_flat = !ValueArrayFlatten || not_null_free || (exact_etype->is_valuetypeptr() && !exact_etype->value_klass()->flatten_array());
+
     bool xk = etype->klass_is_exact();
-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);
+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS, false, not_flat, not_null_free);
     // We used to pass NotNull in here, asserting that the sub-arrays
     // are all not-null.  This is not true in generally, as code can
     // slam NULLs down in the subarrays.
-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, 0);
+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, xk, Offset(0));
     return arr;
   } else if (klass->is_type_array_klass()) {
     // Element is an typeArray
     const Type* etype = get_const_basic_type(klass->as_type_array_klass()->element_type());
-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS);
+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::POS,
+                                        /* stable= */ false, /* not_flat= */ true, /* not_null_free= */ true);
     // We used to pass NotNull in here, asserting that the array pointer
     // is not-null. That was not true in general.
-    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, 0);
+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));
+    return arr;
+  } else if (klass->is_value_array_klass()) {
+    ciValueKlass* vk = klass->as_array_klass()->element_klass()->as_value_klass();
+    const TypeAry* arr0 = TypeAry::make(TypeValueType::make(vk), TypeInt::POS);
+    const TypeAryPtr* arr = TypeAryPtr::make(TypePtr::BotPTR, arr0, klass, true, Offset(0));
     return arr;
   } else {
     ShouldNotReachHere();
     return NULL;
   }
@@ -3232,54 +3514,70 @@
   assert(!o->is_null_object(), "null object not yet handled here.");
 
   const bool make_constant = require_constant || o->should_be_constant();
 
   ciKlass* klass = o->klass();
-  if (klass->is_instance_klass()) {
-    // Element is an instance
+  if (klass->is_instance_klass() || klass->is_valuetype()) {
+    // Element is an instance or value type
     if (make_constant) {
       return TypeInstPtr::make(o);
     } else {
-      return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, 0);
+      return TypeInstPtr::make(TypePtr::NotNull, klass, true, NULL, Offset(0), klass->flatten_array());
     }
   } else if (klass->is_obj_array_klass()) {
     // Element is an object array. Recursively call ourself.
-    const TypeOopPtr *etype =
-      TypeOopPtr::make_from_klass_raw(klass->as_obj_array_klass()->element_klass());
-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));
+    const TypeOopPtr* etype = TypeOopPtr::make_from_klass_raw(klass->as_array_klass()->element_klass());
+    bool null_free = false;
+    if (etype->is_valuetypeptr()) {
+      null_free = true;
+      etype = etype->join_speculative(TypePtr::NOTNULL)->is_oopptr();
+    }
+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),
+                                        /* stable= */ false, /* not_flat= */ true, /* not_null_free= */ !null_free);
     // We used to pass NotNull in here, asserting that the sub-arrays
     // are all not-null.  This is not true in generally, as code can
     // slam NULLs down in the subarrays.
     if (make_constant) {
-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);
+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));
     } else {
-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);
+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));
     }
   } else if (klass->is_type_array_klass()) {
     // Element is an typeArray
-    const Type* etype =
-      (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());
-    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()));
+    const Type* etype = (Type*)get_const_basic_type(klass->as_type_array_klass()->element_type());
+    const TypeAry* arr0 = TypeAry::make(etype, TypeInt::make(o->as_array()->length()),
+                                        /* stable= */ false, /* not_flat= */ true, /* not_null_free= */ true);
     // We used to pass NotNull in here, asserting that the array pointer
     // is not-null. That was not true in general.
     if (make_constant) {
-      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, 0);
+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));
+    } else {
+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));
+    }
+  } else if (klass->is_value_array_klass()) {
+    ciValueKlass* vk = klass->as_array_klass()->element_klass()->as_value_klass();
+    const TypeAry* arr0 = TypeAry::make(TypeValueType::make(vk), TypeInt::make(o->as_array()->length()));
+    // We used to pass NotNull in here, asserting that the sub-arrays
+    // are all not-null.  This is not true in generally, as code can
+    // slam NULLs down in the subarrays.
+    if (make_constant) {
+      return TypeAryPtr::make(TypePtr::Constant, o, arr0, klass, true, Offset(0));
     } else {
-      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, 0);
+      return TypeAryPtr::make(TypePtr::NotNull, arr0, klass, true, Offset(0));
     }
   }
 
   fatal("unhandled object type");
   return NULL;
 }
 
 //------------------------------get_con----------------------------------------
 intptr_t TypeOopPtr::get_con() const {
   assert( _ptr == Null || _ptr == Constant, "" );
-  assert( _offset >= 0, "" );
+  assert(offset() >= 0, "");
 
-  if (_offset != 0) {
+  if (offset() != 0) {
     // After being ported to the compiler interface, the compiler no longer
     // directly manipulates the addresses of oops.  Rather, it only has a pointer
     // to a handle at compile time.  This handle is embedded in the generated
     // code and dereferenced at the time the nmethod is made.  Until that time,
     // it is not reasonable to do arithmetic with the addresses of oops (we don't
@@ -3368,16 +3666,11 @@
 #ifndef PRODUCT
 void TypeOopPtr::dump2( Dict &d, uint depth, outputStream *st ) const {
   st->print("oopptr:%s", ptr_msg[_ptr]);
   if( _klass_is_exact ) st->print(":exact");
   if( const_oop() ) st->print(INTPTR_FORMAT, p2i(const_oop()));
-  switch( _offset ) {
-  case OffsetTop: st->print("+top"); break;
-  case OffsetBot: st->print("+any"); break;
-  case         0: break;
-  default:        st->print("+%d",_offset); break;
-  }
+  _offset.dump2(st);
   if (_instance_id == InstanceTop)
     st->print(",iid=top");
   else if (_instance_id != InstanceBot)
     st->print(",iid=%d",_instance_id);
 
@@ -3390,11 +3683,11 @@
 // TRUE if Type is a singleton type, FALSE otherwise.   Singletons are simple
 // constants
 bool TypeOopPtr::singleton(void) const {
   // detune optimizer to not generate constant oop + constant offset as a constant!
   // TopPTR, Null, AnyNull, Constant are all singletons
-  return (_offset == 0) && !below_centerline(_ptr);
+  return (offset() == 0) && !below_centerline(_ptr);
 }
 
 //------------------------------add_offset-------------------------------------
 const TypePtr *TypeOopPtr::add_offset(intptr_t offset) const {
   return make(_ptr, xadd_offset(offset), _instance_id, add_offset_speculative(offset), _inline_depth);
@@ -3482,25 +3775,29 @@
 const TypeInstPtr *TypeInstPtr::MIRROR;
 const TypeInstPtr *TypeInstPtr::MARK;
 const TypeInstPtr *TypeInstPtr::KLASS;
 
 //------------------------------TypeInstPtr-------------------------------------
-TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, int off,
-                         int instance_id, const TypePtr* speculative, int inline_depth)
-  : TypeOopPtr(InstPtr, ptr, k, xk, o, off, instance_id, speculative, inline_depth),
-    _name(k->name()) {
+TypeInstPtr::TypeInstPtr(PTR ptr, ciKlass* k, bool xk, ciObject* o, Offset off,
+                         bool flat_array, int instance_id, const TypePtr* speculative,
+                         int inline_depth)
+  : TypeOopPtr(InstPtr, ptr, k, xk, o, off, Offset::bottom, instance_id, speculative, inline_depth),
+    _name(k->name()), _flat_array(flat_array) {
    assert(k != NULL &&
           (k->is_loaded() || o == NULL),
           "cannot have constants with non-loaded klass");
+   assert(!klass()->is_valuetype() || !klass()->flatten_array() || flat_array, "incorrect flatten array bit");
+   assert(!flat_array || can_be_value_type(), "incorrect flatten array bit");
 };
 
 //------------------------------make-------------------------------------------
 const TypeInstPtr *TypeInstPtr::make(PTR ptr,
                                      ciKlass* k,
                                      bool xk,
                                      ciObject* o,
-                                     int offset,
+                                     Offset offset,
+                                     bool flat_array,
                                      int instance_id,
                                      const TypePtr* speculative,
                                      int inline_depth) {
   assert( !k->is_loaded() || k->is_instance_klass(), "Must be for instance");
   // Either const_oop() is NULL or else ptr is Constant
@@ -3520,11 +3817,11 @@
     if (xk && ik->is_interface())  xk = false;  // no exact interface
   }
 
   // Now hash this baby
   TypeInstPtr *result =
-    (TypeInstPtr*)(new TypeInstPtr(ptr, k, xk, o ,offset, instance_id, speculative, inline_depth))->hashcons();
+    (TypeInstPtr*)(new TypeInstPtr(ptr, k, xk, o ,offset, flat_array, instance_id, speculative, inline_depth))->hashcons();
 
   return result;
 }
 
 /**
@@ -3553,11 +3850,11 @@
 //------------------------------cast_to_ptr_type-------------------------------
 const Type *TypeInstPtr::cast_to_ptr_type(PTR ptr) const {
   if( ptr == _ptr ) return this;
   // Reconstruct _sig info here since not a problem with later lazy
   // construction, _sig will show up on demand.
-  return make(ptr, klass(), klass_is_exact(), const_oop(), _offset, _instance_id, _speculative, _inline_depth);
+  return make(ptr, klass(), klass_is_exact(), const_oop(), _offset, _flat_array, _instance_id, _speculative, _inline_depth);
 }
 
 
 //-----------------------------cast_to_exactness-------------------------------
 const Type *TypeInstPtr::cast_to_exactness(bool klass_is_exact) const {
@@ -3565,24 +3862,24 @@
   if (!UseExactTypes)  return this;
   if (!_klass->is_loaded())  return this;
   ciInstanceKlass* ik = _klass->as_instance_klass();
   if( (ik->is_final() || _const_oop) )  return this;  // cannot clear xk
   if( ik->is_interface() )              return this;  // cannot set xk
-  return make(ptr(), klass(), klass_is_exact, const_oop(), _offset, _instance_id, _speculative, _inline_depth);
+  return make(ptr(), klass(), klass_is_exact, const_oop(), _offset, _flat_array, _instance_id, _speculative, _inline_depth);
 }
 
 //-----------------------------cast_to_instance_id----------------------------
 const TypeOopPtr *TypeInstPtr::cast_to_instance_id(int instance_id) const {
   if( instance_id == _instance_id ) return this;
-  return make(_ptr, klass(), _klass_is_exact, const_oop(), _offset, instance_id, _speculative, _inline_depth);
+  return make(_ptr, klass(), _klass_is_exact, const_oop(), _offset, _flat_array, instance_id, _speculative, _inline_depth);
 }
 
 //------------------------------xmeet_unloaded---------------------------------
 // Compute the MEET of two InstPtrs when at least one is unloaded.
 // Assume classes are different since called after check for same name/class-loader
 const TypeInstPtr *TypeInstPtr::xmeet_unloaded(const TypeInstPtr *tinst) const {
-    int off = meet_offset(tinst->offset());
+    Offset off = meet_offset(tinst->offset());
     PTR ptr = meet_ptr(tinst->ptr());
     int instance_id = meet_instance_id(tinst->instance_id());
     const TypePtr* speculative = xmeet_speculative(tinst);
     int depth = meet_inline_depth(tinst->inline_depth());
 
@@ -3603,11 +3900,11 @@
       //  BOTTOM  | ........................Object-BOTTOM ..................|
       //
       assert(loaded->ptr() != TypePtr::Null, "insanity check");
       //
       if(      loaded->ptr() == TypePtr::TopPTR ) { return unloaded; }
-      else if (loaded->ptr() == TypePtr::AnyNull) { return TypeInstPtr::make(ptr, unloaded->klass(), false, NULL, off, instance_id, speculative, depth); }
+      else if (loaded->ptr() == TypePtr::AnyNull) { return TypeInstPtr::make(ptr, unloaded->klass(), false, NULL, off, false, instance_id, speculative, depth); }
       else if (loaded->ptr() == TypePtr::BotPTR ) { return TypeInstPtr::BOTTOM; }
       else if (loaded->ptr() == TypePtr::Constant || loaded->ptr() == TypePtr::NotNull) {
         if (unloaded->ptr() == TypePtr::BotPTR  ) { return TypeInstPtr::BOTTOM;  }
         else                                      { return TypeInstPtr::NOTNULL; }
       }
@@ -3656,28 +3953,28 @@
   case KlassPtr:
   case RawPtr: return TypePtr::BOTTOM;
 
   case AryPtr: {                // All arrays inherit from Object class
     const TypeAryPtr *tp = t->is_aryptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     int instance_id = meet_instance_id(tp->instance_id());
     const TypePtr* speculative = xmeet_speculative(tp);
     int depth = meet_inline_depth(tp->inline_depth());
     switch (ptr) {
     case TopPTR:
     case AnyNull:                // Fall 'down' to dual of object klass
       // For instances when a subclass meets a superclass we fall
       // below the centerline when the superclass is exact. We need to
       // do the same here.
-      if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact()) {
-        return TypeAryPtr::make(ptr, tp->ary(), tp->klass(), tp->klass_is_exact(), offset, instance_id, speculative, depth);
+      if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact() && !flat_array()) {
+        return TypeAryPtr::make(ptr, tp->ary(), tp->klass(), tp->klass_is_exact(), offset, tp->field_offset(), instance_id, speculative, depth);
       } else {
         // cannot subclass, so the meet has to fall badly below the centerline
         ptr = NotNull;
         instance_id = InstanceBot;
-        return TypeInstPtr::make( ptr, ciEnv::current()->Object_klass(), false, NULL, offset, instance_id, speculative, depth);
+        return TypeInstPtr::make( ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);
       }
     case Constant:
     case NotNull:
     case BotPTR:                // Fall down to object klass
       // LCA is object_klass, but if we subclass from the top we can do better
@@ -3685,39 +3982,39 @@
         // If 'this' (InstPtr) is above the centerline and it is Object class
         // then we can subclass in the Java class hierarchy.
         // For instances when a subclass meets a superclass we fall
         // below the centerline when the superclass is exact. We need
         // to do the same here.
-        if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact()) {
+        if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact() && !flat_array()) {
           // that is, tp's array type is a subtype of my klass
           return TypeAryPtr::make(ptr, (ptr == Constant ? tp->const_oop() : NULL),
-                                  tp->ary(), tp->klass(), tp->klass_is_exact(), offset, instance_id, speculative, depth);
+                                  tp->ary(), tp->klass(), tp->klass_is_exact(), offset, tp->field_offset(), instance_id, speculative, depth);
         }
       }
       // The other case cannot happen, since I cannot be a subtype of an array.
       // The meet falls down to Object class below centerline.
       if( ptr == Constant )
          ptr = NotNull;
       instance_id = InstanceBot;
-      return make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, instance_id, speculative, depth);
+      return make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);
     default: typerr(t);
     }
   }
 
   case OopPtr: {                // Meeting to OopPtrs
     // Found a OopPtr type vs self-InstPtr type
     const TypeOopPtr *tp = t->is_oopptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     switch (tp->ptr()) {
     case TopPTR:
     case AnyNull: {
       int instance_id = meet_instance_id(InstanceTop);
       const TypePtr* speculative = xmeet_speculative(tp);
       int depth = meet_inline_depth(tp->inline_depth());
       return make(ptr, klass(), klass_is_exact(),
-                  (ptr == Constant ? const_oop() : NULL), offset, instance_id, speculative, depth);
+                  (ptr == Constant ? const_oop() : NULL), offset, flat_array(), instance_id, speculative, depth);
     }
     case NotNull:
     case BotPTR: {
       int instance_id = meet_instance_id(tp->instance_id());
       const TypePtr* speculative = xmeet_speculative(tp);
@@ -3729,11 +4026,11 @@
   }
 
   case AnyPtr: {                // Meeting to AnyPtrs
     // Found an AnyPtr type vs self-InstPtr type
     const TypePtr *tp = t->is_ptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     int instance_id = meet_instance_id(InstanceTop);
     const TypePtr* speculative = xmeet_speculative(tp);
     int depth = meet_inline_depth(tp->inline_depth());
     switch (tp->ptr()) {
@@ -3741,11 +4038,11 @@
       if( ptr == Null ) return TypePtr::make(AnyPtr, ptr, offset, speculative, depth);
       // else fall through to AnyNull
     case TopPTR:
     case AnyNull: {
       return make(ptr, klass(), klass_is_exact(),
-                  (ptr == Constant ? const_oop() : NULL), offset, instance_id, speculative, depth);
+                  (ptr == Constant ? const_oop() : NULL), offset, flat_array(), instance_id, speculative, depth);
     }
     case NotNull:
     case BotPTR:
       return TypePtr::make(AnyPtr, ptr, offset, speculative,depth);
     default: typerr(t);
@@ -3769,29 +4066,32 @@
   */
 
   case InstPtr: {                // Meeting 2 Oops?
     // Found an InstPtr sub-type vs self-InstPtr type
     const TypeInstPtr *tinst = t->is_instptr();
-    int off = meet_offset( tinst->offset() );
+    Offset off = meet_offset( tinst->offset() );
     PTR ptr = meet_ptr( tinst->ptr() );
     int instance_id = meet_instance_id(tinst->instance_id());
     const TypePtr* speculative = xmeet_speculative(tinst);
     int depth = meet_inline_depth(tinst->inline_depth());
 
     // Check for easy case; klasses are equal (and perhaps not loaded!)
     // If we have constants, then we created oops so classes are loaded
     // and we can handle the constants further down.  This case handles
     // both-not-loaded or both-loaded classes
-    if (ptr != Constant && klass()->equals(tinst->klass()) && klass_is_exact() == tinst->klass_is_exact()) {
-      return make(ptr, klass(), klass_is_exact(), NULL, off, instance_id, speculative, depth);
+    if (ptr != Constant && klass()->equals(tinst->klass()) && klass_is_exact() == tinst->klass_is_exact() &&
+        flat_array() == tinst->flat_array()) {
+      return make(ptr, klass(), klass_is_exact(), NULL, off, flat_array(), instance_id, speculative, depth);
     }
 
     // Classes require inspection in the Java klass hierarchy.  Must be loaded.
     ciKlass* tinst_klass = tinst->klass();
     ciKlass* this_klass  = this->klass();
     bool tinst_xk = tinst->klass_is_exact();
     bool this_xk  = this->klass_is_exact();
+    bool tinst_flat_array = tinst->flat_array();
+    bool this_flat_array  = this->flat_array();
     if (!tinst_klass->is_loaded() || !this_klass->is_loaded() ) {
       // One of these classes has not been loaded
       const TypeInstPtr *unloaded_meet = xmeet_unloaded(tinst);
 #ifndef PRODUCT
       if( PrintOpto && Verbose ) {
@@ -3810,10 +4110,13 @@
       tinst_klass = this_klass;
       this_klass = tmp;
       bool tmp2 = tinst_xk;
       tinst_xk = this_xk;
       this_xk = tmp2;
+      tmp2 = tinst_flat_array;
+      tinst_flat_array = this_flat_array;
+      this_flat_array = tmp2;
     }
     if (tinst_klass->is_interface() &&
         !(this_klass->is_interface() ||
           // Treat java/lang/Object as an honorary interface,
           // because we need a bottom for the interface hierarchy.
@@ -3821,34 +4124,37 @@
       // Oop meets interface!
 
       // See if the oop subtypes (implements) interface.
       ciKlass *k;
       bool xk;
+      bool flat_array;
       if( this_klass->is_subtype_of( tinst_klass ) ) {
         // Oop indeed subtypes.  Now keep oop or interface depending
         // on whether we are both above the centerline or either is
         // below the centerline.  If we are on the centerline
         // (e.g., Constant vs. AnyNull interface), use the constant.
         k  = below_centerline(ptr) ? tinst_klass : this_klass;
         // If we are keeping this_klass, keep its exactness too.
         xk = below_centerline(ptr) ? tinst_xk    : this_xk;
+        flat_array = below_centerline(ptr) ? tinst_flat_array    : this_flat_array;
       } else {                  // Does not implement, fall to Object
         // Oop does not implement interface, so mixing falls to Object
         // just like the verifier does (if both are above the
         // centerline fall to interface)
         k = above_centerline(ptr) ? tinst_klass : ciEnv::current()->Object_klass();
         xk = above_centerline(ptr) ? tinst_xk : false;
+        flat_array = above_centerline(ptr) ? tinst_flat_array : false;
         // Watch out for Constant vs. AnyNull interface.
         if (ptr == Constant)  ptr = NotNull;   // forget it was a constant
         instance_id = InstanceBot;
       }
       ciObject* o = NULL;  // the Constant value, if any
       if (ptr == Constant) {
         // Find out which constant.
         o = (this_klass == klass()) ? const_oop() : tinst->const_oop();
       }
-      return make(ptr, k, xk, o, off, instance_id, speculative, depth);
+      return make(ptr, k, xk, o, off, flat_array, instance_id, speculative, depth);
     }
 
     // Either oop vs oop or interface vs interface or interface vs Object
 
     // !!! Here's how the symmetry requirement breaks down into invariants:
@@ -3876,33 +4182,41 @@
     // centerline and or-ed above it.  (N.B. Constants are always exact.)
 
     // Check for subtyping:
     ciKlass *subtype = NULL;
     bool subtype_exact = false;
-    if( tinst_klass->equals(this_klass) ) {
+    bool flat_array = false;
+    if (tinst_klass->equals(this_klass)) {
       subtype = this_klass;
       subtype_exact = below_centerline(ptr) ? (this_xk && tinst_xk) : (this_xk || tinst_xk);
-    } else if( !tinst_xk && this_klass->is_subtype_of( tinst_klass ) ) {
+      flat_array = below_centerline(ptr) ? (this_flat_array && tinst_flat_array) : (this_flat_array || tinst_flat_array);
+    } else if(!tinst_xk && this_klass->is_subtype_of(tinst_klass) && (!tinst_flat_array || this_flat_array)) {
       subtype = this_klass;     // Pick subtyping class
       subtype_exact = this_xk;
-    } else if( !this_xk && tinst_klass->is_subtype_of( this_klass ) ) {
+      flat_array = this_flat_array;
+    } else if(!this_xk && tinst_klass->is_subtype_of(this_klass) && (!this_flat_array || tinst_flat_array)) {
       subtype = tinst_klass;    // Pick subtyping class
       subtype_exact = tinst_xk;
+      flat_array = tinst_flat_array;
     }
 
-    if( subtype ) {
-      if( above_centerline(ptr) ) { // both are up?
+    if (subtype) {
+      if (above_centerline(ptr)) { // both are up?
         this_klass = tinst_klass = subtype;
         this_xk = tinst_xk = subtype_exact;
-      } else if( above_centerline(this ->_ptr) && !above_centerline(tinst->_ptr) ) {
+        this_flat_array = tinst_flat_array = flat_array;
+      } else if (above_centerline(this ->_ptr) && !above_centerline(tinst->_ptr)) {
         this_klass = tinst_klass; // tinst is down; keep down man
         this_xk = tinst_xk;
-      } else if( above_centerline(tinst->_ptr) && !above_centerline(this ->_ptr) ) {
+        this_flat_array = tinst_flat_array;
+      } else if (above_centerline(tinst->_ptr) && !above_centerline(this ->_ptr)) {
         tinst_klass = this_klass; // this is down; keep down man
         tinst_xk = this_xk;
+        tinst_flat_array = this_flat_array;
       } else {
         this_xk = subtype_exact;  // either they are equal, or we'll do an LCA
+        this_flat_array = flat_array;
       }
     }
 
     // Check for classes now being equal
     if (tinst_klass->equals(this_klass)) {
@@ -3921,11 +4235,11 @@
         else if (above_centerline(tinst ->_ptr))
           o = this_oop;
         else
           ptr = NotNull;
       }
-      return make(ptr, this_klass, this_xk, o, off, instance_id, speculative, depth);
+      return make(ptr, this_klass, this_xk, o, off, this_flat_array, instance_id, speculative, depth);
     } // Else classes are not equal
 
     // Since klasses are different, we require a LCA in the Java
     // class hierarchy - which means we have to fall to at least NotNull.
     if( ptr == TopPTR || ptr == AnyNull || ptr == Constant )
@@ -3933,13 +4247,34 @@
 
     instance_id = InstanceBot;
 
     // Now we find the LCA of Java classes
     ciKlass* k = this_klass->least_common_ancestor(tinst_klass);
-    return make(ptr, k, false, NULL, off, instance_id, speculative, depth);
+    return make(ptr, k, false, NULL, off, false, instance_id, speculative, depth);
   } // End of case InstPtr
 
+  case ValueType: {
+    const TypeValueType* tv = t->is_valuetype();
+    if (above_centerline(ptr())) {
+      if (tv->value_klass()->is_subtype_of(_klass)) {
+        return t;
+      } else {
+        return TypeInstPtr::NOTNULL;
+      }
+    } else {
+      PTR ptr = this->_ptr;
+      if (ptr == Constant) {
+        ptr = NotNull;
+      }
+      if (tv->value_klass()->is_subtype_of(_klass)) {
+        return TypeInstPtr::make(ptr, _klass);
+      } else {
+        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass());
+      }
+    }
+  }
+
   } // End of switch
   return this;                  // Return the double constant
 }
 
 
@@ -3948,35 +4283,35 @@
   // must be a singleton type
   if( const_oop() == NULL )  return NULL;
 
   // must be of type java.lang.Class
   if( klass() != ciEnv::current()->Class_klass() )  return NULL;
-
   return const_oop()->as_instance()->java_mirror_type();
 }
 
 
 //------------------------------xdual------------------------------------------
 // Dual: do NOT dual on klasses.  This means I do NOT understand the Java
 // inheritance mechanism.
 const Type *TypeInstPtr::xdual() const {
-  return new TypeInstPtr(dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), dual_instance_id(), dual_speculative(), dual_inline_depth());
+  return new TypeInstPtr(dual_ptr(), klass(), klass_is_exact(), const_oop(), dual_offset(), flat_array(), dual_instance_id(), dual_speculative(), dual_inline_depth());
 }
 
 //------------------------------eq---------------------------------------------
 // Structural equality check for Type representations
 bool TypeInstPtr::eq( const Type *t ) const {
   const TypeInstPtr *p = t->is_instptr();
   return
     klass()->equals(p->klass()) &&
+    flat_array() == p->flat_array() &&
     TypeOopPtr::eq(p);          // Check sub-type stuff
 }
 
 //------------------------------hash-------------------------------------------
 // Type-specific hashing function.
 int TypeInstPtr::hash(void) const {
-  int hash = java_add((jint)klass()->hash(), (jint)TypeOopPtr::hash());
+  int hash = java_add(java_add((jint)klass()->hash(), (jint)TypeOopPtr::hash()), (jint)flat_array());
   return hash;
 }
 
 //------------------------------dump2------------------------------------------
 // Dump oop Type
@@ -4004,17 +4339,18 @@
     break;
   default:
     break;
   }
 
-  if( _offset ) {               // Dump offset, if any
-    if( _offset == OffsetBot )      st->print("+any");
-    else if( _offset == OffsetTop ) st->print("+unknown");
-    else st->print("+%d", _offset);
-  }
+  _offset.dump2(st);
 
   st->print(" *");
+
+  if (flat_array() && !klass()->is_valuetype()) {
+    st->print(" (flatten array)");
+  }
+
   if (_instance_id == InstanceTop)
     st->print(",iid=top");
   else if (_instance_id != InstanceBot)
     st->print(",iid=%d",_instance_id);
 
@@ -4023,35 +4359,40 @@
 }
 #endif
 
 //------------------------------add_offset-------------------------------------
 const TypePtr *TypeInstPtr::add_offset(intptr_t offset) const {
-  return make(_ptr, klass(), klass_is_exact(), const_oop(), xadd_offset(offset),
+  return make(_ptr, klass(), klass_is_exact(), const_oop(), xadd_offset(offset), flat_array(),
               _instance_id, add_offset_speculative(offset), _inline_depth);
 }
 
 const Type *TypeInstPtr::remove_speculative() const {
   if (_speculative == NULL) {
     return this;
   }
   assert(_inline_depth == InlineDepthTop || _inline_depth == InlineDepthBottom, "non speculative type shouldn't have inline depth");
-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset,
+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flat_array(),
               _instance_id, NULL, _inline_depth);
 }
 
 const TypePtr *TypeInstPtr::with_inline_depth(int depth) const {
   if (!UseInlineDepthForSpeculativeTypes) {
     return this;
   }
-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, _instance_id, _speculative, depth);
+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flat_array(), _instance_id, _speculative, depth);
 }
 
 const TypePtr *TypeInstPtr::with_instance_id(int instance_id) const {
   assert(is_known_instance(), "should be known");
-  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, instance_id, _speculative, _inline_depth);
+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, flat_array(), instance_id, _speculative, _inline_depth);
 }
 
+const TypeInstPtr *TypeInstPtr::cast_to_flat_array() const {
+  return make(_ptr, klass(), klass_is_exact(), const_oop(), _offset, true, _instance_id, _speculative, _inline_depth);
+}
+
+
 //=============================================================================
 // Convenience common pre-built types.
 const TypeAryPtr *TypeAryPtr::RANGE;
 const TypeAryPtr *TypeAryPtr::OOPS;
 const TypeAryPtr *TypeAryPtr::NARROWOOPS;
@@ -4060,54 +4401,61 @@
 const TypeAryPtr *TypeAryPtr::CHARS;
 const TypeAryPtr *TypeAryPtr::INTS;
 const TypeAryPtr *TypeAryPtr::LONGS;
 const TypeAryPtr *TypeAryPtr::FLOATS;
 const TypeAryPtr *TypeAryPtr::DOUBLES;
+const TypeAryPtr *TypeAryPtr::VALUES;
 
 //------------------------------make-------------------------------------------
-const TypeAryPtr *TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, int offset,
+const TypeAryPtr* TypeAryPtr::make(PTR ptr, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,
                                    int instance_id, const TypePtr* speculative, int inline_depth) {
   assert(!(k == NULL && ary->_elem->isa_int()),
          "integral arrays must be pre-equipped with a class");
-  if (!xk)  xk = ary->ary_must_be_exact();
+  if (!xk) xk = ary->ary_must_be_exact();
   assert(instance_id <= 0 || xk || !UseExactTypes, "instances are always exactly typed");
   if (!UseExactTypes)  xk = (ptr == Constant);
-  return (TypeAryPtr*)(new TypeAryPtr(ptr, NULL, ary, k, xk, offset, instance_id, false, speculative, inline_depth))->hashcons();
+  return (TypeAryPtr*)(new TypeAryPtr(ptr, NULL, ary, k, xk, offset, field_offset, instance_id, false, speculative, inline_depth))->hashcons();
 }
 
 //------------------------------make-------------------------------------------
-const TypeAryPtr *TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, int offset,
+const TypeAryPtr* TypeAryPtr::make(PTR ptr, ciObject* o, const TypeAry *ary, ciKlass* k, bool xk, Offset offset, Offset field_offset,
                                    int instance_id, const TypePtr* speculative, int inline_depth,
                                    bool is_autobox_cache) {
   assert(!(k == NULL && ary->_elem->isa_int()),
          "integral arrays must be pre-equipped with a class");
   assert( (ptr==Constant && o) || (ptr!=Constant && !o), "" );
   if (!xk)  xk = (o != NULL) || ary->ary_must_be_exact();
   assert(instance_id <= 0 || xk || !UseExactTypes, "instances are always exactly typed");
   if (!UseExactTypes)  xk = (ptr == Constant);
-  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();
+  return (TypeAryPtr*)(new TypeAryPtr(ptr, o, ary, k, xk, offset, field_offset, instance_id, is_autobox_cache, speculative, inline_depth))->hashcons();
 }
 
 //------------------------------cast_to_ptr_type-------------------------------
 const Type *TypeAryPtr::cast_to_ptr_type(PTR ptr) const {
   if( ptr == _ptr ) return this;
-  return make(ptr, const_oop(), _ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);
+  return make(ptr, const_oop(), _ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);
 }
 
 
 //-----------------------------cast_to_exactness-------------------------------
 const Type *TypeAryPtr::cast_to_exactness(bool klass_is_exact) const {
   if( klass_is_exact == _klass_is_exact ) return this;
   if (!UseExactTypes)  return this;
   if (_ary->ary_must_be_exact())  return this;  // cannot clear xk
-  return make(ptr(), const_oop(), _ary, klass(), klass_is_exact, _offset, _instance_id, _speculative, _inline_depth);
+
+  const TypeAry* new_ary = _ary;
+  if (klass() != NULL && klass()->is_obj_array_klass() && klass_is_exact) {
+    // An object array can't be flat or null-free if the klass is exact
+    new_ary = TypeAry::make(elem(), size(), is_stable(), /* not_flat= */ true, /* not_null_free= */ true);
+  }
+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact, _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);
 }
 
 //-----------------------------cast_to_instance_id----------------------------
 const TypeOopPtr *TypeAryPtr::cast_to_instance_id(int instance_id) const {
   if( instance_id == _instance_id ) return this;
-  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);
+  return make(_ptr, const_oop(), _ary, klass(), _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth, _is_autobox_cache);
 }
 
 
 //-----------------------------max_array_length-------------------------------
 // A wrapper around arrayOopDesc::max_array_length(etype) with some input normalization.
@@ -4159,12 +4507,31 @@
 //-------------------------------cast_to_size----------------------------------
 const TypeAryPtr* TypeAryPtr::cast_to_size(const TypeInt* new_size) const {
   assert(new_size != NULL, "");
   new_size = narrow_size_type(new_size);
   if (new_size == size())  return this;
-  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable());
-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);
+  const TypeAry* new_ary = TypeAry::make(elem(), new_size, is_stable(), is_not_flat(), is_not_null_free());
+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);
+}
+
+//-------------------------------cast_to_not_flat------------------------------
+const TypeAryPtr* TypeAryPtr::cast_to_not_flat(bool not_flat) const {
+  if (not_flat == is_not_flat()) {
+    return this;
+  }
+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), not_flat, is_not_null_free());
+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);
+}
+
+//-------------------------------cast_to_not_null_free-------------------------
+const TypeAryPtr* TypeAryPtr::cast_to_not_null_free(bool not_null_free) const {
+  if (not_null_free == is_not_null_free()) {
+    return this;
+  }
+  // Not null free implies not flat
+  const TypeAry* new_ary = TypeAry::make(elem(), size(), is_stable(), not_null_free ? true : is_not_flat(), not_null_free);
+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);
 }
 
 //------------------------------cast_to_stable---------------------------------
 const TypeAryPtr* TypeAryPtr::cast_to_stable(bool stable, int stable_dimension) const {
   if (stable_dimension <= 0 || (stable_dimension == 1 && stable == this->is_stable()))
@@ -4176,13 +4543,13 @@
   if (stable_dimension > 1 && elem_ptr != NULL && elem_ptr->isa_aryptr()) {
     // If this is widened from a narrow oop, TypeAry::make will re-narrow it.
     elem = elem_ptr = elem_ptr->is_aryptr()->cast_to_stable(stable, stable_dimension - 1);
   }
 
-  const TypeAry* new_ary = TypeAry::make(elem, size(), stable);
+  const TypeAry* new_ary = TypeAry::make(elem, size(), stable, is_not_flat(), is_not_null_free());
 
-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth);
+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, _is_autobox_cache);
 }
 
 //-----------------------------stable_dimension--------------------------------
 int TypeAryPtr::stable_dimension() const {
   if (!is_stable())  return 0;
@@ -4199,27 +4566,28 @@
   const TypeOopPtr* etype = elem()->make_oopptr();
   if (etype == NULL)  return this;
   // The pointers in the autobox arrays are always non-null.
   TypePtr::PTR ptr_type = cache ? TypePtr::NotNull : TypePtr::AnyNull;
   etype = etype->cast_to_ptr_type(TypePtr::NotNull)->is_oopptr();
-  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable());
-  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _instance_id, _speculative, _inline_depth, cache);
+  const TypeAry* new_ary = TypeAry::make(etype, size(), is_stable(), is_not_flat(), is_not_null_free());
+  return make(ptr(), const_oop(), new_ary, klass(), klass_is_exact(), _offset, _field_offset, _instance_id, _speculative, _inline_depth, cache);
 }
 
 //------------------------------eq---------------------------------------------
 // Structural equality check for Type representations
 bool TypeAryPtr::eq( const Type *t ) const {
   const TypeAryPtr *p = t->is_aryptr();
   return
     _ary == p->_ary &&  // Check array
-    TypeOopPtr::eq(p);  // Check sub-parts
+    TypeOopPtr::eq(p) &&// Check sub-parts
+    _field_offset == p->_field_offset;
 }
 
 //------------------------------hash-------------------------------------------
 // Type-specific hashing function.
 int TypeAryPtr::hash(void) const {
-  return (intptr_t)_ary + TypeOopPtr::hash();
+  return (intptr_t)_ary + TypeOopPtr::hash() + _field_offset.get();
 }
 
 //------------------------------meet-------------------------------------------
 // Compute the MEET of two types.  It returns a new Type object.
 const Type *TypeAryPtr::xmeet_helper(const Type *t) const {
@@ -4248,20 +4616,20 @@
     typerr(t);
 
   case OopPtr: {                // Meeting to OopPtrs
     // Found a OopPtr type vs self-AryPtr type
     const TypeOopPtr *tp = t->is_oopptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     int depth = meet_inline_depth(tp->inline_depth());
     const TypePtr* speculative = xmeet_speculative(tp);
     switch (tp->ptr()) {
     case TopPTR:
     case AnyNull: {
       int instance_id = meet_instance_id(InstanceTop);
       return make(ptr, (ptr == Constant ? const_oop() : NULL),
-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);
+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);
     }
     case BotPTR:
     case NotNull: {
       int instance_id = meet_instance_id(tp->instance_id());
       return TypeOopPtr::make(ptr, offset, instance_id, speculative, depth);
@@ -4271,11 +4639,11 @@
   }
 
   case AnyPtr: {                // Meeting two AnyPtrs
     // Found an AnyPtr type vs self-AryPtr type
     const TypePtr *tp = t->is_ptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     const TypePtr* speculative = xmeet_speculative(tp);
     int depth = meet_inline_depth(tp->inline_depth());
     switch (tp->ptr()) {
     case TopPTR:
@@ -4287,11 +4655,11 @@
       if( ptr == Null ) return TypePtr::make(AnyPtr, ptr, offset, speculative, depth);
       // else fall through to AnyNull
     case AnyNull: {
       int instance_id = meet_instance_id(InstanceTop);
       return make(ptr, (ptr == Constant ? const_oop() : NULL),
-                  _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);
+                  _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);
     }
     default: ShouldNotReachHere();
     }
   }
 
@@ -4299,11 +4667,12 @@
   case KlassPtr:
   case RawPtr: return TypePtr::BOTTOM;
 
   case AryPtr: {                // Meeting 2 references?
     const TypeAryPtr *tap = t->is_aryptr();
-    int off = meet_offset(tap->offset());
+    Offset off = meet_offset(tap->offset());
+    Offset field_off = meet_field_offset(tap->field_offset());
     const TypeAry *tary = _ary->meet_speculative(tap->_ary)->is_ary();
     PTR ptr = meet_ptr(tap->ptr());
     int instance_id = meet_instance_id(tap->instance_id());
     const TypePtr* speculative = xmeet_speculative(tap);
     int depth = meet_inline_depth(tap->inline_depth());
@@ -4317,28 +4686,39 @@
         lazy_klass = _klass;
       } else {
         // Something like byte[int+] meets char[int+].
         // This must fall to bottom, not (int[-128..65535])[int+].
         instance_id = InstanceBot;
-        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable);
+        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);
       }
     } else // Non integral arrays.
       // Must fall to bottom if exact klasses in upper lattice
       // are not equal or super klass is exact.
       if ((above_centerline(ptr) || ptr == Constant) && klass() != tap->klass() &&
           // meet with top[] and bottom[] are processed further down:
-          tap->_klass != NULL  && this->_klass != NULL   &&
+          tap->_klass != NULL && this->_klass != NULL &&
           // both are exact and not equal:
           ((tap->_klass_is_exact && this->_klass_is_exact) ||
-           // 'tap'  is exact and super or unrelated:
+           // 'tap' is exact and super or unrelated:
            (tap->_klass_is_exact && !tap->klass()->is_subtype_of(klass())) ||
            // 'this' is exact and super or unrelated:
            (this->_klass_is_exact && !klass()->is_subtype_of(tap->klass())))) {
       if (above_centerline(ptr) || (tary->_elem->make_ptr() && above_centerline(tary->_elem->make_ptr()->_ptr))) {
-        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable);
+        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);
+      }
+      return make(NotNull, NULL, tary, lazy_klass, false, off, field_off, InstanceBot, speculative, depth);
+    } else if (klass() != NULL && tap->klass() != NULL && klass()->is_value_array_klass() != tap->klass()->is_value_array_klass()) {
+      // Meeting flattened value type array with non-flattened array. Adjust (field) offset accordingly.
+      if (tary->_elem->isa_valuetype()) {
+        // Result is flattened
+        off = Offset(elem()->isa_valuetype() ? offset() : tap->offset());
+        field_off = elem()->isa_valuetype() ? field_offset() : tap->field_offset();
+      } else if (tary->_elem->make_oopptr() != NULL && tary->_elem->make_oopptr()->isa_instptr() && below_centerline(ptr)) {
+        // Result is non-flattened
+        off = Offset(flattened_offset()).meet(Offset(tap->flattened_offset()));
+        field_off = Offset::bottom;
       }
-      return make(NotNull, NULL, tary, lazy_klass, false, off, InstanceBot, speculative, depth);
     }
 
     bool xk = false;
     switch (tap->ptr()) {
     case AnyNull:
@@ -4347,11 +4727,11 @@
       if (below_centerline(this->_ptr)) {
         xk = this->_klass_is_exact;
       } else {
         xk = (tap->_klass_is_exact || this->_klass_is_exact);
       }
-      return make(ptr, const_oop(), tary, lazy_klass, xk, off, instance_id, speculative, depth);
+      return make(ptr, const_oop(), tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);
     case Constant: {
       ciObject* o = const_oop();
       if( _ptr == Constant ) {
         if( tap->const_oop() != NULL && !o->equals(tap->const_oop()) ) {
           xk = (klass() == tap->klass());
@@ -4366,45 +4746,45 @@
         xk = true;
       } else {
         // Only precise for identical arrays
         xk = this->_klass_is_exact && (klass() == tap->klass());
       }
-      return TypeAryPtr::make(ptr, o, tary, lazy_klass, xk, off, instance_id, speculative, depth);
+      return TypeAryPtr::make(ptr, o, tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);
     }
     case NotNull:
     case BotPTR:
       // Compute new klass on demand, do not use tap->_klass
       if (above_centerline(this->_ptr))
             xk = tap->_klass_is_exact;
       else  xk = (tap->_klass_is_exact & this->_klass_is_exact) &&
               (klass() == tap->klass()); // Only precise for identical arrays
-      return TypeAryPtr::make(ptr, NULL, tary, lazy_klass, xk, off, instance_id, speculative, depth);
+      return TypeAryPtr::make(ptr, NULL, tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);
     default: ShouldNotReachHere();
     }
   }
 
   // All arrays inherit from Object class
   case InstPtr: {
     const TypeInstPtr *tp = t->is_instptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     int instance_id = meet_instance_id(tp->instance_id());
     const TypePtr* speculative = xmeet_speculative(tp);
     int depth = meet_inline_depth(tp->inline_depth());
     switch (ptr) {
     case TopPTR:
     case AnyNull:                // Fall 'down' to dual of object klass
       // For instances when a subclass meets a superclass we fall
       // below the centerline when the superclass is exact. We need to
       // do the same here.
-      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {
-        return TypeAryPtr::make(ptr, _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);
+      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flat_array()) {
+        return TypeAryPtr::make(ptr, _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);
       } else {
         // cannot subclass, so the meet has to fall badly below the centerline
         ptr = NotNull;
         instance_id = InstanceBot;
-        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL,offset, instance_id, speculative, depth);
+        return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);
       }
     case Constant:
     case NotNull:
     case BotPTR:                // Fall down to object klass
       // LCA is object_klass, but if we subclass from the top we can do better
@@ -4412,33 +4792,55 @@
         // If 'tp'  is above the centerline and it is Object class
         // then we can subclass in the Java class hierarchy.
         // For instances when a subclass meets a superclass we fall
         // below the centerline when the superclass is exact. We need
         // to do the same here.
-        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {
+        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact() && !tp->flat_array()) {
           // that is, my array type is a subtype of 'tp' klass
           return make(ptr, (ptr == Constant ? const_oop() : NULL),
-                      _ary, _klass, _klass_is_exact, offset, instance_id, speculative, depth);
+                      _ary, _klass, _klass_is_exact, offset, _field_offset, instance_id, speculative, depth);
         }
       }
       // The other case cannot happen, since t cannot be a subtype of an array.
       // The meet falls down to Object class below centerline.
       if( ptr == Constant )
          ptr = NotNull;
       instance_id = InstanceBot;
-      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL,offset, instance_id, speculative, depth);
+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass(), false, NULL, offset, false, instance_id, speculative, depth);
     default: typerr(t);
     }
   }
+
+  case ValueType: {
+    const TypeValueType* tv = t->is_valuetype();
+    if (above_centerline(ptr())) {
+      return TypeInstPtr::NOTNULL;
+    } else {
+      PTR ptr = this->_ptr;
+      if (ptr == Constant) {
+        ptr = NotNull;
+      }
+      return TypeInstPtr::make(ptr, ciEnv::current()->Object_klass());
+    }
+  }
   }
   return this;                  // Lint noise
 }
 
 //------------------------------xdual------------------------------------------
 // Dual: compute field-by-field dual
 const Type *TypeAryPtr::xdual() const {
-  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(),_klass, _klass_is_exact, dual_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());
+  return new TypeAryPtr(dual_ptr(), _const_oop, _ary->dual()->is_ary(), _klass, _klass_is_exact, dual_offset(), dual_field_offset(), dual_instance_id(), is_autobox_cache(), dual_speculative(), dual_inline_depth());
+}
+
+Type::Offset TypeAryPtr::meet_field_offset(const Type::Offset offset) const {
+  return _field_offset.meet(offset);
+}
+
+//------------------------------dual_offset------------------------------------
+Type::Offset TypeAryPtr::dual_field_offset() const {
+  return _field_offset.dual();
 }
 
 //----------------------interface_vs_oop---------------------------------------
 #ifdef ASSERT
 bool TypeAryPtr::interface_vs_oop(const Type *t) const {
@@ -4471,20 +4873,25 @@
     break;
   default:
     break;
   }
 
-  if( _offset != 0 ) {
+  if (elem()->isa_valuetype()) {
+    st->print("(");
+    _field_offset.dump2(st);
+    st->print(")");
+  }
+  if (offset() != 0) {
     int header_size = objArrayOopDesc::header_size() * wordSize;
-    if( _offset == OffsetTop )       st->print("+undefined");
-    else if( _offset == OffsetBot )  st->print("+any");
-    else if( _offset < header_size ) st->print("+%d", _offset);
+    if( _offset == Offset::top )       st->print("+undefined");
+    else if( _offset == Offset::bottom )  st->print("+any");
+    else if( offset() < header_size ) st->print("+%d", offset());
     else {
       BasicType basic_elem_type = elem()->basic_type();
       int array_base = arrayOopDesc::base_offset_in_bytes(basic_elem_type);
       int elem_size = type2aelembytes(basic_elem_type);
-      st->print("[%d]", (_offset - array_base)/elem_size);
+      st->print("[%d]", (offset() - array_base)/elem_size);
     }
   }
   st->print(" *");
   if (_instance_id == InstanceTop)
     st->print(",iid=top");
@@ -4501,35 +4908,99 @@
   return TypeOopPtr::empty();
 }
 
 //------------------------------add_offset-------------------------------------
 const TypePtr *TypeAryPtr::add_offset(intptr_t offset) const {
-  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _instance_id, add_offset_speculative(offset), _inline_depth);
+  return make(_ptr, _const_oop, _ary, _klass, _klass_is_exact, xadd_offset(offset), _field_offset, _instance_id, add_offset_speculative(offset), _inline_depth, _is_autobox_cache);
 }
 
 const Type *TypeAryPtr::remove_speculative() const {
   if (_speculative == NULL) {
     return this;
   }
   assert(_inline_depth == InlineDepthTop || _inline_depth == InlineDepthBottom, "non speculative type shouldn't have inline depth");
-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, NULL, _inline_depth);
+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, NULL, _inline_depth, _is_autobox_cache);
+}
+
+const Type* TypeAryPtr::cleanup_speculative() const {
+  if (speculative() == NULL) {
+    return this;
+  }
+  // Keep speculative part if it contains information about flat-/nullability
+  const TypeAryPtr* spec_aryptr = speculative()->isa_aryptr();
+  if (spec_aryptr != NULL && (spec_aryptr->is_not_flat() || spec_aryptr->is_not_null_free())) {
+    return this;
+  }
+  return TypeOopPtr::cleanup_speculative();
 }
 
 const TypePtr *TypeAryPtr::with_inline_depth(int depth) const {
   if (!UseInlineDepthForSpeculativeTypes) {
     return this;
   }
-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _instance_id, _speculative, depth);
+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, _instance_id, _speculative, depth, _is_autobox_cache);
+}
+
+const TypeAryPtr* TypeAryPtr::with_field_offset(int offset) const {
+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, Offset(offset), _instance_id, _speculative, _inline_depth, _is_autobox_cache);
+}
+
+const TypePtr* TypeAryPtr::add_field_offset_and_offset(intptr_t offset) const {
+  int adj = 0;
+  if (offset != Type::OffsetBot && offset != Type::OffsetTop) {
+    const Type* elemtype = elem();
+    if (elemtype->isa_valuetype()) {
+      if (_offset.get() != OffsetBot && _offset.get() != OffsetTop) {
+        adj = _offset.get();
+        offset += _offset.get();
+      }
+      uint header = arrayOopDesc::base_offset_in_bytes(T_OBJECT);
+      if (_field_offset.get() != OffsetBot && _field_offset.get() != OffsetTop) {
+        offset += _field_offset.get();
+        if (_offset.get() == OffsetBot || _offset.get() == OffsetTop) {
+          offset += header;
+        }
+      }
+      if (offset >= (intptr_t)header || offset < 0) {
+        // Try to get the field of the value type array element we are pointing to
+        ciKlass* arytype_klass = klass();
+        ciValueArrayKlass* vak = arytype_klass->as_value_array_klass();
+        ciValueKlass* vk = vak->element_klass()->as_value_klass();
+        int shift = vak->log2_element_size();
+        int mask = (1 << shift) - 1;
+        intptr_t field_offset = ((offset - header) & mask);
+        ciField* field = vk->get_field_by_offset(field_offset + vk->first_field_offset(), false);
+        if (field == NULL) {
+          // This may happen with nested AddP(base, AddP(base, base, offset), longcon(16))
+          return add_offset(offset);
+        } else {
+          return with_field_offset(field_offset)->add_offset(offset - field_offset - adj);
+        }
+      }
+    }
+  }
+  return add_offset(offset - adj);
+}
+
+// Return offset incremented by field_offset for flattened value type arrays
+const int TypeAryPtr::flattened_offset() const {
+  int offset = _offset.get();
+  if (offset != Type::OffsetBot && offset != Type::OffsetTop &&
+      _field_offset != Offset::bottom && _field_offset != Offset::top) {
+    offset += _field_offset.get();
+  }
+  return offset;
 }
 
 const TypePtr *TypeAryPtr::with_instance_id(int instance_id) const {
   assert(is_known_instance(), "should be known");
-  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, instance_id, _speculative, _inline_depth);
+  return make(_ptr, _const_oop, _ary->remove_speculative()->is_ary(), _klass, _klass_is_exact, _offset, _field_offset, instance_id, _speculative, _inline_depth);
 }
 
 //=============================================================================
 
+
 //------------------------------hash-------------------------------------------
 // Type-specific hashing function.
 int TypeNarrowPtr::hash(void) const {
   return _ptrtype->hash() + 7;
 }
@@ -4614,16 +5085,18 @@
   case AryPtr:
   case MetadataPtr:
   case KlassPtr:
   case NarrowOop:
   case NarrowKlass:
-
   case Bottom:                  // Ye Olde Default
     return Type::BOTTOM;
   case Top:
     return this;
 
+  case ValueType:
+    return t->xmeet(this);
+
   default:                      // All else is a mistake
     typerr(t);
 
   } // End of switch
 
@@ -4698,11 +5171,11 @@
 // TRUE if Type is a singleton type, FALSE otherwise.   Singletons are simple
 // constants
 bool TypeMetadataPtr::singleton(void) const {
   // detune optimizer to not generate constant metadata + constant offset as a constant!
   // TopPTR, Null, AnyNull, Constant are all singletons
-  return (_offset == 0) && !below_centerline(_ptr);
+  return (offset() == 0) && !below_centerline(_ptr);
 }
 
 //------------------------------add_offset-------------------------------------
 const TypePtr *TypeMetadataPtr::add_offset( intptr_t offset ) const {
   return make( _ptr, _metadata, xadd_offset(offset));
@@ -4718,13 +5191,13 @@
 }
 
  //------------------------------get_con----------------------------------------
 intptr_t TypeMetadataPtr::get_con() const {
   assert( _ptr == Null || _ptr == Constant, "" );
-  assert( _offset >= 0, "" );
+  assert(offset() >= 0, "");
 
-  if (_offset != 0) {
+  if (offset() != 0) {
     // After being ported to the compiler interface, the compiler no longer
     // directly manipulates the addresses of oops.  Rather, it only has a pointer
     // to a handle at compile time.  This handle is embedded in the generated
     // code and dereferenced at the time the nmethod is made.  Until that time,
     // it is not reasonable to do arithmetic with the addresses of oops (we don't
@@ -4771,11 +5244,11 @@
     typerr(t);
 
   case AnyPtr: {
     // Found an AnyPtr type vs self-OopPtr type
     const TypePtr *tp = t->is_ptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     switch (tp->ptr()) {
     case Null:
       if (ptr == Null)  return TypePtr::make(AnyPtr, ptr, offset, tp->speculative(), tp->inline_depth());
       // else fall through:
@@ -4797,11 +5270,11 @@
   case AryPtr:
     return TypePtr::BOTTOM;     // Oop meet raw is not well defined
 
   case MetadataPtr: {
     const TypeMetadataPtr *tp = t->is_metadataptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR tptr = tp->ptr();
     PTR ptr = meet_ptr(tptr);
     ciMetadata* md = (tptr == TopPTR) ? metadata() : tp->metadata();
     if (tptr == TopPTR || _ptr == TopPTR ||
         metadata()->equals(tp->metadata())) {
@@ -4830,38 +5303,38 @@
 //------------------------------dump2------------------------------------------
 #ifndef PRODUCT
 void TypeMetadataPtr::dump2( Dict &d, uint depth, outputStream *st ) const {
   st->print("metadataptr:%s", ptr_msg[_ptr]);
   if( metadata() ) st->print(INTPTR_FORMAT, p2i(metadata()));
-  switch( _offset ) {
+  switch (offset()) {
   case OffsetTop: st->print("+top"); break;
   case OffsetBot: st->print("+any"); break;
   case         0: break;
-  default:        st->print("+%d",_offset); break;
+  default:        st->print("+%d",offset()); break;
   }
 }
 #endif
 
 
 //=============================================================================
 // Convenience common pre-built type.
 const TypeMetadataPtr *TypeMetadataPtr::BOTTOM;
 
-TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, int offset):
+TypeMetadataPtr::TypeMetadataPtr(PTR ptr, ciMetadata* metadata, Offset offset):
   TypePtr(MetadataPtr, ptr, offset), _metadata(metadata) {
 }
 
 const TypeMetadataPtr* TypeMetadataPtr::make(ciMethod* m) {
-  return make(Constant, m, 0);
+  return make(Constant, m, Offset(0));
 }
 const TypeMetadataPtr* TypeMetadataPtr::make(ciMethodData* m) {
-  return make(Constant, m, 0);
+  return make(Constant, m, Offset(0));
 }
 
 //------------------------------make-------------------------------------------
 // Create a meta data constant
-const TypeMetadataPtr *TypeMetadataPtr::make(PTR ptr, ciMetadata* m, int offset) {
+const TypeMetadataPtr* TypeMetadataPtr::make(PTR ptr, ciMetadata* m, Offset offset) {
   assert(m == NULL || !m->is_klass(), "wrong type");
   return (TypeMetadataPtr*)(new TypeMetadataPtr(ptr, m, offset))->hashcons();
 }
 
 
@@ -4871,47 +5344,43 @@
 // Not-null object klass or below
 const TypeKlassPtr *TypeKlassPtr::OBJECT;
 const TypeKlassPtr *TypeKlassPtr::OBJECT_OR_NULL;
 
 //------------------------------TypeKlassPtr-----------------------------------
-TypeKlassPtr::TypeKlassPtr( PTR ptr, ciKlass* klass, int offset )
-  : TypePtr(KlassPtr, ptr, offset), _klass(klass), _klass_is_exact(ptr == Constant) {
+TypeKlassPtr::TypeKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flat_array)
+  : TypePtr(KlassPtr, ptr, offset), _klass(klass), _klass_is_exact(ptr == Constant), _flat_array(flat_array) {
+   assert(!klass->is_valuetype() || !klass->flatten_array() || flat_array, "incorrect flatten array bit");
+   assert(!flat_array || can_be_value_type(), "incorrect flatten array bit");
 }
 
 //------------------------------make-------------------------------------------
 // ptr to klass 'k', if Constant, or possibly to a sub-klass if not a Constant
-const TypeKlassPtr *TypeKlassPtr::make( PTR ptr, ciKlass* k, int offset ) {
-  assert( k != NULL, "Expect a non-NULL klass");
-  assert(k->is_instance_klass() || k->is_array_klass(), "Incorrect type of klass oop");
-  TypeKlassPtr *r =
-    (TypeKlassPtr*)(new TypeKlassPtr(ptr, k, offset))->hashcons();
-
-  return r;
+const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* k, Offset offset, bool flat_array) {
+  assert(k == NULL || k->is_instance_klass() || k->is_array_klass(), "Incorrect type of klass oop");
+  return (TypeKlassPtr*)(new TypeKlassPtr(ptr, k, offset, flat_array))->hashcons();
 }
 
 //------------------------------eq---------------------------------------------
 // Structural equality check for Type representations
 bool TypeKlassPtr::eq( const Type *t ) const {
   const TypeKlassPtr *p = t->is_klassptr();
-  return
-    klass()->equals(p->klass()) &&
-    TypePtr::eq(p);
+  return klass() == p->klass() && TypePtr::eq(p) && flat_array() == p->flat_array();
 }
 
 //------------------------------hash-------------------------------------------
 // Type-specific hashing function.
 int TypeKlassPtr::hash(void) const {
-  return java_add((jint)klass()->hash(), (jint)TypePtr::hash());
+  return java_add(java_add(klass() != NULL ? klass()->hash() : (jint)0, (jint)TypePtr::hash()), (jint)flat_array());
 }
 
 //------------------------------singleton--------------------------------------
 // TRUE if Type is a singleton type, FALSE otherwise.   Singletons are simple
 // constants
 bool TypeKlassPtr::singleton(void) const {
   // detune optimizer to not generate constant klass + constant offset as a constant!
   // TopPTR, Null, AnyNull, Constant are all singletons
-  return (_offset == 0) && !below_centerline(_ptr);
+  return (offset() == 0) && !below_centerline(_ptr);
 }
 
 // Do not allow interface-vs.-noninterface joins to collapse to top.
 const Type *TypeKlassPtr::filter_helper(const Type *kills, bool include_speculative) const {
   // logic here mirrors the one from TypeOopPtr::filter. See comments
@@ -4919,11 +5388,11 @@
   const Type* ft = join_helper(kills, include_speculative);
   const TypeKlassPtr* ftkp = ft->isa_klassptr();
   const TypeKlassPtr* ktkp = kills->isa_klassptr();
 
   if (ft->empty()) {
-    if (!empty() && ktkp != NULL && ktkp->klass()->is_loaded() && ktkp->klass()->is_interface())
+    if (!empty() && ktkp != NULL && ktkp->is_loaded() && ktkp->klass()->is_interface())
       return kills;             // Uplift to interface
 
     return Type::TOP;           // Canonical empty value
   }
 
@@ -4942,21 +5411,25 @@
 //----------------------compute_klass------------------------------------------
 // Compute the defining klass for this class
 ciKlass* TypeAryPtr::compute_klass(DEBUG_ONLY(bool verify)) const {
   // Compute _klass based on element type.
   ciKlass* k_ary = NULL;
-  const TypeInstPtr *tinst;
   const TypeAryPtr *tary;
   const Type* el = elem();
   if (el->isa_narrowoop()) {
     el = el->make_ptr();
   }
 
   // Get element klass
-  if ((tinst = el->isa_instptr()) != NULL) {
-    // Compute array klass from element klass
-    k_ary = ciObjArrayKlass::make(tinst->klass());
+  if (el->isa_instptr()) {
+    // Compute object array klass from element klass
+    k_ary = ciArrayKlass::make(el->is_oopptr()->klass());
+  } else if (el->isa_valuetype()) {
+    // If element type is TypeValueType::BOTTOM, value_klass() will be null.
+    if (el->value_klass() != NULL) {
+      k_ary = ciArrayKlass::make(el->value_klass());
+    }
   } else if ((tary = el->isa_aryptr()) != NULL) {
     // Compute array klass from element klass
     ciKlass* k_elem = tary->klass();
     // If element type is something like bottom[], k_elem will be null.
     if (k_elem != NULL)
@@ -5017,50 +5490,54 @@
     // Recomputing the underlying ciKlass for each request is
     // a bit less efficient than caching, but calls to
     // TypeAryPtr::OOPS->klass() are not common enough to matter.
     ((TypeAryPtr*)this)->_klass = k_ary;
     if (UseCompressedOops && k_ary != NULL && k_ary->is_obj_array_klass() &&
-        _offset != 0 && _offset != arrayOopDesc::length_offset_in_bytes()) {
+        offset() != 0 && offset() != arrayOopDesc::length_offset_in_bytes()) {
       ((TypeAryPtr*)this)->_is_ptr_to_narrowoop = true;
     }
   }
   return k_ary;
 }
 
 
 //------------------------------add_offset-------------------------------------
 // Access internals of klass object
 const TypePtr *TypeKlassPtr::add_offset( intptr_t offset ) const {
-  return make( _ptr, klass(), xadd_offset(offset) );
+  return make(_ptr, klass(), xadd_offset(offset), flat_array());
 }
 
 //------------------------------cast_to_ptr_type-------------------------------
 const Type *TypeKlassPtr::cast_to_ptr_type(PTR ptr) const {
   assert(_base == KlassPtr, "subclass must override cast_to_ptr_type");
   if( ptr == _ptr ) return this;
-  return make(ptr, _klass, _offset);
+  return make(ptr, _klass, _offset, _flat_array);
 }
 
 
 //-----------------------------cast_to_exactness-------------------------------
 const Type *TypeKlassPtr::cast_to_exactness(bool klass_is_exact) const {
   if( klass_is_exact == _klass_is_exact ) return this;
   if (!UseExactTypes)  return this;
-  return make(klass_is_exact ? Constant : NotNull, _klass, _offset);
+  return make(klass_is_exact ? Constant : NotNull, _klass, _offset, _flat_array);
 }
 
 
 //-----------------------------as_instance_type--------------------------------
 // Corresponding type for an instance of the given class.
 // It will be NotNull, and exact if and only if the klass type is exact.
 const TypeOopPtr* TypeKlassPtr::as_instance_type() const {
   ciKlass* k = klass();
+  assert(k != NULL, "klass should not be NULL");
   bool    xk = klass_is_exact();
   //return TypeInstPtr::make(TypePtr::NotNull, k, xk, NULL, 0);
   const TypeOopPtr* toop = TypeOopPtr::make_from_klass_raw(k);
   guarantee(toop != NULL, "need type for given klass");
   toop = toop->cast_to_ptr_type(TypePtr::NotNull)->is_oopptr();
+  if (flat_array() && !klass()->is_valuetype()) {
+    toop = toop->is_instptr()->cast_to_flat_array();
+  }
   return toop->cast_to_exactness(xk)->is_oopptr();
 }
 
 
 //------------------------------xmeet------------------------------------------
@@ -5091,19 +5568,19 @@
     typerr(t);
 
   case AnyPtr: {                // Meeting to AnyPtrs
     // Found an AnyPtr type vs self-KlassPtr type
     const TypePtr *tp = t->is_ptr();
-    int offset = meet_offset(tp->offset());
+    Offset offset = meet_offset(tp->offset());
     PTR ptr = meet_ptr(tp->ptr());
     switch (tp->ptr()) {
     case TopPTR:
       return this;
     case Null:
       if( ptr == Null ) return TypePtr::make(AnyPtr, ptr, offset, tp->speculative(), tp->inline_depth());
     case AnyNull:
-      return make( ptr, klass(), offset );
+      return make(ptr, klass(), offset, flat_array());
     case BotPTR:
     case NotNull:
       return TypePtr::make(AnyPtr, ptr, offset, tp->speculative(), tp->inline_depth());
     default: typerr(t);
     }
@@ -5132,26 +5609,37 @@
   //             A-bot         }
   //
 
   case KlassPtr: {  // Meet two KlassPtr types
     const TypeKlassPtr *tkls = t->is_klassptr();
-    int  off     = meet_offset(tkls->offset());
+    Offset  off  = meet_offset(tkls->offset());
     PTR  ptr     = meet_ptr(tkls->ptr());
 
+    if (klass() == NULL || tkls->klass() == NULL) {
+      ciKlass* k = NULL;
+      if (ptr == Constant) {
+        k = (klass() == NULL) ? tkls->klass() : klass();
+      }
+      return make(ptr, k, off, false);
+    }
+
     // Check for easy case; klasses are equal (and perhaps not loaded!)
     // If we have constants, then we created oops so classes are loaded
     // and we can handle the constants further down.  This case handles
     // not-loaded classes
-    if( ptr != Constant && tkls->klass()->equals(klass()) ) {
-      return make( ptr, klass(), off );
+    if (ptr != Constant && tkls->klass()->equals(klass()) && flat_array() == tkls->flat_array()) {
+      return make(ptr, klass(), off, flat_array());
     }
 
     // Classes require inspection in the Java klass hierarchy.  Must be loaded.
     ciKlass* tkls_klass = tkls->klass();
     ciKlass* this_klass = this->klass();
     assert( tkls_klass->is_loaded(), "This class should have been loaded.");
     assert( this_klass->is_loaded(), "This class should have been loaded.");
+    bool tkls_flat_array = tkls->flat_array();
+    bool this_flat_array  = this->flat_array();
+    bool flat_array = below_centerline(ptr) ? (this_flat_array && tkls_flat_array) : (this_flat_array || tkls_flat_array);
 
     // If 'this' type is above the centerline and is a superclass of the
     // other, we can treat 'this' as having the same type as the other.
     if ((above_centerline(this->ptr())) &&
         tkls_klass->is_subtype_of(this_klass)) {
@@ -5175,38 +5663,38 @@
         else if (above_centerline(this->ptr()));
         else if (above_centerline(tkls->ptr()));
         else
           ptr = NotNull;
       }
-      return make( ptr, this_klass, off );
+      return make(ptr, this_klass, off, flat_array);
     } // Else classes are not equal
 
     // Since klasses are different, we require the LCA in the Java
     // class hierarchy - which means we have to fall to at least NotNull.
     if( ptr == TopPTR || ptr == AnyNull || ptr == Constant )
       ptr = NotNull;
     // Now we find the LCA of Java classes
     ciKlass* k = this_klass->least_common_ancestor(tkls_klass);
-    return   make( ptr, k, off );
+    return   make(ptr, k, off, k->is_valuetype() && k->flatten_array());
   } // End of case KlassPtr
 
   } // End of switch
   return this;                  // Return the double constant
 }
 
 //------------------------------xdual------------------------------------------
 // Dual: compute field-by-field dual
 const Type    *TypeKlassPtr::xdual() const {
-  return new TypeKlassPtr( dual_ptr(), klass(), dual_offset() );
+  return new TypeKlassPtr(dual_ptr(), klass(), dual_offset(), flat_array());
 }
 
 //------------------------------get_con----------------------------------------
 intptr_t TypeKlassPtr::get_con() const {
   assert( _ptr == Null || _ptr == Constant, "" );
-  assert( _offset >= 0, "" );
+  assert(offset() >= 0, "");
 
-  if (_offset != 0) {
+  if (offset() != 0) {
     // After being ported to the compiler interface, the compiler no longer
     // directly manipulates the addresses of oops.  Rather, it only has a pointer
     // to a handle at compile time.  This handle is embedded in the generated
     // code and dereferenced at the time the nmethod is made.  Until that time,
     // it is not reasonable to do arithmetic with the addresses of oops (we don't
@@ -5225,15 +5713,15 @@
   switch( _ptr ) {
   case Constant:
     st->print("precise ");
   case NotNull:
     {
-      const char *name = klass()->name()->as_utf8();
-      if( name ) {
+      if (klass() != NULL) {
+        const char* name = klass()->name()->as_utf8();
         st->print("klass %s: " INTPTR_FORMAT, name, p2i(klass()));
       } else {
-        ShouldNotReachHere();
+        st->print("klass BOTTOM");
       }
     }
   case BotPTR:
     if( !WizardMode && !Verbose && !_klass_is_exact ) break;
   case TopPTR:
@@ -5243,15 +5731,11 @@
     break;
   default:
     break;
   }
 
-  if( _offset ) {               // Dump offset, if any
-    if( _offset == OffsetBot )      { st->print("+any"); }
-    else if( _offset == OffsetTop ) { st->print("+unknown"); }
-    else                            { st->print("+%d", _offset); }
-  }
+  _offset.dump2(st);
 
   st->print(" *");
 }
 #endif
 
@@ -5259,28 +5743,50 @@
 
 //=============================================================================
 // Convenience common pre-built types.
 
 //------------------------------make-------------------------------------------
-const TypeFunc *TypeFunc::make( const TypeTuple *domain, const TypeTuple *range ) {
-  return (TypeFunc*)(new TypeFunc(domain,range))->hashcons();
+const TypeFunc *TypeFunc::make(const TypeTuple *domain_sig, const TypeTuple* domain_cc,
+                               const TypeTuple *range_sig, const TypeTuple *range_cc) {
+  return (TypeFunc*)(new TypeFunc(domain_sig, domain_cc, range_sig, range_cc))->hashcons();
+}
+
+const TypeFunc *TypeFunc::make(const TypeTuple *domain, const TypeTuple *range) {
+  return make(domain, domain, range, range);
+}
+
+//------------------------------osr_domain-----------------------------
+const TypeTuple* osr_domain() {
+  const Type **fields = TypeTuple::fields(2);
+  fields[TypeFunc::Parms+0] = TypeRawPtr::BOTTOM;  // address of osr buffer
+  return TypeTuple::make(TypeFunc::Parms+1, fields);
 }
 
 //------------------------------make-------------------------------------------
-const TypeFunc *TypeFunc::make(ciMethod* method) {
+const TypeFunc* TypeFunc::make(ciMethod* method, bool is_osr_compilation) {
   Compile* C = Compile::current();
-  const TypeFunc* tf = C->last_tf(method); // check cache
-  if (tf != NULL)  return tf;  // The hit rate here is almost 50%.
-  const TypeTuple *domain;
-  if (method->is_static()) {
-    domain = TypeTuple::make_domain(NULL, method->signature());
-  } else {
-    domain = TypeTuple::make_domain(method->holder(), method->signature());
+  const TypeFunc* tf = NULL;
+  if (!is_osr_compilation) {
+    tf = C->last_tf(method); // check cache
+    if (tf != NULL)  return tf;  // The hit rate here is almost 50%.
+  }
+  // Value types are not passed/returned by reference, instead each field of
+  // the value type is passed/returned as an argument. We maintain two views of
+  // the argument/return list here: one based on the signature (with a value
+  // type argument/return as a single slot), one based on the actual calling
+  // convention (with a value type argument/return as a list of its fields).
+  bool has_scalar_args = method->has_scalarized_args() && !is_osr_compilation;
+  const TypeTuple* domain_sig = is_osr_compilation ? osr_domain() : TypeTuple::make_domain(method, false);
+  const TypeTuple* domain_cc = has_scalar_args ? TypeTuple::make_domain(method, true) : domain_sig;
+  ciSignature* sig = method->signature();
+  bool has_scalar_ret = sig->returns_never_null() && sig->return_type()->as_value_klass()->can_be_returned_as_fields();
+  const TypeTuple* range_sig = TypeTuple::make_range(sig, false);
+  const TypeTuple* range_cc = has_scalar_ret ? TypeTuple::make_range(sig, true) : range_sig;
+  tf = TypeFunc::make(domain_sig, domain_cc, range_sig, range_cc);
+  if (!is_osr_compilation) {
+    C->set_last_tf(method, tf);  // fill cache
   }
-  const TypeTuple *range  = TypeTuple::make_range(method->signature());
-  tf = TypeFunc::make(domain, range);
-  C->set_last_tf(method, tf);  // fill cache
   return tf;
 }
 
 //------------------------------meet-------------------------------------------
 // Compute the MEET of two types.  It returns a new Type object.
@@ -5311,46 +5817,48 @@
 
 //------------------------------eq---------------------------------------------
 // Structural equality check for Type representations
 bool TypeFunc::eq( const Type *t ) const {
   const TypeFunc *a = (const TypeFunc*)t;
-  return _domain == a->_domain &&
-    _range == a->_range;
+  return _domain_sig == a->_domain_sig &&
+    _domain_cc == a->_domain_cc &&
+    _range_sig == a->_range_sig &&
+    _range_cc == a->_range_cc;
 }
 
 //------------------------------hash-------------------------------------------
 // Type-specific hashing function.
 int TypeFunc::hash(void) const {
-  return (intptr_t)_domain + (intptr_t)_range;
+  return (intptr_t)_domain_sig + (intptr_t)_domain_cc + (intptr_t)_range_sig + (intptr_t)_range_cc;
 }
 
 //------------------------------dump2------------------------------------------
 // Dump Function Type
 #ifndef PRODUCT
 void TypeFunc::dump2( Dict &d, uint depth, outputStream *st ) const {
-  if( _range->cnt() <= Parms )
+  if( _range_sig->cnt() <= Parms )
     st->print("void");
   else {
     uint i;
-    for (i = Parms; i < _range->cnt()-1; i++) {
-      _range->field_at(i)->dump2(d,depth,st);
+    for (i = Parms; i < _range_sig->cnt()-1; i++) {
+      _range_sig->field_at(i)->dump2(d,depth,st);
       st->print("/");
     }
-    _range->field_at(i)->dump2(d,depth,st);
+    _range_sig->field_at(i)->dump2(d,depth,st);
   }
   st->print(" ");
   st->print("( ");
   if( !depth || d[this] ) {     // Check for recursive dump
     st->print("...)");
     return;
   }
   d.Insert((void*)this,(void*)this);    // Stop recursion
-  if (Parms < _domain->cnt())
-    _domain->field_at(Parms)->dump2(d,depth-1,st);
-  for (uint i = Parms+1; i < _domain->cnt(); i++) {
+  if (Parms < _domain_sig->cnt())
+    _domain_sig->field_at(Parms)->dump2(d,depth-1,st);
+  for (uint i = Parms+1; i < _domain_sig->cnt(); i++) {
     st->print(", ");
-    _domain->field_at(i)->dump2(d,depth-1,st);
+    _domain_sig->field_at(i)->dump2(d,depth-1,st);
   }
   st->print(" )");
 }
 #endif
 
@@ -5366,10 +5874,10 @@
   return false;                 // Never empty
 }
 
 
 BasicType TypeFunc::return_type() const{
-  if (range()->cnt() == TypeFunc::Parms) {
+  if (range_sig()->cnt() == TypeFunc::Parms) {
     return T_VOID;
   }
-  return range()->field_at(TypeFunc::Parms)->basic_type();
+  return range_sig()->field_at(TypeFunc::Parms)->basic_type();
 }
diff a/src/hotspot/share/precompiled/precompiled.hpp b/src/hotspot/share/precompiled/precompiled.hpp
--- a/src/hotspot/share/precompiled/precompiled.hpp
+++ b/src/hotspot/share/precompiled/precompiled.hpp
@@ -30,10 +30,11 @@
 // These header files are included in at least 130 C++ files, as of
 // measurements made in November 2018. This list excludes files named
 // *.include.hpp, since including them decreased build performance.
 
 #include "classfile/classLoaderData.hpp"
+# include "ci/ciValueArrayKlass.hpp"
 #include "classfile/javaClasses.hpp"
 #include "classfile/systemDictionary.hpp"
 #include "gc/shared/collectedHeap.hpp"
 #include "gc/shared/gcCause.hpp"
 #include "logging/log.hpp"
diff a/src/hotspot/share/prims/jni.cpp b/src/hotspot/share/prims/jni.cpp
--- a/src/hotspot/share/prims/jni.cpp
+++ b/src/hotspot/share/prims/jni.cpp
@@ -57,10 +57,12 @@
 #include "oops/objArrayOop.inline.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/symbol.hpp"
 #include "oops/typeArrayKlass.hpp"
 #include "oops/typeArrayOop.inline.hpp"
+#include "oops/valueArrayOop.inline.hpp"
+#include "oops/valueKlass.inline.hpp"
 #include "prims/jniCheck.hpp"
 #include "prims/jniExport.hpp"
 #include "prims/jniFastGetField.hpp"
 #include "prims/jvm_misc.hpp"
 #include "prims/jvmtiExport.hpp"
@@ -474,12 +476,13 @@
 
   // The slot is the index of the field description in the field-array
   // The jfieldID is the offset of the field within the object
   // It may also have hash bits for k, if VerifyJNIFields is turned on.
   intptr_t offset = InstanceKlass::cast(k1)->field_offset( slot );
+  bool is_flattened = InstanceKlass::cast(k1)->field_is_flattened(slot);
   assert(InstanceKlass::cast(k1)->contains_field_offset(offset), "stay within object");
-  ret = jfieldIDWorkaround::to_instance_jfieldID(k1, offset);
+  ret = jfieldIDWorkaround::to_instance_jfieldID(k1, offset, is_flattened);
   return ret;
 JNI_END
 
 
 DT_RETURN_MARK_DECL(ToReflectedMethod, jobject
@@ -494,11 +497,11 @@
   DT_RETURN_MARK(ToReflectedMethod, jobject, (const jobject&)ret);
 
   methodHandle m (THREAD, Method::resolve_jmethod_id(method_id));
   assert(m->is_static() == (isStatic != 0), "jni_ToReflectedMethod access flags doesn't match");
   oop reflection_method;
-  if (m->is_initializer()) {
+  if (m->is_object_constructor()) {
     reflection_method = Reflection::new_constructor(m, CHECK_NULL);
   } else {
     reflection_method = Reflection::new_method(m, false, CHECK_NULL);
   }
   ret = JNIHandles::make_local(env, reflection_method);
@@ -556,11 +559,10 @@
   Klass* sub_klass   = java_lang_Class::as_Klass(sub_mirror);
   Klass* super_klass = java_lang_Class::as_Klass(super_mirror);
   assert(sub_klass != NULL && super_klass != NULL, "invalid arguments to jni_IsAssignableFrom");
   jboolean ret = sub_klass->is_subtype_of(super_klass) ?
                    JNI_TRUE : JNI_FALSE;
-
   HOTSPOT_JNI_ISASSIGNABLEFROM_RETURN(ret);
   return ret;
 JNI_END
 
 
@@ -891,11 +893,12 @@
     // float is coerced to double w/ va_arg
     case T_FLOAT:       push_float((jfloat) va_arg(_ap, jdouble)); break;
     case T_DOUBLE:      push_double(va_arg(_ap, jdouble)); break;
 
     case T_ARRAY:
-    case T_OBJECT:      push_object(va_arg(_ap, jobject)); break;
+    case T_OBJECT:
+    case T_VALUETYPE:   push_object(va_arg(_ap, jobject)); break;
     default:            ShouldNotReachHere();
     }
   }
 
  public:
@@ -927,11 +930,12 @@
     case T_BOOLEAN:     push_boolean((_ap++)->z); break;
     case T_LONG:        push_long((_ap++)->j); break;
     case T_FLOAT:       push_float((_ap++)->f); break;
     case T_DOUBLE:      push_double((_ap++)->d); break;
     case T_ARRAY:
-    case T_OBJECT:      push_object((_ap++)->l); break;
+    case T_OBJECT:
+    case T_VALUETYPE:   push_object((_ap++)->l); break;
     default:            ShouldNotReachHere();
     }
   }
 
  public:
@@ -1067,17 +1071,31 @@
   HOTSPOT_JNI_NEWOBJECTA_ENTRY(env, clazz, (uintptr_t) methodID);
 
   jobject obj = NULL;
   DT_RETURN_MARK(NewObjectA, jobject, (const jobject)obj);
 
-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);
-  obj = JNIHandles::make_local(env, i);
-  JavaValue jvalue(T_VOID);
-  JNI_ArgumentPusherArray ap(methodID, args);
-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
+  oop clazzoop = JNIHandles::resolve_non_null(clazz);
+  Klass* k = java_lang_Class::as_Klass(clazzoop);
+  if (k == NULL) {
+    ResourceMark rm(THREAD);
+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);
+  }
+
+  if (!k->is_value()) {
+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);
+    obj = JNIHandles::make_local(env, i);
+    JavaValue jvalue(T_VOID);
+    JNI_ArgumentPusherArray ap(methodID, args);
+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
+  } else {
+    JavaValue jvalue(T_VALUETYPE);
+    JNI_ArgumentPusherArray ap(methodID, args);
+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);
+    obj = jvalue.get_jobject();
+  }
   return obj;
-JNI_END
+  JNI_END
 
 
 DT_RETURN_MARK_DECL(NewObjectV, jobject
                     , HOTSPOT_JNI_NEWOBJECTV_RETURN(_ret_ref));
 
@@ -1087,15 +1105,29 @@
   HOTSPOT_JNI_NEWOBJECTV_ENTRY(env, clazz, (uintptr_t) methodID);
 
   jobject obj = NULL;
   DT_RETURN_MARK(NewObjectV, jobject, (const jobject&)obj);
 
-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);
-  obj = JNIHandles::make_local(env, i);
-  JavaValue jvalue(T_VOID);
-  JNI_ArgumentPusherVaArg ap(methodID, args);
-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
+  oop clazzoop = JNIHandles::resolve_non_null(clazz);
+  Klass* k = java_lang_Class::as_Klass(clazzoop);
+  if (k == NULL) {
+    ResourceMark rm(THREAD);
+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);
+  }
+
+  if (!k->is_value()) {
+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);
+    obj = JNIHandles::make_local(env, i);
+    JavaValue jvalue(T_VOID);
+    JNI_ArgumentPusherVaArg ap(methodID, args);
+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
+  } else {
+    JavaValue jvalue(T_VALUETYPE);
+    JNI_ArgumentPusherVaArg ap(methodID, args);
+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);
+    obj = jvalue.get_jobject();
+  }
   return obj;
 JNI_END
 
 
 DT_RETURN_MARK_DECL(NewObject, jobject
@@ -1107,18 +1139,35 @@
   HOTSPOT_JNI_NEWOBJECT_ENTRY(env, clazz, (uintptr_t) methodID);
 
   jobject obj = NULL;
   DT_RETURN_MARK(NewObject, jobject, (const jobject&)obj);
 
-  instanceOop i = InstanceKlass::allocate_instance(JNIHandles::resolve_non_null(clazz), CHECK_NULL);
-  obj = JNIHandles::make_local(env, i);
-  va_list args;
-  va_start(args, methodID);
-  JavaValue jvalue(T_VOID);
-  JNI_ArgumentPusherVaArg ap(methodID, args);
-  jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
-  va_end(args);
+  oop clazzoop = JNIHandles::resolve_non_null(clazz);
+  Klass* k = java_lang_Class::as_Klass(clazzoop);
+  if (k == NULL) {
+    ResourceMark rm(THREAD);
+    THROW_(vmSymbols::java_lang_InstantiationException(), NULL);
+  }
+
+  if (!k->is_value()) {
+    instanceOop i = InstanceKlass::allocate_instance(clazzoop, CHECK_NULL);
+    obj = JNIHandles::make_local(env, i);
+    va_list args;
+    va_start(args, methodID);
+    JavaValue jvalue(T_VOID);
+    JNI_ArgumentPusherVaArg ap(methodID, args);
+    jni_invoke_nonstatic(env, &jvalue, obj, JNI_NONVIRTUAL, methodID, &ap, CHECK_NULL);
+    va_end(args);
+  } else {
+    va_list args;
+    va_start(args, methodID);
+    JavaValue jvalue(T_VALUETYPE);
+    JNI_ArgumentPusherVaArg ap(methodID, args);
+    jni_invoke_static(env, &jvalue, NULL, JNI_STATIC, methodID, &ap, CHECK_NULL);
+    va_end(args);
+    obj = jvalue.get_jobject();
+  }
   return obj;
 JNI_END
 
 
 JNI_ENTRY(jclass, jni_GetObjectClass(JNIEnv *env, jobject obj))
@@ -1891,28 +1940,39 @@
     THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg("%s.%s %s", k->external_name(), name, sig));
   }
 
   // A jfieldID for a non-static field is simply the offset of the field within the instanceOop
   // It may also have hash bits for k, if VerifyJNIFields is turned on.
-  ret = jfieldIDWorkaround::to_instance_jfieldID(k, fd.offset());
+  ret = jfieldIDWorkaround::to_instance_jfieldID(k, fd.offset(), fd.is_flattened());
   return ret;
 JNI_END
 
 
 JNI_ENTRY(jobject, jni_GetObjectField(JNIEnv *env, jobject obj, jfieldID fieldID))
   JNIWrapper("GetObjectField");
   HOTSPOT_JNI_GETOBJECTFIELD_ENTRY(env, obj, (uintptr_t) fieldID);
   oop o = JNIHandles::resolve_non_null(obj);
   Klass* k = o->klass();
   int offset = jfieldIDWorkaround::from_instance_jfieldID(k, fieldID);
+  oop res = NULL;
   // Keep JVMTI addition small and only check enabled flag here.
   // jni_GetField_probe() assumes that is okay to create handles.
   if (JvmtiExport::should_post_field_access()) {
     o = JvmtiExport::jni_GetField_probe(thread, obj, o, k, fieldID, false);
   }
-  oop loaded_obj = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(o, offset);
-  jobject ret = JNIHandles::make_local(env, loaded_obj);
+  if (!jfieldIDWorkaround::is_flattened_field(fieldID)) {
+    res = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(o, offset);
+  } else {
+    assert(k->is_instance_klass(), "Only instance can have flattened fields");
+    InstanceKlass* ik = InstanceKlass::cast(k);
+    fieldDescriptor fd;
+    ik->find_field_from_offset(offset, false, &fd);  // performance bottleneck
+    InstanceKlass* holder = fd.field_holder();
+    ValueKlass* field_vklass = ValueKlass::cast(holder->get_value_field_klass(fd.index()));
+    res = field_vklass->read_flattened_field(o, ik->field_offset(fd.index()), CHECK_NULL);
+  }
+  jobject ret = JNIHandles::make_local(env, res);
   HOTSPOT_JNI_GETOBJECTFIELD_RETURN(ret);
   return ret;
 JNI_END
 
 
@@ -2006,11 +2066,22 @@
   if (JvmtiExport::should_post_field_modification()) {
     jvalue field_value;
     field_value.l = value;
     o = JvmtiExport::jni_SetField_probe_nh(thread, obj, o, k, fieldID, false, JVM_SIGNATURE_CLASS, (jvalue *)&field_value);
   }
-  HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(o, offset, JNIHandles::resolve(value));
+  if (!jfieldIDWorkaround::is_flattened_field(fieldID)) {
+    HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(o, offset, JNIHandles::resolve(value));
+  } else {
+    assert(k->is_instance_klass(), "Only instances can have flattened fields");
+    InstanceKlass* ik = InstanceKlass::cast(k);
+    fieldDescriptor fd;
+    ik->find_field_from_offset(offset, false, &fd);
+    InstanceKlass* holder = fd.field_holder();
+    ValueKlass* vklass = ValueKlass::cast(holder->get_value_field_klass(fd.index()));
+    oop v = JNIHandles::resolve_non_null(value);
+    vklass->write_flattened_field(o, offset, v, CHECK);
+  }
   HOTSPOT_JNI_SETOBJECTFIELD_RETURN();
 JNI_END
 
 
 #define DEFINE_SETFIELD(Argument,Fieldname,Result,SigType,unionType \
@@ -2443,54 +2514,93 @@
 JNI_ENTRY(jobject, jni_GetObjectArrayElement(JNIEnv *env, jobjectArray array, jsize index))
   JNIWrapper("GetObjectArrayElement");
  HOTSPOT_JNI_GETOBJECTARRAYELEMENT_ENTRY(env, array, index);
   jobject ret = NULL;
   DT_RETURN_MARK(GetObjectArrayElement, jobject, (const jobject&)ret);
-  objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));
-  if (a->is_within_bounds(index)) {
-    ret = JNIHandles::make_local(env, a->obj_at(index));
-    return ret;
+  oop res = NULL;
+  arrayOop arr((arrayOop)JNIHandles::resolve_non_null(array));
+  if (arr->is_within_bounds(index)) {
+    if (arr->is_valueArray()) {
+      valueArrayOop a = valueArrayOop(JNIHandles::resolve_non_null(array));
+      arrayHandle ah(THREAD, a);
+      valueArrayHandle vah(thread, a);
+      res = valueArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK_NULL);
+      assert(res != NULL, "Must be set in one of two paths above");
+    } else {
+      assert(arr->is_objArray(), "If not a valueArray. must be an objArray");
+      objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));
+      res = a->obj_at(index);
+    }
   } else {
     ResourceMark rm(THREAD);
     stringStream ss;
-    ss.print("Index %d out of bounds for length %d", index, a->length());
+    ss.print("Index %d out of bounds for length %d", index,arr->length());
     THROW_MSG_0(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());
   }
+  ret = JNIHandles::make_local(env, res);
+  return ret;
 JNI_END
 
 DT_VOID_RETURN_MARK_DECL(SetObjectArrayElement
                          , HOTSPOT_JNI_SETOBJECTARRAYELEMENT_RETURN());
 
 JNI_ENTRY(void, jni_SetObjectArrayElement(JNIEnv *env, jobjectArray array, jsize index, jobject value))
   JNIWrapper("SetObjectArrayElement");
- HOTSPOT_JNI_SETOBJECTARRAYELEMENT_ENTRY(env, array, index, value);
+  HOTSPOT_JNI_SETOBJECTARRAYELEMENT_ENTRY(env, array, index, value);
   DT_VOID_RETURN_MARK(SetObjectArrayElement);
 
-  objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));
-  oop v = JNIHandles::resolve(value);
-  if (a->is_within_bounds(index)) {
-    if (v == NULL || v->is_a(ObjArrayKlass::cast(a->klass())->element_klass())) {
-      a->obj_at_put(index, v);
-    } else {
-      ResourceMark rm(THREAD);
-      stringStream ss;
-      Klass *bottom_kl = ObjArrayKlass::cast(a->klass())->bottom_klass();
-      ss.print("type mismatch: can not store %s to %s[%d]",
-               v->klass()->external_name(),
-               bottom_kl->is_typeArray_klass() ? type2name_tab[ArrayKlass::cast(bottom_kl)->element_type()] : bottom_kl->external_name(),
-               index);
-      for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {
-        ss.print("[]");
-      }
-      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());
-    }
-  } else {
-    ResourceMark rm(THREAD);
-    stringStream ss;
-    ss.print("Index %d out of bounds for length %d", index, a->length());
-    THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());
-  }
+   bool oob = false;
+   int length = -1;
+   oop res = NULL;
+   arrayOop arr((arrayOop)JNIHandles::resolve_non_null(array));
+   if (arr->is_within_bounds(index)) {
+     if (arr->is_valueArray()) {
+       valueArrayOop a = valueArrayOop(JNIHandles::resolve_non_null(array));
+       oop v = JNIHandles::resolve(value);
+       ValueArrayKlass* vaklass = ValueArrayKlass::cast(a->klass());
+       ValueKlass* element_vklass = vaklass->element_klass();
+       if (v != NULL && v->is_a(element_vklass)) {
+         a->value_copy_to_index(v, index);
+       } else {
+         ResourceMark rm(THREAD);
+         stringStream ss;
+         Klass *kl = ValueArrayKlass::cast(a->klass());
+         ss.print("type mismatch: can not store %s to %s[%d]",
+             v->klass()->external_name(),
+             kl->external_name(),
+             index);
+         for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {
+           ss.print("[]");
+         }
+         THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());
+       }
+     } else {
+       assert(arr->is_objArray(), "If not a valueArray. must be an objArray");
+       objArrayOop a = objArrayOop(JNIHandles::resolve_non_null(array));
+       oop v = JNIHandles::resolve(value);
+       if (v == NULL || v->is_a(ObjArrayKlass::cast(a->klass())->element_klass())) {
+         a->obj_at_put(index, v);
+       } else {
+         ResourceMark rm(THREAD);
+         stringStream ss;
+         Klass *bottom_kl = ObjArrayKlass::cast(a->klass())->bottom_klass();
+         ss.print("type mismatch: can not store %s to %s[%d]",
+             v->klass()->external_name(),
+             bottom_kl->is_typeArray_klass() ? type2name_tab[ArrayKlass::cast(bottom_kl)->element_type()] : bottom_kl->external_name(),
+                 index);
+         for (int dims = ArrayKlass::cast(a->klass())->dimension(); dims > 1; --dims) {
+           ss.print("[]");
+         }
+         THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), ss.as_string());
+       }
+     }
+   } else {
+     ResourceMark rm(THREAD);
+     stringStream ss;
+     ss.print("Index %d out of bounds for length %d", index, arr->length());
+     THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());
+   }
 JNI_END
 
 
 
 #define DEFINE_NEWSCALARARRAY(Return,Allocator,Result \
@@ -3273,10 +3383,285 @@
   JNIWrapper("GetModule");
   return Modules::get_module(clazz, THREAD);
 JNI_END
 
 
+JNI_ENTRY(void*, jni_GetFlattenedArrayElements(JNIEnv* env, jarray array, jboolean* isCopy))
+  JNIWrapper("jni_GetFlattenedArrayElements");
+  if (isCopy != NULL) {
+    *isCopy = JNI_FALSE;
+  }
+  arrayOop ar = arrayOop(JNIHandles::resolve_non_null(array));
+  if (!ar->is_array()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Not an array");
+  }
+  if (!ar->is_valueArray()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Not a flattened array");
+  }
+  ValueArrayKlass* vak = ValueArrayKlass::cast(ar->klass());
+  if (vak->contains_oops()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Flattened array contains oops");
+  }
+  oop a = lock_gc_or_pin_object(thread, array);
+  valueArrayOop vap = valueArrayOop(a);
+  void* ret = vap->value_at_addr(0, vak->layout_helper());
+  return ret;
+JNI_END
+
+JNI_ENTRY(void, jni_ReleaseFlattenedArrayElements(JNIEnv* env, jarray array, void* elem, jint mode))
+  JNIWrapper("jni_ReleaseFlattenedArrayElements");
+  unlock_gc_or_unpin_object(thread, array);
+JNI_END
+
+JNI_ENTRY(jsize, jni_GetFlattenedArrayElementSize(JNIEnv* env, jarray array)) {
+  JNIWrapper("jni_GetFlattenedElementSize");
+  arrayOop a = arrayOop(JNIHandles::resolve_non_null(array));
+  if (!a->is_array()) {
+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), "Not an array");
+  }
+  if (!a->is_valueArray()) {
+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), "Not a flattened array");
+  }
+  ValueArrayKlass* vak = ValueArrayKlass::cast(a->klass());
+  jsize ret = vak->element_byte_size();
+  return ret;
+}
+JNI_END
+
+JNI_ENTRY(jclass, jni_GetFlattenedArrayElementClass(JNIEnv* env, jarray array))
+  JNIWrapper("jni_GetArrayElementClass");
+  arrayOop a = arrayOop(JNIHandles::resolve_non_null(array));
+  if (!a->is_array()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Not an array");
+  }
+  if (!a->is_valueArray()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Not a flattened array");
+  }
+  ValueArrayKlass* vak = ValueArrayKlass::cast(a->klass());
+  ValueKlass* vk = vak->element_klass();
+  return (jclass) JNIHandles::make_local(vk->java_mirror());
+JNI_END
+
+JNI_ENTRY(jsize, jni_GetFieldOffsetInFlattenedLayout(JNIEnv* env, jclass clazz, const char *name, const char *signature, jboolean* isFlattened))
+  JNIWrapper("jni_GetFieldOffsetInFlattenedLayout");
+
+  oop mirror = JNIHandles::resolve_non_null(clazz);
+  Klass* k = java_lang_Class::as_Klass(mirror);
+  if (!k->is_value()) {
+    ResourceMark rm;
+        THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), err_msg("%s has not flattened layout", k->external_name()));
+  }
+  ValueKlass* vk = ValueKlass::cast(k);
+
+  TempNewSymbol fieldname = SymbolTable::probe(name, (int)strlen(name));
+  TempNewSymbol signame = SymbolTable::probe(signature, (int)strlen(signature));
+  if (fieldname == NULL || signame == NULL) {
+    ResourceMark rm;
+    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg("%s.%s %s", vk->external_name(), name, signature));
+  }
+
+  assert(vk->is_initialized(), "If a flattened array has been created, the element klass must have been initialized");
+
+  fieldDescriptor fd;
+  if (!vk->is_instance_klass() ||
+      !InstanceKlass::cast(vk)->find_field(fieldname, signame, false, &fd)) {
+    ResourceMark rm;
+    THROW_MSG_0(vmSymbols::java_lang_NoSuchFieldError(), err_msg("%s.%s %s", vk->external_name(), name, signature));
+  }
+
+  int offset = fd.offset() - vk->first_field_offset();
+  if (isFlattened != NULL) {
+    *isFlattened = fd.is_flattened();
+  }
+  return (jsize)offset;
+JNI_END
+
+JNI_ENTRY(jobject, jni_CreateSubElementSelector(JNIEnv* env, jarray array))
+  JNIWrapper("jni_CreateSubElementSelector");
+
+  arrayOop ar = arrayOop(JNIHandles::resolve_non_null(array));
+  if (!ar->is_array()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Not an array");
+  }
+  if (!ar->is_valueArray()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Not a flattened array");
+  }
+  Klass* ses_k = SystemDictionary::resolve_or_null(vmSymbols::jdk_internal_vm_jni_SubElementSelector(),
+        Handle(THREAD, SystemDictionary::java_system_loader()), Handle(), CHECK_NULL);
+  InstanceKlass* ses_ik = InstanceKlass::cast(ses_k);
+  ses_ik->initialize(CHECK_NULL);
+  Klass* elementKlass = ArrayKlass::cast(ar->klass())->element_klass();
+  oop ses = ses_ik->allocate_instance(CHECK_NULL);
+  Handle ses_h(THREAD, ses);
+  jdk_internal_vm_jni_SubElementSelector::setArrayElementType(ses_h(), elementKlass->java_mirror());
+  jdk_internal_vm_jni_SubElementSelector::setSubElementType(ses_h(), elementKlass->java_mirror());
+  jdk_internal_vm_jni_SubElementSelector::setOffset(ses_h(), 0);
+  jdk_internal_vm_jni_SubElementSelector::setIsFlattened(ses_h(), true);   // by definition, top element of a flattened array is flattened
+  jdk_internal_vm_jni_SubElementSelector::setIsFlattenable(ses_h(), true); // by definition, top element of a flattened array is flattenable
+  return JNIHandles::make_local(ses_h());
+JNI_END
+
+JNI_ENTRY(jobject, jni_GetSubElementSelector(JNIEnv* env, jobject selector, jfieldID fieldID))
+  JNIWrapper("jni_GetSubElementSelector");
+
+  oop slct = JNIHandles::resolve_non_null(selector);
+  if (slct->klass()->name() != vmSymbols::jdk_internal_vm_jni_SubElementSelector()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Not a SubElementSelector");
+  }
+  jboolean isflattened = jdk_internal_vm_jni_SubElementSelector::getIsFlattened(slct);
+  if (!isflattened) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "SubElement is not flattened");
+  }
+  oop semirror = jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct);
+  Klass* k = java_lang_Class::as_Klass(semirror);
+  if (!k->is_value()) {
+    ResourceMark rm;
+        THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), err_msg("%s is not an inline type", k->external_name()));
+  }
+  ValueKlass* vk = ValueKlass::cast(k);
+  assert(vk->is_initialized(), "If a flattened array has been created, the element klass must have been initialized");
+  int field_offset = jfieldIDWorkaround::from_instance_jfieldID(vk, fieldID);
+  fieldDescriptor fd;
+  if (!vk->find_field_from_offset(field_offset, false, &fd)) {
+    THROW_NULL(vmSymbols::java_lang_NoSuchFieldError());
+  }
+  Handle arrayElementMirror(THREAD, jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct));
+  // offset of the SubElement is offset of the original SubElement plus the offset of the field inside the element
+  int offset = fd.offset() - vk->first_field_offset() + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);
+  InstanceKlass* sesklass = InstanceKlass::cast(JNIHandles::resolve_non_null(selector)->klass());
+  oop res = sesklass->allocate_instance(CHECK_NULL);
+  Handle res_h(THREAD, res);
+  jdk_internal_vm_jni_SubElementSelector::setArrayElementType(res_h(), arrayElementMirror());
+  InstanceKlass* holder = fd.field_holder();
+  BasicType bt = Signature::basic_type(fd.signature());
+  if (is_java_primitive(bt)) {
+    jdk_internal_vm_jni_SubElementSelector::setSubElementType(res_h(), java_lang_Class::primitive_mirror(bt));
+  } else {
+    Klass* fieldKlass = SystemDictionary::resolve_or_fail(fd.signature(), Handle(THREAD, holder->class_loader()),
+        Handle(THREAD, holder->protection_domain()), true, CHECK_NULL);
+    jdk_internal_vm_jni_SubElementSelector::setSubElementType(res_h(),fieldKlass->java_mirror());
+  }
+  jdk_internal_vm_jni_SubElementSelector::setOffset(res_h(), offset);
+  jdk_internal_vm_jni_SubElementSelector::setIsFlattened(res_h(), fd.is_flattened());
+  jdk_internal_vm_jni_SubElementSelector::setIsFlattenable(res_h(), fd.is_flattenable());
+  return JNIHandles::make_local(res_h());
+JNI_END
+
+JNI_ENTRY(jobject, jni_GetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+  JNIWrapper("jni_GetObjectSubElement");
+
+  valueArrayOop ar =  (valueArrayOop)JNIHandles::resolve_non_null(array);
+  oop slct = JNIHandles::resolve_non_null(selector);
+  ValueArrayKlass* vak = ValueArrayKlass::cast(ar->klass());
+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) {
+    THROW_MSG_NULL(vmSymbols::java_lang_IllegalArgumentException(), "Array/Selector mismatch");
+  }
+  oop res = NULL;
+  if (!jdk_internal_vm_jni_SubElementSelector::getIsFlattened(slct)) {
+    int offset = (address)ar->base() - cast_from_oop<address>(ar) + index * vak->element_byte_size()
+                      + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);
+    res = HeapAccess<ON_UNKNOWN_OOP_REF>::oop_load_at(ar, offset);
+  } else {
+    ValueKlass* fieldKlass = ValueKlass::cast(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)));
+    res = fieldKlass->allocate_instance(CHECK_NULL);
+    // The array might have been moved by the GC, refreshing the arrayOop
+    ar =  (valueArrayOop)JNIHandles::resolve_non_null(array);
+    address addr = (address)ar->value_at_addr(index, vak->layout_helper())
+              + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);
+    fieldKlass->value_copy_payload_to_new_oop(addr, res);
+  }
+  return JNIHandles::make_local(res);
+JNI_END
+
+JNI_ENTRY(void, jni_SetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index, jobject value))
+  JNIWrapper("jni_SetObjectSubElement");
+
+  valueArrayOop ar =  (valueArrayOop)JNIHandles::resolve_non_null(array);
+  oop slct = JNIHandles::resolve_non_null(selector);
+  ValueArrayKlass* vak = ValueArrayKlass::cast(ar->klass());
+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) {
+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), "Array/Selector mismatch");
+  }
+  oop val = JNIHandles::resolve(value);
+  if (val == NULL) {
+    if (jdk_internal_vm_jni_SubElementSelector::getIsFlattenable(slct)) {
+      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), "null cannot be stored in a flattened array");
+    }
+  } else {
+    if (!val->is_a(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)))) {
+      THROW_MSG(vmSymbols::java_lang_ArrayStoreException(), "type mismatch");
+    }
+  }
+  if (!jdk_internal_vm_jni_SubElementSelector::getIsFlattened(slct)) {
+    int offset = (address)ar->base() - cast_from_oop<address>(ar) + index * vak->element_byte_size()
+                  + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);
+    HeapAccess<ON_UNKNOWN_OOP_REF>::oop_store_at(ar, offset, JNIHandles::resolve(value));
+  } else {
+    ValueKlass* fieldKlass = ValueKlass::cast(java_lang_Class::as_Klass(jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct)));
+    address addr = (address)ar->value_at_addr(index, vak->layout_helper())
+                  + jdk_internal_vm_jni_SubElementSelector::getOffset(slct);
+    fieldKlass->value_copy_oop_to_payload(JNIHandles::resolve_non_null(value), addr);
+  }
+JNI_END
+
+#define DEFINE_GETSUBELEMENT(ElementType,Result,ElementBasicType) \
+\
+JNI_ENTRY(ElementType, \
+          jni_Get##Result##SubElement(JNIEnv *env, jarray array, jobject selector, int index)) \
+  JNIWrapper("Get" XSTR(Result) "SubElement"); \
+  valueArrayOop ar = (valueArrayOop)JNIHandles::resolve_non_null(array); \
+  oop slct = JNIHandles::resolve_non_null(selector); \
+  ValueArrayKlass* vak = ValueArrayKlass::cast(ar->klass()); \
+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) { \
+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), "Array/Selector mismatch"); \
+  } \
+  if (jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct) != java_lang_Class::primitive_mirror(ElementBasicType)) { \
+    THROW_MSG_0(vmSymbols::java_lang_IllegalArgumentException(), "Wrong SubElement type"); \
+  } \
+  address addr = (address)ar->value_at_addr(index, vak->layout_helper()) \
+               + jdk_internal_vm_jni_SubElementSelector::getOffset(slct); \
+  ElementType result = *(ElementType*)addr; \
+  return result; \
+JNI_END
+
+DEFINE_GETSUBELEMENT(jboolean, Boolean,T_BOOLEAN)
+DEFINE_GETSUBELEMENT(jbyte, Byte, T_BYTE)
+DEFINE_GETSUBELEMENT(jshort, Short,T_SHORT)
+DEFINE_GETSUBELEMENT(jchar, Char,T_CHAR)
+DEFINE_GETSUBELEMENT(jint, Int,T_INT)
+DEFINE_GETSUBELEMENT(jlong, Long,T_LONG)
+DEFINE_GETSUBELEMENT(jfloat, Float,T_FLOAT)
+DEFINE_GETSUBELEMENT(jdouble, Double,T_DOUBLE)
+
+#define DEFINE_SETSUBELEMENT(ElementType,Result,ElementBasicType) \
+\
+JNI_ENTRY(void, \
+          jni_Set##Result##SubElement(JNIEnv *env, jarray array, jobject selector, int index, ElementType value)) \
+  JNIWrapper("Get" XSTR(Result) "SubElement"); \
+  valueArrayOop ar = (valueArrayOop)JNIHandles::resolve_non_null(array); \
+  oop slct = JNIHandles::resolve_non_null(selector); \
+  ValueArrayKlass* vak = ValueArrayKlass::cast(ar->klass()); \
+  if (jdk_internal_vm_jni_SubElementSelector::getArrayElementType(slct) != vak->element_klass()->java_mirror()) { \
+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), "Array/Selector mismatch"); \
+  } \
+  if (jdk_internal_vm_jni_SubElementSelector::getSubElementType(slct) != java_lang_Class::primitive_mirror(ElementBasicType)) { \
+    THROW_MSG(vmSymbols::java_lang_IllegalArgumentException(), "Wrong SubElement type"); \
+  } \
+  address addr = (address)ar->value_at_addr(index, vak->layout_helper()) \
+               + jdk_internal_vm_jni_SubElementSelector::getOffset(slct); \
+  *(ElementType*)addr = value; \
+JNI_END
+
+DEFINE_SETSUBELEMENT(jboolean, Boolean,T_BOOLEAN)
+DEFINE_SETSUBELEMENT(jbyte, Byte, T_BYTE)
+DEFINE_SETSUBELEMENT(jshort, Short,T_SHORT)
+DEFINE_SETSUBELEMENT(jchar, Char,T_CHAR)
+DEFINE_SETSUBELEMENT(jint, Int,T_INT)
+DEFINE_SETSUBELEMENT(jlong, Long,T_LONG)
+DEFINE_SETSUBELEMENT(jfloat, Float,T_FLOAT)
+DEFINE_SETSUBELEMENT(jdouble, Double,T_DOUBLE)
+
 // Structure containing all jni functions
 struct JNINativeInterface_ jni_NativeInterface = {
     NULL,
     NULL,
     NULL,
@@ -3556,11 +3941,42 @@
 
     jni_GetObjectRefType,
 
     // Module features
 
-    jni_GetModule
+    jni_GetModule,
+
+    // Flattened arrays features
+
+    jni_GetFlattenedArrayElements,
+    jni_ReleaseFlattenedArrayElements,
+    jni_GetFlattenedArrayElementClass,
+    jni_GetFlattenedArrayElementSize,
+    jni_GetFieldOffsetInFlattenedLayout,
+
+    jni_CreateSubElementSelector,
+    jni_GetSubElementSelector,
+    jni_GetObjectSubElement,
+    jni_SetObjectSubElement,
+
+    jni_GetBooleanSubElement,
+    jni_GetByteSubElement,
+    jni_GetShortSubElement,
+    jni_GetCharSubElement,
+    jni_GetIntSubElement,
+    jni_GetLongSubElement,
+    jni_GetFloatSubElement,
+    jni_GetDoubleSubElement,
+
+    jni_SetBooleanSubElement,
+    jni_SetByteSubElement,
+    jni_SetShortSubElement,
+    jni_SetCharSubElement,
+    jni_SetIntSubElement,
+    jni_SetLongSubElement,
+    jni_SetFloatSubElement,
+    jni_SetDoubleSubElement
 };
 
 
 // For jvmti use to modify jni function table.
 // Java threads in native contiues to run until it is transitioned
diff a/src/hotspot/share/prims/jniCheck.cpp b/src/hotspot/share/prims/jniCheck.cpp
--- a/src/hotspot/share/prims/jniCheck.cpp
+++ b/src/hotspot/share/prims/jniCheck.cpp
@@ -276,11 +276,12 @@
 
   /* check for proper field type */
   if (!id->find_local_field(&fd))
     ReportJNIFatalError(thr, fatal_static_field_not_found);
   if ((fd.field_type() != ftype) &&
-      !(fd.field_type() == T_ARRAY && ftype == T_OBJECT)) {
+      !(fd.field_type() == T_ARRAY && ftype == T_OBJECT) &&
+      !(fd.field_type() == T_VALUETYPE && ftype == T_OBJECT)) {
     ReportJNIFatalError(thr, fatal_static_field_mismatch);
   }
 }
 
 static inline void
@@ -313,11 +314,12 @@
   if (!InstanceKlass::cast(k_oop)->find_field_from_offset(offset,
                                                               false, &fd))
     ReportJNIFatalError(thr, fatal_instance_field_not_found);
 
   if ((fd.field_type() != ftype) &&
-      !(fd.field_type() == T_ARRAY && ftype == T_OBJECT)) {
+      !(fd.field_type() == T_ARRAY && ftype == T_OBJECT) &&
+      !(fd.field_type() == T_VALUETYPE && ftype == T_OBJECT)) {
     ReportJNIFatalError(thr, fatal_instance_field_mismatch);
   }
 }
 
 static inline void
@@ -2010,10 +2012,211 @@
     jobject result = UNCHECKED()->GetModule(env,clazz);
     functionExit(thr);
     return result;
 JNI_END
 
+JNI_ENTRY_CHECKED(void*,
+    checked_jni_GetFlattenedArrayElements(JNIEnv* env, jarray array, jboolean* isCopy))
+    functionEnter(thr);
+    void* result = UNCHECKED()->GetFlattenedArrayElements(env, array, isCopy);
+    functionExit(thr);
+    return result;
+
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_ReleaseFlattenedArrayElements(JNIEnv* env, jarray array, void* elem, jint mode))
+    functionEnter(thr);
+    UNCHECKED()->ReleaseFlattenedArrayElements(env, array, elem, mode);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jclass,
+    checked_jni_GetFlattenedArrayElementClass(JNIEnv* env, jarray array))
+    functionEnter(thr);
+    jclass clazz = UNCHECKED()->GetFlattenedArrayElementClass(env, array);
+    functionExit(thr);
+    return clazz;
+JNI_END
+
+JNI_ENTRY_CHECKED(jsize,
+    checked_jni_GetFlattenedArrayElementSize(JNIEnv* env, jarray array))
+    functionEnter(thr);
+    jsize size = UNCHECKED()->GetFlattenedArrayElementSize(env, array);
+    functionExit(thr);
+    return size;
+JNI_END
+
+JNI_ENTRY_CHECKED(jsize,
+    checked_jni_GetFieldOffsetInFlattenedLayout(JNIEnv* env, jclass clazz, const char *name, const char *signature, jboolean* isFlattened))
+    functionEnter(thr);
+    jsize offset = UNCHECKED()->GetFieldOffsetInFlattenedLayout(env, clazz, name, signature, isFlattened);
+    functionExit(thr);
+    return offset;
+JNI_END
+
+JNI_ENTRY_CHECKED(jobject,
+    checked_jni_CreateSubElementSelector(JNIEnv* env, jarray array))
+    functionEnter(thr);
+    jobject selector = UNCHECKED()->CreateSubElementSelector(env, array);
+    functionExit(thr);
+    return selector;
+JNI_END
+
+JNI_ENTRY_CHECKED(jobject,
+    checked_jni_GetSubElementSelector(JNIEnv* env, jobject selector, jfieldID fieldID))
+    functionEnter(thr);
+    jobject res = UNCHECKED()->GetSubElementSelector(env, selector, fieldID);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(jobject,
+    checked_jni_GetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jobject res = UNCHECKED()->GetObjectSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetObjectSubElement(JNIEnv* env, jarray array, jobject selector, int index, jobject value))
+    functionEnter(thr);
+    UNCHECKED()->SetObjectSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jboolean,
+    checked_jni_GetBooleanSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jboolean res = UNCHECKED()->GetBooleanSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetBooleanSubElement(JNIEnv* env, jarray array, jobject selector, int index, jboolean value))
+    functionEnter(thr);
+    UNCHECKED()->SetBooleanSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jbyte,
+    checked_jni_GetByteSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jbyte res = UNCHECKED()->GetByteSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetByteSubElement(JNIEnv* env, jarray array, jobject selector, int index, jbyte value))
+    functionEnter(thr);
+    UNCHECKED()->SetByteSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jshort,
+    checked_jni_GetShortSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jshort res = UNCHECKED()->GetShortSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetShortSubElement(JNIEnv* env, jarray array, jobject selector, int index, jshort value))
+    functionEnter(thr);
+    UNCHECKED()->SetShortSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jchar,
+    checked_jni_GetCharSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jchar res = UNCHECKED()->GetCharSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetCharSubElement(JNIEnv* env, jarray array, jobject selector, int index, jchar value))
+    functionEnter(thr);
+    UNCHECKED()->SetCharSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jint,
+    checked_jni_GetIntSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jint res = UNCHECKED()->GetIntSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetIntSubElement(JNIEnv* env, jarray array, jobject selector, int index, jint value))
+    functionEnter(thr);
+    UNCHECKED()->SetIntSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jlong,
+    checked_jni_GetLongSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jlong res = UNCHECKED()->GetLongSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetLongSubElement(JNIEnv* env, jarray array, jobject selector, int index, jlong value))
+    functionEnter(thr);
+    UNCHECKED()->SetLongSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jfloat,
+    checked_jni_GetFloatSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jfloat res = UNCHECKED()->GetFloatSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetFloatSubElement(JNIEnv* env, jarray array, jobject selector, int index, jfloat value))
+    functionEnter(thr);
+    UNCHECKED()->SetFloatSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
+JNI_ENTRY_CHECKED(jdouble,
+    checked_jni_GetDoubleSubElement(JNIEnv* env, jarray array, jobject selector, int index))
+    functionEnter(thr);
+    jdouble res = UNCHECKED()->GetDoubleSubElement(env, array, selector, index);
+    functionExit(thr);
+    return res;
+JNI_END
+
+JNI_ENTRY_CHECKED(void,
+    checked_jni_SetDoubleSubElement(JNIEnv* env, jarray array, jobject selector, int index, jdouble value))
+    functionEnter(thr);
+    UNCHECKED()->SetDoubleSubElement(env, array, selector, index, value);
+    functionExit(thr);
+    return;
+JNI_END
+
 /*
  * Structure containing all checked jni functions
  */
 struct JNINativeInterface_  checked_jni_NativeInterface = {
     NULL,
@@ -2295,11 +2498,41 @@
 
     checked_jni_GetObjectRefType,
 
     // Module Features
 
-    checked_jni_GetModule
+    checked_jni_GetModule,
+
+    // Flattened arrays Features
+    checked_jni_GetFlattenedArrayElements,
+    checked_jni_ReleaseFlattenedArrayElements,
+    checked_jni_GetFlattenedArrayElementClass,
+    checked_jni_GetFlattenedArrayElementSize,
+    checked_jni_GetFieldOffsetInFlattenedLayout,
+
+    checked_jni_CreateSubElementSelector,
+    checked_jni_GetSubElementSelector,
+    checked_jni_GetObjectSubElement,
+    checked_jni_SetObjectSubElement,
+
+    checked_jni_GetBooleanSubElement,
+    checked_jni_GetByteSubElement,
+    checked_jni_GetShortSubElement,
+    checked_jni_GetCharSubElement,
+    checked_jni_GetIntSubElement,
+    checked_jni_GetLongSubElement,
+    checked_jni_GetFloatSubElement,
+    checked_jni_GetDoubleSubElement,
+
+    checked_jni_SetBooleanSubElement,
+    checked_jni_SetByteSubElement,
+    checked_jni_SetShortSubElement,
+    checked_jni_SetCharSubElement,
+    checked_jni_SetIntSubElement,
+    checked_jni_SetLongSubElement,
+    checked_jni_SetFloatSubElement,
+    checked_jni_SetDoubleSubElement
 };
 
 
 // Returns the function structure
 struct JNINativeInterface_* jni_functions_check() {
diff a/src/hotspot/share/prims/jvm.cpp b/src/hotspot/share/prims/jvm.cpp
--- a/src/hotspot/share/prims/jvm.cpp
+++ b/src/hotspot/share/prims/jvm.cpp
@@ -53,10 +53,11 @@
 #include "oops/method.hpp"
 #include "oops/recordComponent.hpp"
 #include "oops/objArrayKlass.hpp"
 #include "oops/objArrayOop.inline.hpp"
 #include "oops/oop.inline.hpp"
+#include "oops/valueArrayKlass.hpp"
 #include "prims/jvm_misc.hpp"
 #include "prims/jvmtiExport.hpp"
 #include "prims/jvmtiThreadState.hpp"
 #include "prims/nativeLookup.hpp"
 #include "prims/stackwalk.hpp"
@@ -703,10 +704,11 @@
 
   // Check if class of obj supports the Cloneable interface.
   // All arrays are considered to be cloneable (See JLS 20.1.5).
   // All j.l.r.Reference classes are considered non-cloneable.
   if (!klass->is_cloneable() ||
+       klass->is_value() ||
       (klass->is_instance_klass() &&
        InstanceKlass::cast(klass)->reference_type() != REF_NONE)) {
     ResourceMark rm(THREAD);
     THROW_MSG_0(vmSymbols::java_lang_CloneNotSupportedException(), klass->external_name());
   }
@@ -1246,30 +1248,39 @@
 
   Klass* klass = java_lang_Class::as_Klass(mirror);
   // Figure size of result array
   int size;
   if (klass->is_instance_klass()) {
-    size = InstanceKlass::cast(klass)->local_interfaces()->length();
+    InstanceKlass* ik = InstanceKlass::cast(klass);
+    size = ik->local_interfaces()->length();
+    if (ik->has_injected_identityObject()) {
+      size--;
+    }
   } else {
     assert(klass->is_objArray_klass() || klass->is_typeArray_klass(), "Illegal mirror klass");
-    size = 2;
+    size = 3;
   }
 
   // Allocate result array
   objArrayOop r = oopFactory::new_objArray(SystemDictionary::Class_klass(), size, CHECK_NULL);
   objArrayHandle result (THREAD, r);
   // Fill in result
   if (klass->is_instance_klass()) {
     // Regular instance klass, fill in all local interfaces
+    int cursor = 0;
     for (int index = 0; index < size; index++) {
-      Klass* k = InstanceKlass::cast(klass)->local_interfaces()->at(index);
-      result->obj_at_put(index, k->java_mirror());
+      InstanceKlass* ik = InstanceKlass::cast(klass);
+      Klass* k = ik->local_interfaces()->at(index);
+      if (!ik->has_injected_identityObject() || k != SystemDictionary::IdentityObject_klass()) {
+        result->obj_at_put(cursor++, k->java_mirror());
+      }
     }
   } else {
-    // All arrays implement java.lang.Cloneable and java.io.Serializable
+    // All arrays implement java.lang.Cloneable, java.io.Serializable and java.lang.IdentityObject
     result->obj_at_put(0, SystemDictionary::Cloneable_klass()->java_mirror());
     result->obj_at_put(1, SystemDictionary::Serializable_klass()->java_mirror());
+    result->obj_at_put(2, SystemDictionary::IdentityObject_klass()->java_mirror());
   }
   return (jobjectArray) JNIHandles::make_local(env, result());
 JVM_END
 
 
@@ -1885,14 +1896,18 @@
   return (jobjectArray)JNIHandles::make_local(env, result);
 }
 JVM_END
 
 static bool select_method(const methodHandle& method, bool want_constructor) {
+  bool is_ctor = (method->is_object_constructor() ||
+                  method->is_static_init_factory());
   if (want_constructor) {
-    return (method->is_initializer() && !method->is_static());
+    return is_ctor;
   } else {
-    return  (!method->is_initializer() && !method->is_overpass());
+    return (!is_ctor &&
+            !method->is_class_initializer() &&
+            !method->is_overpass());
   }
 }
 
 static jobjectArray get_class_declared_methods_helper(
                                   JNIEnv *env,
@@ -1950,10 +1965,12 @@
       // Otherwise should probably put a method that throws NSME
       result->obj_at_put(i, NULL);
     } else {
       oop m;
       if (want_constructor) {
+        assert(method->is_object_constructor() ||
+               method->is_static_init_factory(), "must be");
         m = Reflection::new_constructor(method, CHECK_NULL);
       } else {
         m = Reflection::new_method(method, false, CHECK_NULL);
       }
       result->obj_at_put(i, m);
@@ -2180,14 +2197,14 @@
   methodHandle m (THREAD, k->find_method(name, sig));
   if (m.is_null()) {
     THROW_MSG_0(vmSymbols::java_lang_RuntimeException(), "Unable to look up method in target class");
   }
   oop method;
-  if (!m->is_initializer() || m->is_static()) {
-    method = Reflection::new_method(m, true, CHECK_NULL);
-  } else {
+  if (m->is_object_constructor()) {
     method = Reflection::new_constructor(m, CHECK_NULL);
+  } else {
+    method = Reflection::new_method(m, true, CHECK_NULL);
   }
   return JNIHandles::make_local(method);
 }
 
 JVM_ENTRY(jobject, JVM_ConstantPoolGetMethodAt(JNIEnv *env, jobject obj, jobject unused, jint index))
@@ -2471,10 +2488,49 @@
   JvmtiVMObjectAllocEventCollector oam;
   oop asd = JavaAssertions::createAssertionStatusDirectives(CHECK_NULL);
   return JNIHandles::make_local(env, asd);
 JVM_END
 
+// Arrays support /////////////////////////////////////////////////////////////
+
+JVM_ENTRY(jboolean, JVM_ArrayIsAccessAtomic(JNIEnv *env, jclass unused, jobject array))
+  JVMWrapper("JVM_ArrayIsAccessAtomic");
+  oop o = JNIHandles::resolve(array);
+  Klass* k = o->klass();
+  if ((o == NULL) || (!k->is_array_klass())) {
+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());
+  }
+  return ArrayKlass::cast(k)->element_access_is_atomic();
+JVM_END
+
+JVM_ENTRY(jobject, JVM_ArrayEnsureAccessAtomic(JNIEnv *env, jclass unused, jobject array))
+  JVMWrapper("JVM_ArrayEnsureAccessAtomic");
+  oop o = JNIHandles::resolve(array);
+  Klass* k = o->klass();
+  if ((o == NULL) || (!k->is_array_klass())) {
+    THROW_0(vmSymbols::java_lang_IllegalArgumentException());
+  }
+  if (k->is_valueArray_klass()) {
+    ValueArrayKlass* vk = ValueArrayKlass::cast(k);
+    if (!vk->element_access_is_atomic()) {
+      /**
+       * Need to decide how to implement:
+       *
+       * 1) Change to objArrayOop layout, therefore oop->klass() differs so
+       * then "<atomic>[Qfoo;" klass needs to subclass "[Qfoo;" to pass through
+       * "checkcast" & "instanceof"
+       *
+       * 2) Use extra header in the valueArrayOop to flag atomicity required and
+       * possibly per instance lock structure. Said info, could be placed in
+       * "trailer" rather than disturb the current arrayOop
+       */
+      Unimplemented();
+    }
+  }
+  return array;
+JVM_END
+
 // Verification ////////////////////////////////////////////////////////////////////////////////
 
 // Reflection for the verifier /////////////////////////////////////////////////////////////////
 
 // RedefineClasses support: bug 6214132 caused verification to fail.
@@ -2650,11 +2706,11 @@
   JVMWrapper("JVM_IsConstructorIx");
   ResourceMark rm(THREAD);
   Klass* k = java_lang_Class::as_Klass(JNIHandles::resolve_non_null(cls));
   k = JvmtiThreadState::class_to_verify_considering_redefinition(k, thread);
   Method* method = InstanceKlass::cast(k)->methods()->at(method_index);
-  return method->name() == vmSymbols::object_initializer_name();
+  return method->is_object_constructor();
 JVM_END
 
 
 JVM_ENTRY(jboolean, JVM_IsVMGeneratedMethodIx(JNIEnv *env, jclass cls, int method_index))
   JVMWrapper("JVM_IsVMGeneratedMethodIx");
@@ -3645,11 +3701,11 @@
   JVMWrapper("JVM_InvokeMethod");
   Handle method_handle;
   if (thread->stack_available((address) &method_handle) >= JVMInvokeMethodSlack) {
     method_handle = Handle(THREAD, JNIHandles::resolve(method));
     Handle receiver(THREAD, JNIHandles::resolve(obj));
-    objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));
+    objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);
     oop result = Reflection::invoke_method(method_handle(), receiver, args, CHECK_NULL);
     jobject res = JNIHandles::make_local(env, result);
     if (JvmtiExport::should_post_vm_object_alloc()) {
       oop ret_type = java_lang_reflect_Method::return_type(method_handle());
       assert(ret_type != NULL, "sanity check: ret_type oop must not be NULL!");
@@ -3666,12 +3722,12 @@
 JVM_END
 
 
 JVM_ENTRY(jobject, JVM_NewInstanceFromConstructor(JNIEnv *env, jobject c, jobjectArray args0))
   JVMWrapper("JVM_NewInstanceFromConstructor");
+  objArrayHandle args = oopFactory::ensure_objArray(JNIHandles::resolve(args0), CHECK_NULL);
   oop constructor_mirror = JNIHandles::resolve(c);
-  objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0)));
   oop result = Reflection::invoke_constructor(constructor_mirror, args, CHECK_NULL);
   jobject res = JNIHandles::make_local(env, result);
   if (JvmtiExport::should_post_vm_object_alloc()) {
     JvmtiExport::post_vm_object_alloc(JavaThread::current(), result);
   }
diff a/src/hotspot/share/runtime/arguments.cpp b/src/hotspot/share/runtime/arguments.cpp
--- a/src/hotspot/share/runtime/arguments.cpp
+++ b/src/hotspot/share/runtime/arguments.cpp
@@ -2157,10 +2157,20 @@
   }
 #endif
 
   status = status && GCArguments::check_args_consistency();
 
+  if (AMD64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypePassFieldsAsArgs)) {
+    FLAG_SET_CMDLINE(InlineTypePassFieldsAsArgs, false);
+    warning("InlineTypePassFieldsAsArgs is not supported on this platform");
+  }
+
+  if (AMD64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypeReturnedAsFields)) {
+    FLAG_SET_CMDLINE(InlineTypeReturnedAsFields, false);
+    warning("InlineTypeReturnedAsFields is not supported on this platform");
+  }
+
   return status;
 }
 
 bool Arguments::is_bad_option(const JavaVMOption* option, jboolean ignore,
   const char* option_type) {
@@ -3071,10 +3081,28 @@
     } else if (is_bad_option(option, args->ignoreUnrecognized)) {
       return JNI_ERR;
     }
   }
 
+  if (EnableValhalla) {
+    // create_property("valhalla.enableValhalla", "true", InternalProperty)
+    const char* prop_name = "valhalla.enableValhalla";
+    const char* prop_value = "true";
+    const size_t prop_len = strlen(prop_name) + strlen(prop_value) + 2;
+    char* property = AllocateHeap(prop_len, mtArguments);
+    int ret = jio_snprintf(property, prop_len, "%s=%s", prop_name, prop_value);
+    if (ret < 0 || ret >= (int)prop_len) {
+      FreeHeap(property);
+      return JNI_ENOMEM;
+    }
+    bool added = add_property(property, UnwriteableProperty, InternalProperty);
+    FreeHeap(property);
+    if (!added) {
+      return JNI_ENOMEM;
+    }
+  }
+
   // PrintSharedArchiveAndExit will turn on
   //   -Xshare:on
   //   -Xlog:class+path=info
   if (PrintSharedArchiveAndExit) {
     if (FLAG_SET_CMDLINE(UseSharedSpaces, true) != JVMFlag::SUCCESS) {
@@ -4165,10 +4193,15 @@
   // verification is not as if both were enabled.
   if (BytecodeVerificationLocal && !BytecodeVerificationRemote) {
     log_info(verification)("Turning on remote verification because local verification is on");
     FLAG_SET_DEFAULT(BytecodeVerificationRemote, true);
   }
+  if (!EnableValhalla || (is_interpreter_only() && !is_dumping_archive())) {
+    // Disable calling convention optimizations if value types are not supported
+    InlineTypePassFieldsAsArgs = false;
+    InlineTypeReturnedAsFields = false;
+  }
 
 #ifndef PRODUCT
   if (!LogVMOutput && FLAG_IS_DEFAULT(LogVMOutput)) {
     if (use_vm_log()) {
       LogVMOutput = true;
diff a/src/hotspot/share/runtime/deoptimization.cpp b/src/hotspot/share/runtime/deoptimization.cpp
--- a/src/hotspot/share/runtime/deoptimization.cpp
+++ b/src/hotspot/share/runtime/deoptimization.cpp
@@ -47,10 +47,13 @@
 #include "oops/objArrayKlass.hpp"
 #include "oops/objArrayOop.inline.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/fieldStreams.inline.hpp"
 #include "oops/typeArrayOop.inline.hpp"
+#include "oops/valueArrayKlass.hpp"
+#include "oops/valueArrayOop.hpp"
+#include "oops/valueKlass.inline.hpp"
 #include "oops/verifyOopClosure.hpp"
 #include "prims/jvmtiThreadState.hpp"
 #include "runtime/atomic.hpp"
 #include "runtime/biasedLocking.hpp"
 #include "runtime/deoptimization.hpp"
@@ -180,41 +183,63 @@
   // It is not guaranteed that we can get such information here only
   // by analyzing bytecode in deoptimized frames. This is why this flag
   // is set during method compilation (see Compile::Process_OopMap_Node()).
   // If the previous frame was popped or if we are dispatching an exception,
   // we don't have an oop result.
-  bool save_oop_result = chunk->at(0)->scope()->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);
-  Handle return_value;
+  ScopeDesc* scope = chunk->at(0)->scope();
+  bool save_oop_result = scope->return_oop() && !thread->popframe_forcing_deopt_reexecution() && (exec_mode == Deoptimization::Unpack_deopt);
+  // In case of the return of multiple values, we must take care
+  // of all oop return values.
+  GrowableArray<Handle> return_oops;
+  ValueKlass* vk = NULL;
+  if (save_oop_result && scope->return_vt()) {
+    vk = ValueKlass::returned_value_klass(map);
+    if (vk != NULL) {
+      vk->save_oop_fields(map, return_oops);
+      save_oop_result = false;
+    }
+  }
   if (save_oop_result) {
     // Reallocation may trigger GC. If deoptimization happened on return from
     // call which returns oop we need to save it since it is not in oopmap.
     oop result = deoptee.saved_oop_result(&map);
     assert(oopDesc::is_oop_or_null(result), "must be oop");
-    return_value = Handle(thread, result);
+    return_oops.push(Handle(thread, result));
     assert(Universe::heap()->is_in_or_null(result), "must be heap pointer");
     if (TraceDeoptimization) {
       ttyLocker ttyl;
       tty->print_cr("SAVED OOP RESULT " INTPTR_FORMAT " in thread " INTPTR_FORMAT, p2i(result), p2i(thread));
     }
   }
-  if (objects != NULL) {
+  if (objects != NULL || vk != NULL) {
+    bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();
     JRT_BLOCK
-      realloc_failures = Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);
+      if (vk != NULL) {
+        realloc_failures = Deoptimization::realloc_value_type_result(vk, map, return_oops, THREAD);
+      }
+      if (objects != NULL) {
+        realloc_failures = realloc_failures || Deoptimization::realloc_objects(thread, &deoptee, &map, objects, THREAD);
+        Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal, THREAD);
+      }
     JRT_END
-    bool skip_internal = (compiled_method != NULL) && !compiled_method->is_compiled_by_jvmci();
-    Deoptimization::reassign_fields(&deoptee, &map, objects, realloc_failures, skip_internal);
 #ifndef PRODUCT
     if (TraceDeoptimization) {
       ttyLocker ttyl;
       tty->print_cr("REALLOC OBJECTS in thread " INTPTR_FORMAT, p2i(thread));
-      Deoptimization::print_objects(objects, realloc_failures);
+      if (objects != NULL) {
+        Deoptimization::print_objects(objects, realloc_failures);
+      } else {
+        Handle obj = realloc_failures ? Handle() : return_oops.first();
+        Deoptimization::print_object(vk, obj, realloc_failures);
+      }
     }
 #endif
   }
-  if (save_oop_result) {
+  if (save_oop_result || vk != NULL) {
     // Restore result.
-    deoptee.set_saved_oop_result(&map, return_value());
+    assert(return_oops.length() == 1, "no value type");
+    deoptee.set_saved_oop_result(&map, return_oops.pop()());
   }
   return realloc_failures;
 }
 
 static void eliminate_locks(JavaThread* thread, GrowableArray<compiledVFrame*>* chunk, bool realloc_failures) {
@@ -511,11 +536,11 @@
     // non-parameter locals of the first unpacked interpreted frame.
     // Compute that adjustment.
     caller_adjustment = last_frame_adjust(callee_parameters, callee_locals);
   }
 
-  // If the sender is deoptimized the we must retrieve the address of the handler
+  // If the sender is deoptimized we must retrieve the address of the handler
   // since the frame will "magically" show the original pc before the deopt
   // and we'd undo the deopt.
 
   frame_pcs[0] = deopt_sender.raw_pc();
 
@@ -1002,10 +1027,14 @@
 #endif // INCLUDE_JVMCI || INCLUDE_AOT
       InstanceKlass* ik = InstanceKlass::cast(k);
       if (obj == NULL) {
         obj = ik->allocate_instance(THREAD);
       }
+    } else if (k->is_valueArray_klass()) {
+      ValueArrayKlass* ak = ValueArrayKlass::cast(k);
+      // Value type array must be zeroed because not all memory is reassigned
+      obj = ak->allocate(sv->field_size(), THREAD);
     } else if (k->is_typeArray_klass()) {
       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
       assert(sv->field_size() % type2size[ak->element_type()] == 0, "non-integral array length");
       int len = sv->field_size() / type2size[ak->element_type()];
       obj = ak->allocate(len, THREAD);
@@ -1031,10 +1060,25 @@
   }
 
   return failures;
 }
 
+// We're deoptimizing at the return of a call, value type fields are
+// in registers. When we go back to the interpreter, it will expect a
+// reference to a value type instance. Allocate and initialize it from
+// the register values here.
+bool Deoptimization::realloc_value_type_result(ValueKlass* vk, const RegisterMap& map, GrowableArray<Handle>& return_oops, TRAPS) {
+  oop new_vt = vk->realloc_result(map, return_oops, THREAD);
+  if (new_vt == NULL) {
+    CLEAR_PENDING_EXCEPTION;
+    THROW_OOP_(Universe::out_of_memory_error_realloc_objects(), true);
+  }
+  return_oops.clear();
+  return_oops.push(Handle(THREAD, new_vt));
+  return false;
+}
+
 #if INCLUDE_JVMCI
 /**
  * For primitive types whose kind gets "erased" at runtime (shorts become stack ints),
  * we need to somehow be able to recover the actual kind to be able to write the correct
  * amount of bytes.
@@ -1203,50 +1247,72 @@
 
 class ReassignedField {
 public:
   int _offset;
   BasicType _type;
+  InstanceKlass* _klass;
 public:
   ReassignedField() {
     _offset = 0;
     _type = T_ILLEGAL;
+    _klass = NULL;
   }
 };
 
 int compare(ReassignedField* left, ReassignedField* right) {
   return left->_offset - right->_offset;
 }
 
 // Restore fields of an eliminated instance object using the same field order
 // returned by HotSpotResolvedObjectTypeImpl.getInstanceFields(true)
-static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal) {
+static int reassign_fields_by_klass(InstanceKlass* klass, frame* fr, RegisterMap* reg_map, ObjectValue* sv, int svIndex, oop obj, bool skip_internal, int base_offset, TRAPS) {
+
   GrowableArray<ReassignedField>* fields = new GrowableArray<ReassignedField>();
   InstanceKlass* ik = klass;
   while (ik != NULL) {
     for (AllFieldStream fs(ik); !fs.done(); fs.next()) {
       if (!fs.access_flags().is_static() && (!skip_internal || !fs.access_flags().is_internal())) {
         ReassignedField field;
         field._offset = fs.offset();
         field._type = Signature::basic_type(fs.signature());
+        if (field._type == T_VALUETYPE) {
+          field._type = T_OBJECT;
+        }
+        if (fs.is_flattened()) {
+          // Resolve klass of flattened value type field
+          Klass* vk = klass->get_value_field_klass(fs.index());
+          field._klass = ValueKlass::cast(vk);
+          field._type = T_VALUETYPE;
+        }
         fields->append(field);
       }
     }
     ik = ik->superklass();
   }
   fields->sort(compare);
   for (int i = 0; i < fields->length(); i++) {
     intptr_t val;
     ScopeValue* scope_field = sv->field_at(svIndex);
     StackValue* value = StackValue::create_stack_value(fr, reg_map, scope_field);
-    int offset = fields->at(i)._offset;
+    int offset = base_offset + fields->at(i)._offset;
     BasicType type = fields->at(i)._type;
     switch (type) {
-      case T_OBJECT: case T_ARRAY:
+      case T_OBJECT:
+      case T_ARRAY:
         assert(value->type() == T_OBJECT, "Agreement.");
         obj->obj_field_put(offset, value->get_obj()());
         break;
 
+      case T_VALUETYPE: {
+        // Recursively re-assign flattened value type fields
+        InstanceKlass* vk = fields->at(i)._klass;
+        assert(vk != NULL, "must be resolved");
+        offset -= ValueKlass::cast(vk)->first_field_offset(); // Adjust offset to omit oop header
+        svIndex = reassign_fields_by_klass(vk, fr, reg_map, sv, svIndex, obj, skip_internal, offset, CHECK_0);
+        continue; // Continue because we don't need to increment svIndex
+      }
+
       // Have to cast to INT (32 bits) pointer to avoid little/big-endian problem.
       case T_INT: case T_FLOAT: { // 4 bytes.
         assert(value->type() == T_INT, "Agreement.");
         bool big_value = false;
         if (i+1 < fields->length() && fields->at(i+1)._type == T_INT) {
@@ -1318,12 +1384,26 @@
     svIndex++;
   }
   return svIndex;
 }
 
+// restore fields of an eliminated value type array
+void Deoptimization::reassign_value_array_elements(frame* fr, RegisterMap* reg_map, ObjectValue* sv, valueArrayOop obj, ValueArrayKlass* vak, TRAPS) {
+  ValueKlass* vk = vak->element_klass();
+  assert(vk->flatten_array(), "should only be used for flattened value type arrays");
+  // Adjust offset to omit oop header
+  int base_offset = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE) - ValueKlass::cast(vk)->first_field_offset();
+  // Initialize all elements of the flattened value type array
+  for (int i = 0; i < sv->field_size(); i++) {
+    ScopeValue* val = sv->field_at(i);
+    int offset = base_offset + (i << Klass::layout_helper_log2_element_size(vak->layout_helper()));
+    reassign_fields_by_klass(vk, fr, reg_map, val->as_ObjectValue(), 0, (oop)obj, false /* skip_internal */, offset, CHECK);
+  }
+}
+
 // restore fields of all eliminated objects and arrays
-void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal) {
+void Deoptimization::reassign_fields(frame* fr, RegisterMap* reg_map, GrowableArray<ScopeValue*>* objects, bool realloc_failures, bool skip_internal, TRAPS) {
   for (int i = 0; i < objects->length(); i++) {
     ObjectValue* sv = (ObjectValue*) objects->at(i);
     Klass* k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());
     Handle obj = sv->value();
     assert(obj.not_null() || realloc_failures, "reallocation was missed");
@@ -1339,11 +1419,14 @@
       continue;
     }
 #endif // INCLUDE_JVMCI || INCLUDE_AOT
     if (k->is_instance_klass()) {
       InstanceKlass* ik = InstanceKlass::cast(k);
-      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal);
+      reassign_fields_by_klass(ik, fr, reg_map, sv, 0, obj(), skip_internal, 0, CHECK);
+    } else if (k->is_valueArray_klass()) {
+      ValueArrayKlass* vak = ValueArrayKlass::cast(k);
+      reassign_value_array_elements(fr, reg_map, sv, (valueArrayOop) obj(), vak, CHECK);
     } else if (k->is_typeArray_klass()) {
       TypeArrayKlass* ak = TypeArrayKlass::cast(k);
       reassign_type_array_elements(fr, reg_map, sv, (typeArrayOop) obj(), ak->element_type());
     } else if (k->is_objArray_klass()) {
       reassign_object_array_elements(fr, reg_map, sv, (objArrayOop) obj());
@@ -1382,29 +1465,30 @@
 
 #ifndef PRODUCT
 // print information about reallocated objects
 void Deoptimization::print_objects(GrowableArray<ScopeValue*>* objects, bool realloc_failures) {
   fieldDescriptor fd;
-
   for (int i = 0; i < objects->length(); i++) {
     ObjectValue* sv = (ObjectValue*) objects->at(i);
     Klass* k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());
-    Handle obj = sv->value();
+    print_object(k, sv->value(), realloc_failures);
+  }
+}
 
-    tty->print("     object <" INTPTR_FORMAT "> of type ", p2i(sv->value()()));
-    k->print_value();
-    assert(obj.not_null() || realloc_failures, "reallocation was missed");
-    if (obj.is_null()) {
-      tty->print(" allocation failed");
-    } else {
-      tty->print(" allocated (%d bytes)", obj->size() * HeapWordSize);
-    }
-    tty->cr();
+void Deoptimization::print_object(Klass* k, Handle obj, bool realloc_failures) {
+  tty->print("     object <" INTPTR_FORMAT "> of type ", p2i(obj()));
+  k->print_value();
+  assert(obj.not_null() || realloc_failures, "reallocation was missed");
+  if (obj.is_null()) {
+    tty->print(" allocation failed");
+  } else {
+    tty->print(" allocated (%d bytes)", obj->size() * HeapWordSize);
+  }
+  tty->cr();
 
-    if (Verbose && !obj.is_null()) {
-      k->oop_print_on(obj(), tty);
-    }
+  if (Verbose && !obj.is_null()) {
+    k->oop_print_on(obj(), tty);
   }
 }
 #endif
 #endif // COMPILER2_OR_JVMCI
 
@@ -1573,11 +1657,11 @@
   // deopt the execution state and return to the interpreter.
   fr.deoptimize(thread);
 }
 
 void Deoptimization::deoptimize(JavaThread* thread, frame fr, DeoptReason reason) {
-  // Deoptimize only if the frame comes from compile code.
+  // Deoptimize only if the frame comes from compiled code.
   // Do not deoptimize the frame which is already patched
   // during the execution of the loops below.
   if (!fr.is_compiled_frame() || fr.is_deoptimized_frame()) {
     return;
   }
diff a/src/hotspot/share/runtime/frame.cpp b/src/hotspot/share/runtime/frame.cpp
--- a/src/hotspot/share/runtime/frame.cpp
+++ b/src/hotspot/share/runtime/frame.cpp
@@ -35,10 +35,11 @@
 #include "memory/universe.hpp"
 #include "oops/markWord.hpp"
 #include "oops/method.hpp"
 #include "oops/methodData.hpp"
 #include "oops/oop.inline.hpp"
+#include "oops/valueKlass.hpp"
 #include "oops/verifyOopClosure.hpp"
 #include "prims/methodHandles.hpp"
 #include "runtime/frame.inline.hpp"
 #include "runtime/handles.inline.hpp"
 #include "runtime/javaCalls.hpp"
@@ -50,10 +51,13 @@
 #include "runtime/stubRoutines.hpp"
 #include "runtime/thread.inline.hpp"
 #include "utilities/debug.hpp"
 #include "utilities/decoder.hpp"
 #include "utilities/formatBuffer.hpp"
+#ifdef COMPILER1
+#include "c1/c1_Runtime1.hpp"
+#endif
 
 RegisterMap::RegisterMap(JavaThread *thread, bool update_map) {
   _thread         = thread;
   _update_map     = update_map;
   clear();
@@ -282,10 +286,29 @@
                         cm->deopt_mh_handler_begin() :
                         cm->deopt_handler_begin();
 
   // Save the original pc before we patch in the new one
   cm->set_original_pc(this, pc());
+
+#ifdef COMPILER1
+  if (cm->is_compiled_by_c1() && cm->method()->has_scalarized_args() &&
+      pc() < cm->verified_value_entry_point()) {
+    // The VEP and VVEP(RO) of C1-compiled methods call into the runtime to buffer scalarized value
+    // type args. We can't deoptimize at that point because the buffers have not yet been initialized.
+    // Also, if the method is synchronized, we first need to acquire the lock.
+    // Don't patch the return pc to delay deoptimization until we enter the method body (the check
+    // addedin LIRGenerator::do_Base will detect the pending deoptimization by checking the original_pc).
+#ifdef ASSERT
+    NativeCall* call = nativeCall_before(this->pc());
+    address dest = call->destination();
+    assert(dest == Runtime1::entry_for(Runtime1::buffer_value_args_no_receiver_id) ||
+           dest == Runtime1::entry_for(Runtime1::buffer_value_args_id), "unexpected safepoint in entry point");
+#endif
+    return;
+  }
+#endif
+
   patch_pc(thread, deopt);
 
 #ifdef ASSERT
   {
     RegisterMap map(thread, false);
@@ -677,11 +700,11 @@
   int    _max_locals;
   int    _max_stack;
 
  public:
   InterpreterFrameClosure(frame* fr, int max_locals, int max_stack,
-                          OopClosure* f) {
+                          OopClosure* f, BufferedValueClosure* bvt_f) {
     _fr         = fr;
     _max_locals = max_locals;
     _max_stack  = max_stack;
     _f          = f;
   }
@@ -689,11 +712,13 @@
   void offset_do(int offset) {
     oop* addr;
     if (offset < _max_locals) {
       addr = (oop*) _fr->interpreter_frame_local_at(offset);
       assert((intptr_t*)addr >= _fr->sp(), "must be inside the frame");
-      _f->do_oop(addr);
+      if (_f != NULL) {
+        _f->do_oop(addr);
+      }
     } else {
       addr = (oop*) _fr->interpreter_frame_expression_stack_at((offset - _max_locals));
       // In case of exceptions, the expression stack is invalid and the esp will be reset to express
       // this condition. Therefore, we call f only if addr is 'inside' the stack (i.e., addr >= esp for Intel).
       bool in_stack;
@@ -701,11 +726,13 @@
         in_stack = (intptr_t*)addr <= _fr->interpreter_frame_tos_address();
       } else {
         in_stack = (intptr_t*)addr >= _fr->interpreter_frame_tos_address();
       }
       if (in_stack) {
-        _f->do_oop(addr);
+        if (_f != NULL) {
+          _f->do_oop(addr);
+        }
       }
     }
   }
 
   int max_locals()  { return _max_locals; }
@@ -877,11 +904,11 @@
         oops_interpreted_arguments_do(signature, has_receiver, f);
       }
     }
   }
 
-  InterpreterFrameClosure blk(this, max_locals, m->max_stack(), f);
+  InterpreterFrameClosure blk(this, max_locals, m->max_stack(), f, NULL);
 
   // process locals & expression stack
   InterpreterOopMap mask;
   if (query_oop_map_cache) {
     m->mask_for(bci, &mask);
@@ -889,10 +916,27 @@
     OopMapCache::compute_one_oop_map(m, bci, &mask);
   }
   mask.iterate_oop(&blk);
 }
 
+void frame::buffered_values_interpreted_do(BufferedValueClosure* f) {
+  assert(is_interpreted_frame(), "Not an interpreted frame");
+  Thread *thread = Thread::current();
+  methodHandle m (thread, interpreter_frame_method());
+  jint      bci = interpreter_frame_bci();
+
+  assert(m->is_method(), "checking frame value");
+  assert(!m->is_native() && bci >= 0 && bci < m->code_size(),
+         "invalid bci value");
+
+  InterpreterFrameClosure blk(this, m->max_locals(), m->max_stack(), NULL, f);
+
+  // process locals & expression stack
+  InterpreterOopMap mask;
+  m->mask_for(bci, &mask);
+  mask.iterate_oop(&blk);
+}
 
 void frame::oops_interpreted_arguments_do(Symbol* signature, bool has_receiver, OopClosure* f) {
   InterpretedArgumentOopFinder finder(signature, has_receiver, this, f);
   finder.oops_do();
 }
@@ -935,10 +979,11 @@
   }
 
   virtual void handle_oop_offset() {
     // Extract low order register number from register array.
     // In LP64-land, the high-order bits are valid but unhelpful.
+    assert(_offset < _arg_size, "out of bounds");
     VMReg reg = _regs[_offset].first();
     oop *loc = _fr.oopmapreg_to_location(reg, _reg_map);
     _f->do_oop(loc);
   }
 
@@ -951,15 +996,11 @@
     _offset    = 0;
     _has_receiver = has_receiver;
     _has_appendix = has_appendix;
     _fr        = fr;
     _reg_map   = (RegisterMap*)reg_map;
-    _arg_size  = ArgumentSizeComputer(signature).size() + (has_receiver ? 1 : 0) + (has_appendix ? 1 : 0);
-
-    int arg_size;
-    _regs = SharedRuntime::find_callee_arguments(signature, has_receiver, has_appendix, &arg_size);
-    assert(arg_size == _arg_size, "wrong arg size");
+    _regs = SharedRuntime::find_callee_arguments(signature, has_receiver, has_appendix, &_arg_size);
   }
 
   void oops_do() {
     if (_has_receiver) {
       handle_oop_offset();
diff a/src/hotspot/share/runtime/globals.hpp b/src/hotspot/share/runtime/globals.hpp
--- a/src/hotspot/share/runtime/globals.hpp
+++ b/src/hotspot/share/runtime/globals.hpp
@@ -748,10 +748,28 @@
           "Use SSE2 MOVQ instruction for Arraycopy")                        \
                                                                             \
   notproduct(bool, PrintFieldLayout, false,                                 \
           "Print field layout for each class")                              \
                                                                             \
+  notproduct(bool, PrintInlineLayout, false,                                \
+          "Print field layout for each inline type")                        \
+                                                                            \
+  notproduct(bool, PrintInlineArrayLayout, false,                           \
+          "Print array layout for each inline type array")                  \
+                                                                            \
+  product(intx, InlineArrayElemMaxFlatSize, -1,                             \
+          "Max size for flattening inline array elements, <0 no limit")     \
+                                                                            \
+  product(intx, InlineFieldMaxFlatSize, 128,                                \
+          "Max size for flattening inline type fields, <0 no limit")        \
+                                                                            \
+  product(intx, InlineArrayElemMaxFlatOops, 4,                              \
+          "Max nof embedded object references in an inline type to flatten, <0 no limit")  \
+                                                                            \
+  product(bool, InlineArrayAtomicAccess, false,                             \
+          "Atomic inline array accesses by-default, for all inline arrays") \
+                                                                            \
   /* Need to limit the extent of the padding to reasonable size.          */\
   /* 8K is well beyond the reasonable HW cache line size, even with       */\
   /* aggressive prefetching, while still leaving the room for segregating */\
   /* among the distinct pages.                                            */\
   product(intx, ContendedPaddingWidth, 128,                                 \
@@ -763,11 +781,11 @@
           "Enable @Contended annotation support")                           \
                                                                             \
   product(bool, RestrictContended, true,                                    \
           "Restrict @Contended to trusted classes")                         \
                                                                             \
-  product(bool, UseBiasedLocking, false,                                    \
+  product(bool, UseBiasedLocking, true,                                     \
           "(Deprecated) Enable biased locking in JVM")                      \
                                                                             \
   product(intx, BiasedLockingStartupDelay, 0,                               \
           "(Deprecated) Number of milliseconds to wait before enabling "    \
           "biased locking")                                                 \
@@ -2433,19 +2451,47 @@
           "Start flight recording with options"))                           \
                                                                             \
   experimental(bool, UseFastUnorderedTimeStamps, false,                     \
           "Use platform unstable time where supported for timestamps only") \
                                                                             \
+  product(bool, EnableValhalla, true,                                       \
+          "Enable experimental Valhalla features")                          \
+                                                                            \
+  product_pd(bool, InlineTypePassFieldsAsArgs,                              \
+          "Pass each inline type field as an argument at calls")            \
+                                                                            \
+  product_pd(bool, InlineTypeReturnedAsFields,                              \
+          "Return fields instead of an inline type reference")              \
+                                                                            \
+  develop(bool, StressInlineTypeReturnedAsFields, false,                    \
+          "Stress return of fields instead of an inline type reference")    \
+                                                                            \
+  develop(bool, ScalarizeInlineTypes, true,                                 \
+          "Scalarize inline types in compiled code")                        \
+                                                                            \
+  diagnostic(ccstrlist, ForceNonTearable, "",                               \
+          "List of inline classes which are forced to be atomic "           \
+          "(whitespace and commas separate names, "                         \
+          "and leading and trailing stars '*' are wildcards)")              \
+                                                                            \
+  product(bool, PrintNewLayout, false,                                      \
+               "Print layout compute by new algorithm")                     \
+                                                                            \
+  product(bool, PrintFlattenableLayouts, false,                             \
+                "Print layout of inline classes and classes with "          \
+                "flattenable fields")                                       \
+                                                                            \
   product(bool, UseNewFieldLayout, true,                                    \
-               "(Deprecated) Use new algorithm to compute field layouts")   \
+                "(Deprecated) Use new algorithm to compute field layouts")  \
                                                                             \
   product(bool, UseEmptySlotsInSupers, true,                                \
                 "Allow allocating fields in empty slots of super-classes")  \
                                                                             \
   diagnostic(bool, DeoptimizeNMethodBarriersALot, false,                    \
                 "Make nmethod barriers deoptimise a lot.")                  \
 
+
 // Interface macros
 #define DECLARE_PRODUCT_FLAG(type, name, value, doc)      extern "C" type name;
 #define DECLARE_PD_PRODUCT_FLAG(type, name, doc)          extern "C" type name;
 #define DECLARE_DIAGNOSTIC_FLAG(type, name, value, doc)   extern "C" type name;
 #define DECLARE_PD_DIAGNOSTIC_FLAG(type, name, doc)       extern "C" type name;
diff a/src/hotspot/share/runtime/init.cpp b/src/hotspot/share/runtime/init.cpp
--- a/src/hotspot/share/runtime/init.cpp
+++ b/src/hotspot/share/runtime/init.cpp
@@ -111,21 +111,21 @@
   bytecodes_init();
   classLoader_init1();
   compilationPolicy_init();
   codeCache_init();
   VM_Version_init();
+  VMRegImpl::set_regName();  // need this before generate_stubs (for printing oop maps).
   stubRoutines_init1();
   jint status = universe_init();  // dependent on codeCache_init and
                                   // stubRoutines_init1 and metaspace_init.
   if (status != JNI_OK)
     return status;
 
   gc_barrier_stubs_init();  // depends on universe_init, must be before interpreter_init
   interpreter_init_stub();  // before methods get loaded
   accessFlags_init();
   InterfaceSupport_init();
-  VMRegImpl::set_regName(); // need this before generate_stubs (for printing oop maps).
   SharedRuntime::generate_stubs();
   universe2_init();  // dependent on codeCache_init and stubRoutines_init1
   javaClasses_init();// must happen after vtable initialization, before referenceProcessor_init
   interpreter_init_code();  // after javaClasses_init and before any method gets linked
   invocationCounter_init(); // after javaClasses_init and before any method gets linked
diff a/src/hotspot/share/runtime/thread.cpp b/src/hotspot/share/runtime/thread.cpp
--- a/src/hotspot/share/runtime/thread.cpp
+++ b/src/hotspot/share/runtime/thread.cpp
@@ -56,10 +56,11 @@
 #include "oops/instanceKlass.hpp"
 #include "oops/objArrayOop.hpp"
 #include "oops/oop.inline.hpp"
 #include "oops/symbol.hpp"
 #include "oops/typeArrayOop.inline.hpp"
+#include "oops/valueKlass.hpp"
 #include "oops/verifyOopClosure.hpp"
 #include "prims/jvm_misc.hpp"
 #include "prims/jvmtiExport.hpp"
 #include "prims/jvmtiThreadState.hpp"
 #include "runtime/arguments.hpp"
@@ -1635,10 +1636,11 @@
   set_entry_point(NULL);
   set_jni_functions(jni_functions());
   set_callee_target(NULL);
   set_vm_result(NULL);
   set_vm_result_2(NULL);
+  set_return_buffered_value(NULL);
   set_vframe_array_head(NULL);
   set_vframe_array_last(NULL);
   set_deferred_locals(NULL);
   set_deopt_mark(NULL);
   set_deopt_compiled_method(NULL);
@@ -2841,10 +2843,13 @@
 }
 
 void JavaThread::frames_do(void f(frame*, const RegisterMap* map)) {
   // ignore is there is no stack
   if (!has_last_Java_frame()) return;
+  // Because this method is used to verify oops, it must support
+  // oops in buffered values
+
   // traverse the stack frames. Starts from top frame.
   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
     frame* fr = fst.current();
     f(fr, fst.register_map());
   }
diff a/src/hotspot/share/runtime/thread.hpp b/src/hotspot/share/runtime/thread.hpp
--- a/src/hotspot/share/runtime/thread.hpp
+++ b/src/hotspot/share/runtime/thread.hpp
@@ -443,10 +443,11 @@
  public:
   enum {
     is_definitely_current_thread = true
   };
 
+ public:
   // Constructor
   Thread();
   virtual ~Thread() = 0;        // Thread is abstract.
 
   // Manage Thread::current()
@@ -1015,10 +1016,11 @@
 
 class JavaThread: public Thread {
   friend class VMStructs;
   friend class JVMCIVMStructs;
   friend class WhiteBox;
+  friend class VTBuffer;
   friend class ThreadsSMRSupport; // to access _threadObj for exiting_threads_oops_do
  private:
   bool           _on_thread_list;                // Is set when this JavaThread is added to the Threads list
   oop            _threadObj;                     // The Java level thread object
 
@@ -1073,10 +1075,11 @@
   Method*       _callee_target;
 
   // Used to pass back results to the interpreter or generated code running Java code.
   oop           _vm_result;    // oop result is GC-preserved
   Metadata*     _vm_result_2;  // non-oop result
+  oop           _return_buffered_value; // buffered value being returned
 
   // See ReduceInitialCardMarks: this holds the precise space interval of
   // the most recent slow path allocation for which compiled code has
   // elided card-marks for performance along the fast-path.
   MemRegion     _deferred_card_mark;
@@ -1553,10 +1556,13 @@
   void set_vm_result  (oop x)                    { _vm_result   = x; }
 
   Metadata*    vm_result_2() const               { return _vm_result_2; }
   void set_vm_result_2  (Metadata* x)          { _vm_result_2   = x; }
 
+  oop return_buffered_value() const              { return _return_buffered_value; }
+  void set_return_buffered_value(oop val)        { _return_buffered_value = val; }
+
   MemRegion deferred_card_mark() const           { return _deferred_card_mark; }
   void set_deferred_card_mark(MemRegion mr)      { _deferred_card_mark = mr;   }
 
 #if INCLUDE_JVMCI
   int  pending_deoptimization() const             { return _pending_deoptimization; }
@@ -1792,10 +1798,11 @@
     return byte_offset_of(JavaThread, _anchor);
   }
   static ByteSize callee_target_offset()         { return byte_offset_of(JavaThread, _callee_target); }
   static ByteSize vm_result_offset()             { return byte_offset_of(JavaThread, _vm_result); }
   static ByteSize vm_result_2_offset()           { return byte_offset_of(JavaThread, _vm_result_2); }
+  static ByteSize return_buffered_value_offset() { return byte_offset_of(JavaThread, _return_buffered_value); }
   static ByteSize thread_state_offset()          { return byte_offset_of(JavaThread, _thread_state); }
   static ByteSize saved_exception_pc_offset()    { return byte_offset_of(JavaThread, _saved_exception_pc); }
   static ByteSize osthread_offset()              { return byte_offset_of(JavaThread, _osthread); }
 #if INCLUDE_JVMCI
   static ByteSize pending_deoptimization_offset() { return byte_offset_of(JavaThread, _pending_deoptimization); }
diff a/src/hotspot/share/runtime/vmStructs.cpp b/src/hotspot/share/runtime/vmStructs.cpp
--- a/src/hotspot/share/runtime/vmStructs.cpp
+++ b/src/hotspot/share/runtime/vmStructs.cpp
@@ -231,11 +231,11 @@
   nonstatic_field(InstanceKlass,               _nonstatic_field_size,                         int)                                   \
   nonstatic_field(InstanceKlass,               _static_field_size,                            int)                                   \
   nonstatic_field(InstanceKlass,               _static_oop_field_count,                       u2)                                    \
   nonstatic_field(InstanceKlass,               _nonstatic_oop_map_size,                       int)                                   \
   nonstatic_field(InstanceKlass,               _is_marked_dependent,                          bool)                                  \
-  nonstatic_field(InstanceKlass,               _misc_flags,                                   u2)                                    \
+  nonstatic_field(InstanceKlass,               _misc_flags,                                   u4)                                    \
   nonstatic_field(InstanceKlass,               _init_state,                                   u1)                                    \
   nonstatic_field(InstanceKlass,               _init_thread,                                  Thread*)                               \
   nonstatic_field(InstanceKlass,               _itable_len,                                   int)                                   \
   nonstatic_field(InstanceKlass,               _reference_type,                               u1)                                    \
   volatile_nonstatic_field(InstanceKlass,      _oop_map_cache,                                OopMapCache*)                          \
@@ -1593,13 +1593,15 @@
   declare_c2_type(ConvF2INode, Node)                                      \
   declare_c2_type(ConvF2LNode, Node)                                      \
   declare_c2_type(ConvI2DNode, Node)                                      \
   declare_c2_type(ConvI2FNode, Node)                                      \
   declare_c2_type(ConvI2LNode, TypeNode)                                  \
+  declare_c2_type(CastI2NNode, TypeNode)                                  \
   declare_c2_type(ConvL2DNode, Node)                                      \
   declare_c2_type(ConvL2FNode, Node)                                      \
   declare_c2_type(ConvL2INode, Node)                                      \
+  declare_c2_type(CastN2INode, Node)                                      \
   declare_c2_type(CastX2PNode, Node)                                      \
   declare_c2_type(CastP2XNode, Node)                                      \
   declare_c2_type(SetVectMaskINode, Node)                                 \
   declare_c2_type(MemBarNode, MultiNode)                                  \
   declare_c2_type(MemBarAcquireNode, MemBarNode)                          \
@@ -1636,10 +1638,11 @@
   declare_c2_type(MachNode, Node)                                         \
   declare_c2_type(MachIdealNode, MachNode)                                \
   declare_c2_type(MachTypeNode, MachNode)                                 \
   declare_c2_type(MachBreakpointNode, MachIdealNode)                      \
   declare_c2_type(MachUEPNode, MachIdealNode)                             \
+  declare_c2_type(MachVEPNode, MachIdealNode)                             \
   declare_c2_type(MachPrologNode, MachIdealNode)                          \
   declare_c2_type(MachEpilogNode, MachIdealNode)                          \
   declare_c2_type(MachNopNode, MachIdealNode)                             \
   declare_c2_type(MachSpillCopyNode, MachIdealNode)                       \
   declare_c2_type(MachNullCheckNode, MachIdealNode)                       \
@@ -2289,10 +2292,12 @@
   declare_constant(InstanceKlass::_misc_has_passed_fingerprint_check)     \
   declare_constant(InstanceKlass::_misc_is_scratch_class)                 \
   declare_constant(InstanceKlass::_misc_is_shared_boot_class)             \
   declare_constant(InstanceKlass::_misc_is_shared_platform_class)         \
   declare_constant(InstanceKlass::_misc_is_shared_app_class)              \
+  declare_constant(InstanceKlass::_misc_invalid_inline_super)             \
+  declare_constant(InstanceKlass::_misc_invalid_identity_super)           \
                                                                           \
   /*********************************/                                     \
   /* Symbol* - symbol max length */                                       \
   /*********************************/                                     \
                                                                           \
diff a/src/hotspot/share/utilities/globalDefinitions.hpp b/src/hotspot/share/utilities/globalDefinitions.hpp
--- a/src/hotspot/share/utilities/globalDefinitions.hpp
+++ b/src/hotspot/share/utilities/globalDefinitions.hpp
@@ -529,10 +529,19 @@
 // used to silence compiler warnings
 
 #define Unused_Variable(var) var
 
 
+//----------------------------------------------------------------------------------------------------
+// Prototyping
+// "Code Missing Here" macro, un-define when integrating back from prototyping stage and break
+// compilation on purpose (i.e. "forget me not")
+#define PROTOTYPE
+#ifdef PROTOTYPE
+#define CMH(m)
+#endif
+
 //----------------------------------------------------------------------------------------------------
 // Miscellaneous
 
 // 6302670 Eliminate Hotspot __fabsf dependency
 // All fabs() callers should call this function instead, which will implicitly
@@ -614,16 +623,17 @@
   // T_ADDRESS, T_METADATA, T_NARROWOOP, T_NARROWKLASS describe
   // internal references within the JVM as if they were Java
   // types in their own right.
   T_OBJECT      = 12,
   T_ARRAY       = 13,
-  T_VOID        = 14,
-  T_ADDRESS     = 15,
-  T_NARROWOOP   = 16,
-  T_METADATA    = 17,
-  T_NARROWKLASS = 18,
-  T_CONFLICT    = 19, // for stack value type with conflicting contents
+  T_VALUETYPE   = 14,
+  T_VOID        = 15,
+  T_ADDRESS     = 16,
+  T_NARROWOOP   = 17,
+  T_METADATA    = 18,
+  T_NARROWKLASS = 19,
+  T_CONFLICT    = 20, // for stack value type with conflicting contents
   T_ILLEGAL     = 99
 };
 
 #define SIGNATURE_TYPES_DO(F, N)                \
     F(JVM_SIGNATURE_BOOLEAN, T_BOOLEAN, N)      \
@@ -634,10 +644,11 @@
     F(JVM_SIGNATURE_SHORT,   T_SHORT,   N)      \
     F(JVM_SIGNATURE_INT,     T_INT,     N)      \
     F(JVM_SIGNATURE_LONG,    T_LONG,    N)      \
     F(JVM_SIGNATURE_CLASS,   T_OBJECT,  N)      \
     F(JVM_SIGNATURE_ARRAY,   T_ARRAY,   N)      \
+    F(JVM_SIGNATURE_VALUETYPE,  T_VALUETYPE, N) \
     F(JVM_SIGNATURE_VOID,    T_VOID,    N)      \
     /*end*/
 
 inline bool is_java_type(BasicType t) {
   return T_BOOLEAN <= t && t <= T_VOID;
@@ -659,11 +670,11 @@
 inline bool is_double_word_type(BasicType t) {
   return (t == T_DOUBLE || t == T_LONG);
 }
 
 inline bool is_reference_type(BasicType t) {
-  return (t == T_OBJECT || t == T_ARRAY);
+  return (t == T_OBJECT || t == T_ARRAY || t == T_VALUETYPE);
 }
 
 extern char type2char_tab[T_CONFLICT+1];     // Map a BasicType to a jchar
 inline char type2char(BasicType t) { return (uint)t < T_CONFLICT+1 ? type2char_tab[t] : 0; }
 extern int type2size[T_CONFLICT+1];         // Map BasicType to result stack elements
@@ -688,11 +699,12 @@
   T_LONG_size        = 2,
   T_OBJECT_size      = 1,
   T_ARRAY_size       = 1,
   T_NARROWOOP_size   = 1,
   T_NARROWKLASS_size = 1,
-  T_VOID_size        = 0
+  T_VOID_size        = 0,
+  T_VALUETYPE_size   = 1
 };
 
 // this works on valid parameter types but not T_VOID, T_CONFLICT, etc.
 inline int parameter_type_word_count(BasicType t) {
   if (is_double_word_type(t))  return 2;
@@ -718,13 +730,15 @@
   T_INT_aelem_bytes         = 4,
   T_LONG_aelem_bytes        = 8,
 #ifdef _LP64
   T_OBJECT_aelem_bytes      = 8,
   T_ARRAY_aelem_bytes       = 8,
+  T_VALUETYPE_aelem_bytes   = 8,
 #else
   T_OBJECT_aelem_bytes      = 4,
   T_ARRAY_aelem_bytes       = 4,
+  T_VALUETYPE_aelem_bytes   = 4,
 #endif
   T_NARROWOOP_aelem_bytes   = 4,
   T_NARROWKLASS_aelem_bytes = 4,
   T_VOID_aelem_bytes        = 0
 };
@@ -807,11 +821,11 @@
   itos = 4,             // int tos cached
   ltos = 5,             // long tos cached
   ftos = 6,             // float tos cached
   dtos = 7,             // double tos cached
   atos = 8,             // object cached
-  vtos = 9,             // tos not cached
+  vtos = 9,             // tos not cached,
   number_of_states,
   ilgl                  // illegal state: should not occur
 };
 
 
@@ -824,11 +838,12 @@
     case T_INT    : return itos;
     case T_LONG   : return ltos;
     case T_FLOAT  : return ftos;
     case T_DOUBLE : return dtos;
     case T_VOID   : return vtos;
-    case T_ARRAY  : // fall through
+    case T_VALUETYPE: // fall through
+    case T_ARRAY  :   // fall through
     case T_OBJECT : return atos;
     default       : return ilgl;
   }
 }
 
@@ -1192,7 +1207,13 @@
 
 template<typename K> bool primitive_equals(const K& k0, const K& k1) {
   return k0 == k1;
 }
 
+// TEMP!!!!
+// This should be removed after LW2 arrays are implemented (JDK-8220790).
+// It's an alias to (EnableValhalla && (InlineArrayElemMaxFlatSize != 0)),
+// which is actually not 100% correct, but works for the current set of C1/C2
+// implementation and test cases.
+#define ValueArrayFlatten (EnableValhalla && (InlineArrayElemMaxFlatSize != 0))
 
 #endif // SHARE_UTILITIES_GLOBALDEFINITIONS_HPP
diff a/src/java.base/share/classes/java/lang/System.java b/src/java.base/share/classes/java/lang/System.java
--- a/src/java.base/share/classes/java/lang/System.java
+++ b/src/java.base/share/classes/java/lang/System.java
@@ -2268,11 +2268,10 @@
             }
 
             public byte[] getBytesUTF8NoRepl(String s) {
                 return StringCoding.getBytesUTF8NoRepl(s);
             }
-
             public void setCause(Throwable t, Throwable cause) {
                 t.setCause(cause);
             }
 
             public ProtectionDomain protectionDomain(Class<?> c) {
diff a/src/java.base/share/classes/java/lang/invoke/MethodHandles.java b/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
--- a/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
+++ b/src/java.base/share/classes/java/lang/invoke/MethodHandles.java
@@ -2329,10 +2329,16 @@
          *                              <a href="MethodHandles.Lookup.html#secmgr">refuses access</a>
          * @throws NullPointerException if any argument is null
          */
         public MethodHandle findStatic(Class<?> refc, String name, MethodType type) throws NoSuchMethodException, IllegalAccessException {
             MemberName method = resolveOrFail(REF_invokeStatic, refc, name, type);
+            // resolveOrFail could return a non-static <init> method if present
+            // detect and throw NSME before producing a MethodHandle
+            if (!method.isStatic() && name.equals("<init>")) {
+                throw new NoSuchMethodException("illegal method name: " + name);
+            }
+
             return getDirectMethod(REF_invokeStatic, refc, method, findBoundCallerLookup(method));
         }
 
         /**
          * Produces a method handle for a virtual method.
@@ -2474,10 +2480,17 @@
   ProcessBuilder.class, methodType(void.class, String[].class));
 ProcessBuilder pb = (ProcessBuilder)
   MH_newProcessBuilder.invoke("x", "y", "z");
 assertEquals("[x, y, z]", pb.command().toString());
          * }</pre></blockquote>
+         *
+         * @apiNote
+         * This method does not find a static {@code <init>} factory method as it is invoked
+         * via {@code invokestatic} bytecode as opposed to {@code invokespecial} for an
+         * object constructor.  To look up static {@code <init>} factory method, use
+         * the {@link #findStatic(Class, String, MethodType) findStatic} method.
+         *
          * @param refc the class or interface from which the method is accessed
          * @param type the type of the method, with the receiver argument omitted, and a void return type
          * @return the desired method handle
          * @throws NoSuchMethodException if the constructor does not exist
          * @throws IllegalAccessException if access checking fails
@@ -2489,10 +2502,13 @@
          */
         public MethodHandle findConstructor(Class<?> refc, MethodType type) throws NoSuchMethodException, IllegalAccessException {
             if (refc.isArray()) {
                 throw new NoSuchMethodException("no constructor for array class: " + refc.getName());
             }
+            if (type.returnType() != void.class) {
+                throw new NoSuchMethodException("Constructors must have void return type: " + refc.getName());
+            }
             String name = "<init>";
             MemberName ctor = resolveOrFail(REF_newInvokeSpecial, refc, name, type);
             return getDirectConstructor(refc, ctor);
         }
 
@@ -3106,14 +3122,22 @@
          *                                is set and {@code asVarargsCollector} fails
          * @throws NullPointerException if the argument is null
          */
         public MethodHandle unreflectConstructor(Constructor<?> c) throws IllegalAccessException {
             MemberName ctor = new MemberName(c);
-            assert(ctor.isConstructor());
+            assert(ctor.isObjectConstructorOrStaticInitMethod());
             @SuppressWarnings("deprecation")
             Lookup lookup = c.isAccessible() ? IMPL_LOOKUP : this;
-            return lookup.getDirectConstructorNoSecurityManager(ctor.getDeclaringClass(), ctor);
+            if (ctor.isObjectConstructor()) {
+                assert(ctor.getReturnType() == void.class);
+                return lookup.getDirectConstructorNoSecurityManager(ctor.getDeclaringClass(), ctor);
+            } else {
+                // static init factory is a static method
+                assert(ctor.isMethod() && ctor.getReturnType() == ctor.getDeclaringClass() && ctor.getReferenceKind() == REF_invokeStatic);
+                assert(!MethodHandleNatives.isCallerSensitive(ctor));  // must not be caller-sensitive
+                return lookup.getDirectMethodNoSecurityManager(ctor.getReferenceKind(), ctor.getDeclaringClass(), ctor, lookup);
+            }
         }
 
         /**
          * Produces a method handle giving read access to a reflected field.
          * The type of the method handle will have a return type of the field's
@@ -3362,15 +3386,17 @@
             return caller == null || VerifyAccess.isClassAccessible(refc, caller, prevLookupClass, allowedModes);
         }
 
         /** Check name for an illegal leading "&lt;" character. */
         void checkMethodName(byte refKind, String name) throws NoSuchMethodException {
-            if (name.startsWith("<") && refKind != REF_newInvokeSpecial)
-                throw new NoSuchMethodException("illegal method name: "+name);
+            // "<init>" can only be invoked via invokespecial or it's a static init factory
+            if (name.startsWith("<") && refKind != REF_newInvokeSpecial &&
+                    !(refKind == REF_invokeStatic && name.equals("<init>"))) {
+                    throw new NoSuchMethodException("illegal method name: " + name);
+            }
         }
 
-
         /**
          * Find my trustable caller class if m is a caller sensitive method.
          * If this lookup object has full privilege access, then the caller class is the lookupClass.
          * Otherwise, if m is caller-sensitive, throw IllegalAccessException.
          */
@@ -3451,11 +3477,11 @@
         }
 
         void checkMethod(byte refKind, Class<?> refc, MemberName m) throws IllegalAccessException {
             boolean wantStatic = (refKind == REF_invokeStatic);
             String message;
-            if (m.isConstructor())
+            if (m.isObjectConstructor())
                 message = "expected a method, not a constructor";
             else if (!m.isMethod())
                 message = "expected a method";
             else if (wantStatic != m.isStatic())
                 message = wantStatic ? "expected a static method" : "expected a non-static method";
@@ -3750,11 +3776,11 @@
             return getDirectConstructorCommon(refc, ctor, checkSecurity);
         }
         /** Common code for all constructors; do not call directly except from immediately above. */
         private MethodHandle getDirectConstructorCommon(Class<?> refc, MemberName ctor,
                                                   boolean checkSecurity) throws IllegalAccessException {
-            assert(ctor.isConstructor());
+            assert(ctor.isObjectConstructor());
             checkAccess(REF_newInvokeSpecial, refc, ctor);
             // Optionally check with the security manager; this isn't needed for unreflect* calls.
             if (checkSecurity)
                 checkSecurityManager(refc, ctor);
             assert(!MethodHandleNatives.isCallerSensitive(ctor));  // maybeBindCaller not relevant here
@@ -3940,10 +3966,13 @@
      * @throws NullPointerException if the argument is null
      * @throws IllegalArgumentException if arrayClass is not an array type
      * @jvms 6.5 {@code aastore} Instruction
      */
     public static MethodHandle arrayElementSetter(Class<?> arrayClass) throws IllegalArgumentException {
+        if (arrayClass.isInlineClass()) {
+            throw new UnsupportedOperationException();
+        }
         return MethodHandleImpl.makeArrayElementAccessor(arrayClass, MethodHandleImpl.ArrayAccess.SET);
     }
 
     /**
      * Produces a VarHandle giving access to elements of an array of type
@@ -4700,11 +4729,17 @@
      * @see MethodHandles#explicitCastArguments
      * @since 9
      */
     public static MethodHandle zero(Class<?> type) {
         Objects.requireNonNull(type);
-        return type.isPrimitive() ?  zero(Wrapper.forPrimitiveType(type), type) : zero(Wrapper.OBJECT, type);
+        if (type.isPrimitive()) {
+            return zero(Wrapper.forPrimitiveType(type), type);
+        } else if (type.isInlineClass()) {
+            throw new UnsupportedOperationException();
+        } else {
+            return zero(Wrapper.OBJECT, type);
+        }
     }
 
     private static MethodHandle identityOrVoid(Class<?> type) {
         return type == void.class ? zero(type) : identity(type);
     }
@@ -4730,11 +4765,11 @@
         return dropArguments(zero(type.returnType()), 0, type.parameterList());
     }
 
     private static final MethodHandle[] IDENTITY_MHS = new MethodHandle[Wrapper.COUNT];
     private static MethodHandle makeIdentity(Class<?> ptype) {
-        MethodType mtype = methodType(ptype, ptype);
+        MethodType mtype = MethodType.methodType(ptype, ptype);
         LambdaForm lform = LambdaForm.identityForm(BasicType.basicType(ptype));
         return MethodHandleImpl.makeIntrinsic(mtype, lform, Intrinsic.IDENTITY);
     }
 
     private static MethodHandle zero(Wrapper btw, Class<?> rtype) {
diff a/src/java.base/share/classes/java/lang/invoke/VarHandles.java b/src/java.base/share/classes/java/lang/invoke/VarHandles.java
--- a/src/java.base/share/classes/java/lang/invoke/VarHandles.java
+++ b/src/java.base/share/classes/java/lang/invoke/VarHandles.java
@@ -55,13 +55,19 @@
 
     static VarHandle makeFieldHandle(MemberName f, Class<?> refc, Class<?> type, boolean isWriteAllowedOnFinalFields) {
         if (!f.isStatic()) {
             long foffset = MethodHandleNatives.objectFieldOffset(f);
             if (!type.isPrimitive()) {
-                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
+                if (f.isFlattened()) {
+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
+                        ? new VarHandleValues.FieldInstanceReadOnly(refc, foffset, type)
+                        : new VarHandleValues.FieldInstanceReadWrite(refc, foffset, type));
+                } else {
+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleReferences.FieldInstanceReadOnly(refc, foffset, type)
                        : new VarHandleReferences.FieldInstanceReadWrite(refc, foffset, type));
+                }
             }
             else if (type == boolean.class) {
                 return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleBooleans.FieldInstanceReadOnly(refc, foffset)
                        : new VarHandleBooleans.FieldInstanceReadWrite(refc, foffset));
@@ -116,13 +122,19 @@
                 UNSAFE.ensureClassInitialized(refc);
 
             Object base = MethodHandleNatives.staticFieldBase(f);
             long foffset = MethodHandleNatives.staticFieldOffset(f);
             if (!type.isPrimitive()) {
-                return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
-                       ? new VarHandleReferences.FieldStaticReadOnly(base, foffset, type)
-                       : new VarHandleReferences.FieldStaticReadWrite(base, foffset, type));
+                if (f.isFlattened()) {
+                    return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
+                            ? new VarHandleValues.FieldStaticReadOnly(refc, foffset, type)
+                            : new VarHandleValues.FieldStaticReadWrite(refc, foffset, type));
+                } else {
+                    return f.isFinal() && !isWriteAllowedOnFinalFields
+                            ? new VarHandleReferences.FieldStaticReadOnly(base, foffset, type)
+                            : new VarHandleReferences.FieldStaticReadWrite(base, foffset, type);
+                }
             }
             else if (type == boolean.class) {
                 return maybeAdapt(f.isFinal() && !isWriteAllowedOnFinalFields
                        ? new VarHandleBooleans.FieldStaticReadOnly(base, foffset)
                        : new VarHandleBooleans.FieldStaticReadWrite(base, foffset));
@@ -209,11 +221,17 @@
         int aoffset = UNSAFE.arrayBaseOffset(arrayClass);
         int ascale = UNSAFE.arrayIndexScale(arrayClass);
         int ashift = 31 - Integer.numberOfLeadingZeros(ascale);
 
         if (!componentType.isPrimitive()) {
-            return maybeAdapt(new VarHandleReferences.Array(aoffset, ashift, arrayClass));
+            // the redundant componentType.isValue() check is there to
+            // minimize the performance impact to non-value array.
+            // It should be removed when Unsafe::isFlattenedArray is intrinsified.
+
+            return maybeAdapt(componentType.isInlineClass() && UNSAFE.isFlattenedArray(arrayClass)
+                ? new VarHandleValues.Array(aoffset, ashift, arrayClass)
+                : new VarHandleReferences.Array(aoffset, ashift, arrayClass));
         }
         else if (componentType == boolean.class) {
             return maybeAdapt(new VarHandleBooleans.Array(aoffset, ashift));
         }
         else if (componentType == byte.class) {
diff a/src/java.base/share/classes/java/lang/invoke/X-VarHandle.java.template b/src/java.base/share/classes/java/lang/invoke/X-VarHandle.java.template
--- a/src/java.base/share/classes/java/lang/invoke/X-VarHandle.java.template
+++ b/src/java.base/share/classes/java/lang/invoke/X-VarHandle.java.template
@@ -78,170 +78,178 @@
 
         @ForceInline
         static $type$ get(VarHandle ob, Object holder) {
             FieldInstanceReadOnly handle = (FieldInstanceReadOnly)ob;
             return UNSAFE.get$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                 handle.fieldOffset);
+                                 handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
         static $type$ getVolatile(VarHandle ob, Object holder) {
             FieldInstanceReadOnly handle = (FieldInstanceReadOnly)ob;
             return UNSAFE.get$Type$Volatile(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                 handle.fieldOffset);
+                                 handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
         static $type$ getOpaque(VarHandle ob, Object holder) {
             FieldInstanceReadOnly handle = (FieldInstanceReadOnly)ob;
             return UNSAFE.get$Type$Opaque(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                 handle.fieldOffset);
+                                 handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
         static $type$ getAcquire(VarHandle ob, Object holder) {
             FieldInstanceReadOnly handle = (FieldInstanceReadOnly)ob;
             return UNSAFE.get$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                 handle.fieldOffset);
+                                 handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         static final VarForm FORM = new VarForm(FieldInstanceReadOnly.class, Object.class, $type$.class);
     }
 
     static final class FieldInstanceReadWrite extends FieldInstanceReadOnly {
-
         FieldInstanceReadWrite(Class<?> receiverType, long fieldOffset{#if[Object]?, Class<?> fieldType}) {
             super(receiverType, fieldOffset{#if[Object]?, fieldType}, FieldInstanceReadWrite.FORM);
         }
 
+#if[Object]
+        @ForceInline
+        static Object checkCast(FieldInstanceReadWrite handle, $type$ value) {
+            if (handle.fieldType.isInlineClass())
+                Objects.requireNonNull(value);
+            return handle.fieldType.cast(value);
+        }
+#end[Object]
+
         @ForceInline
         static void set(VarHandle ob, Object holder, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             UNSAFE.put$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                             handle.fieldOffset,
-                             {#if[Object]?handle.fieldType.cast(value):value});
+                             handle.fieldOffset{#if[Value]?, handle.fieldType},
+                             {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static void setVolatile(VarHandle ob, Object holder, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             UNSAFE.put$Type$Volatile(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                     handle.fieldOffset,
-                                     {#if[Object]?handle.fieldType.cast(value):value});
+                                     handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                     {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static void setOpaque(VarHandle ob, Object holder, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             UNSAFE.put$Type$Opaque(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                   handle.fieldOffset,
-                                   {#if[Object]?handle.fieldType.cast(value):value});
+                                   handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                   {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static void setRelease(VarHandle ob, Object holder, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             UNSAFE.put$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                    handle.fieldOffset,
-                                    {#if[Object]?handle.fieldType.cast(value):value});
+                                    handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                    {#if[Object]?checkCast(handle, value):value});
         }
 #if[CAS]
 
         @ForceInline
         static boolean compareAndSet(VarHandle ob, Object holder, $type$ expected, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.compareAndSet$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ compareAndExchange(VarHandle ob, Object holder, $type$ expected, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ compareAndExchangeAcquire(VarHandle ob, Object holder, $type$ expected, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ compareAndExchangeRelease(VarHandle ob, Object holder, $type$ expected, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static boolean weakCompareAndSetPlain(VarHandle ob, Object holder, $type$ expected, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Plain(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static boolean weakCompareAndSet(VarHandle ob, Object holder, $type$ expected, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static boolean weakCompareAndSetAcquire(VarHandle ob, Object holder, $type$ expected, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static boolean weakCompareAndSetRelease(VarHandle ob, Object holder, $type$ expected, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ getAndSet(VarHandle ob, Object holder, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndSet$Type$(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                          handle.fieldOffset,
-                                          {#if[Object]?handle.fieldType.cast(value):value});
+                                          handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                          {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ getAndSetAcquire(VarHandle ob, Object holder, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndSet$Type$Acquire(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                          handle.fieldOffset,
-                                          {#if[Object]?handle.fieldType.cast(value):value});
+                                          handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                          {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ getAndSetRelease(VarHandle ob, Object holder, $type$ value) {
             FieldInstanceReadWrite handle = (FieldInstanceReadWrite)ob;
             return UNSAFE.getAndSet$Type$Release(Objects.requireNonNull(handle.receiverType.cast(holder)),
-                                          handle.fieldOffset,
-                                          {#if[Object]?handle.fieldType.cast(value):value});
+                                          handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                          {#if[Object]?checkCast(handle, value):value});
         }
 #end[CAS]
 #if[AtomicAdd]
 
         @ForceInline
@@ -391,171 +399,178 @@
 
         @ForceInline
         static $type$ get(VarHandle ob) {
             FieldStaticReadOnly handle = (FieldStaticReadOnly)ob;
             return UNSAFE.get$Type$(handle.base,
-                                 handle.fieldOffset);
+                                 handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
         static $type$ getVolatile(VarHandle ob) {
             FieldStaticReadOnly handle = (FieldStaticReadOnly)ob;
             return UNSAFE.get$Type$Volatile(handle.base,
-                                 handle.fieldOffset);
+                                 handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
         static $type$ getOpaque(VarHandle ob) {
             FieldStaticReadOnly handle = (FieldStaticReadOnly)ob;
             return UNSAFE.get$Type$Opaque(handle.base,
-                                 handle.fieldOffset);
+                                 handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         @ForceInline
         static $type$ getAcquire(VarHandle ob) {
             FieldStaticReadOnly handle = (FieldStaticReadOnly)ob;
             return UNSAFE.get$Type$Acquire(handle.base,
-                                 handle.fieldOffset);
+                                 handle.fieldOffset{#if[Value]?, handle.fieldType});
         }
 
         static final VarForm FORM = new VarForm(FieldStaticReadOnly.class, null, $type$.class);
     }
 
     static final class FieldStaticReadWrite extends FieldStaticReadOnly {
-
         FieldStaticReadWrite(Object base, long fieldOffset{#if[Object]?, Class<?> fieldType}) {
             super(base, fieldOffset{#if[Object]?, fieldType}, FieldStaticReadWrite.FORM);
         }
 
+#if[Object]
+        static Object checkCast(FieldStaticReadWrite handle, $type$ value) {
+            if (handle.fieldType.isInlineClass())
+                Objects.requireNonNull(value);
+            return handle.fieldType.cast(value);
+        }
+#end[Object]
+
         @ForceInline
         static void set(VarHandle ob, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             UNSAFE.put$Type$(handle.base,
-                             handle.fieldOffset,
-                             {#if[Object]?handle.fieldType.cast(value):value});
+                             handle.fieldOffset{#if[Value]?, handle.fieldType},
+                             {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static void setVolatile(VarHandle ob, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             UNSAFE.put$Type$Volatile(handle.base,
-                                     handle.fieldOffset,
-                                     {#if[Object]?handle.fieldType.cast(value):value});
+                                     handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                     {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static void setOpaque(VarHandle ob, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             UNSAFE.put$Type$Opaque(handle.base,
-                                   handle.fieldOffset,
-                                   {#if[Object]?handle.fieldType.cast(value):value});
+                                   handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                   {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static void setRelease(VarHandle ob, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             UNSAFE.put$Type$Release(handle.base,
-                                    handle.fieldOffset,
-                                    {#if[Object]?handle.fieldType.cast(value):value});
+                                    handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                    {#if[Object]?checkCast(handle, value):value});
         }
 #if[CAS]
 
         @ForceInline
         static boolean compareAndSet(VarHandle ob, $type$ expected, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.compareAndSet$Type$(handle.base,
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
 
         @ForceInline
         static $type$ compareAndExchange(VarHandle ob, $type$ expected, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$(handle.base,
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ compareAndExchangeAcquire(VarHandle ob, $type$ expected, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$Acquire(handle.base,
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ compareAndExchangeRelease(VarHandle ob, $type$ expected, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.compareAndExchange$Type$Release(handle.base,
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static boolean weakCompareAndSetPlain(VarHandle ob, $type$ expected, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Plain(handle.base,
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static boolean weakCompareAndSet(VarHandle ob, $type$ expected, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$(handle.base,
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static boolean weakCompareAndSetAcquire(VarHandle ob, $type$ expected, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Acquire(handle.base,
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static boolean weakCompareAndSetRelease(VarHandle ob, $type$ expected, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.weakCompareAndSet$Type$Release(handle.base,
-                                               handle.fieldOffset,
-                                               {#if[Object]?handle.fieldType.cast(expected):expected},
-                                               {#if[Object]?handle.fieldType.cast(value):value});
+                                               handle.fieldOffset{#if[Object]?, handle.fieldType},
+                                               {#if[Object]?checkCast(handle, expected):expected},
+                                               {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ getAndSet(VarHandle ob, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndSet$Type$(handle.base,
-                                          handle.fieldOffset,
-                                          {#if[Object]?handle.fieldType.cast(value):value});
+                                          handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                          {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ getAndSetAcquire(VarHandle ob, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndSet$Type$Acquire(handle.base,
-                                          handle.fieldOffset,
-                                          {#if[Object]?handle.fieldType.cast(value):value});
+                                          handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                          {#if[Object]?checkCast(handle, value):value});
         }
 
         @ForceInline
         static $type$ getAndSetRelease(VarHandle ob, $type$ value) {
             FieldStaticReadWrite handle = (FieldStaticReadWrite)ob;
             return UNSAFE.getAndSet$Type$Release(handle.base,
-                                          handle.fieldOffset,
-                                          {#if[Object]?handle.fieldType.cast(value):value});
+                                          handle.fieldOffset{#if[Value]?, handle.fieldType},
+                                          {#if[Object]?checkCast(handle, value):value});
         }
 #end[CAS]
 #if[AtomicAdd]
 
         @ForceInline
@@ -658,10 +673,18 @@
 #end[Bitwise]
 
         static final VarForm FORM = new VarForm(FieldStaticReadWrite.class, null, $type$.class);
     }
 
+#if[Reference]
+    static VarHandle makeVarHandleValuesArray(Class<?> arrayClass) {
+        Class<?> componentType = arrayClass.getComponentType();
+        assert componentType.isInlineClass() && UNSAFE.isFlattenedArray(arrayClass);
+        // should cache these VarHandle for performance
+        return VarHandles.makeArrayElementHandle(arrayClass);
+    }
+#end[Reference]
 
     static final class Array extends VarHandle {
         final int abase;
         final int ashift;
 #if[Object]
@@ -694,10 +717,13 @@
         }
 
 #if[Object]
         @ForceInline
         static Object runtimeTypeCheck(Array handle, Object[] oarray, Object value) {
+            if (handle.componentType.isInlineClass())
+                 Objects.requireNonNull(value);
+
             if (handle.arrayType == oarray.getClass()) {
                 // Fast path: static array type same as argument array type
                 return handle.componentType.cast(value);
             } else {
                 // Slow path: check value against argument array component type
@@ -732,35 +758,58 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
-            array[index] = {#if[Object]?handle.componentType.cast(value):value};
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                vh.set(oarray, index, reflectiveTypeCheck(array, value));
+                return;
+            }
+#end[Reference]
+            array[index] = {#if[Object]?runtimeTypeCheck(handle, array, value):value};
         }
 
         @ForceInline
         static $type$ getVolatile(VarHandle ob, Object oarray, int index) {
             Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.getVolatile(oarray, index);
+            }
+#end[Reference]
             return UNSAFE.get$Type$Volatile(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase);
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType});
         }
 
         @ForceInline
         static void setVolatile(VarHandle ob, Object oarray, int index, $type$ value) {
             Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                vh.setVolatile(oarray, index, reflectiveTypeCheck(array, value));
+                return;
+            }
+#end[Reference]
             UNSAFE.put$Type$Volatile(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
         static $type$ getOpaque(VarHandle ob, Object oarray, int index) {
@@ -768,24 +817,39 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.getOpaque(oarray, index);
+            }
+#end[Reference]
             return UNSAFE.get$Type$Opaque(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase);
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType});
         }
 
         @ForceInline
         static void setOpaque(VarHandle ob, Object oarray, int index, $type$ value) {
             Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                vh.setOpaque(oarray, index, reflectiveTypeCheck(array, value));
+                return;
+            }
+#end[Reference]
             UNSAFE.put$Type$Opaque(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
         static $type$ getAcquire(VarHandle ob, Object oarray, int index) {
@@ -793,24 +857,39 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.getAcquire(oarray, index);
+            }
+#end[Reference]
             return UNSAFE.get$Type$Acquire(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase);
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType});
         }
 
         @ForceInline
         static void setRelease(VarHandle ob, Object oarray, int index, $type$ value) {
             Array handle = (Array)ob;
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                vh.setRelease(oarray, index, reflectiveTypeCheck(array, value));
+                return;
+            }
+#end[Reference]
             UNSAFE.put$Type$Release(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 #if[CAS]
 
         @ForceInline
@@ -819,12 +898,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.compareAndSet(oarray, index, expected, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.compareAndSet$Type$(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Object]?, handle.componentType},
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
@@ -833,12 +919,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.compareAndExchange(oarray, index, expected, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.compareAndExchange$Type$(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Object]?, handle.componentType},
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
@@ -847,12 +940,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.compareAndExchangeAcquire(oarray, index, expected, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.compareAndExchange$Type$Acquire(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Object]?, handle.componentType},
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
@@ -861,12 +961,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.compareAndExchangeRelease(oarray, index, expected, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.compareAndExchange$Type$Release(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Object]?, handle.componentType},
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
@@ -875,12 +982,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.weakCompareAndSetPlain(oarray, index, expected, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.weakCompareAndSet$Type$Plain(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Object]?, handle.componentType},
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
@@ -889,12 +1003,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.weakCompareAndSet(oarray, index, expected, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.weakCompareAndSet$Type$(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Object]?, handle.componentType},
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
@@ -903,12 +1024,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.weakCompareAndSetAcquire(oarray, index, expected, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.weakCompareAndSet$Type$Acquire(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Object]?, handle.componentType},
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
@@ -917,12 +1045,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.weakCompareAndSetRelease(oarray, index, expected, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.weakCompareAndSet$Type$Release(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Object]?, handle.componentType},
                     {#if[Object]?handle.componentType.cast(expected):expected},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
@@ -931,12 +1066,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.getAndSet(oarray, index, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.getAndSet$Type$(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
         static $type$ getAndSetAcquire(VarHandle ob, Object oarray, int index, $type$ value) {
@@ -944,12 +1086,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.getAndSetAcquire(oarray, index, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.getAndSet$Type$Acquire(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 
         @ForceInline
         static $type$ getAndSetRelease(VarHandle ob, Object oarray, int index, $type$ value) {
@@ -957,12 +1106,19 @@
 #if[Object]
             Object[] array = (Object[]) handle.arrayType.cast(oarray);
 #else[Object]
             $type$[] array = ($type$[]) oarray;
 #end[Object]
+#if[Reference]
+            if (UNSAFE.isFlattenedArray(oarray.getClass())) {
+                // for flattened array, delegate to VarHandle of the inline type array
+                VarHandle vh = makeVarHandleValuesArray(oarray.getClass());
+                return vh.getAndSetRelease(oarray, index, reflectiveTypeCheck(array, value));
+            }
+#end[Reference]
             return UNSAFE.getAndSet$Type$Release(array,
-                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase,
+                    (((long) Preconditions.checkIndex(index, array.length, AIOOBE_SUPPLIER)) << handle.ashift) + handle.abase{#if[Value]?, handle.componentType},
                     {#if[Object]?runtimeTypeCheck(handle, array, value):value});
         }
 #end[CAS]
 #if[AtomicAdd]
 
diff a/src/java.base/share/classes/module-info.java b/src/java.base/share/classes/module-info.java
--- a/src/java.base/share/classes/module-info.java
+++ b/src/java.base/share/classes/module-info.java
@@ -127,11 +127,10 @@
     exports javax.security.auth.login;
     exports javax.security.auth.spi;
     exports javax.security.auth.x500;
     exports javax.security.cert;
 
-
     // additional qualified exports may be inserted at build time
     // see make/gensrc/GenModuleInfo.gmk
 
     exports sun.invoke.util to
         jdk.compiler,
@@ -339,11 +338,10 @@
         java.logging,
         java.prefs;
     exports sun.util.resources to
         jdk.localedata;
 
-
     // the service types defined by the APIs in this module
 
     uses java.lang.System.LoggerFinder;
     uses java.net.ContentHandlerFactory;
     uses java.net.spi.URLStreamHandlerProvider;
diff a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
--- a/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
+++ b/src/jdk.compiler/share/classes/com/sun/tools/javac/comp/Check.java
@@ -93,10 +93,11 @@
     private final Source source;
     private final Target target;
     private final Profile profile;
     private final Preview preview;
     private final boolean warnOnAnyAccessToMembers;
+    private final boolean allowValueBasedClasses;
 
     // The set of lint options currently in effect. It is initialized
     // from the context, and then is set/reset as needed by Attr as it
     // visits all the various parts of the trees during attribution.
     private Lint lint;
@@ -133,11 +134,11 @@
         fileManager = context.get(JavaFileManager.class);
 
         source = Source.instance(context);
         target = Target.instance(context);
         warnOnAnyAccessToMembers = options.isSet("warnOnAccessToMembers");
-
+        allowValueBasedClasses = options.isSet("allowValueBasedClasses");
         Target target = Target.instance(context);
         syntheticNameChar = target.syntheticNameChar();
 
         profile = Profile.instance(context);
         preview = Preview.instance(context);
@@ -488,11 +489,11 @@
 
     public void removeCompiled(ClassSymbol csym) {
         compiled.remove(Pair.of(csym.packge().modle, csym.flatname));
     }
 
-/* *************************************************************************
+    /* *************************************************************************
  * Type Checking
  **************************************************************************/
 
     /**
      * A check context is an object that can be used to perform compatibility
@@ -594,16 +595,24 @@
     Type checkType(final DiagnosticPosition pos, final Type found, final Type req, final CheckContext checkContext) {
         final InferenceContext inferenceContext = checkContext.inferenceContext();
         if (inferenceContext.free(req) || inferenceContext.free(found)) {
             inferenceContext.addFreeTypeListener(List.of(req, found),
                     solvedContext -> checkType(pos, solvedContext.asInstType(found), solvedContext.asInstType(req), checkContext));
+        } else {
+            if (found.hasTag(CLASS)) {
+                if (inferenceContext != infer.emptyContext)
+                    checkParameterizationWithValues(pos, found);
+            }
         }
         if (req.hasTag(ERROR))
             return req;
         if (req.hasTag(NONE))
             return found;
         if (checkContext.compatible(found, req, checkContext.checkWarner(pos, found, req))) {
+            if (found.hasTag(BOT) && types.isValueBased(req)) {
+                log.warning(pos, Warnings.SuspiciousMixOfNullWithValueBasedClass(req));
+            }
             return found;
         } else {
             if (found.isNumeric() && req.isNumeric()) {
                 checkContext.report(pos, diags.fragment(Fragments.PossibleLossOfPrecision(found, req)));
                 return types.createErrorType(found);
@@ -622,10 +631,17 @@
     Type checkCastable(DiagnosticPosition pos, Type found, Type req) {
         return checkCastable(pos, found, req, basicHandler);
     }
     Type checkCastable(DiagnosticPosition pos, Type found, Type req, CheckContext checkContext) {
         if (types.isCastable(found, req, castWarner(pos, found, req))) {
+            if (types.isValueBased(req)) {
+                if (found.hasTag(BOT)) {
+                    log.warning(pos, Warnings.SuspiciousMixOfNullWithValueBasedClass(req));
+                } else if (!types.isValueBased(found)) {
+                    log.warning(pos, Warnings.PotentialNullPollution(found));
+                }
+            }
             return req;
         } else {
             checkContext.report(pos, diags.fragment(Fragments.InconvertibleTypes(found, req)));
             return types.createErrorType(found);
         }
@@ -724,10 +740,53 @@
             return (t.hasTag(TYPEVAR))
                                     ? diags.fragment(Fragments.TypeParameter(t))
                                     : t;
         }
 
+    void checkConstraintsOfInlineSuper(DiagnosticPosition pos, ClassSymbol c) {
+        for(Type st = types.supertype(c.type); st != Type.noType; st = types.supertype(st)) {
+            if (st == null || st.tsym == null || st.tsym.kind == ERR)
+                return;
+            if  (st.tsym == syms.objectType.tsym)
+                return;
+            if (!st.tsym.isAbstract()) {
+                log.error(pos, Errors.ConcreteSupertypeForInlineClass(c, st));
+            }
+            if ((st.tsym.flags() & HASINITBLOCK) != 0) {
+                log.error(pos, Errors.SuperClassDeclaresInitBlock(c, st));
+            }
+            // No instance fields and no arged constructors both mean inner classes cannot be inline supers.
+            Type encl = st.getEnclosingType();
+            if (encl != null && encl.hasTag(CLASS)) {
+                log.error(pos, Errors.SuperClassCannotBeInner(c, st));
+            }
+            for (Symbol s : st.tsym.members().getSymbols(NON_RECURSIVE)) {
+                switch (s.kind) {
+                case VAR:
+                    if ((s.flags() & STATIC) == 0) {
+                        log.error(pos, Errors.SuperFieldNotAllowed(s, c, st));
+                    }
+                    break;
+                case MTH:
+                    if ((s.flags() & SYNCHRONIZED) != 0) {
+                        log.error(pos, Errors.SuperMethodCannotBeSynchronized(s, c, st));
+                    } else if (s.isConstructor()) {
+                        MethodSymbol m = (MethodSymbol)s;
+                        if (m.getParameters().size() > 0) {
+                            log.error(pos, Errors.SuperConstructorCannotTakeArguments(m, c, st));
+                        } else {
+                            if ((m.flags() & (GENERATEDCONSTR | EMPTYNOARGCONSTR)) == 0) {
+                                log.error(pos, Errors.SuperNoArgConstructorMustBeEmpty(m, c, st));
+                            }
+                        }
+                    }
+                    break;
+                }
+            }
+        }
+    }
+
     /** Check that type is a valid qualifier for a constructor reference expression
      */
     Type checkConstructorRefType(DiagnosticPosition pos, Type t) {
         t = checkClassOrArrayType(pos, t);
         if (t.hasTag(CLASS)) {
@@ -771,29 +830,39 @@
 
     /** Check that type is a reference type, i.e. a class, interface or array type
      *  or a type variable.
      *  @param pos           Position to be used for error reporting.
      *  @param t             The type to be checked.
+     *  @param valueOK       If false, a value class does not qualify
      */
-    Type checkRefType(DiagnosticPosition pos, Type t) {
-        if (t.isReference())
+    Type checkRefType(DiagnosticPosition pos, Type t, boolean valueOK) {
+        if (t.isReference() && (valueOK || !types.isValue(t)))
             return t;
         else
             return typeTagError(pos,
                                 diags.fragment(Fragments.TypeReqRef),
                                 t);
     }
 
+    /** Check that type is a reference type, i.e. a class, interface or array type
+     *  or a type variable.
+     *  @param pos           Position to be used for error reporting.
+     *  @param t             The type to be checked.
+     */
+    Type checkRefType(DiagnosticPosition pos, Type t) {
+        return checkRefType(pos, t, true);
+    }
+
     /** Check that each type is a reference type, i.e. a class, interface or array type
      *  or a type variable.
      *  @param trees         Original trees, used for error reporting.
      *  @param types         The types to be checked.
      */
     List<Type> checkRefTypes(List<JCExpression> trees, List<Type> types) {
         List<JCExpression> tl = trees;
         for (List<Type> l = types; l.nonEmpty(); l = l.tail) {
-            l.head = checkRefType(tl.head.pos(), l.head);
+            l.head = checkRefType(tl.head.pos(), l.head, false);
             tl = tl.tail;
         }
         return types;
     }
 
@@ -825,10 +894,58 @@
             return false;
         } else
             return true;
     }
 
+    void checkParameterizationWithValues(DiagnosticPosition pos, Type t) {
+        valueParameterizationChecker.visit(t, pos);
+    }
+
+    /** valueParameterizationChecker: A type visitor that descends down the given type looking for instances of value types
+     *  being used as type arguments and issues error against those usages.
+     */
+    private final Types.SimpleVisitor<Void, DiagnosticPosition> valueParameterizationChecker = new Types.SimpleVisitor<Void, DiagnosticPosition>() {
+
+        @Override
+        public Void visitType(Type t, DiagnosticPosition pos) {
+            return null;
+        }
+
+        @Override
+        public Void visitClassType(ClassType t, DiagnosticPosition pos) {
+            for (Type targ : t.allparams()) {
+                if (types.isValue(targ)) {
+                    log.error(pos, Errors.GenericParameterizationWithValueType(t));
+                }
+                visit(targ, pos);
+            }
+            return null;
+        }
+
+        @Override
+        public Void visitTypeVar(TypeVar t, DiagnosticPosition pos) {
+             return null;
+        }
+
+        @Override
+        public Void visitCapturedType(CapturedType t, DiagnosticPosition pos) {
+            return null;
+        }
+
+        @Override
+        public Void visitArrayType(ArrayType t, DiagnosticPosition pos) {
+            return visit(t.elemtype, pos);
+        }
+
+        @Override
+        public Void visitWildcardType(WildcardType t, DiagnosticPosition pos) {
+            return visit(t.type, pos);
+        }
+    };
+
+
+
     /** Check that usage of diamond operator is correct (i.e. diamond should not
      * be used with non-generic classes or in anonymous class creation expressions)
      */
     Type checkDiamond(JCNewClass tree, Type t) {
         if (!TreeInfo.isDiamond(tree) ||
@@ -973,11 +1090,48 @@
             log.error(pos, Errors.CantInferLocalVarType(name, Fragments.LocalCantInferVoid));
             return types.createErrorType(t);
         }
 
         //upward project the initializer type
-        return types.upward(t, types.captures(t));
+        Type varType = types.upward(t, types.captures(t));
+        if (varType.hasTag(CLASS)) {
+            checkParameterizationWithValues(pos, varType);
+        }
+        return varType;
+    }
+
+    public void checkForSuspectClassLiteralComparison(
+            final JCBinary tree,
+            final Type leftType,
+            final Type rightType) {
+
+        if (lint.isEnabled(LintCategory.MIGRATION)) {
+            if (isInvocationOfGetClass(tree.lhs) && isClassOfSomeInterface(rightType) ||
+                    isInvocationOfGetClass(tree.rhs) && isClassOfSomeInterface(leftType)) {
+                log.warning(LintCategory.MIGRATION, tree.pos(), Warnings.GetClassComparedWithInterface);
+            }
+        }
+    }
+    //where
+    private boolean isClassOfSomeInterface(Type someClass) {
+        if (someClass.tsym.flatName() == names.java_lang_Class) {
+            List<Type> arguments = someClass.getTypeArguments();
+            if (arguments.length() == 1) {
+                return arguments.head.isInterface();
+            }
+        }
+        return false;
+    }
+    //where
+    private boolean isInvocationOfGetClass(JCExpression tree) {
+        tree = TreeInfo.skipParens(tree);
+        if (tree.hasTag(APPLY)) {
+            JCMethodInvocation apply = (JCMethodInvocation)tree;
+            MethodSymbol msym = (MethodSymbol)TreeInfo.symbol(apply.meth);
+            return msym.name == names.getClass && msym.implementedIn(syms.objectType.tsym, types) != null;
+        }
+        return false;
     }
 
     Type checkMethod(final Type mtype,
             final Symbol sym,
             final Env<AttrContext> env,
@@ -1171,12 +1325,16 @@
                 mask = ReceiverParamFlags;
             else if (sym.owner.kind != TYP)
                 mask = LocalVarFlags;
             else if ((sym.owner.flags_field & INTERFACE) != 0)
                 mask = implicit = InterfaceVarFlags;
-            else
+            else {
                 mask = VarFlags;
+                if (types.isValue(sym.owner.type) && (flags & STATIC) == 0) {
+                    implicit |= FINAL;
+                }
+            }
             break;
         case MTH:
             if (sym.name == names.init) {
                 if ((sym.owner.flags_field & ENUM) != 0) {
                     // enum constructors cannot be declared public or
@@ -1200,11 +1358,13 @@
                     mask = implicit = InterfaceMethodFlags;
                 }
             } else if ((sym.owner.flags_field & RECORD) != 0) {
                 mask = RecordMethodFlags;
             } else {
-                mask = MethodFlags;
+                // instance methods of value types do not have a monitor associated with their `this'
+                mask = ((sym.owner.flags_field & VALUE) != 0 && (flags & Flags.STATIC) == 0) ?
+                        MethodFlags & ~SYNCHRONIZED : MethodFlags;
             }
             // Imply STRICTFP if owner has STRICTFP set.
             if (((flags|implicit) & Flags.ABSTRACT) == 0 ||
                 ((flags) & Flags.DEFAULT) != 0)
                 implicit |= sym.owner.flags_field & STRICTFP;
@@ -1236,12 +1396,12 @@
             }
             // Interfaces are always ABSTRACT
             if ((flags & INTERFACE) != 0) implicit |= ABSTRACT;
 
             if ((flags & ENUM) != 0) {
-                // enums can't be declared abstract or final
-                mask &= ~(ABSTRACT | FINAL);
+                // enums can't be declared abstract or final or value type
+                mask &= ~(ABSTRACT | FINAL | VALUE);
                 implicit |= implicitEnumFinalFlag(tree);
             }
             if ((flags & RECORD) != 0) {
                 // records can't be declared abstract
                 mask &= ~ABSTRACT;
@@ -1275,21 +1435,21 @@
                                 STATIC | PRIVATE,
                                 DEFAULT)
                  &&
                  checkDisjoint(pos, flags,
                                ABSTRACT | INTERFACE,
-                               FINAL | NATIVE | SYNCHRONIZED)
+                               FINAL | NATIVE | SYNCHRONIZED | VALUE)
                  &&
                  checkDisjoint(pos, flags,
                                PUBLIC,
                                PRIVATE | PROTECTED)
                  &&
                  checkDisjoint(pos, flags,
                                PRIVATE,
                                PUBLIC | PROTECTED)
                  &&
-                 checkDisjoint(pos, flags,
+                 checkDisjoint(pos, (flags | implicit), // complain against volatile & implcitly final entities too.
                                FINAL,
                                VOLATILE)
                  &&
                  (sym.kind == TYP ||
                   checkDisjoint(pos, flags,
@@ -1453,14 +1613,17 @@
             }
         }
 
         public void visitSelectInternal(JCFieldAccess tree) {
             if (tree.type.tsym.isStatic() &&
-                tree.selected.type.isParameterized()) {
+                tree.selected.type.isParameterized() &&
+                    (tree.name != names.ref || !tree.type.isReferenceProjection())) {
                 // The enclosing type is not a class, so we are
                 // looking at a static member type.  However, the
                 // qualifying expression is parameterized.
+                // Tolerate the pseudo-select V.ref: V<T>.ref will be static if V<T> is and
+                // should not be confused as selecting a static member of a parameterized type.
                 log.error(tree.pos(), Errors.CantSelectStaticClassFromParamType);
             } else {
                 // otherwise validate the rest of the expression
                 tree.selected.accept(this);
             }
@@ -1783,10 +1946,19 @@
                                                           asFlagSet(other.flags() & AccessFlags)));
             m.flags_field |= BAD_OVERRIDE;
             return;
         }
 
+        if (origin.isValue() && other.owner == syms.objectType.tsym && m.type.getParameterTypes().size() == 0) {
+            if (m.name == names.clone || m.name == names.finalize) {
+                log.error(TreeInfo.diagnosticPositionFor(m, tree),
+                        Errors.InlineClassMayNotOverride(m.name));
+                m.flags_field |= BAD_OVERRIDE;
+                return;
+            }
+        }
+
         Type mt = types.memberType(origin.type, m);
         Type ot = types.memberType(origin.type, other);
         // Error if overriding result type is different
         // (or, in the case of generics mode, not a subtype) of
         // overridden result type. We have to rename any type parameters
@@ -2095,11 +2267,12 @@
         final boolean explicitOverride = m.attribute(syms.overrideType.tsym) != null;
         // Check if this method must override a super method due to being annotated with @Override
         // or by virtue of being a member of a diamond inferred anonymous class. Latter case is to
         // be treated "as if as they were annotated" with @Override.
         boolean mustOverride = explicitOverride ||
-                (env.info.isAnonymousDiamond && !m.isConstructor() && !m.isPrivate());
+                (env.info.isAnonymousDiamond && !m.isConstructor() && !m.isPrivate() &&
+                        (!m.owner.isValue() || (tree.body.flags & SYNTHETIC) == 0));
         if (mustOverride && !isOverrider(m)) {
             DiagnosticPosition pos = tree.pos();
             for (JCAnnotation a : tree.getModifiers().annotations) {
                 if (a.annotationType.type.tsym == syms.overrideType.tsym) {
                     pos = a.pos();
@@ -2221,10 +2394,49 @@
             log.error(pos,
                       Errors.DoesNotOverrideAbstract(c, undef1, undef1.location()));
         }
     }
 
+    // A value class cannot contain a field of its own type either or indirectly.
+    void checkNonCyclicMembership(JCClassDecl tree) {
+        Assert.check((tree.sym.flags_field & LOCKED) == 0);
+        try {
+            tree.sym.flags_field |= LOCKED;
+            for (List<? extends JCTree> l = tree.defs; l.nonEmpty(); l = l.tail) {
+                if (l.head.hasTag(VARDEF)) {
+                    JCVariableDecl field = (JCVariableDecl) l.head;
+                    if (cyclePossible(field.sym)) {
+                        Type fieldType = field.sym.type;
+                        checkNonCyclicMembership((ClassSymbol) fieldType.tsym, field.pos());
+                    }
+                }
+            }
+        } finally {
+            tree.sym.flags_field &= ~LOCKED;
+        }
+
+    }
+    // where
+    private void checkNonCyclicMembership(ClassSymbol c, DiagnosticPosition pos) {
+        if ((c.flags_field & LOCKED) != 0) {
+            log.error(pos, Errors.CyclicValueTypeMembership(c));
+            return;
+        }
+        try {
+            c.flags_field |= LOCKED;
+            for (Symbol fld : c.members().getSymbols(s -> s.kind == VAR && cyclePossible((VarSymbol) s), NON_RECURSIVE)) {
+                checkNonCyclicMembership((ClassSymbol) fld.type.tsym, pos);
+            }
+        } finally {
+            c.flags_field &= ~LOCKED;
+        }
+    }
+        // where
+        private boolean cyclePossible(VarSymbol symbol) {
+            return (symbol.flags() & STATIC) == 0 && types.isValue(symbol.type);
+        }
+
     void checkNonCyclicDecl(JCClassDecl tree) {
         CycleChecker cc = new CycleChecker();
         cc.scan(tree);
         if (!cc.errorFound && !cc.partialCheck) {
             tree.sym.flags_field |= ACYCLIC;
@@ -2469,10 +2681,14 @@
             for (List<Type> m = supertypes; m != l; m = m.tail)
                 if (!checkCompatibleAbstracts(pos, l.head, m.head, c))
                     return;
         }
         checkCompatibleConcretes(pos, c);
+
+        if (c.isValue() && types.asSuper(c, syms.identityObjectType.tsym, true) != null) {
+            log.error(pos, Errors.InlineTypeMustNotImplementIdentityObject(c));
+        }
     }
 
     /** Check that all non-override equivalent methods accessible from 'site'
      *  are mutually compatible (JLS 8.4.8/9.4.1).
      *
@@ -3028,10 +3244,17 @@
                 log.error(a.pos(), Errors.BadFunctionalIntfAnno);
             } else if (!s.isInterface() || (s.flags() & ANNOTATION) != 0) {
                 log.error(a.pos(), Errors.BadFunctionalIntfAnno1(Fragments.NotAFunctionalIntf(s)));
             }
         }
+        if (a.annotationType.type.tsym == syms.valueBasedType.tsym) {
+            if (s.isInterface() || s.isEnum()) {
+                log.error(a.pos(), Errors.BadValueBasedAnno);
+            } else if (allowValueBasedClasses) {
+                s.flags_field |= VALUEBASED;
+            }
+        }
     }
 
     public void validateTypeAnnotation(JCAnnotation a, boolean isTypeParameter) {
         Assert.checkNonNull(a.type);
         validateAnnotationTree(a);
diff a/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotVMConfig.java b/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotVMConfig.java
--- a/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotVMConfig.java
+++ b/src/jdk.internal.vm.ci/share/classes/jdk.vm.ci.hotspot/src/jdk/vm/ci/hotspot/HotSpotVMConfig.java
@@ -96,11 +96,11 @@
 
     final int instanceKlassInitStateOffset = getFieldOffset("InstanceKlass::_init_state", Integer.class, "u1");
     final int instanceKlassConstantsOffset = getFieldOffset("InstanceKlass::_constants", Integer.class, "ConstantPool*");
     final int instanceKlassFieldsOffset = getFieldOffset("InstanceKlass::_fields", Integer.class, "Array<u2>*");
     final int instanceKlassAnnotationsOffset = getFieldOffset("InstanceKlass::_annotations", Integer.class, "Annotations*");
-    final int instanceKlassMiscFlagsOffset = getFieldOffset("InstanceKlass::_misc_flags", Integer.class, "u2");
+    final int instanceKlassMiscFlagsOffset = getFieldOffset("InstanceKlass::_misc_flags", Integer.class, "u4");
     final int klassVtableStartOffset = getFieldValue("CompilerToVM::Data::Klass_vtable_start_offset", Integer.class, "int");
     final int klassVtableLengthOffset = getFieldValue("CompilerToVM::Data::Klass_vtable_length_offset", Integer.class, "int");
 
     final int instanceKlassStateLinked = getConstant("InstanceKlass::linked", Integer.class);
     final int instanceKlassStateFullyInitialized = getConstant("InstanceKlass::fully_initialized", Integer.class);
@@ -306,10 +306,11 @@
     final int dataLayoutArgInfoDataTag = getConstant("DataLayout::arg_info_data_tag", Integer.class);
     final int dataLayoutCallTypeDataTag = getConstant("DataLayout::call_type_data_tag", Integer.class);
     final int dataLayoutVirtualCallTypeDataTag = getConstant("DataLayout::virtual_call_type_data_tag", Integer.class);
     final int dataLayoutParametersTypeDataTag = getConstant("DataLayout::parameters_type_data_tag", Integer.class);
     final int dataLayoutSpeculativeTrapDataTag = getConstant("DataLayout::speculative_trap_data_tag", Integer.class);
+    final int dataLayoutArrayLoadStoreDataTag = getConstant("DataLayout::array_load_store_data_tag", Integer.class);
 
     final int bciProfileWidth = getFlag("BciProfileWidth", Integer.class);
     final int typeProfileWidth = getFlag("TypeProfileWidth", Integer.class);
     final int methodProfileWidth = getFlag("MethodProfileWidth", Integer.class, 0);
 
diff a/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.test/src/org/graalvm/compiler/hotspot/test/CheckGraalIntrinsics.java b/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.test/src/org/graalvm/compiler/hotspot/test/CheckGraalIntrinsics.java
--- a/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.test/src/org/graalvm/compiler/hotspot/test/CheckGraalIntrinsics.java
+++ b/src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.hotspot.test/src/org/graalvm/compiler/hotspot/test/CheckGraalIntrinsics.java
@@ -410,12 +410,18 @@
 
         if (isJDK14OrHigher()) {
             add(toBeInvestigated,
                             "com/sun/crypto/provider/ElectronicCodeBook.implECBDecrypt([BII[BI)I",
                             "com/sun/crypto/provider/ElectronicCodeBook.implECBEncrypt([BII[BI)I",
+                            "java/lang/Class.asIndirectType()Ljava/lang/Class;",
+                            "java/lang/Class.asPrimaryType()Ljava/lang/Class;",
                             "java/math/BigInteger.shiftLeftImplWorker([I[IIII)V",
-                            "java/math/BigInteger.shiftRightImplWorker([I[IIII)V");
+                            "java/math/BigInteger.shiftRightImplWorker([I[IIII)V",
+                            "jdk/internal/misc/Unsafe.finishPrivateBuffer(Ljava/lang/Object;)Ljava/lang/Object;",
+                            "jdk/internal/misc/Unsafe.getValue(Ljava/lang/Object;JLjava/lang/Class;)Ljava/lang/Object;",
+                            "jdk/internal/misc/Unsafe.makePrivateBuffer(Ljava/lang/Object;)Ljava/lang/Object;",
+                            "jdk/internal/misc/Unsafe.putValue(Ljava/lang/Object;JLjava/lang/Class;Ljava/lang/Object;)V");
         }
 
         if (!config.inlineNotify()) {
             add(ignore, "java/lang/Object.notify()V");
         }
diff a/test/hotspot/jtreg/ProblemList.txt b/test/hotspot/jtreg/ProblemList.txt
--- a/test/hotspot/jtreg/ProblemList.txt
+++ b/test/hotspot/jtreg/ProblemList.txt
@@ -66,10 +66,87 @@
 compiler/rtm/locking/TestRTMSpinLoopCount.java 8183263 generic-x64
 compiler/rtm/locking/TestUseRTMDeopt.java 8183263 generic-x64
 compiler/rtm/locking/TestUseRTMXendForLockBusy.java 8183263 generic-x64
 compiler/rtm/print/TestPrintPreciseRTMLockingStatistics.java 8183263 generic-x64
 
+# Valhalla
+compiler/arguments/CheckCICompilerCount.java                        8205030 generic-all
+compiler/arguments/CheckCompileThresholdScaling.java                8205030 generic-all
+compiler/codecache/CheckSegmentedCodeCache.java                     8205030 generic-all
+compiler/codecache/cli/TestSegmentedCodeCacheOption.java            8205030 generic-all
+compiler/codecache/cli/codeheapsize/TestCodeHeapSizeOptions.java    8205030 generic-all
+compiler/codecache/cli/printcodecache/TestPrintCodeCacheOption.java 8205030 generic-all
+compiler/whitebox/OSRFailureLevel4Test.java                         8205030 generic-all
+
+compiler/aot/cli/DisabledAOTWithLibraryTest.java 8226295 generic-all
+compiler/aot/cli/SingleAOTOptionTest.java 8226295 generic-all
+compiler/aot/cli/MultipleAOTLibraryTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/CompileClassWithDebugTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/CompileModuleTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/AtFileTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/ListOptionWrongFileTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/ClasspathOptionUnknownClassTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/CompileDirectoryTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/ListOptionTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/ListOptionNotExistingTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/CompileClassTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/CompileJarTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/IgnoreErrorsTest.java 8226295 generic-all
+compiler/aot/cli/jaotc/CompileAbsoluteDirectoryTest.java 8226295 generic-all
+compiler/aot/cli/NonExistingAOTLibraryTest.java 8226295 generic-all
+compiler/aot/cli/SingleAOTLibraryTest.java 8226295 generic-all
+compiler/aot/cli/IncorrectAOTLibraryTest.java 8226295 generic-all
+compiler/aot/RecompilationTest.java 8226295 generic-all
+compiler/aot/SharedUsageTest.java 8226295 generic-all
+compiler/aot/jdk.tools.jaotc.test/src/jdk/tools/jaotc/test/collect/ClassSearchTest.java 8226295 generic-all
+compiler/aot/jdk.tools.jaotc.test/src/jdk/tools/jaotc/test/collect/SearchPathTest.java 8226295 generic-all
+compiler/aot/jdk.tools.jaotc.test/src/jdk/tools/jaotc/test/collect/module/ModuleSourceProviderTest.java 8226295 generic-all
+compiler/aot/jdk.tools.jaotc.test/src/jdk/tools/jaotc/test/collect/ClassSourceTest.java 8226295 generic-all
+compiler/aot/jdk.tools.jaotc.test/src/jdk/tools/jaotc/test/collect/directory/DirectorySourceProviderTest.java 8226295 generic-all
+compiler/aot/jdk.tools.jaotc.test/src/jdk/tools/jaotc/test/collect/jar/JarSourceProviderTest.java 8226295 generic-all
+compiler/aot/jdk.tools.jaotc.test/src/jdk/tools/jaotc/test/NativeOrderOutputStreamTest.java 8226295 generic-all
+compiler/aot/verification/vmflags/TrackedFlagTest.java 8226295 generic-all
+compiler/aot/verification/vmflags/NotTrackedFlagTest.java 8226295 generic-all
+compiler/aot/verification/ClassAndLibraryNotMatchTest.java 8226295 generic-all
+compiler/aot/DeoptimizationTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeVirtual2NativeTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeStatic2CompiledTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeSpecial2CompiledTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeVirtual2CompiledTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeVirtual2InterpretedTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeDynamic2NativeTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeDynamic2InterpretedTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeStatic2InterpretedTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeInterface2InterpretedTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeVirtual2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeInterface2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeSpecial2NativeTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeDynamic2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeInterface2NativeTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeStatic2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeInterface2CompiledTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeDynamic2CompiledTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeStatic2NativeTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeSpecial2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromAot/AotInvokeSpecial2InterpretedTest.java 8226295 generic-all
+compiler/aot/calls/fromNative/NativeInvokeStatic2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromNative/NativeInvokeSpecial2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromNative/NativeInvokeVirtual2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromCompiled/CompiledInvokeInterface2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromCompiled/CompiledInvokeVirtual2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromCompiled/CompiledInvokeDynamic2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromCompiled/CompiledInvokeStatic2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromCompiled/CompiledInvokeSpecial2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromInterpreted/InterpretedInvokeDynamic2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromInterpreted/InterpretedInvokeStatic2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromInterpreted/InterpretedInvokeVirtual2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromInterpreted/InterpretedInvokeSpecial2AotTest.java 8226295 generic-all
+compiler/aot/calls/fromInterpreted/InterpretedInvokeInterface2AotTest.java 8226295 generic-all
+compiler/aot/fingerprint/SelfChanged.java 8226295 generic-all
+compiler/aot/fingerprint/SelfChangedCDS.java 8226295 generic-all
+compiler/aot/fingerprint/SuperChanged.java 8226295 generic-all
+
 compiler/c2/Test8004741.java 8235801 generic-all
 
 compiler/jsr292/CreatesInterfaceDotEqualsCallInfo.java 8242923 generic-all
 
 #############################################################################
@@ -91,10 +168,32 @@
 # :hotspot_runtime
 
 runtime/jni/terminatedThread/TestTerminatedThread.java 8219652 aix-ppc64
 runtime/ReservedStack/ReservedStackTest.java 8231031 generic-all
 
+# Valhalla TODO:
+runtime/CompressedOops/CompressedClassPointers.java 8210258 generic-all
+runtime/RedefineTests/RedefineLeak.java 8205032 generic-all
+runtime/SharedArchiveFile/BootAppendTests.java 8210258 generic-all
+runtime/SharedArchiveFile/CdsDifferentCompactStrings.java 8210258 generic-all
+runtime/SharedArchiveFile/CdsDifferentObjectAlignment.java 8210258 generic-all
+runtime/SharedArchiveFile/NonBootLoaderClasses.java 8210258 generic-all
+runtime/SharedArchiveFile/PrintSharedArchiveAndExit.java 8210258 generic-all
+runtime/SharedArchiveFile/SharedArchiveFile.java 8210258 generic-all
+runtime/SharedArchiveFile/SharedStringsDedup.java 8210258 generic-all
+runtime/SharedArchiveFile/SharedStringsRunAuto.java 8210258 generic-all
+runtime/SharedArchiveFile/SharedSymbolTableBucketSize.java 8210258 generic-all
+runtime/SharedArchiveFile/SpaceUtilizationCheck.java 8210258 generic-all
+runtime/SharedArchiveFile/TestInterpreterMethodEntries.java 8210258 generic-all
+runtime/SharedArchiveFile/serviceability/transformRelatedClasses/TransformInterfaceAndImplementor.java 8210258 generic-all
+runtime/SharedArchiveFile/serviceability/transformRelatedClasses/TransformSuperAndSubClasses.java 8210258 generic-all
+runtime/SharedArchiveFile/serviceability/transformRelatedClasses/TransformSuperSubTwoPckgs.java 8210258 generic-all
+runtime/appcds/ClassLoaderTest.java 8210258 generic-all
+runtime/appcds/HelloTest.java 8210258 generic-all
+runtime/appcds/sharedStrings/SharedStringsBasic.java 8210258 generic-all
+
+
 #############################################################################
 
 # :hotspot_serviceability
 
 serviceability/sa/sadebugd/DebugdConnectTest.java 8239062 macosx-x64
@@ -102,10 +201,36 @@
 serviceability/sa/TestInstanceKlassSizeForInterface.java 8230664 linux-ppc64le,linux-ppc64
 serviceability/sa/TestRevPtrsForInvokeDynamic.java 8241235 generic-all
 
 serviceability/jvmti/HeapMonitor/MyPackage/HeapMonitorStatIntervalTest.java 8214032 generic-all
 serviceability/jvmti/HeapMonitor/MyPackage/HeapMonitorStatArrayCorrectnessTest.java 8224150 generic-all
+
+# Valhalla TODO:
+serviceability/sa/ClhsdbCDSCore.java 8190936 generic-all
+serviceability/sa/ClhsdbCDSJstackPrintAll.java 8190936 generic-all
+serviceability/sa/ClhsdbFindPC.java 8190936 generic-all
+serviceability/sa/ClhsdbInspect.java 8190936 generic-all
+serviceability/sa/ClhsdbJdis.java 8190936 generic-all
+serviceability/sa/ClhsdbJstack.java 8190936 generic-all
+serviceability/sa/ClhsdbPrintAll.java 8190936 generic-all
+serviceability/sa/ClhsdbPrintAs.java 8190936 generic-all
+serviceability/sa/ClhsdbPrintStatics.java 8190936 generic-all
+serviceability/sa/ClhsdbSource.java 8190936 generic-all
+serviceability/sa/ClhsdbSymbol.java 8190936 generic-all
+serviceability/sa/ClhsdbWhere.java 8190936 generic-all
+serviceability/sa/JhsdbThreadInfoTest.java 8190936 generic-all
+serviceability/sa/TestClassDump.java 8190936 generic-all
+serviceability/sa/TestClhsdbJstackLock.java 8190936 generic-all
+serviceability/sa/TestCpoolForInvokeDynamic.java 8190936 generic-all
+serviceability/sa/TestHeapDumpForInvokeDynamic.java 8190936 generic-all
+serviceability/sa/TestHeapDumpForLargeArray.java 8190936 generic-all
+serviceability/sa/TestIntConstant.java 8190936 generic-all
+serviceability/sa/TestJhsdbJstackLock.java 8190936 generic-all
+serviceability/sa/TestJmapCore.java 8190936 generic-all
+serviceability/sa/TestJmapCoreMetaspace.java 8190936 generic-all
+serviceability/sa/TestPrintMdo.java 8190936 generic-all
+serviceability/sa/jmap-hprof/JMapHProfLargeHeapTest.java 8190936 generic-all
 
 #############################################################################
 
 # :hotspot_misc
 
diff a/test/jdk/TEST.groups b/test/jdk/TEST.groups
--- a/test/jdk/TEST.groups
+++ b/test/jdk/TEST.groups
@@ -101,11 +101,18 @@
     jdk/internal/loader \
     jdk/internal/misc \
     jdk/internal/ref \
     jdk/internal/jimage \
     jdk/internal/math \
-    jdk/modules
+    jdk/modules \
+    valhalla
+
+# valhalla lworld tests
+jdk_valhalla = \
+    java/lang/invoke \
+    valhalla \
+    com/sun/jdi/JdbInlineTypesTest.java
 
 # All of the java.util package
 jdk_util = \
     :jdk_util_other \
     :jdk_collections \
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeBoolean.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeBoolean.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeBoolean.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeBoolean.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeBoolean
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeBoolean
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeByte.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeByte.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeByte.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeByte.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeByte
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeByte
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeChar.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeChar.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeChar.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeChar.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeChar
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeChar
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeDouble.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeDouble.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeDouble.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeDouble.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeDouble
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeDouble
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeFloat.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeFloat.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeFloat.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeFloat.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeFloat
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeFloat
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeInt.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeInt.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeInt.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeInt.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeInt
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeInt
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeLong.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeLong.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeLong.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeLong.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeLong
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeLong
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeShort.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeShort.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeShort.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeShort.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeShort
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeShort
diff a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeString.java b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeString.java
--- a/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeString.java
+++ b/test/jdk/java/lang/invoke/VarHandles/VarHandleTestMethodTypeString.java
@@ -19,10 +19,12 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+// -- This file was mechanically generated: Do not edit! -- //
+
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodTypeString
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodTypeString
diff a/test/jdk/java/lang/invoke/VarHandles/X-VarHandleTestMethodType.java.template b/test/jdk/java/lang/invoke/VarHandles/X-VarHandleTestMethodType.java.template
--- a/test/jdk/java/lang/invoke/VarHandles/X-VarHandleTestMethodType.java.template
+++ b/test/jdk/java/lang/invoke/VarHandles/X-VarHandleTestMethodType.java.template
@@ -19,18 +19,29 @@
  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  * or visit www.oracle.com if you need additional information or have any
  * questions.
  */
 
+#warn
+
+#if[Value]
+/*
+ * @test
+ * @bug 8156486
+ * @run testng/othervm VarHandleTestMethodType$Type$
+ * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false VarHandleTestMethodType$Type$
+ */
+#else[Value]
 /*
  * @test
  * @bug 8156486
  * @run testng/othervm VarHandleTestMethodType$Type$
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=true -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodType$Type$
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=false VarHandleTestMethodType$Type$
  * @run testng/othervm -Djava.lang.invoke.VarHandle.VAR_HANDLE_GUARDS=false -Djava.lang.invoke.VarHandle.VAR_HANDLE_IDENTITY_ADAPT=true VarHandleTestMethodType$Type$
  */
+#end[Value]
 
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.DataProvider;
 import org.testng.annotations.Test;
 
@@ -136,11 +147,11 @@
         });
         checkWMTE(() -> { // receiver primitive class
             $type$ x = ($type$) vh.get(0);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.get(recv);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.get(recv);
         });
@@ -159,11 +170,11 @@
             vh.set(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             vh.set(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.set(recv, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             vh.set(0, $value1$);
         });
@@ -186,11 +197,11 @@
         });
         checkWMTE(() -> { // receiver primitive class
             $type$ x = ($type$) vh.getVolatile(0);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getVolatile(recv);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getVolatile(recv);
         });
@@ -209,11 +220,11 @@
             vh.setVolatile(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             vh.setVolatile(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setVolatile(recv, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             vh.setVolatile(0, $value1$);
         });
@@ -236,11 +247,11 @@
         });
         checkWMTE(() -> { // receiver primitive class
             $type$ x = ($type$) vh.getOpaque(0);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getOpaque(recv);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getOpaque(recv);
         });
@@ -259,11 +270,11 @@
             vh.setOpaque(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             vh.setOpaque(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setOpaque(recv, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             vh.setOpaque(0, $value1$);
         });
@@ -286,11 +297,11 @@
         });
         checkWMTE(() -> { // receiver primitive class
             $type$ x = ($type$) vh.getAcquire(0);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getAcquire(recv);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAcquire(recv);
         });
@@ -309,11 +320,11 @@
             vh.setRelease(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             vh.setRelease(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setRelease(recv, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             vh.setRelease(0, $value1$);
         });
@@ -333,14 +344,14 @@
             boolean r = vh.compareAndSet(null, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.compareAndSet(Void.class, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.compareAndSet(recv, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.compareAndSet(recv, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.compareAndSet(0, $value1$, $value1$);
         });
@@ -359,14 +370,14 @@
             boolean r = vh.weakCompareAndSetPlain(null, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.weakCompareAndSetPlain(Void.class, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetPlain(recv, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetPlain(recv, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.weakCompareAndSetPlain(0, $value1$, $value1$);
         });
@@ -385,14 +396,14 @@
             boolean r = vh.weakCompareAndSet(null, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.weakCompareAndSet(Void.class, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSet(recv, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSet(recv, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.weakCompareAndSet(0, $value1$, $value1$);
         });
@@ -411,14 +422,14 @@
             boolean r = vh.weakCompareAndSetAcquire(null, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.weakCompareAndSetAcquire(Void.class, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetAcquire(recv, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetAcquire(recv, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.weakCompareAndSetAcquire(0, $value1$, $value1$);
         });
@@ -437,14 +448,14 @@
             boolean r = vh.weakCompareAndSetRelease(null, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.weakCompareAndSetRelease(Void.class, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetRelease(recv, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetRelease(recv, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.weakCompareAndSetRelease(0, $value1$, $value1$);
         });
@@ -463,21 +474,21 @@
             $type$ x = ($type$) vh.compareAndExchange(null, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.compareAndExchange(Void.class, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchange(recv, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchange(recv, $value1$, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.compareAndExchange(0, $value1$, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchange(recv, $value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchange(recv, $value1$, $value1$);
         });
@@ -496,21 +507,21 @@
             $type$ x = ($type$) vh.compareAndExchangeAcquire(null, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(Void.class, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(recv, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(recv, $value1$, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(0, $value1$, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchangeAcquire(recv, $value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchangeAcquire(recv, $value1$, $value1$);
         });
@@ -529,21 +540,21 @@
             $type$ x = ($type$) vh.compareAndExchangeRelease(null, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease(Void.class, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease(recv, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease(recv, $value1$, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.compareAndExchangeRelease(0, $value1$, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchangeRelease(recv, $value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchangeRelease(recv, $value1$, $value1$);
         });
@@ -562,18 +573,18 @@
             $type$ x = ($type$) vh.getAndSet(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndSet(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSet(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndSet(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSet(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSet(recv, $value1$);
         });
@@ -591,18 +602,18 @@
             $type$ x = ($type$) vh.getAndSetAcquire(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndSetAcquire(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSetAcquire(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndSetAcquire(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSetAcquire(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSetAcquire(recv, $value1$);
         });
@@ -620,18 +631,18 @@
             $type$ x = ($type$) vh.getAndSetRelease(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndSetRelease(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSetRelease(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndSetRelease(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSetRelease(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSetRelease(recv, $value1$);
         });
@@ -651,18 +662,18 @@
             $type$ x = ($type$) vh.getAndAdd(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndAdd(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAdd(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndAdd(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAdd(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAdd(recv, $value1$);
         });
@@ -680,18 +691,18 @@
             $type$ x = ($type$) vh.getAndAddAcquire(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndAddAcquire(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAddAcquire(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndAddAcquire(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAddAcquire(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAddAcquire(recv, $value1$);
         });
@@ -709,18 +720,18 @@
             $type$ x = ($type$) vh.getAndAddRelease(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndAddRelease(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAddRelease(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndAddRelease(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAddRelease(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAddRelease(recv, $value1$);
         });
@@ -740,18 +751,18 @@
             $type$ x = ($type$) vh.getAndBitwiseOr(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseOr(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOr(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseOr(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOr(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOr(recv, $value1$);
         });
@@ -770,18 +781,18 @@
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOrAcquire(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOrAcquire(recv, $value1$);
         });
@@ -800,18 +811,18 @@
             $type$ x = ($type$) vh.getAndBitwiseOrRelease(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseOr(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOr(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseOr(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOr(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOr(recv, $value1$);
         });
@@ -830,18 +841,18 @@
             $type$ x = ($type$) vh.getAndBitwiseAnd(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseAnd(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAnd(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseAnd(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAnd(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAnd(recv, $value1$);
         });
@@ -860,18 +871,18 @@
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAndAcquire(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAndAcquire(recv, $value1$);
         });
@@ -890,18 +901,18 @@
             $type$ x = ($type$) vh.getAndBitwiseAndRelease(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseAnd(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAnd(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseAnd(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAnd(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAnd(recv, $value1$);
         });
@@ -920,18 +931,18 @@
             $type$ x = ($type$) vh.getAndBitwiseXor(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseXor(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXor(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseXor(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXor(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXor(recv, $value1$);
         });
@@ -950,18 +961,18 @@
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXorAcquire(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXorAcquire(recv, $value1$);
         });
@@ -980,18 +991,18 @@
             $type$ x = ($type$) vh.getAndBitwiseXorRelease(null, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             $type$ x = ($type$) vh.getAndBitwiseXor(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXor(recv, Void.class);
         });
         checkWMTE(() -> { // reciever primitive class
             $type$ x = ($type$) vh.getAndBitwiseXor(0, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXor(recv, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXor(recv, $value1$);
         });
@@ -1019,11 +1030,11 @@
             checkWMTE(() -> { // receiver primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class)).
                     invokeExact(0);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void x = (Void) hs.get(am, methodType(Void.class, VarHandleTestMethodType$Type$.class)).
                     invokeExact(recv);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, VarHandleTestMethodType$Type$.class)).
@@ -1048,11 +1059,11 @@
             });
             hs.checkWMTEOrCCE(() -> { // receiver reference class
                 hs.get(am, methodType(void.class, Class.class, $type$.class)).
                     invokeExact(Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 hs.get(am, methodType(void.class, VarHandleTestMethodType$Type$.class, Class.class)).
                     invokeExact(recv, Void.class);
             });
             checkWMTE(() -> { // receiver primitive class
                 hs.get(am, methodType(void.class, int.class, $type$.class)).
@@ -1078,15 +1089,15 @@
             });
             hs.checkWMTEOrCCE(() -> { // receiver reference class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, Class.class, $type$.class, $type$.class)).
                     invokeExact(Void.class, $value1$, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, VarHandleTestMethodType$Type$.class, Class.class, $type$.class)).
                     invokeExact(recv, Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, VarHandleTestMethodType$Type$.class, $type$.class, Class.class)).
                     invokeExact(recv, $value1$, Void.class);
             });
             checkWMTE(() -> { // receiver primitive class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, int.class , $type$.class, $type$.class)).
@@ -1110,24 +1121,24 @@
             });
             hs.checkWMTEOrCCE(() -> { // receiver reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, $type$.class, $type$.class)).
                     invokeExact(Void.class, $value1$, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, VarHandleTestMethodType$Type$.class, Class.class, $type$.class)).
                     invokeExact(recv, Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, VarHandleTestMethodType$Type$.class, $type$.class, Class.class)).
                     invokeExact(recv, $value1$, Void.class);
             });
             checkWMTE(() -> { // reciever primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class , $type$.class, $type$.class)).
                     invokeExact(0, $value1$, $value1$);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, VarHandleTestMethodType$Type$.class , $type$.class, $type$.class)).
                     invokeExact(recv, $value1$, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, VarHandleTestMethodType$Type$.class , $type$.class, $type$.class)).
@@ -1151,20 +1162,20 @@
             });
             hs.checkWMTEOrCCE(() -> { // receiver reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, $type$.class)).
                     invokeExact(Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, VarHandleTestMethodType$Type$.class, Class.class)).
                     invokeExact(recv, Void.class);
             });
             checkWMTE(() -> { // reciever primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class, $type$.class)).
                     invokeExact(0, $value1$);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, VarHandleTestMethodType$Type$.class, $type$.class)).
                     invokeExact(recv, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, VarHandleTestMethodType$Type$.class, $type$.class)).
@@ -1190,20 +1201,20 @@
             });
             hs.checkWMTEOrCCE(() -> { // receiver reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, $type$.class)).
                     invokeExact(Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, VarHandleTestMethodType$Type$.class, Class.class)).
                     invokeExact(recv, Void.class);
             });
             checkWMTE(() -> { // reciever primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class, $type$.class)).
                     invokeExact(0, $value1$);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, VarHandleTestMethodType$Type$.class, $type$.class)).
                     invokeExact(recv, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, VarHandleTestMethodType$Type$.class, $type$.class)).
@@ -1229,20 +1240,20 @@
             });
             hs.checkWMTEOrCCE(() -> { // receiver reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, $type$.class)).
                     invokeExact(Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, VarHandleTestMethodType$Type$.class, Class.class)).
                     invokeExact(recv, Void.class);
             });
             checkWMTE(() -> { // reciever primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class, $type$.class)).
                     invokeExact(0, $value1$);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, VarHandleTestMethodType$Type$.class, $type$.class)).
                     invokeExact(recv, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, VarHandleTestMethodType$Type$.class, $type$.class)).
@@ -1263,11 +1274,11 @@
 
 
     static void testStaticFieldWrongMethodType(VarHandle vh) throws Throwable {
         // Get
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.get();
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.get();
         });
@@ -1277,11 +1288,11 @@
         });
 
 
         // Set
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.set(Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             vh.set();
@@ -1291,11 +1302,11 @@
         });
 
 
         // GetVolatile
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getVolatile();
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getVolatile();
         });
@@ -1304,11 +1315,11 @@
         });
 
 
         // SetVolatile
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setVolatile(Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             vh.setVolatile();
@@ -1318,11 +1329,11 @@
         });
 
 
         // GetOpaque
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getOpaque();
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getOpaque();
         });
@@ -1331,11 +1342,11 @@
         });
 
 
         // SetOpaque
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setOpaque(Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             vh.setOpaque();
@@ -1345,11 +1356,11 @@
         });
 
 
         // GetAcquire
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getAcquire();
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAcquire();
         });
@@ -1358,11 +1369,11 @@
         });
 
 
         // SetRelease
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setRelease(Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             vh.setRelease();
@@ -1373,14 +1384,14 @@
 
 
 #if[CAS]
         // CompareAndSet
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.compareAndSet(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.compareAndSet($value1$, Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             boolean r = vh.compareAndSet();
@@ -1390,14 +1401,14 @@
         });
 
 
         // WeakCompareAndSet
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetPlain(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetPlain($value1$, Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             boolean r = vh.weakCompareAndSetPlain();
@@ -1407,14 +1418,14 @@
         });
 
 
         // WeakCompareAndSetVolatile
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSet(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSet($value1$, Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             boolean r = vh.weakCompareAndSet();
@@ -1424,14 +1435,14 @@
         });
 
 
         // WeakCompareAndSetAcquire
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetAcquire(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetAcquire($value1$, Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             boolean r = vh.weakCompareAndSetAcquire();
@@ -1441,14 +1452,14 @@
         });
 
 
         // WeakCompareAndSetRelease
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetRelease(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetRelease($value1$, Void.class);
         });
         // Incorrect arity
         checkWMTE(() -> { // 0
             boolean r = vh.weakCompareAndSetRelease();
@@ -1458,18 +1469,18 @@
         });
 
 
         // CompareAndExchange
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchange(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchange($value1$, Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchange($value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchange($value1$, $value1$);
         });
@@ -1482,18 +1493,18 @@
         });
 
 
         // CompareAndExchangeAcquire
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire($value1$, Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchangeAcquire($value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchangeAcquire($value1$, $value1$);
         });
@@ -1506,18 +1517,18 @@
         });
 
 
         // CompareAndExchangeRelease
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease(Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease($value1$, Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchangeRelease($value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchangeRelease($value1$, $value1$);
         });
@@ -1530,15 +1541,15 @@
         });
 
 
         // GetAndSet
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSet(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSet($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSet($value1$);
         });
@@ -1551,15 +1562,15 @@
         });
 
 
         // GetAndSetAcquire
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSetAcquire(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSetAcquire($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSetAcquire($value1$);
         });
@@ -1572,15 +1583,15 @@
         });
 
 
         // GetAndSetRelease
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSetRelease(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSetRelease($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSetRelease($value1$);
         });
@@ -1594,15 +1605,15 @@
 #end[CAS]
 
 #if[AtomicAdd]
         // GetAndAdd
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAdd(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAdd($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAdd($value1$);
         });
@@ -1615,15 +1626,15 @@
         });
 
 
         // GetAndAddAcquire
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAddAcquire(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAddAcquire($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAddAcquire($value1$);
         });
@@ -1636,15 +1647,15 @@
         });
 
 
         // GetAndAddRelease
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAddRelease(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAddRelease($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAddRelease($value1$);
         });
@@ -1658,15 +1669,15 @@
 #end[AtomicAdd]
 
 #if[Bitwise]
         // GetAndBitwiseOr
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOr(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOr($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOr($value1$);
         });
@@ -1679,15 +1690,15 @@
         });
 
 
         // GetAndBitwiseOrAcquire
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOrAcquire($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOrAcquire($value1$);
         });
@@ -1700,15 +1711,15 @@
         });
 
 
         // GetAndBitwiseOrReleaseRelease
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOrRelease(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOrRelease($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOrRelease($value1$);
         });
@@ -1721,15 +1732,15 @@
         });
 
 
         // GetAndBitwiseAnd
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAnd(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAnd($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAnd($value1$);
         });
@@ -1742,15 +1753,15 @@
         });
 
 
         // GetAndBitwiseAndAcquire
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAndAcquire($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAndAcquire($value1$);
         });
@@ -1763,15 +1774,15 @@
         });
 
 
         // GetAndBitwiseAndReleaseRelease
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAndRelease(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAndRelease($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAndRelease($value1$);
         });
@@ -1784,15 +1795,15 @@
         });
 
 
         // GetAndBitwiseXor
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXor(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXor($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXor($value1$);
         });
@@ -1805,15 +1816,15 @@
         });
 
 
         // GetAndBitwiseXorAcquire
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXorAcquire($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXorAcquire($value1$);
         });
@@ -1826,15 +1837,15 @@
         });
 
 
         // GetAndBitwiseXorReleaseRelease
         // Incorrect argument types
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXorRelease(Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXorRelease($value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXorRelease($value1$);
         });
@@ -1851,11 +1862,11 @@
     static void testStaticFieldWrongMethodType(Handles hs) throws Throwable {
         int i = 0;
 
         for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET)) {
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void x = (Void) hs.get(am, methodType(Void.class)).
                     invokeExact();
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class)).
@@ -1867,11 +1878,11 @@
                     invokeExact(Void.class);
             });
         }
 
         for (TestAccessMode am : testAccessModesOfType(TestAccessType.SET)) {
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 hs.get(am, methodType(void.class, Class.class)).
                     invokeExact(Void.class);
             });
             // Incorrect arity
             checkWMTE(() -> { // 0
@@ -1884,15 +1895,15 @@
             });
         }
 #if[CAS]
         for (TestAccessMode am : testAccessModesOfType(TestAccessType.COMPARE_AND_SET)) {
             // Incorrect argument types
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, Class.class, $type$.class)).
                     invokeExact(Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, $type$.class, Class.class)).
                     invokeExact($value1$, Void.class);
             });
             // Incorrect arity
             checkWMTE(() -> { // 0
@@ -1905,20 +1916,20 @@
             });
         }
 
         for (TestAccessMode am : testAccessModesOfType(TestAccessType.COMPARE_AND_EXCHANGE)) {
             // Incorrect argument types
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, $type$.class)).
                     invokeExact(Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$.class, Class.class)).
                     invokeExact($value1$, Void.class);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, $type$.class, $type$.class)).
                     invokeExact($value1$, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$.class, $type$.class)).
@@ -1935,16 +1946,16 @@
             });
         }
 
         for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_SET)) {
             // Incorrect argument types
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class)).
                     invokeExact(Void.class);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, $type$.class)).
                     invokeExact($value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$.class)).
@@ -1963,16 +1974,16 @@
 #end[CAS]
 
 #if[AtomicAdd]
         for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_ADD)) {
             // Incorrect argument types
-            check{#if[String]?CCE:WMTE}(() -> { // value reference class
+            check{#if[Object]?CCE:WMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class)).
                     invokeExact(Void.class);
             });
             // Incorrect return type
-            check{#if[String]?CCE:WMTE}(() -> { // reference class
+            check{#if[Object]?CCE:WMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, $type$.class)).
                     invokeExact($value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$.class)).
@@ -1991,16 +2002,16 @@
 #end[AtomicAdd]
 
 #if[Bitwise]
         for (TestAccessMode am : testAccessModesOfType(TestAccessType.GET_AND_BITWISE)) {
             // Incorrect argument types
-            check{#if[String]?CCE:WMTE}(() -> { // value reference class
+            check{#if[Object]?CCE:WMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class)).
                     invokeExact(Void.class);
             });
             // Incorrect return type
-            check{#if[String]?CCE:WMTE}(() -> { // reference class
+            check{#if[Object]?CCE:WMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, $type$.class)).
                     invokeExact($value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$.class)).
@@ -2037,11 +2048,11 @@
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.get(array, Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.get(array, 0);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.get(array, 0);
         });
@@ -2060,11 +2071,11 @@
             vh.set(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             vh.set(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.set(array, 0, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             vh.set(0, 0, $value1$);
         });
@@ -2093,11 +2104,11 @@
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getVolatile(array, Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getVolatile(array, 0);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getVolatile(array, 0);
         });
@@ -2116,11 +2127,11 @@
             vh.setVolatile(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             vh.setVolatile(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setVolatile(array, 0, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             vh.setVolatile(0, 0, $value1$);
         });
@@ -2149,11 +2160,11 @@
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getOpaque(array, Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getOpaque(array, 0);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getOpaque(array, 0);
         });
@@ -2172,11 +2183,11 @@
             vh.setOpaque(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             vh.setOpaque(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setOpaque(array, 0, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             vh.setOpaque(0, 0, $value1$);
         });
@@ -2205,11 +2216,11 @@
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAcquire(array, Void.class);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void x = (Void) vh.getAcquire(array, 0);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAcquire(array, 0);
         });
@@ -2228,11 +2239,11 @@
             vh.setRelease(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             vh.setRelease(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             vh.setRelease(array, 0, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             vh.setRelease(0, 0, $value1$);
         });
@@ -2255,14 +2266,14 @@
             boolean r = vh.compareAndSet(null, 0, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.compareAndSet(Void.class, 0, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.compareAndSet(array, 0, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.compareAndSet(array, 0, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.compareAndSet(0, 0, $value1$, $value1$);
         });
@@ -2284,14 +2295,14 @@
             boolean r = vh.weakCompareAndSetPlain(null, 0, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.weakCompareAndSetPlain(Void.class, 0, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetPlain(array, 0, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetPlain(array, 0, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.weakCompareAndSetPlain(0, 0, $value1$, $value1$);
         });
@@ -2313,14 +2324,14 @@
             boolean r = vh.weakCompareAndSet(null, 0, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.weakCompareAndSet(Void.class, 0, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSet(array, 0, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSet(array, 0, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.weakCompareAndSet(0, 0, $value1$, $value1$);
         });
@@ -2342,14 +2353,14 @@
             boolean r = vh.weakCompareAndSetAcquire(null, 0, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.weakCompareAndSetAcquire(Void.class, 0, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetAcquire(array, 0, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetAcquire(array, 0, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.weakCompareAndSetAcquire(0, 0, $value1$, $value1$);
         });
@@ -2371,14 +2382,14 @@
             boolean r = vh.weakCompareAndSetRelease(null, 0, $value1$, $value1$);
         });
         checkCCE(() -> { // receiver reference class
             boolean r = vh.weakCompareAndSetRelease(Void.class, 0, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             boolean r = vh.weakCompareAndSetRelease(array, 0, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             boolean r = vh.weakCompareAndSetRelease(array, 0, $value1$, Void.class);
         });
         checkWMTE(() -> { // receiver primitive class
             boolean r = vh.weakCompareAndSetRelease(0, 0, $value1$, $value1$);
         });
@@ -2400,24 +2411,24 @@
             $type$ x = ($type$) vh.compareAndExchange(null, 0, $value1$, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.compareAndExchange(Void.class, 0, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchange(array, 0, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchange(array, 0, $value1$, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.compareAndExchange(0, 0, $value1$, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.compareAndExchange(array, Void.class, $value1$, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchange(array, 0, $value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchange(array, 0, $value1$, $value1$);
         });
@@ -2436,24 +2447,24 @@
             $type$ x = ($type$) vh.compareAndExchangeAcquire(null, 0, $value1$, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(Void.class, 0, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(array, 0, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(array, 0, $value1$, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(0, 0, $value1$, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.compareAndExchangeAcquire(array, Void.class, $value1$, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchangeAcquire(array, 0, $value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchangeAcquire(array, 0, $value1$, $value1$);
         });
@@ -2472,24 +2483,24 @@
             $type$ x = ($type$) vh.compareAndExchangeRelease(null, 0, $value1$, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease(Void.class, 0, $value1$, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // expected reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // expected reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease(array, 0, Void.class, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // actual reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // actual reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease(array, 0, $value1$, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.compareAndExchangeRelease(0, 0, $value1$, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.compareAndExchangeRelease(array, Void.class, $value1$, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.compareAndExchangeRelease(array, 0, $value1$, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.compareAndExchangeRelease(array, 0, $value1$, $value1$);
         });
@@ -2508,21 +2519,21 @@
             $type$ x = ($type$) vh.getAndSet(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndSet(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSet(array, 0, Void.class);
         });
         checkWMTE(() -> { // reciarrayever primitive class
             $type$ x = ($type$) vh.getAndSet(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndSet(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSet(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSet(array, 0, $value1$);
         });
@@ -2541,21 +2552,21 @@
             $type$ x = ($type$) vh.getAndSetAcquire(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndSetAcquire(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSetAcquire(array, 0, Void.class);
         });
         checkWMTE(() -> { // reciarrayever primitive class
             $type$ x = ($type$) vh.getAndSetAcquire(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndSetAcquire(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSetAcquire(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSetAcquire(array, 0, $value1$);
         });
@@ -2574,21 +2585,21 @@
             $type$ x = ($type$) vh.getAndSetRelease(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndSetRelease(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndSetRelease(array, 0, Void.class);
         });
         checkWMTE(() -> { // reciarrayever primitive class
             $type$ x = ($type$) vh.getAndSetRelease(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndSetRelease(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndSetRelease(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndSetRelease(array, 0, $value1$);
         });
@@ -2608,21 +2619,21 @@
             $type$ x = ($type$) vh.getAndAdd(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndAdd(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAdd(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndAdd(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndAdd(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAdd(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAdd(array, 0, $value1$);
         });
@@ -2641,21 +2652,21 @@
             $type$ x = ($type$) vh.getAndAddAcquire(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndAddAcquire(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAddAcquire(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndAddAcquire(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndAddAcquire(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAddAcquire(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAddAcquire(array, 0, $value1$);
         });
@@ -2674,21 +2685,21 @@
             $type$ x = ($type$) vh.getAndAddRelease(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndAddRelease(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndAddRelease(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndAddRelease(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndAddRelease(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndAddRelease(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndAddRelease(array, 0, $value1$);
         });
@@ -2708,21 +2719,21 @@
             $type$ x = ($type$) vh.getAndBitwiseOr(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseOr(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOr(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseOr(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseOr(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOr(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOr(array, 0, $value1$);
         });
@@ -2741,21 +2752,21 @@
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseOrAcquire(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOrAcquire(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOrAcquire(array, 0, $value1$);
         });
@@ -2774,21 +2785,21 @@
             $type$ x = ($type$) vh.getAndBitwiseOrRelease(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseOrRelease(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseOrRelease(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseOrRelease(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseOrRelease(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseOrRelease(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseOrRelease(array, 0, $value1$);
         });
@@ -2807,21 +2818,21 @@
             $type$ x = ($type$) vh.getAndBitwiseAnd(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseAnd(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAnd(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseAnd(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseAnd(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAnd(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAnd(array, 0, $value1$);
         });
@@ -2840,21 +2851,21 @@
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseAndAcquire(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAndAcquire(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAndAcquire(array, 0, $value1$);
         });
@@ -2873,21 +2884,21 @@
             $type$ x = ($type$) vh.getAndBitwiseAndRelease(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseAndRelease(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseAndRelease(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseAndRelease(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseAndRelease(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseAndRelease(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseAndRelease(array, 0, $value1$);
         });
@@ -2906,21 +2917,21 @@
             $type$ x = ($type$) vh.getAndBitwiseXor(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseXor(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXor(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseXor(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseXor(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXor(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXor(array, 0, $value1$);
         });
@@ -2939,21 +2950,21 @@
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseXorAcquire(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXorAcquire(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXorAcquire(array, 0, $value1$);
         });
@@ -2972,21 +2983,21 @@
             $type$ x = ($type$) vh.getAndBitwiseXorRelease(null, 0, $value1$);
         });
         checkCCE(() -> { // array reference class
             $type$ x = ($type$) vh.getAndBitwiseXorRelease(Void.class, 0, $value1$);
         });
-        check{#if[String]?CCE:WMTE}(() -> { // value reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // value reference class
             $type$ x = ($type$) vh.getAndBitwiseXorRelease(array, 0, Void.class);
         });
         checkWMTE(() -> { // array primitive class
             $type$ x = ($type$) vh.getAndBitwiseXorRelease(0, 0, $value1$);
         });
         checkWMTE(() -> { // index reference class
             $type$ x = ($type$) vh.getAndBitwiseXorRelease(array, Void.class, $value1$);
         });
         // Incorrect return type
-        check{#if[String]?CCE:WMTE}(() -> { // reference class
+        check{#if[Object]?CCE:WMTE}(() -> { // reference class
             Void r = (Void) vh.getAndBitwiseXorRelease(array, 0, $value1$);
         });
         checkWMTE(() -> { // primitive class
             $wrong_primitive_type$ x = ($wrong_primitive_type$) vh.getAndBitwiseXorRelease(array, 0, $value1$);
         });
@@ -3021,11 +3032,11 @@
             checkWMTE(() -> { // index reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, Class.class)).
                     invokeExact(array, Void.class);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void x = (Void) hs.get(am, methodType(Void.class, $type$[].class, int.class)).
                     invokeExact(array, 0);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$[].class, int.class)).
@@ -3050,11 +3061,11 @@
             });
             hs.checkWMTEOrCCE(() -> { // array reference class
                 hs.get(am, methodType(void.class, Class.class, int.class, $type$.class)).
                     invokeExact(Void.class, 0, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 hs.get(am, methodType(void.class, $type$[].class, int.class, Class.class)).
                     invokeExact(array, 0, Void.class);
             });
             checkWMTE(() -> { // receiver primitive class
                 hs.get(am, methodType(void.class, int.class, int.class, $type$.class)).
@@ -3083,15 +3094,15 @@
             });
             hs.checkWMTEOrCCE(() -> { // receiver reference class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, Class.class, int.class, $type$.class, $type$.class)).
                     invokeExact(Void.class, 0, $value1$, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, $type$[].class, int.class, Class.class, $type$.class)).
                     invokeExact(array, 0, Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, $type$[].class, int.class, $type$.class, Class.class)).
                     invokeExact(array, 0, $value1$, Void.class);
             });
             checkWMTE(() -> { // receiver primitive class
                 boolean r = (boolean) hs.get(am, methodType(boolean.class, int.class, int.class, $type$.class, $type$.class)).
@@ -3120,15 +3131,15 @@
             });
             hs.checkWMTEOrCCE(() -> { // array reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, int.class, $type$.class, $type$.class)).
                     invokeExact(Void.class, 0, $value1$, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // expected reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, int.class, Class.class, $type$.class)).
                     invokeExact(array, 0, Void.class, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // actual reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, int.class, $type$.class, Class.class)).
                     invokeExact(array, 0, $value1$, Void.class);
             });
             checkWMTE(() -> { // array primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class, int.class, $type$.class, $type$.class)).
@@ -3137,11 +3148,11 @@
             checkWMTE(() -> { // index reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, Class.class, $type$.class, $type$.class)).
                     invokeExact(array, Void.class, $value1$, $value1$);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, $type$[].class, int.class, $type$.class, $type$.class)).
                     invokeExact(array, 0, $value1$, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$[].class, int.class, $type$.class, $type$.class)).
@@ -3166,11 +3177,11 @@
             });
             hs.checkWMTEOrCCE(() -> { // array reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, int.class, $type$.class)).
                     invokeExact(Void.class, 0, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, int.class, Class.class)).
                     invokeExact(array, 0, Void.class);
             });
             checkWMTE(() -> { // array primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class, int.class, $type$.class)).
@@ -3179,11 +3190,11 @@
             checkWMTE(() -> { // index reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, Class.class, $type$.class)).
                     invokeExact(array, Void.class, $value1$);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, $type$[].class, int.class, $type$.class)).
                     invokeExact(array, 0, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$[].class, int.class, $type$.class)).
@@ -3210,11 +3221,11 @@
             });
             hs.checkWMTEOrCCE(() -> { // array reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, int.class, $type$.class)).
                     invokeExact(Void.class, 0, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, int.class, Class.class)).
                     invokeExact(array, 0, Void.class);
             });
             checkWMTE(() -> { // array primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class, int.class, $type$.class)).
@@ -3223,11 +3234,11 @@
             checkWMTE(() -> { // index reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, Class.class, $type$.class)).
                     invokeExact(array, Void.class, $value1$);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, $type$[].class, int.class, $type$.class)).
                     invokeExact(array, 0, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$[].class, int.class, $type$.class)).
@@ -3254,11 +3265,11 @@
             });
             hs.checkWMTEOrCCE(() -> { // array reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, Class.class, int.class, $type$.class)).
                     invokeExact(Void.class, 0, $value1$);
             });
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // value reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, int.class, Class.class)).
                     invokeExact(array, 0, Void.class);
             });
             checkWMTE(() -> { // array primitive class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, int.class, int.class, $type$.class)).
@@ -3267,11 +3278,11 @@
             checkWMTE(() -> { // index reference class
                 $type$ x = ($type$) hs.get(am, methodType($type$.class, $type$[].class, Class.class, $type$.class)).
                     invokeExact(array, Void.class, $value1$);
             });
             // Incorrect return type
-            {#if[String]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
+            {#if[Object]?hs.checkWMTEOrCCE:checkWMTE}(() -> { // reference class
                 Void r = (Void) hs.get(am, methodType(Void.class, $type$[].class, int.class, $type$.class)).
                     invokeExact(array, 0, $value1$);
             });
             checkWMTE(() -> { // primitive class
                 $wrong_primitive_type$ x = ($wrong_primitive_type$) hs.get(am, methodType($wrong_primitive_type$.class, $type$[].class, int.class, $type$.class)).
