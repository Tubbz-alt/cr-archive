<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.hpp&quot;
  28 #include &quot;asm/macroAssembler.inline.hpp&quot;
  29 #include &quot;classfile/symbolTable.hpp&quot;
  30 #include &quot;code/debugInfoRec.hpp&quot;
  31 #include &quot;code/icBuffer.hpp&quot;
  32 #include &quot;code/vtableStubs.hpp&quot;

  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interp_masm.hpp&quot;
  35 #include &quot;logging/log.hpp&quot;
  36 #include &quot;memory/resourceArea.hpp&quot;
  37 #include &quot;nativeInst_aarch64.hpp&quot;
  38 #include &quot;oops/compiledICHolder.hpp&quot;
  39 #include &quot;oops/klass.inline.hpp&quot;
  40 #include &quot;runtime/safepointMechanism.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/vframeArray.hpp&quot;
  43 #include &quot;utilities/align.hpp&quot;
  44 #include &quot;vmreg_aarch64.inline.hpp&quot;
  45 #ifdef COMPILER1
  46 #include &quot;c1/c1_Runtime1.hpp&quot;
  47 #endif
  48 #ifdef COMPILER2
  49 #include &quot;adfiles/ad_aarch64.hpp&quot;
  50 #include &quot;opto/runtime.hpp&quot;
  51 #endif
  52 #if INCLUDE_JVMCI
</pre>
<hr />
<pre>
 154       // Register slots are 8 bytes wide, 32 floating-point registers.
 155       int sp_offset = RegisterImpl::max_slots_per_register * i +
 156                       FloatRegisterImpl::save_slots_per_register * FloatRegisterImpl::number_of_registers;
 157       oop_map-&gt;set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots),
 158                                 r-&gt;as_VMReg());
 159     }
 160   }
 161 
 162   for (int i = 0; i &lt; FloatRegisterImpl::number_of_registers; i++) {
 163     FloatRegister r = as_FloatRegister(i);
 164     int sp_offset = save_vectors ? (FloatRegisterImpl::max_slots_per_register * i) :
 165                                    (FloatRegisterImpl::save_slots_per_register * i);
 166     oop_map-&gt;set_callee_saved(VMRegImpl::stack2reg(sp_offset),
 167                               r-&gt;as_VMReg());
 168   }
 169 
 170   return oop_map;
 171 }
 172 
 173 void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_vectors) {
<span class="line-modified"> 174 #if COMPILER2_OR_JVMCI</span>
<span class="line-removed"> 175   __ pop_CPU_state(restore_vectors);</span>
<span class="line-removed"> 176   __ leave();</span>
<span class="line-removed"> 177 #else</span>
 178   assert(!restore_vectors, &quot;vectors are generated only by C2 and JVMCI&quot;);
 179 #endif



 180 }
 181 
 182 void RegisterSaver::restore_result_registers(MacroAssembler* masm) {
 183 
 184   // Just restore result register. Only used by deoptimization. By
 185   // now any callee save register that needs to be restored to a c2
 186   // caller of the deoptee has been extracted into the vframeArray
 187   // and will be stuffed into the c2i adapter we create for later
 188   // restoration so only result registers need to be restored here.
 189 
 190   // Restore fp result register
 191   __ ldrd(v0, Address(sp, v0_offset_in_bytes()));
 192   // Restore integer result register
 193   __ ldr(r0, Address(sp, r0_offset_in_bytes()));
 194 
 195   // Pop all of the register save are off the stack
 196   __ add(sp, sp, align_up(return_offset_in_bytes(), 16));
 197 }
 198 
 199 // Is vector&#39;s size (in bytes) bigger than a size saved by default?
</pre>
<hr />
<pre>
 969   if (VM_Version::supports_fast_class_init_checks()) {
 970     Label L_skip_barrier;
 971     { // Bypass the barrier for non-static methods
 972         Register flags  = rscratch1;
 973       __ ldrw(flags, Address(rmethod, Method::access_flags_offset()));
 974       __ tst(flags, JVM_ACC_STATIC);
 975       __ br(Assembler::NE, L_skip_barrier); // non-static
 976     }
 977 
 978     Register klass = rscratch1;
 979     __ load_method_holder(klass, rmethod);
 980     // We pass rthread to this function on x86
 981     __ clinit_barrier(klass, rscratch2, &amp;L_skip_barrier /*L_fast_path*/);
 982 
 983     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub())); // slow path
 984 
 985     __ bind(L_skip_barrier);
 986     c2i_no_clinit_check_entry = __ pc();
 987   }
 988 
<span class="line-modified"> 989 //  FIXME: Not Implemented</span>
<span class="line-modified"> 990 //  BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-removed"> 991 //  bs-&gt;c2i_entry_barrier(masm);</span>
 992 
<span class="line-modified"> 993   gen_c2i_adapter(masm, sig_cc, regs_cc, skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, true);</span>
 994 
 995   address c2i_unverified_value_entry = c2i_unverified_entry;
 996 
 997  // Non-scalarized c2i adapter
 998   address c2i_value_entry = c2i_entry;
 999   if (regs != regs_cc) {
1000     Label value_entry_skip_fixup;
1001     c2i_unverified_value_entry = __ pc();
1002     gen_inline_cache_check(masm, value_entry_skip_fixup);
1003 
1004     c2i_value_entry = __ pc();
1005     Label unused;
1006     gen_c2i_adapter(masm, sig, regs, value_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);
1007   }
1008 
1009   __ flush();
1010 
1011   // The c2i adapter might safepoint and trigger a GC. The caller must make sure that
1012   // the GC knows about the location of oop argument locations passed to the c2i adapter.
1013 
</pre>
<hr />
<pre>
1767     Label L_skip_barrier;
1768     __ mov_metadata(rscratch2, method-&gt;method_holder()); // InstanceKlass*
1769     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
1770     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
1771 
1772     __ bind(L_skip_barrier);
1773   }
1774 
1775   // Generate stack overflow check
1776   if (UseStackBanging) {
1777     __ bang_stack_with_offset(JavaThread::stack_shadow_zone_size());
1778   } else {
1779     Unimplemented();
1780   }
1781 
1782   // Generate a new frame for the wrapper.
1783   __ enter();
1784   // -2 because return address is already present and so is saved rfp
1785   __ sub(sp, sp, stack_size - 2*wordSize);
1786 



1787   // Frame is now completed as far as size and linkage.
1788   int frame_complete = ((intptr_t)__ pc()) - start;
1789 
1790   // We use r20 as the oop handle for the receiver/klass
1791   // It is callee save so it survives the call to native
1792 
1793   const Register oop_handle_reg = r20;
1794 
1795   if (is_critical_native) {
1796     check_needs_gc_for_critical_native(masm, stack_slots, total_c_args, total_in_args,
1797                                        oop_handle_offset, oop_maps, in_regs, in_sig_bt);
1798   }
1799 
1800   //
1801   // We immediately shuffle the arguments so that any vm call we have to
1802   // make from here on out (sync slow path, jvmti, etc.) we will have
1803   // captured the oops from our caller and have a valid oopMap for
1804   // them.
1805 
1806   // -----------------
</pre>
</td>
<td>
<hr />
<pre>
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.hpp&quot;
  28 #include &quot;asm/macroAssembler.inline.hpp&quot;
  29 #include &quot;classfile/symbolTable.hpp&quot;
  30 #include &quot;code/debugInfoRec.hpp&quot;
  31 #include &quot;code/icBuffer.hpp&quot;
  32 #include &quot;code/vtableStubs.hpp&quot;
<span class="line-added">  33 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;</span>
  34 #include &quot;interpreter/interpreter.hpp&quot;
  35 #include &quot;interpreter/interp_masm.hpp&quot;
  36 #include &quot;logging/log.hpp&quot;
  37 #include &quot;memory/resourceArea.hpp&quot;
  38 #include &quot;nativeInst_aarch64.hpp&quot;
  39 #include &quot;oops/compiledICHolder.hpp&quot;
  40 #include &quot;oops/klass.inline.hpp&quot;
  41 #include &quot;runtime/safepointMechanism.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;
  43 #include &quot;runtime/vframeArray.hpp&quot;
  44 #include &quot;utilities/align.hpp&quot;
  45 #include &quot;vmreg_aarch64.inline.hpp&quot;
  46 #ifdef COMPILER1
  47 #include &quot;c1/c1_Runtime1.hpp&quot;
  48 #endif
  49 #ifdef COMPILER2
  50 #include &quot;adfiles/ad_aarch64.hpp&quot;
  51 #include &quot;opto/runtime.hpp&quot;
  52 #endif
  53 #if INCLUDE_JVMCI
</pre>
<hr />
<pre>
 155       // Register slots are 8 bytes wide, 32 floating-point registers.
 156       int sp_offset = RegisterImpl::max_slots_per_register * i +
 157                       FloatRegisterImpl::save_slots_per_register * FloatRegisterImpl::number_of_registers;
 158       oop_map-&gt;set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots),
 159                                 r-&gt;as_VMReg());
 160     }
 161   }
 162 
 163   for (int i = 0; i &lt; FloatRegisterImpl::number_of_registers; i++) {
 164     FloatRegister r = as_FloatRegister(i);
 165     int sp_offset = save_vectors ? (FloatRegisterImpl::max_slots_per_register * i) :
 166                                    (FloatRegisterImpl::save_slots_per_register * i);
 167     oop_map-&gt;set_callee_saved(VMRegImpl::stack2reg(sp_offset),
 168                               r-&gt;as_VMReg());
 169   }
 170 
 171   return oop_map;
 172 }
 173 
 174 void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_vectors) {
<span class="line-modified"> 175 #if !COMPILER2_OR_JVMCI</span>



 176   assert(!restore_vectors, &quot;vectors are generated only by C2 and JVMCI&quot;);
 177 #endif
<span class="line-added"> 178   __ pop_CPU_state(restore_vectors);</span>
<span class="line-added"> 179   __ leave();</span>
<span class="line-added"> 180 </span>
 181 }
 182 
 183 void RegisterSaver::restore_result_registers(MacroAssembler* masm) {
 184 
 185   // Just restore result register. Only used by deoptimization. By
 186   // now any callee save register that needs to be restored to a c2
 187   // caller of the deoptee has been extracted into the vframeArray
 188   // and will be stuffed into the c2i adapter we create for later
 189   // restoration so only result registers need to be restored here.
 190 
 191   // Restore fp result register
 192   __ ldrd(v0, Address(sp, v0_offset_in_bytes()));
 193   // Restore integer result register
 194   __ ldr(r0, Address(sp, r0_offset_in_bytes()));
 195 
 196   // Pop all of the register save are off the stack
 197   __ add(sp, sp, align_up(return_offset_in_bytes(), 16));
 198 }
 199 
 200 // Is vector&#39;s size (in bytes) bigger than a size saved by default?
</pre>
<hr />
<pre>
 970   if (VM_Version::supports_fast_class_init_checks()) {
 971     Label L_skip_barrier;
 972     { // Bypass the barrier for non-static methods
 973         Register flags  = rscratch1;
 974       __ ldrw(flags, Address(rmethod, Method::access_flags_offset()));
 975       __ tst(flags, JVM_ACC_STATIC);
 976       __ br(Assembler::NE, L_skip_barrier); // non-static
 977     }
 978 
 979     Register klass = rscratch1;
 980     __ load_method_holder(klass, rmethod);
 981     // We pass rthread to this function on x86
 982     __ clinit_barrier(klass, rscratch2, &amp;L_skip_barrier /*L_fast_path*/);
 983 
 984     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub())); // slow path
 985 
 986     __ bind(L_skip_barrier);
 987     c2i_no_clinit_check_entry = __ pc();
 988   }
 989 
<span class="line-modified"> 990   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-modified"> 991   bs-&gt;c2i_entry_barrier(masm);</span>

 992 
<span class="line-modified"> 993   gen_c2i_adapter(masm, total_args_passed, comp_args_on_stack, sig_bt, regs, skip_fixup);</span>
 994 
 995   address c2i_unverified_value_entry = c2i_unverified_entry;
 996 
 997  // Non-scalarized c2i adapter
 998   address c2i_value_entry = c2i_entry;
 999   if (regs != regs_cc) {
1000     Label value_entry_skip_fixup;
1001     c2i_unverified_value_entry = __ pc();
1002     gen_inline_cache_check(masm, value_entry_skip_fixup);
1003 
1004     c2i_value_entry = __ pc();
1005     Label unused;
1006     gen_c2i_adapter(masm, sig, regs, value_entry_skip_fixup, i2c_entry, oop_maps, frame_complete, frame_size_in_words, false);
1007   }
1008 
1009   __ flush();
1010 
1011   // The c2i adapter might safepoint and trigger a GC. The caller must make sure that
1012   // the GC knows about the location of oop argument locations passed to the c2i adapter.
1013 
</pre>
<hr />
<pre>
1767     Label L_skip_barrier;
1768     __ mov_metadata(rscratch2, method-&gt;method_holder()); // InstanceKlass*
1769     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
1770     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
1771 
1772     __ bind(L_skip_barrier);
1773   }
1774 
1775   // Generate stack overflow check
1776   if (UseStackBanging) {
1777     __ bang_stack_with_offset(JavaThread::stack_shadow_zone_size());
1778   } else {
1779     Unimplemented();
1780   }
1781 
1782   // Generate a new frame for the wrapper.
1783   __ enter();
1784   // -2 because return address is already present and so is saved rfp
1785   __ sub(sp, sp, stack_size - 2*wordSize);
1786 
<span class="line-added">1787   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-added">1788   bs-&gt;nmethod_entry_barrier(masm);</span>
<span class="line-added">1789 </span>
1790   // Frame is now completed as far as size and linkage.
1791   int frame_complete = ((intptr_t)__ pc()) - start;
1792 
1793   // We use r20 as the oop handle for the receiver/klass
1794   // It is callee save so it survives the call to native
1795 
1796   const Register oop_handle_reg = r20;
1797 
1798   if (is_critical_native) {
1799     check_needs_gc_for_critical_native(masm, stack_slots, total_c_args, total_in_args,
1800                                        oop_handle_offset, oop_maps, in_regs, in_sig_bt);
1801   }
1802 
1803   //
1804   // We immediately shuffle the arguments so that any vm call we have to
1805   // make from here on out (sync slow path, jvmti, etc.) we will have
1806   // captured the oops from our caller and have a valid oopMap for
1807   // them.
1808 
1809   // -----------------
</pre>
</td>
</tr>
</table>
<center><a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="stubGenerator_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>