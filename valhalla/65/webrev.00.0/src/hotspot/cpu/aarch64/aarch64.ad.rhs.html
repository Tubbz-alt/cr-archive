<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   if (UseBarriersForVolatile) {
 1371     // we need to plant a dmb
 1372     return false;
 1373   }
 1374 
 1375   MemBarNode* mb = barrier-&gt;as_MemBar();
 1376 
 1377   if (mb-&gt;trailing_load()) {
 1378     return true;
 1379   }
 1380 
 1381   if (mb-&gt;trailing_load_store()) {
 1382     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1383     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1384     return is_CAS(load_store-&gt;Opcode(), true);
 1385   }
 1386 
 1387   return false;
 1388 }
 1389 
 1390 bool needs_acquiring_load(const Node *n)
 1391 {
 1392   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1393   if (UseBarriersForVolatile) {
 1394     // we use a normal load and a dmb
 1395     return false;
 1396   }
 1397 
 1398   LoadNode *ld = n-&gt;as_Load();
 1399 
 1400   return ld-&gt;is_acquire();
 1401 }
 1402 
 1403 bool unnecessary_release(const Node *n)
 1404 {
 1405   assert((n-&gt;is_MemBar() &amp;&amp;
 1406 	  n-&gt;Opcode() == Op_MemBarRelease),
 1407 	 &quot;expecting a release membar&quot;);
 1408 
 1409   if (UseBarriersForVolatile) {
 1410     // we need to plant a dmb
 1411     return false;
 1412   }
 1413 
 1414   MemBarNode *barrier = n-&gt;as_MemBar();
 1415   if (!barrier-&gt;leading()) {
 1416     return false;
 1417   } else {
 1418     Node* trailing = barrier-&gt;trailing_membar();
 1419     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1420     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1421     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1422 
 1423     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1424     if (mem-&gt;is_Store()) {
 1425       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1426       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1427       return true;
 1428     } else {
 1429       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1430       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1431       return is_CAS(mem-&gt;Opcode(), true);
 1432     }
 1433   }
 1434   return false;
 1435 }
 1436 
 1437 bool unnecessary_volatile(const Node *n)
 1438 {
 1439   // assert n-&gt;is_MemBar();
 1440   if (UseBarriersForVolatile) {
 1441     // we need to plant a dmb
 1442     return false;
 1443   }
 1444 
 1445   MemBarNode *mbvol = n-&gt;as_MemBar();
 1446 
 1447   bool release = mbvol-&gt;trailing_store();
 1448   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1449 #ifdef ASSERT
 1450   if (release) {
 1451     Node* leading = mbvol-&gt;leading_membar();
 1452     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1453     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1454     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1455   }
 1456 #endif
 1457 
 1458   return release;
 1459 }
 1460 
 1461 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1462 
 1463 bool needs_releasing_store(const Node *n)
 1464 {
 1465   // assert n-&gt;is_Store();
 1466   if (UseBarriersForVolatile) {
 1467     // we use a normal store and dmb combination
 1468     return false;
 1469   }
 1470 
 1471   StoreNode *st = n-&gt;as_Store();
 1472 
 1473   return st-&gt;trailing_membar() != NULL;
 1474 }
 1475 
 1476 // predicate controlling translation of CAS
 1477 //
 1478 // returns true if CAS needs to use an acquiring load otherwise false
 1479 
 1480 bool needs_acquiring_load_exclusive(const Node *n)
 1481 {
 1482   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1483   if (UseBarriersForVolatile) {
 1484     return false;
 1485   }
 1486 
 1487   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1488   if (is_CAS(n-&gt;Opcode(), false)) {
 1489     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1490   } else {
 1491     return ldst-&gt;trailing_membar() != NULL;
 1492   }
 1493 
 1494   // so we can just return true here
 1495   return true;
 1496 }
 1497 
 1498 #define __ _masm.
 1499 
 1500 // advance declarations for helper functions to convert register
 1501 // indices to register objects
 1502 
 1503 // the ad file has to provide implementations of certain methods
 1504 // expected by the generic code
 1505 //
 1506 // REQUIRED FUNCTIONALITY
 1507 
 1508 //=============================================================================
 1509 
 1510 // !!!!! Special hack to get all types of calls to specify the byte offset
 1511 //       from the start of the call to the point where the return address
 1512 //       will point.
 1513 
 1514 int MachCallStaticJavaNode::ret_addr_offset()
 1515 {
 1516   // call should be a simple bl
 1517   int off = 4;
 1518   return off;
 1519 }
 1520 
 1521 int MachCallDynamicJavaNode::ret_addr_offset()
 1522 {
 1523   return 16; // movz, movk, movk, bl
 1524 }
 1525 
 1526 int MachCallRuntimeNode::ret_addr_offset() {
 1527   // for generated stubs the call will be
 1528   //   far_call(addr)
 1529   // for real runtime callouts it will be six instructions
 1530   // see aarch64_enc_java_to_runtime
 1531   //   adr(rscratch2, retaddr)
 1532   //   lea(rscratch1, RuntimeAddress(addr)
 1533   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1534   //   blr(rscratch1)
 1535   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1536   if (cb) {
 1537     return MacroAssembler::far_branch_size();
 1538   } else {
 1539     return 6 * NativeInstruction::instruction_size;
 1540   }
 1541 }
 1542 
 1543 // Indicate if the safepoint node needs the polling page as an input
 1544 
 1545 // the shared code plants the oop data at the start of the generated
 1546 // code for the safepoint node and that needs ot be at the load
 1547 // instruction itself. so we cannot plant a mov of the safepoint poll
 1548 // address followed by a load. setting this to true means the mov is
 1549 // scheduled as a prior instruction. that&#39;s better for scheduling
 1550 // anyway.
 1551 
 1552 bool SafePointNode::needs_polling_address_input()
 1553 {
 1554   return true;
 1555 }
 1556 
 1557 //=============================================================================
 1558 
 1559 #ifndef PRODUCT
 1560 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1561   st-&gt;print(&quot;BREAKPOINT&quot;);
 1562 }
 1563 #endif
 1564 
 1565 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1566   C2_MacroAssembler _masm(&amp;cbuf);
 1567   __ brk(0);
 1568 }
 1569 
 1570 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1571   return MachNode::size(ra_);
 1572 }
 1573 
 1574 //=============================================================================
 1575 
 1576 #ifndef PRODUCT
 1577   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1578     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1579   }
 1580 #endif
 1581 
 1582   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1583     C2_MacroAssembler _masm(&amp;cbuf);
 1584     for (int i = 0; i &lt; _count; i++) {
 1585       __ nop();
 1586     }
 1587   }
 1588 
 1589   uint MachNopNode::size(PhaseRegAlloc*) const {
 1590     return _count * NativeInstruction::instruction_size;
 1591   }
 1592 
 1593 //=============================================================================
 1594 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1595 
 1596 int ConstantTable::calculate_table_base_offset() const {
 1597   return 0;  // absolute addressing, no offset
 1598 }
 1599 
 1600 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1601 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1602   ShouldNotReachHere();
 1603 }
 1604 
 1605 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1606   // Empty encoding
 1607 }
 1608 
 1609 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1610   return 0;
 1611 }
 1612 
 1613 #ifndef PRODUCT
 1614 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1615   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1616 }
 1617 #endif
 1618 
 1619 #ifndef PRODUCT
 1620 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1621   Compile* C = ra_-&gt;C;
 1622 
 1623   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1624 
 1625   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1626     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1627 
 1628   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1629     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1630     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1631     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1632   } else {
 1633     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1634     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1635     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1636     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1637   }
<a name="1" id="anc1"></a><span class="line-added"> 1638   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {</span>
<span class="line-added"> 1639     st-&gt;print(&quot;\n\t&quot;);</span>
<span class="line-added"> 1640     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);</span>
<span class="line-added"> 1641     st-&gt;print(&quot;dmb ishld\n\t&quot;);</span>
<span class="line-added"> 1642     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);</span>
<span class="line-added"> 1643     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);</span>
<span class="line-added"> 1644     st-&gt;print(&quot;b.eq skip&quot;);</span>
<span class="line-added"> 1645     st-&gt;print(&quot;\n\t&quot;);</span>
<span class="line-added"> 1646     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);</span>
<span class="line-added"> 1647     st-&gt;print(&quot;b skip\n\t&quot;);</span>
<span class="line-added"> 1648     st-&gt;print(&quot;guard: int\n\t&quot;);</span>
<span class="line-added"> 1649     st-&gt;print(&quot;\n\t&quot;);</span>
<span class="line-added"> 1650     st-&gt;print(&quot;skip:\n\t&quot;);</span>
<span class="line-added"> 1651   }</span>
 1652 }
 1653 #endif
 1654 
 1655 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1656   Compile* C = ra_-&gt;C;
 1657   C2_MacroAssembler _masm(&amp;cbuf);
 1658 
 1659   __ verified_entry(C, 0);
 1660   __ bind(*_verified_entry);
<a name="2" id="anc2"></a><span class="line-added"> 1661   // n.b. frame size includes space for return pc and rfp</span>
<span class="line-added"> 1662   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
<span class="line-added"> 1663   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);</span>
<span class="line-added"> 1664 </span>
<span class="line-added"> 1665   // insert a nop at the start of the prolog so we can patch in a</span>
<span class="line-added"> 1666   // branch if we need to invalidate the method later</span>
<span class="line-added"> 1667   __ nop();</span>
<span class="line-added"> 1668 </span>
<span class="line-added"> 1669   if (C-&gt;clinit_barrier_on_entry()) {</span>
<span class="line-added"> 1670     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);</span>
<span class="line-added"> 1671 </span>
<span class="line-added"> 1672     Label L_skip_barrier;</span>
<span class="line-added"> 1673 </span>
<span class="line-added"> 1674     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());</span>
<span class="line-added"> 1675     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);</span>
<span class="line-added"> 1676     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));</span>
<span class="line-added"> 1677     __ bind(L_skip_barrier);</span>
<span class="line-added"> 1678   }</span>
<span class="line-added"> 1679 </span>
<span class="line-added"> 1680   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
<span class="line-added"> 1681   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)</span>
<span class="line-added"> 1682     __ generate_stack_overflow_check(bangsize);</span>
<span class="line-added"> 1683 </span>
<span class="line-added"> 1684   __ build_frame(framesize);</span>
<span class="line-added"> 1685 </span>
<span class="line-added"> 1686   if (C-&gt;stub_function() == NULL) {</span>
<span class="line-added"> 1687     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-added"> 1688     bs-&gt;nmethod_entry_barrier(&amp;_masm);</span>
<span class="line-added"> 1689   }</span>
<span class="line-added"> 1690 </span>
<span class="line-added"> 1691   if (VerifyStackAtCalls) {</span>
<span class="line-added"> 1692     Unimplemented();</span>
<span class="line-added"> 1693   }</span>
 1694 
 1695   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1696 
 1697   if (C-&gt;has_mach_constant_base_node()) {
 1698     // NOTE: We set the table base offset here because users might be
 1699     // emitted before MachConstantBaseNode.
 1700     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1701     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1702   }
 1703 }
 1704 
 1705 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1706 {
 1707   return MachNode::size(ra_); // too many variables; just compute it
 1708                               // the hard way
 1709 }
 1710 
 1711 int MachPrologNode::reloc() const
 1712 {
 1713   return 0;
 1714 }
 1715 
 1716 //=============================================================================
 1717 
 1718 #ifndef PRODUCT
 1719 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1720   Compile* C = ra_-&gt;C;
 1721   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1722 
 1723   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1724 
 1725   if (framesize == 0) {
 1726     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1727   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1728     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1729     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1730   } else {
 1731     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1732     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1733     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1734   }
 1735 
 1736   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1737     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1738     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1739     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1740   }
 1741 }
 1742 #endif
 1743 
 1744 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1745   Compile* C = ra_-&gt;C;
 1746   C2_MacroAssembler _masm(&amp;cbuf);
 1747   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1748 
 1749   __ remove_frame(framesize);
 1750 
 1751   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1752     __ reserved_stack_check();
 1753   }
 1754 
 1755   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1756     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1757   }
 1758 }
 1759 
 1760 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1761   // Variable size. Determine dynamically.
 1762   return MachNode::size(ra_);
 1763 }
 1764 
 1765 int MachEpilogNode::reloc() const {
 1766   // Return number of relocatable values contained in this instruction.
 1767   return 1; // 1 for polling page.
 1768 }
 1769 
 1770 const Pipeline * MachEpilogNode::pipeline() const {
 1771   return MachNode::pipeline_class();
 1772 }
 1773 
 1774 //=============================================================================
 1775 
 1776 // Figure out which register class each belongs in: rc_int, rc_float or
 1777 // rc_stack.
 1778 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1779 
 1780 static enum RC rc_class(OptoReg::Name reg) {
 1781 
 1782   if (reg == OptoReg::Bad) {
 1783     return rc_bad;
 1784   }
 1785 
 1786   // we have 30 int registers * 2 halves
 1787   // (rscratch1 and rscratch2 are omitted)
 1788   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1789 
 1790   if (reg &lt; slots_of_int_registers) {
 1791     return rc_int;
 1792   }
 1793 
 1794   // we have 32 float register * 4 halves
 1795   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1796     return rc_float;
 1797   }
 1798 
 1799   // Between float regs &amp; stack is the flags regs.
 1800   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1801 
 1802   return rc_stack;
 1803 }
 1804 
 1805 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1806   Compile* C = ra_-&gt;C;
 1807 
 1808   // Get registers to move.
 1809   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1810   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1811   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1812   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1813 
 1814   enum RC src_hi_rc = rc_class(src_hi);
 1815   enum RC src_lo_rc = rc_class(src_lo);
 1816   enum RC dst_hi_rc = rc_class(dst_hi);
 1817   enum RC dst_lo_rc = rc_class(dst_lo);
 1818 
 1819   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1820 
 1821   if (src_hi != OptoReg::Bad) {
 1822     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1823            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1824            &quot;expected aligned-adjacent pairs&quot;);
 1825   }
 1826 
 1827   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1828     return 0;            // Self copy, no move.
 1829   }
 1830 
 1831   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1832               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1833   int src_offset = ra_-&gt;reg2offset(src_lo);
 1834   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1835 
 1836   if (bottom_type()-&gt;isa_vect() != NULL) {
 1837     uint ireg = ideal_reg();
 1838     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1839     if (cbuf) {
 1840       C2_MacroAssembler _masm(cbuf);
 1841       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1842       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1843         // stack-&gt;stack
 1844         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1845         if (ireg == Op_VecD) {
 1846           __ unspill(rscratch1, true, src_offset);
 1847           __ spill(rscratch1, true, dst_offset);
 1848         } else {
 1849           __ spill_copy128(src_offset, dst_offset);
 1850         }
 1851       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1852         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1853                ireg == Op_VecD ? __ T8B : __ T16B,
 1854                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1855       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1856         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1857                        ireg == Op_VecD ? __ D : __ Q,
 1858                        ra_-&gt;reg2offset(dst_lo));
 1859       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1860         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1861                        ireg == Op_VecD ? __ D : __ Q,
 1862                        ra_-&gt;reg2offset(src_lo));
 1863       } else {
 1864         ShouldNotReachHere();
 1865       }
 1866     }
 1867   } else if (cbuf) {
 1868     C2_MacroAssembler _masm(cbuf);
 1869     switch (src_lo_rc) {
 1870     case rc_int:
 1871       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1872         if (is64) {
 1873             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1874                    as_Register(Matcher::_regEncode[src_lo]));
 1875         } else {
 1876             C2_MacroAssembler _masm(cbuf);
 1877             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1878                     as_Register(Matcher::_regEncode[src_lo]));
 1879         }
 1880       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1881         if (is64) {
 1882             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1883                      as_Register(Matcher::_regEncode[src_lo]));
 1884         } else {
 1885             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1886                      as_Register(Matcher::_regEncode[src_lo]));
 1887         }
 1888       } else {                    // gpr --&gt; stack spill
 1889         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1890         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1891       }
 1892       break;
 1893     case rc_float:
 1894       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1895         if (is64) {
 1896             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1897                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1898         } else {
 1899             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1900                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1901         }
 1902       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1903           if (cbuf) {
 1904             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1905                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1906         } else {
 1907             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1908                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1909         }
 1910       } else {                    // fpr --&gt; stack spill
 1911         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1912         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1913                  is64 ? __ D : __ S, dst_offset);
 1914       }
 1915       break;
 1916     case rc_stack:
 1917       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1918         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1919       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1920         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1921                    is64 ? __ D : __ S, src_offset);
 1922       } else {                    // stack --&gt; stack copy
 1923         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1924         __ unspill(rscratch1, is64, src_offset);
 1925         __ spill(rscratch1, is64, dst_offset);
 1926       }
 1927       break;
 1928     default:
 1929       assert(false, &quot;bad rc_class for spill&quot;);
 1930       ShouldNotReachHere();
 1931     }
 1932   }
 1933 
 1934   if (st) {
 1935     st-&gt;print(&quot;spill &quot;);
 1936     if (src_lo_rc == rc_stack) {
 1937       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1938     } else {
 1939       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1940     }
 1941     if (dst_lo_rc == rc_stack) {
 1942       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1943     } else {
 1944       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1945     }
 1946     if (bottom_type()-&gt;isa_vect() != NULL) {
 1947       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1948     } else {
 1949       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1950     }
 1951   }
 1952 
 1953   return 0;
 1954 
 1955 }
 1956 
 1957 #ifndef PRODUCT
 1958 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1959   if (!ra_)
 1960     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1961   else
 1962     implementation(NULL, ra_, false, st);
 1963 }
 1964 #endif
 1965 
 1966 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1967   implementation(&amp;cbuf, ra_, false, NULL);
 1968 }
 1969 
 1970 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1971   return MachNode::size(ra_);
 1972 }
 1973 
 1974 //=============================================================================
 1975 
 1976 #ifndef PRODUCT
 1977 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1978   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1979   int reg = ra_-&gt;get_reg_first(this);
 1980   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1981             Matcher::regName[reg], offset);
 1982 }
 1983 #endif
 1984 
 1985 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1986   C2_MacroAssembler _masm(&amp;cbuf);
 1987 
 1988   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1989   int reg    = ra_-&gt;get_encode(this);
 1990 
 1991   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1992     __ add(as_Register(reg), sp, offset);
 1993   } else {
 1994     ShouldNotReachHere();
 1995   }
 1996 }
 1997 
 1998 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1999   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 2000   return 4;
 2001 }
 2002 
 2003 ///=============================================================================
 2004 #ifndef PRODUCT
 2005 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 2006 {
 2007   st-&gt;print_cr(&quot;# MachVEPNode&quot;);
 2008   if (!_verified) {
 2009     st-&gt;print_cr(&quot;\t load_class&quot;);
 2010   } else {
 2011     st-&gt;print_cr(&quot;\t unpack_value_arg&quot;);
 2012   }
 2013 }
 2014 #endif
 2015 
 2016 void MachVEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2017 {
 2018   MacroAssembler _masm(&amp;cbuf);
 2019 
 2020   if (!_verified) {
 2021     Label skip;
 2022     __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2023     __ br(Assembler::EQ, skip);
 2024       __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2025     __ bind(skip);
 2026 
 2027   } else {
 2028     // Unpack value type args passed as oop and then jump to
 2029     // the verified entry point (skipping the unverified entry).
 2030     __ unpack_value_args(ra_-&gt;C, _receiver_only);
 2031     __ b(*_verified_entry);
 2032   }
 2033 }
 2034 
 2035 
 2036 uint MachVEPNode::size(PhaseRegAlloc* ra_) const
 2037 {
 2038   return MachNode::size(ra_); // too many variables; just compute it the hard way
 2039 }
 2040 
 2041 
 2042 //=============================================================================
 2043 #ifndef PRODUCT
 2044 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 2045 {
 2046   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 2047   if (UseCompressedClassPointers) {
 2048     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2049     if (CompressedKlassPointers::shift() != 0) {
 2050       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 2051     }
 2052   } else {
 2053    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2054   }
 2055   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 2056   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2057 }
 2058 #endif
 2059 
 2060 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2061 {
 2062   // This is the unverified entry point.
 2063   C2_MacroAssembler _masm(&amp;cbuf);
 2064   Label skip;
 2065 
 2066   // UseCompressedClassPointers logic are inside cmp_klass
 2067   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2068 
 2069   // TODO
 2070   // can we avoid this skip and still use a reloc?
 2071   __ br(Assembler::EQ, skip);
 2072   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2073   __ bind(skip);
 2074 }
 2075 
 2076 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2077 {
 2078   return MachNode::size(ra_);
 2079 }
 2080 
 2081 // REQUIRED EMIT CODE
 2082 
 2083 //=============================================================================
 2084 
 2085 // Emit exception handler code.
 2086 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2087 {
 2088   // mov rscratch1 #exception_blob_entry_point
 2089   // br rscratch1
 2090   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2091   // That&#39;s why we must use the macroassembler to generate a handler.
 2092   C2_MacroAssembler _masm(&amp;cbuf);
 2093   address base = __ start_a_stub(size_exception_handler());
 2094   if (base == NULL) {
 2095     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2096     return 0;  // CodeBuffer::expand failed
 2097   }
 2098   int offset = __ offset();
 2099   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2100   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2101   __ end_a_stub();
 2102   return offset;
 2103 }
 2104 
 2105 // Emit deopt handler code.
 2106 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2107 {
 2108   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2109   // That&#39;s why we must use the macroassembler to generate a handler.
 2110   C2_MacroAssembler _masm(&amp;cbuf);
 2111   address base = __ start_a_stub(size_deopt_handler());
 2112   if (base == NULL) {
 2113     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2114     return 0;  // CodeBuffer::expand failed
 2115   }
 2116   int offset = __ offset();
 2117 
 2118   __ adr(lr, __ pc());
 2119   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2120 
 2121   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2122   __ end_a_stub();
 2123   return offset;
 2124 }
 2125 
 2126 // REQUIRED MATCHER CODE
 2127 
 2128 //=============================================================================
 2129 
 2130 const bool Matcher::match_rule_supported(int opcode) {
 2131   if (!has_match_rule(opcode))
 2132     return false;
 2133 
 2134   bool ret_value = true;
 2135   switch (opcode) {
 2136     case Op_CacheWB:
 2137     case Op_CacheWBPreSync:
 2138     case Op_CacheWBPostSync:
 2139       if (!VM_Version::supports_data_cache_line_flush()) {
 2140         ret_value = false;
 2141       }
 2142       break;
 2143   }
 2144 
 2145   return ret_value; // Per default match rules are supported.
 2146 }
 2147 
 2148 // Identify extra cases that we might want to provide match rules for vector nodes and
 2149 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2150 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2151   if (!match_rule_supported(opcode)) {
 2152     return false;
 2153   }
 2154 
 2155   // Special cases which require vector length
 2156   switch (opcode) {
 2157     case Op_MulAddVS2VI: {
 2158       if (vlen != 4) {
 2159         return false;
 2160       }
 2161       break;
 2162     }
 2163   }
 2164 
 2165   return true; // Per default match rules are supported.
 2166 }
 2167 
 2168 const bool Matcher::has_predicated_vectors(void) {
 2169   return false;
 2170 }
 2171 
 2172 const int Matcher::float_pressure(int default_pressure_threshold) {
 2173   return default_pressure_threshold;
 2174 }
 2175 
 2176 int Matcher::regnum_to_fpu_offset(int regnum)
 2177 {
 2178   Unimplemented();
 2179   return 0;
 2180 }
 2181 
 2182 // Is this branch offset short enough that a short branch can be used?
 2183 //
 2184 // NOTE: If the platform does not provide any short branch variants, then
 2185 //       this method should return false for offset 0.
 2186 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2187   // The passed offset is relative to address of the branch.
 2188 
 2189   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2190 }
 2191 
 2192 const bool Matcher::isSimpleConstant64(jlong value) {
 2193   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2194   // Probably always true, even if a temp register is required.
 2195   return true;
 2196 }
 2197 
 2198 // true just means we have fast l2f conversion
 2199 const bool Matcher::convL2FSupported(void) {
 2200   return true;
 2201 }
 2202 
 2203 // Vector width in bytes.
 2204 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2205   int size = MIN2(16,(int)MaxVectorSize);
 2206   // Minimum 2 values in vector
 2207   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2208   // But never &lt; 4
 2209   if (size &lt; 4) size = 0;
 2210   return size;
 2211 }
 2212 
 2213 // Limits on vector size (number of elements) loaded into vector.
 2214 const int Matcher::max_vector_size(const BasicType bt) {
 2215   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2216 }
 2217 const int Matcher::min_vector_size(const BasicType bt) {
 2218 //  For the moment limit the vector size to 8 bytes
 2219     int size = 8 / type2aelembytes(bt);
 2220     if (size &lt; 2) size = 2;
 2221     return size;
 2222 }
 2223 
 2224 // Vector ideal reg.
 2225 const uint Matcher::vector_ideal_reg(int len) {
 2226   switch(len) {
 2227     case  8: return Op_VecD;
 2228     case 16: return Op_VecX;
 2229   }
 2230   ShouldNotReachHere();
 2231   return 0;
 2232 }
 2233 
 2234 // AES support not yet implemented
 2235 const bool Matcher::pass_original_key_for_aes() {
 2236   return false;
 2237 }
 2238 
 2239 // aarch64 supports misaligned vectors store/load.
 2240 const bool Matcher::misaligned_vectors_ok() {
 2241   return true;
 2242 }
 2243 
 2244 // false =&gt; size gets scaled to BytesPerLong, ok.
 2245 const bool Matcher::init_array_count_is_in_bytes = false;
 2246 
 2247 // Use conditional move (CMOVL)
 2248 const int Matcher::long_cmove_cost() {
 2249   // long cmoves are no more expensive than int cmoves
 2250   return 0;
 2251 }
 2252 
 2253 const int Matcher::float_cmove_cost() {
 2254   // float cmoves are no more expensive than int cmoves
 2255   return 0;
 2256 }
 2257 
 2258 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2259 const bool Matcher::require_postalloc_expand = false;
 2260 
 2261 // Do we need to mask the count passed to shift instructions or does
 2262 // the cpu only look at the lower 5/6 bits anyway?
 2263 const bool Matcher::need_masked_shift_count = false;
 2264 
 2265 // No support for generic vector operands.
 2266 const bool Matcher::supports_generic_vector_operands  = false;
 2267 
 2268 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2269   ShouldNotReachHere(); // generic vector operands not supported
 2270   return NULL;
 2271 }
 2272 
 2273 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2274   ShouldNotReachHere();  // generic vector operands not supported
 2275   return false;
 2276 }
 2277 
 2278 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2279   ShouldNotReachHere();  // generic vector operands not supported
 2280   return false;
 2281 }
 2282 
 2283 // This affects two different things:
 2284 //  - how Decode nodes are matched
 2285 //  - how ImplicitNullCheck opportunities are recognized
 2286 // If true, the matcher will try to remove all Decodes and match them
 2287 // (as operands) into nodes. NullChecks are not prepared to deal with
 2288 // Decodes by final_graph_reshaping().
 2289 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2290 // for a NullCheck. The matcher matches the Decode node into a register.
 2291 // Implicit_null_check optimization moves the Decode along with the
 2292 // memory operation back up before the NullCheck.
 2293 bool Matcher::narrow_oop_use_complex_address() {
 2294   return CompressedOops::shift() == 0;
 2295 }
 2296 
 2297 bool Matcher::narrow_klass_use_complex_address() {
 2298 // TODO
 2299 // decide whether we need to set this to true
 2300   return false;
 2301 }
 2302 
 2303 bool Matcher::const_oop_prefer_decode() {
 2304   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2305   return CompressedOops::base() == NULL;
 2306 }
 2307 
 2308 bool Matcher::const_klass_prefer_decode() {
 2309   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2310   return CompressedKlassPointers::base() == NULL;
 2311 }
 2312 
 2313 // Is it better to copy float constants, or load them directly from
 2314 // memory?  Intel can load a float constant from a direct address,
 2315 // requiring no extra registers.  Most RISCs will have to materialize
 2316 // an address into a register first, so they would do better to copy
 2317 // the constant from stack.
 2318 const bool Matcher::rematerialize_float_constants = false;
 2319 
 2320 // If CPU can load and store mis-aligned doubles directly then no
 2321 // fixup is needed.  Else we split the double into 2 integer pieces
 2322 // and move it piece-by-piece.  Only happens when passing doubles into
 2323 // C code as the Java calling convention forces doubles to be aligned.
 2324 const bool Matcher::misaligned_doubles_ok = true;
 2325 
 2326 // No-op on amd64
 2327 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2328   Unimplemented();
 2329 }
 2330 
 2331 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2332 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2333 
 2334 // Are floats converted to double when stored to stack during
 2335 // deoptimization?
 2336 bool Matcher::float_in_double() { return false; }
 2337 
 2338 // Do ints take an entire long register or just half?
 2339 // The relevant question is how the int is callee-saved:
 2340 // the whole long is written but de-opt&#39;ing will have to extract
 2341 // the relevant 32 bits.
 2342 const bool Matcher::int_in_long = true;
 2343 
 2344 // Return whether or not this register is ever used as an argument.
 2345 // This function is used on startup to build the trampoline stubs in
 2346 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2347 // call in the trampoline, and arguments in those registers not be
 2348 // available to the callee.
 2349 bool Matcher::can_be_java_arg(int reg)
 2350 {
 2351   return
 2352     reg ==  R0_num || reg == R0_H_num ||
 2353     reg ==  R1_num || reg == R1_H_num ||
 2354     reg ==  R2_num || reg == R2_H_num ||
 2355     reg ==  R3_num || reg == R3_H_num ||
 2356     reg ==  R4_num || reg == R4_H_num ||
 2357     reg ==  R5_num || reg == R5_H_num ||
 2358     reg ==  R6_num || reg == R6_H_num ||
 2359     reg ==  R7_num || reg == R7_H_num ||
 2360     reg ==  V0_num || reg == V0_H_num ||
 2361     reg ==  V1_num || reg == V1_H_num ||
 2362     reg ==  V2_num || reg == V2_H_num ||
 2363     reg ==  V3_num || reg == V3_H_num ||
 2364     reg ==  V4_num || reg == V4_H_num ||
 2365     reg ==  V5_num || reg == V5_H_num ||
 2366     reg ==  V6_num || reg == V6_H_num ||
 2367     reg ==  V7_num || reg == V7_H_num;
 2368 }
 2369 
 2370 bool Matcher::is_spillable_arg(int reg)
 2371 {
 2372   return can_be_java_arg(reg);
 2373 }
 2374 
 2375 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2376   return false;
 2377 }
 2378 
 2379 RegMask Matcher::divI_proj_mask() {
 2380   ShouldNotReachHere();
 2381   return RegMask();
 2382 }
 2383 
 2384 // Register for MODI projection of divmodI.
 2385 RegMask Matcher::modI_proj_mask() {
 2386   ShouldNotReachHere();
 2387   return RegMask();
 2388 }
 2389 
 2390 // Register for DIVL projection of divmodL.
 2391 RegMask Matcher::divL_proj_mask() {
 2392   ShouldNotReachHere();
 2393   return RegMask();
 2394 }
 2395 
 2396 // Register for MODL projection of divmodL.
 2397 RegMask Matcher::modL_proj_mask() {
 2398   ShouldNotReachHere();
 2399   return RegMask();
 2400 }
 2401 
 2402 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2403   return FP_REG_mask();
 2404 }
 2405 
 2406 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2407   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2408     Node* u = addp-&gt;fast_out(i);
 2409     if (u-&gt;is_Mem()) {
 2410       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2411       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2412       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2413         return false;
 2414       }
 2415     }
 2416   }
 2417   return true;
 2418 }
 2419 
 2420 const bool Matcher::convi2l_type_required = false;
 2421 
 2422 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2423 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2424   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2425     mstack.push(m, Visit);           // m = ShiftCntV
 2426     return true;
 2427   }
 2428   return false;
 2429 }
 2430 
 2431 // Should the Matcher clone shifts on addressing modes, expecting them
 2432 // to be subsumed into complex addressing expressions or compute them
 2433 // into registers?
 2434 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2435   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2436     return true;
 2437   }
 2438 
 2439   Node *off = m-&gt;in(AddPNode::Offset);
 2440   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2441       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2442       // Are there other uses besides address expressions?
 2443       !is_visited(off)) {
 2444     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2445     mstack.push(off-&gt;in(2), Visit);
 2446     Node *conv = off-&gt;in(1);
 2447     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2448         // Are there other uses besides address expressions?
 2449         !is_visited(conv)) {
 2450       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2451       mstack.push(conv-&gt;in(1), Pre_Visit);
 2452     } else {
 2453       mstack.push(conv, Pre_Visit);
 2454     }
 2455     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2456     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2457     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2458     return true;
 2459   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2460              // Are there other uses besides address expressions?
 2461              !is_visited(off)) {
 2462     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2463     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2464     mstack.push(off-&gt;in(1), Pre_Visit);
 2465     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2466     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2467     return true;
 2468   }
 2469   return false;
 2470 }
 2471 
 2472 void Compile::reshape_address(AddPNode* addp) {
 2473 }
 2474 
 2475 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2476   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2477   {                                                                     \
 2478     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2479     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2480     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2481     __ INSN(REG, as_Register(BASE));                                    \
 2482   }
 2483 
 2484 
 2485 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2486   {
 2487     Address::extend scale;
 2488 
 2489     // Hooboy, this is fugly.  We need a way to communicate to the
 2490     // encoder that the index needs to be sign extended, so we have to
 2491     // enumerate all the cases.
 2492     switch (opcode) {
 2493     case INDINDEXSCALEDI2L:
 2494     case INDINDEXSCALEDI2LN:
 2495     case INDINDEXI2L:
 2496     case INDINDEXI2LN:
 2497       scale = Address::sxtw(size);
 2498       break;
 2499     default:
 2500       scale = Address::lsl(size);
 2501     }
 2502 
 2503     if (index == -1) {
 2504       return Address(base, disp);
 2505     } else {
 2506       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2507       return Address(base, as_Register(index), scale);
 2508     }
 2509   }
 2510 
 2511 
 2512 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2513 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2514 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2515 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2516                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2517 
 2518   // Used for all non-volatile memory accesses.  The use of
 2519   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2520   // offsets is something of a kludge.
 2521   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2522                         Register reg, int opcode,
 2523                         Register base, int index, int scale, int disp,
 2524                         int size_in_memory)
 2525   {
 2526     Address addr = mem2address(opcode, base, index, scale, disp);
 2527     if (addr.getMode() == Address::base_plus_offset) {
 2528       /* If we get an out-of-range offset it is a bug in the compiler,
 2529          so we assert here. */
 2530       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2531              &quot;c2 compiler bug&quot;);
 2532       /* Fix up any out-of-range offsets. */
 2533       assert_different_registers(rscratch1, base);
 2534       assert_different_registers(rscratch1, reg);
 2535       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2536     }
 2537     (masm.*insn)(reg, addr);
 2538   }
 2539 
 2540   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2541                         FloatRegister reg, int opcode,
 2542                         Register base, int index, int size, int disp,
 2543                         int size_in_memory)
 2544   {
 2545     Address::extend scale;
 2546 
 2547     switch (opcode) {
 2548     case INDINDEXSCALEDI2L:
 2549     case INDINDEXSCALEDI2LN:
 2550       scale = Address::sxtw(size);
 2551       break;
 2552     default:
 2553       scale = Address::lsl(size);
 2554     }
 2555 
 2556     if (index == -1) {
 2557       /* If we get an out-of-range offset it is a bug in the compiler,
 2558          so we assert here. */
 2559       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2560       /* Fix up any out-of-range offsets. */
 2561       assert_different_registers(rscratch1, base);
 2562       Address addr = Address(base, disp);
 2563       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2564       (masm.*insn)(reg, addr);
 2565     } else {
 2566       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2567       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2568     }
 2569   }
 2570 
 2571   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2572                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2573                         int opcode, Register base, int index, int size, int disp)
 2574   {
 2575     if (index == -1) {
 2576       (masm.*insn)(reg, T, Address(base, disp));
 2577     } else {
 2578       assert(disp == 0, &quot;unsupported address mode&quot;);
 2579       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2580     }
 2581   }
 2582 
 2583 %}
 2584 
 2585 
 2586 
 2587 //----------ENCODING BLOCK-----------------------------------------------------
 2588 // This block specifies the encoding classes used by the compiler to
 2589 // output byte streams.  Encoding classes are parameterized macros
 2590 // used by Machine Instruction Nodes in order to generate the bit
 2591 // encoding of the instruction.  Operands specify their base encoding
 2592 // interface with the interface keyword.  There are currently
 2593 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2594 // COND_INTER.  REG_INTER causes an operand to generate a function
 2595 // which returns its register number when queried.  CONST_INTER causes
 2596 // an operand to generate a function which returns the value of the
 2597 // constant when queried.  MEMORY_INTER causes an operand to generate
 2598 // four functions which return the Base Register, the Index Register,
 2599 // the Scale Value, and the Offset Value of the operand when queried.
 2600 // COND_INTER causes an operand to generate six functions which return
 2601 // the encoding code (ie - encoding bits for the instruction)
 2602 // associated with each basic boolean condition for a conditional
 2603 // instruction.
 2604 //
 2605 // Instructions specify two basic values for encoding.  Again, a
 2606 // function is available to check if the constant displacement is an
 2607 // oop. They use the ins_encode keyword to specify their encoding
 2608 // classes (which must be a sequence of enc_class names, and their
 2609 // parameters, specified in the encoding block), and they use the
 2610 // opcode keyword to specify, in order, their primary, secondary, and
 2611 // tertiary opcode.  Only the opcode sections which a particular
 2612 // instruction needs for encoding need to be specified.
 2613 encode %{
 2614   // Build emit functions for each basic byte or larger field in the
 2615   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2616   // from C++ code in the enc_class source block.  Emit functions will
 2617   // live in the main source block for now.  In future, we can
 2618   // generalize this by adding a syntax that specifies the sizes of
 2619   // fields in an order, so that the adlc can build the emit functions
 2620   // automagically
 2621 
 2622   // catch all for unimplemented encodings
 2623   enc_class enc_unimplemented %{
 2624     C2_MacroAssembler _masm(&amp;cbuf);
 2625     __ unimplemented(&quot;C2 catch all&quot;);
 2626   %}
 2627 
 2628   // BEGIN Non-volatile memory access
 2629 
 2630   // This encoding class is generated automatically from ad_encode.m4.
 2631   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2632   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2633     Register dst_reg = as_Register($dst$$reg);
 2634     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2635                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2636   %}
 2637 
 2638   // This encoding class is generated automatically from ad_encode.m4.
 2639   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2640   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2641     Register dst_reg = as_Register($dst$$reg);
 2642     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2643                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2644   %}
 2645 
 2646   // This encoding class is generated automatically from ad_encode.m4.
 2647   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2648   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2649     Register dst_reg = as_Register($dst$$reg);
 2650     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2651                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2652   %}
 2653 
 2654   // This encoding class is generated automatically from ad_encode.m4.
 2655   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2656   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2657     Register dst_reg = as_Register($dst$$reg);
 2658     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2659                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2660   %}
 2661 
 2662   // This encoding class is generated automatically from ad_encode.m4.
 2663   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2664   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2665     Register dst_reg = as_Register($dst$$reg);
 2666     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2667                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2668   %}
 2669 
 2670   // This encoding class is generated automatically from ad_encode.m4.
 2671   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2672   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2673     Register dst_reg = as_Register($dst$$reg);
 2674     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2675                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2676   %}
 2677 
 2678   // This encoding class is generated automatically from ad_encode.m4.
 2679   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2680   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2681     Register dst_reg = as_Register($dst$$reg);
 2682     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2683                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2684   %}
 2685 
 2686   // This encoding class is generated automatically from ad_encode.m4.
 2687   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2688   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2689     Register dst_reg = as_Register($dst$$reg);
 2690     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2691                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2692   %}
 2693 
 2694   // This encoding class is generated automatically from ad_encode.m4.
 2695   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2696   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2697     Register dst_reg = as_Register($dst$$reg);
 2698     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2699                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2700   %}
 2701 
 2702   // This encoding class is generated automatically from ad_encode.m4.
 2703   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2704   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2705     Register dst_reg = as_Register($dst$$reg);
 2706     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2707                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2708   %}
 2709 
 2710   // This encoding class is generated automatically from ad_encode.m4.
 2711   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2712   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2713     Register dst_reg = as_Register($dst$$reg);
 2714     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2715                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2716   %}
 2717 
 2718   // This encoding class is generated automatically from ad_encode.m4.
 2719   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2720   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2721     Register dst_reg = as_Register($dst$$reg);
 2722     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2723                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2724   %}
 2725 
 2726   // This encoding class is generated automatically from ad_encode.m4.
 2727   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2728   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2729     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2730     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2731                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2732   %}
 2733 
 2734   // This encoding class is generated automatically from ad_encode.m4.
 2735   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2736   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2737     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2738     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2739                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2740   %}
 2741 
 2742   // This encoding class is generated automatically from ad_encode.m4.
 2743   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2744   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2745     Register src_reg = as_Register($src$$reg);
 2746     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2747                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2748   %}
 2749 
 2750   // This encoding class is generated automatically from ad_encode.m4.
 2751   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2752   enc_class aarch64_enc_strb0(memory1 mem) %{
 2753     C2_MacroAssembler _masm(&amp;cbuf);
 2754     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2755                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2756   %}
 2757 
 2758   // This encoding class is generated automatically from ad_encode.m4.
 2759   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2760   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2761     Register src_reg = as_Register($src$$reg);
 2762     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2763                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2764   %}
 2765 
 2766   // This encoding class is generated automatically from ad_encode.m4.
 2767   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2768   enc_class aarch64_enc_strh0(memory2 mem) %{
 2769     C2_MacroAssembler _masm(&amp;cbuf);
 2770     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2771                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2772   %}
 2773 
 2774   // This encoding class is generated automatically from ad_encode.m4.
 2775   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2776   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2777     Register src_reg = as_Register($src$$reg);
 2778     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2779                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2780   %}
 2781 
 2782   // This encoding class is generated automatically from ad_encode.m4.
 2783   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2784   enc_class aarch64_enc_strw0(memory4 mem) %{
 2785     C2_MacroAssembler _masm(&amp;cbuf);
 2786     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2787                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2788   %}
 2789 
 2790   // This encoding class is generated automatically from ad_encode.m4.
 2791   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2792   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2793     Register src_reg = as_Register($src$$reg);
 2794     // we sometimes get asked to store the stack pointer into the
 2795     // current thread -- we cannot do that directly on AArch64
 2796     if (src_reg == r31_sp) {
 2797       C2_MacroAssembler _masm(&amp;cbuf);
 2798       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2799       __ mov(rscratch2, sp);
 2800       src_reg = rscratch2;
 2801     }
 2802     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2803                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2804   %}
 2805 
 2806   // This encoding class is generated automatically from ad_encode.m4.
 2807   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2808   enc_class aarch64_enc_str0(memory8 mem) %{
 2809     C2_MacroAssembler _masm(&amp;cbuf);
 2810     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2811                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2812   %}
 2813 
 2814   // This encoding class is generated automatically from ad_encode.m4.
 2815   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2816   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2817     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2818     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2819                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2820   %}
 2821 
 2822   // This encoding class is generated automatically from ad_encode.m4.
 2823   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2824   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2825     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2826     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2827                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2828   %}
 2829 
 2830   // This encoding class is generated automatically from ad_encode.m4.
 2831   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2832   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2833     C2_MacroAssembler _masm(&amp;cbuf);
 2834     address con = (address)$src$$constant;
 2835     // need to do this the hard way until we can manage relocs
 2836     // for 32 bit constants
 2837     __ movoop(rscratch2, (jobject)con);
 2838     if (con) __ encode_heap_oop_not_null(rscratch2);
 2839     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2840                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2841   %}
 2842 
 2843   // This encoding class is generated automatically from ad_encode.m4.
 2844   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2845   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2846     C2_MacroAssembler _masm(&amp;cbuf);
 2847     address con = (address)$src$$constant;
 2848     // need to do this the hard way until we can manage relocs
 2849     // for 32 bit constants
 2850     __ movoop(rscratch2, (jobject)con);
 2851     __ encode_klass_not_null(rscratch2);
 2852     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2853                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2854   %}
 2855 
 2856   // This encoding class is generated automatically from ad_encode.m4.
 2857   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2858   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2859       C2_MacroAssembler _masm(&amp;cbuf);
 2860       __ membar(Assembler::StoreStore);
 2861       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2862                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2863   %}
 2864 
 2865   // END Non-volatile memory access
 2866 
 2867   // Vector loads and stores
 2868   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2869     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2870     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2871        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2872   %}
 2873 
 2874   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2875     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2876     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2877        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2878   %}
 2879 
 2880   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2881     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2882     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2883        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2884   %}
 2885 
 2886   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2887     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2888     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2889        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2890   %}
 2891 
 2892   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2893     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2894     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2895        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2896   %}
 2897 
 2898   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2899     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2900     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2901        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2902   %}
 2903 
 2904   // volatile loads and stores
 2905 
 2906   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2907     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2908                  rscratch1, stlrb);
 2909   %}
 2910 
 2911   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2912     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2913                  rscratch1, stlrh);
 2914   %}
 2915 
 2916   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2917     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2918                  rscratch1, stlrw);
 2919   %}
 2920 
 2921 
 2922   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2923     Register dst_reg = as_Register($dst$$reg);
 2924     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2925              rscratch1, ldarb);
 2926     __ sxtbw(dst_reg, dst_reg);
 2927   %}
 2928 
 2929   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2930     Register dst_reg = as_Register($dst$$reg);
 2931     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2932              rscratch1, ldarb);
 2933     __ sxtb(dst_reg, dst_reg);
 2934   %}
 2935 
 2936   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2937     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2938              rscratch1, ldarb);
 2939   %}
 2940 
 2941   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2942     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2943              rscratch1, ldarb);
 2944   %}
 2945 
 2946   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2947     Register dst_reg = as_Register($dst$$reg);
 2948     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2949              rscratch1, ldarh);
 2950     __ sxthw(dst_reg, dst_reg);
 2951   %}
 2952 
 2953   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2954     Register dst_reg = as_Register($dst$$reg);
 2955     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2956              rscratch1, ldarh);
 2957     __ sxth(dst_reg, dst_reg);
 2958   %}
 2959 
 2960   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2961     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2962              rscratch1, ldarh);
 2963   %}
 2964 
 2965   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2966     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2967              rscratch1, ldarh);
 2968   %}
 2969 
 2970   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2971     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2972              rscratch1, ldarw);
 2973   %}
 2974 
 2975   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2976     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2977              rscratch1, ldarw);
 2978   %}
 2979 
 2980   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2981     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2982              rscratch1, ldar);
 2983   %}
 2984 
 2985   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2986     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2987              rscratch1, ldarw);
 2988     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2989   %}
 2990 
 2991   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2992     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2993              rscratch1, ldar);
 2994     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2995   %}
 2996 
 2997   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2998     Register src_reg = as_Register($src$$reg);
 2999     // we sometimes get asked to store the stack pointer into the
 3000     // current thread -- we cannot do that directly on AArch64
 3001     if (src_reg == r31_sp) {
 3002       C2_MacroAssembler _masm(&amp;cbuf);
 3003       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 3004       __ mov(rscratch2, sp);
 3005       src_reg = rscratch2;
 3006     }
 3007     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 3008                  rscratch1, stlr);
 3009   %}
 3010 
 3011   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 3012     {
 3013       C2_MacroAssembler _masm(&amp;cbuf);
 3014       FloatRegister src_reg = as_FloatRegister($src$$reg);
 3015       __ fmovs(rscratch2, src_reg);
 3016     }
 3017     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 3018                  rscratch1, stlrw);
 3019   %}
 3020 
 3021   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 3022     {
 3023       C2_MacroAssembler _masm(&amp;cbuf);
 3024       FloatRegister src_reg = as_FloatRegister($src$$reg);
 3025       __ fmovd(rscratch2, src_reg);
 3026     }
 3027     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 3028                  rscratch1, stlr);
 3029   %}
 3030 
 3031   // synchronized read/update encodings
 3032 
 3033   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 3034     C2_MacroAssembler _masm(&amp;cbuf);
 3035     Register dst_reg = as_Register($dst$$reg);
 3036     Register base = as_Register($mem$$base);
 3037     int index = $mem$$index;
 3038     int scale = $mem$$scale;
 3039     int disp = $mem$$disp;
 3040     if (index == -1) {
 3041        if (disp != 0) {
 3042         __ lea(rscratch1, Address(base, disp));
 3043         __ ldaxr(dst_reg, rscratch1);
 3044       } else {
 3045         // TODO
 3046         // should we ever get anything other than this case?
 3047         __ ldaxr(dst_reg, base);
 3048       }
 3049     } else {
 3050       Register index_reg = as_Register(index);
 3051       if (disp == 0) {
 3052         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 3053         __ ldaxr(dst_reg, rscratch1);
 3054       } else {
 3055         __ lea(rscratch1, Address(base, disp));
 3056         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3057         __ ldaxr(dst_reg, rscratch1);
 3058       }
 3059     }
 3060   %}
 3061 
 3062   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3063     C2_MacroAssembler _masm(&amp;cbuf);
 3064     Register src_reg = as_Register($src$$reg);
 3065     Register base = as_Register($mem$$base);
 3066     int index = $mem$$index;
 3067     int scale = $mem$$scale;
 3068     int disp = $mem$$disp;
 3069     if (index == -1) {
 3070        if (disp != 0) {
 3071         __ lea(rscratch2, Address(base, disp));
 3072         __ stlxr(rscratch1, src_reg, rscratch2);
 3073       } else {
 3074         // TODO
 3075         // should we ever get anything other than this case?
 3076         __ stlxr(rscratch1, src_reg, base);
 3077       }
 3078     } else {
 3079       Register index_reg = as_Register(index);
 3080       if (disp == 0) {
 3081         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3082         __ stlxr(rscratch1, src_reg, rscratch2);
 3083       } else {
 3084         __ lea(rscratch2, Address(base, disp));
 3085         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3086         __ stlxr(rscratch1, src_reg, rscratch2);
 3087       }
 3088     }
 3089     __ cmpw(rscratch1, zr);
 3090   %}
 3091 
 3092   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3093     C2_MacroAssembler _masm(&amp;cbuf);
 3094     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3095     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3096                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3097                /*weak*/ false, noreg);
 3098   %}
 3099 
 3100   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3101     C2_MacroAssembler _masm(&amp;cbuf);
 3102     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3103     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3104                Assembler::word, /*acquire*/ false, /*release*/ true,
 3105                /*weak*/ false, noreg);
 3106   %}
 3107 
 3108   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3109     C2_MacroAssembler _masm(&amp;cbuf);
 3110     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3111     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3112                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3113                /*weak*/ false, noreg);
 3114   %}
 3115 
 3116   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3117     C2_MacroAssembler _masm(&amp;cbuf);
 3118     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3119     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3120                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3121                /*weak*/ false, noreg);
 3122   %}
 3123 
 3124 
 3125   // The only difference between aarch64_enc_cmpxchg and
 3126   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3127   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3128   // lock.
 3129   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3130     C2_MacroAssembler _masm(&amp;cbuf);
 3131     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3132     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3133                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3134                /*weak*/ false, noreg);
 3135   %}
 3136 
 3137   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3138     C2_MacroAssembler _masm(&amp;cbuf);
 3139     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3140     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3141                Assembler::word, /*acquire*/ true, /*release*/ true,
 3142                /*weak*/ false, noreg);
 3143   %}
 3144 
 3145   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3146     C2_MacroAssembler _masm(&amp;cbuf);
 3147     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3148     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3149                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3150                /*weak*/ false, noreg);
 3151   %}
 3152 
 3153   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3154     C2_MacroAssembler _masm(&amp;cbuf);
 3155     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3156     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3157                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3158                /*weak*/ false, noreg);
 3159   %}
 3160 
 3161   // auxiliary used for CompareAndSwapX to set result register
 3162   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3163     C2_MacroAssembler _masm(&amp;cbuf);
 3164     Register res_reg = as_Register($res$$reg);
 3165     __ cset(res_reg, Assembler::EQ);
 3166   %}
 3167 
 3168   // prefetch encodings
 3169 
 3170   enc_class aarch64_enc_prefetchw(memory mem) %{
 3171     C2_MacroAssembler _masm(&amp;cbuf);
 3172     Register base = as_Register($mem$$base);
 3173     int index = $mem$$index;
 3174     int scale = $mem$$scale;
 3175     int disp = $mem$$disp;
 3176     if (index == -1) {
 3177       __ prfm(Address(base, disp), PSTL1KEEP);
 3178     } else {
 3179       Register index_reg = as_Register(index);
 3180       if (disp == 0) {
 3181         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3182       } else {
 3183         __ lea(rscratch1, Address(base, disp));
 3184 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3185       }
 3186     }
 3187   %}
 3188 
 3189   /// mov envcodings
 3190 
 3191   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3192     C2_MacroAssembler _masm(&amp;cbuf);
 3193     u_int32_t con = (u_int32_t)$src$$constant;
 3194     Register dst_reg = as_Register($dst$$reg);
 3195     if (con == 0) {
 3196       __ movw(dst_reg, zr);
 3197     } else {
 3198       __ movw(dst_reg, con);
 3199     }
 3200   %}
 3201 
 3202   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3203     C2_MacroAssembler _masm(&amp;cbuf);
 3204     Register dst_reg = as_Register($dst$$reg);
 3205     u_int64_t con = (u_int64_t)$src$$constant;
 3206     if (con == 0) {
 3207       __ mov(dst_reg, zr);
 3208     } else {
 3209       __ mov(dst_reg, con);
 3210     }
 3211   %}
 3212 
 3213   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3214     C2_MacroAssembler _masm(&amp;cbuf);
 3215     Register dst_reg = as_Register($dst$$reg);
 3216     address con = (address)$src$$constant;
 3217     if (con == NULL || con == (address)1) {
 3218       ShouldNotReachHere();
 3219     } else {
 3220       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3221       if (rtype == relocInfo::oop_type) {
 3222         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3223       } else if (rtype == relocInfo::metadata_type) {
 3224         __ mov_metadata(dst_reg, (Metadata*)con);
 3225       } else {
 3226         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3227         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3228           __ mov(dst_reg, con);
 3229         } else {
 3230           unsigned long offset;
 3231           __ adrp(dst_reg, con, offset);
 3232           __ add(dst_reg, dst_reg, offset);
 3233         }
 3234       }
 3235     }
 3236   %}
 3237 
 3238   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3239     C2_MacroAssembler _masm(&amp;cbuf);
 3240     Register dst_reg = as_Register($dst$$reg);
 3241     __ mov(dst_reg, zr);
 3242   %}
 3243 
 3244   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3245     C2_MacroAssembler _masm(&amp;cbuf);
 3246     Register dst_reg = as_Register($dst$$reg);
 3247     __ mov(dst_reg, (u_int64_t)1);
 3248   %}
 3249 
 3250   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3251     C2_MacroAssembler _masm(&amp;cbuf);
 3252     __ load_byte_map_base($dst$$Register);
 3253   %}
 3254 
 3255   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3256     C2_MacroAssembler _masm(&amp;cbuf);
 3257     Register dst_reg = as_Register($dst$$reg);
 3258     address con = (address)$src$$constant;
 3259     if (con == NULL) {
 3260       ShouldNotReachHere();
 3261     } else {
 3262       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3263       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3264       __ set_narrow_oop(dst_reg, (jobject)con);
 3265     }
 3266   %}
 3267 
 3268   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3269     C2_MacroAssembler _masm(&amp;cbuf);
 3270     Register dst_reg = as_Register($dst$$reg);
 3271     __ mov(dst_reg, zr);
 3272   %}
 3273 
 3274   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3275     C2_MacroAssembler _masm(&amp;cbuf);
 3276     Register dst_reg = as_Register($dst$$reg);
 3277     address con = (address)$src$$constant;
 3278     if (con == NULL) {
 3279       ShouldNotReachHere();
 3280     } else {
 3281       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3282       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3283       __ set_narrow_klass(dst_reg, (Klass *)con);
 3284     }
 3285   %}
 3286 
 3287   // arithmetic encodings
 3288 
 3289   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3290     C2_MacroAssembler _masm(&amp;cbuf);
 3291     Register dst_reg = as_Register($dst$$reg);
 3292     Register src_reg = as_Register($src1$$reg);
 3293     int32_t con = (int32_t)$src2$$constant;
 3294     // add has primary == 0, subtract has primary == 1
 3295     if ($primary) { con = -con; }
 3296     if (con &lt; 0) {
 3297       __ subw(dst_reg, src_reg, -con);
 3298     } else {
 3299       __ addw(dst_reg, src_reg, con);
 3300     }
 3301   %}
 3302 
 3303   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3304     C2_MacroAssembler _masm(&amp;cbuf);
 3305     Register dst_reg = as_Register($dst$$reg);
 3306     Register src_reg = as_Register($src1$$reg);
 3307     int32_t con = (int32_t)$src2$$constant;
 3308     // add has primary == 0, subtract has primary == 1
 3309     if ($primary) { con = -con; }
 3310     if (con &lt; 0) {
 3311       __ sub(dst_reg, src_reg, -con);
 3312     } else {
 3313       __ add(dst_reg, src_reg, con);
 3314     }
 3315   %}
 3316 
 3317   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3318     C2_MacroAssembler _masm(&amp;cbuf);
 3319    Register dst_reg = as_Register($dst$$reg);
 3320    Register src1_reg = as_Register($src1$$reg);
 3321    Register src2_reg = as_Register($src2$$reg);
 3322     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3323   %}
 3324 
 3325   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3326     C2_MacroAssembler _masm(&amp;cbuf);
 3327    Register dst_reg = as_Register($dst$$reg);
 3328    Register src1_reg = as_Register($src1$$reg);
 3329    Register src2_reg = as_Register($src2$$reg);
 3330     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3331   %}
 3332 
 3333   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3334     C2_MacroAssembler _masm(&amp;cbuf);
 3335    Register dst_reg = as_Register($dst$$reg);
 3336    Register src1_reg = as_Register($src1$$reg);
 3337    Register src2_reg = as_Register($src2$$reg);
 3338     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3339   %}
 3340 
 3341   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3342     C2_MacroAssembler _masm(&amp;cbuf);
 3343    Register dst_reg = as_Register($dst$$reg);
 3344    Register src1_reg = as_Register($src1$$reg);
 3345    Register src2_reg = as_Register($src2$$reg);
 3346     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3347   %}
 3348 
 3349   // compare instruction encodings
 3350 
 3351   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3352     C2_MacroAssembler _masm(&amp;cbuf);
 3353     Register reg1 = as_Register($src1$$reg);
 3354     Register reg2 = as_Register($src2$$reg);
 3355     __ cmpw(reg1, reg2);
 3356   %}
 3357 
 3358   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3359     C2_MacroAssembler _masm(&amp;cbuf);
 3360     Register reg = as_Register($src1$$reg);
 3361     int32_t val = $src2$$constant;
 3362     if (val &gt;= 0) {
 3363       __ subsw(zr, reg, val);
 3364     } else {
 3365       __ addsw(zr, reg, -val);
 3366     }
 3367   %}
 3368 
 3369   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3370     C2_MacroAssembler _masm(&amp;cbuf);
 3371     Register reg1 = as_Register($src1$$reg);
 3372     u_int32_t val = (u_int32_t)$src2$$constant;
 3373     __ movw(rscratch1, val);
 3374     __ cmpw(reg1, rscratch1);
 3375   %}
 3376 
 3377   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3378     C2_MacroAssembler _masm(&amp;cbuf);
 3379     Register reg1 = as_Register($src1$$reg);
 3380     Register reg2 = as_Register($src2$$reg);
 3381     __ cmp(reg1, reg2);
 3382   %}
 3383 
 3384   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3385     C2_MacroAssembler _masm(&amp;cbuf);
 3386     Register reg = as_Register($src1$$reg);
 3387     int64_t val = $src2$$constant;
 3388     if (val &gt;= 0) {
 3389       __ subs(zr, reg, val);
 3390     } else if (val != -val) {
 3391       __ adds(zr, reg, -val);
 3392     } else {
 3393     // aargh, Long.MIN_VALUE is a special case
 3394       __ orr(rscratch1, zr, (u_int64_t)val);
 3395       __ subs(zr, reg, rscratch1);
 3396     }
 3397   %}
 3398 
 3399   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3400     C2_MacroAssembler _masm(&amp;cbuf);
 3401     Register reg1 = as_Register($src1$$reg);
 3402     u_int64_t val = (u_int64_t)$src2$$constant;
 3403     __ mov(rscratch1, val);
 3404     __ cmp(reg1, rscratch1);
 3405   %}
 3406 
 3407   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3408     C2_MacroAssembler _masm(&amp;cbuf);
 3409     Register reg1 = as_Register($src1$$reg);
 3410     Register reg2 = as_Register($src2$$reg);
 3411     __ cmp(reg1, reg2);
 3412   %}
 3413 
 3414   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3415     C2_MacroAssembler _masm(&amp;cbuf);
 3416     Register reg1 = as_Register($src1$$reg);
 3417     Register reg2 = as_Register($src2$$reg);
 3418     __ cmpw(reg1, reg2);
 3419   %}
 3420 
 3421   enc_class aarch64_enc_testp(iRegP src) %{
 3422     C2_MacroAssembler _masm(&amp;cbuf);
 3423     Register reg = as_Register($src$$reg);
 3424     __ cmp(reg, zr);
 3425   %}
 3426 
 3427   enc_class aarch64_enc_testn(iRegN src) %{
 3428     C2_MacroAssembler _masm(&amp;cbuf);
 3429     Register reg = as_Register($src$$reg);
 3430     __ cmpw(reg, zr);
 3431   %}
 3432 
 3433   enc_class aarch64_enc_b(label lbl) %{
 3434     C2_MacroAssembler _masm(&amp;cbuf);
 3435     Label *L = $lbl$$label;
 3436     __ b(*L);
 3437   %}
 3438 
 3439   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3440     C2_MacroAssembler _masm(&amp;cbuf);
 3441     Label *L = $lbl$$label;
 3442     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3443   %}
 3444 
 3445   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3446     C2_MacroAssembler _masm(&amp;cbuf);
 3447     Label *L = $lbl$$label;
 3448     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3449   %}
 3450 
 3451   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3452   %{
 3453      Register sub_reg = as_Register($sub$$reg);
 3454      Register super_reg = as_Register($super$$reg);
 3455      Register temp_reg = as_Register($temp$$reg);
 3456      Register result_reg = as_Register($result$$reg);
 3457 
 3458      Label miss;
 3459      C2_MacroAssembler _masm(&amp;cbuf);
 3460      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3461                                      NULL, &amp;miss,
 3462                                      /*set_cond_codes:*/ true);
 3463      if ($primary) {
 3464        __ mov(result_reg, zr);
 3465      }
 3466      __ bind(miss);
 3467   %}
 3468 
 3469   enc_class aarch64_enc_java_static_call(method meth) %{
 3470     C2_MacroAssembler _masm(&amp;cbuf);
 3471 
 3472     address addr = (address)$meth$$method;
 3473     address call;
 3474     if (!_method) {
 3475       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3476       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3477     } else {
 3478       int method_index = resolved_method_index(cbuf);
 3479       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3480                                                   : static_call_Relocation::spec(method_index);
 3481       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3482 
 3483       // Emit stub for static call
 3484       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3485       if (stub == NULL) {
 3486         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3487         return;
 3488       }
 3489     }
 3490     if (call == NULL) {
 3491       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3492       return;
 3493     }
 3494   %}
 3495 
 3496   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3497     C2_MacroAssembler _masm(&amp;cbuf);
 3498     int method_index = resolved_method_index(cbuf);
 3499     address call = __ ic_call((address)$meth$$method, method_index);
 3500     if (call == NULL) {
 3501       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3502       return;
 3503     }
 3504   %}
 3505 
 3506   enc_class aarch64_enc_call_epilog() %{
 3507     C2_MacroAssembler _masm(&amp;cbuf);
 3508     if (VerifyStackAtCalls) {
 3509       // Check that stack depth is unchanged: find majik cookie on stack
 3510       __ call_Unimplemented();
 3511     }
 3512   %}
 3513 
 3514   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3515     C2_MacroAssembler _masm(&amp;cbuf);
 3516 
 3517     // some calls to generated routines (arraycopy code) are scheduled
 3518     // by C2 as runtime calls. if so we can call them using a br (they
 3519     // will be in a reachable segment) otherwise we have to use a blr
 3520     // which loads the absolute address into a register.
 3521     address entry = (address)$meth$$method;
 3522     CodeBlob *cb = CodeCache::find_blob(entry);
 3523     if (cb) {
 3524       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3525       if (call == NULL) {
 3526         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3527         return;
 3528       }
 3529     } else {
 3530       Label retaddr;
 3531       __ adr(rscratch2, retaddr);
 3532       __ lea(rscratch1, RuntimeAddress(entry));
 3533       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3534       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3535       __ blr(rscratch1);
 3536       __ bind(retaddr);
 3537       __ add(sp, sp, 2 * wordSize);
 3538     }
 3539   %}
 3540 
 3541   enc_class aarch64_enc_rethrow() %{
 3542     C2_MacroAssembler _masm(&amp;cbuf);
 3543     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3544   %}
 3545 
 3546   enc_class aarch64_enc_ret() %{
 3547     C2_MacroAssembler _masm(&amp;cbuf);
 3548     __ ret(lr);
 3549   %}
 3550 
 3551   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3552     C2_MacroAssembler _masm(&amp;cbuf);
 3553     Register target_reg = as_Register($jump_target$$reg);
 3554     __ br(target_reg);
 3555   %}
 3556 
 3557   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3558     C2_MacroAssembler _masm(&amp;cbuf);
 3559     Register target_reg = as_Register($jump_target$$reg);
 3560     // exception oop should be in r0
 3561     // ret addr has been popped into lr
 3562     // callee expects it in r3
 3563     __ mov(r3, lr);
 3564     __ br(target_reg);
 3565   %}
 3566 
 3567   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3568     C2_MacroAssembler _masm(&amp;cbuf);
 3569     Register oop = as_Register($object$$reg);
 3570     Register box = as_Register($box$$reg);
 3571     Register disp_hdr = as_Register($tmp$$reg);
 3572     Register tmp = as_Register($tmp2$$reg);
 3573     Label cont;
 3574     Label object_has_monitor;
 3575     Label cas_failed;
 3576 
 3577     assert_different_registers(oop, box, tmp, disp_hdr);
 3578 
 3579     // Load markWord from object into displaced_header.
 3580     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3581 
 3582     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3583       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3584     }
 3585 
 3586     // Check for existing monitor
 3587     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3588 
 3589     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3590     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3591 
 3592     // Initialize the box. (Must happen before we update the object mark!)
 3593     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3594 
 3595     // Compare object markWord with an unlocked value (tmp) and if
 3596     // equal exchange the stack address of our box with object markWord.
 3597     // On failure disp_hdr contains the possibly locked markWord.
 3598     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3599                /*release*/ true, /*weak*/ false, disp_hdr);
 3600     __ br(Assembler::EQ, cont);
 3601 
 3602     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3603 
 3604     // If the compare-and-exchange succeeded, then we found an unlocked
 3605     // object, will have now locked it will continue at label cont
 3606 
 3607     __ bind(cas_failed);
 3608     // We did not see an unlocked object so try the fast recursive case.
 3609 
 3610     // Check if the owner is self by comparing the value in the
 3611     // markWord of object (disp_hdr) with the stack pointer.
 3612     __ mov(rscratch1, sp);
 3613     __ sub(disp_hdr, disp_hdr, rscratch1);
 3614     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3615     // If condition is true we are cont and hence we can store 0 as the
 3616     // displaced header in the box, which indicates that it is a recursive lock.
 3617     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3618     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3619 
 3620     __ b(cont);
 3621 
 3622     // Handle existing monitor.
 3623     __ bind(object_has_monitor);
 3624 
 3625     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3626     // otherwise m-&gt;owner may contain a thread or a stack address.
 3627     //
 3628     // Try to CAS m-&gt;owner from NULL to current thread.
 3629     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3630     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3631                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3632 
 3633     // Store a non-null value into the box to avoid looking like a re-entrant
 3634     // lock. The fast-path monitor unlock code checks for
 3635     // markWord::monitor_value so use markWord::unused_mark which has the
 3636     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3637     __ mov(tmp, (address)markWord::unused_mark().value());
 3638     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3639 
 3640     __ bind(cont);
 3641     // flag == EQ indicates success
 3642     // flag == NE indicates failure
 3643   %}
 3644 
 3645   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3646     C2_MacroAssembler _masm(&amp;cbuf);
 3647     Register oop = as_Register($object$$reg);
 3648     Register box = as_Register($box$$reg);
 3649     Register disp_hdr = as_Register($tmp$$reg);
 3650     Register tmp = as_Register($tmp2$$reg);
 3651     Label cont;
 3652     Label object_has_monitor;
 3653 
 3654     assert_different_registers(oop, box, tmp, disp_hdr);
 3655 
 3656     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3657       __ biased_locking_exit(oop, tmp, cont);
 3658     }
 3659 
 3660     // Find the lock address and load the displaced header from the stack.
 3661     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3662 
 3663     // If the displaced header is 0, we have a recursive unlock.
 3664     __ cmp(disp_hdr, zr);
 3665     __ br(Assembler::EQ, cont);
 3666 
 3667     // Handle existing monitor.
 3668     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3669     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3670 
 3671     // Check if it is still a light weight lock, this is is true if we
 3672     // see the stack address of the basicLock in the markWord of the
 3673     // object.
 3674 
 3675     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3676                /*release*/ true, /*weak*/ false, tmp);
 3677     __ b(cont);
 3678 
 3679     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3680 
 3681     // Handle existing monitor.
 3682     __ bind(object_has_monitor);
 3683     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3684     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3685     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3686     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3687     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3688     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3689     __ cmp(rscratch1, zr); // Sets flags for result
 3690     __ br(Assembler::NE, cont);
 3691 
 3692     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3693     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3694     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3695     __ cmp(rscratch1, zr); // Sets flags for result
 3696     __ cbnz(rscratch1, cont);
 3697     // need a release store here
 3698     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3699     __ stlr(zr, tmp); // set unowned
 3700 
 3701     __ bind(cont);
 3702     // flag == EQ indicates success
 3703     // flag == NE indicates failure
 3704   %}
 3705 
 3706 %}
 3707 
 3708 //----------FRAME--------------------------------------------------------------
 3709 // Definition of frame structure and management information.
 3710 //
 3711 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3712 //                             |   (to get allocators register number
 3713 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3714 //  r   CALLER     |        |
 3715 //  o     |        +--------+      pad to even-align allocators stack-slot
 3716 //  w     V        |  pad0  |        numbers; owned by CALLER
 3717 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3718 //  h     ^        |   in   |  5
 3719 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3720 //  |     |        |        |  3
 3721 //  |     |        +--------+
 3722 //  V     |        | old out|      Empty on Intel, window on Sparc
 3723 //        |    old |preserve|      Must be even aligned.
 3724 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3725 //        |        |   in   |  3   area for Intel ret address
 3726 //     Owned by    |preserve|      Empty on Sparc.
 3727 //       SELF      +--------+
 3728 //        |        |  pad2  |  2   pad to align old SP
 3729 //        |        +--------+  1
 3730 //        |        | locks  |  0
 3731 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3732 //        |        |  pad1  | 11   pad to align new SP
 3733 //        |        +--------+
 3734 //        |        |        | 10
 3735 //        |        | spills |  9   spills
 3736 //        V        |        |  8   (pad0 slot for callee)
 3737 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3738 //        ^        |  out   |  7
 3739 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3740 //     Owned by    +--------+
 3741 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3742 //        |    new |preserve|      Must be even-aligned.
 3743 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3744 //        |        |        |
 3745 //
 3746 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3747 //         known from SELF&#39;s arguments and the Java calling convention.
 3748 //         Region 6-7 is determined per call site.
 3749 // Note 2: If the calling convention leaves holes in the incoming argument
 3750 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3751 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3752 //         incoming area, as the Java calling convention is completely under
 3753 //         the control of the AD file.  Doubles can be sorted and packed to
 3754 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3755 //         varargs C calling conventions.
 3756 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3757 //         even aligned with pad0 as needed.
 3758 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3759 //           (the latter is true on Intel but is it false on AArch64?)
 3760 //         region 6-11 is even aligned; it may be padded out more so that
 3761 //         the region from SP to FP meets the minimum stack alignment.
 3762 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3763 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3764 //         SP meets the minimum alignment.
 3765 
 3766 frame %{
 3767   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3768   stack_direction(TOWARDS_LOW);
 3769 
 3770   // These three registers define part of the calling convention
 3771   // between compiled code and the interpreter.
 3772 
 3773   // Inline Cache Register or methodOop for I2C.
 3774   inline_cache_reg(R12);
 3775 
 3776   // Method Oop Register when calling interpreter.
 3777   interpreter_method_oop_reg(R12);
 3778 
 3779   // Number of stack slots consumed by locking an object
 3780   sync_stack_slots(2);
 3781 
 3782   // Compiled code&#39;s Frame Pointer
 3783   frame_pointer(R31);
 3784 
 3785   // Interpreter stores its frame pointer in a register which is
 3786   // stored to the stack by I2CAdaptors.
 3787   // I2CAdaptors convert from interpreted java to compiled java.
 3788   interpreter_frame_pointer(R29);
 3789 
 3790   // Stack alignment requirement
 3791   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3792 
 3793   // Number of stack slots between incoming argument block and the start of
 3794   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3795   // EPILOG must remove this many slots. aarch64 needs two slots for
 3796   // return address and fp.
 3797   // TODO think this is correct but check
 3798   in_preserve_stack_slots(4);
 3799 
 3800   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3801   // for calls to C.  Supports the var-args backing area for register parms.
 3802   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3803 
 3804   // The after-PROLOG location of the return address.  Location of
 3805   // return address specifies a type (REG or STACK) and a number
 3806   // representing the register number (i.e. - use a register name) or
 3807   // stack slot.
 3808   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3809   // Otherwise, it is above the locks and verification slot and alignment word
 3810   // TODO this may well be correct but need to check why that - 2 is there
 3811   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3812   // which folds in the space used for monitors
 3813   return_addr(STACK - 2 +
 3814               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3815                         Compile::current()-&gt;fixed_slots()),
 3816                        stack_alignment_in_slots()));
 3817 
 3818   // Body of function which returns an integer array locating
 3819   // arguments either in registers or in stack slots.  Passed an array
 3820   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3821   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3822   // arguments for a CALLEE.  Incoming stack arguments are
 3823   // automatically biased by the preserve_stack_slots field above.
 3824 
 3825   calling_convention
 3826   %{
 3827     // No difference between ingoing/outgoing just pass false
 3828     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3829   %}
 3830 
 3831   c_calling_convention
 3832   %{
 3833     // This is obviously always outgoing
 3834     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3835   %}
 3836 
 3837   // Location of compiled Java return values.  Same as C for now.
 3838   return_value
 3839   %{
 3840     // TODO do we allow ideal_reg == Op_RegN???
 3841     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3842            &quot;only return normal values&quot;);
 3843 
 3844     static const int lo[Op_RegL + 1] = { // enum name
 3845       0,                                 // Op_Node
 3846       0,                                 // Op_Set
 3847       R0_num,                            // Op_RegN
 3848       R0_num,                            // Op_RegI
 3849       R0_num,                            // Op_RegP
 3850       V0_num,                            // Op_RegF
 3851       V0_num,                            // Op_RegD
 3852       R0_num                             // Op_RegL
 3853     };
 3854 
 3855     static const int hi[Op_RegL + 1] = { // enum name
 3856       0,                                 // Op_Node
 3857       0,                                 // Op_Set
 3858       OptoReg::Bad,                      // Op_RegN
 3859       OptoReg::Bad,                      // Op_RegI
 3860       R0_H_num,                          // Op_RegP
 3861       OptoReg::Bad,                      // Op_RegF
 3862       V0_H_num,                          // Op_RegD
 3863       R0_H_num                           // Op_RegL
 3864     };
 3865 
 3866     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3867   %}
 3868 %}
 3869 
 3870 //----------ATTRIBUTES---------------------------------------------------------
 3871 //----------Operand Attributes-------------------------------------------------
 3872 op_attrib op_cost(1);        // Required cost attribute
 3873 
 3874 //----------Instruction Attributes---------------------------------------------
 3875 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3876 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3877 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3878                                 // a non-matching short branch variant
 3879                                 // of some long branch?
 3880 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3881                                 // be a power of 2) specifies the
 3882                                 // alignment that some part of the
 3883                                 // instruction (not necessarily the
 3884                                 // start) requires.  If &gt; 1, a
 3885                                 // compute_padding() function must be
 3886                                 // provided for the instruction
 3887 
 3888 //----------OPERANDS-----------------------------------------------------------
 3889 // Operand definitions must precede instruction definitions for correct parsing
 3890 // in the ADLC because operands constitute user defined types which are used in
 3891 // instruction definitions.
 3892 
 3893 //----------Simple Operands----------------------------------------------------
 3894 
 3895 // Integer operands 32 bit
 3896 // 32 bit immediate
 3897 operand immI()
 3898 %{
 3899   match(ConI);
 3900 
 3901   op_cost(0);
 3902   format %{ %}
 3903   interface(CONST_INTER);
 3904 %}
 3905 
 3906 // 32 bit zero
 3907 operand immI0()
 3908 %{
 3909   predicate(n-&gt;get_int() == 0);
 3910   match(ConI);
 3911 
 3912   op_cost(0);
 3913   format %{ %}
 3914   interface(CONST_INTER);
 3915 %}
 3916 
 3917 // 32 bit unit increment
 3918 operand immI_1()
 3919 %{
 3920   predicate(n-&gt;get_int() == 1);
 3921   match(ConI);
 3922 
 3923   op_cost(0);
 3924   format %{ %}
 3925   interface(CONST_INTER);
 3926 %}
 3927 
 3928 // 32 bit unit decrement
 3929 operand immI_M1()
 3930 %{
 3931   predicate(n-&gt;get_int() == -1);
 3932   match(ConI);
 3933 
 3934   op_cost(0);
 3935   format %{ %}
 3936   interface(CONST_INTER);
 3937 %}
 3938 
 3939 // Shift values for add/sub extension shift
 3940 operand immIExt()
 3941 %{
 3942   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3943   match(ConI);
 3944 
 3945   op_cost(0);
 3946   format %{ %}
 3947   interface(CONST_INTER);
 3948 %}
 3949 
 3950 operand immI_le_4()
 3951 %{
 3952   predicate(n-&gt;get_int() &lt;= 4);
 3953   match(ConI);
 3954 
 3955   op_cost(0);
 3956   format %{ %}
 3957   interface(CONST_INTER);
 3958 %}
 3959 
 3960 operand immI_31()
 3961 %{
 3962   predicate(n-&gt;get_int() == 31);
 3963   match(ConI);
 3964 
 3965   op_cost(0);
 3966   format %{ %}
 3967   interface(CONST_INTER);
 3968 %}
 3969 
 3970 operand immI_8()
 3971 %{
 3972   predicate(n-&gt;get_int() == 8);
 3973   match(ConI);
 3974 
 3975   op_cost(0);
 3976   format %{ %}
 3977   interface(CONST_INTER);
 3978 %}
 3979 
 3980 operand immI_16()
 3981 %{
 3982   predicate(n-&gt;get_int() == 16);
 3983   match(ConI);
 3984 
 3985   op_cost(0);
 3986   format %{ %}
 3987   interface(CONST_INTER);
 3988 %}
 3989 
 3990 operand immI_24()
 3991 %{
 3992   predicate(n-&gt;get_int() == 24);
 3993   match(ConI);
 3994 
 3995   op_cost(0);
 3996   format %{ %}
 3997   interface(CONST_INTER);
 3998 %}
 3999 
 4000 operand immI_32()
 4001 %{
 4002   predicate(n-&gt;get_int() == 32);
 4003   match(ConI);
 4004 
 4005   op_cost(0);
 4006   format %{ %}
 4007   interface(CONST_INTER);
 4008 %}
 4009 
 4010 operand immI_48()
 4011 %{
 4012   predicate(n-&gt;get_int() == 48);
 4013   match(ConI);
 4014 
 4015   op_cost(0);
 4016   format %{ %}
 4017   interface(CONST_INTER);
 4018 %}
 4019 
 4020 operand immI_56()
 4021 %{
 4022   predicate(n-&gt;get_int() == 56);
 4023   match(ConI);
 4024 
 4025   op_cost(0);
 4026   format %{ %}
 4027   interface(CONST_INTER);
 4028 %}
 4029 
 4030 operand immI_63()
 4031 %{
 4032   predicate(n-&gt;get_int() == 63);
 4033   match(ConI);
 4034 
 4035   op_cost(0);
 4036   format %{ %}
 4037   interface(CONST_INTER);
 4038 %}
 4039 
 4040 operand immI_64()
 4041 %{
 4042   predicate(n-&gt;get_int() == 64);
 4043   match(ConI);
 4044 
 4045   op_cost(0);
 4046   format %{ %}
 4047   interface(CONST_INTER);
 4048 %}
 4049 
 4050 operand immI_255()
 4051 %{
 4052   predicate(n-&gt;get_int() == 255);
 4053   match(ConI);
 4054 
 4055   op_cost(0);
 4056   format %{ %}
 4057   interface(CONST_INTER);
 4058 %}
 4059 
 4060 operand immI_65535()
 4061 %{
 4062   predicate(n-&gt;get_int() == 65535);
 4063   match(ConI);
 4064 
 4065   op_cost(0);
 4066   format %{ %}
 4067   interface(CONST_INTER);
 4068 %}
 4069 
 4070 operand immL_255()
 4071 %{
 4072   predicate(n-&gt;get_long() == 255L);
 4073   match(ConL);
 4074 
 4075   op_cost(0);
 4076   format %{ %}
 4077   interface(CONST_INTER);
 4078 %}
 4079 
 4080 operand immL_65535()
 4081 %{
 4082   predicate(n-&gt;get_long() == 65535L);
 4083   match(ConL);
 4084 
 4085   op_cost(0);
 4086   format %{ %}
 4087   interface(CONST_INTER);
 4088 %}
 4089 
 4090 operand immL_4294967295()
 4091 %{
 4092   predicate(n-&gt;get_long() == 4294967295L);
 4093   match(ConL);
 4094 
 4095   op_cost(0);
 4096   format %{ %}
 4097   interface(CONST_INTER);
 4098 %}
 4099 
 4100 operand immL_bitmask()
 4101 %{
 4102   predicate((n-&gt;get_long() != 0)
 4103             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4104             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4105   match(ConL);
 4106 
 4107   op_cost(0);
 4108   format %{ %}
 4109   interface(CONST_INTER);
 4110 %}
 4111 
 4112 operand immI_bitmask()
 4113 %{
 4114   predicate((n-&gt;get_int() != 0)
 4115             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4116             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4117   match(ConI);
 4118 
 4119   op_cost(0);
 4120   format %{ %}
 4121   interface(CONST_INTER);
 4122 %}
 4123 
 4124 // Scale values for scaled offset addressing modes (up to long but not quad)
 4125 operand immIScale()
 4126 %{
 4127   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4128   match(ConI);
 4129 
 4130   op_cost(0);
 4131   format %{ %}
 4132   interface(CONST_INTER);
 4133 %}
 4134 
 4135 // 26 bit signed offset -- for pc-relative branches
 4136 operand immI26()
 4137 %{
 4138   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4139   match(ConI);
 4140 
 4141   op_cost(0);
 4142   format %{ %}
 4143   interface(CONST_INTER);
 4144 %}
 4145 
 4146 // 19 bit signed offset -- for pc-relative loads
 4147 operand immI19()
 4148 %{
 4149   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4150   match(ConI);
 4151 
 4152   op_cost(0);
 4153   format %{ %}
 4154   interface(CONST_INTER);
 4155 %}
 4156 
 4157 // 12 bit unsigned offset -- for base plus immediate loads
 4158 operand immIU12()
 4159 %{
 4160   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4161   match(ConI);
 4162 
 4163   op_cost(0);
 4164   format %{ %}
 4165   interface(CONST_INTER);
 4166 %}
 4167 
 4168 operand immLU12()
 4169 %{
 4170   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4171   match(ConL);
 4172 
 4173   op_cost(0);
 4174   format %{ %}
 4175   interface(CONST_INTER);
 4176 %}
 4177 
 4178 // Offset for scaled or unscaled immediate loads and stores
 4179 operand immIOffset()
 4180 %{
 4181   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4182   match(ConI);
 4183 
 4184   op_cost(0);
 4185   format %{ %}
 4186   interface(CONST_INTER);
 4187 %}
 4188 
 4189 operand immIOffset1()
 4190 %{
 4191   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4192   match(ConI);
 4193 
 4194   op_cost(0);
 4195   format %{ %}
 4196   interface(CONST_INTER);
 4197 %}
 4198 
 4199 operand immIOffset2()
 4200 %{
 4201   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4202   match(ConI);
 4203 
 4204   op_cost(0);
 4205   format %{ %}
 4206   interface(CONST_INTER);
 4207 %}
 4208 
 4209 operand immIOffset4()
 4210 %{
 4211   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4212   match(ConI);
 4213 
 4214   op_cost(0);
 4215   format %{ %}
 4216   interface(CONST_INTER);
 4217 %}
 4218 
 4219 operand immIOffset8()
 4220 %{
 4221   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4222   match(ConI);
 4223 
 4224   op_cost(0);
 4225   format %{ %}
 4226   interface(CONST_INTER);
 4227 %}
 4228 
 4229 operand immIOffset16()
 4230 %{
 4231   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4232   match(ConI);
 4233 
 4234   op_cost(0);
 4235   format %{ %}
 4236   interface(CONST_INTER);
 4237 %}
 4238 
 4239 operand immLoffset()
 4240 %{
 4241   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4242   match(ConL);
 4243 
 4244   op_cost(0);
 4245   format %{ %}
 4246   interface(CONST_INTER);
 4247 %}
 4248 
 4249 operand immLoffset1()
 4250 %{
 4251   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4252   match(ConL);
 4253 
 4254   op_cost(0);
 4255   format %{ %}
 4256   interface(CONST_INTER);
 4257 %}
 4258 
 4259 operand immLoffset2()
 4260 %{
 4261   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4262   match(ConL);
 4263 
 4264   op_cost(0);
 4265   format %{ %}
 4266   interface(CONST_INTER);
 4267 %}
 4268 
 4269 operand immLoffset4()
 4270 %{
 4271   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4272   match(ConL);
 4273 
 4274   op_cost(0);
 4275   format %{ %}
 4276   interface(CONST_INTER);
 4277 %}
 4278 
 4279 operand immLoffset8()
 4280 %{
 4281   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4282   match(ConL);
 4283 
 4284   op_cost(0);
 4285   format %{ %}
 4286   interface(CONST_INTER);
 4287 %}
 4288 
 4289 operand immLoffset16()
 4290 %{
 4291   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4292   match(ConL);
 4293 
 4294   op_cost(0);
 4295   format %{ %}
 4296   interface(CONST_INTER);
 4297 %}
 4298 
 4299 // 32 bit integer valid for add sub immediate
 4300 operand immIAddSub()
 4301 %{
 4302   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4303   match(ConI);
 4304   op_cost(0);
 4305   format %{ %}
 4306   interface(CONST_INTER);
 4307 %}
 4308 
 4309 // 32 bit unsigned integer valid for logical immediate
 4310 // TODO -- check this is right when e.g the mask is 0x80000000
 4311 operand immILog()
 4312 %{
 4313   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4314   match(ConI);
 4315 
 4316   op_cost(0);
 4317   format %{ %}
 4318   interface(CONST_INTER);
 4319 %}
 4320 
 4321 // Integer operands 64 bit
 4322 // 64 bit immediate
 4323 operand immL()
 4324 %{
 4325   match(ConL);
 4326 
 4327   op_cost(0);
 4328   format %{ %}
 4329   interface(CONST_INTER);
 4330 %}
 4331 
 4332 // 64 bit zero
 4333 operand immL0()
 4334 %{
 4335   predicate(n-&gt;get_long() == 0);
 4336   match(ConL);
 4337 
 4338   op_cost(0);
 4339   format %{ %}
 4340   interface(CONST_INTER);
 4341 %}
 4342 
 4343 // 64 bit unit increment
 4344 operand immL_1()
 4345 %{
 4346   predicate(n-&gt;get_long() == 1);
 4347   match(ConL);
 4348 
 4349   op_cost(0);
 4350   format %{ %}
 4351   interface(CONST_INTER);
 4352 %}
 4353 
 4354 // 64 bit unit decrement
 4355 operand immL_M1()
 4356 %{
 4357   predicate(n-&gt;get_long() == -1);
 4358   match(ConL);
 4359 
 4360   op_cost(0);
 4361   format %{ %}
 4362   interface(CONST_INTER);
 4363 %}
 4364 
 4365 // 32 bit offset of pc in thread anchor
 4366 
 4367 operand immL_pc_off()
 4368 %{
 4369   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4370                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4371   match(ConL);
 4372 
 4373   op_cost(0);
 4374   format %{ %}
 4375   interface(CONST_INTER);
 4376 %}
 4377 
 4378 // 64 bit integer valid for add sub immediate
 4379 operand immLAddSub()
 4380 %{
 4381   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4382   match(ConL);
 4383   op_cost(0);
 4384   format %{ %}
 4385   interface(CONST_INTER);
 4386 %}
 4387 
 4388 // 64 bit integer valid for logical immediate
 4389 operand immLLog()
 4390 %{
 4391   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4392   match(ConL);
 4393   op_cost(0);
 4394   format %{ %}
 4395   interface(CONST_INTER);
 4396 %}
 4397 
 4398 // Long Immediate: low 32-bit mask
 4399 operand immL_32bits()
 4400 %{
 4401   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4402   match(ConL);
 4403   op_cost(0);
 4404   format %{ %}
 4405   interface(CONST_INTER);
 4406 %}
 4407 
 4408 // Pointer operands
 4409 // Pointer Immediate
 4410 operand immP()
 4411 %{
 4412   match(ConP);
 4413 
 4414   op_cost(0);
 4415   format %{ %}
 4416   interface(CONST_INTER);
 4417 %}
 4418 
 4419 // NULL Pointer Immediate
 4420 operand immP0()
 4421 %{
 4422   predicate(n-&gt;get_ptr() == 0);
 4423   match(ConP);
 4424 
 4425   op_cost(0);
 4426   format %{ %}
 4427   interface(CONST_INTER);
 4428 %}
 4429 
 4430 // Pointer Immediate One
 4431 // this is used in object initialization (initial object header)
 4432 operand immP_1()
 4433 %{
 4434   predicate(n-&gt;get_ptr() == 1);
 4435   match(ConP);
 4436 
 4437   op_cost(0);
 4438   format %{ %}
 4439   interface(CONST_INTER);
 4440 %}
 4441 
 4442 // Card Table Byte Map Base
 4443 operand immByteMapBase()
 4444 %{
 4445   // Get base of card map
 4446   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4447             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4448   match(ConP);
 4449 
 4450   op_cost(0);
 4451   format %{ %}
 4452   interface(CONST_INTER);
 4453 %}
 4454 
 4455 // Pointer Immediate Minus One
 4456 // this is used when we want to write the current PC to the thread anchor
 4457 operand immP_M1()
 4458 %{
 4459   predicate(n-&gt;get_ptr() == -1);
 4460   match(ConP);
 4461 
 4462   op_cost(0);
 4463   format %{ %}
 4464   interface(CONST_INTER);
 4465 %}
 4466 
 4467 // Pointer Immediate Minus Two
 4468 // this is used when we want to write the current PC to the thread anchor
 4469 operand immP_M2()
 4470 %{
 4471   predicate(n-&gt;get_ptr() == -2);
 4472   match(ConP);
 4473 
 4474   op_cost(0);
 4475   format %{ %}
 4476   interface(CONST_INTER);
 4477 %}
 4478 
 4479 // Float and Double operands
 4480 // Double Immediate
 4481 operand immD()
 4482 %{
 4483   match(ConD);
 4484   op_cost(0);
 4485   format %{ %}
 4486   interface(CONST_INTER);
 4487 %}
 4488 
 4489 // Double Immediate: +0.0d
 4490 operand immD0()
 4491 %{
 4492   predicate(jlong_cast(n-&gt;getd()) == 0);
 4493   match(ConD);
 4494 
 4495   op_cost(0);
 4496   format %{ %}
 4497   interface(CONST_INTER);
 4498 %}
 4499 
 4500 // constant &#39;double +0.0&#39;.
 4501 operand immDPacked()
 4502 %{
 4503   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4504   match(ConD);
 4505   op_cost(0);
 4506   format %{ %}
 4507   interface(CONST_INTER);
 4508 %}
 4509 
 4510 // Float Immediate
 4511 operand immF()
 4512 %{
 4513   match(ConF);
 4514   op_cost(0);
 4515   format %{ %}
 4516   interface(CONST_INTER);
 4517 %}
 4518 
 4519 // Float Immediate: +0.0f.
 4520 operand immF0()
 4521 %{
 4522   predicate(jint_cast(n-&gt;getf()) == 0);
 4523   match(ConF);
 4524 
 4525   op_cost(0);
 4526   format %{ %}
 4527   interface(CONST_INTER);
 4528 %}
 4529 
 4530 //
 4531 operand immFPacked()
 4532 %{
 4533   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4534   match(ConF);
 4535   op_cost(0);
 4536   format %{ %}
 4537   interface(CONST_INTER);
 4538 %}
 4539 
 4540 // Narrow pointer operands
 4541 // Narrow Pointer Immediate
 4542 operand immN()
 4543 %{
 4544   match(ConN);
 4545 
 4546   op_cost(0);
 4547   format %{ %}
 4548   interface(CONST_INTER);
 4549 %}
 4550 
 4551 // Narrow NULL Pointer Immediate
 4552 operand immN0()
 4553 %{
 4554   predicate(n-&gt;get_narrowcon() == 0);
 4555   match(ConN);
 4556 
 4557   op_cost(0);
 4558   format %{ %}
 4559   interface(CONST_INTER);
 4560 %}
 4561 
 4562 operand immNKlass()
 4563 %{
 4564   match(ConNKlass);
 4565 
 4566   op_cost(0);
 4567   format %{ %}
 4568   interface(CONST_INTER);
 4569 %}
 4570 
 4571 // Integer 32 bit Register Operands
 4572 // Integer 32 bitRegister (excludes SP)
 4573 operand iRegI()
 4574 %{
 4575   constraint(ALLOC_IN_RC(any_reg32));
 4576   match(RegI);
 4577   match(iRegINoSp);
 4578   op_cost(0);
 4579   format %{ %}
 4580   interface(REG_INTER);
 4581 %}
 4582 
 4583 // Integer 32 bit Register not Special
 4584 operand iRegINoSp()
 4585 %{
 4586   constraint(ALLOC_IN_RC(no_special_reg32));
 4587   match(RegI);
 4588   op_cost(0);
 4589   format %{ %}
 4590   interface(REG_INTER);
 4591 %}
 4592 
 4593 // Integer 64 bit Register Operands
 4594 // Integer 64 bit Register (includes SP)
 4595 operand iRegL()
 4596 %{
 4597   constraint(ALLOC_IN_RC(any_reg));
 4598   match(RegL);
 4599   match(iRegLNoSp);
 4600   op_cost(0);
 4601   format %{ %}
 4602   interface(REG_INTER);
 4603 %}
 4604 
 4605 // Integer 64 bit Register not Special
 4606 operand iRegLNoSp()
 4607 %{
 4608   constraint(ALLOC_IN_RC(no_special_reg));
 4609   match(RegL);
 4610   match(iRegL_R0);
 4611   format %{ %}
 4612   interface(REG_INTER);
 4613 %}
 4614 
 4615 // Pointer Register Operands
 4616 // Pointer Register
 4617 operand iRegP()
 4618 %{
 4619   constraint(ALLOC_IN_RC(ptr_reg));
 4620   match(RegP);
 4621   match(iRegPNoSp);
 4622   match(iRegP_R0);
 4623   //match(iRegP_R2);
 4624   //match(iRegP_R4);
 4625   //match(iRegP_R5);
 4626   match(thread_RegP);
 4627   op_cost(0);
 4628   format %{ %}
 4629   interface(REG_INTER);
 4630 %}
 4631 
 4632 // Pointer 64 bit Register not Special
 4633 operand iRegPNoSp()
 4634 %{
 4635   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4636   match(RegP);
 4637   // match(iRegP);
 4638   // match(iRegP_R0);
 4639   // match(iRegP_R2);
 4640   // match(iRegP_R4);
 4641   // match(iRegP_R5);
 4642   // match(thread_RegP);
 4643   op_cost(0);
 4644   format %{ %}
 4645   interface(REG_INTER);
 4646 %}
 4647 
 4648 // Pointer 64 bit Register R0 only
 4649 operand iRegP_R0()
 4650 %{
 4651   constraint(ALLOC_IN_RC(r0_reg));
 4652   match(RegP);
 4653   // match(iRegP);
 4654   match(iRegPNoSp);
 4655   op_cost(0);
 4656   format %{ %}
 4657   interface(REG_INTER);
 4658 %}
 4659 
 4660 // Pointer 64 bit Register R1 only
 4661 operand iRegP_R1()
 4662 %{
 4663   constraint(ALLOC_IN_RC(r1_reg));
 4664   match(RegP);
 4665   // match(iRegP);
 4666   match(iRegPNoSp);
 4667   op_cost(0);
 4668   format %{ %}
 4669   interface(REG_INTER);
 4670 %}
 4671 
 4672 // Pointer 64 bit Register R2 only
 4673 operand iRegP_R2()
 4674 %{
 4675   constraint(ALLOC_IN_RC(r2_reg));
 4676   match(RegP);
 4677   // match(iRegP);
 4678   match(iRegPNoSp);
 4679   op_cost(0);
 4680   format %{ %}
 4681   interface(REG_INTER);
 4682 %}
 4683 
 4684 // Pointer 64 bit Register R3 only
 4685 operand iRegP_R3()
 4686 %{
 4687   constraint(ALLOC_IN_RC(r3_reg));
 4688   match(RegP);
 4689   // match(iRegP);
 4690   match(iRegPNoSp);
 4691   op_cost(0);
 4692   format %{ %}
 4693   interface(REG_INTER);
 4694 %}
 4695 
 4696 // Pointer 64 bit Register R4 only
 4697 operand iRegP_R4()
 4698 %{
 4699   constraint(ALLOC_IN_RC(r4_reg));
 4700   match(RegP);
 4701   // match(iRegP);
 4702   match(iRegPNoSp);
 4703   op_cost(0);
 4704   format %{ %}
 4705   interface(REG_INTER);
 4706 %}
 4707 
 4708 // Pointer 64 bit Register R5 only
 4709 operand iRegP_R5()
 4710 %{
 4711   constraint(ALLOC_IN_RC(r5_reg));
 4712   match(RegP);
 4713   // match(iRegP);
 4714   match(iRegPNoSp);
 4715   op_cost(0);
 4716   format %{ %}
 4717   interface(REG_INTER);
 4718 %}
 4719 
 4720 // Pointer 64 bit Register R10 only
 4721 operand iRegP_R10()
 4722 %{
 4723   constraint(ALLOC_IN_RC(r10_reg));
 4724   match(RegP);
 4725   // match(iRegP);
 4726   match(iRegPNoSp);
 4727   op_cost(0);
 4728   format %{ %}
 4729   interface(REG_INTER);
 4730 %}
 4731 
 4732 // Long 64 bit Register R0 only
 4733 operand iRegL_R0()
 4734 %{
 4735   constraint(ALLOC_IN_RC(r0_reg));
 4736   match(RegL);
 4737   match(iRegLNoSp);
 4738   op_cost(0);
 4739   format %{ %}
 4740   interface(REG_INTER);
 4741 %}
 4742 
 4743 // Long 64 bit Register R2 only
 4744 operand iRegL_R2()
 4745 %{
 4746   constraint(ALLOC_IN_RC(r2_reg));
 4747   match(RegL);
 4748   match(iRegLNoSp);
 4749   op_cost(0);
 4750   format %{ %}
 4751   interface(REG_INTER);
 4752 %}
 4753 
 4754 // Long 64 bit Register R3 only
 4755 operand iRegL_R3()
 4756 %{
 4757   constraint(ALLOC_IN_RC(r3_reg));
 4758   match(RegL);
 4759   match(iRegLNoSp);
 4760   op_cost(0);
 4761   format %{ %}
 4762   interface(REG_INTER);
 4763 %}
 4764 
 4765 // Long 64 bit Register R11 only
 4766 operand iRegL_R11()
 4767 %{
 4768   constraint(ALLOC_IN_RC(r11_reg));
 4769   match(RegL);
 4770   match(iRegLNoSp);
 4771   op_cost(0);
 4772   format %{ %}
 4773   interface(REG_INTER);
 4774 %}
 4775 
 4776 // Pointer 64 bit Register FP only
 4777 operand iRegP_FP()
 4778 %{
 4779   constraint(ALLOC_IN_RC(fp_reg));
 4780   match(RegP);
 4781   // match(iRegP);
 4782   op_cost(0);
 4783   format %{ %}
 4784   interface(REG_INTER);
 4785 %}
 4786 
 4787 // Register R0 only
 4788 operand iRegI_R0()
 4789 %{
 4790   constraint(ALLOC_IN_RC(int_r0_reg));
 4791   match(RegI);
 4792   match(iRegINoSp);
 4793   op_cost(0);
 4794   format %{ %}
 4795   interface(REG_INTER);
 4796 %}
 4797 
 4798 // Register R2 only
 4799 operand iRegI_R2()
 4800 %{
 4801   constraint(ALLOC_IN_RC(int_r2_reg));
 4802   match(RegI);
 4803   match(iRegINoSp);
 4804   op_cost(0);
 4805   format %{ %}
 4806   interface(REG_INTER);
 4807 %}
 4808 
 4809 // Register R3 only
 4810 operand iRegI_R3()
 4811 %{
 4812   constraint(ALLOC_IN_RC(int_r3_reg));
 4813   match(RegI);
 4814   match(iRegINoSp);
 4815   op_cost(0);
 4816   format %{ %}
 4817   interface(REG_INTER);
 4818 %}
 4819 
 4820 
 4821 // Register R4 only
 4822 operand iRegI_R4()
 4823 %{
 4824   constraint(ALLOC_IN_RC(int_r4_reg));
 4825   match(RegI);
 4826   match(iRegINoSp);
 4827   op_cost(0);
 4828   format %{ %}
 4829   interface(REG_INTER);
 4830 %}
 4831 
 4832 
 4833 // Pointer Register Operands
 4834 // Narrow Pointer Register
 4835 operand iRegN()
 4836 %{
 4837   constraint(ALLOC_IN_RC(any_reg32));
 4838   match(RegN);
 4839   match(iRegNNoSp);
 4840   op_cost(0);
 4841   format %{ %}
 4842   interface(REG_INTER);
 4843 %}
 4844 
 4845 operand iRegN_R0()
 4846 %{
 4847   constraint(ALLOC_IN_RC(r0_reg));
 4848   match(iRegN);
 4849   op_cost(0);
 4850   format %{ %}
 4851   interface(REG_INTER);
 4852 %}
 4853 
 4854 operand iRegN_R2()
 4855 %{
 4856   constraint(ALLOC_IN_RC(r2_reg));
 4857   match(iRegN);
 4858   op_cost(0);
 4859   format %{ %}
 4860   interface(REG_INTER);
 4861 %}
 4862 
 4863 operand iRegN_R3()
 4864 %{
 4865   constraint(ALLOC_IN_RC(r3_reg));
 4866   match(iRegN);
 4867   op_cost(0);
 4868   format %{ %}
 4869   interface(REG_INTER);
 4870 %}
 4871 
 4872 // Integer 64 bit Register not Special
 4873 operand iRegNNoSp()
 4874 %{
 4875   constraint(ALLOC_IN_RC(no_special_reg32));
 4876   match(RegN);
 4877   op_cost(0);
 4878   format %{ %}
 4879   interface(REG_INTER);
 4880 %}
 4881 
 4882 // heap base register -- used for encoding immN0
 4883 
 4884 operand iRegIHeapbase()
 4885 %{
 4886   constraint(ALLOC_IN_RC(heapbase_reg));
 4887   match(RegI);
 4888   op_cost(0);
 4889   format %{ %}
 4890   interface(REG_INTER);
 4891 %}
 4892 
 4893 // Float Register
 4894 // Float register operands
 4895 operand vRegF()
 4896 %{
 4897   constraint(ALLOC_IN_RC(float_reg));
 4898   match(RegF);
 4899 
 4900   op_cost(0);
 4901   format %{ %}
 4902   interface(REG_INTER);
 4903 %}
 4904 
 4905 // Double Register
 4906 // Double register operands
 4907 operand vRegD()
 4908 %{
 4909   constraint(ALLOC_IN_RC(double_reg));
 4910   match(RegD);
 4911 
 4912   op_cost(0);
 4913   format %{ %}
 4914   interface(REG_INTER);
 4915 %}
 4916 
 4917 operand vecD()
 4918 %{
 4919   constraint(ALLOC_IN_RC(vectord_reg));
 4920   match(VecD);
 4921 
 4922   op_cost(0);
 4923   format %{ %}
 4924   interface(REG_INTER);
 4925 %}
 4926 
 4927 operand vecX()
 4928 %{
 4929   constraint(ALLOC_IN_RC(vectorx_reg));
 4930   match(VecX);
 4931 
 4932   op_cost(0);
 4933   format %{ %}
 4934   interface(REG_INTER);
 4935 %}
 4936 
 4937 operand vRegD_V0()
 4938 %{
 4939   constraint(ALLOC_IN_RC(v0_reg));
 4940   match(RegD);
 4941   op_cost(0);
 4942   format %{ %}
 4943   interface(REG_INTER);
 4944 %}
 4945 
 4946 operand vRegD_V1()
 4947 %{
 4948   constraint(ALLOC_IN_RC(v1_reg));
 4949   match(RegD);
 4950   op_cost(0);
 4951   format %{ %}
 4952   interface(REG_INTER);
 4953 %}
 4954 
 4955 operand vRegD_V2()
 4956 %{
 4957   constraint(ALLOC_IN_RC(v2_reg));
 4958   match(RegD);
 4959   op_cost(0);
 4960   format %{ %}
 4961   interface(REG_INTER);
 4962 %}
 4963 
 4964 operand vRegD_V3()
 4965 %{
 4966   constraint(ALLOC_IN_RC(v3_reg));
 4967   match(RegD);
 4968   op_cost(0);
 4969   format %{ %}
 4970   interface(REG_INTER);
 4971 %}
 4972 
 4973 operand vRegD_V4()
 4974 %{
 4975   constraint(ALLOC_IN_RC(v4_reg));
 4976   match(RegD);
 4977   op_cost(0);
 4978   format %{ %}
 4979   interface(REG_INTER);
 4980 %}
 4981 
 4982 operand vRegD_V5()
 4983 %{
 4984   constraint(ALLOC_IN_RC(v5_reg));
 4985   match(RegD);
 4986   op_cost(0);
 4987   format %{ %}
 4988   interface(REG_INTER);
 4989 %}
 4990 
 4991 operand vRegD_V6()
 4992 %{
 4993   constraint(ALLOC_IN_RC(v6_reg));
 4994   match(RegD);
 4995   op_cost(0);
 4996   format %{ %}
 4997   interface(REG_INTER);
 4998 %}
 4999 
 5000 operand vRegD_V7()
 5001 %{
 5002   constraint(ALLOC_IN_RC(v7_reg));
 5003   match(RegD);
 5004   op_cost(0);
 5005   format %{ %}
 5006   interface(REG_INTER);
 5007 %}
 5008 
 5009 operand vRegD_V8()
 5010 %{
 5011   constraint(ALLOC_IN_RC(v8_reg));
 5012   match(RegD);
 5013   op_cost(0);
 5014   format %{ %}
 5015   interface(REG_INTER);
 5016 %}
 5017 
 5018 operand vRegD_V9()
 5019 %{
 5020   constraint(ALLOC_IN_RC(v9_reg));
 5021   match(RegD);
 5022   op_cost(0);
 5023   format %{ %}
 5024   interface(REG_INTER);
 5025 %}
 5026 
 5027 operand vRegD_V10()
 5028 %{
 5029   constraint(ALLOC_IN_RC(v10_reg));
 5030   match(RegD);
 5031   op_cost(0);
 5032   format %{ %}
 5033   interface(REG_INTER);
 5034 %}
 5035 
 5036 operand vRegD_V11()
 5037 %{
 5038   constraint(ALLOC_IN_RC(v11_reg));
 5039   match(RegD);
 5040   op_cost(0);
 5041   format %{ %}
 5042   interface(REG_INTER);
 5043 %}
 5044 
 5045 operand vRegD_V12()
 5046 %{
 5047   constraint(ALLOC_IN_RC(v12_reg));
 5048   match(RegD);
 5049   op_cost(0);
 5050   format %{ %}
 5051   interface(REG_INTER);
 5052 %}
 5053 
 5054 operand vRegD_V13()
 5055 %{
 5056   constraint(ALLOC_IN_RC(v13_reg));
 5057   match(RegD);
 5058   op_cost(0);
 5059   format %{ %}
 5060   interface(REG_INTER);
 5061 %}
 5062 
 5063 operand vRegD_V14()
 5064 %{
 5065   constraint(ALLOC_IN_RC(v14_reg));
 5066   match(RegD);
 5067   op_cost(0);
 5068   format %{ %}
 5069   interface(REG_INTER);
 5070 %}
 5071 
 5072 operand vRegD_V15()
 5073 %{
 5074   constraint(ALLOC_IN_RC(v15_reg));
 5075   match(RegD);
 5076   op_cost(0);
 5077   format %{ %}
 5078   interface(REG_INTER);
 5079 %}
 5080 
 5081 operand vRegD_V16()
 5082 %{
 5083   constraint(ALLOC_IN_RC(v16_reg));
 5084   match(RegD);
 5085   op_cost(0);
 5086   format %{ %}
 5087   interface(REG_INTER);
 5088 %}
 5089 
 5090 operand vRegD_V17()
 5091 %{
 5092   constraint(ALLOC_IN_RC(v17_reg));
 5093   match(RegD);
 5094   op_cost(0);
 5095   format %{ %}
 5096   interface(REG_INTER);
 5097 %}
 5098 
 5099 operand vRegD_V18()
 5100 %{
 5101   constraint(ALLOC_IN_RC(v18_reg));
 5102   match(RegD);
 5103   op_cost(0);
 5104   format %{ %}
 5105   interface(REG_INTER);
 5106 %}
 5107 
 5108 operand vRegD_V19()
 5109 %{
 5110   constraint(ALLOC_IN_RC(v19_reg));
 5111   match(RegD);
 5112   op_cost(0);
 5113   format %{ %}
 5114   interface(REG_INTER);
 5115 %}
 5116 
 5117 operand vRegD_V20()
 5118 %{
 5119   constraint(ALLOC_IN_RC(v20_reg));
 5120   match(RegD);
 5121   op_cost(0);
 5122   format %{ %}
 5123   interface(REG_INTER);
 5124 %}
 5125 
 5126 operand vRegD_V21()
 5127 %{
 5128   constraint(ALLOC_IN_RC(v21_reg));
 5129   match(RegD);
 5130   op_cost(0);
 5131   format %{ %}
 5132   interface(REG_INTER);
 5133 %}
 5134 
 5135 operand vRegD_V22()
 5136 %{
 5137   constraint(ALLOC_IN_RC(v22_reg));
 5138   match(RegD);
 5139   op_cost(0);
 5140   format %{ %}
 5141   interface(REG_INTER);
 5142 %}
 5143 
 5144 operand vRegD_V23()
 5145 %{
 5146   constraint(ALLOC_IN_RC(v23_reg));
 5147   match(RegD);
 5148   op_cost(0);
 5149   format %{ %}
 5150   interface(REG_INTER);
 5151 %}
 5152 
 5153 operand vRegD_V24()
 5154 %{
 5155   constraint(ALLOC_IN_RC(v24_reg));
 5156   match(RegD);
 5157   op_cost(0);
 5158   format %{ %}
 5159   interface(REG_INTER);
 5160 %}
 5161 
 5162 operand vRegD_V25()
 5163 %{
 5164   constraint(ALLOC_IN_RC(v25_reg));
 5165   match(RegD);
 5166   op_cost(0);
 5167   format %{ %}
 5168   interface(REG_INTER);
 5169 %}
 5170 
 5171 operand vRegD_V26()
 5172 %{
 5173   constraint(ALLOC_IN_RC(v26_reg));
 5174   match(RegD);
 5175   op_cost(0);
 5176   format %{ %}
 5177   interface(REG_INTER);
 5178 %}
 5179 
 5180 operand vRegD_V27()
 5181 %{
 5182   constraint(ALLOC_IN_RC(v27_reg));
 5183   match(RegD);
 5184   op_cost(0);
 5185   format %{ %}
 5186   interface(REG_INTER);
 5187 %}
 5188 
 5189 operand vRegD_V28()
 5190 %{
 5191   constraint(ALLOC_IN_RC(v28_reg));
 5192   match(RegD);
 5193   op_cost(0);
 5194   format %{ %}
 5195   interface(REG_INTER);
 5196 %}
 5197 
 5198 operand vRegD_V29()
 5199 %{
 5200   constraint(ALLOC_IN_RC(v29_reg));
 5201   match(RegD);
 5202   op_cost(0);
 5203   format %{ %}
 5204   interface(REG_INTER);
 5205 %}
 5206 
 5207 operand vRegD_V30()
 5208 %{
 5209   constraint(ALLOC_IN_RC(v30_reg));
 5210   match(RegD);
 5211   op_cost(0);
 5212   format %{ %}
 5213   interface(REG_INTER);
 5214 %}
 5215 
 5216 operand vRegD_V31()
 5217 %{
 5218   constraint(ALLOC_IN_RC(v31_reg));
 5219   match(RegD);
 5220   op_cost(0);
 5221   format %{ %}
 5222   interface(REG_INTER);
 5223 %}
 5224 
 5225 // Flags register, used as output of signed compare instructions
 5226 
 5227 // note that on AArch64 we also use this register as the output for
 5228 // for floating point compare instructions (CmpF CmpD). this ensures
 5229 // that ordered inequality tests use GT, GE, LT or LE none of which
 5230 // pass through cases where the result is unordered i.e. one or both
 5231 // inputs to the compare is a NaN. this means that the ideal code can
 5232 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5233 // (where the comparison should always fail). EQ and NE tests are
 5234 // always generated in ideal code so that unordered folds into the NE
 5235 // case, matching the behaviour of AArch64 NE.
 5236 //
 5237 // This differs from x86 where the outputs of FP compares use a
 5238 // special FP flags registers and where compares based on this
 5239 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5240 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5241 // to explicitly handle the unordered case in branches. x86 also has
 5242 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5243 
 5244 operand rFlagsReg()
 5245 %{
 5246   constraint(ALLOC_IN_RC(int_flags));
 5247   match(RegFlags);
 5248 
 5249   op_cost(0);
 5250   format %{ &quot;RFLAGS&quot; %}
 5251   interface(REG_INTER);
 5252 %}
 5253 
 5254 // Flags register, used as output of unsigned compare instructions
 5255 operand rFlagsRegU()
 5256 %{
 5257   constraint(ALLOC_IN_RC(int_flags));
 5258   match(RegFlags);
 5259 
 5260   op_cost(0);
 5261   format %{ &quot;RFLAGSU&quot; %}
 5262   interface(REG_INTER);
 5263 %}
 5264 
 5265 // Special Registers
 5266 
 5267 // Method Register
 5268 operand inline_cache_RegP(iRegP reg)
 5269 %{
 5270   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5271   match(reg);
 5272   match(iRegPNoSp);
 5273   op_cost(0);
 5274   format %{ %}
 5275   interface(REG_INTER);
 5276 %}
 5277 
 5278 operand interpreter_method_oop_RegP(iRegP reg)
 5279 %{
 5280   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5281   match(reg);
 5282   match(iRegPNoSp);
 5283   op_cost(0);
 5284   format %{ %}
 5285   interface(REG_INTER);
 5286 %}
 5287 
 5288 // Thread Register
 5289 operand thread_RegP(iRegP reg)
 5290 %{
 5291   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5292   match(reg);
 5293   op_cost(0);
 5294   format %{ %}
 5295   interface(REG_INTER);
 5296 %}
 5297 
 5298 operand lr_RegP(iRegP reg)
 5299 %{
 5300   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5301   match(reg);
 5302   op_cost(0);
 5303   format %{ %}
 5304   interface(REG_INTER);
 5305 %}
 5306 
 5307 //----------Memory Operands----------------------------------------------------
 5308 
 5309 operand indirect(iRegP reg)
 5310 %{
 5311   constraint(ALLOC_IN_RC(ptr_reg));
 5312   match(reg);
 5313   op_cost(0);
 5314   format %{ &quot;[$reg]&quot; %}
 5315   interface(MEMORY_INTER) %{
 5316     base($reg);
 5317     index(0xffffffff);
 5318     scale(0x0);
 5319     disp(0x0);
 5320   %}
 5321 %}
 5322 
 5323 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5324 %{
 5325   constraint(ALLOC_IN_RC(ptr_reg));
 5326   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5327   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5328   op_cost(0);
 5329   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5330   interface(MEMORY_INTER) %{
 5331     base($reg);
 5332     index($ireg);
 5333     scale($scale);
 5334     disp(0x0);
 5335   %}
 5336 %}
 5337 
 5338 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5339 %{
 5340   constraint(ALLOC_IN_RC(ptr_reg));
 5341   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5342   match(AddP reg (LShiftL lreg scale));
 5343   op_cost(0);
 5344   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5345   interface(MEMORY_INTER) %{
 5346     base($reg);
 5347     index($lreg);
 5348     scale($scale);
 5349     disp(0x0);
 5350   %}
 5351 %}
 5352 
 5353 operand indIndexI2L(iRegP reg, iRegI ireg)
 5354 %{
 5355   constraint(ALLOC_IN_RC(ptr_reg));
 5356   match(AddP reg (ConvI2L ireg));
 5357   op_cost(0);
 5358   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5359   interface(MEMORY_INTER) %{
 5360     base($reg);
 5361     index($ireg);
 5362     scale(0x0);
 5363     disp(0x0);
 5364   %}
 5365 %}
 5366 
 5367 operand indIndex(iRegP reg, iRegL lreg)
 5368 %{
 5369   constraint(ALLOC_IN_RC(ptr_reg));
 5370   match(AddP reg lreg);
 5371   op_cost(0);
 5372   format %{ &quot;$reg, $lreg&quot; %}
 5373   interface(MEMORY_INTER) %{
 5374     base($reg);
 5375     index($lreg);
 5376     scale(0x0);
 5377     disp(0x0);
 5378   %}
 5379 %}
 5380 
 5381 operand indOffI(iRegP reg, immIOffset off)
 5382 %{
 5383   constraint(ALLOC_IN_RC(ptr_reg));
 5384   match(AddP reg off);
 5385   op_cost(0);
 5386   format %{ &quot;[$reg, $off]&quot; %}
 5387   interface(MEMORY_INTER) %{
 5388     base($reg);
 5389     index(0xffffffff);
 5390     scale(0x0);
 5391     disp($off);
 5392   %}
 5393 %}
 5394 
 5395 operand indOffI1(iRegP reg, immIOffset1 off)
 5396 %{
 5397   constraint(ALLOC_IN_RC(ptr_reg));
 5398   match(AddP reg off);
 5399   op_cost(0);
 5400   format %{ &quot;[$reg, $off]&quot; %}
 5401   interface(MEMORY_INTER) %{
 5402     base($reg);
 5403     index(0xffffffff);
 5404     scale(0x0);
 5405     disp($off);
 5406   %}
 5407 %}
 5408 
 5409 operand indOffI2(iRegP reg, immIOffset2 off)
 5410 %{
 5411   constraint(ALLOC_IN_RC(ptr_reg));
 5412   match(AddP reg off);
 5413   op_cost(0);
 5414   format %{ &quot;[$reg, $off]&quot; %}
 5415   interface(MEMORY_INTER) %{
 5416     base($reg);
 5417     index(0xffffffff);
 5418     scale(0x0);
 5419     disp($off);
 5420   %}
 5421 %}
 5422 
 5423 operand indOffI4(iRegP reg, immIOffset4 off)
 5424 %{
 5425   constraint(ALLOC_IN_RC(ptr_reg));
 5426   match(AddP reg off);
 5427   op_cost(0);
 5428   format %{ &quot;[$reg, $off]&quot; %}
 5429   interface(MEMORY_INTER) %{
 5430     base($reg);
 5431     index(0xffffffff);
 5432     scale(0x0);
 5433     disp($off);
 5434   %}
 5435 %}
 5436 
 5437 operand indOffI8(iRegP reg, immIOffset8 off)
 5438 %{
 5439   constraint(ALLOC_IN_RC(ptr_reg));
 5440   match(AddP reg off);
 5441   op_cost(0);
 5442   format %{ &quot;[$reg, $off]&quot; %}
 5443   interface(MEMORY_INTER) %{
 5444     base($reg);
 5445     index(0xffffffff);
 5446     scale(0x0);
 5447     disp($off);
 5448   %}
 5449 %}
 5450 
 5451 operand indOffI16(iRegP reg, immIOffset16 off)
 5452 %{
 5453   constraint(ALLOC_IN_RC(ptr_reg));
 5454   match(AddP reg off);
 5455   op_cost(0);
 5456   format %{ &quot;[$reg, $off]&quot; %}
 5457   interface(MEMORY_INTER) %{
 5458     base($reg);
 5459     index(0xffffffff);
 5460     scale(0x0);
 5461     disp($off);
 5462   %}
 5463 %}
 5464 
 5465 operand indOffL(iRegP reg, immLoffset off)
 5466 %{
 5467   constraint(ALLOC_IN_RC(ptr_reg));
 5468   match(AddP reg off);
 5469   op_cost(0);
 5470   format %{ &quot;[$reg, $off]&quot; %}
 5471   interface(MEMORY_INTER) %{
 5472     base($reg);
 5473     index(0xffffffff);
 5474     scale(0x0);
 5475     disp($off);
 5476   %}
 5477 %}
 5478 
 5479 operand indOffL1(iRegP reg, immLoffset1 off)
 5480 %{
 5481   constraint(ALLOC_IN_RC(ptr_reg));
 5482   match(AddP reg off);
 5483   op_cost(0);
 5484   format %{ &quot;[$reg, $off]&quot; %}
 5485   interface(MEMORY_INTER) %{
 5486     base($reg);
 5487     index(0xffffffff);
 5488     scale(0x0);
 5489     disp($off);
 5490   %}
 5491 %}
 5492 
 5493 operand indOffL2(iRegP reg, immLoffset2 off)
 5494 %{
 5495   constraint(ALLOC_IN_RC(ptr_reg));
 5496   match(AddP reg off);
 5497   op_cost(0);
 5498   format %{ &quot;[$reg, $off]&quot; %}
 5499   interface(MEMORY_INTER) %{
 5500     base($reg);
 5501     index(0xffffffff);
 5502     scale(0x0);
 5503     disp($off);
 5504   %}
 5505 %}
 5506 
 5507 operand indOffL4(iRegP reg, immLoffset4 off)
 5508 %{
 5509   constraint(ALLOC_IN_RC(ptr_reg));
 5510   match(AddP reg off);
 5511   op_cost(0);
 5512   format %{ &quot;[$reg, $off]&quot; %}
 5513   interface(MEMORY_INTER) %{
 5514     base($reg);
 5515     index(0xffffffff);
 5516     scale(0x0);
 5517     disp($off);
 5518   %}
 5519 %}
 5520 
 5521 operand indOffL8(iRegP reg, immLoffset8 off)
 5522 %{
 5523   constraint(ALLOC_IN_RC(ptr_reg));
 5524   match(AddP reg off);
 5525   op_cost(0);
 5526   format %{ &quot;[$reg, $off]&quot; %}
 5527   interface(MEMORY_INTER) %{
 5528     base($reg);
 5529     index(0xffffffff);
 5530     scale(0x0);
 5531     disp($off);
 5532   %}
 5533 %}
 5534 
 5535 operand indOffL16(iRegP reg, immLoffset16 off)
 5536 %{
 5537   constraint(ALLOC_IN_RC(ptr_reg));
 5538   match(AddP reg off);
 5539   op_cost(0);
 5540   format %{ &quot;[$reg, $off]&quot; %}
 5541   interface(MEMORY_INTER) %{
 5542     base($reg);
 5543     index(0xffffffff);
 5544     scale(0x0);
 5545     disp($off);
 5546   %}
 5547 %}
 5548 
 5549 operand indirectN(iRegN reg)
 5550 %{
 5551   predicate(CompressedOops::shift() == 0);
 5552   constraint(ALLOC_IN_RC(ptr_reg));
 5553   match(DecodeN reg);
 5554   op_cost(0);
 5555   format %{ &quot;[$reg]\t# narrow&quot; %}
 5556   interface(MEMORY_INTER) %{
 5557     base($reg);
 5558     index(0xffffffff);
 5559     scale(0x0);
 5560     disp(0x0);
 5561   %}
 5562 %}
 5563 
 5564 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5565 %{
 5566   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5567   constraint(ALLOC_IN_RC(ptr_reg));
 5568   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5569   op_cost(0);
 5570   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5571   interface(MEMORY_INTER) %{
 5572     base($reg);
 5573     index($ireg);
 5574     scale($scale);
 5575     disp(0x0);
 5576   %}
 5577 %}
 5578 
 5579 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5580 %{
 5581   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5582   constraint(ALLOC_IN_RC(ptr_reg));
 5583   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5584   op_cost(0);
 5585   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5586   interface(MEMORY_INTER) %{
 5587     base($reg);
 5588     index($lreg);
 5589     scale($scale);
 5590     disp(0x0);
 5591   %}
 5592 %}
 5593 
 5594 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5595 %{
 5596   predicate(CompressedOops::shift() == 0);
 5597   constraint(ALLOC_IN_RC(ptr_reg));
 5598   match(AddP (DecodeN reg) (ConvI2L ireg));
 5599   op_cost(0);
 5600   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5601   interface(MEMORY_INTER) %{
 5602     base($reg);
 5603     index($ireg);
 5604     scale(0x0);
 5605     disp(0x0);
 5606   %}
 5607 %}
 5608 
 5609 operand indIndexN(iRegN reg, iRegL lreg)
 5610 %{
 5611   predicate(CompressedOops::shift() == 0);
 5612   constraint(ALLOC_IN_RC(ptr_reg));
 5613   match(AddP (DecodeN reg) lreg);
 5614   op_cost(0);
 5615   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5616   interface(MEMORY_INTER) %{
 5617     base($reg);
 5618     index($lreg);
 5619     scale(0x0);
 5620     disp(0x0);
 5621   %}
 5622 %}
 5623 
 5624 operand indOffIN(iRegN reg, immIOffset off)
 5625 %{
 5626   predicate(CompressedOops::shift() == 0);
 5627   constraint(ALLOC_IN_RC(ptr_reg));
 5628   match(AddP (DecodeN reg) off);
 5629   op_cost(0);
 5630   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5631   interface(MEMORY_INTER) %{
 5632     base($reg);
 5633     index(0xffffffff);
 5634     scale(0x0);
 5635     disp($off);
 5636   %}
 5637 %}
 5638 
 5639 operand indOffLN(iRegN reg, immLoffset off)
 5640 %{
 5641   predicate(CompressedOops::shift() == 0);
 5642   constraint(ALLOC_IN_RC(ptr_reg));
 5643   match(AddP (DecodeN reg) off);
 5644   op_cost(0);
 5645   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5646   interface(MEMORY_INTER) %{
 5647     base($reg);
 5648     index(0xffffffff);
 5649     scale(0x0);
 5650     disp($off);
 5651   %}
 5652 %}
 5653 
 5654 
 5655 
 5656 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5657 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5658 %{
 5659   constraint(ALLOC_IN_RC(ptr_reg));
 5660   match(AddP reg off);
 5661   op_cost(0);
 5662   format %{ &quot;[$reg, $off]&quot; %}
 5663   interface(MEMORY_INTER) %{
 5664     base($reg);
 5665     index(0xffffffff);
 5666     scale(0x0);
 5667     disp($off);
 5668   %}
 5669 %}
 5670 
 5671 //----------Special Memory Operands--------------------------------------------
 5672 // Stack Slot Operand - This operand is used for loading and storing temporary
 5673 //                      values on the stack where a match requires a value to
 5674 //                      flow through memory.
 5675 operand stackSlotP(sRegP reg)
 5676 %{
 5677   constraint(ALLOC_IN_RC(stack_slots));
 5678   op_cost(100);
 5679   // No match rule because this operand is only generated in matching
 5680   // match(RegP);
 5681   format %{ &quot;[$reg]&quot; %}
 5682   interface(MEMORY_INTER) %{
 5683     base(0x1e);  // RSP
 5684     index(0x0);  // No Index
 5685     scale(0x0);  // No Scale
 5686     disp($reg);  // Stack Offset
 5687   %}
 5688 %}
 5689 
 5690 operand stackSlotI(sRegI reg)
 5691 %{
 5692   constraint(ALLOC_IN_RC(stack_slots));
 5693   // No match rule because this operand is only generated in matching
 5694   // match(RegI);
 5695   format %{ &quot;[$reg]&quot; %}
 5696   interface(MEMORY_INTER) %{
 5697     base(0x1e);  // RSP
 5698     index(0x0);  // No Index
 5699     scale(0x0);  // No Scale
 5700     disp($reg);  // Stack Offset
 5701   %}
 5702 %}
 5703 
 5704 operand stackSlotF(sRegF reg)
 5705 %{
 5706   constraint(ALLOC_IN_RC(stack_slots));
 5707   // No match rule because this operand is only generated in matching
 5708   // match(RegF);
 5709   format %{ &quot;[$reg]&quot; %}
 5710   interface(MEMORY_INTER) %{
 5711     base(0x1e);  // RSP
 5712     index(0x0);  // No Index
 5713     scale(0x0);  // No Scale
 5714     disp($reg);  // Stack Offset
 5715   %}
 5716 %}
 5717 
 5718 operand stackSlotD(sRegD reg)
 5719 %{
 5720   constraint(ALLOC_IN_RC(stack_slots));
 5721   // No match rule because this operand is only generated in matching
 5722   // match(RegD);
 5723   format %{ &quot;[$reg]&quot; %}
 5724   interface(MEMORY_INTER) %{
 5725     base(0x1e);  // RSP
 5726     index(0x0);  // No Index
 5727     scale(0x0);  // No Scale
 5728     disp($reg);  // Stack Offset
 5729   %}
 5730 %}
 5731 
 5732 operand stackSlotL(sRegL reg)
 5733 %{
 5734   constraint(ALLOC_IN_RC(stack_slots));
 5735   // No match rule because this operand is only generated in matching
 5736   // match(RegL);
 5737   format %{ &quot;[$reg]&quot; %}
 5738   interface(MEMORY_INTER) %{
 5739     base(0x1e);  // RSP
 5740     index(0x0);  // No Index
 5741     scale(0x0);  // No Scale
 5742     disp($reg);  // Stack Offset
 5743   %}
 5744 %}
 5745 
 5746 // Operands for expressing Control Flow
 5747 // NOTE: Label is a predefined operand which should not be redefined in
 5748 //       the AD file. It is generically handled within the ADLC.
 5749 
 5750 //----------Conditional Branch Operands----------------------------------------
 5751 // Comparison Op  - This is the operation of the comparison, and is limited to
 5752 //                  the following set of codes:
 5753 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5754 //
 5755 // Other attributes of the comparison, such as unsignedness, are specified
 5756 // by the comparison instruction that sets a condition code flags register.
 5757 // That result is represented by a flags operand whose subtype is appropriate
 5758 // to the unsignedness (etc.) of the comparison.
 5759 //
 5760 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5761 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5762 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5763 
 5764 // used for signed integral comparisons and fp comparisons
 5765 
 5766 operand cmpOp()
 5767 %{
 5768   match(Bool);
 5769 
 5770   format %{ &quot;&quot; %}
 5771   interface(COND_INTER) %{
 5772     equal(0x0, &quot;eq&quot;);
 5773     not_equal(0x1, &quot;ne&quot;);
 5774     less(0xb, &quot;lt&quot;);
 5775     greater_equal(0xa, &quot;ge&quot;);
 5776     less_equal(0xd, &quot;le&quot;);
 5777     greater(0xc, &quot;gt&quot;);
 5778     overflow(0x6, &quot;vs&quot;);
 5779     no_overflow(0x7, &quot;vc&quot;);
 5780   %}
 5781 %}
 5782 
 5783 // used for unsigned integral comparisons
 5784 
 5785 operand cmpOpU()
 5786 %{
 5787   match(Bool);
 5788 
 5789   format %{ &quot;&quot; %}
 5790   interface(COND_INTER) %{
 5791     equal(0x0, &quot;eq&quot;);
 5792     not_equal(0x1, &quot;ne&quot;);
 5793     less(0x3, &quot;lo&quot;);
 5794     greater_equal(0x2, &quot;hs&quot;);
 5795     less_equal(0x9, &quot;ls&quot;);
 5796     greater(0x8, &quot;hi&quot;);
 5797     overflow(0x6, &quot;vs&quot;);
 5798     no_overflow(0x7, &quot;vc&quot;);
 5799   %}
 5800 %}
 5801 
 5802 // used for certain integral comparisons which can be
 5803 // converted to cbxx or tbxx instructions
 5804 
 5805 operand cmpOpEqNe()
 5806 %{
 5807   match(Bool);
 5808   op_cost(0);
 5809   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5810             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5811 
 5812   format %{ &quot;&quot; %}
 5813   interface(COND_INTER) %{
 5814     equal(0x0, &quot;eq&quot;);
 5815     not_equal(0x1, &quot;ne&quot;);
 5816     less(0xb, &quot;lt&quot;);
 5817     greater_equal(0xa, &quot;ge&quot;);
 5818     less_equal(0xd, &quot;le&quot;);
 5819     greater(0xc, &quot;gt&quot;);
 5820     overflow(0x6, &quot;vs&quot;);
 5821     no_overflow(0x7, &quot;vc&quot;);
 5822   %}
 5823 %}
 5824 
 5825 // used for certain integral comparisons which can be
 5826 // converted to cbxx or tbxx instructions
 5827 
 5828 operand cmpOpLtGe()
 5829 %{
 5830   match(Bool);
 5831   op_cost(0);
 5832 
 5833   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5834             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5835 
 5836   format %{ &quot;&quot; %}
 5837   interface(COND_INTER) %{
 5838     equal(0x0, &quot;eq&quot;);
 5839     not_equal(0x1, &quot;ne&quot;);
 5840     less(0xb, &quot;lt&quot;);
 5841     greater_equal(0xa, &quot;ge&quot;);
 5842     less_equal(0xd, &quot;le&quot;);
 5843     greater(0xc, &quot;gt&quot;);
 5844     overflow(0x6, &quot;vs&quot;);
 5845     no_overflow(0x7, &quot;vc&quot;);
 5846   %}
 5847 %}
 5848 
 5849 // used for certain unsigned integral comparisons which can be
 5850 // converted to cbxx or tbxx instructions
 5851 
 5852 operand cmpOpUEqNeLtGe()
 5853 %{
 5854   match(Bool);
 5855   op_cost(0);
 5856 
 5857   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5858             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5859             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5860             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5861 
 5862   format %{ &quot;&quot; %}
 5863   interface(COND_INTER) %{
 5864     equal(0x0, &quot;eq&quot;);
 5865     not_equal(0x1, &quot;ne&quot;);
 5866     less(0xb, &quot;lt&quot;);
 5867     greater_equal(0xa, &quot;ge&quot;);
 5868     less_equal(0xd, &quot;le&quot;);
 5869     greater(0xc, &quot;gt&quot;);
 5870     overflow(0x6, &quot;vs&quot;);
 5871     no_overflow(0x7, &quot;vc&quot;);
 5872   %}
 5873 %}
 5874 
 5875 // Special operand allowing long args to int ops to be truncated for free
 5876 
 5877 operand iRegL2I(iRegL reg) %{
 5878 
 5879   op_cost(0);
 5880 
 5881   match(ConvL2I reg);
 5882 
 5883   format %{ &quot;l2i($reg)&quot; %}
 5884 
 5885   interface(REG_INTER)
 5886 %}
 5887 
 5888 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5889 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5890 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5891 
 5892 //----------OPERAND CLASSES----------------------------------------------------
 5893 // Operand Classes are groups of operands that are used as to simplify
 5894 // instruction definitions by not requiring the AD writer to specify
 5895 // separate instructions for every form of operand when the
 5896 // instruction accepts multiple operand types with the same basic
 5897 // encoding and format. The classic case of this is memory operands.
 5898 
 5899 // memory is used to define read/write location for load/store
 5900 // instruction defs. we can turn a memory op into an Address
 5901 
 5902 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5903                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5904 
 5905 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5906                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5907 
 5908 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5909                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5910 
 5911 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5912                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5913 
 5914 // All of the memory operands. For the pipeline description.
 5915 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5916                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5917                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5918 
 5919 
 5920 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5921 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5922 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5923 // can be elided because the 32-bit instruction will just employ the
 5924 // lower 32 bits anyway.
 5925 //
 5926 // n.b. this does not elide all L2I conversions. if the truncated
 5927 // value is consumed by more than one operation then the ConvL2I
 5928 // cannot be bundled into the consuming nodes so an l2i gets planted
 5929 // (actually a movw $dst $src) and the downstream instructions consume
 5930 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5931 // movw is actually redundant but its not too costly.
 5932 
 5933 opclass iRegIorL2I(iRegI, iRegL2I);
 5934 
 5935 //----------PIPELINE-----------------------------------------------------------
 5936 // Rules which define the behavior of the target architectures pipeline.
 5937 
 5938 // For specific pipelines, eg A53, define the stages of that pipeline
 5939 //pipe_desc(ISS, EX1, EX2, WR);
 5940 #define ISS S0
 5941 #define EX1 S1
 5942 #define EX2 S2
 5943 #define WR  S3
 5944 
 5945 // Integer ALU reg operation
 5946 pipeline %{
 5947 
 5948 attributes %{
 5949   // ARM instructions are of fixed length
 5950   fixed_size_instructions;        // Fixed size instructions TODO does
 5951   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5952   // ARM instructions come in 32-bit word units
 5953   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5954   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5955   instruction_fetch_units = 1;       // of 64 bytes
 5956 
 5957   // List of nop instructions
 5958   nops( MachNop );
 5959 %}
 5960 
 5961 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5962 // or description. we do use pipeline classes to introduce fixed
 5963 // latencies
 5964 
 5965 //----------RESOURCES----------------------------------------------------------
 5966 // Resources are the functional units available to the machine
 5967 
 5968 resources( INS0, INS1, INS01 = INS0 | INS1,
 5969            ALU0, ALU1, ALU = ALU0 | ALU1,
 5970            MAC,
 5971            DIV,
 5972            BRANCH,
 5973            LDST,
 5974            NEON_FP);
 5975 
 5976 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5977 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5978 
 5979 // Define the pipeline as a generic 6 stage pipeline
 5980 pipe_desc(S0, S1, S2, S3, S4, S5);
 5981 
 5982 //----------PIPELINE CLASSES---------------------------------------------------
 5983 // Pipeline Classes describe the stages in which input and output are
 5984 // referenced by the hardware pipeline.
 5985 
 5986 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5987 %{
 5988   single_instruction;
 5989   src1   : S1(read);
 5990   src2   : S2(read);
 5991   dst    : S5(write);
 5992   INS01  : ISS;
 5993   NEON_FP : S5;
 5994 %}
 5995 
 5996 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5997 %{
 5998   single_instruction;
 5999   src1   : S1(read);
 6000   src2   : S2(read);
 6001   dst    : S5(write);
 6002   INS01  : ISS;
 6003   NEON_FP : S5;
 6004 %}
 6005 
 6006 pipe_class fp_uop_s(vRegF dst, vRegF src)
 6007 %{
 6008   single_instruction;
 6009   src    : S1(read);
 6010   dst    : S5(write);
 6011   INS01  : ISS;
 6012   NEON_FP : S5;
 6013 %}
 6014 
 6015 pipe_class fp_uop_d(vRegD dst, vRegD src)
 6016 %{
 6017   single_instruction;
 6018   src    : S1(read);
 6019   dst    : S5(write);
 6020   INS01  : ISS;
 6021   NEON_FP : S5;
 6022 %}
 6023 
 6024 pipe_class fp_d2f(vRegF dst, vRegD src)
 6025 %{
 6026   single_instruction;
 6027   src    : S1(read);
 6028   dst    : S5(write);
 6029   INS01  : ISS;
 6030   NEON_FP : S5;
 6031 %}
 6032 
 6033 pipe_class fp_f2d(vRegD dst, vRegF src)
 6034 %{
 6035   single_instruction;
 6036   src    : S1(read);
 6037   dst    : S5(write);
 6038   INS01  : ISS;
 6039   NEON_FP : S5;
 6040 %}
 6041 
 6042 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 6043 %{
 6044   single_instruction;
 6045   src    : S1(read);
 6046   dst    : S5(write);
 6047   INS01  : ISS;
 6048   NEON_FP : S5;
 6049 %}
 6050 
 6051 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6052 %{
 6053   single_instruction;
 6054   src    : S1(read);
 6055   dst    : S5(write);
 6056   INS01  : ISS;
 6057   NEON_FP : S5;
 6058 %}
 6059 
 6060 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6061 %{
 6062   single_instruction;
 6063   src    : S1(read);
 6064   dst    : S5(write);
 6065   INS01  : ISS;
 6066   NEON_FP : S5;
 6067 %}
 6068 
 6069 pipe_class fp_l2f(vRegF dst, iRegL src)
 6070 %{
 6071   single_instruction;
 6072   src    : S1(read);
 6073   dst    : S5(write);
 6074   INS01  : ISS;
 6075   NEON_FP : S5;
 6076 %}
 6077 
 6078 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6079 %{
 6080   single_instruction;
 6081   src    : S1(read);
 6082   dst    : S5(write);
 6083   INS01  : ISS;
 6084   NEON_FP : S5;
 6085 %}
 6086 
 6087 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6088 %{
 6089   single_instruction;
 6090   src    : S1(read);
 6091   dst    : S5(write);
 6092   INS01  : ISS;
 6093   NEON_FP : S5;
 6094 %}
 6095 
 6096 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6097 %{
 6098   single_instruction;
 6099   src    : S1(read);
 6100   dst    : S5(write);
 6101   INS01  : ISS;
 6102   NEON_FP : S5;
 6103 %}
 6104 
 6105 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6106 %{
 6107   single_instruction;
 6108   src    : S1(read);
 6109   dst    : S5(write);
 6110   INS01  : ISS;
 6111   NEON_FP : S5;
 6112 %}
 6113 
 6114 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6115 %{
 6116   single_instruction;
 6117   src1   : S1(read);
 6118   src2   : S2(read);
 6119   dst    : S5(write);
 6120   INS0   : ISS;
 6121   NEON_FP : S5;
 6122 %}
 6123 
 6124 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6125 %{
 6126   single_instruction;
 6127   src1   : S1(read);
 6128   src2   : S2(read);
 6129   dst    : S5(write);
 6130   INS0   : ISS;
 6131   NEON_FP : S5;
 6132 %}
 6133 
 6134 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6135 %{
 6136   single_instruction;
 6137   cr     : S1(read);
 6138   src1   : S1(read);
 6139   src2   : S1(read);
 6140   dst    : S3(write);
 6141   INS01  : ISS;
 6142   NEON_FP : S3;
 6143 %}
 6144 
 6145 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6146 %{
 6147   single_instruction;
 6148   cr     : S1(read);
 6149   src1   : S1(read);
 6150   src2   : S1(read);
 6151   dst    : S3(write);
 6152   INS01  : ISS;
 6153   NEON_FP : S3;
 6154 %}
 6155 
 6156 pipe_class fp_imm_s(vRegF dst)
 6157 %{
 6158   single_instruction;
 6159   dst    : S3(write);
 6160   INS01  : ISS;
 6161   NEON_FP : S3;
 6162 %}
 6163 
 6164 pipe_class fp_imm_d(vRegD dst)
 6165 %{
 6166   single_instruction;
 6167   dst    : S3(write);
 6168   INS01  : ISS;
 6169   NEON_FP : S3;
 6170 %}
 6171 
 6172 pipe_class fp_load_constant_s(vRegF dst)
 6173 %{
 6174   single_instruction;
 6175   dst    : S4(write);
 6176   INS01  : ISS;
 6177   NEON_FP : S4;
 6178 %}
 6179 
 6180 pipe_class fp_load_constant_d(vRegD dst)
 6181 %{
 6182   single_instruction;
 6183   dst    : S4(write);
 6184   INS01  : ISS;
 6185   NEON_FP : S4;
 6186 %}
 6187 
 6188 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6189 %{
 6190   single_instruction;
 6191   dst    : S5(write);
 6192   src1   : S1(read);
 6193   src2   : S1(read);
 6194   INS01  : ISS;
 6195   NEON_FP : S5;
 6196 %}
 6197 
 6198 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6199 %{
 6200   single_instruction;
 6201   dst    : S5(write);
 6202   src1   : S1(read);
 6203   src2   : S1(read);
 6204   INS0   : ISS;
 6205   NEON_FP : S5;
 6206 %}
 6207 
 6208 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6209 %{
 6210   single_instruction;
 6211   dst    : S5(write);
 6212   src1   : S1(read);
 6213   src2   : S1(read);
 6214   dst    : S1(read);
 6215   INS01  : ISS;
 6216   NEON_FP : S5;
 6217 %}
 6218 
 6219 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6220 %{
 6221   single_instruction;
 6222   dst    : S5(write);
 6223   src1   : S1(read);
 6224   src2   : S1(read);
 6225   dst    : S1(read);
 6226   INS0   : ISS;
 6227   NEON_FP : S5;
 6228 %}
 6229 
 6230 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6231 %{
 6232   single_instruction;
 6233   dst    : S4(write);
 6234   src1   : S2(read);
 6235   src2   : S2(read);
 6236   INS01  : ISS;
 6237   NEON_FP : S4;
 6238 %}
 6239 
 6240 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6241 %{
 6242   single_instruction;
 6243   dst    : S4(write);
 6244   src1   : S2(read);
 6245   src2   : S2(read);
 6246   INS0   : ISS;
 6247   NEON_FP : S4;
 6248 %}
 6249 
 6250 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6251 %{
 6252   single_instruction;
 6253   dst    : S3(write);
 6254   src1   : S2(read);
 6255   src2   : S2(read);
 6256   INS01  : ISS;
 6257   NEON_FP : S3;
 6258 %}
 6259 
 6260 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6261 %{
 6262   single_instruction;
 6263   dst    : S3(write);
 6264   src1   : S2(read);
 6265   src2   : S2(read);
 6266   INS0   : ISS;
 6267   NEON_FP : S3;
 6268 %}
 6269 
 6270 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6271 %{
 6272   single_instruction;
 6273   dst    : S3(write);
 6274   src    : S1(read);
 6275   shift  : S1(read);
 6276   INS01  : ISS;
 6277   NEON_FP : S3;
 6278 %}
 6279 
 6280 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6281 %{
 6282   single_instruction;
 6283   dst    : S3(write);
 6284   src    : S1(read);
 6285   shift  : S1(read);
 6286   INS0   : ISS;
 6287   NEON_FP : S3;
 6288 %}
 6289 
 6290 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6291 %{
 6292   single_instruction;
 6293   dst    : S3(write);
 6294   src    : S1(read);
 6295   INS01  : ISS;
 6296   NEON_FP : S3;
 6297 %}
 6298 
 6299 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6300 %{
 6301   single_instruction;
 6302   dst    : S3(write);
 6303   src    : S1(read);
 6304   INS0   : ISS;
 6305   NEON_FP : S3;
 6306 %}
 6307 
 6308 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6309 %{
 6310   single_instruction;
 6311   dst    : S5(write);
 6312   src1   : S1(read);
 6313   src2   : S1(read);
 6314   INS01  : ISS;
 6315   NEON_FP : S5;
 6316 %}
 6317 
 6318 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6319 %{
 6320   single_instruction;
 6321   dst    : S5(write);
 6322   src1   : S1(read);
 6323   src2   : S1(read);
 6324   INS0   : ISS;
 6325   NEON_FP : S5;
 6326 %}
 6327 
 6328 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6329 %{
 6330   single_instruction;
 6331   dst    : S5(write);
 6332   src1   : S1(read);
 6333   src2   : S1(read);
 6334   INS0   : ISS;
 6335   NEON_FP : S5;
 6336 %}
 6337 
 6338 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6339 %{
 6340   single_instruction;
 6341   dst    : S5(write);
 6342   src1   : S1(read);
 6343   src2   : S1(read);
 6344   INS0   : ISS;
 6345   NEON_FP : S5;
 6346 %}
 6347 
 6348 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6349 %{
 6350   single_instruction;
 6351   dst    : S5(write);
 6352   src    : S1(read);
 6353   INS0   : ISS;
 6354   NEON_FP : S5;
 6355 %}
 6356 
 6357 pipe_class vunop_fp64(vecD dst, vecD src)
 6358 %{
 6359   single_instruction;
 6360   dst    : S5(write);
 6361   src    : S1(read);
 6362   INS01  : ISS;
 6363   NEON_FP : S5;
 6364 %}
 6365 
 6366 pipe_class vunop_fp128(vecX dst, vecX src)
 6367 %{
 6368   single_instruction;
 6369   dst    : S5(write);
 6370   src    : S1(read);
 6371   INS0   : ISS;
 6372   NEON_FP : S5;
 6373 %}
 6374 
 6375 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6376 %{
 6377   single_instruction;
 6378   dst    : S3(write);
 6379   src    : S1(read);
 6380   INS01  : ISS;
 6381   NEON_FP : S3;
 6382 %}
 6383 
 6384 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6385 %{
 6386   single_instruction;
 6387   dst    : S3(write);
 6388   src    : S1(read);
 6389   INS01  : ISS;
 6390   NEON_FP : S3;
 6391 %}
 6392 
 6393 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6394 %{
 6395   single_instruction;
 6396   dst    : S3(write);
 6397   src    : S1(read);
 6398   INS01  : ISS;
 6399   NEON_FP : S3;
 6400 %}
 6401 
 6402 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6403 %{
 6404   single_instruction;
 6405   dst    : S3(write);
 6406   src    : S1(read);
 6407   INS01  : ISS;
 6408   NEON_FP : S3;
 6409 %}
 6410 
 6411 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6412 %{
 6413   single_instruction;
 6414   dst    : S3(write);
 6415   src    : S1(read);
 6416   INS01  : ISS;
 6417   NEON_FP : S3;
 6418 %}
 6419 
 6420 pipe_class vmovi_reg_imm64(vecD dst)
 6421 %{
 6422   single_instruction;
 6423   dst    : S3(write);
 6424   INS01  : ISS;
 6425   NEON_FP : S3;
 6426 %}
 6427 
 6428 pipe_class vmovi_reg_imm128(vecX dst)
 6429 %{
 6430   single_instruction;
 6431   dst    : S3(write);
 6432   INS0   : ISS;
 6433   NEON_FP : S3;
 6434 %}
 6435 
 6436 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6437 %{
 6438   single_instruction;
 6439   dst    : S5(write);
 6440   mem    : ISS(read);
 6441   INS01  : ISS;
 6442   NEON_FP : S3;
 6443 %}
 6444 
 6445 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6446 %{
 6447   single_instruction;
 6448   dst    : S5(write);
 6449   mem    : ISS(read);
 6450   INS01  : ISS;
 6451   NEON_FP : S3;
 6452 %}
 6453 
 6454 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6455 %{
 6456   single_instruction;
 6457   mem    : ISS(read);
 6458   src    : S2(read);
 6459   INS01  : ISS;
 6460   NEON_FP : S3;
 6461 %}
 6462 
 6463 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6464 %{
 6465   single_instruction;
 6466   mem    : ISS(read);
 6467   src    : S2(read);
 6468   INS01  : ISS;
 6469   NEON_FP : S3;
 6470 %}
 6471 
 6472 //------- Integer ALU operations --------------------------
 6473 
 6474 // Integer ALU reg-reg operation
 6475 // Operands needed in EX1, result generated in EX2
 6476 // Eg.  ADD     x0, x1, x2
 6477 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6478 %{
 6479   single_instruction;
 6480   dst    : EX2(write);
 6481   src1   : EX1(read);
 6482   src2   : EX1(read);
 6483   INS01  : ISS; // Dual issue as instruction 0 or 1
 6484   ALU    : EX2;
 6485 %}
 6486 
 6487 // Integer ALU reg-reg operation with constant shift
 6488 // Shifted register must be available in LATE_ISS instead of EX1
 6489 // Eg.  ADD     x0, x1, x2, LSL #2
 6490 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6491 %{
 6492   single_instruction;
 6493   dst    : EX2(write);
 6494   src1   : EX1(read);
 6495   src2   : ISS(read);
 6496   INS01  : ISS;
 6497   ALU    : EX2;
 6498 %}
 6499 
 6500 // Integer ALU reg operation with constant shift
 6501 // Eg.  LSL     x0, x1, #shift
 6502 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6503 %{
 6504   single_instruction;
 6505   dst    : EX2(write);
 6506   src1   : ISS(read);
 6507   INS01  : ISS;
 6508   ALU    : EX2;
 6509 %}
 6510 
 6511 // Integer ALU reg-reg operation with variable shift
 6512 // Both operands must be available in LATE_ISS instead of EX1
 6513 // Result is available in EX1 instead of EX2
 6514 // Eg.  LSLV    x0, x1, x2
 6515 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6516 %{
 6517   single_instruction;
 6518   dst    : EX1(write);
 6519   src1   : ISS(read);
 6520   src2   : ISS(read);
 6521   INS01  : ISS;
 6522   ALU    : EX1;
 6523 %}
 6524 
 6525 // Integer ALU reg-reg operation with extract
 6526 // As for _vshift above, but result generated in EX2
 6527 // Eg.  EXTR    x0, x1, x2, #N
 6528 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6529 %{
 6530   single_instruction;
 6531   dst    : EX2(write);
 6532   src1   : ISS(read);
 6533   src2   : ISS(read);
 6534   INS1   : ISS; // Can only dual issue as Instruction 1
 6535   ALU    : EX1;
 6536 %}
 6537 
 6538 // Integer ALU reg operation
 6539 // Eg.  NEG     x0, x1
 6540 pipe_class ialu_reg(iRegI dst, iRegI src)
 6541 %{
 6542   single_instruction;
 6543   dst    : EX2(write);
 6544   src    : EX1(read);
 6545   INS01  : ISS;
 6546   ALU    : EX2;
 6547 %}
 6548 
 6549 // Integer ALU reg mmediate operation
 6550 // Eg.  ADD     x0, x1, #N
 6551 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6552 %{
 6553   single_instruction;
 6554   dst    : EX2(write);
 6555   src1   : EX1(read);
 6556   INS01  : ISS;
 6557   ALU    : EX2;
 6558 %}
 6559 
 6560 // Integer ALU immediate operation (no source operands)
 6561 // Eg.  MOV     x0, #N
 6562 pipe_class ialu_imm(iRegI dst)
 6563 %{
 6564   single_instruction;
 6565   dst    : EX1(write);
 6566   INS01  : ISS;
 6567   ALU    : EX1;
 6568 %}
 6569 
 6570 //------- Compare operation -------------------------------
 6571 
 6572 // Compare reg-reg
 6573 // Eg.  CMP     x0, x1
 6574 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6575 %{
 6576   single_instruction;
 6577 //  fixed_latency(16);
 6578   cr     : EX2(write);
 6579   op1    : EX1(read);
 6580   op2    : EX1(read);
 6581   INS01  : ISS;
 6582   ALU    : EX2;
 6583 %}
 6584 
 6585 // Compare reg-reg
 6586 // Eg.  CMP     x0, #N
 6587 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6588 %{
 6589   single_instruction;
 6590 //  fixed_latency(16);
 6591   cr     : EX2(write);
 6592   op1    : EX1(read);
 6593   INS01  : ISS;
 6594   ALU    : EX2;
 6595 %}
 6596 
 6597 //------- Conditional instructions ------------------------
 6598 
 6599 // Conditional no operands
 6600 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6601 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6602 %{
 6603   single_instruction;
 6604   cr     : EX1(read);
 6605   dst    : EX2(write);
 6606   INS01  : ISS;
 6607   ALU    : EX2;
 6608 %}
 6609 
 6610 // Conditional 2 operand
 6611 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6612 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6613 %{
 6614   single_instruction;
 6615   cr     : EX1(read);
 6616   src1   : EX1(read);
 6617   src2   : EX1(read);
 6618   dst    : EX2(write);
 6619   INS01  : ISS;
 6620   ALU    : EX2;
 6621 %}
 6622 
 6623 // Conditional 2 operand
 6624 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6625 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6626 %{
 6627   single_instruction;
 6628   cr     : EX1(read);
 6629   src    : EX1(read);
 6630   dst    : EX2(write);
 6631   INS01  : ISS;
 6632   ALU    : EX2;
 6633 %}
 6634 
 6635 //------- Multiply pipeline operations --------------------
 6636 
 6637 // Multiply reg-reg
 6638 // Eg.  MUL     w0, w1, w2
 6639 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6640 %{
 6641   single_instruction;
 6642   dst    : WR(write);
 6643   src1   : ISS(read);
 6644   src2   : ISS(read);
 6645   INS01  : ISS;
 6646   MAC    : WR;
 6647 %}
 6648 
 6649 // Multiply accumulate
 6650 // Eg.  MADD    w0, w1, w2, w3
 6651 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6652 %{
 6653   single_instruction;
 6654   dst    : WR(write);
 6655   src1   : ISS(read);
 6656   src2   : ISS(read);
 6657   src3   : ISS(read);
 6658   INS01  : ISS;
 6659   MAC    : WR;
 6660 %}
 6661 
 6662 // Eg.  MUL     w0, w1, w2
 6663 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6664 %{
 6665   single_instruction;
 6666   fixed_latency(3); // Maximum latency for 64 bit mul
 6667   dst    : WR(write);
 6668   src1   : ISS(read);
 6669   src2   : ISS(read);
 6670   INS01  : ISS;
 6671   MAC    : WR;
 6672 %}
 6673 
 6674 // Multiply accumulate
 6675 // Eg.  MADD    w0, w1, w2, w3
 6676 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6677 %{
 6678   single_instruction;
 6679   fixed_latency(3); // Maximum latency for 64 bit mul
 6680   dst    : WR(write);
 6681   src1   : ISS(read);
 6682   src2   : ISS(read);
 6683   src3   : ISS(read);
 6684   INS01  : ISS;
 6685   MAC    : WR;
 6686 %}
 6687 
 6688 //------- Divide pipeline operations --------------------
 6689 
 6690 // Eg.  SDIV    w0, w1, w2
 6691 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6692 %{
 6693   single_instruction;
 6694   fixed_latency(8); // Maximum latency for 32 bit divide
 6695   dst    : WR(write);
 6696   src1   : ISS(read);
 6697   src2   : ISS(read);
 6698   INS0   : ISS; // Can only dual issue as instruction 0
 6699   DIV    : WR;
 6700 %}
 6701 
 6702 // Eg.  SDIV    x0, x1, x2
 6703 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6704 %{
 6705   single_instruction;
 6706   fixed_latency(16); // Maximum latency for 64 bit divide
 6707   dst    : WR(write);
 6708   src1   : ISS(read);
 6709   src2   : ISS(read);
 6710   INS0   : ISS; // Can only dual issue as instruction 0
 6711   DIV    : WR;
 6712 %}
 6713 
 6714 //------- Load pipeline operations ------------------------
 6715 
 6716 // Load - prefetch
 6717 // Eg.  PFRM    &lt;mem&gt;
 6718 pipe_class iload_prefetch(memory mem)
 6719 %{
 6720   single_instruction;
 6721   mem    : ISS(read);
 6722   INS01  : ISS;
 6723   LDST   : WR;
 6724 %}
 6725 
 6726 // Load - reg, mem
 6727 // Eg.  LDR     x0, &lt;mem&gt;
 6728 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6729 %{
 6730   single_instruction;
 6731   dst    : WR(write);
 6732   mem    : ISS(read);
 6733   INS01  : ISS;
 6734   LDST   : WR;
 6735 %}
 6736 
 6737 // Load - reg, reg
 6738 // Eg.  LDR     x0, [sp, x1]
 6739 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6740 %{
 6741   single_instruction;
 6742   dst    : WR(write);
 6743   src    : ISS(read);
 6744   INS01  : ISS;
 6745   LDST   : WR;
 6746 %}
 6747 
 6748 //------- Store pipeline operations -----------------------
 6749 
 6750 // Store - zr, mem
 6751 // Eg.  STR     zr, &lt;mem&gt;
 6752 pipe_class istore_mem(memory mem)
 6753 %{
 6754   single_instruction;
 6755   mem    : ISS(read);
 6756   INS01  : ISS;
 6757   LDST   : WR;
 6758 %}
 6759 
 6760 // Store - reg, mem
 6761 // Eg.  STR     x0, &lt;mem&gt;
 6762 pipe_class istore_reg_mem(iRegI src, memory mem)
 6763 %{
 6764   single_instruction;
 6765   mem    : ISS(read);
 6766   src    : EX2(read);
 6767   INS01  : ISS;
 6768   LDST   : WR;
 6769 %}
 6770 
 6771 // Store - reg, reg
 6772 // Eg. STR      x0, [sp, x1]
 6773 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6774 %{
 6775   single_instruction;
 6776   dst    : ISS(read);
 6777   src    : EX2(read);
 6778   INS01  : ISS;
 6779   LDST   : WR;
 6780 %}
 6781 
 6782 //------- Store pipeline operations -----------------------
 6783 
 6784 // Branch
 6785 pipe_class pipe_branch()
 6786 %{
 6787   single_instruction;
 6788   INS01  : ISS;
 6789   BRANCH : EX1;
 6790 %}
 6791 
 6792 // Conditional branch
 6793 pipe_class pipe_branch_cond(rFlagsReg cr)
 6794 %{
 6795   single_instruction;
 6796   cr     : EX1(read);
 6797   INS01  : ISS;
 6798   BRANCH : EX1;
 6799 %}
 6800 
 6801 // Compare &amp; Branch
 6802 // EG.  CBZ/CBNZ
 6803 pipe_class pipe_cmp_branch(iRegI op1)
 6804 %{
 6805   single_instruction;
 6806   op1    : EX1(read);
 6807   INS01  : ISS;
 6808   BRANCH : EX1;
 6809 %}
 6810 
 6811 //------- Synchronisation operations ----------------------
 6812 
 6813 // Any operation requiring serialization.
 6814 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6815 pipe_class pipe_serial()
 6816 %{
 6817   single_instruction;
 6818   force_serialization;
 6819   fixed_latency(16);
 6820   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6821   LDST   : WR;
 6822 %}
 6823 
 6824 // Generic big/slow expanded idiom - also serialized
 6825 pipe_class pipe_slow()
 6826 %{
 6827   instruction_count(10);
 6828   multiple_bundles;
 6829   force_serialization;
 6830   fixed_latency(16);
 6831   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6832   LDST   : WR;
 6833 %}
 6834 
 6835 // Empty pipeline class
 6836 pipe_class pipe_class_empty()
 6837 %{
 6838   single_instruction;
 6839   fixed_latency(0);
 6840 %}
 6841 
 6842 // Default pipeline class.
 6843 pipe_class pipe_class_default()
 6844 %{
 6845   single_instruction;
 6846   fixed_latency(2);
 6847 %}
 6848 
 6849 // Pipeline class for compares.
 6850 pipe_class pipe_class_compare()
 6851 %{
 6852   single_instruction;
 6853   fixed_latency(16);
 6854 %}
 6855 
 6856 // Pipeline class for memory operations.
 6857 pipe_class pipe_class_memory()
 6858 %{
 6859   single_instruction;
 6860   fixed_latency(16);
 6861 %}
 6862 
 6863 // Pipeline class for call.
 6864 pipe_class pipe_class_call()
 6865 %{
 6866   single_instruction;
 6867   fixed_latency(100);
 6868 %}
 6869 
 6870 // Define the class for the Nop node.
 6871 define %{
 6872    MachNop = pipe_class_empty;
 6873 %}
 6874 
 6875 %}
 6876 //----------INSTRUCTIONS-------------------------------------------------------
 6877 //
 6878 // match      -- States which machine-independent subtree may be replaced
 6879 //               by this instruction.
 6880 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6881 //               selection to identify a minimum cost tree of machine
 6882 //               instructions that matches a tree of machine-independent
 6883 //               instructions.
 6884 // format     -- A string providing the disassembly for this instruction.
 6885 //               The value of an instruction&#39;s operand may be inserted
 6886 //               by referring to it with a &#39;$&#39; prefix.
 6887 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6888 //               to within an encode class as $primary, $secondary, and $tertiary
 6889 //               rrspectively.  The primary opcode is commonly used to
 6890 //               indicate the type of machine instruction, while secondary
 6891 //               and tertiary are often used for prefix options or addressing
 6892 //               modes.
 6893 // ins_encode -- A list of encode classes with parameters. The encode class
 6894 //               name must have been defined in an &#39;enc_class&#39; specification
 6895 //               in the encode section of the architecture description.
 6896 
 6897 // ============================================================================
 6898 // Memory (Load/Store) Instructions
 6899 
 6900 // Load Instructions
 6901 
 6902 // Load Byte (8 bit signed)
 6903 instruct loadB(iRegINoSp dst, memory1 mem)
 6904 %{
 6905   match(Set dst (LoadB mem));
 6906   predicate(!needs_acquiring_load(n));
 6907 
 6908   ins_cost(4 * INSN_COST);
 6909   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6910 
 6911   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6912 
 6913   ins_pipe(iload_reg_mem);
 6914 %}
 6915 
 6916 // Load Byte (8 bit signed) into long
 6917 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6918 %{
 6919   match(Set dst (ConvI2L (LoadB mem)));
 6920   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6921 
 6922   ins_cost(4 * INSN_COST);
 6923   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6924 
 6925   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6926 
 6927   ins_pipe(iload_reg_mem);
 6928 %}
 6929 
 6930 // Load Byte (8 bit unsigned)
 6931 instruct loadUB(iRegINoSp dst, memory1 mem)
 6932 %{
 6933   match(Set dst (LoadUB mem));
 6934   predicate(!needs_acquiring_load(n));
 6935 
 6936   ins_cost(4 * INSN_COST);
 6937   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6938 
 6939   ins_encode(aarch64_enc_ldrb(dst, mem));
 6940 
 6941   ins_pipe(iload_reg_mem);
 6942 %}
 6943 
 6944 // Load Byte (8 bit unsigned) into long
 6945 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6946 %{
 6947   match(Set dst (ConvI2L (LoadUB mem)));
 6948   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6949 
 6950   ins_cost(4 * INSN_COST);
 6951   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6952 
 6953   ins_encode(aarch64_enc_ldrb(dst, mem));
 6954 
 6955   ins_pipe(iload_reg_mem);
 6956 %}
 6957 
 6958 // Load Short (16 bit signed)
 6959 instruct loadS(iRegINoSp dst, memory2 mem)
 6960 %{
 6961   match(Set dst (LoadS mem));
 6962   predicate(!needs_acquiring_load(n));
 6963 
 6964   ins_cost(4 * INSN_COST);
 6965   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6966 
 6967   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6968 
 6969   ins_pipe(iload_reg_mem);
 6970 %}
 6971 
 6972 // Load Short (16 bit signed) into long
 6973 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6974 %{
 6975   match(Set dst (ConvI2L (LoadS mem)));
 6976   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6977 
 6978   ins_cost(4 * INSN_COST);
 6979   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6980 
 6981   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6982 
 6983   ins_pipe(iload_reg_mem);
 6984 %}
 6985 
 6986 // Load Char (16 bit unsigned)
 6987 instruct loadUS(iRegINoSp dst, memory2 mem)
 6988 %{
 6989   match(Set dst (LoadUS mem));
 6990   predicate(!needs_acquiring_load(n));
 6991 
 6992   ins_cost(4 * INSN_COST);
 6993   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6994 
 6995   ins_encode(aarch64_enc_ldrh(dst, mem));
 6996 
 6997   ins_pipe(iload_reg_mem);
 6998 %}
 6999 
 7000 // Load Short/Char (16 bit unsigned) into long
 7001 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 7002 %{
 7003   match(Set dst (ConvI2L (LoadUS mem)));
 7004   predicate(!needs_acquiring_load(n-&gt;in(1)));
 7005 
 7006   ins_cost(4 * INSN_COST);
 7007   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 7008 
 7009   ins_encode(aarch64_enc_ldrh(dst, mem));
 7010 
 7011   ins_pipe(iload_reg_mem);
 7012 %}
 7013 
 7014 // Load Integer (32 bit signed)
 7015 instruct loadI(iRegINoSp dst, memory4 mem)
 7016 %{
 7017   match(Set dst (LoadI mem));
 7018   predicate(!needs_acquiring_load(n));
 7019 
 7020   ins_cost(4 * INSN_COST);
 7021   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7022 
 7023   ins_encode(aarch64_enc_ldrw(dst, mem));
 7024 
 7025   ins_pipe(iload_reg_mem);
 7026 %}
 7027 
 7028 // Load Integer (32 bit signed) into long
 7029 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 7030 %{
 7031   match(Set dst (ConvI2L (LoadI mem)));
 7032   predicate(!needs_acquiring_load(n-&gt;in(1)));
 7033 
 7034   ins_cost(4 * INSN_COST);
 7035   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 7036 
 7037   ins_encode(aarch64_enc_ldrsw(dst, mem));
 7038 
 7039   ins_pipe(iload_reg_mem);
 7040 %}
 7041 
 7042 // Load Integer (32 bit unsigned) into long
 7043 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 7044 %{
 7045   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7046   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 7047 
 7048   ins_cost(4 * INSN_COST);
 7049   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7050 
 7051   ins_encode(aarch64_enc_ldrw(dst, mem));
 7052 
 7053   ins_pipe(iload_reg_mem);
 7054 %}
 7055 
 7056 // Load Long (64 bit signed)
 7057 instruct loadL(iRegLNoSp dst, memory8 mem)
 7058 %{
 7059   match(Set dst (LoadL mem));
 7060   predicate(!needs_acquiring_load(n));
 7061 
 7062   ins_cost(4 * INSN_COST);
 7063   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7064 
 7065   ins_encode(aarch64_enc_ldr(dst, mem));
 7066 
 7067   ins_pipe(iload_reg_mem);
 7068 %}
 7069 
 7070 // Load Range
 7071 instruct loadRange(iRegINoSp dst, memory4 mem)
 7072 %{
 7073   match(Set dst (LoadRange mem));
 7074 
 7075   ins_cost(4 * INSN_COST);
 7076   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7077 
 7078   ins_encode(aarch64_enc_ldrw(dst, mem));
 7079 
 7080   ins_pipe(iload_reg_mem);
 7081 %}
 7082 
 7083 // Load Pointer
 7084 instruct loadP(iRegPNoSp dst, memory8 mem)
 7085 %{
 7086   match(Set dst (LoadP mem));
 7087   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7088 
 7089   ins_cost(4 * INSN_COST);
 7090   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7091 
 7092   ins_encode(aarch64_enc_ldr(dst, mem));
 7093 
 7094   ins_pipe(iload_reg_mem);
 7095 %}
 7096 
 7097 // Load Compressed Pointer
 7098 instruct loadN(iRegNNoSp dst, memory4 mem)
 7099 %{
 7100   match(Set dst (LoadN mem));
 7101   predicate(!needs_acquiring_load(n));
 7102 
 7103   ins_cost(4 * INSN_COST);
 7104   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7105 
 7106   ins_encode(aarch64_enc_ldrw(dst, mem));
 7107 
 7108   ins_pipe(iload_reg_mem);
 7109 %}
 7110 
 7111 // Load Klass Pointer
 7112 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7113 %{
 7114   match(Set dst (LoadKlass mem));
 7115   predicate(!needs_acquiring_load(n));
 7116 
 7117   ins_cost(4 * INSN_COST);
 7118   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7119 
 7120   ins_encode(aarch64_enc_ldr(dst, mem));
 7121 
 7122   ins_pipe(iload_reg_mem);
 7123 %}
 7124 
 7125 // Load Narrow Klass Pointer
 7126 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7127 %{
 7128   match(Set dst (LoadNKlass mem));
 7129   predicate(!needs_acquiring_load(n));
 7130 
 7131   ins_cost(4 * INSN_COST);
 7132   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7133 
 7134   ins_encode(aarch64_enc_ldrw(dst, mem));
 7135 
 7136   ins_pipe(iload_reg_mem);
 7137 %}
 7138 
 7139 // Load Float
 7140 instruct loadF(vRegF dst, memory4 mem)
 7141 %{
 7142   match(Set dst (LoadF mem));
 7143   predicate(!needs_acquiring_load(n));
 7144 
 7145   ins_cost(4 * INSN_COST);
 7146   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7147 
 7148   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7149 
 7150   ins_pipe(pipe_class_memory);
 7151 %}
 7152 
 7153 // Load Double
 7154 instruct loadD(vRegD dst, memory8 mem)
 7155 %{
 7156   match(Set dst (LoadD mem));
 7157   predicate(!needs_acquiring_load(n));
 7158 
 7159   ins_cost(4 * INSN_COST);
 7160   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7161 
 7162   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7163 
 7164   ins_pipe(pipe_class_memory);
 7165 %}
 7166 
 7167 
 7168 // Load Int Constant
 7169 instruct loadConI(iRegINoSp dst, immI src)
 7170 %{
 7171   match(Set dst src);
 7172 
 7173   ins_cost(INSN_COST);
 7174   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7175 
 7176   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7177 
 7178   ins_pipe(ialu_imm);
 7179 %}
 7180 
 7181 // Load Long Constant
 7182 instruct loadConL(iRegLNoSp dst, immL src)
 7183 %{
 7184   match(Set dst src);
 7185 
 7186   ins_cost(INSN_COST);
 7187   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7188 
 7189   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7190 
 7191   ins_pipe(ialu_imm);
 7192 %}
 7193 
 7194 // Load Pointer Constant
 7195 
 7196 instruct loadConP(iRegPNoSp dst, immP con)
 7197 %{
 7198   match(Set dst con);
 7199 
 7200   ins_cost(INSN_COST * 4);
 7201   format %{
 7202     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7203   %}
 7204 
 7205   ins_encode(aarch64_enc_mov_p(dst, con));
 7206 
 7207   ins_pipe(ialu_imm);
 7208 %}
 7209 
 7210 // Load Null Pointer Constant
 7211 
 7212 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7213 %{
 7214   match(Set dst con);
 7215 
 7216   ins_cost(INSN_COST);
 7217   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7218 
 7219   ins_encode(aarch64_enc_mov_p0(dst, con));
 7220 
 7221   ins_pipe(ialu_imm);
 7222 %}
 7223 
 7224 // Load Pointer Constant One
 7225 
 7226 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7227 %{
 7228   match(Set dst con);
 7229 
 7230   ins_cost(INSN_COST);
 7231   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7232 
 7233   ins_encode(aarch64_enc_mov_p1(dst, con));
 7234 
 7235   ins_pipe(ialu_imm);
 7236 %}
 7237 
 7238 // Load Byte Map Base Constant
 7239 
 7240 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7241 %{
 7242   match(Set dst con);
 7243 
 7244   ins_cost(INSN_COST);
 7245   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7246 
 7247   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7248 
 7249   ins_pipe(ialu_imm);
 7250 %}
 7251 
 7252 // Load Narrow Pointer Constant
 7253 
 7254 instruct loadConN(iRegNNoSp dst, immN con)
 7255 %{
 7256   match(Set dst con);
 7257 
 7258   ins_cost(INSN_COST * 4);
 7259   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7260 
 7261   ins_encode(aarch64_enc_mov_n(dst, con));
 7262 
 7263   ins_pipe(ialu_imm);
 7264 %}
 7265 
 7266 // Load Narrow Null Pointer Constant
 7267 
 7268 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7269 %{
 7270   match(Set dst con);
 7271 
 7272   ins_cost(INSN_COST);
 7273   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7274 
 7275   ins_encode(aarch64_enc_mov_n0(dst, con));
 7276 
 7277   ins_pipe(ialu_imm);
 7278 %}
 7279 
 7280 // Load Narrow Klass Constant
 7281 
 7282 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7283 %{
 7284   match(Set dst con);
 7285 
 7286   ins_cost(INSN_COST);
 7287   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7288 
 7289   ins_encode(aarch64_enc_mov_nk(dst, con));
 7290 
 7291   ins_pipe(ialu_imm);
 7292 %}
 7293 
 7294 // Load Packed Float Constant
 7295 
 7296 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7297   match(Set dst con);
 7298   ins_cost(INSN_COST * 4);
 7299   format %{ &quot;fmovs  $dst, $con&quot;%}
 7300   ins_encode %{
 7301     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7302   %}
 7303 
 7304   ins_pipe(fp_imm_s);
 7305 %}
 7306 
 7307 // Load Float Constant
 7308 
 7309 instruct loadConF(vRegF dst, immF con) %{
 7310   match(Set dst con);
 7311 
 7312   ins_cost(INSN_COST * 4);
 7313 
 7314   format %{
 7315     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7316   %}
 7317 
 7318   ins_encode %{
 7319     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7320   %}
 7321 
 7322   ins_pipe(fp_load_constant_s);
 7323 %}
 7324 
 7325 // Load Packed Double Constant
 7326 
 7327 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7328   match(Set dst con);
 7329   ins_cost(INSN_COST);
 7330   format %{ &quot;fmovd  $dst, $con&quot;%}
 7331   ins_encode %{
 7332     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7333   %}
 7334 
 7335   ins_pipe(fp_imm_d);
 7336 %}
 7337 
 7338 // Load Double Constant
 7339 
 7340 instruct loadConD(vRegD dst, immD con) %{
 7341   match(Set dst con);
 7342 
 7343   ins_cost(INSN_COST * 5);
 7344   format %{
 7345     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7346   %}
 7347 
 7348   ins_encode %{
 7349     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7350   %}
 7351 
 7352   ins_pipe(fp_load_constant_d);
 7353 %}
 7354 
 7355 // Store Instructions
 7356 
 7357 // Store CMS card-mark Immediate
 7358 instruct storeimmCM0(immI0 zero, memory1 mem)
 7359 %{
 7360   match(Set mem (StoreCM mem zero));
 7361 
 7362   ins_cost(INSN_COST);
 7363   format %{ &quot;storestore (elided)\n\t&quot;
 7364             &quot;strb zr, $mem\t# byte&quot; %}
 7365 
 7366   ins_encode(aarch64_enc_strb0(mem));
 7367 
 7368   ins_pipe(istore_mem);
 7369 %}
 7370 
 7371 // Store CMS card-mark Immediate with intervening StoreStore
 7372 // needed when using CMS with no conditional card marking
 7373 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7374 %{
 7375   match(Set mem (StoreCM mem zero));
 7376 
 7377   ins_cost(INSN_COST * 2);
 7378   format %{ &quot;storestore\n\t&quot;
 7379             &quot;dmb ishst&quot;
 7380             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7381 
 7382   ins_encode(aarch64_enc_strb0_ordered(mem));
 7383 
 7384   ins_pipe(istore_mem);
 7385 %}
 7386 
 7387 // Store Byte
 7388 instruct storeB(iRegIorL2I src, memory1 mem)
 7389 %{
 7390   match(Set mem (StoreB mem src));
 7391   predicate(!needs_releasing_store(n));
 7392 
 7393   ins_cost(INSN_COST);
 7394   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7395 
 7396   ins_encode(aarch64_enc_strb(src, mem));
 7397 
 7398   ins_pipe(istore_reg_mem);
 7399 %}
 7400 
 7401 
 7402 instruct storeimmB0(immI0 zero, memory1 mem)
 7403 %{
 7404   match(Set mem (StoreB mem zero));
 7405   predicate(!needs_releasing_store(n));
 7406 
 7407   ins_cost(INSN_COST);
 7408   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7409 
 7410   ins_encode(aarch64_enc_strb0(mem));
 7411 
 7412   ins_pipe(istore_mem);
 7413 %}
 7414 
 7415 // Store Char/Short
 7416 instruct storeC(iRegIorL2I src, memory2 mem)
 7417 %{
 7418   match(Set mem (StoreC mem src));
 7419   predicate(!needs_releasing_store(n));
 7420 
 7421   ins_cost(INSN_COST);
 7422   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7423 
 7424   ins_encode(aarch64_enc_strh(src, mem));
 7425 
 7426   ins_pipe(istore_reg_mem);
 7427 %}
 7428 
 7429 instruct storeimmC0(immI0 zero, memory2 mem)
 7430 %{
 7431   match(Set mem (StoreC mem zero));
 7432   predicate(!needs_releasing_store(n));
 7433 
 7434   ins_cost(INSN_COST);
 7435   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7436 
 7437   ins_encode(aarch64_enc_strh0(mem));
 7438 
 7439   ins_pipe(istore_mem);
 7440 %}
 7441 
 7442 // Store Integer
 7443 
 7444 instruct storeI(iRegIorL2I src, memory4 mem)
 7445 %{
 7446   match(Set mem(StoreI mem src));
 7447   predicate(!needs_releasing_store(n));
 7448 
 7449   ins_cost(INSN_COST);
 7450   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7451 
 7452   ins_encode(aarch64_enc_strw(src, mem));
 7453 
 7454   ins_pipe(istore_reg_mem);
 7455 %}
 7456 
 7457 instruct storeimmI0(immI0 zero, memory4 mem)
 7458 %{
 7459   match(Set mem(StoreI mem zero));
 7460   predicate(!needs_releasing_store(n));
 7461 
 7462   ins_cost(INSN_COST);
 7463   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7464 
 7465   ins_encode(aarch64_enc_strw0(mem));
 7466 
 7467   ins_pipe(istore_mem);
 7468 %}
 7469 
 7470 // Store Long (64 bit signed)
 7471 instruct storeL(iRegL src, memory8 mem)
 7472 %{
 7473   match(Set mem (StoreL mem src));
 7474   predicate(!needs_releasing_store(n));
 7475 
 7476   ins_cost(INSN_COST);
 7477   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7478 
 7479   ins_encode(aarch64_enc_str(src, mem));
 7480 
 7481   ins_pipe(istore_reg_mem);
 7482 %}
 7483 
 7484 // Store Long (64 bit signed)
 7485 instruct storeimmL0(immL0 zero, memory8 mem)
 7486 %{
 7487   match(Set mem (StoreL mem zero));
 7488   predicate(!needs_releasing_store(n));
 7489 
 7490   ins_cost(INSN_COST);
 7491   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7492 
 7493   ins_encode(aarch64_enc_str0(mem));
 7494 
 7495   ins_pipe(istore_mem);
 7496 %}
 7497 
 7498 // Store Pointer
 7499 instruct storeP(iRegP src, memory8 mem)
 7500 %{
 7501   match(Set mem (StoreP mem src));
 7502   predicate(!needs_releasing_store(n));
 7503 
 7504   ins_cost(INSN_COST);
 7505   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7506 
 7507   ins_encode(aarch64_enc_str(src, mem));
 7508 
 7509   ins_pipe(istore_reg_mem);
 7510 %}
 7511 
 7512 // Store Pointer
 7513 instruct storeimmP0(immP0 zero, memory8 mem)
 7514 %{
 7515   match(Set mem (StoreP mem zero));
 7516   predicate(!needs_releasing_store(n));
 7517 
 7518   ins_cost(INSN_COST);
 7519   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7520 
 7521   ins_encode(aarch64_enc_str0(mem));
 7522 
 7523   ins_pipe(istore_mem);
 7524 %}
 7525 
 7526 // Store Compressed Pointer
 7527 instruct storeN(iRegN src, memory4 mem)
 7528 %{
 7529   match(Set mem (StoreN mem src));
 7530   predicate(!needs_releasing_store(n));
 7531 
 7532   ins_cost(INSN_COST);
 7533   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7534 
 7535   ins_encode(aarch64_enc_strw(src, mem));
 7536 
 7537   ins_pipe(istore_reg_mem);
 7538 %}
 7539 
 7540 instruct storeImmN0(immN0 zero, memory4 mem)
 7541 %{
 7542   match(Set mem (StoreN mem zero));
 7543   predicate(!needs_releasing_store(n));
 7544 
 7545   ins_cost(INSN_COST);
 7546   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7547 
 7548   ins_encode(aarch64_enc_strw0(mem));
 7549 
 7550   ins_pipe(istore_mem);
 7551 %}
 7552 
 7553 // Store Float
 7554 instruct storeF(vRegF src, memory4 mem)
 7555 %{
 7556   match(Set mem (StoreF mem src));
 7557   predicate(!needs_releasing_store(n));
 7558 
 7559   ins_cost(INSN_COST);
 7560   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7561 
 7562   ins_encode( aarch64_enc_strs(src, mem) );
 7563 
 7564   ins_pipe(pipe_class_memory);
 7565 %}
 7566 
 7567 // TODO
 7568 // implement storeImmF0 and storeFImmPacked
 7569 
 7570 // Store Double
 7571 instruct storeD(vRegD src, memory8 mem)
 7572 %{
 7573   match(Set mem (StoreD mem src));
 7574   predicate(!needs_releasing_store(n));
 7575 
 7576   ins_cost(INSN_COST);
 7577   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7578 
 7579   ins_encode( aarch64_enc_strd(src, mem) );
 7580 
 7581   ins_pipe(pipe_class_memory);
 7582 %}
 7583 
 7584 // Store Compressed Klass Pointer
 7585 instruct storeNKlass(iRegN src, memory4 mem)
 7586 %{
 7587   predicate(!needs_releasing_store(n));
 7588   match(Set mem (StoreNKlass mem src));
 7589 
 7590   ins_cost(INSN_COST);
 7591   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7592 
 7593   ins_encode(aarch64_enc_strw(src, mem));
 7594 
 7595   ins_pipe(istore_reg_mem);
 7596 %}
 7597 
 7598 // TODO
 7599 // implement storeImmD0 and storeDImmPacked
 7600 
 7601 // prefetch instructions
 7602 // Must be safe to execute with invalid address (cannot fault).
 7603 
 7604 instruct prefetchalloc( memory8 mem ) %{
 7605   match(PrefetchAllocation mem);
 7606 
 7607   ins_cost(INSN_COST);
 7608   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7609 
 7610   ins_encode( aarch64_enc_prefetchw(mem) );
 7611 
 7612   ins_pipe(iload_prefetch);
 7613 %}
 7614 
 7615 //  ---------------- volatile loads and stores ----------------
 7616 
 7617 // Load Byte (8 bit signed)
 7618 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7619 %{
 7620   match(Set dst (LoadB mem));
 7621 
 7622   ins_cost(VOLATILE_REF_COST);
 7623   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7624 
 7625   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7626 
 7627   ins_pipe(pipe_serial);
 7628 %}
 7629 
 7630 // Load Byte (8 bit signed) into long
 7631 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7632 %{
 7633   match(Set dst (ConvI2L (LoadB mem)));
 7634 
 7635   ins_cost(VOLATILE_REF_COST);
 7636   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7637 
 7638   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7639 
 7640   ins_pipe(pipe_serial);
 7641 %}
 7642 
 7643 // Load Byte (8 bit unsigned)
 7644 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7645 %{
 7646   match(Set dst (LoadUB mem));
 7647 
 7648   ins_cost(VOLATILE_REF_COST);
 7649   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7650 
 7651   ins_encode(aarch64_enc_ldarb(dst, mem));
 7652 
 7653   ins_pipe(pipe_serial);
 7654 %}
 7655 
 7656 // Load Byte (8 bit unsigned) into long
 7657 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7658 %{
 7659   match(Set dst (ConvI2L (LoadUB mem)));
 7660 
 7661   ins_cost(VOLATILE_REF_COST);
 7662   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7663 
 7664   ins_encode(aarch64_enc_ldarb(dst, mem));
 7665 
 7666   ins_pipe(pipe_serial);
 7667 %}
 7668 
 7669 // Load Short (16 bit signed)
 7670 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7671 %{
 7672   match(Set dst (LoadS mem));
 7673 
 7674   ins_cost(VOLATILE_REF_COST);
 7675   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7676 
 7677   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7678 
 7679   ins_pipe(pipe_serial);
 7680 %}
 7681 
 7682 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7683 %{
 7684   match(Set dst (LoadUS mem));
 7685 
 7686   ins_cost(VOLATILE_REF_COST);
 7687   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7688 
 7689   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7690 
 7691   ins_pipe(pipe_serial);
 7692 %}
 7693 
 7694 // Load Short/Char (16 bit unsigned) into long
 7695 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7696 %{
 7697   match(Set dst (ConvI2L (LoadUS mem)));
 7698 
 7699   ins_cost(VOLATILE_REF_COST);
 7700   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7701 
 7702   ins_encode(aarch64_enc_ldarh(dst, mem));
 7703 
 7704   ins_pipe(pipe_serial);
 7705 %}
 7706 
 7707 // Load Short/Char (16 bit signed) into long
 7708 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7709 %{
 7710   match(Set dst (ConvI2L (LoadS mem)));
 7711 
 7712   ins_cost(VOLATILE_REF_COST);
 7713   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7714 
 7715   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7716 
 7717   ins_pipe(pipe_serial);
 7718 %}
 7719 
 7720 // Load Integer (32 bit signed)
 7721 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7722 %{
 7723   match(Set dst (LoadI mem));
 7724 
 7725   ins_cost(VOLATILE_REF_COST);
 7726   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7727 
 7728   ins_encode(aarch64_enc_ldarw(dst, mem));
 7729 
 7730   ins_pipe(pipe_serial);
 7731 %}
 7732 
 7733 // Load Integer (32 bit unsigned) into long
 7734 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7735 %{
 7736   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7737 
 7738   ins_cost(VOLATILE_REF_COST);
 7739   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7740 
 7741   ins_encode(aarch64_enc_ldarw(dst, mem));
 7742 
 7743   ins_pipe(pipe_serial);
 7744 %}
 7745 
 7746 // Load Long (64 bit signed)
 7747 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7748 %{
 7749   match(Set dst (LoadL mem));
 7750 
 7751   ins_cost(VOLATILE_REF_COST);
 7752   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7753 
 7754   ins_encode(aarch64_enc_ldar(dst, mem));
 7755 
 7756   ins_pipe(pipe_serial);
 7757 %}
 7758 
 7759 // Load Pointer
 7760 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7761 %{
 7762   match(Set dst (LoadP mem));
 7763   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7764 
 7765   ins_cost(VOLATILE_REF_COST);
 7766   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7767 
 7768   ins_encode(aarch64_enc_ldar(dst, mem));
 7769 
 7770   ins_pipe(pipe_serial);
 7771 %}
 7772 
 7773 // Load Compressed Pointer
 7774 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7775 %{
 7776   match(Set dst (LoadN mem));
 7777 
 7778   ins_cost(VOLATILE_REF_COST);
 7779   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7780 
 7781   ins_encode(aarch64_enc_ldarw(dst, mem));
 7782 
 7783   ins_pipe(pipe_serial);
 7784 %}
 7785 
 7786 // Load Float
 7787 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7788 %{
 7789   match(Set dst (LoadF mem));
 7790 
 7791   ins_cost(VOLATILE_REF_COST);
 7792   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7793 
 7794   ins_encode( aarch64_enc_fldars(dst, mem) );
 7795 
 7796   ins_pipe(pipe_serial);
 7797 %}
 7798 
 7799 // Load Double
 7800 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7801 %{
 7802   match(Set dst (LoadD mem));
 7803 
 7804   ins_cost(VOLATILE_REF_COST);
 7805   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7806 
 7807   ins_encode( aarch64_enc_fldard(dst, mem) );
 7808 
 7809   ins_pipe(pipe_serial);
 7810 %}
 7811 
 7812 // Store Byte
 7813 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7814 %{
 7815   match(Set mem (StoreB mem src));
 7816 
 7817   ins_cost(VOLATILE_REF_COST);
 7818   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7819 
 7820   ins_encode(aarch64_enc_stlrb(src, mem));
 7821 
 7822   ins_pipe(pipe_class_memory);
 7823 %}
 7824 
 7825 // Store Char/Short
 7826 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7827 %{
 7828   match(Set mem (StoreC mem src));
 7829 
 7830   ins_cost(VOLATILE_REF_COST);
 7831   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7832 
 7833   ins_encode(aarch64_enc_stlrh(src, mem));
 7834 
 7835   ins_pipe(pipe_class_memory);
 7836 %}
 7837 
 7838 // Store Integer
 7839 
 7840 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7841 %{
 7842   match(Set mem(StoreI mem src));
 7843 
 7844   ins_cost(VOLATILE_REF_COST);
 7845   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7846 
 7847   ins_encode(aarch64_enc_stlrw(src, mem));
 7848 
 7849   ins_pipe(pipe_class_memory);
 7850 %}
 7851 
 7852 // Store Long (64 bit signed)
 7853 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7854 %{
 7855   match(Set mem (StoreL mem src));
 7856 
 7857   ins_cost(VOLATILE_REF_COST);
 7858   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7859 
 7860   ins_encode(aarch64_enc_stlr(src, mem));
 7861 
 7862   ins_pipe(pipe_class_memory);
 7863 %}
 7864 
 7865 // Store Pointer
 7866 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7867 %{
 7868   match(Set mem (StoreP mem src));
 7869 
 7870   ins_cost(VOLATILE_REF_COST);
 7871   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7872 
 7873   ins_encode(aarch64_enc_stlr(src, mem));
 7874 
 7875   ins_pipe(pipe_class_memory);
 7876 %}
 7877 
 7878 // Store Compressed Pointer
 7879 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7880 %{
 7881   match(Set mem (StoreN mem src));
 7882 
 7883   ins_cost(VOLATILE_REF_COST);
 7884   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7885 
 7886   ins_encode(aarch64_enc_stlrw(src, mem));
 7887 
 7888   ins_pipe(pipe_class_memory);
 7889 %}
 7890 
 7891 // Store Float
 7892 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7893 %{
 7894   match(Set mem (StoreF mem src));
 7895 
 7896   ins_cost(VOLATILE_REF_COST);
 7897   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7898 
 7899   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7900 
 7901   ins_pipe(pipe_class_memory);
 7902 %}
 7903 
 7904 // TODO
 7905 // implement storeImmF0 and storeFImmPacked
 7906 
 7907 // Store Double
 7908 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7909 %{
 7910   match(Set mem (StoreD mem src));
 7911 
 7912   ins_cost(VOLATILE_REF_COST);
 7913   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7914 
 7915   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7916 
 7917   ins_pipe(pipe_class_memory);
 7918 %}
 7919 
 7920 //  ---------------- end of volatile loads and stores ----------------
 7921 
 7922 instruct cacheWB(indirect addr)
 7923 %{
 7924   predicate(VM_Version::supports_data_cache_line_flush());
 7925   match(CacheWB addr);
 7926 
 7927   ins_cost(100);
 7928   format %{&quot;cache wb $addr&quot; %}
 7929   ins_encode %{
 7930     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7931     assert($addr$$disp == 0, &quot;should be&quot;);
 7932     __ cache_wb(Address($addr$$base$$Register, 0));
 7933   %}
 7934   ins_pipe(pipe_slow); // XXX
 7935 %}
 7936 
 7937 instruct cacheWBPreSync()
 7938 %{
 7939   predicate(VM_Version::supports_data_cache_line_flush());
 7940   match(CacheWBPreSync);
 7941 
 7942   ins_cost(100);
 7943   format %{&quot;cache wb presync&quot; %}
 7944   ins_encode %{
 7945     __ cache_wbsync(true);
 7946   %}
 7947   ins_pipe(pipe_slow); // XXX
 7948 %}
 7949 
 7950 instruct cacheWBPostSync()
 7951 %{
 7952   predicate(VM_Version::supports_data_cache_line_flush());
 7953   match(CacheWBPostSync);
 7954 
 7955   ins_cost(100);
 7956   format %{&quot;cache wb postsync&quot; %}
 7957   ins_encode %{
 7958     __ cache_wbsync(false);
 7959   %}
 7960   ins_pipe(pipe_slow); // XXX
 7961 %}
 7962 
 7963 // ============================================================================
 7964 // BSWAP Instructions
 7965 
 7966 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7967   match(Set dst (ReverseBytesI src));
 7968 
 7969   ins_cost(INSN_COST);
 7970   format %{ &quot;revw  $dst, $src&quot; %}
 7971 
 7972   ins_encode %{
 7973     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7974   %}
 7975 
 7976   ins_pipe(ialu_reg);
 7977 %}
 7978 
 7979 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7980   match(Set dst (ReverseBytesL src));
 7981 
 7982   ins_cost(INSN_COST);
 7983   format %{ &quot;rev  $dst, $src&quot; %}
 7984 
 7985   ins_encode %{
 7986     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7987   %}
 7988 
 7989   ins_pipe(ialu_reg);
 7990 %}
 7991 
 7992 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7993   match(Set dst (ReverseBytesUS src));
 7994 
 7995   ins_cost(INSN_COST);
 7996   format %{ &quot;rev16w  $dst, $src&quot; %}
 7997 
 7998   ins_encode %{
 7999     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 8000   %}
 8001 
 8002   ins_pipe(ialu_reg);
 8003 %}
 8004 
 8005 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 8006   match(Set dst (ReverseBytesS src));
 8007 
 8008   ins_cost(INSN_COST);
 8009   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 8010             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 8011 
 8012   ins_encode %{
 8013     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 8014     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 8015   %}
 8016 
 8017   ins_pipe(ialu_reg);
 8018 %}
 8019 
 8020 // ============================================================================
 8021 // Zero Count Instructions
 8022 
 8023 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8024   match(Set dst (CountLeadingZerosI src));
 8025 
 8026   ins_cost(INSN_COST);
 8027   format %{ &quot;clzw  $dst, $src&quot; %}
 8028   ins_encode %{
 8029     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 8030   %}
 8031 
 8032   ins_pipe(ialu_reg);
 8033 %}
 8034 
 8035 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 8036   match(Set dst (CountLeadingZerosL src));
 8037 
 8038   ins_cost(INSN_COST);
 8039   format %{ &quot;clz   $dst, $src&quot; %}
 8040   ins_encode %{
 8041     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 8042   %}
 8043 
 8044   ins_pipe(ialu_reg);
 8045 %}
 8046 
 8047 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8048   match(Set dst (CountTrailingZerosI src));
 8049 
 8050   ins_cost(INSN_COST * 2);
 8051   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8052             &quot;clzw   $dst, $dst&quot; %}
 8053   ins_encode %{
 8054     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8055     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8056   %}
 8057 
 8058   ins_pipe(ialu_reg);
 8059 %}
 8060 
 8061 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8062   match(Set dst (CountTrailingZerosL src));
 8063 
 8064   ins_cost(INSN_COST * 2);
 8065   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8066             &quot;clz    $dst, $dst&quot; %}
 8067   ins_encode %{
 8068     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8069     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8070   %}
 8071 
 8072   ins_pipe(ialu_reg);
 8073 %}
 8074 
 8075 //---------- Population Count Instructions -------------------------------------
 8076 //
 8077 
 8078 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8079   predicate(UsePopCountInstruction);
 8080   match(Set dst (PopCountI src));
 8081   effect(TEMP tmp);
 8082   ins_cost(INSN_COST * 13);
 8083 
 8084   format %{ &quot;movw   $src, $src\n\t&quot;
 8085             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8086             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8087             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8088             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8089   ins_encode %{
 8090     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8091     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8092     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8093     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8094     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8095   %}
 8096 
 8097   ins_pipe(pipe_class_default);
 8098 %}
 8099 
 8100 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8101   predicate(UsePopCountInstruction);
 8102   match(Set dst (PopCountI (LoadI mem)));
 8103   effect(TEMP tmp);
 8104   ins_cost(INSN_COST * 13);
 8105 
 8106   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8107             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8108             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8109             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8110   ins_encode %{
 8111     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8112     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8113               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8114     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8115     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8116     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8117   %}
 8118 
 8119   ins_pipe(pipe_class_default);
 8120 %}
 8121 
 8122 // Note: Long.bitCount(long) returns an int.
 8123 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8124   predicate(UsePopCountInstruction);
 8125   match(Set dst (PopCountL src));
 8126   effect(TEMP tmp);
 8127   ins_cost(INSN_COST * 13);
 8128 
 8129   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8130             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8131             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8132             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8133   ins_encode %{
 8134     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8135     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8136     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8137     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8138   %}
 8139 
 8140   ins_pipe(pipe_class_default);
 8141 %}
 8142 
 8143 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8144   predicate(UsePopCountInstruction);
 8145   match(Set dst (PopCountL (LoadL mem)));
 8146   effect(TEMP tmp);
 8147   ins_cost(INSN_COST * 13);
 8148 
 8149   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8150             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8151             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8152             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8153   ins_encode %{
 8154     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8155     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8156               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8157     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8158     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8159     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8160   %}
 8161 
 8162   ins_pipe(pipe_class_default);
 8163 %}
 8164 
 8165 // ============================================================================
 8166 // MemBar Instruction
 8167 
 8168 instruct load_fence() %{
 8169   match(LoadFence);
 8170   ins_cost(VOLATILE_REF_COST);
 8171 
 8172   format %{ &quot;load_fence&quot; %}
 8173 
 8174   ins_encode %{
 8175     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8176   %}
 8177   ins_pipe(pipe_serial);
 8178 %}
 8179 
 8180 instruct unnecessary_membar_acquire() %{
 8181   predicate(unnecessary_acquire(n));
 8182   match(MemBarAcquire);
 8183   ins_cost(0);
 8184 
 8185   format %{ &quot;membar_acquire (elided)&quot; %}
 8186 
 8187   ins_encode %{
 8188     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8189   %}
 8190 
 8191   ins_pipe(pipe_class_empty);
 8192 %}
 8193 
 8194 instruct membar_acquire() %{
 8195   match(MemBarAcquire);
 8196   ins_cost(VOLATILE_REF_COST);
 8197 
 8198   format %{ &quot;membar_acquire\n\t&quot;
 8199             &quot;dmb ish&quot; %}
 8200 
 8201   ins_encode %{
 8202     __ block_comment(&quot;membar_acquire&quot;);
 8203     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8204   %}
 8205 
 8206   ins_pipe(pipe_serial);
 8207 %}
 8208 
 8209 
 8210 instruct membar_acquire_lock() %{
 8211   match(MemBarAcquireLock);
 8212   ins_cost(VOLATILE_REF_COST);
 8213 
 8214   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8215 
 8216   ins_encode %{
 8217     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8218   %}
 8219 
 8220   ins_pipe(pipe_serial);
 8221 %}
 8222 
 8223 instruct store_fence() %{
 8224   match(StoreFence);
 8225   ins_cost(VOLATILE_REF_COST);
 8226 
 8227   format %{ &quot;store_fence&quot; %}
 8228 
 8229   ins_encode %{
 8230     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8231   %}
 8232   ins_pipe(pipe_serial);
 8233 %}
 8234 
 8235 instruct unnecessary_membar_release() %{
 8236   predicate(unnecessary_release(n));
 8237   match(MemBarRelease);
 8238   ins_cost(0);
 8239 
 8240   format %{ &quot;membar_release (elided)&quot; %}
 8241 
 8242   ins_encode %{
 8243     __ block_comment(&quot;membar_release (elided)&quot;);
 8244   %}
 8245   ins_pipe(pipe_serial);
 8246 %}
 8247 
 8248 instruct membar_release() %{
 8249   match(MemBarRelease);
 8250   ins_cost(VOLATILE_REF_COST);
 8251 
 8252   format %{ &quot;membar_release\n\t&quot;
 8253             &quot;dmb ish&quot; %}
 8254 
 8255   ins_encode %{
 8256     __ block_comment(&quot;membar_release&quot;);
 8257     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8258   %}
 8259   ins_pipe(pipe_serial);
 8260 %}
 8261 
 8262 instruct membar_storestore() %{
 8263   match(MemBarStoreStore);
 8264   ins_cost(VOLATILE_REF_COST);
 8265 
 8266   format %{ &quot;MEMBAR-store-store&quot; %}
 8267 
 8268   ins_encode %{
 8269     __ membar(Assembler::StoreStore);
 8270   %}
 8271   ins_pipe(pipe_serial);
 8272 %}
 8273 
 8274 instruct membar_release_lock() %{
 8275   match(MemBarReleaseLock);
 8276   ins_cost(VOLATILE_REF_COST);
 8277 
 8278   format %{ &quot;membar_release_lock (elided)&quot; %}
 8279 
 8280   ins_encode %{
 8281     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8282   %}
 8283 
 8284   ins_pipe(pipe_serial);
 8285 %}
 8286 
 8287 instruct unnecessary_membar_volatile() %{
 8288   predicate(unnecessary_volatile(n));
 8289   match(MemBarVolatile);
 8290   ins_cost(0);
 8291 
 8292   format %{ &quot;membar_volatile (elided)&quot; %}
 8293 
 8294   ins_encode %{
 8295     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8296   %}
 8297 
 8298   ins_pipe(pipe_serial);
 8299 %}
 8300 
 8301 instruct membar_volatile() %{
 8302   match(MemBarVolatile);
 8303   ins_cost(VOLATILE_REF_COST*100);
 8304 
 8305   format %{ &quot;membar_volatile\n\t&quot;
 8306              &quot;dmb ish&quot;%}
 8307 
 8308   ins_encode %{
 8309     __ block_comment(&quot;membar_volatile&quot;);
 8310     __ membar(Assembler::StoreLoad);
 8311   %}
 8312 
 8313   ins_pipe(pipe_serial);
 8314 %}
 8315 
 8316 // ============================================================================
 8317 // Cast/Convert Instructions
 8318 
 8319 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8320   match(Set dst (CastX2P src));
 8321 
 8322   ins_cost(INSN_COST);
 8323   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8324 
 8325   ins_encode %{
 8326     if ($dst$$reg != $src$$reg) {
 8327       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8328     }
 8329   %}
 8330 
 8331   ins_pipe(ialu_reg);
 8332 %}
 8333 
 8334 instruct castN2X(iRegLNoSp dst, iRegN src) %{
 8335   match(Set dst (CastP2X src));
 8336 
 8337   ins_cost(INSN_COST);
 8338   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8339 
 8340   ins_encode %{
 8341     if ($dst$$reg != $src$$reg) {
 8342       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8343     }
 8344   %}
 8345 
 8346   ins_pipe(ialu_reg);
 8347 %}
 8348 
 8349 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8350   match(Set dst (CastP2X src));
 8351 
 8352   ins_cost(INSN_COST);
 8353   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8354 
 8355   ins_encode %{
 8356     if ($dst$$reg != $src$$reg) {
 8357       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8358     }
 8359   %}
 8360 
 8361   ins_pipe(ialu_reg);
 8362 %}
 8363 
 8364 instruct castN2I(iRegINoSp dst, iRegN src) %{
 8365   match(Set dst (CastN2I src));
 8366 
 8367   ins_cost(INSN_COST);
 8368   format %{ &quot;movw $dst, $src\t# compressed ptr -&gt; int&quot; %}
 8369 
 8370   ins_encode %{
 8371     if ($dst$$reg != $src$$reg) {
 8372       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8373     }
 8374   %}
 8375 
 8376   ins_pipe(ialu_reg);
 8377 %}
 8378 
 8379 instruct castI2N(iRegNNoSp dst, iRegI src) %{
 8380   match(Set dst (CastI2N src));
 8381 
 8382   ins_cost(INSN_COST);
 8383   format %{ &quot;movw $dst, $src\t# int -&gt; compressed ptr&quot; %}
 8384 
 8385   ins_encode %{
 8386     if ($dst$$reg != $src$$reg) {
 8387       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8388     }
 8389   %}
 8390 
 8391   ins_pipe(ialu_reg);
 8392 %}
 8393 
 8394 
 8395 // Convert oop into int for vectors alignment masking
 8396 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8397   match(Set dst (ConvL2I (CastP2X src)));
 8398 
 8399   ins_cost(INSN_COST);
 8400   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8401   ins_encode %{
 8402     __ movw($dst$$Register, $src$$Register);
 8403   %}
 8404 
 8405   ins_pipe(ialu_reg);
 8406 %}
 8407 
 8408 // Convert compressed oop into int for vectors alignment masking
 8409 // in case of 32bit oops (heap &lt; 4Gb).
 8410 instruct convN2I(iRegINoSp dst, iRegN src)
 8411 %{
 8412   predicate(CompressedOops::shift() == 0);
 8413   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8414 
 8415   ins_cost(INSN_COST);
 8416   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8417   ins_encode %{
 8418     __ movw($dst$$Register, $src$$Register);
 8419   %}
 8420 
 8421   ins_pipe(ialu_reg);
 8422 %}
 8423 
 8424 
 8425 // Convert oop pointer into compressed form
 8426 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8427   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8428   match(Set dst (EncodeP src));
 8429   effect(KILL cr);
 8430   ins_cost(INSN_COST * 3);
 8431   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8432   ins_encode %{
 8433     Register s = $src$$Register;
 8434     Register d = $dst$$Register;
 8435     __ encode_heap_oop(d, s);
 8436   %}
 8437   ins_pipe(ialu_reg);
 8438 %}
 8439 
 8440 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8441   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8442   match(Set dst (EncodeP src));
 8443   ins_cost(INSN_COST * 3);
 8444   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8445   ins_encode %{
 8446     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8447   %}
 8448   ins_pipe(ialu_reg);
 8449 %}
 8450 
 8451 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8452   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8453             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8454   match(Set dst (DecodeN src));
 8455   ins_cost(INSN_COST * 3);
 8456   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8457   ins_encode %{
 8458     Register s = $src$$Register;
 8459     Register d = $dst$$Register;
 8460     __ decode_heap_oop(d, s);
 8461   %}
 8462   ins_pipe(ialu_reg);
 8463 %}
 8464 
 8465 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8466   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8467             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8468   match(Set dst (DecodeN src));
 8469   ins_cost(INSN_COST * 3);
 8470   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8471   ins_encode %{
 8472     Register s = $src$$Register;
 8473     Register d = $dst$$Register;
 8474     __ decode_heap_oop_not_null(d, s);
 8475   %}
 8476   ins_pipe(ialu_reg);
 8477 %}
 8478 
 8479 // n.b. AArch64 implementations of encode_klass_not_null and
 8480 // decode_klass_not_null do not modify the flags register so, unlike
 8481 // Intel, we don&#39;t kill CR as a side effect here
 8482 
 8483 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8484   match(Set dst (EncodePKlass src));
 8485 
 8486   ins_cost(INSN_COST * 3);
 8487   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8488 
 8489   ins_encode %{
 8490     Register src_reg = as_Register($src$$reg);
 8491     Register dst_reg = as_Register($dst$$reg);
 8492     __ encode_klass_not_null(dst_reg, src_reg);
 8493   %}
 8494 
 8495    ins_pipe(ialu_reg);
 8496 %}
 8497 
 8498 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8499   match(Set dst (DecodeNKlass src));
 8500 
 8501   ins_cost(INSN_COST * 3);
 8502   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8503 
 8504   ins_encode %{
 8505     Register src_reg = as_Register($src$$reg);
 8506     Register dst_reg = as_Register($dst$$reg);
 8507     if (dst_reg != src_reg) {
 8508       __ decode_klass_not_null(dst_reg, src_reg);
 8509     } else {
 8510       __ decode_klass_not_null(dst_reg);
 8511     }
 8512   %}
 8513 
 8514    ins_pipe(ialu_reg);
 8515 %}
 8516 
 8517 instruct checkCastPP(iRegPNoSp dst)
 8518 %{
 8519   match(Set dst (CheckCastPP dst));
 8520 
 8521   size(0);
 8522   format %{ &quot;# checkcastPP of $dst&quot; %}
 8523   ins_encode(/* empty encoding */);
 8524   ins_pipe(pipe_class_empty);
 8525 %}
 8526 
 8527 instruct castPP(iRegPNoSp dst)
 8528 %{
 8529   match(Set dst (CastPP dst));
 8530 
 8531   size(0);
 8532   format %{ &quot;# castPP of $dst&quot; %}
 8533   ins_encode(/* empty encoding */);
 8534   ins_pipe(pipe_class_empty);
 8535 %}
 8536 
 8537 instruct castII(iRegI dst)
 8538 %{
 8539   match(Set dst (CastII dst));
 8540 
 8541   size(0);
 8542   format %{ &quot;# castII of $dst&quot; %}
 8543   ins_encode(/* empty encoding */);
 8544   ins_cost(0);
 8545   ins_pipe(pipe_class_empty);
 8546 %}
 8547 
 8548 // ============================================================================
 8549 // Atomic operation instructions
 8550 //
 8551 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8552 // Store{PIL}Conditional instructions using a normal load for the
 8553 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8554 //
 8555 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8556 // pair to lock object allocations from Eden space when not using
 8557 // TLABs.
 8558 //
 8559 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8560 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8561 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8562 // only for 64-bit.
 8563 //
 8564 // We implement LoadPLocked and StorePLocked instructions using,
 8565 // respectively the AArch64 hw load-exclusive and store-conditional
 8566 // instructions. Whereas we must implement each of
 8567 // Store{IL}Conditional using a CAS which employs a pair of
 8568 // instructions comprising a load-exclusive followed by a
 8569 // store-conditional.
 8570 
 8571 
 8572 // Locked-load (linked load) of the current heap-top
 8573 // used when updating the eden heap top
 8574 // implemented using ldaxr on AArch64
 8575 
 8576 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8577 %{
 8578   match(Set dst (LoadPLocked mem));
 8579 
 8580   ins_cost(VOLATILE_REF_COST);
 8581 
 8582   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8583 
 8584   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8585 
 8586   ins_pipe(pipe_serial);
 8587 %}
 8588 
 8589 // Conditional-store of the updated heap-top.
 8590 // Used during allocation of the shared heap.
 8591 // Sets flag (EQ) on success.
 8592 // implemented using stlxr on AArch64.
 8593 
 8594 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8595 %{
 8596   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8597 
 8598   ins_cost(VOLATILE_REF_COST);
 8599 
 8600  // TODO
 8601  // do we need to do a store-conditional release or can we just use a
 8602  // plain store-conditional?
 8603 
 8604   format %{
 8605     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8606     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8607   %}
 8608 
 8609   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8610 
 8611   ins_pipe(pipe_serial);
 8612 %}
 8613 
 8614 
 8615 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8616 // when attempting to rebias a lock towards the current thread.  We
 8617 // must use the acquire form of cmpxchg in order to guarantee acquire
 8618 // semantics in this case.
 8619 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8620 %{
 8621   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8622 
 8623   ins_cost(VOLATILE_REF_COST);
 8624 
 8625   format %{
 8626     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8627     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8628   %}
 8629 
 8630   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8631 
 8632   ins_pipe(pipe_slow);
 8633 %}
 8634 
 8635 // storeIConditional also has acquire semantics, for no better reason
 8636 // than matching storeLConditional.  At the time of writing this
 8637 // comment storeIConditional was not used anywhere by AArch64.
 8638 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8639 %{
 8640   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8641 
 8642   ins_cost(VOLATILE_REF_COST);
 8643 
 8644   format %{
 8645     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8646     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8647   %}
 8648 
 8649   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8650 
 8651   ins_pipe(pipe_slow);
 8652 %}
 8653 
 8654 // standard CompareAndSwapX when we are using barriers
 8655 // these have higher priority than the rules selected by a predicate
 8656 
 8657 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8658 // can&#39;t match them
 8659 
 8660 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8661 
 8662   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8663   ins_cost(2 * VOLATILE_REF_COST);
 8664 
 8665   effect(KILL cr);
 8666 
 8667   format %{
 8668     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8669     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8670   %}
 8671 
 8672   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8673             aarch64_enc_cset_eq(res));
 8674 
 8675   ins_pipe(pipe_slow);
 8676 %}
 8677 
 8678 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8679 
 8680   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8681   ins_cost(2 * VOLATILE_REF_COST);
 8682 
 8683   effect(KILL cr);
 8684 
 8685   format %{
 8686     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8687     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8688   %}
 8689 
 8690   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8691             aarch64_enc_cset_eq(res));
 8692 
 8693   ins_pipe(pipe_slow);
 8694 %}
 8695 
 8696 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8697 
 8698   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8699   ins_cost(2 * VOLATILE_REF_COST);
 8700 
 8701   effect(KILL cr);
 8702 
 8703  format %{
 8704     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8705     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8706  %}
 8707 
 8708  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8709             aarch64_enc_cset_eq(res));
 8710 
 8711   ins_pipe(pipe_slow);
 8712 %}
 8713 
 8714 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8715 
 8716   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8717   ins_cost(2 * VOLATILE_REF_COST);
 8718 
 8719   effect(KILL cr);
 8720 
 8721  format %{
 8722     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8723     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8724  %}
 8725 
 8726  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8727             aarch64_enc_cset_eq(res));
 8728 
 8729   ins_pipe(pipe_slow);
 8730 %}
 8731 
 8732 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8733 
 8734   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8735   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8736   ins_cost(2 * VOLATILE_REF_COST);
 8737 
 8738   effect(KILL cr);
 8739 
 8740  format %{
 8741     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8742     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8743  %}
 8744 
 8745  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8746             aarch64_enc_cset_eq(res));
 8747 
 8748   ins_pipe(pipe_slow);
 8749 %}
 8750 
 8751 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8752 
 8753   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8754   ins_cost(2 * VOLATILE_REF_COST);
 8755 
 8756   effect(KILL cr);
 8757 
 8758  format %{
 8759     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8760     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8761  %}
 8762 
 8763  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8764             aarch64_enc_cset_eq(res));
 8765 
 8766   ins_pipe(pipe_slow);
 8767 %}
 8768 
 8769 // alternative CompareAndSwapX when we are eliding barriers
 8770 
 8771 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8772 
 8773   predicate(needs_acquiring_load_exclusive(n));
 8774   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8775   ins_cost(VOLATILE_REF_COST);
 8776 
 8777   effect(KILL cr);
 8778 
 8779   format %{
 8780     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8781     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8782   %}
 8783 
 8784   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8785             aarch64_enc_cset_eq(res));
 8786 
 8787   ins_pipe(pipe_slow);
 8788 %}
 8789 
 8790 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8791 
 8792   predicate(needs_acquiring_load_exclusive(n));
 8793   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8794   ins_cost(VOLATILE_REF_COST);
 8795 
 8796   effect(KILL cr);
 8797 
 8798   format %{
 8799     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8800     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8801   %}
 8802 
 8803   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8804             aarch64_enc_cset_eq(res));
 8805 
 8806   ins_pipe(pipe_slow);
 8807 %}
 8808 
 8809 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8810 
 8811   predicate(needs_acquiring_load_exclusive(n));
 8812   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8813   ins_cost(VOLATILE_REF_COST);
 8814 
 8815   effect(KILL cr);
 8816 
 8817  format %{
 8818     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8819     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8820  %}
 8821 
 8822  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8823             aarch64_enc_cset_eq(res));
 8824 
 8825   ins_pipe(pipe_slow);
 8826 %}
 8827 
 8828 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8829 
 8830   predicate(needs_acquiring_load_exclusive(n));
 8831   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8832   ins_cost(VOLATILE_REF_COST);
 8833 
 8834   effect(KILL cr);
 8835 
 8836  format %{
 8837     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8838     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8839  %}
 8840 
 8841  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8842             aarch64_enc_cset_eq(res));
 8843 
 8844   ins_pipe(pipe_slow);
 8845 %}
 8846 
 8847 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8848 
 8849   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8850   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8851   ins_cost(VOLATILE_REF_COST);
 8852 
 8853   effect(KILL cr);
 8854 
 8855  format %{
 8856     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8857     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8858  %}
 8859 
 8860  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8861             aarch64_enc_cset_eq(res));
 8862 
 8863   ins_pipe(pipe_slow);
 8864 %}
 8865 
 8866 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8867 
 8868   predicate(needs_acquiring_load_exclusive(n));
 8869   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8870   ins_cost(VOLATILE_REF_COST);
 8871 
 8872   effect(KILL cr);
 8873 
 8874  format %{
 8875     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8876     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8877  %}
 8878 
 8879  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8880             aarch64_enc_cset_eq(res));
 8881 
 8882   ins_pipe(pipe_slow);
 8883 %}
 8884 
 8885 
 8886 // ---------------------------------------------------------------------
 8887 
 8888 
 8889 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8890 
 8891 // Sundry CAS operations.  Note that release is always true,
 8892 // regardless of the memory ordering of the CAS.  This is because we
 8893 // need the volatile case to be sequentially consistent but there is
 8894 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8895 // can&#39;t check the type of memory ordering here, so we always emit a
 8896 // STLXR.
 8897 
 8898 // This section is generated from aarch64_ad_cas.m4
 8899 
 8900 
 8901 
 8902 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8903   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8904   ins_cost(2 * VOLATILE_REF_COST);
 8905   effect(TEMP_DEF res, KILL cr);
 8906   format %{
 8907     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8908   %}
 8909   ins_encode %{
 8910     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8911                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8912                /*weak*/ false, $res$$Register);
 8913     __ sxtbw($res$$Register, $res$$Register);
 8914   %}
 8915   ins_pipe(pipe_slow);
 8916 %}
 8917 
 8918 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8919   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8920   ins_cost(2 * VOLATILE_REF_COST);
 8921   effect(TEMP_DEF res, KILL cr);
 8922   format %{
 8923     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8924   %}
 8925   ins_encode %{
 8926     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8927                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8928                /*weak*/ false, $res$$Register);
 8929     __ sxthw($res$$Register, $res$$Register);
 8930   %}
 8931   ins_pipe(pipe_slow);
 8932 %}
 8933 
 8934 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8935   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8936   ins_cost(2 * VOLATILE_REF_COST);
 8937   effect(TEMP_DEF res, KILL cr);
 8938   format %{
 8939     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8940   %}
 8941   ins_encode %{
 8942     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8943                Assembler::word, /*acquire*/ false, /*release*/ true,
 8944                /*weak*/ false, $res$$Register);
 8945   %}
 8946   ins_pipe(pipe_slow);
 8947 %}
 8948 
 8949 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8950   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8951   ins_cost(2 * VOLATILE_REF_COST);
 8952   effect(TEMP_DEF res, KILL cr);
 8953   format %{
 8954     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8955   %}
 8956   ins_encode %{
 8957     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8958                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8959                /*weak*/ false, $res$$Register);
 8960   %}
 8961   ins_pipe(pipe_slow);
 8962 %}
 8963 
 8964 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8965   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8966   ins_cost(2 * VOLATILE_REF_COST);
 8967   effect(TEMP_DEF res, KILL cr);
 8968   format %{
 8969     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8970   %}
 8971   ins_encode %{
 8972     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8973                Assembler::word, /*acquire*/ false, /*release*/ true,
 8974                /*weak*/ false, $res$$Register);
 8975   %}
 8976   ins_pipe(pipe_slow);
 8977 %}
 8978 
 8979 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8980   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8981   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8982   ins_cost(2 * VOLATILE_REF_COST);
 8983   effect(TEMP_DEF res, KILL cr);
 8984   format %{
 8985     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8986   %}
 8987   ins_encode %{
 8988     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8989                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8990                /*weak*/ false, $res$$Register);
 8991   %}
 8992   ins_pipe(pipe_slow);
 8993 %}
 8994 
 8995 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8996   predicate(needs_acquiring_load_exclusive(n));
 8997   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8998   ins_cost(VOLATILE_REF_COST);
 8999   effect(TEMP_DEF res, KILL cr);
 9000   format %{
 9001     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9002   %}
 9003   ins_encode %{
 9004     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9005                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9006                /*weak*/ false, $res$$Register);
 9007     __ sxtbw($res$$Register, $res$$Register);
 9008   %}
 9009   ins_pipe(pipe_slow);
 9010 %}
 9011 
 9012 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9013   predicate(needs_acquiring_load_exclusive(n));
 9014   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 9015   ins_cost(VOLATILE_REF_COST);
 9016   effect(TEMP_DEF res, KILL cr);
 9017   format %{
 9018     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9019   %}
 9020   ins_encode %{
 9021     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9022                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9023                /*weak*/ false, $res$$Register);
 9024     __ sxthw($res$$Register, $res$$Register);
 9025   %}
 9026   ins_pipe(pipe_slow);
 9027 %}
 9028 
 9029 
 9030 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9031   predicate(needs_acquiring_load_exclusive(n));
 9032   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 9033   ins_cost(VOLATILE_REF_COST);
 9034   effect(TEMP_DEF res, KILL cr);
 9035   format %{
 9036     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9037   %}
 9038   ins_encode %{
 9039     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9040                Assembler::word, /*acquire*/ true, /*release*/ true,
 9041                /*weak*/ false, $res$$Register);
 9042   %}
 9043   ins_pipe(pipe_slow);
 9044 %}
 9045 
 9046 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9047   predicate(needs_acquiring_load_exclusive(n));
 9048   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 9049   ins_cost(VOLATILE_REF_COST);
 9050   effect(TEMP_DEF res, KILL cr);
 9051   format %{
 9052     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9053   %}
 9054   ins_encode %{
 9055     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9056                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9057                /*weak*/ false, $res$$Register);
 9058   %}
 9059   ins_pipe(pipe_slow);
 9060 %}
 9061 
 9062 
 9063 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9064   predicate(needs_acquiring_load_exclusive(n));
 9065   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 9066   ins_cost(VOLATILE_REF_COST);
 9067   effect(TEMP_DEF res, KILL cr);
 9068   format %{
 9069     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9070   %}
 9071   ins_encode %{
 9072     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9073                Assembler::word, /*acquire*/ true, /*release*/ true,
 9074                /*weak*/ false, $res$$Register);
 9075   %}
 9076   ins_pipe(pipe_slow);
 9077 %}
 9078 
 9079 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9080   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9081   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9082   ins_cost(VOLATILE_REF_COST);
 9083   effect(TEMP_DEF res, KILL cr);
 9084   format %{
 9085     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9086   %}
 9087   ins_encode %{
 9088     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9089                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9090                /*weak*/ false, $res$$Register);
 9091   %}
 9092   ins_pipe(pipe_slow);
 9093 %}
 9094 
 9095 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9096   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9097   ins_cost(2 * VOLATILE_REF_COST);
 9098   effect(KILL cr);
 9099   format %{
 9100     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9101     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9102   %}
 9103   ins_encode %{
 9104     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9105                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9106                /*weak*/ true, noreg);
 9107     __ csetw($res$$Register, Assembler::EQ);
 9108   %}
 9109   ins_pipe(pipe_slow);
 9110 %}
 9111 
 9112 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9113   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9114   ins_cost(2 * VOLATILE_REF_COST);
 9115   effect(KILL cr);
 9116   format %{
 9117     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9118     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9119   %}
 9120   ins_encode %{
 9121     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9122                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9123                /*weak*/ true, noreg);
 9124     __ csetw($res$$Register, Assembler::EQ);
 9125   %}
 9126   ins_pipe(pipe_slow);
 9127 %}
 9128 
 9129 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9130   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9131   ins_cost(2 * VOLATILE_REF_COST);
 9132   effect(KILL cr);
 9133   format %{
 9134     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9135     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9136   %}
 9137   ins_encode %{
 9138     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9139                Assembler::word, /*acquire*/ false, /*release*/ true,
 9140                /*weak*/ true, noreg);
 9141     __ csetw($res$$Register, Assembler::EQ);
 9142   %}
 9143   ins_pipe(pipe_slow);
 9144 %}
 9145 
 9146 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9147   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9148   ins_cost(2 * VOLATILE_REF_COST);
 9149   effect(KILL cr);
 9150   format %{
 9151     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9152     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9153   %}
 9154   ins_encode %{
 9155     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9156                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9157                /*weak*/ true, noreg);
 9158     __ csetw($res$$Register, Assembler::EQ);
 9159   %}
 9160   ins_pipe(pipe_slow);
 9161 %}
 9162 
 9163 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9164   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9165   ins_cost(2 * VOLATILE_REF_COST);
 9166   effect(KILL cr);
 9167   format %{
 9168     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9169     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9170   %}
 9171   ins_encode %{
 9172     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9173                Assembler::word, /*acquire*/ false, /*release*/ true,
 9174                /*weak*/ true, noreg);
 9175     __ csetw($res$$Register, Assembler::EQ);
 9176   %}
 9177   ins_pipe(pipe_slow);
 9178 %}
 9179 
 9180 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9181   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9182   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9183   ins_cost(2 * VOLATILE_REF_COST);
 9184   effect(KILL cr);
 9185   format %{
 9186     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9187     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9188   %}
 9189   ins_encode %{
 9190     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9191                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9192                /*weak*/ true, noreg);
 9193     __ csetw($res$$Register, Assembler::EQ);
 9194   %}
 9195   ins_pipe(pipe_slow);
 9196 %}
 9197 
 9198 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9199   predicate(needs_acquiring_load_exclusive(n));
 9200   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9201   ins_cost(VOLATILE_REF_COST);
 9202   effect(KILL cr);
 9203   format %{
 9204     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9205     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9206   %}
 9207   ins_encode %{
 9208     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9209                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9210                /*weak*/ true, noreg);
 9211     __ csetw($res$$Register, Assembler::EQ);
 9212   %}
 9213   ins_pipe(pipe_slow);
 9214 %}
 9215 
 9216 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9217   predicate(needs_acquiring_load_exclusive(n));
 9218   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9219   ins_cost(VOLATILE_REF_COST);
 9220   effect(KILL cr);
 9221   format %{
 9222     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9223     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9224   %}
 9225   ins_encode %{
 9226     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9227                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9228                /*weak*/ true, noreg);
 9229     __ csetw($res$$Register, Assembler::EQ);
 9230   %}
 9231   ins_pipe(pipe_slow);
 9232 %}
 9233 
 9234 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9235   predicate(needs_acquiring_load_exclusive(n));
 9236   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9237   ins_cost(VOLATILE_REF_COST);
 9238   effect(KILL cr);
 9239   format %{
 9240     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9241     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9242   %}
 9243   ins_encode %{
 9244     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9245                Assembler::word, /*acquire*/ true, /*release*/ true,
 9246                /*weak*/ true, noreg);
 9247     __ csetw($res$$Register, Assembler::EQ);
 9248   %}
 9249   ins_pipe(pipe_slow);
 9250 %}
 9251 
 9252 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9253   predicate(needs_acquiring_load_exclusive(n));
 9254   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9255   ins_cost(VOLATILE_REF_COST);
 9256   effect(KILL cr);
 9257   format %{
 9258     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9259     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9260   %}
 9261   ins_encode %{
 9262     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9263                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9264                /*weak*/ true, noreg);
 9265     __ csetw($res$$Register, Assembler::EQ);
 9266   %}
 9267   ins_pipe(pipe_slow);
 9268 %}
 9269 
 9270 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9271   predicate(needs_acquiring_load_exclusive(n));
 9272   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9273   ins_cost(VOLATILE_REF_COST);
 9274   effect(KILL cr);
 9275   format %{
 9276     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9277     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9278   %}
 9279   ins_encode %{
 9280     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9281                Assembler::word, /*acquire*/ true, /*release*/ true,
 9282                /*weak*/ true, noreg);
 9283     __ csetw($res$$Register, Assembler::EQ);
 9284   %}
 9285   ins_pipe(pipe_slow);
 9286 %}
 9287 
 9288 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9289   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9290   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9291   ins_cost(VOLATILE_REF_COST);
 9292   effect(KILL cr);
 9293   format %{
 9294     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9295     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9296   %}
 9297   ins_encode %{
 9298     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9299                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9300                /*weak*/ true, noreg);
 9301     __ csetw($res$$Register, Assembler::EQ);
 9302   %}
 9303   ins_pipe(pipe_slow);
 9304 %}
 9305 
 9306 // END This section of the file is automatically generated. Do not edit --------------
 9307 // ---------------------------------------------------------------------
 9308 
 9309 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9310   match(Set prev (GetAndSetI mem newv));
 9311   ins_cost(2 * VOLATILE_REF_COST);
 9312   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9313   ins_encode %{
 9314     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9315   %}
 9316   ins_pipe(pipe_serial);
 9317 %}
 9318 
 9319 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9320   match(Set prev (GetAndSetL mem newv));
 9321   ins_cost(2 * VOLATILE_REF_COST);
 9322   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9323   ins_encode %{
 9324     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9325   %}
 9326   ins_pipe(pipe_serial);
 9327 %}
 9328 
 9329 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9330   match(Set prev (GetAndSetN mem newv));
 9331   ins_cost(2 * VOLATILE_REF_COST);
 9332   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9333   ins_encode %{
 9334     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9335   %}
 9336   ins_pipe(pipe_serial);
 9337 %}
 9338 
 9339 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9340   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9341   match(Set prev (GetAndSetP mem newv));
 9342   ins_cost(2 * VOLATILE_REF_COST);
 9343   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9344   ins_encode %{
 9345     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9346   %}
 9347   ins_pipe(pipe_serial);
 9348 %}
 9349 
 9350 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9351   predicate(needs_acquiring_load_exclusive(n));
 9352   match(Set prev (GetAndSetI mem newv));
 9353   ins_cost(VOLATILE_REF_COST);
 9354   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9355   ins_encode %{
 9356     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9357   %}
 9358   ins_pipe(pipe_serial);
 9359 %}
 9360 
 9361 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9362   predicate(needs_acquiring_load_exclusive(n));
 9363   match(Set prev (GetAndSetL mem newv));
 9364   ins_cost(VOLATILE_REF_COST);
 9365   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9366   ins_encode %{
 9367     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9368   %}
 9369   ins_pipe(pipe_serial);
 9370 %}
 9371 
 9372 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9373   predicate(needs_acquiring_load_exclusive(n));
 9374   match(Set prev (GetAndSetN mem newv));
 9375   ins_cost(VOLATILE_REF_COST);
 9376   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9377   ins_encode %{
 9378     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9379   %}
 9380   ins_pipe(pipe_serial);
 9381 %}
 9382 
 9383 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9384   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9385   match(Set prev (GetAndSetP mem newv));
 9386   ins_cost(VOLATILE_REF_COST);
 9387   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9388   ins_encode %{
 9389     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9390   %}
 9391   ins_pipe(pipe_serial);
 9392 %}
 9393 
 9394 
 9395 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9396   match(Set newval (GetAndAddL mem incr));
 9397   ins_cost(2 * VOLATILE_REF_COST + 1);
 9398   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9399   ins_encode %{
 9400     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9401   %}
 9402   ins_pipe(pipe_serial);
 9403 %}
 9404 
 9405 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9406   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9407   match(Set dummy (GetAndAddL mem incr));
 9408   ins_cost(2 * VOLATILE_REF_COST);
 9409   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9410   ins_encode %{
 9411     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9412   %}
 9413   ins_pipe(pipe_serial);
 9414 %}
 9415 
 9416 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9417   match(Set newval (GetAndAddL mem incr));
 9418   ins_cost(2 * VOLATILE_REF_COST + 1);
 9419   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9420   ins_encode %{
 9421     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9422   %}
 9423   ins_pipe(pipe_serial);
 9424 %}
 9425 
 9426 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9427   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9428   match(Set dummy (GetAndAddL mem incr));
 9429   ins_cost(2 * VOLATILE_REF_COST);
 9430   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9431   ins_encode %{
 9432     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9433   %}
 9434   ins_pipe(pipe_serial);
 9435 %}
 9436 
 9437 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9438   match(Set newval (GetAndAddI mem incr));
 9439   ins_cost(2 * VOLATILE_REF_COST + 1);
 9440   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9441   ins_encode %{
 9442     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9443   %}
 9444   ins_pipe(pipe_serial);
 9445 %}
 9446 
 9447 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9448   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9449   match(Set dummy (GetAndAddI mem incr));
 9450   ins_cost(2 * VOLATILE_REF_COST);
 9451   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9452   ins_encode %{
 9453     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9454   %}
 9455   ins_pipe(pipe_serial);
 9456 %}
 9457 
 9458 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9459   match(Set newval (GetAndAddI mem incr));
 9460   ins_cost(2 * VOLATILE_REF_COST + 1);
 9461   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9462   ins_encode %{
 9463     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9464   %}
 9465   ins_pipe(pipe_serial);
 9466 %}
 9467 
 9468 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9469   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9470   match(Set dummy (GetAndAddI mem incr));
 9471   ins_cost(2 * VOLATILE_REF_COST);
 9472   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9473   ins_encode %{
 9474     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9475   %}
 9476   ins_pipe(pipe_serial);
 9477 %}
 9478 
 9479 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9480   predicate(needs_acquiring_load_exclusive(n));
 9481   match(Set newval (GetAndAddL mem incr));
 9482   ins_cost(VOLATILE_REF_COST + 1);
 9483   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9484   ins_encode %{
 9485     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9486   %}
 9487   ins_pipe(pipe_serial);
 9488 %}
 9489 
 9490 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9491   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9492   match(Set dummy (GetAndAddL mem incr));
 9493   ins_cost(VOLATILE_REF_COST);
 9494   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9495   ins_encode %{
 9496     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9497   %}
 9498   ins_pipe(pipe_serial);
 9499 %}
 9500 
 9501 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9502   predicate(needs_acquiring_load_exclusive(n));
 9503   match(Set newval (GetAndAddL mem incr));
 9504   ins_cost(VOLATILE_REF_COST + 1);
 9505   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9506   ins_encode %{
 9507     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9508   %}
 9509   ins_pipe(pipe_serial);
 9510 %}
 9511 
 9512 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9513   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9514   match(Set dummy (GetAndAddL mem incr));
 9515   ins_cost(VOLATILE_REF_COST);
 9516   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9517   ins_encode %{
 9518     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9519   %}
 9520   ins_pipe(pipe_serial);
 9521 %}
 9522 
 9523 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9524   predicate(needs_acquiring_load_exclusive(n));
 9525   match(Set newval (GetAndAddI mem incr));
 9526   ins_cost(VOLATILE_REF_COST + 1);
 9527   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9528   ins_encode %{
 9529     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9530   %}
 9531   ins_pipe(pipe_serial);
 9532 %}
 9533 
 9534 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9535   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9536   match(Set dummy (GetAndAddI mem incr));
 9537   ins_cost(VOLATILE_REF_COST);
 9538   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9539   ins_encode %{
 9540     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9541   %}
 9542   ins_pipe(pipe_serial);
 9543 %}
 9544 
 9545 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9546   predicate(needs_acquiring_load_exclusive(n));
 9547   match(Set newval (GetAndAddI mem incr));
 9548   ins_cost(VOLATILE_REF_COST + 1);
 9549   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9550   ins_encode %{
 9551     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9552   %}
 9553   ins_pipe(pipe_serial);
 9554 %}
 9555 
 9556 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9557   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9558   match(Set dummy (GetAndAddI mem incr));
 9559   ins_cost(VOLATILE_REF_COST);
 9560   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9561   ins_encode %{
 9562     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9563   %}
 9564   ins_pipe(pipe_serial);
 9565 %}
 9566 
 9567 // Manifest a CmpL result in an integer register.
 9568 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9569 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9570 %{
 9571   match(Set dst (CmpL3 src1 src2));
 9572   effect(KILL flags);
 9573 
 9574   ins_cost(INSN_COST * 6);
 9575   format %{
 9576       &quot;cmp $src1, $src2&quot;
 9577       &quot;csetw $dst, ne&quot;
 9578       &quot;cnegw $dst, lt&quot;
 9579   %}
 9580   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9581   ins_encode %{
 9582     __ cmp($src1$$Register, $src2$$Register);
 9583     __ csetw($dst$$Register, Assembler::NE);
 9584     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9585   %}
 9586 
 9587   ins_pipe(pipe_class_default);
 9588 %}
 9589 
 9590 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9591 %{
 9592   match(Set dst (CmpL3 src1 src2));
 9593   effect(KILL flags);
 9594 
 9595   ins_cost(INSN_COST * 6);
 9596   format %{
 9597       &quot;cmp $src1, $src2&quot;
 9598       &quot;csetw $dst, ne&quot;
 9599       &quot;cnegw $dst, lt&quot;
 9600   %}
 9601   ins_encode %{
 9602     int32_t con = (int32_t)$src2$$constant;
 9603      if (con &lt; 0) {
 9604       __ adds(zr, $src1$$Register, -con);
 9605     } else {
 9606       __ subs(zr, $src1$$Register, con);
 9607     }
 9608     __ csetw($dst$$Register, Assembler::NE);
 9609     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9610   %}
 9611 
 9612   ins_pipe(pipe_class_default);
 9613 %}
 9614 
 9615 // ============================================================================
 9616 // Conditional Move Instructions
 9617 
 9618 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9619 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9620 // define an op class which merged both inputs and use it to type the
 9621 // argument to a single rule. unfortunatelyt his fails because the
 9622 // opclass does not live up to the COND_INTER interface of its
 9623 // component operands. When the generic code tries to negate the
 9624 // operand it ends up running the generci Machoper::negate method
 9625 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9626 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9627 
 9628 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9629   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9630 
 9631   ins_cost(INSN_COST * 2);
 9632   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9633 
 9634   ins_encode %{
 9635     __ cselw(as_Register($dst$$reg),
 9636              as_Register($src2$$reg),
 9637              as_Register($src1$$reg),
 9638              (Assembler::Condition)$cmp$$cmpcode);
 9639   %}
 9640 
 9641   ins_pipe(icond_reg_reg);
 9642 %}
 9643 
 9644 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9645   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9646 
 9647   ins_cost(INSN_COST * 2);
 9648   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9649 
 9650   ins_encode %{
 9651     __ cselw(as_Register($dst$$reg),
 9652              as_Register($src2$$reg),
 9653              as_Register($src1$$reg),
 9654              (Assembler::Condition)$cmp$$cmpcode);
 9655   %}
 9656 
 9657   ins_pipe(icond_reg_reg);
 9658 %}
 9659 
 9660 // special cases where one arg is zero
 9661 
 9662 // n.b. this is selected in preference to the rule above because it
 9663 // avoids loading constant 0 into a source register
 9664 
 9665 // TODO
 9666 // we ought only to be able to cull one of these variants as the ideal
 9667 // transforms ought always to order the zero consistently (to left/right?)
 9668 
 9669 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9670   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9671 
 9672   ins_cost(INSN_COST * 2);
 9673   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9674 
 9675   ins_encode %{
 9676     __ cselw(as_Register($dst$$reg),
 9677              as_Register($src$$reg),
 9678              zr,
 9679              (Assembler::Condition)$cmp$$cmpcode);
 9680   %}
 9681 
 9682   ins_pipe(icond_reg);
 9683 %}
 9684 
 9685 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9686   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9687 
 9688   ins_cost(INSN_COST * 2);
 9689   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9690 
 9691   ins_encode %{
 9692     __ cselw(as_Register($dst$$reg),
 9693              as_Register($src$$reg),
 9694              zr,
 9695              (Assembler::Condition)$cmp$$cmpcode);
 9696   %}
 9697 
 9698   ins_pipe(icond_reg);
 9699 %}
 9700 
 9701 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9702   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9703 
 9704   ins_cost(INSN_COST * 2);
 9705   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9706 
 9707   ins_encode %{
 9708     __ cselw(as_Register($dst$$reg),
 9709              zr,
 9710              as_Register($src$$reg),
 9711              (Assembler::Condition)$cmp$$cmpcode);
 9712   %}
 9713 
 9714   ins_pipe(icond_reg);
 9715 %}
 9716 
 9717 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9718   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9719 
 9720   ins_cost(INSN_COST * 2);
 9721   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9722 
 9723   ins_encode %{
 9724     __ cselw(as_Register($dst$$reg),
 9725              zr,
 9726              as_Register($src$$reg),
 9727              (Assembler::Condition)$cmp$$cmpcode);
 9728   %}
 9729 
 9730   ins_pipe(icond_reg);
 9731 %}
 9732 
 9733 // special case for creating a boolean 0 or 1
 9734 
 9735 // n.b. this is selected in preference to the rule above because it
 9736 // avoids loading constants 0 and 1 into a source register
 9737 
 9738 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9739   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9740 
 9741   ins_cost(INSN_COST * 2);
 9742   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9743 
 9744   ins_encode %{
 9745     // equivalently
 9746     // cset(as_Register($dst$$reg),
 9747     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9748     __ csincw(as_Register($dst$$reg),
 9749              zr,
 9750              zr,
 9751              (Assembler::Condition)$cmp$$cmpcode);
 9752   %}
 9753 
 9754   ins_pipe(icond_none);
 9755 %}
 9756 
 9757 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9758   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9759 
 9760   ins_cost(INSN_COST * 2);
 9761   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9762 
 9763   ins_encode %{
 9764     // equivalently
 9765     // cset(as_Register($dst$$reg),
 9766     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9767     __ csincw(as_Register($dst$$reg),
 9768              zr,
 9769              zr,
 9770              (Assembler::Condition)$cmp$$cmpcode);
 9771   %}
 9772 
 9773   ins_pipe(icond_none);
 9774 %}
 9775 
 9776 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9777   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9778 
 9779   ins_cost(INSN_COST * 2);
 9780   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9781 
 9782   ins_encode %{
 9783     __ csel(as_Register($dst$$reg),
 9784             as_Register($src2$$reg),
 9785             as_Register($src1$$reg),
 9786             (Assembler::Condition)$cmp$$cmpcode);
 9787   %}
 9788 
 9789   ins_pipe(icond_reg_reg);
 9790 %}
 9791 
 9792 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9793   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9794 
 9795   ins_cost(INSN_COST * 2);
 9796   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9797 
 9798   ins_encode %{
 9799     __ csel(as_Register($dst$$reg),
 9800             as_Register($src2$$reg),
 9801             as_Register($src1$$reg),
 9802             (Assembler::Condition)$cmp$$cmpcode);
 9803   %}
 9804 
 9805   ins_pipe(icond_reg_reg);
 9806 %}
 9807 
 9808 // special cases where one arg is zero
 9809 
 9810 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9811   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9812 
 9813   ins_cost(INSN_COST * 2);
 9814   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9815 
 9816   ins_encode %{
 9817     __ csel(as_Register($dst$$reg),
 9818             zr,
 9819             as_Register($src$$reg),
 9820             (Assembler::Condition)$cmp$$cmpcode);
 9821   %}
 9822 
 9823   ins_pipe(icond_reg);
 9824 %}
 9825 
 9826 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9827   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9828 
 9829   ins_cost(INSN_COST * 2);
 9830   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9831 
 9832   ins_encode %{
 9833     __ csel(as_Register($dst$$reg),
 9834             zr,
 9835             as_Register($src$$reg),
 9836             (Assembler::Condition)$cmp$$cmpcode);
 9837   %}
 9838 
 9839   ins_pipe(icond_reg);
 9840 %}
 9841 
 9842 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9843   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9844 
 9845   ins_cost(INSN_COST * 2);
 9846   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9847 
 9848   ins_encode %{
 9849     __ csel(as_Register($dst$$reg),
 9850             as_Register($src$$reg),
 9851             zr,
 9852             (Assembler::Condition)$cmp$$cmpcode);
 9853   %}
 9854 
 9855   ins_pipe(icond_reg);
 9856 %}
 9857 
 9858 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9859   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9860 
 9861   ins_cost(INSN_COST * 2);
 9862   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9863 
 9864   ins_encode %{
 9865     __ csel(as_Register($dst$$reg),
 9866             as_Register($src$$reg),
 9867             zr,
 9868             (Assembler::Condition)$cmp$$cmpcode);
 9869   %}
 9870 
 9871   ins_pipe(icond_reg);
 9872 %}
 9873 
 9874 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9875   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9876 
 9877   ins_cost(INSN_COST * 2);
 9878   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9879 
 9880   ins_encode %{
 9881     __ csel(as_Register($dst$$reg),
 9882             as_Register($src2$$reg),
 9883             as_Register($src1$$reg),
 9884             (Assembler::Condition)$cmp$$cmpcode);
 9885   %}
 9886 
 9887   ins_pipe(icond_reg_reg);
 9888 %}
 9889 
 9890 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9891   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9892 
 9893   ins_cost(INSN_COST * 2);
 9894   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9895 
 9896   ins_encode %{
 9897     __ csel(as_Register($dst$$reg),
 9898             as_Register($src2$$reg),
 9899             as_Register($src1$$reg),
 9900             (Assembler::Condition)$cmp$$cmpcode);
 9901   %}
 9902 
 9903   ins_pipe(icond_reg_reg);
 9904 %}
 9905 
 9906 // special cases where one arg is zero
 9907 
 9908 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9909   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9910 
 9911   ins_cost(INSN_COST * 2);
 9912   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9913 
 9914   ins_encode %{
 9915     __ csel(as_Register($dst$$reg),
 9916             zr,
 9917             as_Register($src$$reg),
 9918             (Assembler::Condition)$cmp$$cmpcode);
 9919   %}
 9920 
 9921   ins_pipe(icond_reg);
 9922 %}
 9923 
 9924 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9925   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9926 
 9927   ins_cost(INSN_COST * 2);
 9928   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9929 
 9930   ins_encode %{
 9931     __ csel(as_Register($dst$$reg),
 9932             zr,
 9933             as_Register($src$$reg),
 9934             (Assembler::Condition)$cmp$$cmpcode);
 9935   %}
 9936 
 9937   ins_pipe(icond_reg);
 9938 %}
 9939 
 9940 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9941   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9942 
 9943   ins_cost(INSN_COST * 2);
 9944   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9945 
 9946   ins_encode %{
 9947     __ csel(as_Register($dst$$reg),
 9948             as_Register($src$$reg),
 9949             zr,
 9950             (Assembler::Condition)$cmp$$cmpcode);
 9951   %}
 9952 
 9953   ins_pipe(icond_reg);
 9954 %}
 9955 
 9956 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9957   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9958 
 9959   ins_cost(INSN_COST * 2);
 9960   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9961 
 9962   ins_encode %{
 9963     __ csel(as_Register($dst$$reg),
 9964             as_Register($src$$reg),
 9965             zr,
 9966             (Assembler::Condition)$cmp$$cmpcode);
 9967   %}
 9968 
 9969   ins_pipe(icond_reg);
 9970 %}
 9971 
 9972 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9973   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9974 
 9975   ins_cost(INSN_COST * 2);
 9976   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9977 
 9978   ins_encode %{
 9979     __ cselw(as_Register($dst$$reg),
 9980              as_Register($src2$$reg),
 9981              as_Register($src1$$reg),
 9982              (Assembler::Condition)$cmp$$cmpcode);
 9983   %}
 9984 
 9985   ins_pipe(icond_reg_reg);
 9986 %}
 9987 
 9988 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9989   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9990 
 9991   ins_cost(INSN_COST * 2);
 9992   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9993 
 9994   ins_encode %{
 9995     __ cselw(as_Register($dst$$reg),
 9996              as_Register($src2$$reg),
 9997              as_Register($src1$$reg),
 9998              (Assembler::Condition)$cmp$$cmpcode);
 9999   %}
10000 
10001   ins_pipe(icond_reg_reg);
10002 %}
10003 
10004 // special cases where one arg is zero
10005 
10006 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
10007   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
10008 
10009   ins_cost(INSN_COST * 2);
10010   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
10011 
10012   ins_encode %{
10013     __ cselw(as_Register($dst$$reg),
10014              zr,
10015              as_Register($src$$reg),
10016              (Assembler::Condition)$cmp$$cmpcode);
10017   %}
10018 
10019   ins_pipe(icond_reg);
10020 %}
10021 
10022 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
10023   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
10024 
10025   ins_cost(INSN_COST * 2);
10026   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
10027 
10028   ins_encode %{
10029     __ cselw(as_Register($dst$$reg),
10030              zr,
10031              as_Register($src$$reg),
10032              (Assembler::Condition)$cmp$$cmpcode);
10033   %}
10034 
10035   ins_pipe(icond_reg);
10036 %}
10037 
10038 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10039   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10040 
10041   ins_cost(INSN_COST * 2);
10042   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
10043 
10044   ins_encode %{
10045     __ cselw(as_Register($dst$$reg),
10046              as_Register($src$$reg),
10047              zr,
10048              (Assembler::Condition)$cmp$$cmpcode);
10049   %}
10050 
10051   ins_pipe(icond_reg);
10052 %}
10053 
10054 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10055   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10056 
10057   ins_cost(INSN_COST * 2);
10058   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
10059 
10060   ins_encode %{
10061     __ cselw(as_Register($dst$$reg),
10062              as_Register($src$$reg),
10063              zr,
10064              (Assembler::Condition)$cmp$$cmpcode);
10065   %}
10066 
10067   ins_pipe(icond_reg);
10068 %}
10069 
10070 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10071 %{
10072   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10073 
10074   ins_cost(INSN_COST * 3);
10075 
10076   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10077   ins_encode %{
10078     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10079     __ fcsels(as_FloatRegister($dst$$reg),
10080               as_FloatRegister($src2$$reg),
10081               as_FloatRegister($src1$$reg),
10082               cond);
10083   %}
10084 
10085   ins_pipe(fp_cond_reg_reg_s);
10086 %}
10087 
10088 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10089 %{
10090   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10091 
10092   ins_cost(INSN_COST * 3);
10093 
10094   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10095   ins_encode %{
10096     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10097     __ fcsels(as_FloatRegister($dst$$reg),
10098               as_FloatRegister($src2$$reg),
10099               as_FloatRegister($src1$$reg),
10100               cond);
10101   %}
10102 
10103   ins_pipe(fp_cond_reg_reg_s);
10104 %}
10105 
10106 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10107 %{
10108   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10109 
10110   ins_cost(INSN_COST * 3);
10111 
10112   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10113   ins_encode %{
10114     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10115     __ fcseld(as_FloatRegister($dst$$reg),
10116               as_FloatRegister($src2$$reg),
10117               as_FloatRegister($src1$$reg),
10118               cond);
10119   %}
10120 
10121   ins_pipe(fp_cond_reg_reg_d);
10122 %}
10123 
10124 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10125 %{
10126   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10127 
10128   ins_cost(INSN_COST * 3);
10129 
10130   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10131   ins_encode %{
10132     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10133     __ fcseld(as_FloatRegister($dst$$reg),
10134               as_FloatRegister($src2$$reg),
10135               as_FloatRegister($src1$$reg),
10136               cond);
10137   %}
10138 
10139   ins_pipe(fp_cond_reg_reg_d);
10140 %}
10141 
10142 // ============================================================================
10143 // Arithmetic Instructions
10144 //
10145 
10146 // Integer Addition
10147 
10148 // TODO
10149 // these currently employ operations which do not set CR and hence are
10150 // not flagged as killing CR but we would like to isolate the cases
10151 // where we want to set flags from those where we don&#39;t. need to work
10152 // out how to do that.
10153 
10154 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10155   match(Set dst (AddI src1 src2));
10156 
10157   ins_cost(INSN_COST);
10158   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10159 
10160   ins_encode %{
10161     __ addw(as_Register($dst$$reg),
10162             as_Register($src1$$reg),
10163             as_Register($src2$$reg));
10164   %}
10165 
10166   ins_pipe(ialu_reg_reg);
10167 %}
10168 
10169 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10170   match(Set dst (AddI src1 src2));
10171 
10172   ins_cost(INSN_COST);
10173   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10174 
10175   // use opcode to indicate that this is an add not a sub
10176   opcode(0x0);
10177 
10178   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10179 
10180   ins_pipe(ialu_reg_imm);
10181 %}
10182 
10183 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10184   match(Set dst (AddI (ConvL2I src1) src2));
10185 
10186   ins_cost(INSN_COST);
10187   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10188 
10189   // use opcode to indicate that this is an add not a sub
10190   opcode(0x0);
10191 
10192   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10193 
10194   ins_pipe(ialu_reg_imm);
10195 %}
10196 
10197 // Pointer Addition
10198 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10199   match(Set dst (AddP src1 src2));
10200 
10201   ins_cost(INSN_COST);
10202   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10203 
10204   ins_encode %{
10205     __ add(as_Register($dst$$reg),
10206            as_Register($src1$$reg),
10207            as_Register($src2$$reg));
10208   %}
10209 
10210   ins_pipe(ialu_reg_reg);
10211 %}
10212 
10213 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10214   match(Set dst (AddP src1 (ConvI2L src2)));
10215 
10216   ins_cost(1.9 * INSN_COST);
10217   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10218 
10219   ins_encode %{
10220     __ add(as_Register($dst$$reg),
10221            as_Register($src1$$reg),
10222            as_Register($src2$$reg), ext::sxtw);
10223   %}
10224 
10225   ins_pipe(ialu_reg_reg);
10226 %}
10227 
10228 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10229   match(Set dst (AddP src1 (LShiftL src2 scale)));
10230 
10231   ins_cost(1.9 * INSN_COST);
10232   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10233 
10234   ins_encode %{
10235     __ lea(as_Register($dst$$reg),
10236            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10237                    Address::lsl($scale$$constant)));
10238   %}
10239 
10240   ins_pipe(ialu_reg_reg_shift);
10241 %}
10242 
10243 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10244   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10245 
10246   ins_cost(1.9 * INSN_COST);
10247   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10248 
10249   ins_encode %{
10250     __ lea(as_Register($dst$$reg),
10251            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10252                    Address::sxtw($scale$$constant)));
10253   %}
10254 
10255   ins_pipe(ialu_reg_reg_shift);
10256 %}
10257 
10258 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10259   match(Set dst (LShiftL (ConvI2L src) scale));
10260 
10261   ins_cost(INSN_COST);
10262   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10263 
10264   ins_encode %{
10265     __ sbfiz(as_Register($dst$$reg),
10266           as_Register($src$$reg),
10267           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10268   %}
10269 
10270   ins_pipe(ialu_reg_shift);
10271 %}
10272 
10273 // Pointer Immediate Addition
10274 // n.b. this needs to be more expensive than using an indirect memory
10275 // operand
10276 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10277   match(Set dst (AddP src1 src2));
10278 
10279   ins_cost(INSN_COST);
10280   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10281 
10282   // use opcode to indicate that this is an add not a sub
10283   opcode(0x0);
10284 
10285   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10286 
10287   ins_pipe(ialu_reg_imm);
10288 %}
10289 
10290 // Long Addition
10291 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10292 
10293   match(Set dst (AddL src1 src2));
10294 
10295   ins_cost(INSN_COST);
10296   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10297 
10298   ins_encode %{
10299     __ add(as_Register($dst$$reg),
10300            as_Register($src1$$reg),
10301            as_Register($src2$$reg));
10302   %}
10303 
10304   ins_pipe(ialu_reg_reg);
10305 %}
10306 
10307 // No constant pool entries requiredLong Immediate Addition.
10308 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10309   match(Set dst (AddL src1 src2));
10310 
10311   ins_cost(INSN_COST);
10312   format %{ &quot;add $dst, $src1, $src2&quot; %}
10313 
10314   // use opcode to indicate that this is an add not a sub
10315   opcode(0x0);
10316 
10317   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10318 
10319   ins_pipe(ialu_reg_imm);
10320 %}
10321 
10322 // Integer Subtraction
10323 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10324   match(Set dst (SubI src1 src2));
10325 
10326   ins_cost(INSN_COST);
10327   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10328 
10329   ins_encode %{
10330     __ subw(as_Register($dst$$reg),
10331             as_Register($src1$$reg),
10332             as_Register($src2$$reg));
10333   %}
10334 
10335   ins_pipe(ialu_reg_reg);
10336 %}
10337 
10338 // Immediate Subtraction
10339 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10340   match(Set dst (SubI src1 src2));
10341 
10342   ins_cost(INSN_COST);
10343   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10344 
10345   // use opcode to indicate that this is a sub not an add
10346   opcode(0x1);
10347 
10348   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10349 
10350   ins_pipe(ialu_reg_imm);
10351 %}
10352 
10353 // Long Subtraction
10354 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10355 
10356   match(Set dst (SubL src1 src2));
10357 
10358   ins_cost(INSN_COST);
10359   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10360 
10361   ins_encode %{
10362     __ sub(as_Register($dst$$reg),
10363            as_Register($src1$$reg),
10364            as_Register($src2$$reg));
10365   %}
10366 
10367   ins_pipe(ialu_reg_reg);
10368 %}
10369 
10370 // No constant pool entries requiredLong Immediate Subtraction.
10371 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10372   match(Set dst (SubL src1 src2));
10373 
10374   ins_cost(INSN_COST);
10375   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10376 
10377   // use opcode to indicate that this is a sub not an add
10378   opcode(0x1);
10379 
10380   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10381 
10382   ins_pipe(ialu_reg_imm);
10383 %}
10384 
10385 // Integer Negation (special case for sub)
10386 
10387 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10388   match(Set dst (SubI zero src));
10389 
10390   ins_cost(INSN_COST);
10391   format %{ &quot;negw $dst, $src\t# int&quot; %}
10392 
10393   ins_encode %{
10394     __ negw(as_Register($dst$$reg),
10395             as_Register($src$$reg));
10396   %}
10397 
10398   ins_pipe(ialu_reg);
10399 %}
10400 
10401 // Long Negation
10402 
10403 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10404   match(Set dst (SubL zero src));
10405 
10406   ins_cost(INSN_COST);
10407   format %{ &quot;neg $dst, $src\t# long&quot; %}
10408 
10409   ins_encode %{
10410     __ neg(as_Register($dst$$reg),
10411            as_Register($src$$reg));
10412   %}
10413 
10414   ins_pipe(ialu_reg);
10415 %}
10416 
10417 // Integer Multiply
10418 
10419 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10420   match(Set dst (MulI src1 src2));
10421 
10422   ins_cost(INSN_COST * 3);
10423   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10424 
10425   ins_encode %{
10426     __ mulw(as_Register($dst$$reg),
10427             as_Register($src1$$reg),
10428             as_Register($src2$$reg));
10429   %}
10430 
10431   ins_pipe(imul_reg_reg);
10432 %}
10433 
10434 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10435   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10436 
10437   ins_cost(INSN_COST * 3);
10438   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10439 
10440   ins_encode %{
10441     __ smull(as_Register($dst$$reg),
10442              as_Register($src1$$reg),
10443              as_Register($src2$$reg));
10444   %}
10445 
10446   ins_pipe(imul_reg_reg);
10447 %}
10448 
10449 // Long Multiply
10450 
10451 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10452   match(Set dst (MulL src1 src2));
10453 
10454   ins_cost(INSN_COST * 5);
10455   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10456 
10457   ins_encode %{
10458     __ mul(as_Register($dst$$reg),
10459            as_Register($src1$$reg),
10460            as_Register($src2$$reg));
10461   %}
10462 
10463   ins_pipe(lmul_reg_reg);
10464 %}
10465 
10466 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10467 %{
10468   match(Set dst (MulHiL src1 src2));
10469 
10470   ins_cost(INSN_COST * 7);
10471   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10472 
10473   ins_encode %{
10474     __ smulh(as_Register($dst$$reg),
10475              as_Register($src1$$reg),
10476              as_Register($src2$$reg));
10477   %}
10478 
10479   ins_pipe(lmul_reg_reg);
10480 %}
10481 
10482 // Combined Integer Multiply &amp; Add/Sub
10483 
10484 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10485   match(Set dst (AddI src3 (MulI src1 src2)));
10486 
10487   ins_cost(INSN_COST * 3);
10488   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10489 
10490   ins_encode %{
10491     __ maddw(as_Register($dst$$reg),
10492              as_Register($src1$$reg),
10493              as_Register($src2$$reg),
10494              as_Register($src3$$reg));
10495   %}
10496 
10497   ins_pipe(imac_reg_reg);
10498 %}
10499 
10500 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10501   match(Set dst (SubI src3 (MulI src1 src2)));
10502 
10503   ins_cost(INSN_COST * 3);
10504   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10505 
10506   ins_encode %{
10507     __ msubw(as_Register($dst$$reg),
10508              as_Register($src1$$reg),
10509              as_Register($src2$$reg),
10510              as_Register($src3$$reg));
10511   %}
10512 
10513   ins_pipe(imac_reg_reg);
10514 %}
10515 
10516 // Combined Integer Multiply &amp; Neg
10517 
10518 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10519   match(Set dst (MulI (SubI zero src1) src2));
10520   match(Set dst (MulI src1 (SubI zero src2)));
10521 
10522   ins_cost(INSN_COST * 3);
10523   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10524 
10525   ins_encode %{
10526     __ mnegw(as_Register($dst$$reg),
10527              as_Register($src1$$reg),
10528              as_Register($src2$$reg));
10529   %}
10530 
10531   ins_pipe(imac_reg_reg);
10532 %}
10533 
10534 // Combined Long Multiply &amp; Add/Sub
10535 
10536 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10537   match(Set dst (AddL src3 (MulL src1 src2)));
10538 
10539   ins_cost(INSN_COST * 5);
10540   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10541 
10542   ins_encode %{
10543     __ madd(as_Register($dst$$reg),
10544             as_Register($src1$$reg),
10545             as_Register($src2$$reg),
10546             as_Register($src3$$reg));
10547   %}
10548 
10549   ins_pipe(lmac_reg_reg);
10550 %}
10551 
10552 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10553   match(Set dst (SubL src3 (MulL src1 src2)));
10554 
10555   ins_cost(INSN_COST * 5);
10556   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10557 
10558   ins_encode %{
10559     __ msub(as_Register($dst$$reg),
10560             as_Register($src1$$reg),
10561             as_Register($src2$$reg),
10562             as_Register($src3$$reg));
10563   %}
10564 
10565   ins_pipe(lmac_reg_reg);
10566 %}
10567 
10568 // Combined Long Multiply &amp; Neg
10569 
10570 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10571   match(Set dst (MulL (SubL zero src1) src2));
10572   match(Set dst (MulL src1 (SubL zero src2)));
10573 
10574   ins_cost(INSN_COST * 5);
10575   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10576 
10577   ins_encode %{
10578     __ mneg(as_Register($dst$$reg),
10579             as_Register($src1$$reg),
10580             as_Register($src2$$reg));
10581   %}
10582 
10583   ins_pipe(lmac_reg_reg);
10584 %}
10585 
10586 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10587 
10588 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10589   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10590 
10591   ins_cost(INSN_COST * 3);
10592   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10593 
10594   ins_encode %{
10595     __ smaddl(as_Register($dst$$reg),
10596               as_Register($src1$$reg),
10597               as_Register($src2$$reg),
10598               as_Register($src3$$reg));
10599   %}
10600 
10601   ins_pipe(imac_reg_reg);
10602 %}
10603 
10604 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10605   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10606 
10607   ins_cost(INSN_COST * 3);
10608   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10609 
10610   ins_encode %{
10611     __ smsubl(as_Register($dst$$reg),
10612               as_Register($src1$$reg),
10613               as_Register($src2$$reg),
10614               as_Register($src3$$reg));
10615   %}
10616 
10617   ins_pipe(imac_reg_reg);
10618 %}
10619 
10620 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10621   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10622   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10623 
10624   ins_cost(INSN_COST * 3);
10625   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10626 
10627   ins_encode %{
10628     __ smnegl(as_Register($dst$$reg),
10629               as_Register($src1$$reg),
10630               as_Register($src2$$reg));
10631   %}
10632 
10633   ins_pipe(imac_reg_reg);
10634 %}
10635 
10636 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10637 
10638 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10639   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10640 
10641   ins_cost(INSN_COST * 5);
10642   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10643             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10644 
10645   ins_encode %{
10646     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10647     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10648 
10649   ins_pipe(imac_reg_reg);
10650 %}
10651 
10652 // Integer Divide
10653 
10654 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10655   match(Set dst (DivI src1 src2));
10656 
10657   ins_cost(INSN_COST * 19);
10658   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10659 
10660   ins_encode(aarch64_enc_divw(dst, src1, src2));
10661   ins_pipe(idiv_reg_reg);
10662 %}
10663 
10664 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10665   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10666   ins_cost(INSN_COST);
10667   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10668   ins_encode %{
10669     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10670   %}
10671   ins_pipe(ialu_reg_shift);
10672 %}
10673 
10674 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10675   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10676   ins_cost(INSN_COST);
10677   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10678 
10679   ins_encode %{
10680     __ addw(as_Register($dst$$reg),
10681               as_Register($src$$reg),
10682               as_Register($src$$reg),
10683               Assembler::LSR, 31);
10684   %}
10685   ins_pipe(ialu_reg);
10686 %}
10687 
10688 // Long Divide
10689 
10690 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10691   match(Set dst (DivL src1 src2));
10692 
10693   ins_cost(INSN_COST * 35);
10694   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10695 
10696   ins_encode(aarch64_enc_div(dst, src1, src2));
10697   ins_pipe(ldiv_reg_reg);
10698 %}
10699 
10700 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10701   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10702   ins_cost(INSN_COST);
10703   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10704   ins_encode %{
10705     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10706   %}
10707   ins_pipe(ialu_reg_shift);
10708 %}
10709 
10710 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10711   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10712   ins_cost(INSN_COST);
10713   format %{ &quot;add $dst, $src, $div1&quot; %}
10714 
10715   ins_encode %{
10716     __ add(as_Register($dst$$reg),
10717               as_Register($src$$reg),
10718               as_Register($src$$reg),
10719               Assembler::LSR, 63);
10720   %}
10721   ins_pipe(ialu_reg);
10722 %}
10723 
10724 // Integer Remainder
10725 
10726 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10727   match(Set dst (ModI src1 src2));
10728 
10729   ins_cost(INSN_COST * 22);
10730   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10731             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10732 
10733   ins_encode(aarch64_enc_modw(dst, src1, src2));
10734   ins_pipe(idiv_reg_reg);
10735 %}
10736 
10737 // Long Remainder
10738 
10739 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10740   match(Set dst (ModL src1 src2));
10741 
10742   ins_cost(INSN_COST * 38);
10743   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10744             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10745 
10746   ins_encode(aarch64_enc_mod(dst, src1, src2));
10747   ins_pipe(ldiv_reg_reg);
10748 %}
10749 
10750 // Integer Shifts
10751 
10752 // Shift Left Register
10753 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10754   match(Set dst (LShiftI src1 src2));
10755 
10756   ins_cost(INSN_COST * 2);
10757   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10758 
10759   ins_encode %{
10760     __ lslvw(as_Register($dst$$reg),
10761              as_Register($src1$$reg),
10762              as_Register($src2$$reg));
10763   %}
10764 
10765   ins_pipe(ialu_reg_reg_vshift);
10766 %}
10767 
10768 // Shift Left Immediate
10769 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10770   match(Set dst (LShiftI src1 src2));
10771 
10772   ins_cost(INSN_COST);
10773   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10774 
10775   ins_encode %{
10776     __ lslw(as_Register($dst$$reg),
10777             as_Register($src1$$reg),
10778             $src2$$constant &amp; 0x1f);
10779   %}
10780 
10781   ins_pipe(ialu_reg_shift);
10782 %}
10783 
10784 // Shift Right Logical Register
10785 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10786   match(Set dst (URShiftI src1 src2));
10787 
10788   ins_cost(INSN_COST * 2);
10789   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10790 
10791   ins_encode %{
10792     __ lsrvw(as_Register($dst$$reg),
10793              as_Register($src1$$reg),
10794              as_Register($src2$$reg));
10795   %}
10796 
10797   ins_pipe(ialu_reg_reg_vshift);
10798 %}
10799 
10800 // Shift Right Logical Immediate
10801 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10802   match(Set dst (URShiftI src1 src2));
10803 
10804   ins_cost(INSN_COST);
10805   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10806 
10807   ins_encode %{
10808     __ lsrw(as_Register($dst$$reg),
10809             as_Register($src1$$reg),
10810             $src2$$constant &amp; 0x1f);
10811   %}
10812 
10813   ins_pipe(ialu_reg_shift);
10814 %}
10815 
10816 // Shift Right Arithmetic Register
10817 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10818   match(Set dst (RShiftI src1 src2));
10819 
10820   ins_cost(INSN_COST * 2);
10821   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10822 
10823   ins_encode %{
10824     __ asrvw(as_Register($dst$$reg),
10825              as_Register($src1$$reg),
10826              as_Register($src2$$reg));
10827   %}
10828 
10829   ins_pipe(ialu_reg_reg_vshift);
10830 %}
10831 
10832 // Shift Right Arithmetic Immediate
10833 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10834   match(Set dst (RShiftI src1 src2));
10835 
10836   ins_cost(INSN_COST);
10837   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10838 
10839   ins_encode %{
10840     __ asrw(as_Register($dst$$reg),
10841             as_Register($src1$$reg),
10842             $src2$$constant &amp; 0x1f);
10843   %}
10844 
10845   ins_pipe(ialu_reg_shift);
10846 %}
10847 
10848 // Combined Int Mask and Right Shift (using UBFM)
10849 // TODO
10850 
10851 // Long Shifts
10852 
10853 // Shift Left Register
10854 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10855   match(Set dst (LShiftL src1 src2));
10856 
10857   ins_cost(INSN_COST * 2);
10858   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10859 
10860   ins_encode %{
10861     __ lslv(as_Register($dst$$reg),
10862             as_Register($src1$$reg),
10863             as_Register($src2$$reg));
10864   %}
10865 
10866   ins_pipe(ialu_reg_reg_vshift);
10867 %}
10868 
10869 // Shift Left Immediate
10870 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10871   match(Set dst (LShiftL src1 src2));
10872 
10873   ins_cost(INSN_COST);
10874   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10875 
10876   ins_encode %{
10877     __ lsl(as_Register($dst$$reg),
10878             as_Register($src1$$reg),
10879             $src2$$constant &amp; 0x3f);
10880   %}
10881 
10882   ins_pipe(ialu_reg_shift);
10883 %}
10884 
10885 // Shift Right Logical Register
10886 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10887   match(Set dst (URShiftL src1 src2));
10888 
10889   ins_cost(INSN_COST * 2);
10890   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10891 
10892   ins_encode %{
10893     __ lsrv(as_Register($dst$$reg),
10894             as_Register($src1$$reg),
10895             as_Register($src2$$reg));
10896   %}
10897 
10898   ins_pipe(ialu_reg_reg_vshift);
10899 %}
10900 
10901 // Shift Right Logical Immediate
10902 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10903   match(Set dst (URShiftL src1 src2));
10904 
10905   ins_cost(INSN_COST);
10906   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10907 
10908   ins_encode %{
10909     __ lsr(as_Register($dst$$reg),
10910            as_Register($src1$$reg),
10911            $src2$$constant &amp; 0x3f);
10912   %}
10913 
10914   ins_pipe(ialu_reg_shift);
10915 %}
10916 
10917 // A special-case pattern for card table stores.
10918 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10919   match(Set dst (URShiftL (CastP2X src1) src2));
10920 
10921   ins_cost(INSN_COST);
10922   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10923 
10924   ins_encode %{
10925     __ lsr(as_Register($dst$$reg),
10926            as_Register($src1$$reg),
10927            $src2$$constant &amp; 0x3f);
10928   %}
10929 
10930   ins_pipe(ialu_reg_shift);
10931 %}
10932 
10933 // Shift Right Arithmetic Register
10934 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10935   match(Set dst (RShiftL src1 src2));
10936 
10937   ins_cost(INSN_COST * 2);
10938   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10939 
10940   ins_encode %{
10941     __ asrv(as_Register($dst$$reg),
10942             as_Register($src1$$reg),
10943             as_Register($src2$$reg));
10944   %}
10945 
10946   ins_pipe(ialu_reg_reg_vshift);
10947 %}
10948 
10949 // Shift Right Arithmetic Immediate
10950 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10951   match(Set dst (RShiftL src1 src2));
10952 
10953   ins_cost(INSN_COST);
10954   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10955 
10956   ins_encode %{
10957     __ asr(as_Register($dst$$reg),
10958            as_Register($src1$$reg),
10959            $src2$$constant &amp; 0x3f);
10960   %}
10961 
10962   ins_pipe(ialu_reg_shift);
10963 %}
10964 
10965 // BEGIN This section of the file is automatically generated. Do not edit --------------
10966 
10967 instruct regL_not_reg(iRegLNoSp dst,
10968                          iRegL src1, immL_M1 m1,
10969                          rFlagsReg cr) %{
10970   match(Set dst (XorL src1 m1));
10971   ins_cost(INSN_COST);
10972   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10973 
10974   ins_encode %{
10975     __ eon(as_Register($dst$$reg),
10976               as_Register($src1$$reg),
10977               zr,
10978               Assembler::LSL, 0);
10979   %}
10980 
10981   ins_pipe(ialu_reg);
10982 %}
10983 instruct regI_not_reg(iRegINoSp dst,
10984                          iRegIorL2I src1, immI_M1 m1,
10985                          rFlagsReg cr) %{
10986   match(Set dst (XorI src1 m1));
10987   ins_cost(INSN_COST);
10988   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10989 
10990   ins_encode %{
10991     __ eonw(as_Register($dst$$reg),
10992               as_Register($src1$$reg),
10993               zr,
10994               Assembler::LSL, 0);
10995   %}
10996 
10997   ins_pipe(ialu_reg);
10998 %}
10999 
11000 instruct AndI_reg_not_reg(iRegINoSp dst,
11001                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11002                          rFlagsReg cr) %{
11003   match(Set dst (AndI src1 (XorI src2 m1)));
11004   ins_cost(INSN_COST);
11005   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
11006 
11007   ins_encode %{
11008     __ bicw(as_Register($dst$$reg),
11009               as_Register($src1$$reg),
11010               as_Register($src2$$reg),
11011               Assembler::LSL, 0);
11012   %}
11013 
11014   ins_pipe(ialu_reg_reg);
11015 %}
11016 
11017 instruct AndL_reg_not_reg(iRegLNoSp dst,
11018                          iRegL src1, iRegL src2, immL_M1 m1,
11019                          rFlagsReg cr) %{
11020   match(Set dst (AndL src1 (XorL src2 m1)));
11021   ins_cost(INSN_COST);
11022   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
11023 
11024   ins_encode %{
11025     __ bic(as_Register($dst$$reg),
11026               as_Register($src1$$reg),
11027               as_Register($src2$$reg),
11028               Assembler::LSL, 0);
11029   %}
11030 
11031   ins_pipe(ialu_reg_reg);
11032 %}
11033 
11034 instruct OrI_reg_not_reg(iRegINoSp dst,
11035                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11036                          rFlagsReg cr) %{
11037   match(Set dst (OrI src1 (XorI src2 m1)));
11038   ins_cost(INSN_COST);
11039   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
11040 
11041   ins_encode %{
11042     __ ornw(as_Register($dst$$reg),
11043               as_Register($src1$$reg),
11044               as_Register($src2$$reg),
11045               Assembler::LSL, 0);
11046   %}
11047 
11048   ins_pipe(ialu_reg_reg);
11049 %}
11050 
11051 instruct OrL_reg_not_reg(iRegLNoSp dst,
11052                          iRegL src1, iRegL src2, immL_M1 m1,
11053                          rFlagsReg cr) %{
11054   match(Set dst (OrL src1 (XorL src2 m1)));
11055   ins_cost(INSN_COST);
11056   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
11057 
11058   ins_encode %{
11059     __ orn(as_Register($dst$$reg),
11060               as_Register($src1$$reg),
11061               as_Register($src2$$reg),
11062               Assembler::LSL, 0);
11063   %}
11064 
11065   ins_pipe(ialu_reg_reg);
11066 %}
11067 
11068 instruct XorI_reg_not_reg(iRegINoSp dst,
11069                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11070                          rFlagsReg cr) %{
11071   match(Set dst (XorI m1 (XorI src2 src1)));
11072   ins_cost(INSN_COST);
11073   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
11074 
11075   ins_encode %{
11076     __ eonw(as_Register($dst$$reg),
11077               as_Register($src1$$reg),
11078               as_Register($src2$$reg),
11079               Assembler::LSL, 0);
11080   %}
11081 
11082   ins_pipe(ialu_reg_reg);
11083 %}
11084 
11085 instruct XorL_reg_not_reg(iRegLNoSp dst,
11086                          iRegL src1, iRegL src2, immL_M1 m1,
11087                          rFlagsReg cr) %{
11088   match(Set dst (XorL m1 (XorL src2 src1)));
11089   ins_cost(INSN_COST);
11090   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11091 
11092   ins_encode %{
11093     __ eon(as_Register($dst$$reg),
11094               as_Register($src1$$reg),
11095               as_Register($src2$$reg),
11096               Assembler::LSL, 0);
11097   %}
11098 
11099   ins_pipe(ialu_reg_reg);
11100 %}
11101 
11102 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11103                          iRegIorL2I src1, iRegIorL2I src2,
11104                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11105   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11106   ins_cost(1.9 * INSN_COST);
11107   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11108 
11109   ins_encode %{
11110     __ bicw(as_Register($dst$$reg),
11111               as_Register($src1$$reg),
11112               as_Register($src2$$reg),
11113               Assembler::LSR,
11114               $src3$$constant &amp; 0x1f);
11115   %}
11116 
11117   ins_pipe(ialu_reg_reg_shift);
11118 %}
11119 
11120 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11121                          iRegL src1, iRegL src2,
11122                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11123   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11124   ins_cost(1.9 * INSN_COST);
11125   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11126 
11127   ins_encode %{
11128     __ bic(as_Register($dst$$reg),
11129               as_Register($src1$$reg),
11130               as_Register($src2$$reg),
11131               Assembler::LSR,
11132               $src3$$constant &amp; 0x3f);
11133   %}
11134 
11135   ins_pipe(ialu_reg_reg_shift);
11136 %}
11137 
11138 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11139                          iRegIorL2I src1, iRegIorL2I src2,
11140                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11141   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11142   ins_cost(1.9 * INSN_COST);
11143   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11144 
11145   ins_encode %{
11146     __ bicw(as_Register($dst$$reg),
11147               as_Register($src1$$reg),
11148               as_Register($src2$$reg),
11149               Assembler::ASR,
11150               $src3$$constant &amp; 0x1f);
11151   %}
11152 
11153   ins_pipe(ialu_reg_reg_shift);
11154 %}
11155 
11156 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11157                          iRegL src1, iRegL src2,
11158                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11159   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11160   ins_cost(1.9 * INSN_COST);
11161   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11162 
11163   ins_encode %{
11164     __ bic(as_Register($dst$$reg),
11165               as_Register($src1$$reg),
11166               as_Register($src2$$reg),
11167               Assembler::ASR,
11168               $src3$$constant &amp; 0x3f);
11169   %}
11170 
11171   ins_pipe(ialu_reg_reg_shift);
11172 %}
11173 
11174 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11175                          iRegIorL2I src1, iRegIorL2I src2,
11176                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11177   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11178   ins_cost(1.9 * INSN_COST);
11179   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11180 
11181   ins_encode %{
11182     __ bicw(as_Register($dst$$reg),
11183               as_Register($src1$$reg),
11184               as_Register($src2$$reg),
11185               Assembler::LSL,
11186               $src3$$constant &amp; 0x1f);
11187   %}
11188 
11189   ins_pipe(ialu_reg_reg_shift);
11190 %}
11191 
11192 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11193                          iRegL src1, iRegL src2,
11194                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11195   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11196   ins_cost(1.9 * INSN_COST);
11197   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11198 
11199   ins_encode %{
11200     __ bic(as_Register($dst$$reg),
11201               as_Register($src1$$reg),
11202               as_Register($src2$$reg),
11203               Assembler::LSL,
11204               $src3$$constant &amp; 0x3f);
11205   %}
11206 
11207   ins_pipe(ialu_reg_reg_shift);
11208 %}
11209 
11210 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11211                          iRegIorL2I src1, iRegIorL2I src2,
11212                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11213   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11214   ins_cost(1.9 * INSN_COST);
11215   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11216 
11217   ins_encode %{
11218     __ eonw(as_Register($dst$$reg),
11219               as_Register($src1$$reg),
11220               as_Register($src2$$reg),
11221               Assembler::LSR,
11222               $src3$$constant &amp; 0x1f);
11223   %}
11224 
11225   ins_pipe(ialu_reg_reg_shift);
11226 %}
11227 
11228 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11229                          iRegL src1, iRegL src2,
11230                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11231   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11232   ins_cost(1.9 * INSN_COST);
11233   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11234 
11235   ins_encode %{
11236     __ eon(as_Register($dst$$reg),
11237               as_Register($src1$$reg),
11238               as_Register($src2$$reg),
11239               Assembler::LSR,
11240               $src3$$constant &amp; 0x3f);
11241   %}
11242 
11243   ins_pipe(ialu_reg_reg_shift);
11244 %}
11245 
11246 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11247                          iRegIorL2I src1, iRegIorL2I src2,
11248                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11249   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11250   ins_cost(1.9 * INSN_COST);
11251   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11252 
11253   ins_encode %{
11254     __ eonw(as_Register($dst$$reg),
11255               as_Register($src1$$reg),
11256               as_Register($src2$$reg),
11257               Assembler::ASR,
11258               $src3$$constant &amp; 0x1f);
11259   %}
11260 
11261   ins_pipe(ialu_reg_reg_shift);
11262 %}
11263 
11264 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11265                          iRegL src1, iRegL src2,
11266                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11267   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11268   ins_cost(1.9 * INSN_COST);
11269   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11270 
11271   ins_encode %{
11272     __ eon(as_Register($dst$$reg),
11273               as_Register($src1$$reg),
11274               as_Register($src2$$reg),
11275               Assembler::ASR,
11276               $src3$$constant &amp; 0x3f);
11277   %}
11278 
11279   ins_pipe(ialu_reg_reg_shift);
11280 %}
11281 
11282 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11283                          iRegIorL2I src1, iRegIorL2I src2,
11284                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11285   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11286   ins_cost(1.9 * INSN_COST);
11287   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11288 
11289   ins_encode %{
11290     __ eonw(as_Register($dst$$reg),
11291               as_Register($src1$$reg),
11292               as_Register($src2$$reg),
11293               Assembler::LSL,
11294               $src3$$constant &amp; 0x1f);
11295   %}
11296 
11297   ins_pipe(ialu_reg_reg_shift);
11298 %}
11299 
11300 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11301                          iRegL src1, iRegL src2,
11302                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11303   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11304   ins_cost(1.9 * INSN_COST);
11305   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11306 
11307   ins_encode %{
11308     __ eon(as_Register($dst$$reg),
11309               as_Register($src1$$reg),
11310               as_Register($src2$$reg),
11311               Assembler::LSL,
11312               $src3$$constant &amp; 0x3f);
11313   %}
11314 
11315   ins_pipe(ialu_reg_reg_shift);
11316 %}
11317 
11318 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11319                          iRegIorL2I src1, iRegIorL2I src2,
11320                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11321   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11322   ins_cost(1.9 * INSN_COST);
11323   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11324 
11325   ins_encode %{
11326     __ ornw(as_Register($dst$$reg),
11327               as_Register($src1$$reg),
11328               as_Register($src2$$reg),
11329               Assembler::LSR,
11330               $src3$$constant &amp; 0x1f);
11331   %}
11332 
11333   ins_pipe(ialu_reg_reg_shift);
11334 %}
11335 
11336 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11337                          iRegL src1, iRegL src2,
11338                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11339   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11340   ins_cost(1.9 * INSN_COST);
11341   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11342 
11343   ins_encode %{
11344     __ orn(as_Register($dst$$reg),
11345               as_Register($src1$$reg),
11346               as_Register($src2$$reg),
11347               Assembler::LSR,
11348               $src3$$constant &amp; 0x3f);
11349   %}
11350 
11351   ins_pipe(ialu_reg_reg_shift);
11352 %}
11353 
11354 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11355                          iRegIorL2I src1, iRegIorL2I src2,
11356                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11357   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11358   ins_cost(1.9 * INSN_COST);
11359   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11360 
11361   ins_encode %{
11362     __ ornw(as_Register($dst$$reg),
11363               as_Register($src1$$reg),
11364               as_Register($src2$$reg),
11365               Assembler::ASR,
11366               $src3$$constant &amp; 0x1f);
11367   %}
11368 
11369   ins_pipe(ialu_reg_reg_shift);
11370 %}
11371 
11372 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11373                          iRegL src1, iRegL src2,
11374                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11375   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11376   ins_cost(1.9 * INSN_COST);
11377   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11378 
11379   ins_encode %{
11380     __ orn(as_Register($dst$$reg),
11381               as_Register($src1$$reg),
11382               as_Register($src2$$reg),
11383               Assembler::ASR,
11384               $src3$$constant &amp; 0x3f);
11385   %}
11386 
11387   ins_pipe(ialu_reg_reg_shift);
11388 %}
11389 
11390 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11391                          iRegIorL2I src1, iRegIorL2I src2,
11392                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11393   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11394   ins_cost(1.9 * INSN_COST);
11395   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11396 
11397   ins_encode %{
11398     __ ornw(as_Register($dst$$reg),
11399               as_Register($src1$$reg),
11400               as_Register($src2$$reg),
11401               Assembler::LSL,
11402               $src3$$constant &amp; 0x1f);
11403   %}
11404 
11405   ins_pipe(ialu_reg_reg_shift);
11406 %}
11407 
11408 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11409                          iRegL src1, iRegL src2,
11410                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11411   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11412   ins_cost(1.9 * INSN_COST);
11413   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11414 
11415   ins_encode %{
11416     __ orn(as_Register($dst$$reg),
11417               as_Register($src1$$reg),
11418               as_Register($src2$$reg),
11419               Assembler::LSL,
11420               $src3$$constant &amp; 0x3f);
11421   %}
11422 
11423   ins_pipe(ialu_reg_reg_shift);
11424 %}
11425 
11426 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11427                          iRegIorL2I src1, iRegIorL2I src2,
11428                          immI src3, rFlagsReg cr) %{
11429   match(Set dst (AndI src1 (URShiftI src2 src3)));
11430 
11431   ins_cost(1.9 * INSN_COST);
11432   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11433 
11434   ins_encode %{
11435     __ andw(as_Register($dst$$reg),
11436               as_Register($src1$$reg),
11437               as_Register($src2$$reg),
11438               Assembler::LSR,
11439               $src3$$constant &amp; 0x1f);
11440   %}
11441 
11442   ins_pipe(ialu_reg_reg_shift);
11443 %}
11444 
11445 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11446                          iRegL src1, iRegL src2,
11447                          immI src3, rFlagsReg cr) %{
11448   match(Set dst (AndL src1 (URShiftL src2 src3)));
11449 
11450   ins_cost(1.9 * INSN_COST);
11451   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11452 
11453   ins_encode %{
11454     __ andr(as_Register($dst$$reg),
11455               as_Register($src1$$reg),
11456               as_Register($src2$$reg),
11457               Assembler::LSR,
11458               $src3$$constant &amp; 0x3f);
11459   %}
11460 
11461   ins_pipe(ialu_reg_reg_shift);
11462 %}
11463 
11464 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11465                          iRegIorL2I src1, iRegIorL2I src2,
11466                          immI src3, rFlagsReg cr) %{
11467   match(Set dst (AndI src1 (RShiftI src2 src3)));
11468 
11469   ins_cost(1.9 * INSN_COST);
11470   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11471 
11472   ins_encode %{
11473     __ andw(as_Register($dst$$reg),
11474               as_Register($src1$$reg),
11475               as_Register($src2$$reg),
11476               Assembler::ASR,
11477               $src3$$constant &amp; 0x1f);
11478   %}
11479 
11480   ins_pipe(ialu_reg_reg_shift);
11481 %}
11482 
11483 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11484                          iRegL src1, iRegL src2,
11485                          immI src3, rFlagsReg cr) %{
11486   match(Set dst (AndL src1 (RShiftL src2 src3)));
11487 
11488   ins_cost(1.9 * INSN_COST);
11489   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11490 
11491   ins_encode %{
11492     __ andr(as_Register($dst$$reg),
11493               as_Register($src1$$reg),
11494               as_Register($src2$$reg),
11495               Assembler::ASR,
11496               $src3$$constant &amp; 0x3f);
11497   %}
11498 
11499   ins_pipe(ialu_reg_reg_shift);
11500 %}
11501 
11502 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11503                          iRegIorL2I src1, iRegIorL2I src2,
11504                          immI src3, rFlagsReg cr) %{
11505   match(Set dst (AndI src1 (LShiftI src2 src3)));
11506 
11507   ins_cost(1.9 * INSN_COST);
11508   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11509 
11510   ins_encode %{
11511     __ andw(as_Register($dst$$reg),
11512               as_Register($src1$$reg),
11513               as_Register($src2$$reg),
11514               Assembler::LSL,
11515               $src3$$constant &amp; 0x1f);
11516   %}
11517 
11518   ins_pipe(ialu_reg_reg_shift);
11519 %}
11520 
11521 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11522                          iRegL src1, iRegL src2,
11523                          immI src3, rFlagsReg cr) %{
11524   match(Set dst (AndL src1 (LShiftL src2 src3)));
11525 
11526   ins_cost(1.9 * INSN_COST);
11527   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11528 
11529   ins_encode %{
11530     __ andr(as_Register($dst$$reg),
11531               as_Register($src1$$reg),
11532               as_Register($src2$$reg),
11533               Assembler::LSL,
11534               $src3$$constant &amp; 0x3f);
11535   %}
11536 
11537   ins_pipe(ialu_reg_reg_shift);
11538 %}
11539 
11540 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11541                          iRegIorL2I src1, iRegIorL2I src2,
11542                          immI src3, rFlagsReg cr) %{
11543   match(Set dst (XorI src1 (URShiftI src2 src3)));
11544 
11545   ins_cost(1.9 * INSN_COST);
11546   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11547 
11548   ins_encode %{
11549     __ eorw(as_Register($dst$$reg),
11550               as_Register($src1$$reg),
11551               as_Register($src2$$reg),
11552               Assembler::LSR,
11553               $src3$$constant &amp; 0x1f);
11554   %}
11555 
11556   ins_pipe(ialu_reg_reg_shift);
11557 %}
11558 
11559 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11560                          iRegL src1, iRegL src2,
11561                          immI src3, rFlagsReg cr) %{
11562   match(Set dst (XorL src1 (URShiftL src2 src3)));
11563 
11564   ins_cost(1.9 * INSN_COST);
11565   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11566 
11567   ins_encode %{
11568     __ eor(as_Register($dst$$reg),
11569               as_Register($src1$$reg),
11570               as_Register($src2$$reg),
11571               Assembler::LSR,
11572               $src3$$constant &amp; 0x3f);
11573   %}
11574 
11575   ins_pipe(ialu_reg_reg_shift);
11576 %}
11577 
11578 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11579                          iRegIorL2I src1, iRegIorL2I src2,
11580                          immI src3, rFlagsReg cr) %{
11581   match(Set dst (XorI src1 (RShiftI src2 src3)));
11582 
11583   ins_cost(1.9 * INSN_COST);
11584   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11585 
11586   ins_encode %{
11587     __ eorw(as_Register($dst$$reg),
11588               as_Register($src1$$reg),
11589               as_Register($src2$$reg),
11590               Assembler::ASR,
11591               $src3$$constant &amp; 0x1f);
11592   %}
11593 
11594   ins_pipe(ialu_reg_reg_shift);
11595 %}
11596 
11597 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11598                          iRegL src1, iRegL src2,
11599                          immI src3, rFlagsReg cr) %{
11600   match(Set dst (XorL src1 (RShiftL src2 src3)));
11601 
11602   ins_cost(1.9 * INSN_COST);
11603   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11604 
11605   ins_encode %{
11606     __ eor(as_Register($dst$$reg),
11607               as_Register($src1$$reg),
11608               as_Register($src2$$reg),
11609               Assembler::ASR,
11610               $src3$$constant &amp; 0x3f);
11611   %}
11612 
11613   ins_pipe(ialu_reg_reg_shift);
11614 %}
11615 
11616 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11617                          iRegIorL2I src1, iRegIorL2I src2,
11618                          immI src3, rFlagsReg cr) %{
11619   match(Set dst (XorI src1 (LShiftI src2 src3)));
11620 
11621   ins_cost(1.9 * INSN_COST);
11622   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11623 
11624   ins_encode %{
11625     __ eorw(as_Register($dst$$reg),
11626               as_Register($src1$$reg),
11627               as_Register($src2$$reg),
11628               Assembler::LSL,
11629               $src3$$constant &amp; 0x1f);
11630   %}
11631 
11632   ins_pipe(ialu_reg_reg_shift);
11633 %}
11634 
11635 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11636                          iRegL src1, iRegL src2,
11637                          immI src3, rFlagsReg cr) %{
11638   match(Set dst (XorL src1 (LShiftL src2 src3)));
11639 
11640   ins_cost(1.9 * INSN_COST);
11641   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11642 
11643   ins_encode %{
11644     __ eor(as_Register($dst$$reg),
11645               as_Register($src1$$reg),
11646               as_Register($src2$$reg),
11647               Assembler::LSL,
11648               $src3$$constant &amp; 0x3f);
11649   %}
11650 
11651   ins_pipe(ialu_reg_reg_shift);
11652 %}
11653 
11654 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11655                          iRegIorL2I src1, iRegIorL2I src2,
11656                          immI src3, rFlagsReg cr) %{
11657   match(Set dst (OrI src1 (URShiftI src2 src3)));
11658 
11659   ins_cost(1.9 * INSN_COST);
11660   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11661 
11662   ins_encode %{
11663     __ orrw(as_Register($dst$$reg),
11664               as_Register($src1$$reg),
11665               as_Register($src2$$reg),
11666               Assembler::LSR,
11667               $src3$$constant &amp; 0x1f);
11668   %}
11669 
11670   ins_pipe(ialu_reg_reg_shift);
11671 %}
11672 
11673 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11674                          iRegL src1, iRegL src2,
11675                          immI src3, rFlagsReg cr) %{
11676   match(Set dst (OrL src1 (URShiftL src2 src3)));
11677 
11678   ins_cost(1.9 * INSN_COST);
11679   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11680 
11681   ins_encode %{
11682     __ orr(as_Register($dst$$reg),
11683               as_Register($src1$$reg),
11684               as_Register($src2$$reg),
11685               Assembler::LSR,
11686               $src3$$constant &amp; 0x3f);
11687   %}
11688 
11689   ins_pipe(ialu_reg_reg_shift);
11690 %}
11691 
11692 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11693                          iRegIorL2I src1, iRegIorL2I src2,
11694                          immI src3, rFlagsReg cr) %{
11695   match(Set dst (OrI src1 (RShiftI src2 src3)));
11696 
11697   ins_cost(1.9 * INSN_COST);
11698   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11699 
11700   ins_encode %{
11701     __ orrw(as_Register($dst$$reg),
11702               as_Register($src1$$reg),
11703               as_Register($src2$$reg),
11704               Assembler::ASR,
11705               $src3$$constant &amp; 0x1f);
11706   %}
11707 
11708   ins_pipe(ialu_reg_reg_shift);
11709 %}
11710 
11711 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11712                          iRegL src1, iRegL src2,
11713                          immI src3, rFlagsReg cr) %{
11714   match(Set dst (OrL src1 (RShiftL src2 src3)));
11715 
11716   ins_cost(1.9 * INSN_COST);
11717   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11718 
11719   ins_encode %{
11720     __ orr(as_Register($dst$$reg),
11721               as_Register($src1$$reg),
11722               as_Register($src2$$reg),
11723               Assembler::ASR,
11724               $src3$$constant &amp; 0x3f);
11725   %}
11726 
11727   ins_pipe(ialu_reg_reg_shift);
11728 %}
11729 
11730 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11731                          iRegIorL2I src1, iRegIorL2I src2,
11732                          immI src3, rFlagsReg cr) %{
11733   match(Set dst (OrI src1 (LShiftI src2 src3)));
11734 
11735   ins_cost(1.9 * INSN_COST);
11736   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11737 
11738   ins_encode %{
11739     __ orrw(as_Register($dst$$reg),
11740               as_Register($src1$$reg),
11741               as_Register($src2$$reg),
11742               Assembler::LSL,
11743               $src3$$constant &amp; 0x1f);
11744   %}
11745 
11746   ins_pipe(ialu_reg_reg_shift);
11747 %}
11748 
11749 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11750                          iRegL src1, iRegL src2,
11751                          immI src3, rFlagsReg cr) %{
11752   match(Set dst (OrL src1 (LShiftL src2 src3)));
11753 
11754   ins_cost(1.9 * INSN_COST);
11755   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11756 
11757   ins_encode %{
11758     __ orr(as_Register($dst$$reg),
11759               as_Register($src1$$reg),
11760               as_Register($src2$$reg),
11761               Assembler::LSL,
11762               $src3$$constant &amp; 0x3f);
11763   %}
11764 
11765   ins_pipe(ialu_reg_reg_shift);
11766 %}
11767 
11768 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11769                          iRegIorL2I src1, iRegIorL2I src2,
11770                          immI src3, rFlagsReg cr) %{
11771   match(Set dst (AddI src1 (URShiftI src2 src3)));
11772 
11773   ins_cost(1.9 * INSN_COST);
11774   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11775 
11776   ins_encode %{
11777     __ addw(as_Register($dst$$reg),
11778               as_Register($src1$$reg),
11779               as_Register($src2$$reg),
11780               Assembler::LSR,
11781               $src3$$constant &amp; 0x1f);
11782   %}
11783 
11784   ins_pipe(ialu_reg_reg_shift);
11785 %}
11786 
11787 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11788                          iRegL src1, iRegL src2,
11789                          immI src3, rFlagsReg cr) %{
11790   match(Set dst (AddL src1 (URShiftL src2 src3)));
11791 
11792   ins_cost(1.9 * INSN_COST);
11793   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11794 
11795   ins_encode %{
11796     __ add(as_Register($dst$$reg),
11797               as_Register($src1$$reg),
11798               as_Register($src2$$reg),
11799               Assembler::LSR,
11800               $src3$$constant &amp; 0x3f);
11801   %}
11802 
11803   ins_pipe(ialu_reg_reg_shift);
11804 %}
11805 
11806 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11807                          iRegIorL2I src1, iRegIorL2I src2,
11808                          immI src3, rFlagsReg cr) %{
11809   match(Set dst (AddI src1 (RShiftI src2 src3)));
11810 
11811   ins_cost(1.9 * INSN_COST);
11812   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11813 
11814   ins_encode %{
11815     __ addw(as_Register($dst$$reg),
11816               as_Register($src1$$reg),
11817               as_Register($src2$$reg),
11818               Assembler::ASR,
11819               $src3$$constant &amp; 0x1f);
11820   %}
11821 
11822   ins_pipe(ialu_reg_reg_shift);
11823 %}
11824 
11825 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11826                          iRegL src1, iRegL src2,
11827                          immI src3, rFlagsReg cr) %{
11828   match(Set dst (AddL src1 (RShiftL src2 src3)));
11829 
11830   ins_cost(1.9 * INSN_COST);
11831   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11832 
11833   ins_encode %{
11834     __ add(as_Register($dst$$reg),
11835               as_Register($src1$$reg),
11836               as_Register($src2$$reg),
11837               Assembler::ASR,
11838               $src3$$constant &amp; 0x3f);
11839   %}
11840 
11841   ins_pipe(ialu_reg_reg_shift);
11842 %}
11843 
11844 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11845                          iRegIorL2I src1, iRegIorL2I src2,
11846                          immI src3, rFlagsReg cr) %{
11847   match(Set dst (AddI src1 (LShiftI src2 src3)));
11848 
11849   ins_cost(1.9 * INSN_COST);
11850   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11851 
11852   ins_encode %{
11853     __ addw(as_Register($dst$$reg),
11854               as_Register($src1$$reg),
11855               as_Register($src2$$reg),
11856               Assembler::LSL,
11857               $src3$$constant &amp; 0x1f);
11858   %}
11859 
11860   ins_pipe(ialu_reg_reg_shift);
11861 %}
11862 
11863 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11864                          iRegL src1, iRegL src2,
11865                          immI src3, rFlagsReg cr) %{
11866   match(Set dst (AddL src1 (LShiftL src2 src3)));
11867 
11868   ins_cost(1.9 * INSN_COST);
11869   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11870 
11871   ins_encode %{
11872     __ add(as_Register($dst$$reg),
11873               as_Register($src1$$reg),
11874               as_Register($src2$$reg),
11875               Assembler::LSL,
11876               $src3$$constant &amp; 0x3f);
11877   %}
11878 
11879   ins_pipe(ialu_reg_reg_shift);
11880 %}
11881 
11882 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11883                          iRegIorL2I src1, iRegIorL2I src2,
11884                          immI src3, rFlagsReg cr) %{
11885   match(Set dst (SubI src1 (URShiftI src2 src3)));
11886 
11887   ins_cost(1.9 * INSN_COST);
11888   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11889 
11890   ins_encode %{
11891     __ subw(as_Register($dst$$reg),
11892               as_Register($src1$$reg),
11893               as_Register($src2$$reg),
11894               Assembler::LSR,
11895               $src3$$constant &amp; 0x1f);
11896   %}
11897 
11898   ins_pipe(ialu_reg_reg_shift);
11899 %}
11900 
11901 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11902                          iRegL src1, iRegL src2,
11903                          immI src3, rFlagsReg cr) %{
11904   match(Set dst (SubL src1 (URShiftL src2 src3)));
11905 
11906   ins_cost(1.9 * INSN_COST);
11907   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11908 
11909   ins_encode %{
11910     __ sub(as_Register($dst$$reg),
11911               as_Register($src1$$reg),
11912               as_Register($src2$$reg),
11913               Assembler::LSR,
11914               $src3$$constant &amp; 0x3f);
11915   %}
11916 
11917   ins_pipe(ialu_reg_reg_shift);
11918 %}
11919 
11920 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11921                          iRegIorL2I src1, iRegIorL2I src2,
11922                          immI src3, rFlagsReg cr) %{
11923   match(Set dst (SubI src1 (RShiftI src2 src3)));
11924 
11925   ins_cost(1.9 * INSN_COST);
11926   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11927 
11928   ins_encode %{
11929     __ subw(as_Register($dst$$reg),
11930               as_Register($src1$$reg),
11931               as_Register($src2$$reg),
11932               Assembler::ASR,
11933               $src3$$constant &amp; 0x1f);
11934   %}
11935 
11936   ins_pipe(ialu_reg_reg_shift);
11937 %}
11938 
11939 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11940                          iRegL src1, iRegL src2,
11941                          immI src3, rFlagsReg cr) %{
11942   match(Set dst (SubL src1 (RShiftL src2 src3)));
11943 
11944   ins_cost(1.9 * INSN_COST);
11945   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11946 
11947   ins_encode %{
11948     __ sub(as_Register($dst$$reg),
11949               as_Register($src1$$reg),
11950               as_Register($src2$$reg),
11951               Assembler::ASR,
11952               $src3$$constant &amp; 0x3f);
11953   %}
11954 
11955   ins_pipe(ialu_reg_reg_shift);
11956 %}
11957 
11958 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11959                          iRegIorL2I src1, iRegIorL2I src2,
11960                          immI src3, rFlagsReg cr) %{
11961   match(Set dst (SubI src1 (LShiftI src2 src3)));
11962 
11963   ins_cost(1.9 * INSN_COST);
11964   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11965 
11966   ins_encode %{
11967     __ subw(as_Register($dst$$reg),
11968               as_Register($src1$$reg),
11969               as_Register($src2$$reg),
11970               Assembler::LSL,
11971               $src3$$constant &amp; 0x1f);
11972   %}
11973 
11974   ins_pipe(ialu_reg_reg_shift);
11975 %}
11976 
11977 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11978                          iRegL src1, iRegL src2,
11979                          immI src3, rFlagsReg cr) %{
11980   match(Set dst (SubL src1 (LShiftL src2 src3)));
11981 
11982   ins_cost(1.9 * INSN_COST);
11983   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11984 
11985   ins_encode %{
11986     __ sub(as_Register($dst$$reg),
11987               as_Register($src1$$reg),
11988               as_Register($src2$$reg),
11989               Assembler::LSL,
11990               $src3$$constant &amp; 0x3f);
11991   %}
11992 
11993   ins_pipe(ialu_reg_reg_shift);
11994 %}
11995 
11996 
11997 
11998 // Shift Left followed by Shift Right.
11999 // This idiom is used by the compiler for the i2b bytecode etc.
12000 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
12001 %{
12002   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
12003   ins_cost(INSN_COST * 2);
12004   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
12005   ins_encode %{
12006     int lshift = $lshift_count$$constant &amp; 63;
12007     int rshift = $rshift_count$$constant &amp; 63;
12008     int s = 63 - lshift;
12009     int r = (rshift - lshift) &amp; 63;
12010     __ sbfm(as_Register($dst$$reg),
12011             as_Register($src$$reg),
12012             r, s);
12013   %}
12014 
12015   ins_pipe(ialu_reg_shift);
12016 %}
12017 
12018 // Shift Left followed by Shift Right.
12019 // This idiom is used by the compiler for the i2b bytecode etc.
12020 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12021 %{
12022   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
12023   ins_cost(INSN_COST * 2);
12024   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12025   ins_encode %{
12026     int lshift = $lshift_count$$constant &amp; 31;
12027     int rshift = $rshift_count$$constant &amp; 31;
12028     int s = 31 - lshift;
12029     int r = (rshift - lshift) &amp; 31;
12030     __ sbfmw(as_Register($dst$$reg),
12031             as_Register($src$$reg),
12032             r, s);
12033   %}
12034 
12035   ins_pipe(ialu_reg_shift);
12036 %}
12037 
12038 // Shift Left followed by Shift Right.
12039 // This idiom is used by the compiler for the i2b bytecode etc.
12040 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
12041 %{
12042   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
12043   ins_cost(INSN_COST * 2);
12044   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
12045   ins_encode %{
12046     int lshift = $lshift_count$$constant &amp; 63;
12047     int rshift = $rshift_count$$constant &amp; 63;
12048     int s = 63 - lshift;
12049     int r = (rshift - lshift) &amp; 63;
12050     __ ubfm(as_Register($dst$$reg),
12051             as_Register($src$$reg),
12052             r, s);
12053   %}
12054 
12055   ins_pipe(ialu_reg_shift);
12056 %}
12057 
12058 // Shift Left followed by Shift Right.
12059 // This idiom is used by the compiler for the i2b bytecode etc.
12060 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12061 %{
12062   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
12063   ins_cost(INSN_COST * 2);
12064   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12065   ins_encode %{
12066     int lshift = $lshift_count$$constant &amp; 31;
12067     int rshift = $rshift_count$$constant &amp; 31;
12068     int s = 31 - lshift;
12069     int r = (rshift - lshift) &amp; 31;
12070     __ ubfmw(as_Register($dst$$reg),
12071             as_Register($src$$reg),
12072             r, s);
12073   %}
12074 
12075   ins_pipe(ialu_reg_shift);
12076 %}
12077 // Bitfield extract with shift &amp; mask
12078 
12079 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12080 %{
12081   match(Set dst (AndI (URShiftI src rshift) mask));
12082   // Make sure we are not going to exceed what ubfxw can do.
12083   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12084 
12085   ins_cost(INSN_COST);
12086   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12087   ins_encode %{
12088     int rshift = $rshift$$constant &amp; 31;
12089     long mask = $mask$$constant;
12090     int width = exact_log2(mask+1);
12091     __ ubfxw(as_Register($dst$$reg),
12092             as_Register($src$$reg), rshift, width);
12093   %}
12094   ins_pipe(ialu_reg_shift);
12095 %}
12096 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12097 %{
12098   match(Set dst (AndL (URShiftL src rshift) mask));
12099   // Make sure we are not going to exceed what ubfx can do.
12100   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12101 
12102   ins_cost(INSN_COST);
12103   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12104   ins_encode %{
12105     int rshift = $rshift$$constant &amp; 63;
12106     long mask = $mask$$constant;
12107     int width = exact_log2_long(mask+1);
12108     __ ubfx(as_Register($dst$$reg),
12109             as_Register($src$$reg), rshift, width);
12110   %}
12111   ins_pipe(ialu_reg_shift);
12112 %}
12113 
12114 // We can use ubfx when extending an And with a mask when we know mask
12115 // is positive.  We know that because immI_bitmask guarantees it.
12116 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12117 %{
12118   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12119   // Make sure we are not going to exceed what ubfxw can do.
12120   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12121 
12122   ins_cost(INSN_COST * 2);
12123   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12124   ins_encode %{
12125     int rshift = $rshift$$constant &amp; 31;
12126     long mask = $mask$$constant;
12127     int width = exact_log2(mask+1);
12128     __ ubfx(as_Register($dst$$reg),
12129             as_Register($src$$reg), rshift, width);
12130   %}
12131   ins_pipe(ialu_reg_shift);
12132 %}
12133 
12134 // We can use ubfiz when masking by a positive number and then left shifting the result.
12135 // We know that the mask is positive because immI_bitmask guarantees it.
12136 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12137 %{
12138   match(Set dst (LShiftI (AndI src mask) lshift));
12139   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12140 
12141   ins_cost(INSN_COST);
12142   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12143   ins_encode %{
12144     int lshift = $lshift$$constant &amp; 31;
12145     long mask = $mask$$constant;
12146     int width = exact_log2(mask+1);
12147     __ ubfizw(as_Register($dst$$reg),
12148           as_Register($src$$reg), lshift, width);
12149   %}
12150   ins_pipe(ialu_reg_shift);
12151 %}
12152 // We can use ubfiz when masking by a positive number and then left shifting the result.
12153 // We know that the mask is positive because immL_bitmask guarantees it.
12154 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12155 %{
12156   match(Set dst (LShiftL (AndL src mask) lshift));
12157   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12158 
12159   ins_cost(INSN_COST);
12160   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12161   ins_encode %{
12162     int lshift = $lshift$$constant &amp; 63;
12163     long mask = $mask$$constant;
12164     int width = exact_log2_long(mask+1);
12165     __ ubfiz(as_Register($dst$$reg),
12166           as_Register($src$$reg), lshift, width);
12167   %}
12168   ins_pipe(ialu_reg_shift);
12169 %}
12170 
12171 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12172 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12173 %{
12174   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12175   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12176 
12177   ins_cost(INSN_COST);
12178   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12179   ins_encode %{
12180     int lshift = $lshift$$constant &amp; 63;
12181     long mask = $mask$$constant;
12182     int width = exact_log2(mask+1);
12183     __ ubfiz(as_Register($dst$$reg),
12184              as_Register($src$$reg), lshift, width);
12185   %}
12186   ins_pipe(ialu_reg_shift);
12187 %}
12188 
12189 // Rotations
12190 
12191 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12192 %{
12193   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12194   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12195 
12196   ins_cost(INSN_COST);
12197   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12198 
12199   ins_encode %{
12200     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12201             $rshift$$constant &amp; 63);
12202   %}
12203   ins_pipe(ialu_reg_reg_extr);
12204 %}
12205 
12206 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12207 %{
12208   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12209   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12210 
12211   ins_cost(INSN_COST);
12212   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12213 
12214   ins_encode %{
12215     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12216             $rshift$$constant &amp; 31);
12217   %}
12218   ins_pipe(ialu_reg_reg_extr);
12219 %}
12220 
12221 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12222 %{
12223   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12224   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12225 
12226   ins_cost(INSN_COST);
12227   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12228 
12229   ins_encode %{
12230     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12231             $rshift$$constant &amp; 63);
12232   %}
12233   ins_pipe(ialu_reg_reg_extr);
12234 %}
12235 
12236 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12237 %{
12238   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12239   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12240 
12241   ins_cost(INSN_COST);
12242   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12243 
12244   ins_encode %{
12245     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12246             $rshift$$constant &amp; 31);
12247   %}
12248   ins_pipe(ialu_reg_reg_extr);
12249 %}
12250 
12251 
12252 // rol expander
12253 
12254 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12255 %{
12256   effect(DEF dst, USE src, USE shift);
12257 
12258   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12259   ins_cost(INSN_COST * 3);
12260   ins_encode %{
12261     __ subw(rscratch1, zr, as_Register($shift$$reg));
12262     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12263             rscratch1);
12264     %}
12265   ins_pipe(ialu_reg_reg_vshift);
12266 %}
12267 
12268 // rol expander
12269 
12270 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12271 %{
12272   effect(DEF dst, USE src, USE shift);
12273 
12274   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12275   ins_cost(INSN_COST * 3);
12276   ins_encode %{
12277     __ subw(rscratch1, zr, as_Register($shift$$reg));
12278     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12279             rscratch1);
12280     %}
12281   ins_pipe(ialu_reg_reg_vshift);
12282 %}
12283 
12284 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12285 %{
12286   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12287 
12288   expand %{
12289     rolL_rReg(dst, src, shift, cr);
12290   %}
12291 %}
12292 
12293 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12294 %{
12295   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12296 
12297   expand %{
12298     rolL_rReg(dst, src, shift, cr);
12299   %}
12300 %}
12301 
12302 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12303 %{
12304   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12305 
12306   expand %{
12307     rolI_rReg(dst, src, shift, cr);
12308   %}
12309 %}
12310 
12311 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12312 %{
12313   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12314 
12315   expand %{
12316     rolI_rReg(dst, src, shift, cr);
12317   %}
12318 %}
12319 
12320 // ror expander
12321 
12322 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12323 %{
12324   effect(DEF dst, USE src, USE shift);
12325 
12326   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12327   ins_cost(INSN_COST);
12328   ins_encode %{
12329     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12330             as_Register($shift$$reg));
12331     %}
12332   ins_pipe(ialu_reg_reg_vshift);
12333 %}
12334 
12335 // ror expander
12336 
12337 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12338 %{
12339   effect(DEF dst, USE src, USE shift);
12340 
12341   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12342   ins_cost(INSN_COST);
12343   ins_encode %{
12344     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12345             as_Register($shift$$reg));
12346     %}
12347   ins_pipe(ialu_reg_reg_vshift);
12348 %}
12349 
12350 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12351 %{
12352   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12353 
12354   expand %{
12355     rorL_rReg(dst, src, shift, cr);
12356   %}
12357 %}
12358 
12359 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12360 %{
12361   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12362 
12363   expand %{
12364     rorL_rReg(dst, src, shift, cr);
12365   %}
12366 %}
12367 
12368 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12369 %{
12370   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12371 
12372   expand %{
12373     rorI_rReg(dst, src, shift, cr);
12374   %}
12375 %}
12376 
12377 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12378 %{
12379   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12380 
12381   expand %{
12382     rorI_rReg(dst, src, shift, cr);
12383   %}
12384 %}
12385 
12386 // Add/subtract (extended)
12387 
12388 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12389 %{
12390   match(Set dst (AddL src1 (ConvI2L src2)));
12391   ins_cost(INSN_COST);
12392   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12393 
12394    ins_encode %{
12395      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12396             as_Register($src2$$reg), ext::sxtw);
12397    %}
12398   ins_pipe(ialu_reg_reg);
12399 %};
12400 
12401 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12402 %{
12403   match(Set dst (SubL src1 (ConvI2L src2)));
12404   ins_cost(INSN_COST);
12405   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12406 
12407    ins_encode %{
12408      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12409             as_Register($src2$$reg), ext::sxtw);
12410    %}
12411   ins_pipe(ialu_reg_reg);
12412 %};
12413 
12414 
12415 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12416 %{
12417   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12418   ins_cost(INSN_COST);
12419   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12420 
12421    ins_encode %{
12422      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12423             as_Register($src2$$reg), ext::sxth);
12424    %}
12425   ins_pipe(ialu_reg_reg);
12426 %}
12427 
12428 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12429 %{
12430   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12431   ins_cost(INSN_COST);
12432   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12433 
12434    ins_encode %{
12435      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12436             as_Register($src2$$reg), ext::sxtb);
12437    %}
12438   ins_pipe(ialu_reg_reg);
12439 %}
12440 
12441 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12442 %{
12443   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12444   ins_cost(INSN_COST);
12445   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12446 
12447    ins_encode %{
12448      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12449             as_Register($src2$$reg), ext::uxtb);
12450    %}
12451   ins_pipe(ialu_reg_reg);
12452 %}
12453 
12454 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12455 %{
12456   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12457   ins_cost(INSN_COST);
12458   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12459 
12460    ins_encode %{
12461      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12462             as_Register($src2$$reg), ext::sxth);
12463    %}
12464   ins_pipe(ialu_reg_reg);
12465 %}
12466 
12467 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12468 %{
12469   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12470   ins_cost(INSN_COST);
12471   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12472 
12473    ins_encode %{
12474      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12475             as_Register($src2$$reg), ext::sxtw);
12476    %}
12477   ins_pipe(ialu_reg_reg);
12478 %}
12479 
12480 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12481 %{
12482   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12483   ins_cost(INSN_COST);
12484   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12485 
12486    ins_encode %{
12487      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12488             as_Register($src2$$reg), ext::sxtb);
12489    %}
12490   ins_pipe(ialu_reg_reg);
12491 %}
12492 
12493 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12494 %{
12495   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12496   ins_cost(INSN_COST);
12497   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12498 
12499    ins_encode %{
12500      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12501             as_Register($src2$$reg), ext::uxtb);
12502    %}
12503   ins_pipe(ialu_reg_reg);
12504 %}
12505 
12506 
12507 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12508 %{
12509   match(Set dst (AddI src1 (AndI src2 mask)));
12510   ins_cost(INSN_COST);
12511   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12512 
12513    ins_encode %{
12514      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12515             as_Register($src2$$reg), ext::uxtb);
12516    %}
12517   ins_pipe(ialu_reg_reg);
12518 %}
12519 
12520 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12521 %{
12522   match(Set dst (AddI src1 (AndI src2 mask)));
12523   ins_cost(INSN_COST);
12524   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12525 
12526    ins_encode %{
12527      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12528             as_Register($src2$$reg), ext::uxth);
12529    %}
12530   ins_pipe(ialu_reg_reg);
12531 %}
12532 
12533 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12534 %{
12535   match(Set dst (AddL src1 (AndL src2 mask)));
12536   ins_cost(INSN_COST);
12537   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12538 
12539    ins_encode %{
12540      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12541             as_Register($src2$$reg), ext::uxtb);
12542    %}
12543   ins_pipe(ialu_reg_reg);
12544 %}
12545 
12546 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12547 %{
12548   match(Set dst (AddL src1 (AndL src2 mask)));
12549   ins_cost(INSN_COST);
12550   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12551 
12552    ins_encode %{
12553      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12554             as_Register($src2$$reg), ext::uxth);
12555    %}
12556   ins_pipe(ialu_reg_reg);
12557 %}
12558 
12559 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12560 %{
12561   match(Set dst (AddL src1 (AndL src2 mask)));
12562   ins_cost(INSN_COST);
12563   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12564 
12565    ins_encode %{
12566      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12567             as_Register($src2$$reg), ext::uxtw);
12568    %}
12569   ins_pipe(ialu_reg_reg);
12570 %}
12571 
12572 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12573 %{
12574   match(Set dst (SubI src1 (AndI src2 mask)));
12575   ins_cost(INSN_COST);
12576   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12577 
12578    ins_encode %{
12579      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12580             as_Register($src2$$reg), ext::uxtb);
12581    %}
12582   ins_pipe(ialu_reg_reg);
12583 %}
12584 
12585 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12586 %{
12587   match(Set dst (SubI src1 (AndI src2 mask)));
12588   ins_cost(INSN_COST);
12589   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12590 
12591    ins_encode %{
12592      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12593             as_Register($src2$$reg), ext::uxth);
12594    %}
12595   ins_pipe(ialu_reg_reg);
12596 %}
12597 
12598 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12599 %{
12600   match(Set dst (SubL src1 (AndL src2 mask)));
12601   ins_cost(INSN_COST);
12602   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12603 
12604    ins_encode %{
12605      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12606             as_Register($src2$$reg), ext::uxtb);
12607    %}
12608   ins_pipe(ialu_reg_reg);
12609 %}
12610 
12611 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12612 %{
12613   match(Set dst (SubL src1 (AndL src2 mask)));
12614   ins_cost(INSN_COST);
12615   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12616 
12617    ins_encode %{
12618      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12619             as_Register($src2$$reg), ext::uxth);
12620    %}
12621   ins_pipe(ialu_reg_reg);
12622 %}
12623 
12624 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12625 %{
12626   match(Set dst (SubL src1 (AndL src2 mask)));
12627   ins_cost(INSN_COST);
12628   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12629 
12630    ins_encode %{
12631      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12632             as_Register($src2$$reg), ext::uxtw);
12633    %}
12634   ins_pipe(ialu_reg_reg);
12635 %}
12636 
12637 
12638 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12639 %{
12640   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12641   ins_cost(1.9 * INSN_COST);
12642   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12643 
12644    ins_encode %{
12645      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12646             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12647    %}
12648   ins_pipe(ialu_reg_reg_shift);
12649 %}
12650 
12651 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12652 %{
12653   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12654   ins_cost(1.9 * INSN_COST);
12655   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12656 
12657    ins_encode %{
12658      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12659             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12660    %}
12661   ins_pipe(ialu_reg_reg_shift);
12662 %}
12663 
12664 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12665 %{
12666   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12667   ins_cost(1.9 * INSN_COST);
12668   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12669 
12670    ins_encode %{
12671      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12672             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12673    %}
12674   ins_pipe(ialu_reg_reg_shift);
12675 %}
12676 
12677 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12678 %{
12679   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12680   ins_cost(1.9 * INSN_COST);
12681   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12682 
12683    ins_encode %{
12684      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12685             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12686    %}
12687   ins_pipe(ialu_reg_reg_shift);
12688 %}
12689 
12690 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12691 %{
12692   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12693   ins_cost(1.9 * INSN_COST);
12694   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12695 
12696    ins_encode %{
12697      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12698             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12699    %}
12700   ins_pipe(ialu_reg_reg_shift);
12701 %}
12702 
12703 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12704 %{
12705   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12706   ins_cost(1.9 * INSN_COST);
12707   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12708 
12709    ins_encode %{
12710      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12711             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12712    %}
12713   ins_pipe(ialu_reg_reg_shift);
12714 %}
12715 
12716 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12717 %{
12718   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12719   ins_cost(1.9 * INSN_COST);
12720   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12721 
12722    ins_encode %{
12723      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12724             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12725    %}
12726   ins_pipe(ialu_reg_reg_shift);
12727 %}
12728 
12729 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12730 %{
12731   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12732   ins_cost(1.9 * INSN_COST);
12733   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12734 
12735    ins_encode %{
12736      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12737             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12738    %}
12739   ins_pipe(ialu_reg_reg_shift);
12740 %}
12741 
12742 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12743 %{
12744   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12745   ins_cost(1.9 * INSN_COST);
12746   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12747 
12748    ins_encode %{
12749      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12750             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12751    %}
12752   ins_pipe(ialu_reg_reg_shift);
12753 %}
12754 
12755 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12756 %{
12757   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12758   ins_cost(1.9 * INSN_COST);
12759   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12760 
12761    ins_encode %{
12762      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12763             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12764    %}
12765   ins_pipe(ialu_reg_reg_shift);
12766 %}
12767 
12768 
12769 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12770 %{
12771   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12772   ins_cost(1.9 * INSN_COST);
12773   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12774 
12775    ins_encode %{
12776      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12777             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12778    %}
12779   ins_pipe(ialu_reg_reg_shift);
12780 %};
12781 
12782 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12783 %{
12784   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12785   ins_cost(1.9 * INSN_COST);
12786   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12787 
12788    ins_encode %{
12789      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12790             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12791    %}
12792   ins_pipe(ialu_reg_reg_shift);
12793 %};
12794 
12795 
12796 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12797 %{
12798   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12799   ins_cost(1.9 * INSN_COST);
12800   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12801 
12802    ins_encode %{
12803      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12804             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12805    %}
12806   ins_pipe(ialu_reg_reg_shift);
12807 %}
12808 
12809 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12810 %{
12811   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12812   ins_cost(1.9 * INSN_COST);
12813   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12814 
12815    ins_encode %{
12816      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12817             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12818    %}
12819   ins_pipe(ialu_reg_reg_shift);
12820 %}
12821 
12822 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12823 %{
12824   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12825   ins_cost(1.9 * INSN_COST);
12826   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12827 
12828    ins_encode %{
12829      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12830             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12831    %}
12832   ins_pipe(ialu_reg_reg_shift);
12833 %}
12834 
12835 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12836 %{
12837   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12838   ins_cost(1.9 * INSN_COST);
12839   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12840 
12841    ins_encode %{
12842      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12843             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12844    %}
12845   ins_pipe(ialu_reg_reg_shift);
12846 %}
12847 
12848 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12849 %{
12850   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12851   ins_cost(1.9 * INSN_COST);
12852   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12853 
12854    ins_encode %{
12855      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12856             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12857    %}
12858   ins_pipe(ialu_reg_reg_shift);
12859 %}
12860 
12861 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12862 %{
12863   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12864   ins_cost(1.9 * INSN_COST);
12865   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12866 
12867    ins_encode %{
12868      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12869             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12870    %}
12871   ins_pipe(ialu_reg_reg_shift);
12872 %}
12873 
12874 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12875 %{
12876   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12877   ins_cost(1.9 * INSN_COST);
12878   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12879 
12880    ins_encode %{
12881      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12882             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12883    %}
12884   ins_pipe(ialu_reg_reg_shift);
12885 %}
12886 
12887 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12888 %{
12889   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12890   ins_cost(1.9 * INSN_COST);
12891   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12892 
12893    ins_encode %{
12894      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12895             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12896    %}
12897   ins_pipe(ialu_reg_reg_shift);
12898 %}
12899 
12900 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12901 %{
12902   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12903   ins_cost(1.9 * INSN_COST);
12904   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12905 
12906    ins_encode %{
12907      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12908             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12909    %}
12910   ins_pipe(ialu_reg_reg_shift);
12911 %}
12912 
12913 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12914 %{
12915   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12916   ins_cost(1.9 * INSN_COST);
12917   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12918 
12919    ins_encode %{
12920      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12921             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12922    %}
12923   ins_pipe(ialu_reg_reg_shift);
12924 %}
12925 // END This section of the file is automatically generated. Do not edit --------------
12926 
12927 // ============================================================================
12928 // Floating Point Arithmetic Instructions
12929 
12930 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12931   match(Set dst (AddF src1 src2));
12932 
12933   ins_cost(INSN_COST * 5);
12934   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12935 
12936   ins_encode %{
12937     __ fadds(as_FloatRegister($dst$$reg),
12938              as_FloatRegister($src1$$reg),
12939              as_FloatRegister($src2$$reg));
12940   %}
12941 
12942   ins_pipe(fp_dop_reg_reg_s);
12943 %}
12944 
12945 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12946   match(Set dst (AddD src1 src2));
12947 
12948   ins_cost(INSN_COST * 5);
12949   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12950 
12951   ins_encode %{
12952     __ faddd(as_FloatRegister($dst$$reg),
12953              as_FloatRegister($src1$$reg),
12954              as_FloatRegister($src2$$reg));
12955   %}
12956 
12957   ins_pipe(fp_dop_reg_reg_d);
12958 %}
12959 
12960 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12961   match(Set dst (SubF src1 src2));
12962 
12963   ins_cost(INSN_COST * 5);
12964   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12965 
12966   ins_encode %{
12967     __ fsubs(as_FloatRegister($dst$$reg),
12968              as_FloatRegister($src1$$reg),
12969              as_FloatRegister($src2$$reg));
12970   %}
12971 
12972   ins_pipe(fp_dop_reg_reg_s);
12973 %}
12974 
12975 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12976   match(Set dst (SubD src1 src2));
12977 
12978   ins_cost(INSN_COST * 5);
12979   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12980 
12981   ins_encode %{
12982     __ fsubd(as_FloatRegister($dst$$reg),
12983              as_FloatRegister($src1$$reg),
12984              as_FloatRegister($src2$$reg));
12985   %}
12986 
12987   ins_pipe(fp_dop_reg_reg_d);
12988 %}
12989 
12990 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12991   match(Set dst (MulF src1 src2));
12992 
12993   ins_cost(INSN_COST * 6);
12994   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12995 
12996   ins_encode %{
12997     __ fmuls(as_FloatRegister($dst$$reg),
12998              as_FloatRegister($src1$$reg),
12999              as_FloatRegister($src2$$reg));
13000   %}
13001 
13002   ins_pipe(fp_dop_reg_reg_s);
13003 %}
13004 
13005 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13006   match(Set dst (MulD src1 src2));
13007 
13008   ins_cost(INSN_COST * 6);
13009   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
13010 
13011   ins_encode %{
13012     __ fmuld(as_FloatRegister($dst$$reg),
13013              as_FloatRegister($src1$$reg),
13014              as_FloatRegister($src2$$reg));
13015   %}
13016 
13017   ins_pipe(fp_dop_reg_reg_d);
13018 %}
13019 
13020 // src1 * src2 + src3
13021 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13022   predicate(UseFMA);
13023   match(Set dst (FmaF src3 (Binary src1 src2)));
13024 
13025   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
13026 
13027   ins_encode %{
13028     __ fmadds(as_FloatRegister($dst$$reg),
13029              as_FloatRegister($src1$$reg),
13030              as_FloatRegister($src2$$reg),
13031              as_FloatRegister($src3$$reg));
13032   %}
13033 
13034   ins_pipe(pipe_class_default);
13035 %}
13036 
13037 // src1 * src2 + src3
13038 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13039   predicate(UseFMA);
13040   match(Set dst (FmaD src3 (Binary src1 src2)));
13041 
13042   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
13043 
13044   ins_encode %{
13045     __ fmaddd(as_FloatRegister($dst$$reg),
13046              as_FloatRegister($src1$$reg),
13047              as_FloatRegister($src2$$reg),
13048              as_FloatRegister($src3$$reg));
13049   %}
13050 
13051   ins_pipe(pipe_class_default);
13052 %}
13053 
13054 // -src1 * src2 + src3
13055 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13056   predicate(UseFMA);
13057   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
13058   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
13059 
13060   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
13061 
13062   ins_encode %{
13063     __ fmsubs(as_FloatRegister($dst$$reg),
13064               as_FloatRegister($src1$$reg),
13065               as_FloatRegister($src2$$reg),
13066               as_FloatRegister($src3$$reg));
13067   %}
13068 
13069   ins_pipe(pipe_class_default);
13070 %}
13071 
13072 // -src1 * src2 + src3
13073 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13074   predicate(UseFMA);
13075   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
13076   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
13077 
13078   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13079 
13080   ins_encode %{
13081     __ fmsubd(as_FloatRegister($dst$$reg),
13082               as_FloatRegister($src1$$reg),
13083               as_FloatRegister($src2$$reg),
13084               as_FloatRegister($src3$$reg));
13085   %}
13086 
13087   ins_pipe(pipe_class_default);
13088 %}
13089 
13090 // -src1 * src2 - src3
13091 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13092   predicate(UseFMA);
13093   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13094   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13095 
13096   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13097 
13098   ins_encode %{
13099     __ fnmadds(as_FloatRegister($dst$$reg),
13100                as_FloatRegister($src1$$reg),
13101                as_FloatRegister($src2$$reg),
13102                as_FloatRegister($src3$$reg));
13103   %}
13104 
13105   ins_pipe(pipe_class_default);
13106 %}
13107 
13108 // -src1 * src2 - src3
13109 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13110   predicate(UseFMA);
13111   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13112   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13113 
13114   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13115 
13116   ins_encode %{
13117     __ fnmaddd(as_FloatRegister($dst$$reg),
13118                as_FloatRegister($src1$$reg),
13119                as_FloatRegister($src2$$reg),
13120                as_FloatRegister($src3$$reg));
13121   %}
13122 
13123   ins_pipe(pipe_class_default);
13124 %}
13125 
13126 // src1 * src2 - src3
13127 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13128   predicate(UseFMA);
13129   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13130 
13131   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13132 
13133   ins_encode %{
13134     __ fnmsubs(as_FloatRegister($dst$$reg),
13135                as_FloatRegister($src1$$reg),
13136                as_FloatRegister($src2$$reg),
13137                as_FloatRegister($src3$$reg));
13138   %}
13139 
13140   ins_pipe(pipe_class_default);
13141 %}
13142 
13143 // src1 * src2 - src3
13144 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13145   predicate(UseFMA);
13146   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13147 
13148   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13149 
13150   ins_encode %{
13151   // n.b. insn name should be fnmsubd
13152     __ fnmsub(as_FloatRegister($dst$$reg),
13153               as_FloatRegister($src1$$reg),
13154               as_FloatRegister($src2$$reg),
13155               as_FloatRegister($src3$$reg));
13156   %}
13157 
13158   ins_pipe(pipe_class_default);
13159 %}
13160 
13161 
13162 // Math.max(FF)F
13163 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13164   match(Set dst (MaxF src1 src2));
13165 
13166   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13167   ins_encode %{
13168     __ fmaxs(as_FloatRegister($dst$$reg),
13169              as_FloatRegister($src1$$reg),
13170              as_FloatRegister($src2$$reg));
13171   %}
13172 
13173   ins_pipe(fp_dop_reg_reg_s);
13174 %}
13175 
13176 // Math.min(FF)F
13177 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13178   match(Set dst (MinF src1 src2));
13179 
13180   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13181   ins_encode %{
13182     __ fmins(as_FloatRegister($dst$$reg),
13183              as_FloatRegister($src1$$reg),
13184              as_FloatRegister($src2$$reg));
13185   %}
13186 
13187   ins_pipe(fp_dop_reg_reg_s);
13188 %}
13189 
13190 // Math.max(DD)D
13191 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13192   match(Set dst (MaxD src1 src2));
13193 
13194   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13195   ins_encode %{
13196     __ fmaxd(as_FloatRegister($dst$$reg),
13197              as_FloatRegister($src1$$reg),
13198              as_FloatRegister($src2$$reg));
13199   %}
13200 
13201   ins_pipe(fp_dop_reg_reg_d);
13202 %}
13203 
13204 // Math.min(DD)D
13205 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13206   match(Set dst (MinD src1 src2));
13207 
13208   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13209   ins_encode %{
13210     __ fmind(as_FloatRegister($dst$$reg),
13211              as_FloatRegister($src1$$reg),
13212              as_FloatRegister($src2$$reg));
13213   %}
13214 
13215   ins_pipe(fp_dop_reg_reg_d);
13216 %}
13217 
13218 
13219 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13220   match(Set dst (DivF src1  src2));
13221 
13222   ins_cost(INSN_COST * 18);
13223   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13224 
13225   ins_encode %{
13226     __ fdivs(as_FloatRegister($dst$$reg),
13227              as_FloatRegister($src1$$reg),
13228              as_FloatRegister($src2$$reg));
13229   %}
13230 
13231   ins_pipe(fp_div_s);
13232 %}
13233 
13234 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13235   match(Set dst (DivD src1  src2));
13236 
13237   ins_cost(INSN_COST * 32);
13238   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13239 
13240   ins_encode %{
13241     __ fdivd(as_FloatRegister($dst$$reg),
13242              as_FloatRegister($src1$$reg),
13243              as_FloatRegister($src2$$reg));
13244   %}
13245 
13246   ins_pipe(fp_div_d);
13247 %}
13248 
13249 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13250   match(Set dst (NegF src));
13251 
13252   ins_cost(INSN_COST * 3);
13253   format %{ &quot;fneg   $dst, $src&quot; %}
13254 
13255   ins_encode %{
13256     __ fnegs(as_FloatRegister($dst$$reg),
13257              as_FloatRegister($src$$reg));
13258   %}
13259 
13260   ins_pipe(fp_uop_s);
13261 %}
13262 
13263 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13264   match(Set dst (NegD src));
13265 
13266   ins_cost(INSN_COST * 3);
13267   format %{ &quot;fnegd   $dst, $src&quot; %}
13268 
13269   ins_encode %{
13270     __ fnegd(as_FloatRegister($dst$$reg),
13271              as_FloatRegister($src$$reg));
13272   %}
13273 
13274   ins_pipe(fp_uop_d);
13275 %}
13276 
13277 instruct absF_reg(vRegF dst, vRegF src) %{
13278   match(Set dst (AbsF src));
13279 
13280   ins_cost(INSN_COST * 3);
13281   format %{ &quot;fabss   $dst, $src&quot; %}
13282   ins_encode %{
13283     __ fabss(as_FloatRegister($dst$$reg),
13284              as_FloatRegister($src$$reg));
13285   %}
13286 
13287   ins_pipe(fp_uop_s);
13288 %}
13289 
13290 instruct absD_reg(vRegD dst, vRegD src) %{
13291   match(Set dst (AbsD src));
13292 
13293   ins_cost(INSN_COST * 3);
13294   format %{ &quot;fabsd   $dst, $src&quot; %}
13295   ins_encode %{
13296     __ fabsd(as_FloatRegister($dst$$reg),
13297              as_FloatRegister($src$$reg));
13298   %}
13299 
13300   ins_pipe(fp_uop_d);
13301 %}
13302 
13303 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13304   match(Set dst (SqrtD src));
13305 
13306   ins_cost(INSN_COST * 50);
13307   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13308   ins_encode %{
13309     __ fsqrtd(as_FloatRegister($dst$$reg),
13310              as_FloatRegister($src$$reg));
13311   %}
13312 
13313   ins_pipe(fp_div_s);
13314 %}
13315 
13316 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13317   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13318 
13319   ins_cost(INSN_COST * 50);
13320   format %{ &quot;fsqrts  $dst, $src&quot; %}
13321   ins_encode %{
13322     __ fsqrts(as_FloatRegister($dst$$reg),
13323              as_FloatRegister($src$$reg));
13324   %}
13325 
13326   ins_pipe(fp_div_d);
13327 %}
13328 
13329 // Math.rint, floor, ceil
13330 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13331   match(Set dst (RoundDoubleMode src rmode));
13332   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13333   ins_encode %{
13334     switch ($rmode$$constant) {
13335       case RoundDoubleModeNode::rmode_rint:
13336         __ frintnd(as_FloatRegister($dst$$reg),
13337                    as_FloatRegister($src$$reg));
13338         break;
13339       case RoundDoubleModeNode::rmode_floor:
13340         __ frintmd(as_FloatRegister($dst$$reg),
13341                    as_FloatRegister($src$$reg));
13342         break;
13343       case RoundDoubleModeNode::rmode_ceil:
13344         __ frintpd(as_FloatRegister($dst$$reg),
13345                    as_FloatRegister($src$$reg));
13346         break;
13347     }
13348   %}
13349   ins_pipe(fp_uop_d);
13350 %}
13351 
13352 // ============================================================================
13353 // Logical Instructions
13354 
13355 // Integer Logical Instructions
13356 
13357 // And Instructions
13358 
13359 
13360 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13361   match(Set dst (AndI src1 src2));
13362 
13363   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13364 
13365   ins_cost(INSN_COST);
13366   ins_encode %{
13367     __ andw(as_Register($dst$$reg),
13368             as_Register($src1$$reg),
13369             as_Register($src2$$reg));
13370   %}
13371 
13372   ins_pipe(ialu_reg_reg);
13373 %}
13374 
13375 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13376   match(Set dst (AndI src1 src2));
13377 
13378   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13379 
13380   ins_cost(INSN_COST);
13381   ins_encode %{
13382     __ andw(as_Register($dst$$reg),
13383             as_Register($src1$$reg),
13384             (unsigned long)($src2$$constant));
13385   %}
13386 
13387   ins_pipe(ialu_reg_imm);
13388 %}
13389 
13390 // Or Instructions
13391 
13392 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13393   match(Set dst (OrI src1 src2));
13394 
13395   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13396 
13397   ins_cost(INSN_COST);
13398   ins_encode %{
13399     __ orrw(as_Register($dst$$reg),
13400             as_Register($src1$$reg),
13401             as_Register($src2$$reg));
13402   %}
13403 
13404   ins_pipe(ialu_reg_reg);
13405 %}
13406 
13407 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13408   match(Set dst (OrI src1 src2));
13409 
13410   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13411 
13412   ins_cost(INSN_COST);
13413   ins_encode %{
13414     __ orrw(as_Register($dst$$reg),
13415             as_Register($src1$$reg),
13416             (unsigned long)($src2$$constant));
13417   %}
13418 
13419   ins_pipe(ialu_reg_imm);
13420 %}
13421 
13422 // Xor Instructions
13423 
13424 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13425   match(Set dst (XorI src1 src2));
13426 
13427   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13428 
13429   ins_cost(INSN_COST);
13430   ins_encode %{
13431     __ eorw(as_Register($dst$$reg),
13432             as_Register($src1$$reg),
13433             as_Register($src2$$reg));
13434   %}
13435 
13436   ins_pipe(ialu_reg_reg);
13437 %}
13438 
13439 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13440   match(Set dst (XorI src1 src2));
13441 
13442   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13443 
13444   ins_cost(INSN_COST);
13445   ins_encode %{
13446     __ eorw(as_Register($dst$$reg),
13447             as_Register($src1$$reg),
13448             (unsigned long)($src2$$constant));
13449   %}
13450 
13451   ins_pipe(ialu_reg_imm);
13452 %}
13453 
13454 // Long Logical Instructions
13455 // TODO
13456 
13457 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13458   match(Set dst (AndL src1 src2));
13459 
13460   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13461 
13462   ins_cost(INSN_COST);
13463   ins_encode %{
13464     __ andr(as_Register($dst$$reg),
13465             as_Register($src1$$reg),
13466             as_Register($src2$$reg));
13467   %}
13468 
13469   ins_pipe(ialu_reg_reg);
13470 %}
13471 
13472 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13473   match(Set dst (AndL src1 src2));
13474 
13475   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13476 
13477   ins_cost(INSN_COST);
13478   ins_encode %{
13479     __ andr(as_Register($dst$$reg),
13480             as_Register($src1$$reg),
13481             (unsigned long)($src2$$constant));
13482   %}
13483 
13484   ins_pipe(ialu_reg_imm);
13485 %}
13486 
13487 // Or Instructions
13488 
13489 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13490   match(Set dst (OrL src1 src2));
13491 
13492   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13493 
13494   ins_cost(INSN_COST);
13495   ins_encode %{
13496     __ orr(as_Register($dst$$reg),
13497            as_Register($src1$$reg),
13498            as_Register($src2$$reg));
13499   %}
13500 
13501   ins_pipe(ialu_reg_reg);
13502 %}
13503 
13504 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13505   match(Set dst (OrL src1 src2));
13506 
13507   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13508 
13509   ins_cost(INSN_COST);
13510   ins_encode %{
13511     __ orr(as_Register($dst$$reg),
13512            as_Register($src1$$reg),
13513            (unsigned long)($src2$$constant));
13514   %}
13515 
13516   ins_pipe(ialu_reg_imm);
13517 %}
13518 
13519 // Xor Instructions
13520 
13521 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13522   match(Set dst (XorL src1 src2));
13523 
13524   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13525 
13526   ins_cost(INSN_COST);
13527   ins_encode %{
13528     __ eor(as_Register($dst$$reg),
13529            as_Register($src1$$reg),
13530            as_Register($src2$$reg));
13531   %}
13532 
13533   ins_pipe(ialu_reg_reg);
13534 %}
13535 
13536 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13537   match(Set dst (XorL src1 src2));
13538 
13539   ins_cost(INSN_COST);
13540   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13541 
13542   ins_encode %{
13543     __ eor(as_Register($dst$$reg),
13544            as_Register($src1$$reg),
13545            (unsigned long)($src2$$constant));
13546   %}
13547 
13548   ins_pipe(ialu_reg_imm);
13549 %}
13550 
13551 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13552 %{
13553   match(Set dst (ConvI2L src));
13554 
13555   ins_cost(INSN_COST);
13556   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13557   ins_encode %{
13558     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13559   %}
13560   ins_pipe(ialu_reg_shift);
13561 %}
13562 
13563 // this pattern occurs in bigmath arithmetic
13564 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13565 %{
13566   match(Set dst (AndL (ConvI2L src) mask));
13567 
13568   ins_cost(INSN_COST);
13569   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13570   ins_encode %{
13571     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13572   %}
13573 
13574   ins_pipe(ialu_reg_shift);
13575 %}
13576 
13577 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13578   match(Set dst (ConvL2I src));
13579 
13580   ins_cost(INSN_COST);
13581   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13582 
13583   ins_encode %{
13584     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13585   %}
13586 
13587   ins_pipe(ialu_reg);
13588 %}
13589 
13590 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13591 %{
13592   match(Set dst (Conv2B src));
13593   effect(KILL cr);
13594 
13595   format %{
13596     &quot;cmpw $src, zr\n\t&quot;
13597     &quot;cset $dst, ne&quot;
13598   %}
13599 
13600   ins_encode %{
13601     __ cmpw(as_Register($src$$reg), zr);
13602     __ cset(as_Register($dst$$reg), Assembler::NE);
13603   %}
13604 
13605   ins_pipe(ialu_reg);
13606 %}
13607 
13608 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13609 %{
13610   match(Set dst (Conv2B src));
13611   effect(KILL cr);
13612 
13613   format %{
13614     &quot;cmp  $src, zr\n\t&quot;
13615     &quot;cset $dst, ne&quot;
13616   %}
13617 
13618   ins_encode %{
13619     __ cmp(as_Register($src$$reg), zr);
13620     __ cset(as_Register($dst$$reg), Assembler::NE);
13621   %}
13622 
13623   ins_pipe(ialu_reg);
13624 %}
13625 
13626 instruct convD2F_reg(vRegF dst, vRegD src) %{
13627   match(Set dst (ConvD2F src));
13628 
13629   ins_cost(INSN_COST * 5);
13630   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13631 
13632   ins_encode %{
13633     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13634   %}
13635 
13636   ins_pipe(fp_d2f);
13637 %}
13638 
13639 instruct convF2D_reg(vRegD dst, vRegF src) %{
13640   match(Set dst (ConvF2D src));
13641 
13642   ins_cost(INSN_COST * 5);
13643   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13644 
13645   ins_encode %{
13646     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13647   %}
13648 
13649   ins_pipe(fp_f2d);
13650 %}
13651 
13652 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13653   match(Set dst (ConvF2I src));
13654 
13655   ins_cost(INSN_COST * 5);
13656   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13657 
13658   ins_encode %{
13659     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13660   %}
13661 
13662   ins_pipe(fp_f2i);
13663 %}
13664 
13665 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13666   match(Set dst (ConvF2L src));
13667 
13668   ins_cost(INSN_COST * 5);
13669   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13670 
13671   ins_encode %{
13672     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13673   %}
13674 
13675   ins_pipe(fp_f2l);
13676 %}
13677 
13678 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13679   match(Set dst (ConvI2F src));
13680 
13681   ins_cost(INSN_COST * 5);
13682   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13683 
13684   ins_encode %{
13685     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13686   %}
13687 
13688   ins_pipe(fp_i2f);
13689 %}
13690 
13691 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13692   match(Set dst (ConvL2F src));
13693 
13694   ins_cost(INSN_COST * 5);
13695   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13696 
13697   ins_encode %{
13698     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13699   %}
13700 
13701   ins_pipe(fp_l2f);
13702 %}
13703 
13704 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13705   match(Set dst (ConvD2I src));
13706 
13707   ins_cost(INSN_COST * 5);
13708   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13709 
13710   ins_encode %{
13711     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13712   %}
13713 
13714   ins_pipe(fp_d2i);
13715 %}
13716 
13717 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13718   match(Set dst (ConvD2L src));
13719 
13720   ins_cost(INSN_COST * 5);
13721   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13722 
13723   ins_encode %{
13724     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13725   %}
13726 
13727   ins_pipe(fp_d2l);
13728 %}
13729 
13730 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13731   match(Set dst (ConvI2D src));
13732 
13733   ins_cost(INSN_COST * 5);
13734   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13735 
13736   ins_encode %{
13737     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13738   %}
13739 
13740   ins_pipe(fp_i2d);
13741 %}
13742 
13743 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13744   match(Set dst (ConvL2D src));
13745 
13746   ins_cost(INSN_COST * 5);
13747   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13748 
13749   ins_encode %{
13750     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13751   %}
13752 
13753   ins_pipe(fp_l2d);
13754 %}
13755 
13756 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13757 
13758 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13759 
13760   match(Set dst (MoveF2I src));
13761 
13762   effect(DEF dst, USE src);
13763 
13764   ins_cost(4 * INSN_COST);
13765 
13766   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13767 
13768   ins_encode %{
13769     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13770   %}
13771 
13772   ins_pipe(iload_reg_reg);
13773 
13774 %}
13775 
13776 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13777 
13778   match(Set dst (MoveI2F src));
13779 
13780   effect(DEF dst, USE src);
13781 
13782   ins_cost(4 * INSN_COST);
13783 
13784   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13785 
13786   ins_encode %{
13787     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13788   %}
13789 
13790   ins_pipe(pipe_class_memory);
13791 
13792 %}
13793 
13794 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13795 
13796   match(Set dst (MoveD2L src));
13797 
13798   effect(DEF dst, USE src);
13799 
13800   ins_cost(4 * INSN_COST);
13801 
13802   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13803 
13804   ins_encode %{
13805     __ ldr($dst$$Register, Address(sp, $src$$disp));
13806   %}
13807 
13808   ins_pipe(iload_reg_reg);
13809 
13810 %}
13811 
13812 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13813 
13814   match(Set dst (MoveL2D src));
13815 
13816   effect(DEF dst, USE src);
13817 
13818   ins_cost(4 * INSN_COST);
13819 
13820   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13821 
13822   ins_encode %{
13823     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13824   %}
13825 
13826   ins_pipe(pipe_class_memory);
13827 
13828 %}
13829 
13830 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13831 
13832   match(Set dst (MoveF2I src));
13833 
13834   effect(DEF dst, USE src);
13835 
13836   ins_cost(INSN_COST);
13837 
13838   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13839 
13840   ins_encode %{
13841     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13842   %}
13843 
13844   ins_pipe(pipe_class_memory);
13845 
13846 %}
13847 
13848 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13849 
13850   match(Set dst (MoveI2F src));
13851 
13852   effect(DEF dst, USE src);
13853 
13854   ins_cost(INSN_COST);
13855 
13856   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13857 
13858   ins_encode %{
13859     __ strw($src$$Register, Address(sp, $dst$$disp));
13860   %}
13861 
13862   ins_pipe(istore_reg_reg);
13863 
13864 %}
13865 
13866 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13867 
13868   match(Set dst (MoveD2L src));
13869 
13870   effect(DEF dst, USE src);
13871 
13872   ins_cost(INSN_COST);
13873 
13874   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13875 
13876   ins_encode %{
13877     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13878   %}
13879 
13880   ins_pipe(pipe_class_memory);
13881 
13882 %}
13883 
13884 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13885 
13886   match(Set dst (MoveL2D src));
13887 
13888   effect(DEF dst, USE src);
13889 
13890   ins_cost(INSN_COST);
13891 
13892   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13893 
13894   ins_encode %{
13895     __ str($src$$Register, Address(sp, $dst$$disp));
13896   %}
13897 
13898   ins_pipe(istore_reg_reg);
13899 
13900 %}
13901 
13902 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13903 
13904   match(Set dst (MoveF2I src));
13905 
13906   effect(DEF dst, USE src);
13907 
13908   ins_cost(INSN_COST);
13909 
13910   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13911 
13912   ins_encode %{
13913     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13914   %}
13915 
13916   ins_pipe(fp_f2i);
13917 
13918 %}
13919 
13920 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13921 
13922   match(Set dst (MoveI2F src));
13923 
13924   effect(DEF dst, USE src);
13925 
13926   ins_cost(INSN_COST);
13927 
13928   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13929 
13930   ins_encode %{
13931     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13932   %}
13933 
13934   ins_pipe(fp_i2f);
13935 
13936 %}
13937 
13938 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13939 
13940   match(Set dst (MoveD2L src));
13941 
13942   effect(DEF dst, USE src);
13943 
13944   ins_cost(INSN_COST);
13945 
13946   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13947 
13948   ins_encode %{
13949     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13950   %}
13951 
13952   ins_pipe(fp_d2l);
13953 
13954 %}
13955 
13956 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13957 
13958   match(Set dst (MoveL2D src));
13959 
13960   effect(DEF dst, USE src);
13961 
13962   ins_cost(INSN_COST);
13963 
13964   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13965 
13966   ins_encode %{
13967     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13968   %}
13969 
13970   ins_pipe(fp_l2d);
13971 
13972 %}
13973 
13974 // ============================================================================
13975 // clearing of an array
13976 
13977 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)
13978 %{
13979   match(Set dummy (ClearArray (Binary cnt base) val));
13980   effect(USE_KILL cnt, USE_KILL base);
13981 
13982   ins_cost(4 * INSN_COST);
13983   format %{ &quot;ClearArray $cnt, $base, $val&quot; %}
13984 
13985   ins_encode %{
13986     __ fill_words($base$$Register, $cnt$$Register, $val$$Register);
13987   %}
13988 
13989   ins_pipe(pipe_class_memory);
13990 %}
13991 
13992 // ============================================================================
13993 // Overflow Math Instructions
13994 
13995 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13996 %{
13997   match(Set cr (OverflowAddI op1 op2));
13998 
13999   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
14000   ins_cost(INSN_COST);
14001   ins_encode %{
14002     __ cmnw($op1$$Register, $op2$$Register);
14003   %}
14004 
14005   ins_pipe(icmp_reg_reg);
14006 %}
14007 
14008 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14009 %{
14010   match(Set cr (OverflowAddI op1 op2));
14011 
14012   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
14013   ins_cost(INSN_COST);
14014   ins_encode %{
14015     __ cmnw($op1$$Register, $op2$$constant);
14016   %}
14017 
14018   ins_pipe(icmp_reg_imm);
14019 %}
14020 
14021 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14022 %{
14023   match(Set cr (OverflowAddL op1 op2));
14024 
14025   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14026   ins_cost(INSN_COST);
14027   ins_encode %{
14028     __ cmn($op1$$Register, $op2$$Register);
14029   %}
14030 
14031   ins_pipe(icmp_reg_reg);
14032 %}
14033 
14034 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14035 %{
14036   match(Set cr (OverflowAddL op1 op2));
14037 
14038   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14039   ins_cost(INSN_COST);
14040   ins_encode %{
14041     __ cmn($op1$$Register, $op2$$constant);
14042   %}
14043 
14044   ins_pipe(icmp_reg_imm);
14045 %}
14046 
14047 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14048 %{
14049   match(Set cr (OverflowSubI op1 op2));
14050 
14051   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14052   ins_cost(INSN_COST);
14053   ins_encode %{
14054     __ cmpw($op1$$Register, $op2$$Register);
14055   %}
14056 
14057   ins_pipe(icmp_reg_reg);
14058 %}
14059 
14060 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14061 %{
14062   match(Set cr (OverflowSubI op1 op2));
14063 
14064   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14065   ins_cost(INSN_COST);
14066   ins_encode %{
14067     __ cmpw($op1$$Register, $op2$$constant);
14068   %}
14069 
14070   ins_pipe(icmp_reg_imm);
14071 %}
14072 
14073 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14074 %{
14075   match(Set cr (OverflowSubL op1 op2));
14076 
14077   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14078   ins_cost(INSN_COST);
14079   ins_encode %{
14080     __ cmp($op1$$Register, $op2$$Register);
14081   %}
14082 
14083   ins_pipe(icmp_reg_reg);
14084 %}
14085 
14086 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14087 %{
14088   match(Set cr (OverflowSubL op1 op2));
14089 
14090   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14091   ins_cost(INSN_COST);
14092   ins_encode %{
14093     __ subs(zr, $op1$$Register, $op2$$constant);
14094   %}
14095 
14096   ins_pipe(icmp_reg_imm);
14097 %}
14098 
14099 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14100 %{
14101   match(Set cr (OverflowSubI zero op1));
14102 
14103   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14104   ins_cost(INSN_COST);
14105   ins_encode %{
14106     __ cmpw(zr, $op1$$Register);
14107   %}
14108 
14109   ins_pipe(icmp_reg_imm);
14110 %}
14111 
14112 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14113 %{
14114   match(Set cr (OverflowSubL zero op1));
14115 
14116   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14117   ins_cost(INSN_COST);
14118   ins_encode %{
14119     __ cmp(zr, $op1$$Register);
14120   %}
14121 
14122   ins_pipe(icmp_reg_imm);
14123 %}
14124 
14125 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14126 %{
14127   match(Set cr (OverflowMulI op1 op2));
14128 
14129   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14130             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14131             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14132             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14133             &quot;cmpw  rscratch1, #1&quot; %}
14134   ins_cost(5 * INSN_COST);
14135   ins_encode %{
14136     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14137     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14138     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14139     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14140     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14141   %}
14142 
14143   ins_pipe(pipe_slow);
14144 %}
14145 
14146 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14147 %{
14148   match(If cmp (OverflowMulI op1 op2));
14149   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14150             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14151   effect(USE labl, KILL cr);
14152 
14153   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14154             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14155             &quot;b$cmp   $labl&quot; %}
14156   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14157   ins_encode %{
14158     Label* L = $labl$$label;
14159     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14160     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14161     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14162     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14163   %}
14164 
14165   ins_pipe(pipe_serial);
14166 %}
14167 
14168 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14169 %{
14170   match(Set cr (OverflowMulL op1 op2));
14171 
14172   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14173             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14174             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14175             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14176             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14177             &quot;cmpw  rscratch1, #1&quot; %}
14178   ins_cost(6 * INSN_COST);
14179   ins_encode %{
14180     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14181     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14182     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14183     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14184     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14185     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14186   %}
14187 
14188   ins_pipe(pipe_slow);
14189 %}
14190 
14191 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14192 %{
14193   match(If cmp (OverflowMulL op1 op2));
14194   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14195             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14196   effect(USE labl, KILL cr);
14197 
14198   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14199             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14200             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14201             &quot;b$cmp $labl&quot; %}
14202   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14203   ins_encode %{
14204     Label* L = $labl$$label;
14205     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14206     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14207     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14208     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14209     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14210   %}
14211 
14212   ins_pipe(pipe_serial);
14213 %}
14214 
14215 // ============================================================================
14216 // Compare Instructions
14217 
14218 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14219 %{
14220   match(Set cr (CmpI op1 op2));
14221 
14222   effect(DEF cr, USE op1, USE op2);
14223 
14224   ins_cost(INSN_COST);
14225   format %{ &quot;cmpw  $op1, $op2&quot; %}
14226 
14227   ins_encode(aarch64_enc_cmpw(op1, op2));
14228 
14229   ins_pipe(icmp_reg_reg);
14230 %}
14231 
14232 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14233 %{
14234   match(Set cr (CmpI op1 zero));
14235 
14236   effect(DEF cr, USE op1);
14237 
14238   ins_cost(INSN_COST);
14239   format %{ &quot;cmpw $op1, 0&quot; %}
14240 
14241   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14242 
14243   ins_pipe(icmp_reg_imm);
14244 %}
14245 
14246 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14247 %{
14248   match(Set cr (CmpI op1 op2));
14249 
14250   effect(DEF cr, USE op1);
14251 
14252   ins_cost(INSN_COST);
14253   format %{ &quot;cmpw  $op1, $op2&quot; %}
14254 
14255   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14256 
14257   ins_pipe(icmp_reg_imm);
14258 %}
14259 
14260 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14261 %{
14262   match(Set cr (CmpI op1 op2));
14263 
14264   effect(DEF cr, USE op1);
14265 
14266   ins_cost(INSN_COST * 2);
14267   format %{ &quot;cmpw  $op1, $op2&quot; %}
14268 
14269   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14270 
14271   ins_pipe(icmp_reg_imm);
14272 %}
14273 
14274 // Unsigned compare Instructions; really, same as signed compare
14275 // except it should only be used to feed an If or a CMovI which takes a
14276 // cmpOpU.
14277 
14278 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14279 %{
14280   match(Set cr (CmpU op1 op2));
14281 
14282   effect(DEF cr, USE op1, USE op2);
14283 
14284   ins_cost(INSN_COST);
14285   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14286 
14287   ins_encode(aarch64_enc_cmpw(op1, op2));
14288 
14289   ins_pipe(icmp_reg_reg);
14290 %}
14291 
14292 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14293 %{
14294   match(Set cr (CmpU op1 zero));
14295 
14296   effect(DEF cr, USE op1);
14297 
14298   ins_cost(INSN_COST);
14299   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14300 
14301   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14302 
14303   ins_pipe(icmp_reg_imm);
14304 %}
14305 
14306 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14307 %{
14308   match(Set cr (CmpU op1 op2));
14309 
14310   effect(DEF cr, USE op1);
14311 
14312   ins_cost(INSN_COST);
14313   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14314 
14315   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14316 
14317   ins_pipe(icmp_reg_imm);
14318 %}
14319 
14320 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14321 %{
14322   match(Set cr (CmpU op1 op2));
14323 
14324   effect(DEF cr, USE op1);
14325 
14326   ins_cost(INSN_COST * 2);
14327   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14328 
14329   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14330 
14331   ins_pipe(icmp_reg_imm);
14332 %}
14333 
14334 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14335 %{
14336   match(Set cr (CmpL op1 op2));
14337 
14338   effect(DEF cr, USE op1, USE op2);
14339 
14340   ins_cost(INSN_COST);
14341   format %{ &quot;cmp  $op1, $op2&quot; %}
14342 
14343   ins_encode(aarch64_enc_cmp(op1, op2));
14344 
14345   ins_pipe(icmp_reg_reg);
14346 %}
14347 
14348 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14349 %{
14350   match(Set cr (CmpL op1 zero));
14351 
14352   effect(DEF cr, USE op1);
14353 
14354   ins_cost(INSN_COST);
14355   format %{ &quot;tst  $op1&quot; %}
14356 
14357   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14358 
14359   ins_pipe(icmp_reg_imm);
14360 %}
14361 
14362 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14363 %{
14364   match(Set cr (CmpL op1 op2));
14365 
14366   effect(DEF cr, USE op1);
14367 
14368   ins_cost(INSN_COST);
14369   format %{ &quot;cmp  $op1, $op2&quot; %}
14370 
14371   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14372 
14373   ins_pipe(icmp_reg_imm);
14374 %}
14375 
14376 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14377 %{
14378   match(Set cr (CmpL op1 op2));
14379 
14380   effect(DEF cr, USE op1);
14381 
14382   ins_cost(INSN_COST * 2);
14383   format %{ &quot;cmp  $op1, $op2&quot; %}
14384 
14385   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14386 
14387   ins_pipe(icmp_reg_imm);
14388 %}
14389 
14390 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14391 %{
14392   match(Set cr (CmpUL op1 op2));
14393 
14394   effect(DEF cr, USE op1, USE op2);
14395 
14396   ins_cost(INSN_COST);
14397   format %{ &quot;cmp  $op1, $op2&quot; %}
14398 
14399   ins_encode(aarch64_enc_cmp(op1, op2));
14400 
14401   ins_pipe(icmp_reg_reg);
14402 %}
14403 
14404 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14405 %{
14406   match(Set cr (CmpUL op1 zero));
14407 
14408   effect(DEF cr, USE op1);
14409 
14410   ins_cost(INSN_COST);
14411   format %{ &quot;tst  $op1&quot; %}
14412 
14413   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14414 
14415   ins_pipe(icmp_reg_imm);
14416 %}
14417 
14418 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14419 %{
14420   match(Set cr (CmpUL op1 op2));
14421 
14422   effect(DEF cr, USE op1);
14423 
14424   ins_cost(INSN_COST);
14425   format %{ &quot;cmp  $op1, $op2&quot; %}
14426 
14427   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14428 
14429   ins_pipe(icmp_reg_imm);
14430 %}
14431 
14432 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14433 %{
14434   match(Set cr (CmpUL op1 op2));
14435 
14436   effect(DEF cr, USE op1);
14437 
14438   ins_cost(INSN_COST * 2);
14439   format %{ &quot;cmp  $op1, $op2&quot; %}
14440 
14441   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14442 
14443   ins_pipe(icmp_reg_imm);
14444 %}
14445 
14446 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14447 %{
14448   match(Set cr (CmpP op1 op2));
14449 
14450   effect(DEF cr, USE op1, USE op2);
14451 
14452   ins_cost(INSN_COST);
14453   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14454 
14455   ins_encode(aarch64_enc_cmpp(op1, op2));
14456 
14457   ins_pipe(icmp_reg_reg);
14458 %}
14459 
14460 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14461 %{
14462   match(Set cr (CmpN op1 op2));
14463 
14464   effect(DEF cr, USE op1, USE op2);
14465 
14466   ins_cost(INSN_COST);
14467   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14468 
14469   ins_encode(aarch64_enc_cmpn(op1, op2));
14470 
14471   ins_pipe(icmp_reg_reg);
14472 %}
14473 
14474 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14475 %{
14476   match(Set cr (CmpP op1 zero));
14477 
14478   effect(DEF cr, USE op1, USE zero);
14479 
14480   ins_cost(INSN_COST);
14481   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14482 
14483   ins_encode(aarch64_enc_testp(op1));
14484 
14485   ins_pipe(icmp_reg_imm);
14486 %}
14487 
14488 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14489 %{
14490   match(Set cr (CmpN op1 zero));
14491 
14492   effect(DEF cr, USE op1, USE zero);
14493 
14494   ins_cost(INSN_COST);
14495   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14496 
14497   ins_encode(aarch64_enc_testn(op1));
14498 
14499   ins_pipe(icmp_reg_imm);
14500 %}
14501 
14502 // FP comparisons
14503 //
14504 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14505 // using normal cmpOp. See declaration of rFlagsReg for details.
14506 
14507 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14508 %{
14509   match(Set cr (CmpF src1 src2));
14510 
14511   ins_cost(3 * INSN_COST);
14512   format %{ &quot;fcmps $src1, $src2&quot; %}
14513 
14514   ins_encode %{
14515     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14516   %}
14517 
14518   ins_pipe(pipe_class_compare);
14519 %}
14520 
14521 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14522 %{
14523   match(Set cr (CmpF src1 src2));
14524 
14525   ins_cost(3 * INSN_COST);
14526   format %{ &quot;fcmps $src1, 0.0&quot; %}
14527 
14528   ins_encode %{
14529     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14530   %}
14531 
14532   ins_pipe(pipe_class_compare);
14533 %}
14534 // FROM HERE
14535 
14536 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14537 %{
14538   match(Set cr (CmpD src1 src2));
14539 
14540   ins_cost(3 * INSN_COST);
14541   format %{ &quot;fcmpd $src1, $src2&quot; %}
14542 
14543   ins_encode %{
14544     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14545   %}
14546 
14547   ins_pipe(pipe_class_compare);
14548 %}
14549 
14550 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14551 %{
14552   match(Set cr (CmpD src1 src2));
14553 
14554   ins_cost(3 * INSN_COST);
14555   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14556 
14557   ins_encode %{
14558     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14559   %}
14560 
14561   ins_pipe(pipe_class_compare);
14562 %}
14563 
14564 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14565 %{
14566   match(Set dst (CmpF3 src1 src2));
14567   effect(KILL cr);
14568 
14569   ins_cost(5 * INSN_COST);
14570   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14571             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14572             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14573   %}
14574 
14575   ins_encode %{
14576     Label done;
14577     FloatRegister s1 = as_FloatRegister($src1$$reg);
14578     FloatRegister s2 = as_FloatRegister($src2$$reg);
14579     Register d = as_Register($dst$$reg);
14580     __ fcmps(s1, s2);
14581     // installs 0 if EQ else -1
14582     __ csinvw(d, zr, zr, Assembler::EQ);
14583     // keeps -1 if less or unordered else installs 1
14584     __ csnegw(d, d, d, Assembler::LT);
14585     __ bind(done);
14586   %}
14587 
14588   ins_pipe(pipe_class_default);
14589 
14590 %}
14591 
14592 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14593 %{
14594   match(Set dst (CmpD3 src1 src2));
14595   effect(KILL cr);
14596 
14597   ins_cost(5 * INSN_COST);
14598   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14599             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14600             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14601   %}
14602 
14603   ins_encode %{
14604     Label done;
14605     FloatRegister s1 = as_FloatRegister($src1$$reg);
14606     FloatRegister s2 = as_FloatRegister($src2$$reg);
14607     Register d = as_Register($dst$$reg);
14608     __ fcmpd(s1, s2);
14609     // installs 0 if EQ else -1
14610     __ csinvw(d, zr, zr, Assembler::EQ);
14611     // keeps -1 if less or unordered else installs 1
14612     __ csnegw(d, d, d, Assembler::LT);
14613     __ bind(done);
14614   %}
14615   ins_pipe(pipe_class_default);
14616 
14617 %}
14618 
14619 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14620 %{
14621   match(Set dst (CmpF3 src1 zero));
14622   effect(KILL cr);
14623 
14624   ins_cost(5 * INSN_COST);
14625   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14626             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14627             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14628   %}
14629 
14630   ins_encode %{
14631     Label done;
14632     FloatRegister s1 = as_FloatRegister($src1$$reg);
14633     Register d = as_Register($dst$$reg);
14634     __ fcmps(s1, 0.0);
14635     // installs 0 if EQ else -1
14636     __ csinvw(d, zr, zr, Assembler::EQ);
14637     // keeps -1 if less or unordered else installs 1
14638     __ csnegw(d, d, d, Assembler::LT);
14639     __ bind(done);
14640   %}
14641 
14642   ins_pipe(pipe_class_default);
14643 
14644 %}
14645 
14646 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14647 %{
14648   match(Set dst (CmpD3 src1 zero));
14649   effect(KILL cr);
14650 
14651   ins_cost(5 * INSN_COST);
14652   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14653             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14654             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14655   %}
14656 
14657   ins_encode %{
14658     Label done;
14659     FloatRegister s1 = as_FloatRegister($src1$$reg);
14660     Register d = as_Register($dst$$reg);
14661     __ fcmpd(s1, 0.0);
14662     // installs 0 if EQ else -1
14663     __ csinvw(d, zr, zr, Assembler::EQ);
14664     // keeps -1 if less or unordered else installs 1
14665     __ csnegw(d, d, d, Assembler::LT);
14666     __ bind(done);
14667   %}
14668   ins_pipe(pipe_class_default);
14669 
14670 %}
14671 
14672 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14673 %{
14674   match(Set dst (CmpLTMask p q));
14675   effect(KILL cr);
14676 
14677   ins_cost(3 * INSN_COST);
14678 
14679   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14680             &quot;csetw $dst, lt\n\t&quot;
14681             &quot;subw $dst, zr, $dst&quot;
14682   %}
14683 
14684   ins_encode %{
14685     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14686     __ csetw(as_Register($dst$$reg), Assembler::LT);
14687     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14688   %}
14689 
14690   ins_pipe(ialu_reg_reg);
14691 %}
14692 
14693 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14694 %{
14695   match(Set dst (CmpLTMask src zero));
14696   effect(KILL cr);
14697 
14698   ins_cost(INSN_COST);
14699 
14700   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14701 
14702   ins_encode %{
14703     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14704   %}
14705 
14706   ins_pipe(ialu_reg_shift);
14707 %}
14708 
14709 // ============================================================================
14710 // Max and Min
14711 
14712 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14713 %{
14714   effect( DEF dst, USE src1, USE src2, USE cr );
14715 
14716   ins_cost(INSN_COST * 2);
14717   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14718 
14719   ins_encode %{
14720     __ cselw(as_Register($dst$$reg),
14721              as_Register($src1$$reg),
14722              as_Register($src2$$reg),
14723              Assembler::LT);
14724   %}
14725 
14726   ins_pipe(icond_reg_reg);
14727 %}
14728 
14729 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14730 %{
14731   match(Set dst (MinI src1 src2));
14732   ins_cost(INSN_COST * 3);
14733 
14734   expand %{
14735     rFlagsReg cr;
14736     compI_reg_reg(cr, src1, src2);
14737     cmovI_reg_reg_lt(dst, src1, src2, cr);
14738   %}
14739 
14740 %}
14741 // FROM HERE
14742 
14743 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14744 %{
14745   effect( DEF dst, USE src1, USE src2, USE cr );
14746 
14747   ins_cost(INSN_COST * 2);
14748   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14749 
14750   ins_encode %{
14751     __ cselw(as_Register($dst$$reg),
14752              as_Register($src1$$reg),
14753              as_Register($src2$$reg),
14754              Assembler::GT);
14755   %}
14756 
14757   ins_pipe(icond_reg_reg);
14758 %}
14759 
14760 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14761 %{
14762   match(Set dst (MaxI src1 src2));
14763   ins_cost(INSN_COST * 3);
14764   expand %{
14765     rFlagsReg cr;
14766     compI_reg_reg(cr, src1, src2);
14767     cmovI_reg_reg_gt(dst, src1, src2, cr);
14768   %}
14769 %}
14770 
14771 // ============================================================================
14772 // Branch Instructions
14773 
14774 // Direct Branch.
14775 instruct branch(label lbl)
14776 %{
14777   match(Goto);
14778 
14779   effect(USE lbl);
14780 
14781   ins_cost(BRANCH_COST);
14782   format %{ &quot;b  $lbl&quot; %}
14783 
14784   ins_encode(aarch64_enc_b(lbl));
14785 
14786   ins_pipe(pipe_branch);
14787 %}
14788 
14789 // Conditional Near Branch
14790 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14791 %{
14792   // Same match rule as `branchConFar&#39;.
14793   match(If cmp cr);
14794 
14795   effect(USE lbl);
14796 
14797   ins_cost(BRANCH_COST);
14798   // If set to 1 this indicates that the current instruction is a
14799   // short variant of a long branch. This avoids using this
14800   // instruction in first-pass matching. It will then only be used in
14801   // the `Shorten_branches&#39; pass.
14802   // ins_short_branch(1);
14803   format %{ &quot;b$cmp  $lbl&quot; %}
14804 
14805   ins_encode(aarch64_enc_br_con(cmp, lbl));
14806 
14807   ins_pipe(pipe_branch_cond);
14808 %}
14809 
14810 // Conditional Near Branch Unsigned
14811 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14812 %{
14813   // Same match rule as `branchConFar&#39;.
14814   match(If cmp cr);
14815 
14816   effect(USE lbl);
14817 
14818   ins_cost(BRANCH_COST);
14819   // If set to 1 this indicates that the current instruction is a
14820   // short variant of a long branch. This avoids using this
14821   // instruction in first-pass matching. It will then only be used in
14822   // the `Shorten_branches&#39; pass.
14823   // ins_short_branch(1);
14824   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14825 
14826   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14827 
14828   ins_pipe(pipe_branch_cond);
14829 %}
14830 
14831 // Make use of CBZ and CBNZ.  These instructions, as well as being
14832 // shorter than (cmp; branch), have the additional benefit of not
14833 // killing the flags.
14834 
14835 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14836   match(If cmp (CmpI op1 op2));
14837   effect(USE labl);
14838 
14839   ins_cost(BRANCH_COST);
14840   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14841   ins_encode %{
14842     Label* L = $labl$$label;
14843     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14844     if (cond == Assembler::EQ)
14845       __ cbzw($op1$$Register, *L);
14846     else
14847       __ cbnzw($op1$$Register, *L);
14848   %}
14849   ins_pipe(pipe_cmp_branch);
14850 %}
14851 
14852 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14853   match(If cmp (CmpL op1 op2));
14854   effect(USE labl);
14855 
14856   ins_cost(BRANCH_COST);
14857   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14858   ins_encode %{
14859     Label* L = $labl$$label;
14860     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14861     if (cond == Assembler::EQ)
14862       __ cbz($op1$$Register, *L);
14863     else
14864       __ cbnz($op1$$Register, *L);
14865   %}
14866   ins_pipe(pipe_cmp_branch);
14867 %}
14868 
14869 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14870   match(If cmp (CmpP op1 op2));
14871   effect(USE labl);
14872 
14873   ins_cost(BRANCH_COST);
14874   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14875   ins_encode %{
14876     Label* L = $labl$$label;
14877     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14878     if (cond == Assembler::EQ)
14879       __ cbz($op1$$Register, *L);
14880     else
14881       __ cbnz($op1$$Register, *L);
14882   %}
14883   ins_pipe(pipe_cmp_branch);
14884 %}
14885 
14886 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14887   match(If cmp (CmpN op1 op2));
14888   effect(USE labl);
14889 
14890   ins_cost(BRANCH_COST);
14891   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14892   ins_encode %{
14893     Label* L = $labl$$label;
14894     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14895     if (cond == Assembler::EQ)
14896       __ cbzw($op1$$Register, *L);
14897     else
14898       __ cbnzw($op1$$Register, *L);
14899   %}
14900   ins_pipe(pipe_cmp_branch);
14901 %}
14902 
14903 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14904   match(If cmp (CmpP (DecodeN oop) zero));
14905   effect(USE labl);
14906 
14907   ins_cost(BRANCH_COST);
14908   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14909   ins_encode %{
14910     Label* L = $labl$$label;
14911     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14912     if (cond == Assembler::EQ)
14913       __ cbzw($oop$$Register, *L);
14914     else
14915       __ cbnzw($oop$$Register, *L);
14916   %}
14917   ins_pipe(pipe_cmp_branch);
14918 %}
14919 
14920 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14921   match(If cmp (CmpU op1 op2));
14922   effect(USE labl);
14923 
14924   ins_cost(BRANCH_COST);
14925   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14926   ins_encode %{
14927     Label* L = $labl$$label;
14928     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14929     if (cond == Assembler::EQ || cond == Assembler::LS)
14930       __ cbzw($op1$$Register, *L);
14931     else
14932       __ cbnzw($op1$$Register, *L);
14933   %}
14934   ins_pipe(pipe_cmp_branch);
14935 %}
14936 
14937 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14938   match(If cmp (CmpUL op1 op2));
14939   effect(USE labl);
14940 
14941   ins_cost(BRANCH_COST);
14942   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14943   ins_encode %{
14944     Label* L = $labl$$label;
14945     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14946     if (cond == Assembler::EQ || cond == Assembler::LS)
14947       __ cbz($op1$$Register, *L);
14948     else
14949       __ cbnz($op1$$Register, *L);
14950   %}
14951   ins_pipe(pipe_cmp_branch);
14952 %}
14953 
14954 // Test bit and Branch
14955 
14956 // Patterns for short (&lt; 32KiB) variants
14957 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14958   match(If cmp (CmpL op1 op2));
14959   effect(USE labl);
14960 
14961   ins_cost(BRANCH_COST);
14962   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14963   ins_encode %{
14964     Label* L = $labl$$label;
14965     Assembler::Condition cond =
14966       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14967     __ tbr(cond, $op1$$Register, 63, *L);
14968   %}
14969   ins_pipe(pipe_cmp_branch);
14970   ins_short_branch(1);
14971 %}
14972 
14973 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14974   match(If cmp (CmpI op1 op2));
14975   effect(USE labl);
14976 
14977   ins_cost(BRANCH_COST);
14978   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14979   ins_encode %{
14980     Label* L = $labl$$label;
14981     Assembler::Condition cond =
14982       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14983     __ tbr(cond, $op1$$Register, 31, *L);
14984   %}
14985   ins_pipe(pipe_cmp_branch);
14986   ins_short_branch(1);
14987 %}
14988 
14989 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14990   match(If cmp (CmpL (AndL op1 op2) op3));
14991   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14992   effect(USE labl);
14993 
14994   ins_cost(BRANCH_COST);
14995   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14996   ins_encode %{
14997     Label* L = $labl$$label;
14998     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14999     int bit = exact_log2_long($op2$$constant);
15000     __ tbr(cond, $op1$$Register, bit, *L);
15001   %}
15002   ins_pipe(pipe_cmp_branch);
15003   ins_short_branch(1);
15004 %}
15005 
15006 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15007   match(If cmp (CmpI (AndI op1 op2) op3));
15008   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15009   effect(USE labl);
15010 
15011   ins_cost(BRANCH_COST);
15012   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15013   ins_encode %{
15014     Label* L = $labl$$label;
15015     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15016     int bit = exact_log2((juint)$op2$$constant);
15017     __ tbr(cond, $op1$$Register, bit, *L);
15018   %}
15019   ins_pipe(pipe_cmp_branch);
15020   ins_short_branch(1);
15021 %}
15022 
15023 // And far variants
15024 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15025   match(If cmp (CmpL op1 op2));
15026   effect(USE labl);
15027 
15028   ins_cost(BRANCH_COST);
15029   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15030   ins_encode %{
15031     Label* L = $labl$$label;
15032     Assembler::Condition cond =
15033       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15034     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15035   %}
15036   ins_pipe(pipe_cmp_branch);
15037 %}
15038 
15039 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15040   match(If cmp (CmpI op1 op2));
15041   effect(USE labl);
15042 
15043   ins_cost(BRANCH_COST);
15044   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15045   ins_encode %{
15046     Label* L = $labl$$label;
15047     Assembler::Condition cond =
15048       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15049     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15050   %}
15051   ins_pipe(pipe_cmp_branch);
15052 %}
15053 
15054 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15055   match(If cmp (CmpL (AndL op1 op2) op3));
15056   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15057   effect(USE labl);
15058 
15059   ins_cost(BRANCH_COST);
15060   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15061   ins_encode %{
15062     Label* L = $labl$$label;
15063     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15064     int bit = exact_log2_long($op2$$constant);
15065     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15066   %}
15067   ins_pipe(pipe_cmp_branch);
15068 %}
15069 
15070 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15071   match(If cmp (CmpI (AndI op1 op2) op3));
15072   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15073   effect(USE labl);
15074 
15075   ins_cost(BRANCH_COST);
15076   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15077   ins_encode %{
15078     Label* L = $labl$$label;
15079     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15080     int bit = exact_log2((juint)$op2$$constant);
15081     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15082   %}
15083   ins_pipe(pipe_cmp_branch);
15084 %}
15085 
15086 // Test bits
15087 
15088 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15089   match(Set cr (CmpL (AndL op1 op2) op3));
15090   predicate(Assembler::operand_valid_for_logical_immediate
15091             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15092 
15093   ins_cost(INSN_COST);
15094   format %{ &quot;tst $op1, $op2 # long&quot; %}
15095   ins_encode %{
15096     __ tst($op1$$Register, $op2$$constant);
15097   %}
15098   ins_pipe(ialu_reg_reg);
15099 %}
15100 
15101 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15102   match(Set cr (CmpI (AndI op1 op2) op3));
15103   predicate(Assembler::operand_valid_for_logical_immediate
15104             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15105 
15106   ins_cost(INSN_COST);
15107   format %{ &quot;tst $op1, $op2 # int&quot; %}
15108   ins_encode %{
15109     __ tstw($op1$$Register, $op2$$constant);
15110   %}
15111   ins_pipe(ialu_reg_reg);
15112 %}
15113 
15114 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15115   match(Set cr (CmpL (AndL op1 op2) op3));
15116 
15117   ins_cost(INSN_COST);
15118   format %{ &quot;tst $op1, $op2 # long&quot; %}
15119   ins_encode %{
15120     __ tst($op1$$Register, $op2$$Register);
15121   %}
15122   ins_pipe(ialu_reg_reg);
15123 %}
15124 
15125 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15126   match(Set cr (CmpI (AndI op1 op2) op3));
15127 
15128   ins_cost(INSN_COST);
15129   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15130   ins_encode %{
15131     __ tstw($op1$$Register, $op2$$Register);
15132   %}
15133   ins_pipe(ialu_reg_reg);
15134 %}
15135 
15136 
15137 // Conditional Far Branch
15138 // Conditional Far Branch Unsigned
15139 // TODO: fixme
15140 
15141 // counted loop end branch near
15142 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15143 %{
15144   match(CountedLoopEnd cmp cr);
15145 
15146   effect(USE lbl);
15147 
15148   ins_cost(BRANCH_COST);
15149   // short variant.
15150   // ins_short_branch(1);
15151   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15152 
15153   ins_encode(aarch64_enc_br_con(cmp, lbl));
15154 
15155   ins_pipe(pipe_branch);
15156 %}
15157 
15158 // counted loop end branch near Unsigned
15159 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15160 %{
15161   match(CountedLoopEnd cmp cr);
15162 
15163   effect(USE lbl);
15164 
15165   ins_cost(BRANCH_COST);
15166   // short variant.
15167   // ins_short_branch(1);
15168   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15169 
15170   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15171 
15172   ins_pipe(pipe_branch);
15173 %}
15174 
15175 // counted loop end branch far
15176 // counted loop end branch far unsigned
15177 // TODO: fixme
15178 
15179 // ============================================================================
15180 // inlined locking and unlocking
15181 
15182 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15183 %{
15184   match(Set cr (FastLock object box));
15185   effect(TEMP tmp, TEMP tmp2);
15186 
15187   // TODO
15188   // identify correct cost
15189   ins_cost(5 * INSN_COST);
15190   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15191 
15192   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15193 
15194   ins_pipe(pipe_serial);
15195 %}
15196 
15197 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15198 %{
15199   match(Set cr (FastUnlock object box));
15200   effect(TEMP tmp, TEMP tmp2);
15201 
15202   ins_cost(5 * INSN_COST);
15203   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15204 
15205   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15206 
15207   ins_pipe(pipe_serial);
15208 %}
15209 
15210 
15211 // ============================================================================
15212 // Safepoint Instructions
15213 
15214 // TODO
15215 // provide a near and far version of this code
15216 
15217 instruct safePoint(rFlagsReg cr, iRegP poll)
15218 %{
15219   match(SafePoint poll);
15220   effect(KILL cr);
15221 
15222   format %{
15223     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15224   %}
15225   ins_encode %{
15226     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15227   %}
15228   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15229 %}
15230 
15231 
15232 // ============================================================================
15233 // Procedure Call/Return Instructions
15234 
15235 // Call Java Static Instruction
15236 
15237 instruct CallStaticJavaDirect(method meth)
15238 %{
15239   match(CallStaticJava);
15240 
15241   effect(USE meth);
15242 
15243   ins_cost(CALL_COST);
15244 
15245   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15246 
15247   ins_encode( aarch64_enc_java_static_call(meth),
15248               aarch64_enc_call_epilog );
15249 
15250   ins_pipe(pipe_class_call);
15251 %}
15252 
15253 // TO HERE
15254 
15255 // Call Java Dynamic Instruction
15256 instruct CallDynamicJavaDirect(method meth)
15257 %{
15258   match(CallDynamicJava);
15259 
15260   effect(USE meth);
15261 
15262   ins_cost(CALL_COST);
15263 
15264   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15265 
15266   ins_encode( aarch64_enc_java_dynamic_call(meth),
15267                aarch64_enc_call_epilog );
15268 
15269   ins_pipe(pipe_class_call);
15270 %}
15271 
15272 // Call Runtime Instruction
15273 
15274 instruct CallRuntimeDirect(method meth)
15275 %{
15276   match(CallRuntime);
15277 
15278   effect(USE meth);
15279 
15280   ins_cost(CALL_COST);
15281 
15282   format %{ &quot;CALL, runtime $meth&quot; %}
15283 
15284   ins_encode( aarch64_enc_java_to_runtime(meth) );
15285 
15286   ins_pipe(pipe_class_call);
15287 %}
15288 
15289 // Call Runtime Instruction
15290 
15291 instruct CallLeafDirect(method meth)
15292 %{
15293   match(CallLeaf);
15294 
15295   effect(USE meth);
15296 
15297   ins_cost(CALL_COST);
15298 
15299   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15300 
15301   ins_encode( aarch64_enc_java_to_runtime(meth) );
15302 
15303   ins_pipe(pipe_class_call);
15304 %}
15305 
15306 // Call Runtime Instruction
15307 
15308 instruct CallLeafNoFPDirect(method meth)
15309 %{
15310   match(CallLeafNoFP);
15311 
15312   effect(USE meth);
15313 
15314   ins_cost(CALL_COST);
15315 
15316   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15317 
15318   ins_encode( aarch64_enc_java_to_runtime(meth) );
15319 
15320   ins_pipe(pipe_class_call);
15321 %}
15322 
15323 // Tail Call; Jump from runtime stub to Java code.
15324 // Also known as an &#39;interprocedural jump&#39;.
15325 // Target of jump will eventually return to caller.
15326 // TailJump below removes the return address.
15327 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15328 %{
15329   match(TailCall jump_target method_oop);
15330 
15331   ins_cost(CALL_COST);
15332 
15333   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15334 
15335   ins_encode(aarch64_enc_tail_call(jump_target));
15336 
15337   ins_pipe(pipe_class_call);
15338 %}
15339 
15340 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15341 %{
15342   match(TailJump jump_target ex_oop);
15343 
15344   ins_cost(CALL_COST);
15345 
15346   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15347 
15348   ins_encode(aarch64_enc_tail_jmp(jump_target));
15349 
15350   ins_pipe(pipe_class_call);
15351 %}
15352 
15353 // Create exception oop: created by stack-crawling runtime code.
15354 // Created exception is now available to this handler, and is setup
15355 // just prior to jumping to this handler. No code emitted.
15356 // TODO check
15357 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15358 instruct CreateException(iRegP_R0 ex_oop)
15359 %{
15360   match(Set ex_oop (CreateEx));
15361 
15362   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15363 
15364   size(0);
15365 
15366   ins_encode( /*empty*/ );
15367 
15368   ins_pipe(pipe_class_empty);
15369 %}
15370 
15371 // Rethrow exception: The exception oop will come in the first
15372 // argument position. Then JUMP (not call) to the rethrow stub code.
15373 instruct RethrowException() %{
15374   match(Rethrow);
15375   ins_cost(CALL_COST);
15376 
15377   format %{ &quot;b rethrow_stub&quot; %}
15378 
15379   ins_encode( aarch64_enc_rethrow() );
15380 
15381   ins_pipe(pipe_class_call);
15382 %}
15383 
15384 
15385 // Return Instruction
15386 // epilog node loads ret address into lr as part of frame pop
15387 instruct Ret()
15388 %{
15389   match(Return);
15390 
15391   format %{ &quot;ret\t// return register&quot; %}
15392 
15393   ins_encode( aarch64_enc_ret() );
15394 
15395   ins_pipe(pipe_branch);
15396 %}
15397 
15398 // Die now.
15399 instruct ShouldNotReachHere() %{
15400   match(Halt);
15401 
15402   ins_cost(CALL_COST);
15403   format %{ &quot;ShouldNotReachHere&quot; %}
15404 
15405   ins_encode %{
15406     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15407     // return true
15408     __ dpcs1(0xdead + 1);
15409   %}
15410 
15411   ins_pipe(pipe_class_default);
15412 %}
15413 
15414 // ============================================================================
15415 // Partial Subtype Check
15416 //
15417 // superklass array for an instance of the superklass.  Set a hidden
15418 // internal cache on a hit (cache is checked with exposed code in
15419 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15420 // encoding ALSO sets flags.
15421 
15422 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15423 %{
15424   match(Set result (PartialSubtypeCheck sub super));
15425   effect(KILL cr, KILL temp);
15426 
15427   ins_cost(1100);  // slightly larger than the next version
15428   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15429 
15430   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15431 
15432   opcode(0x1); // Force zero of result reg on hit
15433 
15434   ins_pipe(pipe_class_memory);
15435 %}
15436 
15437 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15438 %{
15439   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15440   effect(KILL temp, KILL result);
15441 
15442   ins_cost(1100);  // slightly larger than the next version
15443   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15444 
15445   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15446 
15447   opcode(0x0); // Don&#39;t zero result reg on hit
15448 
15449   ins_pipe(pipe_class_memory);
15450 %}
15451 
15452 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15453                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15454 %{
15455   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15456   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15457   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15458 
15459   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15460   ins_encode %{
15461     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15462     __ string_compare($str1$$Register, $str2$$Register,
15463                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15464                       $tmp1$$Register, $tmp2$$Register,
15465                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15466   %}
15467   ins_pipe(pipe_class_memory);
15468 %}
15469 
15470 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15471                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15472 %{
15473   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15474   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15475   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15476 
15477   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15478   ins_encode %{
15479     __ string_compare($str1$$Register, $str2$$Register,
15480                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15481                       $tmp1$$Register, $tmp2$$Register,
15482                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15483   %}
15484   ins_pipe(pipe_class_memory);
15485 %}
15486 
15487 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15488                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15489                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15490 %{
15491   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15492   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15493   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15494          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15495 
15496   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15497   ins_encode %{
15498     __ string_compare($str1$$Register, $str2$$Register,
15499                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15500                       $tmp1$$Register, $tmp2$$Register,
15501                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15502                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15503   %}
15504   ins_pipe(pipe_class_memory);
15505 %}
15506 
15507 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15508                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15509                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15510 %{
15511   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15512   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15513   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15514          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15515 
15516   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15517   ins_encode %{
15518     __ string_compare($str1$$Register, $str2$$Register,
15519                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15520                       $tmp1$$Register, $tmp2$$Register,
15521                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15522                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15523   %}
15524   ins_pipe(pipe_class_memory);
15525 %}
15526 
15527 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15528        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15529        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15530 %{
15531   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15532   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15533   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15534          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15535   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15536 
15537   ins_encode %{
15538     __ string_indexof($str1$$Register, $str2$$Register,
15539                       $cnt1$$Register, $cnt2$$Register,
15540                       $tmp1$$Register, $tmp2$$Register,
15541                       $tmp3$$Register, $tmp4$$Register,
15542                       $tmp5$$Register, $tmp6$$Register,
15543                       -1, $result$$Register, StrIntrinsicNode::UU);
15544   %}
15545   ins_pipe(pipe_class_memory);
15546 %}
15547 
15548 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15549        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15550        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15551 %{
15552   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15553   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15554   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15555          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15556   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15557 
15558   ins_encode %{
15559     __ string_indexof($str1$$Register, $str2$$Register,
15560                       $cnt1$$Register, $cnt2$$Register,
15561                       $tmp1$$Register, $tmp2$$Register,
15562                       $tmp3$$Register, $tmp4$$Register,
15563                       $tmp5$$Register, $tmp6$$Register,
15564                       -1, $result$$Register, StrIntrinsicNode::LL);
15565   %}
15566   ins_pipe(pipe_class_memory);
15567 %}
15568 
15569 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15570        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15571        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15572 %{
15573   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15574   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15575   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15576          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15577   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15578 
15579   ins_encode %{
15580     __ string_indexof($str1$$Register, $str2$$Register,
15581                       $cnt1$$Register, $cnt2$$Register,
15582                       $tmp1$$Register, $tmp2$$Register,
15583                       $tmp3$$Register, $tmp4$$Register,
15584                       $tmp5$$Register, $tmp6$$Register,
15585                       -1, $result$$Register, StrIntrinsicNode::UL);
15586   %}
15587   ins_pipe(pipe_class_memory);
15588 %}
15589 
15590 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15591                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15592                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15593 %{
15594   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15595   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15596   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15597          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15598   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15599 
15600   ins_encode %{
15601     int icnt2 = (int)$int_cnt2$$constant;
15602     __ string_indexof($str1$$Register, $str2$$Register,
15603                       $cnt1$$Register, zr,
15604                       $tmp1$$Register, $tmp2$$Register,
15605                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15606                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15607   %}
15608   ins_pipe(pipe_class_memory);
15609 %}
15610 
15611 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15612                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15613                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15614 %{
15615   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15616   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15617   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15618          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15619   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15620 
15621   ins_encode %{
15622     int icnt2 = (int)$int_cnt2$$constant;
15623     __ string_indexof($str1$$Register, $str2$$Register,
15624                       $cnt1$$Register, zr,
15625                       $tmp1$$Register, $tmp2$$Register,
15626                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15627                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15628   %}
15629   ins_pipe(pipe_class_memory);
15630 %}
15631 
15632 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15633                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15634                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15635 %{
15636   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15637   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15638   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15639          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15640   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15641 
15642   ins_encode %{
15643     int icnt2 = (int)$int_cnt2$$constant;
15644     __ string_indexof($str1$$Register, $str2$$Register,
15645                       $cnt1$$Register, zr,
15646                       $tmp1$$Register, $tmp2$$Register,
15647                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15648                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15649   %}
15650   ins_pipe(pipe_class_memory);
15651 %}
15652 
15653 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15654                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15655                               iRegINoSp tmp3, rFlagsReg cr)
15656 %{
15657   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15658   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15659          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15660 
15661   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15662 
15663   ins_encode %{
15664     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15665                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15666                            $tmp3$$Register);
15667   %}
15668   ins_pipe(pipe_class_memory);
15669 %}
15670 
15671 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15672                         iRegI_R0 result, rFlagsReg cr)
15673 %{
15674   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15675   match(Set result (StrEquals (Binary str1 str2) cnt));
15676   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15677 
15678   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15679   ins_encode %{
15680     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15681     __ string_equals($str1$$Register, $str2$$Register,
15682                      $result$$Register, $cnt$$Register, 1);
15683   %}
15684   ins_pipe(pipe_class_memory);
15685 %}
15686 
15687 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15688                         iRegI_R0 result, rFlagsReg cr)
15689 %{
15690   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15691   match(Set result (StrEquals (Binary str1 str2) cnt));
15692   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15693 
15694   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15695   ins_encode %{
15696     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15697     __ string_equals($str1$$Register, $str2$$Register,
15698                      $result$$Register, $cnt$$Register, 2);
15699   %}
15700   ins_pipe(pipe_class_memory);
15701 %}
15702 
15703 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15704                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15705                        iRegP_R10 tmp, rFlagsReg cr)
15706 %{
15707   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15708   match(Set result (AryEq ary1 ary2));
15709   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15710 
15711   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15712   ins_encode %{
15713     __ arrays_equals($ary1$$Register, $ary2$$Register,
15714                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15715                      $result$$Register, $tmp$$Register, 1);
15716     %}
15717   ins_pipe(pipe_class_memory);
15718 %}
15719 
15720 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15721                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15722                        iRegP_R10 tmp, rFlagsReg cr)
15723 %{
15724   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15725   match(Set result (AryEq ary1 ary2));
15726   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15727 
15728   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15729   ins_encode %{
15730     __ arrays_equals($ary1$$Register, $ary2$$Register,
15731                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15732                      $result$$Register, $tmp$$Register, 2);
15733   %}
15734   ins_pipe(pipe_class_memory);
15735 %}
15736 
15737 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15738 %{
15739   match(Set result (HasNegatives ary1 len));
15740   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15741   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15742   ins_encode %{
15743     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15744   %}
15745   ins_pipe( pipe_slow );
15746 %}
15747 
15748 // fast char[] to byte[] compression
15749 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15750                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15751                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15752                          iRegI_R0 result, rFlagsReg cr)
15753 %{
15754   match(Set result (StrCompressedCopy src (Binary dst len)));
15755   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15756 
15757   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15758   ins_encode %{
15759     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15760                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15761                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15762                            $result$$Register);
15763   %}
15764   ins_pipe( pipe_slow );
15765 %}
15766 
15767 // fast byte[] to char[] inflation
15768 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15769                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15770 %{
15771   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15772   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15773 
15774   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15775   ins_encode %{
15776     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15777                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15778   %}
15779   ins_pipe(pipe_class_memory);
15780 %}
15781 
15782 // encode char[] to byte[] in ISO_8859_1
15783 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15784                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15785                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15786                           iRegI_R0 result, rFlagsReg cr)
15787 %{
15788   match(Set result (EncodeISOArray src (Binary dst len)));
15789   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15790          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15791 
15792   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15793   ins_encode %{
15794     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15795          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15796          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15797   %}
15798   ins_pipe( pipe_class_memory );
15799 %}
15800 
15801 // ============================================================================
15802 // This name is KNOWN by the ADLC and cannot be changed.
15803 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15804 // for this guy.
15805 instruct tlsLoadP(thread_RegP dst)
15806 %{
15807   match(Set dst (ThreadLocal));
15808 
15809   ins_cost(0);
15810 
15811   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15812 
15813   size(0);
15814 
15815   ins_encode( /*empty*/ );
15816 
15817   ins_pipe(pipe_class_empty);
15818 %}
15819 
15820 // ====================VECTOR INSTRUCTIONS=====================================
15821 
15822 // Load vector (32 bits)
15823 instruct loadV4(vecD dst, vmem4 mem)
15824 %{
15825   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15826   match(Set dst (LoadVector mem));
15827   ins_cost(4 * INSN_COST);
15828   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15829   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15830   ins_pipe(vload_reg_mem64);
15831 %}
15832 
15833 // Load vector (64 bits)
15834 instruct loadV8(vecD dst, vmem8 mem)
15835 %{
15836   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15837   match(Set dst (LoadVector mem));
15838   ins_cost(4 * INSN_COST);
15839   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15840   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15841   ins_pipe(vload_reg_mem64);
15842 %}
15843 
15844 // Load Vector (128 bits)
15845 instruct loadV16(vecX dst, vmem16 mem)
15846 %{
15847   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15848   match(Set dst (LoadVector mem));
15849   ins_cost(4 * INSN_COST);
15850   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15851   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15852   ins_pipe(vload_reg_mem128);
15853 %}
15854 
15855 // Store Vector (32 bits)
15856 instruct storeV4(vecD src, vmem4 mem)
15857 %{
15858   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15859   match(Set mem (StoreVector mem src));
15860   ins_cost(4 * INSN_COST);
15861   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15862   ins_encode( aarch64_enc_strvS(src, mem) );
15863   ins_pipe(vstore_reg_mem64);
15864 %}
15865 
15866 // Store Vector (64 bits)
15867 instruct storeV8(vecD src, vmem8 mem)
15868 %{
15869   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15870   match(Set mem (StoreVector mem src));
15871   ins_cost(4 * INSN_COST);
15872   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15873   ins_encode( aarch64_enc_strvD(src, mem) );
15874   ins_pipe(vstore_reg_mem64);
15875 %}
15876 
15877 // Store Vector (128 bits)
15878 instruct storeV16(vecX src, vmem16 mem)
15879 %{
15880   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15881   match(Set mem (StoreVector mem src));
15882   ins_cost(4 * INSN_COST);
15883   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15884   ins_encode( aarch64_enc_strvQ(src, mem) );
15885   ins_pipe(vstore_reg_mem128);
15886 %}
15887 
15888 instruct replicate8B(vecD dst, iRegIorL2I src)
15889 %{
15890   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15891             n-&gt;as_Vector()-&gt;length() == 8);
15892   match(Set dst (ReplicateB src));
15893   ins_cost(INSN_COST);
15894   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15895   ins_encode %{
15896     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15897   %}
15898   ins_pipe(vdup_reg_reg64);
15899 %}
15900 
15901 instruct replicate16B(vecX dst, iRegIorL2I src)
15902 %{
15903   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15904   match(Set dst (ReplicateB src));
15905   ins_cost(INSN_COST);
15906   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15907   ins_encode %{
15908     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15909   %}
15910   ins_pipe(vdup_reg_reg128);
15911 %}
15912 
15913 instruct replicate8B_imm(vecD dst, immI con)
15914 %{
15915   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15916             n-&gt;as_Vector()-&gt;length() == 8);
15917   match(Set dst (ReplicateB con));
15918   ins_cost(INSN_COST);
15919   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15920   ins_encode %{
15921     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15922   %}
15923   ins_pipe(vmovi_reg_imm64);
15924 %}
15925 
15926 instruct replicate16B_imm(vecX dst, immI con)
15927 %{
15928   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15929   match(Set dst (ReplicateB con));
15930   ins_cost(INSN_COST);
15931   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15932   ins_encode %{
15933     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15934   %}
15935   ins_pipe(vmovi_reg_imm128);
15936 %}
15937 
15938 instruct replicate4S(vecD dst, iRegIorL2I src)
15939 %{
15940   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15941             n-&gt;as_Vector()-&gt;length() == 4);
15942   match(Set dst (ReplicateS src));
15943   ins_cost(INSN_COST);
15944   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15945   ins_encode %{
15946     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15947   %}
15948   ins_pipe(vdup_reg_reg64);
15949 %}
15950 
15951 instruct replicate8S(vecX dst, iRegIorL2I src)
15952 %{
15953   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15954   match(Set dst (ReplicateS src));
15955   ins_cost(INSN_COST);
15956   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15957   ins_encode %{
15958     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15959   %}
15960   ins_pipe(vdup_reg_reg128);
15961 %}
15962 
15963 instruct replicate4S_imm(vecD dst, immI con)
15964 %{
15965   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15966             n-&gt;as_Vector()-&gt;length() == 4);
15967   match(Set dst (ReplicateS con));
15968   ins_cost(INSN_COST);
15969   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15970   ins_encode %{
15971     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15972   %}
15973   ins_pipe(vmovi_reg_imm64);
15974 %}
15975 
15976 instruct replicate8S_imm(vecX dst, immI con)
15977 %{
15978   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15979   match(Set dst (ReplicateS con));
15980   ins_cost(INSN_COST);
15981   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15982   ins_encode %{
15983     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15984   %}
15985   ins_pipe(vmovi_reg_imm128);
15986 %}
15987 
15988 instruct replicate2I(vecD dst, iRegIorL2I src)
15989 %{
15990   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15991   match(Set dst (ReplicateI src));
15992   ins_cost(INSN_COST);
15993   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15994   ins_encode %{
15995     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15996   %}
15997   ins_pipe(vdup_reg_reg64);
15998 %}
15999 
16000 instruct replicate4I(vecX dst, iRegIorL2I src)
16001 %{
16002   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16003   match(Set dst (ReplicateI src));
16004   ins_cost(INSN_COST);
16005   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
16006   ins_encode %{
16007     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
16008   %}
16009   ins_pipe(vdup_reg_reg128);
16010 %}
16011 
16012 instruct replicate2I_imm(vecD dst, immI con)
16013 %{
16014   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16015   match(Set dst (ReplicateI con));
16016   ins_cost(INSN_COST);
16017   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
16018   ins_encode %{
16019     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
16020   %}
16021   ins_pipe(vmovi_reg_imm64);
16022 %}
16023 
16024 instruct replicate4I_imm(vecX dst, immI con)
16025 %{
16026   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16027   match(Set dst (ReplicateI con));
16028   ins_cost(INSN_COST);
16029   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
16030   ins_encode %{
16031     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
16032   %}
16033   ins_pipe(vmovi_reg_imm128);
16034 %}
16035 
16036 instruct replicate2L(vecX dst, iRegL src)
16037 %{
16038   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16039   match(Set dst (ReplicateL src));
16040   ins_cost(INSN_COST);
16041   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
16042   ins_encode %{
16043     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
16044   %}
16045   ins_pipe(vdup_reg_reg128);
16046 %}
16047 
16048 instruct replicate2L_zero(vecX dst, immI0 zero)
16049 %{
16050   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16051   match(Set dst (ReplicateI zero));
16052   ins_cost(INSN_COST);
16053   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16054   ins_encode %{
16055     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16056            as_FloatRegister($dst$$reg),
16057            as_FloatRegister($dst$$reg));
16058   %}
16059   ins_pipe(vmovi_reg_imm128);
16060 %}
16061 
16062 instruct replicate2F(vecD dst, vRegF src)
16063 %{
16064   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16065   match(Set dst (ReplicateF src));
16066   ins_cost(INSN_COST);
16067   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16068   ins_encode %{
16069     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16070            as_FloatRegister($src$$reg));
16071   %}
16072   ins_pipe(vdup_reg_freg64);
16073 %}
16074 
16075 instruct replicate4F(vecX dst, vRegF src)
16076 %{
16077   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16078   match(Set dst (ReplicateF src));
16079   ins_cost(INSN_COST);
16080   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16081   ins_encode %{
16082     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16083            as_FloatRegister($src$$reg));
16084   %}
16085   ins_pipe(vdup_reg_freg128);
16086 %}
16087 
16088 instruct replicate2D(vecX dst, vRegD src)
16089 %{
16090   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16091   match(Set dst (ReplicateD src));
16092   ins_cost(INSN_COST);
16093   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16094   ins_encode %{
16095     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16096            as_FloatRegister($src$$reg));
16097   %}
16098   ins_pipe(vdup_reg_dreg128);
16099 %}
16100 
16101 // ====================REDUCTION ARITHMETIC====================================
16102 
16103 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
16104 %{
16105   match(Set dst (AddReductionVI isrc vsrc));
16106   ins_cost(INSN_COST);
16107   effect(TEMP tmp, TEMP tmp2);
16108   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16109             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16110             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16111             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16112   %}
16113   ins_encode %{
16114     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16115     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16116     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16117     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16118   %}
16119   ins_pipe(pipe_class_default);
16120 %}
16121 
16122 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16123 %{
16124   match(Set dst (AddReductionVI isrc vsrc));
16125   ins_cost(INSN_COST);
16126   effect(TEMP vtmp, TEMP itmp);
16127   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16128             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16129             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16130   %}
16131   ins_encode %{
16132     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16133             as_FloatRegister($vsrc$$reg));
16134     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16135     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16136   %}
16137   ins_pipe(pipe_class_default);
16138 %}
16139 
16140 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16141 %{
16142   match(Set dst (MulReductionVI isrc vsrc));
16143   ins_cost(INSN_COST);
16144   effect(TEMP tmp, TEMP dst);
16145   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16146             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16147             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16148             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16149   %}
16150   ins_encode %{
16151     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16152     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16153     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16154     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16155   %}
16156   ins_pipe(pipe_class_default);
16157 %}
16158 
16159 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16160 %{
16161   match(Set dst (MulReductionVI isrc vsrc));
16162   ins_cost(INSN_COST);
16163   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16164   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16165             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16166             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16167             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16168             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16169             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16170   %}
16171   ins_encode %{
16172     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16173            as_FloatRegister($vsrc$$reg), 0, 1);
16174     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16175             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16176     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16177     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16178     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16179     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16180   %}
16181   ins_pipe(pipe_class_default);
16182 %}
16183 
16184 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16185 %{
16186   match(Set dst (AddReductionVF fsrc vsrc));
16187   ins_cost(INSN_COST);
16188   effect(TEMP tmp, TEMP dst);
16189   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16190             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16191             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16192   %}
16193   ins_encode %{
16194     __ fadds(as_FloatRegister($dst$$reg),
16195              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16196     __ ins(as_FloatRegister($tmp$$reg), __ S,
16197            as_FloatRegister($vsrc$$reg), 0, 1);
16198     __ fadds(as_FloatRegister($dst$$reg),
16199              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16200   %}
16201   ins_pipe(pipe_class_default);
16202 %}
16203 
16204 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16205 %{
16206   match(Set dst (AddReductionVF fsrc vsrc));
16207   ins_cost(INSN_COST);
16208   effect(TEMP tmp, TEMP dst);
16209   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16210             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16211             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16212             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16213             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16214             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16215             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16216   %}
16217   ins_encode %{
16218     __ fadds(as_FloatRegister($dst$$reg),
16219              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16220     __ ins(as_FloatRegister($tmp$$reg), __ S,
16221            as_FloatRegister($vsrc$$reg), 0, 1);
16222     __ fadds(as_FloatRegister($dst$$reg),
16223              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16224     __ ins(as_FloatRegister($tmp$$reg), __ S,
16225            as_FloatRegister($vsrc$$reg), 0, 2);
16226     __ fadds(as_FloatRegister($dst$$reg),
16227              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16228     __ ins(as_FloatRegister($tmp$$reg), __ S,
16229            as_FloatRegister($vsrc$$reg), 0, 3);
16230     __ fadds(as_FloatRegister($dst$$reg),
16231              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16232   %}
16233   ins_pipe(pipe_class_default);
16234 %}
16235 
16236 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16237 %{
16238   match(Set dst (MulReductionVF fsrc vsrc));
16239   ins_cost(INSN_COST);
16240   effect(TEMP tmp, TEMP dst);
16241   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16242             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16243             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16244   %}
16245   ins_encode %{
16246     __ fmuls(as_FloatRegister($dst$$reg),
16247              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16248     __ ins(as_FloatRegister($tmp$$reg), __ S,
16249            as_FloatRegister($vsrc$$reg), 0, 1);
16250     __ fmuls(as_FloatRegister($dst$$reg),
16251              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16252   %}
16253   ins_pipe(pipe_class_default);
16254 %}
16255 
16256 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16257 %{
16258   match(Set dst (MulReductionVF fsrc vsrc));
16259   ins_cost(INSN_COST);
16260   effect(TEMP tmp, TEMP dst);
16261   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16262             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16263             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16264             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16265             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16266             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16267             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16268   %}
16269   ins_encode %{
16270     __ fmuls(as_FloatRegister($dst$$reg),
16271              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16272     __ ins(as_FloatRegister($tmp$$reg), __ S,
16273            as_FloatRegister($vsrc$$reg), 0, 1);
16274     __ fmuls(as_FloatRegister($dst$$reg),
16275              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16276     __ ins(as_FloatRegister($tmp$$reg), __ S,
16277            as_FloatRegister($vsrc$$reg), 0, 2);
16278     __ fmuls(as_FloatRegister($dst$$reg),
16279              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16280     __ ins(as_FloatRegister($tmp$$reg), __ S,
16281            as_FloatRegister($vsrc$$reg), 0, 3);
16282     __ fmuls(as_FloatRegister($dst$$reg),
16283              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16284   %}
16285   ins_pipe(pipe_class_default);
16286 %}
16287 
16288 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16289 %{
16290   match(Set dst (AddReductionVD dsrc vsrc));
16291   ins_cost(INSN_COST);
16292   effect(TEMP tmp, TEMP dst);
16293   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16294             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16295             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16296   %}
16297   ins_encode %{
16298     __ faddd(as_FloatRegister($dst$$reg),
16299              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16300     __ ins(as_FloatRegister($tmp$$reg), __ D,
16301            as_FloatRegister($vsrc$$reg), 0, 1);
16302     __ faddd(as_FloatRegister($dst$$reg),
16303              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16304   %}
16305   ins_pipe(pipe_class_default);
16306 %}
16307 
16308 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16309 %{
16310   match(Set dst (MulReductionVD dsrc vsrc));
16311   ins_cost(INSN_COST);
16312   effect(TEMP tmp, TEMP dst);
16313   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16314             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16315             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16316   %}
16317   ins_encode %{
16318     __ fmuld(as_FloatRegister($dst$$reg),
16319              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16320     __ ins(as_FloatRegister($tmp$$reg), __ D,
16321            as_FloatRegister($vsrc$$reg), 0, 1);
16322     __ fmuld(as_FloatRegister($dst$$reg),
16323              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16324   %}
16325   ins_pipe(pipe_class_default);
16326 %}
16327 
16328 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16329   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16330   match(Set dst (MaxReductionV fsrc vsrc));
16331   ins_cost(INSN_COST);
16332   effect(TEMP_DEF dst, TEMP tmp);
16333   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16334             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16335             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16336   ins_encode %{
16337     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16338     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16339     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16340   %}
16341   ins_pipe(pipe_class_default);
16342 %}
16343 
16344 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16345   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16346   match(Set dst (MaxReductionV fsrc vsrc));
16347   ins_cost(INSN_COST);
16348   effect(TEMP_DEF dst);
16349   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16350             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16351   ins_encode %{
16352     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16353     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16354   %}
16355   ins_pipe(pipe_class_default);
16356 %}
16357 
16358 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16359   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16360   match(Set dst (MaxReductionV dsrc vsrc));
16361   ins_cost(INSN_COST);
16362   effect(TEMP_DEF dst, TEMP tmp);
16363   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16364             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16365             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16366   ins_encode %{
16367     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16368     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16369     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16370   %}
16371   ins_pipe(pipe_class_default);
16372 %}
16373 
16374 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16375   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16376   match(Set dst (MinReductionV fsrc vsrc));
16377   ins_cost(INSN_COST);
16378   effect(TEMP_DEF dst, TEMP tmp);
16379   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16380             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16381             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16382   ins_encode %{
16383     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16384     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16385     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16386   %}
16387   ins_pipe(pipe_class_default);
16388 %}
16389 
16390 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16391   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16392   match(Set dst (MinReductionV fsrc vsrc));
16393   ins_cost(INSN_COST);
16394   effect(TEMP_DEF dst);
16395   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16396             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16397   ins_encode %{
16398     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16399     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16400   %}
16401   ins_pipe(pipe_class_default);
16402 %}
16403 
16404 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16405   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16406   match(Set dst (MinReductionV dsrc vsrc));
16407   ins_cost(INSN_COST);
16408   effect(TEMP_DEF dst, TEMP tmp);
16409   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16410             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16411             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16412   ins_encode %{
16413     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16414     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16415     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16416   %}
16417   ins_pipe(pipe_class_default);
16418 %}
16419 
16420 // ====================VECTOR ARITHMETIC=======================================
16421 
16422 // --------------------------------- ADD --------------------------------------
16423 
16424 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16425 %{
16426   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16427             n-&gt;as_Vector()-&gt;length() == 8);
16428   match(Set dst (AddVB src1 src2));
16429   ins_cost(INSN_COST);
16430   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16431   ins_encode %{
16432     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16433             as_FloatRegister($src1$$reg),
16434             as_FloatRegister($src2$$reg));
16435   %}
16436   ins_pipe(vdop64);
16437 %}
16438 
16439 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16440 %{
16441   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16442   match(Set dst (AddVB src1 src2));
16443   ins_cost(INSN_COST);
16444   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16445   ins_encode %{
16446     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16447             as_FloatRegister($src1$$reg),
16448             as_FloatRegister($src2$$reg));
16449   %}
16450   ins_pipe(vdop128);
16451 %}
16452 
16453 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16454 %{
16455   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16456             n-&gt;as_Vector()-&gt;length() == 4);
16457   match(Set dst (AddVS src1 src2));
16458   ins_cost(INSN_COST);
16459   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16460   ins_encode %{
16461     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16462             as_FloatRegister($src1$$reg),
16463             as_FloatRegister($src2$$reg));
16464   %}
16465   ins_pipe(vdop64);
16466 %}
16467 
16468 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16469 %{
16470   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16471   match(Set dst (AddVS src1 src2));
16472   ins_cost(INSN_COST);
16473   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16474   ins_encode %{
16475     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16476             as_FloatRegister($src1$$reg),
16477             as_FloatRegister($src2$$reg));
16478   %}
16479   ins_pipe(vdop128);
16480 %}
16481 
16482 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16483 %{
16484   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16485   match(Set dst (AddVI src1 src2));
16486   ins_cost(INSN_COST);
16487   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16488   ins_encode %{
16489     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16490             as_FloatRegister($src1$$reg),
16491             as_FloatRegister($src2$$reg));
16492   %}
16493   ins_pipe(vdop64);
16494 %}
16495 
16496 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16497 %{
16498   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16499   match(Set dst (AddVI src1 src2));
16500   ins_cost(INSN_COST);
16501   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16502   ins_encode %{
16503     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16504             as_FloatRegister($src1$$reg),
16505             as_FloatRegister($src2$$reg));
16506   %}
16507   ins_pipe(vdop128);
16508 %}
16509 
16510 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16511 %{
16512   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16513   match(Set dst (AddVL src1 src2));
16514   ins_cost(INSN_COST);
16515   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16516   ins_encode %{
16517     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16518             as_FloatRegister($src1$$reg),
16519             as_FloatRegister($src2$$reg));
16520   %}
16521   ins_pipe(vdop128);
16522 %}
16523 
16524 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16525 %{
16526   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16527   match(Set dst (AddVF src1 src2));
16528   ins_cost(INSN_COST);
16529   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16530   ins_encode %{
16531     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16532             as_FloatRegister($src1$$reg),
16533             as_FloatRegister($src2$$reg));
16534   %}
16535   ins_pipe(vdop_fp64);
16536 %}
16537 
16538 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16539 %{
16540   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16541   match(Set dst (AddVF src1 src2));
16542   ins_cost(INSN_COST);
16543   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16544   ins_encode %{
16545     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16546             as_FloatRegister($src1$$reg),
16547             as_FloatRegister($src2$$reg));
16548   %}
16549   ins_pipe(vdop_fp128);
16550 %}
16551 
16552 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16553 %{
16554   match(Set dst (AddVD src1 src2));
16555   ins_cost(INSN_COST);
16556   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16557   ins_encode %{
16558     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16559             as_FloatRegister($src1$$reg),
16560             as_FloatRegister($src2$$reg));
16561   %}
16562   ins_pipe(vdop_fp128);
16563 %}
16564 
16565 // --------------------------------- SUB --------------------------------------
16566 
16567 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16568 %{
16569   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16570             n-&gt;as_Vector()-&gt;length() == 8);
16571   match(Set dst (SubVB src1 src2));
16572   ins_cost(INSN_COST);
16573   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16574   ins_encode %{
16575     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16576             as_FloatRegister($src1$$reg),
16577             as_FloatRegister($src2$$reg));
16578   %}
16579   ins_pipe(vdop64);
16580 %}
16581 
16582 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16583 %{
16584   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16585   match(Set dst (SubVB src1 src2));
16586   ins_cost(INSN_COST);
16587   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16588   ins_encode %{
16589     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16590             as_FloatRegister($src1$$reg),
16591             as_FloatRegister($src2$$reg));
16592   %}
16593   ins_pipe(vdop128);
16594 %}
16595 
16596 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16597 %{
16598   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16599             n-&gt;as_Vector()-&gt;length() == 4);
16600   match(Set dst (SubVS src1 src2));
16601   ins_cost(INSN_COST);
16602   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16603   ins_encode %{
16604     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16605             as_FloatRegister($src1$$reg),
16606             as_FloatRegister($src2$$reg));
16607   %}
16608   ins_pipe(vdop64);
16609 %}
16610 
16611 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16612 %{
16613   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16614   match(Set dst (SubVS src1 src2));
16615   ins_cost(INSN_COST);
16616   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16617   ins_encode %{
16618     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16619             as_FloatRegister($src1$$reg),
16620             as_FloatRegister($src2$$reg));
16621   %}
16622   ins_pipe(vdop128);
16623 %}
16624 
16625 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16626 %{
16627   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16628   match(Set dst (SubVI src1 src2));
16629   ins_cost(INSN_COST);
16630   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16631   ins_encode %{
16632     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16633             as_FloatRegister($src1$$reg),
16634             as_FloatRegister($src2$$reg));
16635   %}
16636   ins_pipe(vdop64);
16637 %}
16638 
16639 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16640 %{
16641   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16642   match(Set dst (SubVI src1 src2));
16643   ins_cost(INSN_COST);
16644   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16645   ins_encode %{
16646     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16647             as_FloatRegister($src1$$reg),
16648             as_FloatRegister($src2$$reg));
16649   %}
16650   ins_pipe(vdop128);
16651 %}
16652 
16653 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16654 %{
16655   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16656   match(Set dst (SubVL src1 src2));
16657   ins_cost(INSN_COST);
16658   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16659   ins_encode %{
16660     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16661             as_FloatRegister($src1$$reg),
16662             as_FloatRegister($src2$$reg));
16663   %}
16664   ins_pipe(vdop128);
16665 %}
16666 
16667 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16668 %{
16669   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16670   match(Set dst (SubVF src1 src2));
16671   ins_cost(INSN_COST);
16672   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16673   ins_encode %{
16674     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16675             as_FloatRegister($src1$$reg),
16676             as_FloatRegister($src2$$reg));
16677   %}
16678   ins_pipe(vdop_fp64);
16679 %}
16680 
16681 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16682 %{
16683   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16684   match(Set dst (SubVF src1 src2));
16685   ins_cost(INSN_COST);
16686   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16687   ins_encode %{
16688     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16689             as_FloatRegister($src1$$reg),
16690             as_FloatRegister($src2$$reg));
16691   %}
16692   ins_pipe(vdop_fp128);
16693 %}
16694 
16695 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16696 %{
16697   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16698   match(Set dst (SubVD src1 src2));
16699   ins_cost(INSN_COST);
16700   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16701   ins_encode %{
16702     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16703             as_FloatRegister($src1$$reg),
16704             as_FloatRegister($src2$$reg));
16705   %}
16706   ins_pipe(vdop_fp128);
16707 %}
16708 
16709 // --------------------------------- MUL --------------------------------------
16710 
<a name="3" id="anc3"></a><span class="line-added">16711 instruct vmul8B(vecD dst, vecD src1, vecD src2)</span>
<span class="line-added">16712 %{</span>
<span class="line-added">16713   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||</span>
<span class="line-added">16714             n-&gt;as_Vector()-&gt;length() == 8);</span>
<span class="line-added">16715   match(Set dst (MulVB src1 src2));</span>
<span class="line-added">16716   ins_cost(INSN_COST);</span>
<span class="line-added">16717   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}</span>
<span class="line-added">16718   ins_encode %{</span>
<span class="line-added">16719     __ mulv(as_FloatRegister($dst$$reg), __ T8B,</span>
<span class="line-added">16720             as_FloatRegister($src1$$reg),</span>
<span class="line-added">16721             as_FloatRegister($src2$$reg));</span>
<span class="line-added">16722   %}</span>
<span class="line-added">16723   ins_pipe(vmul64);</span>
<span class="line-added">16724 %}</span>
<span class="line-added">16725 </span>
<span class="line-added">16726 instruct vmul16B(vecX dst, vecX src1, vecX src2)</span>
<span class="line-added">16727 %{</span>
<span class="line-added">16728   predicate(n-&gt;as_Vector()-&gt;length() == 16);</span>
<span class="line-added">16729   match(Set dst (MulVB src1 src2));</span>
<span class="line-added">16730   ins_cost(INSN_COST);</span>
<span class="line-added">16731   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}</span>
<span class="line-added">16732   ins_encode %{</span>
<span class="line-added">16733     __ mulv(as_FloatRegister($dst$$reg), __ T16B,</span>
<span class="line-added">16734             as_FloatRegister($src1$$reg),</span>
<span class="line-added">16735             as_FloatRegister($src2$$reg));</span>
<span class="line-added">16736   %}</span>
<span class="line-added">16737   ins_pipe(vmul128);</span>
<span class="line-added">16738 %}</span>
<span class="line-added">16739 </span>
16740 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16741 %{
16742   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16743             n-&gt;as_Vector()-&gt;length() == 4);
16744   match(Set dst (MulVS src1 src2));
16745   ins_cost(INSN_COST);
16746   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16747   ins_encode %{
16748     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16749             as_FloatRegister($src1$$reg),
16750             as_FloatRegister($src2$$reg));
16751   %}
16752   ins_pipe(vmul64);
16753 %}
16754 
16755 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16756 %{
16757   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16758   match(Set dst (MulVS src1 src2));
16759   ins_cost(INSN_COST);
16760   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16761   ins_encode %{
16762     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16763             as_FloatRegister($src1$$reg),
16764             as_FloatRegister($src2$$reg));
16765   %}
16766   ins_pipe(vmul128);
16767 %}
16768 
16769 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16770 %{
16771   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16772   match(Set dst (MulVI src1 src2));
16773   ins_cost(INSN_COST);
16774   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16775   ins_encode %{
16776     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16777             as_FloatRegister($src1$$reg),
16778             as_FloatRegister($src2$$reg));
16779   %}
16780   ins_pipe(vmul64);
16781 %}
16782 
16783 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16784 %{
16785   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16786   match(Set dst (MulVI src1 src2));
16787   ins_cost(INSN_COST);
16788   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16789   ins_encode %{
16790     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16791             as_FloatRegister($src1$$reg),
16792             as_FloatRegister($src2$$reg));
16793   %}
16794   ins_pipe(vmul128);
16795 %}
16796 
16797 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16798 %{
16799   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16800   match(Set dst (MulVF src1 src2));
16801   ins_cost(INSN_COST);
16802   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16803   ins_encode %{
16804     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16805             as_FloatRegister($src1$$reg),
16806             as_FloatRegister($src2$$reg));
16807   %}
16808   ins_pipe(vmuldiv_fp64);
16809 %}
16810 
16811 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16812 %{
16813   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16814   match(Set dst (MulVF src1 src2));
16815   ins_cost(INSN_COST);
16816   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16817   ins_encode %{
16818     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16819             as_FloatRegister($src1$$reg),
16820             as_FloatRegister($src2$$reg));
16821   %}
16822   ins_pipe(vmuldiv_fp128);
16823 %}
16824 
16825 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16826 %{
16827   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16828   match(Set dst (MulVD src1 src2));
16829   ins_cost(INSN_COST);
16830   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16831   ins_encode %{
16832     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16833             as_FloatRegister($src1$$reg),
16834             as_FloatRegister($src2$$reg));
16835   %}
16836   ins_pipe(vmuldiv_fp128);
16837 %}
16838 
16839 // --------------------------------- MLA --------------------------------------
16840 
16841 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16842 %{
16843   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16844             n-&gt;as_Vector()-&gt;length() == 4);
16845   match(Set dst (AddVS dst (MulVS src1 src2)));
16846   ins_cost(INSN_COST);
16847   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16848   ins_encode %{
16849     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16850             as_FloatRegister($src1$$reg),
16851             as_FloatRegister($src2$$reg));
16852   %}
16853   ins_pipe(vmla64);
16854 %}
16855 
16856 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16857 %{
16858   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16859   match(Set dst (AddVS dst (MulVS src1 src2)));
16860   ins_cost(INSN_COST);
16861   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16862   ins_encode %{
16863     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16864             as_FloatRegister($src1$$reg),
16865             as_FloatRegister($src2$$reg));
16866   %}
16867   ins_pipe(vmla128);
16868 %}
16869 
16870 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16871 %{
16872   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16873   match(Set dst (AddVI dst (MulVI src1 src2)));
16874   ins_cost(INSN_COST);
16875   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16876   ins_encode %{
16877     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16878             as_FloatRegister($src1$$reg),
16879             as_FloatRegister($src2$$reg));
16880   %}
16881   ins_pipe(vmla64);
16882 %}
16883 
16884 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16885 %{
16886   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16887   match(Set dst (AddVI dst (MulVI src1 src2)));
16888   ins_cost(INSN_COST);
16889   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16890   ins_encode %{
16891     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16892             as_FloatRegister($src1$$reg),
16893             as_FloatRegister($src2$$reg));
16894   %}
16895   ins_pipe(vmla128);
16896 %}
16897 
16898 // dst + src1 * src2
16899 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16900   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16901   match(Set dst (FmaVF  dst (Binary src1 src2)));
16902   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16903   ins_cost(INSN_COST);
16904   ins_encode %{
16905     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16906             as_FloatRegister($src1$$reg),
16907             as_FloatRegister($src2$$reg));
16908   %}
16909   ins_pipe(vmuldiv_fp64);
16910 %}
16911 
16912 // dst + src1 * src2
16913 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16914   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16915   match(Set dst (FmaVF  dst (Binary src1 src2)));
16916   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16917   ins_cost(INSN_COST);
16918   ins_encode %{
16919     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16920             as_FloatRegister($src1$$reg),
16921             as_FloatRegister($src2$$reg));
16922   %}
16923   ins_pipe(vmuldiv_fp128);
16924 %}
16925 
16926 // dst + src1 * src2
16927 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16928   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16929   match(Set dst (FmaVD  dst (Binary src1 src2)));
16930   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16931   ins_cost(INSN_COST);
16932   ins_encode %{
16933     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16934             as_FloatRegister($src1$$reg),
16935             as_FloatRegister($src2$$reg));
16936   %}
16937   ins_pipe(vmuldiv_fp128);
16938 %}
16939 
16940 // --------------------------------- MLS --------------------------------------
16941 
16942 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16943 %{
16944   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16945             n-&gt;as_Vector()-&gt;length() == 4);
16946   match(Set dst (SubVS dst (MulVS src1 src2)));
16947   ins_cost(INSN_COST);
16948   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16949   ins_encode %{
16950     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16951             as_FloatRegister($src1$$reg),
16952             as_FloatRegister($src2$$reg));
16953   %}
16954   ins_pipe(vmla64);
16955 %}
16956 
16957 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16958 %{
16959   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16960   match(Set dst (SubVS dst (MulVS src1 src2)));
16961   ins_cost(INSN_COST);
16962   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16963   ins_encode %{
16964     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16965             as_FloatRegister($src1$$reg),
16966             as_FloatRegister($src2$$reg));
16967   %}
16968   ins_pipe(vmla128);
16969 %}
16970 
16971 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16972 %{
16973   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16974   match(Set dst (SubVI dst (MulVI src1 src2)));
16975   ins_cost(INSN_COST);
16976   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16977   ins_encode %{
16978     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16979             as_FloatRegister($src1$$reg),
16980             as_FloatRegister($src2$$reg));
16981   %}
16982   ins_pipe(vmla64);
16983 %}
16984 
16985 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16986 %{
16987   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16988   match(Set dst (SubVI dst (MulVI src1 src2)));
16989   ins_cost(INSN_COST);
16990   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16991   ins_encode %{
16992     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16993             as_FloatRegister($src1$$reg),
16994             as_FloatRegister($src2$$reg));
16995   %}
16996   ins_pipe(vmla128);
16997 %}
16998 
16999 // dst - src1 * src2
17000 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
17001   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17002   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
17003   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
17004   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
17005   ins_cost(INSN_COST);
17006   ins_encode %{
17007     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
17008             as_FloatRegister($src1$$reg),
17009             as_FloatRegister($src2$$reg));
17010   %}
17011   ins_pipe(vmuldiv_fp64);
17012 %}
17013 
17014 // dst - src1 * src2
17015 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
17016   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
17017   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
17018   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
17019   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
17020   ins_cost(INSN_COST);
17021   ins_encode %{
17022     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
17023             as_FloatRegister($src1$$reg),
17024             as_FloatRegister($src2$$reg));
17025   %}
17026   ins_pipe(vmuldiv_fp128);
17027 %}
17028 
17029 // dst - src1 * src2
17030 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
17031   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
17032   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
17033   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
17034   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
17035   ins_cost(INSN_COST);
17036   ins_encode %{
17037     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
17038             as_FloatRegister($src1$$reg),
17039             as_FloatRegister($src2$$reg));
17040   %}
17041   ins_pipe(vmuldiv_fp128);
17042 %}
17043 
17044 // --------------- Vector Multiply-Add Shorts into Integer --------------------
17045 
17046 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
17047   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
17048   match(Set dst (MulAddVS2VI src1 src2));
17049   ins_cost(INSN_COST);
17050   effect(TEMP_DEF dst, TEMP tmp);
17051   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
17052             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
17053             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17054   ins_encode %{
17055     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17056               as_FloatRegister($src1$$reg),
17057               as_FloatRegister($src2$$reg));
17058     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17059               as_FloatRegister($src1$$reg),
17060               as_FloatRegister($src2$$reg));
17061     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17062              as_FloatRegister($tmp$$reg),
17063              as_FloatRegister($dst$$reg));
17064   %}
17065   ins_pipe(vmuldiv_fp128);
17066 %}
17067 
17068 // --------------------------------- DIV --------------------------------------
17069 
17070 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
17071 %{
17072   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17073   match(Set dst (DivVF src1 src2));
17074   ins_cost(INSN_COST);
17075   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17076   ins_encode %{
17077     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17078             as_FloatRegister($src1$$reg),
17079             as_FloatRegister($src2$$reg));
17080   %}
17081   ins_pipe(vmuldiv_fp64);
17082 %}
17083 
17084 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17085 %{
17086   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17087   match(Set dst (DivVF src1 src2));
17088   ins_cost(INSN_COST);
17089   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17090   ins_encode %{
17091     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17092             as_FloatRegister($src1$$reg),
17093             as_FloatRegister($src2$$reg));
17094   %}
17095   ins_pipe(vmuldiv_fp128);
17096 %}
17097 
17098 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17099 %{
17100   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17101   match(Set dst (DivVD src1 src2));
17102   ins_cost(INSN_COST);
17103   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17104   ins_encode %{
17105     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17106             as_FloatRegister($src1$$reg),
17107             as_FloatRegister($src2$$reg));
17108   %}
17109   ins_pipe(vmuldiv_fp128);
17110 %}
17111 
17112 // --------------------------------- SQRT -------------------------------------
17113 
17114 instruct vsqrt2D(vecX dst, vecX src)
17115 %{
17116   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17117   match(Set dst (SqrtVD src));
17118   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17119   ins_encode %{
17120     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17121              as_FloatRegister($src$$reg));
17122   %}
17123   ins_pipe(vsqrt_fp128);
17124 %}
17125 
17126 // --------------------------------- ABS --------------------------------------
17127 
17128 instruct vabs2F(vecD dst, vecD src)
17129 %{
17130   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17131   match(Set dst (AbsVF src));
17132   ins_cost(INSN_COST * 3);
17133   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17134   ins_encode %{
17135     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17136             as_FloatRegister($src$$reg));
17137   %}
17138   ins_pipe(vunop_fp64);
17139 %}
17140 
17141 instruct vabs4F(vecX dst, vecX src)
17142 %{
17143   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17144   match(Set dst (AbsVF src));
17145   ins_cost(INSN_COST * 3);
17146   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17147   ins_encode %{
17148     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17149             as_FloatRegister($src$$reg));
17150   %}
17151   ins_pipe(vunop_fp128);
17152 %}
17153 
17154 instruct vabs2D(vecX dst, vecX src)
17155 %{
17156   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17157   match(Set dst (AbsVD src));
17158   ins_cost(INSN_COST * 3);
17159   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17160   ins_encode %{
17161     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17162             as_FloatRegister($src$$reg));
17163   %}
17164   ins_pipe(vunop_fp128);
17165 %}
17166 
17167 // --------------------------------- NEG --------------------------------------
17168 
17169 instruct vneg2F(vecD dst, vecD src)
17170 %{
17171   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17172   match(Set dst (NegVF src));
17173   ins_cost(INSN_COST * 3);
17174   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17175   ins_encode %{
17176     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17177             as_FloatRegister($src$$reg));
17178   %}
17179   ins_pipe(vunop_fp64);
17180 %}
17181 
17182 instruct vneg4F(vecX dst, vecX src)
17183 %{
17184   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17185   match(Set dst (NegVF src));
17186   ins_cost(INSN_COST * 3);
17187   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17188   ins_encode %{
17189     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17190             as_FloatRegister($src$$reg));
17191   %}
17192   ins_pipe(vunop_fp128);
17193 %}
17194 
17195 instruct vneg2D(vecX dst, vecX src)
17196 %{
17197   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17198   match(Set dst (NegVD src));
17199   ins_cost(INSN_COST * 3);
17200   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17201   ins_encode %{
17202     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17203             as_FloatRegister($src$$reg));
17204   %}
17205   ins_pipe(vunop_fp128);
17206 %}
17207 
17208 // --------------------------------- AND --------------------------------------
17209 
17210 instruct vand8B(vecD dst, vecD src1, vecD src2)
17211 %{
17212   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17213             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17214   match(Set dst (AndV src1 src2));
17215   ins_cost(INSN_COST);
17216   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17217   ins_encode %{
17218     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17219             as_FloatRegister($src1$$reg),
17220             as_FloatRegister($src2$$reg));
17221   %}
17222   ins_pipe(vlogical64);
17223 %}
17224 
17225 instruct vand16B(vecX dst, vecX src1, vecX src2)
17226 %{
17227   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17228   match(Set dst (AndV src1 src2));
17229   ins_cost(INSN_COST);
17230   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17231   ins_encode %{
17232     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17233             as_FloatRegister($src1$$reg),
17234             as_FloatRegister($src2$$reg));
17235   %}
17236   ins_pipe(vlogical128);
17237 %}
17238 
17239 // --------------------------------- OR ---------------------------------------
17240 
17241 instruct vor8B(vecD dst, vecD src1, vecD src2)
17242 %{
17243   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17244             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17245   match(Set dst (OrV src1 src2));
17246   ins_cost(INSN_COST);
17247   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17248   ins_encode %{
17249     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17250             as_FloatRegister($src1$$reg),
17251             as_FloatRegister($src2$$reg));
17252   %}
17253   ins_pipe(vlogical64);
17254 %}
17255 
17256 instruct vor16B(vecX dst, vecX src1, vecX src2)
17257 %{
17258   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17259   match(Set dst (OrV src1 src2));
17260   ins_cost(INSN_COST);
17261   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17262   ins_encode %{
17263     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17264             as_FloatRegister($src1$$reg),
17265             as_FloatRegister($src2$$reg));
17266   %}
17267   ins_pipe(vlogical128);
17268 %}
17269 
17270 // --------------------------------- XOR --------------------------------------
17271 
17272 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17273 %{
17274   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17275             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17276   match(Set dst (XorV src1 src2));
17277   ins_cost(INSN_COST);
17278   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17279   ins_encode %{
17280     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17281             as_FloatRegister($src1$$reg),
17282             as_FloatRegister($src2$$reg));
17283   %}
17284   ins_pipe(vlogical64);
17285 %}
17286 
17287 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17288 %{
17289   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17290   match(Set dst (XorV src1 src2));
17291   ins_cost(INSN_COST);
17292   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17293   ins_encode %{
17294     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17295             as_FloatRegister($src1$$reg),
17296             as_FloatRegister($src2$$reg));
17297   %}
17298   ins_pipe(vlogical128);
17299 %}
17300 
17301 // ------------------------------ Shift ---------------------------------------
17302 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17303   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17304   match(Set dst (LShiftCntV cnt));
17305   match(Set dst (RShiftCntV cnt));
17306   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17307   ins_encode %{
17308     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17309   %}
17310   ins_pipe(vdup_reg_reg64);
17311 %}
17312 
17313 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17314   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17315   match(Set dst (LShiftCntV cnt));
17316   match(Set dst (RShiftCntV cnt));
17317   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17318   ins_encode %{
17319     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17320   %}
17321   ins_pipe(vdup_reg_reg128);
17322 %}
17323 
17324 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17325   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17326             n-&gt;as_Vector()-&gt;length() == 8);
17327   match(Set dst (LShiftVB src shift));
17328   ins_cost(INSN_COST);
17329   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17330   ins_encode %{
17331     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17332             as_FloatRegister($src$$reg),
17333             as_FloatRegister($shift$$reg));
17334   %}
17335   ins_pipe(vshift64);
17336 %}
17337 
17338 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17339   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17340   match(Set dst (LShiftVB src shift));
17341   ins_cost(INSN_COST);
17342   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17343   ins_encode %{
17344     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17345             as_FloatRegister($src$$reg),
17346             as_FloatRegister($shift$$reg));
17347   %}
17348   ins_pipe(vshift128);
17349 %}
17350 
17351 // Right shifts with vector shift count on aarch64 SIMD are implemented
17352 // as left shift by negative shift count.
17353 // There are two cases for vector shift count.
17354 //
17355 // Case 1: The vector shift count is from replication.
17356 //        |            |
17357 //    LoadVector  RShiftCntV
17358 //        |       /
17359 //     RShiftVI
17360 // Note: In inner loop, multiple neg instructions are used, which can be
17361 // moved to outer loop and merge into one neg instruction.
17362 //
17363 // Case 2: The vector shift count is from loading.
17364 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17365 // panama/vectorIntrinsics(JEP 338: Vector API).
17366 //        |            |
17367 //    LoadVector  LoadVector
17368 //        |       /
17369 //     RShiftVI
17370 //
17371 
17372 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17373   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17374             n-&gt;as_Vector()-&gt;length() == 8);
17375   match(Set dst (RShiftVB src shift));
17376   ins_cost(INSN_COST);
17377   effect(TEMP tmp);
17378   format %{ &quot;negr  $tmp,$shift\t&quot;
17379             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17380   ins_encode %{
17381     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17382             as_FloatRegister($shift$$reg));
17383     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17384             as_FloatRegister($src$$reg),
17385             as_FloatRegister($tmp$$reg));
17386   %}
17387   ins_pipe(vshift64);
17388 %}
17389 
17390 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17391   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17392   match(Set dst (RShiftVB src shift));
17393   ins_cost(INSN_COST);
17394   effect(TEMP tmp);
17395   format %{ &quot;negr  $tmp,$shift\t&quot;
17396             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17397   ins_encode %{
17398     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17399             as_FloatRegister($shift$$reg));
17400     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17401             as_FloatRegister($src$$reg),
17402             as_FloatRegister($tmp$$reg));
17403   %}
17404   ins_pipe(vshift128);
17405 %}
17406 
17407 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17408   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17409             n-&gt;as_Vector()-&gt;length() == 8);
17410   match(Set dst (URShiftVB src shift));
17411   ins_cost(INSN_COST);
17412   effect(TEMP tmp);
17413   format %{ &quot;negr  $tmp,$shift\t&quot;
17414             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17415   ins_encode %{
17416     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17417             as_FloatRegister($shift$$reg));
17418     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17419             as_FloatRegister($src$$reg),
17420             as_FloatRegister($tmp$$reg));
17421   %}
17422   ins_pipe(vshift64);
17423 %}
17424 
17425 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17426   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17427   match(Set dst (URShiftVB src shift));
17428   ins_cost(INSN_COST);
17429   effect(TEMP tmp);
17430   format %{ &quot;negr  $tmp,$shift\t&quot;
17431             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17432   ins_encode %{
17433     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17434             as_FloatRegister($shift$$reg));
17435     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17436             as_FloatRegister($src$$reg),
17437             as_FloatRegister($tmp$$reg));
17438   %}
17439   ins_pipe(vshift128);
17440 %}
17441 
17442 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17443   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17444             n-&gt;as_Vector()-&gt;length() == 8);
17445   match(Set dst (LShiftVB src (LShiftCntV shift)));
17446   ins_cost(INSN_COST);
17447   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17448   ins_encode %{
17449     int sh = (int)$shift$$constant;
17450     if (sh &gt;= 8) {
17451       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17452              as_FloatRegister($src$$reg),
17453              as_FloatRegister($src$$reg));
17454     } else {
17455       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17456              as_FloatRegister($src$$reg), sh);
17457     }
17458   %}
17459   ins_pipe(vshift64_imm);
17460 %}
17461 
17462 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17463   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17464   match(Set dst (LShiftVB src (LShiftCntV shift)));
17465   ins_cost(INSN_COST);
17466   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17467   ins_encode %{
17468     int sh = (int)$shift$$constant;
17469     if (sh &gt;= 8) {
17470       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17471              as_FloatRegister($src$$reg),
17472              as_FloatRegister($src$$reg));
17473     } else {
17474       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17475              as_FloatRegister($src$$reg), sh);
17476     }
17477   %}
17478   ins_pipe(vshift128_imm);
17479 %}
17480 
17481 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17482   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17483             n-&gt;as_Vector()-&gt;length() == 8);
17484   match(Set dst (RShiftVB src (RShiftCntV shift)));
17485   ins_cost(INSN_COST);
17486   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17487   ins_encode %{
17488     int sh = (int)$shift$$constant;
17489     if (sh &gt;= 8) sh = 7;
17490     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17491            as_FloatRegister($src$$reg), sh);
17492   %}
17493   ins_pipe(vshift64_imm);
17494 %}
17495 
17496 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17497   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17498   match(Set dst (RShiftVB src (RShiftCntV shift)));
17499   ins_cost(INSN_COST);
17500   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17501   ins_encode %{
17502     int sh = (int)$shift$$constant;
17503     if (sh &gt;= 8) sh = 7;
17504     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17505            as_FloatRegister($src$$reg), sh);
17506   %}
17507   ins_pipe(vshift128_imm);
17508 %}
17509 
17510 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17511   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17512             n-&gt;as_Vector()-&gt;length() == 8);
17513   match(Set dst (URShiftVB src (RShiftCntV shift)));
17514   ins_cost(INSN_COST);
17515   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17516   ins_encode %{
17517     int sh = (int)$shift$$constant;
17518     if (sh &gt;= 8) {
17519       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17520              as_FloatRegister($src$$reg),
17521              as_FloatRegister($src$$reg));
17522     } else {
17523       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17524              as_FloatRegister($src$$reg), sh);
17525     }
17526   %}
17527   ins_pipe(vshift64_imm);
17528 %}
17529 
17530 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17531   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17532   match(Set dst (URShiftVB src (RShiftCntV shift)));
17533   ins_cost(INSN_COST);
17534   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17535   ins_encode %{
17536     int sh = (int)$shift$$constant;
17537     if (sh &gt;= 8) {
17538       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17539              as_FloatRegister($src$$reg),
17540              as_FloatRegister($src$$reg));
17541     } else {
17542       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17543              as_FloatRegister($src$$reg), sh);
17544     }
17545   %}
17546   ins_pipe(vshift128_imm);
17547 %}
17548 
17549 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17550   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17551             n-&gt;as_Vector()-&gt;length() == 4);
17552   match(Set dst (LShiftVS src shift));
17553   ins_cost(INSN_COST);
17554   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17555   ins_encode %{
17556     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17557             as_FloatRegister($src$$reg),
17558             as_FloatRegister($shift$$reg));
17559   %}
17560   ins_pipe(vshift64);
17561 %}
17562 
17563 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17564   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17565   match(Set dst (LShiftVS src shift));
17566   ins_cost(INSN_COST);
17567   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17568   ins_encode %{
17569     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17570             as_FloatRegister($src$$reg),
17571             as_FloatRegister($shift$$reg));
17572   %}
17573   ins_pipe(vshift128);
17574 %}
17575 
17576 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17577   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17578             n-&gt;as_Vector()-&gt;length() == 4);
17579   match(Set dst (RShiftVS src shift));
17580   ins_cost(INSN_COST);
17581   effect(TEMP tmp);
17582   format %{ &quot;negr  $tmp,$shift\t&quot;
17583             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17584   ins_encode %{
17585     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17586             as_FloatRegister($shift$$reg));
17587     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17588             as_FloatRegister($src$$reg),
17589             as_FloatRegister($tmp$$reg));
17590   %}
17591   ins_pipe(vshift64);
17592 %}
17593 
17594 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17595   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17596   match(Set dst (RShiftVS src shift));
17597   ins_cost(INSN_COST);
17598   effect(TEMP tmp);
17599   format %{ &quot;negr  $tmp,$shift\t&quot;
17600             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17601   ins_encode %{
17602     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17603             as_FloatRegister($shift$$reg));
17604     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17605             as_FloatRegister($src$$reg),
17606             as_FloatRegister($tmp$$reg));
17607   %}
17608   ins_pipe(vshift128);
17609 %}
17610 
17611 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17612   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17613             n-&gt;as_Vector()-&gt;length() == 4);
17614   match(Set dst (URShiftVS src shift));
17615   ins_cost(INSN_COST);
17616   effect(TEMP tmp);
17617   format %{ &quot;negr  $tmp,$shift\t&quot;
17618             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17619   ins_encode %{
17620     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17621             as_FloatRegister($shift$$reg));
17622     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17623             as_FloatRegister($src$$reg),
17624             as_FloatRegister($tmp$$reg));
17625   %}
17626   ins_pipe(vshift64);
17627 %}
17628 
17629 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17630   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17631   match(Set dst (URShiftVS src shift));
17632   ins_cost(INSN_COST);
17633   effect(TEMP tmp);
17634   format %{ &quot;negr  $tmp,$shift\t&quot;
17635             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17636   ins_encode %{
17637     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17638             as_FloatRegister($shift$$reg));
17639     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17640             as_FloatRegister($src$$reg),
17641             as_FloatRegister($tmp$$reg));
17642   %}
17643   ins_pipe(vshift128);
17644 %}
17645 
17646 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17647   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17648             n-&gt;as_Vector()-&gt;length() == 4);
17649   match(Set dst (LShiftVS src (LShiftCntV shift)));
17650   ins_cost(INSN_COST);
17651   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17652   ins_encode %{
17653     int sh = (int)$shift$$constant;
17654     if (sh &gt;= 16) {
17655       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17656              as_FloatRegister($src$$reg),
17657              as_FloatRegister($src$$reg));
17658     } else {
17659       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17660              as_FloatRegister($src$$reg), sh);
17661     }
17662   %}
17663   ins_pipe(vshift64_imm);
17664 %}
17665 
17666 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17667   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17668   match(Set dst (LShiftVS src (LShiftCntV shift)));
17669   ins_cost(INSN_COST);
17670   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17671   ins_encode %{
17672     int sh = (int)$shift$$constant;
17673     if (sh &gt;= 16) {
17674       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17675              as_FloatRegister($src$$reg),
17676              as_FloatRegister($src$$reg));
17677     } else {
17678       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17679              as_FloatRegister($src$$reg), sh);
17680     }
17681   %}
17682   ins_pipe(vshift128_imm);
17683 %}
17684 
17685 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17686   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17687             n-&gt;as_Vector()-&gt;length() == 4);
17688   match(Set dst (RShiftVS src (RShiftCntV shift)));
17689   ins_cost(INSN_COST);
17690   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17691   ins_encode %{
17692     int sh = (int)$shift$$constant;
17693     if (sh &gt;= 16) sh = 15;
17694     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17695            as_FloatRegister($src$$reg), sh);
17696   %}
17697   ins_pipe(vshift64_imm);
17698 %}
17699 
17700 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17701   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17702   match(Set dst (RShiftVS src (RShiftCntV shift)));
17703   ins_cost(INSN_COST);
17704   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17705   ins_encode %{
17706     int sh = (int)$shift$$constant;
17707     if (sh &gt;= 16) sh = 15;
17708     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17709            as_FloatRegister($src$$reg), sh);
17710   %}
17711   ins_pipe(vshift128_imm);
17712 %}
17713 
17714 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17715   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17716             n-&gt;as_Vector()-&gt;length() == 4);
17717   match(Set dst (URShiftVS src (RShiftCntV shift)));
17718   ins_cost(INSN_COST);
17719   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17720   ins_encode %{
17721     int sh = (int)$shift$$constant;
17722     if (sh &gt;= 16) {
17723       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17724              as_FloatRegister($src$$reg),
17725              as_FloatRegister($src$$reg));
17726     } else {
17727       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17728              as_FloatRegister($src$$reg), sh);
17729     }
17730   %}
17731   ins_pipe(vshift64_imm);
17732 %}
17733 
17734 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17735   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17736   match(Set dst (URShiftVS src (RShiftCntV shift)));
17737   ins_cost(INSN_COST);
17738   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17739   ins_encode %{
17740     int sh = (int)$shift$$constant;
17741     if (sh &gt;= 16) {
17742       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17743              as_FloatRegister($src$$reg),
17744              as_FloatRegister($src$$reg));
17745     } else {
17746       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17747              as_FloatRegister($src$$reg), sh);
17748     }
17749   %}
17750   ins_pipe(vshift128_imm);
17751 %}
17752 
17753 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17754   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17755   match(Set dst (LShiftVI src shift));
17756   ins_cost(INSN_COST);
17757   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17758   ins_encode %{
17759     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17760             as_FloatRegister($src$$reg),
17761             as_FloatRegister($shift$$reg));
17762   %}
17763   ins_pipe(vshift64);
17764 %}
17765 
17766 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17767   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17768   match(Set dst (LShiftVI src shift));
17769   ins_cost(INSN_COST);
17770   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17771   ins_encode %{
17772     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17773             as_FloatRegister($src$$reg),
17774             as_FloatRegister($shift$$reg));
17775   %}
17776   ins_pipe(vshift128);
17777 %}
17778 
17779 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17780   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17781   match(Set dst (RShiftVI src shift));
17782   ins_cost(INSN_COST);
17783   effect(TEMP tmp);
17784   format %{ &quot;negr  $tmp,$shift\t&quot;
17785             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17786   ins_encode %{
17787     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17788             as_FloatRegister($shift$$reg));
17789     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17790             as_FloatRegister($src$$reg),
17791             as_FloatRegister($tmp$$reg));
17792   %}
17793   ins_pipe(vshift64);
17794 %}
17795 
17796 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17797   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17798   match(Set dst (RShiftVI src shift));
17799   ins_cost(INSN_COST);
17800   effect(TEMP tmp);
17801   format %{ &quot;negr  $tmp,$shift\t&quot;
17802             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17803   ins_encode %{
17804     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17805             as_FloatRegister($shift$$reg));
17806     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17807             as_FloatRegister($src$$reg),
17808             as_FloatRegister($tmp$$reg));
17809   %}
17810   ins_pipe(vshift128);
17811 %}
17812 
17813 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17814   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17815   match(Set dst (URShiftVI src shift));
17816   ins_cost(INSN_COST);
17817   effect(TEMP tmp);
17818   format %{ &quot;negr  $tmp,$shift\t&quot;
17819             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17820   ins_encode %{
17821     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17822             as_FloatRegister($shift$$reg));
17823     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17824             as_FloatRegister($src$$reg),
17825             as_FloatRegister($tmp$$reg));
17826   %}
17827   ins_pipe(vshift64);
17828 %}
17829 
17830 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17831   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17832   match(Set dst (URShiftVI src shift));
17833   ins_cost(INSN_COST);
17834   effect(TEMP tmp);
17835   format %{ &quot;negr  $tmp,$shift\t&quot;
17836             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17837   ins_encode %{
17838     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17839             as_FloatRegister($shift$$reg));
17840     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17841             as_FloatRegister($src$$reg),
17842             as_FloatRegister($tmp$$reg));
17843   %}
17844   ins_pipe(vshift128);
17845 %}
17846 
17847 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17848   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17849   match(Set dst (LShiftVI src (LShiftCntV shift)));
17850   ins_cost(INSN_COST);
17851   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17852   ins_encode %{
17853     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17854            as_FloatRegister($src$$reg),
17855            (int)$shift$$constant);
17856   %}
17857   ins_pipe(vshift64_imm);
17858 %}
17859 
17860 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17861   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17862   match(Set dst (LShiftVI src (LShiftCntV shift)));
17863   ins_cost(INSN_COST);
17864   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17865   ins_encode %{
17866     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17867            as_FloatRegister($src$$reg),
17868            (int)$shift$$constant);
17869   %}
17870   ins_pipe(vshift128_imm);
17871 %}
17872 
17873 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17874   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17875   match(Set dst (RShiftVI src (RShiftCntV shift)));
17876   ins_cost(INSN_COST);
17877   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17878   ins_encode %{
17879     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17880             as_FloatRegister($src$$reg),
17881             (int)$shift$$constant);
17882   %}
17883   ins_pipe(vshift64_imm);
17884 %}
17885 
17886 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17887   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17888   match(Set dst (RShiftVI src (RShiftCntV shift)));
17889   ins_cost(INSN_COST);
17890   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17891   ins_encode %{
17892     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17893             as_FloatRegister($src$$reg),
17894             (int)$shift$$constant);
17895   %}
17896   ins_pipe(vshift128_imm);
17897 %}
17898 
17899 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17900   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17901   match(Set dst (URShiftVI src (RShiftCntV shift)));
17902   ins_cost(INSN_COST);
17903   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17904   ins_encode %{
17905     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17906             as_FloatRegister($src$$reg),
17907             (int)$shift$$constant);
17908   %}
17909   ins_pipe(vshift64_imm);
17910 %}
17911 
17912 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17913   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17914   match(Set dst (URShiftVI src (RShiftCntV shift)));
17915   ins_cost(INSN_COST);
17916   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17917   ins_encode %{
17918     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17919             as_FloatRegister($src$$reg),
17920             (int)$shift$$constant);
17921   %}
17922   ins_pipe(vshift128_imm);
17923 %}
17924 
17925 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17926   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17927   match(Set dst (LShiftVL src shift));
17928   ins_cost(INSN_COST);
17929   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17930   ins_encode %{
17931     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17932             as_FloatRegister($src$$reg),
17933             as_FloatRegister($shift$$reg));
17934   %}
17935   ins_pipe(vshift128);
17936 %}
17937 
17938 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17939   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17940   match(Set dst (RShiftVL src shift));
17941   ins_cost(INSN_COST);
17942   effect(TEMP tmp);
17943   format %{ &quot;negr  $tmp,$shift\t&quot;
17944             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17945   ins_encode %{
17946     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17947             as_FloatRegister($shift$$reg));
17948     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17949             as_FloatRegister($src$$reg),
17950             as_FloatRegister($tmp$$reg));
17951   %}
17952   ins_pipe(vshift128);
17953 %}
17954 
17955 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17956   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17957   match(Set dst (URShiftVL src shift));
17958   ins_cost(INSN_COST);
17959   effect(TEMP tmp);
17960   format %{ &quot;negr  $tmp,$shift\t&quot;
17961             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17962   ins_encode %{
17963     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17964             as_FloatRegister($shift$$reg));
17965     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17966             as_FloatRegister($src$$reg),
17967             as_FloatRegister($tmp$$reg));
17968   %}
17969   ins_pipe(vshift128);
17970 %}
17971 
17972 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17973   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17974   match(Set dst (LShiftVL src (LShiftCntV shift)));
17975   ins_cost(INSN_COST);
17976   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17977   ins_encode %{
17978     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17979            as_FloatRegister($src$$reg),
17980            (int)$shift$$constant);
17981   %}
17982   ins_pipe(vshift128_imm);
17983 %}
17984 
17985 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17986   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17987   match(Set dst (RShiftVL src (RShiftCntV shift)));
17988   ins_cost(INSN_COST);
17989   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17990   ins_encode %{
17991     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17992             as_FloatRegister($src$$reg),
17993             (int)$shift$$constant);
17994   %}
17995   ins_pipe(vshift128_imm);
17996 %}
17997 
17998 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17999   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18000   match(Set dst (URShiftVL src (RShiftCntV shift)));
18001   ins_cost(INSN_COST);
18002   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
18003   ins_encode %{
18004     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
18005             as_FloatRegister($src$$reg),
18006             (int)$shift$$constant);
18007   %}
18008   ins_pipe(vshift128_imm);
18009 %}
18010 
18011 instruct vmax2F(vecD dst, vecD src1, vecD src2)
18012 %{
18013   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18014   match(Set dst (MaxV src1 src2));
18015   ins_cost(INSN_COST);
18016   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
18017   ins_encode %{
18018     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
18019             as_FloatRegister($src1$$reg),
18020             as_FloatRegister($src2$$reg));
18021   %}
18022   ins_pipe(vdop_fp64);
18023 %}
18024 
18025 instruct vmax4F(vecX dst, vecX src1, vecX src2)
18026 %{
18027   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18028   match(Set dst (MaxV src1 src2));
18029   ins_cost(INSN_COST);
18030   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
18031   ins_encode %{
18032     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
18033             as_FloatRegister($src1$$reg),
18034             as_FloatRegister($src2$$reg));
18035   %}
18036   ins_pipe(vdop_fp128);
18037 %}
18038 
18039 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18040 %{
18041   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18042   match(Set dst (MaxV src1 src2));
18043   ins_cost(INSN_COST);
18044   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18045   ins_encode %{
18046     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18047             as_FloatRegister($src1$$reg),
18048             as_FloatRegister($src2$$reg));
18049   %}
18050   ins_pipe(vdop_fp128);
18051 %}
18052 
18053 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18054 %{
18055   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18056   match(Set dst (MinV src1 src2));
18057   ins_cost(INSN_COST);
18058   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18059   ins_encode %{
18060     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18061             as_FloatRegister($src1$$reg),
18062             as_FloatRegister($src2$$reg));
18063   %}
18064   ins_pipe(vdop_fp64);
18065 %}
18066 
18067 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18068 %{
18069   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18070   match(Set dst (MinV src1 src2));
18071   ins_cost(INSN_COST);
18072   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18073   ins_encode %{
18074     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18075             as_FloatRegister($src1$$reg),
18076             as_FloatRegister($src2$$reg));
18077   %}
18078   ins_pipe(vdop_fp128);
18079 %}
18080 
18081 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18082 %{
18083   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18084   match(Set dst (MinV src1 src2));
18085   ins_cost(INSN_COST);
18086   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18087   ins_encode %{
18088     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18089             as_FloatRegister($src1$$reg),
18090             as_FloatRegister($src2$$reg));
18091   %}
18092   ins_pipe(vdop_fp128);
18093 %}
18094 
18095 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18096   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18097   match(Set dst (RoundDoubleModeV src rmode));
18098   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18099   ins_encode %{
18100     switch ($rmode$$constant) {
18101       case RoundDoubleModeNode::rmode_rint:
18102         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18103                   as_FloatRegister($src$$reg));
18104         break;
18105       case RoundDoubleModeNode::rmode_floor:
18106         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18107                   as_FloatRegister($src$$reg));
18108         break;
18109       case RoundDoubleModeNode::rmode_ceil:
18110         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18111                   as_FloatRegister($src$$reg));
18112         break;
18113     }
18114   %}
18115   ins_pipe(vdop_fp128);
18116 %}
18117 
18118 instruct vpopcount4I(vecX dst, vecX src) %{
18119   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18120   match(Set dst (PopCountVI src));
18121   format %{
18122     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18123     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18124     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18125   %}
18126   ins_encode %{
18127      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18128             as_FloatRegister($src$$reg));
18129      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18130                as_FloatRegister($dst$$reg));
18131      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18132                as_FloatRegister($dst$$reg));
18133   %}
18134   ins_pipe(pipe_class_default);
18135 %}
18136 
18137 instruct vpopcount2I(vecD dst, vecD src) %{
18138   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18139   match(Set dst (PopCountVI src));
18140   format %{
18141     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18142     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18143     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18144   %}
18145   ins_encode %{
18146      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18147             as_FloatRegister($src$$reg));
18148      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18149                as_FloatRegister($dst$$reg));
18150      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18151                as_FloatRegister($dst$$reg));
18152   %}
18153   ins_pipe(pipe_class_default);
18154 %}
18155 
18156 //----------PEEPHOLE RULES-----------------------------------------------------
18157 // These must follow all instruction definitions as they use the names
18158 // defined in the instructions definitions.
18159 //
18160 // peepmatch ( root_instr_name [preceding_instruction]* );
18161 //
18162 // peepconstraint %{
18163 // (instruction_number.operand_name relational_op instruction_number.operand_name
18164 //  [, ...] );
18165 // // instruction numbers are zero-based using left to right order in peepmatch
18166 //
18167 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18168 // // provide an instruction_number.operand_name for each operand that appears
18169 // // in the replacement instruction&#39;s match rule
18170 //
18171 // ---------VM FLAGS---------------------------------------------------------
18172 //
18173 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18174 //
18175 // Each peephole rule is given an identifying number starting with zero and
18176 // increasing by one in the order seen by the parser.  An individual peephole
18177 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18178 // on the command-line.
18179 //
18180 // ---------CURRENT LIMITATIONS----------------------------------------------
18181 //
18182 // Only match adjacent instructions in same basic block
18183 // Only equality constraints
18184 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18185 // Only one replacement instruction
18186 //
18187 // ---------EXAMPLE----------------------------------------------------------
18188 //
18189 // // pertinent parts of existing instructions in architecture description
18190 // instruct movI(iRegINoSp dst, iRegI src)
18191 // %{
18192 //   match(Set dst (CopyI src));
18193 // %}
18194 //
18195 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18196 // %{
18197 //   match(Set dst (AddI dst src));
18198 //   effect(KILL cr);
18199 // %}
18200 //
18201 // // Change (inc mov) to lea
18202 // peephole %{
18203 //   // increment preceeded by register-register move
18204 //   peepmatch ( incI_iReg movI );
18205 //   // require that the destination register of the increment
18206 //   // match the destination register of the move
18207 //   peepconstraint ( 0.dst == 1.dst );
18208 //   // construct a replacement instruction that sets
18209 //   // the destination to ( move&#39;s source register + one )
18210 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18211 // %}
18212 //
18213 
18214 // Implementation no longer uses movX instructions since
18215 // machine-independent system no longer uses CopyX nodes.
18216 //
18217 // peephole
18218 // %{
18219 //   peepmatch (incI_iReg movI);
18220 //   peepconstraint (0.dst == 1.dst);
18221 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18222 // %}
18223 
18224 // peephole
18225 // %{
18226 //   peepmatch (decI_iReg movI);
18227 //   peepconstraint (0.dst == 1.dst);
18228 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18229 // %}
18230 
18231 // peephole
18232 // %{
18233 //   peepmatch (addI_iReg_imm movI);
18234 //   peepconstraint (0.dst == 1.dst);
18235 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18236 // %}
18237 
18238 // peephole
18239 // %{
18240 //   peepmatch (incL_iReg movL);
18241 //   peepconstraint (0.dst == 1.dst);
18242 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18243 // %}
18244 
18245 // peephole
18246 // %{
18247 //   peepmatch (decL_iReg movL);
18248 //   peepconstraint (0.dst == 1.dst);
18249 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18250 // %}
18251 
18252 // peephole
18253 // %{
18254 //   peepmatch (addL_iReg_imm movL);
18255 //   peepconstraint (0.dst == 1.dst);
18256 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18257 // %}
18258 
18259 // peephole
18260 // %{
18261 //   peepmatch (addP_iReg_imm movP);
18262 //   peepconstraint (0.dst == 1.dst);
18263 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18264 // %}
18265 
18266 // // Change load of spilled value to only a spill
18267 // instruct storeI(memory mem, iRegI src)
18268 // %{
18269 //   match(Set mem (StoreI mem src));
18270 // %}
18271 //
18272 // instruct loadI(iRegINoSp dst, memory mem)
18273 // %{
18274 //   match(Set dst (LoadI mem));
18275 // %}
18276 //
18277 
18278 //----------SMARTSPILL RULES---------------------------------------------------
18279 // These must follow all instruction definitions as they use the names
18280 // defined in the instructions definitions.
18281 
18282 // Local Variables:
18283 // mode: c++
18284 // End:
<a name="4" id="anc4"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="4" type="hidden" />
</body>
</html>