<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/oops/instanceKlass.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;jvm.h&quot;
  27 #include &quot;aot/aotLoader.hpp&quot;
  28 #include &quot;classfile/classFileParser.hpp&quot;
  29 #include &quot;classfile/classFileStream.hpp&quot;
  30 #include &quot;classfile/classLoader.hpp&quot;
  31 #include &quot;classfile/classLoaderData.inline.hpp&quot;
  32 #include &quot;classfile/javaClasses.hpp&quot;
  33 #include &quot;classfile/moduleEntry.hpp&quot;
  34 #include &quot;classfile/resolutionErrors.hpp&quot;
  35 #include &quot;classfile/symbolTable.hpp&quot;
  36 #include &quot;classfile/systemDictionary.hpp&quot;
  37 #include &quot;classfile/systemDictionaryShared.hpp&quot;
  38 #include &quot;classfile/verifier.hpp&quot;
  39 #include &quot;classfile/vmSymbols.hpp&quot;
  40 #include &quot;code/dependencyContext.hpp&quot;
  41 #include &quot;compiler/compileBroker.hpp&quot;
  42 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  43 #include &quot;interpreter/oopMapCache.hpp&quot;
  44 #include &quot;interpreter/rewriter.hpp&quot;
  45 #include &quot;jvmtifiles/jvmti.h&quot;
  46 #include &quot;logging/log.hpp&quot;
  47 #include &quot;logging/logMessage.hpp&quot;
  48 #include &quot;logging/logStream.hpp&quot;
  49 #include &quot;memory/allocation.inline.hpp&quot;
  50 #include &quot;memory/iterator.inline.hpp&quot;
  51 #include &quot;memory/metadataFactory.hpp&quot;
  52 #include &quot;memory/metaspaceClosure.hpp&quot;
  53 #include &quot;memory/metaspaceShared.hpp&quot;
  54 #include &quot;memory/oopFactory.hpp&quot;
  55 #include &quot;memory/resourceArea.hpp&quot;
  56 #include &quot;memory/universe.hpp&quot;
  57 #include &quot;oops/fieldStreams.inline.hpp&quot;
  58 #include &quot;oops/constantPool.hpp&quot;
  59 #include &quot;oops/instanceClassLoaderKlass.hpp&quot;
  60 #include &quot;oops/instanceKlass.inline.hpp&quot;
  61 #include &quot;oops/instanceMirrorKlass.hpp&quot;
  62 #include &quot;oops/instanceOop.hpp&quot;
  63 #include &quot;oops/klass.inline.hpp&quot;
  64 #include &quot;oops/method.hpp&quot;
  65 #include &quot;oops/oop.inline.hpp&quot;
  66 #include &quot;oops/recordComponent.hpp&quot;
  67 #include &quot;oops/symbol.hpp&quot;
  68 #include &quot;oops/valueKlass.hpp&quot;
  69 #include &quot;prims/jvmtiExport.hpp&quot;
  70 #include &quot;prims/jvmtiRedefineClasses.hpp&quot;
  71 #include &quot;prims/jvmtiThreadState.hpp&quot;
  72 #include &quot;prims/methodComparator.hpp&quot;
  73 #include &quot;runtime/atomic.hpp&quot;
  74 #include &quot;runtime/biasedLocking.hpp&quot;
  75 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  76 #include &quot;runtime/handles.inline.hpp&quot;
  77 #include &quot;runtime/javaCalls.hpp&quot;
  78 #include &quot;runtime/mutexLocker.hpp&quot;
  79 #include &quot;runtime/orderAccess.hpp&quot;
  80 #include &quot;runtime/thread.inline.hpp&quot;
  81 #include &quot;services/classLoadingService.hpp&quot;
  82 #include &quot;services/threadService.hpp&quot;
  83 #include &quot;utilities/dtrace.hpp&quot;
  84 #include &quot;utilities/events.hpp&quot;
  85 #include &quot;utilities/macros.hpp&quot;
  86 #include &quot;utilities/stringUtils.hpp&quot;
  87 #ifdef COMPILER1
  88 #include &quot;c1/c1_Compiler.hpp&quot;
  89 #endif
  90 #if INCLUDE_JFR
  91 #include &quot;jfr/jfrEvents.hpp&quot;
  92 #endif
  93 
  94 
  95 #ifdef DTRACE_ENABLED
  96 
  97 
  98 #define HOTSPOT_CLASS_INITIALIZATION_required HOTSPOT_CLASS_INITIALIZATION_REQUIRED
  99 #define HOTSPOT_CLASS_INITIALIZATION_recursive HOTSPOT_CLASS_INITIALIZATION_RECURSIVE
 100 #define HOTSPOT_CLASS_INITIALIZATION_concurrent HOTSPOT_CLASS_INITIALIZATION_CONCURRENT
 101 #define HOTSPOT_CLASS_INITIALIZATION_erroneous HOTSPOT_CLASS_INITIALIZATION_ERRONEOUS
 102 #define HOTSPOT_CLASS_INITIALIZATION_super__failed HOTSPOT_CLASS_INITIALIZATION_SUPER_FAILED
 103 #define HOTSPOT_CLASS_INITIALIZATION_clinit HOTSPOT_CLASS_INITIALIZATION_CLINIT
 104 #define HOTSPOT_CLASS_INITIALIZATION_error HOTSPOT_CLASS_INITIALIZATION_ERROR
 105 #define HOTSPOT_CLASS_INITIALIZATION_end HOTSPOT_CLASS_INITIALIZATION_END
 106 #define DTRACE_CLASSINIT_PROBE(type, thread_type)                \
 107   {                                                              \
 108     char* data = NULL;                                           \
 109     int len = 0;                                                 \
 110     Symbol* clss_name = name();                                  \
 111     if (clss_name != NULL) {                                     \
 112       data = (char*)clss_name-&gt;bytes();                          \
 113       len = clss_name-&gt;utf8_length();                            \
 114     }                                                            \
 115     HOTSPOT_CLASS_INITIALIZATION_##type(                         \
 116       data, len, (void*)class_loader(), thread_type);            \
 117   }
 118 
 119 #define DTRACE_CLASSINIT_PROBE_WAIT(type, thread_type, wait)     \
 120   {                                                              \
 121     char* data = NULL;                                           \
 122     int len = 0;                                                 \
 123     Symbol* clss_name = name();                                  \
 124     if (clss_name != NULL) {                                     \
 125       data = (char*)clss_name-&gt;bytes();                          \
 126       len = clss_name-&gt;utf8_length();                            \
 127     }                                                            \
 128     HOTSPOT_CLASS_INITIALIZATION_##type(                         \
 129       data, len, (void*)class_loader(), thread_type, wait);      \
 130   }
 131 
 132 #else //  ndef DTRACE_ENABLED
 133 
 134 #define DTRACE_CLASSINIT_PROBE(type, thread_type)
 135 #define DTRACE_CLASSINIT_PROBE_WAIT(type, thread_type, wait)
 136 
 137 #endif //  ndef DTRACE_ENABLED
 138 
 139 
 140 static inline bool is_class_loader(const Symbol* class_name,
 141                                    const ClassFileParser&amp; parser) {
 142   assert(class_name != NULL, &quot;invariant&quot;);
 143 
 144   if (class_name == vmSymbols::java_lang_ClassLoader()) {
 145     return true;
 146   }
 147 
 148   if (SystemDictionary::ClassLoader_klass_loaded()) {
 149     const Klass* const super_klass = parser.super_klass();
 150     if (super_klass != NULL) {
 151       if (super_klass-&gt;is_subtype_of(SystemDictionary::ClassLoader_klass())) {
 152         return true;
 153       }
 154     }
 155   }
 156   return false;
 157 }
 158 
 159 // private: called to verify that k is a static member of this nest.
 160 // We know that k is an instance class in the same package and hence the
 161 // same classloader.
 162 bool InstanceKlass::has_nest_member(InstanceKlass* k, TRAPS) const {
 163   assert(!is_hidden(), &quot;unexpected hidden class&quot;);
 164   if (_nest_members == NULL || _nest_members == Universe::the_empty_short_array()) {
 165     if (log_is_enabled(Trace, class, nestmates)) {
 166       ResourceMark rm(THREAD);
 167       log_trace(class, nestmates)(&quot;Checked nest membership of %s in non-nest-host class %s&quot;,
 168                                   k-&gt;external_name(), this-&gt;external_name());
 169     }
 170     return false;
 171   }
 172 
 173   if (log_is_enabled(Trace, class, nestmates)) {
 174     ResourceMark rm(THREAD);
 175     log_trace(class, nestmates)(&quot;Checking nest membership of %s in %s&quot;,
 176                                 k-&gt;external_name(), this-&gt;external_name());
 177   }
 178 
 179   // Check for a resolved cp entry , else fall back to a name check.
 180   // We don&#39;t want to resolve any class other than the one being checked.
 181   for (int i = 0; i &lt; _nest_members-&gt;length(); i++) {
 182     int cp_index = _nest_members-&gt;at(i);
 183     if (_constants-&gt;tag_at(cp_index).is_klass()) {
 184       Klass* k2 = _constants-&gt;klass_at(cp_index, THREAD);
 185       assert(!HAS_PENDING_EXCEPTION || PENDING_EXCEPTION-&gt;is_a(SystemDictionary::VirtualMachineError_klass()),
 186              &quot;Exceptions should not be possible here&quot;);
 187       if (k2 == k) {
 188         log_trace(class, nestmates)(&quot;- class is listed at nest_members[%d] =&gt; cp[%d]&quot;, i, cp_index);
 189         return true;
 190       }
 191     }
 192     else {
 193       Symbol* name = _constants-&gt;klass_name_at(cp_index);
 194       if (name == k-&gt;name()) {
 195         log_trace(class, nestmates)(&quot;- Found it at nest_members[%d] =&gt; cp[%d]&quot;, i, cp_index);
 196 
 197         // Names match so check actual klass. This may trigger class loading if
 198         // it doesn&#39;t match though that should be impossible as it means one classloader
 199         // has defined two different classes with the same name! A compiler thread won&#39;t be
 200         // able to perform that loading but we can&#39;t exclude the compiler threads from
 201         // executing this logic. But it should actually be impossible to trigger loading here.
 202         Klass* k2 = _constants-&gt;klass_at(cp_index, THREAD);
 203         assert(!HAS_PENDING_EXCEPTION || PENDING_EXCEPTION-&gt;is_a(SystemDictionary::VirtualMachineError_klass()),
 204                &quot;Exceptions should not be possible here&quot;);
 205         if (k2 == k) {
 206           log_trace(class, nestmates)(&quot;- class is listed as a nest member&quot;);
 207           return true;
 208         }
 209         else {
 210           // same name but different klass!
 211           log_trace(class, nestmates)(&quot; - klass comparison failed!&quot;);
 212           // can&#39;t have two names the same, so we&#39;re done
 213           return false;
 214         }
 215       }
 216     }
 217   }
 218   log_trace(class, nestmates)(&quot;- class is NOT a nest member!&quot;);
 219   return false;
 220 }
 221 
 222 // Return nest-host class, resolving, validating and saving it if needed.
 223 // In cases where this is called from a thread that cannot do classloading
 224 // (such as a native JIT thread) then we simply return NULL, which in turn
 225 // causes the access check to return false. Such code will retry the access
 226 // from a more suitable environment later. Otherwise the _nest_host is always
 227 // set once this method returns.
 228 // Any errors from nest-host resolution must be preserved so they can be queried
 229 // from higher-level access checking code, and reported as part of access checking
 230 // exceptions.
 231 // VirtualMachineErrors are propagated with a NULL return.
 232 // Under any conditions where the _nest_host can be set to non-NULL the resulting
 233 // value of it and, if applicable, the nest host resolution/validation error,
 234 // are idempotent.
 235 InstanceKlass* InstanceKlass::nest_host(TRAPS) {
 236   InstanceKlass* nest_host_k = _nest_host;
 237   if (nest_host_k != NULL) {
 238     return nest_host_k;
 239   }
 240 
 241   ResourceMark rm(THREAD);
 242 
 243   // need to resolve and save our nest-host class.
 244   if (_nest_host_index != 0) { // we have a real nest_host
 245     // Before trying to resolve check if we&#39;re in a suitable context
 246     if (!THREAD-&gt;can_call_java() &amp;&amp; !_constants-&gt;tag_at(_nest_host_index).is_klass()) {
 247       log_trace(class, nestmates)(&quot;Rejected resolution of nest-host of %s in unsuitable thread&quot;,
 248                                   this-&gt;external_name());
 249       return NULL; // sentinel to say &quot;try again from a different context&quot;
 250     }
 251 
 252     log_trace(class, nestmates)(&quot;Resolving nest-host of %s using cp entry for %s&quot;,
 253                                 this-&gt;external_name(),
 254                                 _constants-&gt;klass_name_at(_nest_host_index)-&gt;as_C_string());
 255 
 256     Klass* k = _constants-&gt;klass_at(_nest_host_index, THREAD);
 257     if (HAS_PENDING_EXCEPTION) {
 258       if (PENDING_EXCEPTION-&gt;is_a(SystemDictionary::VirtualMachineError_klass())) {
 259         return NULL; // propagate VMEs
 260       }
 261       stringStream ss;
 262       char* target_host_class = _constants-&gt;klass_name_at(_nest_host_index)-&gt;as_C_string();
 263       ss.print(&quot;Nest host resolution of %s with host %s failed: &quot;,
 264                this-&gt;external_name(), target_host_class);
 265       java_lang_Throwable::print(PENDING_EXCEPTION, &amp;ss);
 266       const char* msg = ss.as_string(true /* on C-heap */);
 267       constantPoolHandle cph(THREAD, constants());
 268       SystemDictionary::add_nest_host_error(cph, _nest_host_index, msg);
 269       CLEAR_PENDING_EXCEPTION;
 270 
 271       log_trace(class, nestmates)(&quot;%s&quot;, msg);
 272     } else {
 273       // A valid nest-host is an instance class in the current package that lists this
 274       // class as a nest member. If any of these conditions are not met the class is
 275       // its own nest-host.
 276       const char* error = NULL;
 277 
 278       // JVMS 5.4.4 indicates package check comes first
 279       if (is_same_class_package(k)) {
 280         // Now check actual membership. We can&#39;t be a member if our &quot;host&quot; is
 281         // not an instance class.
 282         if (k-&gt;is_instance_klass()) {
 283           nest_host_k = InstanceKlass::cast(k);
 284           bool is_member = nest_host_k-&gt;has_nest_member(this, THREAD);
 285           // exception is rare, perhaps impossible
 286           if (!HAS_PENDING_EXCEPTION) {
 287             if (is_member) {
 288               _nest_host = nest_host_k; // save resolved nest-host value
 289 
 290               log_trace(class, nestmates)(&quot;Resolved nest-host of %s to %s&quot;,
 291                                           this-&gt;external_name(), k-&gt;external_name());
 292               return nest_host_k;
 293             } else {
 294               error = &quot;current type is not listed as a nest member&quot;;
 295             }
 296           } else {
 297             if (PENDING_EXCEPTION-&gt;is_a(SystemDictionary::VirtualMachineError_klass())) {
 298               return NULL; // propagate VMEs
 299             }
 300             stringStream ss;
 301             ss.print(&quot;exception on member check: &quot;);
 302             java_lang_Throwable::print(PENDING_EXCEPTION, &amp;ss);
 303             error = ss.as_string();
 304           }
 305         } else {
 306           error = &quot;host is not an instance class&quot;;
 307         }
 308       } else {
 309         error = &quot;types are in different packages&quot;;
 310       }
 311 
 312       // something went wrong, so record what and log it
 313       {
 314         stringStream ss;
 315         ss.print(&quot;Type %s (loader: %s) is not a nest member of type %s (loader: %s): %s&quot;,
 316                  this-&gt;external_name(),
 317                  this-&gt;class_loader_data()-&gt;loader_name_and_id(),
 318                  k-&gt;external_name(),
 319                  k-&gt;class_loader_data()-&gt;loader_name_and_id(),
 320                  error);
 321         const char* msg = ss.as_string(true /* on C-heap */);
 322         constantPoolHandle cph(THREAD, constants());
 323         SystemDictionary::add_nest_host_error(cph, _nest_host_index, msg);
 324         log_trace(class, nestmates)(&quot;%s&quot;, msg);
 325       }
 326     }
 327   } else {
 328     log_trace(class, nestmates)(&quot;Type %s is not part of a nest: setting nest-host to self&quot;,
 329                                 this-&gt;external_name());
 330   }
 331 
 332   // Either not in an explicit nest, or else an error occurred, so
 333   // the nest-host is set to `this`. Any thread that sees this assignment
 334   // will also see any setting of nest_host_error(), if applicable.
 335   return (_nest_host = this);
 336 }
 337 
 338 // Dynamic nest member support: set this class&#39;s nest host to the given class.
 339 // This occurs as part of the class definition, as soon as the instanceKlass
 340 // has been created and doesn&#39;t require further resolution. The code:
 341 //    lookup().defineHiddenClass(bytes_for_X, NESTMATE);
 342 // results in:
 343 //    class_of_X.set_nest_host(lookup().lookupClass().getNestHost())
 344 // If it has an explicit _nest_host_index or _nest_members, these will be ignored.
 345 // We also know the &quot;host&quot; is a valid nest-host in the same package so we can
 346 // assert some of those facts.
 347 void InstanceKlass::set_nest_host(InstanceKlass* host, TRAPS) {
 348   assert(is_hidden(), &quot;must be a hidden class&quot;);
 349   assert(host != NULL, &quot;NULL nest host specified&quot;);
 350   assert(_nest_host == NULL, &quot;current class has resolved nest-host&quot;);
 351   assert(nest_host_error(THREAD) == NULL, &quot;unexpected nest host resolution error exists: %s&quot;,
 352          nest_host_error(THREAD));
 353   assert((host-&gt;_nest_host == NULL &amp;&amp; host-&gt;_nest_host_index == 0) ||
 354          (host-&gt;_nest_host == host), &quot;proposed host is not a valid nest-host&quot;);
 355   // Can&#39;t assert this as package is not set yet:
 356   // assert(is_same_class_package(host), &quot;proposed host is in wrong package&quot;);
 357 
 358   if (log_is_enabled(Trace, class, nestmates)) {
 359     ResourceMark rm(THREAD);
 360     const char* msg = &quot;&quot;;
 361     // a hidden class does not expect a statically defined nest-host
 362     if (_nest_host_index &gt; 0) {
 363       msg = &quot;(the NestHost attribute in the current class is ignored)&quot;;
 364     } else if (_nest_members != NULL &amp;&amp; _nest_members != Universe::the_empty_short_array()) {
 365       msg = &quot;(the NestMembers attribute in the current class is ignored)&quot;;
 366     }
 367     log_trace(class, nestmates)(&quot;Injected type %s into the nest of %s %s&quot;,
 368                                 this-&gt;external_name(),
 369                                 host-&gt;external_name(),
 370                                 msg);
 371   }
 372   // set dynamic nest host
 373   _nest_host = host;
 374   // Record dependency to keep nest host from being unloaded before this class.
 375   ClassLoaderData* this_key = class_loader_data();
 376   this_key-&gt;record_dependency(host);
 377 }
 378 
 379 // check if &#39;this&#39; and k are nestmates (same nest_host), or k is our nest_host,
 380 // or we are k&#39;s nest_host - all of which is covered by comparing the two
 381 // resolved_nest_hosts.
 382 // Any exceptions (i.e. VMEs) are propagated.
 383 bool InstanceKlass::has_nestmate_access_to(InstanceKlass* k, TRAPS) {
 384 
 385   assert(this != k, &quot;this should be handled by higher-level code&quot;);
 386 
 387   // Per JVMS 5.4.4 we first resolve and validate the current class, then
 388   // the target class k.
 389 
 390   InstanceKlass* cur_host = nest_host(CHECK_false);
 391   if (cur_host == NULL) {
 392     return false;
 393   }
 394 
 395   Klass* k_nest_host = k-&gt;nest_host(CHECK_false);
 396   if (k_nest_host == NULL) {
 397     return false;
 398   }
 399 
 400   bool access = (cur_host == k_nest_host);
 401 
 402   ResourceMark rm(THREAD);
 403   log_trace(class, nestmates)(&quot;Class %s does %shave nestmate access to %s&quot;,
 404                               this-&gt;external_name(),
 405                               access ? &quot;&quot; : &quot;NOT &quot;,
 406                               k-&gt;external_name());
 407   return access;
 408 }
 409 
 410 const char* InstanceKlass::nest_host_error(TRAPS) {
 411   if (_nest_host_index == 0) {
 412     return NULL;
 413   } else {
 414     constantPoolHandle cph(THREAD, constants());
 415     return SystemDictionary::find_nest_host_error(cph, (int)_nest_host_index);
 416   }
 417 }
 418 
 419 InstanceKlass* InstanceKlass::allocate_instance_klass(const ClassFileParser&amp; parser, TRAPS) {
 420   bool is_hidden_or_anonymous = parser.is_hidden() || parser.is_unsafe_anonymous();
 421   const int size = InstanceKlass::size(parser.vtable_size(),
 422                                        parser.itable_size(),
 423                                        nonstatic_oop_map_size(parser.total_oop_map_count()),
 424                                        parser.is_interface(),
 425                                        parser.is_unsafe_anonymous(),
 426                                        should_store_fingerprint(is_hidden_or_anonymous),
 427                                        parser.has_flattenable_fields() ? parser.java_fields_count() : 0,
 428                                        parser.is_inline_type());
 429 
 430   const Symbol* const class_name = parser.class_name();
 431   assert(class_name != NULL, &quot;invariant&quot;);
 432   ClassLoaderData* loader_data = parser.loader_data();
 433   assert(loader_data != NULL, &quot;invariant&quot;);
 434 
 435   InstanceKlass* ik;
 436 
 437   // Allocation
 438   if (REF_NONE == parser.reference_type()) {
 439     if (class_name == vmSymbols::java_lang_Class()) {
 440       // mirror
 441       ik = new (loader_data, size, THREAD) InstanceMirrorKlass(parser);
 442     } else if (is_class_loader(class_name, parser)) {
 443       // class loader
 444       ik = new (loader_data, size, THREAD) InstanceClassLoaderKlass(parser);
 445     } else if (parser.is_inline_type()) {
 446       // inline type
 447       ik = new (loader_data, size, THREAD) ValueKlass(parser);
 448     } else {
 449       // normal
 450       ik = new (loader_data, size, THREAD) InstanceKlass(parser, InstanceKlass::_kind_other);
 451     }
 452   } else {
 453     // reference
 454     ik = new (loader_data, size, THREAD) InstanceRefKlass(parser);
 455   }
 456 
 457   // Check for pending exception before adding to the loader data and incrementing
 458   // class count.  Can get OOM here.
 459   if (HAS_PENDING_EXCEPTION) {
 460     return NULL;
 461   }
 462 
 463 #ifdef ASSERT
 464   assert(ik-&gt;size() == size, &quot;&quot;);
 465   ik-&gt;bounds_check((address) ik-&gt;start_of_vtable(), false, size);
 466   ik-&gt;bounds_check((address) ik-&gt;start_of_itable(), false, size);
 467   ik-&gt;bounds_check((address) ik-&gt;end_of_itable(), true, size);
 468   ik-&gt;bounds_check((address) ik-&gt;end_of_nonstatic_oop_maps(), true, size);
 469 #endif //ASSERT
 470   return ik;
 471 }
 472 
 473 #ifndef PRODUCT
 474 bool InstanceKlass::bounds_check(address addr, bool edge_ok, intptr_t size_in_bytes) const {
 475   const char* bad = NULL;
 476   address end = NULL;
 477   if (addr &lt; (address)this) {
 478     bad = &quot;before&quot;;
 479   } else if (addr == (address)this) {
 480     if (edge_ok)  return true;
 481     bad = &quot;just before&quot;;
 482   } else if (addr == (end = (address)this + sizeof(intptr_t) * (size_in_bytes &lt; 0 ? size() : size_in_bytes))) {
 483     if (edge_ok)  return true;
 484     bad = &quot;just after&quot;;
 485   } else if (addr &gt; end) {
 486     bad = &quot;after&quot;;
 487   } else {
 488     return true;
 489   }
 490   tty-&gt;print_cr(&quot;%s object bounds: &quot; INTPTR_FORMAT &quot; [&quot; INTPTR_FORMAT &quot;..&quot; INTPTR_FORMAT &quot;]&quot;,
 491       bad, (intptr_t)addr, (intptr_t)this, (intptr_t)end);
 492   Verbose = WizardMode = true; this-&gt;print(); //@@
 493   return false;
 494 }
 495 #endif //PRODUCT
 496 
 497 // copy method ordering from resource area to Metaspace
 498 void InstanceKlass::copy_method_ordering(const intArray* m, TRAPS) {
 499   if (m != NULL) {
 500     // allocate a new array and copy contents (memcpy?)
 501     _method_ordering = MetadataFactory::new_array&lt;int&gt;(class_loader_data(), m-&gt;length(), CHECK);
 502     for (int i = 0; i &lt; m-&gt;length(); i++) {
 503       _method_ordering-&gt;at_put(i, m-&gt;at(i));
 504     }
 505   } else {
 506     _method_ordering = Universe::the_empty_int_array();
 507   }
 508 }
 509 
 510 // create a new array of vtable_indices for default methods
 511 Array&lt;int&gt;* InstanceKlass::create_new_default_vtable_indices(int len, TRAPS) {
 512   Array&lt;int&gt;* vtable_indices = MetadataFactory::new_array&lt;int&gt;(class_loader_data(), len, CHECK_NULL);
 513   assert(default_vtable_indices() == NULL, &quot;only create once&quot;);
 514   set_default_vtable_indices(vtable_indices);
 515   return vtable_indices;
 516 }
 517 
 518 InstanceKlass::InstanceKlass(const ClassFileParser&amp; parser, unsigned kind, KlassID id) :
 519   Klass(id),
 520   _nest_members(NULL),
 521   _nest_host(NULL),
 522   _record_components(NULL),
 523   _static_field_size(parser.static_field_size()),
 524   _nonstatic_oop_map_size(nonstatic_oop_map_size(parser.total_oop_map_count())),
 525   _itable_len(parser.itable_size()),
 526   _nest_host_index(0),
 527   _init_state(allocated),
 528   _reference_type(parser.reference_type()),
 529   _init_thread(NULL),
 530   _value_field_klasses(NULL),
 531   _adr_valueklass_fixed_block(NULL)
 532 {
 533   set_vtable_length(parser.vtable_size());
 534   set_kind(kind);
 535   set_access_flags(parser.access_flags());
 536   if (parser.is_hidden()) set_is_hidden();
 537   set_is_unsafe_anonymous(parser.is_unsafe_anonymous());
 538   set_layout_helper(Klass::instance_layout_helper(parser.layout_size(),
 539                                                     false));
 540     if (parser.has_flattenable_fields()) {
 541       set_has_inline_fields();
 542     }
 543     _java_fields_count = parser.java_fields_count();
 544 
 545     assert(NULL == _methods, &quot;underlying memory not zeroed?&quot;);
 546     assert(is_instance_klass(), &quot;is layout incorrect?&quot;);
 547     assert(size_helper() == parser.layout_size(), &quot;incorrect size_helper?&quot;);
 548 
 549   if (Arguments::is_dumping_archive()) {
 550       SystemDictionaryShared::init_dumptime_info(this);
 551     }
 552 
 553   // Set biased locking bit for all instances of this class; it will be
 554   // cleared if revocation occurs too often for this type
 555   if (UseBiasedLocking &amp;&amp; BiasedLocking::enabled()) {
 556     set_prototype_header(markWord::biased_locking_prototype());
 557   }
 558   if (has_inline_fields()) {
 559     _value_field_klasses = (const Klass**) adr_value_fields_klasses();
 560   }
 561 }
 562 
 563 void InstanceKlass::deallocate_methods(ClassLoaderData* loader_data,
 564                                        Array&lt;Method*&gt;* methods) {
 565   if (methods != NULL &amp;&amp; methods != Universe::the_empty_method_array() &amp;&amp;
 566       !methods-&gt;is_shared()) {
 567     for (int i = 0; i &lt; methods-&gt;length(); i++) {
 568       Method* method = methods-&gt;at(i);
 569       if (method == NULL) continue;  // maybe null if error processing
 570       // Only want to delete methods that are not executing for RedefineClasses.
 571       // The previous version will point to them so they&#39;re not totally dangling
 572       assert (!method-&gt;on_stack(), &quot;shouldn&#39;t be called with methods on stack&quot;);
 573       MetadataFactory::free_metadata(loader_data, method);
 574     }
 575     MetadataFactory::free_array&lt;Method*&gt;(loader_data, methods);
 576   }
 577 }
 578 
 579 void InstanceKlass::deallocate_interfaces(ClassLoaderData* loader_data,
 580                                           const Klass* super_klass,
 581                                           Array&lt;InstanceKlass*&gt;* local_interfaces,
 582                                           Array&lt;InstanceKlass*&gt;* transitive_interfaces) {
 583   // Only deallocate transitive interfaces if not empty, same as super class
 584   // or same as local interfaces.  See code in parseClassFile.
 585   Array&lt;InstanceKlass*&gt;* ti = transitive_interfaces;
 586   if (ti != Universe::the_empty_instance_klass_array() &amp;&amp; ti != local_interfaces) {
 587     // check that the interfaces don&#39;t come from super class
 588     Array&lt;InstanceKlass*&gt;* sti = (super_klass == NULL) ? NULL :
 589                     InstanceKlass::cast(super_klass)-&gt;transitive_interfaces();
 590     if (ti != sti &amp;&amp; ti != NULL &amp;&amp; !ti-&gt;is_shared() &amp;&amp;
 591         ti != Universe::the_single_IdentityObject_klass_array()) {
 592       MetadataFactory::free_array&lt;InstanceKlass*&gt;(loader_data, ti);
 593     }
 594   }
 595 
 596   // local interfaces can be empty
 597   if (local_interfaces != Universe::the_empty_instance_klass_array() &amp;&amp;
 598       local_interfaces != NULL &amp;&amp; !local_interfaces-&gt;is_shared() &amp;&amp;
 599       local_interfaces != Universe::the_single_IdentityObject_klass_array()) {
 600     MetadataFactory::free_array&lt;InstanceKlass*&gt;(loader_data, local_interfaces);
 601   }
 602 }
 603 
 604 void InstanceKlass::deallocate_record_components(ClassLoaderData* loader_data,
 605                                                  Array&lt;RecordComponent*&gt;* record_components) {
 606   if (record_components != NULL &amp;&amp; !record_components-&gt;is_shared()) {
 607     for (int i = 0; i &lt; record_components-&gt;length(); i++) {
 608       RecordComponent* record_component = record_components-&gt;at(i);
 609       MetadataFactory::free_metadata(loader_data, record_component);
 610     }
 611     MetadataFactory::free_array&lt;RecordComponent*&gt;(loader_data, record_components);
 612   }
 613 }
 614 
 615 // This function deallocates the metadata and C heap pointers that the
 616 // InstanceKlass points to.
 617 void InstanceKlass::deallocate_contents(ClassLoaderData* loader_data) {
 618 
 619   // Orphan the mirror first, CMS thinks it&#39;s still live.
 620   if (java_mirror() != NULL) {
 621     java_lang_Class::set_klass(java_mirror(), NULL);
 622   }
 623 
 624   // Also remove mirror from handles
 625   loader_data-&gt;remove_handle(_java_mirror);
 626 
 627   // Need to take this class off the class loader data list.
 628   loader_data-&gt;remove_class(this);
 629 
 630   // The array_klass for this class is created later, after error handling.
 631   // For class redefinition, we keep the original class so this scratch class
 632   // doesn&#39;t have an array class.  Either way, assert that there is nothing
 633   // to deallocate.
 634   assert(array_klasses() == NULL, &quot;array classes shouldn&#39;t be created for this class yet&quot;);
 635 
 636   // Release C heap allocated data that this points to, which includes
 637   // reference counting symbol names.
 638   release_C_heap_structures_internal();
 639 
 640   deallocate_methods(loader_data, methods());
 641   set_methods(NULL);
 642 
 643   deallocate_record_components(loader_data, record_components());
 644   set_record_components(NULL);
 645 
 646   if (method_ordering() != NULL &amp;&amp;
 647       method_ordering() != Universe::the_empty_int_array() &amp;&amp;
 648       !method_ordering()-&gt;is_shared()) {
 649     MetadataFactory::free_array&lt;int&gt;(loader_data, method_ordering());
 650   }
 651   set_method_ordering(NULL);
 652 
 653   // default methods can be empty
 654   if (default_methods() != NULL &amp;&amp;
 655       default_methods() != Universe::the_empty_method_array() &amp;&amp;
 656       !default_methods()-&gt;is_shared()) {
 657     MetadataFactory::free_array&lt;Method*&gt;(loader_data, default_methods());
 658   }
 659   // Do NOT deallocate the default methods, they are owned by superinterfaces.
 660   set_default_methods(NULL);
 661 
 662   // default methods vtable indices can be empty
 663   if (default_vtable_indices() != NULL &amp;&amp;
 664       !default_vtable_indices()-&gt;is_shared()) {
 665     MetadataFactory::free_array&lt;int&gt;(loader_data, default_vtable_indices());
 666   }
 667   set_default_vtable_indices(NULL);
 668 
 669 
 670   // This array is in Klass, but remove it with the InstanceKlass since
 671   // this place would be the only caller and it can share memory with transitive
 672   // interfaces.
 673   if (secondary_supers() != NULL &amp;&amp;
 674       secondary_supers() != Universe::the_empty_klass_array() &amp;&amp;
 675       // see comments in compute_secondary_supers about the following cast
 676       (address)(secondary_supers()) != (address)(transitive_interfaces()) &amp;&amp;
 677       !secondary_supers()-&gt;is_shared()) {
 678     MetadataFactory::free_array&lt;Klass*&gt;(loader_data, secondary_supers());
 679   }
 680   set_secondary_supers(NULL);
 681 
 682   deallocate_interfaces(loader_data, super(), local_interfaces(), transitive_interfaces());
 683   set_transitive_interfaces(NULL);
 684   set_local_interfaces(NULL);
 685 
 686   if (fields() != NULL &amp;&amp; !fields()-&gt;is_shared()) {
 687     MetadataFactory::free_array&lt;jushort&gt;(loader_data, fields());
 688   }
 689   set_fields(NULL, 0);
 690 
 691   // If a method from a redefined class is using this constant pool, don&#39;t
 692   // delete it, yet.  The new class&#39;s previous version will point to this.
 693   if (constants() != NULL) {
 694     assert (!constants()-&gt;on_stack(), &quot;shouldn&#39;t be called if anything is onstack&quot;);
 695     if (!constants()-&gt;is_shared()) {
 696       MetadataFactory::free_metadata(loader_data, constants());
 697     }
 698     // Delete any cached resolution errors for the constant pool
 699     SystemDictionary::delete_resolution_error(constants());
 700 
 701     set_constants(NULL);
 702   }
 703 
 704   if (inner_classes() != NULL &amp;&amp;
 705       inner_classes() != Universe::the_empty_short_array() &amp;&amp;
 706       !inner_classes()-&gt;is_shared()) {
 707     MetadataFactory::free_array&lt;jushort&gt;(loader_data, inner_classes());
 708   }
 709   set_inner_classes(NULL);
 710 
 711   if (nest_members() != NULL &amp;&amp;
 712       nest_members() != Universe::the_empty_short_array() &amp;&amp;
 713       !nest_members()-&gt;is_shared()) {
 714     MetadataFactory::free_array&lt;jushort&gt;(loader_data, nest_members());
 715   }
 716   set_nest_members(NULL);
 717 
 718   // We should deallocate the Annotations instance if it&#39;s not in shared spaces.
 719   if (annotations() != NULL &amp;&amp; !annotations()-&gt;is_shared()) {
 720     MetadataFactory::free_metadata(loader_data, annotations());
 721   }
 722   set_annotations(NULL);
 723 
 724   if (Arguments::is_dumping_archive()) {
 725     SystemDictionaryShared::remove_dumptime_info(this);
 726   }
 727 }
 728 
 729 bool InstanceKlass::should_be_initialized() const {
 730   return !is_initialized();
 731 }
 732 
 733 klassItable InstanceKlass::itable() const {
 734   return klassItable(const_cast&lt;InstanceKlass*&gt;(this));
 735 }
 736 
 737 void InstanceKlass::eager_initialize(Thread *thread) {
 738   if (!EagerInitialization) return;
 739 
 740   if (this-&gt;is_not_initialized()) {
 741     // abort if the the class has a class initializer
 742     if (this-&gt;class_initializer() != NULL) return;
 743 
 744     // abort if it is java.lang.Object (initialization is handled in genesis)
 745     Klass* super_klass = super();
 746     if (super_klass == NULL) return;
 747 
 748     // abort if the super class should be initialized
 749     if (!InstanceKlass::cast(super_klass)-&gt;is_initialized()) return;
 750 
 751     // call body to expose the this pointer
 752     eager_initialize_impl();
 753   }
 754 }
 755 
 756 // JVMTI spec thinks there are signers and protection domain in the
 757 // instanceKlass.  These accessors pretend these fields are there.
 758 // The hprof specification also thinks these fields are in InstanceKlass.
 759 oop InstanceKlass::protection_domain() const {
 760   // return the protection_domain from the mirror
 761   return java_lang_Class::protection_domain(java_mirror());
 762 }
 763 
 764 // To remove these from requires an incompatible change and CCC request.
 765 objArrayOop InstanceKlass::signers() const {
 766   // return the signers from the mirror
 767   return java_lang_Class::signers(java_mirror());
 768 }
 769 
 770 oop InstanceKlass::init_lock() const {
 771   // return the init lock from the mirror
 772   oop lock = java_lang_Class::init_lock(java_mirror());
 773   // Prevent reordering with any access of initialization state
 774   OrderAccess::loadload();
 775   assert((oop)lock != NULL || !is_not_initialized(), // initialized or in_error state
 776          &quot;only fully initialized state can have a null lock&quot;);
 777   return lock;
 778 }
 779 
 780 // Set the initialization lock to null so the object can be GC&#39;ed.  Any racing
 781 // threads to get this lock will see a null lock and will not lock.
 782 // That&#39;s okay because they all check for initialized state after getting
 783 // the lock and return.
 784 void InstanceKlass::fence_and_clear_init_lock() {
 785   // make sure previous stores are all done, notably the init_state.
 786   OrderAccess::storestore();
 787   java_lang_Class::set_init_lock(java_mirror(), NULL);
 788   assert(!is_not_initialized(), &quot;class must be initialized now&quot;);
 789 }
 790 
 791 void InstanceKlass::eager_initialize_impl() {
 792   EXCEPTION_MARK;
 793   HandleMark hm(THREAD);
 794   Handle h_init_lock(THREAD, init_lock());
 795   ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);
 796 
 797   // abort if someone beat us to the initialization
 798   if (!is_not_initialized()) return;  // note: not equivalent to is_initialized()
 799 
 800   ClassState old_state = init_state();
 801   link_class_impl(THREAD);
 802   if (HAS_PENDING_EXCEPTION) {
 803     CLEAR_PENDING_EXCEPTION;
 804     // Abort if linking the class throws an exception.
 805 
 806     // Use a test to avoid redundantly resetting the state if there&#39;s
 807     // no change.  Set_init_state() asserts that state changes make
 808     // progress, whereas here we might just be spinning in place.
 809     if (old_state != _init_state)
 810       set_init_state(old_state);
 811   } else {
 812     // linking successfull, mark class as initialized
 813     set_init_state(fully_initialized);
 814     fence_and_clear_init_lock();
 815     // trace
 816     if (log_is_enabled(Info, class, init)) {
 817       ResourceMark rm(THREAD);
 818       log_info(class, init)(&quot;[Initialized %s without side effects]&quot;, external_name());
 819     }
 820   }
 821 }
 822 
 823 
 824 // See &quot;The Virtual Machine Specification&quot; section 2.16.5 for a detailed explanation of the class initialization
 825 // process. The step comments refers to the procedure described in that section.
 826 // Note: implementation moved to static method to expose the this pointer.
 827 void InstanceKlass::initialize(TRAPS) {
 828   if (this-&gt;should_be_initialized()) {
 829     initialize_impl(CHECK);
 830     // Note: at this point the class may be initialized
 831     //       OR it may be in the state of being initialized
 832     //       in case of recursive initialization!
 833   } else {
 834     assert(is_initialized(), &quot;sanity check&quot;);
 835   }
 836 }
 837 
 838 
 839 bool InstanceKlass::verify_code(TRAPS) {
 840   // 1) Verify the bytecodes
 841   return Verifier::verify(this, should_verify_class(), THREAD);
 842 }
 843 
 844 void InstanceKlass::link_class(TRAPS) {
 845   assert(is_loaded(), &quot;must be loaded&quot;);
 846   if (!is_linked()) {
 847     link_class_impl(CHECK);
 848   }
 849 }
 850 
 851 // Called to verify that a class can link during initialization, without
 852 // throwing a VerifyError.
 853 bool InstanceKlass::link_class_or_fail(TRAPS) {
 854   assert(is_loaded(), &quot;must be loaded&quot;);
 855   if (!is_linked()) {
 856     link_class_impl(CHECK_false);
 857   }
 858   return is_linked();
 859 }
 860 
 861 bool InstanceKlass::link_class_impl(TRAPS) {
 862   if (DumpSharedSpaces &amp;&amp; SystemDictionaryShared::has_class_failed_verification(this)) {
 863     // This is for CDS dumping phase only -- we use the in_error_state to indicate that
 864     // the class has failed verification. Throwing the NoClassDefFoundError here is just
 865     // a convenient way to stop repeat attempts to verify the same (bad) class.
 866     //
 867     // Note that the NoClassDefFoundError is not part of the JLS, and should not be thrown
 868     // if we are executing Java code. This is not a problem for CDS dumping phase since
 869     // it doesn&#39;t execute any Java code.
 870     ResourceMark rm(THREAD);
 871     Exceptions::fthrow(THREAD_AND_LOCATION,
 872                        vmSymbols::java_lang_NoClassDefFoundError(),
 873                        &quot;Class %s, or one of its supertypes, failed class initialization&quot;,
 874                        external_name());
 875     return false;
 876   }
 877   // return if already verified
 878   if (is_linked()) {
 879     return true;
 880   }
 881 
 882   // Timing
 883   // timer handles recursion
 884   assert(THREAD-&gt;is_Java_thread(), &quot;non-JavaThread in link_class_impl&quot;);
 885   JavaThread* jt = (JavaThread*)THREAD;
 886 
 887   // link super class before linking this class
 888   Klass* super_klass = super();
 889   if (super_klass != NULL) {
 890     if (super_klass-&gt;is_interface()) {  // check if super class is an interface
 891       ResourceMark rm(THREAD);
 892       Exceptions::fthrow(
 893         THREAD_AND_LOCATION,
 894         vmSymbols::java_lang_IncompatibleClassChangeError(),
 895         &quot;class %s has interface %s as super class&quot;,
 896         external_name(),
 897         super_klass-&gt;external_name()
 898       );
 899       return false;
 900     }
 901 
 902     InstanceKlass* ik_super = InstanceKlass::cast(super_klass);
 903     ik_super-&gt;link_class_impl(CHECK_false);
 904   }
 905 
 906   // link all interfaces implemented by this class before linking this class
 907   Array&lt;InstanceKlass*&gt;* interfaces = local_interfaces();
 908   int num_interfaces = interfaces-&gt;length();
 909   for (int index = 0; index &lt; num_interfaces; index++) {
 910     InstanceKlass* interk = interfaces-&gt;at(index);
 911     interk-&gt;link_class_impl(CHECK_false);
 912   }
 913 
 914 
 915   // If a class declares a method that uses an inline class as an argument
 916   // type or return inline type, this inline class must be loaded during the
 917   // linking of this class because size and properties of the inline class
 918   // must be known in order to be able to perform inline type optimizations.
 919   // The implementation below is an approximation of this rule, the code
 920   // iterates over all methods of the current class (including overridden
 921   // methods), not only the methods declared by this class. This
 922   // approximation makes the code simpler, and doesn&#39;t change the semantic
 923   // because classes declaring methods overridden by the current class are
 924   // linked (and have performed their own pre-loading) before the linking
 925   // of the current class.
 926 
 927 
 928   // Note:
 929   // Inline class types used for flattenable fields are loaded during
 930   // the loading phase (see ClassFileParser::post_process_parsed_stream()).
 931   // Inline class types used as element types for array creation
 932   // are not pre-loaded. Their loading is triggered by either anewarray
 933   // or multianewarray bytecodes.
 934 
 935   // Could it be possible to do the following processing only if the
 936   // class uses inline types?
 937   {
 938     ResourceMark rm(THREAD);
 939     for (int i = 0; i &lt; methods()-&gt;length(); i++) {
 940       Method* m = methods()-&gt;at(i);
 941       for (SignatureStream ss(m-&gt;signature()); !ss.is_done(); ss.next()) {
 942         if (ss.is_reference()) {
 943           if (ss.is_array()) {
 944             ss.skip_array_prefix();
 945           }
 946           if (ss.type() == T_VALUETYPE) {
 947             Symbol* symb = ss.as_symbol();
 948 
 949             oop loader = class_loader();
 950             oop protection_domain = this-&gt;protection_domain();
 951             Klass* klass = SystemDictionary::resolve_or_fail(symb,
 952                                                              Handle(THREAD, loader), Handle(THREAD, protection_domain), true,
 953                                                              CHECK_false);
 954             if (klass == NULL) {
 955               THROW_(vmSymbols::java_lang_LinkageError(), false);
 956             }
 957             if (!klass-&gt;is_value()) {
 958               Exceptions::fthrow(
 959                 THREAD_AND_LOCATION,
 960                 vmSymbols::java_lang_IncompatibleClassChangeError(),
 961                 &quot;class %s is not an inline type&quot;,
 962                 klass-&gt;external_name());
 963             }
 964           }
 965         }
 966       }
 967     }
 968   }
 969 
 970   // in case the class is linked in the process of linking its superclasses
 971   if (is_linked()) {
 972     return true;
 973   }
 974 
 975   // trace only the link time for this klass that includes
 976   // the verification time
 977   PerfClassTraceTime vmtimer(ClassLoader::perf_class_link_time(),
 978                              ClassLoader::perf_class_link_selftime(),
 979                              ClassLoader::perf_classes_linked(),
 980                              jt-&gt;get_thread_stat()-&gt;perf_recursion_counts_addr(),
 981                              jt-&gt;get_thread_stat()-&gt;perf_timers_addr(),
 982                              PerfClassTraceTime::CLASS_LINK);
 983 
 984   // verification &amp; rewriting
 985   {
 986     HandleMark hm(THREAD);
 987     Handle h_init_lock(THREAD, init_lock());
 988     ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);
 989     // rewritten will have been set if loader constraint error found
 990     // on an earlier link attempt
 991     // don&#39;t verify or rewrite if already rewritten
 992     //
 993 
 994     if (!is_linked()) {
 995       if (!is_rewritten()) {
 996         {
 997           bool verify_ok = verify_code(THREAD);
 998           if (!verify_ok) {
 999             return false;
1000           }
1001         }
1002 
1003         // Just in case a side-effect of verify linked this class already
1004         // (which can sometimes happen since the verifier loads classes
1005         // using custom class loaders, which are free to initialize things)
1006         if (is_linked()) {
1007           return true;
1008         }
1009 
1010         // also sets rewritten
1011         rewrite_class(CHECK_false);
1012       } else if (is_shared()) {
1013         SystemDictionaryShared::check_verification_constraints(this, CHECK_false);
1014       }
1015 
1016       // relocate jsrs and link methods after they are all rewritten
1017       link_methods(CHECK_false);
1018 
1019       // Initialize the vtable and interface table after
1020       // methods have been rewritten since rewrite may
1021       // fabricate new Method*s.
1022       // also does loader constraint checking
1023       //
1024       // initialize_vtable and initialize_itable need to be rerun for
1025       // a shared class if the class is not loaded by the NULL classloader.
1026       ClassLoaderData * loader_data = class_loader_data();
1027       if (!(is_shared() &amp;&amp;
1028             loader_data-&gt;is_the_null_class_loader_data())) {
1029         vtable().initialize_vtable(true, CHECK_false);
1030         itable().initialize_itable(true, CHECK_false);
1031       }
1032 #ifdef ASSERT
1033       else {
1034         vtable().verify(tty, true);
1035         // In case itable verification is ever added.
1036         // itable().verify(tty, true);
1037       }
1038 #endif
1039 
1040       set_init_state(linked);
1041       if (JvmtiExport::should_post_class_prepare()) {
1042         Thread *thread = THREAD;
1043         assert(thread-&gt;is_Java_thread(), &quot;thread-&gt;is_Java_thread()&quot;);
1044         JvmtiExport::post_class_prepare((JavaThread *) thread, this);
1045       }
1046     }
1047   }
1048   return true;
1049 }
1050 
1051 // Rewrite the byte codes of all of the methods of a class.
1052 // The rewriter must be called exactly once. Rewriting must happen after
1053 // verification but before the first method of the class is executed.
1054 void InstanceKlass::rewrite_class(TRAPS) {
1055   assert(is_loaded(), &quot;must be loaded&quot;);
1056   if (is_rewritten()) {
1057     assert(is_shared(), &quot;rewriting an unshared class?&quot;);
1058     return;
1059   }
1060   Rewriter::rewrite(this, CHECK);
1061   set_rewritten();
1062 }
1063 
1064 // Now relocate and link method entry points after class is rewritten.
1065 // This is outside is_rewritten flag. In case of an exception, it can be
1066 // executed more than once.
1067 void InstanceKlass::link_methods(TRAPS) {
1068   int len = methods()-&gt;length();
1069   for (int i = len-1; i &gt;= 0; i--) {
1070     methodHandle m(THREAD, methods()-&gt;at(i));
1071 
1072     // Set up method entry points for compiler and interpreter    .
1073     m-&gt;link_method(m, CHECK);
1074   }
1075 }
1076 
1077 // Eagerly initialize superinterfaces that declare default methods (concrete instance: any access)
1078 void InstanceKlass::initialize_super_interfaces(TRAPS) {
1079   assert (has_nonstatic_concrete_methods(), &quot;caller should have checked this&quot;);
1080   for (int i = 0; i &lt; local_interfaces()-&gt;length(); ++i) {
1081     InstanceKlass* ik = local_interfaces()-&gt;at(i);
1082 
1083     // Initialization is depth first search ie. we start with top of the inheritance tree
1084     // has_nonstatic_concrete_methods drives searching superinterfaces since it
1085     // means has_nonstatic_concrete_methods in its superinterface hierarchy
1086     if (ik-&gt;has_nonstatic_concrete_methods()) {
1087       ik-&gt;initialize_super_interfaces(CHECK);
1088     }
1089 
1090     // Only initialize() interfaces that &quot;declare&quot; concrete methods.
1091     if (ik-&gt;should_be_initialized() &amp;&amp; ik-&gt;declares_nonstatic_concrete_methods()) {
1092       ik-&gt;initialize(CHECK);
1093     }
1094   }
1095 }
1096 
1097 void InstanceKlass::initialize_impl(TRAPS) {
1098   HandleMark hm(THREAD);
1099 
1100   // Make sure klass is linked (verified) before initialization
1101   // A class could already be verified, since it has been reflected upon.
1102   link_class(CHECK);
1103 
1104   DTRACE_CLASSINIT_PROBE(required, -1);
1105 
1106   bool wait = false;
1107 
1108   assert(THREAD-&gt;is_Java_thread(), &quot;non-JavaThread in initialize_impl&quot;);
1109   JavaThread* jt = (JavaThread*)THREAD;
1110 
1111   // refer to the JVM book page 47 for description of steps
1112   // Step 1
1113   {
1114     Handle h_init_lock(THREAD, init_lock());
1115     ObjectLocker ol(h_init_lock, THREAD, h_init_lock() != NULL);
1116 
1117     // Step 2
1118     // If we were to use wait() instead of waitInterruptibly() then
1119     // we might end up throwing IE from link/symbol resolution sites
1120     // that aren&#39;t expected to throw.  This would wreak havoc.  See 6320309.
1121     while (is_being_initialized() &amp;&amp; !is_reentrant_initialization(jt)) {
1122       wait = true;
1123       jt-&gt;set_class_to_be_initialized(this);
1124       ol.wait_uninterruptibly(jt);
1125       jt-&gt;set_class_to_be_initialized(NULL);
1126     }
1127 
1128     // Step 3
1129     if (is_being_initialized() &amp;&amp; is_reentrant_initialization(jt)) {
1130       DTRACE_CLASSINIT_PROBE_WAIT(recursive, -1, wait);
1131       return;
1132     }
1133 
1134     // Step 4
1135     if (is_initialized()) {
1136       DTRACE_CLASSINIT_PROBE_WAIT(concurrent, -1, wait);
1137       return;
1138     }
1139 
1140     // Step 5
1141     if (is_in_error_state()) {
1142       DTRACE_CLASSINIT_PROBE_WAIT(erroneous, -1, wait);
1143       ResourceMark rm(THREAD);
1144       const char* desc = &quot;Could not initialize class &quot;;
1145       const char* className = external_name();
1146       size_t msglen = strlen(desc) + strlen(className) + 1;
1147       char* message = NEW_RESOURCE_ARRAY(char, msglen);
1148       if (NULL == message) {
1149         // Out of memory: can&#39;t create detailed error message
1150           THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), className);
1151       } else {
1152         jio_snprintf(message, msglen, &quot;%s%s&quot;, desc, className);
1153           THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), message);
1154       }
1155     }
1156 
1157     // Step 6
1158     set_init_state(being_initialized);
1159     set_init_thread(jt);
1160   }
1161 
1162   // Step 7
1163   // Next, if C is a class rather than an interface, initialize it&#39;s super class and super
1164   // interfaces.
1165   if (!is_interface()) {
1166     Klass* super_klass = super();
1167     if (super_klass != NULL &amp;&amp; super_klass-&gt;should_be_initialized()) {
1168       super_klass-&gt;initialize(THREAD);
1169     }
1170     // If C implements any interface that declares a non-static, concrete method,
1171     // the initialization of C triggers initialization of its super interfaces.
1172     // Only need to recurse if has_nonstatic_concrete_methods which includes declaring and
1173     // having a superinterface that declares, non-static, concrete methods
1174     if (!HAS_PENDING_EXCEPTION &amp;&amp; has_nonstatic_concrete_methods()) {
1175       initialize_super_interfaces(THREAD);
1176     }
1177 
1178     // If any exceptions, complete abruptly, throwing the same exception as above.
1179     if (HAS_PENDING_EXCEPTION) {
1180       Handle e(THREAD, PENDING_EXCEPTION);
1181       CLEAR_PENDING_EXCEPTION;
1182       {
1183         EXCEPTION_MARK;
1184         // Locks object, set state, and notify all waiting threads
1185         set_initialization_state_and_notify(initialization_error, THREAD);
1186         CLEAR_PENDING_EXCEPTION;
1187       }
1188       DTRACE_CLASSINIT_PROBE_WAIT(super__failed, -1, wait);
1189       THROW_OOP(e());
1190     }
1191   }
1192 
1193   // Step 8
1194   // Initialize classes of flattenable fields
1195   {
1196     for (AllFieldStream fs(this); !fs.done(); fs.next()) {
1197       if (fs.is_flattenable()) {
1198         Klass* klass = this-&gt;get_value_field_klass_or_null(fs.index());
1199         if (klass == NULL) {
1200           assert(fs.access_flags().is_static() &amp;&amp; fs.access_flags().is_flattenable(),
1201               &quot;Otherwise should have been pre-loaded&quot;);
1202           klass = SystemDictionary::resolve_or_fail(field_signature(fs.index())-&gt;fundamental_name(THREAD),
1203               Handle(THREAD, class_loader()),
1204               Handle(THREAD, protection_domain()),
1205               true, CHECK);
1206           if (klass == NULL) {
1207             THROW(vmSymbols::java_lang_NoClassDefFoundError());
1208           }
1209           if (!klass-&gt;is_value()) {
1210             THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
1211           }
1212           this-&gt;set_value_field_klass(fs.index(), klass);
1213         }
1214         InstanceKlass::cast(klass)-&gt;initialize(CHECK);
1215         if (fs.access_flags().is_static()) {
1216           if (java_mirror()-&gt;obj_field(fs.offset()) == NULL) {
1217             java_mirror()-&gt;obj_field_put(fs.offset(), ValueKlass::cast(klass)-&gt;default_value());
1218           }
1219         }
1220       }
1221     }
1222   }
1223 
1224 
1225   // Look for aot compiled methods for this klass, including class initializer.
1226   AOTLoader::load_for_klass(this, THREAD);
1227 
1228   // Step 9
1229   {
1230     DTRACE_CLASSINIT_PROBE_WAIT(clinit, -1, wait);
1231     // Timer includes any side effects of class initialization (resolution,
1232     // etc), but not recursive entry into call_class_initializer().
1233     PerfClassTraceTime timer(ClassLoader::perf_class_init_time(),
1234                              ClassLoader::perf_class_init_selftime(),
1235                              ClassLoader::perf_classes_inited(),
1236                              jt-&gt;get_thread_stat()-&gt;perf_recursion_counts_addr(),
1237                              jt-&gt;get_thread_stat()-&gt;perf_timers_addr(),
1238                              PerfClassTraceTime::CLASS_CLINIT);
1239     call_class_initializer(THREAD);
1240   }
1241 
1242   // Step 10
1243   if (!HAS_PENDING_EXCEPTION) {
1244     set_initialization_state_and_notify(fully_initialized, CHECK);
1245     {
1246       debug_only(vtable().verify(tty, true);)
1247     }
1248   }
1249   else {
1250     // Step 11 and 12
1251     Handle e(THREAD, PENDING_EXCEPTION);
1252     CLEAR_PENDING_EXCEPTION;
1253     // JVMTI has already reported the pending exception
1254     // JVMTI internal flag reset is needed in order to report ExceptionInInitializerError
1255     JvmtiExport::clear_detected_exception(jt);
1256     {
1257       EXCEPTION_MARK;
1258       set_initialization_state_and_notify(initialization_error, THREAD);
1259       CLEAR_PENDING_EXCEPTION;   // ignore any exception thrown, class initialization error is thrown below
1260       // JVMTI has already reported the pending exception
1261       // JVMTI internal flag reset is needed in order to report ExceptionInInitializerError
1262       JvmtiExport::clear_detected_exception(jt);
1263     }
1264     DTRACE_CLASSINIT_PROBE_WAIT(error, -1, wait);
1265     if (e-&gt;is_a(SystemDictionary::Error_klass())) {
1266       THROW_OOP(e());
1267     } else {
1268       JavaCallArguments args(e);
1269       THROW_ARG(vmSymbols::java_lang_ExceptionInInitializerError(),
1270                 vmSymbols::throwable_void_signature(),
1271                 &amp;args);
1272     }
1273   }
1274   DTRACE_CLASSINIT_PROBE_WAIT(end, -1, wait);
1275 }
1276 
1277 
1278 void InstanceKlass::set_initialization_state_and_notify(ClassState state, TRAPS) {
1279   Handle h_init_lock(THREAD, init_lock());
1280   if (h_init_lock() != NULL) {
1281     ObjectLocker ol(h_init_lock, THREAD);
1282     set_init_thread(NULL); // reset _init_thread before changing _init_state
1283     set_init_state(state);
1284     fence_and_clear_init_lock();
1285     ol.notify_all(CHECK);
1286   } else {
1287     assert(h_init_lock() != NULL, &quot;The initialization state should never be set twice&quot;);
1288     set_init_thread(NULL); // reset _init_thread before changing _init_state
1289     set_init_state(state);
1290   }
1291 }
1292 
1293 Klass* InstanceKlass::implementor() const {
1294   Klass* volatile* k = adr_implementor();
1295   if (k == NULL) {
1296     return NULL;
1297   } else {
1298     // This load races with inserts, and therefore needs acquire.
1299     Klass* kls = Atomic::load_acquire(k);
1300     if (kls != NULL &amp;&amp; !kls-&gt;is_loader_alive()) {
1301       return NULL;  // don&#39;t return unloaded class
1302     } else {
1303       return kls;
1304     }
1305   }
1306 }
1307 
1308 
1309 void InstanceKlass::set_implementor(Klass* k) {
1310   assert_locked_or_safepoint(Compile_lock);
1311   assert(is_interface(), &quot;not interface&quot;);
1312   Klass* volatile* addr = adr_implementor();
1313   assert(addr != NULL, &quot;null addr&quot;);
1314   if (addr != NULL) {
1315     Atomic::release_store(addr, k);
1316   }
1317 }
1318 
1319 int  InstanceKlass::nof_implementors() const {
1320   Klass* k = implementor();
1321   if (k == NULL) {
1322     return 0;
1323   } else if (k != this) {
1324     return 1;
1325   } else {
1326     return 2;
1327   }
1328 }
1329 
1330 // The embedded _implementor field can only record one implementor.
1331 // When there are more than one implementors, the _implementor field
1332 // is set to the interface Klass* itself. Following are the possible
1333 // values for the _implementor field:
1334 //   NULL                  - no implementor
1335 //   implementor Klass*    - one implementor
1336 //   self                  - more than one implementor
1337 //
1338 // The _implementor field only exists for interfaces.
1339 void InstanceKlass::add_implementor(Klass* k) {
1340   if (Universe::is_fully_initialized()) {
1341     assert_lock_strong(Compile_lock);
1342   }
1343   assert(is_interface(), &quot;not interface&quot;);
1344   // Filter out my subinterfaces.
1345   // (Note: Interfaces are never on the subklass list.)
1346   if (InstanceKlass::cast(k)-&gt;is_interface()) return;
1347 
1348   // Filter out subclasses whose supers already implement me.
1349   // (Note: CHA must walk subclasses of direct implementors
1350   // in order to locate indirect implementors.)
1351   Klass* sk = k-&gt;super();
1352   if (sk != NULL &amp;&amp; InstanceKlass::cast(sk)-&gt;implements_interface(this))
1353     // We only need to check one immediate superclass, since the
1354     // implements_interface query looks at transitive_interfaces.
1355     // Any supers of the super have the same (or fewer) transitive_interfaces.
1356     return;
1357 
1358   Klass* ik = implementor();
1359   if (ik == NULL) {
1360     set_implementor(k);
1361   } else if (ik != this &amp;&amp; ik != k) {
1362     // There is already an implementor. Use itself as an indicator of
1363     // more than one implementors.
1364     set_implementor(this);
1365   }
1366 
1367   // The implementor also implements the transitive_interfaces
1368   for (int index = 0; index &lt; local_interfaces()-&gt;length(); index++) {
1369     InstanceKlass::cast(local_interfaces()-&gt;at(index))-&gt;add_implementor(k);
1370   }
1371 }
1372 
1373 void InstanceKlass::init_implementor() {
1374   if (is_interface()) {
1375     set_implementor(NULL);
1376   }
1377 }
1378 
1379 
1380 void InstanceKlass::process_interfaces(Thread *thread) {
1381   // link this class into the implementors list of every interface it implements
1382   for (int i = local_interfaces()-&gt;length() - 1; i &gt;= 0; i--) {
1383     assert(local_interfaces()-&gt;at(i)-&gt;is_klass(), &quot;must be a klass&quot;);
1384     InstanceKlass* interf = InstanceKlass::cast(local_interfaces()-&gt;at(i));
1385     assert(interf-&gt;is_interface(), &quot;expected interface&quot;);
1386     interf-&gt;add_implementor(this);
1387   }
1388 }
1389 
1390 bool InstanceKlass::can_be_primary_super_slow() const {
1391   if (is_interface())
1392     return false;
1393   else
1394     return Klass::can_be_primary_super_slow();
1395 }
1396 
1397 GrowableArray&lt;Klass*&gt;* InstanceKlass::compute_secondary_supers(int num_extra_slots,
1398                                                                Array&lt;InstanceKlass*&gt;* transitive_interfaces) {
1399   // The secondaries are the implemented interfaces.
1400   Array&lt;InstanceKlass*&gt;* interfaces = transitive_interfaces;
1401   int num_secondaries = num_extra_slots + interfaces-&gt;length();
1402   if (num_secondaries == 0) {
1403     // Must share this for correct bootstrapping!
1404     set_secondary_supers(Universe::the_empty_klass_array());
1405     return NULL;
1406   } else if (num_extra_slots == 0) {
1407     // The secondary super list is exactly the same as the transitive interfaces, so
1408     // let&#39;s use it instead of making a copy.
1409     // Redefine classes has to be careful not to delete this!
1410     // We need the cast because Array&lt;Klass*&gt; is NOT a supertype of Array&lt;InstanceKlass*&gt;,
1411     // (but it&#39;s safe to do here because we won&#39;t write into _secondary_supers from this point on).
1412     set_secondary_supers((Array&lt;Klass*&gt;*)(address)interfaces);
1413     return NULL;
1414   } else {
1415     // Copy transitive interfaces to a temporary growable array to be constructed
1416     // into the secondary super list with extra slots.
1417     GrowableArray&lt;Klass*&gt;* secondaries = new GrowableArray&lt;Klass*&gt;(interfaces-&gt;length());
1418     for (int i = 0; i &lt; interfaces-&gt;length(); i++) {
1419       secondaries-&gt;push(interfaces-&gt;at(i));
1420     }
1421     return secondaries;
1422   }
1423 }
1424 
1425 bool InstanceKlass::implements_interface(Klass* k) const {
1426   if (this == k) return true;
1427   assert(k-&gt;is_interface(), &quot;should be an interface class&quot;);
1428   for (int i = 0; i &lt; transitive_interfaces()-&gt;length(); i++) {
1429     if (transitive_interfaces()-&gt;at(i) == k) {
1430       return true;
1431     }
1432   }
1433   return false;
1434 }
1435 
1436 bool InstanceKlass::is_same_or_direct_interface(Klass *k) const {
1437   // Verify direct super interface
1438   if (this == k) return true;
1439   assert(k-&gt;is_interface(), &quot;should be an interface class&quot;);
1440   for (int i = 0; i &lt; local_interfaces()-&gt;length(); i++) {
1441     if (local_interfaces()-&gt;at(i) == k) {
1442       return true;
1443     }
1444   }
1445   return false;
1446 }
1447 
1448 objArrayOop InstanceKlass::allocate_objArray(int n, int length, TRAPS) {
1449   check_array_allocation_length(length, arrayOopDesc::max_array_length(T_OBJECT), CHECK_NULL);
1450   int size = objArrayOopDesc::object_size(length);
1451   Klass* ak = array_klass(n, CHECK_NULL);
1452   objArrayOop o = (objArrayOop)Universe::heap()-&gt;array_allocate(ak, size, length,
1453                                                                 /* do_zero */ true, CHECK_NULL);
1454   return o;
1455 }
1456 
1457 instanceOop InstanceKlass::register_finalizer(instanceOop i, TRAPS) {
1458   if (TraceFinalizerRegistration) {
1459     tty-&gt;print(&quot;Registered &quot;);
1460     i-&gt;print_value_on(tty);
1461     tty-&gt;print_cr(&quot; (&quot; INTPTR_FORMAT &quot;) as finalizable&quot;, p2i(i));
1462   }
1463   instanceHandle h_i(THREAD, i);
1464   // Pass the handle as argument, JavaCalls::call expects oop as jobjects
1465   JavaValue result(T_VOID);
1466   JavaCallArguments args(h_i);
1467   methodHandle mh (THREAD, Universe::finalizer_register_method());
1468   JavaCalls::call(&amp;result, mh, &amp;args, CHECK_NULL);
1469   return h_i();
1470 }
1471 
1472 instanceOop InstanceKlass::allocate_instance(TRAPS) {
1473   bool has_finalizer_flag = has_finalizer(); // Query before possible GC
1474   int size = size_helper();  // Query before forming handle.
1475 
1476   instanceOop i;
1477 
1478   i = (instanceOop)Universe::heap()-&gt;obj_allocate(this, size, CHECK_NULL);
1479   if (has_finalizer_flag &amp;&amp; !RegisterFinalizersAtInit) {
1480     i = register_finalizer(i, CHECK_NULL);
1481   }
1482   return i;
1483 }
1484 
1485 instanceHandle InstanceKlass::allocate_instance_handle(TRAPS) {
1486   return instanceHandle(THREAD, allocate_instance(THREAD));
1487 }
1488 
1489 void InstanceKlass::check_valid_for_instantiation(bool throwError, TRAPS) {
1490   if (is_interface() || is_abstract()) {
1491     ResourceMark rm(THREAD);
1492     THROW_MSG(throwError ? vmSymbols::java_lang_InstantiationError()
1493               : vmSymbols::java_lang_InstantiationException(), external_name());
1494   }
1495   if (this == SystemDictionary::Class_klass()) {
1496     ResourceMark rm(THREAD);
1497     THROW_MSG(throwError ? vmSymbols::java_lang_IllegalAccessError()
1498               : vmSymbols::java_lang_IllegalAccessException(), external_name());
1499   }
1500 }
1501 
1502 Klass* InstanceKlass::array_klass_impl(bool or_null, int n, TRAPS) {
1503   // Need load-acquire for lock-free read
1504   if (array_klasses_acquire() == NULL) {
1505     if (or_null) return NULL;
1506 
1507     ResourceMark rm(THREAD);
1508     JavaThread *jt = (JavaThread *)THREAD;
1509     {
1510       // Atomic creation of array_klasses
1511       MutexLocker ma(THREAD, MultiArray_lock);
1512 
1513       // Check if update has already taken place
1514       if (array_klasses() == NULL) {
1515         Klass*    k = ObjArrayKlass::allocate_objArray_klass(1, this, CHECK_NULL);
1516         // use &#39;release&#39; to pair with lock-free load
1517         release_set_array_klasses(k);
1518       }
1519     }
1520   }
1521   // _this will always be set at this point
1522   ObjArrayKlass* oak = (ObjArrayKlass*)array_klasses();
1523   if (or_null) {
1524     return oak-&gt;array_klass_or_null(n);
1525   }
1526   return oak-&gt;array_klass(n, THREAD);
1527 }
1528 
1529 Klass* InstanceKlass::array_klass_impl(bool or_null, TRAPS) {
1530   return array_klass_impl(or_null, 1, THREAD);
1531 }
1532 
1533 static int call_class_initializer_counter = 0;   // for debugging
1534 
1535 Method* InstanceKlass::class_initializer() const {
1536   Method* clinit = find_method(
1537       vmSymbols::class_initializer_name(), vmSymbols::void_method_signature());
1538   if (clinit != NULL &amp;&amp; clinit-&gt;is_class_initializer()) {
1539     return clinit;
1540   }
1541   return NULL;
1542 }
1543 
1544 void InstanceKlass::call_class_initializer(TRAPS) {
1545   if (ReplayCompiles &amp;&amp;
1546       (ReplaySuppressInitializers == 1 ||
1547        (ReplaySuppressInitializers &gt;= 2 &amp;&amp; class_loader() != NULL))) {
1548     // Hide the existence of the initializer for the purpose of replaying the compile
1549     return;
1550   }
1551 
1552   methodHandle h_method(THREAD, class_initializer());
1553   assert(!is_initialized(), &quot;we cannot initialize twice&quot;);
1554   LogTarget(Info, class, init) lt;
1555   if (lt.is_enabled()) {
1556     ResourceMark rm(THREAD);
1557     LogStream ls(lt);
1558     ls.print(&quot;%d Initializing &quot;, call_class_initializer_counter++);
1559     name()-&gt;print_value_on(&amp;ls);
1560     ls.print_cr(&quot;%s (&quot; INTPTR_FORMAT &quot;)&quot;, h_method() == NULL ? &quot;(no method)&quot; : &quot;&quot;, p2i(this));
1561   }
1562   if (h_method() != NULL) {
1563     JavaCallArguments args; // No arguments
1564     JavaValue result(T_VOID);
1565     JavaCalls::call(&amp;result, h_method, &amp;args, CHECK); // Static call (no args)
1566   }
1567 }
1568 
1569 
1570 void InstanceKlass::mask_for(const methodHandle&amp; method, int bci,
1571   InterpreterOopMap* entry_for) {
1572   // Lazily create the _oop_map_cache at first request
1573   // Lock-free access requires load_acquire.
1574   OopMapCache* oop_map_cache = Atomic::load_acquire(&amp;_oop_map_cache);
1575   if (oop_map_cache == NULL) {
1576     MutexLocker x(OopMapCacheAlloc_lock,  Mutex::_no_safepoint_check_flag);
1577     // Check if _oop_map_cache was allocated while we were waiting for this lock
1578     if ((oop_map_cache = _oop_map_cache) == NULL) {
1579       oop_map_cache = new OopMapCache();
1580       // Ensure _oop_map_cache is stable, since it is examined without a lock
1581       Atomic::release_store(&amp;_oop_map_cache, oop_map_cache);
1582     }
1583   }
1584   // _oop_map_cache is constant after init; lookup below does its own locking.
1585   oop_map_cache-&gt;lookup(method, bci, entry_for);
1586 }
1587 
1588 bool InstanceKlass::find_local_field(Symbol* name, Symbol* sig, fieldDescriptor* fd) const {
1589   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
1590     Symbol* f_name = fs.name();
1591     Symbol* f_sig  = fs.signature();
1592     if (f_name == name &amp;&amp; f_sig == sig) {
1593       fd-&gt;reinitialize(const_cast&lt;InstanceKlass*&gt;(this), fs.index());
1594       return true;
1595     }
1596   }
1597   return false;
1598 }
1599 
1600 
1601 Klass* InstanceKlass::find_interface_field(Symbol* name, Symbol* sig, fieldDescriptor* fd) const {
1602   const int n = local_interfaces()-&gt;length();
1603   for (int i = 0; i &lt; n; i++) {
1604     Klass* intf1 = local_interfaces()-&gt;at(i);
1605     assert(intf1-&gt;is_interface(), &quot;just checking type&quot;);
1606     // search for field in current interface
1607     if (InstanceKlass::cast(intf1)-&gt;find_local_field(name, sig, fd)) {
1608       assert(fd-&gt;is_static(), &quot;interface field must be static&quot;);
1609       return intf1;
1610     }
1611     // search for field in direct superinterfaces
1612     Klass* intf2 = InstanceKlass::cast(intf1)-&gt;find_interface_field(name, sig, fd);
1613     if (intf2 != NULL) return intf2;
1614   }
1615   // otherwise field lookup fails
1616   return NULL;
1617 }
1618 
1619 
1620 Klass* InstanceKlass::find_field(Symbol* name, Symbol* sig, fieldDescriptor* fd) const {
1621   // search order according to newest JVM spec (5.4.3.2, p.167).
1622   // 1) search for field in current klass
1623   if (find_local_field(name, sig, fd)) {
1624     return const_cast&lt;InstanceKlass*&gt;(this);
1625   }
1626   // 2) search for field recursively in direct superinterfaces
1627   { Klass* intf = find_interface_field(name, sig, fd);
1628     if (intf != NULL) return intf;
1629   }
1630   // 3) apply field lookup recursively if superclass exists
1631   { Klass* supr = super();
1632     if (supr != NULL) return InstanceKlass::cast(supr)-&gt;find_field(name, sig, fd);
1633   }
1634   // 4) otherwise field lookup fails
1635   return NULL;
1636 }
1637 
1638 
1639 Klass* InstanceKlass::find_field(Symbol* name, Symbol* sig, bool is_static, fieldDescriptor* fd) const {
1640   // search order according to newest JVM spec (5.4.3.2, p.167).
1641   // 1) search for field in current klass
1642   if (find_local_field(name, sig, fd)) {
1643     if (fd-&gt;is_static() == is_static) return const_cast&lt;InstanceKlass*&gt;(this);
1644   }
1645   // 2) search for field recursively in direct superinterfaces
1646   if (is_static) {
1647     Klass* intf = find_interface_field(name, sig, fd);
1648     if (intf != NULL) return intf;
1649   }
1650   // 3) apply field lookup recursively if superclass exists
1651   { Klass* supr = super();
1652     if (supr != NULL) return InstanceKlass::cast(supr)-&gt;find_field(name, sig, is_static, fd);
1653   }
1654   // 4) otherwise field lookup fails
1655   return NULL;
1656 }
1657 
1658 bool InstanceKlass::contains_field_offset(int offset) {
1659   if (this-&gt;is_value()) {
1660     ValueKlass* vk = ValueKlass::cast(this);
1661     return offset &gt;= vk-&gt;first_field_offset() &amp;&amp; offset &lt; (vk-&gt;first_field_offset() + vk-&gt;get_exact_size_in_bytes());
1662   } else {
1663     fieldDescriptor fd;
1664     return find_field_from_offset(offset, false, &amp;fd);
1665   }
1666 }
1667 
1668 bool InstanceKlass::find_local_field_from_offset(int offset, bool is_static, fieldDescriptor* fd) const {
1669   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
1670     if (fs.offset() == offset) {
1671       fd-&gt;reinitialize(const_cast&lt;InstanceKlass*&gt;(this), fs.index());
1672       if (fd-&gt;is_static() == is_static) return true;
1673     }
1674   }
1675   return false;
1676 }
1677 
1678 
1679 bool InstanceKlass::find_field_from_offset(int offset, bool is_static, fieldDescriptor* fd) const {
1680   Klass* klass = const_cast&lt;InstanceKlass*&gt;(this);
1681   while (klass != NULL) {
1682     if (InstanceKlass::cast(klass)-&gt;find_local_field_from_offset(offset, is_static, fd)) {
1683       return true;
1684     }
1685     klass = klass-&gt;super();
1686   }
1687   return false;
1688 }
1689 
1690 
1691 void InstanceKlass::methods_do(void f(Method* method)) {
1692   // Methods aren&#39;t stable until they are loaded.  This can be read outside
1693   // a lock through the ClassLoaderData for profiling
1694   if (!is_loaded()) {
1695     return;
1696   }
1697 
1698   int len = methods()-&gt;length();
1699   for (int index = 0; index &lt; len; index++) {
1700     Method* m = methods()-&gt;at(index);
1701     assert(m-&gt;is_method(), &quot;must be method&quot;);
1702     f(m);
1703   }
1704 }
1705 
1706 
1707 void InstanceKlass::do_local_static_fields(FieldClosure* cl) {
1708   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
1709     if (fs.access_flags().is_static()) {
1710       fieldDescriptor&amp; fd = fs.field_descriptor();
1711       cl-&gt;do_field(&amp;fd);
1712     }
1713   }
1714 }
1715 
1716 
1717 void InstanceKlass::do_local_static_fields(void f(fieldDescriptor*, Handle, TRAPS), Handle mirror, TRAPS) {
1718   for (JavaFieldStream fs(this); !fs.done(); fs.next()) {
1719     if (fs.access_flags().is_static()) {
1720       fieldDescriptor&amp; fd = fs.field_descriptor();
1721       f(&amp;fd, mirror, CHECK);
1722     }
1723   }
1724 }
1725 
1726 
1727 static int compare_fields_by_offset(int* a, int* b) {
1728   return a[0] - b[0];
1729 }
1730 
1731 void InstanceKlass::do_nonstatic_fields(FieldClosure* cl) {
1732   InstanceKlass* super = superklass();
1733   if (super != NULL) {
1734     super-&gt;do_nonstatic_fields(cl);
1735   }
1736   fieldDescriptor fd;
1737   int length = java_fields_count();
1738   // In DebugInfo nonstatic fields are sorted by offset.
1739   int* fields_sorted = NEW_C_HEAP_ARRAY(int, 2*(length+1), mtClass);
1740   int j = 0;
1741   for (int i = 0; i &lt; length; i += 1) {
1742     fd.reinitialize(this, i);
1743     if (!fd.is_static()) {
1744       fields_sorted[j + 0] = fd.offset();
1745       fields_sorted[j + 1] = i;
1746       j += 2;
1747     }
1748   }
1749   if (j &gt; 0) {
1750     length = j;
1751     // _sort_Fn is defined in growableArray.hpp.
1752     qsort(fields_sorted, length/2, 2*sizeof(int), (_sort_Fn)compare_fields_by_offset);
1753     for (int i = 0; i &lt; length; i += 2) {
1754       fd.reinitialize(this, fields_sorted[i + 1]);
1755       assert(!fd.is_static() &amp;&amp; fd.offset() == fields_sorted[i], &quot;only nonstatic fields&quot;);
1756       cl-&gt;do_field(&amp;fd);
1757     }
1758   }
1759   FREE_C_HEAP_ARRAY(int, fields_sorted);
1760 }
1761 
1762 
1763 void InstanceKlass::array_klasses_do(void f(Klass* k)) {
1764   if (array_klasses() != NULL)
1765     ArrayKlass::cast(array_klasses())-&gt;array_klasses_do(f);
1766 }
1767 
1768 #ifdef ASSERT
1769 static int linear_search(const Array&lt;Method*&gt;* methods,
1770                          const Symbol* name,
1771                          const Symbol* signature) {
1772   const int len = methods-&gt;length();
1773   for (int index = 0; index &lt; len; index++) {
1774     const Method* const m = methods-&gt;at(index);
1775     assert(m-&gt;is_method(), &quot;must be method&quot;);
1776     if (m-&gt;signature() == signature &amp;&amp; m-&gt;name() == name) {
1777        return index;
1778     }
1779   }
1780   return -1;
1781 }
1782 #endif
1783 
1784 bool InstanceKlass::_disable_method_binary_search = false;
1785 
1786 NOINLINE int linear_search(const Array&lt;Method*&gt;* methods, const Symbol* name) {
1787   int len = methods-&gt;length();
1788   int l = 0;
1789   int h = len - 1;
1790   while (l &lt;= h) {
1791     Method* m = methods-&gt;at(l);
1792     if (m-&gt;name() == name) {
1793       return l;
1794     }
1795     l++;
1796   }
1797   return -1;
1798 }
1799 
1800 inline int InstanceKlass::quick_search(const Array&lt;Method*&gt;* methods, const Symbol* name) {
1801   if (_disable_method_binary_search) {
1802     assert(DynamicDumpSharedSpaces, &quot;must be&quot;);
1803     // At the final stage of dynamic dumping, the methods array may not be sorted
1804     // by ascending addresses of their names, so we can&#39;t use binary search anymore.
1805     // However, methods with the same name are still laid out consecutively inside the
1806     // methods array, so let&#39;s look for the first one that matches.
1807     return linear_search(methods, name);
1808   }
1809 
1810   int len = methods-&gt;length();
1811   int l = 0;
1812   int h = len - 1;
1813 
1814   // methods are sorted by ascending addresses of their names, so do binary search
1815   while (l &lt;= h) {
1816     int mid = (l + h) &gt;&gt; 1;
1817     Method* m = methods-&gt;at(mid);
1818     assert(m-&gt;is_method(), &quot;must be method&quot;);
1819     int res = m-&gt;name()-&gt;fast_compare(name);
1820     if (res == 0) {
1821       return mid;
1822     } else if (res &lt; 0) {
1823       l = mid + 1;
1824     } else {
1825       h = mid - 1;
1826     }
1827   }
1828   return -1;
1829 }
1830 
1831 // find_method looks up the name/signature in the local methods array
1832 Method* InstanceKlass::find_method(const Symbol* name,
1833                                    const Symbol* signature) const {
1834   return find_method_impl(name, signature, find_overpass, find_static, find_private);
1835 }
1836 
1837 Method* InstanceKlass::find_method_impl(const Symbol* name,
1838                                         const Symbol* signature,
1839                                         OverpassLookupMode overpass_mode,
1840                                         StaticLookupMode static_mode,
1841                                         PrivateLookupMode private_mode) const {
1842   return InstanceKlass::find_method_impl(methods(),
1843                                          name,
1844                                          signature,
1845                                          overpass_mode,
1846                                          static_mode,
1847                                          private_mode);
1848 }
1849 
1850 // find_instance_method looks up the name/signature in the local methods array
1851 // and skips over static methods
1852 Method* InstanceKlass::find_instance_method(const Array&lt;Method*&gt;* methods,
1853                                             const Symbol* name,
1854                                             const Symbol* signature,
1855                                             PrivateLookupMode private_mode) {
1856   Method* const meth = InstanceKlass::find_method_impl(methods,
1857                                                  name,
1858                                                  signature,
1859                                                  find_overpass,
1860                                                  skip_static,
1861                                                  private_mode);
1862   assert(((meth == NULL) || !meth-&gt;is_static()),
1863     &quot;find_instance_method should have skipped statics&quot;);
1864   return meth;
1865 }
1866 
1867 // find_instance_method looks up the name/signature in the local methods array
1868 // and skips over static methods
1869 Method* InstanceKlass::find_instance_method(const Symbol* name,
1870                                             const Symbol* signature,
1871                                             PrivateLookupMode private_mode) const {
1872   return InstanceKlass::find_instance_method(methods(), name, signature, private_mode);
1873 }
1874 
1875 // Find looks up the name/signature in the local methods array
1876 // and filters on the overpass, static and private flags
1877 // This returns the first one found
1878 // note that the local methods array can have up to one overpass, one static
1879 // and one instance (private or not) with the same name/signature
1880 Method* InstanceKlass::find_local_method(const Symbol* name,
1881                                          const Symbol* signature,
1882                                          OverpassLookupMode overpass_mode,
1883                                          StaticLookupMode static_mode,
1884                                          PrivateLookupMode private_mode) const {
1885   return InstanceKlass::find_method_impl(methods(),
1886                                          name,
1887                                          signature,
1888                                          overpass_mode,
1889                                          static_mode,
1890                                          private_mode);
1891 }
1892 
1893 // Find looks up the name/signature in the local methods array
1894 // and filters on the overpass, static and private flags
1895 // This returns the first one found
1896 // note that the local methods array can have up to one overpass, one static
1897 // and one instance (private or not) with the same name/signature
1898 Method* InstanceKlass::find_local_method(const Array&lt;Method*&gt;* methods,
1899                                          const Symbol* name,
1900                                          const Symbol* signature,
1901                                          OverpassLookupMode overpass_mode,
1902                                          StaticLookupMode static_mode,
1903                                          PrivateLookupMode private_mode) {
1904   return InstanceKlass::find_method_impl(methods,
1905                                          name,
1906                                          signature,
1907                                          overpass_mode,
1908                                          static_mode,
1909                                          private_mode);
1910 }
1911 
1912 Method* InstanceKlass::find_method(const Array&lt;Method*&gt;* methods,
1913                                    const Symbol* name,
1914                                    const Symbol* signature) {
1915   return InstanceKlass::find_method_impl(methods,
1916                                          name,
1917                                          signature,
1918                                          find_overpass,
1919                                          find_static,
1920                                          find_private);
1921 }
1922 
1923 Method* InstanceKlass::find_method_impl(const Array&lt;Method*&gt;* methods,
1924                                         const Symbol* name,
1925                                         const Symbol* signature,
1926                                         OverpassLookupMode overpass_mode,
1927                                         StaticLookupMode static_mode,
1928                                         PrivateLookupMode private_mode) {
1929   int hit = find_method_index(methods, name, signature, overpass_mode, static_mode, private_mode);
1930   return hit &gt;= 0 ? methods-&gt;at(hit): NULL;
1931 }
1932 
1933 // true if method matches signature and conforms to skipping_X conditions.
1934 static bool method_matches(const Method* m,
1935                            const Symbol* signature,
1936                            bool skipping_overpass,
1937                            bool skipping_static,
1938                            bool skipping_private) {
1939   return ((m-&gt;signature() == signature) &amp;&amp;
1940     (!skipping_overpass || !m-&gt;is_overpass()) &amp;&amp;
1941     (!skipping_static || !m-&gt;is_static()) &amp;&amp;
1942     (!skipping_private || !m-&gt;is_private()));
1943 }
1944 
1945 // Used directly for default_methods to find the index into the
1946 // default_vtable_indices, and indirectly by find_method
1947 // find_method_index looks in the local methods array to return the index
1948 // of the matching name/signature. If, overpass methods are being ignored,
1949 // the search continues to find a potential non-overpass match.  This capability
1950 // is important during method resolution to prefer a static method, for example,
1951 // over an overpass method.
1952 // There is the possibility in any _method&#39;s array to have the same name/signature
1953 // for a static method, an overpass method and a local instance method
1954 // To correctly catch a given method, the search criteria may need
1955 // to explicitly skip the other two. For local instance methods, it
1956 // is often necessary to skip private methods
1957 int InstanceKlass::find_method_index(const Array&lt;Method*&gt;* methods,
1958                                      const Symbol* name,
1959                                      const Symbol* signature,
1960                                      OverpassLookupMode overpass_mode,
1961                                      StaticLookupMode static_mode,
1962                                      PrivateLookupMode private_mode) {
1963   const bool skipping_overpass = (overpass_mode == skip_overpass);
1964   const bool skipping_static = (static_mode == skip_static);
1965   const bool skipping_private = (private_mode == skip_private);
1966   const int hit = quick_search(methods, name);
1967   if (hit != -1) {
1968     const Method* const m = methods-&gt;at(hit);
1969 
1970     // Do linear search to find matching signature.  First, quick check
1971     // for common case, ignoring overpasses if requested.
1972     if (method_matches(m, signature, skipping_overpass, skipping_static, skipping_private)) {
1973       return hit;
1974     }
1975 
1976     // search downwards through overloaded methods
1977     int i;
1978     for (i = hit - 1; i &gt;= 0; --i) {
1979         const Method* const m = methods-&gt;at(i);
1980         assert(m-&gt;is_method(), &quot;must be method&quot;);
1981         if (m-&gt;name() != name) {
1982           break;
1983         }
1984         if (method_matches(m, signature, skipping_overpass, skipping_static, skipping_private)) {
1985           return i;
1986         }
1987     }
1988     // search upwards
1989     for (i = hit + 1; i &lt; methods-&gt;length(); ++i) {
1990         const Method* const m = methods-&gt;at(i);
1991         assert(m-&gt;is_method(), &quot;must be method&quot;);
1992         if (m-&gt;name() != name) {
1993           break;
1994         }
1995         if (method_matches(m, signature, skipping_overpass, skipping_static, skipping_private)) {
1996           return i;
1997         }
1998     }
1999     // not found
2000 #ifdef ASSERT
2001     const int index = (skipping_overpass || skipping_static || skipping_private) ? -1 :
2002       linear_search(methods, name, signature);
2003     assert(-1 == index, &quot;binary search should have found entry %d&quot;, index);
2004 #endif
2005   }
2006   return -1;
2007 }
2008 
2009 int InstanceKlass::find_method_by_name(const Symbol* name, int* end) const {
2010   return find_method_by_name(methods(), name, end);
2011 }
2012 
2013 int InstanceKlass::find_method_by_name(const Array&lt;Method*&gt;* methods,
2014                                        const Symbol* name,
2015                                        int* end_ptr) {
2016   assert(end_ptr != NULL, &quot;just checking&quot;);
2017   int start = quick_search(methods, name);
2018   int end = start + 1;
2019   if (start != -1) {
2020     while (start - 1 &gt;= 0 &amp;&amp; (methods-&gt;at(start - 1))-&gt;name() == name) --start;
2021     while (end &lt; methods-&gt;length() &amp;&amp; (methods-&gt;at(end))-&gt;name() == name) ++end;
2022     *end_ptr = end;
2023     return start;
2024   }
2025   return -1;
2026 }
2027 
2028 // uncached_lookup_method searches both the local class methods array and all
2029 // superclasses methods arrays, skipping any overpass methods in superclasses,
2030 // and possibly skipping private methods.
2031 Method* InstanceKlass::uncached_lookup_method(const Symbol* name,
2032                                               const Symbol* signature,
2033                                               OverpassLookupMode overpass_mode,
2034                                               PrivateLookupMode private_mode) const {
2035   OverpassLookupMode overpass_local_mode = overpass_mode;
2036   const Klass* klass = this;
2037   while (klass != NULL) {
2038     Method* const method = InstanceKlass::cast(klass)-&gt;find_method_impl(name,
2039                                                                         signature,
2040                                                                         overpass_local_mode,
2041                                                                         find_static,
2042                                                                         private_mode);
2043     if (method != NULL) {
2044       return method;
2045     }
2046     if (name == vmSymbols::object_initializer_name()) {
2047       break;  // &lt;init&gt; is never inherited, not even as a static factory
2048     }
2049     klass = klass-&gt;super();
2050     overpass_local_mode = skip_overpass;   // Always ignore overpass methods in superclasses
2051   }
2052   return NULL;
2053 }
2054 
2055 #ifdef ASSERT
2056 // search through class hierarchy and return true if this class or
2057 // one of the superclasses was redefined
2058 bool InstanceKlass::has_redefined_this_or_super() const {
2059   const Klass* klass = this;
2060   while (klass != NULL) {
2061     if (InstanceKlass::cast(klass)-&gt;has_been_redefined()) {
2062       return true;
2063     }
2064     klass = klass-&gt;super();
2065   }
2066   return false;
2067 }
2068 #endif
2069 
2070 // lookup a method in the default methods list then in all transitive interfaces
2071 // Do NOT return private or static methods
2072 Method* InstanceKlass::lookup_method_in_ordered_interfaces(Symbol* name,
2073                                                          Symbol* signature) const {
2074   Method* m = NULL;
2075   if (default_methods() != NULL) {
2076     m = find_method(default_methods(), name, signature);
2077   }
2078   // Look up interfaces
2079   if (m == NULL) {
2080     m = lookup_method_in_all_interfaces(name, signature, find_defaults);
2081   }
2082   return m;
2083 }
2084 
2085 // lookup a method in all the interfaces that this class implements
2086 // Do NOT return private or static methods, new in JDK8 which are not externally visible
2087 // They should only be found in the initial InterfaceMethodRef
2088 Method* InstanceKlass::lookup_method_in_all_interfaces(Symbol* name,
2089                                                        Symbol* signature,
2090                                                        DefaultsLookupMode defaults_mode) const {
2091   Array&lt;InstanceKlass*&gt;* all_ifs = transitive_interfaces();
2092   int num_ifs = all_ifs-&gt;length();
2093   InstanceKlass *ik = NULL;
2094   for (int i = 0; i &lt; num_ifs; i++) {
2095     ik = all_ifs-&gt;at(i);
2096     Method* m = ik-&gt;lookup_method(name, signature);
2097     if (m != NULL &amp;&amp; m-&gt;is_public() &amp;&amp; !m-&gt;is_static() &amp;&amp;
2098         ((defaults_mode != skip_defaults) || !m-&gt;is_default_method())) {
2099       return m;
2100     }
2101   }
2102   return NULL;
2103 }
2104 
2105 /* jni_id_for_impl for jfieldIds only */
2106 JNIid* InstanceKlass::jni_id_for_impl(int offset) {
2107   MutexLocker ml(JfieldIdCreation_lock);
2108   // Retry lookup after we got the lock
2109   JNIid* probe = jni_ids() == NULL ? NULL : jni_ids()-&gt;find(offset);
2110   if (probe == NULL) {
2111     // Slow case, allocate new static field identifier
2112     probe = new JNIid(this, offset, jni_ids());
2113     set_jni_ids(probe);
2114   }
2115   return probe;
2116 }
2117 
2118 
2119 /* jni_id_for for jfieldIds only */
2120 JNIid* InstanceKlass::jni_id_for(int offset) {
2121   JNIid* probe = jni_ids() == NULL ? NULL : jni_ids()-&gt;find(offset);
2122   if (probe == NULL) {
2123     probe = jni_id_for_impl(offset);
2124   }
2125   return probe;
2126 }
2127 
2128 u2 InstanceKlass::enclosing_method_data(int offset) const {
2129   const Array&lt;jushort&gt;* const inner_class_list = inner_classes();
2130   if (inner_class_list == NULL) {
2131     return 0;
2132   }
2133   const int length = inner_class_list-&gt;length();
2134   if (length % inner_class_next_offset == 0) {
2135     return 0;
2136   }
2137   const int index = length - enclosing_method_attribute_size;
2138   assert(offset &lt; enclosing_method_attribute_size, &quot;invalid offset&quot;);
2139   return inner_class_list-&gt;at(index + offset);
2140 }
2141 
2142 void InstanceKlass::set_enclosing_method_indices(u2 class_index,
2143                                                  u2 method_index) {
2144   Array&lt;jushort&gt;* inner_class_list = inner_classes();
2145   assert (inner_class_list != NULL, &quot;_inner_classes list is not set up&quot;);
2146   int length = inner_class_list-&gt;length();
2147   if (length % inner_class_next_offset == enclosing_method_attribute_size) {
2148     int index = length - enclosing_method_attribute_size;
2149     inner_class_list-&gt;at_put(
2150       index + enclosing_method_class_index_offset, class_index);
2151     inner_class_list-&gt;at_put(
2152       index + enclosing_method_method_index_offset, method_index);
2153   }
2154 }
2155 
2156 // Lookup or create a jmethodID.
2157 // This code is called by the VMThread and JavaThreads so the
2158 // locking has to be done very carefully to avoid deadlocks
2159 // and/or other cache consistency problems.
2160 //
2161 jmethodID InstanceKlass::get_jmethod_id(const methodHandle&amp; method_h) {
2162   size_t idnum = (size_t)method_h-&gt;method_idnum();
2163   jmethodID* jmeths = methods_jmethod_ids_acquire();
2164   size_t length = 0;
2165   jmethodID id = NULL;
2166 
2167   // We use a double-check locking idiom here because this cache is
2168   // performance sensitive. In the normal system, this cache only
2169   // transitions from NULL to non-NULL which is safe because we use
2170   // release_set_methods_jmethod_ids() to advertise the new cache.
2171   // A partially constructed cache should never be seen by a racing
2172   // thread. We also use release_store() to save a new jmethodID
2173   // in the cache so a partially constructed jmethodID should never be
2174   // seen either. Cache reads of existing jmethodIDs proceed without a
2175   // lock, but cache writes of a new jmethodID requires uniqueness and
2176   // creation of the cache itself requires no leaks so a lock is
2177   // generally acquired in those two cases.
2178   //
2179   // If the RedefineClasses() API has been used, then this cache can
2180   // grow and we&#39;ll have transitions from non-NULL to bigger non-NULL.
2181   // Cache creation requires no leaks and we require safety between all
2182   // cache accesses and freeing of the old cache so a lock is generally
2183   // acquired when the RedefineClasses() API has been used.
2184 
2185   if (jmeths != NULL) {
2186     // the cache already exists
2187     if (!idnum_can_increment()) {
2188       // the cache can&#39;t grow so we can just get the current values
2189       get_jmethod_id_length_value(jmeths, idnum, &amp;length, &amp;id);
2190     } else {
2191       // cache can grow so we have to be more careful
2192       if (Threads::number_of_threads() == 0 ||
2193           SafepointSynchronize::is_at_safepoint()) {
2194         // we&#39;re single threaded or at a safepoint - no locking needed
2195         get_jmethod_id_length_value(jmeths, idnum, &amp;length, &amp;id);
2196       } else {
2197         MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);
2198         get_jmethod_id_length_value(jmeths, idnum, &amp;length, &amp;id);
2199       }
2200     }
2201   }
2202   // implied else:
2203   // we need to allocate a cache so default length and id values are good
2204 
2205   if (jmeths == NULL ||   // no cache yet
2206       length &lt;= idnum ||  // cache is too short
2207       id == NULL) {       // cache doesn&#39;t contain entry
2208 
2209     // This function can be called by the VMThread so we have to do all
2210     // things that might block on a safepoint before grabbing the lock.
2211     // Otherwise, we can deadlock with the VMThread or have a cache
2212     // consistency issue. These vars keep track of what we might have
2213     // to free after the lock is dropped.
2214     jmethodID  to_dealloc_id     = NULL;
2215     jmethodID* to_dealloc_jmeths = NULL;
2216 
2217     // may not allocate new_jmeths or use it if we allocate it
2218     jmethodID* new_jmeths = NULL;
2219     if (length &lt;= idnum) {
2220       // allocate a new cache that might be used
2221       size_t size = MAX2(idnum+1, (size_t)idnum_allocated_count());
2222       new_jmeths = NEW_C_HEAP_ARRAY(jmethodID, size+1, mtClass);
2223       memset(new_jmeths, 0, (size+1)*sizeof(jmethodID));
2224       // cache size is stored in element[0], other elements offset by one
2225       new_jmeths[0] = (jmethodID)size;
2226     }
2227 
2228     // allocate a new jmethodID that might be used
2229     jmethodID new_id = NULL;
2230     if (method_h-&gt;is_old() &amp;&amp; !method_h-&gt;is_obsolete()) {
2231       // The method passed in is old (but not obsolete), we need to use the current version
2232       Method* current_method = method_with_idnum((int)idnum);
2233       assert(current_method != NULL, &quot;old and but not obsolete, so should exist&quot;);
2234       new_id = Method::make_jmethod_id(class_loader_data(), current_method);
2235     } else {
2236       // It is the current version of the method or an obsolete method,
2237       // use the version passed in
2238       new_id = Method::make_jmethod_id(class_loader_data(), method_h());
2239     }
2240 
2241     if (Threads::number_of_threads() == 0 ||
2242         SafepointSynchronize::is_at_safepoint()) {
2243       // we&#39;re single threaded or at a safepoint - no locking needed
2244       id = get_jmethod_id_fetch_or_update(idnum, new_id, new_jmeths,
2245                                           &amp;to_dealloc_id, &amp;to_dealloc_jmeths);
2246     } else {
2247       MutexLocker ml(JmethodIdCreation_lock, Mutex::_no_safepoint_check_flag);
2248       id = get_jmethod_id_fetch_or_update(idnum, new_id, new_jmeths,
2249                                           &amp;to_dealloc_id, &amp;to_dealloc_jmeths);
2250     }
2251 
2252     // The lock has been dropped so we can free resources.
2253     // Free up either the old cache or the new cache if we allocated one.
2254     if (to_dealloc_jmeths != NULL) {
2255       FreeHeap(to_dealloc_jmeths);
2256     }
2257     // free up the new ID since it wasn&#39;t needed
2258     if (to_dealloc_id != NULL) {
2259       Method::destroy_jmethod_id(class_loader_data(), to_dealloc_id);
2260     }
2261   }
2262   return id;
2263 }
2264 
2265 // Figure out how many jmethodIDs haven&#39;t been allocated, and make
2266 // sure space for them is pre-allocated.  This makes getting all
2267 // method ids much, much faster with classes with more than 8
2268 // methods, and has a *substantial* effect on performance with jvmti
2269 // code that loads all jmethodIDs for all classes.
2270 void InstanceKlass::ensure_space_for_methodids(int start_offset) {
2271   int new_jmeths = 0;
2272   int length = methods()-&gt;length();
2273   for (int index = start_offset; index &lt; length; index++) {
2274     Method* m = methods()-&gt;at(index);
2275     jmethodID id = m-&gt;find_jmethod_id_or_null();
2276     if (id == NULL) {
2277       new_jmeths++;
2278     }
2279   }
2280   if (new_jmeths != 0) {
2281     Method::ensure_jmethod_ids(class_loader_data(), new_jmeths);
2282   }
2283 }
2284 
2285 // Common code to fetch the jmethodID from the cache or update the
2286 // cache with the new jmethodID. This function should never do anything
2287 // that causes the caller to go to a safepoint or we can deadlock with
2288 // the VMThread or have cache consistency issues.
2289 //
2290 jmethodID InstanceKlass::get_jmethod_id_fetch_or_update(
2291             size_t idnum, jmethodID new_id,
2292             jmethodID* new_jmeths, jmethodID* to_dealloc_id_p,
2293             jmethodID** to_dealloc_jmeths_p) {
2294   assert(new_id != NULL, &quot;sanity check&quot;);
2295   assert(to_dealloc_id_p != NULL, &quot;sanity check&quot;);
2296   assert(to_dealloc_jmeths_p != NULL, &quot;sanity check&quot;);
2297   assert(Threads::number_of_threads() == 0 ||
2298          SafepointSynchronize::is_at_safepoint() ||
2299          JmethodIdCreation_lock-&gt;owned_by_self(), &quot;sanity check&quot;);
2300 
2301   // reacquire the cache - we are locked, single threaded or at a safepoint
2302   jmethodID* jmeths = methods_jmethod_ids_acquire();
2303   jmethodID  id     = NULL;
2304   size_t     length = 0;
2305 
2306   if (jmeths == NULL ||                         // no cache yet
2307       (length = (size_t)jmeths[0]) &lt;= idnum) {  // cache is too short
2308     if (jmeths != NULL) {
2309       // copy any existing entries from the old cache
2310       for (size_t index = 0; index &lt; length; index++) {
2311         new_jmeths[index+1] = jmeths[index+1];
2312       }
2313       *to_dealloc_jmeths_p = jmeths;  // save old cache for later delete
2314     }
2315     release_set_methods_jmethod_ids(jmeths = new_jmeths);
2316   } else {
2317     // fetch jmethodID (if any) from the existing cache
2318     id = jmeths[idnum+1];
2319     *to_dealloc_jmeths_p = new_jmeths;  // save new cache for later delete
2320   }
2321   if (id == NULL) {
2322     // No matching jmethodID in the existing cache or we have a new
2323     // cache or we just grew the cache. This cache write is done here
2324     // by the first thread to win the foot race because a jmethodID
2325     // needs to be unique once it is generally available.
2326     id = new_id;
2327 
2328     // The jmethodID cache can be read while unlocked so we have to
2329     // make sure the new jmethodID is complete before installing it
2330     // in the cache.
2331     Atomic::release_store(&amp;jmeths[idnum+1], id);
2332   } else {
2333     *to_dealloc_id_p = new_id; // save new id for later delete
2334   }
2335   return id;
2336 }
2337 
2338 
2339 // Common code to get the jmethodID cache length and the jmethodID
2340 // value at index idnum if there is one.
2341 //
2342 void InstanceKlass::get_jmethod_id_length_value(jmethodID* cache,
2343        size_t idnum, size_t *length_p, jmethodID* id_p) {
2344   assert(cache != NULL, &quot;sanity check&quot;);
2345   assert(length_p != NULL, &quot;sanity check&quot;);
2346   assert(id_p != NULL, &quot;sanity check&quot;);
2347 
2348   // cache size is stored in element[0], other elements offset by one
2349   *length_p = (size_t)cache[0];
2350   if (*length_p &lt;= idnum) {  // cache is too short
2351     *id_p = NULL;
2352   } else {
2353     *id_p = cache[idnum+1];  // fetch jmethodID (if any)
2354   }
2355 }
2356 
2357 
2358 // Lookup a jmethodID, NULL if not found.  Do no blocking, no allocations, no handles
2359 jmethodID InstanceKlass::jmethod_id_or_null(Method* method) {
2360   size_t idnum = (size_t)method-&gt;method_idnum();
2361   jmethodID* jmeths = methods_jmethod_ids_acquire();
2362   size_t length;                                // length assigned as debugging crumb
2363   jmethodID id = NULL;
2364   if (jmeths != NULL &amp;&amp;                         // If there is a cache
2365       (length = (size_t)jmeths[0]) &gt; idnum) {   // and if it is long enough,
2366     id = jmeths[idnum+1];                       // Look up the id (may be NULL)
2367   }
2368   return id;
2369 }
2370 
2371 inline DependencyContext InstanceKlass::dependencies() {
2372   DependencyContext dep_context(&amp;_dep_context, &amp;_dep_context_last_cleaned);
2373   return dep_context;
2374 }
2375 
2376 int InstanceKlass::mark_dependent_nmethods(KlassDepChange&amp; changes) {
2377   return dependencies().mark_dependent_nmethods(changes);
2378 }
2379 
2380 void InstanceKlass::add_dependent_nmethod(nmethod* nm) {
2381   dependencies().add_dependent_nmethod(nm);
2382 }
2383 
2384 void InstanceKlass::remove_dependent_nmethod(nmethod* nm) {
2385   dependencies().remove_dependent_nmethod(nm);
2386 }
2387 
2388 void InstanceKlass::clean_dependency_context() {
2389   dependencies().clean_unloading_dependents();
2390 }
2391 
2392 #ifndef PRODUCT
2393 void InstanceKlass::print_dependent_nmethods(bool verbose) {
2394   dependencies().print_dependent_nmethods(verbose);
2395 }
2396 
2397 bool InstanceKlass::is_dependent_nmethod(nmethod* nm) {
2398   return dependencies().is_dependent_nmethod(nm);
2399 }
2400 #endif //PRODUCT
2401 
2402 void InstanceKlass::clean_weak_instanceklass_links() {
2403   clean_implementors_list();
2404   clean_method_data();
2405 }
2406 
2407 void InstanceKlass::clean_implementors_list() {
2408   assert(is_loader_alive(), &quot;this klass should be live&quot;);
2409   if (is_interface()) {
2410     assert (ClassUnloading, &quot;only called for ClassUnloading&quot;);
2411     for (;;) {
2412       // Use load_acquire due to competing with inserts
2413       Klass* impl = Atomic::load_acquire(adr_implementor());
2414       if (impl != NULL &amp;&amp; !impl-&gt;is_loader_alive()) {
2415         // NULL this field, might be an unloaded klass or NULL
2416         Klass* volatile* klass = adr_implementor();
2417         if (Atomic::cmpxchg(klass, impl, (Klass*)NULL) == impl) {
2418           // Successfully unlinking implementor.
2419           if (log_is_enabled(Trace, class, unload)) {
2420             ResourceMark rm;
2421             log_trace(class, unload)(&quot;unlinking class (implementor): %s&quot;, impl-&gt;external_name());
2422           }
2423           return;
2424         }
2425       } else {
2426         return;
2427       }
2428     }
2429   }
2430 }
2431 
2432 void InstanceKlass::clean_method_data() {
2433   for (int m = 0; m &lt; methods()-&gt;length(); m++) {
2434     MethodData* mdo = methods()-&gt;at(m)-&gt;method_data();
2435     if (mdo != NULL) {
2436       MutexLocker ml(SafepointSynchronize::is_at_safepoint() ? NULL : mdo-&gt;extra_data_lock());
2437       mdo-&gt;clean_method_data(/*always_clean*/false);
2438     }
2439   }
2440 }
2441 
2442 bool InstanceKlass::supers_have_passed_fingerprint_checks() {
2443   if (java_super() != NULL &amp;&amp; !java_super()-&gt;has_passed_fingerprint_check()) {
2444     ResourceMark rm;
2445     log_trace(class, fingerprint)(&quot;%s : super %s not fingerprinted&quot;, external_name(), java_super()-&gt;external_name());
2446     return false;
2447   }
2448 
2449   Array&lt;InstanceKlass*&gt;* local_interfaces = this-&gt;local_interfaces();
2450   if (local_interfaces != NULL) {
2451     int length = local_interfaces-&gt;length();
2452     for (int i = 0; i &lt; length; i++) {
2453       InstanceKlass* intf = local_interfaces-&gt;at(i);
2454       if (!intf-&gt;has_passed_fingerprint_check()) {
2455         ResourceMark rm;
2456         log_trace(class, fingerprint)(&quot;%s : interface %s not fingerprinted&quot;, external_name(), intf-&gt;external_name());
2457         return false;
2458       }
2459     }
2460   }
2461 
2462   return true;
2463 }
2464 
2465 bool InstanceKlass::should_store_fingerprint(bool is_hidden_or_anonymous) {
2466 #if INCLUDE_AOT
2467   // We store the fingerprint into the InstanceKlass only in the following 2 cases:
2468   if (CalculateClassFingerprint) {
2469     // (1) We are running AOT to generate a shared library.
2470     return true;
2471   }
2472   if (Arguments::is_dumping_archive()) {
2473     // (2) We are running -Xshare:dump or -XX:ArchiveClassesAtExit to create a shared archive
2474     return true;
2475   }
2476   if (UseAOT &amp;&amp; is_hidden_or_anonymous) {
2477     // (3) We are using AOT code from a shared library and see a hidden or unsafe anonymous class
2478     return true;
2479   }
2480 #endif
2481 
2482   // In all other cases we might set the _misc_has_passed_fingerprint_check bit,
2483   // but do not store the 64-bit fingerprint to save space.
2484   return false;
2485 }
2486 
2487 bool InstanceKlass::has_stored_fingerprint() const {
2488 #if INCLUDE_AOT
2489   return should_store_fingerprint() || is_shared();
2490 #else
2491   return false;
2492 #endif
2493 }
2494 
2495 uint64_t InstanceKlass::get_stored_fingerprint() const {
2496   address adr = adr_fingerprint();
2497   if (adr != NULL) {
2498     return (uint64_t)Bytes::get_native_u8(adr); // adr may not be 64-bit aligned
2499   }
2500   return 0;
2501 }
2502 
2503 void InstanceKlass::store_fingerprint(uint64_t fingerprint) {
2504   address adr = adr_fingerprint();
2505   if (adr != NULL) {
2506     Bytes::put_native_u8(adr, (u8)fingerprint); // adr may not be 64-bit aligned
2507 
2508     ResourceMark rm;
2509     log_trace(class, fingerprint)(&quot;stored as &quot; PTR64_FORMAT &quot; for class %s&quot;, fingerprint, external_name());
2510   }
2511 }
2512 
2513 void InstanceKlass::metaspace_pointers_do(MetaspaceClosure* it) {
2514   Klass::metaspace_pointers_do(it);
2515 
2516   if (log_is_enabled(Trace, cds)) {
2517     ResourceMark rm;
2518     log_trace(cds)(&quot;Iter(InstanceKlass): %p (%s)&quot;, this, external_name());
2519   }
2520 
2521   it-&gt;push(&amp;_annotations);
2522   it-&gt;push((Klass**)&amp;_array_klasses);
2523   it-&gt;push(&amp;_constants);
2524   it-&gt;push(&amp;_inner_classes);
2525 #if INCLUDE_JVMTI
2526   it-&gt;push(&amp;_previous_versions);
2527 #endif
2528   it-&gt;push(&amp;_methods);
2529   it-&gt;push(&amp;_default_methods);
2530   it-&gt;push(&amp;_local_interfaces);
2531   it-&gt;push(&amp;_transitive_interfaces);
2532   it-&gt;push(&amp;_method_ordering);
2533   it-&gt;push(&amp;_default_vtable_indices);
2534   it-&gt;push(&amp;_fields);
2535 
2536   if (itable_length() &gt; 0) {
2537     itableOffsetEntry* ioe = (itableOffsetEntry*)start_of_itable();
2538     int method_table_offset_in_words = ioe-&gt;offset()/wordSize;
2539     int nof_interfaces = (method_table_offset_in_words - itable_offset_in_words())
2540                          / itableOffsetEntry::size();
2541 
2542     for (int i = 0; i &lt; nof_interfaces; i ++, ioe ++) {
2543       if (ioe-&gt;interface_klass() != NULL) {
2544         it-&gt;push(ioe-&gt;interface_klass_addr());
2545         itableMethodEntry* ime = ioe-&gt;first_method_entry(this);
2546         int n = klassItable::method_count_for_interface(ioe-&gt;interface_klass());
2547         for (int index = 0; index &lt; n; index ++) {
2548           it-&gt;push(ime[index].method_addr());
2549         }
2550       }
2551     }
2552   }
2553 
2554   it-&gt;push(&amp;_nest_members);
2555   it-&gt;push(&amp;_record_components);
2556 }
2557 
2558 void InstanceKlass::remove_unshareable_info() {
2559   Klass::remove_unshareable_info();
2560 
2561   if (SystemDictionaryShared::has_class_failed_verification(this)) {
2562     // Classes are attempted to link during dumping and may fail,
2563     // but these classes are still in the dictionary and class list in CLD.
2564     // If the class has failed verification, there is nothing else to remove.
2565     return;
2566   }
2567 
2568   // Reset to the &#39;allocated&#39; state to prevent any premature accessing to
2569   // a shared class at runtime while the class is still being loaded and
2570   // restored. A class&#39; init_state is set to &#39;loaded&#39; at runtime when it&#39;s
2571   // being added to class hierarchy (see SystemDictionary:::add_to_hierarchy()).
2572   _init_state = allocated;
2573 
2574   { // Otherwise this needs to take out the Compile_lock.
2575     assert(SafepointSynchronize::is_at_safepoint(), &quot;only called at safepoint&quot;);
2576     init_implementor();
2577   }
2578 
2579   constants()-&gt;remove_unshareable_info();
2580 
2581   for (int i = 0; i &lt; methods()-&gt;length(); i++) {
2582     Method* m = methods()-&gt;at(i);
2583     m-&gt;remove_unshareable_info();
2584   }
2585 
2586   // do array classes also.
2587   if (array_klasses() != NULL) {
2588     array_klasses()-&gt;remove_unshareable_info();
2589   }
2590 
2591   // These are not allocated from metaspace. They are safe to set to NULL.
2592   _source_debug_extension = NULL;
2593   _dep_context = NULL;
2594   _osr_nmethods_head = NULL;
2595 #if INCLUDE_JVMTI
2596   _breakpoints = NULL;
2597   _previous_versions = NULL;
2598   _cached_class_file = NULL;
2599   _jvmti_cached_class_field_map = NULL;
2600 #endif
2601 
2602   _init_thread = NULL;
2603   _methods_jmethod_ids = NULL;
2604   _jni_ids = NULL;
2605   _oop_map_cache = NULL;
2606   // clear _nest_host to ensure re-load at runtime
2607   _nest_host = NULL;
2608   _package_entry = NULL;
2609   _dep_context_last_cleaned = 0;
2610 }
2611 
2612 void InstanceKlass::remove_java_mirror() {
2613   Klass::remove_java_mirror();
2614 
2615   // do array classes also.
2616   if (array_klasses() != NULL) {
2617     array_klasses()-&gt;remove_java_mirror();
2618   }
2619 }
2620 
2621 void InstanceKlass::restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain,
2622                                              PackageEntry* pkg_entry, TRAPS) {
2623   // SystemDictionary::add_to_hierarchy() sets the init_state to loaded
2624   // before the InstanceKlass is added to the SystemDictionary. Make
2625   // sure the current state is &lt;loaded.
2626   assert(!is_loaded(), &quot;invalid init state&quot;);
2627   set_package(loader_data, pkg_entry, CHECK);
2628   Klass::restore_unshareable_info(loader_data, protection_domain, CHECK);
2629 
2630   if (is_value()) {
2631     ValueKlass::cast(this)-&gt;initialize_calling_convention(CHECK);
2632   }
2633 
2634   Array&lt;Method*&gt;* methods = this-&gt;methods();
2635   int num_methods = methods-&gt;length();
2636   for (int index = 0; index &lt; num_methods; ++index) {
2637     methods-&gt;at(index)-&gt;restore_unshareable_info(CHECK);
2638   }
2639   if (JvmtiExport::has_redefined_a_class()) {
2640     // Reinitialize vtable because RedefineClasses may have changed some
2641     // entries in this vtable for super classes so the CDS vtable might
2642     // point to old or obsolete entries.  RedefineClasses doesn&#39;t fix up
2643     // vtables in the shared system dictionary, only the main one.
2644     // It also redefines the itable too so fix that too.
2645     vtable().initialize_vtable(false, CHECK);
2646     itable().initialize_itable(false, CHECK);
2647   }
2648 
2649   // restore constant pool resolved references
2650   constants()-&gt;restore_unshareable_info(CHECK);
2651 
2652   if (array_klasses() != NULL) {
2653     // Array classes have null protection domain.
2654     // --&gt; see ArrayKlass::complete_create_array_klass()
2655     ArrayKlass::cast(array_klasses())-&gt;restore_unshareable_info(ClassLoaderData::the_null_class_loader_data(), Handle(), CHECK);
2656   }
2657 
2658   // Initialize current biased locking state.
2659   if (UseBiasedLocking &amp;&amp; BiasedLocking::enabled() &amp;&amp; !is_value()) {
2660     set_prototype_header(markWord::biased_locking_prototype());
2661   }
2662 }
2663 
2664 void InstanceKlass::set_shared_class_loader_type(s2 loader_type) {
2665   switch (loader_type) {
2666   case ClassLoader::BOOT_LOADER:
2667     _misc_flags |= _misc_is_shared_boot_class;
2668     break;
2669   case ClassLoader::PLATFORM_LOADER:
2670     _misc_flags |= _misc_is_shared_platform_class;
2671     break;
2672   case ClassLoader::APP_LOADER:
2673     _misc_flags |= _misc_is_shared_app_class;
2674     break;
2675   default:
2676     ShouldNotReachHere();
2677     break;
2678   }
2679 }
2680 
2681 #if INCLUDE_JVMTI
2682 static void clear_all_breakpoints(Method* m) {
2683   m-&gt;clear_all_breakpoints();
2684 }
2685 #endif
2686 
2687 void InstanceKlass::unload_class(InstanceKlass* ik) {
2688   // Release dependencies.
2689   ik-&gt;dependencies().remove_all_dependents();
2690 
2691   // notify the debugger
2692   if (JvmtiExport::should_post_class_unload()) {
2693     JvmtiExport::post_class_unload(ik);
2694   }
2695 
2696   // notify ClassLoadingService of class unload
2697   ClassLoadingService::notify_class_unloaded(ik);
2698 
2699   if (Arguments::is_dumping_archive()) {
2700     SystemDictionaryShared::remove_dumptime_info(ik);
2701   }
2702 
2703   if (log_is_enabled(Info, class, unload)) {
2704     ResourceMark rm;
2705     log_info(class, unload)(&quot;unloading class %s &quot; INTPTR_FORMAT, ik-&gt;external_name(), p2i(ik));
2706   }
2707 
2708   Events::log_class_unloading(Thread::current(), ik);
2709 
2710 #if INCLUDE_JFR
2711   assert(ik != NULL, &quot;invariant&quot;);
2712   EventClassUnload event;
2713   event.set_unloadedClass(ik);
2714   event.set_definingClassLoader(ik-&gt;class_loader_data());
2715   event.commit();
2716 #endif
2717 }
2718 
2719 static void method_release_C_heap_structures(Method* m) {
2720   m-&gt;release_C_heap_structures();
2721 }
2722 
2723 void InstanceKlass::release_C_heap_structures() {
2724 
2725   // Clean up C heap
2726   release_C_heap_structures_internal();
2727   constants()-&gt;release_C_heap_structures();
2728 
2729   // Deallocate and call destructors for MDO mutexes
2730   methods_do(method_release_C_heap_structures);
2731 }
2732 
2733 void InstanceKlass::release_C_heap_structures_internal() {
2734   Klass::release_C_heap_structures();
2735 
2736   // Can&#39;t release the constant pool here because the constant pool can be
2737   // deallocated separately from the InstanceKlass for default methods and
2738   // redefine classes.
2739 
2740   // Deallocate oop map cache
2741   if (_oop_map_cache != NULL) {
2742     delete _oop_map_cache;
2743     _oop_map_cache = NULL;
2744   }
2745 
2746   // Deallocate JNI identifiers for jfieldIDs
2747   JNIid::deallocate(jni_ids());
2748   set_jni_ids(NULL);
2749 
2750   jmethodID* jmeths = methods_jmethod_ids_acquire();
2751   if (jmeths != (jmethodID*)NULL) {
2752     release_set_methods_jmethod_ids(NULL);
2753     FreeHeap(jmeths);
2754   }
2755 
2756   assert(_dep_context == NULL,
2757          &quot;dependencies should already be cleaned&quot;);
2758 
2759 #if INCLUDE_JVMTI
2760   // Deallocate breakpoint records
2761   if (breakpoints() != 0x0) {
2762     methods_do(clear_all_breakpoints);
2763     assert(breakpoints() == 0x0, &quot;should have cleared breakpoints&quot;);
2764   }
2765 
2766   // deallocate the cached class file
2767   if (_cached_class_file != NULL) {
2768     os::free(_cached_class_file);
2769     _cached_class_file = NULL;
2770   }
2771 #endif
2772 
2773   FREE_C_HEAP_ARRAY(char, _source_debug_extension);
2774 }
2775 
2776 void InstanceKlass::set_source_debug_extension(const char* array, int length) {
2777   if (array == NULL) {
2778     _source_debug_extension = NULL;
2779   } else {
2780     // Adding one to the attribute length in order to store a null terminator
2781     // character could cause an overflow because the attribute length is
2782     // already coded with an u4 in the classfile, but in practice, it&#39;s
2783     // unlikely to happen.
2784     assert((length+1) &gt; length, &quot;Overflow checking&quot;);
2785     char* sde = NEW_C_HEAP_ARRAY(char, (length + 1), mtClass);
2786     for (int i = 0; i &lt; length; i++) {
2787       sde[i] = array[i];
2788     }
2789     sde[length] = &#39;\0&#39;;
2790     _source_debug_extension = sde;
2791   }
2792 }
2793 
2794 const char* InstanceKlass::signature_name() const {
2795   int hash_len = 0;
2796   char hash_buf[40];
2797 
2798   // If this is an unsafe anonymous class, append a hash to make the name unique
2799   if (is_unsafe_anonymous()) {
2800     intptr_t hash = (java_mirror() != NULL) ? java_mirror()-&gt;identity_hash() : 0;
2801     jio_snprintf(hash_buf, sizeof(hash_buf), &quot;/&quot; UINTX_FORMAT, (uintx)hash);
2802     hash_len = (int)strlen(hash_buf);
2803   }
2804 
2805   // Get the internal name as a c string
2806   const char* src = (const char*) (name()-&gt;as_C_string());
2807   const int src_length = (int)strlen(src);
2808 
2809   char* dest = NEW_RESOURCE_ARRAY(char, src_length + hash_len + 3);
2810 
2811   // Add L or Q as type indicator
2812   int dest_index = 0;
2813   dest[dest_index++] = is_value() ? JVM_SIGNATURE_VALUETYPE : JVM_SIGNATURE_CLASS;
2814 
2815   // Add the actual class name
2816   for (int src_index = 0; src_index &lt; src_length; ) {
2817     dest[dest_index++] = src[src_index++];
2818   }
2819 
2820   if (is_hidden()) { // Replace the last &#39;+&#39; with a &#39;.&#39;.
2821     for (int index = (int)src_length; index &gt; 0; index--) {
2822       if (dest[index] == &#39;+&#39;) {
2823         dest[index] = JVM_SIGNATURE_DOT;
2824         break;
2825       }
2826     }
2827   }
2828 
2829   // If we have a hash, append it
2830   for (int hash_index = 0; hash_index &lt; hash_len; ) {
2831     dest[dest_index++] = hash_buf[hash_index++];
2832   }
2833 
2834   // Add the semicolon and the NULL
2835   dest[dest_index++] = JVM_SIGNATURE_ENDCLASS;
2836   dest[dest_index] = &#39;\0&#39;;
2837   return dest;
2838 }
2839 
2840 ModuleEntry* InstanceKlass::module() const {
2841   // For an unsafe anonymous class return the host class&#39; module
2842   if (is_unsafe_anonymous()) {
2843     assert(unsafe_anonymous_host() != NULL, &quot;unsafe anonymous class must have a host class&quot;);
2844     return unsafe_anonymous_host()-&gt;module();
2845   }
2846 
2847   if (is_hidden() &amp;&amp;
2848       in_unnamed_package() &amp;&amp;
2849       class_loader_data()-&gt;has_class_mirror_holder()) {
2850     // For a non-strong hidden class defined to an unnamed package,
2851     // its (class held) CLD will not have an unnamed module created for it.
2852     // Two choices to find the correct ModuleEntry:
2853     // 1. If hidden class is within a nest, use nest host&#39;s module
2854     // 2. Find the unnamed module off from the class loader
2855     // For now option #2 is used since a nest host is not set until
2856     // after the instance class is created in jvm_lookup_define_class().
2857     if (class_loader_data()-&gt;is_boot_class_loader_data()) {
2858       return ClassLoaderData::the_null_class_loader_data()-&gt;unnamed_module();
2859     } else {
2860       oop module = java_lang_ClassLoader::unnamedModule(class_loader_data()-&gt;class_loader());
2861       assert(java_lang_Module::is_instance(module), &quot;Not an instance of java.lang.Module&quot;);
2862       return java_lang_Module::module_entry(module);
2863     }
2864   }
2865 
2866   // Class is in a named package
2867   if (!in_unnamed_package()) {
2868     return _package_entry-&gt;module();
2869   }
2870 
2871   // Class is in an unnamed package, return its loader&#39;s unnamed module
2872   return class_loader_data()-&gt;unnamed_module();
2873 }
2874 
2875 void InstanceKlass::set_package(ClassLoaderData* loader_data, PackageEntry* pkg_entry, TRAPS) {
2876 
2877   // ensure java/ packages only loaded by boot or platform builtin loaders
2878   // not needed for shared class since CDS does not archive prohibited classes.
2879   if (!is_shared()) {
2880     check_prohibited_package(name(), loader_data, CHECK);
2881   }
2882 
2883   TempNewSymbol pkg_name = pkg_entry != NULL ? pkg_entry-&gt;name() : ClassLoader::package_from_class_name(name());
2884 
2885   if (pkg_name != NULL &amp;&amp; loader_data != NULL) {
2886 
2887     // Find in class loader&#39;s package entry table.
2888     _package_entry = pkg_entry != NULL ? pkg_entry : loader_data-&gt;packages()-&gt;lookup_only(pkg_name);
2889 
2890     // If the package name is not found in the loader&#39;s package
2891     // entry table, it is an indication that the package has not
2892     // been defined. Consider it defined within the unnamed module.
2893     if (_package_entry == NULL) {
2894 
2895       if (!ModuleEntryTable::javabase_defined()) {
2896         // Before java.base is defined during bootstrapping, define all packages in
2897         // the java.base module.  If a non-java.base package is erroneously placed
2898         // in the java.base module it will be caught later when java.base
2899         // is defined by ModuleEntryTable::verify_javabase_packages check.
2900         assert(ModuleEntryTable::javabase_moduleEntry() != NULL, JAVA_BASE_NAME &quot; module is NULL&quot;);
2901         _package_entry = loader_data-&gt;packages()-&gt;lookup(pkg_name, ModuleEntryTable::javabase_moduleEntry());
2902       } else {
2903         assert(loader_data-&gt;unnamed_module() != NULL, &quot;unnamed module is NULL&quot;);
2904         _package_entry = loader_data-&gt;packages()-&gt;lookup(pkg_name,
2905                                                          loader_data-&gt;unnamed_module());
2906       }
2907 
2908       // A package should have been successfully created
2909       DEBUG_ONLY(ResourceMark rm(THREAD));
2910       assert(_package_entry != NULL, &quot;Package entry for class %s not found, loader %s&quot;,
2911              name()-&gt;as_C_string(), loader_data-&gt;loader_name_and_id());
2912     }
2913 
2914     if (log_is_enabled(Debug, module)) {
2915       ResourceMark rm(THREAD);
2916       ModuleEntry* m = _package_entry-&gt;module();
2917       log_trace(module)(&quot;Setting package: class: %s, package: %s, loader: %s, module: %s&quot;,
2918                         external_name(),
2919                         pkg_name-&gt;as_C_string(),
2920                         loader_data-&gt;loader_name_and_id(),
2921                         (m-&gt;is_named() ? m-&gt;name()-&gt;as_C_string() : UNNAMED_MODULE));
2922     }
2923   } else {
2924     ResourceMark rm(THREAD);
2925     log_trace(module)(&quot;Setting package: class: %s, package: unnamed, loader: %s, module: %s&quot;,
2926                       external_name(),
2927                       (loader_data != NULL) ? loader_data-&gt;loader_name_and_id() : &quot;NULL&quot;,
2928                       UNNAMED_MODULE);
2929   }
2930 }
2931 
2932 // Function set_classpath_index checks if the package of the InstanceKlass is in the
2933 // boot loader&#39;s package entry table.  If so, then it sets the classpath_index
2934 // in the package entry record.
2935 //
2936 // The classpath_index field is used to find the entry on the boot loader class
2937 // path for packages with classes loaded by the boot loader from -Xbootclasspath/a
2938 // in an unnamed module.  It is also used to indicate (for all packages whose
2939 // classes are loaded by the boot loader) that at least one of the package&#39;s
2940 // classes has been loaded.
2941 void InstanceKlass::set_classpath_index(s2 path_index, TRAPS) {
2942   if (_package_entry != NULL) {
2943     DEBUG_ONLY(PackageEntryTable* pkg_entry_tbl = ClassLoaderData::the_null_class_loader_data()-&gt;packages();)
2944     assert(pkg_entry_tbl-&gt;lookup_only(_package_entry-&gt;name()) == _package_entry, &quot;Should be same&quot;);
2945     assert(path_index != -1, &quot;Unexpected classpath_index&quot;);
2946     _package_entry-&gt;set_classpath_index(path_index);
2947   }
2948 }
2949 
2950 // different versions of is_same_class_package
2951 
2952 bool InstanceKlass::is_same_class_package(const Klass* class2) const {
2953   oop classloader1 = this-&gt;class_loader();
2954   PackageEntry* classpkg1 = this-&gt;package();
2955   if (class2-&gt;is_objArray_klass()) {
2956     class2 = ObjArrayKlass::cast(class2)-&gt;bottom_klass();
2957   }
2958 
2959   oop classloader2;
2960   PackageEntry* classpkg2;
2961   if (class2-&gt;is_instance_klass()) {
2962     classloader2 = class2-&gt;class_loader();
2963     classpkg2 = class2-&gt;package();
2964   } else {
2965     assert(class2-&gt;is_typeArray_klass(), &quot;should be type array&quot;);
2966     classloader2 = NULL;
2967     classpkg2 = NULL;
2968   }
2969 
2970   // Same package is determined by comparing class loader
2971   // and package entries. Both must be the same. This rule
2972   // applies even to classes that are defined in the unnamed
2973   // package, they still must have the same class loader.
2974   if ((classloader1 == classloader2) &amp;&amp; (classpkg1 == classpkg2)) {
2975     return true;
2976   }
2977 
2978   return false;
2979 }
2980 
2981 // return true if this class and other_class are in the same package. Classloader
2982 // and classname information is enough to determine a class&#39;s package
2983 bool InstanceKlass::is_same_class_package(oop other_class_loader,
2984                                           const Symbol* other_class_name) const {
2985   if (class_loader() != other_class_loader) {
2986     return false;
2987   }
2988   if (name()-&gt;fast_compare(other_class_name) == 0) {
2989      return true;
2990   }
2991 
2992   {
2993     ResourceMark rm;
2994 
2995     bool bad_class_name = false;
2996     TempNewSymbol other_pkg = ClassLoader::package_from_class_name(other_class_name, &amp;bad_class_name);
2997     if (bad_class_name) {
2998       return false;
2999     }
3000     // Check that package_from_class_name() returns NULL, not &quot;&quot;, if there is no package.
3001     assert(other_pkg == NULL || other_pkg-&gt;utf8_length() &gt; 0, &quot;package name is empty string&quot;);
3002 
3003     const Symbol* const this_package_name =
3004       this-&gt;package() != NULL ? this-&gt;package()-&gt;name() : NULL;
3005 
3006     if (this_package_name == NULL || other_pkg == NULL) {
3007       // One of the two doesn&#39;t have a package.  Only return true if the other
3008       // one also doesn&#39;t have a package.
3009       return this_package_name == other_pkg;
3010     }
3011 
3012     // Check if package is identical
3013     return this_package_name-&gt;fast_compare(other_pkg) == 0;
3014   }
3015 }
3016 
3017 // Returns true iff super_method can be overridden by a method in targetclassname
3018 // See JLS 3rd edition 8.4.6.1
3019 // Assumes name-signature match
3020 // &quot;this&quot; is InstanceKlass of super_method which must exist
3021 // note that the InstanceKlass of the method in the targetclassname has not always been created yet
3022 bool InstanceKlass::is_override(const methodHandle&amp; super_method, Handle targetclassloader, Symbol* targetclassname, TRAPS) {
3023    // Private methods can not be overridden
3024    if (super_method-&gt;is_private()) {
3025      return false;
3026    }
3027    // If super method is accessible, then override
3028    if ((super_method-&gt;is_protected()) ||
3029        (super_method-&gt;is_public())) {
3030      return true;
3031    }
3032    // Package-private methods are not inherited outside of package
3033    assert(super_method-&gt;is_package_private(), &quot;must be package private&quot;);
3034    return(is_same_class_package(targetclassloader(), targetclassname));
3035 }
3036 
3037 // Only boot and platform class loaders can define classes in &quot;java/&quot; packages.
3038 void InstanceKlass::check_prohibited_package(Symbol* class_name,
3039                                              ClassLoaderData* loader_data,
3040                                              TRAPS) {
3041   if (!loader_data-&gt;is_boot_class_loader_data() &amp;&amp;
3042       !loader_data-&gt;is_platform_class_loader_data() &amp;&amp;
3043       class_name != NULL) {
3044     ResourceMark rm(THREAD);
3045     char* name = class_name-&gt;as_C_string();
3046     if (strncmp(name, JAVAPKG, JAVAPKG_LEN) == 0 &amp;&amp; name[JAVAPKG_LEN] == &#39;/&#39;) {
3047       TempNewSymbol pkg_name = ClassLoader::package_from_class_name(class_name);
3048       assert(pkg_name != NULL, &quot;Error in parsing package name starting with &#39;java/&#39;&quot;);
3049       name = pkg_name-&gt;as_C_string();
3050       const char* class_loader_name = loader_data-&gt;loader_name_and_id();
3051       StringUtils::replace_no_expand(name, &quot;/&quot;, &quot;.&quot;);
3052       const char* msg_text1 = &quot;Class loader (instance of): &quot;;
3053       const char* msg_text2 = &quot; tried to load prohibited package name: &quot;;
3054       size_t len = strlen(msg_text1) + strlen(class_loader_name) + strlen(msg_text2) + strlen(name) + 1;
3055       char* message = NEW_RESOURCE_ARRAY_IN_THREAD(THREAD, char, len);
3056       jio_snprintf(message, len, &quot;%s%s%s%s&quot;, msg_text1, class_loader_name, msg_text2, name);
3057       THROW_MSG(vmSymbols::java_lang_SecurityException(), message);
3058     }
3059   }
3060   return;
3061 }
3062 
3063 bool InstanceKlass::find_inner_classes_attr(int* ooff, int* noff, TRAPS) const {
3064   constantPoolHandle i_cp(THREAD, constants());
3065   for (InnerClassesIterator iter(this); !iter.done(); iter.next()) {
3066     int ioff = iter.inner_class_info_index();
3067     if (ioff != 0) {
3068       // Check to see if the name matches the class we&#39;re looking for
3069       // before attempting to find the class.
3070       if (i_cp-&gt;klass_name_at_matches(this, ioff)) {
3071         Klass* inner_klass = i_cp-&gt;klass_at(ioff, CHECK_false);
3072         if (this == inner_klass) {
3073           *ooff = iter.outer_class_info_index();
3074           *noff = iter.inner_name_index();
3075           return true;
3076         }
3077       }
3078     }
3079   }
3080   return false;
3081 }
3082 
3083 InstanceKlass* InstanceKlass::compute_enclosing_class(bool* inner_is_member, TRAPS) const {
3084   InstanceKlass* outer_klass = NULL;
3085   *inner_is_member = false;
3086   int ooff = 0, noff = 0;
3087   bool has_inner_classes_attr = find_inner_classes_attr(&amp;ooff, &amp;noff, THREAD);
3088   if (has_inner_classes_attr) {
3089     constantPoolHandle i_cp(THREAD, constants());
3090     if (ooff != 0) {
3091       Klass* ok = i_cp-&gt;klass_at(ooff, CHECK_NULL);
3092       outer_klass = InstanceKlass::cast(ok);
3093       *inner_is_member = true;
3094     }
3095     if (NULL == outer_klass) {
3096       // It may be a local or anonymous class; try for that.
3097       int encl_method_class_idx = enclosing_method_class_index();
3098       if (encl_method_class_idx != 0) {
3099         Klass* ok = i_cp-&gt;klass_at(encl_method_class_idx, CHECK_NULL);
3100         outer_klass = InstanceKlass::cast(ok);
3101         *inner_is_member = false;
3102       }
3103     }
3104   }
3105 
3106   // If no inner class attribute found for this class.
3107   if (NULL == outer_klass) return NULL;
3108 
3109   // Throws an exception if outer klass has not declared k as an inner klass
3110   // We need evidence that each klass knows about the other, or else
3111   // the system could allow a spoof of an inner class to gain access rights.
3112   Reflection::check_for_inner_class(outer_klass, this, *inner_is_member, CHECK_NULL);
3113   return outer_klass;
3114 }
3115 
3116 jint InstanceKlass::compute_modifier_flags(TRAPS) const {
3117   jint access = access_flags().as_int();
3118 
3119   // But check if it happens to be member class.
3120   InnerClassesIterator iter(this);
3121   for (; !iter.done(); iter.next()) {
3122     int ioff = iter.inner_class_info_index();
3123     // Inner class attribute can be zero, skip it.
3124     // Strange but true:  JVM spec. allows null inner class refs.
3125     if (ioff == 0) continue;
3126 
3127     // only look at classes that are already loaded
3128     // since we are looking for the flags for our self.
3129     Symbol* inner_name = constants()-&gt;klass_name_at(ioff);
3130     if (name() == inner_name) {
3131       // This is really a member class.
3132       access = iter.inner_access_flags();
3133       break;
3134     }
3135   }
3136   // Remember to strip ACC_SUPER bit
3137   return (access &amp; (~JVM_ACC_SUPER)) &amp; JVM_ACC_WRITTEN_FLAGS;
3138 }
3139 
3140 jint InstanceKlass::jvmti_class_status() const {
3141   jint result = 0;
3142 
3143   if (is_linked()) {
3144     result |= JVMTI_CLASS_STATUS_VERIFIED | JVMTI_CLASS_STATUS_PREPARED;
3145   }
3146 
3147   if (is_initialized()) {
3148     assert(is_linked(), &quot;Class status is not consistent&quot;);
3149     result |= JVMTI_CLASS_STATUS_INITIALIZED;
3150   }
3151   if (is_in_error_state()) {
3152     result |= JVMTI_CLASS_STATUS_ERROR;
3153   }
3154   return result;
3155 }
3156 
3157 Method* InstanceKlass::method_at_itable(Klass* holder, int index, TRAPS) {
3158   itableOffsetEntry* ioe = (itableOffsetEntry*)start_of_itable();
3159   int method_table_offset_in_words = ioe-&gt;offset()/wordSize;
3160   int nof_interfaces = (method_table_offset_in_words - itable_offset_in_words())
3161                        / itableOffsetEntry::size();
3162 
3163   for (int cnt = 0 ; ; cnt ++, ioe ++) {
3164     // If the interface isn&#39;t implemented by the receiver class,
3165     // the VM should throw IncompatibleClassChangeError.
3166     if (cnt &gt;= nof_interfaces) {
3167       ResourceMark rm(THREAD);
3168       stringStream ss;
3169       bool same_module = (module() == holder-&gt;module());
3170       ss.print(&quot;Receiver class %s does not implement &quot;
3171                &quot;the interface %s defining the method to be called &quot;
3172                &quot;(%s%s%s)&quot;,
3173                external_name(), holder-&gt;external_name(),
3174                (same_module) ? joint_in_module_of_loader(holder) : class_in_module_of_loader(),
3175                (same_module) ? &quot;&quot; : &quot;; &quot;,
3176                (same_module) ? &quot;&quot; : holder-&gt;class_in_module_of_loader());
3177       THROW_MSG_NULL(vmSymbols::java_lang_IncompatibleClassChangeError(), ss.as_string());
3178     }
3179 
3180     Klass* ik = ioe-&gt;interface_klass();
3181     if (ik == holder) break;
3182   }
3183 
3184   itableMethodEntry* ime = ioe-&gt;first_method_entry(this);
3185   Method* m = ime[index].method();
3186   if (m == NULL) {
3187     THROW_NULL(vmSymbols::java_lang_AbstractMethodError());
3188   }
3189   return m;
3190 }
3191 
3192 
3193 #if INCLUDE_JVMTI
3194 // update default_methods for redefineclasses for methods that are
3195 // not yet in the vtable due to concurrent subclass define and superinterface
3196 // redefinition
3197 // Note: those in the vtable, should have been updated via adjust_method_entries
3198 void InstanceKlass::adjust_default_methods(bool* trace_name_printed) {
3199   // search the default_methods for uses of either obsolete or EMCP methods
3200   if (default_methods() != NULL) {
3201     for (int index = 0; index &lt; default_methods()-&gt;length(); index ++) {
3202       Method* old_method = default_methods()-&gt;at(index);
3203       if (old_method == NULL || !old_method-&gt;is_old()) {
3204         continue; // skip uninteresting entries
3205       }
3206       assert(!old_method-&gt;is_deleted(), &quot;default methods may not be deleted&quot;);
3207       Method* new_method = old_method-&gt;get_new_method();
3208       default_methods()-&gt;at_put(index, new_method);
3209 
3210       if (log_is_enabled(Info, redefine, class, update)) {
3211         ResourceMark rm;
3212         if (!(*trace_name_printed)) {
3213           log_info(redefine, class, update)
3214             (&quot;adjust: klassname=%s default methods from name=%s&quot;,
3215              external_name(), old_method-&gt;method_holder()-&gt;external_name());
3216           *trace_name_printed = true;
3217         }
3218         log_debug(redefine, class, update, vtables)
3219           (&quot;default method update: %s(%s) &quot;,
3220            new_method-&gt;name()-&gt;as_C_string(), new_method-&gt;signature()-&gt;as_C_string());
3221       }
3222     }
3223   }
3224 }
3225 #endif // INCLUDE_JVMTI
3226 
3227 // On-stack replacement stuff
3228 void InstanceKlass::add_osr_nmethod(nmethod* n) {
3229   assert_lock_strong(CompiledMethod_lock);
3230 #ifndef PRODUCT
3231   if (TieredCompilation) {
3232       nmethod * prev = lookup_osr_nmethod(n-&gt;method(), n-&gt;osr_entry_bci(), n-&gt;comp_level(), true);
3233       assert(prev == NULL || !prev-&gt;is_in_use(),
3234       &quot;redundunt OSR recompilation detected. memory leak in CodeCache!&quot;);
3235   }
3236 #endif
3237   // only one compilation can be active
3238   {
3239     assert(n-&gt;is_osr_method(), &quot;wrong kind of nmethod&quot;);
3240     n-&gt;set_osr_link(osr_nmethods_head());
3241     set_osr_nmethods_head(n);
3242     // Raise the highest osr level if necessary
3243     if (TieredCompilation) {
3244       Method* m = n-&gt;method();
3245       m-&gt;set_highest_osr_comp_level(MAX2(m-&gt;highest_osr_comp_level(), n-&gt;comp_level()));
3246     }
3247   }
3248 
3249   // Get rid of the osr methods for the same bci that have lower levels.
3250   if (TieredCompilation) {
3251     for (int l = CompLevel_limited_profile; l &lt; n-&gt;comp_level(); l++) {
3252       nmethod *inv = lookup_osr_nmethod(n-&gt;method(), n-&gt;osr_entry_bci(), l, true);
3253       if (inv != NULL &amp;&amp; inv-&gt;is_in_use()) {
3254         inv-&gt;make_not_entrant();
3255       }
3256     }
3257   }
3258 }
3259 
3260 // Remove osr nmethod from the list. Return true if found and removed.
3261 bool InstanceKlass::remove_osr_nmethod(nmethod* n) {
3262   // This is a short non-blocking critical region, so the no safepoint check is ok.
3263   MutexLocker ml(CompiledMethod_lock-&gt;owned_by_self() ? NULL : CompiledMethod_lock
3264                  , Mutex::_no_safepoint_check_flag);
3265   assert(n-&gt;is_osr_method(), &quot;wrong kind of nmethod&quot;);
3266   nmethod* last = NULL;
3267   nmethod* cur  = osr_nmethods_head();
3268   int max_level = CompLevel_none;  // Find the max comp level excluding n
3269   Method* m = n-&gt;method();
3270   // Search for match
3271   bool found = false;
3272   while(cur != NULL &amp;&amp; cur != n) {
3273     if (TieredCompilation &amp;&amp; m == cur-&gt;method()) {
3274       // Find max level before n
3275       max_level = MAX2(max_level, cur-&gt;comp_level());
3276     }
3277     last = cur;
3278     cur = cur-&gt;osr_link();
3279   }
3280   nmethod* next = NULL;
3281   if (cur == n) {
3282     found = true;
3283     next = cur-&gt;osr_link();
3284     if (last == NULL) {
3285       // Remove first element
3286       set_osr_nmethods_head(next);
3287     } else {
3288       last-&gt;set_osr_link(next);
3289     }
3290   }
3291   n-&gt;set_osr_link(NULL);
3292   if (TieredCompilation) {
3293     cur = next;
3294     while (cur != NULL) {
3295       // Find max level after n
3296       if (m == cur-&gt;method()) {
3297         max_level = MAX2(max_level, cur-&gt;comp_level());
3298       }
3299       cur = cur-&gt;osr_link();
3300     }
3301     m-&gt;set_highest_osr_comp_level(max_level);
3302   }
3303   return found;
3304 }
3305 
3306 int InstanceKlass::mark_osr_nmethods(const Method* m) {
3307   MutexLocker ml(CompiledMethod_lock-&gt;owned_by_self() ? NULL : CompiledMethod_lock,
3308                  Mutex::_no_safepoint_check_flag);
3309   nmethod* osr = osr_nmethods_head();
3310   int found = 0;
3311   while (osr != NULL) {
3312     assert(osr-&gt;is_osr_method(), &quot;wrong kind of nmethod found in chain&quot;);
3313     if (osr-&gt;method() == m) {
3314       osr-&gt;mark_for_deoptimization();
3315       found++;
3316     }
3317     osr = osr-&gt;osr_link();
3318   }
3319   return found;
3320 }
3321 
3322 nmethod* InstanceKlass::lookup_osr_nmethod(const Method* m, int bci, int comp_level, bool match_level) const {
3323   MutexLocker ml(CompiledMethod_lock-&gt;owned_by_self() ? NULL : CompiledMethod_lock,
3324                  Mutex::_no_safepoint_check_flag);
3325   nmethod* osr = osr_nmethods_head();
3326   nmethod* best = NULL;
3327   while (osr != NULL) {
3328     assert(osr-&gt;is_osr_method(), &quot;wrong kind of nmethod found in chain&quot;);
3329     // There can be a time when a c1 osr method exists but we are waiting
3330     // for a c2 version. When c2 completes its osr nmethod we will trash
3331     // the c1 version and only be able to find the c2 version. However
3332     // while we overflow in the c1 code at back branches we don&#39;t want to
3333     // try and switch to the same code as we are already running
3334 
3335     if (osr-&gt;method() == m &amp;&amp;
3336         (bci == InvocationEntryBci || osr-&gt;osr_entry_bci() == bci)) {
3337       if (match_level) {
3338         if (osr-&gt;comp_level() == comp_level) {
3339           // Found a match - return it.
3340           return osr;
3341         }
3342       } else {
3343         if (best == NULL || (osr-&gt;comp_level() &gt; best-&gt;comp_level())) {
3344           if (osr-&gt;comp_level() == CompLevel_highest_tier) {
3345             // Found the best possible - return it.
3346             return osr;
3347           }
3348           best = osr;
3349         }
3350       }
3351     }
3352     osr = osr-&gt;osr_link();
3353   }
3354 
3355   assert(match_level == false || best == NULL, &quot;shouldn&#39;t pick up anything if match_level is set&quot;);
3356   if (best != NULL &amp;&amp; best-&gt;comp_level() &gt;= comp_level) {
3357     return best;
3358   }
3359   return NULL;
3360 }
3361 
3362 // -----------------------------------------------------------------------------------------------------
3363 // Printing
3364 
3365 #ifndef PRODUCT
3366 
3367 #define BULLET  &quot; - &quot;
3368 
3369 static const char* state_names[] = {
3370   &quot;allocated&quot;, &quot;loaded&quot;, &quot;linked&quot;, &quot;being_initialized&quot;, &quot;fully_initialized&quot;, &quot;initialization_error&quot;
3371 };
3372 
3373 static void print_vtable(address self, intptr_t* start, int len, outputStream* st) {
3374   ResourceMark rm;
3375   int* forward_refs = NEW_RESOURCE_ARRAY(int, len);
3376   for (int i = 0; i &lt; len; i++)  forward_refs[i] = 0;
3377   for (int i = 0; i &lt; len; i++) {
3378     intptr_t e = start[i];
3379     st-&gt;print(&quot;%d : &quot; INTPTR_FORMAT, i, e);
3380     if (forward_refs[i] != 0) {
3381       int from = forward_refs[i];
3382       int off = (int) start[from];
3383       st-&gt;print(&quot; (offset %d &lt;= [%d])&quot;, off, from);
3384     }
3385     if (MetaspaceObj::is_valid((Metadata*)e)) {
3386       st-&gt;print(&quot; &quot;);
3387       ((Metadata*)e)-&gt;print_value_on(st);
3388     } else if (self != NULL &amp;&amp; e &gt; 0 &amp;&amp; e &lt; 0x10000) {
3389       address location = self + e;
3390       int index = (int)((intptr_t*)location - start);
3391       st-&gt;print(&quot; (offset %d =&gt; [%d])&quot;, (int)e, index);
3392       if (index &gt;= 0 &amp;&amp; index &lt; len)
3393         forward_refs[index] = i;
3394     }
3395     st-&gt;cr();
3396   }
3397 }
3398 
3399 static void print_vtable(vtableEntry* start, int len, outputStream* st) {
3400   return print_vtable(NULL, reinterpret_cast&lt;intptr_t*&gt;(start), len, st);
3401 }
3402 
3403 template&lt;typename T&gt;
3404  static void print_array_on(outputStream* st, Array&lt;T&gt;* array) {
3405    if (array == NULL) { st-&gt;print_cr(&quot;NULL&quot;); return; }
3406    array-&gt;print_value_on(st); st-&gt;cr();
3407    if (Verbose || WizardMode) {
3408      for (int i = 0; i &lt; array-&gt;length(); i++) {
3409        st-&gt;print(&quot;%d : &quot;, i); array-&gt;at(i)-&gt;print_value_on(st); st-&gt;cr();
3410      }
3411    }
3412  }
3413 
3414 static void print_array_on(outputStream* st, Array&lt;int&gt;* array) {
3415   if (array == NULL) { st-&gt;print_cr(&quot;NULL&quot;); return; }
3416   array-&gt;print_value_on(st); st-&gt;cr();
3417   if (Verbose || WizardMode) {
3418     for (int i = 0; i &lt; array-&gt;length(); i++) {
3419       st-&gt;print(&quot;%d : %d&quot;, i, array-&gt;at(i)); st-&gt;cr();
3420     }
3421   }
3422 }
3423 
3424 void InstanceKlass::print_on(outputStream* st) const {
3425   assert(is_klass(), &quot;must be klass&quot;);
3426   Klass::print_on(st);
3427 
3428   st-&gt;print(BULLET&quot;instance size:     %d&quot;, size_helper());                        st-&gt;cr();
3429   st-&gt;print(BULLET&quot;klass size:        %d&quot;, size());                               st-&gt;cr();
3430   st-&gt;print(BULLET&quot;access:            &quot;); access_flags().print_on(st);            st-&gt;cr();
3431   st-&gt;print(BULLET&quot;misc flags:        0x%x&quot;, _misc_flags);                        st-&gt;cr();
3432   st-&gt;print(BULLET&quot;state:             &quot;); st-&gt;print_cr(&quot;%s&quot;, state_names[_init_state]);
3433   st-&gt;print(BULLET&quot;name:              &quot;); name()-&gt;print_value_on(st);             st-&gt;cr();
3434   st-&gt;print(BULLET&quot;super:             &quot;); Metadata::print_value_on_maybe_null(st, super()); st-&gt;cr();
3435   st-&gt;print(BULLET&quot;sub:               &quot;);
3436   Klass* sub = subklass();
3437   int n;
3438   for (n = 0; sub != NULL; n++, sub = sub-&gt;next_sibling()) {
3439     if (n &lt; MaxSubklassPrintSize) {
3440       sub-&gt;print_value_on(st);
3441       st-&gt;print(&quot;   &quot;);
3442     }
3443   }
3444   if (n &gt;= MaxSubklassPrintSize) st-&gt;print(&quot;(&quot; INTX_FORMAT &quot; more klasses...)&quot;, n - MaxSubklassPrintSize);
3445   st-&gt;cr();
3446 
3447   if (is_interface()) {
3448     st-&gt;print_cr(BULLET&quot;nof implementors:  %d&quot;, nof_implementors());
3449     if (nof_implementors() == 1) {
3450       st-&gt;print_cr(BULLET&quot;implementor:    &quot;);
3451       st-&gt;print(&quot;   &quot;);
3452       implementor()-&gt;print_value_on(st);
3453       st-&gt;cr();
3454     }
3455   }
3456 
3457   st-&gt;print(BULLET&quot;arrays:            &quot;); Metadata::print_value_on_maybe_null(st, array_klasses()); st-&gt;cr();
3458   st-&gt;print(BULLET&quot;methods:           &quot;); print_array_on(st, methods());
3459   st-&gt;print(BULLET&quot;method ordering:   &quot;); print_array_on(st, method_ordering());
3460   st-&gt;print(BULLET&quot;default_methods:   &quot;); print_array_on(st, default_methods());
3461   if (default_vtable_indices() != NULL) {
3462     st-&gt;print(BULLET&quot;default vtable indices:   &quot;); print_array_on(st, default_vtable_indices());
3463   }
3464   st-&gt;print(BULLET&quot;local interfaces:  &quot;); print_array_on(st, local_interfaces());
3465   st-&gt;print(BULLET&quot;trans. interfaces: &quot;); print_array_on(st, transitive_interfaces());
3466   st-&gt;print(BULLET&quot;constants:         &quot;); constants()-&gt;print_value_on(st);         st-&gt;cr();
3467   if (class_loader_data() != NULL) {
3468     st-&gt;print(BULLET&quot;class loader data:  &quot;);
3469     class_loader_data()-&gt;print_value_on(st);
3470     st-&gt;cr();
3471   }
3472   st-&gt;print(BULLET&quot;unsafe anonymous host class:        &quot;); Metadata::print_value_on_maybe_null(st, unsafe_anonymous_host()); st-&gt;cr();
3473   if (source_file_name() != NULL) {
3474     st-&gt;print(BULLET&quot;source file:       &quot;);
3475     source_file_name()-&gt;print_value_on(st);
3476     st-&gt;cr();
3477   }
3478   if (source_debug_extension() != NULL) {
3479     st-&gt;print(BULLET&quot;source debug extension:       &quot;);
3480     st-&gt;print(&quot;%s&quot;, source_debug_extension());
3481     st-&gt;cr();
3482   }
3483   st-&gt;print(BULLET&quot;class annotations:       &quot;); class_annotations()-&gt;print_value_on(st); st-&gt;cr();
3484   st-&gt;print(BULLET&quot;class type annotations:  &quot;); class_type_annotations()-&gt;print_value_on(st); st-&gt;cr();
3485   st-&gt;print(BULLET&quot;field annotations:       &quot;); fields_annotations()-&gt;print_value_on(st); st-&gt;cr();
3486   st-&gt;print(BULLET&quot;field type annotations:  &quot;); fields_type_annotations()-&gt;print_value_on(st); st-&gt;cr();
3487   {
3488     bool have_pv = false;
3489     // previous versions are linked together through the InstanceKlass
3490     for (InstanceKlass* pv_node = previous_versions();
3491          pv_node != NULL;
3492          pv_node = pv_node-&gt;previous_versions()) {
3493       if (!have_pv)
3494         st-&gt;print(BULLET&quot;previous version:  &quot;);
3495       have_pv = true;
3496       pv_node-&gt;constants()-&gt;print_value_on(st);
3497     }
3498     if (have_pv) st-&gt;cr();
3499   }
3500 
3501   if (generic_signature() != NULL) {
3502     st-&gt;print(BULLET&quot;generic signature: &quot;);
3503     generic_signature()-&gt;print_value_on(st);
3504     st-&gt;cr();
3505   }
3506   st-&gt;print(BULLET&quot;inner classes:     &quot;); inner_classes()-&gt;print_value_on(st);     st-&gt;cr();
3507   st-&gt;print(BULLET&quot;nest members:     &quot;); nest_members()-&gt;print_value_on(st);     st-&gt;cr();
3508   if (record_components() != NULL) {
3509     st-&gt;print(BULLET&quot;record components:     &quot;); record_components()-&gt;print_value_on(st);     st-&gt;cr();
3510   }
3511   if (java_mirror() != NULL) {
3512     st-&gt;print(BULLET&quot;java mirror:       &quot;);
3513     java_mirror()-&gt;print_value_on(st);
3514     st-&gt;cr();
3515   } else {
3516     st-&gt;print_cr(BULLET&quot;java mirror:       NULL&quot;);
3517   }
3518   st-&gt;print(BULLET&quot;vtable length      %d  (start addr: &quot; INTPTR_FORMAT &quot;)&quot;, vtable_length(), p2i(start_of_vtable())); st-&gt;cr();
3519   if (vtable_length() &gt; 0 &amp;&amp; (Verbose || WizardMode))  print_vtable(start_of_vtable(), vtable_length(), st);
3520   st-&gt;print(BULLET&quot;itable length      %d (start addr: &quot; INTPTR_FORMAT &quot;)&quot;, itable_length(), p2i(start_of_itable())); st-&gt;cr();
3521   if (itable_length() &gt; 0 &amp;&amp; (Verbose || WizardMode))  print_vtable(NULL, start_of_itable(), itable_length(), st);
3522   st-&gt;print_cr(BULLET&quot;---- static fields (%d words):&quot;, static_field_size());
3523   FieldPrinter print_static_field(st);
3524   ((InstanceKlass*)this)-&gt;do_local_static_fields(&amp;print_static_field);
3525   st-&gt;print_cr(BULLET&quot;---- non-static fields (%d words):&quot;, nonstatic_field_size());
3526   FieldPrinter print_nonstatic_field(st);
3527   InstanceKlass* ik = const_cast&lt;InstanceKlass*&gt;(this);
3528   ik-&gt;do_nonstatic_fields(&amp;print_nonstatic_field);
3529 
3530   st-&gt;print(BULLET&quot;non-static oop maps: &quot;);
3531   OopMapBlock* map     = start_of_nonstatic_oop_maps();
3532   OopMapBlock* end_map = map + nonstatic_oop_map_count();
3533   while (map &lt; end_map) {
3534     st-&gt;print(&quot;%d-%d &quot;, map-&gt;offset(), map-&gt;offset() + heapOopSize*(map-&gt;count() - 1));
3535     map++;
3536   }
3537   st-&gt;cr();
3538 }
3539 
3540 #endif //PRODUCT
3541 
3542 void InstanceKlass::print_value_on(outputStream* st) const {
3543   assert(is_klass(), &quot;must be klass&quot;);
3544   if (Verbose || WizardMode)  access_flags().print_on(st);
3545   name()-&gt;print_value_on(st);
3546 }
3547 
3548 #ifndef PRODUCT
3549 
3550 void FieldPrinter::do_field(fieldDescriptor* fd) {
3551   _st-&gt;print(BULLET);
3552    if (_obj == NULL) {
3553      fd-&gt;print_on(_st);
3554      _st-&gt;cr();
3555    } else {
3556      fd-&gt;print_on_for(_st, _obj);
3557      _st-&gt;cr();
3558    }
3559 }
3560 
3561 
3562 void InstanceKlass::oop_print_on(oop obj, outputStream* st) {
3563   Klass::oop_print_on(obj, st);
3564 
3565   if (this == SystemDictionary::String_klass()) {
3566     typeArrayOop value  = java_lang_String::value(obj);
3567     juint        length = java_lang_String::length(obj);
3568     if (value != NULL &amp;&amp;
3569         value-&gt;is_typeArray() &amp;&amp;
3570         length &lt;= (juint) value-&gt;length()) {
3571       st-&gt;print(BULLET&quot;string: &quot;);
3572       java_lang_String::print(obj, st);
3573       st-&gt;cr();
3574       if (!WizardMode)  return;  // that is enough
3575     }
3576   }
3577 
3578   st-&gt;print_cr(BULLET&quot;---- fields (total size %d words):&quot;, oop_size(obj));
3579   FieldPrinter print_field(st, obj);
3580   do_nonstatic_fields(&amp;print_field);
3581 
3582   if (this == SystemDictionary::Class_klass()) {
3583     st-&gt;print(BULLET&quot;signature: &quot;);
3584     java_lang_Class::print_signature(obj, st);
3585     st-&gt;cr();
3586     Klass* mirrored_klass = java_lang_Class::as_Klass(obj);
3587     st-&gt;print(BULLET&quot;fake entry for mirror: &quot;);
3588     Metadata::print_value_on_maybe_null(st, mirrored_klass);
3589     st-&gt;cr();
3590     Klass* array_klass = java_lang_Class::array_klass_acquire(obj);
3591     st-&gt;print(BULLET&quot;fake entry for array: &quot;);
3592     Metadata::print_value_on_maybe_null(st, array_klass);
3593     st-&gt;cr();
3594     st-&gt;print_cr(BULLET&quot;fake entry for oop_size: %d&quot;, java_lang_Class::oop_size(obj));
3595     st-&gt;print_cr(BULLET&quot;fake entry for static_oop_field_count: %d&quot;, java_lang_Class::static_oop_field_count(obj));
3596     Klass* real_klass = java_lang_Class::as_Klass(obj);
3597     if (real_klass != NULL &amp;&amp; real_klass-&gt;is_instance_klass()) {
3598       InstanceKlass::cast(real_klass)-&gt;do_local_static_fields(&amp;print_field);
3599     }
3600   } else if (this == SystemDictionary::MethodType_klass()) {
3601     st-&gt;print(BULLET&quot;signature: &quot;);
3602     java_lang_invoke_MethodType::print_signature(obj, st);
3603     st-&gt;cr();
3604   }
3605 }
3606 
3607 bool InstanceKlass::verify_itable_index(int i) {
3608   int method_count = klassItable::method_count_for_interface(this);
3609   assert(i &gt;= 0 &amp;&amp; i &lt; method_count, &quot;index out of bounds&quot;);
3610   return true;
3611 }
3612 
3613 #endif //PRODUCT
3614 
3615 void InstanceKlass::oop_print_value_on(oop obj, outputStream* st) {
3616   st-&gt;print(&quot;a &quot;);
3617   name()-&gt;print_value_on(st);
3618   obj-&gt;print_address_on(st);
3619   if (this == SystemDictionary::String_klass()
3620       &amp;&amp; java_lang_String::value(obj) != NULL) {
3621     ResourceMark rm;
3622     int len = java_lang_String::length(obj);
3623     int plen = (len &lt; 24 ? len : 12);
3624     char* str = java_lang_String::as_utf8_string(obj, 0, plen);
3625     st-&gt;print(&quot; = \&quot;%s\&quot;&quot;, str);
3626     if (len &gt; plen)
3627       st-&gt;print(&quot;...[%d]&quot;, len);
3628   } else if (this == SystemDictionary::Class_klass()) {
3629     Klass* k = java_lang_Class::as_Klass(obj);
3630     st-&gt;print(&quot; = &quot;);
3631     if (k != NULL) {
3632       k-&gt;print_value_on(st);
3633     } else {
3634       const char* tname = type2name(java_lang_Class::primitive_type(obj));
3635       st-&gt;print(&quot;%s&quot;, tname ? tname : &quot;type?&quot;);
3636     }
3637   } else if (this == SystemDictionary::MethodType_klass()) {
3638     st-&gt;print(&quot; = &quot;);
3639     java_lang_invoke_MethodType::print_signature(obj, st);
3640   } else if (java_lang_boxing_object::is_instance(obj)) {
3641     st-&gt;print(&quot; = &quot;);
3642     java_lang_boxing_object::print(obj, st);
3643   } else if (this == SystemDictionary::LambdaForm_klass()) {
3644     oop vmentry = java_lang_invoke_LambdaForm::vmentry(obj);
3645     if (vmentry != NULL) {
3646       st-&gt;print(&quot; =&gt; &quot;);
3647       vmentry-&gt;print_value_on(st);
3648     }
3649   } else if (this == SystemDictionary::MemberName_klass()) {
3650     Metadata* vmtarget = java_lang_invoke_MemberName::vmtarget(obj);
3651     if (vmtarget != NULL) {
3652       st-&gt;print(&quot; = &quot;);
3653       vmtarget-&gt;print_value_on(st);
3654     } else {
3655       java_lang_invoke_MemberName::clazz(obj)-&gt;print_value_on(st);
3656       st-&gt;print(&quot;.&quot;);
3657       java_lang_invoke_MemberName::name(obj)-&gt;print_value_on(st);
3658     }
3659   }
3660 }
3661 
3662 const char* InstanceKlass::internal_name() const {
3663   return external_name();
3664 }
3665 
3666 void InstanceKlass::print_class_load_logging(ClassLoaderData* loader_data,
3667                                              const char* module_name,
3668                                              const ClassFileStream* cfs) const {
3669   if (!log_is_enabled(Info, class, load)) {
3670     return;
3671   }
3672 
3673   ResourceMark rm;
3674   LogMessage(class, load) msg;
3675   stringStream info_stream;
3676 
3677   // Name and class hierarchy info
3678   info_stream.print(&quot;%s&quot;, external_name());
3679 
3680   // Source
3681   if (cfs != NULL) {
3682     if (cfs-&gt;source() != NULL) {
3683       if (module_name != NULL) {
3684         // When the boot loader created the stream, it didn&#39;t know the module name
3685         // yet. Let&#39;s format it now.
3686         if (cfs-&gt;from_boot_loader_modules_image()) {
3687           info_stream.print(&quot; source: jrt:/%s&quot;, module_name);
3688         } else {
3689           info_stream.print(&quot; source: %s&quot;, cfs-&gt;source());
3690         }
3691       } else {
3692         info_stream.print(&quot; source: %s&quot;, cfs-&gt;source());
3693       }
3694     } else if (loader_data == ClassLoaderData::the_null_class_loader_data()) {
3695       Thread* THREAD = Thread::current();
3696       Klass* caller =
3697             THREAD-&gt;is_Java_thread()
3698                 ? ((JavaThread*)THREAD)-&gt;security_get_caller_class(1)
3699                 : NULL;
3700       // caller can be NULL, for example, during a JVMTI VM_Init hook
3701       if (caller != NULL) {
3702         info_stream.print(&quot; source: instance of %s&quot;, caller-&gt;external_name());
3703       } else {
3704         // source is unknown
3705       }
3706     } else {
3707       oop class_loader = loader_data-&gt;class_loader();
3708       info_stream.print(&quot; source: %s&quot;, class_loader-&gt;klass()-&gt;external_name());
3709     }
3710   } else {
3711     assert(this-&gt;is_shared(), &quot;must be&quot;);
3712     if (MetaspaceShared::is_shared_dynamic((void*)this)) {
3713       info_stream.print(&quot; source: shared objects file (top)&quot;);
3714     } else {
3715       info_stream.print(&quot; source: shared objects file&quot;);
3716     }
3717   }
3718 
3719   msg.info(&quot;%s&quot;, info_stream.as_string());
3720 
3721   if (log_is_enabled(Debug, class, load)) {
3722     stringStream debug_stream;
3723 
3724     // Class hierarchy info
3725     debug_stream.print(&quot; klass: &quot; INTPTR_FORMAT &quot; super: &quot; INTPTR_FORMAT,
3726                        p2i(this),  p2i(superklass()));
3727 
3728     // Interfaces
3729     if (local_interfaces() != NULL &amp;&amp; local_interfaces()-&gt;length() &gt; 0) {
3730       debug_stream.print(&quot; interfaces:&quot;);
3731       int length = local_interfaces()-&gt;length();
3732       for (int i = 0; i &lt; length; i++) {
3733         debug_stream.print(&quot; &quot; INTPTR_FORMAT,
3734                            p2i(InstanceKlass::cast(local_interfaces()-&gt;at(i))));
3735       }
3736     }
3737 
3738     // Class loader
3739     debug_stream.print(&quot; loader: [&quot;);
3740     loader_data-&gt;print_value_on(&amp;debug_stream);
3741     debug_stream.print(&quot;]&quot;);
3742 
3743     // Classfile checksum
3744     if (cfs) {
3745       debug_stream.print(&quot; bytes: %d checksum: %08x&quot;,
3746                          cfs-&gt;length(),
3747                          ClassLoader::crc32(0, (const char*)cfs-&gt;buffer(),
3748                          cfs-&gt;length()));
3749     }
3750 
3751     msg.debug(&quot;%s&quot;, debug_stream.as_string());
3752   }
3753 }
3754 
3755 // Verification
3756 
3757 class VerifyFieldClosure: public BasicOopIterateClosure {
3758  protected:
3759   template &lt;class T&gt; void do_oop_work(T* p) {
3760     oop obj = RawAccess&lt;&gt;::oop_load(p);
3761     if (!oopDesc::is_oop_or_null(obj)) {
3762       tty-&gt;print_cr(&quot;Failed: &quot; PTR_FORMAT &quot; -&gt; &quot; PTR_FORMAT, p2i(p), p2i(obj));
3763       Universe::print_on(tty);
3764       guarantee(false, &quot;boom&quot;);
3765     }
3766   }
3767  public:
3768   virtual void do_oop(oop* p)       { VerifyFieldClosure::do_oop_work(p); }
3769   virtual void do_oop(narrowOop* p) { VerifyFieldClosure::do_oop_work(p); }
3770 };
3771 
3772 void InstanceKlass::verify_on(outputStream* st) {
3773 #ifndef PRODUCT
3774   // Avoid redundant verifies, this really should be in product.
3775   if (_verify_count == Universe::verify_count()) return;
3776   _verify_count = Universe::verify_count();
3777 #endif
3778 
3779   // Verify Klass
3780   Klass::verify_on(st);
3781 
3782   // Verify that klass is present in ClassLoaderData
3783   guarantee(class_loader_data()-&gt;contains_klass(this),
3784             &quot;this class isn&#39;t found in class loader data&quot;);
3785 
3786   // Verify vtables
3787   if (is_linked()) {
3788     // $$$ This used to be done only for m/s collections.  Doing it
3789     // always seemed a valid generalization.  (DLD -- 6/00)
3790     vtable().verify(st);
3791   }
3792 
3793   // Verify first subklass
3794   if (subklass() != NULL) {
3795     guarantee(subklass()-&gt;is_klass(), &quot;should be klass&quot;);
3796   }
3797 
3798   // Verify siblings
3799   Klass* super = this-&gt;super();
3800   Klass* sib = next_sibling();
3801   if (sib != NULL) {
3802     if (sib == this) {
3803       fatal(&quot;subclass points to itself &quot; PTR_FORMAT, p2i(sib));
3804     }
3805 
3806     guarantee(sib-&gt;is_klass(), &quot;should be klass&quot;);
3807     guarantee(sib-&gt;super() == super, &quot;siblings should have same superklass&quot;);
3808   }
3809 
3810   // Verify local interfaces
3811   if (local_interfaces()) {
3812     Array&lt;InstanceKlass*&gt;* local_interfaces = this-&gt;local_interfaces();
3813     for (int j = 0; j &lt; local_interfaces-&gt;length(); j++) {
3814       InstanceKlass* e = local_interfaces-&gt;at(j);
3815       guarantee(e-&gt;is_klass() &amp;&amp; e-&gt;is_interface(), &quot;invalid local interface&quot;);
3816     }
3817   }
3818 
3819   // Verify transitive interfaces
3820   if (transitive_interfaces() != NULL) {
3821     Array&lt;InstanceKlass*&gt;* transitive_interfaces = this-&gt;transitive_interfaces();
3822     for (int j = 0; j &lt; transitive_interfaces-&gt;length(); j++) {
3823       InstanceKlass* e = transitive_interfaces-&gt;at(j);
3824       guarantee(e-&gt;is_klass() &amp;&amp; e-&gt;is_interface(), &quot;invalid transitive interface&quot;);
3825     }
3826   }
3827 
3828   // Verify methods
3829   if (methods() != NULL) {
3830     Array&lt;Method*&gt;* methods = this-&gt;methods();
3831     for (int j = 0; j &lt; methods-&gt;length(); j++) {
3832       guarantee(methods-&gt;at(j)-&gt;is_method(), &quot;non-method in methods array&quot;);
3833     }
3834     for (int j = 0; j &lt; methods-&gt;length() - 1; j++) {
3835       Method* m1 = methods-&gt;at(j);
3836       Method* m2 = methods-&gt;at(j + 1);
3837       guarantee(m1-&gt;name()-&gt;fast_compare(m2-&gt;name()) &lt;= 0, &quot;methods not sorted correctly&quot;);
3838     }
3839   }
3840 
3841   // Verify method ordering
3842   if (method_ordering() != NULL) {
3843     Array&lt;int&gt;* method_ordering = this-&gt;method_ordering();
3844     int length = method_ordering-&gt;length();
3845     if (JvmtiExport::can_maintain_original_method_order() ||
3846         ((UseSharedSpaces || Arguments::is_dumping_archive()) &amp;&amp; length != 0)) {
3847       guarantee(length == methods()-&gt;length(), &quot;invalid method ordering length&quot;);
3848       jlong sum = 0;
3849       for (int j = 0; j &lt; length; j++) {
3850         int original_index = method_ordering-&gt;at(j);
3851         guarantee(original_index &gt;= 0, &quot;invalid method ordering index&quot;);
3852         guarantee(original_index &lt; length, &quot;invalid method ordering index&quot;);
3853         sum += original_index;
3854       }
3855       // Verify sum of indices 0,1,...,length-1
3856       guarantee(sum == ((jlong)length*(length-1))/2, &quot;invalid method ordering sum&quot;);
3857     } else {
3858       guarantee(length == 0, &quot;invalid method ordering length&quot;);
3859     }
3860   }
3861 
3862   // Verify default methods
3863   if (default_methods() != NULL) {
3864     Array&lt;Method*&gt;* methods = this-&gt;default_methods();
3865     for (int j = 0; j &lt; methods-&gt;length(); j++) {
3866       guarantee(methods-&gt;at(j)-&gt;is_method(), &quot;non-method in methods array&quot;);
3867     }
3868     for (int j = 0; j &lt; methods-&gt;length() - 1; j++) {
3869       Method* m1 = methods-&gt;at(j);
3870       Method* m2 = methods-&gt;at(j + 1);
3871       guarantee(m1-&gt;name()-&gt;fast_compare(m2-&gt;name()) &lt;= 0, &quot;methods not sorted correctly&quot;);
3872     }
3873   }
3874 
3875   // Verify JNI static field identifiers
3876   if (jni_ids() != NULL) {
3877     jni_ids()-&gt;verify(this);
3878   }
3879 
3880   // Verify other fields
3881   if (array_klasses() != NULL) {
3882     guarantee(array_klasses()-&gt;is_klass(), &quot;should be klass&quot;);
3883   }
3884   if (constants() != NULL) {
3885     guarantee(constants()-&gt;is_constantPool(), &quot;should be constant pool&quot;);
3886   }
3887   const Klass* anonymous_host = unsafe_anonymous_host();
3888   if (anonymous_host != NULL) {
3889     guarantee(anonymous_host-&gt;is_klass(), &quot;should be klass&quot;);
3890   }
3891 }
3892 
3893 void InstanceKlass::oop_verify_on(oop obj, outputStream* st) {
3894   Klass::oop_verify_on(obj, st);
3895   VerifyFieldClosure blk;
3896   obj-&gt;oop_iterate(&amp;blk);
3897 }
3898 
3899 
3900 // JNIid class for jfieldIDs only
3901 // Note to reviewers:
3902 // These JNI functions are just moved over to column 1 and not changed
3903 // in the compressed oops workspace.
3904 JNIid::JNIid(Klass* holder, int offset, JNIid* next) {
3905   _holder = holder;
3906   _offset = offset;
3907   _next = next;
3908   debug_only(_is_static_field_id = false;)
3909 }
3910 
3911 
3912 JNIid* JNIid::find(int offset) {
3913   JNIid* current = this;
3914   while (current != NULL) {
3915     if (current-&gt;offset() == offset) return current;
3916     current = current-&gt;next();
3917   }
3918   return NULL;
3919 }
3920 
3921 void JNIid::deallocate(JNIid* current) {
3922   while (current != NULL) {
3923     JNIid* next = current-&gt;next();
3924     delete current;
3925     current = next;
3926   }
3927 }
3928 
3929 
3930 void JNIid::verify(Klass* holder) {
3931   int first_field_offset  = InstanceMirrorKlass::offset_of_static_fields();
3932   int end_field_offset;
3933   end_field_offset = first_field_offset + (InstanceKlass::cast(holder)-&gt;static_field_size() * wordSize);
3934 
3935   JNIid* current = this;
3936   while (current != NULL) {
3937     guarantee(current-&gt;holder() == holder, &quot;Invalid klass in JNIid&quot;);
3938 #ifdef ASSERT
3939     int o = current-&gt;offset();
3940     if (current-&gt;is_static_field_id()) {
3941       guarantee(o &gt;= first_field_offset  &amp;&amp; o &lt; end_field_offset,  &quot;Invalid static field offset in JNIid&quot;);
3942     }
3943 #endif
3944     current = current-&gt;next();
3945   }
3946 }
3947 
3948 void InstanceKlass::set_init_state(ClassState state) {
3949 #ifdef ASSERT
3950   bool good_state = is_shared() ? (_init_state &lt;= state)
3951                                                : (_init_state &lt; state);
3952   assert(good_state || state == allocated, &quot;illegal state transition&quot;);
3953 #endif
3954   assert(_init_thread == NULL, &quot;should be cleared before state change&quot;);
3955   _init_state = (u1)state;
3956 }
3957 
3958 #if INCLUDE_JVMTI
3959 
3960 // RedefineClasses() support for previous versions
3961 
3962 // Globally, there is at least one previous version of a class to walk
3963 // during class unloading, which is saved because old methods in the class
3964 // are still running.   Otherwise the previous version list is cleaned up.
3965 bool InstanceKlass::_has_previous_versions = false;
3966 
3967 // Returns true if there are previous versions of a class for class
3968 // unloading only. Also resets the flag to false. purge_previous_version
3969 // will set the flag to true if there are any left, i.e., if there&#39;s any
3970 // work to do for next time. This is to avoid the expensive code cache
3971 // walk in CLDG::clean_deallocate_lists().
3972 bool InstanceKlass::has_previous_versions_and_reset() {
3973   bool ret = _has_previous_versions;
3974   log_trace(redefine, class, iklass, purge)(&quot;Class unloading: has_previous_versions = %s&quot;,
3975      ret ? &quot;true&quot; : &quot;false&quot;);
3976   _has_previous_versions = false;
3977   return ret;
3978 }
3979 
3980 // Purge previous versions before adding new previous versions of the class and
3981 // during class unloading.
3982 void InstanceKlass::purge_previous_version_list() {
3983   assert(SafepointSynchronize::is_at_safepoint(), &quot;only called at safepoint&quot;);
3984   assert(has_been_redefined(), &quot;Should only be called for main class&quot;);
3985 
3986   // Quick exit.
3987   if (previous_versions() == NULL) {
3988     return;
3989   }
3990 
3991   // This klass has previous versions so see what we can cleanup
3992   // while it is safe to do so.
3993 
3994   int deleted_count = 0;    // leave debugging breadcrumbs
3995   int live_count = 0;
3996   ClassLoaderData* loader_data = class_loader_data();
3997   assert(loader_data != NULL, &quot;should never be null&quot;);
3998 
3999   ResourceMark rm;
4000   log_trace(redefine, class, iklass, purge)(&quot;%s: previous versions&quot;, external_name());
4001 
4002   // previous versions are linked together through the InstanceKlass
4003   InstanceKlass* pv_node = previous_versions();
4004   InstanceKlass* last = this;
4005   int version = 0;
4006 
4007   // check the previous versions list
4008   for (; pv_node != NULL; ) {
4009 
4010     ConstantPool* pvcp = pv_node-&gt;constants();
4011     assert(pvcp != NULL, &quot;cp ref was unexpectedly cleared&quot;);
4012 
4013     if (!pvcp-&gt;on_stack()) {
4014       // If the constant pool isn&#39;t on stack, none of the methods
4015       // are executing.  Unlink this previous_version.
4016       // The previous version InstanceKlass is on the ClassLoaderData deallocate list
4017       // so will be deallocated during the next phase of class unloading.
4018       log_trace(redefine, class, iklass, purge)
4019         (&quot;previous version &quot; INTPTR_FORMAT &quot; is dead.&quot;, p2i(pv_node));
4020       // For debugging purposes.
4021       pv_node-&gt;set_is_scratch_class();
4022       // Unlink from previous version list.
4023       assert(pv_node-&gt;class_loader_data() == loader_data, &quot;wrong loader_data&quot;);
4024       InstanceKlass* next = pv_node-&gt;previous_versions();
4025       pv_node-&gt;link_previous_versions(NULL);   // point next to NULL
4026       last-&gt;link_previous_versions(next);
4027       // Add to the deallocate list after unlinking
4028       loader_data-&gt;add_to_deallocate_list(pv_node);
4029       pv_node = next;
4030       deleted_count++;
4031       version++;
4032       continue;
4033     } else {
4034       log_trace(redefine, class, iklass, purge)(&quot;previous version &quot; INTPTR_FORMAT &quot; is alive&quot;, p2i(pv_node));
4035       assert(pvcp-&gt;pool_holder() != NULL, &quot;Constant pool with no holder&quot;);
4036       guarantee (!loader_data-&gt;is_unloading(), &quot;unloaded classes can&#39;t be on the stack&quot;);
4037       live_count++;
4038       // found a previous version for next time we do class unloading
4039       _has_previous_versions = true;
4040     }
4041 
4042     // At least one method is live in this previous version.
4043     // Reset dead EMCP methods not to get breakpoints.
4044     // All methods are deallocated when all of the methods for this class are no
4045     // longer running.
4046     Array&lt;Method*&gt;* method_refs = pv_node-&gt;methods();
4047     if (method_refs != NULL) {
4048       log_trace(redefine, class, iklass, purge)(&quot;previous methods length=%d&quot;, method_refs-&gt;length());
4049       for (int j = 0; j &lt; method_refs-&gt;length(); j++) {
4050         Method* method = method_refs-&gt;at(j);
4051 
4052         if (!method-&gt;on_stack()) {
4053           // no breakpoints for non-running methods
4054           if (method-&gt;is_running_emcp()) {
4055             method-&gt;set_running_emcp(false);
4056           }
4057         } else {
4058           assert (method-&gt;is_obsolete() || method-&gt;is_running_emcp(),
4059                   &quot;emcp method cannot run after emcp bit is cleared&quot;);
4060           log_trace(redefine, class, iklass, purge)
4061             (&quot;purge: %s(%s): prev method @%d in version @%d is alive&quot;,
4062              method-&gt;name()-&gt;as_C_string(), method-&gt;signature()-&gt;as_C_string(), j, version);
4063         }
4064       }
4065     }
4066     // next previous version
4067     last = pv_node;
4068     pv_node = pv_node-&gt;previous_versions();
4069     version++;
4070   }
4071   log_trace(redefine, class, iklass, purge)
4072     (&quot;previous version stats: live=%d, deleted=%d&quot;, live_count, deleted_count);
4073 }
4074 
4075 void InstanceKlass::mark_newly_obsolete_methods(Array&lt;Method*&gt;* old_methods,
4076                                                 int emcp_method_count) {
4077   int obsolete_method_count = old_methods-&gt;length() - emcp_method_count;
4078 
4079   if (emcp_method_count != 0 &amp;&amp; obsolete_method_count != 0 &amp;&amp;
4080       _previous_versions != NULL) {
4081     // We have a mix of obsolete and EMCP methods so we have to
4082     // clear out any matching EMCP method entries the hard way.
4083     int local_count = 0;
4084     for (int i = 0; i &lt; old_methods-&gt;length(); i++) {
4085       Method* old_method = old_methods-&gt;at(i);
4086       if (old_method-&gt;is_obsolete()) {
4087         // only obsolete methods are interesting
4088         Symbol* m_name = old_method-&gt;name();
4089         Symbol* m_signature = old_method-&gt;signature();
4090 
4091         // previous versions are linked together through the InstanceKlass
4092         int j = 0;
4093         for (InstanceKlass* prev_version = _previous_versions;
4094              prev_version != NULL;
4095              prev_version = prev_version-&gt;previous_versions(), j++) {
4096 
4097           Array&lt;Method*&gt;* method_refs = prev_version-&gt;methods();
4098           for (int k = 0; k &lt; method_refs-&gt;length(); k++) {
4099             Method* method = method_refs-&gt;at(k);
4100 
4101             if (!method-&gt;is_obsolete() &amp;&amp;
4102                 method-&gt;name() == m_name &amp;&amp;
4103                 method-&gt;signature() == m_signature) {
4104               // The current RedefineClasses() call has made all EMCP
4105               // versions of this method obsolete so mark it as obsolete
4106               log_trace(redefine, class, iklass, add)
4107                 (&quot;%s(%s): flush obsolete method @%d in version @%d&quot;,
4108                  m_name-&gt;as_C_string(), m_signature-&gt;as_C_string(), k, j);
4109 
4110               method-&gt;set_is_obsolete();
4111               break;
4112             }
4113           }
4114 
4115           // The previous loop may not find a matching EMCP method, but
4116           // that doesn&#39;t mean that we can optimize and not go any
4117           // further back in the PreviousVersion generations. The EMCP
4118           // method for this generation could have already been made obsolete,
4119           // but there still may be an older EMCP method that has not
4120           // been made obsolete.
4121         }
4122 
4123         if (++local_count &gt;= obsolete_method_count) {
4124           // no more obsolete methods so bail out now
4125           break;
4126         }
4127       }
4128     }
4129   }
4130 }
4131 
4132 // Save the scratch_class as the previous version if any of the methods are running.
4133 // The previous_versions are used to set breakpoints in EMCP methods and they are
4134 // also used to clean MethodData links to redefined methods that are no longer running.
4135 void InstanceKlass::add_previous_version(InstanceKlass* scratch_class,
4136                                          int emcp_method_count) {
4137   assert(Thread::current()-&gt;is_VM_thread(),
4138          &quot;only VMThread can add previous versions&quot;);
4139 
4140   ResourceMark rm;
4141   log_trace(redefine, class, iklass, add)
4142     (&quot;adding previous version ref for %s, EMCP_cnt=%d&quot;, scratch_class-&gt;external_name(), emcp_method_count);
4143 
4144   // Clean out old previous versions for this class
4145   purge_previous_version_list();
4146 
4147   // Mark newly obsolete methods in remaining previous versions.  An EMCP method from
4148   // a previous redefinition may be made obsolete by this redefinition.
4149   Array&lt;Method*&gt;* old_methods = scratch_class-&gt;methods();
4150   mark_newly_obsolete_methods(old_methods, emcp_method_count);
4151 
4152   // If the constant pool for this previous version of the class
4153   // is not marked as being on the stack, then none of the methods
4154   // in this previous version of the class are on the stack so
4155   // we don&#39;t need to add this as a previous version.
4156   ConstantPool* cp_ref = scratch_class-&gt;constants();
4157   if (!cp_ref-&gt;on_stack()) {
4158     log_trace(redefine, class, iklass, add)(&quot;scratch class not added; no methods are running&quot;);
4159     // For debugging purposes.
4160     scratch_class-&gt;set_is_scratch_class();
4161     scratch_class-&gt;class_loader_data()-&gt;add_to_deallocate_list(scratch_class);
4162     return;
4163   }
4164 
4165   if (emcp_method_count != 0) {
4166     // At least one method is still running, check for EMCP methods
4167     for (int i = 0; i &lt; old_methods-&gt;length(); i++) {
4168       Method* old_method = old_methods-&gt;at(i);
4169       if (!old_method-&gt;is_obsolete() &amp;&amp; old_method-&gt;on_stack()) {
4170         // if EMCP method (not obsolete) is on the stack, mark as EMCP so that
4171         // we can add breakpoints for it.
4172 
4173         // We set the method-&gt;on_stack bit during safepoints for class redefinition
4174         // and use this bit to set the is_running_emcp bit.
4175         // After the safepoint, the on_stack bit is cleared and the running emcp
4176         // method may exit.   If so, we would set a breakpoint in a method that
4177         // is never reached, but this won&#39;t be noticeable to the programmer.
4178         old_method-&gt;set_running_emcp(true);
4179         log_trace(redefine, class, iklass, add)
4180           (&quot;EMCP method %s is on_stack &quot; INTPTR_FORMAT, old_method-&gt;name_and_sig_as_C_string(), p2i(old_method));
4181       } else if (!old_method-&gt;is_obsolete()) {
4182         log_trace(redefine, class, iklass, add)
4183           (&quot;EMCP method %s is NOT on_stack &quot; INTPTR_FORMAT, old_method-&gt;name_and_sig_as_C_string(), p2i(old_method));
4184       }
4185     }
4186   }
4187 
4188   // Add previous version if any methods are still running.
4189   // Set has_previous_version flag for processing during class unloading.
4190   _has_previous_versions = true;
4191   log_trace(redefine, class, iklass, add) (&quot;scratch class added; one of its methods is on_stack.&quot;);
4192   assert(scratch_class-&gt;previous_versions() == NULL, &quot;shouldn&#39;t have a previous version&quot;);
4193   scratch_class-&gt;link_previous_versions(previous_versions());
4194   link_previous_versions(scratch_class);
4195 } // end add_previous_version()
4196 
4197 #endif // INCLUDE_JVMTI
4198 
4199 Method* InstanceKlass::method_with_idnum(int idnum) {
4200   Method* m = NULL;
4201   if (idnum &lt; methods()-&gt;length()) {
4202     m = methods()-&gt;at(idnum);
4203   }
4204   if (m == NULL || m-&gt;method_idnum() != idnum) {
4205     for (int index = 0; index &lt; methods()-&gt;length(); ++index) {
4206       m = methods()-&gt;at(index);
4207       if (m-&gt;method_idnum() == idnum) {
4208         return m;
4209       }
4210     }
4211     // None found, return null for the caller to handle.
4212     return NULL;
4213   }
4214   return m;
4215 }
4216 
4217 
4218 Method* InstanceKlass::method_with_orig_idnum(int idnum) {
4219   if (idnum &gt;= methods()-&gt;length()) {
4220     return NULL;
4221   }
4222   Method* m = methods()-&gt;at(idnum);
4223   if (m != NULL &amp;&amp; m-&gt;orig_method_idnum() == idnum) {
4224     return m;
4225   }
4226   // Obsolete method idnum does not match the original idnum
4227   for (int index = 0; index &lt; methods()-&gt;length(); ++index) {
4228     m = methods()-&gt;at(index);
4229     if (m-&gt;orig_method_idnum() == idnum) {
4230       return m;
4231     }
4232   }
4233   // None found, return null for the caller to handle.
4234   return NULL;
4235 }
4236 
4237 
4238 Method* InstanceKlass::method_with_orig_idnum(int idnum, int version) {
4239   InstanceKlass* holder = get_klass_version(version);
4240   if (holder == NULL) {
4241     return NULL; // The version of klass is gone, no method is found
4242   }
4243   Method* method = holder-&gt;method_with_orig_idnum(idnum);
4244   return method;
4245 }
4246 
4247 #if INCLUDE_JVMTI
4248 JvmtiCachedClassFileData* InstanceKlass::get_cached_class_file() {
4249   return _cached_class_file;
4250 }
4251 
4252 jint InstanceKlass::get_cached_class_file_len() {
4253   return VM_RedefineClasses::get_cached_class_file_len(_cached_class_file);
4254 }
4255 
4256 unsigned char * InstanceKlass::get_cached_class_file_bytes() {
4257   return VM_RedefineClasses::get_cached_class_file_bytes(_cached_class_file);
4258 }
4259 #endif
4260 
4261 #define THROW_DVT_ERROR(s) \
4262   Exceptions::fthrow(THREAD_AND_LOCATION, vmSymbols::java_lang_IncompatibleClassChangeError(), \
4263       &quot;ValueCapableClass class &#39;%s&#39; %s&quot;, external_name(),(s)); \
4264       return
    </pre>
  </body>
</html>