<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center>&lt; prev <a href="../../../../index.html" target="_top">index</a> <a href="frame_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
300   verify_oop(receiver);
301   // explicit NULL check not needed since load from [klass_offset] causes a trap
302   // check against inline cache
303   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
304   int start_offset = offset();
305 
306   if (UseCompressedClassPointers) {
307     load_klass(rscratch1, receiver);
308     cmpptr(rscratch1, iCache);
309   } else {
310     cmpptr(iCache, Address(receiver, oopDesc::klass_offset_in_bytes()));
311   }
312   // if icache check fails, then jump to runtime routine
313   // Note: RECEIVER must still contain the receiver!
314   jump_cc(Assembler::notEqual,
315           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
316   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
317   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
318 }
319 




















320 
321 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_value_entry_label) {
322   if (has_scalarized_args) {
323     // Initialize orig_pc to detect deoptimization during buffering in the entry points
324     movptr(Address(rsp, sp_offset_for_orig_pc - frame_size_in_bytes - wordSize), 0);
325   }
326   if (!needs_stack_repair &amp;&amp; verified_value_entry_label != NULL) {
327     bind(*verified_value_entry_label);
328   }
329   // Make sure there is enough stack space for this method&#39;s activation.
330   // Note that we do this before doing an enter(). This matches the
331   // ordering of C2&#39;s stack overflow check / rsp decrement and allows
332   // the SharedRuntime stack overflow handling to be consistent
333   // between the two compilers.
334   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);
335   generate_stack_overflow_check(bang_size_in_bytes);
<span class="line-removed">336   push(rbp);</span>
<span class="line-removed">337   if (PreserveFramePointer) {</span>
<span class="line-removed">338     mov(rbp, rsp);</span>
<span class="line-removed">339   }</span>
<span class="line-removed">340 #if !defined(_LP64) &amp;&amp; defined(TIERED)</span>
<span class="line-removed">341   if (UseSSE &lt; 2 ) {</span>
<span class="line-removed">342     // c2 leaves fpu stack dirty. Clean it on entry</span>
<span class="line-removed">343     empty_FPU_stack();</span>
<span class="line-removed">344   }</span>
<span class="line-removed">345 #endif // !_LP64 &amp;&amp; TIERED</span>
<span class="line-removed">346   decrement(rsp, frame_size_in_bytes); // does not emit code for frame_size == 0</span>
<span class="line-removed">347   if (needs_stack_repair) {</span>
<span class="line-removed">348     // Save stack increment (also account for rbp)</span>
<span class="line-removed">349     int real_frame_size = frame_size_in_bytes + wordSize;</span>
<span class="line-removed">350     movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);</span>
<span class="line-removed">351     if (verified_value_entry_label != NULL) {</span>
<span class="line-removed">352       bind(*verified_value_entry_label);</span>
<span class="line-removed">353     }</span>
<span class="line-removed">354   }</span>
355 







356   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
357   bs-&gt;nmethod_entry_barrier(this);
358 }
359 
360 void C1_MacroAssembler::verified_entry() {
361   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
362     // Verified Entry first instruction should be 5 bytes long for correct
363     // patching by patch_verified_entry().
364     //
365     // C1Breakpoint and VerifyFPU have one byte first instruction.
366     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging
367     // code is not generated (see build_frame() above).
368     // For all these cases generate long instruction first.
369     fat_nop();
370   }
371   if (C1Breakpoint)int3();
372   // build frame
373   IA32_ONLY( verify_FPU(0, &quot;method_entry&quot;); )
374 }
375 
</pre>
<hr />
<pre>
387   int args_on_stack_cc = is_value_ro_entry ? ces-&gt;args_on_stack_cc_ro() : ces-&gt;args_on_stack_cc();
388 
389   assert(sig-&gt;length() &lt;= sig_cc-&gt;length(), &quot;Zero-sized value class not allowed!&quot;);
390   BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig_cc-&gt;length());
391   int args_passed = sig-&gt;length();
392   int args_passed_cc = SigEntry::fill_sig_bt(sig_cc, sig_bt);
393   int extra_stack_offset = wordSize; // tos is return address.
394 
395   // Check if we need to extend the stack for packing
396   int sp_inc = 0;
397   if (args_on_stack &gt; args_on_stack_cc) {
398     // Two additional slots to account for return address
399     sp_inc = (args_on_stack + 2) * VMRegImpl::stack_slot_size;
400     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
401     pop(r13); // Copy return address
402     subptr(rsp, sp_inc);
403     push(r13);
404   }
405 
406   // Create a temp frame so we can call into the runtime. It must be properly set up to accommodate GC.
<span class="line-modified">407   push(rbp);</span>
<span class="line-removed">408   if (PreserveFramePointer) {</span>
<span class="line-removed">409     mov(rbp, rsp);</span>
<span class="line-removed">410   }</span>
<span class="line-removed">411   subptr(rsp, frame_size_in_bytes);</span>
<span class="line-removed">412 </span>
<span class="line-removed">413   if (ces-&gt;c1_needs_stack_repair()) {</span>
<span class="line-removed">414     // Save stack increment (also account for fixed framesize and rbp)</span>
<span class="line-removed">415     assert((sp_inc &amp; (StackAlignmentInBytes-1)) == 0, &quot;stack increment not aligned&quot;);</span>
<span class="line-removed">416     int real_frame_size = sp_inc + frame_size_in_bytes + wordSize;</span>
<span class="line-removed">417     movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);</span>
<span class="line-removed">418   }</span>
419 
420   // Initialize orig_pc to detect deoptimization during buffering in below runtime call
421   movptr(Address(rsp, sp_offset_for_orig_pc), 0);
422 
423   // FIXME -- call runtime only if we cannot in-line allocate all the incoming value args.
424   movptr(rbx, (intptr_t)(ces-&gt;method()));
425   if (is_value_ro_entry) {
426     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_no_receiver_id)));
427   } else {
428     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_id)));
429   }
430   int rt_call_offset = offset();
431 
432   // Remove the temp frame
433   addptr(rsp, frame_size_in_bytes);
434   pop(rbp);
435 
436   shuffle_value_args(true, is_value_ro_entry, extra_stack_offset, sig_bt, sig_cc,
437                      args_passed_cc, args_on_stack_cc, regs_cc, // from
438                      args_passed, args_on_stack, regs, sp_inc); // to
439 
440   if (ces-&gt;c1_needs_stack_repair()) {
<span class="line-modified">441     // Skip over the stack banging and frame setup code in the</span>
<span class="line-modified">442     // verified_value_entry (which has a different real_frame_size).</span>
<span class="line-modified">443     push(rbp);</span>
<span class="line-removed">444     if (PreserveFramePointer) {</span>
<span class="line-removed">445       mov(rbp, rsp);</span>
<span class="line-removed">446     }</span>
<span class="line-removed">447 #if !defined(_LP64) &amp;&amp; defined(TIERED)</span>
<span class="line-removed">448     // c2 leaves fpu stack dirty. Clean it on entry</span>
<span class="line-removed">449     if (UseSSE &lt; 2 ) {</span>
<span class="line-removed">450       empty_FPU_stack();</span>
<span class="line-removed">451     }</span>
<span class="line-removed">452 #endif // TIERED</span>
<span class="line-removed">453     decrement(rsp, frame_size_in_bytes);</span>
454   }
455 
456   jmp(verified_value_entry_label);
457   return rt_call_offset;
458 }
459 
460 void C1_MacroAssembler::load_parameter(int offset_in_words, Register reg) {
461   // rbp, + 0: link
462   //     + 1: return address
463   //     + 2: argument with offset 0
464   //     + 3: argument with offset 1
465   //     + 4: ...
466 
467   movptr(reg, Address(rbp, (offset_in_words + 2) * BytesPerWord));
468 }
469 
470 #ifndef PRODUCT
471 
472 void C1_MacroAssembler::verify_stack_oop(int stack_offset) {
473   if (!VerifyOops) return;
</pre>
</td>
<td>
<hr />
<pre>
300   verify_oop(receiver);
301   // explicit NULL check not needed since load from [klass_offset] causes a trap
302   // check against inline cache
303   assert(!MacroAssembler::needs_explicit_null_check(oopDesc::klass_offset_in_bytes()), &quot;must add explicit null check&quot;);
304   int start_offset = offset();
305 
306   if (UseCompressedClassPointers) {
307     load_klass(rscratch1, receiver);
308     cmpptr(rscratch1, iCache);
309   } else {
310     cmpptr(iCache, Address(receiver, oopDesc::klass_offset_in_bytes()));
311   }
312   // if icache check fails, then jump to runtime routine
313   // Note: RECEIVER must still contain the receiver!
314   jump_cc(Assembler::notEqual,
315           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
316   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
317   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, &quot;check alignment in emit_method_entry&quot;);
318 }
319 
<span class="line-added">320 void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_inc, bool needs_stack_repair) {</span>
<span class="line-added">321   push(rbp);</span>
<span class="line-added">322   if (PreserveFramePointer) {</span>
<span class="line-added">323     mov(rbp, rsp);</span>
<span class="line-added">324   }</span>
<span class="line-added">325   #if !defined(_LP64) &amp;&amp; defined(TIERED)</span>
<span class="line-added">326     if (UseSSE &lt; 2 ) {</span>
<span class="line-added">327       // c2 leaves fpu stack dirty. Clean it on entry</span>
<span class="line-added">328       empty_FPU_stack();</span>
<span class="line-added">329     }</span>
<span class="line-added">330   #endif // !_LP64 &amp;&amp; TIERED</span>
<span class="line-added">331   decrement(rsp, frame_size_in_bytes);</span>
<span class="line-added">332 </span>
<span class="line-added">333   if (needs_stack_repair) {</span>
<span class="line-added">334     // Save stack increment (also account for fixed framesize and rbp)</span>
<span class="line-added">335     assert((sp_inc &amp; (StackAlignmentInBytes-1)) == 0, &quot;stack increment not aligned&quot;);</span>
<span class="line-added">336     int real_frame_size = sp_inc + frame_size_in_bytes + wordSize;</span>
<span class="line-added">337     movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);</span>
<span class="line-added">338   }</span>
<span class="line-added">339 }</span>
340 
341 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_value_entry_label) {
342   if (has_scalarized_args) {
343     // Initialize orig_pc to detect deoptimization during buffering in the entry points
344     movptr(Address(rsp, sp_offset_for_orig_pc - frame_size_in_bytes - wordSize), 0);
345   }
346   if (!needs_stack_repair &amp;&amp; verified_value_entry_label != NULL) {
347     bind(*verified_value_entry_label);
348   }
349   // Make sure there is enough stack space for this method&#39;s activation.
350   // Note that we do this before doing an enter(). This matches the
351   // ordering of C2&#39;s stack overflow check / rsp decrement and allows
352   // the SharedRuntime stack overflow handling to be consistent
353   // between the two compilers.
354   assert(bang_size_in_bytes &gt;= frame_size_in_bytes, &quot;stack bang size incorrect&quot;);
355   generate_stack_overflow_check(bang_size_in_bytes);



















356 
<span class="line-added">357   build_frame_helper(frame_size_in_bytes, 0, needs_stack_repair);</span>
<span class="line-added">358 </span>
<span class="line-added">359   if (needs_stack_repair &amp;&amp; verified_value_entry_label != NULL) {</span>
<span class="line-added">360     // Jump here from the scalarized entry points that require additional stack space</span>
<span class="line-added">361     // for packing scalarized arguments and therefore already created the frame.</span>
<span class="line-added">362     bind(*verified_value_entry_label);</span>
<span class="line-added">363   }</span>
364   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
365   bs-&gt;nmethod_entry_barrier(this);
366 }
367 
368 void C1_MacroAssembler::verified_entry() {
369   if (C1Breakpoint || VerifyFPU || !UseStackBanging) {
370     // Verified Entry first instruction should be 5 bytes long for correct
371     // patching by patch_verified_entry().
372     //
373     // C1Breakpoint and VerifyFPU have one byte first instruction.
374     // Also first instruction will be one byte &quot;push(rbp)&quot; if stack banging
375     // code is not generated (see build_frame() above).
376     // For all these cases generate long instruction first.
377     fat_nop();
378   }
379   if (C1Breakpoint)int3();
380   // build frame
381   IA32_ONLY( verify_FPU(0, &quot;method_entry&quot;); )
382 }
383 
</pre>
<hr />
<pre>
395   int args_on_stack_cc = is_value_ro_entry ? ces-&gt;args_on_stack_cc_ro() : ces-&gt;args_on_stack_cc();
396 
397   assert(sig-&gt;length() &lt;= sig_cc-&gt;length(), &quot;Zero-sized value class not allowed!&quot;);
398   BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, sig_cc-&gt;length());
399   int args_passed = sig-&gt;length();
400   int args_passed_cc = SigEntry::fill_sig_bt(sig_cc, sig_bt);
401   int extra_stack_offset = wordSize; // tos is return address.
402 
403   // Check if we need to extend the stack for packing
404   int sp_inc = 0;
405   if (args_on_stack &gt; args_on_stack_cc) {
406     // Two additional slots to account for return address
407     sp_inc = (args_on_stack + 2) * VMRegImpl::stack_slot_size;
408     sp_inc = align_up(sp_inc, StackAlignmentInBytes);
409     pop(r13); // Copy return address
410     subptr(rsp, sp_inc);
411     push(r13);
412   }
413 
414   // Create a temp frame so we can call into the runtime. It must be properly set up to accommodate GC.
<span class="line-modified">415   build_frame_helper(frame_size_in_bytes, sp_inc, ces-&gt;c1_needs_stack_repair());</span>











416 
417   // Initialize orig_pc to detect deoptimization during buffering in below runtime call
418   movptr(Address(rsp, sp_offset_for_orig_pc), 0);
419 
420   // FIXME -- call runtime only if we cannot in-line allocate all the incoming value args.
421   movptr(rbx, (intptr_t)(ces-&gt;method()));
422   if (is_value_ro_entry) {
423     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_no_receiver_id)));
424   } else {
425     call(RuntimeAddress(Runtime1::entry_for(Runtime1::buffer_value_args_id)));
426   }
427   int rt_call_offset = offset();
428 
429   // Remove the temp frame
430   addptr(rsp, frame_size_in_bytes);
431   pop(rbp);
432 
433   shuffle_value_args(true, is_value_ro_entry, extra_stack_offset, sig_bt, sig_cc,
434                      args_passed_cc, args_on_stack_cc, regs_cc, // from
435                      args_passed, args_on_stack, regs, sp_inc); // to
436 
437   if (ces-&gt;c1_needs_stack_repair()) {
<span class="line-modified">438     // Create the real frame. Below jump will then skip over the stack banging and frame</span>
<span class="line-modified">439     // setup code in the verified_value_entry (which has a different real_frame_size).</span>
<span class="line-modified">440     build_frame_helper(frame_size_in_bytes, sp_inc, true);</span>










441   }
442 
443   jmp(verified_value_entry_label);
444   return rt_call_offset;
445 }
446 
447 void C1_MacroAssembler::load_parameter(int offset_in_words, Register reg) {
448   // rbp, + 0: link
449   //     + 1: return address
450   //     + 2: argument with offset 0
451   //     + 3: argument with offset 1
452   //     + 4: ...
453 
454   movptr(reg, Address(rbp, (offset_in_words + 2) * BytesPerWord));
455 }
456 
457 #ifndef PRODUCT
458 
459 void C1_MacroAssembler::verify_stack_oop(int stack_offset) {
460   if (!VerifyOops) return;
</pre>
</td>
</tr>
</table>
<center>&lt; prev <a href="../../../../index.html" target="_top">index</a> <a href="frame_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>