diff a/src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp b/src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_MacroAssembler_x86.cpp
@@ -315,10 +315,30 @@
           RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
   const int ic_cmp_size = LP64_ONLY(10) NOT_LP64(9);
   assert(UseCompressedClassPointers || offset() - start_offset == ic_cmp_size, "check alignment in emit_method_entry");
 }
 
+void C1_MacroAssembler::build_frame_helper(int frame_size_in_bytes, int sp_inc, bool needs_stack_repair) {
+  push(rbp);
+  if (PreserveFramePointer) {
+    mov(rbp, rsp);
+  }
+  #if !defined(_LP64) && defined(TIERED)
+    if (UseSSE < 2 ) {
+      // c2 leaves fpu stack dirty. Clean it on entry
+      empty_FPU_stack();
+    }
+  #endif // !_LP64 && TIERED
+  decrement(rsp, frame_size_in_bytes);
+
+  if (needs_stack_repair) {
+    // Save stack increment (also account for fixed framesize and rbp)
+    assert((sp_inc & (StackAlignmentInBytes-1)) == 0, "stack increment not aligned");
+    int real_frame_size = sp_inc + frame_size_in_bytes + wordSize;
+    movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);
+  }
+}
 
 void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int sp_offset_for_orig_pc, bool needs_stack_repair, bool has_scalarized_args, Label* verified_value_entry_label) {
   if (has_scalarized_args) {
     // Initialize orig_pc to detect deoptimization during buffering in the entry points
     movptr(Address(rsp, sp_offset_for_orig_pc - frame_size_in_bytes - wordSize), 0);
@@ -331,30 +351,18 @@
   // ordering of C2's stack overflow check / rsp decrement and allows
   // the SharedRuntime stack overflow handling to be consistent
   // between the two compilers.
   assert(bang_size_in_bytes >= frame_size_in_bytes, "stack bang size incorrect");
   generate_stack_overflow_check(bang_size_in_bytes);
-  push(rbp);
-  if (PreserveFramePointer) {
-    mov(rbp, rsp);
-  }
-#if !defined(_LP64) && defined(TIERED)
-  if (UseSSE < 2 ) {
-    // c2 leaves fpu stack dirty. Clean it on entry
-    empty_FPU_stack();
-  }
-#endif // !_LP64 && TIERED
-  decrement(rsp, frame_size_in_bytes); // does not emit code for frame_size == 0
-  if (needs_stack_repair) {
-    // Save stack increment (also account for rbp)
-    int real_frame_size = frame_size_in_bytes + wordSize;
-    movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);
-    if (verified_value_entry_label != NULL) {
-      bind(*verified_value_entry_label);
-    }
-  }
 
+  build_frame_helper(frame_size_in_bytes, 0, needs_stack_repair);
+
+  if (needs_stack_repair && verified_value_entry_label != NULL) {
+    // Jump here from the scalarized entry points that require additional stack space
+    // for packing scalarized arguments and therefore already created the frame.
+    bind(*verified_value_entry_label);
+  }
   BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();
   bs->nmethod_entry_barrier(this);
 }
 
 void C1_MacroAssembler::verified_entry() {
@@ -402,22 +410,11 @@
     subptr(rsp, sp_inc);
     push(r13);
   }
 
   // Create a temp frame so we can call into the runtime. It must be properly set up to accommodate GC.
-  push(rbp);
-  if (PreserveFramePointer) {
-    mov(rbp, rsp);
-  }
-  subptr(rsp, frame_size_in_bytes);
-
-  if (ces->c1_needs_stack_repair()) {
-    // Save stack increment (also account for fixed framesize and rbp)
-    assert((sp_inc & (StackAlignmentInBytes-1)) == 0, "stack increment not aligned");
-    int real_frame_size = sp_inc + frame_size_in_bytes + wordSize;
-    movptr(Address(rsp, frame_size_in_bytes - wordSize), real_frame_size);
-  }
+  build_frame_helper(frame_size_in_bytes, sp_inc, ces->c1_needs_stack_repair());
 
   // Initialize orig_pc to detect deoptimization during buffering in below runtime call
   movptr(Address(rsp, sp_offset_for_orig_pc), 0);
 
   // FIXME -- call runtime only if we cannot in-line allocate all the incoming value args.
@@ -436,23 +433,13 @@
   shuffle_value_args(true, is_value_ro_entry, extra_stack_offset, sig_bt, sig_cc,
                      args_passed_cc, args_on_stack_cc, regs_cc, // from
                      args_passed, args_on_stack, regs, sp_inc); // to
 
   if (ces->c1_needs_stack_repair()) {
-    // Skip over the stack banging and frame setup code in the
-    // verified_value_entry (which has a different real_frame_size).
-    push(rbp);
-    if (PreserveFramePointer) {
-      mov(rbp, rsp);
-    }
-#if !defined(_LP64) && defined(TIERED)
-    // c2 leaves fpu stack dirty. Clean it on entry
-    if (UseSSE < 2 ) {
-      empty_FPU_stack();
-    }
-#endif // TIERED
-    decrement(rsp, frame_size_in_bytes);
+    // Create the real frame. Below jump will then skip over the stack banging and frame
+    // setup code in the verified_value_entry (which has a different real_frame_size).
+    build_frame_helper(frame_size_in_bytes, sp_inc, true);
   }
 
   jmp(verified_value_entry_label);
   return rt_call_offset;
 }
