<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/callnode.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c2_globals.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="classes.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/callnode.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;compiler/compileLog.hpp&quot;
  27 #include &quot;ci/bcEscapeAnalyzer.hpp&quot;
  28 #include &quot;compiler/oopMap.hpp&quot;
  29 #include &quot;gc/shared/barrierSet.hpp&quot;
  30 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  31 #include &quot;interpreter/interpreter.hpp&quot;
  32 #include &quot;opto/callGenerator.hpp&quot;
  33 #include &quot;opto/callnode.hpp&quot;
  34 #include &quot;opto/castnode.hpp&quot;
  35 #include &quot;opto/convertnode.hpp&quot;
  36 #include &quot;opto/escape.hpp&quot;
  37 #include &quot;opto/locknode.hpp&quot;
  38 #include &quot;opto/machnode.hpp&quot;
  39 #include &quot;opto/matcher.hpp&quot;
  40 #include &quot;opto/parse.hpp&quot;
  41 #include &quot;opto/regalloc.hpp&quot;
  42 #include &quot;opto/regmask.hpp&quot;
  43 #include &quot;opto/rootnode.hpp&quot;
  44 #include &quot;opto/runtime.hpp&quot;


  45 #include &quot;utilities/powerOfTwo.hpp&quot;
  46 
  47 // Portions of code courtesy of Clifford Click
  48 
  49 // Optimization - Graph Style
  50 
  51 //=============================================================================
  52 uint StartNode::size_of() const { return sizeof(*this); }
  53 bool StartNode::cmp( const Node &amp;n ) const
  54 { return _domain == ((StartNode&amp;)n)._domain; }
  55 const Type *StartNode::bottom_type() const { return _domain; }
  56 const Type* StartNode::Value(PhaseGVN* phase) const { return _domain; }
  57 #ifndef PRODUCT
  58 void StartNode::dump_spec(outputStream *st) const { st-&gt;print(&quot; #&quot;); _domain-&gt;dump_on(st);}
  59 void StartNode::dump_compact_spec(outputStream *st) const { /* empty */ }
  60 #endif
  61 
  62 //------------------------------Ideal------------------------------------------
  63 Node *StartNode::Ideal(PhaseGVN *phase, bool can_reshape){
  64   return remove_dead_region(phase, can_reshape) ? this : NULL;
  65 }
  66 
  67 //------------------------------calling_convention-----------------------------
  68 void StartNode::calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const {
  69   Matcher::calling_convention( sig_bt, parm_regs, argcnt, false );
  70 }
  71 
  72 //------------------------------Registers--------------------------------------
  73 const RegMask &amp;StartNode::in_RegMask(uint) const {
  74   return RegMask::Empty;
  75 }
  76 
  77 //------------------------------match------------------------------------------
  78 // Construct projections for incoming parameters, and their RegMask info
<span class="line-modified">  79 Node *StartNode::match( const ProjNode *proj, const Matcher *match ) {</span>
  80   switch (proj-&gt;_con) {
  81   case TypeFunc::Control:
  82   case TypeFunc::I_O:
  83   case TypeFunc::Memory:
  84     return new MachProjNode(this,proj-&gt;_con,RegMask::Empty,MachProjNode::unmatched_proj);
  85   case TypeFunc::FramePtr:
  86     return new MachProjNode(this,proj-&gt;_con,Matcher::c_frame_ptr_mask, Op_RegP);
  87   case TypeFunc::ReturnAdr:
  88     return new MachProjNode(this,proj-&gt;_con,match-&gt;_return_addr_mask,Op_RegP);
  89   case TypeFunc::Parms:
  90   default: {
  91       uint parm_num = proj-&gt;_con - TypeFunc::Parms;
  92       const Type *t = _domain-&gt;field_at(proj-&gt;_con);
  93       if (t-&gt;base() == Type::Half)  // 2nd half of Longs and Doubles
  94         return new ConNode(Type::TOP);
  95       uint ideal_reg = t-&gt;ideal_reg();
  96       RegMask &amp;rm = match-&gt;_calling_convention_mask[parm_num];
  97       return new MachProjNode(this,proj-&gt;_con,rm,ideal_reg);
  98     }
  99   }
 100   return NULL;
 101 }
 102 
<span class="line-removed"> 103 //------------------------------StartOSRNode----------------------------------</span>
<span class="line-removed"> 104 // The method start node for an on stack replacement adapter</span>
<span class="line-removed"> 105 </span>
<span class="line-removed"> 106 //------------------------------osr_domain-----------------------------</span>
<span class="line-removed"> 107 const TypeTuple *StartOSRNode::osr_domain() {</span>
<span class="line-removed"> 108   const Type **fields = TypeTuple::fields(2);</span>
<span class="line-removed"> 109   fields[TypeFunc::Parms+0] = TypeRawPtr::BOTTOM;  // address of osr buffer</span>
<span class="line-removed"> 110 </span>
<span class="line-removed"> 111   return TypeTuple::make(TypeFunc::Parms+1, fields);</span>
<span class="line-removed"> 112 }</span>
<span class="line-removed"> 113 </span>
 114 //=============================================================================
 115 const char * const ParmNode::names[TypeFunc::Parms+1] = {
 116   &quot;Control&quot;, &quot;I_O&quot;, &quot;Memory&quot;, &quot;FramePtr&quot;, &quot;ReturnAdr&quot;, &quot;Parms&quot;
 117 };
 118 
 119 #ifndef PRODUCT
 120 void ParmNode::dump_spec(outputStream *st) const {
 121   if( _con &lt; TypeFunc::Parms ) {
 122     st-&gt;print(&quot;%s&quot;, names[_con]);
 123   } else {
 124     st-&gt;print(&quot;Parm%d: &quot;,_con-TypeFunc::Parms);
 125     // Verbose and WizardMode dump bottom_type for all nodes
 126     if( !Verbose &amp;&amp; !WizardMode )   bottom_type()-&gt;dump_on(st);
 127   }
 128 }
 129 
 130 void ParmNode::dump_compact_spec(outputStream *st) const {
 131   if (_con &lt; TypeFunc::Parms) {
 132     st-&gt;print(&quot;%s&quot;, names[_con]);
 133   } else {
</pre>
<hr />
<pre>
 463       if (cik-&gt;is_instance_klass()) {
 464         cik-&gt;print_name_on(st);
 465         iklass = cik-&gt;as_instance_klass();
 466       } else if (cik-&gt;is_type_array_klass()) {
 467         cik-&gt;as_array_klass()-&gt;base_element_type()-&gt;print_name_on(st);
 468         st-&gt;print(&quot;[%d]&quot;, spobj-&gt;n_fields());
 469       } else if (cik-&gt;is_obj_array_klass()) {
 470         ciKlass* cie = cik-&gt;as_obj_array_klass()-&gt;base_element_klass();
 471         if (cie-&gt;is_instance_klass()) {
 472           cie-&gt;print_name_on(st);
 473         } else if (cie-&gt;is_type_array_klass()) {
 474           cie-&gt;as_array_klass()-&gt;base_element_type()-&gt;print_name_on(st);
 475         } else {
 476           ShouldNotReachHere();
 477         }
 478         st-&gt;print(&quot;[%d]&quot;, spobj-&gt;n_fields());
 479         int ndim = cik-&gt;as_array_klass()-&gt;dimension() - 1;
 480         while (ndim-- &gt; 0) {
 481           st-&gt;print(&quot;[]&quot;);
 482         }








 483       }
 484       st-&gt;print(&quot;={&quot;);
 485       uint nf = spobj-&gt;n_fields();
 486       if (nf &gt; 0) {
 487         uint first_ind = spobj-&gt;first_index(mcall-&gt;jvms());
 488         Node* fld_node = mcall-&gt;in(first_ind);
 489         ciField* cifield;
 490         if (iklass != NULL) {
 491           st-&gt;print(&quot; [&quot;);
 492           cifield = iklass-&gt;nonstatic_field_at(0);
 493           cifield-&gt;print_name_on(st);
 494           format_helper(regalloc, st, fld_node, &quot;:&quot;, 0, &amp;scobjs);
 495         } else {
 496           format_helper(regalloc, st, fld_node, &quot;[&quot;, 0, &amp;scobjs);
 497         }
 498         for (uint j = 1; j &lt; nf; j++) {
 499           fld_node = mcall-&gt;in(first_ind+j);
 500           if (iklass != NULL) {
 501             st-&gt;print(&quot;, [&quot;);
 502             cifield = iklass-&gt;nonstatic_field_at(j);
</pre>
<hr />
<pre>
 672 #ifndef PRODUCT
 673 void CallNode::dump_req(outputStream *st) const {
 674   // Dump the required inputs, enclosed in &#39;(&#39; and &#39;)&#39;
 675   uint i;                       // Exit value of loop
 676   for (i = 0; i &lt; req(); i++) {    // For all required inputs
 677     if (i == TypeFunc::Parms) st-&gt;print(&quot;(&quot;);
 678     if (in(i)) st-&gt;print(&quot;%c%d &quot;, Compile::current()-&gt;node_arena()-&gt;contains(in(i)) ? &#39; &#39; : &#39;o&#39;, in(i)-&gt;_idx);
 679     else st-&gt;print(&quot;_ &quot;);
 680   }
 681   st-&gt;print(&quot;)&quot;);
 682 }
 683 
 684 void CallNode::dump_spec(outputStream *st) const {
 685   st-&gt;print(&quot; &quot;);
 686   if (tf() != NULL)  tf()-&gt;dump_on(st);
 687   if (_cnt != COUNT_UNKNOWN)  st-&gt;print(&quot; C=%f&quot;,_cnt);
 688   if (jvms() != NULL)  jvms()-&gt;dump_spec(st);
 689 }
 690 #endif
 691 
<span class="line-modified"> 692 const Type *CallNode::bottom_type() const { return tf()-&gt;range(); }</span>
 693 const Type* CallNode::Value(PhaseGVN* phase) const {
<span class="line-modified"> 694   if (phase-&gt;type(in(0)) == Type::TOP)  return Type::TOP;</span>
<span class="line-modified"> 695   return tf()-&gt;range();</span>


 696 }
 697 
 698 //------------------------------calling_convention-----------------------------
<span class="line-modified"> 699 void CallNode::calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const {</span>







 700   // Use the standard compiler calling convention
 701   Matcher::calling_convention( sig_bt, parm_regs, argcnt, true );
 702 }
 703 
 704 
 705 //------------------------------match------------------------------------------
 706 // Construct projections for control, I/O, memory-fields, ..., and
 707 // return result(s) along with their RegMask info
<span class="line-modified"> 708 Node *CallNode::match( const ProjNode *proj, const Matcher *match ) {</span>
<span class="line-modified"> 709   switch (proj-&gt;_con) {</span>


























 710   case TypeFunc::Control:
 711   case TypeFunc::I_O:
 712   case TypeFunc::Memory:
 713     return new MachProjNode(this,proj-&gt;_con,RegMask::Empty,MachProjNode::unmatched_proj);
 714 
<span class="line-removed"> 715   case TypeFunc::Parms+1:       // For LONG &amp; DOUBLE returns</span>
<span class="line-removed"> 716     assert(tf()-&gt;range()-&gt;field_at(TypeFunc::Parms+1) == Type::HALF, &quot;&quot;);</span>
<span class="line-removed"> 717     // 2nd half of doubles and longs</span>
<span class="line-removed"> 718     return new MachProjNode(this,proj-&gt;_con, RegMask::Empty, (uint)OptoReg::Bad);</span>
<span class="line-removed"> 719 </span>
<span class="line-removed"> 720   case TypeFunc::Parms: {       // Normal returns</span>
<span class="line-removed"> 721     uint ideal_reg = tf()-&gt;range()-&gt;field_at(TypeFunc::Parms)-&gt;ideal_reg();</span>
<span class="line-removed"> 722     OptoRegPair regs = is_CallRuntime()</span>
<span class="line-removed"> 723       ? match-&gt;c_return_value(ideal_reg,true)  // Calls into C runtime</span>
<span class="line-removed"> 724       : match-&gt;  return_value(ideal_reg,true); // Calls into compiled Java code</span>
<span class="line-removed"> 725     RegMask rm = RegMask(regs.first());</span>
<span class="line-removed"> 726     if( OptoReg::is_valid(regs.second()) )</span>
<span class="line-removed"> 727       rm.Insert( regs.second() );</span>
<span class="line-removed"> 728     return new MachProjNode(this,proj-&gt;_con,rm,ideal_reg);</span>
<span class="line-removed"> 729   }</span>
<span class="line-removed"> 730 </span>
 731   case TypeFunc::ReturnAdr:
 732   case TypeFunc::FramePtr:
 733   default:
 734     ShouldNotReachHere();
 735   }
 736   return NULL;
 737 }
 738 
 739 // Do we Match on this edge index or not?  Match no edges
 740 uint CallNode::match_edge(uint idx) const {
 741   return 0;
 742 }
 743 
 744 //
 745 // Determine whether the call could modify the field of the specified
 746 // instance at the specified offset.
 747 //
 748 bool CallNode::may_modify(const TypeOopPtr *t_oop, PhaseTransform *phase) {
 749   assert((t_oop != NULL), &quot;sanity&quot;);
 750   if (is_call_to_arraycopystub() &amp;&amp; strcmp(_name, &quot;unsafe_arraycopy&quot;) != 0) {
<span class="line-modified"> 751     const TypeTuple* args = _tf-&gt;domain();</span>
 752     Node* dest = NULL;
 753     // Stubs that can be called once an ArrayCopyNode is expanded have
 754     // different signatures. Look for the second pointer argument,
 755     // that is the destination of the copy.
 756     for (uint i = TypeFunc::Parms, j = 0; i &lt; args-&gt;cnt(); i++) {
 757       if (args-&gt;field_at(i)-&gt;isa_ptr()) {
 758         j++;
 759         if (j == 2) {
 760           dest = in(i);
 761           break;
 762         }
 763       }
 764     }
 765     guarantee(dest != NULL, &quot;Call had only one ptr in, broken IR!&quot;);
 766     if (!dest-&gt;is_top() &amp;&amp; may_modify_arraycopy_helper(phase-&gt;type(dest)-&gt;is_oopptr(), t_oop, phase)) {
 767       return true;
 768     }
 769     return false;
 770   }
 771   if (t_oop-&gt;is_known_instance()) {
</pre>
<hr />
<pre>
 780       Node* proj = proj_out_or_null(TypeFunc::Parms);
 781       if ((proj == NULL) || (phase-&gt;type(proj)-&gt;is_instptr()-&gt;klass() != boxing_klass)) {
 782         return false;
 783       }
 784     }
 785     if (is_CallJava() &amp;&amp; as_CallJava()-&gt;method() != NULL) {
 786       ciMethod* meth = as_CallJava()-&gt;method();
 787       if (meth-&gt;is_getter()) {
 788         return false;
 789       }
 790       // May modify (by reflection) if an boxing object is passed
 791       // as argument or returned.
 792       Node* proj = returns_pointer() ? proj_out_or_null(TypeFunc::Parms) : NULL;
 793       if (proj != NULL) {
 794         const TypeInstPtr* inst_t = phase-&gt;type(proj)-&gt;isa_instptr();
 795         if ((inst_t != NULL) &amp;&amp; (!inst_t-&gt;klass_is_exact() ||
 796                                  (inst_t-&gt;klass() == boxing_klass))) {
 797           return true;
 798         }
 799       }
<span class="line-modified"> 800       const TypeTuple* d = tf()-&gt;domain();</span>
 801       for (uint i = TypeFunc::Parms; i &lt; d-&gt;cnt(); i++) {
 802         const TypeInstPtr* inst_t = d-&gt;field_at(i)-&gt;isa_instptr();
 803         if ((inst_t != NULL) &amp;&amp; (!inst_t-&gt;klass_is_exact() ||
 804                                  (inst_t-&gt;klass() == boxing_klass))) {
 805           return true;
 806         }
 807       }
 808       return false;
 809     }
 810   }
 811   return true;
 812 }
 813 
 814 // Does this call have a direct reference to n other than debug information?
 815 bool CallNode::has_non_debug_use(Node *n) {
<span class="line-modified"> 816   const TypeTuple * d = tf()-&gt;domain();</span>
 817   for (uint i = TypeFunc::Parms; i &lt; d-&gt;cnt(); i++) {
 818     Node *arg = in(i);
 819     if (arg == n) {
 820       return true;
 821     }
 822   }
 823   return false;
 824 }
 825 











 826 // Returns the unique CheckCastPP of a call
 827 // or &#39;this&#39; if there are several CheckCastPP or unexpected uses
 828 // or returns NULL if there is no one.
 829 Node *CallNode::result_cast() {
 830   Node *cast = NULL;
 831 
 832   Node *p = proj_out_or_null(TypeFunc::Parms);
 833   if (p == NULL)
 834     return NULL;
 835 
 836   for (DUIterator_Fast imax, i = p-&gt;fast_outs(imax); i &lt; imax; i++) {
 837     Node *use = p-&gt;fast_out(i);
 838     if (use-&gt;is_CheckCastPP()) {
 839       if (cast != NULL) {
 840         return this;  // more than 1 CheckCastPP
 841       }
 842       cast = use;
 843     } else if (!use-&gt;is_Initialize() &amp;&amp;
 844                !use-&gt;is_AddP() &amp;&amp;
 845                use-&gt;Opcode() != Op_MemBarStoreStore) {
 846       // Expected uses are restricted to a CheckCastPP, an Initialize
 847       // node, a MemBarStoreStore (clone) and AddP nodes. If we
 848       // encounter any other use (a Phi node can be seen in rare
 849       // cases) return this to prevent incorrect optimizations.
 850       return this;
 851     }
 852   }
 853   return cast;
 854 }
 855 
 856 
<span class="line-modified"> 857 void CallNode::extract_projections(CallProjections* projs, bool separate_io_proj, bool do_asserts) {</span>
<span class="line-modified"> 858   projs-&gt;fallthrough_proj      = NULL;</span>
<span class="line-modified"> 859   projs-&gt;fallthrough_catchproj = NULL;</span>
<span class="line-modified"> 860   projs-&gt;fallthrough_ioproj    = NULL;</span>
<span class="line-modified"> 861   projs-&gt;catchall_ioproj       = NULL;</span>
<span class="line-modified"> 862   projs-&gt;catchall_catchproj    = NULL;</span>
<span class="line-modified"> 863   projs-&gt;fallthrough_memproj   = NULL;</span>
<span class="line-modified"> 864   projs-&gt;catchall_memproj      = NULL;</span>
<span class="line-modified"> 865   projs-&gt;resproj               = NULL;</span>
<span class="line-modified"> 866   projs-&gt;exobj                 = NULL;</span>





 867 
 868   for (DUIterator_Fast imax, i = fast_outs(imax); i &lt; imax; i++) {
 869     ProjNode *pn = fast_out(i)-&gt;as_Proj();
 870     if (pn-&gt;outcnt() == 0) continue;
 871     switch (pn-&gt;_con) {
 872     case TypeFunc::Control:
 873       {
 874         // For Control (fallthrough) and I_O (catch_all_index) we have CatchProj -&gt; Catch -&gt; Proj
 875         projs-&gt;fallthrough_proj = pn;
 876         DUIterator_Fast jmax, j = pn-&gt;fast_outs(jmax);
 877         const Node *cn = pn-&gt;fast_out(j);
 878         if (cn-&gt;is_Catch()) {
 879           ProjNode *cpn = NULL;
 880           for (DUIterator_Fast kmax, k = cn-&gt;fast_outs(kmax); k &lt; kmax; k++) {
 881             cpn = cn-&gt;fast_out(k)-&gt;as_Proj();
 882             assert(cpn-&gt;is_CatchProj(), &quot;must be a CatchProjNode&quot;);
 883             if (cpn-&gt;_con == CatchProjNode::fall_through_index)
 884               projs-&gt;fallthrough_catchproj = cpn;
 885             else {
 886               assert(cpn-&gt;_con == CatchProjNode::catch_all_index, &quot;must be correct index.&quot;);
</pre>
<hr />
<pre>
 893     case TypeFunc::I_O:
 894       if (pn-&gt;_is_io_use)
 895         projs-&gt;catchall_ioproj = pn;
 896       else
 897         projs-&gt;fallthrough_ioproj = pn;
 898       for (DUIterator j = pn-&gt;outs(); pn-&gt;has_out(j); j++) {
 899         Node* e = pn-&gt;out(j);
 900         if (e-&gt;Opcode() == Op_CreateEx &amp;&amp; e-&gt;in(0)-&gt;is_CatchProj() &amp;&amp; e-&gt;outcnt() &gt; 0) {
 901           assert(projs-&gt;exobj == NULL, &quot;only one&quot;);
 902           projs-&gt;exobj = e;
 903         }
 904       }
 905       break;
 906     case TypeFunc::Memory:
 907       if (pn-&gt;_is_io_use)
 908         projs-&gt;catchall_memproj = pn;
 909       else
 910         projs-&gt;fallthrough_memproj = pn;
 911       break;
 912     case TypeFunc::Parms:
<span class="line-modified"> 913       projs-&gt;resproj = pn;</span>
 914       break;
 915     default:
<span class="line-modified"> 916       assert(false, &quot;unexpected projection from allocation node.&quot;);</span>


 917     }
 918   }
 919 
 920   // The resproj may not exist because the result could be ignored
 921   // and the exception object may not exist if an exception handler
 922   // swallows the exception but all the other must exist and be found.
<span class="line-modified"> 923   assert(projs-&gt;fallthrough_proj      != NULL, &quot;must be found&quot;);</span>
 924   do_asserts = do_asserts &amp;&amp; !Compile::current()-&gt;inlining_incrementally();
 925   assert(!do_asserts || projs-&gt;fallthrough_catchproj != NULL, &quot;must be found&quot;);
 926   assert(!do_asserts || projs-&gt;fallthrough_memproj   != NULL, &quot;must be found&quot;);
 927   assert(!do_asserts || projs-&gt;fallthrough_ioproj    != NULL, &quot;must be found&quot;);
 928   assert(!do_asserts || projs-&gt;catchall_catchproj    != NULL, &quot;must be found&quot;);
 929   if (separate_io_proj) {
 930     assert(!do_asserts || projs-&gt;catchall_memproj    != NULL, &quot;must be found&quot;);
 931     assert(!do_asserts || projs-&gt;catchall_ioproj     != NULL, &quot;must be found&quot;);
 932   }

 933 }
 934 
 935 Node *CallNode::Ideal(PhaseGVN *phase, bool can_reshape) {
 936   CallGenerator* cg = generator();
 937   if (can_reshape &amp;&amp; cg != NULL &amp;&amp; cg-&gt;is_mh_late_inline() &amp;&amp; !cg-&gt;already_attempted()) {
 938     // Check whether this MH handle call becomes a candidate for inlining
 939     ciMethod* callee = cg-&gt;method();
 940     vmIntrinsics::ID iid = callee-&gt;intrinsic_id();
 941     if (iid == vmIntrinsics::_invokeBasic) {
 942       if (in(TypeFunc::Parms)-&gt;Opcode() == Op_ConP) {
 943         phase-&gt;C-&gt;prepend_late_inline(cg);
 944         set_generator(NULL);
 945       }
 946     } else {
 947       assert(callee-&gt;has_member_arg(), &quot;wrong type of call?&quot;);
 948       if (in(TypeFunc::Parms + callee-&gt;arg_size() - 1)-&gt;Opcode() == Op_ConP) {
 949         phase-&gt;C-&gt;prepend_late_inline(cg);
 950         set_generator(NULL);
 951       }
 952     }
 953   }
 954   return SafePointNode::Ideal(phase, can_reshape);
 955 }
 956 
 957 bool CallNode::is_call_to_arraycopystub() const {
 958   if (_name != NULL &amp;&amp; strstr(_name, &quot;arraycopy&quot;) != 0) {
 959     return true;
 960   }
 961   return false;
 962 }
 963 
 964 //=============================================================================
 965 uint CallJavaNode::size_of() const { return sizeof(*this); }
 966 bool CallJavaNode::cmp( const Node &amp;n ) const {
 967   CallJavaNode &amp;call = (CallJavaNode&amp;)n;
 968   return CallNode::cmp(call) &amp;&amp; _method == call._method &amp;&amp;
 969          _override_symbolic_info == call._override_symbolic_info;
 970 }








































 971 #ifdef ASSERT
 972 bool CallJavaNode::validate_symbolic_info() const {
 973   if (method() == NULL) {
 974     return true; // call into runtime or uncommon trap
 975   }




 976   ciMethod* symbolic_info = jvms()-&gt;method()-&gt;get_method_at_bci(_bci);
 977   ciMethod* callee = method();
 978   if (symbolic_info-&gt;is_method_handle_intrinsic() &amp;&amp; !callee-&gt;is_method_handle_intrinsic()) {
 979     assert(override_symbolic_info(), &quot;should be set&quot;);
 980   }
 981   assert(ciMethod::is_consistent_info(symbolic_info, callee), &quot;inconsistent info&quot;);
 982   return true;
 983 }
 984 #endif
 985 
 986 #ifndef PRODUCT
 987 void CallJavaNode::dump_spec(outputStream *st) const {
 988   if( _method ) _method-&gt;print_short_name(st);
 989   CallNode::dump_spec(st);
 990 }
 991 
 992 void CallJavaNode::dump_compact_spec(outputStream* st) const {
 993   if (_method) {
 994     _method-&gt;print_short_name(st);
 995   } else {
</pre>
<hr />
<pre>
1010 int CallStaticJavaNode::uncommon_trap_request() const {
1011   if (_name != NULL &amp;&amp; !strcmp(_name, &quot;uncommon_trap&quot;)) {
1012     return extract_uncommon_trap_request(this);
1013   }
1014   return 0;
1015 }
1016 int CallStaticJavaNode::extract_uncommon_trap_request(const Node* call) {
1017 #ifndef PRODUCT
1018   if (!(call-&gt;req() &gt; TypeFunc::Parms &amp;&amp;
1019         call-&gt;in(TypeFunc::Parms) != NULL &amp;&amp;
1020         call-&gt;in(TypeFunc::Parms)-&gt;is_Con() &amp;&amp;
1021         call-&gt;in(TypeFunc::Parms)-&gt;bottom_type()-&gt;isa_int())) {
1022     assert(in_dump() != 0, &quot;OK if dumping&quot;);
1023     tty-&gt;print(&quot;[bad uncommon trap]&quot;);
1024     return 0;
1025   }
1026 #endif
1027   return call-&gt;in(TypeFunc::Parms)-&gt;bottom_type()-&gt;is_int()-&gt;get_con();
1028 }
1029 























































































































































1030 #ifndef PRODUCT
1031 void CallStaticJavaNode::dump_spec(outputStream *st) const {
1032   st-&gt;print(&quot;# Static &quot;);
1033   if (_name != NULL) {
1034     st-&gt;print(&quot;%s&quot;, _name);
1035     int trap_req = uncommon_trap_request();
1036     if (trap_req != 0) {
1037       char buf[100];
1038       st-&gt;print(&quot;(%s)&quot;,
1039                  Deoptimization::format_trap_request(buf, sizeof(buf),
1040                                                      trap_req));
1041     }
1042     st-&gt;print(&quot; &quot;);
1043   }
1044   CallJavaNode::dump_spec(st);
1045 }
1046 
1047 void CallStaticJavaNode::dump_compact_spec(outputStream* st) const {
1048   if (_method) {
1049     _method-&gt;print_short_name(st);
</pre>
<hr />
<pre>
1067   CallJavaNode::dump_spec(st);
1068 }
1069 #endif
1070 
1071 //=============================================================================
1072 uint CallRuntimeNode::size_of() const { return sizeof(*this); }
1073 bool CallRuntimeNode::cmp( const Node &amp;n ) const {
1074   CallRuntimeNode &amp;call = (CallRuntimeNode&amp;)n;
1075   return CallNode::cmp(call) &amp;&amp; !strcmp(_name,call._name);
1076 }
1077 #ifndef PRODUCT
1078 void CallRuntimeNode::dump_spec(outputStream *st) const {
1079   st-&gt;print(&quot;# &quot;);
1080   st-&gt;print(&quot;%s&quot;, _name);
1081   CallNode::dump_spec(st);
1082 }
1083 #endif
1084 
1085 //------------------------------calling_convention-----------------------------
1086 void CallRuntimeNode::calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const {







1087   Matcher::c_calling_convention( sig_bt, parm_regs, argcnt );
1088 }
1089 
1090 //=============================================================================
1091 //------------------------------calling_convention-----------------------------
1092 
1093 
1094 //=============================================================================
1095 #ifndef PRODUCT
1096 void CallLeafNode::dump_spec(outputStream *st) const {
1097   st-&gt;print(&quot;# &quot;);
1098   st-&gt;print(&quot;%s&quot;, _name);
1099   CallNode::dump_spec(st);
1100 }
1101 #endif
1102 






1103 //=============================================================================
1104 
1105 void SafePointNode::set_local(JVMState* jvms, uint idx, Node *c) {
1106   assert(verify_jvms(jvms), &quot;jvms must match&quot;);
1107   int loc = jvms-&gt;locoff() + idx;
1108   if (in(loc)-&gt;is_top() &amp;&amp; idx &gt; 0 &amp;&amp; !c-&gt;is_top() ) {
1109     // If current local idx is top then local idx - 1 could
1110     // be a long/double that needs to be killed since top could
1111     // represent the 2nd half ofthe long/double.
1112     uint ideal = in(loc -1)-&gt;ideal_reg();
1113     if (ideal == Op_RegD || ideal == Op_RegL) {
1114       // set other (low index) half to top
1115       set_req(loc - 1, in(loc));
1116     }
1117   }
1118   set_req(loc, c);
1119 }
1120 
1121 uint SafePointNode::size_of() const { return sizeof(*this); }
1122 bool SafePointNode::cmp( const Node &amp;n ) const {
</pre>
<hr />
<pre>
1340   }
1341   SafePointScalarObjectNode* res = (SafePointScalarObjectNode*)Node::clone();
1342   sosn_map-&gt;Insert((void*)this, (void*)res);
1343   return res;
1344 }
1345 
1346 
1347 #ifndef PRODUCT
1348 void SafePointScalarObjectNode::dump_spec(outputStream *st) const {
1349   st-&gt;print(&quot; # fields@[%d..%d]&quot;, first_index(),
1350              first_index() + n_fields() - 1);
1351 }
1352 
1353 #endif
1354 
1355 //=============================================================================
1356 uint AllocateNode::size_of() const { return sizeof(*this); }
1357 
1358 AllocateNode::AllocateNode(Compile* C, const TypeFunc *atype,
1359                            Node *ctrl, Node *mem, Node *abio,
<span class="line-modified">1360                            Node *size, Node *klass_node, Node *initial_test)</span>


1361   : CallNode(atype, NULL, TypeRawPtr::BOTTOM)
1362 {
1363   init_class_id(Class_Allocate);
1364   init_flags(Flag_is_macro);
1365   _is_scalar_replaceable = false;
1366   _is_non_escaping = false;
1367   _is_allocation_MemBar_redundant = false;

1368   Node *topnode = C-&gt;top();
1369 
1370   init_req( TypeFunc::Control  , ctrl );
1371   init_req( TypeFunc::I_O      , abio );
1372   init_req( TypeFunc::Memory   , mem );
1373   init_req( TypeFunc::ReturnAdr, topnode );
1374   init_req( TypeFunc::FramePtr , topnode );
1375   init_req( AllocSize          , size);
1376   init_req( KlassNode          , klass_node);
1377   init_req( InitialTest        , initial_test);
1378   init_req( ALength            , topnode);




1379   C-&gt;add_macro_node(this);
1380 }
1381 
1382 void AllocateNode::compute_MemBar_redundancy(ciMethod* initializer)
1383 {
1384   assert(initializer != NULL &amp;&amp;
<span class="line-modified">1385          initializer-&gt;is_initializer() &amp;&amp;</span>
<span class="line-modified">1386          !initializer-&gt;is_static(),</span>
<span class="line-removed">1387              &quot;unexpected initializer method&quot;);</span>
1388   BCEscapeAnalyzer* analyzer = initializer-&gt;get_bcea();
1389   if (analyzer == NULL) {
1390     return;
1391   }
1392 
1393   // Allocation node is first parameter in its initializer
1394   if (analyzer-&gt;is_arg_stack(0) || analyzer-&gt;is_arg_local(0)) {
1395     _is_allocation_MemBar_redundant = true;
1396   }
1397 }
<span class="line-modified">1398 Node *AllocateNode::make_ideal_mark(PhaseGVN *phase, Node* obj, Node* control, Node* mem) {</span>
























































1399   Node* mark_node = NULL;
1400   // For now only enable fast locking for non-array types
<span class="line-modified">1401   if (UseBiasedLocking &amp;&amp; Opcode() == Op_Allocate) {</span>
1402     Node* klass_node = in(AllocateNode::KlassNode);
1403     Node* proto_adr = phase-&gt;transform(new AddPNode(klass_node, klass_node, phase-&gt;MakeConX(in_bytes(Klass::prototype_header_offset()))));
1404     mark_node = LoadNode::make(*phase, control, mem, proto_adr, TypeRawPtr::BOTTOM, TypeX_X, TypeX_X-&gt;basic_type(), MemNode::unordered);
1405   } else {
1406     mark_node = phase-&gt;MakeConX(markWord::prototype().value());
1407   }
<span class="line-modified">1408   return mark_node;</span>


1409 }
1410 

1411 //=============================================================================
1412 Node* AllocateArrayNode::Ideal(PhaseGVN *phase, bool can_reshape) {
<span class="line-modified">1413   if (remove_dead_region(phase, can_reshape))  return this;</span>



1414   // Don&#39;t bother trying to transform a dead node
1415   if (in(0) &amp;&amp; in(0)-&gt;is_top())  return NULL;
1416 
1417   const Type* type = phase-&gt;type(Ideal_length());
1418   if (type-&gt;isa_int() &amp;&amp; type-&gt;is_int()-&gt;_hi &lt; 0) {
1419     if (can_reshape) {
1420       PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
1421       // Unreachable fall through path (negative array length),
1422       // the allocation can only throw so disconnect it.
1423       Node* proj = proj_out_or_null(TypeFunc::Control);
1424       Node* catchproj = NULL;
1425       if (proj != NULL) {
1426         for (DUIterator_Fast imax, i = proj-&gt;fast_outs(imax); i &lt; imax; i++) {
1427           Node *cn = proj-&gt;fast_out(i);
1428           if (cn-&gt;is_Catch()) {
1429             catchproj = cn-&gt;as_Multi()-&gt;proj_out_or_null(CatchProjNode::fall_through_index);
1430             break;
1431           }
1432         }
1433       }
</pre>
<hr />
<pre>
1818       this-&gt;collect_nodes_in_all_data(in_rel, true);
1819     }
1820     this-&gt;collect_nodes(out_rel, -2, false, false);
1821 }
1822 #endif
1823 
1824 //=============================================================================
1825 Node *LockNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1826 
1827   // perform any generic optimizations first (returns &#39;this&#39; or NULL)
1828   Node *result = SafePointNode::Ideal(phase, can_reshape);
1829   if (result != NULL)  return result;
1830   // Don&#39;t bother trying to transform a dead node
1831   if (in(0) &amp;&amp; in(0)-&gt;is_top())  return NULL;
1832 
1833   // Now see if we can optimize away this lock.  We don&#39;t actually
1834   // remove the locking here, we simply set the _eliminate flag which
1835   // prevents macro expansion from expanding the lock.  Since we don&#39;t
1836   // modify the graph, the value returned from this function is the
1837   // one computed above.
<span class="line-modified">1838   if (can_reshape &amp;&amp; EliminateLocks &amp;&amp; !is_non_esc_obj()) {</span>


1839     //
1840     // If we are locking an unescaped object, the lock/unlock is unnecessary
1841     //
1842     ConnectionGraph *cgr = phase-&gt;C-&gt;congraph();
1843     if (cgr != NULL &amp;&amp; cgr-&gt;not_global_escape(obj_node())) {
1844       assert(!is_eliminated() || is_coarsened(), &quot;sanity&quot;);
1845       // The lock could be marked eliminated by lock coarsening
1846       // code during first IGVN before EA. Replace coarsened flag
1847       // to eliminate all associated locks/unlocks.
1848 #ifdef ASSERT
1849       this-&gt;log_lock_optimization(phase-&gt;C,&quot;eliminate_lock_set_non_esc1&quot;);
1850 #endif
1851       this-&gt;set_non_esc_obj();
1852       return result;
1853     }
1854 
1855     //
1856     // Try lock coarsening
1857     //
1858     PhaseIterGVN* iter = phase-&gt;is_IterGVN();
</pre>
<hr />
<pre>
1986 }
1987 
1988 //=============================================================================
1989 uint UnlockNode::size_of() const { return sizeof(*this); }
1990 
1991 //=============================================================================
1992 Node *UnlockNode::Ideal(PhaseGVN *phase, bool can_reshape) {
1993 
1994   // perform any generic optimizations first (returns &#39;this&#39; or NULL)
1995   Node *result = SafePointNode::Ideal(phase, can_reshape);
1996   if (result != NULL)  return result;
1997   // Don&#39;t bother trying to transform a dead node
1998   if (in(0) &amp;&amp; in(0)-&gt;is_top())  return NULL;
1999 
2000   // Now see if we can optimize away this unlock.  We don&#39;t actually
2001   // remove the unlocking here, we simply set the _eliminate flag which
2002   // prevents macro expansion from expanding the unlock.  Since we don&#39;t
2003   // modify the graph, the value returned from this function is the
2004   // one computed above.
2005   // Escape state is defined after Parse phase.
<span class="line-modified">2006   if (can_reshape &amp;&amp; EliminateLocks &amp;&amp; !is_non_esc_obj()) {</span>


2007     //
2008     // If we are unlocking an unescaped object, the lock/unlock is unnecessary.
2009     //
2010     ConnectionGraph *cgr = phase-&gt;C-&gt;congraph();
2011     if (cgr != NULL &amp;&amp; cgr-&gt;not_global_escape(obj_node())) {
2012       assert(!is_eliminated() || is_coarsened(), &quot;sanity&quot;);
2013       // The lock could be marked eliminated by lock coarsening
2014       // code during first IGVN before EA. Replace coarsened flag
2015       // to eliminate all associated locks/unlocks.
2016 #ifdef ASSERT
2017       this-&gt;log_lock_optimization(phase-&gt;C, &quot;eliminate_lock_set_non_esc2&quot;);
2018 #endif
2019       this-&gt;set_non_esc_obj();
2020     }
2021   }
2022   return result;
2023 }
2024 
2025 const char * AbstractLockNode::kind_as_string() const {
2026   return is_coarsened()   ? &quot;coarsened&quot; :
</pre>
<hr />
<pre>
2068     }
2069     // unrelated
2070     return false;
2071   }
2072 
2073   if (dest_t-&gt;isa_aryptr()) {
2074     // arraycopy or array clone
2075     if (t_oop-&gt;isa_instptr()) {
2076       return false;
2077     }
2078     if (!t_oop-&gt;isa_aryptr()) {
2079       return true;
2080     }
2081 
2082     const Type* elem = dest_t-&gt;is_aryptr()-&gt;elem();
2083     if (elem == Type::BOTTOM) {
2084       // An array but we don&#39;t know what elements are
2085       return true;
2086     }
2087 
<span class="line-modified">2088     dest_t = dest_t-&gt;add_offset(Type::OffsetBot)-&gt;is_oopptr();</span>

2089     uint dest_alias = phase-&gt;C-&gt;get_alias_index(dest_t);
2090     uint t_oop_alias = phase-&gt;C-&gt;get_alias_index(t_oop);
2091 
2092     return dest_alias == t_oop_alias;
2093   }
2094 
2095   return true;
2096 }
</pre>
</td>
<td>
<hr />
<pre>
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;compiler/compileLog.hpp&quot;
  27 #include &quot;ci/bcEscapeAnalyzer.hpp&quot;
  28 #include &quot;compiler/oopMap.hpp&quot;
  29 #include &quot;gc/shared/barrierSet.hpp&quot;
  30 #include &quot;gc/shared/c2/barrierSetC2.hpp&quot;
  31 #include &quot;interpreter/interpreter.hpp&quot;
  32 #include &quot;opto/callGenerator.hpp&quot;
  33 #include &quot;opto/callnode.hpp&quot;
  34 #include &quot;opto/castnode.hpp&quot;
  35 #include &quot;opto/convertnode.hpp&quot;
  36 #include &quot;opto/escape.hpp&quot;
  37 #include &quot;opto/locknode.hpp&quot;
  38 #include &quot;opto/machnode.hpp&quot;
  39 #include &quot;opto/matcher.hpp&quot;
  40 #include &quot;opto/parse.hpp&quot;
  41 #include &quot;opto/regalloc.hpp&quot;
  42 #include &quot;opto/regmask.hpp&quot;
  43 #include &quot;opto/rootnode.hpp&quot;
  44 #include &quot;opto/runtime.hpp&quot;
<span class="line-added">  45 #include &quot;opto/valuetypenode.hpp&quot;</span>
<span class="line-added">  46 #include &quot;runtime/sharedRuntime.hpp&quot;</span>
  47 #include &quot;utilities/powerOfTwo.hpp&quot;
  48 
  49 // Portions of code courtesy of Clifford Click
  50 
  51 // Optimization - Graph Style
  52 
  53 //=============================================================================
  54 uint StartNode::size_of() const { return sizeof(*this); }
  55 bool StartNode::cmp( const Node &amp;n ) const
  56 { return _domain == ((StartNode&amp;)n)._domain; }
  57 const Type *StartNode::bottom_type() const { return _domain; }
  58 const Type* StartNode::Value(PhaseGVN* phase) const { return _domain; }
  59 #ifndef PRODUCT
  60 void StartNode::dump_spec(outputStream *st) const { st-&gt;print(&quot; #&quot;); _domain-&gt;dump_on(st);}
  61 void StartNode::dump_compact_spec(outputStream *st) const { /* empty */ }
  62 #endif
  63 
  64 //------------------------------Ideal------------------------------------------
  65 Node *StartNode::Ideal(PhaseGVN *phase, bool can_reshape){
  66   return remove_dead_region(phase, can_reshape) ? this : NULL;
  67 }
  68 
  69 //------------------------------calling_convention-----------------------------
  70 void StartNode::calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const {
  71   Matcher::calling_convention( sig_bt, parm_regs, argcnt, false );
  72 }
  73 
  74 //------------------------------Registers--------------------------------------
  75 const RegMask &amp;StartNode::in_RegMask(uint) const {
  76   return RegMask::Empty;
  77 }
  78 
  79 //------------------------------match------------------------------------------
  80 // Construct projections for incoming parameters, and their RegMask info
<span class="line-modified">  81 Node *StartNode::match(const ProjNode *proj, const Matcher *match, const RegMask* mask) {</span>
  82   switch (proj-&gt;_con) {
  83   case TypeFunc::Control:
  84   case TypeFunc::I_O:
  85   case TypeFunc::Memory:
  86     return new MachProjNode(this,proj-&gt;_con,RegMask::Empty,MachProjNode::unmatched_proj);
  87   case TypeFunc::FramePtr:
  88     return new MachProjNode(this,proj-&gt;_con,Matcher::c_frame_ptr_mask, Op_RegP);
  89   case TypeFunc::ReturnAdr:
  90     return new MachProjNode(this,proj-&gt;_con,match-&gt;_return_addr_mask,Op_RegP);
  91   case TypeFunc::Parms:
  92   default: {
  93       uint parm_num = proj-&gt;_con - TypeFunc::Parms;
  94       const Type *t = _domain-&gt;field_at(proj-&gt;_con);
  95       if (t-&gt;base() == Type::Half)  // 2nd half of Longs and Doubles
  96         return new ConNode(Type::TOP);
  97       uint ideal_reg = t-&gt;ideal_reg();
  98       RegMask &amp;rm = match-&gt;_calling_convention_mask[parm_num];
  99       return new MachProjNode(this,proj-&gt;_con,rm,ideal_reg);
 100     }
 101   }
 102   return NULL;
 103 }
 104 











 105 //=============================================================================
 106 const char * const ParmNode::names[TypeFunc::Parms+1] = {
 107   &quot;Control&quot;, &quot;I_O&quot;, &quot;Memory&quot;, &quot;FramePtr&quot;, &quot;ReturnAdr&quot;, &quot;Parms&quot;
 108 };
 109 
 110 #ifndef PRODUCT
 111 void ParmNode::dump_spec(outputStream *st) const {
 112   if( _con &lt; TypeFunc::Parms ) {
 113     st-&gt;print(&quot;%s&quot;, names[_con]);
 114   } else {
 115     st-&gt;print(&quot;Parm%d: &quot;,_con-TypeFunc::Parms);
 116     // Verbose and WizardMode dump bottom_type for all nodes
 117     if( !Verbose &amp;&amp; !WizardMode )   bottom_type()-&gt;dump_on(st);
 118   }
 119 }
 120 
 121 void ParmNode::dump_compact_spec(outputStream *st) const {
 122   if (_con &lt; TypeFunc::Parms) {
 123     st-&gt;print(&quot;%s&quot;, names[_con]);
 124   } else {
</pre>
<hr />
<pre>
 454       if (cik-&gt;is_instance_klass()) {
 455         cik-&gt;print_name_on(st);
 456         iklass = cik-&gt;as_instance_klass();
 457       } else if (cik-&gt;is_type_array_klass()) {
 458         cik-&gt;as_array_klass()-&gt;base_element_type()-&gt;print_name_on(st);
 459         st-&gt;print(&quot;[%d]&quot;, spobj-&gt;n_fields());
 460       } else if (cik-&gt;is_obj_array_klass()) {
 461         ciKlass* cie = cik-&gt;as_obj_array_klass()-&gt;base_element_klass();
 462         if (cie-&gt;is_instance_klass()) {
 463           cie-&gt;print_name_on(st);
 464         } else if (cie-&gt;is_type_array_klass()) {
 465           cie-&gt;as_array_klass()-&gt;base_element_type()-&gt;print_name_on(st);
 466         } else {
 467           ShouldNotReachHere();
 468         }
 469         st-&gt;print(&quot;[%d]&quot;, spobj-&gt;n_fields());
 470         int ndim = cik-&gt;as_array_klass()-&gt;dimension() - 1;
 471         while (ndim-- &gt; 0) {
 472           st-&gt;print(&quot;[]&quot;);
 473         }
<span class="line-added"> 474       } else if (cik-&gt;is_value_array_klass()) {</span>
<span class="line-added"> 475         ciKlass* cie = cik-&gt;as_value_array_klass()-&gt;base_element_klass();</span>
<span class="line-added"> 476         cie-&gt;print_name_on(st);</span>
<span class="line-added"> 477         st-&gt;print(&quot;[%d]&quot;, spobj-&gt;n_fields());</span>
<span class="line-added"> 478         int ndim = cik-&gt;as_array_klass()-&gt;dimension() - 1;</span>
<span class="line-added"> 479         while (ndim-- &gt; 0) {</span>
<span class="line-added"> 480           st-&gt;print(&quot;[]&quot;);</span>
<span class="line-added"> 481         }</span>
 482       }
 483       st-&gt;print(&quot;={&quot;);
 484       uint nf = spobj-&gt;n_fields();
 485       if (nf &gt; 0) {
 486         uint first_ind = spobj-&gt;first_index(mcall-&gt;jvms());
 487         Node* fld_node = mcall-&gt;in(first_ind);
 488         ciField* cifield;
 489         if (iklass != NULL) {
 490           st-&gt;print(&quot; [&quot;);
 491           cifield = iklass-&gt;nonstatic_field_at(0);
 492           cifield-&gt;print_name_on(st);
 493           format_helper(regalloc, st, fld_node, &quot;:&quot;, 0, &amp;scobjs);
 494         } else {
 495           format_helper(regalloc, st, fld_node, &quot;[&quot;, 0, &amp;scobjs);
 496         }
 497         for (uint j = 1; j &lt; nf; j++) {
 498           fld_node = mcall-&gt;in(first_ind+j);
 499           if (iklass != NULL) {
 500             st-&gt;print(&quot;, [&quot;);
 501             cifield = iklass-&gt;nonstatic_field_at(j);
</pre>
<hr />
<pre>
 671 #ifndef PRODUCT
 672 void CallNode::dump_req(outputStream *st) const {
 673   // Dump the required inputs, enclosed in &#39;(&#39; and &#39;)&#39;
 674   uint i;                       // Exit value of loop
 675   for (i = 0; i &lt; req(); i++) {    // For all required inputs
 676     if (i == TypeFunc::Parms) st-&gt;print(&quot;(&quot;);
 677     if (in(i)) st-&gt;print(&quot;%c%d &quot;, Compile::current()-&gt;node_arena()-&gt;contains(in(i)) ? &#39; &#39; : &#39;o&#39;, in(i)-&gt;_idx);
 678     else st-&gt;print(&quot;_ &quot;);
 679   }
 680   st-&gt;print(&quot;)&quot;);
 681 }
 682 
 683 void CallNode::dump_spec(outputStream *st) const {
 684   st-&gt;print(&quot; &quot;);
 685   if (tf() != NULL)  tf()-&gt;dump_on(st);
 686   if (_cnt != COUNT_UNKNOWN)  st-&gt;print(&quot; C=%f&quot;,_cnt);
 687   if (jvms() != NULL)  jvms()-&gt;dump_spec(st);
 688 }
 689 #endif
 690 
<span class="line-modified"> 691 const Type *CallNode::bottom_type() const { return tf()-&gt;range_cc(); }</span>
 692 const Type* CallNode::Value(PhaseGVN* phase) const {
<span class="line-modified"> 693   if (!in(0) || phase-&gt;type(in(0)) == Type::TOP) {</span>
<span class="line-modified"> 694     return Type::TOP;</span>
<span class="line-added"> 695   }</span>
<span class="line-added"> 696   return tf()-&gt;range_cc();</span>
 697 }
 698 
 699 //------------------------------calling_convention-----------------------------
<span class="line-modified"> 700 void CallNode::calling_convention(BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt) const {</span>
<span class="line-added"> 701   if (_entry_point == StubRoutines::store_value_type_fields_to_buf()) {</span>
<span class="line-added"> 702     // The call to that stub is a special case: its inputs are</span>
<span class="line-added"> 703     // multiple values returned from a call and so it should follow</span>
<span class="line-added"> 704     // the return convention.</span>
<span class="line-added"> 705     SharedRuntime::java_return_convention(sig_bt, parm_regs, argcnt);</span>
<span class="line-added"> 706     return;</span>
<span class="line-added"> 707   }</span>
 708   // Use the standard compiler calling convention
 709   Matcher::calling_convention( sig_bt, parm_regs, argcnt, true );
 710 }
 711 
 712 
 713 //------------------------------match------------------------------------------
 714 // Construct projections for control, I/O, memory-fields, ..., and
 715 // return result(s) along with their RegMask info
<span class="line-modified"> 716 Node *CallNode::match(const ProjNode *proj, const Matcher *match, const RegMask* mask) {</span>
<span class="line-modified"> 717   uint con = proj-&gt;_con;</span>
<span class="line-added"> 718   const TypeTuple *range_cc = tf()-&gt;range_cc();</span>
<span class="line-added"> 719   if (con &gt;= TypeFunc::Parms) {</span>
<span class="line-added"> 720     if (is_CallRuntime()) {</span>
<span class="line-added"> 721       if (con == TypeFunc::Parms) {</span>
<span class="line-added"> 722         uint ideal_reg = range_cc-&gt;field_at(TypeFunc::Parms)-&gt;ideal_reg();</span>
<span class="line-added"> 723         OptoRegPair regs = match-&gt;c_return_value(ideal_reg,true);</span>
<span class="line-added"> 724         RegMask rm = RegMask(regs.first());</span>
<span class="line-added"> 725         if (OptoReg::is_valid(regs.second())) {</span>
<span class="line-added"> 726           rm.Insert(regs.second());</span>
<span class="line-added"> 727         }</span>
<span class="line-added"> 728         return new MachProjNode(this,con,rm,ideal_reg);</span>
<span class="line-added"> 729       } else {</span>
<span class="line-added"> 730         assert(con == TypeFunc::Parms+1, &quot;only one return value&quot;);</span>
<span class="line-added"> 731         assert(range_cc-&gt;field_at(TypeFunc::Parms+1) == Type::HALF, &quot;&quot;);</span>
<span class="line-added"> 732         return new MachProjNode(this,con, RegMask::Empty, (uint)OptoReg::Bad);</span>
<span class="line-added"> 733       }</span>
<span class="line-added"> 734     } else {</span>
<span class="line-added"> 735       // The Call may return multiple values (value type fields): we</span>
<span class="line-added"> 736       // create one projection per returned values.</span>
<span class="line-added"> 737       assert(con &lt;= TypeFunc::Parms+1 || ValueTypeReturnedAsFields, &quot;only for multi value return&quot;);</span>
<span class="line-added"> 738       uint ideal_reg = range_cc-&gt;field_at(con)-&gt;ideal_reg();</span>
<span class="line-added"> 739       return new MachProjNode(this, con, mask[con-TypeFunc::Parms], ideal_reg);</span>
<span class="line-added"> 740     }</span>
<span class="line-added"> 741   }</span>
<span class="line-added"> 742 </span>
<span class="line-added"> 743   switch (con) {</span>
 744   case TypeFunc::Control:
 745   case TypeFunc::I_O:
 746   case TypeFunc::Memory:
 747     return new MachProjNode(this,proj-&gt;_con,RegMask::Empty,MachProjNode::unmatched_proj);
 748 
















 749   case TypeFunc::ReturnAdr:
 750   case TypeFunc::FramePtr:
 751   default:
 752     ShouldNotReachHere();
 753   }
 754   return NULL;
 755 }
 756 
 757 // Do we Match on this edge index or not?  Match no edges
 758 uint CallNode::match_edge(uint idx) const {
 759   return 0;
 760 }
 761 
 762 //
 763 // Determine whether the call could modify the field of the specified
 764 // instance at the specified offset.
 765 //
 766 bool CallNode::may_modify(const TypeOopPtr *t_oop, PhaseTransform *phase) {
 767   assert((t_oop != NULL), &quot;sanity&quot;);
 768   if (is_call_to_arraycopystub() &amp;&amp; strcmp(_name, &quot;unsafe_arraycopy&quot;) != 0) {
<span class="line-modified"> 769     const TypeTuple* args = _tf-&gt;domain_sig();</span>
 770     Node* dest = NULL;
 771     // Stubs that can be called once an ArrayCopyNode is expanded have
 772     // different signatures. Look for the second pointer argument,
 773     // that is the destination of the copy.
 774     for (uint i = TypeFunc::Parms, j = 0; i &lt; args-&gt;cnt(); i++) {
 775       if (args-&gt;field_at(i)-&gt;isa_ptr()) {
 776         j++;
 777         if (j == 2) {
 778           dest = in(i);
 779           break;
 780         }
 781       }
 782     }
 783     guarantee(dest != NULL, &quot;Call had only one ptr in, broken IR!&quot;);
 784     if (!dest-&gt;is_top() &amp;&amp; may_modify_arraycopy_helper(phase-&gt;type(dest)-&gt;is_oopptr(), t_oop, phase)) {
 785       return true;
 786     }
 787     return false;
 788   }
 789   if (t_oop-&gt;is_known_instance()) {
</pre>
<hr />
<pre>
 798       Node* proj = proj_out_or_null(TypeFunc::Parms);
 799       if ((proj == NULL) || (phase-&gt;type(proj)-&gt;is_instptr()-&gt;klass() != boxing_klass)) {
 800         return false;
 801       }
 802     }
 803     if (is_CallJava() &amp;&amp; as_CallJava()-&gt;method() != NULL) {
 804       ciMethod* meth = as_CallJava()-&gt;method();
 805       if (meth-&gt;is_getter()) {
 806         return false;
 807       }
 808       // May modify (by reflection) if an boxing object is passed
 809       // as argument or returned.
 810       Node* proj = returns_pointer() ? proj_out_or_null(TypeFunc::Parms) : NULL;
 811       if (proj != NULL) {
 812         const TypeInstPtr* inst_t = phase-&gt;type(proj)-&gt;isa_instptr();
 813         if ((inst_t != NULL) &amp;&amp; (!inst_t-&gt;klass_is_exact() ||
 814                                  (inst_t-&gt;klass() == boxing_klass))) {
 815           return true;
 816         }
 817       }
<span class="line-modified"> 818       const TypeTuple* d = tf()-&gt;domain_cc();</span>
 819       for (uint i = TypeFunc::Parms; i &lt; d-&gt;cnt(); i++) {
 820         const TypeInstPtr* inst_t = d-&gt;field_at(i)-&gt;isa_instptr();
 821         if ((inst_t != NULL) &amp;&amp; (!inst_t-&gt;klass_is_exact() ||
 822                                  (inst_t-&gt;klass() == boxing_klass))) {
 823           return true;
 824         }
 825       }
 826       return false;
 827     }
 828   }
 829   return true;
 830 }
 831 
 832 // Does this call have a direct reference to n other than debug information?
 833 bool CallNode::has_non_debug_use(Node *n) {
<span class="line-modified"> 834   const TypeTuple * d = tf()-&gt;domain_cc();</span>
 835   for (uint i = TypeFunc::Parms; i &lt; d-&gt;cnt(); i++) {
 836     Node *arg = in(i);
 837     if (arg == n) {
 838       return true;
 839     }
 840   }
 841   return false;
 842 }
 843 
<span class="line-added"> 844 bool CallNode::has_debug_use(Node *n) {</span>
<span class="line-added"> 845   assert(jvms() != NULL, &quot;jvms should not be null&quot;);</span>
<span class="line-added"> 846   for (uint i = jvms()-&gt;debug_start(); i &lt; jvms()-&gt;debug_end(); i++) {</span>
<span class="line-added"> 847     Node *arg = in(i);</span>
<span class="line-added"> 848     if (arg == n) {</span>
<span class="line-added"> 849       return true;</span>
<span class="line-added"> 850     }</span>
<span class="line-added"> 851   }</span>
<span class="line-added"> 852   return false;</span>
<span class="line-added"> 853 }</span>
<span class="line-added"> 854 </span>
 855 // Returns the unique CheckCastPP of a call
 856 // or &#39;this&#39; if there are several CheckCastPP or unexpected uses
 857 // or returns NULL if there is no one.
 858 Node *CallNode::result_cast() {
 859   Node *cast = NULL;
 860 
 861   Node *p = proj_out_or_null(TypeFunc::Parms);
 862   if (p == NULL)
 863     return NULL;
 864 
 865   for (DUIterator_Fast imax, i = p-&gt;fast_outs(imax); i &lt; imax; i++) {
 866     Node *use = p-&gt;fast_out(i);
 867     if (use-&gt;is_CheckCastPP()) {
 868       if (cast != NULL) {
 869         return this;  // more than 1 CheckCastPP
 870       }
 871       cast = use;
 872     } else if (!use-&gt;is_Initialize() &amp;&amp;
 873                !use-&gt;is_AddP() &amp;&amp;
 874                use-&gt;Opcode() != Op_MemBarStoreStore) {
 875       // Expected uses are restricted to a CheckCastPP, an Initialize
 876       // node, a MemBarStoreStore (clone) and AddP nodes. If we
 877       // encounter any other use (a Phi node can be seen in rare
 878       // cases) return this to prevent incorrect optimizations.
 879       return this;
 880     }
 881   }
 882   return cast;
 883 }
 884 
 885 
<span class="line-modified"> 886 CallProjections* CallNode::extract_projections(bool separate_io_proj, bool do_asserts) {</span>
<span class="line-modified"> 887   uint max_res = TypeFunc::Parms-1;</span>
<span class="line-modified"> 888   for (DUIterator_Fast imax, i = fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-modified"> 889     ProjNode *pn = fast_out(i)-&gt;as_Proj();</span>
<span class="line-modified"> 890     max_res = MAX2(max_res, pn-&gt;_con);</span>
<span class="line-modified"> 891   }</span>
<span class="line-modified"> 892 </span>
<span class="line-modified"> 893   assert(max_res &lt; _tf-&gt;range_cc()-&gt;cnt(), &quot;result out of bounds&quot;);</span>
<span class="line-modified"> 894 </span>
<span class="line-modified"> 895   uint projs_size = sizeof(CallProjections);</span>
<span class="line-added"> 896   if (max_res &gt; TypeFunc::Parms) {</span>
<span class="line-added"> 897     projs_size += (max_res-TypeFunc::Parms)*sizeof(Node*);</span>
<span class="line-added"> 898   }</span>
<span class="line-added"> 899   char* projs_storage = resource_allocate_bytes(projs_size);</span>
<span class="line-added"> 900   CallProjections* projs = new(projs_storage)CallProjections(max_res - TypeFunc::Parms + 1);</span>
 901 
 902   for (DUIterator_Fast imax, i = fast_outs(imax); i &lt; imax; i++) {
 903     ProjNode *pn = fast_out(i)-&gt;as_Proj();
 904     if (pn-&gt;outcnt() == 0) continue;
 905     switch (pn-&gt;_con) {
 906     case TypeFunc::Control:
 907       {
 908         // For Control (fallthrough) and I_O (catch_all_index) we have CatchProj -&gt; Catch -&gt; Proj
 909         projs-&gt;fallthrough_proj = pn;
 910         DUIterator_Fast jmax, j = pn-&gt;fast_outs(jmax);
 911         const Node *cn = pn-&gt;fast_out(j);
 912         if (cn-&gt;is_Catch()) {
 913           ProjNode *cpn = NULL;
 914           for (DUIterator_Fast kmax, k = cn-&gt;fast_outs(kmax); k &lt; kmax; k++) {
 915             cpn = cn-&gt;fast_out(k)-&gt;as_Proj();
 916             assert(cpn-&gt;is_CatchProj(), &quot;must be a CatchProjNode&quot;);
 917             if (cpn-&gt;_con == CatchProjNode::fall_through_index)
 918               projs-&gt;fallthrough_catchproj = cpn;
 919             else {
 920               assert(cpn-&gt;_con == CatchProjNode::catch_all_index, &quot;must be correct index.&quot;);
</pre>
<hr />
<pre>
 927     case TypeFunc::I_O:
 928       if (pn-&gt;_is_io_use)
 929         projs-&gt;catchall_ioproj = pn;
 930       else
 931         projs-&gt;fallthrough_ioproj = pn;
 932       for (DUIterator j = pn-&gt;outs(); pn-&gt;has_out(j); j++) {
 933         Node* e = pn-&gt;out(j);
 934         if (e-&gt;Opcode() == Op_CreateEx &amp;&amp; e-&gt;in(0)-&gt;is_CatchProj() &amp;&amp; e-&gt;outcnt() &gt; 0) {
 935           assert(projs-&gt;exobj == NULL, &quot;only one&quot;);
 936           projs-&gt;exobj = e;
 937         }
 938       }
 939       break;
 940     case TypeFunc::Memory:
 941       if (pn-&gt;_is_io_use)
 942         projs-&gt;catchall_memproj = pn;
 943       else
 944         projs-&gt;fallthrough_memproj = pn;
 945       break;
 946     case TypeFunc::Parms:
<span class="line-modified"> 947       projs-&gt;resproj[0] = pn;</span>
 948       break;
 949     default:
<span class="line-modified"> 950       assert(pn-&gt;_con &lt;= max_res, &quot;unexpected projection from allocation node.&quot;);</span>
<span class="line-added"> 951       projs-&gt;resproj[pn-&gt;_con-TypeFunc::Parms] = pn;</span>
<span class="line-added"> 952       break;</span>
 953     }
 954   }
 955 
 956   // The resproj may not exist because the result could be ignored
 957   // and the exception object may not exist if an exception handler
 958   // swallows the exception but all the other must exist and be found.
<span class="line-modified"> 959   do_asserts = do_asserts &amp;&amp; !Compile::current()-&gt;inlining_incrementally();</span>
 960   assert(!do_asserts || projs-&gt;fallthrough_proj      != NULL, &quot;must be found&quot;);
 961   assert(!do_asserts || projs-&gt;fallthrough_catchproj != NULL, &quot;must be found&quot;);
 962   assert(!do_asserts || projs-&gt;fallthrough_memproj   != NULL, &quot;must be found&quot;);
 963   assert(!do_asserts || projs-&gt;fallthrough_ioproj    != NULL, &quot;must be found&quot;);
 964   assert(!do_asserts || projs-&gt;catchall_catchproj    != NULL, &quot;must be found&quot;);
 965   if (separate_io_proj) {
 966     assert(!do_asserts || projs-&gt;catchall_memproj    != NULL, &quot;must be found&quot;);
 967     assert(!do_asserts || projs-&gt;catchall_ioproj     != NULL, &quot;must be found&quot;);
 968   }
<span class="line-added"> 969   return projs;</span>
 970 }
 971 
 972 Node *CallNode::Ideal(PhaseGVN *phase, bool can_reshape) {
 973   CallGenerator* cg = generator();
 974   if (can_reshape &amp;&amp; cg != NULL &amp;&amp; cg-&gt;is_mh_late_inline() &amp;&amp; !cg-&gt;already_attempted()) {
 975     // Check whether this MH handle call becomes a candidate for inlining
 976     ciMethod* callee = cg-&gt;method();
 977     vmIntrinsics::ID iid = callee-&gt;intrinsic_id();
 978     if (iid == vmIntrinsics::_invokeBasic) {
 979       if (in(TypeFunc::Parms)-&gt;Opcode() == Op_ConP) {
 980         phase-&gt;C-&gt;prepend_late_inline(cg);
 981         set_generator(NULL);
 982       }
 983     } else {
 984       assert(callee-&gt;has_member_arg(), &quot;wrong type of call?&quot;);
 985       if (in(TypeFunc::Parms + callee-&gt;arg_size() - 1)-&gt;Opcode() == Op_ConP) {
 986         phase-&gt;C-&gt;prepend_late_inline(cg);
 987         set_generator(NULL);
 988       }
 989     }
 990   }
 991   return SafePointNode::Ideal(phase, can_reshape);
 992 }
 993 
 994 bool CallNode::is_call_to_arraycopystub() const {
 995   if (_name != NULL &amp;&amp; strstr(_name, &quot;arraycopy&quot;) != 0) {
 996     return true;
 997   }
 998   return false;
 999 }
1000 
1001 //=============================================================================
1002 uint CallJavaNode::size_of() const { return sizeof(*this); }
1003 bool CallJavaNode::cmp( const Node &amp;n ) const {
1004   CallJavaNode &amp;call = (CallJavaNode&amp;)n;
1005   return CallNode::cmp(call) &amp;&amp; _method == call._method &amp;&amp;
1006          _override_symbolic_info == call._override_symbolic_info;
1007 }
<span class="line-added">1008 </span>
<span class="line-added">1009 void CallJavaNode::copy_call_debug_info(PhaseIterGVN* phase, CallNode *oldcall) {</span>
<span class="line-added">1010   // Copy debug information and adjust JVMState information</span>
<span class="line-added">1011   uint old_dbg_start = oldcall-&gt;tf()-&gt;domain_sig()-&gt;cnt();</span>
<span class="line-added">1012   uint new_dbg_start = tf()-&gt;domain_sig()-&gt;cnt();</span>
<span class="line-added">1013   int jvms_adj  = new_dbg_start - old_dbg_start;</span>
<span class="line-added">1014   assert (new_dbg_start == req(), &quot;argument count mismatch&quot;);</span>
<span class="line-added">1015   Compile* C = phase-&gt;C;</span>
<span class="line-added">1016 </span>
<span class="line-added">1017   // SafePointScalarObject node could be referenced several times in debug info.</span>
<span class="line-added">1018   // Use Dict to record cloned nodes.</span>
<span class="line-added">1019   Dict* sosn_map = new Dict(cmpkey,hashkey);</span>
<span class="line-added">1020   for (uint i = old_dbg_start; i &lt; oldcall-&gt;req(); i++) {</span>
<span class="line-added">1021     Node* old_in = oldcall-&gt;in(i);</span>
<span class="line-added">1022     // Clone old SafePointScalarObjectNodes, adjusting their field contents.</span>
<span class="line-added">1023     if (old_in != NULL &amp;&amp; old_in-&gt;is_SafePointScalarObject()) {</span>
<span class="line-added">1024       SafePointScalarObjectNode* old_sosn = old_in-&gt;as_SafePointScalarObject();</span>
<span class="line-added">1025       uint old_unique = C-&gt;unique();</span>
<span class="line-added">1026       Node* new_in = old_sosn-&gt;clone(sosn_map);</span>
<span class="line-added">1027       if (old_unique != C-&gt;unique()) { // New node?</span>
<span class="line-added">1028         new_in-&gt;set_req(0, C-&gt;root()); // reset control edge</span>
<span class="line-added">1029         new_in = phase-&gt;transform(new_in); // Register new node.</span>
<span class="line-added">1030       }</span>
<span class="line-added">1031       old_in = new_in;</span>
<span class="line-added">1032     }</span>
<span class="line-added">1033     add_req(old_in);</span>
<span class="line-added">1034   }</span>
<span class="line-added">1035 </span>
<span class="line-added">1036   // JVMS may be shared so clone it before we modify it</span>
<span class="line-added">1037   set_jvms(oldcall-&gt;jvms() != NULL ? oldcall-&gt;jvms()-&gt;clone_deep(C) : NULL);</span>
<span class="line-added">1038   for (JVMState *jvms = this-&gt;jvms(); jvms != NULL; jvms = jvms-&gt;caller()) {</span>
<span class="line-added">1039     jvms-&gt;set_map(this);</span>
<span class="line-added">1040     jvms-&gt;set_locoff(jvms-&gt;locoff()+jvms_adj);</span>
<span class="line-added">1041     jvms-&gt;set_stkoff(jvms-&gt;stkoff()+jvms_adj);</span>
<span class="line-added">1042     jvms-&gt;set_monoff(jvms-&gt;monoff()+jvms_adj);</span>
<span class="line-added">1043     jvms-&gt;set_scloff(jvms-&gt;scloff()+jvms_adj);</span>
<span class="line-added">1044     jvms-&gt;set_endoff(jvms-&gt;endoff()+jvms_adj);</span>
<span class="line-added">1045   }</span>
<span class="line-added">1046 }</span>
<span class="line-added">1047 </span>
1048 #ifdef ASSERT
1049 bool CallJavaNode::validate_symbolic_info() const {
1050   if (method() == NULL) {
1051     return true; // call into runtime or uncommon trap
1052   }
<span class="line-added">1053   Bytecodes::Code bc = jvms()-&gt;method()-&gt;java_code_at_bci(_bci);</span>
<span class="line-added">1054   if (EnableValhalla &amp;&amp; (bc == Bytecodes::_if_acmpeq || bc == Bytecodes::_if_acmpne)) {</span>
<span class="line-added">1055     return true;</span>
<span class="line-added">1056   }</span>
1057   ciMethod* symbolic_info = jvms()-&gt;method()-&gt;get_method_at_bci(_bci);
1058   ciMethod* callee = method();
1059   if (symbolic_info-&gt;is_method_handle_intrinsic() &amp;&amp; !callee-&gt;is_method_handle_intrinsic()) {
1060     assert(override_symbolic_info(), &quot;should be set&quot;);
1061   }
1062   assert(ciMethod::is_consistent_info(symbolic_info, callee), &quot;inconsistent info&quot;);
1063   return true;
1064 }
1065 #endif
1066 
1067 #ifndef PRODUCT
1068 void CallJavaNode::dump_spec(outputStream *st) const {
1069   if( _method ) _method-&gt;print_short_name(st);
1070   CallNode::dump_spec(st);
1071 }
1072 
1073 void CallJavaNode::dump_compact_spec(outputStream* st) const {
1074   if (_method) {
1075     _method-&gt;print_short_name(st);
1076   } else {
</pre>
<hr />
<pre>
1091 int CallStaticJavaNode::uncommon_trap_request() const {
1092   if (_name != NULL &amp;&amp; !strcmp(_name, &quot;uncommon_trap&quot;)) {
1093     return extract_uncommon_trap_request(this);
1094   }
1095   return 0;
1096 }
1097 int CallStaticJavaNode::extract_uncommon_trap_request(const Node* call) {
1098 #ifndef PRODUCT
1099   if (!(call-&gt;req() &gt; TypeFunc::Parms &amp;&amp;
1100         call-&gt;in(TypeFunc::Parms) != NULL &amp;&amp;
1101         call-&gt;in(TypeFunc::Parms)-&gt;is_Con() &amp;&amp;
1102         call-&gt;in(TypeFunc::Parms)-&gt;bottom_type()-&gt;isa_int())) {
1103     assert(in_dump() != 0, &quot;OK if dumping&quot;);
1104     tty-&gt;print(&quot;[bad uncommon trap]&quot;);
1105     return 0;
1106   }
1107 #endif
1108   return call-&gt;in(TypeFunc::Parms)-&gt;bottom_type()-&gt;is_int()-&gt;get_con();
1109 }
1110 
<span class="line-added">1111 bool CallStaticJavaNode::remove_useless_allocation(PhaseGVN *phase, Node* ctl, Node* mem, Node* unc_arg) {</span>
<span class="line-added">1112   // Split if can cause the flattened array branch of an array load to</span>
<span class="line-added">1113   // end in an uncommon trap. In that case, the allocation of the</span>
<span class="line-added">1114   // loaded value and its initialization is useless. Eliminate it. use</span>
<span class="line-added">1115   // the jvm state of the allocation to create a new uncommon trap</span>
<span class="line-added">1116   // call at the load.</span>
<span class="line-added">1117   if (ctl == NULL || ctl-&gt;is_top() || mem == NULL || mem-&gt;is_top() || !mem-&gt;is_MergeMem()) {</span>
<span class="line-added">1118     return false;</span>
<span class="line-added">1119   }</span>
<span class="line-added">1120   PhaseIterGVN* igvn = phase-&gt;is_IterGVN();</span>
<span class="line-added">1121   if (ctl-&gt;is_Region()) {</span>
<span class="line-added">1122     bool res = false;</span>
<span class="line-added">1123     for (uint i = 1; i &lt; ctl-&gt;req(); i++) {</span>
<span class="line-added">1124       MergeMemNode* mm = mem-&gt;clone()-&gt;as_MergeMem();</span>
<span class="line-added">1125       for (MergeMemStream mms(mm); mms.next_non_empty(); ) {</span>
<span class="line-added">1126         Node* m = mms.memory();</span>
<span class="line-added">1127         if (m-&gt;is_Phi() &amp;&amp; m-&gt;in(0) == ctl) {</span>
<span class="line-added">1128           mms.set_memory(m-&gt;in(i));</span>
<span class="line-added">1129         }</span>
<span class="line-added">1130       }</span>
<span class="line-added">1131       if (remove_useless_allocation(phase, ctl-&gt;in(i), mm, unc_arg)) {</span>
<span class="line-added">1132         res = true;</span>
<span class="line-added">1133         if (!ctl-&gt;in(i)-&gt;is_Region()) {</span>
<span class="line-added">1134           igvn-&gt;replace_input_of(ctl, i, phase-&gt;C-&gt;top());</span>
<span class="line-added">1135         }</span>
<span class="line-added">1136       }</span>
<span class="line-added">1137       igvn-&gt;remove_dead_node(mm);</span>
<span class="line-added">1138     }</span>
<span class="line-added">1139     return res;</span>
<span class="line-added">1140   }</span>
<span class="line-added">1141   // verify the control flow is ok</span>
<span class="line-added">1142   Node* c = ctl;</span>
<span class="line-added">1143   Node* copy = NULL;</span>
<span class="line-added">1144   Node* alloc = NULL;</span>
<span class="line-added">1145   for (;;) {</span>
<span class="line-added">1146     if (c == NULL || c-&gt;is_top()) {</span>
<span class="line-added">1147       return false;</span>
<span class="line-added">1148     }</span>
<span class="line-added">1149     if (c-&gt;is_Proj() || c-&gt;is_Catch() || c-&gt;is_MemBar()) {</span>
<span class="line-added">1150       c = c-&gt;in(0);</span>
<span class="line-added">1151     } else if (c-&gt;Opcode() == Op_CallLeaf &amp;&amp;</span>
<span class="line-added">1152                c-&gt;as_Call()-&gt;entry_point() == CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_value)) {</span>
<span class="line-added">1153       copy = c;</span>
<span class="line-added">1154       c = c-&gt;in(0);</span>
<span class="line-added">1155     } else if (c-&gt;is_Allocate()) {</span>
<span class="line-added">1156       Node* new_obj = c-&gt;as_Allocate()-&gt;result_cast();</span>
<span class="line-added">1157       if (copy == NULL || new_obj == NULL) {</span>
<span class="line-added">1158         return false;</span>
<span class="line-added">1159       }</span>
<span class="line-added">1160       Node* copy_dest = copy-&gt;in(TypeFunc::Parms + 2);</span>
<span class="line-added">1161       if (copy_dest != new_obj) {</span>
<span class="line-added">1162         return false;</span>
<span class="line-added">1163       }</span>
<span class="line-added">1164       alloc = c;</span>
<span class="line-added">1165       break;</span>
<span class="line-added">1166     } else {</span>
<span class="line-added">1167       return false;</span>
<span class="line-added">1168     }</span>
<span class="line-added">1169   }</span>
<span class="line-added">1170 </span>
<span class="line-added">1171   JVMState* jvms = alloc-&gt;jvms();</span>
<span class="line-added">1172   if (phase-&gt;C-&gt;too_many_traps(jvms-&gt;method(), jvms-&gt;bci(), Deoptimization::trap_request_reason(uncommon_trap_request()))) {</span>
<span class="line-added">1173     return false;</span>
<span class="line-added">1174   }</span>
<span class="line-added">1175 </span>
<span class="line-added">1176   Node* alloc_mem = alloc-&gt;in(TypeFunc::Memory);</span>
<span class="line-added">1177   if (alloc_mem == NULL || alloc_mem-&gt;is_top()) {</span>
<span class="line-added">1178     return false;</span>
<span class="line-added">1179   }</span>
<span class="line-added">1180   if (!alloc_mem-&gt;is_MergeMem()) {</span>
<span class="line-added">1181     alloc_mem = MergeMemNode::make(alloc_mem);</span>
<span class="line-added">1182   }</span>
<span class="line-added">1183 </span>
<span class="line-added">1184   // and that there&#39;s no unexpected side effect</span>
<span class="line-added">1185   for (MergeMemStream mms2(mem-&gt;as_MergeMem(), alloc_mem-&gt;as_MergeMem()); mms2.next_non_empty2(); ) {</span>
<span class="line-added">1186     Node* m1 = mms2.is_empty() ? mms2.base_memory() : mms2.memory();</span>
<span class="line-added">1187     Node* m2 = mms2.memory2();</span>
<span class="line-added">1188 </span>
<span class="line-added">1189     for (uint i = 0; i &lt; 100; i++) {</span>
<span class="line-added">1190       if (m1 == m2) {</span>
<span class="line-added">1191         break;</span>
<span class="line-added">1192       } else if (m1-&gt;is_Proj()) {</span>
<span class="line-added">1193         m1 = m1-&gt;in(0);</span>
<span class="line-added">1194       } else if (m1-&gt;is_MemBar()) {</span>
<span class="line-added">1195         m1 = m1-&gt;in(TypeFunc::Memory);</span>
<span class="line-added">1196       } else if (m1-&gt;Opcode() == Op_CallLeaf &amp;&amp;</span>
<span class="line-added">1197                  m1-&gt;as_Call()-&gt;entry_point() == CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_value)) {</span>
<span class="line-added">1198         if (m1 != copy) {</span>
<span class="line-added">1199           return false;</span>
<span class="line-added">1200         }</span>
<span class="line-added">1201         m1 = m1-&gt;in(TypeFunc::Memory);</span>
<span class="line-added">1202       } else if (m1-&gt;is_Allocate()) {</span>
<span class="line-added">1203         if (m1 != alloc) {</span>
<span class="line-added">1204           return false;</span>
<span class="line-added">1205         }</span>
<span class="line-added">1206         break;</span>
<span class="line-added">1207       } else if (m1-&gt;is_MergeMem()) {</span>
<span class="line-added">1208         MergeMemNode* mm = m1-&gt;as_MergeMem();</span>
<span class="line-added">1209         int idx = mms2.alias_idx();</span>
<span class="line-added">1210         if (idx == Compile::AliasIdxBot) {</span>
<span class="line-added">1211           m1 = mm-&gt;base_memory();</span>
<span class="line-added">1212         } else {</span>
<span class="line-added">1213           m1 = mm-&gt;memory_at(idx);</span>
<span class="line-added">1214         }</span>
<span class="line-added">1215       } else {</span>
<span class="line-added">1216         return false;</span>
<span class="line-added">1217       }</span>
<span class="line-added">1218     }</span>
<span class="line-added">1219   }</span>
<span class="line-added">1220   if (alloc_mem-&gt;outcnt() == 0) {</span>
<span class="line-added">1221     igvn-&gt;remove_dead_node(alloc_mem);</span>
<span class="line-added">1222   }</span>
<span class="line-added">1223 </span>
<span class="line-added">1224   address call_addr = SharedRuntime::uncommon_trap_blob()-&gt;entry_point();</span>
<span class="line-added">1225   CallNode* unc = new CallStaticJavaNode(OptoRuntime::uncommon_trap_Type(), call_addr, &quot;uncommon_trap&quot;,</span>
<span class="line-added">1226                                          jvms-&gt;bci(), NULL);</span>
<span class="line-added">1227   unc-&gt;init_req(TypeFunc::Control, alloc-&gt;in(0));</span>
<span class="line-added">1228   unc-&gt;init_req(TypeFunc::I_O, alloc-&gt;in(TypeFunc::I_O));</span>
<span class="line-added">1229   unc-&gt;init_req(TypeFunc::Memory, alloc-&gt;in(TypeFunc::Memory));</span>
<span class="line-added">1230   unc-&gt;init_req(TypeFunc::FramePtr,  alloc-&gt;in(TypeFunc::FramePtr));</span>
<span class="line-added">1231   unc-&gt;init_req(TypeFunc::ReturnAdr, alloc-&gt;in(TypeFunc::ReturnAdr));</span>
<span class="line-added">1232   unc-&gt;init_req(TypeFunc::Parms+0, unc_arg);</span>
<span class="line-added">1233   unc-&gt;set_cnt(PROB_UNLIKELY_MAG(4));</span>
<span class="line-added">1234   unc-&gt;copy_call_debug_info(igvn, alloc-&gt;as_Allocate());</span>
<span class="line-added">1235 </span>
<span class="line-added">1236   igvn-&gt;replace_input_of(alloc, 0, phase-&gt;C-&gt;top());</span>
<span class="line-added">1237 </span>
<span class="line-added">1238   igvn-&gt;register_new_node_with_optimizer(unc);</span>
<span class="line-added">1239 </span>
<span class="line-added">1240   Node* ctrl = phase-&gt;transform(new ProjNode(unc, TypeFunc::Control));</span>
<span class="line-added">1241   Node* halt = phase-&gt;transform(new HaltNode(ctrl, alloc-&gt;in(TypeFunc::FramePtr), &quot;uncommon trap returned which should never happen&quot;));</span>
<span class="line-added">1242   phase-&gt;C-&gt;root()-&gt;add_req(halt);</span>
<span class="line-added">1243 </span>
<span class="line-added">1244   return true;</span>
<span class="line-added">1245 }</span>
<span class="line-added">1246 </span>
<span class="line-added">1247 </span>
<span class="line-added">1248 Node* CallStaticJavaNode::Ideal(PhaseGVN *phase, bool can_reshape) {</span>
<span class="line-added">1249   if (can_reshape &amp;&amp; uncommon_trap_request() != 0) {</span>
<span class="line-added">1250     if (remove_useless_allocation(phase, in(0), in(TypeFunc::Memory), in(TypeFunc::Parms))) {</span>
<span class="line-added">1251       if (!in(0)-&gt;is_Region()) {</span>
<span class="line-added">1252         PhaseIterGVN* igvn = phase-&gt;is_IterGVN();</span>
<span class="line-added">1253         igvn-&gt;replace_input_of(this, 0, phase-&gt;C-&gt;top());</span>
<span class="line-added">1254       }</span>
<span class="line-added">1255       return this;</span>
<span class="line-added">1256     }</span>
<span class="line-added">1257   }</span>
<span class="line-added">1258   return CallNode::Ideal(phase, can_reshape);</span>
<span class="line-added">1259 }</span>
<span class="line-added">1260 </span>
<span class="line-added">1261 </span>
1262 #ifndef PRODUCT
1263 void CallStaticJavaNode::dump_spec(outputStream *st) const {
1264   st-&gt;print(&quot;# Static &quot;);
1265   if (_name != NULL) {
1266     st-&gt;print(&quot;%s&quot;, _name);
1267     int trap_req = uncommon_trap_request();
1268     if (trap_req != 0) {
1269       char buf[100];
1270       st-&gt;print(&quot;(%s)&quot;,
1271                  Deoptimization::format_trap_request(buf, sizeof(buf),
1272                                                      trap_req));
1273     }
1274     st-&gt;print(&quot; &quot;);
1275   }
1276   CallJavaNode::dump_spec(st);
1277 }
1278 
1279 void CallStaticJavaNode::dump_compact_spec(outputStream* st) const {
1280   if (_method) {
1281     _method-&gt;print_short_name(st);
</pre>
<hr />
<pre>
1299   CallJavaNode::dump_spec(st);
1300 }
1301 #endif
1302 
1303 //=============================================================================
1304 uint CallRuntimeNode::size_of() const { return sizeof(*this); }
1305 bool CallRuntimeNode::cmp( const Node &amp;n ) const {
1306   CallRuntimeNode &amp;call = (CallRuntimeNode&amp;)n;
1307   return CallNode::cmp(call) &amp;&amp; !strcmp(_name,call._name);
1308 }
1309 #ifndef PRODUCT
1310 void CallRuntimeNode::dump_spec(outputStream *st) const {
1311   st-&gt;print(&quot;# &quot;);
1312   st-&gt;print(&quot;%s&quot;, _name);
1313   CallNode::dump_spec(st);
1314 }
1315 #endif
1316 
1317 //------------------------------calling_convention-----------------------------
1318 void CallRuntimeNode::calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const {
<span class="line-added">1319   if (_entry_point == NULL) {</span>
<span class="line-added">1320     // The call to that stub is a special case: its inputs are</span>
<span class="line-added">1321     // multiple values returned from a call and so it should follow</span>
<span class="line-added">1322     // the return convention.</span>
<span class="line-added">1323     SharedRuntime::java_return_convention(sig_bt, parm_regs, argcnt);</span>
<span class="line-added">1324     return;</span>
<span class="line-added">1325   }</span>
1326   Matcher::c_calling_convention( sig_bt, parm_regs, argcnt );
1327 }
1328 
1329 //=============================================================================
1330 //------------------------------calling_convention-----------------------------
1331 
1332 
1333 //=============================================================================
1334 #ifndef PRODUCT
1335 void CallLeafNode::dump_spec(outputStream *st) const {
1336   st-&gt;print(&quot;# &quot;);
1337   st-&gt;print(&quot;%s&quot;, _name);
1338   CallNode::dump_spec(st);
1339 }
1340 #endif
1341 
<span class="line-added">1342 uint CallLeafNoFPNode::match_edge(uint idx) const {</span>
<span class="line-added">1343   // Null entry point is a special case for which the target is in a</span>
<span class="line-added">1344   // register. Need to match that edge.</span>
<span class="line-added">1345   return entry_point() == NULL &amp;&amp; idx == TypeFunc::Parms;</span>
<span class="line-added">1346 }</span>
<span class="line-added">1347 </span>
1348 //=============================================================================
1349 
1350 void SafePointNode::set_local(JVMState* jvms, uint idx, Node *c) {
1351   assert(verify_jvms(jvms), &quot;jvms must match&quot;);
1352   int loc = jvms-&gt;locoff() + idx;
1353   if (in(loc)-&gt;is_top() &amp;&amp; idx &gt; 0 &amp;&amp; !c-&gt;is_top() ) {
1354     // If current local idx is top then local idx - 1 could
1355     // be a long/double that needs to be killed since top could
1356     // represent the 2nd half ofthe long/double.
1357     uint ideal = in(loc -1)-&gt;ideal_reg();
1358     if (ideal == Op_RegD || ideal == Op_RegL) {
1359       // set other (low index) half to top
1360       set_req(loc - 1, in(loc));
1361     }
1362   }
1363   set_req(loc, c);
1364 }
1365 
1366 uint SafePointNode::size_of() const { return sizeof(*this); }
1367 bool SafePointNode::cmp( const Node &amp;n ) const {
</pre>
<hr />
<pre>
1585   }
1586   SafePointScalarObjectNode* res = (SafePointScalarObjectNode*)Node::clone();
1587   sosn_map-&gt;Insert((void*)this, (void*)res);
1588   return res;
1589 }
1590 
1591 
1592 #ifndef PRODUCT
1593 void SafePointScalarObjectNode::dump_spec(outputStream *st) const {
1594   st-&gt;print(&quot; # fields@[%d..%d]&quot;, first_index(),
1595              first_index() + n_fields() - 1);
1596 }
1597 
1598 #endif
1599 
1600 //=============================================================================
1601 uint AllocateNode::size_of() const { return sizeof(*this); }
1602 
1603 AllocateNode::AllocateNode(Compile* C, const TypeFunc *atype,
1604                            Node *ctrl, Node *mem, Node *abio,
<span class="line-modified">1605                            Node *size, Node *klass_node,</span>
<span class="line-added">1606                            Node* initial_test,</span>
<span class="line-added">1607                            ValueTypeBaseNode* value_node)</span>
1608   : CallNode(atype, NULL, TypeRawPtr::BOTTOM)
1609 {
1610   init_class_id(Class_Allocate);
1611   init_flags(Flag_is_macro);
1612   _is_scalar_replaceable = false;
1613   _is_non_escaping = false;
1614   _is_allocation_MemBar_redundant = false;
<span class="line-added">1615   _larval = false;</span>
1616   Node *topnode = C-&gt;top();
1617 
1618   init_req( TypeFunc::Control  , ctrl );
1619   init_req( TypeFunc::I_O      , abio );
1620   init_req( TypeFunc::Memory   , mem );
1621   init_req( TypeFunc::ReturnAdr, topnode );
1622   init_req( TypeFunc::FramePtr , topnode );
1623   init_req( AllocSize          , size);
1624   init_req( KlassNode          , klass_node);
1625   init_req( InitialTest        , initial_test);
1626   init_req( ALength            , topnode);
<span class="line-added">1627   init_req( ValueNode          , value_node);</span>
<span class="line-added">1628   // DefaultValue defaults to NULL</span>
<span class="line-added">1629   // RawDefaultValue defaults to NULL</span>
<span class="line-added">1630   // StorageProperties defaults to NULL</span>
1631   C-&gt;add_macro_node(this);
1632 }
1633 
1634 void AllocateNode::compute_MemBar_redundancy(ciMethod* initializer)
1635 {
1636   assert(initializer != NULL &amp;&amp;
<span class="line-modified">1637          initializer-&gt;is_object_constructor_or_class_initializer(),</span>
<span class="line-modified">1638          &quot;unexpected initializer method&quot;);</span>

1639   BCEscapeAnalyzer* analyzer = initializer-&gt;get_bcea();
1640   if (analyzer == NULL) {
1641     return;
1642   }
1643 
1644   // Allocation node is first parameter in its initializer
1645   if (analyzer-&gt;is_arg_stack(0) || analyzer-&gt;is_arg_local(0)) {
1646     _is_allocation_MemBar_redundant = true;
1647   }
1648 }
<span class="line-modified">1649 </span>
<span class="line-added">1650 Node* AllocateNode::Ideal(PhaseGVN* phase, bool can_reshape) {</span>
<span class="line-added">1651   // Check for unused value type allocation</span>
<span class="line-added">1652   if (can_reshape &amp;&amp; in(AllocateNode::ValueNode) != NULL &amp;&amp;</span>
<span class="line-added">1653       outcnt() != 0 &amp;&amp; result_cast() == NULL) {</span>
<span class="line-added">1654     // Remove allocation by replacing the projection nodes with its inputs</span>
<span class="line-added">1655     InitializeNode* init = initialization();</span>
<span class="line-added">1656     PhaseIterGVN* igvn = phase-&gt;is_IterGVN();</span>
<span class="line-added">1657     CallProjections* projs = extract_projections(true, false);</span>
<span class="line-added">1658     assert(projs-&gt;nb_resproj &lt;= 1, &quot;unexpected number of results&quot;);</span>
<span class="line-added">1659     if (projs-&gt;fallthrough_catchproj != NULL) {</span>
<span class="line-added">1660       igvn-&gt;replace_node(projs-&gt;fallthrough_catchproj, in(TypeFunc::Control));</span>
<span class="line-added">1661     }</span>
<span class="line-added">1662     if (projs-&gt;fallthrough_memproj != NULL) {</span>
<span class="line-added">1663       igvn-&gt;replace_node(projs-&gt;fallthrough_memproj, in(TypeFunc::Memory));</span>
<span class="line-added">1664     }</span>
<span class="line-added">1665     if (projs-&gt;catchall_memproj != NULL) {</span>
<span class="line-added">1666       igvn-&gt;replace_node(projs-&gt;catchall_memproj, phase-&gt;C-&gt;top());</span>
<span class="line-added">1667     }</span>
<span class="line-added">1668     if (projs-&gt;fallthrough_ioproj != NULL) {</span>
<span class="line-added">1669       igvn-&gt;replace_node(projs-&gt;fallthrough_ioproj, in(TypeFunc::I_O));</span>
<span class="line-added">1670     }</span>
<span class="line-added">1671     if (projs-&gt;catchall_ioproj != NULL) {</span>
<span class="line-added">1672       igvn-&gt;replace_node(projs-&gt;catchall_ioproj, phase-&gt;C-&gt;top());</span>
<span class="line-added">1673     }</span>
<span class="line-added">1674     if (projs-&gt;catchall_catchproj != NULL) {</span>
<span class="line-added">1675       igvn-&gt;replace_node(projs-&gt;catchall_catchproj, phase-&gt;C-&gt;top());</span>
<span class="line-added">1676     }</span>
<span class="line-added">1677     if (projs-&gt;resproj[0] != NULL) {</span>
<span class="line-added">1678       // Remove MemBarStoreStore user as well</span>
<span class="line-added">1679       for (DUIterator_Fast imax, i = projs-&gt;resproj[0]-&gt;fast_outs(imax); i &lt; imax; i++) {</span>
<span class="line-added">1680         MemBarStoreStoreNode* mb = projs-&gt;resproj[0]-&gt;fast_out(i)-&gt;isa_MemBarStoreStore();</span>
<span class="line-added">1681         if (mb != NULL &amp;&amp; mb-&gt;outcnt() == 2) {</span>
<span class="line-added">1682           mb-&gt;remove(igvn);</span>
<span class="line-added">1683           --i; --imax;</span>
<span class="line-added">1684         }</span>
<span class="line-added">1685       }</span>
<span class="line-added">1686       igvn-&gt;replace_node(projs-&gt;resproj[0], phase-&gt;C-&gt;top());</span>
<span class="line-added">1687     }</span>
<span class="line-added">1688     igvn-&gt;replace_node(this, phase-&gt;C-&gt;top());</span>
<span class="line-added">1689     if (init != NULL) {</span>
<span class="line-added">1690       Node* ctrl_proj = init-&gt;proj_out_or_null(TypeFunc::Control);</span>
<span class="line-added">1691       Node* mem_proj = init-&gt;proj_out_or_null(TypeFunc::Memory);</span>
<span class="line-added">1692       if (ctrl_proj != NULL) {</span>
<span class="line-added">1693         igvn-&gt;replace_node(ctrl_proj, init-&gt;in(TypeFunc::Control));</span>
<span class="line-added">1694       }</span>
<span class="line-added">1695       if (mem_proj != NULL) {</span>
<span class="line-added">1696         igvn-&gt;replace_node(mem_proj, init-&gt;in(TypeFunc::Memory));</span>
<span class="line-added">1697       }</span>
<span class="line-added">1698     }</span>
<span class="line-added">1699     return NULL;</span>
<span class="line-added">1700   }</span>
<span class="line-added">1701 </span>
<span class="line-added">1702   return CallNode::Ideal(phase, can_reshape);</span>
<span class="line-added">1703 }</span>
<span class="line-added">1704 </span>
<span class="line-added">1705 Node* AllocateNode::make_ideal_mark(PhaseGVN* phase, Node* control, Node* mem) {</span>
1706   Node* mark_node = NULL;
1707   // For now only enable fast locking for non-array types
<span class="line-modified">1708   if ((EnableValhalla || UseBiasedLocking) &amp;&amp; Opcode() == Op_Allocate) {</span>
1709     Node* klass_node = in(AllocateNode::KlassNode);
1710     Node* proto_adr = phase-&gt;transform(new AddPNode(klass_node, klass_node, phase-&gt;MakeConX(in_bytes(Klass::prototype_header_offset()))));
1711     mark_node = LoadNode::make(*phase, control, mem, proto_adr, TypeRawPtr::BOTTOM, TypeX_X, TypeX_X-&gt;basic_type(), MemNode::unordered);
1712   } else {
1713     mark_node = phase-&gt;MakeConX(markWord::prototype().value());
1714   }
<span class="line-modified">1715   mark_node = phase-&gt;transform(mark_node);</span>
<span class="line-added">1716   // Avoid returning a constant (old node) here because this method is used by LoadNode::Ideal</span>
<span class="line-added">1717   return new OrXNode(mark_node, phase-&gt;MakeConX(_larval ? markWord::larval_state_pattern : 0));</span>
1718 }
1719 
<span class="line-added">1720 </span>
1721 //=============================================================================
1722 Node* AllocateArrayNode::Ideal(PhaseGVN *phase, bool can_reshape) {
<span class="line-modified">1723   Node* res = SafePointNode::Ideal(phase, can_reshape);</span>
<span class="line-added">1724   if (res != NULL) {</span>
<span class="line-added">1725     return res;</span>
<span class="line-added">1726   }</span>
1727   // Don&#39;t bother trying to transform a dead node
1728   if (in(0) &amp;&amp; in(0)-&gt;is_top())  return NULL;
1729 
1730   const Type* type = phase-&gt;type(Ideal_length());
1731   if (type-&gt;isa_int() &amp;&amp; type-&gt;is_int()-&gt;_hi &lt; 0) {
1732     if (can_reshape) {
1733       PhaseIterGVN *igvn = phase-&gt;is_IterGVN();
1734       // Unreachable fall through path (negative array length),
1735       // the allocation can only throw so disconnect it.
1736       Node* proj = proj_out_or_null(TypeFunc::Control);
1737       Node* catchproj = NULL;
1738       if (proj != NULL) {
1739         for (DUIterator_Fast imax, i = proj-&gt;fast_outs(imax); i &lt; imax; i++) {
1740           Node *cn = proj-&gt;fast_out(i);
1741           if (cn-&gt;is_Catch()) {
1742             catchproj = cn-&gt;as_Multi()-&gt;proj_out_or_null(CatchProjNode::fall_through_index);
1743             break;
1744           }
1745         }
1746       }
</pre>
<hr />
<pre>
2131       this-&gt;collect_nodes_in_all_data(in_rel, true);
2132     }
2133     this-&gt;collect_nodes(out_rel, -2, false, false);
2134 }
2135 #endif
2136 
2137 //=============================================================================
2138 Node *LockNode::Ideal(PhaseGVN *phase, bool can_reshape) {
2139 
2140   // perform any generic optimizations first (returns &#39;this&#39; or NULL)
2141   Node *result = SafePointNode::Ideal(phase, can_reshape);
2142   if (result != NULL)  return result;
2143   // Don&#39;t bother trying to transform a dead node
2144   if (in(0) &amp;&amp; in(0)-&gt;is_top())  return NULL;
2145 
2146   // Now see if we can optimize away this lock.  We don&#39;t actually
2147   // remove the locking here, we simply set the _eliminate flag which
2148   // prevents macro expansion from expanding the lock.  Since we don&#39;t
2149   // modify the graph, the value returned from this function is the
2150   // one computed above.
<span class="line-modified">2151   const Type* obj_type = phase-&gt;type(obj_node());</span>
<span class="line-added">2152   if (can_reshape &amp;&amp; EliminateLocks &amp;&amp; !is_non_esc_obj() &amp;&amp;</span>
<span class="line-added">2153       !obj_type-&gt;isa_valuetype() &amp;&amp; !obj_type-&gt;is_valuetypeptr()) {</span>
2154     //
2155     // If we are locking an unescaped object, the lock/unlock is unnecessary
2156     //
2157     ConnectionGraph *cgr = phase-&gt;C-&gt;congraph();
2158     if (cgr != NULL &amp;&amp; cgr-&gt;not_global_escape(obj_node())) {
2159       assert(!is_eliminated() || is_coarsened(), &quot;sanity&quot;);
2160       // The lock could be marked eliminated by lock coarsening
2161       // code during first IGVN before EA. Replace coarsened flag
2162       // to eliminate all associated locks/unlocks.
2163 #ifdef ASSERT
2164       this-&gt;log_lock_optimization(phase-&gt;C,&quot;eliminate_lock_set_non_esc1&quot;);
2165 #endif
2166       this-&gt;set_non_esc_obj();
2167       return result;
2168     }
2169 
2170     //
2171     // Try lock coarsening
2172     //
2173     PhaseIterGVN* iter = phase-&gt;is_IterGVN();
</pre>
<hr />
<pre>
2301 }
2302 
2303 //=============================================================================
2304 uint UnlockNode::size_of() const { return sizeof(*this); }
2305 
2306 //=============================================================================
2307 Node *UnlockNode::Ideal(PhaseGVN *phase, bool can_reshape) {
2308 
2309   // perform any generic optimizations first (returns &#39;this&#39; or NULL)
2310   Node *result = SafePointNode::Ideal(phase, can_reshape);
2311   if (result != NULL)  return result;
2312   // Don&#39;t bother trying to transform a dead node
2313   if (in(0) &amp;&amp; in(0)-&gt;is_top())  return NULL;
2314 
2315   // Now see if we can optimize away this unlock.  We don&#39;t actually
2316   // remove the unlocking here, we simply set the _eliminate flag which
2317   // prevents macro expansion from expanding the unlock.  Since we don&#39;t
2318   // modify the graph, the value returned from this function is the
2319   // one computed above.
2320   // Escape state is defined after Parse phase.
<span class="line-modified">2321   const Type* obj_type = phase-&gt;type(obj_node());</span>
<span class="line-added">2322   if (can_reshape &amp;&amp; EliminateLocks &amp;&amp; !is_non_esc_obj() &amp;&amp;</span>
<span class="line-added">2323       !obj_type-&gt;isa_valuetype() &amp;&amp; !obj_type-&gt;is_valuetypeptr()) {</span>
2324     //
2325     // If we are unlocking an unescaped object, the lock/unlock is unnecessary.
2326     //
2327     ConnectionGraph *cgr = phase-&gt;C-&gt;congraph();
2328     if (cgr != NULL &amp;&amp; cgr-&gt;not_global_escape(obj_node())) {
2329       assert(!is_eliminated() || is_coarsened(), &quot;sanity&quot;);
2330       // The lock could be marked eliminated by lock coarsening
2331       // code during first IGVN before EA. Replace coarsened flag
2332       // to eliminate all associated locks/unlocks.
2333 #ifdef ASSERT
2334       this-&gt;log_lock_optimization(phase-&gt;C, &quot;eliminate_lock_set_non_esc2&quot;);
2335 #endif
2336       this-&gt;set_non_esc_obj();
2337     }
2338   }
2339   return result;
2340 }
2341 
2342 const char * AbstractLockNode::kind_as_string() const {
2343   return is_coarsened()   ? &quot;coarsened&quot; :
</pre>
<hr />
<pre>
2385     }
2386     // unrelated
2387     return false;
2388   }
2389 
2390   if (dest_t-&gt;isa_aryptr()) {
2391     // arraycopy or array clone
2392     if (t_oop-&gt;isa_instptr()) {
2393       return false;
2394     }
2395     if (!t_oop-&gt;isa_aryptr()) {
2396       return true;
2397     }
2398 
2399     const Type* elem = dest_t-&gt;is_aryptr()-&gt;elem();
2400     if (elem == Type::BOTTOM) {
2401       // An array but we don&#39;t know what elements are
2402       return true;
2403     }
2404 
<span class="line-modified">2405     dest_t = dest_t-&gt;is_aryptr()-&gt;with_field_offset(Type::OffsetBot)-&gt;add_offset(Type::OffsetBot)-&gt;is_oopptr();</span>
<span class="line-added">2406     t_oop = t_oop-&gt;is_aryptr()-&gt;with_field_offset(Type::OffsetBot);</span>
2407     uint dest_alias = phase-&gt;C-&gt;get_alias_index(dest_t);
2408     uint t_oop_alias = phase-&gt;C-&gt;get_alias_index(t_oop);
2409 
2410     return dest_alias == t_oop_alias;
2411   }
2412 
2413   return true;
2414 }
</pre>
</td>
</tr>
</table>
<center><a href="c2_globals.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="classes.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>