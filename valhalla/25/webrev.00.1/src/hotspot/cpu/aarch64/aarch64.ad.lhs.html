<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on, compressed klass
 1101     // pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   if (UseBarriersForVolatile) {
 1371     // we need to plant a dmb
 1372     return false;
 1373   }
 1374 
 1375   MemBarNode* mb = barrier-&gt;as_MemBar();
 1376 
 1377   if (mb-&gt;trailing_load()) {
 1378     return true;
 1379   }
 1380 
 1381   if (mb-&gt;trailing_load_store()) {
 1382     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1383     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1384     return is_CAS(load_store-&gt;Opcode(), true);
 1385   }
 1386 
 1387   return false;
 1388 }
 1389 
 1390 bool needs_acquiring_load(const Node *n)
 1391 {
 1392   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1393   if (UseBarriersForVolatile) {
 1394     // we use a normal load and a dmb
 1395     return false;
 1396   }
 1397 
 1398   LoadNode *ld = n-&gt;as_Load();
 1399 
 1400   return ld-&gt;is_acquire();
 1401 }
 1402 
 1403 bool unnecessary_release(const Node *n)
 1404 {
 1405   assert((n-&gt;is_MemBar() &amp;&amp;
 1406 	  n-&gt;Opcode() == Op_MemBarRelease),
 1407 	 &quot;expecting a release membar&quot;);
 1408 
 1409   if (UseBarriersForVolatile) {
 1410     // we need to plant a dmb
 1411     return false;
 1412   }
 1413 
 1414   MemBarNode *barrier = n-&gt;as_MemBar();
 1415   if (!barrier-&gt;leading()) {
 1416     return false;
 1417   } else {
 1418     Node* trailing = barrier-&gt;trailing_membar();
 1419     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1420     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1421     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1422 
 1423     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1424     if (mem-&gt;is_Store()) {
 1425       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1426       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1427       return true;
 1428     } else {
 1429       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1430       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1431       return is_CAS(mem-&gt;Opcode(), true);
 1432     }
 1433   }
 1434   return false;
 1435 }
 1436 
 1437 bool unnecessary_volatile(const Node *n)
 1438 {
 1439   // assert n-&gt;is_MemBar();
 1440   if (UseBarriersForVolatile) {
 1441     // we need to plant a dmb
 1442     return false;
 1443   }
 1444 
 1445   MemBarNode *mbvol = n-&gt;as_MemBar();
 1446 
 1447   bool release = mbvol-&gt;trailing_store();
 1448   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1449 #ifdef ASSERT
 1450   if (release) {
 1451     Node* leading = mbvol-&gt;leading_membar();
 1452     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1453     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1454     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1455   }
 1456 #endif
 1457 
 1458   return release;
 1459 }
 1460 
 1461 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1462 
 1463 bool needs_releasing_store(const Node *n)
 1464 {
 1465   // assert n-&gt;is_Store();
 1466   if (UseBarriersForVolatile) {
 1467     // we use a normal store and dmb combination
 1468     return false;
 1469   }
 1470 
 1471   StoreNode *st = n-&gt;as_Store();
 1472 
 1473   return st-&gt;trailing_membar() != NULL;
 1474 }
 1475 
 1476 // predicate controlling translation of CAS
 1477 //
 1478 // returns true if CAS needs to use an acquiring load otherwise false
 1479 
 1480 bool needs_acquiring_load_exclusive(const Node *n)
 1481 {
 1482   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1483   if (UseBarriersForVolatile) {
 1484     return false;
 1485   }
 1486 
 1487   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1488   if (is_CAS(n-&gt;Opcode(), false)) {
 1489     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1490   } else {
 1491     return ldst-&gt;trailing_membar() != NULL;
 1492   }
 1493 
 1494   // so we can just return true here
 1495   return true;
 1496 }
 1497 
 1498 #define __ _masm.
 1499 
 1500 // advance declarations for helper functions to convert register
 1501 // indices to register objects
 1502 
 1503 // the ad file has to provide implementations of certain methods
 1504 // expected by the generic code
 1505 //
 1506 // REQUIRED FUNCTIONALITY
 1507 
 1508 //=============================================================================
 1509 
 1510 // !!!!! Special hack to get all types of calls to specify the byte offset
 1511 //       from the start of the call to the point where the return address
 1512 //       will point.
 1513 
 1514 int MachCallStaticJavaNode::ret_addr_offset()
 1515 {
 1516   // call should be a simple bl
 1517   int off = 4;
 1518   return off;
 1519 }
 1520 
 1521 int MachCallDynamicJavaNode::ret_addr_offset()
 1522 {
 1523   return 16; // movz, movk, movk, bl
 1524 }
 1525 
 1526 int MachCallRuntimeNode::ret_addr_offset() {
 1527   // for generated stubs the call will be
 1528   //   far_call(addr)
 1529   // for real runtime callouts it will be six instructions
 1530   // see aarch64_enc_java_to_runtime
 1531   //   adr(rscratch2, retaddr)
 1532   //   lea(rscratch1, RuntimeAddress(addr)
 1533   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1534   //   blr(rscratch1)
 1535   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1536   if (cb) {
 1537     return MacroAssembler::far_branch_size();
 1538   } else {
 1539     return 6 * NativeInstruction::instruction_size;
 1540   }
 1541 }
 1542 
 1543 // Indicate if the safepoint node needs the polling page as an input
 1544 
 1545 // the shared code plants the oop data at the start of the generated
 1546 // code for the safepoint node and that needs ot be at the load
 1547 // instruction itself. so we cannot plant a mov of the safepoint poll
 1548 // address followed by a load. setting this to true means the mov is
 1549 // scheduled as a prior instruction. that&#39;s better for scheduling
 1550 // anyway.
 1551 
 1552 bool SafePointNode::needs_polling_address_input()
 1553 {
 1554   return true;
 1555 }
 1556 
 1557 //=============================================================================
 1558 
 1559 #ifndef PRODUCT
 1560 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1561   st-&gt;print(&quot;BREAKPOINT&quot;);
 1562 }
 1563 #endif
 1564 
 1565 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1566   C2_MacroAssembler _masm(&amp;cbuf);
 1567   __ brk(0);
 1568 }
 1569 
 1570 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1571   return MachNode::size(ra_);
 1572 }
 1573 
 1574 //=============================================================================
 1575 
 1576 #ifndef PRODUCT
 1577   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1578     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1579   }
 1580 #endif
 1581 
 1582   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1583     C2_MacroAssembler _masm(&amp;cbuf);
 1584     for (int i = 0; i &lt; _count; i++) {
 1585       __ nop();
 1586     }
 1587   }
 1588 
 1589   uint MachNopNode::size(PhaseRegAlloc*) const {
 1590     return _count * NativeInstruction::instruction_size;
 1591   }
 1592 
 1593 //=============================================================================
 1594 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1595 
 1596 int ConstantTable::calculate_table_base_offset() const {
 1597   return 0;  // absolute addressing, no offset
 1598 }
 1599 
 1600 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1601 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1602   ShouldNotReachHere();
 1603 }
 1604 
 1605 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1606   // Empty encoding
 1607 }
 1608 
 1609 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1610   return 0;
 1611 }
 1612 
 1613 #ifndef PRODUCT
 1614 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1615   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1616 }
 1617 #endif
 1618 
 1619 #ifndef PRODUCT
 1620 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1621   Compile* C = ra_-&gt;C;
 1622 
 1623   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1624 
 1625   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1626     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1627 
 1628   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1629     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1630     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1631     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1632   } else {
 1633     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1634     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1635     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1636     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1637   }
 1638 }
 1639 #endif
 1640 
 1641 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1642   Compile* C = ra_-&gt;C;
 1643   C2_MacroAssembler _masm(&amp;cbuf);
 1644 
<a name="1" id="anc1"></a><span class="line-modified"> 1645   // n.b. frame size includes space for return pc and rfp</span>
<span class="line-modified"> 1646   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
<span class="line-removed"> 1647   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);</span>
<span class="line-removed"> 1648 </span>
<span class="line-removed"> 1649   // insert a nop at the start of the prolog so we can patch in a</span>
<span class="line-removed"> 1650   // branch if we need to invalidate the method later</span>
<span class="line-removed"> 1651   __ nop();</span>
<span class="line-removed"> 1652 </span>
<span class="line-removed"> 1653   if (C-&gt;clinit_barrier_on_entry()) {</span>
<span class="line-removed"> 1654     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);</span>
<span class="line-removed"> 1655 </span>
<span class="line-removed"> 1656     Label L_skip_barrier;</span>
<span class="line-removed"> 1657 </span>
<span class="line-removed"> 1658     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());</span>
<span class="line-removed"> 1659     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);</span>
<span class="line-removed"> 1660     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));</span>
<span class="line-removed"> 1661     __ bind(L_skip_barrier);</span>
<span class="line-removed"> 1662   }</span>
<span class="line-removed"> 1663 </span>
<span class="line-removed"> 1664   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
<span class="line-removed"> 1665   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)</span>
<span class="line-removed"> 1666     __ generate_stack_overflow_check(bangsize);</span>
<span class="line-removed"> 1667 </span>
<span class="line-removed"> 1668   __ build_frame(framesize);</span>
<span class="line-removed"> 1669 </span>
<span class="line-removed"> 1670   if (VerifyStackAtCalls) {</span>
<span class="line-removed"> 1671     Unimplemented();</span>
<span class="line-removed"> 1672   }</span>
 1673 
 1674   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1675 
 1676   if (C-&gt;has_mach_constant_base_node()) {
 1677     // NOTE: We set the table base offset here because users might be
 1678     // emitted before MachConstantBaseNode.
 1679     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1680     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1681   }
 1682 }
 1683 
 1684 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1685 {
 1686   return MachNode::size(ra_); // too many variables; just compute it
 1687                               // the hard way
 1688 }
 1689 
 1690 int MachPrologNode::reloc() const
 1691 {
 1692   return 0;
 1693 }
 1694 
 1695 //=============================================================================
 1696 
 1697 #ifndef PRODUCT
 1698 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1699   Compile* C = ra_-&gt;C;
 1700   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1701 
 1702   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1703 
 1704   if (framesize == 0) {
 1705     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1706   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1707     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1708     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1709   } else {
 1710     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1711     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1712     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1713   }
 1714 
 1715   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1716     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1717     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1718     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1719   }
 1720 }
 1721 #endif
 1722 
 1723 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1724   Compile* C = ra_-&gt;C;
 1725   C2_MacroAssembler _masm(&amp;cbuf);
 1726   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1727 
 1728   __ remove_frame(framesize);
 1729 
 1730   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1731     __ reserved_stack_check();
 1732   }
 1733 
 1734   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1735     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1736   }
 1737 }
 1738 
 1739 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1740   // Variable size. Determine dynamically.
 1741   return MachNode::size(ra_);
 1742 }
 1743 
 1744 int MachEpilogNode::reloc() const {
 1745   // Return number of relocatable values contained in this instruction.
 1746   return 1; // 1 for polling page.
 1747 }
 1748 
 1749 const Pipeline * MachEpilogNode::pipeline() const {
 1750   return MachNode::pipeline_class();
 1751 }
 1752 
 1753 //=============================================================================
 1754 
 1755 // Figure out which register class each belongs in: rc_int, rc_float or
 1756 // rc_stack.
 1757 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1758 
 1759 static enum RC rc_class(OptoReg::Name reg) {
 1760 
 1761   if (reg == OptoReg::Bad) {
 1762     return rc_bad;
 1763   }
 1764 
 1765   // we have 30 int registers * 2 halves
 1766   // (rscratch1 and rscratch2 are omitted)
 1767   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1768 
 1769   if (reg &lt; slots_of_int_registers) {
 1770     return rc_int;
 1771   }
 1772 
 1773   // we have 32 float register * 4 halves
 1774   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1775     return rc_float;
 1776   }
 1777 
 1778   // Between float regs &amp; stack is the flags regs.
 1779   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1780 
 1781   return rc_stack;
 1782 }
 1783 
 1784 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1785   Compile* C = ra_-&gt;C;
 1786 
 1787   // Get registers to move.
 1788   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1789   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1790   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1791   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1792 
 1793   enum RC src_hi_rc = rc_class(src_hi);
 1794   enum RC src_lo_rc = rc_class(src_lo);
 1795   enum RC dst_hi_rc = rc_class(dst_hi);
 1796   enum RC dst_lo_rc = rc_class(dst_lo);
 1797 
 1798   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1799 
 1800   if (src_hi != OptoReg::Bad) {
 1801     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1802            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1803            &quot;expected aligned-adjacent pairs&quot;);
 1804   }
 1805 
 1806   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1807     return 0;            // Self copy, no move.
 1808   }
 1809 
 1810   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1811               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1812   int src_offset = ra_-&gt;reg2offset(src_lo);
 1813   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1814 
 1815   if (bottom_type()-&gt;isa_vect() != NULL) {
 1816     uint ireg = ideal_reg();
 1817     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1818     if (cbuf) {
 1819       C2_MacroAssembler _masm(cbuf);
 1820       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1821       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1822         // stack-&gt;stack
 1823         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1824         if (ireg == Op_VecD) {
 1825           __ unspill(rscratch1, true, src_offset);
 1826           __ spill(rscratch1, true, dst_offset);
 1827         } else {
 1828           __ spill_copy128(src_offset, dst_offset);
 1829         }
 1830       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1831         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1832                ireg == Op_VecD ? __ T8B : __ T16B,
 1833                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1834       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1835         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1836                        ireg == Op_VecD ? __ D : __ Q,
 1837                        ra_-&gt;reg2offset(dst_lo));
 1838       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1839         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1840                        ireg == Op_VecD ? __ D : __ Q,
 1841                        ra_-&gt;reg2offset(src_lo));
 1842       } else {
 1843         ShouldNotReachHere();
 1844       }
 1845     }
 1846   } else if (cbuf) {
 1847     C2_MacroAssembler _masm(cbuf);
 1848     switch (src_lo_rc) {
 1849     case rc_int:
 1850       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1851         if (is64) {
 1852             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1853                    as_Register(Matcher::_regEncode[src_lo]));
 1854         } else {
 1855             C2_MacroAssembler _masm(cbuf);
 1856             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1857                     as_Register(Matcher::_regEncode[src_lo]));
 1858         }
 1859       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1860         if (is64) {
 1861             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1862                      as_Register(Matcher::_regEncode[src_lo]));
 1863         } else {
 1864             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1865                      as_Register(Matcher::_regEncode[src_lo]));
 1866         }
 1867       } else {                    // gpr --&gt; stack spill
 1868         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1869         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1870       }
 1871       break;
 1872     case rc_float:
 1873       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1874         if (is64) {
 1875             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1876                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1877         } else {
 1878             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1879                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1880         }
 1881       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1882           if (cbuf) {
 1883             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1884                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1885         } else {
 1886             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1887                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1888         }
 1889       } else {                    // fpr --&gt; stack spill
 1890         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1891         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1892                  is64 ? __ D : __ S, dst_offset);
 1893       }
 1894       break;
 1895     case rc_stack:
 1896       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1897         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1898       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1899         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1900                    is64 ? __ D : __ S, src_offset);
 1901       } else {                    // stack --&gt; stack copy
 1902         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1903         __ unspill(rscratch1, is64, src_offset);
 1904         __ spill(rscratch1, is64, dst_offset);
 1905       }
 1906       break;
 1907     default:
 1908       assert(false, &quot;bad rc_class for spill&quot;);
 1909       ShouldNotReachHere();
 1910     }
 1911   }
 1912 
 1913   if (st) {
 1914     st-&gt;print(&quot;spill &quot;);
 1915     if (src_lo_rc == rc_stack) {
 1916       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1917     } else {
 1918       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1919     }
 1920     if (dst_lo_rc == rc_stack) {
 1921       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1922     } else {
 1923       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1924     }
 1925     if (bottom_type()-&gt;isa_vect() != NULL) {
 1926       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1927     } else {
 1928       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1929     }
 1930   }
 1931 
 1932   return 0;
 1933 
 1934 }
 1935 
 1936 #ifndef PRODUCT
 1937 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1938   if (!ra_)
 1939     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1940   else
 1941     implementation(NULL, ra_, false, st);
 1942 }
 1943 #endif
 1944 
 1945 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1946   implementation(&amp;cbuf, ra_, false, NULL);
 1947 }
 1948 
 1949 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1950   return MachNode::size(ra_);
 1951 }
 1952 
 1953 //=============================================================================
 1954 
 1955 #ifndef PRODUCT
 1956 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg = ra_-&gt;get_reg_first(this);
 1959   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1960             Matcher::regName[reg], offset);
 1961 }
 1962 #endif
 1963 
 1964 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1965   C2_MacroAssembler _masm(&amp;cbuf);
 1966 
 1967   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1968   int reg    = ra_-&gt;get_encode(this);
 1969 
 1970   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1971     __ add(as_Register(reg), sp, offset);
 1972   } else {
 1973     ShouldNotReachHere();
 1974   }
 1975 }
 1976 
 1977 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1978   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1979   return 4;
 1980 }
 1981 
<a name="2" id="anc2"></a><span class="line-modified"> 1982 //=============================================================================</span>





































 1983 
<a name="3" id="anc3"></a>
 1984 #ifndef PRODUCT
 1985 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1986 {
 1987   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1988   if (UseCompressedClassPointers) {
 1989     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1990     if (CompressedKlassPointers::shift() != 0) {
 1991       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1992     }
 1993   } else {
 1994    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1995   }
 1996   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1997   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1998 }
 1999 #endif
 2000 
 2001 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2002 {
 2003   // This is the unverified entry point.
 2004   C2_MacroAssembler _masm(&amp;cbuf);
<a name="4" id="anc4"></a>
 2005 
<a name="5" id="anc5"></a>
 2006   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
<a name="6" id="anc6"></a><span class="line-modified"> 2007   Label skip;</span>
 2008   // TODO
 2009   // can we avoid this skip and still use a reloc?
 2010   __ br(Assembler::EQ, skip);
 2011   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2012   __ bind(skip);
 2013 }
 2014 
 2015 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2016 {
 2017   return MachNode::size(ra_);
 2018 }
 2019 
 2020 // REQUIRED EMIT CODE
 2021 
 2022 //=============================================================================
 2023 
 2024 // Emit exception handler code.
 2025 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2026 {
 2027   // mov rscratch1 #exception_blob_entry_point
 2028   // br rscratch1
 2029   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2030   // That&#39;s why we must use the macroassembler to generate a handler.
 2031   C2_MacroAssembler _masm(&amp;cbuf);
 2032   address base = __ start_a_stub(size_exception_handler());
 2033   if (base == NULL) {
 2034     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2035     return 0;  // CodeBuffer::expand failed
 2036   }
 2037   int offset = __ offset();
 2038   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2039   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2040   __ end_a_stub();
 2041   return offset;
 2042 }
 2043 
 2044 // Emit deopt handler code.
 2045 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2046 {
 2047   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2048   // That&#39;s why we must use the macroassembler to generate a handler.
 2049   C2_MacroAssembler _masm(&amp;cbuf);
 2050   address base = __ start_a_stub(size_deopt_handler());
 2051   if (base == NULL) {
 2052     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2053     return 0;  // CodeBuffer::expand failed
 2054   }
 2055   int offset = __ offset();
 2056 
 2057   __ adr(lr, __ pc());
 2058   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2059 
 2060   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2061   __ end_a_stub();
 2062   return offset;
 2063 }
 2064 
 2065 // REQUIRED MATCHER CODE
 2066 
 2067 //=============================================================================
 2068 
 2069 const bool Matcher::match_rule_supported(int opcode) {
 2070   if (!has_match_rule(opcode))
 2071     return false;
 2072 
 2073   bool ret_value = true;
 2074   switch (opcode) {
 2075     case Op_CacheWB:
 2076     case Op_CacheWBPreSync:
 2077     case Op_CacheWBPostSync:
 2078       if (!VM_Version::supports_data_cache_line_flush()) {
 2079         ret_value = false;
 2080       }
 2081       break;
 2082   }
 2083 
 2084   return ret_value; // Per default match rules are supported.
 2085 }
 2086 
 2087 // Identify extra cases that we might want to provide match rules for vector nodes and
 2088 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2089 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2090   if (!match_rule_supported(opcode)) {
 2091     return false;
 2092   }
 2093 
 2094   // Special cases which require vector length
 2095   switch (opcode) {
 2096     case Op_MulAddVS2VI: {
 2097       if (vlen != 4) {
 2098         return false;
 2099       }
 2100       break;
 2101     }
 2102   }
 2103 
 2104   return true; // Per default match rules are supported.
 2105 }
 2106 
 2107 const bool Matcher::has_predicated_vectors(void) {
 2108   return false;
 2109 }
 2110 
 2111 const int Matcher::float_pressure(int default_pressure_threshold) {
 2112   return default_pressure_threshold;
 2113 }
 2114 
 2115 int Matcher::regnum_to_fpu_offset(int regnum)
 2116 {
 2117   Unimplemented();
 2118   return 0;
 2119 }
 2120 
 2121 // Is this branch offset short enough that a short branch can be used?
 2122 //
 2123 // NOTE: If the platform does not provide any short branch variants, then
 2124 //       this method should return false for offset 0.
 2125 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2126   // The passed offset is relative to address of the branch.
 2127 
 2128   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2129 }
 2130 
 2131 const bool Matcher::isSimpleConstant64(jlong value) {
 2132   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2133   // Probably always true, even if a temp register is required.
 2134   return true;
 2135 }
 2136 
 2137 // true just means we have fast l2f conversion
 2138 const bool Matcher::convL2FSupported(void) {
 2139   return true;
 2140 }
 2141 
 2142 // Vector width in bytes.
 2143 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2144   int size = MIN2(16,(int)MaxVectorSize);
 2145   // Minimum 2 values in vector
 2146   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2147   // But never &lt; 4
 2148   if (size &lt; 4) size = 0;
 2149   return size;
 2150 }
 2151 
 2152 // Limits on vector size (number of elements) loaded into vector.
 2153 const int Matcher::max_vector_size(const BasicType bt) {
 2154   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2155 }
 2156 const int Matcher::min_vector_size(const BasicType bt) {
 2157 //  For the moment limit the vector size to 8 bytes
 2158     int size = 8 / type2aelembytes(bt);
 2159     if (size &lt; 2) size = 2;
 2160     return size;
 2161 }
 2162 
 2163 // Vector ideal reg.
 2164 const uint Matcher::vector_ideal_reg(int len) {
 2165   switch(len) {
 2166     case  8: return Op_VecD;
 2167     case 16: return Op_VecX;
 2168   }
 2169   ShouldNotReachHere();
 2170   return 0;
 2171 }
 2172 
 2173 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 2174   switch(size) {
 2175     case  8: return Op_VecD;
 2176     case 16: return Op_VecX;
 2177   }
 2178   ShouldNotReachHere();
 2179   return 0;
 2180 }
 2181 
 2182 // AES support not yet implemented
 2183 const bool Matcher::pass_original_key_for_aes() {
 2184   return false;
 2185 }
 2186 
 2187 // aarch64 supports misaligned vectors store/load.
 2188 const bool Matcher::misaligned_vectors_ok() {
 2189   return true;
 2190 }
 2191 
 2192 // false =&gt; size gets scaled to BytesPerLong, ok.
 2193 const bool Matcher::init_array_count_is_in_bytes = false;
 2194 
 2195 // Use conditional move (CMOVL)
 2196 const int Matcher::long_cmove_cost() {
 2197   // long cmoves are no more expensive than int cmoves
 2198   return 0;
 2199 }
 2200 
 2201 const int Matcher::float_cmove_cost() {
 2202   // float cmoves are no more expensive than int cmoves
 2203   return 0;
 2204 }
 2205 
 2206 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2207 const bool Matcher::require_postalloc_expand = false;
 2208 
 2209 // Do we need to mask the count passed to shift instructions or does
 2210 // the cpu only look at the lower 5/6 bits anyway?
 2211 const bool Matcher::need_masked_shift_count = false;
 2212 
 2213 // No support for generic vector operands.
 2214 const bool Matcher::supports_generic_vector_operands  = false;
 2215 
 2216 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2217   ShouldNotReachHere(); // generic vector operands not supported
 2218   return NULL;
 2219 }
 2220 
 2221 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2222   ShouldNotReachHere();  // generic vector operands not supported
 2223   return false;
 2224 }
 2225 
 2226 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2227   ShouldNotReachHere();  // generic vector operands not supported
 2228   return false;
 2229 }
 2230 
 2231 // This affects two different things:
 2232 //  - how Decode nodes are matched
 2233 //  - how ImplicitNullCheck opportunities are recognized
 2234 // If true, the matcher will try to remove all Decodes and match them
 2235 // (as operands) into nodes. NullChecks are not prepared to deal with
 2236 // Decodes by final_graph_reshaping().
 2237 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2238 // for a NullCheck. The matcher matches the Decode node into a register.
 2239 // Implicit_null_check optimization moves the Decode along with the
 2240 // memory operation back up before the NullCheck.
 2241 bool Matcher::narrow_oop_use_complex_address() {
 2242   return CompressedOops::shift() == 0;
 2243 }
 2244 
 2245 bool Matcher::narrow_klass_use_complex_address() {
 2246 // TODO
 2247 // decide whether we need to set this to true
 2248   return false;
 2249 }
 2250 
 2251 bool Matcher::const_oop_prefer_decode() {
 2252   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2253   return CompressedOops::base() == NULL;
 2254 }
 2255 
 2256 bool Matcher::const_klass_prefer_decode() {
 2257   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2258   return CompressedKlassPointers::base() == NULL;
 2259 }
 2260 
 2261 // Is it better to copy float constants, or load them directly from
 2262 // memory?  Intel can load a float constant from a direct address,
 2263 // requiring no extra registers.  Most RISCs will have to materialize
 2264 // an address into a register first, so they would do better to copy
 2265 // the constant from stack.
 2266 const bool Matcher::rematerialize_float_constants = false;
 2267 
 2268 // If CPU can load and store mis-aligned doubles directly then no
 2269 // fixup is needed.  Else we split the double into 2 integer pieces
 2270 // and move it piece-by-piece.  Only happens when passing doubles into
 2271 // C code as the Java calling convention forces doubles to be aligned.
 2272 const bool Matcher::misaligned_doubles_ok = true;
 2273 
 2274 // No-op on amd64
 2275 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2276   Unimplemented();
 2277 }
 2278 
 2279 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2280 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2281 
 2282 // Are floats converted to double when stored to stack during
 2283 // deoptimization?
 2284 bool Matcher::float_in_double() { return false; }
 2285 
 2286 // Do ints take an entire long register or just half?
 2287 // The relevant question is how the int is callee-saved:
 2288 // the whole long is written but de-opt&#39;ing will have to extract
 2289 // the relevant 32 bits.
 2290 const bool Matcher::int_in_long = true;
 2291 
 2292 // Return whether or not this register is ever used as an argument.
 2293 // This function is used on startup to build the trampoline stubs in
 2294 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2295 // call in the trampoline, and arguments in those registers not be
 2296 // available to the callee.
 2297 bool Matcher::can_be_java_arg(int reg)
 2298 {
 2299   return
 2300     reg ==  R0_num || reg == R0_H_num ||
 2301     reg ==  R1_num || reg == R1_H_num ||
 2302     reg ==  R2_num || reg == R2_H_num ||
 2303     reg ==  R3_num || reg == R3_H_num ||
 2304     reg ==  R4_num || reg == R4_H_num ||
 2305     reg ==  R5_num || reg == R5_H_num ||
 2306     reg ==  R6_num || reg == R6_H_num ||
 2307     reg ==  R7_num || reg == R7_H_num ||
 2308     reg ==  V0_num || reg == V0_H_num ||
 2309     reg ==  V1_num || reg == V1_H_num ||
 2310     reg ==  V2_num || reg == V2_H_num ||
 2311     reg ==  V3_num || reg == V3_H_num ||
 2312     reg ==  V4_num || reg == V4_H_num ||
 2313     reg ==  V5_num || reg == V5_H_num ||
 2314     reg ==  V6_num || reg == V6_H_num ||
 2315     reg ==  V7_num || reg == V7_H_num;
 2316 }
 2317 
 2318 bool Matcher::is_spillable_arg(int reg)
 2319 {
 2320   return can_be_java_arg(reg);
 2321 }
 2322 
 2323 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2324   return false;
 2325 }
 2326 
 2327 RegMask Matcher::divI_proj_mask() {
 2328   ShouldNotReachHere();
 2329   return RegMask();
 2330 }
 2331 
 2332 // Register for MODI projection of divmodI.
 2333 RegMask Matcher::modI_proj_mask() {
 2334   ShouldNotReachHere();
 2335   return RegMask();
 2336 }
 2337 
 2338 // Register for DIVL projection of divmodL.
 2339 RegMask Matcher::divL_proj_mask() {
 2340   ShouldNotReachHere();
 2341   return RegMask();
 2342 }
 2343 
 2344 // Register for MODL projection of divmodL.
 2345 RegMask Matcher::modL_proj_mask() {
 2346   ShouldNotReachHere();
 2347   return RegMask();
 2348 }
 2349 
 2350 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2351   return FP_REG_mask();
 2352 }
 2353 
 2354 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2355   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2356     Node* u = addp-&gt;fast_out(i);
 2357     if (u-&gt;is_Mem()) {
 2358       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2359       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2360       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2361         return false;
 2362       }
 2363     }
 2364   }
 2365   return true;
 2366 }
 2367 
 2368 const bool Matcher::convi2l_type_required = false;
 2369 
 2370 // Should the Matcher clone shifts on addressing modes, expecting them
 2371 // to be subsumed into complex addressing expressions or compute them
 2372 // into registers?
 2373 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2374   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2375     return true;
 2376   }
 2377 
 2378   Node *off = m-&gt;in(AddPNode::Offset);
 2379   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2380       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2381       // Are there other uses besides address expressions?
 2382       !is_visited(off)) {
 2383     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2384     mstack.push(off-&gt;in(2), Visit);
 2385     Node *conv = off-&gt;in(1);
 2386     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2387         // Are there other uses besides address expressions?
 2388         !is_visited(conv)) {
 2389       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2390       mstack.push(conv-&gt;in(1), Pre_Visit);
 2391     } else {
 2392       mstack.push(conv, Pre_Visit);
 2393     }
 2394     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2395     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2396     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2397     return true;
 2398   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2399              // Are there other uses besides address expressions?
 2400              !is_visited(off)) {
 2401     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2402     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2403     mstack.push(off-&gt;in(1), Pre_Visit);
 2404     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2405     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2406     return true;
 2407   }
 2408   return false;
 2409 }
 2410 
 2411 void Compile::reshape_address(AddPNode* addp) {
 2412 }
 2413 
<a name="7" id="anc7"></a><span class="line-removed"> 2414 </span>
 2415 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2416   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2417   {                                                                     \
 2418     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2419     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2420     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2421     __ INSN(REG, as_Register(BASE));                                    \
 2422   }
 2423 
 2424 
 2425 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2426   {
 2427     Address::extend scale;
 2428 
 2429     // Hooboy, this is fugly.  We need a way to communicate to the
 2430     // encoder that the index needs to be sign extended, so we have to
 2431     // enumerate all the cases.
 2432     switch (opcode) {
 2433     case INDINDEXSCALEDI2L:
 2434     case INDINDEXSCALEDI2LN:
 2435     case INDINDEXI2L:
 2436     case INDINDEXI2LN:
 2437       scale = Address::sxtw(size);
 2438       break;
 2439     default:
 2440       scale = Address::lsl(size);
 2441     }
 2442 
 2443     if (index == -1) {
 2444       return Address(base, disp);
 2445     } else {
 2446       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2447       return Address(base, as_Register(index), scale);
 2448     }
 2449   }
 2450 
 2451 
 2452 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2453 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2454 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2455 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2456                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2457 
 2458   // Used for all non-volatile memory accesses.  The use of
 2459   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2460   // offsets is something of a kludge.
 2461   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2462                         Register reg, int opcode,
 2463                         Register base, int index, int scale, int disp,
 2464                         int size_in_memory)
 2465   {
 2466     Address addr = mem2address(opcode, base, index, scale, disp);
 2467     if (addr.getMode() == Address::base_plus_offset) {
 2468       /* If we get an out-of-range offset it is a bug in the compiler,
 2469          so we assert here. */
 2470       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2471              &quot;c2 compiler bug&quot;);
 2472       /* Fix up any out-of-range offsets. */
 2473       assert_different_registers(rscratch1, base);
 2474       assert_different_registers(rscratch1, reg);
 2475       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2476     }
 2477     (masm.*insn)(reg, addr);
 2478   }
 2479 
 2480   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2481                         FloatRegister reg, int opcode,
 2482                         Register base, int index, int size, int disp,
 2483                         int size_in_memory)
 2484   {
 2485     Address::extend scale;
 2486 
 2487     switch (opcode) {
 2488     case INDINDEXSCALEDI2L:
 2489     case INDINDEXSCALEDI2LN:
 2490       scale = Address::sxtw(size);
 2491       break;
 2492     default:
 2493       scale = Address::lsl(size);
 2494     }
 2495 
 2496     if (index == -1) {
 2497       /* If we get an out-of-range offset it is a bug in the compiler,
 2498          so we assert here. */
 2499       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2500       /* Fix up any out-of-range offsets. */
 2501       assert_different_registers(rscratch1, base);
 2502       Address addr = Address(base, disp);
 2503       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2504       (masm.*insn)(reg, addr);
 2505     } else {
 2506       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2507       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2508     }
 2509   }
 2510 
 2511   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2512                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2513                         int opcode, Register base, int index, int size, int disp)
 2514   {
 2515     if (index == -1) {
 2516       (masm.*insn)(reg, T, Address(base, disp));
 2517     } else {
 2518       assert(disp == 0, &quot;unsupported address mode&quot;);
 2519       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2520     }
 2521   }
 2522 
 2523 %}
 2524 
 2525 
 2526 
 2527 //----------ENCODING BLOCK-----------------------------------------------------
 2528 // This block specifies the encoding classes used by the compiler to
 2529 // output byte streams.  Encoding classes are parameterized macros
 2530 // used by Machine Instruction Nodes in order to generate the bit
 2531 // encoding of the instruction.  Operands specify their base encoding
 2532 // interface with the interface keyword.  There are currently
 2533 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2534 // COND_INTER.  REG_INTER causes an operand to generate a function
 2535 // which returns its register number when queried.  CONST_INTER causes
 2536 // an operand to generate a function which returns the value of the
 2537 // constant when queried.  MEMORY_INTER causes an operand to generate
 2538 // four functions which return the Base Register, the Index Register,
 2539 // the Scale Value, and the Offset Value of the operand when queried.
 2540 // COND_INTER causes an operand to generate six functions which return
 2541 // the encoding code (ie - encoding bits for the instruction)
 2542 // associated with each basic boolean condition for a conditional
 2543 // instruction.
 2544 //
 2545 // Instructions specify two basic values for encoding.  Again, a
 2546 // function is available to check if the constant displacement is an
 2547 // oop. They use the ins_encode keyword to specify their encoding
 2548 // classes (which must be a sequence of enc_class names, and their
 2549 // parameters, specified in the encoding block), and they use the
 2550 // opcode keyword to specify, in order, their primary, secondary, and
 2551 // tertiary opcode.  Only the opcode sections which a particular
 2552 // instruction needs for encoding need to be specified.
 2553 encode %{
 2554   // Build emit functions for each basic byte or larger field in the
 2555   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2556   // from C++ code in the enc_class source block.  Emit functions will
 2557   // live in the main source block for now.  In future, we can
 2558   // generalize this by adding a syntax that specifies the sizes of
 2559   // fields in an order, so that the adlc can build the emit functions
 2560   // automagically
 2561 
 2562   // catch all for unimplemented encodings
 2563   enc_class enc_unimplemented %{
 2564     C2_MacroAssembler _masm(&amp;cbuf);
 2565     __ unimplemented(&quot;C2 catch all&quot;);
 2566   %}
 2567 
 2568   // BEGIN Non-volatile memory access
 2569 
 2570   // This encoding class is generated automatically from ad_encode.m4.
 2571   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2572   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2573     Register dst_reg = as_Register($dst$$reg);
 2574     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2575                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2576   %}
 2577 
 2578   // This encoding class is generated automatically from ad_encode.m4.
 2579   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2580   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2581     Register dst_reg = as_Register($dst$$reg);
 2582     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2583                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2584   %}
 2585 
 2586   // This encoding class is generated automatically from ad_encode.m4.
 2587   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2588   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2589     Register dst_reg = as_Register($dst$$reg);
 2590     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2591                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2592   %}
 2593 
 2594   // This encoding class is generated automatically from ad_encode.m4.
 2595   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2596   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2597     Register dst_reg = as_Register($dst$$reg);
 2598     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2599                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2600   %}
 2601 
 2602   // This encoding class is generated automatically from ad_encode.m4.
 2603   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2604   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2605     Register dst_reg = as_Register($dst$$reg);
 2606     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2607                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2608   %}
 2609 
 2610   // This encoding class is generated automatically from ad_encode.m4.
 2611   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2612   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2613     Register dst_reg = as_Register($dst$$reg);
 2614     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2615                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2616   %}
 2617 
 2618   // This encoding class is generated automatically from ad_encode.m4.
 2619   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2620   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2621     Register dst_reg = as_Register($dst$$reg);
 2622     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2623                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2624   %}
 2625 
 2626   // This encoding class is generated automatically from ad_encode.m4.
 2627   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2628   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2629     Register dst_reg = as_Register($dst$$reg);
 2630     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2631                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2632   %}
 2633 
 2634   // This encoding class is generated automatically from ad_encode.m4.
 2635   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2636   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2637     Register dst_reg = as_Register($dst$$reg);
 2638     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2639                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2640   %}
 2641 
 2642   // This encoding class is generated automatically from ad_encode.m4.
 2643   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2644   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2645     Register dst_reg = as_Register($dst$$reg);
 2646     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2647                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2648   %}
 2649 
 2650   // This encoding class is generated automatically from ad_encode.m4.
 2651   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2652   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2653     Register dst_reg = as_Register($dst$$reg);
 2654     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2655                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2656   %}
 2657 
 2658   // This encoding class is generated automatically from ad_encode.m4.
 2659   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2660   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2661     Register dst_reg = as_Register($dst$$reg);
 2662     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2663                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2664   %}
 2665 
 2666   // This encoding class is generated automatically from ad_encode.m4.
 2667   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2668   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2669     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2670     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2671                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2672   %}
 2673 
 2674   // This encoding class is generated automatically from ad_encode.m4.
 2675   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2676   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2677     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2678     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2679                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2680   %}
 2681 
 2682   // This encoding class is generated automatically from ad_encode.m4.
 2683   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2684   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2685     Register src_reg = as_Register($src$$reg);
 2686     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2687                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2688   %}
 2689 
 2690   // This encoding class is generated automatically from ad_encode.m4.
 2691   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2692   enc_class aarch64_enc_strb0(memory1 mem) %{
 2693     C2_MacroAssembler _masm(&amp;cbuf);
 2694     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2695                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2696   %}
 2697 
 2698   // This encoding class is generated automatically from ad_encode.m4.
 2699   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2700   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2701     Register src_reg = as_Register($src$$reg);
 2702     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2703                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2704   %}
 2705 
 2706   // This encoding class is generated automatically from ad_encode.m4.
 2707   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2708   enc_class aarch64_enc_strh0(memory2 mem) %{
 2709     C2_MacroAssembler _masm(&amp;cbuf);
 2710     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2711                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2712   %}
 2713 
 2714   // This encoding class is generated automatically from ad_encode.m4.
 2715   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2716   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2717     Register src_reg = as_Register($src$$reg);
 2718     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2719                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2720   %}
 2721 
 2722   // This encoding class is generated automatically from ad_encode.m4.
 2723   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2724   enc_class aarch64_enc_strw0(memory4 mem) %{
 2725     C2_MacroAssembler _masm(&amp;cbuf);
 2726     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2727                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2728   %}
 2729 
 2730   // This encoding class is generated automatically from ad_encode.m4.
 2731   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2732   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2733     Register src_reg = as_Register($src$$reg);
 2734     // we sometimes get asked to store the stack pointer into the
 2735     // current thread -- we cannot do that directly on AArch64
 2736     if (src_reg == r31_sp) {
 2737       C2_MacroAssembler _masm(&amp;cbuf);
 2738       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2739       __ mov(rscratch2, sp);
 2740       src_reg = rscratch2;
 2741     }
 2742     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2743                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2744   %}
 2745 
 2746   // This encoding class is generated automatically from ad_encode.m4.
 2747   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2748   enc_class aarch64_enc_str0(memory8 mem) %{
 2749     C2_MacroAssembler _masm(&amp;cbuf);
 2750     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2751                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2752   %}
 2753 
 2754   // This encoding class is generated automatically from ad_encode.m4.
 2755   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2756   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2757     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2758     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2759                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2760   %}
 2761 
 2762   // This encoding class is generated automatically from ad_encode.m4.
 2763   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2764   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2765     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2766     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2767                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2768   %}
 2769 
 2770   // This encoding class is generated automatically from ad_encode.m4.
 2771   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2772   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2773     C2_MacroAssembler _masm(&amp;cbuf);
 2774     address con = (address)$src$$constant;
 2775     // need to do this the hard way until we can manage relocs
 2776     // for 32 bit constants
 2777     __ movoop(rscratch2, (jobject)con);
 2778     if (con) __ encode_heap_oop_not_null(rscratch2);
 2779     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2780                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2781   %}
 2782 
 2783   // This encoding class is generated automatically from ad_encode.m4.
 2784   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2785   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2786     C2_MacroAssembler _masm(&amp;cbuf);
 2787     address con = (address)$src$$constant;
 2788     // need to do this the hard way until we can manage relocs
 2789     // for 32 bit constants
 2790     __ movoop(rscratch2, (jobject)con);
 2791     __ encode_klass_not_null(rscratch2);
 2792     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2793                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2794   %}
 2795 
 2796   // This encoding class is generated automatically from ad_encode.m4.
 2797   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2798   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2799       C2_MacroAssembler _masm(&amp;cbuf);
 2800       __ membar(Assembler::StoreStore);
 2801       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2802                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2803   %}
 2804 
 2805   // END Non-volatile memory access
 2806 
 2807   // Vector loads and stores
 2808   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2809     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2810     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2811        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2812   %}
 2813 
 2814   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2815     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2816     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2817        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2818   %}
 2819 
 2820   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2821     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2822     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2823        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2824   %}
 2825 
 2826   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2827     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2828     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2829        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2830   %}
 2831 
 2832   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2833     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2834     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2835        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2836   %}
 2837 
 2838   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2839     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2840     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2841        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2842   %}
 2843 
 2844   // volatile loads and stores
 2845 
 2846   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2847     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2848                  rscratch1, stlrb);
 2849   %}
 2850 
 2851   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2852     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2853                  rscratch1, stlrh);
 2854   %}
 2855 
 2856   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2857     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2858                  rscratch1, stlrw);
 2859   %}
 2860 
 2861 
 2862   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2863     Register dst_reg = as_Register($dst$$reg);
 2864     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2865              rscratch1, ldarb);
 2866     __ sxtbw(dst_reg, dst_reg);
 2867   %}
 2868 
 2869   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2870     Register dst_reg = as_Register($dst$$reg);
 2871     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2872              rscratch1, ldarb);
 2873     __ sxtb(dst_reg, dst_reg);
 2874   %}
 2875 
 2876   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2877     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2878              rscratch1, ldarb);
 2879   %}
 2880 
 2881   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2882     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2883              rscratch1, ldarb);
 2884   %}
 2885 
 2886   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2887     Register dst_reg = as_Register($dst$$reg);
 2888     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2889              rscratch1, ldarh);
 2890     __ sxthw(dst_reg, dst_reg);
 2891   %}
 2892 
 2893   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2894     Register dst_reg = as_Register($dst$$reg);
 2895     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2896              rscratch1, ldarh);
 2897     __ sxth(dst_reg, dst_reg);
 2898   %}
 2899 
 2900   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2901     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2902              rscratch1, ldarh);
 2903   %}
 2904 
 2905   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2906     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2907              rscratch1, ldarh);
 2908   %}
 2909 
 2910   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2911     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2912              rscratch1, ldarw);
 2913   %}
 2914 
 2915   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2916     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2917              rscratch1, ldarw);
 2918   %}
 2919 
 2920   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2921     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2922              rscratch1, ldar);
 2923   %}
 2924 
 2925   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2926     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2927              rscratch1, ldarw);
 2928     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2929   %}
 2930 
 2931   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2932     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2933              rscratch1, ldar);
 2934     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2935   %}
 2936 
 2937   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2938     Register src_reg = as_Register($src$$reg);
 2939     // we sometimes get asked to store the stack pointer into the
 2940     // current thread -- we cannot do that directly on AArch64
 2941     if (src_reg == r31_sp) {
 2942       C2_MacroAssembler _masm(&amp;cbuf);
 2943       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2944       __ mov(rscratch2, sp);
 2945       src_reg = rscratch2;
 2946     }
 2947     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2948                  rscratch1, stlr);
 2949   %}
 2950 
 2951   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2952     {
 2953       C2_MacroAssembler _masm(&amp;cbuf);
 2954       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2955       __ fmovs(rscratch2, src_reg);
 2956     }
 2957     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2958                  rscratch1, stlrw);
 2959   %}
 2960 
 2961   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2962     {
 2963       C2_MacroAssembler _masm(&amp;cbuf);
 2964       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2965       __ fmovd(rscratch2, src_reg);
 2966     }
 2967     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2968                  rscratch1, stlr);
 2969   %}
 2970 
 2971   // synchronized read/update encodings
 2972 
 2973   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2974     C2_MacroAssembler _masm(&amp;cbuf);
 2975     Register dst_reg = as_Register($dst$$reg);
 2976     Register base = as_Register($mem$$base);
 2977     int index = $mem$$index;
 2978     int scale = $mem$$scale;
 2979     int disp = $mem$$disp;
 2980     if (index == -1) {
 2981        if (disp != 0) {
 2982         __ lea(rscratch1, Address(base, disp));
 2983         __ ldaxr(dst_reg, rscratch1);
 2984       } else {
 2985         // TODO
 2986         // should we ever get anything other than this case?
 2987         __ ldaxr(dst_reg, base);
 2988       }
 2989     } else {
 2990       Register index_reg = as_Register(index);
 2991       if (disp == 0) {
 2992         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2993         __ ldaxr(dst_reg, rscratch1);
 2994       } else {
 2995         __ lea(rscratch1, Address(base, disp));
 2996         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2997         __ ldaxr(dst_reg, rscratch1);
 2998       }
 2999     }
 3000   %}
 3001 
 3002   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3003     C2_MacroAssembler _masm(&amp;cbuf);
 3004     Register src_reg = as_Register($src$$reg);
 3005     Register base = as_Register($mem$$base);
 3006     int index = $mem$$index;
 3007     int scale = $mem$$scale;
 3008     int disp = $mem$$disp;
 3009     if (index == -1) {
 3010        if (disp != 0) {
 3011         __ lea(rscratch2, Address(base, disp));
 3012         __ stlxr(rscratch1, src_reg, rscratch2);
 3013       } else {
 3014         // TODO
 3015         // should we ever get anything other than this case?
 3016         __ stlxr(rscratch1, src_reg, base);
 3017       }
 3018     } else {
 3019       Register index_reg = as_Register(index);
 3020       if (disp == 0) {
 3021         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3022         __ stlxr(rscratch1, src_reg, rscratch2);
 3023       } else {
 3024         __ lea(rscratch2, Address(base, disp));
 3025         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3026         __ stlxr(rscratch1, src_reg, rscratch2);
 3027       }
 3028     }
 3029     __ cmpw(rscratch1, zr);
 3030   %}
 3031 
 3032   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3033     C2_MacroAssembler _masm(&amp;cbuf);
 3034     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3035     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3036                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3037                /*weak*/ false, noreg);
 3038   %}
 3039 
 3040   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3041     C2_MacroAssembler _masm(&amp;cbuf);
 3042     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3043     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3044                Assembler::word, /*acquire*/ false, /*release*/ true,
 3045                /*weak*/ false, noreg);
 3046   %}
 3047 
 3048   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3049     C2_MacroAssembler _masm(&amp;cbuf);
 3050     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3051     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3052                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3053                /*weak*/ false, noreg);
 3054   %}
 3055 
 3056   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3057     C2_MacroAssembler _masm(&amp;cbuf);
 3058     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3059     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3060                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3061                /*weak*/ false, noreg);
 3062   %}
 3063 
 3064 
 3065   // The only difference between aarch64_enc_cmpxchg and
 3066   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3067   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3068   // lock.
 3069   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3070     C2_MacroAssembler _masm(&amp;cbuf);
 3071     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3072     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3073                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3074                /*weak*/ false, noreg);
 3075   %}
 3076 
 3077   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3078     C2_MacroAssembler _masm(&amp;cbuf);
 3079     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3080     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3081                Assembler::word, /*acquire*/ true, /*release*/ true,
 3082                /*weak*/ false, noreg);
 3083   %}
 3084 
 3085   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3086     C2_MacroAssembler _masm(&amp;cbuf);
 3087     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3088     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3089                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3090                /*weak*/ false, noreg);
 3091   %}
 3092 
 3093   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3094     C2_MacroAssembler _masm(&amp;cbuf);
 3095     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3096     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3097                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3098                /*weak*/ false, noreg);
 3099   %}
 3100 
 3101   // auxiliary used for CompareAndSwapX to set result register
 3102   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3103     C2_MacroAssembler _masm(&amp;cbuf);
 3104     Register res_reg = as_Register($res$$reg);
 3105     __ cset(res_reg, Assembler::EQ);
 3106   %}
 3107 
 3108   // prefetch encodings
 3109 
 3110   enc_class aarch64_enc_prefetchw(memory mem) %{
 3111     C2_MacroAssembler _masm(&amp;cbuf);
 3112     Register base = as_Register($mem$$base);
 3113     int index = $mem$$index;
 3114     int scale = $mem$$scale;
 3115     int disp = $mem$$disp;
 3116     if (index == -1) {
 3117       __ prfm(Address(base, disp), PSTL1KEEP);
 3118     } else {
 3119       Register index_reg = as_Register(index);
 3120       if (disp == 0) {
 3121         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3122       } else {
 3123         __ lea(rscratch1, Address(base, disp));
 3124 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3125       }
 3126     }
 3127   %}
 3128 
 3129   /// mov envcodings
 3130 
 3131   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3132     C2_MacroAssembler _masm(&amp;cbuf);
 3133     u_int32_t con = (u_int32_t)$src$$constant;
 3134     Register dst_reg = as_Register($dst$$reg);
 3135     if (con == 0) {
 3136       __ movw(dst_reg, zr);
 3137     } else {
 3138       __ movw(dst_reg, con);
 3139     }
 3140   %}
 3141 
 3142   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3143     C2_MacroAssembler _masm(&amp;cbuf);
 3144     Register dst_reg = as_Register($dst$$reg);
 3145     u_int64_t con = (u_int64_t)$src$$constant;
 3146     if (con == 0) {
 3147       __ mov(dst_reg, zr);
 3148     } else {
 3149       __ mov(dst_reg, con);
 3150     }
 3151   %}
 3152 
 3153   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3154     C2_MacroAssembler _masm(&amp;cbuf);
 3155     Register dst_reg = as_Register($dst$$reg);
 3156     address con = (address)$src$$constant;
 3157     if (con == NULL || con == (address)1) {
 3158       ShouldNotReachHere();
 3159     } else {
 3160       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3161       if (rtype == relocInfo::oop_type) {
 3162         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3163       } else if (rtype == relocInfo::metadata_type) {
 3164         __ mov_metadata(dst_reg, (Metadata*)con);
 3165       } else {
 3166         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3167         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3168           __ mov(dst_reg, con);
 3169         } else {
 3170           unsigned long offset;
 3171           __ adrp(dst_reg, con, offset);
 3172           __ add(dst_reg, dst_reg, offset);
 3173         }
 3174       }
 3175     }
 3176   %}
 3177 
 3178   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3179     C2_MacroAssembler _masm(&amp;cbuf);
 3180     Register dst_reg = as_Register($dst$$reg);
 3181     __ mov(dst_reg, zr);
 3182   %}
 3183 
 3184   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3185     C2_MacroAssembler _masm(&amp;cbuf);
 3186     Register dst_reg = as_Register($dst$$reg);
 3187     __ mov(dst_reg, (u_int64_t)1);
 3188   %}
 3189 
 3190   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3191     C2_MacroAssembler _masm(&amp;cbuf);
 3192     __ load_byte_map_base($dst$$Register);
 3193   %}
 3194 
 3195   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3196     C2_MacroAssembler _masm(&amp;cbuf);
 3197     Register dst_reg = as_Register($dst$$reg);
 3198     address con = (address)$src$$constant;
 3199     if (con == NULL) {
 3200       ShouldNotReachHere();
 3201     } else {
 3202       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3203       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3204       __ set_narrow_oop(dst_reg, (jobject)con);
 3205     }
 3206   %}
 3207 
 3208   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3209     C2_MacroAssembler _masm(&amp;cbuf);
 3210     Register dst_reg = as_Register($dst$$reg);
 3211     __ mov(dst_reg, zr);
 3212   %}
 3213 
 3214   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3215     C2_MacroAssembler _masm(&amp;cbuf);
 3216     Register dst_reg = as_Register($dst$$reg);
 3217     address con = (address)$src$$constant;
 3218     if (con == NULL) {
 3219       ShouldNotReachHere();
 3220     } else {
 3221       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3222       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3223       __ set_narrow_klass(dst_reg, (Klass *)con);
 3224     }
 3225   %}
 3226 
 3227   // arithmetic encodings
 3228 
 3229   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3230     C2_MacroAssembler _masm(&amp;cbuf);
 3231     Register dst_reg = as_Register($dst$$reg);
 3232     Register src_reg = as_Register($src1$$reg);
 3233     int32_t con = (int32_t)$src2$$constant;
 3234     // add has primary == 0, subtract has primary == 1
 3235     if ($primary) { con = -con; }
 3236     if (con &lt; 0) {
 3237       __ subw(dst_reg, src_reg, -con);
 3238     } else {
 3239       __ addw(dst_reg, src_reg, con);
 3240     }
 3241   %}
 3242 
 3243   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3244     C2_MacroAssembler _masm(&amp;cbuf);
 3245     Register dst_reg = as_Register($dst$$reg);
 3246     Register src_reg = as_Register($src1$$reg);
 3247     int32_t con = (int32_t)$src2$$constant;
 3248     // add has primary == 0, subtract has primary == 1
 3249     if ($primary) { con = -con; }
 3250     if (con &lt; 0) {
 3251       __ sub(dst_reg, src_reg, -con);
 3252     } else {
 3253       __ add(dst_reg, src_reg, con);
 3254     }
 3255   %}
 3256 
 3257   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3258     C2_MacroAssembler _masm(&amp;cbuf);
 3259    Register dst_reg = as_Register($dst$$reg);
 3260    Register src1_reg = as_Register($src1$$reg);
 3261    Register src2_reg = as_Register($src2$$reg);
 3262     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3263   %}
 3264 
 3265   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3266     C2_MacroAssembler _masm(&amp;cbuf);
 3267    Register dst_reg = as_Register($dst$$reg);
 3268    Register src1_reg = as_Register($src1$$reg);
 3269    Register src2_reg = as_Register($src2$$reg);
 3270     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3271   %}
 3272 
 3273   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3274     C2_MacroAssembler _masm(&amp;cbuf);
 3275    Register dst_reg = as_Register($dst$$reg);
 3276    Register src1_reg = as_Register($src1$$reg);
 3277    Register src2_reg = as_Register($src2$$reg);
 3278     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3279   %}
 3280 
 3281   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3282     C2_MacroAssembler _masm(&amp;cbuf);
 3283    Register dst_reg = as_Register($dst$$reg);
 3284    Register src1_reg = as_Register($src1$$reg);
 3285    Register src2_reg = as_Register($src2$$reg);
 3286     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3287   %}
 3288 
 3289   // compare instruction encodings
 3290 
 3291   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3292     C2_MacroAssembler _masm(&amp;cbuf);
 3293     Register reg1 = as_Register($src1$$reg);
 3294     Register reg2 = as_Register($src2$$reg);
 3295     __ cmpw(reg1, reg2);
 3296   %}
 3297 
 3298   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3299     C2_MacroAssembler _masm(&amp;cbuf);
 3300     Register reg = as_Register($src1$$reg);
 3301     int32_t val = $src2$$constant;
 3302     if (val &gt;= 0) {
 3303       __ subsw(zr, reg, val);
 3304     } else {
 3305       __ addsw(zr, reg, -val);
 3306     }
 3307   %}
 3308 
 3309   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3310     C2_MacroAssembler _masm(&amp;cbuf);
 3311     Register reg1 = as_Register($src1$$reg);
 3312     u_int32_t val = (u_int32_t)$src2$$constant;
 3313     __ movw(rscratch1, val);
 3314     __ cmpw(reg1, rscratch1);
 3315   %}
 3316 
 3317   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3318     C2_MacroAssembler _masm(&amp;cbuf);
 3319     Register reg1 = as_Register($src1$$reg);
 3320     Register reg2 = as_Register($src2$$reg);
 3321     __ cmp(reg1, reg2);
 3322   %}
 3323 
 3324   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3325     C2_MacroAssembler _masm(&amp;cbuf);
 3326     Register reg = as_Register($src1$$reg);
 3327     int64_t val = $src2$$constant;
 3328     if (val &gt;= 0) {
 3329       __ subs(zr, reg, val);
 3330     } else if (val != -val) {
 3331       __ adds(zr, reg, -val);
 3332     } else {
 3333     // aargh, Long.MIN_VALUE is a special case
 3334       __ orr(rscratch1, zr, (u_int64_t)val);
 3335       __ subs(zr, reg, rscratch1);
 3336     }
 3337   %}
 3338 
 3339   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3340     C2_MacroAssembler _masm(&amp;cbuf);
 3341     Register reg1 = as_Register($src1$$reg);
 3342     u_int64_t val = (u_int64_t)$src2$$constant;
 3343     __ mov(rscratch1, val);
 3344     __ cmp(reg1, rscratch1);
 3345   %}
 3346 
 3347   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3348     C2_MacroAssembler _masm(&amp;cbuf);
 3349     Register reg1 = as_Register($src1$$reg);
 3350     Register reg2 = as_Register($src2$$reg);
 3351     __ cmp(reg1, reg2);
 3352   %}
 3353 
 3354   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3355     C2_MacroAssembler _masm(&amp;cbuf);
 3356     Register reg1 = as_Register($src1$$reg);
 3357     Register reg2 = as_Register($src2$$reg);
 3358     __ cmpw(reg1, reg2);
 3359   %}
 3360 
 3361   enc_class aarch64_enc_testp(iRegP src) %{
 3362     C2_MacroAssembler _masm(&amp;cbuf);
 3363     Register reg = as_Register($src$$reg);
 3364     __ cmp(reg, zr);
 3365   %}
 3366 
 3367   enc_class aarch64_enc_testn(iRegN src) %{
 3368     C2_MacroAssembler _masm(&amp;cbuf);
 3369     Register reg = as_Register($src$$reg);
 3370     __ cmpw(reg, zr);
 3371   %}
 3372 
 3373   enc_class aarch64_enc_b(label lbl) %{
 3374     C2_MacroAssembler _masm(&amp;cbuf);
 3375     Label *L = $lbl$$label;
 3376     __ b(*L);
 3377   %}
 3378 
 3379   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3380     C2_MacroAssembler _masm(&amp;cbuf);
 3381     Label *L = $lbl$$label;
 3382     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3383   %}
 3384 
 3385   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3386     C2_MacroAssembler _masm(&amp;cbuf);
 3387     Label *L = $lbl$$label;
 3388     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3389   %}
 3390 
 3391   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3392   %{
 3393      Register sub_reg = as_Register($sub$$reg);
 3394      Register super_reg = as_Register($super$$reg);
 3395      Register temp_reg = as_Register($temp$$reg);
 3396      Register result_reg = as_Register($result$$reg);
 3397 
 3398      Label miss;
 3399      C2_MacroAssembler _masm(&amp;cbuf);
 3400      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3401                                      NULL, &amp;miss,
 3402                                      /*set_cond_codes:*/ true);
 3403      if ($primary) {
 3404        __ mov(result_reg, zr);
 3405      }
 3406      __ bind(miss);
 3407   %}
 3408 
 3409   enc_class aarch64_enc_java_static_call(method meth) %{
 3410     C2_MacroAssembler _masm(&amp;cbuf);
 3411 
 3412     address addr = (address)$meth$$method;
 3413     address call;
 3414     if (!_method) {
 3415       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3416       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3417     } else {
 3418       int method_index = resolved_method_index(cbuf);
 3419       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3420                                                   : static_call_Relocation::spec(method_index);
 3421       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3422 
 3423       // Emit stub for static call
 3424       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3425       if (stub == NULL) {
 3426         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3427         return;
 3428       }
 3429     }
 3430     if (call == NULL) {
 3431       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3432       return;
 3433     }
 3434   %}
 3435 
 3436   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3437     C2_MacroAssembler _masm(&amp;cbuf);
 3438     int method_index = resolved_method_index(cbuf);
 3439     address call = __ ic_call((address)$meth$$method, method_index);
 3440     if (call == NULL) {
 3441       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3442       return;
 3443     }
 3444   %}
 3445 
 3446   enc_class aarch64_enc_call_epilog() %{
 3447     C2_MacroAssembler _masm(&amp;cbuf);
 3448     if (VerifyStackAtCalls) {
 3449       // Check that stack depth is unchanged: find majik cookie on stack
 3450       __ call_Unimplemented();
 3451     }
 3452   %}
 3453 
 3454   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3455     C2_MacroAssembler _masm(&amp;cbuf);
 3456 
 3457     // some calls to generated routines (arraycopy code) are scheduled
 3458     // by C2 as runtime calls. if so we can call them using a br (they
 3459     // will be in a reachable segment) otherwise we have to use a blr
 3460     // which loads the absolute address into a register.
 3461     address entry = (address)$meth$$method;
 3462     CodeBlob *cb = CodeCache::find_blob(entry);
 3463     if (cb) {
 3464       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3465       if (call == NULL) {
 3466         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3467         return;
 3468       }
 3469     } else {
 3470       Label retaddr;
 3471       __ adr(rscratch2, retaddr);
 3472       __ lea(rscratch1, RuntimeAddress(entry));
 3473       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3474       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3475       __ blr(rscratch1);
 3476       __ bind(retaddr);
 3477       __ add(sp, sp, 2 * wordSize);
 3478     }
 3479   %}
 3480 
 3481   enc_class aarch64_enc_rethrow() %{
 3482     C2_MacroAssembler _masm(&amp;cbuf);
 3483     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3484   %}
 3485 
 3486   enc_class aarch64_enc_ret() %{
 3487     C2_MacroAssembler _masm(&amp;cbuf);
 3488     __ ret(lr);
 3489   %}
 3490 
 3491   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3492     C2_MacroAssembler _masm(&amp;cbuf);
 3493     Register target_reg = as_Register($jump_target$$reg);
 3494     __ br(target_reg);
 3495   %}
 3496 
 3497   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3498     C2_MacroAssembler _masm(&amp;cbuf);
 3499     Register target_reg = as_Register($jump_target$$reg);
 3500     // exception oop should be in r0
 3501     // ret addr has been popped into lr
 3502     // callee expects it in r3
 3503     __ mov(r3, lr);
 3504     __ br(target_reg);
 3505   %}
 3506 
 3507   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3508     C2_MacroAssembler _masm(&amp;cbuf);
 3509     Register oop = as_Register($object$$reg);
 3510     Register box = as_Register($box$$reg);
 3511     Register disp_hdr = as_Register($tmp$$reg);
 3512     Register tmp = as_Register($tmp2$$reg);
 3513     Label cont;
 3514     Label object_has_monitor;
 3515     Label cas_failed;
 3516 
 3517     assert_different_registers(oop, box, tmp, disp_hdr);
 3518 
 3519     // Load markWord from object into displaced_header.
 3520     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3521 
 3522     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3523       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3524     }
 3525 
 3526     // Check for existing monitor
 3527     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3528 
 3529     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3530     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3531 
 3532     // Initialize the box. (Must happen before we update the object mark!)
 3533     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3534 
 3535     // Compare object markWord with an unlocked value (tmp) and if
 3536     // equal exchange the stack address of our box with object markWord.
 3537     // On failure disp_hdr contains the possibly locked markWord.
 3538     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3539                /*release*/ true, /*weak*/ false, disp_hdr);
 3540     __ br(Assembler::EQ, cont);
 3541 
 3542     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3543 
 3544     // If the compare-and-exchange succeeded, then we found an unlocked
 3545     // object, will have now locked it will continue at label cont
 3546 
 3547     __ bind(cas_failed);
 3548     // We did not see an unlocked object so try the fast recursive case.
 3549 
 3550     // Check if the owner is self by comparing the value in the
 3551     // markWord of object (disp_hdr) with the stack pointer.
 3552     __ mov(rscratch1, sp);
 3553     __ sub(disp_hdr, disp_hdr, rscratch1);
 3554     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3555     // If condition is true we are cont and hence we can store 0 as the
 3556     // displaced header in the box, which indicates that it is a recursive lock.
 3557     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3558     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3559 
 3560     __ b(cont);
 3561 
 3562     // Handle existing monitor.
 3563     __ bind(object_has_monitor);
 3564 
 3565     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3566     // otherwise m-&gt;owner may contain a thread or a stack address.
 3567     //
 3568     // Try to CAS m-&gt;owner from NULL to current thread.
 3569     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3570     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3571                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3572 
 3573     // Store a non-null value into the box to avoid looking like a re-entrant
 3574     // lock. The fast-path monitor unlock code checks for
 3575     // markWord::monitor_value so use markWord::unused_mark which has the
 3576     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3577     __ mov(tmp, (address)markWord::unused_mark().value());
 3578     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3579 
 3580     __ bind(cont);
 3581     // flag == EQ indicates success
 3582     // flag == NE indicates failure
 3583   %}
 3584 
 3585   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3586     C2_MacroAssembler _masm(&amp;cbuf);
 3587     Register oop = as_Register($object$$reg);
 3588     Register box = as_Register($box$$reg);
 3589     Register disp_hdr = as_Register($tmp$$reg);
 3590     Register tmp = as_Register($tmp2$$reg);
 3591     Label cont;
 3592     Label object_has_monitor;
 3593 
 3594     assert_different_registers(oop, box, tmp, disp_hdr);
 3595 
 3596     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3597       __ biased_locking_exit(oop, tmp, cont);
 3598     }
 3599 
 3600     // Find the lock address and load the displaced header from the stack.
 3601     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3602 
 3603     // If the displaced header is 0, we have a recursive unlock.
 3604     __ cmp(disp_hdr, zr);
 3605     __ br(Assembler::EQ, cont);
 3606 
 3607     // Handle existing monitor.
 3608     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3609     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3610 
 3611     // Check if it is still a light weight lock, this is is true if we
 3612     // see the stack address of the basicLock in the markWord of the
 3613     // object.
 3614 
 3615     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3616                /*release*/ true, /*weak*/ false, tmp);
 3617     __ b(cont);
 3618 
 3619     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3620 
 3621     // Handle existing monitor.
 3622     __ bind(object_has_monitor);
 3623     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3624     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3625     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3626     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3627     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3628     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3629     __ cmp(rscratch1, zr); // Sets flags for result
 3630     __ br(Assembler::NE, cont);
 3631 
 3632     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3633     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3634     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3635     __ cmp(rscratch1, zr); // Sets flags for result
 3636     __ cbnz(rscratch1, cont);
 3637     // need a release store here
 3638     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3639     __ stlr(zr, tmp); // set unowned
 3640 
 3641     __ bind(cont);
 3642     // flag == EQ indicates success
 3643     // flag == NE indicates failure
 3644   %}
 3645 
 3646 %}
 3647 
 3648 //----------FRAME--------------------------------------------------------------
 3649 // Definition of frame structure and management information.
 3650 //
 3651 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3652 //                             |   (to get allocators register number
 3653 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3654 //  r   CALLER     |        |
 3655 //  o     |        +--------+      pad to even-align allocators stack-slot
 3656 //  w     V        |  pad0  |        numbers; owned by CALLER
 3657 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3658 //  h     ^        |   in   |  5
 3659 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3660 //  |     |        |        |  3
 3661 //  |     |        +--------+
 3662 //  V     |        | old out|      Empty on Intel, window on Sparc
 3663 //        |    old |preserve|      Must be even aligned.
 3664 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3665 //        |        |   in   |  3   area for Intel ret address
 3666 //     Owned by    |preserve|      Empty on Sparc.
 3667 //       SELF      +--------+
 3668 //        |        |  pad2  |  2   pad to align old SP
 3669 //        |        +--------+  1
 3670 //        |        | locks  |  0
 3671 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3672 //        |        |  pad1  | 11   pad to align new SP
 3673 //        |        +--------+
 3674 //        |        |        | 10
 3675 //        |        | spills |  9   spills
 3676 //        V        |        |  8   (pad0 slot for callee)
 3677 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3678 //        ^        |  out   |  7
 3679 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3680 //     Owned by    +--------+
 3681 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3682 //        |    new |preserve|      Must be even-aligned.
 3683 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3684 //        |        |        |
 3685 //
 3686 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3687 //         known from SELF&#39;s arguments and the Java calling convention.
 3688 //         Region 6-7 is determined per call site.
 3689 // Note 2: If the calling convention leaves holes in the incoming argument
 3690 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3691 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3692 //         incoming area, as the Java calling convention is completely under
 3693 //         the control of the AD file.  Doubles can be sorted and packed to
 3694 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3695 //         varargs C calling conventions.
 3696 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3697 //         even aligned with pad0 as needed.
 3698 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3699 //           (the latter is true on Intel but is it false on AArch64?)
 3700 //         region 6-11 is even aligned; it may be padded out more so that
 3701 //         the region from SP to FP meets the minimum stack alignment.
 3702 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3703 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3704 //         SP meets the minimum alignment.
 3705 
 3706 frame %{
 3707   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3708   stack_direction(TOWARDS_LOW);
 3709 
 3710   // These three registers define part of the calling convention
 3711   // between compiled code and the interpreter.
 3712 
 3713   // Inline Cache Register or methodOop for I2C.
 3714   inline_cache_reg(R12);
 3715 
 3716   // Method Oop Register when calling interpreter.
 3717   interpreter_method_oop_reg(R12);
 3718 
 3719   // Number of stack slots consumed by locking an object
 3720   sync_stack_slots(2);
 3721 
 3722   // Compiled code&#39;s Frame Pointer
 3723   frame_pointer(R31);
 3724 
 3725   // Interpreter stores its frame pointer in a register which is
 3726   // stored to the stack by I2CAdaptors.
 3727   // I2CAdaptors convert from interpreted java to compiled java.
 3728   interpreter_frame_pointer(R29);
 3729 
 3730   // Stack alignment requirement
 3731   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3732 
 3733   // Number of stack slots between incoming argument block and the start of
 3734   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3735   // EPILOG must remove this many slots. aarch64 needs two slots for
 3736   // return address and fp.
 3737   // TODO think this is correct but check
 3738   in_preserve_stack_slots(4);
 3739 
 3740   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3741   // for calls to C.  Supports the var-args backing area for register parms.
 3742   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3743 
 3744   // The after-PROLOG location of the return address.  Location of
 3745   // return address specifies a type (REG or STACK) and a number
 3746   // representing the register number (i.e. - use a register name) or
 3747   // stack slot.
 3748   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3749   // Otherwise, it is above the locks and verification slot and alignment word
 3750   // TODO this may well be correct but need to check why that - 2 is there
 3751   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3752   // which folds in the space used for monitors
 3753   return_addr(STACK - 2 +
 3754               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3755                         Compile::current()-&gt;fixed_slots()),
 3756                        stack_alignment_in_slots()));
 3757 
 3758   // Body of function which returns an integer array locating
 3759   // arguments either in registers or in stack slots.  Passed an array
 3760   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3761   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3762   // arguments for a CALLEE.  Incoming stack arguments are
 3763   // automatically biased by the preserve_stack_slots field above.
 3764 
 3765   calling_convention
 3766   %{
 3767     // No difference between ingoing/outgoing just pass false
 3768     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3769   %}
 3770 
 3771   c_calling_convention
 3772   %{
 3773     // This is obviously always outgoing
 3774     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3775   %}
 3776 
 3777   // Location of compiled Java return values.  Same as C for now.
 3778   return_value
 3779   %{
 3780     // TODO do we allow ideal_reg == Op_RegN???
 3781     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3782            &quot;only return normal values&quot;);
 3783 
 3784     static const int lo[Op_RegL + 1] = { // enum name
 3785       0,                                 // Op_Node
 3786       0,                                 // Op_Set
 3787       R0_num,                            // Op_RegN
 3788       R0_num,                            // Op_RegI
 3789       R0_num,                            // Op_RegP
 3790       V0_num,                            // Op_RegF
 3791       V0_num,                            // Op_RegD
 3792       R0_num                             // Op_RegL
 3793     };
 3794 
 3795     static const int hi[Op_RegL + 1] = { // enum name
 3796       0,                                 // Op_Node
 3797       0,                                 // Op_Set
 3798       OptoReg::Bad,                      // Op_RegN
 3799       OptoReg::Bad,                      // Op_RegI
 3800       R0_H_num,                          // Op_RegP
 3801       OptoReg::Bad,                      // Op_RegF
 3802       V0_H_num,                          // Op_RegD
 3803       R0_H_num                           // Op_RegL
 3804     };
 3805 
 3806     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3807   %}
 3808 %}
 3809 
 3810 //----------ATTRIBUTES---------------------------------------------------------
 3811 //----------Operand Attributes-------------------------------------------------
 3812 op_attrib op_cost(1);        // Required cost attribute
 3813 
 3814 //----------Instruction Attributes---------------------------------------------
 3815 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3816 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3817 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3818                                 // a non-matching short branch variant
 3819                                 // of some long branch?
 3820 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3821                                 // be a power of 2) specifies the
 3822                                 // alignment that some part of the
 3823                                 // instruction (not necessarily the
 3824                                 // start) requires.  If &gt; 1, a
 3825                                 // compute_padding() function must be
 3826                                 // provided for the instruction
 3827 
 3828 //----------OPERANDS-----------------------------------------------------------
 3829 // Operand definitions must precede instruction definitions for correct parsing
 3830 // in the ADLC because operands constitute user defined types which are used in
 3831 // instruction definitions.
 3832 
 3833 //----------Simple Operands----------------------------------------------------
 3834 
 3835 // Integer operands 32 bit
 3836 // 32 bit immediate
 3837 operand immI()
 3838 %{
 3839   match(ConI);
 3840 
 3841   op_cost(0);
 3842   format %{ %}
 3843   interface(CONST_INTER);
 3844 %}
 3845 
 3846 // 32 bit zero
 3847 operand immI0()
 3848 %{
 3849   predicate(n-&gt;get_int() == 0);
 3850   match(ConI);
 3851 
 3852   op_cost(0);
 3853   format %{ %}
 3854   interface(CONST_INTER);
 3855 %}
 3856 
 3857 // 32 bit unit increment
 3858 operand immI_1()
 3859 %{
 3860   predicate(n-&gt;get_int() == 1);
 3861   match(ConI);
 3862 
 3863   op_cost(0);
 3864   format %{ %}
 3865   interface(CONST_INTER);
 3866 %}
 3867 
 3868 // 32 bit unit decrement
 3869 operand immI_M1()
 3870 %{
 3871   predicate(n-&gt;get_int() == -1);
 3872   match(ConI);
 3873 
 3874   op_cost(0);
 3875   format %{ %}
 3876   interface(CONST_INTER);
 3877 %}
 3878 
 3879 // Shift values for add/sub extension shift
 3880 operand immIExt()
 3881 %{
 3882   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3883   match(ConI);
 3884 
 3885   op_cost(0);
 3886   format %{ %}
 3887   interface(CONST_INTER);
 3888 %}
 3889 
 3890 operand immI_le_4()
 3891 %{
 3892   predicate(n-&gt;get_int() &lt;= 4);
 3893   match(ConI);
 3894 
 3895   op_cost(0);
 3896   format %{ %}
 3897   interface(CONST_INTER);
 3898 %}
 3899 
 3900 operand immI_31()
 3901 %{
 3902   predicate(n-&gt;get_int() == 31);
 3903   match(ConI);
 3904 
 3905   op_cost(0);
 3906   format %{ %}
 3907   interface(CONST_INTER);
 3908 %}
 3909 
 3910 operand immI_8()
 3911 %{
 3912   predicate(n-&gt;get_int() == 8);
 3913   match(ConI);
 3914 
 3915   op_cost(0);
 3916   format %{ %}
 3917   interface(CONST_INTER);
 3918 %}
 3919 
 3920 operand immI_16()
 3921 %{
 3922   predicate(n-&gt;get_int() == 16);
 3923   match(ConI);
 3924 
 3925   op_cost(0);
 3926   format %{ %}
 3927   interface(CONST_INTER);
 3928 %}
 3929 
 3930 operand immI_24()
 3931 %{
 3932   predicate(n-&gt;get_int() == 24);
 3933   match(ConI);
 3934 
 3935   op_cost(0);
 3936   format %{ %}
 3937   interface(CONST_INTER);
 3938 %}
 3939 
 3940 operand immI_32()
 3941 %{
 3942   predicate(n-&gt;get_int() == 32);
 3943   match(ConI);
 3944 
 3945   op_cost(0);
 3946   format %{ %}
 3947   interface(CONST_INTER);
 3948 %}
 3949 
 3950 operand immI_48()
 3951 %{
 3952   predicate(n-&gt;get_int() == 48);
 3953   match(ConI);
 3954 
 3955   op_cost(0);
 3956   format %{ %}
 3957   interface(CONST_INTER);
 3958 %}
 3959 
 3960 operand immI_56()
 3961 %{
 3962   predicate(n-&gt;get_int() == 56);
 3963   match(ConI);
 3964 
 3965   op_cost(0);
 3966   format %{ %}
 3967   interface(CONST_INTER);
 3968 %}
 3969 
 3970 operand immI_63()
 3971 %{
 3972   predicate(n-&gt;get_int() == 63);
 3973   match(ConI);
 3974 
 3975   op_cost(0);
 3976   format %{ %}
 3977   interface(CONST_INTER);
 3978 %}
 3979 
 3980 operand immI_64()
 3981 %{
 3982   predicate(n-&gt;get_int() == 64);
 3983   match(ConI);
 3984 
 3985   op_cost(0);
 3986   format %{ %}
 3987   interface(CONST_INTER);
 3988 %}
 3989 
 3990 operand immI_255()
 3991 %{
 3992   predicate(n-&gt;get_int() == 255);
 3993   match(ConI);
 3994 
 3995   op_cost(0);
 3996   format %{ %}
 3997   interface(CONST_INTER);
 3998 %}
 3999 
 4000 operand immI_65535()
 4001 %{
 4002   predicate(n-&gt;get_int() == 65535);
 4003   match(ConI);
 4004 
 4005   op_cost(0);
 4006   format %{ %}
 4007   interface(CONST_INTER);
 4008 %}
 4009 
 4010 operand immL_255()
 4011 %{
 4012   predicate(n-&gt;get_long() == 255L);
 4013   match(ConL);
 4014 
 4015   op_cost(0);
 4016   format %{ %}
 4017   interface(CONST_INTER);
 4018 %}
 4019 
 4020 operand immL_65535()
 4021 %{
 4022   predicate(n-&gt;get_long() == 65535L);
 4023   match(ConL);
 4024 
 4025   op_cost(0);
 4026   format %{ %}
 4027   interface(CONST_INTER);
 4028 %}
 4029 
 4030 operand immL_4294967295()
 4031 %{
 4032   predicate(n-&gt;get_long() == 4294967295L);
 4033   match(ConL);
 4034 
 4035   op_cost(0);
 4036   format %{ %}
 4037   interface(CONST_INTER);
 4038 %}
 4039 
 4040 operand immL_bitmask()
 4041 %{
 4042   predicate((n-&gt;get_long() != 0)
 4043             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4044             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4045   match(ConL);
 4046 
 4047   op_cost(0);
 4048   format %{ %}
 4049   interface(CONST_INTER);
 4050 %}
 4051 
 4052 operand immI_bitmask()
 4053 %{
 4054   predicate((n-&gt;get_int() != 0)
 4055             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4056             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4057   match(ConI);
 4058 
 4059   op_cost(0);
 4060   format %{ %}
 4061   interface(CONST_INTER);
 4062 %}
 4063 
 4064 // Scale values for scaled offset addressing modes (up to long but not quad)
 4065 operand immIScale()
 4066 %{
 4067   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4068   match(ConI);
 4069 
 4070   op_cost(0);
 4071   format %{ %}
 4072   interface(CONST_INTER);
 4073 %}
 4074 
 4075 // 26 bit signed offset -- for pc-relative branches
 4076 operand immI26()
 4077 %{
 4078   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4079   match(ConI);
 4080 
 4081   op_cost(0);
 4082   format %{ %}
 4083   interface(CONST_INTER);
 4084 %}
 4085 
 4086 // 19 bit signed offset -- for pc-relative loads
 4087 operand immI19()
 4088 %{
 4089   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4090   match(ConI);
 4091 
 4092   op_cost(0);
 4093   format %{ %}
 4094   interface(CONST_INTER);
 4095 %}
 4096 
 4097 // 12 bit unsigned offset -- for base plus immediate loads
 4098 operand immIU12()
 4099 %{
 4100   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4101   match(ConI);
 4102 
 4103   op_cost(0);
 4104   format %{ %}
 4105   interface(CONST_INTER);
 4106 %}
 4107 
 4108 operand immLU12()
 4109 %{
 4110   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4111   match(ConL);
 4112 
 4113   op_cost(0);
 4114   format %{ %}
 4115   interface(CONST_INTER);
 4116 %}
 4117 
 4118 // Offset for scaled or unscaled immediate loads and stores
 4119 operand immIOffset()
 4120 %{
 4121   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4122   match(ConI);
 4123 
 4124   op_cost(0);
 4125   format %{ %}
 4126   interface(CONST_INTER);
 4127 %}
 4128 
 4129 operand immIOffset1()
 4130 %{
 4131   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4132   match(ConI);
 4133 
 4134   op_cost(0);
 4135   format %{ %}
 4136   interface(CONST_INTER);
 4137 %}
 4138 
 4139 operand immIOffset2()
 4140 %{
 4141   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4142   match(ConI);
 4143 
 4144   op_cost(0);
 4145   format %{ %}
 4146   interface(CONST_INTER);
 4147 %}
 4148 
 4149 operand immIOffset4()
 4150 %{
 4151   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4152   match(ConI);
 4153 
 4154   op_cost(0);
 4155   format %{ %}
 4156   interface(CONST_INTER);
 4157 %}
 4158 
 4159 operand immIOffset8()
 4160 %{
 4161   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4162   match(ConI);
 4163 
 4164   op_cost(0);
 4165   format %{ %}
 4166   interface(CONST_INTER);
 4167 %}
 4168 
 4169 operand immIOffset16()
 4170 %{
 4171   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4172   match(ConI);
 4173 
 4174   op_cost(0);
 4175   format %{ %}
 4176   interface(CONST_INTER);
 4177 %}
 4178 
 4179 operand immLoffset()
 4180 %{
 4181   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4182   match(ConL);
 4183 
 4184   op_cost(0);
 4185   format %{ %}
 4186   interface(CONST_INTER);
 4187 %}
 4188 
 4189 operand immLoffset1()
 4190 %{
 4191   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4192   match(ConL);
 4193 
 4194   op_cost(0);
 4195   format %{ %}
 4196   interface(CONST_INTER);
 4197 %}
 4198 
 4199 operand immLoffset2()
 4200 %{
 4201   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4202   match(ConL);
 4203 
 4204   op_cost(0);
 4205   format %{ %}
 4206   interface(CONST_INTER);
 4207 %}
 4208 
 4209 operand immLoffset4()
 4210 %{
 4211   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4212   match(ConL);
 4213 
 4214   op_cost(0);
 4215   format %{ %}
 4216   interface(CONST_INTER);
 4217 %}
 4218 
 4219 operand immLoffset8()
 4220 %{
 4221   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4222   match(ConL);
 4223 
 4224   op_cost(0);
 4225   format %{ %}
 4226   interface(CONST_INTER);
 4227 %}
 4228 
 4229 operand immLoffset16()
 4230 %{
 4231   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4232   match(ConL);
 4233 
 4234   op_cost(0);
 4235   format %{ %}
 4236   interface(CONST_INTER);
 4237 %}
 4238 
 4239 // 32 bit integer valid for add sub immediate
 4240 operand immIAddSub()
 4241 %{
 4242   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4243   match(ConI);
 4244   op_cost(0);
 4245   format %{ %}
 4246   interface(CONST_INTER);
 4247 %}
 4248 
 4249 // 32 bit unsigned integer valid for logical immediate
 4250 // TODO -- check this is right when e.g the mask is 0x80000000
 4251 operand immILog()
 4252 %{
 4253   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4254   match(ConI);
 4255 
 4256   op_cost(0);
 4257   format %{ %}
 4258   interface(CONST_INTER);
 4259 %}
 4260 
 4261 // Integer operands 64 bit
 4262 // 64 bit immediate
 4263 operand immL()
 4264 %{
 4265   match(ConL);
 4266 
 4267   op_cost(0);
 4268   format %{ %}
 4269   interface(CONST_INTER);
 4270 %}
 4271 
 4272 // 64 bit zero
 4273 operand immL0()
 4274 %{
 4275   predicate(n-&gt;get_long() == 0);
 4276   match(ConL);
 4277 
 4278   op_cost(0);
 4279   format %{ %}
 4280   interface(CONST_INTER);
 4281 %}
 4282 
 4283 // 64 bit unit increment
 4284 operand immL_1()
 4285 %{
 4286   predicate(n-&gt;get_long() == 1);
 4287   match(ConL);
 4288 
 4289   op_cost(0);
 4290   format %{ %}
 4291   interface(CONST_INTER);
 4292 %}
 4293 
 4294 // 64 bit unit decrement
 4295 operand immL_M1()
 4296 %{
 4297   predicate(n-&gt;get_long() == -1);
 4298   match(ConL);
 4299 
 4300   op_cost(0);
 4301   format %{ %}
 4302   interface(CONST_INTER);
 4303 %}
 4304 
 4305 // 32 bit offset of pc in thread anchor
 4306 
 4307 operand immL_pc_off()
 4308 %{
 4309   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4310                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4311   match(ConL);
 4312 
 4313   op_cost(0);
 4314   format %{ %}
 4315   interface(CONST_INTER);
 4316 %}
 4317 
 4318 // 64 bit integer valid for add sub immediate
 4319 operand immLAddSub()
 4320 %{
 4321   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4322   match(ConL);
 4323   op_cost(0);
 4324   format %{ %}
 4325   interface(CONST_INTER);
 4326 %}
 4327 
 4328 // 64 bit integer valid for logical immediate
 4329 operand immLLog()
 4330 %{
 4331   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4332   match(ConL);
 4333   op_cost(0);
 4334   format %{ %}
 4335   interface(CONST_INTER);
 4336 %}
 4337 
 4338 // Long Immediate: low 32-bit mask
 4339 operand immL_32bits()
 4340 %{
 4341   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4342   match(ConL);
 4343   op_cost(0);
 4344   format %{ %}
 4345   interface(CONST_INTER);
 4346 %}
 4347 
 4348 // Pointer operands
 4349 // Pointer Immediate
 4350 operand immP()
 4351 %{
 4352   match(ConP);
 4353 
 4354   op_cost(0);
 4355   format %{ %}
 4356   interface(CONST_INTER);
 4357 %}
 4358 
 4359 // NULL Pointer Immediate
 4360 operand immP0()
 4361 %{
 4362   predicate(n-&gt;get_ptr() == 0);
 4363   match(ConP);
 4364 
 4365   op_cost(0);
 4366   format %{ %}
 4367   interface(CONST_INTER);
 4368 %}
 4369 
 4370 // Pointer Immediate One
 4371 // this is used in object initialization (initial object header)
 4372 operand immP_1()
 4373 %{
 4374   predicate(n-&gt;get_ptr() == 1);
 4375   match(ConP);
 4376 
 4377   op_cost(0);
 4378   format %{ %}
 4379   interface(CONST_INTER);
 4380 %}
 4381 
 4382 // Card Table Byte Map Base
 4383 operand immByteMapBase()
 4384 %{
 4385   // Get base of card map
 4386   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4387             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4388   match(ConP);
 4389 
 4390   op_cost(0);
 4391   format %{ %}
 4392   interface(CONST_INTER);
 4393 %}
 4394 
 4395 // Pointer Immediate Minus One
 4396 // this is used when we want to write the current PC to the thread anchor
 4397 operand immP_M1()
 4398 %{
 4399   predicate(n-&gt;get_ptr() == -1);
 4400   match(ConP);
 4401 
 4402   op_cost(0);
 4403   format %{ %}
 4404   interface(CONST_INTER);
 4405 %}
 4406 
 4407 // Pointer Immediate Minus Two
 4408 // this is used when we want to write the current PC to the thread anchor
 4409 operand immP_M2()
 4410 %{
 4411   predicate(n-&gt;get_ptr() == -2);
 4412   match(ConP);
 4413 
 4414   op_cost(0);
 4415   format %{ %}
 4416   interface(CONST_INTER);
 4417 %}
 4418 
 4419 // Float and Double operands
 4420 // Double Immediate
 4421 operand immD()
 4422 %{
 4423   match(ConD);
 4424   op_cost(0);
 4425   format %{ %}
 4426   interface(CONST_INTER);
 4427 %}
 4428 
 4429 // Double Immediate: +0.0d
 4430 operand immD0()
 4431 %{
 4432   predicate(jlong_cast(n-&gt;getd()) == 0);
 4433   match(ConD);
 4434 
 4435   op_cost(0);
 4436   format %{ %}
 4437   interface(CONST_INTER);
 4438 %}
 4439 
 4440 // constant &#39;double +0.0&#39;.
 4441 operand immDPacked()
 4442 %{
 4443   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4444   match(ConD);
 4445   op_cost(0);
 4446   format %{ %}
 4447   interface(CONST_INTER);
 4448 %}
 4449 
 4450 // Float Immediate
 4451 operand immF()
 4452 %{
 4453   match(ConF);
 4454   op_cost(0);
 4455   format %{ %}
 4456   interface(CONST_INTER);
 4457 %}
 4458 
 4459 // Float Immediate: +0.0f.
 4460 operand immF0()
 4461 %{
 4462   predicate(jint_cast(n-&gt;getf()) == 0);
 4463   match(ConF);
 4464 
 4465   op_cost(0);
 4466   format %{ %}
 4467   interface(CONST_INTER);
 4468 %}
 4469 
 4470 //
 4471 operand immFPacked()
 4472 %{
 4473   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4474   match(ConF);
 4475   op_cost(0);
 4476   format %{ %}
 4477   interface(CONST_INTER);
 4478 %}
 4479 
 4480 // Narrow pointer operands
 4481 // Narrow Pointer Immediate
 4482 operand immN()
 4483 %{
 4484   match(ConN);
 4485 
 4486   op_cost(0);
 4487   format %{ %}
 4488   interface(CONST_INTER);
 4489 %}
 4490 
 4491 // Narrow NULL Pointer Immediate
 4492 operand immN0()
 4493 %{
 4494   predicate(n-&gt;get_narrowcon() == 0);
 4495   match(ConN);
 4496 
 4497   op_cost(0);
 4498   format %{ %}
 4499   interface(CONST_INTER);
 4500 %}
 4501 
 4502 operand immNKlass()
 4503 %{
 4504   match(ConNKlass);
 4505 
 4506   op_cost(0);
 4507   format %{ %}
 4508   interface(CONST_INTER);
 4509 %}
 4510 
 4511 // Integer 32 bit Register Operands
 4512 // Integer 32 bitRegister (excludes SP)
 4513 operand iRegI()
 4514 %{
 4515   constraint(ALLOC_IN_RC(any_reg32));
 4516   match(RegI);
 4517   match(iRegINoSp);
 4518   op_cost(0);
 4519   format %{ %}
 4520   interface(REG_INTER);
 4521 %}
 4522 
 4523 // Integer 32 bit Register not Special
 4524 operand iRegINoSp()
 4525 %{
 4526   constraint(ALLOC_IN_RC(no_special_reg32));
 4527   match(RegI);
 4528   op_cost(0);
 4529   format %{ %}
 4530   interface(REG_INTER);
 4531 %}
 4532 
 4533 // Integer 64 bit Register Operands
 4534 // Integer 64 bit Register (includes SP)
 4535 operand iRegL()
 4536 %{
 4537   constraint(ALLOC_IN_RC(any_reg));
 4538   match(RegL);
 4539   match(iRegLNoSp);
 4540   op_cost(0);
 4541   format %{ %}
 4542   interface(REG_INTER);
 4543 %}
 4544 
 4545 // Integer 64 bit Register not Special
 4546 operand iRegLNoSp()
 4547 %{
 4548   constraint(ALLOC_IN_RC(no_special_reg));
 4549   match(RegL);
 4550   match(iRegL_R0);
 4551   format %{ %}
 4552   interface(REG_INTER);
 4553 %}
 4554 
 4555 // Pointer Register Operands
 4556 // Pointer Register
 4557 operand iRegP()
 4558 %{
 4559   constraint(ALLOC_IN_RC(ptr_reg));
 4560   match(RegP);
 4561   match(iRegPNoSp);
 4562   match(iRegP_R0);
 4563   //match(iRegP_R2);
 4564   //match(iRegP_R4);
 4565   //match(iRegP_R5);
 4566   match(thread_RegP);
 4567   op_cost(0);
 4568   format %{ %}
 4569   interface(REG_INTER);
 4570 %}
 4571 
 4572 // Pointer 64 bit Register not Special
 4573 operand iRegPNoSp()
 4574 %{
 4575   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4576   match(RegP);
 4577   // match(iRegP);
 4578   // match(iRegP_R0);
 4579   // match(iRegP_R2);
 4580   // match(iRegP_R4);
 4581   // match(iRegP_R5);
 4582   // match(thread_RegP);
 4583   op_cost(0);
 4584   format %{ %}
 4585   interface(REG_INTER);
 4586 %}
 4587 
 4588 // Pointer 64 bit Register R0 only
 4589 operand iRegP_R0()
 4590 %{
 4591   constraint(ALLOC_IN_RC(r0_reg));
 4592   match(RegP);
 4593   // match(iRegP);
 4594   match(iRegPNoSp);
 4595   op_cost(0);
 4596   format %{ %}
 4597   interface(REG_INTER);
 4598 %}
 4599 
 4600 // Pointer 64 bit Register R1 only
 4601 operand iRegP_R1()
 4602 %{
 4603   constraint(ALLOC_IN_RC(r1_reg));
 4604   match(RegP);
 4605   // match(iRegP);
 4606   match(iRegPNoSp);
 4607   op_cost(0);
 4608   format %{ %}
 4609   interface(REG_INTER);
 4610 %}
 4611 
 4612 // Pointer 64 bit Register R2 only
 4613 operand iRegP_R2()
 4614 %{
 4615   constraint(ALLOC_IN_RC(r2_reg));
 4616   match(RegP);
 4617   // match(iRegP);
 4618   match(iRegPNoSp);
 4619   op_cost(0);
 4620   format %{ %}
 4621   interface(REG_INTER);
 4622 %}
 4623 
 4624 // Pointer 64 bit Register R3 only
 4625 operand iRegP_R3()
 4626 %{
 4627   constraint(ALLOC_IN_RC(r3_reg));
 4628   match(RegP);
 4629   // match(iRegP);
 4630   match(iRegPNoSp);
 4631   op_cost(0);
 4632   format %{ %}
 4633   interface(REG_INTER);
 4634 %}
 4635 
 4636 // Pointer 64 bit Register R4 only
 4637 operand iRegP_R4()
 4638 %{
 4639   constraint(ALLOC_IN_RC(r4_reg));
 4640   match(RegP);
 4641   // match(iRegP);
 4642   match(iRegPNoSp);
 4643   op_cost(0);
 4644   format %{ %}
 4645   interface(REG_INTER);
 4646 %}
 4647 
 4648 // Pointer 64 bit Register R5 only
 4649 operand iRegP_R5()
 4650 %{
 4651   constraint(ALLOC_IN_RC(r5_reg));
 4652   match(RegP);
 4653   // match(iRegP);
 4654   match(iRegPNoSp);
 4655   op_cost(0);
 4656   format %{ %}
 4657   interface(REG_INTER);
 4658 %}
 4659 
 4660 // Pointer 64 bit Register R10 only
 4661 operand iRegP_R10()
 4662 %{
 4663   constraint(ALLOC_IN_RC(r10_reg));
 4664   match(RegP);
 4665   // match(iRegP);
 4666   match(iRegPNoSp);
 4667   op_cost(0);
 4668   format %{ %}
 4669   interface(REG_INTER);
 4670 %}
 4671 
 4672 // Long 64 bit Register R0 only
 4673 operand iRegL_R0()
 4674 %{
 4675   constraint(ALLOC_IN_RC(r0_reg));
 4676   match(RegL);
 4677   match(iRegLNoSp);
 4678   op_cost(0);
 4679   format %{ %}
 4680   interface(REG_INTER);
 4681 %}
 4682 
 4683 // Long 64 bit Register R2 only
 4684 operand iRegL_R2()
 4685 %{
 4686   constraint(ALLOC_IN_RC(r2_reg));
 4687   match(RegL);
 4688   match(iRegLNoSp);
 4689   op_cost(0);
 4690   format %{ %}
 4691   interface(REG_INTER);
 4692 %}
 4693 
 4694 // Long 64 bit Register R3 only
 4695 operand iRegL_R3()
 4696 %{
 4697   constraint(ALLOC_IN_RC(r3_reg));
 4698   match(RegL);
 4699   match(iRegLNoSp);
 4700   op_cost(0);
 4701   format %{ %}
 4702   interface(REG_INTER);
 4703 %}
 4704 
 4705 // Long 64 bit Register R11 only
 4706 operand iRegL_R11()
 4707 %{
 4708   constraint(ALLOC_IN_RC(r11_reg));
 4709   match(RegL);
 4710   match(iRegLNoSp);
 4711   op_cost(0);
 4712   format %{ %}
 4713   interface(REG_INTER);
 4714 %}
 4715 
 4716 // Pointer 64 bit Register FP only
 4717 operand iRegP_FP()
 4718 %{
 4719   constraint(ALLOC_IN_RC(fp_reg));
 4720   match(RegP);
 4721   // match(iRegP);
 4722   op_cost(0);
 4723   format %{ %}
 4724   interface(REG_INTER);
 4725 %}
 4726 
 4727 // Register R0 only
 4728 operand iRegI_R0()
 4729 %{
 4730   constraint(ALLOC_IN_RC(int_r0_reg));
 4731   match(RegI);
 4732   match(iRegINoSp);
 4733   op_cost(0);
 4734   format %{ %}
 4735   interface(REG_INTER);
 4736 %}
 4737 
 4738 // Register R2 only
 4739 operand iRegI_R2()
 4740 %{
 4741   constraint(ALLOC_IN_RC(int_r2_reg));
 4742   match(RegI);
 4743   match(iRegINoSp);
 4744   op_cost(0);
 4745   format %{ %}
 4746   interface(REG_INTER);
 4747 %}
 4748 
 4749 // Register R3 only
 4750 operand iRegI_R3()
 4751 %{
 4752   constraint(ALLOC_IN_RC(int_r3_reg));
 4753   match(RegI);
 4754   match(iRegINoSp);
 4755   op_cost(0);
 4756   format %{ %}
 4757   interface(REG_INTER);
 4758 %}
 4759 
 4760 
 4761 // Register R4 only
 4762 operand iRegI_R4()
 4763 %{
 4764   constraint(ALLOC_IN_RC(int_r4_reg));
 4765   match(RegI);
 4766   match(iRegINoSp);
 4767   op_cost(0);
 4768   format %{ %}
 4769   interface(REG_INTER);
 4770 %}
 4771 
 4772 
 4773 // Pointer Register Operands
 4774 // Narrow Pointer Register
 4775 operand iRegN()
 4776 %{
 4777   constraint(ALLOC_IN_RC(any_reg32));
 4778   match(RegN);
 4779   match(iRegNNoSp);
 4780   op_cost(0);
 4781   format %{ %}
 4782   interface(REG_INTER);
 4783 %}
 4784 
 4785 operand iRegN_R0()
 4786 %{
 4787   constraint(ALLOC_IN_RC(r0_reg));
 4788   match(iRegN);
 4789   op_cost(0);
 4790   format %{ %}
 4791   interface(REG_INTER);
 4792 %}
 4793 
 4794 operand iRegN_R2()
 4795 %{
 4796   constraint(ALLOC_IN_RC(r2_reg));
 4797   match(iRegN);
 4798   op_cost(0);
 4799   format %{ %}
 4800   interface(REG_INTER);
 4801 %}
 4802 
 4803 operand iRegN_R3()
 4804 %{
 4805   constraint(ALLOC_IN_RC(r3_reg));
 4806   match(iRegN);
 4807   op_cost(0);
 4808   format %{ %}
 4809   interface(REG_INTER);
 4810 %}
 4811 
 4812 // Integer 64 bit Register not Special
 4813 operand iRegNNoSp()
 4814 %{
 4815   constraint(ALLOC_IN_RC(no_special_reg32));
 4816   match(RegN);
 4817   op_cost(0);
 4818   format %{ %}
 4819   interface(REG_INTER);
 4820 %}
 4821 
 4822 // heap base register -- used for encoding immN0
 4823 
 4824 operand iRegIHeapbase()
 4825 %{
 4826   constraint(ALLOC_IN_RC(heapbase_reg));
 4827   match(RegI);
 4828   op_cost(0);
 4829   format %{ %}
 4830   interface(REG_INTER);
 4831 %}
 4832 
 4833 // Float Register
 4834 // Float register operands
 4835 operand vRegF()
 4836 %{
 4837   constraint(ALLOC_IN_RC(float_reg));
 4838   match(RegF);
 4839 
 4840   op_cost(0);
 4841   format %{ %}
 4842   interface(REG_INTER);
 4843 %}
 4844 
 4845 // Double Register
 4846 // Double register operands
 4847 operand vRegD()
 4848 %{
 4849   constraint(ALLOC_IN_RC(double_reg));
 4850   match(RegD);
 4851 
 4852   op_cost(0);
 4853   format %{ %}
 4854   interface(REG_INTER);
 4855 %}
 4856 
 4857 operand vecD()
 4858 %{
 4859   constraint(ALLOC_IN_RC(vectord_reg));
 4860   match(VecD);
 4861 
 4862   op_cost(0);
 4863   format %{ %}
 4864   interface(REG_INTER);
 4865 %}
 4866 
 4867 operand vecX()
 4868 %{
 4869   constraint(ALLOC_IN_RC(vectorx_reg));
 4870   match(VecX);
 4871 
 4872   op_cost(0);
 4873   format %{ %}
 4874   interface(REG_INTER);
 4875 %}
 4876 
 4877 operand vRegD_V0()
 4878 %{
 4879   constraint(ALLOC_IN_RC(v0_reg));
 4880   match(RegD);
 4881   op_cost(0);
 4882   format %{ %}
 4883   interface(REG_INTER);
 4884 %}
 4885 
 4886 operand vRegD_V1()
 4887 %{
 4888   constraint(ALLOC_IN_RC(v1_reg));
 4889   match(RegD);
 4890   op_cost(0);
 4891   format %{ %}
 4892   interface(REG_INTER);
 4893 %}
 4894 
 4895 operand vRegD_V2()
 4896 %{
 4897   constraint(ALLOC_IN_RC(v2_reg));
 4898   match(RegD);
 4899   op_cost(0);
 4900   format %{ %}
 4901   interface(REG_INTER);
 4902 %}
 4903 
 4904 operand vRegD_V3()
 4905 %{
 4906   constraint(ALLOC_IN_RC(v3_reg));
 4907   match(RegD);
 4908   op_cost(0);
 4909   format %{ %}
 4910   interface(REG_INTER);
 4911 %}
 4912 
 4913 operand vRegD_V4()
 4914 %{
 4915   constraint(ALLOC_IN_RC(v4_reg));
 4916   match(RegD);
 4917   op_cost(0);
 4918   format %{ %}
 4919   interface(REG_INTER);
 4920 %}
 4921 
 4922 operand vRegD_V5()
 4923 %{
 4924   constraint(ALLOC_IN_RC(v5_reg));
 4925   match(RegD);
 4926   op_cost(0);
 4927   format %{ %}
 4928   interface(REG_INTER);
 4929 %}
 4930 
 4931 operand vRegD_V6()
 4932 %{
 4933   constraint(ALLOC_IN_RC(v6_reg));
 4934   match(RegD);
 4935   op_cost(0);
 4936   format %{ %}
 4937   interface(REG_INTER);
 4938 %}
 4939 
 4940 operand vRegD_V7()
 4941 %{
 4942   constraint(ALLOC_IN_RC(v7_reg));
 4943   match(RegD);
 4944   op_cost(0);
 4945   format %{ %}
 4946   interface(REG_INTER);
 4947 %}
 4948 
 4949 operand vRegD_V8()
 4950 %{
 4951   constraint(ALLOC_IN_RC(v8_reg));
 4952   match(RegD);
 4953   op_cost(0);
 4954   format %{ %}
 4955   interface(REG_INTER);
 4956 %}
 4957 
 4958 operand vRegD_V9()
 4959 %{
 4960   constraint(ALLOC_IN_RC(v9_reg));
 4961   match(RegD);
 4962   op_cost(0);
 4963   format %{ %}
 4964   interface(REG_INTER);
 4965 %}
 4966 
 4967 operand vRegD_V10()
 4968 %{
 4969   constraint(ALLOC_IN_RC(v10_reg));
 4970   match(RegD);
 4971   op_cost(0);
 4972   format %{ %}
 4973   interface(REG_INTER);
 4974 %}
 4975 
 4976 operand vRegD_V11()
 4977 %{
 4978   constraint(ALLOC_IN_RC(v11_reg));
 4979   match(RegD);
 4980   op_cost(0);
 4981   format %{ %}
 4982   interface(REG_INTER);
 4983 %}
 4984 
 4985 operand vRegD_V12()
 4986 %{
 4987   constraint(ALLOC_IN_RC(v12_reg));
 4988   match(RegD);
 4989   op_cost(0);
 4990   format %{ %}
 4991   interface(REG_INTER);
 4992 %}
 4993 
 4994 operand vRegD_V13()
 4995 %{
 4996   constraint(ALLOC_IN_RC(v13_reg));
 4997   match(RegD);
 4998   op_cost(0);
 4999   format %{ %}
 5000   interface(REG_INTER);
 5001 %}
 5002 
 5003 operand vRegD_V14()
 5004 %{
 5005   constraint(ALLOC_IN_RC(v14_reg));
 5006   match(RegD);
 5007   op_cost(0);
 5008   format %{ %}
 5009   interface(REG_INTER);
 5010 %}
 5011 
 5012 operand vRegD_V15()
 5013 %{
 5014   constraint(ALLOC_IN_RC(v15_reg));
 5015   match(RegD);
 5016   op_cost(0);
 5017   format %{ %}
 5018   interface(REG_INTER);
 5019 %}
 5020 
 5021 operand vRegD_V16()
 5022 %{
 5023   constraint(ALLOC_IN_RC(v16_reg));
 5024   match(RegD);
 5025   op_cost(0);
 5026   format %{ %}
 5027   interface(REG_INTER);
 5028 %}
 5029 
 5030 operand vRegD_V17()
 5031 %{
 5032   constraint(ALLOC_IN_RC(v17_reg));
 5033   match(RegD);
 5034   op_cost(0);
 5035   format %{ %}
 5036   interface(REG_INTER);
 5037 %}
 5038 
 5039 operand vRegD_V18()
 5040 %{
 5041   constraint(ALLOC_IN_RC(v18_reg));
 5042   match(RegD);
 5043   op_cost(0);
 5044   format %{ %}
 5045   interface(REG_INTER);
 5046 %}
 5047 
 5048 operand vRegD_V19()
 5049 %{
 5050   constraint(ALLOC_IN_RC(v19_reg));
 5051   match(RegD);
 5052   op_cost(0);
 5053   format %{ %}
 5054   interface(REG_INTER);
 5055 %}
 5056 
 5057 operand vRegD_V20()
 5058 %{
 5059   constraint(ALLOC_IN_RC(v20_reg));
 5060   match(RegD);
 5061   op_cost(0);
 5062   format %{ %}
 5063   interface(REG_INTER);
 5064 %}
 5065 
 5066 operand vRegD_V21()
 5067 %{
 5068   constraint(ALLOC_IN_RC(v21_reg));
 5069   match(RegD);
 5070   op_cost(0);
 5071   format %{ %}
 5072   interface(REG_INTER);
 5073 %}
 5074 
 5075 operand vRegD_V22()
 5076 %{
 5077   constraint(ALLOC_IN_RC(v22_reg));
 5078   match(RegD);
 5079   op_cost(0);
 5080   format %{ %}
 5081   interface(REG_INTER);
 5082 %}
 5083 
 5084 operand vRegD_V23()
 5085 %{
 5086   constraint(ALLOC_IN_RC(v23_reg));
 5087   match(RegD);
 5088   op_cost(0);
 5089   format %{ %}
 5090   interface(REG_INTER);
 5091 %}
 5092 
 5093 operand vRegD_V24()
 5094 %{
 5095   constraint(ALLOC_IN_RC(v24_reg));
 5096   match(RegD);
 5097   op_cost(0);
 5098   format %{ %}
 5099   interface(REG_INTER);
 5100 %}
 5101 
 5102 operand vRegD_V25()
 5103 %{
 5104   constraint(ALLOC_IN_RC(v25_reg));
 5105   match(RegD);
 5106   op_cost(0);
 5107   format %{ %}
 5108   interface(REG_INTER);
 5109 %}
 5110 
 5111 operand vRegD_V26()
 5112 %{
 5113   constraint(ALLOC_IN_RC(v26_reg));
 5114   match(RegD);
 5115   op_cost(0);
 5116   format %{ %}
 5117   interface(REG_INTER);
 5118 %}
 5119 
 5120 operand vRegD_V27()
 5121 %{
 5122   constraint(ALLOC_IN_RC(v27_reg));
 5123   match(RegD);
 5124   op_cost(0);
 5125   format %{ %}
 5126   interface(REG_INTER);
 5127 %}
 5128 
 5129 operand vRegD_V28()
 5130 %{
 5131   constraint(ALLOC_IN_RC(v28_reg));
 5132   match(RegD);
 5133   op_cost(0);
 5134   format %{ %}
 5135   interface(REG_INTER);
 5136 %}
 5137 
 5138 operand vRegD_V29()
 5139 %{
 5140   constraint(ALLOC_IN_RC(v29_reg));
 5141   match(RegD);
 5142   op_cost(0);
 5143   format %{ %}
 5144   interface(REG_INTER);
 5145 %}
 5146 
 5147 operand vRegD_V30()
 5148 %{
 5149   constraint(ALLOC_IN_RC(v30_reg));
 5150   match(RegD);
 5151   op_cost(0);
 5152   format %{ %}
 5153   interface(REG_INTER);
 5154 %}
 5155 
 5156 operand vRegD_V31()
 5157 %{
 5158   constraint(ALLOC_IN_RC(v31_reg));
 5159   match(RegD);
 5160   op_cost(0);
 5161   format %{ %}
 5162   interface(REG_INTER);
 5163 %}
 5164 
 5165 // Flags register, used as output of signed compare instructions
 5166 
 5167 // note that on AArch64 we also use this register as the output for
 5168 // for floating point compare instructions (CmpF CmpD). this ensures
 5169 // that ordered inequality tests use GT, GE, LT or LE none of which
 5170 // pass through cases where the result is unordered i.e. one or both
 5171 // inputs to the compare is a NaN. this means that the ideal code can
 5172 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5173 // (where the comparison should always fail). EQ and NE tests are
 5174 // always generated in ideal code so that unordered folds into the NE
 5175 // case, matching the behaviour of AArch64 NE.
 5176 //
 5177 // This differs from x86 where the outputs of FP compares use a
 5178 // special FP flags registers and where compares based on this
 5179 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5180 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5181 // to explicitly handle the unordered case in branches. x86 also has
 5182 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5183 
 5184 operand rFlagsReg()
 5185 %{
 5186   constraint(ALLOC_IN_RC(int_flags));
 5187   match(RegFlags);
 5188 
 5189   op_cost(0);
 5190   format %{ &quot;RFLAGS&quot; %}
 5191   interface(REG_INTER);
 5192 %}
 5193 
 5194 // Flags register, used as output of unsigned compare instructions
 5195 operand rFlagsRegU()
 5196 %{
 5197   constraint(ALLOC_IN_RC(int_flags));
 5198   match(RegFlags);
 5199 
 5200   op_cost(0);
 5201   format %{ &quot;RFLAGSU&quot; %}
 5202   interface(REG_INTER);
 5203 %}
 5204 
 5205 // Special Registers
 5206 
 5207 // Method Register
 5208 operand inline_cache_RegP(iRegP reg)
 5209 %{
 5210   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5211   match(reg);
 5212   match(iRegPNoSp);
 5213   op_cost(0);
 5214   format %{ %}
 5215   interface(REG_INTER);
 5216 %}
 5217 
 5218 operand interpreter_method_oop_RegP(iRegP reg)
 5219 %{
 5220   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5221   match(reg);
 5222   match(iRegPNoSp);
 5223   op_cost(0);
 5224   format %{ %}
 5225   interface(REG_INTER);
 5226 %}
 5227 
 5228 // Thread Register
 5229 operand thread_RegP(iRegP reg)
 5230 %{
 5231   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5232   match(reg);
 5233   op_cost(0);
 5234   format %{ %}
 5235   interface(REG_INTER);
 5236 %}
 5237 
 5238 operand lr_RegP(iRegP reg)
 5239 %{
 5240   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5241   match(reg);
 5242   op_cost(0);
 5243   format %{ %}
 5244   interface(REG_INTER);
 5245 %}
 5246 
 5247 //----------Memory Operands----------------------------------------------------
 5248 
 5249 operand indirect(iRegP reg)
 5250 %{
 5251   constraint(ALLOC_IN_RC(ptr_reg));
 5252   match(reg);
 5253   op_cost(0);
 5254   format %{ &quot;[$reg]&quot; %}
 5255   interface(MEMORY_INTER) %{
 5256     base($reg);
 5257     index(0xffffffff);
 5258     scale(0x0);
 5259     disp(0x0);
 5260   %}
 5261 %}
 5262 
 5263 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5264 %{
 5265   constraint(ALLOC_IN_RC(ptr_reg));
 5266   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5267   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5268   op_cost(0);
 5269   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5270   interface(MEMORY_INTER) %{
 5271     base($reg);
 5272     index($ireg);
 5273     scale($scale);
 5274     disp(0x0);
 5275   %}
 5276 %}
 5277 
 5278 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5279 %{
 5280   constraint(ALLOC_IN_RC(ptr_reg));
 5281   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5282   match(AddP reg (LShiftL lreg scale));
 5283   op_cost(0);
 5284   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5285   interface(MEMORY_INTER) %{
 5286     base($reg);
 5287     index($lreg);
 5288     scale($scale);
 5289     disp(0x0);
 5290   %}
 5291 %}
 5292 
 5293 operand indIndexI2L(iRegP reg, iRegI ireg)
 5294 %{
 5295   constraint(ALLOC_IN_RC(ptr_reg));
 5296   match(AddP reg (ConvI2L ireg));
 5297   op_cost(0);
 5298   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5299   interface(MEMORY_INTER) %{
 5300     base($reg);
 5301     index($ireg);
 5302     scale(0x0);
 5303     disp(0x0);
 5304   %}
 5305 %}
 5306 
 5307 operand indIndex(iRegP reg, iRegL lreg)
 5308 %{
 5309   constraint(ALLOC_IN_RC(ptr_reg));
 5310   match(AddP reg lreg);
 5311   op_cost(0);
 5312   format %{ &quot;$reg, $lreg&quot; %}
 5313   interface(MEMORY_INTER) %{
 5314     base($reg);
 5315     index($lreg);
 5316     scale(0x0);
 5317     disp(0x0);
 5318   %}
 5319 %}
 5320 
 5321 operand indOffI(iRegP reg, immIOffset off)
 5322 %{
 5323   constraint(ALLOC_IN_RC(ptr_reg));
 5324   match(AddP reg off);
 5325   op_cost(0);
 5326   format %{ &quot;[$reg, $off]&quot; %}
 5327   interface(MEMORY_INTER) %{
 5328     base($reg);
 5329     index(0xffffffff);
 5330     scale(0x0);
 5331     disp($off);
 5332   %}
 5333 %}
 5334 
 5335 operand indOffI1(iRegP reg, immIOffset1 off)
 5336 %{
 5337   constraint(ALLOC_IN_RC(ptr_reg));
 5338   match(AddP reg off);
 5339   op_cost(0);
 5340   format %{ &quot;[$reg, $off]&quot; %}
 5341   interface(MEMORY_INTER) %{
 5342     base($reg);
 5343     index(0xffffffff);
 5344     scale(0x0);
 5345     disp($off);
 5346   %}
 5347 %}
 5348 
 5349 operand indOffI2(iRegP reg, immIOffset2 off)
 5350 %{
 5351   constraint(ALLOC_IN_RC(ptr_reg));
 5352   match(AddP reg off);
 5353   op_cost(0);
 5354   format %{ &quot;[$reg, $off]&quot; %}
 5355   interface(MEMORY_INTER) %{
 5356     base($reg);
 5357     index(0xffffffff);
 5358     scale(0x0);
 5359     disp($off);
 5360   %}
 5361 %}
 5362 
 5363 operand indOffI4(iRegP reg, immIOffset4 off)
 5364 %{
 5365   constraint(ALLOC_IN_RC(ptr_reg));
 5366   match(AddP reg off);
 5367   op_cost(0);
 5368   format %{ &quot;[$reg, $off]&quot; %}
 5369   interface(MEMORY_INTER) %{
 5370     base($reg);
 5371     index(0xffffffff);
 5372     scale(0x0);
 5373     disp($off);
 5374   %}
 5375 %}
 5376 
 5377 operand indOffI8(iRegP reg, immIOffset8 off)
 5378 %{
 5379   constraint(ALLOC_IN_RC(ptr_reg));
 5380   match(AddP reg off);
 5381   op_cost(0);
 5382   format %{ &quot;[$reg, $off]&quot; %}
 5383   interface(MEMORY_INTER) %{
 5384     base($reg);
 5385     index(0xffffffff);
 5386     scale(0x0);
 5387     disp($off);
 5388   %}
 5389 %}
 5390 
 5391 operand indOffI16(iRegP reg, immIOffset16 off)
 5392 %{
 5393   constraint(ALLOC_IN_RC(ptr_reg));
 5394   match(AddP reg off);
 5395   op_cost(0);
 5396   format %{ &quot;[$reg, $off]&quot; %}
 5397   interface(MEMORY_INTER) %{
 5398     base($reg);
 5399     index(0xffffffff);
 5400     scale(0x0);
 5401     disp($off);
 5402   %}
 5403 %}
 5404 
 5405 operand indOffL(iRegP reg, immLoffset off)
 5406 %{
 5407   constraint(ALLOC_IN_RC(ptr_reg));
 5408   match(AddP reg off);
 5409   op_cost(0);
 5410   format %{ &quot;[$reg, $off]&quot; %}
 5411   interface(MEMORY_INTER) %{
 5412     base($reg);
 5413     index(0xffffffff);
 5414     scale(0x0);
 5415     disp($off);
 5416   %}
 5417 %}
 5418 
 5419 operand indOffL1(iRegP reg, immLoffset1 off)
 5420 %{
 5421   constraint(ALLOC_IN_RC(ptr_reg));
 5422   match(AddP reg off);
 5423   op_cost(0);
 5424   format %{ &quot;[$reg, $off]&quot; %}
 5425   interface(MEMORY_INTER) %{
 5426     base($reg);
 5427     index(0xffffffff);
 5428     scale(0x0);
 5429     disp($off);
 5430   %}
 5431 %}
 5432 
 5433 operand indOffL2(iRegP reg, immLoffset2 off)
 5434 %{
 5435   constraint(ALLOC_IN_RC(ptr_reg));
 5436   match(AddP reg off);
 5437   op_cost(0);
 5438   format %{ &quot;[$reg, $off]&quot; %}
 5439   interface(MEMORY_INTER) %{
 5440     base($reg);
 5441     index(0xffffffff);
 5442     scale(0x0);
 5443     disp($off);
 5444   %}
 5445 %}
 5446 
 5447 operand indOffL4(iRegP reg, immLoffset4 off)
 5448 %{
 5449   constraint(ALLOC_IN_RC(ptr_reg));
 5450   match(AddP reg off);
 5451   op_cost(0);
 5452   format %{ &quot;[$reg, $off]&quot; %}
 5453   interface(MEMORY_INTER) %{
 5454     base($reg);
 5455     index(0xffffffff);
 5456     scale(0x0);
 5457     disp($off);
 5458   %}
 5459 %}
 5460 
 5461 operand indOffL8(iRegP reg, immLoffset8 off)
 5462 %{
 5463   constraint(ALLOC_IN_RC(ptr_reg));
 5464   match(AddP reg off);
 5465   op_cost(0);
 5466   format %{ &quot;[$reg, $off]&quot; %}
 5467   interface(MEMORY_INTER) %{
 5468     base($reg);
 5469     index(0xffffffff);
 5470     scale(0x0);
 5471     disp($off);
 5472   %}
 5473 %}
 5474 
 5475 operand indOffL16(iRegP reg, immLoffset16 off)
 5476 %{
 5477   constraint(ALLOC_IN_RC(ptr_reg));
 5478   match(AddP reg off);
 5479   op_cost(0);
 5480   format %{ &quot;[$reg, $off]&quot; %}
 5481   interface(MEMORY_INTER) %{
 5482     base($reg);
 5483     index(0xffffffff);
 5484     scale(0x0);
 5485     disp($off);
 5486   %}
 5487 %}
 5488 
 5489 operand indirectN(iRegN reg)
 5490 %{
 5491   predicate(CompressedOops::shift() == 0);
 5492   constraint(ALLOC_IN_RC(ptr_reg));
 5493   match(DecodeN reg);
 5494   op_cost(0);
 5495   format %{ &quot;[$reg]\t# narrow&quot; %}
 5496   interface(MEMORY_INTER) %{
 5497     base($reg);
 5498     index(0xffffffff);
 5499     scale(0x0);
 5500     disp(0x0);
 5501   %}
 5502 %}
 5503 
 5504 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5505 %{
 5506   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5507   constraint(ALLOC_IN_RC(ptr_reg));
 5508   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5509   op_cost(0);
 5510   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5511   interface(MEMORY_INTER) %{
 5512     base($reg);
 5513     index($ireg);
 5514     scale($scale);
 5515     disp(0x0);
 5516   %}
 5517 %}
 5518 
 5519 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5520 %{
 5521   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5522   constraint(ALLOC_IN_RC(ptr_reg));
 5523   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5524   op_cost(0);
 5525   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5526   interface(MEMORY_INTER) %{
 5527     base($reg);
 5528     index($lreg);
 5529     scale($scale);
 5530     disp(0x0);
 5531   %}
 5532 %}
 5533 
 5534 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5535 %{
 5536   predicate(CompressedOops::shift() == 0);
 5537   constraint(ALLOC_IN_RC(ptr_reg));
 5538   match(AddP (DecodeN reg) (ConvI2L ireg));
 5539   op_cost(0);
 5540   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5541   interface(MEMORY_INTER) %{
 5542     base($reg);
 5543     index($ireg);
 5544     scale(0x0);
 5545     disp(0x0);
 5546   %}
 5547 %}
 5548 
 5549 operand indIndexN(iRegN reg, iRegL lreg)
 5550 %{
 5551   predicate(CompressedOops::shift() == 0);
 5552   constraint(ALLOC_IN_RC(ptr_reg));
 5553   match(AddP (DecodeN reg) lreg);
 5554   op_cost(0);
 5555   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5556   interface(MEMORY_INTER) %{
 5557     base($reg);
 5558     index($lreg);
 5559     scale(0x0);
 5560     disp(0x0);
 5561   %}
 5562 %}
 5563 
 5564 operand indOffIN(iRegN reg, immIOffset off)
 5565 %{
 5566   predicate(CompressedOops::shift() == 0);
 5567   constraint(ALLOC_IN_RC(ptr_reg));
 5568   match(AddP (DecodeN reg) off);
 5569   op_cost(0);
 5570   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5571   interface(MEMORY_INTER) %{
 5572     base($reg);
 5573     index(0xffffffff);
 5574     scale(0x0);
 5575     disp($off);
 5576   %}
 5577 %}
 5578 
 5579 operand indOffLN(iRegN reg, immLoffset off)
 5580 %{
 5581   predicate(CompressedOops::shift() == 0);
 5582   constraint(ALLOC_IN_RC(ptr_reg));
 5583   match(AddP (DecodeN reg) off);
 5584   op_cost(0);
 5585   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5586   interface(MEMORY_INTER) %{
 5587     base($reg);
 5588     index(0xffffffff);
 5589     scale(0x0);
 5590     disp($off);
 5591   %}
 5592 %}
 5593 
 5594 
 5595 
 5596 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5597 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5598 %{
 5599   constraint(ALLOC_IN_RC(ptr_reg));
 5600   match(AddP reg off);
 5601   op_cost(0);
 5602   format %{ &quot;[$reg, $off]&quot; %}
 5603   interface(MEMORY_INTER) %{
 5604     base($reg);
 5605     index(0xffffffff);
 5606     scale(0x0);
 5607     disp($off);
 5608   %}
 5609 %}
 5610 
 5611 //----------Special Memory Operands--------------------------------------------
 5612 // Stack Slot Operand - This operand is used for loading and storing temporary
 5613 //                      values on the stack where a match requires a value to
 5614 //                      flow through memory.
 5615 operand stackSlotP(sRegP reg)
 5616 %{
 5617   constraint(ALLOC_IN_RC(stack_slots));
 5618   op_cost(100);
 5619   // No match rule because this operand is only generated in matching
 5620   // match(RegP);
 5621   format %{ &quot;[$reg]&quot; %}
 5622   interface(MEMORY_INTER) %{
 5623     base(0x1e);  // RSP
 5624     index(0x0);  // No Index
 5625     scale(0x0);  // No Scale
 5626     disp($reg);  // Stack Offset
 5627   %}
 5628 %}
 5629 
 5630 operand stackSlotI(sRegI reg)
 5631 %{
 5632   constraint(ALLOC_IN_RC(stack_slots));
 5633   // No match rule because this operand is only generated in matching
 5634   // match(RegI);
 5635   format %{ &quot;[$reg]&quot; %}
 5636   interface(MEMORY_INTER) %{
 5637     base(0x1e);  // RSP
 5638     index(0x0);  // No Index
 5639     scale(0x0);  // No Scale
 5640     disp($reg);  // Stack Offset
 5641   %}
 5642 %}
 5643 
 5644 operand stackSlotF(sRegF reg)
 5645 %{
 5646   constraint(ALLOC_IN_RC(stack_slots));
 5647   // No match rule because this operand is only generated in matching
 5648   // match(RegF);
 5649   format %{ &quot;[$reg]&quot; %}
 5650   interface(MEMORY_INTER) %{
 5651     base(0x1e);  // RSP
 5652     index(0x0);  // No Index
 5653     scale(0x0);  // No Scale
 5654     disp($reg);  // Stack Offset
 5655   %}
 5656 %}
 5657 
 5658 operand stackSlotD(sRegD reg)
 5659 %{
 5660   constraint(ALLOC_IN_RC(stack_slots));
 5661   // No match rule because this operand is only generated in matching
 5662   // match(RegD);
 5663   format %{ &quot;[$reg]&quot; %}
 5664   interface(MEMORY_INTER) %{
 5665     base(0x1e);  // RSP
 5666     index(0x0);  // No Index
 5667     scale(0x0);  // No Scale
 5668     disp($reg);  // Stack Offset
 5669   %}
 5670 %}
 5671 
 5672 operand stackSlotL(sRegL reg)
 5673 %{
 5674   constraint(ALLOC_IN_RC(stack_slots));
 5675   // No match rule because this operand is only generated in matching
 5676   // match(RegL);
 5677   format %{ &quot;[$reg]&quot; %}
 5678   interface(MEMORY_INTER) %{
 5679     base(0x1e);  // RSP
 5680     index(0x0);  // No Index
 5681     scale(0x0);  // No Scale
 5682     disp($reg);  // Stack Offset
 5683   %}
 5684 %}
 5685 
 5686 // Operands for expressing Control Flow
 5687 // NOTE: Label is a predefined operand which should not be redefined in
 5688 //       the AD file. It is generically handled within the ADLC.
 5689 
 5690 //----------Conditional Branch Operands----------------------------------------
 5691 // Comparison Op  - This is the operation of the comparison, and is limited to
 5692 //                  the following set of codes:
 5693 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5694 //
 5695 // Other attributes of the comparison, such as unsignedness, are specified
 5696 // by the comparison instruction that sets a condition code flags register.
 5697 // That result is represented by a flags operand whose subtype is appropriate
 5698 // to the unsignedness (etc.) of the comparison.
 5699 //
 5700 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5701 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5702 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5703 
 5704 // used for signed integral comparisons and fp comparisons
 5705 
 5706 operand cmpOp()
 5707 %{
 5708   match(Bool);
 5709 
 5710   format %{ &quot;&quot; %}
 5711   interface(COND_INTER) %{
 5712     equal(0x0, &quot;eq&quot;);
 5713     not_equal(0x1, &quot;ne&quot;);
 5714     less(0xb, &quot;lt&quot;);
 5715     greater_equal(0xa, &quot;ge&quot;);
 5716     less_equal(0xd, &quot;le&quot;);
 5717     greater(0xc, &quot;gt&quot;);
 5718     overflow(0x6, &quot;vs&quot;);
 5719     no_overflow(0x7, &quot;vc&quot;);
 5720   %}
 5721 %}
 5722 
 5723 // used for unsigned integral comparisons
 5724 
 5725 operand cmpOpU()
 5726 %{
 5727   match(Bool);
 5728 
 5729   format %{ &quot;&quot; %}
 5730   interface(COND_INTER) %{
 5731     equal(0x0, &quot;eq&quot;);
 5732     not_equal(0x1, &quot;ne&quot;);
 5733     less(0x3, &quot;lo&quot;);
 5734     greater_equal(0x2, &quot;hs&quot;);
 5735     less_equal(0x9, &quot;ls&quot;);
 5736     greater(0x8, &quot;hi&quot;);
 5737     overflow(0x6, &quot;vs&quot;);
 5738     no_overflow(0x7, &quot;vc&quot;);
 5739   %}
 5740 %}
 5741 
 5742 // used for certain integral comparisons which can be
 5743 // converted to cbxx or tbxx instructions
 5744 
 5745 operand cmpOpEqNe()
 5746 %{
 5747   match(Bool);
 5748   op_cost(0);
 5749   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5750             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5751 
 5752   format %{ &quot;&quot; %}
 5753   interface(COND_INTER) %{
 5754     equal(0x0, &quot;eq&quot;);
 5755     not_equal(0x1, &quot;ne&quot;);
 5756     less(0xb, &quot;lt&quot;);
 5757     greater_equal(0xa, &quot;ge&quot;);
 5758     less_equal(0xd, &quot;le&quot;);
 5759     greater(0xc, &quot;gt&quot;);
 5760     overflow(0x6, &quot;vs&quot;);
 5761     no_overflow(0x7, &quot;vc&quot;);
 5762   %}
 5763 %}
 5764 
 5765 // used for certain integral comparisons which can be
 5766 // converted to cbxx or tbxx instructions
 5767 
 5768 operand cmpOpLtGe()
 5769 %{
 5770   match(Bool);
 5771   op_cost(0);
 5772 
 5773   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5774             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5775 
 5776   format %{ &quot;&quot; %}
 5777   interface(COND_INTER) %{
 5778     equal(0x0, &quot;eq&quot;);
 5779     not_equal(0x1, &quot;ne&quot;);
 5780     less(0xb, &quot;lt&quot;);
 5781     greater_equal(0xa, &quot;ge&quot;);
 5782     less_equal(0xd, &quot;le&quot;);
 5783     greater(0xc, &quot;gt&quot;);
 5784     overflow(0x6, &quot;vs&quot;);
 5785     no_overflow(0x7, &quot;vc&quot;);
 5786   %}
 5787 %}
 5788 
 5789 // used for certain unsigned integral comparisons which can be
 5790 // converted to cbxx or tbxx instructions
 5791 
 5792 operand cmpOpUEqNeLtGe()
 5793 %{
 5794   match(Bool);
 5795   op_cost(0);
 5796 
 5797   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5798             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5799             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5800             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5801 
 5802   format %{ &quot;&quot; %}
 5803   interface(COND_INTER) %{
 5804     equal(0x0, &quot;eq&quot;);
 5805     not_equal(0x1, &quot;ne&quot;);
 5806     less(0xb, &quot;lt&quot;);
 5807     greater_equal(0xa, &quot;ge&quot;);
 5808     less_equal(0xd, &quot;le&quot;);
 5809     greater(0xc, &quot;gt&quot;);
 5810     overflow(0x6, &quot;vs&quot;);
 5811     no_overflow(0x7, &quot;vc&quot;);
 5812   %}
 5813 %}
 5814 
 5815 // Special operand allowing long args to int ops to be truncated for free
 5816 
 5817 operand iRegL2I(iRegL reg) %{
 5818 
 5819   op_cost(0);
 5820 
 5821   match(ConvL2I reg);
 5822 
 5823   format %{ &quot;l2i($reg)&quot; %}
 5824 
 5825   interface(REG_INTER)
 5826 %}
 5827 
 5828 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5829 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5830 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5831 
 5832 //----------OPERAND CLASSES----------------------------------------------------
 5833 // Operand Classes are groups of operands that are used as to simplify
 5834 // instruction definitions by not requiring the AD writer to specify
 5835 // separate instructions for every form of operand when the
 5836 // instruction accepts multiple operand types with the same basic
 5837 // encoding and format. The classic case of this is memory operands.
 5838 
 5839 // memory is used to define read/write location for load/store
 5840 // instruction defs. we can turn a memory op into an Address
 5841 
 5842 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5843                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5844 
 5845 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5846                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5847 
 5848 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5849                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5850 
 5851 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5852                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5853 
 5854 // All of the memory operands. For the pipeline description.
 5855 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5856                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5857                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5858 
 5859 
 5860 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5861 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5862 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5863 // can be elided because the 32-bit instruction will just employ the
 5864 // lower 32 bits anyway.
 5865 //
 5866 // n.b. this does not elide all L2I conversions. if the truncated
 5867 // value is consumed by more than one operation then the ConvL2I
 5868 // cannot be bundled into the consuming nodes so an l2i gets planted
 5869 // (actually a movw $dst $src) and the downstream instructions consume
 5870 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5871 // movw is actually redundant but its not too costly.
 5872 
 5873 opclass iRegIorL2I(iRegI, iRegL2I);
 5874 
 5875 //----------PIPELINE-----------------------------------------------------------
 5876 // Rules which define the behavior of the target architectures pipeline.
 5877 
 5878 // For specific pipelines, eg A53, define the stages of that pipeline
 5879 //pipe_desc(ISS, EX1, EX2, WR);
 5880 #define ISS S0
 5881 #define EX1 S1
 5882 #define EX2 S2
 5883 #define WR  S3
 5884 
 5885 // Integer ALU reg operation
 5886 pipeline %{
 5887 
 5888 attributes %{
 5889   // ARM instructions are of fixed length
 5890   fixed_size_instructions;        // Fixed size instructions TODO does
 5891   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5892   // ARM instructions come in 32-bit word units
 5893   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5894   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5895   instruction_fetch_units = 1;       // of 64 bytes
 5896 
 5897   // List of nop instructions
 5898   nops( MachNop );
 5899 %}
 5900 
 5901 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5902 // or description. we do use pipeline classes to introduce fixed
 5903 // latencies
 5904 
 5905 //----------RESOURCES----------------------------------------------------------
 5906 // Resources are the functional units available to the machine
 5907 
 5908 resources( INS0, INS1, INS01 = INS0 | INS1,
 5909            ALU0, ALU1, ALU = ALU0 | ALU1,
 5910            MAC,
 5911            DIV,
 5912            BRANCH,
 5913            LDST,
 5914            NEON_FP);
 5915 
 5916 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5917 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5918 
 5919 // Define the pipeline as a generic 6 stage pipeline
 5920 pipe_desc(S0, S1, S2, S3, S4, S5);
 5921 
 5922 //----------PIPELINE CLASSES---------------------------------------------------
 5923 // Pipeline Classes describe the stages in which input and output are
 5924 // referenced by the hardware pipeline.
 5925 
 5926 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5927 %{
 5928   single_instruction;
 5929   src1   : S1(read);
 5930   src2   : S2(read);
 5931   dst    : S5(write);
 5932   INS01  : ISS;
 5933   NEON_FP : S5;
 5934 %}
 5935 
 5936 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5937 %{
 5938   single_instruction;
 5939   src1   : S1(read);
 5940   src2   : S2(read);
 5941   dst    : S5(write);
 5942   INS01  : ISS;
 5943   NEON_FP : S5;
 5944 %}
 5945 
 5946 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5947 %{
 5948   single_instruction;
 5949   src    : S1(read);
 5950   dst    : S5(write);
 5951   INS01  : ISS;
 5952   NEON_FP : S5;
 5953 %}
 5954 
 5955 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5956 %{
 5957   single_instruction;
 5958   src    : S1(read);
 5959   dst    : S5(write);
 5960   INS01  : ISS;
 5961   NEON_FP : S5;
 5962 %}
 5963 
 5964 pipe_class fp_d2f(vRegF dst, vRegD src)
 5965 %{
 5966   single_instruction;
 5967   src    : S1(read);
 5968   dst    : S5(write);
 5969   INS01  : ISS;
 5970   NEON_FP : S5;
 5971 %}
 5972 
 5973 pipe_class fp_f2d(vRegD dst, vRegF src)
 5974 %{
 5975   single_instruction;
 5976   src    : S1(read);
 5977   dst    : S5(write);
 5978   INS01  : ISS;
 5979   NEON_FP : S5;
 5980 %}
 5981 
 5982 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5983 %{
 5984   single_instruction;
 5985   src    : S1(read);
 5986   dst    : S5(write);
 5987   INS01  : ISS;
 5988   NEON_FP : S5;
 5989 %}
 5990 
 5991 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 5992 %{
 5993   single_instruction;
 5994   src    : S1(read);
 5995   dst    : S5(write);
 5996   INS01  : ISS;
 5997   NEON_FP : S5;
 5998 %}
 5999 
 6000 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6001 %{
 6002   single_instruction;
 6003   src    : S1(read);
 6004   dst    : S5(write);
 6005   INS01  : ISS;
 6006   NEON_FP : S5;
 6007 %}
 6008 
 6009 pipe_class fp_l2f(vRegF dst, iRegL src)
 6010 %{
 6011   single_instruction;
 6012   src    : S1(read);
 6013   dst    : S5(write);
 6014   INS01  : ISS;
 6015   NEON_FP : S5;
 6016 %}
 6017 
 6018 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6019 %{
 6020   single_instruction;
 6021   src    : S1(read);
 6022   dst    : S5(write);
 6023   INS01  : ISS;
 6024   NEON_FP : S5;
 6025 %}
 6026 
 6027 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6028 %{
 6029   single_instruction;
 6030   src    : S1(read);
 6031   dst    : S5(write);
 6032   INS01  : ISS;
 6033   NEON_FP : S5;
 6034 %}
 6035 
 6036 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6037 %{
 6038   single_instruction;
 6039   src    : S1(read);
 6040   dst    : S5(write);
 6041   INS01  : ISS;
 6042   NEON_FP : S5;
 6043 %}
 6044 
 6045 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6046 %{
 6047   single_instruction;
 6048   src    : S1(read);
 6049   dst    : S5(write);
 6050   INS01  : ISS;
 6051   NEON_FP : S5;
 6052 %}
 6053 
 6054 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6055 %{
 6056   single_instruction;
 6057   src1   : S1(read);
 6058   src2   : S2(read);
 6059   dst    : S5(write);
 6060   INS0   : ISS;
 6061   NEON_FP : S5;
 6062 %}
 6063 
 6064 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6065 %{
 6066   single_instruction;
 6067   src1   : S1(read);
 6068   src2   : S2(read);
 6069   dst    : S5(write);
 6070   INS0   : ISS;
 6071   NEON_FP : S5;
 6072 %}
 6073 
 6074 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6075 %{
 6076   single_instruction;
 6077   cr     : S1(read);
 6078   src1   : S1(read);
 6079   src2   : S1(read);
 6080   dst    : S3(write);
 6081   INS01  : ISS;
 6082   NEON_FP : S3;
 6083 %}
 6084 
 6085 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6086 %{
 6087   single_instruction;
 6088   cr     : S1(read);
 6089   src1   : S1(read);
 6090   src2   : S1(read);
 6091   dst    : S3(write);
 6092   INS01  : ISS;
 6093   NEON_FP : S3;
 6094 %}
 6095 
 6096 pipe_class fp_imm_s(vRegF dst)
 6097 %{
 6098   single_instruction;
 6099   dst    : S3(write);
 6100   INS01  : ISS;
 6101   NEON_FP : S3;
 6102 %}
 6103 
 6104 pipe_class fp_imm_d(vRegD dst)
 6105 %{
 6106   single_instruction;
 6107   dst    : S3(write);
 6108   INS01  : ISS;
 6109   NEON_FP : S3;
 6110 %}
 6111 
 6112 pipe_class fp_load_constant_s(vRegF dst)
 6113 %{
 6114   single_instruction;
 6115   dst    : S4(write);
 6116   INS01  : ISS;
 6117   NEON_FP : S4;
 6118 %}
 6119 
 6120 pipe_class fp_load_constant_d(vRegD dst)
 6121 %{
 6122   single_instruction;
 6123   dst    : S4(write);
 6124   INS01  : ISS;
 6125   NEON_FP : S4;
 6126 %}
 6127 
 6128 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6129 %{
 6130   single_instruction;
 6131   dst    : S5(write);
 6132   src1   : S1(read);
 6133   src2   : S1(read);
 6134   INS01  : ISS;
 6135   NEON_FP : S5;
 6136 %}
 6137 
 6138 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6139 %{
 6140   single_instruction;
 6141   dst    : S5(write);
 6142   src1   : S1(read);
 6143   src2   : S1(read);
 6144   INS0   : ISS;
 6145   NEON_FP : S5;
 6146 %}
 6147 
 6148 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6149 %{
 6150   single_instruction;
 6151   dst    : S5(write);
 6152   src1   : S1(read);
 6153   src2   : S1(read);
 6154   dst    : S1(read);
 6155   INS01  : ISS;
 6156   NEON_FP : S5;
 6157 %}
 6158 
 6159 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6160 %{
 6161   single_instruction;
 6162   dst    : S5(write);
 6163   src1   : S1(read);
 6164   src2   : S1(read);
 6165   dst    : S1(read);
 6166   INS0   : ISS;
 6167   NEON_FP : S5;
 6168 %}
 6169 
 6170 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6171 %{
 6172   single_instruction;
 6173   dst    : S4(write);
 6174   src1   : S2(read);
 6175   src2   : S2(read);
 6176   INS01  : ISS;
 6177   NEON_FP : S4;
 6178 %}
 6179 
 6180 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6181 %{
 6182   single_instruction;
 6183   dst    : S4(write);
 6184   src1   : S2(read);
 6185   src2   : S2(read);
 6186   INS0   : ISS;
 6187   NEON_FP : S4;
 6188 %}
 6189 
 6190 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6191 %{
 6192   single_instruction;
 6193   dst    : S3(write);
 6194   src1   : S2(read);
 6195   src2   : S2(read);
 6196   INS01  : ISS;
 6197   NEON_FP : S3;
 6198 %}
 6199 
 6200 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6201 %{
 6202   single_instruction;
 6203   dst    : S3(write);
 6204   src1   : S2(read);
 6205   src2   : S2(read);
 6206   INS0   : ISS;
 6207   NEON_FP : S3;
 6208 %}
 6209 
 6210 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6211 %{
 6212   single_instruction;
 6213   dst    : S3(write);
 6214   src    : S1(read);
 6215   shift  : S1(read);
 6216   INS01  : ISS;
 6217   NEON_FP : S3;
 6218 %}
 6219 
 6220 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6221 %{
 6222   single_instruction;
 6223   dst    : S3(write);
 6224   src    : S1(read);
 6225   shift  : S1(read);
 6226   INS0   : ISS;
 6227   NEON_FP : S3;
 6228 %}
 6229 
 6230 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6231 %{
 6232   single_instruction;
 6233   dst    : S3(write);
 6234   src    : S1(read);
 6235   INS01  : ISS;
 6236   NEON_FP : S3;
 6237 %}
 6238 
 6239 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6240 %{
 6241   single_instruction;
 6242   dst    : S3(write);
 6243   src    : S1(read);
 6244   INS0   : ISS;
 6245   NEON_FP : S3;
 6246 %}
 6247 
 6248 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6249 %{
 6250   single_instruction;
 6251   dst    : S5(write);
 6252   src1   : S1(read);
 6253   src2   : S1(read);
 6254   INS01  : ISS;
 6255   NEON_FP : S5;
 6256 %}
 6257 
 6258 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6259 %{
 6260   single_instruction;
 6261   dst    : S5(write);
 6262   src1   : S1(read);
 6263   src2   : S1(read);
 6264   INS0   : ISS;
 6265   NEON_FP : S5;
 6266 %}
 6267 
 6268 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6269 %{
 6270   single_instruction;
 6271   dst    : S5(write);
 6272   src1   : S1(read);
 6273   src2   : S1(read);
 6274   INS0   : ISS;
 6275   NEON_FP : S5;
 6276 %}
 6277 
 6278 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6279 %{
 6280   single_instruction;
 6281   dst    : S5(write);
 6282   src1   : S1(read);
 6283   src2   : S1(read);
 6284   INS0   : ISS;
 6285   NEON_FP : S5;
 6286 %}
 6287 
 6288 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6289 %{
 6290   single_instruction;
 6291   dst    : S5(write);
 6292   src    : S1(read);
 6293   INS0   : ISS;
 6294   NEON_FP : S5;
 6295 %}
 6296 
 6297 pipe_class vunop_fp64(vecD dst, vecD src)
 6298 %{
 6299   single_instruction;
 6300   dst    : S5(write);
 6301   src    : S1(read);
 6302   INS01  : ISS;
 6303   NEON_FP : S5;
 6304 %}
 6305 
 6306 pipe_class vunop_fp128(vecX dst, vecX src)
 6307 %{
 6308   single_instruction;
 6309   dst    : S5(write);
 6310   src    : S1(read);
 6311   INS0   : ISS;
 6312   NEON_FP : S5;
 6313 %}
 6314 
 6315 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6316 %{
 6317   single_instruction;
 6318   dst    : S3(write);
 6319   src    : S1(read);
 6320   INS01  : ISS;
 6321   NEON_FP : S3;
 6322 %}
 6323 
 6324 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6325 %{
 6326   single_instruction;
 6327   dst    : S3(write);
 6328   src    : S1(read);
 6329   INS01  : ISS;
 6330   NEON_FP : S3;
 6331 %}
 6332 
 6333 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6334 %{
 6335   single_instruction;
 6336   dst    : S3(write);
 6337   src    : S1(read);
 6338   INS01  : ISS;
 6339   NEON_FP : S3;
 6340 %}
 6341 
 6342 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6343 %{
 6344   single_instruction;
 6345   dst    : S3(write);
 6346   src    : S1(read);
 6347   INS01  : ISS;
 6348   NEON_FP : S3;
 6349 %}
 6350 
 6351 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6352 %{
 6353   single_instruction;
 6354   dst    : S3(write);
 6355   src    : S1(read);
 6356   INS01  : ISS;
 6357   NEON_FP : S3;
 6358 %}
 6359 
 6360 pipe_class vmovi_reg_imm64(vecD dst)
 6361 %{
 6362   single_instruction;
 6363   dst    : S3(write);
 6364   INS01  : ISS;
 6365   NEON_FP : S3;
 6366 %}
 6367 
 6368 pipe_class vmovi_reg_imm128(vecX dst)
 6369 %{
 6370   single_instruction;
 6371   dst    : S3(write);
 6372   INS0   : ISS;
 6373   NEON_FP : S3;
 6374 %}
 6375 
 6376 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6377 %{
 6378   single_instruction;
 6379   dst    : S5(write);
 6380   mem    : ISS(read);
 6381   INS01  : ISS;
 6382   NEON_FP : S3;
 6383 %}
 6384 
 6385 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6386 %{
 6387   single_instruction;
 6388   dst    : S5(write);
 6389   mem    : ISS(read);
 6390   INS01  : ISS;
 6391   NEON_FP : S3;
 6392 %}
 6393 
 6394 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6395 %{
 6396   single_instruction;
 6397   mem    : ISS(read);
 6398   src    : S2(read);
 6399   INS01  : ISS;
 6400   NEON_FP : S3;
 6401 %}
 6402 
 6403 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6404 %{
 6405   single_instruction;
 6406   mem    : ISS(read);
 6407   src    : S2(read);
 6408   INS01  : ISS;
 6409   NEON_FP : S3;
 6410 %}
 6411 
 6412 //------- Integer ALU operations --------------------------
 6413 
 6414 // Integer ALU reg-reg operation
 6415 // Operands needed in EX1, result generated in EX2
 6416 // Eg.  ADD     x0, x1, x2
 6417 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6418 %{
 6419   single_instruction;
 6420   dst    : EX2(write);
 6421   src1   : EX1(read);
 6422   src2   : EX1(read);
 6423   INS01  : ISS; // Dual issue as instruction 0 or 1
 6424   ALU    : EX2;
 6425 %}
 6426 
 6427 // Integer ALU reg-reg operation with constant shift
 6428 // Shifted register must be available in LATE_ISS instead of EX1
 6429 // Eg.  ADD     x0, x1, x2, LSL #2
 6430 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6431 %{
 6432   single_instruction;
 6433   dst    : EX2(write);
 6434   src1   : EX1(read);
 6435   src2   : ISS(read);
 6436   INS01  : ISS;
 6437   ALU    : EX2;
 6438 %}
 6439 
 6440 // Integer ALU reg operation with constant shift
 6441 // Eg.  LSL     x0, x1, #shift
 6442 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6443 %{
 6444   single_instruction;
 6445   dst    : EX2(write);
 6446   src1   : ISS(read);
 6447   INS01  : ISS;
 6448   ALU    : EX2;
 6449 %}
 6450 
 6451 // Integer ALU reg-reg operation with variable shift
 6452 // Both operands must be available in LATE_ISS instead of EX1
 6453 // Result is available in EX1 instead of EX2
 6454 // Eg.  LSLV    x0, x1, x2
 6455 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6456 %{
 6457   single_instruction;
 6458   dst    : EX1(write);
 6459   src1   : ISS(read);
 6460   src2   : ISS(read);
 6461   INS01  : ISS;
 6462   ALU    : EX1;
 6463 %}
 6464 
 6465 // Integer ALU reg-reg operation with extract
 6466 // As for _vshift above, but result generated in EX2
 6467 // Eg.  EXTR    x0, x1, x2, #N
 6468 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6469 %{
 6470   single_instruction;
 6471   dst    : EX2(write);
 6472   src1   : ISS(read);
 6473   src2   : ISS(read);
 6474   INS1   : ISS; // Can only dual issue as Instruction 1
 6475   ALU    : EX1;
 6476 %}
 6477 
 6478 // Integer ALU reg operation
 6479 // Eg.  NEG     x0, x1
 6480 pipe_class ialu_reg(iRegI dst, iRegI src)
 6481 %{
 6482   single_instruction;
 6483   dst    : EX2(write);
 6484   src    : EX1(read);
 6485   INS01  : ISS;
 6486   ALU    : EX2;
 6487 %}
 6488 
 6489 // Integer ALU reg mmediate operation
 6490 // Eg.  ADD     x0, x1, #N
 6491 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6492 %{
 6493   single_instruction;
 6494   dst    : EX2(write);
 6495   src1   : EX1(read);
 6496   INS01  : ISS;
 6497   ALU    : EX2;
 6498 %}
 6499 
 6500 // Integer ALU immediate operation (no source operands)
 6501 // Eg.  MOV     x0, #N
 6502 pipe_class ialu_imm(iRegI dst)
 6503 %{
 6504   single_instruction;
 6505   dst    : EX1(write);
 6506   INS01  : ISS;
 6507   ALU    : EX1;
 6508 %}
 6509 
 6510 //------- Compare operation -------------------------------
 6511 
 6512 // Compare reg-reg
 6513 // Eg.  CMP     x0, x1
 6514 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6515 %{
 6516   single_instruction;
 6517 //  fixed_latency(16);
 6518   cr     : EX2(write);
 6519   op1    : EX1(read);
 6520   op2    : EX1(read);
 6521   INS01  : ISS;
 6522   ALU    : EX2;
 6523 %}
 6524 
 6525 // Compare reg-reg
 6526 // Eg.  CMP     x0, #N
 6527 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6528 %{
 6529   single_instruction;
 6530 //  fixed_latency(16);
 6531   cr     : EX2(write);
 6532   op1    : EX1(read);
 6533   INS01  : ISS;
 6534   ALU    : EX2;
 6535 %}
 6536 
 6537 //------- Conditional instructions ------------------------
 6538 
 6539 // Conditional no operands
 6540 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6541 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6542 %{
 6543   single_instruction;
 6544   cr     : EX1(read);
 6545   dst    : EX2(write);
 6546   INS01  : ISS;
 6547   ALU    : EX2;
 6548 %}
 6549 
 6550 // Conditional 2 operand
 6551 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6552 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6553 %{
 6554   single_instruction;
 6555   cr     : EX1(read);
 6556   src1   : EX1(read);
 6557   src2   : EX1(read);
 6558   dst    : EX2(write);
 6559   INS01  : ISS;
 6560   ALU    : EX2;
 6561 %}
 6562 
 6563 // Conditional 2 operand
 6564 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6565 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6566 %{
 6567   single_instruction;
 6568   cr     : EX1(read);
 6569   src    : EX1(read);
 6570   dst    : EX2(write);
 6571   INS01  : ISS;
 6572   ALU    : EX2;
 6573 %}
 6574 
 6575 //------- Multiply pipeline operations --------------------
 6576 
 6577 // Multiply reg-reg
 6578 // Eg.  MUL     w0, w1, w2
 6579 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6580 %{
 6581   single_instruction;
 6582   dst    : WR(write);
 6583   src1   : ISS(read);
 6584   src2   : ISS(read);
 6585   INS01  : ISS;
 6586   MAC    : WR;
 6587 %}
 6588 
 6589 // Multiply accumulate
 6590 // Eg.  MADD    w0, w1, w2, w3
 6591 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6592 %{
 6593   single_instruction;
 6594   dst    : WR(write);
 6595   src1   : ISS(read);
 6596   src2   : ISS(read);
 6597   src3   : ISS(read);
 6598   INS01  : ISS;
 6599   MAC    : WR;
 6600 %}
 6601 
 6602 // Eg.  MUL     w0, w1, w2
 6603 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6604 %{
 6605   single_instruction;
 6606   fixed_latency(3); // Maximum latency for 64 bit mul
 6607   dst    : WR(write);
 6608   src1   : ISS(read);
 6609   src2   : ISS(read);
 6610   INS01  : ISS;
 6611   MAC    : WR;
 6612 %}
 6613 
 6614 // Multiply accumulate
 6615 // Eg.  MADD    w0, w1, w2, w3
 6616 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6617 %{
 6618   single_instruction;
 6619   fixed_latency(3); // Maximum latency for 64 bit mul
 6620   dst    : WR(write);
 6621   src1   : ISS(read);
 6622   src2   : ISS(read);
 6623   src3   : ISS(read);
 6624   INS01  : ISS;
 6625   MAC    : WR;
 6626 %}
 6627 
 6628 //------- Divide pipeline operations --------------------
 6629 
 6630 // Eg.  SDIV    w0, w1, w2
 6631 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6632 %{
 6633   single_instruction;
 6634   fixed_latency(8); // Maximum latency for 32 bit divide
 6635   dst    : WR(write);
 6636   src1   : ISS(read);
 6637   src2   : ISS(read);
 6638   INS0   : ISS; // Can only dual issue as instruction 0
 6639   DIV    : WR;
 6640 %}
 6641 
 6642 // Eg.  SDIV    x0, x1, x2
 6643 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6644 %{
 6645   single_instruction;
 6646   fixed_latency(16); // Maximum latency for 64 bit divide
 6647   dst    : WR(write);
 6648   src1   : ISS(read);
 6649   src2   : ISS(read);
 6650   INS0   : ISS; // Can only dual issue as instruction 0
 6651   DIV    : WR;
 6652 %}
 6653 
 6654 //------- Load pipeline operations ------------------------
 6655 
 6656 // Load - prefetch
 6657 // Eg.  PFRM    &lt;mem&gt;
 6658 pipe_class iload_prefetch(memory mem)
 6659 %{
 6660   single_instruction;
 6661   mem    : ISS(read);
 6662   INS01  : ISS;
 6663   LDST   : WR;
 6664 %}
 6665 
 6666 // Load - reg, mem
 6667 // Eg.  LDR     x0, &lt;mem&gt;
 6668 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6669 %{
 6670   single_instruction;
 6671   dst    : WR(write);
 6672   mem    : ISS(read);
 6673   INS01  : ISS;
 6674   LDST   : WR;
 6675 %}
 6676 
 6677 // Load - reg, reg
 6678 // Eg.  LDR     x0, [sp, x1]
 6679 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6680 %{
 6681   single_instruction;
 6682   dst    : WR(write);
 6683   src    : ISS(read);
 6684   INS01  : ISS;
 6685   LDST   : WR;
 6686 %}
 6687 
 6688 //------- Store pipeline operations -----------------------
 6689 
 6690 // Store - zr, mem
 6691 // Eg.  STR     zr, &lt;mem&gt;
 6692 pipe_class istore_mem(memory mem)
 6693 %{
 6694   single_instruction;
 6695   mem    : ISS(read);
 6696   INS01  : ISS;
 6697   LDST   : WR;
 6698 %}
 6699 
 6700 // Store - reg, mem
 6701 // Eg.  STR     x0, &lt;mem&gt;
 6702 pipe_class istore_reg_mem(iRegI src, memory mem)
 6703 %{
 6704   single_instruction;
 6705   mem    : ISS(read);
 6706   src    : EX2(read);
 6707   INS01  : ISS;
 6708   LDST   : WR;
 6709 %}
 6710 
 6711 // Store - reg, reg
 6712 // Eg. STR      x0, [sp, x1]
 6713 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6714 %{
 6715   single_instruction;
 6716   dst    : ISS(read);
 6717   src    : EX2(read);
 6718   INS01  : ISS;
 6719   LDST   : WR;
 6720 %}
 6721 
 6722 //------- Store pipeline operations -----------------------
 6723 
 6724 // Branch
 6725 pipe_class pipe_branch()
 6726 %{
 6727   single_instruction;
 6728   INS01  : ISS;
 6729   BRANCH : EX1;
 6730 %}
 6731 
 6732 // Conditional branch
 6733 pipe_class pipe_branch_cond(rFlagsReg cr)
 6734 %{
 6735   single_instruction;
 6736   cr     : EX1(read);
 6737   INS01  : ISS;
 6738   BRANCH : EX1;
 6739 %}
 6740 
 6741 // Compare &amp; Branch
 6742 // EG.  CBZ/CBNZ
 6743 pipe_class pipe_cmp_branch(iRegI op1)
 6744 %{
 6745   single_instruction;
 6746   op1    : EX1(read);
 6747   INS01  : ISS;
 6748   BRANCH : EX1;
 6749 %}
 6750 
 6751 //------- Synchronisation operations ----------------------
 6752 
 6753 // Any operation requiring serialization.
 6754 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6755 pipe_class pipe_serial()
 6756 %{
 6757   single_instruction;
 6758   force_serialization;
 6759   fixed_latency(16);
 6760   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6761   LDST   : WR;
 6762 %}
 6763 
 6764 // Generic big/slow expanded idiom - also serialized
 6765 pipe_class pipe_slow()
 6766 %{
 6767   instruction_count(10);
 6768   multiple_bundles;
 6769   force_serialization;
 6770   fixed_latency(16);
 6771   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6772   LDST   : WR;
 6773 %}
 6774 
 6775 // Empty pipeline class
 6776 pipe_class pipe_class_empty()
 6777 %{
 6778   single_instruction;
 6779   fixed_latency(0);
 6780 %}
 6781 
 6782 // Default pipeline class.
 6783 pipe_class pipe_class_default()
 6784 %{
 6785   single_instruction;
 6786   fixed_latency(2);
 6787 %}
 6788 
 6789 // Pipeline class for compares.
 6790 pipe_class pipe_class_compare()
 6791 %{
 6792   single_instruction;
 6793   fixed_latency(16);
 6794 %}
 6795 
 6796 // Pipeline class for memory operations.
 6797 pipe_class pipe_class_memory()
 6798 %{
 6799   single_instruction;
 6800   fixed_latency(16);
 6801 %}
 6802 
 6803 // Pipeline class for call.
 6804 pipe_class pipe_class_call()
 6805 %{
 6806   single_instruction;
 6807   fixed_latency(100);
 6808 %}
 6809 
 6810 // Define the class for the Nop node.
 6811 define %{
 6812    MachNop = pipe_class_empty;
 6813 %}
 6814 
 6815 %}
 6816 //----------INSTRUCTIONS-------------------------------------------------------
 6817 //
 6818 // match      -- States which machine-independent subtree may be replaced
 6819 //               by this instruction.
 6820 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6821 //               selection to identify a minimum cost tree of machine
 6822 //               instructions that matches a tree of machine-independent
 6823 //               instructions.
 6824 // format     -- A string providing the disassembly for this instruction.
 6825 //               The value of an instruction&#39;s operand may be inserted
 6826 //               by referring to it with a &#39;$&#39; prefix.
 6827 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6828 //               to within an encode class as $primary, $secondary, and $tertiary
 6829 //               rrspectively.  The primary opcode is commonly used to
 6830 //               indicate the type of machine instruction, while secondary
 6831 //               and tertiary are often used for prefix options or addressing
 6832 //               modes.
 6833 // ins_encode -- A list of encode classes with parameters. The encode class
 6834 //               name must have been defined in an &#39;enc_class&#39; specification
 6835 //               in the encode section of the architecture description.
 6836 
 6837 // ============================================================================
 6838 // Memory (Load/Store) Instructions
 6839 
 6840 // Load Instructions
 6841 
 6842 // Load Byte (8 bit signed)
 6843 instruct loadB(iRegINoSp dst, memory1 mem)
 6844 %{
 6845   match(Set dst (LoadB mem));
 6846   predicate(!needs_acquiring_load(n));
 6847 
 6848   ins_cost(4 * INSN_COST);
 6849   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6850 
 6851   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6852 
 6853   ins_pipe(iload_reg_mem);
 6854 %}
 6855 
 6856 // Load Byte (8 bit signed) into long
 6857 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6858 %{
 6859   match(Set dst (ConvI2L (LoadB mem)));
 6860   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6861 
 6862   ins_cost(4 * INSN_COST);
 6863   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6864 
 6865   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6866 
 6867   ins_pipe(iload_reg_mem);
 6868 %}
 6869 
 6870 // Load Byte (8 bit unsigned)
 6871 instruct loadUB(iRegINoSp dst, memory1 mem)
 6872 %{
 6873   match(Set dst (LoadUB mem));
 6874   predicate(!needs_acquiring_load(n));
 6875 
 6876   ins_cost(4 * INSN_COST);
 6877   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6878 
 6879   ins_encode(aarch64_enc_ldrb(dst, mem));
 6880 
 6881   ins_pipe(iload_reg_mem);
 6882 %}
 6883 
 6884 // Load Byte (8 bit unsigned) into long
 6885 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6886 %{
 6887   match(Set dst (ConvI2L (LoadUB mem)));
 6888   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6889 
 6890   ins_cost(4 * INSN_COST);
 6891   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6892 
 6893   ins_encode(aarch64_enc_ldrb(dst, mem));
 6894 
 6895   ins_pipe(iload_reg_mem);
 6896 %}
 6897 
 6898 // Load Short (16 bit signed)
 6899 instruct loadS(iRegINoSp dst, memory2 mem)
 6900 %{
 6901   match(Set dst (LoadS mem));
 6902   predicate(!needs_acquiring_load(n));
 6903 
 6904   ins_cost(4 * INSN_COST);
 6905   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6906 
 6907   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6908 
 6909   ins_pipe(iload_reg_mem);
 6910 %}
 6911 
 6912 // Load Short (16 bit signed) into long
 6913 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6914 %{
 6915   match(Set dst (ConvI2L (LoadS mem)));
 6916   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6917 
 6918   ins_cost(4 * INSN_COST);
 6919   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6920 
 6921   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6922 
 6923   ins_pipe(iload_reg_mem);
 6924 %}
 6925 
 6926 // Load Char (16 bit unsigned)
 6927 instruct loadUS(iRegINoSp dst, memory2 mem)
 6928 %{
 6929   match(Set dst (LoadUS mem));
 6930   predicate(!needs_acquiring_load(n));
 6931 
 6932   ins_cost(4 * INSN_COST);
 6933   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6934 
 6935   ins_encode(aarch64_enc_ldrh(dst, mem));
 6936 
 6937   ins_pipe(iload_reg_mem);
 6938 %}
 6939 
 6940 // Load Short/Char (16 bit unsigned) into long
 6941 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6942 %{
 6943   match(Set dst (ConvI2L (LoadUS mem)));
 6944   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6945 
 6946   ins_cost(4 * INSN_COST);
 6947   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6948 
 6949   ins_encode(aarch64_enc_ldrh(dst, mem));
 6950 
 6951   ins_pipe(iload_reg_mem);
 6952 %}
 6953 
 6954 // Load Integer (32 bit signed)
 6955 instruct loadI(iRegINoSp dst, memory4 mem)
 6956 %{
 6957   match(Set dst (LoadI mem));
 6958   predicate(!needs_acquiring_load(n));
 6959 
 6960   ins_cost(4 * INSN_COST);
 6961   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6962 
 6963   ins_encode(aarch64_enc_ldrw(dst, mem));
 6964 
 6965   ins_pipe(iload_reg_mem);
 6966 %}
 6967 
 6968 // Load Integer (32 bit signed) into long
 6969 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6970 %{
 6971   match(Set dst (ConvI2L (LoadI mem)));
 6972   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6973 
 6974   ins_cost(4 * INSN_COST);
 6975   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6976 
 6977   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6978 
 6979   ins_pipe(iload_reg_mem);
 6980 %}
 6981 
 6982 // Load Integer (32 bit unsigned) into long
 6983 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6984 %{
 6985   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6986   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6987 
 6988   ins_cost(4 * INSN_COST);
 6989   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6990 
 6991   ins_encode(aarch64_enc_ldrw(dst, mem));
 6992 
 6993   ins_pipe(iload_reg_mem);
 6994 %}
 6995 
 6996 // Load Long (64 bit signed)
 6997 instruct loadL(iRegLNoSp dst, memory8 mem)
 6998 %{
 6999   match(Set dst (LoadL mem));
 7000   predicate(!needs_acquiring_load(n));
 7001 
 7002   ins_cost(4 * INSN_COST);
 7003   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7004 
 7005   ins_encode(aarch64_enc_ldr(dst, mem));
 7006 
 7007   ins_pipe(iload_reg_mem);
 7008 %}
 7009 
 7010 // Load Range
 7011 instruct loadRange(iRegINoSp dst, memory4 mem)
 7012 %{
 7013   match(Set dst (LoadRange mem));
 7014 
 7015   ins_cost(4 * INSN_COST);
 7016   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7017 
 7018   ins_encode(aarch64_enc_ldrw(dst, mem));
 7019 
 7020   ins_pipe(iload_reg_mem);
 7021 %}
 7022 
 7023 // Load Pointer
 7024 instruct loadP(iRegPNoSp dst, memory8 mem)
 7025 %{
 7026   match(Set dst (LoadP mem));
 7027   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7028 
 7029   ins_cost(4 * INSN_COST);
 7030   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7031 
 7032   ins_encode(aarch64_enc_ldr(dst, mem));
 7033 
 7034   ins_pipe(iload_reg_mem);
 7035 %}
 7036 
 7037 // Load Compressed Pointer
 7038 instruct loadN(iRegNNoSp dst, memory4 mem)
 7039 %{
 7040   match(Set dst (LoadN mem));
 7041   predicate(!needs_acquiring_load(n));
 7042 
 7043   ins_cost(4 * INSN_COST);
 7044   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7045 
 7046   ins_encode(aarch64_enc_ldrw(dst, mem));
 7047 
 7048   ins_pipe(iload_reg_mem);
 7049 %}
 7050 
 7051 // Load Klass Pointer
 7052 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7053 %{
 7054   match(Set dst (LoadKlass mem));
 7055   predicate(!needs_acquiring_load(n));
 7056 
 7057   ins_cost(4 * INSN_COST);
 7058   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7059 
 7060   ins_encode(aarch64_enc_ldr(dst, mem));
 7061 
 7062   ins_pipe(iload_reg_mem);
 7063 %}
 7064 
 7065 // Load Narrow Klass Pointer
 7066 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7067 %{
 7068   match(Set dst (LoadNKlass mem));
 7069   predicate(!needs_acquiring_load(n));
 7070 
 7071   ins_cost(4 * INSN_COST);
 7072   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7073 
 7074   ins_encode(aarch64_enc_ldrw(dst, mem));
 7075 
 7076   ins_pipe(iload_reg_mem);
 7077 %}
 7078 
 7079 // Load Float
 7080 instruct loadF(vRegF dst, memory4 mem)
 7081 %{
 7082   match(Set dst (LoadF mem));
 7083   predicate(!needs_acquiring_load(n));
 7084 
 7085   ins_cost(4 * INSN_COST);
 7086   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7087 
 7088   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7089 
 7090   ins_pipe(pipe_class_memory);
 7091 %}
 7092 
 7093 // Load Double
 7094 instruct loadD(vRegD dst, memory8 mem)
 7095 %{
 7096   match(Set dst (LoadD mem));
 7097   predicate(!needs_acquiring_load(n));
 7098 
 7099   ins_cost(4 * INSN_COST);
 7100   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7101 
 7102   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7103 
 7104   ins_pipe(pipe_class_memory);
 7105 %}
 7106 
 7107 
 7108 // Load Int Constant
 7109 instruct loadConI(iRegINoSp dst, immI src)
 7110 %{
 7111   match(Set dst src);
 7112 
 7113   ins_cost(INSN_COST);
 7114   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7115 
 7116   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7117 
 7118   ins_pipe(ialu_imm);
 7119 %}
 7120 
 7121 // Load Long Constant
 7122 instruct loadConL(iRegLNoSp dst, immL src)
 7123 %{
 7124   match(Set dst src);
 7125 
 7126   ins_cost(INSN_COST);
 7127   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7128 
 7129   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7130 
 7131   ins_pipe(ialu_imm);
 7132 %}
 7133 
 7134 // Load Pointer Constant
 7135 
 7136 instruct loadConP(iRegPNoSp dst, immP con)
 7137 %{
 7138   match(Set dst con);
 7139 
 7140   ins_cost(INSN_COST * 4);
 7141   format %{
 7142     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7143   %}
 7144 
 7145   ins_encode(aarch64_enc_mov_p(dst, con));
 7146 
 7147   ins_pipe(ialu_imm);
 7148 %}
 7149 
 7150 // Load Null Pointer Constant
 7151 
 7152 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7153 %{
 7154   match(Set dst con);
 7155 
 7156   ins_cost(INSN_COST);
 7157   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7158 
 7159   ins_encode(aarch64_enc_mov_p0(dst, con));
 7160 
 7161   ins_pipe(ialu_imm);
 7162 %}
 7163 
 7164 // Load Pointer Constant One
 7165 
 7166 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7167 %{
 7168   match(Set dst con);
 7169 
 7170   ins_cost(INSN_COST);
 7171   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7172 
 7173   ins_encode(aarch64_enc_mov_p1(dst, con));
 7174 
 7175   ins_pipe(ialu_imm);
 7176 %}
 7177 
 7178 // Load Byte Map Base Constant
 7179 
 7180 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7181 %{
 7182   match(Set dst con);
 7183 
 7184   ins_cost(INSN_COST);
 7185   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7186 
 7187   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7188 
 7189   ins_pipe(ialu_imm);
 7190 %}
 7191 
 7192 // Load Narrow Pointer Constant
 7193 
 7194 instruct loadConN(iRegNNoSp dst, immN con)
 7195 %{
 7196   match(Set dst con);
 7197 
 7198   ins_cost(INSN_COST * 4);
 7199   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7200 
 7201   ins_encode(aarch64_enc_mov_n(dst, con));
 7202 
 7203   ins_pipe(ialu_imm);
 7204 %}
 7205 
 7206 // Load Narrow Null Pointer Constant
 7207 
 7208 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7209 %{
 7210   match(Set dst con);
 7211 
 7212   ins_cost(INSN_COST);
 7213   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7214 
 7215   ins_encode(aarch64_enc_mov_n0(dst, con));
 7216 
 7217   ins_pipe(ialu_imm);
 7218 %}
 7219 
 7220 // Load Narrow Klass Constant
 7221 
 7222 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7223 %{
 7224   match(Set dst con);
 7225 
 7226   ins_cost(INSN_COST);
 7227   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7228 
 7229   ins_encode(aarch64_enc_mov_nk(dst, con));
 7230 
 7231   ins_pipe(ialu_imm);
 7232 %}
 7233 
 7234 // Load Packed Float Constant
 7235 
 7236 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7237   match(Set dst con);
 7238   ins_cost(INSN_COST * 4);
 7239   format %{ &quot;fmovs  $dst, $con&quot;%}
 7240   ins_encode %{
 7241     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7242   %}
 7243 
 7244   ins_pipe(fp_imm_s);
 7245 %}
 7246 
 7247 // Load Float Constant
 7248 
 7249 instruct loadConF(vRegF dst, immF con) %{
 7250   match(Set dst con);
 7251 
 7252   ins_cost(INSN_COST * 4);
 7253 
 7254   format %{
 7255     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7256   %}
 7257 
 7258   ins_encode %{
 7259     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7260   %}
 7261 
 7262   ins_pipe(fp_load_constant_s);
 7263 %}
 7264 
 7265 // Load Packed Double Constant
 7266 
 7267 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7268   match(Set dst con);
 7269   ins_cost(INSN_COST);
 7270   format %{ &quot;fmovd  $dst, $con&quot;%}
 7271   ins_encode %{
 7272     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7273   %}
 7274 
 7275   ins_pipe(fp_imm_d);
 7276 %}
 7277 
 7278 // Load Double Constant
 7279 
 7280 instruct loadConD(vRegD dst, immD con) %{
 7281   match(Set dst con);
 7282 
 7283   ins_cost(INSN_COST * 5);
 7284   format %{
 7285     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7286   %}
 7287 
 7288   ins_encode %{
 7289     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7290   %}
 7291 
 7292   ins_pipe(fp_load_constant_d);
 7293 %}
 7294 
 7295 // Store Instructions
 7296 
 7297 // Store CMS card-mark Immediate
 7298 instruct storeimmCM0(immI0 zero, memory1 mem)
 7299 %{
 7300   match(Set mem (StoreCM mem zero));
 7301 
 7302   ins_cost(INSN_COST);
 7303   format %{ &quot;storestore (elided)\n\t&quot;
 7304             &quot;strb zr, $mem\t# byte&quot; %}
 7305 
 7306   ins_encode(aarch64_enc_strb0(mem));
 7307 
 7308   ins_pipe(istore_mem);
 7309 %}
 7310 
 7311 // Store CMS card-mark Immediate with intervening StoreStore
 7312 // needed when using CMS with no conditional card marking
 7313 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7314 %{
 7315   match(Set mem (StoreCM mem zero));
 7316 
 7317   ins_cost(INSN_COST * 2);
 7318   format %{ &quot;storestore\n\t&quot;
 7319             &quot;dmb ishst&quot;
 7320             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7321 
 7322   ins_encode(aarch64_enc_strb0_ordered(mem));
 7323 
 7324   ins_pipe(istore_mem);
 7325 %}
 7326 
 7327 // Store Byte
 7328 instruct storeB(iRegIorL2I src, memory1 mem)
 7329 %{
 7330   match(Set mem (StoreB mem src));
 7331   predicate(!needs_releasing_store(n));
 7332 
 7333   ins_cost(INSN_COST);
 7334   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7335 
 7336   ins_encode(aarch64_enc_strb(src, mem));
 7337 
 7338   ins_pipe(istore_reg_mem);
 7339 %}
 7340 
 7341 
 7342 instruct storeimmB0(immI0 zero, memory1 mem)
 7343 %{
 7344   match(Set mem (StoreB mem zero));
 7345   predicate(!needs_releasing_store(n));
 7346 
 7347   ins_cost(INSN_COST);
 7348   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7349 
 7350   ins_encode(aarch64_enc_strb0(mem));
 7351 
 7352   ins_pipe(istore_mem);
 7353 %}
 7354 
 7355 // Store Char/Short
 7356 instruct storeC(iRegIorL2I src, memory2 mem)
 7357 %{
 7358   match(Set mem (StoreC mem src));
 7359   predicate(!needs_releasing_store(n));
 7360 
 7361   ins_cost(INSN_COST);
 7362   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7363 
 7364   ins_encode(aarch64_enc_strh(src, mem));
 7365 
 7366   ins_pipe(istore_reg_mem);
 7367 %}
 7368 
 7369 instruct storeimmC0(immI0 zero, memory2 mem)
 7370 %{
 7371   match(Set mem (StoreC mem zero));
 7372   predicate(!needs_releasing_store(n));
 7373 
 7374   ins_cost(INSN_COST);
 7375   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7376 
 7377   ins_encode(aarch64_enc_strh0(mem));
 7378 
 7379   ins_pipe(istore_mem);
 7380 %}
 7381 
 7382 // Store Integer
 7383 
 7384 instruct storeI(iRegIorL2I src, memory4 mem)
 7385 %{
 7386   match(Set mem(StoreI mem src));
 7387   predicate(!needs_releasing_store(n));
 7388 
 7389   ins_cost(INSN_COST);
 7390   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7391 
 7392   ins_encode(aarch64_enc_strw(src, mem));
 7393 
 7394   ins_pipe(istore_reg_mem);
 7395 %}
 7396 
 7397 instruct storeimmI0(immI0 zero, memory4 mem)
 7398 %{
 7399   match(Set mem(StoreI mem zero));
 7400   predicate(!needs_releasing_store(n));
 7401 
 7402   ins_cost(INSN_COST);
 7403   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7404 
 7405   ins_encode(aarch64_enc_strw0(mem));
 7406 
 7407   ins_pipe(istore_mem);
 7408 %}
 7409 
 7410 // Store Long (64 bit signed)
 7411 instruct storeL(iRegL src, memory8 mem)
 7412 %{
 7413   match(Set mem (StoreL mem src));
 7414   predicate(!needs_releasing_store(n));
 7415 
 7416   ins_cost(INSN_COST);
 7417   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7418 
 7419   ins_encode(aarch64_enc_str(src, mem));
 7420 
 7421   ins_pipe(istore_reg_mem);
 7422 %}
 7423 
 7424 // Store Long (64 bit signed)
 7425 instruct storeimmL0(immL0 zero, memory8 mem)
 7426 %{
 7427   match(Set mem (StoreL mem zero));
 7428   predicate(!needs_releasing_store(n));
 7429 
 7430   ins_cost(INSN_COST);
 7431   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7432 
 7433   ins_encode(aarch64_enc_str0(mem));
 7434 
 7435   ins_pipe(istore_mem);
 7436 %}
 7437 
 7438 // Store Pointer
 7439 instruct storeP(iRegP src, memory8 mem)
 7440 %{
 7441   match(Set mem (StoreP mem src));
 7442   predicate(!needs_releasing_store(n));
 7443 
 7444   ins_cost(INSN_COST);
 7445   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7446 
 7447   ins_encode(aarch64_enc_str(src, mem));
 7448 
 7449   ins_pipe(istore_reg_mem);
 7450 %}
 7451 
 7452 // Store Pointer
 7453 instruct storeimmP0(immP0 zero, memory8 mem)
 7454 %{
 7455   match(Set mem (StoreP mem zero));
 7456   predicate(!needs_releasing_store(n));
 7457 
 7458   ins_cost(INSN_COST);
 7459   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7460 
 7461   ins_encode(aarch64_enc_str0(mem));
 7462 
 7463   ins_pipe(istore_mem);
 7464 %}
 7465 
 7466 // Store Compressed Pointer
 7467 instruct storeN(iRegN src, memory4 mem)
 7468 %{
 7469   match(Set mem (StoreN mem src));
 7470   predicate(!needs_releasing_store(n));
 7471 
 7472   ins_cost(INSN_COST);
 7473   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7474 
 7475   ins_encode(aarch64_enc_strw(src, mem));
 7476 
 7477   ins_pipe(istore_reg_mem);
 7478 %}
 7479 
 7480 instruct storeImmN0(iRegIHeapbase heapbase, immN0 zero, memory4 mem)
 7481 %{
 7482   match(Set mem (StoreN mem zero));
 7483   predicate(CompressedOops::base() == NULL &amp;&amp;
 7484             CompressedKlassPointers::base() == NULL &amp;&amp;
 7485             (!needs_releasing_store(n)));
 7486 
 7487   ins_cost(INSN_COST);
 7488   format %{ &quot;strw  rheapbase, $mem\t# compressed ptr (rheapbase==0)&quot; %}
 7489 
 7490   ins_encode(aarch64_enc_strw(heapbase, mem));
 7491 
 7492   ins_pipe(istore_reg_mem);
 7493 %}
 7494 
 7495 // Store Float
 7496 instruct storeF(vRegF src, memory4 mem)
 7497 %{
 7498   match(Set mem (StoreF mem src));
 7499   predicate(!needs_releasing_store(n));
 7500 
 7501   ins_cost(INSN_COST);
 7502   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7503 
 7504   ins_encode( aarch64_enc_strs(src, mem) );
 7505 
 7506   ins_pipe(pipe_class_memory);
 7507 %}
 7508 
 7509 // TODO
 7510 // implement storeImmF0 and storeFImmPacked
 7511 
 7512 // Store Double
 7513 instruct storeD(vRegD src, memory8 mem)
 7514 %{
 7515   match(Set mem (StoreD mem src));
 7516   predicate(!needs_releasing_store(n));
 7517 
 7518   ins_cost(INSN_COST);
 7519   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7520 
 7521   ins_encode( aarch64_enc_strd(src, mem) );
 7522 
 7523   ins_pipe(pipe_class_memory);
 7524 %}
 7525 
 7526 // Store Compressed Klass Pointer
 7527 instruct storeNKlass(iRegN src, memory4 mem)
 7528 %{
 7529   predicate(!needs_releasing_store(n));
 7530   match(Set mem (StoreNKlass mem src));
 7531 
 7532   ins_cost(INSN_COST);
 7533   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7534 
 7535   ins_encode(aarch64_enc_strw(src, mem));
 7536 
 7537   ins_pipe(istore_reg_mem);
 7538 %}
 7539 
 7540 // TODO
 7541 // implement storeImmD0 and storeDImmPacked
 7542 
 7543 // prefetch instructions
 7544 // Must be safe to execute with invalid address (cannot fault).
 7545 
 7546 instruct prefetchalloc( memory8 mem ) %{
 7547   match(PrefetchAllocation mem);
 7548 
 7549   ins_cost(INSN_COST);
 7550   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7551 
 7552   ins_encode( aarch64_enc_prefetchw(mem) );
 7553 
 7554   ins_pipe(iload_prefetch);
 7555 %}
 7556 
 7557 //  ---------------- volatile loads and stores ----------------
 7558 
 7559 // Load Byte (8 bit signed)
 7560 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7561 %{
 7562   match(Set dst (LoadB mem));
 7563 
 7564   ins_cost(VOLATILE_REF_COST);
 7565   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7566 
 7567   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7568 
 7569   ins_pipe(pipe_serial);
 7570 %}
 7571 
 7572 // Load Byte (8 bit signed) into long
 7573 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7574 %{
 7575   match(Set dst (ConvI2L (LoadB mem)));
 7576 
 7577   ins_cost(VOLATILE_REF_COST);
 7578   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7579 
 7580   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7581 
 7582   ins_pipe(pipe_serial);
 7583 %}
 7584 
 7585 // Load Byte (8 bit unsigned)
 7586 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7587 %{
 7588   match(Set dst (LoadUB mem));
 7589 
 7590   ins_cost(VOLATILE_REF_COST);
 7591   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7592 
 7593   ins_encode(aarch64_enc_ldarb(dst, mem));
 7594 
 7595   ins_pipe(pipe_serial);
 7596 %}
 7597 
 7598 // Load Byte (8 bit unsigned) into long
 7599 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7600 %{
 7601   match(Set dst (ConvI2L (LoadUB mem)));
 7602 
 7603   ins_cost(VOLATILE_REF_COST);
 7604   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7605 
 7606   ins_encode(aarch64_enc_ldarb(dst, mem));
 7607 
 7608   ins_pipe(pipe_serial);
 7609 %}
 7610 
 7611 // Load Short (16 bit signed)
 7612 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7613 %{
 7614   match(Set dst (LoadS mem));
 7615 
 7616   ins_cost(VOLATILE_REF_COST);
 7617   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7618 
 7619   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7620 
 7621   ins_pipe(pipe_serial);
 7622 %}
 7623 
 7624 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7625 %{
 7626   match(Set dst (LoadUS mem));
 7627 
 7628   ins_cost(VOLATILE_REF_COST);
 7629   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7630 
 7631   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7632 
 7633   ins_pipe(pipe_serial);
 7634 %}
 7635 
 7636 // Load Short/Char (16 bit unsigned) into long
 7637 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7638 %{
 7639   match(Set dst (ConvI2L (LoadUS mem)));
 7640 
 7641   ins_cost(VOLATILE_REF_COST);
 7642   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7643 
 7644   ins_encode(aarch64_enc_ldarh(dst, mem));
 7645 
 7646   ins_pipe(pipe_serial);
 7647 %}
 7648 
 7649 // Load Short/Char (16 bit signed) into long
 7650 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7651 %{
 7652   match(Set dst (ConvI2L (LoadS mem)));
 7653 
 7654   ins_cost(VOLATILE_REF_COST);
 7655   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7656 
 7657   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7658 
 7659   ins_pipe(pipe_serial);
 7660 %}
 7661 
 7662 // Load Integer (32 bit signed)
 7663 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7664 %{
 7665   match(Set dst (LoadI mem));
 7666 
 7667   ins_cost(VOLATILE_REF_COST);
 7668   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7669 
 7670   ins_encode(aarch64_enc_ldarw(dst, mem));
 7671 
 7672   ins_pipe(pipe_serial);
 7673 %}
 7674 
 7675 // Load Integer (32 bit unsigned) into long
 7676 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7677 %{
 7678   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7679 
 7680   ins_cost(VOLATILE_REF_COST);
 7681   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7682 
 7683   ins_encode(aarch64_enc_ldarw(dst, mem));
 7684 
 7685   ins_pipe(pipe_serial);
 7686 %}
 7687 
 7688 // Load Long (64 bit signed)
 7689 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7690 %{
 7691   match(Set dst (LoadL mem));
 7692 
 7693   ins_cost(VOLATILE_REF_COST);
 7694   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7695 
 7696   ins_encode(aarch64_enc_ldar(dst, mem));
 7697 
 7698   ins_pipe(pipe_serial);
 7699 %}
 7700 
 7701 // Load Pointer
 7702 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7703 %{
 7704   match(Set dst (LoadP mem));
 7705   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7706 
 7707   ins_cost(VOLATILE_REF_COST);
 7708   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7709 
 7710   ins_encode(aarch64_enc_ldar(dst, mem));
 7711 
 7712   ins_pipe(pipe_serial);
 7713 %}
 7714 
 7715 // Load Compressed Pointer
 7716 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7717 %{
 7718   match(Set dst (LoadN mem));
 7719 
 7720   ins_cost(VOLATILE_REF_COST);
 7721   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7722 
 7723   ins_encode(aarch64_enc_ldarw(dst, mem));
 7724 
 7725   ins_pipe(pipe_serial);
 7726 %}
 7727 
 7728 // Load Float
 7729 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7730 %{
 7731   match(Set dst (LoadF mem));
 7732 
 7733   ins_cost(VOLATILE_REF_COST);
 7734   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7735 
 7736   ins_encode( aarch64_enc_fldars(dst, mem) );
 7737 
 7738   ins_pipe(pipe_serial);
 7739 %}
 7740 
 7741 // Load Double
 7742 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7743 %{
 7744   match(Set dst (LoadD mem));
 7745 
 7746   ins_cost(VOLATILE_REF_COST);
 7747   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7748 
 7749   ins_encode( aarch64_enc_fldard(dst, mem) );
 7750 
 7751   ins_pipe(pipe_serial);
 7752 %}
 7753 
 7754 // Store Byte
 7755 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7756 %{
 7757   match(Set mem (StoreB mem src));
 7758 
 7759   ins_cost(VOLATILE_REF_COST);
 7760   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7761 
 7762   ins_encode(aarch64_enc_stlrb(src, mem));
 7763 
 7764   ins_pipe(pipe_class_memory);
 7765 %}
 7766 
 7767 // Store Char/Short
 7768 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7769 %{
 7770   match(Set mem (StoreC mem src));
 7771 
 7772   ins_cost(VOLATILE_REF_COST);
 7773   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7774 
 7775   ins_encode(aarch64_enc_stlrh(src, mem));
 7776 
 7777   ins_pipe(pipe_class_memory);
 7778 %}
 7779 
 7780 // Store Integer
 7781 
 7782 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7783 %{
 7784   match(Set mem(StoreI mem src));
 7785 
 7786   ins_cost(VOLATILE_REF_COST);
 7787   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7788 
 7789   ins_encode(aarch64_enc_stlrw(src, mem));
 7790 
 7791   ins_pipe(pipe_class_memory);
 7792 %}
 7793 
 7794 // Store Long (64 bit signed)
 7795 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7796 %{
 7797   match(Set mem (StoreL mem src));
 7798 
 7799   ins_cost(VOLATILE_REF_COST);
 7800   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7801 
 7802   ins_encode(aarch64_enc_stlr(src, mem));
 7803 
 7804   ins_pipe(pipe_class_memory);
 7805 %}
 7806 
 7807 // Store Pointer
 7808 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7809 %{
 7810   match(Set mem (StoreP mem src));
 7811 
 7812   ins_cost(VOLATILE_REF_COST);
 7813   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7814 
 7815   ins_encode(aarch64_enc_stlr(src, mem));
 7816 
 7817   ins_pipe(pipe_class_memory);
 7818 %}
 7819 
 7820 // Store Compressed Pointer
 7821 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7822 %{
 7823   match(Set mem (StoreN mem src));
 7824 
 7825   ins_cost(VOLATILE_REF_COST);
 7826   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7827 
 7828   ins_encode(aarch64_enc_stlrw(src, mem));
 7829 
 7830   ins_pipe(pipe_class_memory);
 7831 %}
 7832 
 7833 // Store Float
 7834 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7835 %{
 7836   match(Set mem (StoreF mem src));
 7837 
 7838   ins_cost(VOLATILE_REF_COST);
 7839   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7840 
 7841   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7842 
 7843   ins_pipe(pipe_class_memory);
 7844 %}
 7845 
 7846 // TODO
 7847 // implement storeImmF0 and storeFImmPacked
 7848 
 7849 // Store Double
 7850 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7851 %{
 7852   match(Set mem (StoreD mem src));
 7853 
 7854   ins_cost(VOLATILE_REF_COST);
 7855   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7856 
 7857   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7858 
 7859   ins_pipe(pipe_class_memory);
 7860 %}
 7861 
 7862 //  ---------------- end of volatile loads and stores ----------------
 7863 
 7864 instruct cacheWB(indirect addr)
 7865 %{
 7866   predicate(VM_Version::supports_data_cache_line_flush());
 7867   match(CacheWB addr);
 7868 
 7869   ins_cost(100);
 7870   format %{&quot;cache wb $addr&quot; %}
 7871   ins_encode %{
 7872     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7873     assert($addr$$disp == 0, &quot;should be&quot;);
 7874     __ cache_wb(Address($addr$$base$$Register, 0));
 7875   %}
 7876   ins_pipe(pipe_slow); // XXX
 7877 %}
 7878 
 7879 instruct cacheWBPreSync()
 7880 %{
 7881   predicate(VM_Version::supports_data_cache_line_flush());
 7882   match(CacheWBPreSync);
 7883 
 7884   ins_cost(100);
 7885   format %{&quot;cache wb presync&quot; %}
 7886   ins_encode %{
 7887     __ cache_wbsync(true);
 7888   %}
 7889   ins_pipe(pipe_slow); // XXX
 7890 %}
 7891 
 7892 instruct cacheWBPostSync()
 7893 %{
 7894   predicate(VM_Version::supports_data_cache_line_flush());
 7895   match(CacheWBPostSync);
 7896 
 7897   ins_cost(100);
 7898   format %{&quot;cache wb postsync&quot; %}
 7899   ins_encode %{
 7900     __ cache_wbsync(false);
 7901   %}
 7902   ins_pipe(pipe_slow); // XXX
 7903 %}
 7904 
 7905 // ============================================================================
 7906 // BSWAP Instructions
 7907 
 7908 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7909   match(Set dst (ReverseBytesI src));
 7910 
 7911   ins_cost(INSN_COST);
 7912   format %{ &quot;revw  $dst, $src&quot; %}
 7913 
 7914   ins_encode %{
 7915     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7916   %}
 7917 
 7918   ins_pipe(ialu_reg);
 7919 %}
 7920 
 7921 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7922   match(Set dst (ReverseBytesL src));
 7923 
 7924   ins_cost(INSN_COST);
 7925   format %{ &quot;rev  $dst, $src&quot; %}
 7926 
 7927   ins_encode %{
 7928     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7929   %}
 7930 
 7931   ins_pipe(ialu_reg);
 7932 %}
 7933 
 7934 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7935   match(Set dst (ReverseBytesUS src));
 7936 
 7937   ins_cost(INSN_COST);
 7938   format %{ &quot;rev16w  $dst, $src&quot; %}
 7939 
 7940   ins_encode %{
 7941     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7942   %}
 7943 
 7944   ins_pipe(ialu_reg);
 7945 %}
 7946 
 7947 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7948   match(Set dst (ReverseBytesS src));
 7949 
 7950   ins_cost(INSN_COST);
 7951   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7952             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7953 
 7954   ins_encode %{
 7955     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7956     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7957   %}
 7958 
 7959   ins_pipe(ialu_reg);
 7960 %}
 7961 
 7962 // ============================================================================
 7963 // Zero Count Instructions
 7964 
 7965 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7966   match(Set dst (CountLeadingZerosI src));
 7967 
 7968   ins_cost(INSN_COST);
 7969   format %{ &quot;clzw  $dst, $src&quot; %}
 7970   ins_encode %{
 7971     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7972   %}
 7973 
 7974   ins_pipe(ialu_reg);
 7975 %}
 7976 
 7977 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7978   match(Set dst (CountLeadingZerosL src));
 7979 
 7980   ins_cost(INSN_COST);
 7981   format %{ &quot;clz   $dst, $src&quot; %}
 7982   ins_encode %{
 7983     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7984   %}
 7985 
 7986   ins_pipe(ialu_reg);
 7987 %}
 7988 
 7989 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7990   match(Set dst (CountTrailingZerosI src));
 7991 
 7992   ins_cost(INSN_COST * 2);
 7993   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 7994             &quot;clzw   $dst, $dst&quot; %}
 7995   ins_encode %{
 7996     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 7997     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 7998   %}
 7999 
 8000   ins_pipe(ialu_reg);
 8001 %}
 8002 
 8003 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8004   match(Set dst (CountTrailingZerosL src));
 8005 
 8006   ins_cost(INSN_COST * 2);
 8007   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8008             &quot;clz    $dst, $dst&quot; %}
 8009   ins_encode %{
 8010     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8011     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8012   %}
 8013 
 8014   ins_pipe(ialu_reg);
 8015 %}
 8016 
 8017 //---------- Population Count Instructions -------------------------------------
 8018 //
 8019 
 8020 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8021   predicate(UsePopCountInstruction);
 8022   match(Set dst (PopCountI src));
 8023   effect(TEMP tmp);
 8024   ins_cost(INSN_COST * 13);
 8025 
 8026   format %{ &quot;movw   $src, $src\n\t&quot;
 8027             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8028             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8029             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8030             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8031   ins_encode %{
 8032     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8033     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8034     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8035     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8036     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8037   %}
 8038 
 8039   ins_pipe(pipe_class_default);
 8040 %}
 8041 
 8042 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8043   predicate(UsePopCountInstruction);
 8044   match(Set dst (PopCountI (LoadI mem)));
 8045   effect(TEMP tmp);
 8046   ins_cost(INSN_COST * 13);
 8047 
 8048   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8049             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8050             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8051             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8052   ins_encode %{
 8053     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8054     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8055               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8056     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8057     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8058     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8059   %}
 8060 
 8061   ins_pipe(pipe_class_default);
 8062 %}
 8063 
 8064 // Note: Long.bitCount(long) returns an int.
 8065 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8066   predicate(UsePopCountInstruction);
 8067   match(Set dst (PopCountL src));
 8068   effect(TEMP tmp);
 8069   ins_cost(INSN_COST * 13);
 8070 
 8071   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8072             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8073             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8074             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8075   ins_encode %{
 8076     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8077     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8078     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8079     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8080   %}
 8081 
 8082   ins_pipe(pipe_class_default);
 8083 %}
 8084 
 8085 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8086   predicate(UsePopCountInstruction);
 8087   match(Set dst (PopCountL (LoadL mem)));
 8088   effect(TEMP tmp);
 8089   ins_cost(INSN_COST * 13);
 8090 
 8091   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8092             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8093             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8094             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8095   ins_encode %{
 8096     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8097     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8098               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8099     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8100     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8101     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8102   %}
 8103 
 8104   ins_pipe(pipe_class_default);
 8105 %}
 8106 
 8107 // ============================================================================
 8108 // MemBar Instruction
 8109 
 8110 instruct load_fence() %{
 8111   match(LoadFence);
 8112   ins_cost(VOLATILE_REF_COST);
 8113 
 8114   format %{ &quot;load_fence&quot; %}
 8115 
 8116   ins_encode %{
 8117     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8118   %}
 8119   ins_pipe(pipe_serial);
 8120 %}
 8121 
 8122 instruct unnecessary_membar_acquire() %{
 8123   predicate(unnecessary_acquire(n));
 8124   match(MemBarAcquire);
 8125   ins_cost(0);
 8126 
 8127   format %{ &quot;membar_acquire (elided)&quot; %}
 8128 
 8129   ins_encode %{
 8130     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8131   %}
 8132 
 8133   ins_pipe(pipe_class_empty);
 8134 %}
 8135 
 8136 instruct membar_acquire() %{
 8137   match(MemBarAcquire);
 8138   ins_cost(VOLATILE_REF_COST);
 8139 
 8140   format %{ &quot;membar_acquire\n\t&quot;
 8141             &quot;dmb ish&quot; %}
 8142 
 8143   ins_encode %{
 8144     __ block_comment(&quot;membar_acquire&quot;);
 8145     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8146   %}
 8147 
 8148   ins_pipe(pipe_serial);
 8149 %}
 8150 
 8151 
 8152 instruct membar_acquire_lock() %{
 8153   match(MemBarAcquireLock);
 8154   ins_cost(VOLATILE_REF_COST);
 8155 
 8156   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8157 
 8158   ins_encode %{
 8159     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8160   %}
 8161 
 8162   ins_pipe(pipe_serial);
 8163 %}
 8164 
 8165 instruct store_fence() %{
 8166   match(StoreFence);
 8167   ins_cost(VOLATILE_REF_COST);
 8168 
 8169   format %{ &quot;store_fence&quot; %}
 8170 
 8171   ins_encode %{
 8172     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8173   %}
 8174   ins_pipe(pipe_serial);
 8175 %}
 8176 
 8177 instruct unnecessary_membar_release() %{
 8178   predicate(unnecessary_release(n));
 8179   match(MemBarRelease);
 8180   ins_cost(0);
 8181 
 8182   format %{ &quot;membar_release (elided)&quot; %}
 8183 
 8184   ins_encode %{
 8185     __ block_comment(&quot;membar_release (elided)&quot;);
 8186   %}
 8187   ins_pipe(pipe_serial);
 8188 %}
 8189 
 8190 instruct membar_release() %{
 8191   match(MemBarRelease);
 8192   ins_cost(VOLATILE_REF_COST);
 8193 
 8194   format %{ &quot;membar_release\n\t&quot;
 8195             &quot;dmb ish&quot; %}
 8196 
 8197   ins_encode %{
 8198     __ block_comment(&quot;membar_release&quot;);
 8199     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8200   %}
 8201   ins_pipe(pipe_serial);
 8202 %}
 8203 
 8204 instruct membar_storestore() %{
 8205   match(MemBarStoreStore);
 8206   ins_cost(VOLATILE_REF_COST);
 8207 
 8208   format %{ &quot;MEMBAR-store-store&quot; %}
 8209 
 8210   ins_encode %{
 8211     __ membar(Assembler::StoreStore);
 8212   %}
 8213   ins_pipe(pipe_serial);
 8214 %}
 8215 
 8216 instruct membar_release_lock() %{
 8217   match(MemBarReleaseLock);
 8218   ins_cost(VOLATILE_REF_COST);
 8219 
 8220   format %{ &quot;membar_release_lock (elided)&quot; %}
 8221 
 8222   ins_encode %{
 8223     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8224   %}
 8225 
 8226   ins_pipe(pipe_serial);
 8227 %}
 8228 
 8229 instruct unnecessary_membar_volatile() %{
 8230   predicate(unnecessary_volatile(n));
 8231   match(MemBarVolatile);
 8232   ins_cost(0);
 8233 
 8234   format %{ &quot;membar_volatile (elided)&quot; %}
 8235 
 8236   ins_encode %{
 8237     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8238   %}
 8239 
 8240   ins_pipe(pipe_serial);
 8241 %}
 8242 
 8243 instruct membar_volatile() %{
 8244   match(MemBarVolatile);
 8245   ins_cost(VOLATILE_REF_COST*100);
 8246 
 8247   format %{ &quot;membar_volatile\n\t&quot;
 8248              &quot;dmb ish&quot;%}
 8249 
 8250   ins_encode %{
 8251     __ block_comment(&quot;membar_volatile&quot;);
 8252     __ membar(Assembler::StoreLoad);
 8253   %}
 8254 
 8255   ins_pipe(pipe_serial);
 8256 %}
 8257 
 8258 // ============================================================================
 8259 // Cast/Convert Instructions
 8260 
 8261 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8262   match(Set dst (CastX2P src));
 8263 
 8264   ins_cost(INSN_COST);
 8265   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8266 
 8267   ins_encode %{
 8268     if ($dst$$reg != $src$$reg) {
 8269       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8270     }
 8271   %}
 8272 
 8273   ins_pipe(ialu_reg);
 8274 %}
 8275 
<a name="8" id="anc8"></a>














 8276 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8277   match(Set dst (CastP2X src));
 8278 
 8279   ins_cost(INSN_COST);
 8280   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8281 
 8282   ins_encode %{
 8283     if ($dst$$reg != $src$$reg) {
 8284       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8285     }
 8286   %}
 8287 
 8288   ins_pipe(ialu_reg);
 8289 %}
 8290 
<a name="9" id="anc9"></a>






























 8291 // Convert oop into int for vectors alignment masking
 8292 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8293   match(Set dst (ConvL2I (CastP2X src)));
 8294 
 8295   ins_cost(INSN_COST);
 8296   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8297   ins_encode %{
 8298     __ movw($dst$$Register, $src$$Register);
 8299   %}
 8300 
 8301   ins_pipe(ialu_reg);
 8302 %}
 8303 
 8304 // Convert compressed oop into int for vectors alignment masking
 8305 // in case of 32bit oops (heap &lt; 4Gb).
 8306 instruct convN2I(iRegINoSp dst, iRegN src)
 8307 %{
 8308   predicate(CompressedOops::shift() == 0);
 8309   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8310 
 8311   ins_cost(INSN_COST);
 8312   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8313   ins_encode %{
 8314     __ movw($dst$$Register, $src$$Register);
 8315   %}
 8316 
 8317   ins_pipe(ialu_reg);
 8318 %}
 8319 
 8320 
 8321 // Convert oop pointer into compressed form
 8322 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8323   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8324   match(Set dst (EncodeP src));
 8325   effect(KILL cr);
 8326   ins_cost(INSN_COST * 3);
 8327   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8328   ins_encode %{
 8329     Register s = $src$$Register;
 8330     Register d = $dst$$Register;
 8331     __ encode_heap_oop(d, s);
 8332   %}
 8333   ins_pipe(ialu_reg);
 8334 %}
 8335 
 8336 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8337   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8338   match(Set dst (EncodeP src));
 8339   ins_cost(INSN_COST * 3);
 8340   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8341   ins_encode %{
 8342     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8343   %}
 8344   ins_pipe(ialu_reg);
 8345 %}
 8346 
 8347 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8348   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8349             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8350   match(Set dst (DecodeN src));
 8351   ins_cost(INSN_COST * 3);
 8352   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8353   ins_encode %{
 8354     Register s = $src$$Register;
 8355     Register d = $dst$$Register;
 8356     __ decode_heap_oop(d, s);
 8357   %}
 8358   ins_pipe(ialu_reg);
 8359 %}
 8360 
 8361 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8362   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8363             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8364   match(Set dst (DecodeN src));
 8365   ins_cost(INSN_COST * 3);
 8366   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8367   ins_encode %{
 8368     Register s = $src$$Register;
 8369     Register d = $dst$$Register;
 8370     __ decode_heap_oop_not_null(d, s);
 8371   %}
 8372   ins_pipe(ialu_reg);
 8373 %}
 8374 
 8375 // n.b. AArch64 implementations of encode_klass_not_null and
 8376 // decode_klass_not_null do not modify the flags register so, unlike
 8377 // Intel, we don&#39;t kill CR as a side effect here
 8378 
 8379 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8380   match(Set dst (EncodePKlass src));
 8381 
 8382   ins_cost(INSN_COST * 3);
 8383   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8384 
 8385   ins_encode %{
 8386     Register src_reg = as_Register($src$$reg);
 8387     Register dst_reg = as_Register($dst$$reg);
 8388     __ encode_klass_not_null(dst_reg, src_reg);
 8389   %}
 8390 
 8391    ins_pipe(ialu_reg);
 8392 %}
 8393 
 8394 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8395   match(Set dst (DecodeNKlass src));
 8396 
 8397   ins_cost(INSN_COST * 3);
 8398   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8399 
 8400   ins_encode %{
 8401     Register src_reg = as_Register($src$$reg);
 8402     Register dst_reg = as_Register($dst$$reg);
 8403     if (dst_reg != src_reg) {
 8404       __ decode_klass_not_null(dst_reg, src_reg);
 8405     } else {
 8406       __ decode_klass_not_null(dst_reg);
 8407     }
 8408   %}
 8409 
 8410    ins_pipe(ialu_reg);
 8411 %}
 8412 
 8413 instruct checkCastPP(iRegPNoSp dst)
 8414 %{
 8415   match(Set dst (CheckCastPP dst));
 8416 
 8417   size(0);
 8418   format %{ &quot;# checkcastPP of $dst&quot; %}
 8419   ins_encode(/* empty encoding */);
 8420   ins_pipe(pipe_class_empty);
 8421 %}
 8422 
 8423 instruct castPP(iRegPNoSp dst)
 8424 %{
 8425   match(Set dst (CastPP dst));
 8426 
 8427   size(0);
 8428   format %{ &quot;# castPP of $dst&quot; %}
 8429   ins_encode(/* empty encoding */);
 8430   ins_pipe(pipe_class_empty);
 8431 %}
 8432 
 8433 instruct castII(iRegI dst)
 8434 %{
 8435   match(Set dst (CastII dst));
 8436 
 8437   size(0);
 8438   format %{ &quot;# castII of $dst&quot; %}
 8439   ins_encode(/* empty encoding */);
 8440   ins_cost(0);
 8441   ins_pipe(pipe_class_empty);
 8442 %}
 8443 
 8444 instruct castLL(iRegL dst)
 8445 %{
 8446   match(Set dst (CastLL dst));
 8447 
 8448   size(0);
 8449   format %{ &quot;# castLL of $dst&quot; %}
 8450   ins_encode(/* empty encoding */);
 8451   ins_cost(0);
 8452   ins_pipe(pipe_class_empty);
 8453 %}
 8454 
 8455 // ============================================================================
 8456 // Atomic operation instructions
 8457 //
 8458 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8459 // Store{PIL}Conditional instructions using a normal load for the
 8460 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8461 //
 8462 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8463 // pair to lock object allocations from Eden space when not using
 8464 // TLABs.
 8465 //
 8466 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8467 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8468 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8469 // only for 64-bit.
 8470 //
 8471 // We implement LoadPLocked and StorePLocked instructions using,
 8472 // respectively the AArch64 hw load-exclusive and store-conditional
 8473 // instructions. Whereas we must implement each of
 8474 // Store{IL}Conditional using a CAS which employs a pair of
 8475 // instructions comprising a load-exclusive followed by a
 8476 // store-conditional.
 8477 
 8478 
 8479 // Locked-load (linked load) of the current heap-top
 8480 // used when updating the eden heap top
 8481 // implemented using ldaxr on AArch64
 8482 
 8483 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8484 %{
 8485   match(Set dst (LoadPLocked mem));
 8486 
 8487   ins_cost(VOLATILE_REF_COST);
 8488 
 8489   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8490 
 8491   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8492 
 8493   ins_pipe(pipe_serial);
 8494 %}
 8495 
 8496 // Conditional-store of the updated heap-top.
 8497 // Used during allocation of the shared heap.
 8498 // Sets flag (EQ) on success.
 8499 // implemented using stlxr on AArch64.
 8500 
 8501 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8502 %{
 8503   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8504 
 8505   ins_cost(VOLATILE_REF_COST);
 8506 
 8507  // TODO
 8508  // do we need to do a store-conditional release or can we just use a
 8509  // plain store-conditional?
 8510 
 8511   format %{
 8512     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8513     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8514   %}
 8515 
 8516   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8517 
 8518   ins_pipe(pipe_serial);
 8519 %}
 8520 
 8521 
 8522 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8523 // when attempting to rebias a lock towards the current thread.  We
 8524 // must use the acquire form of cmpxchg in order to guarantee acquire
 8525 // semantics in this case.
 8526 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8527 %{
 8528   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8529 
 8530   ins_cost(VOLATILE_REF_COST);
 8531 
 8532   format %{
 8533     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8534     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8535   %}
 8536 
 8537   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8538 
 8539   ins_pipe(pipe_slow);
 8540 %}
 8541 
 8542 // storeIConditional also has acquire semantics, for no better reason
 8543 // than matching storeLConditional.  At the time of writing this
 8544 // comment storeIConditional was not used anywhere by AArch64.
 8545 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8546 %{
 8547   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8548 
 8549   ins_cost(VOLATILE_REF_COST);
 8550 
 8551   format %{
 8552     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8553     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8554   %}
 8555 
 8556   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8557 
 8558   ins_pipe(pipe_slow);
 8559 %}
 8560 
 8561 // standard CompareAndSwapX when we are using barriers
 8562 // these have higher priority than the rules selected by a predicate
 8563 
 8564 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8565 // can&#39;t match them
 8566 
 8567 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8568 
 8569   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8570   ins_cost(2 * VOLATILE_REF_COST);
 8571 
 8572   effect(KILL cr);
 8573 
 8574   format %{
 8575     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8576     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8577   %}
 8578 
 8579   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8580             aarch64_enc_cset_eq(res));
 8581 
 8582   ins_pipe(pipe_slow);
 8583 %}
 8584 
 8585 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8586 
 8587   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8588   ins_cost(2 * VOLATILE_REF_COST);
 8589 
 8590   effect(KILL cr);
 8591 
 8592   format %{
 8593     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8594     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8595   %}
 8596 
 8597   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8598             aarch64_enc_cset_eq(res));
 8599 
 8600   ins_pipe(pipe_slow);
 8601 %}
 8602 
 8603 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8604 
 8605   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8606   ins_cost(2 * VOLATILE_REF_COST);
 8607 
 8608   effect(KILL cr);
 8609 
 8610  format %{
 8611     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8612     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8613  %}
 8614 
 8615  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8616             aarch64_enc_cset_eq(res));
 8617 
 8618   ins_pipe(pipe_slow);
 8619 %}
 8620 
 8621 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8622 
 8623   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8624   ins_cost(2 * VOLATILE_REF_COST);
 8625 
 8626   effect(KILL cr);
 8627 
 8628  format %{
 8629     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8630     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8631  %}
 8632 
 8633  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8634             aarch64_enc_cset_eq(res));
 8635 
 8636   ins_pipe(pipe_slow);
 8637 %}
 8638 
 8639 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8640 
 8641   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8642   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8643   ins_cost(2 * VOLATILE_REF_COST);
 8644 
 8645   effect(KILL cr);
 8646 
 8647  format %{
 8648     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8649     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8650  %}
 8651 
 8652  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8653             aarch64_enc_cset_eq(res));
 8654 
 8655   ins_pipe(pipe_slow);
 8656 %}
 8657 
 8658 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8659 
 8660   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8661   ins_cost(2 * VOLATILE_REF_COST);
 8662 
 8663   effect(KILL cr);
 8664 
 8665  format %{
 8666     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8667     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8668  %}
 8669 
 8670  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8671             aarch64_enc_cset_eq(res));
 8672 
 8673   ins_pipe(pipe_slow);
 8674 %}
 8675 
 8676 // alternative CompareAndSwapX when we are eliding barriers
 8677 
 8678 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8679 
 8680   predicate(needs_acquiring_load_exclusive(n));
 8681   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8682   ins_cost(VOLATILE_REF_COST);
 8683 
 8684   effect(KILL cr);
 8685 
 8686   format %{
 8687     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8688     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8689   %}
 8690 
 8691   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8692             aarch64_enc_cset_eq(res));
 8693 
 8694   ins_pipe(pipe_slow);
 8695 %}
 8696 
 8697 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8698 
 8699   predicate(needs_acquiring_load_exclusive(n));
 8700   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8701   ins_cost(VOLATILE_REF_COST);
 8702 
 8703   effect(KILL cr);
 8704 
 8705   format %{
 8706     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8707     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8708   %}
 8709 
 8710   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8711             aarch64_enc_cset_eq(res));
 8712 
 8713   ins_pipe(pipe_slow);
 8714 %}
 8715 
 8716 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8717 
 8718   predicate(needs_acquiring_load_exclusive(n));
 8719   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8720   ins_cost(VOLATILE_REF_COST);
 8721 
 8722   effect(KILL cr);
 8723 
 8724  format %{
 8725     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8726     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8727  %}
 8728 
 8729  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8730             aarch64_enc_cset_eq(res));
 8731 
 8732   ins_pipe(pipe_slow);
 8733 %}
 8734 
 8735 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8736 
 8737   predicate(needs_acquiring_load_exclusive(n));
 8738   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8739   ins_cost(VOLATILE_REF_COST);
 8740 
 8741   effect(KILL cr);
 8742 
 8743  format %{
 8744     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8745     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8746  %}
 8747 
 8748  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8749             aarch64_enc_cset_eq(res));
 8750 
 8751   ins_pipe(pipe_slow);
 8752 %}
 8753 
 8754 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8755 
 8756   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8757   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8758   ins_cost(VOLATILE_REF_COST);
 8759 
 8760   effect(KILL cr);
 8761 
 8762  format %{
 8763     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8764     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8765  %}
 8766 
 8767  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8768             aarch64_enc_cset_eq(res));
 8769 
 8770   ins_pipe(pipe_slow);
 8771 %}
 8772 
 8773 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8774 
 8775   predicate(needs_acquiring_load_exclusive(n));
 8776   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8777   ins_cost(VOLATILE_REF_COST);
 8778 
 8779   effect(KILL cr);
 8780 
 8781  format %{
 8782     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8783     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8784  %}
 8785 
 8786  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8787             aarch64_enc_cset_eq(res));
 8788 
 8789   ins_pipe(pipe_slow);
 8790 %}
 8791 
 8792 
 8793 // ---------------------------------------------------------------------
 8794 
 8795 
 8796 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8797 
 8798 // Sundry CAS operations.  Note that release is always true,
 8799 // regardless of the memory ordering of the CAS.  This is because we
 8800 // need the volatile case to be sequentially consistent but there is
 8801 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8802 // can&#39;t check the type of memory ordering here, so we always emit a
 8803 // STLXR.
 8804 
 8805 // This section is generated from aarch64_ad_cas.m4
 8806 
 8807 
 8808 
 8809 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8810   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8811   ins_cost(2 * VOLATILE_REF_COST);
 8812   effect(TEMP_DEF res, KILL cr);
 8813   format %{
 8814     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8815   %}
 8816   ins_encode %{
 8817     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8818                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8819                /*weak*/ false, $res$$Register);
 8820     __ sxtbw($res$$Register, $res$$Register);
 8821   %}
 8822   ins_pipe(pipe_slow);
 8823 %}
 8824 
 8825 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8826   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8827   ins_cost(2 * VOLATILE_REF_COST);
 8828   effect(TEMP_DEF res, KILL cr);
 8829   format %{
 8830     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8831   %}
 8832   ins_encode %{
 8833     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8834                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8835                /*weak*/ false, $res$$Register);
 8836     __ sxthw($res$$Register, $res$$Register);
 8837   %}
 8838   ins_pipe(pipe_slow);
 8839 %}
 8840 
 8841 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8842   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8843   ins_cost(2 * VOLATILE_REF_COST);
 8844   effect(TEMP_DEF res, KILL cr);
 8845   format %{
 8846     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8847   %}
 8848   ins_encode %{
 8849     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8850                Assembler::word, /*acquire*/ false, /*release*/ true,
 8851                /*weak*/ false, $res$$Register);
 8852   %}
 8853   ins_pipe(pipe_slow);
 8854 %}
 8855 
 8856 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8857   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8858   ins_cost(2 * VOLATILE_REF_COST);
 8859   effect(TEMP_DEF res, KILL cr);
 8860   format %{
 8861     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8862   %}
 8863   ins_encode %{
 8864     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8865                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8866                /*weak*/ false, $res$$Register);
 8867   %}
 8868   ins_pipe(pipe_slow);
 8869 %}
 8870 
 8871 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8872   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8873   ins_cost(2 * VOLATILE_REF_COST);
 8874   effect(TEMP_DEF res, KILL cr);
 8875   format %{
 8876     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8877   %}
 8878   ins_encode %{
 8879     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8880                Assembler::word, /*acquire*/ false, /*release*/ true,
 8881                /*weak*/ false, $res$$Register);
 8882   %}
 8883   ins_pipe(pipe_slow);
 8884 %}
 8885 
 8886 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8887   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8888   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8889   ins_cost(2 * VOLATILE_REF_COST);
 8890   effect(TEMP_DEF res, KILL cr);
 8891   format %{
 8892     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8893   %}
 8894   ins_encode %{
 8895     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8896                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8897                /*weak*/ false, $res$$Register);
 8898   %}
 8899   ins_pipe(pipe_slow);
 8900 %}
 8901 
 8902 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8903   predicate(needs_acquiring_load_exclusive(n));
 8904   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8905   ins_cost(VOLATILE_REF_COST);
 8906   effect(TEMP_DEF res, KILL cr);
 8907   format %{
 8908     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8909   %}
 8910   ins_encode %{
 8911     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8912                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8913                /*weak*/ false, $res$$Register);
 8914     __ sxtbw($res$$Register, $res$$Register);
 8915   %}
 8916   ins_pipe(pipe_slow);
 8917 %}
 8918 
 8919 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8920   predicate(needs_acquiring_load_exclusive(n));
 8921   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8922   ins_cost(VOLATILE_REF_COST);
 8923   effect(TEMP_DEF res, KILL cr);
 8924   format %{
 8925     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8926   %}
 8927   ins_encode %{
 8928     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8929                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8930                /*weak*/ false, $res$$Register);
 8931     __ sxthw($res$$Register, $res$$Register);
 8932   %}
 8933   ins_pipe(pipe_slow);
 8934 %}
 8935 
 8936 
 8937 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8938   predicate(needs_acquiring_load_exclusive(n));
 8939   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8940   ins_cost(VOLATILE_REF_COST);
 8941   effect(TEMP_DEF res, KILL cr);
 8942   format %{
 8943     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8944   %}
 8945   ins_encode %{
 8946     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8947                Assembler::word, /*acquire*/ true, /*release*/ true,
 8948                /*weak*/ false, $res$$Register);
 8949   %}
 8950   ins_pipe(pipe_slow);
 8951 %}
 8952 
 8953 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8954   predicate(needs_acquiring_load_exclusive(n));
 8955   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8956   ins_cost(VOLATILE_REF_COST);
 8957   effect(TEMP_DEF res, KILL cr);
 8958   format %{
 8959     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8960   %}
 8961   ins_encode %{
 8962     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8963                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8964                /*weak*/ false, $res$$Register);
 8965   %}
 8966   ins_pipe(pipe_slow);
 8967 %}
 8968 
 8969 
 8970 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8971   predicate(needs_acquiring_load_exclusive(n));
 8972   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8973   ins_cost(VOLATILE_REF_COST);
 8974   effect(TEMP_DEF res, KILL cr);
 8975   format %{
 8976     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8977   %}
 8978   ins_encode %{
 8979     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8980                Assembler::word, /*acquire*/ true, /*release*/ true,
 8981                /*weak*/ false, $res$$Register);
 8982   %}
 8983   ins_pipe(pipe_slow);
 8984 %}
 8985 
 8986 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8987   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8988   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8989   ins_cost(VOLATILE_REF_COST);
 8990   effect(TEMP_DEF res, KILL cr);
 8991   format %{
 8992     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8993   %}
 8994   ins_encode %{
 8995     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8996                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8997                /*weak*/ false, $res$$Register);
 8998   %}
 8999   ins_pipe(pipe_slow);
 9000 %}
 9001 
 9002 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9003   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9004   ins_cost(2 * VOLATILE_REF_COST);
 9005   effect(KILL cr);
 9006   format %{
 9007     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9008     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9009   %}
 9010   ins_encode %{
 9011     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9012                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9013                /*weak*/ true, noreg);
 9014     __ csetw($res$$Register, Assembler::EQ);
 9015   %}
 9016   ins_pipe(pipe_slow);
 9017 %}
 9018 
 9019 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9020   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9021   ins_cost(2 * VOLATILE_REF_COST);
 9022   effect(KILL cr);
 9023   format %{
 9024     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9025     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9026   %}
 9027   ins_encode %{
 9028     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9029                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9030                /*weak*/ true, noreg);
 9031     __ csetw($res$$Register, Assembler::EQ);
 9032   %}
 9033   ins_pipe(pipe_slow);
 9034 %}
 9035 
 9036 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9037   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9038   ins_cost(2 * VOLATILE_REF_COST);
 9039   effect(KILL cr);
 9040   format %{
 9041     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9042     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9043   %}
 9044   ins_encode %{
 9045     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9046                Assembler::word, /*acquire*/ false, /*release*/ true,
 9047                /*weak*/ true, noreg);
 9048     __ csetw($res$$Register, Assembler::EQ);
 9049   %}
 9050   ins_pipe(pipe_slow);
 9051 %}
 9052 
 9053 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9054   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9055   ins_cost(2 * VOLATILE_REF_COST);
 9056   effect(KILL cr);
 9057   format %{
 9058     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9059     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9060   %}
 9061   ins_encode %{
 9062     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9063                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9064                /*weak*/ true, noreg);
 9065     __ csetw($res$$Register, Assembler::EQ);
 9066   %}
 9067   ins_pipe(pipe_slow);
 9068 %}
 9069 
 9070 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9071   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9072   ins_cost(2 * VOLATILE_REF_COST);
 9073   effect(KILL cr);
 9074   format %{
 9075     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9076     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9077   %}
 9078   ins_encode %{
 9079     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9080                Assembler::word, /*acquire*/ false, /*release*/ true,
 9081                /*weak*/ true, noreg);
 9082     __ csetw($res$$Register, Assembler::EQ);
 9083   %}
 9084   ins_pipe(pipe_slow);
 9085 %}
 9086 
 9087 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9088   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9089   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9090   ins_cost(2 * VOLATILE_REF_COST);
 9091   effect(KILL cr);
 9092   format %{
 9093     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9094     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9095   %}
 9096   ins_encode %{
 9097     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9098                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9099                /*weak*/ true, noreg);
 9100     __ csetw($res$$Register, Assembler::EQ);
 9101   %}
 9102   ins_pipe(pipe_slow);
 9103 %}
 9104 
 9105 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9106   predicate(needs_acquiring_load_exclusive(n));
 9107   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9108   ins_cost(VOLATILE_REF_COST);
 9109   effect(KILL cr);
 9110   format %{
 9111     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9112     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9113   %}
 9114   ins_encode %{
 9115     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9116                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9117                /*weak*/ true, noreg);
 9118     __ csetw($res$$Register, Assembler::EQ);
 9119   %}
 9120   ins_pipe(pipe_slow);
 9121 %}
 9122 
 9123 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9124   predicate(needs_acquiring_load_exclusive(n));
 9125   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9126   ins_cost(VOLATILE_REF_COST);
 9127   effect(KILL cr);
 9128   format %{
 9129     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9130     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9131   %}
 9132   ins_encode %{
 9133     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9134                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9135                /*weak*/ true, noreg);
 9136     __ csetw($res$$Register, Assembler::EQ);
 9137   %}
 9138   ins_pipe(pipe_slow);
 9139 %}
 9140 
 9141 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9142   predicate(needs_acquiring_load_exclusive(n));
 9143   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9144   ins_cost(VOLATILE_REF_COST);
 9145   effect(KILL cr);
 9146   format %{
 9147     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9148     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9149   %}
 9150   ins_encode %{
 9151     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9152                Assembler::word, /*acquire*/ true, /*release*/ true,
 9153                /*weak*/ true, noreg);
 9154     __ csetw($res$$Register, Assembler::EQ);
 9155   %}
 9156   ins_pipe(pipe_slow);
 9157 %}
 9158 
 9159 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9160   predicate(needs_acquiring_load_exclusive(n));
 9161   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9162   ins_cost(VOLATILE_REF_COST);
 9163   effect(KILL cr);
 9164   format %{
 9165     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9166     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9167   %}
 9168   ins_encode %{
 9169     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9170                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9171                /*weak*/ true, noreg);
 9172     __ csetw($res$$Register, Assembler::EQ);
 9173   %}
 9174   ins_pipe(pipe_slow);
 9175 %}
 9176 
 9177 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9178   predicate(needs_acquiring_load_exclusive(n));
 9179   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9180   ins_cost(VOLATILE_REF_COST);
 9181   effect(KILL cr);
 9182   format %{
 9183     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9184     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9185   %}
 9186   ins_encode %{
 9187     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9188                Assembler::word, /*acquire*/ true, /*release*/ true,
 9189                /*weak*/ true, noreg);
 9190     __ csetw($res$$Register, Assembler::EQ);
 9191   %}
 9192   ins_pipe(pipe_slow);
 9193 %}
 9194 
 9195 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9196   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9197   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9198   ins_cost(VOLATILE_REF_COST);
 9199   effect(KILL cr);
 9200   format %{
 9201     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9202     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9203   %}
 9204   ins_encode %{
 9205     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9206                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9207                /*weak*/ true, noreg);
 9208     __ csetw($res$$Register, Assembler::EQ);
 9209   %}
 9210   ins_pipe(pipe_slow);
 9211 %}
 9212 
 9213 // END This section of the file is automatically generated. Do not edit --------------
 9214 // ---------------------------------------------------------------------
 9215 
 9216 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9217   match(Set prev (GetAndSetI mem newv));
 9218   ins_cost(2 * VOLATILE_REF_COST);
 9219   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9220   ins_encode %{
 9221     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9222   %}
 9223   ins_pipe(pipe_serial);
 9224 %}
 9225 
 9226 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9227   match(Set prev (GetAndSetL mem newv));
 9228   ins_cost(2 * VOLATILE_REF_COST);
 9229   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9230   ins_encode %{
 9231     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9232   %}
 9233   ins_pipe(pipe_serial);
 9234 %}
 9235 
 9236 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9237   match(Set prev (GetAndSetN mem newv));
 9238   ins_cost(2 * VOLATILE_REF_COST);
 9239   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9240   ins_encode %{
 9241     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9242   %}
 9243   ins_pipe(pipe_serial);
 9244 %}
 9245 
 9246 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9247   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9248   match(Set prev (GetAndSetP mem newv));
 9249   ins_cost(2 * VOLATILE_REF_COST);
 9250   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9251   ins_encode %{
 9252     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9253   %}
 9254   ins_pipe(pipe_serial);
 9255 %}
 9256 
 9257 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9258   predicate(needs_acquiring_load_exclusive(n));
 9259   match(Set prev (GetAndSetI mem newv));
 9260   ins_cost(VOLATILE_REF_COST);
 9261   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9262   ins_encode %{
 9263     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9264   %}
 9265   ins_pipe(pipe_serial);
 9266 %}
 9267 
 9268 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9269   predicate(needs_acquiring_load_exclusive(n));
 9270   match(Set prev (GetAndSetL mem newv));
 9271   ins_cost(VOLATILE_REF_COST);
 9272   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9273   ins_encode %{
 9274     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9275   %}
 9276   ins_pipe(pipe_serial);
 9277 %}
 9278 
 9279 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9280   predicate(needs_acquiring_load_exclusive(n));
 9281   match(Set prev (GetAndSetN mem newv));
 9282   ins_cost(VOLATILE_REF_COST);
 9283   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9284   ins_encode %{
 9285     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9286   %}
 9287   ins_pipe(pipe_serial);
 9288 %}
 9289 
 9290 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9291   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9292   match(Set prev (GetAndSetP mem newv));
 9293   ins_cost(VOLATILE_REF_COST);
 9294   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9295   ins_encode %{
 9296     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9297   %}
 9298   ins_pipe(pipe_serial);
 9299 %}
 9300 
 9301 
 9302 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9303   match(Set newval (GetAndAddL mem incr));
 9304   ins_cost(2 * VOLATILE_REF_COST + 1);
 9305   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9306   ins_encode %{
 9307     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9308   %}
 9309   ins_pipe(pipe_serial);
 9310 %}
 9311 
 9312 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9313   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9314   match(Set dummy (GetAndAddL mem incr));
 9315   ins_cost(2 * VOLATILE_REF_COST);
 9316   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9317   ins_encode %{
 9318     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9319   %}
 9320   ins_pipe(pipe_serial);
 9321 %}
 9322 
 9323 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9324   match(Set newval (GetAndAddL mem incr));
 9325   ins_cost(2 * VOLATILE_REF_COST + 1);
 9326   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9327   ins_encode %{
 9328     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9329   %}
 9330   ins_pipe(pipe_serial);
 9331 %}
 9332 
 9333 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9334   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9335   match(Set dummy (GetAndAddL mem incr));
 9336   ins_cost(2 * VOLATILE_REF_COST);
 9337   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9338   ins_encode %{
 9339     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9340   %}
 9341   ins_pipe(pipe_serial);
 9342 %}
 9343 
 9344 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9345   match(Set newval (GetAndAddI mem incr));
 9346   ins_cost(2 * VOLATILE_REF_COST + 1);
 9347   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9348   ins_encode %{
 9349     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9350   %}
 9351   ins_pipe(pipe_serial);
 9352 %}
 9353 
 9354 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9355   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9356   match(Set dummy (GetAndAddI mem incr));
 9357   ins_cost(2 * VOLATILE_REF_COST);
 9358   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9359   ins_encode %{
 9360     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9361   %}
 9362   ins_pipe(pipe_serial);
 9363 %}
 9364 
 9365 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9366   match(Set newval (GetAndAddI mem incr));
 9367   ins_cost(2 * VOLATILE_REF_COST + 1);
 9368   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9369   ins_encode %{
 9370     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9371   %}
 9372   ins_pipe(pipe_serial);
 9373 %}
 9374 
 9375 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9376   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9377   match(Set dummy (GetAndAddI mem incr));
 9378   ins_cost(2 * VOLATILE_REF_COST);
 9379   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9380   ins_encode %{
 9381     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9382   %}
 9383   ins_pipe(pipe_serial);
 9384 %}
 9385 
 9386 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9387   predicate(needs_acquiring_load_exclusive(n));
 9388   match(Set newval (GetAndAddL mem incr));
 9389   ins_cost(VOLATILE_REF_COST + 1);
 9390   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9391   ins_encode %{
 9392     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9393   %}
 9394   ins_pipe(pipe_serial);
 9395 %}
 9396 
 9397 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9398   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9399   match(Set dummy (GetAndAddL mem incr));
 9400   ins_cost(VOLATILE_REF_COST);
 9401   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9402   ins_encode %{
 9403     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9404   %}
 9405   ins_pipe(pipe_serial);
 9406 %}
 9407 
 9408 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9409   predicate(needs_acquiring_load_exclusive(n));
 9410   match(Set newval (GetAndAddL mem incr));
 9411   ins_cost(VOLATILE_REF_COST + 1);
 9412   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9413   ins_encode %{
 9414     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9415   %}
 9416   ins_pipe(pipe_serial);
 9417 %}
 9418 
 9419 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9420   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9421   match(Set dummy (GetAndAddL mem incr));
 9422   ins_cost(VOLATILE_REF_COST);
 9423   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9424   ins_encode %{
 9425     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9426   %}
 9427   ins_pipe(pipe_serial);
 9428 %}
 9429 
 9430 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9431   predicate(needs_acquiring_load_exclusive(n));
 9432   match(Set newval (GetAndAddI mem incr));
 9433   ins_cost(VOLATILE_REF_COST + 1);
 9434   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9435   ins_encode %{
 9436     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9437   %}
 9438   ins_pipe(pipe_serial);
 9439 %}
 9440 
 9441 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9442   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9443   match(Set dummy (GetAndAddI mem incr));
 9444   ins_cost(VOLATILE_REF_COST);
 9445   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9446   ins_encode %{
 9447     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9448   %}
 9449   ins_pipe(pipe_serial);
 9450 %}
 9451 
 9452 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9453   predicate(needs_acquiring_load_exclusive(n));
 9454   match(Set newval (GetAndAddI mem incr));
 9455   ins_cost(VOLATILE_REF_COST + 1);
 9456   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9457   ins_encode %{
 9458     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9459   %}
 9460   ins_pipe(pipe_serial);
 9461 %}
 9462 
 9463 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9464   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9465   match(Set dummy (GetAndAddI mem incr));
 9466   ins_cost(VOLATILE_REF_COST);
 9467   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9468   ins_encode %{
 9469     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9470   %}
 9471   ins_pipe(pipe_serial);
 9472 %}
 9473 
 9474 // Manifest a CmpL result in an integer register.
 9475 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9476 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9477 %{
 9478   match(Set dst (CmpL3 src1 src2));
 9479   effect(KILL flags);
 9480 
 9481   ins_cost(INSN_COST * 6);
 9482   format %{
 9483       &quot;cmp $src1, $src2&quot;
 9484       &quot;csetw $dst, ne&quot;
 9485       &quot;cnegw $dst, lt&quot;
 9486   %}
 9487   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9488   ins_encode %{
 9489     __ cmp($src1$$Register, $src2$$Register);
 9490     __ csetw($dst$$Register, Assembler::NE);
 9491     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9492   %}
 9493 
 9494   ins_pipe(pipe_class_default);
 9495 %}
 9496 
 9497 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9498 %{
 9499   match(Set dst (CmpL3 src1 src2));
 9500   effect(KILL flags);
 9501 
 9502   ins_cost(INSN_COST * 6);
 9503   format %{
 9504       &quot;cmp $src1, $src2&quot;
 9505       &quot;csetw $dst, ne&quot;
 9506       &quot;cnegw $dst, lt&quot;
 9507   %}
 9508   ins_encode %{
 9509     int32_t con = (int32_t)$src2$$constant;
 9510      if (con &lt; 0) {
 9511       __ adds(zr, $src1$$Register, -con);
 9512     } else {
 9513       __ subs(zr, $src1$$Register, con);
 9514     }
 9515     __ csetw($dst$$Register, Assembler::NE);
 9516     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9517   %}
 9518 
 9519   ins_pipe(pipe_class_default);
 9520 %}
 9521 
 9522 // ============================================================================
 9523 // Conditional Move Instructions
 9524 
 9525 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9526 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9527 // define an op class which merged both inputs and use it to type the
 9528 // argument to a single rule. unfortunatelyt his fails because the
 9529 // opclass does not live up to the COND_INTER interface of its
 9530 // component operands. When the generic code tries to negate the
 9531 // operand it ends up running the generci Machoper::negate method
 9532 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9533 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9534 
 9535 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9536   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9537 
 9538   ins_cost(INSN_COST * 2);
 9539   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9540 
 9541   ins_encode %{
 9542     __ cselw(as_Register($dst$$reg),
 9543              as_Register($src2$$reg),
 9544              as_Register($src1$$reg),
 9545              (Assembler::Condition)$cmp$$cmpcode);
 9546   %}
 9547 
 9548   ins_pipe(icond_reg_reg);
 9549 %}
 9550 
 9551 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9552   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9553 
 9554   ins_cost(INSN_COST * 2);
 9555   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9556 
 9557   ins_encode %{
 9558     __ cselw(as_Register($dst$$reg),
 9559              as_Register($src2$$reg),
 9560              as_Register($src1$$reg),
 9561              (Assembler::Condition)$cmp$$cmpcode);
 9562   %}
 9563 
 9564   ins_pipe(icond_reg_reg);
 9565 %}
 9566 
 9567 // special cases where one arg is zero
 9568 
 9569 // n.b. this is selected in preference to the rule above because it
 9570 // avoids loading constant 0 into a source register
 9571 
 9572 // TODO
 9573 // we ought only to be able to cull one of these variants as the ideal
 9574 // transforms ought always to order the zero consistently (to left/right?)
 9575 
 9576 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9577   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9578 
 9579   ins_cost(INSN_COST * 2);
 9580   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9581 
 9582   ins_encode %{
 9583     __ cselw(as_Register($dst$$reg),
 9584              as_Register($src$$reg),
 9585              zr,
 9586              (Assembler::Condition)$cmp$$cmpcode);
 9587   %}
 9588 
 9589   ins_pipe(icond_reg);
 9590 %}
 9591 
 9592 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9593   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9594 
 9595   ins_cost(INSN_COST * 2);
 9596   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9597 
 9598   ins_encode %{
 9599     __ cselw(as_Register($dst$$reg),
 9600              as_Register($src$$reg),
 9601              zr,
 9602              (Assembler::Condition)$cmp$$cmpcode);
 9603   %}
 9604 
 9605   ins_pipe(icond_reg);
 9606 %}
 9607 
 9608 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9609   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9610 
 9611   ins_cost(INSN_COST * 2);
 9612   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9613 
 9614   ins_encode %{
 9615     __ cselw(as_Register($dst$$reg),
 9616              zr,
 9617              as_Register($src$$reg),
 9618              (Assembler::Condition)$cmp$$cmpcode);
 9619   %}
 9620 
 9621   ins_pipe(icond_reg);
 9622 %}
 9623 
 9624 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9625   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9626 
 9627   ins_cost(INSN_COST * 2);
 9628   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9629 
 9630   ins_encode %{
 9631     __ cselw(as_Register($dst$$reg),
 9632              zr,
 9633              as_Register($src$$reg),
 9634              (Assembler::Condition)$cmp$$cmpcode);
 9635   %}
 9636 
 9637   ins_pipe(icond_reg);
 9638 %}
 9639 
 9640 // special case for creating a boolean 0 or 1
 9641 
 9642 // n.b. this is selected in preference to the rule above because it
 9643 // avoids loading constants 0 and 1 into a source register
 9644 
 9645 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9646   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9647 
 9648   ins_cost(INSN_COST * 2);
 9649   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9650 
 9651   ins_encode %{
 9652     // equivalently
 9653     // cset(as_Register($dst$$reg),
 9654     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9655     __ csincw(as_Register($dst$$reg),
 9656              zr,
 9657              zr,
 9658              (Assembler::Condition)$cmp$$cmpcode);
 9659   %}
 9660 
 9661   ins_pipe(icond_none);
 9662 %}
 9663 
 9664 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9665   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9666 
 9667   ins_cost(INSN_COST * 2);
 9668   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9669 
 9670   ins_encode %{
 9671     // equivalently
 9672     // cset(as_Register($dst$$reg),
 9673     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9674     __ csincw(as_Register($dst$$reg),
 9675              zr,
 9676              zr,
 9677              (Assembler::Condition)$cmp$$cmpcode);
 9678   %}
 9679 
 9680   ins_pipe(icond_none);
 9681 %}
 9682 
 9683 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9684   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9685 
 9686   ins_cost(INSN_COST * 2);
 9687   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9688 
 9689   ins_encode %{
 9690     __ csel(as_Register($dst$$reg),
 9691             as_Register($src2$$reg),
 9692             as_Register($src1$$reg),
 9693             (Assembler::Condition)$cmp$$cmpcode);
 9694   %}
 9695 
 9696   ins_pipe(icond_reg_reg);
 9697 %}
 9698 
 9699 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9700   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9701 
 9702   ins_cost(INSN_COST * 2);
 9703   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9704 
 9705   ins_encode %{
 9706     __ csel(as_Register($dst$$reg),
 9707             as_Register($src2$$reg),
 9708             as_Register($src1$$reg),
 9709             (Assembler::Condition)$cmp$$cmpcode);
 9710   %}
 9711 
 9712   ins_pipe(icond_reg_reg);
 9713 %}
 9714 
 9715 // special cases where one arg is zero
 9716 
 9717 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9718   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9719 
 9720   ins_cost(INSN_COST * 2);
 9721   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9722 
 9723   ins_encode %{
 9724     __ csel(as_Register($dst$$reg),
 9725             zr,
 9726             as_Register($src$$reg),
 9727             (Assembler::Condition)$cmp$$cmpcode);
 9728   %}
 9729 
 9730   ins_pipe(icond_reg);
 9731 %}
 9732 
 9733 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9734   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9735 
 9736   ins_cost(INSN_COST * 2);
 9737   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9738 
 9739   ins_encode %{
 9740     __ csel(as_Register($dst$$reg),
 9741             zr,
 9742             as_Register($src$$reg),
 9743             (Assembler::Condition)$cmp$$cmpcode);
 9744   %}
 9745 
 9746   ins_pipe(icond_reg);
 9747 %}
 9748 
 9749 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9750   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9751 
 9752   ins_cost(INSN_COST * 2);
 9753   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9754 
 9755   ins_encode %{
 9756     __ csel(as_Register($dst$$reg),
 9757             as_Register($src$$reg),
 9758             zr,
 9759             (Assembler::Condition)$cmp$$cmpcode);
 9760   %}
 9761 
 9762   ins_pipe(icond_reg);
 9763 %}
 9764 
 9765 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9766   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9767 
 9768   ins_cost(INSN_COST * 2);
 9769   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9770 
 9771   ins_encode %{
 9772     __ csel(as_Register($dst$$reg),
 9773             as_Register($src$$reg),
 9774             zr,
 9775             (Assembler::Condition)$cmp$$cmpcode);
 9776   %}
 9777 
 9778   ins_pipe(icond_reg);
 9779 %}
 9780 
 9781 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9782   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9783 
 9784   ins_cost(INSN_COST * 2);
 9785   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9786 
 9787   ins_encode %{
 9788     __ csel(as_Register($dst$$reg),
 9789             as_Register($src2$$reg),
 9790             as_Register($src1$$reg),
 9791             (Assembler::Condition)$cmp$$cmpcode);
 9792   %}
 9793 
 9794   ins_pipe(icond_reg_reg);
 9795 %}
 9796 
 9797 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9798   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9799 
 9800   ins_cost(INSN_COST * 2);
 9801   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9802 
 9803   ins_encode %{
 9804     __ csel(as_Register($dst$$reg),
 9805             as_Register($src2$$reg),
 9806             as_Register($src1$$reg),
 9807             (Assembler::Condition)$cmp$$cmpcode);
 9808   %}
 9809 
 9810   ins_pipe(icond_reg_reg);
 9811 %}
 9812 
 9813 // special cases where one arg is zero
 9814 
 9815 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9816   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9817 
 9818   ins_cost(INSN_COST * 2);
 9819   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9820 
 9821   ins_encode %{
 9822     __ csel(as_Register($dst$$reg),
 9823             zr,
 9824             as_Register($src$$reg),
 9825             (Assembler::Condition)$cmp$$cmpcode);
 9826   %}
 9827 
 9828   ins_pipe(icond_reg);
 9829 %}
 9830 
 9831 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9832   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9833 
 9834   ins_cost(INSN_COST * 2);
 9835   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9836 
 9837   ins_encode %{
 9838     __ csel(as_Register($dst$$reg),
 9839             zr,
 9840             as_Register($src$$reg),
 9841             (Assembler::Condition)$cmp$$cmpcode);
 9842   %}
 9843 
 9844   ins_pipe(icond_reg);
 9845 %}
 9846 
 9847 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9848   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9849 
 9850   ins_cost(INSN_COST * 2);
 9851   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9852 
 9853   ins_encode %{
 9854     __ csel(as_Register($dst$$reg),
 9855             as_Register($src$$reg),
 9856             zr,
 9857             (Assembler::Condition)$cmp$$cmpcode);
 9858   %}
 9859 
 9860   ins_pipe(icond_reg);
 9861 %}
 9862 
 9863 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9864   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9865 
 9866   ins_cost(INSN_COST * 2);
 9867   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9868 
 9869   ins_encode %{
 9870     __ csel(as_Register($dst$$reg),
 9871             as_Register($src$$reg),
 9872             zr,
 9873             (Assembler::Condition)$cmp$$cmpcode);
 9874   %}
 9875 
 9876   ins_pipe(icond_reg);
 9877 %}
 9878 
 9879 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9880   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9881 
 9882   ins_cost(INSN_COST * 2);
 9883   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9884 
 9885   ins_encode %{
 9886     __ cselw(as_Register($dst$$reg),
 9887              as_Register($src2$$reg),
 9888              as_Register($src1$$reg),
 9889              (Assembler::Condition)$cmp$$cmpcode);
 9890   %}
 9891 
 9892   ins_pipe(icond_reg_reg);
 9893 %}
 9894 
 9895 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9896   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9897 
 9898   ins_cost(INSN_COST * 2);
 9899   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9900 
 9901   ins_encode %{
 9902     __ cselw(as_Register($dst$$reg),
 9903              as_Register($src2$$reg),
 9904              as_Register($src1$$reg),
 9905              (Assembler::Condition)$cmp$$cmpcode);
 9906   %}
 9907 
 9908   ins_pipe(icond_reg_reg);
 9909 %}
 9910 
 9911 // special cases where one arg is zero
 9912 
 9913 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9914   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9915 
 9916   ins_cost(INSN_COST * 2);
 9917   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9918 
 9919   ins_encode %{
 9920     __ cselw(as_Register($dst$$reg),
 9921              zr,
 9922              as_Register($src$$reg),
 9923              (Assembler::Condition)$cmp$$cmpcode);
 9924   %}
 9925 
 9926   ins_pipe(icond_reg);
 9927 %}
 9928 
 9929 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9930   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9931 
 9932   ins_cost(INSN_COST * 2);
 9933   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9934 
 9935   ins_encode %{
 9936     __ cselw(as_Register($dst$$reg),
 9937              zr,
 9938              as_Register($src$$reg),
 9939              (Assembler::Condition)$cmp$$cmpcode);
 9940   %}
 9941 
 9942   ins_pipe(icond_reg);
 9943 %}
 9944 
 9945 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9946   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9947 
 9948   ins_cost(INSN_COST * 2);
 9949   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9950 
 9951   ins_encode %{
 9952     __ cselw(as_Register($dst$$reg),
 9953              as_Register($src$$reg),
 9954              zr,
 9955              (Assembler::Condition)$cmp$$cmpcode);
 9956   %}
 9957 
 9958   ins_pipe(icond_reg);
 9959 %}
 9960 
 9961 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9962   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9963 
 9964   ins_cost(INSN_COST * 2);
 9965   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9966 
 9967   ins_encode %{
 9968     __ cselw(as_Register($dst$$reg),
 9969              as_Register($src$$reg),
 9970              zr,
 9971              (Assembler::Condition)$cmp$$cmpcode);
 9972   %}
 9973 
 9974   ins_pipe(icond_reg);
 9975 %}
 9976 
 9977 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9978 %{
 9979   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9980 
 9981   ins_cost(INSN_COST * 3);
 9982 
 9983   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
 9984   ins_encode %{
 9985     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
 9986     __ fcsels(as_FloatRegister($dst$$reg),
 9987               as_FloatRegister($src2$$reg),
 9988               as_FloatRegister($src1$$reg),
 9989               cond);
 9990   %}
 9991 
 9992   ins_pipe(fp_cond_reg_reg_s);
 9993 %}
 9994 
 9995 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
 9996 %{
 9997   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9998 
 9999   ins_cost(INSN_COST * 3);
10000 
10001   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10002   ins_encode %{
10003     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10004     __ fcsels(as_FloatRegister($dst$$reg),
10005               as_FloatRegister($src2$$reg),
10006               as_FloatRegister($src1$$reg),
10007               cond);
10008   %}
10009 
10010   ins_pipe(fp_cond_reg_reg_s);
10011 %}
10012 
10013 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10014 %{
10015   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10016 
10017   ins_cost(INSN_COST * 3);
10018 
10019   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10020   ins_encode %{
10021     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10022     __ fcseld(as_FloatRegister($dst$$reg),
10023               as_FloatRegister($src2$$reg),
10024               as_FloatRegister($src1$$reg),
10025               cond);
10026   %}
10027 
10028   ins_pipe(fp_cond_reg_reg_d);
10029 %}
10030 
10031 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10032 %{
10033   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10034 
10035   ins_cost(INSN_COST * 3);
10036 
10037   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10038   ins_encode %{
10039     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10040     __ fcseld(as_FloatRegister($dst$$reg),
10041               as_FloatRegister($src2$$reg),
10042               as_FloatRegister($src1$$reg),
10043               cond);
10044   %}
10045 
10046   ins_pipe(fp_cond_reg_reg_d);
10047 %}
10048 
10049 // ============================================================================
10050 // Arithmetic Instructions
10051 //
10052 
10053 // Integer Addition
10054 
10055 // TODO
10056 // these currently employ operations which do not set CR and hence are
10057 // not flagged as killing CR but we would like to isolate the cases
10058 // where we want to set flags from those where we don&#39;t. need to work
10059 // out how to do that.
10060 
10061 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10062   match(Set dst (AddI src1 src2));
10063 
10064   ins_cost(INSN_COST);
10065   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10066 
10067   ins_encode %{
10068     __ addw(as_Register($dst$$reg),
10069             as_Register($src1$$reg),
10070             as_Register($src2$$reg));
10071   %}
10072 
10073   ins_pipe(ialu_reg_reg);
10074 %}
10075 
10076 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10077   match(Set dst (AddI src1 src2));
10078 
10079   ins_cost(INSN_COST);
10080   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10081 
10082   // use opcode to indicate that this is an add not a sub
10083   opcode(0x0);
10084 
10085   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10086 
10087   ins_pipe(ialu_reg_imm);
10088 %}
10089 
10090 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10091   match(Set dst (AddI (ConvL2I src1) src2));
10092 
10093   ins_cost(INSN_COST);
10094   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10095 
10096   // use opcode to indicate that this is an add not a sub
10097   opcode(0x0);
10098 
10099   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10100 
10101   ins_pipe(ialu_reg_imm);
10102 %}
10103 
10104 // Pointer Addition
10105 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10106   match(Set dst (AddP src1 src2));
10107 
10108   ins_cost(INSN_COST);
10109   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10110 
10111   ins_encode %{
10112     __ add(as_Register($dst$$reg),
10113            as_Register($src1$$reg),
10114            as_Register($src2$$reg));
10115   %}
10116 
10117   ins_pipe(ialu_reg_reg);
10118 %}
10119 
10120 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10121   match(Set dst (AddP src1 (ConvI2L src2)));
10122 
10123   ins_cost(1.9 * INSN_COST);
10124   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10125 
10126   ins_encode %{
10127     __ add(as_Register($dst$$reg),
10128            as_Register($src1$$reg),
10129            as_Register($src2$$reg), ext::sxtw);
10130   %}
10131 
10132   ins_pipe(ialu_reg_reg);
10133 %}
10134 
10135 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10136   match(Set dst (AddP src1 (LShiftL src2 scale)));
10137 
10138   ins_cost(1.9 * INSN_COST);
10139   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10140 
10141   ins_encode %{
10142     __ lea(as_Register($dst$$reg),
10143            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10144                    Address::lsl($scale$$constant)));
10145   %}
10146 
10147   ins_pipe(ialu_reg_reg_shift);
10148 %}
10149 
10150 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10151   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10152 
10153   ins_cost(1.9 * INSN_COST);
10154   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10155 
10156   ins_encode %{
10157     __ lea(as_Register($dst$$reg),
10158            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10159                    Address::sxtw($scale$$constant)));
10160   %}
10161 
10162   ins_pipe(ialu_reg_reg_shift);
10163 %}
10164 
10165 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10166   match(Set dst (LShiftL (ConvI2L src) scale));
10167 
10168   ins_cost(INSN_COST);
10169   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10170 
10171   ins_encode %{
10172     __ sbfiz(as_Register($dst$$reg),
10173           as_Register($src$$reg),
10174           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10175   %}
10176 
10177   ins_pipe(ialu_reg_shift);
10178 %}
10179 
10180 // Pointer Immediate Addition
10181 // n.b. this needs to be more expensive than using an indirect memory
10182 // operand
10183 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10184   match(Set dst (AddP src1 src2));
10185 
10186   ins_cost(INSN_COST);
10187   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10188 
10189   // use opcode to indicate that this is an add not a sub
10190   opcode(0x0);
10191 
10192   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10193 
10194   ins_pipe(ialu_reg_imm);
10195 %}
10196 
10197 // Long Addition
10198 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10199 
10200   match(Set dst (AddL src1 src2));
10201 
10202   ins_cost(INSN_COST);
10203   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10204 
10205   ins_encode %{
10206     __ add(as_Register($dst$$reg),
10207            as_Register($src1$$reg),
10208            as_Register($src2$$reg));
10209   %}
10210 
10211   ins_pipe(ialu_reg_reg);
10212 %}
10213 
10214 // No constant pool entries requiredLong Immediate Addition.
10215 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10216   match(Set dst (AddL src1 src2));
10217 
10218   ins_cost(INSN_COST);
10219   format %{ &quot;add $dst, $src1, $src2&quot; %}
10220 
10221   // use opcode to indicate that this is an add not a sub
10222   opcode(0x0);
10223 
10224   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10225 
10226   ins_pipe(ialu_reg_imm);
10227 %}
10228 
10229 // Integer Subtraction
10230 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10231   match(Set dst (SubI src1 src2));
10232 
10233   ins_cost(INSN_COST);
10234   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10235 
10236   ins_encode %{
10237     __ subw(as_Register($dst$$reg),
10238             as_Register($src1$$reg),
10239             as_Register($src2$$reg));
10240   %}
10241 
10242   ins_pipe(ialu_reg_reg);
10243 %}
10244 
10245 // Immediate Subtraction
10246 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10247   match(Set dst (SubI src1 src2));
10248 
10249   ins_cost(INSN_COST);
10250   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10251 
10252   // use opcode to indicate that this is a sub not an add
10253   opcode(0x1);
10254 
10255   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10256 
10257   ins_pipe(ialu_reg_imm);
10258 %}
10259 
10260 // Long Subtraction
10261 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10262 
10263   match(Set dst (SubL src1 src2));
10264 
10265   ins_cost(INSN_COST);
10266   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10267 
10268   ins_encode %{
10269     __ sub(as_Register($dst$$reg),
10270            as_Register($src1$$reg),
10271            as_Register($src2$$reg));
10272   %}
10273 
10274   ins_pipe(ialu_reg_reg);
10275 %}
10276 
10277 // No constant pool entries requiredLong Immediate Subtraction.
10278 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10279   match(Set dst (SubL src1 src2));
10280 
10281   ins_cost(INSN_COST);
10282   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10283 
10284   // use opcode to indicate that this is a sub not an add
10285   opcode(0x1);
10286 
10287   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10288 
10289   ins_pipe(ialu_reg_imm);
10290 %}
10291 
10292 // Integer Negation (special case for sub)
10293 
10294 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10295   match(Set dst (SubI zero src));
10296 
10297   ins_cost(INSN_COST);
10298   format %{ &quot;negw $dst, $src\t# int&quot; %}
10299 
10300   ins_encode %{
10301     __ negw(as_Register($dst$$reg),
10302             as_Register($src$$reg));
10303   %}
10304 
10305   ins_pipe(ialu_reg);
10306 %}
10307 
10308 // Long Negation
10309 
10310 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10311   match(Set dst (SubL zero src));
10312 
10313   ins_cost(INSN_COST);
10314   format %{ &quot;neg $dst, $src\t# long&quot; %}
10315 
10316   ins_encode %{
10317     __ neg(as_Register($dst$$reg),
10318            as_Register($src$$reg));
10319   %}
10320 
10321   ins_pipe(ialu_reg);
10322 %}
10323 
10324 // Integer Multiply
10325 
10326 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10327   match(Set dst (MulI src1 src2));
10328 
10329   ins_cost(INSN_COST * 3);
10330   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10331 
10332   ins_encode %{
10333     __ mulw(as_Register($dst$$reg),
10334             as_Register($src1$$reg),
10335             as_Register($src2$$reg));
10336   %}
10337 
10338   ins_pipe(imul_reg_reg);
10339 %}
10340 
10341 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10342   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10343 
10344   ins_cost(INSN_COST * 3);
10345   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10346 
10347   ins_encode %{
10348     __ smull(as_Register($dst$$reg),
10349              as_Register($src1$$reg),
10350              as_Register($src2$$reg));
10351   %}
10352 
10353   ins_pipe(imul_reg_reg);
10354 %}
10355 
10356 // Long Multiply
10357 
10358 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10359   match(Set dst (MulL src1 src2));
10360 
10361   ins_cost(INSN_COST * 5);
10362   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10363 
10364   ins_encode %{
10365     __ mul(as_Register($dst$$reg),
10366            as_Register($src1$$reg),
10367            as_Register($src2$$reg));
10368   %}
10369 
10370   ins_pipe(lmul_reg_reg);
10371 %}
10372 
10373 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10374 %{
10375   match(Set dst (MulHiL src1 src2));
10376 
10377   ins_cost(INSN_COST * 7);
10378   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10379 
10380   ins_encode %{
10381     __ smulh(as_Register($dst$$reg),
10382              as_Register($src1$$reg),
10383              as_Register($src2$$reg));
10384   %}
10385 
10386   ins_pipe(lmul_reg_reg);
10387 %}
10388 
10389 // Combined Integer Multiply &amp; Add/Sub
10390 
10391 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10392   match(Set dst (AddI src3 (MulI src1 src2)));
10393 
10394   ins_cost(INSN_COST * 3);
10395   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10396 
10397   ins_encode %{
10398     __ maddw(as_Register($dst$$reg),
10399              as_Register($src1$$reg),
10400              as_Register($src2$$reg),
10401              as_Register($src3$$reg));
10402   %}
10403 
10404   ins_pipe(imac_reg_reg);
10405 %}
10406 
10407 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10408   match(Set dst (SubI src3 (MulI src1 src2)));
10409 
10410   ins_cost(INSN_COST * 3);
10411   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10412 
10413   ins_encode %{
10414     __ msubw(as_Register($dst$$reg),
10415              as_Register($src1$$reg),
10416              as_Register($src2$$reg),
10417              as_Register($src3$$reg));
10418   %}
10419 
10420   ins_pipe(imac_reg_reg);
10421 %}
10422 
10423 // Combined Integer Multiply &amp; Neg
10424 
10425 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10426   match(Set dst (MulI (SubI zero src1) src2));
10427   match(Set dst (MulI src1 (SubI zero src2)));
10428 
10429   ins_cost(INSN_COST * 3);
10430   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10431 
10432   ins_encode %{
10433     __ mnegw(as_Register($dst$$reg),
10434              as_Register($src1$$reg),
10435              as_Register($src2$$reg));
10436   %}
10437 
10438   ins_pipe(imac_reg_reg);
10439 %}
10440 
10441 // Combined Long Multiply &amp; Add/Sub
10442 
10443 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10444   match(Set dst (AddL src3 (MulL src1 src2)));
10445 
10446   ins_cost(INSN_COST * 5);
10447   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10448 
10449   ins_encode %{
10450     __ madd(as_Register($dst$$reg),
10451             as_Register($src1$$reg),
10452             as_Register($src2$$reg),
10453             as_Register($src3$$reg));
10454   %}
10455 
10456   ins_pipe(lmac_reg_reg);
10457 %}
10458 
10459 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10460   match(Set dst (SubL src3 (MulL src1 src2)));
10461 
10462   ins_cost(INSN_COST * 5);
10463   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10464 
10465   ins_encode %{
10466     __ msub(as_Register($dst$$reg),
10467             as_Register($src1$$reg),
10468             as_Register($src2$$reg),
10469             as_Register($src3$$reg));
10470   %}
10471 
10472   ins_pipe(lmac_reg_reg);
10473 %}
10474 
10475 // Combined Long Multiply &amp; Neg
10476 
10477 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10478   match(Set dst (MulL (SubL zero src1) src2));
10479   match(Set dst (MulL src1 (SubL zero src2)));
10480 
10481   ins_cost(INSN_COST * 5);
10482   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10483 
10484   ins_encode %{
10485     __ mneg(as_Register($dst$$reg),
10486             as_Register($src1$$reg),
10487             as_Register($src2$$reg));
10488   %}
10489 
10490   ins_pipe(lmac_reg_reg);
10491 %}
10492 
10493 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10494 
10495 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10496   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10497 
10498   ins_cost(INSN_COST * 3);
10499   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10500 
10501   ins_encode %{
10502     __ smaddl(as_Register($dst$$reg),
10503               as_Register($src1$$reg),
10504               as_Register($src2$$reg),
10505               as_Register($src3$$reg));
10506   %}
10507 
10508   ins_pipe(imac_reg_reg);
10509 %}
10510 
10511 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10512   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10513 
10514   ins_cost(INSN_COST * 3);
10515   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10516 
10517   ins_encode %{
10518     __ smsubl(as_Register($dst$$reg),
10519               as_Register($src1$$reg),
10520               as_Register($src2$$reg),
10521               as_Register($src3$$reg));
10522   %}
10523 
10524   ins_pipe(imac_reg_reg);
10525 %}
10526 
10527 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10528   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10529   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10530 
10531   ins_cost(INSN_COST * 3);
10532   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10533 
10534   ins_encode %{
10535     __ smnegl(as_Register($dst$$reg),
10536               as_Register($src1$$reg),
10537               as_Register($src2$$reg));
10538   %}
10539 
10540   ins_pipe(imac_reg_reg);
10541 %}
10542 
10543 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10544 
10545 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10546   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10547 
10548   ins_cost(INSN_COST * 5);
10549   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10550             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10551 
10552   ins_encode %{
10553     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10554     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10555 
10556   ins_pipe(imac_reg_reg);
10557 %}
10558 
10559 // Integer Divide
10560 
10561 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10562   match(Set dst (DivI src1 src2));
10563 
10564   ins_cost(INSN_COST * 19);
10565   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10566 
10567   ins_encode(aarch64_enc_divw(dst, src1, src2));
10568   ins_pipe(idiv_reg_reg);
10569 %}
10570 
10571 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10572   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10573   ins_cost(INSN_COST);
10574   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10575   ins_encode %{
10576     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10577   %}
10578   ins_pipe(ialu_reg_shift);
10579 %}
10580 
10581 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10582   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10583   ins_cost(INSN_COST);
10584   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10585 
10586   ins_encode %{
10587     __ addw(as_Register($dst$$reg),
10588               as_Register($src$$reg),
10589               as_Register($src$$reg),
10590               Assembler::LSR, 31);
10591   %}
10592   ins_pipe(ialu_reg);
10593 %}
10594 
10595 // Long Divide
10596 
10597 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10598   match(Set dst (DivL src1 src2));
10599 
10600   ins_cost(INSN_COST * 35);
10601   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10602 
10603   ins_encode(aarch64_enc_div(dst, src1, src2));
10604   ins_pipe(ldiv_reg_reg);
10605 %}
10606 
10607 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10608   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10609   ins_cost(INSN_COST);
10610   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10611   ins_encode %{
10612     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10613   %}
10614   ins_pipe(ialu_reg_shift);
10615 %}
10616 
10617 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10618   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10619   ins_cost(INSN_COST);
10620   format %{ &quot;add $dst, $src, $div1&quot; %}
10621 
10622   ins_encode %{
10623     __ add(as_Register($dst$$reg),
10624               as_Register($src$$reg),
10625               as_Register($src$$reg),
10626               Assembler::LSR, 63);
10627   %}
10628   ins_pipe(ialu_reg);
10629 %}
10630 
10631 // Integer Remainder
10632 
10633 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10634   match(Set dst (ModI src1 src2));
10635 
10636   ins_cost(INSN_COST * 22);
10637   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10638             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10639 
10640   ins_encode(aarch64_enc_modw(dst, src1, src2));
10641   ins_pipe(idiv_reg_reg);
10642 %}
10643 
10644 // Long Remainder
10645 
10646 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10647   match(Set dst (ModL src1 src2));
10648 
10649   ins_cost(INSN_COST * 38);
10650   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10651             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10652 
10653   ins_encode(aarch64_enc_mod(dst, src1, src2));
10654   ins_pipe(ldiv_reg_reg);
10655 %}
10656 
10657 // Integer Shifts
10658 
10659 // Shift Left Register
10660 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10661   match(Set dst (LShiftI src1 src2));
10662 
10663   ins_cost(INSN_COST * 2);
10664   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10665 
10666   ins_encode %{
10667     __ lslvw(as_Register($dst$$reg),
10668              as_Register($src1$$reg),
10669              as_Register($src2$$reg));
10670   %}
10671 
10672   ins_pipe(ialu_reg_reg_vshift);
10673 %}
10674 
10675 // Shift Left Immediate
10676 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10677   match(Set dst (LShiftI src1 src2));
10678 
10679   ins_cost(INSN_COST);
10680   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10681 
10682   ins_encode %{
10683     __ lslw(as_Register($dst$$reg),
10684             as_Register($src1$$reg),
10685             $src2$$constant &amp; 0x1f);
10686   %}
10687 
10688   ins_pipe(ialu_reg_shift);
10689 %}
10690 
10691 // Shift Right Logical Register
10692 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10693   match(Set dst (URShiftI src1 src2));
10694 
10695   ins_cost(INSN_COST * 2);
10696   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10697 
10698   ins_encode %{
10699     __ lsrvw(as_Register($dst$$reg),
10700              as_Register($src1$$reg),
10701              as_Register($src2$$reg));
10702   %}
10703 
10704   ins_pipe(ialu_reg_reg_vshift);
10705 %}
10706 
10707 // Shift Right Logical Immediate
10708 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10709   match(Set dst (URShiftI src1 src2));
10710 
10711   ins_cost(INSN_COST);
10712   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10713 
10714   ins_encode %{
10715     __ lsrw(as_Register($dst$$reg),
10716             as_Register($src1$$reg),
10717             $src2$$constant &amp; 0x1f);
10718   %}
10719 
10720   ins_pipe(ialu_reg_shift);
10721 %}
10722 
10723 // Shift Right Arithmetic Register
10724 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10725   match(Set dst (RShiftI src1 src2));
10726 
10727   ins_cost(INSN_COST * 2);
10728   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10729 
10730   ins_encode %{
10731     __ asrvw(as_Register($dst$$reg),
10732              as_Register($src1$$reg),
10733              as_Register($src2$$reg));
10734   %}
10735 
10736   ins_pipe(ialu_reg_reg_vshift);
10737 %}
10738 
10739 // Shift Right Arithmetic Immediate
10740 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10741   match(Set dst (RShiftI src1 src2));
10742 
10743   ins_cost(INSN_COST);
10744   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10745 
10746   ins_encode %{
10747     __ asrw(as_Register($dst$$reg),
10748             as_Register($src1$$reg),
10749             $src2$$constant &amp; 0x1f);
10750   %}
10751 
10752   ins_pipe(ialu_reg_shift);
10753 %}
10754 
10755 // Combined Int Mask and Right Shift (using UBFM)
10756 // TODO
10757 
10758 // Long Shifts
10759 
10760 // Shift Left Register
10761 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10762   match(Set dst (LShiftL src1 src2));
10763 
10764   ins_cost(INSN_COST * 2);
10765   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10766 
10767   ins_encode %{
10768     __ lslv(as_Register($dst$$reg),
10769             as_Register($src1$$reg),
10770             as_Register($src2$$reg));
10771   %}
10772 
10773   ins_pipe(ialu_reg_reg_vshift);
10774 %}
10775 
10776 // Shift Left Immediate
10777 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10778   match(Set dst (LShiftL src1 src2));
10779 
10780   ins_cost(INSN_COST);
10781   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10782 
10783   ins_encode %{
10784     __ lsl(as_Register($dst$$reg),
10785             as_Register($src1$$reg),
10786             $src2$$constant &amp; 0x3f);
10787   %}
10788 
10789   ins_pipe(ialu_reg_shift);
10790 %}
10791 
10792 // Shift Right Logical Register
10793 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10794   match(Set dst (URShiftL src1 src2));
10795 
10796   ins_cost(INSN_COST * 2);
10797   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10798 
10799   ins_encode %{
10800     __ lsrv(as_Register($dst$$reg),
10801             as_Register($src1$$reg),
10802             as_Register($src2$$reg));
10803   %}
10804 
10805   ins_pipe(ialu_reg_reg_vshift);
10806 %}
10807 
10808 // Shift Right Logical Immediate
10809 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10810   match(Set dst (URShiftL src1 src2));
10811 
10812   ins_cost(INSN_COST);
10813   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10814 
10815   ins_encode %{
10816     __ lsr(as_Register($dst$$reg),
10817            as_Register($src1$$reg),
10818            $src2$$constant &amp; 0x3f);
10819   %}
10820 
10821   ins_pipe(ialu_reg_shift);
10822 %}
10823 
10824 // A special-case pattern for card table stores.
10825 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10826   match(Set dst (URShiftL (CastP2X src1) src2));
10827 
10828   ins_cost(INSN_COST);
10829   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10830 
10831   ins_encode %{
10832     __ lsr(as_Register($dst$$reg),
10833            as_Register($src1$$reg),
10834            $src2$$constant &amp; 0x3f);
10835   %}
10836 
10837   ins_pipe(ialu_reg_shift);
10838 %}
10839 
10840 // Shift Right Arithmetic Register
10841 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10842   match(Set dst (RShiftL src1 src2));
10843 
10844   ins_cost(INSN_COST * 2);
10845   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10846 
10847   ins_encode %{
10848     __ asrv(as_Register($dst$$reg),
10849             as_Register($src1$$reg),
10850             as_Register($src2$$reg));
10851   %}
10852 
10853   ins_pipe(ialu_reg_reg_vshift);
10854 %}
10855 
10856 // Shift Right Arithmetic Immediate
10857 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10858   match(Set dst (RShiftL src1 src2));
10859 
10860   ins_cost(INSN_COST);
10861   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10862 
10863   ins_encode %{
10864     __ asr(as_Register($dst$$reg),
10865            as_Register($src1$$reg),
10866            $src2$$constant &amp; 0x3f);
10867   %}
10868 
10869   ins_pipe(ialu_reg_shift);
10870 %}
10871 
10872 // BEGIN This section of the file is automatically generated. Do not edit --------------
10873 
10874 instruct regL_not_reg(iRegLNoSp dst,
10875                          iRegL src1, immL_M1 m1,
10876                          rFlagsReg cr) %{
10877   match(Set dst (XorL src1 m1));
10878   ins_cost(INSN_COST);
10879   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10880 
10881   ins_encode %{
10882     __ eon(as_Register($dst$$reg),
10883               as_Register($src1$$reg),
10884               zr,
10885               Assembler::LSL, 0);
10886   %}
10887 
10888   ins_pipe(ialu_reg);
10889 %}
10890 instruct regI_not_reg(iRegINoSp dst,
10891                          iRegIorL2I src1, immI_M1 m1,
10892                          rFlagsReg cr) %{
10893   match(Set dst (XorI src1 m1));
10894   ins_cost(INSN_COST);
10895   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10896 
10897   ins_encode %{
10898     __ eonw(as_Register($dst$$reg),
10899               as_Register($src1$$reg),
10900               zr,
10901               Assembler::LSL, 0);
10902   %}
10903 
10904   ins_pipe(ialu_reg);
10905 %}
10906 
10907 instruct AndI_reg_not_reg(iRegINoSp dst,
10908                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10909                          rFlagsReg cr) %{
10910   match(Set dst (AndI src1 (XorI src2 m1)));
10911   ins_cost(INSN_COST);
10912   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10913 
10914   ins_encode %{
10915     __ bicw(as_Register($dst$$reg),
10916               as_Register($src1$$reg),
10917               as_Register($src2$$reg),
10918               Assembler::LSL, 0);
10919   %}
10920 
10921   ins_pipe(ialu_reg_reg);
10922 %}
10923 
10924 instruct AndL_reg_not_reg(iRegLNoSp dst,
10925                          iRegL src1, iRegL src2, immL_M1 m1,
10926                          rFlagsReg cr) %{
10927   match(Set dst (AndL src1 (XorL src2 m1)));
10928   ins_cost(INSN_COST);
10929   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10930 
10931   ins_encode %{
10932     __ bic(as_Register($dst$$reg),
10933               as_Register($src1$$reg),
10934               as_Register($src2$$reg),
10935               Assembler::LSL, 0);
10936   %}
10937 
10938   ins_pipe(ialu_reg_reg);
10939 %}
10940 
10941 instruct OrI_reg_not_reg(iRegINoSp dst,
10942                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10943                          rFlagsReg cr) %{
10944   match(Set dst (OrI src1 (XorI src2 m1)));
10945   ins_cost(INSN_COST);
10946   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10947 
10948   ins_encode %{
10949     __ ornw(as_Register($dst$$reg),
10950               as_Register($src1$$reg),
10951               as_Register($src2$$reg),
10952               Assembler::LSL, 0);
10953   %}
10954 
10955   ins_pipe(ialu_reg_reg);
10956 %}
10957 
10958 instruct OrL_reg_not_reg(iRegLNoSp dst,
10959                          iRegL src1, iRegL src2, immL_M1 m1,
10960                          rFlagsReg cr) %{
10961   match(Set dst (OrL src1 (XorL src2 m1)));
10962   ins_cost(INSN_COST);
10963   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10964 
10965   ins_encode %{
10966     __ orn(as_Register($dst$$reg),
10967               as_Register($src1$$reg),
10968               as_Register($src2$$reg),
10969               Assembler::LSL, 0);
10970   %}
10971 
10972   ins_pipe(ialu_reg_reg);
10973 %}
10974 
10975 instruct XorI_reg_not_reg(iRegINoSp dst,
10976                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10977                          rFlagsReg cr) %{
10978   match(Set dst (XorI m1 (XorI src2 src1)));
10979   ins_cost(INSN_COST);
10980   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10981 
10982   ins_encode %{
10983     __ eonw(as_Register($dst$$reg),
10984               as_Register($src1$$reg),
10985               as_Register($src2$$reg),
10986               Assembler::LSL, 0);
10987   %}
10988 
10989   ins_pipe(ialu_reg_reg);
10990 %}
10991 
10992 instruct XorL_reg_not_reg(iRegLNoSp dst,
10993                          iRegL src1, iRegL src2, immL_M1 m1,
10994                          rFlagsReg cr) %{
10995   match(Set dst (XorL m1 (XorL src2 src1)));
10996   ins_cost(INSN_COST);
10997   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10998 
10999   ins_encode %{
11000     __ eon(as_Register($dst$$reg),
11001               as_Register($src1$$reg),
11002               as_Register($src2$$reg),
11003               Assembler::LSL, 0);
11004   %}
11005 
11006   ins_pipe(ialu_reg_reg);
11007 %}
11008 
11009 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11010                          iRegIorL2I src1, iRegIorL2I src2,
11011                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11012   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11013   ins_cost(1.9 * INSN_COST);
11014   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11015 
11016   ins_encode %{
11017     __ bicw(as_Register($dst$$reg),
11018               as_Register($src1$$reg),
11019               as_Register($src2$$reg),
11020               Assembler::LSR,
11021               $src3$$constant &amp; 0x1f);
11022   %}
11023 
11024   ins_pipe(ialu_reg_reg_shift);
11025 %}
11026 
11027 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11028                          iRegL src1, iRegL src2,
11029                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11030   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11031   ins_cost(1.9 * INSN_COST);
11032   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11033 
11034   ins_encode %{
11035     __ bic(as_Register($dst$$reg),
11036               as_Register($src1$$reg),
11037               as_Register($src2$$reg),
11038               Assembler::LSR,
11039               $src3$$constant &amp; 0x3f);
11040   %}
11041 
11042   ins_pipe(ialu_reg_reg_shift);
11043 %}
11044 
11045 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11046                          iRegIorL2I src1, iRegIorL2I src2,
11047                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11048   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11049   ins_cost(1.9 * INSN_COST);
11050   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11051 
11052   ins_encode %{
11053     __ bicw(as_Register($dst$$reg),
11054               as_Register($src1$$reg),
11055               as_Register($src2$$reg),
11056               Assembler::ASR,
11057               $src3$$constant &amp; 0x1f);
11058   %}
11059 
11060   ins_pipe(ialu_reg_reg_shift);
11061 %}
11062 
11063 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11064                          iRegL src1, iRegL src2,
11065                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11066   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11067   ins_cost(1.9 * INSN_COST);
11068   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11069 
11070   ins_encode %{
11071     __ bic(as_Register($dst$$reg),
11072               as_Register($src1$$reg),
11073               as_Register($src2$$reg),
11074               Assembler::ASR,
11075               $src3$$constant &amp; 0x3f);
11076   %}
11077 
11078   ins_pipe(ialu_reg_reg_shift);
11079 %}
11080 
11081 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11082                          iRegIorL2I src1, iRegIorL2I src2,
11083                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11084   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11085   ins_cost(1.9 * INSN_COST);
11086   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11087 
11088   ins_encode %{
11089     __ bicw(as_Register($dst$$reg),
11090               as_Register($src1$$reg),
11091               as_Register($src2$$reg),
11092               Assembler::LSL,
11093               $src3$$constant &amp; 0x1f);
11094   %}
11095 
11096   ins_pipe(ialu_reg_reg_shift);
11097 %}
11098 
11099 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11100                          iRegL src1, iRegL src2,
11101                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11102   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11103   ins_cost(1.9 * INSN_COST);
11104   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11105 
11106   ins_encode %{
11107     __ bic(as_Register($dst$$reg),
11108               as_Register($src1$$reg),
11109               as_Register($src2$$reg),
11110               Assembler::LSL,
11111               $src3$$constant &amp; 0x3f);
11112   %}
11113 
11114   ins_pipe(ialu_reg_reg_shift);
11115 %}
11116 
11117 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11118                          iRegIorL2I src1, iRegIorL2I src2,
11119                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11120   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11121   ins_cost(1.9 * INSN_COST);
11122   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11123 
11124   ins_encode %{
11125     __ eonw(as_Register($dst$$reg),
11126               as_Register($src1$$reg),
11127               as_Register($src2$$reg),
11128               Assembler::LSR,
11129               $src3$$constant &amp; 0x1f);
11130   %}
11131 
11132   ins_pipe(ialu_reg_reg_shift);
11133 %}
11134 
11135 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11136                          iRegL src1, iRegL src2,
11137                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11138   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11139   ins_cost(1.9 * INSN_COST);
11140   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11141 
11142   ins_encode %{
11143     __ eon(as_Register($dst$$reg),
11144               as_Register($src1$$reg),
11145               as_Register($src2$$reg),
11146               Assembler::LSR,
11147               $src3$$constant &amp; 0x3f);
11148   %}
11149 
11150   ins_pipe(ialu_reg_reg_shift);
11151 %}
11152 
11153 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11154                          iRegIorL2I src1, iRegIorL2I src2,
11155                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11156   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11157   ins_cost(1.9 * INSN_COST);
11158   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11159 
11160   ins_encode %{
11161     __ eonw(as_Register($dst$$reg),
11162               as_Register($src1$$reg),
11163               as_Register($src2$$reg),
11164               Assembler::ASR,
11165               $src3$$constant &amp; 0x1f);
11166   %}
11167 
11168   ins_pipe(ialu_reg_reg_shift);
11169 %}
11170 
11171 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11172                          iRegL src1, iRegL src2,
11173                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11174   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11175   ins_cost(1.9 * INSN_COST);
11176   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11177 
11178   ins_encode %{
11179     __ eon(as_Register($dst$$reg),
11180               as_Register($src1$$reg),
11181               as_Register($src2$$reg),
11182               Assembler::ASR,
11183               $src3$$constant &amp; 0x3f);
11184   %}
11185 
11186   ins_pipe(ialu_reg_reg_shift);
11187 %}
11188 
11189 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11190                          iRegIorL2I src1, iRegIorL2I src2,
11191                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11192   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11193   ins_cost(1.9 * INSN_COST);
11194   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11195 
11196   ins_encode %{
11197     __ eonw(as_Register($dst$$reg),
11198               as_Register($src1$$reg),
11199               as_Register($src2$$reg),
11200               Assembler::LSL,
11201               $src3$$constant &amp; 0x1f);
11202   %}
11203 
11204   ins_pipe(ialu_reg_reg_shift);
11205 %}
11206 
11207 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11208                          iRegL src1, iRegL src2,
11209                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11210   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11211   ins_cost(1.9 * INSN_COST);
11212   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11213 
11214   ins_encode %{
11215     __ eon(as_Register($dst$$reg),
11216               as_Register($src1$$reg),
11217               as_Register($src2$$reg),
11218               Assembler::LSL,
11219               $src3$$constant &amp; 0x3f);
11220   %}
11221 
11222   ins_pipe(ialu_reg_reg_shift);
11223 %}
11224 
11225 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11226                          iRegIorL2I src1, iRegIorL2I src2,
11227                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11228   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11229   ins_cost(1.9 * INSN_COST);
11230   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11231 
11232   ins_encode %{
11233     __ ornw(as_Register($dst$$reg),
11234               as_Register($src1$$reg),
11235               as_Register($src2$$reg),
11236               Assembler::LSR,
11237               $src3$$constant &amp; 0x1f);
11238   %}
11239 
11240   ins_pipe(ialu_reg_reg_shift);
11241 %}
11242 
11243 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11244                          iRegL src1, iRegL src2,
11245                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11246   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11247   ins_cost(1.9 * INSN_COST);
11248   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11249 
11250   ins_encode %{
11251     __ orn(as_Register($dst$$reg),
11252               as_Register($src1$$reg),
11253               as_Register($src2$$reg),
11254               Assembler::LSR,
11255               $src3$$constant &amp; 0x3f);
11256   %}
11257 
11258   ins_pipe(ialu_reg_reg_shift);
11259 %}
11260 
11261 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11262                          iRegIorL2I src1, iRegIorL2I src2,
11263                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11264   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11265   ins_cost(1.9 * INSN_COST);
11266   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11267 
11268   ins_encode %{
11269     __ ornw(as_Register($dst$$reg),
11270               as_Register($src1$$reg),
11271               as_Register($src2$$reg),
11272               Assembler::ASR,
11273               $src3$$constant &amp; 0x1f);
11274   %}
11275 
11276   ins_pipe(ialu_reg_reg_shift);
11277 %}
11278 
11279 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11280                          iRegL src1, iRegL src2,
11281                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11282   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11283   ins_cost(1.9 * INSN_COST);
11284   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11285 
11286   ins_encode %{
11287     __ orn(as_Register($dst$$reg),
11288               as_Register($src1$$reg),
11289               as_Register($src2$$reg),
11290               Assembler::ASR,
11291               $src3$$constant &amp; 0x3f);
11292   %}
11293 
11294   ins_pipe(ialu_reg_reg_shift);
11295 %}
11296 
11297 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11298                          iRegIorL2I src1, iRegIorL2I src2,
11299                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11300   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11301   ins_cost(1.9 * INSN_COST);
11302   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11303 
11304   ins_encode %{
11305     __ ornw(as_Register($dst$$reg),
11306               as_Register($src1$$reg),
11307               as_Register($src2$$reg),
11308               Assembler::LSL,
11309               $src3$$constant &amp; 0x1f);
11310   %}
11311 
11312   ins_pipe(ialu_reg_reg_shift);
11313 %}
11314 
11315 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11316                          iRegL src1, iRegL src2,
11317                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11318   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11319   ins_cost(1.9 * INSN_COST);
11320   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11321 
11322   ins_encode %{
11323     __ orn(as_Register($dst$$reg),
11324               as_Register($src1$$reg),
11325               as_Register($src2$$reg),
11326               Assembler::LSL,
11327               $src3$$constant &amp; 0x3f);
11328   %}
11329 
11330   ins_pipe(ialu_reg_reg_shift);
11331 %}
11332 
11333 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11334                          iRegIorL2I src1, iRegIorL2I src2,
11335                          immI src3, rFlagsReg cr) %{
11336   match(Set dst (AndI src1 (URShiftI src2 src3)));
11337 
11338   ins_cost(1.9 * INSN_COST);
11339   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11340 
11341   ins_encode %{
11342     __ andw(as_Register($dst$$reg),
11343               as_Register($src1$$reg),
11344               as_Register($src2$$reg),
11345               Assembler::LSR,
11346               $src3$$constant &amp; 0x1f);
11347   %}
11348 
11349   ins_pipe(ialu_reg_reg_shift);
11350 %}
11351 
11352 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11353                          iRegL src1, iRegL src2,
11354                          immI src3, rFlagsReg cr) %{
11355   match(Set dst (AndL src1 (URShiftL src2 src3)));
11356 
11357   ins_cost(1.9 * INSN_COST);
11358   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11359 
11360   ins_encode %{
11361     __ andr(as_Register($dst$$reg),
11362               as_Register($src1$$reg),
11363               as_Register($src2$$reg),
11364               Assembler::LSR,
11365               $src3$$constant &amp; 0x3f);
11366   %}
11367 
11368   ins_pipe(ialu_reg_reg_shift);
11369 %}
11370 
11371 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11372                          iRegIorL2I src1, iRegIorL2I src2,
11373                          immI src3, rFlagsReg cr) %{
11374   match(Set dst (AndI src1 (RShiftI src2 src3)));
11375 
11376   ins_cost(1.9 * INSN_COST);
11377   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11378 
11379   ins_encode %{
11380     __ andw(as_Register($dst$$reg),
11381               as_Register($src1$$reg),
11382               as_Register($src2$$reg),
11383               Assembler::ASR,
11384               $src3$$constant &amp; 0x1f);
11385   %}
11386 
11387   ins_pipe(ialu_reg_reg_shift);
11388 %}
11389 
11390 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11391                          iRegL src1, iRegL src2,
11392                          immI src3, rFlagsReg cr) %{
11393   match(Set dst (AndL src1 (RShiftL src2 src3)));
11394 
11395   ins_cost(1.9 * INSN_COST);
11396   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11397 
11398   ins_encode %{
11399     __ andr(as_Register($dst$$reg),
11400               as_Register($src1$$reg),
11401               as_Register($src2$$reg),
11402               Assembler::ASR,
11403               $src3$$constant &amp; 0x3f);
11404   %}
11405 
11406   ins_pipe(ialu_reg_reg_shift);
11407 %}
11408 
11409 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11410                          iRegIorL2I src1, iRegIorL2I src2,
11411                          immI src3, rFlagsReg cr) %{
11412   match(Set dst (AndI src1 (LShiftI src2 src3)));
11413 
11414   ins_cost(1.9 * INSN_COST);
11415   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11416 
11417   ins_encode %{
11418     __ andw(as_Register($dst$$reg),
11419               as_Register($src1$$reg),
11420               as_Register($src2$$reg),
11421               Assembler::LSL,
11422               $src3$$constant &amp; 0x1f);
11423   %}
11424 
11425   ins_pipe(ialu_reg_reg_shift);
11426 %}
11427 
11428 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11429                          iRegL src1, iRegL src2,
11430                          immI src3, rFlagsReg cr) %{
11431   match(Set dst (AndL src1 (LShiftL src2 src3)));
11432 
11433   ins_cost(1.9 * INSN_COST);
11434   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11435 
11436   ins_encode %{
11437     __ andr(as_Register($dst$$reg),
11438               as_Register($src1$$reg),
11439               as_Register($src2$$reg),
11440               Assembler::LSL,
11441               $src3$$constant &amp; 0x3f);
11442   %}
11443 
11444   ins_pipe(ialu_reg_reg_shift);
11445 %}
11446 
11447 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11448                          iRegIorL2I src1, iRegIorL2I src2,
11449                          immI src3, rFlagsReg cr) %{
11450   match(Set dst (XorI src1 (URShiftI src2 src3)));
11451 
11452   ins_cost(1.9 * INSN_COST);
11453   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11454 
11455   ins_encode %{
11456     __ eorw(as_Register($dst$$reg),
11457               as_Register($src1$$reg),
11458               as_Register($src2$$reg),
11459               Assembler::LSR,
11460               $src3$$constant &amp; 0x1f);
11461   %}
11462 
11463   ins_pipe(ialu_reg_reg_shift);
11464 %}
11465 
11466 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11467                          iRegL src1, iRegL src2,
11468                          immI src3, rFlagsReg cr) %{
11469   match(Set dst (XorL src1 (URShiftL src2 src3)));
11470 
11471   ins_cost(1.9 * INSN_COST);
11472   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11473 
11474   ins_encode %{
11475     __ eor(as_Register($dst$$reg),
11476               as_Register($src1$$reg),
11477               as_Register($src2$$reg),
11478               Assembler::LSR,
11479               $src3$$constant &amp; 0x3f);
11480   %}
11481 
11482   ins_pipe(ialu_reg_reg_shift);
11483 %}
11484 
11485 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11486                          iRegIorL2I src1, iRegIorL2I src2,
11487                          immI src3, rFlagsReg cr) %{
11488   match(Set dst (XorI src1 (RShiftI src2 src3)));
11489 
11490   ins_cost(1.9 * INSN_COST);
11491   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11492 
11493   ins_encode %{
11494     __ eorw(as_Register($dst$$reg),
11495               as_Register($src1$$reg),
11496               as_Register($src2$$reg),
11497               Assembler::ASR,
11498               $src3$$constant &amp; 0x1f);
11499   %}
11500 
11501   ins_pipe(ialu_reg_reg_shift);
11502 %}
11503 
11504 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11505                          iRegL src1, iRegL src2,
11506                          immI src3, rFlagsReg cr) %{
11507   match(Set dst (XorL src1 (RShiftL src2 src3)));
11508 
11509   ins_cost(1.9 * INSN_COST);
11510   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11511 
11512   ins_encode %{
11513     __ eor(as_Register($dst$$reg),
11514               as_Register($src1$$reg),
11515               as_Register($src2$$reg),
11516               Assembler::ASR,
11517               $src3$$constant &amp; 0x3f);
11518   %}
11519 
11520   ins_pipe(ialu_reg_reg_shift);
11521 %}
11522 
11523 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11524                          iRegIorL2I src1, iRegIorL2I src2,
11525                          immI src3, rFlagsReg cr) %{
11526   match(Set dst (XorI src1 (LShiftI src2 src3)));
11527 
11528   ins_cost(1.9 * INSN_COST);
11529   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11530 
11531   ins_encode %{
11532     __ eorw(as_Register($dst$$reg),
11533               as_Register($src1$$reg),
11534               as_Register($src2$$reg),
11535               Assembler::LSL,
11536               $src3$$constant &amp; 0x1f);
11537   %}
11538 
11539   ins_pipe(ialu_reg_reg_shift);
11540 %}
11541 
11542 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11543                          iRegL src1, iRegL src2,
11544                          immI src3, rFlagsReg cr) %{
11545   match(Set dst (XorL src1 (LShiftL src2 src3)));
11546 
11547   ins_cost(1.9 * INSN_COST);
11548   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11549 
11550   ins_encode %{
11551     __ eor(as_Register($dst$$reg),
11552               as_Register($src1$$reg),
11553               as_Register($src2$$reg),
11554               Assembler::LSL,
11555               $src3$$constant &amp; 0x3f);
11556   %}
11557 
11558   ins_pipe(ialu_reg_reg_shift);
11559 %}
11560 
11561 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11562                          iRegIorL2I src1, iRegIorL2I src2,
11563                          immI src3, rFlagsReg cr) %{
11564   match(Set dst (OrI src1 (URShiftI src2 src3)));
11565 
11566   ins_cost(1.9 * INSN_COST);
11567   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11568 
11569   ins_encode %{
11570     __ orrw(as_Register($dst$$reg),
11571               as_Register($src1$$reg),
11572               as_Register($src2$$reg),
11573               Assembler::LSR,
11574               $src3$$constant &amp; 0x1f);
11575   %}
11576 
11577   ins_pipe(ialu_reg_reg_shift);
11578 %}
11579 
11580 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11581                          iRegL src1, iRegL src2,
11582                          immI src3, rFlagsReg cr) %{
11583   match(Set dst (OrL src1 (URShiftL src2 src3)));
11584 
11585   ins_cost(1.9 * INSN_COST);
11586   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11587 
11588   ins_encode %{
11589     __ orr(as_Register($dst$$reg),
11590               as_Register($src1$$reg),
11591               as_Register($src2$$reg),
11592               Assembler::LSR,
11593               $src3$$constant &amp; 0x3f);
11594   %}
11595 
11596   ins_pipe(ialu_reg_reg_shift);
11597 %}
11598 
11599 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11600                          iRegIorL2I src1, iRegIorL2I src2,
11601                          immI src3, rFlagsReg cr) %{
11602   match(Set dst (OrI src1 (RShiftI src2 src3)));
11603 
11604   ins_cost(1.9 * INSN_COST);
11605   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11606 
11607   ins_encode %{
11608     __ orrw(as_Register($dst$$reg),
11609               as_Register($src1$$reg),
11610               as_Register($src2$$reg),
11611               Assembler::ASR,
11612               $src3$$constant &amp; 0x1f);
11613   %}
11614 
11615   ins_pipe(ialu_reg_reg_shift);
11616 %}
11617 
11618 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11619                          iRegL src1, iRegL src2,
11620                          immI src3, rFlagsReg cr) %{
11621   match(Set dst (OrL src1 (RShiftL src2 src3)));
11622 
11623   ins_cost(1.9 * INSN_COST);
11624   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11625 
11626   ins_encode %{
11627     __ orr(as_Register($dst$$reg),
11628               as_Register($src1$$reg),
11629               as_Register($src2$$reg),
11630               Assembler::ASR,
11631               $src3$$constant &amp; 0x3f);
11632   %}
11633 
11634   ins_pipe(ialu_reg_reg_shift);
11635 %}
11636 
11637 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11638                          iRegIorL2I src1, iRegIorL2I src2,
11639                          immI src3, rFlagsReg cr) %{
11640   match(Set dst (OrI src1 (LShiftI src2 src3)));
11641 
11642   ins_cost(1.9 * INSN_COST);
11643   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11644 
11645   ins_encode %{
11646     __ orrw(as_Register($dst$$reg),
11647               as_Register($src1$$reg),
11648               as_Register($src2$$reg),
11649               Assembler::LSL,
11650               $src3$$constant &amp; 0x1f);
11651   %}
11652 
11653   ins_pipe(ialu_reg_reg_shift);
11654 %}
11655 
11656 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11657                          iRegL src1, iRegL src2,
11658                          immI src3, rFlagsReg cr) %{
11659   match(Set dst (OrL src1 (LShiftL src2 src3)));
11660 
11661   ins_cost(1.9 * INSN_COST);
11662   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11663 
11664   ins_encode %{
11665     __ orr(as_Register($dst$$reg),
11666               as_Register($src1$$reg),
11667               as_Register($src2$$reg),
11668               Assembler::LSL,
11669               $src3$$constant &amp; 0x3f);
11670   %}
11671 
11672   ins_pipe(ialu_reg_reg_shift);
11673 %}
11674 
11675 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11676                          iRegIorL2I src1, iRegIorL2I src2,
11677                          immI src3, rFlagsReg cr) %{
11678   match(Set dst (AddI src1 (URShiftI src2 src3)));
11679 
11680   ins_cost(1.9 * INSN_COST);
11681   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11682 
11683   ins_encode %{
11684     __ addw(as_Register($dst$$reg),
11685               as_Register($src1$$reg),
11686               as_Register($src2$$reg),
11687               Assembler::LSR,
11688               $src3$$constant &amp; 0x1f);
11689   %}
11690 
11691   ins_pipe(ialu_reg_reg_shift);
11692 %}
11693 
11694 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11695                          iRegL src1, iRegL src2,
11696                          immI src3, rFlagsReg cr) %{
11697   match(Set dst (AddL src1 (URShiftL src2 src3)));
11698 
11699   ins_cost(1.9 * INSN_COST);
11700   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11701 
11702   ins_encode %{
11703     __ add(as_Register($dst$$reg),
11704               as_Register($src1$$reg),
11705               as_Register($src2$$reg),
11706               Assembler::LSR,
11707               $src3$$constant &amp; 0x3f);
11708   %}
11709 
11710   ins_pipe(ialu_reg_reg_shift);
11711 %}
11712 
11713 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11714                          iRegIorL2I src1, iRegIorL2I src2,
11715                          immI src3, rFlagsReg cr) %{
11716   match(Set dst (AddI src1 (RShiftI src2 src3)));
11717 
11718   ins_cost(1.9 * INSN_COST);
11719   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11720 
11721   ins_encode %{
11722     __ addw(as_Register($dst$$reg),
11723               as_Register($src1$$reg),
11724               as_Register($src2$$reg),
11725               Assembler::ASR,
11726               $src3$$constant &amp; 0x1f);
11727   %}
11728 
11729   ins_pipe(ialu_reg_reg_shift);
11730 %}
11731 
11732 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11733                          iRegL src1, iRegL src2,
11734                          immI src3, rFlagsReg cr) %{
11735   match(Set dst (AddL src1 (RShiftL src2 src3)));
11736 
11737   ins_cost(1.9 * INSN_COST);
11738   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11739 
11740   ins_encode %{
11741     __ add(as_Register($dst$$reg),
11742               as_Register($src1$$reg),
11743               as_Register($src2$$reg),
11744               Assembler::ASR,
11745               $src3$$constant &amp; 0x3f);
11746   %}
11747 
11748   ins_pipe(ialu_reg_reg_shift);
11749 %}
11750 
11751 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11752                          iRegIorL2I src1, iRegIorL2I src2,
11753                          immI src3, rFlagsReg cr) %{
11754   match(Set dst (AddI src1 (LShiftI src2 src3)));
11755 
11756   ins_cost(1.9 * INSN_COST);
11757   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11758 
11759   ins_encode %{
11760     __ addw(as_Register($dst$$reg),
11761               as_Register($src1$$reg),
11762               as_Register($src2$$reg),
11763               Assembler::LSL,
11764               $src3$$constant &amp; 0x1f);
11765   %}
11766 
11767   ins_pipe(ialu_reg_reg_shift);
11768 %}
11769 
11770 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11771                          iRegL src1, iRegL src2,
11772                          immI src3, rFlagsReg cr) %{
11773   match(Set dst (AddL src1 (LShiftL src2 src3)));
11774 
11775   ins_cost(1.9 * INSN_COST);
11776   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11777 
11778   ins_encode %{
11779     __ add(as_Register($dst$$reg),
11780               as_Register($src1$$reg),
11781               as_Register($src2$$reg),
11782               Assembler::LSL,
11783               $src3$$constant &amp; 0x3f);
11784   %}
11785 
11786   ins_pipe(ialu_reg_reg_shift);
11787 %}
11788 
11789 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11790                          iRegIorL2I src1, iRegIorL2I src2,
11791                          immI src3, rFlagsReg cr) %{
11792   match(Set dst (SubI src1 (URShiftI src2 src3)));
11793 
11794   ins_cost(1.9 * INSN_COST);
11795   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11796 
11797   ins_encode %{
11798     __ subw(as_Register($dst$$reg),
11799               as_Register($src1$$reg),
11800               as_Register($src2$$reg),
11801               Assembler::LSR,
11802               $src3$$constant &amp; 0x1f);
11803   %}
11804 
11805   ins_pipe(ialu_reg_reg_shift);
11806 %}
11807 
11808 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11809                          iRegL src1, iRegL src2,
11810                          immI src3, rFlagsReg cr) %{
11811   match(Set dst (SubL src1 (URShiftL src2 src3)));
11812 
11813   ins_cost(1.9 * INSN_COST);
11814   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11815 
11816   ins_encode %{
11817     __ sub(as_Register($dst$$reg),
11818               as_Register($src1$$reg),
11819               as_Register($src2$$reg),
11820               Assembler::LSR,
11821               $src3$$constant &amp; 0x3f);
11822   %}
11823 
11824   ins_pipe(ialu_reg_reg_shift);
11825 %}
11826 
11827 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11828                          iRegIorL2I src1, iRegIorL2I src2,
11829                          immI src3, rFlagsReg cr) %{
11830   match(Set dst (SubI src1 (RShiftI src2 src3)));
11831 
11832   ins_cost(1.9 * INSN_COST);
11833   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11834 
11835   ins_encode %{
11836     __ subw(as_Register($dst$$reg),
11837               as_Register($src1$$reg),
11838               as_Register($src2$$reg),
11839               Assembler::ASR,
11840               $src3$$constant &amp; 0x1f);
11841   %}
11842 
11843   ins_pipe(ialu_reg_reg_shift);
11844 %}
11845 
11846 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11847                          iRegL src1, iRegL src2,
11848                          immI src3, rFlagsReg cr) %{
11849   match(Set dst (SubL src1 (RShiftL src2 src3)));
11850 
11851   ins_cost(1.9 * INSN_COST);
11852   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11853 
11854   ins_encode %{
11855     __ sub(as_Register($dst$$reg),
11856               as_Register($src1$$reg),
11857               as_Register($src2$$reg),
11858               Assembler::ASR,
11859               $src3$$constant &amp; 0x3f);
11860   %}
11861 
11862   ins_pipe(ialu_reg_reg_shift);
11863 %}
11864 
11865 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11866                          iRegIorL2I src1, iRegIorL2I src2,
11867                          immI src3, rFlagsReg cr) %{
11868   match(Set dst (SubI src1 (LShiftI src2 src3)));
11869 
11870   ins_cost(1.9 * INSN_COST);
11871   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11872 
11873   ins_encode %{
11874     __ subw(as_Register($dst$$reg),
11875               as_Register($src1$$reg),
11876               as_Register($src2$$reg),
11877               Assembler::LSL,
11878               $src3$$constant &amp; 0x1f);
11879   %}
11880 
11881   ins_pipe(ialu_reg_reg_shift);
11882 %}
11883 
11884 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11885                          iRegL src1, iRegL src2,
11886                          immI src3, rFlagsReg cr) %{
11887   match(Set dst (SubL src1 (LShiftL src2 src3)));
11888 
11889   ins_cost(1.9 * INSN_COST);
11890   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11891 
11892   ins_encode %{
11893     __ sub(as_Register($dst$$reg),
11894               as_Register($src1$$reg),
11895               as_Register($src2$$reg),
11896               Assembler::LSL,
11897               $src3$$constant &amp; 0x3f);
11898   %}
11899 
11900   ins_pipe(ialu_reg_reg_shift);
11901 %}
11902 
11903 
11904 
11905 // Shift Left followed by Shift Right.
11906 // This idiom is used by the compiler for the i2b bytecode etc.
11907 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11908 %{
11909   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11910   ins_cost(INSN_COST * 2);
11911   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11912   ins_encode %{
11913     int lshift = $lshift_count$$constant &amp; 63;
11914     int rshift = $rshift_count$$constant &amp; 63;
11915     int s = 63 - lshift;
11916     int r = (rshift - lshift) &amp; 63;
11917     __ sbfm(as_Register($dst$$reg),
11918             as_Register($src$$reg),
11919             r, s);
11920   %}
11921 
11922   ins_pipe(ialu_reg_shift);
11923 %}
11924 
11925 // Shift Left followed by Shift Right.
11926 // This idiom is used by the compiler for the i2b bytecode etc.
11927 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11928 %{
11929   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11930   ins_cost(INSN_COST * 2);
11931   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11932   ins_encode %{
11933     int lshift = $lshift_count$$constant &amp; 31;
11934     int rshift = $rshift_count$$constant &amp; 31;
11935     int s = 31 - lshift;
11936     int r = (rshift - lshift) &amp; 31;
11937     __ sbfmw(as_Register($dst$$reg),
11938             as_Register($src$$reg),
11939             r, s);
11940   %}
11941 
11942   ins_pipe(ialu_reg_shift);
11943 %}
11944 
11945 // Shift Left followed by Shift Right.
11946 // This idiom is used by the compiler for the i2b bytecode etc.
11947 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11948 %{
11949   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11950   ins_cost(INSN_COST * 2);
11951   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11952   ins_encode %{
11953     int lshift = $lshift_count$$constant &amp; 63;
11954     int rshift = $rshift_count$$constant &amp; 63;
11955     int s = 63 - lshift;
11956     int r = (rshift - lshift) &amp; 63;
11957     __ ubfm(as_Register($dst$$reg),
11958             as_Register($src$$reg),
11959             r, s);
11960   %}
11961 
11962   ins_pipe(ialu_reg_shift);
11963 %}
11964 
11965 // Shift Left followed by Shift Right.
11966 // This idiom is used by the compiler for the i2b bytecode etc.
11967 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11968 %{
11969   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11970   ins_cost(INSN_COST * 2);
11971   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11972   ins_encode %{
11973     int lshift = $lshift_count$$constant &amp; 31;
11974     int rshift = $rshift_count$$constant &amp; 31;
11975     int s = 31 - lshift;
11976     int r = (rshift - lshift) &amp; 31;
11977     __ ubfmw(as_Register($dst$$reg),
11978             as_Register($src$$reg),
11979             r, s);
11980   %}
11981 
11982   ins_pipe(ialu_reg_shift);
11983 %}
11984 // Bitfield extract with shift &amp; mask
11985 
11986 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11987 %{
11988   match(Set dst (AndI (URShiftI src rshift) mask));
11989   // Make sure we are not going to exceed what ubfxw can do.
11990   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11991 
11992   ins_cost(INSN_COST);
11993   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
11994   ins_encode %{
11995     int rshift = $rshift$$constant &amp; 31;
11996     long mask = $mask$$constant;
11997     int width = exact_log2(mask+1);
11998     __ ubfxw(as_Register($dst$$reg),
11999             as_Register($src$$reg), rshift, width);
12000   %}
12001   ins_pipe(ialu_reg_shift);
12002 %}
12003 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12004 %{
12005   match(Set dst (AndL (URShiftL src rshift) mask));
12006   // Make sure we are not going to exceed what ubfx can do.
12007   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12008 
12009   ins_cost(INSN_COST);
12010   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12011   ins_encode %{
12012     int rshift = $rshift$$constant &amp; 63;
12013     long mask = $mask$$constant;
12014     int width = exact_log2_long(mask+1);
12015     __ ubfx(as_Register($dst$$reg),
12016             as_Register($src$$reg), rshift, width);
12017   %}
12018   ins_pipe(ialu_reg_shift);
12019 %}
12020 
12021 // We can use ubfx when extending an And with a mask when we know mask
12022 // is positive.  We know that because immI_bitmask guarantees it.
12023 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12024 %{
12025   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12026   // Make sure we are not going to exceed what ubfxw can do.
12027   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12028 
12029   ins_cost(INSN_COST * 2);
12030   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12031   ins_encode %{
12032     int rshift = $rshift$$constant &amp; 31;
12033     long mask = $mask$$constant;
12034     int width = exact_log2(mask+1);
12035     __ ubfx(as_Register($dst$$reg),
12036             as_Register($src$$reg), rshift, width);
12037   %}
12038   ins_pipe(ialu_reg_shift);
12039 %}
12040 
12041 // We can use ubfiz when masking by a positive number and then left shifting the result.
12042 // We know that the mask is positive because immI_bitmask guarantees it.
12043 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12044 %{
12045   match(Set dst (LShiftI (AndI src mask) lshift));
12046   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12047 
12048   ins_cost(INSN_COST);
12049   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12050   ins_encode %{
12051     int lshift = $lshift$$constant &amp; 31;
12052     long mask = $mask$$constant;
12053     int width = exact_log2(mask+1);
12054     __ ubfizw(as_Register($dst$$reg),
12055           as_Register($src$$reg), lshift, width);
12056   %}
12057   ins_pipe(ialu_reg_shift);
12058 %}
12059 // We can use ubfiz when masking by a positive number and then left shifting the result.
12060 // We know that the mask is positive because immL_bitmask guarantees it.
12061 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12062 %{
12063   match(Set dst (LShiftL (AndL src mask) lshift));
12064   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12065 
12066   ins_cost(INSN_COST);
12067   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12068   ins_encode %{
12069     int lshift = $lshift$$constant &amp; 63;
12070     long mask = $mask$$constant;
12071     int width = exact_log2_long(mask+1);
12072     __ ubfiz(as_Register($dst$$reg),
12073           as_Register($src$$reg), lshift, width);
12074   %}
12075   ins_pipe(ialu_reg_shift);
12076 %}
12077 
12078 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12079 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12080 %{
12081   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12082   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12083 
12084   ins_cost(INSN_COST);
12085   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12086   ins_encode %{
12087     int lshift = $lshift$$constant &amp; 63;
12088     long mask = $mask$$constant;
12089     int width = exact_log2(mask+1);
12090     __ ubfiz(as_Register($dst$$reg),
12091              as_Register($src$$reg), lshift, width);
12092   %}
12093   ins_pipe(ialu_reg_shift);
12094 %}
12095 
12096 // Rotations
12097 
12098 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12099 %{
12100   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12101   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12102 
12103   ins_cost(INSN_COST);
12104   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12105 
12106   ins_encode %{
12107     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12108             $rshift$$constant &amp; 63);
12109   %}
12110   ins_pipe(ialu_reg_reg_extr);
12111 %}
12112 
12113 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12114 %{
12115   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12116   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12117 
12118   ins_cost(INSN_COST);
12119   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12120 
12121   ins_encode %{
12122     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12123             $rshift$$constant &amp; 31);
12124   %}
12125   ins_pipe(ialu_reg_reg_extr);
12126 %}
12127 
12128 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12129 %{
12130   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12131   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12132 
12133   ins_cost(INSN_COST);
12134   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12135 
12136   ins_encode %{
12137     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12138             $rshift$$constant &amp; 63);
12139   %}
12140   ins_pipe(ialu_reg_reg_extr);
12141 %}
12142 
12143 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12144 %{
12145   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12146   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12147 
12148   ins_cost(INSN_COST);
12149   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12150 
12151   ins_encode %{
12152     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12153             $rshift$$constant &amp; 31);
12154   %}
12155   ins_pipe(ialu_reg_reg_extr);
12156 %}
12157 
12158 
12159 // rol expander
12160 
12161 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12162 %{
12163   effect(DEF dst, USE src, USE shift);
12164 
12165   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12166   ins_cost(INSN_COST * 3);
12167   ins_encode %{
12168     __ subw(rscratch1, zr, as_Register($shift$$reg));
12169     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12170             rscratch1);
12171     %}
12172   ins_pipe(ialu_reg_reg_vshift);
12173 %}
12174 
12175 // rol expander
12176 
12177 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12178 %{
12179   effect(DEF dst, USE src, USE shift);
12180 
12181   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12182   ins_cost(INSN_COST * 3);
12183   ins_encode %{
12184     __ subw(rscratch1, zr, as_Register($shift$$reg));
12185     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12186             rscratch1);
12187     %}
12188   ins_pipe(ialu_reg_reg_vshift);
12189 %}
12190 
12191 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12192 %{
12193   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12194 
12195   expand %{
12196     rolL_rReg(dst, src, shift, cr);
12197   %}
12198 %}
12199 
12200 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12201 %{
12202   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12203 
12204   expand %{
12205     rolL_rReg(dst, src, shift, cr);
12206   %}
12207 %}
12208 
12209 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12210 %{
12211   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12212 
12213   expand %{
12214     rolI_rReg(dst, src, shift, cr);
12215   %}
12216 %}
12217 
12218 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12219 %{
12220   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12221 
12222   expand %{
12223     rolI_rReg(dst, src, shift, cr);
12224   %}
12225 %}
12226 
12227 // ror expander
12228 
12229 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12230 %{
12231   effect(DEF dst, USE src, USE shift);
12232 
12233   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12234   ins_cost(INSN_COST);
12235   ins_encode %{
12236     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12237             as_Register($shift$$reg));
12238     %}
12239   ins_pipe(ialu_reg_reg_vshift);
12240 %}
12241 
12242 // ror expander
12243 
12244 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12245 %{
12246   effect(DEF dst, USE src, USE shift);
12247 
12248   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12249   ins_cost(INSN_COST);
12250   ins_encode %{
12251     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12252             as_Register($shift$$reg));
12253     %}
12254   ins_pipe(ialu_reg_reg_vshift);
12255 %}
12256 
12257 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12258 %{
12259   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12260 
12261   expand %{
12262     rorL_rReg(dst, src, shift, cr);
12263   %}
12264 %}
12265 
12266 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12267 %{
12268   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12269 
12270   expand %{
12271     rorL_rReg(dst, src, shift, cr);
12272   %}
12273 %}
12274 
12275 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12276 %{
12277   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12278 
12279   expand %{
12280     rorI_rReg(dst, src, shift, cr);
12281   %}
12282 %}
12283 
12284 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12285 %{
12286   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12287 
12288   expand %{
12289     rorI_rReg(dst, src, shift, cr);
12290   %}
12291 %}
12292 
12293 // Add/subtract (extended)
12294 
12295 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12296 %{
12297   match(Set dst (AddL src1 (ConvI2L src2)));
12298   ins_cost(INSN_COST);
12299   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12300 
12301    ins_encode %{
12302      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12303             as_Register($src2$$reg), ext::sxtw);
12304    %}
12305   ins_pipe(ialu_reg_reg);
12306 %};
12307 
12308 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12309 %{
12310   match(Set dst (SubL src1 (ConvI2L src2)));
12311   ins_cost(INSN_COST);
12312   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12313 
12314    ins_encode %{
12315      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12316             as_Register($src2$$reg), ext::sxtw);
12317    %}
12318   ins_pipe(ialu_reg_reg);
12319 %};
12320 
12321 
12322 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12323 %{
12324   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12325   ins_cost(INSN_COST);
12326   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12327 
12328    ins_encode %{
12329      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12330             as_Register($src2$$reg), ext::sxth);
12331    %}
12332   ins_pipe(ialu_reg_reg);
12333 %}
12334 
12335 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12336 %{
12337   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12338   ins_cost(INSN_COST);
12339   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12340 
12341    ins_encode %{
12342      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12343             as_Register($src2$$reg), ext::sxtb);
12344    %}
12345   ins_pipe(ialu_reg_reg);
12346 %}
12347 
12348 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12349 %{
12350   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12351   ins_cost(INSN_COST);
12352   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12353 
12354    ins_encode %{
12355      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12356             as_Register($src2$$reg), ext::uxtb);
12357    %}
12358   ins_pipe(ialu_reg_reg);
12359 %}
12360 
12361 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12362 %{
12363   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12364   ins_cost(INSN_COST);
12365   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12366 
12367    ins_encode %{
12368      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12369             as_Register($src2$$reg), ext::sxth);
12370    %}
12371   ins_pipe(ialu_reg_reg);
12372 %}
12373 
12374 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12375 %{
12376   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12377   ins_cost(INSN_COST);
12378   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12379 
12380    ins_encode %{
12381      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12382             as_Register($src2$$reg), ext::sxtw);
12383    %}
12384   ins_pipe(ialu_reg_reg);
12385 %}
12386 
12387 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12388 %{
12389   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12390   ins_cost(INSN_COST);
12391   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12392 
12393    ins_encode %{
12394      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12395             as_Register($src2$$reg), ext::sxtb);
12396    %}
12397   ins_pipe(ialu_reg_reg);
12398 %}
12399 
12400 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12401 %{
12402   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12403   ins_cost(INSN_COST);
12404   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12405 
12406    ins_encode %{
12407      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12408             as_Register($src2$$reg), ext::uxtb);
12409    %}
12410   ins_pipe(ialu_reg_reg);
12411 %}
12412 
12413 
12414 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12415 %{
12416   match(Set dst (AddI src1 (AndI src2 mask)));
12417   ins_cost(INSN_COST);
12418   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12419 
12420    ins_encode %{
12421      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12422             as_Register($src2$$reg), ext::uxtb);
12423    %}
12424   ins_pipe(ialu_reg_reg);
12425 %}
12426 
12427 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12428 %{
12429   match(Set dst (AddI src1 (AndI src2 mask)));
12430   ins_cost(INSN_COST);
12431   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12432 
12433    ins_encode %{
12434      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12435             as_Register($src2$$reg), ext::uxth);
12436    %}
12437   ins_pipe(ialu_reg_reg);
12438 %}
12439 
12440 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12441 %{
12442   match(Set dst (AddL src1 (AndL src2 mask)));
12443   ins_cost(INSN_COST);
12444   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12445 
12446    ins_encode %{
12447      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12448             as_Register($src2$$reg), ext::uxtb);
12449    %}
12450   ins_pipe(ialu_reg_reg);
12451 %}
12452 
12453 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12454 %{
12455   match(Set dst (AddL src1 (AndL src2 mask)));
12456   ins_cost(INSN_COST);
12457   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12458 
12459    ins_encode %{
12460      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12461             as_Register($src2$$reg), ext::uxth);
12462    %}
12463   ins_pipe(ialu_reg_reg);
12464 %}
12465 
12466 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12467 %{
12468   match(Set dst (AddL src1 (AndL src2 mask)));
12469   ins_cost(INSN_COST);
12470   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12471 
12472    ins_encode %{
12473      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12474             as_Register($src2$$reg), ext::uxtw);
12475    %}
12476   ins_pipe(ialu_reg_reg);
12477 %}
12478 
12479 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12480 %{
12481   match(Set dst (SubI src1 (AndI src2 mask)));
12482   ins_cost(INSN_COST);
12483   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12484 
12485    ins_encode %{
12486      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12487             as_Register($src2$$reg), ext::uxtb);
12488    %}
12489   ins_pipe(ialu_reg_reg);
12490 %}
12491 
12492 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12493 %{
12494   match(Set dst (SubI src1 (AndI src2 mask)));
12495   ins_cost(INSN_COST);
12496   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12497 
12498    ins_encode %{
12499      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12500             as_Register($src2$$reg), ext::uxth);
12501    %}
12502   ins_pipe(ialu_reg_reg);
12503 %}
12504 
12505 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12506 %{
12507   match(Set dst (SubL src1 (AndL src2 mask)));
12508   ins_cost(INSN_COST);
12509   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12510 
12511    ins_encode %{
12512      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12513             as_Register($src2$$reg), ext::uxtb);
12514    %}
12515   ins_pipe(ialu_reg_reg);
12516 %}
12517 
12518 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12519 %{
12520   match(Set dst (SubL src1 (AndL src2 mask)));
12521   ins_cost(INSN_COST);
12522   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12523 
12524    ins_encode %{
12525      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12526             as_Register($src2$$reg), ext::uxth);
12527    %}
12528   ins_pipe(ialu_reg_reg);
12529 %}
12530 
12531 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12532 %{
12533   match(Set dst (SubL src1 (AndL src2 mask)));
12534   ins_cost(INSN_COST);
12535   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12536 
12537    ins_encode %{
12538      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12539             as_Register($src2$$reg), ext::uxtw);
12540    %}
12541   ins_pipe(ialu_reg_reg);
12542 %}
12543 
12544 
12545 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12546 %{
12547   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12548   ins_cost(1.9 * INSN_COST);
12549   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12550 
12551    ins_encode %{
12552      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12553             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12554    %}
12555   ins_pipe(ialu_reg_reg_shift);
12556 %}
12557 
12558 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12559 %{
12560   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12561   ins_cost(1.9 * INSN_COST);
12562   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12563 
12564    ins_encode %{
12565      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12566             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12567    %}
12568   ins_pipe(ialu_reg_reg_shift);
12569 %}
12570 
12571 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12572 %{
12573   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12574   ins_cost(1.9 * INSN_COST);
12575   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12576 
12577    ins_encode %{
12578      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12579             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12580    %}
12581   ins_pipe(ialu_reg_reg_shift);
12582 %}
12583 
12584 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12585 %{
12586   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12587   ins_cost(1.9 * INSN_COST);
12588   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12589 
12590    ins_encode %{
12591      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12592             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12593    %}
12594   ins_pipe(ialu_reg_reg_shift);
12595 %}
12596 
12597 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12598 %{
12599   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12600   ins_cost(1.9 * INSN_COST);
12601   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12602 
12603    ins_encode %{
12604      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12605             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12606    %}
12607   ins_pipe(ialu_reg_reg_shift);
12608 %}
12609 
12610 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12611 %{
12612   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12613   ins_cost(1.9 * INSN_COST);
12614   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12615 
12616    ins_encode %{
12617      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12618             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12619    %}
12620   ins_pipe(ialu_reg_reg_shift);
12621 %}
12622 
12623 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12624 %{
12625   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12626   ins_cost(1.9 * INSN_COST);
12627   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12628 
12629    ins_encode %{
12630      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12631             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12632    %}
12633   ins_pipe(ialu_reg_reg_shift);
12634 %}
12635 
12636 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12637 %{
12638   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12639   ins_cost(1.9 * INSN_COST);
12640   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12641 
12642    ins_encode %{
12643      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12644             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12645    %}
12646   ins_pipe(ialu_reg_reg_shift);
12647 %}
12648 
12649 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12650 %{
12651   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12652   ins_cost(1.9 * INSN_COST);
12653   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12654 
12655    ins_encode %{
12656      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12657             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12658    %}
12659   ins_pipe(ialu_reg_reg_shift);
12660 %}
12661 
12662 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12663 %{
12664   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12665   ins_cost(1.9 * INSN_COST);
12666   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12667 
12668    ins_encode %{
12669      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12670             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12671    %}
12672   ins_pipe(ialu_reg_reg_shift);
12673 %}
12674 
12675 
12676 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12677 %{
12678   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12679   ins_cost(1.9 * INSN_COST);
12680   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12681 
12682    ins_encode %{
12683      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12684             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12685    %}
12686   ins_pipe(ialu_reg_reg_shift);
12687 %};
12688 
12689 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12690 %{
12691   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12692   ins_cost(1.9 * INSN_COST);
12693   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12694 
12695    ins_encode %{
12696      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12697             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12698    %}
12699   ins_pipe(ialu_reg_reg_shift);
12700 %};
12701 
12702 
12703 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12704 %{
12705   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12706   ins_cost(1.9 * INSN_COST);
12707   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12708 
12709    ins_encode %{
12710      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12711             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12712    %}
12713   ins_pipe(ialu_reg_reg_shift);
12714 %}
12715 
12716 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12717 %{
12718   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12719   ins_cost(1.9 * INSN_COST);
12720   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12721 
12722    ins_encode %{
12723      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12724             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12725    %}
12726   ins_pipe(ialu_reg_reg_shift);
12727 %}
12728 
12729 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12730 %{
12731   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12732   ins_cost(1.9 * INSN_COST);
12733   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12734 
12735    ins_encode %{
12736      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12737             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12738    %}
12739   ins_pipe(ialu_reg_reg_shift);
12740 %}
12741 
12742 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12743 %{
12744   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12745   ins_cost(1.9 * INSN_COST);
12746   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12747 
12748    ins_encode %{
12749      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12750             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12751    %}
12752   ins_pipe(ialu_reg_reg_shift);
12753 %}
12754 
12755 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12756 %{
12757   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12758   ins_cost(1.9 * INSN_COST);
12759   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12760 
12761    ins_encode %{
12762      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12763             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12764    %}
12765   ins_pipe(ialu_reg_reg_shift);
12766 %}
12767 
12768 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12769 %{
12770   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12771   ins_cost(1.9 * INSN_COST);
12772   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12773 
12774    ins_encode %{
12775      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12776             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12777    %}
12778   ins_pipe(ialu_reg_reg_shift);
12779 %}
12780 
12781 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12782 %{
12783   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12784   ins_cost(1.9 * INSN_COST);
12785   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12786 
12787    ins_encode %{
12788      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12789             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12790    %}
12791   ins_pipe(ialu_reg_reg_shift);
12792 %}
12793 
12794 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12795 %{
12796   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12797   ins_cost(1.9 * INSN_COST);
12798   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12799 
12800    ins_encode %{
12801      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12802             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12803    %}
12804   ins_pipe(ialu_reg_reg_shift);
12805 %}
12806 
12807 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12808 %{
12809   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12810   ins_cost(1.9 * INSN_COST);
12811   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12812 
12813    ins_encode %{
12814      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12815             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12816    %}
12817   ins_pipe(ialu_reg_reg_shift);
12818 %}
12819 
12820 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12821 %{
12822   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12823   ins_cost(1.9 * INSN_COST);
12824   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12825 
12826    ins_encode %{
12827      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12828             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12829    %}
12830   ins_pipe(ialu_reg_reg_shift);
12831 %}
12832 // END This section of the file is automatically generated. Do not edit --------------
12833 
12834 // ============================================================================
12835 // Floating Point Arithmetic Instructions
12836 
12837 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12838   match(Set dst (AddF src1 src2));
12839 
12840   ins_cost(INSN_COST * 5);
12841   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12842 
12843   ins_encode %{
12844     __ fadds(as_FloatRegister($dst$$reg),
12845              as_FloatRegister($src1$$reg),
12846              as_FloatRegister($src2$$reg));
12847   %}
12848 
12849   ins_pipe(fp_dop_reg_reg_s);
12850 %}
12851 
12852 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12853   match(Set dst (AddD src1 src2));
12854 
12855   ins_cost(INSN_COST * 5);
12856   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12857 
12858   ins_encode %{
12859     __ faddd(as_FloatRegister($dst$$reg),
12860              as_FloatRegister($src1$$reg),
12861              as_FloatRegister($src2$$reg));
12862   %}
12863 
12864   ins_pipe(fp_dop_reg_reg_d);
12865 %}
12866 
12867 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12868   match(Set dst (SubF src1 src2));
12869 
12870   ins_cost(INSN_COST * 5);
12871   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12872 
12873   ins_encode %{
12874     __ fsubs(as_FloatRegister($dst$$reg),
12875              as_FloatRegister($src1$$reg),
12876              as_FloatRegister($src2$$reg));
12877   %}
12878 
12879   ins_pipe(fp_dop_reg_reg_s);
12880 %}
12881 
12882 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12883   match(Set dst (SubD src1 src2));
12884 
12885   ins_cost(INSN_COST * 5);
12886   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12887 
12888   ins_encode %{
12889     __ fsubd(as_FloatRegister($dst$$reg),
12890              as_FloatRegister($src1$$reg),
12891              as_FloatRegister($src2$$reg));
12892   %}
12893 
12894   ins_pipe(fp_dop_reg_reg_d);
12895 %}
12896 
12897 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12898   match(Set dst (MulF src1 src2));
12899 
12900   ins_cost(INSN_COST * 6);
12901   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12902 
12903   ins_encode %{
12904     __ fmuls(as_FloatRegister($dst$$reg),
12905              as_FloatRegister($src1$$reg),
12906              as_FloatRegister($src2$$reg));
12907   %}
12908 
12909   ins_pipe(fp_dop_reg_reg_s);
12910 %}
12911 
12912 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12913   match(Set dst (MulD src1 src2));
12914 
12915   ins_cost(INSN_COST * 6);
12916   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12917 
12918   ins_encode %{
12919     __ fmuld(as_FloatRegister($dst$$reg),
12920              as_FloatRegister($src1$$reg),
12921              as_FloatRegister($src2$$reg));
12922   %}
12923 
12924   ins_pipe(fp_dop_reg_reg_d);
12925 %}
12926 
12927 // src1 * src2 + src3
12928 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12929   predicate(UseFMA);
12930   match(Set dst (FmaF src3 (Binary src1 src2)));
12931 
12932   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12933 
12934   ins_encode %{
12935     __ fmadds(as_FloatRegister($dst$$reg),
12936              as_FloatRegister($src1$$reg),
12937              as_FloatRegister($src2$$reg),
12938              as_FloatRegister($src3$$reg));
12939   %}
12940 
12941   ins_pipe(pipe_class_default);
12942 %}
12943 
12944 // src1 * src2 + src3
12945 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12946   predicate(UseFMA);
12947   match(Set dst (FmaD src3 (Binary src1 src2)));
12948 
12949   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12950 
12951   ins_encode %{
12952     __ fmaddd(as_FloatRegister($dst$$reg),
12953              as_FloatRegister($src1$$reg),
12954              as_FloatRegister($src2$$reg),
12955              as_FloatRegister($src3$$reg));
12956   %}
12957 
12958   ins_pipe(pipe_class_default);
12959 %}
12960 
12961 // -src1 * src2 + src3
12962 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12963   predicate(UseFMA);
12964   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12965   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12966 
12967   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12968 
12969   ins_encode %{
12970     __ fmsubs(as_FloatRegister($dst$$reg),
12971               as_FloatRegister($src1$$reg),
12972               as_FloatRegister($src2$$reg),
12973               as_FloatRegister($src3$$reg));
12974   %}
12975 
12976   ins_pipe(pipe_class_default);
12977 %}
12978 
12979 // -src1 * src2 + src3
12980 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12981   predicate(UseFMA);
12982   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12983   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12984 
12985   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
12986 
12987   ins_encode %{
12988     __ fmsubd(as_FloatRegister($dst$$reg),
12989               as_FloatRegister($src1$$reg),
12990               as_FloatRegister($src2$$reg),
12991               as_FloatRegister($src3$$reg));
12992   %}
12993 
12994   ins_pipe(pipe_class_default);
12995 %}
12996 
12997 // -src1 * src2 - src3
12998 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12999   predicate(UseFMA);
13000   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13001   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13002 
13003   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13004 
13005   ins_encode %{
13006     __ fnmadds(as_FloatRegister($dst$$reg),
13007                as_FloatRegister($src1$$reg),
13008                as_FloatRegister($src2$$reg),
13009                as_FloatRegister($src3$$reg));
13010   %}
13011 
13012   ins_pipe(pipe_class_default);
13013 %}
13014 
13015 // -src1 * src2 - src3
13016 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13017   predicate(UseFMA);
13018   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13019   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13020 
13021   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13022 
13023   ins_encode %{
13024     __ fnmaddd(as_FloatRegister($dst$$reg),
13025                as_FloatRegister($src1$$reg),
13026                as_FloatRegister($src2$$reg),
13027                as_FloatRegister($src3$$reg));
13028   %}
13029 
13030   ins_pipe(pipe_class_default);
13031 %}
13032 
13033 // src1 * src2 - src3
13034 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13035   predicate(UseFMA);
13036   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13037 
13038   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13039 
13040   ins_encode %{
13041     __ fnmsubs(as_FloatRegister($dst$$reg),
13042                as_FloatRegister($src1$$reg),
13043                as_FloatRegister($src2$$reg),
13044                as_FloatRegister($src3$$reg));
13045   %}
13046 
13047   ins_pipe(pipe_class_default);
13048 %}
13049 
13050 // src1 * src2 - src3
13051 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13052   predicate(UseFMA);
13053   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13054 
13055   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13056 
13057   ins_encode %{
13058   // n.b. insn name should be fnmsubd
13059     __ fnmsub(as_FloatRegister($dst$$reg),
13060               as_FloatRegister($src1$$reg),
13061               as_FloatRegister($src2$$reg),
13062               as_FloatRegister($src3$$reg));
13063   %}
13064 
13065   ins_pipe(pipe_class_default);
13066 %}
13067 
13068 
13069 // Math.max(FF)F
13070 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13071   match(Set dst (MaxF src1 src2));
13072 
13073   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13074   ins_encode %{
13075     __ fmaxs(as_FloatRegister($dst$$reg),
13076              as_FloatRegister($src1$$reg),
13077              as_FloatRegister($src2$$reg));
13078   %}
13079 
13080   ins_pipe(fp_dop_reg_reg_s);
13081 %}
13082 
13083 // Math.min(FF)F
13084 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13085   match(Set dst (MinF src1 src2));
13086 
13087   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13088   ins_encode %{
13089     __ fmins(as_FloatRegister($dst$$reg),
13090              as_FloatRegister($src1$$reg),
13091              as_FloatRegister($src2$$reg));
13092   %}
13093 
13094   ins_pipe(fp_dop_reg_reg_s);
13095 %}
13096 
13097 // Math.max(DD)D
13098 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13099   match(Set dst (MaxD src1 src2));
13100 
13101   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13102   ins_encode %{
13103     __ fmaxd(as_FloatRegister($dst$$reg),
13104              as_FloatRegister($src1$$reg),
13105              as_FloatRegister($src2$$reg));
13106   %}
13107 
13108   ins_pipe(fp_dop_reg_reg_d);
13109 %}
13110 
13111 // Math.min(DD)D
13112 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13113   match(Set dst (MinD src1 src2));
13114 
13115   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13116   ins_encode %{
13117     __ fmind(as_FloatRegister($dst$$reg),
13118              as_FloatRegister($src1$$reg),
13119              as_FloatRegister($src2$$reg));
13120   %}
13121 
13122   ins_pipe(fp_dop_reg_reg_d);
13123 %}
13124 
13125 
13126 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13127   match(Set dst (DivF src1  src2));
13128 
13129   ins_cost(INSN_COST * 18);
13130   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13131 
13132   ins_encode %{
13133     __ fdivs(as_FloatRegister($dst$$reg),
13134              as_FloatRegister($src1$$reg),
13135              as_FloatRegister($src2$$reg));
13136   %}
13137 
13138   ins_pipe(fp_div_s);
13139 %}
13140 
13141 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13142   match(Set dst (DivD src1  src2));
13143 
13144   ins_cost(INSN_COST * 32);
13145   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13146 
13147   ins_encode %{
13148     __ fdivd(as_FloatRegister($dst$$reg),
13149              as_FloatRegister($src1$$reg),
13150              as_FloatRegister($src2$$reg));
13151   %}
13152 
13153   ins_pipe(fp_div_d);
13154 %}
13155 
13156 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13157   match(Set dst (NegF src));
13158 
13159   ins_cost(INSN_COST * 3);
13160   format %{ &quot;fneg   $dst, $src&quot; %}
13161 
13162   ins_encode %{
13163     __ fnegs(as_FloatRegister($dst$$reg),
13164              as_FloatRegister($src$$reg));
13165   %}
13166 
13167   ins_pipe(fp_uop_s);
13168 %}
13169 
13170 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13171   match(Set dst (NegD src));
13172 
13173   ins_cost(INSN_COST * 3);
13174   format %{ &quot;fnegd   $dst, $src&quot; %}
13175 
13176   ins_encode %{
13177     __ fnegd(as_FloatRegister($dst$$reg),
13178              as_FloatRegister($src$$reg));
13179   %}
13180 
13181   ins_pipe(fp_uop_d);
13182 %}
13183 
13184 instruct absF_reg(vRegF dst, vRegF src) %{
13185   match(Set dst (AbsF src));
13186 
13187   ins_cost(INSN_COST * 3);
13188   format %{ &quot;fabss   $dst, $src&quot; %}
13189   ins_encode %{
13190     __ fabss(as_FloatRegister($dst$$reg),
13191              as_FloatRegister($src$$reg));
13192   %}
13193 
13194   ins_pipe(fp_uop_s);
13195 %}
13196 
13197 instruct absD_reg(vRegD dst, vRegD src) %{
13198   match(Set dst (AbsD src));
13199 
13200   ins_cost(INSN_COST * 3);
13201   format %{ &quot;fabsd   $dst, $src&quot; %}
13202   ins_encode %{
13203     __ fabsd(as_FloatRegister($dst$$reg),
13204              as_FloatRegister($src$$reg));
13205   %}
13206 
13207   ins_pipe(fp_uop_d);
13208 %}
13209 
13210 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13211   match(Set dst (SqrtD src));
13212 
13213   ins_cost(INSN_COST * 50);
13214   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13215   ins_encode %{
13216     __ fsqrtd(as_FloatRegister($dst$$reg),
13217              as_FloatRegister($src$$reg));
13218   %}
13219 
13220   ins_pipe(fp_div_s);
13221 %}
13222 
13223 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13224   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13225 
13226   ins_cost(INSN_COST * 50);
13227   format %{ &quot;fsqrts  $dst, $src&quot; %}
13228   ins_encode %{
13229     __ fsqrts(as_FloatRegister($dst$$reg),
13230              as_FloatRegister($src$$reg));
13231   %}
13232 
13233   ins_pipe(fp_div_d);
13234 %}
13235 
13236 // Math.rint, floor, ceil
13237 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13238   match(Set dst (RoundDoubleMode src rmode));
13239   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13240   ins_encode %{
13241     switch ($rmode$$constant) {
13242       case RoundDoubleModeNode::rmode_rint:
13243         __ frintnd(as_FloatRegister($dst$$reg),
13244                    as_FloatRegister($src$$reg));
13245         break;
13246       case RoundDoubleModeNode::rmode_floor:
13247         __ frintmd(as_FloatRegister($dst$$reg),
13248                    as_FloatRegister($src$$reg));
13249         break;
13250       case RoundDoubleModeNode::rmode_ceil:
13251         __ frintpd(as_FloatRegister($dst$$reg),
13252                    as_FloatRegister($src$$reg));
13253         break;
13254     }
13255   %}
13256   ins_pipe(fp_uop_d);
13257 %}
13258 
13259 // ============================================================================
13260 // Logical Instructions
13261 
13262 // Integer Logical Instructions
13263 
13264 // And Instructions
13265 
13266 
13267 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13268   match(Set dst (AndI src1 src2));
13269 
13270   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13271 
13272   ins_cost(INSN_COST);
13273   ins_encode %{
13274     __ andw(as_Register($dst$$reg),
13275             as_Register($src1$$reg),
13276             as_Register($src2$$reg));
13277   %}
13278 
13279   ins_pipe(ialu_reg_reg);
13280 %}
13281 
13282 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13283   match(Set dst (AndI src1 src2));
13284 
13285   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13286 
13287   ins_cost(INSN_COST);
13288   ins_encode %{
13289     __ andw(as_Register($dst$$reg),
13290             as_Register($src1$$reg),
13291             (unsigned long)($src2$$constant));
13292   %}
13293 
13294   ins_pipe(ialu_reg_imm);
13295 %}
13296 
13297 // Or Instructions
13298 
13299 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13300   match(Set dst (OrI src1 src2));
13301 
13302   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13303 
13304   ins_cost(INSN_COST);
13305   ins_encode %{
13306     __ orrw(as_Register($dst$$reg),
13307             as_Register($src1$$reg),
13308             as_Register($src2$$reg));
13309   %}
13310 
13311   ins_pipe(ialu_reg_reg);
13312 %}
13313 
13314 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13315   match(Set dst (OrI src1 src2));
13316 
13317   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13318 
13319   ins_cost(INSN_COST);
13320   ins_encode %{
13321     __ orrw(as_Register($dst$$reg),
13322             as_Register($src1$$reg),
13323             (unsigned long)($src2$$constant));
13324   %}
13325 
13326   ins_pipe(ialu_reg_imm);
13327 %}
13328 
13329 // Xor Instructions
13330 
13331 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13332   match(Set dst (XorI src1 src2));
13333 
13334   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13335 
13336   ins_cost(INSN_COST);
13337   ins_encode %{
13338     __ eorw(as_Register($dst$$reg),
13339             as_Register($src1$$reg),
13340             as_Register($src2$$reg));
13341   %}
13342 
13343   ins_pipe(ialu_reg_reg);
13344 %}
13345 
13346 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13347   match(Set dst (XorI src1 src2));
13348 
13349   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13350 
13351   ins_cost(INSN_COST);
13352   ins_encode %{
13353     __ eorw(as_Register($dst$$reg),
13354             as_Register($src1$$reg),
13355             (unsigned long)($src2$$constant));
13356   %}
13357 
13358   ins_pipe(ialu_reg_imm);
13359 %}
13360 
13361 // Long Logical Instructions
13362 // TODO
13363 
13364 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13365   match(Set dst (AndL src1 src2));
13366 
13367   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13368 
13369   ins_cost(INSN_COST);
13370   ins_encode %{
13371     __ andr(as_Register($dst$$reg),
13372             as_Register($src1$$reg),
13373             as_Register($src2$$reg));
13374   %}
13375 
13376   ins_pipe(ialu_reg_reg);
13377 %}
13378 
13379 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13380   match(Set dst (AndL src1 src2));
13381 
13382   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13383 
13384   ins_cost(INSN_COST);
13385   ins_encode %{
13386     __ andr(as_Register($dst$$reg),
13387             as_Register($src1$$reg),
13388             (unsigned long)($src2$$constant));
13389   %}
13390 
13391   ins_pipe(ialu_reg_imm);
13392 %}
13393 
13394 // Or Instructions
13395 
13396 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13397   match(Set dst (OrL src1 src2));
13398 
13399   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13400 
13401   ins_cost(INSN_COST);
13402   ins_encode %{
13403     __ orr(as_Register($dst$$reg),
13404            as_Register($src1$$reg),
13405            as_Register($src2$$reg));
13406   %}
13407 
13408   ins_pipe(ialu_reg_reg);
13409 %}
13410 
13411 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13412   match(Set dst (OrL src1 src2));
13413 
13414   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13415 
13416   ins_cost(INSN_COST);
13417   ins_encode %{
13418     __ orr(as_Register($dst$$reg),
13419            as_Register($src1$$reg),
13420            (unsigned long)($src2$$constant));
13421   %}
13422 
13423   ins_pipe(ialu_reg_imm);
13424 %}
13425 
13426 // Xor Instructions
13427 
13428 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13429   match(Set dst (XorL src1 src2));
13430 
13431   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13432 
13433   ins_cost(INSN_COST);
13434   ins_encode %{
13435     __ eor(as_Register($dst$$reg),
13436            as_Register($src1$$reg),
13437            as_Register($src2$$reg));
13438   %}
13439 
13440   ins_pipe(ialu_reg_reg);
13441 %}
13442 
13443 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13444   match(Set dst (XorL src1 src2));
13445 
13446   ins_cost(INSN_COST);
13447   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13448 
13449   ins_encode %{
13450     __ eor(as_Register($dst$$reg),
13451            as_Register($src1$$reg),
13452            (unsigned long)($src2$$constant));
13453   %}
13454 
13455   ins_pipe(ialu_reg_imm);
13456 %}
13457 
13458 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13459 %{
13460   match(Set dst (ConvI2L src));
13461 
13462   ins_cost(INSN_COST);
13463   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13464   ins_encode %{
13465     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13466   %}
13467   ins_pipe(ialu_reg_shift);
13468 %}
13469 
13470 // this pattern occurs in bigmath arithmetic
13471 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13472 %{
13473   match(Set dst (AndL (ConvI2L src) mask));
13474 
13475   ins_cost(INSN_COST);
13476   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13477   ins_encode %{
13478     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13479   %}
13480 
13481   ins_pipe(ialu_reg_shift);
13482 %}
13483 
13484 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13485   match(Set dst (ConvL2I src));
13486 
13487   ins_cost(INSN_COST);
13488   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13489 
13490   ins_encode %{
13491     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13492   %}
13493 
13494   ins_pipe(ialu_reg);
13495 %}
13496 
13497 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13498 %{
13499   match(Set dst (Conv2B src));
13500   effect(KILL cr);
13501 
13502   format %{
13503     &quot;cmpw $src, zr\n\t&quot;
13504     &quot;cset $dst, ne&quot;
13505   %}
13506 
13507   ins_encode %{
13508     __ cmpw(as_Register($src$$reg), zr);
13509     __ cset(as_Register($dst$$reg), Assembler::NE);
13510   %}
13511 
13512   ins_pipe(ialu_reg);
13513 %}
13514 
13515 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13516 %{
13517   match(Set dst (Conv2B src));
13518   effect(KILL cr);
13519 
13520   format %{
13521     &quot;cmp  $src, zr\n\t&quot;
13522     &quot;cset $dst, ne&quot;
13523   %}
13524 
13525   ins_encode %{
13526     __ cmp(as_Register($src$$reg), zr);
13527     __ cset(as_Register($dst$$reg), Assembler::NE);
13528   %}
13529 
13530   ins_pipe(ialu_reg);
13531 %}
13532 
13533 instruct convD2F_reg(vRegF dst, vRegD src) %{
13534   match(Set dst (ConvD2F src));
13535 
13536   ins_cost(INSN_COST * 5);
13537   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13538 
13539   ins_encode %{
13540     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13541   %}
13542 
13543   ins_pipe(fp_d2f);
13544 %}
13545 
13546 instruct convF2D_reg(vRegD dst, vRegF src) %{
13547   match(Set dst (ConvF2D src));
13548 
13549   ins_cost(INSN_COST * 5);
13550   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13551 
13552   ins_encode %{
13553     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13554   %}
13555 
13556   ins_pipe(fp_f2d);
13557 %}
13558 
13559 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13560   match(Set dst (ConvF2I src));
13561 
13562   ins_cost(INSN_COST * 5);
13563   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13564 
13565   ins_encode %{
13566     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13567   %}
13568 
13569   ins_pipe(fp_f2i);
13570 %}
13571 
13572 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13573   match(Set dst (ConvF2L src));
13574 
13575   ins_cost(INSN_COST * 5);
13576   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13577 
13578   ins_encode %{
13579     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13580   %}
13581 
13582   ins_pipe(fp_f2l);
13583 %}
13584 
13585 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13586   match(Set dst (ConvI2F src));
13587 
13588   ins_cost(INSN_COST * 5);
13589   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13590 
13591   ins_encode %{
13592     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13593   %}
13594 
13595   ins_pipe(fp_i2f);
13596 %}
13597 
13598 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13599   match(Set dst (ConvL2F src));
13600 
13601   ins_cost(INSN_COST * 5);
13602   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13603 
13604   ins_encode %{
13605     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13606   %}
13607 
13608   ins_pipe(fp_l2f);
13609 %}
13610 
13611 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13612   match(Set dst (ConvD2I src));
13613 
13614   ins_cost(INSN_COST * 5);
13615   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13616 
13617   ins_encode %{
13618     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13619   %}
13620 
13621   ins_pipe(fp_d2i);
13622 %}
13623 
13624 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13625   match(Set dst (ConvD2L src));
13626 
13627   ins_cost(INSN_COST * 5);
13628   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13629 
13630   ins_encode %{
13631     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13632   %}
13633 
13634   ins_pipe(fp_d2l);
13635 %}
13636 
13637 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13638   match(Set dst (ConvI2D src));
13639 
13640   ins_cost(INSN_COST * 5);
13641   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13642 
13643   ins_encode %{
13644     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13645   %}
13646 
13647   ins_pipe(fp_i2d);
13648 %}
13649 
13650 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13651   match(Set dst (ConvL2D src));
13652 
13653   ins_cost(INSN_COST * 5);
13654   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13655 
13656   ins_encode %{
13657     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13658   %}
13659 
13660   ins_pipe(fp_l2d);
13661 %}
13662 
13663 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13664 
13665 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13666 
13667   match(Set dst (MoveF2I src));
13668 
13669   effect(DEF dst, USE src);
13670 
13671   ins_cost(4 * INSN_COST);
13672 
13673   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13674 
13675   ins_encode %{
13676     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13677   %}
13678 
13679   ins_pipe(iload_reg_reg);
13680 
13681 %}
13682 
13683 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13684 
13685   match(Set dst (MoveI2F src));
13686 
13687   effect(DEF dst, USE src);
13688 
13689   ins_cost(4 * INSN_COST);
13690 
13691   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13692 
13693   ins_encode %{
13694     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13695   %}
13696 
13697   ins_pipe(pipe_class_memory);
13698 
13699 %}
13700 
13701 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13702 
13703   match(Set dst (MoveD2L src));
13704 
13705   effect(DEF dst, USE src);
13706 
13707   ins_cost(4 * INSN_COST);
13708 
13709   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13710 
13711   ins_encode %{
13712     __ ldr($dst$$Register, Address(sp, $src$$disp));
13713   %}
13714 
13715   ins_pipe(iload_reg_reg);
13716 
13717 %}
13718 
13719 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13720 
13721   match(Set dst (MoveL2D src));
13722 
13723   effect(DEF dst, USE src);
13724 
13725   ins_cost(4 * INSN_COST);
13726 
13727   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13728 
13729   ins_encode %{
13730     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13731   %}
13732 
13733   ins_pipe(pipe_class_memory);
13734 
13735 %}
13736 
13737 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13738 
13739   match(Set dst (MoveF2I src));
13740 
13741   effect(DEF dst, USE src);
13742 
13743   ins_cost(INSN_COST);
13744 
13745   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13746 
13747   ins_encode %{
13748     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13749   %}
13750 
13751   ins_pipe(pipe_class_memory);
13752 
13753 %}
13754 
13755 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13756 
13757   match(Set dst (MoveI2F src));
13758 
13759   effect(DEF dst, USE src);
13760 
13761   ins_cost(INSN_COST);
13762 
13763   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13764 
13765   ins_encode %{
13766     __ strw($src$$Register, Address(sp, $dst$$disp));
13767   %}
13768 
13769   ins_pipe(istore_reg_reg);
13770 
13771 %}
13772 
13773 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13774 
13775   match(Set dst (MoveD2L src));
13776 
13777   effect(DEF dst, USE src);
13778 
13779   ins_cost(INSN_COST);
13780 
13781   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13782 
13783   ins_encode %{
13784     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13785   %}
13786 
13787   ins_pipe(pipe_class_memory);
13788 
13789 %}
13790 
13791 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13792 
13793   match(Set dst (MoveL2D src));
13794 
13795   effect(DEF dst, USE src);
13796 
13797   ins_cost(INSN_COST);
13798 
13799   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13800 
13801   ins_encode %{
13802     __ str($src$$Register, Address(sp, $dst$$disp));
13803   %}
13804 
13805   ins_pipe(istore_reg_reg);
13806 
13807 %}
13808 
13809 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13810 
13811   match(Set dst (MoveF2I src));
13812 
13813   effect(DEF dst, USE src);
13814 
13815   ins_cost(INSN_COST);
13816 
13817   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13818 
13819   ins_encode %{
13820     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13821   %}
13822 
13823   ins_pipe(fp_f2i);
13824 
13825 %}
13826 
13827 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13828 
13829   match(Set dst (MoveI2F src));
13830 
13831   effect(DEF dst, USE src);
13832 
13833   ins_cost(INSN_COST);
13834 
13835   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13836 
13837   ins_encode %{
13838     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13839   %}
13840 
13841   ins_pipe(fp_i2f);
13842 
13843 %}
13844 
13845 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13846 
13847   match(Set dst (MoveD2L src));
13848 
13849   effect(DEF dst, USE src);
13850 
13851   ins_cost(INSN_COST);
13852 
13853   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13854 
13855   ins_encode %{
13856     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13857   %}
13858 
13859   ins_pipe(fp_d2l);
13860 
13861 %}
13862 
13863 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13864 
13865   match(Set dst (MoveL2D src));
13866 
13867   effect(DEF dst, USE src);
13868 
13869   ins_cost(INSN_COST);
13870 
13871   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13872 
13873   ins_encode %{
13874     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13875   %}
13876 
13877   ins_pipe(fp_l2d);
13878 
13879 %}
13880 
13881 // ============================================================================
13882 // clearing of an array
13883 
<a name="10" id="anc10"></a><span class="line-modified">13884 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)</span>
13885 %{
<a name="11" id="anc11"></a><span class="line-modified">13886   match(Set dummy (ClearArray cnt base));</span>
13887   effect(USE_KILL cnt, USE_KILL base);
13888 
13889   ins_cost(4 * INSN_COST);
<a name="12" id="anc12"></a><span class="line-modified">13890   format %{ &quot;ClearArray $cnt, $base&quot; %}</span>
<span class="line-removed">13891 </span>
<span class="line-removed">13892   ins_encode %{</span>
<span class="line-removed">13893     __ zero_words($base$$Register, $cnt$$Register);</span>
<span class="line-removed">13894   %}</span>
<span class="line-removed">13895 </span>
<span class="line-removed">13896   ins_pipe(pipe_class_memory);</span>
<span class="line-removed">13897 %}</span>
<span class="line-removed">13898 </span>
<span class="line-removed">13899 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)</span>
<span class="line-removed">13900 %{</span>
<span class="line-removed">13901   predicate((u_int64_t)n-&gt;in(2)-&gt;get_long()</span>
<span class="line-removed">13902             &lt; (u_int64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));</span>
<span class="line-removed">13903   match(Set dummy (ClearArray cnt base));</span>
<span class="line-removed">13904   effect(USE_KILL base);</span>
<span class="line-removed">13905 </span>
<span class="line-removed">13906   ins_cost(4 * INSN_COST);</span>
<span class="line-removed">13907   format %{ &quot;ClearArray $cnt, $base&quot; %}</span>
13908 
13909   ins_encode %{
<a name="13" id="anc13"></a><span class="line-modified">13910     __ zero_words($base$$Register, (u_int64_t)$cnt$$constant);</span>
13911   %}
13912 
13913   ins_pipe(pipe_class_memory);
13914 %}
13915 
13916 // ============================================================================
13917 // Overflow Math Instructions
13918 
13919 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13920 %{
13921   match(Set cr (OverflowAddI op1 op2));
13922 
13923   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13924   ins_cost(INSN_COST);
13925   ins_encode %{
13926     __ cmnw($op1$$Register, $op2$$Register);
13927   %}
13928 
13929   ins_pipe(icmp_reg_reg);
13930 %}
13931 
13932 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13933 %{
13934   match(Set cr (OverflowAddI op1 op2));
13935 
13936   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13937   ins_cost(INSN_COST);
13938   ins_encode %{
13939     __ cmnw($op1$$Register, $op2$$constant);
13940   %}
13941 
13942   ins_pipe(icmp_reg_imm);
13943 %}
13944 
13945 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13946 %{
13947   match(Set cr (OverflowAddL op1 op2));
13948 
13949   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13950   ins_cost(INSN_COST);
13951   ins_encode %{
13952     __ cmn($op1$$Register, $op2$$Register);
13953   %}
13954 
13955   ins_pipe(icmp_reg_reg);
13956 %}
13957 
13958 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13959 %{
13960   match(Set cr (OverflowAddL op1 op2));
13961 
13962   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13963   ins_cost(INSN_COST);
13964   ins_encode %{
13965     __ cmn($op1$$Register, $op2$$constant);
13966   %}
13967 
13968   ins_pipe(icmp_reg_imm);
13969 %}
13970 
13971 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13972 %{
13973   match(Set cr (OverflowSubI op1 op2));
13974 
13975   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13976   ins_cost(INSN_COST);
13977   ins_encode %{
13978     __ cmpw($op1$$Register, $op2$$Register);
13979   %}
13980 
13981   ins_pipe(icmp_reg_reg);
13982 %}
13983 
13984 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13985 %{
13986   match(Set cr (OverflowSubI op1 op2));
13987 
13988   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13989   ins_cost(INSN_COST);
13990   ins_encode %{
13991     __ cmpw($op1$$Register, $op2$$constant);
13992   %}
13993 
13994   ins_pipe(icmp_reg_imm);
13995 %}
13996 
13997 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13998 %{
13999   match(Set cr (OverflowSubL op1 op2));
14000 
14001   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14002   ins_cost(INSN_COST);
14003   ins_encode %{
14004     __ cmp($op1$$Register, $op2$$Register);
14005   %}
14006 
14007   ins_pipe(icmp_reg_reg);
14008 %}
14009 
14010 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14011 %{
14012   match(Set cr (OverflowSubL op1 op2));
14013 
14014   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14015   ins_cost(INSN_COST);
14016   ins_encode %{
14017     __ subs(zr, $op1$$Register, $op2$$constant);
14018   %}
14019 
14020   ins_pipe(icmp_reg_imm);
14021 %}
14022 
14023 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14024 %{
14025   match(Set cr (OverflowSubI zero op1));
14026 
14027   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14028   ins_cost(INSN_COST);
14029   ins_encode %{
14030     __ cmpw(zr, $op1$$Register);
14031   %}
14032 
14033   ins_pipe(icmp_reg_imm);
14034 %}
14035 
14036 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14037 %{
14038   match(Set cr (OverflowSubL zero op1));
14039 
14040   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14041   ins_cost(INSN_COST);
14042   ins_encode %{
14043     __ cmp(zr, $op1$$Register);
14044   %}
14045 
14046   ins_pipe(icmp_reg_imm);
14047 %}
14048 
14049 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14050 %{
14051   match(Set cr (OverflowMulI op1 op2));
14052 
14053   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14054             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14055             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14056             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14057             &quot;cmpw  rscratch1, #1&quot; %}
14058   ins_cost(5 * INSN_COST);
14059   ins_encode %{
14060     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14061     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14062     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14063     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14064     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14065   %}
14066 
14067   ins_pipe(pipe_slow);
14068 %}
14069 
14070 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14071 %{
14072   match(If cmp (OverflowMulI op1 op2));
14073   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14074             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14075   effect(USE labl, KILL cr);
14076 
14077   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14078             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14079             &quot;b$cmp   $labl&quot; %}
14080   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14081   ins_encode %{
14082     Label* L = $labl$$label;
14083     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14084     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14085     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14086     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14087   %}
14088 
14089   ins_pipe(pipe_serial);
14090 %}
14091 
14092 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14093 %{
14094   match(Set cr (OverflowMulL op1 op2));
14095 
14096   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14097             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14098             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14099             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14100             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14101             &quot;cmpw  rscratch1, #1&quot; %}
14102   ins_cost(6 * INSN_COST);
14103   ins_encode %{
14104     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14105     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14106     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14107     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14108     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14109     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14110   %}
14111 
14112   ins_pipe(pipe_slow);
14113 %}
14114 
14115 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14116 %{
14117   match(If cmp (OverflowMulL op1 op2));
14118   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14119             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14120   effect(USE labl, KILL cr);
14121 
14122   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14123             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14124             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14125             &quot;b$cmp $labl&quot; %}
14126   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14127   ins_encode %{
14128     Label* L = $labl$$label;
14129     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14130     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14131     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14132     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14133     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14134   %}
14135 
14136   ins_pipe(pipe_serial);
14137 %}
14138 
14139 // ============================================================================
14140 // Compare Instructions
14141 
14142 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14143 %{
14144   match(Set cr (CmpI op1 op2));
14145 
14146   effect(DEF cr, USE op1, USE op2);
14147 
14148   ins_cost(INSN_COST);
14149   format %{ &quot;cmpw  $op1, $op2&quot; %}
14150 
14151   ins_encode(aarch64_enc_cmpw(op1, op2));
14152 
14153   ins_pipe(icmp_reg_reg);
14154 %}
14155 
14156 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14157 %{
14158   match(Set cr (CmpI op1 zero));
14159 
14160   effect(DEF cr, USE op1);
14161 
14162   ins_cost(INSN_COST);
14163   format %{ &quot;cmpw $op1, 0&quot; %}
14164 
14165   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14166 
14167   ins_pipe(icmp_reg_imm);
14168 %}
14169 
14170 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14171 %{
14172   match(Set cr (CmpI op1 op2));
14173 
14174   effect(DEF cr, USE op1);
14175 
14176   ins_cost(INSN_COST);
14177   format %{ &quot;cmpw  $op1, $op2&quot; %}
14178 
14179   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14180 
14181   ins_pipe(icmp_reg_imm);
14182 %}
14183 
14184 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14185 %{
14186   match(Set cr (CmpI op1 op2));
14187 
14188   effect(DEF cr, USE op1);
14189 
14190   ins_cost(INSN_COST * 2);
14191   format %{ &quot;cmpw  $op1, $op2&quot; %}
14192 
14193   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14194 
14195   ins_pipe(icmp_reg_imm);
14196 %}
14197 
14198 // Unsigned compare Instructions; really, same as signed compare
14199 // except it should only be used to feed an If or a CMovI which takes a
14200 // cmpOpU.
14201 
14202 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14203 %{
14204   match(Set cr (CmpU op1 op2));
14205 
14206   effect(DEF cr, USE op1, USE op2);
14207 
14208   ins_cost(INSN_COST);
14209   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14210 
14211   ins_encode(aarch64_enc_cmpw(op1, op2));
14212 
14213   ins_pipe(icmp_reg_reg);
14214 %}
14215 
14216 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14217 %{
14218   match(Set cr (CmpU op1 zero));
14219 
14220   effect(DEF cr, USE op1);
14221 
14222   ins_cost(INSN_COST);
14223   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14224 
14225   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14226 
14227   ins_pipe(icmp_reg_imm);
14228 %}
14229 
14230 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14231 %{
14232   match(Set cr (CmpU op1 op2));
14233 
14234   effect(DEF cr, USE op1);
14235 
14236   ins_cost(INSN_COST);
14237   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14238 
14239   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14240 
14241   ins_pipe(icmp_reg_imm);
14242 %}
14243 
14244 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14245 %{
14246   match(Set cr (CmpU op1 op2));
14247 
14248   effect(DEF cr, USE op1);
14249 
14250   ins_cost(INSN_COST * 2);
14251   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14252 
14253   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14254 
14255   ins_pipe(icmp_reg_imm);
14256 %}
14257 
14258 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14259 %{
14260   match(Set cr (CmpL op1 op2));
14261 
14262   effect(DEF cr, USE op1, USE op2);
14263 
14264   ins_cost(INSN_COST);
14265   format %{ &quot;cmp  $op1, $op2&quot; %}
14266 
14267   ins_encode(aarch64_enc_cmp(op1, op2));
14268 
14269   ins_pipe(icmp_reg_reg);
14270 %}
14271 
14272 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14273 %{
14274   match(Set cr (CmpL op1 zero));
14275 
14276   effect(DEF cr, USE op1);
14277 
14278   ins_cost(INSN_COST);
14279   format %{ &quot;tst  $op1&quot; %}
14280 
14281   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14282 
14283   ins_pipe(icmp_reg_imm);
14284 %}
14285 
14286 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14287 %{
14288   match(Set cr (CmpL op1 op2));
14289 
14290   effect(DEF cr, USE op1);
14291 
14292   ins_cost(INSN_COST);
14293   format %{ &quot;cmp  $op1, $op2&quot; %}
14294 
14295   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14296 
14297   ins_pipe(icmp_reg_imm);
14298 %}
14299 
14300 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14301 %{
14302   match(Set cr (CmpL op1 op2));
14303 
14304   effect(DEF cr, USE op1);
14305 
14306   ins_cost(INSN_COST * 2);
14307   format %{ &quot;cmp  $op1, $op2&quot; %}
14308 
14309   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14310 
14311   ins_pipe(icmp_reg_imm);
14312 %}
14313 
14314 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14315 %{
14316   match(Set cr (CmpUL op1 op2));
14317 
14318   effect(DEF cr, USE op1, USE op2);
14319 
14320   ins_cost(INSN_COST);
14321   format %{ &quot;cmp  $op1, $op2&quot; %}
14322 
14323   ins_encode(aarch64_enc_cmp(op1, op2));
14324 
14325   ins_pipe(icmp_reg_reg);
14326 %}
14327 
14328 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14329 %{
14330   match(Set cr (CmpUL op1 zero));
14331 
14332   effect(DEF cr, USE op1);
14333 
14334   ins_cost(INSN_COST);
14335   format %{ &quot;tst  $op1&quot; %}
14336 
14337   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14338 
14339   ins_pipe(icmp_reg_imm);
14340 %}
14341 
14342 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14343 %{
14344   match(Set cr (CmpUL op1 op2));
14345 
14346   effect(DEF cr, USE op1);
14347 
14348   ins_cost(INSN_COST);
14349   format %{ &quot;cmp  $op1, $op2&quot; %}
14350 
14351   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14352 
14353   ins_pipe(icmp_reg_imm);
14354 %}
14355 
14356 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14357 %{
14358   match(Set cr (CmpUL op1 op2));
14359 
14360   effect(DEF cr, USE op1);
14361 
14362   ins_cost(INSN_COST * 2);
14363   format %{ &quot;cmp  $op1, $op2&quot; %}
14364 
14365   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14366 
14367   ins_pipe(icmp_reg_imm);
14368 %}
14369 
14370 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14371 %{
14372   match(Set cr (CmpP op1 op2));
14373 
14374   effect(DEF cr, USE op1, USE op2);
14375 
14376   ins_cost(INSN_COST);
14377   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14378 
14379   ins_encode(aarch64_enc_cmpp(op1, op2));
14380 
14381   ins_pipe(icmp_reg_reg);
14382 %}
14383 
14384 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14385 %{
14386   match(Set cr (CmpN op1 op2));
14387 
14388   effect(DEF cr, USE op1, USE op2);
14389 
14390   ins_cost(INSN_COST);
14391   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14392 
14393   ins_encode(aarch64_enc_cmpn(op1, op2));
14394 
14395   ins_pipe(icmp_reg_reg);
14396 %}
14397 
14398 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14399 %{
14400   match(Set cr (CmpP op1 zero));
14401 
14402   effect(DEF cr, USE op1, USE zero);
14403 
14404   ins_cost(INSN_COST);
14405   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14406 
14407   ins_encode(aarch64_enc_testp(op1));
14408 
14409   ins_pipe(icmp_reg_imm);
14410 %}
14411 
14412 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14413 %{
14414   match(Set cr (CmpN op1 zero));
14415 
14416   effect(DEF cr, USE op1, USE zero);
14417 
14418   ins_cost(INSN_COST);
14419   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14420 
14421   ins_encode(aarch64_enc_testn(op1));
14422 
14423   ins_pipe(icmp_reg_imm);
14424 %}
14425 
14426 // FP comparisons
14427 //
14428 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14429 // using normal cmpOp. See declaration of rFlagsReg for details.
14430 
14431 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14432 %{
14433   match(Set cr (CmpF src1 src2));
14434 
14435   ins_cost(3 * INSN_COST);
14436   format %{ &quot;fcmps $src1, $src2&quot; %}
14437 
14438   ins_encode %{
14439     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14440   %}
14441 
14442   ins_pipe(pipe_class_compare);
14443 %}
14444 
14445 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14446 %{
14447   match(Set cr (CmpF src1 src2));
14448 
14449   ins_cost(3 * INSN_COST);
14450   format %{ &quot;fcmps $src1, 0.0&quot; %}
14451 
14452   ins_encode %{
14453     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14454   %}
14455 
14456   ins_pipe(pipe_class_compare);
14457 %}
14458 // FROM HERE
14459 
14460 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14461 %{
14462   match(Set cr (CmpD src1 src2));
14463 
14464   ins_cost(3 * INSN_COST);
14465   format %{ &quot;fcmpd $src1, $src2&quot; %}
14466 
14467   ins_encode %{
14468     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14469   %}
14470 
14471   ins_pipe(pipe_class_compare);
14472 %}
14473 
14474 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14475 %{
14476   match(Set cr (CmpD src1 src2));
14477 
14478   ins_cost(3 * INSN_COST);
14479   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14480 
14481   ins_encode %{
14482     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14483   %}
14484 
14485   ins_pipe(pipe_class_compare);
14486 %}
14487 
14488 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14489 %{
14490   match(Set dst (CmpF3 src1 src2));
14491   effect(KILL cr);
14492 
14493   ins_cost(5 * INSN_COST);
14494   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14495             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14496             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14497   %}
14498 
14499   ins_encode %{
14500     Label done;
14501     FloatRegister s1 = as_FloatRegister($src1$$reg);
14502     FloatRegister s2 = as_FloatRegister($src2$$reg);
14503     Register d = as_Register($dst$$reg);
14504     __ fcmps(s1, s2);
14505     // installs 0 if EQ else -1
14506     __ csinvw(d, zr, zr, Assembler::EQ);
14507     // keeps -1 if less or unordered else installs 1
14508     __ csnegw(d, d, d, Assembler::LT);
14509     __ bind(done);
14510   %}
14511 
14512   ins_pipe(pipe_class_default);
14513 
14514 %}
14515 
14516 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14517 %{
14518   match(Set dst (CmpD3 src1 src2));
14519   effect(KILL cr);
14520 
14521   ins_cost(5 * INSN_COST);
14522   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14523             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14524             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14525   %}
14526 
14527   ins_encode %{
14528     Label done;
14529     FloatRegister s1 = as_FloatRegister($src1$$reg);
14530     FloatRegister s2 = as_FloatRegister($src2$$reg);
14531     Register d = as_Register($dst$$reg);
14532     __ fcmpd(s1, s2);
14533     // installs 0 if EQ else -1
14534     __ csinvw(d, zr, zr, Assembler::EQ);
14535     // keeps -1 if less or unordered else installs 1
14536     __ csnegw(d, d, d, Assembler::LT);
14537     __ bind(done);
14538   %}
14539   ins_pipe(pipe_class_default);
14540 
14541 %}
14542 
14543 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14544 %{
14545   match(Set dst (CmpF3 src1 zero));
14546   effect(KILL cr);
14547 
14548   ins_cost(5 * INSN_COST);
14549   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14550             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14551             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14552   %}
14553 
14554   ins_encode %{
14555     Label done;
14556     FloatRegister s1 = as_FloatRegister($src1$$reg);
14557     Register d = as_Register($dst$$reg);
14558     __ fcmps(s1, 0.0);
14559     // installs 0 if EQ else -1
14560     __ csinvw(d, zr, zr, Assembler::EQ);
14561     // keeps -1 if less or unordered else installs 1
14562     __ csnegw(d, d, d, Assembler::LT);
14563     __ bind(done);
14564   %}
14565 
14566   ins_pipe(pipe_class_default);
14567 
14568 %}
14569 
14570 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14571 %{
14572   match(Set dst (CmpD3 src1 zero));
14573   effect(KILL cr);
14574 
14575   ins_cost(5 * INSN_COST);
14576   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14577             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14578             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14579   %}
14580 
14581   ins_encode %{
14582     Label done;
14583     FloatRegister s1 = as_FloatRegister($src1$$reg);
14584     Register d = as_Register($dst$$reg);
14585     __ fcmpd(s1, 0.0);
14586     // installs 0 if EQ else -1
14587     __ csinvw(d, zr, zr, Assembler::EQ);
14588     // keeps -1 if less or unordered else installs 1
14589     __ csnegw(d, d, d, Assembler::LT);
14590     __ bind(done);
14591   %}
14592   ins_pipe(pipe_class_default);
14593 
14594 %}
14595 
14596 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14597 %{
14598   match(Set dst (CmpLTMask p q));
14599   effect(KILL cr);
14600 
14601   ins_cost(3 * INSN_COST);
14602 
14603   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14604             &quot;csetw $dst, lt\n\t&quot;
14605             &quot;subw $dst, zr, $dst&quot;
14606   %}
14607 
14608   ins_encode %{
14609     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14610     __ csetw(as_Register($dst$$reg), Assembler::LT);
14611     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14612   %}
14613 
14614   ins_pipe(ialu_reg_reg);
14615 %}
14616 
14617 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14618 %{
14619   match(Set dst (CmpLTMask src zero));
14620   effect(KILL cr);
14621 
14622   ins_cost(INSN_COST);
14623 
14624   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14625 
14626   ins_encode %{
14627     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14628   %}
14629 
14630   ins_pipe(ialu_reg_shift);
14631 %}
14632 
14633 // ============================================================================
14634 // Max and Min
14635 
14636 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14637 %{
14638   effect( DEF dst, USE src1, USE src2, USE cr );
14639 
14640   ins_cost(INSN_COST * 2);
14641   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14642 
14643   ins_encode %{
14644     __ cselw(as_Register($dst$$reg),
14645              as_Register($src1$$reg),
14646              as_Register($src2$$reg),
14647              Assembler::LT);
14648   %}
14649 
14650   ins_pipe(icond_reg_reg);
14651 %}
14652 
14653 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14654 %{
14655   match(Set dst (MinI src1 src2));
14656   ins_cost(INSN_COST * 3);
14657 
14658   expand %{
14659     rFlagsReg cr;
14660     compI_reg_reg(cr, src1, src2);
14661     cmovI_reg_reg_lt(dst, src1, src2, cr);
14662   %}
14663 
14664 %}
14665 // FROM HERE
14666 
14667 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14668 %{
14669   effect( DEF dst, USE src1, USE src2, USE cr );
14670 
14671   ins_cost(INSN_COST * 2);
14672   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14673 
14674   ins_encode %{
14675     __ cselw(as_Register($dst$$reg),
14676              as_Register($src1$$reg),
14677              as_Register($src2$$reg),
14678              Assembler::GT);
14679   %}
14680 
14681   ins_pipe(icond_reg_reg);
14682 %}
14683 
14684 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14685 %{
14686   match(Set dst (MaxI src1 src2));
14687   ins_cost(INSN_COST * 3);
14688   expand %{
14689     rFlagsReg cr;
14690     compI_reg_reg(cr, src1, src2);
14691     cmovI_reg_reg_gt(dst, src1, src2, cr);
14692   %}
14693 %}
14694 
14695 // ============================================================================
14696 // Branch Instructions
14697 
14698 // Direct Branch.
14699 instruct branch(label lbl)
14700 %{
14701   match(Goto);
14702 
14703   effect(USE lbl);
14704 
14705   ins_cost(BRANCH_COST);
14706   format %{ &quot;b  $lbl&quot; %}
14707 
14708   ins_encode(aarch64_enc_b(lbl));
14709 
14710   ins_pipe(pipe_branch);
14711 %}
14712 
14713 // Conditional Near Branch
14714 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14715 %{
14716   // Same match rule as `branchConFar&#39;.
14717   match(If cmp cr);
14718 
14719   effect(USE lbl);
14720 
14721   ins_cost(BRANCH_COST);
14722   // If set to 1 this indicates that the current instruction is a
14723   // short variant of a long branch. This avoids using this
14724   // instruction in first-pass matching. It will then only be used in
14725   // the `Shorten_branches&#39; pass.
14726   // ins_short_branch(1);
14727   format %{ &quot;b$cmp  $lbl&quot; %}
14728 
14729   ins_encode(aarch64_enc_br_con(cmp, lbl));
14730 
14731   ins_pipe(pipe_branch_cond);
14732 %}
14733 
14734 // Conditional Near Branch Unsigned
14735 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14736 %{
14737   // Same match rule as `branchConFar&#39;.
14738   match(If cmp cr);
14739 
14740   effect(USE lbl);
14741 
14742   ins_cost(BRANCH_COST);
14743   // If set to 1 this indicates that the current instruction is a
14744   // short variant of a long branch. This avoids using this
14745   // instruction in first-pass matching. It will then only be used in
14746   // the `Shorten_branches&#39; pass.
14747   // ins_short_branch(1);
14748   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14749 
14750   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14751 
14752   ins_pipe(pipe_branch_cond);
14753 %}
14754 
14755 // Make use of CBZ and CBNZ.  These instructions, as well as being
14756 // shorter than (cmp; branch), have the additional benefit of not
14757 // killing the flags.
14758 
14759 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14760   match(If cmp (CmpI op1 op2));
14761   effect(USE labl);
14762 
14763   ins_cost(BRANCH_COST);
14764   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14765   ins_encode %{
14766     Label* L = $labl$$label;
14767     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14768     if (cond == Assembler::EQ)
14769       __ cbzw($op1$$Register, *L);
14770     else
14771       __ cbnzw($op1$$Register, *L);
14772   %}
14773   ins_pipe(pipe_cmp_branch);
14774 %}
14775 
14776 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14777   match(If cmp (CmpL op1 op2));
14778   effect(USE labl);
14779 
14780   ins_cost(BRANCH_COST);
14781   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14782   ins_encode %{
14783     Label* L = $labl$$label;
14784     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14785     if (cond == Assembler::EQ)
14786       __ cbz($op1$$Register, *L);
14787     else
14788       __ cbnz($op1$$Register, *L);
14789   %}
14790   ins_pipe(pipe_cmp_branch);
14791 %}
14792 
14793 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14794   match(If cmp (CmpP op1 op2));
14795   effect(USE labl);
14796 
14797   ins_cost(BRANCH_COST);
14798   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14799   ins_encode %{
14800     Label* L = $labl$$label;
14801     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14802     if (cond == Assembler::EQ)
14803       __ cbz($op1$$Register, *L);
14804     else
14805       __ cbnz($op1$$Register, *L);
14806   %}
14807   ins_pipe(pipe_cmp_branch);
14808 %}
14809 
14810 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14811   match(If cmp (CmpN op1 op2));
14812   effect(USE labl);
14813 
14814   ins_cost(BRANCH_COST);
14815   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14816   ins_encode %{
14817     Label* L = $labl$$label;
14818     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14819     if (cond == Assembler::EQ)
14820       __ cbzw($op1$$Register, *L);
14821     else
14822       __ cbnzw($op1$$Register, *L);
14823   %}
14824   ins_pipe(pipe_cmp_branch);
14825 %}
14826 
14827 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14828   match(If cmp (CmpP (DecodeN oop) zero));
14829   effect(USE labl);
14830 
14831   ins_cost(BRANCH_COST);
14832   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14833   ins_encode %{
14834     Label* L = $labl$$label;
14835     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14836     if (cond == Assembler::EQ)
14837       __ cbzw($oop$$Register, *L);
14838     else
14839       __ cbnzw($oop$$Register, *L);
14840   %}
14841   ins_pipe(pipe_cmp_branch);
14842 %}
14843 
14844 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14845   match(If cmp (CmpU op1 op2));
14846   effect(USE labl);
14847 
14848   ins_cost(BRANCH_COST);
14849   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14850   ins_encode %{
14851     Label* L = $labl$$label;
14852     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14853     if (cond == Assembler::EQ || cond == Assembler::LS)
14854       __ cbzw($op1$$Register, *L);
14855     else
14856       __ cbnzw($op1$$Register, *L);
14857   %}
14858   ins_pipe(pipe_cmp_branch);
14859 %}
14860 
14861 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14862   match(If cmp (CmpUL op1 op2));
14863   effect(USE labl);
14864 
14865   ins_cost(BRANCH_COST);
14866   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14867   ins_encode %{
14868     Label* L = $labl$$label;
14869     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14870     if (cond == Assembler::EQ || cond == Assembler::LS)
14871       __ cbz($op1$$Register, *L);
14872     else
14873       __ cbnz($op1$$Register, *L);
14874   %}
14875   ins_pipe(pipe_cmp_branch);
14876 %}
14877 
14878 // Test bit and Branch
14879 
14880 // Patterns for short (&lt; 32KiB) variants
14881 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14882   match(If cmp (CmpL op1 op2));
14883   effect(USE labl);
14884 
14885   ins_cost(BRANCH_COST);
14886   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14887   ins_encode %{
14888     Label* L = $labl$$label;
14889     Assembler::Condition cond =
14890       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14891     __ tbr(cond, $op1$$Register, 63, *L);
14892   %}
14893   ins_pipe(pipe_cmp_branch);
14894   ins_short_branch(1);
14895 %}
14896 
14897 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14898   match(If cmp (CmpI op1 op2));
14899   effect(USE labl);
14900 
14901   ins_cost(BRANCH_COST);
14902   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14903   ins_encode %{
14904     Label* L = $labl$$label;
14905     Assembler::Condition cond =
14906       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14907     __ tbr(cond, $op1$$Register, 31, *L);
14908   %}
14909   ins_pipe(pipe_cmp_branch);
14910   ins_short_branch(1);
14911 %}
14912 
14913 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14914   match(If cmp (CmpL (AndL op1 op2) op3));
14915   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14916   effect(USE labl);
14917 
14918   ins_cost(BRANCH_COST);
14919   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14920   ins_encode %{
14921     Label* L = $labl$$label;
14922     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14923     int bit = exact_log2_long($op2$$constant);
14924     __ tbr(cond, $op1$$Register, bit, *L);
14925   %}
14926   ins_pipe(pipe_cmp_branch);
14927   ins_short_branch(1);
14928 %}
14929 
14930 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14931   match(If cmp (CmpI (AndI op1 op2) op3));
14932   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14933   effect(USE labl);
14934 
14935   ins_cost(BRANCH_COST);
14936   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14937   ins_encode %{
14938     Label* L = $labl$$label;
14939     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14940     int bit = exact_log2((juint)$op2$$constant);
14941     __ tbr(cond, $op1$$Register, bit, *L);
14942   %}
14943   ins_pipe(pipe_cmp_branch);
14944   ins_short_branch(1);
14945 %}
14946 
14947 // And far variants
14948 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14949   match(If cmp (CmpL op1 op2));
14950   effect(USE labl);
14951 
14952   ins_cost(BRANCH_COST);
14953   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14954   ins_encode %{
14955     Label* L = $labl$$label;
14956     Assembler::Condition cond =
14957       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14958     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14959   %}
14960   ins_pipe(pipe_cmp_branch);
14961 %}
14962 
14963 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14964   match(If cmp (CmpI op1 op2));
14965   effect(USE labl);
14966 
14967   ins_cost(BRANCH_COST);
14968   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14969   ins_encode %{
14970     Label* L = $labl$$label;
14971     Assembler::Condition cond =
14972       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14973     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14974   %}
14975   ins_pipe(pipe_cmp_branch);
14976 %}
14977 
14978 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14979   match(If cmp (CmpL (AndL op1 op2) op3));
14980   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14981   effect(USE labl);
14982 
14983   ins_cost(BRANCH_COST);
14984   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14985   ins_encode %{
14986     Label* L = $labl$$label;
14987     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14988     int bit = exact_log2_long($op2$$constant);
14989     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14990   %}
14991   ins_pipe(pipe_cmp_branch);
14992 %}
14993 
14994 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14995   match(If cmp (CmpI (AndI op1 op2) op3));
14996   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14997   effect(USE labl);
14998 
14999   ins_cost(BRANCH_COST);
15000   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15001   ins_encode %{
15002     Label* L = $labl$$label;
15003     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15004     int bit = exact_log2((juint)$op2$$constant);
15005     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15006   %}
15007   ins_pipe(pipe_cmp_branch);
15008 %}
15009 
15010 // Test bits
15011 
15012 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15013   match(Set cr (CmpL (AndL op1 op2) op3));
15014   predicate(Assembler::operand_valid_for_logical_immediate
15015             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15016 
15017   ins_cost(INSN_COST);
15018   format %{ &quot;tst $op1, $op2 # long&quot; %}
15019   ins_encode %{
15020     __ tst($op1$$Register, $op2$$constant);
15021   %}
15022   ins_pipe(ialu_reg_reg);
15023 %}
15024 
15025 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15026   match(Set cr (CmpI (AndI op1 op2) op3));
15027   predicate(Assembler::operand_valid_for_logical_immediate
15028             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15029 
15030   ins_cost(INSN_COST);
15031   format %{ &quot;tst $op1, $op2 # int&quot; %}
15032   ins_encode %{
15033     __ tstw($op1$$Register, $op2$$constant);
15034   %}
15035   ins_pipe(ialu_reg_reg);
15036 %}
15037 
15038 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15039   match(Set cr (CmpL (AndL op1 op2) op3));
15040 
15041   ins_cost(INSN_COST);
15042   format %{ &quot;tst $op1, $op2 # long&quot; %}
15043   ins_encode %{
15044     __ tst($op1$$Register, $op2$$Register);
15045   %}
15046   ins_pipe(ialu_reg_reg);
15047 %}
15048 
15049 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15050   match(Set cr (CmpI (AndI op1 op2) op3));
15051 
15052   ins_cost(INSN_COST);
15053   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15054   ins_encode %{
15055     __ tstw($op1$$Register, $op2$$Register);
15056   %}
15057   ins_pipe(ialu_reg_reg);
15058 %}
15059 
15060 
15061 // Conditional Far Branch
15062 // Conditional Far Branch Unsigned
15063 // TODO: fixme
15064 
15065 // counted loop end branch near
15066 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15067 %{
15068   match(CountedLoopEnd cmp cr);
15069 
15070   effect(USE lbl);
15071 
15072   ins_cost(BRANCH_COST);
15073   // short variant.
15074   // ins_short_branch(1);
15075   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15076 
15077   ins_encode(aarch64_enc_br_con(cmp, lbl));
15078 
15079   ins_pipe(pipe_branch);
15080 %}
15081 
15082 // counted loop end branch near Unsigned
15083 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15084 %{
15085   match(CountedLoopEnd cmp cr);
15086 
15087   effect(USE lbl);
15088 
15089   ins_cost(BRANCH_COST);
15090   // short variant.
15091   // ins_short_branch(1);
15092   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15093 
15094   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15095 
15096   ins_pipe(pipe_branch);
15097 %}
15098 
15099 // counted loop end branch far
15100 // counted loop end branch far unsigned
15101 // TODO: fixme
15102 
15103 // ============================================================================
15104 // inlined locking and unlocking
15105 
15106 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15107 %{
15108   match(Set cr (FastLock object box));
15109   effect(TEMP tmp, TEMP tmp2);
15110 
15111   // TODO
15112   // identify correct cost
15113   ins_cost(5 * INSN_COST);
15114   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15115 
15116   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15117 
15118   ins_pipe(pipe_serial);
15119 %}
15120 
15121 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15122 %{
15123   match(Set cr (FastUnlock object box));
15124   effect(TEMP tmp, TEMP tmp2);
15125 
15126   ins_cost(5 * INSN_COST);
15127   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15128 
15129   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15130 
15131   ins_pipe(pipe_serial);
15132 %}
15133 
15134 
15135 // ============================================================================
15136 // Safepoint Instructions
15137 
15138 // TODO
15139 // provide a near and far version of this code
15140 
15141 instruct safePoint(rFlagsReg cr, iRegP poll)
15142 %{
15143   match(SafePoint poll);
15144   effect(KILL cr);
15145 
15146   format %{
15147     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15148   %}
15149   ins_encode %{
15150     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15151   %}
15152   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15153 %}
15154 
15155 
15156 // ============================================================================
15157 // Procedure Call/Return Instructions
15158 
15159 // Call Java Static Instruction
15160 
15161 instruct CallStaticJavaDirect(method meth)
15162 %{
15163   match(CallStaticJava);
15164 
15165   effect(USE meth);
15166 
15167   ins_cost(CALL_COST);
15168 
15169   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15170 
15171   ins_encode( aarch64_enc_java_static_call(meth),
15172               aarch64_enc_call_epilog );
15173 
15174   ins_pipe(pipe_class_call);
15175 %}
15176 
15177 // TO HERE
15178 
15179 // Call Java Dynamic Instruction
15180 instruct CallDynamicJavaDirect(method meth)
15181 %{
15182   match(CallDynamicJava);
15183 
15184   effect(USE meth);
15185 
15186   ins_cost(CALL_COST);
15187 
15188   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15189 
15190   ins_encode( aarch64_enc_java_dynamic_call(meth),
15191                aarch64_enc_call_epilog );
15192 
15193   ins_pipe(pipe_class_call);
15194 %}
15195 
15196 // Call Runtime Instruction
15197 
15198 instruct CallRuntimeDirect(method meth)
15199 %{
15200   match(CallRuntime);
15201 
15202   effect(USE meth);
15203 
15204   ins_cost(CALL_COST);
15205 
15206   format %{ &quot;CALL, runtime $meth&quot; %}
15207 
15208   ins_encode( aarch64_enc_java_to_runtime(meth) );
15209 
15210   ins_pipe(pipe_class_call);
15211 %}
15212 
15213 // Call Runtime Instruction
15214 
15215 instruct CallLeafDirect(method meth)
15216 %{
15217   match(CallLeaf);
15218 
15219   effect(USE meth);
15220 
15221   ins_cost(CALL_COST);
15222 
15223   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15224 
15225   ins_encode( aarch64_enc_java_to_runtime(meth) );
15226 
15227   ins_pipe(pipe_class_call);
15228 %}
15229 
15230 // Call Runtime Instruction
15231 
15232 instruct CallLeafNoFPDirect(method meth)
15233 %{
15234   match(CallLeafNoFP);
15235 
15236   effect(USE meth);
15237 
15238   ins_cost(CALL_COST);
15239 
15240   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15241 
15242   ins_encode( aarch64_enc_java_to_runtime(meth) );
15243 
15244   ins_pipe(pipe_class_call);
15245 %}
15246 
15247 // Tail Call; Jump from runtime stub to Java code.
15248 // Also known as an &#39;interprocedural jump&#39;.
15249 // Target of jump will eventually return to caller.
15250 // TailJump below removes the return address.
15251 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15252 %{
15253   match(TailCall jump_target method_oop);
15254 
15255   ins_cost(CALL_COST);
15256 
15257   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15258 
15259   ins_encode(aarch64_enc_tail_call(jump_target));
15260 
15261   ins_pipe(pipe_class_call);
15262 %}
15263 
15264 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15265 %{
15266   match(TailJump jump_target ex_oop);
15267 
15268   ins_cost(CALL_COST);
15269 
15270   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15271 
15272   ins_encode(aarch64_enc_tail_jmp(jump_target));
15273 
15274   ins_pipe(pipe_class_call);
15275 %}
15276 
15277 // Create exception oop: created by stack-crawling runtime code.
15278 // Created exception is now available to this handler, and is setup
15279 // just prior to jumping to this handler. No code emitted.
15280 // TODO check
15281 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15282 instruct CreateException(iRegP_R0 ex_oop)
15283 %{
15284   match(Set ex_oop (CreateEx));
15285 
15286   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15287 
15288   size(0);
15289 
15290   ins_encode( /*empty*/ );
15291 
15292   ins_pipe(pipe_class_empty);
15293 %}
15294 
15295 // Rethrow exception: The exception oop will come in the first
15296 // argument position. Then JUMP (not call) to the rethrow stub code.
15297 instruct RethrowException() %{
15298   match(Rethrow);
15299   ins_cost(CALL_COST);
15300 
15301   format %{ &quot;b rethrow_stub&quot; %}
15302 
15303   ins_encode( aarch64_enc_rethrow() );
15304 
15305   ins_pipe(pipe_class_call);
15306 %}
15307 
15308 
15309 // Return Instruction
15310 // epilog node loads ret address into lr as part of frame pop
15311 instruct Ret()
15312 %{
15313   match(Return);
15314 
15315   format %{ &quot;ret\t// return register&quot; %}
15316 
15317   ins_encode( aarch64_enc_ret() );
15318 
15319   ins_pipe(pipe_branch);
15320 %}
15321 
15322 // Die now.
15323 instruct ShouldNotReachHere() %{
15324   match(Halt);
15325 
15326   ins_cost(CALL_COST);
15327   format %{ &quot;ShouldNotReachHere&quot; %}
15328 
15329   ins_encode %{
15330     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15331     // return true
15332     __ dpcs1(0xdead + 1);
15333   %}
15334 
15335   ins_pipe(pipe_class_default);
15336 %}
15337 
15338 // ============================================================================
15339 // Partial Subtype Check
15340 //
15341 // superklass array for an instance of the superklass.  Set a hidden
15342 // internal cache on a hit (cache is checked with exposed code in
15343 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15344 // encoding ALSO sets flags.
15345 
15346 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15347 %{
15348   match(Set result (PartialSubtypeCheck sub super));
15349   effect(KILL cr, KILL temp);
15350 
15351   ins_cost(1100);  // slightly larger than the next version
15352   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15353 
15354   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15355 
15356   opcode(0x1); // Force zero of result reg on hit
15357 
15358   ins_pipe(pipe_class_memory);
15359 %}
15360 
15361 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15362 %{
15363   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15364   effect(KILL temp, KILL result);
15365 
15366   ins_cost(1100);  // slightly larger than the next version
15367   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15368 
15369   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15370 
15371   opcode(0x0); // Don&#39;t zero result reg on hit
15372 
15373   ins_pipe(pipe_class_memory);
15374 %}
15375 
15376 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15377                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15378 %{
15379   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15380   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15381   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15382 
15383   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15384   ins_encode %{
15385     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15386     __ string_compare($str1$$Register, $str2$$Register,
15387                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15388                       $tmp1$$Register, $tmp2$$Register,
15389                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15390   %}
15391   ins_pipe(pipe_class_memory);
15392 %}
15393 
15394 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15395                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15396 %{
15397   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15398   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15399   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15400 
15401   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15402   ins_encode %{
15403     __ string_compare($str1$$Register, $str2$$Register,
15404                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15405                       $tmp1$$Register, $tmp2$$Register,
15406                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15407   %}
15408   ins_pipe(pipe_class_memory);
15409 %}
15410 
15411 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15412                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15413                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15414 %{
15415   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15416   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15417   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15418          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15419 
15420   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15421   ins_encode %{
15422     __ string_compare($str1$$Register, $str2$$Register,
15423                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15424                       $tmp1$$Register, $tmp2$$Register,
15425                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15426                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15427   %}
15428   ins_pipe(pipe_class_memory);
15429 %}
15430 
15431 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15432                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15433                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15434 %{
15435   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15436   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15437   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15438          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15439 
15440   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15441   ins_encode %{
15442     __ string_compare($str1$$Register, $str2$$Register,
15443                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15444                       $tmp1$$Register, $tmp2$$Register,
15445                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15446                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15447   %}
15448   ins_pipe(pipe_class_memory);
15449 %}
15450 
15451 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15452        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15453        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15454 %{
15455   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15456   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15457   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15458          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15459   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15460 
15461   ins_encode %{
15462     __ string_indexof($str1$$Register, $str2$$Register,
15463                       $cnt1$$Register, $cnt2$$Register,
15464                       $tmp1$$Register, $tmp2$$Register,
15465                       $tmp3$$Register, $tmp4$$Register,
15466                       $tmp5$$Register, $tmp6$$Register,
15467                       -1, $result$$Register, StrIntrinsicNode::UU);
15468   %}
15469   ins_pipe(pipe_class_memory);
15470 %}
15471 
15472 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15473        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15474        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15475 %{
15476   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15477   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15478   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15479          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15480   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15481 
15482   ins_encode %{
15483     __ string_indexof($str1$$Register, $str2$$Register,
15484                       $cnt1$$Register, $cnt2$$Register,
15485                       $tmp1$$Register, $tmp2$$Register,
15486                       $tmp3$$Register, $tmp4$$Register,
15487                       $tmp5$$Register, $tmp6$$Register,
15488                       -1, $result$$Register, StrIntrinsicNode::LL);
15489   %}
15490   ins_pipe(pipe_class_memory);
15491 %}
15492 
15493 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15494        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15495        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15496 %{
15497   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15498   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15499   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15500          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15501   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15502 
15503   ins_encode %{
15504     __ string_indexof($str1$$Register, $str2$$Register,
15505                       $cnt1$$Register, $cnt2$$Register,
15506                       $tmp1$$Register, $tmp2$$Register,
15507                       $tmp3$$Register, $tmp4$$Register,
15508                       $tmp5$$Register, $tmp6$$Register,
15509                       -1, $result$$Register, StrIntrinsicNode::UL);
15510   %}
15511   ins_pipe(pipe_class_memory);
15512 %}
15513 
15514 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15515                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15516                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15517 %{
15518   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15519   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15520   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15521          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15522   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15523 
15524   ins_encode %{
15525     int icnt2 = (int)$int_cnt2$$constant;
15526     __ string_indexof($str1$$Register, $str2$$Register,
15527                       $cnt1$$Register, zr,
15528                       $tmp1$$Register, $tmp2$$Register,
15529                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15530                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15531   %}
15532   ins_pipe(pipe_class_memory);
15533 %}
15534 
15535 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15536                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15537                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15538 %{
15539   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15540   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15541   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15542          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15543   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15544 
15545   ins_encode %{
15546     int icnt2 = (int)$int_cnt2$$constant;
15547     __ string_indexof($str1$$Register, $str2$$Register,
15548                       $cnt1$$Register, zr,
15549                       $tmp1$$Register, $tmp2$$Register,
15550                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15551                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15552   %}
15553   ins_pipe(pipe_class_memory);
15554 %}
15555 
15556 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15557                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15558                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15559 %{
15560   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15561   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15562   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15563          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15564   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15565 
15566   ins_encode %{
15567     int icnt2 = (int)$int_cnt2$$constant;
15568     __ string_indexof($str1$$Register, $str2$$Register,
15569                       $cnt1$$Register, zr,
15570                       $tmp1$$Register, $tmp2$$Register,
15571                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15572                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15573   %}
15574   ins_pipe(pipe_class_memory);
15575 %}
15576 
15577 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15578                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15579                               iRegINoSp tmp3, rFlagsReg cr)
15580 %{
15581   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15582   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15583          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15584 
15585   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15586 
15587   ins_encode %{
15588     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15589                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15590                            $tmp3$$Register);
15591   %}
15592   ins_pipe(pipe_class_memory);
15593 %}
15594 
15595 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15596                         iRegI_R0 result, rFlagsReg cr)
15597 %{
15598   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15599   match(Set result (StrEquals (Binary str1 str2) cnt));
15600   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15601 
15602   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15603   ins_encode %{
15604     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15605     __ string_equals($str1$$Register, $str2$$Register,
15606                      $result$$Register, $cnt$$Register, 1);
15607   %}
15608   ins_pipe(pipe_class_memory);
15609 %}
15610 
15611 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15612                         iRegI_R0 result, rFlagsReg cr)
15613 %{
15614   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15615   match(Set result (StrEquals (Binary str1 str2) cnt));
15616   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15617 
15618   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15619   ins_encode %{
15620     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15621     __ string_equals($str1$$Register, $str2$$Register,
15622                      $result$$Register, $cnt$$Register, 2);
15623   %}
15624   ins_pipe(pipe_class_memory);
15625 %}
15626 
15627 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15628                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15629                        iRegP_R10 tmp, rFlagsReg cr)
15630 %{
15631   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15632   match(Set result (AryEq ary1 ary2));
15633   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15634 
15635   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15636   ins_encode %{
15637     __ arrays_equals($ary1$$Register, $ary2$$Register,
15638                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15639                      $result$$Register, $tmp$$Register, 1);
15640     %}
15641   ins_pipe(pipe_class_memory);
15642 %}
15643 
15644 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15645                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15646                        iRegP_R10 tmp, rFlagsReg cr)
15647 %{
15648   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15649   match(Set result (AryEq ary1 ary2));
15650   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15651 
15652   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15653   ins_encode %{
15654     __ arrays_equals($ary1$$Register, $ary2$$Register,
15655                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15656                      $result$$Register, $tmp$$Register, 2);
15657   %}
15658   ins_pipe(pipe_class_memory);
15659 %}
15660 
15661 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15662 %{
15663   match(Set result (HasNegatives ary1 len));
15664   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15665   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15666   ins_encode %{
15667     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15668   %}
15669   ins_pipe( pipe_slow );
15670 %}
15671 
15672 // fast char[] to byte[] compression
15673 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15674                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15675                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15676                          iRegI_R0 result, rFlagsReg cr)
15677 %{
15678   match(Set result (StrCompressedCopy src (Binary dst len)));
15679   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15680 
15681   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15682   ins_encode %{
15683     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15684                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15685                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15686                            $result$$Register);
15687   %}
15688   ins_pipe( pipe_slow );
15689 %}
15690 
15691 // fast byte[] to char[] inflation
15692 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15693                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15694 %{
15695   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15696   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15697 
15698   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15699   ins_encode %{
15700     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15701                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15702   %}
15703   ins_pipe(pipe_class_memory);
15704 %}
15705 
15706 // encode char[] to byte[] in ISO_8859_1
15707 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15708                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15709                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15710                           iRegI_R0 result, rFlagsReg cr)
15711 %{
15712   match(Set result (EncodeISOArray src (Binary dst len)));
15713   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15714          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15715 
15716   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15717   ins_encode %{
15718     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15719          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15720          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15721   %}
15722   ins_pipe( pipe_class_memory );
15723 %}
15724 
15725 // ============================================================================
15726 // This name is KNOWN by the ADLC and cannot be changed.
15727 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15728 // for this guy.
15729 instruct tlsLoadP(thread_RegP dst)
15730 %{
15731   match(Set dst (ThreadLocal));
15732 
15733   ins_cost(0);
15734 
15735   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15736 
15737   size(0);
15738 
15739   ins_encode( /*empty*/ );
15740 
15741   ins_pipe(pipe_class_empty);
15742 %}
15743 
15744 // ====================VECTOR INSTRUCTIONS=====================================
15745 
15746 // Load vector (32 bits)
15747 instruct loadV4(vecD dst, vmem4 mem)
15748 %{
15749   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15750   match(Set dst (LoadVector mem));
15751   ins_cost(4 * INSN_COST);
15752   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15753   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15754   ins_pipe(vload_reg_mem64);
15755 %}
15756 
15757 // Load vector (64 bits)
15758 instruct loadV8(vecD dst, vmem8 mem)
15759 %{
15760   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15761   match(Set dst (LoadVector mem));
15762   ins_cost(4 * INSN_COST);
15763   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15764   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15765   ins_pipe(vload_reg_mem64);
15766 %}
15767 
15768 // Load Vector (128 bits)
15769 instruct loadV16(vecX dst, vmem16 mem)
15770 %{
15771   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15772   match(Set dst (LoadVector mem));
15773   ins_cost(4 * INSN_COST);
15774   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15775   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15776   ins_pipe(vload_reg_mem128);
15777 %}
15778 
15779 // Store Vector (32 bits)
15780 instruct storeV4(vecD src, vmem4 mem)
15781 %{
15782   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15783   match(Set mem (StoreVector mem src));
15784   ins_cost(4 * INSN_COST);
15785   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15786   ins_encode( aarch64_enc_strvS(src, mem) );
15787   ins_pipe(vstore_reg_mem64);
15788 %}
15789 
15790 // Store Vector (64 bits)
15791 instruct storeV8(vecD src, vmem8 mem)
15792 %{
15793   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15794   match(Set mem (StoreVector mem src));
15795   ins_cost(4 * INSN_COST);
15796   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15797   ins_encode( aarch64_enc_strvD(src, mem) );
15798   ins_pipe(vstore_reg_mem64);
15799 %}
15800 
15801 // Store Vector (128 bits)
15802 instruct storeV16(vecX src, vmem16 mem)
15803 %{
15804   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15805   match(Set mem (StoreVector mem src));
15806   ins_cost(4 * INSN_COST);
15807   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15808   ins_encode( aarch64_enc_strvQ(src, mem) );
15809   ins_pipe(vstore_reg_mem128);
15810 %}
15811 
15812 instruct replicate8B(vecD dst, iRegIorL2I src)
15813 %{
15814   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15815             n-&gt;as_Vector()-&gt;length() == 8);
15816   match(Set dst (ReplicateB src));
15817   ins_cost(INSN_COST);
15818   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15819   ins_encode %{
15820     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15821   %}
15822   ins_pipe(vdup_reg_reg64);
15823 %}
15824 
15825 instruct replicate16B(vecX dst, iRegIorL2I src)
15826 %{
15827   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15828   match(Set dst (ReplicateB src));
15829   ins_cost(INSN_COST);
15830   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15831   ins_encode %{
15832     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15833   %}
15834   ins_pipe(vdup_reg_reg128);
15835 %}
15836 
15837 instruct replicate8B_imm(vecD dst, immI con)
15838 %{
15839   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15840             n-&gt;as_Vector()-&gt;length() == 8);
15841   match(Set dst (ReplicateB con));
15842   ins_cost(INSN_COST);
15843   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15844   ins_encode %{
15845     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15846   %}
15847   ins_pipe(vmovi_reg_imm64);
15848 %}
15849 
15850 instruct replicate16B_imm(vecX dst, immI con)
15851 %{
15852   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15853   match(Set dst (ReplicateB con));
15854   ins_cost(INSN_COST);
15855   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15856   ins_encode %{
15857     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15858   %}
15859   ins_pipe(vmovi_reg_imm128);
15860 %}
15861 
15862 instruct replicate4S(vecD dst, iRegIorL2I src)
15863 %{
15864   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15865             n-&gt;as_Vector()-&gt;length() == 4);
15866   match(Set dst (ReplicateS src));
15867   ins_cost(INSN_COST);
15868   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15869   ins_encode %{
15870     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15871   %}
15872   ins_pipe(vdup_reg_reg64);
15873 %}
15874 
15875 instruct replicate8S(vecX dst, iRegIorL2I src)
15876 %{
15877   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15878   match(Set dst (ReplicateS src));
15879   ins_cost(INSN_COST);
15880   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15881   ins_encode %{
15882     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15883   %}
15884   ins_pipe(vdup_reg_reg128);
15885 %}
15886 
15887 instruct replicate4S_imm(vecD dst, immI con)
15888 %{
15889   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15890             n-&gt;as_Vector()-&gt;length() == 4);
15891   match(Set dst (ReplicateS con));
15892   ins_cost(INSN_COST);
15893   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15894   ins_encode %{
15895     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15896   %}
15897   ins_pipe(vmovi_reg_imm64);
15898 %}
15899 
15900 instruct replicate8S_imm(vecX dst, immI con)
15901 %{
15902   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15903   match(Set dst (ReplicateS con));
15904   ins_cost(INSN_COST);
15905   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15906   ins_encode %{
15907     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15908   %}
15909   ins_pipe(vmovi_reg_imm128);
15910 %}
15911 
15912 instruct replicate2I(vecD dst, iRegIorL2I src)
15913 %{
15914   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15915   match(Set dst (ReplicateI src));
15916   ins_cost(INSN_COST);
15917   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15918   ins_encode %{
15919     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15920   %}
15921   ins_pipe(vdup_reg_reg64);
15922 %}
15923 
15924 instruct replicate4I(vecX dst, iRegIorL2I src)
15925 %{
15926   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15927   match(Set dst (ReplicateI src));
15928   ins_cost(INSN_COST);
15929   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15930   ins_encode %{
15931     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15932   %}
15933   ins_pipe(vdup_reg_reg128);
15934 %}
15935 
15936 instruct replicate2I_imm(vecD dst, immI con)
15937 %{
15938   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15939   match(Set dst (ReplicateI con));
15940   ins_cost(INSN_COST);
15941   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15942   ins_encode %{
15943     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15944   %}
15945   ins_pipe(vmovi_reg_imm64);
15946 %}
15947 
15948 instruct replicate4I_imm(vecX dst, immI con)
15949 %{
15950   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15951   match(Set dst (ReplicateI con));
15952   ins_cost(INSN_COST);
15953   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15954   ins_encode %{
15955     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15956   %}
15957   ins_pipe(vmovi_reg_imm128);
15958 %}
15959 
15960 instruct replicate2L(vecX dst, iRegL src)
15961 %{
15962   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15963   match(Set dst (ReplicateL src));
15964   ins_cost(INSN_COST);
15965   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15966   ins_encode %{
15967     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15968   %}
15969   ins_pipe(vdup_reg_reg128);
15970 %}
15971 
15972 instruct replicate2L_zero(vecX dst, immI0 zero)
15973 %{
15974   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15975   match(Set dst (ReplicateI zero));
15976   ins_cost(INSN_COST);
15977   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15978   ins_encode %{
15979     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15980            as_FloatRegister($dst$$reg),
15981            as_FloatRegister($dst$$reg));
15982   %}
15983   ins_pipe(vmovi_reg_imm128);
15984 %}
15985 
15986 instruct replicate2F(vecD dst, vRegF src)
15987 %{
15988   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15989   match(Set dst (ReplicateF src));
15990   ins_cost(INSN_COST);
15991   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15992   ins_encode %{
15993     __ dup(as_FloatRegister($dst$$reg), __ T2S,
15994            as_FloatRegister($src$$reg));
15995   %}
15996   ins_pipe(vdup_reg_freg64);
15997 %}
15998 
15999 instruct replicate4F(vecX dst, vRegF src)
16000 %{
16001   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16002   match(Set dst (ReplicateF src));
16003   ins_cost(INSN_COST);
16004   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16005   ins_encode %{
16006     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16007            as_FloatRegister($src$$reg));
16008   %}
16009   ins_pipe(vdup_reg_freg128);
16010 %}
16011 
16012 instruct replicate2D(vecX dst, vRegD src)
16013 %{
16014   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16015   match(Set dst (ReplicateD src));
16016   ins_cost(INSN_COST);
16017   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16018   ins_encode %{
16019     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16020            as_FloatRegister($src$$reg));
16021   %}
16022   ins_pipe(vdup_reg_dreg128);
16023 %}
16024 
16025 // ====================REDUCTION ARITHMETIC====================================
16026 
16027 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16028 %{
16029   match(Set dst (AddReductionVI src1 src2));
16030   ins_cost(INSN_COST);
16031   effect(TEMP tmp, TEMP tmp2);
16032   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16033             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
16034             &quot;addw  $dst, $src1, $tmp\n\t&quot;
16035             &quot;addw  $dst, $dst, $tmp2\t add reduction2i&quot;
16036   %}
16037   ins_encode %{
16038     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16039     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16040     __ addw($dst$$Register, $src1$$Register, $tmp$$Register);
16041     __ addw($dst$$Register, $dst$$Register, $tmp2$$Register);
16042   %}
16043   ins_pipe(pipe_class_default);
16044 %}
16045 
16046 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16047 %{
16048   match(Set dst (AddReductionVI src1 src2));
16049   ins_cost(INSN_COST);
16050   effect(TEMP tmp, TEMP tmp2);
16051   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16052             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16053             &quot;addw  $dst, $tmp2, $src1\t add reduction4i&quot;
16054   %}
16055   ins_encode %{
16056     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16057             as_FloatRegister($src2$$reg));
16058     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16059     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16060   %}
16061   ins_pipe(pipe_class_default);
16062 %}
16063 
16064 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16065 %{
16066   match(Set dst (MulReductionVI src1 src2));
16067   ins_cost(INSN_COST);
16068   effect(TEMP tmp, TEMP dst);
16069   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16070             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16071             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
16072             &quot;mul   $dst, $tmp, $dst\t mul reduction2i\n\t&quot;
16073   %}
16074   ins_encode %{
16075     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16076     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16077     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16078     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16079   %}
16080   ins_pipe(pipe_class_default);
16081 %}
16082 
16083 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16084 %{
16085   match(Set dst (MulReductionVI src1 src2));
16086   ins_cost(INSN_COST);
16087   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16088   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16089             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16090             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16091             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16092             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
16093             &quot;mul   $dst, $tmp2, $dst\t mul reduction4i\n\t&quot;
16094   %}
16095   ins_encode %{
16096     __ ins(as_FloatRegister($tmp$$reg), __ D,
16097            as_FloatRegister($src2$$reg), 0, 1);
16098     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16099            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16100     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16101     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16102     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16103     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16104   %}
16105   ins_pipe(pipe_class_default);
16106 %}
16107 
16108 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16109 %{
16110   match(Set dst (AddReductionVF src1 src2));
16111   ins_cost(INSN_COST);
16112   effect(TEMP tmp, TEMP dst);
16113   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16114             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16115             &quot;fadds $dst, $dst, $tmp\t add reduction2f&quot;
16116   %}
16117   ins_encode %{
16118     __ fadds(as_FloatRegister($dst$$reg),
16119              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16120     __ ins(as_FloatRegister($tmp$$reg), __ S,
16121            as_FloatRegister($src2$$reg), 0, 1);
16122     __ fadds(as_FloatRegister($dst$$reg),
16123              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16124   %}
16125   ins_pipe(pipe_class_default);
16126 %}
16127 
16128 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16129 %{
16130   match(Set dst (AddReductionVF src1 src2));
16131   ins_cost(INSN_COST);
16132   effect(TEMP tmp, TEMP dst);
16133   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16134             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16135             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16136             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16137             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16138             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16139             &quot;fadds $dst, $dst, $tmp\t add reduction4f&quot;
16140   %}
16141   ins_encode %{
16142     __ fadds(as_FloatRegister($dst$$reg),
16143              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16144     __ ins(as_FloatRegister($tmp$$reg), __ S,
16145            as_FloatRegister($src2$$reg), 0, 1);
16146     __ fadds(as_FloatRegister($dst$$reg),
16147              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16148     __ ins(as_FloatRegister($tmp$$reg), __ S,
16149            as_FloatRegister($src2$$reg), 0, 2);
16150     __ fadds(as_FloatRegister($dst$$reg),
16151              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16152     __ ins(as_FloatRegister($tmp$$reg), __ S,
16153            as_FloatRegister($src2$$reg), 0, 3);
16154     __ fadds(as_FloatRegister($dst$$reg),
16155              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16156   %}
16157   ins_pipe(pipe_class_default);
16158 %}
16159 
16160 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16161 %{
16162   match(Set dst (MulReductionVF src1 src2));
16163   ins_cost(INSN_COST);
16164   effect(TEMP tmp, TEMP dst);
16165   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16166             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16167             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16168   %}
16169   ins_encode %{
16170     __ fmuls(as_FloatRegister($dst$$reg),
16171              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16172     __ ins(as_FloatRegister($tmp$$reg), __ S,
16173            as_FloatRegister($src2$$reg), 0, 1);
16174     __ fmuls(as_FloatRegister($dst$$reg),
16175              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16176   %}
16177   ins_pipe(pipe_class_default);
16178 %}
16179 
16180 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16181 %{
16182   match(Set dst (MulReductionVF src1 src2));
16183   ins_cost(INSN_COST);
16184   effect(TEMP tmp, TEMP dst);
16185   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16186             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16187             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16188             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16189             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16190             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16191             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16192   %}
16193   ins_encode %{
16194     __ fmuls(as_FloatRegister($dst$$reg),
16195              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16196     __ ins(as_FloatRegister($tmp$$reg), __ S,
16197            as_FloatRegister($src2$$reg), 0, 1);
16198     __ fmuls(as_FloatRegister($dst$$reg),
16199              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16200     __ ins(as_FloatRegister($tmp$$reg), __ S,
16201            as_FloatRegister($src2$$reg), 0, 2);
16202     __ fmuls(as_FloatRegister($dst$$reg),
16203              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16204     __ ins(as_FloatRegister($tmp$$reg), __ S,
16205            as_FloatRegister($src2$$reg), 0, 3);
16206     __ fmuls(as_FloatRegister($dst$$reg),
16207              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16208   %}
16209   ins_pipe(pipe_class_default);
16210 %}
16211 
16212 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16213 %{
16214   match(Set dst (AddReductionVD src1 src2));
16215   ins_cost(INSN_COST);
16216   effect(TEMP tmp, TEMP dst);
16217   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16218             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16219             &quot;faddd $dst, $dst, $tmp\t add reduction2d&quot;
16220   %}
16221   ins_encode %{
16222     __ faddd(as_FloatRegister($dst$$reg),
16223              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16224     __ ins(as_FloatRegister($tmp$$reg), __ D,
16225            as_FloatRegister($src2$$reg), 0, 1);
16226     __ faddd(as_FloatRegister($dst$$reg),
16227              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16228   %}
16229   ins_pipe(pipe_class_default);
16230 %}
16231 
16232 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16233 %{
16234   match(Set dst (MulReductionVD src1 src2));
16235   ins_cost(INSN_COST);
16236   effect(TEMP tmp, TEMP dst);
16237   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16238             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16239             &quot;fmuld $dst, $dst, $tmp\t add reduction2d&quot;
16240   %}
16241   ins_encode %{
16242     __ fmuld(as_FloatRegister($dst$$reg),
16243              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16244     __ ins(as_FloatRegister($tmp$$reg), __ D,
16245            as_FloatRegister($src2$$reg), 0, 1);
16246     __ fmuld(as_FloatRegister($dst$$reg),
16247              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16248   %}
16249   ins_pipe(pipe_class_default);
16250 %}
16251 
16252 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16253   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16254   match(Set dst (MaxReductionV src1 src2));
16255   ins_cost(INSN_COST);
16256   effect(TEMP_DEF dst, TEMP tmp);
16257   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16258             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16259             &quot;fmaxs $dst, $dst, $tmp\t max reduction2F&quot; %}
16260   ins_encode %{
16261     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16262     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16263     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16264   %}
16265   ins_pipe(pipe_class_default);
16266 %}
16267 
16268 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16269   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16270   match(Set dst (MaxReductionV src1 src2));
16271   ins_cost(INSN_COST);
16272   effect(TEMP_DEF dst);
16273   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
16274             &quot;fmaxs $dst, $dst, $src1\t max reduction4F&quot; %}
16275   ins_encode %{
16276     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16277     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16278   %}
16279   ins_pipe(pipe_class_default);
16280 %}
16281 
16282 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16283   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16284   match(Set dst (MaxReductionV src1 src2));
16285   ins_cost(INSN_COST);
16286   effect(TEMP_DEF dst, TEMP tmp);
16287   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16288             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16289             &quot;fmaxd $dst, $dst, $tmp\t max reduction2D&quot; %}
16290   ins_encode %{
16291     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16292     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16293     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16294   %}
16295   ins_pipe(pipe_class_default);
16296 %}
16297 
16298 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16299   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16300   match(Set dst (MinReductionV src1 src2));
16301   ins_cost(INSN_COST);
16302   effect(TEMP_DEF dst, TEMP tmp);
16303   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16304             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16305             &quot;fmins $dst, $dst, $tmp\t min reduction2F&quot; %}
16306   ins_encode %{
16307     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16308     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16309     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16310   %}
16311   ins_pipe(pipe_class_default);
16312 %}
16313 
16314 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16315   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16316   match(Set dst (MinReductionV src1 src2));
16317   ins_cost(INSN_COST);
16318   effect(TEMP_DEF dst);
16319   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
16320             &quot;fmins $dst, $dst, $src1\t min reduction4F&quot; %}
16321   ins_encode %{
16322     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16323     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16324   %}
16325   ins_pipe(pipe_class_default);
16326 %}
16327 
16328 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16329   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16330   match(Set dst (MinReductionV src1 src2));
16331   ins_cost(INSN_COST);
16332   effect(TEMP_DEF dst, TEMP tmp);
16333   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16334             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16335             &quot;fmind $dst, $dst, $tmp\t min reduction2D&quot; %}
16336   ins_encode %{
16337     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16338     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16339     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16340   %}
16341   ins_pipe(pipe_class_default);
16342 %}
16343 
16344 // ====================VECTOR ARITHMETIC=======================================
16345 
16346 // --------------------------------- ADD --------------------------------------
16347 
16348 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16349 %{
16350   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16351             n-&gt;as_Vector()-&gt;length() == 8);
16352   match(Set dst (AddVB src1 src2));
16353   ins_cost(INSN_COST);
16354   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16355   ins_encode %{
16356     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16357             as_FloatRegister($src1$$reg),
16358             as_FloatRegister($src2$$reg));
16359   %}
16360   ins_pipe(vdop64);
16361 %}
16362 
16363 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16364 %{
16365   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16366   match(Set dst (AddVB src1 src2));
16367   ins_cost(INSN_COST);
16368   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16369   ins_encode %{
16370     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16371             as_FloatRegister($src1$$reg),
16372             as_FloatRegister($src2$$reg));
16373   %}
16374   ins_pipe(vdop128);
16375 %}
16376 
16377 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16378 %{
16379   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16380             n-&gt;as_Vector()-&gt;length() == 4);
16381   match(Set dst (AddVS src1 src2));
16382   ins_cost(INSN_COST);
16383   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16384   ins_encode %{
16385     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16386             as_FloatRegister($src1$$reg),
16387             as_FloatRegister($src2$$reg));
16388   %}
16389   ins_pipe(vdop64);
16390 %}
16391 
16392 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16393 %{
16394   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16395   match(Set dst (AddVS src1 src2));
16396   ins_cost(INSN_COST);
16397   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16398   ins_encode %{
16399     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16400             as_FloatRegister($src1$$reg),
16401             as_FloatRegister($src2$$reg));
16402   %}
16403   ins_pipe(vdop128);
16404 %}
16405 
16406 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16407 %{
16408   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16409   match(Set dst (AddVI src1 src2));
16410   ins_cost(INSN_COST);
16411   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16412   ins_encode %{
16413     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16414             as_FloatRegister($src1$$reg),
16415             as_FloatRegister($src2$$reg));
16416   %}
16417   ins_pipe(vdop64);
16418 %}
16419 
16420 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16421 %{
16422   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16423   match(Set dst (AddVI src1 src2));
16424   ins_cost(INSN_COST);
16425   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16426   ins_encode %{
16427     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16428             as_FloatRegister($src1$$reg),
16429             as_FloatRegister($src2$$reg));
16430   %}
16431   ins_pipe(vdop128);
16432 %}
16433 
16434 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16435 %{
16436   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16437   match(Set dst (AddVL src1 src2));
16438   ins_cost(INSN_COST);
16439   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16440   ins_encode %{
16441     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16442             as_FloatRegister($src1$$reg),
16443             as_FloatRegister($src2$$reg));
16444   %}
16445   ins_pipe(vdop128);
16446 %}
16447 
16448 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16449 %{
16450   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16451   match(Set dst (AddVF src1 src2));
16452   ins_cost(INSN_COST);
16453   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16454   ins_encode %{
16455     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16456             as_FloatRegister($src1$$reg),
16457             as_FloatRegister($src2$$reg));
16458   %}
16459   ins_pipe(vdop_fp64);
16460 %}
16461 
16462 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16463 %{
16464   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16465   match(Set dst (AddVF src1 src2));
16466   ins_cost(INSN_COST);
16467   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16468   ins_encode %{
16469     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16470             as_FloatRegister($src1$$reg),
16471             as_FloatRegister($src2$$reg));
16472   %}
16473   ins_pipe(vdop_fp128);
16474 %}
16475 
16476 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16477 %{
16478   match(Set dst (AddVD src1 src2));
16479   ins_cost(INSN_COST);
16480   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16481   ins_encode %{
16482     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16483             as_FloatRegister($src1$$reg),
16484             as_FloatRegister($src2$$reg));
16485   %}
16486   ins_pipe(vdop_fp128);
16487 %}
16488 
16489 // --------------------------------- SUB --------------------------------------
16490 
16491 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16492 %{
16493   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16494             n-&gt;as_Vector()-&gt;length() == 8);
16495   match(Set dst (SubVB src1 src2));
16496   ins_cost(INSN_COST);
16497   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16498   ins_encode %{
16499     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16500             as_FloatRegister($src1$$reg),
16501             as_FloatRegister($src2$$reg));
16502   %}
16503   ins_pipe(vdop64);
16504 %}
16505 
16506 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16507 %{
16508   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16509   match(Set dst (SubVB src1 src2));
16510   ins_cost(INSN_COST);
16511   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16512   ins_encode %{
16513     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16514             as_FloatRegister($src1$$reg),
16515             as_FloatRegister($src2$$reg));
16516   %}
16517   ins_pipe(vdop128);
16518 %}
16519 
16520 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16521 %{
16522   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16523             n-&gt;as_Vector()-&gt;length() == 4);
16524   match(Set dst (SubVS src1 src2));
16525   ins_cost(INSN_COST);
16526   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16527   ins_encode %{
16528     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16529             as_FloatRegister($src1$$reg),
16530             as_FloatRegister($src2$$reg));
16531   %}
16532   ins_pipe(vdop64);
16533 %}
16534 
16535 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16536 %{
16537   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16538   match(Set dst (SubVS src1 src2));
16539   ins_cost(INSN_COST);
16540   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16541   ins_encode %{
16542     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16543             as_FloatRegister($src1$$reg),
16544             as_FloatRegister($src2$$reg));
16545   %}
16546   ins_pipe(vdop128);
16547 %}
16548 
16549 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16550 %{
16551   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16552   match(Set dst (SubVI src1 src2));
16553   ins_cost(INSN_COST);
16554   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16555   ins_encode %{
16556     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16557             as_FloatRegister($src1$$reg),
16558             as_FloatRegister($src2$$reg));
16559   %}
16560   ins_pipe(vdop64);
16561 %}
16562 
16563 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16564 %{
16565   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16566   match(Set dst (SubVI src1 src2));
16567   ins_cost(INSN_COST);
16568   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16569   ins_encode %{
16570     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16571             as_FloatRegister($src1$$reg),
16572             as_FloatRegister($src2$$reg));
16573   %}
16574   ins_pipe(vdop128);
16575 %}
16576 
16577 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16578 %{
16579   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16580   match(Set dst (SubVL src1 src2));
16581   ins_cost(INSN_COST);
16582   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16583   ins_encode %{
16584     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16585             as_FloatRegister($src1$$reg),
16586             as_FloatRegister($src2$$reg));
16587   %}
16588   ins_pipe(vdop128);
16589 %}
16590 
16591 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16592 %{
16593   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16594   match(Set dst (SubVF src1 src2));
16595   ins_cost(INSN_COST);
16596   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16597   ins_encode %{
16598     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16599             as_FloatRegister($src1$$reg),
16600             as_FloatRegister($src2$$reg));
16601   %}
16602   ins_pipe(vdop_fp64);
16603 %}
16604 
16605 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16606 %{
16607   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16608   match(Set dst (SubVF src1 src2));
16609   ins_cost(INSN_COST);
16610   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16611   ins_encode %{
16612     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16613             as_FloatRegister($src1$$reg),
16614             as_FloatRegister($src2$$reg));
16615   %}
16616   ins_pipe(vdop_fp128);
16617 %}
16618 
16619 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16620 %{
16621   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16622   match(Set dst (SubVD src1 src2));
16623   ins_cost(INSN_COST);
16624   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16625   ins_encode %{
16626     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16627             as_FloatRegister($src1$$reg),
16628             as_FloatRegister($src2$$reg));
16629   %}
16630   ins_pipe(vdop_fp128);
16631 %}
16632 
16633 // --------------------------------- MUL --------------------------------------
16634 
16635 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16636 %{
16637   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16638             n-&gt;as_Vector()-&gt;length() == 4);
16639   match(Set dst (MulVS src1 src2));
16640   ins_cost(INSN_COST);
16641   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16642   ins_encode %{
16643     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16644             as_FloatRegister($src1$$reg),
16645             as_FloatRegister($src2$$reg));
16646   %}
16647   ins_pipe(vmul64);
16648 %}
16649 
16650 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16651 %{
16652   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16653   match(Set dst (MulVS src1 src2));
16654   ins_cost(INSN_COST);
16655   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16656   ins_encode %{
16657     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16658             as_FloatRegister($src1$$reg),
16659             as_FloatRegister($src2$$reg));
16660   %}
16661   ins_pipe(vmul128);
16662 %}
16663 
16664 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16665 %{
16666   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16667   match(Set dst (MulVI src1 src2));
16668   ins_cost(INSN_COST);
16669   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16670   ins_encode %{
16671     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16672             as_FloatRegister($src1$$reg),
16673             as_FloatRegister($src2$$reg));
16674   %}
16675   ins_pipe(vmul64);
16676 %}
16677 
16678 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16679 %{
16680   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16681   match(Set dst (MulVI src1 src2));
16682   ins_cost(INSN_COST);
16683   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16684   ins_encode %{
16685     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16686             as_FloatRegister($src1$$reg),
16687             as_FloatRegister($src2$$reg));
16688   %}
16689   ins_pipe(vmul128);
16690 %}
16691 
16692 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16693 %{
16694   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16695   match(Set dst (MulVF src1 src2));
16696   ins_cost(INSN_COST);
16697   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16698   ins_encode %{
16699     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16700             as_FloatRegister($src1$$reg),
16701             as_FloatRegister($src2$$reg));
16702   %}
16703   ins_pipe(vmuldiv_fp64);
16704 %}
16705 
16706 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16707 %{
16708   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16709   match(Set dst (MulVF src1 src2));
16710   ins_cost(INSN_COST);
16711   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16712   ins_encode %{
16713     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16714             as_FloatRegister($src1$$reg),
16715             as_FloatRegister($src2$$reg));
16716   %}
16717   ins_pipe(vmuldiv_fp128);
16718 %}
16719 
16720 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16721 %{
16722   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16723   match(Set dst (MulVD src1 src2));
16724   ins_cost(INSN_COST);
16725   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16726   ins_encode %{
16727     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16728             as_FloatRegister($src1$$reg),
16729             as_FloatRegister($src2$$reg));
16730   %}
16731   ins_pipe(vmuldiv_fp128);
16732 %}
16733 
16734 // --------------------------------- MLA --------------------------------------
16735 
16736 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16737 %{
16738   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16739             n-&gt;as_Vector()-&gt;length() == 4);
16740   match(Set dst (AddVS dst (MulVS src1 src2)));
16741   ins_cost(INSN_COST);
16742   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16743   ins_encode %{
16744     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16745             as_FloatRegister($src1$$reg),
16746             as_FloatRegister($src2$$reg));
16747   %}
16748   ins_pipe(vmla64);
16749 %}
16750 
16751 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16752 %{
16753   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16754   match(Set dst (AddVS dst (MulVS src1 src2)));
16755   ins_cost(INSN_COST);
16756   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16757   ins_encode %{
16758     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16759             as_FloatRegister($src1$$reg),
16760             as_FloatRegister($src2$$reg));
16761   %}
16762   ins_pipe(vmla128);
16763 %}
16764 
16765 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16766 %{
16767   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16768   match(Set dst (AddVI dst (MulVI src1 src2)));
16769   ins_cost(INSN_COST);
16770   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16771   ins_encode %{
16772     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16773             as_FloatRegister($src1$$reg),
16774             as_FloatRegister($src2$$reg));
16775   %}
16776   ins_pipe(vmla64);
16777 %}
16778 
16779 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16780 %{
16781   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16782   match(Set dst (AddVI dst (MulVI src1 src2)));
16783   ins_cost(INSN_COST);
16784   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16785   ins_encode %{
16786     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16787             as_FloatRegister($src1$$reg),
16788             as_FloatRegister($src2$$reg));
16789   %}
16790   ins_pipe(vmla128);
16791 %}
16792 
16793 // dst + src1 * src2
16794 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16795   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16796   match(Set dst (FmaVF  dst (Binary src1 src2)));
16797   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16798   ins_cost(INSN_COST);
16799   ins_encode %{
16800     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16801             as_FloatRegister($src1$$reg),
16802             as_FloatRegister($src2$$reg));
16803   %}
16804   ins_pipe(vmuldiv_fp64);
16805 %}
16806 
16807 // dst + src1 * src2
16808 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16809   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16810   match(Set dst (FmaVF  dst (Binary src1 src2)));
16811   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16812   ins_cost(INSN_COST);
16813   ins_encode %{
16814     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16815             as_FloatRegister($src1$$reg),
16816             as_FloatRegister($src2$$reg));
16817   %}
16818   ins_pipe(vmuldiv_fp128);
16819 %}
16820 
16821 // dst + src1 * src2
16822 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16823   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16824   match(Set dst (FmaVD  dst (Binary src1 src2)));
16825   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16826   ins_cost(INSN_COST);
16827   ins_encode %{
16828     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16829             as_FloatRegister($src1$$reg),
16830             as_FloatRegister($src2$$reg));
16831   %}
16832   ins_pipe(vmuldiv_fp128);
16833 %}
16834 
16835 // --------------------------------- MLS --------------------------------------
16836 
16837 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16838 %{
16839   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16840             n-&gt;as_Vector()-&gt;length() == 4);
16841   match(Set dst (SubVS dst (MulVS src1 src2)));
16842   ins_cost(INSN_COST);
16843   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16844   ins_encode %{
16845     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16846             as_FloatRegister($src1$$reg),
16847             as_FloatRegister($src2$$reg));
16848   %}
16849   ins_pipe(vmla64);
16850 %}
16851 
16852 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16853 %{
16854   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16855   match(Set dst (SubVS dst (MulVS src1 src2)));
16856   ins_cost(INSN_COST);
16857   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16858   ins_encode %{
16859     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16860             as_FloatRegister($src1$$reg),
16861             as_FloatRegister($src2$$reg));
16862   %}
16863   ins_pipe(vmla128);
16864 %}
16865 
16866 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16867 %{
16868   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16869   match(Set dst (SubVI dst (MulVI src1 src2)));
16870   ins_cost(INSN_COST);
16871   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16872   ins_encode %{
16873     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16874             as_FloatRegister($src1$$reg),
16875             as_FloatRegister($src2$$reg));
16876   %}
16877   ins_pipe(vmla64);
16878 %}
16879 
16880 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16881 %{
16882   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16883   match(Set dst (SubVI dst (MulVI src1 src2)));
16884   ins_cost(INSN_COST);
16885   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16886   ins_encode %{
16887     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16888             as_FloatRegister($src1$$reg),
16889             as_FloatRegister($src2$$reg));
16890   %}
16891   ins_pipe(vmla128);
16892 %}
16893 
16894 // dst - src1 * src2
16895 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16896   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16897   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16898   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16899   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16900   ins_cost(INSN_COST);
16901   ins_encode %{
16902     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16903             as_FloatRegister($src1$$reg),
16904             as_FloatRegister($src2$$reg));
16905   %}
16906   ins_pipe(vmuldiv_fp64);
16907 %}
16908 
16909 // dst - src1 * src2
16910 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16911   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16912   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16913   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16914   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16915   ins_cost(INSN_COST);
16916   ins_encode %{
16917     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16918             as_FloatRegister($src1$$reg),
16919             as_FloatRegister($src2$$reg));
16920   %}
16921   ins_pipe(vmuldiv_fp128);
16922 %}
16923 
16924 // dst - src1 * src2
16925 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16926   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16927   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16928   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16929   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16930   ins_cost(INSN_COST);
16931   ins_encode %{
16932     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16933             as_FloatRegister($src1$$reg),
16934             as_FloatRegister($src2$$reg));
16935   %}
16936   ins_pipe(vmuldiv_fp128);
16937 %}
16938 
16939 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16940 
16941 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16942   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16943   match(Set dst (MulAddVS2VI src1 src2));
16944   ins_cost(INSN_COST);
16945   effect(TEMP_DEF dst, TEMP tmp);
16946   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16947             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16948             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16949   ins_encode %{
16950     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16951               as_FloatRegister($src1$$reg),
16952               as_FloatRegister($src2$$reg));
16953     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16954               as_FloatRegister($src1$$reg),
16955               as_FloatRegister($src2$$reg));
16956     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16957              as_FloatRegister($tmp$$reg),
16958              as_FloatRegister($dst$$reg));
16959   %}
16960   ins_pipe(vmuldiv_fp128);
16961 %}
16962 
16963 // --------------------------------- DIV --------------------------------------
16964 
16965 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16966 %{
16967   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16968   match(Set dst (DivVF src1 src2));
16969   ins_cost(INSN_COST);
16970   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16971   ins_encode %{
16972     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16973             as_FloatRegister($src1$$reg),
16974             as_FloatRegister($src2$$reg));
16975   %}
16976   ins_pipe(vmuldiv_fp64);
16977 %}
16978 
16979 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
16980 %{
16981   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16982   match(Set dst (DivVF src1 src2));
16983   ins_cost(INSN_COST);
16984   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16985   ins_encode %{
16986     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
16987             as_FloatRegister($src1$$reg),
16988             as_FloatRegister($src2$$reg));
16989   %}
16990   ins_pipe(vmuldiv_fp128);
16991 %}
16992 
16993 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
16994 %{
16995   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16996   match(Set dst (DivVD src1 src2));
16997   ins_cost(INSN_COST);
16998   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
16999   ins_encode %{
17000     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17001             as_FloatRegister($src1$$reg),
17002             as_FloatRegister($src2$$reg));
17003   %}
17004   ins_pipe(vmuldiv_fp128);
17005 %}
17006 
17007 // --------------------------------- SQRT -------------------------------------
17008 
17009 instruct vsqrt2D(vecX dst, vecX src)
17010 %{
17011   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17012   match(Set dst (SqrtVD src));
17013   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17014   ins_encode %{
17015     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17016              as_FloatRegister($src$$reg));
17017   %}
17018   ins_pipe(vsqrt_fp128);
17019 %}
17020 
17021 // --------------------------------- ABS --------------------------------------
17022 
17023 instruct vabs2F(vecD dst, vecD src)
17024 %{
17025   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17026   match(Set dst (AbsVF src));
17027   ins_cost(INSN_COST * 3);
17028   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17029   ins_encode %{
17030     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17031             as_FloatRegister($src$$reg));
17032   %}
17033   ins_pipe(vunop_fp64);
17034 %}
17035 
17036 instruct vabs4F(vecX dst, vecX src)
17037 %{
17038   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17039   match(Set dst (AbsVF src));
17040   ins_cost(INSN_COST * 3);
17041   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17042   ins_encode %{
17043     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17044             as_FloatRegister($src$$reg));
17045   %}
17046   ins_pipe(vunop_fp128);
17047 %}
17048 
17049 instruct vabs2D(vecX dst, vecX src)
17050 %{
17051   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17052   match(Set dst (AbsVD src));
17053   ins_cost(INSN_COST * 3);
17054   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17055   ins_encode %{
17056     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17057             as_FloatRegister($src$$reg));
17058   %}
17059   ins_pipe(vunop_fp128);
17060 %}
17061 
17062 // --------------------------------- NEG --------------------------------------
17063 
17064 instruct vneg2F(vecD dst, vecD src)
17065 %{
17066   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17067   match(Set dst (NegVF src));
17068   ins_cost(INSN_COST * 3);
17069   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17070   ins_encode %{
17071     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17072             as_FloatRegister($src$$reg));
17073   %}
17074   ins_pipe(vunop_fp64);
17075 %}
17076 
17077 instruct vneg4F(vecX dst, vecX src)
17078 %{
17079   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17080   match(Set dst (NegVF src));
17081   ins_cost(INSN_COST * 3);
17082   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17083   ins_encode %{
17084     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17085             as_FloatRegister($src$$reg));
17086   %}
17087   ins_pipe(vunop_fp128);
17088 %}
17089 
17090 instruct vneg2D(vecX dst, vecX src)
17091 %{
17092   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17093   match(Set dst (NegVD src));
17094   ins_cost(INSN_COST * 3);
17095   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17096   ins_encode %{
17097     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17098             as_FloatRegister($src$$reg));
17099   %}
17100   ins_pipe(vunop_fp128);
17101 %}
17102 
17103 // --------------------------------- AND --------------------------------------
17104 
17105 instruct vand8B(vecD dst, vecD src1, vecD src2)
17106 %{
17107   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17108             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17109   match(Set dst (AndV src1 src2));
17110   ins_cost(INSN_COST);
17111   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17112   ins_encode %{
17113     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17114             as_FloatRegister($src1$$reg),
17115             as_FloatRegister($src2$$reg));
17116   %}
17117   ins_pipe(vlogical64);
17118 %}
17119 
17120 instruct vand16B(vecX dst, vecX src1, vecX src2)
17121 %{
17122   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17123   match(Set dst (AndV src1 src2));
17124   ins_cost(INSN_COST);
17125   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17126   ins_encode %{
17127     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17128             as_FloatRegister($src1$$reg),
17129             as_FloatRegister($src2$$reg));
17130   %}
17131   ins_pipe(vlogical128);
17132 %}
17133 
17134 // --------------------------------- OR ---------------------------------------
17135 
17136 instruct vor8B(vecD dst, vecD src1, vecD src2)
17137 %{
17138   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17139             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17140   match(Set dst (OrV src1 src2));
17141   ins_cost(INSN_COST);
17142   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17143   ins_encode %{
17144     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17145             as_FloatRegister($src1$$reg),
17146             as_FloatRegister($src2$$reg));
17147   %}
17148   ins_pipe(vlogical64);
17149 %}
17150 
17151 instruct vor16B(vecX dst, vecX src1, vecX src2)
17152 %{
17153   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17154   match(Set dst (OrV src1 src2));
17155   ins_cost(INSN_COST);
17156   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17157   ins_encode %{
17158     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17159             as_FloatRegister($src1$$reg),
17160             as_FloatRegister($src2$$reg));
17161   %}
17162   ins_pipe(vlogical128);
17163 %}
17164 
17165 // --------------------------------- XOR --------------------------------------
17166 
17167 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17168 %{
17169   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17170             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17171   match(Set dst (XorV src1 src2));
17172   ins_cost(INSN_COST);
17173   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17174   ins_encode %{
17175     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17176             as_FloatRegister($src1$$reg),
17177             as_FloatRegister($src2$$reg));
17178   %}
17179   ins_pipe(vlogical64);
17180 %}
17181 
17182 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17183 %{
17184   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17185   match(Set dst (XorV src1 src2));
17186   ins_cost(INSN_COST);
17187   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17188   ins_encode %{
17189     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17190             as_FloatRegister($src1$$reg),
17191             as_FloatRegister($src2$$reg));
17192   %}
17193   ins_pipe(vlogical128);
17194 %}
17195 
17196 // ------------------------------ Shift ---------------------------------------
17197 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17198   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17199   match(Set dst (LShiftCntV cnt));
17200   match(Set dst (RShiftCntV cnt));
17201   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17202   ins_encode %{
17203     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17204   %}
17205   ins_pipe(vdup_reg_reg64);
17206 %}
17207 
17208 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17209   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17210   match(Set dst (LShiftCntV cnt));
17211   match(Set dst (RShiftCntV cnt));
17212   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17213   ins_encode %{
17214     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17215   %}
17216   ins_pipe(vdup_reg_reg128);
17217 %}
17218 
17219 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17220   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17221             n-&gt;as_Vector()-&gt;length() == 8);
17222   match(Set dst (LShiftVB src shift));
17223   ins_cost(INSN_COST);
17224   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17225   ins_encode %{
17226     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17227             as_FloatRegister($src$$reg),
17228             as_FloatRegister($shift$$reg));
17229   %}
17230   ins_pipe(vshift64);
17231 %}
17232 
17233 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17234   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17235   match(Set dst (LShiftVB src shift));
17236   ins_cost(INSN_COST);
17237   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17238   ins_encode %{
17239     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17240             as_FloatRegister($src$$reg),
17241             as_FloatRegister($shift$$reg));
17242   %}
17243   ins_pipe(vshift128);
17244 %}
17245 
17246 // Right shifts with vector shift count on aarch64 SIMD are implemented
17247 // as left shift by negative shift count.
17248 // There are two cases for vector shift count.
17249 //
17250 // Case 1: The vector shift count is from replication.
17251 //        |            |
17252 //    LoadVector  RShiftCntV
17253 //        |       /
17254 //     RShiftVI
17255 // Note: In inner loop, multiple neg instructions are used, which can be
17256 // moved to outer loop and merge into one neg instruction.
17257 //
17258 // Case 2: The vector shift count is from loading.
17259 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17260 // panama/vectorIntrinsics(JEP 338: Vector API).
17261 //        |            |
17262 //    LoadVector  LoadVector
17263 //        |       /
17264 //     RShiftVI
17265 //
17266 
17267 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17268   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17269             n-&gt;as_Vector()-&gt;length() == 8);
17270   match(Set dst (RShiftVB src shift));
17271   ins_cost(INSN_COST);
17272   effect(TEMP tmp);
17273   format %{ &quot;negr  $tmp,$shift\t&quot;
17274             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17275   ins_encode %{
17276     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17277             as_FloatRegister($shift$$reg));
17278     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17279             as_FloatRegister($src$$reg),
17280             as_FloatRegister($tmp$$reg));
17281   %}
17282   ins_pipe(vshift64);
17283 %}
17284 
17285 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17286   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17287   match(Set dst (RShiftVB src shift));
17288   ins_cost(INSN_COST);
17289   effect(TEMP tmp);
17290   format %{ &quot;negr  $tmp,$shift\t&quot;
17291             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17292   ins_encode %{
17293     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17294             as_FloatRegister($shift$$reg));
17295     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17296             as_FloatRegister($src$$reg),
17297             as_FloatRegister($tmp$$reg));
17298   %}
17299   ins_pipe(vshift128);
17300 %}
17301 
17302 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17303   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17304             n-&gt;as_Vector()-&gt;length() == 8);
17305   match(Set dst (URShiftVB src shift));
17306   ins_cost(INSN_COST);
17307   effect(TEMP tmp);
17308   format %{ &quot;negr  $tmp,$shift\t&quot;
17309             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17310   ins_encode %{
17311     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17312             as_FloatRegister($shift$$reg));
17313     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17314             as_FloatRegister($src$$reg),
17315             as_FloatRegister($tmp$$reg));
17316   %}
17317   ins_pipe(vshift64);
17318 %}
17319 
17320 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17321   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17322   match(Set dst (URShiftVB src shift));
17323   ins_cost(INSN_COST);
17324   effect(TEMP tmp);
17325   format %{ &quot;negr  $tmp,$shift\t&quot;
17326             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17327   ins_encode %{
17328     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17329             as_FloatRegister($shift$$reg));
17330     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17331             as_FloatRegister($src$$reg),
17332             as_FloatRegister($tmp$$reg));
17333   %}
17334   ins_pipe(vshift128);
17335 %}
17336 
17337 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17338   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17339             n-&gt;as_Vector()-&gt;length() == 8);
17340   match(Set dst (LShiftVB src (LShiftCntV shift)));
17341   ins_cost(INSN_COST);
17342   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17343   ins_encode %{
17344     int sh = (int)$shift$$constant;
17345     if (sh &gt;= 8) {
17346       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17347              as_FloatRegister($src$$reg),
17348              as_FloatRegister($src$$reg));
17349     } else {
17350       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17351              as_FloatRegister($src$$reg), sh);
17352     }
17353   %}
17354   ins_pipe(vshift64_imm);
17355 %}
17356 
17357 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17358   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17359   match(Set dst (LShiftVB src (LShiftCntV shift)));
17360   ins_cost(INSN_COST);
17361   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17362   ins_encode %{
17363     int sh = (int)$shift$$constant;
17364     if (sh &gt;= 8) {
17365       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17366              as_FloatRegister($src$$reg),
17367              as_FloatRegister($src$$reg));
17368     } else {
17369       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17370              as_FloatRegister($src$$reg), sh);
17371     }
17372   %}
17373   ins_pipe(vshift128_imm);
17374 %}
17375 
17376 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17377   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17378             n-&gt;as_Vector()-&gt;length() == 8);
17379   match(Set dst (RShiftVB src (RShiftCntV shift)));
17380   ins_cost(INSN_COST);
17381   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17382   ins_encode %{
17383     int sh = (int)$shift$$constant;
17384     if (sh &gt;= 8) sh = 7;
17385     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17386            as_FloatRegister($src$$reg), sh);
17387   %}
17388   ins_pipe(vshift64_imm);
17389 %}
17390 
17391 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17392   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17393   match(Set dst (RShiftVB src (RShiftCntV shift)));
17394   ins_cost(INSN_COST);
17395   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17396   ins_encode %{
17397     int sh = (int)$shift$$constant;
17398     if (sh &gt;= 8) sh = 7;
17399     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17400            as_FloatRegister($src$$reg), sh);
17401   %}
17402   ins_pipe(vshift128_imm);
17403 %}
17404 
17405 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17406   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17407             n-&gt;as_Vector()-&gt;length() == 8);
17408   match(Set dst (URShiftVB src (RShiftCntV shift)));
17409   ins_cost(INSN_COST);
17410   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17411   ins_encode %{
17412     int sh = (int)$shift$$constant;
17413     if (sh &gt;= 8) {
17414       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17415              as_FloatRegister($src$$reg),
17416              as_FloatRegister($src$$reg));
17417     } else {
17418       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17419              as_FloatRegister($src$$reg), sh);
17420     }
17421   %}
17422   ins_pipe(vshift64_imm);
17423 %}
17424 
17425 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17426   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17427   match(Set dst (URShiftVB src (RShiftCntV shift)));
17428   ins_cost(INSN_COST);
17429   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17430   ins_encode %{
17431     int sh = (int)$shift$$constant;
17432     if (sh &gt;= 8) {
17433       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17434              as_FloatRegister($src$$reg),
17435              as_FloatRegister($src$$reg));
17436     } else {
17437       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17438              as_FloatRegister($src$$reg), sh);
17439     }
17440   %}
17441   ins_pipe(vshift128_imm);
17442 %}
17443 
17444 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17445   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17446             n-&gt;as_Vector()-&gt;length() == 4);
17447   match(Set dst (LShiftVS src shift));
17448   ins_cost(INSN_COST);
17449   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17450   ins_encode %{
17451     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17452             as_FloatRegister($src$$reg),
17453             as_FloatRegister($shift$$reg));
17454   %}
17455   ins_pipe(vshift64);
17456 %}
17457 
17458 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17459   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17460   match(Set dst (LShiftVS src shift));
17461   ins_cost(INSN_COST);
17462   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17463   ins_encode %{
17464     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17465             as_FloatRegister($src$$reg),
17466             as_FloatRegister($shift$$reg));
17467   %}
17468   ins_pipe(vshift128);
17469 %}
17470 
17471 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17472   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17473             n-&gt;as_Vector()-&gt;length() == 4);
17474   match(Set dst (RShiftVS src shift));
17475   ins_cost(INSN_COST);
17476   effect(TEMP tmp);
17477   format %{ &quot;negr  $tmp,$shift\t&quot;
17478             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17479   ins_encode %{
17480     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17481             as_FloatRegister($shift$$reg));
17482     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17483             as_FloatRegister($src$$reg),
17484             as_FloatRegister($tmp$$reg));
17485   %}
17486   ins_pipe(vshift64);
17487 %}
17488 
17489 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17490   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17491   match(Set dst (RShiftVS src shift));
17492   ins_cost(INSN_COST);
17493   effect(TEMP tmp);
17494   format %{ &quot;negr  $tmp,$shift\t&quot;
17495             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17496   ins_encode %{
17497     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17498             as_FloatRegister($shift$$reg));
17499     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17500             as_FloatRegister($src$$reg),
17501             as_FloatRegister($tmp$$reg));
17502   %}
17503   ins_pipe(vshift128);
17504 %}
17505 
17506 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17507   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17508             n-&gt;as_Vector()-&gt;length() == 4);
17509   match(Set dst (URShiftVS src shift));
17510   ins_cost(INSN_COST);
17511   effect(TEMP tmp);
17512   format %{ &quot;negr  $tmp,$shift\t&quot;
17513             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17514   ins_encode %{
17515     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17516             as_FloatRegister($shift$$reg));
17517     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17518             as_FloatRegister($src$$reg),
17519             as_FloatRegister($tmp$$reg));
17520   %}
17521   ins_pipe(vshift64);
17522 %}
17523 
17524 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17525   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17526   match(Set dst (URShiftVS src shift));
17527   ins_cost(INSN_COST);
17528   effect(TEMP tmp);
17529   format %{ &quot;negr  $tmp,$shift\t&quot;
17530             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17531   ins_encode %{
17532     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17533             as_FloatRegister($shift$$reg));
17534     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17535             as_FloatRegister($src$$reg),
17536             as_FloatRegister($tmp$$reg));
17537   %}
17538   ins_pipe(vshift128);
17539 %}
17540 
17541 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17542   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17543             n-&gt;as_Vector()-&gt;length() == 4);
17544   match(Set dst (LShiftVS src (LShiftCntV shift)));
17545   ins_cost(INSN_COST);
17546   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17547   ins_encode %{
17548     int sh = (int)$shift$$constant;
17549     if (sh &gt;= 16) {
17550       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17551              as_FloatRegister($src$$reg),
17552              as_FloatRegister($src$$reg));
17553     } else {
17554       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17555              as_FloatRegister($src$$reg), sh);
17556     }
17557   %}
17558   ins_pipe(vshift64_imm);
17559 %}
17560 
17561 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17562   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17563   match(Set dst (LShiftVS src (LShiftCntV shift)));
17564   ins_cost(INSN_COST);
17565   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17566   ins_encode %{
17567     int sh = (int)$shift$$constant;
17568     if (sh &gt;= 16) {
17569       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17570              as_FloatRegister($src$$reg),
17571              as_FloatRegister($src$$reg));
17572     } else {
17573       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17574              as_FloatRegister($src$$reg), sh);
17575     }
17576   %}
17577   ins_pipe(vshift128_imm);
17578 %}
17579 
17580 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17581   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17582             n-&gt;as_Vector()-&gt;length() == 4);
17583   match(Set dst (RShiftVS src (LShiftCntV shift)));
17584   ins_cost(INSN_COST);
17585   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17586   ins_encode %{
17587     int sh = (int)$shift$$constant;
17588     if (sh &gt;= 16) sh = 15;
17589     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17590            as_FloatRegister($src$$reg), sh);
17591   %}
17592   ins_pipe(vshift64_imm);
17593 %}
17594 
17595 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17596   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17597   match(Set dst (RShiftVS src (LShiftCntV shift)));
17598   ins_cost(INSN_COST);
17599   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17600   ins_encode %{
17601     int sh = (int)$shift$$constant;
17602     if (sh &gt;= 16) sh = 15;
17603     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17604            as_FloatRegister($src$$reg), sh);
17605   %}
17606   ins_pipe(vshift128_imm);
17607 %}
17608 
17609 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17610   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17611             n-&gt;as_Vector()-&gt;length() == 4);
17612   match(Set dst (URShiftVS src (RShiftCntV shift)));
17613   ins_cost(INSN_COST);
17614   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17615   ins_encode %{
17616     int sh = (int)$shift$$constant;
17617     if (sh &gt;= 16) {
17618       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17619              as_FloatRegister($src$$reg),
17620              as_FloatRegister($src$$reg));
17621     } else {
17622       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17623              as_FloatRegister($src$$reg), sh);
17624     }
17625   %}
17626   ins_pipe(vshift64_imm);
17627 %}
17628 
17629 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17630   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17631   match(Set dst (URShiftVS src (RShiftCntV shift)));
17632   ins_cost(INSN_COST);
17633   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17634   ins_encode %{
17635     int sh = (int)$shift$$constant;
17636     if (sh &gt;= 16) {
17637       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17638              as_FloatRegister($src$$reg),
17639              as_FloatRegister($src$$reg));
17640     } else {
17641       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17642              as_FloatRegister($src$$reg), sh);
17643     }
17644   %}
17645   ins_pipe(vshift128_imm);
17646 %}
17647 
17648 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17649   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17650   match(Set dst (LShiftVI src shift));
17651   ins_cost(INSN_COST);
17652   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17653   ins_encode %{
17654     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17655             as_FloatRegister($src$$reg),
17656             as_FloatRegister($shift$$reg));
17657   %}
17658   ins_pipe(vshift64);
17659 %}
17660 
17661 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17662   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17663   match(Set dst (LShiftVI src shift));
17664   ins_cost(INSN_COST);
17665   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17666   ins_encode %{
17667     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17668             as_FloatRegister($src$$reg),
17669             as_FloatRegister($shift$$reg));
17670   %}
17671   ins_pipe(vshift128);
17672 %}
17673 
17674 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17675   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17676   match(Set dst (RShiftVI src shift));
17677   ins_cost(INSN_COST);
17678   effect(TEMP tmp);
17679   format %{ &quot;negr  $tmp,$shift\t&quot;
17680             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17681   ins_encode %{
17682     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17683             as_FloatRegister($shift$$reg));
17684     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17685             as_FloatRegister($src$$reg),
17686             as_FloatRegister($tmp$$reg));
17687   %}
17688   ins_pipe(vshift64);
17689 %}
17690 
17691 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17692   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17693   match(Set dst (RShiftVI src shift));
17694   ins_cost(INSN_COST);
17695   effect(TEMP tmp);
17696   format %{ &quot;negr  $tmp,$shift\t&quot;
17697             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17698   ins_encode %{
17699     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17700             as_FloatRegister($shift$$reg));
17701     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17702             as_FloatRegister($src$$reg),
17703             as_FloatRegister($tmp$$reg));
17704   %}
17705   ins_pipe(vshift128);
17706 %}
17707 
17708 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17709   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17710   match(Set dst (URShiftVI src shift));
17711   ins_cost(INSN_COST);
17712   effect(TEMP tmp);
17713   format %{ &quot;negr  $tmp,$shift\t&quot;
17714             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17715   ins_encode %{
17716     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17717             as_FloatRegister($shift$$reg));
17718     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17719             as_FloatRegister($src$$reg),
17720             as_FloatRegister($tmp$$reg));
17721   %}
17722   ins_pipe(vshift64);
17723 %}
17724 
17725 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17726   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17727   match(Set dst (URShiftVI src shift));
17728   ins_cost(INSN_COST);
17729   effect(TEMP tmp);
17730   format %{ &quot;negr  $tmp,$shift\t&quot;
17731             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17732   ins_encode %{
17733     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17734             as_FloatRegister($shift$$reg));
17735     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17736             as_FloatRegister($src$$reg),
17737             as_FloatRegister($tmp$$reg));
17738   %}
17739   ins_pipe(vshift128);
17740 %}
17741 
17742 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17743   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17744   match(Set dst (LShiftVI src (LShiftCntV shift)));
17745   ins_cost(INSN_COST);
17746   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17747   ins_encode %{
17748     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17749            as_FloatRegister($src$$reg),
17750            (int)$shift$$constant);
17751   %}
17752   ins_pipe(vshift64_imm);
17753 %}
17754 
17755 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17756   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17757   match(Set dst (LShiftVI src (LShiftCntV shift)));
17758   ins_cost(INSN_COST);
17759   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17760   ins_encode %{
17761     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17762            as_FloatRegister($src$$reg),
17763            (int)$shift$$constant);
17764   %}
17765   ins_pipe(vshift128_imm);
17766 %}
17767 
17768 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17769   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17770   match(Set dst (RShiftVI src (RShiftCntV shift)));
17771   ins_cost(INSN_COST);
17772   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17773   ins_encode %{
17774     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17775             as_FloatRegister($src$$reg),
17776             (int)$shift$$constant);
17777   %}
17778   ins_pipe(vshift64_imm);
17779 %}
17780 
17781 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17782   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17783   match(Set dst (RShiftVI src (RShiftCntV shift)));
17784   ins_cost(INSN_COST);
17785   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17786   ins_encode %{
17787     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17788             as_FloatRegister($src$$reg),
17789             (int)$shift$$constant);
17790   %}
17791   ins_pipe(vshift128_imm);
17792 %}
17793 
17794 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17795   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17796   match(Set dst (URShiftVI src (RShiftCntV shift)));
17797   ins_cost(INSN_COST);
17798   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17799   ins_encode %{
17800     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17801             as_FloatRegister($src$$reg),
17802             (int)$shift$$constant);
17803   %}
17804   ins_pipe(vshift64_imm);
17805 %}
17806 
17807 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17808   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17809   match(Set dst (URShiftVI src (RShiftCntV shift)));
17810   ins_cost(INSN_COST);
17811   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17812   ins_encode %{
17813     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17814             as_FloatRegister($src$$reg),
17815             (int)$shift$$constant);
17816   %}
17817   ins_pipe(vshift128_imm);
17818 %}
17819 
17820 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17821   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17822   match(Set dst (LShiftVL src shift));
17823   ins_cost(INSN_COST);
17824   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17825   ins_encode %{
17826     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17827             as_FloatRegister($src$$reg),
17828             as_FloatRegister($shift$$reg));
17829   %}
17830   ins_pipe(vshift128);
17831 %}
17832 
17833 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17834   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17835   match(Set dst (RShiftVL src shift));
17836   ins_cost(INSN_COST);
17837   effect(TEMP tmp);
17838   format %{ &quot;negr  $tmp,$shift\t&quot;
17839             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17840   ins_encode %{
17841     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17842             as_FloatRegister($shift$$reg));
17843     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17844             as_FloatRegister($src$$reg),
17845             as_FloatRegister($tmp$$reg));
17846   %}
17847   ins_pipe(vshift128);
17848 %}
17849 
17850 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17851   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17852   match(Set dst (URShiftVL src shift));
17853   ins_cost(INSN_COST);
17854   effect(TEMP tmp);
17855   format %{ &quot;negr  $tmp,$shift\t&quot;
17856             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17857   ins_encode %{
17858     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17859             as_FloatRegister($shift$$reg));
17860     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17861             as_FloatRegister($src$$reg),
17862             as_FloatRegister($tmp$$reg));
17863   %}
17864   ins_pipe(vshift128);
17865 %}
17866 
17867 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17868   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17869   match(Set dst (LShiftVL src (LShiftCntV shift)));
17870   ins_cost(INSN_COST);
17871   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17872   ins_encode %{
17873     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17874            as_FloatRegister($src$$reg),
17875            (int)$shift$$constant);
17876   %}
17877   ins_pipe(vshift128_imm);
17878 %}
17879 
17880 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17881   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17882   match(Set dst (RShiftVL src (RShiftCntV shift)));
17883   ins_cost(INSN_COST);
17884   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17885   ins_encode %{
17886     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17887             as_FloatRegister($src$$reg),
17888             (int)$shift$$constant);
17889   %}
17890   ins_pipe(vshift128_imm);
17891 %}
17892 
17893 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17894   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17895   match(Set dst (URShiftVL src (RShiftCntV shift)));
17896   ins_cost(INSN_COST);
17897   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17898   ins_encode %{
17899     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17900             as_FloatRegister($src$$reg),
17901             (int)$shift$$constant);
17902   %}
17903   ins_pipe(vshift128_imm);
17904 %}
17905 
17906 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17907 %{
17908   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17909   match(Set dst (MaxV src1 src2));
17910   ins_cost(INSN_COST);
17911   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17912   ins_encode %{
17913     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17914             as_FloatRegister($src1$$reg),
17915             as_FloatRegister($src2$$reg));
17916   %}
17917   ins_pipe(vdop_fp64);
17918 %}
17919 
17920 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17921 %{
17922   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17923   match(Set dst (MaxV src1 src2));
17924   ins_cost(INSN_COST);
17925   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17926   ins_encode %{
17927     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17928             as_FloatRegister($src1$$reg),
17929             as_FloatRegister($src2$$reg));
17930   %}
17931   ins_pipe(vdop_fp128);
17932 %}
17933 
17934 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17935 %{
17936   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17937   match(Set dst (MaxV src1 src2));
17938   ins_cost(INSN_COST);
17939   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17940   ins_encode %{
17941     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17942             as_FloatRegister($src1$$reg),
17943             as_FloatRegister($src2$$reg));
17944   %}
17945   ins_pipe(vdop_fp128);
17946 %}
17947 
17948 instruct vmin2F(vecD dst, vecD src1, vecD src2)
17949 %{
17950   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17951   match(Set dst (MinV src1 src2));
17952   ins_cost(INSN_COST);
17953   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
17954   ins_encode %{
17955     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
17956             as_FloatRegister($src1$$reg),
17957             as_FloatRegister($src2$$reg));
17958   %}
17959   ins_pipe(vdop_fp64);
17960 %}
17961 
17962 instruct vmin4F(vecX dst, vecX src1, vecX src2)
17963 %{
17964   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17965   match(Set dst (MinV src1 src2));
17966   ins_cost(INSN_COST);
17967   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
17968   ins_encode %{
17969     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
17970             as_FloatRegister($src1$$reg),
17971             as_FloatRegister($src2$$reg));
17972   %}
17973   ins_pipe(vdop_fp128);
17974 %}
17975 
17976 instruct vmin2D(vecX dst, vecX src1, vecX src2)
17977 %{
17978   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17979   match(Set dst (MinV src1 src2));
17980   ins_cost(INSN_COST);
17981   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
17982   ins_encode %{
17983     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
17984             as_FloatRegister($src1$$reg),
17985             as_FloatRegister($src2$$reg));
17986   %}
17987   ins_pipe(vdop_fp128);
17988 %}
17989 
17990 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
17991   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17992   match(Set dst (RoundDoubleModeV src rmode));
17993   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
17994   ins_encode %{
17995     switch ($rmode$$constant) {
17996       case RoundDoubleModeNode::rmode_rint:
17997         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
17998                   as_FloatRegister($src$$reg));
17999         break;
18000       case RoundDoubleModeNode::rmode_floor:
18001         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18002                   as_FloatRegister($src$$reg));
18003         break;
18004       case RoundDoubleModeNode::rmode_ceil:
18005         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18006                   as_FloatRegister($src$$reg));
18007         break;
18008     }
18009   %}
18010   ins_pipe(vdop_fp128);
18011 %}
18012 
18013 instruct vpopcount4I(vecX dst, vecX src) %{
18014   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18015   match(Set dst (PopCountVI src));
18016   format %{
18017     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18018     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18019     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18020   %}
18021   ins_encode %{
18022      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18023             as_FloatRegister($src$$reg));
18024      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18025                as_FloatRegister($dst$$reg));
18026      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18027                as_FloatRegister($dst$$reg));
18028   %}
18029   ins_pipe(pipe_class_default);
18030 %}
18031 
18032 instruct vpopcount2I(vecD dst, vecD src) %{
18033   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18034   match(Set dst (PopCountVI src));
18035   format %{
18036     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18037     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18038     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18039   %}
18040   ins_encode %{
18041      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18042             as_FloatRegister($src$$reg));
18043      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18044                as_FloatRegister($dst$$reg));
18045      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18046                as_FloatRegister($dst$$reg));
18047   %}
18048   ins_pipe(pipe_class_default);
18049 %}
18050 
18051 //----------PEEPHOLE RULES-----------------------------------------------------
18052 // These must follow all instruction definitions as they use the names
18053 // defined in the instructions definitions.
18054 //
18055 // peepmatch ( root_instr_name [preceding_instruction]* );
18056 //
18057 // peepconstraint %{
18058 // (instruction_number.operand_name relational_op instruction_number.operand_name
18059 //  [, ...] );
18060 // // instruction numbers are zero-based using left to right order in peepmatch
18061 //
18062 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18063 // // provide an instruction_number.operand_name for each operand that appears
18064 // // in the replacement instruction&#39;s match rule
18065 //
18066 // ---------VM FLAGS---------------------------------------------------------
18067 //
18068 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18069 //
18070 // Each peephole rule is given an identifying number starting with zero and
18071 // increasing by one in the order seen by the parser.  An individual peephole
18072 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18073 // on the command-line.
18074 //
18075 // ---------CURRENT LIMITATIONS----------------------------------------------
18076 //
18077 // Only match adjacent instructions in same basic block
18078 // Only equality constraints
18079 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18080 // Only one replacement instruction
18081 //
18082 // ---------EXAMPLE----------------------------------------------------------
18083 //
18084 // // pertinent parts of existing instructions in architecture description
18085 // instruct movI(iRegINoSp dst, iRegI src)
18086 // %{
18087 //   match(Set dst (CopyI src));
18088 // %}
18089 //
18090 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18091 // %{
18092 //   match(Set dst (AddI dst src));
18093 //   effect(KILL cr);
18094 // %}
18095 //
18096 // // Change (inc mov) to lea
18097 // peephole %{
18098 //   // increment preceeded by register-register move
18099 //   peepmatch ( incI_iReg movI );
18100 //   // require that the destination register of the increment
18101 //   // match the destination register of the move
18102 //   peepconstraint ( 0.dst == 1.dst );
18103 //   // construct a replacement instruction that sets
18104 //   // the destination to ( move&#39;s source register + one )
18105 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18106 // %}
18107 //
18108 
18109 // Implementation no longer uses movX instructions since
18110 // machine-independent system no longer uses CopyX nodes.
18111 //
18112 // peephole
18113 // %{
18114 //   peepmatch (incI_iReg movI);
18115 //   peepconstraint (0.dst == 1.dst);
18116 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18117 // %}
18118 
18119 // peephole
18120 // %{
18121 //   peepmatch (decI_iReg movI);
18122 //   peepconstraint (0.dst == 1.dst);
18123 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18124 // %}
18125 
18126 // peephole
18127 // %{
18128 //   peepmatch (addI_iReg_imm movI);
18129 //   peepconstraint (0.dst == 1.dst);
18130 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18131 // %}
18132 
18133 // peephole
18134 // %{
18135 //   peepmatch (incL_iReg movL);
18136 //   peepconstraint (0.dst == 1.dst);
18137 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18138 // %}
18139 
18140 // peephole
18141 // %{
18142 //   peepmatch (decL_iReg movL);
18143 //   peepconstraint (0.dst == 1.dst);
18144 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18145 // %}
18146 
18147 // peephole
18148 // %{
18149 //   peepmatch (addL_iReg_imm movL);
18150 //   peepconstraint (0.dst == 1.dst);
18151 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18152 // %}
18153 
18154 // peephole
18155 // %{
18156 //   peepmatch (addP_iReg_imm movP);
18157 //   peepconstraint (0.dst == 1.dst);
18158 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18159 // %}
18160 
18161 // // Change load of spilled value to only a spill
18162 // instruct storeI(memory mem, iRegI src)
18163 // %{
18164 //   match(Set mem (StoreI mem src));
18165 // %}
18166 //
18167 // instruct loadI(iRegINoSp dst, memory mem)
18168 // %{
18169 //   match(Set dst (LoadI mem));
18170 // %}
18171 //
18172 
18173 //----------SMARTSPILL RULES---------------------------------------------------
18174 // These must follow all instruction definitions as they use the names
18175 // defined in the instructions definitions.
18176 
18177 // Local Variables:
18178 // mode: c++
18179 // End:
<a name="14" id="anc14"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="14" type="hidden" />
</body>
</html>