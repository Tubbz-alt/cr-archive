<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="gc/g1/g1BarrierSetAssembler_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  30 #include &quot;interp_masm_aarch64.hpp&quot;
  31 #include &quot;interpreter/interpreter.hpp&quot;
  32 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  33 #include &quot;logging/log.hpp&quot;
  34 #include &quot;oops/arrayOop.hpp&quot;
  35 #include &quot;oops/markWord.hpp&quot;
  36 #include &quot;oops/method.hpp&quot;
  37 #include &quot;oops/methodData.hpp&quot;

  38 #include &quot;prims/jvmtiExport.hpp&quot;
  39 #include &quot;prims/jvmtiThreadState.hpp&quot;
  40 #include &quot;runtime/basicLock.hpp&quot;
  41 #include &quot;runtime/biasedLocking.hpp&quot;
  42 #include &quot;runtime/frame.inline.hpp&quot;
  43 #include &quot;runtime/safepointMechanism.hpp&quot;
  44 #include &quot;runtime/sharedRuntime.hpp&quot;
  45 #include &quot;runtime/thread.inline.hpp&quot;
  46 #include &quot;utilities/powerOfTwo.hpp&quot;
  47 
  48 void InterpreterMacroAssembler::narrow(Register result) {
  49 
  50   // Get method-&gt;_constMethod-&gt;_result_type
  51   ldr(rscratch1, Address(rfp, frame::interpreter_frame_method_offset * wordSize));
  52   ldr(rscratch1, Address(rscratch1, Method::const_offset()));
  53   ldrb(rscratch1, Address(rscratch1, ConstMethod::result_type_offset()));
  54 
  55   Label done, notBool, notByte, notChar;
  56 
  57   // common case first
</pre>
<hr />
<pre>
 650 
 651     add(c_rarg1, c_rarg1, entry_size); // otherwise advance to next entry
 652     bind(entry);
 653     cmp(c_rarg1, r19); // check if bottom reached
 654     br(Assembler::NE, loop); // if not at bottom then check this entry
 655   }
 656 
 657   bind(no_unlock);
 658 
 659   // jvmti support
 660   if (notify_jvmdi) {
 661     notify_method_exit(state, NotifyJVMTI);    // preserve TOSCA
 662   } else {
 663     notify_method_exit(state, SkipNotifyJVMTI); // preserve TOSCA
 664   }
 665 
 666   // remove activation
 667   // get sender esp
 668   ldr(esp,
 669       Address(rfp, frame::interpreter_frame_sender_sp_offset * wordSize));

 670   if (StackReservedPages &gt; 0) {
 671     // testing if reserved zone needs to be re-enabled
 672     Label no_reserved_zone_enabling;
 673 
 674     ldr(rscratch1, Address(rthread, JavaThread::reserved_stack_activation_offset()));
 675     cmp(esp, rscratch1);
 676     br(Assembler::LS, no_reserved_zone_enabling);
 677 
 678     call_VM_leaf(
 679       CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone), rthread);
 680     call_VM(noreg, CAST_FROM_FN_PTR(address,
 681                    InterpreterRuntime::throw_delayed_StackOverflowError));
 682     should_not_reach_here();
 683 
 684     bind(no_reserved_zone_enabling);
 685   }



























 686   // remove frame anchor
 687   leave();
 688   // If we&#39;re returning to interpreted code we will shortly be
 689   // adjusting SP to allow some space for ESP.  If we&#39;re returning to
 690   // compiled code the saved sender SP was saved in sender_sp, so this
 691   // restores it.
 692   andr(sp, esp, -16);
 693 }
 694 
 695 // Lock object
 696 //
 697 // Args:
 698 //      c_rarg1: BasicObjectLock to be used for locking
 699 //
 700 // Kills:
 701 //      r0
 702 //      c_rarg0, c_rarg1, c_rarg2, c_rarg3, .. (param regs)
 703 //      rscratch1, rscratch2 (scratch regs)
 704 void InterpreterMacroAssembler::lock_object(Register lock_reg)
 705 {
</pre>
<hr />
<pre>
 719     const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();
 720     const int mark_offset = lock_offset +
 721                             BasicLock::displaced_header_offset_in_bytes();
 722 
 723     Label slow_case;
 724 
 725     // Load object pointer into obj_reg %c_rarg3
 726     ldr(obj_reg, Address(lock_reg, obj_offset));
 727 
 728     if (UseBiasedLocking) {
 729       biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp, false, done, &amp;slow_case);
 730     }
 731 
 732     // Load (object-&gt;mark() | 1) into swap_reg
 733     ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
 734     orr(swap_reg, rscratch1, 1);
 735 
 736     // Save (object-&gt;mark() | 1) into BasicLock&#39;s displaced header
 737     str(swap_reg, Address(lock_reg, mark_offset));
 738 





 739     assert(lock_offset == 0,
 740            &quot;displached header must be first word in BasicObjectLock&quot;);
 741 
 742     Label fail;
 743     if (PrintBiasedLockingStatistics) {
 744       Label fast;
 745       cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, fast, &amp;fail);
 746       bind(fast);
 747       atomic_incw(Address((address)BiasedLocking::fast_path_entry_count_addr()),
 748                   rscratch2, rscratch1, tmp);
 749       b(done);
 750       bind(fail);
 751     } else {
 752       cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, done, /*fallthrough*/NULL);
 753     }
 754 
 755     // Test if the oopMark is an obvious stack pointer, i.e.,
 756     //  1) (mark &amp; 7) == 0, and
 757     //  2) rsp &lt;= mark &lt; mark + os::pagesize()
 758     //
</pre>
<hr />
<pre>
1684         profile_obj_type(tmp, mdo_arg_addr);
1685 
1686         int to_add = in_bytes(TypeStackSlotEntries::per_arg_size());
1687         off_to_args += to_add;
1688       }
1689 
1690       if (MethodData::profile_return()) {
1691         ldr(tmp, Address(mdp, in_bytes(TypeEntriesAtCall::cell_count_offset())));
1692         sub(tmp, tmp, TypeProfileArgsLimit*TypeStackSlotEntries::per_arg_count());
1693       }
1694 
1695       add(rscratch1, mdp, off_to_args);
1696       bind(done);
1697       mov(mdp, rscratch1);
1698 
1699       if (MethodData::profile_return()) {
1700         // We&#39;re right after the type profile for the last
1701         // argument. tmp is the number of cells left in the
1702         // CallTypeData/VirtualCallTypeData to reach its end. Non null
1703         // if there&#39;s a return to profile.
<span class="line-modified">1704         assert(ReturnTypeEntry::static_cell_count() &lt; TypeStackSlotEntries::per_arg_count(), &quot;can&#39;t move past ret type&quot;);</span>
1705         add(mdp, mdp, tmp, LSL, exact_log2(DataLayout::cell_size));
1706       }
1707       str(mdp, Address(rfp, frame::interpreter_frame_mdp_offset * wordSize));
1708     } else {
1709       assert(MethodData::profile_return(), &quot;either profile call args or call ret&quot;);
1710       update_mdp_by_constant(mdp, in_bytes(TypeEntriesAtCall::return_only_size()));
1711     }
1712 
1713     // mdp points right after the end of the
1714     // CallTypeData/VirtualCallTypeData, right after the cells for the
1715     // return value type if there&#39;s one
1716 
1717     bind(profile_continue);
1718   }
1719 }
1720 
1721 void InterpreterMacroAssembler::profile_return_type(Register mdp, Register ret, Register tmp) {
1722   assert_different_registers(mdp, ret, tmp, rbcp);
1723   if (ProfileInterpreter &amp;&amp; MethodData::profile_return()) {
1724     Label profile_continue, done;
</pre>
<hr />
<pre>
1730 
1731       // If we don&#39;t profile all invoke bytecodes we must make sure
1732       // it&#39;s a bytecode we indeed profile. We can&#39;t go back to the
1733       // begining of the ProfileData we intend to update to check its
1734       // type because we&#39;re right after it and we don&#39;t known its
1735       // length
1736       Label do_profile;
1737       ldrb(rscratch1, Address(rbcp, 0));
1738       cmp(rscratch1, (u1)Bytecodes::_invokedynamic);
1739       br(Assembler::EQ, do_profile);
1740       cmp(rscratch1, (u1)Bytecodes::_invokehandle);
1741       br(Assembler::EQ, do_profile);
1742       get_method(tmp);
1743       ldrh(rscratch1, Address(tmp, Method::intrinsic_id_offset_in_bytes()));
1744       subs(zr, rscratch1, vmIntrinsics::_compiledLambdaForm);
1745       br(Assembler::NE, profile_continue);
1746 
1747       bind(do_profile);
1748     }
1749 
<span class="line-modified">1750     Address mdo_ret_addr(mdp, -in_bytes(ReturnTypeEntry::size()));</span>
1751     mov(tmp, ret);
1752     profile_obj_type(tmp, mdo_ret_addr);
1753 
1754     bind(profile_continue);
1755   }
1756 }
1757 
1758 void InterpreterMacroAssembler::profile_parameters_type(Register mdp, Register tmp1, Register tmp2) {
1759   assert_different_registers(rscratch1, rscratch2, mdp, tmp1, tmp2);
1760   if (ProfileInterpreter &amp;&amp; MethodData::profile_parameters()) {
1761     Label profile_continue, done;
1762 
1763     test_method_data_pointer(mdp, profile_continue);
1764 
1765     // Load the offset of the area within the MDO used for
1766     // parameters. If it&#39;s negative we&#39;re not profiling any parameters
1767     ldrw(tmp1, Address(mdp, in_bytes(MethodData::parameters_type_data_di_offset()) - in_bytes(MethodData::data_offset())));
1768     tbnz(tmp1, 31, profile_continue);  // i.e. sign bit set
1769 
1770     // Compute a pointer to the area for parameters from the offset
</pre>
</td>
<td>
<hr />
<pre>
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;gc/shared/barrierSet.hpp&quot;
  29 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  30 #include &quot;interp_masm_aarch64.hpp&quot;
  31 #include &quot;interpreter/interpreter.hpp&quot;
  32 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  33 #include &quot;logging/log.hpp&quot;
  34 #include &quot;oops/arrayOop.hpp&quot;
  35 #include &quot;oops/markWord.hpp&quot;
  36 #include &quot;oops/method.hpp&quot;
  37 #include &quot;oops/methodData.hpp&quot;
<span class="line-added">  38 #include &quot;oops/valueKlass.hpp&quot;</span>
  39 #include &quot;prims/jvmtiExport.hpp&quot;
  40 #include &quot;prims/jvmtiThreadState.hpp&quot;
  41 #include &quot;runtime/basicLock.hpp&quot;
  42 #include &quot;runtime/biasedLocking.hpp&quot;
  43 #include &quot;runtime/frame.inline.hpp&quot;
  44 #include &quot;runtime/safepointMechanism.hpp&quot;
  45 #include &quot;runtime/sharedRuntime.hpp&quot;
  46 #include &quot;runtime/thread.inline.hpp&quot;
  47 #include &quot;utilities/powerOfTwo.hpp&quot;
  48 
  49 void InterpreterMacroAssembler::narrow(Register result) {
  50 
  51   // Get method-&gt;_constMethod-&gt;_result_type
  52   ldr(rscratch1, Address(rfp, frame::interpreter_frame_method_offset * wordSize));
  53   ldr(rscratch1, Address(rscratch1, Method::const_offset()));
  54   ldrb(rscratch1, Address(rscratch1, ConstMethod::result_type_offset()));
  55 
  56   Label done, notBool, notByte, notChar;
  57 
  58   // common case first
</pre>
<hr />
<pre>
 651 
 652     add(c_rarg1, c_rarg1, entry_size); // otherwise advance to next entry
 653     bind(entry);
 654     cmp(c_rarg1, r19); // check if bottom reached
 655     br(Assembler::NE, loop); // if not at bottom then check this entry
 656   }
 657 
 658   bind(no_unlock);
 659 
 660   // jvmti support
 661   if (notify_jvmdi) {
 662     notify_method_exit(state, NotifyJVMTI);    // preserve TOSCA
 663   } else {
 664     notify_method_exit(state, SkipNotifyJVMTI); // preserve TOSCA
 665   }
 666 
 667   // remove activation
 668   // get sender esp
 669   ldr(esp,
 670       Address(rfp, frame::interpreter_frame_sender_sp_offset * wordSize));
<span class="line-added"> 671 </span>
 672   if (StackReservedPages &gt; 0) {
 673     // testing if reserved zone needs to be re-enabled
 674     Label no_reserved_zone_enabling;
 675 
 676     ldr(rscratch1, Address(rthread, JavaThread::reserved_stack_activation_offset()));
 677     cmp(esp, rscratch1);
 678     br(Assembler::LS, no_reserved_zone_enabling);
 679 
 680     call_VM_leaf(
 681       CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone), rthread);
 682     call_VM(noreg, CAST_FROM_FN_PTR(address,
 683                    InterpreterRuntime::throw_delayed_StackOverflowError));
 684     should_not_reach_here();
 685 
 686     bind(no_reserved_zone_enabling);
 687   }
<span class="line-added"> 688 </span>
<span class="line-added"> 689 </span>
<span class="line-added"> 690   if (state == atos &amp;&amp; ValueTypeReturnedAsFields) {</span>
<span class="line-added"> 691     Label skip;</span>
<span class="line-added"> 692     // Test if the return type is a value type</span>
<span class="line-added"> 693     ldr(rscratch1, Address(rfp, frame::interpreter_frame_method_offset * wordSize));</span>
<span class="line-added"> 694     ldr(rscratch1, Address(rscratch1, Method::const_offset()));</span>
<span class="line-added"> 695     ldrb(rscratch1, Address(rscratch1, ConstMethod::result_type_offset()));</span>
<span class="line-added"> 696     cmpw(rscratch1, (u1) T_VALUETYPE);</span>
<span class="line-added"> 697     br(Assembler::NE, skip);</span>
<span class="line-added"> 698 </span>
<span class="line-added"> 699     // We are returning a value type, load its fields into registers</span>
<span class="line-added"> 700     // Load fields from a buffered value with a value class specific handler</span>
<span class="line-added"> 701 </span>
<span class="line-added"> 702     load_klass(rscratch1 /*dst*/, r0 /*src*/);</span>
<span class="line-added"> 703     ldr(rscratch1, Address(rscratch1, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added"> 704     ldr(rscratch1, Address(rscratch1, ValueKlass::unpack_handler_offset()));</span>
<span class="line-added"> 705     cbz(rscratch1, skip);</span>
<span class="line-added"> 706 </span>
<span class="line-added"> 707     blr(rscratch1);</span>
<span class="line-added"> 708 </span>
<span class="line-added"> 709     // call above kills the value in r1. Reload it.</span>
<span class="line-added"> 710     ldr(r1, Address(rfp, frame::interpreter_frame_sender_sp_offset * wordSize));</span>
<span class="line-added"> 711     bind(skip);</span>
<span class="line-added"> 712   }</span>
<span class="line-added"> 713 </span>
<span class="line-added"> 714 </span>
 715   // remove frame anchor
 716   leave();
 717   // If we&#39;re returning to interpreted code we will shortly be
 718   // adjusting SP to allow some space for ESP.  If we&#39;re returning to
 719   // compiled code the saved sender SP was saved in sender_sp, so this
 720   // restores it.
 721   andr(sp, esp, -16);
 722 }
 723 
 724 // Lock object
 725 //
 726 // Args:
 727 //      c_rarg1: BasicObjectLock to be used for locking
 728 //
 729 // Kills:
 730 //      r0
 731 //      c_rarg0, c_rarg1, c_rarg2, c_rarg3, .. (param regs)
 732 //      rscratch1, rscratch2 (scratch regs)
 733 void InterpreterMacroAssembler::lock_object(Register lock_reg)
 734 {
</pre>
<hr />
<pre>
 748     const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();
 749     const int mark_offset = lock_offset +
 750                             BasicLock::displaced_header_offset_in_bytes();
 751 
 752     Label slow_case;
 753 
 754     // Load object pointer into obj_reg %c_rarg3
 755     ldr(obj_reg, Address(lock_reg, obj_offset));
 756 
 757     if (UseBiasedLocking) {
 758       biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp, false, done, &amp;slow_case);
 759     }
 760 
 761     // Load (object-&gt;mark() | 1) into swap_reg
 762     ldr(rscratch1, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
 763     orr(swap_reg, rscratch1, 1);
 764 
 765     // Save (object-&gt;mark() | 1) into BasicLock&#39;s displaced header
 766     str(swap_reg, Address(lock_reg, mark_offset));
 767 
<span class="line-added"> 768     if (EnableValhalla &amp;&amp; !UseBiasedLocking) {</span>
<span class="line-added"> 769       // For slow path is_always_locked, using biased, which is never natural for !UseBiasLocking</span>
<span class="line-added"> 770       andr(swap_reg, swap_reg, ~((int) markWord::biased_lock_bit_in_place));</span>
<span class="line-added"> 771     }</span>
<span class="line-added"> 772 </span>
 773     assert(lock_offset == 0,
 774            &quot;displached header must be first word in BasicObjectLock&quot;);
 775 
 776     Label fail;
 777     if (PrintBiasedLockingStatistics) {
 778       Label fast;
 779       cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, fast, &amp;fail);
 780       bind(fast);
 781       atomic_incw(Address((address)BiasedLocking::fast_path_entry_count_addr()),
 782                   rscratch2, rscratch1, tmp);
 783       b(done);
 784       bind(fail);
 785     } else {
 786       cmpxchg_obj_header(swap_reg, lock_reg, obj_reg, rscratch1, done, /*fallthrough*/NULL);
 787     }
 788 
 789     // Test if the oopMark is an obvious stack pointer, i.e.,
 790     //  1) (mark &amp; 7) == 0, and
 791     //  2) rsp &lt;= mark &lt; mark + os::pagesize()
 792     //
</pre>
<hr />
<pre>
1718         profile_obj_type(tmp, mdo_arg_addr);
1719 
1720         int to_add = in_bytes(TypeStackSlotEntries::per_arg_size());
1721         off_to_args += to_add;
1722       }
1723 
1724       if (MethodData::profile_return()) {
1725         ldr(tmp, Address(mdp, in_bytes(TypeEntriesAtCall::cell_count_offset())));
1726         sub(tmp, tmp, TypeProfileArgsLimit*TypeStackSlotEntries::per_arg_count());
1727       }
1728 
1729       add(rscratch1, mdp, off_to_args);
1730       bind(done);
1731       mov(mdp, rscratch1);
1732 
1733       if (MethodData::profile_return()) {
1734         // We&#39;re right after the type profile for the last
1735         // argument. tmp is the number of cells left in the
1736         // CallTypeData/VirtualCallTypeData to reach its end. Non null
1737         // if there&#39;s a return to profile.
<span class="line-modified">1738         assert(SingleTypeEntry::static_cell_count() &lt; TypeStackSlotEntries::per_arg_count(), &quot;can&#39;t move past ret type&quot;);</span>
1739         add(mdp, mdp, tmp, LSL, exact_log2(DataLayout::cell_size));
1740       }
1741       str(mdp, Address(rfp, frame::interpreter_frame_mdp_offset * wordSize));
1742     } else {
1743       assert(MethodData::profile_return(), &quot;either profile call args or call ret&quot;);
1744       update_mdp_by_constant(mdp, in_bytes(TypeEntriesAtCall::return_only_size()));
1745     }
1746 
1747     // mdp points right after the end of the
1748     // CallTypeData/VirtualCallTypeData, right after the cells for the
1749     // return value type if there&#39;s one
1750 
1751     bind(profile_continue);
1752   }
1753 }
1754 
1755 void InterpreterMacroAssembler::profile_return_type(Register mdp, Register ret, Register tmp) {
1756   assert_different_registers(mdp, ret, tmp, rbcp);
1757   if (ProfileInterpreter &amp;&amp; MethodData::profile_return()) {
1758     Label profile_continue, done;
</pre>
<hr />
<pre>
1764 
1765       // If we don&#39;t profile all invoke bytecodes we must make sure
1766       // it&#39;s a bytecode we indeed profile. We can&#39;t go back to the
1767       // begining of the ProfileData we intend to update to check its
1768       // type because we&#39;re right after it and we don&#39;t known its
1769       // length
1770       Label do_profile;
1771       ldrb(rscratch1, Address(rbcp, 0));
1772       cmp(rscratch1, (u1)Bytecodes::_invokedynamic);
1773       br(Assembler::EQ, do_profile);
1774       cmp(rscratch1, (u1)Bytecodes::_invokehandle);
1775       br(Assembler::EQ, do_profile);
1776       get_method(tmp);
1777       ldrh(rscratch1, Address(tmp, Method::intrinsic_id_offset_in_bytes()));
1778       subs(zr, rscratch1, vmIntrinsics::_compiledLambdaForm);
1779       br(Assembler::NE, profile_continue);
1780 
1781       bind(do_profile);
1782     }
1783 
<span class="line-modified">1784     Address mdo_ret_addr(mdp, -in_bytes(SingleTypeEntry::size()));</span>
1785     mov(tmp, ret);
1786     profile_obj_type(tmp, mdo_ret_addr);
1787 
1788     bind(profile_continue);
1789   }
1790 }
1791 
1792 void InterpreterMacroAssembler::profile_parameters_type(Register mdp, Register tmp1, Register tmp2) {
1793   assert_different_registers(rscratch1, rscratch2, mdp, tmp1, tmp2);
1794   if (ProfileInterpreter &amp;&amp; MethodData::profile_parameters()) {
1795     Label profile_continue, done;
1796 
1797     test_method_data_pointer(mdp, profile_continue);
1798 
1799     // Load the offset of the area within the MDO used for
1800     // parameters. If it&#39;s negative we&#39;re not profiling any parameters
1801     ldrw(tmp1, Address(mdp, in_bytes(MethodData::parameters_type_data_di_offset()) - in_bytes(MethodData::data_offset())));
1802     tbnz(tmp1, 31, profile_continue);  // i.e. sign bit set
1803 
1804     // Compute a pointer to the area for parameters from the offset
</pre>
</td>
</tr>
</table>
<center><a href="gc/g1/g1BarrierSetAssembler_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>