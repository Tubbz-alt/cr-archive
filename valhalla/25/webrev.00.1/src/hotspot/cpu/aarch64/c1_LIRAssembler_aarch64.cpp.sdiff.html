<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="frame_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;asm/assembler.hpp&quot;
  29 #include &quot;c1/c1_CodeStubs.hpp&quot;
  30 #include &quot;c1/c1_Compilation.hpp&quot;
  31 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  32 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  33 #include &quot;c1/c1_Runtime1.hpp&quot;
  34 #include &quot;c1/c1_ValueStack.hpp&quot;
  35 #include &quot;ci/ciArrayKlass.hpp&quot;
  36 #include &quot;ci/ciInstance.hpp&quot;

  37 #include &quot;code/compiledIC.hpp&quot;
  38 #include &quot;gc/shared/collectedHeap.hpp&quot;
  39 #include &quot;nativeInst_aarch64.hpp&quot;
  40 #include &quot;oops/objArrayKlass.hpp&quot;

  41 #include &quot;runtime/frame.inline.hpp&quot;
  42 #include &quot;runtime/sharedRuntime.hpp&quot;
  43 #include &quot;utilities/powerOfTwo.hpp&quot;
  44 #include &quot;vmreg_aarch64.inline.hpp&quot;
  45 
  46 
  47 #ifndef PRODUCT
  48 #define COMMENT(x)   do { __ block_comment(x); } while (0)
  49 #else
  50 #define COMMENT(x)
  51 #endif
  52 
  53 NEEDS_CLEANUP // remove this definitions ?
  54 const Register IC_Klass    = rscratch2;   // where the IC klass is cached
  55 const Register SYNC_header = r0;   // synchronization header
  56 const Register SHIFT_count = r0;   // where count for shift operations must be
  57 
  58 #define __ _masm-&gt;
  59 
  60 
</pre>
<hr />
<pre>
 211   // FIXME: This needs to be much more clever.  See x86.
 212 }
 213 
 214 
 215 void LIR_Assembler::osr_entry() {
 216   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 217   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 218   ValueStack* entry_state = osr_entry-&gt;state();
 219   int number_of_locks = entry_state-&gt;locks_size();
 220 
 221   // we jump here if osr happens with the interpreter
 222   // state set up to continue at the beginning of the
 223   // loop that triggered osr - in particular, we have
 224   // the following registers setup:
 225   //
 226   // r2: osr buffer
 227   //
 228 
 229   // build frame
 230   ciMethod* m = compilation()-&gt;method();
<span class="line-modified"> 231   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());</span>
 232 
 233   // OSR buffer is
 234   //
 235   // locals[nlocals-1..0]
 236   // monitors[0..number_of_locks]
 237   //
 238   // locals is a direct copy of the interpreter frame so in the osr buffer
 239   // so first slot in the local array is the last local from the interpreter
 240   // and last slot is local[0] (receiver) from the interpreter
 241   //
 242   // Similarly with locks. The first lock slot in the osr buffer is the nth lock
 243   // from the interpreter frame, the nth lock slot in the osr buffer is 0th lock
 244   // in the interpreter frame (the method lock if a sync method)
 245 
 246   // Initialize monitors in the compiled activation.
 247   //   r2: pointer to osr buffer
 248   //
 249   // All other registers are dead at this point and the locals will be
 250   // copied into place by code emitted in the IR.
 251 
</pre>
<hr />
<pre>
 426   MonitorExitStub* stub = NULL;
 427   if (method()-&gt;is_synchronized()) {
 428     monitor_address(0, FrameMap::r0_opr);
 429     stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);
 430     __ unlock_object(r5, r4, r0, *stub-&gt;entry());
 431     __ bind(*stub-&gt;continuation());
 432   }
 433 
 434   if (compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 435     __ mov(c_rarg0, rthread);
 436     __ mov_metadata(c_rarg1, method()-&gt;constant_encoding());
 437     __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit), c_rarg0, c_rarg1);
 438   }
 439 
 440   if (method()-&gt;is_synchronized() || compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 441     __ mov(r0, r19);  // Restore the exception
 442   }
 443 
 444   // remove the activation and dispatch to the unwind handler
 445   __ block_comment(&quot;remove_frame and dispatch to the unwind handler&quot;);
<span class="line-modified"> 446   __ remove_frame(initial_frame_size_in_bytes());</span>
 447   __ far_jump(RuntimeAddress(Runtime1::entry_for(Runtime1::unwind_exception_id)));
 448 
 449   // Emit the slow path assembly
 450   if (stub != NULL) {
 451     stub-&gt;emit_code(this);
 452   }
 453 
 454   return offset;
 455 }
 456 
 457 
 458 int LIR_Assembler::emit_deopt_handler() {
 459   // if the last instruction is a call (typically to do a throw which
 460   // is coming at the end after block reordering) the return address
 461   // must still point into the code area in order to avoid assertion
 462   // failures when searching for the corresponding bci =&gt; add a nop
 463   // (was bug 5/14/1999 - gri)
 464   __ nop();
 465 
 466   // generate code for exception handler
</pre>
<hr />
<pre>
 477   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 478   guarantee(code_offset() - offset &lt;= deopt_handler_size(), &quot;overflow&quot;);
 479   __ end_a_stub();
 480 
 481   return offset;
 482 }
 483 
 484 void LIR_Assembler::add_debug_info_for_branch(address adr, CodeEmitInfo* info) {
 485   _masm-&gt;code_section()-&gt;relocate(adr, relocInfo::poll_type);
 486   int pc_offset = code_offset();
 487   flush_debug_info(pc_offset);
 488   info-&gt;record_debug_info(compilation()-&gt;debug_info_recorder(), pc_offset);
 489   if (info-&gt;exception_handlers() != NULL) {
 490     compilation()-&gt;add_exception_handlers_for_pco(pc_offset, info-&gt;exception_handlers());
 491   }
 492 }
 493 
 494 void LIR_Assembler::return_op(LIR_Opr result) {
 495   assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == r0, &quot;word returns are in r0,&quot;);
 496 
















 497   // Pop the stack before the safepoint code
<span class="line-modified"> 498   __ remove_frame(initial_frame_size_in_bytes());</span>
 499 
 500   if (StackReservedPages &gt; 0 &amp;&amp; compilation()-&gt;has_reserved_stack_access()) {
 501     __ reserved_stack_check();
 502   }
 503 
 504   __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 505   __ ret(lr);
 506 }
 507 




 508 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
 509   guarantee(info != NULL, &quot;Shouldn&#39;t be NULL&quot;);
 510   __ get_polling_page(rscratch1, relocInfo::poll_type);
 511   add_debug_info_for_branch(info);  // This isn&#39;t just debug info:
 512                                     // it&#39;s the oop map
 513   __ read_polling_page(rscratch1, relocInfo::poll_type);
 514   return __ offset();
 515 }
 516 
 517 
 518 void LIR_Assembler::move_regs(Register from_reg, Register to_reg) {
 519   if (from_reg == r31_sp)
 520     from_reg = sp;
 521   if (to_reg == r31_sp)
 522     to_reg = sp;
 523   __ mov(to_reg, from_reg);
 524 }
 525 
 526 void LIR_Assembler::swap_reg(Register a, Register b) { Unimplemented(); }
 527 
</pre>
<hr />
<pre>
 533 
 534   switch (c-&gt;type()) {
 535     case T_INT: {
 536       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 537       __ movw(dest-&gt;as_register(), c-&gt;as_jint());
 538       break;
 539     }
 540 
 541     case T_ADDRESS: {
 542       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 543       __ mov(dest-&gt;as_register(), c-&gt;as_jint());
 544       break;
 545     }
 546 
 547     case T_LONG: {
 548       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 549       __ mov(dest-&gt;as_register_lo(), (intptr_t)c-&gt;as_jlong());
 550       break;
 551     }
 552 

 553     case T_OBJECT: {
<span class="line-modified"> 554         if (patch_code == lir_patch_none) {</span>
<span class="line-removed"> 555           jobject2reg(c-&gt;as_jobject(), dest-&gt;as_register());</span>
<span class="line-removed"> 556         } else {</span>
 557           jobject2reg_with_patching(dest-&gt;as_register(), info);


 558         }
 559       break;
 560     }
 561 
 562     case T_METADATA: {
 563       if (patch_code != lir_patch_none) {
 564         klass2reg_with_patching(dest-&gt;as_register(), info);
 565       } else {
 566         __ mov_metadata(dest-&gt;as_register(), c-&gt;as_metadata());
 567       }
 568       break;
 569     }
 570 
 571     case T_FLOAT: {
 572       if (__ operand_valid_for_float_immediate(c-&gt;as_jfloat())) {
 573         __ fmovs(dest-&gt;as_float_reg(), (c-&gt;as_jfloat()));
 574       } else {
 575         __ adr(rscratch1, InternalAddress(float_constant(c-&gt;as_jfloat())));
 576         __ ldrs(dest-&gt;as_float_reg(), Address(rscratch1));
 577       }
</pre>
<hr />
<pre>
 579     }
 580 
 581     case T_DOUBLE: {
 582       if (__ operand_valid_for_float_immediate(c-&gt;as_jdouble())) {
 583         __ fmovd(dest-&gt;as_double_reg(), (c-&gt;as_jdouble()));
 584       } else {
 585         __ adr(rscratch1, InternalAddress(double_constant(c-&gt;as_jdouble())));
 586         __ ldrd(dest-&gt;as_double_reg(), Address(rscratch1));
 587       }
 588       break;
 589     }
 590 
 591     default:
 592       ShouldNotReachHere();
 593   }
 594 }
 595 
 596 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 597   LIR_Const* c = src-&gt;as_constant_ptr();
 598   switch (c-&gt;type()) {

 599   case T_OBJECT:
 600     {
 601       if (! c-&gt;as_jobject())
 602         __ str(zr, frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()));
 603       else {
 604         const2reg(src, FrameMap::rscratch1_opr, lir_patch_none, NULL);
 605         reg2stack(FrameMap::rscratch1_opr, dest, c-&gt;type(), false);
 606       }
 607     }
 608     break;
 609   case T_ADDRESS:
 610     {
 611       const2reg(src, FrameMap::rscratch1_opr, lir_patch_none, NULL);
 612       reg2stack(FrameMap::rscratch1_opr, dest, c-&gt;type(), false);
 613     }
 614   case T_INT:
 615   case T_FLOAT:
 616     {
 617       Register reg = zr;
 618       if (c-&gt;as_jint_bits() == 0)
</pre>
<hr />
<pre>
 645 void LIR_Assembler::const2mem(LIR_Opr src, LIR_Opr dest, BasicType type, CodeEmitInfo* info, bool wide) {
 646   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 647   LIR_Const* c = src-&gt;as_constant_ptr();
 648   LIR_Address* to_addr = dest-&gt;as_address_ptr();
 649 
 650   void (Assembler::* insn)(Register Rt, const Address &amp;adr);
 651 
 652   switch (type) {
 653   case T_ADDRESS:
 654     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 655     insn = &amp;Assembler::str;
 656     break;
 657   case T_LONG:
 658     assert(c-&gt;as_jlong() == 0, &quot;should be&quot;);
 659     insn = &amp;Assembler::str;
 660     break;
 661   case T_INT:
 662     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 663     insn = &amp;Assembler::strw;
 664     break;

 665   case T_OBJECT:
 666   case T_ARRAY:


 667     assert(c-&gt;as_jobject() == 0, &quot;should be&quot;);
 668     if (UseCompressedOops &amp;&amp; !wide) {
 669       insn = &amp;Assembler::strw;
 670     } else {
 671       insn = &amp;Assembler::str;
 672     }
 673     break;
 674   case T_CHAR:
 675   case T_SHORT:
 676     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 677     insn = &amp;Assembler::strh;
 678     break;
 679   case T_BOOLEAN:
 680   case T_BYTE:
 681     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 682     insn = &amp;Assembler::strb;
 683     break;
 684   default:
 685     ShouldNotReachHere();
 686     insn = &amp;Assembler::str;  // unreachable
 687   }
 688 
 689   if (info) add_debug_info_for_null_check_here(info);
 690   (_masm-&gt;*insn)(zr, as_Address(to_addr, rscratch1));
 691 }
 692 
 693 void LIR_Assembler::reg2reg(LIR_Opr src, LIR_Opr dest) {
 694   assert(src-&gt;is_register(), &quot;should not call otherwise&quot;);
 695   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
 696 
 697   // move between cpu-registers
 698   if (dest-&gt;is_single_cpu()) {
 699     if (src-&gt;type() == T_LONG) {
 700       // Can do LONG -&gt; OBJECT
 701       move_regs(src-&gt;as_register_lo(), dest-&gt;as_register());
 702       return;
 703     }
 704     assert(src-&gt;is_single_cpu(), &quot;must match&quot;);
<span class="line-modified"> 705     if (src-&gt;type() == T_OBJECT) {</span>
 706       __ verify_oop(src-&gt;as_register());
 707     }
 708     move_regs(src-&gt;as_register(), dest-&gt;as_register());
 709 
 710   } else if (dest-&gt;is_double_cpu()) {
 711     if (is_reference_type(src-&gt;type())) {
 712       // Surprising to me but we can see move of a long to t_object
 713       __ verify_oop(src-&gt;as_register());
 714       move_regs(src-&gt;as_register(), dest-&gt;as_register_lo());
 715       return;
 716     }
 717     assert(src-&gt;is_double_cpu(), &quot;must match&quot;);
 718     Register f_lo = src-&gt;as_register_lo();
 719     Register f_hi = src-&gt;as_register_hi();
 720     Register t_lo = dest-&gt;as_register_lo();
 721     Register t_hi = dest-&gt;as_register_hi();
 722     assert(f_hi == f_lo, &quot;must be same&quot;);
 723     assert(t_hi == t_lo, &quot;must be same&quot;);
 724     move_regs(f_lo, t_lo);
 725 
</pre>
<hr />
<pre>
 779 
 780     if (UseCompressedOops &amp;&amp; !wide) {
 781       __ encode_heap_oop(compressed_src, src-&gt;as_register());
 782     } else {
 783       compressed_src = src-&gt;as_register();
 784     }
 785   }
 786 
 787   int null_check_here = code_offset();
 788   switch (type) {
 789     case T_FLOAT: {
 790       __ strs(src-&gt;as_float_reg(), as_Address(to_addr));
 791       break;
 792     }
 793 
 794     case T_DOUBLE: {
 795       __ strd(src-&gt;as_double_reg(), as_Address(to_addr));
 796       break;
 797     }
 798 

 799     case T_ARRAY:   // fall through
 800     case T_OBJECT:  // fall through
 801       if (UseCompressedOops &amp;&amp; !wide) {
 802         __ strw(compressed_src, as_Address(to_addr, rscratch2));
 803       } else {
 804          __ str(compressed_src, as_Address(to_addr));
 805       }
 806       break;
 807     case T_METADATA:
 808       // We get here to store a method pointer to the stack to pass to
 809       // a dtrace runtime call. This can&#39;t work on 64 bit with
 810       // compressed klass ptrs: T_METADATA can be a compressed klass
 811       // ptr or a 64 bit method pointer.
 812       ShouldNotReachHere();
 813       __ str(src-&gt;as_register(), as_Address(to_addr));
 814       break;
 815     case T_ADDRESS:
 816       __ str(src-&gt;as_register(), as_Address(to_addr));
 817       break;
 818     case T_INT:
</pre>
<hr />
<pre>
 904   add_call_info_here(info);
 905 }
 906 
 907 void LIR_Assembler::stack2stack(LIR_Opr src, LIR_Opr dest, BasicType type) {
 908 
 909   LIR_Opr temp;
 910   if (type == T_LONG || type == T_DOUBLE)
 911     temp = FrameMap::rscratch1_long_opr;
 912   else
 913     temp = FrameMap::rscratch1_opr;
 914 
 915   stack2reg(src, temp, src-&gt;type());
 916   reg2stack(temp, dest, dest-&gt;type(), false);
 917 }
 918 
 919 
 920 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
 921   LIR_Address* addr = src-&gt;as_address_ptr();
 922   LIR_Address* from_addr = src-&gt;as_address_ptr();
 923 
<span class="line-modified"> 924   if (addr-&gt;base()-&gt;type() == T_OBJECT) {</span>
 925     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
 926   }
 927 
 928   if (patch_code != lir_patch_none) {
 929     deoptimize_trap(info);
 930     return;
 931   }
 932 
 933   if (info != NULL) {
 934     add_debug_info_for_null_check_here(info);
 935   }
 936   int null_check_here = code_offset();
 937   switch (type) {
 938     case T_FLOAT: {
 939       __ ldrs(dest-&gt;as_float_reg(), as_Address(from_addr));
 940       break;
 941     }
 942 
 943     case T_DOUBLE: {
 944       __ ldrd(dest-&gt;as_double_reg(), as_Address(from_addr));
 945       break;
 946     }
 947 

 948     case T_ARRAY:   // fall through
 949     case T_OBJECT:  // fall through
 950       if (UseCompressedOops &amp;&amp; !wide) {
 951         __ ldrw(dest-&gt;as_register(), as_Address(from_addr));
 952       } else {
 953          __ ldr(dest-&gt;as_register(), as_Address(from_addr));
 954       }
 955       break;
 956     case T_METADATA:
 957       // We get here to store a method pointer to the stack to pass to
 958       // a dtrace runtime call. This can&#39;t work on 64 bit with
 959       // compressed klass ptrs: T_METADATA can be a compressed klass
 960       // ptr or a 64 bit method pointer.
 961       ShouldNotReachHere();
 962       __ ldr(dest-&gt;as_register(), as_Address(from_addr));
 963       break;
 964     case T_ADDRESS:
 965       // FIXME: OMG this is a horrible kludge.  Any offset from an
 966       // address that matches klass_offset_in_bytes() will be loaded
 967       // as a word, not a long.
</pre>
<hr />
<pre>
 993       break;
 994     case T_SHORT:
 995       __ ldrsh(dest-&gt;as_register(), as_Address(from_addr));
 996       break;
 997 
 998     default:
 999       ShouldNotReachHere();
1000   }
1001 
1002   if (is_reference_type(type)) {
1003     if (UseCompressedOops &amp;&amp; !wide) {
1004       __ decode_heap_oop(dest-&gt;as_register());
1005     }
1006 
1007     if (!UseZGC) {
1008       // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
1009       __ verify_oop(dest-&gt;as_register());
1010     }
1011   } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1012     if (UseCompressedClassPointers) {

1013       __ decode_klass_not_null(dest-&gt;as_register());


1014     }
1015   }
1016 }
1017 














1018 
1019 int LIR_Assembler::array_element_size(BasicType type) const {
1020   int elem_size = type2aelembytes(type);
1021   return exact_log2(elem_size);
1022 }
1023 
1024 
1025 void LIR_Assembler::emit_op3(LIR_Op3* op) {
1026   switch (op-&gt;code()) {
1027   case lir_idiv:
1028   case lir_irem:
1029     arithmetic_idiv(op-&gt;code(),
1030                     op-&gt;in_opr1(),
1031                     op-&gt;in_opr2(),
1032                     op-&gt;in_opr3(),
1033                     op-&gt;result_opr(),
1034                     op-&gt;info());
1035     break;
1036   case lir_fmad:
1037     __ fmaddd(op-&gt;result_opr()-&gt;as_double_reg(),
</pre>
<hr />
<pre>
1189     __ ldrb(rscratch1, Address(op-&gt;klass()-&gt;as_register(),
1190                                InstanceKlass::init_state_offset()));
1191     __ cmpw(rscratch1, InstanceKlass::fully_initialized);
1192     add_debug_info_for_null_check_here(op-&gt;stub()-&gt;info());
1193     __ br(Assembler::NE, *op-&gt;stub()-&gt;entry());
1194   }
1195   __ allocate_object(op-&gt;obj()-&gt;as_register(),
1196                      op-&gt;tmp1()-&gt;as_register(),
1197                      op-&gt;tmp2()-&gt;as_register(),
1198                      op-&gt;header_size(),
1199                      op-&gt;object_size(),
1200                      op-&gt;klass()-&gt;as_register(),
1201                      *op-&gt;stub()-&gt;entry());
1202   __ bind(*op-&gt;stub()-&gt;continuation());
1203 }
1204 
1205 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
1206   Register len =  op-&gt;len()-&gt;as_register();
1207   __ uxtw(len, len);
1208 
<span class="line-modified">1209   if (UseSlowPath ||</span>
1210       (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||
1211       (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {
1212     __ b(*op-&gt;stub()-&gt;entry());
1213   } else {
1214     Register tmp1 = op-&gt;tmp1()-&gt;as_register();
1215     Register tmp2 = op-&gt;tmp2()-&gt;as_register();
1216     Register tmp3 = op-&gt;tmp3()-&gt;as_register();
1217     if (len == tmp1) {
1218       tmp1 = tmp3;
1219     } else if (len == tmp2) {
1220       tmp2 = tmp3;
1221     } else if (len == tmp3) {
1222       // everything is ok
1223     } else {
1224       __ mov(tmp3, len);
1225     }
1226     __ allocate_array(op-&gt;obj()-&gt;as_register(),
1227                       len,
1228                       tmp1,
1229                       tmp2,
</pre>
<hr />
<pre>
1501     __ bind(success);
1502     if (dst != obj) {
1503       __ mov(dst, obj);
1504     }
1505   } else if (code == lir_instanceof) {
1506     Register obj = op-&gt;object()-&gt;as_register();
1507     Register dst = op-&gt;result_opr()-&gt;as_register();
1508     Label success, failure, done;
1509     emit_typecheck_helper(op, &amp;success, &amp;failure, &amp;failure);
1510     __ bind(failure);
1511     __ mov(dst, zr);
1512     __ b(done);
1513     __ bind(success);
1514     __ mov(dst, 1);
1515     __ bind(done);
1516   } else {
1517     ShouldNotReachHere();
1518   }
1519 }
1520 


























































































































1521 void LIR_Assembler::casw(Register addr, Register newval, Register cmpval) {
1522   __ cmpxchg(addr, cmpval, newval, Assembler::word, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
1523   __ cset(rscratch1, Assembler::NE);
1524   __ membar(__ AnyAny);
1525 }
1526 
1527 void LIR_Assembler::casl(Register addr, Register newval, Register cmpval) {
1528   __ cmpxchg(addr, cmpval, newval, Assembler::xword, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
1529   __ cset(rscratch1, Assembler::NE);
1530   __ membar(__ AnyAny);
1531 }
1532 
1533 
1534 void LIR_Assembler::emit_compare_and_swap(LIR_OpCompareAndSwap* op) {
1535   assert(VM_Version::supports_cx8(), &quot;wrong machine&quot;);
1536   Register addr;
1537   if (op-&gt;addr()-&gt;is_register()) {
1538     addr = as_reg(op-&gt;addr());
1539   } else {
1540     assert(op-&gt;addr()-&gt;is_address(), &quot;what else?&quot;);
</pre>
<hr />
<pre>
1944     }
1945 
1946     if (opr2-&gt;is_constant()) {
1947       bool is_32bit = false; // width of register operand
1948       jlong imm;
1949 
1950       switch(opr2-&gt;type()) {
1951       case T_INT:
1952         imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
1953         is_32bit = true;
1954         break;
1955       case T_LONG:
1956         imm = opr2-&gt;as_constant_ptr()-&gt;as_jlong();
1957         break;
1958       case T_ADDRESS:
1959         imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
1960         break;
1961       case T_METADATA:
1962         imm = (intptr_t)(opr2-&gt;as_constant_ptr()-&gt;as_metadata());
1963         break;

1964       case T_OBJECT:
1965       case T_ARRAY:
1966         jobject2reg(opr2-&gt;as_constant_ptr()-&gt;as_jobject(), rscratch1);
1967         __ cmpoop(reg1, rscratch1);
1968         return;
1969       default:
1970         ShouldNotReachHere();
1971         imm = 0;  // unreachable
1972         break;
1973       }
1974 
1975       if (Assembler::operand_valid_for_add_sub_immediate(imm)) {
1976         if (is_32bit)
1977           __ cmpw(reg1, imm);
1978         else
1979           __ subs(zr, reg1, imm);
1980         return;
1981       } else {
1982         __ mov(rscratch1, imm);
1983         if (is_32bit)
</pre>
<hr />
<pre>
2110   __ b(_unwind_handler_entry);
2111 }
2112 
2113 
2114 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, LIR_Opr count, LIR_Opr dest, LIR_Opr tmp) {
2115   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2116   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2117 
2118   switch (left-&gt;type()) {
2119     case T_INT: {
2120       switch (code) {
2121       case lir_shl:  __ lslvw (dreg, lreg, count-&gt;as_register()); break;
2122       case lir_shr:  __ asrvw (dreg, lreg, count-&gt;as_register()); break;
2123       case lir_ushr: __ lsrvw (dreg, lreg, count-&gt;as_register()); break;
2124       default:
2125         ShouldNotReachHere();
2126         break;
2127       }
2128       break;
2129     case T_LONG:

2130     case T_ADDRESS:
2131     case T_OBJECT:
2132       switch (code) {
2133       case lir_shl:  __ lslv (dreg, lreg, count-&gt;as_register()); break;
2134       case lir_shr:  __ asrv (dreg, lreg, count-&gt;as_register()); break;
2135       case lir_ushr: __ lsrv (dreg, lreg, count-&gt;as_register()); break;
2136       default:
2137         ShouldNotReachHere();
2138         break;
2139       }
2140       break;
2141     default:
2142       ShouldNotReachHere();
2143       break;
2144     }
2145   }
2146 }
2147 
2148 
2149 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, jint count, LIR_Opr dest) {
2150   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2151   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2152 
2153   switch (left-&gt;type()) {
2154     case T_INT: {
2155       switch (code) {
2156       case lir_shl:  __ lslw (dreg, lreg, count); break;
2157       case lir_shr:  __ asrw (dreg, lreg, count); break;
2158       case lir_ushr: __ lsrw (dreg, lreg, count); break;
2159       default:
2160         ShouldNotReachHere();
2161         break;
2162       }
2163       break;
2164     case T_LONG:
2165     case T_ADDRESS:

2166     case T_OBJECT:
2167       switch (code) {
2168       case lir_shl:  __ lsl (dreg, lreg, count); break;
2169       case lir_shr:  __ asr (dreg, lreg, count); break;
2170       case lir_ushr: __ lsr (dreg, lreg, count); break;
2171       default:
2172         ShouldNotReachHere();
2173         break;
2174       }
2175       break;
2176     default:
2177       ShouldNotReachHere();
2178       break;
2179     }
2180   }
2181 }
2182 
2183 
2184 void LIR_Assembler::store_parameter(Register r, int offset_from_rsp_in_words) {
2185   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
</pre>
<hr />
<pre>
2190 
2191 
2192 void LIR_Assembler::store_parameter(jint c,     int offset_from_rsp_in_words) {
2193   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
2194   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
2195   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
2196   __ mov (rscratch1, c);
2197   __ str (rscratch1, Address(sp, offset_from_rsp_in_bytes));
2198 }
2199 
2200 
2201 void LIR_Assembler::store_parameter(jobject o,  int offset_from_rsp_in_words) {
2202   ShouldNotReachHere();
2203   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
2204   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
2205   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
2206   __ lea(rscratch1, __ constant_oop_address(o));
2207   __ str(rscratch1, Address(sp, offset_from_rsp_in_bytes));
2208 }
2209 













2210 
2211 // This code replaces a call to arraycopy; no exception may
2212 // be thrown in this code, they must be thrown in the System.arraycopy
2213 // activation frame; we could save some checks if this would not be the case
2214 void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
2215   ciArrayKlass* default_type = op-&gt;expected_type();
2216   Register src = op-&gt;src()-&gt;as_register();
2217   Register dst = op-&gt;dst()-&gt;as_register();
2218   Register src_pos = op-&gt;src_pos()-&gt;as_register();
2219   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
2220   Register length  = op-&gt;length()-&gt;as_register();
2221   Register tmp = op-&gt;tmp()-&gt;as_register();
2222 
2223   __ resolve(ACCESS_READ, src);
2224   __ resolve(ACCESS_WRITE, dst);
2225 
2226   CodeStub* stub = op-&gt;stub();
2227   int flags = op-&gt;flags();
2228   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
2229   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
2230 
















2231   // if we don&#39;t know anything, just go through the generic arraycopy
2232   if (default_type == NULL // || basic_type == T_OBJECT
2233       ) {
2234     Label done;
2235     assert(src == r1 &amp;&amp; src_pos == r2, &quot;mismatch in calling convention&quot;);
2236 
2237     // Save the arguments in case the generic arraycopy fails and we
2238     // have to fall back to the JNI stub
2239     __ stp(dst,     dst_pos, Address(sp, 0*BytesPerWord));
2240     __ stp(length,  src_pos, Address(sp, 2*BytesPerWord));
2241     __ str(src,              Address(sp, 4*BytesPerWord));
2242 
2243     address copyfunc_addr = StubRoutines::generic_arraycopy();
2244     assert(copyfunc_addr != NULL, &quot;generic arraycopy stub required&quot;);
2245 
2246     // The arguments are in java calling convention so we shift them
2247     // to C convention
2248     assert_different_registers(c_rarg0, j_rarg1, j_rarg2, j_rarg3, j_rarg4);
2249     __ mov(c_rarg0, j_rarg0);
2250     assert_different_registers(c_rarg1, j_rarg2, j_rarg3, j_rarg4);
</pre>
<hr />
<pre>
3111 #endif
3112 }
3113 
3114 void LIR_Assembler::atomic_op(LIR_Code code, LIR_Opr src, LIR_Opr data, LIR_Opr dest, LIR_Opr tmp_op) {
3115   Address addr = as_Address(src-&gt;as_address_ptr());
3116   BasicType type = src-&gt;type();
3117   bool is_oop = is_reference_type(type);
3118 
3119   void (MacroAssembler::* add)(Register prev, RegisterOrConstant incr, Register addr);
3120   void (MacroAssembler::* xchg)(Register prev, Register newv, Register addr);
3121 
3122   switch(type) {
3123   case T_INT:
3124     xchg = &amp;MacroAssembler::atomic_xchgalw;
3125     add = &amp;MacroAssembler::atomic_addalw;
3126     break;
3127   case T_LONG:
3128     xchg = &amp;MacroAssembler::atomic_xchgal;
3129     add = &amp;MacroAssembler::atomic_addal;
3130     break;

3131   case T_OBJECT:
3132   case T_ARRAY:
3133     if (UseCompressedOops) {
3134       xchg = &amp;MacroAssembler::atomic_xchgalw;
3135       add = &amp;MacroAssembler::atomic_addalw;
3136     } else {
3137       xchg = &amp;MacroAssembler::atomic_xchgal;
3138       add = &amp;MacroAssembler::atomic_addal;
3139     }
3140     break;
3141   default:
3142     ShouldNotReachHere();
3143     xchg = &amp;MacroAssembler::atomic_xchgal;
3144     add = &amp;MacroAssembler::atomic_addal; // unreachable
3145   }
3146 
3147   switch (code) {
3148   case lir_xadd:
3149     {
3150       RegisterOrConstant inc;
</pre>
</td>
<td>
<hr />
<pre>
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
  23  *
  24  */
  25 
  26 #include &quot;precompiled.hpp&quot;
  27 #include &quot;asm/macroAssembler.inline.hpp&quot;
  28 #include &quot;asm/assembler.hpp&quot;
  29 #include &quot;c1/c1_CodeStubs.hpp&quot;
  30 #include &quot;c1/c1_Compilation.hpp&quot;
  31 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  32 #include &quot;c1/c1_MacroAssembler.hpp&quot;
  33 #include &quot;c1/c1_Runtime1.hpp&quot;
  34 #include &quot;c1/c1_ValueStack.hpp&quot;
  35 #include &quot;ci/ciArrayKlass.hpp&quot;
  36 #include &quot;ci/ciInstance.hpp&quot;
<span class="line-added">  37 #include &quot;ci/ciValueKlass.hpp&quot;</span>
  38 #include &quot;code/compiledIC.hpp&quot;
  39 #include &quot;gc/shared/collectedHeap.hpp&quot;
  40 #include &quot;nativeInst_aarch64.hpp&quot;
  41 #include &quot;oops/objArrayKlass.hpp&quot;
<span class="line-added">  42 #include &quot;oops/oop.inline.hpp&quot;</span>
  43 #include &quot;runtime/frame.inline.hpp&quot;
  44 #include &quot;runtime/sharedRuntime.hpp&quot;
  45 #include &quot;utilities/powerOfTwo.hpp&quot;
  46 #include &quot;vmreg_aarch64.inline.hpp&quot;
  47 
  48 
  49 #ifndef PRODUCT
  50 #define COMMENT(x)   do { __ block_comment(x); } while (0)
  51 #else
  52 #define COMMENT(x)
  53 #endif
  54 
  55 NEEDS_CLEANUP // remove this definitions ?
  56 const Register IC_Klass    = rscratch2;   // where the IC klass is cached
  57 const Register SYNC_header = r0;   // synchronization header
  58 const Register SHIFT_count = r0;   // where count for shift operations must be
  59 
  60 #define __ _masm-&gt;
  61 
  62 
</pre>
<hr />
<pre>
 213   // FIXME: This needs to be much more clever.  See x86.
 214 }
 215 
 216 
 217 void LIR_Assembler::osr_entry() {
 218   offsets()-&gt;set_value(CodeOffsets::OSR_Entry, code_offset());
 219   BlockBegin* osr_entry = compilation()-&gt;hir()-&gt;osr_entry();
 220   ValueStack* entry_state = osr_entry-&gt;state();
 221   int number_of_locks = entry_state-&gt;locks_size();
 222 
 223   // we jump here if osr happens with the interpreter
 224   // state set up to continue at the beginning of the
 225   // loop that triggered osr - in particular, we have
 226   // the following registers setup:
 227   //
 228   // r2: osr buffer
 229   //
 230 
 231   // build frame
 232   ciMethod* m = compilation()-&gt;method();
<span class="line-modified"> 233   __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), needs_stack_repair(), NULL);</span>
 234 
 235   // OSR buffer is
 236   //
 237   // locals[nlocals-1..0]
 238   // monitors[0..number_of_locks]
 239   //
 240   // locals is a direct copy of the interpreter frame so in the osr buffer
 241   // so first slot in the local array is the last local from the interpreter
 242   // and last slot is local[0] (receiver) from the interpreter
 243   //
 244   // Similarly with locks. The first lock slot in the osr buffer is the nth lock
 245   // from the interpreter frame, the nth lock slot in the osr buffer is 0th lock
 246   // in the interpreter frame (the method lock if a sync method)
 247 
 248   // Initialize monitors in the compiled activation.
 249   //   r2: pointer to osr buffer
 250   //
 251   // All other registers are dead at this point and the locals will be
 252   // copied into place by code emitted in the IR.
 253 
</pre>
<hr />
<pre>
 428   MonitorExitStub* stub = NULL;
 429   if (method()-&gt;is_synchronized()) {
 430     monitor_address(0, FrameMap::r0_opr);
 431     stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);
 432     __ unlock_object(r5, r4, r0, *stub-&gt;entry());
 433     __ bind(*stub-&gt;continuation());
 434   }
 435 
 436   if (compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 437     __ mov(c_rarg0, rthread);
 438     __ mov_metadata(c_rarg1, method()-&gt;constant_encoding());
 439     __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit), c_rarg0, c_rarg1);
 440   }
 441 
 442   if (method()-&gt;is_synchronized() || compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 443     __ mov(r0, r19);  // Restore the exception
 444   }
 445 
 446   // remove the activation and dispatch to the unwind handler
 447   __ block_comment(&quot;remove_frame and dispatch to the unwind handler&quot;);
<span class="line-modified"> 448   __ remove_frame(initial_frame_size_in_bytes(), needs_stack_repair());</span>
 449   __ far_jump(RuntimeAddress(Runtime1::entry_for(Runtime1::unwind_exception_id)));
 450 
 451   // Emit the slow path assembly
 452   if (stub != NULL) {
 453     stub-&gt;emit_code(this);
 454   }
 455 
 456   return offset;
 457 }
 458 
 459 
 460 int LIR_Assembler::emit_deopt_handler() {
 461   // if the last instruction is a call (typically to do a throw which
 462   // is coming at the end after block reordering) the return address
 463   // must still point into the code area in order to avoid assertion
 464   // failures when searching for the corresponding bci =&gt; add a nop
 465   // (was bug 5/14/1999 - gri)
 466   __ nop();
 467 
 468   // generate code for exception handler
</pre>
<hr />
<pre>
 479   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 480   guarantee(code_offset() - offset &lt;= deopt_handler_size(), &quot;overflow&quot;);
 481   __ end_a_stub();
 482 
 483   return offset;
 484 }
 485 
 486 void LIR_Assembler::add_debug_info_for_branch(address adr, CodeEmitInfo* info) {
 487   _masm-&gt;code_section()-&gt;relocate(adr, relocInfo::poll_type);
 488   int pc_offset = code_offset();
 489   flush_debug_info(pc_offset);
 490   info-&gt;record_debug_info(compilation()-&gt;debug_info_recorder(), pc_offset);
 491   if (info-&gt;exception_handlers() != NULL) {
 492     compilation()-&gt;add_exception_handlers_for_pco(pc_offset, info-&gt;exception_handlers());
 493   }
 494 }
 495 
 496 void LIR_Assembler::return_op(LIR_Opr result) {
 497   assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == r0, &quot;word returns are in r0,&quot;);
 498 
<span class="line-added"> 499   ciMethod* method = compilation()-&gt;method();</span>
<span class="line-added"> 500 </span>
<span class="line-added"> 501   if (ValueTypeReturnedAsFields &amp;&amp; method-&gt;signature()-&gt;returns_never_null()) {</span>
<span class="line-added"> 502     ciType* return_type = method-&gt;return_type();</span>
<span class="line-added"> 503     if (return_type-&gt;is_valuetype()) {</span>
<span class="line-added"> 504       ciValueKlass* vk = return_type-&gt;as_value_klass();</span>
<span class="line-added"> 505       if (vk-&gt;can_be_returned_as_fields()) {</span>
<span class="line-added"> 506         address unpack_handler = vk-&gt;unpack_handler();</span>
<span class="line-added"> 507         assert(unpack_handler != NULL, &quot;must be&quot;);</span>
<span class="line-added"> 508         __ far_call(RuntimeAddress(unpack_handler));</span>
<span class="line-added"> 509         // At this point, rax points to the value object (for interpreter or C1 caller).</span>
<span class="line-added"> 510         // The fields of the object are copied into registers (for C2 caller).</span>
<span class="line-added"> 511       }</span>
<span class="line-added"> 512     }</span>
<span class="line-added"> 513   }</span>
<span class="line-added"> 514 </span>
 515   // Pop the stack before the safepoint code
<span class="line-modified"> 516   __ remove_frame(initial_frame_size_in_bytes(), needs_stack_repair());</span>
 517 
 518   if (StackReservedPages &gt; 0 &amp;&amp; compilation()-&gt;has_reserved_stack_access()) {
 519     __ reserved_stack_check();
 520   }
 521 
 522   __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 523   __ ret(lr);
 524 }
 525 
<span class="line-added"> 526 int LIR_Assembler::store_value_type_fields_to_buf(ciValueKlass* vk) {</span>
<span class="line-added"> 527   return (__ store_value_type_fields_to_buf(vk, false));</span>
<span class="line-added"> 528 }</span>
<span class="line-added"> 529 </span>
 530 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
 531   guarantee(info != NULL, &quot;Shouldn&#39;t be NULL&quot;);
 532   __ get_polling_page(rscratch1, relocInfo::poll_type);
 533   add_debug_info_for_branch(info);  // This isn&#39;t just debug info:
 534                                     // it&#39;s the oop map
 535   __ read_polling_page(rscratch1, relocInfo::poll_type);
 536   return __ offset();
 537 }
 538 
 539 
 540 void LIR_Assembler::move_regs(Register from_reg, Register to_reg) {
 541   if (from_reg == r31_sp)
 542     from_reg = sp;
 543   if (to_reg == r31_sp)
 544     to_reg = sp;
 545   __ mov(to_reg, from_reg);
 546 }
 547 
 548 void LIR_Assembler::swap_reg(Register a, Register b) { Unimplemented(); }
 549 
</pre>
<hr />
<pre>
 555 
 556   switch (c-&gt;type()) {
 557     case T_INT: {
 558       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 559       __ movw(dest-&gt;as_register(), c-&gt;as_jint());
 560       break;
 561     }
 562 
 563     case T_ADDRESS: {
 564       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 565       __ mov(dest-&gt;as_register(), c-&gt;as_jint());
 566       break;
 567     }
 568 
 569     case T_LONG: {
 570       assert(patch_code == lir_patch_none, &quot;no patching handled here&quot;);
 571       __ mov(dest-&gt;as_register_lo(), (intptr_t)c-&gt;as_jlong());
 572       break;
 573     }
 574 
<span class="line-added"> 575     case T_VALUETYPE:</span>
 576     case T_OBJECT: {
<span class="line-modified"> 577         if (patch_code != lir_patch_none) {</span>


 578           jobject2reg_with_patching(dest-&gt;as_register(), info);
<span class="line-added"> 579         } else {</span>
<span class="line-added"> 580           jobject2reg(c-&gt;as_jobject(), dest-&gt;as_register());</span>
 581         }
 582       break;
 583     }
 584 
 585     case T_METADATA: {
 586       if (patch_code != lir_patch_none) {
 587         klass2reg_with_patching(dest-&gt;as_register(), info);
 588       } else {
 589         __ mov_metadata(dest-&gt;as_register(), c-&gt;as_metadata());
 590       }
 591       break;
 592     }
 593 
 594     case T_FLOAT: {
 595       if (__ operand_valid_for_float_immediate(c-&gt;as_jfloat())) {
 596         __ fmovs(dest-&gt;as_float_reg(), (c-&gt;as_jfloat()));
 597       } else {
 598         __ adr(rscratch1, InternalAddress(float_constant(c-&gt;as_jfloat())));
 599         __ ldrs(dest-&gt;as_float_reg(), Address(rscratch1));
 600       }
</pre>
<hr />
<pre>
 602     }
 603 
 604     case T_DOUBLE: {
 605       if (__ operand_valid_for_float_immediate(c-&gt;as_jdouble())) {
 606         __ fmovd(dest-&gt;as_double_reg(), (c-&gt;as_jdouble()));
 607       } else {
 608         __ adr(rscratch1, InternalAddress(double_constant(c-&gt;as_jdouble())));
 609         __ ldrd(dest-&gt;as_double_reg(), Address(rscratch1));
 610       }
 611       break;
 612     }
 613 
 614     default:
 615       ShouldNotReachHere();
 616   }
 617 }
 618 
 619 void LIR_Assembler::const2stack(LIR_Opr src, LIR_Opr dest) {
 620   LIR_Const* c = src-&gt;as_constant_ptr();
 621   switch (c-&gt;type()) {
<span class="line-added"> 622   case T_VALUETYPE:</span>
 623   case T_OBJECT:
 624     {
 625       if (! c-&gt;as_jobject())
 626         __ str(zr, frame_map()-&gt;address_for_slot(dest-&gt;single_stack_ix()));
 627       else {
 628         const2reg(src, FrameMap::rscratch1_opr, lir_patch_none, NULL);
 629         reg2stack(FrameMap::rscratch1_opr, dest, c-&gt;type(), false);
 630       }
 631     }
 632     break;
 633   case T_ADDRESS:
 634     {
 635       const2reg(src, FrameMap::rscratch1_opr, lir_patch_none, NULL);
 636       reg2stack(FrameMap::rscratch1_opr, dest, c-&gt;type(), false);
 637     }
 638   case T_INT:
 639   case T_FLOAT:
 640     {
 641       Register reg = zr;
 642       if (c-&gt;as_jint_bits() == 0)
</pre>
<hr />
<pre>
 669 void LIR_Assembler::const2mem(LIR_Opr src, LIR_Opr dest, BasicType type, CodeEmitInfo* info, bool wide) {
 670   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 671   LIR_Const* c = src-&gt;as_constant_ptr();
 672   LIR_Address* to_addr = dest-&gt;as_address_ptr();
 673 
 674   void (Assembler::* insn)(Register Rt, const Address &amp;adr);
 675 
 676   switch (type) {
 677   case T_ADDRESS:
 678     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 679     insn = &amp;Assembler::str;
 680     break;
 681   case T_LONG:
 682     assert(c-&gt;as_jlong() == 0, &quot;should be&quot;);
 683     insn = &amp;Assembler::str;
 684     break;
 685   case T_INT:
 686     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 687     insn = &amp;Assembler::strw;
 688     break;
<span class="line-added"> 689   case T_VALUETYPE:</span>
 690   case T_OBJECT:
 691   case T_ARRAY:
<span class="line-added"> 692     // Non-null case is not handled on aarch64 but handled on x86</span>
<span class="line-added"> 693     // FIXME: do we need to add it here?</span>
 694     assert(c-&gt;as_jobject() == 0, &quot;should be&quot;);
 695     if (UseCompressedOops &amp;&amp; !wide) {
 696       insn = &amp;Assembler::strw;
 697     } else {
 698       insn = &amp;Assembler::str;
 699     }
 700     break;
 701   case T_CHAR:
 702   case T_SHORT:
 703     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 704     insn = &amp;Assembler::strh;
 705     break;
 706   case T_BOOLEAN:
 707   case T_BYTE:
 708     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 709     insn = &amp;Assembler::strb;
 710     break;
 711   default:
 712     ShouldNotReachHere();
 713     insn = &amp;Assembler::str;  // unreachable
 714   }
 715 
 716   if (info) add_debug_info_for_null_check_here(info);
 717   (_masm-&gt;*insn)(zr, as_Address(to_addr, rscratch1));
 718 }
 719 
 720 void LIR_Assembler::reg2reg(LIR_Opr src, LIR_Opr dest) {
 721   assert(src-&gt;is_register(), &quot;should not call otherwise&quot;);
 722   assert(dest-&gt;is_register(), &quot;should not call otherwise&quot;);
 723 
 724   // move between cpu-registers
 725   if (dest-&gt;is_single_cpu()) {
 726     if (src-&gt;type() == T_LONG) {
 727       // Can do LONG -&gt; OBJECT
 728       move_regs(src-&gt;as_register_lo(), dest-&gt;as_register());
 729       return;
 730     }
 731     assert(src-&gt;is_single_cpu(), &quot;must match&quot;);
<span class="line-modified"> 732     if (src-&gt;type() == T_OBJECT || src-&gt;type() == T_VALUETYPE) {</span>
 733       __ verify_oop(src-&gt;as_register());
 734     }
 735     move_regs(src-&gt;as_register(), dest-&gt;as_register());
 736 
 737   } else if (dest-&gt;is_double_cpu()) {
 738     if (is_reference_type(src-&gt;type())) {
 739       // Surprising to me but we can see move of a long to t_object
 740       __ verify_oop(src-&gt;as_register());
 741       move_regs(src-&gt;as_register(), dest-&gt;as_register_lo());
 742       return;
 743     }
 744     assert(src-&gt;is_double_cpu(), &quot;must match&quot;);
 745     Register f_lo = src-&gt;as_register_lo();
 746     Register f_hi = src-&gt;as_register_hi();
 747     Register t_lo = dest-&gt;as_register_lo();
 748     Register t_hi = dest-&gt;as_register_hi();
 749     assert(f_hi == f_lo, &quot;must be same&quot;);
 750     assert(t_hi == t_lo, &quot;must be same&quot;);
 751     move_regs(f_lo, t_lo);
 752 
</pre>
<hr />
<pre>
 806 
 807     if (UseCompressedOops &amp;&amp; !wide) {
 808       __ encode_heap_oop(compressed_src, src-&gt;as_register());
 809     } else {
 810       compressed_src = src-&gt;as_register();
 811     }
 812   }
 813 
 814   int null_check_here = code_offset();
 815   switch (type) {
 816     case T_FLOAT: {
 817       __ strs(src-&gt;as_float_reg(), as_Address(to_addr));
 818       break;
 819     }
 820 
 821     case T_DOUBLE: {
 822       __ strd(src-&gt;as_double_reg(), as_Address(to_addr));
 823       break;
 824     }
 825 
<span class="line-added"> 826     case T_VALUETYPE: // fall through</span>
 827     case T_ARRAY:   // fall through
 828     case T_OBJECT:  // fall through
 829       if (UseCompressedOops &amp;&amp; !wide) {
 830         __ strw(compressed_src, as_Address(to_addr, rscratch2));
 831       } else {
 832          __ str(compressed_src, as_Address(to_addr));
 833       }
 834       break;
 835     case T_METADATA:
 836       // We get here to store a method pointer to the stack to pass to
 837       // a dtrace runtime call. This can&#39;t work on 64 bit with
 838       // compressed klass ptrs: T_METADATA can be a compressed klass
 839       // ptr or a 64 bit method pointer.
 840       ShouldNotReachHere();
 841       __ str(src-&gt;as_register(), as_Address(to_addr));
 842       break;
 843     case T_ADDRESS:
 844       __ str(src-&gt;as_register(), as_Address(to_addr));
 845       break;
 846     case T_INT:
</pre>
<hr />
<pre>
 932   add_call_info_here(info);
 933 }
 934 
 935 void LIR_Assembler::stack2stack(LIR_Opr src, LIR_Opr dest, BasicType type) {
 936 
 937   LIR_Opr temp;
 938   if (type == T_LONG || type == T_DOUBLE)
 939     temp = FrameMap::rscratch1_long_opr;
 940   else
 941     temp = FrameMap::rscratch1_opr;
 942 
 943   stack2reg(src, temp, src-&gt;type());
 944   reg2stack(temp, dest, dest-&gt;type(), false);
 945 }
 946 
 947 
 948 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
 949   LIR_Address* addr = src-&gt;as_address_ptr();
 950   LIR_Address* from_addr = src-&gt;as_address_ptr();
 951 
<span class="line-modified"> 952   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_VALUETYPE) {</span>
 953     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
 954   }
 955 
 956   if (patch_code != lir_patch_none) {
 957     deoptimize_trap(info);
 958     return;
 959   }
 960 
 961   if (info != NULL) {
 962     add_debug_info_for_null_check_here(info);
 963   }
 964   int null_check_here = code_offset();
 965   switch (type) {
 966     case T_FLOAT: {
 967       __ ldrs(dest-&gt;as_float_reg(), as_Address(from_addr));
 968       break;
 969     }
 970 
 971     case T_DOUBLE: {
 972       __ ldrd(dest-&gt;as_double_reg(), as_Address(from_addr));
 973       break;
 974     }
 975 
<span class="line-added"> 976     case T_VALUETYPE: // fall through</span>
 977     case T_ARRAY:   // fall through
 978     case T_OBJECT:  // fall through
 979       if (UseCompressedOops &amp;&amp; !wide) {
 980         __ ldrw(dest-&gt;as_register(), as_Address(from_addr));
 981       } else {
 982          __ ldr(dest-&gt;as_register(), as_Address(from_addr));
 983       }
 984       break;
 985     case T_METADATA:
 986       // We get here to store a method pointer to the stack to pass to
 987       // a dtrace runtime call. This can&#39;t work on 64 bit with
 988       // compressed klass ptrs: T_METADATA can be a compressed klass
 989       // ptr or a 64 bit method pointer.
 990       ShouldNotReachHere();
 991       __ ldr(dest-&gt;as_register(), as_Address(from_addr));
 992       break;
 993     case T_ADDRESS:
 994       // FIXME: OMG this is a horrible kludge.  Any offset from an
 995       // address that matches klass_offset_in_bytes() will be loaded
 996       // as a word, not a long.
</pre>
<hr />
<pre>
1022       break;
1023     case T_SHORT:
1024       __ ldrsh(dest-&gt;as_register(), as_Address(from_addr));
1025       break;
1026 
1027     default:
1028       ShouldNotReachHere();
1029   }
1030 
1031   if (is_reference_type(type)) {
1032     if (UseCompressedOops &amp;&amp; !wide) {
1033       __ decode_heap_oop(dest-&gt;as_register());
1034     }
1035 
1036     if (!UseZGC) {
1037       // Load barrier has not yet been applied, so ZGC can&#39;t verify the oop here
1038       __ verify_oop(dest-&gt;as_register());
1039     }
1040   } else if (type == T_ADDRESS &amp;&amp; addr-&gt;disp() == oopDesc::klass_offset_in_bytes()) {
1041     if (UseCompressedClassPointers) {
<span class="line-added">1042       __ andr(dest-&gt;as_register(), dest-&gt;as_register(), oopDesc::compressed_klass_mask());</span>
1043       __ decode_klass_not_null(dest-&gt;as_register());
<span class="line-added">1044     } else {</span>
<span class="line-added">1045       __   ubfm(dest-&gt;as_register(), dest-&gt;as_register(), 0, 63 - oopDesc::storage_props_nof_bits);</span>
1046     }
1047   }
1048 }
1049 
<span class="line-added">1050 void LIR_Assembler::move(LIR_Opr src, LIR_Opr dst) {</span>
<span class="line-added">1051   assert(dst-&gt;is_cpu_register(), &quot;must be&quot;);</span>
<span class="line-added">1052   assert(dst-&gt;type() == src-&gt;type(), &quot;must be&quot;);</span>
<span class="line-added">1053 </span>
<span class="line-added">1054   if (src-&gt;is_cpu_register()) {</span>
<span class="line-added">1055     reg2reg(src, dst);</span>
<span class="line-added">1056   } else if (src-&gt;is_stack()) {</span>
<span class="line-added">1057     stack2reg(src, dst, dst-&gt;type());</span>
<span class="line-added">1058   } else if (src-&gt;is_constant()) {</span>
<span class="line-added">1059     const2reg(src, dst, lir_patch_none, NULL);</span>
<span class="line-added">1060   } else {</span>
<span class="line-added">1061     ShouldNotReachHere();</span>
<span class="line-added">1062   }</span>
<span class="line-added">1063 }</span>
1064 
1065 int LIR_Assembler::array_element_size(BasicType type) const {
1066   int elem_size = type2aelembytes(type);
1067   return exact_log2(elem_size);
1068 }
1069 
1070 
1071 void LIR_Assembler::emit_op3(LIR_Op3* op) {
1072   switch (op-&gt;code()) {
1073   case lir_idiv:
1074   case lir_irem:
1075     arithmetic_idiv(op-&gt;code(),
1076                     op-&gt;in_opr1(),
1077                     op-&gt;in_opr2(),
1078                     op-&gt;in_opr3(),
1079                     op-&gt;result_opr(),
1080                     op-&gt;info());
1081     break;
1082   case lir_fmad:
1083     __ fmaddd(op-&gt;result_opr()-&gt;as_double_reg(),
</pre>
<hr />
<pre>
1235     __ ldrb(rscratch1, Address(op-&gt;klass()-&gt;as_register(),
1236                                InstanceKlass::init_state_offset()));
1237     __ cmpw(rscratch1, InstanceKlass::fully_initialized);
1238     add_debug_info_for_null_check_here(op-&gt;stub()-&gt;info());
1239     __ br(Assembler::NE, *op-&gt;stub()-&gt;entry());
1240   }
1241   __ allocate_object(op-&gt;obj()-&gt;as_register(),
1242                      op-&gt;tmp1()-&gt;as_register(),
1243                      op-&gt;tmp2()-&gt;as_register(),
1244                      op-&gt;header_size(),
1245                      op-&gt;object_size(),
1246                      op-&gt;klass()-&gt;as_register(),
1247                      *op-&gt;stub()-&gt;entry());
1248   __ bind(*op-&gt;stub()-&gt;continuation());
1249 }
1250 
1251 void LIR_Assembler::emit_alloc_array(LIR_OpAllocArray* op) {
1252   Register len =  op-&gt;len()-&gt;as_register();
1253   __ uxtw(len, len);
1254 
<span class="line-modified">1255   if (UseSlowPath || op-&gt;type() == T_VALUETYPE ||</span>
1256       (!UseFastNewObjectArray &amp;&amp; is_reference_type(op-&gt;type())) ||
1257       (!UseFastNewTypeArray   &amp;&amp; !is_reference_type(op-&gt;type()))) {
1258     __ b(*op-&gt;stub()-&gt;entry());
1259   } else {
1260     Register tmp1 = op-&gt;tmp1()-&gt;as_register();
1261     Register tmp2 = op-&gt;tmp2()-&gt;as_register();
1262     Register tmp3 = op-&gt;tmp3()-&gt;as_register();
1263     if (len == tmp1) {
1264       tmp1 = tmp3;
1265     } else if (len == tmp2) {
1266       tmp2 = tmp3;
1267     } else if (len == tmp3) {
1268       // everything is ok
1269     } else {
1270       __ mov(tmp3, len);
1271     }
1272     __ allocate_array(op-&gt;obj()-&gt;as_register(),
1273                       len,
1274                       tmp1,
1275                       tmp2,
</pre>
<hr />
<pre>
1547     __ bind(success);
1548     if (dst != obj) {
1549       __ mov(dst, obj);
1550     }
1551   } else if (code == lir_instanceof) {
1552     Register obj = op-&gt;object()-&gt;as_register();
1553     Register dst = op-&gt;result_opr()-&gt;as_register();
1554     Label success, failure, done;
1555     emit_typecheck_helper(op, &amp;success, &amp;failure, &amp;failure);
1556     __ bind(failure);
1557     __ mov(dst, zr);
1558     __ b(done);
1559     __ bind(success);
1560     __ mov(dst, 1);
1561     __ bind(done);
1562   } else {
1563     ShouldNotReachHere();
1564   }
1565 }
1566 
<span class="line-added">1567 void LIR_Assembler::emit_opFlattenedArrayCheck(LIR_OpFlattenedArrayCheck* op) {</span>
<span class="line-added">1568   // We are loading/storing an array that *may* be a flattened array (the declared type</span>
<span class="line-added">1569   // Object[], interface[], or VT?[]). If this array is flattened, take slow path.</span>
<span class="line-added">1570 </span>
<span class="line-added">1571   __ load_storage_props(op-&gt;tmp()-&gt;as_register(), op-&gt;array()-&gt;as_register());</span>
<span class="line-added">1572   __ tst(op-&gt;tmp()-&gt;as_register(), ArrayStorageProperties::flattened_value);</span>
<span class="line-added">1573   __ br(Assembler::NE, *op-&gt;stub()-&gt;entry());</span>
<span class="line-added">1574   if (!op-&gt;value()-&gt;is_illegal()) {</span>
<span class="line-added">1575     // We are storing into the array.</span>
<span class="line-added">1576     Label skip;</span>
<span class="line-added">1577     __ tst(op-&gt;tmp()-&gt;as_register(), ArrayStorageProperties::null_free_value);</span>
<span class="line-added">1578     __ br(Assembler::EQ, skip);</span>
<span class="line-added">1579     // The array is not flattened, but it is null_free. If we are storing</span>
<span class="line-added">1580     // a null, take the slow path (which will throw NPE).</span>
<span class="line-added">1581     __ cbz(op-&gt;value()-&gt;as_register(), *op-&gt;stub()-&gt;entry());</span>
<span class="line-added">1582     __ bind(skip);</span>
<span class="line-added">1583   }</span>
<span class="line-added">1584 </span>
<span class="line-added">1585 }</span>
<span class="line-added">1586 </span>
<span class="line-added">1587 void LIR_Assembler::emit_opNullFreeArrayCheck(LIR_OpNullFreeArrayCheck* op) {</span>
<span class="line-added">1588   // This is called when we use aastore into a an array declared as &quot;[LVT;&quot;,</span>
<span class="line-added">1589   // where we know VT is not flattenable (due to ValueArrayElemMaxFlatOops, etc).</span>
<span class="line-added">1590   // However, we need to do a NULL check if the actual array is a &quot;[QVT;&quot;.</span>
<span class="line-added">1591 </span>
<span class="line-added">1592   __ load_storage_props(op-&gt;tmp()-&gt;as_register(), op-&gt;array()-&gt;as_register());</span>
<span class="line-added">1593   __ mov(rscratch1, (uint64_t) ArrayStorageProperties::null_free_value);</span>
<span class="line-added">1594   __ cmp(op-&gt;tmp()-&gt;as_register(), rscratch1);</span>
<span class="line-added">1595 }</span>
<span class="line-added">1596 </span>
<span class="line-added">1597 void LIR_Assembler::emit_opSubstitutabilityCheck(LIR_OpSubstitutabilityCheck* op) {</span>
<span class="line-added">1598   Label L_oops_equal;</span>
<span class="line-added">1599   Label L_oops_not_equal;</span>
<span class="line-added">1600   Label L_end;</span>
<span class="line-added">1601 </span>
<span class="line-added">1602   Register left  = op-&gt;left()-&gt;as_register();</span>
<span class="line-added">1603   Register right = op-&gt;right()-&gt;as_register();</span>
<span class="line-added">1604 </span>
<span class="line-added">1605   __ cmp(left, right);</span>
<span class="line-added">1606   __ br(Assembler::EQ, L_oops_equal);</span>
<span class="line-added">1607 </span>
<span class="line-added">1608   // (1) Null check -- if one of the operands is null, the other must not be null (because</span>
<span class="line-added">1609   //     the two references are not equal), so they are not substitutable,</span>
<span class="line-added">1610   //     FIXME: do null check only if the operand is nullable</span>
<span class="line-added">1611   {</span>
<span class="line-added">1612     __ cbz(left, L_oops_not_equal);</span>
<span class="line-added">1613     __ cbz(right, L_oops_not_equal);</span>
<span class="line-added">1614   }</span>
<span class="line-added">1615 </span>
<span class="line-added">1616 </span>
<span class="line-added">1617   ciKlass* left_klass = op-&gt;left_klass();</span>
<span class="line-added">1618   ciKlass* right_klass = op-&gt;right_klass();</span>
<span class="line-added">1619 </span>
<span class="line-added">1620   // (2) Value object check -- if either of the operands is not a value object,</span>
<span class="line-added">1621   //     they are not substitutable. We do this only if we are not sure that the</span>
<span class="line-added">1622   //     operands are value objects</span>
<span class="line-added">1623   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.</span>
<span class="line-added">1624       !left_klass-&gt;is_valuetype() || !right_klass-&gt;is_valuetype()) {</span>
<span class="line-added">1625     Register tmp1  = rscratch1; /* op-&gt;tmp1()-&gt;as_register(); */</span>
<span class="line-added">1626     Register tmp2  = rscratch2; /* op-&gt;tmp2()-&gt;as_register(); */</span>
<span class="line-added">1627 </span>
<span class="line-added">1628     __ mov(tmp1, (intptr_t)markWord::always_locked_pattern);</span>
<span class="line-added">1629 </span>
<span class="line-added">1630     __ ldr(tmp2, Address(left, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">1631     __ andr(tmp1, tmp1, tmp2);</span>
<span class="line-added">1632 </span>
<span class="line-added">1633     __ ldr(tmp2, Address(right, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">1634     __ andr(tmp1, tmp1, tmp2);</span>
<span class="line-added">1635 </span>
<span class="line-added">1636     __ mov(tmp2, (intptr_t)markWord::always_locked_pattern);</span>
<span class="line-added">1637     __ cmp(tmp1, tmp2);</span>
<span class="line-added">1638     __ br(Assembler::NE, L_oops_not_equal);</span>
<span class="line-added">1639   }</span>
<span class="line-added">1640 </span>
<span class="line-added">1641   // (3) Same klass check: if the operands are of different klasses, they are not substitutable.</span>
<span class="line-added">1642   if (left_klass != NULL &amp;&amp; left_klass-&gt;is_valuetype() &amp;&amp; left_klass == right_klass) {</span>
<span class="line-added">1643     // No need to load klass -- the operands are statically known to be the same value klass.</span>
<span class="line-added">1644     __ b(*op-&gt;stub()-&gt;entry());</span>
<span class="line-added">1645   } else {</span>
<span class="line-added">1646     Register left_klass_op = op-&gt;left_klass_op()-&gt;as_register();</span>
<span class="line-added">1647     Register right_klass_op = op-&gt;right_klass_op()-&gt;as_register();</span>
<span class="line-added">1648 </span>
<span class="line-added">1649     if (UseCompressedOops) {</span>
<span class="line-added">1650       __ ldrw(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">1651       __ ldrw(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">1652       __ cmpw(left_klass_op, right_klass_op);</span>
<span class="line-added">1653     } else {</span>
<span class="line-added">1654       __ ldr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">1655       __ ldr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">1656       __ cmp(left_klass_op, right_klass_op);</span>
<span class="line-added">1657     }</span>
<span class="line-added">1658 </span>
<span class="line-added">1659     __ br(Assembler::EQ, *op-&gt;stub()-&gt;entry()); // same klass -&gt; do slow check</span>
<span class="line-added">1660     // fall through to L_oops_not_equal</span>
<span class="line-added">1661   }</span>
<span class="line-added">1662 </span>
<span class="line-added">1663   __ bind(L_oops_not_equal);</span>
<span class="line-added">1664   move(op-&gt;not_equal_result(), op-&gt;result_opr());</span>
<span class="line-added">1665   __ b(L_end);</span>
<span class="line-added">1666 </span>
<span class="line-added">1667   __ bind(L_oops_equal);</span>
<span class="line-added">1668   move(op-&gt;equal_result(), op-&gt;result_opr());</span>
<span class="line-added">1669   __ b(L_end);</span>
<span class="line-added">1670 </span>
<span class="line-added">1671   // We&#39;ve returned from the stub. op-&gt;result_opr() contains 0x0 IFF the two</span>
<span class="line-added">1672   // operands are not substitutable. (Don&#39;t compare against 0x1 in case the</span>
<span class="line-added">1673   // C compiler is naughty)</span>
<span class="line-added">1674   __ bind(*op-&gt;stub()-&gt;continuation());</span>
<span class="line-added">1675 </span>
<span class="line-added">1676   if (op-&gt;result_opr()-&gt;type() == T_LONG) {</span>
<span class="line-added">1677     __ cbzw(op-&gt;result_opr()-&gt;as_register(), L_oops_not_equal); // (call_stub() == 0x0) -&gt; not_equal</span>
<span class="line-added">1678   } else {</span>
<span class="line-added">1679     __ cbz(op-&gt;result_opr()-&gt;as_register(), L_oops_not_equal); // (call_stub() == 0x0) -&gt; not_equal</span>
<span class="line-added">1680   }</span>
<span class="line-added">1681 </span>
<span class="line-added">1682   move(op-&gt;equal_result(), op-&gt;result_opr()); // (call_stub() != 0x0) -&gt; equal</span>
<span class="line-added">1683   // fall-through</span>
<span class="line-added">1684   __ bind(L_end);</span>
<span class="line-added">1685 </span>
<span class="line-added">1686 }</span>
<span class="line-added">1687 </span>
<span class="line-added">1688 </span>
1689 void LIR_Assembler::casw(Register addr, Register newval, Register cmpval) {
1690   __ cmpxchg(addr, cmpval, newval, Assembler::word, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
1691   __ cset(rscratch1, Assembler::NE);
1692   __ membar(__ AnyAny);
1693 }
1694 
1695 void LIR_Assembler::casl(Register addr, Register newval, Register cmpval) {
1696   __ cmpxchg(addr, cmpval, newval, Assembler::xword, /* acquire*/ true, /* release*/ true, /* weak*/ false, rscratch1);
1697   __ cset(rscratch1, Assembler::NE);
1698   __ membar(__ AnyAny);
1699 }
1700 
1701 
1702 void LIR_Assembler::emit_compare_and_swap(LIR_OpCompareAndSwap* op) {
1703   assert(VM_Version::supports_cx8(), &quot;wrong machine&quot;);
1704   Register addr;
1705   if (op-&gt;addr()-&gt;is_register()) {
1706     addr = as_reg(op-&gt;addr());
1707   } else {
1708     assert(op-&gt;addr()-&gt;is_address(), &quot;what else?&quot;);
</pre>
<hr />
<pre>
2112     }
2113 
2114     if (opr2-&gt;is_constant()) {
2115       bool is_32bit = false; // width of register operand
2116       jlong imm;
2117 
2118       switch(opr2-&gt;type()) {
2119       case T_INT:
2120         imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
2121         is_32bit = true;
2122         break;
2123       case T_LONG:
2124         imm = opr2-&gt;as_constant_ptr()-&gt;as_jlong();
2125         break;
2126       case T_ADDRESS:
2127         imm = opr2-&gt;as_constant_ptr()-&gt;as_jint();
2128         break;
2129       case T_METADATA:
2130         imm = (intptr_t)(opr2-&gt;as_constant_ptr()-&gt;as_metadata());
2131         break;
<span class="line-added">2132       case T_VALUETYPE:</span>
2133       case T_OBJECT:
2134       case T_ARRAY:
2135         jobject2reg(opr2-&gt;as_constant_ptr()-&gt;as_jobject(), rscratch1);
2136         __ cmpoop(reg1, rscratch1);
2137         return;
2138       default:
2139         ShouldNotReachHere();
2140         imm = 0;  // unreachable
2141         break;
2142       }
2143 
2144       if (Assembler::operand_valid_for_add_sub_immediate(imm)) {
2145         if (is_32bit)
2146           __ cmpw(reg1, imm);
2147         else
2148           __ subs(zr, reg1, imm);
2149         return;
2150       } else {
2151         __ mov(rscratch1, imm);
2152         if (is_32bit)
</pre>
<hr />
<pre>
2279   __ b(_unwind_handler_entry);
2280 }
2281 
2282 
2283 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, LIR_Opr count, LIR_Opr dest, LIR_Opr tmp) {
2284   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2285   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2286 
2287   switch (left-&gt;type()) {
2288     case T_INT: {
2289       switch (code) {
2290       case lir_shl:  __ lslvw (dreg, lreg, count-&gt;as_register()); break;
2291       case lir_shr:  __ asrvw (dreg, lreg, count-&gt;as_register()); break;
2292       case lir_ushr: __ lsrvw (dreg, lreg, count-&gt;as_register()); break;
2293       default:
2294         ShouldNotReachHere();
2295         break;
2296       }
2297       break;
2298     case T_LONG:
<span class="line-added">2299     case T_VALUETYPE:</span>
2300     case T_ADDRESS:
2301     case T_OBJECT:
2302       switch (code) {
2303       case lir_shl:  __ lslv (dreg, lreg, count-&gt;as_register()); break;
2304       case lir_shr:  __ asrv (dreg, lreg, count-&gt;as_register()); break;
2305       case lir_ushr: __ lsrv (dreg, lreg, count-&gt;as_register()); break;
2306       default:
2307         ShouldNotReachHere();
2308         break;
2309       }
2310       break;
2311     default:
2312       ShouldNotReachHere();
2313       break;
2314     }
2315   }
2316 }
2317 
2318 
2319 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, jint count, LIR_Opr dest) {
2320   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2321   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2322 
2323   switch (left-&gt;type()) {
2324     case T_INT: {
2325       switch (code) {
2326       case lir_shl:  __ lslw (dreg, lreg, count); break;
2327       case lir_shr:  __ asrw (dreg, lreg, count); break;
2328       case lir_ushr: __ lsrw (dreg, lreg, count); break;
2329       default:
2330         ShouldNotReachHere();
2331         break;
2332       }
2333       break;
2334     case T_LONG:
2335     case T_ADDRESS:
<span class="line-added">2336     case T_VALUETYPE:</span>
2337     case T_OBJECT:
2338       switch (code) {
2339       case lir_shl:  __ lsl (dreg, lreg, count); break;
2340       case lir_shr:  __ asr (dreg, lreg, count); break;
2341       case lir_ushr: __ lsr (dreg, lreg, count); break;
2342       default:
2343         ShouldNotReachHere();
2344         break;
2345       }
2346       break;
2347     default:
2348       ShouldNotReachHere();
2349       break;
2350     }
2351   }
2352 }
2353 
2354 
2355 void LIR_Assembler::store_parameter(Register r, int offset_from_rsp_in_words) {
2356   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
</pre>
<hr />
<pre>
2361 
2362 
2363 void LIR_Assembler::store_parameter(jint c,     int offset_from_rsp_in_words) {
2364   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
2365   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
2366   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
2367   __ mov (rscratch1, c);
2368   __ str (rscratch1, Address(sp, offset_from_rsp_in_bytes));
2369 }
2370 
2371 
2372 void LIR_Assembler::store_parameter(jobject o,  int offset_from_rsp_in_words) {
2373   ShouldNotReachHere();
2374   assert(offset_from_rsp_in_words &gt;= 0, &quot;invalid offset from rsp&quot;);
2375   int offset_from_rsp_in_bytes = offset_from_rsp_in_words * BytesPerWord;
2376   assert(offset_from_rsp_in_bytes &lt; frame_map()-&gt;reserved_argument_area_size(), &quot;invalid offset&quot;);
2377   __ lea(rscratch1, __ constant_oop_address(o));
2378   __ str(rscratch1, Address(sp, offset_from_rsp_in_bytes));
2379 }
2380 
<span class="line-added">2381 void LIR_Assembler::arraycopy_valuetype_check(Register obj, Register tmp, CodeStub* slow_path, bool is_dest) {</span>
<span class="line-added">2382   __ load_storage_props(tmp, obj);</span>
<span class="line-added">2383   if (is_dest) {</span>
<span class="line-added">2384     // We also take slow path if it&#39;s a null_free destination array, just in case the source array</span>
<span class="line-added">2385     // contains NULLs.</span>
<span class="line-added">2386     __ tst(tmp, ArrayStorageProperties::flattened_value | ArrayStorageProperties::null_free_value);</span>
<span class="line-added">2387   } else {</span>
<span class="line-added">2388     __ tst(tmp, ArrayStorageProperties::flattened_value);</span>
<span class="line-added">2389   }</span>
<span class="line-added">2390   __ br(Assembler::NE, *slow_path-&gt;entry());</span>
<span class="line-added">2391 }</span>
<span class="line-added">2392 </span>
<span class="line-added">2393 </span>
2394 
2395 // This code replaces a call to arraycopy; no exception may
2396 // be thrown in this code, they must be thrown in the System.arraycopy
2397 // activation frame; we could save some checks if this would not be the case
2398 void LIR_Assembler::emit_arraycopy(LIR_OpArrayCopy* op) {
2399   ciArrayKlass* default_type = op-&gt;expected_type();
2400   Register src = op-&gt;src()-&gt;as_register();
2401   Register dst = op-&gt;dst()-&gt;as_register();
2402   Register src_pos = op-&gt;src_pos()-&gt;as_register();
2403   Register dst_pos = op-&gt;dst_pos()-&gt;as_register();
2404   Register length  = op-&gt;length()-&gt;as_register();
2405   Register tmp = op-&gt;tmp()-&gt;as_register();
2406 
2407   __ resolve(ACCESS_READ, src);
2408   __ resolve(ACCESS_WRITE, dst);
2409 
2410   CodeStub* stub = op-&gt;stub();
2411   int flags = op-&gt;flags();
2412   BasicType basic_type = default_type != NULL ? default_type-&gt;element_type()-&gt;basic_type() : T_ILLEGAL;
2413   if (is_reference_type(basic_type)) basic_type = T_OBJECT;
2414 
<span class="line-added">2415   if (flags &amp; LIR_OpArrayCopy::always_slow_path) {</span>
<span class="line-added">2416     __ b(*stub-&gt;entry());</span>
<span class="line-added">2417     __ bind(*stub-&gt;continuation());</span>
<span class="line-added">2418     return;</span>
<span class="line-added">2419   }</span>
<span class="line-added">2420 </span>
<span class="line-added">2421   if (flags &amp; LIR_OpArrayCopy::src_valuetype_check) {</span>
<span class="line-added">2422     arraycopy_valuetype_check(src, tmp, stub, false);</span>
<span class="line-added">2423   }</span>
<span class="line-added">2424 </span>
<span class="line-added">2425   if (flags &amp; LIR_OpArrayCopy::dst_valuetype_check) {</span>
<span class="line-added">2426     arraycopy_valuetype_check(dst, tmp, stub, true);</span>
<span class="line-added">2427   }</span>
<span class="line-added">2428 </span>
<span class="line-added">2429 </span>
<span class="line-added">2430 </span>
2431   // if we don&#39;t know anything, just go through the generic arraycopy
2432   if (default_type == NULL // || basic_type == T_OBJECT
2433       ) {
2434     Label done;
2435     assert(src == r1 &amp;&amp; src_pos == r2, &quot;mismatch in calling convention&quot;);
2436 
2437     // Save the arguments in case the generic arraycopy fails and we
2438     // have to fall back to the JNI stub
2439     __ stp(dst,     dst_pos, Address(sp, 0*BytesPerWord));
2440     __ stp(length,  src_pos, Address(sp, 2*BytesPerWord));
2441     __ str(src,              Address(sp, 4*BytesPerWord));
2442 
2443     address copyfunc_addr = StubRoutines::generic_arraycopy();
2444     assert(copyfunc_addr != NULL, &quot;generic arraycopy stub required&quot;);
2445 
2446     // The arguments are in java calling convention so we shift them
2447     // to C convention
2448     assert_different_registers(c_rarg0, j_rarg1, j_rarg2, j_rarg3, j_rarg4);
2449     __ mov(c_rarg0, j_rarg0);
2450     assert_different_registers(c_rarg1, j_rarg2, j_rarg3, j_rarg4);
</pre>
<hr />
<pre>
3311 #endif
3312 }
3313 
3314 void LIR_Assembler::atomic_op(LIR_Code code, LIR_Opr src, LIR_Opr data, LIR_Opr dest, LIR_Opr tmp_op) {
3315   Address addr = as_Address(src-&gt;as_address_ptr());
3316   BasicType type = src-&gt;type();
3317   bool is_oop = is_reference_type(type);
3318 
3319   void (MacroAssembler::* add)(Register prev, RegisterOrConstant incr, Register addr);
3320   void (MacroAssembler::* xchg)(Register prev, Register newv, Register addr);
3321 
3322   switch(type) {
3323   case T_INT:
3324     xchg = &amp;MacroAssembler::atomic_xchgalw;
3325     add = &amp;MacroAssembler::atomic_addalw;
3326     break;
3327   case T_LONG:
3328     xchg = &amp;MacroAssembler::atomic_xchgal;
3329     add = &amp;MacroAssembler::atomic_addal;
3330     break;
<span class="line-added">3331   case T_VALUETYPE:</span>
3332   case T_OBJECT:
3333   case T_ARRAY:
3334     if (UseCompressedOops) {
3335       xchg = &amp;MacroAssembler::atomic_xchgalw;
3336       add = &amp;MacroAssembler::atomic_addalw;
3337     } else {
3338       xchg = &amp;MacroAssembler::atomic_xchgal;
3339       add = &amp;MacroAssembler::atomic_addal;
3340     }
3341     break;
3342   default:
3343     ShouldNotReachHere();
3344     xchg = &amp;MacroAssembler::atomic_xchgal;
3345     add = &amp;MacroAssembler::atomic_addal; // unreachable
3346   }
3347 
3348   switch (code) {
3349   case lir_xadd:
3350     {
3351       RegisterOrConstant inc;
</pre>
</td>
</tr>
</table>
<center><a href="aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="frame_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>