<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  29 #include &quot;jvm.h&quot;
  30 #include &quot;asm/assembler.hpp&quot;
  31 #include &quot;asm/assembler.inline.hpp&quot;
  32 #include &quot;gc/shared/barrierSet.hpp&quot;
  33 #include &quot;gc/shared/cardTable.hpp&quot;
  34 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  35 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  36 #include &quot;interpreter/interpreter.hpp&quot;
  37 #include &quot;compiler/disassembler.hpp&quot;
  38 #include &quot;memory/resourceArea.hpp&quot;
  39 #include &quot;memory/universe.hpp&quot;
  40 #include &quot;nativeInst_aarch64.hpp&quot;
  41 #include &quot;oops/accessDecorators.hpp&quot;
  42 #include &quot;oops/compressedOops.inline.hpp&quot;
  43 #include &quot;oops/klass.inline.hpp&quot;
  44 #include &quot;runtime/biasedLocking.hpp&quot;
  45 #include &quot;runtime/icache.hpp&quot;
  46 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  47 #include &quot;runtime/jniHandles.inline.hpp&quot;
  48 #include &quot;runtime/sharedRuntime.hpp&quot;

  49 #include &quot;runtime/thread.hpp&quot;
  50 #include &quot;utilities/powerOfTwo.hpp&quot;
  51 #ifdef COMPILER1
  52 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  53 #endif
  54 #ifdef COMPILER2
  55 #include &quot;oops/oop.hpp&quot;
  56 #include &quot;opto/compile.hpp&quot;
  57 #include &quot;opto/node.hpp&quot;
  58 #include &quot;opto/output.hpp&quot;
  59 #endif
  60 
  61 #ifdef PRODUCT
  62 #define BLOCK_COMMENT(str) /* nothing */
  63 #define STOP(error) stop(error)
  64 #else
  65 #define BLOCK_COMMENT(str) block_comment(str)
  66 #define STOP(error) block_comment(error); stop(error)
  67 #endif
  68 
</pre>
<hr />
<pre>
1299   ldrb(scratch, Address(klass, InstanceKlass::init_state_offset()));
1300   subs(zr, scratch, InstanceKlass::fully_initialized);
1301   br(Assembler::EQ, *L_fast_path);
1302 
1303   // Fast path check: current thread is initializer thread
1304   ldr(scratch, Address(klass, InstanceKlass::init_thread_offset()));
1305   cmp(rthread, scratch);
1306 
1307   if (L_slow_path == &amp;L_fallthrough) {
1308     br(Assembler::EQ, *L_fast_path);
1309     bind(*L_slow_path);
1310   } else if (L_fast_path == &amp;L_fallthrough) {
1311     br(Assembler::NE, *L_slow_path);
1312     bind(*L_fast_path);
1313   } else {
1314     Unimplemented();
1315   }
1316 }
1317 
1318 void MacroAssembler::verify_oop(Register reg, const char* s) {
<span class="line-modified">1319   if (!VerifyOops) return;</span>




1320 
1321   // Pass register number to verify_oop_subroutine
1322   const char* b = NULL;
1323   {
1324     ResourceMark rm;
1325     stringStream ss;
1326     ss.print(&quot;verify_oop: %s: %s&quot;, reg-&gt;name(), s);
1327     b = code_string(ss.as_string());
1328   }
1329   BLOCK_COMMENT(&quot;verify_oop {&quot;);
1330 
1331   stp(r0, rscratch1, Address(pre(sp, -2 * wordSize)));
1332   stp(rscratch2, lr, Address(pre(sp, -2 * wordSize)));
1333 
1334   mov(r0, reg);
1335   mov(rscratch1, (address)b);
1336 
1337   // call indirectly to solve generation ordering problem
1338   lea(rscratch2, ExternalAddress(StubRoutines::verify_oop_subroutine_entry_address()));
1339   ldr(rscratch2, Address(rscratch2));
1340   blr(rscratch2);
1341 
1342   ldp(rscratch2, lr, Address(post(sp, 2 * wordSize)));
1343   ldp(r0, rscratch1, Address(post(sp, 2 * wordSize)));
1344 
1345   BLOCK_COMMENT(&quot;} verify_oop&quot;);
1346 }
1347 
1348 void MacroAssembler::verify_oop_addr(Address addr, const char* s) {
<span class="line-modified">1349   if (!VerifyOops) return;</span>




1350 
1351   const char* b = NULL;
1352   {
1353     ResourceMark rm;
1354     stringStream ss;
1355     ss.print(&quot;verify_oop_addr: %s&quot;, s);
1356     b = code_string(ss.as_string());
1357   }
1358   BLOCK_COMMENT(&quot;verify_oop_addr {&quot;);
1359 
1360   stp(r0, rscratch1, Address(pre(sp, -2 * wordSize)));
1361   stp(rscratch2, lr, Address(pre(sp, -2 * wordSize)));
1362 
1363   // addr may contain sp so we will have to adjust it based on the
1364   // pushes that we just did.
1365   if (addr.uses(sp)) {
1366     lea(r0, addr);
1367     ldr(r0, Address(r0, 4 * wordSize));
1368   } else {
1369     ldr(r0, addr);
</pre>
<hr />
<pre>
1422 
1423 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0) {
1424   pass_arg0(this, arg_0);
1425   call_VM_leaf_base(entry_point, 1);
1426 }
1427 
1428 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1429   pass_arg0(this, arg_0);
1430   pass_arg1(this, arg_1);
1431   call_VM_leaf_base(entry_point, 2);
1432 }
1433 
1434 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0,
1435                                   Register arg_1, Register arg_2) {
1436   pass_arg0(this, arg_0);
1437   pass_arg1(this, arg_1);
1438   pass_arg2(this, arg_2);
1439   call_VM_leaf_base(entry_point, 3);
1440 }
1441 




1442 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1443   pass_arg0(this, arg_0);
1444   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1445 }
1446 
1447 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1448 
1449   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1450   pass_arg1(this, arg_1);
1451   pass_arg0(this, arg_0);
1452   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1453 }
1454 
1455 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1456   assert(arg_0 != c_rarg2, &quot;smashed arg&quot;);
1457   assert(arg_1 != c_rarg2, &quot;smashed arg&quot;);
1458   pass_arg2(this, arg_2);
1459   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1460   pass_arg1(this, arg_1);
1461   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
1471   assert(arg_1 != c_rarg2, &quot;smashed arg&quot;);
1472   pass_arg2(this, arg_2);
1473   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1474   pass_arg1(this, arg_1);
1475   pass_arg0(this, arg_0);
1476   MacroAssembler::call_VM_leaf_base(entry_point, 4);
1477 }
1478 
1479 void MacroAssembler::null_check(Register reg, int offset) {
1480   if (needs_explicit_null_check(offset)) {
1481     // provoke OS NULL exception if reg = NULL by
1482     // accessing M[reg] w/o changing any registers
1483     // NOTE: this is plenty to provoke a segv
1484     ldr(zr, Address(reg));
1485   } else {
1486     // nothing to do, (later) access of M[reg + offset]
1487     // will provoke OS NULL exception if reg = NULL
1488   }
1489 }
1490 

































1491 // MacroAssembler protected routines needed to implement
1492 // public methods
1493 
1494 void MacroAssembler::mov(Register r, Address dest) {
1495   code_section()-&gt;relocate(pc(), dest.rspec());
1496   u_int64_t imm64 = (u_int64_t)dest.target();
1497   movptr(r, imm64);
1498 }
1499 
1500 // Move a constant pointer into r.  In AArch64 mode the virtual
1501 // address space is 48 bits in size, so we only need three
1502 // instructions to create a patchable instruction sequence that can
1503 // reach anywhere.
1504 void MacroAssembler::movptr(Register r, uintptr_t imm64) {
1505 #ifndef PRODUCT
1506   {
1507     char buffer[64];
1508     snprintf(buffer, sizeof(buffer), &quot;0x%&quot; PRIX64, imm64);
1509     block_comment(buffer);
1510   }
</pre>
<hr />
<pre>
3678 }
3679 
3680 void MacroAssembler::cmpptr(Register src1, Address src2) {
3681   unsigned long offset;
3682   adrp(rscratch1, src2, offset);
3683   ldr(rscratch1, Address(rscratch1, offset));
3684   cmp(src1, rscratch1);
3685 }
3686 
3687 void MacroAssembler::cmpoop(Register obj1, Register obj2) {
3688   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3689   bs-&gt;obj_equals(this, obj1, obj2);
3690 }
3691 
3692 void MacroAssembler::load_method_holder(Register holder, Register method) {
3693   ldr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
3694   ldr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
3695   ldr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
3696 }
3697 
<span class="line-modified">3698 void MacroAssembler::load_klass(Register dst, Register src) {</span>
3699   if (UseCompressedClassPointers) {
3700     ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));
<span class="line-removed">3701     decode_klass_not_null(dst);</span>
3702   } else {
3703     ldr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
3704   }
3705 }
3706 










3707 // ((OopHandle)result).resolve();
3708 void MacroAssembler::resolve_oop_handle(Register result, Register tmp) {
3709   // OopHandle::resolve is an indirection.
3710   access_load_at(T_OBJECT, IN_NATIVE, result, Address(result, 0), tmp, noreg);
3711 }
3712 
3713 void MacroAssembler::load_mirror(Register dst, Register method, Register tmp) {
3714   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
3715   ldr(dst, Address(rmethod, Method::const_offset()));
3716   ldr(dst, Address(dst, ConstMethod::constants_offset()));
3717   ldr(dst, Address(dst, ConstantPool::pool_holder_offset_in_bytes()));
3718   ldr(dst, Address(dst, mirror_offset));
3719   resolve_oop_handle(dst, tmp);
3720 }
3721 









3722 void MacroAssembler::cmp_klass(Register oop, Register trial_klass, Register tmp) {
3723   if (UseCompressedClassPointers) {
3724     ldrw(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));
3725     if (CompressedKlassPointers::base() == NULL) {
3726       cmp(trial_klass, tmp, LSL, CompressedKlassPointers::shift());
3727       return;
3728     } else if (((uint64_t)CompressedKlassPointers::base() &amp; 0xffffffff) == 0
3729                &amp;&amp; CompressedKlassPointers::shift() == 0) {
3730       // Only the bottom 32 bits matter
3731       cmpw(trial_klass, tmp);
3732       return;
3733     }
3734     decode_klass_not_null(tmp);
3735   } else {
3736     ldr(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));
3737   }
3738   cmp(trial_klass, tmp);
3739 }
3740 
3741 void MacroAssembler::load_prototype_header(Register dst, Register src) {
</pre>
<hr />
<pre>
4039   narrowKlass nk = CompressedKlassPointers::encode(k);
4040   movz(dst, (nk &gt;&gt; 16), 16);
4041   movk(dst, nk &amp; 0xffff);
4042 }
4043 
4044 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators,
4045                                     Register dst, Address src,
4046                                     Register tmp1, Register thread_tmp) {
4047   BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4048   decorators = AccessInternal::decorator_fixup(decorators);
4049   bool as_raw = (decorators &amp; AS_RAW) != 0;
4050   if (as_raw) {
4051     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4052   } else {
4053     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4054   }
4055 }
4056 
4057 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators,
4058                                      Address dst, Register src,
<span class="line-modified">4059                                      Register tmp1, Register thread_tmp) {</span>

4060   BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4061   decorators = AccessInternal::decorator_fixup(decorators);
4062   bool as_raw = (decorators &amp; AS_RAW) != 0;
4063   if (as_raw) {
<span class="line-modified">4064     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, thread_tmp);</span>
4065   } else {
<span class="line-modified">4066     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, thread_tmp);</span>
4067   }
4068 }
4069 
4070 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4071   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4072   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4073     decorators |= ACCESS_READ | ACCESS_WRITE;
4074   }
4075   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4076   return bs-&gt;resolve(this, decorators, obj);
4077 }
4078 
4079 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4080                                    Register thread_tmp, DecoratorSet decorators) {
4081   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4082 }
4083 
4084 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4085                                             Register thread_tmp, DecoratorSet decorators) {
4086   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4087 }
4088 
4089 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4090                                     Register thread_tmp, DecoratorSet decorators) {</span>
<span class="line-modified">4091   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);</span>
4092 }
4093 
4094 // Used for storing NULLs.
4095 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4096   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);</span>
4097 }
4098 
4099 Address MacroAssembler::allocate_metadata_address(Metadata* obj) {
4100   assert(oop_recorder() != NULL, &quot;this assembler needs a Recorder&quot;);
4101   int index = oop_recorder()-&gt;allocate_metadata_index(obj);
4102   RelocationHolder rspec = metadata_Relocation::spec(index);
4103   return Address((address)obj, rspec);
4104 }
4105 
4106 // Move an oop into a register.  immediate is true if we want
4107 // immediate instrcutions, i.e. we are not going to patch this
4108 // instruction while the code is being executed by another thread.  In
4109 // that case we can use move immediates rather than the constant pool.
4110 void MacroAssembler::movoop(Register dst, jobject obj, bool immediate) {
4111   int oop_index;
4112   if (obj == NULL) {
4113     oop_index = oop_recorder()-&gt;allocate_oop_index(obj);
4114   } else {
4115 #ifdef ASSERT
4116     {
</pre>
<hr />
<pre>
5144 // get_thread() can be called anywhere inside generated code so we
5145 // need to save whatever non-callee save context might get clobbered
5146 // by the call to JavaThread::aarch64_get_thread_helper() or, indeed,
5147 // the call setup code.
5148 //
5149 // aarch64_get_thread_helper() clobbers only r0, r1, and flags.
5150 //
5151 void MacroAssembler::get_thread(Register dst) {
5152   RegSet saved_regs = RegSet::range(r0, r1) + lr - dst;
5153   push(saved_regs, sp);
5154 
5155   mov(lr, CAST_FROM_FN_PTR(address, JavaThread::aarch64_get_thread_helper));
5156   blr(lr);
5157   if (dst != c_rarg0) {
5158     mov(dst, c_rarg0);
5159   }
5160 
5161   pop(saved_regs, sp);
5162 }
5163 






































































































































































































































































































































































































5164 void MacroAssembler::cache_wb(Address line) {
5165   assert(line.getMode() == Address::base_plus_offset, &quot;mode should be base_plus_offset&quot;);
5166   assert(line.index() == noreg, &quot;index should be noreg&quot;);
5167   assert(line.offset() == 0, &quot;offset should be 0&quot;);
5168   // would like to assert this
5169   // assert(line._ext.shift == 0, &quot;shift should be zero&quot;);
5170   if (VM_Version::supports_dcpop()) {
5171     // writeback using clear virtual address to point of persistence
5172     dc(Assembler::CVAP, line.base());
5173   } else {
5174     // no need to generate anything as Unsafe.writebackMemory should
5175     // never invoke this stub
5176   }
5177 }
5178 
5179 void MacroAssembler::cache_wbsync(bool is_pre) {
5180   // we only need a barrier post sync
5181   if (!is_pre) {
5182     membar(Assembler::AnyAny);
5183   }
</pre>
</td>
<td>
<hr />
<pre>
  29 #include &quot;jvm.h&quot;
  30 #include &quot;asm/assembler.hpp&quot;
  31 #include &quot;asm/assembler.inline.hpp&quot;
  32 #include &quot;gc/shared/barrierSet.hpp&quot;
  33 #include &quot;gc/shared/cardTable.hpp&quot;
  34 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  35 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  36 #include &quot;interpreter/interpreter.hpp&quot;
  37 #include &quot;compiler/disassembler.hpp&quot;
  38 #include &quot;memory/resourceArea.hpp&quot;
  39 #include &quot;memory/universe.hpp&quot;
  40 #include &quot;nativeInst_aarch64.hpp&quot;
  41 #include &quot;oops/accessDecorators.hpp&quot;
  42 #include &quot;oops/compressedOops.inline.hpp&quot;
  43 #include &quot;oops/klass.inline.hpp&quot;
  44 #include &quot;runtime/biasedLocking.hpp&quot;
  45 #include &quot;runtime/icache.hpp&quot;
  46 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  47 #include &quot;runtime/jniHandles.inline.hpp&quot;
  48 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  49 #include &quot;runtime/signature_cc.hpp&quot;</span>
  50 #include &quot;runtime/thread.hpp&quot;
  51 #include &quot;utilities/powerOfTwo.hpp&quot;
  52 #ifdef COMPILER1
  53 #include &quot;c1/c1_LIRAssembler.hpp&quot;
  54 #endif
  55 #ifdef COMPILER2
  56 #include &quot;oops/oop.hpp&quot;
  57 #include &quot;opto/compile.hpp&quot;
  58 #include &quot;opto/node.hpp&quot;
  59 #include &quot;opto/output.hpp&quot;
  60 #endif
  61 
  62 #ifdef PRODUCT
  63 #define BLOCK_COMMENT(str) /* nothing */
  64 #define STOP(error) stop(error)
  65 #else
  66 #define BLOCK_COMMENT(str) block_comment(str)
  67 #define STOP(error) block_comment(error); stop(error)
  68 #endif
  69 
</pre>
<hr />
<pre>
1300   ldrb(scratch, Address(klass, InstanceKlass::init_state_offset()));
1301   subs(zr, scratch, InstanceKlass::fully_initialized);
1302   br(Assembler::EQ, *L_fast_path);
1303 
1304   // Fast path check: current thread is initializer thread
1305   ldr(scratch, Address(klass, InstanceKlass::init_thread_offset()));
1306   cmp(rthread, scratch);
1307 
1308   if (L_slow_path == &amp;L_fallthrough) {
1309     br(Assembler::EQ, *L_fast_path);
1310     bind(*L_slow_path);
1311   } else if (L_fast_path == &amp;L_fallthrough) {
1312     br(Assembler::NE, *L_slow_path);
1313     bind(*L_fast_path);
1314   } else {
1315     Unimplemented();
1316   }
1317 }
1318 
1319 void MacroAssembler::verify_oop(Register reg, const char* s) {
<span class="line-modified">1320   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">1321     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">1322     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">1323     return;</span>
<span class="line-added">1324   }</span>
1325 
1326   // Pass register number to verify_oop_subroutine
1327   const char* b = NULL;
1328   {
1329     ResourceMark rm;
1330     stringStream ss;
1331     ss.print(&quot;verify_oop: %s: %s&quot;, reg-&gt;name(), s);
1332     b = code_string(ss.as_string());
1333   }
1334   BLOCK_COMMENT(&quot;verify_oop {&quot;);
1335 
1336   stp(r0, rscratch1, Address(pre(sp, -2 * wordSize)));
1337   stp(rscratch2, lr, Address(pre(sp, -2 * wordSize)));
1338 
1339   mov(r0, reg);
1340   mov(rscratch1, (address)b);
1341 
1342   // call indirectly to solve generation ordering problem
1343   lea(rscratch2, ExternalAddress(StubRoutines::verify_oop_subroutine_entry_address()));
1344   ldr(rscratch2, Address(rscratch2));
1345   blr(rscratch2);
1346 
1347   ldp(rscratch2, lr, Address(post(sp, 2 * wordSize)));
1348   ldp(r0, rscratch1, Address(post(sp, 2 * wordSize)));
1349 
1350   BLOCK_COMMENT(&quot;} verify_oop&quot;);
1351 }
1352 
1353 void MacroAssembler::verify_oop_addr(Address addr, const char* s) {
<span class="line-modified">1354   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">1355     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">1356     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">1357     return;</span>
<span class="line-added">1358   }</span>
1359 
1360   const char* b = NULL;
1361   {
1362     ResourceMark rm;
1363     stringStream ss;
1364     ss.print(&quot;verify_oop_addr: %s&quot;, s);
1365     b = code_string(ss.as_string());
1366   }
1367   BLOCK_COMMENT(&quot;verify_oop_addr {&quot;);
1368 
1369   stp(r0, rscratch1, Address(pre(sp, -2 * wordSize)));
1370   stp(rscratch2, lr, Address(pre(sp, -2 * wordSize)));
1371 
1372   // addr may contain sp so we will have to adjust it based on the
1373   // pushes that we just did.
1374   if (addr.uses(sp)) {
1375     lea(r0, addr);
1376     ldr(r0, Address(r0, 4 * wordSize));
1377   } else {
1378     ldr(r0, addr);
</pre>
<hr />
<pre>
1431 
1432 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0) {
1433   pass_arg0(this, arg_0);
1434   call_VM_leaf_base(entry_point, 1);
1435 }
1436 
1437 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1438   pass_arg0(this, arg_0);
1439   pass_arg1(this, arg_1);
1440   call_VM_leaf_base(entry_point, 2);
1441 }
1442 
1443 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0,
1444                                   Register arg_1, Register arg_2) {
1445   pass_arg0(this, arg_0);
1446   pass_arg1(this, arg_1);
1447   pass_arg2(this, arg_2);
1448   call_VM_leaf_base(entry_point, 3);
1449 }
1450 
<span class="line-added">1451 void MacroAssembler::super_call_VM_leaf(address entry_point) {</span>
<span class="line-added">1452   MacroAssembler::call_VM_leaf_base(entry_point, 1);</span>
<span class="line-added">1453 }</span>
<span class="line-added">1454 </span>
1455 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1456   pass_arg0(this, arg_0);
1457   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1458 }
1459 
1460 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1461 
1462   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1463   pass_arg1(this, arg_1);
1464   pass_arg0(this, arg_0);
1465   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1466 }
1467 
1468 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1469   assert(arg_0 != c_rarg2, &quot;smashed arg&quot;);
1470   assert(arg_1 != c_rarg2, &quot;smashed arg&quot;);
1471   pass_arg2(this, arg_2);
1472   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1473   pass_arg1(this, arg_1);
1474   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
1484   assert(arg_1 != c_rarg2, &quot;smashed arg&quot;);
1485   pass_arg2(this, arg_2);
1486   assert(arg_0 != c_rarg1, &quot;smashed arg&quot;);
1487   pass_arg1(this, arg_1);
1488   pass_arg0(this, arg_0);
1489   MacroAssembler::call_VM_leaf_base(entry_point, 4);
1490 }
1491 
1492 void MacroAssembler::null_check(Register reg, int offset) {
1493   if (needs_explicit_null_check(offset)) {
1494     // provoke OS NULL exception if reg = NULL by
1495     // accessing M[reg] w/o changing any registers
1496     // NOTE: this is plenty to provoke a segv
1497     ldr(zr, Address(reg));
1498   } else {
1499     // nothing to do, (later) access of M[reg + offset]
1500     // will provoke OS NULL exception if reg = NULL
1501   }
1502 }
1503 
<span class="line-added">1504 void MacroAssembler::test_klass_is_value(Register klass, Register temp_reg, Label&amp; is_value) {</span>
<span class="line-added">1505   ldrw(temp_reg, Address(klass, Klass::access_flags_offset()));</span>
<span class="line-added">1506   andr(temp_reg, temp_reg, JVM_ACC_VALUE);</span>
<span class="line-added">1507   cbnz(temp_reg, is_value);</span>
<span class="line-added">1508 }</span>
<span class="line-added">1509 </span>
<span class="line-added">1510 void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label&amp; is_flattenable) {</span>
<span class="line-added">1511   (void) temp_reg; // keep signature uniform with x86</span>
<span class="line-added">1512   tbnz(flags, ConstantPoolCacheEntry::is_flattenable_field_shift, is_flattenable);</span>
<span class="line-added">1513 }</span>
<span class="line-added">1514 </span>
<span class="line-added">1515 void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label&amp; not_flattenable) {</span>
<span class="line-added">1516   (void) temp_reg; // keep signature uniform with x86</span>
<span class="line-added">1517   tbz(flags, ConstantPoolCacheEntry::is_flattenable_field_shift, not_flattenable);</span>
<span class="line-added">1518 }</span>
<span class="line-added">1519 </span>
<span class="line-added">1520 void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label&amp; is_flattened) {</span>
<span class="line-added">1521   (void) temp_reg; // keep signature uniform with x86</span>
<span class="line-added">1522   tbnz(flags, ConstantPoolCacheEntry::is_flattened_field_shift, is_flattened);</span>
<span class="line-added">1523 }</span>
<span class="line-added">1524 </span>
<span class="line-added">1525 void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg, Label&amp; is_flattened_array) {</span>
<span class="line-added">1526   load_storage_props(temp_reg, oop);</span>
<span class="line-added">1527   andr(temp_reg, temp_reg, ArrayStorageProperties::flattened_value);</span>
<span class="line-added">1528   cbnz(temp_reg, is_flattened_array);</span>
<span class="line-added">1529 }</span>
<span class="line-added">1530 </span>
<span class="line-added">1531 void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&amp; is_null_free_array) {</span>
<span class="line-added">1532   load_storage_props(temp_reg, oop);</span>
<span class="line-added">1533   andr(temp_reg, temp_reg, ArrayStorageProperties::null_free_value);</span>
<span class="line-added">1534   cbnz(temp_reg, is_null_free_array);</span>
<span class="line-added">1535 }</span>
<span class="line-added">1536 </span>
1537 // MacroAssembler protected routines needed to implement
1538 // public methods
1539 
1540 void MacroAssembler::mov(Register r, Address dest) {
1541   code_section()-&gt;relocate(pc(), dest.rspec());
1542   u_int64_t imm64 = (u_int64_t)dest.target();
1543   movptr(r, imm64);
1544 }
1545 
1546 // Move a constant pointer into r.  In AArch64 mode the virtual
1547 // address space is 48 bits in size, so we only need three
1548 // instructions to create a patchable instruction sequence that can
1549 // reach anywhere.
1550 void MacroAssembler::movptr(Register r, uintptr_t imm64) {
1551 #ifndef PRODUCT
1552   {
1553     char buffer[64];
1554     snprintf(buffer, sizeof(buffer), &quot;0x%&quot; PRIX64, imm64);
1555     block_comment(buffer);
1556   }
</pre>
<hr />
<pre>
3724 }
3725 
3726 void MacroAssembler::cmpptr(Register src1, Address src2) {
3727   unsigned long offset;
3728   adrp(rscratch1, src2, offset);
3729   ldr(rscratch1, Address(rscratch1, offset));
3730   cmp(src1, rscratch1);
3731 }
3732 
3733 void MacroAssembler::cmpoop(Register obj1, Register obj2) {
3734   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3735   bs-&gt;obj_equals(this, obj1, obj2);
3736 }
3737 
3738 void MacroAssembler::load_method_holder(Register holder, Register method) {
3739   ldr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
3740   ldr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
3741   ldr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
3742 }
3743 
<span class="line-modified">3744 void MacroAssembler::load_metadata(Register dst, Register src) {</span>
3745   if (UseCompressedClassPointers) {
3746     ldrw(dst, Address(src, oopDesc::klass_offset_in_bytes()));

3747   } else {
3748     ldr(dst, Address(src, oopDesc::klass_offset_in_bytes()));
3749   }
3750 }
3751 
<span class="line-added">3752 void MacroAssembler::load_klass(Register dst, Register src) {</span>
<span class="line-added">3753   load_metadata(dst, src);</span>
<span class="line-added">3754   if (UseCompressedClassPointers) {</span>
<span class="line-added">3755     andr(dst, dst, oopDesc::compressed_klass_mask());</span>
<span class="line-added">3756     decode_klass_not_null(dst);</span>
<span class="line-added">3757   } else {</span>
<span class="line-added">3758     ubfm(dst, dst, 0, 63 - oopDesc::storage_props_nof_bits);</span>
<span class="line-added">3759   }</span>
<span class="line-added">3760 }</span>
<span class="line-added">3761 </span>
3762 // ((OopHandle)result).resolve();
3763 void MacroAssembler::resolve_oop_handle(Register result, Register tmp) {
3764   // OopHandle::resolve is an indirection.
3765   access_load_at(T_OBJECT, IN_NATIVE, result, Address(result, 0), tmp, noreg);
3766 }
3767 
3768 void MacroAssembler::load_mirror(Register dst, Register method, Register tmp) {
3769   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
3770   ldr(dst, Address(rmethod, Method::const_offset()));
3771   ldr(dst, Address(dst, ConstMethod::constants_offset()));
3772   ldr(dst, Address(dst, ConstantPool::pool_holder_offset_in_bytes()));
3773   ldr(dst, Address(dst, mirror_offset));
3774   resolve_oop_handle(dst, tmp);
3775 }
3776 
<span class="line-added">3777 void MacroAssembler::load_storage_props(Register dst, Register src) {</span>
<span class="line-added">3778   load_metadata(dst, src);</span>
<span class="line-added">3779   if (UseCompressedClassPointers) {</span>
<span class="line-added">3780     asrw(dst, dst, oopDesc::narrow_storage_props_shift);</span>
<span class="line-added">3781   } else {</span>
<span class="line-added">3782     asr(dst, dst, oopDesc::wide_storage_props_shift);</span>
<span class="line-added">3783   }</span>
<span class="line-added">3784 }</span>
<span class="line-added">3785 </span>
3786 void MacroAssembler::cmp_klass(Register oop, Register trial_klass, Register tmp) {
3787   if (UseCompressedClassPointers) {
3788     ldrw(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));
3789     if (CompressedKlassPointers::base() == NULL) {
3790       cmp(trial_klass, tmp, LSL, CompressedKlassPointers::shift());
3791       return;
3792     } else if (((uint64_t)CompressedKlassPointers::base() &amp; 0xffffffff) == 0
3793                &amp;&amp; CompressedKlassPointers::shift() == 0) {
3794       // Only the bottom 32 bits matter
3795       cmpw(trial_klass, tmp);
3796       return;
3797     }
3798     decode_klass_not_null(tmp);
3799   } else {
3800     ldr(tmp, Address(oop, oopDesc::klass_offset_in_bytes()));
3801   }
3802   cmp(trial_klass, tmp);
3803 }
3804 
3805 void MacroAssembler::load_prototype_header(Register dst, Register src) {
</pre>
<hr />
<pre>
4103   narrowKlass nk = CompressedKlassPointers::encode(k);
4104   movz(dst, (nk &gt;&gt; 16), 16);
4105   movk(dst, nk &amp; 0xffff);
4106 }
4107 
4108 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators,
4109                                     Register dst, Address src,
4110                                     Register tmp1, Register thread_tmp) {
4111   BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4112   decorators = AccessInternal::decorator_fixup(decorators);
4113   bool as_raw = (decorators &amp; AS_RAW) != 0;
4114   if (as_raw) {
4115     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4116   } else {
4117     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4118   }
4119 }
4120 
4121 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators,
4122                                      Address dst, Register src,
<span class="line-modified">4123                                      Register tmp1, Register thread_tmp, Register tmp3) {</span>
<span class="line-added">4124 </span>
4125   BarrierSetAssembler *bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4126   decorators = AccessInternal::decorator_fixup(decorators);
4127   bool as_raw = (decorators &amp; AS_RAW) != 0;
4128   if (as_raw) {
<span class="line-modified">4129     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, thread_tmp, tmp3);</span>
4130   } else {
<span class="line-modified">4131     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, thread_tmp, tmp3);</span>
4132   }
4133 }
4134 
4135 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4136   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4137   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4138     decorators |= ACCESS_READ | ACCESS_WRITE;
4139   }
4140   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4141   return bs-&gt;resolve(this, decorators, obj);
4142 }
4143 
4144 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4145                                    Register thread_tmp, DecoratorSet decorators) {
4146   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4147 }
4148 
4149 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4150                                             Register thread_tmp, DecoratorSet decorators) {
4151   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4152 }
4153 
4154 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4155                                     Register thread_tmp, Register tmp3, DecoratorSet decorators) {</span>
<span class="line-modified">4156   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp, tmp3);</span>
4157 }
4158 
4159 // Used for storing NULLs.
4160 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4161   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);</span>
4162 }
4163 
4164 Address MacroAssembler::allocate_metadata_address(Metadata* obj) {
4165   assert(oop_recorder() != NULL, &quot;this assembler needs a Recorder&quot;);
4166   int index = oop_recorder()-&gt;allocate_metadata_index(obj);
4167   RelocationHolder rspec = metadata_Relocation::spec(index);
4168   return Address((address)obj, rspec);
4169 }
4170 
4171 // Move an oop into a register.  immediate is true if we want
4172 // immediate instrcutions, i.e. we are not going to patch this
4173 // instruction while the code is being executed by another thread.  In
4174 // that case we can use move immediates rather than the constant pool.
4175 void MacroAssembler::movoop(Register dst, jobject obj, bool immediate) {
4176   int oop_index;
4177   if (obj == NULL) {
4178     oop_index = oop_recorder()-&gt;allocate_oop_index(obj);
4179   } else {
4180 #ifdef ASSERT
4181     {
</pre>
<hr />
<pre>
5209 // get_thread() can be called anywhere inside generated code so we
5210 // need to save whatever non-callee save context might get clobbered
5211 // by the call to JavaThread::aarch64_get_thread_helper() or, indeed,
5212 // the call setup code.
5213 //
5214 // aarch64_get_thread_helper() clobbers only r0, r1, and flags.
5215 //
5216 void MacroAssembler::get_thread(Register dst) {
5217   RegSet saved_regs = RegSet::range(r0, r1) + lr - dst;
5218   push(saved_regs, sp);
5219 
5220   mov(lr, CAST_FROM_FN_PTR(address, JavaThread::aarch64_get_thread_helper));
5221   blr(lr);
5222   if (dst != c_rarg0) {
5223     mov(dst, c_rarg0);
5224   }
5225 
5226   pop(saved_regs, sp);
5227 }
5228 
<span class="line-added">5229 // C2 compiled method&#39;s prolog code</span>
<span class="line-added">5230 // Moved here from aarch64.ad to support Valhalla code belows</span>
<span class="line-added">5231 void MacroAssembler::verified_entry(Compile* C, int sp_inc) {</span>
<span class="line-added">5232 </span>
<span class="line-added">5233 // n.b. frame size includes space for return pc and rfp</span>
<span class="line-added">5234   const long framesize = C-&gt;frame_size_in_bytes();</span>
<span class="line-added">5235   assert(framesize % (2 * wordSize) == 0, &quot;must preserve 2 * wordSize alignment&quot;);</span>
<span class="line-added">5236 </span>
<span class="line-added">5237   // insert a nop at the start of the prolog so we can patch in a</span>
<span class="line-added">5238   // branch if we need to invalidate the method later</span>
<span class="line-added">5239   nop();</span>
<span class="line-added">5240 </span>
<span class="line-added">5241   int bangsize = C-&gt;bang_size_in_bytes();</span>
<span class="line-added">5242   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)</span>
<span class="line-added">5243      generate_stack_overflow_check(bangsize);</span>
<span class="line-added">5244 </span>
<span class="line-added">5245   build_frame(framesize);</span>
<span class="line-added">5246 </span>
<span class="line-added">5247   if (VerifyStackAtCalls) {</span>
<span class="line-added">5248     Unimplemented();</span>
<span class="line-added">5249   }</span>
<span class="line-added">5250 }</span>
<span class="line-added">5251 </span>
<span class="line-added">5252 int MacroAssembler::store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {</span>
<span class="line-added">5253   // A value type might be returned. If fields are in registers we</span>
<span class="line-added">5254   // need to allocate a value type instance and initialize it with</span>
<span class="line-added">5255   // the value of the fields.</span>
<span class="line-added">5256   Label skip;</span>
<span class="line-added">5257   // We only need a new buffered value if a new one is not returned</span>
<span class="line-added">5258   cmp(r0, (u1) 1);</span>
<span class="line-added">5259   br(Assembler::EQ, skip);</span>
<span class="line-added">5260   int call_offset = -1;</span>
<span class="line-added">5261 </span>
<span class="line-added">5262   Label slow_case;</span>
<span class="line-added">5263 </span>
<span class="line-added">5264   // Try to allocate a new buffered value (from the heap)</span>
<span class="line-added">5265   if (UseTLAB) {</span>
<span class="line-added">5266 </span>
<span class="line-added">5267     if (vk != NULL) {</span>
<span class="line-added">5268       // Called from C1, where the return type is statically known.</span>
<span class="line-added">5269       mov(r1, (intptr_t)vk-&gt;get_ValueKlass());</span>
<span class="line-added">5270       jint lh = vk-&gt;layout_helper();</span>
<span class="line-added">5271       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);</span>
<span class="line-added">5272       mov(r14, lh);</span>
<span class="line-added">5273     } else {</span>
<span class="line-added">5274        // Call from interpreter. R0 contains ((the ValueKlass* of the return type) | 0x01)</span>
<span class="line-added">5275        andr(r1, r0, -2);</span>
<span class="line-added">5276        // get obj size</span>
<span class="line-added">5277        ldrw(r14, Address(rscratch1 /*klass*/, Klass::layout_helper_offset()));</span>
<span class="line-added">5278     }</span>
<span class="line-added">5279 </span>
<span class="line-added">5280      ldr(r13, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));</span>
<span class="line-added">5281 </span>
<span class="line-added">5282      // check whether we have space in TLAB,</span>
<span class="line-added">5283      // rscratch1 contains pointer to just allocated obj</span>
<span class="line-added">5284       lea(r14, Address(r13, r14));</span>
<span class="line-added">5285       ldr(rscratch1, Address(rthread, in_bytes(JavaThread::tlab_end_offset())));</span>
<span class="line-added">5286 </span>
<span class="line-added">5287       cmp(r14, rscratch1);</span>
<span class="line-added">5288       br(Assembler::GT, slow_case);</span>
<span class="line-added">5289 </span>
<span class="line-added">5290       // OK we have room in TLAB,</span>
<span class="line-added">5291       // Set new TLAB top</span>
<span class="line-added">5292       str(r14, Address(rthread, in_bytes(JavaThread::tlab_top_offset())));</span>
<span class="line-added">5293 </span>
<span class="line-added">5294       // Set new class always locked</span>
<span class="line-added">5295       mov(rscratch1, (uint64_t) markWord::always_locked_prototype().value());</span>
<span class="line-added">5296       str(rscratch1, Address(r13, oopDesc::mark_offset_in_bytes()));</span>
<span class="line-added">5297 </span>
<span class="line-added">5298       store_klass_gap(r13, zr);  // zero klass gap for compressed oops</span>
<span class="line-added">5299       if (vk == NULL) {</span>
<span class="line-added">5300         // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).</span>
<span class="line-added">5301          mov(r0, r1);</span>
<span class="line-added">5302       }</span>
<span class="line-added">5303 </span>
<span class="line-added">5304       store_klass(r13, r1);  // klass</span>
<span class="line-added">5305 </span>
<span class="line-added">5306       if (vk != NULL) {</span>
<span class="line-added">5307         // FIXME -- do the packing in-line to avoid the runtime call</span>
<span class="line-added">5308         mov(r0, r13);</span>
<span class="line-added">5309         far_call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.</span>
<span class="line-added">5310       } else {</span>
<span class="line-added">5311 </span>
<span class="line-added">5312         // We have our new buffered value, initialize its fields with a</span>
<span class="line-added">5313         // value class specific handler</span>
<span class="line-added">5314         ldr(r1, Address(r0, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">5315         ldr(r1, Address(r1, ValueKlass::pack_handler_offset()));</span>
<span class="line-added">5316 </span>
<span class="line-added">5317         // Mov new class to r0 and call pack_handler</span>
<span class="line-added">5318         mov(r0, r13);</span>
<span class="line-added">5319         blr(r1);</span>
<span class="line-added">5320       }</span>
<span class="line-added">5321       b(skip);</span>
<span class="line-added">5322   }</span>
<span class="line-added">5323 </span>
<span class="line-added">5324   bind(slow_case);</span>
<span class="line-added">5325   // We failed to allocate a new value, fall back to a runtime</span>
<span class="line-added">5326   // call. Some oop field may be live in some registers but we can&#39;t</span>
<span class="line-added">5327   // tell. That runtime call will take care of preserving them</span>
<span class="line-added">5328   // across a GC if there&#39;s one.</span>
<span class="line-added">5329 </span>
<span class="line-added">5330 </span>
<span class="line-added">5331   if (from_interpreter) {</span>
<span class="line-added">5332     super_call_VM_leaf(StubRoutines::store_value_type_fields_to_buf());</span>
<span class="line-added">5333   } else {</span>
<span class="line-added">5334     ldr(rscratch1, RuntimeAddress(StubRoutines::store_value_type_fields_to_buf()));</span>
<span class="line-added">5335     blr(rscratch1);</span>
<span class="line-added">5336     call_offset = offset();</span>
<span class="line-added">5337   }</span>
<span class="line-added">5338 </span>
<span class="line-added">5339   bind(skip);</span>
<span class="line-added">5340   return call_offset;</span>
<span class="line-added">5341 }</span>
<span class="line-added">5342 </span>
<span class="line-added">5343 // Move a value between registers/stack slots and update the reg_state</span>
<span class="line-added">5344 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5345   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5346     return true; // Already written</span>
<span class="line-added">5347   }</span>
<span class="line-added">5348 </span>
<span class="line-added">5349   if (from != to &amp;&amp; bt != T_VOID) {</span>
<span class="line-added">5350     if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5351       return false; // Not yet writable</span>
<span class="line-added">5352     }</span>
<span class="line-added">5353     if (from-&gt;is_reg()) {</span>
<span class="line-added">5354       if (to-&gt;is_reg()) {</span>
<span class="line-added">5355         mov(to-&gt;as_Register(), from-&gt;as_Register());</span>
<span class="line-added">5356       } else {</span>
<span class="line-added">5357         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5358         Address to_addr = Address(sp, st_off);</span>
<span class="line-added">5359         if (from-&gt;is_FloatRegister()) {</span>
<span class="line-added">5360           if (bt == T_DOUBLE) {</span>
<span class="line-added">5361              strd(from-&gt;as_FloatRegister(), to_addr);</span>
<span class="line-added">5362           } else {</span>
<span class="line-added">5363              assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5364              strs(from-&gt;as_FloatRegister(), to_addr);</span>
<span class="line-added">5365           }</span>
<span class="line-added">5366         } else {</span>
<span class="line-added">5367           str(from-&gt;as_Register(), to_addr);</span>
<span class="line-added">5368         }</span>
<span class="line-added">5369       }</span>
<span class="line-added">5370     } else {</span>
<span class="line-added">5371       Address from_addr = Address(sp, from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset);</span>
<span class="line-added">5372       if (to-&gt;is_reg()) {</span>
<span class="line-added">5373         if (to-&gt;is_FloatRegister()) {</span>
<span class="line-added">5374           if (bt == T_DOUBLE) {</span>
<span class="line-added">5375              ldrd(to-&gt;as_FloatRegister(), from_addr);</span>
<span class="line-added">5376           } else {</span>
<span class="line-added">5377             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5378             ldrs(to-&gt;as_FloatRegister(), from_addr);</span>
<span class="line-added">5379           }</span>
<span class="line-added">5380         } else {</span>
<span class="line-added">5381           ldr(to-&gt;as_Register(), from_addr);</span>
<span class="line-added">5382         }</span>
<span class="line-added">5383       } else {</span>
<span class="line-added">5384         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5385         ldr(rscratch1, from_addr);</span>
<span class="line-added">5386         str(rscratch1, Address(sp, st_off));</span>
<span class="line-added">5387       }</span>
<span class="line-added">5388     }</span>
<span class="line-added">5389   }</span>
<span class="line-added">5390 </span>
<span class="line-added">5391   // Update register states</span>
<span class="line-added">5392   reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5393   reg_state[to-&gt;value()] = reg_written;</span>
<span class="line-added">5394   return true;</span>
<span class="line-added">5395 }</span>
<span class="line-added">5396 </span>
<span class="line-added">5397 // Read all fields from a value type oop and store the values in registers/stack slots</span>
<span class="line-added">5398 bool MacroAssembler::unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
<span class="line-added">5399                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5400   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;</span>
<span class="line-added">5401   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5402 </span>
<span class="line-added">5403 </span>
<span class="line-added">5404   int vt = 1;</span>
<span class="line-added">5405   bool done = true;</span>
<span class="line-added">5406   bool mark_done = true;</span>
<span class="line-added">5407   do {</span>
<span class="line-added">5408     sig_index--;</span>
<span class="line-added">5409     BasicType bt = sig-&gt;at(sig_index)._bt;</span>
<span class="line-added">5410     if (bt == T_VALUETYPE) {</span>
<span class="line-added">5411       vt--;</span>
<span class="line-added">5412     } else if (bt == T_VOID &amp;&amp;</span>
<span class="line-added">5413                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;</span>
<span class="line-added">5414                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {</span>
<span class="line-added">5415       vt++;</span>
<span class="line-added">5416     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {</span>
<span class="line-added">5417       to_index--; // Ignore this</span>
<span class="line-added">5418     } else {</span>
<span class="line-added">5419       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);</span>
<span class="line-added">5420       VMRegPair pair_to = regs_to[to_index--];</span>
<span class="line-added">5421       VMReg to = pair_to.first();</span>
<span class="line-added">5422 </span>
<span class="line-added">5423       if (bt == T_VOID) continue;</span>
<span class="line-added">5424 </span>
<span class="line-added">5425       int idx = (int) to-&gt;value();</span>
<span class="line-added">5426       if (reg_state[idx] == reg_readonly) {</span>
<span class="line-added">5427          if (idx != from-&gt;value()) {</span>
<span class="line-added">5428            mark_done = false;</span>
<span class="line-added">5429          }</span>
<span class="line-added">5430          done = false;</span>
<span class="line-added">5431          continue;</span>
<span class="line-added">5432       } else if (reg_state[idx] == reg_written) {</span>
<span class="line-added">5433         continue;</span>
<span class="line-added">5434       } else {</span>
<span class="line-added">5435         assert(reg_state[idx] == reg_writable, &quot;must be writable&quot;);</span>
<span class="line-added">5436         reg_state[idx] = reg_written;</span>
<span class="line-added">5437       }</span>
<span class="line-added">5438 </span>
<span class="line-added">5439       if (fromReg == noreg) {</span>
<span class="line-added">5440         int st_off = from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5441         ldr(rscratch2, Address(sp, st_off));</span>
<span class="line-added">5442         fromReg = rscratch2;</span>
<span class="line-added">5443       }</span>
<span class="line-added">5444 </span>
<span class="line-added">5445       int off = sig-&gt;at(sig_index)._offset;</span>
<span class="line-added">5446       assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5447       bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5448 </span>
<span class="line-added">5449       Address fromAddr = Address(fromReg, off);</span>
<span class="line-added">5450       bool is_signed = (bt != T_CHAR) &amp;&amp; (bt != T_BOOLEAN);</span>
<span class="line-added">5451 </span>
<span class="line-added">5452       if (!to-&gt;is_FloatRegister()) {</span>
<span class="line-added">5453 </span>
<span class="line-added">5454         Register dst = to-&gt;is_stack() ? rscratch1 : to-&gt;as_Register();</span>
<span class="line-added">5455 </span>
<span class="line-added">5456         if (is_oop) {</span>
<span class="line-added">5457           load_heap_oop(dst, fromAddr);</span>
<span class="line-added">5458         } else {</span>
<span class="line-added">5459           load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);</span>
<span class="line-added">5460         }</span>
<span class="line-added">5461         if (to-&gt;is_stack()) {</span>
<span class="line-added">5462           int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5463           str(dst, Address(sp, st_off));</span>
<span class="line-added">5464         }</span>
<span class="line-added">5465       } else {</span>
<span class="line-added">5466         if (bt == T_DOUBLE) {</span>
<span class="line-added">5467           ldrd(to-&gt;as_FloatRegister(), fromAddr);</span>
<span class="line-added">5468         } else {</span>
<span class="line-added">5469           assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5470           ldrs(to-&gt;as_FloatRegister(), fromAddr);</span>
<span class="line-added">5471         }</span>
<span class="line-added">5472      }</span>
<span class="line-added">5473 </span>
<span class="line-added">5474     }</span>
<span class="line-added">5475 </span>
<span class="line-added">5476   } while (vt != 0);</span>
<span class="line-added">5477 </span>
<span class="line-added">5478   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {</span>
<span class="line-added">5479     // This is okay because no one else will write to that slot</span>
<span class="line-added">5480     reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5481   }</span>
<span class="line-added">5482   return done;</span>
<span class="line-added">5483 }</span>
<span class="line-added">5484 </span>
<span class="line-added">5485 // Pack fields back into a value type oop</span>
<span class="line-added">5486 bool MacroAssembler::pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
<span class="line-added">5487                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-added">5488                                        int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5489   assert(sig-&gt;at(sig_index)._bt == T_VALUETYPE, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5490   assert(to-&gt;is_valid(), &quot;must be&quot;);</span>
<span class="line-added">5491 </span>
<span class="line-added">5492   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5493     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5494     return true; // Already written</span>
<span class="line-added">5495   }</span>
<span class="line-added">5496 </span>
<span class="line-added">5497   Register val_array = r0;</span>
<span class="line-added">5498   Register val_obj_tmp = r11;</span>
<span class="line-added">5499   Register from_reg_tmp = r10;</span>
<span class="line-added">5500   Register tmp1 = r14;</span>
<span class="line-added">5501   Register tmp2 = r13;</span>
<span class="line-added">5502   Register tmp3 = r1;</span>
<span class="line-added">5503   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();</span>
<span class="line-added">5504 </span>
<span class="line-added">5505   if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5506     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {</span>
<span class="line-added">5507       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5508       return false; // Not yet writable</span>
<span class="line-added">5509     }</span>
<span class="line-added">5510     val_obj = val_obj_tmp;</span>
<span class="line-added">5511   }</span>
<span class="line-added">5512 </span>
<span class="line-added">5513   int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_VALUETYPE);</span>
<span class="line-added">5514   load_heap_oop(val_obj, Address(val_array, index));</span>
<span class="line-added">5515 </span>
<span class="line-added">5516   ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5517   VMRegPair from_pair;</span>
<span class="line-added">5518   BasicType bt;</span>
<span class="line-added">5519 </span>
<span class="line-added">5520   while (stream.next(from_pair, bt)) {</span>
<span class="line-added">5521     int off = sig-&gt;at(stream.sig_cc_index())._offset;</span>
<span class="line-added">5522     assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5523     bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5524     size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;</span>
<span class="line-added">5525 </span>
<span class="line-added">5526     VMReg from_r1 = from_pair.first();</span>
<span class="line-added">5527     VMReg from_r2 = from_pair.second();</span>
<span class="line-added">5528 </span>
<span class="line-added">5529     // Pack the scalarized field into the value object.</span>
<span class="line-added">5530     Address dst(val_obj, off);</span>
<span class="line-added">5531 </span>
<span class="line-added">5532     if (!from_r1-&gt;is_FloatRegister()) {</span>
<span class="line-added">5533       Register from_reg;</span>
<span class="line-added">5534       if (from_r1-&gt;is_stack()) {</span>
<span class="line-added">5535         from_reg = from_reg_tmp;</span>
<span class="line-added">5536         int ld_off = from_r1-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5537         load_sized_value(from_reg, Address(sp, ld_off), size_in_bytes, /* is_signed */ false);</span>
<span class="line-added">5538       } else {</span>
<span class="line-added">5539         from_reg = from_r1-&gt;as_Register();</span>
<span class="line-added">5540       }</span>
<span class="line-added">5541 </span>
<span class="line-added">5542       if (is_oop) {</span>
<span class="line-added">5543         DecoratorSet decorators = IN_HEAP | ACCESS_WRITE;</span>
<span class="line-added">5544         store_heap_oop(dst, from_reg, tmp1, tmp2, tmp3, decorators);</span>
<span class="line-added">5545       } else {</span>
<span class="line-added">5546         store_sized_value(dst, from_reg, size_in_bytes);</span>
<span class="line-added">5547       }</span>
<span class="line-added">5548     } else {</span>
<span class="line-added">5549       if (from_r2-&gt;is_valid()) {</span>
<span class="line-added">5550         strd(from_r1-&gt;as_FloatRegister(), dst);</span>
<span class="line-added">5551       } else {</span>
<span class="line-added">5552         strs(from_r1-&gt;as_FloatRegister(), dst);</span>
<span class="line-added">5553       }</span>
<span class="line-added">5554     }</span>
<span class="line-added">5555 </span>
<span class="line-added">5556     reg_state[from_r1-&gt;value()] = reg_writable;</span>
<span class="line-added">5557   }</span>
<span class="line-added">5558   sig_index = stream.sig_cc_index();</span>
<span class="line-added">5559   from_index = stream.regs_cc_index();</span>
<span class="line-added">5560 </span>
<span class="line-added">5561   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);</span>
<span class="line-added">5562   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);</span>
<span class="line-added">5563   assert(success, &quot;to register must be writeable&quot;);</span>
<span class="line-added">5564 </span>
<span class="line-added">5565   return true;</span>
<span class="line-added">5566 }</span>
<span class="line-added">5567 </span>
<span class="line-added">5568 // Unpack all value type arguments passed as oops</span>
<span class="line-added">5569 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {</span>
<span class="line-added">5570   int sp_inc = unpack_value_args_common(C, receiver_only);</span>
<span class="line-added">5571   // Emit code for verified entry and save increment for stack repair on return</span>
<span class="line-added">5572   verified_entry(C, sp_inc);</span>
<span class="line-added">5573 }</span>
<span class="line-added">5574 </span>
<span class="line-added">5575 int MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-added">5576                                        BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-added">5577                                        int args_passed, int args_on_stack, VMRegPair* regs,            // from</span>
<span class="line-added">5578                                        int args_passed_to, int args_on_stack_to, VMRegPair* regs_to) { // to</span>
<span class="line-added">5579   // Check if we need to extend the stack for packing/unpacking</span>
<span class="line-added">5580   int sp_inc = (args_on_stack_to - args_on_stack) * VMRegImpl::stack_slot_size;</span>
<span class="line-added">5581   if (sp_inc &gt; 0) {</span>
<span class="line-added">5582     sp_inc = align_up(sp_inc, StackAlignmentInBytes);</span>
<span class="line-added">5583     if (!is_packing) {</span>
<span class="line-added">5584       // Save the return address, adjust the stack (make sure it is properly</span>
<span class="line-added">5585       // 16-byte aligned) and copy the return address to the new top of the stack.</span>
<span class="line-added">5586       // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).</span>
<span class="line-added">5587       // FIXME: We need not to preserve return address on aarch64</span>
<span class="line-added">5588       pop(rscratch1);</span>
<span class="line-added">5589       sub(sp, sp, sp_inc);</span>
<span class="line-added">5590       push(rscratch1);</span>
<span class="line-added">5591     }</span>
<span class="line-added">5592   } else {</span>
<span class="line-added">5593     // The scalarized calling convention needs less stack space than the unscalarized one.</span>
<span class="line-added">5594     // No need to extend the stack, the caller will take care of these adjustments.</span>
<span class="line-added">5595     sp_inc = 0;</span>
<span class="line-added">5596   }</span>
<span class="line-added">5597 </span>
<span class="line-added">5598   int ret_off; // make sure we don&#39;t overwrite the return address</span>
<span class="line-added">5599   if (is_packing) {</span>
<span class="line-added">5600     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at</span>
<span class="line-added">5601     // rsp[0] during shuffling.</span>
<span class="line-added">5602     ret_off = 0;</span>
<span class="line-added">5603   } else {</span>
<span class="line-added">5604     // C2 code ensures that sp_inc is a reserved slot.</span>
<span class="line-added">5605     ret_off = sp_inc;</span>
<span class="line-added">5606   }</span>
<span class="line-added">5607 </span>
<span class="line-added">5608   return shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-added">5609                                    sig_bt, sig_cc,</span>
<span class="line-added">5610                                    args_passed, args_on_stack, regs,</span>
<span class="line-added">5611                                    args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-added">5612                                    sp_inc, ret_off);</span>
<span class="line-added">5613 }</span>
<span class="line-added">5614 </span>
<span class="line-added">5615 VMReg MacroAssembler::spill_reg_for(VMReg reg) {</span>
<span class="line-added">5616   return (reg-&gt;is_FloatRegister()) ? v0-&gt;as_VMReg() : r14-&gt;as_VMReg();</span>
<span class="line-added">5617 }</span>
<span class="line-added">5618 </span>
5619 void MacroAssembler::cache_wb(Address line) {
5620   assert(line.getMode() == Address::base_plus_offset, &quot;mode should be base_plus_offset&quot;);
5621   assert(line.index() == noreg, &quot;index should be noreg&quot;);
5622   assert(line.offset() == 0, &quot;offset should be 0&quot;);
5623   // would like to assert this
5624   // assert(line._ext.shift == 0, &quot;shift should be zero&quot;);
5625   if (VM_Version::supports_dcpop()) {
5626     // writeback using clear virtual address to point of persistence
5627     dc(Assembler::CVAP, line.base());
5628   } else {
5629     // no need to generate anything as Unsafe.writebackMemory should
5630     // never invoke this stub
5631   }
5632 }
5633 
5634 void MacroAssembler::cache_wbsync(bool is_pre) {
5635   // we only need a barrier post sync
5636   if (!is_pre) {
5637     membar(Assembler::AnyAny);
5638   }
</pre>
</td>
</tr>
</table>
<center><a href="interp_masm_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_aarch64.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>