<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="interp_masm_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  28 #include &quot;asm/assembler.inline.hpp&quot;
  29 #include &quot;compiler/disassembler.hpp&quot;
  30 #include &quot;gc/shared/barrierSet.hpp&quot;
  31 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  32 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;
  35 #include &quot;memory/universe.hpp&quot;
  36 #include &quot;oops/accessDecorators.hpp&quot;
  37 #include &quot;oops/compressedOops.inline.hpp&quot;
  38 #include &quot;oops/klass.inline.hpp&quot;
  39 #include &quot;prims/methodHandles.hpp&quot;
  40 #include &quot;runtime/biasedLocking.hpp&quot;
  41 #include &quot;runtime/flags/flagSetting.hpp&quot;
  42 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  43 #include &quot;runtime/objectMonitor.hpp&quot;
  44 #include &quot;runtime/os.hpp&quot;
  45 #include &quot;runtime/safepoint.hpp&quot;
  46 #include &quot;runtime/safepointMechanism.hpp&quot;
  47 #include &quot;runtime/sharedRuntime.hpp&quot;

  48 #include &quot;runtime/stubRoutines.hpp&quot;
  49 #include &quot;runtime/thread.hpp&quot;
  50 #include &quot;utilities/macros.hpp&quot;

  51 #include &quot;crc32c.h&quot;



  52 
  53 #ifdef PRODUCT
  54 #define BLOCK_COMMENT(str) /* nothing */
  55 #define STOP(error) stop(error)
  56 #else
  57 #define BLOCK_COMMENT(str) block_comment(str)
  58 #define STOP(error) block_comment(error); stop(error)
  59 #endif
  60 
  61 #define BIND(label) bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
  62 
  63 #ifdef ASSERT
  64 bool AbstractAssembler::pd_check_instruction_mark() { return true; }
  65 #endif
  66 
  67 static Assembler::Condition reverse[] = {
  68     Assembler::noOverflow     /* overflow      = 0x0 */ ,
  69     Assembler::overflow       /* noOverflow    = 0x1 */ ,
  70     Assembler::aboveEqual     /* carrySet      = 0x2, below         = 0x2 */ ,
  71     Assembler::below          /* aboveEqual    = 0x3, carryClear    = 0x3 */ ,
</pre>
<hr />
<pre>
1621 }
1622 
1623 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1624 
1625   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1626   pass_arg1(this, arg_1);
1627   pass_arg0(this, arg_0);
1628   call_VM_leaf(entry_point, 2);
1629 }
1630 
1631 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1632   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1633   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1634   pass_arg2(this, arg_2);
1635   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1636   pass_arg1(this, arg_1);
1637   pass_arg0(this, arg_0);
1638   call_VM_leaf(entry_point, 3);
1639 }
1640 




1641 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1642   pass_arg0(this, arg_0);
1643   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1644 }
1645 
1646 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1647 
1648   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1649   pass_arg1(this, arg_1);
1650   pass_arg0(this, arg_0);
1651   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1652 }
1653 
1654 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1655   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1656   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1657   pass_arg2(this, arg_2);
1658   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1659   pass_arg1(this, arg_1);
1660   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
2589     lea(rscratch1, src);
2590     Assembler::mulss(dst, Address(rscratch1, 0));
2591   }
2592 }
2593 
2594 void MacroAssembler::null_check(Register reg, int offset) {
2595   if (needs_explicit_null_check(offset)) {
2596     // provoke OS NULL exception if reg = NULL by
2597     // accessing M[reg] w/o changing any (non-CC) registers
2598     // NOTE: cmpl is plenty here to provoke a segv
2599     cmpptr(rax, Address(reg, 0));
2600     // Note: should probably use testl(rax, Address(reg, 0));
2601     //       may be shorter code (however, this version of
2602     //       testl needs to be implemented first)
2603   } else {
2604     // nothing to do, (later) access of M[reg + offset]
2605     // will provoke OS NULL exception if reg = NULL
2606   }
2607 }
2608 






































































2609 void MacroAssembler::os_breakpoint() {
2610   // instead of directly emitting a breakpoint, call os:breakpoint for better debugability
2611   // (e.g., MSVC can&#39;t call ps() otherwise)
2612   call(RuntimeAddress(CAST_FROM_FN_PTR(address, os::breakpoint)));
2613 }
2614 
2615 void MacroAssembler::unimplemented(const char* what) {
2616   const char* buf = NULL;
2617   {
2618     ResourceMark rm;
2619     stringStream ss;
2620     ss.print(&quot;unimplemented: %s&quot;, what);
2621     buf = code_string(ss.as_string());
2622   }
2623   stop(buf);
2624 }
2625 
2626 #ifdef _LP64
2627 #define XSTATE_BV 0x200
2628 #endif
</pre>
<hr />
<pre>
3287 }
3288 
3289 // C++ bool manipulation
3290 void MacroAssembler::testbool(Register dst) {
3291   if(sizeof(bool) == 1)
3292     testb(dst, 0xff);
3293   else if(sizeof(bool) == 2) {
3294     // testw implementation needed for two byte bools
3295     ShouldNotReachHere();
3296   } else if(sizeof(bool) == 4)
3297     testl(dst, dst);
3298   else
3299     // unsupported
3300     ShouldNotReachHere();
3301 }
3302 
3303 void MacroAssembler::testptr(Register dst, Register src) {
3304   LP64_ONLY(testq(dst, src)) NOT_LP64(testl(dst, src));
3305 }
3306 
































































































































3307 // Defines obj, preserves var_size_in_bytes, okay for t2 == var_size_in_bytes.
3308 void MacroAssembler::tlab_allocate(Register thread, Register obj,
3309                                    Register var_size_in_bytes,
3310                                    int con_size_in_bytes,
3311                                    Register t1,
3312                                    Register t2,
3313                                    Label&amp; slow_case) {
3314   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3315   bs-&gt;tlab_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
3316 }
3317 
3318 // Defines obj, preserves var_size_in_bytes
3319 void MacroAssembler::eden_allocate(Register thread, Register obj,
3320                                    Register var_size_in_bytes,
3321                                    int con_size_in_bytes,
3322                                    Register t1,
3323                                    Label&amp; slow_case) {
3324   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3325   bs-&gt;eden_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
3326 }
</pre>
<hr />
<pre>
3364     // clear topmost word (no jump would be needed if conditional assignment worked here)
3365     movptr(Address(address, index, Address::times_8, offset_in_bytes - 0*BytesPerWord), temp);
3366     // index could be 0 now, must check again
3367     jcc(Assembler::zero, done);
3368     bind(even);
3369   }
3370 #endif // !_LP64
3371   // initialize remaining object fields: index is a multiple of 2 now
3372   {
3373     Label loop;
3374     bind(loop);
3375     movptr(Address(address, index, Address::times_8, offset_in_bytes - 1*BytesPerWord), temp);
3376     NOT_LP64(movptr(Address(address, index, Address::times_8, offset_in_bytes - 2*BytesPerWord), temp);)
3377     decrement(index);
3378     jcc(Assembler::notZero, loop);
3379   }
3380 
3381   bind(done);
3382 }
3383 


















































3384 // Look up the method for a megamorphic invokeinterface call.
3385 // The target method is determined by &lt;intf_klass, itable_index&gt;.
3386 // The receiver klass is in recv_klass.
3387 // On success, the result will be in method_result, and execution falls through.
3388 // On failure, execution transfers to the given label.
3389 void MacroAssembler::lookup_interface_method(Register recv_klass,
3390                                              Register intf_klass,
3391                                              RegisterOrConstant itable_index,
3392                                              Register method_result,
3393                                              Register scan_temp,
3394                                              Label&amp; L_no_such_interface,
3395                                              bool return_method) {
3396   assert_different_registers(recv_klass, intf_klass, scan_temp);
3397   assert_different_registers(method_result, intf_klass, scan_temp);
3398   assert(recv_klass != method_result || !return_method,
3399          &quot;recv_klass can be destroyed when method isn&#39;t needed&quot;);
3400 
3401   assert(itable_index.is_constant() || itable_index.as_register() == method_result,
3402          &quot;caller must use same register for non-constant itable index as for method&quot;);
3403 
</pre>
<hr />
<pre>
3712   } else {
3713     Label L;
3714     jccb(negate_condition(cc), L);
3715     movl(dst, src);
3716     bind(L);
3717   }
3718 }
3719 
3720 void MacroAssembler::cmov32(Condition cc, Register dst, Register src) {
3721   if (VM_Version::supports_cmov()) {
3722     cmovl(cc, dst, src);
3723   } else {
3724     Label L;
3725     jccb(negate_condition(cc), L);
3726     movl(dst, src);
3727     bind(L);
3728   }
3729 }
3730 
3731 void MacroAssembler::_verify_oop(Register reg, const char* s, const char* file, int line) {
<span class="line-modified">3732   if (!VerifyOops) return;</span>




3733 
3734   // Pass register number to verify_oop_subroutine
3735   const char* b = NULL;
3736   {
3737     ResourceMark rm;
3738     stringStream ss;
3739     ss.print(&quot;verify_oop: %s: %s (%s:%d)&quot;, reg-&gt;name(), s, file, line);
3740     b = code_string(ss.as_string());
3741   }
3742   BLOCK_COMMENT(&quot;verify_oop {&quot;);
3743 #ifdef _LP64
3744   push(rscratch1);                    // save r10, trashed by movptr()
3745 #endif
3746   push(rax);                          // save rax,
3747   push(reg);                          // pass register argument
3748   ExternalAddress buffer((address) b);
3749   // avoid using pushptr, as it modifies scratch registers
3750   // and our contract is not to modify anything
3751   movptr(rax, buffer.addr());
3752   push(rax);
</pre>
<hr />
<pre>
3810   int stackElementSize = Interpreter::stackElementSize;
3811   int offset = Interpreter::expr_offset_in_bytes(extra_slot_offset+0);
3812 #ifdef ASSERT
3813   int offset1 = Interpreter::expr_offset_in_bytes(extra_slot_offset+1);
3814   assert(offset1 - offset == stackElementSize, &quot;correct arithmetic&quot;);
3815 #endif
3816   Register             scale_reg    = noreg;
3817   Address::ScaleFactor scale_factor = Address::no_scale;
3818   if (arg_slot.is_constant()) {
3819     offset += arg_slot.as_constant() * stackElementSize;
3820   } else {
3821     scale_reg    = arg_slot.as_register();
3822     scale_factor = Address::times(stackElementSize);
3823   }
3824   offset += wordSize;           // return PC is on stack
3825   return Address(rsp, scale_reg, scale_factor, offset);
3826 }
3827 
3828 
3829 void MacroAssembler::_verify_oop_addr(Address addr, const char* s, const char* file, int line) {
<span class="line-modified">3830   if (!VerifyOops) return;</span>




3831 
3832   // Address adjust(addr.base(), addr.index(), addr.scale(), addr.disp() + BytesPerWord);
3833   // Pass register number to verify_oop_subroutine
3834   const char* b = NULL;
3835   {
3836     ResourceMark rm;
3837     stringStream ss;
3838     ss.print(&quot;verify_oop_addr: %s (%s:%d)&quot;, s, file, line);
3839     b = code_string(ss.as_string());
3840   }
3841 #ifdef _LP64
3842   push(rscratch1);                    // save r10, trashed by movptr()
3843 #endif
3844   push(rax);                          // save rax,
3845   // addr may contain rsp so we will have to adjust it based on the push
3846   // we just did (and on 64 bit we do two pushes)
3847   // NOTE: 64bit seemed to have had a bug in that it did movq(addr, rax); which
3848   // stores rax into addr which is backwards of what was intended.
3849   if (addr.uses(rsp)) {
3850     lea(rax, addr);
</pre>
<hr />
<pre>
4300   // Only IN_HEAP loads require a thread_tmp register
4301   // WeakHandle::resolve is an indirection like jweak.
4302   access_load_at(T_OBJECT, IN_NATIVE | ON_PHANTOM_OOP_REF,
4303                  rresult, Address(rresult, 0), rtmp, /*tmp_thread*/noreg);
4304   bind(resolved);
4305 }
4306 
4307 void MacroAssembler::load_mirror(Register mirror, Register method, Register tmp) {
4308   // get mirror
4309   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
4310   load_method_holder(mirror, method);
4311   movptr(mirror, Address(mirror, mirror_offset));
4312   resolve_oop_handle(mirror, tmp);
4313 }
4314 
4315 void MacroAssembler::load_method_holder_cld(Register rresult, Register rmethod) {
4316   load_method_holder(rresult, rmethod);
4317   movptr(rresult, Address(rresult, InstanceKlass::class_loader_data_offset()));
4318 }
4319 

















4320 void MacroAssembler::load_method_holder(Register holder, Register method) {
4321   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
4322   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
4323   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
4324 }
4325 
4326 void MacroAssembler::load_klass(Register dst, Register src) {

4327 #ifdef _LP64
4328   if (UseCompressedClassPointers) {
<span class="line-modified">4329     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
4330     decode_klass_not_null(dst);
4331   } else
4332 #endif
<span class="line-modified">4333     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>







4334 }
4335 
4336 void MacroAssembler::load_prototype_header(Register dst, Register src) {
4337   load_klass(dst, src);
4338   movptr(dst, Address(dst, Klass::prototype_header_offset()));
4339 }
4340 
4341 void MacroAssembler::store_klass(Register dst, Register src) {
4342 #ifdef _LP64
4343   if (UseCompressedClassPointers) {
4344     encode_klass_not_null(src);
4345     movl(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4346   } else
4347 #endif
4348     movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4349 }
4350 
4351 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators, Register dst, Address src,
4352                                     Register tmp1, Register thread_tmp) {
4353   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4354   decorators = AccessInternal::decorator_fixup(decorators);
4355   bool as_raw = (decorators &amp; AS_RAW) != 0;
4356   if (as_raw) {
4357     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4358   } else {
4359     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4360   }
4361 }
4362 
4363 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
<span class="line-modified">4364                                      Register tmp1, Register tmp2) {</span>
4365   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4366   decorators = AccessInternal::decorator_fixup(decorators);
4367   bool as_raw = (decorators &amp; AS_RAW) != 0;
4368   if (as_raw) {
<span class="line-modified">4369     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2);</span>






















4370   } else {
<span class="line-modified">4371     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2);</span>
4372   }
4373 }
4374 


















4375 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4376   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4377   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4378     decorators |= ACCESS_READ | ACCESS_WRITE;
4379   }
4380   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4381   return bs-&gt;resolve(this, decorators, obj);
4382 }
4383 
4384 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4385                                    Register thread_tmp, DecoratorSet decorators) {
4386   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4387 }
4388 
4389 // Doesn&#39;t do verfication, generates fixed size code
4390 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4391                                             Register thread_tmp, DecoratorSet decorators) {
4392   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4393 }
4394 
4395 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4396                                     Register tmp2, DecoratorSet decorators) {</span>
<span class="line-modified">4397   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2);</span>
4398 }
4399 
4400 // Used for storing NULLs.
4401 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4402   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg);</span>
4403 }
4404 
4405 #ifdef _LP64
4406 void MacroAssembler::store_klass_gap(Register dst, Register src) {
4407   if (UseCompressedClassPointers) {
4408     // Store to klass gap in destination
4409     movl(Address(dst, oopDesc::klass_gap_offset_in_bytes()), src);
4410   }
4411 }
4412 
4413 #ifdef ASSERT
4414 void MacroAssembler::verify_heapbase(const char* msg) {
4415   assert (UseCompressedOops, &quot;should be compressed&quot;);
4416   assert (Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
4417   if (CheckCompressedOops) {
4418     Label ok;
4419     push(rscratch1); // cmpptr trashes rscratch1
4420     cmpptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4421     jcc(Assembler::equal, ok);
4422     STOP(msg);
</pre>
<hr />
<pre>
4713   Assembler::cmp_narrow_oop(dst, CompressedKlassPointers::encode(k), rspec);
4714 }
4715 
4716 void MacroAssembler::reinit_heapbase() {
4717   if (UseCompressedOops || UseCompressedClassPointers) {
4718     if (Universe::heap() != NULL) {
4719       if (CompressedOops::base() == NULL) {
4720         MacroAssembler::xorptr(r12_heapbase, r12_heapbase);
4721       } else {
4722         mov64(r12_heapbase, (int64_t)CompressedOops::ptrs_base());
4723       }
4724     } else {
4725       movptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4726     }
4727   }
4728 }
4729 
4730 #endif // _LP64
4731 
4732 // C2 compiled method&#39;s prolog code.
<span class="line-modified">4733 void MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub) {</span>




4734 
4735   // WARNING: Initial instruction MUST be 5 bytes or longer so that
4736   // NativeJump::patch_verified_entry will be able to patch out the entry
4737   // code safely. The push to verify stack depth is ok at 5 bytes,
4738   // the frame allocation can be either 3 or 6 bytes. So if we don&#39;t do
4739   // stack bang then we must use the 6 byte frame allocation even if
4740   // we have no frame. :-(
4741   assert(stack_bang_size &gt;= framesize || stack_bang_size &lt;= 0, &quot;stack bang size incorrect&quot;);
4742 
4743   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
4744   // Remove word for return addr
4745   framesize -= wordSize;
4746   stack_bang_size -= wordSize;
4747 
4748   // Calls to C2R adapters often do not accept exceptional returns.
4749   // We require that their callers must bang for them.  But be careful, because
4750   // some VM calls (such as call site linkage) can use several kilobytes of
4751   // stack.  But the stack safety zone should account for that.
4752   // See bugs 4446381, 4468289, 4497237.
4753   if (stack_bang_size &gt; 0) {
</pre>
<hr />
<pre>
4766     // Create frame
4767     if (framesize) {
4768       subptr(rsp, framesize);
4769     }
4770   } else {
4771     // Create frame (force generation of a 4 byte immediate value)
4772     subptr_imm32(rsp, framesize);
4773 
4774     // Save RBP register now.
4775     framesize -= wordSize;
4776     movptr(Address(rsp, framesize), rbp);
4777     // Save caller&#39;s stack pointer into RBP if the frame pointer is preserved.
4778     if (PreserveFramePointer) {
4779       movptr(rbp, rsp);
4780       if (framesize &gt; 0) {
4781         addptr(rbp, framesize);
4782       }
4783     }
4784   }
4785 






4786   if (VerifyStackAtCalls) { // Majik cookie to verify stack depth
4787     framesize -= wordSize;
4788     movptr(Address(rsp, framesize), (int32_t)0xbadb100d);
4789   }
4790 
4791 #ifndef _LP64
4792   // If method sets FPU control word do it now
4793   if (fp_mode_24b) {
4794     fldcw(ExternalAddress(StubRoutines::addr_fpu_cntrl_wrd_24()));
4795   }
4796   if (UseSSE &gt;= 2 &amp;&amp; VerifyFPU) {
4797     verify_FPU(0, &quot;FPU stack must be clean on entry&quot;);
4798   }
4799 #endif
4800 
4801 #ifdef ASSERT
4802   if (VerifyStackAtCalls) {
4803     Label L;
4804     push(rax);
4805     mov(rax, rsp);
4806     andptr(rax, StackAlignmentInBytes-1);
4807     cmpptr(rax, StackAlignmentInBytes-wordSize);
4808     pop(rax);
4809     jcc(Assembler::equal, L);
4810     STOP(&quot;Stack is not properly aligned!&quot;);
4811     bind(L);
4812   }
4813 #endif
<span class="line-removed">4814 </span>
<span class="line-removed">4815   if (!is_stub) {</span>
<span class="line-removed">4816     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-removed">4817     bs-&gt;nmethod_entry_barrier(this);</span>
<span class="line-removed">4818   }</span>
4819 }
4820 
4821 // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
<span class="line-modified">4822 void MacroAssembler::xmm_clear_mem(Register base, Register cnt, XMMRegister xtmp) {</span>
4823   // cnt - number of qwords (8-byte words).
4824   // base - start address, qword aligned.
4825   Label L_zero_64_bytes, L_loop, L_sloop, L_tail, L_end;

4826   if (UseAVX &gt;= 2) {
<span class="line-modified">4827     vpxor(xtmp, xtmp, xtmp, AVX_256bit);</span>

4828   } else {
<span class="line-modified">4829     pxor(xtmp, xtmp);</span>
4830   }
4831   jmp(L_zero_64_bytes);
4832 
4833   BIND(L_loop);
4834   if (UseAVX &gt;= 2) {
4835     vmovdqu(Address(base,  0), xtmp);
4836     vmovdqu(Address(base, 32), xtmp);
4837   } else {
4838     movdqu(Address(base,  0), xtmp);
4839     movdqu(Address(base, 16), xtmp);
4840     movdqu(Address(base, 32), xtmp);
4841     movdqu(Address(base, 48), xtmp);
4842   }
4843   addptr(base, 64);
4844 
4845   BIND(L_zero_64_bytes);
4846   subptr(cnt, 8);
4847   jccb(Assembler::greaterEqual, L_loop);
4848   addptr(cnt, 4);
4849   jccb(Assembler::less, L_tail);
</pre>
<hr />
<pre>
4853   } else {
4854     movdqu(Address(base,  0), xtmp);
4855     movdqu(Address(base, 16), xtmp);
4856   }
4857   addptr(base, 32);
4858   subptr(cnt, 4);
4859 
4860   BIND(L_tail);
4861   addptr(cnt, 4);
4862   jccb(Assembler::lessEqual, L_end);
4863   decrement(cnt);
4864 
4865   BIND(L_sloop);
4866   movq(Address(base, 0), xtmp);
4867   addptr(base, 8);
4868   decrement(cnt);
4869   jccb(Assembler::greaterEqual, L_sloop);
4870   BIND(L_end);
4871 }
4872 
<span class="line-modified">4873 void MacroAssembler::clear_mem(Register base, Register cnt, Register tmp, XMMRegister xtmp, bool is_large) {</span>






































































































































































































































































































































































4874   // cnt - number of qwords (8-byte words).
4875   // base - start address, qword aligned.
4876   // is_large - if optimizers know cnt is larger than InitArrayShortSize
4877   assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
<span class="line-modified">4878   assert(tmp==rax,   &quot;tmp register must be eax for rep stos&quot;);</span>
4879   assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
4880   assert(InitArrayShortSize % BytesPerLong == 0,
4881     &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
4882 
4883   Label DONE;
4884 
<span class="line-removed">4885   if (!is_large || !UseXMMForObjInit) {</span>
<span class="line-removed">4886     xorptr(tmp, tmp);</span>
<span class="line-removed">4887   }</span>
<span class="line-removed">4888 </span>
4889   if (!is_large) {
4890     Label LOOP, LONG;
4891     cmpptr(cnt, InitArrayShortSize/BytesPerLong);
4892     jccb(Assembler::greater, LONG);
4893 
4894     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
4895 
4896     decrement(cnt);
4897     jccb(Assembler::negative, DONE); // Zero length
4898 
4899     // Use individual pointer-sized stores for small counts:
4900     BIND(LOOP);
<span class="line-modified">4901     movptr(Address(base, cnt, Address::times_ptr), tmp);</span>
4902     decrement(cnt);
4903     jccb(Assembler::greaterEqual, LOOP);
4904     jmpb(DONE);
4905 
4906     BIND(LONG);
4907   }
4908 
4909   // Use longer rep-prefixed ops for non-small counts:
<span class="line-modified">4910   if (UseFastStosb) {</span>
4911     shlptr(cnt, 3); // convert to number of bytes
4912     rep_stosb();
4913   } else if (UseXMMForObjInit) {
<span class="line-modified">4914     movptr(tmp, base);</span>
<span class="line-removed">4915     xmm_clear_mem(tmp, cnt, xtmp);</span>
4916   } else {
4917     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
4918     rep_stos();
4919   }
4920 
4921   BIND(DONE);
4922 }
4923 
4924 void MacroAssembler::generate_fill(BasicType t, bool aligned,
4925                                    Register to, Register value, Register count,
4926                                    Register rtmp, XMMRegister xtmp) {
4927   ShortBranchVerifier sbv(this);
4928   assert_different_registers(to, value, count, rtmp);
4929   Label L_exit;
4930   Label L_fill_2_bytes, L_fill_4_bytes;
4931 
4932   int shift = -1;
4933   switch (t) {
4934     case T_BYTE:
4935       shift = 2;
</pre>
</td>
<td>
<hr />
<pre>
  28 #include &quot;asm/assembler.inline.hpp&quot;
  29 #include &quot;compiler/disassembler.hpp&quot;
  30 #include &quot;gc/shared/barrierSet.hpp&quot;
  31 #include &quot;gc/shared/barrierSetAssembler.hpp&quot;
  32 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;memory/resourceArea.hpp&quot;
  35 #include &quot;memory/universe.hpp&quot;
  36 #include &quot;oops/accessDecorators.hpp&quot;
  37 #include &quot;oops/compressedOops.inline.hpp&quot;
  38 #include &quot;oops/klass.inline.hpp&quot;
  39 #include &quot;prims/methodHandles.hpp&quot;
  40 #include &quot;runtime/biasedLocking.hpp&quot;
  41 #include &quot;runtime/flags/flagSetting.hpp&quot;
  42 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  43 #include &quot;runtime/objectMonitor.hpp&quot;
  44 #include &quot;runtime/os.hpp&quot;
  45 #include &quot;runtime/safepoint.hpp&quot;
  46 #include &quot;runtime/safepointMechanism.hpp&quot;
  47 #include &quot;runtime/sharedRuntime.hpp&quot;
<span class="line-added">  48 #include &quot;runtime/signature_cc.hpp&quot;</span>
  49 #include &quot;runtime/stubRoutines.hpp&quot;
  50 #include &quot;runtime/thread.hpp&quot;
  51 #include &quot;utilities/macros.hpp&quot;
<span class="line-added">  52 #include &quot;vmreg_x86.inline.hpp&quot;</span>
  53 #include &quot;crc32c.h&quot;
<span class="line-added">  54 #ifdef COMPILER2</span>
<span class="line-added">  55 #include &quot;opto/output.hpp&quot;</span>
<span class="line-added">  56 #endif</span>
  57 
  58 #ifdef PRODUCT
  59 #define BLOCK_COMMENT(str) /* nothing */
  60 #define STOP(error) stop(error)
  61 #else
  62 #define BLOCK_COMMENT(str) block_comment(str)
  63 #define STOP(error) block_comment(error); stop(error)
  64 #endif
  65 
  66 #define BIND(label) bind(label); BLOCK_COMMENT(#label &quot;:&quot;)
  67 
  68 #ifdef ASSERT
  69 bool AbstractAssembler::pd_check_instruction_mark() { return true; }
  70 #endif
  71 
  72 static Assembler::Condition reverse[] = {
  73     Assembler::noOverflow     /* overflow      = 0x0 */ ,
  74     Assembler::overflow       /* noOverflow    = 0x1 */ ,
  75     Assembler::aboveEqual     /* carrySet      = 0x2, below         = 0x2 */ ,
  76     Assembler::below          /* aboveEqual    = 0x3, carryClear    = 0x3 */ ,
</pre>
<hr />
<pre>
1626 }
1627 
1628 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1629 
1630   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1631   pass_arg1(this, arg_1);
1632   pass_arg0(this, arg_0);
1633   call_VM_leaf(entry_point, 2);
1634 }
1635 
1636 void MacroAssembler::call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1637   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1638   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1639   pass_arg2(this, arg_2);
1640   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1641   pass_arg1(this, arg_1);
1642   pass_arg0(this, arg_0);
1643   call_VM_leaf(entry_point, 3);
1644 }
1645 
<span class="line-added">1646 void MacroAssembler::super_call_VM_leaf(address entry_point) {</span>
<span class="line-added">1647   MacroAssembler::call_VM_leaf_base(entry_point, 1);</span>
<span class="line-added">1648 }</span>
<span class="line-added">1649 </span>
1650 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0) {
1651   pass_arg0(this, arg_0);
1652   MacroAssembler::call_VM_leaf_base(entry_point, 1);
1653 }
1654 
1655 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1) {
1656 
1657   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1658   pass_arg1(this, arg_1);
1659   pass_arg0(this, arg_0);
1660   MacroAssembler::call_VM_leaf_base(entry_point, 2);
1661 }
1662 
1663 void MacroAssembler::super_call_VM_leaf(address entry_point, Register arg_0, Register arg_1, Register arg_2) {
1664   LP64_ONLY(assert(arg_0 != c_rarg2, &quot;smashed arg&quot;));
1665   LP64_ONLY(assert(arg_1 != c_rarg2, &quot;smashed arg&quot;));
1666   pass_arg2(this, arg_2);
1667   LP64_ONLY(assert(arg_0 != c_rarg1, &quot;smashed arg&quot;));
1668   pass_arg1(this, arg_1);
1669   pass_arg0(this, arg_0);
</pre>
<hr />
<pre>
2598     lea(rscratch1, src);
2599     Assembler::mulss(dst, Address(rscratch1, 0));
2600   }
2601 }
2602 
2603 void MacroAssembler::null_check(Register reg, int offset) {
2604   if (needs_explicit_null_check(offset)) {
2605     // provoke OS NULL exception if reg = NULL by
2606     // accessing M[reg] w/o changing any (non-CC) registers
2607     // NOTE: cmpl is plenty here to provoke a segv
2608     cmpptr(rax, Address(reg, 0));
2609     // Note: should probably use testl(rax, Address(reg, 0));
2610     //       may be shorter code (however, this version of
2611     //       testl needs to be implemented first)
2612   } else {
2613     // nothing to do, (later) access of M[reg + offset]
2614     // will provoke OS NULL exception if reg = NULL
2615   }
2616 }
2617 
<span class="line-added">2618 void MacroAssembler::test_klass_is_value(Register klass, Register temp_reg, Label&amp; is_value) {</span>
<span class="line-added">2619   movl(temp_reg, Address(klass, Klass::access_flags_offset()));</span>
<span class="line-added">2620   testl(temp_reg, JVM_ACC_VALUE);</span>
<span class="line-added">2621   jcc(Assembler::notZero, is_value);</span>
<span class="line-added">2622 }</span>
<span class="line-added">2623 </span>
<span class="line-added">2624 void MacroAssembler::test_klass_is_empty_value(Register klass, Register temp_reg, Label&amp; is_empty_value) {</span>
<span class="line-added">2625 #ifdef ASSERT</span>
<span class="line-added">2626   {</span>
<span class="line-added">2627     Label done_check;</span>
<span class="line-added">2628     test_klass_is_value(klass, temp_reg, done_check);</span>
<span class="line-added">2629     stop(&quot;test_klass_is_empty_value with none value klass&quot;);</span>
<span class="line-added">2630     bind(done_check);</span>
<span class="line-added">2631   }</span>
<span class="line-added">2632 #endif</span>
<span class="line-added">2633   movl(temp_reg, Address(klass, InstanceKlass::misc_flags_offset()));</span>
<span class="line-added">2634   testl(temp_reg, InstanceKlass::misc_flags_is_empty_value());</span>
<span class="line-added">2635   jcc(Assembler::notZero, is_empty_value);</span>
<span class="line-added">2636 }</span>
<span class="line-added">2637 </span>
<span class="line-added">2638 void MacroAssembler::test_field_is_flattenable(Register flags, Register temp_reg, Label&amp; is_flattenable) {</span>
<span class="line-added">2639   movl(temp_reg, flags);</span>
<span class="line-added">2640   shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);</span>
<span class="line-added">2641   andl(temp_reg, 0x1);</span>
<span class="line-added">2642   testl(temp_reg, temp_reg);</span>
<span class="line-added">2643   jcc(Assembler::notZero, is_flattenable);</span>
<span class="line-added">2644 }</span>
<span class="line-added">2645 </span>
<span class="line-added">2646 void MacroAssembler::test_field_is_not_flattenable(Register flags, Register temp_reg, Label&amp; notFlattenable) {</span>
<span class="line-added">2647   movl(temp_reg, flags);</span>
<span class="line-added">2648   shrl(temp_reg, ConstantPoolCacheEntry::is_flattenable_field_shift);</span>
<span class="line-added">2649   andl(temp_reg, 0x1);</span>
<span class="line-added">2650   testl(temp_reg, temp_reg);</span>
<span class="line-added">2651   jcc(Assembler::zero, notFlattenable);</span>
<span class="line-added">2652 }</span>
<span class="line-added">2653 </span>
<span class="line-added">2654 void MacroAssembler::test_field_is_flattened(Register flags, Register temp_reg, Label&amp; is_flattened) {</span>
<span class="line-added">2655   movl(temp_reg, flags);</span>
<span class="line-added">2656   shrl(temp_reg, ConstantPoolCacheEntry::is_flattened_field_shift);</span>
<span class="line-added">2657   andl(temp_reg, 0x1);</span>
<span class="line-added">2658   testl(temp_reg, temp_reg);</span>
<span class="line-added">2659   jcc(Assembler::notZero, is_flattened);</span>
<span class="line-added">2660 }</span>
<span class="line-added">2661 </span>
<span class="line-added">2662 void MacroAssembler::test_flattened_array_oop(Register oop, Register temp_reg,</span>
<span class="line-added">2663                                               Label&amp;is_flattened_array) {</span>
<span class="line-added">2664   load_storage_props(temp_reg, oop);</span>
<span class="line-added">2665   testb(temp_reg, ArrayStorageProperties::flattened_value);</span>
<span class="line-added">2666   jcc(Assembler::notZero, is_flattened_array);</span>
<span class="line-added">2667 }</span>
<span class="line-added">2668 </span>
<span class="line-added">2669 void MacroAssembler::test_non_flattened_array_oop(Register oop, Register temp_reg,</span>
<span class="line-added">2670                                                   Label&amp;is_non_flattened_array) {</span>
<span class="line-added">2671   load_storage_props(temp_reg, oop);</span>
<span class="line-added">2672   testb(temp_reg, ArrayStorageProperties::flattened_value);</span>
<span class="line-added">2673   jcc(Assembler::zero, is_non_flattened_array);</span>
<span class="line-added">2674 }</span>
<span class="line-added">2675 </span>
<span class="line-added">2676 void MacroAssembler::test_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_null_free_array) {</span>
<span class="line-added">2677   load_storage_props(temp_reg, oop);</span>
<span class="line-added">2678   testb(temp_reg, ArrayStorageProperties::null_free_value);</span>
<span class="line-added">2679   jcc(Assembler::notZero, is_null_free_array);</span>
<span class="line-added">2680 }</span>
<span class="line-added">2681 </span>
<span class="line-added">2682 void MacroAssembler::test_non_null_free_array_oop(Register oop, Register temp_reg, Label&amp;is_non_null_free_array) {</span>
<span class="line-added">2683   load_storage_props(temp_reg, oop);</span>
<span class="line-added">2684   testb(temp_reg, ArrayStorageProperties::null_free_value);</span>
<span class="line-added">2685   jcc(Assembler::zero, is_non_null_free_array);</span>
<span class="line-added">2686 }</span>
<span class="line-added">2687 </span>
2688 void MacroAssembler::os_breakpoint() {
2689   // instead of directly emitting a breakpoint, call os:breakpoint for better debugability
2690   // (e.g., MSVC can&#39;t call ps() otherwise)
2691   call(RuntimeAddress(CAST_FROM_FN_PTR(address, os::breakpoint)));
2692 }
2693 
2694 void MacroAssembler::unimplemented(const char* what) {
2695   const char* buf = NULL;
2696   {
2697     ResourceMark rm;
2698     stringStream ss;
2699     ss.print(&quot;unimplemented: %s&quot;, what);
2700     buf = code_string(ss.as_string());
2701   }
2702   stop(buf);
2703 }
2704 
2705 #ifdef _LP64
2706 #define XSTATE_BV 0x200
2707 #endif
</pre>
<hr />
<pre>
3366 }
3367 
3368 // C++ bool manipulation
3369 void MacroAssembler::testbool(Register dst) {
3370   if(sizeof(bool) == 1)
3371     testb(dst, 0xff);
3372   else if(sizeof(bool) == 2) {
3373     // testw implementation needed for two byte bools
3374     ShouldNotReachHere();
3375   } else if(sizeof(bool) == 4)
3376     testl(dst, dst);
3377   else
3378     // unsupported
3379     ShouldNotReachHere();
3380 }
3381 
3382 void MacroAssembler::testptr(Register dst, Register src) {
3383   LP64_ONLY(testq(dst, src)) NOT_LP64(testl(dst, src));
3384 }
3385 
<span class="line-added">3386 // Object / value buffer allocation...</span>
<span class="line-added">3387 //</span>
<span class="line-added">3388 // Kills klass and rsi on LP64</span>
<span class="line-added">3389 void MacroAssembler::allocate_instance(Register klass, Register new_obj,</span>
<span class="line-added">3390                                        Register t1, Register t2,</span>
<span class="line-added">3391                                        bool clear_fields, Label&amp; alloc_failed)</span>
<span class="line-added">3392 {</span>
<span class="line-added">3393   Label done, initialize_header, initialize_object, slow_case, slow_case_no_pop;</span>
<span class="line-added">3394   Register layout_size = t1;</span>
<span class="line-added">3395   assert(new_obj == rax, &quot;needs to be rax, according to barrier asm eden_allocate&quot;);</span>
<span class="line-added">3396   assert_different_registers(klass, new_obj, t1, t2);</span>
<span class="line-added">3397 </span>
<span class="line-added">3398 #ifdef ASSERT</span>
<span class="line-added">3399   {</span>
<span class="line-added">3400     Label L;</span>
<span class="line-added">3401     cmpb(Address(klass, InstanceKlass::init_state_offset()), InstanceKlass::fully_initialized);</span>
<span class="line-added">3402     jcc(Assembler::equal, L);</span>
<span class="line-added">3403     stop(&quot;klass not initialized&quot;);</span>
<span class="line-added">3404     bind(L);</span>
<span class="line-added">3405   }</span>
<span class="line-added">3406 #endif</span>
<span class="line-added">3407 </span>
<span class="line-added">3408   // get instance_size in InstanceKlass (scaled to a count of bytes)</span>
<span class="line-added">3409   movl(layout_size, Address(klass, Klass::layout_helper_offset()));</span>
<span class="line-added">3410   // test to see if it has a finalizer or is malformed in some way</span>
<span class="line-added">3411   testl(layout_size, Klass::_lh_instance_slow_path_bit);</span>
<span class="line-added">3412   jcc(Assembler::notZero, slow_case_no_pop);</span>
<span class="line-added">3413 </span>
<span class="line-added">3414   // Allocate the instance:</span>
<span class="line-added">3415   //  If TLAB is enabled:</span>
<span class="line-added">3416   //    Try to allocate in the TLAB.</span>
<span class="line-added">3417   //    If fails, go to the slow path.</span>
<span class="line-added">3418   //  Else If inline contiguous allocations are enabled:</span>
<span class="line-added">3419   //    Try to allocate in eden.</span>
<span class="line-added">3420   //    If fails due to heap end, go to slow path.</span>
<span class="line-added">3421   //</span>
<span class="line-added">3422   //  If TLAB is enabled OR inline contiguous is enabled:</span>
<span class="line-added">3423   //    Initialize the allocation.</span>
<span class="line-added">3424   //    Exit.</span>
<span class="line-added">3425   //</span>
<span class="line-added">3426   //  Go to slow path.</span>
<span class="line-added">3427   const bool allow_shared_alloc =</span>
<span class="line-added">3428     Universe::heap()-&gt;supports_inline_contig_alloc();</span>
<span class="line-added">3429 </span>
<span class="line-added">3430   push(klass);</span>
<span class="line-added">3431   const Register thread = LP64_ONLY(r15_thread) NOT_LP64(klass);</span>
<span class="line-added">3432 #ifndef _LP64</span>
<span class="line-added">3433   if (UseTLAB || allow_shared_alloc) {</span>
<span class="line-added">3434     get_thread(thread);</span>
<span class="line-added">3435   }</span>
<span class="line-added">3436 #endif // _LP64</span>
<span class="line-added">3437 </span>
<span class="line-added">3438   if (UseTLAB) {</span>
<span class="line-added">3439     tlab_allocate(thread, new_obj, layout_size, 0, klass, t2, slow_case);</span>
<span class="line-added">3440     if (ZeroTLAB || (!clear_fields)) {</span>
<span class="line-added">3441       // the fields have been already cleared</span>
<span class="line-added">3442       jmp(initialize_header);</span>
<span class="line-added">3443     } else {</span>
<span class="line-added">3444       // initialize both the header and fields</span>
<span class="line-added">3445       jmp(initialize_object);</span>
<span class="line-added">3446     }</span>
<span class="line-added">3447   } else {</span>
<span class="line-added">3448     // Allocation in the shared Eden, if allowed.</span>
<span class="line-added">3449     //</span>
<span class="line-added">3450     eden_allocate(thread, new_obj, layout_size, 0, t2, slow_case);</span>
<span class="line-added">3451   }</span>
<span class="line-added">3452 </span>
<span class="line-added">3453   // If UseTLAB or allow_shared_alloc are true, the object is created above and</span>
<span class="line-added">3454   // there is an initialize need. Otherwise, skip and go to the slow path.</span>
<span class="line-added">3455   if (UseTLAB || allow_shared_alloc) {</span>
<span class="line-added">3456     if (clear_fields) {</span>
<span class="line-added">3457       // The object is initialized before the header.  If the object size is</span>
<span class="line-added">3458       // zero, go directly to the header initialization.</span>
<span class="line-added">3459       bind(initialize_object);</span>
<span class="line-added">3460       decrement(layout_size, sizeof(oopDesc));</span>
<span class="line-added">3461       jcc(Assembler::zero, initialize_header);</span>
<span class="line-added">3462 </span>
<span class="line-added">3463       // Initialize topmost object field, divide size by 8, check if odd and</span>
<span class="line-added">3464       // test if zero.</span>
<span class="line-added">3465       Register zero = klass;</span>
<span class="line-added">3466       xorl(zero, zero);    // use zero reg to clear memory (shorter code)</span>
<span class="line-added">3467       shrl(layout_size, LogBytesPerLong); // divide by 2*oopSize and set carry flag if odd</span>
<span class="line-added">3468 </span>
<span class="line-added">3469   #ifdef ASSERT</span>
<span class="line-added">3470       // make sure instance_size was multiple of 8</span>
<span class="line-added">3471       Label L;</span>
<span class="line-added">3472       // Ignore partial flag stall after shrl() since it is debug VM</span>
<span class="line-added">3473       jcc(Assembler::carryClear, L);</span>
<span class="line-added">3474       stop(&quot;object size is not multiple of 2 - adjust this code&quot;);</span>
<span class="line-added">3475       bind(L);</span>
<span class="line-added">3476       // must be &gt; 0, no extra check needed here</span>
<span class="line-added">3477   #endif</span>
<span class="line-added">3478 </span>
<span class="line-added">3479       // initialize remaining object fields: instance_size was a multiple of 8</span>
<span class="line-added">3480       {</span>
<span class="line-added">3481         Label loop;</span>
<span class="line-added">3482         bind(loop);</span>
<span class="line-added">3483         movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 1*oopSize), zero);</span>
<span class="line-added">3484         NOT_LP64(movptr(Address(new_obj, layout_size, Address::times_8, sizeof(oopDesc) - 2*oopSize), zero));</span>
<span class="line-added">3485         decrement(layout_size);</span>
<span class="line-added">3486         jcc(Assembler::notZero, loop);</span>
<span class="line-added">3487       }</span>
<span class="line-added">3488     } // clear_fields</span>
<span class="line-added">3489 </span>
<span class="line-added">3490     // initialize object header only.</span>
<span class="line-added">3491     bind(initialize_header);</span>
<span class="line-added">3492     pop(klass);</span>
<span class="line-added">3493     Register mark_word = t2;</span>
<span class="line-added">3494     movptr(mark_word, Address(klass, Klass::prototype_header_offset()));</span>
<span class="line-added">3495     movptr(Address(new_obj, oopDesc::mark_offset_in_bytes ()), mark_word);</span>
<span class="line-added">3496 #ifdef _LP64</span>
<span class="line-added">3497     xorl(rsi, rsi);                 // use zero reg to clear memory (shorter code)</span>
<span class="line-added">3498     store_klass_gap(new_obj, rsi);  // zero klass gap for compressed oops</span>
<span class="line-added">3499 #endif</span>
<span class="line-added">3500     movptr(t2, klass);         // preserve klass</span>
<span class="line-added">3501     store_klass(new_obj, t2);  // src klass reg is potentially compressed</span>
<span class="line-added">3502 </span>
<span class="line-added">3503     jmp(done);</span>
<span class="line-added">3504   }</span>
<span class="line-added">3505 </span>
<span class="line-added">3506   bind(slow_case);</span>
<span class="line-added">3507   pop(klass);</span>
<span class="line-added">3508   bind(slow_case_no_pop);</span>
<span class="line-added">3509   jmp(alloc_failed);</span>
<span class="line-added">3510 </span>
<span class="line-added">3511   bind(done);</span>
<span class="line-added">3512 }</span>
<span class="line-added">3513 </span>
3514 // Defines obj, preserves var_size_in_bytes, okay for t2 == var_size_in_bytes.
3515 void MacroAssembler::tlab_allocate(Register thread, Register obj,
3516                                    Register var_size_in_bytes,
3517                                    int con_size_in_bytes,
3518                                    Register t1,
3519                                    Register t2,
3520                                    Label&amp; slow_case) {
3521   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3522   bs-&gt;tlab_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, t2, slow_case);
3523 }
3524 
3525 // Defines obj, preserves var_size_in_bytes
3526 void MacroAssembler::eden_allocate(Register thread, Register obj,
3527                                    Register var_size_in_bytes,
3528                                    int con_size_in_bytes,
3529                                    Register t1,
3530                                    Label&amp; slow_case) {
3531   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
3532   bs-&gt;eden_allocate(this, thread, obj, var_size_in_bytes, con_size_in_bytes, t1, slow_case);
3533 }
</pre>
<hr />
<pre>
3571     // clear topmost word (no jump would be needed if conditional assignment worked here)
3572     movptr(Address(address, index, Address::times_8, offset_in_bytes - 0*BytesPerWord), temp);
3573     // index could be 0 now, must check again
3574     jcc(Assembler::zero, done);
3575     bind(even);
3576   }
3577 #endif // !_LP64
3578   // initialize remaining object fields: index is a multiple of 2 now
3579   {
3580     Label loop;
3581     bind(loop);
3582     movptr(Address(address, index, Address::times_8, offset_in_bytes - 1*BytesPerWord), temp);
3583     NOT_LP64(movptr(Address(address, index, Address::times_8, offset_in_bytes - 2*BytesPerWord), temp);)
3584     decrement(index);
3585     jcc(Assembler::notZero, loop);
3586   }
3587 
3588   bind(done);
3589 }
3590 
<span class="line-added">3591 void MacroAssembler::get_value_field_klass(Register klass, Register index, Register value_klass) {</span>
<span class="line-added">3592   movptr(value_klass, Address(klass, InstanceKlass::value_field_klasses_offset()));</span>
<span class="line-added">3593 #ifdef ASSERT</span>
<span class="line-added">3594   {</span>
<span class="line-added">3595     Label done;</span>
<span class="line-added">3596     cmpptr(value_klass, 0);</span>
<span class="line-added">3597     jcc(Assembler::notEqual, done);</span>
<span class="line-added">3598     stop(&quot;get_value_field_klass contains no inline klasses&quot;);</span>
<span class="line-added">3599     bind(done);</span>
<span class="line-added">3600   }</span>
<span class="line-added">3601 #endif</span>
<span class="line-added">3602   movptr(value_klass, Address(value_klass, index, Address::times_ptr));</span>
<span class="line-added">3603 }</span>
<span class="line-added">3604 </span>
<span class="line-added">3605 void MacroAssembler::get_default_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
<span class="line-added">3606 #ifdef ASSERT</span>
<span class="line-added">3607   {</span>
<span class="line-added">3608     Label done_check;</span>
<span class="line-added">3609     test_klass_is_value(value_klass, temp_reg, done_check);</span>
<span class="line-added">3610     stop(&quot;get_default_value_oop from non-value klass&quot;);</span>
<span class="line-added">3611     bind(done_check);</span>
<span class="line-added">3612   }</span>
<span class="line-added">3613 #endif</span>
<span class="line-added">3614   Register offset = temp_reg;</span>
<span class="line-added">3615   // Getting the offset of the pre-allocated default value</span>
<span class="line-added">3616   movptr(offset, Address(value_klass, in_bytes(InstanceKlass::adr_valueklass_fixed_block_offset())));</span>
<span class="line-added">3617   movl(offset, Address(offset, in_bytes(ValueKlass::default_value_offset_offset())));</span>
<span class="line-added">3618 </span>
<span class="line-added">3619   // Getting the mirror</span>
<span class="line-added">3620   movptr(obj, Address(value_klass, in_bytes(Klass::java_mirror_offset())));</span>
<span class="line-added">3621   resolve_oop_handle(obj, value_klass);</span>
<span class="line-added">3622 </span>
<span class="line-added">3623   // Getting the pre-allocated default value from the mirror</span>
<span class="line-added">3624   Address field(obj, offset, Address::times_1);</span>
<span class="line-added">3625   load_heap_oop(obj, field);</span>
<span class="line-added">3626 }</span>
<span class="line-added">3627 </span>
<span class="line-added">3628 void MacroAssembler::get_empty_value_oop(Register value_klass, Register temp_reg, Register obj) {</span>
<span class="line-added">3629 #ifdef ASSERT</span>
<span class="line-added">3630   {</span>
<span class="line-added">3631     Label done_check;</span>
<span class="line-added">3632     test_klass_is_empty_value(value_klass, temp_reg, done_check);</span>
<span class="line-added">3633     stop(&quot;get_empty_value from non-empty value klass&quot;);</span>
<span class="line-added">3634     bind(done_check);</span>
<span class="line-added">3635   }</span>
<span class="line-added">3636 #endif</span>
<span class="line-added">3637   get_default_value_oop(value_klass, temp_reg, obj);</span>
<span class="line-added">3638 }</span>
<span class="line-added">3639 </span>
<span class="line-added">3640 </span>
3641 // Look up the method for a megamorphic invokeinterface call.
3642 // The target method is determined by &lt;intf_klass, itable_index&gt;.
3643 // The receiver klass is in recv_klass.
3644 // On success, the result will be in method_result, and execution falls through.
3645 // On failure, execution transfers to the given label.
3646 void MacroAssembler::lookup_interface_method(Register recv_klass,
3647                                              Register intf_klass,
3648                                              RegisterOrConstant itable_index,
3649                                              Register method_result,
3650                                              Register scan_temp,
3651                                              Label&amp; L_no_such_interface,
3652                                              bool return_method) {
3653   assert_different_registers(recv_klass, intf_klass, scan_temp);
3654   assert_different_registers(method_result, intf_klass, scan_temp);
3655   assert(recv_klass != method_result || !return_method,
3656          &quot;recv_klass can be destroyed when method isn&#39;t needed&quot;);
3657 
3658   assert(itable_index.is_constant() || itable_index.as_register() == method_result,
3659          &quot;caller must use same register for non-constant itable index as for method&quot;);
3660 
</pre>
<hr />
<pre>
3969   } else {
3970     Label L;
3971     jccb(negate_condition(cc), L);
3972     movl(dst, src);
3973     bind(L);
3974   }
3975 }
3976 
3977 void MacroAssembler::cmov32(Condition cc, Register dst, Register src) {
3978   if (VM_Version::supports_cmov()) {
3979     cmovl(cc, dst, src);
3980   } else {
3981     Label L;
3982     jccb(negate_condition(cc), L);
3983     movl(dst, src);
3984     bind(L);
3985   }
3986 }
3987 
3988 void MacroAssembler::_verify_oop(Register reg, const char* s, const char* file, int line) {
<span class="line-modified">3989   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">3990     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">3991     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">3992     return;</span>
<span class="line-added">3993   }</span>
3994 
3995   // Pass register number to verify_oop_subroutine
3996   const char* b = NULL;
3997   {
3998     ResourceMark rm;
3999     stringStream ss;
4000     ss.print(&quot;verify_oop: %s: %s (%s:%d)&quot;, reg-&gt;name(), s, file, line);
4001     b = code_string(ss.as_string());
4002   }
4003   BLOCK_COMMENT(&quot;verify_oop {&quot;);
4004 #ifdef _LP64
4005   push(rscratch1);                    // save r10, trashed by movptr()
4006 #endif
4007   push(rax);                          // save rax,
4008   push(reg);                          // pass register argument
4009   ExternalAddress buffer((address) b);
4010   // avoid using pushptr, as it modifies scratch registers
4011   // and our contract is not to modify anything
4012   movptr(rax, buffer.addr());
4013   push(rax);
</pre>
<hr />
<pre>
4071   int stackElementSize = Interpreter::stackElementSize;
4072   int offset = Interpreter::expr_offset_in_bytes(extra_slot_offset+0);
4073 #ifdef ASSERT
4074   int offset1 = Interpreter::expr_offset_in_bytes(extra_slot_offset+1);
4075   assert(offset1 - offset == stackElementSize, &quot;correct arithmetic&quot;);
4076 #endif
4077   Register             scale_reg    = noreg;
4078   Address::ScaleFactor scale_factor = Address::no_scale;
4079   if (arg_slot.is_constant()) {
4080     offset += arg_slot.as_constant() * stackElementSize;
4081   } else {
4082     scale_reg    = arg_slot.as_register();
4083     scale_factor = Address::times(stackElementSize);
4084   }
4085   offset += wordSize;           // return PC is on stack
4086   return Address(rsp, scale_reg, scale_factor, offset);
4087 }
4088 
4089 
4090 void MacroAssembler::_verify_oop_addr(Address addr, const char* s, const char* file, int line) {
<span class="line-modified">4091   if (!VerifyOops || VerifyAdapterSharing) {</span>
<span class="line-added">4092     // Below address of the code string confuses VerifyAdapterSharing</span>
<span class="line-added">4093     // because it may differ between otherwise equivalent adapters.</span>
<span class="line-added">4094     return;</span>
<span class="line-added">4095   }</span>
4096 
4097   // Address adjust(addr.base(), addr.index(), addr.scale(), addr.disp() + BytesPerWord);
4098   // Pass register number to verify_oop_subroutine
4099   const char* b = NULL;
4100   {
4101     ResourceMark rm;
4102     stringStream ss;
4103     ss.print(&quot;verify_oop_addr: %s (%s:%d)&quot;, s, file, line);
4104     b = code_string(ss.as_string());
4105   }
4106 #ifdef _LP64
4107   push(rscratch1);                    // save r10, trashed by movptr()
4108 #endif
4109   push(rax);                          // save rax,
4110   // addr may contain rsp so we will have to adjust it based on the push
4111   // we just did (and on 64 bit we do two pushes)
4112   // NOTE: 64bit seemed to have had a bug in that it did movq(addr, rax); which
4113   // stores rax into addr which is backwards of what was intended.
4114   if (addr.uses(rsp)) {
4115     lea(rax, addr);
</pre>
<hr />
<pre>
4565   // Only IN_HEAP loads require a thread_tmp register
4566   // WeakHandle::resolve is an indirection like jweak.
4567   access_load_at(T_OBJECT, IN_NATIVE | ON_PHANTOM_OOP_REF,
4568                  rresult, Address(rresult, 0), rtmp, /*tmp_thread*/noreg);
4569   bind(resolved);
4570 }
4571 
4572 void MacroAssembler::load_mirror(Register mirror, Register method, Register tmp) {
4573   // get mirror
4574   const int mirror_offset = in_bytes(Klass::java_mirror_offset());
4575   load_method_holder(mirror, method);
4576   movptr(mirror, Address(mirror, mirror_offset));
4577   resolve_oop_handle(mirror, tmp);
4578 }
4579 
4580 void MacroAssembler::load_method_holder_cld(Register rresult, Register rmethod) {
4581   load_method_holder(rresult, rmethod);
4582   movptr(rresult, Address(rresult, InstanceKlass::class_loader_data_offset()));
4583 }
4584 
<span class="line-added">4585 void MacroAssembler::load_metadata(Register dst, Register src) {</span>
<span class="line-added">4586   if (UseCompressedClassPointers) {</span>
<span class="line-added">4587     movl(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">4588   } else {</span>
<span class="line-added">4589     movptr(dst, Address(src, oopDesc::klass_offset_in_bytes()));</span>
<span class="line-added">4590   }</span>
<span class="line-added">4591 }</span>
<span class="line-added">4592 </span>
<span class="line-added">4593 void MacroAssembler::load_storage_props(Register dst, Register src) {</span>
<span class="line-added">4594   load_metadata(dst, src);</span>
<span class="line-added">4595   if (UseCompressedClassPointers) {</span>
<span class="line-added">4596     shrl(dst, oopDesc::narrow_storage_props_shift);</span>
<span class="line-added">4597   } else {</span>
<span class="line-added">4598     shrq(dst, oopDesc::wide_storage_props_shift);</span>
<span class="line-added">4599   }</span>
<span class="line-added">4600 }</span>
<span class="line-added">4601 </span>
4602 void MacroAssembler::load_method_holder(Register holder, Register method) {
4603   movptr(holder, Address(method, Method::const_offset()));                      // ConstMethod*
4604   movptr(holder, Address(holder, ConstMethod::constants_offset()));             // ConstantPool*
4605   movptr(holder, Address(holder, ConstantPool::pool_holder_offset_in_bytes())); // InstanceKlass*
4606 }
4607 
4608 void MacroAssembler::load_klass(Register dst, Register src) {
<span class="line-added">4609   load_metadata(dst, src);</span>
4610 #ifdef _LP64
4611   if (UseCompressedClassPointers) {
<span class="line-modified">4612     andl(dst, oopDesc::compressed_klass_mask());</span>
4613     decode_klass_not_null(dst);
4614   } else
4615 #endif
<span class="line-modified">4616   {</span>
<span class="line-added">4617 #ifdef _LP64</span>
<span class="line-added">4618     shlq(dst, oopDesc::storage_props_nof_bits);</span>
<span class="line-added">4619     shrq(dst, oopDesc::storage_props_nof_bits);</span>
<span class="line-added">4620 #else</span>
<span class="line-added">4621     andl(dst, oopDesc::wide_klass_mask());</span>
<span class="line-added">4622 #endif</span>
<span class="line-added">4623   }</span>
4624 }
4625 
4626 void MacroAssembler::load_prototype_header(Register dst, Register src) {
4627   load_klass(dst, src);
4628   movptr(dst, Address(dst, Klass::prototype_header_offset()));
4629 }
4630 
4631 void MacroAssembler::store_klass(Register dst, Register src) {
4632 #ifdef _LP64
4633   if (UseCompressedClassPointers) {
4634     encode_klass_not_null(src);
4635     movl(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4636   } else
4637 #endif
4638     movptr(Address(dst, oopDesc::klass_offset_in_bytes()), src);
4639 }
4640 
4641 void MacroAssembler::access_load_at(BasicType type, DecoratorSet decorators, Register dst, Address src,
4642                                     Register tmp1, Register thread_tmp) {
4643   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4644   decorators = AccessInternal::decorator_fixup(decorators);
4645   bool as_raw = (decorators &amp; AS_RAW) != 0;
4646   if (as_raw) {
4647     bs-&gt;BarrierSetAssembler::load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4648   } else {
4649     bs-&gt;load_at(this, decorators, type, dst, src, tmp1, thread_tmp);
4650   }
4651 }
4652 
4653 void MacroAssembler::access_store_at(BasicType type, DecoratorSet decorators, Address dst, Register src,
<span class="line-modified">4654                                      Register tmp1, Register tmp2, Register tmp3) {</span>
4655   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4656   decorators = AccessInternal::decorator_fixup(decorators);
4657   bool as_raw = (decorators &amp; AS_RAW) != 0;
4658   if (as_raw) {
<span class="line-modified">4659     bs-&gt;BarrierSetAssembler::store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);</span>
<span class="line-added">4660   } else {</span>
<span class="line-added">4661     bs-&gt;store_at(this, decorators, type, dst, src, tmp1, tmp2, tmp3);</span>
<span class="line-added">4662   }</span>
<span class="line-added">4663 }</span>
<span class="line-added">4664 </span>
<span class="line-added">4665 void MacroAssembler::access_value_copy(DecoratorSet decorators, Register src, Register dst,</span>
<span class="line-added">4666                                        Register value_klass) {</span>
<span class="line-added">4667   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();</span>
<span class="line-added">4668   bs-&gt;value_copy(this, decorators, src, dst, value_klass);</span>
<span class="line-added">4669 }</span>
<span class="line-added">4670 </span>
<span class="line-added">4671 void MacroAssembler::first_field_offset(Register value_klass, Register offset) {</span>
<span class="line-added">4672   movptr(offset, Address(value_klass, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">4673   movl(offset, Address(offset, ValueKlass::first_field_offset_offset()));</span>
<span class="line-added">4674 }</span>
<span class="line-added">4675 </span>
<span class="line-added">4676 void MacroAssembler::data_for_oop(Register oop, Register data, Register value_klass) {</span>
<span class="line-added">4677   // ((address) (void*) o) + vk-&gt;first_field_offset();</span>
<span class="line-added">4678   Register offset = (data == oop) ? rscratch1 : data;</span>
<span class="line-added">4679   first_field_offset(value_klass, offset);</span>
<span class="line-added">4680   if (data == oop) {</span>
<span class="line-added">4681     addptr(data, offset);</span>
4682   } else {
<span class="line-modified">4683     lea(data, Address(oop, offset));</span>
4684   }
4685 }
4686 
<span class="line-added">4687 void MacroAssembler::data_for_value_array_index(Register array, Register array_klass,</span>
<span class="line-added">4688                                                 Register index, Register data) {</span>
<span class="line-added">4689   assert(index != rcx, &quot;index needs to shift by rcx&quot;);</span>
<span class="line-added">4690   assert_different_registers(array, array_klass, index);</span>
<span class="line-added">4691   assert_different_registers(rcx, array, index);</span>
<span class="line-added">4692 </span>
<span class="line-added">4693   // array-&gt;base() + (index &lt;&lt; Klass::layout_helper_log2_element_size(lh));</span>
<span class="line-added">4694   movl(rcx, Address(array_klass, Klass::layout_helper_offset()));</span>
<span class="line-added">4695 </span>
<span class="line-added">4696   // Klass::layout_helper_log2_element_size(lh)</span>
<span class="line-added">4697   // (lh &gt;&gt; _lh_log2_element_size_shift) &amp; _lh_log2_element_size_mask;</span>
<span class="line-added">4698   shrl(rcx, Klass::_lh_log2_element_size_shift);</span>
<span class="line-added">4699   andl(rcx, Klass::_lh_log2_element_size_mask);</span>
<span class="line-added">4700   shlptr(index); // index &lt;&lt; rcx</span>
<span class="line-added">4701 </span>
<span class="line-added">4702   lea(data, Address(array, index, Address::times_1, arrayOopDesc::base_offset_in_bytes(T_VALUETYPE)));</span>
<span class="line-added">4703 }</span>
<span class="line-added">4704 </span>
4705 void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {
4706   // Use stronger ACCESS_WRITE|ACCESS_READ by default.
4707   if ((decorators &amp; (ACCESS_READ | ACCESS_WRITE)) == 0) {
4708     decorators |= ACCESS_READ | ACCESS_WRITE;
4709   }
4710   BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
4711   return bs-&gt;resolve(this, decorators, obj);
4712 }
4713 
4714 void MacroAssembler::load_heap_oop(Register dst, Address src, Register tmp1,
4715                                    Register thread_tmp, DecoratorSet decorators) {
4716   access_load_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, thread_tmp);
4717 }
4718 
4719 // Doesn&#39;t do verfication, generates fixed size code
4720 void MacroAssembler::load_heap_oop_not_null(Register dst, Address src, Register tmp1,
4721                                             Register thread_tmp, DecoratorSet decorators) {
4722   access_load_at(T_OBJECT, IN_HEAP | IS_NOT_NULL | decorators, dst, src, tmp1, thread_tmp);
4723 }
4724 
4725 void MacroAssembler::store_heap_oop(Address dst, Register src, Register tmp1,
<span class="line-modified">4726                                     Register tmp2, Register tmp3, DecoratorSet decorators) {</span>
<span class="line-modified">4727   access_store_at(T_OBJECT, IN_HEAP | decorators, dst, src, tmp1, tmp2, tmp3);</span>
4728 }
4729 
4730 // Used for storing NULLs.
4731 void MacroAssembler::store_heap_oop_null(Address dst) {
<span class="line-modified">4732   access_store_at(T_OBJECT, IN_HEAP, dst, noreg, noreg, noreg, noreg);</span>
4733 }
4734 
4735 #ifdef _LP64
4736 void MacroAssembler::store_klass_gap(Register dst, Register src) {
4737   if (UseCompressedClassPointers) {
4738     // Store to klass gap in destination
4739     movl(Address(dst, oopDesc::klass_gap_offset_in_bytes()), src);
4740   }
4741 }
4742 
4743 #ifdef ASSERT
4744 void MacroAssembler::verify_heapbase(const char* msg) {
4745   assert (UseCompressedOops, &quot;should be compressed&quot;);
4746   assert (Universe::heap() != NULL, &quot;java heap should be initialized&quot;);
4747   if (CheckCompressedOops) {
4748     Label ok;
4749     push(rscratch1); // cmpptr trashes rscratch1
4750     cmpptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
4751     jcc(Assembler::equal, ok);
4752     STOP(msg);
</pre>
<hr />
<pre>
5043   Assembler::cmp_narrow_oop(dst, CompressedKlassPointers::encode(k), rspec);
5044 }
5045 
5046 void MacroAssembler::reinit_heapbase() {
5047   if (UseCompressedOops || UseCompressedClassPointers) {
5048     if (Universe::heap() != NULL) {
5049       if (CompressedOops::base() == NULL) {
5050         MacroAssembler::xorptr(r12_heapbase, r12_heapbase);
5051       } else {
5052         mov64(r12_heapbase, (int64_t)CompressedOops::ptrs_base());
5053       }
5054     } else {
5055       movptr(r12_heapbase, ExternalAddress((address)CompressedOops::ptrs_base_addr()));
5056     }
5057   }
5058 }
5059 
5060 #endif // _LP64
5061 
5062 // C2 compiled method&#39;s prolog code.
<span class="line-modified">5063 void MacroAssembler::verified_entry(Compile* C, int sp_inc) {</span>
<span class="line-added">5064   int framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
<span class="line-added">5065   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
<span class="line-added">5066   bool fp_mode_24b = false;</span>
<span class="line-added">5067   int stack_bang_size = C-&gt;output()-&gt;need_stack_bang(bangsize) ? bangsize : 0;</span>
5068 
5069   // WARNING: Initial instruction MUST be 5 bytes or longer so that
5070   // NativeJump::patch_verified_entry will be able to patch out the entry
5071   // code safely. The push to verify stack depth is ok at 5 bytes,
5072   // the frame allocation can be either 3 or 6 bytes. So if we don&#39;t do
5073   // stack bang then we must use the 6 byte frame allocation even if
5074   // we have no frame. :-(
5075   assert(stack_bang_size &gt;= framesize || stack_bang_size &lt;= 0, &quot;stack bang size incorrect&quot;);
5076 
5077   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
5078   // Remove word for return addr
5079   framesize -= wordSize;
5080   stack_bang_size -= wordSize;
5081 
5082   // Calls to C2R adapters often do not accept exceptional returns.
5083   // We require that their callers must bang for them.  But be careful, because
5084   // some VM calls (such as call site linkage) can use several kilobytes of
5085   // stack.  But the stack safety zone should account for that.
5086   // See bugs 4446381, 4468289, 4497237.
5087   if (stack_bang_size &gt; 0) {
</pre>
<hr />
<pre>
5100     // Create frame
5101     if (framesize) {
5102       subptr(rsp, framesize);
5103     }
5104   } else {
5105     // Create frame (force generation of a 4 byte immediate value)
5106     subptr_imm32(rsp, framesize);
5107 
5108     // Save RBP register now.
5109     framesize -= wordSize;
5110     movptr(Address(rsp, framesize), rbp);
5111     // Save caller&#39;s stack pointer into RBP if the frame pointer is preserved.
5112     if (PreserveFramePointer) {
5113       movptr(rbp, rsp);
5114       if (framesize &gt; 0) {
5115         addptr(rbp, framesize);
5116       }
5117     }
5118   }
5119 
<span class="line-added">5120   if (C-&gt;needs_stack_repair()) {</span>
<span class="line-added">5121     // Save stack increment (also account for fixed framesize and rbp)</span>
<span class="line-added">5122     assert((sp_inc &amp; (StackAlignmentInBytes-1)) == 0, &quot;stack increment not aligned&quot;);</span>
<span class="line-added">5123     movptr(Address(rsp, C-&gt;output()-&gt;sp_inc_offset()), sp_inc + framesize + wordSize);</span>
<span class="line-added">5124   }</span>
<span class="line-added">5125 </span>
5126   if (VerifyStackAtCalls) { // Majik cookie to verify stack depth
5127     framesize -= wordSize;
5128     movptr(Address(rsp, framesize), (int32_t)0xbadb100d);
5129   }
5130 
5131 #ifndef _LP64
5132   // If method sets FPU control word do it now
5133   if (fp_mode_24b) {
5134     fldcw(ExternalAddress(StubRoutines::addr_fpu_cntrl_wrd_24()));
5135   }
5136   if (UseSSE &gt;= 2 &amp;&amp; VerifyFPU) {
5137     verify_FPU(0, &quot;FPU stack must be clean on entry&quot;);
5138   }
5139 #endif
5140 
5141 #ifdef ASSERT
5142   if (VerifyStackAtCalls) {
5143     Label L;
5144     push(rax);
5145     mov(rax, rsp);
5146     andptr(rax, StackAlignmentInBytes-1);
5147     cmpptr(rax, StackAlignmentInBytes-wordSize);
5148     pop(rax);
5149     jcc(Assembler::equal, L);
5150     STOP(&quot;Stack is not properly aligned!&quot;);
5151     bind(L);
5152   }
5153 #endif





5154 }
5155 
5156 // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
<span class="line-modified">5157 void MacroAssembler::xmm_clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp) {</span>
5158   // cnt - number of qwords (8-byte words).
5159   // base - start address, qword aligned.
5160   Label L_zero_64_bytes, L_loop, L_sloop, L_tail, L_end;
<span class="line-added">5161   movdq(xtmp, val);</span>
5162   if (UseAVX &gt;= 2) {
<span class="line-modified">5163     punpcklqdq(xtmp, xtmp);</span>
<span class="line-added">5164     vinserti128_high(xtmp, xtmp);</span>
5165   } else {
<span class="line-modified">5166     punpcklqdq(xtmp, xtmp);</span>
5167   }
5168   jmp(L_zero_64_bytes);
5169 
5170   BIND(L_loop);
5171   if (UseAVX &gt;= 2) {
5172     vmovdqu(Address(base,  0), xtmp);
5173     vmovdqu(Address(base, 32), xtmp);
5174   } else {
5175     movdqu(Address(base,  0), xtmp);
5176     movdqu(Address(base, 16), xtmp);
5177     movdqu(Address(base, 32), xtmp);
5178     movdqu(Address(base, 48), xtmp);
5179   }
5180   addptr(base, 64);
5181 
5182   BIND(L_zero_64_bytes);
5183   subptr(cnt, 8);
5184   jccb(Assembler::greaterEqual, L_loop);
5185   addptr(cnt, 4);
5186   jccb(Assembler::less, L_tail);
</pre>
<hr />
<pre>
5190   } else {
5191     movdqu(Address(base,  0), xtmp);
5192     movdqu(Address(base, 16), xtmp);
5193   }
5194   addptr(base, 32);
5195   subptr(cnt, 4);
5196 
5197   BIND(L_tail);
5198   addptr(cnt, 4);
5199   jccb(Assembler::lessEqual, L_end);
5200   decrement(cnt);
5201 
5202   BIND(L_sloop);
5203   movq(Address(base, 0), xtmp);
5204   addptr(base, 8);
5205   decrement(cnt);
5206   jccb(Assembler::greaterEqual, L_sloop);
5207   BIND(L_end);
5208 }
5209 
<span class="line-modified">5210 int MacroAssembler::store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter) {</span>
<span class="line-added">5211   // A value type might be returned. If fields are in registers we</span>
<span class="line-added">5212   // need to allocate a value type instance and initialize it with</span>
<span class="line-added">5213   // the value of the fields.</span>
<span class="line-added">5214   Label skip;</span>
<span class="line-added">5215   // We only need a new buffered value if a new one is not returned</span>
<span class="line-added">5216   testptr(rax, 1);</span>
<span class="line-added">5217   jcc(Assembler::zero, skip);</span>
<span class="line-added">5218   int call_offset = -1;</span>
<span class="line-added">5219 </span>
<span class="line-added">5220 #ifdef _LP64</span>
<span class="line-added">5221   Label slow_case;</span>
<span class="line-added">5222 </span>
<span class="line-added">5223   // Try to allocate a new buffered value (from the heap)</span>
<span class="line-added">5224   if (UseTLAB) {</span>
<span class="line-added">5225     // FIXME -- for smaller code, the inline allocation (and the slow case) should be moved inside the pack handler.</span>
<span class="line-added">5226     if (vk != NULL) {</span>
<span class="line-added">5227       // Called from C1, where the return type is statically known.</span>
<span class="line-added">5228       movptr(rbx, (intptr_t)vk-&gt;get_ValueKlass());</span>
<span class="line-added">5229       jint lh = vk-&gt;layout_helper();</span>
<span class="line-added">5230       assert(lh != Klass::_lh_neutral_value, &quot;inline class in return type must have been resolved&quot;);</span>
<span class="line-added">5231       movl(r14, lh);</span>
<span class="line-added">5232     } else {</span>
<span class="line-added">5233       // Call from interpreter. RAX contains ((the ValueKlass* of the return type) | 0x01)</span>
<span class="line-added">5234       mov(rbx, rax);</span>
<span class="line-added">5235       andptr(rbx, -2);</span>
<span class="line-added">5236       movl(r14, Address(rbx, Klass::layout_helper_offset()));</span>
<span class="line-added">5237     }</span>
<span class="line-added">5238 </span>
<span class="line-added">5239     movptr(r13, Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())));</span>
<span class="line-added">5240     lea(r14, Address(r13, r14, Address::times_1));</span>
<span class="line-added">5241     cmpptr(r14, Address(r15_thread, in_bytes(JavaThread::tlab_end_offset())));</span>
<span class="line-added">5242     jcc(Assembler::above, slow_case);</span>
<span class="line-added">5243     movptr(Address(r15_thread, in_bytes(JavaThread::tlab_top_offset())), r14);</span>
<span class="line-added">5244     movptr(Address(r13, oopDesc::mark_offset_in_bytes()), (intptr_t)markWord::always_locked_prototype().value());</span>
<span class="line-added">5245 </span>
<span class="line-added">5246     xorl(rax, rax); // use zero reg to clear memory (shorter code)</span>
<span class="line-added">5247     store_klass_gap(r13, rax);  // zero klass gap for compressed oops</span>
<span class="line-added">5248 </span>
<span class="line-added">5249     if (vk == NULL) {</span>
<span class="line-added">5250       // store_klass corrupts rbx, so save it in rax for later use (interpreter case only).</span>
<span class="line-added">5251       mov(rax, rbx);</span>
<span class="line-added">5252     }</span>
<span class="line-added">5253     store_klass(r13, rbx);  // klass</span>
<span class="line-added">5254 </span>
<span class="line-added">5255     // We have our new buffered value, initialize its fields with a</span>
<span class="line-added">5256     // value class specific handler</span>
<span class="line-added">5257     if (vk != NULL) {</span>
<span class="line-added">5258       // FIXME -- do the packing in-line to avoid the runtime call</span>
<span class="line-added">5259       mov(rax, r13);</span>
<span class="line-added">5260       call(RuntimeAddress(vk-&gt;pack_handler())); // no need for call info as this will not safepoint.</span>
<span class="line-added">5261     } else {</span>
<span class="line-added">5262       movptr(rbx, Address(rax, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">5263       movptr(rbx, Address(rbx, ValueKlass::pack_handler_offset()));</span>
<span class="line-added">5264       mov(rax, r13);</span>
<span class="line-added">5265       call(rbx);</span>
<span class="line-added">5266     }</span>
<span class="line-added">5267     jmp(skip);</span>
<span class="line-added">5268   }</span>
<span class="line-added">5269 </span>
<span class="line-added">5270   bind(slow_case);</span>
<span class="line-added">5271   // We failed to allocate a new value, fall back to a runtime</span>
<span class="line-added">5272   // call. Some oop field may be live in some registers but we can&#39;t</span>
<span class="line-added">5273   // tell. That runtime call will take care of preserving them</span>
<span class="line-added">5274   // across a GC if there&#39;s one.</span>
<span class="line-added">5275 #endif</span>
<span class="line-added">5276 </span>
<span class="line-added">5277   if (from_interpreter) {</span>
<span class="line-added">5278     super_call_VM_leaf(StubRoutines::store_value_type_fields_to_buf());</span>
<span class="line-added">5279   } else {</span>
<span class="line-added">5280     call(RuntimeAddress(StubRoutines::store_value_type_fields_to_buf()));</span>
<span class="line-added">5281     call_offset = offset();</span>
<span class="line-added">5282   }</span>
<span class="line-added">5283 </span>
<span class="line-added">5284   bind(skip);</span>
<span class="line-added">5285   return call_offset;</span>
<span class="line-added">5286 }</span>
<span class="line-added">5287 </span>
<span class="line-added">5288 </span>
<span class="line-added">5289 // Move a value between registers/stack slots and update the reg_state</span>
<span class="line-added">5290 bool MacroAssembler::move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5291   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5292     return true; // Already written</span>
<span class="line-added">5293   }</span>
<span class="line-added">5294   if (from != to &amp;&amp; bt != T_VOID) {</span>
<span class="line-added">5295     if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5296       return false; // Not yet writable</span>
<span class="line-added">5297     }</span>
<span class="line-added">5298     if (from-&gt;is_reg()) {</span>
<span class="line-added">5299       if (to-&gt;is_reg()) {</span>
<span class="line-added">5300         if (from-&gt;is_XMMRegister()) {</span>
<span class="line-added">5301           if (bt == T_DOUBLE) {</span>
<span class="line-added">5302             movdbl(to-&gt;as_XMMRegister(), from-&gt;as_XMMRegister());</span>
<span class="line-added">5303           } else {</span>
<span class="line-added">5304             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5305             movflt(to-&gt;as_XMMRegister(), from-&gt;as_XMMRegister());</span>
<span class="line-added">5306           }</span>
<span class="line-added">5307         } else {</span>
<span class="line-added">5308           movq(to-&gt;as_Register(), from-&gt;as_Register());</span>
<span class="line-added">5309         }</span>
<span class="line-added">5310       } else {</span>
<span class="line-added">5311         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5312         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5313         Address to_addr = Address(rsp, st_off);</span>
<span class="line-added">5314         if (from-&gt;is_XMMRegister()) {</span>
<span class="line-added">5315           if (bt == T_DOUBLE) {</span>
<span class="line-added">5316             movdbl(to_addr, from-&gt;as_XMMRegister());</span>
<span class="line-added">5317           } else {</span>
<span class="line-added">5318             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5319             movflt(to_addr, from-&gt;as_XMMRegister());</span>
<span class="line-added">5320           }</span>
<span class="line-added">5321         } else {</span>
<span class="line-added">5322           movq(to_addr, from-&gt;as_Register());</span>
<span class="line-added">5323         }</span>
<span class="line-added">5324       }</span>
<span class="line-added">5325     } else {</span>
<span class="line-added">5326       Address from_addr = Address(rsp, from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset);</span>
<span class="line-added">5327       if (to-&gt;is_reg()) {</span>
<span class="line-added">5328         if (to-&gt;is_XMMRegister()) {</span>
<span class="line-added">5329           if (bt == T_DOUBLE) {</span>
<span class="line-added">5330             movdbl(to-&gt;as_XMMRegister(), from_addr);</span>
<span class="line-added">5331           } else {</span>
<span class="line-added">5332             assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5333             movflt(to-&gt;as_XMMRegister(), from_addr);</span>
<span class="line-added">5334           }</span>
<span class="line-added">5335         } else {</span>
<span class="line-added">5336           movq(to-&gt;as_Register(), from_addr);</span>
<span class="line-added">5337         }</span>
<span class="line-added">5338       } else {</span>
<span class="line-added">5339         int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5340         assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5341         movq(r13, from_addr);</span>
<span class="line-added">5342         movq(Address(rsp, st_off), r13);</span>
<span class="line-added">5343       }</span>
<span class="line-added">5344     }</span>
<span class="line-added">5345   }</span>
<span class="line-added">5346   // Update register states</span>
<span class="line-added">5347   reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5348   reg_state[to-&gt;value()] = reg_written;</span>
<span class="line-added">5349   return true;</span>
<span class="line-added">5350 }</span>
<span class="line-added">5351 </span>
<span class="line-added">5352 // Read all fields from a value type oop and store the values in registers/stack slots</span>
<span class="line-added">5353 bool MacroAssembler::unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to,</span>
<span class="line-added">5354                                          int&amp; to_index, RegState reg_state[], int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5355   Register fromReg = from-&gt;is_reg() ? from-&gt;as_Register() : noreg;</span>
<span class="line-added">5356   assert(sig-&gt;at(sig_index)._bt == T_VOID, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5357 </span>
<span class="line-added">5358   int vt = 1;</span>
<span class="line-added">5359   bool done = true;</span>
<span class="line-added">5360   bool mark_done = true;</span>
<span class="line-added">5361   do {</span>
<span class="line-added">5362     sig_index--;</span>
<span class="line-added">5363     BasicType bt = sig-&gt;at(sig_index)._bt;</span>
<span class="line-added">5364     if (bt == T_VALUETYPE) {</span>
<span class="line-added">5365       vt--;</span>
<span class="line-added">5366     } else if (bt == T_VOID &amp;&amp;</span>
<span class="line-added">5367                sig-&gt;at(sig_index-1)._bt != T_LONG &amp;&amp;</span>
<span class="line-added">5368                sig-&gt;at(sig_index-1)._bt != T_DOUBLE) {</span>
<span class="line-added">5369       vt++;</span>
<span class="line-added">5370     } else if (SigEntry::is_reserved_entry(sig, sig_index)) {</span>
<span class="line-added">5371       to_index--; // Ignore this</span>
<span class="line-added">5372     } else {</span>
<span class="line-added">5373       assert(to_index &gt;= 0, &quot;invalid to_index&quot;);</span>
<span class="line-added">5374       VMRegPair pair_to = regs_to[to_index--];</span>
<span class="line-added">5375       VMReg to = pair_to.first();</span>
<span class="line-added">5376 </span>
<span class="line-added">5377       if (bt == T_VOID) continue;</span>
<span class="line-added">5378 </span>
<span class="line-added">5379       int idx = (int)to-&gt;value();</span>
<span class="line-added">5380       if (reg_state[idx] == reg_readonly) {</span>
<span class="line-added">5381          if (idx != from-&gt;value()) {</span>
<span class="line-added">5382            mark_done = false;</span>
<span class="line-added">5383          }</span>
<span class="line-added">5384          done = false;</span>
<span class="line-added">5385          continue;</span>
<span class="line-added">5386       } else if (reg_state[idx] == reg_written) {</span>
<span class="line-added">5387         continue;</span>
<span class="line-added">5388       } else {</span>
<span class="line-added">5389         assert(reg_state[idx] == reg_writable, &quot;must be writable&quot;);</span>
<span class="line-added">5390         reg_state[idx] = reg_written;</span>
<span class="line-added">5391        }</span>
<span class="line-added">5392 </span>
<span class="line-added">5393       if (fromReg == noreg) {</span>
<span class="line-added">5394         int st_off = from-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5395         movq(r10, Address(rsp, st_off));</span>
<span class="line-added">5396         fromReg = r10;</span>
<span class="line-added">5397       }</span>
<span class="line-added">5398 </span>
<span class="line-added">5399       int off = sig-&gt;at(sig_index)._offset;</span>
<span class="line-added">5400       assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5401       bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5402 </span>
<span class="line-added">5403       Address fromAddr = Address(fromReg, off);</span>
<span class="line-added">5404       bool is_signed = (bt != T_CHAR) &amp;&amp; (bt != T_BOOLEAN);</span>
<span class="line-added">5405       if (!to-&gt;is_XMMRegister()) {</span>
<span class="line-added">5406         Register dst = to-&gt;is_stack() ? r13 : to-&gt;as_Register();</span>
<span class="line-added">5407         if (is_oop) {</span>
<span class="line-added">5408           load_heap_oop(dst, fromAddr);</span>
<span class="line-added">5409         } else {</span>
<span class="line-added">5410           load_sized_value(dst, fromAddr, type2aelembytes(bt), is_signed);</span>
<span class="line-added">5411         }</span>
<span class="line-added">5412         if (to-&gt;is_stack()) {</span>
<span class="line-added">5413           int st_off = to-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5414           assert(st_off != ret_off, &quot;overwriting return address at %d&quot;, st_off);</span>
<span class="line-added">5415           movq(Address(rsp, st_off), dst);</span>
<span class="line-added">5416         }</span>
<span class="line-added">5417       } else {</span>
<span class="line-added">5418         if (bt == T_DOUBLE) {</span>
<span class="line-added">5419           movdbl(to-&gt;as_XMMRegister(), fromAddr);</span>
<span class="line-added">5420         } else {</span>
<span class="line-added">5421           assert(bt == T_FLOAT, &quot;must be float&quot;);</span>
<span class="line-added">5422           movflt(to-&gt;as_XMMRegister(), fromAddr);</span>
<span class="line-added">5423         }</span>
<span class="line-added">5424       }</span>
<span class="line-added">5425     }</span>
<span class="line-added">5426   } while (vt != 0);</span>
<span class="line-added">5427   if (mark_done &amp;&amp; reg_state[from-&gt;value()] != reg_written) {</span>
<span class="line-added">5428     // This is okay because no one else will write to that slot</span>
<span class="line-added">5429     reg_state[from-&gt;value()] = reg_writable;</span>
<span class="line-added">5430   }</span>
<span class="line-added">5431   return done;</span>
<span class="line-added">5432 }</span>
<span class="line-added">5433 </span>
<span class="line-added">5434 // Pack fields back into a value type oop</span>
<span class="line-added">5435 bool MacroAssembler::pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,</span>
<span class="line-added">5436                                        VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],</span>
<span class="line-added">5437                                        int ret_off, int extra_stack_offset) {</span>
<span class="line-added">5438   assert(sig-&gt;at(sig_index)._bt == T_VALUETYPE, &quot;should be at end delimiter&quot;);</span>
<span class="line-added">5439   assert(to-&gt;is_valid(), &quot;must be&quot;);</span>
<span class="line-added">5440 </span>
<span class="line-added">5441   if (reg_state[to-&gt;value()] == reg_written) {</span>
<span class="line-added">5442     skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5443     return true; // Already written</span>
<span class="line-added">5444   }</span>
<span class="line-added">5445 </span>
<span class="line-added">5446   Register val_array = rax;</span>
<span class="line-added">5447   Register val_obj_tmp = r11;</span>
<span class="line-added">5448   Register from_reg_tmp = r14; // Be careful with r14 because it&#39;s used for spilling</span>
<span class="line-added">5449   Register tmp1 = r10;</span>
<span class="line-added">5450   Register tmp2 = r13;</span>
<span class="line-added">5451   Register tmp3 = rbx;</span>
<span class="line-added">5452   Register val_obj = to-&gt;is_stack() ? val_obj_tmp : to-&gt;as_Register();</span>
<span class="line-added">5453 </span>
<span class="line-added">5454   if (reg_state[to-&gt;value()] == reg_readonly) {</span>
<span class="line-added">5455     if (!is_reg_in_unpacked_fields(sig, sig_index, to, regs_from, regs_from_count, from_index)) {</span>
<span class="line-added">5456       skip_unpacked_fields(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5457       return false; // Not yet writable</span>
<span class="line-added">5458     }</span>
<span class="line-added">5459     val_obj = val_obj_tmp;</span>
<span class="line-added">5460   }</span>
<span class="line-added">5461 </span>
<span class="line-added">5462   int index = arrayOopDesc::base_offset_in_bytes(T_OBJECT) + vtarg_index * type2aelembytes(T_VALUETYPE);</span>
<span class="line-added">5463   load_heap_oop(val_obj, Address(val_array, index));</span>
<span class="line-added">5464 </span>
<span class="line-added">5465   ScalarizedValueArgsStream stream(sig, sig_index, regs_from, regs_from_count, from_index);</span>
<span class="line-added">5466   VMRegPair from_pair;</span>
<span class="line-added">5467   BasicType bt;</span>
<span class="line-added">5468   while (stream.next(from_pair, bt)) {</span>
<span class="line-added">5469     int off = sig-&gt;at(stream.sig_cc_index())._offset;</span>
<span class="line-added">5470     assert(off &gt; 0, &quot;offset in object should be positive&quot;);</span>
<span class="line-added">5471     bool is_oop = (bt == T_OBJECT || bt == T_ARRAY);</span>
<span class="line-added">5472     size_t size_in_bytes = is_java_primitive(bt) ? type2aelembytes(bt) : wordSize;</span>
<span class="line-added">5473 </span>
<span class="line-added">5474     VMReg from_r1 = from_pair.first();</span>
<span class="line-added">5475     VMReg from_r2 = from_pair.second();</span>
<span class="line-added">5476 </span>
<span class="line-added">5477     // Pack the scalarized field into the value object.</span>
<span class="line-added">5478     Address dst(val_obj, off);</span>
<span class="line-added">5479     if (!from_r1-&gt;is_XMMRegister()) {</span>
<span class="line-added">5480       Register from_reg;</span>
<span class="line-added">5481       if (from_r1-&gt;is_stack()) {</span>
<span class="line-added">5482         from_reg = from_reg_tmp;</span>
<span class="line-added">5483         int ld_off = from_r1-&gt;reg2stack() * VMRegImpl::stack_slot_size + extra_stack_offset;</span>
<span class="line-added">5484         load_sized_value(from_reg, Address(rsp, ld_off), size_in_bytes, /* is_signed */ false);</span>
<span class="line-added">5485       } else {</span>
<span class="line-added">5486         from_reg = from_r1-&gt;as_Register();</span>
<span class="line-added">5487       }</span>
<span class="line-added">5488       assert_different_registers(dst.base(), from_reg, tmp1, tmp2, tmp3, val_array);</span>
<span class="line-added">5489       if (is_oop) {</span>
<span class="line-added">5490         store_heap_oop(dst, from_reg, tmp1, tmp2, tmp3, IN_HEAP | ACCESS_WRITE | IS_DEST_UNINITIALIZED);</span>
<span class="line-added">5491       } else {</span>
<span class="line-added">5492         store_sized_value(dst, from_reg, size_in_bytes);</span>
<span class="line-added">5493       }</span>
<span class="line-added">5494     } else {</span>
<span class="line-added">5495       if (from_r2-&gt;is_valid()) {</span>
<span class="line-added">5496         movdbl(dst, from_r1-&gt;as_XMMRegister());</span>
<span class="line-added">5497       } else {</span>
<span class="line-added">5498         movflt(dst, from_r1-&gt;as_XMMRegister());</span>
<span class="line-added">5499       }</span>
<span class="line-added">5500     }</span>
<span class="line-added">5501     reg_state[from_r1-&gt;value()] = reg_writable;</span>
<span class="line-added">5502   }</span>
<span class="line-added">5503   sig_index = stream.sig_cc_index();</span>
<span class="line-added">5504   from_index = stream.regs_cc_index();</span>
<span class="line-added">5505 </span>
<span class="line-added">5506   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);</span>
<span class="line-added">5507   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);</span>
<span class="line-added">5508   assert(success, &quot;to register must be writeable&quot;);</span>
<span class="line-added">5509 </span>
<span class="line-added">5510   return true;</span>
<span class="line-added">5511 }</span>
<span class="line-added">5512 </span>
<span class="line-added">5513 // Unpack all value type arguments passed as oops</span>
<span class="line-added">5514 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {</span>
<span class="line-added">5515   int sp_inc = unpack_value_args_common(C, receiver_only);</span>
<span class="line-added">5516   // Emit code for verified entry and save increment for stack repair on return</span>
<span class="line-added">5517   verified_entry(C, sp_inc);</span>
<span class="line-added">5518 }</span>
<span class="line-added">5519 </span>
<span class="line-added">5520 void MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-added">5521                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-added">5522                                         int args_passed, int args_on_stack, VMRegPair* regs,</span>
<span class="line-added">5523                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {</span>
<span class="line-added">5524   // Check if we need to extend the stack for packing/unpacking</span>
<span class="line-added">5525   if (sp_inc &gt; 0 &amp;&amp; !is_packing) {</span>
<span class="line-added">5526     // Save the return address, adjust the stack (make sure it is properly</span>
<span class="line-added">5527     // 16-byte aligned) and copy the return address to the new top of the stack.</span>
<span class="line-added">5528     // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).</span>
<span class="line-added">5529     pop(r13);</span>
<span class="line-added">5530     subptr(rsp, sp_inc);</span>
<span class="line-added">5531     push(r13);</span>
<span class="line-added">5532   }</span>
<span class="line-added">5533 </span>
<span class="line-added">5534   int ret_off; // make sure we don&#39;t overwrite the return address</span>
<span class="line-added">5535   if (is_packing) {</span>
<span class="line-added">5536     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at</span>
<span class="line-added">5537     // rsp[0] during shuffling.</span>
<span class="line-added">5538     ret_off = 0;</span>
<span class="line-added">5539   } else {</span>
<span class="line-added">5540     // C2 code ensures that sp_inc is a reserved slot.</span>
<span class="line-added">5541     ret_off = sp_inc;</span>
<span class="line-added">5542   }</span>
<span class="line-added">5543 </span>
<span class="line-added">5544   shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-added">5545                             sig_bt, sig_cc,</span>
<span class="line-added">5546                             args_passed, args_on_stack, regs,</span>
<span class="line-added">5547                             args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-added">5548                             sp_inc, ret_off);</span>
<span class="line-added">5549 }</span>
<span class="line-added">5550 </span>
<span class="line-added">5551 VMReg MacroAssembler::spill_reg_for(VMReg reg) {</span>
<span class="line-added">5552   return reg-&gt;is_XMMRegister() ? xmm8-&gt;as_VMReg() : r14-&gt;as_VMReg();</span>
<span class="line-added">5553 }</span>
<span class="line-added">5554 </span>
<span class="line-added">5555 void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {</span>
<span class="line-added">5556   assert((initial_framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);</span>
<span class="line-added">5557   if (needs_stack_repair) {</span>
<span class="line-added">5558     movq(rbp, Address(rsp, initial_framesize));</span>
<span class="line-added">5559     addq(rsp, Address(rsp, sp_inc_offset));</span>
<span class="line-added">5560   } else {</span>
<span class="line-added">5561     if (initial_framesize &gt; 0) {</span>
<span class="line-added">5562       addq(rsp, initial_framesize);</span>
<span class="line-added">5563     }</span>
<span class="line-added">5564     pop(rbp);</span>
<span class="line-added">5565   }</span>
<span class="line-added">5566 }</span>
<span class="line-added">5567 </span>
<span class="line-added">5568 void MacroAssembler::clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only) {</span>
5569   // cnt - number of qwords (8-byte words).
5570   // base - start address, qword aligned.
5571   // is_large - if optimizers know cnt is larger than InitArrayShortSize
5572   assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
<span class="line-modified">5573   assert(val==rax,   &quot;tmp register must be eax for rep stos&quot;);</span>
5574   assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
5575   assert(InitArrayShortSize % BytesPerLong == 0,
5576     &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
5577 
5578   Label DONE;
5579 




5580   if (!is_large) {
5581     Label LOOP, LONG;
5582     cmpptr(cnt, InitArrayShortSize/BytesPerLong);
5583     jccb(Assembler::greater, LONG);
5584 
5585     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
5586 
5587     decrement(cnt);
5588     jccb(Assembler::negative, DONE); // Zero length
5589 
5590     // Use individual pointer-sized stores for small counts:
5591     BIND(LOOP);
<span class="line-modified">5592     movptr(Address(base, cnt, Address::times_ptr), val);</span>
5593     decrement(cnt);
5594     jccb(Assembler::greaterEqual, LOOP);
5595     jmpb(DONE);
5596 
5597     BIND(LONG);
5598   }
5599 
5600   // Use longer rep-prefixed ops for non-small counts:
<span class="line-modified">5601   if (UseFastStosb &amp;&amp; !word_copy_only) {</span>
5602     shlptr(cnt, 3); // convert to number of bytes
5603     rep_stosb();
5604   } else if (UseXMMForObjInit) {
<span class="line-modified">5605     xmm_clear_mem(base, cnt, val, xtmp);</span>

5606   } else {
5607     NOT_LP64(shlptr(cnt, 1);) // convert to number of 32-bit words for 32-bit VM
5608     rep_stos();
5609   }
5610 
5611   BIND(DONE);
5612 }
5613 
5614 void MacroAssembler::generate_fill(BasicType t, bool aligned,
5615                                    Register to, Register value, Register count,
5616                                    Register rtmp, XMMRegister xtmp) {
5617   ShortBranchVerifier sbv(this);
5618   assert_different_registers(to, value, count, rtmp);
5619   Label L_exit;
5620   Label L_fill_2_bytes, L_fill_4_bytes;
5621 
5622   int shift = -1;
5623   switch (t) {
5624     case T_BYTE:
5625       shift = 2;
</pre>
</td>
</tr>
</table>
<center><a href="interp_masm_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>