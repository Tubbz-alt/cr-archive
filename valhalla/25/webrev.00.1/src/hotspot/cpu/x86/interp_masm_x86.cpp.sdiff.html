<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/interp_masm_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/interp_masm_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;interp_masm_x86.hpp&quot;
  27 #include &quot;interpreter/interpreter.hpp&quot;
  28 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  29 #include &quot;logging/log.hpp&quot;
  30 #include &quot;oops/arrayOop.hpp&quot;
  31 #include &quot;oops/markWord.hpp&quot;
  32 #include &quot;oops/methodData.hpp&quot;
  33 #include &quot;oops/method.hpp&quot;

  34 #include &quot;prims/jvmtiExport.hpp&quot;
  35 #include &quot;prims/jvmtiThreadState.hpp&quot;
  36 #include &quot;runtime/basicLock.hpp&quot;
  37 #include &quot;runtime/biasedLocking.hpp&quot;
  38 #include &quot;runtime/frame.inline.hpp&quot;
  39 #include &quot;runtime/safepointMechanism.hpp&quot;
  40 #include &quot;runtime/sharedRuntime.hpp&quot;
  41 #include &quot;runtime/thread.inline.hpp&quot;
  42 #include &quot;utilities/powerOfTwo.hpp&quot;
  43 
  44 // Implementation of InterpreterMacroAssembler
  45 
  46 void InterpreterMacroAssembler::jump_to_entry(address entry) {
  47   assert(entry, &quot;Entry must have been generated by now&quot;);
  48   jump(RuntimeAddress(entry));
  49 }
  50 
  51 void InterpreterMacroAssembler::profile_obj_type(Register obj, const Address&amp; mdo_addr) {
  52   Label update, next, none;
  53 
</pre>
<hr />
<pre>
 133         Address mdo_arg_addr(mdp, in_bytes(TypeEntriesAtCall::argument_type_offset(i))-off_to_args);
 134         profile_obj_type(tmp, mdo_arg_addr);
 135 
 136         int to_add = in_bytes(TypeStackSlotEntries::per_arg_size());
 137         addptr(mdp, to_add);
 138         off_to_args += to_add;
 139       }
 140 
 141       if (MethodData::profile_return()) {
 142         movptr(tmp, Address(mdp, in_bytes(TypeEntriesAtCall::cell_count_offset())-off_to_args));
 143         subl(tmp, TypeProfileArgsLimit*TypeStackSlotEntries::per_arg_count());
 144       }
 145 
 146       bind(done);
 147 
 148       if (MethodData::profile_return()) {
 149         // We&#39;re right after the type profile for the last
 150         // argument. tmp is the number of cells left in the
 151         // CallTypeData/VirtualCallTypeData to reach its end. Non null
 152         // if there&#39;s a return to profile.
<span class="line-modified"> 153         assert(ReturnTypeEntry::static_cell_count() &lt; TypeStackSlotEntries::per_arg_count(), &quot;can&#39;t move past ret type&quot;);</span>
 154         shll(tmp, exact_log2(DataLayout::cell_size));
 155         addptr(mdp, tmp);
 156       }
 157       movptr(Address(rbp, frame::interpreter_frame_mdp_offset * wordSize), mdp);
 158     } else {
 159       assert(MethodData::profile_return(), &quot;either profile call args or call ret&quot;);
 160       update_mdp_by_constant(mdp, in_bytes(TypeEntriesAtCall::return_only_size()));
 161     }
 162 
 163     // mdp points right after the end of the
 164     // CallTypeData/VirtualCallTypeData, right after the cells for the
 165     // return value type if there&#39;s one
 166 
 167     bind(profile_continue);
 168   }
 169 }
 170 
 171 void InterpreterMacroAssembler::profile_return_type(Register mdp, Register ret, Register tmp) {
 172   assert_different_registers(mdp, ret, tmp, _bcp_register);
 173   if (ProfileInterpreter &amp;&amp; MethodData::profile_return()) {
</pre>
<hr />
<pre>
 178     if (MethodData::profile_return_jsr292_only()) {
 179       assert(Method::intrinsic_id_size_in_bytes() == 2, &quot;assuming Method::_intrinsic_id is u2&quot;);
 180 
 181       // If we don&#39;t profile all invoke bytecodes we must make sure
 182       // it&#39;s a bytecode we indeed profile. We can&#39;t go back to the
 183       // begining of the ProfileData we intend to update to check its
 184       // type because we&#39;re right after it and we don&#39;t known its
 185       // length
 186       Label do_profile;
 187       cmpb(Address(_bcp_register, 0), Bytecodes::_invokedynamic);
 188       jcc(Assembler::equal, do_profile);
 189       cmpb(Address(_bcp_register, 0), Bytecodes::_invokehandle);
 190       jcc(Assembler::equal, do_profile);
 191       get_method(tmp);
 192       cmpw(Address(tmp, Method::intrinsic_id_offset_in_bytes()), vmIntrinsics::_compiledLambdaForm);
 193       jcc(Assembler::notEqual, profile_continue);
 194 
 195       bind(do_profile);
 196     }
 197 
<span class="line-modified"> 198     Address mdo_ret_addr(mdp, -in_bytes(ReturnTypeEntry::size()));</span>
 199     mov(tmp, ret);
 200     profile_obj_type(tmp, mdo_ret_addr);
 201 
 202     bind(profile_continue);
 203   }
 204 }
 205 
 206 void InterpreterMacroAssembler::profile_parameters_type(Register mdp, Register tmp1, Register tmp2) {
 207   if (ProfileInterpreter &amp;&amp; MethodData::profile_parameters()) {
 208     Label profile_continue;
 209 
 210     test_method_data_pointer(mdp, profile_continue);
 211 
 212     // Load the offset of the area within the MDO used for
 213     // parameters. If it&#39;s negative we&#39;re not profiling any parameters
 214     movl(tmp1, Address(mdp, in_bytes(MethodData::parameters_type_data_di_offset()) - in_bytes(MethodData::data_offset())));
 215     testl(tmp1, tmp1);
 216     jcc(Assembler::negative, profile_continue);
 217 
 218     // Compute a pointer to the area for parameters from the offset
</pre>
<hr />
<pre>
 538 
 539   const int method_offset = in_bytes(
 540     ConstantPoolCache::base_offset() +
 541       ((byte_no == TemplateTable::f2_byte)
 542        ? ConstantPoolCacheEntry::f2_offset()
 543        : ConstantPoolCacheEntry::f1_offset()));
 544 
 545   movptr(method, Address(cache, index, Address::times_ptr, method_offset)); // get f1 Method*
 546 }
 547 
 548 // Generate a subtype check: branch to ok_is_subtype if sub_klass is a
 549 // subtype of super_klass.
 550 //
 551 // Args:
 552 //      rax: superklass
 553 //      Rsub_klass: subklass
 554 //
 555 // Kills:
 556 //      rcx, rdi
 557 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass,
<span class="line-modified"> 558                                                   Label&amp; ok_is_subtype) {</span>

 559   assert(Rsub_klass != rax, &quot;rax holds superklass&quot;);
 560   LP64_ONLY(assert(Rsub_klass != r14, &quot;r14 holds locals&quot;);)
 561   LP64_ONLY(assert(Rsub_klass != r13, &quot;r13 holds bcp&quot;);)
 562   assert(Rsub_klass != rcx, &quot;rcx holds 2ndary super array length&quot;);
 563   assert(Rsub_klass != rdi, &quot;rdi holds 2ndary super array scan ptr&quot;);
 564 
 565   // Profile the not-null value&#39;s klass.
<span class="line-modified"> 566   profile_typecheck(rcx, Rsub_klass, rdi); // blows rcx, reloads rdi</span>


 567 
 568   // Do the check.
 569   check_klass_subtype(Rsub_klass, rax, rcx, ok_is_subtype); // blows rcx
 570 
 571   // Profile the failure of the check.
<span class="line-modified"> 572   profile_typecheck_failed(rcx); // blows rcx</span>


 573 }
 574 
 575 
 576 #ifndef _LP64
 577 void InterpreterMacroAssembler::f2ieee() {
 578   if (IEEEPrecision) {
 579     fstp_s(Address(rsp, 0));
 580     fld_s(Address(rsp, 0));
 581   }
 582 }
 583 
 584 
 585 void InterpreterMacroAssembler::d2ieee() {
 586   if (IEEEPrecision) {
 587     fstp_d(Address(rsp, 0));
 588     fld_d(Address(rsp, 0));
 589   }
 590 }
 591 #endif // _LP64
 592 
</pre>
<hr />
<pre>
 977         bool throw_monitor_exception,
 978         bool install_monitor_exception,
 979         bool notify_jvmdi) {
 980   // Note: Registers rdx xmm0 may be in use for the
 981   // result check if synchronized method
 982   Label unlocked, unlock, no_unlock;
 983 
 984   const Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
 985   const Register robj    = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
 986   const Register rmon    = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
 987                               // monitor pointers need different register
 988                               // because rdx may have the result in it
 989   NOT_LP64(get_thread(rcx);)
 990 
 991   // get the value of _do_not_unlock_if_synchronized into rdx
 992   const Address do_not_unlock_if_synchronized(rthread,
 993     in_bytes(JavaThread::do_not_unlock_if_synchronized_offset()));
 994   movbool(rbx, do_not_unlock_if_synchronized);
 995   movbool(do_not_unlock_if_synchronized, false); // reset the flag
 996 
<span class="line-modified"> 997  // get method access flags</span>
 998   movptr(rcx, Address(rbp, frame::interpreter_frame_method_offset * wordSize));
 999   movl(rcx, Address(rcx, Method::access_flags_offset()));
1000   testl(rcx, JVM_ACC_SYNCHRONIZED);
1001   jcc(Assembler::zero, unlocked);
1002 
1003   // Don&#39;t unlock anything if the _do_not_unlock_if_synchronized flag
1004   // is set.
1005   testbool(rbx);
1006   jcc(Assembler::notZero, no_unlock);
1007 
1008   // unlock monitor
1009   push(state); // save result
1010 
1011   // BasicObjectLock will be first in list, since this is a
1012   // synchronized method. However, need to check that the object has
1013   // not been unlocked by an explicit monitorexit bytecode.
1014   const Address monitor(rbp, frame::interpreter_frame_initial_sp_offset *
1015                         wordSize - (int) sizeof(BasicObjectLock));
1016   // We use c_rarg1/rdx so that if we go slow path it will be the correct
1017   // register for unlock_object to pass to VM directly
</pre>
<hr />
<pre>
1101     bind(loop);
1102     // check if current entry is used
1103     cmpptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL);
1104     jcc(Assembler::notEqual, exception);
1105 
1106     addptr(rmon, entry_size); // otherwise advance to next entry
1107     bind(entry);
1108     cmpptr(rmon, rbx); // check if bottom reached
1109     jcc(Assembler::notEqual, loop); // if not at bottom then check this entry
1110   }
1111 
1112   bind(no_unlock);
1113 
1114   // jvmti support
1115   if (notify_jvmdi) {
1116     notify_method_exit(state, NotifyJVMTI);    // preserve TOSCA
1117   } else {
1118     notify_method_exit(state, SkipNotifyJVMTI); // preserve TOSCA
1119   }
1120 
<span class="line-modified">1121   // remove activation</span>
<span class="line-modified">1122   // get sender sp</span>
<span class="line-removed">1123   movptr(rbx,</span>
<span class="line-removed">1124          Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));</span>
1125   if (StackReservedPages &gt; 0) {
1126     // testing if reserved zone needs to be re-enabled
1127     Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
1128     Label no_reserved_zone_enabling;
1129 
1130     NOT_LP64(get_thread(rthread);)
1131 
1132     cmpl(Address(rthread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_enabled);
1133     jcc(Assembler::equal, no_reserved_zone_enabling);
1134 
1135     cmpptr(rbx, Address(rthread, JavaThread::reserved_stack_activation_offset()));
1136     jcc(Assembler::lessEqual, no_reserved_zone_enabling);
1137 
1138     call_VM_leaf(
1139       CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone), rthread);
1140     call_VM(noreg, CAST_FROM_FN_PTR(address,
1141                    InterpreterRuntime::throw_delayed_StackOverflowError));
1142     should_not_reach_here();
1143 
1144     bind(no_reserved_zone_enabling);
1145   }

































1146   leave();                           // remove frame anchor
1147   pop(ret_addr);                     // get return address
1148   mov(rsp, rbx);                     // set sp to sender sp
1149 }
1150 
1151 void InterpreterMacroAssembler::get_method_counters(Register method,
1152                                                     Register mcs, Label&amp; skip) {
1153   Label has_counters;
1154   movptr(mcs, Address(method, Method::method_counters_offset()));
1155   testptr(mcs, mcs);
1156   jcc(Assembler::notZero, has_counters);
1157   call_VM(noreg, CAST_FROM_FN_PTR(address,
1158           InterpreterRuntime::build_method_counters), method);
1159   movptr(mcs, Address(method,Method::method_counters_offset()));
1160   testptr(mcs, mcs);
1161   jcc(Assembler::zero, skip); // No MethodCounters allocated, OutOfMemory
1162   bind(has_counters);
1163 }
1164 









































































































1165 
1166 // Lock object
1167 //
1168 // Args:
1169 //      rdx, c_rarg1: BasicObjectLock to be used for locking
1170 //
1171 // Kills:
1172 //      rax, rbx
1173 void InterpreterMacroAssembler::lock_object(Register lock_reg) {
1174   assert(lock_reg == LP64_ONLY(c_rarg1) NOT_LP64(rdx),
1175          &quot;The argument is only for looks. It must be c_rarg1&quot;);
1176 
1177   if (UseHeavyMonitors) {
1178     call_VM(noreg,
1179             CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
1180             lock_reg);
1181   } else {
1182     Label done;
1183 
1184     const Register swap_reg = rax; // Must use rax for cmpxchg instruction
</pre>
<hr />
<pre>
1188 
1189     const int obj_offset = BasicObjectLock::obj_offset_in_bytes();
1190     const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();
1191     const int mark_offset = lock_offset +
1192                             BasicLock::displaced_header_offset_in_bytes();
1193 
1194     Label slow_case;
1195 
1196     // Load object pointer into obj_reg
1197     movptr(obj_reg, Address(lock_reg, obj_offset));
1198 
1199     if (UseBiasedLocking) {
1200       biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp_reg, false, done, &amp;slow_case);
1201     }
1202 
1203     // Load immediate 1 into swap_reg %rax
1204     movl(swap_reg, (int32_t)1);
1205 
1206     // Load (object-&gt;mark() | 1) into swap_reg %rax
1207     orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));




1208 
1209     // Save (object-&gt;mark() | 1) into BasicLock&#39;s displaced header
1210     movptr(Address(lock_reg, mark_offset), swap_reg);
1211 
1212     assert(lock_offset == 0,
1213            &quot;displaced header must be first word in BasicObjectLock&quot;);
1214 
1215     lock();
1216     cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
1217     if (PrintBiasedLockingStatistics) {
1218       cond_inc32(Assembler::zero,
1219                  ExternalAddress((address) BiasedLocking::fast_path_entry_count_addr()));
1220     }
1221     jcc(Assembler::zero, done);
1222 
1223     const int zero_bits = LP64_ONLY(7) NOT_LP64(3);
1224 
1225     // Test if the oopMark is an obvious stack pointer, i.e.,
1226     //  1) (mark &amp; zero_bits) == 0, and
1227     //  2) rsp &lt;= mark &lt; mark + os::pagesize()
</pre>
<hr />
<pre>
1912     // case_array_offset_in_bytes()
1913     movl(reg2, in_bytes(MultiBranchData::per_case_size()));
1914     imulptr(index, reg2); // XXX l ?
1915     addptr(index, in_bytes(MultiBranchData::case_array_offset())); // XXX l ?
1916 
1917     // Update the case count
1918     increment_mdp_data_at(mdp,
1919                           index,
1920                           in_bytes(MultiBranchData::relative_count_offset()));
1921 
1922     // The method data pointer needs to be updated.
1923     update_mdp_by_offset(mdp,
1924                          index,
1925                          in_bytes(MultiBranchData::
1926                                   relative_displacement_offset()));
1927 
1928     bind(profile_continue);
1929   }
1930 }
1931 























1932 
























1933 
1934 void InterpreterMacroAssembler::_interp_verify_oop(Register reg, TosState state, const char* file, int line) {
1935   if (state == atos) {
1936     MacroAssembler::_verify_oop(reg, &quot;broken oop&quot;, file, line);
1937   }
1938 }
1939 
1940 void InterpreterMacroAssembler::verify_FPU(int stack_depth, TosState state) {
1941 #ifndef _LP64
1942   if ((state == ftos &amp;&amp; UseSSE &lt; 1) ||
1943       (state == dtos &amp;&amp; UseSSE &lt; 2)) {
1944     MacroAssembler::verify_FPU(stack_depth);
1945   }
1946 #endif
1947 }
1948 
1949 // Jump if ((*counter_addr += increment) &amp; mask) satisfies the condition.
1950 void InterpreterMacroAssembler::increment_mask_and_jump(Address counter_addr,
1951                                                         int increment, Address mask,
1952                                                         Register scratch, bool preloaded,
</pre>
</td>
<td>
<hr />
<pre>
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;interp_masm_x86.hpp&quot;
  27 #include &quot;interpreter/interpreter.hpp&quot;
  28 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  29 #include &quot;logging/log.hpp&quot;
  30 #include &quot;oops/arrayOop.hpp&quot;
  31 #include &quot;oops/markWord.hpp&quot;
  32 #include &quot;oops/methodData.hpp&quot;
  33 #include &quot;oops/method.hpp&quot;
<span class="line-added">  34 #include &quot;oops/valueKlass.hpp&quot;</span>
  35 #include &quot;prims/jvmtiExport.hpp&quot;
  36 #include &quot;prims/jvmtiThreadState.hpp&quot;
  37 #include &quot;runtime/basicLock.hpp&quot;
  38 #include &quot;runtime/biasedLocking.hpp&quot;
  39 #include &quot;runtime/frame.inline.hpp&quot;
  40 #include &quot;runtime/safepointMechanism.hpp&quot;
  41 #include &quot;runtime/sharedRuntime.hpp&quot;
  42 #include &quot;runtime/thread.inline.hpp&quot;
  43 #include &quot;utilities/powerOfTwo.hpp&quot;
  44 
  45 // Implementation of InterpreterMacroAssembler
  46 
  47 void InterpreterMacroAssembler::jump_to_entry(address entry) {
  48   assert(entry, &quot;Entry must have been generated by now&quot;);
  49   jump(RuntimeAddress(entry));
  50 }
  51 
  52 void InterpreterMacroAssembler::profile_obj_type(Register obj, const Address&amp; mdo_addr) {
  53   Label update, next, none;
  54 
</pre>
<hr />
<pre>
 134         Address mdo_arg_addr(mdp, in_bytes(TypeEntriesAtCall::argument_type_offset(i))-off_to_args);
 135         profile_obj_type(tmp, mdo_arg_addr);
 136 
 137         int to_add = in_bytes(TypeStackSlotEntries::per_arg_size());
 138         addptr(mdp, to_add);
 139         off_to_args += to_add;
 140       }
 141 
 142       if (MethodData::profile_return()) {
 143         movptr(tmp, Address(mdp, in_bytes(TypeEntriesAtCall::cell_count_offset())-off_to_args));
 144         subl(tmp, TypeProfileArgsLimit*TypeStackSlotEntries::per_arg_count());
 145       }
 146 
 147       bind(done);
 148 
 149       if (MethodData::profile_return()) {
 150         // We&#39;re right after the type profile for the last
 151         // argument. tmp is the number of cells left in the
 152         // CallTypeData/VirtualCallTypeData to reach its end. Non null
 153         // if there&#39;s a return to profile.
<span class="line-modified"> 154         assert(SingleTypeEntry::static_cell_count() &lt; TypeStackSlotEntries::per_arg_count(), &quot;can&#39;t move past ret type&quot;);</span>
 155         shll(tmp, exact_log2(DataLayout::cell_size));
 156         addptr(mdp, tmp);
 157       }
 158       movptr(Address(rbp, frame::interpreter_frame_mdp_offset * wordSize), mdp);
 159     } else {
 160       assert(MethodData::profile_return(), &quot;either profile call args or call ret&quot;);
 161       update_mdp_by_constant(mdp, in_bytes(TypeEntriesAtCall::return_only_size()));
 162     }
 163 
 164     // mdp points right after the end of the
 165     // CallTypeData/VirtualCallTypeData, right after the cells for the
 166     // return value type if there&#39;s one
 167 
 168     bind(profile_continue);
 169   }
 170 }
 171 
 172 void InterpreterMacroAssembler::profile_return_type(Register mdp, Register ret, Register tmp) {
 173   assert_different_registers(mdp, ret, tmp, _bcp_register);
 174   if (ProfileInterpreter &amp;&amp; MethodData::profile_return()) {
</pre>
<hr />
<pre>
 179     if (MethodData::profile_return_jsr292_only()) {
 180       assert(Method::intrinsic_id_size_in_bytes() == 2, &quot;assuming Method::_intrinsic_id is u2&quot;);
 181 
 182       // If we don&#39;t profile all invoke bytecodes we must make sure
 183       // it&#39;s a bytecode we indeed profile. We can&#39;t go back to the
 184       // begining of the ProfileData we intend to update to check its
 185       // type because we&#39;re right after it and we don&#39;t known its
 186       // length
 187       Label do_profile;
 188       cmpb(Address(_bcp_register, 0), Bytecodes::_invokedynamic);
 189       jcc(Assembler::equal, do_profile);
 190       cmpb(Address(_bcp_register, 0), Bytecodes::_invokehandle);
 191       jcc(Assembler::equal, do_profile);
 192       get_method(tmp);
 193       cmpw(Address(tmp, Method::intrinsic_id_offset_in_bytes()), vmIntrinsics::_compiledLambdaForm);
 194       jcc(Assembler::notEqual, profile_continue);
 195 
 196       bind(do_profile);
 197     }
 198 
<span class="line-modified"> 199     Address mdo_ret_addr(mdp, -in_bytes(SingleTypeEntry::size()));</span>
 200     mov(tmp, ret);
 201     profile_obj_type(tmp, mdo_ret_addr);
 202 
 203     bind(profile_continue);
 204   }
 205 }
 206 
 207 void InterpreterMacroAssembler::profile_parameters_type(Register mdp, Register tmp1, Register tmp2) {
 208   if (ProfileInterpreter &amp;&amp; MethodData::profile_parameters()) {
 209     Label profile_continue;
 210 
 211     test_method_data_pointer(mdp, profile_continue);
 212 
 213     // Load the offset of the area within the MDO used for
 214     // parameters. If it&#39;s negative we&#39;re not profiling any parameters
 215     movl(tmp1, Address(mdp, in_bytes(MethodData::parameters_type_data_di_offset()) - in_bytes(MethodData::data_offset())));
 216     testl(tmp1, tmp1);
 217     jcc(Assembler::negative, profile_continue);
 218 
 219     // Compute a pointer to the area for parameters from the offset
</pre>
<hr />
<pre>
 539 
 540   const int method_offset = in_bytes(
 541     ConstantPoolCache::base_offset() +
 542       ((byte_no == TemplateTable::f2_byte)
 543        ? ConstantPoolCacheEntry::f2_offset()
 544        : ConstantPoolCacheEntry::f1_offset()));
 545 
 546   movptr(method, Address(cache, index, Address::times_ptr, method_offset)); // get f1 Method*
 547 }
 548 
 549 // Generate a subtype check: branch to ok_is_subtype if sub_klass is a
 550 // subtype of super_klass.
 551 //
 552 // Args:
 553 //      rax: superklass
 554 //      Rsub_klass: subklass
 555 //
 556 // Kills:
 557 //      rcx, rdi
 558 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass,
<span class="line-modified"> 559                                                   Label&amp; ok_is_subtype,</span>
<span class="line-added"> 560                                                   bool profile) {</span>
 561   assert(Rsub_klass != rax, &quot;rax holds superklass&quot;);
 562   LP64_ONLY(assert(Rsub_klass != r14, &quot;r14 holds locals&quot;);)
 563   LP64_ONLY(assert(Rsub_klass != r13, &quot;r13 holds bcp&quot;);)
 564   assert(Rsub_klass != rcx, &quot;rcx holds 2ndary super array length&quot;);
 565   assert(Rsub_klass != rdi, &quot;rdi holds 2ndary super array scan ptr&quot;);
 566 
 567   // Profile the not-null value&#39;s klass.
<span class="line-modified"> 568   if (profile) {</span>
<span class="line-added"> 569     profile_typecheck(rcx, Rsub_klass, rdi); // blows rcx, reloads rdi</span>
<span class="line-added"> 570   }</span>
 571 
 572   // Do the check.
 573   check_klass_subtype(Rsub_klass, rax, rcx, ok_is_subtype); // blows rcx
 574 
 575   // Profile the failure of the check.
<span class="line-modified"> 576   if (profile) {</span>
<span class="line-added"> 577     profile_typecheck_failed(rcx); // blows rcx</span>
<span class="line-added"> 578   }</span>
 579 }
 580 
 581 
 582 #ifndef _LP64
 583 void InterpreterMacroAssembler::f2ieee() {
 584   if (IEEEPrecision) {
 585     fstp_s(Address(rsp, 0));
 586     fld_s(Address(rsp, 0));
 587   }
 588 }
 589 
 590 
 591 void InterpreterMacroAssembler::d2ieee() {
 592   if (IEEEPrecision) {
 593     fstp_d(Address(rsp, 0));
 594     fld_d(Address(rsp, 0));
 595   }
 596 }
 597 #endif // _LP64
 598 
</pre>
<hr />
<pre>
 983         bool throw_monitor_exception,
 984         bool install_monitor_exception,
 985         bool notify_jvmdi) {
 986   // Note: Registers rdx xmm0 may be in use for the
 987   // result check if synchronized method
 988   Label unlocked, unlock, no_unlock;
 989 
 990   const Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
 991   const Register robj    = LP64_ONLY(c_rarg1) NOT_LP64(rdx);
 992   const Register rmon    = LP64_ONLY(c_rarg1) NOT_LP64(rcx);
 993                               // monitor pointers need different register
 994                               // because rdx may have the result in it
 995   NOT_LP64(get_thread(rcx);)
 996 
 997   // get the value of _do_not_unlock_if_synchronized into rdx
 998   const Address do_not_unlock_if_synchronized(rthread,
 999     in_bytes(JavaThread::do_not_unlock_if_synchronized_offset()));
1000   movbool(rbx, do_not_unlock_if_synchronized);
1001   movbool(do_not_unlock_if_synchronized, false); // reset the flag
1002 
<span class="line-modified">1003   // get method access flags</span>
1004   movptr(rcx, Address(rbp, frame::interpreter_frame_method_offset * wordSize));
1005   movl(rcx, Address(rcx, Method::access_flags_offset()));
1006   testl(rcx, JVM_ACC_SYNCHRONIZED);
1007   jcc(Assembler::zero, unlocked);
1008 
1009   // Don&#39;t unlock anything if the _do_not_unlock_if_synchronized flag
1010   // is set.
1011   testbool(rbx);
1012   jcc(Assembler::notZero, no_unlock);
1013 
1014   // unlock monitor
1015   push(state); // save result
1016 
1017   // BasicObjectLock will be first in list, since this is a
1018   // synchronized method. However, need to check that the object has
1019   // not been unlocked by an explicit monitorexit bytecode.
1020   const Address monitor(rbp, frame::interpreter_frame_initial_sp_offset *
1021                         wordSize - (int) sizeof(BasicObjectLock));
1022   // We use c_rarg1/rdx so that if we go slow path it will be the correct
1023   // register for unlock_object to pass to VM directly
</pre>
<hr />
<pre>
1107     bind(loop);
1108     // check if current entry is used
1109     cmpptr(Address(rmon, BasicObjectLock::obj_offset_in_bytes()), (int32_t) NULL);
1110     jcc(Assembler::notEqual, exception);
1111 
1112     addptr(rmon, entry_size); // otherwise advance to next entry
1113     bind(entry);
1114     cmpptr(rmon, rbx); // check if bottom reached
1115     jcc(Assembler::notEqual, loop); // if not at bottom then check this entry
1116   }
1117 
1118   bind(no_unlock);
1119 
1120   // jvmti support
1121   if (notify_jvmdi) {
1122     notify_method_exit(state, NotifyJVMTI);    // preserve TOSCA
1123   } else {
1124     notify_method_exit(state, SkipNotifyJVMTI); // preserve TOSCA
1125   }
1126 
<span class="line-modified">1127   if (StackReservedPages &gt; 0) {</span>
<span class="line-modified">1128     movptr(rbx,</span>


1129                Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));
1130     // testing if reserved zone needs to be re-enabled
1131     Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
1132     Label no_reserved_zone_enabling;
1133 
1134     NOT_LP64(get_thread(rthread);)
1135 
1136     cmpl(Address(rthread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_enabled);
1137     jcc(Assembler::equal, no_reserved_zone_enabling);
1138 
1139     cmpptr(rbx, Address(rthread, JavaThread::reserved_stack_activation_offset()));
1140     jcc(Assembler::lessEqual, no_reserved_zone_enabling);
1141 
1142     call_VM_leaf(
1143       CAST_FROM_FN_PTR(address, SharedRuntime::enable_stack_reserved_zone), rthread);
1144     call_VM(noreg, CAST_FROM_FN_PTR(address,
1145                    InterpreterRuntime::throw_delayed_StackOverflowError));
1146     should_not_reach_here();
1147 
1148     bind(no_reserved_zone_enabling);
1149   }
<span class="line-added">1150 </span>
<span class="line-added">1151   // remove activation</span>
<span class="line-added">1152   // get sender sp</span>
<span class="line-added">1153   movptr(rbx,</span>
<span class="line-added">1154          Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));</span>
<span class="line-added">1155 </span>
<span class="line-added">1156   if (state == atos &amp;&amp; ValueTypeReturnedAsFields) {</span>
<span class="line-added">1157     Label skip;</span>
<span class="line-added">1158     // Test if the return type is a value type</span>
<span class="line-added">1159     movptr(rdi, Address(rbp, frame::interpreter_frame_method_offset * wordSize));</span>
<span class="line-added">1160     movptr(rdi, Address(rdi, Method::const_offset()));</span>
<span class="line-added">1161     load_unsigned_byte(rdi, Address(rdi, ConstMethod::result_type_offset()));</span>
<span class="line-added">1162     cmpl(rdi, T_VALUETYPE);</span>
<span class="line-added">1163     jcc(Assembler::notEqual, skip);</span>
<span class="line-added">1164 </span>
<span class="line-added">1165     // We are returning a value type, load its fields into registers</span>
<span class="line-added">1166 #ifndef _LP64</span>
<span class="line-added">1167     super_call_VM_leaf(StubRoutines::load_value_type_fields_in_regs());</span>
<span class="line-added">1168 #else</span>
<span class="line-added">1169     // Load fields from a buffered value with a value class specific handler</span>
<span class="line-added">1170     load_klass(rdi, rax);</span>
<span class="line-added">1171     movptr(rdi, Address(rdi, InstanceKlass::adr_valueklass_fixed_block_offset()));</span>
<span class="line-added">1172     movptr(rdi, Address(rdi, ValueKlass::unpack_handler_offset()));</span>
<span class="line-added">1173 </span>
<span class="line-added">1174     testptr(rdi, rdi);</span>
<span class="line-added">1175     jcc(Assembler::equal, skip);</span>
<span class="line-added">1176 </span>
<span class="line-added">1177     call(rdi);</span>
<span class="line-added">1178 #endif</span>
<span class="line-added">1179     // call above kills the value in rbx. Reload it.</span>
<span class="line-added">1180     movptr(rbx, Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));</span>
<span class="line-added">1181     bind(skip);</span>
<span class="line-added">1182   }</span>
1183   leave();                           // remove frame anchor
1184   pop(ret_addr);                     // get return address
1185   mov(rsp, rbx);                     // set sp to sender sp
1186 }
1187 
1188 void InterpreterMacroAssembler::get_method_counters(Register method,
1189                                                     Register mcs, Label&amp; skip) {
1190   Label has_counters;
1191   movptr(mcs, Address(method, Method::method_counters_offset()));
1192   testptr(mcs, mcs);
1193   jcc(Assembler::notZero, has_counters);
1194   call_VM(noreg, CAST_FROM_FN_PTR(address,
1195           InterpreterRuntime::build_method_counters), method);
1196   movptr(mcs, Address(method,Method::method_counters_offset()));
1197   testptr(mcs, mcs);
1198   jcc(Assembler::zero, skip); // No MethodCounters allocated, OutOfMemory
1199   bind(has_counters);
1200 }
1201 
<span class="line-added">1202 void InterpreterMacroAssembler::allocate_instance(Register klass, Register new_obj,</span>
<span class="line-added">1203                                                   Register t1, Register t2,</span>
<span class="line-added">1204                                                   bool clear_fields, Label&amp; alloc_failed) {</span>
<span class="line-added">1205   MacroAssembler::allocate_instance(klass, new_obj, t1, t2, clear_fields, alloc_failed);</span>
<span class="line-added">1206   {</span>
<span class="line-added">1207     SkipIfEqual skip_if(this, &amp;DTraceAllocProbes, 0);</span>
<span class="line-added">1208     // Trigger dtrace event for fastpath</span>
<span class="line-added">1209     push(atos);</span>
<span class="line-added">1210     call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), new_obj);</span>
<span class="line-added">1211     pop(atos);</span>
<span class="line-added">1212   }</span>
<span class="line-added">1213 }</span>
<span class="line-added">1214 </span>
<span class="line-added">1215 </span>
<span class="line-added">1216 void InterpreterMacroAssembler::read_flattened_field(Register holder_klass,</span>
<span class="line-added">1217                                                      Register field_index, Register field_offset,</span>
<span class="line-added">1218                                                      Register obj) {</span>
<span class="line-added">1219   Label alloc_failed, empty_value, done;</span>
<span class="line-added">1220   const Register src = field_offset;</span>
<span class="line-added">1221   const Register alloc_temp = LP64_ONLY(rscratch1) NOT_LP64(rsi);</span>
<span class="line-added">1222   const Register dst_temp   = LP64_ONLY(rscratch2) NOT_LP64(rdi);</span>
<span class="line-added">1223   assert_different_registers(obj, holder_klass, field_index, field_offset, dst_temp);</span>
<span class="line-added">1224 </span>
<span class="line-added">1225   // Grap the inline field klass</span>
<span class="line-added">1226   push(holder_klass);</span>
<span class="line-added">1227   const Register field_klass = holder_klass;</span>
<span class="line-added">1228   get_value_field_klass(holder_klass, field_index, field_klass);</span>
<span class="line-added">1229 </span>
<span class="line-added">1230   //check for empty value klass</span>
<span class="line-added">1231   test_klass_is_empty_value(field_klass, dst_temp, empty_value);</span>
<span class="line-added">1232 </span>
<span class="line-added">1233   // allocate buffer</span>
<span class="line-added">1234   push(obj); // save holder</span>
<span class="line-added">1235   allocate_instance(field_klass, obj, alloc_temp, dst_temp, false, alloc_failed);</span>
<span class="line-added">1236 </span>
<span class="line-added">1237   // Have an oop instance buffer, copy into it</span>
<span class="line-added">1238   data_for_oop(obj, dst_temp, field_klass);</span>
<span class="line-added">1239   pop(alloc_temp);             // restore holder</span>
<span class="line-added">1240   lea(src, Address(alloc_temp, field_offset));</span>
<span class="line-added">1241   // call_VM_leaf, clobbers a few regs, save restore new obj</span>
<span class="line-added">1242   push(obj);</span>
<span class="line-added">1243   access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, field_klass);</span>
<span class="line-added">1244   pop(obj);</span>
<span class="line-added">1245   pop(holder_klass);</span>
<span class="line-added">1246   jmp(done);</span>
<span class="line-added">1247 </span>
<span class="line-added">1248   bind(empty_value);</span>
<span class="line-added">1249   get_empty_value_oop(field_klass, dst_temp, obj);</span>
<span class="line-added">1250   pop(holder_klass);</span>
<span class="line-added">1251   jmp(done);</span>
<span class="line-added">1252 </span>
<span class="line-added">1253   bind(alloc_failed);</span>
<span class="line-added">1254   pop(obj);</span>
<span class="line-added">1255   pop(holder_klass);</span>
<span class="line-added">1256   call_VM(obj, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field),</span>
<span class="line-added">1257           obj, field_index, holder_klass);</span>
<span class="line-added">1258 </span>
<span class="line-added">1259   bind(done);</span>
<span class="line-added">1260 }</span>
<span class="line-added">1261 </span>
<span class="line-added">1262 void InterpreterMacroAssembler::read_flattened_element(Register array, Register index,</span>
<span class="line-added">1263                                                        Register t1, Register t2,</span>
<span class="line-added">1264                                                        Register obj) {</span>
<span class="line-added">1265   assert_different_registers(array, index, t1, t2);</span>
<span class="line-added">1266   Label alloc_failed, empty_value, done;</span>
<span class="line-added">1267   const Register array_klass = t2;</span>
<span class="line-added">1268   const Register elem_klass = t1;</span>
<span class="line-added">1269   const Register alloc_temp = LP64_ONLY(rscratch1) NOT_LP64(rsi);</span>
<span class="line-added">1270   const Register dst_temp   = LP64_ONLY(rscratch2) NOT_LP64(rdi);</span>
<span class="line-added">1271 </span>
<span class="line-added">1272   // load in array-&gt;klass()-&gt;element_klass()</span>
<span class="line-added">1273   load_klass(array_klass, array);</span>
<span class="line-added">1274   movptr(elem_klass, Address(array_klass, ArrayKlass::element_klass_offset()));</span>
<span class="line-added">1275 </span>
<span class="line-added">1276   //check for empty value klass</span>
<span class="line-added">1277   test_klass_is_empty_value(elem_klass, dst_temp, empty_value);</span>
<span class="line-added">1278 </span>
<span class="line-added">1279   // calc source into &quot;array_klass&quot; and free up some regs</span>
<span class="line-added">1280   const Register src = array_klass;</span>
<span class="line-added">1281   push(index); // preserve index reg in case alloc_failed</span>
<span class="line-added">1282   data_for_value_array_index(array, array_klass, index, src);</span>
<span class="line-added">1283 </span>
<span class="line-added">1284   allocate_instance(elem_klass, obj, alloc_temp, dst_temp, false, alloc_failed);</span>
<span class="line-added">1285   // Have an oop instance buffer, copy into it</span>
<span class="line-added">1286   store_ptr(0, obj); // preserve obj (overwrite index, no longer needed)</span>
<span class="line-added">1287   data_for_oop(obj, dst_temp, elem_klass);</span>
<span class="line-added">1288   access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, elem_klass);</span>
<span class="line-added">1289   pop(obj);</span>
<span class="line-added">1290   jmp(done);</span>
<span class="line-added">1291 </span>
<span class="line-added">1292   bind(empty_value);</span>
<span class="line-added">1293   get_empty_value_oop(elem_klass, dst_temp, obj);</span>
<span class="line-added">1294   jmp(done);</span>
<span class="line-added">1295 </span>
<span class="line-added">1296   bind(alloc_failed);</span>
<span class="line-added">1297   pop(index);</span>
<span class="line-added">1298   if (array == c_rarg2) {</span>
<span class="line-added">1299     mov(elem_klass, array);</span>
<span class="line-added">1300     array = elem_klass;</span>
<span class="line-added">1301   }</span>
<span class="line-added">1302   call_VM(obj, CAST_FROM_FN_PTR(address, InterpreterRuntime::value_array_load), array, index);</span>
<span class="line-added">1303 </span>
<span class="line-added">1304   bind(done);</span>
<span class="line-added">1305 }</span>
<span class="line-added">1306 </span>
1307 
1308 // Lock object
1309 //
1310 // Args:
1311 //      rdx, c_rarg1: BasicObjectLock to be used for locking
1312 //
1313 // Kills:
1314 //      rax, rbx
1315 void InterpreterMacroAssembler::lock_object(Register lock_reg) {
1316   assert(lock_reg == LP64_ONLY(c_rarg1) NOT_LP64(rdx),
1317          &quot;The argument is only for looks. It must be c_rarg1&quot;);
1318 
1319   if (UseHeavyMonitors) {
1320     call_VM(noreg,
1321             CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),
1322             lock_reg);
1323   } else {
1324     Label done;
1325 
1326     const Register swap_reg = rax; // Must use rax for cmpxchg instruction
</pre>
<hr />
<pre>
1330 
1331     const int obj_offset = BasicObjectLock::obj_offset_in_bytes();
1332     const int lock_offset = BasicObjectLock::lock_offset_in_bytes ();
1333     const int mark_offset = lock_offset +
1334                             BasicLock::displaced_header_offset_in_bytes();
1335 
1336     Label slow_case;
1337 
1338     // Load object pointer into obj_reg
1339     movptr(obj_reg, Address(lock_reg, obj_offset));
1340 
1341     if (UseBiasedLocking) {
1342       biased_locking_enter(lock_reg, obj_reg, swap_reg, tmp_reg, false, done, &amp;slow_case);
1343     }
1344 
1345     // Load immediate 1 into swap_reg %rax
1346     movl(swap_reg, (int32_t)1);
1347 
1348     // Load (object-&gt;mark() | 1) into swap_reg %rax
1349     orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
<span class="line-added">1350     if (EnableValhalla &amp;&amp; !UseBiasedLocking) {</span>
<span class="line-added">1351       // For slow path is_always_locked, using biased, which is never natural for !UseBiasLocking</span>
<span class="line-added">1352       andptr(swap_reg, ~((int) markWord::biased_lock_bit_in_place));</span>
<span class="line-added">1353     }</span>
1354 
1355     // Save (object-&gt;mark() | 1) into BasicLock&#39;s displaced header
1356     movptr(Address(lock_reg, mark_offset), swap_reg);
1357 
1358     assert(lock_offset == 0,
1359            &quot;displaced header must be first word in BasicObjectLock&quot;);
1360 
1361     lock();
1362     cmpxchgptr(lock_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
1363     if (PrintBiasedLockingStatistics) {
1364       cond_inc32(Assembler::zero,
1365                  ExternalAddress((address) BiasedLocking::fast_path_entry_count_addr()));
1366     }
1367     jcc(Assembler::zero, done);
1368 
1369     const int zero_bits = LP64_ONLY(7) NOT_LP64(3);
1370 
1371     // Test if the oopMark is an obvious stack pointer, i.e.,
1372     //  1) (mark &amp; zero_bits) == 0, and
1373     //  2) rsp &lt;= mark &lt; mark + os::pagesize()
</pre>
<hr />
<pre>
2058     // case_array_offset_in_bytes()
2059     movl(reg2, in_bytes(MultiBranchData::per_case_size()));
2060     imulptr(index, reg2); // XXX l ?
2061     addptr(index, in_bytes(MultiBranchData::case_array_offset())); // XXX l ?
2062 
2063     // Update the case count
2064     increment_mdp_data_at(mdp,
2065                           index,
2066                           in_bytes(MultiBranchData::relative_count_offset()));
2067 
2068     // The method data pointer needs to be updated.
2069     update_mdp_by_offset(mdp,
2070                          index,
2071                          in_bytes(MultiBranchData::
2072                                   relative_displacement_offset()));
2073 
2074     bind(profile_continue);
2075   }
2076 }
2077 
<span class="line-added">2078 void InterpreterMacroAssembler::profile_array(Register mdp,</span>
<span class="line-added">2079                                               Register array,</span>
<span class="line-added">2080                                               Register tmp) {</span>
<span class="line-added">2081   if (ProfileInterpreter) {</span>
<span class="line-added">2082     Label profile_continue;</span>
<span class="line-added">2083 </span>
<span class="line-added">2084     // If no method data exists, go to profile_continue.</span>
<span class="line-added">2085     test_method_data_pointer(mdp, profile_continue);</span>
<span class="line-added">2086 </span>
<span class="line-added">2087     mov(tmp, array);</span>
<span class="line-added">2088     profile_obj_type(tmp, Address(mdp, in_bytes(ArrayLoadStoreData::array_offset())));</span>
<span class="line-added">2089 </span>
<span class="line-added">2090     Label not_flat;</span>
<span class="line-added">2091     test_non_flattened_array_oop(array, tmp, not_flat);</span>
<span class="line-added">2092 </span>
<span class="line-added">2093     set_mdp_flag_at(mdp, ArrayLoadStoreData::flat_array_byte_constant());</span>
<span class="line-added">2094 </span>
<span class="line-added">2095     bind(not_flat);</span>
<span class="line-added">2096 </span>
<span class="line-added">2097     Label not_null_free;</span>
<span class="line-added">2098     test_non_null_free_array_oop(array, tmp, not_null_free);</span>
<span class="line-added">2099 </span>
<span class="line-added">2100     set_mdp_flag_at(mdp, ArrayLoadStoreData::null_free_array_byte_constant());</span>
2101 
<span class="line-added">2102     bind(not_null_free);</span>
<span class="line-added">2103 </span>
<span class="line-added">2104     bind(profile_continue);</span>
<span class="line-added">2105   }</span>
<span class="line-added">2106 }</span>
<span class="line-added">2107 </span>
<span class="line-added">2108 void InterpreterMacroAssembler::profile_element(Register mdp,</span>
<span class="line-added">2109                                                 Register element,</span>
<span class="line-added">2110                                                 Register tmp) {</span>
<span class="line-added">2111   if (ProfileInterpreter) {</span>
<span class="line-added">2112     Label profile_continue;</span>
<span class="line-added">2113 </span>
<span class="line-added">2114     // If no method data exists, go to profile_continue.</span>
<span class="line-added">2115     test_method_data_pointer(mdp, profile_continue);</span>
<span class="line-added">2116 </span>
<span class="line-added">2117     mov(tmp, element);</span>
<span class="line-added">2118     profile_obj_type(tmp, Address(mdp, in_bytes(ArrayLoadStoreData::element_offset())));</span>
<span class="line-added">2119 </span>
<span class="line-added">2120     // The method data pointer needs to be updated.</span>
<span class="line-added">2121     update_mdp_by_constant(mdp, in_bytes(ArrayLoadStoreData::array_load_store_data_size()));</span>
<span class="line-added">2122 </span>
<span class="line-added">2123     bind(profile_continue);</span>
<span class="line-added">2124   }</span>
<span class="line-added">2125 }</span>
2126 
2127 void InterpreterMacroAssembler::_interp_verify_oop(Register reg, TosState state, const char* file, int line) {
2128   if (state == atos) {
2129     MacroAssembler::_verify_oop(reg, &quot;broken oop&quot;, file, line);
2130   }
2131 }
2132 
2133 void InterpreterMacroAssembler::verify_FPU(int stack_depth, TosState state) {
2134 #ifndef _LP64
2135   if ((state == ftos &amp;&amp; UseSSE &lt; 1) ||
2136       (state == dtos &amp;&amp; UseSSE &lt; 2)) {
2137     MacroAssembler::verify_FPU(stack_depth);
2138   }
2139 #endif
2140 }
2141 
2142 // Jump if ((*counter_addr += increment) &amp; mask) satisfies the condition.
2143 void InterpreterMacroAssembler::increment_mask_and_jump(Address counter_addr,
2144                                                         int increment, Address mask,
2145                                                         Register scratch, bool preloaded,
</pre>
</td>
</tr>
</table>
<center><a href="gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>