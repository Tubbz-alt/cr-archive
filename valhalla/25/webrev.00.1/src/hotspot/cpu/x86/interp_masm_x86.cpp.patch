diff a/src/hotspot/cpu/x86/interp_masm_x86.cpp b/src/hotspot/cpu/x86/interp_masm_x86.cpp
--- a/src/hotspot/cpu/x86/interp_masm_x86.cpp
+++ b/src/hotspot/cpu/x86/interp_masm_x86.cpp
@@ -29,10 +29,11 @@
 #include "logging/log.hpp"
 #include "oops/arrayOop.hpp"
 #include "oops/markWord.hpp"
 #include "oops/methodData.hpp"
 #include "oops/method.hpp"
+#include "oops/valueKlass.hpp"
 #include "prims/jvmtiExport.hpp"
 #include "prims/jvmtiThreadState.hpp"
 #include "runtime/basicLock.hpp"
 #include "runtime/biasedLocking.hpp"
 #include "runtime/frame.inline.hpp"
@@ -148,11 +149,11 @@
       if (MethodData::profile_return()) {
         // We're right after the type profile for the last
         // argument. tmp is the number of cells left in the
         // CallTypeData/VirtualCallTypeData to reach its end. Non null
         // if there's a return to profile.
-        assert(ReturnTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(), "can't move past ret type");
+        assert(SingleTypeEntry::static_cell_count() < TypeStackSlotEntries::per_arg_count(), "can't move past ret type");
         shll(tmp, exact_log2(DataLayout::cell_size));
         addptr(mdp, tmp);
       }
       movptr(Address(rbp, frame::interpreter_frame_mdp_offset * wordSize), mdp);
     } else {
@@ -193,11 +194,11 @@
       jcc(Assembler::notEqual, profile_continue);
 
       bind(do_profile);
     }
 
-    Address mdo_ret_addr(mdp, -in_bytes(ReturnTypeEntry::size()));
+    Address mdo_ret_addr(mdp, -in_bytes(SingleTypeEntry::size()));
     mov(tmp, ret);
     profile_obj_type(tmp, mdo_ret_addr);
 
     bind(profile_continue);
   }
@@ -553,25 +554,30 @@
 //      Rsub_klass: subklass
 //
 // Kills:
 //      rcx, rdi
 void InterpreterMacroAssembler::gen_subtype_check(Register Rsub_klass,
-                                                  Label& ok_is_subtype) {
+                                                  Label& ok_is_subtype,
+                                                  bool profile) {
   assert(Rsub_klass != rax, "rax holds superklass");
   LP64_ONLY(assert(Rsub_klass != r14, "r14 holds locals");)
   LP64_ONLY(assert(Rsub_klass != r13, "r13 holds bcp");)
   assert(Rsub_klass != rcx, "rcx holds 2ndary super array length");
   assert(Rsub_klass != rdi, "rdi holds 2ndary super array scan ptr");
 
   // Profile the not-null value's klass.
-  profile_typecheck(rcx, Rsub_klass, rdi); // blows rcx, reloads rdi
+  if (profile) {
+    profile_typecheck(rcx, Rsub_klass, rdi); // blows rcx, reloads rdi
+  }
 
   // Do the check.
   check_klass_subtype(Rsub_klass, rax, rcx, ok_is_subtype); // blows rcx
 
   // Profile the failure of the check.
-  profile_typecheck_failed(rcx); // blows rcx
+  if (profile) {
+    profile_typecheck_failed(rcx); // blows rcx
+  }
 }
 
 
 #ifndef _LP64
 void InterpreterMacroAssembler::f2ieee() {
@@ -992,11 +998,11 @@
   const Address do_not_unlock_if_synchronized(rthread,
     in_bytes(JavaThread::do_not_unlock_if_synchronized_offset()));
   movbool(rbx, do_not_unlock_if_synchronized);
   movbool(do_not_unlock_if_synchronized, false); // reset the flag
 
- // get method access flags
+  // get method access flags
   movptr(rcx, Address(rbp, frame::interpreter_frame_method_offset * wordSize));
   movl(rcx, Address(rcx, Method::access_flags_offset()));
   testl(rcx, JVM_ACC_SYNCHRONIZED);
   jcc(Assembler::zero, unlocked);
 
@@ -1116,14 +1122,12 @@
     notify_method_exit(state, NotifyJVMTI);    // preserve TOSCA
   } else {
     notify_method_exit(state, SkipNotifyJVMTI); // preserve TOSCA
   }
 
-  // remove activation
-  // get sender sp
-  movptr(rbx,
-         Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));
+  if (StackReservedPages > 0) {
+    movptr(rbx,
   if (StackReservedPages > 0) {
     // testing if reserved zone needs to be re-enabled
     Register rthread = LP64_ONLY(r15_thread) NOT_LP64(rcx);
     Label no_reserved_zone_enabling;
 
@@ -1141,10 +1145,43 @@
                    InterpreterRuntime::throw_delayed_StackOverflowError));
     should_not_reach_here();
 
     bind(no_reserved_zone_enabling);
   }
+
+  // remove activation
+  // get sender sp
+  movptr(rbx,
+         Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));
+
+  if (state == atos && ValueTypeReturnedAsFields) {
+    Label skip;
+    // Test if the return type is a value type
+    movptr(rdi, Address(rbp, frame::interpreter_frame_method_offset * wordSize));
+    movptr(rdi, Address(rdi, Method::const_offset()));
+    load_unsigned_byte(rdi, Address(rdi, ConstMethod::result_type_offset()));
+    cmpl(rdi, T_VALUETYPE);
+    jcc(Assembler::notEqual, skip);
+
+    // We are returning a value type, load its fields into registers
+#ifndef _LP64
+    super_call_VM_leaf(StubRoutines::load_value_type_fields_in_regs());
+#else
+    // Load fields from a buffered value with a value class specific handler
+    load_klass(rdi, rax);
+    movptr(rdi, Address(rdi, InstanceKlass::adr_valueklass_fixed_block_offset()));
+    movptr(rdi, Address(rdi, ValueKlass::unpack_handler_offset()));
+
+    testptr(rdi, rdi);
+    jcc(Assembler::equal, skip);
+
+    call(rdi);
+#endif
+    // call above kills the value in rbx. Reload it.
+    movptr(rbx, Address(rbp, frame::interpreter_frame_sender_sp_offset * wordSize));
+    bind(skip);
+  }
   leave();                           // remove frame anchor
   pop(ret_addr);                     // get return address
   mov(rsp, rbx);                     // set sp to sender sp
 }
 
@@ -1160,10 +1197,115 @@
   testptr(mcs, mcs);
   jcc(Assembler::zero, skip); // No MethodCounters allocated, OutOfMemory
   bind(has_counters);
 }
 
+void InterpreterMacroAssembler::allocate_instance(Register klass, Register new_obj,
+                                                  Register t1, Register t2,
+                                                  bool clear_fields, Label& alloc_failed) {
+  MacroAssembler::allocate_instance(klass, new_obj, t1, t2, clear_fields, alloc_failed);
+  {
+    SkipIfEqual skip_if(this, &DTraceAllocProbes, 0);
+    // Trigger dtrace event for fastpath
+    push(atos);
+    call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_object_alloc), new_obj);
+    pop(atos);
+  }
+}
+
+
+void InterpreterMacroAssembler::read_flattened_field(Register holder_klass,
+                                                     Register field_index, Register field_offset,
+                                                     Register obj) {
+  Label alloc_failed, empty_value, done;
+  const Register src = field_offset;
+  const Register alloc_temp = LP64_ONLY(rscratch1) NOT_LP64(rsi);
+  const Register dst_temp   = LP64_ONLY(rscratch2) NOT_LP64(rdi);
+  assert_different_registers(obj, holder_klass, field_index, field_offset, dst_temp);
+
+  // Grap the inline field klass
+  push(holder_klass);
+  const Register field_klass = holder_klass;
+  get_value_field_klass(holder_klass, field_index, field_klass);
+
+  //check for empty value klass
+  test_klass_is_empty_value(field_klass, dst_temp, empty_value);
+
+  // allocate buffer
+  push(obj); // save holder
+  allocate_instance(field_klass, obj, alloc_temp, dst_temp, false, alloc_failed);
+
+  // Have an oop instance buffer, copy into it
+  data_for_oop(obj, dst_temp, field_klass);
+  pop(alloc_temp);             // restore holder
+  lea(src, Address(alloc_temp, field_offset));
+  // call_VM_leaf, clobbers a few regs, save restore new obj
+  push(obj);
+  access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, field_klass);
+  pop(obj);
+  pop(holder_klass);
+  jmp(done);
+
+  bind(empty_value);
+  get_empty_value_oop(field_klass, dst_temp, obj);
+  pop(holder_klass);
+  jmp(done);
+
+  bind(alloc_failed);
+  pop(obj);
+  pop(holder_klass);
+  call_VM(obj, CAST_FROM_FN_PTR(address, InterpreterRuntime::read_flattened_field),
+          obj, field_index, holder_klass);
+
+  bind(done);
+}
+
+void InterpreterMacroAssembler::read_flattened_element(Register array, Register index,
+                                                       Register t1, Register t2,
+                                                       Register obj) {
+  assert_different_registers(array, index, t1, t2);
+  Label alloc_failed, empty_value, done;
+  const Register array_klass = t2;
+  const Register elem_klass = t1;
+  const Register alloc_temp = LP64_ONLY(rscratch1) NOT_LP64(rsi);
+  const Register dst_temp   = LP64_ONLY(rscratch2) NOT_LP64(rdi);
+
+  // load in array->klass()->element_klass()
+  load_klass(array_klass, array);
+  movptr(elem_klass, Address(array_klass, ArrayKlass::element_klass_offset()));
+
+  //check for empty value klass
+  test_klass_is_empty_value(elem_klass, dst_temp, empty_value);
+
+  // calc source into "array_klass" and free up some regs
+  const Register src = array_klass;
+  push(index); // preserve index reg in case alloc_failed
+  data_for_value_array_index(array, array_klass, index, src);
+
+  allocate_instance(elem_klass, obj, alloc_temp, dst_temp, false, alloc_failed);
+  // Have an oop instance buffer, copy into it
+  store_ptr(0, obj); // preserve obj (overwrite index, no longer needed)
+  data_for_oop(obj, dst_temp, elem_klass);
+  access_value_copy(IS_DEST_UNINITIALIZED, src, dst_temp, elem_klass);
+  pop(obj);
+  jmp(done);
+
+  bind(empty_value);
+  get_empty_value_oop(elem_klass, dst_temp, obj);
+  jmp(done);
+
+  bind(alloc_failed);
+  pop(index);
+  if (array == c_rarg2) {
+    mov(elem_klass, array);
+    array = elem_klass;
+  }
+  call_VM(obj, CAST_FROM_FN_PTR(address, InterpreterRuntime::value_array_load), array, index);
+
+  bind(done);
+}
+
 
 // Lock object
 //
 // Args:
 //      rdx, c_rarg1: BasicObjectLock to be used for locking
@@ -1203,10 +1345,14 @@
     // Load immediate 1 into swap_reg %rax
     movl(swap_reg, (int32_t)1);
 
     // Load (object->mark() | 1) into swap_reg %rax
     orptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));
+    if (EnableValhalla && !UseBiasedLocking) {
+      // For slow path is_always_locked, using biased, which is never natural for !UseBiasLocking
+      andptr(swap_reg, ~((int) markWord::biased_lock_bit_in_place));
+    }
 
     // Save (object->mark() | 1) into BasicLock's displaced header
     movptr(Address(lock_reg, mark_offset), swap_reg);
 
     assert(lock_offset == 0,
@@ -1927,11 +2073,58 @@
 
     bind(profile_continue);
   }
 }
 
+void InterpreterMacroAssembler::profile_array(Register mdp,
+                                              Register array,
+                                              Register tmp) {
+  if (ProfileInterpreter) {
+    Label profile_continue;
+
+    // If no method data exists, go to profile_continue.
+    test_method_data_pointer(mdp, profile_continue);
+
+    mov(tmp, array);
+    profile_obj_type(tmp, Address(mdp, in_bytes(ArrayLoadStoreData::array_offset())));
+
+    Label not_flat;
+    test_non_flattened_array_oop(array, tmp, not_flat);
+
+    set_mdp_flag_at(mdp, ArrayLoadStoreData::flat_array_byte_constant());
+
+    bind(not_flat);
+
+    Label not_null_free;
+    test_non_null_free_array_oop(array, tmp, not_null_free);
+
+    set_mdp_flag_at(mdp, ArrayLoadStoreData::null_free_array_byte_constant());
 
+    bind(not_null_free);
+
+    bind(profile_continue);
+  }
+}
+
+void InterpreterMacroAssembler::profile_element(Register mdp,
+                                                Register element,
+                                                Register tmp) {
+  if (ProfileInterpreter) {
+    Label profile_continue;
+
+    // If no method data exists, go to profile_continue.
+    test_method_data_pointer(mdp, profile_continue);
+
+    mov(tmp, element);
+    profile_obj_type(tmp, Address(mdp, in_bytes(ArrayLoadStoreData::element_offset())));
+
+    // The method data pointer needs to be updated.
+    update_mdp_by_constant(mdp, in_bytes(ArrayLoadStoreData::array_load_store_data_size()));
+
+    bind(profile_continue);
+  }
+}
 
 void InterpreterMacroAssembler::_interp_verify_oop(Register reg, TosState state, const char* file, int line) {
   if (state == atos) {
     MacroAssembler::_verify_oop(reg, "broken oop", file, line);
   }
