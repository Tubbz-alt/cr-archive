<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on, compressed klass
 1101     // pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   if (UseBarriersForVolatile) {
 1371     // we need to plant a dmb
 1372     return false;
 1373   }
 1374 
 1375   MemBarNode* mb = barrier-&gt;as_MemBar();
 1376 
 1377   if (mb-&gt;trailing_load()) {
 1378     return true;
 1379   }
 1380 
 1381   if (mb-&gt;trailing_load_store()) {
 1382     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1383     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1384     return is_CAS(load_store-&gt;Opcode(), true);
 1385   }
 1386 
 1387   return false;
 1388 }
 1389 
 1390 bool needs_acquiring_load(const Node *n)
 1391 {
 1392   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1393   if (UseBarriersForVolatile) {
 1394     // we use a normal load and a dmb
 1395     return false;
 1396   }
 1397 
 1398   LoadNode *ld = n-&gt;as_Load();
 1399 
 1400   return ld-&gt;is_acquire();
 1401 }
 1402 
 1403 bool unnecessary_release(const Node *n)
 1404 {
 1405   assert((n-&gt;is_MemBar() &amp;&amp;
 1406 	  n-&gt;Opcode() == Op_MemBarRelease),
 1407 	 &quot;expecting a release membar&quot;);
 1408 
 1409   if (UseBarriersForVolatile) {
 1410     // we need to plant a dmb
 1411     return false;
 1412   }
 1413 
 1414   MemBarNode *barrier = n-&gt;as_MemBar();
 1415   if (!barrier-&gt;leading()) {
 1416     return false;
 1417   } else {
 1418     Node* trailing = barrier-&gt;trailing_membar();
 1419     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1420     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1421     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1422 
 1423     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1424     if (mem-&gt;is_Store()) {
 1425       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1426       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1427       return true;
 1428     } else {
 1429       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1430       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1431       return is_CAS(mem-&gt;Opcode(), true);
 1432     }
 1433   }
 1434   return false;
 1435 }
 1436 
 1437 bool unnecessary_volatile(const Node *n)
 1438 {
 1439   // assert n-&gt;is_MemBar();
 1440   if (UseBarriersForVolatile) {
 1441     // we need to plant a dmb
 1442     return false;
 1443   }
 1444 
 1445   MemBarNode *mbvol = n-&gt;as_MemBar();
 1446 
 1447   bool release = mbvol-&gt;trailing_store();
 1448   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1449 #ifdef ASSERT
 1450   if (release) {
 1451     Node* leading = mbvol-&gt;leading_membar();
 1452     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1453     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1454     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1455   }
 1456 #endif
 1457 
 1458   return release;
 1459 }
 1460 
 1461 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1462 
 1463 bool needs_releasing_store(const Node *n)
 1464 {
 1465   // assert n-&gt;is_Store();
 1466   if (UseBarriersForVolatile) {
 1467     // we use a normal store and dmb combination
 1468     return false;
 1469   }
 1470 
 1471   StoreNode *st = n-&gt;as_Store();
 1472 
 1473   return st-&gt;trailing_membar() != NULL;
 1474 }
 1475 
 1476 // predicate controlling translation of CAS
 1477 //
 1478 // returns true if CAS needs to use an acquiring load otherwise false
 1479 
 1480 bool needs_acquiring_load_exclusive(const Node *n)
 1481 {
 1482   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1483   if (UseBarriersForVolatile) {
 1484     return false;
 1485   }
 1486 
 1487   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1488   if (is_CAS(n-&gt;Opcode(), false)) {
 1489     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1490   } else {
 1491     return ldst-&gt;trailing_membar() != NULL;
 1492   }
 1493 
 1494   // so we can just return true here
 1495   return true;
 1496 }
 1497 
 1498 #define __ _masm.
 1499 
 1500 // advance declarations for helper functions to convert register
 1501 // indices to register objects
 1502 
 1503 // the ad file has to provide implementations of certain methods
 1504 // expected by the generic code
 1505 //
 1506 // REQUIRED FUNCTIONALITY
 1507 
 1508 //=============================================================================
 1509 
 1510 // !!!!! Special hack to get all types of calls to specify the byte offset
 1511 //       from the start of the call to the point where the return address
 1512 //       will point.
 1513 
 1514 int MachCallStaticJavaNode::ret_addr_offset()
 1515 {
 1516   // call should be a simple bl
 1517   int off = 4;
 1518   return off;
 1519 }
 1520 
 1521 int MachCallDynamicJavaNode::ret_addr_offset()
 1522 {
 1523   return 16; // movz, movk, movk, bl
 1524 }
 1525 
 1526 int MachCallRuntimeNode::ret_addr_offset() {
 1527   // for generated stubs the call will be
 1528   //   far_call(addr)
 1529   // for real runtime callouts it will be six instructions
 1530   // see aarch64_enc_java_to_runtime
 1531   //   adr(rscratch2, retaddr)
 1532   //   lea(rscratch1, RuntimeAddress(addr)
 1533   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1534   //   blr(rscratch1)
 1535   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1536   if (cb) {
 1537     return MacroAssembler::far_branch_size();
 1538   } else {
 1539     return 6 * NativeInstruction::instruction_size;
 1540   }
 1541 }
 1542 
 1543 // Indicate if the safepoint node needs the polling page as an input
 1544 
 1545 // the shared code plants the oop data at the start of the generated
 1546 // code for the safepoint node and that needs ot be at the load
 1547 // instruction itself. so we cannot plant a mov of the safepoint poll
 1548 // address followed by a load. setting this to true means the mov is
 1549 // scheduled as a prior instruction. that&#39;s better for scheduling
 1550 // anyway.
 1551 
 1552 bool SafePointNode::needs_polling_address_input()
 1553 {
 1554   return true;
 1555 }
 1556 
 1557 //=============================================================================
 1558 
 1559 #ifndef PRODUCT
 1560 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1561   st-&gt;print(&quot;BREAKPOINT&quot;);
 1562 }
 1563 #endif
 1564 
 1565 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1566   C2_MacroAssembler _masm(&amp;cbuf);
 1567   __ brk(0);
 1568 }
 1569 
 1570 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1571   return MachNode::size(ra_);
 1572 }
 1573 
 1574 //=============================================================================
 1575 
 1576 #ifndef PRODUCT
 1577   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1578     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1579   }
 1580 #endif
 1581 
 1582   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1583     C2_MacroAssembler _masm(&amp;cbuf);
 1584     for (int i = 0; i &lt; _count; i++) {
 1585       __ nop();
 1586     }
 1587   }
 1588 
 1589   uint MachNopNode::size(PhaseRegAlloc*) const {
 1590     return _count * NativeInstruction::instruction_size;
 1591   }
 1592 
 1593 //=============================================================================
 1594 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1595 
 1596 int ConstantTable::calculate_table_base_offset() const {
 1597   return 0;  // absolute addressing, no offset
 1598 }
 1599 
 1600 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1601 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1602   ShouldNotReachHere();
 1603 }
 1604 
 1605 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1606   // Empty encoding
 1607 }
 1608 
 1609 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1610   return 0;
 1611 }
 1612 
 1613 #ifndef PRODUCT
 1614 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1615   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1616 }
 1617 #endif
 1618 
 1619 #ifndef PRODUCT
 1620 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1621   Compile* C = ra_-&gt;C;
 1622 
 1623   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1624 
 1625   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1626     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1627 
 1628   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1629     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1630     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1631     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1632   } else {
 1633     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1634     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1635     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1636     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1637   }
 1638 }
 1639 #endif
 1640 
 1641 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1642   Compile* C = ra_-&gt;C;
 1643   C2_MacroAssembler _masm(&amp;cbuf);
 1644 
 1645   __ verified_entry(C, 0);
 1646   __ bind(*_verified_entry);
 1647 
 1648   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1649 
 1650   if (C-&gt;has_mach_constant_base_node()) {
 1651     // NOTE: We set the table base offset here because users might be
 1652     // emitted before MachConstantBaseNode.
 1653     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1654     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1655   }
 1656 }
 1657 
 1658 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1659 {
 1660   return MachNode::size(ra_); // too many variables; just compute it
 1661                               // the hard way
 1662 }
 1663 
 1664 int MachPrologNode::reloc() const
 1665 {
 1666   return 0;
 1667 }
 1668 
 1669 //=============================================================================
 1670 
 1671 #ifndef PRODUCT
 1672 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1673   Compile* C = ra_-&gt;C;
 1674   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1675 
 1676   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1677 
 1678   if (framesize == 0) {
 1679     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1680   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1681     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1682     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1683   } else {
 1684     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1685     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1686     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1687   }
 1688 
 1689   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1690     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1691     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1692     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1693   }
 1694 }
 1695 #endif
 1696 
 1697 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1698   Compile* C = ra_-&gt;C;
 1699   C2_MacroAssembler _masm(&amp;cbuf);
 1700   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1701 
 1702   __ remove_frame(framesize);
 1703 
 1704   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1705     __ reserved_stack_check();
 1706   }
 1707 
 1708   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1709     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1710   }
 1711 }
 1712 
 1713 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1714   // Variable size. Determine dynamically.
 1715   return MachNode::size(ra_);
 1716 }
 1717 
 1718 int MachEpilogNode::reloc() const {
 1719   // Return number of relocatable values contained in this instruction.
 1720   return 1; // 1 for polling page.
 1721 }
 1722 
 1723 const Pipeline * MachEpilogNode::pipeline() const {
 1724   return MachNode::pipeline_class();
 1725 }
 1726 
 1727 //=============================================================================
 1728 
 1729 // Figure out which register class each belongs in: rc_int, rc_float or
 1730 // rc_stack.
 1731 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1732 
 1733 static enum RC rc_class(OptoReg::Name reg) {
 1734 
 1735   if (reg == OptoReg::Bad) {
 1736     return rc_bad;
 1737   }
 1738 
 1739   // we have 30 int registers * 2 halves
 1740   // (rscratch1 and rscratch2 are omitted)
 1741   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1742 
 1743   if (reg &lt; slots_of_int_registers) {
 1744     return rc_int;
 1745   }
 1746 
 1747   // we have 32 float register * 4 halves
 1748   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1749     return rc_float;
 1750   }
 1751 
 1752   // Between float regs &amp; stack is the flags regs.
 1753   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1754 
 1755   return rc_stack;
 1756 }
 1757 
 1758 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1759   Compile* C = ra_-&gt;C;
 1760 
 1761   // Get registers to move.
 1762   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1763   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1764   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1765   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1766 
 1767   enum RC src_hi_rc = rc_class(src_hi);
 1768   enum RC src_lo_rc = rc_class(src_lo);
 1769   enum RC dst_hi_rc = rc_class(dst_hi);
 1770   enum RC dst_lo_rc = rc_class(dst_lo);
 1771 
 1772   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1773 
 1774   if (src_hi != OptoReg::Bad) {
 1775     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1776            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1777            &quot;expected aligned-adjacent pairs&quot;);
 1778   }
 1779 
 1780   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1781     return 0;            // Self copy, no move.
 1782   }
 1783 
 1784   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1785               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1786   int src_offset = ra_-&gt;reg2offset(src_lo);
 1787   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1788 
 1789   if (bottom_type()-&gt;isa_vect() != NULL) {
 1790     uint ireg = ideal_reg();
 1791     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1792     if (cbuf) {
 1793       C2_MacroAssembler _masm(cbuf);
 1794       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1795       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1796         // stack-&gt;stack
 1797         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1798         if (ireg == Op_VecD) {
 1799           __ unspill(rscratch1, true, src_offset);
 1800           __ spill(rscratch1, true, dst_offset);
 1801         } else {
 1802           __ spill_copy128(src_offset, dst_offset);
 1803         }
 1804       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1805         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1806                ireg == Op_VecD ? __ T8B : __ T16B,
 1807                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1808       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1809         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1810                        ireg == Op_VecD ? __ D : __ Q,
 1811                        ra_-&gt;reg2offset(dst_lo));
 1812       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1813         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1814                        ireg == Op_VecD ? __ D : __ Q,
 1815                        ra_-&gt;reg2offset(src_lo));
 1816       } else {
 1817         ShouldNotReachHere();
 1818       }
 1819     }
 1820   } else if (cbuf) {
 1821     C2_MacroAssembler _masm(cbuf);
 1822     switch (src_lo_rc) {
 1823     case rc_int:
 1824       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1825         if (is64) {
 1826             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1827                    as_Register(Matcher::_regEncode[src_lo]));
 1828         } else {
 1829             C2_MacroAssembler _masm(cbuf);
 1830             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1831                     as_Register(Matcher::_regEncode[src_lo]));
 1832         }
 1833       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1834         if (is64) {
 1835             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1836                      as_Register(Matcher::_regEncode[src_lo]));
 1837         } else {
 1838             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1839                      as_Register(Matcher::_regEncode[src_lo]));
 1840         }
 1841       } else {                    // gpr --&gt; stack spill
 1842         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1843         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1844       }
 1845       break;
 1846     case rc_float:
 1847       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1848         if (is64) {
 1849             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1850                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1851         } else {
 1852             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1853                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1854         }
 1855       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1856           if (cbuf) {
 1857             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1858                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1859         } else {
 1860             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1861                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1862         }
 1863       } else {                    // fpr --&gt; stack spill
 1864         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1865         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1866                  is64 ? __ D : __ S, dst_offset);
 1867       }
 1868       break;
 1869     case rc_stack:
 1870       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1871         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1872       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1873         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1874                    is64 ? __ D : __ S, src_offset);
 1875       } else {                    // stack --&gt; stack copy
 1876         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1877         __ unspill(rscratch1, is64, src_offset);
 1878         __ spill(rscratch1, is64, dst_offset);
 1879       }
 1880       break;
 1881     default:
 1882       assert(false, &quot;bad rc_class for spill&quot;);
 1883       ShouldNotReachHere();
 1884     }
 1885   }
 1886 
 1887   if (st) {
 1888     st-&gt;print(&quot;spill &quot;);
 1889     if (src_lo_rc == rc_stack) {
 1890       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1891     } else {
 1892       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1893     }
 1894     if (dst_lo_rc == rc_stack) {
 1895       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1896     } else {
 1897       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1898     }
 1899     if (bottom_type()-&gt;isa_vect() != NULL) {
 1900       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1901     } else {
 1902       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1903     }
 1904   }
 1905 
 1906   return 0;
 1907 
 1908 }
 1909 
 1910 #ifndef PRODUCT
 1911 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1912   if (!ra_)
 1913     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1914   else
 1915     implementation(NULL, ra_, false, st);
 1916 }
 1917 #endif
 1918 
 1919 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1920   implementation(&amp;cbuf, ra_, false, NULL);
 1921 }
 1922 
 1923 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1924   return MachNode::size(ra_);
 1925 }
 1926 
 1927 //=============================================================================
 1928 
 1929 #ifndef PRODUCT
 1930 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1931   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1932   int reg = ra_-&gt;get_reg_first(this);
 1933   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1934             Matcher::regName[reg], offset);
 1935 }
 1936 #endif
 1937 
 1938 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1939   C2_MacroAssembler _masm(&amp;cbuf);
 1940 
 1941   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1942   int reg    = ra_-&gt;get_encode(this);
 1943 
 1944   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1945     __ add(as_Register(reg), sp, offset);
 1946   } else {
 1947     ShouldNotReachHere();
 1948   }
 1949 }
 1950 
 1951 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1952   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1953   return 4;
 1954 }
 1955 
 1956 ///=============================================================================
 1957 #ifndef PRODUCT
 1958 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1959 {
 1960   st-&gt;print_cr(&quot;# MachVEPNode&quot;);
 1961   if (!_verified) {
 1962     st-&gt;print_cr(&quot;\t load_class&quot;);
 1963   } else {
 1964     st-&gt;print_cr(&quot;\t unpack_value_arg&quot;);
 1965   }
 1966 }
 1967 #endif
 1968 
 1969 void MachVEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1970 {
 1971   MacroAssembler _masm(&amp;cbuf);
 1972 
 1973   if (!_verified) {
 1974     Label skip;
 1975     __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 1976     __ br(Assembler::EQ, skip);
 1977       __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 1978     __ bind(skip);
 1979 
 1980   } else {
 1981     // Unpack value type args passed as oop and then jump to
 1982     // the verified entry point (skipping the unverified entry).
 1983     __ unpack_value_args(ra_-&gt;C, _receiver_only);
 1984     __ b(*_verified_entry);
 1985   }
 1986 }
 1987 
 1988 
 1989 uint MachVEPNode::size(PhaseRegAlloc* ra_) const
 1990 {
 1991   return MachNode::size(ra_); // too many variables; just compute it the hard way
 1992 }
 1993 
 1994 
 1995 //=============================================================================
 1996 #ifndef PRODUCT
 1997 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1998 {
 1999   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 2000   if (UseCompressedClassPointers) {
 2001     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2002     if (CompressedKlassPointers::shift() != 0) {
 2003       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 2004     }
 2005   } else {
 2006    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2007   }
 2008   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 2009   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2010 }
 2011 #endif
 2012 
 2013 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2014 {
 2015   // This is the unverified entry point.
 2016   C2_MacroAssembler _masm(&amp;cbuf);
 2017   Label skip;
 2018 
 2019   // UseCompressedClassPointers logic are inside cmp_klass
 2020   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2021 
 2022   // TODO
 2023   // can we avoid this skip and still use a reloc?
 2024   __ br(Assembler::EQ, skip);
 2025   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2026   __ bind(skip);
 2027 }
 2028 
 2029 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2030 {
 2031   return MachNode::size(ra_);
 2032 }
 2033 
 2034 // REQUIRED EMIT CODE
 2035 
 2036 //=============================================================================
 2037 
 2038 // Emit exception handler code.
 2039 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2040 {
 2041   // mov rscratch1 #exception_blob_entry_point
 2042   // br rscratch1
 2043   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2044   // That&#39;s why we must use the macroassembler to generate a handler.
 2045   C2_MacroAssembler _masm(&amp;cbuf);
 2046   address base = __ start_a_stub(size_exception_handler());
 2047   if (base == NULL) {
 2048     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2049     return 0;  // CodeBuffer::expand failed
 2050   }
 2051   int offset = __ offset();
 2052   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2053   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2054   __ end_a_stub();
 2055   return offset;
 2056 }
 2057 
 2058 // Emit deopt handler code.
 2059 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2060 {
 2061   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2062   // That&#39;s why we must use the macroassembler to generate a handler.
 2063   C2_MacroAssembler _masm(&amp;cbuf);
 2064   address base = __ start_a_stub(size_deopt_handler());
 2065   if (base == NULL) {
 2066     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2067     return 0;  // CodeBuffer::expand failed
 2068   }
 2069   int offset = __ offset();
 2070 
 2071   __ adr(lr, __ pc());
 2072   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2073 
 2074   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2075   __ end_a_stub();
 2076   return offset;
 2077 }
 2078 
 2079 // REQUIRED MATCHER CODE
 2080 
 2081 //=============================================================================
 2082 
 2083 const bool Matcher::match_rule_supported(int opcode) {
 2084   if (!has_match_rule(opcode))
 2085     return false;
 2086 
 2087   bool ret_value = true;
 2088   switch (opcode) {
 2089     case Op_CacheWB:
 2090     case Op_CacheWBPreSync:
 2091     case Op_CacheWBPostSync:
 2092       if (!VM_Version::supports_data_cache_line_flush()) {
 2093         ret_value = false;
 2094       }
 2095       break;
 2096   }
 2097 
 2098   return ret_value; // Per default match rules are supported.
 2099 }
 2100 
 2101 // Identify extra cases that we might want to provide match rules for vector nodes and
 2102 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2103 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2104   if (!match_rule_supported(opcode)) {
 2105     return false;
 2106   }
 2107 
 2108   // Special cases which require vector length
 2109   switch (opcode) {
 2110     case Op_MulAddVS2VI: {
 2111       if (vlen != 4) {
 2112         return false;
 2113       }
 2114       break;
 2115     }
 2116   }
 2117 
 2118   return true; // Per default match rules are supported.
 2119 }
 2120 
 2121 const bool Matcher::has_predicated_vectors(void) {
 2122   return false;
 2123 }
 2124 
 2125 const int Matcher::float_pressure(int default_pressure_threshold) {
 2126   return default_pressure_threshold;
 2127 }
 2128 
 2129 int Matcher::regnum_to_fpu_offset(int regnum)
 2130 {
 2131   Unimplemented();
 2132   return 0;
 2133 }
 2134 
 2135 // Is this branch offset short enough that a short branch can be used?
 2136 //
 2137 // NOTE: If the platform does not provide any short branch variants, then
 2138 //       this method should return false for offset 0.
 2139 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2140   // The passed offset is relative to address of the branch.
 2141 
 2142   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2143 }
 2144 
 2145 const bool Matcher::isSimpleConstant64(jlong value) {
 2146   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2147   // Probably always true, even if a temp register is required.
 2148   return true;
 2149 }
 2150 
 2151 // true just means we have fast l2f conversion
 2152 const bool Matcher::convL2FSupported(void) {
 2153   return true;
 2154 }
 2155 
 2156 // Vector width in bytes.
 2157 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2158   int size = MIN2(16,(int)MaxVectorSize);
 2159   // Minimum 2 values in vector
 2160   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2161   // But never &lt; 4
 2162   if (size &lt; 4) size = 0;
 2163   return size;
 2164 }
 2165 
 2166 // Limits on vector size (number of elements) loaded into vector.
 2167 const int Matcher::max_vector_size(const BasicType bt) {
 2168   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2169 }
 2170 const int Matcher::min_vector_size(const BasicType bt) {
 2171 //  For the moment limit the vector size to 8 bytes
 2172     int size = 8 / type2aelembytes(bt);
 2173     if (size &lt; 2) size = 2;
 2174     return size;
 2175 }
 2176 
 2177 // Vector ideal reg.
 2178 const uint Matcher::vector_ideal_reg(int len) {
 2179   switch(len) {
 2180     case  8: return Op_VecD;
 2181     case 16: return Op_VecX;
 2182   }
 2183   ShouldNotReachHere();
 2184   return 0;
 2185 }
 2186 
 2187 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 2188   switch(size) {
 2189     case  8: return Op_VecD;
 2190     case 16: return Op_VecX;
 2191   }
 2192   ShouldNotReachHere();
 2193   return 0;
 2194 }
 2195 
 2196 // AES support not yet implemented
 2197 const bool Matcher::pass_original_key_for_aes() {
 2198   return false;
 2199 }
 2200 
 2201 // aarch64 supports misaligned vectors store/load.
 2202 const bool Matcher::misaligned_vectors_ok() {
 2203   return true;
 2204 }
 2205 
 2206 // false =&gt; size gets scaled to BytesPerLong, ok.
 2207 const bool Matcher::init_array_count_is_in_bytes = false;
 2208 
 2209 // Use conditional move (CMOVL)
 2210 const int Matcher::long_cmove_cost() {
 2211   // long cmoves are no more expensive than int cmoves
 2212   return 0;
 2213 }
 2214 
 2215 const int Matcher::float_cmove_cost() {
 2216   // float cmoves are no more expensive than int cmoves
 2217   return 0;
 2218 }
 2219 
 2220 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2221 const bool Matcher::require_postalloc_expand = false;
 2222 
 2223 // Do we need to mask the count passed to shift instructions or does
 2224 // the cpu only look at the lower 5/6 bits anyway?
 2225 const bool Matcher::need_masked_shift_count = false;
 2226 
 2227 // No support for generic vector operands.
 2228 const bool Matcher::supports_generic_vector_operands  = false;
 2229 
 2230 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2231   ShouldNotReachHere(); // generic vector operands not supported
 2232   return NULL;
 2233 }
 2234 
 2235 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2236   ShouldNotReachHere();  // generic vector operands not supported
 2237   return false;
 2238 }
 2239 
 2240 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2241   ShouldNotReachHere();  // generic vector operands not supported
 2242   return false;
 2243 }
 2244 
 2245 // This affects two different things:
 2246 //  - how Decode nodes are matched
 2247 //  - how ImplicitNullCheck opportunities are recognized
 2248 // If true, the matcher will try to remove all Decodes and match them
 2249 // (as operands) into nodes. NullChecks are not prepared to deal with
 2250 // Decodes by final_graph_reshaping().
 2251 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2252 // for a NullCheck. The matcher matches the Decode node into a register.
 2253 // Implicit_null_check optimization moves the Decode along with the
 2254 // memory operation back up before the NullCheck.
 2255 bool Matcher::narrow_oop_use_complex_address() {
 2256   return CompressedOops::shift() == 0;
 2257 }
 2258 
 2259 bool Matcher::narrow_klass_use_complex_address() {
 2260 // TODO
 2261 // decide whether we need to set this to true
 2262   return false;
 2263 }
 2264 
 2265 bool Matcher::const_oop_prefer_decode() {
 2266   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2267   return CompressedOops::base() == NULL;
 2268 }
 2269 
 2270 bool Matcher::const_klass_prefer_decode() {
 2271   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2272   return CompressedKlassPointers::base() == NULL;
 2273 }
 2274 
 2275 // Is it better to copy float constants, or load them directly from
 2276 // memory?  Intel can load a float constant from a direct address,
 2277 // requiring no extra registers.  Most RISCs will have to materialize
 2278 // an address into a register first, so they would do better to copy
 2279 // the constant from stack.
 2280 const bool Matcher::rematerialize_float_constants = false;
 2281 
 2282 // If CPU can load and store mis-aligned doubles directly then no
 2283 // fixup is needed.  Else we split the double into 2 integer pieces
 2284 // and move it piece-by-piece.  Only happens when passing doubles into
 2285 // C code as the Java calling convention forces doubles to be aligned.
 2286 const bool Matcher::misaligned_doubles_ok = true;
 2287 
 2288 // No-op on amd64
 2289 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2290   Unimplemented();
 2291 }
 2292 
 2293 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2294 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2295 
 2296 // Are floats converted to double when stored to stack during
 2297 // deoptimization?
 2298 bool Matcher::float_in_double() { return false; }
 2299 
 2300 // Do ints take an entire long register or just half?
 2301 // The relevant question is how the int is callee-saved:
 2302 // the whole long is written but de-opt&#39;ing will have to extract
 2303 // the relevant 32 bits.
 2304 const bool Matcher::int_in_long = true;
 2305 
 2306 // Return whether or not this register is ever used as an argument.
 2307 // This function is used on startup to build the trampoline stubs in
 2308 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2309 // call in the trampoline, and arguments in those registers not be
 2310 // available to the callee.
 2311 bool Matcher::can_be_java_arg(int reg)
 2312 {
 2313   return
 2314     reg ==  R0_num || reg == R0_H_num ||
 2315     reg ==  R1_num || reg == R1_H_num ||
 2316     reg ==  R2_num || reg == R2_H_num ||
 2317     reg ==  R3_num || reg == R3_H_num ||
 2318     reg ==  R4_num || reg == R4_H_num ||
 2319     reg ==  R5_num || reg == R5_H_num ||
 2320     reg ==  R6_num || reg == R6_H_num ||
 2321     reg ==  R7_num || reg == R7_H_num ||
 2322     reg ==  V0_num || reg == V0_H_num ||
 2323     reg ==  V1_num || reg == V1_H_num ||
 2324     reg ==  V2_num || reg == V2_H_num ||
 2325     reg ==  V3_num || reg == V3_H_num ||
 2326     reg ==  V4_num || reg == V4_H_num ||
 2327     reg ==  V5_num || reg == V5_H_num ||
 2328     reg ==  V6_num || reg == V6_H_num ||
 2329     reg ==  V7_num || reg == V7_H_num;
 2330 }
 2331 
 2332 bool Matcher::is_spillable_arg(int reg)
 2333 {
 2334   return can_be_java_arg(reg);
 2335 }
 2336 
 2337 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2338   return false;
 2339 }
 2340 
 2341 RegMask Matcher::divI_proj_mask() {
 2342   ShouldNotReachHere();
 2343   return RegMask();
 2344 }
 2345 
 2346 // Register for MODI projection of divmodI.
 2347 RegMask Matcher::modI_proj_mask() {
 2348   ShouldNotReachHere();
 2349   return RegMask();
 2350 }
 2351 
 2352 // Register for DIVL projection of divmodL.
 2353 RegMask Matcher::divL_proj_mask() {
 2354   ShouldNotReachHere();
 2355   return RegMask();
 2356 }
 2357 
 2358 // Register for MODL projection of divmodL.
 2359 RegMask Matcher::modL_proj_mask() {
 2360   ShouldNotReachHere();
 2361   return RegMask();
 2362 }
 2363 
 2364 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2365   return FP_REG_mask();
 2366 }
 2367 
 2368 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2369   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2370     Node* u = addp-&gt;fast_out(i);
 2371     if (u-&gt;is_Mem()) {
 2372       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2373       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2374       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2375         return false;
 2376       }
 2377     }
 2378   }
 2379   return true;
 2380 }
 2381 
 2382 const bool Matcher::convi2l_type_required = false;
 2383 
 2384 // Should the Matcher clone shifts on addressing modes, expecting them
 2385 // to be subsumed into complex addressing expressions or compute them
 2386 // into registers?
 2387 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2388   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2389     return true;
 2390   }
 2391 
 2392   Node *off = m-&gt;in(AddPNode::Offset);
 2393   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2394       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2395       // Are there other uses besides address expressions?
 2396       !is_visited(off)) {
 2397     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2398     mstack.push(off-&gt;in(2), Visit);
 2399     Node *conv = off-&gt;in(1);
 2400     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2401         // Are there other uses besides address expressions?
 2402         !is_visited(conv)) {
 2403       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2404       mstack.push(conv-&gt;in(1), Pre_Visit);
 2405     } else {
 2406       mstack.push(conv, Pre_Visit);
 2407     }
 2408     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2409     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2410     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2411     return true;
 2412   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2413              // Are there other uses besides address expressions?
 2414              !is_visited(off)) {
 2415     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2416     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2417     mstack.push(off-&gt;in(1), Pre_Visit);
 2418     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2419     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2420     return true;
 2421   }
 2422   return false;
 2423 }
 2424 
 2425 void Compile::reshape_address(AddPNode* addp) {
 2426 }
 2427 
 2428 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2429   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2430   {                                                                     \
 2431     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2432     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2433     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2434     __ INSN(REG, as_Register(BASE));                                    \
 2435   }
 2436 
 2437 
 2438 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2439   {
 2440     Address::extend scale;
 2441 
 2442     // Hooboy, this is fugly.  We need a way to communicate to the
 2443     // encoder that the index needs to be sign extended, so we have to
 2444     // enumerate all the cases.
 2445     switch (opcode) {
 2446     case INDINDEXSCALEDI2L:
 2447     case INDINDEXSCALEDI2LN:
 2448     case INDINDEXI2L:
 2449     case INDINDEXI2LN:
 2450       scale = Address::sxtw(size);
 2451       break;
 2452     default:
 2453       scale = Address::lsl(size);
 2454     }
 2455 
 2456     if (index == -1) {
 2457       return Address(base, disp);
 2458     } else {
 2459       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2460       return Address(base, as_Register(index), scale);
 2461     }
 2462   }
 2463 
 2464 
 2465 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2466 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2467 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2468 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2469                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2470 
 2471   // Used for all non-volatile memory accesses.  The use of
 2472   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2473   // offsets is something of a kludge.
 2474   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2475                         Register reg, int opcode,
 2476                         Register base, int index, int scale, int disp,
 2477                         int size_in_memory)
 2478   {
 2479     Address addr = mem2address(opcode, base, index, scale, disp);
 2480     if (addr.getMode() == Address::base_plus_offset) {
 2481       /* If we get an out-of-range offset it is a bug in the compiler,
 2482          so we assert here. */
 2483       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2484              &quot;c2 compiler bug&quot;);
 2485       /* Fix up any out-of-range offsets. */
 2486       assert_different_registers(rscratch1, base);
 2487       assert_different_registers(rscratch1, reg);
 2488       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2489     }
 2490     (masm.*insn)(reg, addr);
 2491   }
 2492 
 2493   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2494                         FloatRegister reg, int opcode,
 2495                         Register base, int index, int size, int disp,
 2496                         int size_in_memory)
 2497   {
 2498     Address::extend scale;
 2499 
 2500     switch (opcode) {
 2501     case INDINDEXSCALEDI2L:
 2502     case INDINDEXSCALEDI2LN:
 2503       scale = Address::sxtw(size);
 2504       break;
 2505     default:
 2506       scale = Address::lsl(size);
 2507     }
 2508 
 2509     if (index == -1) {
 2510       /* If we get an out-of-range offset it is a bug in the compiler,
 2511          so we assert here. */
 2512       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2513       /* Fix up any out-of-range offsets. */
 2514       assert_different_registers(rscratch1, base);
 2515       Address addr = Address(base, disp);
 2516       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2517       (masm.*insn)(reg, addr);
 2518     } else {
 2519       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2520       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2521     }
 2522   }
 2523 
 2524   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2525                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2526                         int opcode, Register base, int index, int size, int disp)
 2527   {
 2528     if (index == -1) {
 2529       (masm.*insn)(reg, T, Address(base, disp));
 2530     } else {
 2531       assert(disp == 0, &quot;unsupported address mode&quot;);
 2532       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2533     }
 2534   }
 2535 
 2536 %}
 2537 
 2538 
 2539 
 2540 //----------ENCODING BLOCK-----------------------------------------------------
 2541 // This block specifies the encoding classes used by the compiler to
 2542 // output byte streams.  Encoding classes are parameterized macros
 2543 // used by Machine Instruction Nodes in order to generate the bit
 2544 // encoding of the instruction.  Operands specify their base encoding
 2545 // interface with the interface keyword.  There are currently
 2546 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2547 // COND_INTER.  REG_INTER causes an operand to generate a function
 2548 // which returns its register number when queried.  CONST_INTER causes
 2549 // an operand to generate a function which returns the value of the
 2550 // constant when queried.  MEMORY_INTER causes an operand to generate
 2551 // four functions which return the Base Register, the Index Register,
 2552 // the Scale Value, and the Offset Value of the operand when queried.
 2553 // COND_INTER causes an operand to generate six functions which return
 2554 // the encoding code (ie - encoding bits for the instruction)
 2555 // associated with each basic boolean condition for a conditional
 2556 // instruction.
 2557 //
 2558 // Instructions specify two basic values for encoding.  Again, a
 2559 // function is available to check if the constant displacement is an
 2560 // oop. They use the ins_encode keyword to specify their encoding
 2561 // classes (which must be a sequence of enc_class names, and their
 2562 // parameters, specified in the encoding block), and they use the
 2563 // opcode keyword to specify, in order, their primary, secondary, and
 2564 // tertiary opcode.  Only the opcode sections which a particular
 2565 // instruction needs for encoding need to be specified.
 2566 encode %{
 2567   // Build emit functions for each basic byte or larger field in the
 2568   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2569   // from C++ code in the enc_class source block.  Emit functions will
 2570   // live in the main source block for now.  In future, we can
 2571   // generalize this by adding a syntax that specifies the sizes of
 2572   // fields in an order, so that the adlc can build the emit functions
 2573   // automagically
 2574 
 2575   // catch all for unimplemented encodings
 2576   enc_class enc_unimplemented %{
 2577     C2_MacroAssembler _masm(&amp;cbuf);
 2578     __ unimplemented(&quot;C2 catch all&quot;);
 2579   %}
 2580 
 2581   // BEGIN Non-volatile memory access
 2582 
 2583   // This encoding class is generated automatically from ad_encode.m4.
 2584   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2585   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2586     Register dst_reg = as_Register($dst$$reg);
 2587     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2588                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2589   %}
 2590 
 2591   // This encoding class is generated automatically from ad_encode.m4.
 2592   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2593   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2594     Register dst_reg = as_Register($dst$$reg);
 2595     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2596                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2597   %}
 2598 
 2599   // This encoding class is generated automatically from ad_encode.m4.
 2600   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2601   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2602     Register dst_reg = as_Register($dst$$reg);
 2603     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2604                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2605   %}
 2606 
 2607   // This encoding class is generated automatically from ad_encode.m4.
 2608   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2609   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2610     Register dst_reg = as_Register($dst$$reg);
 2611     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2612                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2613   %}
 2614 
 2615   // This encoding class is generated automatically from ad_encode.m4.
 2616   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2617   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2618     Register dst_reg = as_Register($dst$$reg);
 2619     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2620                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2621   %}
 2622 
 2623   // This encoding class is generated automatically from ad_encode.m4.
 2624   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2625   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2626     Register dst_reg = as_Register($dst$$reg);
 2627     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2628                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2629   %}
 2630 
 2631   // This encoding class is generated automatically from ad_encode.m4.
 2632   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2633   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2634     Register dst_reg = as_Register($dst$$reg);
 2635     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2636                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2637   %}
 2638 
 2639   // This encoding class is generated automatically from ad_encode.m4.
 2640   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2641   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2642     Register dst_reg = as_Register($dst$$reg);
 2643     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2644                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2645   %}
 2646 
 2647   // This encoding class is generated automatically from ad_encode.m4.
 2648   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2649   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2650     Register dst_reg = as_Register($dst$$reg);
 2651     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2652                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2653   %}
 2654 
 2655   // This encoding class is generated automatically from ad_encode.m4.
 2656   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2657   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2658     Register dst_reg = as_Register($dst$$reg);
 2659     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2660                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2661   %}
 2662 
 2663   // This encoding class is generated automatically from ad_encode.m4.
 2664   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2665   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2666     Register dst_reg = as_Register($dst$$reg);
 2667     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2668                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2669   %}
 2670 
 2671   // This encoding class is generated automatically from ad_encode.m4.
 2672   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2673   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2674     Register dst_reg = as_Register($dst$$reg);
 2675     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2676                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2677   %}
 2678 
 2679   // This encoding class is generated automatically from ad_encode.m4.
 2680   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2681   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2682     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2683     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2684                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2685   %}
 2686 
 2687   // This encoding class is generated automatically from ad_encode.m4.
 2688   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2689   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2690     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2691     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2692                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2693   %}
 2694 
 2695   // This encoding class is generated automatically from ad_encode.m4.
 2696   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2697   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2698     Register src_reg = as_Register($src$$reg);
 2699     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2700                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2701   %}
 2702 
 2703   // This encoding class is generated automatically from ad_encode.m4.
 2704   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2705   enc_class aarch64_enc_strb0(memory1 mem) %{
 2706     C2_MacroAssembler _masm(&amp;cbuf);
 2707     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2708                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2709   %}
 2710 
 2711   // This encoding class is generated automatically from ad_encode.m4.
 2712   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2713   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2714     Register src_reg = as_Register($src$$reg);
 2715     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2716                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2717   %}
 2718 
 2719   // This encoding class is generated automatically from ad_encode.m4.
 2720   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2721   enc_class aarch64_enc_strh0(memory2 mem) %{
 2722     C2_MacroAssembler _masm(&amp;cbuf);
 2723     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2724                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2725   %}
 2726 
 2727   // This encoding class is generated automatically from ad_encode.m4.
 2728   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2729   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2730     Register src_reg = as_Register($src$$reg);
 2731     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2732                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2733   %}
 2734 
 2735   // This encoding class is generated automatically from ad_encode.m4.
 2736   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2737   enc_class aarch64_enc_strw0(memory4 mem) %{
 2738     C2_MacroAssembler _masm(&amp;cbuf);
 2739     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2740                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2741   %}
 2742 
 2743   // This encoding class is generated automatically from ad_encode.m4.
 2744   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2745   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2746     Register src_reg = as_Register($src$$reg);
 2747     // we sometimes get asked to store the stack pointer into the
 2748     // current thread -- we cannot do that directly on AArch64
 2749     if (src_reg == r31_sp) {
 2750       C2_MacroAssembler _masm(&amp;cbuf);
 2751       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2752       __ mov(rscratch2, sp);
 2753       src_reg = rscratch2;
 2754     }
 2755     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2756                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2757   %}
 2758 
 2759   // This encoding class is generated automatically from ad_encode.m4.
 2760   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2761   enc_class aarch64_enc_str0(memory8 mem) %{
 2762     C2_MacroAssembler _masm(&amp;cbuf);
 2763     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2764                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2765   %}
 2766 
 2767   // This encoding class is generated automatically from ad_encode.m4.
 2768   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2769   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2770     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2771     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2772                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2773   %}
 2774 
 2775   // This encoding class is generated automatically from ad_encode.m4.
 2776   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2777   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2778     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2779     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2780                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2781   %}
 2782 
 2783   // This encoding class is generated automatically from ad_encode.m4.
 2784   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2785   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2786     C2_MacroAssembler _masm(&amp;cbuf);
 2787     address con = (address)$src$$constant;
 2788     // need to do this the hard way until we can manage relocs
 2789     // for 32 bit constants
 2790     __ movoop(rscratch2, (jobject)con);
 2791     if (con) __ encode_heap_oop_not_null(rscratch2);
 2792     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2793                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2794   %}
 2795 
 2796   // This encoding class is generated automatically from ad_encode.m4.
 2797   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2798   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2799     C2_MacroAssembler _masm(&amp;cbuf);
 2800     address con = (address)$src$$constant;
 2801     // need to do this the hard way until we can manage relocs
 2802     // for 32 bit constants
 2803     __ movoop(rscratch2, (jobject)con);
 2804     __ encode_klass_not_null(rscratch2);
 2805     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2806                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2807   %}
 2808 
 2809   // This encoding class is generated automatically from ad_encode.m4.
 2810   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2811   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2812       C2_MacroAssembler _masm(&amp;cbuf);
 2813       __ membar(Assembler::StoreStore);
 2814       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2815                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2816   %}
 2817 
 2818   // END Non-volatile memory access
 2819 
 2820   // Vector loads and stores
 2821   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2822     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2823     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2824        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2825   %}
 2826 
 2827   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2828     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2829     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2830        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2831   %}
 2832 
 2833   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2834     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2835     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2836        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2837   %}
 2838 
 2839   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2840     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2841     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2842        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2843   %}
 2844 
 2845   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2846     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2847     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2848        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2849   %}
 2850 
 2851   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2852     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2853     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2854        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2855   %}
 2856 
 2857   // volatile loads and stores
 2858 
 2859   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2860     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2861                  rscratch1, stlrb);
 2862   %}
 2863 
 2864   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2865     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2866                  rscratch1, stlrh);
 2867   %}
 2868 
 2869   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2870     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2871                  rscratch1, stlrw);
 2872   %}
 2873 
 2874 
 2875   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2876     Register dst_reg = as_Register($dst$$reg);
 2877     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2878              rscratch1, ldarb);
 2879     __ sxtbw(dst_reg, dst_reg);
 2880   %}
 2881 
 2882   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2883     Register dst_reg = as_Register($dst$$reg);
 2884     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2885              rscratch1, ldarb);
 2886     __ sxtb(dst_reg, dst_reg);
 2887   %}
 2888 
 2889   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2890     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2891              rscratch1, ldarb);
 2892   %}
 2893 
 2894   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2895     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2896              rscratch1, ldarb);
 2897   %}
 2898 
 2899   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2900     Register dst_reg = as_Register($dst$$reg);
 2901     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2902              rscratch1, ldarh);
 2903     __ sxthw(dst_reg, dst_reg);
 2904   %}
 2905 
 2906   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2907     Register dst_reg = as_Register($dst$$reg);
 2908     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2909              rscratch1, ldarh);
 2910     __ sxth(dst_reg, dst_reg);
 2911   %}
 2912 
 2913   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2914     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2915              rscratch1, ldarh);
 2916   %}
 2917 
 2918   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2919     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2920              rscratch1, ldarh);
 2921   %}
 2922 
 2923   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2924     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2925              rscratch1, ldarw);
 2926   %}
 2927 
 2928   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2929     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930              rscratch1, ldarw);
 2931   %}
 2932 
 2933   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2934     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2935              rscratch1, ldar);
 2936   %}
 2937 
 2938   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2939     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2940              rscratch1, ldarw);
 2941     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2942   %}
 2943 
 2944   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2945     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2946              rscratch1, ldar);
 2947     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2948   %}
 2949 
 2950   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2951     Register src_reg = as_Register($src$$reg);
 2952     // we sometimes get asked to store the stack pointer into the
 2953     // current thread -- we cannot do that directly on AArch64
 2954     if (src_reg == r31_sp) {
 2955       C2_MacroAssembler _masm(&amp;cbuf);
 2956       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2957       __ mov(rscratch2, sp);
 2958       src_reg = rscratch2;
 2959     }
 2960     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2961                  rscratch1, stlr);
 2962   %}
 2963 
 2964   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2965     {
 2966       C2_MacroAssembler _masm(&amp;cbuf);
 2967       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2968       __ fmovs(rscratch2, src_reg);
 2969     }
 2970     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2971                  rscratch1, stlrw);
 2972   %}
 2973 
 2974   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2975     {
 2976       C2_MacroAssembler _masm(&amp;cbuf);
 2977       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2978       __ fmovd(rscratch2, src_reg);
 2979     }
 2980     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2981                  rscratch1, stlr);
 2982   %}
 2983 
 2984   // synchronized read/update encodings
 2985 
 2986   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2987     C2_MacroAssembler _masm(&amp;cbuf);
 2988     Register dst_reg = as_Register($dst$$reg);
 2989     Register base = as_Register($mem$$base);
 2990     int index = $mem$$index;
 2991     int scale = $mem$$scale;
 2992     int disp = $mem$$disp;
 2993     if (index == -1) {
 2994        if (disp != 0) {
 2995         __ lea(rscratch1, Address(base, disp));
 2996         __ ldaxr(dst_reg, rscratch1);
 2997       } else {
 2998         // TODO
 2999         // should we ever get anything other than this case?
 3000         __ ldaxr(dst_reg, base);
 3001       }
 3002     } else {
 3003       Register index_reg = as_Register(index);
 3004       if (disp == 0) {
 3005         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 3006         __ ldaxr(dst_reg, rscratch1);
 3007       } else {
 3008         __ lea(rscratch1, Address(base, disp));
 3009         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3010         __ ldaxr(dst_reg, rscratch1);
 3011       }
 3012     }
 3013   %}
 3014 
 3015   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3016     C2_MacroAssembler _masm(&amp;cbuf);
 3017     Register src_reg = as_Register($src$$reg);
 3018     Register base = as_Register($mem$$base);
 3019     int index = $mem$$index;
 3020     int scale = $mem$$scale;
 3021     int disp = $mem$$disp;
 3022     if (index == -1) {
 3023        if (disp != 0) {
 3024         __ lea(rscratch2, Address(base, disp));
 3025         __ stlxr(rscratch1, src_reg, rscratch2);
 3026       } else {
 3027         // TODO
 3028         // should we ever get anything other than this case?
 3029         __ stlxr(rscratch1, src_reg, base);
 3030       }
 3031     } else {
 3032       Register index_reg = as_Register(index);
 3033       if (disp == 0) {
 3034         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3035         __ stlxr(rscratch1, src_reg, rscratch2);
 3036       } else {
 3037         __ lea(rscratch2, Address(base, disp));
 3038         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3039         __ stlxr(rscratch1, src_reg, rscratch2);
 3040       }
 3041     }
 3042     __ cmpw(rscratch1, zr);
 3043   %}
 3044 
 3045   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3046     C2_MacroAssembler _masm(&amp;cbuf);
 3047     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3048     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3049                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3050                /*weak*/ false, noreg);
 3051   %}
 3052 
 3053   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3054     C2_MacroAssembler _masm(&amp;cbuf);
 3055     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3056     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3057                Assembler::word, /*acquire*/ false, /*release*/ true,
 3058                /*weak*/ false, noreg);
 3059   %}
 3060 
 3061   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3062     C2_MacroAssembler _masm(&amp;cbuf);
 3063     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3064     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3065                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3066                /*weak*/ false, noreg);
 3067   %}
 3068 
 3069   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3070     C2_MacroAssembler _masm(&amp;cbuf);
 3071     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3072     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3073                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3074                /*weak*/ false, noreg);
 3075   %}
 3076 
 3077 
 3078   // The only difference between aarch64_enc_cmpxchg and
 3079   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3080   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3081   // lock.
 3082   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3083     C2_MacroAssembler _masm(&amp;cbuf);
 3084     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3085     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3086                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3087                /*weak*/ false, noreg);
 3088   %}
 3089 
 3090   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3091     C2_MacroAssembler _masm(&amp;cbuf);
 3092     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3093     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3094                Assembler::word, /*acquire*/ true, /*release*/ true,
 3095                /*weak*/ false, noreg);
 3096   %}
 3097 
 3098   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3099     C2_MacroAssembler _masm(&amp;cbuf);
 3100     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3101     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3102                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3103                /*weak*/ false, noreg);
 3104   %}
 3105 
 3106   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3107     C2_MacroAssembler _masm(&amp;cbuf);
 3108     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3109     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3110                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3111                /*weak*/ false, noreg);
 3112   %}
 3113 
 3114   // auxiliary used for CompareAndSwapX to set result register
 3115   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3116     C2_MacroAssembler _masm(&amp;cbuf);
 3117     Register res_reg = as_Register($res$$reg);
 3118     __ cset(res_reg, Assembler::EQ);
 3119   %}
 3120 
 3121   // prefetch encodings
 3122 
 3123   enc_class aarch64_enc_prefetchw(memory mem) %{
 3124     C2_MacroAssembler _masm(&amp;cbuf);
 3125     Register base = as_Register($mem$$base);
 3126     int index = $mem$$index;
 3127     int scale = $mem$$scale;
 3128     int disp = $mem$$disp;
 3129     if (index == -1) {
 3130       __ prfm(Address(base, disp), PSTL1KEEP);
 3131     } else {
 3132       Register index_reg = as_Register(index);
 3133       if (disp == 0) {
 3134         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3135       } else {
 3136         __ lea(rscratch1, Address(base, disp));
 3137 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3138       }
 3139     }
 3140   %}
 3141 
 3142   /// mov envcodings
 3143 
 3144   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3145     C2_MacroAssembler _masm(&amp;cbuf);
 3146     u_int32_t con = (u_int32_t)$src$$constant;
 3147     Register dst_reg = as_Register($dst$$reg);
 3148     if (con == 0) {
 3149       __ movw(dst_reg, zr);
 3150     } else {
 3151       __ movw(dst_reg, con);
 3152     }
 3153   %}
 3154 
 3155   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3156     C2_MacroAssembler _masm(&amp;cbuf);
 3157     Register dst_reg = as_Register($dst$$reg);
 3158     u_int64_t con = (u_int64_t)$src$$constant;
 3159     if (con == 0) {
 3160       __ mov(dst_reg, zr);
 3161     } else {
 3162       __ mov(dst_reg, con);
 3163     }
 3164   %}
 3165 
 3166   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3167     C2_MacroAssembler _masm(&amp;cbuf);
 3168     Register dst_reg = as_Register($dst$$reg);
 3169     address con = (address)$src$$constant;
 3170     if (con == NULL || con == (address)1) {
 3171       ShouldNotReachHere();
 3172     } else {
 3173       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3174       if (rtype == relocInfo::oop_type) {
 3175         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3176       } else if (rtype == relocInfo::metadata_type) {
 3177         __ mov_metadata(dst_reg, (Metadata*)con);
 3178       } else {
 3179         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3180         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3181           __ mov(dst_reg, con);
 3182         } else {
 3183           unsigned long offset;
 3184           __ adrp(dst_reg, con, offset);
 3185           __ add(dst_reg, dst_reg, offset);
 3186         }
 3187       }
 3188     }
 3189   %}
 3190 
 3191   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3192     C2_MacroAssembler _masm(&amp;cbuf);
 3193     Register dst_reg = as_Register($dst$$reg);
 3194     __ mov(dst_reg, zr);
 3195   %}
 3196 
 3197   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3198     C2_MacroAssembler _masm(&amp;cbuf);
 3199     Register dst_reg = as_Register($dst$$reg);
 3200     __ mov(dst_reg, (u_int64_t)1);
 3201   %}
 3202 
 3203   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3204     C2_MacroAssembler _masm(&amp;cbuf);
 3205     __ load_byte_map_base($dst$$Register);
 3206   %}
 3207 
 3208   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3209     C2_MacroAssembler _masm(&amp;cbuf);
 3210     Register dst_reg = as_Register($dst$$reg);
 3211     address con = (address)$src$$constant;
 3212     if (con == NULL) {
 3213       ShouldNotReachHere();
 3214     } else {
 3215       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3216       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3217       __ set_narrow_oop(dst_reg, (jobject)con);
 3218     }
 3219   %}
 3220 
 3221   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3222     C2_MacroAssembler _masm(&amp;cbuf);
 3223     Register dst_reg = as_Register($dst$$reg);
 3224     __ mov(dst_reg, zr);
 3225   %}
 3226 
 3227   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3228     C2_MacroAssembler _masm(&amp;cbuf);
 3229     Register dst_reg = as_Register($dst$$reg);
 3230     address con = (address)$src$$constant;
 3231     if (con == NULL) {
 3232       ShouldNotReachHere();
 3233     } else {
 3234       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3235       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3236       __ set_narrow_klass(dst_reg, (Klass *)con);
 3237     }
 3238   %}
 3239 
 3240   // arithmetic encodings
 3241 
 3242   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3243     C2_MacroAssembler _masm(&amp;cbuf);
 3244     Register dst_reg = as_Register($dst$$reg);
 3245     Register src_reg = as_Register($src1$$reg);
 3246     int32_t con = (int32_t)$src2$$constant;
 3247     // add has primary == 0, subtract has primary == 1
 3248     if ($primary) { con = -con; }
 3249     if (con &lt; 0) {
 3250       __ subw(dst_reg, src_reg, -con);
 3251     } else {
 3252       __ addw(dst_reg, src_reg, con);
 3253     }
 3254   %}
 3255 
 3256   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3257     C2_MacroAssembler _masm(&amp;cbuf);
 3258     Register dst_reg = as_Register($dst$$reg);
 3259     Register src_reg = as_Register($src1$$reg);
 3260     int32_t con = (int32_t)$src2$$constant;
 3261     // add has primary == 0, subtract has primary == 1
 3262     if ($primary) { con = -con; }
 3263     if (con &lt; 0) {
 3264       __ sub(dst_reg, src_reg, -con);
 3265     } else {
 3266       __ add(dst_reg, src_reg, con);
 3267     }
 3268   %}
 3269 
 3270   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3271     C2_MacroAssembler _masm(&amp;cbuf);
 3272    Register dst_reg = as_Register($dst$$reg);
 3273    Register src1_reg = as_Register($src1$$reg);
 3274    Register src2_reg = as_Register($src2$$reg);
 3275     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3276   %}
 3277 
 3278   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3279     C2_MacroAssembler _masm(&amp;cbuf);
 3280    Register dst_reg = as_Register($dst$$reg);
 3281    Register src1_reg = as_Register($src1$$reg);
 3282    Register src2_reg = as_Register($src2$$reg);
 3283     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3284   %}
 3285 
 3286   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3287     C2_MacroAssembler _masm(&amp;cbuf);
 3288    Register dst_reg = as_Register($dst$$reg);
 3289    Register src1_reg = as_Register($src1$$reg);
 3290    Register src2_reg = as_Register($src2$$reg);
 3291     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3292   %}
 3293 
 3294   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3295     C2_MacroAssembler _masm(&amp;cbuf);
 3296    Register dst_reg = as_Register($dst$$reg);
 3297    Register src1_reg = as_Register($src1$$reg);
 3298    Register src2_reg = as_Register($src2$$reg);
 3299     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3300   %}
 3301 
 3302   // compare instruction encodings
 3303 
 3304   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3305     C2_MacroAssembler _masm(&amp;cbuf);
 3306     Register reg1 = as_Register($src1$$reg);
 3307     Register reg2 = as_Register($src2$$reg);
 3308     __ cmpw(reg1, reg2);
 3309   %}
 3310 
 3311   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3312     C2_MacroAssembler _masm(&amp;cbuf);
 3313     Register reg = as_Register($src1$$reg);
 3314     int32_t val = $src2$$constant;
 3315     if (val &gt;= 0) {
 3316       __ subsw(zr, reg, val);
 3317     } else {
 3318       __ addsw(zr, reg, -val);
 3319     }
 3320   %}
 3321 
 3322   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3323     C2_MacroAssembler _masm(&amp;cbuf);
 3324     Register reg1 = as_Register($src1$$reg);
 3325     u_int32_t val = (u_int32_t)$src2$$constant;
 3326     __ movw(rscratch1, val);
 3327     __ cmpw(reg1, rscratch1);
 3328   %}
 3329 
 3330   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3331     C2_MacroAssembler _masm(&amp;cbuf);
 3332     Register reg1 = as_Register($src1$$reg);
 3333     Register reg2 = as_Register($src2$$reg);
 3334     __ cmp(reg1, reg2);
 3335   %}
 3336 
 3337   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3338     C2_MacroAssembler _masm(&amp;cbuf);
 3339     Register reg = as_Register($src1$$reg);
 3340     int64_t val = $src2$$constant;
 3341     if (val &gt;= 0) {
 3342       __ subs(zr, reg, val);
 3343     } else if (val != -val) {
 3344       __ adds(zr, reg, -val);
 3345     } else {
 3346     // aargh, Long.MIN_VALUE is a special case
 3347       __ orr(rscratch1, zr, (u_int64_t)val);
 3348       __ subs(zr, reg, rscratch1);
 3349     }
 3350   %}
 3351 
 3352   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3353     C2_MacroAssembler _masm(&amp;cbuf);
 3354     Register reg1 = as_Register($src1$$reg);
 3355     u_int64_t val = (u_int64_t)$src2$$constant;
 3356     __ mov(rscratch1, val);
 3357     __ cmp(reg1, rscratch1);
 3358   %}
 3359 
 3360   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3361     C2_MacroAssembler _masm(&amp;cbuf);
 3362     Register reg1 = as_Register($src1$$reg);
 3363     Register reg2 = as_Register($src2$$reg);
 3364     __ cmp(reg1, reg2);
 3365   %}
 3366 
 3367   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3368     C2_MacroAssembler _masm(&amp;cbuf);
 3369     Register reg1 = as_Register($src1$$reg);
 3370     Register reg2 = as_Register($src2$$reg);
 3371     __ cmpw(reg1, reg2);
 3372   %}
 3373 
 3374   enc_class aarch64_enc_testp(iRegP src) %{
 3375     C2_MacroAssembler _masm(&amp;cbuf);
 3376     Register reg = as_Register($src$$reg);
 3377     __ cmp(reg, zr);
 3378   %}
 3379 
 3380   enc_class aarch64_enc_testn(iRegN src) %{
 3381     C2_MacroAssembler _masm(&amp;cbuf);
 3382     Register reg = as_Register($src$$reg);
 3383     __ cmpw(reg, zr);
 3384   %}
 3385 
 3386   enc_class aarch64_enc_b(label lbl) %{
 3387     C2_MacroAssembler _masm(&amp;cbuf);
 3388     Label *L = $lbl$$label;
 3389     __ b(*L);
 3390   %}
 3391 
 3392   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3393     C2_MacroAssembler _masm(&amp;cbuf);
 3394     Label *L = $lbl$$label;
 3395     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3396   %}
 3397 
 3398   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3399     C2_MacroAssembler _masm(&amp;cbuf);
 3400     Label *L = $lbl$$label;
 3401     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3402   %}
 3403 
 3404   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3405   %{
 3406      Register sub_reg = as_Register($sub$$reg);
 3407      Register super_reg = as_Register($super$$reg);
 3408      Register temp_reg = as_Register($temp$$reg);
 3409      Register result_reg = as_Register($result$$reg);
 3410 
 3411      Label miss;
 3412      C2_MacroAssembler _masm(&amp;cbuf);
 3413      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3414                                      NULL, &amp;miss,
 3415                                      /*set_cond_codes:*/ true);
 3416      if ($primary) {
 3417        __ mov(result_reg, zr);
 3418      }
 3419      __ bind(miss);
 3420   %}
 3421 
 3422   enc_class aarch64_enc_java_static_call(method meth) %{
 3423     C2_MacroAssembler _masm(&amp;cbuf);
 3424 
 3425     address addr = (address)$meth$$method;
 3426     address call;
 3427     if (!_method) {
 3428       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3429       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3430     } else {
 3431       int method_index = resolved_method_index(cbuf);
 3432       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3433                                                   : static_call_Relocation::spec(method_index);
 3434       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3435 
 3436       // Emit stub for static call
 3437       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3438       if (stub == NULL) {
 3439         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3440         return;
 3441       }
 3442     }
 3443     if (call == NULL) {
 3444       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3445       return;
 3446     }
 3447   %}
 3448 
 3449   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3450     C2_MacroAssembler _masm(&amp;cbuf);
 3451     int method_index = resolved_method_index(cbuf);
 3452     address call = __ ic_call((address)$meth$$method, method_index);
 3453     if (call == NULL) {
 3454       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3455       return;
 3456     }
 3457   %}
 3458 
 3459   enc_class aarch64_enc_call_epilog() %{
 3460     C2_MacroAssembler _masm(&amp;cbuf);
 3461     if (VerifyStackAtCalls) {
 3462       // Check that stack depth is unchanged: find majik cookie on stack
 3463       __ call_Unimplemented();
 3464     }
 3465   %}
 3466 
 3467   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3468     C2_MacroAssembler _masm(&amp;cbuf);
 3469 
 3470     // some calls to generated routines (arraycopy code) are scheduled
 3471     // by C2 as runtime calls. if so we can call them using a br (they
 3472     // will be in a reachable segment) otherwise we have to use a blr
 3473     // which loads the absolute address into a register.
 3474     address entry = (address)$meth$$method;
 3475     CodeBlob *cb = CodeCache::find_blob(entry);
 3476     if (cb) {
 3477       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3478       if (call == NULL) {
 3479         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3480         return;
 3481       }
 3482     } else {
 3483       Label retaddr;
 3484       __ adr(rscratch2, retaddr);
 3485       __ lea(rscratch1, RuntimeAddress(entry));
 3486       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3487       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3488       __ blr(rscratch1);
 3489       __ bind(retaddr);
 3490       __ add(sp, sp, 2 * wordSize);
 3491     }
 3492   %}
 3493 
 3494   enc_class aarch64_enc_rethrow() %{
 3495     C2_MacroAssembler _masm(&amp;cbuf);
 3496     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3497   %}
 3498 
 3499   enc_class aarch64_enc_ret() %{
 3500     C2_MacroAssembler _masm(&amp;cbuf);
 3501     __ ret(lr);
 3502   %}
 3503 
 3504   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3505     C2_MacroAssembler _masm(&amp;cbuf);
 3506     Register target_reg = as_Register($jump_target$$reg);
 3507     __ br(target_reg);
 3508   %}
 3509 
 3510   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3511     C2_MacroAssembler _masm(&amp;cbuf);
 3512     Register target_reg = as_Register($jump_target$$reg);
 3513     // exception oop should be in r0
 3514     // ret addr has been popped into lr
 3515     // callee expects it in r3
 3516     __ mov(r3, lr);
 3517     __ br(target_reg);
 3518   %}
 3519 
 3520   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3521     C2_MacroAssembler _masm(&amp;cbuf);
 3522     Register oop = as_Register($object$$reg);
 3523     Register box = as_Register($box$$reg);
 3524     Register disp_hdr = as_Register($tmp$$reg);
 3525     Register tmp = as_Register($tmp2$$reg);
 3526     Label cont;
 3527     Label object_has_monitor;
 3528     Label cas_failed;
 3529 
 3530     assert_different_registers(oop, box, tmp, disp_hdr);
 3531 
 3532     // Load markWord from object into displaced_header.
 3533     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3534 
 3535     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3536       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3537     }
 3538 
 3539     // Check for existing monitor
 3540     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3541 
 3542     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3543     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3544 
 3545     // Initialize the box. (Must happen before we update the object mark!)
 3546     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3547 
 3548     // Compare object markWord with an unlocked value (tmp) and if
 3549     // equal exchange the stack address of our box with object markWord.
 3550     // On failure disp_hdr contains the possibly locked markWord.
 3551     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3552                /*release*/ true, /*weak*/ false, disp_hdr);
 3553     __ br(Assembler::EQ, cont);
 3554 
 3555     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3556 
 3557     // If the compare-and-exchange succeeded, then we found an unlocked
 3558     // object, will have now locked it will continue at label cont
 3559 
 3560     __ bind(cas_failed);
 3561     // We did not see an unlocked object so try the fast recursive case.
 3562 
 3563     // Check if the owner is self by comparing the value in the
 3564     // markWord of object (disp_hdr) with the stack pointer.
 3565     __ mov(rscratch1, sp);
 3566     __ sub(disp_hdr, disp_hdr, rscratch1);
 3567     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3568     // If condition is true we are cont and hence we can store 0 as the
 3569     // displaced header in the box, which indicates that it is a recursive lock.
 3570     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3571     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3572 
 3573     __ b(cont);
 3574 
 3575     // Handle existing monitor.
 3576     __ bind(object_has_monitor);
 3577 
 3578     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3579     // otherwise m-&gt;owner may contain a thread or a stack address.
 3580     //
 3581     // Try to CAS m-&gt;owner from NULL to current thread.
 3582     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3583     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3584                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3585 
 3586     // Store a non-null value into the box to avoid looking like a re-entrant
 3587     // lock. The fast-path monitor unlock code checks for
 3588     // markWord::monitor_value so use markWord::unused_mark which has the
 3589     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3590     __ mov(tmp, (address)markWord::unused_mark().value());
 3591     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3592 
 3593     __ bind(cont);
 3594     // flag == EQ indicates success
 3595     // flag == NE indicates failure
 3596   %}
 3597 
 3598   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3599     C2_MacroAssembler _masm(&amp;cbuf);
 3600     Register oop = as_Register($object$$reg);
 3601     Register box = as_Register($box$$reg);
 3602     Register disp_hdr = as_Register($tmp$$reg);
 3603     Register tmp = as_Register($tmp2$$reg);
 3604     Label cont;
 3605     Label object_has_monitor;
 3606 
 3607     assert_different_registers(oop, box, tmp, disp_hdr);
 3608 
 3609     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3610       __ biased_locking_exit(oop, tmp, cont);
 3611     }
 3612 
 3613     // Find the lock address and load the displaced header from the stack.
 3614     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3615 
 3616     // If the displaced header is 0, we have a recursive unlock.
 3617     __ cmp(disp_hdr, zr);
 3618     __ br(Assembler::EQ, cont);
 3619 
 3620     // Handle existing monitor.
 3621     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3622     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3623 
 3624     // Check if it is still a light weight lock, this is is true if we
 3625     // see the stack address of the basicLock in the markWord of the
 3626     // object.
 3627 
 3628     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3629                /*release*/ true, /*weak*/ false, tmp);
 3630     __ b(cont);
 3631 
 3632     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3633 
 3634     // Handle existing monitor.
 3635     __ bind(object_has_monitor);
 3636     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3637     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3638     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3639     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3640     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3641     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3642     __ cmp(rscratch1, zr); // Sets flags for result
 3643     __ br(Assembler::NE, cont);
 3644 
 3645     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3646     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3647     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3648     __ cmp(rscratch1, zr); // Sets flags for result
 3649     __ cbnz(rscratch1, cont);
 3650     // need a release store here
 3651     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3652     __ stlr(zr, tmp); // set unowned
 3653 
 3654     __ bind(cont);
 3655     // flag == EQ indicates success
 3656     // flag == NE indicates failure
 3657   %}
 3658 
 3659 %}
 3660 
 3661 //----------FRAME--------------------------------------------------------------
 3662 // Definition of frame structure and management information.
 3663 //
 3664 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3665 //                             |   (to get allocators register number
 3666 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3667 //  r   CALLER     |        |
 3668 //  o     |        +--------+      pad to even-align allocators stack-slot
 3669 //  w     V        |  pad0  |        numbers; owned by CALLER
 3670 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3671 //  h     ^        |   in   |  5
 3672 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3673 //  |     |        |        |  3
 3674 //  |     |        +--------+
 3675 //  V     |        | old out|      Empty on Intel, window on Sparc
 3676 //        |    old |preserve|      Must be even aligned.
 3677 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3678 //        |        |   in   |  3   area for Intel ret address
 3679 //     Owned by    |preserve|      Empty on Sparc.
 3680 //       SELF      +--------+
 3681 //        |        |  pad2  |  2   pad to align old SP
 3682 //        |        +--------+  1
 3683 //        |        | locks  |  0
 3684 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3685 //        |        |  pad1  | 11   pad to align new SP
 3686 //        |        +--------+
 3687 //        |        |        | 10
 3688 //        |        | spills |  9   spills
 3689 //        V        |        |  8   (pad0 slot for callee)
 3690 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3691 //        ^        |  out   |  7
 3692 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3693 //     Owned by    +--------+
 3694 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3695 //        |    new |preserve|      Must be even-aligned.
 3696 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3697 //        |        |        |
 3698 //
 3699 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3700 //         known from SELF&#39;s arguments and the Java calling convention.
 3701 //         Region 6-7 is determined per call site.
 3702 // Note 2: If the calling convention leaves holes in the incoming argument
 3703 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3704 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3705 //         incoming area, as the Java calling convention is completely under
 3706 //         the control of the AD file.  Doubles can be sorted and packed to
 3707 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3708 //         varargs C calling conventions.
 3709 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3710 //         even aligned with pad0 as needed.
 3711 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3712 //           (the latter is true on Intel but is it false on AArch64?)
 3713 //         region 6-11 is even aligned; it may be padded out more so that
 3714 //         the region from SP to FP meets the minimum stack alignment.
 3715 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3716 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3717 //         SP meets the minimum alignment.
 3718 
 3719 frame %{
 3720   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3721   stack_direction(TOWARDS_LOW);
 3722 
 3723   // These three registers define part of the calling convention
 3724   // between compiled code and the interpreter.
 3725 
 3726   // Inline Cache Register or methodOop for I2C.
 3727   inline_cache_reg(R12);
 3728 
 3729   // Method Oop Register when calling interpreter.
 3730   interpreter_method_oop_reg(R12);
 3731 
 3732   // Number of stack slots consumed by locking an object
 3733   sync_stack_slots(2);
 3734 
 3735   // Compiled code&#39;s Frame Pointer
 3736   frame_pointer(R31);
 3737 
 3738   // Interpreter stores its frame pointer in a register which is
 3739   // stored to the stack by I2CAdaptors.
 3740   // I2CAdaptors convert from interpreted java to compiled java.
 3741   interpreter_frame_pointer(R29);
 3742 
 3743   // Stack alignment requirement
 3744   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3745 
 3746   // Number of stack slots between incoming argument block and the start of
 3747   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3748   // EPILOG must remove this many slots. aarch64 needs two slots for
 3749   // return address and fp.
 3750   // TODO think this is correct but check
 3751   in_preserve_stack_slots(4);
 3752 
 3753   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3754   // for calls to C.  Supports the var-args backing area for register parms.
 3755   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3756 
 3757   // The after-PROLOG location of the return address.  Location of
 3758   // return address specifies a type (REG or STACK) and a number
 3759   // representing the register number (i.e. - use a register name) or
 3760   // stack slot.
 3761   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3762   // Otherwise, it is above the locks and verification slot and alignment word
 3763   // TODO this may well be correct but need to check why that - 2 is there
 3764   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3765   // which folds in the space used for monitors
 3766   return_addr(STACK - 2 +
 3767               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3768                         Compile::current()-&gt;fixed_slots()),
 3769                        stack_alignment_in_slots()));
 3770 
 3771   // Body of function which returns an integer array locating
 3772   // arguments either in registers or in stack slots.  Passed an array
 3773   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3774   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3775   // arguments for a CALLEE.  Incoming stack arguments are
 3776   // automatically biased by the preserve_stack_slots field above.
 3777 
 3778   calling_convention
 3779   %{
 3780     // No difference between ingoing/outgoing just pass false
 3781     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3782   %}
 3783 
 3784   c_calling_convention
 3785   %{
 3786     // This is obviously always outgoing
 3787     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3788   %}
 3789 
 3790   // Location of compiled Java return values.  Same as C for now.
 3791   return_value
 3792   %{
 3793     // TODO do we allow ideal_reg == Op_RegN???
 3794     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3795            &quot;only return normal values&quot;);
 3796 
 3797     static const int lo[Op_RegL + 1] = { // enum name
 3798       0,                                 // Op_Node
 3799       0,                                 // Op_Set
 3800       R0_num,                            // Op_RegN
 3801       R0_num,                            // Op_RegI
 3802       R0_num,                            // Op_RegP
 3803       V0_num,                            // Op_RegF
 3804       V0_num,                            // Op_RegD
 3805       R0_num                             // Op_RegL
 3806     };
 3807 
 3808     static const int hi[Op_RegL + 1] = { // enum name
 3809       0,                                 // Op_Node
 3810       0,                                 // Op_Set
 3811       OptoReg::Bad,                      // Op_RegN
 3812       OptoReg::Bad,                      // Op_RegI
 3813       R0_H_num,                          // Op_RegP
 3814       OptoReg::Bad,                      // Op_RegF
 3815       V0_H_num,                          // Op_RegD
 3816       R0_H_num                           // Op_RegL
 3817     };
 3818 
 3819     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3820   %}
 3821 %}
 3822 
 3823 //----------ATTRIBUTES---------------------------------------------------------
 3824 //----------Operand Attributes-------------------------------------------------
 3825 op_attrib op_cost(1);        // Required cost attribute
 3826 
 3827 //----------Instruction Attributes---------------------------------------------
 3828 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3829 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3830 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3831                                 // a non-matching short branch variant
 3832                                 // of some long branch?
 3833 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3834                                 // be a power of 2) specifies the
 3835                                 // alignment that some part of the
 3836                                 // instruction (not necessarily the
 3837                                 // start) requires.  If &gt; 1, a
 3838                                 // compute_padding() function must be
 3839                                 // provided for the instruction
 3840 
 3841 //----------OPERANDS-----------------------------------------------------------
 3842 // Operand definitions must precede instruction definitions for correct parsing
 3843 // in the ADLC because operands constitute user defined types which are used in
 3844 // instruction definitions.
 3845 
 3846 //----------Simple Operands----------------------------------------------------
 3847 
 3848 // Integer operands 32 bit
 3849 // 32 bit immediate
 3850 operand immI()
 3851 %{
 3852   match(ConI);
 3853 
 3854   op_cost(0);
 3855   format %{ %}
 3856   interface(CONST_INTER);
 3857 %}
 3858 
 3859 // 32 bit zero
 3860 operand immI0()
 3861 %{
 3862   predicate(n-&gt;get_int() == 0);
 3863   match(ConI);
 3864 
 3865   op_cost(0);
 3866   format %{ %}
 3867   interface(CONST_INTER);
 3868 %}
 3869 
 3870 // 32 bit unit increment
 3871 operand immI_1()
 3872 %{
 3873   predicate(n-&gt;get_int() == 1);
 3874   match(ConI);
 3875 
 3876   op_cost(0);
 3877   format %{ %}
 3878   interface(CONST_INTER);
 3879 %}
 3880 
 3881 // 32 bit unit decrement
 3882 operand immI_M1()
 3883 %{
 3884   predicate(n-&gt;get_int() == -1);
 3885   match(ConI);
 3886 
 3887   op_cost(0);
 3888   format %{ %}
 3889   interface(CONST_INTER);
 3890 %}
 3891 
 3892 // Shift values for add/sub extension shift
 3893 operand immIExt()
 3894 %{
 3895   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3896   match(ConI);
 3897 
 3898   op_cost(0);
 3899   format %{ %}
 3900   interface(CONST_INTER);
 3901 %}
 3902 
 3903 operand immI_le_4()
 3904 %{
 3905   predicate(n-&gt;get_int() &lt;= 4);
 3906   match(ConI);
 3907 
 3908   op_cost(0);
 3909   format %{ %}
 3910   interface(CONST_INTER);
 3911 %}
 3912 
 3913 operand immI_31()
 3914 %{
 3915   predicate(n-&gt;get_int() == 31);
 3916   match(ConI);
 3917 
 3918   op_cost(0);
 3919   format %{ %}
 3920   interface(CONST_INTER);
 3921 %}
 3922 
 3923 operand immI_8()
 3924 %{
 3925   predicate(n-&gt;get_int() == 8);
 3926   match(ConI);
 3927 
 3928   op_cost(0);
 3929   format %{ %}
 3930   interface(CONST_INTER);
 3931 %}
 3932 
 3933 operand immI_16()
 3934 %{
 3935   predicate(n-&gt;get_int() == 16);
 3936   match(ConI);
 3937 
 3938   op_cost(0);
 3939   format %{ %}
 3940   interface(CONST_INTER);
 3941 %}
 3942 
 3943 operand immI_24()
 3944 %{
 3945   predicate(n-&gt;get_int() == 24);
 3946   match(ConI);
 3947 
 3948   op_cost(0);
 3949   format %{ %}
 3950   interface(CONST_INTER);
 3951 %}
 3952 
 3953 operand immI_32()
 3954 %{
 3955   predicate(n-&gt;get_int() == 32);
 3956   match(ConI);
 3957 
 3958   op_cost(0);
 3959   format %{ %}
 3960   interface(CONST_INTER);
 3961 %}
 3962 
 3963 operand immI_48()
 3964 %{
 3965   predicate(n-&gt;get_int() == 48);
 3966   match(ConI);
 3967 
 3968   op_cost(0);
 3969   format %{ %}
 3970   interface(CONST_INTER);
 3971 %}
 3972 
 3973 operand immI_56()
 3974 %{
 3975   predicate(n-&gt;get_int() == 56);
 3976   match(ConI);
 3977 
 3978   op_cost(0);
 3979   format %{ %}
 3980   interface(CONST_INTER);
 3981 %}
 3982 
 3983 operand immI_63()
 3984 %{
 3985   predicate(n-&gt;get_int() == 63);
 3986   match(ConI);
 3987 
 3988   op_cost(0);
 3989   format %{ %}
 3990   interface(CONST_INTER);
 3991 %}
 3992 
 3993 operand immI_64()
 3994 %{
 3995   predicate(n-&gt;get_int() == 64);
 3996   match(ConI);
 3997 
 3998   op_cost(0);
 3999   format %{ %}
 4000   interface(CONST_INTER);
 4001 %}
 4002 
 4003 operand immI_255()
 4004 %{
 4005   predicate(n-&gt;get_int() == 255);
 4006   match(ConI);
 4007 
 4008   op_cost(0);
 4009   format %{ %}
 4010   interface(CONST_INTER);
 4011 %}
 4012 
 4013 operand immI_65535()
 4014 %{
 4015   predicate(n-&gt;get_int() == 65535);
 4016   match(ConI);
 4017 
 4018   op_cost(0);
 4019   format %{ %}
 4020   interface(CONST_INTER);
 4021 %}
 4022 
 4023 operand immL_255()
 4024 %{
 4025   predicate(n-&gt;get_long() == 255L);
 4026   match(ConL);
 4027 
 4028   op_cost(0);
 4029   format %{ %}
 4030   interface(CONST_INTER);
 4031 %}
 4032 
 4033 operand immL_65535()
 4034 %{
 4035   predicate(n-&gt;get_long() == 65535L);
 4036   match(ConL);
 4037 
 4038   op_cost(0);
 4039   format %{ %}
 4040   interface(CONST_INTER);
 4041 %}
 4042 
 4043 operand immL_4294967295()
 4044 %{
 4045   predicate(n-&gt;get_long() == 4294967295L);
 4046   match(ConL);
 4047 
 4048   op_cost(0);
 4049   format %{ %}
 4050   interface(CONST_INTER);
 4051 %}
 4052 
 4053 operand immL_bitmask()
 4054 %{
 4055   predicate((n-&gt;get_long() != 0)
 4056             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4057             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4058   match(ConL);
 4059 
 4060   op_cost(0);
 4061   format %{ %}
 4062   interface(CONST_INTER);
 4063 %}
 4064 
 4065 operand immI_bitmask()
 4066 %{
 4067   predicate((n-&gt;get_int() != 0)
 4068             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4069             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4070   match(ConI);
 4071 
 4072   op_cost(0);
 4073   format %{ %}
 4074   interface(CONST_INTER);
 4075 %}
 4076 
 4077 // Scale values for scaled offset addressing modes (up to long but not quad)
 4078 operand immIScale()
 4079 %{
 4080   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4081   match(ConI);
 4082 
 4083   op_cost(0);
 4084   format %{ %}
 4085   interface(CONST_INTER);
 4086 %}
 4087 
 4088 // 26 bit signed offset -- for pc-relative branches
 4089 operand immI26()
 4090 %{
 4091   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4092   match(ConI);
 4093 
 4094   op_cost(0);
 4095   format %{ %}
 4096   interface(CONST_INTER);
 4097 %}
 4098 
 4099 // 19 bit signed offset -- for pc-relative loads
 4100 operand immI19()
 4101 %{
 4102   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4103   match(ConI);
 4104 
 4105   op_cost(0);
 4106   format %{ %}
 4107   interface(CONST_INTER);
 4108 %}
 4109 
 4110 // 12 bit unsigned offset -- for base plus immediate loads
 4111 operand immIU12()
 4112 %{
 4113   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4114   match(ConI);
 4115 
 4116   op_cost(0);
 4117   format %{ %}
 4118   interface(CONST_INTER);
 4119 %}
 4120 
 4121 operand immLU12()
 4122 %{
 4123   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4124   match(ConL);
 4125 
 4126   op_cost(0);
 4127   format %{ %}
 4128   interface(CONST_INTER);
 4129 %}
 4130 
 4131 // Offset for scaled or unscaled immediate loads and stores
 4132 operand immIOffset()
 4133 %{
 4134   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4135   match(ConI);
 4136 
 4137   op_cost(0);
 4138   format %{ %}
 4139   interface(CONST_INTER);
 4140 %}
 4141 
 4142 operand immIOffset1()
 4143 %{
 4144   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4145   match(ConI);
 4146 
 4147   op_cost(0);
 4148   format %{ %}
 4149   interface(CONST_INTER);
 4150 %}
 4151 
 4152 operand immIOffset2()
 4153 %{
 4154   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4155   match(ConI);
 4156 
 4157   op_cost(0);
 4158   format %{ %}
 4159   interface(CONST_INTER);
 4160 %}
 4161 
 4162 operand immIOffset4()
 4163 %{
 4164   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4165   match(ConI);
 4166 
 4167   op_cost(0);
 4168   format %{ %}
 4169   interface(CONST_INTER);
 4170 %}
 4171 
 4172 operand immIOffset8()
 4173 %{
 4174   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4175   match(ConI);
 4176 
 4177   op_cost(0);
 4178   format %{ %}
 4179   interface(CONST_INTER);
 4180 %}
 4181 
 4182 operand immIOffset16()
 4183 %{
 4184   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4185   match(ConI);
 4186 
 4187   op_cost(0);
 4188   format %{ %}
 4189   interface(CONST_INTER);
 4190 %}
 4191 
 4192 operand immLoffset()
 4193 %{
 4194   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4195   match(ConL);
 4196 
 4197   op_cost(0);
 4198   format %{ %}
 4199   interface(CONST_INTER);
 4200 %}
 4201 
 4202 operand immLoffset1()
 4203 %{
 4204   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4205   match(ConL);
 4206 
 4207   op_cost(0);
 4208   format %{ %}
 4209   interface(CONST_INTER);
 4210 %}
 4211 
 4212 operand immLoffset2()
 4213 %{
 4214   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4215   match(ConL);
 4216 
 4217   op_cost(0);
 4218   format %{ %}
 4219   interface(CONST_INTER);
 4220 %}
 4221 
 4222 operand immLoffset4()
 4223 %{
 4224   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4225   match(ConL);
 4226 
 4227   op_cost(0);
 4228   format %{ %}
 4229   interface(CONST_INTER);
 4230 %}
 4231 
 4232 operand immLoffset8()
 4233 %{
 4234   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4235   match(ConL);
 4236 
 4237   op_cost(0);
 4238   format %{ %}
 4239   interface(CONST_INTER);
 4240 %}
 4241 
 4242 operand immLoffset16()
 4243 %{
 4244   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4245   match(ConL);
 4246 
 4247   op_cost(0);
 4248   format %{ %}
 4249   interface(CONST_INTER);
 4250 %}
 4251 
 4252 // 32 bit integer valid for add sub immediate
 4253 operand immIAddSub()
 4254 %{
 4255   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4256   match(ConI);
 4257   op_cost(0);
 4258   format %{ %}
 4259   interface(CONST_INTER);
 4260 %}
 4261 
 4262 // 32 bit unsigned integer valid for logical immediate
 4263 // TODO -- check this is right when e.g the mask is 0x80000000
 4264 operand immILog()
 4265 %{
 4266   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4267   match(ConI);
 4268 
 4269   op_cost(0);
 4270   format %{ %}
 4271   interface(CONST_INTER);
 4272 %}
 4273 
 4274 // Integer operands 64 bit
 4275 // 64 bit immediate
 4276 operand immL()
 4277 %{
 4278   match(ConL);
 4279 
 4280   op_cost(0);
 4281   format %{ %}
 4282   interface(CONST_INTER);
 4283 %}
 4284 
 4285 // 64 bit zero
 4286 operand immL0()
 4287 %{
 4288   predicate(n-&gt;get_long() == 0);
 4289   match(ConL);
 4290 
 4291   op_cost(0);
 4292   format %{ %}
 4293   interface(CONST_INTER);
 4294 %}
 4295 
 4296 // 64 bit unit increment
 4297 operand immL_1()
 4298 %{
 4299   predicate(n-&gt;get_long() == 1);
 4300   match(ConL);
 4301 
 4302   op_cost(0);
 4303   format %{ %}
 4304   interface(CONST_INTER);
 4305 %}
 4306 
 4307 // 64 bit unit decrement
 4308 operand immL_M1()
 4309 %{
 4310   predicate(n-&gt;get_long() == -1);
 4311   match(ConL);
 4312 
 4313   op_cost(0);
 4314   format %{ %}
 4315   interface(CONST_INTER);
 4316 %}
 4317 
 4318 // 32 bit offset of pc in thread anchor
 4319 
 4320 operand immL_pc_off()
 4321 %{
 4322   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4323                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4324   match(ConL);
 4325 
 4326   op_cost(0);
 4327   format %{ %}
 4328   interface(CONST_INTER);
 4329 %}
 4330 
 4331 // 64 bit integer valid for add sub immediate
 4332 operand immLAddSub()
 4333 %{
 4334   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4335   match(ConL);
 4336   op_cost(0);
 4337   format %{ %}
 4338   interface(CONST_INTER);
 4339 %}
 4340 
 4341 // 64 bit integer valid for logical immediate
 4342 operand immLLog()
 4343 %{
 4344   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4345   match(ConL);
 4346   op_cost(0);
 4347   format %{ %}
 4348   interface(CONST_INTER);
 4349 %}
 4350 
 4351 // Long Immediate: low 32-bit mask
 4352 operand immL_32bits()
 4353 %{
 4354   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4355   match(ConL);
 4356   op_cost(0);
 4357   format %{ %}
 4358   interface(CONST_INTER);
 4359 %}
 4360 
 4361 // Pointer operands
 4362 // Pointer Immediate
 4363 operand immP()
 4364 %{
 4365   match(ConP);
 4366 
 4367   op_cost(0);
 4368   format %{ %}
 4369   interface(CONST_INTER);
 4370 %}
 4371 
 4372 // NULL Pointer Immediate
 4373 operand immP0()
 4374 %{
 4375   predicate(n-&gt;get_ptr() == 0);
 4376   match(ConP);
 4377 
 4378   op_cost(0);
 4379   format %{ %}
 4380   interface(CONST_INTER);
 4381 %}
 4382 
 4383 // Pointer Immediate One
 4384 // this is used in object initialization (initial object header)
 4385 operand immP_1()
 4386 %{
 4387   predicate(n-&gt;get_ptr() == 1);
 4388   match(ConP);
 4389 
 4390   op_cost(0);
 4391   format %{ %}
 4392   interface(CONST_INTER);
 4393 %}
 4394 
 4395 // Card Table Byte Map Base
 4396 operand immByteMapBase()
 4397 %{
 4398   // Get base of card map
 4399   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4400             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4401   match(ConP);
 4402 
 4403   op_cost(0);
 4404   format %{ %}
 4405   interface(CONST_INTER);
 4406 %}
 4407 
 4408 // Pointer Immediate Minus One
 4409 // this is used when we want to write the current PC to the thread anchor
 4410 operand immP_M1()
 4411 %{
 4412   predicate(n-&gt;get_ptr() == -1);
 4413   match(ConP);
 4414 
 4415   op_cost(0);
 4416   format %{ %}
 4417   interface(CONST_INTER);
 4418 %}
 4419 
 4420 // Pointer Immediate Minus Two
 4421 // this is used when we want to write the current PC to the thread anchor
 4422 operand immP_M2()
 4423 %{
 4424   predicate(n-&gt;get_ptr() == -2);
 4425   match(ConP);
 4426 
 4427   op_cost(0);
 4428   format %{ %}
 4429   interface(CONST_INTER);
 4430 %}
 4431 
 4432 // Float and Double operands
 4433 // Double Immediate
 4434 operand immD()
 4435 %{
 4436   match(ConD);
 4437   op_cost(0);
 4438   format %{ %}
 4439   interface(CONST_INTER);
 4440 %}
 4441 
 4442 // Double Immediate: +0.0d
 4443 operand immD0()
 4444 %{
 4445   predicate(jlong_cast(n-&gt;getd()) == 0);
 4446   match(ConD);
 4447 
 4448   op_cost(0);
 4449   format %{ %}
 4450   interface(CONST_INTER);
 4451 %}
 4452 
 4453 // constant &#39;double +0.0&#39;.
 4454 operand immDPacked()
 4455 %{
 4456   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4457   match(ConD);
 4458   op_cost(0);
 4459   format %{ %}
 4460   interface(CONST_INTER);
 4461 %}
 4462 
 4463 // Float Immediate
 4464 operand immF()
 4465 %{
 4466   match(ConF);
 4467   op_cost(0);
 4468   format %{ %}
 4469   interface(CONST_INTER);
 4470 %}
 4471 
 4472 // Float Immediate: +0.0f.
 4473 operand immF0()
 4474 %{
 4475   predicate(jint_cast(n-&gt;getf()) == 0);
 4476   match(ConF);
 4477 
 4478   op_cost(0);
 4479   format %{ %}
 4480   interface(CONST_INTER);
 4481 %}
 4482 
 4483 //
 4484 operand immFPacked()
 4485 %{
 4486   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4487   match(ConF);
 4488   op_cost(0);
 4489   format %{ %}
 4490   interface(CONST_INTER);
 4491 %}
 4492 
 4493 // Narrow pointer operands
 4494 // Narrow Pointer Immediate
 4495 operand immN()
 4496 %{
 4497   match(ConN);
 4498 
 4499   op_cost(0);
 4500   format %{ %}
 4501   interface(CONST_INTER);
 4502 %}
 4503 
 4504 // Narrow NULL Pointer Immediate
 4505 operand immN0()
 4506 %{
 4507   predicate(n-&gt;get_narrowcon() == 0);
 4508   match(ConN);
 4509 
 4510   op_cost(0);
 4511   format %{ %}
 4512   interface(CONST_INTER);
 4513 %}
 4514 
 4515 operand immNKlass()
 4516 %{
 4517   match(ConNKlass);
 4518 
 4519   op_cost(0);
 4520   format %{ %}
 4521   interface(CONST_INTER);
 4522 %}
 4523 
 4524 // Integer 32 bit Register Operands
 4525 // Integer 32 bitRegister (excludes SP)
 4526 operand iRegI()
 4527 %{
 4528   constraint(ALLOC_IN_RC(any_reg32));
 4529   match(RegI);
 4530   match(iRegINoSp);
 4531   op_cost(0);
 4532   format %{ %}
 4533   interface(REG_INTER);
 4534 %}
 4535 
 4536 // Integer 32 bit Register not Special
 4537 operand iRegINoSp()
 4538 %{
 4539   constraint(ALLOC_IN_RC(no_special_reg32));
 4540   match(RegI);
 4541   op_cost(0);
 4542   format %{ %}
 4543   interface(REG_INTER);
 4544 %}
 4545 
 4546 // Integer 64 bit Register Operands
 4547 // Integer 64 bit Register (includes SP)
 4548 operand iRegL()
 4549 %{
 4550   constraint(ALLOC_IN_RC(any_reg));
 4551   match(RegL);
 4552   match(iRegLNoSp);
 4553   op_cost(0);
 4554   format %{ %}
 4555   interface(REG_INTER);
 4556 %}
 4557 
 4558 // Integer 64 bit Register not Special
 4559 operand iRegLNoSp()
 4560 %{
 4561   constraint(ALLOC_IN_RC(no_special_reg));
 4562   match(RegL);
 4563   match(iRegL_R0);
 4564   format %{ %}
 4565   interface(REG_INTER);
 4566 %}
 4567 
 4568 // Pointer Register Operands
 4569 // Pointer Register
 4570 operand iRegP()
 4571 %{
 4572   constraint(ALLOC_IN_RC(ptr_reg));
 4573   match(RegP);
 4574   match(iRegPNoSp);
 4575   match(iRegP_R0);
 4576   //match(iRegP_R2);
 4577   //match(iRegP_R4);
 4578   //match(iRegP_R5);
 4579   match(thread_RegP);
 4580   op_cost(0);
 4581   format %{ %}
 4582   interface(REG_INTER);
 4583 %}
 4584 
 4585 // Pointer 64 bit Register not Special
 4586 operand iRegPNoSp()
 4587 %{
 4588   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4589   match(RegP);
 4590   // match(iRegP);
 4591   // match(iRegP_R0);
 4592   // match(iRegP_R2);
 4593   // match(iRegP_R4);
 4594   // match(iRegP_R5);
 4595   // match(thread_RegP);
 4596   op_cost(0);
 4597   format %{ %}
 4598   interface(REG_INTER);
 4599 %}
 4600 
 4601 // Pointer 64 bit Register R0 only
 4602 operand iRegP_R0()
 4603 %{
 4604   constraint(ALLOC_IN_RC(r0_reg));
 4605   match(RegP);
 4606   // match(iRegP);
 4607   match(iRegPNoSp);
 4608   op_cost(0);
 4609   format %{ %}
 4610   interface(REG_INTER);
 4611 %}
 4612 
 4613 // Pointer 64 bit Register R1 only
 4614 operand iRegP_R1()
 4615 %{
 4616   constraint(ALLOC_IN_RC(r1_reg));
 4617   match(RegP);
 4618   // match(iRegP);
 4619   match(iRegPNoSp);
 4620   op_cost(0);
 4621   format %{ %}
 4622   interface(REG_INTER);
 4623 %}
 4624 
 4625 // Pointer 64 bit Register R2 only
 4626 operand iRegP_R2()
 4627 %{
 4628   constraint(ALLOC_IN_RC(r2_reg));
 4629   match(RegP);
 4630   // match(iRegP);
 4631   match(iRegPNoSp);
 4632   op_cost(0);
 4633   format %{ %}
 4634   interface(REG_INTER);
 4635 %}
 4636 
 4637 // Pointer 64 bit Register R3 only
 4638 operand iRegP_R3()
 4639 %{
 4640   constraint(ALLOC_IN_RC(r3_reg));
 4641   match(RegP);
 4642   // match(iRegP);
 4643   match(iRegPNoSp);
 4644   op_cost(0);
 4645   format %{ %}
 4646   interface(REG_INTER);
 4647 %}
 4648 
 4649 // Pointer 64 bit Register R4 only
 4650 operand iRegP_R4()
 4651 %{
 4652   constraint(ALLOC_IN_RC(r4_reg));
 4653   match(RegP);
 4654   // match(iRegP);
 4655   match(iRegPNoSp);
 4656   op_cost(0);
 4657   format %{ %}
 4658   interface(REG_INTER);
 4659 %}
 4660 
 4661 // Pointer 64 bit Register R5 only
 4662 operand iRegP_R5()
 4663 %{
 4664   constraint(ALLOC_IN_RC(r5_reg));
 4665   match(RegP);
 4666   // match(iRegP);
 4667   match(iRegPNoSp);
 4668   op_cost(0);
 4669   format %{ %}
 4670   interface(REG_INTER);
 4671 %}
 4672 
 4673 // Pointer 64 bit Register R10 only
 4674 operand iRegP_R10()
 4675 %{
 4676   constraint(ALLOC_IN_RC(r10_reg));
 4677   match(RegP);
 4678   // match(iRegP);
 4679   match(iRegPNoSp);
 4680   op_cost(0);
 4681   format %{ %}
 4682   interface(REG_INTER);
 4683 %}
 4684 
 4685 // Long 64 bit Register R0 only
 4686 operand iRegL_R0()
 4687 %{
 4688   constraint(ALLOC_IN_RC(r0_reg));
 4689   match(RegL);
 4690   match(iRegLNoSp);
 4691   op_cost(0);
 4692   format %{ %}
 4693   interface(REG_INTER);
 4694 %}
 4695 
 4696 // Long 64 bit Register R2 only
 4697 operand iRegL_R2()
 4698 %{
 4699   constraint(ALLOC_IN_RC(r2_reg));
 4700   match(RegL);
 4701   match(iRegLNoSp);
 4702   op_cost(0);
 4703   format %{ %}
 4704   interface(REG_INTER);
 4705 %}
 4706 
 4707 // Long 64 bit Register R3 only
 4708 operand iRegL_R3()
 4709 %{
 4710   constraint(ALLOC_IN_RC(r3_reg));
 4711   match(RegL);
 4712   match(iRegLNoSp);
 4713   op_cost(0);
 4714   format %{ %}
 4715   interface(REG_INTER);
 4716 %}
 4717 
 4718 // Long 64 bit Register R11 only
 4719 operand iRegL_R11()
 4720 %{
 4721   constraint(ALLOC_IN_RC(r11_reg));
 4722   match(RegL);
 4723   match(iRegLNoSp);
 4724   op_cost(0);
 4725   format %{ %}
 4726   interface(REG_INTER);
 4727 %}
 4728 
 4729 // Pointer 64 bit Register FP only
 4730 operand iRegP_FP()
 4731 %{
 4732   constraint(ALLOC_IN_RC(fp_reg));
 4733   match(RegP);
 4734   // match(iRegP);
 4735   op_cost(0);
 4736   format %{ %}
 4737   interface(REG_INTER);
 4738 %}
 4739 
 4740 // Register R0 only
 4741 operand iRegI_R0()
 4742 %{
 4743   constraint(ALLOC_IN_RC(int_r0_reg));
 4744   match(RegI);
 4745   match(iRegINoSp);
 4746   op_cost(0);
 4747   format %{ %}
 4748   interface(REG_INTER);
 4749 %}
 4750 
 4751 // Register R2 only
 4752 operand iRegI_R2()
 4753 %{
 4754   constraint(ALLOC_IN_RC(int_r2_reg));
 4755   match(RegI);
 4756   match(iRegINoSp);
 4757   op_cost(0);
 4758   format %{ %}
 4759   interface(REG_INTER);
 4760 %}
 4761 
 4762 // Register R3 only
 4763 operand iRegI_R3()
 4764 %{
 4765   constraint(ALLOC_IN_RC(int_r3_reg));
 4766   match(RegI);
 4767   match(iRegINoSp);
 4768   op_cost(0);
 4769   format %{ %}
 4770   interface(REG_INTER);
 4771 %}
 4772 
 4773 
 4774 // Register R4 only
 4775 operand iRegI_R4()
 4776 %{
 4777   constraint(ALLOC_IN_RC(int_r4_reg));
 4778   match(RegI);
 4779   match(iRegINoSp);
 4780   op_cost(0);
 4781   format %{ %}
 4782   interface(REG_INTER);
 4783 %}
 4784 
 4785 
 4786 // Pointer Register Operands
 4787 // Narrow Pointer Register
 4788 operand iRegN()
 4789 %{
 4790   constraint(ALLOC_IN_RC(any_reg32));
 4791   match(RegN);
 4792   match(iRegNNoSp);
 4793   op_cost(0);
 4794   format %{ %}
 4795   interface(REG_INTER);
 4796 %}
 4797 
 4798 operand iRegN_R0()
 4799 %{
 4800   constraint(ALLOC_IN_RC(r0_reg));
 4801   match(iRegN);
 4802   op_cost(0);
 4803   format %{ %}
 4804   interface(REG_INTER);
 4805 %}
 4806 
 4807 operand iRegN_R2()
 4808 %{
 4809   constraint(ALLOC_IN_RC(r2_reg));
 4810   match(iRegN);
 4811   op_cost(0);
 4812   format %{ %}
 4813   interface(REG_INTER);
 4814 %}
 4815 
 4816 operand iRegN_R3()
 4817 %{
 4818   constraint(ALLOC_IN_RC(r3_reg));
 4819   match(iRegN);
 4820   op_cost(0);
 4821   format %{ %}
 4822   interface(REG_INTER);
 4823 %}
 4824 
 4825 // Integer 64 bit Register not Special
 4826 operand iRegNNoSp()
 4827 %{
 4828   constraint(ALLOC_IN_RC(no_special_reg32));
 4829   match(RegN);
 4830   op_cost(0);
 4831   format %{ %}
 4832   interface(REG_INTER);
 4833 %}
 4834 
 4835 // heap base register -- used for encoding immN0
 4836 
 4837 operand iRegIHeapbase()
 4838 %{
 4839   constraint(ALLOC_IN_RC(heapbase_reg));
 4840   match(RegI);
 4841   op_cost(0);
 4842   format %{ %}
 4843   interface(REG_INTER);
 4844 %}
 4845 
 4846 // Float Register
 4847 // Float register operands
 4848 operand vRegF()
 4849 %{
 4850   constraint(ALLOC_IN_RC(float_reg));
 4851   match(RegF);
 4852 
 4853   op_cost(0);
 4854   format %{ %}
 4855   interface(REG_INTER);
 4856 %}
 4857 
 4858 // Double Register
 4859 // Double register operands
 4860 operand vRegD()
 4861 %{
 4862   constraint(ALLOC_IN_RC(double_reg));
 4863   match(RegD);
 4864 
 4865   op_cost(0);
 4866   format %{ %}
 4867   interface(REG_INTER);
 4868 %}
 4869 
 4870 operand vecD()
 4871 %{
 4872   constraint(ALLOC_IN_RC(vectord_reg));
 4873   match(VecD);
 4874 
 4875   op_cost(0);
 4876   format %{ %}
 4877   interface(REG_INTER);
 4878 %}
 4879 
 4880 operand vecX()
 4881 %{
 4882   constraint(ALLOC_IN_RC(vectorx_reg));
 4883   match(VecX);
 4884 
 4885   op_cost(0);
 4886   format %{ %}
 4887   interface(REG_INTER);
 4888 %}
 4889 
 4890 operand vRegD_V0()
 4891 %{
 4892   constraint(ALLOC_IN_RC(v0_reg));
 4893   match(RegD);
 4894   op_cost(0);
 4895   format %{ %}
 4896   interface(REG_INTER);
 4897 %}
 4898 
 4899 operand vRegD_V1()
 4900 %{
 4901   constraint(ALLOC_IN_RC(v1_reg));
 4902   match(RegD);
 4903   op_cost(0);
 4904   format %{ %}
 4905   interface(REG_INTER);
 4906 %}
 4907 
 4908 operand vRegD_V2()
 4909 %{
 4910   constraint(ALLOC_IN_RC(v2_reg));
 4911   match(RegD);
 4912   op_cost(0);
 4913   format %{ %}
 4914   interface(REG_INTER);
 4915 %}
 4916 
 4917 operand vRegD_V3()
 4918 %{
 4919   constraint(ALLOC_IN_RC(v3_reg));
 4920   match(RegD);
 4921   op_cost(0);
 4922   format %{ %}
 4923   interface(REG_INTER);
 4924 %}
 4925 
 4926 operand vRegD_V4()
 4927 %{
 4928   constraint(ALLOC_IN_RC(v4_reg));
 4929   match(RegD);
 4930   op_cost(0);
 4931   format %{ %}
 4932   interface(REG_INTER);
 4933 %}
 4934 
 4935 operand vRegD_V5()
 4936 %{
 4937   constraint(ALLOC_IN_RC(v5_reg));
 4938   match(RegD);
 4939   op_cost(0);
 4940   format %{ %}
 4941   interface(REG_INTER);
 4942 %}
 4943 
 4944 operand vRegD_V6()
 4945 %{
 4946   constraint(ALLOC_IN_RC(v6_reg));
 4947   match(RegD);
 4948   op_cost(0);
 4949   format %{ %}
 4950   interface(REG_INTER);
 4951 %}
 4952 
 4953 operand vRegD_V7()
 4954 %{
 4955   constraint(ALLOC_IN_RC(v7_reg));
 4956   match(RegD);
 4957   op_cost(0);
 4958   format %{ %}
 4959   interface(REG_INTER);
 4960 %}
 4961 
 4962 operand vRegD_V8()
 4963 %{
 4964   constraint(ALLOC_IN_RC(v8_reg));
 4965   match(RegD);
 4966   op_cost(0);
 4967   format %{ %}
 4968   interface(REG_INTER);
 4969 %}
 4970 
 4971 operand vRegD_V9()
 4972 %{
 4973   constraint(ALLOC_IN_RC(v9_reg));
 4974   match(RegD);
 4975   op_cost(0);
 4976   format %{ %}
 4977   interface(REG_INTER);
 4978 %}
 4979 
 4980 operand vRegD_V10()
 4981 %{
 4982   constraint(ALLOC_IN_RC(v10_reg));
 4983   match(RegD);
 4984   op_cost(0);
 4985   format %{ %}
 4986   interface(REG_INTER);
 4987 %}
 4988 
 4989 operand vRegD_V11()
 4990 %{
 4991   constraint(ALLOC_IN_RC(v11_reg));
 4992   match(RegD);
 4993   op_cost(0);
 4994   format %{ %}
 4995   interface(REG_INTER);
 4996 %}
 4997 
 4998 operand vRegD_V12()
 4999 %{
 5000   constraint(ALLOC_IN_RC(v12_reg));
 5001   match(RegD);
 5002   op_cost(0);
 5003   format %{ %}
 5004   interface(REG_INTER);
 5005 %}
 5006 
 5007 operand vRegD_V13()
 5008 %{
 5009   constraint(ALLOC_IN_RC(v13_reg));
 5010   match(RegD);
 5011   op_cost(0);
 5012   format %{ %}
 5013   interface(REG_INTER);
 5014 %}
 5015 
 5016 operand vRegD_V14()
 5017 %{
 5018   constraint(ALLOC_IN_RC(v14_reg));
 5019   match(RegD);
 5020   op_cost(0);
 5021   format %{ %}
 5022   interface(REG_INTER);
 5023 %}
 5024 
 5025 operand vRegD_V15()
 5026 %{
 5027   constraint(ALLOC_IN_RC(v15_reg));
 5028   match(RegD);
 5029   op_cost(0);
 5030   format %{ %}
 5031   interface(REG_INTER);
 5032 %}
 5033 
 5034 operand vRegD_V16()
 5035 %{
 5036   constraint(ALLOC_IN_RC(v16_reg));
 5037   match(RegD);
 5038   op_cost(0);
 5039   format %{ %}
 5040   interface(REG_INTER);
 5041 %}
 5042 
 5043 operand vRegD_V17()
 5044 %{
 5045   constraint(ALLOC_IN_RC(v17_reg));
 5046   match(RegD);
 5047   op_cost(0);
 5048   format %{ %}
 5049   interface(REG_INTER);
 5050 %}
 5051 
 5052 operand vRegD_V18()
 5053 %{
 5054   constraint(ALLOC_IN_RC(v18_reg));
 5055   match(RegD);
 5056   op_cost(0);
 5057   format %{ %}
 5058   interface(REG_INTER);
 5059 %}
 5060 
 5061 operand vRegD_V19()
 5062 %{
 5063   constraint(ALLOC_IN_RC(v19_reg));
 5064   match(RegD);
 5065   op_cost(0);
 5066   format %{ %}
 5067   interface(REG_INTER);
 5068 %}
 5069 
 5070 operand vRegD_V20()
 5071 %{
 5072   constraint(ALLOC_IN_RC(v20_reg));
 5073   match(RegD);
 5074   op_cost(0);
 5075   format %{ %}
 5076   interface(REG_INTER);
 5077 %}
 5078 
 5079 operand vRegD_V21()
 5080 %{
 5081   constraint(ALLOC_IN_RC(v21_reg));
 5082   match(RegD);
 5083   op_cost(0);
 5084   format %{ %}
 5085   interface(REG_INTER);
 5086 %}
 5087 
 5088 operand vRegD_V22()
 5089 %{
 5090   constraint(ALLOC_IN_RC(v22_reg));
 5091   match(RegD);
 5092   op_cost(0);
 5093   format %{ %}
 5094   interface(REG_INTER);
 5095 %}
 5096 
 5097 operand vRegD_V23()
 5098 %{
 5099   constraint(ALLOC_IN_RC(v23_reg));
 5100   match(RegD);
 5101   op_cost(0);
 5102   format %{ %}
 5103   interface(REG_INTER);
 5104 %}
 5105 
 5106 operand vRegD_V24()
 5107 %{
 5108   constraint(ALLOC_IN_RC(v24_reg));
 5109   match(RegD);
 5110   op_cost(0);
 5111   format %{ %}
 5112   interface(REG_INTER);
 5113 %}
 5114 
 5115 operand vRegD_V25()
 5116 %{
 5117   constraint(ALLOC_IN_RC(v25_reg));
 5118   match(RegD);
 5119   op_cost(0);
 5120   format %{ %}
 5121   interface(REG_INTER);
 5122 %}
 5123 
 5124 operand vRegD_V26()
 5125 %{
 5126   constraint(ALLOC_IN_RC(v26_reg));
 5127   match(RegD);
 5128   op_cost(0);
 5129   format %{ %}
 5130   interface(REG_INTER);
 5131 %}
 5132 
 5133 operand vRegD_V27()
 5134 %{
 5135   constraint(ALLOC_IN_RC(v27_reg));
 5136   match(RegD);
 5137   op_cost(0);
 5138   format %{ %}
 5139   interface(REG_INTER);
 5140 %}
 5141 
 5142 operand vRegD_V28()
 5143 %{
 5144   constraint(ALLOC_IN_RC(v28_reg));
 5145   match(RegD);
 5146   op_cost(0);
 5147   format %{ %}
 5148   interface(REG_INTER);
 5149 %}
 5150 
 5151 operand vRegD_V29()
 5152 %{
 5153   constraint(ALLOC_IN_RC(v29_reg));
 5154   match(RegD);
 5155   op_cost(0);
 5156   format %{ %}
 5157   interface(REG_INTER);
 5158 %}
 5159 
 5160 operand vRegD_V30()
 5161 %{
 5162   constraint(ALLOC_IN_RC(v30_reg));
 5163   match(RegD);
 5164   op_cost(0);
 5165   format %{ %}
 5166   interface(REG_INTER);
 5167 %}
 5168 
 5169 operand vRegD_V31()
 5170 %{
 5171   constraint(ALLOC_IN_RC(v31_reg));
 5172   match(RegD);
 5173   op_cost(0);
 5174   format %{ %}
 5175   interface(REG_INTER);
 5176 %}
 5177 
 5178 // Flags register, used as output of signed compare instructions
 5179 
 5180 // note that on AArch64 we also use this register as the output for
 5181 // for floating point compare instructions (CmpF CmpD). this ensures
 5182 // that ordered inequality tests use GT, GE, LT or LE none of which
 5183 // pass through cases where the result is unordered i.e. one or both
 5184 // inputs to the compare is a NaN. this means that the ideal code can
 5185 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5186 // (where the comparison should always fail). EQ and NE tests are
 5187 // always generated in ideal code so that unordered folds into the NE
 5188 // case, matching the behaviour of AArch64 NE.
 5189 //
 5190 // This differs from x86 where the outputs of FP compares use a
 5191 // special FP flags registers and where compares based on this
 5192 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5193 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5194 // to explicitly handle the unordered case in branches. x86 also has
 5195 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5196 
 5197 operand rFlagsReg()
 5198 %{
 5199   constraint(ALLOC_IN_RC(int_flags));
 5200   match(RegFlags);
 5201 
 5202   op_cost(0);
 5203   format %{ &quot;RFLAGS&quot; %}
 5204   interface(REG_INTER);
 5205 %}
 5206 
 5207 // Flags register, used as output of unsigned compare instructions
 5208 operand rFlagsRegU()
 5209 %{
 5210   constraint(ALLOC_IN_RC(int_flags));
 5211   match(RegFlags);
 5212 
 5213   op_cost(0);
 5214   format %{ &quot;RFLAGSU&quot; %}
 5215   interface(REG_INTER);
 5216 %}
 5217 
 5218 // Special Registers
 5219 
 5220 // Method Register
 5221 operand inline_cache_RegP(iRegP reg)
 5222 %{
 5223   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5224   match(reg);
 5225   match(iRegPNoSp);
 5226   op_cost(0);
 5227   format %{ %}
 5228   interface(REG_INTER);
 5229 %}
 5230 
 5231 operand interpreter_method_oop_RegP(iRegP reg)
 5232 %{
 5233   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5234   match(reg);
 5235   match(iRegPNoSp);
 5236   op_cost(0);
 5237   format %{ %}
 5238   interface(REG_INTER);
 5239 %}
 5240 
 5241 // Thread Register
 5242 operand thread_RegP(iRegP reg)
 5243 %{
 5244   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5245   match(reg);
 5246   op_cost(0);
 5247   format %{ %}
 5248   interface(REG_INTER);
 5249 %}
 5250 
 5251 operand lr_RegP(iRegP reg)
 5252 %{
 5253   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5254   match(reg);
 5255   op_cost(0);
 5256   format %{ %}
 5257   interface(REG_INTER);
 5258 %}
 5259 
 5260 //----------Memory Operands----------------------------------------------------
 5261 
 5262 operand indirect(iRegP reg)
 5263 %{
 5264   constraint(ALLOC_IN_RC(ptr_reg));
 5265   match(reg);
 5266   op_cost(0);
 5267   format %{ &quot;[$reg]&quot; %}
 5268   interface(MEMORY_INTER) %{
 5269     base($reg);
 5270     index(0xffffffff);
 5271     scale(0x0);
 5272     disp(0x0);
 5273   %}
 5274 %}
 5275 
 5276 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5277 %{
 5278   constraint(ALLOC_IN_RC(ptr_reg));
 5279   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5280   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5281   op_cost(0);
 5282   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5283   interface(MEMORY_INTER) %{
 5284     base($reg);
 5285     index($ireg);
 5286     scale($scale);
 5287     disp(0x0);
 5288   %}
 5289 %}
 5290 
 5291 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5292 %{
 5293   constraint(ALLOC_IN_RC(ptr_reg));
 5294   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5295   match(AddP reg (LShiftL lreg scale));
 5296   op_cost(0);
 5297   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5298   interface(MEMORY_INTER) %{
 5299     base($reg);
 5300     index($lreg);
 5301     scale($scale);
 5302     disp(0x0);
 5303   %}
 5304 %}
 5305 
 5306 operand indIndexI2L(iRegP reg, iRegI ireg)
 5307 %{
 5308   constraint(ALLOC_IN_RC(ptr_reg));
 5309   match(AddP reg (ConvI2L ireg));
 5310   op_cost(0);
 5311   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5312   interface(MEMORY_INTER) %{
 5313     base($reg);
 5314     index($ireg);
 5315     scale(0x0);
 5316     disp(0x0);
 5317   %}
 5318 %}
 5319 
 5320 operand indIndex(iRegP reg, iRegL lreg)
 5321 %{
 5322   constraint(ALLOC_IN_RC(ptr_reg));
 5323   match(AddP reg lreg);
 5324   op_cost(0);
 5325   format %{ &quot;$reg, $lreg&quot; %}
 5326   interface(MEMORY_INTER) %{
 5327     base($reg);
 5328     index($lreg);
 5329     scale(0x0);
 5330     disp(0x0);
 5331   %}
 5332 %}
 5333 
 5334 operand indOffI(iRegP reg, immIOffset off)
 5335 %{
 5336   constraint(ALLOC_IN_RC(ptr_reg));
 5337   match(AddP reg off);
 5338   op_cost(0);
 5339   format %{ &quot;[$reg, $off]&quot; %}
 5340   interface(MEMORY_INTER) %{
 5341     base($reg);
 5342     index(0xffffffff);
 5343     scale(0x0);
 5344     disp($off);
 5345   %}
 5346 %}
 5347 
 5348 operand indOffI1(iRegP reg, immIOffset1 off)
 5349 %{
 5350   constraint(ALLOC_IN_RC(ptr_reg));
 5351   match(AddP reg off);
 5352   op_cost(0);
 5353   format %{ &quot;[$reg, $off]&quot; %}
 5354   interface(MEMORY_INTER) %{
 5355     base($reg);
 5356     index(0xffffffff);
 5357     scale(0x0);
 5358     disp($off);
 5359   %}
 5360 %}
 5361 
 5362 operand indOffI2(iRegP reg, immIOffset2 off)
 5363 %{
 5364   constraint(ALLOC_IN_RC(ptr_reg));
 5365   match(AddP reg off);
 5366   op_cost(0);
 5367   format %{ &quot;[$reg, $off]&quot; %}
 5368   interface(MEMORY_INTER) %{
 5369     base($reg);
 5370     index(0xffffffff);
 5371     scale(0x0);
 5372     disp($off);
 5373   %}
 5374 %}
 5375 
 5376 operand indOffI4(iRegP reg, immIOffset4 off)
 5377 %{
 5378   constraint(ALLOC_IN_RC(ptr_reg));
 5379   match(AddP reg off);
 5380   op_cost(0);
 5381   format %{ &quot;[$reg, $off]&quot; %}
 5382   interface(MEMORY_INTER) %{
 5383     base($reg);
 5384     index(0xffffffff);
 5385     scale(0x0);
 5386     disp($off);
 5387   %}
 5388 %}
 5389 
 5390 operand indOffI8(iRegP reg, immIOffset8 off)
 5391 %{
 5392   constraint(ALLOC_IN_RC(ptr_reg));
 5393   match(AddP reg off);
 5394   op_cost(0);
 5395   format %{ &quot;[$reg, $off]&quot; %}
 5396   interface(MEMORY_INTER) %{
 5397     base($reg);
 5398     index(0xffffffff);
 5399     scale(0x0);
 5400     disp($off);
 5401   %}
 5402 %}
 5403 
 5404 operand indOffI16(iRegP reg, immIOffset16 off)
 5405 %{
 5406   constraint(ALLOC_IN_RC(ptr_reg));
 5407   match(AddP reg off);
 5408   op_cost(0);
 5409   format %{ &quot;[$reg, $off]&quot; %}
 5410   interface(MEMORY_INTER) %{
 5411     base($reg);
 5412     index(0xffffffff);
 5413     scale(0x0);
 5414     disp($off);
 5415   %}
 5416 %}
 5417 
 5418 operand indOffL(iRegP reg, immLoffset off)
 5419 %{
 5420   constraint(ALLOC_IN_RC(ptr_reg));
 5421   match(AddP reg off);
 5422   op_cost(0);
 5423   format %{ &quot;[$reg, $off]&quot; %}
 5424   interface(MEMORY_INTER) %{
 5425     base($reg);
 5426     index(0xffffffff);
 5427     scale(0x0);
 5428     disp($off);
 5429   %}
 5430 %}
 5431 
 5432 operand indOffL1(iRegP reg, immLoffset1 off)
 5433 %{
 5434   constraint(ALLOC_IN_RC(ptr_reg));
 5435   match(AddP reg off);
 5436   op_cost(0);
 5437   format %{ &quot;[$reg, $off]&quot; %}
 5438   interface(MEMORY_INTER) %{
 5439     base($reg);
 5440     index(0xffffffff);
 5441     scale(0x0);
 5442     disp($off);
 5443   %}
 5444 %}
 5445 
 5446 operand indOffL2(iRegP reg, immLoffset2 off)
 5447 %{
 5448   constraint(ALLOC_IN_RC(ptr_reg));
 5449   match(AddP reg off);
 5450   op_cost(0);
 5451   format %{ &quot;[$reg, $off]&quot; %}
 5452   interface(MEMORY_INTER) %{
 5453     base($reg);
 5454     index(0xffffffff);
 5455     scale(0x0);
 5456     disp($off);
 5457   %}
 5458 %}
 5459 
 5460 operand indOffL4(iRegP reg, immLoffset4 off)
 5461 %{
 5462   constraint(ALLOC_IN_RC(ptr_reg));
 5463   match(AddP reg off);
 5464   op_cost(0);
 5465   format %{ &quot;[$reg, $off]&quot; %}
 5466   interface(MEMORY_INTER) %{
 5467     base($reg);
 5468     index(0xffffffff);
 5469     scale(0x0);
 5470     disp($off);
 5471   %}
 5472 %}
 5473 
 5474 operand indOffL8(iRegP reg, immLoffset8 off)
 5475 %{
 5476   constraint(ALLOC_IN_RC(ptr_reg));
 5477   match(AddP reg off);
 5478   op_cost(0);
 5479   format %{ &quot;[$reg, $off]&quot; %}
 5480   interface(MEMORY_INTER) %{
 5481     base($reg);
 5482     index(0xffffffff);
 5483     scale(0x0);
 5484     disp($off);
 5485   %}
 5486 %}
 5487 
 5488 operand indOffL16(iRegP reg, immLoffset16 off)
 5489 %{
 5490   constraint(ALLOC_IN_RC(ptr_reg));
 5491   match(AddP reg off);
 5492   op_cost(0);
 5493   format %{ &quot;[$reg, $off]&quot; %}
 5494   interface(MEMORY_INTER) %{
 5495     base($reg);
 5496     index(0xffffffff);
 5497     scale(0x0);
 5498     disp($off);
 5499   %}
 5500 %}
 5501 
 5502 operand indirectN(iRegN reg)
 5503 %{
 5504   predicate(CompressedOops::shift() == 0);
 5505   constraint(ALLOC_IN_RC(ptr_reg));
 5506   match(DecodeN reg);
 5507   op_cost(0);
 5508   format %{ &quot;[$reg]\t# narrow&quot; %}
 5509   interface(MEMORY_INTER) %{
 5510     base($reg);
 5511     index(0xffffffff);
 5512     scale(0x0);
 5513     disp(0x0);
 5514   %}
 5515 %}
 5516 
 5517 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5518 %{
 5519   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5520   constraint(ALLOC_IN_RC(ptr_reg));
 5521   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5522   op_cost(0);
 5523   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5524   interface(MEMORY_INTER) %{
 5525     base($reg);
 5526     index($ireg);
 5527     scale($scale);
 5528     disp(0x0);
 5529   %}
 5530 %}
 5531 
 5532 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5533 %{
 5534   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5535   constraint(ALLOC_IN_RC(ptr_reg));
 5536   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5537   op_cost(0);
 5538   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5539   interface(MEMORY_INTER) %{
 5540     base($reg);
 5541     index($lreg);
 5542     scale($scale);
 5543     disp(0x0);
 5544   %}
 5545 %}
 5546 
 5547 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5548 %{
 5549   predicate(CompressedOops::shift() == 0);
 5550   constraint(ALLOC_IN_RC(ptr_reg));
 5551   match(AddP (DecodeN reg) (ConvI2L ireg));
 5552   op_cost(0);
 5553   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5554   interface(MEMORY_INTER) %{
 5555     base($reg);
 5556     index($ireg);
 5557     scale(0x0);
 5558     disp(0x0);
 5559   %}
 5560 %}
 5561 
 5562 operand indIndexN(iRegN reg, iRegL lreg)
 5563 %{
 5564   predicate(CompressedOops::shift() == 0);
 5565   constraint(ALLOC_IN_RC(ptr_reg));
 5566   match(AddP (DecodeN reg) lreg);
 5567   op_cost(0);
 5568   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5569   interface(MEMORY_INTER) %{
 5570     base($reg);
 5571     index($lreg);
 5572     scale(0x0);
 5573     disp(0x0);
 5574   %}
 5575 %}
 5576 
 5577 operand indOffIN(iRegN reg, immIOffset off)
 5578 %{
 5579   predicate(CompressedOops::shift() == 0);
 5580   constraint(ALLOC_IN_RC(ptr_reg));
 5581   match(AddP (DecodeN reg) off);
 5582   op_cost(0);
 5583   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5584   interface(MEMORY_INTER) %{
 5585     base($reg);
 5586     index(0xffffffff);
 5587     scale(0x0);
 5588     disp($off);
 5589   %}
 5590 %}
 5591 
 5592 operand indOffLN(iRegN reg, immLoffset off)
 5593 %{
 5594   predicate(CompressedOops::shift() == 0);
 5595   constraint(ALLOC_IN_RC(ptr_reg));
 5596   match(AddP (DecodeN reg) off);
 5597   op_cost(0);
 5598   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5599   interface(MEMORY_INTER) %{
 5600     base($reg);
 5601     index(0xffffffff);
 5602     scale(0x0);
 5603     disp($off);
 5604   %}
 5605 %}
 5606 
 5607 
 5608 
 5609 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5610 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5611 %{
 5612   constraint(ALLOC_IN_RC(ptr_reg));
 5613   match(AddP reg off);
 5614   op_cost(0);
 5615   format %{ &quot;[$reg, $off]&quot; %}
 5616   interface(MEMORY_INTER) %{
 5617     base($reg);
 5618     index(0xffffffff);
 5619     scale(0x0);
 5620     disp($off);
 5621   %}
 5622 %}
 5623 
 5624 //----------Special Memory Operands--------------------------------------------
 5625 // Stack Slot Operand - This operand is used for loading and storing temporary
 5626 //                      values on the stack where a match requires a value to
 5627 //                      flow through memory.
 5628 operand stackSlotP(sRegP reg)
 5629 %{
 5630   constraint(ALLOC_IN_RC(stack_slots));
 5631   op_cost(100);
 5632   // No match rule because this operand is only generated in matching
 5633   // match(RegP);
 5634   format %{ &quot;[$reg]&quot; %}
 5635   interface(MEMORY_INTER) %{
 5636     base(0x1e);  // RSP
 5637     index(0x0);  // No Index
 5638     scale(0x0);  // No Scale
 5639     disp($reg);  // Stack Offset
 5640   %}
 5641 %}
 5642 
 5643 operand stackSlotI(sRegI reg)
 5644 %{
 5645   constraint(ALLOC_IN_RC(stack_slots));
 5646   // No match rule because this operand is only generated in matching
 5647   // match(RegI);
 5648   format %{ &quot;[$reg]&quot; %}
 5649   interface(MEMORY_INTER) %{
 5650     base(0x1e);  // RSP
 5651     index(0x0);  // No Index
 5652     scale(0x0);  // No Scale
 5653     disp($reg);  // Stack Offset
 5654   %}
 5655 %}
 5656 
 5657 operand stackSlotF(sRegF reg)
 5658 %{
 5659   constraint(ALLOC_IN_RC(stack_slots));
 5660   // No match rule because this operand is only generated in matching
 5661   // match(RegF);
 5662   format %{ &quot;[$reg]&quot; %}
 5663   interface(MEMORY_INTER) %{
 5664     base(0x1e);  // RSP
 5665     index(0x0);  // No Index
 5666     scale(0x0);  // No Scale
 5667     disp($reg);  // Stack Offset
 5668   %}
 5669 %}
 5670 
 5671 operand stackSlotD(sRegD reg)
 5672 %{
 5673   constraint(ALLOC_IN_RC(stack_slots));
 5674   // No match rule because this operand is only generated in matching
 5675   // match(RegD);
 5676   format %{ &quot;[$reg]&quot; %}
 5677   interface(MEMORY_INTER) %{
 5678     base(0x1e);  // RSP
 5679     index(0x0);  // No Index
 5680     scale(0x0);  // No Scale
 5681     disp($reg);  // Stack Offset
 5682   %}
 5683 %}
 5684 
 5685 operand stackSlotL(sRegL reg)
 5686 %{
 5687   constraint(ALLOC_IN_RC(stack_slots));
 5688   // No match rule because this operand is only generated in matching
 5689   // match(RegL);
 5690   format %{ &quot;[$reg]&quot; %}
 5691   interface(MEMORY_INTER) %{
 5692     base(0x1e);  // RSP
 5693     index(0x0);  // No Index
 5694     scale(0x0);  // No Scale
 5695     disp($reg);  // Stack Offset
 5696   %}
 5697 %}
 5698 
 5699 // Operands for expressing Control Flow
 5700 // NOTE: Label is a predefined operand which should not be redefined in
 5701 //       the AD file. It is generically handled within the ADLC.
 5702 
 5703 //----------Conditional Branch Operands----------------------------------------
 5704 // Comparison Op  - This is the operation of the comparison, and is limited to
 5705 //                  the following set of codes:
 5706 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5707 //
 5708 // Other attributes of the comparison, such as unsignedness, are specified
 5709 // by the comparison instruction that sets a condition code flags register.
 5710 // That result is represented by a flags operand whose subtype is appropriate
 5711 // to the unsignedness (etc.) of the comparison.
 5712 //
 5713 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5714 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5715 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5716 
 5717 // used for signed integral comparisons and fp comparisons
 5718 
 5719 operand cmpOp()
 5720 %{
 5721   match(Bool);
 5722 
 5723   format %{ &quot;&quot; %}
 5724   interface(COND_INTER) %{
 5725     equal(0x0, &quot;eq&quot;);
 5726     not_equal(0x1, &quot;ne&quot;);
 5727     less(0xb, &quot;lt&quot;);
 5728     greater_equal(0xa, &quot;ge&quot;);
 5729     less_equal(0xd, &quot;le&quot;);
 5730     greater(0xc, &quot;gt&quot;);
 5731     overflow(0x6, &quot;vs&quot;);
 5732     no_overflow(0x7, &quot;vc&quot;);
 5733   %}
 5734 %}
 5735 
 5736 // used for unsigned integral comparisons
 5737 
 5738 operand cmpOpU()
 5739 %{
 5740   match(Bool);
 5741 
 5742   format %{ &quot;&quot; %}
 5743   interface(COND_INTER) %{
 5744     equal(0x0, &quot;eq&quot;);
 5745     not_equal(0x1, &quot;ne&quot;);
 5746     less(0x3, &quot;lo&quot;);
 5747     greater_equal(0x2, &quot;hs&quot;);
 5748     less_equal(0x9, &quot;ls&quot;);
 5749     greater(0x8, &quot;hi&quot;);
 5750     overflow(0x6, &quot;vs&quot;);
 5751     no_overflow(0x7, &quot;vc&quot;);
 5752   %}
 5753 %}
 5754 
 5755 // used for certain integral comparisons which can be
 5756 // converted to cbxx or tbxx instructions
 5757 
 5758 operand cmpOpEqNe()
 5759 %{
 5760   match(Bool);
 5761   op_cost(0);
 5762   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5763             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5764 
 5765   format %{ &quot;&quot; %}
 5766   interface(COND_INTER) %{
 5767     equal(0x0, &quot;eq&quot;);
 5768     not_equal(0x1, &quot;ne&quot;);
 5769     less(0xb, &quot;lt&quot;);
 5770     greater_equal(0xa, &quot;ge&quot;);
 5771     less_equal(0xd, &quot;le&quot;);
 5772     greater(0xc, &quot;gt&quot;);
 5773     overflow(0x6, &quot;vs&quot;);
 5774     no_overflow(0x7, &quot;vc&quot;);
 5775   %}
 5776 %}
 5777 
 5778 // used for certain integral comparisons which can be
 5779 // converted to cbxx or tbxx instructions
 5780 
 5781 operand cmpOpLtGe()
 5782 %{
 5783   match(Bool);
 5784   op_cost(0);
 5785 
 5786   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5787             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5788 
 5789   format %{ &quot;&quot; %}
 5790   interface(COND_INTER) %{
 5791     equal(0x0, &quot;eq&quot;);
 5792     not_equal(0x1, &quot;ne&quot;);
 5793     less(0xb, &quot;lt&quot;);
 5794     greater_equal(0xa, &quot;ge&quot;);
 5795     less_equal(0xd, &quot;le&quot;);
 5796     greater(0xc, &quot;gt&quot;);
 5797     overflow(0x6, &quot;vs&quot;);
 5798     no_overflow(0x7, &quot;vc&quot;);
 5799   %}
 5800 %}
 5801 
 5802 // used for certain unsigned integral comparisons which can be
 5803 // converted to cbxx or tbxx instructions
 5804 
 5805 operand cmpOpUEqNeLtGe()
 5806 %{
 5807   match(Bool);
 5808   op_cost(0);
 5809 
 5810   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5811             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5812             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5813             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5814 
 5815   format %{ &quot;&quot; %}
 5816   interface(COND_INTER) %{
 5817     equal(0x0, &quot;eq&quot;);
 5818     not_equal(0x1, &quot;ne&quot;);
 5819     less(0xb, &quot;lt&quot;);
 5820     greater_equal(0xa, &quot;ge&quot;);
 5821     less_equal(0xd, &quot;le&quot;);
 5822     greater(0xc, &quot;gt&quot;);
 5823     overflow(0x6, &quot;vs&quot;);
 5824     no_overflow(0x7, &quot;vc&quot;);
 5825   %}
 5826 %}
 5827 
 5828 // Special operand allowing long args to int ops to be truncated for free
 5829 
 5830 operand iRegL2I(iRegL reg) %{
 5831 
 5832   op_cost(0);
 5833 
 5834   match(ConvL2I reg);
 5835 
 5836   format %{ &quot;l2i($reg)&quot; %}
 5837 
 5838   interface(REG_INTER)
 5839 %}
 5840 
 5841 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5842 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5843 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5844 
 5845 //----------OPERAND CLASSES----------------------------------------------------
 5846 // Operand Classes are groups of operands that are used as to simplify
 5847 // instruction definitions by not requiring the AD writer to specify
 5848 // separate instructions for every form of operand when the
 5849 // instruction accepts multiple operand types with the same basic
 5850 // encoding and format. The classic case of this is memory operands.
 5851 
 5852 // memory is used to define read/write location for load/store
 5853 // instruction defs. we can turn a memory op into an Address
 5854 
 5855 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5856                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5857 
 5858 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5859                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5860 
 5861 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5862                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5863 
 5864 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5865                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5866 
 5867 // All of the memory operands. For the pipeline description.
 5868 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5869                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5870                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5871 
 5872 
 5873 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5874 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5875 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5876 // can be elided because the 32-bit instruction will just employ the
 5877 // lower 32 bits anyway.
 5878 //
 5879 // n.b. this does not elide all L2I conversions. if the truncated
 5880 // value is consumed by more than one operation then the ConvL2I
 5881 // cannot be bundled into the consuming nodes so an l2i gets planted
 5882 // (actually a movw $dst $src) and the downstream instructions consume
 5883 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5884 // movw is actually redundant but its not too costly.
 5885 
 5886 opclass iRegIorL2I(iRegI, iRegL2I);
 5887 
 5888 //----------PIPELINE-----------------------------------------------------------
 5889 // Rules which define the behavior of the target architectures pipeline.
 5890 
 5891 // For specific pipelines, eg A53, define the stages of that pipeline
 5892 //pipe_desc(ISS, EX1, EX2, WR);
 5893 #define ISS S0
 5894 #define EX1 S1
 5895 #define EX2 S2
 5896 #define WR  S3
 5897 
 5898 // Integer ALU reg operation
 5899 pipeline %{
 5900 
 5901 attributes %{
 5902   // ARM instructions are of fixed length
 5903   fixed_size_instructions;        // Fixed size instructions TODO does
 5904   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5905   // ARM instructions come in 32-bit word units
 5906   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5907   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5908   instruction_fetch_units = 1;       // of 64 bytes
 5909 
 5910   // List of nop instructions
 5911   nops( MachNop );
 5912 %}
 5913 
 5914 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5915 // or description. we do use pipeline classes to introduce fixed
 5916 // latencies
 5917 
 5918 //----------RESOURCES----------------------------------------------------------
 5919 // Resources are the functional units available to the machine
 5920 
 5921 resources( INS0, INS1, INS01 = INS0 | INS1,
 5922            ALU0, ALU1, ALU = ALU0 | ALU1,
 5923            MAC,
 5924            DIV,
 5925            BRANCH,
 5926            LDST,
 5927            NEON_FP);
 5928 
 5929 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5930 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5931 
 5932 // Define the pipeline as a generic 6 stage pipeline
 5933 pipe_desc(S0, S1, S2, S3, S4, S5);
 5934 
 5935 //----------PIPELINE CLASSES---------------------------------------------------
 5936 // Pipeline Classes describe the stages in which input and output are
 5937 // referenced by the hardware pipeline.
 5938 
 5939 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5940 %{
 5941   single_instruction;
 5942   src1   : S1(read);
 5943   src2   : S2(read);
 5944   dst    : S5(write);
 5945   INS01  : ISS;
 5946   NEON_FP : S5;
 5947 %}
 5948 
 5949 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5950 %{
 5951   single_instruction;
 5952   src1   : S1(read);
 5953   src2   : S2(read);
 5954   dst    : S5(write);
 5955   INS01  : ISS;
 5956   NEON_FP : S5;
 5957 %}
 5958 
 5959 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5960 %{
 5961   single_instruction;
 5962   src    : S1(read);
 5963   dst    : S5(write);
 5964   INS01  : ISS;
 5965   NEON_FP : S5;
 5966 %}
 5967 
 5968 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5969 %{
 5970   single_instruction;
 5971   src    : S1(read);
 5972   dst    : S5(write);
 5973   INS01  : ISS;
 5974   NEON_FP : S5;
 5975 %}
 5976 
 5977 pipe_class fp_d2f(vRegF dst, vRegD src)
 5978 %{
 5979   single_instruction;
 5980   src    : S1(read);
 5981   dst    : S5(write);
 5982   INS01  : ISS;
 5983   NEON_FP : S5;
 5984 %}
 5985 
 5986 pipe_class fp_f2d(vRegD dst, vRegF src)
 5987 %{
 5988   single_instruction;
 5989   src    : S1(read);
 5990   dst    : S5(write);
 5991   INS01  : ISS;
 5992   NEON_FP : S5;
 5993 %}
 5994 
 5995 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5996 %{
 5997   single_instruction;
 5998   src    : S1(read);
 5999   dst    : S5(write);
 6000   INS01  : ISS;
 6001   NEON_FP : S5;
 6002 %}
 6003 
 6004 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6005 %{
 6006   single_instruction;
 6007   src    : S1(read);
 6008   dst    : S5(write);
 6009   INS01  : ISS;
 6010   NEON_FP : S5;
 6011 %}
 6012 
 6013 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6014 %{
 6015   single_instruction;
 6016   src    : S1(read);
 6017   dst    : S5(write);
 6018   INS01  : ISS;
 6019   NEON_FP : S5;
 6020 %}
 6021 
 6022 pipe_class fp_l2f(vRegF dst, iRegL src)
 6023 %{
 6024   single_instruction;
 6025   src    : S1(read);
 6026   dst    : S5(write);
 6027   INS01  : ISS;
 6028   NEON_FP : S5;
 6029 %}
 6030 
 6031 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6032 %{
 6033   single_instruction;
 6034   src    : S1(read);
 6035   dst    : S5(write);
 6036   INS01  : ISS;
 6037   NEON_FP : S5;
 6038 %}
 6039 
 6040 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6041 %{
 6042   single_instruction;
 6043   src    : S1(read);
 6044   dst    : S5(write);
 6045   INS01  : ISS;
 6046   NEON_FP : S5;
 6047 %}
 6048 
 6049 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6050 %{
 6051   single_instruction;
 6052   src    : S1(read);
 6053   dst    : S5(write);
 6054   INS01  : ISS;
 6055   NEON_FP : S5;
 6056 %}
 6057 
 6058 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6059 %{
 6060   single_instruction;
 6061   src    : S1(read);
 6062   dst    : S5(write);
 6063   INS01  : ISS;
 6064   NEON_FP : S5;
 6065 %}
 6066 
 6067 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6068 %{
 6069   single_instruction;
 6070   src1   : S1(read);
 6071   src2   : S2(read);
 6072   dst    : S5(write);
 6073   INS0   : ISS;
 6074   NEON_FP : S5;
 6075 %}
 6076 
 6077 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6078 %{
 6079   single_instruction;
 6080   src1   : S1(read);
 6081   src2   : S2(read);
 6082   dst    : S5(write);
 6083   INS0   : ISS;
 6084   NEON_FP : S5;
 6085 %}
 6086 
 6087 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6088 %{
 6089   single_instruction;
 6090   cr     : S1(read);
 6091   src1   : S1(read);
 6092   src2   : S1(read);
 6093   dst    : S3(write);
 6094   INS01  : ISS;
 6095   NEON_FP : S3;
 6096 %}
 6097 
 6098 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6099 %{
 6100   single_instruction;
 6101   cr     : S1(read);
 6102   src1   : S1(read);
 6103   src2   : S1(read);
 6104   dst    : S3(write);
 6105   INS01  : ISS;
 6106   NEON_FP : S3;
 6107 %}
 6108 
 6109 pipe_class fp_imm_s(vRegF dst)
 6110 %{
 6111   single_instruction;
 6112   dst    : S3(write);
 6113   INS01  : ISS;
 6114   NEON_FP : S3;
 6115 %}
 6116 
 6117 pipe_class fp_imm_d(vRegD dst)
 6118 %{
 6119   single_instruction;
 6120   dst    : S3(write);
 6121   INS01  : ISS;
 6122   NEON_FP : S3;
 6123 %}
 6124 
 6125 pipe_class fp_load_constant_s(vRegF dst)
 6126 %{
 6127   single_instruction;
 6128   dst    : S4(write);
 6129   INS01  : ISS;
 6130   NEON_FP : S4;
 6131 %}
 6132 
 6133 pipe_class fp_load_constant_d(vRegD dst)
 6134 %{
 6135   single_instruction;
 6136   dst    : S4(write);
 6137   INS01  : ISS;
 6138   NEON_FP : S4;
 6139 %}
 6140 
 6141 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6142 %{
 6143   single_instruction;
 6144   dst    : S5(write);
 6145   src1   : S1(read);
 6146   src2   : S1(read);
 6147   INS01  : ISS;
 6148   NEON_FP : S5;
 6149 %}
 6150 
 6151 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6152 %{
 6153   single_instruction;
 6154   dst    : S5(write);
 6155   src1   : S1(read);
 6156   src2   : S1(read);
 6157   INS0   : ISS;
 6158   NEON_FP : S5;
 6159 %}
 6160 
 6161 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6162 %{
 6163   single_instruction;
 6164   dst    : S5(write);
 6165   src1   : S1(read);
 6166   src2   : S1(read);
 6167   dst    : S1(read);
 6168   INS01  : ISS;
 6169   NEON_FP : S5;
 6170 %}
 6171 
 6172 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6173 %{
 6174   single_instruction;
 6175   dst    : S5(write);
 6176   src1   : S1(read);
 6177   src2   : S1(read);
 6178   dst    : S1(read);
 6179   INS0   : ISS;
 6180   NEON_FP : S5;
 6181 %}
 6182 
 6183 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6184 %{
 6185   single_instruction;
 6186   dst    : S4(write);
 6187   src1   : S2(read);
 6188   src2   : S2(read);
 6189   INS01  : ISS;
 6190   NEON_FP : S4;
 6191 %}
 6192 
 6193 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6194 %{
 6195   single_instruction;
 6196   dst    : S4(write);
 6197   src1   : S2(read);
 6198   src2   : S2(read);
 6199   INS0   : ISS;
 6200   NEON_FP : S4;
 6201 %}
 6202 
 6203 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6204 %{
 6205   single_instruction;
 6206   dst    : S3(write);
 6207   src1   : S2(read);
 6208   src2   : S2(read);
 6209   INS01  : ISS;
 6210   NEON_FP : S3;
 6211 %}
 6212 
 6213 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6214 %{
 6215   single_instruction;
 6216   dst    : S3(write);
 6217   src1   : S2(read);
 6218   src2   : S2(read);
 6219   INS0   : ISS;
 6220   NEON_FP : S3;
 6221 %}
 6222 
 6223 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6224 %{
 6225   single_instruction;
 6226   dst    : S3(write);
 6227   src    : S1(read);
 6228   shift  : S1(read);
 6229   INS01  : ISS;
 6230   NEON_FP : S3;
 6231 %}
 6232 
 6233 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6234 %{
 6235   single_instruction;
 6236   dst    : S3(write);
 6237   src    : S1(read);
 6238   shift  : S1(read);
 6239   INS0   : ISS;
 6240   NEON_FP : S3;
 6241 %}
 6242 
 6243 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6244 %{
 6245   single_instruction;
 6246   dst    : S3(write);
 6247   src    : S1(read);
 6248   INS01  : ISS;
 6249   NEON_FP : S3;
 6250 %}
 6251 
 6252 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6253 %{
 6254   single_instruction;
 6255   dst    : S3(write);
 6256   src    : S1(read);
 6257   INS0   : ISS;
 6258   NEON_FP : S3;
 6259 %}
 6260 
 6261 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6262 %{
 6263   single_instruction;
 6264   dst    : S5(write);
 6265   src1   : S1(read);
 6266   src2   : S1(read);
 6267   INS01  : ISS;
 6268   NEON_FP : S5;
 6269 %}
 6270 
 6271 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6272 %{
 6273   single_instruction;
 6274   dst    : S5(write);
 6275   src1   : S1(read);
 6276   src2   : S1(read);
 6277   INS0   : ISS;
 6278   NEON_FP : S5;
 6279 %}
 6280 
 6281 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6282 %{
 6283   single_instruction;
 6284   dst    : S5(write);
 6285   src1   : S1(read);
 6286   src2   : S1(read);
 6287   INS0   : ISS;
 6288   NEON_FP : S5;
 6289 %}
 6290 
 6291 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6292 %{
 6293   single_instruction;
 6294   dst    : S5(write);
 6295   src1   : S1(read);
 6296   src2   : S1(read);
 6297   INS0   : ISS;
 6298   NEON_FP : S5;
 6299 %}
 6300 
 6301 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6302 %{
 6303   single_instruction;
 6304   dst    : S5(write);
 6305   src    : S1(read);
 6306   INS0   : ISS;
 6307   NEON_FP : S5;
 6308 %}
 6309 
 6310 pipe_class vunop_fp64(vecD dst, vecD src)
 6311 %{
 6312   single_instruction;
 6313   dst    : S5(write);
 6314   src    : S1(read);
 6315   INS01  : ISS;
 6316   NEON_FP : S5;
 6317 %}
 6318 
 6319 pipe_class vunop_fp128(vecX dst, vecX src)
 6320 %{
 6321   single_instruction;
 6322   dst    : S5(write);
 6323   src    : S1(read);
 6324   INS0   : ISS;
 6325   NEON_FP : S5;
 6326 %}
 6327 
 6328 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6329 %{
 6330   single_instruction;
 6331   dst    : S3(write);
 6332   src    : S1(read);
 6333   INS01  : ISS;
 6334   NEON_FP : S3;
 6335 %}
 6336 
 6337 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6338 %{
 6339   single_instruction;
 6340   dst    : S3(write);
 6341   src    : S1(read);
 6342   INS01  : ISS;
 6343   NEON_FP : S3;
 6344 %}
 6345 
 6346 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6347 %{
 6348   single_instruction;
 6349   dst    : S3(write);
 6350   src    : S1(read);
 6351   INS01  : ISS;
 6352   NEON_FP : S3;
 6353 %}
 6354 
 6355 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6356 %{
 6357   single_instruction;
 6358   dst    : S3(write);
 6359   src    : S1(read);
 6360   INS01  : ISS;
 6361   NEON_FP : S3;
 6362 %}
 6363 
 6364 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6365 %{
 6366   single_instruction;
 6367   dst    : S3(write);
 6368   src    : S1(read);
 6369   INS01  : ISS;
 6370   NEON_FP : S3;
 6371 %}
 6372 
 6373 pipe_class vmovi_reg_imm64(vecD dst)
 6374 %{
 6375   single_instruction;
 6376   dst    : S3(write);
 6377   INS01  : ISS;
 6378   NEON_FP : S3;
 6379 %}
 6380 
 6381 pipe_class vmovi_reg_imm128(vecX dst)
 6382 %{
 6383   single_instruction;
 6384   dst    : S3(write);
 6385   INS0   : ISS;
 6386   NEON_FP : S3;
 6387 %}
 6388 
 6389 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6390 %{
 6391   single_instruction;
 6392   dst    : S5(write);
 6393   mem    : ISS(read);
 6394   INS01  : ISS;
 6395   NEON_FP : S3;
 6396 %}
 6397 
 6398 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6399 %{
 6400   single_instruction;
 6401   dst    : S5(write);
 6402   mem    : ISS(read);
 6403   INS01  : ISS;
 6404   NEON_FP : S3;
 6405 %}
 6406 
 6407 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6408 %{
 6409   single_instruction;
 6410   mem    : ISS(read);
 6411   src    : S2(read);
 6412   INS01  : ISS;
 6413   NEON_FP : S3;
 6414 %}
 6415 
 6416 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6417 %{
 6418   single_instruction;
 6419   mem    : ISS(read);
 6420   src    : S2(read);
 6421   INS01  : ISS;
 6422   NEON_FP : S3;
 6423 %}
 6424 
 6425 //------- Integer ALU operations --------------------------
 6426 
 6427 // Integer ALU reg-reg operation
 6428 // Operands needed in EX1, result generated in EX2
 6429 // Eg.  ADD     x0, x1, x2
 6430 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6431 %{
 6432   single_instruction;
 6433   dst    : EX2(write);
 6434   src1   : EX1(read);
 6435   src2   : EX1(read);
 6436   INS01  : ISS; // Dual issue as instruction 0 or 1
 6437   ALU    : EX2;
 6438 %}
 6439 
 6440 // Integer ALU reg-reg operation with constant shift
 6441 // Shifted register must be available in LATE_ISS instead of EX1
 6442 // Eg.  ADD     x0, x1, x2, LSL #2
 6443 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6444 %{
 6445   single_instruction;
 6446   dst    : EX2(write);
 6447   src1   : EX1(read);
 6448   src2   : ISS(read);
 6449   INS01  : ISS;
 6450   ALU    : EX2;
 6451 %}
 6452 
 6453 // Integer ALU reg operation with constant shift
 6454 // Eg.  LSL     x0, x1, #shift
 6455 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6456 %{
 6457   single_instruction;
 6458   dst    : EX2(write);
 6459   src1   : ISS(read);
 6460   INS01  : ISS;
 6461   ALU    : EX2;
 6462 %}
 6463 
 6464 // Integer ALU reg-reg operation with variable shift
 6465 // Both operands must be available in LATE_ISS instead of EX1
 6466 // Result is available in EX1 instead of EX2
 6467 // Eg.  LSLV    x0, x1, x2
 6468 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6469 %{
 6470   single_instruction;
 6471   dst    : EX1(write);
 6472   src1   : ISS(read);
 6473   src2   : ISS(read);
 6474   INS01  : ISS;
 6475   ALU    : EX1;
 6476 %}
 6477 
 6478 // Integer ALU reg-reg operation with extract
 6479 // As for _vshift above, but result generated in EX2
 6480 // Eg.  EXTR    x0, x1, x2, #N
 6481 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6482 %{
 6483   single_instruction;
 6484   dst    : EX2(write);
 6485   src1   : ISS(read);
 6486   src2   : ISS(read);
 6487   INS1   : ISS; // Can only dual issue as Instruction 1
 6488   ALU    : EX1;
 6489 %}
 6490 
 6491 // Integer ALU reg operation
 6492 // Eg.  NEG     x0, x1
 6493 pipe_class ialu_reg(iRegI dst, iRegI src)
 6494 %{
 6495   single_instruction;
 6496   dst    : EX2(write);
 6497   src    : EX1(read);
 6498   INS01  : ISS;
 6499   ALU    : EX2;
 6500 %}
 6501 
 6502 // Integer ALU reg mmediate operation
 6503 // Eg.  ADD     x0, x1, #N
 6504 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6505 %{
 6506   single_instruction;
 6507   dst    : EX2(write);
 6508   src1   : EX1(read);
 6509   INS01  : ISS;
 6510   ALU    : EX2;
 6511 %}
 6512 
 6513 // Integer ALU immediate operation (no source operands)
 6514 // Eg.  MOV     x0, #N
 6515 pipe_class ialu_imm(iRegI dst)
 6516 %{
 6517   single_instruction;
 6518   dst    : EX1(write);
 6519   INS01  : ISS;
 6520   ALU    : EX1;
 6521 %}
 6522 
 6523 //------- Compare operation -------------------------------
 6524 
 6525 // Compare reg-reg
 6526 // Eg.  CMP     x0, x1
 6527 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6528 %{
 6529   single_instruction;
 6530 //  fixed_latency(16);
 6531   cr     : EX2(write);
 6532   op1    : EX1(read);
 6533   op2    : EX1(read);
 6534   INS01  : ISS;
 6535   ALU    : EX2;
 6536 %}
 6537 
 6538 // Compare reg-reg
 6539 // Eg.  CMP     x0, #N
 6540 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6541 %{
 6542   single_instruction;
 6543 //  fixed_latency(16);
 6544   cr     : EX2(write);
 6545   op1    : EX1(read);
 6546   INS01  : ISS;
 6547   ALU    : EX2;
 6548 %}
 6549 
 6550 //------- Conditional instructions ------------------------
 6551 
 6552 // Conditional no operands
 6553 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6554 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6555 %{
 6556   single_instruction;
 6557   cr     : EX1(read);
 6558   dst    : EX2(write);
 6559   INS01  : ISS;
 6560   ALU    : EX2;
 6561 %}
 6562 
 6563 // Conditional 2 operand
 6564 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6565 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6566 %{
 6567   single_instruction;
 6568   cr     : EX1(read);
 6569   src1   : EX1(read);
 6570   src2   : EX1(read);
 6571   dst    : EX2(write);
 6572   INS01  : ISS;
 6573   ALU    : EX2;
 6574 %}
 6575 
 6576 // Conditional 2 operand
 6577 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6578 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6579 %{
 6580   single_instruction;
 6581   cr     : EX1(read);
 6582   src    : EX1(read);
 6583   dst    : EX2(write);
 6584   INS01  : ISS;
 6585   ALU    : EX2;
 6586 %}
 6587 
 6588 //------- Multiply pipeline operations --------------------
 6589 
 6590 // Multiply reg-reg
 6591 // Eg.  MUL     w0, w1, w2
 6592 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6593 %{
 6594   single_instruction;
 6595   dst    : WR(write);
 6596   src1   : ISS(read);
 6597   src2   : ISS(read);
 6598   INS01  : ISS;
 6599   MAC    : WR;
 6600 %}
 6601 
 6602 // Multiply accumulate
 6603 // Eg.  MADD    w0, w1, w2, w3
 6604 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6605 %{
 6606   single_instruction;
 6607   dst    : WR(write);
 6608   src1   : ISS(read);
 6609   src2   : ISS(read);
 6610   src3   : ISS(read);
 6611   INS01  : ISS;
 6612   MAC    : WR;
 6613 %}
 6614 
 6615 // Eg.  MUL     w0, w1, w2
 6616 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6617 %{
 6618   single_instruction;
 6619   fixed_latency(3); // Maximum latency for 64 bit mul
 6620   dst    : WR(write);
 6621   src1   : ISS(read);
 6622   src2   : ISS(read);
 6623   INS01  : ISS;
 6624   MAC    : WR;
 6625 %}
 6626 
 6627 // Multiply accumulate
 6628 // Eg.  MADD    w0, w1, w2, w3
 6629 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6630 %{
 6631   single_instruction;
 6632   fixed_latency(3); // Maximum latency for 64 bit mul
 6633   dst    : WR(write);
 6634   src1   : ISS(read);
 6635   src2   : ISS(read);
 6636   src3   : ISS(read);
 6637   INS01  : ISS;
 6638   MAC    : WR;
 6639 %}
 6640 
 6641 //------- Divide pipeline operations --------------------
 6642 
 6643 // Eg.  SDIV    w0, w1, w2
 6644 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6645 %{
 6646   single_instruction;
 6647   fixed_latency(8); // Maximum latency for 32 bit divide
 6648   dst    : WR(write);
 6649   src1   : ISS(read);
 6650   src2   : ISS(read);
 6651   INS0   : ISS; // Can only dual issue as instruction 0
 6652   DIV    : WR;
 6653 %}
 6654 
 6655 // Eg.  SDIV    x0, x1, x2
 6656 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6657 %{
 6658   single_instruction;
 6659   fixed_latency(16); // Maximum latency for 64 bit divide
 6660   dst    : WR(write);
 6661   src1   : ISS(read);
 6662   src2   : ISS(read);
 6663   INS0   : ISS; // Can only dual issue as instruction 0
 6664   DIV    : WR;
 6665 %}
 6666 
 6667 //------- Load pipeline operations ------------------------
 6668 
 6669 // Load - prefetch
 6670 // Eg.  PFRM    &lt;mem&gt;
 6671 pipe_class iload_prefetch(memory mem)
 6672 %{
 6673   single_instruction;
 6674   mem    : ISS(read);
 6675   INS01  : ISS;
 6676   LDST   : WR;
 6677 %}
 6678 
 6679 // Load - reg, mem
 6680 // Eg.  LDR     x0, &lt;mem&gt;
 6681 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6682 %{
 6683   single_instruction;
 6684   dst    : WR(write);
 6685   mem    : ISS(read);
 6686   INS01  : ISS;
 6687   LDST   : WR;
 6688 %}
 6689 
 6690 // Load - reg, reg
 6691 // Eg.  LDR     x0, [sp, x1]
 6692 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6693 %{
 6694   single_instruction;
 6695   dst    : WR(write);
 6696   src    : ISS(read);
 6697   INS01  : ISS;
 6698   LDST   : WR;
 6699 %}
 6700 
 6701 //------- Store pipeline operations -----------------------
 6702 
 6703 // Store - zr, mem
 6704 // Eg.  STR     zr, &lt;mem&gt;
 6705 pipe_class istore_mem(memory mem)
 6706 %{
 6707   single_instruction;
 6708   mem    : ISS(read);
 6709   INS01  : ISS;
 6710   LDST   : WR;
 6711 %}
 6712 
 6713 // Store - reg, mem
 6714 // Eg.  STR     x0, &lt;mem&gt;
 6715 pipe_class istore_reg_mem(iRegI src, memory mem)
 6716 %{
 6717   single_instruction;
 6718   mem    : ISS(read);
 6719   src    : EX2(read);
 6720   INS01  : ISS;
 6721   LDST   : WR;
 6722 %}
 6723 
 6724 // Store - reg, reg
 6725 // Eg. STR      x0, [sp, x1]
 6726 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6727 %{
 6728   single_instruction;
 6729   dst    : ISS(read);
 6730   src    : EX2(read);
 6731   INS01  : ISS;
 6732   LDST   : WR;
 6733 %}
 6734 
 6735 //------- Store pipeline operations -----------------------
 6736 
 6737 // Branch
 6738 pipe_class pipe_branch()
 6739 %{
 6740   single_instruction;
 6741   INS01  : ISS;
 6742   BRANCH : EX1;
 6743 %}
 6744 
 6745 // Conditional branch
 6746 pipe_class pipe_branch_cond(rFlagsReg cr)
 6747 %{
 6748   single_instruction;
 6749   cr     : EX1(read);
 6750   INS01  : ISS;
 6751   BRANCH : EX1;
 6752 %}
 6753 
 6754 // Compare &amp; Branch
 6755 // EG.  CBZ/CBNZ
 6756 pipe_class pipe_cmp_branch(iRegI op1)
 6757 %{
 6758   single_instruction;
 6759   op1    : EX1(read);
 6760   INS01  : ISS;
 6761   BRANCH : EX1;
 6762 %}
 6763 
 6764 //------- Synchronisation operations ----------------------
 6765 
 6766 // Any operation requiring serialization.
 6767 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6768 pipe_class pipe_serial()
 6769 %{
 6770   single_instruction;
 6771   force_serialization;
 6772   fixed_latency(16);
 6773   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6774   LDST   : WR;
 6775 %}
 6776 
 6777 // Generic big/slow expanded idiom - also serialized
 6778 pipe_class pipe_slow()
 6779 %{
 6780   instruction_count(10);
 6781   multiple_bundles;
 6782   force_serialization;
 6783   fixed_latency(16);
 6784   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6785   LDST   : WR;
 6786 %}
 6787 
 6788 // Empty pipeline class
 6789 pipe_class pipe_class_empty()
 6790 %{
 6791   single_instruction;
 6792   fixed_latency(0);
 6793 %}
 6794 
 6795 // Default pipeline class.
 6796 pipe_class pipe_class_default()
 6797 %{
 6798   single_instruction;
 6799   fixed_latency(2);
 6800 %}
 6801 
 6802 // Pipeline class for compares.
 6803 pipe_class pipe_class_compare()
 6804 %{
 6805   single_instruction;
 6806   fixed_latency(16);
 6807 %}
 6808 
 6809 // Pipeline class for memory operations.
 6810 pipe_class pipe_class_memory()
 6811 %{
 6812   single_instruction;
 6813   fixed_latency(16);
 6814 %}
 6815 
 6816 // Pipeline class for call.
 6817 pipe_class pipe_class_call()
 6818 %{
 6819   single_instruction;
 6820   fixed_latency(100);
 6821 %}
 6822 
 6823 // Define the class for the Nop node.
 6824 define %{
 6825    MachNop = pipe_class_empty;
 6826 %}
 6827 
 6828 %}
 6829 //----------INSTRUCTIONS-------------------------------------------------------
 6830 //
 6831 // match      -- States which machine-independent subtree may be replaced
 6832 //               by this instruction.
 6833 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6834 //               selection to identify a minimum cost tree of machine
 6835 //               instructions that matches a tree of machine-independent
 6836 //               instructions.
 6837 // format     -- A string providing the disassembly for this instruction.
 6838 //               The value of an instruction&#39;s operand may be inserted
 6839 //               by referring to it with a &#39;$&#39; prefix.
 6840 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6841 //               to within an encode class as $primary, $secondary, and $tertiary
 6842 //               rrspectively.  The primary opcode is commonly used to
 6843 //               indicate the type of machine instruction, while secondary
 6844 //               and tertiary are often used for prefix options or addressing
 6845 //               modes.
 6846 // ins_encode -- A list of encode classes with parameters. The encode class
 6847 //               name must have been defined in an &#39;enc_class&#39; specification
 6848 //               in the encode section of the architecture description.
 6849 
 6850 // ============================================================================
 6851 // Memory (Load/Store) Instructions
 6852 
 6853 // Load Instructions
 6854 
 6855 // Load Byte (8 bit signed)
 6856 instruct loadB(iRegINoSp dst, memory1 mem)
 6857 %{
 6858   match(Set dst (LoadB mem));
 6859   predicate(!needs_acquiring_load(n));
 6860 
 6861   ins_cost(4 * INSN_COST);
 6862   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6863 
 6864   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6865 
 6866   ins_pipe(iload_reg_mem);
 6867 %}
 6868 
 6869 // Load Byte (8 bit signed) into long
 6870 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6871 %{
 6872   match(Set dst (ConvI2L (LoadB mem)));
 6873   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6874 
 6875   ins_cost(4 * INSN_COST);
 6876   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6877 
 6878   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6879 
 6880   ins_pipe(iload_reg_mem);
 6881 %}
 6882 
 6883 // Load Byte (8 bit unsigned)
 6884 instruct loadUB(iRegINoSp dst, memory1 mem)
 6885 %{
 6886   match(Set dst (LoadUB mem));
 6887   predicate(!needs_acquiring_load(n));
 6888 
 6889   ins_cost(4 * INSN_COST);
 6890   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6891 
 6892   ins_encode(aarch64_enc_ldrb(dst, mem));
 6893 
 6894   ins_pipe(iload_reg_mem);
 6895 %}
 6896 
 6897 // Load Byte (8 bit unsigned) into long
 6898 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6899 %{
 6900   match(Set dst (ConvI2L (LoadUB mem)));
 6901   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6902 
 6903   ins_cost(4 * INSN_COST);
 6904   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6905 
 6906   ins_encode(aarch64_enc_ldrb(dst, mem));
 6907 
 6908   ins_pipe(iload_reg_mem);
 6909 %}
 6910 
 6911 // Load Short (16 bit signed)
 6912 instruct loadS(iRegINoSp dst, memory2 mem)
 6913 %{
 6914   match(Set dst (LoadS mem));
 6915   predicate(!needs_acquiring_load(n));
 6916 
 6917   ins_cost(4 * INSN_COST);
 6918   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6919 
 6920   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6921 
 6922   ins_pipe(iload_reg_mem);
 6923 %}
 6924 
 6925 // Load Short (16 bit signed) into long
 6926 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6927 %{
 6928   match(Set dst (ConvI2L (LoadS mem)));
 6929   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6930 
 6931   ins_cost(4 * INSN_COST);
 6932   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6933 
 6934   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6935 
 6936   ins_pipe(iload_reg_mem);
 6937 %}
 6938 
 6939 // Load Char (16 bit unsigned)
 6940 instruct loadUS(iRegINoSp dst, memory2 mem)
 6941 %{
 6942   match(Set dst (LoadUS mem));
 6943   predicate(!needs_acquiring_load(n));
 6944 
 6945   ins_cost(4 * INSN_COST);
 6946   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6947 
 6948   ins_encode(aarch64_enc_ldrh(dst, mem));
 6949 
 6950   ins_pipe(iload_reg_mem);
 6951 %}
 6952 
 6953 // Load Short/Char (16 bit unsigned) into long
 6954 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6955 %{
 6956   match(Set dst (ConvI2L (LoadUS mem)));
 6957   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6958 
 6959   ins_cost(4 * INSN_COST);
 6960   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6961 
 6962   ins_encode(aarch64_enc_ldrh(dst, mem));
 6963 
 6964   ins_pipe(iload_reg_mem);
 6965 %}
 6966 
 6967 // Load Integer (32 bit signed)
 6968 instruct loadI(iRegINoSp dst, memory4 mem)
 6969 %{
 6970   match(Set dst (LoadI mem));
 6971   predicate(!needs_acquiring_load(n));
 6972 
 6973   ins_cost(4 * INSN_COST);
 6974   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6975 
 6976   ins_encode(aarch64_enc_ldrw(dst, mem));
 6977 
 6978   ins_pipe(iload_reg_mem);
 6979 %}
 6980 
 6981 // Load Integer (32 bit signed) into long
 6982 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6983 %{
 6984   match(Set dst (ConvI2L (LoadI mem)));
 6985   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6986 
 6987   ins_cost(4 * INSN_COST);
 6988   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6989 
 6990   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6991 
 6992   ins_pipe(iload_reg_mem);
 6993 %}
 6994 
 6995 // Load Integer (32 bit unsigned) into long
 6996 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6997 %{
 6998   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6999   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 7000 
 7001   ins_cost(4 * INSN_COST);
 7002   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7003 
 7004   ins_encode(aarch64_enc_ldrw(dst, mem));
 7005 
 7006   ins_pipe(iload_reg_mem);
 7007 %}
 7008 
 7009 // Load Long (64 bit signed)
 7010 instruct loadL(iRegLNoSp dst, memory8 mem)
 7011 %{
 7012   match(Set dst (LoadL mem));
 7013   predicate(!needs_acquiring_load(n));
 7014 
 7015   ins_cost(4 * INSN_COST);
 7016   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7017 
 7018   ins_encode(aarch64_enc_ldr(dst, mem));
 7019 
 7020   ins_pipe(iload_reg_mem);
 7021 %}
 7022 
 7023 // Load Range
 7024 instruct loadRange(iRegINoSp dst, memory4 mem)
 7025 %{
 7026   match(Set dst (LoadRange mem));
 7027 
 7028   ins_cost(4 * INSN_COST);
 7029   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7030 
 7031   ins_encode(aarch64_enc_ldrw(dst, mem));
 7032 
 7033   ins_pipe(iload_reg_mem);
 7034 %}
 7035 
 7036 // Load Pointer
 7037 instruct loadP(iRegPNoSp dst, memory8 mem)
 7038 %{
 7039   match(Set dst (LoadP mem));
 7040   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7041 
 7042   ins_cost(4 * INSN_COST);
 7043   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7044 
 7045   ins_encode(aarch64_enc_ldr(dst, mem));
 7046 
 7047   ins_pipe(iload_reg_mem);
 7048 %}
 7049 
 7050 // Load Compressed Pointer
 7051 instruct loadN(iRegNNoSp dst, memory4 mem)
 7052 %{
 7053   match(Set dst (LoadN mem));
 7054   predicate(!needs_acquiring_load(n));
 7055 
 7056   ins_cost(4 * INSN_COST);
 7057   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7058 
 7059   ins_encode(aarch64_enc_ldrw(dst, mem));
 7060 
 7061   ins_pipe(iload_reg_mem);
 7062 %}
 7063 
 7064 // Load Klass Pointer
 7065 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7066 %{
 7067   match(Set dst (LoadKlass mem));
 7068   predicate(!needs_acquiring_load(n));
 7069 
 7070   ins_cost(4 * INSN_COST);
 7071   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7072 
 7073   ins_encode(aarch64_enc_ldr(dst, mem));
 7074 
 7075   ins_pipe(iload_reg_mem);
 7076 %}
 7077 
 7078 // Load Narrow Klass Pointer
 7079 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7080 %{
 7081   match(Set dst (LoadNKlass mem));
 7082   predicate(!needs_acquiring_load(n));
 7083 
 7084   ins_cost(4 * INSN_COST);
 7085   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7086 
 7087   ins_encode(aarch64_enc_ldrw(dst, mem));
 7088 
 7089   ins_pipe(iload_reg_mem);
 7090 %}
 7091 
 7092 // Load Float
 7093 instruct loadF(vRegF dst, memory4 mem)
 7094 %{
 7095   match(Set dst (LoadF mem));
 7096   predicate(!needs_acquiring_load(n));
 7097 
 7098   ins_cost(4 * INSN_COST);
 7099   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7100 
 7101   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7102 
 7103   ins_pipe(pipe_class_memory);
 7104 %}
 7105 
 7106 // Load Double
 7107 instruct loadD(vRegD dst, memory8 mem)
 7108 %{
 7109   match(Set dst (LoadD mem));
 7110   predicate(!needs_acquiring_load(n));
 7111 
 7112   ins_cost(4 * INSN_COST);
 7113   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7114 
 7115   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7116 
 7117   ins_pipe(pipe_class_memory);
 7118 %}
 7119 
 7120 
 7121 // Load Int Constant
 7122 instruct loadConI(iRegINoSp dst, immI src)
 7123 %{
 7124   match(Set dst src);
 7125 
 7126   ins_cost(INSN_COST);
 7127   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7128 
 7129   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7130 
 7131   ins_pipe(ialu_imm);
 7132 %}
 7133 
 7134 // Load Long Constant
 7135 instruct loadConL(iRegLNoSp dst, immL src)
 7136 %{
 7137   match(Set dst src);
 7138 
 7139   ins_cost(INSN_COST);
 7140   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7141 
 7142   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7143 
 7144   ins_pipe(ialu_imm);
 7145 %}
 7146 
 7147 // Load Pointer Constant
 7148 
 7149 instruct loadConP(iRegPNoSp dst, immP con)
 7150 %{
 7151   match(Set dst con);
 7152 
 7153   ins_cost(INSN_COST * 4);
 7154   format %{
 7155     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7156   %}
 7157 
 7158   ins_encode(aarch64_enc_mov_p(dst, con));
 7159 
 7160   ins_pipe(ialu_imm);
 7161 %}
 7162 
 7163 // Load Null Pointer Constant
 7164 
 7165 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7166 %{
 7167   match(Set dst con);
 7168 
 7169   ins_cost(INSN_COST);
 7170   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7171 
 7172   ins_encode(aarch64_enc_mov_p0(dst, con));
 7173 
 7174   ins_pipe(ialu_imm);
 7175 %}
 7176 
 7177 // Load Pointer Constant One
 7178 
 7179 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7180 %{
 7181   match(Set dst con);
 7182 
 7183   ins_cost(INSN_COST);
 7184   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7185 
 7186   ins_encode(aarch64_enc_mov_p1(dst, con));
 7187 
 7188   ins_pipe(ialu_imm);
 7189 %}
 7190 
 7191 // Load Byte Map Base Constant
 7192 
 7193 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7194 %{
 7195   match(Set dst con);
 7196 
 7197   ins_cost(INSN_COST);
 7198   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7199 
 7200   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7201 
 7202   ins_pipe(ialu_imm);
 7203 %}
 7204 
 7205 // Load Narrow Pointer Constant
 7206 
 7207 instruct loadConN(iRegNNoSp dst, immN con)
 7208 %{
 7209   match(Set dst con);
 7210 
 7211   ins_cost(INSN_COST * 4);
 7212   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7213 
 7214   ins_encode(aarch64_enc_mov_n(dst, con));
 7215 
 7216   ins_pipe(ialu_imm);
 7217 %}
 7218 
 7219 // Load Narrow Null Pointer Constant
 7220 
 7221 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7222 %{
 7223   match(Set dst con);
 7224 
 7225   ins_cost(INSN_COST);
 7226   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7227 
 7228   ins_encode(aarch64_enc_mov_n0(dst, con));
 7229 
 7230   ins_pipe(ialu_imm);
 7231 %}
 7232 
 7233 // Load Narrow Klass Constant
 7234 
 7235 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7236 %{
 7237   match(Set dst con);
 7238 
 7239   ins_cost(INSN_COST);
 7240   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7241 
 7242   ins_encode(aarch64_enc_mov_nk(dst, con));
 7243 
 7244   ins_pipe(ialu_imm);
 7245 %}
 7246 
 7247 // Load Packed Float Constant
 7248 
 7249 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7250   match(Set dst con);
 7251   ins_cost(INSN_COST * 4);
 7252   format %{ &quot;fmovs  $dst, $con&quot;%}
 7253   ins_encode %{
 7254     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7255   %}
 7256 
 7257   ins_pipe(fp_imm_s);
 7258 %}
 7259 
 7260 // Load Float Constant
 7261 
 7262 instruct loadConF(vRegF dst, immF con) %{
 7263   match(Set dst con);
 7264 
 7265   ins_cost(INSN_COST * 4);
 7266 
 7267   format %{
 7268     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7269   %}
 7270 
 7271   ins_encode %{
 7272     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7273   %}
 7274 
 7275   ins_pipe(fp_load_constant_s);
 7276 %}
 7277 
 7278 // Load Packed Double Constant
 7279 
 7280 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7281   match(Set dst con);
 7282   ins_cost(INSN_COST);
 7283   format %{ &quot;fmovd  $dst, $con&quot;%}
 7284   ins_encode %{
 7285     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7286   %}
 7287 
 7288   ins_pipe(fp_imm_d);
 7289 %}
 7290 
 7291 // Load Double Constant
 7292 
 7293 instruct loadConD(vRegD dst, immD con) %{
 7294   match(Set dst con);
 7295 
 7296   ins_cost(INSN_COST * 5);
 7297   format %{
 7298     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7299   %}
 7300 
 7301   ins_encode %{
 7302     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7303   %}
 7304 
 7305   ins_pipe(fp_load_constant_d);
 7306 %}
 7307 
 7308 // Store Instructions
 7309 
 7310 // Store CMS card-mark Immediate
 7311 instruct storeimmCM0(immI0 zero, memory1 mem)
 7312 %{
 7313   match(Set mem (StoreCM mem zero));
 7314 
 7315   ins_cost(INSN_COST);
 7316   format %{ &quot;storestore (elided)\n\t&quot;
 7317             &quot;strb zr, $mem\t# byte&quot; %}
 7318 
 7319   ins_encode(aarch64_enc_strb0(mem));
 7320 
 7321   ins_pipe(istore_mem);
 7322 %}
 7323 
 7324 // Store CMS card-mark Immediate with intervening StoreStore
 7325 // needed when using CMS with no conditional card marking
 7326 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7327 %{
 7328   match(Set mem (StoreCM mem zero));
 7329 
 7330   ins_cost(INSN_COST * 2);
 7331   format %{ &quot;storestore\n\t&quot;
 7332             &quot;dmb ishst&quot;
 7333             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7334 
 7335   ins_encode(aarch64_enc_strb0_ordered(mem));
 7336 
 7337   ins_pipe(istore_mem);
 7338 %}
 7339 
 7340 // Store Byte
 7341 instruct storeB(iRegIorL2I src, memory1 mem)
 7342 %{
 7343   match(Set mem (StoreB mem src));
 7344   predicate(!needs_releasing_store(n));
 7345 
 7346   ins_cost(INSN_COST);
 7347   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7348 
 7349   ins_encode(aarch64_enc_strb(src, mem));
 7350 
 7351   ins_pipe(istore_reg_mem);
 7352 %}
 7353 
 7354 
 7355 instruct storeimmB0(immI0 zero, memory1 mem)
 7356 %{
 7357   match(Set mem (StoreB mem zero));
 7358   predicate(!needs_releasing_store(n));
 7359 
 7360   ins_cost(INSN_COST);
 7361   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7362 
 7363   ins_encode(aarch64_enc_strb0(mem));
 7364 
 7365   ins_pipe(istore_mem);
 7366 %}
 7367 
 7368 // Store Char/Short
 7369 instruct storeC(iRegIorL2I src, memory2 mem)
 7370 %{
 7371   match(Set mem (StoreC mem src));
 7372   predicate(!needs_releasing_store(n));
 7373 
 7374   ins_cost(INSN_COST);
 7375   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7376 
 7377   ins_encode(aarch64_enc_strh(src, mem));
 7378 
 7379   ins_pipe(istore_reg_mem);
 7380 %}
 7381 
 7382 instruct storeimmC0(immI0 zero, memory2 mem)
 7383 %{
 7384   match(Set mem (StoreC mem zero));
 7385   predicate(!needs_releasing_store(n));
 7386 
 7387   ins_cost(INSN_COST);
 7388   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7389 
 7390   ins_encode(aarch64_enc_strh0(mem));
 7391 
 7392   ins_pipe(istore_mem);
 7393 %}
 7394 
 7395 // Store Integer
 7396 
 7397 instruct storeI(iRegIorL2I src, memory4 mem)
 7398 %{
 7399   match(Set mem(StoreI mem src));
 7400   predicate(!needs_releasing_store(n));
 7401 
 7402   ins_cost(INSN_COST);
 7403   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7404 
 7405   ins_encode(aarch64_enc_strw(src, mem));
 7406 
 7407   ins_pipe(istore_reg_mem);
 7408 %}
 7409 
 7410 instruct storeimmI0(immI0 zero, memory4 mem)
 7411 %{
 7412   match(Set mem(StoreI mem zero));
 7413   predicate(!needs_releasing_store(n));
 7414 
 7415   ins_cost(INSN_COST);
 7416   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7417 
 7418   ins_encode(aarch64_enc_strw0(mem));
 7419 
 7420   ins_pipe(istore_mem);
 7421 %}
 7422 
 7423 // Store Long (64 bit signed)
 7424 instruct storeL(iRegL src, memory8 mem)
 7425 %{
 7426   match(Set mem (StoreL mem src));
 7427   predicate(!needs_releasing_store(n));
 7428 
 7429   ins_cost(INSN_COST);
 7430   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7431 
 7432   ins_encode(aarch64_enc_str(src, mem));
 7433 
 7434   ins_pipe(istore_reg_mem);
 7435 %}
 7436 
 7437 // Store Long (64 bit signed)
 7438 instruct storeimmL0(immL0 zero, memory8 mem)
 7439 %{
 7440   match(Set mem (StoreL mem zero));
 7441   predicate(!needs_releasing_store(n));
 7442 
 7443   ins_cost(INSN_COST);
 7444   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7445 
 7446   ins_encode(aarch64_enc_str0(mem));
 7447 
 7448   ins_pipe(istore_mem);
 7449 %}
 7450 
 7451 // Store Pointer
 7452 instruct storeP(iRegP src, memory8 mem)
 7453 %{
 7454   match(Set mem (StoreP mem src));
 7455   predicate(!needs_releasing_store(n));
 7456 
 7457   ins_cost(INSN_COST);
 7458   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7459 
 7460   ins_encode(aarch64_enc_str(src, mem));
 7461 
 7462   ins_pipe(istore_reg_mem);
 7463 %}
 7464 
 7465 // Store Pointer
 7466 instruct storeimmP0(immP0 zero, memory8 mem)
 7467 %{
 7468   match(Set mem (StoreP mem zero));
 7469   predicate(!needs_releasing_store(n));
 7470 
 7471   ins_cost(INSN_COST);
 7472   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7473 
 7474   ins_encode(aarch64_enc_str0(mem));
 7475 
 7476   ins_pipe(istore_mem);
 7477 %}
 7478 
 7479 // Store Compressed Pointer
 7480 instruct storeN(iRegN src, memory4 mem)
 7481 %{
 7482   match(Set mem (StoreN mem src));
 7483   predicate(!needs_releasing_store(n));
 7484 
 7485   ins_cost(INSN_COST);
 7486   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7487 
 7488   ins_encode(aarch64_enc_strw(src, mem));
 7489 
 7490   ins_pipe(istore_reg_mem);
 7491 %}
 7492 
 7493 instruct storeImmN0(iRegIHeapbase heapbase, immN0 zero, memory4 mem)
 7494 %{
 7495   match(Set mem (StoreN mem zero));
 7496   predicate(CompressedOops::base() == NULL &amp;&amp;
 7497             CompressedKlassPointers::base() == NULL &amp;&amp;
 7498             (!needs_releasing_store(n)));
 7499 
 7500   ins_cost(INSN_COST);
 7501   format %{ &quot;strw  rheapbase, $mem\t# compressed ptr (rheapbase==0)&quot; %}
 7502 
 7503   ins_encode(aarch64_enc_strw(heapbase, mem));
 7504 
 7505   ins_pipe(istore_reg_mem);
 7506 %}
 7507 
 7508 // Store Float
 7509 instruct storeF(vRegF src, memory4 mem)
 7510 %{
 7511   match(Set mem (StoreF mem src));
 7512   predicate(!needs_releasing_store(n));
 7513 
 7514   ins_cost(INSN_COST);
 7515   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7516 
 7517   ins_encode( aarch64_enc_strs(src, mem) );
 7518 
 7519   ins_pipe(pipe_class_memory);
 7520 %}
 7521 
 7522 // TODO
 7523 // implement storeImmF0 and storeFImmPacked
 7524 
 7525 // Store Double
 7526 instruct storeD(vRegD src, memory8 mem)
 7527 %{
 7528   match(Set mem (StoreD mem src));
 7529   predicate(!needs_releasing_store(n));
 7530 
 7531   ins_cost(INSN_COST);
 7532   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7533 
 7534   ins_encode( aarch64_enc_strd(src, mem) );
 7535 
 7536   ins_pipe(pipe_class_memory);
 7537 %}
 7538 
 7539 // Store Compressed Klass Pointer
 7540 instruct storeNKlass(iRegN src, memory4 mem)
 7541 %{
 7542   predicate(!needs_releasing_store(n));
 7543   match(Set mem (StoreNKlass mem src));
 7544 
 7545   ins_cost(INSN_COST);
 7546   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7547 
 7548   ins_encode(aarch64_enc_strw(src, mem));
 7549 
 7550   ins_pipe(istore_reg_mem);
 7551 %}
 7552 
 7553 // TODO
 7554 // implement storeImmD0 and storeDImmPacked
 7555 
 7556 // prefetch instructions
 7557 // Must be safe to execute with invalid address (cannot fault).
 7558 
 7559 instruct prefetchalloc( memory8 mem ) %{
 7560   match(PrefetchAllocation mem);
 7561 
 7562   ins_cost(INSN_COST);
 7563   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7564 
 7565   ins_encode( aarch64_enc_prefetchw(mem) );
 7566 
 7567   ins_pipe(iload_prefetch);
 7568 %}
 7569 
 7570 //  ---------------- volatile loads and stores ----------------
 7571 
 7572 // Load Byte (8 bit signed)
 7573 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7574 %{
 7575   match(Set dst (LoadB mem));
 7576 
 7577   ins_cost(VOLATILE_REF_COST);
 7578   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7579 
 7580   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7581 
 7582   ins_pipe(pipe_serial);
 7583 %}
 7584 
 7585 // Load Byte (8 bit signed) into long
 7586 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7587 %{
 7588   match(Set dst (ConvI2L (LoadB mem)));
 7589 
 7590   ins_cost(VOLATILE_REF_COST);
 7591   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7592 
 7593   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7594 
 7595   ins_pipe(pipe_serial);
 7596 %}
 7597 
 7598 // Load Byte (8 bit unsigned)
 7599 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7600 %{
 7601   match(Set dst (LoadUB mem));
 7602 
 7603   ins_cost(VOLATILE_REF_COST);
 7604   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7605 
 7606   ins_encode(aarch64_enc_ldarb(dst, mem));
 7607 
 7608   ins_pipe(pipe_serial);
 7609 %}
 7610 
 7611 // Load Byte (8 bit unsigned) into long
 7612 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7613 %{
 7614   match(Set dst (ConvI2L (LoadUB mem)));
 7615 
 7616   ins_cost(VOLATILE_REF_COST);
 7617   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7618 
 7619   ins_encode(aarch64_enc_ldarb(dst, mem));
 7620 
 7621   ins_pipe(pipe_serial);
 7622 %}
 7623 
 7624 // Load Short (16 bit signed)
 7625 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7626 %{
 7627   match(Set dst (LoadS mem));
 7628 
 7629   ins_cost(VOLATILE_REF_COST);
 7630   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7631 
 7632   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7633 
 7634   ins_pipe(pipe_serial);
 7635 %}
 7636 
 7637 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7638 %{
 7639   match(Set dst (LoadUS mem));
 7640 
 7641   ins_cost(VOLATILE_REF_COST);
 7642   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7643 
 7644   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7645 
 7646   ins_pipe(pipe_serial);
 7647 %}
 7648 
 7649 // Load Short/Char (16 bit unsigned) into long
 7650 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7651 %{
 7652   match(Set dst (ConvI2L (LoadUS mem)));
 7653 
 7654   ins_cost(VOLATILE_REF_COST);
 7655   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7656 
 7657   ins_encode(aarch64_enc_ldarh(dst, mem));
 7658 
 7659   ins_pipe(pipe_serial);
 7660 %}
 7661 
 7662 // Load Short/Char (16 bit signed) into long
 7663 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7664 %{
 7665   match(Set dst (ConvI2L (LoadS mem)));
 7666 
 7667   ins_cost(VOLATILE_REF_COST);
 7668   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7669 
 7670   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7671 
 7672   ins_pipe(pipe_serial);
 7673 %}
 7674 
 7675 // Load Integer (32 bit signed)
 7676 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7677 %{
 7678   match(Set dst (LoadI mem));
 7679 
 7680   ins_cost(VOLATILE_REF_COST);
 7681   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7682 
 7683   ins_encode(aarch64_enc_ldarw(dst, mem));
 7684 
 7685   ins_pipe(pipe_serial);
 7686 %}
 7687 
 7688 // Load Integer (32 bit unsigned) into long
 7689 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7690 %{
 7691   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7692 
 7693   ins_cost(VOLATILE_REF_COST);
 7694   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7695 
 7696   ins_encode(aarch64_enc_ldarw(dst, mem));
 7697 
 7698   ins_pipe(pipe_serial);
 7699 %}
 7700 
 7701 // Load Long (64 bit signed)
 7702 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7703 %{
 7704   match(Set dst (LoadL mem));
 7705 
 7706   ins_cost(VOLATILE_REF_COST);
 7707   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7708 
 7709   ins_encode(aarch64_enc_ldar(dst, mem));
 7710 
 7711   ins_pipe(pipe_serial);
 7712 %}
 7713 
 7714 // Load Pointer
 7715 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7716 %{
 7717   match(Set dst (LoadP mem));
 7718   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7719 
 7720   ins_cost(VOLATILE_REF_COST);
 7721   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7722 
 7723   ins_encode(aarch64_enc_ldar(dst, mem));
 7724 
 7725   ins_pipe(pipe_serial);
 7726 %}
 7727 
 7728 // Load Compressed Pointer
 7729 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7730 %{
 7731   match(Set dst (LoadN mem));
 7732 
 7733   ins_cost(VOLATILE_REF_COST);
 7734   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7735 
 7736   ins_encode(aarch64_enc_ldarw(dst, mem));
 7737 
 7738   ins_pipe(pipe_serial);
 7739 %}
 7740 
 7741 // Load Float
 7742 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7743 %{
 7744   match(Set dst (LoadF mem));
 7745 
 7746   ins_cost(VOLATILE_REF_COST);
 7747   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7748 
 7749   ins_encode( aarch64_enc_fldars(dst, mem) );
 7750 
 7751   ins_pipe(pipe_serial);
 7752 %}
 7753 
 7754 // Load Double
 7755 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7756 %{
 7757   match(Set dst (LoadD mem));
 7758 
 7759   ins_cost(VOLATILE_REF_COST);
 7760   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7761 
 7762   ins_encode( aarch64_enc_fldard(dst, mem) );
 7763 
 7764   ins_pipe(pipe_serial);
 7765 %}
 7766 
 7767 // Store Byte
 7768 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7769 %{
 7770   match(Set mem (StoreB mem src));
 7771 
 7772   ins_cost(VOLATILE_REF_COST);
 7773   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7774 
 7775   ins_encode(aarch64_enc_stlrb(src, mem));
 7776 
 7777   ins_pipe(pipe_class_memory);
 7778 %}
 7779 
 7780 // Store Char/Short
 7781 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7782 %{
 7783   match(Set mem (StoreC mem src));
 7784 
 7785   ins_cost(VOLATILE_REF_COST);
 7786   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7787 
 7788   ins_encode(aarch64_enc_stlrh(src, mem));
 7789 
 7790   ins_pipe(pipe_class_memory);
 7791 %}
 7792 
 7793 // Store Integer
 7794 
 7795 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7796 %{
 7797   match(Set mem(StoreI mem src));
 7798 
 7799   ins_cost(VOLATILE_REF_COST);
 7800   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7801 
 7802   ins_encode(aarch64_enc_stlrw(src, mem));
 7803 
 7804   ins_pipe(pipe_class_memory);
 7805 %}
 7806 
 7807 // Store Long (64 bit signed)
 7808 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7809 %{
 7810   match(Set mem (StoreL mem src));
 7811 
 7812   ins_cost(VOLATILE_REF_COST);
 7813   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7814 
 7815   ins_encode(aarch64_enc_stlr(src, mem));
 7816 
 7817   ins_pipe(pipe_class_memory);
 7818 %}
 7819 
 7820 // Store Pointer
 7821 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7822 %{
 7823   match(Set mem (StoreP mem src));
 7824 
 7825   ins_cost(VOLATILE_REF_COST);
 7826   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7827 
 7828   ins_encode(aarch64_enc_stlr(src, mem));
 7829 
 7830   ins_pipe(pipe_class_memory);
 7831 %}
 7832 
 7833 // Store Compressed Pointer
 7834 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7835 %{
 7836   match(Set mem (StoreN mem src));
 7837 
 7838   ins_cost(VOLATILE_REF_COST);
 7839   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7840 
 7841   ins_encode(aarch64_enc_stlrw(src, mem));
 7842 
 7843   ins_pipe(pipe_class_memory);
 7844 %}
 7845 
 7846 // Store Float
 7847 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7848 %{
 7849   match(Set mem (StoreF mem src));
 7850 
 7851   ins_cost(VOLATILE_REF_COST);
 7852   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7853 
 7854   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7855 
 7856   ins_pipe(pipe_class_memory);
 7857 %}
 7858 
 7859 // TODO
 7860 // implement storeImmF0 and storeFImmPacked
 7861 
 7862 // Store Double
 7863 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7864 %{
 7865   match(Set mem (StoreD mem src));
 7866 
 7867   ins_cost(VOLATILE_REF_COST);
 7868   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7869 
 7870   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7871 
 7872   ins_pipe(pipe_class_memory);
 7873 %}
 7874 
 7875 //  ---------------- end of volatile loads and stores ----------------
 7876 
 7877 instruct cacheWB(indirect addr)
 7878 %{
 7879   predicate(VM_Version::supports_data_cache_line_flush());
 7880   match(CacheWB addr);
 7881 
 7882   ins_cost(100);
 7883   format %{&quot;cache wb $addr&quot; %}
 7884   ins_encode %{
 7885     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7886     assert($addr$$disp == 0, &quot;should be&quot;);
 7887     __ cache_wb(Address($addr$$base$$Register, 0));
 7888   %}
 7889   ins_pipe(pipe_slow); // XXX
 7890 %}
 7891 
 7892 instruct cacheWBPreSync()
 7893 %{
 7894   predicate(VM_Version::supports_data_cache_line_flush());
 7895   match(CacheWBPreSync);
 7896 
 7897   ins_cost(100);
 7898   format %{&quot;cache wb presync&quot; %}
 7899   ins_encode %{
 7900     __ cache_wbsync(true);
 7901   %}
 7902   ins_pipe(pipe_slow); // XXX
 7903 %}
 7904 
 7905 instruct cacheWBPostSync()
 7906 %{
 7907   predicate(VM_Version::supports_data_cache_line_flush());
 7908   match(CacheWBPostSync);
 7909 
 7910   ins_cost(100);
 7911   format %{&quot;cache wb postsync&quot; %}
 7912   ins_encode %{
 7913     __ cache_wbsync(false);
 7914   %}
 7915   ins_pipe(pipe_slow); // XXX
 7916 %}
 7917 
 7918 // ============================================================================
 7919 // BSWAP Instructions
 7920 
 7921 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7922   match(Set dst (ReverseBytesI src));
 7923 
 7924   ins_cost(INSN_COST);
 7925   format %{ &quot;revw  $dst, $src&quot; %}
 7926 
 7927   ins_encode %{
 7928     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7929   %}
 7930 
 7931   ins_pipe(ialu_reg);
 7932 %}
 7933 
 7934 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7935   match(Set dst (ReverseBytesL src));
 7936 
 7937   ins_cost(INSN_COST);
 7938   format %{ &quot;rev  $dst, $src&quot; %}
 7939 
 7940   ins_encode %{
 7941     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7942   %}
 7943 
 7944   ins_pipe(ialu_reg);
 7945 %}
 7946 
 7947 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7948   match(Set dst (ReverseBytesUS src));
 7949 
 7950   ins_cost(INSN_COST);
 7951   format %{ &quot;rev16w  $dst, $src&quot; %}
 7952 
 7953   ins_encode %{
 7954     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7955   %}
 7956 
 7957   ins_pipe(ialu_reg);
 7958 %}
 7959 
 7960 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7961   match(Set dst (ReverseBytesS src));
 7962 
 7963   ins_cost(INSN_COST);
 7964   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7965             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7966 
 7967   ins_encode %{
 7968     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7969     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7970   %}
 7971 
 7972   ins_pipe(ialu_reg);
 7973 %}
 7974 
 7975 // ============================================================================
 7976 // Zero Count Instructions
 7977 
 7978 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7979   match(Set dst (CountLeadingZerosI src));
 7980 
 7981   ins_cost(INSN_COST);
 7982   format %{ &quot;clzw  $dst, $src&quot; %}
 7983   ins_encode %{
 7984     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7985   %}
 7986 
 7987   ins_pipe(ialu_reg);
 7988 %}
 7989 
 7990 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7991   match(Set dst (CountLeadingZerosL src));
 7992 
 7993   ins_cost(INSN_COST);
 7994   format %{ &quot;clz   $dst, $src&quot; %}
 7995   ins_encode %{
 7996     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 7997   %}
 7998 
 7999   ins_pipe(ialu_reg);
 8000 %}
 8001 
 8002 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8003   match(Set dst (CountTrailingZerosI src));
 8004 
 8005   ins_cost(INSN_COST * 2);
 8006   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8007             &quot;clzw   $dst, $dst&quot; %}
 8008   ins_encode %{
 8009     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8010     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8011   %}
 8012 
 8013   ins_pipe(ialu_reg);
 8014 %}
 8015 
 8016 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8017   match(Set dst (CountTrailingZerosL src));
 8018 
 8019   ins_cost(INSN_COST * 2);
 8020   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8021             &quot;clz    $dst, $dst&quot; %}
 8022   ins_encode %{
 8023     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8024     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8025   %}
 8026 
 8027   ins_pipe(ialu_reg);
 8028 %}
 8029 
 8030 //---------- Population Count Instructions -------------------------------------
 8031 //
 8032 
 8033 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8034   predicate(UsePopCountInstruction);
 8035   match(Set dst (PopCountI src));
 8036   effect(TEMP tmp);
 8037   ins_cost(INSN_COST * 13);
 8038 
 8039   format %{ &quot;movw   $src, $src\n\t&quot;
 8040             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8041             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8042             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8043             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8044   ins_encode %{
 8045     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8046     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8047     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8048     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8049     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8050   %}
 8051 
 8052   ins_pipe(pipe_class_default);
 8053 %}
 8054 
 8055 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8056   predicate(UsePopCountInstruction);
 8057   match(Set dst (PopCountI (LoadI mem)));
 8058   effect(TEMP tmp);
 8059   ins_cost(INSN_COST * 13);
 8060 
 8061   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8062             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8063             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8064             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8065   ins_encode %{
 8066     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8067     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8068               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8069     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8070     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8071     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8072   %}
 8073 
 8074   ins_pipe(pipe_class_default);
 8075 %}
 8076 
 8077 // Note: Long.bitCount(long) returns an int.
 8078 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8079   predicate(UsePopCountInstruction);
 8080   match(Set dst (PopCountL src));
 8081   effect(TEMP tmp);
 8082   ins_cost(INSN_COST * 13);
 8083 
 8084   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8085             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8086             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8087             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8088   ins_encode %{
 8089     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8090     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8091     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8092     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8093   %}
 8094 
 8095   ins_pipe(pipe_class_default);
 8096 %}
 8097 
 8098 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8099   predicate(UsePopCountInstruction);
 8100   match(Set dst (PopCountL (LoadL mem)));
 8101   effect(TEMP tmp);
 8102   ins_cost(INSN_COST * 13);
 8103 
 8104   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8105             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8106             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8107             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8108   ins_encode %{
 8109     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8110     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8111               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8112     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8113     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8114     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8115   %}
 8116 
 8117   ins_pipe(pipe_class_default);
 8118 %}
 8119 
 8120 // ============================================================================
 8121 // MemBar Instruction
 8122 
 8123 instruct load_fence() %{
 8124   match(LoadFence);
 8125   ins_cost(VOLATILE_REF_COST);
 8126 
 8127   format %{ &quot;load_fence&quot; %}
 8128 
 8129   ins_encode %{
 8130     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8131   %}
 8132   ins_pipe(pipe_serial);
 8133 %}
 8134 
 8135 instruct unnecessary_membar_acquire() %{
 8136   predicate(unnecessary_acquire(n));
 8137   match(MemBarAcquire);
 8138   ins_cost(0);
 8139 
 8140   format %{ &quot;membar_acquire (elided)&quot; %}
 8141 
 8142   ins_encode %{
 8143     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8144   %}
 8145 
 8146   ins_pipe(pipe_class_empty);
 8147 %}
 8148 
 8149 instruct membar_acquire() %{
 8150   match(MemBarAcquire);
 8151   ins_cost(VOLATILE_REF_COST);
 8152 
 8153   format %{ &quot;membar_acquire\n\t&quot;
 8154             &quot;dmb ish&quot; %}
 8155 
 8156   ins_encode %{
 8157     __ block_comment(&quot;membar_acquire&quot;);
 8158     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8159   %}
 8160 
 8161   ins_pipe(pipe_serial);
 8162 %}
 8163 
 8164 
 8165 instruct membar_acquire_lock() %{
 8166   match(MemBarAcquireLock);
 8167   ins_cost(VOLATILE_REF_COST);
 8168 
 8169   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8170 
 8171   ins_encode %{
 8172     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8173   %}
 8174 
 8175   ins_pipe(pipe_serial);
 8176 %}
 8177 
 8178 instruct store_fence() %{
 8179   match(StoreFence);
 8180   ins_cost(VOLATILE_REF_COST);
 8181 
 8182   format %{ &quot;store_fence&quot; %}
 8183 
 8184   ins_encode %{
 8185     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8186   %}
 8187   ins_pipe(pipe_serial);
 8188 %}
 8189 
 8190 instruct unnecessary_membar_release() %{
 8191   predicate(unnecessary_release(n));
 8192   match(MemBarRelease);
 8193   ins_cost(0);
 8194 
 8195   format %{ &quot;membar_release (elided)&quot; %}
 8196 
 8197   ins_encode %{
 8198     __ block_comment(&quot;membar_release (elided)&quot;);
 8199   %}
 8200   ins_pipe(pipe_serial);
 8201 %}
 8202 
 8203 instruct membar_release() %{
 8204   match(MemBarRelease);
 8205   ins_cost(VOLATILE_REF_COST);
 8206 
 8207   format %{ &quot;membar_release\n\t&quot;
 8208             &quot;dmb ish&quot; %}
 8209 
 8210   ins_encode %{
 8211     __ block_comment(&quot;membar_release&quot;);
 8212     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8213   %}
 8214   ins_pipe(pipe_serial);
 8215 %}
 8216 
 8217 instruct membar_storestore() %{
 8218   match(MemBarStoreStore);
 8219   ins_cost(VOLATILE_REF_COST);
 8220 
 8221   format %{ &quot;MEMBAR-store-store&quot; %}
 8222 
 8223   ins_encode %{
 8224     __ membar(Assembler::StoreStore);
 8225   %}
 8226   ins_pipe(pipe_serial);
 8227 %}
 8228 
 8229 instruct membar_release_lock() %{
 8230   match(MemBarReleaseLock);
 8231   ins_cost(VOLATILE_REF_COST);
 8232 
 8233   format %{ &quot;membar_release_lock (elided)&quot; %}
 8234 
 8235   ins_encode %{
 8236     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8237   %}
 8238 
 8239   ins_pipe(pipe_serial);
 8240 %}
 8241 
 8242 instruct unnecessary_membar_volatile() %{
 8243   predicate(unnecessary_volatile(n));
 8244   match(MemBarVolatile);
 8245   ins_cost(0);
 8246 
 8247   format %{ &quot;membar_volatile (elided)&quot; %}
 8248 
 8249   ins_encode %{
 8250     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8251   %}
 8252 
 8253   ins_pipe(pipe_serial);
 8254 %}
 8255 
 8256 instruct membar_volatile() %{
 8257   match(MemBarVolatile);
 8258   ins_cost(VOLATILE_REF_COST*100);
 8259 
 8260   format %{ &quot;membar_volatile\n\t&quot;
 8261              &quot;dmb ish&quot;%}
 8262 
 8263   ins_encode %{
 8264     __ block_comment(&quot;membar_volatile&quot;);
 8265     __ membar(Assembler::StoreLoad);
 8266   %}
 8267 
 8268   ins_pipe(pipe_serial);
 8269 %}
 8270 
 8271 // ============================================================================
 8272 // Cast/Convert Instructions
 8273 
 8274 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8275   match(Set dst (CastX2P src));
 8276 
 8277   ins_cost(INSN_COST);
 8278   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8279 
 8280   ins_encode %{
 8281     if ($dst$$reg != $src$$reg) {
 8282       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8283     }
 8284   %}
 8285 
 8286   ins_pipe(ialu_reg);
 8287 %}
 8288 
 8289 instruct castN2X(iRegLNoSp dst, iRegN src) %{
 8290   match(Set dst (CastP2X src));
 8291 
 8292   ins_cost(INSN_COST);
 8293   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8294 
 8295   ins_encode %{
 8296     if ($dst$$reg != $src$$reg) {
 8297       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8298     }
 8299   %}
 8300 
 8301   ins_pipe(ialu_reg);
 8302 %}
 8303 
 8304 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8305   match(Set dst (CastP2X src));
 8306 
 8307   ins_cost(INSN_COST);
 8308   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8309 
 8310   ins_encode %{
 8311     if ($dst$$reg != $src$$reg) {
 8312       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8313     }
 8314   %}
 8315 
 8316   ins_pipe(ialu_reg);
 8317 %}
 8318 
 8319 instruct castN2I(iRegINoSp dst, iRegN src) %{
 8320   match(Set dst (CastN2I src));
 8321 
 8322   ins_cost(INSN_COST);
 8323   format %{ &quot;movw $dst, $src\t# compressed ptr -&gt; int&quot; %}
 8324 
 8325   ins_encode %{
 8326     if ($dst$$reg != $src$$reg) {
 8327       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8328     }
 8329   %}
 8330 
 8331   ins_pipe(ialu_reg);
 8332 %}
 8333 
 8334 instruct castI2N(iRegNNoSp dst, iRegI src) %{
 8335   match(Set dst (CastI2N src));
 8336 
 8337   ins_cost(INSN_COST);
 8338   format %{ &quot;movw $dst, $src\t# int -&gt; compressed ptr&quot; %}
 8339 
 8340   ins_encode %{
 8341     if ($dst$$reg != $src$$reg) {
 8342       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8343     }
 8344   %}
 8345 
 8346   ins_pipe(ialu_reg);
 8347 %}
 8348 
 8349 
 8350 // Convert oop into int for vectors alignment masking
 8351 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8352   match(Set dst (ConvL2I (CastP2X src)));
 8353 
 8354   ins_cost(INSN_COST);
 8355   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8356   ins_encode %{
 8357     __ movw($dst$$Register, $src$$Register);
 8358   %}
 8359 
 8360   ins_pipe(ialu_reg);
 8361 %}
 8362 
 8363 // Convert compressed oop into int for vectors alignment masking
 8364 // in case of 32bit oops (heap &lt; 4Gb).
 8365 instruct convN2I(iRegINoSp dst, iRegN src)
 8366 %{
 8367   predicate(CompressedOops::shift() == 0);
 8368   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8369 
 8370   ins_cost(INSN_COST);
 8371   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8372   ins_encode %{
 8373     __ movw($dst$$Register, $src$$Register);
 8374   %}
 8375 
 8376   ins_pipe(ialu_reg);
 8377 %}
 8378 
 8379 
 8380 // Convert oop pointer into compressed form
 8381 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8382   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8383   match(Set dst (EncodeP src));
 8384   effect(KILL cr);
 8385   ins_cost(INSN_COST * 3);
 8386   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8387   ins_encode %{
 8388     Register s = $src$$Register;
 8389     Register d = $dst$$Register;
 8390     __ encode_heap_oop(d, s);
 8391   %}
 8392   ins_pipe(ialu_reg);
 8393 %}
 8394 
 8395 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8396   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8397   match(Set dst (EncodeP src));
 8398   ins_cost(INSN_COST * 3);
 8399   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8400   ins_encode %{
 8401     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8402   %}
 8403   ins_pipe(ialu_reg);
 8404 %}
 8405 
 8406 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8407   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8408             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8409   match(Set dst (DecodeN src));
 8410   ins_cost(INSN_COST * 3);
 8411   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8412   ins_encode %{
 8413     Register s = $src$$Register;
 8414     Register d = $dst$$Register;
 8415     __ decode_heap_oop(d, s);
 8416   %}
 8417   ins_pipe(ialu_reg);
 8418 %}
 8419 
 8420 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8421   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8422             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8423   match(Set dst (DecodeN src));
 8424   ins_cost(INSN_COST * 3);
 8425   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8426   ins_encode %{
 8427     Register s = $src$$Register;
 8428     Register d = $dst$$Register;
 8429     __ decode_heap_oop_not_null(d, s);
 8430   %}
 8431   ins_pipe(ialu_reg);
 8432 %}
 8433 
 8434 // n.b. AArch64 implementations of encode_klass_not_null and
 8435 // decode_klass_not_null do not modify the flags register so, unlike
 8436 // Intel, we don&#39;t kill CR as a side effect here
 8437 
 8438 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8439   match(Set dst (EncodePKlass src));
 8440 
 8441   ins_cost(INSN_COST * 3);
 8442   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8443 
 8444   ins_encode %{
 8445     Register src_reg = as_Register($src$$reg);
 8446     Register dst_reg = as_Register($dst$$reg);
 8447     __ encode_klass_not_null(dst_reg, src_reg);
 8448   %}
 8449 
 8450    ins_pipe(ialu_reg);
 8451 %}
 8452 
 8453 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8454   match(Set dst (DecodeNKlass src));
 8455 
 8456   ins_cost(INSN_COST * 3);
 8457   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8458 
 8459   ins_encode %{
 8460     Register src_reg = as_Register($src$$reg);
 8461     Register dst_reg = as_Register($dst$$reg);
 8462     if (dst_reg != src_reg) {
 8463       __ decode_klass_not_null(dst_reg, src_reg);
 8464     } else {
 8465       __ decode_klass_not_null(dst_reg);
 8466     }
 8467   %}
 8468 
 8469    ins_pipe(ialu_reg);
 8470 %}
 8471 
 8472 instruct checkCastPP(iRegPNoSp dst)
 8473 %{
 8474   match(Set dst (CheckCastPP dst));
 8475 
 8476   size(0);
 8477   format %{ &quot;# checkcastPP of $dst&quot; %}
 8478   ins_encode(/* empty encoding */);
 8479   ins_pipe(pipe_class_empty);
 8480 %}
 8481 
 8482 instruct castPP(iRegPNoSp dst)
 8483 %{
 8484   match(Set dst (CastPP dst));
 8485 
 8486   size(0);
 8487   format %{ &quot;# castPP of $dst&quot; %}
 8488   ins_encode(/* empty encoding */);
 8489   ins_pipe(pipe_class_empty);
 8490 %}
 8491 
 8492 instruct castII(iRegI dst)
 8493 %{
 8494   match(Set dst (CastII dst));
 8495 
 8496   size(0);
 8497   format %{ &quot;# castII of $dst&quot; %}
 8498   ins_encode(/* empty encoding */);
 8499   ins_cost(0);
 8500   ins_pipe(pipe_class_empty);
 8501 %}
 8502 
 8503 instruct castLL(iRegL dst)
 8504 %{
 8505   match(Set dst (CastLL dst));
 8506 
 8507   size(0);
 8508   format %{ &quot;# castLL of $dst&quot; %}
 8509   ins_encode(/* empty encoding */);
 8510   ins_cost(0);
 8511   ins_pipe(pipe_class_empty);
 8512 %}
 8513 
 8514 // ============================================================================
 8515 // Atomic operation instructions
 8516 //
 8517 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8518 // Store{PIL}Conditional instructions using a normal load for the
 8519 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8520 //
 8521 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8522 // pair to lock object allocations from Eden space when not using
 8523 // TLABs.
 8524 //
 8525 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8526 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8527 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8528 // only for 64-bit.
 8529 //
 8530 // We implement LoadPLocked and StorePLocked instructions using,
 8531 // respectively the AArch64 hw load-exclusive and store-conditional
 8532 // instructions. Whereas we must implement each of
 8533 // Store{IL}Conditional using a CAS which employs a pair of
 8534 // instructions comprising a load-exclusive followed by a
 8535 // store-conditional.
 8536 
 8537 
 8538 // Locked-load (linked load) of the current heap-top
 8539 // used when updating the eden heap top
 8540 // implemented using ldaxr on AArch64
 8541 
 8542 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8543 %{
 8544   match(Set dst (LoadPLocked mem));
 8545 
 8546   ins_cost(VOLATILE_REF_COST);
 8547 
 8548   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8549 
 8550   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8551 
 8552   ins_pipe(pipe_serial);
 8553 %}
 8554 
 8555 // Conditional-store of the updated heap-top.
 8556 // Used during allocation of the shared heap.
 8557 // Sets flag (EQ) on success.
 8558 // implemented using stlxr on AArch64.
 8559 
 8560 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8561 %{
 8562   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8563 
 8564   ins_cost(VOLATILE_REF_COST);
 8565 
 8566  // TODO
 8567  // do we need to do a store-conditional release or can we just use a
 8568  // plain store-conditional?
 8569 
 8570   format %{
 8571     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8572     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8573   %}
 8574 
 8575   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8576 
 8577   ins_pipe(pipe_serial);
 8578 %}
 8579 
 8580 
 8581 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8582 // when attempting to rebias a lock towards the current thread.  We
 8583 // must use the acquire form of cmpxchg in order to guarantee acquire
 8584 // semantics in this case.
 8585 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8586 %{
 8587   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8588 
 8589   ins_cost(VOLATILE_REF_COST);
 8590 
 8591   format %{
 8592     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8593     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8594   %}
 8595 
 8596   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8597 
 8598   ins_pipe(pipe_slow);
 8599 %}
 8600 
 8601 // storeIConditional also has acquire semantics, for no better reason
 8602 // than matching storeLConditional.  At the time of writing this
 8603 // comment storeIConditional was not used anywhere by AArch64.
 8604 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8605 %{
 8606   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8607 
 8608   ins_cost(VOLATILE_REF_COST);
 8609 
 8610   format %{
 8611     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8612     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8613   %}
 8614 
 8615   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8616 
 8617   ins_pipe(pipe_slow);
 8618 %}
 8619 
 8620 // standard CompareAndSwapX when we are using barriers
 8621 // these have higher priority than the rules selected by a predicate
 8622 
 8623 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8624 // can&#39;t match them
 8625 
 8626 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8627 
 8628   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8629   ins_cost(2 * VOLATILE_REF_COST);
 8630 
 8631   effect(KILL cr);
 8632 
 8633   format %{
 8634     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8635     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8636   %}
 8637 
 8638   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8639             aarch64_enc_cset_eq(res));
 8640 
 8641   ins_pipe(pipe_slow);
 8642 %}
 8643 
 8644 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8645 
 8646   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8647   ins_cost(2 * VOLATILE_REF_COST);
 8648 
 8649   effect(KILL cr);
 8650 
 8651   format %{
 8652     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8653     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8654   %}
 8655 
 8656   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8657             aarch64_enc_cset_eq(res));
 8658 
 8659   ins_pipe(pipe_slow);
 8660 %}
 8661 
 8662 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8663 
 8664   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8665   ins_cost(2 * VOLATILE_REF_COST);
 8666 
 8667   effect(KILL cr);
 8668 
 8669  format %{
 8670     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8671     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8672  %}
 8673 
 8674  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8675             aarch64_enc_cset_eq(res));
 8676 
 8677   ins_pipe(pipe_slow);
 8678 %}
 8679 
 8680 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8681 
 8682   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8683   ins_cost(2 * VOLATILE_REF_COST);
 8684 
 8685   effect(KILL cr);
 8686 
 8687  format %{
 8688     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8689     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8690  %}
 8691 
 8692  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8693             aarch64_enc_cset_eq(res));
 8694 
 8695   ins_pipe(pipe_slow);
 8696 %}
 8697 
 8698 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8699 
 8700   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8701   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8702   ins_cost(2 * VOLATILE_REF_COST);
 8703 
 8704   effect(KILL cr);
 8705 
 8706  format %{
 8707     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8708     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8709  %}
 8710 
 8711  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8712             aarch64_enc_cset_eq(res));
 8713 
 8714   ins_pipe(pipe_slow);
 8715 %}
 8716 
 8717 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8718 
 8719   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8720   ins_cost(2 * VOLATILE_REF_COST);
 8721 
 8722   effect(KILL cr);
 8723 
 8724  format %{
 8725     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8726     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8727  %}
 8728 
 8729  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8730             aarch64_enc_cset_eq(res));
 8731 
 8732   ins_pipe(pipe_slow);
 8733 %}
 8734 
 8735 // alternative CompareAndSwapX when we are eliding barriers
 8736 
 8737 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8738 
 8739   predicate(needs_acquiring_load_exclusive(n));
 8740   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8741   ins_cost(VOLATILE_REF_COST);
 8742 
 8743   effect(KILL cr);
 8744 
 8745   format %{
 8746     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8747     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8748   %}
 8749 
 8750   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8751             aarch64_enc_cset_eq(res));
 8752 
 8753   ins_pipe(pipe_slow);
 8754 %}
 8755 
 8756 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8757 
 8758   predicate(needs_acquiring_load_exclusive(n));
 8759   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8760   ins_cost(VOLATILE_REF_COST);
 8761 
 8762   effect(KILL cr);
 8763 
 8764   format %{
 8765     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8766     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8767   %}
 8768 
 8769   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8770             aarch64_enc_cset_eq(res));
 8771 
 8772   ins_pipe(pipe_slow);
 8773 %}
 8774 
 8775 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8776 
 8777   predicate(needs_acquiring_load_exclusive(n));
 8778   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8779   ins_cost(VOLATILE_REF_COST);
 8780 
 8781   effect(KILL cr);
 8782 
 8783  format %{
 8784     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8785     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8786  %}
 8787 
 8788  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8789             aarch64_enc_cset_eq(res));
 8790 
 8791   ins_pipe(pipe_slow);
 8792 %}
 8793 
 8794 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8795 
 8796   predicate(needs_acquiring_load_exclusive(n));
 8797   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8798   ins_cost(VOLATILE_REF_COST);
 8799 
 8800   effect(KILL cr);
 8801 
 8802  format %{
 8803     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8804     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8805  %}
 8806 
 8807  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8808             aarch64_enc_cset_eq(res));
 8809 
 8810   ins_pipe(pipe_slow);
 8811 %}
 8812 
 8813 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8814 
 8815   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8816   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8817   ins_cost(VOLATILE_REF_COST);
 8818 
 8819   effect(KILL cr);
 8820 
 8821  format %{
 8822     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8823     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8824  %}
 8825 
 8826  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8827             aarch64_enc_cset_eq(res));
 8828 
 8829   ins_pipe(pipe_slow);
 8830 %}
 8831 
 8832 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8833 
 8834   predicate(needs_acquiring_load_exclusive(n));
 8835   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8836   ins_cost(VOLATILE_REF_COST);
 8837 
 8838   effect(KILL cr);
 8839 
 8840  format %{
 8841     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8842     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8843  %}
 8844 
 8845  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8846             aarch64_enc_cset_eq(res));
 8847 
 8848   ins_pipe(pipe_slow);
 8849 %}
 8850 
 8851 
 8852 // ---------------------------------------------------------------------
 8853 
 8854 
 8855 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8856 
 8857 // Sundry CAS operations.  Note that release is always true,
 8858 // regardless of the memory ordering of the CAS.  This is because we
 8859 // need the volatile case to be sequentially consistent but there is
 8860 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8861 // can&#39;t check the type of memory ordering here, so we always emit a
 8862 // STLXR.
 8863 
 8864 // This section is generated from aarch64_ad_cas.m4
 8865 
 8866 
 8867 
 8868 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8869   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8870   ins_cost(2 * VOLATILE_REF_COST);
 8871   effect(TEMP_DEF res, KILL cr);
 8872   format %{
 8873     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8874   %}
 8875   ins_encode %{
 8876     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8877                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8878                /*weak*/ false, $res$$Register);
 8879     __ sxtbw($res$$Register, $res$$Register);
 8880   %}
 8881   ins_pipe(pipe_slow);
 8882 %}
 8883 
 8884 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8885   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8886   ins_cost(2 * VOLATILE_REF_COST);
 8887   effect(TEMP_DEF res, KILL cr);
 8888   format %{
 8889     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8890   %}
 8891   ins_encode %{
 8892     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8893                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8894                /*weak*/ false, $res$$Register);
 8895     __ sxthw($res$$Register, $res$$Register);
 8896   %}
 8897   ins_pipe(pipe_slow);
 8898 %}
 8899 
 8900 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8901   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8902   ins_cost(2 * VOLATILE_REF_COST);
 8903   effect(TEMP_DEF res, KILL cr);
 8904   format %{
 8905     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8906   %}
 8907   ins_encode %{
 8908     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8909                Assembler::word, /*acquire*/ false, /*release*/ true,
 8910                /*weak*/ false, $res$$Register);
 8911   %}
 8912   ins_pipe(pipe_slow);
 8913 %}
 8914 
 8915 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8916   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8917   ins_cost(2 * VOLATILE_REF_COST);
 8918   effect(TEMP_DEF res, KILL cr);
 8919   format %{
 8920     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8921   %}
 8922   ins_encode %{
 8923     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8924                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8925                /*weak*/ false, $res$$Register);
 8926   %}
 8927   ins_pipe(pipe_slow);
 8928 %}
 8929 
 8930 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8931   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8932   ins_cost(2 * VOLATILE_REF_COST);
 8933   effect(TEMP_DEF res, KILL cr);
 8934   format %{
 8935     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8936   %}
 8937   ins_encode %{
 8938     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8939                Assembler::word, /*acquire*/ false, /*release*/ true,
 8940                /*weak*/ false, $res$$Register);
 8941   %}
 8942   ins_pipe(pipe_slow);
 8943 %}
 8944 
 8945 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8946   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8947   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8948   ins_cost(2 * VOLATILE_REF_COST);
 8949   effect(TEMP_DEF res, KILL cr);
 8950   format %{
 8951     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8952   %}
 8953   ins_encode %{
 8954     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8955                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8956                /*weak*/ false, $res$$Register);
 8957   %}
 8958   ins_pipe(pipe_slow);
 8959 %}
 8960 
 8961 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8962   predicate(needs_acquiring_load_exclusive(n));
 8963   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8964   ins_cost(VOLATILE_REF_COST);
 8965   effect(TEMP_DEF res, KILL cr);
 8966   format %{
 8967     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8968   %}
 8969   ins_encode %{
 8970     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8971                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8972                /*weak*/ false, $res$$Register);
 8973     __ sxtbw($res$$Register, $res$$Register);
 8974   %}
 8975   ins_pipe(pipe_slow);
 8976 %}
 8977 
 8978 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8979   predicate(needs_acquiring_load_exclusive(n));
 8980   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8981   ins_cost(VOLATILE_REF_COST);
 8982   effect(TEMP_DEF res, KILL cr);
 8983   format %{
 8984     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8985   %}
 8986   ins_encode %{
 8987     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8988                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8989                /*weak*/ false, $res$$Register);
 8990     __ sxthw($res$$Register, $res$$Register);
 8991   %}
 8992   ins_pipe(pipe_slow);
 8993 %}
 8994 
 8995 
 8996 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8997   predicate(needs_acquiring_load_exclusive(n));
 8998   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8999   ins_cost(VOLATILE_REF_COST);
 9000   effect(TEMP_DEF res, KILL cr);
 9001   format %{
 9002     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9003   %}
 9004   ins_encode %{
 9005     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9006                Assembler::word, /*acquire*/ true, /*release*/ true,
 9007                /*weak*/ false, $res$$Register);
 9008   %}
 9009   ins_pipe(pipe_slow);
 9010 %}
 9011 
 9012 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9013   predicate(needs_acquiring_load_exclusive(n));
 9014   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 9015   ins_cost(VOLATILE_REF_COST);
 9016   effect(TEMP_DEF res, KILL cr);
 9017   format %{
 9018     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9019   %}
 9020   ins_encode %{
 9021     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9022                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9023                /*weak*/ false, $res$$Register);
 9024   %}
 9025   ins_pipe(pipe_slow);
 9026 %}
 9027 
 9028 
 9029 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9030   predicate(needs_acquiring_load_exclusive(n));
 9031   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 9032   ins_cost(VOLATILE_REF_COST);
 9033   effect(TEMP_DEF res, KILL cr);
 9034   format %{
 9035     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9036   %}
 9037   ins_encode %{
 9038     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9039                Assembler::word, /*acquire*/ true, /*release*/ true,
 9040                /*weak*/ false, $res$$Register);
 9041   %}
 9042   ins_pipe(pipe_slow);
 9043 %}
 9044 
 9045 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9046   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9047   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9048   ins_cost(VOLATILE_REF_COST);
 9049   effect(TEMP_DEF res, KILL cr);
 9050   format %{
 9051     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9052   %}
 9053   ins_encode %{
 9054     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9055                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9056                /*weak*/ false, $res$$Register);
 9057   %}
 9058   ins_pipe(pipe_slow);
 9059 %}
 9060 
 9061 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9062   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9063   ins_cost(2 * VOLATILE_REF_COST);
 9064   effect(KILL cr);
 9065   format %{
 9066     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9067     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9068   %}
 9069   ins_encode %{
 9070     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9071                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9072                /*weak*/ true, noreg);
 9073     __ csetw($res$$Register, Assembler::EQ);
 9074   %}
 9075   ins_pipe(pipe_slow);
 9076 %}
 9077 
 9078 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9079   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9080   ins_cost(2 * VOLATILE_REF_COST);
 9081   effect(KILL cr);
 9082   format %{
 9083     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9084     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9085   %}
 9086   ins_encode %{
 9087     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9088                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9089                /*weak*/ true, noreg);
 9090     __ csetw($res$$Register, Assembler::EQ);
 9091   %}
 9092   ins_pipe(pipe_slow);
 9093 %}
 9094 
 9095 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9096   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9097   ins_cost(2 * VOLATILE_REF_COST);
 9098   effect(KILL cr);
 9099   format %{
 9100     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9101     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9102   %}
 9103   ins_encode %{
 9104     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9105                Assembler::word, /*acquire*/ false, /*release*/ true,
 9106                /*weak*/ true, noreg);
 9107     __ csetw($res$$Register, Assembler::EQ);
 9108   %}
 9109   ins_pipe(pipe_slow);
 9110 %}
 9111 
 9112 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9113   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9114   ins_cost(2 * VOLATILE_REF_COST);
 9115   effect(KILL cr);
 9116   format %{
 9117     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9118     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9119   %}
 9120   ins_encode %{
 9121     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9122                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9123                /*weak*/ true, noreg);
 9124     __ csetw($res$$Register, Assembler::EQ);
 9125   %}
 9126   ins_pipe(pipe_slow);
 9127 %}
 9128 
 9129 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9130   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9131   ins_cost(2 * VOLATILE_REF_COST);
 9132   effect(KILL cr);
 9133   format %{
 9134     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9135     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9136   %}
 9137   ins_encode %{
 9138     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9139                Assembler::word, /*acquire*/ false, /*release*/ true,
 9140                /*weak*/ true, noreg);
 9141     __ csetw($res$$Register, Assembler::EQ);
 9142   %}
 9143   ins_pipe(pipe_slow);
 9144 %}
 9145 
 9146 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9147   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9148   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9149   ins_cost(2 * VOLATILE_REF_COST);
 9150   effect(KILL cr);
 9151   format %{
 9152     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9153     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9154   %}
 9155   ins_encode %{
 9156     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9157                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9158                /*weak*/ true, noreg);
 9159     __ csetw($res$$Register, Assembler::EQ);
 9160   %}
 9161   ins_pipe(pipe_slow);
 9162 %}
 9163 
 9164 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9165   predicate(needs_acquiring_load_exclusive(n));
 9166   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9167   ins_cost(VOLATILE_REF_COST);
 9168   effect(KILL cr);
 9169   format %{
 9170     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9171     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9172   %}
 9173   ins_encode %{
 9174     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9175                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9176                /*weak*/ true, noreg);
 9177     __ csetw($res$$Register, Assembler::EQ);
 9178   %}
 9179   ins_pipe(pipe_slow);
 9180 %}
 9181 
 9182 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9183   predicate(needs_acquiring_load_exclusive(n));
 9184   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9185   ins_cost(VOLATILE_REF_COST);
 9186   effect(KILL cr);
 9187   format %{
 9188     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9189     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9190   %}
 9191   ins_encode %{
 9192     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9193                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9194                /*weak*/ true, noreg);
 9195     __ csetw($res$$Register, Assembler::EQ);
 9196   %}
 9197   ins_pipe(pipe_slow);
 9198 %}
 9199 
 9200 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9201   predicate(needs_acquiring_load_exclusive(n));
 9202   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9203   ins_cost(VOLATILE_REF_COST);
 9204   effect(KILL cr);
 9205   format %{
 9206     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9207     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9208   %}
 9209   ins_encode %{
 9210     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9211                Assembler::word, /*acquire*/ true, /*release*/ true,
 9212                /*weak*/ true, noreg);
 9213     __ csetw($res$$Register, Assembler::EQ);
 9214   %}
 9215   ins_pipe(pipe_slow);
 9216 %}
 9217 
 9218 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9219   predicate(needs_acquiring_load_exclusive(n));
 9220   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9221   ins_cost(VOLATILE_REF_COST);
 9222   effect(KILL cr);
 9223   format %{
 9224     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9225     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9226   %}
 9227   ins_encode %{
 9228     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9229                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9230                /*weak*/ true, noreg);
 9231     __ csetw($res$$Register, Assembler::EQ);
 9232   %}
 9233   ins_pipe(pipe_slow);
 9234 %}
 9235 
 9236 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9237   predicate(needs_acquiring_load_exclusive(n));
 9238   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9239   ins_cost(VOLATILE_REF_COST);
 9240   effect(KILL cr);
 9241   format %{
 9242     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9243     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9244   %}
 9245   ins_encode %{
 9246     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9247                Assembler::word, /*acquire*/ true, /*release*/ true,
 9248                /*weak*/ true, noreg);
 9249     __ csetw($res$$Register, Assembler::EQ);
 9250   %}
 9251   ins_pipe(pipe_slow);
 9252 %}
 9253 
 9254 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9255   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9256   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9257   ins_cost(VOLATILE_REF_COST);
 9258   effect(KILL cr);
 9259   format %{
 9260     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9261     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9262   %}
 9263   ins_encode %{
 9264     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9265                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9266                /*weak*/ true, noreg);
 9267     __ csetw($res$$Register, Assembler::EQ);
 9268   %}
 9269   ins_pipe(pipe_slow);
 9270 %}
 9271 
 9272 // END This section of the file is automatically generated. Do not edit --------------
 9273 // ---------------------------------------------------------------------
 9274 
 9275 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9276   match(Set prev (GetAndSetI mem newv));
 9277   ins_cost(2 * VOLATILE_REF_COST);
 9278   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9279   ins_encode %{
 9280     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9281   %}
 9282   ins_pipe(pipe_serial);
 9283 %}
 9284 
 9285 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9286   match(Set prev (GetAndSetL mem newv));
 9287   ins_cost(2 * VOLATILE_REF_COST);
 9288   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9289   ins_encode %{
 9290     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9291   %}
 9292   ins_pipe(pipe_serial);
 9293 %}
 9294 
 9295 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9296   match(Set prev (GetAndSetN mem newv));
 9297   ins_cost(2 * VOLATILE_REF_COST);
 9298   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9299   ins_encode %{
 9300     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9301   %}
 9302   ins_pipe(pipe_serial);
 9303 %}
 9304 
 9305 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9306   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9307   match(Set prev (GetAndSetP mem newv));
 9308   ins_cost(2 * VOLATILE_REF_COST);
 9309   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9310   ins_encode %{
 9311     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9312   %}
 9313   ins_pipe(pipe_serial);
 9314 %}
 9315 
 9316 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9317   predicate(needs_acquiring_load_exclusive(n));
 9318   match(Set prev (GetAndSetI mem newv));
 9319   ins_cost(VOLATILE_REF_COST);
 9320   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9321   ins_encode %{
 9322     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9323   %}
 9324   ins_pipe(pipe_serial);
 9325 %}
 9326 
 9327 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9328   predicate(needs_acquiring_load_exclusive(n));
 9329   match(Set prev (GetAndSetL mem newv));
 9330   ins_cost(VOLATILE_REF_COST);
 9331   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9332   ins_encode %{
 9333     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9334   %}
 9335   ins_pipe(pipe_serial);
 9336 %}
 9337 
 9338 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9339   predicate(needs_acquiring_load_exclusive(n));
 9340   match(Set prev (GetAndSetN mem newv));
 9341   ins_cost(VOLATILE_REF_COST);
 9342   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9343   ins_encode %{
 9344     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9345   %}
 9346   ins_pipe(pipe_serial);
 9347 %}
 9348 
 9349 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9350   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9351   match(Set prev (GetAndSetP mem newv));
 9352   ins_cost(VOLATILE_REF_COST);
 9353   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9354   ins_encode %{
 9355     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9356   %}
 9357   ins_pipe(pipe_serial);
 9358 %}
 9359 
 9360 
 9361 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9362   match(Set newval (GetAndAddL mem incr));
 9363   ins_cost(2 * VOLATILE_REF_COST + 1);
 9364   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9365   ins_encode %{
 9366     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9367   %}
 9368   ins_pipe(pipe_serial);
 9369 %}
 9370 
 9371 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9372   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9373   match(Set dummy (GetAndAddL mem incr));
 9374   ins_cost(2 * VOLATILE_REF_COST);
 9375   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9376   ins_encode %{
 9377     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9378   %}
 9379   ins_pipe(pipe_serial);
 9380 %}
 9381 
 9382 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9383   match(Set newval (GetAndAddL mem incr));
 9384   ins_cost(2 * VOLATILE_REF_COST + 1);
 9385   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9386   ins_encode %{
 9387     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9388   %}
 9389   ins_pipe(pipe_serial);
 9390 %}
 9391 
 9392 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9393   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9394   match(Set dummy (GetAndAddL mem incr));
 9395   ins_cost(2 * VOLATILE_REF_COST);
 9396   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9397   ins_encode %{
 9398     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9399   %}
 9400   ins_pipe(pipe_serial);
 9401 %}
 9402 
 9403 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9404   match(Set newval (GetAndAddI mem incr));
 9405   ins_cost(2 * VOLATILE_REF_COST + 1);
 9406   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9407   ins_encode %{
 9408     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9409   %}
 9410   ins_pipe(pipe_serial);
 9411 %}
 9412 
 9413 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9414   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9415   match(Set dummy (GetAndAddI mem incr));
 9416   ins_cost(2 * VOLATILE_REF_COST);
 9417   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9418   ins_encode %{
 9419     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9420   %}
 9421   ins_pipe(pipe_serial);
 9422 %}
 9423 
 9424 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9425   match(Set newval (GetAndAddI mem incr));
 9426   ins_cost(2 * VOLATILE_REF_COST + 1);
 9427   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9428   ins_encode %{
 9429     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9430   %}
 9431   ins_pipe(pipe_serial);
 9432 %}
 9433 
 9434 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9435   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9436   match(Set dummy (GetAndAddI mem incr));
 9437   ins_cost(2 * VOLATILE_REF_COST);
 9438   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9439   ins_encode %{
 9440     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9441   %}
 9442   ins_pipe(pipe_serial);
 9443 %}
 9444 
 9445 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9446   predicate(needs_acquiring_load_exclusive(n));
 9447   match(Set newval (GetAndAddL mem incr));
 9448   ins_cost(VOLATILE_REF_COST + 1);
 9449   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9450   ins_encode %{
 9451     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9452   %}
 9453   ins_pipe(pipe_serial);
 9454 %}
 9455 
 9456 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9457   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9458   match(Set dummy (GetAndAddL mem incr));
 9459   ins_cost(VOLATILE_REF_COST);
 9460   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9461   ins_encode %{
 9462     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9463   %}
 9464   ins_pipe(pipe_serial);
 9465 %}
 9466 
 9467 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9468   predicate(needs_acquiring_load_exclusive(n));
 9469   match(Set newval (GetAndAddL mem incr));
 9470   ins_cost(VOLATILE_REF_COST + 1);
 9471   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9472   ins_encode %{
 9473     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9474   %}
 9475   ins_pipe(pipe_serial);
 9476 %}
 9477 
 9478 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9479   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9480   match(Set dummy (GetAndAddL mem incr));
 9481   ins_cost(VOLATILE_REF_COST);
 9482   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9483   ins_encode %{
 9484     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9485   %}
 9486   ins_pipe(pipe_serial);
 9487 %}
 9488 
 9489 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9490   predicate(needs_acquiring_load_exclusive(n));
 9491   match(Set newval (GetAndAddI mem incr));
 9492   ins_cost(VOLATILE_REF_COST + 1);
 9493   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9494   ins_encode %{
 9495     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9496   %}
 9497   ins_pipe(pipe_serial);
 9498 %}
 9499 
 9500 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9501   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9502   match(Set dummy (GetAndAddI mem incr));
 9503   ins_cost(VOLATILE_REF_COST);
 9504   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9505   ins_encode %{
 9506     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9507   %}
 9508   ins_pipe(pipe_serial);
 9509 %}
 9510 
 9511 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9512   predicate(needs_acquiring_load_exclusive(n));
 9513   match(Set newval (GetAndAddI mem incr));
 9514   ins_cost(VOLATILE_REF_COST + 1);
 9515   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9516   ins_encode %{
 9517     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9518   %}
 9519   ins_pipe(pipe_serial);
 9520 %}
 9521 
 9522 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9523   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9524   match(Set dummy (GetAndAddI mem incr));
 9525   ins_cost(VOLATILE_REF_COST);
 9526   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9527   ins_encode %{
 9528     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9529   %}
 9530   ins_pipe(pipe_serial);
 9531 %}
 9532 
 9533 // Manifest a CmpL result in an integer register.
 9534 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9535 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9536 %{
 9537   match(Set dst (CmpL3 src1 src2));
 9538   effect(KILL flags);
 9539 
 9540   ins_cost(INSN_COST * 6);
 9541   format %{
 9542       &quot;cmp $src1, $src2&quot;
 9543       &quot;csetw $dst, ne&quot;
 9544       &quot;cnegw $dst, lt&quot;
 9545   %}
 9546   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9547   ins_encode %{
 9548     __ cmp($src1$$Register, $src2$$Register);
 9549     __ csetw($dst$$Register, Assembler::NE);
 9550     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9551   %}
 9552 
 9553   ins_pipe(pipe_class_default);
 9554 %}
 9555 
 9556 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9557 %{
 9558   match(Set dst (CmpL3 src1 src2));
 9559   effect(KILL flags);
 9560 
 9561   ins_cost(INSN_COST * 6);
 9562   format %{
 9563       &quot;cmp $src1, $src2&quot;
 9564       &quot;csetw $dst, ne&quot;
 9565       &quot;cnegw $dst, lt&quot;
 9566   %}
 9567   ins_encode %{
 9568     int32_t con = (int32_t)$src2$$constant;
 9569      if (con &lt; 0) {
 9570       __ adds(zr, $src1$$Register, -con);
 9571     } else {
 9572       __ subs(zr, $src1$$Register, con);
 9573     }
 9574     __ csetw($dst$$Register, Assembler::NE);
 9575     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9576   %}
 9577 
 9578   ins_pipe(pipe_class_default);
 9579 %}
 9580 
 9581 // ============================================================================
 9582 // Conditional Move Instructions
 9583 
 9584 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9585 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9586 // define an op class which merged both inputs and use it to type the
 9587 // argument to a single rule. unfortunatelyt his fails because the
 9588 // opclass does not live up to the COND_INTER interface of its
 9589 // component operands. When the generic code tries to negate the
 9590 // operand it ends up running the generci Machoper::negate method
 9591 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9592 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9593 
 9594 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9595   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9596 
 9597   ins_cost(INSN_COST * 2);
 9598   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9599 
 9600   ins_encode %{
 9601     __ cselw(as_Register($dst$$reg),
 9602              as_Register($src2$$reg),
 9603              as_Register($src1$$reg),
 9604              (Assembler::Condition)$cmp$$cmpcode);
 9605   %}
 9606 
 9607   ins_pipe(icond_reg_reg);
 9608 %}
 9609 
 9610 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9611   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9612 
 9613   ins_cost(INSN_COST * 2);
 9614   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9615 
 9616   ins_encode %{
 9617     __ cselw(as_Register($dst$$reg),
 9618              as_Register($src2$$reg),
 9619              as_Register($src1$$reg),
 9620              (Assembler::Condition)$cmp$$cmpcode);
 9621   %}
 9622 
 9623   ins_pipe(icond_reg_reg);
 9624 %}
 9625 
 9626 // special cases where one arg is zero
 9627 
 9628 // n.b. this is selected in preference to the rule above because it
 9629 // avoids loading constant 0 into a source register
 9630 
 9631 // TODO
 9632 // we ought only to be able to cull one of these variants as the ideal
 9633 // transforms ought always to order the zero consistently (to left/right?)
 9634 
 9635 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9636   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9637 
 9638   ins_cost(INSN_COST * 2);
 9639   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9640 
 9641   ins_encode %{
 9642     __ cselw(as_Register($dst$$reg),
 9643              as_Register($src$$reg),
 9644              zr,
 9645              (Assembler::Condition)$cmp$$cmpcode);
 9646   %}
 9647 
 9648   ins_pipe(icond_reg);
 9649 %}
 9650 
 9651 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9652   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9653 
 9654   ins_cost(INSN_COST * 2);
 9655   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9656 
 9657   ins_encode %{
 9658     __ cselw(as_Register($dst$$reg),
 9659              as_Register($src$$reg),
 9660              zr,
 9661              (Assembler::Condition)$cmp$$cmpcode);
 9662   %}
 9663 
 9664   ins_pipe(icond_reg);
 9665 %}
 9666 
 9667 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9668   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9669 
 9670   ins_cost(INSN_COST * 2);
 9671   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9672 
 9673   ins_encode %{
 9674     __ cselw(as_Register($dst$$reg),
 9675              zr,
 9676              as_Register($src$$reg),
 9677              (Assembler::Condition)$cmp$$cmpcode);
 9678   %}
 9679 
 9680   ins_pipe(icond_reg);
 9681 %}
 9682 
 9683 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9684   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9685 
 9686   ins_cost(INSN_COST * 2);
 9687   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9688 
 9689   ins_encode %{
 9690     __ cselw(as_Register($dst$$reg),
 9691              zr,
 9692              as_Register($src$$reg),
 9693              (Assembler::Condition)$cmp$$cmpcode);
 9694   %}
 9695 
 9696   ins_pipe(icond_reg);
 9697 %}
 9698 
 9699 // special case for creating a boolean 0 or 1
 9700 
 9701 // n.b. this is selected in preference to the rule above because it
 9702 // avoids loading constants 0 and 1 into a source register
 9703 
 9704 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9705   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9706 
 9707   ins_cost(INSN_COST * 2);
 9708   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9709 
 9710   ins_encode %{
 9711     // equivalently
 9712     // cset(as_Register($dst$$reg),
 9713     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9714     __ csincw(as_Register($dst$$reg),
 9715              zr,
 9716              zr,
 9717              (Assembler::Condition)$cmp$$cmpcode);
 9718   %}
 9719 
 9720   ins_pipe(icond_none);
 9721 %}
 9722 
 9723 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9724   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9725 
 9726   ins_cost(INSN_COST * 2);
 9727   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9728 
 9729   ins_encode %{
 9730     // equivalently
 9731     // cset(as_Register($dst$$reg),
 9732     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9733     __ csincw(as_Register($dst$$reg),
 9734              zr,
 9735              zr,
 9736              (Assembler::Condition)$cmp$$cmpcode);
 9737   %}
 9738 
 9739   ins_pipe(icond_none);
 9740 %}
 9741 
 9742 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9743   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9744 
 9745   ins_cost(INSN_COST * 2);
 9746   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9747 
 9748   ins_encode %{
 9749     __ csel(as_Register($dst$$reg),
 9750             as_Register($src2$$reg),
 9751             as_Register($src1$$reg),
 9752             (Assembler::Condition)$cmp$$cmpcode);
 9753   %}
 9754 
 9755   ins_pipe(icond_reg_reg);
 9756 %}
 9757 
 9758 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9759   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9760 
 9761   ins_cost(INSN_COST * 2);
 9762   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9763 
 9764   ins_encode %{
 9765     __ csel(as_Register($dst$$reg),
 9766             as_Register($src2$$reg),
 9767             as_Register($src1$$reg),
 9768             (Assembler::Condition)$cmp$$cmpcode);
 9769   %}
 9770 
 9771   ins_pipe(icond_reg_reg);
 9772 %}
 9773 
 9774 // special cases where one arg is zero
 9775 
 9776 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9777   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9778 
 9779   ins_cost(INSN_COST * 2);
 9780   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9781 
 9782   ins_encode %{
 9783     __ csel(as_Register($dst$$reg),
 9784             zr,
 9785             as_Register($src$$reg),
 9786             (Assembler::Condition)$cmp$$cmpcode);
 9787   %}
 9788 
 9789   ins_pipe(icond_reg);
 9790 %}
 9791 
 9792 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9793   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9794 
 9795   ins_cost(INSN_COST * 2);
 9796   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9797 
 9798   ins_encode %{
 9799     __ csel(as_Register($dst$$reg),
 9800             zr,
 9801             as_Register($src$$reg),
 9802             (Assembler::Condition)$cmp$$cmpcode);
 9803   %}
 9804 
 9805   ins_pipe(icond_reg);
 9806 %}
 9807 
 9808 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9809   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9810 
 9811   ins_cost(INSN_COST * 2);
 9812   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9813 
 9814   ins_encode %{
 9815     __ csel(as_Register($dst$$reg),
 9816             as_Register($src$$reg),
 9817             zr,
 9818             (Assembler::Condition)$cmp$$cmpcode);
 9819   %}
 9820 
 9821   ins_pipe(icond_reg);
 9822 %}
 9823 
 9824 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9825   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9826 
 9827   ins_cost(INSN_COST * 2);
 9828   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9829 
 9830   ins_encode %{
 9831     __ csel(as_Register($dst$$reg),
 9832             as_Register($src$$reg),
 9833             zr,
 9834             (Assembler::Condition)$cmp$$cmpcode);
 9835   %}
 9836 
 9837   ins_pipe(icond_reg);
 9838 %}
 9839 
 9840 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9841   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9842 
 9843   ins_cost(INSN_COST * 2);
 9844   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9845 
 9846   ins_encode %{
 9847     __ csel(as_Register($dst$$reg),
 9848             as_Register($src2$$reg),
 9849             as_Register($src1$$reg),
 9850             (Assembler::Condition)$cmp$$cmpcode);
 9851   %}
 9852 
 9853   ins_pipe(icond_reg_reg);
 9854 %}
 9855 
 9856 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9857   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9858 
 9859   ins_cost(INSN_COST * 2);
 9860   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9861 
 9862   ins_encode %{
 9863     __ csel(as_Register($dst$$reg),
 9864             as_Register($src2$$reg),
 9865             as_Register($src1$$reg),
 9866             (Assembler::Condition)$cmp$$cmpcode);
 9867   %}
 9868 
 9869   ins_pipe(icond_reg_reg);
 9870 %}
 9871 
 9872 // special cases where one arg is zero
 9873 
 9874 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9875   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9876 
 9877   ins_cost(INSN_COST * 2);
 9878   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9879 
 9880   ins_encode %{
 9881     __ csel(as_Register($dst$$reg),
 9882             zr,
 9883             as_Register($src$$reg),
 9884             (Assembler::Condition)$cmp$$cmpcode);
 9885   %}
 9886 
 9887   ins_pipe(icond_reg);
 9888 %}
 9889 
 9890 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9891   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9892 
 9893   ins_cost(INSN_COST * 2);
 9894   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9895 
 9896   ins_encode %{
 9897     __ csel(as_Register($dst$$reg),
 9898             zr,
 9899             as_Register($src$$reg),
 9900             (Assembler::Condition)$cmp$$cmpcode);
 9901   %}
 9902 
 9903   ins_pipe(icond_reg);
 9904 %}
 9905 
 9906 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9907   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9908 
 9909   ins_cost(INSN_COST * 2);
 9910   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9911 
 9912   ins_encode %{
 9913     __ csel(as_Register($dst$$reg),
 9914             as_Register($src$$reg),
 9915             zr,
 9916             (Assembler::Condition)$cmp$$cmpcode);
 9917   %}
 9918 
 9919   ins_pipe(icond_reg);
 9920 %}
 9921 
 9922 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9923   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9924 
 9925   ins_cost(INSN_COST * 2);
 9926   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9927 
 9928   ins_encode %{
 9929     __ csel(as_Register($dst$$reg),
 9930             as_Register($src$$reg),
 9931             zr,
 9932             (Assembler::Condition)$cmp$$cmpcode);
 9933   %}
 9934 
 9935   ins_pipe(icond_reg);
 9936 %}
 9937 
 9938 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9939   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9940 
 9941   ins_cost(INSN_COST * 2);
 9942   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9943 
 9944   ins_encode %{
 9945     __ cselw(as_Register($dst$$reg),
 9946              as_Register($src2$$reg),
 9947              as_Register($src1$$reg),
 9948              (Assembler::Condition)$cmp$$cmpcode);
 9949   %}
 9950 
 9951   ins_pipe(icond_reg_reg);
 9952 %}
 9953 
 9954 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9955   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9956 
 9957   ins_cost(INSN_COST * 2);
 9958   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9959 
 9960   ins_encode %{
 9961     __ cselw(as_Register($dst$$reg),
 9962              as_Register($src2$$reg),
 9963              as_Register($src1$$reg),
 9964              (Assembler::Condition)$cmp$$cmpcode);
 9965   %}
 9966 
 9967   ins_pipe(icond_reg_reg);
 9968 %}
 9969 
 9970 // special cases where one arg is zero
 9971 
 9972 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9973   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9974 
 9975   ins_cost(INSN_COST * 2);
 9976   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9977 
 9978   ins_encode %{
 9979     __ cselw(as_Register($dst$$reg),
 9980              zr,
 9981              as_Register($src$$reg),
 9982              (Assembler::Condition)$cmp$$cmpcode);
 9983   %}
 9984 
 9985   ins_pipe(icond_reg);
 9986 %}
 9987 
 9988 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9989   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9990 
 9991   ins_cost(INSN_COST * 2);
 9992   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9993 
 9994   ins_encode %{
 9995     __ cselw(as_Register($dst$$reg),
 9996              zr,
 9997              as_Register($src$$reg),
 9998              (Assembler::Condition)$cmp$$cmpcode);
 9999   %}
10000 
10001   ins_pipe(icond_reg);
10002 %}
10003 
10004 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10005   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10006 
10007   ins_cost(INSN_COST * 2);
10008   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
10009 
10010   ins_encode %{
10011     __ cselw(as_Register($dst$$reg),
10012              as_Register($src$$reg),
10013              zr,
10014              (Assembler::Condition)$cmp$$cmpcode);
10015   %}
10016 
10017   ins_pipe(icond_reg);
10018 %}
10019 
10020 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10021   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10022 
10023   ins_cost(INSN_COST * 2);
10024   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
10025 
10026   ins_encode %{
10027     __ cselw(as_Register($dst$$reg),
10028              as_Register($src$$reg),
10029              zr,
10030              (Assembler::Condition)$cmp$$cmpcode);
10031   %}
10032 
10033   ins_pipe(icond_reg);
10034 %}
10035 
10036 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10037 %{
10038   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10039 
10040   ins_cost(INSN_COST * 3);
10041 
10042   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10043   ins_encode %{
10044     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10045     __ fcsels(as_FloatRegister($dst$$reg),
10046               as_FloatRegister($src2$$reg),
10047               as_FloatRegister($src1$$reg),
10048               cond);
10049   %}
10050 
10051   ins_pipe(fp_cond_reg_reg_s);
10052 %}
10053 
10054 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10055 %{
10056   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10057 
10058   ins_cost(INSN_COST * 3);
10059 
10060   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10061   ins_encode %{
10062     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10063     __ fcsels(as_FloatRegister($dst$$reg),
10064               as_FloatRegister($src2$$reg),
10065               as_FloatRegister($src1$$reg),
10066               cond);
10067   %}
10068 
10069   ins_pipe(fp_cond_reg_reg_s);
10070 %}
10071 
10072 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10073 %{
10074   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10075 
10076   ins_cost(INSN_COST * 3);
10077 
10078   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10079   ins_encode %{
10080     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10081     __ fcseld(as_FloatRegister($dst$$reg),
10082               as_FloatRegister($src2$$reg),
10083               as_FloatRegister($src1$$reg),
10084               cond);
10085   %}
10086 
10087   ins_pipe(fp_cond_reg_reg_d);
10088 %}
10089 
10090 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10091 %{
10092   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10093 
10094   ins_cost(INSN_COST * 3);
10095 
10096   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10097   ins_encode %{
10098     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10099     __ fcseld(as_FloatRegister($dst$$reg),
10100               as_FloatRegister($src2$$reg),
10101               as_FloatRegister($src1$$reg),
10102               cond);
10103   %}
10104 
10105   ins_pipe(fp_cond_reg_reg_d);
10106 %}
10107 
10108 // ============================================================================
10109 // Arithmetic Instructions
10110 //
10111 
10112 // Integer Addition
10113 
10114 // TODO
10115 // these currently employ operations which do not set CR and hence are
10116 // not flagged as killing CR but we would like to isolate the cases
10117 // where we want to set flags from those where we don&#39;t. need to work
10118 // out how to do that.
10119 
10120 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10121   match(Set dst (AddI src1 src2));
10122 
10123   ins_cost(INSN_COST);
10124   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10125 
10126   ins_encode %{
10127     __ addw(as_Register($dst$$reg),
10128             as_Register($src1$$reg),
10129             as_Register($src2$$reg));
10130   %}
10131 
10132   ins_pipe(ialu_reg_reg);
10133 %}
10134 
10135 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10136   match(Set dst (AddI src1 src2));
10137 
10138   ins_cost(INSN_COST);
10139   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10140 
10141   // use opcode to indicate that this is an add not a sub
10142   opcode(0x0);
10143 
10144   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10145 
10146   ins_pipe(ialu_reg_imm);
10147 %}
10148 
10149 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10150   match(Set dst (AddI (ConvL2I src1) src2));
10151 
10152   ins_cost(INSN_COST);
10153   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10154 
10155   // use opcode to indicate that this is an add not a sub
10156   opcode(0x0);
10157 
10158   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10159 
10160   ins_pipe(ialu_reg_imm);
10161 %}
10162 
10163 // Pointer Addition
10164 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10165   match(Set dst (AddP src1 src2));
10166 
10167   ins_cost(INSN_COST);
10168   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10169 
10170   ins_encode %{
10171     __ add(as_Register($dst$$reg),
10172            as_Register($src1$$reg),
10173            as_Register($src2$$reg));
10174   %}
10175 
10176   ins_pipe(ialu_reg_reg);
10177 %}
10178 
10179 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10180   match(Set dst (AddP src1 (ConvI2L src2)));
10181 
10182   ins_cost(1.9 * INSN_COST);
10183   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10184 
10185   ins_encode %{
10186     __ add(as_Register($dst$$reg),
10187            as_Register($src1$$reg),
10188            as_Register($src2$$reg), ext::sxtw);
10189   %}
10190 
10191   ins_pipe(ialu_reg_reg);
10192 %}
10193 
10194 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10195   match(Set dst (AddP src1 (LShiftL src2 scale)));
10196 
10197   ins_cost(1.9 * INSN_COST);
10198   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10199 
10200   ins_encode %{
10201     __ lea(as_Register($dst$$reg),
10202            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10203                    Address::lsl($scale$$constant)));
10204   %}
10205 
10206   ins_pipe(ialu_reg_reg_shift);
10207 %}
10208 
10209 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10210   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10211 
10212   ins_cost(1.9 * INSN_COST);
10213   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10214 
10215   ins_encode %{
10216     __ lea(as_Register($dst$$reg),
10217            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10218                    Address::sxtw($scale$$constant)));
10219   %}
10220 
10221   ins_pipe(ialu_reg_reg_shift);
10222 %}
10223 
10224 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10225   match(Set dst (LShiftL (ConvI2L src) scale));
10226 
10227   ins_cost(INSN_COST);
10228   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10229 
10230   ins_encode %{
10231     __ sbfiz(as_Register($dst$$reg),
10232           as_Register($src$$reg),
10233           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10234   %}
10235 
10236   ins_pipe(ialu_reg_shift);
10237 %}
10238 
10239 // Pointer Immediate Addition
10240 // n.b. this needs to be more expensive than using an indirect memory
10241 // operand
10242 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10243   match(Set dst (AddP src1 src2));
10244 
10245   ins_cost(INSN_COST);
10246   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10247 
10248   // use opcode to indicate that this is an add not a sub
10249   opcode(0x0);
10250 
10251   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10252 
10253   ins_pipe(ialu_reg_imm);
10254 %}
10255 
10256 // Long Addition
10257 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10258 
10259   match(Set dst (AddL src1 src2));
10260 
10261   ins_cost(INSN_COST);
10262   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10263 
10264   ins_encode %{
10265     __ add(as_Register($dst$$reg),
10266            as_Register($src1$$reg),
10267            as_Register($src2$$reg));
10268   %}
10269 
10270   ins_pipe(ialu_reg_reg);
10271 %}
10272 
10273 // No constant pool entries requiredLong Immediate Addition.
10274 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10275   match(Set dst (AddL src1 src2));
10276 
10277   ins_cost(INSN_COST);
10278   format %{ &quot;add $dst, $src1, $src2&quot; %}
10279 
10280   // use opcode to indicate that this is an add not a sub
10281   opcode(0x0);
10282 
10283   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10284 
10285   ins_pipe(ialu_reg_imm);
10286 %}
10287 
10288 // Integer Subtraction
10289 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10290   match(Set dst (SubI src1 src2));
10291 
10292   ins_cost(INSN_COST);
10293   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10294 
10295   ins_encode %{
10296     __ subw(as_Register($dst$$reg),
10297             as_Register($src1$$reg),
10298             as_Register($src2$$reg));
10299   %}
10300 
10301   ins_pipe(ialu_reg_reg);
10302 %}
10303 
10304 // Immediate Subtraction
10305 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10306   match(Set dst (SubI src1 src2));
10307 
10308   ins_cost(INSN_COST);
10309   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10310 
10311   // use opcode to indicate that this is a sub not an add
10312   opcode(0x1);
10313 
10314   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10315 
10316   ins_pipe(ialu_reg_imm);
10317 %}
10318 
10319 // Long Subtraction
10320 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10321 
10322   match(Set dst (SubL src1 src2));
10323 
10324   ins_cost(INSN_COST);
10325   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10326 
10327   ins_encode %{
10328     __ sub(as_Register($dst$$reg),
10329            as_Register($src1$$reg),
10330            as_Register($src2$$reg));
10331   %}
10332 
10333   ins_pipe(ialu_reg_reg);
10334 %}
10335 
10336 // No constant pool entries requiredLong Immediate Subtraction.
10337 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10338   match(Set dst (SubL src1 src2));
10339 
10340   ins_cost(INSN_COST);
10341   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10342 
10343   // use opcode to indicate that this is a sub not an add
10344   opcode(0x1);
10345 
10346   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10347 
10348   ins_pipe(ialu_reg_imm);
10349 %}
10350 
10351 // Integer Negation (special case for sub)
10352 
10353 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10354   match(Set dst (SubI zero src));
10355 
10356   ins_cost(INSN_COST);
10357   format %{ &quot;negw $dst, $src\t# int&quot; %}
10358 
10359   ins_encode %{
10360     __ negw(as_Register($dst$$reg),
10361             as_Register($src$$reg));
10362   %}
10363 
10364   ins_pipe(ialu_reg);
10365 %}
10366 
10367 // Long Negation
10368 
10369 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10370   match(Set dst (SubL zero src));
10371 
10372   ins_cost(INSN_COST);
10373   format %{ &quot;neg $dst, $src\t# long&quot; %}
10374 
10375   ins_encode %{
10376     __ neg(as_Register($dst$$reg),
10377            as_Register($src$$reg));
10378   %}
10379 
10380   ins_pipe(ialu_reg);
10381 %}
10382 
10383 // Integer Multiply
10384 
10385 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10386   match(Set dst (MulI src1 src2));
10387 
10388   ins_cost(INSN_COST * 3);
10389   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10390 
10391   ins_encode %{
10392     __ mulw(as_Register($dst$$reg),
10393             as_Register($src1$$reg),
10394             as_Register($src2$$reg));
10395   %}
10396 
10397   ins_pipe(imul_reg_reg);
10398 %}
10399 
10400 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10401   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10402 
10403   ins_cost(INSN_COST * 3);
10404   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10405 
10406   ins_encode %{
10407     __ smull(as_Register($dst$$reg),
10408              as_Register($src1$$reg),
10409              as_Register($src2$$reg));
10410   %}
10411 
10412   ins_pipe(imul_reg_reg);
10413 %}
10414 
10415 // Long Multiply
10416 
10417 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10418   match(Set dst (MulL src1 src2));
10419 
10420   ins_cost(INSN_COST * 5);
10421   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10422 
10423   ins_encode %{
10424     __ mul(as_Register($dst$$reg),
10425            as_Register($src1$$reg),
10426            as_Register($src2$$reg));
10427   %}
10428 
10429   ins_pipe(lmul_reg_reg);
10430 %}
10431 
10432 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10433 %{
10434   match(Set dst (MulHiL src1 src2));
10435 
10436   ins_cost(INSN_COST * 7);
10437   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10438 
10439   ins_encode %{
10440     __ smulh(as_Register($dst$$reg),
10441              as_Register($src1$$reg),
10442              as_Register($src2$$reg));
10443   %}
10444 
10445   ins_pipe(lmul_reg_reg);
10446 %}
10447 
10448 // Combined Integer Multiply &amp; Add/Sub
10449 
10450 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10451   match(Set dst (AddI src3 (MulI src1 src2)));
10452 
10453   ins_cost(INSN_COST * 3);
10454   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10455 
10456   ins_encode %{
10457     __ maddw(as_Register($dst$$reg),
10458              as_Register($src1$$reg),
10459              as_Register($src2$$reg),
10460              as_Register($src3$$reg));
10461   %}
10462 
10463   ins_pipe(imac_reg_reg);
10464 %}
10465 
10466 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10467   match(Set dst (SubI src3 (MulI src1 src2)));
10468 
10469   ins_cost(INSN_COST * 3);
10470   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10471 
10472   ins_encode %{
10473     __ msubw(as_Register($dst$$reg),
10474              as_Register($src1$$reg),
10475              as_Register($src2$$reg),
10476              as_Register($src3$$reg));
10477   %}
10478 
10479   ins_pipe(imac_reg_reg);
10480 %}
10481 
10482 // Combined Integer Multiply &amp; Neg
10483 
10484 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10485   match(Set dst (MulI (SubI zero src1) src2));
10486   match(Set dst (MulI src1 (SubI zero src2)));
10487 
10488   ins_cost(INSN_COST * 3);
10489   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10490 
10491   ins_encode %{
10492     __ mnegw(as_Register($dst$$reg),
10493              as_Register($src1$$reg),
10494              as_Register($src2$$reg));
10495   %}
10496 
10497   ins_pipe(imac_reg_reg);
10498 %}
10499 
10500 // Combined Long Multiply &amp; Add/Sub
10501 
10502 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10503   match(Set dst (AddL src3 (MulL src1 src2)));
10504 
10505   ins_cost(INSN_COST * 5);
10506   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10507 
10508   ins_encode %{
10509     __ madd(as_Register($dst$$reg),
10510             as_Register($src1$$reg),
10511             as_Register($src2$$reg),
10512             as_Register($src3$$reg));
10513   %}
10514 
10515   ins_pipe(lmac_reg_reg);
10516 %}
10517 
10518 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10519   match(Set dst (SubL src3 (MulL src1 src2)));
10520 
10521   ins_cost(INSN_COST * 5);
10522   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10523 
10524   ins_encode %{
10525     __ msub(as_Register($dst$$reg),
10526             as_Register($src1$$reg),
10527             as_Register($src2$$reg),
10528             as_Register($src3$$reg));
10529   %}
10530 
10531   ins_pipe(lmac_reg_reg);
10532 %}
10533 
10534 // Combined Long Multiply &amp; Neg
10535 
10536 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10537   match(Set dst (MulL (SubL zero src1) src2));
10538   match(Set dst (MulL src1 (SubL zero src2)));
10539 
10540   ins_cost(INSN_COST * 5);
10541   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10542 
10543   ins_encode %{
10544     __ mneg(as_Register($dst$$reg),
10545             as_Register($src1$$reg),
10546             as_Register($src2$$reg));
10547   %}
10548 
10549   ins_pipe(lmac_reg_reg);
10550 %}
10551 
10552 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10553 
10554 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10555   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10556 
10557   ins_cost(INSN_COST * 3);
10558   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10559 
10560   ins_encode %{
10561     __ smaddl(as_Register($dst$$reg),
10562               as_Register($src1$$reg),
10563               as_Register($src2$$reg),
10564               as_Register($src3$$reg));
10565   %}
10566 
10567   ins_pipe(imac_reg_reg);
10568 %}
10569 
10570 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10571   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10572 
10573   ins_cost(INSN_COST * 3);
10574   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10575 
10576   ins_encode %{
10577     __ smsubl(as_Register($dst$$reg),
10578               as_Register($src1$$reg),
10579               as_Register($src2$$reg),
10580               as_Register($src3$$reg));
10581   %}
10582 
10583   ins_pipe(imac_reg_reg);
10584 %}
10585 
10586 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10587   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10588   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10589 
10590   ins_cost(INSN_COST * 3);
10591   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10592 
10593   ins_encode %{
10594     __ smnegl(as_Register($dst$$reg),
10595               as_Register($src1$$reg),
10596               as_Register($src2$$reg));
10597   %}
10598 
10599   ins_pipe(imac_reg_reg);
10600 %}
10601 
10602 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10603 
10604 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10605   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10606 
10607   ins_cost(INSN_COST * 5);
10608   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10609             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10610 
10611   ins_encode %{
10612     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10613     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10614 
10615   ins_pipe(imac_reg_reg);
10616 %}
10617 
10618 // Integer Divide
10619 
10620 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10621   match(Set dst (DivI src1 src2));
10622 
10623   ins_cost(INSN_COST * 19);
10624   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10625 
10626   ins_encode(aarch64_enc_divw(dst, src1, src2));
10627   ins_pipe(idiv_reg_reg);
10628 %}
10629 
10630 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10631   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10632   ins_cost(INSN_COST);
10633   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10634   ins_encode %{
10635     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10636   %}
10637   ins_pipe(ialu_reg_shift);
10638 %}
10639 
10640 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10641   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10642   ins_cost(INSN_COST);
10643   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10644 
10645   ins_encode %{
10646     __ addw(as_Register($dst$$reg),
10647               as_Register($src$$reg),
10648               as_Register($src$$reg),
10649               Assembler::LSR, 31);
10650   %}
10651   ins_pipe(ialu_reg);
10652 %}
10653 
10654 // Long Divide
10655 
10656 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10657   match(Set dst (DivL src1 src2));
10658 
10659   ins_cost(INSN_COST * 35);
10660   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10661 
10662   ins_encode(aarch64_enc_div(dst, src1, src2));
10663   ins_pipe(ldiv_reg_reg);
10664 %}
10665 
10666 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10667   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10668   ins_cost(INSN_COST);
10669   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10670   ins_encode %{
10671     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10672   %}
10673   ins_pipe(ialu_reg_shift);
10674 %}
10675 
10676 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10677   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10678   ins_cost(INSN_COST);
10679   format %{ &quot;add $dst, $src, $div1&quot; %}
10680 
10681   ins_encode %{
10682     __ add(as_Register($dst$$reg),
10683               as_Register($src$$reg),
10684               as_Register($src$$reg),
10685               Assembler::LSR, 63);
10686   %}
10687   ins_pipe(ialu_reg);
10688 %}
10689 
10690 // Integer Remainder
10691 
10692 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10693   match(Set dst (ModI src1 src2));
10694 
10695   ins_cost(INSN_COST * 22);
10696   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10697             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10698 
10699   ins_encode(aarch64_enc_modw(dst, src1, src2));
10700   ins_pipe(idiv_reg_reg);
10701 %}
10702 
10703 // Long Remainder
10704 
10705 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10706   match(Set dst (ModL src1 src2));
10707 
10708   ins_cost(INSN_COST * 38);
10709   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10710             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10711 
10712   ins_encode(aarch64_enc_mod(dst, src1, src2));
10713   ins_pipe(ldiv_reg_reg);
10714 %}
10715 
10716 // Integer Shifts
10717 
10718 // Shift Left Register
10719 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10720   match(Set dst (LShiftI src1 src2));
10721 
10722   ins_cost(INSN_COST * 2);
10723   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10724 
10725   ins_encode %{
10726     __ lslvw(as_Register($dst$$reg),
10727              as_Register($src1$$reg),
10728              as_Register($src2$$reg));
10729   %}
10730 
10731   ins_pipe(ialu_reg_reg_vshift);
10732 %}
10733 
10734 // Shift Left Immediate
10735 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10736   match(Set dst (LShiftI src1 src2));
10737 
10738   ins_cost(INSN_COST);
10739   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10740 
10741   ins_encode %{
10742     __ lslw(as_Register($dst$$reg),
10743             as_Register($src1$$reg),
10744             $src2$$constant &amp; 0x1f);
10745   %}
10746 
10747   ins_pipe(ialu_reg_shift);
10748 %}
10749 
10750 // Shift Right Logical Register
10751 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10752   match(Set dst (URShiftI src1 src2));
10753 
10754   ins_cost(INSN_COST * 2);
10755   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10756 
10757   ins_encode %{
10758     __ lsrvw(as_Register($dst$$reg),
10759              as_Register($src1$$reg),
10760              as_Register($src2$$reg));
10761   %}
10762 
10763   ins_pipe(ialu_reg_reg_vshift);
10764 %}
10765 
10766 // Shift Right Logical Immediate
10767 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10768   match(Set dst (URShiftI src1 src2));
10769 
10770   ins_cost(INSN_COST);
10771   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10772 
10773   ins_encode %{
10774     __ lsrw(as_Register($dst$$reg),
10775             as_Register($src1$$reg),
10776             $src2$$constant &amp; 0x1f);
10777   %}
10778 
10779   ins_pipe(ialu_reg_shift);
10780 %}
10781 
10782 // Shift Right Arithmetic Register
10783 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10784   match(Set dst (RShiftI src1 src2));
10785 
10786   ins_cost(INSN_COST * 2);
10787   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10788 
10789   ins_encode %{
10790     __ asrvw(as_Register($dst$$reg),
10791              as_Register($src1$$reg),
10792              as_Register($src2$$reg));
10793   %}
10794 
10795   ins_pipe(ialu_reg_reg_vshift);
10796 %}
10797 
10798 // Shift Right Arithmetic Immediate
10799 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10800   match(Set dst (RShiftI src1 src2));
10801 
10802   ins_cost(INSN_COST);
10803   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10804 
10805   ins_encode %{
10806     __ asrw(as_Register($dst$$reg),
10807             as_Register($src1$$reg),
10808             $src2$$constant &amp; 0x1f);
10809   %}
10810 
10811   ins_pipe(ialu_reg_shift);
10812 %}
10813 
10814 // Combined Int Mask and Right Shift (using UBFM)
10815 // TODO
10816 
10817 // Long Shifts
10818 
10819 // Shift Left Register
10820 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10821   match(Set dst (LShiftL src1 src2));
10822 
10823   ins_cost(INSN_COST * 2);
10824   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10825 
10826   ins_encode %{
10827     __ lslv(as_Register($dst$$reg),
10828             as_Register($src1$$reg),
10829             as_Register($src2$$reg));
10830   %}
10831 
10832   ins_pipe(ialu_reg_reg_vshift);
10833 %}
10834 
10835 // Shift Left Immediate
10836 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10837   match(Set dst (LShiftL src1 src2));
10838 
10839   ins_cost(INSN_COST);
10840   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10841 
10842   ins_encode %{
10843     __ lsl(as_Register($dst$$reg),
10844             as_Register($src1$$reg),
10845             $src2$$constant &amp; 0x3f);
10846   %}
10847 
10848   ins_pipe(ialu_reg_shift);
10849 %}
10850 
10851 // Shift Right Logical Register
10852 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10853   match(Set dst (URShiftL src1 src2));
10854 
10855   ins_cost(INSN_COST * 2);
10856   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10857 
10858   ins_encode %{
10859     __ lsrv(as_Register($dst$$reg),
10860             as_Register($src1$$reg),
10861             as_Register($src2$$reg));
10862   %}
10863 
10864   ins_pipe(ialu_reg_reg_vshift);
10865 %}
10866 
10867 // Shift Right Logical Immediate
10868 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10869   match(Set dst (URShiftL src1 src2));
10870 
10871   ins_cost(INSN_COST);
10872   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10873 
10874   ins_encode %{
10875     __ lsr(as_Register($dst$$reg),
10876            as_Register($src1$$reg),
10877            $src2$$constant &amp; 0x3f);
10878   %}
10879 
10880   ins_pipe(ialu_reg_shift);
10881 %}
10882 
10883 // A special-case pattern for card table stores.
10884 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10885   match(Set dst (URShiftL (CastP2X src1) src2));
10886 
10887   ins_cost(INSN_COST);
10888   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10889 
10890   ins_encode %{
10891     __ lsr(as_Register($dst$$reg),
10892            as_Register($src1$$reg),
10893            $src2$$constant &amp; 0x3f);
10894   %}
10895 
10896   ins_pipe(ialu_reg_shift);
10897 %}
10898 
10899 // Shift Right Arithmetic Register
10900 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10901   match(Set dst (RShiftL src1 src2));
10902 
10903   ins_cost(INSN_COST * 2);
10904   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10905 
10906   ins_encode %{
10907     __ asrv(as_Register($dst$$reg),
10908             as_Register($src1$$reg),
10909             as_Register($src2$$reg));
10910   %}
10911 
10912   ins_pipe(ialu_reg_reg_vshift);
10913 %}
10914 
10915 // Shift Right Arithmetic Immediate
10916 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10917   match(Set dst (RShiftL src1 src2));
10918 
10919   ins_cost(INSN_COST);
10920   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10921 
10922   ins_encode %{
10923     __ asr(as_Register($dst$$reg),
10924            as_Register($src1$$reg),
10925            $src2$$constant &amp; 0x3f);
10926   %}
10927 
10928   ins_pipe(ialu_reg_shift);
10929 %}
10930 
10931 // BEGIN This section of the file is automatically generated. Do not edit --------------
10932 
10933 instruct regL_not_reg(iRegLNoSp dst,
10934                          iRegL src1, immL_M1 m1,
10935                          rFlagsReg cr) %{
10936   match(Set dst (XorL src1 m1));
10937   ins_cost(INSN_COST);
10938   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10939 
10940   ins_encode %{
10941     __ eon(as_Register($dst$$reg),
10942               as_Register($src1$$reg),
10943               zr,
10944               Assembler::LSL, 0);
10945   %}
10946 
10947   ins_pipe(ialu_reg);
10948 %}
10949 instruct regI_not_reg(iRegINoSp dst,
10950                          iRegIorL2I src1, immI_M1 m1,
10951                          rFlagsReg cr) %{
10952   match(Set dst (XorI src1 m1));
10953   ins_cost(INSN_COST);
10954   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10955 
10956   ins_encode %{
10957     __ eonw(as_Register($dst$$reg),
10958               as_Register($src1$$reg),
10959               zr,
10960               Assembler::LSL, 0);
10961   %}
10962 
10963   ins_pipe(ialu_reg);
10964 %}
10965 
10966 instruct AndI_reg_not_reg(iRegINoSp dst,
10967                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10968                          rFlagsReg cr) %{
10969   match(Set dst (AndI src1 (XorI src2 m1)));
10970   ins_cost(INSN_COST);
10971   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10972 
10973   ins_encode %{
10974     __ bicw(as_Register($dst$$reg),
10975               as_Register($src1$$reg),
10976               as_Register($src2$$reg),
10977               Assembler::LSL, 0);
10978   %}
10979 
10980   ins_pipe(ialu_reg_reg);
10981 %}
10982 
10983 instruct AndL_reg_not_reg(iRegLNoSp dst,
10984                          iRegL src1, iRegL src2, immL_M1 m1,
10985                          rFlagsReg cr) %{
10986   match(Set dst (AndL src1 (XorL src2 m1)));
10987   ins_cost(INSN_COST);
10988   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10989 
10990   ins_encode %{
10991     __ bic(as_Register($dst$$reg),
10992               as_Register($src1$$reg),
10993               as_Register($src2$$reg),
10994               Assembler::LSL, 0);
10995   %}
10996 
10997   ins_pipe(ialu_reg_reg);
10998 %}
10999 
11000 instruct OrI_reg_not_reg(iRegINoSp dst,
11001                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11002                          rFlagsReg cr) %{
11003   match(Set dst (OrI src1 (XorI src2 m1)));
11004   ins_cost(INSN_COST);
11005   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
11006 
11007   ins_encode %{
11008     __ ornw(as_Register($dst$$reg),
11009               as_Register($src1$$reg),
11010               as_Register($src2$$reg),
11011               Assembler::LSL, 0);
11012   %}
11013 
11014   ins_pipe(ialu_reg_reg);
11015 %}
11016 
11017 instruct OrL_reg_not_reg(iRegLNoSp dst,
11018                          iRegL src1, iRegL src2, immL_M1 m1,
11019                          rFlagsReg cr) %{
11020   match(Set dst (OrL src1 (XorL src2 m1)));
11021   ins_cost(INSN_COST);
11022   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
11023 
11024   ins_encode %{
11025     __ orn(as_Register($dst$$reg),
11026               as_Register($src1$$reg),
11027               as_Register($src2$$reg),
11028               Assembler::LSL, 0);
11029   %}
11030 
11031   ins_pipe(ialu_reg_reg);
11032 %}
11033 
11034 instruct XorI_reg_not_reg(iRegINoSp dst,
11035                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11036                          rFlagsReg cr) %{
11037   match(Set dst (XorI m1 (XorI src2 src1)));
11038   ins_cost(INSN_COST);
11039   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
11040 
11041   ins_encode %{
11042     __ eonw(as_Register($dst$$reg),
11043               as_Register($src1$$reg),
11044               as_Register($src2$$reg),
11045               Assembler::LSL, 0);
11046   %}
11047 
11048   ins_pipe(ialu_reg_reg);
11049 %}
11050 
11051 instruct XorL_reg_not_reg(iRegLNoSp dst,
11052                          iRegL src1, iRegL src2, immL_M1 m1,
11053                          rFlagsReg cr) %{
11054   match(Set dst (XorL m1 (XorL src2 src1)));
11055   ins_cost(INSN_COST);
11056   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11057 
11058   ins_encode %{
11059     __ eon(as_Register($dst$$reg),
11060               as_Register($src1$$reg),
11061               as_Register($src2$$reg),
11062               Assembler::LSL, 0);
11063   %}
11064 
11065   ins_pipe(ialu_reg_reg);
11066 %}
11067 
11068 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11069                          iRegIorL2I src1, iRegIorL2I src2,
11070                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11071   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11072   ins_cost(1.9 * INSN_COST);
11073   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11074 
11075   ins_encode %{
11076     __ bicw(as_Register($dst$$reg),
11077               as_Register($src1$$reg),
11078               as_Register($src2$$reg),
11079               Assembler::LSR,
11080               $src3$$constant &amp; 0x1f);
11081   %}
11082 
11083   ins_pipe(ialu_reg_reg_shift);
11084 %}
11085 
11086 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11087                          iRegL src1, iRegL src2,
11088                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11089   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11090   ins_cost(1.9 * INSN_COST);
11091   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11092 
11093   ins_encode %{
11094     __ bic(as_Register($dst$$reg),
11095               as_Register($src1$$reg),
11096               as_Register($src2$$reg),
11097               Assembler::LSR,
11098               $src3$$constant &amp; 0x3f);
11099   %}
11100 
11101   ins_pipe(ialu_reg_reg_shift);
11102 %}
11103 
11104 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11105                          iRegIorL2I src1, iRegIorL2I src2,
11106                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11107   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11108   ins_cost(1.9 * INSN_COST);
11109   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11110 
11111   ins_encode %{
11112     __ bicw(as_Register($dst$$reg),
11113               as_Register($src1$$reg),
11114               as_Register($src2$$reg),
11115               Assembler::ASR,
11116               $src3$$constant &amp; 0x1f);
11117   %}
11118 
11119   ins_pipe(ialu_reg_reg_shift);
11120 %}
11121 
11122 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11123                          iRegL src1, iRegL src2,
11124                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11125   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11126   ins_cost(1.9 * INSN_COST);
11127   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11128 
11129   ins_encode %{
11130     __ bic(as_Register($dst$$reg),
11131               as_Register($src1$$reg),
11132               as_Register($src2$$reg),
11133               Assembler::ASR,
11134               $src3$$constant &amp; 0x3f);
11135   %}
11136 
11137   ins_pipe(ialu_reg_reg_shift);
11138 %}
11139 
11140 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11141                          iRegIorL2I src1, iRegIorL2I src2,
11142                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11143   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11144   ins_cost(1.9 * INSN_COST);
11145   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11146 
11147   ins_encode %{
11148     __ bicw(as_Register($dst$$reg),
11149               as_Register($src1$$reg),
11150               as_Register($src2$$reg),
11151               Assembler::LSL,
11152               $src3$$constant &amp; 0x1f);
11153   %}
11154 
11155   ins_pipe(ialu_reg_reg_shift);
11156 %}
11157 
11158 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11159                          iRegL src1, iRegL src2,
11160                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11161   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11162   ins_cost(1.9 * INSN_COST);
11163   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11164 
11165   ins_encode %{
11166     __ bic(as_Register($dst$$reg),
11167               as_Register($src1$$reg),
11168               as_Register($src2$$reg),
11169               Assembler::LSL,
11170               $src3$$constant &amp; 0x3f);
11171   %}
11172 
11173   ins_pipe(ialu_reg_reg_shift);
11174 %}
11175 
11176 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11177                          iRegIorL2I src1, iRegIorL2I src2,
11178                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11179   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11180   ins_cost(1.9 * INSN_COST);
11181   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11182 
11183   ins_encode %{
11184     __ eonw(as_Register($dst$$reg),
11185               as_Register($src1$$reg),
11186               as_Register($src2$$reg),
11187               Assembler::LSR,
11188               $src3$$constant &amp; 0x1f);
11189   %}
11190 
11191   ins_pipe(ialu_reg_reg_shift);
11192 %}
11193 
11194 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11195                          iRegL src1, iRegL src2,
11196                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11197   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11198   ins_cost(1.9 * INSN_COST);
11199   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11200 
11201   ins_encode %{
11202     __ eon(as_Register($dst$$reg),
11203               as_Register($src1$$reg),
11204               as_Register($src2$$reg),
11205               Assembler::LSR,
11206               $src3$$constant &amp; 0x3f);
11207   %}
11208 
11209   ins_pipe(ialu_reg_reg_shift);
11210 %}
11211 
11212 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11213                          iRegIorL2I src1, iRegIorL2I src2,
11214                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11215   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11216   ins_cost(1.9 * INSN_COST);
11217   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11218 
11219   ins_encode %{
11220     __ eonw(as_Register($dst$$reg),
11221               as_Register($src1$$reg),
11222               as_Register($src2$$reg),
11223               Assembler::ASR,
11224               $src3$$constant &amp; 0x1f);
11225   %}
11226 
11227   ins_pipe(ialu_reg_reg_shift);
11228 %}
11229 
11230 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11231                          iRegL src1, iRegL src2,
11232                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11233   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11234   ins_cost(1.9 * INSN_COST);
11235   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11236 
11237   ins_encode %{
11238     __ eon(as_Register($dst$$reg),
11239               as_Register($src1$$reg),
11240               as_Register($src2$$reg),
11241               Assembler::ASR,
11242               $src3$$constant &amp; 0x3f);
11243   %}
11244 
11245   ins_pipe(ialu_reg_reg_shift);
11246 %}
11247 
11248 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11249                          iRegIorL2I src1, iRegIorL2I src2,
11250                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11251   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11252   ins_cost(1.9 * INSN_COST);
11253   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11254 
11255   ins_encode %{
11256     __ eonw(as_Register($dst$$reg),
11257               as_Register($src1$$reg),
11258               as_Register($src2$$reg),
11259               Assembler::LSL,
11260               $src3$$constant &amp; 0x1f);
11261   %}
11262 
11263   ins_pipe(ialu_reg_reg_shift);
11264 %}
11265 
11266 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11267                          iRegL src1, iRegL src2,
11268                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11269   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11270   ins_cost(1.9 * INSN_COST);
11271   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11272 
11273   ins_encode %{
11274     __ eon(as_Register($dst$$reg),
11275               as_Register($src1$$reg),
11276               as_Register($src2$$reg),
11277               Assembler::LSL,
11278               $src3$$constant &amp; 0x3f);
11279   %}
11280 
11281   ins_pipe(ialu_reg_reg_shift);
11282 %}
11283 
11284 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11285                          iRegIorL2I src1, iRegIorL2I src2,
11286                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11287   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11288   ins_cost(1.9 * INSN_COST);
11289   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11290 
11291   ins_encode %{
11292     __ ornw(as_Register($dst$$reg),
11293               as_Register($src1$$reg),
11294               as_Register($src2$$reg),
11295               Assembler::LSR,
11296               $src3$$constant &amp; 0x1f);
11297   %}
11298 
11299   ins_pipe(ialu_reg_reg_shift);
11300 %}
11301 
11302 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11303                          iRegL src1, iRegL src2,
11304                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11305   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11306   ins_cost(1.9 * INSN_COST);
11307   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11308 
11309   ins_encode %{
11310     __ orn(as_Register($dst$$reg),
11311               as_Register($src1$$reg),
11312               as_Register($src2$$reg),
11313               Assembler::LSR,
11314               $src3$$constant &amp; 0x3f);
11315   %}
11316 
11317   ins_pipe(ialu_reg_reg_shift);
11318 %}
11319 
11320 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11321                          iRegIorL2I src1, iRegIorL2I src2,
11322                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11323   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11324   ins_cost(1.9 * INSN_COST);
11325   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11326 
11327   ins_encode %{
11328     __ ornw(as_Register($dst$$reg),
11329               as_Register($src1$$reg),
11330               as_Register($src2$$reg),
11331               Assembler::ASR,
11332               $src3$$constant &amp; 0x1f);
11333   %}
11334 
11335   ins_pipe(ialu_reg_reg_shift);
11336 %}
11337 
11338 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11339                          iRegL src1, iRegL src2,
11340                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11341   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11342   ins_cost(1.9 * INSN_COST);
11343   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11344 
11345   ins_encode %{
11346     __ orn(as_Register($dst$$reg),
11347               as_Register($src1$$reg),
11348               as_Register($src2$$reg),
11349               Assembler::ASR,
11350               $src3$$constant &amp; 0x3f);
11351   %}
11352 
11353   ins_pipe(ialu_reg_reg_shift);
11354 %}
11355 
11356 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11357                          iRegIorL2I src1, iRegIorL2I src2,
11358                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11359   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11360   ins_cost(1.9 * INSN_COST);
11361   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11362 
11363   ins_encode %{
11364     __ ornw(as_Register($dst$$reg),
11365               as_Register($src1$$reg),
11366               as_Register($src2$$reg),
11367               Assembler::LSL,
11368               $src3$$constant &amp; 0x1f);
11369   %}
11370 
11371   ins_pipe(ialu_reg_reg_shift);
11372 %}
11373 
11374 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11375                          iRegL src1, iRegL src2,
11376                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11377   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11378   ins_cost(1.9 * INSN_COST);
11379   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11380 
11381   ins_encode %{
11382     __ orn(as_Register($dst$$reg),
11383               as_Register($src1$$reg),
11384               as_Register($src2$$reg),
11385               Assembler::LSL,
11386               $src3$$constant &amp; 0x3f);
11387   %}
11388 
11389   ins_pipe(ialu_reg_reg_shift);
11390 %}
11391 
11392 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11393                          iRegIorL2I src1, iRegIorL2I src2,
11394                          immI src3, rFlagsReg cr) %{
11395   match(Set dst (AndI src1 (URShiftI src2 src3)));
11396 
11397   ins_cost(1.9 * INSN_COST);
11398   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11399 
11400   ins_encode %{
11401     __ andw(as_Register($dst$$reg),
11402               as_Register($src1$$reg),
11403               as_Register($src2$$reg),
11404               Assembler::LSR,
11405               $src3$$constant &amp; 0x1f);
11406   %}
11407 
11408   ins_pipe(ialu_reg_reg_shift);
11409 %}
11410 
11411 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11412                          iRegL src1, iRegL src2,
11413                          immI src3, rFlagsReg cr) %{
11414   match(Set dst (AndL src1 (URShiftL src2 src3)));
11415 
11416   ins_cost(1.9 * INSN_COST);
11417   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11418 
11419   ins_encode %{
11420     __ andr(as_Register($dst$$reg),
11421               as_Register($src1$$reg),
11422               as_Register($src2$$reg),
11423               Assembler::LSR,
11424               $src3$$constant &amp; 0x3f);
11425   %}
11426 
11427   ins_pipe(ialu_reg_reg_shift);
11428 %}
11429 
11430 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11431                          iRegIorL2I src1, iRegIorL2I src2,
11432                          immI src3, rFlagsReg cr) %{
11433   match(Set dst (AndI src1 (RShiftI src2 src3)));
11434 
11435   ins_cost(1.9 * INSN_COST);
11436   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11437 
11438   ins_encode %{
11439     __ andw(as_Register($dst$$reg),
11440               as_Register($src1$$reg),
11441               as_Register($src2$$reg),
11442               Assembler::ASR,
11443               $src3$$constant &amp; 0x1f);
11444   %}
11445 
11446   ins_pipe(ialu_reg_reg_shift);
11447 %}
11448 
11449 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11450                          iRegL src1, iRegL src2,
11451                          immI src3, rFlagsReg cr) %{
11452   match(Set dst (AndL src1 (RShiftL src2 src3)));
11453 
11454   ins_cost(1.9 * INSN_COST);
11455   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11456 
11457   ins_encode %{
11458     __ andr(as_Register($dst$$reg),
11459               as_Register($src1$$reg),
11460               as_Register($src2$$reg),
11461               Assembler::ASR,
11462               $src3$$constant &amp; 0x3f);
11463   %}
11464 
11465   ins_pipe(ialu_reg_reg_shift);
11466 %}
11467 
11468 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11469                          iRegIorL2I src1, iRegIorL2I src2,
11470                          immI src3, rFlagsReg cr) %{
11471   match(Set dst (AndI src1 (LShiftI src2 src3)));
11472 
11473   ins_cost(1.9 * INSN_COST);
11474   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11475 
11476   ins_encode %{
11477     __ andw(as_Register($dst$$reg),
11478               as_Register($src1$$reg),
11479               as_Register($src2$$reg),
11480               Assembler::LSL,
11481               $src3$$constant &amp; 0x1f);
11482   %}
11483 
11484   ins_pipe(ialu_reg_reg_shift);
11485 %}
11486 
11487 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11488                          iRegL src1, iRegL src2,
11489                          immI src3, rFlagsReg cr) %{
11490   match(Set dst (AndL src1 (LShiftL src2 src3)));
11491 
11492   ins_cost(1.9 * INSN_COST);
11493   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11494 
11495   ins_encode %{
11496     __ andr(as_Register($dst$$reg),
11497               as_Register($src1$$reg),
11498               as_Register($src2$$reg),
11499               Assembler::LSL,
11500               $src3$$constant &amp; 0x3f);
11501   %}
11502 
11503   ins_pipe(ialu_reg_reg_shift);
11504 %}
11505 
11506 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11507                          iRegIorL2I src1, iRegIorL2I src2,
11508                          immI src3, rFlagsReg cr) %{
11509   match(Set dst (XorI src1 (URShiftI src2 src3)));
11510 
11511   ins_cost(1.9 * INSN_COST);
11512   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11513 
11514   ins_encode %{
11515     __ eorw(as_Register($dst$$reg),
11516               as_Register($src1$$reg),
11517               as_Register($src2$$reg),
11518               Assembler::LSR,
11519               $src3$$constant &amp; 0x1f);
11520   %}
11521 
11522   ins_pipe(ialu_reg_reg_shift);
11523 %}
11524 
11525 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11526                          iRegL src1, iRegL src2,
11527                          immI src3, rFlagsReg cr) %{
11528   match(Set dst (XorL src1 (URShiftL src2 src3)));
11529 
11530   ins_cost(1.9 * INSN_COST);
11531   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11532 
11533   ins_encode %{
11534     __ eor(as_Register($dst$$reg),
11535               as_Register($src1$$reg),
11536               as_Register($src2$$reg),
11537               Assembler::LSR,
11538               $src3$$constant &amp; 0x3f);
11539   %}
11540 
11541   ins_pipe(ialu_reg_reg_shift);
11542 %}
11543 
11544 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11545                          iRegIorL2I src1, iRegIorL2I src2,
11546                          immI src3, rFlagsReg cr) %{
11547   match(Set dst (XorI src1 (RShiftI src2 src3)));
11548 
11549   ins_cost(1.9 * INSN_COST);
11550   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11551 
11552   ins_encode %{
11553     __ eorw(as_Register($dst$$reg),
11554               as_Register($src1$$reg),
11555               as_Register($src2$$reg),
11556               Assembler::ASR,
11557               $src3$$constant &amp; 0x1f);
11558   %}
11559 
11560   ins_pipe(ialu_reg_reg_shift);
11561 %}
11562 
11563 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11564                          iRegL src1, iRegL src2,
11565                          immI src3, rFlagsReg cr) %{
11566   match(Set dst (XorL src1 (RShiftL src2 src3)));
11567 
11568   ins_cost(1.9 * INSN_COST);
11569   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11570 
11571   ins_encode %{
11572     __ eor(as_Register($dst$$reg),
11573               as_Register($src1$$reg),
11574               as_Register($src2$$reg),
11575               Assembler::ASR,
11576               $src3$$constant &amp; 0x3f);
11577   %}
11578 
11579   ins_pipe(ialu_reg_reg_shift);
11580 %}
11581 
11582 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11583                          iRegIorL2I src1, iRegIorL2I src2,
11584                          immI src3, rFlagsReg cr) %{
11585   match(Set dst (XorI src1 (LShiftI src2 src3)));
11586 
11587   ins_cost(1.9 * INSN_COST);
11588   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11589 
11590   ins_encode %{
11591     __ eorw(as_Register($dst$$reg),
11592               as_Register($src1$$reg),
11593               as_Register($src2$$reg),
11594               Assembler::LSL,
11595               $src3$$constant &amp; 0x1f);
11596   %}
11597 
11598   ins_pipe(ialu_reg_reg_shift);
11599 %}
11600 
11601 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11602                          iRegL src1, iRegL src2,
11603                          immI src3, rFlagsReg cr) %{
11604   match(Set dst (XorL src1 (LShiftL src2 src3)));
11605 
11606   ins_cost(1.9 * INSN_COST);
11607   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11608 
11609   ins_encode %{
11610     __ eor(as_Register($dst$$reg),
11611               as_Register($src1$$reg),
11612               as_Register($src2$$reg),
11613               Assembler::LSL,
11614               $src3$$constant &amp; 0x3f);
11615   %}
11616 
11617   ins_pipe(ialu_reg_reg_shift);
11618 %}
11619 
11620 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11621                          iRegIorL2I src1, iRegIorL2I src2,
11622                          immI src3, rFlagsReg cr) %{
11623   match(Set dst (OrI src1 (URShiftI src2 src3)));
11624 
11625   ins_cost(1.9 * INSN_COST);
11626   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11627 
11628   ins_encode %{
11629     __ orrw(as_Register($dst$$reg),
11630               as_Register($src1$$reg),
11631               as_Register($src2$$reg),
11632               Assembler::LSR,
11633               $src3$$constant &amp; 0x1f);
11634   %}
11635 
11636   ins_pipe(ialu_reg_reg_shift);
11637 %}
11638 
11639 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11640                          iRegL src1, iRegL src2,
11641                          immI src3, rFlagsReg cr) %{
11642   match(Set dst (OrL src1 (URShiftL src2 src3)));
11643 
11644   ins_cost(1.9 * INSN_COST);
11645   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11646 
11647   ins_encode %{
11648     __ orr(as_Register($dst$$reg),
11649               as_Register($src1$$reg),
11650               as_Register($src2$$reg),
11651               Assembler::LSR,
11652               $src3$$constant &amp; 0x3f);
11653   %}
11654 
11655   ins_pipe(ialu_reg_reg_shift);
11656 %}
11657 
11658 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11659                          iRegIorL2I src1, iRegIorL2I src2,
11660                          immI src3, rFlagsReg cr) %{
11661   match(Set dst (OrI src1 (RShiftI src2 src3)));
11662 
11663   ins_cost(1.9 * INSN_COST);
11664   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11665 
11666   ins_encode %{
11667     __ orrw(as_Register($dst$$reg),
11668               as_Register($src1$$reg),
11669               as_Register($src2$$reg),
11670               Assembler::ASR,
11671               $src3$$constant &amp; 0x1f);
11672   %}
11673 
11674   ins_pipe(ialu_reg_reg_shift);
11675 %}
11676 
11677 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11678                          iRegL src1, iRegL src2,
11679                          immI src3, rFlagsReg cr) %{
11680   match(Set dst (OrL src1 (RShiftL src2 src3)));
11681 
11682   ins_cost(1.9 * INSN_COST);
11683   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11684 
11685   ins_encode %{
11686     __ orr(as_Register($dst$$reg),
11687               as_Register($src1$$reg),
11688               as_Register($src2$$reg),
11689               Assembler::ASR,
11690               $src3$$constant &amp; 0x3f);
11691   %}
11692 
11693   ins_pipe(ialu_reg_reg_shift);
11694 %}
11695 
11696 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11697                          iRegIorL2I src1, iRegIorL2I src2,
11698                          immI src3, rFlagsReg cr) %{
11699   match(Set dst (OrI src1 (LShiftI src2 src3)));
11700 
11701   ins_cost(1.9 * INSN_COST);
11702   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11703 
11704   ins_encode %{
11705     __ orrw(as_Register($dst$$reg),
11706               as_Register($src1$$reg),
11707               as_Register($src2$$reg),
11708               Assembler::LSL,
11709               $src3$$constant &amp; 0x1f);
11710   %}
11711 
11712   ins_pipe(ialu_reg_reg_shift);
11713 %}
11714 
11715 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11716                          iRegL src1, iRegL src2,
11717                          immI src3, rFlagsReg cr) %{
11718   match(Set dst (OrL src1 (LShiftL src2 src3)));
11719 
11720   ins_cost(1.9 * INSN_COST);
11721   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11722 
11723   ins_encode %{
11724     __ orr(as_Register($dst$$reg),
11725               as_Register($src1$$reg),
11726               as_Register($src2$$reg),
11727               Assembler::LSL,
11728               $src3$$constant &amp; 0x3f);
11729   %}
11730 
11731   ins_pipe(ialu_reg_reg_shift);
11732 %}
11733 
11734 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11735                          iRegIorL2I src1, iRegIorL2I src2,
11736                          immI src3, rFlagsReg cr) %{
11737   match(Set dst (AddI src1 (URShiftI src2 src3)));
11738 
11739   ins_cost(1.9 * INSN_COST);
11740   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11741 
11742   ins_encode %{
11743     __ addw(as_Register($dst$$reg),
11744               as_Register($src1$$reg),
11745               as_Register($src2$$reg),
11746               Assembler::LSR,
11747               $src3$$constant &amp; 0x1f);
11748   %}
11749 
11750   ins_pipe(ialu_reg_reg_shift);
11751 %}
11752 
11753 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11754                          iRegL src1, iRegL src2,
11755                          immI src3, rFlagsReg cr) %{
11756   match(Set dst (AddL src1 (URShiftL src2 src3)));
11757 
11758   ins_cost(1.9 * INSN_COST);
11759   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11760 
11761   ins_encode %{
11762     __ add(as_Register($dst$$reg),
11763               as_Register($src1$$reg),
11764               as_Register($src2$$reg),
11765               Assembler::LSR,
11766               $src3$$constant &amp; 0x3f);
11767   %}
11768 
11769   ins_pipe(ialu_reg_reg_shift);
11770 %}
11771 
11772 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11773                          iRegIorL2I src1, iRegIorL2I src2,
11774                          immI src3, rFlagsReg cr) %{
11775   match(Set dst (AddI src1 (RShiftI src2 src3)));
11776 
11777   ins_cost(1.9 * INSN_COST);
11778   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11779 
11780   ins_encode %{
11781     __ addw(as_Register($dst$$reg),
11782               as_Register($src1$$reg),
11783               as_Register($src2$$reg),
11784               Assembler::ASR,
11785               $src3$$constant &amp; 0x1f);
11786   %}
11787 
11788   ins_pipe(ialu_reg_reg_shift);
11789 %}
11790 
11791 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11792                          iRegL src1, iRegL src2,
11793                          immI src3, rFlagsReg cr) %{
11794   match(Set dst (AddL src1 (RShiftL src2 src3)));
11795 
11796   ins_cost(1.9 * INSN_COST);
11797   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11798 
11799   ins_encode %{
11800     __ add(as_Register($dst$$reg),
11801               as_Register($src1$$reg),
11802               as_Register($src2$$reg),
11803               Assembler::ASR,
11804               $src3$$constant &amp; 0x3f);
11805   %}
11806 
11807   ins_pipe(ialu_reg_reg_shift);
11808 %}
11809 
11810 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11811                          iRegIorL2I src1, iRegIorL2I src2,
11812                          immI src3, rFlagsReg cr) %{
11813   match(Set dst (AddI src1 (LShiftI src2 src3)));
11814 
11815   ins_cost(1.9 * INSN_COST);
11816   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11817 
11818   ins_encode %{
11819     __ addw(as_Register($dst$$reg),
11820               as_Register($src1$$reg),
11821               as_Register($src2$$reg),
11822               Assembler::LSL,
11823               $src3$$constant &amp; 0x1f);
11824   %}
11825 
11826   ins_pipe(ialu_reg_reg_shift);
11827 %}
11828 
11829 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11830                          iRegL src1, iRegL src2,
11831                          immI src3, rFlagsReg cr) %{
11832   match(Set dst (AddL src1 (LShiftL src2 src3)));
11833 
11834   ins_cost(1.9 * INSN_COST);
11835   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11836 
11837   ins_encode %{
11838     __ add(as_Register($dst$$reg),
11839               as_Register($src1$$reg),
11840               as_Register($src2$$reg),
11841               Assembler::LSL,
11842               $src3$$constant &amp; 0x3f);
11843   %}
11844 
11845   ins_pipe(ialu_reg_reg_shift);
11846 %}
11847 
11848 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11849                          iRegIorL2I src1, iRegIorL2I src2,
11850                          immI src3, rFlagsReg cr) %{
11851   match(Set dst (SubI src1 (URShiftI src2 src3)));
11852 
11853   ins_cost(1.9 * INSN_COST);
11854   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11855 
11856   ins_encode %{
11857     __ subw(as_Register($dst$$reg),
11858               as_Register($src1$$reg),
11859               as_Register($src2$$reg),
11860               Assembler::LSR,
11861               $src3$$constant &amp; 0x1f);
11862   %}
11863 
11864   ins_pipe(ialu_reg_reg_shift);
11865 %}
11866 
11867 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11868                          iRegL src1, iRegL src2,
11869                          immI src3, rFlagsReg cr) %{
11870   match(Set dst (SubL src1 (URShiftL src2 src3)));
11871 
11872   ins_cost(1.9 * INSN_COST);
11873   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11874 
11875   ins_encode %{
11876     __ sub(as_Register($dst$$reg),
11877               as_Register($src1$$reg),
11878               as_Register($src2$$reg),
11879               Assembler::LSR,
11880               $src3$$constant &amp; 0x3f);
11881   %}
11882 
11883   ins_pipe(ialu_reg_reg_shift);
11884 %}
11885 
11886 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11887                          iRegIorL2I src1, iRegIorL2I src2,
11888                          immI src3, rFlagsReg cr) %{
11889   match(Set dst (SubI src1 (RShiftI src2 src3)));
11890 
11891   ins_cost(1.9 * INSN_COST);
11892   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11893 
11894   ins_encode %{
11895     __ subw(as_Register($dst$$reg),
11896               as_Register($src1$$reg),
11897               as_Register($src2$$reg),
11898               Assembler::ASR,
11899               $src3$$constant &amp; 0x1f);
11900   %}
11901 
11902   ins_pipe(ialu_reg_reg_shift);
11903 %}
11904 
11905 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11906                          iRegL src1, iRegL src2,
11907                          immI src3, rFlagsReg cr) %{
11908   match(Set dst (SubL src1 (RShiftL src2 src3)));
11909 
11910   ins_cost(1.9 * INSN_COST);
11911   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11912 
11913   ins_encode %{
11914     __ sub(as_Register($dst$$reg),
11915               as_Register($src1$$reg),
11916               as_Register($src2$$reg),
11917               Assembler::ASR,
11918               $src3$$constant &amp; 0x3f);
11919   %}
11920 
11921   ins_pipe(ialu_reg_reg_shift);
11922 %}
11923 
11924 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11925                          iRegIorL2I src1, iRegIorL2I src2,
11926                          immI src3, rFlagsReg cr) %{
11927   match(Set dst (SubI src1 (LShiftI src2 src3)));
11928 
11929   ins_cost(1.9 * INSN_COST);
11930   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11931 
11932   ins_encode %{
11933     __ subw(as_Register($dst$$reg),
11934               as_Register($src1$$reg),
11935               as_Register($src2$$reg),
11936               Assembler::LSL,
11937               $src3$$constant &amp; 0x1f);
11938   %}
11939 
11940   ins_pipe(ialu_reg_reg_shift);
11941 %}
11942 
11943 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11944                          iRegL src1, iRegL src2,
11945                          immI src3, rFlagsReg cr) %{
11946   match(Set dst (SubL src1 (LShiftL src2 src3)));
11947 
11948   ins_cost(1.9 * INSN_COST);
11949   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11950 
11951   ins_encode %{
11952     __ sub(as_Register($dst$$reg),
11953               as_Register($src1$$reg),
11954               as_Register($src2$$reg),
11955               Assembler::LSL,
11956               $src3$$constant &amp; 0x3f);
11957   %}
11958 
11959   ins_pipe(ialu_reg_reg_shift);
11960 %}
11961 
11962 
11963 
11964 // Shift Left followed by Shift Right.
11965 // This idiom is used by the compiler for the i2b bytecode etc.
11966 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11967 %{
11968   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11969   ins_cost(INSN_COST * 2);
11970   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11971   ins_encode %{
11972     int lshift = $lshift_count$$constant &amp; 63;
11973     int rshift = $rshift_count$$constant &amp; 63;
11974     int s = 63 - lshift;
11975     int r = (rshift - lshift) &amp; 63;
11976     __ sbfm(as_Register($dst$$reg),
11977             as_Register($src$$reg),
11978             r, s);
11979   %}
11980 
11981   ins_pipe(ialu_reg_shift);
11982 %}
11983 
11984 // Shift Left followed by Shift Right.
11985 // This idiom is used by the compiler for the i2b bytecode etc.
11986 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11987 %{
11988   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11989   ins_cost(INSN_COST * 2);
11990   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11991   ins_encode %{
11992     int lshift = $lshift_count$$constant &amp; 31;
11993     int rshift = $rshift_count$$constant &amp; 31;
11994     int s = 31 - lshift;
11995     int r = (rshift - lshift) &amp; 31;
11996     __ sbfmw(as_Register($dst$$reg),
11997             as_Register($src$$reg),
11998             r, s);
11999   %}
12000 
12001   ins_pipe(ialu_reg_shift);
12002 %}
12003 
12004 // Shift Left followed by Shift Right.
12005 // This idiom is used by the compiler for the i2b bytecode etc.
12006 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
12007 %{
12008   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
12009   ins_cost(INSN_COST * 2);
12010   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
12011   ins_encode %{
12012     int lshift = $lshift_count$$constant &amp; 63;
12013     int rshift = $rshift_count$$constant &amp; 63;
12014     int s = 63 - lshift;
12015     int r = (rshift - lshift) &amp; 63;
12016     __ ubfm(as_Register($dst$$reg),
12017             as_Register($src$$reg),
12018             r, s);
12019   %}
12020 
12021   ins_pipe(ialu_reg_shift);
12022 %}
12023 
12024 // Shift Left followed by Shift Right.
12025 // This idiom is used by the compiler for the i2b bytecode etc.
12026 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12027 %{
12028   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
12029   ins_cost(INSN_COST * 2);
12030   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12031   ins_encode %{
12032     int lshift = $lshift_count$$constant &amp; 31;
12033     int rshift = $rshift_count$$constant &amp; 31;
12034     int s = 31 - lshift;
12035     int r = (rshift - lshift) &amp; 31;
12036     __ ubfmw(as_Register($dst$$reg),
12037             as_Register($src$$reg),
12038             r, s);
12039   %}
12040 
12041   ins_pipe(ialu_reg_shift);
12042 %}
12043 // Bitfield extract with shift &amp; mask
12044 
12045 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12046 %{
12047   match(Set dst (AndI (URShiftI src rshift) mask));
12048   // Make sure we are not going to exceed what ubfxw can do.
12049   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12050 
12051   ins_cost(INSN_COST);
12052   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12053   ins_encode %{
12054     int rshift = $rshift$$constant &amp; 31;
12055     long mask = $mask$$constant;
12056     int width = exact_log2(mask+1);
12057     __ ubfxw(as_Register($dst$$reg),
12058             as_Register($src$$reg), rshift, width);
12059   %}
12060   ins_pipe(ialu_reg_shift);
12061 %}
12062 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12063 %{
12064   match(Set dst (AndL (URShiftL src rshift) mask));
12065   // Make sure we are not going to exceed what ubfx can do.
12066   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12067 
12068   ins_cost(INSN_COST);
12069   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12070   ins_encode %{
12071     int rshift = $rshift$$constant &amp; 63;
12072     long mask = $mask$$constant;
12073     int width = exact_log2_long(mask+1);
12074     __ ubfx(as_Register($dst$$reg),
12075             as_Register($src$$reg), rshift, width);
12076   %}
12077   ins_pipe(ialu_reg_shift);
12078 %}
12079 
12080 // We can use ubfx when extending an And with a mask when we know mask
12081 // is positive.  We know that because immI_bitmask guarantees it.
12082 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12083 %{
12084   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12085   // Make sure we are not going to exceed what ubfxw can do.
12086   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12087 
12088   ins_cost(INSN_COST * 2);
12089   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12090   ins_encode %{
12091     int rshift = $rshift$$constant &amp; 31;
12092     long mask = $mask$$constant;
12093     int width = exact_log2(mask+1);
12094     __ ubfx(as_Register($dst$$reg),
12095             as_Register($src$$reg), rshift, width);
12096   %}
12097   ins_pipe(ialu_reg_shift);
12098 %}
12099 
12100 // We can use ubfiz when masking by a positive number and then left shifting the result.
12101 // We know that the mask is positive because immI_bitmask guarantees it.
12102 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12103 %{
12104   match(Set dst (LShiftI (AndI src mask) lshift));
12105   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12106 
12107   ins_cost(INSN_COST);
12108   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12109   ins_encode %{
12110     int lshift = $lshift$$constant &amp; 31;
12111     long mask = $mask$$constant;
12112     int width = exact_log2(mask+1);
12113     __ ubfizw(as_Register($dst$$reg),
12114           as_Register($src$$reg), lshift, width);
12115   %}
12116   ins_pipe(ialu_reg_shift);
12117 %}
12118 // We can use ubfiz when masking by a positive number and then left shifting the result.
12119 // We know that the mask is positive because immL_bitmask guarantees it.
12120 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12121 %{
12122   match(Set dst (LShiftL (AndL src mask) lshift));
12123   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12124 
12125   ins_cost(INSN_COST);
12126   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12127   ins_encode %{
12128     int lshift = $lshift$$constant &amp; 63;
12129     long mask = $mask$$constant;
12130     int width = exact_log2_long(mask+1);
12131     __ ubfiz(as_Register($dst$$reg),
12132           as_Register($src$$reg), lshift, width);
12133   %}
12134   ins_pipe(ialu_reg_shift);
12135 %}
12136 
12137 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12138 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12139 %{
12140   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12141   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12142 
12143   ins_cost(INSN_COST);
12144   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12145   ins_encode %{
12146     int lshift = $lshift$$constant &amp; 63;
12147     long mask = $mask$$constant;
12148     int width = exact_log2(mask+1);
12149     __ ubfiz(as_Register($dst$$reg),
12150              as_Register($src$$reg), lshift, width);
12151   %}
12152   ins_pipe(ialu_reg_shift);
12153 %}
12154 
12155 // Rotations
12156 
12157 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12158 %{
12159   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12160   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12161 
12162   ins_cost(INSN_COST);
12163   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12164 
12165   ins_encode %{
12166     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12167             $rshift$$constant &amp; 63);
12168   %}
12169   ins_pipe(ialu_reg_reg_extr);
12170 %}
12171 
12172 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12173 %{
12174   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12175   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12176 
12177   ins_cost(INSN_COST);
12178   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12179 
12180   ins_encode %{
12181     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12182             $rshift$$constant &amp; 31);
12183   %}
12184   ins_pipe(ialu_reg_reg_extr);
12185 %}
12186 
12187 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12188 %{
12189   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12190   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12191 
12192   ins_cost(INSN_COST);
12193   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12194 
12195   ins_encode %{
12196     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12197             $rshift$$constant &amp; 63);
12198   %}
12199   ins_pipe(ialu_reg_reg_extr);
12200 %}
12201 
12202 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12203 %{
12204   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12205   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12206 
12207   ins_cost(INSN_COST);
12208   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12209 
12210   ins_encode %{
12211     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12212             $rshift$$constant &amp; 31);
12213   %}
12214   ins_pipe(ialu_reg_reg_extr);
12215 %}
12216 
12217 
12218 // rol expander
12219 
12220 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12221 %{
12222   effect(DEF dst, USE src, USE shift);
12223 
12224   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12225   ins_cost(INSN_COST * 3);
12226   ins_encode %{
12227     __ subw(rscratch1, zr, as_Register($shift$$reg));
12228     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12229             rscratch1);
12230     %}
12231   ins_pipe(ialu_reg_reg_vshift);
12232 %}
12233 
12234 // rol expander
12235 
12236 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12237 %{
12238   effect(DEF dst, USE src, USE shift);
12239 
12240   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12241   ins_cost(INSN_COST * 3);
12242   ins_encode %{
12243     __ subw(rscratch1, zr, as_Register($shift$$reg));
12244     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12245             rscratch1);
12246     %}
12247   ins_pipe(ialu_reg_reg_vshift);
12248 %}
12249 
12250 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12251 %{
12252   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12253 
12254   expand %{
12255     rolL_rReg(dst, src, shift, cr);
12256   %}
12257 %}
12258 
12259 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12260 %{
12261   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12262 
12263   expand %{
12264     rolL_rReg(dst, src, shift, cr);
12265   %}
12266 %}
12267 
12268 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12269 %{
12270   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12271 
12272   expand %{
12273     rolI_rReg(dst, src, shift, cr);
12274   %}
12275 %}
12276 
12277 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12278 %{
12279   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12280 
12281   expand %{
12282     rolI_rReg(dst, src, shift, cr);
12283   %}
12284 %}
12285 
12286 // ror expander
12287 
12288 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12289 %{
12290   effect(DEF dst, USE src, USE shift);
12291 
12292   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12293   ins_cost(INSN_COST);
12294   ins_encode %{
12295     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12296             as_Register($shift$$reg));
12297     %}
12298   ins_pipe(ialu_reg_reg_vshift);
12299 %}
12300 
12301 // ror expander
12302 
12303 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12304 %{
12305   effect(DEF dst, USE src, USE shift);
12306 
12307   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12308   ins_cost(INSN_COST);
12309   ins_encode %{
12310     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12311             as_Register($shift$$reg));
12312     %}
12313   ins_pipe(ialu_reg_reg_vshift);
12314 %}
12315 
12316 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12317 %{
12318   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12319 
12320   expand %{
12321     rorL_rReg(dst, src, shift, cr);
12322   %}
12323 %}
12324 
12325 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12326 %{
12327   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12328 
12329   expand %{
12330     rorL_rReg(dst, src, shift, cr);
12331   %}
12332 %}
12333 
12334 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12335 %{
12336   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12337 
12338   expand %{
12339     rorI_rReg(dst, src, shift, cr);
12340   %}
12341 %}
12342 
12343 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12344 %{
12345   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12346 
12347   expand %{
12348     rorI_rReg(dst, src, shift, cr);
12349   %}
12350 %}
12351 
12352 // Add/subtract (extended)
12353 
12354 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12355 %{
12356   match(Set dst (AddL src1 (ConvI2L src2)));
12357   ins_cost(INSN_COST);
12358   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12359 
12360    ins_encode %{
12361      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12362             as_Register($src2$$reg), ext::sxtw);
12363    %}
12364   ins_pipe(ialu_reg_reg);
12365 %};
12366 
12367 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12368 %{
12369   match(Set dst (SubL src1 (ConvI2L src2)));
12370   ins_cost(INSN_COST);
12371   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12372 
12373    ins_encode %{
12374      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12375             as_Register($src2$$reg), ext::sxtw);
12376    %}
12377   ins_pipe(ialu_reg_reg);
12378 %};
12379 
12380 
12381 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12382 %{
12383   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12384   ins_cost(INSN_COST);
12385   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12386 
12387    ins_encode %{
12388      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12389             as_Register($src2$$reg), ext::sxth);
12390    %}
12391   ins_pipe(ialu_reg_reg);
12392 %}
12393 
12394 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12395 %{
12396   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12397   ins_cost(INSN_COST);
12398   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12399 
12400    ins_encode %{
12401      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12402             as_Register($src2$$reg), ext::sxtb);
12403    %}
12404   ins_pipe(ialu_reg_reg);
12405 %}
12406 
12407 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12408 %{
12409   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12410   ins_cost(INSN_COST);
12411   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12412 
12413    ins_encode %{
12414      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12415             as_Register($src2$$reg), ext::uxtb);
12416    %}
12417   ins_pipe(ialu_reg_reg);
12418 %}
12419 
12420 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12421 %{
12422   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12423   ins_cost(INSN_COST);
12424   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12425 
12426    ins_encode %{
12427      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12428             as_Register($src2$$reg), ext::sxth);
12429    %}
12430   ins_pipe(ialu_reg_reg);
12431 %}
12432 
12433 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12434 %{
12435   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12436   ins_cost(INSN_COST);
12437   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12438 
12439    ins_encode %{
12440      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12441             as_Register($src2$$reg), ext::sxtw);
12442    %}
12443   ins_pipe(ialu_reg_reg);
12444 %}
12445 
12446 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12447 %{
12448   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12449   ins_cost(INSN_COST);
12450   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12451 
12452    ins_encode %{
12453      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12454             as_Register($src2$$reg), ext::sxtb);
12455    %}
12456   ins_pipe(ialu_reg_reg);
12457 %}
12458 
12459 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12460 %{
12461   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12462   ins_cost(INSN_COST);
12463   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12464 
12465    ins_encode %{
12466      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12467             as_Register($src2$$reg), ext::uxtb);
12468    %}
12469   ins_pipe(ialu_reg_reg);
12470 %}
12471 
12472 
12473 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12474 %{
12475   match(Set dst (AddI src1 (AndI src2 mask)));
12476   ins_cost(INSN_COST);
12477   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12478 
12479    ins_encode %{
12480      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12481             as_Register($src2$$reg), ext::uxtb);
12482    %}
12483   ins_pipe(ialu_reg_reg);
12484 %}
12485 
12486 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12487 %{
12488   match(Set dst (AddI src1 (AndI src2 mask)));
12489   ins_cost(INSN_COST);
12490   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12491 
12492    ins_encode %{
12493      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12494             as_Register($src2$$reg), ext::uxth);
12495    %}
12496   ins_pipe(ialu_reg_reg);
12497 %}
12498 
12499 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12500 %{
12501   match(Set dst (AddL src1 (AndL src2 mask)));
12502   ins_cost(INSN_COST);
12503   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12504 
12505    ins_encode %{
12506      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12507             as_Register($src2$$reg), ext::uxtb);
12508    %}
12509   ins_pipe(ialu_reg_reg);
12510 %}
12511 
12512 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12513 %{
12514   match(Set dst (AddL src1 (AndL src2 mask)));
12515   ins_cost(INSN_COST);
12516   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12517 
12518    ins_encode %{
12519      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12520             as_Register($src2$$reg), ext::uxth);
12521    %}
12522   ins_pipe(ialu_reg_reg);
12523 %}
12524 
12525 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12526 %{
12527   match(Set dst (AddL src1 (AndL src2 mask)));
12528   ins_cost(INSN_COST);
12529   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12530 
12531    ins_encode %{
12532      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12533             as_Register($src2$$reg), ext::uxtw);
12534    %}
12535   ins_pipe(ialu_reg_reg);
12536 %}
12537 
12538 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12539 %{
12540   match(Set dst (SubI src1 (AndI src2 mask)));
12541   ins_cost(INSN_COST);
12542   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12543 
12544    ins_encode %{
12545      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12546             as_Register($src2$$reg), ext::uxtb);
12547    %}
12548   ins_pipe(ialu_reg_reg);
12549 %}
12550 
12551 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12552 %{
12553   match(Set dst (SubI src1 (AndI src2 mask)));
12554   ins_cost(INSN_COST);
12555   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12556 
12557    ins_encode %{
12558      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12559             as_Register($src2$$reg), ext::uxth);
12560    %}
12561   ins_pipe(ialu_reg_reg);
12562 %}
12563 
12564 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12565 %{
12566   match(Set dst (SubL src1 (AndL src2 mask)));
12567   ins_cost(INSN_COST);
12568   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12569 
12570    ins_encode %{
12571      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12572             as_Register($src2$$reg), ext::uxtb);
12573    %}
12574   ins_pipe(ialu_reg_reg);
12575 %}
12576 
12577 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12578 %{
12579   match(Set dst (SubL src1 (AndL src2 mask)));
12580   ins_cost(INSN_COST);
12581   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12582 
12583    ins_encode %{
12584      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12585             as_Register($src2$$reg), ext::uxth);
12586    %}
12587   ins_pipe(ialu_reg_reg);
12588 %}
12589 
12590 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12591 %{
12592   match(Set dst (SubL src1 (AndL src2 mask)));
12593   ins_cost(INSN_COST);
12594   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12595 
12596    ins_encode %{
12597      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12598             as_Register($src2$$reg), ext::uxtw);
12599    %}
12600   ins_pipe(ialu_reg_reg);
12601 %}
12602 
12603 
12604 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12605 %{
12606   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12607   ins_cost(1.9 * INSN_COST);
12608   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12609 
12610    ins_encode %{
12611      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12612             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12613    %}
12614   ins_pipe(ialu_reg_reg_shift);
12615 %}
12616 
12617 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12618 %{
12619   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12620   ins_cost(1.9 * INSN_COST);
12621   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12622 
12623    ins_encode %{
12624      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12625             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12626    %}
12627   ins_pipe(ialu_reg_reg_shift);
12628 %}
12629 
12630 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12631 %{
12632   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12633   ins_cost(1.9 * INSN_COST);
12634   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12635 
12636    ins_encode %{
12637      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12638             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12639    %}
12640   ins_pipe(ialu_reg_reg_shift);
12641 %}
12642 
12643 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12644 %{
12645   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12646   ins_cost(1.9 * INSN_COST);
12647   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12648 
12649    ins_encode %{
12650      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12651             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12652    %}
12653   ins_pipe(ialu_reg_reg_shift);
12654 %}
12655 
12656 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12657 %{
12658   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12659   ins_cost(1.9 * INSN_COST);
12660   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12661 
12662    ins_encode %{
12663      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12664             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12665    %}
12666   ins_pipe(ialu_reg_reg_shift);
12667 %}
12668 
12669 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12670 %{
12671   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12672   ins_cost(1.9 * INSN_COST);
12673   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12674 
12675    ins_encode %{
12676      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12677             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12678    %}
12679   ins_pipe(ialu_reg_reg_shift);
12680 %}
12681 
12682 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12683 %{
12684   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12685   ins_cost(1.9 * INSN_COST);
12686   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12687 
12688    ins_encode %{
12689      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12690             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12691    %}
12692   ins_pipe(ialu_reg_reg_shift);
12693 %}
12694 
12695 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12696 %{
12697   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12698   ins_cost(1.9 * INSN_COST);
12699   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12700 
12701    ins_encode %{
12702      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12703             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12704    %}
12705   ins_pipe(ialu_reg_reg_shift);
12706 %}
12707 
12708 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12709 %{
12710   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12711   ins_cost(1.9 * INSN_COST);
12712   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12713 
12714    ins_encode %{
12715      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12716             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12717    %}
12718   ins_pipe(ialu_reg_reg_shift);
12719 %}
12720 
12721 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12722 %{
12723   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12724   ins_cost(1.9 * INSN_COST);
12725   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12726 
12727    ins_encode %{
12728      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12729             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12730    %}
12731   ins_pipe(ialu_reg_reg_shift);
12732 %}
12733 
12734 
12735 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12736 %{
12737   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12738   ins_cost(1.9 * INSN_COST);
12739   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12740 
12741    ins_encode %{
12742      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12743             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12744    %}
12745   ins_pipe(ialu_reg_reg_shift);
12746 %};
12747 
12748 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12749 %{
12750   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12751   ins_cost(1.9 * INSN_COST);
12752   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12753 
12754    ins_encode %{
12755      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12756             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12757    %}
12758   ins_pipe(ialu_reg_reg_shift);
12759 %};
12760 
12761 
12762 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12763 %{
12764   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12765   ins_cost(1.9 * INSN_COST);
12766   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12767 
12768    ins_encode %{
12769      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12770             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12771    %}
12772   ins_pipe(ialu_reg_reg_shift);
12773 %}
12774 
12775 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12776 %{
12777   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12778   ins_cost(1.9 * INSN_COST);
12779   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12780 
12781    ins_encode %{
12782      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12783             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12784    %}
12785   ins_pipe(ialu_reg_reg_shift);
12786 %}
12787 
12788 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12789 %{
12790   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12791   ins_cost(1.9 * INSN_COST);
12792   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12793 
12794    ins_encode %{
12795      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12796             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12797    %}
12798   ins_pipe(ialu_reg_reg_shift);
12799 %}
12800 
12801 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12802 %{
12803   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12804   ins_cost(1.9 * INSN_COST);
12805   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12806 
12807    ins_encode %{
12808      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12809             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12810    %}
12811   ins_pipe(ialu_reg_reg_shift);
12812 %}
12813 
12814 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12815 %{
12816   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12817   ins_cost(1.9 * INSN_COST);
12818   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12819 
12820    ins_encode %{
12821      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12822             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12823    %}
12824   ins_pipe(ialu_reg_reg_shift);
12825 %}
12826 
12827 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12828 %{
12829   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12830   ins_cost(1.9 * INSN_COST);
12831   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12832 
12833    ins_encode %{
12834      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12835             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12836    %}
12837   ins_pipe(ialu_reg_reg_shift);
12838 %}
12839 
12840 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12841 %{
12842   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12843   ins_cost(1.9 * INSN_COST);
12844   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12845 
12846    ins_encode %{
12847      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12848             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12849    %}
12850   ins_pipe(ialu_reg_reg_shift);
12851 %}
12852 
12853 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12854 %{
12855   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12856   ins_cost(1.9 * INSN_COST);
12857   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12858 
12859    ins_encode %{
12860      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12861             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12862    %}
12863   ins_pipe(ialu_reg_reg_shift);
12864 %}
12865 
12866 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12867 %{
12868   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12869   ins_cost(1.9 * INSN_COST);
12870   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12871 
12872    ins_encode %{
12873      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12874             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12875    %}
12876   ins_pipe(ialu_reg_reg_shift);
12877 %}
12878 
12879 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12880 %{
12881   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12882   ins_cost(1.9 * INSN_COST);
12883   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12884 
12885    ins_encode %{
12886      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12887             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12888    %}
12889   ins_pipe(ialu_reg_reg_shift);
12890 %}
12891 // END This section of the file is automatically generated. Do not edit --------------
12892 
12893 // ============================================================================
12894 // Floating Point Arithmetic Instructions
12895 
12896 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12897   match(Set dst (AddF src1 src2));
12898 
12899   ins_cost(INSN_COST * 5);
12900   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12901 
12902   ins_encode %{
12903     __ fadds(as_FloatRegister($dst$$reg),
12904              as_FloatRegister($src1$$reg),
12905              as_FloatRegister($src2$$reg));
12906   %}
12907 
12908   ins_pipe(fp_dop_reg_reg_s);
12909 %}
12910 
12911 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12912   match(Set dst (AddD src1 src2));
12913 
12914   ins_cost(INSN_COST * 5);
12915   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12916 
12917   ins_encode %{
12918     __ faddd(as_FloatRegister($dst$$reg),
12919              as_FloatRegister($src1$$reg),
12920              as_FloatRegister($src2$$reg));
12921   %}
12922 
12923   ins_pipe(fp_dop_reg_reg_d);
12924 %}
12925 
12926 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12927   match(Set dst (SubF src1 src2));
12928 
12929   ins_cost(INSN_COST * 5);
12930   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12931 
12932   ins_encode %{
12933     __ fsubs(as_FloatRegister($dst$$reg),
12934              as_FloatRegister($src1$$reg),
12935              as_FloatRegister($src2$$reg));
12936   %}
12937 
12938   ins_pipe(fp_dop_reg_reg_s);
12939 %}
12940 
12941 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12942   match(Set dst (SubD src1 src2));
12943 
12944   ins_cost(INSN_COST * 5);
12945   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12946 
12947   ins_encode %{
12948     __ fsubd(as_FloatRegister($dst$$reg),
12949              as_FloatRegister($src1$$reg),
12950              as_FloatRegister($src2$$reg));
12951   %}
12952 
12953   ins_pipe(fp_dop_reg_reg_d);
12954 %}
12955 
12956 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12957   match(Set dst (MulF src1 src2));
12958 
12959   ins_cost(INSN_COST * 6);
12960   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12961 
12962   ins_encode %{
12963     __ fmuls(as_FloatRegister($dst$$reg),
12964              as_FloatRegister($src1$$reg),
12965              as_FloatRegister($src2$$reg));
12966   %}
12967 
12968   ins_pipe(fp_dop_reg_reg_s);
12969 %}
12970 
12971 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12972   match(Set dst (MulD src1 src2));
12973 
12974   ins_cost(INSN_COST * 6);
12975   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12976 
12977   ins_encode %{
12978     __ fmuld(as_FloatRegister($dst$$reg),
12979              as_FloatRegister($src1$$reg),
12980              as_FloatRegister($src2$$reg));
12981   %}
12982 
12983   ins_pipe(fp_dop_reg_reg_d);
12984 %}
12985 
12986 // src1 * src2 + src3
12987 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12988   predicate(UseFMA);
12989   match(Set dst (FmaF src3 (Binary src1 src2)));
12990 
12991   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12992 
12993   ins_encode %{
12994     __ fmadds(as_FloatRegister($dst$$reg),
12995              as_FloatRegister($src1$$reg),
12996              as_FloatRegister($src2$$reg),
12997              as_FloatRegister($src3$$reg));
12998   %}
12999 
13000   ins_pipe(pipe_class_default);
13001 %}
13002 
13003 // src1 * src2 + src3
13004 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13005   predicate(UseFMA);
13006   match(Set dst (FmaD src3 (Binary src1 src2)));
13007 
13008   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
13009 
13010   ins_encode %{
13011     __ fmaddd(as_FloatRegister($dst$$reg),
13012              as_FloatRegister($src1$$reg),
13013              as_FloatRegister($src2$$reg),
13014              as_FloatRegister($src3$$reg));
13015   %}
13016 
13017   ins_pipe(pipe_class_default);
13018 %}
13019 
13020 // -src1 * src2 + src3
13021 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13022   predicate(UseFMA);
13023   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
13024   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
13025 
13026   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
13027 
13028   ins_encode %{
13029     __ fmsubs(as_FloatRegister($dst$$reg),
13030               as_FloatRegister($src1$$reg),
13031               as_FloatRegister($src2$$reg),
13032               as_FloatRegister($src3$$reg));
13033   %}
13034 
13035   ins_pipe(pipe_class_default);
13036 %}
13037 
13038 // -src1 * src2 + src3
13039 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13040   predicate(UseFMA);
13041   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
13042   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
13043 
13044   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13045 
13046   ins_encode %{
13047     __ fmsubd(as_FloatRegister($dst$$reg),
13048               as_FloatRegister($src1$$reg),
13049               as_FloatRegister($src2$$reg),
13050               as_FloatRegister($src3$$reg));
13051   %}
13052 
13053   ins_pipe(pipe_class_default);
13054 %}
13055 
13056 // -src1 * src2 - src3
13057 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13058   predicate(UseFMA);
13059   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13060   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13061 
13062   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13063 
13064   ins_encode %{
13065     __ fnmadds(as_FloatRegister($dst$$reg),
13066                as_FloatRegister($src1$$reg),
13067                as_FloatRegister($src2$$reg),
13068                as_FloatRegister($src3$$reg));
13069   %}
13070 
13071   ins_pipe(pipe_class_default);
13072 %}
13073 
13074 // -src1 * src2 - src3
13075 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13076   predicate(UseFMA);
13077   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13078   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13079 
13080   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13081 
13082   ins_encode %{
13083     __ fnmaddd(as_FloatRegister($dst$$reg),
13084                as_FloatRegister($src1$$reg),
13085                as_FloatRegister($src2$$reg),
13086                as_FloatRegister($src3$$reg));
13087   %}
13088 
13089   ins_pipe(pipe_class_default);
13090 %}
13091 
13092 // src1 * src2 - src3
13093 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13094   predicate(UseFMA);
13095   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13096 
13097   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13098 
13099   ins_encode %{
13100     __ fnmsubs(as_FloatRegister($dst$$reg),
13101                as_FloatRegister($src1$$reg),
13102                as_FloatRegister($src2$$reg),
13103                as_FloatRegister($src3$$reg));
13104   %}
13105 
13106   ins_pipe(pipe_class_default);
13107 %}
13108 
13109 // src1 * src2 - src3
13110 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13111   predicate(UseFMA);
13112   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13113 
13114   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13115 
13116   ins_encode %{
13117   // n.b. insn name should be fnmsubd
13118     __ fnmsub(as_FloatRegister($dst$$reg),
13119               as_FloatRegister($src1$$reg),
13120               as_FloatRegister($src2$$reg),
13121               as_FloatRegister($src3$$reg));
13122   %}
13123 
13124   ins_pipe(pipe_class_default);
13125 %}
13126 
13127 
13128 // Math.max(FF)F
13129 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13130   match(Set dst (MaxF src1 src2));
13131 
13132   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13133   ins_encode %{
13134     __ fmaxs(as_FloatRegister($dst$$reg),
13135              as_FloatRegister($src1$$reg),
13136              as_FloatRegister($src2$$reg));
13137   %}
13138 
13139   ins_pipe(fp_dop_reg_reg_s);
13140 %}
13141 
13142 // Math.min(FF)F
13143 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13144   match(Set dst (MinF src1 src2));
13145 
13146   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13147   ins_encode %{
13148     __ fmins(as_FloatRegister($dst$$reg),
13149              as_FloatRegister($src1$$reg),
13150              as_FloatRegister($src2$$reg));
13151   %}
13152 
13153   ins_pipe(fp_dop_reg_reg_s);
13154 %}
13155 
13156 // Math.max(DD)D
13157 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13158   match(Set dst (MaxD src1 src2));
13159 
13160   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13161   ins_encode %{
13162     __ fmaxd(as_FloatRegister($dst$$reg),
13163              as_FloatRegister($src1$$reg),
13164              as_FloatRegister($src2$$reg));
13165   %}
13166 
13167   ins_pipe(fp_dop_reg_reg_d);
13168 %}
13169 
13170 // Math.min(DD)D
13171 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13172   match(Set dst (MinD src1 src2));
13173 
13174   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13175   ins_encode %{
13176     __ fmind(as_FloatRegister($dst$$reg),
13177              as_FloatRegister($src1$$reg),
13178              as_FloatRegister($src2$$reg));
13179   %}
13180 
13181   ins_pipe(fp_dop_reg_reg_d);
13182 %}
13183 
13184 
13185 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13186   match(Set dst (DivF src1  src2));
13187 
13188   ins_cost(INSN_COST * 18);
13189   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13190 
13191   ins_encode %{
13192     __ fdivs(as_FloatRegister($dst$$reg),
13193              as_FloatRegister($src1$$reg),
13194              as_FloatRegister($src2$$reg));
13195   %}
13196 
13197   ins_pipe(fp_div_s);
13198 %}
13199 
13200 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13201   match(Set dst (DivD src1  src2));
13202 
13203   ins_cost(INSN_COST * 32);
13204   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13205 
13206   ins_encode %{
13207     __ fdivd(as_FloatRegister($dst$$reg),
13208              as_FloatRegister($src1$$reg),
13209              as_FloatRegister($src2$$reg));
13210   %}
13211 
13212   ins_pipe(fp_div_d);
13213 %}
13214 
13215 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13216   match(Set dst (NegF src));
13217 
13218   ins_cost(INSN_COST * 3);
13219   format %{ &quot;fneg   $dst, $src&quot; %}
13220 
13221   ins_encode %{
13222     __ fnegs(as_FloatRegister($dst$$reg),
13223              as_FloatRegister($src$$reg));
13224   %}
13225 
13226   ins_pipe(fp_uop_s);
13227 %}
13228 
13229 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13230   match(Set dst (NegD src));
13231 
13232   ins_cost(INSN_COST * 3);
13233   format %{ &quot;fnegd   $dst, $src&quot; %}
13234 
13235   ins_encode %{
13236     __ fnegd(as_FloatRegister($dst$$reg),
13237              as_FloatRegister($src$$reg));
13238   %}
13239 
13240   ins_pipe(fp_uop_d);
13241 %}
13242 
13243 instruct absF_reg(vRegF dst, vRegF src) %{
13244   match(Set dst (AbsF src));
13245 
13246   ins_cost(INSN_COST * 3);
13247   format %{ &quot;fabss   $dst, $src&quot; %}
13248   ins_encode %{
13249     __ fabss(as_FloatRegister($dst$$reg),
13250              as_FloatRegister($src$$reg));
13251   %}
13252 
13253   ins_pipe(fp_uop_s);
13254 %}
13255 
13256 instruct absD_reg(vRegD dst, vRegD src) %{
13257   match(Set dst (AbsD src));
13258 
13259   ins_cost(INSN_COST * 3);
13260   format %{ &quot;fabsd   $dst, $src&quot; %}
13261   ins_encode %{
13262     __ fabsd(as_FloatRegister($dst$$reg),
13263              as_FloatRegister($src$$reg));
13264   %}
13265 
13266   ins_pipe(fp_uop_d);
13267 %}
13268 
13269 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13270   match(Set dst (SqrtD src));
13271 
13272   ins_cost(INSN_COST * 50);
13273   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13274   ins_encode %{
13275     __ fsqrtd(as_FloatRegister($dst$$reg),
13276              as_FloatRegister($src$$reg));
13277   %}
13278 
13279   ins_pipe(fp_div_s);
13280 %}
13281 
13282 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13283   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13284 
13285   ins_cost(INSN_COST * 50);
13286   format %{ &quot;fsqrts  $dst, $src&quot; %}
13287   ins_encode %{
13288     __ fsqrts(as_FloatRegister($dst$$reg),
13289              as_FloatRegister($src$$reg));
13290   %}
13291 
13292   ins_pipe(fp_div_d);
13293 %}
13294 
13295 // Math.rint, floor, ceil
13296 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13297   match(Set dst (RoundDoubleMode src rmode));
13298   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13299   ins_encode %{
13300     switch ($rmode$$constant) {
13301       case RoundDoubleModeNode::rmode_rint:
13302         __ frintnd(as_FloatRegister($dst$$reg),
13303                    as_FloatRegister($src$$reg));
13304         break;
13305       case RoundDoubleModeNode::rmode_floor:
13306         __ frintmd(as_FloatRegister($dst$$reg),
13307                    as_FloatRegister($src$$reg));
13308         break;
13309       case RoundDoubleModeNode::rmode_ceil:
13310         __ frintpd(as_FloatRegister($dst$$reg),
13311                    as_FloatRegister($src$$reg));
13312         break;
13313     }
13314   %}
13315   ins_pipe(fp_uop_d);
13316 %}
13317 
13318 // ============================================================================
13319 // Logical Instructions
13320 
13321 // Integer Logical Instructions
13322 
13323 // And Instructions
13324 
13325 
13326 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13327   match(Set dst (AndI src1 src2));
13328 
13329   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13330 
13331   ins_cost(INSN_COST);
13332   ins_encode %{
13333     __ andw(as_Register($dst$$reg),
13334             as_Register($src1$$reg),
13335             as_Register($src2$$reg));
13336   %}
13337 
13338   ins_pipe(ialu_reg_reg);
13339 %}
13340 
13341 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13342   match(Set dst (AndI src1 src2));
13343 
13344   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13345 
13346   ins_cost(INSN_COST);
13347   ins_encode %{
13348     __ andw(as_Register($dst$$reg),
13349             as_Register($src1$$reg),
13350             (unsigned long)($src2$$constant));
13351   %}
13352 
13353   ins_pipe(ialu_reg_imm);
13354 %}
13355 
13356 // Or Instructions
13357 
13358 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13359   match(Set dst (OrI src1 src2));
13360 
13361   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13362 
13363   ins_cost(INSN_COST);
13364   ins_encode %{
13365     __ orrw(as_Register($dst$$reg),
13366             as_Register($src1$$reg),
13367             as_Register($src2$$reg));
13368   %}
13369 
13370   ins_pipe(ialu_reg_reg);
13371 %}
13372 
13373 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13374   match(Set dst (OrI src1 src2));
13375 
13376   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13377 
13378   ins_cost(INSN_COST);
13379   ins_encode %{
13380     __ orrw(as_Register($dst$$reg),
13381             as_Register($src1$$reg),
13382             (unsigned long)($src2$$constant));
13383   %}
13384 
13385   ins_pipe(ialu_reg_imm);
13386 %}
13387 
13388 // Xor Instructions
13389 
13390 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13391   match(Set dst (XorI src1 src2));
13392 
13393   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13394 
13395   ins_cost(INSN_COST);
13396   ins_encode %{
13397     __ eorw(as_Register($dst$$reg),
13398             as_Register($src1$$reg),
13399             as_Register($src2$$reg));
13400   %}
13401 
13402   ins_pipe(ialu_reg_reg);
13403 %}
13404 
13405 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13406   match(Set dst (XorI src1 src2));
13407 
13408   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13409 
13410   ins_cost(INSN_COST);
13411   ins_encode %{
13412     __ eorw(as_Register($dst$$reg),
13413             as_Register($src1$$reg),
13414             (unsigned long)($src2$$constant));
13415   %}
13416 
13417   ins_pipe(ialu_reg_imm);
13418 %}
13419 
13420 // Long Logical Instructions
13421 // TODO
13422 
13423 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13424   match(Set dst (AndL src1 src2));
13425 
13426   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13427 
13428   ins_cost(INSN_COST);
13429   ins_encode %{
13430     __ andr(as_Register($dst$$reg),
13431             as_Register($src1$$reg),
13432             as_Register($src2$$reg));
13433   %}
13434 
13435   ins_pipe(ialu_reg_reg);
13436 %}
13437 
13438 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13439   match(Set dst (AndL src1 src2));
13440 
13441   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13442 
13443   ins_cost(INSN_COST);
13444   ins_encode %{
13445     __ andr(as_Register($dst$$reg),
13446             as_Register($src1$$reg),
13447             (unsigned long)($src2$$constant));
13448   %}
13449 
13450   ins_pipe(ialu_reg_imm);
13451 %}
13452 
13453 // Or Instructions
13454 
13455 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13456   match(Set dst (OrL src1 src2));
13457 
13458   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13459 
13460   ins_cost(INSN_COST);
13461   ins_encode %{
13462     __ orr(as_Register($dst$$reg),
13463            as_Register($src1$$reg),
13464            as_Register($src2$$reg));
13465   %}
13466 
13467   ins_pipe(ialu_reg_reg);
13468 %}
13469 
13470 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13471   match(Set dst (OrL src1 src2));
13472 
13473   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13474 
13475   ins_cost(INSN_COST);
13476   ins_encode %{
13477     __ orr(as_Register($dst$$reg),
13478            as_Register($src1$$reg),
13479            (unsigned long)($src2$$constant));
13480   %}
13481 
13482   ins_pipe(ialu_reg_imm);
13483 %}
13484 
13485 // Xor Instructions
13486 
13487 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13488   match(Set dst (XorL src1 src2));
13489 
13490   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13491 
13492   ins_cost(INSN_COST);
13493   ins_encode %{
13494     __ eor(as_Register($dst$$reg),
13495            as_Register($src1$$reg),
13496            as_Register($src2$$reg));
13497   %}
13498 
13499   ins_pipe(ialu_reg_reg);
13500 %}
13501 
13502 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13503   match(Set dst (XorL src1 src2));
13504 
13505   ins_cost(INSN_COST);
13506   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13507 
13508   ins_encode %{
13509     __ eor(as_Register($dst$$reg),
13510            as_Register($src1$$reg),
13511            (unsigned long)($src2$$constant));
13512   %}
13513 
13514   ins_pipe(ialu_reg_imm);
13515 %}
13516 
13517 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13518 %{
13519   match(Set dst (ConvI2L src));
13520 
13521   ins_cost(INSN_COST);
13522   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13523   ins_encode %{
13524     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13525   %}
13526   ins_pipe(ialu_reg_shift);
13527 %}
13528 
13529 // this pattern occurs in bigmath arithmetic
13530 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13531 %{
13532   match(Set dst (AndL (ConvI2L src) mask));
13533 
13534   ins_cost(INSN_COST);
13535   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13536   ins_encode %{
13537     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13538   %}
13539 
13540   ins_pipe(ialu_reg_shift);
13541 %}
13542 
13543 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13544   match(Set dst (ConvL2I src));
13545 
13546   ins_cost(INSN_COST);
13547   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13548 
13549   ins_encode %{
13550     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13551   %}
13552 
13553   ins_pipe(ialu_reg);
13554 %}
13555 
13556 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13557 %{
13558   match(Set dst (Conv2B src));
13559   effect(KILL cr);
13560 
13561   format %{
13562     &quot;cmpw $src, zr\n\t&quot;
13563     &quot;cset $dst, ne&quot;
13564   %}
13565 
13566   ins_encode %{
13567     __ cmpw(as_Register($src$$reg), zr);
13568     __ cset(as_Register($dst$$reg), Assembler::NE);
13569   %}
13570 
13571   ins_pipe(ialu_reg);
13572 %}
13573 
13574 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13575 %{
13576   match(Set dst (Conv2B src));
13577   effect(KILL cr);
13578 
13579   format %{
13580     &quot;cmp  $src, zr\n\t&quot;
13581     &quot;cset $dst, ne&quot;
13582   %}
13583 
13584   ins_encode %{
13585     __ cmp(as_Register($src$$reg), zr);
13586     __ cset(as_Register($dst$$reg), Assembler::NE);
13587   %}
13588 
13589   ins_pipe(ialu_reg);
13590 %}
13591 
13592 instruct convD2F_reg(vRegF dst, vRegD src) %{
13593   match(Set dst (ConvD2F src));
13594 
13595   ins_cost(INSN_COST * 5);
13596   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13597 
13598   ins_encode %{
13599     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13600   %}
13601 
13602   ins_pipe(fp_d2f);
13603 %}
13604 
13605 instruct convF2D_reg(vRegD dst, vRegF src) %{
13606   match(Set dst (ConvF2D src));
13607 
13608   ins_cost(INSN_COST * 5);
13609   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13610 
13611   ins_encode %{
13612     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13613   %}
13614 
13615   ins_pipe(fp_f2d);
13616 %}
13617 
13618 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13619   match(Set dst (ConvF2I src));
13620 
13621   ins_cost(INSN_COST * 5);
13622   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13623 
13624   ins_encode %{
13625     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13626   %}
13627 
13628   ins_pipe(fp_f2i);
13629 %}
13630 
13631 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13632   match(Set dst (ConvF2L src));
13633 
13634   ins_cost(INSN_COST * 5);
13635   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13636 
13637   ins_encode %{
13638     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13639   %}
13640 
13641   ins_pipe(fp_f2l);
13642 %}
13643 
13644 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13645   match(Set dst (ConvI2F src));
13646 
13647   ins_cost(INSN_COST * 5);
13648   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13649 
13650   ins_encode %{
13651     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13652   %}
13653 
13654   ins_pipe(fp_i2f);
13655 %}
13656 
13657 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13658   match(Set dst (ConvL2F src));
13659 
13660   ins_cost(INSN_COST * 5);
13661   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13662 
13663   ins_encode %{
13664     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13665   %}
13666 
13667   ins_pipe(fp_l2f);
13668 %}
13669 
13670 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13671   match(Set dst (ConvD2I src));
13672 
13673   ins_cost(INSN_COST * 5);
13674   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13675 
13676   ins_encode %{
13677     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13678   %}
13679 
13680   ins_pipe(fp_d2i);
13681 %}
13682 
13683 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13684   match(Set dst (ConvD2L src));
13685 
13686   ins_cost(INSN_COST * 5);
13687   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13688 
13689   ins_encode %{
13690     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13691   %}
13692 
13693   ins_pipe(fp_d2l);
13694 %}
13695 
13696 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13697   match(Set dst (ConvI2D src));
13698 
13699   ins_cost(INSN_COST * 5);
13700   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13701 
13702   ins_encode %{
13703     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13704   %}
13705 
13706   ins_pipe(fp_i2d);
13707 %}
13708 
13709 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13710   match(Set dst (ConvL2D src));
13711 
13712   ins_cost(INSN_COST * 5);
13713   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13714 
13715   ins_encode %{
13716     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13717   %}
13718 
13719   ins_pipe(fp_l2d);
13720 %}
13721 
13722 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13723 
13724 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13725 
13726   match(Set dst (MoveF2I src));
13727 
13728   effect(DEF dst, USE src);
13729 
13730   ins_cost(4 * INSN_COST);
13731 
13732   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13733 
13734   ins_encode %{
13735     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13736   %}
13737 
13738   ins_pipe(iload_reg_reg);
13739 
13740 %}
13741 
13742 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13743 
13744   match(Set dst (MoveI2F src));
13745 
13746   effect(DEF dst, USE src);
13747 
13748   ins_cost(4 * INSN_COST);
13749 
13750   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13751 
13752   ins_encode %{
13753     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13754   %}
13755 
13756   ins_pipe(pipe_class_memory);
13757 
13758 %}
13759 
13760 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13761 
13762   match(Set dst (MoveD2L src));
13763 
13764   effect(DEF dst, USE src);
13765 
13766   ins_cost(4 * INSN_COST);
13767 
13768   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13769 
13770   ins_encode %{
13771     __ ldr($dst$$Register, Address(sp, $src$$disp));
13772   %}
13773 
13774   ins_pipe(iload_reg_reg);
13775 
13776 %}
13777 
13778 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13779 
13780   match(Set dst (MoveL2D src));
13781 
13782   effect(DEF dst, USE src);
13783 
13784   ins_cost(4 * INSN_COST);
13785 
13786   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13787 
13788   ins_encode %{
13789     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13790   %}
13791 
13792   ins_pipe(pipe_class_memory);
13793 
13794 %}
13795 
13796 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13797 
13798   match(Set dst (MoveF2I src));
13799 
13800   effect(DEF dst, USE src);
13801 
13802   ins_cost(INSN_COST);
13803 
13804   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13805 
13806   ins_encode %{
13807     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13808   %}
13809 
13810   ins_pipe(pipe_class_memory);
13811 
13812 %}
13813 
13814 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13815 
13816   match(Set dst (MoveI2F src));
13817 
13818   effect(DEF dst, USE src);
13819 
13820   ins_cost(INSN_COST);
13821 
13822   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13823 
13824   ins_encode %{
13825     __ strw($src$$Register, Address(sp, $dst$$disp));
13826   %}
13827 
13828   ins_pipe(istore_reg_reg);
13829 
13830 %}
13831 
13832 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13833 
13834   match(Set dst (MoveD2L src));
13835 
13836   effect(DEF dst, USE src);
13837 
13838   ins_cost(INSN_COST);
13839 
13840   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13841 
13842   ins_encode %{
13843     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13844   %}
13845 
13846   ins_pipe(pipe_class_memory);
13847 
13848 %}
13849 
13850 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13851 
13852   match(Set dst (MoveL2D src));
13853 
13854   effect(DEF dst, USE src);
13855 
13856   ins_cost(INSN_COST);
13857 
13858   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13859 
13860   ins_encode %{
13861     __ str($src$$Register, Address(sp, $dst$$disp));
13862   %}
13863 
13864   ins_pipe(istore_reg_reg);
13865 
13866 %}
13867 
13868 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13869 
13870   match(Set dst (MoveF2I src));
13871 
13872   effect(DEF dst, USE src);
13873 
13874   ins_cost(INSN_COST);
13875 
13876   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13877 
13878   ins_encode %{
13879     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13880   %}
13881 
13882   ins_pipe(fp_f2i);
13883 
13884 %}
13885 
13886 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13887 
13888   match(Set dst (MoveI2F src));
13889 
13890   effect(DEF dst, USE src);
13891 
13892   ins_cost(INSN_COST);
13893 
13894   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13895 
13896   ins_encode %{
13897     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13898   %}
13899 
13900   ins_pipe(fp_i2f);
13901 
13902 %}
13903 
13904 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13905 
13906   match(Set dst (MoveD2L src));
13907 
13908   effect(DEF dst, USE src);
13909 
13910   ins_cost(INSN_COST);
13911 
13912   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13913 
13914   ins_encode %{
13915     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13916   %}
13917 
13918   ins_pipe(fp_d2l);
13919 
13920 %}
13921 
13922 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13923 
13924   match(Set dst (MoveL2D src));
13925 
13926   effect(DEF dst, USE src);
13927 
13928   ins_cost(INSN_COST);
13929 
13930   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13931 
13932   ins_encode %{
13933     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13934   %}
13935 
13936   ins_pipe(fp_l2d);
13937 
13938 %}
13939 
13940 // ============================================================================
13941 // clearing of an array
13942 
13943 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)
13944 %{
13945   match(Set dummy (ClearArray (Binary cnt base) val));
13946   effect(USE_KILL cnt, USE_KILL base);
13947 
13948   ins_cost(4 * INSN_COST);
13949   format %{ &quot;ClearArray $cnt, $base, $val&quot; %}
13950 
13951   ins_encode %{
13952     __ fill_words($base$$Register, $cnt$$Register, $val$$Register);
13953   %}
13954 
13955   ins_pipe(pipe_class_memory);
13956 %}
13957 
13958 // ============================================================================
13959 // Overflow Math Instructions
13960 
13961 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13962 %{
13963   match(Set cr (OverflowAddI op1 op2));
13964 
13965   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13966   ins_cost(INSN_COST);
13967   ins_encode %{
13968     __ cmnw($op1$$Register, $op2$$Register);
13969   %}
13970 
13971   ins_pipe(icmp_reg_reg);
13972 %}
13973 
13974 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13975 %{
13976   match(Set cr (OverflowAddI op1 op2));
13977 
13978   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13979   ins_cost(INSN_COST);
13980   ins_encode %{
13981     __ cmnw($op1$$Register, $op2$$constant);
13982   %}
13983 
13984   ins_pipe(icmp_reg_imm);
13985 %}
13986 
13987 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13988 %{
13989   match(Set cr (OverflowAddL op1 op2));
13990 
13991   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13992   ins_cost(INSN_COST);
13993   ins_encode %{
13994     __ cmn($op1$$Register, $op2$$Register);
13995   %}
13996 
13997   ins_pipe(icmp_reg_reg);
13998 %}
13999 
14000 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14001 %{
14002   match(Set cr (OverflowAddL op1 op2));
14003 
14004   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14005   ins_cost(INSN_COST);
14006   ins_encode %{
14007     __ cmn($op1$$Register, $op2$$constant);
14008   %}
14009 
14010   ins_pipe(icmp_reg_imm);
14011 %}
14012 
14013 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14014 %{
14015   match(Set cr (OverflowSubI op1 op2));
14016 
14017   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14018   ins_cost(INSN_COST);
14019   ins_encode %{
14020     __ cmpw($op1$$Register, $op2$$Register);
14021   %}
14022 
14023   ins_pipe(icmp_reg_reg);
14024 %}
14025 
14026 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14027 %{
14028   match(Set cr (OverflowSubI op1 op2));
14029 
14030   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14031   ins_cost(INSN_COST);
14032   ins_encode %{
14033     __ cmpw($op1$$Register, $op2$$constant);
14034   %}
14035 
14036   ins_pipe(icmp_reg_imm);
14037 %}
14038 
14039 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14040 %{
14041   match(Set cr (OverflowSubL op1 op2));
14042 
14043   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14044   ins_cost(INSN_COST);
14045   ins_encode %{
14046     __ cmp($op1$$Register, $op2$$Register);
14047   %}
14048 
14049   ins_pipe(icmp_reg_reg);
14050 %}
14051 
14052 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14053 %{
14054   match(Set cr (OverflowSubL op1 op2));
14055 
14056   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14057   ins_cost(INSN_COST);
14058   ins_encode %{
14059     __ subs(zr, $op1$$Register, $op2$$constant);
14060   %}
14061 
14062   ins_pipe(icmp_reg_imm);
14063 %}
14064 
14065 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14066 %{
14067   match(Set cr (OverflowSubI zero op1));
14068 
14069   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14070   ins_cost(INSN_COST);
14071   ins_encode %{
14072     __ cmpw(zr, $op1$$Register);
14073   %}
14074 
14075   ins_pipe(icmp_reg_imm);
14076 %}
14077 
14078 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14079 %{
14080   match(Set cr (OverflowSubL zero op1));
14081 
14082   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14083   ins_cost(INSN_COST);
14084   ins_encode %{
14085     __ cmp(zr, $op1$$Register);
14086   %}
14087 
14088   ins_pipe(icmp_reg_imm);
14089 %}
14090 
14091 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14092 %{
14093   match(Set cr (OverflowMulI op1 op2));
14094 
14095   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14096             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14097             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14098             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14099             &quot;cmpw  rscratch1, #1&quot; %}
14100   ins_cost(5 * INSN_COST);
14101   ins_encode %{
14102     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14103     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14104     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14105     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14106     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14107   %}
14108 
14109   ins_pipe(pipe_slow);
14110 %}
14111 
14112 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14113 %{
14114   match(If cmp (OverflowMulI op1 op2));
14115   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14116             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14117   effect(USE labl, KILL cr);
14118 
14119   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14120             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14121             &quot;b$cmp   $labl&quot; %}
14122   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14123   ins_encode %{
14124     Label* L = $labl$$label;
14125     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14126     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14127     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14128     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14129   %}
14130 
14131   ins_pipe(pipe_serial);
14132 %}
14133 
14134 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14135 %{
14136   match(Set cr (OverflowMulL op1 op2));
14137 
14138   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14139             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14140             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14141             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14142             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14143             &quot;cmpw  rscratch1, #1&quot; %}
14144   ins_cost(6 * INSN_COST);
14145   ins_encode %{
14146     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14147     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14148     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14149     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14150     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14151     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14152   %}
14153 
14154   ins_pipe(pipe_slow);
14155 %}
14156 
14157 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14158 %{
14159   match(If cmp (OverflowMulL op1 op2));
14160   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14161             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14162   effect(USE labl, KILL cr);
14163 
14164   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14165             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14166             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14167             &quot;b$cmp $labl&quot; %}
14168   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14169   ins_encode %{
14170     Label* L = $labl$$label;
14171     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14172     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14173     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14174     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14175     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14176   %}
14177 
14178   ins_pipe(pipe_serial);
14179 %}
14180 
14181 // ============================================================================
14182 // Compare Instructions
14183 
14184 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14185 %{
14186   match(Set cr (CmpI op1 op2));
14187 
14188   effect(DEF cr, USE op1, USE op2);
14189 
14190   ins_cost(INSN_COST);
14191   format %{ &quot;cmpw  $op1, $op2&quot; %}
14192 
14193   ins_encode(aarch64_enc_cmpw(op1, op2));
14194 
14195   ins_pipe(icmp_reg_reg);
14196 %}
14197 
14198 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14199 %{
14200   match(Set cr (CmpI op1 zero));
14201 
14202   effect(DEF cr, USE op1);
14203 
14204   ins_cost(INSN_COST);
14205   format %{ &quot;cmpw $op1, 0&quot; %}
14206 
14207   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14208 
14209   ins_pipe(icmp_reg_imm);
14210 %}
14211 
14212 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14213 %{
14214   match(Set cr (CmpI op1 op2));
14215 
14216   effect(DEF cr, USE op1);
14217 
14218   ins_cost(INSN_COST);
14219   format %{ &quot;cmpw  $op1, $op2&quot; %}
14220 
14221   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14222 
14223   ins_pipe(icmp_reg_imm);
14224 %}
14225 
14226 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14227 %{
14228   match(Set cr (CmpI op1 op2));
14229 
14230   effect(DEF cr, USE op1);
14231 
14232   ins_cost(INSN_COST * 2);
14233   format %{ &quot;cmpw  $op1, $op2&quot; %}
14234 
14235   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14236 
14237   ins_pipe(icmp_reg_imm);
14238 %}
14239 
14240 // Unsigned compare Instructions; really, same as signed compare
14241 // except it should only be used to feed an If or a CMovI which takes a
14242 // cmpOpU.
14243 
14244 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14245 %{
14246   match(Set cr (CmpU op1 op2));
14247 
14248   effect(DEF cr, USE op1, USE op2);
14249 
14250   ins_cost(INSN_COST);
14251   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14252 
14253   ins_encode(aarch64_enc_cmpw(op1, op2));
14254 
14255   ins_pipe(icmp_reg_reg);
14256 %}
14257 
14258 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14259 %{
14260   match(Set cr (CmpU op1 zero));
14261 
14262   effect(DEF cr, USE op1);
14263 
14264   ins_cost(INSN_COST);
14265   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14266 
14267   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14268 
14269   ins_pipe(icmp_reg_imm);
14270 %}
14271 
14272 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14273 %{
14274   match(Set cr (CmpU op1 op2));
14275 
14276   effect(DEF cr, USE op1);
14277 
14278   ins_cost(INSN_COST);
14279   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14280 
14281   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14282 
14283   ins_pipe(icmp_reg_imm);
14284 %}
14285 
14286 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14287 %{
14288   match(Set cr (CmpU op1 op2));
14289 
14290   effect(DEF cr, USE op1);
14291 
14292   ins_cost(INSN_COST * 2);
14293   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14294 
14295   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14296 
14297   ins_pipe(icmp_reg_imm);
14298 %}
14299 
14300 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14301 %{
14302   match(Set cr (CmpL op1 op2));
14303 
14304   effect(DEF cr, USE op1, USE op2);
14305 
14306   ins_cost(INSN_COST);
14307   format %{ &quot;cmp  $op1, $op2&quot; %}
14308 
14309   ins_encode(aarch64_enc_cmp(op1, op2));
14310 
14311   ins_pipe(icmp_reg_reg);
14312 %}
14313 
14314 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14315 %{
14316   match(Set cr (CmpL op1 zero));
14317 
14318   effect(DEF cr, USE op1);
14319 
14320   ins_cost(INSN_COST);
14321   format %{ &quot;tst  $op1&quot; %}
14322 
14323   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14324 
14325   ins_pipe(icmp_reg_imm);
14326 %}
14327 
14328 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14329 %{
14330   match(Set cr (CmpL op1 op2));
14331 
14332   effect(DEF cr, USE op1);
14333 
14334   ins_cost(INSN_COST);
14335   format %{ &quot;cmp  $op1, $op2&quot; %}
14336 
14337   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14338 
14339   ins_pipe(icmp_reg_imm);
14340 %}
14341 
14342 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14343 %{
14344   match(Set cr (CmpL op1 op2));
14345 
14346   effect(DEF cr, USE op1);
14347 
14348   ins_cost(INSN_COST * 2);
14349   format %{ &quot;cmp  $op1, $op2&quot; %}
14350 
14351   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14352 
14353   ins_pipe(icmp_reg_imm);
14354 %}
14355 
14356 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14357 %{
14358   match(Set cr (CmpUL op1 op2));
14359 
14360   effect(DEF cr, USE op1, USE op2);
14361 
14362   ins_cost(INSN_COST);
14363   format %{ &quot;cmp  $op1, $op2&quot; %}
14364 
14365   ins_encode(aarch64_enc_cmp(op1, op2));
14366 
14367   ins_pipe(icmp_reg_reg);
14368 %}
14369 
14370 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14371 %{
14372   match(Set cr (CmpUL op1 zero));
14373 
14374   effect(DEF cr, USE op1);
14375 
14376   ins_cost(INSN_COST);
14377   format %{ &quot;tst  $op1&quot; %}
14378 
14379   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14380 
14381   ins_pipe(icmp_reg_imm);
14382 %}
14383 
14384 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14385 %{
14386   match(Set cr (CmpUL op1 op2));
14387 
14388   effect(DEF cr, USE op1);
14389 
14390   ins_cost(INSN_COST);
14391   format %{ &quot;cmp  $op1, $op2&quot; %}
14392 
14393   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14394 
14395   ins_pipe(icmp_reg_imm);
14396 %}
14397 
14398 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14399 %{
14400   match(Set cr (CmpUL op1 op2));
14401 
14402   effect(DEF cr, USE op1);
14403 
14404   ins_cost(INSN_COST * 2);
14405   format %{ &quot;cmp  $op1, $op2&quot; %}
14406 
14407   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14408 
14409   ins_pipe(icmp_reg_imm);
14410 %}
14411 
14412 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14413 %{
14414   match(Set cr (CmpP op1 op2));
14415 
14416   effect(DEF cr, USE op1, USE op2);
14417 
14418   ins_cost(INSN_COST);
14419   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14420 
14421   ins_encode(aarch64_enc_cmpp(op1, op2));
14422 
14423   ins_pipe(icmp_reg_reg);
14424 %}
14425 
14426 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14427 %{
14428   match(Set cr (CmpN op1 op2));
14429 
14430   effect(DEF cr, USE op1, USE op2);
14431 
14432   ins_cost(INSN_COST);
14433   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14434 
14435   ins_encode(aarch64_enc_cmpn(op1, op2));
14436 
14437   ins_pipe(icmp_reg_reg);
14438 %}
14439 
14440 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14441 %{
14442   match(Set cr (CmpP op1 zero));
14443 
14444   effect(DEF cr, USE op1, USE zero);
14445 
14446   ins_cost(INSN_COST);
14447   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14448 
14449   ins_encode(aarch64_enc_testp(op1));
14450 
14451   ins_pipe(icmp_reg_imm);
14452 %}
14453 
14454 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14455 %{
14456   match(Set cr (CmpN op1 zero));
14457 
14458   effect(DEF cr, USE op1, USE zero);
14459 
14460   ins_cost(INSN_COST);
14461   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14462 
14463   ins_encode(aarch64_enc_testn(op1));
14464 
14465   ins_pipe(icmp_reg_imm);
14466 %}
14467 
14468 // FP comparisons
14469 //
14470 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14471 // using normal cmpOp. See declaration of rFlagsReg for details.
14472 
14473 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14474 %{
14475   match(Set cr (CmpF src1 src2));
14476 
14477   ins_cost(3 * INSN_COST);
14478   format %{ &quot;fcmps $src1, $src2&quot; %}
14479 
14480   ins_encode %{
14481     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14482   %}
14483 
14484   ins_pipe(pipe_class_compare);
14485 %}
14486 
14487 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14488 %{
14489   match(Set cr (CmpF src1 src2));
14490 
14491   ins_cost(3 * INSN_COST);
14492   format %{ &quot;fcmps $src1, 0.0&quot; %}
14493 
14494   ins_encode %{
14495     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14496   %}
14497 
14498   ins_pipe(pipe_class_compare);
14499 %}
14500 // FROM HERE
14501 
14502 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14503 %{
14504   match(Set cr (CmpD src1 src2));
14505 
14506   ins_cost(3 * INSN_COST);
14507   format %{ &quot;fcmpd $src1, $src2&quot; %}
14508 
14509   ins_encode %{
14510     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14511   %}
14512 
14513   ins_pipe(pipe_class_compare);
14514 %}
14515 
14516 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14517 %{
14518   match(Set cr (CmpD src1 src2));
14519 
14520   ins_cost(3 * INSN_COST);
14521   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14522 
14523   ins_encode %{
14524     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14525   %}
14526 
14527   ins_pipe(pipe_class_compare);
14528 %}
14529 
14530 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14531 %{
14532   match(Set dst (CmpF3 src1 src2));
14533   effect(KILL cr);
14534 
14535   ins_cost(5 * INSN_COST);
14536   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14537             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14538             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14539   %}
14540 
14541   ins_encode %{
14542     Label done;
14543     FloatRegister s1 = as_FloatRegister($src1$$reg);
14544     FloatRegister s2 = as_FloatRegister($src2$$reg);
14545     Register d = as_Register($dst$$reg);
14546     __ fcmps(s1, s2);
14547     // installs 0 if EQ else -1
14548     __ csinvw(d, zr, zr, Assembler::EQ);
14549     // keeps -1 if less or unordered else installs 1
14550     __ csnegw(d, d, d, Assembler::LT);
14551     __ bind(done);
14552   %}
14553 
14554   ins_pipe(pipe_class_default);
14555 
14556 %}
14557 
14558 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14559 %{
14560   match(Set dst (CmpD3 src1 src2));
14561   effect(KILL cr);
14562 
14563   ins_cost(5 * INSN_COST);
14564   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14565             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14566             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14567   %}
14568 
14569   ins_encode %{
14570     Label done;
14571     FloatRegister s1 = as_FloatRegister($src1$$reg);
14572     FloatRegister s2 = as_FloatRegister($src2$$reg);
14573     Register d = as_Register($dst$$reg);
14574     __ fcmpd(s1, s2);
14575     // installs 0 if EQ else -1
14576     __ csinvw(d, zr, zr, Assembler::EQ);
14577     // keeps -1 if less or unordered else installs 1
14578     __ csnegw(d, d, d, Assembler::LT);
14579     __ bind(done);
14580   %}
14581   ins_pipe(pipe_class_default);
14582 
14583 %}
14584 
14585 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14586 %{
14587   match(Set dst (CmpF3 src1 zero));
14588   effect(KILL cr);
14589 
14590   ins_cost(5 * INSN_COST);
14591   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14592             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14593             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14594   %}
14595 
14596   ins_encode %{
14597     Label done;
14598     FloatRegister s1 = as_FloatRegister($src1$$reg);
14599     Register d = as_Register($dst$$reg);
14600     __ fcmps(s1, 0.0);
14601     // installs 0 if EQ else -1
14602     __ csinvw(d, zr, zr, Assembler::EQ);
14603     // keeps -1 if less or unordered else installs 1
14604     __ csnegw(d, d, d, Assembler::LT);
14605     __ bind(done);
14606   %}
14607 
14608   ins_pipe(pipe_class_default);
14609 
14610 %}
14611 
14612 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14613 %{
14614   match(Set dst (CmpD3 src1 zero));
14615   effect(KILL cr);
14616 
14617   ins_cost(5 * INSN_COST);
14618   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14619             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14620             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14621   %}
14622 
14623   ins_encode %{
14624     Label done;
14625     FloatRegister s1 = as_FloatRegister($src1$$reg);
14626     Register d = as_Register($dst$$reg);
14627     __ fcmpd(s1, 0.0);
14628     // installs 0 if EQ else -1
14629     __ csinvw(d, zr, zr, Assembler::EQ);
14630     // keeps -1 if less or unordered else installs 1
14631     __ csnegw(d, d, d, Assembler::LT);
14632     __ bind(done);
14633   %}
14634   ins_pipe(pipe_class_default);
14635 
14636 %}
14637 
14638 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14639 %{
14640   match(Set dst (CmpLTMask p q));
14641   effect(KILL cr);
14642 
14643   ins_cost(3 * INSN_COST);
14644 
14645   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14646             &quot;csetw $dst, lt\n\t&quot;
14647             &quot;subw $dst, zr, $dst&quot;
14648   %}
14649 
14650   ins_encode %{
14651     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14652     __ csetw(as_Register($dst$$reg), Assembler::LT);
14653     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14654   %}
14655 
14656   ins_pipe(ialu_reg_reg);
14657 %}
14658 
14659 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14660 %{
14661   match(Set dst (CmpLTMask src zero));
14662   effect(KILL cr);
14663 
14664   ins_cost(INSN_COST);
14665 
14666   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14667 
14668   ins_encode %{
14669     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14670   %}
14671 
14672   ins_pipe(ialu_reg_shift);
14673 %}
14674 
14675 // ============================================================================
14676 // Max and Min
14677 
14678 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14679 %{
14680   effect( DEF dst, USE src1, USE src2, USE cr );
14681 
14682   ins_cost(INSN_COST * 2);
14683   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14684 
14685   ins_encode %{
14686     __ cselw(as_Register($dst$$reg),
14687              as_Register($src1$$reg),
14688              as_Register($src2$$reg),
14689              Assembler::LT);
14690   %}
14691 
14692   ins_pipe(icond_reg_reg);
14693 %}
14694 
14695 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14696 %{
14697   match(Set dst (MinI src1 src2));
14698   ins_cost(INSN_COST * 3);
14699 
14700   expand %{
14701     rFlagsReg cr;
14702     compI_reg_reg(cr, src1, src2);
14703     cmovI_reg_reg_lt(dst, src1, src2, cr);
14704   %}
14705 
14706 %}
14707 // FROM HERE
14708 
14709 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14710 %{
14711   effect( DEF dst, USE src1, USE src2, USE cr );
14712 
14713   ins_cost(INSN_COST * 2);
14714   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14715 
14716   ins_encode %{
14717     __ cselw(as_Register($dst$$reg),
14718              as_Register($src1$$reg),
14719              as_Register($src2$$reg),
14720              Assembler::GT);
14721   %}
14722 
14723   ins_pipe(icond_reg_reg);
14724 %}
14725 
14726 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14727 %{
14728   match(Set dst (MaxI src1 src2));
14729   ins_cost(INSN_COST * 3);
14730   expand %{
14731     rFlagsReg cr;
14732     compI_reg_reg(cr, src1, src2);
14733     cmovI_reg_reg_gt(dst, src1, src2, cr);
14734   %}
14735 %}
14736 
14737 // ============================================================================
14738 // Branch Instructions
14739 
14740 // Direct Branch.
14741 instruct branch(label lbl)
14742 %{
14743   match(Goto);
14744 
14745   effect(USE lbl);
14746 
14747   ins_cost(BRANCH_COST);
14748   format %{ &quot;b  $lbl&quot; %}
14749 
14750   ins_encode(aarch64_enc_b(lbl));
14751 
14752   ins_pipe(pipe_branch);
14753 %}
14754 
14755 // Conditional Near Branch
14756 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14757 %{
14758   // Same match rule as `branchConFar&#39;.
14759   match(If cmp cr);
14760 
14761   effect(USE lbl);
14762 
14763   ins_cost(BRANCH_COST);
14764   // If set to 1 this indicates that the current instruction is a
14765   // short variant of a long branch. This avoids using this
14766   // instruction in first-pass matching. It will then only be used in
14767   // the `Shorten_branches&#39; pass.
14768   // ins_short_branch(1);
14769   format %{ &quot;b$cmp  $lbl&quot; %}
14770 
14771   ins_encode(aarch64_enc_br_con(cmp, lbl));
14772 
14773   ins_pipe(pipe_branch_cond);
14774 %}
14775 
14776 // Conditional Near Branch Unsigned
14777 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14778 %{
14779   // Same match rule as `branchConFar&#39;.
14780   match(If cmp cr);
14781 
14782   effect(USE lbl);
14783 
14784   ins_cost(BRANCH_COST);
14785   // If set to 1 this indicates that the current instruction is a
14786   // short variant of a long branch. This avoids using this
14787   // instruction in first-pass matching. It will then only be used in
14788   // the `Shorten_branches&#39; pass.
14789   // ins_short_branch(1);
14790   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14791 
14792   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14793 
14794   ins_pipe(pipe_branch_cond);
14795 %}
14796 
14797 // Make use of CBZ and CBNZ.  These instructions, as well as being
14798 // shorter than (cmp; branch), have the additional benefit of not
14799 // killing the flags.
14800 
14801 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14802   match(If cmp (CmpI op1 op2));
14803   effect(USE labl);
14804 
14805   ins_cost(BRANCH_COST);
14806   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14807   ins_encode %{
14808     Label* L = $labl$$label;
14809     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14810     if (cond == Assembler::EQ)
14811       __ cbzw($op1$$Register, *L);
14812     else
14813       __ cbnzw($op1$$Register, *L);
14814   %}
14815   ins_pipe(pipe_cmp_branch);
14816 %}
14817 
14818 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14819   match(If cmp (CmpL op1 op2));
14820   effect(USE labl);
14821 
14822   ins_cost(BRANCH_COST);
14823   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14824   ins_encode %{
14825     Label* L = $labl$$label;
14826     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14827     if (cond == Assembler::EQ)
14828       __ cbz($op1$$Register, *L);
14829     else
14830       __ cbnz($op1$$Register, *L);
14831   %}
14832   ins_pipe(pipe_cmp_branch);
14833 %}
14834 
14835 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14836   match(If cmp (CmpP op1 op2));
14837   effect(USE labl);
14838 
14839   ins_cost(BRANCH_COST);
14840   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14841   ins_encode %{
14842     Label* L = $labl$$label;
14843     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14844     if (cond == Assembler::EQ)
14845       __ cbz($op1$$Register, *L);
14846     else
14847       __ cbnz($op1$$Register, *L);
14848   %}
14849   ins_pipe(pipe_cmp_branch);
14850 %}
14851 
14852 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14853   match(If cmp (CmpN op1 op2));
14854   effect(USE labl);
14855 
14856   ins_cost(BRANCH_COST);
14857   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14858   ins_encode %{
14859     Label* L = $labl$$label;
14860     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14861     if (cond == Assembler::EQ)
14862       __ cbzw($op1$$Register, *L);
14863     else
14864       __ cbnzw($op1$$Register, *L);
14865   %}
14866   ins_pipe(pipe_cmp_branch);
14867 %}
14868 
14869 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14870   match(If cmp (CmpP (DecodeN oop) zero));
14871   effect(USE labl);
14872 
14873   ins_cost(BRANCH_COST);
14874   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14875   ins_encode %{
14876     Label* L = $labl$$label;
14877     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14878     if (cond == Assembler::EQ)
14879       __ cbzw($oop$$Register, *L);
14880     else
14881       __ cbnzw($oop$$Register, *L);
14882   %}
14883   ins_pipe(pipe_cmp_branch);
14884 %}
14885 
14886 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14887   match(If cmp (CmpU op1 op2));
14888   effect(USE labl);
14889 
14890   ins_cost(BRANCH_COST);
14891   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14892   ins_encode %{
14893     Label* L = $labl$$label;
14894     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14895     if (cond == Assembler::EQ || cond == Assembler::LS)
14896       __ cbzw($op1$$Register, *L);
14897     else
14898       __ cbnzw($op1$$Register, *L);
14899   %}
14900   ins_pipe(pipe_cmp_branch);
14901 %}
14902 
14903 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14904   match(If cmp (CmpUL op1 op2));
14905   effect(USE labl);
14906 
14907   ins_cost(BRANCH_COST);
14908   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14909   ins_encode %{
14910     Label* L = $labl$$label;
14911     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14912     if (cond == Assembler::EQ || cond == Assembler::LS)
14913       __ cbz($op1$$Register, *L);
14914     else
14915       __ cbnz($op1$$Register, *L);
14916   %}
14917   ins_pipe(pipe_cmp_branch);
14918 %}
14919 
14920 // Test bit and Branch
14921 
14922 // Patterns for short (&lt; 32KiB) variants
14923 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14924   match(If cmp (CmpL op1 op2));
14925   effect(USE labl);
14926 
14927   ins_cost(BRANCH_COST);
14928   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14929   ins_encode %{
14930     Label* L = $labl$$label;
14931     Assembler::Condition cond =
14932       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14933     __ tbr(cond, $op1$$Register, 63, *L);
14934   %}
14935   ins_pipe(pipe_cmp_branch);
14936   ins_short_branch(1);
14937 %}
14938 
14939 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14940   match(If cmp (CmpI op1 op2));
14941   effect(USE labl);
14942 
14943   ins_cost(BRANCH_COST);
14944   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14945   ins_encode %{
14946     Label* L = $labl$$label;
14947     Assembler::Condition cond =
14948       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14949     __ tbr(cond, $op1$$Register, 31, *L);
14950   %}
14951   ins_pipe(pipe_cmp_branch);
14952   ins_short_branch(1);
14953 %}
14954 
14955 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14956   match(If cmp (CmpL (AndL op1 op2) op3));
14957   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14958   effect(USE labl);
14959 
14960   ins_cost(BRANCH_COST);
14961   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14962   ins_encode %{
14963     Label* L = $labl$$label;
14964     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14965     int bit = exact_log2_long($op2$$constant);
14966     __ tbr(cond, $op1$$Register, bit, *L);
14967   %}
14968   ins_pipe(pipe_cmp_branch);
14969   ins_short_branch(1);
14970 %}
14971 
14972 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14973   match(If cmp (CmpI (AndI op1 op2) op3));
14974   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14975   effect(USE labl);
14976 
14977   ins_cost(BRANCH_COST);
14978   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14979   ins_encode %{
14980     Label* L = $labl$$label;
14981     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14982     int bit = exact_log2((juint)$op2$$constant);
14983     __ tbr(cond, $op1$$Register, bit, *L);
14984   %}
14985   ins_pipe(pipe_cmp_branch);
14986   ins_short_branch(1);
14987 %}
14988 
14989 // And far variants
14990 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14991   match(If cmp (CmpL op1 op2));
14992   effect(USE labl);
14993 
14994   ins_cost(BRANCH_COST);
14995   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14996   ins_encode %{
14997     Label* L = $labl$$label;
14998     Assembler::Condition cond =
14999       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15000     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15001   %}
15002   ins_pipe(pipe_cmp_branch);
15003 %}
15004 
15005 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15006   match(If cmp (CmpI op1 op2));
15007   effect(USE labl);
15008 
15009   ins_cost(BRANCH_COST);
15010   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15011   ins_encode %{
15012     Label* L = $labl$$label;
15013     Assembler::Condition cond =
15014       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15015     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15016   %}
15017   ins_pipe(pipe_cmp_branch);
15018 %}
15019 
15020 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15021   match(If cmp (CmpL (AndL op1 op2) op3));
15022   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15023   effect(USE labl);
15024 
15025   ins_cost(BRANCH_COST);
15026   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15027   ins_encode %{
15028     Label* L = $labl$$label;
15029     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15030     int bit = exact_log2_long($op2$$constant);
15031     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15032   %}
15033   ins_pipe(pipe_cmp_branch);
15034 %}
15035 
15036 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15037   match(If cmp (CmpI (AndI op1 op2) op3));
15038   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15039   effect(USE labl);
15040 
15041   ins_cost(BRANCH_COST);
15042   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15043   ins_encode %{
15044     Label* L = $labl$$label;
15045     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15046     int bit = exact_log2((juint)$op2$$constant);
15047     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15048   %}
15049   ins_pipe(pipe_cmp_branch);
15050 %}
15051 
15052 // Test bits
15053 
15054 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15055   match(Set cr (CmpL (AndL op1 op2) op3));
15056   predicate(Assembler::operand_valid_for_logical_immediate
15057             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15058 
15059   ins_cost(INSN_COST);
15060   format %{ &quot;tst $op1, $op2 # long&quot; %}
15061   ins_encode %{
15062     __ tst($op1$$Register, $op2$$constant);
15063   %}
15064   ins_pipe(ialu_reg_reg);
15065 %}
15066 
15067 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15068   match(Set cr (CmpI (AndI op1 op2) op3));
15069   predicate(Assembler::operand_valid_for_logical_immediate
15070             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15071 
15072   ins_cost(INSN_COST);
15073   format %{ &quot;tst $op1, $op2 # int&quot; %}
15074   ins_encode %{
15075     __ tstw($op1$$Register, $op2$$constant);
15076   %}
15077   ins_pipe(ialu_reg_reg);
15078 %}
15079 
15080 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15081   match(Set cr (CmpL (AndL op1 op2) op3));
15082 
15083   ins_cost(INSN_COST);
15084   format %{ &quot;tst $op1, $op2 # long&quot; %}
15085   ins_encode %{
15086     __ tst($op1$$Register, $op2$$Register);
15087   %}
15088   ins_pipe(ialu_reg_reg);
15089 %}
15090 
15091 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15092   match(Set cr (CmpI (AndI op1 op2) op3));
15093 
15094   ins_cost(INSN_COST);
15095   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15096   ins_encode %{
15097     __ tstw($op1$$Register, $op2$$Register);
15098   %}
15099   ins_pipe(ialu_reg_reg);
15100 %}
15101 
15102 
15103 // Conditional Far Branch
15104 // Conditional Far Branch Unsigned
15105 // TODO: fixme
15106 
15107 // counted loop end branch near
15108 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15109 %{
15110   match(CountedLoopEnd cmp cr);
15111 
15112   effect(USE lbl);
15113 
15114   ins_cost(BRANCH_COST);
15115   // short variant.
15116   // ins_short_branch(1);
15117   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15118 
15119   ins_encode(aarch64_enc_br_con(cmp, lbl));
15120 
15121   ins_pipe(pipe_branch);
15122 %}
15123 
15124 // counted loop end branch near Unsigned
15125 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15126 %{
15127   match(CountedLoopEnd cmp cr);
15128 
15129   effect(USE lbl);
15130 
15131   ins_cost(BRANCH_COST);
15132   // short variant.
15133   // ins_short_branch(1);
15134   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15135 
15136   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15137 
15138   ins_pipe(pipe_branch);
15139 %}
15140 
15141 // counted loop end branch far
15142 // counted loop end branch far unsigned
15143 // TODO: fixme
15144 
15145 // ============================================================================
15146 // inlined locking and unlocking
15147 
15148 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15149 %{
15150   match(Set cr (FastLock object box));
15151   effect(TEMP tmp, TEMP tmp2);
15152 
15153   // TODO
15154   // identify correct cost
15155   ins_cost(5 * INSN_COST);
15156   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15157 
15158   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15159 
15160   ins_pipe(pipe_serial);
15161 %}
15162 
15163 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15164 %{
15165   match(Set cr (FastUnlock object box));
15166   effect(TEMP tmp, TEMP tmp2);
15167 
15168   ins_cost(5 * INSN_COST);
15169   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15170 
15171   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15172 
15173   ins_pipe(pipe_serial);
15174 %}
15175 
15176 
15177 // ============================================================================
15178 // Safepoint Instructions
15179 
15180 // TODO
15181 // provide a near and far version of this code
15182 
15183 instruct safePoint(rFlagsReg cr, iRegP poll)
15184 %{
15185   match(SafePoint poll);
15186   effect(KILL cr);
15187 
15188   format %{
15189     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15190   %}
15191   ins_encode %{
15192     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15193   %}
15194   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15195 %}
15196 
15197 
15198 // ============================================================================
15199 // Procedure Call/Return Instructions
15200 
15201 // Call Java Static Instruction
15202 
15203 instruct CallStaticJavaDirect(method meth)
15204 %{
15205   match(CallStaticJava);
15206 
15207   effect(USE meth);
15208 
15209   ins_cost(CALL_COST);
15210 
15211   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15212 
15213   ins_encode( aarch64_enc_java_static_call(meth),
15214               aarch64_enc_call_epilog );
15215 
15216   ins_pipe(pipe_class_call);
15217 %}
15218 
15219 // TO HERE
15220 
15221 // Call Java Dynamic Instruction
15222 instruct CallDynamicJavaDirect(method meth)
15223 %{
15224   match(CallDynamicJava);
15225 
15226   effect(USE meth);
15227 
15228   ins_cost(CALL_COST);
15229 
15230   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15231 
15232   ins_encode( aarch64_enc_java_dynamic_call(meth),
15233                aarch64_enc_call_epilog );
15234 
15235   ins_pipe(pipe_class_call);
15236 %}
15237 
15238 // Call Runtime Instruction
15239 
15240 instruct CallRuntimeDirect(method meth)
15241 %{
15242   match(CallRuntime);
15243 
15244   effect(USE meth);
15245 
15246   ins_cost(CALL_COST);
15247 
15248   format %{ &quot;CALL, runtime $meth&quot; %}
15249 
15250   ins_encode( aarch64_enc_java_to_runtime(meth) );
15251 
15252   ins_pipe(pipe_class_call);
15253 %}
15254 
15255 // Call Runtime Instruction
15256 
15257 instruct CallLeafDirect(method meth)
15258 %{
15259   match(CallLeaf);
15260 
15261   effect(USE meth);
15262 
15263   ins_cost(CALL_COST);
15264 
15265   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15266 
15267   ins_encode( aarch64_enc_java_to_runtime(meth) );
15268 
15269   ins_pipe(pipe_class_call);
15270 %}
15271 
15272 // Call Runtime Instruction
15273 
15274 instruct CallLeafNoFPDirect(method meth)
15275 %{
15276   match(CallLeafNoFP);
15277 
15278   effect(USE meth);
15279 
15280   ins_cost(CALL_COST);
15281 
15282   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15283 
15284   ins_encode( aarch64_enc_java_to_runtime(meth) );
15285 
15286   ins_pipe(pipe_class_call);
15287 %}
15288 
15289 // Tail Call; Jump from runtime stub to Java code.
15290 // Also known as an &#39;interprocedural jump&#39;.
15291 // Target of jump will eventually return to caller.
15292 // TailJump below removes the return address.
15293 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15294 %{
15295   match(TailCall jump_target method_oop);
15296 
15297   ins_cost(CALL_COST);
15298 
15299   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15300 
15301   ins_encode(aarch64_enc_tail_call(jump_target));
15302 
15303   ins_pipe(pipe_class_call);
15304 %}
15305 
15306 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15307 %{
15308   match(TailJump jump_target ex_oop);
15309 
15310   ins_cost(CALL_COST);
15311 
15312   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15313 
15314   ins_encode(aarch64_enc_tail_jmp(jump_target));
15315 
15316   ins_pipe(pipe_class_call);
15317 %}
15318 
15319 // Create exception oop: created by stack-crawling runtime code.
15320 // Created exception is now available to this handler, and is setup
15321 // just prior to jumping to this handler. No code emitted.
15322 // TODO check
15323 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15324 instruct CreateException(iRegP_R0 ex_oop)
15325 %{
15326   match(Set ex_oop (CreateEx));
15327 
15328   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15329 
15330   size(0);
15331 
15332   ins_encode( /*empty*/ );
15333 
15334   ins_pipe(pipe_class_empty);
15335 %}
15336 
15337 // Rethrow exception: The exception oop will come in the first
15338 // argument position. Then JUMP (not call) to the rethrow stub code.
15339 instruct RethrowException() %{
15340   match(Rethrow);
15341   ins_cost(CALL_COST);
15342 
15343   format %{ &quot;b rethrow_stub&quot; %}
15344 
15345   ins_encode( aarch64_enc_rethrow() );
15346 
15347   ins_pipe(pipe_class_call);
15348 %}
15349 
15350 
15351 // Return Instruction
15352 // epilog node loads ret address into lr as part of frame pop
15353 instruct Ret()
15354 %{
15355   match(Return);
15356 
15357   format %{ &quot;ret\t// return register&quot; %}
15358 
15359   ins_encode( aarch64_enc_ret() );
15360 
15361   ins_pipe(pipe_branch);
15362 %}
15363 
15364 // Die now.
15365 instruct ShouldNotReachHere() %{
15366   match(Halt);
15367 
15368   ins_cost(CALL_COST);
15369   format %{ &quot;ShouldNotReachHere&quot; %}
15370 
15371   ins_encode %{
15372     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15373     // return true
15374     __ dpcs1(0xdead + 1);
15375   %}
15376 
15377   ins_pipe(pipe_class_default);
15378 %}
15379 
15380 // ============================================================================
15381 // Partial Subtype Check
15382 //
15383 // superklass array for an instance of the superklass.  Set a hidden
15384 // internal cache on a hit (cache is checked with exposed code in
15385 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15386 // encoding ALSO sets flags.
15387 
15388 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15389 %{
15390   match(Set result (PartialSubtypeCheck sub super));
15391   effect(KILL cr, KILL temp);
15392 
15393   ins_cost(1100);  // slightly larger than the next version
15394   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15395 
15396   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15397 
15398   opcode(0x1); // Force zero of result reg on hit
15399 
15400   ins_pipe(pipe_class_memory);
15401 %}
15402 
15403 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15404 %{
15405   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15406   effect(KILL temp, KILL result);
15407 
15408   ins_cost(1100);  // slightly larger than the next version
15409   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15410 
15411   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15412 
15413   opcode(0x0); // Don&#39;t zero result reg on hit
15414 
15415   ins_pipe(pipe_class_memory);
15416 %}
15417 
15418 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15419                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15420 %{
15421   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15422   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15423   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15424 
15425   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15426   ins_encode %{
15427     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15428     __ string_compare($str1$$Register, $str2$$Register,
15429                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15430                       $tmp1$$Register, $tmp2$$Register,
15431                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15432   %}
15433   ins_pipe(pipe_class_memory);
15434 %}
15435 
15436 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15437                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15438 %{
15439   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15440   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15441   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15442 
15443   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15444   ins_encode %{
15445     __ string_compare($str1$$Register, $str2$$Register,
15446                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15447                       $tmp1$$Register, $tmp2$$Register,
15448                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15449   %}
15450   ins_pipe(pipe_class_memory);
15451 %}
15452 
15453 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15454                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15455                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15456 %{
15457   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15458   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15459   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15460          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15461 
15462   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15463   ins_encode %{
15464     __ string_compare($str1$$Register, $str2$$Register,
15465                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15466                       $tmp1$$Register, $tmp2$$Register,
15467                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15468                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15469   %}
15470   ins_pipe(pipe_class_memory);
15471 %}
15472 
15473 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15474                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15475                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15476 %{
15477   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15478   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15479   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15480          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15481 
15482   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15483   ins_encode %{
15484     __ string_compare($str1$$Register, $str2$$Register,
15485                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15486                       $tmp1$$Register, $tmp2$$Register,
15487                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15488                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15489   %}
15490   ins_pipe(pipe_class_memory);
15491 %}
15492 
15493 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15494        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15495        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15496 %{
15497   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15498   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15499   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15500          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15501   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15502 
15503   ins_encode %{
15504     __ string_indexof($str1$$Register, $str2$$Register,
15505                       $cnt1$$Register, $cnt2$$Register,
15506                       $tmp1$$Register, $tmp2$$Register,
15507                       $tmp3$$Register, $tmp4$$Register,
15508                       $tmp5$$Register, $tmp6$$Register,
15509                       -1, $result$$Register, StrIntrinsicNode::UU);
15510   %}
15511   ins_pipe(pipe_class_memory);
15512 %}
15513 
15514 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15515        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15516        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15517 %{
15518   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15519   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15520   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15521          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15522   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15523 
15524   ins_encode %{
15525     __ string_indexof($str1$$Register, $str2$$Register,
15526                       $cnt1$$Register, $cnt2$$Register,
15527                       $tmp1$$Register, $tmp2$$Register,
15528                       $tmp3$$Register, $tmp4$$Register,
15529                       $tmp5$$Register, $tmp6$$Register,
15530                       -1, $result$$Register, StrIntrinsicNode::LL);
15531   %}
15532   ins_pipe(pipe_class_memory);
15533 %}
15534 
15535 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15536        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15537        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15538 %{
15539   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15540   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15541   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15542          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15543   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15544 
15545   ins_encode %{
15546     __ string_indexof($str1$$Register, $str2$$Register,
15547                       $cnt1$$Register, $cnt2$$Register,
15548                       $tmp1$$Register, $tmp2$$Register,
15549                       $tmp3$$Register, $tmp4$$Register,
15550                       $tmp5$$Register, $tmp6$$Register,
15551                       -1, $result$$Register, StrIntrinsicNode::UL);
15552   %}
15553   ins_pipe(pipe_class_memory);
15554 %}
15555 
15556 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15557                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15558                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15559 %{
15560   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15561   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15562   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15563          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15564   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15565 
15566   ins_encode %{
15567     int icnt2 = (int)$int_cnt2$$constant;
15568     __ string_indexof($str1$$Register, $str2$$Register,
15569                       $cnt1$$Register, zr,
15570                       $tmp1$$Register, $tmp2$$Register,
15571                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15572                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15573   %}
15574   ins_pipe(pipe_class_memory);
15575 %}
15576 
15577 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15578                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15579                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15580 %{
15581   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15582   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15583   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15584          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15585   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15586 
15587   ins_encode %{
15588     int icnt2 = (int)$int_cnt2$$constant;
15589     __ string_indexof($str1$$Register, $str2$$Register,
15590                       $cnt1$$Register, zr,
15591                       $tmp1$$Register, $tmp2$$Register,
15592                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15593                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15594   %}
15595   ins_pipe(pipe_class_memory);
15596 %}
15597 
15598 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15599                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15600                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15601 %{
15602   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15603   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15604   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15605          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15606   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15607 
15608   ins_encode %{
15609     int icnt2 = (int)$int_cnt2$$constant;
15610     __ string_indexof($str1$$Register, $str2$$Register,
15611                       $cnt1$$Register, zr,
15612                       $tmp1$$Register, $tmp2$$Register,
15613                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15614                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15615   %}
15616   ins_pipe(pipe_class_memory);
15617 %}
15618 
15619 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15620                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15621                               iRegINoSp tmp3, rFlagsReg cr)
15622 %{
15623   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15624   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15625          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15626 
15627   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15628 
15629   ins_encode %{
15630     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15631                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15632                            $tmp3$$Register);
15633   %}
15634   ins_pipe(pipe_class_memory);
15635 %}
15636 
15637 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15638                         iRegI_R0 result, rFlagsReg cr)
15639 %{
15640   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15641   match(Set result (StrEquals (Binary str1 str2) cnt));
15642   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15643 
15644   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15645   ins_encode %{
15646     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15647     __ string_equals($str1$$Register, $str2$$Register,
15648                      $result$$Register, $cnt$$Register, 1);
15649   %}
15650   ins_pipe(pipe_class_memory);
15651 %}
15652 
15653 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15654                         iRegI_R0 result, rFlagsReg cr)
15655 %{
15656   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15657   match(Set result (StrEquals (Binary str1 str2) cnt));
15658   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15659 
15660   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15661   ins_encode %{
15662     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15663     __ string_equals($str1$$Register, $str2$$Register,
15664                      $result$$Register, $cnt$$Register, 2);
15665   %}
15666   ins_pipe(pipe_class_memory);
15667 %}
15668 
15669 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15670                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15671                        iRegP_R10 tmp, rFlagsReg cr)
15672 %{
15673   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15674   match(Set result (AryEq ary1 ary2));
15675   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15676 
15677   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15678   ins_encode %{
15679     __ arrays_equals($ary1$$Register, $ary2$$Register,
15680                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15681                      $result$$Register, $tmp$$Register, 1);
15682     %}
15683   ins_pipe(pipe_class_memory);
15684 %}
15685 
15686 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15687                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15688                        iRegP_R10 tmp, rFlagsReg cr)
15689 %{
15690   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15691   match(Set result (AryEq ary1 ary2));
15692   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15693 
15694   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15695   ins_encode %{
15696     __ arrays_equals($ary1$$Register, $ary2$$Register,
15697                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15698                      $result$$Register, $tmp$$Register, 2);
15699   %}
15700   ins_pipe(pipe_class_memory);
15701 %}
15702 
15703 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15704 %{
15705   match(Set result (HasNegatives ary1 len));
15706   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15707   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15708   ins_encode %{
15709     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15710   %}
15711   ins_pipe( pipe_slow );
15712 %}
15713 
15714 // fast char[] to byte[] compression
15715 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15716                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15717                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15718                          iRegI_R0 result, rFlagsReg cr)
15719 %{
15720   match(Set result (StrCompressedCopy src (Binary dst len)));
15721   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15722 
15723   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15724   ins_encode %{
15725     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15726                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15727                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15728                            $result$$Register);
15729   %}
15730   ins_pipe( pipe_slow );
15731 %}
15732 
15733 // fast byte[] to char[] inflation
15734 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15735                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15736 %{
15737   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15738   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15739 
15740   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15741   ins_encode %{
15742     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15743                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15744   %}
15745   ins_pipe(pipe_class_memory);
15746 %}
15747 
15748 // encode char[] to byte[] in ISO_8859_1
15749 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15750                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15751                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15752                           iRegI_R0 result, rFlagsReg cr)
15753 %{
15754   match(Set result (EncodeISOArray src (Binary dst len)));
15755   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15756          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15757 
15758   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15759   ins_encode %{
15760     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15761          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15762          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15763   %}
15764   ins_pipe( pipe_class_memory );
15765 %}
15766 
15767 // ============================================================================
15768 // This name is KNOWN by the ADLC and cannot be changed.
15769 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15770 // for this guy.
15771 instruct tlsLoadP(thread_RegP dst)
15772 %{
15773   match(Set dst (ThreadLocal));
15774 
15775   ins_cost(0);
15776 
15777   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15778 
15779   size(0);
15780 
15781   ins_encode( /*empty*/ );
15782 
15783   ins_pipe(pipe_class_empty);
15784 %}
15785 
15786 // ====================VECTOR INSTRUCTIONS=====================================
15787 
15788 // Load vector (32 bits)
15789 instruct loadV4(vecD dst, vmem4 mem)
15790 %{
15791   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15792   match(Set dst (LoadVector mem));
15793   ins_cost(4 * INSN_COST);
15794   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15795   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15796   ins_pipe(vload_reg_mem64);
15797 %}
15798 
15799 // Load vector (64 bits)
15800 instruct loadV8(vecD dst, vmem8 mem)
15801 %{
15802   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15803   match(Set dst (LoadVector mem));
15804   ins_cost(4 * INSN_COST);
15805   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15806   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15807   ins_pipe(vload_reg_mem64);
15808 %}
15809 
15810 // Load Vector (128 bits)
15811 instruct loadV16(vecX dst, vmem16 mem)
15812 %{
15813   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15814   match(Set dst (LoadVector mem));
15815   ins_cost(4 * INSN_COST);
15816   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15817   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15818   ins_pipe(vload_reg_mem128);
15819 %}
15820 
15821 // Store Vector (32 bits)
15822 instruct storeV4(vecD src, vmem4 mem)
15823 %{
15824   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15825   match(Set mem (StoreVector mem src));
15826   ins_cost(4 * INSN_COST);
15827   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15828   ins_encode( aarch64_enc_strvS(src, mem) );
15829   ins_pipe(vstore_reg_mem64);
15830 %}
15831 
15832 // Store Vector (64 bits)
15833 instruct storeV8(vecD src, vmem8 mem)
15834 %{
15835   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15836   match(Set mem (StoreVector mem src));
15837   ins_cost(4 * INSN_COST);
15838   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15839   ins_encode( aarch64_enc_strvD(src, mem) );
15840   ins_pipe(vstore_reg_mem64);
15841 %}
15842 
15843 // Store Vector (128 bits)
15844 instruct storeV16(vecX src, vmem16 mem)
15845 %{
15846   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15847   match(Set mem (StoreVector mem src));
15848   ins_cost(4 * INSN_COST);
15849   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15850   ins_encode( aarch64_enc_strvQ(src, mem) );
15851   ins_pipe(vstore_reg_mem128);
15852 %}
15853 
15854 instruct replicate8B(vecD dst, iRegIorL2I src)
15855 %{
15856   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15857             n-&gt;as_Vector()-&gt;length() == 8);
15858   match(Set dst (ReplicateB src));
15859   ins_cost(INSN_COST);
15860   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15861   ins_encode %{
15862     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15863   %}
15864   ins_pipe(vdup_reg_reg64);
15865 %}
15866 
15867 instruct replicate16B(vecX dst, iRegIorL2I src)
15868 %{
15869   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15870   match(Set dst (ReplicateB src));
15871   ins_cost(INSN_COST);
15872   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15873   ins_encode %{
15874     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15875   %}
15876   ins_pipe(vdup_reg_reg128);
15877 %}
15878 
15879 instruct replicate8B_imm(vecD dst, immI con)
15880 %{
15881   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15882             n-&gt;as_Vector()-&gt;length() == 8);
15883   match(Set dst (ReplicateB con));
15884   ins_cost(INSN_COST);
15885   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15886   ins_encode %{
15887     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15888   %}
15889   ins_pipe(vmovi_reg_imm64);
15890 %}
15891 
15892 instruct replicate16B_imm(vecX dst, immI con)
15893 %{
15894   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15895   match(Set dst (ReplicateB con));
15896   ins_cost(INSN_COST);
15897   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15898   ins_encode %{
15899     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15900   %}
15901   ins_pipe(vmovi_reg_imm128);
15902 %}
15903 
15904 instruct replicate4S(vecD dst, iRegIorL2I src)
15905 %{
15906   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15907             n-&gt;as_Vector()-&gt;length() == 4);
15908   match(Set dst (ReplicateS src));
15909   ins_cost(INSN_COST);
15910   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15911   ins_encode %{
15912     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15913   %}
15914   ins_pipe(vdup_reg_reg64);
15915 %}
15916 
15917 instruct replicate8S(vecX dst, iRegIorL2I src)
15918 %{
15919   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15920   match(Set dst (ReplicateS src));
15921   ins_cost(INSN_COST);
15922   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15923   ins_encode %{
15924     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15925   %}
15926   ins_pipe(vdup_reg_reg128);
15927 %}
15928 
15929 instruct replicate4S_imm(vecD dst, immI con)
15930 %{
15931   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15932             n-&gt;as_Vector()-&gt;length() == 4);
15933   match(Set dst (ReplicateS con));
15934   ins_cost(INSN_COST);
15935   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15936   ins_encode %{
15937     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15938   %}
15939   ins_pipe(vmovi_reg_imm64);
15940 %}
15941 
15942 instruct replicate8S_imm(vecX dst, immI con)
15943 %{
15944   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15945   match(Set dst (ReplicateS con));
15946   ins_cost(INSN_COST);
15947   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15948   ins_encode %{
15949     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15950   %}
15951   ins_pipe(vmovi_reg_imm128);
15952 %}
15953 
15954 instruct replicate2I(vecD dst, iRegIorL2I src)
15955 %{
15956   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15957   match(Set dst (ReplicateI src));
15958   ins_cost(INSN_COST);
15959   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15960   ins_encode %{
15961     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15962   %}
15963   ins_pipe(vdup_reg_reg64);
15964 %}
15965 
15966 instruct replicate4I(vecX dst, iRegIorL2I src)
15967 %{
15968   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15969   match(Set dst (ReplicateI src));
15970   ins_cost(INSN_COST);
15971   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15972   ins_encode %{
15973     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15974   %}
15975   ins_pipe(vdup_reg_reg128);
15976 %}
15977 
15978 instruct replicate2I_imm(vecD dst, immI con)
15979 %{
15980   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15981   match(Set dst (ReplicateI con));
15982   ins_cost(INSN_COST);
15983   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15984   ins_encode %{
15985     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15986   %}
15987   ins_pipe(vmovi_reg_imm64);
15988 %}
15989 
15990 instruct replicate4I_imm(vecX dst, immI con)
15991 %{
15992   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15993   match(Set dst (ReplicateI con));
15994   ins_cost(INSN_COST);
15995   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15996   ins_encode %{
15997     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15998   %}
15999   ins_pipe(vmovi_reg_imm128);
16000 %}
16001 
16002 instruct replicate2L(vecX dst, iRegL src)
16003 %{
16004   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16005   match(Set dst (ReplicateL src));
16006   ins_cost(INSN_COST);
16007   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
16008   ins_encode %{
16009     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
16010   %}
16011   ins_pipe(vdup_reg_reg128);
16012 %}
16013 
16014 instruct replicate2L_zero(vecX dst, immI0 zero)
16015 %{
16016   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16017   match(Set dst (ReplicateI zero));
16018   ins_cost(INSN_COST);
16019   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16020   ins_encode %{
16021     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16022            as_FloatRegister($dst$$reg),
16023            as_FloatRegister($dst$$reg));
16024   %}
16025   ins_pipe(vmovi_reg_imm128);
16026 %}
16027 
16028 instruct replicate2F(vecD dst, vRegF src)
16029 %{
16030   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16031   match(Set dst (ReplicateF src));
16032   ins_cost(INSN_COST);
16033   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16034   ins_encode %{
16035     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16036            as_FloatRegister($src$$reg));
16037   %}
16038   ins_pipe(vdup_reg_freg64);
16039 %}
16040 
16041 instruct replicate4F(vecX dst, vRegF src)
16042 %{
16043   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16044   match(Set dst (ReplicateF src));
16045   ins_cost(INSN_COST);
16046   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16047   ins_encode %{
16048     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16049            as_FloatRegister($src$$reg));
16050   %}
16051   ins_pipe(vdup_reg_freg128);
16052 %}
16053 
16054 instruct replicate2D(vecX dst, vRegD src)
16055 %{
16056   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16057   match(Set dst (ReplicateD src));
16058   ins_cost(INSN_COST);
16059   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16060   ins_encode %{
16061     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16062            as_FloatRegister($src$$reg));
16063   %}
16064   ins_pipe(vdup_reg_dreg128);
16065 %}
16066 
16067 // ====================REDUCTION ARITHMETIC====================================
16068 
16069 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16070 %{
16071   match(Set dst (AddReductionVI src1 src2));
16072   ins_cost(INSN_COST);
16073   effect(TEMP tmp, TEMP tmp2);
16074   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16075             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
16076             &quot;addw  $dst, $src1, $tmp\n\t&quot;
16077             &quot;addw  $dst, $dst, $tmp2\t add reduction2i&quot;
16078   %}
16079   ins_encode %{
16080     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16081     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16082     __ addw($dst$$Register, $src1$$Register, $tmp$$Register);
16083     __ addw($dst$$Register, $dst$$Register, $tmp2$$Register);
16084   %}
16085   ins_pipe(pipe_class_default);
16086 %}
16087 
16088 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16089 %{
16090   match(Set dst (AddReductionVI src1 src2));
16091   ins_cost(INSN_COST);
16092   effect(TEMP tmp, TEMP tmp2);
16093   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16094             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16095             &quot;addw  $dst, $tmp2, $src1\t add reduction4i&quot;
16096   %}
16097   ins_encode %{
16098     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16099             as_FloatRegister($src2$$reg));
16100     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16101     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16102   %}
16103   ins_pipe(pipe_class_default);
16104 %}
16105 
16106 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16107 %{
16108   match(Set dst (MulReductionVI src1 src2));
16109   ins_cost(INSN_COST);
16110   effect(TEMP tmp, TEMP dst);
16111   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16112             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16113             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
16114             &quot;mul   $dst, $tmp, $dst\t mul reduction2i\n\t&quot;
16115   %}
16116   ins_encode %{
16117     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16118     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16119     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16120     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16121   %}
16122   ins_pipe(pipe_class_default);
16123 %}
16124 
16125 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16126 %{
16127   match(Set dst (MulReductionVI src1 src2));
16128   ins_cost(INSN_COST);
16129   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16130   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16131             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16132             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16133             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16134             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
16135             &quot;mul   $dst, $tmp2, $dst\t mul reduction4i\n\t&quot;
16136   %}
16137   ins_encode %{
16138     __ ins(as_FloatRegister($tmp$$reg), __ D,
16139            as_FloatRegister($src2$$reg), 0, 1);
16140     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16141            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16142     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16143     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16144     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16145     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16146   %}
16147   ins_pipe(pipe_class_default);
16148 %}
16149 
16150 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16151 %{
16152   match(Set dst (AddReductionVF src1 src2));
16153   ins_cost(INSN_COST);
16154   effect(TEMP tmp, TEMP dst);
16155   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16156             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16157             &quot;fadds $dst, $dst, $tmp\t add reduction2f&quot;
16158   %}
16159   ins_encode %{
16160     __ fadds(as_FloatRegister($dst$$reg),
16161              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16162     __ ins(as_FloatRegister($tmp$$reg), __ S,
16163            as_FloatRegister($src2$$reg), 0, 1);
16164     __ fadds(as_FloatRegister($dst$$reg),
16165              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16166   %}
16167   ins_pipe(pipe_class_default);
16168 %}
16169 
16170 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16171 %{
16172   match(Set dst (AddReductionVF src1 src2));
16173   ins_cost(INSN_COST);
16174   effect(TEMP tmp, TEMP dst);
16175   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16176             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16177             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16178             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16179             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16180             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16181             &quot;fadds $dst, $dst, $tmp\t add reduction4f&quot;
16182   %}
16183   ins_encode %{
16184     __ fadds(as_FloatRegister($dst$$reg),
16185              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16186     __ ins(as_FloatRegister($tmp$$reg), __ S,
16187            as_FloatRegister($src2$$reg), 0, 1);
16188     __ fadds(as_FloatRegister($dst$$reg),
16189              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16190     __ ins(as_FloatRegister($tmp$$reg), __ S,
16191            as_FloatRegister($src2$$reg), 0, 2);
16192     __ fadds(as_FloatRegister($dst$$reg),
16193              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16194     __ ins(as_FloatRegister($tmp$$reg), __ S,
16195            as_FloatRegister($src2$$reg), 0, 3);
16196     __ fadds(as_FloatRegister($dst$$reg),
16197              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16198   %}
16199   ins_pipe(pipe_class_default);
16200 %}
16201 
16202 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16203 %{
16204   match(Set dst (MulReductionVF src1 src2));
16205   ins_cost(INSN_COST);
16206   effect(TEMP tmp, TEMP dst);
16207   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16208             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16209             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16210   %}
16211   ins_encode %{
16212     __ fmuls(as_FloatRegister($dst$$reg),
16213              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16214     __ ins(as_FloatRegister($tmp$$reg), __ S,
16215            as_FloatRegister($src2$$reg), 0, 1);
16216     __ fmuls(as_FloatRegister($dst$$reg),
16217              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16218   %}
16219   ins_pipe(pipe_class_default);
16220 %}
16221 
16222 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16223 %{
16224   match(Set dst (MulReductionVF src1 src2));
16225   ins_cost(INSN_COST);
16226   effect(TEMP tmp, TEMP dst);
16227   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16228             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16229             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16230             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16231             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16232             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16233             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16234   %}
16235   ins_encode %{
16236     __ fmuls(as_FloatRegister($dst$$reg),
16237              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16238     __ ins(as_FloatRegister($tmp$$reg), __ S,
16239            as_FloatRegister($src2$$reg), 0, 1);
16240     __ fmuls(as_FloatRegister($dst$$reg),
16241              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16242     __ ins(as_FloatRegister($tmp$$reg), __ S,
16243            as_FloatRegister($src2$$reg), 0, 2);
16244     __ fmuls(as_FloatRegister($dst$$reg),
16245              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16246     __ ins(as_FloatRegister($tmp$$reg), __ S,
16247            as_FloatRegister($src2$$reg), 0, 3);
16248     __ fmuls(as_FloatRegister($dst$$reg),
16249              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16250   %}
16251   ins_pipe(pipe_class_default);
16252 %}
16253 
16254 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16255 %{
16256   match(Set dst (AddReductionVD src1 src2));
16257   ins_cost(INSN_COST);
16258   effect(TEMP tmp, TEMP dst);
16259   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16260             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16261             &quot;faddd $dst, $dst, $tmp\t add reduction2d&quot;
16262   %}
16263   ins_encode %{
16264     __ faddd(as_FloatRegister($dst$$reg),
16265              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16266     __ ins(as_FloatRegister($tmp$$reg), __ D,
16267            as_FloatRegister($src2$$reg), 0, 1);
16268     __ faddd(as_FloatRegister($dst$$reg),
16269              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16270   %}
16271   ins_pipe(pipe_class_default);
16272 %}
16273 
16274 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16275 %{
16276   match(Set dst (MulReductionVD src1 src2));
16277   ins_cost(INSN_COST);
16278   effect(TEMP tmp, TEMP dst);
16279   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16280             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16281             &quot;fmuld $dst, $dst, $tmp\t add reduction2d&quot;
16282   %}
16283   ins_encode %{
16284     __ fmuld(as_FloatRegister($dst$$reg),
16285              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16286     __ ins(as_FloatRegister($tmp$$reg), __ D,
16287            as_FloatRegister($src2$$reg), 0, 1);
16288     __ fmuld(as_FloatRegister($dst$$reg),
16289              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16290   %}
16291   ins_pipe(pipe_class_default);
16292 %}
16293 
16294 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16295   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16296   match(Set dst (MaxReductionV src1 src2));
16297   ins_cost(INSN_COST);
16298   effect(TEMP_DEF dst, TEMP tmp);
16299   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16300             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16301             &quot;fmaxs $dst, $dst, $tmp\t max reduction2F&quot; %}
16302   ins_encode %{
16303     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16304     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16305     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16306   %}
16307   ins_pipe(pipe_class_default);
16308 %}
16309 
16310 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16311   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16312   match(Set dst (MaxReductionV src1 src2));
16313   ins_cost(INSN_COST);
16314   effect(TEMP_DEF dst);
16315   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
16316             &quot;fmaxs $dst, $dst, $src1\t max reduction4F&quot; %}
16317   ins_encode %{
16318     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16319     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16320   %}
16321   ins_pipe(pipe_class_default);
16322 %}
16323 
16324 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16325   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16326   match(Set dst (MaxReductionV src1 src2));
16327   ins_cost(INSN_COST);
16328   effect(TEMP_DEF dst, TEMP tmp);
16329   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16330             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16331             &quot;fmaxd $dst, $dst, $tmp\t max reduction2D&quot; %}
16332   ins_encode %{
16333     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16334     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16335     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16336   %}
16337   ins_pipe(pipe_class_default);
16338 %}
16339 
16340 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16341   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16342   match(Set dst (MinReductionV src1 src2));
16343   ins_cost(INSN_COST);
16344   effect(TEMP_DEF dst, TEMP tmp);
16345   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16346             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16347             &quot;fmins $dst, $dst, $tmp\t min reduction2F&quot; %}
16348   ins_encode %{
16349     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16350     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16351     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16352   %}
16353   ins_pipe(pipe_class_default);
16354 %}
16355 
16356 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16357   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16358   match(Set dst (MinReductionV src1 src2));
16359   ins_cost(INSN_COST);
16360   effect(TEMP_DEF dst);
16361   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
16362             &quot;fmins $dst, $dst, $src1\t min reduction4F&quot; %}
16363   ins_encode %{
16364     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16365     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16366   %}
16367   ins_pipe(pipe_class_default);
16368 %}
16369 
16370 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16371   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16372   match(Set dst (MinReductionV src1 src2));
16373   ins_cost(INSN_COST);
16374   effect(TEMP_DEF dst, TEMP tmp);
16375   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16376             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16377             &quot;fmind $dst, $dst, $tmp\t min reduction2D&quot; %}
16378   ins_encode %{
16379     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16380     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16381     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16382   %}
16383   ins_pipe(pipe_class_default);
16384 %}
16385 
16386 // ====================VECTOR ARITHMETIC=======================================
16387 
16388 // --------------------------------- ADD --------------------------------------
16389 
16390 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16391 %{
16392   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16393             n-&gt;as_Vector()-&gt;length() == 8);
16394   match(Set dst (AddVB src1 src2));
16395   ins_cost(INSN_COST);
16396   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16397   ins_encode %{
16398     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16399             as_FloatRegister($src1$$reg),
16400             as_FloatRegister($src2$$reg));
16401   %}
16402   ins_pipe(vdop64);
16403 %}
16404 
16405 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16406 %{
16407   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16408   match(Set dst (AddVB src1 src2));
16409   ins_cost(INSN_COST);
16410   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16411   ins_encode %{
16412     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16413             as_FloatRegister($src1$$reg),
16414             as_FloatRegister($src2$$reg));
16415   %}
16416   ins_pipe(vdop128);
16417 %}
16418 
16419 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16420 %{
16421   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16422             n-&gt;as_Vector()-&gt;length() == 4);
16423   match(Set dst (AddVS src1 src2));
16424   ins_cost(INSN_COST);
16425   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16426   ins_encode %{
16427     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16428             as_FloatRegister($src1$$reg),
16429             as_FloatRegister($src2$$reg));
16430   %}
16431   ins_pipe(vdop64);
16432 %}
16433 
16434 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16435 %{
16436   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16437   match(Set dst (AddVS src1 src2));
16438   ins_cost(INSN_COST);
16439   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16440   ins_encode %{
16441     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16442             as_FloatRegister($src1$$reg),
16443             as_FloatRegister($src2$$reg));
16444   %}
16445   ins_pipe(vdop128);
16446 %}
16447 
16448 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16449 %{
16450   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16451   match(Set dst (AddVI src1 src2));
16452   ins_cost(INSN_COST);
16453   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16454   ins_encode %{
16455     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16456             as_FloatRegister($src1$$reg),
16457             as_FloatRegister($src2$$reg));
16458   %}
16459   ins_pipe(vdop64);
16460 %}
16461 
16462 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16463 %{
16464   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16465   match(Set dst (AddVI src1 src2));
16466   ins_cost(INSN_COST);
16467   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16468   ins_encode %{
16469     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16470             as_FloatRegister($src1$$reg),
16471             as_FloatRegister($src2$$reg));
16472   %}
16473   ins_pipe(vdop128);
16474 %}
16475 
16476 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16477 %{
16478   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16479   match(Set dst (AddVL src1 src2));
16480   ins_cost(INSN_COST);
16481   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16482   ins_encode %{
16483     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16484             as_FloatRegister($src1$$reg),
16485             as_FloatRegister($src2$$reg));
16486   %}
16487   ins_pipe(vdop128);
16488 %}
16489 
16490 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16491 %{
16492   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16493   match(Set dst (AddVF src1 src2));
16494   ins_cost(INSN_COST);
16495   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16496   ins_encode %{
16497     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16498             as_FloatRegister($src1$$reg),
16499             as_FloatRegister($src2$$reg));
16500   %}
16501   ins_pipe(vdop_fp64);
16502 %}
16503 
16504 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16505 %{
16506   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16507   match(Set dst (AddVF src1 src2));
16508   ins_cost(INSN_COST);
16509   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16510   ins_encode %{
16511     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16512             as_FloatRegister($src1$$reg),
16513             as_FloatRegister($src2$$reg));
16514   %}
16515   ins_pipe(vdop_fp128);
16516 %}
16517 
16518 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16519 %{
16520   match(Set dst (AddVD src1 src2));
16521   ins_cost(INSN_COST);
16522   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16523   ins_encode %{
16524     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16525             as_FloatRegister($src1$$reg),
16526             as_FloatRegister($src2$$reg));
16527   %}
16528   ins_pipe(vdop_fp128);
16529 %}
16530 
16531 // --------------------------------- SUB --------------------------------------
16532 
16533 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16534 %{
16535   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16536             n-&gt;as_Vector()-&gt;length() == 8);
16537   match(Set dst (SubVB src1 src2));
16538   ins_cost(INSN_COST);
16539   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16540   ins_encode %{
16541     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16542             as_FloatRegister($src1$$reg),
16543             as_FloatRegister($src2$$reg));
16544   %}
16545   ins_pipe(vdop64);
16546 %}
16547 
16548 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16549 %{
16550   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16551   match(Set dst (SubVB src1 src2));
16552   ins_cost(INSN_COST);
16553   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16554   ins_encode %{
16555     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16556             as_FloatRegister($src1$$reg),
16557             as_FloatRegister($src2$$reg));
16558   %}
16559   ins_pipe(vdop128);
16560 %}
16561 
16562 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16563 %{
16564   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16565             n-&gt;as_Vector()-&gt;length() == 4);
16566   match(Set dst (SubVS src1 src2));
16567   ins_cost(INSN_COST);
16568   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16569   ins_encode %{
16570     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16571             as_FloatRegister($src1$$reg),
16572             as_FloatRegister($src2$$reg));
16573   %}
16574   ins_pipe(vdop64);
16575 %}
16576 
16577 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16578 %{
16579   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16580   match(Set dst (SubVS src1 src2));
16581   ins_cost(INSN_COST);
16582   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16583   ins_encode %{
16584     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16585             as_FloatRegister($src1$$reg),
16586             as_FloatRegister($src2$$reg));
16587   %}
16588   ins_pipe(vdop128);
16589 %}
16590 
16591 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16592 %{
16593   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16594   match(Set dst (SubVI src1 src2));
16595   ins_cost(INSN_COST);
16596   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16597   ins_encode %{
16598     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16599             as_FloatRegister($src1$$reg),
16600             as_FloatRegister($src2$$reg));
16601   %}
16602   ins_pipe(vdop64);
16603 %}
16604 
16605 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16606 %{
16607   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16608   match(Set dst (SubVI src1 src2));
16609   ins_cost(INSN_COST);
16610   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16611   ins_encode %{
16612     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16613             as_FloatRegister($src1$$reg),
16614             as_FloatRegister($src2$$reg));
16615   %}
16616   ins_pipe(vdop128);
16617 %}
16618 
16619 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16620 %{
16621   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16622   match(Set dst (SubVL src1 src2));
16623   ins_cost(INSN_COST);
16624   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16625   ins_encode %{
16626     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16627             as_FloatRegister($src1$$reg),
16628             as_FloatRegister($src2$$reg));
16629   %}
16630   ins_pipe(vdop128);
16631 %}
16632 
16633 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16634 %{
16635   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16636   match(Set dst (SubVF src1 src2));
16637   ins_cost(INSN_COST);
16638   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16639   ins_encode %{
16640     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16641             as_FloatRegister($src1$$reg),
16642             as_FloatRegister($src2$$reg));
16643   %}
16644   ins_pipe(vdop_fp64);
16645 %}
16646 
16647 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16648 %{
16649   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16650   match(Set dst (SubVF src1 src2));
16651   ins_cost(INSN_COST);
16652   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16653   ins_encode %{
16654     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16655             as_FloatRegister($src1$$reg),
16656             as_FloatRegister($src2$$reg));
16657   %}
16658   ins_pipe(vdop_fp128);
16659 %}
16660 
16661 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16662 %{
16663   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16664   match(Set dst (SubVD src1 src2));
16665   ins_cost(INSN_COST);
16666   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16667   ins_encode %{
16668     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16669             as_FloatRegister($src1$$reg),
16670             as_FloatRegister($src2$$reg));
16671   %}
16672   ins_pipe(vdop_fp128);
16673 %}
16674 
16675 // --------------------------------- MUL --------------------------------------
16676 
16677 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16678 %{
16679   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16680             n-&gt;as_Vector()-&gt;length() == 4);
16681   match(Set dst (MulVS src1 src2));
16682   ins_cost(INSN_COST);
16683   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16684   ins_encode %{
16685     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16686             as_FloatRegister($src1$$reg),
16687             as_FloatRegister($src2$$reg));
16688   %}
16689   ins_pipe(vmul64);
16690 %}
16691 
16692 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16693 %{
16694   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16695   match(Set dst (MulVS src1 src2));
16696   ins_cost(INSN_COST);
16697   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16698   ins_encode %{
16699     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16700             as_FloatRegister($src1$$reg),
16701             as_FloatRegister($src2$$reg));
16702   %}
16703   ins_pipe(vmul128);
16704 %}
16705 
16706 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16707 %{
16708   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16709   match(Set dst (MulVI src1 src2));
16710   ins_cost(INSN_COST);
16711   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16712   ins_encode %{
16713     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16714             as_FloatRegister($src1$$reg),
16715             as_FloatRegister($src2$$reg));
16716   %}
16717   ins_pipe(vmul64);
16718 %}
16719 
16720 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16721 %{
16722   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16723   match(Set dst (MulVI src1 src2));
16724   ins_cost(INSN_COST);
16725   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16726   ins_encode %{
16727     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16728             as_FloatRegister($src1$$reg),
16729             as_FloatRegister($src2$$reg));
16730   %}
16731   ins_pipe(vmul128);
16732 %}
16733 
16734 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16735 %{
16736   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16737   match(Set dst (MulVF src1 src2));
16738   ins_cost(INSN_COST);
16739   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16740   ins_encode %{
16741     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16742             as_FloatRegister($src1$$reg),
16743             as_FloatRegister($src2$$reg));
16744   %}
16745   ins_pipe(vmuldiv_fp64);
16746 %}
16747 
16748 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16749 %{
16750   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16751   match(Set dst (MulVF src1 src2));
16752   ins_cost(INSN_COST);
16753   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16754   ins_encode %{
16755     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16756             as_FloatRegister($src1$$reg),
16757             as_FloatRegister($src2$$reg));
16758   %}
16759   ins_pipe(vmuldiv_fp128);
16760 %}
16761 
16762 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16763 %{
16764   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16765   match(Set dst (MulVD src1 src2));
16766   ins_cost(INSN_COST);
16767   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16768   ins_encode %{
16769     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16770             as_FloatRegister($src1$$reg),
16771             as_FloatRegister($src2$$reg));
16772   %}
16773   ins_pipe(vmuldiv_fp128);
16774 %}
16775 
16776 // --------------------------------- MLA --------------------------------------
16777 
16778 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16779 %{
16780   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16781             n-&gt;as_Vector()-&gt;length() == 4);
16782   match(Set dst (AddVS dst (MulVS src1 src2)));
16783   ins_cost(INSN_COST);
16784   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16785   ins_encode %{
16786     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16787             as_FloatRegister($src1$$reg),
16788             as_FloatRegister($src2$$reg));
16789   %}
16790   ins_pipe(vmla64);
16791 %}
16792 
16793 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16794 %{
16795   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16796   match(Set dst (AddVS dst (MulVS src1 src2)));
16797   ins_cost(INSN_COST);
16798   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16799   ins_encode %{
16800     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16801             as_FloatRegister($src1$$reg),
16802             as_FloatRegister($src2$$reg));
16803   %}
16804   ins_pipe(vmla128);
16805 %}
16806 
16807 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16808 %{
16809   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16810   match(Set dst (AddVI dst (MulVI src1 src2)));
16811   ins_cost(INSN_COST);
16812   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16813   ins_encode %{
16814     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16815             as_FloatRegister($src1$$reg),
16816             as_FloatRegister($src2$$reg));
16817   %}
16818   ins_pipe(vmla64);
16819 %}
16820 
16821 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16822 %{
16823   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16824   match(Set dst (AddVI dst (MulVI src1 src2)));
16825   ins_cost(INSN_COST);
16826   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16827   ins_encode %{
16828     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16829             as_FloatRegister($src1$$reg),
16830             as_FloatRegister($src2$$reg));
16831   %}
16832   ins_pipe(vmla128);
16833 %}
16834 
16835 // dst + src1 * src2
16836 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16837   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16838   match(Set dst (FmaVF  dst (Binary src1 src2)));
16839   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16840   ins_cost(INSN_COST);
16841   ins_encode %{
16842     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16843             as_FloatRegister($src1$$reg),
16844             as_FloatRegister($src2$$reg));
16845   %}
16846   ins_pipe(vmuldiv_fp64);
16847 %}
16848 
16849 // dst + src1 * src2
16850 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16851   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16852   match(Set dst (FmaVF  dst (Binary src1 src2)));
16853   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16854   ins_cost(INSN_COST);
16855   ins_encode %{
16856     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16857             as_FloatRegister($src1$$reg),
16858             as_FloatRegister($src2$$reg));
16859   %}
16860   ins_pipe(vmuldiv_fp128);
16861 %}
16862 
16863 // dst + src1 * src2
16864 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16865   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16866   match(Set dst (FmaVD  dst (Binary src1 src2)));
16867   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16868   ins_cost(INSN_COST);
16869   ins_encode %{
16870     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16871             as_FloatRegister($src1$$reg),
16872             as_FloatRegister($src2$$reg));
16873   %}
16874   ins_pipe(vmuldiv_fp128);
16875 %}
16876 
16877 // --------------------------------- MLS --------------------------------------
16878 
16879 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16880 %{
16881   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16882             n-&gt;as_Vector()-&gt;length() == 4);
16883   match(Set dst (SubVS dst (MulVS src1 src2)));
16884   ins_cost(INSN_COST);
16885   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16886   ins_encode %{
16887     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16888             as_FloatRegister($src1$$reg),
16889             as_FloatRegister($src2$$reg));
16890   %}
16891   ins_pipe(vmla64);
16892 %}
16893 
16894 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16895 %{
16896   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16897   match(Set dst (SubVS dst (MulVS src1 src2)));
16898   ins_cost(INSN_COST);
16899   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16900   ins_encode %{
16901     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16902             as_FloatRegister($src1$$reg),
16903             as_FloatRegister($src2$$reg));
16904   %}
16905   ins_pipe(vmla128);
16906 %}
16907 
16908 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16909 %{
16910   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16911   match(Set dst (SubVI dst (MulVI src1 src2)));
16912   ins_cost(INSN_COST);
16913   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16914   ins_encode %{
16915     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16916             as_FloatRegister($src1$$reg),
16917             as_FloatRegister($src2$$reg));
16918   %}
16919   ins_pipe(vmla64);
16920 %}
16921 
16922 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16923 %{
16924   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16925   match(Set dst (SubVI dst (MulVI src1 src2)));
16926   ins_cost(INSN_COST);
16927   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16928   ins_encode %{
16929     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16930             as_FloatRegister($src1$$reg),
16931             as_FloatRegister($src2$$reg));
16932   %}
16933   ins_pipe(vmla128);
16934 %}
16935 
16936 // dst - src1 * src2
16937 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16938   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16939   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16940   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16941   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16942   ins_cost(INSN_COST);
16943   ins_encode %{
16944     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16945             as_FloatRegister($src1$$reg),
16946             as_FloatRegister($src2$$reg));
16947   %}
16948   ins_pipe(vmuldiv_fp64);
16949 %}
16950 
16951 // dst - src1 * src2
16952 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16953   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16954   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16955   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16956   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16957   ins_cost(INSN_COST);
16958   ins_encode %{
16959     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16960             as_FloatRegister($src1$$reg),
16961             as_FloatRegister($src2$$reg));
16962   %}
16963   ins_pipe(vmuldiv_fp128);
16964 %}
16965 
16966 // dst - src1 * src2
16967 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16968   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16969   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16970   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16971   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16972   ins_cost(INSN_COST);
16973   ins_encode %{
16974     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16975             as_FloatRegister($src1$$reg),
16976             as_FloatRegister($src2$$reg));
16977   %}
16978   ins_pipe(vmuldiv_fp128);
16979 %}
16980 
16981 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16982 
16983 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16984   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16985   match(Set dst (MulAddVS2VI src1 src2));
16986   ins_cost(INSN_COST);
16987   effect(TEMP_DEF dst, TEMP tmp);
16988   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16989             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16990             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
16991   ins_encode %{
16992     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
16993               as_FloatRegister($src1$$reg),
16994               as_FloatRegister($src2$$reg));
16995     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
16996               as_FloatRegister($src1$$reg),
16997               as_FloatRegister($src2$$reg));
16998     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
16999              as_FloatRegister($tmp$$reg),
17000              as_FloatRegister($dst$$reg));
17001   %}
17002   ins_pipe(vmuldiv_fp128);
17003 %}
17004 
17005 // --------------------------------- DIV --------------------------------------
17006 
17007 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
17008 %{
17009   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17010   match(Set dst (DivVF src1 src2));
17011   ins_cost(INSN_COST);
17012   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17013   ins_encode %{
17014     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17015             as_FloatRegister($src1$$reg),
17016             as_FloatRegister($src2$$reg));
17017   %}
17018   ins_pipe(vmuldiv_fp64);
17019 %}
17020 
17021 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17022 %{
17023   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17024   match(Set dst (DivVF src1 src2));
17025   ins_cost(INSN_COST);
17026   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17027   ins_encode %{
17028     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17029             as_FloatRegister($src1$$reg),
17030             as_FloatRegister($src2$$reg));
17031   %}
17032   ins_pipe(vmuldiv_fp128);
17033 %}
17034 
17035 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17036 %{
17037   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17038   match(Set dst (DivVD src1 src2));
17039   ins_cost(INSN_COST);
17040   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17041   ins_encode %{
17042     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17043             as_FloatRegister($src1$$reg),
17044             as_FloatRegister($src2$$reg));
17045   %}
17046   ins_pipe(vmuldiv_fp128);
17047 %}
17048 
17049 // --------------------------------- SQRT -------------------------------------
17050 
17051 instruct vsqrt2D(vecX dst, vecX src)
17052 %{
17053   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17054   match(Set dst (SqrtVD src));
17055   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17056   ins_encode %{
17057     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17058              as_FloatRegister($src$$reg));
17059   %}
17060   ins_pipe(vsqrt_fp128);
17061 %}
17062 
17063 // --------------------------------- ABS --------------------------------------
17064 
17065 instruct vabs2F(vecD dst, vecD src)
17066 %{
17067   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17068   match(Set dst (AbsVF src));
17069   ins_cost(INSN_COST * 3);
17070   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17071   ins_encode %{
17072     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17073             as_FloatRegister($src$$reg));
17074   %}
17075   ins_pipe(vunop_fp64);
17076 %}
17077 
17078 instruct vabs4F(vecX dst, vecX src)
17079 %{
17080   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17081   match(Set dst (AbsVF src));
17082   ins_cost(INSN_COST * 3);
17083   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17084   ins_encode %{
17085     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17086             as_FloatRegister($src$$reg));
17087   %}
17088   ins_pipe(vunop_fp128);
17089 %}
17090 
17091 instruct vabs2D(vecX dst, vecX src)
17092 %{
17093   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17094   match(Set dst (AbsVD src));
17095   ins_cost(INSN_COST * 3);
17096   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17097   ins_encode %{
17098     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17099             as_FloatRegister($src$$reg));
17100   %}
17101   ins_pipe(vunop_fp128);
17102 %}
17103 
17104 // --------------------------------- NEG --------------------------------------
17105 
17106 instruct vneg2F(vecD dst, vecD src)
17107 %{
17108   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17109   match(Set dst (NegVF src));
17110   ins_cost(INSN_COST * 3);
17111   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17112   ins_encode %{
17113     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17114             as_FloatRegister($src$$reg));
17115   %}
17116   ins_pipe(vunop_fp64);
17117 %}
17118 
17119 instruct vneg4F(vecX dst, vecX src)
17120 %{
17121   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17122   match(Set dst (NegVF src));
17123   ins_cost(INSN_COST * 3);
17124   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17125   ins_encode %{
17126     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17127             as_FloatRegister($src$$reg));
17128   %}
17129   ins_pipe(vunop_fp128);
17130 %}
17131 
17132 instruct vneg2D(vecX dst, vecX src)
17133 %{
17134   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17135   match(Set dst (NegVD src));
17136   ins_cost(INSN_COST * 3);
17137   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17138   ins_encode %{
17139     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17140             as_FloatRegister($src$$reg));
17141   %}
17142   ins_pipe(vunop_fp128);
17143 %}
17144 
17145 // --------------------------------- AND --------------------------------------
17146 
17147 instruct vand8B(vecD dst, vecD src1, vecD src2)
17148 %{
17149   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17150             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17151   match(Set dst (AndV src1 src2));
17152   ins_cost(INSN_COST);
17153   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17154   ins_encode %{
17155     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17156             as_FloatRegister($src1$$reg),
17157             as_FloatRegister($src2$$reg));
17158   %}
17159   ins_pipe(vlogical64);
17160 %}
17161 
17162 instruct vand16B(vecX dst, vecX src1, vecX src2)
17163 %{
17164   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17165   match(Set dst (AndV src1 src2));
17166   ins_cost(INSN_COST);
17167   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17168   ins_encode %{
17169     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17170             as_FloatRegister($src1$$reg),
17171             as_FloatRegister($src2$$reg));
17172   %}
17173   ins_pipe(vlogical128);
17174 %}
17175 
17176 // --------------------------------- OR ---------------------------------------
17177 
17178 instruct vor8B(vecD dst, vecD src1, vecD src2)
17179 %{
17180   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17181             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17182   match(Set dst (OrV src1 src2));
17183   ins_cost(INSN_COST);
17184   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17185   ins_encode %{
17186     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17187             as_FloatRegister($src1$$reg),
17188             as_FloatRegister($src2$$reg));
17189   %}
17190   ins_pipe(vlogical64);
17191 %}
17192 
17193 instruct vor16B(vecX dst, vecX src1, vecX src2)
17194 %{
17195   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17196   match(Set dst (OrV src1 src2));
17197   ins_cost(INSN_COST);
17198   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17199   ins_encode %{
17200     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17201             as_FloatRegister($src1$$reg),
17202             as_FloatRegister($src2$$reg));
17203   %}
17204   ins_pipe(vlogical128);
17205 %}
17206 
17207 // --------------------------------- XOR --------------------------------------
17208 
17209 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17210 %{
17211   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17212             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17213   match(Set dst (XorV src1 src2));
17214   ins_cost(INSN_COST);
17215   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17216   ins_encode %{
17217     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17218             as_FloatRegister($src1$$reg),
17219             as_FloatRegister($src2$$reg));
17220   %}
17221   ins_pipe(vlogical64);
17222 %}
17223 
17224 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17225 %{
17226   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17227   match(Set dst (XorV src1 src2));
17228   ins_cost(INSN_COST);
17229   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17230   ins_encode %{
17231     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17232             as_FloatRegister($src1$$reg),
17233             as_FloatRegister($src2$$reg));
17234   %}
17235   ins_pipe(vlogical128);
17236 %}
17237 
17238 // ------------------------------ Shift ---------------------------------------
17239 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17240   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17241   match(Set dst (LShiftCntV cnt));
17242   match(Set dst (RShiftCntV cnt));
17243   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17244   ins_encode %{
17245     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17246   %}
17247   ins_pipe(vdup_reg_reg64);
17248 %}
17249 
17250 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17251   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17252   match(Set dst (LShiftCntV cnt));
17253   match(Set dst (RShiftCntV cnt));
17254   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17255   ins_encode %{
17256     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17257   %}
17258   ins_pipe(vdup_reg_reg128);
17259 %}
17260 
17261 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17262   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17263             n-&gt;as_Vector()-&gt;length() == 8);
17264   match(Set dst (LShiftVB src shift));
17265   ins_cost(INSN_COST);
17266   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17267   ins_encode %{
17268     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17269             as_FloatRegister($src$$reg),
17270             as_FloatRegister($shift$$reg));
17271   %}
17272   ins_pipe(vshift64);
17273 %}
17274 
17275 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17276   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17277   match(Set dst (LShiftVB src shift));
17278   ins_cost(INSN_COST);
17279   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17280   ins_encode %{
17281     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17282             as_FloatRegister($src$$reg),
17283             as_FloatRegister($shift$$reg));
17284   %}
17285   ins_pipe(vshift128);
17286 %}
17287 
17288 // Right shifts with vector shift count on aarch64 SIMD are implemented
17289 // as left shift by negative shift count.
17290 // There are two cases for vector shift count.
17291 //
17292 // Case 1: The vector shift count is from replication.
17293 //        |            |
17294 //    LoadVector  RShiftCntV
17295 //        |       /
17296 //     RShiftVI
17297 // Note: In inner loop, multiple neg instructions are used, which can be
17298 // moved to outer loop and merge into one neg instruction.
17299 //
17300 // Case 2: The vector shift count is from loading.
17301 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17302 // panama/vectorIntrinsics(JEP 338: Vector API).
17303 //        |            |
17304 //    LoadVector  LoadVector
17305 //        |       /
17306 //     RShiftVI
17307 //
17308 
17309 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17310   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17311             n-&gt;as_Vector()-&gt;length() == 8);
17312   match(Set dst (RShiftVB src shift));
17313   ins_cost(INSN_COST);
17314   effect(TEMP tmp);
17315   format %{ &quot;negr  $tmp,$shift\t&quot;
17316             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17317   ins_encode %{
17318     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17319             as_FloatRegister($shift$$reg));
17320     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17321             as_FloatRegister($src$$reg),
17322             as_FloatRegister($tmp$$reg));
17323   %}
17324   ins_pipe(vshift64);
17325 %}
17326 
17327 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17328   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17329   match(Set dst (RShiftVB src shift));
17330   ins_cost(INSN_COST);
17331   effect(TEMP tmp);
17332   format %{ &quot;negr  $tmp,$shift\t&quot;
17333             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17334   ins_encode %{
17335     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17336             as_FloatRegister($shift$$reg));
17337     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17338             as_FloatRegister($src$$reg),
17339             as_FloatRegister($tmp$$reg));
17340   %}
17341   ins_pipe(vshift128);
17342 %}
17343 
17344 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17345   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17346             n-&gt;as_Vector()-&gt;length() == 8);
17347   match(Set dst (URShiftVB src shift));
17348   ins_cost(INSN_COST);
17349   effect(TEMP tmp);
17350   format %{ &quot;negr  $tmp,$shift\t&quot;
17351             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17352   ins_encode %{
17353     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17354             as_FloatRegister($shift$$reg));
17355     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17356             as_FloatRegister($src$$reg),
17357             as_FloatRegister($tmp$$reg));
17358   %}
17359   ins_pipe(vshift64);
17360 %}
17361 
17362 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17363   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17364   match(Set dst (URShiftVB src shift));
17365   ins_cost(INSN_COST);
17366   effect(TEMP tmp);
17367   format %{ &quot;negr  $tmp,$shift\t&quot;
17368             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17369   ins_encode %{
17370     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17371             as_FloatRegister($shift$$reg));
17372     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17373             as_FloatRegister($src$$reg),
17374             as_FloatRegister($tmp$$reg));
17375   %}
17376   ins_pipe(vshift128);
17377 %}
17378 
17379 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17380   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17381             n-&gt;as_Vector()-&gt;length() == 8);
17382   match(Set dst (LShiftVB src (LShiftCntV shift)));
17383   ins_cost(INSN_COST);
17384   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17385   ins_encode %{
17386     int sh = (int)$shift$$constant;
17387     if (sh &gt;= 8) {
17388       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17389              as_FloatRegister($src$$reg),
17390              as_FloatRegister($src$$reg));
17391     } else {
17392       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17393              as_FloatRegister($src$$reg), sh);
17394     }
17395   %}
17396   ins_pipe(vshift64_imm);
17397 %}
17398 
17399 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17400   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17401   match(Set dst (LShiftVB src (LShiftCntV shift)));
17402   ins_cost(INSN_COST);
17403   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17404   ins_encode %{
17405     int sh = (int)$shift$$constant;
17406     if (sh &gt;= 8) {
17407       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17408              as_FloatRegister($src$$reg),
17409              as_FloatRegister($src$$reg));
17410     } else {
17411       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17412              as_FloatRegister($src$$reg), sh);
17413     }
17414   %}
17415   ins_pipe(vshift128_imm);
17416 %}
17417 
17418 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17419   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17420             n-&gt;as_Vector()-&gt;length() == 8);
17421   match(Set dst (RShiftVB src (RShiftCntV shift)));
17422   ins_cost(INSN_COST);
17423   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17424   ins_encode %{
17425     int sh = (int)$shift$$constant;
17426     if (sh &gt;= 8) sh = 7;
17427     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17428            as_FloatRegister($src$$reg), sh);
17429   %}
17430   ins_pipe(vshift64_imm);
17431 %}
17432 
17433 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17434   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17435   match(Set dst (RShiftVB src (RShiftCntV shift)));
17436   ins_cost(INSN_COST);
17437   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17438   ins_encode %{
17439     int sh = (int)$shift$$constant;
17440     if (sh &gt;= 8) sh = 7;
17441     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17442            as_FloatRegister($src$$reg), sh);
17443   %}
17444   ins_pipe(vshift128_imm);
17445 %}
17446 
17447 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17448   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17449             n-&gt;as_Vector()-&gt;length() == 8);
17450   match(Set dst (URShiftVB src (RShiftCntV shift)));
17451   ins_cost(INSN_COST);
17452   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17453   ins_encode %{
17454     int sh = (int)$shift$$constant;
17455     if (sh &gt;= 8) {
17456       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17457              as_FloatRegister($src$$reg),
17458              as_FloatRegister($src$$reg));
17459     } else {
17460       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17461              as_FloatRegister($src$$reg), sh);
17462     }
17463   %}
17464   ins_pipe(vshift64_imm);
17465 %}
17466 
17467 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17468   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17469   match(Set dst (URShiftVB src (RShiftCntV shift)));
17470   ins_cost(INSN_COST);
17471   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17472   ins_encode %{
17473     int sh = (int)$shift$$constant;
17474     if (sh &gt;= 8) {
17475       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17476              as_FloatRegister($src$$reg),
17477              as_FloatRegister($src$$reg));
17478     } else {
17479       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17480              as_FloatRegister($src$$reg), sh);
17481     }
17482   %}
17483   ins_pipe(vshift128_imm);
17484 %}
17485 
17486 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17487   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17488             n-&gt;as_Vector()-&gt;length() == 4);
17489   match(Set dst (LShiftVS src shift));
17490   ins_cost(INSN_COST);
17491   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17492   ins_encode %{
17493     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17494             as_FloatRegister($src$$reg),
17495             as_FloatRegister($shift$$reg));
17496   %}
17497   ins_pipe(vshift64);
17498 %}
17499 
17500 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17501   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17502   match(Set dst (LShiftVS src shift));
17503   ins_cost(INSN_COST);
17504   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17505   ins_encode %{
17506     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17507             as_FloatRegister($src$$reg),
17508             as_FloatRegister($shift$$reg));
17509   %}
17510   ins_pipe(vshift128);
17511 %}
17512 
17513 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17514   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17515             n-&gt;as_Vector()-&gt;length() == 4);
17516   match(Set dst (RShiftVS src shift));
17517   ins_cost(INSN_COST);
17518   effect(TEMP tmp);
17519   format %{ &quot;negr  $tmp,$shift\t&quot;
17520             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17521   ins_encode %{
17522     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17523             as_FloatRegister($shift$$reg));
17524     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17525             as_FloatRegister($src$$reg),
17526             as_FloatRegister($tmp$$reg));
17527   %}
17528   ins_pipe(vshift64);
17529 %}
17530 
17531 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17532   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17533   match(Set dst (RShiftVS src shift));
17534   ins_cost(INSN_COST);
17535   effect(TEMP tmp);
17536   format %{ &quot;negr  $tmp,$shift\t&quot;
17537             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17538   ins_encode %{
17539     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17540             as_FloatRegister($shift$$reg));
17541     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17542             as_FloatRegister($src$$reg),
17543             as_FloatRegister($tmp$$reg));
17544   %}
17545   ins_pipe(vshift128);
17546 %}
17547 
17548 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17549   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17550             n-&gt;as_Vector()-&gt;length() == 4);
17551   match(Set dst (URShiftVS src shift));
17552   ins_cost(INSN_COST);
17553   effect(TEMP tmp);
17554   format %{ &quot;negr  $tmp,$shift\t&quot;
17555             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17556   ins_encode %{
17557     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17558             as_FloatRegister($shift$$reg));
17559     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17560             as_FloatRegister($src$$reg),
17561             as_FloatRegister($tmp$$reg));
17562   %}
17563   ins_pipe(vshift64);
17564 %}
17565 
17566 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17567   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17568   match(Set dst (URShiftVS src shift));
17569   ins_cost(INSN_COST);
17570   effect(TEMP tmp);
17571   format %{ &quot;negr  $tmp,$shift\t&quot;
17572             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17573   ins_encode %{
17574     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17575             as_FloatRegister($shift$$reg));
17576     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17577             as_FloatRegister($src$$reg),
17578             as_FloatRegister($tmp$$reg));
17579   %}
17580   ins_pipe(vshift128);
17581 %}
17582 
17583 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17584   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17585             n-&gt;as_Vector()-&gt;length() == 4);
17586   match(Set dst (LShiftVS src (LShiftCntV shift)));
17587   ins_cost(INSN_COST);
17588   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17589   ins_encode %{
17590     int sh = (int)$shift$$constant;
17591     if (sh &gt;= 16) {
17592       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17593              as_FloatRegister($src$$reg),
17594              as_FloatRegister($src$$reg));
17595     } else {
17596       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17597              as_FloatRegister($src$$reg), sh);
17598     }
17599   %}
17600   ins_pipe(vshift64_imm);
17601 %}
17602 
17603 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17604   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17605   match(Set dst (LShiftVS src (LShiftCntV shift)));
17606   ins_cost(INSN_COST);
17607   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17608   ins_encode %{
17609     int sh = (int)$shift$$constant;
17610     if (sh &gt;= 16) {
17611       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17612              as_FloatRegister($src$$reg),
17613              as_FloatRegister($src$$reg));
17614     } else {
17615       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17616              as_FloatRegister($src$$reg), sh);
17617     }
17618   %}
17619   ins_pipe(vshift128_imm);
17620 %}
17621 
17622 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17623   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17624             n-&gt;as_Vector()-&gt;length() == 4);
17625   match(Set dst (RShiftVS src (LShiftCntV shift)));
17626   ins_cost(INSN_COST);
17627   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17628   ins_encode %{
17629     int sh = (int)$shift$$constant;
17630     if (sh &gt;= 16) sh = 15;
17631     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17632            as_FloatRegister($src$$reg), sh);
17633   %}
17634   ins_pipe(vshift64_imm);
17635 %}
17636 
17637 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17638   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17639   match(Set dst (RShiftVS src (LShiftCntV shift)));
17640   ins_cost(INSN_COST);
17641   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17642   ins_encode %{
17643     int sh = (int)$shift$$constant;
17644     if (sh &gt;= 16) sh = 15;
17645     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17646            as_FloatRegister($src$$reg), sh);
17647   %}
17648   ins_pipe(vshift128_imm);
17649 %}
17650 
17651 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17652   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17653             n-&gt;as_Vector()-&gt;length() == 4);
17654   match(Set dst (URShiftVS src (RShiftCntV shift)));
17655   ins_cost(INSN_COST);
17656   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17657   ins_encode %{
17658     int sh = (int)$shift$$constant;
17659     if (sh &gt;= 16) {
17660       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17661              as_FloatRegister($src$$reg),
17662              as_FloatRegister($src$$reg));
17663     } else {
17664       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17665              as_FloatRegister($src$$reg), sh);
17666     }
17667   %}
17668   ins_pipe(vshift64_imm);
17669 %}
17670 
17671 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17672   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17673   match(Set dst (URShiftVS src (RShiftCntV shift)));
17674   ins_cost(INSN_COST);
17675   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17676   ins_encode %{
17677     int sh = (int)$shift$$constant;
17678     if (sh &gt;= 16) {
17679       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17680              as_FloatRegister($src$$reg),
17681              as_FloatRegister($src$$reg));
17682     } else {
17683       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17684              as_FloatRegister($src$$reg), sh);
17685     }
17686   %}
17687   ins_pipe(vshift128_imm);
17688 %}
17689 
17690 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17691   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17692   match(Set dst (LShiftVI src shift));
17693   ins_cost(INSN_COST);
17694   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17695   ins_encode %{
17696     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17697             as_FloatRegister($src$$reg),
17698             as_FloatRegister($shift$$reg));
17699   %}
17700   ins_pipe(vshift64);
17701 %}
17702 
17703 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17704   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17705   match(Set dst (LShiftVI src shift));
17706   ins_cost(INSN_COST);
17707   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17708   ins_encode %{
17709     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17710             as_FloatRegister($src$$reg),
17711             as_FloatRegister($shift$$reg));
17712   %}
17713   ins_pipe(vshift128);
17714 %}
17715 
17716 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17717   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17718   match(Set dst (RShiftVI src shift));
17719   ins_cost(INSN_COST);
17720   effect(TEMP tmp);
17721   format %{ &quot;negr  $tmp,$shift\t&quot;
17722             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17723   ins_encode %{
17724     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17725             as_FloatRegister($shift$$reg));
17726     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17727             as_FloatRegister($src$$reg),
17728             as_FloatRegister($tmp$$reg));
17729   %}
17730   ins_pipe(vshift64);
17731 %}
17732 
17733 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17734   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17735   match(Set dst (RShiftVI src shift));
17736   ins_cost(INSN_COST);
17737   effect(TEMP tmp);
17738   format %{ &quot;negr  $tmp,$shift\t&quot;
17739             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17740   ins_encode %{
17741     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17742             as_FloatRegister($shift$$reg));
17743     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17744             as_FloatRegister($src$$reg),
17745             as_FloatRegister($tmp$$reg));
17746   %}
17747   ins_pipe(vshift128);
17748 %}
17749 
17750 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17751   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17752   match(Set dst (URShiftVI src shift));
17753   ins_cost(INSN_COST);
17754   effect(TEMP tmp);
17755   format %{ &quot;negr  $tmp,$shift\t&quot;
17756             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17757   ins_encode %{
17758     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17759             as_FloatRegister($shift$$reg));
17760     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17761             as_FloatRegister($src$$reg),
17762             as_FloatRegister($tmp$$reg));
17763   %}
17764   ins_pipe(vshift64);
17765 %}
17766 
17767 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17768   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17769   match(Set dst (URShiftVI src shift));
17770   ins_cost(INSN_COST);
17771   effect(TEMP tmp);
17772   format %{ &quot;negr  $tmp,$shift\t&quot;
17773             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17774   ins_encode %{
17775     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17776             as_FloatRegister($shift$$reg));
17777     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17778             as_FloatRegister($src$$reg),
17779             as_FloatRegister($tmp$$reg));
17780   %}
17781   ins_pipe(vshift128);
17782 %}
17783 
17784 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17785   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17786   match(Set dst (LShiftVI src (LShiftCntV shift)));
17787   ins_cost(INSN_COST);
17788   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17789   ins_encode %{
17790     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17791            as_FloatRegister($src$$reg),
17792            (int)$shift$$constant);
17793   %}
17794   ins_pipe(vshift64_imm);
17795 %}
17796 
17797 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17798   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17799   match(Set dst (LShiftVI src (LShiftCntV shift)));
17800   ins_cost(INSN_COST);
17801   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17802   ins_encode %{
17803     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17804            as_FloatRegister($src$$reg),
17805            (int)$shift$$constant);
17806   %}
17807   ins_pipe(vshift128_imm);
17808 %}
17809 
17810 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17811   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17812   match(Set dst (RShiftVI src (RShiftCntV shift)));
17813   ins_cost(INSN_COST);
17814   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17815   ins_encode %{
17816     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17817             as_FloatRegister($src$$reg),
17818             (int)$shift$$constant);
17819   %}
17820   ins_pipe(vshift64_imm);
17821 %}
17822 
17823 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17824   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17825   match(Set dst (RShiftVI src (RShiftCntV shift)));
17826   ins_cost(INSN_COST);
17827   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17828   ins_encode %{
17829     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17830             as_FloatRegister($src$$reg),
17831             (int)$shift$$constant);
17832   %}
17833   ins_pipe(vshift128_imm);
17834 %}
17835 
17836 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17837   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17838   match(Set dst (URShiftVI src (RShiftCntV shift)));
17839   ins_cost(INSN_COST);
17840   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17841   ins_encode %{
17842     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17843             as_FloatRegister($src$$reg),
17844             (int)$shift$$constant);
17845   %}
17846   ins_pipe(vshift64_imm);
17847 %}
17848 
17849 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17850   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17851   match(Set dst (URShiftVI src (RShiftCntV shift)));
17852   ins_cost(INSN_COST);
17853   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17854   ins_encode %{
17855     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17856             as_FloatRegister($src$$reg),
17857             (int)$shift$$constant);
17858   %}
17859   ins_pipe(vshift128_imm);
17860 %}
17861 
17862 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17863   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17864   match(Set dst (LShiftVL src shift));
17865   ins_cost(INSN_COST);
17866   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17867   ins_encode %{
17868     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17869             as_FloatRegister($src$$reg),
17870             as_FloatRegister($shift$$reg));
17871   %}
17872   ins_pipe(vshift128);
17873 %}
17874 
17875 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17876   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17877   match(Set dst (RShiftVL src shift));
17878   ins_cost(INSN_COST);
17879   effect(TEMP tmp);
17880   format %{ &quot;negr  $tmp,$shift\t&quot;
17881             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17882   ins_encode %{
17883     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17884             as_FloatRegister($shift$$reg));
17885     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17886             as_FloatRegister($src$$reg),
17887             as_FloatRegister($tmp$$reg));
17888   %}
17889   ins_pipe(vshift128);
17890 %}
17891 
17892 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17893   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17894   match(Set dst (URShiftVL src shift));
17895   ins_cost(INSN_COST);
17896   effect(TEMP tmp);
17897   format %{ &quot;negr  $tmp,$shift\t&quot;
17898             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17899   ins_encode %{
17900     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17901             as_FloatRegister($shift$$reg));
17902     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17903             as_FloatRegister($src$$reg),
17904             as_FloatRegister($tmp$$reg));
17905   %}
17906   ins_pipe(vshift128);
17907 %}
17908 
17909 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17910   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17911   match(Set dst (LShiftVL src (LShiftCntV shift)));
17912   ins_cost(INSN_COST);
17913   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17914   ins_encode %{
17915     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17916            as_FloatRegister($src$$reg),
17917            (int)$shift$$constant);
17918   %}
17919   ins_pipe(vshift128_imm);
17920 %}
17921 
17922 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17923   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17924   match(Set dst (RShiftVL src (RShiftCntV shift)));
17925   ins_cost(INSN_COST);
17926   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17927   ins_encode %{
17928     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17929             as_FloatRegister($src$$reg),
17930             (int)$shift$$constant);
17931   %}
17932   ins_pipe(vshift128_imm);
17933 %}
17934 
17935 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17936   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17937   match(Set dst (URShiftVL src (RShiftCntV shift)));
17938   ins_cost(INSN_COST);
17939   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17940   ins_encode %{
17941     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17942             as_FloatRegister($src$$reg),
17943             (int)$shift$$constant);
17944   %}
17945   ins_pipe(vshift128_imm);
17946 %}
17947 
17948 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17949 %{
17950   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17951   match(Set dst (MaxV src1 src2));
17952   ins_cost(INSN_COST);
17953   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17954   ins_encode %{
17955     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17956             as_FloatRegister($src1$$reg),
17957             as_FloatRegister($src2$$reg));
17958   %}
17959   ins_pipe(vdop_fp64);
17960 %}
17961 
17962 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17963 %{
17964   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17965   match(Set dst (MaxV src1 src2));
17966   ins_cost(INSN_COST);
17967   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17968   ins_encode %{
17969     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17970             as_FloatRegister($src1$$reg),
17971             as_FloatRegister($src2$$reg));
17972   %}
17973   ins_pipe(vdop_fp128);
17974 %}
17975 
17976 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17977 %{
17978   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17979   match(Set dst (MaxV src1 src2));
17980   ins_cost(INSN_COST);
17981   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17982   ins_encode %{
17983     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17984             as_FloatRegister($src1$$reg),
17985             as_FloatRegister($src2$$reg));
17986   %}
17987   ins_pipe(vdop_fp128);
17988 %}
17989 
17990 instruct vmin2F(vecD dst, vecD src1, vecD src2)
17991 %{
17992   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17993   match(Set dst (MinV src1 src2));
17994   ins_cost(INSN_COST);
17995   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
17996   ins_encode %{
17997     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
17998             as_FloatRegister($src1$$reg),
17999             as_FloatRegister($src2$$reg));
18000   %}
18001   ins_pipe(vdop_fp64);
18002 %}
18003 
18004 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18005 %{
18006   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18007   match(Set dst (MinV src1 src2));
18008   ins_cost(INSN_COST);
18009   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18010   ins_encode %{
18011     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18012             as_FloatRegister($src1$$reg),
18013             as_FloatRegister($src2$$reg));
18014   %}
18015   ins_pipe(vdop_fp128);
18016 %}
18017 
18018 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18019 %{
18020   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18021   match(Set dst (MinV src1 src2));
18022   ins_cost(INSN_COST);
18023   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18024   ins_encode %{
18025     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18026             as_FloatRegister($src1$$reg),
18027             as_FloatRegister($src2$$reg));
18028   %}
18029   ins_pipe(vdop_fp128);
18030 %}
18031 
18032 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18033   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18034   match(Set dst (RoundDoubleModeV src rmode));
18035   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18036   ins_encode %{
18037     switch ($rmode$$constant) {
18038       case RoundDoubleModeNode::rmode_rint:
18039         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18040                   as_FloatRegister($src$$reg));
18041         break;
18042       case RoundDoubleModeNode::rmode_floor:
18043         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18044                   as_FloatRegister($src$$reg));
18045         break;
18046       case RoundDoubleModeNode::rmode_ceil:
18047         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18048                   as_FloatRegister($src$$reg));
18049         break;
18050     }
18051   %}
18052   ins_pipe(vdop_fp128);
18053 %}
18054 
18055 instruct vpopcount4I(vecX dst, vecX src) %{
18056   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18057   match(Set dst (PopCountVI src));
18058   format %{
18059     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18060     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18061     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18062   %}
18063   ins_encode %{
18064      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18065             as_FloatRegister($src$$reg));
18066      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18067                as_FloatRegister($dst$$reg));
18068      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18069                as_FloatRegister($dst$$reg));
18070   %}
18071   ins_pipe(pipe_class_default);
18072 %}
18073 
18074 instruct vpopcount2I(vecD dst, vecD src) %{
18075   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18076   match(Set dst (PopCountVI src));
18077   format %{
18078     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18079     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18080     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18081   %}
18082   ins_encode %{
18083      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18084             as_FloatRegister($src$$reg));
18085      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18086                as_FloatRegister($dst$$reg));
18087      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18088                as_FloatRegister($dst$$reg));
18089   %}
18090   ins_pipe(pipe_class_default);
18091 %}
18092 
18093 //----------PEEPHOLE RULES-----------------------------------------------------
18094 // These must follow all instruction definitions as they use the names
18095 // defined in the instructions definitions.
18096 //
18097 // peepmatch ( root_instr_name [preceding_instruction]* );
18098 //
18099 // peepconstraint %{
18100 // (instruction_number.operand_name relational_op instruction_number.operand_name
18101 //  [, ...] );
18102 // // instruction numbers are zero-based using left to right order in peepmatch
18103 //
18104 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18105 // // provide an instruction_number.operand_name for each operand that appears
18106 // // in the replacement instruction&#39;s match rule
18107 //
18108 // ---------VM FLAGS---------------------------------------------------------
18109 //
18110 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18111 //
18112 // Each peephole rule is given an identifying number starting with zero and
18113 // increasing by one in the order seen by the parser.  An individual peephole
18114 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18115 // on the command-line.
18116 //
18117 // ---------CURRENT LIMITATIONS----------------------------------------------
18118 //
18119 // Only match adjacent instructions in same basic block
18120 // Only equality constraints
18121 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18122 // Only one replacement instruction
18123 //
18124 // ---------EXAMPLE----------------------------------------------------------
18125 //
18126 // // pertinent parts of existing instructions in architecture description
18127 // instruct movI(iRegINoSp dst, iRegI src)
18128 // %{
18129 //   match(Set dst (CopyI src));
18130 // %}
18131 //
18132 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18133 // %{
18134 //   match(Set dst (AddI dst src));
18135 //   effect(KILL cr);
18136 // %}
18137 //
18138 // // Change (inc mov) to lea
18139 // peephole %{
18140 //   // increment preceeded by register-register move
18141 //   peepmatch ( incI_iReg movI );
18142 //   // require that the destination register of the increment
18143 //   // match the destination register of the move
18144 //   peepconstraint ( 0.dst == 1.dst );
18145 //   // construct a replacement instruction that sets
18146 //   // the destination to ( move&#39;s source register + one )
18147 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18148 // %}
18149 //
18150 
18151 // Implementation no longer uses movX instructions since
18152 // machine-independent system no longer uses CopyX nodes.
18153 //
18154 // peephole
18155 // %{
18156 //   peepmatch (incI_iReg movI);
18157 //   peepconstraint (0.dst == 1.dst);
18158 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18159 // %}
18160 
18161 // peephole
18162 // %{
18163 //   peepmatch (decI_iReg movI);
18164 //   peepconstraint (0.dst == 1.dst);
18165 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18166 // %}
18167 
18168 // peephole
18169 // %{
18170 //   peepmatch (addI_iReg_imm movI);
18171 //   peepconstraint (0.dst == 1.dst);
18172 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18173 // %}
18174 
18175 // peephole
18176 // %{
18177 //   peepmatch (incL_iReg movL);
18178 //   peepconstraint (0.dst == 1.dst);
18179 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18180 // %}
18181 
18182 // peephole
18183 // %{
18184 //   peepmatch (decL_iReg movL);
18185 //   peepconstraint (0.dst == 1.dst);
18186 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18187 // %}
18188 
18189 // peephole
18190 // %{
18191 //   peepmatch (addL_iReg_imm movL);
18192 //   peepconstraint (0.dst == 1.dst);
18193 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18194 // %}
18195 
18196 // peephole
18197 // %{
18198 //   peepmatch (addP_iReg_imm movP);
18199 //   peepconstraint (0.dst == 1.dst);
18200 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18201 // %}
18202 
18203 // // Change load of spilled value to only a spill
18204 // instruct storeI(memory mem, iRegI src)
18205 // %{
18206 //   match(Set mem (StoreI mem src));
18207 // %}
18208 //
18209 // instruct loadI(iRegINoSp dst, memory mem)
18210 // %{
18211 //   match(Set dst (LoadI mem));
18212 // %}
18213 //
18214 
18215 //----------SMARTSPILL RULES---------------------------------------------------
18216 // These must follow all instruction definitions as they use the names
18217 // defined in the instructions definitions.
18218 
18219 // Local Variables:
18220 // mode: c++
18221 // End:
    </pre>
  </body>
</html>