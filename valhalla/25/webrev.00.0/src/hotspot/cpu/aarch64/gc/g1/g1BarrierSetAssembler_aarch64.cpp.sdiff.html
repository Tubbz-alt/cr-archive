<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/gc/g1/g1BarrierSetAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
<body>
<center><a href="../../frame_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../index.html" target="_top">index</a> <a href="../../interp_masm_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/gc/g1/g1BarrierSetAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 30 #include &quot;gc/g1/g1CardTable.hpp&quot;
 31 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
 32 #include &quot;gc/g1/heapRegion.hpp&quot;
 33 #include &quot;gc/shared/collectedHeap.hpp&quot;
 34 #include &quot;runtime/sharedRuntime.hpp&quot;
 35 #include &quot;runtime/thread.hpp&quot;
 36 #include &quot;interpreter/interp_masm.hpp&quot;
 37 #include &quot;runtime/sharedRuntime.hpp&quot;
 38 #ifdef COMPILER1
 39 #include &quot;c1/c1_LIRAssembler.hpp&quot;
 40 #include &quot;c1/c1_MacroAssembler.hpp&quot;
 41 #include &quot;gc/g1/c1/g1BarrierSetC1.hpp&quot;
 42 #endif
 43 
 44 #define __ masm-&gt;
 45 
 46 void G1BarrierSetAssembler::gen_write_ref_array_pre_barrier(MacroAssembler* masm, DecoratorSet decorators,
 47                                                             Register addr, Register count, RegSet saved_regs) {
 48   bool dest_uninitialized = (decorators &amp; IS_DEST_UNINITIALIZED) != 0;
 49   if (!dest_uninitialized) {












 50     __ push(saved_regs, sp);
 51     if (count == c_rarg0) {
 52       if (addr == c_rarg1) {
 53         // exactly backwards!!
 54         __ mov(rscratch1, c_rarg0);
 55         __ mov(c_rarg0, c_rarg1);
 56         __ mov(c_rarg1, rscratch1);
 57       } else {
 58         __ mov(c_rarg1, count);
 59         __ mov(c_rarg0, addr);
 60       }
 61     } else {
 62       __ mov(c_rarg0, addr);
 63       __ mov(c_rarg1, count);
 64     }
 65     if (UseCompressedOops) {
 66       __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_pre_narrow_oop_entry), 2);
 67     } else {
 68       __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_pre_oop_entry), 2);
 69     }
 70     __ pop(saved_regs, sp);


 71   }
 72 }
 73 
 74 void G1BarrierSetAssembler::gen_write_ref_array_post_barrier(MacroAssembler* masm, DecoratorSet decorators,
 75                                                              Register start, Register count, Register scratch, RegSet saved_regs) {
 76   __ push(saved_regs, sp);
 77   assert_different_registers(start, count, scratch);
 78   assert_different_registers(c_rarg0, count);
 79   __ mov(c_rarg0, start);
 80   __ mov(c_rarg1, count);
 81   __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_post_entry), 2);
 82   __ pop(saved_regs, sp);
 83 }
 84 
 85 void G1BarrierSetAssembler::g1_write_barrier_pre(MacroAssembler* masm,
 86                                                  Register obj,
 87                                                  Register pre_val,
 88                                                  Register thread,
 89                                                  Register tmp,
 90                                                  bool tosca_live,
</pre>
<hr />
<pre>
285 
286    if (tmp3 == noreg) {
287      tmp3 = rscratch2;
288    }
289    // assert_different_registers(val, tmp1, tmp2, tmp3, rscratch1, rscratch2);
290    assert_different_registers(val, tmp1, tmp2, tmp3);
291 
292   // flatten object address if needed
293   if (dst.index() == noreg &amp;&amp; dst.offset() == 0) {
294     if (dst.base() != tmp1) {
295       __ mov(tmp1, dst.base());
296     }
297   } else {
298     __ lea(tmp1, dst);
299   }
300 
301 
302   if (needs_pre_barrier) {
303       g1_write_barrier_pre(masm,
304                        tmp1 /* obj */,
<span class="line-modified">305                        tmp2 /* pre_val */,  </span>
306                        rthread /* thread */,
307                        tmp3  /* tmp */,
308                        val != noreg /* tosca_live */,
309                        false /* expand_call */);
310   }
311 
312   if (val == noreg) {
313     BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), noreg, noreg, noreg, noreg);
314   } else {
315     // G1 barrier needs uncompressed oop for region cross check.
316     Register new_val = val;
317     if (needs_post_barrier) {
<span class="line-modified">318       if (UseCompressedOops) { </span>
319         // FIXME: Refactor the code to avoid usage of r19 and stay within tmpX
320         new_val = r19;
321         __ mov(new_val, val);
322       }
323    }
324 
325    BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg, noreg);
326 
327     if (needs_post_barrier) {
328        g1_write_barrier_post(masm,
329                           tmp1 /* store_adr */,
330                           new_val /* new_val */,
331                           rthread /* thread */,
332                           tmp2 /* tmp */,
333                           tmp3 /* tmp2 */);
334    }
335  }
336 
337 }
338 
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
</pre>
<hr />
<pre>
 30 #include &quot;gc/g1/g1CardTable.hpp&quot;
 31 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
 32 #include &quot;gc/g1/heapRegion.hpp&quot;
 33 #include &quot;gc/shared/collectedHeap.hpp&quot;
 34 #include &quot;runtime/sharedRuntime.hpp&quot;
 35 #include &quot;runtime/thread.hpp&quot;
 36 #include &quot;interpreter/interp_masm.hpp&quot;
 37 #include &quot;runtime/sharedRuntime.hpp&quot;
 38 #ifdef COMPILER1
 39 #include &quot;c1/c1_LIRAssembler.hpp&quot;
 40 #include &quot;c1/c1_MacroAssembler.hpp&quot;
 41 #include &quot;gc/g1/c1/g1BarrierSetC1.hpp&quot;
 42 #endif
 43 
 44 #define __ masm-&gt;
 45 
 46 void G1BarrierSetAssembler::gen_write_ref_array_pre_barrier(MacroAssembler* masm, DecoratorSet decorators,
 47                                                             Register addr, Register count, RegSet saved_regs) {
 48   bool dest_uninitialized = (decorators &amp; IS_DEST_UNINITIALIZED) != 0;
 49   if (!dest_uninitialized) {
<span class="line-added"> 50     Label done;</span>
<span class="line-added"> 51     Address in_progress(rthread, in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset()));</span>
<span class="line-added"> 52 </span>
<span class="line-added"> 53     // Is marking active?</span>
<span class="line-added"> 54     if (in_bytes(SATBMarkQueue::byte_width_of_active()) == 4) {</span>
<span class="line-added"> 55       __ ldrw(rscratch1, in_progress);</span>
<span class="line-added"> 56     } else {</span>
<span class="line-added"> 57       assert(in_bytes(SATBMarkQueue::byte_width_of_active()) == 1, &quot;Assumption&quot;);</span>
<span class="line-added"> 58       __ ldrb(rscratch1, in_progress);</span>
<span class="line-added"> 59     }</span>
<span class="line-added"> 60     __ cbzw(rscratch1, done);</span>
<span class="line-added"> 61 </span>
 62     __ push(saved_regs, sp);
 63     if (count == c_rarg0) {
 64       if (addr == c_rarg1) {
 65         // exactly backwards!!
 66         __ mov(rscratch1, c_rarg0);
 67         __ mov(c_rarg0, c_rarg1);
 68         __ mov(c_rarg1, rscratch1);
 69       } else {
 70         __ mov(c_rarg1, count);
 71         __ mov(c_rarg0, addr);
 72       }
 73     } else {
 74       __ mov(c_rarg0, addr);
 75       __ mov(c_rarg1, count);
 76     }
 77     if (UseCompressedOops) {
 78       __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_pre_narrow_oop_entry), 2);
 79     } else {
 80       __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_pre_oop_entry), 2);
 81     }
 82     __ pop(saved_regs, sp);
<span class="line-added"> 83 </span>
<span class="line-added"> 84     __ bind(done);</span>
 85   }
 86 }
 87 
 88 void G1BarrierSetAssembler::gen_write_ref_array_post_barrier(MacroAssembler* masm, DecoratorSet decorators,
 89                                                              Register start, Register count, Register scratch, RegSet saved_regs) {
 90   __ push(saved_regs, sp);
 91   assert_different_registers(start, count, scratch);
 92   assert_different_registers(c_rarg0, count);
 93   __ mov(c_rarg0, start);
 94   __ mov(c_rarg1, count);
 95   __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_post_entry), 2);
 96   __ pop(saved_regs, sp);
 97 }
 98 
 99 void G1BarrierSetAssembler::g1_write_barrier_pre(MacroAssembler* masm,
100                                                  Register obj,
101                                                  Register pre_val,
102                                                  Register thread,
103                                                  Register tmp,
104                                                  bool tosca_live,
</pre>
<hr />
<pre>
299 
300    if (tmp3 == noreg) {
301      tmp3 = rscratch2;
302    }
303    // assert_different_registers(val, tmp1, tmp2, tmp3, rscratch1, rscratch2);
304    assert_different_registers(val, tmp1, tmp2, tmp3);
305 
306   // flatten object address if needed
307   if (dst.index() == noreg &amp;&amp; dst.offset() == 0) {
308     if (dst.base() != tmp1) {
309       __ mov(tmp1, dst.base());
310     }
311   } else {
312     __ lea(tmp1, dst);
313   }
314 
315 
316   if (needs_pre_barrier) {
317       g1_write_barrier_pre(masm,
318                        tmp1 /* obj */,
<span class="line-modified">319                        tmp2 /* pre_val */,</span>
320                        rthread /* thread */,
321                        tmp3  /* tmp */,
322                        val != noreg /* tosca_live */,
323                        false /* expand_call */);
324   }
325 
326   if (val == noreg) {
327     BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), noreg, noreg, noreg, noreg);
328   } else {
329     // G1 barrier needs uncompressed oop for region cross check.
330     Register new_val = val;
331     if (needs_post_barrier) {
<span class="line-modified">332       if (UseCompressedOops) {</span>
333         // FIXME: Refactor the code to avoid usage of r19 and stay within tmpX
334         new_val = r19;
335         __ mov(new_val, val);
336       }
337    }
338 
339    BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), val, noreg, noreg, noreg);
340 
341     if (needs_post_barrier) {
342        g1_write_barrier_post(masm,
343                           tmp1 /* store_adr */,
344                           new_val /* new_val */,
345                           rthread /* thread */,
346                           tmp2 /* tmp */,
347                           tmp3 /* tmp2 */);
348    }
349  }
350 
351 }
352 
</pre>
</td>
</tr>
</table>
<center><a href="../../frame_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../index.html" target="_top">index</a> <a href="../../interp_masm_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>