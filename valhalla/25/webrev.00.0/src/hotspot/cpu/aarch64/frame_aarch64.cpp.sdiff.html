<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/frame_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="c1_LIRAssembler_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="gc/g1/g1BarrierSetAssembler_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/frame_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 59   address   unextended_sp = (address)_unextended_sp;
 60 
 61   // consider stack guards when trying to determine &quot;safe&quot; stack pointers
 62   // sp must be within the usable part of the stack (not in guards)
 63   if (!thread-&gt;is_in_usable_stack(sp)) {
 64     return false;
 65   }
 66 
 67   // When we are running interpreted code the machine stack pointer, SP, is
 68   // set low enough so that the Java expression stack can grow and shrink
 69   // without ever exceeding the machine stack bounds.  So, ESP &gt;= SP.
 70 
 71   // When we call out of an interpreted method, SP is incremented so that
 72   // the space between SP and ESP is removed.  The SP saved in the callee&#39;s
 73   // frame is the SP *before* this increment.  So, when we walk a stack of
 74   // interpreter frames the sender&#39;s SP saved in a frame might be less than
 75   // the SP at the point of call.
 76 
 77   // So unextended sp must be within the stack but we need not to check
 78   // that unextended sp &gt;= sp
<span class="line-modified"> 79   if (!thread-&gt;is_in_full_stack(unextended_sp)) {</span>
 80     return false;
 81   }
 82 
 83   // an fp must be within the stack and above (but not equal) sp
 84   // second evaluation on fp+ is added to handle situation where fp is -1
 85   bool fp_safe = thread-&gt;is_in_stack_range_excl(fp, sp) &amp;&amp;
<span class="line-modified"> 86                  thread-&gt;is_in_full_stack(fp + (return_addr_offset * sizeof(void*)));</span>
 87 
 88   // We know sp/unextended_sp are safe only fp is questionable here
 89 
 90   // If the current frame is known to the code cache then we can attempt to
 91   // to construct the sender and do some validation of it. This goes a long way
 92   // toward eliminating issues when we get in frame construction code
 93 
 94   if (_cb != NULL ) {
 95 
 96     // First check if frame is complete and tester is reliable
 97     // Unfortunately we can only check frame complete for runtime stubs and nmethod
 98     // other generic buffer blobs are more problematic so we just assume they are
 99     // ok. adapter blobs never have a frame complete and are never ok.
100 
101     if (!_cb-&gt;is_frame_complete_at(_pc)) {
102       if (_cb-&gt;is_nmethod() || _cb-&gt;is_adapter_blob() || _cb-&gt;is_runtime_stub()) {
103         return false;
104       }
105     }
106 
</pre>
<hr />
<pre>
128 
129       sender_pc = (address) this-&gt;fp()[return_addr_offset];
130       // for interpreted frames, the value below is the sender &quot;raw&quot; sp,
131       // which can be different from the sender unextended sp (the sp seen
132       // by the sender) because of current frame local variables
133       sender_sp = (intptr_t*) addr_at(sender_sp_offset);
134       sender_unextended_sp = (intptr_t*) this-&gt;fp()[interpreter_frame_sender_sp_offset];
135       saved_fp = (intptr_t*) this-&gt;fp()[link_offset];
136 
137     } else {
138       // must be some sort of compiled/runtime frame
139       // fp does not have to be safe (although it could be check for c1?)
140 
141       // check for a valid frame_size, otherwise we are unlikely to get a valid sender_pc
142       if (_cb-&gt;frame_size() &lt;= 0) {
143         return false;
144       }
145 
146       sender_sp = _unextended_sp + _cb-&gt;frame_size();
147       // Is sender_sp safe?
<span class="line-modified">148       if (!thread-&gt;is_in_full_stack((address)sender_sp)) {</span>
149         return false;
150       }
151       sender_unextended_sp = sender_sp;
152       sender_pc = (address) *(sender_sp-1);
153       // Note: frame::sender_sp_offset is only valid for compiled frame
154       saved_fp = (intptr_t*) *(sender_sp - frame::sender_sp_offset);
155     }
156 
157 
158     // If the potential sender is the interpreter then we can do some more checking
159     if (Interpreter::contains(sender_pc)) {
160 
161       // fp is always saved in a recognizable place in any code we generate. However
162       // only if the sender is interpreted/call_stub (c1 too?) are we certain that the saved fp
163       // is really a frame pointer.
164 
165       if (!thread-&gt;is_in_stack_range_excl((address)saved_fp, (address)sender_sp)) {
166         return false;
167       }
168 
</pre>
<hr />
<pre>
247 
248   // Must be native-compiled frame. Since sender will try and use fp to find
249   // linkages it must be safe
250 
251   if (!fp_safe) {
252     return false;
253   }
254 
255   // Will the pc we fetch be non-zero (which we&#39;ll find at the oldest frame)
256 
257   if ( (address) this-&gt;fp()[return_addr_offset] == NULL) return false;
258 
259 
260   // could try and do some more potential verification of native frame if we could think of some...
261 
262   return true;
263 
264 }
265 
266 void frame::patch_pc(Thread* thread, address pc) {

267   address* pc_addr = &amp;(((address*) sp())[-1]);
268   if (TracePcPatching) {
269     tty-&gt;print_cr(&quot;patch_pc at address &quot; INTPTR_FORMAT &quot; [&quot; INTPTR_FORMAT &quot; -&gt; &quot; INTPTR_FORMAT &quot;]&quot;,
270                   p2i(pc_addr), p2i(*pc_addr), p2i(pc));
271   }
272   // Either the return address is the original one or we are going to
273   // patch in the same address that&#39;s already there.
274   assert(_pc == *pc_addr || pc == *pc_addr, &quot;must be&quot;);
275   *pc_addr = pc;
<span class="line-removed">276   _cb = CodeCache::find_blob(pc);</span>
277   address original_pc = CompiledMethod::get_deopt_original_pc(this);
278   if (original_pc != NULL) {
279     assert(original_pc == _pc, &quot;expected original PC to be stored before patching&quot;);
280     _deopt_state = is_deoptimized;
281     // leave _pc as is
282   } else {
283     _deopt_state = not_deoptimized;
284     _pc = pc;
285   }
286 }
287 
288 bool frame::is_interpreted_frame() const  {
289   return Interpreter::contains(pc());
290 }
291 
292 int frame::frame_size(RegisterMap* map) const {
293   frame sender = this-&gt;sender(map);
294   return sender.sp() - sp();
295 }
296 
</pre>
</td>
<td>
<hr />
<pre>
 59   address   unextended_sp = (address)_unextended_sp;
 60 
 61   // consider stack guards when trying to determine &quot;safe&quot; stack pointers
 62   // sp must be within the usable part of the stack (not in guards)
 63   if (!thread-&gt;is_in_usable_stack(sp)) {
 64     return false;
 65   }
 66 
 67   // When we are running interpreted code the machine stack pointer, SP, is
 68   // set low enough so that the Java expression stack can grow and shrink
 69   // without ever exceeding the machine stack bounds.  So, ESP &gt;= SP.
 70 
 71   // When we call out of an interpreted method, SP is incremented so that
 72   // the space between SP and ESP is removed.  The SP saved in the callee&#39;s
 73   // frame is the SP *before* this increment.  So, when we walk a stack of
 74   // interpreter frames the sender&#39;s SP saved in a frame might be less than
 75   // the SP at the point of call.
 76 
 77   // So unextended sp must be within the stack but we need not to check
 78   // that unextended sp &gt;= sp
<span class="line-modified"> 79   if (!thread-&gt;is_in_full_stack_checked(unextended_sp)) {</span>
 80     return false;
 81   }
 82 
 83   // an fp must be within the stack and above (but not equal) sp
 84   // second evaluation on fp+ is added to handle situation where fp is -1
 85   bool fp_safe = thread-&gt;is_in_stack_range_excl(fp, sp) &amp;&amp;
<span class="line-modified"> 86                  thread-&gt;is_in_full_stack_checked(fp + (return_addr_offset * sizeof(void*)));</span>
 87 
 88   // We know sp/unextended_sp are safe only fp is questionable here
 89 
 90   // If the current frame is known to the code cache then we can attempt to
 91   // to construct the sender and do some validation of it. This goes a long way
 92   // toward eliminating issues when we get in frame construction code
 93 
 94   if (_cb != NULL ) {
 95 
 96     // First check if frame is complete and tester is reliable
 97     // Unfortunately we can only check frame complete for runtime stubs and nmethod
 98     // other generic buffer blobs are more problematic so we just assume they are
 99     // ok. adapter blobs never have a frame complete and are never ok.
100 
101     if (!_cb-&gt;is_frame_complete_at(_pc)) {
102       if (_cb-&gt;is_nmethod() || _cb-&gt;is_adapter_blob() || _cb-&gt;is_runtime_stub()) {
103         return false;
104       }
105     }
106 
</pre>
<hr />
<pre>
128 
129       sender_pc = (address) this-&gt;fp()[return_addr_offset];
130       // for interpreted frames, the value below is the sender &quot;raw&quot; sp,
131       // which can be different from the sender unextended sp (the sp seen
132       // by the sender) because of current frame local variables
133       sender_sp = (intptr_t*) addr_at(sender_sp_offset);
134       sender_unextended_sp = (intptr_t*) this-&gt;fp()[interpreter_frame_sender_sp_offset];
135       saved_fp = (intptr_t*) this-&gt;fp()[link_offset];
136 
137     } else {
138       // must be some sort of compiled/runtime frame
139       // fp does not have to be safe (although it could be check for c1?)
140 
141       // check for a valid frame_size, otherwise we are unlikely to get a valid sender_pc
142       if (_cb-&gt;frame_size() &lt;= 0) {
143         return false;
144       }
145 
146       sender_sp = _unextended_sp + _cb-&gt;frame_size();
147       // Is sender_sp safe?
<span class="line-modified">148       if (!thread-&gt;is_in_full_stack_checked((address)sender_sp)) {</span>
149         return false;
150       }
151       sender_unextended_sp = sender_sp;
152       sender_pc = (address) *(sender_sp-1);
153       // Note: frame::sender_sp_offset is only valid for compiled frame
154       saved_fp = (intptr_t*) *(sender_sp - frame::sender_sp_offset);
155     }
156 
157 
158     // If the potential sender is the interpreter then we can do some more checking
159     if (Interpreter::contains(sender_pc)) {
160 
161       // fp is always saved in a recognizable place in any code we generate. However
162       // only if the sender is interpreted/call_stub (c1 too?) are we certain that the saved fp
163       // is really a frame pointer.
164 
165       if (!thread-&gt;is_in_stack_range_excl((address)saved_fp, (address)sender_sp)) {
166         return false;
167       }
168 
</pre>
<hr />
<pre>
247 
248   // Must be native-compiled frame. Since sender will try and use fp to find
249   // linkages it must be safe
250 
251   if (!fp_safe) {
252     return false;
253   }
254 
255   // Will the pc we fetch be non-zero (which we&#39;ll find at the oldest frame)
256 
257   if ( (address) this-&gt;fp()[return_addr_offset] == NULL) return false;
258 
259 
260   // could try and do some more potential verification of native frame if we could think of some...
261 
262   return true;
263 
264 }
265 
266 void frame::patch_pc(Thread* thread, address pc) {
<span class="line-added">267   assert(_cb == CodeCache::find_blob(pc), &quot;unexpected pc&quot;);</span>
268   address* pc_addr = &amp;(((address*) sp())[-1]);
269   if (TracePcPatching) {
270     tty-&gt;print_cr(&quot;patch_pc at address &quot; INTPTR_FORMAT &quot; [&quot; INTPTR_FORMAT &quot; -&gt; &quot; INTPTR_FORMAT &quot;]&quot;,
271                   p2i(pc_addr), p2i(*pc_addr), p2i(pc));
272   }
273   // Either the return address is the original one or we are going to
274   // patch in the same address that&#39;s already there.
275   assert(_pc == *pc_addr || pc == *pc_addr, &quot;must be&quot;);
276   *pc_addr = pc;

277   address original_pc = CompiledMethod::get_deopt_original_pc(this);
278   if (original_pc != NULL) {
279     assert(original_pc == _pc, &quot;expected original PC to be stored before patching&quot;);
280     _deopt_state = is_deoptimized;
281     // leave _pc as is
282   } else {
283     _deopt_state = not_deoptimized;
284     _pc = pc;
285   }
286 }
287 
288 bool frame::is_interpreted_frame() const  {
289   return Interpreter::contains(pc());
290 }
291 
292 int frame::frame_size(RegisterMap* map) const {
293   frame sender = this-&gt;sender(map);
294   return sender.sp() - sp();
295 }
296 
</pre>
</td>
</tr>
</table>
<center><a href="c1_LIRAssembler_aarch64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="gc/g1/g1BarrierSetAssembler_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>