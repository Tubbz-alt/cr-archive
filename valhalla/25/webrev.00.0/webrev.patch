diff a/.hgtags b/.hgtags
--- a/.hgtags
+++ b/.hgtags
@@ -631,5 +631,6 @@
 1c06a8ee8acad4d93c782626a233693a73de0add jdk-15+13
 1d6ceb13e142665ea833fca01c8c8598e0ddd211 jdk-15+14
 bc54620a3848c26cff9766e5e2a6e5ddab98ed18 jdk-14-ga
 82b7c62cf4cc56828a8fb724f57087967232a2a7 jdk-15+15
 5c7ec21f5d13f6eb5cd32288c69b8be2f9cac256 jdk-15+16
+dd5198db2e5b1ebcafe065d987c03ba9fcb50fc3 jdk-15+17
diff a/make/CompileJavaModules.gmk b/make/CompileJavaModules.gmk
--- a/make/CompileJavaModules.gmk
+++ b/make/CompileJavaModules.gmk
@@ -350,15 +350,10 @@
 
 ################################################################################
 
 jdk.scripting.nashorn.shell_DISABLED_WARNINGS += removal
 jdk.scripting.nashorn.shell_COPY += .js .properties
-
-################################################################################
-
-jdk.rmic_DISABLED_WARNINGS += deprecation
-jdk.rmic_CLEAN += .properties
 
 ################################################################################
 
 # No SCTP implementation on Mac OS X or AIX. These classes should be excluded.
 SCTP_IMPL_CLASSES = \
diff a/make/conf/jib-profiles.js b/make/conf/jib-profiles.js
--- a/make/conf/jib-profiles.js
+++ b/make/conf/jib-profiles.js
@@ -883,10 +883,11 @@
             ],
             src: "src.conf",
             make_args: testOnlyMake,
             environment: {
                 "BOOT_JDK": common.boot_jdk_home,
+                "JT_HOME": input.get("jtreg", "home_path"),
                 "JDK_IMAGE_DIR": input.get(testedProfileJdk, "home_path"),
                 "TEST_IMAGE_DIR": input.get(testedProfileTest, "home_path")
             },
             labels: "test"
         }
@@ -1061,11 +1062,12 @@
             version: "5.0",
             build_number: "b01",
             checksum_file: "MD5_VALUES",
             file: "bundles/jtreg_bin-5.0.zip",
             environment_name: "JT_HOME",
-            environment_path: input.get("jtreg", "install_path") + "/jtreg/bin"
+            environment_path: input.get("jtreg", "home_path") + "/bin",
+            configure_args: "--with-jtreg=" + input.get("jtreg", "home_path"),
         },
 
         jmh: {
             organization: common.organization,
             ext: "tar.gz",
diff a/src/hotspot/cpu/aarch64/aarch64.ad b/src/hotspot/cpu/aarch64/aarch64.ad
--- a/src/hotspot/cpu/aarch64/aarch64.ad
+++ b/src/hotspot/cpu/aarch64/aarch64.ad
@@ -1025,10 +1025,17 @@
     // count one adr and one far branch instruction
     return 4 * NativeInstruction::instruction_size;
   }
 };
 
+class Node::PD {
+public:
+  enum NodeFlags {
+    _last_flag = Node::_last_flag
+  };
+};
+
  bool is_CAS(int opcode, bool maybe_volatile);
 
   // predicates controlling emit of ldr<x>/ldar<x> and associated dmb
 
   bool unnecessary_acquire(const Node *barrier);
@@ -1049,10 +1056,21 @@
 
 source %{
 
   // Derived RegMask with conditionally allocatable registers
 
+  void PhaseOutput::pd_perform_mach_node_analysis() {
+  }
+
+  int MachNode::pd_alignment_required() const {
+    return 1;
+  }
+
+  int MachNode::compute_padding(int current_offset) const {
+    return 0;
+  }
+
   RegMask _ANY_REG32_mask;
   RegMask _ANY_REG_mask;
   RegMask _PTR_REG_mask;
   RegMask _NO_SPECIAL_REG32_mask;
   RegMask _NO_SPECIAL_REG_mask;
@@ -1668,11 +1686,11 @@
     st->print("ldp  lr, rfp, [sp],#%d\n\t", (2 * wordSize));
   }
 
   if (do_polling() && C->is_method_compilation()) {
     st->print("# touch polling page\n\t");
-    st->print("mov  rscratch1, #0x%lx\n\t", p2i(os::get_polling_page()));
+    st->print("ldr rscratch1, [rthread],#polling_page_offset\n\t");
     st->print("ldr zr, [rscratch1]");
   }
 }
 #endif
 
@@ -1686,11 +1704,11 @@
   if (StackReservedPages > 0 && C->has_reserved_stack_access()) {
     __ reserved_stack_check();
   }
 
   if (do_polling() && C->is_method_compilation()) {
-    __ read_polling_page(rscratch1, os::get_polling_page(), relocInfo::poll_return_type);
+    __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
   }
 }
 
 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
   // Variable size. Determine dynamically.
@@ -1704,18 +1722,10 @@
 
 const Pipeline * MachEpilogNode::pipeline() const {
   return MachNode::pipeline_class();
 }
 
-// This method seems to be obsolete. It is declared in machnode.hpp
-// and defined in all *.ad files, but it is never called. Should we
-// get rid of it?
-int MachEpilogNode::safepoint_offset() const {
-  assert(do_polling(), "no return for this epilog node");
-  return 4;
-}
-
 //=============================================================================
 
 // Figure out which register class each belongs in: rc_int, rc_float or
 // rc_stack.
 enum RC { rc_bad, rc_int, rc_float, rc_stack };
@@ -3188,19 +3198,10 @@
     C2_MacroAssembler _masm(&cbuf);
     Register dst_reg = as_Register($dst$$reg);
     __ mov(dst_reg, (u_int64_t)1);
   %}
 
-  enc_class aarch64_enc_mov_poll_page(iRegP dst, immPollPage src) %{
-    C2_MacroAssembler _masm(&cbuf);
-    address page = (address)$src$$constant;
-    Register dst_reg = as_Register($dst$$reg);
-    unsigned long off;
-    __ adrp(dst_reg, Address(page, relocInfo::poll_type), off);
-    assert(off == 0, "assumed offset == 0");
-  %}
-
   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
     C2_MacroAssembler _masm(&cbuf);
     __ load_byte_map_base($dst$$Register);
   %}
 
@@ -4389,21 +4390,10 @@
   op_cost(0);
   format %{ %}
   interface(CONST_INTER);
 %}
 
-// Polling Page Pointer Immediate
-operand immPollPage()
-%{
-  predicate((address)n->get_ptr() == os::get_polling_page());
-  match(ConP);
-
-  op_cost(0);
-  format %{ %}
-  interface(CONST_INTER);
-%}
-
 // Card Table Byte Map Base
 operand immByteMapBase()
 %{
   // Get base of card map
   predicate(BarrierSet::barrier_set()->is_a(BarrierSet::CardTableBarrierSet) &&
@@ -7196,24 +7186,10 @@
   ins_encode(aarch64_enc_mov_p1(dst, con));
 
   ins_pipe(ialu_imm);
 %}
 
-// Load Poll Page Constant
-
-instruct loadConPollPage(iRegPNoSp dst, immPollPage con)
-%{
-  match(Set dst con);
-
-  ins_cost(INSN_COST);
-  format %{ "adr  $dst, $con\t# Poll Page Ptr" %}
-
-  ins_encode(aarch64_enc_mov_poll_page(dst, con));
-
-  ins_pipe(ialu_imm);
-%}
-
 // Load Byte Map Base Constant
 
 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 %{
   match(Set dst con);
@@ -18074,10 +18050,48 @@
     }
   %}
   ins_pipe(vdop_fp128);
 %}
 
+instruct vpopcount4I(vecX dst, vecX src) %{
+  predicate(UsePopCountInstruction && n->as_Vector()->length() == 4);
+  match(Set dst (PopCountVI src));
+  format %{
+    "cnt     $dst, $src\t# vector (16B)\n\t"
+    "uaddlp  $dst, $dst\t# vector (16B)\n\t"
+    "uaddlp  $dst, $dst\t# vector (8H)"
+  %}
+  ins_encode %{
+     __ cnt(as_FloatRegister($dst$$reg), __ T16B,
+            as_FloatRegister($src$$reg));
+     __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
+               as_FloatRegister($dst$$reg));
+     __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
+               as_FloatRegister($dst$$reg));
+  %}
+  ins_pipe(pipe_class_default);
+%}
+
+instruct vpopcount2I(vecD dst, vecD src) %{
+  predicate(UsePopCountInstruction && n->as_Vector()->length() == 2);
+  match(Set dst (PopCountVI src));
+  format %{
+    "cnt     $dst, $src\t# vector (8B)\n\t"
+    "uaddlp  $dst, $dst\t# vector (8B)\n\t"
+    "uaddlp  $dst, $dst\t# vector (4H)"
+  %}
+  ins_encode %{
+     __ cnt(as_FloatRegister($dst$$reg), __ T8B,
+            as_FloatRegister($src$$reg));
+     __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
+               as_FloatRegister($dst$$reg));
+     __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
+               as_FloatRegister($dst$$reg));
+  %}
+  ins_pipe(pipe_class_default);
+%}
+
 //----------PEEPHOLE RULES-----------------------------------------------------
 // These must follow all instruction definitions as they use the names
 // defined in the instructions definitions.
 //
 // peepmatch ( root_instr_name [preceding_instruction]* );
diff a/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp
@@ -517,23 +517,20 @@
 
   if (StackReservedPages > 0 && compilation()->has_reserved_stack_access()) {
     __ reserved_stack_check();
   }
 
-  address polling_page(os::get_polling_page());
-  __ read_polling_page(rscratch1, polling_page, relocInfo::poll_return_type);
+  __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
   __ ret(lr);
 }
 
 int LIR_Assembler::store_value_type_fields_to_buf(ciValueKlass* vk) {
   return (__ store_value_type_fields_to_buf(vk, false));
 }
 
 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
-  address polling_page(os::get_polling_page());
-  guarantee(info != NULL, "Shouldn't be NULL");
-  assert(os::is_poll_address(polling_page), "should be");
+  guarantee(info != NULL, "Shouldn't be NULL");
   __ get_polling_page(rscratch1, polling_page, relocInfo::poll_type);
   add_debug_info_for_branch(info);  // This isn't just debug info:
                                     // it's the oop map
   __ read_polling_page(rscratch1, relocInfo::poll_type);
   return __ offset();
diff a/src/hotspot/cpu/aarch64/frame_aarch64.cpp b/src/hotspot/cpu/aarch64/frame_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/frame_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/frame_aarch64.cpp
@@ -74,18 +74,18 @@
   // interpreter frames the sender's SP saved in a frame might be less than
   // the SP at the point of call.
 
   // So unextended sp must be within the stack but we need not to check
   // that unextended sp >= sp
-  if (!thread->is_in_full_stack(unextended_sp)) {
+  if (!thread->is_in_full_stack_checked(unextended_sp)) {
     return false;
   }
 
   // an fp must be within the stack and above (but not equal) sp
   // second evaluation on fp+ is added to handle situation where fp is -1
   bool fp_safe = thread->is_in_stack_range_excl(fp, sp) &&
-                 thread->is_in_full_stack(fp + (return_addr_offset * sizeof(void*)));
+                 thread->is_in_full_stack_checked(fp + (return_addr_offset * sizeof(void*)));
 
   // We know sp/unextended_sp are safe only fp is questionable here
 
   // If the current frame is known to the code cache then we can attempt to
   // to construct the sender and do some validation of it. This goes a long way
@@ -143,11 +143,11 @@
         return false;
       }
 
       sender_sp = _unextended_sp + _cb->frame_size();
       // Is sender_sp safe?
-      if (!thread->is_in_full_stack((address)sender_sp)) {
+      if (!thread->is_in_full_stack_checked((address)sender_sp)) {
         return false;
       }
       sender_unextended_sp = sender_sp;
       sender_pc = (address) *(sender_sp-1);
       // Note: frame::sender_sp_offset is only valid for compiled frame
@@ -262,20 +262,20 @@
   return true;
 
 }
 
 void frame::patch_pc(Thread* thread, address pc) {
+  assert(_cb == CodeCache::find_blob(pc), "unexpected pc");
   address* pc_addr = &(((address*) sp())[-1]);
   if (TracePcPatching) {
     tty->print_cr("patch_pc at address " INTPTR_FORMAT " [" INTPTR_FORMAT " -> " INTPTR_FORMAT "]",
                   p2i(pc_addr), p2i(*pc_addr), p2i(pc));
   }
   // Either the return address is the original one or we are going to
   // patch in the same address that's already there.
   assert(_pc == *pc_addr || pc == *pc_addr, "must be");
   *pc_addr = pc;
-  _cb = CodeCache::find_blob(pc);
   address original_pc = CompiledMethod::get_deopt_original_pc(this);
   if (original_pc != NULL) {
     assert(original_pc == _pc, "expected original PC to be stored before patching");
     _deopt_state = is_deoptimized;
     // leave _pc as is
diff a/src/hotspot/cpu/aarch64/gc/g1/g1BarrierSetAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/gc/g1/g1BarrierSetAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/gc/g1/g1BarrierSetAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/gc/g1/g1BarrierSetAssembler_aarch64.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2018, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2018, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -45,10 +45,22 @@
 
 void G1BarrierSetAssembler::gen_write_ref_array_pre_barrier(MacroAssembler* masm, DecoratorSet decorators,
                                                             Register addr, Register count, RegSet saved_regs) {
   bool dest_uninitialized = (decorators & IS_DEST_UNINITIALIZED) != 0;
   if (!dest_uninitialized) {
+    Label done;
+    Address in_progress(rthread, in_bytes(G1ThreadLocalData::satb_mark_queue_active_offset()));
+
+    // Is marking active?
+    if (in_bytes(SATBMarkQueue::byte_width_of_active()) == 4) {
+      __ ldrw(rscratch1, in_progress);
+    } else {
+      assert(in_bytes(SATBMarkQueue::byte_width_of_active()) == 1, "Assumption");
+      __ ldrb(rscratch1, in_progress);
+    }
+    __ cbzw(rscratch1, done);
+
     __ push(saved_regs, sp);
     if (count == c_rarg0) {
       if (addr == c_rarg1) {
         // exactly backwards!!
         __ mov(rscratch1, c_rarg0);
@@ -66,10 +78,12 @@
       __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_pre_narrow_oop_entry), 2);
     } else {
       __ call_VM_leaf(CAST_FROM_FN_PTR(address, G1BarrierSetRuntime::write_ref_array_pre_oop_entry), 2);
     }
     __ pop(saved_regs, sp);
+
+    __ bind(done);
   }
 }
 
 void G1BarrierSetAssembler::gen_write_ref_array_post_barrier(MacroAssembler* masm, DecoratorSet decorators,
                                                              Register start, Register count, Register scratch, RegSet saved_regs) {
@@ -300,11 +314,11 @@
 
 
   if (needs_pre_barrier) {
       g1_write_barrier_pre(masm,
                        tmp1 /* obj */,
-                       tmp2 /* pre_val */,  
+                       tmp2 /* pre_val */,
                        rthread /* thread */,
                        tmp3  /* tmp */,
                        val != noreg /* tosca_live */,
                        false /* expand_call */);
   }
@@ -313,11 +327,11 @@
     BarrierSetAssembler::store_at(masm, decorators, type, Address(tmp1, 0), noreg, noreg, noreg, noreg);
   } else {
     // G1 barrier needs uncompressed oop for region cross check.
     Register new_val = val;
     if (needs_post_barrier) {
-      if (UseCompressedOops) { 
+      if (UseCompressedOops) {
         // FIXME: Refactor the code to avoid usage of r19 and stay within tmpX
         new_val = r19;
         __ mov(new_val, val);
       }
    }
diff a/src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp b/src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/interp_masm_aarch64.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2003, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
@@ -468,12 +468,11 @@
     verify_oop(r0, state);
   }
 
   Label safepoint;
   address* const safepoint_table = Interpreter::safept_table(state);
-  bool needs_thread_local_poll = generate_poll &&
-    SafepointMechanism::uses_thread_local_poll() && table != safepoint_table;
+  bool needs_thread_local_poll = generate_poll && table != safepoint_table;
 
   if (needs_thread_local_poll) {
     NOT_PRODUCT(block_comment("Thread-local Safepoint poll"));
     ldr(rscratch2, Address(rthread, Thread::polling_page_offset()));
     tbnz(rscratch2, exact_log2(SafepointMechanism::poll_bit()), safepoint);
diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.cpp
@@ -290,20 +290,12 @@
   }
   return address(((uint64_t)insn_addr + (offset << 2)));
 }
 
 void MacroAssembler::safepoint_poll(Label& slow_path) {
-  if (SafepointMechanism::uses_thread_local_poll()) {
-    ldr(rscratch1, Address(rthread, Thread::polling_page_offset()));
-    tbnz(rscratch1, exact_log2(SafepointMechanism::poll_bit()), slow_path);
-  } else {
-    unsigned long offset;
-    adrp(rscratch1, ExternalAddress(SafepointSynchronize::address_of_state()), offset);
-    ldrw(rscratch1, Address(rscratch1, offset));
-    assert(SafepointSynchronize::_not_synchronized == 0, "rewrite this code");
-    cbnz(rscratch1, slow_path);
-  }
+  ldr(rscratch1, Address(rthread, Thread::polling_page_offset()));
+  tbnz(rscratch1, exact_log2(SafepointMechanism::poll_bit()), slow_path);
 }
 
 // Just like safepoint_poll, but use an acquiring load for thread-
 // local polling.
 //
@@ -315,17 +307,13 @@
 //
 // This is to avoid a race when we're in a native->Java transition
 // racing the code which wakes up from a safepoint.
 //
 void MacroAssembler::safepoint_poll_acquire(Label& slow_path) {
-  if (SafepointMechanism::uses_thread_local_poll()) {
-    lea(rscratch1, Address(rthread, Thread::polling_page_offset()));
-    ldar(rscratch1, rscratch1);
-    tbnz(rscratch1, exact_log2(SafepointMechanism::poll_bit()), slow_path);
-  } else {
-    safepoint_poll(slow_path);
-  }
+  lea(rscratch1, Address(rthread, Thread::polling_page_offset()));
+  ldar(rscratch1, rscratch1);
+  tbnz(rscratch1, exact_log2(SafepointMechanism::poll_bit()), slow_path);
 }
 
 void MacroAssembler::reset_last_Java_frame(bool clear_fp) {
   // we must set sp to zero to clear frame
   str(zr, Address(rthread, JavaThread::last_Java_sp_offset()));
@@ -4368,26 +4356,19 @@
     lea(tmp, Address(tmp, -os::vm_page_size()));
     str(size, Address(tmp));
   }
 }
 
-
-// Move the address of the polling page into dest.
-void MacroAssembler::get_polling_page(Register dest, address page, relocInfo::relocType rtype) {
-  if (SafepointMechanism::uses_thread_local_poll()) {
-    ldr(dest, Address(rthread, Thread::polling_page_offset()));
-  } else {
-    unsigned long off;
-    adrp(dest, Address(page, rtype), off);
-    assert(off == 0, "polling page must be page aligned");
+// Move the address of the polling page into dest.
+void MacroAssembler::get_polling_page(Register dest, relocInfo::relocType rtype) {
   }
 }
 
 // Move the address of the polling page into r, then read the polling
 // page.
-address MacroAssembler::read_polling_page(Register r, address page, relocInfo::relocType rtype) {
-  get_polling_page(r, page, rtype);
+address MacroAssembler::fetch_and_read_polling_page(Register r, relocInfo::relocType rtype) {
+  get_polling_page(r, rtype);
   return read_polling_page(r, rtype);
 }
 
 // Read the polling page.  The address of the polling page must
 // already be in r.
diff a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
--- a/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
+++ b/src/hotspot/cpu/aarch64/macroAssembler_aarch64.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2014, 2019, Red Hat Inc. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
@@ -1264,12 +1264,12 @@
       adrp(dest, InternalAddress(const_addr.target()), offset);
       ldr(dest, Address(dest, offset));
     }
   }
 
-  address read_polling_page(Register r, address page, relocInfo::relocType rtype);
-  address read_polling_page(Register r, relocInfo::relocType rtype);
+  address read_polling_page(Register r, relocInfo::relocType rtype);
+  void get_polling_page(Register dest, relocInfo::relocType rtype);
   void get_polling_page(Register dest, address page, relocInfo::relocType rtype);
 
   // CRC32 code for java.util.zip.CRC32::updateBytes() instrinsic.
   void update_byte_crc32(Register crc, Register val, Register table);
   void update_word_crc32(Register crc, Register v, Register tmp,
diff a/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp b/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
--- a/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
+++ b/src/hotspot/cpu/aarch64/sharedRuntime_aarch64.cpp
@@ -1,8 +1,8 @@
 /*
  * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
- * Copyright (c) 2014, 2019, Red Hat Inc. All rights reserved.
+ * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -43,11 +43,11 @@
 #include "utilities/align.hpp"
 #include "vmreg_aarch64.inline.hpp"
 #ifdef COMPILER1
 #include "c1/c1_Runtime1.hpp"
 #endif
-#if COMPILER2_OR_JVMCI
+#ifdef COMPILER2
 #include "adfiles/ad_aarch64.hpp"
 #include "opto/runtime.hpp"
 #endif
 #if INCLUDE_JVMCI
 #include "jvmci/jvmciJavaClasses.hpp"
@@ -169,15 +169,16 @@
 
   return oop_map;
 }
 
 void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_vectors) {
-#ifndef COMPILER2
-  assert(!restore_vectors, "vectors are generated only by C2 and JVMCI");
-#endif
+#if COMPILER2_OR_JVMCI
   __ pop_CPU_state(restore_vectors);
   __ leave();
+#else
+  assert(!restore_vectors, "vectors are generated only by C2 and JVMCI");
+#endif
 }
 
 void RegisterSaver::restore_result_registers(MacroAssembler* masm) {
 
   // Just restore result register. Only used by deoptimization. By
@@ -2818,11 +2819,11 @@
 
 uint SharedRuntime::out_preserve_stack_slots() {
   return 0;
 }
 
-#if COMPILER2_OR_JVMCI
+#ifdef COMPILER2
 //------------------------------generate_uncommon_trap_blob--------------------
 void SharedRuntime::generate_uncommon_trap_blob() {
   // Allocate space for the code
   ResourceMark rm;
   // Setup code generation tools
@@ -3009,11 +3010,11 @@
   masm->flush();
 
   _uncommon_trap_blob =  UncommonTrapBlob::create(&buffer, oop_maps,
                                                  SimpleRuntimeFrame::framesize >> 1);
 }
-#endif // COMPILER2_OR_JVMCI
+#endif // COMPILER2
 
 
 //------------------------------generate_handler_blob------
 //
 // Generate a special Compile2Runtime blob that saves all registers,
@@ -3087,11 +3088,11 @@
 
   // No exception case
   __ bind(noException);
 
   Label no_adjust, bail;
-  if (SafepointMechanism::uses_thread_local_poll() && !cause_return) {
+  if (!cause_return) {
     // If our stashed return pc was modified by the runtime we avoid touching it
     __ ldr(rscratch1, Address(rfp, wordSize));
     __ cmp(r20, rscratch1);
     __ br(Assembler::NE, no_adjust);
 
@@ -3217,11 +3218,11 @@
   // return the  blob
   // frame_size_words or bytes??
   return RuntimeStub::new_runtime_stub(name, &buffer, frame_complete, frame_size_in_words, oop_maps, true);
 }
 
-#if COMPILER2_OR_JVMCI
+#ifdef COMPILER2
 // This is here instead of runtime_x86_64.cpp because it uses SimpleRuntimeFrame
 //
 //------------------------------generate_exception_blob---------------------------
 // creates exception blob at the end
 // Using exception blob, this code is jumped from a compiled method.
@@ -3346,11 +3347,10 @@
   masm->flush();
 
   // Set exception blob
   _exception_blob =  ExceptionBlob::create(&buffer, oop_maps, SimpleRuntimeFrame::framesize >> 1);
 }
-#endif // COMPILER2_OR_JVMCI
 
 BufferedValueTypeBlob* SharedRuntime::generate_buffered_value_type_adapter(const ValueKlass* vk) {
   BufferBlob* buf = BufferBlob::create("value types pack/unpack", 16 * K);
   CodeBuffer buffer(buf);
   short buffer_locs[20];
@@ -3452,5 +3452,6 @@
 
   __ flush();
 
   return BufferedValueTypeBlob::create(&buffer, pack_fields_off, unpack_fields_off);
 }
+#endif // COMPILER2
diff a/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp b/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
--- a/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
+++ b/src/hotspot/cpu/ppc/interp_masm_ppc_64.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2003, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2012, 2018 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
@@ -216,11 +216,11 @@
   assert_different_registers(bytecode, R11_scratch1);
 
   // Calc dispatch table address.
   load_dispatch_table(R11_scratch1, table);
 
-  if (SafepointMechanism::uses_thread_local_poll() && generate_poll) {
+  if (generate_poll) {
     address *sfpt_tbl = Interpreter::safept_table(state);
     if (table != sfpt_tbl) {
       Label dispatch;
       ld(R0, in_bytes(Thread::polling_page_offset()), R16_thread);
       // Armed page has poll_bit set, if poll bit is cleared just continue.
diff a/src/hotspot/cpu/s390/interp_masm_s390.cpp b/src/hotspot/cpu/s390/interp_masm_s390.cpp
--- a/src/hotspot/cpu/s390/interp_masm_s390.cpp
+++ b/src/hotspot/cpu/s390/interp_masm_s390.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2016, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2016, 2020, Oracle and/or its affiliates. All rights reserved.
  * Copyright (c) 2016, 2019 SAP SE. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
@@ -114,11 +114,11 @@
   verify_oop(Z_tos, state);
 
   // Dispatch table to use.
   load_absolute_address(Z_tmp_1, (address)table);  // Z_tmp_1 = table;
 
-  if (SafepointMechanism::uses_thread_local_poll() && generate_poll) {
+  if (generate_poll) {
     address *sfpt_tbl = Interpreter::safept_table(state);
     if (table != sfpt_tbl) {
       Label dispatch;
       const Address poll_byte_addr(Z_thread, in_bytes(Thread::polling_page_offset()) + 7 /* Big Endian */);
       // Armed page has poll_bit set, if poll bit is cleared just continue.
diff a/src/hotspot/cpu/sparc/interp_masm_sparc.cpp b/src/hotspot/cpu/sparc/interp_masm_sparc.cpp
--- a/src/hotspot/cpu/sparc/interp_masm_sparc.cpp
+++ b/src/hotspot/cpu/sparc/interp_masm_sparc.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2018, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -269,11 +269,11 @@
   if (verify) interp_verify_oop(Otos_i, state, __FILE__, __LINE__);
   // dispatch table to use
   AddressLiteral tbl(table);
   Label dispatch;
 
-  if (SafepointMechanism::uses_thread_local_poll() && generate_poll) {
+  if (generate_poll) {
     AddressLiteral sfpt_tbl(Interpreter::safept_table(state));
     Label no_safepoint;
 
     if (tbl.value() != sfpt_tbl.value()) {
       ldx(Address(G2_thread, Thread::polling_page_offset()), G3_scratch, 0);
diff a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRAssembler_x86.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -557,33 +557,21 @@
   bool result_is_oop = result->is_valid() ? result->is_oop() : false;
 
   // Note: we do not need to round double result; float result has the right precision
   // the poll sets the condition code, but no data registers
 
-  if (SafepointMechanism::uses_thread_local_poll()) {
-#ifdef _LP64
-    const Register poll_addr = rscratch1;
+#ifdef _LP64
+  const Register poll_addr = rscratch1;
     __ movptr(poll_addr, Address(r15_thread, Thread::polling_page_offset()));
 #else
-    const Register poll_addr = rbx;
-    assert(FrameMap::is_caller_save_register(poll_addr), "will overwrite");
-    __ get_thread(poll_addr);
-    __ movptr(poll_addr, Address(poll_addr, Thread::polling_page_offset()));
+  const Register poll_addr = rbx;
+  assert(FrameMap::is_caller_save_register(poll_addr), "will overwrite");
+  __ get_thread(poll_addr);
+  __ movptr(poll_addr, Address(poll_addr, Thread::polling_page_offset()));
 #endif
-    __ relocate(relocInfo::poll_return_type);
-    __ testl(rax, Address(poll_addr, 0));
-  } else {
-    AddressLiteral polling_page(os::get_polling_page(), relocInfo::poll_return_type);
-
-    if (Assembler::is_polling_page_far()) {
-      __ lea(rscratch1, polling_page);
-      __ relocate(relocInfo::poll_return_type);
-      __ testl(rax, Address(rscratch1, 0));
-    } else {
-      __ testl(rax, polling_page);
-    }
-  }
+  __ relocate(relocInfo::poll_return_type);
+  __ testl(rax, Address(poll_addr, 0));
   __ ret(0);
 }
 
 
 int LIR_Assembler::store_value_type_fields_to_buf(ciValueKlass* vk) {
@@ -591,39 +579,25 @@
 }
 
 int LIR_Assembler::safepoint_poll(LIR_Opr tmp, CodeEmitInfo* info) {
   guarantee(info != NULL, "Shouldn't be NULL");
   int offset = __ offset();
-  if (SafepointMechanism::uses_thread_local_poll()) {
-#ifdef _LP64
-    const Register poll_addr = rscratch1;
+#ifdef _LP64
+  const Register poll_addr = rscratch1;
     __ movptr(poll_addr, Address(r15_thread, Thread::polling_page_offset()));
 #else
-    assert(tmp->is_cpu_register(), "needed");
-    const Register poll_addr = tmp->as_register();
-    __ get_thread(poll_addr);
-    __ movptr(poll_addr, Address(poll_addr, in_bytes(Thread::polling_page_offset())));
+  assert(tmp->is_cpu_register(), "needed");
+  const Register poll_addr = tmp->as_register();
+  __ get_thread(poll_addr);
+  __ movptr(poll_addr, Address(poll_addr, in_bytes(Thread::polling_page_offset())));
 #endif
-    add_debug_info_for_branch(info);
-    __ relocate(relocInfo::poll_type);
-    address pre_pc = __ pc();
-    __ testl(rax, Address(poll_addr, 0));
-    address post_pc = __ pc();
-    guarantee(pointer_delta(post_pc, pre_pc, 1) == 2 LP64_ONLY(+1), "must be exact length");
-  } else {
-    AddressLiteral polling_page(os::get_polling_page(), relocInfo::poll_type);
-    if (Assembler::is_polling_page_far()) {
-      __ lea(rscratch1, polling_page);
-      offset = __ offset();
-      add_debug_info_for_branch(info);
-      __ relocate(relocInfo::poll_type);
-      __ testl(rax, Address(rscratch1, 0));
-    } else {
-      add_debug_info_for_branch(info);
-      __ testl(rax, polling_page);
-    }
-  }
+  add_debug_info_for_branch(info);
+  __ relocate(relocInfo::poll_type);
+  address pre_pc = __ pc();
+  __ testl(rax, Address(poll_addr, 0));
+  address post_pc = __ pc();
+  guarantee(pointer_delta(post_pc, pre_pc, 1) == 2 LP64_ONLY(+1), "must be exact length");
   return offset;
 }
 
 
 void LIR_Assembler::move_regs(Register from_reg, Register to_reg) {
diff a/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp b/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
--- a/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
+++ b/src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -161,11 +161,11 @@
   return c->type() != T_OBJECT || c->as_jobject() == NULL;
 }
 
 
 LIR_Opr LIRGenerator::safepoint_poll_register() {
-  NOT_LP64( if (SafepointMechanism::uses_thread_local_poll()) { return new_register(T_ADDRESS); } )
+  NOT_LP64( return new_register(T_ADDRESS); )
   return LIR_OprFact::illegalOpr;
 }
 
 
 LIR_Address* LIRGenerator::generate_address(LIR_Opr base, LIR_Opr index,
diff a/src/hotspot/cpu/x86/frame_x86.cpp b/src/hotspot/cpu/x86/frame_x86.cpp
--- a/src/hotspot/cpu/x86/frame_x86.cpp
+++ b/src/hotspot/cpu/x86/frame_x86.cpp
@@ -68,11 +68,11 @@
   }
 
   // an fp must be within the stack and above (but not equal) sp
   // second evaluation on fp+ is added to handle situation where fp is -1
   bool fp_safe = thread->is_in_stack_range_excl(fp, sp) &&
-                 thread->is_in_full_stack(fp + (return_addr_offset * sizeof(void*)));
+                 thread->is_in_full_stack_checked(fp + (return_addr_offset * sizeof(void*)));
 
   // We know sp/unextended_sp are safe only fp is questionable here
 
   // If the current frame is known to the code cache then we can attempt to
   // construct the sender and do some validation of it. This goes a long way
@@ -130,11 +130,11 @@
         return false;
       }
 
       sender_sp = _unextended_sp + _cb->frame_size();
       // Is sender_sp safe?
-      if (!thread->is_in_full_stack((address)sender_sp)) {
+      if (!thread->is_in_full_stack_checked((address)sender_sp)) {
         return false;
       }
       // On Intel the return_address is always the word on the stack
       sender_pc = (address) *(sender_sp-1);
       // Note: frame::sender_sp_offset is only valid for compiled frame
@@ -254,20 +254,20 @@
 
 }
 
 
 void frame::patch_pc(Thread* thread, address pc) {
+  assert(_cb == CodeCache::find_blob(pc), "unexpected pc");
   address* pc_addr = &(((address*) sp())[-1]);
   if (TracePcPatching) {
     tty->print_cr("patch_pc at address " INTPTR_FORMAT " [" INTPTR_FORMAT " -> " INTPTR_FORMAT "]",
                   p2i(pc_addr), p2i(*pc_addr), p2i(pc));
   }
   // Either the return address is the original one or we are going to
   // patch in the same address that's already there.
   assert(_pc == *pc_addr || pc == *pc_addr, "must be");
   *pc_addr = pc;
-  _cb = CodeCache::find_blob(pc);
   address original_pc = CompiledMethod::get_deopt_original_pc(this);
   if (original_pc != NULL) {
     assert(original_pc == _pc, "expected original PC to be stored before patching");
     _deopt_state = is_deoptimized;
     // leave _pc as is
diff a/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp b/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/gc/shenandoah/shenandoahBarrierSetAssembler_x86.cpp
@@ -51,11 +51,11 @@
 
   bool dest_uninitialized = (decorators & IS_DEST_UNINITIALIZED) != 0;
 
   if (is_reference_type(type)) {
 
-    if ((ShenandoahSATBBarrier && !dest_uninitialized) || ShenandoahLoadRefBarrier) {
+    if ((ShenandoahSATBBarrier && !dest_uninitialized) || ShenandoahStoreValEnqueueBarrier || ShenandoahLoadRefBarrier) {
 #ifdef _LP64
       Register thread = r15_thread;
 #else
       Register thread = rax;
       if (thread == src || thread == dst || thread == count) {
@@ -75,39 +75,37 @@
       Label done;
       // Short-circuit if count == 0.
       __ testptr(count, count);
       __ jcc(Assembler::zero, done);
 
-      // Avoid runtime call when not marking.
+      // Avoid runtime call when not active.
       Address gc_state(thread, in_bytes(ShenandoahThreadLocalData::gc_state_offset()));
-      int flags = ShenandoahHeap::HAS_FORWARDED;
-      if (!dest_uninitialized) {
-        flags |= ShenandoahHeap::MARKING;
+      int flags;
+      if (ShenandoahSATBBarrier && dest_uninitialized) {
+        flags = ShenandoahHeap::HAS_FORWARDED;
+      } else {
+        flags = ShenandoahHeap::HAS_FORWARDED | ShenandoahHeap::MARKING;
       }
       __ testb(gc_state, flags);
       __ jcc(Assembler::zero, done);
 
       __ pusha();                      // push registers
+
 #ifdef _LP64
       assert(src == rdi, "expected");
       assert(dst == rsi, "expected");
       assert(count == rdx, "expected");
       if (UseCompressedOops) {
-        if (dest_uninitialized) {
-          __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::write_ref_array_pre_duinit_narrow_oop_entry), src, dst, count);
-        } else {
-          __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::write_ref_array_pre_narrow_oop_entry), src, dst, count);
-        }
+        __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::arraycopy_barrier_narrow_oop_entry),
+                        src, dst, count);
       } else
 #endif
       {
-        if (dest_uninitialized) {
-          __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::write_ref_array_pre_duinit_oop_entry), src, dst, count);
-        } else {
-          __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::write_ref_array_pre_oop_entry), src, dst, count);
-        }
+        __ call_VM_leaf(CAST_FROM_FN_PTR(address, ShenandoahRuntime::arraycopy_barrier_oop_entry),
+                        src, dst, count);
       }
+
       __ popa();
       __ bind(done);
       NOT_LP64(__ pop(thread);)
     }
   }
@@ -155,11 +153,11 @@
   Address in_progress(thread, in_bytes(ShenandoahThreadLocalData::satb_mark_queue_active_offset()));
   Address index(thread, in_bytes(ShenandoahThreadLocalData::satb_mark_queue_index_offset()));
   Address buffer(thread, in_bytes(ShenandoahThreadLocalData::satb_mark_queue_buffer_offset()));
 
   Address gc_state(thread, in_bytes(ShenandoahThreadLocalData::gc_state_offset()));
-  __ testb(gc_state, ShenandoahHeap::MARKING | ShenandoahHeap::TRAVERSAL);
+  __ testb(gc_state, ShenandoahHeap::MARKING);
   __ jcc(Assembler::zero, done);
 
   // Do we need to load the previous value?
   if (obj != noreg) {
     __ load_heap_oop(pre_val, Address(obj, 0), noreg, noreg, AS_RAW);
@@ -890,11 +888,11 @@
   Label done;
   Label runtime;
 
   // Is SATB still active?
   Address gc_state(thread, in_bytes(ShenandoahThreadLocalData::gc_state_offset()));
-  __ testb(gc_state, ShenandoahHeap::MARKING | ShenandoahHeap::TRAVERSAL);
+  __ testb(gc_state, ShenandoahHeap::MARKING);
   __ jcc(Assembler::zero, done);
 
   // Can we store original value in the thread's buffer?
 
   __ movptr(tmp, queue_index);
diff a/src/hotspot/cpu/x86/interp_masm_x86.cpp b/src/hotspot/cpu/x86/interp_masm_x86.cpp
--- a/src/hotspot/cpu/x86/interp_masm_x86.cpp
+++ b/src/hotspot/cpu/x86/interp_masm_x86.cpp
@@ -854,11 +854,11 @@
   }
 
   address* const safepoint_table = Interpreter::safept_table(state);
 #ifdef _LP64
   Label no_safepoint, dispatch;
-  if (SafepointMechanism::uses_thread_local_poll() && table != safepoint_table && generate_poll) {
+  if (table != safepoint_table && generate_poll) {
     NOT_PRODUCT(block_comment("Thread-local Safepoint poll"));
     testb(Address(r15_thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
 
     jccb(Assembler::zero, no_safepoint);
     lea(rscratch1, ExternalAddress((address)safepoint_table));
@@ -870,11 +870,11 @@
   bind(dispatch);
   jmp(Address(rscratch1, rbx, Address::times_8));
 
 #else
   Address index(noreg, rbx, Address::times_ptr);
-  if (SafepointMechanism::uses_thread_local_poll() && table != safepoint_table && generate_poll) {
+  if (table != safepoint_table && generate_poll) {
     NOT_PRODUCT(block_comment("Thread-local Safepoint poll"));
     Label no_safepoint;
     const Register thread = rcx;
     get_thread(thread);
     testb(Address(thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
diff a/src/hotspot/cpu/x86/macroAssembler_x86.cpp b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.cpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.cpp
@@ -2782,26 +2782,20 @@
   if (tmp == noreg) push(rax);
   else if (tmp != rax) mov(tmp, rax);
 }
 
 void MacroAssembler::safepoint_poll(Label& slow_path, Register thread_reg, Register temp_reg) {
-  if (SafepointMechanism::uses_thread_local_poll()) {
-#ifdef _LP64
+#ifdef _LP64
     assert(thread_reg == r15_thread, "should be");
 #else
-    if (thread_reg == noreg) {
-      thread_reg = temp_reg;
-      get_thread(thread_reg);
-    }
-#endif
-    testb(Address(thread_reg, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
-    jcc(Assembler::notZero, slow_path); // handshake bit set implies poll
-  } else {
-    cmp32(ExternalAddress(SafepointSynchronize::address_of_state()),
-        SafepointSynchronize::_not_synchronized);
-    jcc(Assembler::notEqual, slow_path);
+  if (thread_reg == noreg) {
+    thread_reg = temp_reg;
+    get_thread(thread_reg);
   }
+#endif
+  testb(Address(thread_reg, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
+  jcc(Assembler::notZero, slow_path); // handshake bit set implies poll
 }
 
 // Calls to C land
 //
 // When entering C land, the rbp, & rsp of the last Java frame have to be recorded
@@ -4022,10 +4016,18 @@
   call(rax);
   // Caller pops the arguments (oop, message) and restores rax, r10
   BLOCK_COMMENT("} verify_oop");
 }
 
+void MacroAssembler::vallones(XMMRegister dst, int vector_len) {
+  if (UseAVX > 2 && (vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl())) {
+    vpternlogd(dst, 0xFF, dst, dst, vector_len);
+  } else {
+    assert(UseAVX > 0, "");
+    vpcmpeqb(dst, dst, dst, vector_len);
+  }
+}
 
 RegisterOrConstant MacroAssembler::delayed_value_impl(intptr_t* delayed_value_addr,
                                                       Register tmp,
                                                       int offset) {
   intptr_t value = *delayed_value_addr;
diff a/src/hotspot/cpu/x86/macroAssembler_x86.hpp b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
--- a/src/hotspot/cpu/x86/macroAssembler_x86.hpp
+++ b/src/hotspot/cpu/x86/macroAssembler_x86.hpp
@@ -1794,12 +1794,13 @@
 
   void cache_wb(Address line);
   void cache_wbsync(bool is_pre);
 #endif // _LP64
 
-  #include "asm/macroAssembler_common.hpp"
+  void vallones(XMMRegister dst, int vector_len);
 
+  #include "asm/macroAssembler_common.hpp"
 };
 
 /**
  * class SkipIfEqual:
  *
diff a/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp b/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
--- a/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
+++ b/src/hotspot/cpu/x86/sharedRuntime_x86_32.cpp
@@ -3169,11 +3169,11 @@
   __ jump(RuntimeAddress(StubRoutines::forward_exception_entry()));
 
   __ bind(noException);
 
   Label no_adjust, bail, not_special;
-  if (SafepointMechanism::uses_thread_local_poll() && !cause_return) {
+  if (!cause_return) {
     // If our stashed return pc was modified by the runtime we avoid touching it
     __ cmpptr(rbx, Address(rbp, wordSize));
     __ jccb(Assembler::notEqual, no_adjust);
 
     // Skip over the poll instruction.
diff a/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp b/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
--- a/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
+++ b/src/hotspot/cpu/x86/sharedRuntime_x86_64.cpp
@@ -3781,11 +3781,11 @@
 
   Label no_adjust;
 #ifdef ASSERT
   Label bail;
 #endif
-  if (SafepointMechanism::uses_thread_local_poll() && !cause_return) {
+  if (!cause_return) {
     Label no_prefix, not_special;
 
     // If our stashed return pc was modified by the runtime we avoid touching it
     __ cmpptr(rbx, Address(rbp, wordSize));
     __ jccb(Assembler::notEqual, no_adjust);
diff a/src/hotspot/cpu/x86/templateTable_x86.cpp b/src/hotspot/cpu/x86/templateTable_x86.cpp
--- a/src/hotspot/cpu/x86/templateTable_x86.cpp
+++ b/src/hotspot/cpu/x86/templateTable_x86.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -2774,11 +2774,11 @@
     __ call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::register_finalizer), robj);
 
     __ bind(skip_register_finalizer);
   }
 
-  if (SafepointMechanism::uses_thread_local_poll() && _desc->bytecode() != Bytecodes::_return_register_finalizer) {
+  if (_desc->bytecode() != Bytecodes::_return_register_finalizer) {
     Label no_safepoint;
     NOT_PRODUCT(__ block_comment("Thread-local Safepoint poll"));
 #ifdef _LP64
     __ testb(Address(r15_thread, Thread::polling_page_offset()), SafepointMechanism::poll_bit());
 #else
diff a/src/hotspot/cpu/x86/x86_32.ad b/src/hotspot/cpu/x86/x86_32.ad
--- a/src/hotspot/cpu/x86/x86_32.ad
+++ b/src/hotspot/cpu/x86/x86_32.ad
@@ -1,7 +1,7 @@
 //
-// Copyright (c) 1997, 2018, Oracle and/or its affiliates. All rights reserved.
+// Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 //
 // This code is free software; you can redistribute it and/or modify it
 // under the terms of the GNU General Public License version 2 only, as
 // published by the Free Software Foundation.
@@ -312,16 +312,10 @@
 int MachCallRuntimeNode::ret_addr_offset() {
   assert(sizeof_FFree_Float_Stack_All != -1, "must have been emitted already");
   return sizeof_FFree_Float_Stack_All + 5 + pre_call_resets_size();
 }
 
-// Indicate if the safepoint node needs the polling page as an input.
-// Since x86 does have absolute addressing, it doesn't.
-bool SafePointNode::needs_polling_address_input() {
-  return SafepointMechanism::uses_thread_local_poll();
-}
-
 //
 // Compute padding required for nodes which need alignment
 //
 
 // The address of the call instruction needs to be 4-byte aligned to
@@ -701,23 +695,16 @@
   if (StackReservedPages > 0 && C->has_reserved_stack_access()) {
     __ reserved_stack_check();
   }
 
   if (do_polling() && C->is_method_compilation()) {
-    if (SafepointMechanism::uses_thread_local_poll()) {
-      Register pollReg = as_Register(EBX_enc);
-      MacroAssembler masm(&cbuf);
-      masm.get_thread(pollReg);
-      masm.movl(pollReg, Address(pollReg, in_bytes(Thread::polling_page_offset())));
-      masm.relocate(relocInfo::poll_return_type);
-      masm.testl(rax, Address(pollReg, 0));
-    } else {
-      cbuf.relocate(cbuf.insts_end(), relocInfo::poll_return_type, 0);
-      emit_opcode(cbuf,0x85);
-      emit_rm(cbuf, 0x0, EAX_enc, 0x5); // EAX
-      emit_d32(cbuf, (intptr_t)os::get_polling_page());
-    }
+    Register pollReg = as_Register(EBX_enc);
+    MacroAssembler masm(&cbuf);
+    masm.get_thread(pollReg);
+    masm.movl(pollReg, Address(pollReg, in_bytes(Thread::polling_page_offset())));
+    masm.relocate(relocInfo::poll_return_type);
+    masm.testl(rax, Address(pollReg, 0));
   }
 }
 
 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
   return MachNode::size(ra_); // too many variables; just compute it
@@ -730,12 +717,10 @@
 
 const Pipeline * MachEpilogNode::pipeline() const {
   return MachNode::pipeline_class();
 }
 
-int MachEpilogNode::safepoint_offset() const { return 0; }
-
 //=============================================================================
 
 enum RC { rc_bad, rc_int, rc_float, rc_xmm, rc_stack };
 static enum RC rc_class( OptoReg::Name reg ) {
 
@@ -3143,22 +3128,10 @@
     int displace = $mem$$disp;
     relocInfo::relocType disp_reloc = $mem->disp_reloc(); // disp-as-oop when working with static globals
     encode_RegMem(cbuf, rm_byte_opcode, base, index, scale, displace, disp_reloc);
   %}
 
-  // Safepoint Poll.  This polls the safepoint page, and causes an
-  // exception if it is not readable. Unfortunately, it kills the condition code
-  // in the process
-  // We current use TESTL [spp],EDI
-  // A better choice might be TESTB [spp + pagesize() - CacheLineSize()],0
-
-  enc_class Safepoint_Poll() %{
-    cbuf.relocate(cbuf.insts_mark(), relocInfo::poll_type, 0);
-    emit_opcode(cbuf,0x85);
-    emit_rm (cbuf, 0x0, 0x7, 0x5);
-    emit_d32(cbuf, (intptr_t)os::get_polling_page());
-  %}
 %}
 
 
 //----------FRAME--------------------------------------------------------------
 // Definition of frame structure and management information.
@@ -3391,10 +3364,19 @@
   op_cost(5);
   format %{ %}
   interface(CONST_INTER);
 %}
 
+operand immU8() %{
+  predicate((0 <= n->get_int()) && (n->get_int() <= 255));
+  match(ConI);
+
+  op_cost(5);
+  format %{ %}
+  interface(CONST_INTER);
+%}
+
 operand immI16() %{
   predicate((-32768 <= n->get_int()) && (n->get_int() <= 32767));
   match(ConI);
 
   op_cost(10);
@@ -13436,31 +13418,10 @@
 
 
 
 // ============================================================================
 // Safepoint Instruction
-instruct safePoint_poll(eFlagsReg cr) %{
-  predicate(SafepointMechanism::uses_global_page_poll());
-  match(SafePoint);
-  effect(KILL cr);
-
-  // TODO-FIXME: we currently poll at offset 0 of the safepoint polling page.
-  // On SPARC that might be acceptable as we can generate the address with
-  // just a sethi, saving an or.  By polling at offset 0 we can end up
-  // putting additional pressure on the index-0 in the D$.  Because of
-  // alignment (just like the situation at hand) the lower indices tend
-  // to see more traffic.  It'd be better to change the polling address
-  // to offset 0 of the last $line in the polling page.
-
-  format %{ "TSTL   #polladdr,EAX\t! Safepoint: poll for GC" %}
-  ins_cost(125);
-  size(6) ;
-  ins_encode( Safepoint_Poll() );
-  ins_pipe( ialu_reg_mem );
-%}
-
-instruct safePoint_poll_tls(eFlagsReg cr, eRegP_no_EBP poll) %{
   predicate(SafepointMechanism::uses_thread_local_poll());
   match(SafePoint poll);
   effect(KILL cr, USE poll);
 
   format %{ "TSTL   #EAX,[$poll]\t! Safepoint: poll for GC" %}
diff a/src/hotspot/cpu/x86/x86_64.ad b/src/hotspot/cpu/x86/x86_64.ad
--- a/src/hotspot/cpu/x86/x86_64.ad
+++ b/src/hotspot/cpu/x86/x86_64.ad
@@ -1,7 +1,7 @@
 //
-// Copyright (c) 2003, 2019, Oracle and/or its affiliates. All rights reserved.
+// Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 //
 // This code is free software; you can redistribute it and/or modify it
 // under the terms of the GNU General Public License version 2 only, as
 // published by the Free Software Foundation.
@@ -457,17 +457,10 @@
   int offset = 13; // movq r10,#addr; callq (r10)
   offset += clear_avx_size();
   return offset;
 }
 
-// Indicate if the safepoint node needs the polling page as an input,
-// it does if the polling page is more than disp32 away.
-bool SafePointNode::needs_polling_address_input()
-{
-  return SafepointMechanism::uses_thread_local_poll() || Assembler::is_polling_page_far();
-}
-
 //
 // Compute padding required for nodes which need alignment
 //
 
 // The address of the call instruction needs to be 4-byte aligned to
@@ -934,22 +927,13 @@
   }
 
   st->print_cr("popq    rbp");
   if (do_polling() && C->is_method_compilation()) {
     st->print("\t");
-    if (SafepointMechanism::uses_thread_local_poll()) {
-      st->print_cr("movq    rscratch1, poll_offset[r15_thread] #polling_page_address\n\t"
-                   "testl   rax, [rscratch1]\t"
-                   "# Safepoint: poll for GC");
-    } else if (Assembler::is_polling_page_far()) {
-      st->print_cr("movq    rscratch1, #polling_page_address\n\t"
-                   "testl   rax, [rscratch1]\t"
-                   "# Safepoint: poll for GC");
-    } else {
-      st->print_cr("testl   rax, [rip + #offset_to_poll_page]\t"
-                   "# Safepoint: poll for GC");
-    }
+    st->print_cr("movq    rscratch1, poll_offset[r15_thread] #polling_page_address\n\t"
+                 "testl   rax, [rscratch1]\t"
+                 "# Safepoint: poll for GC");
   }
 }
 #endif
 
 void MachEpilogNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const
@@ -971,24 +955,13 @@
     __ reserved_stack_check();
   }
 
   if (do_polling() && C->is_method_compilation()) {
     MacroAssembler _masm(&cbuf);
-    if (SafepointMechanism::uses_thread_local_poll()) {
-      __ movq(rscratch1, Address(r15_thread, Thread::polling_page_offset()));
-      __ relocate(relocInfo::poll_return_type);
-      __ testl(rax, Address(rscratch1, 0));
-    } else {
-      AddressLiteral polling_page(os::get_polling_page(), relocInfo::poll_return_type);
-      if (Assembler::is_polling_page_far()) {
-        __ lea(rscratch1, polling_page);
-        __ relocate(relocInfo::poll_return_type);
-        __ testl(rax, Address(rscratch1, 0));
-      } else {
-        __ testl(rax, polling_page);
-      }
-    }
+    __ movq(rscratch1, Address(r15_thread, Thread::polling_page_offset()));
+    __ relocate(relocInfo::poll_return_type);
+    __ testl(rax, Address(rscratch1, 0));
   }
 }
 
 int MachEpilogNode::reloc() const
 {
@@ -998,15 +971,10 @@
 const Pipeline* MachEpilogNode::pipeline() const
 {
   return MachNode::pipeline_class();
 }
 
-int MachEpilogNode::safepoint_offset() const
-{
-  return 0;
-}
-
 //=============================================================================
 
 enum RC {
   rc_bad,
   rc_int,
@@ -12720,45 +12688,12 @@
 %}
 
 
 // ============================================================================
 // Safepoint Instructions
-instruct safePoint_poll(rFlagsReg cr)
-%{
-  predicate(!Assembler::is_polling_page_far() && SafepointMechanism::uses_global_page_poll());
-  match(SafePoint);
-  effect(KILL cr);
-
-  format %{ "testl   rax, [rip + #offset_to_poll_page]\t"
-            "# Safepoint: poll for GC" %}
-  ins_cost(125);
-  ins_encode %{
-    AddressLiteral addr(os::get_polling_page(), relocInfo::poll_type);
-    __ testl(rax, addr);
-  %}
-  ins_pipe(ialu_reg_mem);
-%}
-
-instruct safePoint_poll_far(rFlagsReg cr, rRegP poll)
-%{
-  predicate(Assembler::is_polling_page_far() && SafepointMechanism::uses_global_page_poll());
-  match(SafePoint poll);
-  effect(KILL cr, USE poll);
-
-  format %{ "testl   rax, [$poll]\t"
-            "# Safepoint: poll for GC" %}
-  ins_cost(125);
-  ins_encode %{
-    __ relocate(relocInfo::poll_type);
-    __ testl(rax, Address($poll$$Register, 0));
-  %}
-  ins_pipe(ialu_reg_mem);
-%}
-
 instruct safePoint_poll_tls(rFlagsReg cr, rRegP poll)
 %{
-  predicate(SafepointMechanism::uses_thread_local_poll());
   match(SafePoint poll);
   effect(KILL cr, USE poll);
 
   format %{ "testl   rax, [$poll]\t"
             "# Safepoint: poll for GC" %}
diff a/src/hotspot/share/adlc/formssel.cpp b/src/hotspot/share/adlc/formssel.cpp
--- a/src/hotspot/share/adlc/formssel.cpp
+++ b/src/hotspot/share/adlc/formssel.cpp
@@ -4168,11 +4168,11 @@
     "AddReductionVF", "AddReductionVD",
     "MulReductionVI", "MulReductionVL",
     "MulReductionVF", "MulReductionVD",
     "MaxReductionV", "MinReductionV",
     "AndReductionV", "OrReductionV", "XorReductionV",
-    "MulAddVS2VI",
+    "MulAddVS2VI", "MacroLogicV",
     "LShiftCntV","RShiftCntV",
     "LShiftVB","LShiftVS","LShiftVI","LShiftVL",
     "RShiftVB","RShiftVS","RShiftVI","RShiftVL",
     "URShiftVB","URShiftVS","URShiftVI","URShiftVL",
     "ReplicateB","ReplicateS","ReplicateI","ReplicateL","ReplicateF","ReplicateD",
diff a/src/hotspot/share/c1/c1_LIR.cpp b/src/hotspot/share/c1/c1_LIR.cpp
--- a/src/hotspot/share/c1/c1_LIR.cpp
+++ b/src/hotspot/share/c1/c1_LIR.cpp
@@ -71,25 +71,10 @@
   default: ShouldNotReachHere(); return LIR_OprFact::intConst(-1);
   }
 }
 
 
-LIR_Opr LIR_OprFact::dummy_value_type(ValueType* type) {
-  switch (type->tag()) {
-    case objectTag: return LIR_OprFact::oopConst(NULL);
-    case addressTag:return LIR_OprFact::addressConst(0);
-    case intTag:    return LIR_OprFact::intConst(0);
-    case floatTag:  return LIR_OprFact::floatConst(0.0);
-    case longTag:   return LIR_OprFact::longConst(0);
-    case doubleTag: return LIR_OprFact::doubleConst(0.0);
-    default:        ShouldNotReachHere(); return LIR_OprFact::intConst(-1);
-  }
-  return illegalOpr;
-}
-
-
-
 //---------------------------------------------------
 
 
 LIR_Address::Scale LIR_Address::scale(BasicType type) {
   int elem_size = type2aelembytes(type);
@@ -454,12 +439,10 @@
   set_op(op);
 
   switch (op->code()) {
 
 // LIR_Op0
-    case lir_word_align:               // result and info always invalid
-    case lir_backwardbranch_target:    // result and info always invalid
     case lir_build_frame:              // result and info always invalid
     case lir_fpop_raw:                 // result and info always invalid
     case lir_breakpoint:               // result and info always invalid
     case lir_membar:                   // result and info always invalid
     case lir_membar_acquire:           // result and info always invalid
@@ -1805,18 +1788,16 @@
      case lir_membar_release:        s = "membar_release"; break;
      case lir_membar_loadload:       s = "membar_loadload";   break;
      case lir_membar_storestore:     s = "membar_storestore"; break;
      case lir_membar_loadstore:      s = "membar_loadstore";  break;
      case lir_membar_storeload:      s = "membar_storeload";  break;
-     case lir_word_align:            s = "word_align";    break;
      case lir_label:                 s = "label";         break;
      case lir_nop:                   s = "nop";           break;
      case lir_on_spin_wait:          s = "on_spin_wait";  break;
      case lir_backwardbranch_target: s = "backbranch";    break;
      case lir_std_entry:             s = "std_entry";     break;
      case lir_osr_entry:             s = "osr_entry";     break;
-     case lir_build_frame:           s = "build_frm";     break;
      case lir_fpop_raw:              s = "fpop_raw";      break;
      case lir_breakpoint:            s = "breakpoint";    break;
      case lir_get_thread:            s = "get_thread";    break;
      case lir_check_orig_pc:         s = "check_orig_pc"; break;
      // LIR_Op1
diff a/src/hotspot/share/c1/c1_LIR.hpp b/src/hotspot/share/c1/c1_LIR.hpp
--- a/src/hotspot/share/c1/c1_LIR.hpp
+++ b/src/hotspot/share/c1/c1_LIR.hpp
@@ -836,11 +836,10 @@
   static LIR_Opr illegal()                       { return (LIR_Opr)-1; }
   static LIR_Opr addressConst(jint i)            { return (LIR_Opr)(new LIR_Const(i, true)); }
   static LIR_Opr metadataConst(Metadata* m)      { return (LIR_Opr)(new LIR_Const(m)); }
 
   static LIR_Opr value_type(ValueType* type);
-  static LIR_Opr dummy_value_type(ValueType* type);
 };
 
 
 //-------------------------------------------------------------------------------
 //                   LIR Instructions
@@ -885,17 +884,15 @@
 
 // LIR operation codes
 enum LIR_Code {
     lir_none
   , begin_op0
-      , lir_word_align
       , lir_label
       , lir_nop
       , lir_backwardbranch_target
       , lir_std_entry
       , lir_osr_entry
-      , lir_build_frame
       , lir_fpop_raw
       , lir_breakpoint
       , lir_rtcall
       , lir_membar
       , lir_membar_acquire
@@ -2155,21 +2152,19 @@
                     address dest, LIR_OprList* arguments, CodeEmitInfo* info) {
     append(new LIR_OpJavaCall(lir_dynamic_call, method, receiver, result, dest, arguments, info));
   }
 
   void get_thread(LIR_Opr result)                { append(new LIR_Op0(lir_get_thread, result)); }
-  void word_align()                              { append(new LIR_Op0(lir_word_align)); }
   void membar()                                  { append(new LIR_Op0(lir_membar)); }
   void membar_acquire()                          { append(new LIR_Op0(lir_membar_acquire)); }
   void membar_release()                          { append(new LIR_Op0(lir_membar_release)); }
   void membar_loadload()                         { append(new LIR_Op0(lir_membar_loadload)); }
   void membar_storestore()                       { append(new LIR_Op0(lir_membar_storestore)); }
   void membar_loadstore()                        { append(new LIR_Op0(lir_membar_loadstore)); }
   void membar_storeload()                        { append(new LIR_Op0(lir_membar_storeload)); }
 
   void nop()                                     { append(new LIR_Op0(lir_nop)); }
-  void build_frame()                             { append(new LIR_Op0(lir_build_frame)); }
 
   void std_entry(LIR_Opr receiver)               { append(new LIR_Op0(lir_std_entry, receiver)); }
   void osr_entry(LIR_Opr osrPointer)             { append(new LIR_Op0(lir_osr_entry, osrPointer)); }
 
   void on_spin_wait()                            { append(new LIR_Op0(lir_on_spin_wait)); }
@@ -2338,12 +2333,10 @@
 
   void arraycopy(LIR_Opr src, LIR_Opr src_pos, LIR_Opr dst, LIR_Opr dst_pos, LIR_Opr length, LIR_Opr tmp, ciArrayKlass* expected_type, int flags, CodeEmitInfo* info) { append(new LIR_OpArrayCopy(src, src_pos, dst, dst_pos, length, tmp, expected_type, flags, info)); }
 
   void update_crc32(LIR_Opr crc, LIR_Opr val, LIR_Opr res)  { append(new LIR_OpUpdateCRC32(crc, val, res)); }
 
-  void fpop_raw()                                { append(new LIR_Op0(lir_fpop_raw)); }
-
   void instanceof(LIR_Opr result, LIR_Opr object, ciKlass* klass, LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3, bool fast_check, CodeEmitInfo* info_for_patch, ciMethod* profiled_method, int profiled_bci);
   void store_check(LIR_Opr object, LIR_Opr array, LIR_Opr tmp1, LIR_Opr tmp2, LIR_Opr tmp3, CodeEmitInfo* info_for_exception, ciMethod* profiled_method, int profiled_bci);
   void check_flattened_array(LIR_Opr array, LIR_Opr value, LIR_Opr tmp, CodeStub* stub);
   void check_null_free_array(LIR_Opr array, LIR_Opr tmp);
   void substitutability_check(LIR_Opr result, LIR_Opr left, LIR_Opr right, LIR_Opr equal_result, LIR_Opr not_equal_result,
diff a/src/hotspot/share/c1/c1_LIRAssembler.cpp b/src/hotspot/share/c1/c1_LIRAssembler.cpp
--- a/src/hotspot/share/c1/c1_LIRAssembler.cpp
+++ b/src/hotspot/share/c1/c1_LIRAssembler.cpp
@@ -738,28 +738,19 @@
   }
 }
 
 void LIR_Assembler::emit_op0(LIR_Op0* op) {
   switch (op->code()) {
-    case lir_word_align: {
-      _masm->align(BytesPerWord);
-      break;
-    }
-
     case lir_nop:
       assert(op->info() == NULL, "not supported");
       _masm->nop();
       break;
 
     case lir_label:
       Unimplemented();
       break;
 
-    case lir_build_frame:
-      build_frame();
-      break;
-
     case lir_std_entry:
       emit_std_entries();
       break;
 
     case lir_osr_entry:
diff a/src/hotspot/share/classfile/classFileParser.cpp b/src/hotspot/share/classfile/classFileParser.cpp
--- a/src/hotspot/share/classfile/classFileParser.cpp
+++ b/src/hotspot/share/classfile/classFileParser.cpp
@@ -6154,11 +6154,11 @@
 
   // Set PackageEntry for this_klass
   oop cl = ik->class_loader();
   Handle clh = Handle(THREAD, java_lang_ClassLoader::non_reflection_class_loader(cl));
   ClassLoaderData* cld = ClassLoaderData::class_loader_data_or_null(clh());
-  ik->set_package(cld, CHECK);
+  ik->set_package(cld, NULL, CHECK);
 
   const Array<Method*>* const methods = ik->methods();
   assert(methods != NULL, "invariant");
   const int methods_len = methods->length();
 
diff a/src/hotspot/share/classfile/classLoader.cpp b/src/hotspot/share/classfile/classLoader.cpp
--- a/src/hotspot/share/classfile/classLoader.cpp
+++ b/src/hotspot/share/classfile/classLoader.cpp
@@ -218,13 +218,13 @@
     return NULL;
   }
   return SymbolTable::new_symbol(name, start - base, end - base);
 }
 
-// Given a fully qualified class name, find its defining package in the class loader's
+// Given a fully qualified package name, find its defining package in the class loader's
 // package entry table.
-PackageEntry* ClassLoader::get_package_entry(Symbol* pkg_name, ClassLoaderData* loader_data, TRAPS) {
+PackageEntry* ClassLoader::get_package_entry(Symbol* pkg_name, ClassLoaderData* loader_data) {
   if (pkg_name == NULL) {
     return NULL;
   }
   PackageEntryTable* pkgEntryTable = loader_data->packages();
   return pkgEntryTable->lookup_only(pkg_name);
@@ -394,13 +394,13 @@
 
     if (pkg_name != NULL) {
       if (!Universe::is_module_initialized()) {
         location = (*JImageFindResource)(_jimage, JAVA_BASE_NAME, get_jimage_version_string(), name, &size);
       } else {
-        PackageEntry* package_entry = ClassLoader::get_package_entry(pkg_name, loader_data, CHECK_NULL);
+        PackageEntry* package_entry = ClassLoader::get_package_entry(pkg_name, loader_data);
         if (package_entry != NULL) {
-          ResourceMark rm;
+          ResourceMark rm(THREAD);
           // Get the module name
           ModuleEntry* module = package_entry->module();
           assert(module != NULL, "Boot classLoader package missing module");
           assert(module->is_named(), "Boot classLoader package is in unnamed module");
           const char* module_name = module->name()->as_C_string();
@@ -1145,11 +1145,11 @@
   ClassFileStream* stream = NULL;
 
   // Find the class' defining module in the boot loader's module entry table
   TempNewSymbol class_name_symbol = SymbolTable::new_symbol(class_name);
   TempNewSymbol pkg_name = package_from_class_name(class_name_symbol);
-  PackageEntry* pkg_entry = get_package_entry(pkg_name, ClassLoaderData::the_null_class_loader_data(), CHECK_NULL);
+  PackageEntry* pkg_entry = get_package_entry(pkg_name, ClassLoaderData::the_null_class_loader_data());
   ModuleEntry* mod_entry = (pkg_entry != NULL) ? pkg_entry->module() : NULL;
 
   // If the module system has not defined java.base yet, then
   // classes loaded are assumed to be defined to java.base.
   // When java.base is eventually defined by the module system,
diff a/src/hotspot/share/classfile/systemDictionary.cpp b/src/hotspot/share/classfile/systemDictionary.cpp
--- a/src/hotspot/share/classfile/systemDictionary.cpp
+++ b/src/hotspot/share/classfile/systemDictionary.cpp
@@ -1202,14 +1202,15 @@
 
 #if INCLUDE_CDS
 // Load a class for boot loader from the shared spaces. This also
 // forces the super class and all interfaces to be loaded.
 InstanceKlass* SystemDictionary::load_shared_boot_class(Symbol* class_name,
+                                                        PackageEntry* pkg_entry,
                                                         TRAPS) {
   InstanceKlass* ik = SystemDictionaryShared::find_builtin_class(class_name);
   if (ik != NULL && ik->is_shared_boot_class()) {
-    return load_shared_class(ik, Handle(), Handle(), NULL, THREAD);
+    return load_shared_class(ik, Handle(), Handle(), NULL, pkg_entry, THREAD);
   }
   return NULL;
 }
 
 // Check if a shared class can be loaded by the specific classloader:
@@ -1218,10 +1219,11 @@
 //   - Module class from "modules" jimage. ModuleEntry must be defined in the classloader.
 //   - Class from -Xbootclasspath/a. The class has no defined PackageEntry, or must
 //     be defined in an unnamed module.
 bool SystemDictionary::is_shared_class_visible(Symbol* class_name,
                                                InstanceKlass* ik,
+                                               PackageEntry* pkg_entry,
                                                Handle class_loader, TRAPS) {
   assert(!ModuleEntryTable::javabase_moduleEntry()->is_patched(),
          "Cannot use sharing if java.base is patched");
   ResourceMark rm(THREAD);
   int path_index = ik->shared_classpath_index();
@@ -1242,16 +1244,15 @@
            "Loading non-bootstrap classes before the module system is initialized");
     assert(class_loader.is_null(), "sanity");
     return true;
   }
   // Get the pkg_entry from the classloader
-  PackageEntry* pkg_entry = NULL;
-  ModuleEntry* mod_entry = NULL;
+  ModuleEntry* mod_entry = NULL;
+  TempNewSymbol pkg_name = pkg_entry != NULL ? pkg_entry->name() :
   TempNewSymbol pkg_name = ClassLoader::package_from_class_name(class_name);
   if (pkg_name != NULL) {
     if (loader_data != NULL) {
-      pkg_entry = loader_data->packages()->lookup_only(pkg_name);
       if (pkg_entry != NULL) {
         mod_entry = pkg_entry->module();
         // If the archived class is from a module that has been patched at runtime,
         // the class cannot be loaded from the archive.
         if (mod_entry != NULL && mod_entry->is_patched()) {
@@ -1344,17 +1345,18 @@
 
 InstanceKlass* SystemDictionary::load_shared_class(InstanceKlass* ik,
                                                    Handle class_loader,
                                                    Handle protection_domain,
                                                    const ClassFileStream *cfs,
+                                                   PackageEntry* pkg_entry,
                                                    TRAPS) {
   assert(ik != NULL, "sanity");
   assert(!ik->is_unshareable_info_restored(), "shared class can be loaded only once");
   Symbol* class_name = ik->name();
 
   bool visible = is_shared_class_visible(
-                          class_name, ik, class_loader, CHECK_NULL);
+                          class_name, ik, pkg_entry, class_loader, CHECK_NULL);
   if (!visible) {
     return NULL;
   }
 
   if (!check_shared_class_super_types(ik, class_loader, protection_domain, THREAD)) {
@@ -1386,11 +1388,11 @@
     Handle lockObject = compute_loader_lock_object(class_loader, THREAD);
     check_loader_lock_contention(lockObject, THREAD);
     ObjectLocker ol(lockObject, THREAD, true);
     // prohibited package check assumes all classes loaded from archive call
     // restore_unshareable_info which calls ik->set_package()
-    ik->restore_unshareable_info(loader_data, protection_domain, CHECK_NULL);
+    ik->restore_unshareable_info(loader_data, protection_domain, pkg_entry, CHECK_NULL);
   }
 
   load_shared_class_misc(ik, loader_data, CHECK_NULL);
   return ik;
 }
@@ -1453,11 +1455,11 @@
     if (ik->class_loader_data()  == NULL) {
       quick_resolve(ik, loader_data, domain, CHECK);
     }
   }
 
-  klass->restore_unshareable_info(loader_data, domain, THREAD);
+  klass->restore_unshareable_info(loader_data, domain, NULL, THREAD);
   load_shared_class_misc(klass, loader_data, CHECK);
   Dictionary* dictionary = loader_data->dictionary();
   unsigned int hash = dictionary->compute_hash(klass->name());
   dictionary->add_klass(hash, klass->name(), klass);
   add_to_hierarchy(klass, CHECK);
@@ -1533,11 +1535,11 @@
     // Search for classes in the CDS archive.
     InstanceKlass* k = NULL;
     {
 #if INCLUDE_CDS
       PerfTraceTime vmtimer(ClassLoader::perf_shared_classload_time());
-      k = load_shared_boot_class(class_name, THREAD);
+      k = load_shared_boot_class(class_name, pkg_entry, THREAD);
 #endif
     }
 
     if (k == NULL) {
       // Use VM class loader
@@ -2611,13 +2613,11 @@
 
   if (accessing_klass != NULL) {
     // Check accessibility, emulating ConstantPool::verify_constant_pool_resolve.
     Klass* sel_klass = java_lang_Class::as_Klass(mirror());
     if (sel_klass != NULL) {
-      bool fold_type_to_class = true;
-      LinkResolver::check_klass_accessability(accessing_klass, sel_klass,
-                                              fold_type_to_class, CHECK_NH);
+      LinkResolver::check_klass_accessibility(accessing_klass, sel_klass, CHECK_NH);
     }
   }
   return mirror;
 }
 
@@ -2678,13 +2678,11 @@
     // Check accessibility.
     if (!java_lang_Class::is_primitive(mirror) && accessing_klass != NULL) {
       Klass* sel_klass = java_lang_Class::as_Klass(mirror);
       mirror = NULL;  // safety
       // Emulate ConstantPool::verify_constant_pool_resolve.
-      bool fold_type_to_class = true;
-      LinkResolver::check_klass_accessability(accessing_klass, sel_klass,
-                                              fold_type_to_class, CHECK_(empty));
+      LinkResolver::check_klass_accessibility(accessing_klass, sel_klass, CHECK_(empty));
     }
   }
   assert(arg == npts, "");
 
   // call java.lang.invoke.MethodHandleNatives::findMethodHandleType(Class rt, Class[] pts) -> MethodType
diff a/src/hotspot/share/classfile/systemDictionary.hpp b/src/hotspot/share/classfile/systemDictionary.hpp
--- a/src/hotspot/share/classfile/systemDictionary.hpp
+++ b/src/hotspot/share/classfile/systemDictionary.hpp
@@ -601,24 +601,27 @@
   static void define_instance_class(InstanceKlass* k, TRAPS);
   static InstanceKlass* find_or_define_instance_class(Symbol* class_name,
                                                 Handle class_loader,
                                                 InstanceKlass* k, TRAPS);
   static bool is_shared_class_visible(Symbol* class_name, InstanceKlass* ik,
+                                      PackageEntry* pkg_entry,
                                       Handle class_loader, TRAPS);
   static bool check_shared_class_super_type(InstanceKlass* child, InstanceKlass* super,
                                             Handle class_loader,  Handle protection_domain,
                                             bool is_superclass, TRAPS);
   static bool check_shared_class_super_types(InstanceKlass* ik, Handle class_loader,
                                                Handle protection_domain, TRAPS);
   static InstanceKlass* load_shared_class(InstanceKlass* ik,
                                           Handle class_loader,
                                           Handle protection_domain,
                                           const ClassFileStream *cfs,
+                                          PackageEntry* pkg_entry,
                                           TRAPS);
   // Second part of load_shared_class
   static void load_shared_class_misc(InstanceKlass* ik, ClassLoaderData* loader_data, TRAPS) NOT_CDS_RETURN;
   static InstanceKlass* load_shared_boot_class(Symbol* class_name,
+                                               PackageEntry* pkg_entry,
                                                TRAPS);
   static InstanceKlass* load_instance_class(Symbol* class_name, Handle class_loader, TRAPS);
   static Handle compute_loader_lock_object(Handle class_loader, TRAPS);
   static void check_loader_lock_contention(Handle loader_lock, TRAPS);
   static bool is_parallelCapable(Handle class_loader);
diff a/src/hotspot/share/code/compiledMethod.cpp b/src/hotspot/share/code/compiledMethod.cpp
--- a/src/hotspot/share/code/compiledMethod.cpp
+++ b/src/hotspot/share/code/compiledMethod.cpp
@@ -654,10 +654,15 @@
         // metadata relocation of the static stub used to pass the Method* to
         // c2i adapters.
         continue;
       }
       is_in_static_stub = false;
+      if (is_unloading()) {
+        // If the nmethod itself is dying, then it may point at dead metadata.
+        // Nobody should follow that metadata; it is strictly unsafe.
+        continue;
+      }
       metadata_Relocation* r = iter.metadata_reloc();
       Metadata* md = r->metadata_value();
       if (md != NULL && md->is_method()) {
         Method* method = static_cast<Method*>(md);
         if (!method->method_holder()->is_loader_alive()) {
diff a/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp b/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
--- a/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
+++ b/src/hotspot/share/gc/shenandoah/c2/shenandoahBarrierSetC2.cpp
@@ -564,12 +564,11 @@
     Node* offset = adr->is_AddP() ? adr->in(AddPNode::Offset) : top;
     Node* obj = access.base();
 
     bool unknown = (decorators & ON_UNKNOWN_OOP_REF) != 0;
     bool on_weak_ref = (decorators & (ON_WEAK_OOP_REF | ON_PHANTOM_OOP_REF)) != 0;
-    bool is_traversal_mode = ShenandoahHeap::heap()->is_traversal_mode();
-    bool keep_alive = (decorators & AS_NO_KEEPALIVE) == 0 || is_traversal_mode;
+    bool keep_alive = (decorators & AS_NO_KEEPALIVE) == 0;
 
     // If we are reading the value of the referent field of a Reference
     // object (either by using Unsafe directly or through reflection)
     // then, if SATB is enabled, we need to record the referent in an
     // SATB log buffer using the pre-barrier mechanism.
@@ -773,11 +772,11 @@
 bool ShenandoahBarrierSetC2::array_copy_requires_gc_barriers(bool tightly_coupled_alloc, BasicType type, bool is_clone, ArrayCopyPhase phase) const {
   bool is_oop = is_reference_type(type);
   if (!is_oop) {
     return false;
   }
-  if (tightly_coupled_alloc) {
+  if (ShenandoahSATBBarrier && tightly_coupled_alloc) {
     if (phase == Optimization) {
       return false;
     }
     return !is_clone;
   }
@@ -840,11 +839,15 @@
     uint gc_state_idx = Compile::AliasIdxRaw;
     const TypePtr* gc_state_adr_type = NULL; // debug-mode-only argument
     debug_only(gc_state_adr_type = phase->C->get_adr_type(gc_state_idx));
 
     Node* gc_state    = phase->transform_later(new LoadBNode(ctrl, mem, gc_state_addr, gc_state_adr_type, TypeInt::BYTE, MemNode::unordered));
-    Node* stable_and  = phase->transform_later(new AndINode(gc_state, phase->igvn().intcon(ShenandoahHeap::HAS_FORWARDED)));
+    int flags = ShenandoahHeap::HAS_FORWARDED;
+    if (ShenandoahStoreValEnqueueBarrier) {
+      flags |= ShenandoahHeap::MARKING;
+    }
+    Node* stable_and  = phase->transform_later(new AndINode(gc_state, phase->igvn().intcon(flags)));
     Node* stable_cmp  = phase->transform_later(new CmpINode(stable_and, phase->igvn().zerocon(T_INT)));
     Node* stable_test = phase->transform_later(new BoolNode(stable_cmp, BoolTest::ne));
 
     IfNode* stable_iff  = phase->transform_later(new IfNode(ctrl, stable_test, PROB_UNLIKELY(0.999), COUNT_UNKNOWN))->as_If();
     Node* stable_ctrl   = phase->transform_later(new IfFalseNode(stable_iff));
diff a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
--- a/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
+++ b/src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp
@@ -857,12 +857,12 @@
   phase->lazy_replace(outer, new_outer);
   phase->lazy_replace(le, new_le);
   inner->clear_strip_mined();
 }
 
-void ShenandoahBarrierC2Support::test_heap_stable(Node*& ctrl, Node* raw_mem, Node*& heap_stable_ctrl,
-                                                  PhaseIdealLoop* phase) {
+void ShenandoahBarrierC2Support::test_heap_state(Node*& ctrl, Node* raw_mem, Node*& heap_stable_ctrl,
+                                                 PhaseIdealLoop* phase, int flags) {
   IdealLoopTree* loop = phase->get_loop(ctrl);
   Node* thread = new ThreadLocalNode();
   phase->register_new_node(thread, ctrl);
   Node* offset = phase->igvn().MakeConX(in_bytes(ShenandoahThreadLocalData::gc_state_offset()));
   phase->set_ctrl(offset, phase->C->root());
@@ -872,11 +872,11 @@
   const TypePtr* gc_state_adr_type = NULL; // debug-mode-only argument
   debug_only(gc_state_adr_type = phase->C->get_adr_type(gc_state_idx));
 
   Node* gc_state = new LoadBNode(ctrl, raw_mem, gc_state_addr, gc_state_adr_type, TypeInt::BYTE, MemNode::unordered);
   phase->register_new_node(gc_state, ctrl);
-  Node* heap_stable_and = new AndINode(gc_state, phase->igvn().intcon(ShenandoahHeap::HAS_FORWARDED));
+  Node* heap_stable_and = new AndINode(gc_state, phase->igvn().intcon(flags));
   phase->register_new_node(heap_stable_and, ctrl);
   Node* heap_stable_cmp = new CmpINode(heap_stable_and, phase->igvn().zerocon(T_INT));
   phase->register_new_node(heap_stable_cmp, ctrl);
   Node* heap_stable_test = new BoolNode(heap_stable_cmp, BoolTest::ne);
   phase->register_new_node(heap_stable_test, ctrl);
@@ -886,11 +886,11 @@
   heap_stable_ctrl = new IfFalseNode(heap_stable_iff);
   phase->register_control(heap_stable_ctrl, loop, heap_stable_iff);
   ctrl = new IfTrueNode(heap_stable_iff);
   phase->register_control(ctrl, loop, heap_stable_iff);
 
-  assert(is_heap_stable_test(heap_stable_iff), "Should match the shape");
+  assert(is_heap_state_test(heap_stable_iff, flags), "Should match the shape");
 }
 
 void ShenandoahBarrierC2Support::test_null(Node*& ctrl, Node* val, Node*& null_ctrl, PhaseIdealLoop* phase) {
   const Type* val_t = phase->igvn().type(val);
   if (val_t->meet(TypePtr::NULL_PTR) == val_t) {
@@ -1432,11 +1432,11 @@
     Node* region = new RegionNode(PATH_LIMIT);
     Node* val_phi = new PhiNode(region, uncasted_val->bottom_type()->is_oopptr());
     Node* raw_mem_phi = PhiNode::make(region, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
 
     // Stable path.
-    test_heap_stable(ctrl, raw_mem, heap_stable_ctrl, phase);
+    test_heap_state(ctrl, raw_mem, heap_stable_ctrl, phase, ShenandoahHeap::HAS_FORWARDED);
     IfNode* heap_stable_iff = heap_stable_ctrl->in(0)->as_If();
 
     // Heap stable case
     region->init_req(_heap_stable, heap_stable_ctrl);
     val_phi->init_req(_heap_stable, uncasted_val);
@@ -1603,11 +1603,11 @@
     enum { _fast_path = 1, _slow_path, _null_path, PATH_LIMIT2 };
     Node* region2 = new RegionNode(PATH_LIMIT2);
     Node* phi2 = PhiNode::make(region2, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
 
     // Stable path.
-    test_heap_stable(ctrl, raw_mem, heap_stable_ctrl, phase);
+    test_heap_state(ctrl, raw_mem, heap_stable_ctrl, phase, ShenandoahHeap::MARKING);
     region->init_req(_heap_stable, heap_stable_ctrl);
     phi->init_req(_heap_stable, raw_mem);
 
     // Null path
     Node* reg2_ctrl = NULL;
diff a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.hpp b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.hpp
--- a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.hpp
+++ b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.hpp
@@ -66,17 +66,12 @@
 
   bool is_a(BarrierSet::Name bsn);
 
   bool is_aligned(HeapWord* hw);
 
-  template <class T> void
-  write_ref_array_pre_work(T* src, T* dst, size_t count, bool dest_uninitialized);
-
-  inline void arraycopy_pre(oop* src, oop* dst, size_t count);
-  inline void arraycopy_pre(narrowOop* src, narrowOop* dst, size_t count);
-  inline void arraycopy_update(oop* src, size_t count);
-  inline void arraycopy_update(narrowOop* src, size_t count);
+  template <class T>
+  inline void arraycopy_barrier(T* src, T* dst, size_t count);
   inline void clone_barrier(oop src);
   void clone_barrier_runtime(oop src);
 
   virtual void on_thread_create(Thread* thread);
   virtual void on_thread_destroy(Thread* thread);
@@ -99,33 +94,37 @@
   inline void enqueue(oop obj);
 
   oop load_reference_barrier(oop obj);
   oop load_reference_barrier_not_null(oop obj);
 
-  oop load_reference_barrier_mutator(oop obj, oop* load_addr);
-  oop load_reference_barrier_mutator(oop obj, narrowOop* load_addr);
-
-  template <class T>
+  template <class T>
   oop load_reference_barrier_mutator_work(oop obj, T* load_addr);
 
   oop load_reference_barrier_native(oop obj, oop* load_addr);
   oop load_reference_barrier_native(oop obj, narrowOop* load_addr);
 
 private:
   template <class T>
-  inline void arraycopy_pre_work(T* src, T* dst, size_t count);
+  inline void arraycopy_marking(T* src, T* dst, size_t count);
+  template <class T>
+  inline void arraycopy_evacuation(T* src, size_t count);
+  template <class T>
+  inline void arraycopy_update(T* src, size_t count);
+
+  inline void clone_marking(oop src);
+  inline void clone_evacuation(oop src);
+  inline void clone_update(oop src);
+
   template <class T, bool HAS_FWD, bool EVAC, bool ENQUEUE>
   inline void arraycopy_work(T* src, size_t count);
-  template <class T>
-  inline void arraycopy_update_impl(T* src, size_t count);
 
   oop load_reference_barrier_impl(oop obj);
 
   template <class T>
   oop load_reference_barrier_native_impl(oop obj, T* load_addr);
 
-  inline bool skip_bulk_update(HeapWord* dst);
+  inline bool need_bulk_update(HeapWord* dst);
 public:
   // Callbacks for runtime accesses.
   template <DecoratorSet decorators, typename BarrierSetT = ShenandoahBarrierSet>
   class AccessBarrier: public BarrierSet::AccessBarrier<decorators, BarrierSetT> {
     typedef BarrierSet::AccessBarrier<decorators, BarrierSetT> Raw;
diff a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
--- a/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
+++ b/src/hotspot/share/gc/shenandoah/shenandoahBarrierSet.inline.hpp
@@ -51,12 +51,32 @@
 
 inline oop ShenandoahBarrierSet::resolve_forwarded_not_null_mutator(oop p) {
   return ShenandoahForwarding::get_forwardee_mutator(p);
 }
 
+template <class T>
+inline oop ShenandoahBarrierSet::load_reference_barrier_mutator(oop obj, T* load_addr) {
+  assert(ShenandoahLoadRefBarrier, "should be enabled");
+  shenandoah_assert_in_cset(load_addr, obj);
+
+  oop fwd = resolve_forwarded_not_null_mutator(obj);
+  if (obj == fwd) {
+    assert(_heap->is_evacuation_in_progress(),
+           "evac should be in progress");
+    ShenandoahEvacOOMScope scope;
+    fwd = _heap->evacuate_object(obj, Thread::current());
+  }
+
+  if (load_addr != NULL && fwd != obj) {
+    // Since we are here and we know the load address, update the reference.
+    ShenandoahHeap::cas_oop(fwd, load_addr, obj);
+  }
+
+  return fwd;
+}
+
 inline void ShenandoahBarrierSet::enqueue(oop obj) {
-  shenandoah_assert_not_forwarded_if(NULL, obj, _heap->is_concurrent_traversal_in_progress());
   assert(_satb_mark_queue_set.is_active(), "only get here when SATB active");
 
   // Filter marked objects before hitting the SATB queues. The same predicate would
   // be used by SATBMQ::filter to eliminate already marked objects downstream, but
   // filtering here helps to avoid wasteful SATB queueing work to begin with.
@@ -85,11 +105,11 @@
     enqueue(value);
   }
 }
 
 inline void ShenandoahBarrierSet::storeval_barrier(oop obj) {
-  if (obj != NULL && ShenandoahStoreValEnqueueBarrier && _heap->is_concurrent_traversal_in_progress()) {
+  if (ShenandoahStoreValEnqueueBarrier && obj != NULL && _heap->is_concurrent_mark_in_progress()) {
     enqueue(obj);
   }
 }
 
 inline void ShenandoahBarrierSet::keep_alive_if_weak(DecoratorSet decorators, oop value) {
@@ -248,13 +268,13 @@
 template <typename T>
 void ShenandoahBarrierSet::AccessBarrier<decorators, BarrierSetT>::oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,
                                                                                          arrayOop dst_obj, size_t dst_offset_in_bytes, T* dst_raw,
                                                                                          size_t length) {
   ShenandoahBarrierSet* bs = ShenandoahBarrierSet::barrier_set();
-  bs->arraycopy_pre(arrayOopDesc::obj_offset_to_raw(src_obj, src_offset_in_bytes, src_raw),
-                    arrayOopDesc::obj_offset_to_raw(dst_obj, dst_offset_in_bytes, dst_raw),
-                    length);
+  bs->arraycopy_barrier(arrayOopDesc::obj_offset_to_raw(src_obj, src_offset_in_bytes, src_raw),
+                        arrayOopDesc::obj_offset_to_raw(dst_obj, dst_offset_in_bytes, dst_raw),
+                        length);
   Raw::oop_arraycopy_in_heap(src_obj, src_offset_in_bytes, src_raw, dst_obj, dst_offset_in_bytes, dst_raw, length);
 }
 
 template <class T, bool HAS_FWD, bool EVAC, bool ENQUEUE>
 void ShenandoahBarrierSet::arraycopy_work(T* src, size_t count) {
@@ -284,51 +304,50 @@
     }
   }
 }
 
 template <class T>
-void ShenandoahBarrierSet::arraycopy_pre_work(T* src, T* dst, size_t count) {
-  if (_heap->is_concurrent_mark_in_progress() &&
-      !_heap->marking_context()->allocated_after_mark_start(reinterpret_cast<HeapWord*>(dst))) {
-    arraycopy_work<T, false, false, true>(dst, count);
+void ShenandoahBarrierSet::arraycopy_barrier(T* src, T* dst, size_t count) {
+  if (count == 0) {
+    return;
   }
-
-  if (_heap->has_forwarded_objects()) {
-    arraycopy_update_impl(src, count);
+  int gc_state = _heap->gc_state();
+  if ((gc_state & ShenandoahHeap::MARKING) != 0) {
+    arraycopy_marking(src, dst, count);
+  } else if ((gc_state & ShenandoahHeap::EVACUATION) != 0) {
+    arraycopy_evacuation(src, count);
+  } else if ((gc_state & ShenandoahHeap::UPDATEREFS) != 0) {
+    arraycopy_update(src, count);
   }
 }
 
-void ShenandoahBarrierSet::arraycopy_pre(oop* src, oop* dst, size_t count) {
-  arraycopy_pre_work(src, dst, count);
-}
-
-void ShenandoahBarrierSet::arraycopy_pre(narrowOop* src, narrowOop* dst, size_t count) {
-  arraycopy_pre_work(src, dst, count);
+template <class T>
+void ShenandoahBarrierSet::arraycopy_marking(T* src, T* dst, size_t count) {
+  assert(_heap->is_concurrent_mark_in_progress(), "only during marking");
+  T* array = ShenandoahSATBBarrier ? dst : src;
+  if (!_heap->marking_context()->allocated_after_mark_start(reinterpret_cast<HeapWord*>(array))) {
+    arraycopy_work<T, false, false, true>(array, count);
+  }
 }
 
-inline bool ShenandoahBarrierSet::skip_bulk_update(HeapWord* dst) {
-  return dst >= _heap->heap_region_containing(dst)->get_update_watermark();
+inline bool ShenandoahBarrierSet::need_bulk_update(HeapWord* ary) {
+  return ary < _heap->heap_region_containing(ary)->get_update_watermark();
 }
 
 template <class T>
-void ShenandoahBarrierSet::arraycopy_update_impl(T* src, size_t count) {
-  if (skip_bulk_update(reinterpret_cast<HeapWord*>(src))) return;
-  if (_heap->is_evacuation_in_progress()) {
+void ShenandoahBarrierSet::arraycopy_evacuation(T* src, size_t count) {
+  assert(_heap->is_evacuation_in_progress(), "only during evacuation");
+  if (need_bulk_update(reinterpret_cast<HeapWord*>(src))) {
     ShenandoahEvacOOMScope oom_evac;
     arraycopy_work<T, true, true, false>(src, count);
-  } else if (_heap->is_concurrent_traversal_in_progress()){
-    ShenandoahEvacOOMScope oom_evac;
-    arraycopy_work<T, true, true, true>(src, count);
-  } else if (_heap->has_forwarded_objects()) {
-    arraycopy_work<T, true, false, false>(src, count);
   }
 }
 
-void ShenandoahBarrierSet::arraycopy_update(oop* src, size_t count) {
-  arraycopy_update_impl(src, count);
-}
-
-void ShenandoahBarrierSet::arraycopy_update(narrowOop* src, size_t count) {
-  arraycopy_update_impl(src, count);
+template <class T>
+void ShenandoahBarrierSet::arraycopy_update(T* src, size_t count) {
+  assert(_heap->is_update_refs_in_progress(), "only during update-refs");
+  if (need_bulk_update(reinterpret_cast<HeapWord*>(src))) {
+    arraycopy_work<T, true, false, false>(src, count);
+  }
 }
 
 #endif // SHARE_GC_SHENANDOAH_SHENANDOAHBARRIERSET_INLINE_HPP
diff a/src/hotspot/share/interpreter/linkResolver.cpp b/src/hotspot/share/interpreter/linkResolver.cpp
--- a/src/hotspot/share/interpreter/linkResolver.cpp
+++ b/src/hotspot/share/interpreter/linkResolver.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -62,37 +62,35 @@
 // Implementation of CallInfo
 
 
 void CallInfo::set_static(Klass* resolved_klass, const methodHandle& resolved_method, TRAPS) {
   int vtable_index = Method::nonvirtual_vtable_index;
-  set_common(resolved_klass, resolved_klass, resolved_method, resolved_method, CallInfo::direct_call, vtable_index, CHECK);
+  set_common(resolved_klass, resolved_method, resolved_method, CallInfo::direct_call, vtable_index, CHECK);
 }
 
 
 void CallInfo::set_interface(Klass* resolved_klass,
-                             Klass* selected_klass,
                              const methodHandle& resolved_method,
                              const methodHandle& selected_method,
                              int itable_index, TRAPS) {
   // This is only called for interface methods. If the resolved_method
   // comes from java/lang/Object, it can be the subject of a virtual call, so
   // we should pick the vtable index from the resolved method.
   // In that case, the caller must call set_virtual instead of set_interface.
   assert(resolved_method->method_holder()->is_interface(), "");
   assert(itable_index == resolved_method()->itable_index(), "");
-  set_common(resolved_klass, selected_klass, resolved_method, selected_method, CallInfo::itable_call, itable_index, CHECK);
+  set_common(resolved_klass, resolved_method, selected_method, CallInfo::itable_call, itable_index, CHECK);
 }
 
 void CallInfo::set_virtual(Klass* resolved_klass,
-                           Klass* selected_klass,
                            const methodHandle& resolved_method,
                            const methodHandle& selected_method,
                            int vtable_index, TRAPS) {
   assert(vtable_index >= 0 || vtable_index == Method::nonvirtual_vtable_index, "valid index");
   assert(vtable_index < 0 || !resolved_method->has_vtable_index() || vtable_index == resolved_method->vtable_index(), "");
   CallKind kind = (vtable_index >= 0 && !resolved_method->can_be_statically_bound() ? CallInfo::vtable_call : CallInfo::direct_call);
-  set_common(resolved_klass, selected_klass, resolved_method, selected_method, kind, vtable_index, CHECK);
+  set_common(resolved_klass, resolved_method, selected_method, kind, vtable_index, CHECK);
   assert(!resolved_method->is_compiled_lambda_form(), "these must be handled via an invokehandle call");
 }
 
 void CallInfo::set_handle(const methodHandle& resolved_method,
                           Handle resolved_appendix, TRAPS) {
@@ -106,24 +104,22 @@
   assert(resolved_method->intrinsic_id() == vmIntrinsics::_invokeBasic ||
          resolved_method->is_compiled_lambda_form(),
          "linkMethod must return one of these");
   int vtable_index = Method::nonvirtual_vtable_index;
   assert(!resolved_method->has_vtable_index(), "");
-  set_common(resolved_klass, resolved_klass, resolved_method, resolved_method, CallInfo::direct_call, vtable_index, CHECK);
+  set_common(resolved_klass, resolved_method, resolved_method, CallInfo::direct_call, vtable_index, CHECK);
   _resolved_appendix = resolved_appendix;
 }
 
 void CallInfo::set_common(Klass* resolved_klass,
-                          Klass* selected_klass,
                           const methodHandle& resolved_method,
                           const methodHandle& selected_method,
                           CallKind kind,
                           int index,
                           TRAPS) {
   assert(resolved_method->signature() == selected_method->signature(), "signatures must correspond");
   _resolved_klass  = resolved_klass;
-  _selected_klass  = selected_klass;
   _resolved_method = resolved_method;
   _selected_method = selected_method;
   _call_kind       = kind;
   _call_index      = index;
   _resolved_appendix = Handle();
@@ -137,11 +133,10 @@
   Klass* resolved_method_holder = resolved_method->method_holder();
   if (resolved_klass == NULL) { // 2nd argument defaults to holder of 1st
     resolved_klass = resolved_method_holder;
   }
   _resolved_klass  = resolved_klass;
-  _selected_klass  = resolved_klass;
   _resolved_method = methodHandle(THREAD, resolved_method);
   _selected_method = methodHandle(THREAD, resolved_method);
   // classify:
   CallKind kind = CallInfo::unknown_kind;
   int index = resolved_method->vtable_index();
@@ -275,23 +270,21 @@
 }
 #endif // PRODUCT
 //------------------------------------------------------------------------------------------------------------------------
 // Klass resolution
 
-void LinkResolver::check_klass_accessability(Klass* ref_klass, Klass* sel_klass,
-                                             bool fold_type_to_class, TRAPS) {
+void LinkResolver::check_klass_accessibility(Klass* ref_klass, Klass* sel_klass, TRAPS) {
   Klass* base_klass = sel_klass;
-  if (fold_type_to_class) {
-    if (sel_klass->is_objArray_klass()) {
-      base_klass = ObjArrayKlass::cast(sel_klass)->bottom_klass();
-    }
-    // The element type could be a typeArray - we only need the access
-    // check if it is a reference to another class.
-    if (!base_klass->is_instance_klass()) {
-      return;  // no relevant check to do
-    }
+  if (sel_klass->is_objArray_klass()) {
+    base_klass = ObjArrayKlass::cast(sel_klass)->bottom_klass();
   }
+  // The element type could be a typeArray - we only need the access
+  // check if it is a reference to another class.
+  if (!base_klass->is_instance_klass()) {
+    return;  // no relevant check to do
+  }
+
   Reflection::VerifyClassAccessResults vca_result =
     Reflection::verify_class_access(ref_klass, InstanceKlass::cast(base_klass), true);
   if (vca_result != Reflection::ACCESS_OK) {
     ResourceMark rm(THREAD);
     char* msg = Reflection::verify_class_access_msg(ref_klass,
@@ -988,12 +981,10 @@
     // (2) by the <clinit> method (in case of a static field)
     //     or by the <init> method (in case of an instance field).
     // (3) by withfield when field is in a value type and the
     //     selected class and current class are nest mates.
     if (is_put && fd.access_flags().is_final()) {
-      ResourceMark rm(THREAD);
-      stringStream ss;
 
       if (sel_klass != current_klass) {
       // If byte code is a withfield check if they are nestmates.
       bool are_nestmates = false;
       if (sel_klass->is_instance_klass() &&
@@ -1001,10 +992,12 @@
           current_klass->is_instance_klass()) {
         are_nestmates = InstanceKlass::cast(link_info.current_klass())->has_nestmate_access_to(
                                                         InstanceKlass::cast(sel_klass), THREAD);
       }
       if (!are_nestmates) {
+        ResourceMark rm(THREAD);
+        stringStream ss;
         ss.print("Update to %s final field %s.%s attempted from a different class (%s) than the field's declaring class",
                  is_static ? "static" : "non-static", resolved_klass->external_name(), fd.name()->as_C_string(),
                   current_klass->external_name());
         THROW_MSG(vmSymbols::java_lang_IllegalAccessError(), ss.as_string());
       }
@@ -1019,10 +1012,12 @@
         bool is_initialized_instance_final_update = ((byte == Bytecodes::_putfield || byte == Bytecodes::_nofast_putfield) &&
                                                      !fd.is_static() &&
                                                      !m->is_object_constructor());
 
         if (is_initialized_static_final_update || is_initialized_instance_final_update) {
+          ResourceMark rm(THREAD);
+          stringStream ss;
           ss.print("Update to %s final field %s.%s attempted from a different method (%s) than the initializer method %s ",
                    is_static ? "static" : "non-static", resolved_klass->external_name(), fd.name()->as_C_string(),
                    m->name()->as_C_string(),
                    is_static ? "<clinit>" : "<init>");
           THROW_MSG(vmSymbols::java_lang_IllegalAccessError(), ss.as_string());
@@ -1409,11 +1404,11 @@
     trace_method_resolution("invokevirtual selected method: receiver-class:",
                             recv_klass, resolved_klass, selected_method(),
                             false, vtable_index);
   }
   // setup result
-  result.set_virtual(resolved_klass, recv_klass, resolved_method, selected_method, vtable_index, CHECK);
+  result.set_virtual(resolved_klass, resolved_method, selected_method, vtable_index, CHECK);
 }
 
 void LinkResolver::resolve_interface_call(CallInfo& result, Handle recv, Klass* recv_klass,
                                           const LinkInfo& link_info,
                                           bool check_null_and_abstract, TRAPS) {
@@ -1505,25 +1500,25 @@
   // setup result
   if (resolved_method->has_vtable_index()) {
     int vtable_index = resolved_method->vtable_index();
     log_develop_trace(itables)("  -- vtable index: %d", vtable_index);
     assert(vtable_index == selected_method->vtable_index(), "sanity check");
-    result.set_virtual(resolved_klass, recv_klass, resolved_method, selected_method, vtable_index, CHECK);
+    result.set_virtual(resolved_klass, resolved_method, selected_method, vtable_index, CHECK);
   } else if (resolved_method->has_itable_index()) {
     int itable_index = resolved_method()->itable_index();
     log_develop_trace(itables)("  -- itable index: %d", itable_index);
-    result.set_interface(resolved_klass, recv_klass, resolved_method, selected_method, itable_index, CHECK);
+    result.set_interface(resolved_klass, resolved_method, selected_method, itable_index, CHECK);
   } else {
     int index = resolved_method->vtable_index();
     log_develop_trace(itables)("  -- non itable/vtable index: %d", index);
     assert(index == Method::nonvirtual_vtable_index, "Oops hit another case!");
     assert(resolved_method()->is_private() ||
            (resolved_method()->is_final() && resolved_method->method_holder() == SystemDictionary::Object_klass()),
            "Should only have non-virtual invokeinterface for private or final-Object methods!");
     assert(resolved_method()->can_be_statically_bound(), "Should only have non-virtual invokeinterface for statically bound methods!");
     // This sets up the nonvirtual form of "virtual" call (as needed for final and private methods)
-    result.set_virtual(resolved_klass, resolved_klass, resolved_method, resolved_method, index, CHECK);
+    result.set_virtual(resolved_klass, resolved_method, resolved_method, index, CHECK);
   }
 }
 
 
 Method* LinkResolver::linktime_resolve_interface_method_or_null(
diff a/src/hotspot/share/interpreter/linkResolver.hpp b/src/hotspot/share/interpreter/linkResolver.hpp
--- a/src/hotspot/share/interpreter/linkResolver.hpp
+++ b/src/hotspot/share/interpreter/linkResolver.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -47,34 +47,33 @@
     itable_call,                        // select recv.klass.method_at_itable(resolved_method.holder, index)
     unknown_kind = -1
   };
  private:
   Klass*       _resolved_klass;         // static receiver klass, resolved from a symbolic reference
-  Klass*       _selected_klass;         // dynamic receiver class (same as static, or subklass)
   methodHandle _resolved_method;        // static target method
   methodHandle _selected_method;        // dynamic (actual) target method
   CallKind     _call_kind;              // kind of call (static(=bytecode static/special +
                                         //               others inferred), vtable, itable)
   int          _call_index;             // vtable or itable index of selected class method (if any)
   Handle       _resolved_appendix;      // extra argument in constant pool (if CPCE::has_appendix)
   Handle       _resolved_method_name;   // Object holding the ResolvedMethodName
 
   void set_static(Klass* resolved_klass, const methodHandle& resolved_method, TRAPS);
-  void set_interface(Klass* resolved_klass, Klass* selected_klass,
+  void set_interface(Klass* resolved_klass,
                      const methodHandle& resolved_method,
                      const methodHandle& selected_method,
                      int itable_index, TRAPS);
-  void set_virtual(Klass* resolved_klass, Klass* selected_klass,
+  void set_virtual(Klass* resolved_klass,
                    const methodHandle& resolved_method,
                    const methodHandle& selected_method,
                    int vtable_index, TRAPS);
   void set_handle(const methodHandle& resolved_method,
                   Handle resolved_appendix, TRAPS);
   void set_handle(Klass* resolved_klass,
                   const methodHandle& resolved_method,
                   Handle resolved_appendix, TRAPS);
-  void set_common(Klass* resolved_klass, Klass* selected_klass,
+  void set_common(Klass* resolved_klass,
                   const methodHandle& resolved_method,
                   const methodHandle& selected_method,
                   CallKind kind,
                   int index, TRAPS);
 
@@ -93,21 +92,19 @@
   // does not queue the method for compilation.  This also creates a ResolvedMethodName
   // object for the resolved_method.
   CallInfo(Method* resolved_method, Klass* resolved_klass, TRAPS);
 
   Klass*  resolved_klass() const                 { return _resolved_klass; }
-  Klass*  selected_klass() const                 { return _selected_klass; }
   Method* resolved_method() const                { return _resolved_method(); }
   Method* selected_method() const                { return _selected_method(); }
   Handle       resolved_appendix() const         { return _resolved_appendix; }
   Handle       resolved_method_name() const      { return _resolved_method_name; }
   // Materialize a java.lang.invoke.ResolvedMethodName for this resolved_method
   void     set_resolved_method_name(TRAPS);
 
   BasicType    result_type() const               { return selected_method()->result_type(); }
   CallKind     call_kind() const                 { return _call_kind; }
-  int          call_index() const                { return _call_index; }
   int          vtable_index() const {
     // Even for interface calls the vtable index could be non-negative.
     // See CallInfo::set_interface.
     assert(has_vtable_index() || is_statically_bound(), "");
     assert(call_kind() == vtable_call || call_kind() == direct_call, "");
@@ -270,20 +267,11 @@
                                       const constantPoolHandle& pool, int index, TRAPS);
   static void resolve_invokehandle   (CallInfo& result,
                                       const constantPoolHandle& pool, int index, TRAPS);
  public:
   // constant pool resolving
-  static void check_klass_accessability(Klass* ref_klass, Klass* sel_klass,
-                                        bool fold_type_to_class, TRAPS);
-  // The optional 'fold_type_to_class' means that a derived type (array)
-  // is first converted to the class it is derived from (element type).
-  // If this element type is not a class, then the check passes quietly.
-  // This is usually what is needed, but a few existing uses might break
-  // if this flag were always turned on.  FIXME: See if it can be, always.
-  static void check_klass_accessability(Klass* ref_klass, Klass* sel_klass, TRAPS) {
-    return check_klass_accessability(ref_klass, sel_klass, false, THREAD);
-  }
+  static void check_klass_accessibility(Klass* ref_klass, Klass* sel_klass, TRAPS);
 
   // static resolving calls (will not run any Java code);
   // used only from Bytecode_invoke::static_target
   static Method* resolve_method_statically(Bytecodes::Code code,
                                            const constantPoolHandle& pool,
diff a/src/hotspot/share/memory/universe.cpp b/src/hotspot/share/memory/universe.cpp
--- a/src/hotspot/share/memory/universe.cpp
+++ b/src/hotspot/share/memory/universe.cpp
@@ -281,11 +281,15 @@
   Klass* ok = SystemDictionary::Object_klass();
 #if INCLUDE_CDS
   if (UseSharedSpaces) {
     ClassLoaderData* loader_data = ClassLoaderData::the_null_class_loader_data();
     assert(k->super() == ok, "u3");
-    k->restore_unshareable_info(loader_data, Handle(), CHECK);
+    if (k->is_instance_klass()) {
+      InstanceKlass::cast(k)->restore_unshareable_info(loader_data, Handle(), NULL, CHECK);
+    } else {
+      ArrayKlass::cast(k)->restore_unshareable_info(loader_data, Handle(), CHECK);
+    }
   } else
 #endif
   {
     k->initialize_supers(ok, NULL, CHECK);
   }
diff a/src/hotspot/share/oops/arrayKlass.hpp b/src/hotspot/share/oops/arrayKlass.hpp
--- a/src/hotspot/share/oops/arrayKlass.hpp
+++ b/src/hotspot/share/oops/arrayKlass.hpp
@@ -144,11 +144,11 @@
   jint jvmti_class_status() const;
 
   // CDS support - remove and restore oops from metadata. Oops are not shared.
   virtual void remove_unshareable_info();
   virtual void remove_java_mirror();
-  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, TRAPS);
+  void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, TRAPS);
 
   // Printing
   void print_on(outputStream* st) const;
   void print_value_on(outputStream* st) const;
 
diff a/src/hotspot/share/oops/constantPool.cpp b/src/hotspot/share/oops/constantPool.cpp
--- a/src/hotspot/share/oops/constantPool.cpp
+++ b/src/hotspot/share/oops/constantPool.cpp
@@ -722,12 +722,11 @@
 void ConstantPool::verify_constant_pool_resolve(const constantPoolHandle& this_cp, Klass* k, TRAPS) {
   if (!(k->is_instance_klass() || k->is_objArray_klass())) {
     return;  // short cut, typeArray klass is always accessible
   }
   Klass* holder = this_cp->pool_holder();
-  bool fold_type_to_class = true;
-  LinkResolver::check_klass_accessability(holder, k, fold_type_to_class, CHECK);
+  LinkResolver::check_klass_accessibility(holder, k, CHECK);
 }
 
 
 int ConstantPool::name_ref_index_at(int which_nt) {
   jint ref_index = name_and_type_at(which_nt);
diff a/src/hotspot/share/oops/instanceKlass.cpp b/src/hotspot/share/oops/instanceKlass.cpp
--- a/src/hotspot/share/oops/instanceKlass.cpp
+++ b/src/hotspot/share/oops/instanceKlass.cpp
@@ -2568,16 +2568,17 @@
   if (array_klasses() != NULL) {
     array_klasses()->remove_java_mirror();
   }
 }
 
-void InstanceKlass::restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, TRAPS) {
+void InstanceKlass::restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain,
+                                             PackageEntry* pkg_entry, TRAPS) {
   // SystemDictionary::add_to_hierarchy() sets the init_state to loaded
   // before the InstanceKlass is added to the SystemDictionary. Make
   // sure the current state is <loaded.
   assert(!is_loaded(), "invalid init state");
-  set_package(loader_data, CHECK);
+  set_package(loader_data, pkg_entry, CHECK);
   Klass::restore_unshareable_info(loader_data, protection_domain, CHECK);
 
   if (is_value()) {
     ValueKlass::cast(this)->initialize_calling_convention(CHECK);
   }
@@ -2601,11 +2602,11 @@
   constants()->restore_unshareable_info(CHECK);
 
   if (array_klasses() != NULL) {
     // Array classes have null protection domain.
     // --> see ArrayKlass::complete_create_array_klass()
-    array_klasses()->restore_unshareable_info(ClassLoaderData::the_null_class_loader_data(), Handle(), CHECK);
+    ArrayKlass::cast(array_klasses())->restore_unshareable_info(ClassLoaderData::the_null_class_loader_data(), Handle(), CHECK);
   }
 
   // Initialize current biased locking state.
   if (UseBiasedLocking && BiasedLocking::enabled() && !is_value()) {
     set_prototype_header(markWord::biased_locking_prototype());
@@ -2808,27 +2809,26 @@
 
   // Class is in an unnamed package, return its loader's unnamed module
   return class_loader_data()->unnamed_module();
 }
 
-void InstanceKlass::set_package(ClassLoaderData* loader_data, TRAPS) {
+void InstanceKlass::set_package(ClassLoaderData* loader_data, PackageEntry* pkg_entry, TRAPS) {
 
   // ensure java/ packages only loaded by boot or platform builtin loaders
   check_prohibited_package(name(), loader_data, CHECK);
 
-  TempNewSymbol pkg_name = ClassLoader::package_from_class_name(name());
+  TempNewSymbol pkg_name = pkg_entry != NULL ? pkg_entry->name() : ClassLoader::package_from_class_name(name());
 
   if (pkg_name != NULL && loader_data != NULL) {
 
     // Find in class loader's package entry table.
-    _package_entry = loader_data->packages()->lookup_only(pkg_name);
+    _package_entry = pkg_entry != NULL ? pkg_entry : loader_data->packages()->lookup_only(pkg_name);
 
     // If the package name is not found in the loader's package
     // entry table, it is an indication that the package has not
     // been defined. Consider it defined within the unnamed module.
     if (_package_entry == NULL) {
-      ResourceMark rm(THREAD);
 
       if (!ModuleEntryTable::javabase_defined()) {
         // Before java.base is defined during bootstrapping, define all packages in
         // the java.base module.  If a non-java.base package is erroneously placed
         // in the java.base module it will be caught later when java.base
@@ -2840,10 +2840,11 @@
         _package_entry = loader_data->packages()->lookup(pkg_name,
                                                          loader_data->unnamed_module());
       }
 
       // A package should have been successfully created
+      DEBUG_ONLY(ResourceMark rm(THREAD));
       assert(_package_entry != NULL, "Package entry for class %s not found, loader %s",
              name()->as_C_string(), loader_data->loader_name_and_id());
     }
 
     if (log_is_enabled(Debug, module)) {
diff a/src/hotspot/share/oops/instanceKlass.hpp b/src/hotspot/share/oops/instanceKlass.hpp
--- a/src/hotspot/share/oops/instanceKlass.hpp
+++ b/src/hotspot/share/oops/instanceKlass.hpp
@@ -588,11 +588,11 @@
   // package
   PackageEntry* package() const     { return _package_entry; }
   ModuleEntry* module() const;
   bool in_unnamed_package() const   { return (_package_entry == NULL); }
   void set_package(PackageEntry* p) { _package_entry = p; }
-  void set_package(ClassLoaderData* loader_data, TRAPS);
+  void set_package(ClassLoaderData* loader_data, PackageEntry* pkg_entry, TRAPS);
   bool is_same_class_package(const Klass* class2) const;
   bool is_same_class_package(oop other_class_loader, const Symbol* other_class_name) const;
 
   // find an enclosing class
   InstanceKlass* compute_enclosing_class(bool* inner_is_member, TRAPS) const;
@@ -1466,11 +1466,11 @@
 #endif
 public:
   // CDS support - remove and restore oops from metadata. Oops are not shared.
   virtual void remove_unshareable_info();
   virtual void remove_java_mirror();
-  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, TRAPS);
+  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS);
 
   // jvm support
   jint compute_modifier_flags(TRAPS) const;
 
 public:
diff a/src/hotspot/share/oops/klass.hpp b/src/hotspot/share/oops/klass.hpp
--- a/src/hotspot/share/oops/klass.hpp
+++ b/src/hotspot/share/oops/klass.hpp
@@ -520,10 +520,11 @@
   static void check_array_allocation_length(int length, int max_length, TRAPS);
 
   void set_vtable_length(int len) { _vtable_len= len; }
 
   vtableEntry* start_of_vtable() const;
+  void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, TRAPS);
  public:
   Method* method_at_vtable(int index);
 
   static ByteSize vtable_start_offset();
   static ByteSize vtable_length_offset() {
@@ -531,11 +532,10 @@
   }
 
   // CDS support - remove and restore oops from metadata. Oops are not shared.
   virtual void remove_unshareable_info();
   virtual void remove_java_mirror();
-  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, TRAPS);
 
   bool is_unshareable_info_restored() const {
     assert(is_shared(), "use this for shared classes only");
     if (has_raw_archived_mirror()) {
       // _java_mirror is not a valid OopHandle but rather an encoded reference in the shared heap
diff a/src/hotspot/share/oops/valueKlass.cpp b/src/hotspot/share/oops/valueKlass.cpp
--- a/src/hotspot/share/oops/valueKlass.cpp
+++ b/src/hotspot/share/oops/valueKlass.cpp
@@ -209,12 +209,12 @@
   *((address*)adr_unpack_handler()) = NULL;
   assert(pack_handler() == NULL, "pack handler not null");
   *((Klass**)adr_value_array_klass()) = NULL;
 }
 
-void ValueKlass::restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, TRAPS) {
-  InstanceKlass::restore_unshareable_info(loader_data, protection_domain, CHECK);
+void ValueKlass::restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS) {
+  InstanceKlass::restore_unshareable_info(loader_data, protection_domain, pkg_entry, CHECK);
   oop val = allocate_instance(CHECK);
   set_default_value(val);
 }
 
 
diff a/src/hotspot/share/oops/valueKlass.hpp b/src/hotspot/share/oops/valueKlass.hpp
--- a/src/hotspot/share/oops/valueKlass.hpp
+++ b/src/hotspot/share/oops/valueKlass.hpp
@@ -158,11 +158,11 @@
   }
 
   int first_field_offset_old();
 
   virtual void remove_unshareable_info();
-  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, TRAPS);
+  virtual void restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS);
   virtual void metaspace_pointers_do(MetaspaceClosure* it);
 
  private:
   int collect_fields(GrowableArray<SigEntry>* sig, int base_off = 0);
 
diff a/src/hotspot/share/opto/c2_globals.hpp b/src/hotspot/share/opto/c2_globals.hpp
--- a/src/hotspot/share/opto/c2_globals.hpp
+++ b/src/hotspot/share/opto/c2_globals.hpp
@@ -184,10 +184,13 @@
            "Multi versioned post loops to eliminate range checks")          \
                                                                             \
   notproduct(bool, TraceSuperWordLoopUnrollAnalysis, false,                 \
           "Trace what Superword Level Parallelism analysis applies")        \
                                                                             \
+  diagnostic(bool, UseVectorMacroLogic, true,                               \
+          "Use ternary macro logic instructions")                           \
+                                                                            \
   product(intx,  LoopUnrollMin, 4,                                          \
           "Minimum number of unroll loop bodies before checking progress"   \
           "of rounds of unroll,optimize,..")                                \
           range(0, max_jint)                                                \
                                                                             \
diff a/src/hotspot/share/opto/callnode.cpp b/src/hotspot/share/opto/callnode.cpp
--- a/src/hotspot/share/opto/callnode.cpp
+++ b/src/hotspot/share/opto/callnode.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -1524,13 +1524,10 @@
   return monitor_obj(jvms(), mon);
 }
 
 // Do we Match on this edge index or not?  Match no edges
 uint SafePointNode::match_edge(uint idx) const {
-  if( !needs_polling_address_input() )
-    return 0;
-
   return (TypeFunc::Parms == idx);
 }
 
 void SafePointNode::disconnect_from_root(PhaseIterGVN *igvn) {
   assert(Opcode() == Op_SafePoint, "only value for safepoint in loops");
diff a/src/hotspot/share/opto/classes.hpp b/src/hotspot/share/opto/classes.hpp
--- a/src/hotspot/share/opto/classes.hpp
+++ b/src/hotspot/share/opto/classes.hpp
@@ -312,10 +312,11 @@
 macro(SubF)
 macro(SubI)
 macro(SubL)
 macro(TailCall)
 macro(TailJump)
+macro(MacroLogicV)
 macro(ThreadLocal)
 macro(Unlock)
 macro(URShiftI)
 macro(URShiftL)
 macro(XorI)
diff a/src/hotspot/share/opto/compile.cpp b/src/hotspot/share/opto/compile.cpp
--- a/src/hotspot/share/opto/compile.cpp
+++ b/src/hotspot/share/opto/compile.cpp
@@ -75,10 +75,11 @@
 #include "runtime/stubRoutines.hpp"
 #include "runtime/timer.hpp"
 #include "utilities/align.hpp"
 #include "utilities/copy.hpp"
 #include "utilities/macros.hpp"
+#include "utilities/resourceHash.hpp"
 
 
 // -------------------- Compile::mach_constant_base_node -----------------------
 // Constant table base node singleton.
 MachConstantBaseNode* Compile::mach_constant_base_node() {
@@ -2630,10 +2631,15 @@
   if (opaque4_count() > 0) {
     C->remove_opaque4_nodes(igvn);
     igvn.optimize();
   }
 
+  if (C->max_vector_size() > 0) {
+    C->optimize_logic_cones(igvn);
+    igvn.optimize();
+  }
+
   DEBUG_ONLY( _modified_nodes = NULL; )
  } // (End scope of igvn; run destructor if necessary for asserts.)
 
  process_print_inlining();
  // A method with only infinite loops has no edges entering loops from root
@@ -2646,10 +2652,322 @@
  }
 
  print_method(PHASE_OPTIMIZE_FINISHED, 2);
 }
 
+//---------------------------- Bitwise operation packing optimization ---------------------------
+
+static bool is_vector_unary_bitwise_op(Node* n) {
+  return n->Opcode() == Op_XorV &&
+         VectorNode::is_vector_bitwise_not_pattern(n);
+}
+
+static bool is_vector_binary_bitwise_op(Node* n) {
+  switch (n->Opcode()) {
+    case Op_AndV:
+    case Op_OrV:
+      return true;
+
+    case Op_XorV:
+      return !is_vector_unary_bitwise_op(n);
+
+    default:
+      return false;
+  }
+}
+
+static bool is_vector_ternary_bitwise_op(Node* n) {
+  return n->Opcode() == Op_MacroLogicV;
+}
+
+static bool is_vector_bitwise_op(Node* n) {
+  return is_vector_unary_bitwise_op(n)  ||
+         is_vector_binary_bitwise_op(n) ||
+         is_vector_ternary_bitwise_op(n);
+}
+
+static bool is_vector_bitwise_cone_root(Node* n) {
+  if (!is_vector_bitwise_op(n)) {
+    return false;
+  }
+  for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {
+    if (is_vector_bitwise_op(n->fast_out(i))) {
+      return false;
+    }
+  }
+  return true;
+}
+
+static uint collect_unique_inputs(Node* n, Unique_Node_List& partition, Unique_Node_List& inputs) {
+  uint cnt = 0;
+  if (is_vector_bitwise_op(n)) {
+    if (VectorNode::is_vector_bitwise_not_pattern(n)) {
+      for (uint i = 1; i < n->req(); i++) {
+        Node* in = n->in(i);
+        bool skip = VectorNode::is_all_ones_vector(in);
+        if (!skip && !inputs.member(in)) {
+          inputs.push(in);
+          cnt++;
+        }
+      }
+      assert(cnt <= 1, "not unary");
+    } else {
+      uint last_req = n->req();
+      if (is_vector_ternary_bitwise_op(n)) {
+        last_req = n->req() - 1; // skip last input
+      }
+      for (uint i = 1; i < last_req; i++) {
+        Node* def = n->in(i);
+        if (!inputs.member(def)) {
+          inputs.push(def);
+          cnt++;
+        }
+      }
+    }
+    partition.push(n);
+  } else { // not a bitwise operations
+    if (!inputs.member(n)) {
+      inputs.push(n);
+      cnt++;
+    }
+  }
+  return cnt;
+}
+
+void Compile::collect_logic_cone_roots(Unique_Node_List& list) {
+  Unique_Node_List useful_nodes;
+  C->identify_useful_nodes(useful_nodes);
+
+  for (uint i = 0; i < useful_nodes.size(); i++) {
+    Node* n = useful_nodes.at(i);
+    if (is_vector_bitwise_cone_root(n)) {
+      list.push(n);
+    }
+  }
+}
+
+Node* Compile::xform_to_MacroLogicV(PhaseIterGVN& igvn,
+                                    const TypeVect* vt,
+                                    Unique_Node_List& partition,
+                                    Unique_Node_List& inputs) {
+  assert(partition.size() == 2 || partition.size() == 3, "not supported");
+  assert(inputs.size()    == 2 || inputs.size()    == 3, "not supported");
+  assert(Matcher::match_rule_supported_vector(Op_MacroLogicV, vt->length(), vt->element_basic_type()), "not supported");
+
+  Node* in1 = inputs.at(0);
+  Node* in2 = inputs.at(1);
+  Node* in3 = (inputs.size() == 3 ? inputs.at(2) : in2);
+
+  uint func = compute_truth_table(partition, inputs);
+  return igvn.transform(MacroLogicVNode::make(igvn, in3, in2, in1, func, vt));
+}
+
+static uint extract_bit(uint func, uint pos) {
+  return (func & (1 << pos)) >> pos;
+}
+
+//
+//  A macro logic node represents a truth table. It has 4 inputs,
+//  First three inputs corresponds to 3 columns of a truth table
+//  and fourth input captures the logic function.
+//
+//  eg.  fn = (in1 AND in2) OR in3;
+//
+//      MacroNode(in1,in2,in3,fn)
+//
+//  -----------------
+//  in1 in2 in3  fn
+//  -----------------
+//  0    0   0    0
+//  0    0   1    1
+//  0    1   0    0
+//  0    1   1    1
+//  1    0   0    0
+//  1    0   1    1
+//  1    1   0    1
+//  1    1   1    1
+//
+
+uint Compile::eval_macro_logic_op(uint func, uint in1 , uint in2, uint in3) {
+  int res = 0;
+  for (int i = 0; i < 8; i++) {
+    int bit1 = extract_bit(in1, i);
+    int bit2 = extract_bit(in2, i);
+    int bit3 = extract_bit(in3, i);
+
+    int func_bit_pos = (bit1 << 2 | bit2 << 1 | bit3);
+    int func_bit = extract_bit(func, func_bit_pos);
+
+    res |= func_bit << i;
+  }
+  return res;
+}
+
+static uint eval_operand(Node* n, ResourceHashtable<Node*,uint>& eval_map) {
+  assert(n != NULL, "");
+  assert(eval_map.contains(n), "absent");
+  return *(eval_map.get(n));
+}
+
+static void eval_operands(Node* n,
+                          uint& func1, uint& func2, uint& func3,
+                          ResourceHashtable<Node*,uint>& eval_map) {
+  assert(is_vector_bitwise_op(n), "");
+  func1 = eval_operand(n->in(1), eval_map);
+
+  if (is_vector_binary_bitwise_op(n)) {
+    func2 = eval_operand(n->in(2), eval_map);
+  } else if (is_vector_ternary_bitwise_op(n)) {
+    func2 = eval_operand(n->in(2), eval_map);
+    func3 = eval_operand(n->in(3), eval_map);
+  } else {
+    assert(is_vector_unary_bitwise_op(n), "not unary");
+  }
+}
+
+uint Compile::compute_truth_table(Unique_Node_List& partition, Unique_Node_List& inputs) {
+  assert(inputs.size() <= 3, "sanity");
+  ResourceMark rm;
+  uint res = 0;
+  ResourceHashtable<Node*,uint> eval_map;
+
+  // Populate precomputed functions for inputs.
+  // Each input corresponds to one column of 3 input truth-table.
+  uint input_funcs[] = { 0xAA,   // (_, _, a) -> a
+                         0xCC,   // (_, b, _) -> b
+                         0xF0 }; // (c, _, _) -> c
+  for (uint i = 0; i < inputs.size(); i++) {
+    eval_map.put(inputs.at(i), input_funcs[i]);
+  }
+
+  for (uint i = 0; i < partition.size(); i++) {
+    Node* n = partition.at(i);
+
+    uint func1 = 0, func2 = 0, func3 = 0;
+    eval_operands(n, func1, func2, func3, eval_map);
+
+    switch (n->Opcode()) {
+      case Op_OrV:
+        assert(func3 == 0, "not binary");
+        res = func1 | func2;
+        break;
+      case Op_AndV:
+        assert(func3 == 0, "not binary");
+        res = func1 & func2;
+        break;
+      case Op_XorV:
+        if (VectorNode::is_vector_bitwise_not_pattern(n)) {
+          assert(func2 == 0 && func3 == 0, "not unary");
+          res = (~func1) & 0xFF;
+        } else {
+          assert(func3 == 0, "not binary");
+          res = func1 ^ func2;
+        }
+        break;
+      case Op_MacroLogicV:
+        // Ordering of inputs may change during evaluation of sub-tree
+        // containing MacroLogic node as a child node, thus a re-evaluation
+        // makes sure that function is evaluated in context of current
+        // inputs.
+        res = eval_macro_logic_op(n->in(4)->get_int(), func1, func2, func3);
+        break;
+
+      default: assert(false, "not supported: %s", n->Name());
+    }
+    assert(res <= 0xFF, "invalid");
+    eval_map.put(n, res);
+  }
+  return res;
+}
+
+bool Compile::compute_logic_cone(Node* n, Unique_Node_List& partition, Unique_Node_List& inputs) {
+  assert(partition.size() == 0, "not empty");
+  assert(inputs.size() == 0, "not empty");
+  assert(!is_vector_ternary_bitwise_op(n), "not supported");
+
+  bool is_unary_op = is_vector_unary_bitwise_op(n);
+  if (is_unary_op) {
+    assert(collect_unique_inputs(n, partition, inputs) == 1, "not unary");
+    return false; // too few inputs
+  }
+
+  assert(is_vector_binary_bitwise_op(n), "not binary");
+  Node* in1 = n->in(1);
+  Node* in2 = n->in(2);
+
+  int in1_unique_inputs_cnt = collect_unique_inputs(in1, partition, inputs);
+  int in2_unique_inputs_cnt = collect_unique_inputs(in2, partition, inputs);
+  partition.push(n);
+
+  // Too many inputs?
+  if (inputs.size() > 3) {
+    partition.clear();
+    inputs.clear();
+    { // Recompute in2 inputs
+      Unique_Node_List not_used;
+      in2_unique_inputs_cnt = collect_unique_inputs(in2, not_used, not_used);
+    }
+    // Pick the node with minimum number of inputs.
+    if (in1_unique_inputs_cnt >= 3 && in2_unique_inputs_cnt >= 3) {
+      return false; // still too many inputs
+    }
+    // Recompute partition & inputs.
+    Node* child       = (in1_unique_inputs_cnt < in2_unique_inputs_cnt ? in1 : in2);
+    collect_unique_inputs(child, partition, inputs);
+
+    Node* other_input = (in1_unique_inputs_cnt < in2_unique_inputs_cnt ? in2 : in1);
+    inputs.push(other_input);
+
+    partition.push(n);
+  }
+
+  return (partition.size() == 2 || partition.size() == 3) &&
+         (inputs.size()    == 2 || inputs.size()    == 3);
+}
+
+void Compile::process_logic_cone_root(PhaseIterGVN &igvn, Node *n, VectorSet &visited) {
+  assert(is_vector_bitwise_op(n), "not a root");
+
+  visited.set(n->_idx);
+
+  // 1) Do a DFS walk over the logic cone.
+  for (uint i = 1; i < n->req(); i++) {
+    Node* in = n->in(i);
+    if (!visited.test(in->_idx) && is_vector_bitwise_op(in)) {
+      process_logic_cone_root(igvn, in, visited);
+    }
+  }
+
+  // 2) Bottom up traversal: Merge node[s] with
+  // the parent to form macro logic node.
+  Unique_Node_List partition;
+  Unique_Node_List inputs;
+  if (compute_logic_cone(n, partition, inputs)) {
+    const TypeVect* vt = n->bottom_type()->is_vect();
+    Node* macro_logic = xform_to_MacroLogicV(igvn, vt, partition, inputs);
+    igvn.replace_node(n, macro_logic);
+  }
+}
+
+void Compile::optimize_logic_cones(PhaseIterGVN &igvn) {
+  ResourceMark rm;
+  if (Matcher::match_rule_supported(Op_MacroLogicV)) {
+    Unique_Node_List list;
+    collect_logic_cone_roots(list);
+
+    while (list.size() > 0) {
+      Node* n = list.pop();
+      const TypeVect* vt = n->bottom_type()->is_vect();
+      bool supported = Matcher::match_rule_supported_vector(Op_MacroLogicV, vt->length(), vt->element_basic_type());
+      if (supported) {
+        VectorSet visited(comp_arena());
+        process_logic_cone_root(igvn, n, visited);
+      }
+    }
+  }
+}
+
 //------------------------------Code_Gen---------------------------------------
 // Given a graph, generate code for it
 void Compile::Code_Gen() {
   if (failing()) {
     return;
@@ -4722,5 +5040,23 @@
   if (val != 0) {
     NodeCloneInfo ni(val);
     ni.dump();
   }
 }
+
+
+// Move Allocate nodes to the start of the list
+void Compile::sort_macro_nodes() {
+  int count = macro_count();
+  int allocates = 0;
+  for (int i = 0; i < count; i++) {
+    Node* n = macro_node(i);
+    if (n->is_Allocate()) {
+      if (i != allocates) {
+        Node* tmp = macro_node(allocates);
+        _macro_nodes->at_put(allocates, n);
+        _macro_nodes->at_put(i, tmp);
+      }
+      allocates++;
+    }
+  }
+}
diff a/src/hotspot/share/opto/compile.hpp b/src/hotspot/share/opto/compile.hpp
--- a/src/hotspot/share/opto/compile.hpp
+++ b/src/hotspot/share/opto/compile.hpp
@@ -82,12 +82,13 @@
 class TypeData;
 class TypeInt;
 class TypePtr;
 class TypeOopPtr;
 class TypeFunc;
-class ValueTypeBaseNode;
+class TypeVect;
 class Unique_Node_List;
+class ValueTypeBaseNode;
 class nmethod;
 class WarmCallInfo;
 class Node_Stack;
 struct Final_Reshape_Counts;
 
@@ -736,10 +737,12 @@
   void process_value_types(PhaseIterGVN &igvn);
   bool can_add_value_type() const { return _value_type_nodes != NULL; }
 
   void adjust_flattened_array_access_aliases(PhaseIterGVN& igvn);
 
+  void sort_macro_nodes();
+
   // remove the opaque nodes that protect the predicates so that the unused checks and
   // uncommon traps will be eliminated from the graph.
   void cleanup_loop_predicates(PhaseIterGVN &igvn);
   bool is_predicate_opaq(Node * n) {
     return _predicate_opaqs->contains(n);
@@ -1122,10 +1125,19 @@
   void final_graph_reshaping_impl( Node *n, Final_Reshape_Counts &frc);
   void final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts& frc, uint nop);
   void final_graph_reshaping_walk( Node_Stack &nstack, Node *root, Final_Reshape_Counts &frc );
   void eliminate_redundant_card_marks(Node* n);
 
+  // Logic cone optimization.
+  void optimize_logic_cones(PhaseIterGVN &igvn);
+  void collect_logic_cone_roots(Unique_Node_List& list);
+  void process_logic_cone_root(PhaseIterGVN &igvn, Node* n, VectorSet& visited);
+  bool compute_logic_cone(Node* n, Unique_Node_List& partition, Unique_Node_List& inputs);
+  uint compute_truth_table(Unique_Node_List& partition, Unique_Node_List& inputs);
+  uint eval_macro_logic_op(uint func, uint op1, uint op2, uint op3);
+  Node* xform_to_MacroLogicV(PhaseIterGVN &igvn, const TypeVect* vt, Unique_Node_List& partitions, Unique_Node_List& inputs);
+
  public:
 
   // Note:  Histogram array size is about 1 Kb.
   enum {                        // flag bits:
     _intrinsic_worked = 1,      // succeeded at least once
diff a/src/hotspot/share/opto/loopUnswitch.cpp b/src/hotspot/share/opto/loopUnswitch.cpp
--- a/src/hotspot/share/opto/loopUnswitch.cpp
+++ b/src/hotspot/share/opto/loopUnswitch.cpp
@@ -314,19 +314,20 @@
 
   IfNode* unswitch_iff_clone = old_new[unswitch_iff->_idx]->as_If();
   if (flattened_checks.size() > 0) {
     for (uint i = 0; i < flattened_checks.size(); i++) {
       IfNode* iff = flattened_checks.at(i)->as_If();
-      _igvn.rehash_node_delayed(iff);
+      _igvn.rehash_node_delayed(iff);
       short_circuit_if(old_new[iff->_idx]->as_If(), proj_false);
     }
   } else {
     // Hardwire the control paths in the loops into if(true) and if(false)
-    _igvn.rehash_node_delayed(unswitch_iff);
+    _igvn.rehash_node_delayed(unswitch_iff);
     short_circuit_if(unswitch_iff, proj_true);
+
 
-    _igvn.rehash_node_delayed(unswitch_iff_clone);
+    _igvn.rehash_node_delayed(unswitch_iff_clone);
     short_circuit_if(unswitch_iff_clone, proj_false);
   }
 
   // Reoptimize loops
   loop->record_for_igvn();
diff a/src/hotspot/share/opto/machnode.cpp b/src/hotspot/share/opto/machnode.cpp
--- a/src/hotspot/share/opto/machnode.cpp
+++ b/src/hotspot/share/opto/machnode.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2017, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -668,12 +668,11 @@
 const RegMask &MachSafePointNode::in_RegMask( uint idx ) const {
   // Values in the domain use the users calling convention, embodied in the
   // _in_rms array of RegMasks.
   if( idx < TypeFunc::Parms ) return _in_rms[idx];
 
-  if (SafePointNode::needs_polling_address_input() &&
-      idx == TypeFunc::Parms &&
+  if (idx == TypeFunc::Parms &&
       ideal_Opcode() == Op_SafePoint) {
     return MachNode::in_RegMask(idx);
   }
 
   // Values outside the domain represent debug info
diff a/src/hotspot/share/opto/machnode.hpp b/src/hotspot/share/opto/machnode.hpp
--- a/src/hotspot/share/opto/machnode.hpp
+++ b/src/hotspot/share/opto/machnode.hpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -285,15 +285,16 @@
   // Helper function that computes size by emitting code
   virtual uint  emit_size(PhaseRegAlloc *ra_) const;
 
   // Return the alignment required (in units of relocInfo::addr_unit())
   // for this instruction (must be a power of 2)
-  virtual int   alignment_required() const { return 1; }
+  int           pd_alignment_required() const;
+  virtual int   alignment_required() const { return pd_alignment_required(); }
 
   // Return the padding (in bytes) to be emitted before this
   // instruction to properly align it.
-  virtual int   compute_padding(int current_offset) const { return 0; }
+  virtual int   compute_padding(int current_offset) const;
 
   // Return number of relocatable values contained in this instruction
   virtual int   reloc() const { return 0; }
 
   // Return number of words used for double constants in this instruction
@@ -557,13 +558,10 @@
   bool _do_polling;
 
 public:
   bool do_polling() const { return _do_polling; }
 
-  // Offset of safepoint from the beginning of the node
-  int safepoint_offset() const;
-
 #ifndef PRODUCT
   virtual const char *Name() const { return "Epilog"; }
   virtual void format( PhaseRegAlloc *, outputStream *st ) const;
 #endif
 };
diff a/src/hotspot/share/opto/macro.cpp b/src/hotspot/share/opto/macro.cpp
--- a/src/hotspot/share/opto/macro.cpp
+++ b/src/hotspot/share/opto/macro.cpp
@@ -2975,16 +2975,10 @@
 //  Returns true if a failure occurred.
 bool PhaseMacroExpand::expand_macro_nodes() {
   // Last attempt to eliminate macro nodes.
   eliminate_macro_nodes();
 
-  // Make sure expansion will not cause node limit to be exceeded.
-  // Worst case is a macro node gets expanded into about 200 nodes.
-  // Allow 50% more for optimization.
-  if (C->check_node_count(C->macro_count() * 300, "out of nodes before macro expansion" ) )
-    return true;
-
   // Eliminate Opaque and LoopLimit nodes. Do it after all loop optimizations.
   bool progress = true;
   while (progress) {
     progress = false;
     for (int i = C->macro_count(); i > 0; i--) {
@@ -3039,21 +3033,48 @@
       assert(!success || (C->macro_count() == (old_macro_count - 1)), "elimination must have deleted one node from macro list");
       progress = progress || success;
     }
   }
 
+  // Clean up the graph so we're less likely to hit the maximum node
+  // limit
+  _igvn.set_delay_transform(false);
+  _igvn.optimize();
+  if (C->failing())  return true;
+  _igvn.set_delay_transform(true);
+
+
+  // Because we run IGVN after each expansion, some macro nodes may go
+  // dead and be removed from the list as we iterate over it. Move
+  // Allocate nodes (processed in a second pass) at the beginning of
+  // the list and then iterate from the last element of the list until
+  // an Allocate node is seen. This is robust to random deletion in
+  // the list due to nodes going dead.
+  C->sort_macro_nodes();
+
   // expand arraycopy "macro" nodes first
   // For ReduceBulkZeroing, we must first process all arraycopy nodes
   // before the allocate nodes are expanded.
-  for (int i = C->macro_count(); i > 0; i--) {
-    Node* n = C->macro_node(i-1);
+  while (C->macro_count() > 0) {
+    int macro_count = C->macro_count();
+    Node * n = C->macro_node(macro_count-1);
     assert(n->is_macro(), "only macro nodes expected here");
     if (_igvn.type(n) == Type::TOP || (n->in(0) != NULL && n->in(0)->is_top())) {
       // node is unreachable, so don't try to expand it
       C->remove_macro_node(n);
       continue;
     }
+    if (n->is_Allocate()) {
+      break;
+    }
+    // Make sure expansion will not cause node limit to be exceeded.
+    // Worst case is a macro node gets expanded into about 200 nodes.
+    // Allow 50% more for optimization.
+    if (C->check_node_count(300, "out of nodes before macro expansion")) {
+      return true;
+    }
+
     debug_only(int old_macro_count = C->macro_count(););
     switch (n->class_id()) {
     case Node::Class_Lock:
       expand_lock_node(n->as_Lock());
       assert(C->macro_count() == (old_macro_count - 1), "expansion must have deleted one node from macro list");
@@ -3068,22 +3089,32 @@
       break;
     case Node::Class_SubTypeCheck:
       expand_subtypecheck_node(n->as_SubTypeCheck());
       assert(C->macro_count() == (old_macro_count - 1), "expansion must have deleted one node from macro list");
       break;
+    case Node::Class_CallStaticJava:
+      expand_mh_intrinsic_return(n->as_CallStaticJava());
+      C->remove_macro_node(n);
+      assert(C->macro_count() == (old_macro_count - 1), "expansion must have deleted one node from macro list");
+      break;
+    default:
+      assert(false, "unknown node type in macro list");
     }
+    assert(C->macro_count() < macro_count, "must have deleted a node from macro list");
+    if (C->failing())  return true;
+
+    // Clean up the graph so we're less likely to hit the maximum node
+    // limit
+    _igvn.set_delay_transform(false);
+    _igvn.optimize();
     if (C->failing())  return true;
+    _igvn.set_delay_transform(true);
   }
 
   // All nodes except Allocate nodes are expanded now. There could be
   // new optimization opportunities (such as folding newly created
   // load from a just allocated object). Run IGVN.
-  _igvn.set_delay_transform(false);
-  _igvn.optimize();
-  if (C->failing())  return true;
-
-  _igvn.set_delay_transform(true);
 
   // expand "macro" nodes
   // nodes are removed from the macro list as they are processed
   while (C->macro_count() > 0) {
     int macro_count = C->macro_count();
@@ -3092,28 +3123,35 @@
     if (_igvn.type(n) == Type::TOP || (n->in(0) != NULL && n->in(0)->is_top())) {
       // node is unreachable, so don't try to expand it
       C->remove_macro_node(n);
       continue;
     }
+    // Make sure expansion will not cause node limit to be exceeded.
+    // Worst case is a macro node gets expanded into about 200 nodes.
+    // Allow 50% more for optimization.
+    if (C->check_node_count(300, "out of nodes before macro expansion")) {
+      return true;
+    }
     switch (n->class_id()) {
     case Node::Class_Allocate:
       expand_allocate(n->as_Allocate());
       break;
     case Node::Class_AllocateArray:
       expand_allocate_array(n->as_AllocateArray());
       break;
-    case Node::Class_CallStaticJava:
-      expand_mh_intrinsic_return(n->as_CallStaticJava());
-      C->remove_macro_node(n);
-      break;
     default:
       assert(false, "unknown node type in macro list");
     }
     assert(C->macro_count() < macro_count, "must have deleted a node from macro list");
     if (C->failing())  return true;
+
+    // Clean up the graph so we're less likely to hit the maximum node
+    // limit
+    _igvn.set_delay_transform(false);
+    _igvn.optimize();
+    if (C->failing())  return true;
+    _igvn.set_delay_transform(true);
   }
 
   _igvn.set_delay_transform(false);
-  _igvn.optimize();
-  if (C->failing())  return true;
   return false;
 }
diff a/src/hotspot/share/opto/matcher.cpp b/src/hotspot/share/opto/matcher.cpp
--- a/src/hotspot/share/opto/matcher.cpp
+++ b/src/hotspot/share/opto/matcher.cpp
@@ -2280,10 +2280,11 @@
     case Op_EncodeISOArray:
     case Op_FmaD:
     case Op_FmaF:
     case Op_FmaVD:
     case Op_FmaVF:
+    case Op_MacroLogicV:
       set_shared(n); // Force result into register (it will be anyways)
       break;
     case Op_ConP: {  // Convert pointers above the centerline to NUL
       TypeNode *tn = n->as_Type(); // Constants derive from type nodes
       const TypePtr* tp = tn->type()->is_ptr();
@@ -2373,10 +2374,19 @@
       Node* pair2 = new BinaryNode(n->in(2), n->in(3));
       n->set_req(2, pair2);
       n->del_req(3);
       break;
     }
+    case Op_MacroLogicV: {
+      Node* pair1 = new BinaryNode(n->in(1), n->in(2));
+      Node* pair2 = new BinaryNode(n->in(3), n->in(4));
+      n->set_req(1, pair1);
+      n->set_req(2, pair2);
+      n->del_req(4);
+      n->del_req(3);
+      break;
+    }
     case Op_LoopLimit: {
       Node* pair1 = new BinaryNode(n->in(1), n->in(2));
       n->set_req(1, pair1);
       n->set_req(2, n->in(3));
       n->del_req(3);
diff a/src/hotspot/share/opto/node.cpp b/src/hotspot/share/opto/node.cpp
--- a/src/hotspot/share/opto/node.cpp
+++ b/src/hotspot/share/opto/node.cpp
@@ -26,10 +26,11 @@
 #include "gc/shared/barrierSet.hpp"
 #include "gc/shared/c2/barrierSetC2.hpp"
 #include "libadt/vectset.hpp"
 #include "memory/allocation.inline.hpp"
 #include "memory/resourceArea.hpp"
+#include "opto/ad.hpp"
 #include "opto/castnode.hpp"
 #include "opto/cfgnode.hpp"
 #include "opto/connode.hpp"
 #include "opto/loopnode.hpp"
 #include "opto/machnode.hpp"
@@ -1037,11 +1038,16 @@
 }
 
 //------------------------------init_NodeProperty------------------------------
 void Node::init_NodeProperty() {
   assert(_max_classes <= max_jushort, "too many NodeProperty classes");
-  assert(_max_flags <= max_jushort, "too many NodeProperty flags");
+  assert(max_flags() <= max_jushort, "too many NodeProperty flags");
+}
+
+//-----------------------------max_flags---------------------------------------
+juint Node::max_flags() {
+  return (PD::_last_flag << 1) - 1; // allow flags combination
 }
 #endif
 
 //------------------------------format-----------------------------------------
 // Print as assembly
diff a/src/hotspot/share/opto/node.hpp b/src/hotspot/share/opto/node.hpp
--- a/src/hotspot/share/opto/node.hpp
+++ b/src/hotspot/share/opto/node.hpp
@@ -748,29 +748,32 @@
     Flag_has_call                    = Flag_avoid_back_to_back_after << 1,
     Flag_is_reduction                = Flag_has_call << 1,
     Flag_is_scheduled                = Flag_is_reduction << 1,
     Flag_has_vector_mask_set         = Flag_is_scheduled << 1,
     Flag_is_expensive                = Flag_has_vector_mask_set << 1,
-    Flag_intel_jcc_erratum           = Flag_is_expensive << 1,
-    _max_flags = (Flag_intel_jcc_erratum << 1) - 1 // allow flags combination
+    _last_flag                       = Flag_is_expensive
   };
 
+  class PD;
+
 private:
   jushort _class_id;
   jushort _flags;
 
+  static juint max_flags();
+
 protected:
   // These methods should be called from constructors only.
   void init_class_id(jushort c) {
     _class_id = c; // cast out const
   }
   void init_flags(uint fl) {
-    assert(fl <= _max_flags, "invalid node flag");
+    assert(fl <= max_flags(), "invalid node flag");
     _flags |= fl;
   }
   void clear_flag(uint fl) {
-    assert(fl <= _max_flags, "invalid node flag");
+    assert(fl <= max_flags(), "invalid node flag");
     _flags &= ~fl;
   }
 
 public:
   const jushort class_id() const { return _class_id; }
diff a/src/hotspot/share/opto/output.cpp b/src/hotspot/share/opto/output.cpp
--- a/src/hotspot/share/opto/output.cpp
+++ b/src/hotspot/share/opto/output.cpp
@@ -51,13 +51,10 @@
 #include "runtime/handles.inline.hpp"
 #include "runtime/sharedRuntime.hpp"
 #include "utilities/macros.hpp"
 #include "utilities/powerOfTwo.hpp"
 #include "utilities/xmlstream.hpp"
-#ifdef X86
-#include "c2_intelJccErratum_x86.hpp"
-#endif
 
 #ifndef PRODUCT
 #define DEBUG_ARG(x) , x
 #else
 #define DEBUG_ARG(x)
@@ -243,11 +240,14 @@
     _node_bundling_limit(0),
     _node_bundling_base(NULL),
     _orig_pc_slot(0),
     _orig_pc_slot_offset_in_bytes(0),
     _sp_inc_slot(0),
-    _sp_inc_slot_offset_in_bytes(0) {
+    _sp_inc_slot_offset_in_bytes(0),
+    _buf_sizes(),
+    _block(NULL),
+    _index(0) {
   C->set_output(this);
   if (C->stub_name() == NULL) {
     int fixed_slots = C->fixed_slots();
     if (C->needs_stack_repair()) {
       fixed_slots -= 2;
@@ -262,10 +262,19 @@
   if (_scratch_buffer_blob != NULL) {
     BufferBlob::free(_scratch_buffer_blob);
   }
 }
 
+void PhaseOutput::perform_mach_node_analysis() {
+  // Late barrier analysis must be done after schedule and bundle
+  // Otherwise liveness based spilling will fail
+  BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();
+  bs->late_barrier_analysis();
+
+  pd_perform_mach_node_analysis();
+}
+
 // Convert Nodes to instruction bits and pass off to the VM
 void PhaseOutput::Output() {
   // RootNode goes
   assert( C->cfg()->get_root_block()->number_of_nodes() == 0, "" );
 
@@ -335,22 +344,22 @@
       }
     }
   }
 
   // Keeper of sizing aspects
-  BufferSizingData buf_sizes = BufferSizingData();
+  _buf_sizes = BufferSizingData();
 
   // Initialize code buffer
-  estimate_buffer_size(buf_sizes._const);
+  estimate_buffer_size(_buf_sizes._const);
   if (C->failing()) return;
 
   // Pre-compute the length of blocks and replace
   // long branches with short if machine supports it.
   // Must be done before ScheduleAndBundle due to SPARC delay slots
   uint* blk_starts = NEW_RESOURCE_ARRAY(uint, C->cfg()->number_of_blocks() + 1);
   blk_starts[0] = 0;
-  shorten_branches(blk_starts, buf_sizes);
+  shorten_branches(blk_starts);
 
   if (!C->is_osr_compilation() && C->has_scalarized_args()) {
     // Compute the offsets of the entry points required by the value type calling convention
     if (!C->method()->is_static()) {
       // We have entries at the beginning of the method, implemented by the first 4 nodes.
@@ -378,24 +387,14 @@
   ScheduleAndBundle();
   if (C->failing()) {
     return;
   }
 
-  // Late barrier analysis must be done after schedule and bundle
-  // Otherwise liveness based spilling will fail
-  BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();
-  bs->late_barrier_analysis();
-
-#ifdef X86
-  if (VM_Version::has_intel_jcc_erratum()) {
-    int extra_padding = IntelJccErratum::tag_affected_machnodes(C, C->cfg(), C->regalloc());
-    buf_sizes._code += extra_padding;
-  }
-#endif
+  perform_mach_node_analysis();
 
   // Complete sizing of codebuffer
-  CodeBuffer* cb = init_buffer(buf_sizes);
+  CodeBuffer* cb = init_buffer();
   if (cb == NULL || C->failing()) {
     return;
   }
 
   BuildOopMaps();
@@ -473,11 +472,11 @@
   } // if( MaxLoopPad < OptoLoopAlignment-1 )
 }
 
 // The architecture description provides short branch variants for some long
 // branch instructions. Replace eligible long branches with short branches.
-void PhaseOutput::shorten_branches(uint* blk_starts, BufferSizingData& buf_sizes) {
+void PhaseOutput::shorten_branches(uint* blk_starts) {
   // Compute size of each block, method size, and relocation information size
   uint nblocks  = C->cfg()->number_of_blocks();
 
   uint*      jmp_offset = NEW_RESOURCE_ARRAY(uint,nblocks);
   uint*      jmp_size   = NEW_RESOURCE_ARRAY(uint,nblocks);
@@ -508,10 +507,11 @@
   uint last_call_adr = max_juint;
   uint last_avoid_back_to_back_adr = max_juint;
   uint nop_size = (new MachNopNode())->size(C->regalloc());
   for (uint i = 0; i < nblocks; i++) { // For all blocks
     Block* block = C->cfg()->get_block(i);
+    _block = block;
 
     // During short branch replacement, we store the relative (to blk_starts)
     // offset of jump in jmp_offset, rather than the absolute offset of jump.
     // This is so that we do not need to recompute sizes of all nodes when
     // we compute correct blk_starts in our next sizing pass.
@@ -523,22 +523,16 @@
 
     // Sum all instruction sizes to compute block size
     uint last_inst = block->number_of_nodes();
     uint blk_size = 0;
     for (uint j = 0; j < last_inst; j++) {
-      Node* nj = block->get_node(j);
+      _index = j;
+      Node* nj = block->get_node(_index);
       // Handle machine instruction nodes
       if (nj->is_Mach()) {
-        MachNode *mach = nj->as_Mach();
+        MachNode* mach = nj->as_Mach();
         blk_size += (mach->alignment_required() - 1) * relocInfo::addr_unit(); // assume worst case padding
-#ifdef X86
-        if (VM_Version::has_intel_jcc_erratum() && IntelJccErratum::is_jcc_erratum_branch(block, mach, j)) {
-          // Conservatively add worst case padding
-          blk_size += IntelJccErratum::largest_jcc_size();
-        }
-#endif
-
         reloc_size += mach->reloc();
         if (mach->is_MachCall()) {
           // add size information for trampoline stub
           // class CallStubImpl is platform-specific and defined in the *.ad files.
           stub_size  += CallStubImpl::size_call_trampoline();
@@ -739,13 +733,13 @@
   // Min is 2 bytes, max is probably 6 or 8, with a tax up to 25% for
   // a relocation index.
   // The CodeBuffer will expand the locs array if this estimate is too low.
   reloc_size *= 10 / sizeof(relocInfo);
 
-  buf_sizes._reloc = reloc_size;
-  buf_sizes._code  = code_size;
-  buf_sizes._stub  = stub_size;
+  _buf_sizes._reloc = reloc_size;
+  _buf_sizes._code  = code_size;
+  _buf_sizes._stub  = stub_size;
 }
 
 //------------------------------FillLocArray-----------------------------------
 // Create a bit of debug info and append it to the array.  The mapping is from
 // Java local or expression stack to constant, register or stack-slot.  For
@@ -1289,15 +1283,14 @@
   // Initialize the space for the BufferBlob used to find and verify
   // instruction size in MachNode::emit_size()
   init_scratch_buffer_blob(const_req);
 }
 
-CodeBuffer* PhaseOutput::init_buffer(BufferSizingData& buf_sizes) {
-
-  int stub_req  = buf_sizes._stub;
-  int code_req  = buf_sizes._code;
-  int const_req = buf_sizes._const;
+CodeBuffer* PhaseOutput::init_buffer() {
+  int stub_req  = _buf_sizes._stub;
+  int code_req  = _buf_sizes._code;
+  int const_req = _buf_sizes._const;
 
   int pad_req   = NativeCall::instruction_size;
 
   BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();
   stub_req += bs->estimate_stub_size();
@@ -1322,11 +1315,11 @@
 
   if (C->has_method_handle_invokes())
     total_req += deopt_handler_req;  // deopt MH handler
 
   CodeBuffer* cb = code_buffer();
-  cb->initialize(total_req, buf_sizes._reloc);
+  cb->initialize(total_req, _buf_sizes._reloc);
 
   // Have we run out of code space?
   if ((cb->blob() == NULL) || (!CompileBroker::should_compile_new_jobs())) {
     C->record_failure("CodeCache is full");
     return NULL;
@@ -1411,10 +1404,11 @@
   // Now fill in the code buffer
   Node *delay_slot = NULL;
 
   for (uint i = 0; i < nblocks; i++) {
     Block* block = C->cfg()->get_block(i);
+    _block = block;
     Node* head = block->head();
 
     // If this block needs to start aligned (i.e, can be reached other
     // than by falling-thru from the previous block), then force the
     // start of a new bundle.
@@ -1441,10 +1435,11 @@
     uint last_inst = block->number_of_nodes();
 
     // Emit block normally, except for last instruction.
     // Emit means "dump code bits into code buffer".
     for (uint j = 0; j<last_inst; j++) {
+      _index = j;
 
       // Get the node
       Node* n = block->get_node(j);
 
       // See if delay slots are supported
@@ -1487,16 +1482,10 @@
         if (padding == 0 && mach->avoid_back_to_back(MachNode::AVOID_BEFORE) &&
             current_offset == last_avoid_back_to_back_offset) {
           // Avoid back to back some instructions.
           padding = nop_size;
         }
-#ifdef X86
-        if (mach->flags() & Node::Flag_intel_jcc_erratum) {
-          assert(padding == 0, "can't have contradicting padding requirements");
-          padding = IntelJccErratum::compute_padding(current_offset, mach, block, j, C->regalloc());
-        }
-#endif
 
         if (padding > 0) {
           assert((padding % nop_size) == 0, "padding is not a multiple of NOP size");
           int nops_cnt = padding / nop_size;
           MachNode *nop = new MachNopNode(nops_cnt);
diff a/src/hotspot/share/opto/output.hpp b/src/hotspot/share/opto/output.hpp
--- a/src/hotspot/share/opto/output.hpp
+++ b/src/hotspot/share/opto/output.hpp
@@ -97,10 +97,17 @@
   int                    _sp_inc_slot;
   int                    _sp_inc_slot_offset_in_bytes;
 
   ConstantTable          _constant_table;        // The constant table for this compilation unit.
 
+  BufferSizingData       _buf_sizes;
+  Block*                 _block;
+  uint                   _index;
+
+  void perform_mach_node_analysis();
+  void pd_perform_mach_node_analysis();
+
 public:
   PhaseOutput();
   ~PhaseOutput();
 
   // Convert Nodes to instruction bits and pass off to the VM
@@ -120,24 +127,28 @@
                     bool        caller_must_gc_arguments);
 
   // Constant table
   ConstantTable& constant_table() { return _constant_table; }
 
+  // Code emission iterator
+  Block* block()   { return _block; }
+  int index()      { return _index; }
+
   // The architecture description provides short branch variants for some long
   // branch instructions. Replace eligible long branches with short branches.
-  void shorten_branches(uint* blk_starts, BufferSizingData& buf_sizes);
+  void shorten_branches(uint* blk_starts);
   ObjectValue* sv_for_node_id(GrowableArray<ScopeValue*> *objs, int id);
   void set_sv_for_object_node(GrowableArray<ScopeValue*> *objs, ObjectValue* sv);
   void FillLocArray( int idx, MachSafePointNode* sfpt, Node *local,
                      GrowableArray<ScopeValue*> *array,
                      GrowableArray<ScopeValue*> *objs );
 
   void Process_OopMap_Node(MachNode *mach, int current_offset);
 
   // Initialize code buffer
   void estimate_buffer_size(int& const_req);
-  CodeBuffer* init_buffer(BufferSizingData& buf_sizes);
+  CodeBuffer* init_buffer();
 
   // Write out basic block data to code buffer
   void fill_buffer(CodeBuffer* cb, uint* blk_starts);
 
   // Compute the information for the exception tables
diff a/src/hotspot/share/opto/parse1.cpp b/src/hotspot/share/opto/parse1.cpp
--- a/src/hotspot/share/opto/parse1.cpp
+++ b/src/hotspot/share/opto/parse1.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -2425,12 +2425,11 @@
 //------------------------------add_safepoint----------------------------------
 void Parse::add_safepoint() {
   // See if we can avoid this safepoint.  No need for a SafePoint immediately
   // after a Call (except Leaf Call) or another SafePoint.
   Node *proj = control();
-  bool add_poll_param = SafePointNode::needs_polling_address_input();
-  uint parms = add_poll_param ? TypeFunc::Parms+1 : TypeFunc::Parms;
+  uint parms = TypeFunc::Parms+1;
   if( proj->is_Proj() ) {
     Node *n0 = proj->in(0);
     if( n0->is_Catch() ) {
       n0 = n0->in(0)->in(0);
       assert( n0->is_Call(), "expect a call here" );
@@ -2473,21 +2472,15 @@
   sfpnt->init_req(TypeFunc::Memory   , mem   );
   sfpnt->init_req(TypeFunc::ReturnAdr, top() );
   sfpnt->init_req(TypeFunc::FramePtr , top() );
 
   // Create a node for the polling address
-  if( add_poll_param ) {
-    Node *polladr;
-    if (SafepointMechanism::uses_thread_local_poll()) {
-      Node *thread = _gvn.transform(new ThreadLocalNode());
-      Node *polling_page_load_addr = _gvn.transform(basic_plus_adr(top(), thread, in_bytes(Thread::polling_page_offset())));
-      polladr = make_load(control(), polling_page_load_addr, TypeRawPtr::BOTTOM, T_ADDRESS, Compile::AliasIdxRaw, MemNode::unordered);
-    } else {
-      polladr = ConPNode::make((address)os::get_polling_page());
-    }
-    sfpnt->init_req(TypeFunc::Parms+0, _gvn.transform(polladr));
-  }
+  Node *polladr;
+  Node *thread = _gvn.transform(new ThreadLocalNode());
+  Node *polling_page_load_addr = _gvn.transform(basic_plus_adr(top(), thread, in_bytes(Thread::polling_page_offset())));
+  polladr = make_load(control(), polling_page_load_addr, TypeRawPtr::BOTTOM, T_ADDRESS, Compile::AliasIdxRaw, MemNode::unordered);
+  sfpnt->init_req(TypeFunc::Parms+0, _gvn.transform(polladr));
 
   // Fix up the JVM State edges
   add_safepoint_edges(sfpnt);
   Node *transformed_sfpnt = _gvn.transform(sfpnt);
   set_control(transformed_sfpnt);
diff a/src/hotspot/share/opto/subtypenode.cpp b/src/hotspot/share/opto/subtypenode.cpp
--- a/src/hotspot/share/opto/subtypenode.cpp
+++ b/src/hotspot/share/opto/subtypenode.cpp
@@ -22,13 +22,15 @@
  *
  */
 
 #include "precompiled.hpp"
 #include "opto/addnode.hpp"
+#include "opto/callnode.hpp"
 #include "opto/connode.hpp"
 #include "opto/convertnode.hpp"
 #include "opto/phaseX.hpp"
+#include "opto/rootnode.hpp"
 #include "opto/subnode.hpp"
 #include "opto/subtypenode.hpp"
 
 const Type* SubTypeCheckNode::sub(const Type* sub_t, const Type* super_t) const {
   ciKlass* superk = super_t->is_klassptr()->klass();
@@ -135,16 +137,25 @@
   }
 
   if (addr != NULL) {
     intptr_t con = 0;
     Node* obj = AddPNode::Ideal_base_and_offset(addr, phase, con);
-    if (con == oopDesc::klass_offset_in_bytes() && obj != NULL && phase->type(obj)->isa_oopptr()) {
+    if (con == oopDesc::klass_offset_in_bytes() && obj != NULL) {
+      assert(phase->type(obj)->isa_oopptr(), "only for oop input");
       set_req(ObjOrSubKlass, obj);
       return this;
     }
   }
 
+  // AllocateNode might have more accurate klass input
+  Node* allocated_klass = AllocateNode::Ideal_klass(obj_or_subklass, phase);
+  if (allocated_klass != NULL) {
+    assert(phase->type(obj_or_subklass)->isa_oopptr(), "only for oop input");
+    set_req(ObjOrSubKlass, allocated_klass);
+    return this;
+  }
+
   // Verify that optimizing the subtype check to a simple code pattern
   // when possible would not constant fold better
 #ifdef ASSERT
   ciKlass* superk = super_t->is_klassptr()->klass();
   ciKlass* subk   = sub_t->isa_klassptr() ? sub_t->is_klassptr()->klass() : sub_t->is_oopptr()->klass();
@@ -156,12 +167,23 @@
       subklass = phase->transform(LoadKlassNode::make(*phase, NULL, phase->C->immutable_memory(), adr, TypeInstPtr::KLASS));
     } else {
       subklass = obj_or_subklass;
     }
     Node* res = new CmpPNode(subklass, superklass);
-    const Type* t = phase->type(phase->transform(res));
-    assert((Value(phase) == t) || (t != TypeInt::CC_GT && t != TypeInt::CC_EQ), "missing Value() optimization");
+    Node* cmp = phase->transform(res);
+    const Type* t = phase->type(cmp);
+    if (!((Value(phase) == t) || (t != TypeInt::CC_GT && t != TypeInt::CC_EQ))) {
+      Value(phase)->dump(); tty->cr();
+      t->dump(); tty->cr();
+      obj_or_subklass->dump();
+      subklass->dump();
+      superklass->dump();
+      cmp->dump();
+      tty->print_cr("==============================");
+      phase->C->root()->dump(9999);
+      fatal("missing Value() optimization");
+    }
     if (phase->is_IterGVN()) {
       phase->is_IterGVN()->_worklist.push(res);
     }
     return NULL;
   }
@@ -192,12 +214,24 @@
     Node *p2 = phase->transform(new AddPNode(subklass,subklass,chk_off_X));
     Node *kmem = phase->C->immutable_memory();
     Node *nkls = phase->transform(LoadKlassNode::make(*phase, NULL, kmem, p2, phase->type(p2)->is_ptr(), TypeKlassPtr::OBJECT_OR_NULL));
 
     Node* res = new CmpPNode(superklass, nkls);
-    const Type* t = phase->type(phase->transform(res));
-    assert((Value(phase) == t) || (t != TypeInt::CC_GT && t != TypeInt::CC_EQ), "missing Value() optimization");
+    Node* cmp = phase->transform(res);
+    const Type* t = phase->type(cmp);
+    if (!((Value(phase) == t) || (t != TypeInt::CC_GT && t != TypeInt::CC_EQ))) {
+      Value(phase)->dump(); tty->cr();
+      t->dump(); tty->cr();
+      obj_or_subklass->dump();
+      subklass->dump();
+      superklass->dump();
+      nkls->dump();
+      cmp->dump();
+      tty->print_cr("==============================");
+      phase->C->root()->dump(9999);
+      fatal("missing Value() optimization");
+    }
     if (phase->is_IterGVN()) {
       phase->is_IterGVN()->_worklist.push(res);
     }
     return NULL;
   }
diff a/src/hotspot/share/runtime/biasedLocking.cpp b/src/hotspot/share/runtime/biasedLocking.cpp
--- a/src/hotspot/share/runtime/biasedLocking.cpp
+++ b/src/hotspot/share/runtime/biasedLocking.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 2005, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 2005, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -622,11 +622,11 @@
   log_info(biasedlocking, handshake)("JavaThread " INTPTR_FORMAT " handshaking JavaThread "
                                      INTPTR_FORMAT " to revoke object " INTPTR_FORMAT, p2i(requester),
                                      p2i(biaser), p2i(obj()));
 
   RevokeOneBias revoke(obj, requester, biaser);
-  bool executed = Handshake::execute(&revoke, biaser);
+  bool executed = Handshake::execute_direct(&revoke, biaser);
   if (revoke.status_code() == NOT_REVOKED) {
     return NOT_REVOKED;
   }
   if (executed) {
     log_info(biasedlocking, handshake)("Handshake revocation for object " INTPTR_FORMAT " succeeded. Bias was %srevoked",
@@ -666,29 +666,28 @@
 }
 
 
 // Caller should have instantiated a ResourceMark object before calling this method
 void BiasedLocking::walk_stack_and_revoke(oop obj, JavaThread* biased_locker) {
-  assert(!SafepointSynchronize::is_at_safepoint() || !SafepointMechanism::uses_thread_local_poll(),
-         "if SafepointMechanism::uses_thread_local_poll() is enabled this should always be executed outside safepoints");
-  assert(Thread::current() == biased_locker || Thread::current()->is_VM_thread(), "wrong thread");
+  Thread* cur = Thread::current();
+  assert(!SafepointSynchronize::is_at_safepoint(), "this should always be executed outside safepoints");
+  assert(cur == biased_locker || cur == biased_locker->active_handshaker(), "wrong thread");
 
   markWord mark = obj->mark();
   assert(mark.biased_locker() == biased_locker &&
          obj->klass()->prototype_header().bias_epoch() == mark.bias_epoch(), "invariant");
 
-  log_trace(biasedlocking)("%s(" INTPTR_FORMAT ") revoking object " INTPTR_FORMAT ", mark "
+  log_trace(biasedlocking)("JavaThread(" INTPTR_FORMAT ") revoking object " INTPTR_FORMAT ", mark "
                            INTPTR_FORMAT ", type %s, prototype header " INTPTR_FORMAT
                            ", biaser " INTPTR_FORMAT " %s",
-                           Thread::current()->is_VM_thread() ? "VMThread" : "JavaThread",
-                           p2i(Thread::current()),
+                           p2i(cur),
                            p2i(obj),
                            mark.value(),
                            obj->klass()->external_name(),
                            obj->klass()->prototype_header().value(),
                            p2i(biased_locker),
-                           Thread::current()->is_VM_thread() ? "" : "(walking own stack)");
+                           cur != biased_locker ? "" : "(walking own stack)");
 
   markWord unbiased_prototype = markWord::prototype().set_age(obj->mark().age());
 
   GrowableArray<MonitorInfo*>* cached_monitor_info = get_or_compute_monitor_info(biased_locker);
   BasicLock* highest_lock = NULL;
diff a/src/hotspot/share/runtime/safepoint.cpp b/src/hotspot/share/runtime/safepoint.cpp
--- a/src/hotspot/share/runtime/safepoint.cpp
+++ b/src/hotspot/share/runtime/safepoint.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1997, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.
@@ -139,11 +139,10 @@
 const uint64_t SafepointSynchronize::InactiveSafepointCounter = 0;
 int SafepointSynchronize::_current_jni_active_count = 0;
 
 WaitBarrier* SafepointSynchronize::_wait_barrier;
 
-static volatile bool PageArmed = false;        // safepoint polling page is RO|RW vs PROT_NONE
 static bool timeout_error_printed = false;
 
 // Statistic related
 static jlong _safepoint_begin_time = 0;
 static volatile int _nof_threads_hit_polling_page = 0;
@@ -249,17 +248,10 @@
   do {
     // Check if this has taken too long:
     if (SafepointTimeout && safepoint_limit_time < os::javaTimeNanos()) {
       print_safepoint_timeout();
     }
-    if (int(iterations) == -1) { // overflow - something is wrong.
-      // We can only overflow here when we are using global
-      // polling pages. We keep this guarantee in its original
-      // form so that searches of the bug database for this
-      // failure mode find the right bugs.
-      guarantee (!PageArmed, "invariant");
-    }
 
     p_prev = &tss_head;
     ThreadSafepointState *cur_tss = tss_head;
     while (cur_tss != NULL) {
       assert(cur_tss->is_running(), "Illegal initial state");
@@ -296,13 +288,10 @@
   // stopped by different mechanisms:
   //
   //  1. Running interpreted
   //     When executing branching/returning byte codes interpreter
   //     checks if the poll is armed, if so blocks in SS::block().
-  //     When using global polling the interpreter dispatch table
-  //     is changed to force it to check for a safepoint condition
-  //     between bytecodes.
   //  2. Running in native code
   //     When returning from the native code, a Java thread must check
   //     the safepoint _state to see if we must block.  If the
   //     VM thread sees a Java thread in native, it does
   //     not wait for this thread to block.  The order of the memory
@@ -333,29 +322,18 @@
 
   // We are synchronizing
   OrderAccess::storestore(); // Ordered with _safepoint_counter
   _state = _synchronizing;
 
-  if (SafepointMechanism::uses_thread_local_poll()) {
-    // Arming the per thread poll while having _state != _not_synchronized means safepointing
-    log_trace(safepoint)("Setting thread local yield flag for threads");
-    OrderAccess::storestore(); // storestore, global state -> local state
-    for (JavaThreadIteratorWithHandle jtiwh; JavaThread *cur = jtiwh.next(); ) {
-      // Make sure the threads start polling, it is time to yield.
-      SafepointMechanism::arm_local_poll(cur);
-    }
+  // Arming the per thread poll while having _state != _not_synchronized means safepointing
+  log_trace(safepoint)("Setting thread local yield flag for threads");
+  OrderAccess::storestore(); // storestore, global state -> local state
+  for (JavaThreadIteratorWithHandle jtiwh; JavaThread *cur = jtiwh.next(); ) {
+    // Make sure the threads start polling, it is time to yield.
+    SafepointMechanism::arm_local_poll(cur);
   }
-  OrderAccess::fence(); // storestore|storeload, global state -> local state
-
-  if (SafepointMechanism::uses_global_page_poll()) {
-    // Make interpreter safepoint aware
-    Interpreter::notice_safepoints();
-
-    // Make polling safepoint aware
-    guarantee (!PageArmed, "invariant") ;
-    PageArmed = true;
-    os::make_polling_page_unreadable();
+
   }
 }
 
 // Roll all threads forward to a safepoint and suspend them all
 void SafepointSynchronize::begin() {
@@ -463,19 +441,10 @@
                 cur->safepoint_state()->is_at_poll_safepoint()),
               "safepoint installed a pending exception");
     }
 #endif // ASSERT
 
-    if (SafepointMechanism::uses_global_page_poll()) {
-      guarantee (PageArmed, "invariant");
-      // Make polling safepoint aware
-      os::make_polling_page_readable();
-      PageArmed = false;
-      // Remove safepoint check from interpreter
-      Interpreter::ignore_safepoints();
-    }
-
     OrderAccess::fence(); // keep read and write of _state from floating up
     assert(_state == _synchronized, "must be synchronized before ending safepoint synchronization");
 
     // Change state first to _not_synchronized.
     // No threads should see _synchronized when running.
@@ -493,12 +462,10 @@
       DEBUG_ONLY(current->reset_visited_for_critical_count(active_safepoint_counter);)
       ThreadSafepointState* cur_state = current->safepoint_state();
       assert(!cur_state->is_running(), "Thread not suspended at safepoint");
       cur_state->restart(); // TSS _running
       assert(cur_state->is_running(), "safepoint state has not been reset");
-
-      SafepointMechanism::disarm_if_needed(current, false /* NO release */);
     }
   } // ~JavaThreadIteratorWithHandle
 
   // Release threads lock, so threads can be created/destroyed again.
   Threads_lock->unlock();
@@ -735,11 +702,10 @@
     return false;
   }
 }
 
 bool SafepointSynchronize::handshake_safe(JavaThread *thread) {
-  assert(Thread::current()->is_VM_thread(), "Must be VMThread");
   if (thread->is_ext_suspended() || thread->is_terminated()) {
     return true;
   }
   JavaThreadState stable_state;
   if (try_stable_load_state(&stable_state, thread, InactiveSafepointCounter)) {
@@ -877,13 +843,10 @@
 
 
 void SafepointSynchronize::handle_polling_page_exception(JavaThread *thread) {
   assert(thread->is_Java_thread(), "polling reference encountered by VM thread");
   assert(thread->thread_state() == _thread_in_Java, "should come from Java code");
-  if (!SafepointMechanism::uses_thread_local_poll()) {
-    assert(SafepointSynchronize::is_synchronizing(), "polling encountered outside safepoint synchronization");
-  }
 
   if (log_is_enabled(Info, safepoint, stats)) {
     Atomic::inc(&_nof_threads_hit_polling_page);
   }
 
@@ -1048,15 +1011,10 @@
 // ---------------------------------------------------------------------------------------------------------------------
 
 // Block the thread at poll or poll return for safepoint/handshake.
 void ThreadSafepointState::handle_polling_page_exception() {
 
-  // If we're using a global poll, then the thread should not be
-  // marked as safepoint safe yet.
-  assert(!SafepointMechanism::uses_global_page_poll() || !_safepoint_safe,
-         "polling page exception on thread safepoint safe");
-
   // Step 1: Find the nmethod from the return address
   address real_return_addr = thread()->saved_exception_pc();
 
   CodeBlob *cb = CodeCache::find_blob(real_return_addr);
   assert(cb != NULL && cb->is_compiled(), "return address should be in nmethod");
diff a/src/hotspot/share/runtime/synchronizer.cpp b/src/hotspot/share/runtime/synchronizer.cpp
--- a/src/hotspot/share/runtime/synchronizer.cpp
+++ b/src/hotspot/share/runtime/synchronizer.cpp
@@ -1312,11 +1312,10 @@
   // scavenge costs.  As usual, we lean toward time in space-time
   // tradeoffs.
   const int MAXPRIVATE = 1024;
   NoSafepointVerifier nsv;
 
-  stringStream ss;
   for (;;) {
     ObjectMonitor* m;
 
     // 1: try to allocate from the thread's local om_free_list.
     // Threads will attempt to allocate first from their local list, then
@@ -1419,14 +1418,15 @@
                                     bool from_per_thread_alloc) {
   guarantee(m->header().value() == 0, "invariant");
   guarantee(m->object() == NULL, "invariant");
   NoSafepointVerifier nsv;
 
-  stringStream ss;
-  guarantee((m->is_busy() | m->_recursions) == 0, "freeing in-use monitor: "
-            "%s, recursions=" INTX_FORMAT, m->is_busy_to_string(&ss),
-            m->_recursions);
+  if ((m->is_busy() | m->_recursions) != 0) {
+    stringStream ss;
+    fatal("freeing in-use monitor: %s, recursions=" INTX_FORMAT,
+          m->is_busy_to_string(&ss), m->_recursions);
+  }
   // _next_om is used for both per-thread in-use and free lists so
   // we have to remove 'm' from the in-use list first (as needed).
   if (from_per_thread_alloc) {
     // Need to remove 'm' from om_in_use_list.
     ObjectMonitor* mid = NULL;
@@ -1585,12 +1585,14 @@
         }
       }
       free_tail = s;
       free_count++;
       guarantee(s->object() == NULL, "invariant");
-      stringStream ss;
-      guarantee(!s->is_busy(), "must be !is_busy: %s", s->is_busy_to_string(&ss));
+      if (s->is_busy()) {
+        stringStream ss;
+        fatal("must be !is_busy: %s", s->is_busy_to_string(&ss));
+      }
     }
     guarantee(free_tail != NULL, "invariant");
     int l_om_free_count = Atomic::load(&self->om_free_count);
     assert(l_om_free_count == free_count, "free counts don't match: "
            "l_om_free_count=%d, free_count=%d", l_om_free_count, free_count);
diff a/src/hotspot/share/runtime/thread.cpp b/src/hotspot/share/runtime/thread.cpp
--- a/src/hotspot/share/runtime/thread.cpp
+++ b/src/hotspot/share/runtime/thread.cpp
@@ -348,11 +348,10 @@
   // Note: at this point, Thread object is not yet initialized. Do not rely on
   // any members being initialized. Do not rely on Thread::current() being set.
   // If possible, refrain from doing anything which may crash or assert since
   // quite probably those crash dumps will be useless.
   set_stack_base(os::current_stack_base());
-  assert(_stack_base != NULL, "current_stack_base failed for %s", name());
   set_stack_size(os::current_stack_size());
 
 #ifdef SOLARIS
   if (os::is_primordial_thread()) {
     os::Solaris::correct_stack_boundaries_for_primordial_thread(this);
@@ -1691,22 +1690,21 @@
   _cached_monitor_info = NULL;
   _parker = Parker::Allocate(this);
   _SleepEvent = ParkEvent::Allocate(this);
   // Setup safepoint state info for this thread
   ThreadSafepointState::create(this);
+  _handshake.set_handshakee(this);
 
   debug_only(_java_call_counter = 0);
 
   // JVMTI PopFrame support
   _popframe_condition = popframe_inactive;
   _popframe_preserved_args = NULL;
   _popframe_preserved_args_size = 0;
   _frames_to_pop_failed_realloc = 0;
 
-  if (SafepointMechanism::uses_thread_local_poll()) {
-    SafepointMechanism::initialize_header(this);
-  }
+  SafepointMechanism::initialize_header(this);
 
   _class_to_be_initialized = NULL;
 
   pd_initialize();
 }
@@ -4471,16 +4469,25 @@
   notify_vm_shutdown();
 
   // exit_globals() will delete tty
   exit_globals();
 
-  // We are after VM_Exit::set_vm_exited() so we can't call
-  // thread->smr_delete() or we will block on the Threads_lock.
-  // Deleting the shutdown thread here is safe because another
-  // JavaThread cannot have an active ThreadsListHandle for
-  // this JavaThread.
-  delete thread;
+  // We are here after VM_Exit::set_vm_exited() so we can't call
+  // thread->smr_delete() or we will block on the Threads_lock. We
+  // must check that there are no active references to this thread
+  // before attempting to delete it. A thread could be waiting on
+  // _handshake_turn_sem trying to execute a direct handshake with
+  // this thread.
+  if (!ThreadsSMRSupport::is_a_protected_JavaThread(thread)) {
+    delete thread;
+  } else {
+    // Clear value for _thread_key in TLS to prevent, depending
+    // on pthreads implementation, possible execution of
+    // thread-specific destructor in infinite loop at thread
+    // exit.
+    Thread::clear_thread_current();
+  }
 
 #if INCLUDE_JVMCI
   if (JVMCICounterSize > 0) {
     FREE_C_HEAP_ARRAY(jlong, JavaThread::_jvmci_old_thread_counters);
   }
diff a/src/hotspot/share/runtime/thread.hpp b/src/hotspot/share/runtime/thread.hpp
--- a/src/hotspot/share/runtime/thread.hpp
+++ b/src/hotspot/share/runtime/thread.hpp
@@ -710,14 +710,22 @@
     return is_in_stack_range(adr, limit, false);
   }
 
   // Check if address is in the stack mapped to this thread. Used mainly in
   // error reporting (so has to include guard zone) and frame printing.
-  bool is_in_full_stack(address adr) const {
+  // Expects _stack_base to be initialized - checked with assert.
+  bool is_in_full_stack_checked(address adr) const {
     return is_in_stack_range_incl(adr, stack_end());
   }
 
+  // Like is_in_full_stack_checked but without the assertions as this
+  // may be called in a thread before _stack_base is initialized.
+  bool is_in_full_stack(address adr) const {
+    address stack_end = _stack_base - _stack_size;
+    return _stack_base > adr && adr >= stack_end;
+  }
+
   // Check if address is in the live stack of this thread (not just for locks).
   // Warning: can only be called by the current thread on itself.
   bool is_in_live_stack(address adr) const {
     assert(Thread::current() == this, "is_in_live_stack can only be called from current thread");
     return is_in_stack_range_incl(adr, os::current_stack_pointer());
@@ -747,11 +755,11 @@
 
   volatile void** polling_page_addr() { return &_polling_page; }
 
  public:
   // Stack overflow support
-  address stack_base() const           { assert(_stack_base != NULL,"Sanity check failed for %s", name()); return _stack_base; }
+  address stack_base() const           { assert(_stack_base != NULL,"Sanity check"); return _stack_base; }
   void    set_stack_base(address base) { _stack_base = base; }
   size_t  stack_size() const           { return _stack_size; }
   void    set_stack_size(size_t size)  { _stack_size = size; }
   address stack_end()  const           { return stack_base() - stack_size(); }
   void    record_stack_base_and_size();
@@ -1341,28 +1349,28 @@
  private:
   // Support for thread handshake operations
   HandshakeState _handshake;
  public:
   void set_handshake_operation(HandshakeOperation* op) {
-    _handshake.set_operation(this, op);
+    _handshake.set_operation(op);
   }
 
   bool has_handshake() const {
     return _handshake.has_operation();
   }
 
   void handshake_process_by_self() {
-    _handshake.process_by_self(this);
+    _handshake.process_by_self();
   }
 
-  bool handshake_try_process_by_vmThread() {
-    return _handshake.try_process_by_vmThread(this);
+  bool handshake_try_process(HandshakeOperation* op) {
+    return _handshake.try_process(op);
   }
 
 #ifdef ASSERT
-  bool is_vmthread_processing_handshake() const {
-    return _handshake.is_vmthread_processing_handshake();
+  Thread* active_handshaker() const {
+    return _handshake.active_handshaker();
   }
 #endif
 
   // Suspend/resume support for JavaThread
  private:
diff a/src/hotspot/share/runtime/vmOperations.hpp b/src/hotspot/share/runtime/vmOperations.hpp
--- a/src/hotspot/share/runtime/vmOperations.hpp
+++ b/src/hotspot/share/runtime/vmOperations.hpp
@@ -99,12 +99,10 @@
   template(ReportJavaOutOfMemory)                 \
   template(JFRCheckpoint)                         \
   template(ShenandoahFullGC)                      \
   template(ShenandoahInitMark)                    \
   template(ShenandoahFinalMarkStartEvac)          \
-  template(ShenandoahInitTraversalGC)             \
-  template(ShenandoahFinalTraversalGC)            \
   template(ShenandoahInitUpdateRefs)              \
   template(ShenandoahFinalUpdateRefs)             \
   template(ShenandoahDegeneratedGC)               \
   template(Exit)                                  \
   template(LinuxDllLoad)                          \
diff a/src/java.base/share/classes/java/lang/Class.java b/src/java.base/share/classes/java/lang/Class.java
--- a/src/java.base/share/classes/java/lang/Class.java
+++ b/src/java.base/share/classes/java/lang/Class.java
@@ -140,11 +140,11 @@
  * type (or for void) using a class literal.  See Section {@jls
  * 15.8.2} of <cite>The Java&trade; Language Specification</cite>.
  * For example:
  *
  * <blockquote>
- *     {@code System.out.println("The name of class Foo is: "+Foo.class.getName());}
+ *     {@code System.out.println("The name of class Foo is: " + Foo.class.getName());}
  * </blockquote>
  *
  * @param <T> the type of the class modeled by this {@code Class}
  * object.  For example, the type of {@code String.class} is {@code
  * Class<String>}.  Use {@code Class<?>} if the class being modeled is
@@ -190,11 +190,11 @@
      * primitive type, this method returns the name of the primitive type.  If
      * this {@code Class} object represents void this method returns
      * "void". If this {@code Class} object represents an array type,
      * this method returns "class " followed by {@code getName}.
      *
-     * @return a string representation of this class object.
+     * @return a string representation of this {@code Class} object.
      */
     public String toString() {
         return (isInlineClass() ? "inline " : "")
                + (isInterface() ? "interface " : (isPrimitive() ? "" : "class "))
                + getName() + (isInlineClass() && isIndirectType() ? "?" : "");
@@ -205,11 +205,11 @@
      * information about modifiers and type parameters.
      *
      * The string is formatted as a list of type modifiers, if any,
      * followed by the kind of type (empty string for primitive types
      * and {@code class}, {@code enum}, {@code interface},
-     * <code>&#64;</code>{@code interface}, or {@code record} as appropriate), followed
+     * {@code @interface}, or {@code record} as appropriate), followed
      * by the type's name, followed by an angle-bracketed
      * comma-separated list of the type's type parameters, if any,
      * including informative bounds on the type parameters, if any.
      *
      * A space is used to separate modifiers from one another and to
@@ -769,24 +769,24 @@
     @HotSpotIntrinsicCandidate
     public native boolean isAssignableFrom(Class<?> cls);
 
 
     /**
-     * Determines if the specified {@code Class} object represents an
+     * Determines if this {@code Class} object represents an
      * interface type.
      *
-     * @return  {@code true} if this object represents an interface;
+     * @return  {@code true} if this {@code Class} object represents an interface;
      *          {@code false} otherwise.
      */
     @HotSpotIntrinsicCandidate
     public native boolean isInterface();
 
 
     /**
      * Determines if this {@code Class} object represents an array class.
      *
-     * @return  {@code true} if this object represents an array class;
+     * @return  {@code true} if this {@code Class} object represents an array class;
      *          {@code false} otherwise.
      * @since   1.1
      */
     @HotSpotIntrinsicCandidate
     public native boolean isArray();
@@ -826,11 +826,11 @@
     /**
      * Returns true if this {@code Class} object represents an annotation
      * type.  Note that if this method returns true, {@link #isInterface()}
      * would also return true, as all annotation types are also interfaces.
      *
-     * @return {@code true} if this class object represents an annotation
+     * @return {@code true} if this {@code Class} object represents an annotation
      *      type; {@code false} otherwise
      * @since 1.5
      */
     public boolean isAnnotation() {
         return (getModifiers() & ANNOTATION) != 0;
@@ -851,20 +851,20 @@
     /**
      * Returns the  name of the entity (class, interface, array class,
      * primitive type, or void) represented by this {@code Class} object,
      * as a {@code String}.
      *
-     * <p> If this class object represents a reference type that is
+     * <p> If this {@code Class} object represents a reference type that is
      * not an array type then the binary name of the class is
      * returned, as specified by <cite>The Java&trade; Language
      * Specification</cite>.
      *
-     * <p> If this class object represents a primitive type or void, then the
+     * <p> If this {@code Class} object represents a primitive type or void, then the
      * name returned is a {@code String} equal to the Java language
      * keyword corresponding to the primitive type or void.
      *
-     * <p> If this class object represents a class of arrays, then the internal
+     * <p> If this {@code Class} object represents a class of arrays, then the internal
      * form of the name consists of the name of the element type preceded by
      * one or more '{@code [}' characters representing the depth of the array
      * nesting.  The encoding of element type names is as follows:
      *
      * <blockquote><table class="striped">
@@ -908,11 +908,11 @@
      * (new int[3][4][5][6][7][8][9]).getClass().getName()
      *     returns "[[[[[[[I"
      * </pre></blockquote>
      *
      * @return  the name of the class or interface
-     *          represented by this object.
+     *          represented by this {@code Class} object.
      */
     public String getName() {
         String name = this.name;
         return name != null ? name : initClassName();
     }
@@ -926,15 +926,15 @@
      * Returns the class loader for the class.  Some implementations may use
      * null to represent the bootstrap class loader. This method will return
      * null in such implementations if this class was loaded by the bootstrap
      * class loader.
      *
-     * <p>If this object
+     * <p>If this {@code Class} object
      * represents a primitive type or void, null is returned.
      *
      * @return  the class loader that loaded the class or interface
-     *          represented by this object.
+     *          represented by this {@code Class} object.
      * @throws  SecurityException
      *          if a security manager is present, and the caller's class loader
      *          is not {@code null} and is not the same as or an ancestor of the
      *          class loader for the class whose class loader is requested,
      *          and the caller does not have the
@@ -1016,36 +1016,36 @@
     /**
      * Returns the {@code Class} representing the direct superclass of the
      * entity (class, interface, primitive type or void) represented by
      * this {@code Class}.  If this {@code Class} represents either the
      * {@code Object} class, an interface, a primitive type, or void, then
-     * null is returned.  If this object represents an array class then the
-     * {@code Class} object representing the {@code Object} class is
+     * null is returned.  If this {@code Class} object represents an array class
+     * then the {@code Class} object representing the {@code Object} class is
      * returned.
      *
-     * @return the direct superclass of the class represented by this object
+     * @return the direct superclass of the class represented by this {@code Class} object
      */
     @HotSpotIntrinsicCandidate
     public native Class<? super T> getSuperclass();
 
 
     /**
      * Returns the {@code Type} representing the direct superclass of
      * the entity (class, interface, primitive type or void) represented by
-     * this {@code Class}.
+     * this {@code Class} object.
      *
      * <p>If the superclass is a parameterized type, the {@code Type}
      * object returned must accurately reflect the actual type
      * arguments used in the source code. The parameterized type
      * representing the superclass is created if it had not been
      * created before. See the declaration of {@link
      * java.lang.reflect.ParameterizedType ParameterizedType} for the
      * semantics of the creation process for parameterized types.  If
-     * this {@code Class} represents either the {@code Object}
+     * this {@code Class} object represents either the {@code Object}
      * class, an interface, a primitive type, or void, then null is
-     * returned.  If this object represents an array class then the
-     * {@code Class} object representing the {@code Object} class is
+     * returned.  If this {@code Class} object represents an array class
+     * then the {@code Class} object representing the {@code Object} class is
      * returned.
      *
      * @throws java.lang.reflect.GenericSignatureFormatError if the generic
      *     class signature does not conform to the format specified in
      *     section {@jvms 4.7.9} of <cite>The Java&trade; Virtual
@@ -1053,11 +1053,11 @@
      * @throws TypeNotPresentException if the generic superclass
      *     refers to a non-existent type declaration
      * @throws java.lang.reflect.MalformedParameterizedTypeException if the
      *     generic superclass refers to a parameterized type that cannot be
      *     instantiated  for any reason
-     * @return the direct superclass of the class represented by this object
+     * @return the direct superclass of the class represented by this {@code Class} object
      * @since 1.5
      */
     public Type getGenericSuperclass() {
         ClassRepository info = getGenericInfo();
         if (info == null) {
@@ -1142,17 +1142,17 @@
     // cached package name
     private transient String packageName;
 
     /**
      * Returns the interfaces directly implemented by the class or interface
-     * represented by this object.
+     * represented by this {@code Class} object.
      *
-     * <p>If this object represents a class, the return value is an array
+     * <p>If this {@code Class} object represents a class, the return value is an array
      * containing objects representing all interfaces directly implemented by
      * the class.  The order of the interface objects in the array corresponds
      * to the order of the interface names in the {@code implements} clause of
-     * the declaration of the class represented by this object.  For example,
+     * the declaration of the class represented by this {@code Class} object.  For example,
      * given the declaration:
      * <blockquote>
      * {@code class Shimmer implements FloorWax, DessertTopping { ... }}
      * </blockquote>
      * suppose the value of {@code s} is an instance of
@@ -1166,20 +1166,20 @@
      * {@code s.getClass().getInterfaces()[1]}
      * </blockquote>
      * is the {@code Class} object that represents interface
      * {@code DessertTopping}.
      *
-     * <p>If this object represents an interface, the array contains objects
+     * <p>If this {@code Class} object represents an interface, the array contains objects
      * representing all interfaces directly extended by the interface.  The
      * order of the interface objects in the array corresponds to the order of
      * the interface names in the {@code extends} clause of the declaration of
-     * the interface represented by this object.
+     * the interface represented by this {@code Class} object.
      *
-     * <p>If this object represents a class or interface that implements no
+     * <p>If this {@code Class} object represents a class or interface that implements no
      * interfaces, the method returns an array of length 0.
      *
-     * <p>If this object represents a primitive type or void, the method
+     * <p>If this {@code Class} object represents a primitive type or void, the method
      * returns an array of length 0.
      *
      * <p>If this {@code Class} object represents an array type, the
      * interfaces {@code Cloneable} and {@code java.io.Serializable} are
      * returned in that order.
@@ -1210,37 +1210,37 @@
     private native Class<?>[] getInterfaces0();
 
     /**
      * Returns the {@code Type}s representing the interfaces
      * directly implemented by the class or interface represented by
-     * this object.
+     * this {@code Class} object.
      *
      * <p>If a superinterface is a parameterized type, the
      * {@code Type} object returned for it must accurately reflect
      * the actual type arguments used in the source code. The
      * parameterized type representing each superinterface is created
      * if it had not been created before. See the declaration of
      * {@link java.lang.reflect.ParameterizedType ParameterizedType}
      * for the semantics of the creation process for parameterized
      * types.
      *
-     * <p>If this object represents a class, the return value is an array
+     * <p>If this {@code Class} object represents a class, the return value is an array
      * containing objects representing all interfaces directly implemented by
      * the class.  The order of the interface objects in the array corresponds
      * to the order of the interface names in the {@code implements} clause of
-     * the declaration of the class represented by this object.
+     * the declaration of the class represented by this {@code Class} object.
      *
-     * <p>If this object represents an interface, the array contains objects
+     * <p>If this {@code Class} object represents an interface, the array contains objects
      * representing all interfaces directly extended by the interface.  The
      * order of the interface objects in the array corresponds to the order of
      * the interface names in the {@code extends} clause of the declaration of
-     * the interface represented by this object.
+     * the interface represented by this {@code Class} object.
      *
-     * <p>If this object represents a class or interface that implements no
+     * <p>If this {@code Class} object represents a class or interface that implements no
      * interfaces, the method returns an array of length 0.
      *
-     * <p>If this object represents a primitive type or void, the method
+     * <p>If this {@code Class} object represents a primitive type or void, the method
      * returns an array of length 0.
      *
      * <p>If this {@code Class} object represents an array type, the
      * interfaces {@code Cloneable} and {@code java.io.Serializable} are
      * returned in that order.
@@ -1294,14 +1294,14 @@
      * using the methods of class {@code Modifier}.
      *
      * <p> If the underlying class is an array class, then its
      * {@code public}, {@code private} and {@code protected}
      * modifiers are the same as those of its component type.  If this
-     * {@code Class} represents a primitive type or void, its
+     * {@code Class} object represents a primitive type or void, its
      * {@code public} modifier is always {@code true}, and its
      * {@code protected} and {@code private} modifiers are always
-     * {@code false}. If this object represents an array class, a
+     * {@code false}. If this {@code Class} object represents an array class, a
      * primitive type or void, then its {@code final} modifier is always
      * {@code true} and its interface modifier is always
      * {@code false}. The values of its other modifiers are not determined
      * by this specification.
      *
@@ -1317,11 +1317,11 @@
 
     /**
      * Gets the signers of this class.
      *
      * @return  the signers of this class, or null if there are no signers.  In
-     *          particular, this method returns null if this object represents
+     *          particular, this method returns null if this {@code Class} object represents
      *          a primitive type or void.
      * @since   1.1
      */
     public Object[] getSigners() {
         return asPrimaryType().getSigners0();
@@ -2076,11 +2076,11 @@
      * field of the class or interface represented by this {@code Class}
      * object. The {@code name} parameter is a {@code String} specifying the
      * simple name of the desired field.
      *
      * <p> The field to be reflected is determined by the algorithm that
-     * follows.  Let C be the class or interface represented by this object:
+     * follows.  Let C be the class or interface represented by this {@code Class} object:
      *
      * <OL>
      * <LI> If C declares a public field with the name specified, that is the
      *      field to be reflected.</LI>
      * <LI> If no field was found in step 1 above, this algorithm is applied
@@ -2761,13 +2761,13 @@
      * caller's module.
      *
      * <p> Otherwise, if this class is not in a named module then the rules for
      * searching resources associated with a given class are implemented by the
      * defining {@linkplain ClassLoader class loader} of the class.  This method
-     * delegates to this object's class loader.  If this object was loaded by
-     * the bootstrap class loader, the method delegates to {@link
-     * ClassLoader#getSystemResourceAsStream}.
+     * delegates to this {@code Class} object's class loader.
+     * If this {@code Class} object was loaded by the bootstrap class loader,
+     * the method delegates to {@link ClassLoader#getSystemResourceAsStream}.
      *
      * <p> Before delegation, an absolute resource name is constructed from the
      * given resource name using this algorithm:
      *
      * <ul>
@@ -2859,13 +2859,13 @@
      * caller's module.
      *
      * <p> Otherwise, if this class is not in a named module then the rules for
      * searching resources associated with a given class are implemented by the
      * defining {@linkplain ClassLoader class loader} of the class.  This method
-     * delegates to this object's class loader. If this object was loaded by
-     * the bootstrap class loader, the method delegates to {@link
-     * ClassLoader#getSystemResource}.
+     * delegates to this {@code Class} object's class loader.
+     * If this {@code Class} object was loaded by the bootstrap class loader,
+     * the method delegates to {@link ClassLoader#getSystemResource}.
      *
      * <p> Before delegation, an absolute resource name is constructed from the
      * given resource name using this algorithm:
      *
      * <ul>
@@ -3770,12 +3770,12 @@
     /**
      * Returns the elements of this enum class or null if this
      * Class object does not represent an enum type.
      *
      * @return an array containing the values comprising the enum class
-     *     represented by this Class object in the order they're
-     *     declared, or null if this Class object does not
+     *     represented by this {@code Class} object in the order they're
+     *     declared, or null if this {@code Class} object does not
      *     represent an enum type
      * @since 1.5
      */
     public T[] getEnumConstants() {
         T[] values = getEnumConstantsShared();
@@ -3869,21 +3869,21 @@
 
     /**
      * Casts this {@code Class} object to represent a subclass of the class
      * represented by the specified class object.  Checks that the cast
      * is valid, and throws a {@code ClassCastException} if it is not.  If
-     * this method succeeds, it always returns a reference to this class object.
+     * this method succeeds, it always returns a reference to this {@code Class} object.
      *
      * <p>This method is useful when a client needs to "narrow" the type of
      * a {@code Class} object to pass it to an API that restricts the
      * {@code Class} objects that it is willing to accept.  A cast would
      * generate a compile-time warning, as the correctness of the cast
      * could not be checked at runtime (because generic types are implemented
      * by erasure).
      *
-     * @param <U> the type to cast this class object to
-     * @param clazz the class of the type to cast this class object to
+     * @param <U> the type to cast this {@code Class} object to
+     * @param clazz the class of the type to cast this {@code Class} object to
      * @return this {@code Class} object, cast to represent a subclass of
      *    the specified class object.
      * @throws ClassCastException if this {@code Class} object does not
      *    represent a subclass of the specified class (here "subclass" includes
      *    the class itself).
diff a/src/java.base/share/classes/java/lang/System.java b/src/java.base/share/classes/java/lang/System.java
--- a/src/java.base/share/classes/java/lang/System.java
+++ b/src/java.base/share/classes/java/lang/System.java
@@ -47,12 +47,10 @@
 import java.security.AccessController;
 import java.security.PrivilegedAction;
 import java.nio.channels.Channel;
 import java.nio.channels.spi.SelectorProvider;
 import java.nio.charset.Charset;
-import java.util.Collections;
-import java.util.Iterator;
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
 import java.util.Properties;
 import java.util.PropertyPermission;
@@ -584,32 +582,14 @@
      */
     @HotSpotIntrinsicCandidate
     public static native int identityHashCode(Object x);
 
     /**
-     * System properties. The following properties are guaranteed to be defined:
-     * <dl>
-     * <dt>java.version         <dd>Java version number
-     * <dt>java.version.date    <dd>Java version date
-     * <dt>java.vendor          <dd>Java vendor specific string
-     * <dt>java.vendor.url      <dd>Java vendor URL
-     * <dt>java.vendor.version  <dd>Java vendor version
-     * <dt>java.home            <dd>Java installation directory
-     * <dt>java.class.version   <dd>Java class version number
-     * <dt>java.class.path      <dd>Java classpath
-     * <dt>os.name              <dd>Operating System Name
-     * <dt>os.arch              <dd>Operating System Architecture
-     * <dt>os.version           <dd>Operating System Version
-     * <dt>file.separator       <dd>File separator ("/" on Unix)
-     * <dt>path.separator       <dd>Path separator (":" on Unix)
-     * <dt>line.separator       <dd>Line separator ("\n" on Unix)
-     * <dt>user.name            <dd>User account name
-     * <dt>user.home            <dd>User home directory
-     * <dt>user.dir             <dd>User's current working directory
-     * </dl>
+     * System properties.
+     *
+     * See {@linkplain #getProperties getProperties} for details.
      */
-
     private static Properties props;
 
     /**
      * Determines the current system properties.
      *
@@ -1881,12 +1861,12 @@
      * JNI_OnLoad_{@code libname} function exported by the library is invoked.
      * See the <a href="{@docRoot}/../specs/jni/index.html"> JNI Specification</a>
      * for more details.
      *
      * Otherwise, the libname argument is loaded from a system library
-     * location and mapped to a native library image in an implementation-
-     * dependent manner.
+     * location and mapped to a native library image in an
+     * implementation-dependent manner.
      * <p>
      * The call {@code System.loadLibrary(name)} is effectively
      * equivalent to the call
      * <blockquote><pre>
      * Runtime.getRuntime().loadLibrary(name)
diff a/src/jdk.javadoc/share/classes/jdk/javadoc/internal/doclets/toolkit/util/Utils.java b/src/jdk.javadoc/share/classes/jdk/javadoc/internal/doclets/toolkit/util/Utils.java
--- a/src/jdk.javadoc/share/classes/jdk/javadoc/internal/doclets/toolkit/util/Utils.java
+++ b/src/jdk.javadoc/share/classes/jdk/javadoc/internal/doclets/toolkit/util/Utils.java
@@ -35,11 +35,10 @@
 import java.util.ArrayDeque;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
-import java.util.Comparator;
 import java.util.Deque;
 import java.util.EnumSet;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
@@ -95,25 +94,22 @@
 import com.sun.source.doctree.DocCommentTree;
 import com.sun.source.doctree.DocTree;
 import com.sun.source.doctree.DocTree.Kind;
 import com.sun.source.doctree.EndElementTree;
 import com.sun.source.doctree.ParamTree;
-import com.sun.source.doctree.SerialFieldTree;
 import com.sun.source.doctree.StartElementTree;
 import com.sun.source.doctree.TextTree;
 import com.sun.source.doctree.UnknownBlockTagTree;
 import com.sun.source.tree.CompilationUnitTree;
 import com.sun.source.tree.LineMap;
 import com.sun.source.util.DocSourcePositions;
 import com.sun.source.util.DocTrees;
 import com.sun.source.util.TreePath;
 import com.sun.tools.javac.model.JavacTypes;
-import jdk.javadoc.internal.doclets.formats.html.SearchIndexItem;
 import jdk.javadoc.internal.doclets.toolkit.BaseConfiguration;
 import jdk.javadoc.internal.doclets.toolkit.BaseOptions;
 import jdk.javadoc.internal.doclets.toolkit.CommentUtils.DocCommentDuo;
-import jdk.javadoc.internal.doclets.toolkit.Messages;
 import jdk.javadoc.internal.doclets.toolkit.Resources;
 import jdk.javadoc.internal.doclets.toolkit.WorkArounds;
 import jdk.javadoc.internal.doclets.toolkit.taglets.BaseTaglet;
 import jdk.javadoc.internal.doclets.toolkit.taglets.Taglet;
 import jdk.javadoc.internal.tool.DocEnvImpl;
@@ -134,26 +130,26 @@
  *  deletion without notice.</b>
  */
 public class Utils {
     public final BaseConfiguration configuration;
     private final BaseOptions options;
-    private final Messages messages;
     private final Resources resources;
     public final DocTrees docTrees;
     public final Elements elementUtils;
     public final Types typeUtils;
+    public final Comparators comparators;
     private final JavaScriptScanner javaScriptScanner;
 
     public Utils(BaseConfiguration c) {
         configuration = c;
         options = configuration.getOptions();
-        messages = configuration.getMessages();
         resources = configuration.getDocResources();
         elementUtils = c.docEnv.getElementUtils();
         typeUtils = c.docEnv.getTypeUtils();
         docTrees = c.docEnv.getDocTrees();
         javaScriptScanner = c.isAllowScriptInComments() ? null : new JavaScriptScanner();
+        comparators = new Comparators(this);
     }
 
     // our own little symbol table
     private HashMap<String, TypeMirror> symtab = new HashMap<>();
 
@@ -217,11 +213,11 @@
      *                    documentation is getting generated.
      */
     public List<Element> excludeDeprecatedMembers(List<? extends Element> members) {
         return members.stream()
                       .filter(member -> !isDeprecated(member))
-                      .sorted(makeGeneralPurposeComparator())
+                      .sorted(comparators.makeGeneralPurposeComparator())
                       .collect(Collectors.toCollection(ArrayList::new));
     }
 
     /**
      * Search for the given method in the given class.
@@ -662,43 +658,48 @@
                 return false;
         }
     }
 
     /**
-     * Get the signature. It is the parameter list, type is qualified.
+     * Get the signature of an executable element with qualified parameter types
+     * in the context of type element {@code site}.
      * For instance, for a method {@code mymethod(String x, int y)},
      * it will return {@code (java.lang.String,int)}.
      *
-     * @param e
-     * @return String
+     * @param e the executable element
+     * @param site the contextual site
+     * @return String signature with qualified parameter types
      */
-    public String signature(ExecutableElement e) {
-        return makeSignature(e, true);
+    public String signature(ExecutableElement e, TypeElement site) {
+        return makeSignature(e, site, true);
     }
 
     /**
-     * Get flat signature.  All types are not qualified.
-     * Return a String, which is the flat signature of this member.
-     * It is the parameter list, type is not qualified.
+     * Get the flat signature of an executable element with simple (unqualified)
+     * parameter types in the context of type element {@code site}.
      * For instance, for a method {@code mymethod(String x, int y)},
      * it will return {@code (String, int)}.
+     *
+     * @param e the executable element
+     * @param site the contextual site
+     * @return String signature with simple (unqualified) parameter types
      */
-    public String flatSignature(ExecutableElement e) {
-        return makeSignature(e, false);
+    public String flatSignature(ExecutableElement e, TypeElement site) {
+        return makeSignature(e, site, false);
     }
 
-    public String makeSignature(ExecutableElement e, boolean full) {
-        return makeSignature(e, full, false);
+    public String makeSignature(ExecutableElement e, TypeElement site, boolean full) {
+        return makeSignature(e, site, full, false);
     }
 
-    public String makeSignature(ExecutableElement e, boolean full, boolean ignoreTypeParameters) {
+    public String makeSignature(ExecutableElement e, TypeElement site, boolean full, boolean ignoreTypeParameters) {
         StringBuilder result = new StringBuilder();
         result.append("(");
-        Iterator<? extends VariableElement> iterator = e.getParameters().iterator();
+        ExecutableType executableType = asInstantiatedMethodType(site, e);
+        Iterator<? extends TypeMirror> iterator = executableType.getParameterTypes().iterator();
         while (iterator.hasNext()) {
-            VariableElement next = iterator.next();
-            TypeMirror type = next.asType();
+            TypeMirror type = iterator.next();
             result.append(getTypeSignature(type, full, ignoreTypeParameters));
             if (iterator.hasNext()) {
                 result.append(", ");
             }
         }
@@ -927,11 +928,11 @@
         }
         return null;
     }
 
     public SortedSet<TypeElement> getTypeElementsAsSortedSet(Iterable<TypeElement> typeElements) {
-        SortedSet<TypeElement> set = new TreeSet<>(makeGeneralPurposeComparator());
+        SortedSet<TypeElement> set = new TreeSet<>(comparators.makeGeneralPurposeComparator());
         typeElements.forEach(set::add);
         return set;
     }
 
     public List<? extends DocTree> getSerialDataTrees(ExecutableElement member) {
@@ -1575,11 +1576,11 @@
      * @return list of filtered classes.
      */
     public SortedSet<TypeElement> filterOutPrivateClasses(Iterable<TypeElement> classlist,
             boolean javafx) {
         SortedSet<TypeElement> filteredOutClasses =
-                new TreeSet<>(makeGeneralPurposeComparator());
+                new TreeSet<>(comparators.makeGeneralPurposeComparator());
         if (!javafx) {
             for (Element te : classlist) {
                 if (!hasHiddenTag(te)) {
                     filteredOutClasses.add((TypeElement)te);
                 }
@@ -1642,11 +1643,11 @@
     }
 
     private DocCollator tertiaryCollator = null;
     private DocCollator secondaryCollator = null;
 
-    private int compareStrings(boolean caseSensitive, String s1, String s2) {
+    int compareStrings(boolean caseSensitive, String s1, String s2) {
         if (caseSensitive) {
             if (tertiaryCollator == null) {
                 tertiaryCollator = new DocCollator(configuration.locale, Collator.TERTIARY);
             }
             return tertiaryCollator.compare(s1, s2);
@@ -1730,249 +1731,10 @@
             }
             return baseCollator;
         }
     }
 
-    private Comparator<Element> moduleComparator = null;
-    /**
-     * Comparator for ModuleElements, simply compares the fully qualified names
-     * @return a Comparator
-     */
-    public Comparator<Element> makeModuleComparator() {
-        if (moduleComparator == null) {
-            moduleComparator = new Utils.ElementComparator() {
-                @Override
-                public int compare(Element mod1, Element mod2) {
-                    return compareFullyQualifiedNames(mod1, mod2);
-                }
-            };
-        }
-        return moduleComparator;
-    }
-
-    private Comparator<Element> allClassesComparator = null;
-    /**
-     * Returns a Comparator for all classes, compares the simple names of
-     * TypeElement, if equal then the fully qualified names.
-     *
-     * @return Comparator
-     */
-    public Comparator<Element> makeAllClassesComparator() {
-        if (allClassesComparator == null) {
-            allClassesComparator = new Utils.ElementComparator() {
-                @Override
-                public int compare(Element e1, Element e2) {
-                    int result = compareNames(e1, e2);
-                    if (result == 0)
-                        result = compareFullyQualifiedNames(e1, e2);
-
-                    return result;
-                }
-            };
-        }
-        return allClassesComparator;
-    }
-
-    private Comparator<Element> packageComparator = null;
-    /**
-     * Returns a Comparator for packages, by comparing the fully qualified names.
-     *
-     * @return a Comparator
-     */
-    public Comparator<Element> makePackageComparator() {
-        if (packageComparator == null) {
-            packageComparator = new Utils.ElementComparator() {
-                @Override
-                public int compare(Element pkg1, Element pkg2) {
-                    return compareFullyQualifiedNames(pkg1, pkg2);
-                }
-            };
-        }
-        return packageComparator;
-    }
-
-    private Comparator<Element> deprecatedComparator = null;
-    /**
-     * Returns a Comparator for deprecated items listed on deprecated list page, by comparing the
-     * fully qualified names.
-     *
-     * @return a Comparator
-     */
-    public Comparator<Element> makeDeprecatedComparator() {
-        if (deprecatedComparator == null) {
-            deprecatedComparator = new Utils.ElementComparator() {
-                @Override
-                public int compare(Element e1, Element e2) {
-                    return compareFullyQualifiedNames(e1, e2);
-                }
-            };
-        }
-        return deprecatedComparator;
-    }
-
-    private Comparator<SerialFieldTree> serialFieldTreeComparator = null;
-    /**
-     * Returns a Comparator for SerialFieldTree.
-     * @return a Comparator
-     */
-    public Comparator<SerialFieldTree> makeSerialFieldTreeComparator() {
-        if (serialFieldTreeComparator == null) {
-            serialFieldTreeComparator = (SerialFieldTree o1, SerialFieldTree o2) -> {
-                String s1 = o1.getName().toString();
-                String s2 = o2.getName().toString();
-                return s1.compareTo(s2);
-            };
-        }
-        return serialFieldTreeComparator;
-    }
-
-    /**
-     * Returns a general purpose comparator.
-     * @return a Comparator
-     */
-    public Comparator<Element> makeGeneralPurposeComparator() {
-        return makeClassUseComparator();
-    }
-
-    private Comparator<Element> overrideUseComparator = null;
-
-    /**
-     * Returns a Comparator for overrides and implements,
-     * used primarily on methods, compares the name first,
-     * then compares the simple names of the enclosing
-     * TypeElement and the fully qualified name of the enclosing TypeElement.
-     * @return a Comparator
-     */
-    public Comparator<Element> makeOverrideUseComparator() {
-        if (overrideUseComparator == null) {
-            overrideUseComparator = new Utils.ElementComparator() {
-                @Override
-                public int compare(Element o1, Element o2) {
-                    int result = compareStrings(getSimpleName(o1), getSimpleName(o2));
-                    if (result != 0) {
-                        return result;
-                    }
-                    if (!isTypeElement(o1) && !isTypeElement(o2) && !isPackage(o1) && !isPackage(o2)) {
-                        TypeElement t1 = getEnclosingTypeElement(o1);
-                        TypeElement t2 = getEnclosingTypeElement(o2);
-                        result = compareStrings(getSimpleName(t1), getSimpleName(t2));
-                        if (result != 0)
-                            return result;
-                    }
-                    result = compareStrings(getFullyQualifiedName(o1), getFullyQualifiedName(o2));
-                    if (result != 0)
-                        return result;
-                    return compareElementKinds(o1, o2);
-                }
-            };
-        }
-        return overrideUseComparator;
-    }
-
-    private Comparator<Element> indexUseComparator = null;
-    /**
-     *  Returns a Comparator for index file presentations, and are sorted as follows.
-     *  If comparing modules and/or packages then simply compare the qualified names,
-     *  if comparing a module or a package with a type/member then compare the
-     *  FullyQualifiedName of the module or a package with the SimpleName of the entity,
-     *  otherwise:
-     *  1. compare the ElementKind ex: Module, Package, Interface etc.
-     *  2a. if equal and if the type is of ExecutableElement(Constructor, Methods),
-     *      a case insensitive comparison of parameter the type signatures
-     *  2b. if equal, case sensitive comparison of the type signatures
-     *  3. finally, if equal, compare the FQNs of the entities
-     * @return a comparator for index file use
-     */
-    public Comparator<Element> makeIndexUseComparator() {
-        if (indexUseComparator == null) {
-            indexUseComparator = new Utils.ElementComparator() {
-                /**
-                 * Compares two elements.
-                 *
-                 * @param e1 - an element.
-                 * @param e2 - an element.
-                 * @return a negative integer, zero, or a positive integer as the first
-                 * argument is less than, equal to, or greater than the second.
-                 */
-                @Override
-                public int compare(Element e1, Element e2) {
-                    int result;
-                    // first, compare names as appropriate
-                    if ((isModule(e1) || isPackage(e1)) && (isModule(e2) || isPackage(e2))) {
-                        result = compareFullyQualifiedNames(e1, e2);
-                    } else if (isModule(e1) || isPackage(e1)) {
-                        result = compareStrings(getFullyQualifiedName(e1), getSimpleName(e2));
-                    } else if (isModule(e2) || isPackage(e2)) {
-                        result = compareStrings(getSimpleName(e1), getFullyQualifiedName(e2));
-                    } else {
-                        result = compareNames(e1, e2);
-                    }
-                    if (result != 0) {
-                        return result;
-                    }
-                    // if names are the same, compare element kinds
-                    result = compareElementKinds(e1, e2);
-                    if (result != 0) {
-                        return result;
-                    }
-                    // if element kinds are the same, and are methods,
-                    // compare the method parameters
-                    if (hasParameters(e1)) {
-                        List<? extends VariableElement> parameters1 = ((ExecutableElement)e1).getParameters();
-                        List<? extends VariableElement> parameters2 = ((ExecutableElement)e2).getParameters();
-                        result = compareParameters(false, parameters1, parameters2);
-                        if (result != 0) {
-                            return result;
-                        }
-                        result = compareParameters(true, parameters1, parameters2);
-                        if (result != 0) {
-                            return result;
-                        }
-                    }
-                    // else fall back on fully qualified names
-                    return compareFullyQualifiedNames(e1, e2);
-                }
-            };
-        }
-        return indexUseComparator;
-    }
-
-    private Comparator<TypeMirror> typeMirrorClassUseComparator = null;
-    /**
-     * Compares the FullyQualifiedNames of two TypeMirrors
-     * @return
-     */
-    public Comparator<TypeMirror> makeTypeMirrorClassUseComparator() {
-        if (typeMirrorClassUseComparator == null) {
-            typeMirrorClassUseComparator = (TypeMirror type1, TypeMirror type2) -> {
-                String s1 = getQualifiedTypeName(type1);
-                String s2 = getQualifiedTypeName(type2);
-                return compareStrings(s1, s2);
-            };
-        }
-        return typeMirrorClassUseComparator;
-    }
-
-    private Comparator<TypeMirror> typeMirrorIndexUseComparator = null;
-    /**
-     * Compares the SimpleNames of TypeMirrors if equal then the
-     * FullyQualifiedNames of TypeMirrors.
-     *
-     * @return
-     */
-    public Comparator<TypeMirror> makeTypeMirrorIndexUseComparator() {
-        if (typeMirrorIndexUseComparator == null) {
-            typeMirrorIndexUseComparator = (TypeMirror t1, TypeMirror t2) -> {
-                int result = compareStrings(getTypeName(t1, false), getTypeName(t2, false));
-                if (result != 0)
-                    return result;
-                return compareStrings(getQualifiedTypeName(t1), getQualifiedTypeName(t2));
-            };
-        }
-        return typeMirrorIndexUseComparator;
-    }
-
     /**
      * Get the qualified type name of a TypeMirror compatible with the Element's
      * getQualified name, returns  the qualified name of the Reference type
      * otherwise the primitive name.
      * @param t the type whose name is to be obtained.
@@ -2041,256 +1803,10 @@
                 return outer ? visit(e.getEnclosingElement()) : e.getSimpleName().toString();
             }
         }.visit(e);
     }
 
-    private Comparator<Element> classUseComparator = null;
-
-    /**
-     * Comparator for ClassUse presentations, and sorts as follows:
-     * 1. member names
-     * 2. then fully qualified member names
-     * 3. then parameter types if applicable
-     * 4. finally the element kinds ie. package, class, interface etc.
-     * @return a comparator to sort classes and members for class use
-     */
-    public Comparator<Element> makeClassUseComparator() {
-        if (classUseComparator == null) {
-            classUseComparator = new Utils.ElementComparator() {
-                /**
-                 * Compares two Elements.
-                 *
-                 * @param e1 - an element.
-                 * @param e2 - an element.
-                 * @return a negative integer, zero, or a positive integer as the first
-                 * argument is less than, equal to, or greater than the second.
-                 */
-                @Override
-                public int compare(Element e1, Element e2) {
-                    int result = compareNames(e1, e2);
-                    if (result != 0) {
-                        return result;
-                    }
-                    result = compareFullyQualifiedNames(e1, e2);
-                    if (result != 0) {
-                        return result;
-                    }
-                    if (hasParameters(e1) && hasParameters(e2)) {
-                        List<? extends VariableElement> parameters1 = ((ExecutableElement)e1).getParameters();
-                        List<? extends VariableElement> parameters2 = ((ExecutableElement)e2).getParameters();
-                        result = compareParameters(false, parameters1, parameters2);
-                        if (result != 0) {
-                            return result;
-                        }
-                        result = compareParameters(true, parameters1, parameters2);
-                    }
-                    if (result != 0) {
-                        return result;
-                    }
-                    return compareElementKinds(e1, e2);
-                }
-            };
-        }
-        return classUseComparator;
-    }
-
-    /**
-     * A general purpose comparator to sort Element entities, basically provides the building blocks
-     * for creating specific comparators for an use-case.
-     */
-    private abstract class ElementComparator implements Comparator<Element> {
-        public ElementComparator() { }
-
-        /**
-         * compares two parameter arrays by first comparing the length of the arrays, and
-         * then each Type of the parameter in the array.
-         * @param params1 the first parameter array.
-         * @param params2 the first parameter array.
-         * @return a negative integer, zero, or a positive integer as the first
-         *         argument is less than, equal to, or greater than the second.
-         */
-        protected int compareParameters(boolean caseSensitive, List<? extends VariableElement> params1,
-                                                               List<? extends VariableElement> params2) {
-
-            return compareStrings(caseSensitive, getParametersAsString(params1),
-                                                 getParametersAsString(params2));
-        }
-
-        String getParametersAsString(List<? extends VariableElement> params) {
-            StringBuilder sb = new StringBuilder();
-            for (VariableElement param : params) {
-                TypeMirror t = param.asType();
-                // prefix P for primitive and R for reference types, thus items will
-                // be ordered lexically and correctly.
-                sb.append(getTypeCode(t)).append("-").append(t).append("-");
-            }
-            return sb.toString();
-        }
-
-        private String getTypeCode(TypeMirror t) {
-            return new SimpleTypeVisitor9<String, Void>() {
-
-                @Override
-                public String visitPrimitive(PrimitiveType t, Void p) {
-                    return "P";
-                }
-                @Override
-                public String visitArray(ArrayType t, Void p) {
-                    return visit(t.getComponentType());
-                }
-                @Override
-                protected String defaultAction(TypeMirror e, Void p) {
-                    return "R";
-                }
-
-            }.visit(t);
-        }
-
-        /**
-         * Compares two Elements, typically the name of a method,
-         * field or constructor.
-         * @param e1 the first Element.
-         * @param e2 the second Element.
-         * @return a negative integer, zero, or a positive integer as the first
-         *         argument is less than, equal to, or greater than the second.
-         */
-        protected int compareNames(Element e1, Element e2) {
-            return compareStrings(getSimpleName(e1), getSimpleName(e2));
-        }
-
-        /**
-         * Compares the fully qualified names of the entities
-         * @param e1 the first Element.
-         * @param e2 the first Element.
-         * @return a negative integer, zero, or a positive integer as the first
-         *         argument is less than, equal to, or greater than the second.
-         */
-        protected int compareFullyQualifiedNames(Element e1, Element e2) {
-            // add simplename to be compatible
-            String thisElement = getFullyQualifiedName(e1);
-            String thatElement = getFullyQualifiedName(e2);
-            return compareStrings(thisElement, thatElement);
-        }
-
-        protected int compareElementKinds(Element e1, Element e2) {
-            return Integer.compare(getKindIndex(e1), getKindIndex(e2));
-        }
-
-        private int getKindIndex(Element e) {
-            switch (e.getKind()) {
-                case MODULE:            return 0;
-                case PACKAGE:           return 1;
-                case CLASS:             return 2;
-                case ENUM:              return 3;
-                case ENUM_CONSTANT:     return 4;
-                case RECORD:            return 5;
-                case INTERFACE:         return 6;
-                case ANNOTATION_TYPE:   return 7;
-                case FIELD:             return 8;
-                case CONSTRUCTOR:       return 9;
-                case METHOD:            return 10;
-                default: throw new IllegalArgumentException(e.getKind().toString());
-            }
-        }
-
-        @SuppressWarnings("preview")
-        boolean hasParameters(Element e) {
-            return new SimpleElementVisitor14<Boolean, Void>() {
-                @Override
-                public Boolean visitExecutable(ExecutableElement e, Void p) {
-                    return true;
-                }
-
-                @Override
-                protected Boolean defaultAction(Element e, Void p) {
-                    return false;
-                }
-
-            }.visit(e);
-        }
-
-        /**
-         * The fully qualified names of the entities, used solely by the comparator.
-         *
-         * @return a negative integer, zero, or a positive integer as the first argument is less
-         * than, equal to, or greater than the second.
-         */
-        @SuppressWarnings("preview")
-        private String getFullyQualifiedName(Element e) {
-            return new SimpleElementVisitor14<String, Void>() {
-                @Override
-                public String visitModule(ModuleElement e, Void p) {
-                    return e.getQualifiedName().toString();
-                }
-
-                @Override
-                public String visitPackage(PackageElement e, Void p) {
-                    return e.getQualifiedName().toString();
-                }
-
-                @Override
-                public String visitExecutable(ExecutableElement e, Void p) {
-                    // For backward compatibility
-                    return getFullyQualifiedName(e.getEnclosingElement())
-                            + "." + e.getSimpleName().toString();
-                }
-
-                @Override
-                public String visitType(TypeElement e, Void p) {
-                    return e.getQualifiedName().toString();
-                }
-
-                @Override
-                protected String defaultAction(Element e, Void p) {
-                    return getEnclosingTypeElement(e).getQualifiedName().toString()
-                            + "." + e.getSimpleName().toString();
-                }
-            }.visit(e);
-        }
-    }
-
-    /**
-     * Returns a Comparator for SearchIndexItems representing types. Items are
-     * compared by short name, or full string representation if names are equal.
-     *
-     * @return a Comparator
-     */
-    public Comparator<SearchIndexItem> makeTypeSearchIndexComparator() {
-        return (SearchIndexItem sii1, SearchIndexItem sii2) -> {
-            int result = compareStrings(sii1.getSimpleName(), sii2.getSimpleName());
-            if (result == 0) {
-                // TreeSet needs this to be consistent with equal so we do
-                // a plain comparison of string representations as fallback.
-                result = sii1.toString().compareTo(sii2.toString());
-            }
-            return result;
-        };
-    }
-
-    private Comparator<SearchIndexItem> genericSearchIndexComparator = null;
-    /**
-     * Returns a Comparator for SearchIndexItems representing modules, packages, or members.
-     * Items are compared by label (member name plus signature for members, package name for
-     * packages, and module name for modules). If labels are equal then full string
-     * representation is compared.
-     *
-     * @return a Comparator
-     */
-    public Comparator<SearchIndexItem> makeGenericSearchIndexComparator() {
-        if (genericSearchIndexComparator == null) {
-            genericSearchIndexComparator = (SearchIndexItem sii1, SearchIndexItem sii2) -> {
-                int result = compareStrings(sii1.getLabel(), sii2.getLabel());
-                if (result == 0) {
-                    // TreeSet needs this to be consistent with equal so we do
-                    // a plain comparison of string representations as fallback.
-                    result = sii1.toString().compareTo(sii2.toString());
-                }
-                return result;
-            };
-        }
-        return genericSearchIndexComparator;
-    }
 
     public Iterable<TypeElement> getEnclosedTypeElements(PackageElement pkg) {
         List<TypeElement> out = getInterfaces(pkg);
         out.addAll(getClasses(pkg));
         out.addAll(getEnums(pkg));
@@ -2383,11 +1899,11 @@
         }
         return modulePackageMap;
     }
 
     public Map<ModuleElement, String> getDependentModules(ModuleElement mdle) {
-        Map<ModuleElement, String> result = new TreeMap<>(makeModuleComparator());
+        Map<ModuleElement, String> result = new TreeMap<>(comparators.makeModuleComparator());
         Deque<ModuleElement> queue = new ArrayDeque<>();
         // get all the requires for the element in question
         for (RequiresDirective rd : ElementFilter.requiresIn(mdle.getDirectives())) {
             ModuleElement dep = rd.getDependency();
             // add the dependency to work queue
@@ -2489,11 +2005,11 @@
     public SortedSet<TypeElement> getAllClassesUnfiltered(Element e) {
         List<TypeElement> clist = getClassesUnfiltered(e);
         clist.addAll(getInterfacesUnfiltered(e));
         clist.addAll(getAnnotationTypesUnfiltered(e));
         clist.addAll(getRecordsUnfiltered(e));
-        SortedSet<TypeElement> oset = new TreeSet<>(makeGeneralPurposeComparator());
+        SortedSet<TypeElement> oset = new TreeSet<>(comparators.makeGeneralPurposeComparator());
         oset.addAll(clist);
         return oset;
     }
 
     private final HashMap<Element, SortedSet<TypeElement>> cachedClasses = new HashMap<>();
@@ -2510,11 +2026,11 @@
         List<TypeElement> clist = getClasses(e);
         clist.addAll(getInterfaces(e));
         clist.addAll(getAnnotationTypes(e));
         clist.addAll(getEnums(e));
         clist.addAll(getRecords(e));
-        oset = new TreeSet<>(makeGeneralPurposeComparator());
+        oset = new TreeSet<>(comparators.makeGeneralPurposeComparator());
         oset.addAll(clist);
         cachedClasses.put(e, oset);
         return oset;
     }
 
diff a/src/jdk.jdi/share/classes/com/sun/tools/jdi/VirtualMachineImpl.java b/src/jdk.jdi/share/classes/com/sun/tools/jdi/VirtualMachineImpl.java
--- a/src/jdk.jdi/share/classes/com/sun/tools/jdi/VirtualMachineImpl.java
+++ b/src/jdk.jdi/share/classes/com/sun/tools/jdi/VirtualMachineImpl.java
@@ -1,7 +1,7 @@
 /*
- * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
+ * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.
  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  *
  * This code is free software; you can redistribute it and/or modify it
  * under the terms of the GNU General Public License version 2 only, as
  * published by the Free Software Foundation.  Oracle designates this
@@ -313,46 +313,39 @@
         validateVM();
         List<ModuleReference> modules = retrieveAllModules();
         return Collections.unmodifiableList(modules);
     }
 
-     List<ReferenceType> classesBySignature(String signature) {
-        validateVM();
-        List<ReferenceType> list;
-        if (retrievedAllTypes) {
-            list = findReferenceTypes(signature);
-        } else {
-            list = retrieveClassesBySignature(signature);
-        }
-        return Collections.unmodifiableList(list);
-    }
-
     private static boolean isReferenceArray(String signature) {
         int i = signature.lastIndexOf('[');
         if (i > -1 && signature.charAt(i+1) == 'L') {
             return true;
         }
         return false;
     }
 
     public List<ReferenceType> classesByName(String className) {
         validateVM();
-        String signature = JNITypeParser.typeNameToSignature(className);
+        return classesBySignature(JNITypeParser.typeNameToSignature(className));
+    }
+
+    List<ReferenceType> classesBySignature(String signature) {
+        validateVM();
         List<ReferenceType> list;
         if (retrievedAllTypes) {
-           list = findReferenceTypes(signature);
+            list = findReferenceTypes(signature);
         } else {
-           list = retrieveClassesBySignature(signature);
+            list = retrieveClassesBySignature(signature);
         }
         // HACK: add second request to cover the case where className
         // is the name of an inline type. This is done only if the
         // first signature is either a reference type or an array
         // of a reference type.
         if (signature.length() > 1 &&
                 (signature.charAt(0) == 'L' || isReferenceArray((signature)))) {
             List<ReferenceType> listInlineTypes;
-            signature = JNITypeParser.inlineTypeNameToSignature(className);
+            signature = signature.replaceFirst("L", "Q");
             if (retrievedAllTypes) {
                 listInlineTypes = findReferenceTypes(signature);
             } else {
                 listInlineTypes = retrieveClassesBySignature(signature);
             }
diff a/test/hotspot/jtreg/ProblemList.txt b/test/hotspot/jtreg/ProblemList.txt
--- a/test/hotspot/jtreg/ProblemList.txt
+++ b/test/hotspot/jtreg/ProblemList.txt
@@ -160,11 +160,11 @@
 gc/g1/humongousObjects/TestHeapCounters.java 8178918 generic-all
 gc/stress/gclocker/TestExcessGCLockerCollections.java 8229120 generic-all
 gc/stress/gclocker/TestGCLockerWithParallel.java 8180622 generic-all
 gc/stress/gclocker/TestGCLockerWithG1.java 8180622 generic-all
 gc/stress/TestJNIBlockFullGC/TestJNIBlockFullGC.java 8192647 generic-all
-gc/metaspace/CompressedClassSpaceSizeInJmapHeap.java 8193639,8241293 solaris-all,macosx-x64
+gc/metaspace/CompressedClassSpaceSizeInJmapHeap.java 8241293 macosx-x64
 
 #############################################################################
 
 # :hotspot_runtime
 
@@ -195,55 +195,18 @@
 
 #############################################################################
 
 # :hotspot_serviceability
 
-serviceability/sa/ClhsdbAttach.java 8193639 solaris-all
-serviceability/sa/ClhsdbCDSCore.java 8193639 solaris-all
-serviceability/sa/ClhsdbCDSJstackPrintAll.java 8193639 solaris-all
-serviceability/sa/CDSJMapClstats.java 8193639 solaris-all
-serviceability/sa/ClhsdbField.java 8193639 solaris-all
-serviceability/sa/ClhsdbFindPC.java 8193639 solaris-all
-serviceability/sa/ClhsdbFlags.java 8193639 solaris-all
-serviceability/sa/ClhsdbInspect.java 8193639 solaris-all
-serviceability/sa/ClhsdbJdis.java 8193639 solaris-all
-serviceability/sa/ClhsdbJhisto.java 8193639 solaris-all
-serviceability/sa/ClhsdbJstack.java 8193639 solaris-all
-serviceability/sa/ClhsdbJstackXcompStress.java 8193639 solaris-all
-serviceability/sa/ClhsdbLongConstant.java 8193639 solaris-all
-serviceability/sa/ClhsdbPmap.java 8193639 solaris-all
-serviceability/sa/ClhsdbPrintAll.java 8193639 solaris-all
-serviceability/sa/ClhsdbPrintAs.java 8193639 solaris-all
-serviceability/sa/ClhsdbPrintStatics.java 8193639 solaris-all
-serviceability/sa/ClhsdbPstack.java 8193639 solaris-all
-serviceability/sa/ClhsdbRegionDetailsScanOopsForG1.java 8193639 solaris-all
-serviceability/sa/ClhsdbScanOops.java 8193639,8235220,8230731 solaris-all,linux-x64,macosx-x64,windows-x64
-serviceability/sa/ClhsdbSource.java 8193639 solaris-all
-serviceability/sa/ClhsdbThread.java 8193639 solaris-all
-serviceability/sa/ClhsdbVmStructsDump.java 8193639 solaris-all
-serviceability/sa/ClhsdbWhere.java 8193639 solaris-all
-serviceability/sa/DeadlockDetectionTest.java 8193639 solaris-all
-serviceability/sa/JhsdbThreadInfoTest.java 8193639 solaris-all
-serviceability/sa/jmap-hprof/JMapHProfLargeHeapTest.java 8193639 solaris-all
-serviceability/sa/sadebugd/DebugdConnectTest.java 8239062 macosx-x64 
-serviceability/sa/TestClassDump.java 8193639 solaris-all
-serviceability/sa/TestClhsdbJstackLock.java 8193639 solaris-all
-serviceability/sa/TestCpoolForInvokeDynamic.java 8193639 solaris-all
-serviceability/sa/TestDefaultMethods.java 8193639 solaris-all
-serviceability/sa/TestG1HeapRegion.java 8193639 solaris-all
-serviceability/sa/TestHeapDumpForInvokeDynamic.java 8193639,8241158 solaris-all,macosx-x64
-serviceability/sa/TestHeapDumpForLargeArray.java 8193639 solaris-all
-serviceability/sa/TestInstanceKlassSize.java 8193639,8230664 solaris-all,linux-ppc64le,linux-ppc64
-serviceability/sa/TestInstanceKlassSizeForInterface.java 8193639,8230664 solaris-all,linux-ppc64le,linux-ppc64
-serviceability/sa/TestIntConstant.java 8193639 solaris-all
-serviceability/sa/TestJhsdbJstackLock.java 8193639 solaris-all
-serviceability/sa/TestJmapCore.java 8193639 solaris-all
-serviceability/sa/TestJmapCoreMetaspace.java 8193639 solaris-all
-serviceability/sa/TestPrintMdo.java 8193639 solaris-all
+serviceability/sa/ClhsdbDumpheap.java 8241158 macosx-x64
+serviceability/sa/ClhsdbScanOops.java#id0 8235220,8230731 linux-x64,macosx-x64,windows-x64
+serviceability/sa/ClhsdbScanOops.java#id1 8235220,8230731 linux-x64,macosx-x64,windows-x64
+serviceability/sa/sadebugd/DebugdConnectTest.java 8239062 macosx-x64
+serviceability/sa/TestHeapDumpForInvokeDynamic.java 8241158 macosx-x64
+serviceability/sa/TestInstanceKlassSize.java 8230664 linux-ppc64le,linux-ppc64
+serviceability/sa/TestInstanceKlassSizeForInterface.java 8230664 linux-ppc64le,linux-ppc64
 serviceability/sa/TestRevPtrsForInvokeDynamic.java 8241235 generic-all
-serviceability/sa/TestType.java 8193639 solaris-all
-serviceability/sa/TestUniverse.java#id0 8193639 solaris-all
 
 serviceability/jvmti/HeapMonitor/MyPackage/HeapMonitorStatIntervalTest.java 8214032 generic-all
 serviceability/jvmti/HeapMonitor/MyPackage/HeapMonitorStatArrayCorrectnessTest.java 8224150 generic-all
 
 # Valhalla TODO:
diff a/test/jdk/TEST.groups b/test/jdk/TEST.groups
--- a/test/jdk/TEST.groups
+++ b/test/jdk/TEST.groups
@@ -1,6 +1,6 @@
-#  Copyright (c) 2013, 2019, Oracle and/or its affiliates. All rights reserved.
+#  Copyright (c) 2013, 2020, Oracle and/or its affiliates. All rights reserved.
 #  DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 #
 #  This code is free software; you can redistribute it and/or modify it
 #  under the terms of the GNU General Public License version 2 only, as
 #  published by the Free Software Foundation.
@@ -269,17 +269,15 @@
 # Tool (and tool API) tests are split into core and svc groups
 #
 core_tools = \
     tools \
     jdk/internal/jrtfs \
-    sun/tools/java \
     sun/tools/jrunscript
 
 svc_tools = \
     com/sun/tools/attach \
     sun/tools \
-    -sun/tools/java \
     -sun/tools/jrunscript \
     sun/jvmstat
 
 jdk_tools = \
     :core_tools \
diff a/test/langtools/jdk/javadoc/doclet/testDeprecatedDocs/TestDeprecatedDocs.java b/test/langtools/jdk/javadoc/doclet/testDeprecatedDocs/TestDeprecatedDocs.java
--- a/test/langtools/jdk/javadoc/doclet/testDeprecatedDocs/TestDeprecatedDocs.java
+++ b/test/langtools/jdk/javadoc/doclet/testDeprecatedDocs/TestDeprecatedDocs.java
@@ -96,11 +96,11 @@
 
         checkOutput("pkg/TestAnnotationType.html", true,
                 "<hr>\n"
                 + "<pre>@Deprecated(forRemoval=true)\n"
                 + "@Documented\n"
-                + "public @interface <span class=\"member-name-label\">TestAnnotationType</span></pre>\n"
+                + "public @interface <span class=\"type-name-label\">TestAnnotationType</span></pre>\n"
                 + "<div class=\"deprecation-block\"><span class=\"deprecated-label\">Deprecated, for removal: This API element is subject to removal in a future version.</span>\n"
                 + "<div class=\"deprecation-comment\">annotation_test1 passes.</div>\n"
                 + "</div>",
                 "<div class=\"member-signature\"><span class=\"annotations\">@Deprecated(forRemoval=true)\n" +
                         "</span><span class=\"modifiers\">static final</span>&nbsp;<span class=\"return-type\">int</span>&nbsp;<span class=\"member-name\">field</span></div>\n"
diff a/test/langtools/jdk/javadoc/doclet/testMemberInheritance/TestMemberInheritance.java b/test/langtools/jdk/javadoc/doclet/testMemberInheritance/TestMemberInheritance.java
--- a/test/langtools/jdk/javadoc/doclet/testMemberInheritance/TestMemberInheritance.java
+++ b/test/langtools/jdk/javadoc/doclet/testMemberInheritance/TestMemberInheritance.java
@@ -23,11 +23,11 @@
 
 /*
  * @ignore
  * @test
  * @bug 4638588 4635809 6256068 6270645 8025633 8026567 8162363 8175200
- *      8192850 8182765 8220217 8224052
+ *      8192850 8182765 8220217 8224052 8237383
  * @summary Test to make sure that members are inherited properly in the Javadoc.
  *          Verify that inheritance labels are correct.
  * @library ../../lib
  * @modules jdk.javadoc/jdk.javadoc.internal.tool
  * @build javadoc.tester.*
@@ -116,11 +116,11 @@
         checkOutput("pkg2/DocumentedNonGenericChild.html", true,
                 "<td class=\"col-first\"><code>protected abstract java.lang.String</code></td>\n"
                 + "<th class=\"col-second\" scope=\"row\"><code><span class=\"member-name-link\">"
                 + "<a href=\"#parentMethod(T)\">parentMethod</a></span>&#8203;(java.lang.String&nbsp;t)</code></th>\n"
                 + "<td class=\"col-last\">\n"
-                + "<div class=\"block\">Returns some value.</div>\n"
+                + "<div class=\"block\">Returns some value with an inherited search tag.</div>\n"
                 + "</td>\n");
 
         checkOutput("pkg2/DocumentedNonGenericChild.html", true,
                 "<section class=\"detail\" id=\"parentMethod(T)\">\n"
                 + "<h3 id=\"parentMethod(java.lang.Object)\">parentMethod</h3>\n"
@@ -129,28 +129,30 @@
                 + "<span class=\"member-name\">parentMethod</span>&#8203;"
                 + "(<span class=\"parameters\">java.lang.String&nbsp;t)</span>\n"
                 + "                                          "
                 + "throws <span class=\"exceptions\">java.lang.IllegalArgumentException,\n"
                 + "java.lang.InterruptedException,\n"
-                + "java.lang.IllegalStateException</span></div>");
+                + "java.lang.IllegalStateException</span></div>\n"
+                + "<div class=\"block\">Returns some value with an <span id=\"inheritedsearchtag\" "
+                + "class=\"search-tag-result\">inherited search tag</span>.</div>");
 
         checkOutput("pkg2/DocumentedNonGenericChild.html", true,
                 "<dt>Throws:</dt>\n"
                 + "<dd><code>java.lang.InterruptedException</code> - a generic error</dd>\n"
                 + "<dd><code>java.lang.IllegalStateException</code> - illegal state</dd>\n"
                 + "<dd><code>java.lang.IllegalArgumentException</code></dd>");
 
         checkOutput("pkg2/DocumentedNonGenericChild.html", true,
                 "<td class=\"col-first\"><code>java.lang.String</code></td>\n"
                 + "<th class=\"col-second\" scope=\"row\"><code><span class=\"member-name-link\">"
-                + "<a href=\"#f\">f</a></span></code></th>\n"
+                + "<a href=\"#parentField\">parentField</a></span></code></th>\n"
                 + "<td class=\"col-last\">\n"
                 + "<div class=\"block\">A field.</div>",
-                "<section class=\"detail\" id=\"f\">\n"
-                + "<h3>f</h3>\n"
+                "<section class=\"detail\" id=\"parentField\">\n"
+                + "<h3>parentField</h3>\n"
                 + "<div class=\"member-signature\"><span class=\"modifiers\">public</span>&nbsp;"
-                + "<span class=\"return-type\">java.lang.String</span>&nbsp;<span class=\"member-name\">f</span></div>\n"
+                + "<span class=\"return-type\">java.lang.String</span>&nbsp;<span class=\"member-name\">parentField</span></div>\n"
                 + "<div class=\"block\">A field.</div>\n"
                 + "</section>");
 
         checkOutput("pkg3/PrivateGenericParent.PublicChild.html", true,
                 "<td class=\"col-first\"><code>java.lang.String</code></td>\n"
@@ -161,7 +163,70 @@
                 + "<div class=\"member-signature\"><span class=\"modifiers\">public</span>"
                 + "&nbsp;<span class=\"return-type\">java.lang.String</span>&nbsp;"
                 + "<span class=\"member-name\">method</span>&#8203;(<span class=\"parameters\">"
                 + "java.lang.String&nbsp;t)</span></div>\n"
                 + "</section>");
+
+        checkOutput("index-all.html", true,
+                "<dt><span class=\"member-name-link\"><a href=\"pkg2/DocumentedNonGenericChild.html#parentField\">"
+                + "parentField</a></span> - Variable in class pkg2.<a href=\"pkg2/DocumentedNonGenericChild.html\" "
+                + "title=\"class in pkg2\">DocumentedNonGenericChild</a></dt>\n"
+                + "<dd>\n<div class=\"block\">A field.</div>\n"
+                + "</dd>\n",
+                "<dt><span class=\"member-name-link\"><a href=\"pkg2/DocumentedNonGenericChild.html#parentMethod(T)\">"
+                + "parentMethod(String)</a></span> - Method in class pkg2.<a "
+                + "href=\"pkg2/DocumentedNonGenericChild.html\" title=\"class in pkg2\">DocumentedNonGenericChild</a></dt>\n"
+                + "<dd>\n<div class=\"block\">Returns some value with an inherited search tag.</div>\n"
+                + "</dd>");
+        checkOutput("member-search-index.js", true,
+                "{\"p\":\"pkg2\",\"c\":\"DocumentedNonGenericChild\",\"l\":\"parentField\"}",
+                "{\"p\":\"pkg2\",\"c\":\"DocumentedNonGenericChild\",\"l\":\"parentMethod(String)"
+                + "\",\"u\":\"parentMethod(T)\"}");
+        checkOutput("tag-search-index.js", true,
+                "{\"l\":\"inherited search tag\",\"h\":\"pkg2.UndocumentedGenericParent.parentMethod(String)\","
+                + "\"u\":\"pkg2/DocumentedNonGenericChild.html#inheritedsearchtag\"}");
+
+    }
+
+    @Test
+    public void testSplitIndex() {
+        javadoc("-d", "out-split",
+                "-splitindex",
+                "-sourcepath", testSrc,
+                "pkg", "diamond", "inheritDist", "pkg1", "pkg2", "pkg3");
+        checkExit(Exit.OK);
+
+        checkOutput("pkg2/DocumentedNonGenericChild.html", true,
+                "<section class=\"detail\" id=\"parentMethod(T)\">\n"
+                + "<h3 id=\"parentMethod(java.lang.Object)\">parentMethod</h3>\n"
+                + "<div class=\"member-signature\"><span class=\"modifiers\">protected abstract</span>"
+                + "&nbsp;<span class=\"return-type\">java.lang.String</span>&nbsp;"
+                + "<span class=\"member-name\">parentMethod</span>&#8203;"
+                + "(<span class=\"parameters\">java.lang.String&nbsp;t)</span>\n"
+                + "                                          "
+                + "throws <span class=\"exceptions\">java.lang.IllegalArgumentException,\n"
+                + "java.lang.InterruptedException,\n"
+                + "java.lang.IllegalStateException</span></div>\n"
+                + "<div class=\"block\">Returns some value with an <span id=\"inheritedsearchtag\" "
+                + "class=\"search-tag-result\">inherited search tag</span>.</div>");
+
+        checkOutput("index-files/index-9.html", true,
+                "<dt><span class=\"member-name-link\"><a href=\"../pkg2/DocumentedNonGenericChild.html#parentField\">"
+                + "parentField</a></span> - Variable in class pkg2.<a href=\"../pkg2/DocumentedNonGenericChild.html\" "
+                + "title=\"class in pkg2\">DocumentedNonGenericChild</a></dt>\n"
+                + "<dd>\n<div class=\"block\">A field.</div>\n"
+                + "</dd>\n",
+                "<dt><span class=\"member-name-link\"><a href=\"../pkg2/DocumentedNonGenericChild.html#parentMethod(T)\">"
+                + "parentMethod(String)</a></span> - Method in class pkg2.<a "
+                + "href=\"../pkg2/DocumentedNonGenericChild.html\" title=\"class in pkg2\">DocumentedNonGenericChild</a></dt>\n"
+                + "<dd>\n<div class=\"block\">Returns some value with an inherited search tag.</div>\n"
+                + "</dd>");
+        checkOutput("member-search-index.js", true,
+                "{\"p\":\"pkg2\",\"c\":\"DocumentedNonGenericChild\",\"l\":\"parentField\"}",
+                "{\"p\":\"pkg2\",\"c\":\"DocumentedNonGenericChild\",\"l\":\"parentMethod(String)"
+                + "\",\"u\":\"parentMethod(T)\"}");
+        checkOutput("tag-search-index.js", true,
+                "{\"l\":\"inherited search tag\",\"h\":\"pkg2.UndocumentedGenericParent.parentMethod(String)\","
+                + "\"u\":\"pkg2/DocumentedNonGenericChild.html#inheritedsearchtag\"}");
     }
+
 }
diff a/test/langtools/jdk/javadoc/doclet/testModules/TestModules.java b/test/langtools/jdk/javadoc/doclet/testModules/TestModules.java
--- a/test/langtools/jdk/javadoc/doclet/testModules/TestModules.java
+++ b/test/langtools/jdk/javadoc/doclet/testModules/TestModules.java
@@ -494,19 +494,19 @@
                 + "<p>@Deprecated(forRemoval=true)\n"
                 + "</p>\n"
                 + "<h1 title=\"Module\" class=\"title\">Module&nbsp;moduleA</h1>\n"
                 + "</div>"
                 + "<ul class=\"block-list\">\n"
-                + "<li class=\"block-list\">\n"
+                + "<li>\n"
                 + "<ul class=\"block-list\">\n"
-                + "<li class=\"block-list\">\n"
+                + "<li>\n"
                 + "<!-- ============ PACKAGES SUMMARY =========== -->");
         checkOutput("moduleB/module-summary.html", found,
                 "<ul class=\"block-list\">\n"
-                + "<li class=\"block-list\">\n"
+                + "<li>\n"
                 + "<ul class=\"block-list\">\n"
-                + "<li class=\"block-list\">\n"
+                + "<li>\n"
                 + "<!-- ============ PACKAGES SUMMARY =========== -->");
     }
 
     void checkHtml5Description(boolean found) {
         checkOutput("moduleA/module-summary.html", found,
@@ -549,11 +549,11 @@
                 + "</p>\n"
                 + "<h1 title=\"Module\" class=\"title\">Module&nbsp;moduleA</h1>\n"
                 + "</div>\n"
                 + "<section class=\"summary\">\n"
                 + "<ul class=\"block-list\">\n"
-                + "<li class=\"block-list\">\n"
+                + "<li>\n"
                 + "<section class=\"packages-summary\" id=\"packages.summary\">\n"
                 + "<!-- ============ PACKAGES SUMMARY =========== -->");
         checkOutput("moduleB/module-summary.html", found,
                 "<p><a href=\"testpkgmdlB/AnnotationType.html\" title=\"annotation in testpkgmdlB\">@AnnotationType</a>"
                 + "(<a href=\"testpkgmdlB/AnnotationType.html#optional()\">optional</a>=\"Module Annotation\",\n"
@@ -561,11 +561,11 @@
                 + "</p>\n"
                 + "<h1 title=\"Module\" class=\"title\">Module&nbsp;moduleB</h1>\n"
                 + "</div>\n"
                 + "<section class=\"summary\">\n"
                 + "<ul class=\"block-list\">\n"
-                + "<li class=\"block-list\">\n"
+                + "<li>\n"
                 + "<section class=\"packages-summary\" id=\"packages.summary\">\n"
                 + "<!-- ============ PACKAGES SUMMARY =========== -->");
     }
 
     void checkModuleLink() {
