<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/synchronizer.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="sharedRuntime.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> next &gt;</center>    <h2>src/hotspot/share/runtime/synchronizer.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 433 // returns true  -- to indicate the call was satisfied.
 434 // returns false -- to indicate the call needs the services of the slow-path.
 435 // A no-loitering ordinance is in effect for code in the quick_* family
 436 // operators: safepoints or indefinite blocking (blocking that might span a
 437 // safepoint) are forbidden. Generally the thread_state() is _in_Java upon
 438 // entry.
 439 //
 440 // Consider: An interesting optimization is to have the JIT recognize the
 441 // following common idiom:
 442 //   synchronized (someobj) { .... ; notify(); }
 443 // That is, we find a notify() or notifyAll() call that immediately precedes
 444 // the monitorexit operation.  In that case the JIT could fuse the operations
 445 // into a single notifyAndExit() runtime primitive.
 446 
 447 bool ObjectSynchronizer::quick_notify(oopDesc* obj, Thread* self, bool all) {
 448   assert(!SafepointSynchronize::is_at_safepoint(), &quot;invariant&quot;);
 449   assert(self-&gt;is_Java_thread(), &quot;invariant&quot;);
 450   assert(((JavaThread *) self)-&gt;thread_state() == _thread_in_Java, &quot;invariant&quot;);
 451   NoSafepointVerifier nsv;
 452   if (obj == NULL) return false;  // slow-path for invalid obj
<span class="line-modified"> 453   assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_value(), &quot;monitor op on value type&quot;);</span>
 454   const markWord mark = obj-&gt;mark();
 455 
 456   if (mark.has_locker() &amp;&amp; self-&gt;is_lock_owned((address)mark.locker())) {
 457     // Degenerate notify
 458     // stack-locked by caller so by definition the implied waitset is empty.
 459     return true;
 460   }
 461 
 462   if (mark.has_monitor()) {
 463     ObjectMonitor* const mon = mark.monitor();
 464     assert(mon-&gt;object() == obj, &quot;invariant&quot;);
 465     if (mon-&gt;owner() != self) return false;  // slow-path for IMS exception
 466 
 467     if (mon-&gt;first_waiter() != NULL) {
 468       // We have one or more waiters. Since this is an inflated monitor
 469       // that we own, we can transfer one or more threads from the waitset
 470       // to the entrylist here and now, avoiding the slow-path.
 471       if (all) {
 472         DTRACE_MONITOR_PROBE(notifyAll, mon, obj, self);
 473       } else {
</pre>
<hr />
<pre>
 484   }
 485 
 486   // biased locking and any other IMS exception states take the slow-path
 487   return false;
 488 }
 489 
 490 
 491 // The LockNode emitted directly at the synchronization site would have
 492 // been too big if it were to have included support for the cases of inflated
 493 // recursive enter and exit, so they go here instead.
 494 // Note that we can&#39;t safely call AsyncPrintJavaStack() from within
 495 // quick_enter() as our thread state remains _in_Java.
 496 
 497 bool ObjectSynchronizer::quick_enter(oop obj, Thread* self,
 498                                      BasicLock * lock) {
 499   assert(!SafepointSynchronize::is_at_safepoint(), &quot;invariant&quot;);
 500   assert(self-&gt;is_Java_thread(), &quot;invariant&quot;);
 501   assert(((JavaThread *) self)-&gt;thread_state() == _thread_in_Java, &quot;invariant&quot;);
 502   NoSafepointVerifier nsv;
 503   if (obj == NULL) return false;       // Need to throw NPE
<span class="line-modified"> 504   assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_value(), &quot;monitor op on value type&quot;);</span>
 505   const markWord mark = obj-&gt;mark();
 506 
 507   if (mark.has_monitor()) {
 508     ObjectMonitor* const m = mark.monitor();
 509     if (AsyncDeflateIdleMonitors) {
 510       // An async deflation can race us before we manage to make the
 511       // ObjectMonitor busy by setting the owner below. If we detect
 512       // that race we just bail out to the slow-path here.
 513       if (m-&gt;object() == NULL) {
 514         return false;
 515       }
 516     } else {
 517       assert(m-&gt;object() == obj, &quot;invariant&quot;);
 518     }
 519     Thread* const owner = (Thread *) m-&gt;_owner;
 520 
 521     // Lock contention and Transactional Lock Elision (TLE) diagnostics
 522     // and observability
 523     // Case: light contention possibly amenable to TLE
 524     // Case: TLE inimical operations such as nested/recursive synchronization
</pre>
<hr />
<pre>
 595   // so it does not matter what the value is, except that it
 596   // must be non-zero to avoid looking like a re-entrant lock,
 597   // and must not look locked either.
 598   lock-&gt;set_displaced_header(markWord::unused_mark());
 599   // An async deflation can race after the inflate() call and before
 600   // enter() can make the ObjectMonitor busy. enter() returns false if
 601   // we have lost the race to async deflation and we simply try again.
 602   while (true) {
 603     ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_monitor_enter);
 604     if (monitor-&gt;enter(THREAD)) {
 605       return;
 606     }
 607   }
 608 }
 609 
 610 void ObjectSynchronizer::exit(oop object, BasicLock* lock, TRAPS) {
 611   markWord mark = object-&gt;mark();
 612   if (EnableValhalla &amp;&amp; mark.is_always_locked()) {
 613     return;
 614   }
<span class="line-modified"> 615   assert(!EnableValhalla || !object-&gt;klass()-&gt;is_value(), &quot;monitor op on value type&quot;);</span>
 616   // We cannot check for Biased Locking if we are racing an inflation.
 617   assert(mark == markWord::INFLATING() ||
 618          !mark.has_bias_pattern(), &quot;should not see bias pattern here&quot;);
 619 
 620   markWord dhw = lock-&gt;displaced_header();
 621   if (dhw.value() == 0) {
 622     // If the displaced header is NULL, then this exit matches up with
 623     // a recursive enter. No real work to do here except for diagnostics.
 624 #ifndef PRODUCT
 625     if (mark != markWord::INFLATING()) {
 626       // Only do diagnostics if we are not racing an inflation. Simply
 627       // exiting a recursive enter of a Java Monitor that is being
 628       // inflated is safe; see the has_monitor() comment below.
 629       assert(!mark.is_neutral(), &quot;invariant&quot;);
 630       assert(!mark.has_locker() ||
 631              THREAD-&gt;is_lock_owned((address)mark.locker()), &quot;invariant&quot;);
 632       if (mark.has_monitor()) {
 633         // The BasicLock&#39;s displaced_header is marked as a recursive
 634         // enter and we have an inflated Java Monitor (ObjectMonitor).
 635         // This is a special case where the Java Monitor was inflated
</pre>
<hr />
<pre>
 659   // We have to take the slow-path of possible inflation and then exit.
 660   // The ObjectMonitor* can&#39;t be async deflated until ownership is
 661   // dropped inside exit() and the ObjectMonitor* must be !is_busy().
 662   ObjectMonitor* monitor = inflate(THREAD, object, inflate_cause_vm_internal);
 663   monitor-&gt;exit(true, THREAD);
 664 }
 665 
 666 // -----------------------------------------------------------------------------
 667 // Class Loader  support to workaround deadlocks on the class loader lock objects
 668 // Also used by GC
 669 // complete_exit()/reenter() are used to wait on a nested lock
 670 // i.e. to give up an outer lock completely and then re-enter
 671 // Used when holding nested locks - lock acquisition order: lock1 then lock2
 672 //  1) complete_exit lock1 - saving recursion count
 673 //  2) wait on lock2
 674 //  3) when notified on lock2, unlock lock2
 675 //  4) reenter lock1 with original recursion count
 676 //  5) lock lock2
 677 // NOTE: must use heavy weight monitor to handle complete_exit/reenter()
 678 intx ObjectSynchronizer::complete_exit(Handle obj, TRAPS) {
<span class="line-modified"> 679   assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_value(), &quot;monitor op on value type&quot;);</span>
 680   if (UseBiasedLocking) {
 681     BiasedLocking::revoke(obj, THREAD);
 682     assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
 683   }
 684 
 685   // The ObjectMonitor* can&#39;t be async deflated until ownership is
 686   // dropped inside exit() and the ObjectMonitor* must be !is_busy().
 687   ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);
 688   intptr_t ret_code = monitor-&gt;complete_exit(THREAD);
 689   return ret_code;
 690 }
 691 
 692 // NOTE: must use heavy weight monitor to handle complete_exit/reenter()
 693 void ObjectSynchronizer::reenter(Handle obj, intx recursions, TRAPS) {
<span class="line-modified"> 694   assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_value(), &quot;monitor op on value type&quot;);</span>
 695   if (UseBiasedLocking) {
 696     BiasedLocking::revoke(obj, THREAD);
 697     assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
 698   }
 699 
 700   // An async deflation can race after the inflate() call and before
 701   // reenter() -&gt; enter() can make the ObjectMonitor busy. reenter() -&gt;
 702   // enter() returns false if we have lost the race to async deflation
 703   // and we simply try again.
 704   while (true) {
 705     ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);
 706     if (monitor-&gt;reenter(recursions, THREAD)) {
 707       return;
 708     }
 709   }
 710 }
 711 
 712 // -----------------------------------------------------------------------------
 713 // JNI locks on java objects
 714 // NOTE: must use heavy weight monitor to handle jni monitor enter
</pre>
<hr />
<pre>
 995     // This is probably the best overall implementation -- we&#39;ll
 996     // likely make this the default in future releases.
 997     unsigned t = self-&gt;_hashStateX;
 998     t ^= (t &lt;&lt; 11);
 999     self-&gt;_hashStateX = self-&gt;_hashStateY;
1000     self-&gt;_hashStateY = self-&gt;_hashStateZ;
1001     self-&gt;_hashStateZ = self-&gt;_hashStateW;
1002     unsigned v = self-&gt;_hashStateW;
1003     v = (v ^ (v &gt;&gt; 19)) ^ (t ^ (t &gt;&gt; 8));
1004     self-&gt;_hashStateW = v;
1005     value = v;
1006   }
1007 
1008   value &amp;= markWord::hash_mask;
1009   if (value == 0) value = 0xBAD;
1010   assert(value != markWord::no_hash, &quot;invariant&quot;);
1011   return value;
1012 }
1013 
1014 intptr_t ObjectSynchronizer::FastHashCode(Thread* self, oop obj) {
<span class="line-modified">1015   if (EnableValhalla &amp;&amp; obj-&gt;klass()-&gt;is_value()) {</span>
<span class="line-modified">1016     // Expected tooling to override hashCode for value type, just don&#39;t crash</span>
1017     if (log_is_enabled(Debug, monitorinflation)) {
1018       ResourceMark rm;
1019       log_debug(monitorinflation)(&quot;FastHashCode for value type: %s&quot;, obj-&gt;klass()-&gt;external_name());
1020     }
1021     return obj-&gt;klass()-&gt;java_mirror()-&gt;identity_hash();
1022   }
1023   if (UseBiasedLocking) {
1024     // NOTE: many places throughout the JVM do not expect a safepoint
1025     // to be taken here, in particular most operations on perm gen
1026     // objects. However, we only ever bias Java instances and all of
1027     // the call sites of identity_hash that might revoke biases have
1028     // been checked to make sure they can handle a safepoint. The
1029     // added check of the bias pattern is to avoid useless calls to
1030     // thread-local storage.
1031     if (obj-&gt;mark().has_bias_pattern()) {
1032       // Handle for oop obj in case of STW safepoint
1033       Handle hobj(self, obj);
1034       // Relaxing assertion for bug 6320749.
1035       assert(Universe::verify_in_progress() ||
1036              !SafepointSynchronize::is_at_safepoint(),
</pre>
<hr />
<pre>
1794 void ObjectSynchronizer::inflate_helper(oop obj) {
1795   markWord mark = obj-&gt;mark();
1796   if (mark.has_monitor()) {
1797     ObjectMonitor* monitor = mark.monitor();
1798     assert(ObjectSynchronizer::verify_objmon_isinpool(monitor), &quot;monitor=&quot; INTPTR_FORMAT &quot; is invalid&quot;, p2i(monitor));
1799     markWord dmw = monitor-&gt;header();
1800     assert(dmw.is_neutral(), &quot;sanity check: header=&quot; INTPTR_FORMAT, dmw.value());
1801     return;
1802   }
1803   (void)inflate(Thread::current(), obj, inflate_cause_vm_internal);
1804 }
1805 
1806 ObjectMonitor* ObjectSynchronizer::inflate(Thread* self, oop object,
1807                                            const InflateCause cause) {
1808   // Inflate mutates the heap ...
1809   // Relaxing assertion for bug 6320749.
1810   assert(Universe::verify_in_progress() ||
1811          !SafepointSynchronize::is_at_safepoint(), &quot;invariant&quot;);
1812 
1813   if (EnableValhalla) {
<span class="line-modified">1814     guarantee(!object-&gt;klass()-&gt;is_value(), &quot;Attempt to inflate value type&quot;);</span>
1815   }
1816 
1817   EventJavaMonitorInflate event;
1818 
1819   for (;;) {
1820     const markWord mark = object-&gt;mark();
1821     assert(!mark.has_bias_pattern(), &quot;invariant&quot;);
1822 
1823     // The mark can be in one of the following states:
1824     // *  Inflated     - just return
1825     // *  Stack-locked - coerce it to inflated
1826     // *  INFLATING    - busy wait for conversion to complete
1827     // *  Neutral      - aggressively inflate the object.
1828     // *  BIASED       - Illegal.  We should never see this
1829 
1830     // CASE: inflated
1831     if (mark.has_monitor()) {
1832       ObjectMonitor* inf = mark.monitor();
1833       markWord dmw = inf-&gt;header();
1834       assert(dmw.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, dmw.value());
</pre>
</td>
<td>
<hr />
<pre>
 433 // returns true  -- to indicate the call was satisfied.
 434 // returns false -- to indicate the call needs the services of the slow-path.
 435 // A no-loitering ordinance is in effect for code in the quick_* family
 436 // operators: safepoints or indefinite blocking (blocking that might span a
 437 // safepoint) are forbidden. Generally the thread_state() is _in_Java upon
 438 // entry.
 439 //
 440 // Consider: An interesting optimization is to have the JIT recognize the
 441 // following common idiom:
 442 //   synchronized (someobj) { .... ; notify(); }
 443 // That is, we find a notify() or notifyAll() call that immediately precedes
 444 // the monitorexit operation.  In that case the JIT could fuse the operations
 445 // into a single notifyAndExit() runtime primitive.
 446 
 447 bool ObjectSynchronizer::quick_notify(oopDesc* obj, Thread* self, bool all) {
 448   assert(!SafepointSynchronize::is_at_safepoint(), &quot;invariant&quot;);
 449   assert(self-&gt;is_Java_thread(), &quot;invariant&quot;);
 450   assert(((JavaThread *) self)-&gt;thread_state() == _thread_in_Java, &quot;invariant&quot;);
 451   NoSafepointVerifier nsv;
 452   if (obj == NULL) return false;  // slow-path for invalid obj
<span class="line-modified"> 453   assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_inline_klass(), &quot;monitor op on inline type&quot;);</span>
 454   const markWord mark = obj-&gt;mark();
 455 
 456   if (mark.has_locker() &amp;&amp; self-&gt;is_lock_owned((address)mark.locker())) {
 457     // Degenerate notify
 458     // stack-locked by caller so by definition the implied waitset is empty.
 459     return true;
 460   }
 461 
 462   if (mark.has_monitor()) {
 463     ObjectMonitor* const mon = mark.monitor();
 464     assert(mon-&gt;object() == obj, &quot;invariant&quot;);
 465     if (mon-&gt;owner() != self) return false;  // slow-path for IMS exception
 466 
 467     if (mon-&gt;first_waiter() != NULL) {
 468       // We have one or more waiters. Since this is an inflated monitor
 469       // that we own, we can transfer one or more threads from the waitset
 470       // to the entrylist here and now, avoiding the slow-path.
 471       if (all) {
 472         DTRACE_MONITOR_PROBE(notifyAll, mon, obj, self);
 473       } else {
</pre>
<hr />
<pre>
 484   }
 485 
 486   // biased locking and any other IMS exception states take the slow-path
 487   return false;
 488 }
 489 
 490 
 491 // The LockNode emitted directly at the synchronization site would have
 492 // been too big if it were to have included support for the cases of inflated
 493 // recursive enter and exit, so they go here instead.
 494 // Note that we can&#39;t safely call AsyncPrintJavaStack() from within
 495 // quick_enter() as our thread state remains _in_Java.
 496 
 497 bool ObjectSynchronizer::quick_enter(oop obj, Thread* self,
 498                                      BasicLock * lock) {
 499   assert(!SafepointSynchronize::is_at_safepoint(), &quot;invariant&quot;);
 500   assert(self-&gt;is_Java_thread(), &quot;invariant&quot;);
 501   assert(((JavaThread *) self)-&gt;thread_state() == _thread_in_Java, &quot;invariant&quot;);
 502   NoSafepointVerifier nsv;
 503   if (obj == NULL) return false;       // Need to throw NPE
<span class="line-modified"> 504   assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_inline_klass(), &quot;monitor op on inline type&quot;);</span>
 505   const markWord mark = obj-&gt;mark();
 506 
 507   if (mark.has_monitor()) {
 508     ObjectMonitor* const m = mark.monitor();
 509     if (AsyncDeflateIdleMonitors) {
 510       // An async deflation can race us before we manage to make the
 511       // ObjectMonitor busy by setting the owner below. If we detect
 512       // that race we just bail out to the slow-path here.
 513       if (m-&gt;object() == NULL) {
 514         return false;
 515       }
 516     } else {
 517       assert(m-&gt;object() == obj, &quot;invariant&quot;);
 518     }
 519     Thread* const owner = (Thread *) m-&gt;_owner;
 520 
 521     // Lock contention and Transactional Lock Elision (TLE) diagnostics
 522     // and observability
 523     // Case: light contention possibly amenable to TLE
 524     // Case: TLE inimical operations such as nested/recursive synchronization
</pre>
<hr />
<pre>
 595   // so it does not matter what the value is, except that it
 596   // must be non-zero to avoid looking like a re-entrant lock,
 597   // and must not look locked either.
 598   lock-&gt;set_displaced_header(markWord::unused_mark());
 599   // An async deflation can race after the inflate() call and before
 600   // enter() can make the ObjectMonitor busy. enter() returns false if
 601   // we have lost the race to async deflation and we simply try again.
 602   while (true) {
 603     ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_monitor_enter);
 604     if (monitor-&gt;enter(THREAD)) {
 605       return;
 606     }
 607   }
 608 }
 609 
 610 void ObjectSynchronizer::exit(oop object, BasicLock* lock, TRAPS) {
 611   markWord mark = object-&gt;mark();
 612   if (EnableValhalla &amp;&amp; mark.is_always_locked()) {
 613     return;
 614   }
<span class="line-modified"> 615   assert(!EnableValhalla || !object-&gt;klass()-&gt;is_inline_klass(), &quot;monitor op on inline type&quot;);</span>
 616   // We cannot check for Biased Locking if we are racing an inflation.
 617   assert(mark == markWord::INFLATING() ||
 618          !mark.has_bias_pattern(), &quot;should not see bias pattern here&quot;);
 619 
 620   markWord dhw = lock-&gt;displaced_header();
 621   if (dhw.value() == 0) {
 622     // If the displaced header is NULL, then this exit matches up with
 623     // a recursive enter. No real work to do here except for diagnostics.
 624 #ifndef PRODUCT
 625     if (mark != markWord::INFLATING()) {
 626       // Only do diagnostics if we are not racing an inflation. Simply
 627       // exiting a recursive enter of a Java Monitor that is being
 628       // inflated is safe; see the has_monitor() comment below.
 629       assert(!mark.is_neutral(), &quot;invariant&quot;);
 630       assert(!mark.has_locker() ||
 631              THREAD-&gt;is_lock_owned((address)mark.locker()), &quot;invariant&quot;);
 632       if (mark.has_monitor()) {
 633         // The BasicLock&#39;s displaced_header is marked as a recursive
 634         // enter and we have an inflated Java Monitor (ObjectMonitor).
 635         // This is a special case where the Java Monitor was inflated
</pre>
<hr />
<pre>
 659   // We have to take the slow-path of possible inflation and then exit.
 660   // The ObjectMonitor* can&#39;t be async deflated until ownership is
 661   // dropped inside exit() and the ObjectMonitor* must be !is_busy().
 662   ObjectMonitor* monitor = inflate(THREAD, object, inflate_cause_vm_internal);
 663   monitor-&gt;exit(true, THREAD);
 664 }
 665 
 666 // -----------------------------------------------------------------------------
 667 // Class Loader  support to workaround deadlocks on the class loader lock objects
 668 // Also used by GC
 669 // complete_exit()/reenter() are used to wait on a nested lock
 670 // i.e. to give up an outer lock completely and then re-enter
 671 // Used when holding nested locks - lock acquisition order: lock1 then lock2
 672 //  1) complete_exit lock1 - saving recursion count
 673 //  2) wait on lock2
 674 //  3) when notified on lock2, unlock lock2
 675 //  4) reenter lock1 with original recursion count
 676 //  5) lock lock2
 677 // NOTE: must use heavy weight monitor to handle complete_exit/reenter()
 678 intx ObjectSynchronizer::complete_exit(Handle obj, TRAPS) {
<span class="line-modified"> 679   assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_inline_klass(), &quot;monitor op on inline type&quot;);</span>
 680   if (UseBiasedLocking) {
 681     BiasedLocking::revoke(obj, THREAD);
 682     assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
 683   }
 684 
 685   // The ObjectMonitor* can&#39;t be async deflated until ownership is
 686   // dropped inside exit() and the ObjectMonitor* must be !is_busy().
 687   ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);
 688   intptr_t ret_code = monitor-&gt;complete_exit(THREAD);
 689   return ret_code;
 690 }
 691 
 692 // NOTE: must use heavy weight monitor to handle complete_exit/reenter()
 693 void ObjectSynchronizer::reenter(Handle obj, intx recursions, TRAPS) {
<span class="line-modified"> 694   assert(!EnableValhalla || !obj-&gt;klass()-&gt;is_inline_klass(), &quot;monitor op on inline type&quot;);</span>
 695   if (UseBiasedLocking) {
 696     BiasedLocking::revoke(obj, THREAD);
 697     assert(!obj-&gt;mark().has_bias_pattern(), &quot;biases should be revoked by now&quot;);
 698   }
 699 
 700   // An async deflation can race after the inflate() call and before
 701   // reenter() -&gt; enter() can make the ObjectMonitor busy. reenter() -&gt;
 702   // enter() returns false if we have lost the race to async deflation
 703   // and we simply try again.
 704   while (true) {
 705     ObjectMonitor* monitor = inflate(THREAD, obj(), inflate_cause_vm_internal);
 706     if (monitor-&gt;reenter(recursions, THREAD)) {
 707       return;
 708     }
 709   }
 710 }
 711 
 712 // -----------------------------------------------------------------------------
 713 // JNI locks on java objects
 714 // NOTE: must use heavy weight monitor to handle jni monitor enter
</pre>
<hr />
<pre>
 995     // This is probably the best overall implementation -- we&#39;ll
 996     // likely make this the default in future releases.
 997     unsigned t = self-&gt;_hashStateX;
 998     t ^= (t &lt;&lt; 11);
 999     self-&gt;_hashStateX = self-&gt;_hashStateY;
1000     self-&gt;_hashStateY = self-&gt;_hashStateZ;
1001     self-&gt;_hashStateZ = self-&gt;_hashStateW;
1002     unsigned v = self-&gt;_hashStateW;
1003     v = (v ^ (v &gt;&gt; 19)) ^ (t ^ (t &gt;&gt; 8));
1004     self-&gt;_hashStateW = v;
1005     value = v;
1006   }
1007 
1008   value &amp;= markWord::hash_mask;
1009   if (value == 0) value = 0xBAD;
1010   assert(value != markWord::no_hash, &quot;invariant&quot;);
1011   return value;
1012 }
1013 
1014 intptr_t ObjectSynchronizer::FastHashCode(Thread* self, oop obj) {
<span class="line-modified">1015   if (EnableValhalla &amp;&amp; obj-&gt;klass()-&gt;is_inline_klass()) {</span>
<span class="line-modified">1016     // Expected tooling to override hashCode for inline type, just don&#39;t crash</span>
1017     if (log_is_enabled(Debug, monitorinflation)) {
1018       ResourceMark rm;
1019       log_debug(monitorinflation)(&quot;FastHashCode for value type: %s&quot;, obj-&gt;klass()-&gt;external_name());
1020     }
1021     return obj-&gt;klass()-&gt;java_mirror()-&gt;identity_hash();
1022   }
1023   if (UseBiasedLocking) {
1024     // NOTE: many places throughout the JVM do not expect a safepoint
1025     // to be taken here, in particular most operations on perm gen
1026     // objects. However, we only ever bias Java instances and all of
1027     // the call sites of identity_hash that might revoke biases have
1028     // been checked to make sure they can handle a safepoint. The
1029     // added check of the bias pattern is to avoid useless calls to
1030     // thread-local storage.
1031     if (obj-&gt;mark().has_bias_pattern()) {
1032       // Handle for oop obj in case of STW safepoint
1033       Handle hobj(self, obj);
1034       // Relaxing assertion for bug 6320749.
1035       assert(Universe::verify_in_progress() ||
1036              !SafepointSynchronize::is_at_safepoint(),
</pre>
<hr />
<pre>
1794 void ObjectSynchronizer::inflate_helper(oop obj) {
1795   markWord mark = obj-&gt;mark();
1796   if (mark.has_monitor()) {
1797     ObjectMonitor* monitor = mark.monitor();
1798     assert(ObjectSynchronizer::verify_objmon_isinpool(monitor), &quot;monitor=&quot; INTPTR_FORMAT &quot; is invalid&quot;, p2i(monitor));
1799     markWord dmw = monitor-&gt;header();
1800     assert(dmw.is_neutral(), &quot;sanity check: header=&quot; INTPTR_FORMAT, dmw.value());
1801     return;
1802   }
1803   (void)inflate(Thread::current(), obj, inflate_cause_vm_internal);
1804 }
1805 
1806 ObjectMonitor* ObjectSynchronizer::inflate(Thread* self, oop object,
1807                                            const InflateCause cause) {
1808   // Inflate mutates the heap ...
1809   // Relaxing assertion for bug 6320749.
1810   assert(Universe::verify_in_progress() ||
1811          !SafepointSynchronize::is_at_safepoint(), &quot;invariant&quot;);
1812 
1813   if (EnableValhalla) {
<span class="line-modified">1814     guarantee(!object-&gt;klass()-&gt;is_inline_klass(), &quot;Attempt to inflate inline type&quot;);</span>
1815   }
1816 
1817   EventJavaMonitorInflate event;
1818 
1819   for (;;) {
1820     const markWord mark = object-&gt;mark();
1821     assert(!mark.has_bias_pattern(), &quot;invariant&quot;);
1822 
1823     // The mark can be in one of the following states:
1824     // *  Inflated     - just return
1825     // *  Stack-locked - coerce it to inflated
1826     // *  INFLATING    - busy wait for conversion to complete
1827     // *  Neutral      - aggressively inflate the object.
1828     // *  BIASED       - Illegal.  We should never see this
1829 
1830     // CASE: inflated
1831     if (mark.has_monitor()) {
1832       ObjectMonitor* inf = mark.monitor();
1833       markWord dmw = inf-&gt;header();
1834       assert(dmw.is_neutral(), &quot;invariant: header=&quot; INTPTR_FORMAT, dmw.value());
</pre>
</td>
</tr>
</table>
<center><a href="sharedRuntime.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> next &gt;</center>  </body>
</html>