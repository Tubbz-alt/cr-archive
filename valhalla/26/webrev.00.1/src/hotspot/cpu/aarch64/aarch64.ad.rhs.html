<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on, compressed klass
 1101     // pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   if (UseBarriersForVolatile) {
 1371     // we need to plant a dmb
 1372     return false;
 1373   }
 1374 
 1375   MemBarNode* mb = barrier-&gt;as_MemBar();
 1376 
 1377   if (mb-&gt;trailing_load()) {
 1378     return true;
 1379   }
 1380 
 1381   if (mb-&gt;trailing_load_store()) {
 1382     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1383     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1384     return is_CAS(load_store-&gt;Opcode(), true);
 1385   }
 1386 
 1387   return false;
 1388 }
 1389 
 1390 bool needs_acquiring_load(const Node *n)
 1391 {
 1392   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1393   if (UseBarriersForVolatile) {
 1394     // we use a normal load and a dmb
 1395     return false;
 1396   }
 1397 
 1398   LoadNode *ld = n-&gt;as_Load();
 1399 
 1400   return ld-&gt;is_acquire();
 1401 }
 1402 
 1403 bool unnecessary_release(const Node *n)
 1404 {
 1405   assert((n-&gt;is_MemBar() &amp;&amp;
 1406 	  n-&gt;Opcode() == Op_MemBarRelease),
 1407 	 &quot;expecting a release membar&quot;);
 1408 
 1409   if (UseBarriersForVolatile) {
 1410     // we need to plant a dmb
 1411     return false;
 1412   }
 1413 
 1414   MemBarNode *barrier = n-&gt;as_MemBar();
 1415   if (!barrier-&gt;leading()) {
 1416     return false;
 1417   } else {
 1418     Node* trailing = barrier-&gt;trailing_membar();
 1419     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1420     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1421     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1422 
 1423     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1424     if (mem-&gt;is_Store()) {
 1425       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1426       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1427       return true;
 1428     } else {
 1429       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1430       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1431       return is_CAS(mem-&gt;Opcode(), true);
 1432     }
 1433   }
 1434   return false;
 1435 }
 1436 
 1437 bool unnecessary_volatile(const Node *n)
 1438 {
 1439   // assert n-&gt;is_MemBar();
 1440   if (UseBarriersForVolatile) {
 1441     // we need to plant a dmb
 1442     return false;
 1443   }
 1444 
 1445   MemBarNode *mbvol = n-&gt;as_MemBar();
 1446 
 1447   bool release = mbvol-&gt;trailing_store();
 1448   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1449 #ifdef ASSERT
 1450   if (release) {
 1451     Node* leading = mbvol-&gt;leading_membar();
 1452     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1453     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1454     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1455   }
 1456 #endif
 1457 
 1458   return release;
 1459 }
 1460 
 1461 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1462 
 1463 bool needs_releasing_store(const Node *n)
 1464 {
 1465   // assert n-&gt;is_Store();
 1466   if (UseBarriersForVolatile) {
 1467     // we use a normal store and dmb combination
 1468     return false;
 1469   }
 1470 
 1471   StoreNode *st = n-&gt;as_Store();
 1472 
 1473   return st-&gt;trailing_membar() != NULL;
 1474 }
 1475 
 1476 // predicate controlling translation of CAS
 1477 //
 1478 // returns true if CAS needs to use an acquiring load otherwise false
 1479 
 1480 bool needs_acquiring_load_exclusive(const Node *n)
 1481 {
 1482   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1483   if (UseBarriersForVolatile) {
 1484     return false;
 1485   }
 1486 
 1487   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1488   if (is_CAS(n-&gt;Opcode(), false)) {
 1489     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1490   } else {
 1491     return ldst-&gt;trailing_membar() != NULL;
 1492   }
 1493 
 1494   // so we can just return true here
 1495   return true;
 1496 }
 1497 
 1498 #define __ _masm.
 1499 
 1500 // advance declarations for helper functions to convert register
 1501 // indices to register objects
 1502 
 1503 // the ad file has to provide implementations of certain methods
 1504 // expected by the generic code
 1505 //
 1506 // REQUIRED FUNCTIONALITY
 1507 
 1508 //=============================================================================
 1509 
 1510 // !!!!! Special hack to get all types of calls to specify the byte offset
 1511 //       from the start of the call to the point where the return address
 1512 //       will point.
 1513 
 1514 int MachCallStaticJavaNode::ret_addr_offset()
 1515 {
 1516   // call should be a simple bl
 1517   int off = 4;
 1518   return off;
 1519 }
 1520 
 1521 int MachCallDynamicJavaNode::ret_addr_offset()
 1522 {
 1523   return 16; // movz, movk, movk, bl
 1524 }
 1525 
 1526 int MachCallRuntimeNode::ret_addr_offset() {
 1527   // for generated stubs the call will be
 1528   //   far_call(addr)
 1529   // for real runtime callouts it will be six instructions
 1530   // see aarch64_enc_java_to_runtime
 1531   //   adr(rscratch2, retaddr)
 1532   //   lea(rscratch1, RuntimeAddress(addr)
 1533   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1534   //   blr(rscratch1)
 1535   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1536   if (cb) {
 1537     return MacroAssembler::far_branch_size();
 1538   } else {
 1539     return 6 * NativeInstruction::instruction_size;
 1540   }
 1541 }
 1542 
 1543 // Indicate if the safepoint node needs the polling page as an input
 1544 
 1545 // the shared code plants the oop data at the start of the generated
 1546 // code for the safepoint node and that needs ot be at the load
 1547 // instruction itself. so we cannot plant a mov of the safepoint poll
 1548 // address followed by a load. setting this to true means the mov is
 1549 // scheduled as a prior instruction. that&#39;s better for scheduling
 1550 // anyway.
 1551 
 1552 bool SafePointNode::needs_polling_address_input()
 1553 {
 1554   return true;
 1555 }
 1556 
 1557 //=============================================================================
 1558 
 1559 #ifndef PRODUCT
 1560 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1561   st-&gt;print(&quot;BREAKPOINT&quot;);
 1562 }
 1563 #endif
 1564 
 1565 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1566   C2_MacroAssembler _masm(&amp;cbuf);
 1567   __ brk(0);
 1568 }
 1569 
 1570 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1571   return MachNode::size(ra_);
 1572 }
 1573 
 1574 //=============================================================================
 1575 
 1576 #ifndef PRODUCT
 1577   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1578     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1579   }
 1580 #endif
 1581 
 1582   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1583     C2_MacroAssembler _masm(&amp;cbuf);
 1584     for (int i = 0; i &lt; _count; i++) {
 1585       __ nop();
 1586     }
 1587   }
 1588 
 1589   uint MachNopNode::size(PhaseRegAlloc*) const {
 1590     return _count * NativeInstruction::instruction_size;
 1591   }
 1592 
 1593 //=============================================================================
 1594 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1595 
 1596 int ConstantTable::calculate_table_base_offset() const {
 1597   return 0;  // absolute addressing, no offset
 1598 }
 1599 
 1600 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1601 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1602   ShouldNotReachHere();
 1603 }
 1604 
 1605 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1606   // Empty encoding
 1607 }
 1608 
 1609 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1610   return 0;
 1611 }
 1612 
 1613 #ifndef PRODUCT
 1614 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1615   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1616 }
 1617 #endif
 1618 
 1619 #ifndef PRODUCT
 1620 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1621   Compile* C = ra_-&gt;C;
 1622 
 1623   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1624 
 1625   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1626     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1627 
 1628   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1629     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1630     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1631     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1632   } else {
 1633     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1634     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1635     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1636     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1637   }
 1638 }
 1639 #endif
 1640 
 1641 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1642   Compile* C = ra_-&gt;C;
 1643   C2_MacroAssembler _masm(&amp;cbuf);
 1644 
<a name="1" id="anc1"></a><span class="line-modified"> 1645   __ verified_entry(C, 0);</span>
<span class="line-modified"> 1646   __ bind(*_verified_entry);</span>


























 1647 
 1648   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1649 
 1650   if (C-&gt;has_mach_constant_base_node()) {
 1651     // NOTE: We set the table base offset here because users might be
 1652     // emitted before MachConstantBaseNode.
 1653     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1654     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1655   }
 1656 }
 1657 
 1658 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1659 {
 1660   return MachNode::size(ra_); // too many variables; just compute it
 1661                               // the hard way
 1662 }
 1663 
 1664 int MachPrologNode::reloc() const
 1665 {
 1666   return 0;
 1667 }
 1668 
 1669 //=============================================================================
 1670 
 1671 #ifndef PRODUCT
 1672 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1673   Compile* C = ra_-&gt;C;
 1674   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1675 
 1676   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1677 
 1678   if (framesize == 0) {
 1679     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1680   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1681     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1682     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1683   } else {
 1684     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1685     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1686     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1687   }
 1688 
 1689   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1690     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1691     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1692     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1693   }
 1694 }
 1695 #endif
 1696 
 1697 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1698   Compile* C = ra_-&gt;C;
 1699   C2_MacroAssembler _masm(&amp;cbuf);
 1700   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1701 
 1702   __ remove_frame(framesize);
 1703 
 1704   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1705     __ reserved_stack_check();
 1706   }
 1707 
 1708   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1709     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1710   }
 1711 }
 1712 
 1713 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1714   // Variable size. Determine dynamically.
 1715   return MachNode::size(ra_);
 1716 }
 1717 
 1718 int MachEpilogNode::reloc() const {
 1719   // Return number of relocatable values contained in this instruction.
 1720   return 1; // 1 for polling page.
 1721 }
 1722 
 1723 const Pipeline * MachEpilogNode::pipeline() const {
 1724   return MachNode::pipeline_class();
 1725 }
 1726 
 1727 //=============================================================================
 1728 
 1729 // Figure out which register class each belongs in: rc_int, rc_float or
 1730 // rc_stack.
 1731 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1732 
 1733 static enum RC rc_class(OptoReg::Name reg) {
 1734 
 1735   if (reg == OptoReg::Bad) {
 1736     return rc_bad;
 1737   }
 1738 
 1739   // we have 30 int registers * 2 halves
 1740   // (rscratch1 and rscratch2 are omitted)
 1741   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1742 
 1743   if (reg &lt; slots_of_int_registers) {
 1744     return rc_int;
 1745   }
 1746 
 1747   // we have 32 float register * 4 halves
 1748   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1749     return rc_float;
 1750   }
 1751 
 1752   // Between float regs &amp; stack is the flags regs.
 1753   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1754 
 1755   return rc_stack;
 1756 }
 1757 
 1758 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1759   Compile* C = ra_-&gt;C;
 1760 
 1761   // Get registers to move.
 1762   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1763   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1764   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1765   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1766 
 1767   enum RC src_hi_rc = rc_class(src_hi);
 1768   enum RC src_lo_rc = rc_class(src_lo);
 1769   enum RC dst_hi_rc = rc_class(dst_hi);
 1770   enum RC dst_lo_rc = rc_class(dst_lo);
 1771 
 1772   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1773 
 1774   if (src_hi != OptoReg::Bad) {
 1775     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1776            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1777            &quot;expected aligned-adjacent pairs&quot;);
 1778   }
 1779 
 1780   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1781     return 0;            // Self copy, no move.
 1782   }
 1783 
 1784   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1785               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1786   int src_offset = ra_-&gt;reg2offset(src_lo);
 1787   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1788 
 1789   if (bottom_type()-&gt;isa_vect() != NULL) {
 1790     uint ireg = ideal_reg();
 1791     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1792     if (cbuf) {
 1793       C2_MacroAssembler _masm(cbuf);
 1794       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1795       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1796         // stack-&gt;stack
 1797         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1798         if (ireg == Op_VecD) {
 1799           __ unspill(rscratch1, true, src_offset);
 1800           __ spill(rscratch1, true, dst_offset);
 1801         } else {
 1802           __ spill_copy128(src_offset, dst_offset);
 1803         }
 1804       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1805         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1806                ireg == Op_VecD ? __ T8B : __ T16B,
 1807                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1808       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1809         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1810                        ireg == Op_VecD ? __ D : __ Q,
 1811                        ra_-&gt;reg2offset(dst_lo));
 1812       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1813         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1814                        ireg == Op_VecD ? __ D : __ Q,
 1815                        ra_-&gt;reg2offset(src_lo));
 1816       } else {
 1817         ShouldNotReachHere();
 1818       }
 1819     }
 1820   } else if (cbuf) {
 1821     C2_MacroAssembler _masm(cbuf);
 1822     switch (src_lo_rc) {
 1823     case rc_int:
 1824       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1825         if (is64) {
 1826             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1827                    as_Register(Matcher::_regEncode[src_lo]));
 1828         } else {
 1829             C2_MacroAssembler _masm(cbuf);
 1830             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1831                     as_Register(Matcher::_regEncode[src_lo]));
 1832         }
 1833       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1834         if (is64) {
 1835             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1836                      as_Register(Matcher::_regEncode[src_lo]));
 1837         } else {
 1838             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1839                      as_Register(Matcher::_regEncode[src_lo]));
 1840         }
 1841       } else {                    // gpr --&gt; stack spill
 1842         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1843         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1844       }
 1845       break;
 1846     case rc_float:
 1847       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1848         if (is64) {
 1849             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1850                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1851         } else {
 1852             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1853                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1854         }
 1855       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1856           if (cbuf) {
 1857             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1858                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1859         } else {
 1860             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1861                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1862         }
 1863       } else {                    // fpr --&gt; stack spill
 1864         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1865         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1866                  is64 ? __ D : __ S, dst_offset);
 1867       }
 1868       break;
 1869     case rc_stack:
 1870       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1871         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1872       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1873         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1874                    is64 ? __ D : __ S, src_offset);
 1875       } else {                    // stack --&gt; stack copy
 1876         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1877         __ unspill(rscratch1, is64, src_offset);
 1878         __ spill(rscratch1, is64, dst_offset);
 1879       }
 1880       break;
 1881     default:
 1882       assert(false, &quot;bad rc_class for spill&quot;);
 1883       ShouldNotReachHere();
 1884     }
 1885   }
 1886 
 1887   if (st) {
 1888     st-&gt;print(&quot;spill &quot;);
 1889     if (src_lo_rc == rc_stack) {
 1890       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1891     } else {
 1892       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1893     }
 1894     if (dst_lo_rc == rc_stack) {
 1895       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1896     } else {
 1897       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1898     }
 1899     if (bottom_type()-&gt;isa_vect() != NULL) {
 1900       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1901     } else {
 1902       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1903     }
 1904   }
 1905 
 1906   return 0;
 1907 
 1908 }
 1909 
 1910 #ifndef PRODUCT
 1911 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1912   if (!ra_)
 1913     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1914   else
 1915     implementation(NULL, ra_, false, st);
 1916 }
 1917 #endif
 1918 
 1919 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1920   implementation(&amp;cbuf, ra_, false, NULL);
 1921 }
 1922 
 1923 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1924   return MachNode::size(ra_);
 1925 }
 1926 
 1927 //=============================================================================
 1928 
 1929 #ifndef PRODUCT
 1930 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1931   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1932   int reg = ra_-&gt;get_reg_first(this);
 1933   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1934             Matcher::regName[reg], offset);
 1935 }
 1936 #endif
 1937 
 1938 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1939   C2_MacroAssembler _masm(&amp;cbuf);
 1940 
 1941   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1942   int reg    = ra_-&gt;get_encode(this);
 1943 
 1944   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1945     __ add(as_Register(reg), sp, offset);
 1946   } else {
 1947     ShouldNotReachHere();
 1948   }
 1949 }
 1950 
 1951 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1952   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1953   return 4;
 1954 }
 1955 
<a name="2" id="anc2"></a><span class="line-modified"> 1956 ///=============================================================================</span>
<span class="line-added"> 1957 #ifndef PRODUCT</span>
<span class="line-added"> 1958 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const</span>
<span class="line-added"> 1959 {</span>
<span class="line-added"> 1960   st-&gt;print_cr(&quot;# MachVEPNode&quot;);</span>
<span class="line-added"> 1961   if (!_verified) {</span>
<span class="line-added"> 1962     st-&gt;print_cr(&quot;\t load_class&quot;);</span>
<span class="line-added"> 1963   } else {</span>
<span class="line-added"> 1964     st-&gt;print_cr(&quot;\t unpack_value_arg&quot;);</span>
<span class="line-added"> 1965   }</span>
<span class="line-added"> 1966 }</span>
<span class="line-added"> 1967 #endif</span>
<span class="line-added"> 1968 </span>
<span class="line-added"> 1969 void MachVEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const</span>
<span class="line-added"> 1970 {</span>
<span class="line-added"> 1971   MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-added"> 1972 </span>
<span class="line-added"> 1973   if (!_verified) {</span>
<span class="line-added"> 1974     Label skip;</span>
<span class="line-added"> 1975     __ cmp_klass(j_rarg0, rscratch2, rscratch1);</span>
<span class="line-added"> 1976     __ br(Assembler::EQ, skip);</span>
<span class="line-added"> 1977       __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));</span>
<span class="line-added"> 1978     __ bind(skip);</span>
<span class="line-added"> 1979 </span>
<span class="line-added"> 1980   } else {</span>
<span class="line-added"> 1981     // Unpack value type args passed as oop and then jump to</span>
<span class="line-added"> 1982     // the verified entry point (skipping the unverified entry).</span>
<span class="line-added"> 1983     __ unpack_value_args(ra_-&gt;C, _receiver_only);</span>
<span class="line-added"> 1984     __ b(*_verified_entry);</span>
<span class="line-added"> 1985   }</span>
<span class="line-added"> 1986 }</span>
<span class="line-added"> 1987 </span>
<span class="line-added"> 1988 </span>
<span class="line-added"> 1989 uint MachVEPNode::size(PhaseRegAlloc* ra_) const</span>
<span class="line-added"> 1990 {</span>
<span class="line-added"> 1991   return MachNode::size(ra_); // too many variables; just compute it the hard way</span>
<span class="line-added"> 1992 }</span>
<span class="line-added"> 1993 </span>
 1994 
<a name="3" id="anc3"></a><span class="line-added"> 1995 //=============================================================================</span>
 1996 #ifndef PRODUCT
 1997 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1998 {
 1999   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 2000   if (UseCompressedClassPointers) {
 2001     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2002     if (CompressedKlassPointers::shift() != 0) {
 2003       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 2004     }
 2005   } else {
 2006    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2007   }
 2008   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 2009   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2010 }
 2011 #endif
 2012 
 2013 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2014 {
 2015   // This is the unverified entry point.
 2016   C2_MacroAssembler _masm(&amp;cbuf);
<a name="4" id="anc4"></a><span class="line-added"> 2017   Label skip;</span>
 2018 
<a name="5" id="anc5"></a><span class="line-added"> 2019   // UseCompressedClassPointers logic are inside cmp_klass</span>
 2020   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
<a name="6" id="anc6"></a><span class="line-modified"> 2021 </span>
 2022   // TODO
 2023   // can we avoid this skip and still use a reloc?
 2024   __ br(Assembler::EQ, skip);
 2025   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2026   __ bind(skip);
 2027 }
 2028 
 2029 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2030 {
 2031   return MachNode::size(ra_);
 2032 }
 2033 
 2034 // REQUIRED EMIT CODE
 2035 
 2036 //=============================================================================
 2037 
 2038 // Emit exception handler code.
 2039 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2040 {
 2041   // mov rscratch1 #exception_blob_entry_point
 2042   // br rscratch1
 2043   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2044   // That&#39;s why we must use the macroassembler to generate a handler.
 2045   C2_MacroAssembler _masm(&amp;cbuf);
 2046   address base = __ start_a_stub(size_exception_handler());
 2047   if (base == NULL) {
 2048     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2049     return 0;  // CodeBuffer::expand failed
 2050   }
 2051   int offset = __ offset();
 2052   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2053   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2054   __ end_a_stub();
 2055   return offset;
 2056 }
 2057 
 2058 // Emit deopt handler code.
 2059 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2060 {
 2061   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2062   // That&#39;s why we must use the macroassembler to generate a handler.
 2063   C2_MacroAssembler _masm(&amp;cbuf);
 2064   address base = __ start_a_stub(size_deopt_handler());
 2065   if (base == NULL) {
 2066     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2067     return 0;  // CodeBuffer::expand failed
 2068   }
 2069   int offset = __ offset();
 2070 
 2071   __ adr(lr, __ pc());
 2072   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2073 
 2074   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2075   __ end_a_stub();
 2076   return offset;
 2077 }
 2078 
 2079 // REQUIRED MATCHER CODE
 2080 
 2081 //=============================================================================
 2082 
 2083 const bool Matcher::match_rule_supported(int opcode) {
 2084   if (!has_match_rule(opcode))
 2085     return false;
 2086 
 2087   bool ret_value = true;
 2088   switch (opcode) {
 2089     case Op_CacheWB:
 2090     case Op_CacheWBPreSync:
 2091     case Op_CacheWBPostSync:
 2092       if (!VM_Version::supports_data_cache_line_flush()) {
 2093         ret_value = false;
 2094       }
 2095       break;
 2096   }
 2097 
 2098   return ret_value; // Per default match rules are supported.
 2099 }
 2100 
 2101 // Identify extra cases that we might want to provide match rules for vector nodes and
 2102 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2103 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2104   if (!match_rule_supported(opcode)) {
 2105     return false;
 2106   }
 2107 
 2108   // Special cases which require vector length
 2109   switch (opcode) {
 2110     case Op_MulAddVS2VI: {
 2111       if (vlen != 4) {
 2112         return false;
 2113       }
 2114       break;
 2115     }
 2116   }
 2117 
 2118   return true; // Per default match rules are supported.
 2119 }
 2120 
 2121 const bool Matcher::has_predicated_vectors(void) {
 2122   return false;
 2123 }
 2124 
 2125 const int Matcher::float_pressure(int default_pressure_threshold) {
 2126   return default_pressure_threshold;
 2127 }
 2128 
 2129 int Matcher::regnum_to_fpu_offset(int regnum)
 2130 {
 2131   Unimplemented();
 2132   return 0;
 2133 }
 2134 
 2135 // Is this branch offset short enough that a short branch can be used?
 2136 //
 2137 // NOTE: If the platform does not provide any short branch variants, then
 2138 //       this method should return false for offset 0.
 2139 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2140   // The passed offset is relative to address of the branch.
 2141 
 2142   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2143 }
 2144 
 2145 const bool Matcher::isSimpleConstant64(jlong value) {
 2146   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2147   // Probably always true, even if a temp register is required.
 2148   return true;
 2149 }
 2150 
 2151 // true just means we have fast l2f conversion
 2152 const bool Matcher::convL2FSupported(void) {
 2153   return true;
 2154 }
 2155 
 2156 // Vector width in bytes.
 2157 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2158   int size = MIN2(16,(int)MaxVectorSize);
 2159   // Minimum 2 values in vector
 2160   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2161   // But never &lt; 4
 2162   if (size &lt; 4) size = 0;
 2163   return size;
 2164 }
 2165 
 2166 // Limits on vector size (number of elements) loaded into vector.
 2167 const int Matcher::max_vector_size(const BasicType bt) {
 2168   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2169 }
 2170 const int Matcher::min_vector_size(const BasicType bt) {
 2171 //  For the moment limit the vector size to 8 bytes
 2172     int size = 8 / type2aelembytes(bt);
 2173     if (size &lt; 2) size = 2;
 2174     return size;
 2175 }
 2176 
 2177 // Vector ideal reg.
 2178 const uint Matcher::vector_ideal_reg(int len) {
 2179   switch(len) {
 2180     case  8: return Op_VecD;
 2181     case 16: return Op_VecX;
 2182   }
 2183   ShouldNotReachHere();
 2184   return 0;
 2185 }
 2186 
 2187 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 2188   switch(size) {
 2189     case  8: return Op_VecD;
 2190     case 16: return Op_VecX;
 2191   }
 2192   ShouldNotReachHere();
 2193   return 0;
 2194 }
 2195 
 2196 // AES support not yet implemented
 2197 const bool Matcher::pass_original_key_for_aes() {
 2198   return false;
 2199 }
 2200 
 2201 // aarch64 supports misaligned vectors store/load.
 2202 const bool Matcher::misaligned_vectors_ok() {
 2203   return true;
 2204 }
 2205 
 2206 // false =&gt; size gets scaled to BytesPerLong, ok.
 2207 const bool Matcher::init_array_count_is_in_bytes = false;
 2208 
 2209 // Use conditional move (CMOVL)
 2210 const int Matcher::long_cmove_cost() {
 2211   // long cmoves are no more expensive than int cmoves
 2212   return 0;
 2213 }
 2214 
 2215 const int Matcher::float_cmove_cost() {
 2216   // float cmoves are no more expensive than int cmoves
 2217   return 0;
 2218 }
 2219 
 2220 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2221 const bool Matcher::require_postalloc_expand = false;
 2222 
 2223 // Do we need to mask the count passed to shift instructions or does
 2224 // the cpu only look at the lower 5/6 bits anyway?
 2225 const bool Matcher::need_masked_shift_count = false;
 2226 
 2227 // No support for generic vector operands.
 2228 const bool Matcher::supports_generic_vector_operands  = false;
 2229 
 2230 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2231   ShouldNotReachHere(); // generic vector operands not supported
 2232   return NULL;
 2233 }
 2234 
 2235 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2236   ShouldNotReachHere();  // generic vector operands not supported
 2237   return false;
 2238 }
 2239 
 2240 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2241   ShouldNotReachHere();  // generic vector operands not supported
 2242   return false;
 2243 }
 2244 
 2245 // This affects two different things:
 2246 //  - how Decode nodes are matched
 2247 //  - how ImplicitNullCheck opportunities are recognized
 2248 // If true, the matcher will try to remove all Decodes and match them
 2249 // (as operands) into nodes. NullChecks are not prepared to deal with
 2250 // Decodes by final_graph_reshaping().
 2251 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2252 // for a NullCheck. The matcher matches the Decode node into a register.
 2253 // Implicit_null_check optimization moves the Decode along with the
 2254 // memory operation back up before the NullCheck.
 2255 bool Matcher::narrow_oop_use_complex_address() {
 2256   return CompressedOops::shift() == 0;
 2257 }
 2258 
 2259 bool Matcher::narrow_klass_use_complex_address() {
 2260 // TODO
 2261 // decide whether we need to set this to true
 2262   return false;
 2263 }
 2264 
 2265 bool Matcher::const_oop_prefer_decode() {
 2266   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2267   return CompressedOops::base() == NULL;
 2268 }
 2269 
 2270 bool Matcher::const_klass_prefer_decode() {
 2271   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2272   return CompressedKlassPointers::base() == NULL;
 2273 }
 2274 
 2275 // Is it better to copy float constants, or load them directly from
 2276 // memory?  Intel can load a float constant from a direct address,
 2277 // requiring no extra registers.  Most RISCs will have to materialize
 2278 // an address into a register first, so they would do better to copy
 2279 // the constant from stack.
 2280 const bool Matcher::rematerialize_float_constants = false;
 2281 
 2282 // If CPU can load and store mis-aligned doubles directly then no
 2283 // fixup is needed.  Else we split the double into 2 integer pieces
 2284 // and move it piece-by-piece.  Only happens when passing doubles into
 2285 // C code as the Java calling convention forces doubles to be aligned.
 2286 const bool Matcher::misaligned_doubles_ok = true;
 2287 
 2288 // No-op on amd64
 2289 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2290   Unimplemented();
 2291 }
 2292 
 2293 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2294 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2295 
 2296 // Are floats converted to double when stored to stack during
 2297 // deoptimization?
 2298 bool Matcher::float_in_double() { return false; }
 2299 
 2300 // Do ints take an entire long register or just half?
 2301 // The relevant question is how the int is callee-saved:
 2302 // the whole long is written but de-opt&#39;ing will have to extract
 2303 // the relevant 32 bits.
 2304 const bool Matcher::int_in_long = true;
 2305 
 2306 // Return whether or not this register is ever used as an argument.
 2307 // This function is used on startup to build the trampoline stubs in
 2308 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2309 // call in the trampoline, and arguments in those registers not be
 2310 // available to the callee.
 2311 bool Matcher::can_be_java_arg(int reg)
 2312 {
 2313   return
 2314     reg ==  R0_num || reg == R0_H_num ||
 2315     reg ==  R1_num || reg == R1_H_num ||
 2316     reg ==  R2_num || reg == R2_H_num ||
 2317     reg ==  R3_num || reg == R3_H_num ||
 2318     reg ==  R4_num || reg == R4_H_num ||
 2319     reg ==  R5_num || reg == R5_H_num ||
 2320     reg ==  R6_num || reg == R6_H_num ||
 2321     reg ==  R7_num || reg == R7_H_num ||
 2322     reg ==  V0_num || reg == V0_H_num ||
 2323     reg ==  V1_num || reg == V1_H_num ||
 2324     reg ==  V2_num || reg == V2_H_num ||
 2325     reg ==  V3_num || reg == V3_H_num ||
 2326     reg ==  V4_num || reg == V4_H_num ||
 2327     reg ==  V5_num || reg == V5_H_num ||
 2328     reg ==  V6_num || reg == V6_H_num ||
 2329     reg ==  V7_num || reg == V7_H_num;
 2330 }
 2331 
 2332 bool Matcher::is_spillable_arg(int reg)
 2333 {
 2334   return can_be_java_arg(reg);
 2335 }
 2336 
 2337 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2338   return false;
 2339 }
 2340 
 2341 RegMask Matcher::divI_proj_mask() {
 2342   ShouldNotReachHere();
 2343   return RegMask();
 2344 }
 2345 
 2346 // Register for MODI projection of divmodI.
 2347 RegMask Matcher::modI_proj_mask() {
 2348   ShouldNotReachHere();
 2349   return RegMask();
 2350 }
 2351 
 2352 // Register for DIVL projection of divmodL.
 2353 RegMask Matcher::divL_proj_mask() {
 2354   ShouldNotReachHere();
 2355   return RegMask();
 2356 }
 2357 
 2358 // Register for MODL projection of divmodL.
 2359 RegMask Matcher::modL_proj_mask() {
 2360   ShouldNotReachHere();
 2361   return RegMask();
 2362 }
 2363 
 2364 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2365   return FP_REG_mask();
 2366 }
 2367 
 2368 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2369   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2370     Node* u = addp-&gt;fast_out(i);
 2371     if (u-&gt;is_Mem()) {
 2372       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2373       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2374       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2375         return false;
 2376       }
 2377     }
 2378   }
 2379   return true;
 2380 }
 2381 
 2382 const bool Matcher::convi2l_type_required = false;
 2383 
 2384 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2385 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2386   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2387     mstack.push(m, Visit);           // m = ShiftCntV
 2388     return true;
 2389   }
 2390   return false;
 2391 }
 2392 
 2393 // Should the Matcher clone shifts on addressing modes, expecting them
 2394 // to be subsumed into complex addressing expressions or compute them
 2395 // into registers?
 2396 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2397   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2398     return true;
 2399   }
 2400 
 2401   Node *off = m-&gt;in(AddPNode::Offset);
 2402   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2403       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2404       // Are there other uses besides address expressions?
 2405       !is_visited(off)) {
 2406     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2407     mstack.push(off-&gt;in(2), Visit);
 2408     Node *conv = off-&gt;in(1);
 2409     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2410         // Are there other uses besides address expressions?
 2411         !is_visited(conv)) {
 2412       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2413       mstack.push(conv-&gt;in(1), Pre_Visit);
 2414     } else {
 2415       mstack.push(conv, Pre_Visit);
 2416     }
 2417     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2418     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2419     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2420     return true;
 2421   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2422              // Are there other uses besides address expressions?
 2423              !is_visited(off)) {
 2424     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2425     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2426     mstack.push(off-&gt;in(1), Pre_Visit);
 2427     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2428     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2429     return true;
 2430   }
 2431   return false;
 2432 }
 2433 
 2434 void Compile::reshape_address(AddPNode* addp) {
 2435 }
 2436 
<a name="7" id="anc7"></a>
 2437 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2438   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2439   {                                                                     \
 2440     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2441     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2442     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2443     __ INSN(REG, as_Register(BASE));                                    \
 2444   }
 2445 
 2446 
 2447 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2448   {
 2449     Address::extend scale;
 2450 
 2451     // Hooboy, this is fugly.  We need a way to communicate to the
 2452     // encoder that the index needs to be sign extended, so we have to
 2453     // enumerate all the cases.
 2454     switch (opcode) {
 2455     case INDINDEXSCALEDI2L:
 2456     case INDINDEXSCALEDI2LN:
 2457     case INDINDEXI2L:
 2458     case INDINDEXI2LN:
 2459       scale = Address::sxtw(size);
 2460       break;
 2461     default:
 2462       scale = Address::lsl(size);
 2463     }
 2464 
 2465     if (index == -1) {
 2466       return Address(base, disp);
 2467     } else {
 2468       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2469       return Address(base, as_Register(index), scale);
 2470     }
 2471   }
 2472 
 2473 
 2474 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2475 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2476 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2477 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2478                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2479 
 2480   // Used for all non-volatile memory accesses.  The use of
 2481   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2482   // offsets is something of a kludge.
 2483   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2484                         Register reg, int opcode,
 2485                         Register base, int index, int scale, int disp,
 2486                         int size_in_memory)
 2487   {
 2488     Address addr = mem2address(opcode, base, index, scale, disp);
 2489     if (addr.getMode() == Address::base_plus_offset) {
 2490       /* If we get an out-of-range offset it is a bug in the compiler,
 2491          so we assert here. */
 2492       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2493              &quot;c2 compiler bug&quot;);
 2494       /* Fix up any out-of-range offsets. */
 2495       assert_different_registers(rscratch1, base);
 2496       assert_different_registers(rscratch1, reg);
 2497       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2498     }
 2499     (masm.*insn)(reg, addr);
 2500   }
 2501 
 2502   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2503                         FloatRegister reg, int opcode,
 2504                         Register base, int index, int size, int disp,
 2505                         int size_in_memory)
 2506   {
 2507     Address::extend scale;
 2508 
 2509     switch (opcode) {
 2510     case INDINDEXSCALEDI2L:
 2511     case INDINDEXSCALEDI2LN:
 2512       scale = Address::sxtw(size);
 2513       break;
 2514     default:
 2515       scale = Address::lsl(size);
 2516     }
 2517 
 2518     if (index == -1) {
 2519       /* If we get an out-of-range offset it is a bug in the compiler,
 2520          so we assert here. */
 2521       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2522       /* Fix up any out-of-range offsets. */
 2523       assert_different_registers(rscratch1, base);
 2524       Address addr = Address(base, disp);
 2525       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2526       (masm.*insn)(reg, addr);
 2527     } else {
 2528       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2529       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2530     }
 2531   }
 2532 
 2533   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2534                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2535                         int opcode, Register base, int index, int size, int disp)
 2536   {
 2537     if (index == -1) {
 2538       (masm.*insn)(reg, T, Address(base, disp));
 2539     } else {
 2540       assert(disp == 0, &quot;unsupported address mode&quot;);
 2541       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2542     }
 2543   }
 2544 
 2545 %}
 2546 
 2547 
 2548 
 2549 //----------ENCODING BLOCK-----------------------------------------------------
 2550 // This block specifies the encoding classes used by the compiler to
 2551 // output byte streams.  Encoding classes are parameterized macros
 2552 // used by Machine Instruction Nodes in order to generate the bit
 2553 // encoding of the instruction.  Operands specify their base encoding
 2554 // interface with the interface keyword.  There are currently
 2555 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2556 // COND_INTER.  REG_INTER causes an operand to generate a function
 2557 // which returns its register number when queried.  CONST_INTER causes
 2558 // an operand to generate a function which returns the value of the
 2559 // constant when queried.  MEMORY_INTER causes an operand to generate
 2560 // four functions which return the Base Register, the Index Register,
 2561 // the Scale Value, and the Offset Value of the operand when queried.
 2562 // COND_INTER causes an operand to generate six functions which return
 2563 // the encoding code (ie - encoding bits for the instruction)
 2564 // associated with each basic boolean condition for a conditional
 2565 // instruction.
 2566 //
 2567 // Instructions specify two basic values for encoding.  Again, a
 2568 // function is available to check if the constant displacement is an
 2569 // oop. They use the ins_encode keyword to specify their encoding
 2570 // classes (which must be a sequence of enc_class names, and their
 2571 // parameters, specified in the encoding block), and they use the
 2572 // opcode keyword to specify, in order, their primary, secondary, and
 2573 // tertiary opcode.  Only the opcode sections which a particular
 2574 // instruction needs for encoding need to be specified.
 2575 encode %{
 2576   // Build emit functions for each basic byte or larger field in the
 2577   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2578   // from C++ code in the enc_class source block.  Emit functions will
 2579   // live in the main source block for now.  In future, we can
 2580   // generalize this by adding a syntax that specifies the sizes of
 2581   // fields in an order, so that the adlc can build the emit functions
 2582   // automagically
 2583 
 2584   // catch all for unimplemented encodings
 2585   enc_class enc_unimplemented %{
 2586     C2_MacroAssembler _masm(&amp;cbuf);
 2587     __ unimplemented(&quot;C2 catch all&quot;);
 2588   %}
 2589 
 2590   // BEGIN Non-volatile memory access
 2591 
 2592   // This encoding class is generated automatically from ad_encode.m4.
 2593   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2594   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2595     Register dst_reg = as_Register($dst$$reg);
 2596     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2597                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2598   %}
 2599 
 2600   // This encoding class is generated automatically from ad_encode.m4.
 2601   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2602   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2603     Register dst_reg = as_Register($dst$$reg);
 2604     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2605                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2606   %}
 2607 
 2608   // This encoding class is generated automatically from ad_encode.m4.
 2609   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2610   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2611     Register dst_reg = as_Register($dst$$reg);
 2612     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2613                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2614   %}
 2615 
 2616   // This encoding class is generated automatically from ad_encode.m4.
 2617   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2618   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2619     Register dst_reg = as_Register($dst$$reg);
 2620     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2621                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2622   %}
 2623 
 2624   // This encoding class is generated automatically from ad_encode.m4.
 2625   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2626   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2627     Register dst_reg = as_Register($dst$$reg);
 2628     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2629                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2630   %}
 2631 
 2632   // This encoding class is generated automatically from ad_encode.m4.
 2633   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2634   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2635     Register dst_reg = as_Register($dst$$reg);
 2636     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2637                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2638   %}
 2639 
 2640   // This encoding class is generated automatically from ad_encode.m4.
 2641   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2642   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2643     Register dst_reg = as_Register($dst$$reg);
 2644     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2645                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2646   %}
 2647 
 2648   // This encoding class is generated automatically from ad_encode.m4.
 2649   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2650   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2651     Register dst_reg = as_Register($dst$$reg);
 2652     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2653                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2654   %}
 2655 
 2656   // This encoding class is generated automatically from ad_encode.m4.
 2657   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2658   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2659     Register dst_reg = as_Register($dst$$reg);
 2660     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2661                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2662   %}
 2663 
 2664   // This encoding class is generated automatically from ad_encode.m4.
 2665   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2666   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2667     Register dst_reg = as_Register($dst$$reg);
 2668     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2669                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2670   %}
 2671 
 2672   // This encoding class is generated automatically from ad_encode.m4.
 2673   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2674   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2675     Register dst_reg = as_Register($dst$$reg);
 2676     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2677                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2678   %}
 2679 
 2680   // This encoding class is generated automatically from ad_encode.m4.
 2681   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2682   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2683     Register dst_reg = as_Register($dst$$reg);
 2684     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2685                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2686   %}
 2687 
 2688   // This encoding class is generated automatically from ad_encode.m4.
 2689   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2690   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2691     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2692     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2693                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2694   %}
 2695 
 2696   // This encoding class is generated automatically from ad_encode.m4.
 2697   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2698   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2699     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2700     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2701                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2702   %}
 2703 
 2704   // This encoding class is generated automatically from ad_encode.m4.
 2705   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2706   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2707     Register src_reg = as_Register($src$$reg);
 2708     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2709                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2710   %}
 2711 
 2712   // This encoding class is generated automatically from ad_encode.m4.
 2713   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2714   enc_class aarch64_enc_strb0(memory1 mem) %{
 2715     C2_MacroAssembler _masm(&amp;cbuf);
 2716     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2717                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2718   %}
 2719 
 2720   // This encoding class is generated automatically from ad_encode.m4.
 2721   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2722   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2723     Register src_reg = as_Register($src$$reg);
 2724     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2725                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2726   %}
 2727 
 2728   // This encoding class is generated automatically from ad_encode.m4.
 2729   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2730   enc_class aarch64_enc_strh0(memory2 mem) %{
 2731     C2_MacroAssembler _masm(&amp;cbuf);
 2732     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2733                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2734   %}
 2735 
 2736   // This encoding class is generated automatically from ad_encode.m4.
 2737   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2738   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2739     Register src_reg = as_Register($src$$reg);
 2740     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2741                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2742   %}
 2743 
 2744   // This encoding class is generated automatically from ad_encode.m4.
 2745   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2746   enc_class aarch64_enc_strw0(memory4 mem) %{
 2747     C2_MacroAssembler _masm(&amp;cbuf);
 2748     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2749                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2750   %}
 2751 
 2752   // This encoding class is generated automatically from ad_encode.m4.
 2753   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2754   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2755     Register src_reg = as_Register($src$$reg);
 2756     // we sometimes get asked to store the stack pointer into the
 2757     // current thread -- we cannot do that directly on AArch64
 2758     if (src_reg == r31_sp) {
 2759       C2_MacroAssembler _masm(&amp;cbuf);
 2760       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2761       __ mov(rscratch2, sp);
 2762       src_reg = rscratch2;
 2763     }
 2764     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2765                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2766   %}
 2767 
 2768   // This encoding class is generated automatically from ad_encode.m4.
 2769   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2770   enc_class aarch64_enc_str0(memory8 mem) %{
 2771     C2_MacroAssembler _masm(&amp;cbuf);
 2772     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2773                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2774   %}
 2775 
 2776   // This encoding class is generated automatically from ad_encode.m4.
 2777   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2778   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2779     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2780     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2781                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2782   %}
 2783 
 2784   // This encoding class is generated automatically from ad_encode.m4.
 2785   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2786   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2787     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2788     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2789                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2790   %}
 2791 
 2792   // This encoding class is generated automatically from ad_encode.m4.
 2793   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2794   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2795     C2_MacroAssembler _masm(&amp;cbuf);
 2796     address con = (address)$src$$constant;
 2797     // need to do this the hard way until we can manage relocs
 2798     // for 32 bit constants
 2799     __ movoop(rscratch2, (jobject)con);
 2800     if (con) __ encode_heap_oop_not_null(rscratch2);
 2801     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2802                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2803   %}
 2804 
 2805   // This encoding class is generated automatically from ad_encode.m4.
 2806   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2807   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2808     C2_MacroAssembler _masm(&amp;cbuf);
 2809     address con = (address)$src$$constant;
 2810     // need to do this the hard way until we can manage relocs
 2811     // for 32 bit constants
 2812     __ movoop(rscratch2, (jobject)con);
 2813     __ encode_klass_not_null(rscratch2);
 2814     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2815                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2816   %}
 2817 
 2818   // This encoding class is generated automatically from ad_encode.m4.
 2819   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2820   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2821       C2_MacroAssembler _masm(&amp;cbuf);
 2822       __ membar(Assembler::StoreStore);
 2823       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2824                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2825   %}
 2826 
 2827   // END Non-volatile memory access
 2828 
 2829   // Vector loads and stores
 2830   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2831     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2832     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2833        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2834   %}
 2835 
 2836   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2837     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2838     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2839        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2840   %}
 2841 
 2842   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2843     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2844     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2845        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2846   %}
 2847 
 2848   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2849     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2850     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2851        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2852   %}
 2853 
 2854   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2855     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2856     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2857        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2858   %}
 2859 
 2860   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2861     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2862     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2863        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2864   %}
 2865 
 2866   // volatile loads and stores
 2867 
 2868   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2869     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2870                  rscratch1, stlrb);
 2871   %}
 2872 
 2873   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2874     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2875                  rscratch1, stlrh);
 2876   %}
 2877 
 2878   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2879     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2880                  rscratch1, stlrw);
 2881   %}
 2882 
 2883 
 2884   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2885     Register dst_reg = as_Register($dst$$reg);
 2886     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2887              rscratch1, ldarb);
 2888     __ sxtbw(dst_reg, dst_reg);
 2889   %}
 2890 
 2891   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2892     Register dst_reg = as_Register($dst$$reg);
 2893     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2894              rscratch1, ldarb);
 2895     __ sxtb(dst_reg, dst_reg);
 2896   %}
 2897 
 2898   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2899     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2900              rscratch1, ldarb);
 2901   %}
 2902 
 2903   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2904     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2905              rscratch1, ldarb);
 2906   %}
 2907 
 2908   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2909     Register dst_reg = as_Register($dst$$reg);
 2910     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2911              rscratch1, ldarh);
 2912     __ sxthw(dst_reg, dst_reg);
 2913   %}
 2914 
 2915   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2916     Register dst_reg = as_Register($dst$$reg);
 2917     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2918              rscratch1, ldarh);
 2919     __ sxth(dst_reg, dst_reg);
 2920   %}
 2921 
 2922   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2923     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2924              rscratch1, ldarh);
 2925   %}
 2926 
 2927   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2928     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2929              rscratch1, ldarh);
 2930   %}
 2931 
 2932   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2933     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2934              rscratch1, ldarw);
 2935   %}
 2936 
 2937   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2938     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2939              rscratch1, ldarw);
 2940   %}
 2941 
 2942   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2943     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2944              rscratch1, ldar);
 2945   %}
 2946 
 2947   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2948     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2949              rscratch1, ldarw);
 2950     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2951   %}
 2952 
 2953   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2954     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2955              rscratch1, ldar);
 2956     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2957   %}
 2958 
 2959   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2960     Register src_reg = as_Register($src$$reg);
 2961     // we sometimes get asked to store the stack pointer into the
 2962     // current thread -- we cannot do that directly on AArch64
 2963     if (src_reg == r31_sp) {
 2964       C2_MacroAssembler _masm(&amp;cbuf);
 2965       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2966       __ mov(rscratch2, sp);
 2967       src_reg = rscratch2;
 2968     }
 2969     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2970                  rscratch1, stlr);
 2971   %}
 2972 
 2973   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2974     {
 2975       C2_MacroAssembler _masm(&amp;cbuf);
 2976       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2977       __ fmovs(rscratch2, src_reg);
 2978     }
 2979     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2980                  rscratch1, stlrw);
 2981   %}
 2982 
 2983   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2984     {
 2985       C2_MacroAssembler _masm(&amp;cbuf);
 2986       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2987       __ fmovd(rscratch2, src_reg);
 2988     }
 2989     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2990                  rscratch1, stlr);
 2991   %}
 2992 
 2993   // synchronized read/update encodings
 2994 
 2995   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2996     C2_MacroAssembler _masm(&amp;cbuf);
 2997     Register dst_reg = as_Register($dst$$reg);
 2998     Register base = as_Register($mem$$base);
 2999     int index = $mem$$index;
 3000     int scale = $mem$$scale;
 3001     int disp = $mem$$disp;
 3002     if (index == -1) {
 3003        if (disp != 0) {
 3004         __ lea(rscratch1, Address(base, disp));
 3005         __ ldaxr(dst_reg, rscratch1);
 3006       } else {
 3007         // TODO
 3008         // should we ever get anything other than this case?
 3009         __ ldaxr(dst_reg, base);
 3010       }
 3011     } else {
 3012       Register index_reg = as_Register(index);
 3013       if (disp == 0) {
 3014         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 3015         __ ldaxr(dst_reg, rscratch1);
 3016       } else {
 3017         __ lea(rscratch1, Address(base, disp));
 3018         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3019         __ ldaxr(dst_reg, rscratch1);
 3020       }
 3021     }
 3022   %}
 3023 
 3024   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3025     C2_MacroAssembler _masm(&amp;cbuf);
 3026     Register src_reg = as_Register($src$$reg);
 3027     Register base = as_Register($mem$$base);
 3028     int index = $mem$$index;
 3029     int scale = $mem$$scale;
 3030     int disp = $mem$$disp;
 3031     if (index == -1) {
 3032        if (disp != 0) {
 3033         __ lea(rscratch2, Address(base, disp));
 3034         __ stlxr(rscratch1, src_reg, rscratch2);
 3035       } else {
 3036         // TODO
 3037         // should we ever get anything other than this case?
 3038         __ stlxr(rscratch1, src_reg, base);
 3039       }
 3040     } else {
 3041       Register index_reg = as_Register(index);
 3042       if (disp == 0) {
 3043         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3044         __ stlxr(rscratch1, src_reg, rscratch2);
 3045       } else {
 3046         __ lea(rscratch2, Address(base, disp));
 3047         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3048         __ stlxr(rscratch1, src_reg, rscratch2);
 3049       }
 3050     }
 3051     __ cmpw(rscratch1, zr);
 3052   %}
 3053 
 3054   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3055     C2_MacroAssembler _masm(&amp;cbuf);
 3056     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3057     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3058                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3059                /*weak*/ false, noreg);
 3060   %}
 3061 
 3062   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3063     C2_MacroAssembler _masm(&amp;cbuf);
 3064     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3065     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3066                Assembler::word, /*acquire*/ false, /*release*/ true,
 3067                /*weak*/ false, noreg);
 3068   %}
 3069 
 3070   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3071     C2_MacroAssembler _masm(&amp;cbuf);
 3072     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3073     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3074                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3075                /*weak*/ false, noreg);
 3076   %}
 3077 
 3078   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3079     C2_MacroAssembler _masm(&amp;cbuf);
 3080     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3081     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3082                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3083                /*weak*/ false, noreg);
 3084   %}
 3085 
 3086 
 3087   // The only difference between aarch64_enc_cmpxchg and
 3088   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3089   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3090   // lock.
 3091   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3092     C2_MacroAssembler _masm(&amp;cbuf);
 3093     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3094     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3095                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3096                /*weak*/ false, noreg);
 3097   %}
 3098 
 3099   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3100     C2_MacroAssembler _masm(&amp;cbuf);
 3101     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3102     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3103                Assembler::word, /*acquire*/ true, /*release*/ true,
 3104                /*weak*/ false, noreg);
 3105   %}
 3106 
 3107   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3108     C2_MacroAssembler _masm(&amp;cbuf);
 3109     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3110     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3111                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3112                /*weak*/ false, noreg);
 3113   %}
 3114 
 3115   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3116     C2_MacroAssembler _masm(&amp;cbuf);
 3117     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3118     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3119                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3120                /*weak*/ false, noreg);
 3121   %}
 3122 
 3123   // auxiliary used for CompareAndSwapX to set result register
 3124   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3125     C2_MacroAssembler _masm(&amp;cbuf);
 3126     Register res_reg = as_Register($res$$reg);
 3127     __ cset(res_reg, Assembler::EQ);
 3128   %}
 3129 
 3130   // prefetch encodings
 3131 
 3132   enc_class aarch64_enc_prefetchw(memory mem) %{
 3133     C2_MacroAssembler _masm(&amp;cbuf);
 3134     Register base = as_Register($mem$$base);
 3135     int index = $mem$$index;
 3136     int scale = $mem$$scale;
 3137     int disp = $mem$$disp;
 3138     if (index == -1) {
 3139       __ prfm(Address(base, disp), PSTL1KEEP);
 3140     } else {
 3141       Register index_reg = as_Register(index);
 3142       if (disp == 0) {
 3143         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3144       } else {
 3145         __ lea(rscratch1, Address(base, disp));
 3146 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3147       }
 3148     }
 3149   %}
 3150 
 3151   /// mov envcodings
 3152 
 3153   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3154     C2_MacroAssembler _masm(&amp;cbuf);
 3155     u_int32_t con = (u_int32_t)$src$$constant;
 3156     Register dst_reg = as_Register($dst$$reg);
 3157     if (con == 0) {
 3158       __ movw(dst_reg, zr);
 3159     } else {
 3160       __ movw(dst_reg, con);
 3161     }
 3162   %}
 3163 
 3164   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3165     C2_MacroAssembler _masm(&amp;cbuf);
 3166     Register dst_reg = as_Register($dst$$reg);
 3167     u_int64_t con = (u_int64_t)$src$$constant;
 3168     if (con == 0) {
 3169       __ mov(dst_reg, zr);
 3170     } else {
 3171       __ mov(dst_reg, con);
 3172     }
 3173   %}
 3174 
 3175   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3176     C2_MacroAssembler _masm(&amp;cbuf);
 3177     Register dst_reg = as_Register($dst$$reg);
 3178     address con = (address)$src$$constant;
 3179     if (con == NULL || con == (address)1) {
 3180       ShouldNotReachHere();
 3181     } else {
 3182       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3183       if (rtype == relocInfo::oop_type) {
 3184         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3185       } else if (rtype == relocInfo::metadata_type) {
 3186         __ mov_metadata(dst_reg, (Metadata*)con);
 3187       } else {
 3188         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3189         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3190           __ mov(dst_reg, con);
 3191         } else {
 3192           unsigned long offset;
 3193           __ adrp(dst_reg, con, offset);
 3194           __ add(dst_reg, dst_reg, offset);
 3195         }
 3196       }
 3197     }
 3198   %}
 3199 
 3200   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3201     C2_MacroAssembler _masm(&amp;cbuf);
 3202     Register dst_reg = as_Register($dst$$reg);
 3203     __ mov(dst_reg, zr);
 3204   %}
 3205 
 3206   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3207     C2_MacroAssembler _masm(&amp;cbuf);
 3208     Register dst_reg = as_Register($dst$$reg);
 3209     __ mov(dst_reg, (u_int64_t)1);
 3210   %}
 3211 
 3212   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3213     C2_MacroAssembler _masm(&amp;cbuf);
 3214     __ load_byte_map_base($dst$$Register);
 3215   %}
 3216 
 3217   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3218     C2_MacroAssembler _masm(&amp;cbuf);
 3219     Register dst_reg = as_Register($dst$$reg);
 3220     address con = (address)$src$$constant;
 3221     if (con == NULL) {
 3222       ShouldNotReachHere();
 3223     } else {
 3224       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3225       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3226       __ set_narrow_oop(dst_reg, (jobject)con);
 3227     }
 3228   %}
 3229 
 3230   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3231     C2_MacroAssembler _masm(&amp;cbuf);
 3232     Register dst_reg = as_Register($dst$$reg);
 3233     __ mov(dst_reg, zr);
 3234   %}
 3235 
 3236   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3237     C2_MacroAssembler _masm(&amp;cbuf);
 3238     Register dst_reg = as_Register($dst$$reg);
 3239     address con = (address)$src$$constant;
 3240     if (con == NULL) {
 3241       ShouldNotReachHere();
 3242     } else {
 3243       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3244       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3245       __ set_narrow_klass(dst_reg, (Klass *)con);
 3246     }
 3247   %}
 3248 
 3249   // arithmetic encodings
 3250 
 3251   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3252     C2_MacroAssembler _masm(&amp;cbuf);
 3253     Register dst_reg = as_Register($dst$$reg);
 3254     Register src_reg = as_Register($src1$$reg);
 3255     int32_t con = (int32_t)$src2$$constant;
 3256     // add has primary == 0, subtract has primary == 1
 3257     if ($primary) { con = -con; }
 3258     if (con &lt; 0) {
 3259       __ subw(dst_reg, src_reg, -con);
 3260     } else {
 3261       __ addw(dst_reg, src_reg, con);
 3262     }
 3263   %}
 3264 
 3265   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3266     C2_MacroAssembler _masm(&amp;cbuf);
 3267     Register dst_reg = as_Register($dst$$reg);
 3268     Register src_reg = as_Register($src1$$reg);
 3269     int32_t con = (int32_t)$src2$$constant;
 3270     // add has primary == 0, subtract has primary == 1
 3271     if ($primary) { con = -con; }
 3272     if (con &lt; 0) {
 3273       __ sub(dst_reg, src_reg, -con);
 3274     } else {
 3275       __ add(dst_reg, src_reg, con);
 3276     }
 3277   %}
 3278 
 3279   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3280     C2_MacroAssembler _masm(&amp;cbuf);
 3281    Register dst_reg = as_Register($dst$$reg);
 3282    Register src1_reg = as_Register($src1$$reg);
 3283    Register src2_reg = as_Register($src2$$reg);
 3284     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3285   %}
 3286 
 3287   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3288     C2_MacroAssembler _masm(&amp;cbuf);
 3289    Register dst_reg = as_Register($dst$$reg);
 3290    Register src1_reg = as_Register($src1$$reg);
 3291    Register src2_reg = as_Register($src2$$reg);
 3292     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3293   %}
 3294 
 3295   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3296     C2_MacroAssembler _masm(&amp;cbuf);
 3297    Register dst_reg = as_Register($dst$$reg);
 3298    Register src1_reg = as_Register($src1$$reg);
 3299    Register src2_reg = as_Register($src2$$reg);
 3300     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3301   %}
 3302 
 3303   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3304     C2_MacroAssembler _masm(&amp;cbuf);
 3305    Register dst_reg = as_Register($dst$$reg);
 3306    Register src1_reg = as_Register($src1$$reg);
 3307    Register src2_reg = as_Register($src2$$reg);
 3308     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3309   %}
 3310 
 3311   // compare instruction encodings
 3312 
 3313   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3314     C2_MacroAssembler _masm(&amp;cbuf);
 3315     Register reg1 = as_Register($src1$$reg);
 3316     Register reg2 = as_Register($src2$$reg);
 3317     __ cmpw(reg1, reg2);
 3318   %}
 3319 
 3320   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3321     C2_MacroAssembler _masm(&amp;cbuf);
 3322     Register reg = as_Register($src1$$reg);
 3323     int32_t val = $src2$$constant;
 3324     if (val &gt;= 0) {
 3325       __ subsw(zr, reg, val);
 3326     } else {
 3327       __ addsw(zr, reg, -val);
 3328     }
 3329   %}
 3330 
 3331   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3332     C2_MacroAssembler _masm(&amp;cbuf);
 3333     Register reg1 = as_Register($src1$$reg);
 3334     u_int32_t val = (u_int32_t)$src2$$constant;
 3335     __ movw(rscratch1, val);
 3336     __ cmpw(reg1, rscratch1);
 3337   %}
 3338 
 3339   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3340     C2_MacroAssembler _masm(&amp;cbuf);
 3341     Register reg1 = as_Register($src1$$reg);
 3342     Register reg2 = as_Register($src2$$reg);
 3343     __ cmp(reg1, reg2);
 3344   %}
 3345 
 3346   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3347     C2_MacroAssembler _masm(&amp;cbuf);
 3348     Register reg = as_Register($src1$$reg);
 3349     int64_t val = $src2$$constant;
 3350     if (val &gt;= 0) {
 3351       __ subs(zr, reg, val);
 3352     } else if (val != -val) {
 3353       __ adds(zr, reg, -val);
 3354     } else {
 3355     // aargh, Long.MIN_VALUE is a special case
 3356       __ orr(rscratch1, zr, (u_int64_t)val);
 3357       __ subs(zr, reg, rscratch1);
 3358     }
 3359   %}
 3360 
 3361   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3362     C2_MacroAssembler _masm(&amp;cbuf);
 3363     Register reg1 = as_Register($src1$$reg);
 3364     u_int64_t val = (u_int64_t)$src2$$constant;
 3365     __ mov(rscratch1, val);
 3366     __ cmp(reg1, rscratch1);
 3367   %}
 3368 
 3369   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3370     C2_MacroAssembler _masm(&amp;cbuf);
 3371     Register reg1 = as_Register($src1$$reg);
 3372     Register reg2 = as_Register($src2$$reg);
 3373     __ cmp(reg1, reg2);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3377     C2_MacroAssembler _masm(&amp;cbuf);
 3378     Register reg1 = as_Register($src1$$reg);
 3379     Register reg2 = as_Register($src2$$reg);
 3380     __ cmpw(reg1, reg2);
 3381   %}
 3382 
 3383   enc_class aarch64_enc_testp(iRegP src) %{
 3384     C2_MacroAssembler _masm(&amp;cbuf);
 3385     Register reg = as_Register($src$$reg);
 3386     __ cmp(reg, zr);
 3387   %}
 3388 
 3389   enc_class aarch64_enc_testn(iRegN src) %{
 3390     C2_MacroAssembler _masm(&amp;cbuf);
 3391     Register reg = as_Register($src$$reg);
 3392     __ cmpw(reg, zr);
 3393   %}
 3394 
 3395   enc_class aarch64_enc_b(label lbl) %{
 3396     C2_MacroAssembler _masm(&amp;cbuf);
 3397     Label *L = $lbl$$label;
 3398     __ b(*L);
 3399   %}
 3400 
 3401   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3402     C2_MacroAssembler _masm(&amp;cbuf);
 3403     Label *L = $lbl$$label;
 3404     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3405   %}
 3406 
 3407   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3408     C2_MacroAssembler _masm(&amp;cbuf);
 3409     Label *L = $lbl$$label;
 3410     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3411   %}
 3412 
 3413   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3414   %{
 3415      Register sub_reg = as_Register($sub$$reg);
 3416      Register super_reg = as_Register($super$$reg);
 3417      Register temp_reg = as_Register($temp$$reg);
 3418      Register result_reg = as_Register($result$$reg);
 3419 
 3420      Label miss;
 3421      C2_MacroAssembler _masm(&amp;cbuf);
 3422      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3423                                      NULL, &amp;miss,
 3424                                      /*set_cond_codes:*/ true);
 3425      if ($primary) {
 3426        __ mov(result_reg, zr);
 3427      }
 3428      __ bind(miss);
 3429   %}
 3430 
 3431   enc_class aarch64_enc_java_static_call(method meth) %{
 3432     C2_MacroAssembler _masm(&amp;cbuf);
 3433 
 3434     address addr = (address)$meth$$method;
 3435     address call;
 3436     if (!_method) {
 3437       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3438       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3439     } else {
 3440       int method_index = resolved_method_index(cbuf);
 3441       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3442                                                   : static_call_Relocation::spec(method_index);
 3443       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3444 
 3445       // Emit stub for static call
 3446       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3447       if (stub == NULL) {
 3448         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3449         return;
 3450       }
 3451     }
 3452     if (call == NULL) {
 3453       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3454       return;
 3455     }
 3456   %}
 3457 
 3458   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3459     C2_MacroAssembler _masm(&amp;cbuf);
 3460     int method_index = resolved_method_index(cbuf);
 3461     address call = __ ic_call((address)$meth$$method, method_index);
 3462     if (call == NULL) {
 3463       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3464       return;
 3465     }
 3466   %}
 3467 
 3468   enc_class aarch64_enc_call_epilog() %{
 3469     C2_MacroAssembler _masm(&amp;cbuf);
 3470     if (VerifyStackAtCalls) {
 3471       // Check that stack depth is unchanged: find majik cookie on stack
 3472       __ call_Unimplemented();
 3473     }
 3474   %}
 3475 
 3476   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3477     C2_MacroAssembler _masm(&amp;cbuf);
 3478 
 3479     // some calls to generated routines (arraycopy code) are scheduled
 3480     // by C2 as runtime calls. if so we can call them using a br (they
 3481     // will be in a reachable segment) otherwise we have to use a blr
 3482     // which loads the absolute address into a register.
 3483     address entry = (address)$meth$$method;
 3484     CodeBlob *cb = CodeCache::find_blob(entry);
 3485     if (cb) {
 3486       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3487       if (call == NULL) {
 3488         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3489         return;
 3490       }
 3491     } else {
 3492       Label retaddr;
 3493       __ adr(rscratch2, retaddr);
 3494       __ lea(rscratch1, RuntimeAddress(entry));
 3495       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3496       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3497       __ blr(rscratch1);
 3498       __ bind(retaddr);
 3499       __ add(sp, sp, 2 * wordSize);
 3500     }
 3501   %}
 3502 
 3503   enc_class aarch64_enc_rethrow() %{
 3504     C2_MacroAssembler _masm(&amp;cbuf);
 3505     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3506   %}
 3507 
 3508   enc_class aarch64_enc_ret() %{
 3509     C2_MacroAssembler _masm(&amp;cbuf);
 3510     __ ret(lr);
 3511   %}
 3512 
 3513   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3514     C2_MacroAssembler _masm(&amp;cbuf);
 3515     Register target_reg = as_Register($jump_target$$reg);
 3516     __ br(target_reg);
 3517   %}
 3518 
 3519   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3520     C2_MacroAssembler _masm(&amp;cbuf);
 3521     Register target_reg = as_Register($jump_target$$reg);
 3522     // exception oop should be in r0
 3523     // ret addr has been popped into lr
 3524     // callee expects it in r3
 3525     __ mov(r3, lr);
 3526     __ br(target_reg);
 3527   %}
 3528 
 3529   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3530     C2_MacroAssembler _masm(&amp;cbuf);
 3531     Register oop = as_Register($object$$reg);
 3532     Register box = as_Register($box$$reg);
 3533     Register disp_hdr = as_Register($tmp$$reg);
 3534     Register tmp = as_Register($tmp2$$reg);
 3535     Label cont;
 3536     Label object_has_monitor;
 3537     Label cas_failed;
 3538 
 3539     assert_different_registers(oop, box, tmp, disp_hdr);
 3540 
 3541     // Load markWord from object into displaced_header.
 3542     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3543 
 3544     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3545       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3546     }
 3547 
 3548     // Check for existing monitor
 3549     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3550 
 3551     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3552     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3553 
 3554     // Initialize the box. (Must happen before we update the object mark!)
 3555     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3556 
 3557     // Compare object markWord with an unlocked value (tmp) and if
 3558     // equal exchange the stack address of our box with object markWord.
 3559     // On failure disp_hdr contains the possibly locked markWord.
 3560     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3561                /*release*/ true, /*weak*/ false, disp_hdr);
 3562     __ br(Assembler::EQ, cont);
 3563 
 3564     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3565 
 3566     // If the compare-and-exchange succeeded, then we found an unlocked
 3567     // object, will have now locked it will continue at label cont
 3568 
 3569     __ bind(cas_failed);
 3570     // We did not see an unlocked object so try the fast recursive case.
 3571 
 3572     // Check if the owner is self by comparing the value in the
 3573     // markWord of object (disp_hdr) with the stack pointer.
 3574     __ mov(rscratch1, sp);
 3575     __ sub(disp_hdr, disp_hdr, rscratch1);
 3576     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3577     // If condition is true we are cont and hence we can store 0 as the
 3578     // displaced header in the box, which indicates that it is a recursive lock.
 3579     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3580     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3581 
 3582     __ b(cont);
 3583 
 3584     // Handle existing monitor.
 3585     __ bind(object_has_monitor);
 3586 
 3587     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3588     // otherwise m-&gt;owner may contain a thread or a stack address.
 3589     //
 3590     // Try to CAS m-&gt;owner from NULL to current thread.
 3591     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3592     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3593                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3594 
 3595     // Store a non-null value into the box to avoid looking like a re-entrant
 3596     // lock. The fast-path monitor unlock code checks for
 3597     // markWord::monitor_value so use markWord::unused_mark which has the
 3598     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3599     __ mov(tmp, (address)markWord::unused_mark().value());
 3600     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3601 
 3602     __ bind(cont);
 3603     // flag == EQ indicates success
 3604     // flag == NE indicates failure
 3605   %}
 3606 
 3607   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3608     C2_MacroAssembler _masm(&amp;cbuf);
 3609     Register oop = as_Register($object$$reg);
 3610     Register box = as_Register($box$$reg);
 3611     Register disp_hdr = as_Register($tmp$$reg);
 3612     Register tmp = as_Register($tmp2$$reg);
 3613     Label cont;
 3614     Label object_has_monitor;
 3615 
 3616     assert_different_registers(oop, box, tmp, disp_hdr);
 3617 
 3618     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3619       __ biased_locking_exit(oop, tmp, cont);
 3620     }
 3621 
 3622     // Find the lock address and load the displaced header from the stack.
 3623     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3624 
 3625     // If the displaced header is 0, we have a recursive unlock.
 3626     __ cmp(disp_hdr, zr);
 3627     __ br(Assembler::EQ, cont);
 3628 
 3629     // Handle existing monitor.
 3630     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3631     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3632 
 3633     // Check if it is still a light weight lock, this is is true if we
 3634     // see the stack address of the basicLock in the markWord of the
 3635     // object.
 3636 
 3637     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3638                /*release*/ true, /*weak*/ false, tmp);
 3639     __ b(cont);
 3640 
 3641     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3642 
 3643     // Handle existing monitor.
 3644     __ bind(object_has_monitor);
 3645     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3646     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3647     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3648     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3649     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3650     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3651     __ cmp(rscratch1, zr); // Sets flags for result
 3652     __ br(Assembler::NE, cont);
 3653 
 3654     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3655     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3656     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3657     __ cmp(rscratch1, zr); // Sets flags for result
 3658     __ cbnz(rscratch1, cont);
 3659     // need a release store here
 3660     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3661     __ stlr(zr, tmp); // set unowned
 3662 
 3663     __ bind(cont);
 3664     // flag == EQ indicates success
 3665     // flag == NE indicates failure
 3666   %}
 3667 
 3668 %}
 3669 
 3670 //----------FRAME--------------------------------------------------------------
 3671 // Definition of frame structure and management information.
 3672 //
 3673 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3674 //                             |   (to get allocators register number
 3675 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3676 //  r   CALLER     |        |
 3677 //  o     |        +--------+      pad to even-align allocators stack-slot
 3678 //  w     V        |  pad0  |        numbers; owned by CALLER
 3679 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3680 //  h     ^        |   in   |  5
 3681 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3682 //  |     |        |        |  3
 3683 //  |     |        +--------+
 3684 //  V     |        | old out|      Empty on Intel, window on Sparc
 3685 //        |    old |preserve|      Must be even aligned.
 3686 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3687 //        |        |   in   |  3   area for Intel ret address
 3688 //     Owned by    |preserve|      Empty on Sparc.
 3689 //       SELF      +--------+
 3690 //        |        |  pad2  |  2   pad to align old SP
 3691 //        |        +--------+  1
 3692 //        |        | locks  |  0
 3693 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3694 //        |        |  pad1  | 11   pad to align new SP
 3695 //        |        +--------+
 3696 //        |        |        | 10
 3697 //        |        | spills |  9   spills
 3698 //        V        |        |  8   (pad0 slot for callee)
 3699 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3700 //        ^        |  out   |  7
 3701 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3702 //     Owned by    +--------+
 3703 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3704 //        |    new |preserve|      Must be even-aligned.
 3705 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3706 //        |        |        |
 3707 //
 3708 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3709 //         known from SELF&#39;s arguments and the Java calling convention.
 3710 //         Region 6-7 is determined per call site.
 3711 // Note 2: If the calling convention leaves holes in the incoming argument
 3712 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3713 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3714 //         incoming area, as the Java calling convention is completely under
 3715 //         the control of the AD file.  Doubles can be sorted and packed to
 3716 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3717 //         varargs C calling conventions.
 3718 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3719 //         even aligned with pad0 as needed.
 3720 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3721 //           (the latter is true on Intel but is it false on AArch64?)
 3722 //         region 6-11 is even aligned; it may be padded out more so that
 3723 //         the region from SP to FP meets the minimum stack alignment.
 3724 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3725 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3726 //         SP meets the minimum alignment.
 3727 
 3728 frame %{
 3729   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3730   stack_direction(TOWARDS_LOW);
 3731 
 3732   // These three registers define part of the calling convention
 3733   // between compiled code and the interpreter.
 3734 
 3735   // Inline Cache Register or methodOop for I2C.
 3736   inline_cache_reg(R12);
 3737 
 3738   // Method Oop Register when calling interpreter.
 3739   interpreter_method_oop_reg(R12);
 3740 
 3741   // Number of stack slots consumed by locking an object
 3742   sync_stack_slots(2);
 3743 
 3744   // Compiled code&#39;s Frame Pointer
 3745   frame_pointer(R31);
 3746 
 3747   // Interpreter stores its frame pointer in a register which is
 3748   // stored to the stack by I2CAdaptors.
 3749   // I2CAdaptors convert from interpreted java to compiled java.
 3750   interpreter_frame_pointer(R29);
 3751 
 3752   // Stack alignment requirement
 3753   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3754 
 3755   // Number of stack slots between incoming argument block and the start of
 3756   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3757   // EPILOG must remove this many slots. aarch64 needs two slots for
 3758   // return address and fp.
 3759   // TODO think this is correct but check
 3760   in_preserve_stack_slots(4);
 3761 
 3762   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3763   // for calls to C.  Supports the var-args backing area for register parms.
 3764   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3765 
 3766   // The after-PROLOG location of the return address.  Location of
 3767   // return address specifies a type (REG or STACK) and a number
 3768   // representing the register number (i.e. - use a register name) or
 3769   // stack slot.
 3770   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3771   // Otherwise, it is above the locks and verification slot and alignment word
 3772   // TODO this may well be correct but need to check why that - 2 is there
 3773   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3774   // which folds in the space used for monitors
 3775   return_addr(STACK - 2 +
 3776               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3777                         Compile::current()-&gt;fixed_slots()),
 3778                        stack_alignment_in_slots()));
 3779 
 3780   // Body of function which returns an integer array locating
 3781   // arguments either in registers or in stack slots.  Passed an array
 3782   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3783   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3784   // arguments for a CALLEE.  Incoming stack arguments are
 3785   // automatically biased by the preserve_stack_slots field above.
 3786 
 3787   calling_convention
 3788   %{
 3789     // No difference between ingoing/outgoing just pass false
 3790     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3791   %}
 3792 
 3793   c_calling_convention
 3794   %{
 3795     // This is obviously always outgoing
 3796     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3797   %}
 3798 
 3799   // Location of compiled Java return values.  Same as C for now.
 3800   return_value
 3801   %{
 3802     // TODO do we allow ideal_reg == Op_RegN???
 3803     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3804            &quot;only return normal values&quot;);
 3805 
 3806     static const int lo[Op_RegL + 1] = { // enum name
 3807       0,                                 // Op_Node
 3808       0,                                 // Op_Set
 3809       R0_num,                            // Op_RegN
 3810       R0_num,                            // Op_RegI
 3811       R0_num,                            // Op_RegP
 3812       V0_num,                            // Op_RegF
 3813       V0_num,                            // Op_RegD
 3814       R0_num                             // Op_RegL
 3815     };
 3816 
 3817     static const int hi[Op_RegL + 1] = { // enum name
 3818       0,                                 // Op_Node
 3819       0,                                 // Op_Set
 3820       OptoReg::Bad,                      // Op_RegN
 3821       OptoReg::Bad,                      // Op_RegI
 3822       R0_H_num,                          // Op_RegP
 3823       OptoReg::Bad,                      // Op_RegF
 3824       V0_H_num,                          // Op_RegD
 3825       R0_H_num                           // Op_RegL
 3826     };
 3827 
 3828     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3829   %}
 3830 %}
 3831 
 3832 //----------ATTRIBUTES---------------------------------------------------------
 3833 //----------Operand Attributes-------------------------------------------------
 3834 op_attrib op_cost(1);        // Required cost attribute
 3835 
 3836 //----------Instruction Attributes---------------------------------------------
 3837 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3838 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3839 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3840                                 // a non-matching short branch variant
 3841                                 // of some long branch?
 3842 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3843                                 // be a power of 2) specifies the
 3844                                 // alignment that some part of the
 3845                                 // instruction (not necessarily the
 3846                                 // start) requires.  If &gt; 1, a
 3847                                 // compute_padding() function must be
 3848                                 // provided for the instruction
 3849 
 3850 //----------OPERANDS-----------------------------------------------------------
 3851 // Operand definitions must precede instruction definitions for correct parsing
 3852 // in the ADLC because operands constitute user defined types which are used in
 3853 // instruction definitions.
 3854 
 3855 //----------Simple Operands----------------------------------------------------
 3856 
 3857 // Integer operands 32 bit
 3858 // 32 bit immediate
 3859 operand immI()
 3860 %{
 3861   match(ConI);
 3862 
 3863   op_cost(0);
 3864   format %{ %}
 3865   interface(CONST_INTER);
 3866 %}
 3867 
 3868 // 32 bit zero
 3869 operand immI0()
 3870 %{
 3871   predicate(n-&gt;get_int() == 0);
 3872   match(ConI);
 3873 
 3874   op_cost(0);
 3875   format %{ %}
 3876   interface(CONST_INTER);
 3877 %}
 3878 
 3879 // 32 bit unit increment
 3880 operand immI_1()
 3881 %{
 3882   predicate(n-&gt;get_int() == 1);
 3883   match(ConI);
 3884 
 3885   op_cost(0);
 3886   format %{ %}
 3887   interface(CONST_INTER);
 3888 %}
 3889 
 3890 // 32 bit unit decrement
 3891 operand immI_M1()
 3892 %{
 3893   predicate(n-&gt;get_int() == -1);
 3894   match(ConI);
 3895 
 3896   op_cost(0);
 3897   format %{ %}
 3898   interface(CONST_INTER);
 3899 %}
 3900 
 3901 // Shift values for add/sub extension shift
 3902 operand immIExt()
 3903 %{
 3904   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3905   match(ConI);
 3906 
 3907   op_cost(0);
 3908   format %{ %}
 3909   interface(CONST_INTER);
 3910 %}
 3911 
 3912 operand immI_le_4()
 3913 %{
 3914   predicate(n-&gt;get_int() &lt;= 4);
 3915   match(ConI);
 3916 
 3917   op_cost(0);
 3918   format %{ %}
 3919   interface(CONST_INTER);
 3920 %}
 3921 
 3922 operand immI_31()
 3923 %{
 3924   predicate(n-&gt;get_int() == 31);
 3925   match(ConI);
 3926 
 3927   op_cost(0);
 3928   format %{ %}
 3929   interface(CONST_INTER);
 3930 %}
 3931 
 3932 operand immI_8()
 3933 %{
 3934   predicate(n-&gt;get_int() == 8);
 3935   match(ConI);
 3936 
 3937   op_cost(0);
 3938   format %{ %}
 3939   interface(CONST_INTER);
 3940 %}
 3941 
 3942 operand immI_16()
 3943 %{
 3944   predicate(n-&gt;get_int() == 16);
 3945   match(ConI);
 3946 
 3947   op_cost(0);
 3948   format %{ %}
 3949   interface(CONST_INTER);
 3950 %}
 3951 
 3952 operand immI_24()
 3953 %{
 3954   predicate(n-&gt;get_int() == 24);
 3955   match(ConI);
 3956 
 3957   op_cost(0);
 3958   format %{ %}
 3959   interface(CONST_INTER);
 3960 %}
 3961 
 3962 operand immI_32()
 3963 %{
 3964   predicate(n-&gt;get_int() == 32);
 3965   match(ConI);
 3966 
 3967   op_cost(0);
 3968   format %{ %}
 3969   interface(CONST_INTER);
 3970 %}
 3971 
 3972 operand immI_48()
 3973 %{
 3974   predicate(n-&gt;get_int() == 48);
 3975   match(ConI);
 3976 
 3977   op_cost(0);
 3978   format %{ %}
 3979   interface(CONST_INTER);
 3980 %}
 3981 
 3982 operand immI_56()
 3983 %{
 3984   predicate(n-&gt;get_int() == 56);
 3985   match(ConI);
 3986 
 3987   op_cost(0);
 3988   format %{ %}
 3989   interface(CONST_INTER);
 3990 %}
 3991 
 3992 operand immI_63()
 3993 %{
 3994   predicate(n-&gt;get_int() == 63);
 3995   match(ConI);
 3996 
 3997   op_cost(0);
 3998   format %{ %}
 3999   interface(CONST_INTER);
 4000 %}
 4001 
 4002 operand immI_64()
 4003 %{
 4004   predicate(n-&gt;get_int() == 64);
 4005   match(ConI);
 4006 
 4007   op_cost(0);
 4008   format %{ %}
 4009   interface(CONST_INTER);
 4010 %}
 4011 
 4012 operand immI_255()
 4013 %{
 4014   predicate(n-&gt;get_int() == 255);
 4015   match(ConI);
 4016 
 4017   op_cost(0);
 4018   format %{ %}
 4019   interface(CONST_INTER);
 4020 %}
 4021 
 4022 operand immI_65535()
 4023 %{
 4024   predicate(n-&gt;get_int() == 65535);
 4025   match(ConI);
 4026 
 4027   op_cost(0);
 4028   format %{ %}
 4029   interface(CONST_INTER);
 4030 %}
 4031 
 4032 operand immL_255()
 4033 %{
 4034   predicate(n-&gt;get_long() == 255L);
 4035   match(ConL);
 4036 
 4037   op_cost(0);
 4038   format %{ %}
 4039   interface(CONST_INTER);
 4040 %}
 4041 
 4042 operand immL_65535()
 4043 %{
 4044   predicate(n-&gt;get_long() == 65535L);
 4045   match(ConL);
 4046 
 4047   op_cost(0);
 4048   format %{ %}
 4049   interface(CONST_INTER);
 4050 %}
 4051 
 4052 operand immL_4294967295()
 4053 %{
 4054   predicate(n-&gt;get_long() == 4294967295L);
 4055   match(ConL);
 4056 
 4057   op_cost(0);
 4058   format %{ %}
 4059   interface(CONST_INTER);
 4060 %}
 4061 
 4062 operand immL_bitmask()
 4063 %{
 4064   predicate((n-&gt;get_long() != 0)
 4065             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4066             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4067   match(ConL);
 4068 
 4069   op_cost(0);
 4070   format %{ %}
 4071   interface(CONST_INTER);
 4072 %}
 4073 
 4074 operand immI_bitmask()
 4075 %{
 4076   predicate((n-&gt;get_int() != 0)
 4077             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4078             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4079   match(ConI);
 4080 
 4081   op_cost(0);
 4082   format %{ %}
 4083   interface(CONST_INTER);
 4084 %}
 4085 
 4086 // Scale values for scaled offset addressing modes (up to long but not quad)
 4087 operand immIScale()
 4088 %{
 4089   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4090   match(ConI);
 4091 
 4092   op_cost(0);
 4093   format %{ %}
 4094   interface(CONST_INTER);
 4095 %}
 4096 
 4097 // 26 bit signed offset -- for pc-relative branches
 4098 operand immI26()
 4099 %{
 4100   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4101   match(ConI);
 4102 
 4103   op_cost(0);
 4104   format %{ %}
 4105   interface(CONST_INTER);
 4106 %}
 4107 
 4108 // 19 bit signed offset -- for pc-relative loads
 4109 operand immI19()
 4110 %{
 4111   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4112   match(ConI);
 4113 
 4114   op_cost(0);
 4115   format %{ %}
 4116   interface(CONST_INTER);
 4117 %}
 4118 
 4119 // 12 bit unsigned offset -- for base plus immediate loads
 4120 operand immIU12()
 4121 %{
 4122   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4123   match(ConI);
 4124 
 4125   op_cost(0);
 4126   format %{ %}
 4127   interface(CONST_INTER);
 4128 %}
 4129 
 4130 operand immLU12()
 4131 %{
 4132   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4133   match(ConL);
 4134 
 4135   op_cost(0);
 4136   format %{ %}
 4137   interface(CONST_INTER);
 4138 %}
 4139 
 4140 // Offset for scaled or unscaled immediate loads and stores
 4141 operand immIOffset()
 4142 %{
 4143   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4144   match(ConI);
 4145 
 4146   op_cost(0);
 4147   format %{ %}
 4148   interface(CONST_INTER);
 4149 %}
 4150 
 4151 operand immIOffset1()
 4152 %{
 4153   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4154   match(ConI);
 4155 
 4156   op_cost(0);
 4157   format %{ %}
 4158   interface(CONST_INTER);
 4159 %}
 4160 
 4161 operand immIOffset2()
 4162 %{
 4163   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4164   match(ConI);
 4165 
 4166   op_cost(0);
 4167   format %{ %}
 4168   interface(CONST_INTER);
 4169 %}
 4170 
 4171 operand immIOffset4()
 4172 %{
 4173   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4174   match(ConI);
 4175 
 4176   op_cost(0);
 4177   format %{ %}
 4178   interface(CONST_INTER);
 4179 %}
 4180 
 4181 operand immIOffset8()
 4182 %{
 4183   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4184   match(ConI);
 4185 
 4186   op_cost(0);
 4187   format %{ %}
 4188   interface(CONST_INTER);
 4189 %}
 4190 
 4191 operand immIOffset16()
 4192 %{
 4193   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4194   match(ConI);
 4195 
 4196   op_cost(0);
 4197   format %{ %}
 4198   interface(CONST_INTER);
 4199 %}
 4200 
 4201 operand immLoffset()
 4202 %{
 4203   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4204   match(ConL);
 4205 
 4206   op_cost(0);
 4207   format %{ %}
 4208   interface(CONST_INTER);
 4209 %}
 4210 
 4211 operand immLoffset1()
 4212 %{
 4213   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4214   match(ConL);
 4215 
 4216   op_cost(0);
 4217   format %{ %}
 4218   interface(CONST_INTER);
 4219 %}
 4220 
 4221 operand immLoffset2()
 4222 %{
 4223   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4224   match(ConL);
 4225 
 4226   op_cost(0);
 4227   format %{ %}
 4228   interface(CONST_INTER);
 4229 %}
 4230 
 4231 operand immLoffset4()
 4232 %{
 4233   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4234   match(ConL);
 4235 
 4236   op_cost(0);
 4237   format %{ %}
 4238   interface(CONST_INTER);
 4239 %}
 4240 
 4241 operand immLoffset8()
 4242 %{
 4243   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4244   match(ConL);
 4245 
 4246   op_cost(0);
 4247   format %{ %}
 4248   interface(CONST_INTER);
 4249 %}
 4250 
 4251 operand immLoffset16()
 4252 %{
 4253   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4254   match(ConL);
 4255 
 4256   op_cost(0);
 4257   format %{ %}
 4258   interface(CONST_INTER);
 4259 %}
 4260 
 4261 // 32 bit integer valid for add sub immediate
 4262 operand immIAddSub()
 4263 %{
 4264   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4265   match(ConI);
 4266   op_cost(0);
 4267   format %{ %}
 4268   interface(CONST_INTER);
 4269 %}
 4270 
 4271 // 32 bit unsigned integer valid for logical immediate
 4272 // TODO -- check this is right when e.g the mask is 0x80000000
 4273 operand immILog()
 4274 %{
 4275   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4276   match(ConI);
 4277 
 4278   op_cost(0);
 4279   format %{ %}
 4280   interface(CONST_INTER);
 4281 %}
 4282 
 4283 // Integer operands 64 bit
 4284 // 64 bit immediate
 4285 operand immL()
 4286 %{
 4287   match(ConL);
 4288 
 4289   op_cost(0);
 4290   format %{ %}
 4291   interface(CONST_INTER);
 4292 %}
 4293 
 4294 // 64 bit zero
 4295 operand immL0()
 4296 %{
 4297   predicate(n-&gt;get_long() == 0);
 4298   match(ConL);
 4299 
 4300   op_cost(0);
 4301   format %{ %}
 4302   interface(CONST_INTER);
 4303 %}
 4304 
 4305 // 64 bit unit increment
 4306 operand immL_1()
 4307 %{
 4308   predicate(n-&gt;get_long() == 1);
 4309   match(ConL);
 4310 
 4311   op_cost(0);
 4312   format %{ %}
 4313   interface(CONST_INTER);
 4314 %}
 4315 
 4316 // 64 bit unit decrement
 4317 operand immL_M1()
 4318 %{
 4319   predicate(n-&gt;get_long() == -1);
 4320   match(ConL);
 4321 
 4322   op_cost(0);
 4323   format %{ %}
 4324   interface(CONST_INTER);
 4325 %}
 4326 
 4327 // 32 bit offset of pc in thread anchor
 4328 
 4329 operand immL_pc_off()
 4330 %{
 4331   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4332                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4333   match(ConL);
 4334 
 4335   op_cost(0);
 4336   format %{ %}
 4337   interface(CONST_INTER);
 4338 %}
 4339 
 4340 // 64 bit integer valid for add sub immediate
 4341 operand immLAddSub()
 4342 %{
 4343   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4344   match(ConL);
 4345   op_cost(0);
 4346   format %{ %}
 4347   interface(CONST_INTER);
 4348 %}
 4349 
 4350 // 64 bit integer valid for logical immediate
 4351 operand immLLog()
 4352 %{
 4353   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4354   match(ConL);
 4355   op_cost(0);
 4356   format %{ %}
 4357   interface(CONST_INTER);
 4358 %}
 4359 
 4360 // Long Immediate: low 32-bit mask
 4361 operand immL_32bits()
 4362 %{
 4363   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4364   match(ConL);
 4365   op_cost(0);
 4366   format %{ %}
 4367   interface(CONST_INTER);
 4368 %}
 4369 
 4370 // Pointer operands
 4371 // Pointer Immediate
 4372 operand immP()
 4373 %{
 4374   match(ConP);
 4375 
 4376   op_cost(0);
 4377   format %{ %}
 4378   interface(CONST_INTER);
 4379 %}
 4380 
 4381 // NULL Pointer Immediate
 4382 operand immP0()
 4383 %{
 4384   predicate(n-&gt;get_ptr() == 0);
 4385   match(ConP);
 4386 
 4387   op_cost(0);
 4388   format %{ %}
 4389   interface(CONST_INTER);
 4390 %}
 4391 
 4392 // Pointer Immediate One
 4393 // this is used in object initialization (initial object header)
 4394 operand immP_1()
 4395 %{
 4396   predicate(n-&gt;get_ptr() == 1);
 4397   match(ConP);
 4398 
 4399   op_cost(0);
 4400   format %{ %}
 4401   interface(CONST_INTER);
 4402 %}
 4403 
 4404 // Card Table Byte Map Base
 4405 operand immByteMapBase()
 4406 %{
 4407   // Get base of card map
 4408   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4409             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4410   match(ConP);
 4411 
 4412   op_cost(0);
 4413   format %{ %}
 4414   interface(CONST_INTER);
 4415 %}
 4416 
 4417 // Pointer Immediate Minus One
 4418 // this is used when we want to write the current PC to the thread anchor
 4419 operand immP_M1()
 4420 %{
 4421   predicate(n-&gt;get_ptr() == -1);
 4422   match(ConP);
 4423 
 4424   op_cost(0);
 4425   format %{ %}
 4426   interface(CONST_INTER);
 4427 %}
 4428 
 4429 // Pointer Immediate Minus Two
 4430 // this is used when we want to write the current PC to the thread anchor
 4431 operand immP_M2()
 4432 %{
 4433   predicate(n-&gt;get_ptr() == -2);
 4434   match(ConP);
 4435 
 4436   op_cost(0);
 4437   format %{ %}
 4438   interface(CONST_INTER);
 4439 %}
 4440 
 4441 // Float and Double operands
 4442 // Double Immediate
 4443 operand immD()
 4444 %{
 4445   match(ConD);
 4446   op_cost(0);
 4447   format %{ %}
 4448   interface(CONST_INTER);
 4449 %}
 4450 
 4451 // Double Immediate: +0.0d
 4452 operand immD0()
 4453 %{
 4454   predicate(jlong_cast(n-&gt;getd()) == 0);
 4455   match(ConD);
 4456 
 4457   op_cost(0);
 4458   format %{ %}
 4459   interface(CONST_INTER);
 4460 %}
 4461 
 4462 // constant &#39;double +0.0&#39;.
 4463 operand immDPacked()
 4464 %{
 4465   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4466   match(ConD);
 4467   op_cost(0);
 4468   format %{ %}
 4469   interface(CONST_INTER);
 4470 %}
 4471 
 4472 // Float Immediate
 4473 operand immF()
 4474 %{
 4475   match(ConF);
 4476   op_cost(0);
 4477   format %{ %}
 4478   interface(CONST_INTER);
 4479 %}
 4480 
 4481 // Float Immediate: +0.0f.
 4482 operand immF0()
 4483 %{
 4484   predicate(jint_cast(n-&gt;getf()) == 0);
 4485   match(ConF);
 4486 
 4487   op_cost(0);
 4488   format %{ %}
 4489   interface(CONST_INTER);
 4490 %}
 4491 
 4492 //
 4493 operand immFPacked()
 4494 %{
 4495   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4496   match(ConF);
 4497   op_cost(0);
 4498   format %{ %}
 4499   interface(CONST_INTER);
 4500 %}
 4501 
 4502 // Narrow pointer operands
 4503 // Narrow Pointer Immediate
 4504 operand immN()
 4505 %{
 4506   match(ConN);
 4507 
 4508   op_cost(0);
 4509   format %{ %}
 4510   interface(CONST_INTER);
 4511 %}
 4512 
 4513 // Narrow NULL Pointer Immediate
 4514 operand immN0()
 4515 %{
 4516   predicate(n-&gt;get_narrowcon() == 0);
 4517   match(ConN);
 4518 
 4519   op_cost(0);
 4520   format %{ %}
 4521   interface(CONST_INTER);
 4522 %}
 4523 
 4524 operand immNKlass()
 4525 %{
 4526   match(ConNKlass);
 4527 
 4528   op_cost(0);
 4529   format %{ %}
 4530   interface(CONST_INTER);
 4531 %}
 4532 
 4533 // Integer 32 bit Register Operands
 4534 // Integer 32 bitRegister (excludes SP)
 4535 operand iRegI()
 4536 %{
 4537   constraint(ALLOC_IN_RC(any_reg32));
 4538   match(RegI);
 4539   match(iRegINoSp);
 4540   op_cost(0);
 4541   format %{ %}
 4542   interface(REG_INTER);
 4543 %}
 4544 
 4545 // Integer 32 bit Register not Special
 4546 operand iRegINoSp()
 4547 %{
 4548   constraint(ALLOC_IN_RC(no_special_reg32));
 4549   match(RegI);
 4550   op_cost(0);
 4551   format %{ %}
 4552   interface(REG_INTER);
 4553 %}
 4554 
 4555 // Integer 64 bit Register Operands
 4556 // Integer 64 bit Register (includes SP)
 4557 operand iRegL()
 4558 %{
 4559   constraint(ALLOC_IN_RC(any_reg));
 4560   match(RegL);
 4561   match(iRegLNoSp);
 4562   op_cost(0);
 4563   format %{ %}
 4564   interface(REG_INTER);
 4565 %}
 4566 
 4567 // Integer 64 bit Register not Special
 4568 operand iRegLNoSp()
 4569 %{
 4570   constraint(ALLOC_IN_RC(no_special_reg));
 4571   match(RegL);
 4572   match(iRegL_R0);
 4573   format %{ %}
 4574   interface(REG_INTER);
 4575 %}
 4576 
 4577 // Pointer Register Operands
 4578 // Pointer Register
 4579 operand iRegP()
 4580 %{
 4581   constraint(ALLOC_IN_RC(ptr_reg));
 4582   match(RegP);
 4583   match(iRegPNoSp);
 4584   match(iRegP_R0);
 4585   //match(iRegP_R2);
 4586   //match(iRegP_R4);
 4587   //match(iRegP_R5);
 4588   match(thread_RegP);
 4589   op_cost(0);
 4590   format %{ %}
 4591   interface(REG_INTER);
 4592 %}
 4593 
 4594 // Pointer 64 bit Register not Special
 4595 operand iRegPNoSp()
 4596 %{
 4597   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4598   match(RegP);
 4599   // match(iRegP);
 4600   // match(iRegP_R0);
 4601   // match(iRegP_R2);
 4602   // match(iRegP_R4);
 4603   // match(iRegP_R5);
 4604   // match(thread_RegP);
 4605   op_cost(0);
 4606   format %{ %}
 4607   interface(REG_INTER);
 4608 %}
 4609 
 4610 // Pointer 64 bit Register R0 only
 4611 operand iRegP_R0()
 4612 %{
 4613   constraint(ALLOC_IN_RC(r0_reg));
 4614   match(RegP);
 4615   // match(iRegP);
 4616   match(iRegPNoSp);
 4617   op_cost(0);
 4618   format %{ %}
 4619   interface(REG_INTER);
 4620 %}
 4621 
 4622 // Pointer 64 bit Register R1 only
 4623 operand iRegP_R1()
 4624 %{
 4625   constraint(ALLOC_IN_RC(r1_reg));
 4626   match(RegP);
 4627   // match(iRegP);
 4628   match(iRegPNoSp);
 4629   op_cost(0);
 4630   format %{ %}
 4631   interface(REG_INTER);
 4632 %}
 4633 
 4634 // Pointer 64 bit Register R2 only
 4635 operand iRegP_R2()
 4636 %{
 4637   constraint(ALLOC_IN_RC(r2_reg));
 4638   match(RegP);
 4639   // match(iRegP);
 4640   match(iRegPNoSp);
 4641   op_cost(0);
 4642   format %{ %}
 4643   interface(REG_INTER);
 4644 %}
 4645 
 4646 // Pointer 64 bit Register R3 only
 4647 operand iRegP_R3()
 4648 %{
 4649   constraint(ALLOC_IN_RC(r3_reg));
 4650   match(RegP);
 4651   // match(iRegP);
 4652   match(iRegPNoSp);
 4653   op_cost(0);
 4654   format %{ %}
 4655   interface(REG_INTER);
 4656 %}
 4657 
 4658 // Pointer 64 bit Register R4 only
 4659 operand iRegP_R4()
 4660 %{
 4661   constraint(ALLOC_IN_RC(r4_reg));
 4662   match(RegP);
 4663   // match(iRegP);
 4664   match(iRegPNoSp);
 4665   op_cost(0);
 4666   format %{ %}
 4667   interface(REG_INTER);
 4668 %}
 4669 
 4670 // Pointer 64 bit Register R5 only
 4671 operand iRegP_R5()
 4672 %{
 4673   constraint(ALLOC_IN_RC(r5_reg));
 4674   match(RegP);
 4675   // match(iRegP);
 4676   match(iRegPNoSp);
 4677   op_cost(0);
 4678   format %{ %}
 4679   interface(REG_INTER);
 4680 %}
 4681 
 4682 // Pointer 64 bit Register R10 only
 4683 operand iRegP_R10()
 4684 %{
 4685   constraint(ALLOC_IN_RC(r10_reg));
 4686   match(RegP);
 4687   // match(iRegP);
 4688   match(iRegPNoSp);
 4689   op_cost(0);
 4690   format %{ %}
 4691   interface(REG_INTER);
 4692 %}
 4693 
 4694 // Long 64 bit Register R0 only
 4695 operand iRegL_R0()
 4696 %{
 4697   constraint(ALLOC_IN_RC(r0_reg));
 4698   match(RegL);
 4699   match(iRegLNoSp);
 4700   op_cost(0);
 4701   format %{ %}
 4702   interface(REG_INTER);
 4703 %}
 4704 
 4705 // Long 64 bit Register R2 only
 4706 operand iRegL_R2()
 4707 %{
 4708   constraint(ALLOC_IN_RC(r2_reg));
 4709   match(RegL);
 4710   match(iRegLNoSp);
 4711   op_cost(0);
 4712   format %{ %}
 4713   interface(REG_INTER);
 4714 %}
 4715 
 4716 // Long 64 bit Register R3 only
 4717 operand iRegL_R3()
 4718 %{
 4719   constraint(ALLOC_IN_RC(r3_reg));
 4720   match(RegL);
 4721   match(iRegLNoSp);
 4722   op_cost(0);
 4723   format %{ %}
 4724   interface(REG_INTER);
 4725 %}
 4726 
 4727 // Long 64 bit Register R11 only
 4728 operand iRegL_R11()
 4729 %{
 4730   constraint(ALLOC_IN_RC(r11_reg));
 4731   match(RegL);
 4732   match(iRegLNoSp);
 4733   op_cost(0);
 4734   format %{ %}
 4735   interface(REG_INTER);
 4736 %}
 4737 
 4738 // Pointer 64 bit Register FP only
 4739 operand iRegP_FP()
 4740 %{
 4741   constraint(ALLOC_IN_RC(fp_reg));
 4742   match(RegP);
 4743   // match(iRegP);
 4744   op_cost(0);
 4745   format %{ %}
 4746   interface(REG_INTER);
 4747 %}
 4748 
 4749 // Register R0 only
 4750 operand iRegI_R0()
 4751 %{
 4752   constraint(ALLOC_IN_RC(int_r0_reg));
 4753   match(RegI);
 4754   match(iRegINoSp);
 4755   op_cost(0);
 4756   format %{ %}
 4757   interface(REG_INTER);
 4758 %}
 4759 
 4760 // Register R2 only
 4761 operand iRegI_R2()
 4762 %{
 4763   constraint(ALLOC_IN_RC(int_r2_reg));
 4764   match(RegI);
 4765   match(iRegINoSp);
 4766   op_cost(0);
 4767   format %{ %}
 4768   interface(REG_INTER);
 4769 %}
 4770 
 4771 // Register R3 only
 4772 operand iRegI_R3()
 4773 %{
 4774   constraint(ALLOC_IN_RC(int_r3_reg));
 4775   match(RegI);
 4776   match(iRegINoSp);
 4777   op_cost(0);
 4778   format %{ %}
 4779   interface(REG_INTER);
 4780 %}
 4781 
 4782 
 4783 // Register R4 only
 4784 operand iRegI_R4()
 4785 %{
 4786   constraint(ALLOC_IN_RC(int_r4_reg));
 4787   match(RegI);
 4788   match(iRegINoSp);
 4789   op_cost(0);
 4790   format %{ %}
 4791   interface(REG_INTER);
 4792 %}
 4793 
 4794 
 4795 // Pointer Register Operands
 4796 // Narrow Pointer Register
 4797 operand iRegN()
 4798 %{
 4799   constraint(ALLOC_IN_RC(any_reg32));
 4800   match(RegN);
 4801   match(iRegNNoSp);
 4802   op_cost(0);
 4803   format %{ %}
 4804   interface(REG_INTER);
 4805 %}
 4806 
 4807 operand iRegN_R0()
 4808 %{
 4809   constraint(ALLOC_IN_RC(r0_reg));
 4810   match(iRegN);
 4811   op_cost(0);
 4812   format %{ %}
 4813   interface(REG_INTER);
 4814 %}
 4815 
 4816 operand iRegN_R2()
 4817 %{
 4818   constraint(ALLOC_IN_RC(r2_reg));
 4819   match(iRegN);
 4820   op_cost(0);
 4821   format %{ %}
 4822   interface(REG_INTER);
 4823 %}
 4824 
 4825 operand iRegN_R3()
 4826 %{
 4827   constraint(ALLOC_IN_RC(r3_reg));
 4828   match(iRegN);
 4829   op_cost(0);
 4830   format %{ %}
 4831   interface(REG_INTER);
 4832 %}
 4833 
 4834 // Integer 64 bit Register not Special
 4835 operand iRegNNoSp()
 4836 %{
 4837   constraint(ALLOC_IN_RC(no_special_reg32));
 4838   match(RegN);
 4839   op_cost(0);
 4840   format %{ %}
 4841   interface(REG_INTER);
 4842 %}
 4843 
 4844 // heap base register -- used for encoding immN0
 4845 
 4846 operand iRegIHeapbase()
 4847 %{
 4848   constraint(ALLOC_IN_RC(heapbase_reg));
 4849   match(RegI);
 4850   op_cost(0);
 4851   format %{ %}
 4852   interface(REG_INTER);
 4853 %}
 4854 
 4855 // Float Register
 4856 // Float register operands
 4857 operand vRegF()
 4858 %{
 4859   constraint(ALLOC_IN_RC(float_reg));
 4860   match(RegF);
 4861 
 4862   op_cost(0);
 4863   format %{ %}
 4864   interface(REG_INTER);
 4865 %}
 4866 
 4867 // Double Register
 4868 // Double register operands
 4869 operand vRegD()
 4870 %{
 4871   constraint(ALLOC_IN_RC(double_reg));
 4872   match(RegD);
 4873 
 4874   op_cost(0);
 4875   format %{ %}
 4876   interface(REG_INTER);
 4877 %}
 4878 
 4879 operand vecD()
 4880 %{
 4881   constraint(ALLOC_IN_RC(vectord_reg));
 4882   match(VecD);
 4883 
 4884   op_cost(0);
 4885   format %{ %}
 4886   interface(REG_INTER);
 4887 %}
 4888 
 4889 operand vecX()
 4890 %{
 4891   constraint(ALLOC_IN_RC(vectorx_reg));
 4892   match(VecX);
 4893 
 4894   op_cost(0);
 4895   format %{ %}
 4896   interface(REG_INTER);
 4897 %}
 4898 
 4899 operand vRegD_V0()
 4900 %{
 4901   constraint(ALLOC_IN_RC(v0_reg));
 4902   match(RegD);
 4903   op_cost(0);
 4904   format %{ %}
 4905   interface(REG_INTER);
 4906 %}
 4907 
 4908 operand vRegD_V1()
 4909 %{
 4910   constraint(ALLOC_IN_RC(v1_reg));
 4911   match(RegD);
 4912   op_cost(0);
 4913   format %{ %}
 4914   interface(REG_INTER);
 4915 %}
 4916 
 4917 operand vRegD_V2()
 4918 %{
 4919   constraint(ALLOC_IN_RC(v2_reg));
 4920   match(RegD);
 4921   op_cost(0);
 4922   format %{ %}
 4923   interface(REG_INTER);
 4924 %}
 4925 
 4926 operand vRegD_V3()
 4927 %{
 4928   constraint(ALLOC_IN_RC(v3_reg));
 4929   match(RegD);
 4930   op_cost(0);
 4931   format %{ %}
 4932   interface(REG_INTER);
 4933 %}
 4934 
 4935 operand vRegD_V4()
 4936 %{
 4937   constraint(ALLOC_IN_RC(v4_reg));
 4938   match(RegD);
 4939   op_cost(0);
 4940   format %{ %}
 4941   interface(REG_INTER);
 4942 %}
 4943 
 4944 operand vRegD_V5()
 4945 %{
 4946   constraint(ALLOC_IN_RC(v5_reg));
 4947   match(RegD);
 4948   op_cost(0);
 4949   format %{ %}
 4950   interface(REG_INTER);
 4951 %}
 4952 
 4953 operand vRegD_V6()
 4954 %{
 4955   constraint(ALLOC_IN_RC(v6_reg));
 4956   match(RegD);
 4957   op_cost(0);
 4958   format %{ %}
 4959   interface(REG_INTER);
 4960 %}
 4961 
 4962 operand vRegD_V7()
 4963 %{
 4964   constraint(ALLOC_IN_RC(v7_reg));
 4965   match(RegD);
 4966   op_cost(0);
 4967   format %{ %}
 4968   interface(REG_INTER);
 4969 %}
 4970 
 4971 operand vRegD_V8()
 4972 %{
 4973   constraint(ALLOC_IN_RC(v8_reg));
 4974   match(RegD);
 4975   op_cost(0);
 4976   format %{ %}
 4977   interface(REG_INTER);
 4978 %}
 4979 
 4980 operand vRegD_V9()
 4981 %{
 4982   constraint(ALLOC_IN_RC(v9_reg));
 4983   match(RegD);
 4984   op_cost(0);
 4985   format %{ %}
 4986   interface(REG_INTER);
 4987 %}
 4988 
 4989 operand vRegD_V10()
 4990 %{
 4991   constraint(ALLOC_IN_RC(v10_reg));
 4992   match(RegD);
 4993   op_cost(0);
 4994   format %{ %}
 4995   interface(REG_INTER);
 4996 %}
 4997 
 4998 operand vRegD_V11()
 4999 %{
 5000   constraint(ALLOC_IN_RC(v11_reg));
 5001   match(RegD);
 5002   op_cost(0);
 5003   format %{ %}
 5004   interface(REG_INTER);
 5005 %}
 5006 
 5007 operand vRegD_V12()
 5008 %{
 5009   constraint(ALLOC_IN_RC(v12_reg));
 5010   match(RegD);
 5011   op_cost(0);
 5012   format %{ %}
 5013   interface(REG_INTER);
 5014 %}
 5015 
 5016 operand vRegD_V13()
 5017 %{
 5018   constraint(ALLOC_IN_RC(v13_reg));
 5019   match(RegD);
 5020   op_cost(0);
 5021   format %{ %}
 5022   interface(REG_INTER);
 5023 %}
 5024 
 5025 operand vRegD_V14()
 5026 %{
 5027   constraint(ALLOC_IN_RC(v14_reg));
 5028   match(RegD);
 5029   op_cost(0);
 5030   format %{ %}
 5031   interface(REG_INTER);
 5032 %}
 5033 
 5034 operand vRegD_V15()
 5035 %{
 5036   constraint(ALLOC_IN_RC(v15_reg));
 5037   match(RegD);
 5038   op_cost(0);
 5039   format %{ %}
 5040   interface(REG_INTER);
 5041 %}
 5042 
 5043 operand vRegD_V16()
 5044 %{
 5045   constraint(ALLOC_IN_RC(v16_reg));
 5046   match(RegD);
 5047   op_cost(0);
 5048   format %{ %}
 5049   interface(REG_INTER);
 5050 %}
 5051 
 5052 operand vRegD_V17()
 5053 %{
 5054   constraint(ALLOC_IN_RC(v17_reg));
 5055   match(RegD);
 5056   op_cost(0);
 5057   format %{ %}
 5058   interface(REG_INTER);
 5059 %}
 5060 
 5061 operand vRegD_V18()
 5062 %{
 5063   constraint(ALLOC_IN_RC(v18_reg));
 5064   match(RegD);
 5065   op_cost(0);
 5066   format %{ %}
 5067   interface(REG_INTER);
 5068 %}
 5069 
 5070 operand vRegD_V19()
 5071 %{
 5072   constraint(ALLOC_IN_RC(v19_reg));
 5073   match(RegD);
 5074   op_cost(0);
 5075   format %{ %}
 5076   interface(REG_INTER);
 5077 %}
 5078 
 5079 operand vRegD_V20()
 5080 %{
 5081   constraint(ALLOC_IN_RC(v20_reg));
 5082   match(RegD);
 5083   op_cost(0);
 5084   format %{ %}
 5085   interface(REG_INTER);
 5086 %}
 5087 
 5088 operand vRegD_V21()
 5089 %{
 5090   constraint(ALLOC_IN_RC(v21_reg));
 5091   match(RegD);
 5092   op_cost(0);
 5093   format %{ %}
 5094   interface(REG_INTER);
 5095 %}
 5096 
 5097 operand vRegD_V22()
 5098 %{
 5099   constraint(ALLOC_IN_RC(v22_reg));
 5100   match(RegD);
 5101   op_cost(0);
 5102   format %{ %}
 5103   interface(REG_INTER);
 5104 %}
 5105 
 5106 operand vRegD_V23()
 5107 %{
 5108   constraint(ALLOC_IN_RC(v23_reg));
 5109   match(RegD);
 5110   op_cost(0);
 5111   format %{ %}
 5112   interface(REG_INTER);
 5113 %}
 5114 
 5115 operand vRegD_V24()
 5116 %{
 5117   constraint(ALLOC_IN_RC(v24_reg));
 5118   match(RegD);
 5119   op_cost(0);
 5120   format %{ %}
 5121   interface(REG_INTER);
 5122 %}
 5123 
 5124 operand vRegD_V25()
 5125 %{
 5126   constraint(ALLOC_IN_RC(v25_reg));
 5127   match(RegD);
 5128   op_cost(0);
 5129   format %{ %}
 5130   interface(REG_INTER);
 5131 %}
 5132 
 5133 operand vRegD_V26()
 5134 %{
 5135   constraint(ALLOC_IN_RC(v26_reg));
 5136   match(RegD);
 5137   op_cost(0);
 5138   format %{ %}
 5139   interface(REG_INTER);
 5140 %}
 5141 
 5142 operand vRegD_V27()
 5143 %{
 5144   constraint(ALLOC_IN_RC(v27_reg));
 5145   match(RegD);
 5146   op_cost(0);
 5147   format %{ %}
 5148   interface(REG_INTER);
 5149 %}
 5150 
 5151 operand vRegD_V28()
 5152 %{
 5153   constraint(ALLOC_IN_RC(v28_reg));
 5154   match(RegD);
 5155   op_cost(0);
 5156   format %{ %}
 5157   interface(REG_INTER);
 5158 %}
 5159 
 5160 operand vRegD_V29()
 5161 %{
 5162   constraint(ALLOC_IN_RC(v29_reg));
 5163   match(RegD);
 5164   op_cost(0);
 5165   format %{ %}
 5166   interface(REG_INTER);
 5167 %}
 5168 
 5169 operand vRegD_V30()
 5170 %{
 5171   constraint(ALLOC_IN_RC(v30_reg));
 5172   match(RegD);
 5173   op_cost(0);
 5174   format %{ %}
 5175   interface(REG_INTER);
 5176 %}
 5177 
 5178 operand vRegD_V31()
 5179 %{
 5180   constraint(ALLOC_IN_RC(v31_reg));
 5181   match(RegD);
 5182   op_cost(0);
 5183   format %{ %}
 5184   interface(REG_INTER);
 5185 %}
 5186 
 5187 // Flags register, used as output of signed compare instructions
 5188 
 5189 // note that on AArch64 we also use this register as the output for
 5190 // for floating point compare instructions (CmpF CmpD). this ensures
 5191 // that ordered inequality tests use GT, GE, LT or LE none of which
 5192 // pass through cases where the result is unordered i.e. one or both
 5193 // inputs to the compare is a NaN. this means that the ideal code can
 5194 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5195 // (where the comparison should always fail). EQ and NE tests are
 5196 // always generated in ideal code so that unordered folds into the NE
 5197 // case, matching the behaviour of AArch64 NE.
 5198 //
 5199 // This differs from x86 where the outputs of FP compares use a
 5200 // special FP flags registers and where compares based on this
 5201 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5202 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5203 // to explicitly handle the unordered case in branches. x86 also has
 5204 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5205 
 5206 operand rFlagsReg()
 5207 %{
 5208   constraint(ALLOC_IN_RC(int_flags));
 5209   match(RegFlags);
 5210 
 5211   op_cost(0);
 5212   format %{ &quot;RFLAGS&quot; %}
 5213   interface(REG_INTER);
 5214 %}
 5215 
 5216 // Flags register, used as output of unsigned compare instructions
 5217 operand rFlagsRegU()
 5218 %{
 5219   constraint(ALLOC_IN_RC(int_flags));
 5220   match(RegFlags);
 5221 
 5222   op_cost(0);
 5223   format %{ &quot;RFLAGSU&quot; %}
 5224   interface(REG_INTER);
 5225 %}
 5226 
 5227 // Special Registers
 5228 
 5229 // Method Register
 5230 operand inline_cache_RegP(iRegP reg)
 5231 %{
 5232   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5233   match(reg);
 5234   match(iRegPNoSp);
 5235   op_cost(0);
 5236   format %{ %}
 5237   interface(REG_INTER);
 5238 %}
 5239 
 5240 operand interpreter_method_oop_RegP(iRegP reg)
 5241 %{
 5242   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5243   match(reg);
 5244   match(iRegPNoSp);
 5245   op_cost(0);
 5246   format %{ %}
 5247   interface(REG_INTER);
 5248 %}
 5249 
 5250 // Thread Register
 5251 operand thread_RegP(iRegP reg)
 5252 %{
 5253   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5254   match(reg);
 5255   op_cost(0);
 5256   format %{ %}
 5257   interface(REG_INTER);
 5258 %}
 5259 
 5260 operand lr_RegP(iRegP reg)
 5261 %{
 5262   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5263   match(reg);
 5264   op_cost(0);
 5265   format %{ %}
 5266   interface(REG_INTER);
 5267 %}
 5268 
 5269 //----------Memory Operands----------------------------------------------------
 5270 
 5271 operand indirect(iRegP reg)
 5272 %{
 5273   constraint(ALLOC_IN_RC(ptr_reg));
 5274   match(reg);
 5275   op_cost(0);
 5276   format %{ &quot;[$reg]&quot; %}
 5277   interface(MEMORY_INTER) %{
 5278     base($reg);
 5279     index(0xffffffff);
 5280     scale(0x0);
 5281     disp(0x0);
 5282   %}
 5283 %}
 5284 
 5285 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5286 %{
 5287   constraint(ALLOC_IN_RC(ptr_reg));
 5288   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5289   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5290   op_cost(0);
 5291   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5292   interface(MEMORY_INTER) %{
 5293     base($reg);
 5294     index($ireg);
 5295     scale($scale);
 5296     disp(0x0);
 5297   %}
 5298 %}
 5299 
 5300 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5301 %{
 5302   constraint(ALLOC_IN_RC(ptr_reg));
 5303   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5304   match(AddP reg (LShiftL lreg scale));
 5305   op_cost(0);
 5306   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5307   interface(MEMORY_INTER) %{
 5308     base($reg);
 5309     index($lreg);
 5310     scale($scale);
 5311     disp(0x0);
 5312   %}
 5313 %}
 5314 
 5315 operand indIndexI2L(iRegP reg, iRegI ireg)
 5316 %{
 5317   constraint(ALLOC_IN_RC(ptr_reg));
 5318   match(AddP reg (ConvI2L ireg));
 5319   op_cost(0);
 5320   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5321   interface(MEMORY_INTER) %{
 5322     base($reg);
 5323     index($ireg);
 5324     scale(0x0);
 5325     disp(0x0);
 5326   %}
 5327 %}
 5328 
 5329 operand indIndex(iRegP reg, iRegL lreg)
 5330 %{
 5331   constraint(ALLOC_IN_RC(ptr_reg));
 5332   match(AddP reg lreg);
 5333   op_cost(0);
 5334   format %{ &quot;$reg, $lreg&quot; %}
 5335   interface(MEMORY_INTER) %{
 5336     base($reg);
 5337     index($lreg);
 5338     scale(0x0);
 5339     disp(0x0);
 5340   %}
 5341 %}
 5342 
 5343 operand indOffI(iRegP reg, immIOffset off)
 5344 %{
 5345   constraint(ALLOC_IN_RC(ptr_reg));
 5346   match(AddP reg off);
 5347   op_cost(0);
 5348   format %{ &quot;[$reg, $off]&quot; %}
 5349   interface(MEMORY_INTER) %{
 5350     base($reg);
 5351     index(0xffffffff);
 5352     scale(0x0);
 5353     disp($off);
 5354   %}
 5355 %}
 5356 
 5357 operand indOffI1(iRegP reg, immIOffset1 off)
 5358 %{
 5359   constraint(ALLOC_IN_RC(ptr_reg));
 5360   match(AddP reg off);
 5361   op_cost(0);
 5362   format %{ &quot;[$reg, $off]&quot; %}
 5363   interface(MEMORY_INTER) %{
 5364     base($reg);
 5365     index(0xffffffff);
 5366     scale(0x0);
 5367     disp($off);
 5368   %}
 5369 %}
 5370 
 5371 operand indOffI2(iRegP reg, immIOffset2 off)
 5372 %{
 5373   constraint(ALLOC_IN_RC(ptr_reg));
 5374   match(AddP reg off);
 5375   op_cost(0);
 5376   format %{ &quot;[$reg, $off]&quot; %}
 5377   interface(MEMORY_INTER) %{
 5378     base($reg);
 5379     index(0xffffffff);
 5380     scale(0x0);
 5381     disp($off);
 5382   %}
 5383 %}
 5384 
 5385 operand indOffI4(iRegP reg, immIOffset4 off)
 5386 %{
 5387   constraint(ALLOC_IN_RC(ptr_reg));
 5388   match(AddP reg off);
 5389   op_cost(0);
 5390   format %{ &quot;[$reg, $off]&quot; %}
 5391   interface(MEMORY_INTER) %{
 5392     base($reg);
 5393     index(0xffffffff);
 5394     scale(0x0);
 5395     disp($off);
 5396   %}
 5397 %}
 5398 
 5399 operand indOffI8(iRegP reg, immIOffset8 off)
 5400 %{
 5401   constraint(ALLOC_IN_RC(ptr_reg));
 5402   match(AddP reg off);
 5403   op_cost(0);
 5404   format %{ &quot;[$reg, $off]&quot; %}
 5405   interface(MEMORY_INTER) %{
 5406     base($reg);
 5407     index(0xffffffff);
 5408     scale(0x0);
 5409     disp($off);
 5410   %}
 5411 %}
 5412 
 5413 operand indOffI16(iRegP reg, immIOffset16 off)
 5414 %{
 5415   constraint(ALLOC_IN_RC(ptr_reg));
 5416   match(AddP reg off);
 5417   op_cost(0);
 5418   format %{ &quot;[$reg, $off]&quot; %}
 5419   interface(MEMORY_INTER) %{
 5420     base($reg);
 5421     index(0xffffffff);
 5422     scale(0x0);
 5423     disp($off);
 5424   %}
 5425 %}
 5426 
 5427 operand indOffL(iRegP reg, immLoffset off)
 5428 %{
 5429   constraint(ALLOC_IN_RC(ptr_reg));
 5430   match(AddP reg off);
 5431   op_cost(0);
 5432   format %{ &quot;[$reg, $off]&quot; %}
 5433   interface(MEMORY_INTER) %{
 5434     base($reg);
 5435     index(0xffffffff);
 5436     scale(0x0);
 5437     disp($off);
 5438   %}
 5439 %}
 5440 
 5441 operand indOffL1(iRegP reg, immLoffset1 off)
 5442 %{
 5443   constraint(ALLOC_IN_RC(ptr_reg));
 5444   match(AddP reg off);
 5445   op_cost(0);
 5446   format %{ &quot;[$reg, $off]&quot; %}
 5447   interface(MEMORY_INTER) %{
 5448     base($reg);
 5449     index(0xffffffff);
 5450     scale(0x0);
 5451     disp($off);
 5452   %}
 5453 %}
 5454 
 5455 operand indOffL2(iRegP reg, immLoffset2 off)
 5456 %{
 5457   constraint(ALLOC_IN_RC(ptr_reg));
 5458   match(AddP reg off);
 5459   op_cost(0);
 5460   format %{ &quot;[$reg, $off]&quot; %}
 5461   interface(MEMORY_INTER) %{
 5462     base($reg);
 5463     index(0xffffffff);
 5464     scale(0x0);
 5465     disp($off);
 5466   %}
 5467 %}
 5468 
 5469 operand indOffL4(iRegP reg, immLoffset4 off)
 5470 %{
 5471   constraint(ALLOC_IN_RC(ptr_reg));
 5472   match(AddP reg off);
 5473   op_cost(0);
 5474   format %{ &quot;[$reg, $off]&quot; %}
 5475   interface(MEMORY_INTER) %{
 5476     base($reg);
 5477     index(0xffffffff);
 5478     scale(0x0);
 5479     disp($off);
 5480   %}
 5481 %}
 5482 
 5483 operand indOffL8(iRegP reg, immLoffset8 off)
 5484 %{
 5485   constraint(ALLOC_IN_RC(ptr_reg));
 5486   match(AddP reg off);
 5487   op_cost(0);
 5488   format %{ &quot;[$reg, $off]&quot; %}
 5489   interface(MEMORY_INTER) %{
 5490     base($reg);
 5491     index(0xffffffff);
 5492     scale(0x0);
 5493     disp($off);
 5494   %}
 5495 %}
 5496 
 5497 operand indOffL16(iRegP reg, immLoffset16 off)
 5498 %{
 5499   constraint(ALLOC_IN_RC(ptr_reg));
 5500   match(AddP reg off);
 5501   op_cost(0);
 5502   format %{ &quot;[$reg, $off]&quot; %}
 5503   interface(MEMORY_INTER) %{
 5504     base($reg);
 5505     index(0xffffffff);
 5506     scale(0x0);
 5507     disp($off);
 5508   %}
 5509 %}
 5510 
 5511 operand indirectN(iRegN reg)
 5512 %{
 5513   predicate(CompressedOops::shift() == 0);
 5514   constraint(ALLOC_IN_RC(ptr_reg));
 5515   match(DecodeN reg);
 5516   op_cost(0);
 5517   format %{ &quot;[$reg]\t# narrow&quot; %}
 5518   interface(MEMORY_INTER) %{
 5519     base($reg);
 5520     index(0xffffffff);
 5521     scale(0x0);
 5522     disp(0x0);
 5523   %}
 5524 %}
 5525 
 5526 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5527 %{
 5528   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5529   constraint(ALLOC_IN_RC(ptr_reg));
 5530   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5531   op_cost(0);
 5532   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5533   interface(MEMORY_INTER) %{
 5534     base($reg);
 5535     index($ireg);
 5536     scale($scale);
 5537     disp(0x0);
 5538   %}
 5539 %}
 5540 
 5541 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5542 %{
 5543   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5544   constraint(ALLOC_IN_RC(ptr_reg));
 5545   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5546   op_cost(0);
 5547   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5548   interface(MEMORY_INTER) %{
 5549     base($reg);
 5550     index($lreg);
 5551     scale($scale);
 5552     disp(0x0);
 5553   %}
 5554 %}
 5555 
 5556 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5557 %{
 5558   predicate(CompressedOops::shift() == 0);
 5559   constraint(ALLOC_IN_RC(ptr_reg));
 5560   match(AddP (DecodeN reg) (ConvI2L ireg));
 5561   op_cost(0);
 5562   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5563   interface(MEMORY_INTER) %{
 5564     base($reg);
 5565     index($ireg);
 5566     scale(0x0);
 5567     disp(0x0);
 5568   %}
 5569 %}
 5570 
 5571 operand indIndexN(iRegN reg, iRegL lreg)
 5572 %{
 5573   predicate(CompressedOops::shift() == 0);
 5574   constraint(ALLOC_IN_RC(ptr_reg));
 5575   match(AddP (DecodeN reg) lreg);
 5576   op_cost(0);
 5577   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5578   interface(MEMORY_INTER) %{
 5579     base($reg);
 5580     index($lreg);
 5581     scale(0x0);
 5582     disp(0x0);
 5583   %}
 5584 %}
 5585 
 5586 operand indOffIN(iRegN reg, immIOffset off)
 5587 %{
 5588   predicate(CompressedOops::shift() == 0);
 5589   constraint(ALLOC_IN_RC(ptr_reg));
 5590   match(AddP (DecodeN reg) off);
 5591   op_cost(0);
 5592   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5593   interface(MEMORY_INTER) %{
 5594     base($reg);
 5595     index(0xffffffff);
 5596     scale(0x0);
 5597     disp($off);
 5598   %}
 5599 %}
 5600 
 5601 operand indOffLN(iRegN reg, immLoffset off)
 5602 %{
 5603   predicate(CompressedOops::shift() == 0);
 5604   constraint(ALLOC_IN_RC(ptr_reg));
 5605   match(AddP (DecodeN reg) off);
 5606   op_cost(0);
 5607   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5608   interface(MEMORY_INTER) %{
 5609     base($reg);
 5610     index(0xffffffff);
 5611     scale(0x0);
 5612     disp($off);
 5613   %}
 5614 %}
 5615 
 5616 
 5617 
 5618 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5619 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5620 %{
 5621   constraint(ALLOC_IN_RC(ptr_reg));
 5622   match(AddP reg off);
 5623   op_cost(0);
 5624   format %{ &quot;[$reg, $off]&quot; %}
 5625   interface(MEMORY_INTER) %{
 5626     base($reg);
 5627     index(0xffffffff);
 5628     scale(0x0);
 5629     disp($off);
 5630   %}
 5631 %}
 5632 
 5633 //----------Special Memory Operands--------------------------------------------
 5634 // Stack Slot Operand - This operand is used for loading and storing temporary
 5635 //                      values on the stack where a match requires a value to
 5636 //                      flow through memory.
 5637 operand stackSlotP(sRegP reg)
 5638 %{
 5639   constraint(ALLOC_IN_RC(stack_slots));
 5640   op_cost(100);
 5641   // No match rule because this operand is only generated in matching
 5642   // match(RegP);
 5643   format %{ &quot;[$reg]&quot; %}
 5644   interface(MEMORY_INTER) %{
 5645     base(0x1e);  // RSP
 5646     index(0x0);  // No Index
 5647     scale(0x0);  // No Scale
 5648     disp($reg);  // Stack Offset
 5649   %}
 5650 %}
 5651 
 5652 operand stackSlotI(sRegI reg)
 5653 %{
 5654   constraint(ALLOC_IN_RC(stack_slots));
 5655   // No match rule because this operand is only generated in matching
 5656   // match(RegI);
 5657   format %{ &quot;[$reg]&quot; %}
 5658   interface(MEMORY_INTER) %{
 5659     base(0x1e);  // RSP
 5660     index(0x0);  // No Index
 5661     scale(0x0);  // No Scale
 5662     disp($reg);  // Stack Offset
 5663   %}
 5664 %}
 5665 
 5666 operand stackSlotF(sRegF reg)
 5667 %{
 5668   constraint(ALLOC_IN_RC(stack_slots));
 5669   // No match rule because this operand is only generated in matching
 5670   // match(RegF);
 5671   format %{ &quot;[$reg]&quot; %}
 5672   interface(MEMORY_INTER) %{
 5673     base(0x1e);  // RSP
 5674     index(0x0);  // No Index
 5675     scale(0x0);  // No Scale
 5676     disp($reg);  // Stack Offset
 5677   %}
 5678 %}
 5679 
 5680 operand stackSlotD(sRegD reg)
 5681 %{
 5682   constraint(ALLOC_IN_RC(stack_slots));
 5683   // No match rule because this operand is only generated in matching
 5684   // match(RegD);
 5685   format %{ &quot;[$reg]&quot; %}
 5686   interface(MEMORY_INTER) %{
 5687     base(0x1e);  // RSP
 5688     index(0x0);  // No Index
 5689     scale(0x0);  // No Scale
 5690     disp($reg);  // Stack Offset
 5691   %}
 5692 %}
 5693 
 5694 operand stackSlotL(sRegL reg)
 5695 %{
 5696   constraint(ALLOC_IN_RC(stack_slots));
 5697   // No match rule because this operand is only generated in matching
 5698   // match(RegL);
 5699   format %{ &quot;[$reg]&quot; %}
 5700   interface(MEMORY_INTER) %{
 5701     base(0x1e);  // RSP
 5702     index(0x0);  // No Index
 5703     scale(0x0);  // No Scale
 5704     disp($reg);  // Stack Offset
 5705   %}
 5706 %}
 5707 
 5708 // Operands for expressing Control Flow
 5709 // NOTE: Label is a predefined operand which should not be redefined in
 5710 //       the AD file. It is generically handled within the ADLC.
 5711 
 5712 //----------Conditional Branch Operands----------------------------------------
 5713 // Comparison Op  - This is the operation of the comparison, and is limited to
 5714 //                  the following set of codes:
 5715 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5716 //
 5717 // Other attributes of the comparison, such as unsignedness, are specified
 5718 // by the comparison instruction that sets a condition code flags register.
 5719 // That result is represented by a flags operand whose subtype is appropriate
 5720 // to the unsignedness (etc.) of the comparison.
 5721 //
 5722 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5723 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5724 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5725 
 5726 // used for signed integral comparisons and fp comparisons
 5727 
 5728 operand cmpOp()
 5729 %{
 5730   match(Bool);
 5731 
 5732   format %{ &quot;&quot; %}
 5733   interface(COND_INTER) %{
 5734     equal(0x0, &quot;eq&quot;);
 5735     not_equal(0x1, &quot;ne&quot;);
 5736     less(0xb, &quot;lt&quot;);
 5737     greater_equal(0xa, &quot;ge&quot;);
 5738     less_equal(0xd, &quot;le&quot;);
 5739     greater(0xc, &quot;gt&quot;);
 5740     overflow(0x6, &quot;vs&quot;);
 5741     no_overflow(0x7, &quot;vc&quot;);
 5742   %}
 5743 %}
 5744 
 5745 // used for unsigned integral comparisons
 5746 
 5747 operand cmpOpU()
 5748 %{
 5749   match(Bool);
 5750 
 5751   format %{ &quot;&quot; %}
 5752   interface(COND_INTER) %{
 5753     equal(0x0, &quot;eq&quot;);
 5754     not_equal(0x1, &quot;ne&quot;);
 5755     less(0x3, &quot;lo&quot;);
 5756     greater_equal(0x2, &quot;hs&quot;);
 5757     less_equal(0x9, &quot;ls&quot;);
 5758     greater(0x8, &quot;hi&quot;);
 5759     overflow(0x6, &quot;vs&quot;);
 5760     no_overflow(0x7, &quot;vc&quot;);
 5761   %}
 5762 %}
 5763 
 5764 // used for certain integral comparisons which can be
 5765 // converted to cbxx or tbxx instructions
 5766 
 5767 operand cmpOpEqNe()
 5768 %{
 5769   match(Bool);
 5770   op_cost(0);
 5771   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5772             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5773 
 5774   format %{ &quot;&quot; %}
 5775   interface(COND_INTER) %{
 5776     equal(0x0, &quot;eq&quot;);
 5777     not_equal(0x1, &quot;ne&quot;);
 5778     less(0xb, &quot;lt&quot;);
 5779     greater_equal(0xa, &quot;ge&quot;);
 5780     less_equal(0xd, &quot;le&quot;);
 5781     greater(0xc, &quot;gt&quot;);
 5782     overflow(0x6, &quot;vs&quot;);
 5783     no_overflow(0x7, &quot;vc&quot;);
 5784   %}
 5785 %}
 5786 
 5787 // used for certain integral comparisons which can be
 5788 // converted to cbxx or tbxx instructions
 5789 
 5790 operand cmpOpLtGe()
 5791 %{
 5792   match(Bool);
 5793   op_cost(0);
 5794 
 5795   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5796             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5797 
 5798   format %{ &quot;&quot; %}
 5799   interface(COND_INTER) %{
 5800     equal(0x0, &quot;eq&quot;);
 5801     not_equal(0x1, &quot;ne&quot;);
 5802     less(0xb, &quot;lt&quot;);
 5803     greater_equal(0xa, &quot;ge&quot;);
 5804     less_equal(0xd, &quot;le&quot;);
 5805     greater(0xc, &quot;gt&quot;);
 5806     overflow(0x6, &quot;vs&quot;);
 5807     no_overflow(0x7, &quot;vc&quot;);
 5808   %}
 5809 %}
 5810 
 5811 // used for certain unsigned integral comparisons which can be
 5812 // converted to cbxx or tbxx instructions
 5813 
 5814 operand cmpOpUEqNeLtGe()
 5815 %{
 5816   match(Bool);
 5817   op_cost(0);
 5818 
 5819   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5820             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5821             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5822             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5823 
 5824   format %{ &quot;&quot; %}
 5825   interface(COND_INTER) %{
 5826     equal(0x0, &quot;eq&quot;);
 5827     not_equal(0x1, &quot;ne&quot;);
 5828     less(0xb, &quot;lt&quot;);
 5829     greater_equal(0xa, &quot;ge&quot;);
 5830     less_equal(0xd, &quot;le&quot;);
 5831     greater(0xc, &quot;gt&quot;);
 5832     overflow(0x6, &quot;vs&quot;);
 5833     no_overflow(0x7, &quot;vc&quot;);
 5834   %}
 5835 %}
 5836 
 5837 // Special operand allowing long args to int ops to be truncated for free
 5838 
 5839 operand iRegL2I(iRegL reg) %{
 5840 
 5841   op_cost(0);
 5842 
 5843   match(ConvL2I reg);
 5844 
 5845   format %{ &quot;l2i($reg)&quot; %}
 5846 
 5847   interface(REG_INTER)
 5848 %}
 5849 
 5850 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5851 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5852 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5853 
 5854 //----------OPERAND CLASSES----------------------------------------------------
 5855 // Operand Classes are groups of operands that are used as to simplify
 5856 // instruction definitions by not requiring the AD writer to specify
 5857 // separate instructions for every form of operand when the
 5858 // instruction accepts multiple operand types with the same basic
 5859 // encoding and format. The classic case of this is memory operands.
 5860 
 5861 // memory is used to define read/write location for load/store
 5862 // instruction defs. we can turn a memory op into an Address
 5863 
 5864 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5865                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5866 
 5867 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5868                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5869 
 5870 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5871                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5872 
 5873 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5874                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5875 
 5876 // All of the memory operands. For the pipeline description.
 5877 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5878                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5879                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5880 
 5881 
 5882 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5883 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5884 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5885 // can be elided because the 32-bit instruction will just employ the
 5886 // lower 32 bits anyway.
 5887 //
 5888 // n.b. this does not elide all L2I conversions. if the truncated
 5889 // value is consumed by more than one operation then the ConvL2I
 5890 // cannot be bundled into the consuming nodes so an l2i gets planted
 5891 // (actually a movw $dst $src) and the downstream instructions consume
 5892 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5893 // movw is actually redundant but its not too costly.
 5894 
 5895 opclass iRegIorL2I(iRegI, iRegL2I);
 5896 
 5897 //----------PIPELINE-----------------------------------------------------------
 5898 // Rules which define the behavior of the target architectures pipeline.
 5899 
 5900 // For specific pipelines, eg A53, define the stages of that pipeline
 5901 //pipe_desc(ISS, EX1, EX2, WR);
 5902 #define ISS S0
 5903 #define EX1 S1
 5904 #define EX2 S2
 5905 #define WR  S3
 5906 
 5907 // Integer ALU reg operation
 5908 pipeline %{
 5909 
 5910 attributes %{
 5911   // ARM instructions are of fixed length
 5912   fixed_size_instructions;        // Fixed size instructions TODO does
 5913   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5914   // ARM instructions come in 32-bit word units
 5915   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5916   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5917   instruction_fetch_units = 1;       // of 64 bytes
 5918 
 5919   // List of nop instructions
 5920   nops( MachNop );
 5921 %}
 5922 
 5923 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5924 // or description. we do use pipeline classes to introduce fixed
 5925 // latencies
 5926 
 5927 //----------RESOURCES----------------------------------------------------------
 5928 // Resources are the functional units available to the machine
 5929 
 5930 resources( INS0, INS1, INS01 = INS0 | INS1,
 5931            ALU0, ALU1, ALU = ALU0 | ALU1,
 5932            MAC,
 5933            DIV,
 5934            BRANCH,
 5935            LDST,
 5936            NEON_FP);
 5937 
 5938 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5939 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5940 
 5941 // Define the pipeline as a generic 6 stage pipeline
 5942 pipe_desc(S0, S1, S2, S3, S4, S5);
 5943 
 5944 //----------PIPELINE CLASSES---------------------------------------------------
 5945 // Pipeline Classes describe the stages in which input and output are
 5946 // referenced by the hardware pipeline.
 5947 
 5948 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5949 %{
 5950   single_instruction;
 5951   src1   : S1(read);
 5952   src2   : S2(read);
 5953   dst    : S5(write);
 5954   INS01  : ISS;
 5955   NEON_FP : S5;
 5956 %}
 5957 
 5958 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5959 %{
 5960   single_instruction;
 5961   src1   : S1(read);
 5962   src2   : S2(read);
 5963   dst    : S5(write);
 5964   INS01  : ISS;
 5965   NEON_FP : S5;
 5966 %}
 5967 
 5968 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5969 %{
 5970   single_instruction;
 5971   src    : S1(read);
 5972   dst    : S5(write);
 5973   INS01  : ISS;
 5974   NEON_FP : S5;
 5975 %}
 5976 
 5977 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5978 %{
 5979   single_instruction;
 5980   src    : S1(read);
 5981   dst    : S5(write);
 5982   INS01  : ISS;
 5983   NEON_FP : S5;
 5984 %}
 5985 
 5986 pipe_class fp_d2f(vRegF dst, vRegD src)
 5987 %{
 5988   single_instruction;
 5989   src    : S1(read);
 5990   dst    : S5(write);
 5991   INS01  : ISS;
 5992   NEON_FP : S5;
 5993 %}
 5994 
 5995 pipe_class fp_f2d(vRegD dst, vRegF src)
 5996 %{
 5997   single_instruction;
 5998   src    : S1(read);
 5999   dst    : S5(write);
 6000   INS01  : ISS;
 6001   NEON_FP : S5;
 6002 %}
 6003 
 6004 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 6005 %{
 6006   single_instruction;
 6007   src    : S1(read);
 6008   dst    : S5(write);
 6009   INS01  : ISS;
 6010   NEON_FP : S5;
 6011 %}
 6012 
 6013 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6014 %{
 6015   single_instruction;
 6016   src    : S1(read);
 6017   dst    : S5(write);
 6018   INS01  : ISS;
 6019   NEON_FP : S5;
 6020 %}
 6021 
 6022 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6023 %{
 6024   single_instruction;
 6025   src    : S1(read);
 6026   dst    : S5(write);
 6027   INS01  : ISS;
 6028   NEON_FP : S5;
 6029 %}
 6030 
 6031 pipe_class fp_l2f(vRegF dst, iRegL src)
 6032 %{
 6033   single_instruction;
 6034   src    : S1(read);
 6035   dst    : S5(write);
 6036   INS01  : ISS;
 6037   NEON_FP : S5;
 6038 %}
 6039 
 6040 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6041 %{
 6042   single_instruction;
 6043   src    : S1(read);
 6044   dst    : S5(write);
 6045   INS01  : ISS;
 6046   NEON_FP : S5;
 6047 %}
 6048 
 6049 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6050 %{
 6051   single_instruction;
 6052   src    : S1(read);
 6053   dst    : S5(write);
 6054   INS01  : ISS;
 6055   NEON_FP : S5;
 6056 %}
 6057 
 6058 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6059 %{
 6060   single_instruction;
 6061   src    : S1(read);
 6062   dst    : S5(write);
 6063   INS01  : ISS;
 6064   NEON_FP : S5;
 6065 %}
 6066 
 6067 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6068 %{
 6069   single_instruction;
 6070   src    : S1(read);
 6071   dst    : S5(write);
 6072   INS01  : ISS;
 6073   NEON_FP : S5;
 6074 %}
 6075 
 6076 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6077 %{
 6078   single_instruction;
 6079   src1   : S1(read);
 6080   src2   : S2(read);
 6081   dst    : S5(write);
 6082   INS0   : ISS;
 6083   NEON_FP : S5;
 6084 %}
 6085 
 6086 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6087 %{
 6088   single_instruction;
 6089   src1   : S1(read);
 6090   src2   : S2(read);
 6091   dst    : S5(write);
 6092   INS0   : ISS;
 6093   NEON_FP : S5;
 6094 %}
 6095 
 6096 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6097 %{
 6098   single_instruction;
 6099   cr     : S1(read);
 6100   src1   : S1(read);
 6101   src2   : S1(read);
 6102   dst    : S3(write);
 6103   INS01  : ISS;
 6104   NEON_FP : S3;
 6105 %}
 6106 
 6107 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6108 %{
 6109   single_instruction;
 6110   cr     : S1(read);
 6111   src1   : S1(read);
 6112   src2   : S1(read);
 6113   dst    : S3(write);
 6114   INS01  : ISS;
 6115   NEON_FP : S3;
 6116 %}
 6117 
 6118 pipe_class fp_imm_s(vRegF dst)
 6119 %{
 6120   single_instruction;
 6121   dst    : S3(write);
 6122   INS01  : ISS;
 6123   NEON_FP : S3;
 6124 %}
 6125 
 6126 pipe_class fp_imm_d(vRegD dst)
 6127 %{
 6128   single_instruction;
 6129   dst    : S3(write);
 6130   INS01  : ISS;
 6131   NEON_FP : S3;
 6132 %}
 6133 
 6134 pipe_class fp_load_constant_s(vRegF dst)
 6135 %{
 6136   single_instruction;
 6137   dst    : S4(write);
 6138   INS01  : ISS;
 6139   NEON_FP : S4;
 6140 %}
 6141 
 6142 pipe_class fp_load_constant_d(vRegD dst)
 6143 %{
 6144   single_instruction;
 6145   dst    : S4(write);
 6146   INS01  : ISS;
 6147   NEON_FP : S4;
 6148 %}
 6149 
 6150 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6151 %{
 6152   single_instruction;
 6153   dst    : S5(write);
 6154   src1   : S1(read);
 6155   src2   : S1(read);
 6156   INS01  : ISS;
 6157   NEON_FP : S5;
 6158 %}
 6159 
 6160 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6161 %{
 6162   single_instruction;
 6163   dst    : S5(write);
 6164   src1   : S1(read);
 6165   src2   : S1(read);
 6166   INS0   : ISS;
 6167   NEON_FP : S5;
 6168 %}
 6169 
 6170 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6171 %{
 6172   single_instruction;
 6173   dst    : S5(write);
 6174   src1   : S1(read);
 6175   src2   : S1(read);
 6176   dst    : S1(read);
 6177   INS01  : ISS;
 6178   NEON_FP : S5;
 6179 %}
 6180 
 6181 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6182 %{
 6183   single_instruction;
 6184   dst    : S5(write);
 6185   src1   : S1(read);
 6186   src2   : S1(read);
 6187   dst    : S1(read);
 6188   INS0   : ISS;
 6189   NEON_FP : S5;
 6190 %}
 6191 
 6192 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6193 %{
 6194   single_instruction;
 6195   dst    : S4(write);
 6196   src1   : S2(read);
 6197   src2   : S2(read);
 6198   INS01  : ISS;
 6199   NEON_FP : S4;
 6200 %}
 6201 
 6202 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6203 %{
 6204   single_instruction;
 6205   dst    : S4(write);
 6206   src1   : S2(read);
 6207   src2   : S2(read);
 6208   INS0   : ISS;
 6209   NEON_FP : S4;
 6210 %}
 6211 
 6212 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6213 %{
 6214   single_instruction;
 6215   dst    : S3(write);
 6216   src1   : S2(read);
 6217   src2   : S2(read);
 6218   INS01  : ISS;
 6219   NEON_FP : S3;
 6220 %}
 6221 
 6222 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6223 %{
 6224   single_instruction;
 6225   dst    : S3(write);
 6226   src1   : S2(read);
 6227   src2   : S2(read);
 6228   INS0   : ISS;
 6229   NEON_FP : S3;
 6230 %}
 6231 
 6232 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6233 %{
 6234   single_instruction;
 6235   dst    : S3(write);
 6236   src    : S1(read);
 6237   shift  : S1(read);
 6238   INS01  : ISS;
 6239   NEON_FP : S3;
 6240 %}
 6241 
 6242 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6243 %{
 6244   single_instruction;
 6245   dst    : S3(write);
 6246   src    : S1(read);
 6247   shift  : S1(read);
 6248   INS0   : ISS;
 6249   NEON_FP : S3;
 6250 %}
 6251 
 6252 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6253 %{
 6254   single_instruction;
 6255   dst    : S3(write);
 6256   src    : S1(read);
 6257   INS01  : ISS;
 6258   NEON_FP : S3;
 6259 %}
 6260 
 6261 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6262 %{
 6263   single_instruction;
 6264   dst    : S3(write);
 6265   src    : S1(read);
 6266   INS0   : ISS;
 6267   NEON_FP : S3;
 6268 %}
 6269 
 6270 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6271 %{
 6272   single_instruction;
 6273   dst    : S5(write);
 6274   src1   : S1(read);
 6275   src2   : S1(read);
 6276   INS01  : ISS;
 6277   NEON_FP : S5;
 6278 %}
 6279 
 6280 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6281 %{
 6282   single_instruction;
 6283   dst    : S5(write);
 6284   src1   : S1(read);
 6285   src2   : S1(read);
 6286   INS0   : ISS;
 6287   NEON_FP : S5;
 6288 %}
 6289 
 6290 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6291 %{
 6292   single_instruction;
 6293   dst    : S5(write);
 6294   src1   : S1(read);
 6295   src2   : S1(read);
 6296   INS0   : ISS;
 6297   NEON_FP : S5;
 6298 %}
 6299 
 6300 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6301 %{
 6302   single_instruction;
 6303   dst    : S5(write);
 6304   src1   : S1(read);
 6305   src2   : S1(read);
 6306   INS0   : ISS;
 6307   NEON_FP : S5;
 6308 %}
 6309 
 6310 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6311 %{
 6312   single_instruction;
 6313   dst    : S5(write);
 6314   src    : S1(read);
 6315   INS0   : ISS;
 6316   NEON_FP : S5;
 6317 %}
 6318 
 6319 pipe_class vunop_fp64(vecD dst, vecD src)
 6320 %{
 6321   single_instruction;
 6322   dst    : S5(write);
 6323   src    : S1(read);
 6324   INS01  : ISS;
 6325   NEON_FP : S5;
 6326 %}
 6327 
 6328 pipe_class vunop_fp128(vecX dst, vecX src)
 6329 %{
 6330   single_instruction;
 6331   dst    : S5(write);
 6332   src    : S1(read);
 6333   INS0   : ISS;
 6334   NEON_FP : S5;
 6335 %}
 6336 
 6337 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6338 %{
 6339   single_instruction;
 6340   dst    : S3(write);
 6341   src    : S1(read);
 6342   INS01  : ISS;
 6343   NEON_FP : S3;
 6344 %}
 6345 
 6346 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6347 %{
 6348   single_instruction;
 6349   dst    : S3(write);
 6350   src    : S1(read);
 6351   INS01  : ISS;
 6352   NEON_FP : S3;
 6353 %}
 6354 
 6355 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6356 %{
 6357   single_instruction;
 6358   dst    : S3(write);
 6359   src    : S1(read);
 6360   INS01  : ISS;
 6361   NEON_FP : S3;
 6362 %}
 6363 
 6364 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6365 %{
 6366   single_instruction;
 6367   dst    : S3(write);
 6368   src    : S1(read);
 6369   INS01  : ISS;
 6370   NEON_FP : S3;
 6371 %}
 6372 
 6373 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6374 %{
 6375   single_instruction;
 6376   dst    : S3(write);
 6377   src    : S1(read);
 6378   INS01  : ISS;
 6379   NEON_FP : S3;
 6380 %}
 6381 
 6382 pipe_class vmovi_reg_imm64(vecD dst)
 6383 %{
 6384   single_instruction;
 6385   dst    : S3(write);
 6386   INS01  : ISS;
 6387   NEON_FP : S3;
 6388 %}
 6389 
 6390 pipe_class vmovi_reg_imm128(vecX dst)
 6391 %{
 6392   single_instruction;
 6393   dst    : S3(write);
 6394   INS0   : ISS;
 6395   NEON_FP : S3;
 6396 %}
 6397 
 6398 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6399 %{
 6400   single_instruction;
 6401   dst    : S5(write);
 6402   mem    : ISS(read);
 6403   INS01  : ISS;
 6404   NEON_FP : S3;
 6405 %}
 6406 
 6407 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6408 %{
 6409   single_instruction;
 6410   dst    : S5(write);
 6411   mem    : ISS(read);
 6412   INS01  : ISS;
 6413   NEON_FP : S3;
 6414 %}
 6415 
 6416 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6417 %{
 6418   single_instruction;
 6419   mem    : ISS(read);
 6420   src    : S2(read);
 6421   INS01  : ISS;
 6422   NEON_FP : S3;
 6423 %}
 6424 
 6425 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6426 %{
 6427   single_instruction;
 6428   mem    : ISS(read);
 6429   src    : S2(read);
 6430   INS01  : ISS;
 6431   NEON_FP : S3;
 6432 %}
 6433 
 6434 //------- Integer ALU operations --------------------------
 6435 
 6436 // Integer ALU reg-reg operation
 6437 // Operands needed in EX1, result generated in EX2
 6438 // Eg.  ADD     x0, x1, x2
 6439 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6440 %{
 6441   single_instruction;
 6442   dst    : EX2(write);
 6443   src1   : EX1(read);
 6444   src2   : EX1(read);
 6445   INS01  : ISS; // Dual issue as instruction 0 or 1
 6446   ALU    : EX2;
 6447 %}
 6448 
 6449 // Integer ALU reg-reg operation with constant shift
 6450 // Shifted register must be available in LATE_ISS instead of EX1
 6451 // Eg.  ADD     x0, x1, x2, LSL #2
 6452 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6453 %{
 6454   single_instruction;
 6455   dst    : EX2(write);
 6456   src1   : EX1(read);
 6457   src2   : ISS(read);
 6458   INS01  : ISS;
 6459   ALU    : EX2;
 6460 %}
 6461 
 6462 // Integer ALU reg operation with constant shift
 6463 // Eg.  LSL     x0, x1, #shift
 6464 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6465 %{
 6466   single_instruction;
 6467   dst    : EX2(write);
 6468   src1   : ISS(read);
 6469   INS01  : ISS;
 6470   ALU    : EX2;
 6471 %}
 6472 
 6473 // Integer ALU reg-reg operation with variable shift
 6474 // Both operands must be available in LATE_ISS instead of EX1
 6475 // Result is available in EX1 instead of EX2
 6476 // Eg.  LSLV    x0, x1, x2
 6477 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6478 %{
 6479   single_instruction;
 6480   dst    : EX1(write);
 6481   src1   : ISS(read);
 6482   src2   : ISS(read);
 6483   INS01  : ISS;
 6484   ALU    : EX1;
 6485 %}
 6486 
 6487 // Integer ALU reg-reg operation with extract
 6488 // As for _vshift above, but result generated in EX2
 6489 // Eg.  EXTR    x0, x1, x2, #N
 6490 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6491 %{
 6492   single_instruction;
 6493   dst    : EX2(write);
 6494   src1   : ISS(read);
 6495   src2   : ISS(read);
 6496   INS1   : ISS; // Can only dual issue as Instruction 1
 6497   ALU    : EX1;
 6498 %}
 6499 
 6500 // Integer ALU reg operation
 6501 // Eg.  NEG     x0, x1
 6502 pipe_class ialu_reg(iRegI dst, iRegI src)
 6503 %{
 6504   single_instruction;
 6505   dst    : EX2(write);
 6506   src    : EX1(read);
 6507   INS01  : ISS;
 6508   ALU    : EX2;
 6509 %}
 6510 
 6511 // Integer ALU reg mmediate operation
 6512 // Eg.  ADD     x0, x1, #N
 6513 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6514 %{
 6515   single_instruction;
 6516   dst    : EX2(write);
 6517   src1   : EX1(read);
 6518   INS01  : ISS;
 6519   ALU    : EX2;
 6520 %}
 6521 
 6522 // Integer ALU immediate operation (no source operands)
 6523 // Eg.  MOV     x0, #N
 6524 pipe_class ialu_imm(iRegI dst)
 6525 %{
 6526   single_instruction;
 6527   dst    : EX1(write);
 6528   INS01  : ISS;
 6529   ALU    : EX1;
 6530 %}
 6531 
 6532 //------- Compare operation -------------------------------
 6533 
 6534 // Compare reg-reg
 6535 // Eg.  CMP     x0, x1
 6536 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6537 %{
 6538   single_instruction;
 6539 //  fixed_latency(16);
 6540   cr     : EX2(write);
 6541   op1    : EX1(read);
 6542   op2    : EX1(read);
 6543   INS01  : ISS;
 6544   ALU    : EX2;
 6545 %}
 6546 
 6547 // Compare reg-reg
 6548 // Eg.  CMP     x0, #N
 6549 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6550 %{
 6551   single_instruction;
 6552 //  fixed_latency(16);
 6553   cr     : EX2(write);
 6554   op1    : EX1(read);
 6555   INS01  : ISS;
 6556   ALU    : EX2;
 6557 %}
 6558 
 6559 //------- Conditional instructions ------------------------
 6560 
 6561 // Conditional no operands
 6562 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6563 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6564 %{
 6565   single_instruction;
 6566   cr     : EX1(read);
 6567   dst    : EX2(write);
 6568   INS01  : ISS;
 6569   ALU    : EX2;
 6570 %}
 6571 
 6572 // Conditional 2 operand
 6573 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6574 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6575 %{
 6576   single_instruction;
 6577   cr     : EX1(read);
 6578   src1   : EX1(read);
 6579   src2   : EX1(read);
 6580   dst    : EX2(write);
 6581   INS01  : ISS;
 6582   ALU    : EX2;
 6583 %}
 6584 
 6585 // Conditional 2 operand
 6586 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6587 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6588 %{
 6589   single_instruction;
 6590   cr     : EX1(read);
 6591   src    : EX1(read);
 6592   dst    : EX2(write);
 6593   INS01  : ISS;
 6594   ALU    : EX2;
 6595 %}
 6596 
 6597 //------- Multiply pipeline operations --------------------
 6598 
 6599 // Multiply reg-reg
 6600 // Eg.  MUL     w0, w1, w2
 6601 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6602 %{
 6603   single_instruction;
 6604   dst    : WR(write);
 6605   src1   : ISS(read);
 6606   src2   : ISS(read);
 6607   INS01  : ISS;
 6608   MAC    : WR;
 6609 %}
 6610 
 6611 // Multiply accumulate
 6612 // Eg.  MADD    w0, w1, w2, w3
 6613 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6614 %{
 6615   single_instruction;
 6616   dst    : WR(write);
 6617   src1   : ISS(read);
 6618   src2   : ISS(read);
 6619   src3   : ISS(read);
 6620   INS01  : ISS;
 6621   MAC    : WR;
 6622 %}
 6623 
 6624 // Eg.  MUL     w0, w1, w2
 6625 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6626 %{
 6627   single_instruction;
 6628   fixed_latency(3); // Maximum latency for 64 bit mul
 6629   dst    : WR(write);
 6630   src1   : ISS(read);
 6631   src2   : ISS(read);
 6632   INS01  : ISS;
 6633   MAC    : WR;
 6634 %}
 6635 
 6636 // Multiply accumulate
 6637 // Eg.  MADD    w0, w1, w2, w3
 6638 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6639 %{
 6640   single_instruction;
 6641   fixed_latency(3); // Maximum latency for 64 bit mul
 6642   dst    : WR(write);
 6643   src1   : ISS(read);
 6644   src2   : ISS(read);
 6645   src3   : ISS(read);
 6646   INS01  : ISS;
 6647   MAC    : WR;
 6648 %}
 6649 
 6650 //------- Divide pipeline operations --------------------
 6651 
 6652 // Eg.  SDIV    w0, w1, w2
 6653 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6654 %{
 6655   single_instruction;
 6656   fixed_latency(8); // Maximum latency for 32 bit divide
 6657   dst    : WR(write);
 6658   src1   : ISS(read);
 6659   src2   : ISS(read);
 6660   INS0   : ISS; // Can only dual issue as instruction 0
 6661   DIV    : WR;
 6662 %}
 6663 
 6664 // Eg.  SDIV    x0, x1, x2
 6665 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6666 %{
 6667   single_instruction;
 6668   fixed_latency(16); // Maximum latency for 64 bit divide
 6669   dst    : WR(write);
 6670   src1   : ISS(read);
 6671   src2   : ISS(read);
 6672   INS0   : ISS; // Can only dual issue as instruction 0
 6673   DIV    : WR;
 6674 %}
 6675 
 6676 //------- Load pipeline operations ------------------------
 6677 
 6678 // Load - prefetch
 6679 // Eg.  PFRM    &lt;mem&gt;
 6680 pipe_class iload_prefetch(memory mem)
 6681 %{
 6682   single_instruction;
 6683   mem    : ISS(read);
 6684   INS01  : ISS;
 6685   LDST   : WR;
 6686 %}
 6687 
 6688 // Load - reg, mem
 6689 // Eg.  LDR     x0, &lt;mem&gt;
 6690 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6691 %{
 6692   single_instruction;
 6693   dst    : WR(write);
 6694   mem    : ISS(read);
 6695   INS01  : ISS;
 6696   LDST   : WR;
 6697 %}
 6698 
 6699 // Load - reg, reg
 6700 // Eg.  LDR     x0, [sp, x1]
 6701 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6702 %{
 6703   single_instruction;
 6704   dst    : WR(write);
 6705   src    : ISS(read);
 6706   INS01  : ISS;
 6707   LDST   : WR;
 6708 %}
 6709 
 6710 //------- Store pipeline operations -----------------------
 6711 
 6712 // Store - zr, mem
 6713 // Eg.  STR     zr, &lt;mem&gt;
 6714 pipe_class istore_mem(memory mem)
 6715 %{
 6716   single_instruction;
 6717   mem    : ISS(read);
 6718   INS01  : ISS;
 6719   LDST   : WR;
 6720 %}
 6721 
 6722 // Store - reg, mem
 6723 // Eg.  STR     x0, &lt;mem&gt;
 6724 pipe_class istore_reg_mem(iRegI src, memory mem)
 6725 %{
 6726   single_instruction;
 6727   mem    : ISS(read);
 6728   src    : EX2(read);
 6729   INS01  : ISS;
 6730   LDST   : WR;
 6731 %}
 6732 
 6733 // Store - reg, reg
 6734 // Eg. STR      x0, [sp, x1]
 6735 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6736 %{
 6737   single_instruction;
 6738   dst    : ISS(read);
 6739   src    : EX2(read);
 6740   INS01  : ISS;
 6741   LDST   : WR;
 6742 %}
 6743 
 6744 //------- Store pipeline operations -----------------------
 6745 
 6746 // Branch
 6747 pipe_class pipe_branch()
 6748 %{
 6749   single_instruction;
 6750   INS01  : ISS;
 6751   BRANCH : EX1;
 6752 %}
 6753 
 6754 // Conditional branch
 6755 pipe_class pipe_branch_cond(rFlagsReg cr)
 6756 %{
 6757   single_instruction;
 6758   cr     : EX1(read);
 6759   INS01  : ISS;
 6760   BRANCH : EX1;
 6761 %}
 6762 
 6763 // Compare &amp; Branch
 6764 // EG.  CBZ/CBNZ
 6765 pipe_class pipe_cmp_branch(iRegI op1)
 6766 %{
 6767   single_instruction;
 6768   op1    : EX1(read);
 6769   INS01  : ISS;
 6770   BRANCH : EX1;
 6771 %}
 6772 
 6773 //------- Synchronisation operations ----------------------
 6774 
 6775 // Any operation requiring serialization.
 6776 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6777 pipe_class pipe_serial()
 6778 %{
 6779   single_instruction;
 6780   force_serialization;
 6781   fixed_latency(16);
 6782   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6783   LDST   : WR;
 6784 %}
 6785 
 6786 // Generic big/slow expanded idiom - also serialized
 6787 pipe_class pipe_slow()
 6788 %{
 6789   instruction_count(10);
 6790   multiple_bundles;
 6791   force_serialization;
 6792   fixed_latency(16);
 6793   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6794   LDST   : WR;
 6795 %}
 6796 
 6797 // Empty pipeline class
 6798 pipe_class pipe_class_empty()
 6799 %{
 6800   single_instruction;
 6801   fixed_latency(0);
 6802 %}
 6803 
 6804 // Default pipeline class.
 6805 pipe_class pipe_class_default()
 6806 %{
 6807   single_instruction;
 6808   fixed_latency(2);
 6809 %}
 6810 
 6811 // Pipeline class for compares.
 6812 pipe_class pipe_class_compare()
 6813 %{
 6814   single_instruction;
 6815   fixed_latency(16);
 6816 %}
 6817 
 6818 // Pipeline class for memory operations.
 6819 pipe_class pipe_class_memory()
 6820 %{
 6821   single_instruction;
 6822   fixed_latency(16);
 6823 %}
 6824 
 6825 // Pipeline class for call.
 6826 pipe_class pipe_class_call()
 6827 %{
 6828   single_instruction;
 6829   fixed_latency(100);
 6830 %}
 6831 
 6832 // Define the class for the Nop node.
 6833 define %{
 6834    MachNop = pipe_class_empty;
 6835 %}
 6836 
 6837 %}
 6838 //----------INSTRUCTIONS-------------------------------------------------------
 6839 //
 6840 // match      -- States which machine-independent subtree may be replaced
 6841 //               by this instruction.
 6842 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6843 //               selection to identify a minimum cost tree of machine
 6844 //               instructions that matches a tree of machine-independent
 6845 //               instructions.
 6846 // format     -- A string providing the disassembly for this instruction.
 6847 //               The value of an instruction&#39;s operand may be inserted
 6848 //               by referring to it with a &#39;$&#39; prefix.
 6849 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6850 //               to within an encode class as $primary, $secondary, and $tertiary
 6851 //               rrspectively.  The primary opcode is commonly used to
 6852 //               indicate the type of machine instruction, while secondary
 6853 //               and tertiary are often used for prefix options or addressing
 6854 //               modes.
 6855 // ins_encode -- A list of encode classes with parameters. The encode class
 6856 //               name must have been defined in an &#39;enc_class&#39; specification
 6857 //               in the encode section of the architecture description.
 6858 
 6859 // ============================================================================
 6860 // Memory (Load/Store) Instructions
 6861 
 6862 // Load Instructions
 6863 
 6864 // Load Byte (8 bit signed)
 6865 instruct loadB(iRegINoSp dst, memory1 mem)
 6866 %{
 6867   match(Set dst (LoadB mem));
 6868   predicate(!needs_acquiring_load(n));
 6869 
 6870   ins_cost(4 * INSN_COST);
 6871   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6872 
 6873   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6874 
 6875   ins_pipe(iload_reg_mem);
 6876 %}
 6877 
 6878 // Load Byte (8 bit signed) into long
 6879 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6880 %{
 6881   match(Set dst (ConvI2L (LoadB mem)));
 6882   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6883 
 6884   ins_cost(4 * INSN_COST);
 6885   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6886 
 6887   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6888 
 6889   ins_pipe(iload_reg_mem);
 6890 %}
 6891 
 6892 // Load Byte (8 bit unsigned)
 6893 instruct loadUB(iRegINoSp dst, memory1 mem)
 6894 %{
 6895   match(Set dst (LoadUB mem));
 6896   predicate(!needs_acquiring_load(n));
 6897 
 6898   ins_cost(4 * INSN_COST);
 6899   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6900 
 6901   ins_encode(aarch64_enc_ldrb(dst, mem));
 6902 
 6903   ins_pipe(iload_reg_mem);
 6904 %}
 6905 
 6906 // Load Byte (8 bit unsigned) into long
 6907 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6908 %{
 6909   match(Set dst (ConvI2L (LoadUB mem)));
 6910   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6911 
 6912   ins_cost(4 * INSN_COST);
 6913   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6914 
 6915   ins_encode(aarch64_enc_ldrb(dst, mem));
 6916 
 6917   ins_pipe(iload_reg_mem);
 6918 %}
 6919 
 6920 // Load Short (16 bit signed)
 6921 instruct loadS(iRegINoSp dst, memory2 mem)
 6922 %{
 6923   match(Set dst (LoadS mem));
 6924   predicate(!needs_acquiring_load(n));
 6925 
 6926   ins_cost(4 * INSN_COST);
 6927   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6928 
 6929   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6930 
 6931   ins_pipe(iload_reg_mem);
 6932 %}
 6933 
 6934 // Load Short (16 bit signed) into long
 6935 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6936 %{
 6937   match(Set dst (ConvI2L (LoadS mem)));
 6938   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6939 
 6940   ins_cost(4 * INSN_COST);
 6941   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6942 
 6943   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6944 
 6945   ins_pipe(iload_reg_mem);
 6946 %}
 6947 
 6948 // Load Char (16 bit unsigned)
 6949 instruct loadUS(iRegINoSp dst, memory2 mem)
 6950 %{
 6951   match(Set dst (LoadUS mem));
 6952   predicate(!needs_acquiring_load(n));
 6953 
 6954   ins_cost(4 * INSN_COST);
 6955   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6956 
 6957   ins_encode(aarch64_enc_ldrh(dst, mem));
 6958 
 6959   ins_pipe(iload_reg_mem);
 6960 %}
 6961 
 6962 // Load Short/Char (16 bit unsigned) into long
 6963 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6964 %{
 6965   match(Set dst (ConvI2L (LoadUS mem)));
 6966   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6967 
 6968   ins_cost(4 * INSN_COST);
 6969   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6970 
 6971   ins_encode(aarch64_enc_ldrh(dst, mem));
 6972 
 6973   ins_pipe(iload_reg_mem);
 6974 %}
 6975 
 6976 // Load Integer (32 bit signed)
 6977 instruct loadI(iRegINoSp dst, memory4 mem)
 6978 %{
 6979   match(Set dst (LoadI mem));
 6980   predicate(!needs_acquiring_load(n));
 6981 
 6982   ins_cost(4 * INSN_COST);
 6983   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6984 
 6985   ins_encode(aarch64_enc_ldrw(dst, mem));
 6986 
 6987   ins_pipe(iload_reg_mem);
 6988 %}
 6989 
 6990 // Load Integer (32 bit signed) into long
 6991 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6992 %{
 6993   match(Set dst (ConvI2L (LoadI mem)));
 6994   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6995 
 6996   ins_cost(4 * INSN_COST);
 6997   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6998 
 6999   ins_encode(aarch64_enc_ldrsw(dst, mem));
 7000 
 7001   ins_pipe(iload_reg_mem);
 7002 %}
 7003 
 7004 // Load Integer (32 bit unsigned) into long
 7005 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 7006 %{
 7007   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7008   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 7009 
 7010   ins_cost(4 * INSN_COST);
 7011   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7012 
 7013   ins_encode(aarch64_enc_ldrw(dst, mem));
 7014 
 7015   ins_pipe(iload_reg_mem);
 7016 %}
 7017 
 7018 // Load Long (64 bit signed)
 7019 instruct loadL(iRegLNoSp dst, memory8 mem)
 7020 %{
 7021   match(Set dst (LoadL mem));
 7022   predicate(!needs_acquiring_load(n));
 7023 
 7024   ins_cost(4 * INSN_COST);
 7025   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7026 
 7027   ins_encode(aarch64_enc_ldr(dst, mem));
 7028 
 7029   ins_pipe(iload_reg_mem);
 7030 %}
 7031 
 7032 // Load Range
 7033 instruct loadRange(iRegINoSp dst, memory4 mem)
 7034 %{
 7035   match(Set dst (LoadRange mem));
 7036 
 7037   ins_cost(4 * INSN_COST);
 7038   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7039 
 7040   ins_encode(aarch64_enc_ldrw(dst, mem));
 7041 
 7042   ins_pipe(iload_reg_mem);
 7043 %}
 7044 
 7045 // Load Pointer
 7046 instruct loadP(iRegPNoSp dst, memory8 mem)
 7047 %{
 7048   match(Set dst (LoadP mem));
 7049   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7050 
 7051   ins_cost(4 * INSN_COST);
 7052   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7053 
 7054   ins_encode(aarch64_enc_ldr(dst, mem));
 7055 
 7056   ins_pipe(iload_reg_mem);
 7057 %}
 7058 
 7059 // Load Compressed Pointer
 7060 instruct loadN(iRegNNoSp dst, memory4 mem)
 7061 %{
 7062   match(Set dst (LoadN mem));
 7063   predicate(!needs_acquiring_load(n));
 7064 
 7065   ins_cost(4 * INSN_COST);
 7066   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7067 
 7068   ins_encode(aarch64_enc_ldrw(dst, mem));
 7069 
 7070   ins_pipe(iload_reg_mem);
 7071 %}
 7072 
 7073 // Load Klass Pointer
 7074 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7075 %{
 7076   match(Set dst (LoadKlass mem));
 7077   predicate(!needs_acquiring_load(n));
 7078 
 7079   ins_cost(4 * INSN_COST);
 7080   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7081 
 7082   ins_encode(aarch64_enc_ldr(dst, mem));
 7083 
 7084   ins_pipe(iload_reg_mem);
 7085 %}
 7086 
 7087 // Load Narrow Klass Pointer
 7088 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7089 %{
 7090   match(Set dst (LoadNKlass mem));
 7091   predicate(!needs_acquiring_load(n));
 7092 
 7093   ins_cost(4 * INSN_COST);
 7094   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7095 
 7096   ins_encode(aarch64_enc_ldrw(dst, mem));
 7097 
 7098   ins_pipe(iload_reg_mem);
 7099 %}
 7100 
 7101 // Load Float
 7102 instruct loadF(vRegF dst, memory4 mem)
 7103 %{
 7104   match(Set dst (LoadF mem));
 7105   predicate(!needs_acquiring_load(n));
 7106 
 7107   ins_cost(4 * INSN_COST);
 7108   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7109 
 7110   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7111 
 7112   ins_pipe(pipe_class_memory);
 7113 %}
 7114 
 7115 // Load Double
 7116 instruct loadD(vRegD dst, memory8 mem)
 7117 %{
 7118   match(Set dst (LoadD mem));
 7119   predicate(!needs_acquiring_load(n));
 7120 
 7121   ins_cost(4 * INSN_COST);
 7122   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7123 
 7124   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7125 
 7126   ins_pipe(pipe_class_memory);
 7127 %}
 7128 
 7129 
 7130 // Load Int Constant
 7131 instruct loadConI(iRegINoSp dst, immI src)
 7132 %{
 7133   match(Set dst src);
 7134 
 7135   ins_cost(INSN_COST);
 7136   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7137 
 7138   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7139 
 7140   ins_pipe(ialu_imm);
 7141 %}
 7142 
 7143 // Load Long Constant
 7144 instruct loadConL(iRegLNoSp dst, immL src)
 7145 %{
 7146   match(Set dst src);
 7147 
 7148   ins_cost(INSN_COST);
 7149   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7150 
 7151   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7152 
 7153   ins_pipe(ialu_imm);
 7154 %}
 7155 
 7156 // Load Pointer Constant
 7157 
 7158 instruct loadConP(iRegPNoSp dst, immP con)
 7159 %{
 7160   match(Set dst con);
 7161 
 7162   ins_cost(INSN_COST * 4);
 7163   format %{
 7164     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7165   %}
 7166 
 7167   ins_encode(aarch64_enc_mov_p(dst, con));
 7168 
 7169   ins_pipe(ialu_imm);
 7170 %}
 7171 
 7172 // Load Null Pointer Constant
 7173 
 7174 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7175 %{
 7176   match(Set dst con);
 7177 
 7178   ins_cost(INSN_COST);
 7179   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7180 
 7181   ins_encode(aarch64_enc_mov_p0(dst, con));
 7182 
 7183   ins_pipe(ialu_imm);
 7184 %}
 7185 
 7186 // Load Pointer Constant One
 7187 
 7188 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7189 %{
 7190   match(Set dst con);
 7191 
 7192   ins_cost(INSN_COST);
 7193   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7194 
 7195   ins_encode(aarch64_enc_mov_p1(dst, con));
 7196 
 7197   ins_pipe(ialu_imm);
 7198 %}
 7199 
 7200 // Load Byte Map Base Constant
 7201 
 7202 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7203 %{
 7204   match(Set dst con);
 7205 
 7206   ins_cost(INSN_COST);
 7207   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7208 
 7209   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7210 
 7211   ins_pipe(ialu_imm);
 7212 %}
 7213 
 7214 // Load Narrow Pointer Constant
 7215 
 7216 instruct loadConN(iRegNNoSp dst, immN con)
 7217 %{
 7218   match(Set dst con);
 7219 
 7220   ins_cost(INSN_COST * 4);
 7221   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7222 
 7223   ins_encode(aarch64_enc_mov_n(dst, con));
 7224 
 7225   ins_pipe(ialu_imm);
 7226 %}
 7227 
 7228 // Load Narrow Null Pointer Constant
 7229 
 7230 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7231 %{
 7232   match(Set dst con);
 7233 
 7234   ins_cost(INSN_COST);
 7235   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7236 
 7237   ins_encode(aarch64_enc_mov_n0(dst, con));
 7238 
 7239   ins_pipe(ialu_imm);
 7240 %}
 7241 
 7242 // Load Narrow Klass Constant
 7243 
 7244 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7245 %{
 7246   match(Set dst con);
 7247 
 7248   ins_cost(INSN_COST);
 7249   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7250 
 7251   ins_encode(aarch64_enc_mov_nk(dst, con));
 7252 
 7253   ins_pipe(ialu_imm);
 7254 %}
 7255 
 7256 // Load Packed Float Constant
 7257 
 7258 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7259   match(Set dst con);
 7260   ins_cost(INSN_COST * 4);
 7261   format %{ &quot;fmovs  $dst, $con&quot;%}
 7262   ins_encode %{
 7263     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7264   %}
 7265 
 7266   ins_pipe(fp_imm_s);
 7267 %}
 7268 
 7269 // Load Float Constant
 7270 
 7271 instruct loadConF(vRegF dst, immF con) %{
 7272   match(Set dst con);
 7273 
 7274   ins_cost(INSN_COST * 4);
 7275 
 7276   format %{
 7277     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7278   %}
 7279 
 7280   ins_encode %{
 7281     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7282   %}
 7283 
 7284   ins_pipe(fp_load_constant_s);
 7285 %}
 7286 
 7287 // Load Packed Double Constant
 7288 
 7289 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7290   match(Set dst con);
 7291   ins_cost(INSN_COST);
 7292   format %{ &quot;fmovd  $dst, $con&quot;%}
 7293   ins_encode %{
 7294     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7295   %}
 7296 
 7297   ins_pipe(fp_imm_d);
 7298 %}
 7299 
 7300 // Load Double Constant
 7301 
 7302 instruct loadConD(vRegD dst, immD con) %{
 7303   match(Set dst con);
 7304 
 7305   ins_cost(INSN_COST * 5);
 7306   format %{
 7307     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7308   %}
 7309 
 7310   ins_encode %{
 7311     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7312   %}
 7313 
 7314   ins_pipe(fp_load_constant_d);
 7315 %}
 7316 
 7317 // Store Instructions
 7318 
 7319 // Store CMS card-mark Immediate
 7320 instruct storeimmCM0(immI0 zero, memory1 mem)
 7321 %{
 7322   match(Set mem (StoreCM mem zero));
 7323 
 7324   ins_cost(INSN_COST);
 7325   format %{ &quot;storestore (elided)\n\t&quot;
 7326             &quot;strb zr, $mem\t# byte&quot; %}
 7327 
 7328   ins_encode(aarch64_enc_strb0(mem));
 7329 
 7330   ins_pipe(istore_mem);
 7331 %}
 7332 
 7333 // Store CMS card-mark Immediate with intervening StoreStore
 7334 // needed when using CMS with no conditional card marking
 7335 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7336 %{
 7337   match(Set mem (StoreCM mem zero));
 7338 
 7339   ins_cost(INSN_COST * 2);
 7340   format %{ &quot;storestore\n\t&quot;
 7341             &quot;dmb ishst&quot;
 7342             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7343 
 7344   ins_encode(aarch64_enc_strb0_ordered(mem));
 7345 
 7346   ins_pipe(istore_mem);
 7347 %}
 7348 
 7349 // Store Byte
 7350 instruct storeB(iRegIorL2I src, memory1 mem)
 7351 %{
 7352   match(Set mem (StoreB mem src));
 7353   predicate(!needs_releasing_store(n));
 7354 
 7355   ins_cost(INSN_COST);
 7356   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7357 
 7358   ins_encode(aarch64_enc_strb(src, mem));
 7359 
 7360   ins_pipe(istore_reg_mem);
 7361 %}
 7362 
 7363 
 7364 instruct storeimmB0(immI0 zero, memory1 mem)
 7365 %{
 7366   match(Set mem (StoreB mem zero));
 7367   predicate(!needs_releasing_store(n));
 7368 
 7369   ins_cost(INSN_COST);
 7370   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7371 
 7372   ins_encode(aarch64_enc_strb0(mem));
 7373 
 7374   ins_pipe(istore_mem);
 7375 %}
 7376 
 7377 // Store Char/Short
 7378 instruct storeC(iRegIorL2I src, memory2 mem)
 7379 %{
 7380   match(Set mem (StoreC mem src));
 7381   predicate(!needs_releasing_store(n));
 7382 
 7383   ins_cost(INSN_COST);
 7384   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7385 
 7386   ins_encode(aarch64_enc_strh(src, mem));
 7387 
 7388   ins_pipe(istore_reg_mem);
 7389 %}
 7390 
 7391 instruct storeimmC0(immI0 zero, memory2 mem)
 7392 %{
 7393   match(Set mem (StoreC mem zero));
 7394   predicate(!needs_releasing_store(n));
 7395 
 7396   ins_cost(INSN_COST);
 7397   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7398 
 7399   ins_encode(aarch64_enc_strh0(mem));
 7400 
 7401   ins_pipe(istore_mem);
 7402 %}
 7403 
 7404 // Store Integer
 7405 
 7406 instruct storeI(iRegIorL2I src, memory4 mem)
 7407 %{
 7408   match(Set mem(StoreI mem src));
 7409   predicate(!needs_releasing_store(n));
 7410 
 7411   ins_cost(INSN_COST);
 7412   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7413 
 7414   ins_encode(aarch64_enc_strw(src, mem));
 7415 
 7416   ins_pipe(istore_reg_mem);
 7417 %}
 7418 
 7419 instruct storeimmI0(immI0 zero, memory4 mem)
 7420 %{
 7421   match(Set mem(StoreI mem zero));
 7422   predicate(!needs_releasing_store(n));
 7423 
 7424   ins_cost(INSN_COST);
 7425   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7426 
 7427   ins_encode(aarch64_enc_strw0(mem));
 7428 
 7429   ins_pipe(istore_mem);
 7430 %}
 7431 
 7432 // Store Long (64 bit signed)
 7433 instruct storeL(iRegL src, memory8 mem)
 7434 %{
 7435   match(Set mem (StoreL mem src));
 7436   predicate(!needs_releasing_store(n));
 7437 
 7438   ins_cost(INSN_COST);
 7439   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7440 
 7441   ins_encode(aarch64_enc_str(src, mem));
 7442 
 7443   ins_pipe(istore_reg_mem);
 7444 %}
 7445 
 7446 // Store Long (64 bit signed)
 7447 instruct storeimmL0(immL0 zero, memory8 mem)
 7448 %{
 7449   match(Set mem (StoreL mem zero));
 7450   predicate(!needs_releasing_store(n));
 7451 
 7452   ins_cost(INSN_COST);
 7453   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7454 
 7455   ins_encode(aarch64_enc_str0(mem));
 7456 
 7457   ins_pipe(istore_mem);
 7458 %}
 7459 
 7460 // Store Pointer
 7461 instruct storeP(iRegP src, memory8 mem)
 7462 %{
 7463   match(Set mem (StoreP mem src));
 7464   predicate(!needs_releasing_store(n));
 7465 
 7466   ins_cost(INSN_COST);
 7467   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7468 
 7469   ins_encode(aarch64_enc_str(src, mem));
 7470 
 7471   ins_pipe(istore_reg_mem);
 7472 %}
 7473 
 7474 // Store Pointer
 7475 instruct storeimmP0(immP0 zero, memory8 mem)
 7476 %{
 7477   match(Set mem (StoreP mem zero));
 7478   predicate(!needs_releasing_store(n));
 7479 
 7480   ins_cost(INSN_COST);
 7481   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7482 
 7483   ins_encode(aarch64_enc_str0(mem));
 7484 
 7485   ins_pipe(istore_mem);
 7486 %}
 7487 
 7488 // Store Compressed Pointer
 7489 instruct storeN(iRegN src, memory4 mem)
 7490 %{
 7491   match(Set mem (StoreN mem src));
 7492   predicate(!needs_releasing_store(n));
 7493 
 7494   ins_cost(INSN_COST);
 7495   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7496 
 7497   ins_encode(aarch64_enc_strw(src, mem));
 7498 
 7499   ins_pipe(istore_reg_mem);
 7500 %}
 7501 
 7502 instruct storeImmN0(iRegIHeapbase heapbase, immN0 zero, memory4 mem)
 7503 %{
 7504   match(Set mem (StoreN mem zero));
 7505   predicate(CompressedOops::base() == NULL &amp;&amp;
 7506             CompressedKlassPointers::base() == NULL &amp;&amp;
 7507             (!needs_releasing_store(n)));
 7508 
 7509   ins_cost(INSN_COST);
 7510   format %{ &quot;strw  rheapbase, $mem\t# compressed ptr (rheapbase==0)&quot; %}
 7511 
 7512   ins_encode(aarch64_enc_strw(heapbase, mem));
 7513 
 7514   ins_pipe(istore_reg_mem);
 7515 %}
 7516 
 7517 // Store Float
 7518 instruct storeF(vRegF src, memory4 mem)
 7519 %{
 7520   match(Set mem (StoreF mem src));
 7521   predicate(!needs_releasing_store(n));
 7522 
 7523   ins_cost(INSN_COST);
 7524   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7525 
 7526   ins_encode( aarch64_enc_strs(src, mem) );
 7527 
 7528   ins_pipe(pipe_class_memory);
 7529 %}
 7530 
 7531 // TODO
 7532 // implement storeImmF0 and storeFImmPacked
 7533 
 7534 // Store Double
 7535 instruct storeD(vRegD src, memory8 mem)
 7536 %{
 7537   match(Set mem (StoreD mem src));
 7538   predicate(!needs_releasing_store(n));
 7539 
 7540   ins_cost(INSN_COST);
 7541   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7542 
 7543   ins_encode( aarch64_enc_strd(src, mem) );
 7544 
 7545   ins_pipe(pipe_class_memory);
 7546 %}
 7547 
 7548 // Store Compressed Klass Pointer
 7549 instruct storeNKlass(iRegN src, memory4 mem)
 7550 %{
 7551   predicate(!needs_releasing_store(n));
 7552   match(Set mem (StoreNKlass mem src));
 7553 
 7554   ins_cost(INSN_COST);
 7555   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7556 
 7557   ins_encode(aarch64_enc_strw(src, mem));
 7558 
 7559   ins_pipe(istore_reg_mem);
 7560 %}
 7561 
 7562 // TODO
 7563 // implement storeImmD0 and storeDImmPacked
 7564 
 7565 // prefetch instructions
 7566 // Must be safe to execute with invalid address (cannot fault).
 7567 
 7568 instruct prefetchalloc( memory8 mem ) %{
 7569   match(PrefetchAllocation mem);
 7570 
 7571   ins_cost(INSN_COST);
 7572   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7573 
 7574   ins_encode( aarch64_enc_prefetchw(mem) );
 7575 
 7576   ins_pipe(iload_prefetch);
 7577 %}
 7578 
 7579 //  ---------------- volatile loads and stores ----------------
 7580 
 7581 // Load Byte (8 bit signed)
 7582 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7583 %{
 7584   match(Set dst (LoadB mem));
 7585 
 7586   ins_cost(VOLATILE_REF_COST);
 7587   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7588 
 7589   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7590 
 7591   ins_pipe(pipe_serial);
 7592 %}
 7593 
 7594 // Load Byte (8 bit signed) into long
 7595 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7596 %{
 7597   match(Set dst (ConvI2L (LoadB mem)));
 7598 
 7599   ins_cost(VOLATILE_REF_COST);
 7600   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7601 
 7602   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7603 
 7604   ins_pipe(pipe_serial);
 7605 %}
 7606 
 7607 // Load Byte (8 bit unsigned)
 7608 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7609 %{
 7610   match(Set dst (LoadUB mem));
 7611 
 7612   ins_cost(VOLATILE_REF_COST);
 7613   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7614 
 7615   ins_encode(aarch64_enc_ldarb(dst, mem));
 7616 
 7617   ins_pipe(pipe_serial);
 7618 %}
 7619 
 7620 // Load Byte (8 bit unsigned) into long
 7621 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7622 %{
 7623   match(Set dst (ConvI2L (LoadUB mem)));
 7624 
 7625   ins_cost(VOLATILE_REF_COST);
 7626   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7627 
 7628   ins_encode(aarch64_enc_ldarb(dst, mem));
 7629 
 7630   ins_pipe(pipe_serial);
 7631 %}
 7632 
 7633 // Load Short (16 bit signed)
 7634 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7635 %{
 7636   match(Set dst (LoadS mem));
 7637 
 7638   ins_cost(VOLATILE_REF_COST);
 7639   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7640 
 7641   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7642 
 7643   ins_pipe(pipe_serial);
 7644 %}
 7645 
 7646 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7647 %{
 7648   match(Set dst (LoadUS mem));
 7649 
 7650   ins_cost(VOLATILE_REF_COST);
 7651   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7652 
 7653   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7654 
 7655   ins_pipe(pipe_serial);
 7656 %}
 7657 
 7658 // Load Short/Char (16 bit unsigned) into long
 7659 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7660 %{
 7661   match(Set dst (ConvI2L (LoadUS mem)));
 7662 
 7663   ins_cost(VOLATILE_REF_COST);
 7664   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7665 
 7666   ins_encode(aarch64_enc_ldarh(dst, mem));
 7667 
 7668   ins_pipe(pipe_serial);
 7669 %}
 7670 
 7671 // Load Short/Char (16 bit signed) into long
 7672 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7673 %{
 7674   match(Set dst (ConvI2L (LoadS mem)));
 7675 
 7676   ins_cost(VOLATILE_REF_COST);
 7677   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7678 
 7679   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7680 
 7681   ins_pipe(pipe_serial);
 7682 %}
 7683 
 7684 // Load Integer (32 bit signed)
 7685 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7686 %{
 7687   match(Set dst (LoadI mem));
 7688 
 7689   ins_cost(VOLATILE_REF_COST);
 7690   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7691 
 7692   ins_encode(aarch64_enc_ldarw(dst, mem));
 7693 
 7694   ins_pipe(pipe_serial);
 7695 %}
 7696 
 7697 // Load Integer (32 bit unsigned) into long
 7698 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7699 %{
 7700   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7701 
 7702   ins_cost(VOLATILE_REF_COST);
 7703   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7704 
 7705   ins_encode(aarch64_enc_ldarw(dst, mem));
 7706 
 7707   ins_pipe(pipe_serial);
 7708 %}
 7709 
 7710 // Load Long (64 bit signed)
 7711 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7712 %{
 7713   match(Set dst (LoadL mem));
 7714 
 7715   ins_cost(VOLATILE_REF_COST);
 7716   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7717 
 7718   ins_encode(aarch64_enc_ldar(dst, mem));
 7719 
 7720   ins_pipe(pipe_serial);
 7721 %}
 7722 
 7723 // Load Pointer
 7724 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7725 %{
 7726   match(Set dst (LoadP mem));
 7727   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7728 
 7729   ins_cost(VOLATILE_REF_COST);
 7730   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7731 
 7732   ins_encode(aarch64_enc_ldar(dst, mem));
 7733 
 7734   ins_pipe(pipe_serial);
 7735 %}
 7736 
 7737 // Load Compressed Pointer
 7738 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7739 %{
 7740   match(Set dst (LoadN mem));
 7741 
 7742   ins_cost(VOLATILE_REF_COST);
 7743   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7744 
 7745   ins_encode(aarch64_enc_ldarw(dst, mem));
 7746 
 7747   ins_pipe(pipe_serial);
 7748 %}
 7749 
 7750 // Load Float
 7751 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7752 %{
 7753   match(Set dst (LoadF mem));
 7754 
 7755   ins_cost(VOLATILE_REF_COST);
 7756   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7757 
 7758   ins_encode( aarch64_enc_fldars(dst, mem) );
 7759 
 7760   ins_pipe(pipe_serial);
 7761 %}
 7762 
 7763 // Load Double
 7764 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7765 %{
 7766   match(Set dst (LoadD mem));
 7767 
 7768   ins_cost(VOLATILE_REF_COST);
 7769   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7770 
 7771   ins_encode( aarch64_enc_fldard(dst, mem) );
 7772 
 7773   ins_pipe(pipe_serial);
 7774 %}
 7775 
 7776 // Store Byte
 7777 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7778 %{
 7779   match(Set mem (StoreB mem src));
 7780 
 7781   ins_cost(VOLATILE_REF_COST);
 7782   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7783 
 7784   ins_encode(aarch64_enc_stlrb(src, mem));
 7785 
 7786   ins_pipe(pipe_class_memory);
 7787 %}
 7788 
 7789 // Store Char/Short
 7790 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7791 %{
 7792   match(Set mem (StoreC mem src));
 7793 
 7794   ins_cost(VOLATILE_REF_COST);
 7795   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7796 
 7797   ins_encode(aarch64_enc_stlrh(src, mem));
 7798 
 7799   ins_pipe(pipe_class_memory);
 7800 %}
 7801 
 7802 // Store Integer
 7803 
 7804 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7805 %{
 7806   match(Set mem(StoreI mem src));
 7807 
 7808   ins_cost(VOLATILE_REF_COST);
 7809   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7810 
 7811   ins_encode(aarch64_enc_stlrw(src, mem));
 7812 
 7813   ins_pipe(pipe_class_memory);
 7814 %}
 7815 
 7816 // Store Long (64 bit signed)
 7817 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7818 %{
 7819   match(Set mem (StoreL mem src));
 7820 
 7821   ins_cost(VOLATILE_REF_COST);
 7822   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7823 
 7824   ins_encode(aarch64_enc_stlr(src, mem));
 7825 
 7826   ins_pipe(pipe_class_memory);
 7827 %}
 7828 
 7829 // Store Pointer
 7830 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7831 %{
 7832   match(Set mem (StoreP mem src));
 7833 
 7834   ins_cost(VOLATILE_REF_COST);
 7835   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7836 
 7837   ins_encode(aarch64_enc_stlr(src, mem));
 7838 
 7839   ins_pipe(pipe_class_memory);
 7840 %}
 7841 
 7842 // Store Compressed Pointer
 7843 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7844 %{
 7845   match(Set mem (StoreN mem src));
 7846 
 7847   ins_cost(VOLATILE_REF_COST);
 7848   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7849 
 7850   ins_encode(aarch64_enc_stlrw(src, mem));
 7851 
 7852   ins_pipe(pipe_class_memory);
 7853 %}
 7854 
 7855 // Store Float
 7856 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7857 %{
 7858   match(Set mem (StoreF mem src));
 7859 
 7860   ins_cost(VOLATILE_REF_COST);
 7861   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7862 
 7863   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7864 
 7865   ins_pipe(pipe_class_memory);
 7866 %}
 7867 
 7868 // TODO
 7869 // implement storeImmF0 and storeFImmPacked
 7870 
 7871 // Store Double
 7872 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7873 %{
 7874   match(Set mem (StoreD mem src));
 7875 
 7876   ins_cost(VOLATILE_REF_COST);
 7877   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7878 
 7879   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7880 
 7881   ins_pipe(pipe_class_memory);
 7882 %}
 7883 
 7884 //  ---------------- end of volatile loads and stores ----------------
 7885 
 7886 instruct cacheWB(indirect addr)
 7887 %{
 7888   predicate(VM_Version::supports_data_cache_line_flush());
 7889   match(CacheWB addr);
 7890 
 7891   ins_cost(100);
 7892   format %{&quot;cache wb $addr&quot; %}
 7893   ins_encode %{
 7894     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7895     assert($addr$$disp == 0, &quot;should be&quot;);
 7896     __ cache_wb(Address($addr$$base$$Register, 0));
 7897   %}
 7898   ins_pipe(pipe_slow); // XXX
 7899 %}
 7900 
 7901 instruct cacheWBPreSync()
 7902 %{
 7903   predicate(VM_Version::supports_data_cache_line_flush());
 7904   match(CacheWBPreSync);
 7905 
 7906   ins_cost(100);
 7907   format %{&quot;cache wb presync&quot; %}
 7908   ins_encode %{
 7909     __ cache_wbsync(true);
 7910   %}
 7911   ins_pipe(pipe_slow); // XXX
 7912 %}
 7913 
 7914 instruct cacheWBPostSync()
 7915 %{
 7916   predicate(VM_Version::supports_data_cache_line_flush());
 7917   match(CacheWBPostSync);
 7918 
 7919   ins_cost(100);
 7920   format %{&quot;cache wb postsync&quot; %}
 7921   ins_encode %{
 7922     __ cache_wbsync(false);
 7923   %}
 7924   ins_pipe(pipe_slow); // XXX
 7925 %}
 7926 
 7927 // ============================================================================
 7928 // BSWAP Instructions
 7929 
 7930 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7931   match(Set dst (ReverseBytesI src));
 7932 
 7933   ins_cost(INSN_COST);
 7934   format %{ &quot;revw  $dst, $src&quot; %}
 7935 
 7936   ins_encode %{
 7937     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7938   %}
 7939 
 7940   ins_pipe(ialu_reg);
 7941 %}
 7942 
 7943 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7944   match(Set dst (ReverseBytesL src));
 7945 
 7946   ins_cost(INSN_COST);
 7947   format %{ &quot;rev  $dst, $src&quot; %}
 7948 
 7949   ins_encode %{
 7950     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7951   %}
 7952 
 7953   ins_pipe(ialu_reg);
 7954 %}
 7955 
 7956 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7957   match(Set dst (ReverseBytesUS src));
 7958 
 7959   ins_cost(INSN_COST);
 7960   format %{ &quot;rev16w  $dst, $src&quot; %}
 7961 
 7962   ins_encode %{
 7963     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7964   %}
 7965 
 7966   ins_pipe(ialu_reg);
 7967 %}
 7968 
 7969 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7970   match(Set dst (ReverseBytesS src));
 7971 
 7972   ins_cost(INSN_COST);
 7973   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7974             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7975 
 7976   ins_encode %{
 7977     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7978     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7979   %}
 7980 
 7981   ins_pipe(ialu_reg);
 7982 %}
 7983 
 7984 // ============================================================================
 7985 // Zero Count Instructions
 7986 
 7987 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7988   match(Set dst (CountLeadingZerosI src));
 7989 
 7990   ins_cost(INSN_COST);
 7991   format %{ &quot;clzw  $dst, $src&quot; %}
 7992   ins_encode %{
 7993     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7994   %}
 7995 
 7996   ins_pipe(ialu_reg);
 7997 %}
 7998 
 7999 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 8000   match(Set dst (CountLeadingZerosL src));
 8001 
 8002   ins_cost(INSN_COST);
 8003   format %{ &quot;clz   $dst, $src&quot; %}
 8004   ins_encode %{
 8005     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 8006   %}
 8007 
 8008   ins_pipe(ialu_reg);
 8009 %}
 8010 
 8011 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8012   match(Set dst (CountTrailingZerosI src));
 8013 
 8014   ins_cost(INSN_COST * 2);
 8015   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8016             &quot;clzw   $dst, $dst&quot; %}
 8017   ins_encode %{
 8018     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8019     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8020   %}
 8021 
 8022   ins_pipe(ialu_reg);
 8023 %}
 8024 
 8025 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8026   match(Set dst (CountTrailingZerosL src));
 8027 
 8028   ins_cost(INSN_COST * 2);
 8029   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8030             &quot;clz    $dst, $dst&quot; %}
 8031   ins_encode %{
 8032     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8033     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8034   %}
 8035 
 8036   ins_pipe(ialu_reg);
 8037 %}
 8038 
 8039 //---------- Population Count Instructions -------------------------------------
 8040 //
 8041 
 8042 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8043   predicate(UsePopCountInstruction);
 8044   match(Set dst (PopCountI src));
 8045   effect(TEMP tmp);
 8046   ins_cost(INSN_COST * 13);
 8047 
 8048   format %{ &quot;movw   $src, $src\n\t&quot;
 8049             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8050             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8051             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8052             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8053   ins_encode %{
 8054     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8055     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8056     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8057     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8058     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8059   %}
 8060 
 8061   ins_pipe(pipe_class_default);
 8062 %}
 8063 
 8064 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8065   predicate(UsePopCountInstruction);
 8066   match(Set dst (PopCountI (LoadI mem)));
 8067   effect(TEMP tmp);
 8068   ins_cost(INSN_COST * 13);
 8069 
 8070   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8071             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8072             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8073             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8074   ins_encode %{
 8075     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8076     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8077               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8078     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8079     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8080     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8081   %}
 8082 
 8083   ins_pipe(pipe_class_default);
 8084 %}
 8085 
 8086 // Note: Long.bitCount(long) returns an int.
 8087 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8088   predicate(UsePopCountInstruction);
 8089   match(Set dst (PopCountL src));
 8090   effect(TEMP tmp);
 8091   ins_cost(INSN_COST * 13);
 8092 
 8093   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8094             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8095             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8096             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8097   ins_encode %{
 8098     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8099     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8100     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8101     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8102   %}
 8103 
 8104   ins_pipe(pipe_class_default);
 8105 %}
 8106 
 8107 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8108   predicate(UsePopCountInstruction);
 8109   match(Set dst (PopCountL (LoadL mem)));
 8110   effect(TEMP tmp);
 8111   ins_cost(INSN_COST * 13);
 8112 
 8113   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8114             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8115             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8116             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8117   ins_encode %{
 8118     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8119     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8120               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8121     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8122     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8123     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8124   %}
 8125 
 8126   ins_pipe(pipe_class_default);
 8127 %}
 8128 
 8129 // ============================================================================
 8130 // MemBar Instruction
 8131 
 8132 instruct load_fence() %{
 8133   match(LoadFence);
 8134   ins_cost(VOLATILE_REF_COST);
 8135 
 8136   format %{ &quot;load_fence&quot; %}
 8137 
 8138   ins_encode %{
 8139     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8140   %}
 8141   ins_pipe(pipe_serial);
 8142 %}
 8143 
 8144 instruct unnecessary_membar_acquire() %{
 8145   predicate(unnecessary_acquire(n));
 8146   match(MemBarAcquire);
 8147   ins_cost(0);
 8148 
 8149   format %{ &quot;membar_acquire (elided)&quot; %}
 8150 
 8151   ins_encode %{
 8152     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8153   %}
 8154 
 8155   ins_pipe(pipe_class_empty);
 8156 %}
 8157 
 8158 instruct membar_acquire() %{
 8159   match(MemBarAcquire);
 8160   ins_cost(VOLATILE_REF_COST);
 8161 
 8162   format %{ &quot;membar_acquire\n\t&quot;
 8163             &quot;dmb ish&quot; %}
 8164 
 8165   ins_encode %{
 8166     __ block_comment(&quot;membar_acquire&quot;);
 8167     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8168   %}
 8169 
 8170   ins_pipe(pipe_serial);
 8171 %}
 8172 
 8173 
 8174 instruct membar_acquire_lock() %{
 8175   match(MemBarAcquireLock);
 8176   ins_cost(VOLATILE_REF_COST);
 8177 
 8178   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8179 
 8180   ins_encode %{
 8181     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8182   %}
 8183 
 8184   ins_pipe(pipe_serial);
 8185 %}
 8186 
 8187 instruct store_fence() %{
 8188   match(StoreFence);
 8189   ins_cost(VOLATILE_REF_COST);
 8190 
 8191   format %{ &quot;store_fence&quot; %}
 8192 
 8193   ins_encode %{
 8194     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8195   %}
 8196   ins_pipe(pipe_serial);
 8197 %}
 8198 
 8199 instruct unnecessary_membar_release() %{
 8200   predicate(unnecessary_release(n));
 8201   match(MemBarRelease);
 8202   ins_cost(0);
 8203 
 8204   format %{ &quot;membar_release (elided)&quot; %}
 8205 
 8206   ins_encode %{
 8207     __ block_comment(&quot;membar_release (elided)&quot;);
 8208   %}
 8209   ins_pipe(pipe_serial);
 8210 %}
 8211 
 8212 instruct membar_release() %{
 8213   match(MemBarRelease);
 8214   ins_cost(VOLATILE_REF_COST);
 8215 
 8216   format %{ &quot;membar_release\n\t&quot;
 8217             &quot;dmb ish&quot; %}
 8218 
 8219   ins_encode %{
 8220     __ block_comment(&quot;membar_release&quot;);
 8221     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8222   %}
 8223   ins_pipe(pipe_serial);
 8224 %}
 8225 
 8226 instruct membar_storestore() %{
 8227   match(MemBarStoreStore);
 8228   ins_cost(VOLATILE_REF_COST);
 8229 
 8230   format %{ &quot;MEMBAR-store-store&quot; %}
 8231 
 8232   ins_encode %{
 8233     __ membar(Assembler::StoreStore);
 8234   %}
 8235   ins_pipe(pipe_serial);
 8236 %}
 8237 
 8238 instruct membar_release_lock() %{
 8239   match(MemBarReleaseLock);
 8240   ins_cost(VOLATILE_REF_COST);
 8241 
 8242   format %{ &quot;membar_release_lock (elided)&quot; %}
 8243 
 8244   ins_encode %{
 8245     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8246   %}
 8247 
 8248   ins_pipe(pipe_serial);
 8249 %}
 8250 
 8251 instruct unnecessary_membar_volatile() %{
 8252   predicate(unnecessary_volatile(n));
 8253   match(MemBarVolatile);
 8254   ins_cost(0);
 8255 
 8256   format %{ &quot;membar_volatile (elided)&quot; %}
 8257 
 8258   ins_encode %{
 8259     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8260   %}
 8261 
 8262   ins_pipe(pipe_serial);
 8263 %}
 8264 
 8265 instruct membar_volatile() %{
 8266   match(MemBarVolatile);
 8267   ins_cost(VOLATILE_REF_COST*100);
 8268 
 8269   format %{ &quot;membar_volatile\n\t&quot;
 8270              &quot;dmb ish&quot;%}
 8271 
 8272   ins_encode %{
 8273     __ block_comment(&quot;membar_volatile&quot;);
 8274     __ membar(Assembler::StoreLoad);
 8275   %}
 8276 
 8277   ins_pipe(pipe_serial);
 8278 %}
 8279 
 8280 // ============================================================================
 8281 // Cast/Convert Instructions
 8282 
 8283 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8284   match(Set dst (CastX2P src));
 8285 
 8286   ins_cost(INSN_COST);
 8287   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8288 
 8289   ins_encode %{
 8290     if ($dst$$reg != $src$$reg) {
 8291       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8292     }
 8293   %}
 8294 
 8295   ins_pipe(ialu_reg);
 8296 %}
 8297 
<a name="8" id="anc8"></a><span class="line-added"> 8298 instruct castN2X(iRegLNoSp dst, iRegN src) %{</span>
<span class="line-added"> 8299   match(Set dst (CastP2X src));</span>
<span class="line-added"> 8300 </span>
<span class="line-added"> 8301   ins_cost(INSN_COST);</span>
<span class="line-added"> 8302   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}</span>
<span class="line-added"> 8303 </span>
<span class="line-added"> 8304   ins_encode %{</span>
<span class="line-added"> 8305     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8306       __ mov(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8307     }</span>
<span class="line-added"> 8308   %}</span>
<span class="line-added"> 8309 </span>
<span class="line-added"> 8310   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8311 %}</span>
<span class="line-added"> 8312 </span>
 8313 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8314   match(Set dst (CastP2X src));
 8315 
 8316   ins_cost(INSN_COST);
 8317   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8318 
 8319   ins_encode %{
 8320     if ($dst$$reg != $src$$reg) {
 8321       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8322     }
 8323   %}
 8324 
 8325   ins_pipe(ialu_reg);
 8326 %}
 8327 
<a name="9" id="anc9"></a><span class="line-added"> 8328 instruct castN2I(iRegINoSp dst, iRegN src) %{</span>
<span class="line-added"> 8329   match(Set dst (CastN2I src));</span>
<span class="line-added"> 8330 </span>
<span class="line-added"> 8331   ins_cost(INSN_COST);</span>
<span class="line-added"> 8332   format %{ &quot;movw $dst, $src\t# compressed ptr -&gt; int&quot; %}</span>
<span class="line-added"> 8333 </span>
<span class="line-added"> 8334   ins_encode %{</span>
<span class="line-added"> 8335     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8336       __ movw(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8337     }</span>
<span class="line-added"> 8338   %}</span>
<span class="line-added"> 8339 </span>
<span class="line-added"> 8340   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8341 %}</span>
<span class="line-added"> 8342 </span>
<span class="line-added"> 8343 instruct castI2N(iRegNNoSp dst, iRegI src) %{</span>
<span class="line-added"> 8344   match(Set dst (CastI2N src));</span>
<span class="line-added"> 8345 </span>
<span class="line-added"> 8346   ins_cost(INSN_COST);</span>
<span class="line-added"> 8347   format %{ &quot;movw $dst, $src\t# int -&gt; compressed ptr&quot; %}</span>
<span class="line-added"> 8348 </span>
<span class="line-added"> 8349   ins_encode %{</span>
<span class="line-added"> 8350     if ($dst$$reg != $src$$reg) {</span>
<span class="line-added"> 8351       __ movw(as_Register($dst$$reg), as_Register($src$$reg));</span>
<span class="line-added"> 8352     }</span>
<span class="line-added"> 8353   %}</span>
<span class="line-added"> 8354 </span>
<span class="line-added"> 8355   ins_pipe(ialu_reg);</span>
<span class="line-added"> 8356 %}</span>
<span class="line-added"> 8357 </span>
<span class="line-added"> 8358 </span>
 8359 // Convert oop into int for vectors alignment masking
 8360 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8361   match(Set dst (ConvL2I (CastP2X src)));
 8362 
 8363   ins_cost(INSN_COST);
 8364   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8365   ins_encode %{
 8366     __ movw($dst$$Register, $src$$Register);
 8367   %}
 8368 
 8369   ins_pipe(ialu_reg);
 8370 %}
 8371 
 8372 // Convert compressed oop into int for vectors alignment masking
 8373 // in case of 32bit oops (heap &lt; 4Gb).
 8374 instruct convN2I(iRegINoSp dst, iRegN src)
 8375 %{
 8376   predicate(CompressedOops::shift() == 0);
 8377   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8378 
 8379   ins_cost(INSN_COST);
 8380   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8381   ins_encode %{
 8382     __ movw($dst$$Register, $src$$Register);
 8383   %}
 8384 
 8385   ins_pipe(ialu_reg);
 8386 %}
 8387 
 8388 
 8389 // Convert oop pointer into compressed form
 8390 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8391   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8392   match(Set dst (EncodeP src));
 8393   effect(KILL cr);
 8394   ins_cost(INSN_COST * 3);
 8395   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8396   ins_encode %{
 8397     Register s = $src$$Register;
 8398     Register d = $dst$$Register;
 8399     __ encode_heap_oop(d, s);
 8400   %}
 8401   ins_pipe(ialu_reg);
 8402 %}
 8403 
 8404 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8405   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8406   match(Set dst (EncodeP src));
 8407   ins_cost(INSN_COST * 3);
 8408   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8409   ins_encode %{
 8410     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8411   %}
 8412   ins_pipe(ialu_reg);
 8413 %}
 8414 
 8415 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8416   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8417             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8418   match(Set dst (DecodeN src));
 8419   ins_cost(INSN_COST * 3);
 8420   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8421   ins_encode %{
 8422     Register s = $src$$Register;
 8423     Register d = $dst$$Register;
 8424     __ decode_heap_oop(d, s);
 8425   %}
 8426   ins_pipe(ialu_reg);
 8427 %}
 8428 
 8429 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8430   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8431             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8432   match(Set dst (DecodeN src));
 8433   ins_cost(INSN_COST * 3);
 8434   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8435   ins_encode %{
 8436     Register s = $src$$Register;
 8437     Register d = $dst$$Register;
 8438     __ decode_heap_oop_not_null(d, s);
 8439   %}
 8440   ins_pipe(ialu_reg);
 8441 %}
 8442 
 8443 // n.b. AArch64 implementations of encode_klass_not_null and
 8444 // decode_klass_not_null do not modify the flags register so, unlike
 8445 // Intel, we don&#39;t kill CR as a side effect here
 8446 
 8447 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8448   match(Set dst (EncodePKlass src));
 8449 
 8450   ins_cost(INSN_COST * 3);
 8451   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8452 
 8453   ins_encode %{
 8454     Register src_reg = as_Register($src$$reg);
 8455     Register dst_reg = as_Register($dst$$reg);
 8456     __ encode_klass_not_null(dst_reg, src_reg);
 8457   %}
 8458 
 8459    ins_pipe(ialu_reg);
 8460 %}
 8461 
 8462 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8463   match(Set dst (DecodeNKlass src));
 8464 
 8465   ins_cost(INSN_COST * 3);
 8466   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8467 
 8468   ins_encode %{
 8469     Register src_reg = as_Register($src$$reg);
 8470     Register dst_reg = as_Register($dst$$reg);
 8471     if (dst_reg != src_reg) {
 8472       __ decode_klass_not_null(dst_reg, src_reg);
 8473     } else {
 8474       __ decode_klass_not_null(dst_reg);
 8475     }
 8476   %}
 8477 
 8478    ins_pipe(ialu_reg);
 8479 %}
 8480 
 8481 instruct checkCastPP(iRegPNoSp dst)
 8482 %{
 8483   match(Set dst (CheckCastPP dst));
 8484 
 8485   size(0);
 8486   format %{ &quot;# checkcastPP of $dst&quot; %}
 8487   ins_encode(/* empty encoding */);
 8488   ins_pipe(pipe_class_empty);
 8489 %}
 8490 
 8491 instruct castPP(iRegPNoSp dst)
 8492 %{
 8493   match(Set dst (CastPP dst));
 8494 
 8495   size(0);
 8496   format %{ &quot;# castPP of $dst&quot; %}
 8497   ins_encode(/* empty encoding */);
 8498   ins_pipe(pipe_class_empty);
 8499 %}
 8500 
 8501 instruct castII(iRegI dst)
 8502 %{
 8503   match(Set dst (CastII dst));
 8504 
 8505   size(0);
 8506   format %{ &quot;# castII of $dst&quot; %}
 8507   ins_encode(/* empty encoding */);
 8508   ins_cost(0);
 8509   ins_pipe(pipe_class_empty);
 8510 %}
 8511 
 8512 instruct castLL(iRegL dst)
 8513 %{
 8514   match(Set dst (CastLL dst));
 8515 
 8516   size(0);
 8517   format %{ &quot;# castLL of $dst&quot; %}
 8518   ins_encode(/* empty encoding */);
 8519   ins_cost(0);
 8520   ins_pipe(pipe_class_empty);
 8521 %}
 8522 
 8523 // ============================================================================
 8524 // Atomic operation instructions
 8525 //
 8526 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8527 // Store{PIL}Conditional instructions using a normal load for the
 8528 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8529 //
 8530 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8531 // pair to lock object allocations from Eden space when not using
 8532 // TLABs.
 8533 //
 8534 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8535 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8536 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8537 // only for 64-bit.
 8538 //
 8539 // We implement LoadPLocked and StorePLocked instructions using,
 8540 // respectively the AArch64 hw load-exclusive and store-conditional
 8541 // instructions. Whereas we must implement each of
 8542 // Store{IL}Conditional using a CAS which employs a pair of
 8543 // instructions comprising a load-exclusive followed by a
 8544 // store-conditional.
 8545 
 8546 
 8547 // Locked-load (linked load) of the current heap-top
 8548 // used when updating the eden heap top
 8549 // implemented using ldaxr on AArch64
 8550 
 8551 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8552 %{
 8553   match(Set dst (LoadPLocked mem));
 8554 
 8555   ins_cost(VOLATILE_REF_COST);
 8556 
 8557   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8558 
 8559   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8560 
 8561   ins_pipe(pipe_serial);
 8562 %}
 8563 
 8564 // Conditional-store of the updated heap-top.
 8565 // Used during allocation of the shared heap.
 8566 // Sets flag (EQ) on success.
 8567 // implemented using stlxr on AArch64.
 8568 
 8569 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8570 %{
 8571   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8572 
 8573   ins_cost(VOLATILE_REF_COST);
 8574 
 8575  // TODO
 8576  // do we need to do a store-conditional release or can we just use a
 8577  // plain store-conditional?
 8578 
 8579   format %{
 8580     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8581     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8582   %}
 8583 
 8584   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8585 
 8586   ins_pipe(pipe_serial);
 8587 %}
 8588 
 8589 
 8590 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8591 // when attempting to rebias a lock towards the current thread.  We
 8592 // must use the acquire form of cmpxchg in order to guarantee acquire
 8593 // semantics in this case.
 8594 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8595 %{
 8596   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8597 
 8598   ins_cost(VOLATILE_REF_COST);
 8599 
 8600   format %{
 8601     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8602     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8603   %}
 8604 
 8605   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8606 
 8607   ins_pipe(pipe_slow);
 8608 %}
 8609 
 8610 // storeIConditional also has acquire semantics, for no better reason
 8611 // than matching storeLConditional.  At the time of writing this
 8612 // comment storeIConditional was not used anywhere by AArch64.
 8613 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8614 %{
 8615   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8616 
 8617   ins_cost(VOLATILE_REF_COST);
 8618 
 8619   format %{
 8620     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8621     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8622   %}
 8623 
 8624   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8625 
 8626   ins_pipe(pipe_slow);
 8627 %}
 8628 
 8629 // standard CompareAndSwapX when we are using barriers
 8630 // these have higher priority than the rules selected by a predicate
 8631 
 8632 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8633 // can&#39;t match them
 8634 
 8635 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8636 
 8637   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8638   ins_cost(2 * VOLATILE_REF_COST);
 8639 
 8640   effect(KILL cr);
 8641 
 8642   format %{
 8643     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8644     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8645   %}
 8646 
 8647   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8648             aarch64_enc_cset_eq(res));
 8649 
 8650   ins_pipe(pipe_slow);
 8651 %}
 8652 
 8653 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8654 
 8655   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8656   ins_cost(2 * VOLATILE_REF_COST);
 8657 
 8658   effect(KILL cr);
 8659 
 8660   format %{
 8661     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8662     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8663   %}
 8664 
 8665   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8666             aarch64_enc_cset_eq(res));
 8667 
 8668   ins_pipe(pipe_slow);
 8669 %}
 8670 
 8671 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8672 
 8673   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8674   ins_cost(2 * VOLATILE_REF_COST);
 8675 
 8676   effect(KILL cr);
 8677 
 8678  format %{
 8679     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8680     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8681  %}
 8682 
 8683  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8684             aarch64_enc_cset_eq(res));
 8685 
 8686   ins_pipe(pipe_slow);
 8687 %}
 8688 
 8689 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8690 
 8691   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8692   ins_cost(2 * VOLATILE_REF_COST);
 8693 
 8694   effect(KILL cr);
 8695 
 8696  format %{
 8697     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8698     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8699  %}
 8700 
 8701  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8702             aarch64_enc_cset_eq(res));
 8703 
 8704   ins_pipe(pipe_slow);
 8705 %}
 8706 
 8707 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8708 
 8709   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8710   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8711   ins_cost(2 * VOLATILE_REF_COST);
 8712 
 8713   effect(KILL cr);
 8714 
 8715  format %{
 8716     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8717     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8718  %}
 8719 
 8720  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8721             aarch64_enc_cset_eq(res));
 8722 
 8723   ins_pipe(pipe_slow);
 8724 %}
 8725 
 8726 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8727 
 8728   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8729   ins_cost(2 * VOLATILE_REF_COST);
 8730 
 8731   effect(KILL cr);
 8732 
 8733  format %{
 8734     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8735     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8736  %}
 8737 
 8738  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8739             aarch64_enc_cset_eq(res));
 8740 
 8741   ins_pipe(pipe_slow);
 8742 %}
 8743 
 8744 // alternative CompareAndSwapX when we are eliding barriers
 8745 
 8746 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8747 
 8748   predicate(needs_acquiring_load_exclusive(n));
 8749   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8750   ins_cost(VOLATILE_REF_COST);
 8751 
 8752   effect(KILL cr);
 8753 
 8754   format %{
 8755     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8756     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8757   %}
 8758 
 8759   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8760             aarch64_enc_cset_eq(res));
 8761 
 8762   ins_pipe(pipe_slow);
 8763 %}
 8764 
 8765 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8766 
 8767   predicate(needs_acquiring_load_exclusive(n));
 8768   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8769   ins_cost(VOLATILE_REF_COST);
 8770 
 8771   effect(KILL cr);
 8772 
 8773   format %{
 8774     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8775     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8776   %}
 8777 
 8778   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8779             aarch64_enc_cset_eq(res));
 8780 
 8781   ins_pipe(pipe_slow);
 8782 %}
 8783 
 8784 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8785 
 8786   predicate(needs_acquiring_load_exclusive(n));
 8787   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8788   ins_cost(VOLATILE_REF_COST);
 8789 
 8790   effect(KILL cr);
 8791 
 8792  format %{
 8793     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8794     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8795  %}
 8796 
 8797  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8798             aarch64_enc_cset_eq(res));
 8799 
 8800   ins_pipe(pipe_slow);
 8801 %}
 8802 
 8803 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8804 
 8805   predicate(needs_acquiring_load_exclusive(n));
 8806   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8807   ins_cost(VOLATILE_REF_COST);
 8808 
 8809   effect(KILL cr);
 8810 
 8811  format %{
 8812     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8813     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8814  %}
 8815 
 8816  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8817             aarch64_enc_cset_eq(res));
 8818 
 8819   ins_pipe(pipe_slow);
 8820 %}
 8821 
 8822 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8823 
 8824   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8825   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8826   ins_cost(VOLATILE_REF_COST);
 8827 
 8828   effect(KILL cr);
 8829 
 8830  format %{
 8831     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8832     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8833  %}
 8834 
 8835  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8836             aarch64_enc_cset_eq(res));
 8837 
 8838   ins_pipe(pipe_slow);
 8839 %}
 8840 
 8841 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8842 
 8843   predicate(needs_acquiring_load_exclusive(n));
 8844   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8845   ins_cost(VOLATILE_REF_COST);
 8846 
 8847   effect(KILL cr);
 8848 
 8849  format %{
 8850     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8851     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8852  %}
 8853 
 8854  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8855             aarch64_enc_cset_eq(res));
 8856 
 8857   ins_pipe(pipe_slow);
 8858 %}
 8859 
 8860 
 8861 // ---------------------------------------------------------------------
 8862 
 8863 
 8864 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8865 
 8866 // Sundry CAS operations.  Note that release is always true,
 8867 // regardless of the memory ordering of the CAS.  This is because we
 8868 // need the volatile case to be sequentially consistent but there is
 8869 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8870 // can&#39;t check the type of memory ordering here, so we always emit a
 8871 // STLXR.
 8872 
 8873 // This section is generated from aarch64_ad_cas.m4
 8874 
 8875 
 8876 
 8877 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8878   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8879   ins_cost(2 * VOLATILE_REF_COST);
 8880   effect(TEMP_DEF res, KILL cr);
 8881   format %{
 8882     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8883   %}
 8884   ins_encode %{
 8885     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8886                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8887                /*weak*/ false, $res$$Register);
 8888     __ sxtbw($res$$Register, $res$$Register);
 8889   %}
 8890   ins_pipe(pipe_slow);
 8891 %}
 8892 
 8893 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8894   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8895   ins_cost(2 * VOLATILE_REF_COST);
 8896   effect(TEMP_DEF res, KILL cr);
 8897   format %{
 8898     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8899   %}
 8900   ins_encode %{
 8901     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8902                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8903                /*weak*/ false, $res$$Register);
 8904     __ sxthw($res$$Register, $res$$Register);
 8905   %}
 8906   ins_pipe(pipe_slow);
 8907 %}
 8908 
 8909 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8910   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8911   ins_cost(2 * VOLATILE_REF_COST);
 8912   effect(TEMP_DEF res, KILL cr);
 8913   format %{
 8914     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8915   %}
 8916   ins_encode %{
 8917     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8918                Assembler::word, /*acquire*/ false, /*release*/ true,
 8919                /*weak*/ false, $res$$Register);
 8920   %}
 8921   ins_pipe(pipe_slow);
 8922 %}
 8923 
 8924 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8925   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8926   ins_cost(2 * VOLATILE_REF_COST);
 8927   effect(TEMP_DEF res, KILL cr);
 8928   format %{
 8929     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8930   %}
 8931   ins_encode %{
 8932     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8933                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8934                /*weak*/ false, $res$$Register);
 8935   %}
 8936   ins_pipe(pipe_slow);
 8937 %}
 8938 
 8939 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8940   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8941   ins_cost(2 * VOLATILE_REF_COST);
 8942   effect(TEMP_DEF res, KILL cr);
 8943   format %{
 8944     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8945   %}
 8946   ins_encode %{
 8947     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8948                Assembler::word, /*acquire*/ false, /*release*/ true,
 8949                /*weak*/ false, $res$$Register);
 8950   %}
 8951   ins_pipe(pipe_slow);
 8952 %}
 8953 
 8954 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8955   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8956   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8957   ins_cost(2 * VOLATILE_REF_COST);
 8958   effect(TEMP_DEF res, KILL cr);
 8959   format %{
 8960     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8961   %}
 8962   ins_encode %{
 8963     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8964                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8965                /*weak*/ false, $res$$Register);
 8966   %}
 8967   ins_pipe(pipe_slow);
 8968 %}
 8969 
 8970 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8971   predicate(needs_acquiring_load_exclusive(n));
 8972   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8973   ins_cost(VOLATILE_REF_COST);
 8974   effect(TEMP_DEF res, KILL cr);
 8975   format %{
 8976     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8977   %}
 8978   ins_encode %{
 8979     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8980                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8981                /*weak*/ false, $res$$Register);
 8982     __ sxtbw($res$$Register, $res$$Register);
 8983   %}
 8984   ins_pipe(pipe_slow);
 8985 %}
 8986 
 8987 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8988   predicate(needs_acquiring_load_exclusive(n));
 8989   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8990   ins_cost(VOLATILE_REF_COST);
 8991   effect(TEMP_DEF res, KILL cr);
 8992   format %{
 8993     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8994   %}
 8995   ins_encode %{
 8996     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8997                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8998                /*weak*/ false, $res$$Register);
 8999     __ sxthw($res$$Register, $res$$Register);
 9000   %}
 9001   ins_pipe(pipe_slow);
 9002 %}
 9003 
 9004 
 9005 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9006   predicate(needs_acquiring_load_exclusive(n));
 9007   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 9008   ins_cost(VOLATILE_REF_COST);
 9009   effect(TEMP_DEF res, KILL cr);
 9010   format %{
 9011     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9012   %}
 9013   ins_encode %{
 9014     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9015                Assembler::word, /*acquire*/ true, /*release*/ true,
 9016                /*weak*/ false, $res$$Register);
 9017   %}
 9018   ins_pipe(pipe_slow);
 9019 %}
 9020 
 9021 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9022   predicate(needs_acquiring_load_exclusive(n));
 9023   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 9024   ins_cost(VOLATILE_REF_COST);
 9025   effect(TEMP_DEF res, KILL cr);
 9026   format %{
 9027     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9028   %}
 9029   ins_encode %{
 9030     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9031                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9032                /*weak*/ false, $res$$Register);
 9033   %}
 9034   ins_pipe(pipe_slow);
 9035 %}
 9036 
 9037 
 9038 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9039   predicate(needs_acquiring_load_exclusive(n));
 9040   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 9041   ins_cost(VOLATILE_REF_COST);
 9042   effect(TEMP_DEF res, KILL cr);
 9043   format %{
 9044     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9045   %}
 9046   ins_encode %{
 9047     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9048                Assembler::word, /*acquire*/ true, /*release*/ true,
 9049                /*weak*/ false, $res$$Register);
 9050   %}
 9051   ins_pipe(pipe_slow);
 9052 %}
 9053 
 9054 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9055   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9056   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9057   ins_cost(VOLATILE_REF_COST);
 9058   effect(TEMP_DEF res, KILL cr);
 9059   format %{
 9060     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9061   %}
 9062   ins_encode %{
 9063     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9064                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9065                /*weak*/ false, $res$$Register);
 9066   %}
 9067   ins_pipe(pipe_slow);
 9068 %}
 9069 
 9070 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9071   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9072   ins_cost(2 * VOLATILE_REF_COST);
 9073   effect(KILL cr);
 9074   format %{
 9075     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9076     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9077   %}
 9078   ins_encode %{
 9079     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9080                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9081                /*weak*/ true, noreg);
 9082     __ csetw($res$$Register, Assembler::EQ);
 9083   %}
 9084   ins_pipe(pipe_slow);
 9085 %}
 9086 
 9087 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9088   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9089   ins_cost(2 * VOLATILE_REF_COST);
 9090   effect(KILL cr);
 9091   format %{
 9092     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9093     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9094   %}
 9095   ins_encode %{
 9096     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9097                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9098                /*weak*/ true, noreg);
 9099     __ csetw($res$$Register, Assembler::EQ);
 9100   %}
 9101   ins_pipe(pipe_slow);
 9102 %}
 9103 
 9104 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9105   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9106   ins_cost(2 * VOLATILE_REF_COST);
 9107   effect(KILL cr);
 9108   format %{
 9109     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9110     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9111   %}
 9112   ins_encode %{
 9113     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9114                Assembler::word, /*acquire*/ false, /*release*/ true,
 9115                /*weak*/ true, noreg);
 9116     __ csetw($res$$Register, Assembler::EQ);
 9117   %}
 9118   ins_pipe(pipe_slow);
 9119 %}
 9120 
 9121 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9122   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9123   ins_cost(2 * VOLATILE_REF_COST);
 9124   effect(KILL cr);
 9125   format %{
 9126     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9127     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9128   %}
 9129   ins_encode %{
 9130     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9131                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9132                /*weak*/ true, noreg);
 9133     __ csetw($res$$Register, Assembler::EQ);
 9134   %}
 9135   ins_pipe(pipe_slow);
 9136 %}
 9137 
 9138 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9139   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9140   ins_cost(2 * VOLATILE_REF_COST);
 9141   effect(KILL cr);
 9142   format %{
 9143     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9144     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9145   %}
 9146   ins_encode %{
 9147     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9148                Assembler::word, /*acquire*/ false, /*release*/ true,
 9149                /*weak*/ true, noreg);
 9150     __ csetw($res$$Register, Assembler::EQ);
 9151   %}
 9152   ins_pipe(pipe_slow);
 9153 %}
 9154 
 9155 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9156   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9157   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9158   ins_cost(2 * VOLATILE_REF_COST);
 9159   effect(KILL cr);
 9160   format %{
 9161     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9162     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9163   %}
 9164   ins_encode %{
 9165     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9166                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9167                /*weak*/ true, noreg);
 9168     __ csetw($res$$Register, Assembler::EQ);
 9169   %}
 9170   ins_pipe(pipe_slow);
 9171 %}
 9172 
 9173 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9174   predicate(needs_acquiring_load_exclusive(n));
 9175   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9176   ins_cost(VOLATILE_REF_COST);
 9177   effect(KILL cr);
 9178   format %{
 9179     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9180     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9181   %}
 9182   ins_encode %{
 9183     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9184                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9185                /*weak*/ true, noreg);
 9186     __ csetw($res$$Register, Assembler::EQ);
 9187   %}
 9188   ins_pipe(pipe_slow);
 9189 %}
 9190 
 9191 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9192   predicate(needs_acquiring_load_exclusive(n));
 9193   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9194   ins_cost(VOLATILE_REF_COST);
 9195   effect(KILL cr);
 9196   format %{
 9197     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9198     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9199   %}
 9200   ins_encode %{
 9201     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9202                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9203                /*weak*/ true, noreg);
 9204     __ csetw($res$$Register, Assembler::EQ);
 9205   %}
 9206   ins_pipe(pipe_slow);
 9207 %}
 9208 
 9209 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9210   predicate(needs_acquiring_load_exclusive(n));
 9211   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9212   ins_cost(VOLATILE_REF_COST);
 9213   effect(KILL cr);
 9214   format %{
 9215     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9216     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9217   %}
 9218   ins_encode %{
 9219     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9220                Assembler::word, /*acquire*/ true, /*release*/ true,
 9221                /*weak*/ true, noreg);
 9222     __ csetw($res$$Register, Assembler::EQ);
 9223   %}
 9224   ins_pipe(pipe_slow);
 9225 %}
 9226 
 9227 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9228   predicate(needs_acquiring_load_exclusive(n));
 9229   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9230   ins_cost(VOLATILE_REF_COST);
 9231   effect(KILL cr);
 9232   format %{
 9233     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9234     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9235   %}
 9236   ins_encode %{
 9237     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9238                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9239                /*weak*/ true, noreg);
 9240     __ csetw($res$$Register, Assembler::EQ);
 9241   %}
 9242   ins_pipe(pipe_slow);
 9243 %}
 9244 
 9245 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9246   predicate(needs_acquiring_load_exclusive(n));
 9247   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9248   ins_cost(VOLATILE_REF_COST);
 9249   effect(KILL cr);
 9250   format %{
 9251     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9252     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9253   %}
 9254   ins_encode %{
 9255     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9256                Assembler::word, /*acquire*/ true, /*release*/ true,
 9257                /*weak*/ true, noreg);
 9258     __ csetw($res$$Register, Assembler::EQ);
 9259   %}
 9260   ins_pipe(pipe_slow);
 9261 %}
 9262 
 9263 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9264   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9265   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9266   ins_cost(VOLATILE_REF_COST);
 9267   effect(KILL cr);
 9268   format %{
 9269     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9270     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9271   %}
 9272   ins_encode %{
 9273     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9274                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9275                /*weak*/ true, noreg);
 9276     __ csetw($res$$Register, Assembler::EQ);
 9277   %}
 9278   ins_pipe(pipe_slow);
 9279 %}
 9280 
 9281 // END This section of the file is automatically generated. Do not edit --------------
 9282 // ---------------------------------------------------------------------
 9283 
 9284 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9285   match(Set prev (GetAndSetI mem newv));
 9286   ins_cost(2 * VOLATILE_REF_COST);
 9287   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9288   ins_encode %{
 9289     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9290   %}
 9291   ins_pipe(pipe_serial);
 9292 %}
 9293 
 9294 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9295   match(Set prev (GetAndSetL mem newv));
 9296   ins_cost(2 * VOLATILE_REF_COST);
 9297   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9298   ins_encode %{
 9299     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9300   %}
 9301   ins_pipe(pipe_serial);
 9302 %}
 9303 
 9304 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9305   match(Set prev (GetAndSetN mem newv));
 9306   ins_cost(2 * VOLATILE_REF_COST);
 9307   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9308   ins_encode %{
 9309     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9310   %}
 9311   ins_pipe(pipe_serial);
 9312 %}
 9313 
 9314 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9315   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9316   match(Set prev (GetAndSetP mem newv));
 9317   ins_cost(2 * VOLATILE_REF_COST);
 9318   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9319   ins_encode %{
 9320     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9321   %}
 9322   ins_pipe(pipe_serial);
 9323 %}
 9324 
 9325 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9326   predicate(needs_acquiring_load_exclusive(n));
 9327   match(Set prev (GetAndSetI mem newv));
 9328   ins_cost(VOLATILE_REF_COST);
 9329   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9330   ins_encode %{
 9331     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9332   %}
 9333   ins_pipe(pipe_serial);
 9334 %}
 9335 
 9336 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9337   predicate(needs_acquiring_load_exclusive(n));
 9338   match(Set prev (GetAndSetL mem newv));
 9339   ins_cost(VOLATILE_REF_COST);
 9340   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9341   ins_encode %{
 9342     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9343   %}
 9344   ins_pipe(pipe_serial);
 9345 %}
 9346 
 9347 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9348   predicate(needs_acquiring_load_exclusive(n));
 9349   match(Set prev (GetAndSetN mem newv));
 9350   ins_cost(VOLATILE_REF_COST);
 9351   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9352   ins_encode %{
 9353     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9354   %}
 9355   ins_pipe(pipe_serial);
 9356 %}
 9357 
 9358 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9359   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9360   match(Set prev (GetAndSetP mem newv));
 9361   ins_cost(VOLATILE_REF_COST);
 9362   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9363   ins_encode %{
 9364     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9365   %}
 9366   ins_pipe(pipe_serial);
 9367 %}
 9368 
 9369 
 9370 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9371   match(Set newval (GetAndAddL mem incr));
 9372   ins_cost(2 * VOLATILE_REF_COST + 1);
 9373   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9374   ins_encode %{
 9375     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9376   %}
 9377   ins_pipe(pipe_serial);
 9378 %}
 9379 
 9380 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9381   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9382   match(Set dummy (GetAndAddL mem incr));
 9383   ins_cost(2 * VOLATILE_REF_COST);
 9384   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9385   ins_encode %{
 9386     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9387   %}
 9388   ins_pipe(pipe_serial);
 9389 %}
 9390 
 9391 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9392   match(Set newval (GetAndAddL mem incr));
 9393   ins_cost(2 * VOLATILE_REF_COST + 1);
 9394   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9395   ins_encode %{
 9396     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9397   %}
 9398   ins_pipe(pipe_serial);
 9399 %}
 9400 
 9401 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9402   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9403   match(Set dummy (GetAndAddL mem incr));
 9404   ins_cost(2 * VOLATILE_REF_COST);
 9405   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9406   ins_encode %{
 9407     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9408   %}
 9409   ins_pipe(pipe_serial);
 9410 %}
 9411 
 9412 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9413   match(Set newval (GetAndAddI mem incr));
 9414   ins_cost(2 * VOLATILE_REF_COST + 1);
 9415   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9416   ins_encode %{
 9417     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9418   %}
 9419   ins_pipe(pipe_serial);
 9420 %}
 9421 
 9422 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9423   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9424   match(Set dummy (GetAndAddI mem incr));
 9425   ins_cost(2 * VOLATILE_REF_COST);
 9426   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9427   ins_encode %{
 9428     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9429   %}
 9430   ins_pipe(pipe_serial);
 9431 %}
 9432 
 9433 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9434   match(Set newval (GetAndAddI mem incr));
 9435   ins_cost(2 * VOLATILE_REF_COST + 1);
 9436   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9437   ins_encode %{
 9438     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9439   %}
 9440   ins_pipe(pipe_serial);
 9441 %}
 9442 
 9443 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9444   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9445   match(Set dummy (GetAndAddI mem incr));
 9446   ins_cost(2 * VOLATILE_REF_COST);
 9447   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9448   ins_encode %{
 9449     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9450   %}
 9451   ins_pipe(pipe_serial);
 9452 %}
 9453 
 9454 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9455   predicate(needs_acquiring_load_exclusive(n));
 9456   match(Set newval (GetAndAddL mem incr));
 9457   ins_cost(VOLATILE_REF_COST + 1);
 9458   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9459   ins_encode %{
 9460     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9461   %}
 9462   ins_pipe(pipe_serial);
 9463 %}
 9464 
 9465 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9466   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9467   match(Set dummy (GetAndAddL mem incr));
 9468   ins_cost(VOLATILE_REF_COST);
 9469   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9470   ins_encode %{
 9471     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9472   %}
 9473   ins_pipe(pipe_serial);
 9474 %}
 9475 
 9476 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9477   predicate(needs_acquiring_load_exclusive(n));
 9478   match(Set newval (GetAndAddL mem incr));
 9479   ins_cost(VOLATILE_REF_COST + 1);
 9480   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9481   ins_encode %{
 9482     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9483   %}
 9484   ins_pipe(pipe_serial);
 9485 %}
 9486 
 9487 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9488   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9489   match(Set dummy (GetAndAddL mem incr));
 9490   ins_cost(VOLATILE_REF_COST);
 9491   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9492   ins_encode %{
 9493     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9494   %}
 9495   ins_pipe(pipe_serial);
 9496 %}
 9497 
 9498 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9499   predicate(needs_acquiring_load_exclusive(n));
 9500   match(Set newval (GetAndAddI mem incr));
 9501   ins_cost(VOLATILE_REF_COST + 1);
 9502   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9503   ins_encode %{
 9504     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9505   %}
 9506   ins_pipe(pipe_serial);
 9507 %}
 9508 
 9509 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9510   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9511   match(Set dummy (GetAndAddI mem incr));
 9512   ins_cost(VOLATILE_REF_COST);
 9513   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9514   ins_encode %{
 9515     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9516   %}
 9517   ins_pipe(pipe_serial);
 9518 %}
 9519 
 9520 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9521   predicate(needs_acquiring_load_exclusive(n));
 9522   match(Set newval (GetAndAddI mem incr));
 9523   ins_cost(VOLATILE_REF_COST + 1);
 9524   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9525   ins_encode %{
 9526     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9527   %}
 9528   ins_pipe(pipe_serial);
 9529 %}
 9530 
 9531 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9532   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9533   match(Set dummy (GetAndAddI mem incr));
 9534   ins_cost(VOLATILE_REF_COST);
 9535   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9536   ins_encode %{
 9537     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9538   %}
 9539   ins_pipe(pipe_serial);
 9540 %}
 9541 
 9542 // Manifest a CmpL result in an integer register.
 9543 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9544 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9545 %{
 9546   match(Set dst (CmpL3 src1 src2));
 9547   effect(KILL flags);
 9548 
 9549   ins_cost(INSN_COST * 6);
 9550   format %{
 9551       &quot;cmp $src1, $src2&quot;
 9552       &quot;csetw $dst, ne&quot;
 9553       &quot;cnegw $dst, lt&quot;
 9554   %}
 9555   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9556   ins_encode %{
 9557     __ cmp($src1$$Register, $src2$$Register);
 9558     __ csetw($dst$$Register, Assembler::NE);
 9559     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9560   %}
 9561 
 9562   ins_pipe(pipe_class_default);
 9563 %}
 9564 
 9565 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9566 %{
 9567   match(Set dst (CmpL3 src1 src2));
 9568   effect(KILL flags);
 9569 
 9570   ins_cost(INSN_COST * 6);
 9571   format %{
 9572       &quot;cmp $src1, $src2&quot;
 9573       &quot;csetw $dst, ne&quot;
 9574       &quot;cnegw $dst, lt&quot;
 9575   %}
 9576   ins_encode %{
 9577     int32_t con = (int32_t)$src2$$constant;
 9578      if (con &lt; 0) {
 9579       __ adds(zr, $src1$$Register, -con);
 9580     } else {
 9581       __ subs(zr, $src1$$Register, con);
 9582     }
 9583     __ csetw($dst$$Register, Assembler::NE);
 9584     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9585   %}
 9586 
 9587   ins_pipe(pipe_class_default);
 9588 %}
 9589 
 9590 // ============================================================================
 9591 // Conditional Move Instructions
 9592 
 9593 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9594 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9595 // define an op class which merged both inputs and use it to type the
 9596 // argument to a single rule. unfortunatelyt his fails because the
 9597 // opclass does not live up to the COND_INTER interface of its
 9598 // component operands. When the generic code tries to negate the
 9599 // operand it ends up running the generci Machoper::negate method
 9600 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9601 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9602 
 9603 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9604   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9605 
 9606   ins_cost(INSN_COST * 2);
 9607   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9608 
 9609   ins_encode %{
 9610     __ cselw(as_Register($dst$$reg),
 9611              as_Register($src2$$reg),
 9612              as_Register($src1$$reg),
 9613              (Assembler::Condition)$cmp$$cmpcode);
 9614   %}
 9615 
 9616   ins_pipe(icond_reg_reg);
 9617 %}
 9618 
 9619 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9620   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9621 
 9622   ins_cost(INSN_COST * 2);
 9623   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9624 
 9625   ins_encode %{
 9626     __ cselw(as_Register($dst$$reg),
 9627              as_Register($src2$$reg),
 9628              as_Register($src1$$reg),
 9629              (Assembler::Condition)$cmp$$cmpcode);
 9630   %}
 9631 
 9632   ins_pipe(icond_reg_reg);
 9633 %}
 9634 
 9635 // special cases where one arg is zero
 9636 
 9637 // n.b. this is selected in preference to the rule above because it
 9638 // avoids loading constant 0 into a source register
 9639 
 9640 // TODO
 9641 // we ought only to be able to cull one of these variants as the ideal
 9642 // transforms ought always to order the zero consistently (to left/right?)
 9643 
 9644 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9645   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9646 
 9647   ins_cost(INSN_COST * 2);
 9648   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9649 
 9650   ins_encode %{
 9651     __ cselw(as_Register($dst$$reg),
 9652              as_Register($src$$reg),
 9653              zr,
 9654              (Assembler::Condition)$cmp$$cmpcode);
 9655   %}
 9656 
 9657   ins_pipe(icond_reg);
 9658 %}
 9659 
 9660 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9661   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9662 
 9663   ins_cost(INSN_COST * 2);
 9664   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9665 
 9666   ins_encode %{
 9667     __ cselw(as_Register($dst$$reg),
 9668              as_Register($src$$reg),
 9669              zr,
 9670              (Assembler::Condition)$cmp$$cmpcode);
 9671   %}
 9672 
 9673   ins_pipe(icond_reg);
 9674 %}
 9675 
 9676 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9677   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9678 
 9679   ins_cost(INSN_COST * 2);
 9680   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9681 
 9682   ins_encode %{
 9683     __ cselw(as_Register($dst$$reg),
 9684              zr,
 9685              as_Register($src$$reg),
 9686              (Assembler::Condition)$cmp$$cmpcode);
 9687   %}
 9688 
 9689   ins_pipe(icond_reg);
 9690 %}
 9691 
 9692 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9693   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9694 
 9695   ins_cost(INSN_COST * 2);
 9696   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9697 
 9698   ins_encode %{
 9699     __ cselw(as_Register($dst$$reg),
 9700              zr,
 9701              as_Register($src$$reg),
 9702              (Assembler::Condition)$cmp$$cmpcode);
 9703   %}
 9704 
 9705   ins_pipe(icond_reg);
 9706 %}
 9707 
 9708 // special case for creating a boolean 0 or 1
 9709 
 9710 // n.b. this is selected in preference to the rule above because it
 9711 // avoids loading constants 0 and 1 into a source register
 9712 
 9713 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9714   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9715 
 9716   ins_cost(INSN_COST * 2);
 9717   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9718 
 9719   ins_encode %{
 9720     // equivalently
 9721     // cset(as_Register($dst$$reg),
 9722     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9723     __ csincw(as_Register($dst$$reg),
 9724              zr,
 9725              zr,
 9726              (Assembler::Condition)$cmp$$cmpcode);
 9727   %}
 9728 
 9729   ins_pipe(icond_none);
 9730 %}
 9731 
 9732 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9733   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9734 
 9735   ins_cost(INSN_COST * 2);
 9736   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9737 
 9738   ins_encode %{
 9739     // equivalently
 9740     // cset(as_Register($dst$$reg),
 9741     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9742     __ csincw(as_Register($dst$$reg),
 9743              zr,
 9744              zr,
 9745              (Assembler::Condition)$cmp$$cmpcode);
 9746   %}
 9747 
 9748   ins_pipe(icond_none);
 9749 %}
 9750 
 9751 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9752   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9753 
 9754   ins_cost(INSN_COST * 2);
 9755   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9756 
 9757   ins_encode %{
 9758     __ csel(as_Register($dst$$reg),
 9759             as_Register($src2$$reg),
 9760             as_Register($src1$$reg),
 9761             (Assembler::Condition)$cmp$$cmpcode);
 9762   %}
 9763 
 9764   ins_pipe(icond_reg_reg);
 9765 %}
 9766 
 9767 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9768   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9769 
 9770   ins_cost(INSN_COST * 2);
 9771   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9772 
 9773   ins_encode %{
 9774     __ csel(as_Register($dst$$reg),
 9775             as_Register($src2$$reg),
 9776             as_Register($src1$$reg),
 9777             (Assembler::Condition)$cmp$$cmpcode);
 9778   %}
 9779 
 9780   ins_pipe(icond_reg_reg);
 9781 %}
 9782 
 9783 // special cases where one arg is zero
 9784 
 9785 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9786   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9787 
 9788   ins_cost(INSN_COST * 2);
 9789   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9790 
 9791   ins_encode %{
 9792     __ csel(as_Register($dst$$reg),
 9793             zr,
 9794             as_Register($src$$reg),
 9795             (Assembler::Condition)$cmp$$cmpcode);
 9796   %}
 9797 
 9798   ins_pipe(icond_reg);
 9799 %}
 9800 
 9801 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9802   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9803 
 9804   ins_cost(INSN_COST * 2);
 9805   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9806 
 9807   ins_encode %{
 9808     __ csel(as_Register($dst$$reg),
 9809             zr,
 9810             as_Register($src$$reg),
 9811             (Assembler::Condition)$cmp$$cmpcode);
 9812   %}
 9813 
 9814   ins_pipe(icond_reg);
 9815 %}
 9816 
 9817 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9818   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9819 
 9820   ins_cost(INSN_COST * 2);
 9821   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9822 
 9823   ins_encode %{
 9824     __ csel(as_Register($dst$$reg),
 9825             as_Register($src$$reg),
 9826             zr,
 9827             (Assembler::Condition)$cmp$$cmpcode);
 9828   %}
 9829 
 9830   ins_pipe(icond_reg);
 9831 %}
 9832 
 9833 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9834   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9835 
 9836   ins_cost(INSN_COST * 2);
 9837   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9838 
 9839   ins_encode %{
 9840     __ csel(as_Register($dst$$reg),
 9841             as_Register($src$$reg),
 9842             zr,
 9843             (Assembler::Condition)$cmp$$cmpcode);
 9844   %}
 9845 
 9846   ins_pipe(icond_reg);
 9847 %}
 9848 
 9849 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9850   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9851 
 9852   ins_cost(INSN_COST * 2);
 9853   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9854 
 9855   ins_encode %{
 9856     __ csel(as_Register($dst$$reg),
 9857             as_Register($src2$$reg),
 9858             as_Register($src1$$reg),
 9859             (Assembler::Condition)$cmp$$cmpcode);
 9860   %}
 9861 
 9862   ins_pipe(icond_reg_reg);
 9863 %}
 9864 
 9865 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9866   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9867 
 9868   ins_cost(INSN_COST * 2);
 9869   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9870 
 9871   ins_encode %{
 9872     __ csel(as_Register($dst$$reg),
 9873             as_Register($src2$$reg),
 9874             as_Register($src1$$reg),
 9875             (Assembler::Condition)$cmp$$cmpcode);
 9876   %}
 9877 
 9878   ins_pipe(icond_reg_reg);
 9879 %}
 9880 
 9881 // special cases where one arg is zero
 9882 
 9883 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9884   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9885 
 9886   ins_cost(INSN_COST * 2);
 9887   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9888 
 9889   ins_encode %{
 9890     __ csel(as_Register($dst$$reg),
 9891             zr,
 9892             as_Register($src$$reg),
 9893             (Assembler::Condition)$cmp$$cmpcode);
 9894   %}
 9895 
 9896   ins_pipe(icond_reg);
 9897 %}
 9898 
 9899 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9900   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9901 
 9902   ins_cost(INSN_COST * 2);
 9903   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9904 
 9905   ins_encode %{
 9906     __ csel(as_Register($dst$$reg),
 9907             zr,
 9908             as_Register($src$$reg),
 9909             (Assembler::Condition)$cmp$$cmpcode);
 9910   %}
 9911 
 9912   ins_pipe(icond_reg);
 9913 %}
 9914 
 9915 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9916   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9917 
 9918   ins_cost(INSN_COST * 2);
 9919   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9920 
 9921   ins_encode %{
 9922     __ csel(as_Register($dst$$reg),
 9923             as_Register($src$$reg),
 9924             zr,
 9925             (Assembler::Condition)$cmp$$cmpcode);
 9926   %}
 9927 
 9928   ins_pipe(icond_reg);
 9929 %}
 9930 
 9931 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9932   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9933 
 9934   ins_cost(INSN_COST * 2);
 9935   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9936 
 9937   ins_encode %{
 9938     __ csel(as_Register($dst$$reg),
 9939             as_Register($src$$reg),
 9940             zr,
 9941             (Assembler::Condition)$cmp$$cmpcode);
 9942   %}
 9943 
 9944   ins_pipe(icond_reg);
 9945 %}
 9946 
 9947 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9948   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9949 
 9950   ins_cost(INSN_COST * 2);
 9951   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9952 
 9953   ins_encode %{
 9954     __ cselw(as_Register($dst$$reg),
 9955              as_Register($src2$$reg),
 9956              as_Register($src1$$reg),
 9957              (Assembler::Condition)$cmp$$cmpcode);
 9958   %}
 9959 
 9960   ins_pipe(icond_reg_reg);
 9961 %}
 9962 
 9963 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9964   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9965 
 9966   ins_cost(INSN_COST * 2);
 9967   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9968 
 9969   ins_encode %{
 9970     __ cselw(as_Register($dst$$reg),
 9971              as_Register($src2$$reg),
 9972              as_Register($src1$$reg),
 9973              (Assembler::Condition)$cmp$$cmpcode);
 9974   %}
 9975 
 9976   ins_pipe(icond_reg_reg);
 9977 %}
 9978 
 9979 // special cases where one arg is zero
 9980 
 9981 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9982   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9983 
 9984   ins_cost(INSN_COST * 2);
 9985   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9986 
 9987   ins_encode %{
 9988     __ cselw(as_Register($dst$$reg),
 9989              zr,
 9990              as_Register($src$$reg),
 9991              (Assembler::Condition)$cmp$$cmpcode);
 9992   %}
 9993 
 9994   ins_pipe(icond_reg);
 9995 %}
 9996 
 9997 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9998   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9999 
10000   ins_cost(INSN_COST * 2);
10001   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
10002 
10003   ins_encode %{
10004     __ cselw(as_Register($dst$$reg),
10005              zr,
10006              as_Register($src$$reg),
10007              (Assembler::Condition)$cmp$$cmpcode);
10008   %}
10009 
10010   ins_pipe(icond_reg);
10011 %}
10012 
10013 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10014   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10015 
10016   ins_cost(INSN_COST * 2);
10017   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
10018 
10019   ins_encode %{
10020     __ cselw(as_Register($dst$$reg),
10021              as_Register($src$$reg),
10022              zr,
10023              (Assembler::Condition)$cmp$$cmpcode);
10024   %}
10025 
10026   ins_pipe(icond_reg);
10027 %}
10028 
10029 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10030   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10031 
10032   ins_cost(INSN_COST * 2);
10033   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
10034 
10035   ins_encode %{
10036     __ cselw(as_Register($dst$$reg),
10037              as_Register($src$$reg),
10038              zr,
10039              (Assembler::Condition)$cmp$$cmpcode);
10040   %}
10041 
10042   ins_pipe(icond_reg);
10043 %}
10044 
10045 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10046 %{
10047   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10048 
10049   ins_cost(INSN_COST * 3);
10050 
10051   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10052   ins_encode %{
10053     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10054     __ fcsels(as_FloatRegister($dst$$reg),
10055               as_FloatRegister($src2$$reg),
10056               as_FloatRegister($src1$$reg),
10057               cond);
10058   %}
10059 
10060   ins_pipe(fp_cond_reg_reg_s);
10061 %}
10062 
10063 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10064 %{
10065   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10066 
10067   ins_cost(INSN_COST * 3);
10068 
10069   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10070   ins_encode %{
10071     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10072     __ fcsels(as_FloatRegister($dst$$reg),
10073               as_FloatRegister($src2$$reg),
10074               as_FloatRegister($src1$$reg),
10075               cond);
10076   %}
10077 
10078   ins_pipe(fp_cond_reg_reg_s);
10079 %}
10080 
10081 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10082 %{
10083   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10084 
10085   ins_cost(INSN_COST * 3);
10086 
10087   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10088   ins_encode %{
10089     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10090     __ fcseld(as_FloatRegister($dst$$reg),
10091               as_FloatRegister($src2$$reg),
10092               as_FloatRegister($src1$$reg),
10093               cond);
10094   %}
10095 
10096   ins_pipe(fp_cond_reg_reg_d);
10097 %}
10098 
10099 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10100 %{
10101   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10102 
10103   ins_cost(INSN_COST * 3);
10104 
10105   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10106   ins_encode %{
10107     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10108     __ fcseld(as_FloatRegister($dst$$reg),
10109               as_FloatRegister($src2$$reg),
10110               as_FloatRegister($src1$$reg),
10111               cond);
10112   %}
10113 
10114   ins_pipe(fp_cond_reg_reg_d);
10115 %}
10116 
10117 // ============================================================================
10118 // Arithmetic Instructions
10119 //
10120 
10121 // Integer Addition
10122 
10123 // TODO
10124 // these currently employ operations which do not set CR and hence are
10125 // not flagged as killing CR but we would like to isolate the cases
10126 // where we want to set flags from those where we don&#39;t. need to work
10127 // out how to do that.
10128 
10129 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10130   match(Set dst (AddI src1 src2));
10131 
10132   ins_cost(INSN_COST);
10133   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10134 
10135   ins_encode %{
10136     __ addw(as_Register($dst$$reg),
10137             as_Register($src1$$reg),
10138             as_Register($src2$$reg));
10139   %}
10140 
10141   ins_pipe(ialu_reg_reg);
10142 %}
10143 
10144 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10145   match(Set dst (AddI src1 src2));
10146 
10147   ins_cost(INSN_COST);
10148   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10149 
10150   // use opcode to indicate that this is an add not a sub
10151   opcode(0x0);
10152 
10153   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10154 
10155   ins_pipe(ialu_reg_imm);
10156 %}
10157 
10158 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10159   match(Set dst (AddI (ConvL2I src1) src2));
10160 
10161   ins_cost(INSN_COST);
10162   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10163 
10164   // use opcode to indicate that this is an add not a sub
10165   opcode(0x0);
10166 
10167   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10168 
10169   ins_pipe(ialu_reg_imm);
10170 %}
10171 
10172 // Pointer Addition
10173 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10174   match(Set dst (AddP src1 src2));
10175 
10176   ins_cost(INSN_COST);
10177   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10178 
10179   ins_encode %{
10180     __ add(as_Register($dst$$reg),
10181            as_Register($src1$$reg),
10182            as_Register($src2$$reg));
10183   %}
10184 
10185   ins_pipe(ialu_reg_reg);
10186 %}
10187 
10188 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10189   match(Set dst (AddP src1 (ConvI2L src2)));
10190 
10191   ins_cost(1.9 * INSN_COST);
10192   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10193 
10194   ins_encode %{
10195     __ add(as_Register($dst$$reg),
10196            as_Register($src1$$reg),
10197            as_Register($src2$$reg), ext::sxtw);
10198   %}
10199 
10200   ins_pipe(ialu_reg_reg);
10201 %}
10202 
10203 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10204   match(Set dst (AddP src1 (LShiftL src2 scale)));
10205 
10206   ins_cost(1.9 * INSN_COST);
10207   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10208 
10209   ins_encode %{
10210     __ lea(as_Register($dst$$reg),
10211            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10212                    Address::lsl($scale$$constant)));
10213   %}
10214 
10215   ins_pipe(ialu_reg_reg_shift);
10216 %}
10217 
10218 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10219   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10220 
10221   ins_cost(1.9 * INSN_COST);
10222   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10223 
10224   ins_encode %{
10225     __ lea(as_Register($dst$$reg),
10226            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10227                    Address::sxtw($scale$$constant)));
10228   %}
10229 
10230   ins_pipe(ialu_reg_reg_shift);
10231 %}
10232 
10233 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10234   match(Set dst (LShiftL (ConvI2L src) scale));
10235 
10236   ins_cost(INSN_COST);
10237   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10238 
10239   ins_encode %{
10240     __ sbfiz(as_Register($dst$$reg),
10241           as_Register($src$$reg),
10242           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10243   %}
10244 
10245   ins_pipe(ialu_reg_shift);
10246 %}
10247 
10248 // Pointer Immediate Addition
10249 // n.b. this needs to be more expensive than using an indirect memory
10250 // operand
10251 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10252   match(Set dst (AddP src1 src2));
10253 
10254   ins_cost(INSN_COST);
10255   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10256 
10257   // use opcode to indicate that this is an add not a sub
10258   opcode(0x0);
10259 
10260   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10261 
10262   ins_pipe(ialu_reg_imm);
10263 %}
10264 
10265 // Long Addition
10266 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10267 
10268   match(Set dst (AddL src1 src2));
10269 
10270   ins_cost(INSN_COST);
10271   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10272 
10273   ins_encode %{
10274     __ add(as_Register($dst$$reg),
10275            as_Register($src1$$reg),
10276            as_Register($src2$$reg));
10277   %}
10278 
10279   ins_pipe(ialu_reg_reg);
10280 %}
10281 
10282 // No constant pool entries requiredLong Immediate Addition.
10283 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10284   match(Set dst (AddL src1 src2));
10285 
10286   ins_cost(INSN_COST);
10287   format %{ &quot;add $dst, $src1, $src2&quot; %}
10288 
10289   // use opcode to indicate that this is an add not a sub
10290   opcode(0x0);
10291 
10292   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10293 
10294   ins_pipe(ialu_reg_imm);
10295 %}
10296 
10297 // Integer Subtraction
10298 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10299   match(Set dst (SubI src1 src2));
10300 
10301   ins_cost(INSN_COST);
10302   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10303 
10304   ins_encode %{
10305     __ subw(as_Register($dst$$reg),
10306             as_Register($src1$$reg),
10307             as_Register($src2$$reg));
10308   %}
10309 
10310   ins_pipe(ialu_reg_reg);
10311 %}
10312 
10313 // Immediate Subtraction
10314 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10315   match(Set dst (SubI src1 src2));
10316 
10317   ins_cost(INSN_COST);
10318   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10319 
10320   // use opcode to indicate that this is a sub not an add
10321   opcode(0x1);
10322 
10323   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10324 
10325   ins_pipe(ialu_reg_imm);
10326 %}
10327 
10328 // Long Subtraction
10329 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10330 
10331   match(Set dst (SubL src1 src2));
10332 
10333   ins_cost(INSN_COST);
10334   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10335 
10336   ins_encode %{
10337     __ sub(as_Register($dst$$reg),
10338            as_Register($src1$$reg),
10339            as_Register($src2$$reg));
10340   %}
10341 
10342   ins_pipe(ialu_reg_reg);
10343 %}
10344 
10345 // No constant pool entries requiredLong Immediate Subtraction.
10346 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10347   match(Set dst (SubL src1 src2));
10348 
10349   ins_cost(INSN_COST);
10350   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10351 
10352   // use opcode to indicate that this is a sub not an add
10353   opcode(0x1);
10354 
10355   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10356 
10357   ins_pipe(ialu_reg_imm);
10358 %}
10359 
10360 // Integer Negation (special case for sub)
10361 
10362 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10363   match(Set dst (SubI zero src));
10364 
10365   ins_cost(INSN_COST);
10366   format %{ &quot;negw $dst, $src\t# int&quot; %}
10367 
10368   ins_encode %{
10369     __ negw(as_Register($dst$$reg),
10370             as_Register($src$$reg));
10371   %}
10372 
10373   ins_pipe(ialu_reg);
10374 %}
10375 
10376 // Long Negation
10377 
10378 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10379   match(Set dst (SubL zero src));
10380 
10381   ins_cost(INSN_COST);
10382   format %{ &quot;neg $dst, $src\t# long&quot; %}
10383 
10384   ins_encode %{
10385     __ neg(as_Register($dst$$reg),
10386            as_Register($src$$reg));
10387   %}
10388 
10389   ins_pipe(ialu_reg);
10390 %}
10391 
10392 // Integer Multiply
10393 
10394 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10395   match(Set dst (MulI src1 src2));
10396 
10397   ins_cost(INSN_COST * 3);
10398   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10399 
10400   ins_encode %{
10401     __ mulw(as_Register($dst$$reg),
10402             as_Register($src1$$reg),
10403             as_Register($src2$$reg));
10404   %}
10405 
10406   ins_pipe(imul_reg_reg);
10407 %}
10408 
10409 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10410   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10411 
10412   ins_cost(INSN_COST * 3);
10413   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10414 
10415   ins_encode %{
10416     __ smull(as_Register($dst$$reg),
10417              as_Register($src1$$reg),
10418              as_Register($src2$$reg));
10419   %}
10420 
10421   ins_pipe(imul_reg_reg);
10422 %}
10423 
10424 // Long Multiply
10425 
10426 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10427   match(Set dst (MulL src1 src2));
10428 
10429   ins_cost(INSN_COST * 5);
10430   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10431 
10432   ins_encode %{
10433     __ mul(as_Register($dst$$reg),
10434            as_Register($src1$$reg),
10435            as_Register($src2$$reg));
10436   %}
10437 
10438   ins_pipe(lmul_reg_reg);
10439 %}
10440 
10441 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10442 %{
10443   match(Set dst (MulHiL src1 src2));
10444 
10445   ins_cost(INSN_COST * 7);
10446   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10447 
10448   ins_encode %{
10449     __ smulh(as_Register($dst$$reg),
10450              as_Register($src1$$reg),
10451              as_Register($src2$$reg));
10452   %}
10453 
10454   ins_pipe(lmul_reg_reg);
10455 %}
10456 
10457 // Combined Integer Multiply &amp; Add/Sub
10458 
10459 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10460   match(Set dst (AddI src3 (MulI src1 src2)));
10461 
10462   ins_cost(INSN_COST * 3);
10463   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10464 
10465   ins_encode %{
10466     __ maddw(as_Register($dst$$reg),
10467              as_Register($src1$$reg),
10468              as_Register($src2$$reg),
10469              as_Register($src3$$reg));
10470   %}
10471 
10472   ins_pipe(imac_reg_reg);
10473 %}
10474 
10475 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10476   match(Set dst (SubI src3 (MulI src1 src2)));
10477 
10478   ins_cost(INSN_COST * 3);
10479   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10480 
10481   ins_encode %{
10482     __ msubw(as_Register($dst$$reg),
10483              as_Register($src1$$reg),
10484              as_Register($src2$$reg),
10485              as_Register($src3$$reg));
10486   %}
10487 
10488   ins_pipe(imac_reg_reg);
10489 %}
10490 
10491 // Combined Integer Multiply &amp; Neg
10492 
10493 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10494   match(Set dst (MulI (SubI zero src1) src2));
10495   match(Set dst (MulI src1 (SubI zero src2)));
10496 
10497   ins_cost(INSN_COST * 3);
10498   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10499 
10500   ins_encode %{
10501     __ mnegw(as_Register($dst$$reg),
10502              as_Register($src1$$reg),
10503              as_Register($src2$$reg));
10504   %}
10505 
10506   ins_pipe(imac_reg_reg);
10507 %}
10508 
10509 // Combined Long Multiply &amp; Add/Sub
10510 
10511 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10512   match(Set dst (AddL src3 (MulL src1 src2)));
10513 
10514   ins_cost(INSN_COST * 5);
10515   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10516 
10517   ins_encode %{
10518     __ madd(as_Register($dst$$reg),
10519             as_Register($src1$$reg),
10520             as_Register($src2$$reg),
10521             as_Register($src3$$reg));
10522   %}
10523 
10524   ins_pipe(lmac_reg_reg);
10525 %}
10526 
10527 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10528   match(Set dst (SubL src3 (MulL src1 src2)));
10529 
10530   ins_cost(INSN_COST * 5);
10531   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10532 
10533   ins_encode %{
10534     __ msub(as_Register($dst$$reg),
10535             as_Register($src1$$reg),
10536             as_Register($src2$$reg),
10537             as_Register($src3$$reg));
10538   %}
10539 
10540   ins_pipe(lmac_reg_reg);
10541 %}
10542 
10543 // Combined Long Multiply &amp; Neg
10544 
10545 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10546   match(Set dst (MulL (SubL zero src1) src2));
10547   match(Set dst (MulL src1 (SubL zero src2)));
10548 
10549   ins_cost(INSN_COST * 5);
10550   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10551 
10552   ins_encode %{
10553     __ mneg(as_Register($dst$$reg),
10554             as_Register($src1$$reg),
10555             as_Register($src2$$reg));
10556   %}
10557 
10558   ins_pipe(lmac_reg_reg);
10559 %}
10560 
10561 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10562 
10563 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10564   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10565 
10566   ins_cost(INSN_COST * 3);
10567   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10568 
10569   ins_encode %{
10570     __ smaddl(as_Register($dst$$reg),
10571               as_Register($src1$$reg),
10572               as_Register($src2$$reg),
10573               as_Register($src3$$reg));
10574   %}
10575 
10576   ins_pipe(imac_reg_reg);
10577 %}
10578 
10579 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10580   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10581 
10582   ins_cost(INSN_COST * 3);
10583   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10584 
10585   ins_encode %{
10586     __ smsubl(as_Register($dst$$reg),
10587               as_Register($src1$$reg),
10588               as_Register($src2$$reg),
10589               as_Register($src3$$reg));
10590   %}
10591 
10592   ins_pipe(imac_reg_reg);
10593 %}
10594 
10595 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10596   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10597   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10598 
10599   ins_cost(INSN_COST * 3);
10600   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10601 
10602   ins_encode %{
10603     __ smnegl(as_Register($dst$$reg),
10604               as_Register($src1$$reg),
10605               as_Register($src2$$reg));
10606   %}
10607 
10608   ins_pipe(imac_reg_reg);
10609 %}
10610 
10611 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10612 
10613 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10614   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10615 
10616   ins_cost(INSN_COST * 5);
10617   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10618             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10619 
10620   ins_encode %{
10621     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10622     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10623 
10624   ins_pipe(imac_reg_reg);
10625 %}
10626 
10627 // Integer Divide
10628 
10629 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10630   match(Set dst (DivI src1 src2));
10631 
10632   ins_cost(INSN_COST * 19);
10633   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10634 
10635   ins_encode(aarch64_enc_divw(dst, src1, src2));
10636   ins_pipe(idiv_reg_reg);
10637 %}
10638 
10639 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10640   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10641   ins_cost(INSN_COST);
10642   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10643   ins_encode %{
10644     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10645   %}
10646   ins_pipe(ialu_reg_shift);
10647 %}
10648 
10649 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10650   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10651   ins_cost(INSN_COST);
10652   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10653 
10654   ins_encode %{
10655     __ addw(as_Register($dst$$reg),
10656               as_Register($src$$reg),
10657               as_Register($src$$reg),
10658               Assembler::LSR, 31);
10659   %}
10660   ins_pipe(ialu_reg);
10661 %}
10662 
10663 // Long Divide
10664 
10665 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10666   match(Set dst (DivL src1 src2));
10667 
10668   ins_cost(INSN_COST * 35);
10669   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10670 
10671   ins_encode(aarch64_enc_div(dst, src1, src2));
10672   ins_pipe(ldiv_reg_reg);
10673 %}
10674 
10675 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10676   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10677   ins_cost(INSN_COST);
10678   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10679   ins_encode %{
10680     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10681   %}
10682   ins_pipe(ialu_reg_shift);
10683 %}
10684 
10685 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10686   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10687   ins_cost(INSN_COST);
10688   format %{ &quot;add $dst, $src, $div1&quot; %}
10689 
10690   ins_encode %{
10691     __ add(as_Register($dst$$reg),
10692               as_Register($src$$reg),
10693               as_Register($src$$reg),
10694               Assembler::LSR, 63);
10695   %}
10696   ins_pipe(ialu_reg);
10697 %}
10698 
10699 // Integer Remainder
10700 
10701 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10702   match(Set dst (ModI src1 src2));
10703 
10704   ins_cost(INSN_COST * 22);
10705   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10706             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10707 
10708   ins_encode(aarch64_enc_modw(dst, src1, src2));
10709   ins_pipe(idiv_reg_reg);
10710 %}
10711 
10712 // Long Remainder
10713 
10714 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10715   match(Set dst (ModL src1 src2));
10716 
10717   ins_cost(INSN_COST * 38);
10718   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10719             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10720 
10721   ins_encode(aarch64_enc_mod(dst, src1, src2));
10722   ins_pipe(ldiv_reg_reg);
10723 %}
10724 
10725 // Integer Shifts
10726 
10727 // Shift Left Register
10728 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10729   match(Set dst (LShiftI src1 src2));
10730 
10731   ins_cost(INSN_COST * 2);
10732   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10733 
10734   ins_encode %{
10735     __ lslvw(as_Register($dst$$reg),
10736              as_Register($src1$$reg),
10737              as_Register($src2$$reg));
10738   %}
10739 
10740   ins_pipe(ialu_reg_reg_vshift);
10741 %}
10742 
10743 // Shift Left Immediate
10744 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10745   match(Set dst (LShiftI src1 src2));
10746 
10747   ins_cost(INSN_COST);
10748   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10749 
10750   ins_encode %{
10751     __ lslw(as_Register($dst$$reg),
10752             as_Register($src1$$reg),
10753             $src2$$constant &amp; 0x1f);
10754   %}
10755 
10756   ins_pipe(ialu_reg_shift);
10757 %}
10758 
10759 // Shift Right Logical Register
10760 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10761   match(Set dst (URShiftI src1 src2));
10762 
10763   ins_cost(INSN_COST * 2);
10764   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10765 
10766   ins_encode %{
10767     __ lsrvw(as_Register($dst$$reg),
10768              as_Register($src1$$reg),
10769              as_Register($src2$$reg));
10770   %}
10771 
10772   ins_pipe(ialu_reg_reg_vshift);
10773 %}
10774 
10775 // Shift Right Logical Immediate
10776 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10777   match(Set dst (URShiftI src1 src2));
10778 
10779   ins_cost(INSN_COST);
10780   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10781 
10782   ins_encode %{
10783     __ lsrw(as_Register($dst$$reg),
10784             as_Register($src1$$reg),
10785             $src2$$constant &amp; 0x1f);
10786   %}
10787 
10788   ins_pipe(ialu_reg_shift);
10789 %}
10790 
10791 // Shift Right Arithmetic Register
10792 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10793   match(Set dst (RShiftI src1 src2));
10794 
10795   ins_cost(INSN_COST * 2);
10796   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10797 
10798   ins_encode %{
10799     __ asrvw(as_Register($dst$$reg),
10800              as_Register($src1$$reg),
10801              as_Register($src2$$reg));
10802   %}
10803 
10804   ins_pipe(ialu_reg_reg_vshift);
10805 %}
10806 
10807 // Shift Right Arithmetic Immediate
10808 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10809   match(Set dst (RShiftI src1 src2));
10810 
10811   ins_cost(INSN_COST);
10812   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10813 
10814   ins_encode %{
10815     __ asrw(as_Register($dst$$reg),
10816             as_Register($src1$$reg),
10817             $src2$$constant &amp; 0x1f);
10818   %}
10819 
10820   ins_pipe(ialu_reg_shift);
10821 %}
10822 
10823 // Combined Int Mask and Right Shift (using UBFM)
10824 // TODO
10825 
10826 // Long Shifts
10827 
10828 // Shift Left Register
10829 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10830   match(Set dst (LShiftL src1 src2));
10831 
10832   ins_cost(INSN_COST * 2);
10833   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10834 
10835   ins_encode %{
10836     __ lslv(as_Register($dst$$reg),
10837             as_Register($src1$$reg),
10838             as_Register($src2$$reg));
10839   %}
10840 
10841   ins_pipe(ialu_reg_reg_vshift);
10842 %}
10843 
10844 // Shift Left Immediate
10845 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10846   match(Set dst (LShiftL src1 src2));
10847 
10848   ins_cost(INSN_COST);
10849   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10850 
10851   ins_encode %{
10852     __ lsl(as_Register($dst$$reg),
10853             as_Register($src1$$reg),
10854             $src2$$constant &amp; 0x3f);
10855   %}
10856 
10857   ins_pipe(ialu_reg_shift);
10858 %}
10859 
10860 // Shift Right Logical Register
10861 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10862   match(Set dst (URShiftL src1 src2));
10863 
10864   ins_cost(INSN_COST * 2);
10865   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10866 
10867   ins_encode %{
10868     __ lsrv(as_Register($dst$$reg),
10869             as_Register($src1$$reg),
10870             as_Register($src2$$reg));
10871   %}
10872 
10873   ins_pipe(ialu_reg_reg_vshift);
10874 %}
10875 
10876 // Shift Right Logical Immediate
10877 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10878   match(Set dst (URShiftL src1 src2));
10879 
10880   ins_cost(INSN_COST);
10881   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10882 
10883   ins_encode %{
10884     __ lsr(as_Register($dst$$reg),
10885            as_Register($src1$$reg),
10886            $src2$$constant &amp; 0x3f);
10887   %}
10888 
10889   ins_pipe(ialu_reg_shift);
10890 %}
10891 
10892 // A special-case pattern for card table stores.
10893 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10894   match(Set dst (URShiftL (CastP2X src1) src2));
10895 
10896   ins_cost(INSN_COST);
10897   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10898 
10899   ins_encode %{
10900     __ lsr(as_Register($dst$$reg),
10901            as_Register($src1$$reg),
10902            $src2$$constant &amp; 0x3f);
10903   %}
10904 
10905   ins_pipe(ialu_reg_shift);
10906 %}
10907 
10908 // Shift Right Arithmetic Register
10909 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10910   match(Set dst (RShiftL src1 src2));
10911 
10912   ins_cost(INSN_COST * 2);
10913   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10914 
10915   ins_encode %{
10916     __ asrv(as_Register($dst$$reg),
10917             as_Register($src1$$reg),
10918             as_Register($src2$$reg));
10919   %}
10920 
10921   ins_pipe(ialu_reg_reg_vshift);
10922 %}
10923 
10924 // Shift Right Arithmetic Immediate
10925 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10926   match(Set dst (RShiftL src1 src2));
10927 
10928   ins_cost(INSN_COST);
10929   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10930 
10931   ins_encode %{
10932     __ asr(as_Register($dst$$reg),
10933            as_Register($src1$$reg),
10934            $src2$$constant &amp; 0x3f);
10935   %}
10936 
10937   ins_pipe(ialu_reg_shift);
10938 %}
10939 
10940 // BEGIN This section of the file is automatically generated. Do not edit --------------
10941 
10942 instruct regL_not_reg(iRegLNoSp dst,
10943                          iRegL src1, immL_M1 m1,
10944                          rFlagsReg cr) %{
10945   match(Set dst (XorL src1 m1));
10946   ins_cost(INSN_COST);
10947   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10948 
10949   ins_encode %{
10950     __ eon(as_Register($dst$$reg),
10951               as_Register($src1$$reg),
10952               zr,
10953               Assembler::LSL, 0);
10954   %}
10955 
10956   ins_pipe(ialu_reg);
10957 %}
10958 instruct regI_not_reg(iRegINoSp dst,
10959                          iRegIorL2I src1, immI_M1 m1,
10960                          rFlagsReg cr) %{
10961   match(Set dst (XorI src1 m1));
10962   ins_cost(INSN_COST);
10963   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10964 
10965   ins_encode %{
10966     __ eonw(as_Register($dst$$reg),
10967               as_Register($src1$$reg),
10968               zr,
10969               Assembler::LSL, 0);
10970   %}
10971 
10972   ins_pipe(ialu_reg);
10973 %}
10974 
10975 instruct AndI_reg_not_reg(iRegINoSp dst,
10976                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10977                          rFlagsReg cr) %{
10978   match(Set dst (AndI src1 (XorI src2 m1)));
10979   ins_cost(INSN_COST);
10980   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10981 
10982   ins_encode %{
10983     __ bicw(as_Register($dst$$reg),
10984               as_Register($src1$$reg),
10985               as_Register($src2$$reg),
10986               Assembler::LSL, 0);
10987   %}
10988 
10989   ins_pipe(ialu_reg_reg);
10990 %}
10991 
10992 instruct AndL_reg_not_reg(iRegLNoSp dst,
10993                          iRegL src1, iRegL src2, immL_M1 m1,
10994                          rFlagsReg cr) %{
10995   match(Set dst (AndL src1 (XorL src2 m1)));
10996   ins_cost(INSN_COST);
10997   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10998 
10999   ins_encode %{
11000     __ bic(as_Register($dst$$reg),
11001               as_Register($src1$$reg),
11002               as_Register($src2$$reg),
11003               Assembler::LSL, 0);
11004   %}
11005 
11006   ins_pipe(ialu_reg_reg);
11007 %}
11008 
11009 instruct OrI_reg_not_reg(iRegINoSp dst,
11010                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11011                          rFlagsReg cr) %{
11012   match(Set dst (OrI src1 (XorI src2 m1)));
11013   ins_cost(INSN_COST);
11014   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
11015 
11016   ins_encode %{
11017     __ ornw(as_Register($dst$$reg),
11018               as_Register($src1$$reg),
11019               as_Register($src2$$reg),
11020               Assembler::LSL, 0);
11021   %}
11022 
11023   ins_pipe(ialu_reg_reg);
11024 %}
11025 
11026 instruct OrL_reg_not_reg(iRegLNoSp dst,
11027                          iRegL src1, iRegL src2, immL_M1 m1,
11028                          rFlagsReg cr) %{
11029   match(Set dst (OrL src1 (XorL src2 m1)));
11030   ins_cost(INSN_COST);
11031   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
11032 
11033   ins_encode %{
11034     __ orn(as_Register($dst$$reg),
11035               as_Register($src1$$reg),
11036               as_Register($src2$$reg),
11037               Assembler::LSL, 0);
11038   %}
11039 
11040   ins_pipe(ialu_reg_reg);
11041 %}
11042 
11043 instruct XorI_reg_not_reg(iRegINoSp dst,
11044                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11045                          rFlagsReg cr) %{
11046   match(Set dst (XorI m1 (XorI src2 src1)));
11047   ins_cost(INSN_COST);
11048   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
11049 
11050   ins_encode %{
11051     __ eonw(as_Register($dst$$reg),
11052               as_Register($src1$$reg),
11053               as_Register($src2$$reg),
11054               Assembler::LSL, 0);
11055   %}
11056 
11057   ins_pipe(ialu_reg_reg);
11058 %}
11059 
11060 instruct XorL_reg_not_reg(iRegLNoSp dst,
11061                          iRegL src1, iRegL src2, immL_M1 m1,
11062                          rFlagsReg cr) %{
11063   match(Set dst (XorL m1 (XorL src2 src1)));
11064   ins_cost(INSN_COST);
11065   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11066 
11067   ins_encode %{
11068     __ eon(as_Register($dst$$reg),
11069               as_Register($src1$$reg),
11070               as_Register($src2$$reg),
11071               Assembler::LSL, 0);
11072   %}
11073 
11074   ins_pipe(ialu_reg_reg);
11075 %}
11076 
11077 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11078                          iRegIorL2I src1, iRegIorL2I src2,
11079                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11080   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11081   ins_cost(1.9 * INSN_COST);
11082   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11083 
11084   ins_encode %{
11085     __ bicw(as_Register($dst$$reg),
11086               as_Register($src1$$reg),
11087               as_Register($src2$$reg),
11088               Assembler::LSR,
11089               $src3$$constant &amp; 0x1f);
11090   %}
11091 
11092   ins_pipe(ialu_reg_reg_shift);
11093 %}
11094 
11095 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11096                          iRegL src1, iRegL src2,
11097                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11098   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11099   ins_cost(1.9 * INSN_COST);
11100   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11101 
11102   ins_encode %{
11103     __ bic(as_Register($dst$$reg),
11104               as_Register($src1$$reg),
11105               as_Register($src2$$reg),
11106               Assembler::LSR,
11107               $src3$$constant &amp; 0x3f);
11108   %}
11109 
11110   ins_pipe(ialu_reg_reg_shift);
11111 %}
11112 
11113 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11114                          iRegIorL2I src1, iRegIorL2I src2,
11115                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11116   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11117   ins_cost(1.9 * INSN_COST);
11118   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11119 
11120   ins_encode %{
11121     __ bicw(as_Register($dst$$reg),
11122               as_Register($src1$$reg),
11123               as_Register($src2$$reg),
11124               Assembler::ASR,
11125               $src3$$constant &amp; 0x1f);
11126   %}
11127 
11128   ins_pipe(ialu_reg_reg_shift);
11129 %}
11130 
11131 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11132                          iRegL src1, iRegL src2,
11133                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11134   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11135   ins_cost(1.9 * INSN_COST);
11136   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11137 
11138   ins_encode %{
11139     __ bic(as_Register($dst$$reg),
11140               as_Register($src1$$reg),
11141               as_Register($src2$$reg),
11142               Assembler::ASR,
11143               $src3$$constant &amp; 0x3f);
11144   %}
11145 
11146   ins_pipe(ialu_reg_reg_shift);
11147 %}
11148 
11149 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11150                          iRegIorL2I src1, iRegIorL2I src2,
11151                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11152   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11153   ins_cost(1.9 * INSN_COST);
11154   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11155 
11156   ins_encode %{
11157     __ bicw(as_Register($dst$$reg),
11158               as_Register($src1$$reg),
11159               as_Register($src2$$reg),
11160               Assembler::LSL,
11161               $src3$$constant &amp; 0x1f);
11162   %}
11163 
11164   ins_pipe(ialu_reg_reg_shift);
11165 %}
11166 
11167 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11168                          iRegL src1, iRegL src2,
11169                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11170   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11171   ins_cost(1.9 * INSN_COST);
11172   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11173 
11174   ins_encode %{
11175     __ bic(as_Register($dst$$reg),
11176               as_Register($src1$$reg),
11177               as_Register($src2$$reg),
11178               Assembler::LSL,
11179               $src3$$constant &amp; 0x3f);
11180   %}
11181 
11182   ins_pipe(ialu_reg_reg_shift);
11183 %}
11184 
11185 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11186                          iRegIorL2I src1, iRegIorL2I src2,
11187                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11188   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11189   ins_cost(1.9 * INSN_COST);
11190   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11191 
11192   ins_encode %{
11193     __ eonw(as_Register($dst$$reg),
11194               as_Register($src1$$reg),
11195               as_Register($src2$$reg),
11196               Assembler::LSR,
11197               $src3$$constant &amp; 0x1f);
11198   %}
11199 
11200   ins_pipe(ialu_reg_reg_shift);
11201 %}
11202 
11203 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11204                          iRegL src1, iRegL src2,
11205                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11206   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11207   ins_cost(1.9 * INSN_COST);
11208   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11209 
11210   ins_encode %{
11211     __ eon(as_Register($dst$$reg),
11212               as_Register($src1$$reg),
11213               as_Register($src2$$reg),
11214               Assembler::LSR,
11215               $src3$$constant &amp; 0x3f);
11216   %}
11217 
11218   ins_pipe(ialu_reg_reg_shift);
11219 %}
11220 
11221 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11222                          iRegIorL2I src1, iRegIorL2I src2,
11223                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11224   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11225   ins_cost(1.9 * INSN_COST);
11226   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11227 
11228   ins_encode %{
11229     __ eonw(as_Register($dst$$reg),
11230               as_Register($src1$$reg),
11231               as_Register($src2$$reg),
11232               Assembler::ASR,
11233               $src3$$constant &amp; 0x1f);
11234   %}
11235 
11236   ins_pipe(ialu_reg_reg_shift);
11237 %}
11238 
11239 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11240                          iRegL src1, iRegL src2,
11241                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11242   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11243   ins_cost(1.9 * INSN_COST);
11244   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11245 
11246   ins_encode %{
11247     __ eon(as_Register($dst$$reg),
11248               as_Register($src1$$reg),
11249               as_Register($src2$$reg),
11250               Assembler::ASR,
11251               $src3$$constant &amp; 0x3f);
11252   %}
11253 
11254   ins_pipe(ialu_reg_reg_shift);
11255 %}
11256 
11257 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11258                          iRegIorL2I src1, iRegIorL2I src2,
11259                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11260   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11261   ins_cost(1.9 * INSN_COST);
11262   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11263 
11264   ins_encode %{
11265     __ eonw(as_Register($dst$$reg),
11266               as_Register($src1$$reg),
11267               as_Register($src2$$reg),
11268               Assembler::LSL,
11269               $src3$$constant &amp; 0x1f);
11270   %}
11271 
11272   ins_pipe(ialu_reg_reg_shift);
11273 %}
11274 
11275 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11276                          iRegL src1, iRegL src2,
11277                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11278   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11279   ins_cost(1.9 * INSN_COST);
11280   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11281 
11282   ins_encode %{
11283     __ eon(as_Register($dst$$reg),
11284               as_Register($src1$$reg),
11285               as_Register($src2$$reg),
11286               Assembler::LSL,
11287               $src3$$constant &amp; 0x3f);
11288   %}
11289 
11290   ins_pipe(ialu_reg_reg_shift);
11291 %}
11292 
11293 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11294                          iRegIorL2I src1, iRegIorL2I src2,
11295                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11296   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11297   ins_cost(1.9 * INSN_COST);
11298   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11299 
11300   ins_encode %{
11301     __ ornw(as_Register($dst$$reg),
11302               as_Register($src1$$reg),
11303               as_Register($src2$$reg),
11304               Assembler::LSR,
11305               $src3$$constant &amp; 0x1f);
11306   %}
11307 
11308   ins_pipe(ialu_reg_reg_shift);
11309 %}
11310 
11311 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11312                          iRegL src1, iRegL src2,
11313                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11314   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11315   ins_cost(1.9 * INSN_COST);
11316   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11317 
11318   ins_encode %{
11319     __ orn(as_Register($dst$$reg),
11320               as_Register($src1$$reg),
11321               as_Register($src2$$reg),
11322               Assembler::LSR,
11323               $src3$$constant &amp; 0x3f);
11324   %}
11325 
11326   ins_pipe(ialu_reg_reg_shift);
11327 %}
11328 
11329 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11330                          iRegIorL2I src1, iRegIorL2I src2,
11331                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11332   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11333   ins_cost(1.9 * INSN_COST);
11334   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11335 
11336   ins_encode %{
11337     __ ornw(as_Register($dst$$reg),
11338               as_Register($src1$$reg),
11339               as_Register($src2$$reg),
11340               Assembler::ASR,
11341               $src3$$constant &amp; 0x1f);
11342   %}
11343 
11344   ins_pipe(ialu_reg_reg_shift);
11345 %}
11346 
11347 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11348                          iRegL src1, iRegL src2,
11349                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11350   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11351   ins_cost(1.9 * INSN_COST);
11352   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11353 
11354   ins_encode %{
11355     __ orn(as_Register($dst$$reg),
11356               as_Register($src1$$reg),
11357               as_Register($src2$$reg),
11358               Assembler::ASR,
11359               $src3$$constant &amp; 0x3f);
11360   %}
11361 
11362   ins_pipe(ialu_reg_reg_shift);
11363 %}
11364 
11365 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11366                          iRegIorL2I src1, iRegIorL2I src2,
11367                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11368   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11369   ins_cost(1.9 * INSN_COST);
11370   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11371 
11372   ins_encode %{
11373     __ ornw(as_Register($dst$$reg),
11374               as_Register($src1$$reg),
11375               as_Register($src2$$reg),
11376               Assembler::LSL,
11377               $src3$$constant &amp; 0x1f);
11378   %}
11379 
11380   ins_pipe(ialu_reg_reg_shift);
11381 %}
11382 
11383 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11384                          iRegL src1, iRegL src2,
11385                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11386   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11387   ins_cost(1.9 * INSN_COST);
11388   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11389 
11390   ins_encode %{
11391     __ orn(as_Register($dst$$reg),
11392               as_Register($src1$$reg),
11393               as_Register($src2$$reg),
11394               Assembler::LSL,
11395               $src3$$constant &amp; 0x3f);
11396   %}
11397 
11398   ins_pipe(ialu_reg_reg_shift);
11399 %}
11400 
11401 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11402                          iRegIorL2I src1, iRegIorL2I src2,
11403                          immI src3, rFlagsReg cr) %{
11404   match(Set dst (AndI src1 (URShiftI src2 src3)));
11405 
11406   ins_cost(1.9 * INSN_COST);
11407   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11408 
11409   ins_encode %{
11410     __ andw(as_Register($dst$$reg),
11411               as_Register($src1$$reg),
11412               as_Register($src2$$reg),
11413               Assembler::LSR,
11414               $src3$$constant &amp; 0x1f);
11415   %}
11416 
11417   ins_pipe(ialu_reg_reg_shift);
11418 %}
11419 
11420 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11421                          iRegL src1, iRegL src2,
11422                          immI src3, rFlagsReg cr) %{
11423   match(Set dst (AndL src1 (URShiftL src2 src3)));
11424 
11425   ins_cost(1.9 * INSN_COST);
11426   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11427 
11428   ins_encode %{
11429     __ andr(as_Register($dst$$reg),
11430               as_Register($src1$$reg),
11431               as_Register($src2$$reg),
11432               Assembler::LSR,
11433               $src3$$constant &amp; 0x3f);
11434   %}
11435 
11436   ins_pipe(ialu_reg_reg_shift);
11437 %}
11438 
11439 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11440                          iRegIorL2I src1, iRegIorL2I src2,
11441                          immI src3, rFlagsReg cr) %{
11442   match(Set dst (AndI src1 (RShiftI src2 src3)));
11443 
11444   ins_cost(1.9 * INSN_COST);
11445   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11446 
11447   ins_encode %{
11448     __ andw(as_Register($dst$$reg),
11449               as_Register($src1$$reg),
11450               as_Register($src2$$reg),
11451               Assembler::ASR,
11452               $src3$$constant &amp; 0x1f);
11453   %}
11454 
11455   ins_pipe(ialu_reg_reg_shift);
11456 %}
11457 
11458 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11459                          iRegL src1, iRegL src2,
11460                          immI src3, rFlagsReg cr) %{
11461   match(Set dst (AndL src1 (RShiftL src2 src3)));
11462 
11463   ins_cost(1.9 * INSN_COST);
11464   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11465 
11466   ins_encode %{
11467     __ andr(as_Register($dst$$reg),
11468               as_Register($src1$$reg),
11469               as_Register($src2$$reg),
11470               Assembler::ASR,
11471               $src3$$constant &amp; 0x3f);
11472   %}
11473 
11474   ins_pipe(ialu_reg_reg_shift);
11475 %}
11476 
11477 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11478                          iRegIorL2I src1, iRegIorL2I src2,
11479                          immI src3, rFlagsReg cr) %{
11480   match(Set dst (AndI src1 (LShiftI src2 src3)));
11481 
11482   ins_cost(1.9 * INSN_COST);
11483   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11484 
11485   ins_encode %{
11486     __ andw(as_Register($dst$$reg),
11487               as_Register($src1$$reg),
11488               as_Register($src2$$reg),
11489               Assembler::LSL,
11490               $src3$$constant &amp; 0x1f);
11491   %}
11492 
11493   ins_pipe(ialu_reg_reg_shift);
11494 %}
11495 
11496 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11497                          iRegL src1, iRegL src2,
11498                          immI src3, rFlagsReg cr) %{
11499   match(Set dst (AndL src1 (LShiftL src2 src3)));
11500 
11501   ins_cost(1.9 * INSN_COST);
11502   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11503 
11504   ins_encode %{
11505     __ andr(as_Register($dst$$reg),
11506               as_Register($src1$$reg),
11507               as_Register($src2$$reg),
11508               Assembler::LSL,
11509               $src3$$constant &amp; 0x3f);
11510   %}
11511 
11512   ins_pipe(ialu_reg_reg_shift);
11513 %}
11514 
11515 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11516                          iRegIorL2I src1, iRegIorL2I src2,
11517                          immI src3, rFlagsReg cr) %{
11518   match(Set dst (XorI src1 (URShiftI src2 src3)));
11519 
11520   ins_cost(1.9 * INSN_COST);
11521   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11522 
11523   ins_encode %{
11524     __ eorw(as_Register($dst$$reg),
11525               as_Register($src1$$reg),
11526               as_Register($src2$$reg),
11527               Assembler::LSR,
11528               $src3$$constant &amp; 0x1f);
11529   %}
11530 
11531   ins_pipe(ialu_reg_reg_shift);
11532 %}
11533 
11534 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11535                          iRegL src1, iRegL src2,
11536                          immI src3, rFlagsReg cr) %{
11537   match(Set dst (XorL src1 (URShiftL src2 src3)));
11538 
11539   ins_cost(1.9 * INSN_COST);
11540   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11541 
11542   ins_encode %{
11543     __ eor(as_Register($dst$$reg),
11544               as_Register($src1$$reg),
11545               as_Register($src2$$reg),
11546               Assembler::LSR,
11547               $src3$$constant &amp; 0x3f);
11548   %}
11549 
11550   ins_pipe(ialu_reg_reg_shift);
11551 %}
11552 
11553 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11554                          iRegIorL2I src1, iRegIorL2I src2,
11555                          immI src3, rFlagsReg cr) %{
11556   match(Set dst (XorI src1 (RShiftI src2 src3)));
11557 
11558   ins_cost(1.9 * INSN_COST);
11559   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11560 
11561   ins_encode %{
11562     __ eorw(as_Register($dst$$reg),
11563               as_Register($src1$$reg),
11564               as_Register($src2$$reg),
11565               Assembler::ASR,
11566               $src3$$constant &amp; 0x1f);
11567   %}
11568 
11569   ins_pipe(ialu_reg_reg_shift);
11570 %}
11571 
11572 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11573                          iRegL src1, iRegL src2,
11574                          immI src3, rFlagsReg cr) %{
11575   match(Set dst (XorL src1 (RShiftL src2 src3)));
11576 
11577   ins_cost(1.9 * INSN_COST);
11578   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11579 
11580   ins_encode %{
11581     __ eor(as_Register($dst$$reg),
11582               as_Register($src1$$reg),
11583               as_Register($src2$$reg),
11584               Assembler::ASR,
11585               $src3$$constant &amp; 0x3f);
11586   %}
11587 
11588   ins_pipe(ialu_reg_reg_shift);
11589 %}
11590 
11591 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11592                          iRegIorL2I src1, iRegIorL2I src2,
11593                          immI src3, rFlagsReg cr) %{
11594   match(Set dst (XorI src1 (LShiftI src2 src3)));
11595 
11596   ins_cost(1.9 * INSN_COST);
11597   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11598 
11599   ins_encode %{
11600     __ eorw(as_Register($dst$$reg),
11601               as_Register($src1$$reg),
11602               as_Register($src2$$reg),
11603               Assembler::LSL,
11604               $src3$$constant &amp; 0x1f);
11605   %}
11606 
11607   ins_pipe(ialu_reg_reg_shift);
11608 %}
11609 
11610 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11611                          iRegL src1, iRegL src2,
11612                          immI src3, rFlagsReg cr) %{
11613   match(Set dst (XorL src1 (LShiftL src2 src3)));
11614 
11615   ins_cost(1.9 * INSN_COST);
11616   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11617 
11618   ins_encode %{
11619     __ eor(as_Register($dst$$reg),
11620               as_Register($src1$$reg),
11621               as_Register($src2$$reg),
11622               Assembler::LSL,
11623               $src3$$constant &amp; 0x3f);
11624   %}
11625 
11626   ins_pipe(ialu_reg_reg_shift);
11627 %}
11628 
11629 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11630                          iRegIorL2I src1, iRegIorL2I src2,
11631                          immI src3, rFlagsReg cr) %{
11632   match(Set dst (OrI src1 (URShiftI src2 src3)));
11633 
11634   ins_cost(1.9 * INSN_COST);
11635   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11636 
11637   ins_encode %{
11638     __ orrw(as_Register($dst$$reg),
11639               as_Register($src1$$reg),
11640               as_Register($src2$$reg),
11641               Assembler::LSR,
11642               $src3$$constant &amp; 0x1f);
11643   %}
11644 
11645   ins_pipe(ialu_reg_reg_shift);
11646 %}
11647 
11648 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11649                          iRegL src1, iRegL src2,
11650                          immI src3, rFlagsReg cr) %{
11651   match(Set dst (OrL src1 (URShiftL src2 src3)));
11652 
11653   ins_cost(1.9 * INSN_COST);
11654   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11655 
11656   ins_encode %{
11657     __ orr(as_Register($dst$$reg),
11658               as_Register($src1$$reg),
11659               as_Register($src2$$reg),
11660               Assembler::LSR,
11661               $src3$$constant &amp; 0x3f);
11662   %}
11663 
11664   ins_pipe(ialu_reg_reg_shift);
11665 %}
11666 
11667 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11668                          iRegIorL2I src1, iRegIorL2I src2,
11669                          immI src3, rFlagsReg cr) %{
11670   match(Set dst (OrI src1 (RShiftI src2 src3)));
11671 
11672   ins_cost(1.9 * INSN_COST);
11673   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11674 
11675   ins_encode %{
11676     __ orrw(as_Register($dst$$reg),
11677               as_Register($src1$$reg),
11678               as_Register($src2$$reg),
11679               Assembler::ASR,
11680               $src3$$constant &amp; 0x1f);
11681   %}
11682 
11683   ins_pipe(ialu_reg_reg_shift);
11684 %}
11685 
11686 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11687                          iRegL src1, iRegL src2,
11688                          immI src3, rFlagsReg cr) %{
11689   match(Set dst (OrL src1 (RShiftL src2 src3)));
11690 
11691   ins_cost(1.9 * INSN_COST);
11692   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11693 
11694   ins_encode %{
11695     __ orr(as_Register($dst$$reg),
11696               as_Register($src1$$reg),
11697               as_Register($src2$$reg),
11698               Assembler::ASR,
11699               $src3$$constant &amp; 0x3f);
11700   %}
11701 
11702   ins_pipe(ialu_reg_reg_shift);
11703 %}
11704 
11705 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11706                          iRegIorL2I src1, iRegIorL2I src2,
11707                          immI src3, rFlagsReg cr) %{
11708   match(Set dst (OrI src1 (LShiftI src2 src3)));
11709 
11710   ins_cost(1.9 * INSN_COST);
11711   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11712 
11713   ins_encode %{
11714     __ orrw(as_Register($dst$$reg),
11715               as_Register($src1$$reg),
11716               as_Register($src2$$reg),
11717               Assembler::LSL,
11718               $src3$$constant &amp; 0x1f);
11719   %}
11720 
11721   ins_pipe(ialu_reg_reg_shift);
11722 %}
11723 
11724 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11725                          iRegL src1, iRegL src2,
11726                          immI src3, rFlagsReg cr) %{
11727   match(Set dst (OrL src1 (LShiftL src2 src3)));
11728 
11729   ins_cost(1.9 * INSN_COST);
11730   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11731 
11732   ins_encode %{
11733     __ orr(as_Register($dst$$reg),
11734               as_Register($src1$$reg),
11735               as_Register($src2$$reg),
11736               Assembler::LSL,
11737               $src3$$constant &amp; 0x3f);
11738   %}
11739 
11740   ins_pipe(ialu_reg_reg_shift);
11741 %}
11742 
11743 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11744                          iRegIorL2I src1, iRegIorL2I src2,
11745                          immI src3, rFlagsReg cr) %{
11746   match(Set dst (AddI src1 (URShiftI src2 src3)));
11747 
11748   ins_cost(1.9 * INSN_COST);
11749   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11750 
11751   ins_encode %{
11752     __ addw(as_Register($dst$$reg),
11753               as_Register($src1$$reg),
11754               as_Register($src2$$reg),
11755               Assembler::LSR,
11756               $src3$$constant &amp; 0x1f);
11757   %}
11758 
11759   ins_pipe(ialu_reg_reg_shift);
11760 %}
11761 
11762 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11763                          iRegL src1, iRegL src2,
11764                          immI src3, rFlagsReg cr) %{
11765   match(Set dst (AddL src1 (URShiftL src2 src3)));
11766 
11767   ins_cost(1.9 * INSN_COST);
11768   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11769 
11770   ins_encode %{
11771     __ add(as_Register($dst$$reg),
11772               as_Register($src1$$reg),
11773               as_Register($src2$$reg),
11774               Assembler::LSR,
11775               $src3$$constant &amp; 0x3f);
11776   %}
11777 
11778   ins_pipe(ialu_reg_reg_shift);
11779 %}
11780 
11781 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11782                          iRegIorL2I src1, iRegIorL2I src2,
11783                          immI src3, rFlagsReg cr) %{
11784   match(Set dst (AddI src1 (RShiftI src2 src3)));
11785 
11786   ins_cost(1.9 * INSN_COST);
11787   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11788 
11789   ins_encode %{
11790     __ addw(as_Register($dst$$reg),
11791               as_Register($src1$$reg),
11792               as_Register($src2$$reg),
11793               Assembler::ASR,
11794               $src3$$constant &amp; 0x1f);
11795   %}
11796 
11797   ins_pipe(ialu_reg_reg_shift);
11798 %}
11799 
11800 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11801                          iRegL src1, iRegL src2,
11802                          immI src3, rFlagsReg cr) %{
11803   match(Set dst (AddL src1 (RShiftL src2 src3)));
11804 
11805   ins_cost(1.9 * INSN_COST);
11806   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11807 
11808   ins_encode %{
11809     __ add(as_Register($dst$$reg),
11810               as_Register($src1$$reg),
11811               as_Register($src2$$reg),
11812               Assembler::ASR,
11813               $src3$$constant &amp; 0x3f);
11814   %}
11815 
11816   ins_pipe(ialu_reg_reg_shift);
11817 %}
11818 
11819 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11820                          iRegIorL2I src1, iRegIorL2I src2,
11821                          immI src3, rFlagsReg cr) %{
11822   match(Set dst (AddI src1 (LShiftI src2 src3)));
11823 
11824   ins_cost(1.9 * INSN_COST);
11825   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11826 
11827   ins_encode %{
11828     __ addw(as_Register($dst$$reg),
11829               as_Register($src1$$reg),
11830               as_Register($src2$$reg),
11831               Assembler::LSL,
11832               $src3$$constant &amp; 0x1f);
11833   %}
11834 
11835   ins_pipe(ialu_reg_reg_shift);
11836 %}
11837 
11838 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11839                          iRegL src1, iRegL src2,
11840                          immI src3, rFlagsReg cr) %{
11841   match(Set dst (AddL src1 (LShiftL src2 src3)));
11842 
11843   ins_cost(1.9 * INSN_COST);
11844   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11845 
11846   ins_encode %{
11847     __ add(as_Register($dst$$reg),
11848               as_Register($src1$$reg),
11849               as_Register($src2$$reg),
11850               Assembler::LSL,
11851               $src3$$constant &amp; 0x3f);
11852   %}
11853 
11854   ins_pipe(ialu_reg_reg_shift);
11855 %}
11856 
11857 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11858                          iRegIorL2I src1, iRegIorL2I src2,
11859                          immI src3, rFlagsReg cr) %{
11860   match(Set dst (SubI src1 (URShiftI src2 src3)));
11861 
11862   ins_cost(1.9 * INSN_COST);
11863   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11864 
11865   ins_encode %{
11866     __ subw(as_Register($dst$$reg),
11867               as_Register($src1$$reg),
11868               as_Register($src2$$reg),
11869               Assembler::LSR,
11870               $src3$$constant &amp; 0x1f);
11871   %}
11872 
11873   ins_pipe(ialu_reg_reg_shift);
11874 %}
11875 
11876 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11877                          iRegL src1, iRegL src2,
11878                          immI src3, rFlagsReg cr) %{
11879   match(Set dst (SubL src1 (URShiftL src2 src3)));
11880 
11881   ins_cost(1.9 * INSN_COST);
11882   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11883 
11884   ins_encode %{
11885     __ sub(as_Register($dst$$reg),
11886               as_Register($src1$$reg),
11887               as_Register($src2$$reg),
11888               Assembler::LSR,
11889               $src3$$constant &amp; 0x3f);
11890   %}
11891 
11892   ins_pipe(ialu_reg_reg_shift);
11893 %}
11894 
11895 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11896                          iRegIorL2I src1, iRegIorL2I src2,
11897                          immI src3, rFlagsReg cr) %{
11898   match(Set dst (SubI src1 (RShiftI src2 src3)));
11899 
11900   ins_cost(1.9 * INSN_COST);
11901   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11902 
11903   ins_encode %{
11904     __ subw(as_Register($dst$$reg),
11905               as_Register($src1$$reg),
11906               as_Register($src2$$reg),
11907               Assembler::ASR,
11908               $src3$$constant &amp; 0x1f);
11909   %}
11910 
11911   ins_pipe(ialu_reg_reg_shift);
11912 %}
11913 
11914 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11915                          iRegL src1, iRegL src2,
11916                          immI src3, rFlagsReg cr) %{
11917   match(Set dst (SubL src1 (RShiftL src2 src3)));
11918 
11919   ins_cost(1.9 * INSN_COST);
11920   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11921 
11922   ins_encode %{
11923     __ sub(as_Register($dst$$reg),
11924               as_Register($src1$$reg),
11925               as_Register($src2$$reg),
11926               Assembler::ASR,
11927               $src3$$constant &amp; 0x3f);
11928   %}
11929 
11930   ins_pipe(ialu_reg_reg_shift);
11931 %}
11932 
11933 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11934                          iRegIorL2I src1, iRegIorL2I src2,
11935                          immI src3, rFlagsReg cr) %{
11936   match(Set dst (SubI src1 (LShiftI src2 src3)));
11937 
11938   ins_cost(1.9 * INSN_COST);
11939   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11940 
11941   ins_encode %{
11942     __ subw(as_Register($dst$$reg),
11943               as_Register($src1$$reg),
11944               as_Register($src2$$reg),
11945               Assembler::LSL,
11946               $src3$$constant &amp; 0x1f);
11947   %}
11948 
11949   ins_pipe(ialu_reg_reg_shift);
11950 %}
11951 
11952 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11953                          iRegL src1, iRegL src2,
11954                          immI src3, rFlagsReg cr) %{
11955   match(Set dst (SubL src1 (LShiftL src2 src3)));
11956 
11957   ins_cost(1.9 * INSN_COST);
11958   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11959 
11960   ins_encode %{
11961     __ sub(as_Register($dst$$reg),
11962               as_Register($src1$$reg),
11963               as_Register($src2$$reg),
11964               Assembler::LSL,
11965               $src3$$constant &amp; 0x3f);
11966   %}
11967 
11968   ins_pipe(ialu_reg_reg_shift);
11969 %}
11970 
11971 
11972 
11973 // Shift Left followed by Shift Right.
11974 // This idiom is used by the compiler for the i2b bytecode etc.
11975 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11976 %{
11977   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11978   ins_cost(INSN_COST * 2);
11979   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11980   ins_encode %{
11981     int lshift = $lshift_count$$constant &amp; 63;
11982     int rshift = $rshift_count$$constant &amp; 63;
11983     int s = 63 - lshift;
11984     int r = (rshift - lshift) &amp; 63;
11985     __ sbfm(as_Register($dst$$reg),
11986             as_Register($src$$reg),
11987             r, s);
11988   %}
11989 
11990   ins_pipe(ialu_reg_shift);
11991 %}
11992 
11993 // Shift Left followed by Shift Right.
11994 // This idiom is used by the compiler for the i2b bytecode etc.
11995 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11996 %{
11997   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11998   ins_cost(INSN_COST * 2);
11999   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12000   ins_encode %{
12001     int lshift = $lshift_count$$constant &amp; 31;
12002     int rshift = $rshift_count$$constant &amp; 31;
12003     int s = 31 - lshift;
12004     int r = (rshift - lshift) &amp; 31;
12005     __ sbfmw(as_Register($dst$$reg),
12006             as_Register($src$$reg),
12007             r, s);
12008   %}
12009 
12010   ins_pipe(ialu_reg_shift);
12011 %}
12012 
12013 // Shift Left followed by Shift Right.
12014 // This idiom is used by the compiler for the i2b bytecode etc.
12015 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
12016 %{
12017   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
12018   ins_cost(INSN_COST * 2);
12019   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
12020   ins_encode %{
12021     int lshift = $lshift_count$$constant &amp; 63;
12022     int rshift = $rshift_count$$constant &amp; 63;
12023     int s = 63 - lshift;
12024     int r = (rshift - lshift) &amp; 63;
12025     __ ubfm(as_Register($dst$$reg),
12026             as_Register($src$$reg),
12027             r, s);
12028   %}
12029 
12030   ins_pipe(ialu_reg_shift);
12031 %}
12032 
12033 // Shift Left followed by Shift Right.
12034 // This idiom is used by the compiler for the i2b bytecode etc.
12035 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12036 %{
12037   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
12038   ins_cost(INSN_COST * 2);
12039   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12040   ins_encode %{
12041     int lshift = $lshift_count$$constant &amp; 31;
12042     int rshift = $rshift_count$$constant &amp; 31;
12043     int s = 31 - lshift;
12044     int r = (rshift - lshift) &amp; 31;
12045     __ ubfmw(as_Register($dst$$reg),
12046             as_Register($src$$reg),
12047             r, s);
12048   %}
12049 
12050   ins_pipe(ialu_reg_shift);
12051 %}
12052 // Bitfield extract with shift &amp; mask
12053 
12054 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12055 %{
12056   match(Set dst (AndI (URShiftI src rshift) mask));
12057   // Make sure we are not going to exceed what ubfxw can do.
12058   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12059 
12060   ins_cost(INSN_COST);
12061   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12062   ins_encode %{
12063     int rshift = $rshift$$constant &amp; 31;
12064     long mask = $mask$$constant;
12065     int width = exact_log2(mask+1);
12066     __ ubfxw(as_Register($dst$$reg),
12067             as_Register($src$$reg), rshift, width);
12068   %}
12069   ins_pipe(ialu_reg_shift);
12070 %}
12071 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12072 %{
12073   match(Set dst (AndL (URShiftL src rshift) mask));
12074   // Make sure we are not going to exceed what ubfx can do.
12075   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12076 
12077   ins_cost(INSN_COST);
12078   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12079   ins_encode %{
12080     int rshift = $rshift$$constant &amp; 63;
12081     long mask = $mask$$constant;
12082     int width = exact_log2_long(mask+1);
12083     __ ubfx(as_Register($dst$$reg),
12084             as_Register($src$$reg), rshift, width);
12085   %}
12086   ins_pipe(ialu_reg_shift);
12087 %}
12088 
12089 // We can use ubfx when extending an And with a mask when we know mask
12090 // is positive.  We know that because immI_bitmask guarantees it.
12091 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12092 %{
12093   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12094   // Make sure we are not going to exceed what ubfxw can do.
12095   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12096 
12097   ins_cost(INSN_COST * 2);
12098   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12099   ins_encode %{
12100     int rshift = $rshift$$constant &amp; 31;
12101     long mask = $mask$$constant;
12102     int width = exact_log2(mask+1);
12103     __ ubfx(as_Register($dst$$reg),
12104             as_Register($src$$reg), rshift, width);
12105   %}
12106   ins_pipe(ialu_reg_shift);
12107 %}
12108 
12109 // We can use ubfiz when masking by a positive number and then left shifting the result.
12110 // We know that the mask is positive because immI_bitmask guarantees it.
12111 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12112 %{
12113   match(Set dst (LShiftI (AndI src mask) lshift));
12114   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12115 
12116   ins_cost(INSN_COST);
12117   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12118   ins_encode %{
12119     int lshift = $lshift$$constant &amp; 31;
12120     long mask = $mask$$constant;
12121     int width = exact_log2(mask+1);
12122     __ ubfizw(as_Register($dst$$reg),
12123           as_Register($src$$reg), lshift, width);
12124   %}
12125   ins_pipe(ialu_reg_shift);
12126 %}
12127 // We can use ubfiz when masking by a positive number and then left shifting the result.
12128 // We know that the mask is positive because immL_bitmask guarantees it.
12129 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12130 %{
12131   match(Set dst (LShiftL (AndL src mask) lshift));
12132   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12133 
12134   ins_cost(INSN_COST);
12135   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12136   ins_encode %{
12137     int lshift = $lshift$$constant &amp; 63;
12138     long mask = $mask$$constant;
12139     int width = exact_log2_long(mask+1);
12140     __ ubfiz(as_Register($dst$$reg),
12141           as_Register($src$$reg), lshift, width);
12142   %}
12143   ins_pipe(ialu_reg_shift);
12144 %}
12145 
12146 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12147 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12148 %{
12149   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12150   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12151 
12152   ins_cost(INSN_COST);
12153   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12154   ins_encode %{
12155     int lshift = $lshift$$constant &amp; 63;
12156     long mask = $mask$$constant;
12157     int width = exact_log2(mask+1);
12158     __ ubfiz(as_Register($dst$$reg),
12159              as_Register($src$$reg), lshift, width);
12160   %}
12161   ins_pipe(ialu_reg_shift);
12162 %}
12163 
12164 // Rotations
12165 
12166 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12167 %{
12168   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12169   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12170 
12171   ins_cost(INSN_COST);
12172   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12173 
12174   ins_encode %{
12175     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12176             $rshift$$constant &amp; 63);
12177   %}
12178   ins_pipe(ialu_reg_reg_extr);
12179 %}
12180 
12181 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12182 %{
12183   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12184   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12185 
12186   ins_cost(INSN_COST);
12187   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12188 
12189   ins_encode %{
12190     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12191             $rshift$$constant &amp; 31);
12192   %}
12193   ins_pipe(ialu_reg_reg_extr);
12194 %}
12195 
12196 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12197 %{
12198   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12199   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12200 
12201   ins_cost(INSN_COST);
12202   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12203 
12204   ins_encode %{
12205     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12206             $rshift$$constant &amp; 63);
12207   %}
12208   ins_pipe(ialu_reg_reg_extr);
12209 %}
12210 
12211 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12212 %{
12213   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12214   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12215 
12216   ins_cost(INSN_COST);
12217   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12218 
12219   ins_encode %{
12220     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12221             $rshift$$constant &amp; 31);
12222   %}
12223   ins_pipe(ialu_reg_reg_extr);
12224 %}
12225 
12226 
12227 // rol expander
12228 
12229 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12230 %{
12231   effect(DEF dst, USE src, USE shift);
12232 
12233   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12234   ins_cost(INSN_COST * 3);
12235   ins_encode %{
12236     __ subw(rscratch1, zr, as_Register($shift$$reg));
12237     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12238             rscratch1);
12239     %}
12240   ins_pipe(ialu_reg_reg_vshift);
12241 %}
12242 
12243 // rol expander
12244 
12245 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12246 %{
12247   effect(DEF dst, USE src, USE shift);
12248 
12249   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12250   ins_cost(INSN_COST * 3);
12251   ins_encode %{
12252     __ subw(rscratch1, zr, as_Register($shift$$reg));
12253     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12254             rscratch1);
12255     %}
12256   ins_pipe(ialu_reg_reg_vshift);
12257 %}
12258 
12259 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12260 %{
12261   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12262 
12263   expand %{
12264     rolL_rReg(dst, src, shift, cr);
12265   %}
12266 %}
12267 
12268 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12269 %{
12270   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12271 
12272   expand %{
12273     rolL_rReg(dst, src, shift, cr);
12274   %}
12275 %}
12276 
12277 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12278 %{
12279   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12280 
12281   expand %{
12282     rolI_rReg(dst, src, shift, cr);
12283   %}
12284 %}
12285 
12286 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12287 %{
12288   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12289 
12290   expand %{
12291     rolI_rReg(dst, src, shift, cr);
12292   %}
12293 %}
12294 
12295 // ror expander
12296 
12297 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12298 %{
12299   effect(DEF dst, USE src, USE shift);
12300 
12301   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12302   ins_cost(INSN_COST);
12303   ins_encode %{
12304     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12305             as_Register($shift$$reg));
12306     %}
12307   ins_pipe(ialu_reg_reg_vshift);
12308 %}
12309 
12310 // ror expander
12311 
12312 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12313 %{
12314   effect(DEF dst, USE src, USE shift);
12315 
12316   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12317   ins_cost(INSN_COST);
12318   ins_encode %{
12319     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12320             as_Register($shift$$reg));
12321     %}
12322   ins_pipe(ialu_reg_reg_vshift);
12323 %}
12324 
12325 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12326 %{
12327   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12328 
12329   expand %{
12330     rorL_rReg(dst, src, shift, cr);
12331   %}
12332 %}
12333 
12334 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12335 %{
12336   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12337 
12338   expand %{
12339     rorL_rReg(dst, src, shift, cr);
12340   %}
12341 %}
12342 
12343 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12344 %{
12345   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12346 
12347   expand %{
12348     rorI_rReg(dst, src, shift, cr);
12349   %}
12350 %}
12351 
12352 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12353 %{
12354   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12355 
12356   expand %{
12357     rorI_rReg(dst, src, shift, cr);
12358   %}
12359 %}
12360 
12361 // Add/subtract (extended)
12362 
12363 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12364 %{
12365   match(Set dst (AddL src1 (ConvI2L src2)));
12366   ins_cost(INSN_COST);
12367   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12368 
12369    ins_encode %{
12370      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12371             as_Register($src2$$reg), ext::sxtw);
12372    %}
12373   ins_pipe(ialu_reg_reg);
12374 %};
12375 
12376 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12377 %{
12378   match(Set dst (SubL src1 (ConvI2L src2)));
12379   ins_cost(INSN_COST);
12380   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12381 
12382    ins_encode %{
12383      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12384             as_Register($src2$$reg), ext::sxtw);
12385    %}
12386   ins_pipe(ialu_reg_reg);
12387 %};
12388 
12389 
12390 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12391 %{
12392   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12393   ins_cost(INSN_COST);
12394   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12395 
12396    ins_encode %{
12397      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12398             as_Register($src2$$reg), ext::sxth);
12399    %}
12400   ins_pipe(ialu_reg_reg);
12401 %}
12402 
12403 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12404 %{
12405   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12406   ins_cost(INSN_COST);
12407   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12408 
12409    ins_encode %{
12410      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12411             as_Register($src2$$reg), ext::sxtb);
12412    %}
12413   ins_pipe(ialu_reg_reg);
12414 %}
12415 
12416 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12417 %{
12418   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12419   ins_cost(INSN_COST);
12420   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12421 
12422    ins_encode %{
12423      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12424             as_Register($src2$$reg), ext::uxtb);
12425    %}
12426   ins_pipe(ialu_reg_reg);
12427 %}
12428 
12429 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12430 %{
12431   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12432   ins_cost(INSN_COST);
12433   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12434 
12435    ins_encode %{
12436      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12437             as_Register($src2$$reg), ext::sxth);
12438    %}
12439   ins_pipe(ialu_reg_reg);
12440 %}
12441 
12442 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12443 %{
12444   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12445   ins_cost(INSN_COST);
12446   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12447 
12448    ins_encode %{
12449      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12450             as_Register($src2$$reg), ext::sxtw);
12451    %}
12452   ins_pipe(ialu_reg_reg);
12453 %}
12454 
12455 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12456 %{
12457   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12458   ins_cost(INSN_COST);
12459   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12460 
12461    ins_encode %{
12462      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12463             as_Register($src2$$reg), ext::sxtb);
12464    %}
12465   ins_pipe(ialu_reg_reg);
12466 %}
12467 
12468 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12469 %{
12470   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12471   ins_cost(INSN_COST);
12472   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12473 
12474    ins_encode %{
12475      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12476             as_Register($src2$$reg), ext::uxtb);
12477    %}
12478   ins_pipe(ialu_reg_reg);
12479 %}
12480 
12481 
12482 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12483 %{
12484   match(Set dst (AddI src1 (AndI src2 mask)));
12485   ins_cost(INSN_COST);
12486   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12487 
12488    ins_encode %{
12489      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12490             as_Register($src2$$reg), ext::uxtb);
12491    %}
12492   ins_pipe(ialu_reg_reg);
12493 %}
12494 
12495 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12496 %{
12497   match(Set dst (AddI src1 (AndI src2 mask)));
12498   ins_cost(INSN_COST);
12499   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12500 
12501    ins_encode %{
12502      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12503             as_Register($src2$$reg), ext::uxth);
12504    %}
12505   ins_pipe(ialu_reg_reg);
12506 %}
12507 
12508 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12509 %{
12510   match(Set dst (AddL src1 (AndL src2 mask)));
12511   ins_cost(INSN_COST);
12512   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12513 
12514    ins_encode %{
12515      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12516             as_Register($src2$$reg), ext::uxtb);
12517    %}
12518   ins_pipe(ialu_reg_reg);
12519 %}
12520 
12521 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12522 %{
12523   match(Set dst (AddL src1 (AndL src2 mask)));
12524   ins_cost(INSN_COST);
12525   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12526 
12527    ins_encode %{
12528      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12529             as_Register($src2$$reg), ext::uxth);
12530    %}
12531   ins_pipe(ialu_reg_reg);
12532 %}
12533 
12534 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12535 %{
12536   match(Set dst (AddL src1 (AndL src2 mask)));
12537   ins_cost(INSN_COST);
12538   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12539 
12540    ins_encode %{
12541      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12542             as_Register($src2$$reg), ext::uxtw);
12543    %}
12544   ins_pipe(ialu_reg_reg);
12545 %}
12546 
12547 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12548 %{
12549   match(Set dst (SubI src1 (AndI src2 mask)));
12550   ins_cost(INSN_COST);
12551   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12552 
12553    ins_encode %{
12554      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12555             as_Register($src2$$reg), ext::uxtb);
12556    %}
12557   ins_pipe(ialu_reg_reg);
12558 %}
12559 
12560 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12561 %{
12562   match(Set dst (SubI src1 (AndI src2 mask)));
12563   ins_cost(INSN_COST);
12564   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12565 
12566    ins_encode %{
12567      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12568             as_Register($src2$$reg), ext::uxth);
12569    %}
12570   ins_pipe(ialu_reg_reg);
12571 %}
12572 
12573 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12574 %{
12575   match(Set dst (SubL src1 (AndL src2 mask)));
12576   ins_cost(INSN_COST);
12577   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12578 
12579    ins_encode %{
12580      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12581             as_Register($src2$$reg), ext::uxtb);
12582    %}
12583   ins_pipe(ialu_reg_reg);
12584 %}
12585 
12586 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12587 %{
12588   match(Set dst (SubL src1 (AndL src2 mask)));
12589   ins_cost(INSN_COST);
12590   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12591 
12592    ins_encode %{
12593      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12594             as_Register($src2$$reg), ext::uxth);
12595    %}
12596   ins_pipe(ialu_reg_reg);
12597 %}
12598 
12599 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12600 %{
12601   match(Set dst (SubL src1 (AndL src2 mask)));
12602   ins_cost(INSN_COST);
12603   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12604 
12605    ins_encode %{
12606      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12607             as_Register($src2$$reg), ext::uxtw);
12608    %}
12609   ins_pipe(ialu_reg_reg);
12610 %}
12611 
12612 
12613 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12614 %{
12615   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12616   ins_cost(1.9 * INSN_COST);
12617   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12618 
12619    ins_encode %{
12620      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12621             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12622    %}
12623   ins_pipe(ialu_reg_reg_shift);
12624 %}
12625 
12626 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12627 %{
12628   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12629   ins_cost(1.9 * INSN_COST);
12630   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12631 
12632    ins_encode %{
12633      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12634             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12635    %}
12636   ins_pipe(ialu_reg_reg_shift);
12637 %}
12638 
12639 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12640 %{
12641   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12642   ins_cost(1.9 * INSN_COST);
12643   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12644 
12645    ins_encode %{
12646      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12647             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12648    %}
12649   ins_pipe(ialu_reg_reg_shift);
12650 %}
12651 
12652 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12653 %{
12654   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12655   ins_cost(1.9 * INSN_COST);
12656   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12657 
12658    ins_encode %{
12659      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12660             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12661    %}
12662   ins_pipe(ialu_reg_reg_shift);
12663 %}
12664 
12665 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12666 %{
12667   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12668   ins_cost(1.9 * INSN_COST);
12669   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12670 
12671    ins_encode %{
12672      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12673             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12674    %}
12675   ins_pipe(ialu_reg_reg_shift);
12676 %}
12677 
12678 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12679 %{
12680   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12681   ins_cost(1.9 * INSN_COST);
12682   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12683 
12684    ins_encode %{
12685      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12686             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12687    %}
12688   ins_pipe(ialu_reg_reg_shift);
12689 %}
12690 
12691 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12692 %{
12693   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12694   ins_cost(1.9 * INSN_COST);
12695   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12696 
12697    ins_encode %{
12698      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12699             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12700    %}
12701   ins_pipe(ialu_reg_reg_shift);
12702 %}
12703 
12704 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12705 %{
12706   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12707   ins_cost(1.9 * INSN_COST);
12708   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12709 
12710    ins_encode %{
12711      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12712             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12713    %}
12714   ins_pipe(ialu_reg_reg_shift);
12715 %}
12716 
12717 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12718 %{
12719   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12720   ins_cost(1.9 * INSN_COST);
12721   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12722 
12723    ins_encode %{
12724      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12725             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12726    %}
12727   ins_pipe(ialu_reg_reg_shift);
12728 %}
12729 
12730 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12731 %{
12732   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12733   ins_cost(1.9 * INSN_COST);
12734   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12735 
12736    ins_encode %{
12737      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12738             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12739    %}
12740   ins_pipe(ialu_reg_reg_shift);
12741 %}
12742 
12743 
12744 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12745 %{
12746   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12747   ins_cost(1.9 * INSN_COST);
12748   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12749 
12750    ins_encode %{
12751      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12752             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12753    %}
12754   ins_pipe(ialu_reg_reg_shift);
12755 %};
12756 
12757 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12758 %{
12759   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12760   ins_cost(1.9 * INSN_COST);
12761   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12762 
12763    ins_encode %{
12764      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12765             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12766    %}
12767   ins_pipe(ialu_reg_reg_shift);
12768 %};
12769 
12770 
12771 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12772 %{
12773   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12774   ins_cost(1.9 * INSN_COST);
12775   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12776 
12777    ins_encode %{
12778      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12779             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12780    %}
12781   ins_pipe(ialu_reg_reg_shift);
12782 %}
12783 
12784 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12785 %{
12786   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12787   ins_cost(1.9 * INSN_COST);
12788   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12789 
12790    ins_encode %{
12791      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12792             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12793    %}
12794   ins_pipe(ialu_reg_reg_shift);
12795 %}
12796 
12797 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12798 %{
12799   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12800   ins_cost(1.9 * INSN_COST);
12801   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12802 
12803    ins_encode %{
12804      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12805             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12806    %}
12807   ins_pipe(ialu_reg_reg_shift);
12808 %}
12809 
12810 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12811 %{
12812   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12813   ins_cost(1.9 * INSN_COST);
12814   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12815 
12816    ins_encode %{
12817      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12818             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12819    %}
12820   ins_pipe(ialu_reg_reg_shift);
12821 %}
12822 
12823 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12824 %{
12825   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12826   ins_cost(1.9 * INSN_COST);
12827   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12828 
12829    ins_encode %{
12830      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12831             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12832    %}
12833   ins_pipe(ialu_reg_reg_shift);
12834 %}
12835 
12836 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12837 %{
12838   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12839   ins_cost(1.9 * INSN_COST);
12840   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12841 
12842    ins_encode %{
12843      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12844             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12845    %}
12846   ins_pipe(ialu_reg_reg_shift);
12847 %}
12848 
12849 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12850 %{
12851   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12852   ins_cost(1.9 * INSN_COST);
12853   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12854 
12855    ins_encode %{
12856      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12857             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12858    %}
12859   ins_pipe(ialu_reg_reg_shift);
12860 %}
12861 
12862 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12863 %{
12864   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12865   ins_cost(1.9 * INSN_COST);
12866   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12867 
12868    ins_encode %{
12869      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12870             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12871    %}
12872   ins_pipe(ialu_reg_reg_shift);
12873 %}
12874 
12875 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12876 %{
12877   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12878   ins_cost(1.9 * INSN_COST);
12879   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12880 
12881    ins_encode %{
12882      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12883             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12884    %}
12885   ins_pipe(ialu_reg_reg_shift);
12886 %}
12887 
12888 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12889 %{
12890   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12891   ins_cost(1.9 * INSN_COST);
12892   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12893 
12894    ins_encode %{
12895      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12896             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12897    %}
12898   ins_pipe(ialu_reg_reg_shift);
12899 %}
12900 // END This section of the file is automatically generated. Do not edit --------------
12901 
12902 // ============================================================================
12903 // Floating Point Arithmetic Instructions
12904 
12905 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12906   match(Set dst (AddF src1 src2));
12907 
12908   ins_cost(INSN_COST * 5);
12909   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12910 
12911   ins_encode %{
12912     __ fadds(as_FloatRegister($dst$$reg),
12913              as_FloatRegister($src1$$reg),
12914              as_FloatRegister($src2$$reg));
12915   %}
12916 
12917   ins_pipe(fp_dop_reg_reg_s);
12918 %}
12919 
12920 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12921   match(Set dst (AddD src1 src2));
12922 
12923   ins_cost(INSN_COST * 5);
12924   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12925 
12926   ins_encode %{
12927     __ faddd(as_FloatRegister($dst$$reg),
12928              as_FloatRegister($src1$$reg),
12929              as_FloatRegister($src2$$reg));
12930   %}
12931 
12932   ins_pipe(fp_dop_reg_reg_d);
12933 %}
12934 
12935 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12936   match(Set dst (SubF src1 src2));
12937 
12938   ins_cost(INSN_COST * 5);
12939   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12940 
12941   ins_encode %{
12942     __ fsubs(as_FloatRegister($dst$$reg),
12943              as_FloatRegister($src1$$reg),
12944              as_FloatRegister($src2$$reg));
12945   %}
12946 
12947   ins_pipe(fp_dop_reg_reg_s);
12948 %}
12949 
12950 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12951   match(Set dst (SubD src1 src2));
12952 
12953   ins_cost(INSN_COST * 5);
12954   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12955 
12956   ins_encode %{
12957     __ fsubd(as_FloatRegister($dst$$reg),
12958              as_FloatRegister($src1$$reg),
12959              as_FloatRegister($src2$$reg));
12960   %}
12961 
12962   ins_pipe(fp_dop_reg_reg_d);
12963 %}
12964 
12965 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12966   match(Set dst (MulF src1 src2));
12967 
12968   ins_cost(INSN_COST * 6);
12969   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12970 
12971   ins_encode %{
12972     __ fmuls(as_FloatRegister($dst$$reg),
12973              as_FloatRegister($src1$$reg),
12974              as_FloatRegister($src2$$reg));
12975   %}
12976 
12977   ins_pipe(fp_dop_reg_reg_s);
12978 %}
12979 
12980 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12981   match(Set dst (MulD src1 src2));
12982 
12983   ins_cost(INSN_COST * 6);
12984   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12985 
12986   ins_encode %{
12987     __ fmuld(as_FloatRegister($dst$$reg),
12988              as_FloatRegister($src1$$reg),
12989              as_FloatRegister($src2$$reg));
12990   %}
12991 
12992   ins_pipe(fp_dop_reg_reg_d);
12993 %}
12994 
12995 // src1 * src2 + src3
12996 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12997   predicate(UseFMA);
12998   match(Set dst (FmaF src3 (Binary src1 src2)));
12999 
13000   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
13001 
13002   ins_encode %{
13003     __ fmadds(as_FloatRegister($dst$$reg),
13004              as_FloatRegister($src1$$reg),
13005              as_FloatRegister($src2$$reg),
13006              as_FloatRegister($src3$$reg));
13007   %}
13008 
13009   ins_pipe(pipe_class_default);
13010 %}
13011 
13012 // src1 * src2 + src3
13013 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13014   predicate(UseFMA);
13015   match(Set dst (FmaD src3 (Binary src1 src2)));
13016 
13017   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
13018 
13019   ins_encode %{
13020     __ fmaddd(as_FloatRegister($dst$$reg),
13021              as_FloatRegister($src1$$reg),
13022              as_FloatRegister($src2$$reg),
13023              as_FloatRegister($src3$$reg));
13024   %}
13025 
13026   ins_pipe(pipe_class_default);
13027 %}
13028 
13029 // -src1 * src2 + src3
13030 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13031   predicate(UseFMA);
13032   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
13033   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
13034 
13035   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
13036 
13037   ins_encode %{
13038     __ fmsubs(as_FloatRegister($dst$$reg),
13039               as_FloatRegister($src1$$reg),
13040               as_FloatRegister($src2$$reg),
13041               as_FloatRegister($src3$$reg));
13042   %}
13043 
13044   ins_pipe(pipe_class_default);
13045 %}
13046 
13047 // -src1 * src2 + src3
13048 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13049   predicate(UseFMA);
13050   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
13051   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
13052 
13053   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13054 
13055   ins_encode %{
13056     __ fmsubd(as_FloatRegister($dst$$reg),
13057               as_FloatRegister($src1$$reg),
13058               as_FloatRegister($src2$$reg),
13059               as_FloatRegister($src3$$reg));
13060   %}
13061 
13062   ins_pipe(pipe_class_default);
13063 %}
13064 
13065 // -src1 * src2 - src3
13066 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13067   predicate(UseFMA);
13068   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13069   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13070 
13071   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13072 
13073   ins_encode %{
13074     __ fnmadds(as_FloatRegister($dst$$reg),
13075                as_FloatRegister($src1$$reg),
13076                as_FloatRegister($src2$$reg),
13077                as_FloatRegister($src3$$reg));
13078   %}
13079 
13080   ins_pipe(pipe_class_default);
13081 %}
13082 
13083 // -src1 * src2 - src3
13084 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13085   predicate(UseFMA);
13086   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13087   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13088 
13089   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13090 
13091   ins_encode %{
13092     __ fnmaddd(as_FloatRegister($dst$$reg),
13093                as_FloatRegister($src1$$reg),
13094                as_FloatRegister($src2$$reg),
13095                as_FloatRegister($src3$$reg));
13096   %}
13097 
13098   ins_pipe(pipe_class_default);
13099 %}
13100 
13101 // src1 * src2 - src3
13102 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13103   predicate(UseFMA);
13104   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13105 
13106   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13107 
13108   ins_encode %{
13109     __ fnmsubs(as_FloatRegister($dst$$reg),
13110                as_FloatRegister($src1$$reg),
13111                as_FloatRegister($src2$$reg),
13112                as_FloatRegister($src3$$reg));
13113   %}
13114 
13115   ins_pipe(pipe_class_default);
13116 %}
13117 
13118 // src1 * src2 - src3
13119 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13120   predicate(UseFMA);
13121   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13122 
13123   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13124 
13125   ins_encode %{
13126   // n.b. insn name should be fnmsubd
13127     __ fnmsub(as_FloatRegister($dst$$reg),
13128               as_FloatRegister($src1$$reg),
13129               as_FloatRegister($src2$$reg),
13130               as_FloatRegister($src3$$reg));
13131   %}
13132 
13133   ins_pipe(pipe_class_default);
13134 %}
13135 
13136 
13137 // Math.max(FF)F
13138 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13139   match(Set dst (MaxF src1 src2));
13140 
13141   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13142   ins_encode %{
13143     __ fmaxs(as_FloatRegister($dst$$reg),
13144              as_FloatRegister($src1$$reg),
13145              as_FloatRegister($src2$$reg));
13146   %}
13147 
13148   ins_pipe(fp_dop_reg_reg_s);
13149 %}
13150 
13151 // Math.min(FF)F
13152 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13153   match(Set dst (MinF src1 src2));
13154 
13155   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13156   ins_encode %{
13157     __ fmins(as_FloatRegister($dst$$reg),
13158              as_FloatRegister($src1$$reg),
13159              as_FloatRegister($src2$$reg));
13160   %}
13161 
13162   ins_pipe(fp_dop_reg_reg_s);
13163 %}
13164 
13165 // Math.max(DD)D
13166 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13167   match(Set dst (MaxD src1 src2));
13168 
13169   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13170   ins_encode %{
13171     __ fmaxd(as_FloatRegister($dst$$reg),
13172              as_FloatRegister($src1$$reg),
13173              as_FloatRegister($src2$$reg));
13174   %}
13175 
13176   ins_pipe(fp_dop_reg_reg_d);
13177 %}
13178 
13179 // Math.min(DD)D
13180 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13181   match(Set dst (MinD src1 src2));
13182 
13183   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13184   ins_encode %{
13185     __ fmind(as_FloatRegister($dst$$reg),
13186              as_FloatRegister($src1$$reg),
13187              as_FloatRegister($src2$$reg));
13188   %}
13189 
13190   ins_pipe(fp_dop_reg_reg_d);
13191 %}
13192 
13193 
13194 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13195   match(Set dst (DivF src1  src2));
13196 
13197   ins_cost(INSN_COST * 18);
13198   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13199 
13200   ins_encode %{
13201     __ fdivs(as_FloatRegister($dst$$reg),
13202              as_FloatRegister($src1$$reg),
13203              as_FloatRegister($src2$$reg));
13204   %}
13205 
13206   ins_pipe(fp_div_s);
13207 %}
13208 
13209 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13210   match(Set dst (DivD src1  src2));
13211 
13212   ins_cost(INSN_COST * 32);
13213   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13214 
13215   ins_encode %{
13216     __ fdivd(as_FloatRegister($dst$$reg),
13217              as_FloatRegister($src1$$reg),
13218              as_FloatRegister($src2$$reg));
13219   %}
13220 
13221   ins_pipe(fp_div_d);
13222 %}
13223 
13224 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13225   match(Set dst (NegF src));
13226 
13227   ins_cost(INSN_COST * 3);
13228   format %{ &quot;fneg   $dst, $src&quot; %}
13229 
13230   ins_encode %{
13231     __ fnegs(as_FloatRegister($dst$$reg),
13232              as_FloatRegister($src$$reg));
13233   %}
13234 
13235   ins_pipe(fp_uop_s);
13236 %}
13237 
13238 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13239   match(Set dst (NegD src));
13240 
13241   ins_cost(INSN_COST * 3);
13242   format %{ &quot;fnegd   $dst, $src&quot; %}
13243 
13244   ins_encode %{
13245     __ fnegd(as_FloatRegister($dst$$reg),
13246              as_FloatRegister($src$$reg));
13247   %}
13248 
13249   ins_pipe(fp_uop_d);
13250 %}
13251 
13252 instruct absF_reg(vRegF dst, vRegF src) %{
13253   match(Set dst (AbsF src));
13254 
13255   ins_cost(INSN_COST * 3);
13256   format %{ &quot;fabss   $dst, $src&quot; %}
13257   ins_encode %{
13258     __ fabss(as_FloatRegister($dst$$reg),
13259              as_FloatRegister($src$$reg));
13260   %}
13261 
13262   ins_pipe(fp_uop_s);
13263 %}
13264 
13265 instruct absD_reg(vRegD dst, vRegD src) %{
13266   match(Set dst (AbsD src));
13267 
13268   ins_cost(INSN_COST * 3);
13269   format %{ &quot;fabsd   $dst, $src&quot; %}
13270   ins_encode %{
13271     __ fabsd(as_FloatRegister($dst$$reg),
13272              as_FloatRegister($src$$reg));
13273   %}
13274 
13275   ins_pipe(fp_uop_d);
13276 %}
13277 
13278 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13279   match(Set dst (SqrtD src));
13280 
13281   ins_cost(INSN_COST * 50);
13282   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13283   ins_encode %{
13284     __ fsqrtd(as_FloatRegister($dst$$reg),
13285              as_FloatRegister($src$$reg));
13286   %}
13287 
13288   ins_pipe(fp_div_s);
13289 %}
13290 
13291 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13292   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13293 
13294   ins_cost(INSN_COST * 50);
13295   format %{ &quot;fsqrts  $dst, $src&quot; %}
13296   ins_encode %{
13297     __ fsqrts(as_FloatRegister($dst$$reg),
13298              as_FloatRegister($src$$reg));
13299   %}
13300 
13301   ins_pipe(fp_div_d);
13302 %}
13303 
13304 // Math.rint, floor, ceil
13305 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13306   match(Set dst (RoundDoubleMode src rmode));
13307   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13308   ins_encode %{
13309     switch ($rmode$$constant) {
13310       case RoundDoubleModeNode::rmode_rint:
13311         __ frintnd(as_FloatRegister($dst$$reg),
13312                    as_FloatRegister($src$$reg));
13313         break;
13314       case RoundDoubleModeNode::rmode_floor:
13315         __ frintmd(as_FloatRegister($dst$$reg),
13316                    as_FloatRegister($src$$reg));
13317         break;
13318       case RoundDoubleModeNode::rmode_ceil:
13319         __ frintpd(as_FloatRegister($dst$$reg),
13320                    as_FloatRegister($src$$reg));
13321         break;
13322     }
13323   %}
13324   ins_pipe(fp_uop_d);
13325 %}
13326 
13327 // ============================================================================
13328 // Logical Instructions
13329 
13330 // Integer Logical Instructions
13331 
13332 // And Instructions
13333 
13334 
13335 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13336   match(Set dst (AndI src1 src2));
13337 
13338   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13339 
13340   ins_cost(INSN_COST);
13341   ins_encode %{
13342     __ andw(as_Register($dst$$reg),
13343             as_Register($src1$$reg),
13344             as_Register($src2$$reg));
13345   %}
13346 
13347   ins_pipe(ialu_reg_reg);
13348 %}
13349 
13350 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13351   match(Set dst (AndI src1 src2));
13352 
13353   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13354 
13355   ins_cost(INSN_COST);
13356   ins_encode %{
13357     __ andw(as_Register($dst$$reg),
13358             as_Register($src1$$reg),
13359             (unsigned long)($src2$$constant));
13360   %}
13361 
13362   ins_pipe(ialu_reg_imm);
13363 %}
13364 
13365 // Or Instructions
13366 
13367 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13368   match(Set dst (OrI src1 src2));
13369 
13370   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13371 
13372   ins_cost(INSN_COST);
13373   ins_encode %{
13374     __ orrw(as_Register($dst$$reg),
13375             as_Register($src1$$reg),
13376             as_Register($src2$$reg));
13377   %}
13378 
13379   ins_pipe(ialu_reg_reg);
13380 %}
13381 
13382 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13383   match(Set dst (OrI src1 src2));
13384 
13385   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13386 
13387   ins_cost(INSN_COST);
13388   ins_encode %{
13389     __ orrw(as_Register($dst$$reg),
13390             as_Register($src1$$reg),
13391             (unsigned long)($src2$$constant));
13392   %}
13393 
13394   ins_pipe(ialu_reg_imm);
13395 %}
13396 
13397 // Xor Instructions
13398 
13399 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13400   match(Set dst (XorI src1 src2));
13401 
13402   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13403 
13404   ins_cost(INSN_COST);
13405   ins_encode %{
13406     __ eorw(as_Register($dst$$reg),
13407             as_Register($src1$$reg),
13408             as_Register($src2$$reg));
13409   %}
13410 
13411   ins_pipe(ialu_reg_reg);
13412 %}
13413 
13414 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13415   match(Set dst (XorI src1 src2));
13416 
13417   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13418 
13419   ins_cost(INSN_COST);
13420   ins_encode %{
13421     __ eorw(as_Register($dst$$reg),
13422             as_Register($src1$$reg),
13423             (unsigned long)($src2$$constant));
13424   %}
13425 
13426   ins_pipe(ialu_reg_imm);
13427 %}
13428 
13429 // Long Logical Instructions
13430 // TODO
13431 
13432 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13433   match(Set dst (AndL src1 src2));
13434 
13435   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13436 
13437   ins_cost(INSN_COST);
13438   ins_encode %{
13439     __ andr(as_Register($dst$$reg),
13440             as_Register($src1$$reg),
13441             as_Register($src2$$reg));
13442   %}
13443 
13444   ins_pipe(ialu_reg_reg);
13445 %}
13446 
13447 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13448   match(Set dst (AndL src1 src2));
13449 
13450   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13451 
13452   ins_cost(INSN_COST);
13453   ins_encode %{
13454     __ andr(as_Register($dst$$reg),
13455             as_Register($src1$$reg),
13456             (unsigned long)($src2$$constant));
13457   %}
13458 
13459   ins_pipe(ialu_reg_imm);
13460 %}
13461 
13462 // Or Instructions
13463 
13464 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13465   match(Set dst (OrL src1 src2));
13466 
13467   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13468 
13469   ins_cost(INSN_COST);
13470   ins_encode %{
13471     __ orr(as_Register($dst$$reg),
13472            as_Register($src1$$reg),
13473            as_Register($src2$$reg));
13474   %}
13475 
13476   ins_pipe(ialu_reg_reg);
13477 %}
13478 
13479 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13480   match(Set dst (OrL src1 src2));
13481 
13482   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13483 
13484   ins_cost(INSN_COST);
13485   ins_encode %{
13486     __ orr(as_Register($dst$$reg),
13487            as_Register($src1$$reg),
13488            (unsigned long)($src2$$constant));
13489   %}
13490 
13491   ins_pipe(ialu_reg_imm);
13492 %}
13493 
13494 // Xor Instructions
13495 
13496 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13497   match(Set dst (XorL src1 src2));
13498 
13499   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13500 
13501   ins_cost(INSN_COST);
13502   ins_encode %{
13503     __ eor(as_Register($dst$$reg),
13504            as_Register($src1$$reg),
13505            as_Register($src2$$reg));
13506   %}
13507 
13508   ins_pipe(ialu_reg_reg);
13509 %}
13510 
13511 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13512   match(Set dst (XorL src1 src2));
13513 
13514   ins_cost(INSN_COST);
13515   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13516 
13517   ins_encode %{
13518     __ eor(as_Register($dst$$reg),
13519            as_Register($src1$$reg),
13520            (unsigned long)($src2$$constant));
13521   %}
13522 
13523   ins_pipe(ialu_reg_imm);
13524 %}
13525 
13526 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13527 %{
13528   match(Set dst (ConvI2L src));
13529 
13530   ins_cost(INSN_COST);
13531   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13532   ins_encode %{
13533     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13534   %}
13535   ins_pipe(ialu_reg_shift);
13536 %}
13537 
13538 // this pattern occurs in bigmath arithmetic
13539 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13540 %{
13541   match(Set dst (AndL (ConvI2L src) mask));
13542 
13543   ins_cost(INSN_COST);
13544   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13545   ins_encode %{
13546     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13547   %}
13548 
13549   ins_pipe(ialu_reg_shift);
13550 %}
13551 
13552 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13553   match(Set dst (ConvL2I src));
13554 
13555   ins_cost(INSN_COST);
13556   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13557 
13558   ins_encode %{
13559     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13560   %}
13561 
13562   ins_pipe(ialu_reg);
13563 %}
13564 
13565 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13566 %{
13567   match(Set dst (Conv2B src));
13568   effect(KILL cr);
13569 
13570   format %{
13571     &quot;cmpw $src, zr\n\t&quot;
13572     &quot;cset $dst, ne&quot;
13573   %}
13574 
13575   ins_encode %{
13576     __ cmpw(as_Register($src$$reg), zr);
13577     __ cset(as_Register($dst$$reg), Assembler::NE);
13578   %}
13579 
13580   ins_pipe(ialu_reg);
13581 %}
13582 
13583 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13584 %{
13585   match(Set dst (Conv2B src));
13586   effect(KILL cr);
13587 
13588   format %{
13589     &quot;cmp  $src, zr\n\t&quot;
13590     &quot;cset $dst, ne&quot;
13591   %}
13592 
13593   ins_encode %{
13594     __ cmp(as_Register($src$$reg), zr);
13595     __ cset(as_Register($dst$$reg), Assembler::NE);
13596   %}
13597 
13598   ins_pipe(ialu_reg);
13599 %}
13600 
13601 instruct convD2F_reg(vRegF dst, vRegD src) %{
13602   match(Set dst (ConvD2F src));
13603 
13604   ins_cost(INSN_COST * 5);
13605   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13606 
13607   ins_encode %{
13608     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13609   %}
13610 
13611   ins_pipe(fp_d2f);
13612 %}
13613 
13614 instruct convF2D_reg(vRegD dst, vRegF src) %{
13615   match(Set dst (ConvF2D src));
13616 
13617   ins_cost(INSN_COST * 5);
13618   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13619 
13620   ins_encode %{
13621     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13622   %}
13623 
13624   ins_pipe(fp_f2d);
13625 %}
13626 
13627 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13628   match(Set dst (ConvF2I src));
13629 
13630   ins_cost(INSN_COST * 5);
13631   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13632 
13633   ins_encode %{
13634     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13635   %}
13636 
13637   ins_pipe(fp_f2i);
13638 %}
13639 
13640 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13641   match(Set dst (ConvF2L src));
13642 
13643   ins_cost(INSN_COST * 5);
13644   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13645 
13646   ins_encode %{
13647     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13648   %}
13649 
13650   ins_pipe(fp_f2l);
13651 %}
13652 
13653 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13654   match(Set dst (ConvI2F src));
13655 
13656   ins_cost(INSN_COST * 5);
13657   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13658 
13659   ins_encode %{
13660     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13661   %}
13662 
13663   ins_pipe(fp_i2f);
13664 %}
13665 
13666 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13667   match(Set dst (ConvL2F src));
13668 
13669   ins_cost(INSN_COST * 5);
13670   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13671 
13672   ins_encode %{
13673     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13674   %}
13675 
13676   ins_pipe(fp_l2f);
13677 %}
13678 
13679 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13680   match(Set dst (ConvD2I src));
13681 
13682   ins_cost(INSN_COST * 5);
13683   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13684 
13685   ins_encode %{
13686     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13687   %}
13688 
13689   ins_pipe(fp_d2i);
13690 %}
13691 
13692 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13693   match(Set dst (ConvD2L src));
13694 
13695   ins_cost(INSN_COST * 5);
13696   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13697 
13698   ins_encode %{
13699     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13700   %}
13701 
13702   ins_pipe(fp_d2l);
13703 %}
13704 
13705 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13706   match(Set dst (ConvI2D src));
13707 
13708   ins_cost(INSN_COST * 5);
13709   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13710 
13711   ins_encode %{
13712     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13713   %}
13714 
13715   ins_pipe(fp_i2d);
13716 %}
13717 
13718 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13719   match(Set dst (ConvL2D src));
13720 
13721   ins_cost(INSN_COST * 5);
13722   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13723 
13724   ins_encode %{
13725     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13726   %}
13727 
13728   ins_pipe(fp_l2d);
13729 %}
13730 
13731 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13732 
13733 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13734 
13735   match(Set dst (MoveF2I src));
13736 
13737   effect(DEF dst, USE src);
13738 
13739   ins_cost(4 * INSN_COST);
13740 
13741   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13742 
13743   ins_encode %{
13744     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13745   %}
13746 
13747   ins_pipe(iload_reg_reg);
13748 
13749 %}
13750 
13751 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13752 
13753   match(Set dst (MoveI2F src));
13754 
13755   effect(DEF dst, USE src);
13756 
13757   ins_cost(4 * INSN_COST);
13758 
13759   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13760 
13761   ins_encode %{
13762     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13763   %}
13764 
13765   ins_pipe(pipe_class_memory);
13766 
13767 %}
13768 
13769 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13770 
13771   match(Set dst (MoveD2L src));
13772 
13773   effect(DEF dst, USE src);
13774 
13775   ins_cost(4 * INSN_COST);
13776 
13777   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13778 
13779   ins_encode %{
13780     __ ldr($dst$$Register, Address(sp, $src$$disp));
13781   %}
13782 
13783   ins_pipe(iload_reg_reg);
13784 
13785 %}
13786 
13787 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13788 
13789   match(Set dst (MoveL2D src));
13790 
13791   effect(DEF dst, USE src);
13792 
13793   ins_cost(4 * INSN_COST);
13794 
13795   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13796 
13797   ins_encode %{
13798     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13799   %}
13800 
13801   ins_pipe(pipe_class_memory);
13802 
13803 %}
13804 
13805 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13806 
13807   match(Set dst (MoveF2I src));
13808 
13809   effect(DEF dst, USE src);
13810 
13811   ins_cost(INSN_COST);
13812 
13813   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13814 
13815   ins_encode %{
13816     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13817   %}
13818 
13819   ins_pipe(pipe_class_memory);
13820 
13821 %}
13822 
13823 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13824 
13825   match(Set dst (MoveI2F src));
13826 
13827   effect(DEF dst, USE src);
13828 
13829   ins_cost(INSN_COST);
13830 
13831   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13832 
13833   ins_encode %{
13834     __ strw($src$$Register, Address(sp, $dst$$disp));
13835   %}
13836 
13837   ins_pipe(istore_reg_reg);
13838 
13839 %}
13840 
13841 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13842 
13843   match(Set dst (MoveD2L src));
13844 
13845   effect(DEF dst, USE src);
13846 
13847   ins_cost(INSN_COST);
13848 
13849   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13850 
13851   ins_encode %{
13852     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13853   %}
13854 
13855   ins_pipe(pipe_class_memory);
13856 
13857 %}
13858 
13859 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13860 
13861   match(Set dst (MoveL2D src));
13862 
13863   effect(DEF dst, USE src);
13864 
13865   ins_cost(INSN_COST);
13866 
13867   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13868 
13869   ins_encode %{
13870     __ str($src$$Register, Address(sp, $dst$$disp));
13871   %}
13872 
13873   ins_pipe(istore_reg_reg);
13874 
13875 %}
13876 
13877 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13878 
13879   match(Set dst (MoveF2I src));
13880 
13881   effect(DEF dst, USE src);
13882 
13883   ins_cost(INSN_COST);
13884 
13885   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13886 
13887   ins_encode %{
13888     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13889   %}
13890 
13891   ins_pipe(fp_f2i);
13892 
13893 %}
13894 
13895 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13896 
13897   match(Set dst (MoveI2F src));
13898 
13899   effect(DEF dst, USE src);
13900 
13901   ins_cost(INSN_COST);
13902 
13903   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13904 
13905   ins_encode %{
13906     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13907   %}
13908 
13909   ins_pipe(fp_i2f);
13910 
13911 %}
13912 
13913 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13914 
13915   match(Set dst (MoveD2L src));
13916 
13917   effect(DEF dst, USE src);
13918 
13919   ins_cost(INSN_COST);
13920 
13921   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13922 
13923   ins_encode %{
13924     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13925   %}
13926 
13927   ins_pipe(fp_d2l);
13928 
13929 %}
13930 
13931 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13932 
13933   match(Set dst (MoveL2D src));
13934 
13935   effect(DEF dst, USE src);
13936 
13937   ins_cost(INSN_COST);
13938 
13939   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13940 
13941   ins_encode %{
13942     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13943   %}
13944 
13945   ins_pipe(fp_l2d);
13946 
13947 %}
13948 
13949 // ============================================================================
13950 // clearing of an array
13951 
<a name="10" id="anc10"></a><span class="line-modified">13952 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)</span>
13953 %{
<a name="11" id="anc11"></a><span class="line-modified">13954   match(Set dummy (ClearArray (Binary cnt base) val));</span>
13955   effect(USE_KILL cnt, USE_KILL base);
13956 
13957   ins_cost(4 * INSN_COST);
<a name="12" id="anc12"></a><span class="line-modified">13958   format %{ &quot;ClearArray $cnt, $base, $val&quot; %}</span>

















13959 
13960   ins_encode %{
<a name="13" id="anc13"></a><span class="line-modified">13961     __ fill_words($base$$Register, $cnt$$Register, $val$$Register);</span>
13962   %}
13963 
13964   ins_pipe(pipe_class_memory);
13965 %}
13966 
13967 // ============================================================================
13968 // Overflow Math Instructions
13969 
13970 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13971 %{
13972   match(Set cr (OverflowAddI op1 op2));
13973 
13974   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13975   ins_cost(INSN_COST);
13976   ins_encode %{
13977     __ cmnw($op1$$Register, $op2$$Register);
13978   %}
13979 
13980   ins_pipe(icmp_reg_reg);
13981 %}
13982 
13983 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13984 %{
13985   match(Set cr (OverflowAddI op1 op2));
13986 
13987   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13988   ins_cost(INSN_COST);
13989   ins_encode %{
13990     __ cmnw($op1$$Register, $op2$$constant);
13991   %}
13992 
13993   ins_pipe(icmp_reg_imm);
13994 %}
13995 
13996 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13997 %{
13998   match(Set cr (OverflowAddL op1 op2));
13999 
14000   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14001   ins_cost(INSN_COST);
14002   ins_encode %{
14003     __ cmn($op1$$Register, $op2$$Register);
14004   %}
14005 
14006   ins_pipe(icmp_reg_reg);
14007 %}
14008 
14009 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14010 %{
14011   match(Set cr (OverflowAddL op1 op2));
14012 
14013   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14014   ins_cost(INSN_COST);
14015   ins_encode %{
14016     __ cmn($op1$$Register, $op2$$constant);
14017   %}
14018 
14019   ins_pipe(icmp_reg_imm);
14020 %}
14021 
14022 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14023 %{
14024   match(Set cr (OverflowSubI op1 op2));
14025 
14026   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14027   ins_cost(INSN_COST);
14028   ins_encode %{
14029     __ cmpw($op1$$Register, $op2$$Register);
14030   %}
14031 
14032   ins_pipe(icmp_reg_reg);
14033 %}
14034 
14035 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14036 %{
14037   match(Set cr (OverflowSubI op1 op2));
14038 
14039   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14040   ins_cost(INSN_COST);
14041   ins_encode %{
14042     __ cmpw($op1$$Register, $op2$$constant);
14043   %}
14044 
14045   ins_pipe(icmp_reg_imm);
14046 %}
14047 
14048 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14049 %{
14050   match(Set cr (OverflowSubL op1 op2));
14051 
14052   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14053   ins_cost(INSN_COST);
14054   ins_encode %{
14055     __ cmp($op1$$Register, $op2$$Register);
14056   %}
14057 
14058   ins_pipe(icmp_reg_reg);
14059 %}
14060 
14061 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14062 %{
14063   match(Set cr (OverflowSubL op1 op2));
14064 
14065   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14066   ins_cost(INSN_COST);
14067   ins_encode %{
14068     __ subs(zr, $op1$$Register, $op2$$constant);
14069   %}
14070 
14071   ins_pipe(icmp_reg_imm);
14072 %}
14073 
14074 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14075 %{
14076   match(Set cr (OverflowSubI zero op1));
14077 
14078   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14079   ins_cost(INSN_COST);
14080   ins_encode %{
14081     __ cmpw(zr, $op1$$Register);
14082   %}
14083 
14084   ins_pipe(icmp_reg_imm);
14085 %}
14086 
14087 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14088 %{
14089   match(Set cr (OverflowSubL zero op1));
14090 
14091   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14092   ins_cost(INSN_COST);
14093   ins_encode %{
14094     __ cmp(zr, $op1$$Register);
14095   %}
14096 
14097   ins_pipe(icmp_reg_imm);
14098 %}
14099 
14100 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14101 %{
14102   match(Set cr (OverflowMulI op1 op2));
14103 
14104   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14105             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14106             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14107             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14108             &quot;cmpw  rscratch1, #1&quot; %}
14109   ins_cost(5 * INSN_COST);
14110   ins_encode %{
14111     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14112     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14113     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14114     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14115     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14116   %}
14117 
14118   ins_pipe(pipe_slow);
14119 %}
14120 
14121 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14122 %{
14123   match(If cmp (OverflowMulI op1 op2));
14124   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14125             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14126   effect(USE labl, KILL cr);
14127 
14128   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14129             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14130             &quot;b$cmp   $labl&quot; %}
14131   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14132   ins_encode %{
14133     Label* L = $labl$$label;
14134     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14135     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14136     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14137     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14138   %}
14139 
14140   ins_pipe(pipe_serial);
14141 %}
14142 
14143 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14144 %{
14145   match(Set cr (OverflowMulL op1 op2));
14146 
14147   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14148             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14149             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14150             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14151             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14152             &quot;cmpw  rscratch1, #1&quot; %}
14153   ins_cost(6 * INSN_COST);
14154   ins_encode %{
14155     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14156     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14157     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14158     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14159     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14160     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14161   %}
14162 
14163   ins_pipe(pipe_slow);
14164 %}
14165 
14166 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14167 %{
14168   match(If cmp (OverflowMulL op1 op2));
14169   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14170             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14171   effect(USE labl, KILL cr);
14172 
14173   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14174             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14175             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14176             &quot;b$cmp $labl&quot; %}
14177   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14178   ins_encode %{
14179     Label* L = $labl$$label;
14180     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14181     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14182     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14183     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14184     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14185   %}
14186 
14187   ins_pipe(pipe_serial);
14188 %}
14189 
14190 // ============================================================================
14191 // Compare Instructions
14192 
14193 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14194 %{
14195   match(Set cr (CmpI op1 op2));
14196 
14197   effect(DEF cr, USE op1, USE op2);
14198 
14199   ins_cost(INSN_COST);
14200   format %{ &quot;cmpw  $op1, $op2&quot; %}
14201 
14202   ins_encode(aarch64_enc_cmpw(op1, op2));
14203 
14204   ins_pipe(icmp_reg_reg);
14205 %}
14206 
14207 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14208 %{
14209   match(Set cr (CmpI op1 zero));
14210 
14211   effect(DEF cr, USE op1);
14212 
14213   ins_cost(INSN_COST);
14214   format %{ &quot;cmpw $op1, 0&quot; %}
14215 
14216   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14217 
14218   ins_pipe(icmp_reg_imm);
14219 %}
14220 
14221 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14222 %{
14223   match(Set cr (CmpI op1 op2));
14224 
14225   effect(DEF cr, USE op1);
14226 
14227   ins_cost(INSN_COST);
14228   format %{ &quot;cmpw  $op1, $op2&quot; %}
14229 
14230   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14231 
14232   ins_pipe(icmp_reg_imm);
14233 %}
14234 
14235 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14236 %{
14237   match(Set cr (CmpI op1 op2));
14238 
14239   effect(DEF cr, USE op1);
14240 
14241   ins_cost(INSN_COST * 2);
14242   format %{ &quot;cmpw  $op1, $op2&quot; %}
14243 
14244   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14245 
14246   ins_pipe(icmp_reg_imm);
14247 %}
14248 
14249 // Unsigned compare Instructions; really, same as signed compare
14250 // except it should only be used to feed an If or a CMovI which takes a
14251 // cmpOpU.
14252 
14253 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14254 %{
14255   match(Set cr (CmpU op1 op2));
14256 
14257   effect(DEF cr, USE op1, USE op2);
14258 
14259   ins_cost(INSN_COST);
14260   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14261 
14262   ins_encode(aarch64_enc_cmpw(op1, op2));
14263 
14264   ins_pipe(icmp_reg_reg);
14265 %}
14266 
14267 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14268 %{
14269   match(Set cr (CmpU op1 zero));
14270 
14271   effect(DEF cr, USE op1);
14272 
14273   ins_cost(INSN_COST);
14274   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14275 
14276   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14277 
14278   ins_pipe(icmp_reg_imm);
14279 %}
14280 
14281 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14282 %{
14283   match(Set cr (CmpU op1 op2));
14284 
14285   effect(DEF cr, USE op1);
14286 
14287   ins_cost(INSN_COST);
14288   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14289 
14290   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14291 
14292   ins_pipe(icmp_reg_imm);
14293 %}
14294 
14295 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14296 %{
14297   match(Set cr (CmpU op1 op2));
14298 
14299   effect(DEF cr, USE op1);
14300 
14301   ins_cost(INSN_COST * 2);
14302   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14303 
14304   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14305 
14306   ins_pipe(icmp_reg_imm);
14307 %}
14308 
14309 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14310 %{
14311   match(Set cr (CmpL op1 op2));
14312 
14313   effect(DEF cr, USE op1, USE op2);
14314 
14315   ins_cost(INSN_COST);
14316   format %{ &quot;cmp  $op1, $op2&quot; %}
14317 
14318   ins_encode(aarch64_enc_cmp(op1, op2));
14319 
14320   ins_pipe(icmp_reg_reg);
14321 %}
14322 
14323 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14324 %{
14325   match(Set cr (CmpL op1 zero));
14326 
14327   effect(DEF cr, USE op1);
14328 
14329   ins_cost(INSN_COST);
14330   format %{ &quot;tst  $op1&quot; %}
14331 
14332   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14333 
14334   ins_pipe(icmp_reg_imm);
14335 %}
14336 
14337 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14338 %{
14339   match(Set cr (CmpL op1 op2));
14340 
14341   effect(DEF cr, USE op1);
14342 
14343   ins_cost(INSN_COST);
14344   format %{ &quot;cmp  $op1, $op2&quot; %}
14345 
14346   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14347 
14348   ins_pipe(icmp_reg_imm);
14349 %}
14350 
14351 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14352 %{
14353   match(Set cr (CmpL op1 op2));
14354 
14355   effect(DEF cr, USE op1);
14356 
14357   ins_cost(INSN_COST * 2);
14358   format %{ &quot;cmp  $op1, $op2&quot; %}
14359 
14360   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14361 
14362   ins_pipe(icmp_reg_imm);
14363 %}
14364 
14365 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14366 %{
14367   match(Set cr (CmpUL op1 op2));
14368 
14369   effect(DEF cr, USE op1, USE op2);
14370 
14371   ins_cost(INSN_COST);
14372   format %{ &quot;cmp  $op1, $op2&quot; %}
14373 
14374   ins_encode(aarch64_enc_cmp(op1, op2));
14375 
14376   ins_pipe(icmp_reg_reg);
14377 %}
14378 
14379 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14380 %{
14381   match(Set cr (CmpUL op1 zero));
14382 
14383   effect(DEF cr, USE op1);
14384 
14385   ins_cost(INSN_COST);
14386   format %{ &quot;tst  $op1&quot; %}
14387 
14388   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14389 
14390   ins_pipe(icmp_reg_imm);
14391 %}
14392 
14393 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14394 %{
14395   match(Set cr (CmpUL op1 op2));
14396 
14397   effect(DEF cr, USE op1);
14398 
14399   ins_cost(INSN_COST);
14400   format %{ &quot;cmp  $op1, $op2&quot; %}
14401 
14402   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14403 
14404   ins_pipe(icmp_reg_imm);
14405 %}
14406 
14407 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14408 %{
14409   match(Set cr (CmpUL op1 op2));
14410 
14411   effect(DEF cr, USE op1);
14412 
14413   ins_cost(INSN_COST * 2);
14414   format %{ &quot;cmp  $op1, $op2&quot; %}
14415 
14416   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14417 
14418   ins_pipe(icmp_reg_imm);
14419 %}
14420 
14421 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14422 %{
14423   match(Set cr (CmpP op1 op2));
14424 
14425   effect(DEF cr, USE op1, USE op2);
14426 
14427   ins_cost(INSN_COST);
14428   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14429 
14430   ins_encode(aarch64_enc_cmpp(op1, op2));
14431 
14432   ins_pipe(icmp_reg_reg);
14433 %}
14434 
14435 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14436 %{
14437   match(Set cr (CmpN op1 op2));
14438 
14439   effect(DEF cr, USE op1, USE op2);
14440 
14441   ins_cost(INSN_COST);
14442   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14443 
14444   ins_encode(aarch64_enc_cmpn(op1, op2));
14445 
14446   ins_pipe(icmp_reg_reg);
14447 %}
14448 
14449 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14450 %{
14451   match(Set cr (CmpP op1 zero));
14452 
14453   effect(DEF cr, USE op1, USE zero);
14454 
14455   ins_cost(INSN_COST);
14456   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14457 
14458   ins_encode(aarch64_enc_testp(op1));
14459 
14460   ins_pipe(icmp_reg_imm);
14461 %}
14462 
14463 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14464 %{
14465   match(Set cr (CmpN op1 zero));
14466 
14467   effect(DEF cr, USE op1, USE zero);
14468 
14469   ins_cost(INSN_COST);
14470   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14471 
14472   ins_encode(aarch64_enc_testn(op1));
14473 
14474   ins_pipe(icmp_reg_imm);
14475 %}
14476 
14477 // FP comparisons
14478 //
14479 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14480 // using normal cmpOp. See declaration of rFlagsReg for details.
14481 
14482 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14483 %{
14484   match(Set cr (CmpF src1 src2));
14485 
14486   ins_cost(3 * INSN_COST);
14487   format %{ &quot;fcmps $src1, $src2&quot; %}
14488 
14489   ins_encode %{
14490     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14491   %}
14492 
14493   ins_pipe(pipe_class_compare);
14494 %}
14495 
14496 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14497 %{
14498   match(Set cr (CmpF src1 src2));
14499 
14500   ins_cost(3 * INSN_COST);
14501   format %{ &quot;fcmps $src1, 0.0&quot; %}
14502 
14503   ins_encode %{
14504     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14505   %}
14506 
14507   ins_pipe(pipe_class_compare);
14508 %}
14509 // FROM HERE
14510 
14511 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14512 %{
14513   match(Set cr (CmpD src1 src2));
14514 
14515   ins_cost(3 * INSN_COST);
14516   format %{ &quot;fcmpd $src1, $src2&quot; %}
14517 
14518   ins_encode %{
14519     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14520   %}
14521 
14522   ins_pipe(pipe_class_compare);
14523 %}
14524 
14525 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14526 %{
14527   match(Set cr (CmpD src1 src2));
14528 
14529   ins_cost(3 * INSN_COST);
14530   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14531 
14532   ins_encode %{
14533     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14534   %}
14535 
14536   ins_pipe(pipe_class_compare);
14537 %}
14538 
14539 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14540 %{
14541   match(Set dst (CmpF3 src1 src2));
14542   effect(KILL cr);
14543 
14544   ins_cost(5 * INSN_COST);
14545   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14546             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14547             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14548   %}
14549 
14550   ins_encode %{
14551     Label done;
14552     FloatRegister s1 = as_FloatRegister($src1$$reg);
14553     FloatRegister s2 = as_FloatRegister($src2$$reg);
14554     Register d = as_Register($dst$$reg);
14555     __ fcmps(s1, s2);
14556     // installs 0 if EQ else -1
14557     __ csinvw(d, zr, zr, Assembler::EQ);
14558     // keeps -1 if less or unordered else installs 1
14559     __ csnegw(d, d, d, Assembler::LT);
14560     __ bind(done);
14561   %}
14562 
14563   ins_pipe(pipe_class_default);
14564 
14565 %}
14566 
14567 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14568 %{
14569   match(Set dst (CmpD3 src1 src2));
14570   effect(KILL cr);
14571 
14572   ins_cost(5 * INSN_COST);
14573   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14574             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14575             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14576   %}
14577 
14578   ins_encode %{
14579     Label done;
14580     FloatRegister s1 = as_FloatRegister($src1$$reg);
14581     FloatRegister s2 = as_FloatRegister($src2$$reg);
14582     Register d = as_Register($dst$$reg);
14583     __ fcmpd(s1, s2);
14584     // installs 0 if EQ else -1
14585     __ csinvw(d, zr, zr, Assembler::EQ);
14586     // keeps -1 if less or unordered else installs 1
14587     __ csnegw(d, d, d, Assembler::LT);
14588     __ bind(done);
14589   %}
14590   ins_pipe(pipe_class_default);
14591 
14592 %}
14593 
14594 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14595 %{
14596   match(Set dst (CmpF3 src1 zero));
14597   effect(KILL cr);
14598 
14599   ins_cost(5 * INSN_COST);
14600   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14601             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14602             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14603   %}
14604 
14605   ins_encode %{
14606     Label done;
14607     FloatRegister s1 = as_FloatRegister($src1$$reg);
14608     Register d = as_Register($dst$$reg);
14609     __ fcmps(s1, 0.0);
14610     // installs 0 if EQ else -1
14611     __ csinvw(d, zr, zr, Assembler::EQ);
14612     // keeps -1 if less or unordered else installs 1
14613     __ csnegw(d, d, d, Assembler::LT);
14614     __ bind(done);
14615   %}
14616 
14617   ins_pipe(pipe_class_default);
14618 
14619 %}
14620 
14621 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14622 %{
14623   match(Set dst (CmpD3 src1 zero));
14624   effect(KILL cr);
14625 
14626   ins_cost(5 * INSN_COST);
14627   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14628             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14629             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14630   %}
14631 
14632   ins_encode %{
14633     Label done;
14634     FloatRegister s1 = as_FloatRegister($src1$$reg);
14635     Register d = as_Register($dst$$reg);
14636     __ fcmpd(s1, 0.0);
14637     // installs 0 if EQ else -1
14638     __ csinvw(d, zr, zr, Assembler::EQ);
14639     // keeps -1 if less or unordered else installs 1
14640     __ csnegw(d, d, d, Assembler::LT);
14641     __ bind(done);
14642   %}
14643   ins_pipe(pipe_class_default);
14644 
14645 %}
14646 
14647 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14648 %{
14649   match(Set dst (CmpLTMask p q));
14650   effect(KILL cr);
14651 
14652   ins_cost(3 * INSN_COST);
14653 
14654   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14655             &quot;csetw $dst, lt\n\t&quot;
14656             &quot;subw $dst, zr, $dst&quot;
14657   %}
14658 
14659   ins_encode %{
14660     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14661     __ csetw(as_Register($dst$$reg), Assembler::LT);
14662     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14663   %}
14664 
14665   ins_pipe(ialu_reg_reg);
14666 %}
14667 
14668 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14669 %{
14670   match(Set dst (CmpLTMask src zero));
14671   effect(KILL cr);
14672 
14673   ins_cost(INSN_COST);
14674 
14675   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14676 
14677   ins_encode %{
14678     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14679   %}
14680 
14681   ins_pipe(ialu_reg_shift);
14682 %}
14683 
14684 // ============================================================================
14685 // Max and Min
14686 
14687 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14688 %{
14689   effect( DEF dst, USE src1, USE src2, USE cr );
14690 
14691   ins_cost(INSN_COST * 2);
14692   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14693 
14694   ins_encode %{
14695     __ cselw(as_Register($dst$$reg),
14696              as_Register($src1$$reg),
14697              as_Register($src2$$reg),
14698              Assembler::LT);
14699   %}
14700 
14701   ins_pipe(icond_reg_reg);
14702 %}
14703 
14704 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14705 %{
14706   match(Set dst (MinI src1 src2));
14707   ins_cost(INSN_COST * 3);
14708 
14709   expand %{
14710     rFlagsReg cr;
14711     compI_reg_reg(cr, src1, src2);
14712     cmovI_reg_reg_lt(dst, src1, src2, cr);
14713   %}
14714 
14715 %}
14716 // FROM HERE
14717 
14718 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14719 %{
14720   effect( DEF dst, USE src1, USE src2, USE cr );
14721 
14722   ins_cost(INSN_COST * 2);
14723   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14724 
14725   ins_encode %{
14726     __ cselw(as_Register($dst$$reg),
14727              as_Register($src1$$reg),
14728              as_Register($src2$$reg),
14729              Assembler::GT);
14730   %}
14731 
14732   ins_pipe(icond_reg_reg);
14733 %}
14734 
14735 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14736 %{
14737   match(Set dst (MaxI src1 src2));
14738   ins_cost(INSN_COST * 3);
14739   expand %{
14740     rFlagsReg cr;
14741     compI_reg_reg(cr, src1, src2);
14742     cmovI_reg_reg_gt(dst, src1, src2, cr);
14743   %}
14744 %}
14745 
14746 // ============================================================================
14747 // Branch Instructions
14748 
14749 // Direct Branch.
14750 instruct branch(label lbl)
14751 %{
14752   match(Goto);
14753 
14754   effect(USE lbl);
14755 
14756   ins_cost(BRANCH_COST);
14757   format %{ &quot;b  $lbl&quot; %}
14758 
14759   ins_encode(aarch64_enc_b(lbl));
14760 
14761   ins_pipe(pipe_branch);
14762 %}
14763 
14764 // Conditional Near Branch
14765 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14766 %{
14767   // Same match rule as `branchConFar&#39;.
14768   match(If cmp cr);
14769 
14770   effect(USE lbl);
14771 
14772   ins_cost(BRANCH_COST);
14773   // If set to 1 this indicates that the current instruction is a
14774   // short variant of a long branch. This avoids using this
14775   // instruction in first-pass matching. It will then only be used in
14776   // the `Shorten_branches&#39; pass.
14777   // ins_short_branch(1);
14778   format %{ &quot;b$cmp  $lbl&quot; %}
14779 
14780   ins_encode(aarch64_enc_br_con(cmp, lbl));
14781 
14782   ins_pipe(pipe_branch_cond);
14783 %}
14784 
14785 // Conditional Near Branch Unsigned
14786 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14787 %{
14788   // Same match rule as `branchConFar&#39;.
14789   match(If cmp cr);
14790 
14791   effect(USE lbl);
14792 
14793   ins_cost(BRANCH_COST);
14794   // If set to 1 this indicates that the current instruction is a
14795   // short variant of a long branch. This avoids using this
14796   // instruction in first-pass matching. It will then only be used in
14797   // the `Shorten_branches&#39; pass.
14798   // ins_short_branch(1);
14799   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14800 
14801   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14802 
14803   ins_pipe(pipe_branch_cond);
14804 %}
14805 
14806 // Make use of CBZ and CBNZ.  These instructions, as well as being
14807 // shorter than (cmp; branch), have the additional benefit of not
14808 // killing the flags.
14809 
14810 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14811   match(If cmp (CmpI op1 op2));
14812   effect(USE labl);
14813 
14814   ins_cost(BRANCH_COST);
14815   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14816   ins_encode %{
14817     Label* L = $labl$$label;
14818     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14819     if (cond == Assembler::EQ)
14820       __ cbzw($op1$$Register, *L);
14821     else
14822       __ cbnzw($op1$$Register, *L);
14823   %}
14824   ins_pipe(pipe_cmp_branch);
14825 %}
14826 
14827 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14828   match(If cmp (CmpL op1 op2));
14829   effect(USE labl);
14830 
14831   ins_cost(BRANCH_COST);
14832   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14833   ins_encode %{
14834     Label* L = $labl$$label;
14835     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14836     if (cond == Assembler::EQ)
14837       __ cbz($op1$$Register, *L);
14838     else
14839       __ cbnz($op1$$Register, *L);
14840   %}
14841   ins_pipe(pipe_cmp_branch);
14842 %}
14843 
14844 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14845   match(If cmp (CmpP op1 op2));
14846   effect(USE labl);
14847 
14848   ins_cost(BRANCH_COST);
14849   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14850   ins_encode %{
14851     Label* L = $labl$$label;
14852     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14853     if (cond == Assembler::EQ)
14854       __ cbz($op1$$Register, *L);
14855     else
14856       __ cbnz($op1$$Register, *L);
14857   %}
14858   ins_pipe(pipe_cmp_branch);
14859 %}
14860 
14861 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14862   match(If cmp (CmpN op1 op2));
14863   effect(USE labl);
14864 
14865   ins_cost(BRANCH_COST);
14866   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14867   ins_encode %{
14868     Label* L = $labl$$label;
14869     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14870     if (cond == Assembler::EQ)
14871       __ cbzw($op1$$Register, *L);
14872     else
14873       __ cbnzw($op1$$Register, *L);
14874   %}
14875   ins_pipe(pipe_cmp_branch);
14876 %}
14877 
14878 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14879   match(If cmp (CmpP (DecodeN oop) zero));
14880   effect(USE labl);
14881 
14882   ins_cost(BRANCH_COST);
14883   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14884   ins_encode %{
14885     Label* L = $labl$$label;
14886     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14887     if (cond == Assembler::EQ)
14888       __ cbzw($oop$$Register, *L);
14889     else
14890       __ cbnzw($oop$$Register, *L);
14891   %}
14892   ins_pipe(pipe_cmp_branch);
14893 %}
14894 
14895 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14896   match(If cmp (CmpU op1 op2));
14897   effect(USE labl);
14898 
14899   ins_cost(BRANCH_COST);
14900   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14901   ins_encode %{
14902     Label* L = $labl$$label;
14903     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14904     if (cond == Assembler::EQ || cond == Assembler::LS)
14905       __ cbzw($op1$$Register, *L);
14906     else
14907       __ cbnzw($op1$$Register, *L);
14908   %}
14909   ins_pipe(pipe_cmp_branch);
14910 %}
14911 
14912 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14913   match(If cmp (CmpUL op1 op2));
14914   effect(USE labl);
14915 
14916   ins_cost(BRANCH_COST);
14917   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14918   ins_encode %{
14919     Label* L = $labl$$label;
14920     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14921     if (cond == Assembler::EQ || cond == Assembler::LS)
14922       __ cbz($op1$$Register, *L);
14923     else
14924       __ cbnz($op1$$Register, *L);
14925   %}
14926   ins_pipe(pipe_cmp_branch);
14927 %}
14928 
14929 // Test bit and Branch
14930 
14931 // Patterns for short (&lt; 32KiB) variants
14932 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14933   match(If cmp (CmpL op1 op2));
14934   effect(USE labl);
14935 
14936   ins_cost(BRANCH_COST);
14937   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14938   ins_encode %{
14939     Label* L = $labl$$label;
14940     Assembler::Condition cond =
14941       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14942     __ tbr(cond, $op1$$Register, 63, *L);
14943   %}
14944   ins_pipe(pipe_cmp_branch);
14945   ins_short_branch(1);
14946 %}
14947 
14948 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14949   match(If cmp (CmpI op1 op2));
14950   effect(USE labl);
14951 
14952   ins_cost(BRANCH_COST);
14953   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14954   ins_encode %{
14955     Label* L = $labl$$label;
14956     Assembler::Condition cond =
14957       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14958     __ tbr(cond, $op1$$Register, 31, *L);
14959   %}
14960   ins_pipe(pipe_cmp_branch);
14961   ins_short_branch(1);
14962 %}
14963 
14964 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14965   match(If cmp (CmpL (AndL op1 op2) op3));
14966   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14967   effect(USE labl);
14968 
14969   ins_cost(BRANCH_COST);
14970   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14971   ins_encode %{
14972     Label* L = $labl$$label;
14973     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14974     int bit = exact_log2_long($op2$$constant);
14975     __ tbr(cond, $op1$$Register, bit, *L);
14976   %}
14977   ins_pipe(pipe_cmp_branch);
14978   ins_short_branch(1);
14979 %}
14980 
14981 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14982   match(If cmp (CmpI (AndI op1 op2) op3));
14983   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14984   effect(USE labl);
14985 
14986   ins_cost(BRANCH_COST);
14987   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14988   ins_encode %{
14989     Label* L = $labl$$label;
14990     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14991     int bit = exact_log2((juint)$op2$$constant);
14992     __ tbr(cond, $op1$$Register, bit, *L);
14993   %}
14994   ins_pipe(pipe_cmp_branch);
14995   ins_short_branch(1);
14996 %}
14997 
14998 // And far variants
14999 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15000   match(If cmp (CmpL op1 op2));
15001   effect(USE labl);
15002 
15003   ins_cost(BRANCH_COST);
15004   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15005   ins_encode %{
15006     Label* L = $labl$$label;
15007     Assembler::Condition cond =
15008       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15009     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15010   %}
15011   ins_pipe(pipe_cmp_branch);
15012 %}
15013 
15014 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15015   match(If cmp (CmpI op1 op2));
15016   effect(USE labl);
15017 
15018   ins_cost(BRANCH_COST);
15019   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15020   ins_encode %{
15021     Label* L = $labl$$label;
15022     Assembler::Condition cond =
15023       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15024     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15025   %}
15026   ins_pipe(pipe_cmp_branch);
15027 %}
15028 
15029 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15030   match(If cmp (CmpL (AndL op1 op2) op3));
15031   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15032   effect(USE labl);
15033 
15034   ins_cost(BRANCH_COST);
15035   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15036   ins_encode %{
15037     Label* L = $labl$$label;
15038     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15039     int bit = exact_log2_long($op2$$constant);
15040     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15041   %}
15042   ins_pipe(pipe_cmp_branch);
15043 %}
15044 
15045 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15046   match(If cmp (CmpI (AndI op1 op2) op3));
15047   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15048   effect(USE labl);
15049 
15050   ins_cost(BRANCH_COST);
15051   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15052   ins_encode %{
15053     Label* L = $labl$$label;
15054     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15055     int bit = exact_log2((juint)$op2$$constant);
15056     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15057   %}
15058   ins_pipe(pipe_cmp_branch);
15059 %}
15060 
15061 // Test bits
15062 
15063 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15064   match(Set cr (CmpL (AndL op1 op2) op3));
15065   predicate(Assembler::operand_valid_for_logical_immediate
15066             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15067 
15068   ins_cost(INSN_COST);
15069   format %{ &quot;tst $op1, $op2 # long&quot; %}
15070   ins_encode %{
15071     __ tst($op1$$Register, $op2$$constant);
15072   %}
15073   ins_pipe(ialu_reg_reg);
15074 %}
15075 
15076 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15077   match(Set cr (CmpI (AndI op1 op2) op3));
15078   predicate(Assembler::operand_valid_for_logical_immediate
15079             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15080 
15081   ins_cost(INSN_COST);
15082   format %{ &quot;tst $op1, $op2 # int&quot; %}
15083   ins_encode %{
15084     __ tstw($op1$$Register, $op2$$constant);
15085   %}
15086   ins_pipe(ialu_reg_reg);
15087 %}
15088 
15089 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15090   match(Set cr (CmpL (AndL op1 op2) op3));
15091 
15092   ins_cost(INSN_COST);
15093   format %{ &quot;tst $op1, $op2 # long&quot; %}
15094   ins_encode %{
15095     __ tst($op1$$Register, $op2$$Register);
15096   %}
15097   ins_pipe(ialu_reg_reg);
15098 %}
15099 
15100 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15101   match(Set cr (CmpI (AndI op1 op2) op3));
15102 
15103   ins_cost(INSN_COST);
15104   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15105   ins_encode %{
15106     __ tstw($op1$$Register, $op2$$Register);
15107   %}
15108   ins_pipe(ialu_reg_reg);
15109 %}
15110 
15111 
15112 // Conditional Far Branch
15113 // Conditional Far Branch Unsigned
15114 // TODO: fixme
15115 
15116 // counted loop end branch near
15117 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15118 %{
15119   match(CountedLoopEnd cmp cr);
15120 
15121   effect(USE lbl);
15122 
15123   ins_cost(BRANCH_COST);
15124   // short variant.
15125   // ins_short_branch(1);
15126   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15127 
15128   ins_encode(aarch64_enc_br_con(cmp, lbl));
15129 
15130   ins_pipe(pipe_branch);
15131 %}
15132 
15133 // counted loop end branch near Unsigned
15134 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15135 %{
15136   match(CountedLoopEnd cmp cr);
15137 
15138   effect(USE lbl);
15139 
15140   ins_cost(BRANCH_COST);
15141   // short variant.
15142   // ins_short_branch(1);
15143   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15144 
15145   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15146 
15147   ins_pipe(pipe_branch);
15148 %}
15149 
15150 // counted loop end branch far
15151 // counted loop end branch far unsigned
15152 // TODO: fixme
15153 
15154 // ============================================================================
15155 // inlined locking and unlocking
15156 
15157 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15158 %{
15159   match(Set cr (FastLock object box));
15160   effect(TEMP tmp, TEMP tmp2);
15161 
15162   // TODO
15163   // identify correct cost
15164   ins_cost(5 * INSN_COST);
15165   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15166 
15167   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15168 
15169   ins_pipe(pipe_serial);
15170 %}
15171 
15172 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15173 %{
15174   match(Set cr (FastUnlock object box));
15175   effect(TEMP tmp, TEMP tmp2);
15176 
15177   ins_cost(5 * INSN_COST);
15178   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15179 
15180   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15181 
15182   ins_pipe(pipe_serial);
15183 %}
15184 
15185 
15186 // ============================================================================
15187 // Safepoint Instructions
15188 
15189 // TODO
15190 // provide a near and far version of this code
15191 
15192 instruct safePoint(rFlagsReg cr, iRegP poll)
15193 %{
15194   match(SafePoint poll);
15195   effect(KILL cr);
15196 
15197   format %{
15198     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15199   %}
15200   ins_encode %{
15201     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15202   %}
15203   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15204 %}
15205 
15206 
15207 // ============================================================================
15208 // Procedure Call/Return Instructions
15209 
15210 // Call Java Static Instruction
15211 
15212 instruct CallStaticJavaDirect(method meth)
15213 %{
15214   match(CallStaticJava);
15215 
15216   effect(USE meth);
15217 
15218   ins_cost(CALL_COST);
15219 
15220   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15221 
15222   ins_encode( aarch64_enc_java_static_call(meth),
15223               aarch64_enc_call_epilog );
15224 
15225   ins_pipe(pipe_class_call);
15226 %}
15227 
15228 // TO HERE
15229 
15230 // Call Java Dynamic Instruction
15231 instruct CallDynamicJavaDirect(method meth)
15232 %{
15233   match(CallDynamicJava);
15234 
15235   effect(USE meth);
15236 
15237   ins_cost(CALL_COST);
15238 
15239   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15240 
15241   ins_encode( aarch64_enc_java_dynamic_call(meth),
15242                aarch64_enc_call_epilog );
15243 
15244   ins_pipe(pipe_class_call);
15245 %}
15246 
15247 // Call Runtime Instruction
15248 
15249 instruct CallRuntimeDirect(method meth)
15250 %{
15251   match(CallRuntime);
15252 
15253   effect(USE meth);
15254 
15255   ins_cost(CALL_COST);
15256 
15257   format %{ &quot;CALL, runtime $meth&quot; %}
15258 
15259   ins_encode( aarch64_enc_java_to_runtime(meth) );
15260 
15261   ins_pipe(pipe_class_call);
15262 %}
15263 
15264 // Call Runtime Instruction
15265 
15266 instruct CallLeafDirect(method meth)
15267 %{
15268   match(CallLeaf);
15269 
15270   effect(USE meth);
15271 
15272   ins_cost(CALL_COST);
15273 
15274   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15275 
15276   ins_encode( aarch64_enc_java_to_runtime(meth) );
15277 
15278   ins_pipe(pipe_class_call);
15279 %}
15280 
15281 // Call Runtime Instruction
15282 
15283 instruct CallLeafNoFPDirect(method meth)
15284 %{
15285   match(CallLeafNoFP);
15286 
15287   effect(USE meth);
15288 
15289   ins_cost(CALL_COST);
15290 
15291   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15292 
15293   ins_encode( aarch64_enc_java_to_runtime(meth) );
15294 
15295   ins_pipe(pipe_class_call);
15296 %}
15297 
15298 // Tail Call; Jump from runtime stub to Java code.
15299 // Also known as an &#39;interprocedural jump&#39;.
15300 // Target of jump will eventually return to caller.
15301 // TailJump below removes the return address.
15302 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15303 %{
15304   match(TailCall jump_target method_oop);
15305 
15306   ins_cost(CALL_COST);
15307 
15308   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15309 
15310   ins_encode(aarch64_enc_tail_call(jump_target));
15311 
15312   ins_pipe(pipe_class_call);
15313 %}
15314 
15315 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15316 %{
15317   match(TailJump jump_target ex_oop);
15318 
15319   ins_cost(CALL_COST);
15320 
15321   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15322 
15323   ins_encode(aarch64_enc_tail_jmp(jump_target));
15324 
15325   ins_pipe(pipe_class_call);
15326 %}
15327 
15328 // Create exception oop: created by stack-crawling runtime code.
15329 // Created exception is now available to this handler, and is setup
15330 // just prior to jumping to this handler. No code emitted.
15331 // TODO check
15332 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15333 instruct CreateException(iRegP_R0 ex_oop)
15334 %{
15335   match(Set ex_oop (CreateEx));
15336 
15337   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15338 
15339   size(0);
15340 
15341   ins_encode( /*empty*/ );
15342 
15343   ins_pipe(pipe_class_empty);
15344 %}
15345 
15346 // Rethrow exception: The exception oop will come in the first
15347 // argument position. Then JUMP (not call) to the rethrow stub code.
15348 instruct RethrowException() %{
15349   match(Rethrow);
15350   ins_cost(CALL_COST);
15351 
15352   format %{ &quot;b rethrow_stub&quot; %}
15353 
15354   ins_encode( aarch64_enc_rethrow() );
15355 
15356   ins_pipe(pipe_class_call);
15357 %}
15358 
15359 
15360 // Return Instruction
15361 // epilog node loads ret address into lr as part of frame pop
15362 instruct Ret()
15363 %{
15364   match(Return);
15365 
15366   format %{ &quot;ret\t// return register&quot; %}
15367 
15368   ins_encode( aarch64_enc_ret() );
15369 
15370   ins_pipe(pipe_branch);
15371 %}
15372 
15373 // Die now.
15374 instruct ShouldNotReachHere() %{
15375   match(Halt);
15376 
15377   ins_cost(CALL_COST);
15378   format %{ &quot;ShouldNotReachHere&quot; %}
15379 
15380   ins_encode %{
15381     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15382     // return true
15383     __ dpcs1(0xdead + 1);
15384   %}
15385 
15386   ins_pipe(pipe_class_default);
15387 %}
15388 
15389 // ============================================================================
15390 // Partial Subtype Check
15391 //
15392 // superklass array for an instance of the superklass.  Set a hidden
15393 // internal cache on a hit (cache is checked with exposed code in
15394 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15395 // encoding ALSO sets flags.
15396 
15397 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15398 %{
15399   match(Set result (PartialSubtypeCheck sub super));
15400   effect(KILL cr, KILL temp);
15401 
15402   ins_cost(1100);  // slightly larger than the next version
15403   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15404 
15405   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15406 
15407   opcode(0x1); // Force zero of result reg on hit
15408 
15409   ins_pipe(pipe_class_memory);
15410 %}
15411 
15412 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15413 %{
15414   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15415   effect(KILL temp, KILL result);
15416 
15417   ins_cost(1100);  // slightly larger than the next version
15418   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15419 
15420   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15421 
15422   opcode(0x0); // Don&#39;t zero result reg on hit
15423 
15424   ins_pipe(pipe_class_memory);
15425 %}
15426 
15427 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15428                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15429 %{
15430   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15431   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15432   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15433 
15434   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15435   ins_encode %{
15436     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15437     __ string_compare($str1$$Register, $str2$$Register,
15438                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15439                       $tmp1$$Register, $tmp2$$Register,
15440                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15441   %}
15442   ins_pipe(pipe_class_memory);
15443 %}
15444 
15445 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15446                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15447 %{
15448   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15449   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15450   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15451 
15452   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15453   ins_encode %{
15454     __ string_compare($str1$$Register, $str2$$Register,
15455                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15456                       $tmp1$$Register, $tmp2$$Register,
15457                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15458   %}
15459   ins_pipe(pipe_class_memory);
15460 %}
15461 
15462 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15463                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15464                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15465 %{
15466   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15467   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15468   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15469          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15470 
15471   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15472   ins_encode %{
15473     __ string_compare($str1$$Register, $str2$$Register,
15474                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15475                       $tmp1$$Register, $tmp2$$Register,
15476                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15477                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15478   %}
15479   ins_pipe(pipe_class_memory);
15480 %}
15481 
15482 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15483                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15484                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15485 %{
15486   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15487   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15488   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15489          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15490 
15491   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15492   ins_encode %{
15493     __ string_compare($str1$$Register, $str2$$Register,
15494                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15495                       $tmp1$$Register, $tmp2$$Register,
15496                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15497                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15498   %}
15499   ins_pipe(pipe_class_memory);
15500 %}
15501 
15502 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15503        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15504        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15505 %{
15506   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15507   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15508   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15509          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15510   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15511 
15512   ins_encode %{
15513     __ string_indexof($str1$$Register, $str2$$Register,
15514                       $cnt1$$Register, $cnt2$$Register,
15515                       $tmp1$$Register, $tmp2$$Register,
15516                       $tmp3$$Register, $tmp4$$Register,
15517                       $tmp5$$Register, $tmp6$$Register,
15518                       -1, $result$$Register, StrIntrinsicNode::UU);
15519   %}
15520   ins_pipe(pipe_class_memory);
15521 %}
15522 
15523 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15524        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15525        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15526 %{
15527   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15528   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15529   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15530          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15531   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15532 
15533   ins_encode %{
15534     __ string_indexof($str1$$Register, $str2$$Register,
15535                       $cnt1$$Register, $cnt2$$Register,
15536                       $tmp1$$Register, $tmp2$$Register,
15537                       $tmp3$$Register, $tmp4$$Register,
15538                       $tmp5$$Register, $tmp6$$Register,
15539                       -1, $result$$Register, StrIntrinsicNode::LL);
15540   %}
15541   ins_pipe(pipe_class_memory);
15542 %}
15543 
15544 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15545        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15546        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15547 %{
15548   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15549   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15550   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15551          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15552   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15553 
15554   ins_encode %{
15555     __ string_indexof($str1$$Register, $str2$$Register,
15556                       $cnt1$$Register, $cnt2$$Register,
15557                       $tmp1$$Register, $tmp2$$Register,
15558                       $tmp3$$Register, $tmp4$$Register,
15559                       $tmp5$$Register, $tmp6$$Register,
15560                       -1, $result$$Register, StrIntrinsicNode::UL);
15561   %}
15562   ins_pipe(pipe_class_memory);
15563 %}
15564 
15565 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15566                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15567                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15568 %{
15569   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15570   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15571   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15572          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15573   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15574 
15575   ins_encode %{
15576     int icnt2 = (int)$int_cnt2$$constant;
15577     __ string_indexof($str1$$Register, $str2$$Register,
15578                       $cnt1$$Register, zr,
15579                       $tmp1$$Register, $tmp2$$Register,
15580                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15581                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15582   %}
15583   ins_pipe(pipe_class_memory);
15584 %}
15585 
15586 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15587                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15588                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15589 %{
15590   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15591   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15592   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15593          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15594   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15595 
15596   ins_encode %{
15597     int icnt2 = (int)$int_cnt2$$constant;
15598     __ string_indexof($str1$$Register, $str2$$Register,
15599                       $cnt1$$Register, zr,
15600                       $tmp1$$Register, $tmp2$$Register,
15601                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15602                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15603   %}
15604   ins_pipe(pipe_class_memory);
15605 %}
15606 
15607 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15608                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15609                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15610 %{
15611   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15612   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15613   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15614          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15615   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15616 
15617   ins_encode %{
15618     int icnt2 = (int)$int_cnt2$$constant;
15619     __ string_indexof($str1$$Register, $str2$$Register,
15620                       $cnt1$$Register, zr,
15621                       $tmp1$$Register, $tmp2$$Register,
15622                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15623                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15624   %}
15625   ins_pipe(pipe_class_memory);
15626 %}
15627 
15628 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15629                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15630                               iRegINoSp tmp3, rFlagsReg cr)
15631 %{
15632   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15633   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15634          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15635 
15636   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15637 
15638   ins_encode %{
15639     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15640                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15641                            $tmp3$$Register);
15642   %}
15643   ins_pipe(pipe_class_memory);
15644 %}
15645 
15646 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15647                         iRegI_R0 result, rFlagsReg cr)
15648 %{
15649   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15650   match(Set result (StrEquals (Binary str1 str2) cnt));
15651   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15652 
15653   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15654   ins_encode %{
15655     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15656     __ string_equals($str1$$Register, $str2$$Register,
15657                      $result$$Register, $cnt$$Register, 1);
15658   %}
15659   ins_pipe(pipe_class_memory);
15660 %}
15661 
15662 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15663                         iRegI_R0 result, rFlagsReg cr)
15664 %{
15665   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15666   match(Set result (StrEquals (Binary str1 str2) cnt));
15667   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15668 
15669   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15670   ins_encode %{
15671     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15672     __ string_equals($str1$$Register, $str2$$Register,
15673                      $result$$Register, $cnt$$Register, 2);
15674   %}
15675   ins_pipe(pipe_class_memory);
15676 %}
15677 
15678 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15679                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15680                        iRegP_R10 tmp, rFlagsReg cr)
15681 %{
15682   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15683   match(Set result (AryEq ary1 ary2));
15684   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15685 
15686   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15687   ins_encode %{
15688     __ arrays_equals($ary1$$Register, $ary2$$Register,
15689                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15690                      $result$$Register, $tmp$$Register, 1);
15691     %}
15692   ins_pipe(pipe_class_memory);
15693 %}
15694 
15695 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15696                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15697                        iRegP_R10 tmp, rFlagsReg cr)
15698 %{
15699   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15700   match(Set result (AryEq ary1 ary2));
15701   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15702 
15703   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15704   ins_encode %{
15705     __ arrays_equals($ary1$$Register, $ary2$$Register,
15706                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15707                      $result$$Register, $tmp$$Register, 2);
15708   %}
15709   ins_pipe(pipe_class_memory);
15710 %}
15711 
15712 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15713 %{
15714   match(Set result (HasNegatives ary1 len));
15715   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15716   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15717   ins_encode %{
15718     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15719   %}
15720   ins_pipe( pipe_slow );
15721 %}
15722 
15723 // fast char[] to byte[] compression
15724 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15725                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15726                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15727                          iRegI_R0 result, rFlagsReg cr)
15728 %{
15729   match(Set result (StrCompressedCopy src (Binary dst len)));
15730   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15731 
15732   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15733   ins_encode %{
15734     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15735                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15736                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15737                            $result$$Register);
15738   %}
15739   ins_pipe( pipe_slow );
15740 %}
15741 
15742 // fast byte[] to char[] inflation
15743 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15744                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15745 %{
15746   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15747   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15748 
15749   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15750   ins_encode %{
15751     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15752                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15753   %}
15754   ins_pipe(pipe_class_memory);
15755 %}
15756 
15757 // encode char[] to byte[] in ISO_8859_1
15758 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15759                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15760                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15761                           iRegI_R0 result, rFlagsReg cr)
15762 %{
15763   match(Set result (EncodeISOArray src (Binary dst len)));
15764   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15765          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15766 
15767   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15768   ins_encode %{
15769     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15770          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15771          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15772   %}
15773   ins_pipe( pipe_class_memory );
15774 %}
15775 
15776 // ============================================================================
15777 // This name is KNOWN by the ADLC and cannot be changed.
15778 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15779 // for this guy.
15780 instruct tlsLoadP(thread_RegP dst)
15781 %{
15782   match(Set dst (ThreadLocal));
15783 
15784   ins_cost(0);
15785 
15786   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15787 
15788   size(0);
15789 
15790   ins_encode( /*empty*/ );
15791 
15792   ins_pipe(pipe_class_empty);
15793 %}
15794 
15795 // ====================VECTOR INSTRUCTIONS=====================================
15796 
15797 // Load vector (32 bits)
15798 instruct loadV4(vecD dst, vmem4 mem)
15799 %{
15800   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15801   match(Set dst (LoadVector mem));
15802   ins_cost(4 * INSN_COST);
15803   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15804   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15805   ins_pipe(vload_reg_mem64);
15806 %}
15807 
15808 // Load vector (64 bits)
15809 instruct loadV8(vecD dst, vmem8 mem)
15810 %{
15811   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15812   match(Set dst (LoadVector mem));
15813   ins_cost(4 * INSN_COST);
15814   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15815   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15816   ins_pipe(vload_reg_mem64);
15817 %}
15818 
15819 // Load Vector (128 bits)
15820 instruct loadV16(vecX dst, vmem16 mem)
15821 %{
15822   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15823   match(Set dst (LoadVector mem));
15824   ins_cost(4 * INSN_COST);
15825   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15826   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15827   ins_pipe(vload_reg_mem128);
15828 %}
15829 
15830 // Store Vector (32 bits)
15831 instruct storeV4(vecD src, vmem4 mem)
15832 %{
15833   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15834   match(Set mem (StoreVector mem src));
15835   ins_cost(4 * INSN_COST);
15836   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15837   ins_encode( aarch64_enc_strvS(src, mem) );
15838   ins_pipe(vstore_reg_mem64);
15839 %}
15840 
15841 // Store Vector (64 bits)
15842 instruct storeV8(vecD src, vmem8 mem)
15843 %{
15844   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15845   match(Set mem (StoreVector mem src));
15846   ins_cost(4 * INSN_COST);
15847   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15848   ins_encode( aarch64_enc_strvD(src, mem) );
15849   ins_pipe(vstore_reg_mem64);
15850 %}
15851 
15852 // Store Vector (128 bits)
15853 instruct storeV16(vecX src, vmem16 mem)
15854 %{
15855   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15856   match(Set mem (StoreVector mem src));
15857   ins_cost(4 * INSN_COST);
15858   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15859   ins_encode( aarch64_enc_strvQ(src, mem) );
15860   ins_pipe(vstore_reg_mem128);
15861 %}
15862 
15863 instruct replicate8B(vecD dst, iRegIorL2I src)
15864 %{
15865   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15866             n-&gt;as_Vector()-&gt;length() == 8);
15867   match(Set dst (ReplicateB src));
15868   ins_cost(INSN_COST);
15869   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15870   ins_encode %{
15871     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15872   %}
15873   ins_pipe(vdup_reg_reg64);
15874 %}
15875 
15876 instruct replicate16B(vecX dst, iRegIorL2I src)
15877 %{
15878   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15879   match(Set dst (ReplicateB src));
15880   ins_cost(INSN_COST);
15881   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15882   ins_encode %{
15883     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15884   %}
15885   ins_pipe(vdup_reg_reg128);
15886 %}
15887 
15888 instruct replicate8B_imm(vecD dst, immI con)
15889 %{
15890   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15891             n-&gt;as_Vector()-&gt;length() == 8);
15892   match(Set dst (ReplicateB con));
15893   ins_cost(INSN_COST);
15894   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15895   ins_encode %{
15896     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15897   %}
15898   ins_pipe(vmovi_reg_imm64);
15899 %}
15900 
15901 instruct replicate16B_imm(vecX dst, immI con)
15902 %{
15903   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15904   match(Set dst (ReplicateB con));
15905   ins_cost(INSN_COST);
15906   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15907   ins_encode %{
15908     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15909   %}
15910   ins_pipe(vmovi_reg_imm128);
15911 %}
15912 
15913 instruct replicate4S(vecD dst, iRegIorL2I src)
15914 %{
15915   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15916             n-&gt;as_Vector()-&gt;length() == 4);
15917   match(Set dst (ReplicateS src));
15918   ins_cost(INSN_COST);
15919   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15920   ins_encode %{
15921     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15922   %}
15923   ins_pipe(vdup_reg_reg64);
15924 %}
15925 
15926 instruct replicate8S(vecX dst, iRegIorL2I src)
15927 %{
15928   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15929   match(Set dst (ReplicateS src));
15930   ins_cost(INSN_COST);
15931   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15932   ins_encode %{
15933     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15934   %}
15935   ins_pipe(vdup_reg_reg128);
15936 %}
15937 
15938 instruct replicate4S_imm(vecD dst, immI con)
15939 %{
15940   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15941             n-&gt;as_Vector()-&gt;length() == 4);
15942   match(Set dst (ReplicateS con));
15943   ins_cost(INSN_COST);
15944   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15945   ins_encode %{
15946     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15947   %}
15948   ins_pipe(vmovi_reg_imm64);
15949 %}
15950 
15951 instruct replicate8S_imm(vecX dst, immI con)
15952 %{
15953   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15954   match(Set dst (ReplicateS con));
15955   ins_cost(INSN_COST);
15956   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15957   ins_encode %{
15958     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15959   %}
15960   ins_pipe(vmovi_reg_imm128);
15961 %}
15962 
15963 instruct replicate2I(vecD dst, iRegIorL2I src)
15964 %{
15965   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15966   match(Set dst (ReplicateI src));
15967   ins_cost(INSN_COST);
15968   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15969   ins_encode %{
15970     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15971   %}
15972   ins_pipe(vdup_reg_reg64);
15973 %}
15974 
15975 instruct replicate4I(vecX dst, iRegIorL2I src)
15976 %{
15977   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15978   match(Set dst (ReplicateI src));
15979   ins_cost(INSN_COST);
15980   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15981   ins_encode %{
15982     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15983   %}
15984   ins_pipe(vdup_reg_reg128);
15985 %}
15986 
15987 instruct replicate2I_imm(vecD dst, immI con)
15988 %{
15989   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15990   match(Set dst (ReplicateI con));
15991   ins_cost(INSN_COST);
15992   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15993   ins_encode %{
15994     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15995   %}
15996   ins_pipe(vmovi_reg_imm64);
15997 %}
15998 
15999 instruct replicate4I_imm(vecX dst, immI con)
16000 %{
16001   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16002   match(Set dst (ReplicateI con));
16003   ins_cost(INSN_COST);
16004   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
16005   ins_encode %{
16006     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
16007   %}
16008   ins_pipe(vmovi_reg_imm128);
16009 %}
16010 
16011 instruct replicate2L(vecX dst, iRegL src)
16012 %{
16013   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16014   match(Set dst (ReplicateL src));
16015   ins_cost(INSN_COST);
16016   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
16017   ins_encode %{
16018     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
16019   %}
16020   ins_pipe(vdup_reg_reg128);
16021 %}
16022 
16023 instruct replicate2L_zero(vecX dst, immI0 zero)
16024 %{
16025   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16026   match(Set dst (ReplicateI zero));
16027   ins_cost(INSN_COST);
16028   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16029   ins_encode %{
16030     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16031            as_FloatRegister($dst$$reg),
16032            as_FloatRegister($dst$$reg));
16033   %}
16034   ins_pipe(vmovi_reg_imm128);
16035 %}
16036 
16037 instruct replicate2F(vecD dst, vRegF src)
16038 %{
16039   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16040   match(Set dst (ReplicateF src));
16041   ins_cost(INSN_COST);
16042   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16043   ins_encode %{
16044     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16045            as_FloatRegister($src$$reg));
16046   %}
16047   ins_pipe(vdup_reg_freg64);
16048 %}
16049 
16050 instruct replicate4F(vecX dst, vRegF src)
16051 %{
16052   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16053   match(Set dst (ReplicateF src));
16054   ins_cost(INSN_COST);
16055   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16056   ins_encode %{
16057     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16058            as_FloatRegister($src$$reg));
16059   %}
16060   ins_pipe(vdup_reg_freg128);
16061 %}
16062 
16063 instruct replicate2D(vecX dst, vRegD src)
16064 %{
16065   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16066   match(Set dst (ReplicateD src));
16067   ins_cost(INSN_COST);
16068   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16069   ins_encode %{
16070     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16071            as_FloatRegister($src$$reg));
16072   %}
16073   ins_pipe(vdup_reg_dreg128);
16074 %}
16075 
16076 // ====================REDUCTION ARITHMETIC====================================
16077 
16078 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16079 %{
16080   match(Set dst (AddReductionVI src1 src2));
16081   ins_cost(INSN_COST);
16082   effect(TEMP tmp, TEMP tmp2);
16083   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16084             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
16085             &quot;addw  $tmp, $src1, $tmp\n\t&quot;
16086             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16087   %}
16088   ins_encode %{
16089     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16090     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16091     __ addw($tmp$$Register, $src1$$Register, $tmp$$Register);
16092     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16093   %}
16094   ins_pipe(pipe_class_default);
16095 %}
16096 
16097 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16098 %{
16099   match(Set dst (AddReductionVI src1 src2));
16100   ins_cost(INSN_COST);
16101   effect(TEMP tmp, TEMP tmp2);
16102   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16103             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16104             &quot;addw  $dst, $tmp2, $src1\t# add reduction4I&quot;
16105   %}
16106   ins_encode %{
16107     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16108             as_FloatRegister($src2$$reg));
16109     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16110     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16111   %}
16112   ins_pipe(pipe_class_default);
16113 %}
16114 
16115 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16116 %{
16117   match(Set dst (MulReductionVI src1 src2));
16118   ins_cost(INSN_COST);
16119   effect(TEMP tmp, TEMP dst);
16120   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16121             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16122             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
16123             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16124   %}
16125   ins_encode %{
16126     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16127     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16128     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16129     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16130   %}
16131   ins_pipe(pipe_class_default);
16132 %}
16133 
16134 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16135 %{
16136   match(Set dst (MulReductionVI src1 src2));
16137   ins_cost(INSN_COST);
16138   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16139   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16140             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16141             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16142             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16143             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
16144             &quot;mul   $dst, $tmp2, $dst\t# mul reduction4I&quot;
16145   %}
16146   ins_encode %{
16147     __ ins(as_FloatRegister($tmp$$reg), __ D,
16148            as_FloatRegister($src2$$reg), 0, 1);
16149     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16150            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16151     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16152     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16153     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16154     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16155   %}
16156   ins_pipe(pipe_class_default);
16157 %}
16158 
16159 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16160 %{
16161   match(Set dst (AddReductionVF src1 src2));
16162   ins_cost(INSN_COST);
16163   effect(TEMP tmp, TEMP dst);
16164   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16165             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16166             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16167   %}
16168   ins_encode %{
16169     __ fadds(as_FloatRegister($dst$$reg),
16170              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16171     __ ins(as_FloatRegister($tmp$$reg), __ S,
16172            as_FloatRegister($src2$$reg), 0, 1);
16173     __ fadds(as_FloatRegister($dst$$reg),
16174              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16175   %}
16176   ins_pipe(pipe_class_default);
16177 %}
16178 
16179 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16180 %{
16181   match(Set dst (AddReductionVF src1 src2));
16182   ins_cost(INSN_COST);
16183   effect(TEMP tmp, TEMP dst);
16184   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16185             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16186             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16187             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16188             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16189             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16190             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16191   %}
16192   ins_encode %{
16193     __ fadds(as_FloatRegister($dst$$reg),
16194              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16195     __ ins(as_FloatRegister($tmp$$reg), __ S,
16196            as_FloatRegister($src2$$reg), 0, 1);
16197     __ fadds(as_FloatRegister($dst$$reg),
16198              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16199     __ ins(as_FloatRegister($tmp$$reg), __ S,
16200            as_FloatRegister($src2$$reg), 0, 2);
16201     __ fadds(as_FloatRegister($dst$$reg),
16202              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16203     __ ins(as_FloatRegister($tmp$$reg), __ S,
16204            as_FloatRegister($src2$$reg), 0, 3);
16205     __ fadds(as_FloatRegister($dst$$reg),
16206              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16207   %}
16208   ins_pipe(pipe_class_default);
16209 %}
16210 
16211 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16212 %{
16213   match(Set dst (MulReductionVF src1 src2));
16214   ins_cost(INSN_COST);
16215   effect(TEMP tmp, TEMP dst);
16216   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16217             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16218             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16219   %}
16220   ins_encode %{
16221     __ fmuls(as_FloatRegister($dst$$reg),
16222              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16223     __ ins(as_FloatRegister($tmp$$reg), __ S,
16224            as_FloatRegister($src2$$reg), 0, 1);
16225     __ fmuls(as_FloatRegister($dst$$reg),
16226              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16227   %}
16228   ins_pipe(pipe_class_default);
16229 %}
16230 
16231 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16232 %{
16233   match(Set dst (MulReductionVF src1 src2));
16234   ins_cost(INSN_COST);
16235   effect(TEMP tmp, TEMP dst);
16236   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16237             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16238             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16239             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16240             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16241             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16242             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16243   %}
16244   ins_encode %{
16245     __ fmuls(as_FloatRegister($dst$$reg),
16246              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16247     __ ins(as_FloatRegister($tmp$$reg), __ S,
16248            as_FloatRegister($src2$$reg), 0, 1);
16249     __ fmuls(as_FloatRegister($dst$$reg),
16250              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16251     __ ins(as_FloatRegister($tmp$$reg), __ S,
16252            as_FloatRegister($src2$$reg), 0, 2);
16253     __ fmuls(as_FloatRegister($dst$$reg),
16254              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16255     __ ins(as_FloatRegister($tmp$$reg), __ S,
16256            as_FloatRegister($src2$$reg), 0, 3);
16257     __ fmuls(as_FloatRegister($dst$$reg),
16258              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16259   %}
16260   ins_pipe(pipe_class_default);
16261 %}
16262 
16263 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16264 %{
16265   match(Set dst (AddReductionVD src1 src2));
16266   ins_cost(INSN_COST);
16267   effect(TEMP tmp, TEMP dst);
16268   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16269             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16270             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16271   %}
16272   ins_encode %{
16273     __ faddd(as_FloatRegister($dst$$reg),
16274              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16275     __ ins(as_FloatRegister($tmp$$reg), __ D,
16276            as_FloatRegister($src2$$reg), 0, 1);
16277     __ faddd(as_FloatRegister($dst$$reg),
16278              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16279   %}
16280   ins_pipe(pipe_class_default);
16281 %}
16282 
16283 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16284 %{
16285   match(Set dst (MulReductionVD src1 src2));
16286   ins_cost(INSN_COST);
16287   effect(TEMP tmp, TEMP dst);
16288   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16289             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16290             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16291   %}
16292   ins_encode %{
16293     __ fmuld(as_FloatRegister($dst$$reg),
16294              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16295     __ ins(as_FloatRegister($tmp$$reg), __ D,
16296            as_FloatRegister($src2$$reg), 0, 1);
16297     __ fmuld(as_FloatRegister($dst$$reg),
16298              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16299   %}
16300   ins_pipe(pipe_class_default);
16301 %}
16302 
16303 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16304   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16305   match(Set dst (MaxReductionV src1 src2));
16306   ins_cost(INSN_COST);
16307   effect(TEMP_DEF dst, TEMP tmp);
16308   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16309             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16310             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16311   ins_encode %{
16312     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16313     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16314     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16315   %}
16316   ins_pipe(pipe_class_default);
16317 %}
16318 
16319 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16320   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16321   match(Set dst (MaxReductionV src1 src2));
16322   ins_cost(INSN_COST);
16323   effect(TEMP_DEF dst);
16324   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
16325             &quot;fmaxs $dst, $dst, $src1\t# max reduction4F&quot; %}
16326   ins_encode %{
16327     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16328     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16329   %}
16330   ins_pipe(pipe_class_default);
16331 %}
16332 
16333 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16334   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16335   match(Set dst (MaxReductionV src1 src2));
16336   ins_cost(INSN_COST);
16337   effect(TEMP_DEF dst, TEMP tmp);
16338   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16339             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16340             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16341   ins_encode %{
16342     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16343     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16344     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16345   %}
16346   ins_pipe(pipe_class_default);
16347 %}
16348 
16349 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16350   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16351   match(Set dst (MinReductionV src1 src2));
16352   ins_cost(INSN_COST);
16353   effect(TEMP_DEF dst, TEMP tmp);
16354   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16355             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16356             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16357   ins_encode %{
16358     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16359     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16360     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16361   %}
16362   ins_pipe(pipe_class_default);
16363 %}
16364 
16365 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16366   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16367   match(Set dst (MinReductionV src1 src2));
16368   ins_cost(INSN_COST);
16369   effect(TEMP_DEF dst);
16370   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
16371             &quot;fmins $dst, $dst, $src1\t# min reduction4F&quot; %}
16372   ins_encode %{
16373     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16374     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16375   %}
16376   ins_pipe(pipe_class_default);
16377 %}
16378 
16379 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16380   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16381   match(Set dst (MinReductionV src1 src2));
16382   ins_cost(INSN_COST);
16383   effect(TEMP_DEF dst, TEMP tmp);
16384   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16385             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16386             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16387   ins_encode %{
16388     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16389     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16390     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16391   %}
16392   ins_pipe(pipe_class_default);
16393 %}
16394 
16395 // ====================VECTOR ARITHMETIC=======================================
16396 
16397 // --------------------------------- ADD --------------------------------------
16398 
16399 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16400 %{
16401   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16402             n-&gt;as_Vector()-&gt;length() == 8);
16403   match(Set dst (AddVB src1 src2));
16404   ins_cost(INSN_COST);
16405   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16406   ins_encode %{
16407     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16408             as_FloatRegister($src1$$reg),
16409             as_FloatRegister($src2$$reg));
16410   %}
16411   ins_pipe(vdop64);
16412 %}
16413 
16414 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16415 %{
16416   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16417   match(Set dst (AddVB src1 src2));
16418   ins_cost(INSN_COST);
16419   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16420   ins_encode %{
16421     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16422             as_FloatRegister($src1$$reg),
16423             as_FloatRegister($src2$$reg));
16424   %}
16425   ins_pipe(vdop128);
16426 %}
16427 
16428 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16429 %{
16430   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16431             n-&gt;as_Vector()-&gt;length() == 4);
16432   match(Set dst (AddVS src1 src2));
16433   ins_cost(INSN_COST);
16434   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16435   ins_encode %{
16436     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16437             as_FloatRegister($src1$$reg),
16438             as_FloatRegister($src2$$reg));
16439   %}
16440   ins_pipe(vdop64);
16441 %}
16442 
16443 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16444 %{
16445   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16446   match(Set dst (AddVS src1 src2));
16447   ins_cost(INSN_COST);
16448   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16449   ins_encode %{
16450     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16451             as_FloatRegister($src1$$reg),
16452             as_FloatRegister($src2$$reg));
16453   %}
16454   ins_pipe(vdop128);
16455 %}
16456 
16457 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16458 %{
16459   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16460   match(Set dst (AddVI src1 src2));
16461   ins_cost(INSN_COST);
16462   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16463   ins_encode %{
16464     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16465             as_FloatRegister($src1$$reg),
16466             as_FloatRegister($src2$$reg));
16467   %}
16468   ins_pipe(vdop64);
16469 %}
16470 
16471 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16472 %{
16473   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16474   match(Set dst (AddVI src1 src2));
16475   ins_cost(INSN_COST);
16476   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16477   ins_encode %{
16478     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16479             as_FloatRegister($src1$$reg),
16480             as_FloatRegister($src2$$reg));
16481   %}
16482   ins_pipe(vdop128);
16483 %}
16484 
16485 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16486 %{
16487   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16488   match(Set dst (AddVL src1 src2));
16489   ins_cost(INSN_COST);
16490   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16491   ins_encode %{
16492     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16493             as_FloatRegister($src1$$reg),
16494             as_FloatRegister($src2$$reg));
16495   %}
16496   ins_pipe(vdop128);
16497 %}
16498 
16499 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16500 %{
16501   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16502   match(Set dst (AddVF src1 src2));
16503   ins_cost(INSN_COST);
16504   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16505   ins_encode %{
16506     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16507             as_FloatRegister($src1$$reg),
16508             as_FloatRegister($src2$$reg));
16509   %}
16510   ins_pipe(vdop_fp64);
16511 %}
16512 
16513 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16514 %{
16515   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16516   match(Set dst (AddVF src1 src2));
16517   ins_cost(INSN_COST);
16518   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16519   ins_encode %{
16520     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16521             as_FloatRegister($src1$$reg),
16522             as_FloatRegister($src2$$reg));
16523   %}
16524   ins_pipe(vdop_fp128);
16525 %}
16526 
16527 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16528 %{
16529   match(Set dst (AddVD src1 src2));
16530   ins_cost(INSN_COST);
16531   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16532   ins_encode %{
16533     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16534             as_FloatRegister($src1$$reg),
16535             as_FloatRegister($src2$$reg));
16536   %}
16537   ins_pipe(vdop_fp128);
16538 %}
16539 
16540 // --------------------------------- SUB --------------------------------------
16541 
16542 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16543 %{
16544   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16545             n-&gt;as_Vector()-&gt;length() == 8);
16546   match(Set dst (SubVB src1 src2));
16547   ins_cost(INSN_COST);
16548   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16549   ins_encode %{
16550     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16551             as_FloatRegister($src1$$reg),
16552             as_FloatRegister($src2$$reg));
16553   %}
16554   ins_pipe(vdop64);
16555 %}
16556 
16557 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16558 %{
16559   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16560   match(Set dst (SubVB src1 src2));
16561   ins_cost(INSN_COST);
16562   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16563   ins_encode %{
16564     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16565             as_FloatRegister($src1$$reg),
16566             as_FloatRegister($src2$$reg));
16567   %}
16568   ins_pipe(vdop128);
16569 %}
16570 
16571 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16572 %{
16573   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16574             n-&gt;as_Vector()-&gt;length() == 4);
16575   match(Set dst (SubVS src1 src2));
16576   ins_cost(INSN_COST);
16577   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16578   ins_encode %{
16579     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16580             as_FloatRegister($src1$$reg),
16581             as_FloatRegister($src2$$reg));
16582   %}
16583   ins_pipe(vdop64);
16584 %}
16585 
16586 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16587 %{
16588   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16589   match(Set dst (SubVS src1 src2));
16590   ins_cost(INSN_COST);
16591   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16592   ins_encode %{
16593     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16594             as_FloatRegister($src1$$reg),
16595             as_FloatRegister($src2$$reg));
16596   %}
16597   ins_pipe(vdop128);
16598 %}
16599 
16600 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16601 %{
16602   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16603   match(Set dst (SubVI src1 src2));
16604   ins_cost(INSN_COST);
16605   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16606   ins_encode %{
16607     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16608             as_FloatRegister($src1$$reg),
16609             as_FloatRegister($src2$$reg));
16610   %}
16611   ins_pipe(vdop64);
16612 %}
16613 
16614 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16615 %{
16616   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16617   match(Set dst (SubVI src1 src2));
16618   ins_cost(INSN_COST);
16619   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16620   ins_encode %{
16621     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16622             as_FloatRegister($src1$$reg),
16623             as_FloatRegister($src2$$reg));
16624   %}
16625   ins_pipe(vdop128);
16626 %}
16627 
16628 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16629 %{
16630   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16631   match(Set dst (SubVL src1 src2));
16632   ins_cost(INSN_COST);
16633   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16634   ins_encode %{
16635     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16636             as_FloatRegister($src1$$reg),
16637             as_FloatRegister($src2$$reg));
16638   %}
16639   ins_pipe(vdop128);
16640 %}
16641 
16642 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16643 %{
16644   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16645   match(Set dst (SubVF src1 src2));
16646   ins_cost(INSN_COST);
16647   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16648   ins_encode %{
16649     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16650             as_FloatRegister($src1$$reg),
16651             as_FloatRegister($src2$$reg));
16652   %}
16653   ins_pipe(vdop_fp64);
16654 %}
16655 
16656 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16657 %{
16658   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16659   match(Set dst (SubVF src1 src2));
16660   ins_cost(INSN_COST);
16661   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16662   ins_encode %{
16663     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16664             as_FloatRegister($src1$$reg),
16665             as_FloatRegister($src2$$reg));
16666   %}
16667   ins_pipe(vdop_fp128);
16668 %}
16669 
16670 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16671 %{
16672   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16673   match(Set dst (SubVD src1 src2));
16674   ins_cost(INSN_COST);
16675   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16676   ins_encode %{
16677     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16678             as_FloatRegister($src1$$reg),
16679             as_FloatRegister($src2$$reg));
16680   %}
16681   ins_pipe(vdop_fp128);
16682 %}
16683 
16684 // --------------------------------- MUL --------------------------------------
16685 
16686 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16687 %{
16688   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16689             n-&gt;as_Vector()-&gt;length() == 4);
16690   match(Set dst (MulVS src1 src2));
16691   ins_cost(INSN_COST);
16692   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16693   ins_encode %{
16694     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16695             as_FloatRegister($src1$$reg),
16696             as_FloatRegister($src2$$reg));
16697   %}
16698   ins_pipe(vmul64);
16699 %}
16700 
16701 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16702 %{
16703   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16704   match(Set dst (MulVS src1 src2));
16705   ins_cost(INSN_COST);
16706   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16707   ins_encode %{
16708     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16709             as_FloatRegister($src1$$reg),
16710             as_FloatRegister($src2$$reg));
16711   %}
16712   ins_pipe(vmul128);
16713 %}
16714 
16715 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16716 %{
16717   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16718   match(Set dst (MulVI src1 src2));
16719   ins_cost(INSN_COST);
16720   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16721   ins_encode %{
16722     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16723             as_FloatRegister($src1$$reg),
16724             as_FloatRegister($src2$$reg));
16725   %}
16726   ins_pipe(vmul64);
16727 %}
16728 
16729 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16730 %{
16731   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16732   match(Set dst (MulVI src1 src2));
16733   ins_cost(INSN_COST);
16734   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16735   ins_encode %{
16736     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16737             as_FloatRegister($src1$$reg),
16738             as_FloatRegister($src2$$reg));
16739   %}
16740   ins_pipe(vmul128);
16741 %}
16742 
16743 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16744 %{
16745   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16746   match(Set dst (MulVF src1 src2));
16747   ins_cost(INSN_COST);
16748   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16749   ins_encode %{
16750     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16751             as_FloatRegister($src1$$reg),
16752             as_FloatRegister($src2$$reg));
16753   %}
16754   ins_pipe(vmuldiv_fp64);
16755 %}
16756 
16757 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16758 %{
16759   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16760   match(Set dst (MulVF src1 src2));
16761   ins_cost(INSN_COST);
16762   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16763   ins_encode %{
16764     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16765             as_FloatRegister($src1$$reg),
16766             as_FloatRegister($src2$$reg));
16767   %}
16768   ins_pipe(vmuldiv_fp128);
16769 %}
16770 
16771 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16772 %{
16773   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16774   match(Set dst (MulVD src1 src2));
16775   ins_cost(INSN_COST);
16776   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16777   ins_encode %{
16778     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16779             as_FloatRegister($src1$$reg),
16780             as_FloatRegister($src2$$reg));
16781   %}
16782   ins_pipe(vmuldiv_fp128);
16783 %}
16784 
16785 // --------------------------------- MLA --------------------------------------
16786 
16787 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16788 %{
16789   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16790             n-&gt;as_Vector()-&gt;length() == 4);
16791   match(Set dst (AddVS dst (MulVS src1 src2)));
16792   ins_cost(INSN_COST);
16793   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16794   ins_encode %{
16795     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16796             as_FloatRegister($src1$$reg),
16797             as_FloatRegister($src2$$reg));
16798   %}
16799   ins_pipe(vmla64);
16800 %}
16801 
16802 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16803 %{
16804   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16805   match(Set dst (AddVS dst (MulVS src1 src2)));
16806   ins_cost(INSN_COST);
16807   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16808   ins_encode %{
16809     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16810             as_FloatRegister($src1$$reg),
16811             as_FloatRegister($src2$$reg));
16812   %}
16813   ins_pipe(vmla128);
16814 %}
16815 
16816 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16817 %{
16818   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16819   match(Set dst (AddVI dst (MulVI src1 src2)));
16820   ins_cost(INSN_COST);
16821   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16822   ins_encode %{
16823     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16824             as_FloatRegister($src1$$reg),
16825             as_FloatRegister($src2$$reg));
16826   %}
16827   ins_pipe(vmla64);
16828 %}
16829 
16830 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16831 %{
16832   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16833   match(Set dst (AddVI dst (MulVI src1 src2)));
16834   ins_cost(INSN_COST);
16835   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16836   ins_encode %{
16837     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16838             as_FloatRegister($src1$$reg),
16839             as_FloatRegister($src2$$reg));
16840   %}
16841   ins_pipe(vmla128);
16842 %}
16843 
16844 // dst + src1 * src2
16845 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16846   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16847   match(Set dst (FmaVF  dst (Binary src1 src2)));
16848   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16849   ins_cost(INSN_COST);
16850   ins_encode %{
16851     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16852             as_FloatRegister($src1$$reg),
16853             as_FloatRegister($src2$$reg));
16854   %}
16855   ins_pipe(vmuldiv_fp64);
16856 %}
16857 
16858 // dst + src1 * src2
16859 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16860   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16861   match(Set dst (FmaVF  dst (Binary src1 src2)));
16862   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16863   ins_cost(INSN_COST);
16864   ins_encode %{
16865     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16866             as_FloatRegister($src1$$reg),
16867             as_FloatRegister($src2$$reg));
16868   %}
16869   ins_pipe(vmuldiv_fp128);
16870 %}
16871 
16872 // dst + src1 * src2
16873 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16874   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16875   match(Set dst (FmaVD  dst (Binary src1 src2)));
16876   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16877   ins_cost(INSN_COST);
16878   ins_encode %{
16879     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16880             as_FloatRegister($src1$$reg),
16881             as_FloatRegister($src2$$reg));
16882   %}
16883   ins_pipe(vmuldiv_fp128);
16884 %}
16885 
16886 // --------------------------------- MLS --------------------------------------
16887 
16888 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16889 %{
16890   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16891             n-&gt;as_Vector()-&gt;length() == 4);
16892   match(Set dst (SubVS dst (MulVS src1 src2)));
16893   ins_cost(INSN_COST);
16894   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16895   ins_encode %{
16896     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16897             as_FloatRegister($src1$$reg),
16898             as_FloatRegister($src2$$reg));
16899   %}
16900   ins_pipe(vmla64);
16901 %}
16902 
16903 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16904 %{
16905   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16906   match(Set dst (SubVS dst (MulVS src1 src2)));
16907   ins_cost(INSN_COST);
16908   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16909   ins_encode %{
16910     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16911             as_FloatRegister($src1$$reg),
16912             as_FloatRegister($src2$$reg));
16913   %}
16914   ins_pipe(vmla128);
16915 %}
16916 
16917 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16918 %{
16919   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16920   match(Set dst (SubVI dst (MulVI src1 src2)));
16921   ins_cost(INSN_COST);
16922   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16923   ins_encode %{
16924     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16925             as_FloatRegister($src1$$reg),
16926             as_FloatRegister($src2$$reg));
16927   %}
16928   ins_pipe(vmla64);
16929 %}
16930 
16931 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16932 %{
16933   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16934   match(Set dst (SubVI dst (MulVI src1 src2)));
16935   ins_cost(INSN_COST);
16936   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16937   ins_encode %{
16938     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16939             as_FloatRegister($src1$$reg),
16940             as_FloatRegister($src2$$reg));
16941   %}
16942   ins_pipe(vmla128);
16943 %}
16944 
16945 // dst - src1 * src2
16946 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16947   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16948   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16949   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16950   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16951   ins_cost(INSN_COST);
16952   ins_encode %{
16953     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16954             as_FloatRegister($src1$$reg),
16955             as_FloatRegister($src2$$reg));
16956   %}
16957   ins_pipe(vmuldiv_fp64);
16958 %}
16959 
16960 // dst - src1 * src2
16961 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16962   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16963   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16964   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16965   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16966   ins_cost(INSN_COST);
16967   ins_encode %{
16968     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16969             as_FloatRegister($src1$$reg),
16970             as_FloatRegister($src2$$reg));
16971   %}
16972   ins_pipe(vmuldiv_fp128);
16973 %}
16974 
16975 // dst - src1 * src2
16976 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16977   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16978   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16979   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16980   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16981   ins_cost(INSN_COST);
16982   ins_encode %{
16983     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16984             as_FloatRegister($src1$$reg),
16985             as_FloatRegister($src2$$reg));
16986   %}
16987   ins_pipe(vmuldiv_fp128);
16988 %}
16989 
16990 // --------------- Vector Multiply-Add Shorts into Integer --------------------
16991 
16992 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
16993   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
16994   match(Set dst (MulAddVS2VI src1 src2));
16995   ins_cost(INSN_COST);
16996   effect(TEMP_DEF dst, TEMP tmp);
16997   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
16998             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
16999             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17000   ins_encode %{
17001     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17002               as_FloatRegister($src1$$reg),
17003               as_FloatRegister($src2$$reg));
17004     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17005               as_FloatRegister($src1$$reg),
17006               as_FloatRegister($src2$$reg));
17007     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17008              as_FloatRegister($tmp$$reg),
17009              as_FloatRegister($dst$$reg));
17010   %}
17011   ins_pipe(vmuldiv_fp128);
17012 %}
17013 
17014 // --------------------------------- DIV --------------------------------------
17015 
17016 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
17017 %{
17018   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17019   match(Set dst (DivVF src1 src2));
17020   ins_cost(INSN_COST);
17021   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17022   ins_encode %{
17023     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17024             as_FloatRegister($src1$$reg),
17025             as_FloatRegister($src2$$reg));
17026   %}
17027   ins_pipe(vmuldiv_fp64);
17028 %}
17029 
17030 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17031 %{
17032   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17033   match(Set dst (DivVF src1 src2));
17034   ins_cost(INSN_COST);
17035   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17036   ins_encode %{
17037     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17038             as_FloatRegister($src1$$reg),
17039             as_FloatRegister($src2$$reg));
17040   %}
17041   ins_pipe(vmuldiv_fp128);
17042 %}
17043 
17044 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17045 %{
17046   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17047   match(Set dst (DivVD src1 src2));
17048   ins_cost(INSN_COST);
17049   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17050   ins_encode %{
17051     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17052             as_FloatRegister($src1$$reg),
17053             as_FloatRegister($src2$$reg));
17054   %}
17055   ins_pipe(vmuldiv_fp128);
17056 %}
17057 
17058 // --------------------------------- SQRT -------------------------------------
17059 
17060 instruct vsqrt2D(vecX dst, vecX src)
17061 %{
17062   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17063   match(Set dst (SqrtVD src));
17064   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17065   ins_encode %{
17066     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17067              as_FloatRegister($src$$reg));
17068   %}
17069   ins_pipe(vsqrt_fp128);
17070 %}
17071 
17072 // --------------------------------- ABS --------------------------------------
17073 
17074 instruct vabs2F(vecD dst, vecD src)
17075 %{
17076   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17077   match(Set dst (AbsVF src));
17078   ins_cost(INSN_COST * 3);
17079   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17080   ins_encode %{
17081     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17082             as_FloatRegister($src$$reg));
17083   %}
17084   ins_pipe(vunop_fp64);
17085 %}
17086 
17087 instruct vabs4F(vecX dst, vecX src)
17088 %{
17089   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17090   match(Set dst (AbsVF src));
17091   ins_cost(INSN_COST * 3);
17092   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17093   ins_encode %{
17094     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17095             as_FloatRegister($src$$reg));
17096   %}
17097   ins_pipe(vunop_fp128);
17098 %}
17099 
17100 instruct vabs2D(vecX dst, vecX src)
17101 %{
17102   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17103   match(Set dst (AbsVD src));
17104   ins_cost(INSN_COST * 3);
17105   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17106   ins_encode %{
17107     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17108             as_FloatRegister($src$$reg));
17109   %}
17110   ins_pipe(vunop_fp128);
17111 %}
17112 
17113 // --------------------------------- NEG --------------------------------------
17114 
17115 instruct vneg2F(vecD dst, vecD src)
17116 %{
17117   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17118   match(Set dst (NegVF src));
17119   ins_cost(INSN_COST * 3);
17120   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17121   ins_encode %{
17122     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17123             as_FloatRegister($src$$reg));
17124   %}
17125   ins_pipe(vunop_fp64);
17126 %}
17127 
17128 instruct vneg4F(vecX dst, vecX src)
17129 %{
17130   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17131   match(Set dst (NegVF src));
17132   ins_cost(INSN_COST * 3);
17133   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17134   ins_encode %{
17135     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17136             as_FloatRegister($src$$reg));
17137   %}
17138   ins_pipe(vunop_fp128);
17139 %}
17140 
17141 instruct vneg2D(vecX dst, vecX src)
17142 %{
17143   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17144   match(Set dst (NegVD src));
17145   ins_cost(INSN_COST * 3);
17146   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17147   ins_encode %{
17148     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17149             as_FloatRegister($src$$reg));
17150   %}
17151   ins_pipe(vunop_fp128);
17152 %}
17153 
17154 // --------------------------------- AND --------------------------------------
17155 
17156 instruct vand8B(vecD dst, vecD src1, vecD src2)
17157 %{
17158   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17159             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17160   match(Set dst (AndV src1 src2));
17161   ins_cost(INSN_COST);
17162   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17163   ins_encode %{
17164     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17165             as_FloatRegister($src1$$reg),
17166             as_FloatRegister($src2$$reg));
17167   %}
17168   ins_pipe(vlogical64);
17169 %}
17170 
17171 instruct vand16B(vecX dst, vecX src1, vecX src2)
17172 %{
17173   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17174   match(Set dst (AndV src1 src2));
17175   ins_cost(INSN_COST);
17176   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17177   ins_encode %{
17178     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17179             as_FloatRegister($src1$$reg),
17180             as_FloatRegister($src2$$reg));
17181   %}
17182   ins_pipe(vlogical128);
17183 %}
17184 
17185 // --------------------------------- OR ---------------------------------------
17186 
17187 instruct vor8B(vecD dst, vecD src1, vecD src2)
17188 %{
17189   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17190             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17191   match(Set dst (OrV src1 src2));
17192   ins_cost(INSN_COST);
17193   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17194   ins_encode %{
17195     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17196             as_FloatRegister($src1$$reg),
17197             as_FloatRegister($src2$$reg));
17198   %}
17199   ins_pipe(vlogical64);
17200 %}
17201 
17202 instruct vor16B(vecX dst, vecX src1, vecX src2)
17203 %{
17204   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17205   match(Set dst (OrV src1 src2));
17206   ins_cost(INSN_COST);
17207   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17208   ins_encode %{
17209     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17210             as_FloatRegister($src1$$reg),
17211             as_FloatRegister($src2$$reg));
17212   %}
17213   ins_pipe(vlogical128);
17214 %}
17215 
17216 // --------------------------------- XOR --------------------------------------
17217 
17218 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17219 %{
17220   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17221             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17222   match(Set dst (XorV src1 src2));
17223   ins_cost(INSN_COST);
17224   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17225   ins_encode %{
17226     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17227             as_FloatRegister($src1$$reg),
17228             as_FloatRegister($src2$$reg));
17229   %}
17230   ins_pipe(vlogical64);
17231 %}
17232 
17233 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17234 %{
17235   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17236   match(Set dst (XorV src1 src2));
17237   ins_cost(INSN_COST);
17238   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17239   ins_encode %{
17240     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17241             as_FloatRegister($src1$$reg),
17242             as_FloatRegister($src2$$reg));
17243   %}
17244   ins_pipe(vlogical128);
17245 %}
17246 
17247 // ------------------------------ Shift ---------------------------------------
17248 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17249   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17250   match(Set dst (LShiftCntV cnt));
17251   match(Set dst (RShiftCntV cnt));
17252   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17253   ins_encode %{
17254     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17255   %}
17256   ins_pipe(vdup_reg_reg64);
17257 %}
17258 
17259 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17260   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17261   match(Set dst (LShiftCntV cnt));
17262   match(Set dst (RShiftCntV cnt));
17263   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17264   ins_encode %{
17265     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17266   %}
17267   ins_pipe(vdup_reg_reg128);
17268 %}
17269 
17270 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17271   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17272             n-&gt;as_Vector()-&gt;length() == 8);
17273   match(Set dst (LShiftVB src shift));
17274   ins_cost(INSN_COST);
17275   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17276   ins_encode %{
17277     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17278             as_FloatRegister($src$$reg),
17279             as_FloatRegister($shift$$reg));
17280   %}
17281   ins_pipe(vshift64);
17282 %}
17283 
17284 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17285   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17286   match(Set dst (LShiftVB src shift));
17287   ins_cost(INSN_COST);
17288   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17289   ins_encode %{
17290     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17291             as_FloatRegister($src$$reg),
17292             as_FloatRegister($shift$$reg));
17293   %}
17294   ins_pipe(vshift128);
17295 %}
17296 
17297 // Right shifts with vector shift count on aarch64 SIMD are implemented
17298 // as left shift by negative shift count.
17299 // There are two cases for vector shift count.
17300 //
17301 // Case 1: The vector shift count is from replication.
17302 //        |            |
17303 //    LoadVector  RShiftCntV
17304 //        |       /
17305 //     RShiftVI
17306 // Note: In inner loop, multiple neg instructions are used, which can be
17307 // moved to outer loop and merge into one neg instruction.
17308 //
17309 // Case 2: The vector shift count is from loading.
17310 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17311 // panama/vectorIntrinsics(JEP 338: Vector API).
17312 //        |            |
17313 //    LoadVector  LoadVector
17314 //        |       /
17315 //     RShiftVI
17316 //
17317 
17318 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17319   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17320             n-&gt;as_Vector()-&gt;length() == 8);
17321   match(Set dst (RShiftVB src shift));
17322   ins_cost(INSN_COST);
17323   effect(TEMP tmp);
17324   format %{ &quot;negr  $tmp,$shift\t&quot;
17325             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17326   ins_encode %{
17327     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17328             as_FloatRegister($shift$$reg));
17329     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17330             as_FloatRegister($src$$reg),
17331             as_FloatRegister($tmp$$reg));
17332   %}
17333   ins_pipe(vshift64);
17334 %}
17335 
17336 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17337   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17338   match(Set dst (RShiftVB src shift));
17339   ins_cost(INSN_COST);
17340   effect(TEMP tmp);
17341   format %{ &quot;negr  $tmp,$shift\t&quot;
17342             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17343   ins_encode %{
17344     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17345             as_FloatRegister($shift$$reg));
17346     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17347             as_FloatRegister($src$$reg),
17348             as_FloatRegister($tmp$$reg));
17349   %}
17350   ins_pipe(vshift128);
17351 %}
17352 
17353 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17354   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17355             n-&gt;as_Vector()-&gt;length() == 8);
17356   match(Set dst (URShiftVB src shift));
17357   ins_cost(INSN_COST);
17358   effect(TEMP tmp);
17359   format %{ &quot;negr  $tmp,$shift\t&quot;
17360             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17361   ins_encode %{
17362     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17363             as_FloatRegister($shift$$reg));
17364     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17365             as_FloatRegister($src$$reg),
17366             as_FloatRegister($tmp$$reg));
17367   %}
17368   ins_pipe(vshift64);
17369 %}
17370 
17371 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17372   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17373   match(Set dst (URShiftVB src shift));
17374   ins_cost(INSN_COST);
17375   effect(TEMP tmp);
17376   format %{ &quot;negr  $tmp,$shift\t&quot;
17377             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17378   ins_encode %{
17379     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17380             as_FloatRegister($shift$$reg));
17381     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17382             as_FloatRegister($src$$reg),
17383             as_FloatRegister($tmp$$reg));
17384   %}
17385   ins_pipe(vshift128);
17386 %}
17387 
17388 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17389   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17390             n-&gt;as_Vector()-&gt;length() == 8);
17391   match(Set dst (LShiftVB src (LShiftCntV shift)));
17392   ins_cost(INSN_COST);
17393   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17394   ins_encode %{
17395     int sh = (int)$shift$$constant;
17396     if (sh &gt;= 8) {
17397       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17398              as_FloatRegister($src$$reg),
17399              as_FloatRegister($src$$reg));
17400     } else {
17401       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17402              as_FloatRegister($src$$reg), sh);
17403     }
17404   %}
17405   ins_pipe(vshift64_imm);
17406 %}
17407 
17408 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17409   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17410   match(Set dst (LShiftVB src (LShiftCntV shift)));
17411   ins_cost(INSN_COST);
17412   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17413   ins_encode %{
17414     int sh = (int)$shift$$constant;
17415     if (sh &gt;= 8) {
17416       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17417              as_FloatRegister($src$$reg),
17418              as_FloatRegister($src$$reg));
17419     } else {
17420       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17421              as_FloatRegister($src$$reg), sh);
17422     }
17423   %}
17424   ins_pipe(vshift128_imm);
17425 %}
17426 
17427 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17428   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17429             n-&gt;as_Vector()-&gt;length() == 8);
17430   match(Set dst (RShiftVB src (RShiftCntV shift)));
17431   ins_cost(INSN_COST);
17432   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17433   ins_encode %{
17434     int sh = (int)$shift$$constant;
17435     if (sh &gt;= 8) sh = 7;
17436     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17437            as_FloatRegister($src$$reg), sh);
17438   %}
17439   ins_pipe(vshift64_imm);
17440 %}
17441 
17442 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17443   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17444   match(Set dst (RShiftVB src (RShiftCntV shift)));
17445   ins_cost(INSN_COST);
17446   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17447   ins_encode %{
17448     int sh = (int)$shift$$constant;
17449     if (sh &gt;= 8) sh = 7;
17450     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17451            as_FloatRegister($src$$reg), sh);
17452   %}
17453   ins_pipe(vshift128_imm);
17454 %}
17455 
17456 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17457   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17458             n-&gt;as_Vector()-&gt;length() == 8);
17459   match(Set dst (URShiftVB src (RShiftCntV shift)));
17460   ins_cost(INSN_COST);
17461   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17462   ins_encode %{
17463     int sh = (int)$shift$$constant;
17464     if (sh &gt;= 8) {
17465       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17466              as_FloatRegister($src$$reg),
17467              as_FloatRegister($src$$reg));
17468     } else {
17469       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17470              as_FloatRegister($src$$reg), sh);
17471     }
17472   %}
17473   ins_pipe(vshift64_imm);
17474 %}
17475 
17476 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17477   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17478   match(Set dst (URShiftVB src (RShiftCntV shift)));
17479   ins_cost(INSN_COST);
17480   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17481   ins_encode %{
17482     int sh = (int)$shift$$constant;
17483     if (sh &gt;= 8) {
17484       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17485              as_FloatRegister($src$$reg),
17486              as_FloatRegister($src$$reg));
17487     } else {
17488       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17489              as_FloatRegister($src$$reg), sh);
17490     }
17491   %}
17492   ins_pipe(vshift128_imm);
17493 %}
17494 
17495 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17496   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17497             n-&gt;as_Vector()-&gt;length() == 4);
17498   match(Set dst (LShiftVS src shift));
17499   ins_cost(INSN_COST);
17500   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17501   ins_encode %{
17502     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17503             as_FloatRegister($src$$reg),
17504             as_FloatRegister($shift$$reg));
17505   %}
17506   ins_pipe(vshift64);
17507 %}
17508 
17509 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17510   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17511   match(Set dst (LShiftVS src shift));
17512   ins_cost(INSN_COST);
17513   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17514   ins_encode %{
17515     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17516             as_FloatRegister($src$$reg),
17517             as_FloatRegister($shift$$reg));
17518   %}
17519   ins_pipe(vshift128);
17520 %}
17521 
17522 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17523   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17524             n-&gt;as_Vector()-&gt;length() == 4);
17525   match(Set dst (RShiftVS src shift));
17526   ins_cost(INSN_COST);
17527   effect(TEMP tmp);
17528   format %{ &quot;negr  $tmp,$shift\t&quot;
17529             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17530   ins_encode %{
17531     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17532             as_FloatRegister($shift$$reg));
17533     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17534             as_FloatRegister($src$$reg),
17535             as_FloatRegister($tmp$$reg));
17536   %}
17537   ins_pipe(vshift64);
17538 %}
17539 
17540 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17541   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17542   match(Set dst (RShiftVS src shift));
17543   ins_cost(INSN_COST);
17544   effect(TEMP tmp);
17545   format %{ &quot;negr  $tmp,$shift\t&quot;
17546             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17547   ins_encode %{
17548     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17549             as_FloatRegister($shift$$reg));
17550     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17551             as_FloatRegister($src$$reg),
17552             as_FloatRegister($tmp$$reg));
17553   %}
17554   ins_pipe(vshift128);
17555 %}
17556 
17557 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17558   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17559             n-&gt;as_Vector()-&gt;length() == 4);
17560   match(Set dst (URShiftVS src shift));
17561   ins_cost(INSN_COST);
17562   effect(TEMP tmp);
17563   format %{ &quot;negr  $tmp,$shift\t&quot;
17564             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17565   ins_encode %{
17566     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17567             as_FloatRegister($shift$$reg));
17568     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17569             as_FloatRegister($src$$reg),
17570             as_FloatRegister($tmp$$reg));
17571   %}
17572   ins_pipe(vshift64);
17573 %}
17574 
17575 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17576   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17577   match(Set dst (URShiftVS src shift));
17578   ins_cost(INSN_COST);
17579   effect(TEMP tmp);
17580   format %{ &quot;negr  $tmp,$shift\t&quot;
17581             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17582   ins_encode %{
17583     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17584             as_FloatRegister($shift$$reg));
17585     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17586             as_FloatRegister($src$$reg),
17587             as_FloatRegister($tmp$$reg));
17588   %}
17589   ins_pipe(vshift128);
17590 %}
17591 
17592 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17593   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17594             n-&gt;as_Vector()-&gt;length() == 4);
17595   match(Set dst (LShiftVS src (LShiftCntV shift)));
17596   ins_cost(INSN_COST);
17597   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17598   ins_encode %{
17599     int sh = (int)$shift$$constant;
17600     if (sh &gt;= 16) {
17601       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17602              as_FloatRegister($src$$reg),
17603              as_FloatRegister($src$$reg));
17604     } else {
17605       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17606              as_FloatRegister($src$$reg), sh);
17607     }
17608   %}
17609   ins_pipe(vshift64_imm);
17610 %}
17611 
17612 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17613   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17614   match(Set dst (LShiftVS src (LShiftCntV shift)));
17615   ins_cost(INSN_COST);
17616   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17617   ins_encode %{
17618     int sh = (int)$shift$$constant;
17619     if (sh &gt;= 16) {
17620       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17621              as_FloatRegister($src$$reg),
17622              as_FloatRegister($src$$reg));
17623     } else {
17624       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17625              as_FloatRegister($src$$reg), sh);
17626     }
17627   %}
17628   ins_pipe(vshift128_imm);
17629 %}
17630 
17631 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17632   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17633             n-&gt;as_Vector()-&gt;length() == 4);
17634   match(Set dst (RShiftVS src (LShiftCntV shift)));
17635   ins_cost(INSN_COST);
17636   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17637   ins_encode %{
17638     int sh = (int)$shift$$constant;
17639     if (sh &gt;= 16) sh = 15;
17640     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17641            as_FloatRegister($src$$reg), sh);
17642   %}
17643   ins_pipe(vshift64_imm);
17644 %}
17645 
17646 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17647   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17648   match(Set dst (RShiftVS src (LShiftCntV shift)));
17649   ins_cost(INSN_COST);
17650   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17651   ins_encode %{
17652     int sh = (int)$shift$$constant;
17653     if (sh &gt;= 16) sh = 15;
17654     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17655            as_FloatRegister($src$$reg), sh);
17656   %}
17657   ins_pipe(vshift128_imm);
17658 %}
17659 
17660 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17661   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17662             n-&gt;as_Vector()-&gt;length() == 4);
17663   match(Set dst (URShiftVS src (RShiftCntV shift)));
17664   ins_cost(INSN_COST);
17665   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17666   ins_encode %{
17667     int sh = (int)$shift$$constant;
17668     if (sh &gt;= 16) {
17669       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17670              as_FloatRegister($src$$reg),
17671              as_FloatRegister($src$$reg));
17672     } else {
17673       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17674              as_FloatRegister($src$$reg), sh);
17675     }
17676   %}
17677   ins_pipe(vshift64_imm);
17678 %}
17679 
17680 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17681   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17682   match(Set dst (URShiftVS src (RShiftCntV shift)));
17683   ins_cost(INSN_COST);
17684   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17685   ins_encode %{
17686     int sh = (int)$shift$$constant;
17687     if (sh &gt;= 16) {
17688       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17689              as_FloatRegister($src$$reg),
17690              as_FloatRegister($src$$reg));
17691     } else {
17692       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17693              as_FloatRegister($src$$reg), sh);
17694     }
17695   %}
17696   ins_pipe(vshift128_imm);
17697 %}
17698 
17699 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17700   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17701   match(Set dst (LShiftVI src shift));
17702   ins_cost(INSN_COST);
17703   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17704   ins_encode %{
17705     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17706             as_FloatRegister($src$$reg),
17707             as_FloatRegister($shift$$reg));
17708   %}
17709   ins_pipe(vshift64);
17710 %}
17711 
17712 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17713   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17714   match(Set dst (LShiftVI src shift));
17715   ins_cost(INSN_COST);
17716   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17717   ins_encode %{
17718     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17719             as_FloatRegister($src$$reg),
17720             as_FloatRegister($shift$$reg));
17721   %}
17722   ins_pipe(vshift128);
17723 %}
17724 
17725 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17726   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17727   match(Set dst (RShiftVI src shift));
17728   ins_cost(INSN_COST);
17729   effect(TEMP tmp);
17730   format %{ &quot;negr  $tmp,$shift\t&quot;
17731             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17732   ins_encode %{
17733     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17734             as_FloatRegister($shift$$reg));
17735     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17736             as_FloatRegister($src$$reg),
17737             as_FloatRegister($tmp$$reg));
17738   %}
17739   ins_pipe(vshift64);
17740 %}
17741 
17742 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17743   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17744   match(Set dst (RShiftVI src shift));
17745   ins_cost(INSN_COST);
17746   effect(TEMP tmp);
17747   format %{ &quot;negr  $tmp,$shift\t&quot;
17748             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17749   ins_encode %{
17750     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17751             as_FloatRegister($shift$$reg));
17752     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17753             as_FloatRegister($src$$reg),
17754             as_FloatRegister($tmp$$reg));
17755   %}
17756   ins_pipe(vshift128);
17757 %}
17758 
17759 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17760   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17761   match(Set dst (URShiftVI src shift));
17762   ins_cost(INSN_COST);
17763   effect(TEMP tmp);
17764   format %{ &quot;negr  $tmp,$shift\t&quot;
17765             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17766   ins_encode %{
17767     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17768             as_FloatRegister($shift$$reg));
17769     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17770             as_FloatRegister($src$$reg),
17771             as_FloatRegister($tmp$$reg));
17772   %}
17773   ins_pipe(vshift64);
17774 %}
17775 
17776 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17777   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17778   match(Set dst (URShiftVI src shift));
17779   ins_cost(INSN_COST);
17780   effect(TEMP tmp);
17781   format %{ &quot;negr  $tmp,$shift\t&quot;
17782             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17783   ins_encode %{
17784     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17785             as_FloatRegister($shift$$reg));
17786     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17787             as_FloatRegister($src$$reg),
17788             as_FloatRegister($tmp$$reg));
17789   %}
17790   ins_pipe(vshift128);
17791 %}
17792 
17793 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17794   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17795   match(Set dst (LShiftVI src (LShiftCntV shift)));
17796   ins_cost(INSN_COST);
17797   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17798   ins_encode %{
17799     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17800            as_FloatRegister($src$$reg),
17801            (int)$shift$$constant);
17802   %}
17803   ins_pipe(vshift64_imm);
17804 %}
17805 
17806 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17807   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17808   match(Set dst (LShiftVI src (LShiftCntV shift)));
17809   ins_cost(INSN_COST);
17810   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17811   ins_encode %{
17812     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17813            as_FloatRegister($src$$reg),
17814            (int)$shift$$constant);
17815   %}
17816   ins_pipe(vshift128_imm);
17817 %}
17818 
17819 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17820   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17821   match(Set dst (RShiftVI src (RShiftCntV shift)));
17822   ins_cost(INSN_COST);
17823   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17824   ins_encode %{
17825     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17826             as_FloatRegister($src$$reg),
17827             (int)$shift$$constant);
17828   %}
17829   ins_pipe(vshift64_imm);
17830 %}
17831 
17832 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17833   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17834   match(Set dst (RShiftVI src (RShiftCntV shift)));
17835   ins_cost(INSN_COST);
17836   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17837   ins_encode %{
17838     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17839             as_FloatRegister($src$$reg),
17840             (int)$shift$$constant);
17841   %}
17842   ins_pipe(vshift128_imm);
17843 %}
17844 
17845 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17846   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17847   match(Set dst (URShiftVI src (RShiftCntV shift)));
17848   ins_cost(INSN_COST);
17849   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17850   ins_encode %{
17851     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17852             as_FloatRegister($src$$reg),
17853             (int)$shift$$constant);
17854   %}
17855   ins_pipe(vshift64_imm);
17856 %}
17857 
17858 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17859   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17860   match(Set dst (URShiftVI src (RShiftCntV shift)));
17861   ins_cost(INSN_COST);
17862   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17863   ins_encode %{
17864     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17865             as_FloatRegister($src$$reg),
17866             (int)$shift$$constant);
17867   %}
17868   ins_pipe(vshift128_imm);
17869 %}
17870 
17871 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17872   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17873   match(Set dst (LShiftVL src shift));
17874   ins_cost(INSN_COST);
17875   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17876   ins_encode %{
17877     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17878             as_FloatRegister($src$$reg),
17879             as_FloatRegister($shift$$reg));
17880   %}
17881   ins_pipe(vshift128);
17882 %}
17883 
17884 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17885   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17886   match(Set dst (RShiftVL src shift));
17887   ins_cost(INSN_COST);
17888   effect(TEMP tmp);
17889   format %{ &quot;negr  $tmp,$shift\t&quot;
17890             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17891   ins_encode %{
17892     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17893             as_FloatRegister($shift$$reg));
17894     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17895             as_FloatRegister($src$$reg),
17896             as_FloatRegister($tmp$$reg));
17897   %}
17898   ins_pipe(vshift128);
17899 %}
17900 
17901 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17902   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17903   match(Set dst (URShiftVL src shift));
17904   ins_cost(INSN_COST);
17905   effect(TEMP tmp);
17906   format %{ &quot;negr  $tmp,$shift\t&quot;
17907             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17908   ins_encode %{
17909     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17910             as_FloatRegister($shift$$reg));
17911     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17912             as_FloatRegister($src$$reg),
17913             as_FloatRegister($tmp$$reg));
17914   %}
17915   ins_pipe(vshift128);
17916 %}
17917 
17918 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17919   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17920   match(Set dst (LShiftVL src (LShiftCntV shift)));
17921   ins_cost(INSN_COST);
17922   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17923   ins_encode %{
17924     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17925            as_FloatRegister($src$$reg),
17926            (int)$shift$$constant);
17927   %}
17928   ins_pipe(vshift128_imm);
17929 %}
17930 
17931 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17932   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17933   match(Set dst (RShiftVL src (RShiftCntV shift)));
17934   ins_cost(INSN_COST);
17935   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17936   ins_encode %{
17937     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17938             as_FloatRegister($src$$reg),
17939             (int)$shift$$constant);
17940   %}
17941   ins_pipe(vshift128_imm);
17942 %}
17943 
17944 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17945   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17946   match(Set dst (URShiftVL src (RShiftCntV shift)));
17947   ins_cost(INSN_COST);
17948   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17949   ins_encode %{
17950     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17951             as_FloatRegister($src$$reg),
17952             (int)$shift$$constant);
17953   %}
17954   ins_pipe(vshift128_imm);
17955 %}
17956 
17957 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17958 %{
17959   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17960   match(Set dst (MaxV src1 src2));
17961   ins_cost(INSN_COST);
17962   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17963   ins_encode %{
17964     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17965             as_FloatRegister($src1$$reg),
17966             as_FloatRegister($src2$$reg));
17967   %}
17968   ins_pipe(vdop_fp64);
17969 %}
17970 
17971 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17972 %{
17973   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17974   match(Set dst (MaxV src1 src2));
17975   ins_cost(INSN_COST);
17976   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17977   ins_encode %{
17978     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17979             as_FloatRegister($src1$$reg),
17980             as_FloatRegister($src2$$reg));
17981   %}
17982   ins_pipe(vdop_fp128);
17983 %}
17984 
17985 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17986 %{
17987   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17988   match(Set dst (MaxV src1 src2));
17989   ins_cost(INSN_COST);
17990   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17991   ins_encode %{
17992     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17993             as_FloatRegister($src1$$reg),
17994             as_FloatRegister($src2$$reg));
17995   %}
17996   ins_pipe(vdop_fp128);
17997 %}
17998 
17999 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18000 %{
18001   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18002   match(Set dst (MinV src1 src2));
18003   ins_cost(INSN_COST);
18004   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18005   ins_encode %{
18006     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18007             as_FloatRegister($src1$$reg),
18008             as_FloatRegister($src2$$reg));
18009   %}
18010   ins_pipe(vdop_fp64);
18011 %}
18012 
18013 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18014 %{
18015   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18016   match(Set dst (MinV src1 src2));
18017   ins_cost(INSN_COST);
18018   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18019   ins_encode %{
18020     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18021             as_FloatRegister($src1$$reg),
18022             as_FloatRegister($src2$$reg));
18023   %}
18024   ins_pipe(vdop_fp128);
18025 %}
18026 
18027 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18028 %{
18029   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18030   match(Set dst (MinV src1 src2));
18031   ins_cost(INSN_COST);
18032   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18033   ins_encode %{
18034     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18035             as_FloatRegister($src1$$reg),
18036             as_FloatRegister($src2$$reg));
18037   %}
18038   ins_pipe(vdop_fp128);
18039 %}
18040 
18041 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18042   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18043   match(Set dst (RoundDoubleModeV src rmode));
18044   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18045   ins_encode %{
18046     switch ($rmode$$constant) {
18047       case RoundDoubleModeNode::rmode_rint:
18048         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18049                   as_FloatRegister($src$$reg));
18050         break;
18051       case RoundDoubleModeNode::rmode_floor:
18052         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18053                   as_FloatRegister($src$$reg));
18054         break;
18055       case RoundDoubleModeNode::rmode_ceil:
18056         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18057                   as_FloatRegister($src$$reg));
18058         break;
18059     }
18060   %}
18061   ins_pipe(vdop_fp128);
18062 %}
18063 
18064 instruct vpopcount4I(vecX dst, vecX src) %{
18065   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18066   match(Set dst (PopCountVI src));
18067   format %{
18068     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18069     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18070     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18071   %}
18072   ins_encode %{
18073      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18074             as_FloatRegister($src$$reg));
18075      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18076                as_FloatRegister($dst$$reg));
18077      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18078                as_FloatRegister($dst$$reg));
18079   %}
18080   ins_pipe(pipe_class_default);
18081 %}
18082 
18083 instruct vpopcount2I(vecD dst, vecD src) %{
18084   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18085   match(Set dst (PopCountVI src));
18086   format %{
18087     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18088     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18089     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18090   %}
18091   ins_encode %{
18092      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18093             as_FloatRegister($src$$reg));
18094      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18095                as_FloatRegister($dst$$reg));
18096      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18097                as_FloatRegister($dst$$reg));
18098   %}
18099   ins_pipe(pipe_class_default);
18100 %}
18101 
18102 //----------PEEPHOLE RULES-----------------------------------------------------
18103 // These must follow all instruction definitions as they use the names
18104 // defined in the instructions definitions.
18105 //
18106 // peepmatch ( root_instr_name [preceding_instruction]* );
18107 //
18108 // peepconstraint %{
18109 // (instruction_number.operand_name relational_op instruction_number.operand_name
18110 //  [, ...] );
18111 // // instruction numbers are zero-based using left to right order in peepmatch
18112 //
18113 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18114 // // provide an instruction_number.operand_name for each operand that appears
18115 // // in the replacement instruction&#39;s match rule
18116 //
18117 // ---------VM FLAGS---------------------------------------------------------
18118 //
18119 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18120 //
18121 // Each peephole rule is given an identifying number starting with zero and
18122 // increasing by one in the order seen by the parser.  An individual peephole
18123 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18124 // on the command-line.
18125 //
18126 // ---------CURRENT LIMITATIONS----------------------------------------------
18127 //
18128 // Only match adjacent instructions in same basic block
18129 // Only equality constraints
18130 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18131 // Only one replacement instruction
18132 //
18133 // ---------EXAMPLE----------------------------------------------------------
18134 //
18135 // // pertinent parts of existing instructions in architecture description
18136 // instruct movI(iRegINoSp dst, iRegI src)
18137 // %{
18138 //   match(Set dst (CopyI src));
18139 // %}
18140 //
18141 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18142 // %{
18143 //   match(Set dst (AddI dst src));
18144 //   effect(KILL cr);
18145 // %}
18146 //
18147 // // Change (inc mov) to lea
18148 // peephole %{
18149 //   // increment preceeded by register-register move
18150 //   peepmatch ( incI_iReg movI );
18151 //   // require that the destination register of the increment
18152 //   // match the destination register of the move
18153 //   peepconstraint ( 0.dst == 1.dst );
18154 //   // construct a replacement instruction that sets
18155 //   // the destination to ( move&#39;s source register + one )
18156 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18157 // %}
18158 //
18159 
18160 // Implementation no longer uses movX instructions since
18161 // machine-independent system no longer uses CopyX nodes.
18162 //
18163 // peephole
18164 // %{
18165 //   peepmatch (incI_iReg movI);
18166 //   peepconstraint (0.dst == 1.dst);
18167 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18168 // %}
18169 
18170 // peephole
18171 // %{
18172 //   peepmatch (decI_iReg movI);
18173 //   peepconstraint (0.dst == 1.dst);
18174 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18175 // %}
18176 
18177 // peephole
18178 // %{
18179 //   peepmatch (addI_iReg_imm movI);
18180 //   peepconstraint (0.dst == 1.dst);
18181 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18182 // %}
18183 
18184 // peephole
18185 // %{
18186 //   peepmatch (incL_iReg movL);
18187 //   peepconstraint (0.dst == 1.dst);
18188 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18189 // %}
18190 
18191 // peephole
18192 // %{
18193 //   peepmatch (decL_iReg movL);
18194 //   peepconstraint (0.dst == 1.dst);
18195 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18196 // %}
18197 
18198 // peephole
18199 // %{
18200 //   peepmatch (addL_iReg_imm movL);
18201 //   peepconstraint (0.dst == 1.dst);
18202 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18203 // %}
18204 
18205 // peephole
18206 // %{
18207 //   peepmatch (addP_iReg_imm movP);
18208 //   peepconstraint (0.dst == 1.dst);
18209 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18210 // %}
18211 
18212 // // Change load of spilled value to only a spill
18213 // instruct storeI(memory mem, iRegI src)
18214 // %{
18215 //   match(Set mem (StoreI mem src));
18216 // %}
18217 //
18218 // instruct loadI(iRegINoSp dst, memory mem)
18219 // %{
18220 //   match(Set dst (LoadI mem));
18221 // %}
18222 //
18223 
18224 //----------SMARTSPILL RULES---------------------------------------------------
18225 // These must follow all instruction definitions as they use the names
18226 // defined in the instructions definitions.
18227 
18228 // Local Variables:
18229 // mode: c++
18230 // End:
<a name="14" id="anc14"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="14" type="hidden" />
</body>
</html>