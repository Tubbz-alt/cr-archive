<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/matcher.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../oops/instanceKlass.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="matcher.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/matcher.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1963     }
1964   }
1965 }
1966 
1967 
1968 // -------------------------------------------------------------------------
1969 // Java-Java calling convention
1970 // (what you use when Java calls Java)
1971 
1972 //------------------------------find_receiver----------------------------------
1973 // For a given signature, return the OptoReg for parameter 0.
1974 OptoReg::Name Matcher::find_receiver( bool is_outgoing ) {
1975   VMRegPair regs;
1976   BasicType sig_bt = T_OBJECT;
1977   calling_convention(&amp;sig_bt, &amp;regs, 1, is_outgoing);
1978   // Return argument 0 register.  In the LP64 build pointers
1979   // take 2 registers, but the VM wants only the &#39;main&#39; name.
1980   return OptoReg::as_OptoReg(regs.first());
1981 }
1982 
<span class="line-removed">1983 // This function identifies sub-graphs in which a &#39;load&#39; node is</span>
<span class="line-removed">1984 // input to two different nodes, and such that it can be matched</span>
<span class="line-removed">1985 // with BMI instructions like blsi, blsr, etc.</span>
<span class="line-removed">1986 // Example : for b = -a[i] &amp; a[i] can be matched to blsi r32, m32.</span>
<span class="line-removed">1987 // The graph is (AndL (SubL Con0 LoadL*) LoadL*), where LoadL*</span>
<span class="line-removed">1988 // refers to the same node.</span>
<span class="line-removed">1989 #ifdef X86</span>
<span class="line-removed">1990 // Match the generic fused operations pattern (op1 (op2 Con{ConType} mop) mop)</span>
<span class="line-removed">1991 // This is a temporary solution until we make DAGs expressible in ADL.</span>
<span class="line-removed">1992 template&lt;typename ConType&gt;</span>
<span class="line-removed">1993 class FusedPatternMatcher {</span>
<span class="line-removed">1994   Node* _op1_node;</span>
<span class="line-removed">1995   Node* _mop_node;</span>
<span class="line-removed">1996   int _con_op;</span>
<span class="line-removed">1997 </span>
<span class="line-removed">1998   static int match_next(Node* n, int next_op, int next_op_idx) {</span>
<span class="line-removed">1999     if (n-&gt;in(1) == NULL || n-&gt;in(2) == NULL) {</span>
<span class="line-removed">2000       return -1;</span>
<span class="line-removed">2001     }</span>
<span class="line-removed">2002 </span>
<span class="line-removed">2003     if (next_op_idx == -1) { // n is commutative, try rotations</span>
<span class="line-removed">2004       if (n-&gt;in(1)-&gt;Opcode() == next_op) {</span>
<span class="line-removed">2005         return 1;</span>
<span class="line-removed">2006       } else if (n-&gt;in(2)-&gt;Opcode() == next_op) {</span>
<span class="line-removed">2007         return 2;</span>
<span class="line-removed">2008       }</span>
<span class="line-removed">2009     } else {</span>
<span class="line-removed">2010       assert(next_op_idx &gt; 0 &amp;&amp; next_op_idx &lt;= 2, &quot;Bad argument index&quot;);</span>
<span class="line-removed">2011       if (n-&gt;in(next_op_idx)-&gt;Opcode() == next_op) {</span>
<span class="line-removed">2012         return next_op_idx;</span>
<span class="line-removed">2013       }</span>
<span class="line-removed">2014     }</span>
<span class="line-removed">2015     return -1;</span>
<span class="line-removed">2016   }</span>
<span class="line-removed">2017 public:</span>
<span class="line-removed">2018   FusedPatternMatcher(Node* op1_node, Node *mop_node, int con_op) :</span>
<span class="line-removed">2019     _op1_node(op1_node), _mop_node(mop_node), _con_op(con_op) { }</span>
<span class="line-removed">2020 </span>
<span class="line-removed">2021   bool match(int op1, int op1_op2_idx,  // op1 and the index of the op1-&gt;op2 edge, -1 if op1 is commutative</span>
<span class="line-removed">2022              int op2, int op2_con_idx,  // op2 and the index of the op2-&gt;con edge, -1 if op2 is commutative</span>
<span class="line-removed">2023              typename ConType::NativeType con_value) {</span>
<span class="line-removed">2024     if (_op1_node-&gt;Opcode() != op1) {</span>
<span class="line-removed">2025       return false;</span>
<span class="line-removed">2026     }</span>
<span class="line-removed">2027     if (_mop_node-&gt;outcnt() &gt; 2) {</span>
<span class="line-removed">2028       return false;</span>
<span class="line-removed">2029     }</span>
<span class="line-removed">2030     op1_op2_idx = match_next(_op1_node, op2, op1_op2_idx);</span>
<span class="line-removed">2031     if (op1_op2_idx == -1) {</span>
<span class="line-removed">2032       return false;</span>
<span class="line-removed">2033     }</span>
<span class="line-removed">2034     // Memory operation must be the other edge</span>
<span class="line-removed">2035     int op1_mop_idx = (op1_op2_idx &amp; 1) + 1;</span>
<span class="line-removed">2036 </span>
<span class="line-removed">2037     // Check that the mop node is really what we want</span>
<span class="line-removed">2038     if (_op1_node-&gt;in(op1_mop_idx) == _mop_node) {</span>
<span class="line-removed">2039       Node *op2_node = _op1_node-&gt;in(op1_op2_idx);</span>
<span class="line-removed">2040       if (op2_node-&gt;outcnt() &gt; 1) {</span>
<span class="line-removed">2041         return false;</span>
<span class="line-removed">2042       }</span>
<span class="line-removed">2043       assert(op2_node-&gt;Opcode() == op2, &quot;Should be&quot;);</span>
<span class="line-removed">2044       op2_con_idx = match_next(op2_node, _con_op, op2_con_idx);</span>
<span class="line-removed">2045       if (op2_con_idx == -1) {</span>
<span class="line-removed">2046         return false;</span>
<span class="line-removed">2047       }</span>
<span class="line-removed">2048       // Memory operation must be the other edge</span>
<span class="line-removed">2049       int op2_mop_idx = (op2_con_idx &amp; 1) + 1;</span>
<span class="line-removed">2050       // Check that the memory operation is the same node</span>
<span class="line-removed">2051       if (op2_node-&gt;in(op2_mop_idx) == _mop_node) {</span>
<span class="line-removed">2052         // Now check the constant</span>
<span class="line-removed">2053         const Type* con_type = op2_node-&gt;in(op2_con_idx)-&gt;bottom_type();</span>
<span class="line-removed">2054         if (con_type != Type::TOP &amp;&amp; ConType::as_self(con_type)-&gt;get_con() == con_value) {</span>
<span class="line-removed">2055           return true;</span>
<span class="line-removed">2056         }</span>
<span class="line-removed">2057       }</span>
<span class="line-removed">2058     }</span>
<span class="line-removed">2059     return false;</span>
<span class="line-removed">2060   }</span>
<span class="line-removed">2061 };</span>
<span class="line-removed">2062 </span>
<span class="line-removed">2063 </span>
<span class="line-removed">2064 bool Matcher::is_bmi_pattern(Node *n, Node *m) {</span>
<span class="line-removed">2065   if (n != NULL &amp;&amp; m != NULL) {</span>
<span class="line-removed">2066     if (m-&gt;Opcode() == Op_LoadI) {</span>
<span class="line-removed">2067       FusedPatternMatcher&lt;TypeInt&gt; bmii(n, m, Op_ConI);</span>
<span class="line-removed">2068       return bmii.match(Op_AndI, -1, Op_SubI,  1,  0)  ||</span>
<span class="line-removed">2069              bmii.match(Op_AndI, -1, Op_AddI, -1, -1)  ||</span>
<span class="line-removed">2070              bmii.match(Op_XorI, -1, Op_AddI, -1, -1);</span>
<span class="line-removed">2071     } else if (m-&gt;Opcode() == Op_LoadL) {</span>
<span class="line-removed">2072       FusedPatternMatcher&lt;TypeLong&gt; bmil(n, m, Op_ConL);</span>
<span class="line-removed">2073       return bmil.match(Op_AndL, -1, Op_SubL,  1,  0) ||</span>
<span class="line-removed">2074              bmil.match(Op_AndL, -1, Op_AddL, -1, -1) ||</span>
<span class="line-removed">2075              bmil.match(Op_XorL, -1, Op_AddL, -1, -1);</span>
<span class="line-removed">2076     }</span>
<span class="line-removed">2077   }</span>
<span class="line-removed">2078   return false;</span>
<span class="line-removed">2079 }</span>
<span class="line-removed">2080 #endif // X86</span>
<span class="line-removed">2081 </span>
2082 bool Matcher::is_vshift_con_pattern(Node *n, Node *m) {
2083   if (n != NULL &amp;&amp; m != NULL) {
2084     return VectorNode::is_vector_shift(n) &amp;&amp;
2085            VectorNode::is_vector_shift_count(m) &amp;&amp; m-&gt;in(1)-&gt;is_Con();
2086   }
2087   return false;
2088 }
2089 
2090 














2091 bool Matcher::clone_base_plus_offset_address(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
2092   Node *off = m-&gt;in(AddPNode::Offset);
2093   if (off-&gt;is_Con()) {
2094     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
2095     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
2096     // Clone X+offset as it also folds into most addressing expressions
2097     mstack.push(off, Visit);
2098     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
2099     return true;
2100   }
2101   return false;
2102 }
2103 
2104 // A method-klass-holder may be passed in the inline_cache_reg
2105 // and then expanded into the inline_cache_reg and a method_oop register
2106 //   defined in ad_&lt;arch&gt;.cpp
2107 
2108 //------------------------------find_shared------------------------------------
2109 // Set bits if Node is shared or otherwise a root
<span class="line-modified">2110 void Matcher::find_shared( Node *n ) {</span>
2111   // Allocate stack of size C-&gt;live_nodes() * 2 to avoid frequent realloc
2112   MStack mstack(C-&gt;live_nodes() * 2);
2113   // Mark nodes as address_visited if they are inputs to an address expression
2114   VectorSet address_visited(Thread::current()-&gt;resource_area());
2115   mstack.push(n, Visit);     // Don&#39;t need to pre-visit root node
2116   while (mstack.is_nonempty()) {
2117     n = mstack.node();       // Leave node on stack
2118     Node_State nstate = mstack.state();
2119     uint nop = n-&gt;Opcode();
2120     if (nstate == Pre_Visit) {
2121       if (address_visited.test(n-&gt;_idx)) { // Visited in address already?
2122         // Flag as visited and shared now.
2123         set_visited(n);
2124       }
2125       if (is_visited(n)) {   // Visited already?
2126         // Node is shared and has no reason to clone.  Flag it as shared.
2127         // This causes it to match into a register for the sharing.
2128         set_shared(n);       // Flag as shared and
2129         if (n-&gt;is_DecodeNarrowPtr()) {
2130           // Oop field/array element loads must be shared but since
2131           // they are shared through a DecodeN they may appear to have
2132           // a single use so force sharing here.
2133           set_shared(n-&gt;in(1));
2134         }
2135         mstack.pop();        // remove node from stack
2136         continue;
2137       }
2138       nstate = Visit; // Not already visited; so visit now
2139     }
2140     if (nstate == Visit) {
2141       mstack.set_state(Post_Visit);
2142       set_visited(n);   // Flag as visited now
2143       bool mem_op = false;
2144       int mem_addr_idx = MemNode::Address;
2145       if (find_shared_visit(mstack, n, nop, mem_op, mem_addr_idx)) {
2146         continue;
2147       }
<span class="line-modified">2148       for(int i = n-&gt;req() - 1; i &gt;= 0; --i) { // For my children</span>
<span class="line-modified">2149         Node *m = n-&gt;in(i); // Get ith input</span>
<span class="line-modified">2150         if (m == NULL) continue;  // Ignore NULLs</span>
<span class="line-modified">2151         uint mop = m-&gt;Opcode();</span>
<span class="line-removed">2152 </span>
<span class="line-removed">2153         // Must clone all producers of flags, or we will not match correctly.</span>
<span class="line-removed">2154         // Suppose a compare setting int-flags is shared (e.g., a switch-tree)</span>
<span class="line-removed">2155         // then it will match into an ideal Op_RegFlags.  Alas, the fp-flags</span>
<span class="line-removed">2156         // are also there, so we may match a float-branch to int-flags and</span>
<span class="line-removed">2157         // expect the allocator to haul the flags from the int-side to the</span>
<span class="line-removed">2158         // fp-side.  No can do.</span>
<span class="line-removed">2159         if( _must_clone[mop] ) {</span>
<span class="line-removed">2160           mstack.push(m, Visit);</span>
<span class="line-removed">2161           continue; // for(int i = ...)</span>
2162         }
<span class="line-modified">2163 </span>
<span class="line-removed">2164         // if &#39;n&#39; and &#39;m&#39; are part of a graph for BMI instruction, clone this node.</span>
<span class="line-removed">2165 #ifdef X86</span>
<span class="line-removed">2166         if (UseBMI1Instructions &amp;&amp; is_bmi_pattern(n, m)) {</span>
<span class="line-removed">2167           mstack.push(m, Visit);</span>
<span class="line-removed">2168           continue;</span>
<span class="line-removed">2169         }</span>
<span class="line-removed">2170 #endif</span>
<span class="line-removed">2171         if (is_vshift_con_pattern(n, m)) {</span>
<span class="line-removed">2172           mstack.push(m, Visit);</span>
2173           continue;
2174         }
2175 
2176         // Clone addressing expressions as they are &quot;free&quot; in memory access instructions
<span class="line-modified">2177         if (mem_op &amp;&amp; i == mem_addr_idx &amp;&amp; mop == Op_AddP &amp;&amp;</span>
2178             // When there are other uses besides address expressions
2179             // put it on stack and mark as shared.
2180             !is_visited(m)) {
2181           // Some inputs for address expression are not put on stack
2182           // to avoid marking them as shared and forcing them into register
2183           // if they are used only in address expressions.
2184           // But they should be marked as shared if there are other uses
2185           // besides address expressions.
2186 
<span class="line-modified">2187           if (clone_address_expressions(m-&gt;as_AddP(), mstack, address_visited)) {</span>
2188             continue;
2189           }
2190         }   // if( mem_op &amp;&amp;
2191         mstack.push(m, Pre_Visit);
2192       }     // for(int i = ...)
2193     }
2194     else if (nstate == Alt_Post_Visit) {
2195       mstack.pop(); // Remove node from stack
2196       // We cannot remove the Cmp input from the Bool here, as the Bool may be
2197       // shared and all users of the Bool need to move the Cmp in parallel.
2198       // This leaves both the Bool and the If pointing at the Cmp.  To
2199       // prevent the Matcher from trying to Match the Cmp along both paths
2200       // BoolNode::match_edge always returns a zero.
2201 
2202       // We reorder the Op_If in a pre-order manner, so we can visit without
2203       // accidentally sharing the Cmp (the Bool and the If make 2 users).
2204       n-&gt;add_req( n-&gt;in(1)-&gt;in(1) ); // Add the Cmp next to the Bool
2205     }
2206     else if (nstate == Post_Visit) {
2207       mstack.pop(); // Remove node from stack
</pre>
</td>
<td>
<hr />
<pre>
1963     }
1964   }
1965 }
1966 
1967 
1968 // -------------------------------------------------------------------------
1969 // Java-Java calling convention
1970 // (what you use when Java calls Java)
1971 
1972 //------------------------------find_receiver----------------------------------
1973 // For a given signature, return the OptoReg for parameter 0.
1974 OptoReg::Name Matcher::find_receiver( bool is_outgoing ) {
1975   VMRegPair regs;
1976   BasicType sig_bt = T_OBJECT;
1977   calling_convention(&amp;sig_bt, &amp;regs, 1, is_outgoing);
1978   // Return argument 0 register.  In the LP64 build pointers
1979   // take 2 registers, but the VM wants only the &#39;main&#39; name.
1980   return OptoReg::as_OptoReg(regs.first());
1981 }
1982 



































































































1983 bool Matcher::is_vshift_con_pattern(Node *n, Node *m) {
1984   if (n != NULL &amp;&amp; m != NULL) {
1985     return VectorNode::is_vector_shift(n) &amp;&amp;
1986            VectorNode::is_vector_shift_count(m) &amp;&amp; m-&gt;in(1)-&gt;is_Con();
1987   }
1988   return false;
1989 }
1990 
1991 
<span class="line-added">1992 bool Matcher::clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {</span>
<span class="line-added">1993   // Must clone all producers of flags, or we will not match correctly.</span>
<span class="line-added">1994   // Suppose a compare setting int-flags is shared (e.g., a switch-tree)</span>
<span class="line-added">1995   // then it will match into an ideal Op_RegFlags.  Alas, the fp-flags</span>
<span class="line-added">1996   // are also there, so we may match a float-branch to int-flags and</span>
<span class="line-added">1997   // expect the allocator to haul the flags from the int-side to the</span>
<span class="line-added">1998   // fp-side.  No can do.</span>
<span class="line-added">1999   if (_must_clone[m-&gt;Opcode()]) {</span>
<span class="line-added">2000     mstack.push(m, Visit);</span>
<span class="line-added">2001     return true;</span>
<span class="line-added">2002   }</span>
<span class="line-added">2003   return pd_clone_node(n, m, mstack);</span>
<span class="line-added">2004 }</span>
<span class="line-added">2005 </span>
2006 bool Matcher::clone_base_plus_offset_address(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
2007   Node *off = m-&gt;in(AddPNode::Offset);
2008   if (off-&gt;is_Con()) {
2009     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
2010     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
2011     // Clone X+offset as it also folds into most addressing expressions
2012     mstack.push(off, Visit);
2013     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
2014     return true;
2015   }
2016   return false;
2017 }
2018 
2019 // A method-klass-holder may be passed in the inline_cache_reg
2020 // and then expanded into the inline_cache_reg and a method_oop register
2021 //   defined in ad_&lt;arch&gt;.cpp
2022 
2023 //------------------------------find_shared------------------------------------
2024 // Set bits if Node is shared or otherwise a root
<span class="line-modified">2025 void Matcher::find_shared(Node* n) {</span>
2026   // Allocate stack of size C-&gt;live_nodes() * 2 to avoid frequent realloc
2027   MStack mstack(C-&gt;live_nodes() * 2);
2028   // Mark nodes as address_visited if they are inputs to an address expression
2029   VectorSet address_visited(Thread::current()-&gt;resource_area());
2030   mstack.push(n, Visit);     // Don&#39;t need to pre-visit root node
2031   while (mstack.is_nonempty()) {
2032     n = mstack.node();       // Leave node on stack
2033     Node_State nstate = mstack.state();
2034     uint nop = n-&gt;Opcode();
2035     if (nstate == Pre_Visit) {
2036       if (address_visited.test(n-&gt;_idx)) { // Visited in address already?
2037         // Flag as visited and shared now.
2038         set_visited(n);
2039       }
2040       if (is_visited(n)) {   // Visited already?
2041         // Node is shared and has no reason to clone.  Flag it as shared.
2042         // This causes it to match into a register for the sharing.
2043         set_shared(n);       // Flag as shared and
2044         if (n-&gt;is_DecodeNarrowPtr()) {
2045           // Oop field/array element loads must be shared but since
2046           // they are shared through a DecodeN they may appear to have
2047           // a single use so force sharing here.
2048           set_shared(n-&gt;in(1));
2049         }
2050         mstack.pop();        // remove node from stack
2051         continue;
2052       }
2053       nstate = Visit; // Not already visited; so visit now
2054     }
2055     if (nstate == Visit) {
2056       mstack.set_state(Post_Visit);
2057       set_visited(n);   // Flag as visited now
2058       bool mem_op = false;
2059       int mem_addr_idx = MemNode::Address;
2060       if (find_shared_visit(mstack, n, nop, mem_op, mem_addr_idx)) {
2061         continue;
2062       }
<span class="line-modified">2063       for (int i = n-&gt;req() - 1; i &gt;= 0; --i) { // For my children</span>
<span class="line-modified">2064         Node* m = n-&gt;in(i); // Get ith input</span>
<span class="line-modified">2065         if (m == NULL) {</span>
<span class="line-modified">2066           continue;  // Ignore NULLs</span>










2067         }
<span class="line-modified">2068         if (clone_node(n, m, mstack)) {</span>









2069           continue;
2070         }
2071 
2072         // Clone addressing expressions as they are &quot;free&quot; in memory access instructions
<span class="line-modified">2073         if (mem_op &amp;&amp; i == mem_addr_idx &amp;&amp; m-&gt;is_AddP() &amp;&amp;</span>
2074             // When there are other uses besides address expressions
2075             // put it on stack and mark as shared.
2076             !is_visited(m)) {
2077           // Some inputs for address expression are not put on stack
2078           // to avoid marking them as shared and forcing them into register
2079           // if they are used only in address expressions.
2080           // But they should be marked as shared if there are other uses
2081           // besides address expressions.
2082 
<span class="line-modified">2083           if (pd_clone_address_expressions(m-&gt;as_AddP(), mstack, address_visited)) {</span>
2084             continue;
2085           }
2086         }   // if( mem_op &amp;&amp;
2087         mstack.push(m, Pre_Visit);
2088       }     // for(int i = ...)
2089     }
2090     else if (nstate == Alt_Post_Visit) {
2091       mstack.pop(); // Remove node from stack
2092       // We cannot remove the Cmp input from the Bool here, as the Bool may be
2093       // shared and all users of the Bool need to move the Cmp in parallel.
2094       // This leaves both the Bool and the If pointing at the Cmp.  To
2095       // prevent the Matcher from trying to Match the Cmp along both paths
2096       // BoolNode::match_edge always returns a zero.
2097 
2098       // We reorder the Op_If in a pre-order manner, so we can visit without
2099       // accidentally sharing the Cmp (the Bool and the If make 2 users).
2100       n-&gt;add_req( n-&gt;in(1)-&gt;in(1) ); // Add the Cmp next to the Bool
2101     }
2102     else if (nstate == Post_Visit) {
2103       mstack.pop(); // Remove node from stack
</pre>
</td>
</tr>
</table>
<center><a href="../oops/instanceKlass.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="matcher.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>