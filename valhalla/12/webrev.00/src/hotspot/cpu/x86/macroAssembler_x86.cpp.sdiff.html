<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/macroAssembler_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="frame_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 6403     }
 6404     reg_state[from_r1-&gt;value()] = reg_writable;
 6405   }
 6406   sig_index = stream.sig_cc_index();
 6407   from_index = stream.regs_cc_index();
 6408 
 6409   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);
 6410   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);
 6411   assert(success, &quot;to register must be writeable&quot;);
 6412 
 6413   return true;
 6414 }
 6415 
 6416 // Unpack all value type arguments passed as oops
 6417 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {
 6418   int sp_inc = unpack_value_args_common(C, receiver_only);
 6419   // Emit code for verified entry and save increment for stack repair on return
 6420   verified_entry(C, sp_inc);
 6421 }
 6422 
<span class="line-modified"> 6423 int MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-modified"> 6424                                        BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-modified"> 6425                                        int args_passed, int args_on_stack, VMRegPair* regs,            // from</span>
<span class="line-modified"> 6426                                        int args_passed_to, int args_on_stack_to, VMRegPair* regs_to) { // to</span>
 6427   // Check if we need to extend the stack for packing/unpacking
<span class="line-modified"> 6428   int sp_inc = (args_on_stack_to - args_on_stack) * VMRegImpl::stack_slot_size;</span>
<span class="line-modified"> 6429   if (sp_inc &gt; 0) {</span>
<span class="line-modified"> 6430     sp_inc = align_up(sp_inc, StackAlignmentInBytes);</span>
<span class="line-modified"> 6431     if (!is_packing) {</span>
<span class="line-modified"> 6432       // Save the return address, adjust the stack (make sure it is properly</span>
<span class="line-modified"> 6433       // 16-byte aligned) and copy the return address to the new top of the stack.</span>
<span class="line-modified"> 6434       // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).</span>
<span class="line-removed"> 6435       pop(r13);</span>
<span class="line-removed"> 6436       subptr(rsp, sp_inc);</span>
<span class="line-removed"> 6437       push(r13);</span>
<span class="line-removed"> 6438     }</span>
<span class="line-removed"> 6439   } else {</span>
<span class="line-removed"> 6440     // The scalarized calling convention needs less stack space than the unscalarized one.</span>
<span class="line-removed"> 6441     // No need to extend the stack, the caller will take care of these adjustments.</span>
<span class="line-removed"> 6442     sp_inc = 0;</span>
 6443   }
 6444 
 6445   int ret_off; // make sure we don&#39;t overwrite the return address
 6446   if (is_packing) {
 6447     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at
 6448     // rsp[0] during shuffling.
 6449     ret_off = 0;
 6450   } else {
 6451     // C2 code ensures that sp_inc is a reserved slot.
 6452     ret_off = sp_inc;
 6453   }
 6454 
<span class="line-modified"> 6455   return shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-modified"> 6456                                    sig_bt, sig_cc,</span>
<span class="line-modified"> 6457                                    args_passed, args_on_stack, regs,</span>
<span class="line-modified"> 6458                                    args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-modified"> 6459                                    sp_inc, ret_off);</span>
 6460 }
 6461 
 6462 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
 6463   return reg-&gt;is_XMMRegister() ? xmm8-&gt;as_VMReg() : r14-&gt;as_VMReg();
 6464 }
 6465 
<span class="line-modified"> 6466 // Restores the stack on return</span>
<span class="line-modified"> 6467 void MacroAssembler::restore_stack(Compile* C) {</span>
<span class="line-modified"> 6468   int framesize = C-&gt;frame_size_in_bytes();</span>
<span class="line-removed"> 6469   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);</span>
<span class="line-removed"> 6470   // Remove word for return addr already pushed and RBP</span>
<span class="line-removed"> 6471   framesize -= 2*wordSize;</span>
<span class="line-removed"> 6472 </span>
<span class="line-removed"> 6473   if (C-&gt;needs_stack_repair()) {</span>
 6474     // Restore rbp and repair rsp by adding the stack increment
<span class="line-modified"> 6475     movq(rbp, Address(rsp, framesize));</span>
<span class="line-modified"> 6476     addq(rsp, Address(rsp, C-&gt;sp_inc_offset()));</span>
 6477   } else {
<span class="line-modified"> 6478     if (framesize &gt; 0) {</span>
<span class="line-modified"> 6479       addq(rsp, framesize);</span>
 6480     }
 6481     pop(rbp);
 6482   }
 6483 }
 6484 
 6485 void MacroAssembler::clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only) {
 6486   // cnt - number of qwords (8-byte words).
 6487   // base - start address, qword aligned.
 6488   // is_large - if optimizers know cnt is larger than InitArrayShortSize
 6489   assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
 6490   assert(val==rax,   &quot;tmp register must be eax for rep stos&quot;);
 6491   assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
 6492   assert(InitArrayShortSize % BytesPerLong == 0,
 6493     &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
 6494 
 6495   Label DONE;
 6496 
 6497   if (!is_large) {
 6498     Label LOOP, LONG;
 6499     cmpptr(cnt, InitArrayShortSize/BytesPerLong);
</pre>
</td>
<td>
<hr />
<pre>
 6403     }
 6404     reg_state[from_r1-&gt;value()] = reg_writable;
 6405   }
 6406   sig_index = stream.sig_cc_index();
 6407   from_index = stream.regs_cc_index();
 6408 
 6409   assert(reg_state[to-&gt;value()] == reg_writable, &quot;must have already been read&quot;);
 6410   bool success = move_helper(val_obj-&gt;as_VMReg(), to, T_OBJECT, reg_state, ret_off, extra_stack_offset);
 6411   assert(success, &quot;to register must be writeable&quot;);
 6412 
 6413   return true;
 6414 }
 6415 
 6416 // Unpack all value type arguments passed as oops
 6417 void MacroAssembler::unpack_value_args(Compile* C, bool receiver_only) {
 6418   int sp_inc = unpack_value_args_common(C, receiver_only);
 6419   // Emit code for verified entry and save increment for stack repair on return
 6420   verified_entry(C, sp_inc);
 6421 }
 6422 
<span class="line-modified"> 6423 void MacroAssembler::shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,</span>
<span class="line-modified"> 6424                                         BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,</span>
<span class="line-modified"> 6425                                         int args_passed, int args_on_stack, VMRegPair* regs,</span>
<span class="line-modified"> 6426                                         int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc) {</span>
 6427   // Check if we need to extend the stack for packing/unpacking
<span class="line-modified"> 6428   if (sp_inc &gt; 0 &amp;&amp; !is_packing) {</span>
<span class="line-modified"> 6429     // Save the return address, adjust the stack (make sure it is properly</span>
<span class="line-modified"> 6430     // 16-byte aligned) and copy the return address to the new top of the stack.</span>
<span class="line-modified"> 6431     // (Note: C1 does this in C1_MacroAssembler::scalarized_entry).</span>
<span class="line-modified"> 6432     pop(r13);</span>
<span class="line-modified"> 6433     subptr(rsp, sp_inc);</span>
<span class="line-modified"> 6434     push(r13);</span>








 6435   }
 6436 
 6437   int ret_off; // make sure we don&#39;t overwrite the return address
 6438   if (is_packing) {
 6439     // For C1 code, the VVEP doesn&#39;t have reserved slots, so we store the returned address at
 6440     // rsp[0] during shuffling.
 6441     ret_off = 0;
 6442   } else {
 6443     // C2 code ensures that sp_inc is a reserved slot.
 6444     ret_off = sp_inc;
 6445   }
 6446 
<span class="line-modified"> 6447   shuffle_value_args_common(is_packing, receiver_only, extra_stack_offset,</span>
<span class="line-modified"> 6448                             sig_bt, sig_cc,</span>
<span class="line-modified"> 6449                             args_passed, args_on_stack, regs,</span>
<span class="line-modified"> 6450                             args_passed_to, args_on_stack_to, regs_to,</span>
<span class="line-modified"> 6451                             sp_inc, ret_off);</span>
 6452 }
 6453 
 6454 VMReg MacroAssembler::spill_reg_for(VMReg reg) {
 6455   return reg-&gt;is_XMMRegister() ? xmm8-&gt;as_VMReg() : r14-&gt;as_VMReg();
 6456 }
 6457 
<span class="line-modified"> 6458 void MacroAssembler::remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset) {</span>
<span class="line-modified"> 6459   assert((initial_framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);</span>
<span class="line-modified"> 6460   if (needs_stack_repair) {</span>





 6461     // Restore rbp and repair rsp by adding the stack increment
<span class="line-modified"> 6462     movq(rbp, Address(rsp, initial_framesize));</span>
<span class="line-modified"> 6463     addq(rsp, Address(rsp, sp_inc_offset));</span>
 6464   } else {
<span class="line-modified"> 6465     if (initial_framesize &gt; 0) {</span>
<span class="line-modified"> 6466       addq(rsp, initial_framesize);</span>
 6467     }
 6468     pop(rbp);
 6469   }
 6470 }
 6471 
 6472 void MacroAssembler::clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only) {
 6473   // cnt - number of qwords (8-byte words).
 6474   // base - start address, qword aligned.
 6475   // is_large - if optimizers know cnt is larger than InitArrayShortSize
 6476   assert(base==rdi, &quot;base register must be edi for rep stos&quot;);
 6477   assert(val==rax,   &quot;tmp register must be eax for rep stos&quot;);
 6478   assert(cnt==rcx,   &quot;cnt register must be ecx for rep stos&quot;);
 6479   assert(InitArrayShortSize % BytesPerLong == 0,
 6480     &quot;InitArrayShortSize should be the multiple of BytesPerLong&quot;);
 6481 
 6482   Label DONE;
 6483 
 6484   if (!is_large) {
 6485     Label LOOP, LONG;
 6486     cmpptr(cnt, InitArrayShortSize/BytesPerLong);
</pre>
</td>
</tr>
</table>
<center><a href="frame_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macroAssembler_x86.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>