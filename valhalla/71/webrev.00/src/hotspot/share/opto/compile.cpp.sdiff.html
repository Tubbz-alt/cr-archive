<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/compile.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="cfgnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/compile.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 389     Node* cast = range_check_cast_node(i);
 390     if (!useful.member(cast)) {
 391       remove_range_check_cast(cast);
 392     }
 393   }
 394   // Remove useless expensive nodes
 395   for (int i = C-&gt;expensive_count()-1; i &gt;= 0; i--) {
 396     Node* n = C-&gt;expensive_node(i);
 397     if (!useful.member(n)) {
 398       remove_expensive_node(n);
 399     }
 400   }
 401   // Remove useless Opaque4 nodes
 402   for (int i = opaque4_count() - 1; i &gt;= 0; i--) {
 403     Node* opaq = opaque4_node(i);
 404     if (!useful.member(opaq)) {
 405       remove_opaque4_node(opaq);
 406     }
 407   }
 408   // Remove useless value type nodes
<span class="line-modified"> 409   if (_value_type_nodes != NULL) {</span>
<span class="line-modified"> 410     _value_type_nodes-&gt;remove_useless_nodes(useful.member_set());</span>



 411   }
 412   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 413   bs-&gt;eliminate_useless_gc_barriers(useful, this);
 414   // clean up the late inline lists
 415   remove_useless_late_inlines(&amp;_string_late_inlines, useful);
 416   remove_useless_late_inlines(&amp;_boxing_late_inlines, useful);
 417   remove_useless_late_inlines(&amp;_late_inlines, useful);
 418   debug_only(verify_graph_edges(true/*check for no_dead_code*/);)
 419 }
 420 
 421 // ============================================================================
 422 //------------------------------CompileWrapper---------------------------------
 423 class CompileWrapper : public StackObj {
 424   Compile *const _compile;
 425  public:
 426   CompileWrapper(Compile* compile);
 427 
 428   ~CompileWrapper();
 429 };
 430 
</pre>
<hr />
<pre>
1002   Copy::zero_to_bytes(ats, sizeof(AliasType)*grow_ats);
1003   {
1004     for (int i = 0; i &lt; grow_ats; i++)  _alias_types[i] = &amp;ats[i];
1005   }
1006   // Initialize the first few types.
1007   _alias_types[AliasIdxTop]-&gt;Init(AliasIdxTop, NULL);
1008   _alias_types[AliasIdxBot]-&gt;Init(AliasIdxBot, TypePtr::BOTTOM);
1009   _alias_types[AliasIdxRaw]-&gt;Init(AliasIdxRaw, TypeRawPtr::BOTTOM);
1010   _num_alias_types = AliasIdxRaw+1;
1011   // Zero out the alias type cache.
1012   Copy::zero_to_bytes(_alias_cache, sizeof(_alias_cache));
1013   // A NULL adr_type hits in the cache right away.  Preload the right answer.
1014   probe_alias_cache(NULL)-&gt;_index = AliasIdxTop;
1015 
1016   _intrinsics = NULL;
1017   _macro_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1018   _predicate_opaqs = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1019   _expensive_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1020   _range_check_casts = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1021   _opaque4_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
<span class="line-modified">1022   _value_type_nodes = new (comp_arena()) Unique_Node_List(comp_arena());</span>
1023   register_library_intrinsics();
1024 #ifdef ASSERT
1025   _type_verify_symmetry = true;
1026 #endif
1027 }
1028 
1029 //---------------------------init_start----------------------------------------
1030 // Install the StartNode on this compile object.
1031 void Compile::init_start(StartNode* s) {
1032   if (failing())
1033     return; // already failing
1034   assert(s == start(), &quot;&quot;);
1035 }
1036 
1037 /**
1038  * Return the &#39;StartNode&#39;. We must not have a pending failure, since the ideal graph
1039  * can be in an inconsistent state, i.e., we can get segmentation faults when traversing
1040  * the ideal graph.
1041  */
1042 StartNode* Compile::start() const {
</pre>
<hr />
<pre>
1858 
1859 // Remove all Opaque4 nodes.
1860 void Compile::remove_opaque4_nodes(PhaseIterGVN &amp;igvn) {
1861   for (int i = opaque4_count(); i &gt; 0; i--) {
1862     Node* opaq = opaque4_node(i-1);
1863     assert(opaq-&gt;Opcode() == Op_Opaque4, &quot;Opaque4 only&quot;);
1864     igvn.replace_node(opaq, opaq-&gt;in(2));
1865   }
1866   assert(opaque4_count() == 0, &quot;should be empty&quot;);
1867 }
1868 
1869 void Compile::add_value_type(Node* n) {
1870   assert(n-&gt;is_ValueTypeBase(), &quot;unexpected node&quot;);
1871   if (_value_type_nodes != NULL) {
1872     _value_type_nodes-&gt;push(n);
1873   }
1874 }
1875 
1876 void Compile::remove_value_type(Node* n) {
1877   assert(n-&gt;is_ValueTypeBase(), &quot;unexpected node&quot;);
<span class="line-modified">1878   if (_value_type_nodes != NULL) {</span>
1879     _value_type_nodes-&gt;remove(n);
1880   }
1881 }
1882 
<span class="line-modified">1883 // Does the return value keep otherwise useless value type allocations</span>
<span class="line-removed">1884 // alive?</span>
1885 static bool return_val_keeps_allocations_alive(Node* ret_val) {
1886   ResourceMark rm;
1887   Unique_Node_List wq;
1888   wq.push(ret_val);
1889   bool some_allocations = false;
1890   for (uint i = 0; i &lt; wq.size(); i++) {
1891     Node* n = wq.at(i);
<span class="line-modified">1892     assert(!n-&gt;is_ValueTypeBase(), &quot;chain of value type nodes&quot;);</span>
1893     if (n-&gt;outcnt() &gt; 1) {
1894       // Some other use for the allocation
1895       return false;


1896     } else if (n-&gt;is_Phi()) {
1897       for (uint j = 1; j &lt; n-&gt;req(); j++) {
1898         wq.push(n-&gt;in(j));
1899       }
1900     } else if (n-&gt;is_CheckCastPP() &amp;&amp;
1901                n-&gt;in(1)-&gt;is_Proj() &amp;&amp;
1902                n-&gt;in(1)-&gt;in(0)-&gt;is_Allocate()) {
1903       some_allocations = true;
1904     }
1905   }
1906   return some_allocations;
1907 }
1908 
<span class="line-modified">1909 void Compile::process_value_types(PhaseIterGVN &amp;igvn) {</span>
1910   // Make value types scalar in safepoints
<span class="line-modified">1911   while (_value_type_nodes-&gt;size() != 0) {</span>
<span class="line-modified">1912     ValueTypeBaseNode* vt = _value_type_nodes-&gt;pop()-&gt;as_ValueTypeBase();</span>
1913     vt-&gt;make_scalar_in_safepoints(&amp;igvn);
<span class="line-modified">1914     if (vt-&gt;is_ValueTypePtr()) {</span>
<span class="line-modified">1915       igvn.replace_node(vt, vt-&gt;get_oop());</span>
<span class="line-modified">1916     } else if (vt-&gt;outcnt() == 0) {</span>
<span class="line-modified">1917       igvn.remove_dead_node(vt);</span>






1918     }
1919   }
<span class="line-modified">1920   _value_type_nodes = NULL;</span>
1921   if (tf()-&gt;returns_value_type_as_fields()) {
1922     Node* ret = NULL;
1923     for (uint i = 1; i &lt; root()-&gt;req(); i++){
1924       Node* in = root()-&gt;in(i);
1925       if (in-&gt;Opcode() == Op_Return) {
1926         assert(ret == NULL, &quot;only one return&quot;);
1927         ret = in;
1928       }
1929     }
1930     if (ret != NULL) {
1931       Node* ret_val = ret-&gt;in(TypeFunc::Parms);
1932       if (igvn.type(ret_val)-&gt;isa_oopptr() &amp;&amp;
1933           return_val_keeps_allocations_alive(ret_val)) {
1934         igvn.replace_input_of(ret, TypeFunc::Parms, ValueTypeNode::tagged_klass(igvn.type(ret_val)-&gt;value_klass(), igvn));
1935         assert(ret_val-&gt;outcnt() == 0, &quot;should be dead now&quot;);
1936         igvn.remove_dead_node(ret_val);
1937       }
1938     }
1939   }
1940   igvn.optimize();
</pre>
<hr />
<pre>
2469   remove_speculative_types(igvn);
2470 
2471   // No more new expensive nodes will be added to the list from here
2472   // so keep only the actual candidates for optimizations.
2473   cleanup_expensive_nodes(igvn);
2474 
2475   if (!failing() &amp;&amp; RenumberLiveNodes &amp;&amp; live_nodes() + NodeLimitFudgeFactor &lt; unique()) {
2476     Compile::TracePhase tp(&quot;&quot;, &amp;timers[_t_renumberLive]);
2477     initial_gvn()-&gt;replace_with(&amp;igvn);
2478     for_igvn()-&gt;clear();
2479     Unique_Node_List new_worklist(C-&gt;comp_arena());
2480     {
2481       ResourceMark rm;
2482       PhaseRenumberLive prl = PhaseRenumberLive(initial_gvn(), for_igvn(), &amp;new_worklist);
2483     }
2484     set_for_igvn(&amp;new_worklist);
2485     igvn = PhaseIterGVN(initial_gvn());
2486     igvn.optimize();
2487   }
2488 
<span class="line-modified">2489   if (_value_type_nodes-&gt;size() &gt; 0) {</span>
2490     // Do this once all inlining is over to avoid getting inconsistent debug info
2491     process_value_types(igvn);
2492   }
2493 
2494   adjust_flattened_array_access_aliases(igvn);
2495 
2496   // Perform escape analysis
2497   if (_do_escape_analysis &amp;&amp; ConnectionGraph::has_candidates(this)) {
2498     if (has_loops()) {
2499       // Cleanup graph (remove dead nodes).
2500       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2501       PhaseIdealLoop::optimize(igvn, LoopOptsMaxUnroll);
2502       if (major_progress()) print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);
2503       if (failing())  return;
2504     }
2505     ConnectionGraph::do_analysis(this, &amp;igvn);
2506 
2507     if (failing())  return;
2508 
2509     // Optimize out fields loads from scalar replaceable allocations.
2510     igvn.optimize();
2511     print_method(PHASE_ITER_GVN_AFTER_EA, 2);
2512 
2513     if (failing())  return;
2514 
2515     if (congraph() != NULL &amp;&amp; macro_count() &gt; 0) {
2516       TracePhase tp(&quot;macroEliminate&quot;, &amp;timers[_t_macroEliminate]);
2517       PhaseMacroExpand mexp(igvn);
2518       mexp.eliminate_macro_nodes();
2519       igvn.set_delay_transform(false);
2520 
2521       igvn.optimize();
2522       print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);
2523 
2524       if (failing())  return;
2525     }
2526   }
2527 





2528   // Loop transforms on the ideal graph.  Range Check Elimination,
2529   // peeling, unrolling, etc.
2530 
2531   // Set loop opts counter
2532   if((_loop_opts_cnt &gt; 0) &amp;&amp; (has_loops() || has_split_ifs())) {
2533     {
2534       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2535       PhaseIdealLoop::optimize(igvn, LoopOptsDefault);
2536       _loop_opts_cnt--;
2537       if (major_progress()) print_method(PHASE_PHASEIDEALLOOP1, 2);
2538       if (failing())  return;
2539     }
2540     // Loop opts pass if partial peeling occurred in previous pass
2541     if(PartialPeelLoop &amp;&amp; major_progress() &amp;&amp; (_loop_opts_cnt &gt; 0)) {
2542       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2543       PhaseIdealLoop::optimize(igvn, LoopOptsSkipSplitIf);
2544       _loop_opts_cnt--;
2545       if (major_progress()) print_method(PHASE_PHASEIDEALLOOP2, 2);
2546       if (failing())  return;
2547     }
</pre>
</td>
<td>
<hr />
<pre>
 389     Node* cast = range_check_cast_node(i);
 390     if (!useful.member(cast)) {
 391       remove_range_check_cast(cast);
 392     }
 393   }
 394   // Remove useless expensive nodes
 395   for (int i = C-&gt;expensive_count()-1; i &gt;= 0; i--) {
 396     Node* n = C-&gt;expensive_node(i);
 397     if (!useful.member(n)) {
 398       remove_expensive_node(n);
 399     }
 400   }
 401   // Remove useless Opaque4 nodes
 402   for (int i = opaque4_count() - 1; i &gt;= 0; i--) {
 403     Node* opaq = opaque4_node(i);
 404     if (!useful.member(opaq)) {
 405       remove_opaque4_node(opaq);
 406     }
 407   }
 408   // Remove useless value type nodes
<span class="line-modified"> 409   for (int i = _value_type_nodes-&gt;length() - 1; i &gt;= 0; i--) {</span>
<span class="line-modified"> 410     Node* vt = _value_type_nodes-&gt;at(i);</span>
<span class="line-added"> 411     if (!useful.member(vt)) {</span>
<span class="line-added"> 412       _value_type_nodes-&gt;remove(vt);</span>
<span class="line-added"> 413     }</span>
 414   }
 415   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 416   bs-&gt;eliminate_useless_gc_barriers(useful, this);
 417   // clean up the late inline lists
 418   remove_useless_late_inlines(&amp;_string_late_inlines, useful);
 419   remove_useless_late_inlines(&amp;_boxing_late_inlines, useful);
 420   remove_useless_late_inlines(&amp;_late_inlines, useful);
 421   debug_only(verify_graph_edges(true/*check for no_dead_code*/);)
 422 }
 423 
 424 // ============================================================================
 425 //------------------------------CompileWrapper---------------------------------
 426 class CompileWrapper : public StackObj {
 427   Compile *const _compile;
 428  public:
 429   CompileWrapper(Compile* compile);
 430 
 431   ~CompileWrapper();
 432 };
 433 
</pre>
<hr />
<pre>
1005   Copy::zero_to_bytes(ats, sizeof(AliasType)*grow_ats);
1006   {
1007     for (int i = 0; i &lt; grow_ats; i++)  _alias_types[i] = &amp;ats[i];
1008   }
1009   // Initialize the first few types.
1010   _alias_types[AliasIdxTop]-&gt;Init(AliasIdxTop, NULL);
1011   _alias_types[AliasIdxBot]-&gt;Init(AliasIdxBot, TypePtr::BOTTOM);
1012   _alias_types[AliasIdxRaw]-&gt;Init(AliasIdxRaw, TypeRawPtr::BOTTOM);
1013   _num_alias_types = AliasIdxRaw+1;
1014   // Zero out the alias type cache.
1015   Copy::zero_to_bytes(_alias_cache, sizeof(_alias_cache));
1016   // A NULL adr_type hits in the cache right away.  Preload the right answer.
1017   probe_alias_cache(NULL)-&gt;_index = AliasIdxTop;
1018 
1019   _intrinsics = NULL;
1020   _macro_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1021   _predicate_opaqs = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1022   _expensive_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1023   _range_check_casts = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1024   _opaque4_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
<span class="line-modified">1025   _value_type_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);</span>
1026   register_library_intrinsics();
1027 #ifdef ASSERT
1028   _type_verify_symmetry = true;
1029 #endif
1030 }
1031 
1032 //---------------------------init_start----------------------------------------
1033 // Install the StartNode on this compile object.
1034 void Compile::init_start(StartNode* s) {
1035   if (failing())
1036     return; // already failing
1037   assert(s == start(), &quot;&quot;);
1038 }
1039 
1040 /**
1041  * Return the &#39;StartNode&#39;. We must not have a pending failure, since the ideal graph
1042  * can be in an inconsistent state, i.e., we can get segmentation faults when traversing
1043  * the ideal graph.
1044  */
1045 StartNode* Compile::start() const {
</pre>
<hr />
<pre>
1861 
1862 // Remove all Opaque4 nodes.
1863 void Compile::remove_opaque4_nodes(PhaseIterGVN &amp;igvn) {
1864   for (int i = opaque4_count(); i &gt; 0; i--) {
1865     Node* opaq = opaque4_node(i-1);
1866     assert(opaq-&gt;Opcode() == Op_Opaque4, &quot;Opaque4 only&quot;);
1867     igvn.replace_node(opaq, opaq-&gt;in(2));
1868   }
1869   assert(opaque4_count() == 0, &quot;should be empty&quot;);
1870 }
1871 
1872 void Compile::add_value_type(Node* n) {
1873   assert(n-&gt;is_ValueTypeBase(), &quot;unexpected node&quot;);
1874   if (_value_type_nodes != NULL) {
1875     _value_type_nodes-&gt;push(n);
1876   }
1877 }
1878 
1879 void Compile::remove_value_type(Node* n) {
1880   assert(n-&gt;is_ValueTypeBase(), &quot;unexpected node&quot;);
<span class="line-modified">1881   if (_value_type_nodes != NULL &amp;&amp; _value_type_nodes-&gt;contains(n)) {</span>
1882     _value_type_nodes-&gt;remove(n);
1883   }
1884 }
1885 
<span class="line-modified">1886 // Does the return value keep otherwise useless value type allocations alive?</span>

1887 static bool return_val_keeps_allocations_alive(Node* ret_val) {
1888   ResourceMark rm;
1889   Unique_Node_List wq;
1890   wq.push(ret_val);
1891   bool some_allocations = false;
1892   for (uint i = 0; i &lt; wq.size(); i++) {
1893     Node* n = wq.at(i);
<span class="line-modified">1894     assert(!n-&gt;is_ValueType(), &quot;chain of value type nodes&quot;);</span>
1895     if (n-&gt;outcnt() &gt; 1) {
1896       // Some other use for the allocation
1897       return false;
<span class="line-added">1898     } else if (n-&gt;is_ValueTypePtr()) {</span>
<span class="line-added">1899       wq.push(n-&gt;in(1));</span>
1900     } else if (n-&gt;is_Phi()) {
1901       for (uint j = 1; j &lt; n-&gt;req(); j++) {
1902         wq.push(n-&gt;in(j));
1903       }
1904     } else if (n-&gt;is_CheckCastPP() &amp;&amp;
1905                n-&gt;in(1)-&gt;is_Proj() &amp;&amp;
1906                n-&gt;in(1)-&gt;in(0)-&gt;is_Allocate()) {
1907       some_allocations = true;
1908     }
1909   }
1910   return some_allocations;
1911 }
1912 
<span class="line-modified">1913 void Compile::process_value_types(PhaseIterGVN &amp;igvn, bool post_ea) {</span>
1914   // Make value types scalar in safepoints
<span class="line-modified">1915   for (int i = _value_type_nodes-&gt;length()-1; i &gt;= 0; i--) {</span>
<span class="line-modified">1916     ValueTypeBaseNode* vt = _value_type_nodes-&gt;at(i)-&gt;as_ValueTypeBase();</span>
1917     vt-&gt;make_scalar_in_safepoints(&amp;igvn);
<span class="line-modified">1918   }</span>
<span class="line-modified">1919   // Remove ValueTypePtr nodes only after EA to give scalar replacement a chance</span>
<span class="line-modified">1920   // to remove buffer allocations. ValueType nodes are kept until loop opts and</span>
<span class="line-modified">1921   // removed via ValueTypeNode::remove_redundant_allocations.</span>
<span class="line-added">1922   if (post_ea) {</span>
<span class="line-added">1923     while (_value_type_nodes-&gt;length() &gt; 0) {</span>
<span class="line-added">1924       ValueTypeBaseNode* vt = _value_type_nodes-&gt;pop()-&gt;as_ValueTypeBase();</span>
<span class="line-added">1925       if (vt-&gt;is_ValueTypePtr()) {</span>
<span class="line-added">1926         igvn.replace_node(vt, vt-&gt;get_oop());</span>
<span class="line-added">1927       }</span>
1928     }
1929   }
<span class="line-modified">1930   // Make sure that the return value does not keep an unused allocation alive</span>
1931   if (tf()-&gt;returns_value_type_as_fields()) {
1932     Node* ret = NULL;
1933     for (uint i = 1; i &lt; root()-&gt;req(); i++){
1934       Node* in = root()-&gt;in(i);
1935       if (in-&gt;Opcode() == Op_Return) {
1936         assert(ret == NULL, &quot;only one return&quot;);
1937         ret = in;
1938       }
1939     }
1940     if (ret != NULL) {
1941       Node* ret_val = ret-&gt;in(TypeFunc::Parms);
1942       if (igvn.type(ret_val)-&gt;isa_oopptr() &amp;&amp;
1943           return_val_keeps_allocations_alive(ret_val)) {
1944         igvn.replace_input_of(ret, TypeFunc::Parms, ValueTypeNode::tagged_klass(igvn.type(ret_val)-&gt;value_klass(), igvn));
1945         assert(ret_val-&gt;outcnt() == 0, &quot;should be dead now&quot;);
1946         igvn.remove_dead_node(ret_val);
1947       }
1948     }
1949   }
1950   igvn.optimize();
</pre>
<hr />
<pre>
2479   remove_speculative_types(igvn);
2480 
2481   // No more new expensive nodes will be added to the list from here
2482   // so keep only the actual candidates for optimizations.
2483   cleanup_expensive_nodes(igvn);
2484 
2485   if (!failing() &amp;&amp; RenumberLiveNodes &amp;&amp; live_nodes() + NodeLimitFudgeFactor &lt; unique()) {
2486     Compile::TracePhase tp(&quot;&quot;, &amp;timers[_t_renumberLive]);
2487     initial_gvn()-&gt;replace_with(&amp;igvn);
2488     for_igvn()-&gt;clear();
2489     Unique_Node_List new_worklist(C-&gt;comp_arena());
2490     {
2491       ResourceMark rm;
2492       PhaseRenumberLive prl = PhaseRenumberLive(initial_gvn(), for_igvn(), &amp;new_worklist);
2493     }
2494     set_for_igvn(&amp;new_worklist);
2495     igvn = PhaseIterGVN(initial_gvn());
2496     igvn.optimize();
2497   }
2498 
<span class="line-modified">2499   if (_value_type_nodes-&gt;length() &gt; 0) {</span>
2500     // Do this once all inlining is over to avoid getting inconsistent debug info
2501     process_value_types(igvn);
2502   }
2503 
2504   adjust_flattened_array_access_aliases(igvn);
2505 
2506   // Perform escape analysis
2507   if (_do_escape_analysis &amp;&amp; ConnectionGraph::has_candidates(this)) {
2508     if (has_loops()) {
2509       // Cleanup graph (remove dead nodes).
2510       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2511       PhaseIdealLoop::optimize(igvn, LoopOptsMaxUnroll);
2512       if (major_progress()) print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);
2513       if (failing())  return;
2514     }
2515     ConnectionGraph::do_analysis(this, &amp;igvn);
2516 
2517     if (failing())  return;
2518 
2519     // Optimize out fields loads from scalar replaceable allocations.
2520     igvn.optimize();
2521     print_method(PHASE_ITER_GVN_AFTER_EA, 2);
2522 
2523     if (failing())  return;
2524 
2525     if (congraph() != NULL &amp;&amp; macro_count() &gt; 0) {
2526       TracePhase tp(&quot;macroEliminate&quot;, &amp;timers[_t_macroEliminate]);
2527       PhaseMacroExpand mexp(igvn);
2528       mexp.eliminate_macro_nodes();
2529       igvn.set_delay_transform(false);
2530 
2531       igvn.optimize();
2532       print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);
2533 
2534       if (failing())  return;
2535     }
2536   }
2537 
<span class="line-added">2538   if (_value_type_nodes-&gt;length() &gt; 0) {</span>
<span class="line-added">2539     // Process value types again now that EA might have simplified the graph</span>
<span class="line-added">2540     process_value_types(igvn, /* post_ea= */ true);</span>
<span class="line-added">2541   }</span>
<span class="line-added">2542 </span>
2543   // Loop transforms on the ideal graph.  Range Check Elimination,
2544   // peeling, unrolling, etc.
2545 
2546   // Set loop opts counter
2547   if((_loop_opts_cnt &gt; 0) &amp;&amp; (has_loops() || has_split_ifs())) {
2548     {
2549       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2550       PhaseIdealLoop::optimize(igvn, LoopOptsDefault);
2551       _loop_opts_cnt--;
2552       if (major_progress()) print_method(PHASE_PHASEIDEALLOOP1, 2);
2553       if (failing())  return;
2554     }
2555     // Loop opts pass if partial peeling occurred in previous pass
2556     if(PartialPeelLoop &amp;&amp; major_progress() &amp;&amp; (_loop_opts_cnt &gt; 0)) {
2557       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2558       PhaseIdealLoop::optimize(igvn, LoopOptsSkipSplitIf);
2559       _loop_opts_cnt--;
2560       if (major_progress()) print_method(PHASE_PHASEIDEALLOOP2, 2);
2561       if (failing())  return;
2562     }
</pre>
</td>
</tr>
</table>
<center><a href="cfgnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>