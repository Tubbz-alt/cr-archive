<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/macro.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="library_call.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/macro.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 964   // Scalarize value types that were added to the safepoint
 965   for (uint i = 0; i &lt; value_worklist.size(); ++i) {
 966     Node* vt = value_worklist.at(i);
 967     vt-&gt;as_ValueType()-&gt;make_scalar_in_safepoints(&amp;_igvn);
 968   }
 969   return true;
 970 }
 971 
 972 static void disconnect_projections(MultiNode* n, PhaseIterGVN&amp; igvn) {
 973   Node* ctl_proj = n-&gt;proj_out_or_null(TypeFunc::Control);
 974   Node* mem_proj = n-&gt;proj_out_or_null(TypeFunc::Memory);
 975   if (ctl_proj != NULL) {
 976     igvn.replace_node(ctl_proj, n-&gt;in(0));
 977   }
 978   if (mem_proj != NULL) {
 979     igvn.replace_node(mem_proj, n-&gt;in(TypeFunc::Memory));
 980   }
 981 }
 982 
 983 // Process users of eliminated allocation.
<span class="line-modified"> 984 void PhaseMacroExpand::process_users_of_allocation(CallNode *alloc) {</span>
 985   Node* res = alloc-&gt;result_cast();
 986   if (res != NULL) {
 987     for (DUIterator_Last jmin, j = res-&gt;last_outs(jmin); j &gt;= jmin; ) {
 988       Node *use = res-&gt;last_out(j);
 989       uint oc1 = res-&gt;outcnt();
 990 
 991       if (use-&gt;is_AddP()) {
 992         for (DUIterator_Last kmin, k = use-&gt;last_outs(kmin); k &gt;= kmin; ) {
 993           Node *n = use-&gt;last_out(k);
 994           uint oc2 = use-&gt;outcnt();
 995           if (n-&gt;is_Store()) {
 996 #ifdef ASSERT
 997             // Verify that there is no dependent MemBarVolatile nodes,
 998             // they should be removed during IGVN, see MemBarNode::Ideal().
 999             for (DUIterator_Fast pmax, p = n-&gt;fast_outs(pmax);
1000                                        p &lt; pmax; p++) {
1001               Node* mb = n-&gt;fast_out(p);
1002               assert(mb-&gt;is_Initialize() || !mb-&gt;is_MemBar() ||
1003                      mb-&gt;req() &lt;= MemBarNode::Precedent ||
<span class="line-modified">1004                      mb-&gt;in(MemBarNode::Precedent) != n,</span>

1005                      &quot;MemBarVolatile should be eliminated for non-escaping object&quot;);
1006             }
1007 #endif
1008             _igvn.replace_node(n, n-&gt;in(MemNode::Memory));
1009           } else {
1010             eliminate_gc_barrier(n);
1011           }
1012           k -= (oc2 - use-&gt;outcnt());
1013         }
1014         _igvn.remove_dead_node(use);
1015       } else if (use-&gt;is_ArrayCopy()) {
1016         // Disconnect ArrayCopy node
1017         ArrayCopyNode* ac = use-&gt;as_ArrayCopy();
1018         if (ac-&gt;is_clonebasic()) {
1019           Node* membar_after = ac-&gt;proj_out(TypeFunc::Control)-&gt;unique_ctrl_out();
1020           disconnect_projections(ac, _igvn);
1021           assert(alloc-&gt;in(0)-&gt;is_Proj() &amp;&amp; alloc-&gt;in(0)-&gt;in(0)-&gt;Opcode() == Op_MemBarCPUOrder, &quot;mem barrier expected before allocation&quot;);
1022           Node* membar_before = alloc-&gt;in(0)-&gt;in(0);
1023           disconnect_projections(membar_before-&gt;as_MemBar(), _igvn);
1024           if (membar_after-&gt;is_MemBar()) {
</pre>
<hr />
<pre>
1071     // First disconnect stores captured by Initialize node.
1072     // If Initialize node is eliminated first in the following code,
1073     // it will kill such stores and DUIterator_Last will assert.
1074     for (DUIterator_Fast jmax, j = _resproj-&gt;fast_outs(jmax);  j &lt; jmax; j++) {
1075       Node *use = _resproj-&gt;fast_out(j);
1076       if (use-&gt;is_AddP()) {
1077         // raw memory addresses used only by the initialization
1078         _igvn.replace_node(use, C-&gt;top());
1079         --j; --jmax;
1080       }
1081     }
1082     for (DUIterator_Last jmin, j = _resproj-&gt;last_outs(jmin); j &gt;= jmin; ) {
1083       Node *use = _resproj-&gt;last_out(j);
1084       uint oc1 = _resproj-&gt;outcnt();
1085       if (use-&gt;is_Initialize()) {
1086         // Eliminate Initialize node.
1087         InitializeNode *init = use-&gt;as_Initialize();
1088         assert(init-&gt;outcnt() &lt;= 2, &quot;only a control and memory projection expected&quot;);
1089         Node *ctrl_proj = init-&gt;proj_out_or_null(TypeFunc::Control);
1090         if (ctrl_proj != NULL) {





1091           _igvn.replace_node(ctrl_proj, init-&gt;in(TypeFunc::Control));
1092 #ifdef ASSERT
1093           Node* tmp = init-&gt;in(TypeFunc::Control);
1094           assert(tmp == _fallthroughcatchproj, &quot;allocation control projection&quot;);
1095 #endif
1096         }
1097         Node *mem_proj = init-&gt;proj_out_or_null(TypeFunc::Memory);
1098         if (mem_proj != NULL) {
1099           Node *mem = init-&gt;in(TypeFunc::Memory);
1100 #ifdef ASSERT
1101           if (mem-&gt;is_MergeMem()) {
1102             assert(mem-&gt;in(TypeFunc::Memory) == _memproj_fallthrough, &quot;allocation memory projection&quot;);
1103           } else {
1104             assert(mem == _memproj_fallthrough, &quot;allocation memory projection&quot;);
1105           }
1106 #endif
1107           _igvn.replace_node(mem_proj, mem);
1108         }




1109       } else  {
1110         assert(false, &quot;only Initialize or AddP expected&quot;);
1111       }
1112       j -= (oc1 - _resproj-&gt;outcnt());
1113     }
1114   }
1115   if (_fallthroughcatchproj != NULL) {
1116     _igvn.replace_node(_fallthroughcatchproj, alloc-&gt;in(TypeFunc::Control));
1117   }
1118   if (_memproj_fallthrough != NULL) {
1119     _igvn.replace_node(_memproj_fallthrough, alloc-&gt;in(TypeFunc::Memory));
1120   }
1121   if (_memproj_catchall != NULL) {
1122     _igvn.replace_node(_memproj_catchall, C-&gt;top());
1123   }
1124   if (_ioproj_fallthrough != NULL) {
1125     _igvn.replace_node(_ioproj_fallthrough, alloc-&gt;in(TypeFunc::I_O));
1126   }
1127   if (_ioproj_catchall != NULL) {
1128     _igvn.replace_node(_ioproj_catchall, C-&gt;top());
1129   }
1130   if (_catchallcatchproj != NULL) {
1131     _igvn.replace_node(_catchallcatchproj, C-&gt;top());
1132   }
1133 }
1134 
1135 bool PhaseMacroExpand::eliminate_allocate_node(AllocateNode *alloc) {
1136   // Don&#39;t do scalar replacement if the frame can be popped by JVMTI:
1137   // if reallocation fails during deoptimization we&#39;ll pop all
1138   // interpreter frames for this compiled frame and that won&#39;t play
1139   // nice with JVMTI popframe.
<span class="line-modified">1140   if (!EliminateAllocations || JvmtiExport::can_pop_frame() || !alloc-&gt;_is_non_escaping) {</span>
1141     return false;
1142   }
1143   Node* klass = alloc-&gt;in(AllocateNode::KlassNode);
1144   const TypeKlassPtr* tklass = _igvn.type(klass)-&gt;is_klassptr();
<span class="line-modified">1145   Node* res = alloc-&gt;result_cast();</span>






1146   // Eliminate boxing allocations which are not used
<span class="line-modified">1147   // regardless scalar replacable status.</span>
<span class="line-modified">1148   bool boxing_alloc = C-&gt;eliminate_boxing() &amp;&amp;</span>
<span class="line-modified">1149                       tklass-&gt;klass()-&gt;is_instance_klass()  &amp;&amp;</span>

1150                       tklass-&gt;klass()-&gt;as_instance_klass()-&gt;is_box_klass();
<span class="line-modified">1151   if (!alloc-&gt;_is_scalar_replaceable &amp;&amp; (!boxing_alloc || (res != NULL))) {</span>
1152     return false;
1153   }
1154 
1155   extract_call_projections(alloc);
1156 
1157   GrowableArray &lt;SafePointNode *&gt; safepoints;
1158   if (!can_eliminate_allocation(alloc, safepoints)) {
1159     return false;
1160   }
1161 
1162   if (!alloc-&gt;_is_scalar_replaceable) {
<span class="line-modified">1163     assert(res == NULL, &quot;sanity&quot;);</span>
1164     // We can only eliminate allocation if all debug info references
1165     // are already replaced with SafePointScalarObject because
1166     // we can&#39;t search for a fields value without instance_id.
1167     if (safepoints.length() &gt; 0) {

1168       return false;
1169     }
1170   }
1171 
1172   if (!scalar_replacement(alloc, safepoints)) {
1173     return false;
1174   }
1175 
1176   CompileLog* log = C-&gt;log();
1177   if (log != NULL) {
1178     log-&gt;head(&quot;eliminate_allocation type=&#39;%d&#39;&quot;,
1179               log-&gt;identify(tklass-&gt;klass()));
1180     JVMState* p = alloc-&gt;jvms();
1181     while (p != NULL) {
1182       log-&gt;elem(&quot;jvms bci=&#39;%d&#39; method=&#39;%d&#39;&quot;, p-&gt;bci(), log-&gt;identify(p-&gt;method()));
1183       p = p-&gt;caller();
1184     }
1185     log-&gt;tail(&quot;eliminate_allocation&quot;);
1186   }
1187 
<span class="line-modified">1188   process_users_of_allocation(alloc);</span>
1189 
1190 #ifndef PRODUCT
1191   if (PrintEliminateAllocations) {
1192     if (alloc-&gt;is_AllocateArray())
1193       tty-&gt;print_cr(&quot;++++ Eliminated: %d AllocateArray&quot;, alloc-&gt;_idx);
1194     else
1195       tty-&gt;print_cr(&quot;++++ Eliminated: %d Allocate&quot;, alloc-&gt;_idx);
1196   }
1197 #endif
1198 
1199   return true;
1200 }
1201 
1202 bool PhaseMacroExpand::eliminate_boxing_node(CallStaticJavaNode *boxing) {
1203   // EA should remove all uses of non-escaping boxing node.
1204   if (!C-&gt;eliminate_boxing() || boxing-&gt;proj_out_or_null(TypeFunc::Parms) != NULL) {
1205     return false;
1206   }
1207 
1208   assert(boxing-&gt;result_cast() == NULL, &quot;unexpected boxing node result&quot;);
</pre>
</td>
<td>
<hr />
<pre>
 964   // Scalarize value types that were added to the safepoint
 965   for (uint i = 0; i &lt; value_worklist.size(); ++i) {
 966     Node* vt = value_worklist.at(i);
 967     vt-&gt;as_ValueType()-&gt;make_scalar_in_safepoints(&amp;_igvn);
 968   }
 969   return true;
 970 }
 971 
 972 static void disconnect_projections(MultiNode* n, PhaseIterGVN&amp; igvn) {
 973   Node* ctl_proj = n-&gt;proj_out_or_null(TypeFunc::Control);
 974   Node* mem_proj = n-&gt;proj_out_or_null(TypeFunc::Memory);
 975   if (ctl_proj != NULL) {
 976     igvn.replace_node(ctl_proj, n-&gt;in(0));
 977   }
 978   if (mem_proj != NULL) {
 979     igvn.replace_node(mem_proj, n-&gt;in(TypeFunc::Memory));
 980   }
 981 }
 982 
 983 // Process users of eliminated allocation.
<span class="line-modified"> 984 void PhaseMacroExpand::process_users_of_allocation(CallNode *alloc, bool inline_alloc) {</span>
 985   Node* res = alloc-&gt;result_cast();
 986   if (res != NULL) {
 987     for (DUIterator_Last jmin, j = res-&gt;last_outs(jmin); j &gt;= jmin; ) {
 988       Node *use = res-&gt;last_out(j);
 989       uint oc1 = res-&gt;outcnt();
 990 
 991       if (use-&gt;is_AddP()) {
 992         for (DUIterator_Last kmin, k = use-&gt;last_outs(kmin); k &gt;= kmin; ) {
 993           Node *n = use-&gt;last_out(k);
 994           uint oc2 = use-&gt;outcnt();
 995           if (n-&gt;is_Store()) {
 996 #ifdef ASSERT
 997             // Verify that there is no dependent MemBarVolatile nodes,
 998             // they should be removed during IGVN, see MemBarNode::Ideal().
 999             for (DUIterator_Fast pmax, p = n-&gt;fast_outs(pmax);
1000                                        p &lt; pmax; p++) {
1001               Node* mb = n-&gt;fast_out(p);
1002               assert(mb-&gt;is_Initialize() || !mb-&gt;is_MemBar() ||
1003                      mb-&gt;req() &lt;= MemBarNode::Precedent ||
<span class="line-modified">1004                      mb-&gt;in(MemBarNode::Precedent) != n ||</span>
<span class="line-added">1005                      (inline_alloc &amp;&amp; !ReduceInitialCardMarks),</span>
1006                      &quot;MemBarVolatile should be eliminated for non-escaping object&quot;);
1007             }
1008 #endif
1009             _igvn.replace_node(n, n-&gt;in(MemNode::Memory));
1010           } else {
1011             eliminate_gc_barrier(n);
1012           }
1013           k -= (oc2 - use-&gt;outcnt());
1014         }
1015         _igvn.remove_dead_node(use);
1016       } else if (use-&gt;is_ArrayCopy()) {
1017         // Disconnect ArrayCopy node
1018         ArrayCopyNode* ac = use-&gt;as_ArrayCopy();
1019         if (ac-&gt;is_clonebasic()) {
1020           Node* membar_after = ac-&gt;proj_out(TypeFunc::Control)-&gt;unique_ctrl_out();
1021           disconnect_projections(ac, _igvn);
1022           assert(alloc-&gt;in(0)-&gt;is_Proj() &amp;&amp; alloc-&gt;in(0)-&gt;in(0)-&gt;Opcode() == Op_MemBarCPUOrder, &quot;mem barrier expected before allocation&quot;);
1023           Node* membar_before = alloc-&gt;in(0)-&gt;in(0);
1024           disconnect_projections(membar_before-&gt;as_MemBar(), _igvn);
1025           if (membar_after-&gt;is_MemBar()) {
</pre>
<hr />
<pre>
1072     // First disconnect stores captured by Initialize node.
1073     // If Initialize node is eliminated first in the following code,
1074     // it will kill such stores and DUIterator_Last will assert.
1075     for (DUIterator_Fast jmax, j = _resproj-&gt;fast_outs(jmax);  j &lt; jmax; j++) {
1076       Node *use = _resproj-&gt;fast_out(j);
1077       if (use-&gt;is_AddP()) {
1078         // raw memory addresses used only by the initialization
1079         _igvn.replace_node(use, C-&gt;top());
1080         --j; --jmax;
1081       }
1082     }
1083     for (DUIterator_Last jmin, j = _resproj-&gt;last_outs(jmin); j &gt;= jmin; ) {
1084       Node *use = _resproj-&gt;last_out(j);
1085       uint oc1 = _resproj-&gt;outcnt();
1086       if (use-&gt;is_Initialize()) {
1087         // Eliminate Initialize node.
1088         InitializeNode *init = use-&gt;as_Initialize();
1089         assert(init-&gt;outcnt() &lt;= 2, &quot;only a control and memory projection expected&quot;);
1090         Node *ctrl_proj = init-&gt;proj_out_or_null(TypeFunc::Control);
1091         if (ctrl_proj != NULL) {
<span class="line-added">1092           // Inline type buffer allocations are followed by a membar</span>
<span class="line-added">1093           Node* membar_after = ctrl_proj-&gt;unique_ctrl_out();</span>
<span class="line-added">1094           if (inline_alloc &amp;&amp; membar_after-&gt;Opcode() == Op_MemBarCPUOrder) {</span>
<span class="line-added">1095             membar_after-&gt;as_MemBar()-&gt;remove(&amp;_igvn);</span>
<span class="line-added">1096           }</span>
1097           _igvn.replace_node(ctrl_proj, init-&gt;in(TypeFunc::Control));
1098 #ifdef ASSERT
1099           Node* tmp = init-&gt;in(TypeFunc::Control);
1100           assert(tmp == _fallthroughcatchproj, &quot;allocation control projection&quot;);
1101 #endif
1102         }
1103         Node *mem_proj = init-&gt;proj_out_or_null(TypeFunc::Memory);
1104         if (mem_proj != NULL) {
1105           Node *mem = init-&gt;in(TypeFunc::Memory);
1106 #ifdef ASSERT
1107           if (mem-&gt;is_MergeMem()) {
1108             assert(mem-&gt;in(TypeFunc::Memory) == _memproj_fallthrough, &quot;allocation memory projection&quot;);
1109           } else {
1110             assert(mem == _memproj_fallthrough, &quot;allocation memory projection&quot;);
1111           }
1112 #endif
1113           _igvn.replace_node(mem_proj, mem);
1114         }
<span class="line-added">1115       } else if (use-&gt;Opcode() == Op_MemBarStoreStore) {</span>
<span class="line-added">1116         // Inline type buffer allocations are followed by a membar</span>
<span class="line-added">1117         assert(inline_alloc, &quot;Unexpected MemBarStoreStore&quot;);</span>
<span class="line-added">1118         use-&gt;as_MemBar()-&gt;remove(&amp;_igvn);</span>
1119       } else  {
1120         assert(false, &quot;only Initialize or AddP expected&quot;);
1121       }
1122       j -= (oc1 - _resproj-&gt;outcnt());
1123     }
1124   }
1125   if (_fallthroughcatchproj != NULL) {
1126     _igvn.replace_node(_fallthroughcatchproj, alloc-&gt;in(TypeFunc::Control));
1127   }
1128   if (_memproj_fallthrough != NULL) {
1129     _igvn.replace_node(_memproj_fallthrough, alloc-&gt;in(TypeFunc::Memory));
1130   }
1131   if (_memproj_catchall != NULL) {
1132     _igvn.replace_node(_memproj_catchall, C-&gt;top());
1133   }
1134   if (_ioproj_fallthrough != NULL) {
1135     _igvn.replace_node(_ioproj_fallthrough, alloc-&gt;in(TypeFunc::I_O));
1136   }
1137   if (_ioproj_catchall != NULL) {
1138     _igvn.replace_node(_ioproj_catchall, C-&gt;top());
1139   }
1140   if (_catchallcatchproj != NULL) {
1141     _igvn.replace_node(_catchallcatchproj, C-&gt;top());
1142   }
1143 }
1144 
1145 bool PhaseMacroExpand::eliminate_allocate_node(AllocateNode *alloc) {
1146   // Don&#39;t do scalar replacement if the frame can be popped by JVMTI:
1147   // if reallocation fails during deoptimization we&#39;ll pop all
1148   // interpreter frames for this compiled frame and that won&#39;t play
1149   // nice with JVMTI popframe.
<span class="line-modified">1150   if (!EliminateAllocations || JvmtiExport::can_pop_frame()) {</span>
1151     return false;
1152   }
1153   Node* klass = alloc-&gt;in(AllocateNode::KlassNode);
1154   const TypeKlassPtr* tklass = _igvn.type(klass)-&gt;is_klassptr();
<span class="line-modified">1155 </span>
<span class="line-added">1156   // Attempt to eliminate inline type buffer allocations</span>
<span class="line-added">1157   // regardless of usage and escape/replaceable status.</span>
<span class="line-added">1158   bool inline_alloc = tklass-&gt;klass()-&gt;is_valuetype();</span>
<span class="line-added">1159   if (!alloc-&gt;_is_non_escaping &amp;&amp; !inline_alloc) {</span>
<span class="line-added">1160     return false;</span>
<span class="line-added">1161   }</span>
1162   // Eliminate boxing allocations which are not used
<span class="line-modified">1163   // regardless of scalar replaceable status.</span>
<span class="line-modified">1164   Node* res = alloc-&gt;result_cast();</span>
<span class="line-modified">1165   bool boxing_alloc = (res == NULL) &amp;&amp; C-&gt;eliminate_boxing() &amp;&amp;</span>
<span class="line-added">1166                       tklass-&gt;klass()-&gt;is_instance_klass() &amp;&amp;</span>
1167                       tklass-&gt;klass()-&gt;as_instance_klass()-&gt;is_box_klass();
<span class="line-modified">1168   if (!alloc-&gt;_is_scalar_replaceable &amp;&amp; !boxing_alloc &amp;&amp; !inline_alloc) {</span>
1169     return false;
1170   }
1171 
1172   extract_call_projections(alloc);
1173 
1174   GrowableArray &lt;SafePointNode *&gt; safepoints;
1175   if (!can_eliminate_allocation(alloc, safepoints)) {
1176     return false;
1177   }
1178 
1179   if (!alloc-&gt;_is_scalar_replaceable) {
<span class="line-modified">1180     assert(res == NULL || inline_alloc, &quot;sanity&quot;);</span>
1181     // We can only eliminate allocation if all debug info references
1182     // are already replaced with SafePointScalarObject because
1183     // we can&#39;t search for a fields value without instance_id.
1184     if (safepoints.length() &gt; 0) {
<span class="line-added">1185       assert(!inline_alloc, &quot;Inline type allocations should not have safepoint uses&quot;);</span>
1186       return false;
1187     }
1188   }
1189 
1190   if (!scalar_replacement(alloc, safepoints)) {
1191     return false;
1192   }
1193 
1194   CompileLog* log = C-&gt;log();
1195   if (log != NULL) {
1196     log-&gt;head(&quot;eliminate_allocation type=&#39;%d&#39;&quot;,
1197               log-&gt;identify(tklass-&gt;klass()));
1198     JVMState* p = alloc-&gt;jvms();
1199     while (p != NULL) {
1200       log-&gt;elem(&quot;jvms bci=&#39;%d&#39; method=&#39;%d&#39;&quot;, p-&gt;bci(), log-&gt;identify(p-&gt;method()));
1201       p = p-&gt;caller();
1202     }
1203     log-&gt;tail(&quot;eliminate_allocation&quot;);
1204   }
1205 
<span class="line-modified">1206   process_users_of_allocation(alloc, inline_alloc);</span>
1207 
1208 #ifndef PRODUCT
1209   if (PrintEliminateAllocations) {
1210     if (alloc-&gt;is_AllocateArray())
1211       tty-&gt;print_cr(&quot;++++ Eliminated: %d AllocateArray&quot;, alloc-&gt;_idx);
1212     else
1213       tty-&gt;print_cr(&quot;++++ Eliminated: %d Allocate&quot;, alloc-&gt;_idx);
1214   }
1215 #endif
1216 
1217   return true;
1218 }
1219 
1220 bool PhaseMacroExpand::eliminate_boxing_node(CallStaticJavaNode *boxing) {
1221   // EA should remove all uses of non-escaping boxing node.
1222   if (!C-&gt;eliminate_boxing() || boxing-&gt;proj_out_or_null(TypeFunc::Parms) != NULL) {
1223     return false;
1224   }
1225 
1226   assert(boxing-&gt;result_cast() == NULL, &quot;unexpected boxing node result&quot;);
</pre>
</td>
</tr>
</table>
<center><a href="library_call.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="macro.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>