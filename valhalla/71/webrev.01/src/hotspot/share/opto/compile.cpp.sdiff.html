<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/compile.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="cfgnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/compile.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 390     Node* cast = range_check_cast_node(i);
 391     if (!useful.member(cast)) {
 392       remove_range_check_cast(cast);
 393     }
 394   }
 395   // Remove useless expensive nodes
 396   for (int i = C-&gt;expensive_count()-1; i &gt;= 0; i--) {
 397     Node* n = C-&gt;expensive_node(i);
 398     if (!useful.member(n)) {
 399       remove_expensive_node(n);
 400     }
 401   }
 402   // Remove useless Opaque4 nodes
 403   for (int i = opaque4_count() - 1; i &gt;= 0; i--) {
 404     Node* opaq = opaque4_node(i);
 405     if (!useful.member(opaq)) {
 406       remove_opaque4_node(opaq);
 407     }
 408   }
 409   // Remove useless value type nodes
<span class="line-modified"> 410   if (_value_type_nodes != NULL) {</span>
<span class="line-modified"> 411     _value_type_nodes-&gt;remove_useless_nodes(useful.member_set());</span>



 412   }
 413   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 414   bs-&gt;eliminate_useless_gc_barriers(useful, this);
 415   // clean up the late inline lists
 416   remove_useless_late_inlines(&amp;_string_late_inlines, useful);
 417   remove_useless_late_inlines(&amp;_boxing_late_inlines, useful);
 418   remove_useless_late_inlines(&amp;_late_inlines, useful);
 419   debug_only(verify_graph_edges(true/*check for no_dead_code*/);)
 420 }
 421 
 422 // ============================================================================
 423 //------------------------------CompileWrapper---------------------------------
 424 class CompileWrapper : public StackObj {
 425   Compile *const _compile;
 426  public:
 427   CompileWrapper(Compile* compile);
 428 
 429   ~CompileWrapper();
 430 };
 431 
</pre>
<hr />
<pre>
1003   Copy::zero_to_bytes(ats, sizeof(AliasType)*grow_ats);
1004   {
1005     for (int i = 0; i &lt; grow_ats; i++)  _alias_types[i] = &amp;ats[i];
1006   }
1007   // Initialize the first few types.
1008   _alias_types[AliasIdxTop]-&gt;Init(AliasIdxTop, NULL);
1009   _alias_types[AliasIdxBot]-&gt;Init(AliasIdxBot, TypePtr::BOTTOM);
1010   _alias_types[AliasIdxRaw]-&gt;Init(AliasIdxRaw, TypeRawPtr::BOTTOM);
1011   _num_alias_types = AliasIdxRaw+1;
1012   // Zero out the alias type cache.
1013   Copy::zero_to_bytes(_alias_cache, sizeof(_alias_cache));
1014   // A NULL adr_type hits in the cache right away.  Preload the right answer.
1015   probe_alias_cache(NULL)-&gt;_index = AliasIdxTop;
1016 
1017   _intrinsics = NULL;
1018   _macro_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1019   _predicate_opaqs = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1020   _expensive_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1021   _range_check_casts = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1022   _opaque4_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
<span class="line-modified">1023   _value_type_nodes = new (comp_arena()) Unique_Node_List(comp_arena());</span>
1024   register_library_intrinsics();
1025 #ifdef ASSERT
1026   _type_verify_symmetry = true;
1027 #endif
1028 }
1029 
1030 //---------------------------init_start----------------------------------------
1031 // Install the StartNode on this compile object.
1032 void Compile::init_start(StartNode* s) {
1033   if (failing())
1034     return; // already failing
1035   assert(s == start(), &quot;&quot;);
1036 }
1037 
1038 /**
1039  * Return the &#39;StartNode&#39;. We must not have a pending failure, since the ideal graph
1040  * can be in an inconsistent state, i.e., we can get segmentation faults when traversing
1041  * the ideal graph.
1042  */
1043 StartNode* Compile::start() const {
</pre>
<hr />
<pre>
1859 
1860 // Remove all Opaque4 nodes.
1861 void Compile::remove_opaque4_nodes(PhaseIterGVN &amp;igvn) {
1862   for (int i = opaque4_count(); i &gt; 0; i--) {
1863     Node* opaq = opaque4_node(i-1);
1864     assert(opaq-&gt;Opcode() == Op_Opaque4, &quot;Opaque4 only&quot;);
1865     igvn.replace_node(opaq, opaq-&gt;in(2));
1866   }
1867   assert(opaque4_count() == 0, &quot;should be empty&quot;);
1868 }
1869 
1870 void Compile::add_value_type(Node* n) {
1871   assert(n-&gt;is_ValueTypeBase(), &quot;unexpected node&quot;);
1872   if (_value_type_nodes != NULL) {
1873     _value_type_nodes-&gt;push(n);
1874   }
1875 }
1876 
1877 void Compile::remove_value_type(Node* n) {
1878   assert(n-&gt;is_ValueTypeBase(), &quot;unexpected node&quot;);
<span class="line-modified">1879   if (_value_type_nodes != NULL) {</span>
1880     _value_type_nodes-&gt;remove(n);
1881   }
1882 }
1883 
<span class="line-modified">1884 // Does the return value keep otherwise useless value type allocations</span>
<span class="line-removed">1885 // alive?</span>
1886 static bool return_val_keeps_allocations_alive(Node* ret_val) {
1887   ResourceMark rm;
1888   Unique_Node_List wq;
1889   wq.push(ret_val);
1890   bool some_allocations = false;
1891   for (uint i = 0; i &lt; wq.size(); i++) {
1892     Node* n = wq.at(i);
<span class="line-modified">1893     assert(!n-&gt;is_ValueTypeBase(), &quot;chain of value type nodes&quot;);</span>
1894     if (n-&gt;outcnt() &gt; 1) {
1895       // Some other use for the allocation
1896       return false;


1897     } else if (n-&gt;is_Phi()) {
1898       for (uint j = 1; j &lt; n-&gt;req(); j++) {
1899         wq.push(n-&gt;in(j));
1900       }
1901     } else if (n-&gt;is_CheckCastPP() &amp;&amp;
1902                n-&gt;in(1)-&gt;is_Proj() &amp;&amp;
1903                n-&gt;in(1)-&gt;in(0)-&gt;is_Allocate()) {
1904       some_allocations = true;
1905     }
1906   }
1907   return some_allocations;
1908 }
1909 
<span class="line-modified">1910 void Compile::process_value_types(PhaseIterGVN &amp;igvn) {</span>
1911   // Make value types scalar in safepoints
<span class="line-modified">1912   while (_value_type_nodes-&gt;size() != 0) {</span>
<span class="line-modified">1913     ValueTypeBaseNode* vt = _value_type_nodes-&gt;pop()-&gt;as_ValueTypeBase();</span>
1914     vt-&gt;make_scalar_in_safepoints(&amp;igvn);
<span class="line-modified">1915     if (vt-&gt;is_ValueTypePtr()) {</span>
<span class="line-modified">1916       igvn.replace_node(vt, vt-&gt;get_oop());</span>
<span class="line-modified">1917     } else if (vt-&gt;outcnt() == 0) {</span>
<span class="line-modified">1918       igvn.remove_dead_node(vt);</span>






1919     }
1920   }
<span class="line-modified">1921   _value_type_nodes = NULL;</span>
1922   if (tf()-&gt;returns_value_type_as_fields()) {
1923     Node* ret = NULL;
1924     for (uint i = 1; i &lt; root()-&gt;req(); i++){
1925       Node* in = root()-&gt;in(i);
1926       if (in-&gt;Opcode() == Op_Return) {
1927         assert(ret == NULL, &quot;only one return&quot;);
1928         ret = in;
1929       }
1930     }
1931     if (ret != NULL) {
1932       Node* ret_val = ret-&gt;in(TypeFunc::Parms);
1933       if (igvn.type(ret_val)-&gt;isa_oopptr() &amp;&amp;
1934           return_val_keeps_allocations_alive(ret_val)) {
1935         igvn.replace_input_of(ret, TypeFunc::Parms, ValueTypeNode::tagged_klass(igvn.type(ret_val)-&gt;value_klass(), igvn));
1936         assert(ret_val-&gt;outcnt() == 0, &quot;should be dead now&quot;);
1937         igvn.remove_dead_node(ret_val);
1938       }
1939     }
1940   }
1941   igvn.optimize();
</pre>
<hr />
<pre>
2470   remove_speculative_types(igvn);
2471 
2472   // No more new expensive nodes will be added to the list from here
2473   // so keep only the actual candidates for optimizations.
2474   cleanup_expensive_nodes(igvn);
2475 
2476   if (!failing() &amp;&amp; RenumberLiveNodes &amp;&amp; live_nodes() + NodeLimitFudgeFactor &lt; unique()) {
2477     Compile::TracePhase tp(&quot;&quot;, &amp;timers[_t_renumberLive]);
2478     initial_gvn()-&gt;replace_with(&amp;igvn);
2479     for_igvn()-&gt;clear();
2480     Unique_Node_List new_worklist(C-&gt;comp_arena());
2481     {
2482       ResourceMark rm;
2483       PhaseRenumberLive prl = PhaseRenumberLive(initial_gvn(), for_igvn(), &amp;new_worklist);
2484     }
2485     set_for_igvn(&amp;new_worklist);
2486     igvn = PhaseIterGVN(initial_gvn());
2487     igvn.optimize();
2488   }
2489 
<span class="line-modified">2490   if (_value_type_nodes-&gt;size() &gt; 0) {</span>
2491     // Do this once all inlining is over to avoid getting inconsistent debug info
2492     process_value_types(igvn);
2493   }
2494 
2495   adjust_flattened_array_access_aliases(igvn);
2496 
2497   // Perform escape analysis
2498   if (_do_escape_analysis &amp;&amp; ConnectionGraph::has_candidates(this)) {
2499     if (has_loops()) {
2500       // Cleanup graph (remove dead nodes).
2501       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2502       PhaseIdealLoop::optimize(igvn, LoopOptsMaxUnroll);
2503       if (major_progress()) print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);
2504       if (failing())  return;
2505     }
2506     ConnectionGraph::do_analysis(this, &amp;igvn);
2507 
2508     if (failing())  return;
2509 
2510     // Optimize out fields loads from scalar replaceable allocations.
2511     igvn.optimize();
2512     print_method(PHASE_ITER_GVN_AFTER_EA, 2);
2513 
2514     if (failing())  return;
2515 
2516     if (congraph() != NULL &amp;&amp; macro_count() &gt; 0) {
2517       TracePhase tp(&quot;macroEliminate&quot;, &amp;timers[_t_macroEliminate]);
2518       PhaseMacroExpand mexp(igvn);
2519       mexp.eliminate_macro_nodes();
2520       igvn.set_delay_transform(false);
2521 
2522       igvn.optimize();
2523       print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);
2524 
2525       if (failing())  return;
2526     }
2527   }
2528 





2529   // Loop transforms on the ideal graph.  Range Check Elimination,
2530   // peeling, unrolling, etc.
2531 
2532   // Set loop opts counter
2533   if((_loop_opts_cnt &gt; 0) &amp;&amp; (has_loops() || has_split_ifs())) {
2534     {
2535       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2536       PhaseIdealLoop::optimize(igvn, LoopOptsDefault);
2537       _loop_opts_cnt--;
2538       if (major_progress()) print_method(PHASE_PHASEIDEALLOOP1, 2);
2539       if (failing())  return;
2540     }
2541     // Loop opts pass if partial peeling occurred in previous pass
2542     if(PartialPeelLoop &amp;&amp; major_progress() &amp;&amp; (_loop_opts_cnt &gt; 0)) {
2543       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2544       PhaseIdealLoop::optimize(igvn, LoopOptsSkipSplitIf);
2545       _loop_opts_cnt--;
2546       if (major_progress()) print_method(PHASE_PHASEIDEALLOOP2, 2);
2547       if (failing())  return;
2548     }
</pre>
</td>
<td>
<hr />
<pre>
 390     Node* cast = range_check_cast_node(i);
 391     if (!useful.member(cast)) {
 392       remove_range_check_cast(cast);
 393     }
 394   }
 395   // Remove useless expensive nodes
 396   for (int i = C-&gt;expensive_count()-1; i &gt;= 0; i--) {
 397     Node* n = C-&gt;expensive_node(i);
 398     if (!useful.member(n)) {
 399       remove_expensive_node(n);
 400     }
 401   }
 402   // Remove useless Opaque4 nodes
 403   for (int i = opaque4_count() - 1; i &gt;= 0; i--) {
 404     Node* opaq = opaque4_node(i);
 405     if (!useful.member(opaq)) {
 406       remove_opaque4_node(opaq);
 407     }
 408   }
 409   // Remove useless value type nodes
<span class="line-modified"> 410   for (int i = _value_type_nodes-&gt;length() - 1; i &gt;= 0; i--) {</span>
<span class="line-modified"> 411     Node* vt = _value_type_nodes-&gt;at(i);</span>
<span class="line-added"> 412     if (!useful.member(vt)) {</span>
<span class="line-added"> 413       _value_type_nodes-&gt;remove(vt);</span>
<span class="line-added"> 414     }</span>
 415   }
 416   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 417   bs-&gt;eliminate_useless_gc_barriers(useful, this);
 418   // clean up the late inline lists
 419   remove_useless_late_inlines(&amp;_string_late_inlines, useful);
 420   remove_useless_late_inlines(&amp;_boxing_late_inlines, useful);
 421   remove_useless_late_inlines(&amp;_late_inlines, useful);
 422   debug_only(verify_graph_edges(true/*check for no_dead_code*/);)
 423 }
 424 
 425 // ============================================================================
 426 //------------------------------CompileWrapper---------------------------------
 427 class CompileWrapper : public StackObj {
 428   Compile *const _compile;
 429  public:
 430   CompileWrapper(Compile* compile);
 431 
 432   ~CompileWrapper();
 433 };
 434 
</pre>
<hr />
<pre>
1006   Copy::zero_to_bytes(ats, sizeof(AliasType)*grow_ats);
1007   {
1008     for (int i = 0; i &lt; grow_ats; i++)  _alias_types[i] = &amp;ats[i];
1009   }
1010   // Initialize the first few types.
1011   _alias_types[AliasIdxTop]-&gt;Init(AliasIdxTop, NULL);
1012   _alias_types[AliasIdxBot]-&gt;Init(AliasIdxBot, TypePtr::BOTTOM);
1013   _alias_types[AliasIdxRaw]-&gt;Init(AliasIdxRaw, TypeRawPtr::BOTTOM);
1014   _num_alias_types = AliasIdxRaw+1;
1015   // Zero out the alias type cache.
1016   Copy::zero_to_bytes(_alias_cache, sizeof(_alias_cache));
1017   // A NULL adr_type hits in the cache right away.  Preload the right answer.
1018   probe_alias_cache(NULL)-&gt;_index = AliasIdxTop;
1019 
1020   _intrinsics = NULL;
1021   _macro_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1022   _predicate_opaqs = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1023   _expensive_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1024   _range_check_casts = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1025   _opaque4_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
<span class="line-modified">1026   _value_type_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);</span>
1027   register_library_intrinsics();
1028 #ifdef ASSERT
1029   _type_verify_symmetry = true;
1030 #endif
1031 }
1032 
1033 //---------------------------init_start----------------------------------------
1034 // Install the StartNode on this compile object.
1035 void Compile::init_start(StartNode* s) {
1036   if (failing())
1037     return; // already failing
1038   assert(s == start(), &quot;&quot;);
1039 }
1040 
1041 /**
1042  * Return the &#39;StartNode&#39;. We must not have a pending failure, since the ideal graph
1043  * can be in an inconsistent state, i.e., we can get segmentation faults when traversing
1044  * the ideal graph.
1045  */
1046 StartNode* Compile::start() const {
</pre>
<hr />
<pre>
1862 
1863 // Remove all Opaque4 nodes.
1864 void Compile::remove_opaque4_nodes(PhaseIterGVN &amp;igvn) {
1865   for (int i = opaque4_count(); i &gt; 0; i--) {
1866     Node* opaq = opaque4_node(i-1);
1867     assert(opaq-&gt;Opcode() == Op_Opaque4, &quot;Opaque4 only&quot;);
1868     igvn.replace_node(opaq, opaq-&gt;in(2));
1869   }
1870   assert(opaque4_count() == 0, &quot;should be empty&quot;);
1871 }
1872 
1873 void Compile::add_value_type(Node* n) {
1874   assert(n-&gt;is_ValueTypeBase(), &quot;unexpected node&quot;);
1875   if (_value_type_nodes != NULL) {
1876     _value_type_nodes-&gt;push(n);
1877   }
1878 }
1879 
1880 void Compile::remove_value_type(Node* n) {
1881   assert(n-&gt;is_ValueTypeBase(), &quot;unexpected node&quot;);
<span class="line-modified">1882   if (_value_type_nodes != NULL &amp;&amp; _value_type_nodes-&gt;contains(n)) {</span>
1883     _value_type_nodes-&gt;remove(n);
1884   }
1885 }
1886 
<span class="line-modified">1887 // Does the return value keep otherwise useless value type allocations alive?</span>

1888 static bool return_val_keeps_allocations_alive(Node* ret_val) {
1889   ResourceMark rm;
1890   Unique_Node_List wq;
1891   wq.push(ret_val);
1892   bool some_allocations = false;
1893   for (uint i = 0; i &lt; wq.size(); i++) {
1894     Node* n = wq.at(i);
<span class="line-modified">1895     assert(!n-&gt;is_ValueType(), &quot;chain of value type nodes&quot;);</span>
1896     if (n-&gt;outcnt() &gt; 1) {
1897       // Some other use for the allocation
1898       return false;
<span class="line-added">1899     } else if (n-&gt;is_ValueTypePtr()) {</span>
<span class="line-added">1900       wq.push(n-&gt;in(1));</span>
1901     } else if (n-&gt;is_Phi()) {
1902       for (uint j = 1; j &lt; n-&gt;req(); j++) {
1903         wq.push(n-&gt;in(j));
1904       }
1905     } else if (n-&gt;is_CheckCastPP() &amp;&amp;
1906                n-&gt;in(1)-&gt;is_Proj() &amp;&amp;
1907                n-&gt;in(1)-&gt;in(0)-&gt;is_Allocate()) {
1908       some_allocations = true;
1909     }
1910   }
1911   return some_allocations;
1912 }
1913 
<span class="line-modified">1914 void Compile::process_value_types(PhaseIterGVN &amp;igvn, bool post_ea) {</span>
1915   // Make value types scalar in safepoints
<span class="line-modified">1916   for (int i = _value_type_nodes-&gt;length()-1; i &gt;= 0; i--) {</span>
<span class="line-modified">1917     ValueTypeBaseNode* vt = _value_type_nodes-&gt;at(i)-&gt;as_ValueTypeBase();</span>
1918     vt-&gt;make_scalar_in_safepoints(&amp;igvn);
<span class="line-modified">1919   }</span>
<span class="line-modified">1920   // Remove ValueTypePtr nodes only after EA to give scalar replacement a chance</span>
<span class="line-modified">1921   // to remove buffer allocations. ValueType nodes are kept until loop opts and</span>
<span class="line-modified">1922   // removed via ValueTypeNode::remove_redundant_allocations.</span>
<span class="line-added">1923   if (post_ea) {</span>
<span class="line-added">1924     while (_value_type_nodes-&gt;length() &gt; 0) {</span>
<span class="line-added">1925       ValueTypeBaseNode* vt = _value_type_nodes-&gt;pop()-&gt;as_ValueTypeBase();</span>
<span class="line-added">1926       if (vt-&gt;is_ValueTypePtr()) {</span>
<span class="line-added">1927         igvn.replace_node(vt, vt-&gt;get_oop());</span>
<span class="line-added">1928       }</span>
1929     }
1930   }
<span class="line-modified">1931   // Make sure that the return value does not keep an unused allocation alive</span>
1932   if (tf()-&gt;returns_value_type_as_fields()) {
1933     Node* ret = NULL;
1934     for (uint i = 1; i &lt; root()-&gt;req(); i++){
1935       Node* in = root()-&gt;in(i);
1936       if (in-&gt;Opcode() == Op_Return) {
1937         assert(ret == NULL, &quot;only one return&quot;);
1938         ret = in;
1939       }
1940     }
1941     if (ret != NULL) {
1942       Node* ret_val = ret-&gt;in(TypeFunc::Parms);
1943       if (igvn.type(ret_val)-&gt;isa_oopptr() &amp;&amp;
1944           return_val_keeps_allocations_alive(ret_val)) {
1945         igvn.replace_input_of(ret, TypeFunc::Parms, ValueTypeNode::tagged_klass(igvn.type(ret_val)-&gt;value_klass(), igvn));
1946         assert(ret_val-&gt;outcnt() == 0, &quot;should be dead now&quot;);
1947         igvn.remove_dead_node(ret_val);
1948       }
1949     }
1950   }
1951   igvn.optimize();
</pre>
<hr />
<pre>
2480   remove_speculative_types(igvn);
2481 
2482   // No more new expensive nodes will be added to the list from here
2483   // so keep only the actual candidates for optimizations.
2484   cleanup_expensive_nodes(igvn);
2485 
2486   if (!failing() &amp;&amp; RenumberLiveNodes &amp;&amp; live_nodes() + NodeLimitFudgeFactor &lt; unique()) {
2487     Compile::TracePhase tp(&quot;&quot;, &amp;timers[_t_renumberLive]);
2488     initial_gvn()-&gt;replace_with(&amp;igvn);
2489     for_igvn()-&gt;clear();
2490     Unique_Node_List new_worklist(C-&gt;comp_arena());
2491     {
2492       ResourceMark rm;
2493       PhaseRenumberLive prl = PhaseRenumberLive(initial_gvn(), for_igvn(), &amp;new_worklist);
2494     }
2495     set_for_igvn(&amp;new_worklist);
2496     igvn = PhaseIterGVN(initial_gvn());
2497     igvn.optimize();
2498   }
2499 
<span class="line-modified">2500   if (_value_type_nodes-&gt;length() &gt; 0) {</span>
2501     // Do this once all inlining is over to avoid getting inconsistent debug info
2502     process_value_types(igvn);
2503   }
2504 
2505   adjust_flattened_array_access_aliases(igvn);
2506 
2507   // Perform escape analysis
2508   if (_do_escape_analysis &amp;&amp; ConnectionGraph::has_candidates(this)) {
2509     if (has_loops()) {
2510       // Cleanup graph (remove dead nodes).
2511       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2512       PhaseIdealLoop::optimize(igvn, LoopOptsMaxUnroll);
2513       if (major_progress()) print_method(PHASE_PHASEIDEAL_BEFORE_EA, 2);
2514       if (failing())  return;
2515     }
2516     ConnectionGraph::do_analysis(this, &amp;igvn);
2517 
2518     if (failing())  return;
2519 
2520     // Optimize out fields loads from scalar replaceable allocations.
2521     igvn.optimize();
2522     print_method(PHASE_ITER_GVN_AFTER_EA, 2);
2523 
2524     if (failing())  return;
2525 
2526     if (congraph() != NULL &amp;&amp; macro_count() &gt; 0) {
2527       TracePhase tp(&quot;macroEliminate&quot;, &amp;timers[_t_macroEliminate]);
2528       PhaseMacroExpand mexp(igvn);
2529       mexp.eliminate_macro_nodes();
2530       igvn.set_delay_transform(false);
2531 
2532       igvn.optimize();
2533       print_method(PHASE_ITER_GVN_AFTER_ELIMINATION, 2);
2534 
2535       if (failing())  return;
2536     }
2537   }
2538 
<span class="line-added">2539   if (_value_type_nodes-&gt;length() &gt; 0) {</span>
<span class="line-added">2540     // Process value types again now that EA might have simplified the graph</span>
<span class="line-added">2541     process_value_types(igvn, /* post_ea= */ true);</span>
<span class="line-added">2542   }</span>
<span class="line-added">2543 </span>
2544   // Loop transforms on the ideal graph.  Range Check Elimination,
2545   // peeling, unrolling, etc.
2546 
2547   // Set loop opts counter
2548   if((_loop_opts_cnt &gt; 0) &amp;&amp; (has_loops() || has_split_ifs())) {
2549     {
2550       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2551       PhaseIdealLoop::optimize(igvn, LoopOptsDefault);
2552       _loop_opts_cnt--;
2553       if (major_progress()) print_method(PHASE_PHASEIDEALLOOP1, 2);
2554       if (failing())  return;
2555     }
2556     // Loop opts pass if partial peeling occurred in previous pass
2557     if(PartialPeelLoop &amp;&amp; major_progress() &amp;&amp; (_loop_opts_cnt &gt; 0)) {
2558       TracePhase tp(&quot;idealLoop&quot;, &amp;timers[_t_idealLoop]);
2559       PhaseIdealLoop::optimize(igvn, LoopOptsSkipSplitIf);
2560       _loop_opts_cnt--;
2561       if (major_progress()) print_method(PHASE_PHASEIDEALLOOP2, 2);
2562       if (failing())  return;
2563     }
</pre>
</td>
</tr>
</table>
<center><a href="cfgnode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>