diff a/src/hotspot/share/opto/macro.cpp b/src/hotspot/share/opto/macro.cpp
--- a/src/hotspot/share/opto/macro.cpp
+++ b/src/hotspot/share/opto/macro.cpp
@@ -979,11 +979,11 @@
     igvn.replace_node(mem_proj, n->in(TypeFunc::Memory));
   }
 }
 
 // Process users of eliminated allocation.
-void PhaseMacroExpand::process_users_of_allocation(CallNode *alloc) {
+void PhaseMacroExpand::process_users_of_allocation(CallNode *alloc, bool inline_alloc) {
   Node* res = alloc->result_cast();
   if (res != NULL) {
     for (DUIterator_Last jmin, j = res->last_outs(jmin); j >= jmin; ) {
       Node *use = res->last_out(j);
       uint oc1 = res->outcnt();
@@ -999,11 +999,12 @@
             for (DUIterator_Fast pmax, p = n->fast_outs(pmax);
                                        p < pmax; p++) {
               Node* mb = n->fast_out(p);
               assert(mb->is_Initialize() || !mb->is_MemBar() ||
                      mb->req() <= MemBarNode::Precedent ||
-                     mb->in(MemBarNode::Precedent) != n,
+                     mb->in(MemBarNode::Precedent) != n ||
+                     (inline_alloc && !ReduceInitialCardMarks),
                      "MemBarVolatile should be eliminated for non-escaping object");
             }
 #endif
             _igvn.replace_node(n, n->in(MemNode::Memory));
           } else {
@@ -1086,10 +1087,15 @@
         // Eliminate Initialize node.
         InitializeNode *init = use->as_Initialize();
         assert(init->outcnt() <= 2, "only a control and memory projection expected");
         Node *ctrl_proj = init->proj_out_or_null(TypeFunc::Control);
         if (ctrl_proj != NULL) {
+          // Inline type buffer allocations are followed by a membar
+          Node* membar_after = ctrl_proj->unique_ctrl_out();
+          if (inline_alloc && membar_after->Opcode() == Op_MemBarCPUOrder) {
+            membar_after->as_MemBar()->remove(&_igvn);
+          }
           _igvn.replace_node(ctrl_proj, init->in(TypeFunc::Control));
 #ifdef ASSERT
           Node* tmp = init->in(TypeFunc::Control);
           assert(tmp == _fallthroughcatchproj, "allocation control projection");
 #endif
@@ -1104,10 +1110,14 @@
             assert(mem == _memproj_fallthrough, "allocation memory projection");
           }
 #endif
           _igvn.replace_node(mem_proj, mem);
         }
+      } else if (use->Opcode() == Op_MemBarStoreStore) {
+        // Inline type buffer allocations are followed by a membar
+        assert(inline_alloc, "Unexpected MemBarStoreStore");
+        use->as_MemBar()->remove(&_igvn);
       } else  {
         assert(false, "only Initialize or AddP expected");
       }
       j -= (oc1 - _resproj->outcnt());
     }
@@ -1135,22 +1145,29 @@
 bool PhaseMacroExpand::eliminate_allocate_node(AllocateNode *alloc) {
   // Don't do scalar replacement if the frame can be popped by JVMTI:
   // if reallocation fails during deoptimization we'll pop all
   // interpreter frames for this compiled frame and that won't play
   // nice with JVMTI popframe.
-  if (!EliminateAllocations || JvmtiExport::can_pop_frame() || !alloc->_is_non_escaping) {
+  if (!EliminateAllocations || JvmtiExport::can_pop_frame()) {
     return false;
   }
   Node* klass = alloc->in(AllocateNode::KlassNode);
   const TypeKlassPtr* tklass = _igvn.type(klass)->is_klassptr();
-  Node* res = alloc->result_cast();
+
+  // Attempt to eliminate inline type buffer allocations
+  // regardless of usage and escape/replaceable status.
+  bool inline_alloc = tklass->klass()->is_valuetype();
+  if (!alloc->_is_non_escaping && !inline_alloc) {
+    return false;
+  }
   // Eliminate boxing allocations which are not used
-  // regardless scalar replacable status.
-  bool boxing_alloc = C->eliminate_boxing() &&
-                      tklass->klass()->is_instance_klass()  &&
+  // regardless of scalar replaceable status.
+  Node* res = alloc->result_cast();
+  bool boxing_alloc = (res == NULL) && C->eliminate_boxing() &&
+                      tklass->klass()->is_instance_klass() &&
                       tklass->klass()->as_instance_klass()->is_box_klass();
-  if (!alloc->_is_scalar_replaceable && (!boxing_alloc || (res != NULL))) {
+  if (!alloc->_is_scalar_replaceable && !boxing_alloc && !inline_alloc) {
     return false;
   }
 
   extract_call_projections(alloc);
 
@@ -1158,15 +1175,16 @@
   if (!can_eliminate_allocation(alloc, safepoints)) {
     return false;
   }
 
   if (!alloc->_is_scalar_replaceable) {
-    assert(res == NULL, "sanity");
+    assert(res == NULL || inline_alloc, "sanity");
     // We can only eliminate allocation if all debug info references
     // are already replaced with SafePointScalarObject because
     // we can't search for a fields value without instance_id.
     if (safepoints.length() > 0) {
+      assert(!inline_alloc, "Inline type allocations should not have safepoint uses");
       return false;
     }
   }
 
   if (!scalar_replacement(alloc, safepoints)) {
@@ -1183,11 +1201,11 @@
       p = p->caller();
     }
     log->tail("eliminate_allocation");
   }
 
-  process_users_of_allocation(alloc);
+  process_users_of_allocation(alloc, inline_alloc);
 
 #ifndef PRODUCT
   if (PrintEliminateAllocations) {
     if (alloc->is_AllocateArray())
       tty->print_cr("++++ Eliminated: %d AllocateArray", alloc->_idx);
