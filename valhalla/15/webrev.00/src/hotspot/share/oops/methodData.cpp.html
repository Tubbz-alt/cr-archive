<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/oops/methodData.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/systemDictionary.hpp&quot;
  27 #include &quot;compiler/compilationPolicy.hpp&quot;
  28 #include &quot;compiler/compilerOracle.hpp&quot;
  29 #include &quot;interpreter/bytecode.hpp&quot;
  30 #include &quot;interpreter/bytecodeStream.hpp&quot;
  31 #include &quot;interpreter/linkResolver.hpp&quot;
  32 #include &quot;memory/metaspaceClosure.hpp&quot;
  33 #include &quot;memory/resourceArea.hpp&quot;
  34 #include &quot;oops/methodData.inline.hpp&quot;
  35 #include &quot;prims/jvmtiRedefineClasses.hpp&quot;
  36 #include &quot;runtime/arguments.hpp&quot;
  37 #include &quot;runtime/atomic.hpp&quot;
  38 #include &quot;runtime/deoptimization.hpp&quot;
  39 #include &quot;runtime/handles.inline.hpp&quot;
  40 #include &quot;runtime/orderAccess.hpp&quot;
  41 #include &quot;runtime/safepointVerifiers.hpp&quot;
  42 #include &quot;utilities/align.hpp&quot;
  43 #include &quot;utilities/copy.hpp&quot;
  44 
  45 // ==================================================================
  46 // DataLayout
  47 //
  48 // Overlay for generic profiling data.
  49 
  50 // Some types of data layouts need a length field.
  51 bool DataLayout::needs_array_len(u1 tag) {
  52   return (tag == multi_branch_data_tag) || (tag == arg_info_data_tag) || (tag == parameters_type_data_tag);
  53 }
  54 
  55 // Perform generic initialization of the data.  More specific
  56 // initialization occurs in overrides of ProfileData::post_initialize.
  57 void DataLayout::initialize(u1 tag, u2 bci, int cell_count) {
  58   _header._bits = (intptr_t)0;
  59   _header._struct._tag = tag;
  60   _header._struct._bci = bci;
  61   for (int i = 0; i &lt; cell_count; i++) {
  62     set_cell_at(i, (intptr_t)0);
  63   }
  64   if (needs_array_len(tag)) {
  65     set_cell_at(ArrayData::array_len_off_set, cell_count - 1); // -1 for header.
  66   }
  67   if (tag == call_type_data_tag) {
  68     CallTypeData::initialize(this, cell_count);
  69   } else if (tag == virtual_call_type_data_tag) {
  70     VirtualCallTypeData::initialize(this, cell_count);
  71   }
  72 }
  73 
  74 void DataLayout::clean_weak_klass_links(bool always_clean) {
  75   ResourceMark m;
  76   data_in()-&gt;clean_weak_klass_links(always_clean);
  77 }
  78 
  79 
  80 // ==================================================================
  81 // ProfileData
  82 //
  83 // A ProfileData object is created to refer to a section of profiling
  84 // data in a structured way.
  85 
  86 // Constructor for invalid ProfileData.
  87 ProfileData::ProfileData() {
  88   _data = NULL;
  89 }
  90 
  91 char* ProfileData::print_data_on_helper(const MethodData* md) const {
  92   DataLayout* dp  = md-&gt;extra_data_base();
  93   DataLayout* end = md-&gt;args_data_limit();
  94   stringStream ss;
  95   for (;; dp = MethodData::next_extra(dp)) {
  96     assert(dp &lt; end, &quot;moved past end of extra data&quot;);
  97     switch(dp-&gt;tag()) {
  98     case DataLayout::speculative_trap_data_tag:
  99       if (dp-&gt;bci() == bci()) {
 100         SpeculativeTrapData* data = new SpeculativeTrapData(dp);
 101         int trap = data-&gt;trap_state();
 102         char buf[100];
 103         ss.print(&quot;trap/&quot;);
 104         data-&gt;method()-&gt;print_short_name(&amp;ss);
 105         ss.print(&quot;(%s) &quot;, Deoptimization::format_trap_state(buf, sizeof(buf), trap));
 106       }
 107       break;
 108     case DataLayout::bit_data_tag:
 109       break;
 110     case DataLayout::no_tag:
 111     case DataLayout::arg_info_data_tag:
 112       return ss.as_string();
 113       break;
 114     default:
 115       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
 116     }
 117   }
 118   return NULL;
 119 }
 120 
 121 void ProfileData::print_data_on(outputStream* st, const MethodData* md) const {
 122   print_data_on(st, print_data_on_helper(md));
 123 }
 124 
 125 void ProfileData::print_shared(outputStream* st, const char* name, const char* extra) const {
 126   st-&gt;print(&quot;bci: %d&quot;, bci());
 127   st-&gt;fill_to(tab_width_one);
 128   st-&gt;print(&quot;%s&quot;, name);
 129   tab(st);
 130   int trap = trap_state();
 131   if (trap != 0) {
 132     char buf[100];
 133     st-&gt;print(&quot;trap(%s) &quot;, Deoptimization::format_trap_state(buf, sizeof(buf), trap));
 134   }
 135   if (extra != NULL) {
 136     st-&gt;print(&quot;%s&quot;, extra);
 137   }
 138   int flags = data()-&gt;flags();
 139   if (flags != 0) {
 140     st-&gt;print(&quot;flags(%d) %p/%d&quot;, flags, data(), in_bytes(DataLayout::flags_offset()));
 141   }
 142 }
 143 
 144 void ProfileData::tab(outputStream* st, bool first) const {
 145   st-&gt;fill_to(first ? tab_width_one : tab_width_two);
 146 }
 147 
 148 // ==================================================================
 149 // BitData
 150 //
 151 // A BitData corresponds to a one-bit flag.  This is used to indicate
 152 // whether a checkcast bytecode has seen a null value.
 153 
 154 
 155 void BitData::print_data_on(outputStream* st, const char* extra) const {
 156   print_shared(st, &quot;BitData&quot;, extra);
 157   st-&gt;cr();
 158 }
 159 
 160 // ==================================================================
 161 // CounterData
 162 //
 163 // A CounterData corresponds to a simple counter.
 164 
 165 void CounterData::print_data_on(outputStream* st, const char* extra) const {
 166   print_shared(st, &quot;CounterData&quot;, extra);
 167   st-&gt;print_cr(&quot;count(%u)&quot;, count());
 168 }
 169 
 170 // ==================================================================
 171 // JumpData
 172 //
 173 // A JumpData is used to access profiling information for a direct
 174 // branch.  It is a counter, used for counting the number of branches,
 175 // plus a data displacement, used for realigning the data pointer to
 176 // the corresponding target bci.
 177 
 178 void JumpData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 179   assert(stream-&gt;bci() == bci(), &quot;wrong pos&quot;);
 180   int target;
 181   Bytecodes::Code c = stream-&gt;code();
 182   if (c == Bytecodes::_goto_w || c == Bytecodes::_jsr_w) {
 183     target = stream-&gt;dest_w();
 184   } else {
 185     target = stream-&gt;dest();
 186   }
 187   int my_di = mdo-&gt;dp_to_di(dp());
 188   int target_di = mdo-&gt;bci_to_di(target);
 189   int offset = target_di - my_di;
 190   set_displacement(offset);
 191 }
 192 
 193 void JumpData::print_data_on(outputStream* st, const char* extra) const {
 194   print_shared(st, &quot;JumpData&quot;, extra);
 195   st-&gt;print_cr(&quot;taken(%u) displacement(%d)&quot;, taken(), displacement());
 196 }
 197 
 198 int TypeStackSlotEntries::compute_cell_count(Symbol* signature, bool include_receiver, int max) {
 199   // Parameter profiling include the receiver
 200   int args_count = include_receiver ? 1 : 0;
 201   ResourceMark rm;
 202   ReferenceArgumentCount rac(signature);
 203   args_count += rac.count();
 204   args_count = MIN2(args_count, max);
 205   return args_count * per_arg_cell_count;
 206 }
 207 
 208 int TypeEntriesAtCall::compute_cell_count(BytecodeStream* stream) {
 209   assert(Bytecodes::is_invoke(stream-&gt;code()), &quot;should be invoke&quot;);
 210   assert(TypeStackSlotEntries::per_arg_count() &gt; SingleTypeEntry::static_cell_count(), &quot;code to test for arguments/results broken&quot;);
 211   const methodHandle m = stream-&gt;method();
 212   int bci = stream-&gt;bci();
 213   Bytecode_invoke inv(m, bci);
 214   int args_cell = 0;
 215   if (MethodData::profile_arguments_for_invoke(m, bci)) {
 216     args_cell = TypeStackSlotEntries::compute_cell_count(inv.signature(), false, TypeProfileArgsLimit);
 217   }
 218   int ret_cell = 0;
 219   if (MethodData::profile_return_for_invoke(m, bci) &amp;&amp; is_reference_type(inv.result_type())) {
 220     ret_cell = SingleTypeEntry::static_cell_count();
 221   }
 222   int header_cell = 0;
 223   if (args_cell + ret_cell &gt; 0) {
 224     header_cell = header_cell_count();
 225   }
 226 
 227   return header_cell + args_cell + ret_cell;
 228 }
 229 
 230 class ArgumentOffsetComputer : public SignatureIterator {
 231 private:
 232   int _max;
 233   int _offset;
 234   GrowableArray&lt;int&gt; _offsets;
 235 
 236   friend class SignatureIterator;  // so do_parameters_on can call do_type
 237   void do_type(BasicType type) {
 238     if (is_reference_type(type) &amp;&amp; _offsets.length() &lt; _max) {
 239       _offsets.push(_offset);
 240     }
 241     _offset += parameter_type_word_count(type);
 242   }
 243 
 244  public:
 245   ArgumentOffsetComputer(Symbol* signature, int max)
 246     : SignatureIterator(signature),
 247       _max(max), _offset(0),
 248       _offsets(Thread::current(), max) {
 249     do_parameters_on(this);  // non-virtual template execution
 250   }
 251 
 252   int off_at(int i) const { return _offsets.at(i); }
 253 };
 254 
 255 void TypeStackSlotEntries::post_initialize(Symbol* signature, bool has_receiver, bool include_receiver) {
 256   ResourceMark rm;
 257   int start = 0;
 258   // Parameter profiling include the receiver
 259   if (include_receiver &amp;&amp; has_receiver) {
 260     set_stack_slot(0, 0);
 261     set_type(0, type_none());
 262     start += 1;
 263   }
 264   ArgumentOffsetComputer aos(signature, _number_of_entries-start);
 265   for (int i = start; i &lt; _number_of_entries; i++) {
 266     set_stack_slot(i, aos.off_at(i-start) + (has_receiver ? 1 : 0));
 267     set_type(i, type_none());
 268   }
 269 }
 270 
 271 void CallTypeData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 272   assert(Bytecodes::is_invoke(stream-&gt;code()), &quot;should be invoke&quot;);
 273   Bytecode_invoke inv(stream-&gt;method(), stream-&gt;bci());
 274 
 275   if (has_arguments()) {
 276 #ifdef ASSERT
 277     ResourceMark rm;
 278     ReferenceArgumentCount rac(inv.signature());
 279     int count = MIN2(rac.count(), (int)TypeProfileArgsLimit);
 280     assert(count &gt; 0, &quot;room for args type but none found?&quot;);
 281     check_number_of_arguments(count);
 282 #endif
 283     _args.post_initialize(inv.signature(), inv.has_receiver(), false);
 284   }
 285 
 286   if (has_return()) {
 287     assert(is_reference_type(inv.result_type()), &quot;room for a ret type but doesn&#39;t return obj?&quot;);
 288     _ret.post_initialize();
 289   }
 290 }
 291 
 292 void VirtualCallTypeData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 293   assert(Bytecodes::is_invoke(stream-&gt;code()), &quot;should be invoke&quot;);
 294   Bytecode_invoke inv(stream-&gt;method(), stream-&gt;bci());
 295 
 296   if (has_arguments()) {
 297 #ifdef ASSERT
 298     ResourceMark rm;
 299     ReferenceArgumentCount rac(inv.signature());
 300     int count = MIN2(rac.count(), (int)TypeProfileArgsLimit);
 301     assert(count &gt; 0, &quot;room for args type but none found?&quot;);
 302     check_number_of_arguments(count);
 303 #endif
 304     _args.post_initialize(inv.signature(), inv.has_receiver(), false);
 305   }
 306 
 307   if (has_return()) {
 308     assert(is_reference_type(inv.result_type()), &quot;room for a ret type but doesn&#39;t return obj?&quot;);
 309     _ret.post_initialize();
 310   }
 311 }
 312 
 313 void TypeStackSlotEntries::clean_weak_klass_links(bool always_clean) {
 314   for (int i = 0; i &lt; _number_of_entries; i++) {
 315     intptr_t p = type(i);
 316     Klass* k = (Klass*)klass_part(p);
 317     if (k != NULL &amp;&amp; (always_clean || !k-&gt;is_loader_alive())) {
 318       set_type(i, with_status((Klass*)NULL, p));
 319     }
 320   }
 321 }
 322 
 323 void SingleTypeEntry::clean_weak_klass_links(bool always_clean) {
 324   intptr_t p = type();
 325   Klass* k = (Klass*)klass_part(p);
 326   if (k != NULL &amp;&amp; (always_clean || !k-&gt;is_loader_alive())) {
 327     set_type(with_status((Klass*)NULL, p));
 328   }
 329 }
 330 
 331 bool TypeEntriesAtCall::return_profiling_enabled() {
 332   return MethodData::profile_return();
 333 }
 334 
 335 bool TypeEntriesAtCall::arguments_profiling_enabled() {
 336   return MethodData::profile_arguments();
 337 }
 338 
 339 void TypeEntries::print_klass(outputStream* st, intptr_t k) {
 340   if (is_type_none(k)) {
 341     st-&gt;print(&quot;none&quot;);
 342   } else if (is_type_unknown(k)) {
 343     st-&gt;print(&quot;unknown&quot;);
 344   } else {
 345     valid_klass(k)-&gt;print_value_on(st);
 346   }
 347   if (was_null_seen(k)) {
 348     st-&gt;print(&quot; (null seen)&quot;);
 349   }
 350 }
 351 
 352 void TypeStackSlotEntries::print_data_on(outputStream* st) const {
 353   for (int i = 0; i &lt; _number_of_entries; i++) {
 354     _pd-&gt;tab(st);
 355     st-&gt;print(&quot;%d: stack(%u) &quot;, i, stack_slot(i));
 356     print_klass(st, type(i));
 357     st-&gt;cr();
 358   }
 359 }
 360 
 361 void SingleTypeEntry::print_data_on(outputStream* st) const {
 362   _pd-&gt;tab(st);
 363   print_klass(st, type());
 364   st-&gt;cr();
 365 }
 366 
 367 void CallTypeData::print_data_on(outputStream* st, const char* extra) const {
 368   CounterData::print_data_on(st, extra);
 369   if (has_arguments()) {
 370     tab(st, true);
 371     st-&gt;print(&quot;argument types&quot;);
 372     _args.print_data_on(st);
 373   }
 374   if (has_return()) {
 375     tab(st, true);
 376     st-&gt;print(&quot;return type&quot;);
 377     _ret.print_data_on(st);
 378   }
 379 }
 380 
 381 void VirtualCallTypeData::print_data_on(outputStream* st, const char* extra) const {
 382   VirtualCallData::print_data_on(st, extra);
 383   if (has_arguments()) {
 384     tab(st, true);
 385     st-&gt;print(&quot;argument types&quot;);
 386     _args.print_data_on(st);
 387   }
 388   if (has_return()) {
 389     tab(st, true);
 390     st-&gt;print(&quot;return type&quot;);
 391     _ret.print_data_on(st);
 392   }
 393 }
 394 
 395 // ==================================================================
 396 // ReceiverTypeData
 397 //
 398 // A ReceiverTypeData is used to access profiling information about a
 399 // dynamic type check.  It consists of a counter which counts the total times
 400 // that the check is reached, and a series of (Klass*, count) pairs
 401 // which are used to store a type profile for the receiver of the check.
 402 
 403 void ReceiverTypeData::clean_weak_klass_links(bool always_clean) {
 404     for (uint row = 0; row &lt; row_limit(); row++) {
 405     Klass* p = receiver(row);
 406     if (p != NULL &amp;&amp; (always_clean || !p-&gt;is_loader_alive())) {
 407       clear_row(row);
 408     }
 409   }
 410 }
 411 
 412 void ReceiverTypeData::print_receiver_data_on(outputStream* st) const {
 413   uint row;
 414   int entries = 0;
 415   for (row = 0; row &lt; row_limit(); row++) {
 416     if (receiver(row) != NULL)  entries++;
 417   }
 418 #if INCLUDE_JVMCI
 419   st-&gt;print_cr(&quot;count(%u) nonprofiled_count(%u) entries(%u)&quot;, count(), nonprofiled_count(), entries);
 420 #else
 421   st-&gt;print_cr(&quot;count(%u) entries(%u)&quot;, count(), entries);
 422 #endif
 423   int total = count();
 424   for (row = 0; row &lt; row_limit(); row++) {
 425     if (receiver(row) != NULL) {
 426       total += receiver_count(row);
 427     }
 428   }
 429   for (row = 0; row &lt; row_limit(); row++) {
 430     if (receiver(row) != NULL) {
 431       tab(st);
 432       receiver(row)-&gt;print_value_on(st);
 433       st-&gt;print_cr(&quot;(%u %4.2f)&quot;, receiver_count(row), (float) receiver_count(row) / (float) total);
 434     }
 435   }
 436 }
 437 void ReceiverTypeData::print_data_on(outputStream* st, const char* extra) const {
 438   print_shared(st, &quot;ReceiverTypeData&quot;, extra);
 439   print_receiver_data_on(st);
 440 }
 441 
 442 void VirtualCallData::print_data_on(outputStream* st, const char* extra) const {
 443   print_shared(st, &quot;VirtualCallData&quot;, extra);
 444   print_receiver_data_on(st);
 445 }
 446 
 447 // ==================================================================
 448 // RetData
 449 //
 450 // A RetData is used to access profiling information for a ret bytecode.
 451 // It is composed of a count of the number of times that the ret has
 452 // been executed, followed by a series of triples of the form
 453 // (bci, count, di) which count the number of times that some bci was the
 454 // target of the ret and cache a corresponding displacement.
 455 
 456 void RetData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 457   for (uint row = 0; row &lt; row_limit(); row++) {
 458     set_bci_displacement(row, -1);
 459     set_bci(row, no_bci);
 460   }
 461   // release so other threads see a consistent state.  bci is used as
 462   // a valid flag for bci_displacement.
 463   OrderAccess::release();
 464 }
 465 
 466 // This routine needs to atomically update the RetData structure, so the
 467 // caller needs to hold the RetData_lock before it gets here.  Since taking
 468 // the lock can block (and allow GC) and since RetData is a ProfileData is a
 469 // wrapper around a derived oop, taking the lock in _this_ method will
 470 // basically cause the &#39;this&#39; pointer&#39;s _data field to contain junk after the
 471 // lock.  We require the caller to take the lock before making the ProfileData
 472 // structure.  Currently the only caller is InterpreterRuntime::update_mdp_for_ret
 473 address RetData::fixup_ret(int return_bci, MethodData* h_mdo) {
 474   // First find the mdp which corresponds to the return bci.
 475   address mdp = h_mdo-&gt;bci_to_dp(return_bci);
 476 
 477   // Now check to see if any of the cache slots are open.
 478   for (uint row = 0; row &lt; row_limit(); row++) {
 479     if (bci(row) == no_bci) {
 480       set_bci_displacement(row, mdp - dp());
 481       set_bci_count(row, DataLayout::counter_increment);
 482       // Barrier to ensure displacement is written before the bci; allows
 483       // the interpreter to read displacement without fear of race condition.
 484       release_set_bci(row, return_bci);
 485       break;
 486     }
 487   }
 488   return mdp;
 489 }
 490 
 491 void RetData::print_data_on(outputStream* st, const char* extra) const {
 492   print_shared(st, &quot;RetData&quot;, extra);
 493   uint row;
 494   int entries = 0;
 495   for (row = 0; row &lt; row_limit(); row++) {
 496     if (bci(row) != no_bci)  entries++;
 497   }
 498   st-&gt;print_cr(&quot;count(%u) entries(%u)&quot;, count(), entries);
 499   for (row = 0; row &lt; row_limit(); row++) {
 500     if (bci(row) != no_bci) {
 501       tab(st);
 502       st-&gt;print_cr(&quot;bci(%d: count(%u) displacement(%d))&quot;,
 503                    bci(row), bci_count(row), bci_displacement(row));
 504     }
 505   }
 506 }
 507 
 508 // ==================================================================
 509 // BranchData
 510 //
 511 // A BranchData is used to access profiling data for a two-way branch.
 512 // It consists of taken and not_taken counts as well as a data displacement
 513 // for the taken case.
 514 
 515 void BranchData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 516   assert(stream-&gt;bci() == bci(), &quot;wrong pos&quot;);
 517   int target = stream-&gt;dest();
 518   int my_di = mdo-&gt;dp_to_di(dp());
 519   int target_di = mdo-&gt;bci_to_di(target);
 520   int offset = target_di - my_di;
 521   set_displacement(offset);
 522 }
 523 
 524 void BranchData::print_data_on(outputStream* st, const char* extra) const {
 525   print_shared(st, &quot;BranchData&quot;, extra);
 526   st-&gt;print_cr(&quot;taken(%u) displacement(%d)&quot;,
 527                taken(), displacement());
 528   tab(st);
 529   st-&gt;print_cr(&quot;not taken(%u)&quot;, not_taken());
 530 }
 531 
 532 // ==================================================================
 533 // MultiBranchData
 534 //
 535 // A MultiBranchData is used to access profiling information for
 536 // a multi-way branch (*switch bytecodes).  It consists of a series
 537 // of (count, displacement) pairs, which count the number of times each
 538 // case was taken and specify the data displacment for each branch target.
 539 
 540 int MultiBranchData::compute_cell_count(BytecodeStream* stream) {
 541   int cell_count = 0;
 542   if (stream-&gt;code() == Bytecodes::_tableswitch) {
 543     Bytecode_tableswitch sw(stream-&gt;method()(), stream-&gt;bcp());
 544     cell_count = 1 + per_case_cell_count * (1 + sw.length()); // 1 for default
 545   } else {
 546     Bytecode_lookupswitch sw(stream-&gt;method()(), stream-&gt;bcp());
 547     cell_count = 1 + per_case_cell_count * (sw.number_of_pairs() + 1); // 1 for default
 548   }
 549   return cell_count;
 550 }
 551 
 552 void MultiBranchData::post_initialize(BytecodeStream* stream,
 553                                       MethodData* mdo) {
 554   assert(stream-&gt;bci() == bci(), &quot;wrong pos&quot;);
 555   int target;
 556   int my_di;
 557   int target_di;
 558   int offset;
 559   if (stream-&gt;code() == Bytecodes::_tableswitch) {
 560     Bytecode_tableswitch sw(stream-&gt;method()(), stream-&gt;bcp());
 561     int len = sw.length();
 562     assert(array_len() == per_case_cell_count * (len + 1), &quot;wrong len&quot;);
 563     for (int count = 0; count &lt; len; count++) {
 564       target = sw.dest_offset_at(count) + bci();
 565       my_di = mdo-&gt;dp_to_di(dp());
 566       target_di = mdo-&gt;bci_to_di(target);
 567       offset = target_di - my_di;
 568       set_displacement_at(count, offset);
 569     }
 570     target = sw.default_offset() + bci();
 571     my_di = mdo-&gt;dp_to_di(dp());
 572     target_di = mdo-&gt;bci_to_di(target);
 573     offset = target_di - my_di;
 574     set_default_displacement(offset);
 575 
 576   } else {
 577     Bytecode_lookupswitch sw(stream-&gt;method()(), stream-&gt;bcp());
 578     int npairs = sw.number_of_pairs();
 579     assert(array_len() == per_case_cell_count * (npairs + 1), &quot;wrong len&quot;);
 580     for (int count = 0; count &lt; npairs; count++) {
 581       LookupswitchPair pair = sw.pair_at(count);
 582       target = pair.offset() + bci();
 583       my_di = mdo-&gt;dp_to_di(dp());
 584       target_di = mdo-&gt;bci_to_di(target);
 585       offset = target_di - my_di;
 586       set_displacement_at(count, offset);
 587     }
 588     target = sw.default_offset() + bci();
 589     my_di = mdo-&gt;dp_to_di(dp());
 590     target_di = mdo-&gt;bci_to_di(target);
 591     offset = target_di - my_di;
 592     set_default_displacement(offset);
 593   }
 594 }
 595 
 596 void MultiBranchData::print_data_on(outputStream* st, const char* extra) const {
 597   print_shared(st, &quot;MultiBranchData&quot;, extra);
 598   st-&gt;print_cr(&quot;default_count(%u) displacement(%d)&quot;,
 599                default_count(), default_displacement());
 600   int cases = number_of_cases();
 601   for (int i = 0; i &lt; cases; i++) {
 602     tab(st);
 603     st-&gt;print_cr(&quot;count(%u) displacement(%d)&quot;,
 604                  count_at(i), displacement_at(i));
 605   }
 606 }
 607 
 608 void ArgInfoData::print_data_on(outputStream* st, const char* extra) const {
 609   print_shared(st, &quot;ArgInfoData&quot;, extra);
 610   int nargs = number_of_args();
 611   for (int i = 0; i &lt; nargs; i++) {
 612     st-&gt;print(&quot;  0x%x&quot;, arg_modified(i));
 613   }
 614   st-&gt;cr();
 615 }
 616 
 617 int ParametersTypeData::compute_cell_count(Method* m) {
 618   if (!MethodData::profile_parameters_for_method(methodHandle(Thread::current(), m))) {
 619     return 0;
 620   }
 621   int max = TypeProfileParmsLimit == -1 ? INT_MAX : TypeProfileParmsLimit;
 622   int obj_args = TypeStackSlotEntries::compute_cell_count(m-&gt;signature(), !m-&gt;is_static(), max);
 623   if (obj_args &gt; 0) {
 624     return obj_args + 1; // 1 cell for array len
 625   }
 626   return 0;
 627 }
 628 
 629 void ParametersTypeData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 630   _parameters.post_initialize(mdo-&gt;method()-&gt;signature(), !mdo-&gt;method()-&gt;is_static(), true);
 631 }
 632 
 633 bool ParametersTypeData::profiling_enabled() {
 634   return MethodData::profile_parameters();
 635 }
 636 
 637 void ParametersTypeData::print_data_on(outputStream* st, const char* extra) const {
 638   st-&gt;print(&quot;parameter types&quot;); // FIXME extra ignored?
 639   _parameters.print_data_on(st);
 640 }
 641 
 642 void SpeculativeTrapData::print_data_on(outputStream* st, const char* extra) const {
 643   print_shared(st, &quot;SpeculativeTrapData&quot;, extra);
 644   tab(st);
 645   method()-&gt;print_short_name(st);
 646   st-&gt;cr();
 647 }
 648 
 649 void ArrayLoadStoreData::print_data_on(outputStream* st, const char* extra) const {
 650   print_shared(st, &quot;ArrayLoadStore&quot;, extra);
 651   st-&gt;cr();
 652   tab(st, true);
 653   st-&gt;print(&quot;array&quot;);
 654   _array.print_data_on(st);
 655   tab(st, true);
 656   st-&gt;print(&quot;element&quot;);
 657   _element.print_data_on(st);
 658 }
 659 
 660 // ==================================================================
 661 // MethodData*
 662 //
 663 // A MethodData* holds information which has been collected about
 664 // a method.
 665 
 666 MethodData* MethodData::allocate(ClassLoaderData* loader_data, const methodHandle&amp; method, TRAPS) {
 667   int size = MethodData::compute_allocation_size_in_words(method);
 668 
 669   return new (loader_data, size, MetaspaceObj::MethodDataType, THREAD)
 670     MethodData(method, size, THREAD);
 671 }
 672 
 673 int MethodData::bytecode_cell_count(Bytecodes::Code code) {
 674   if (is_client_compilation_mode_vm()) {
 675     return no_profile_data;
 676   }
 677   switch (code) {
 678   case Bytecodes::_checkcast:
 679   case Bytecodes::_instanceof:
 680     if (TypeProfileCasts) {
 681       return ReceiverTypeData::static_cell_count();
 682     } else {
 683       return BitData::static_cell_count();
 684     }
 685   case Bytecodes::_aaload:
 686   case Bytecodes::_aastore:
 687     return ArrayLoadStoreData::static_cell_count();
 688   case Bytecodes::_invokespecial:
 689   case Bytecodes::_invokestatic:
 690     if (MethodData::profile_arguments() || MethodData::profile_return()) {
 691       return variable_cell_count;
 692     } else {
 693       return CounterData::static_cell_count();
 694     }
 695   case Bytecodes::_goto:
 696   case Bytecodes::_goto_w:
 697   case Bytecodes::_jsr:
 698   case Bytecodes::_jsr_w:
 699     return JumpData::static_cell_count();
 700   case Bytecodes::_invokevirtual:
 701   case Bytecodes::_invokeinterface:
 702     if (MethodData::profile_arguments() || MethodData::profile_return()) {
 703       return variable_cell_count;
 704     } else {
 705       return VirtualCallData::static_cell_count();
 706     }
 707   case Bytecodes::_invokedynamic:
 708     if (MethodData::profile_arguments() || MethodData::profile_return()) {
 709       return variable_cell_count;
 710     } else {
 711       return CounterData::static_cell_count();
 712     }
 713   case Bytecodes::_ret:
 714     return RetData::static_cell_count();
 715   case Bytecodes::_ifeq:
 716   case Bytecodes::_ifne:
 717   case Bytecodes::_iflt:
 718   case Bytecodes::_ifge:
 719   case Bytecodes::_ifgt:
 720   case Bytecodes::_ifle:
 721   case Bytecodes::_if_icmpeq:
 722   case Bytecodes::_if_icmpne:
 723   case Bytecodes::_if_icmplt:
 724   case Bytecodes::_if_icmpge:
 725   case Bytecodes::_if_icmpgt:
 726   case Bytecodes::_if_icmple:
 727   case Bytecodes::_if_acmpeq:
 728   case Bytecodes::_if_acmpne:
 729   case Bytecodes::_ifnull:
 730   case Bytecodes::_ifnonnull:
 731     return BranchData::static_cell_count();
 732   case Bytecodes::_lookupswitch:
 733   case Bytecodes::_tableswitch:
 734     return variable_cell_count;
 735   default:
 736     return no_profile_data;
 737   }
 738 }
 739 
 740 // Compute the size of the profiling information corresponding to
 741 // the current bytecode.
 742 int MethodData::compute_data_size(BytecodeStream* stream) {
 743   int cell_count = bytecode_cell_count(stream-&gt;code());
 744   if (cell_count == no_profile_data) {
 745     return 0;
 746   }
 747   if (cell_count == variable_cell_count) {
 748     switch (stream-&gt;code()) {
 749     case Bytecodes::_lookupswitch:
 750     case Bytecodes::_tableswitch:
 751       cell_count = MultiBranchData::compute_cell_count(stream);
 752       break;
 753     case Bytecodes::_invokespecial:
 754     case Bytecodes::_invokestatic:
 755     case Bytecodes::_invokedynamic:
 756       assert(MethodData::profile_arguments() || MethodData::profile_return(), &quot;should be collecting args profile&quot;);
 757       if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
 758           profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
 759         cell_count = CallTypeData::compute_cell_count(stream);
 760       } else {
 761         cell_count = CounterData::static_cell_count();
 762       }
 763       break;
 764     case Bytecodes::_invokevirtual:
 765     case Bytecodes::_invokeinterface: {
 766       assert(MethodData::profile_arguments() || MethodData::profile_return(), &quot;should be collecting args profile&quot;);
 767       if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
 768           profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
 769         cell_count = VirtualCallTypeData::compute_cell_count(stream);
 770       } else {
 771         cell_count = VirtualCallData::static_cell_count();
 772       }
 773       break;
 774     }
 775     default:
 776       fatal(&quot;unexpected bytecode for var length profile data&quot;);
 777     }
 778   }
 779   // Note:  cell_count might be zero, meaning that there is just
 780   //        a DataLayout header, with no extra cells.
 781   assert(cell_count &gt;= 0, &quot;sanity&quot;);
 782   return DataLayout::compute_size_in_bytes(cell_count);
 783 }
 784 
 785 bool MethodData::is_speculative_trap_bytecode(Bytecodes::Code code) {
 786   // Bytecodes for which we may use speculation
 787   switch (code) {
 788   case Bytecodes::_checkcast:
 789   case Bytecodes::_instanceof:
 790   case Bytecodes::_aaload:
 791   case Bytecodes::_aastore:
 792   case Bytecodes::_invokevirtual:
 793   case Bytecodes::_invokeinterface:
 794   case Bytecodes::_if_acmpeq:
 795   case Bytecodes::_if_acmpne:
 796   case Bytecodes::_ifnull:
 797   case Bytecodes::_ifnonnull:
 798   case Bytecodes::_invokestatic:
 799 #ifdef COMPILER2
 800     if (is_server_compilation_mode_vm()) {
 801       return UseTypeSpeculation;
 802     }
 803 #endif
 804   default:
 805     return false;
 806   }
 807   return false;
 808 }
 809 
 810 #if INCLUDE_JVMCI
 811 
 812 void* FailedSpeculation::operator new(size_t size, size_t fs_size) throw() {
 813   return CHeapObj&lt;mtCompiler&gt;::operator new(fs_size, std::nothrow);
 814 }
 815 
 816 FailedSpeculation::FailedSpeculation(address speculation, int speculation_len) : _data_len(speculation_len), _next(NULL) {
 817   memcpy(data(), speculation, speculation_len);
 818 }
 819 
 820 // A heuristic check to detect nmethods that outlive a failed speculations list.
 821 static void guarantee_failed_speculations_alive(nmethod* nm, FailedSpeculation** failed_speculations_address) {
 822   jlong head = (jlong)(address) *failed_speculations_address;
 823   if ((head &amp; 0x1) == 0x1) {
 824     stringStream st;
 825     if (nm != NULL) {
 826       st.print(&quot;%d&quot;, nm-&gt;compile_id());
 827       Method* method = nm-&gt;method();
 828       st.print_raw(&quot;{&quot;);
 829       if (method != NULL) {
 830         method-&gt;print_name(&amp;st);
 831       } else {
 832         const char* jvmci_name = nm-&gt;jvmci_name();
 833         if (jvmci_name != NULL) {
 834           st.print_raw(jvmci_name);
 835         }
 836       }
 837       st.print_raw(&quot;}&quot;);
 838     } else {
 839       st.print(&quot;&lt;unknown&gt;&quot;);
 840     }
 841     fatal(&quot;Adding to failed speculations list that appears to have been freed. Source: %s&quot;, st.as_string());
 842   }
 843 }
 844 
 845 bool FailedSpeculation::add_failed_speculation(nmethod* nm, FailedSpeculation** failed_speculations_address, address speculation, int speculation_len) {
 846   assert(failed_speculations_address != NULL, &quot;must be&quot;);
 847   size_t fs_size = sizeof(FailedSpeculation) + speculation_len;
 848   FailedSpeculation* fs = new (fs_size) FailedSpeculation(speculation, speculation_len);
 849   if (fs == NULL) {
 850     // no memory -&gt; ignore failed speculation
 851     return false;
 852   }
 853 
 854   guarantee(is_aligned(fs, sizeof(FailedSpeculation*)), &quot;FailedSpeculation objects must be pointer aligned&quot;);
 855   guarantee_failed_speculations_alive(nm, failed_speculations_address);
 856 
 857   FailedSpeculation** cursor = failed_speculations_address;
 858   do {
 859     if (*cursor == NULL) {
 860       FailedSpeculation* old_fs = Atomic::cmpxchg(cursor, (FailedSpeculation*) NULL, fs);
 861       if (old_fs == NULL) {
 862         // Successfully appended fs to end of the list
 863         return true;
 864       }
 865       cursor = old_fs-&gt;next_adr();
 866     } else {
 867       cursor = (*cursor)-&gt;next_adr();
 868     }
 869   } while (true);
 870 }
 871 
 872 void FailedSpeculation::free_failed_speculations(FailedSpeculation** failed_speculations_address) {
 873   assert(failed_speculations_address != NULL, &quot;must be&quot;);
 874   FailedSpeculation* fs = *failed_speculations_address;
 875   while (fs != NULL) {
 876     FailedSpeculation* next = fs-&gt;next();
 877     delete fs;
 878     fs = next;
 879   }
 880 
 881   // Write an unaligned value to failed_speculations_address to denote
 882   // that it is no longer a valid pointer. This is allows for the check
 883   // in add_failed_speculation against adding to a freed failed
 884   // speculations list.
 885   long* head = (long*) failed_speculations_address;
 886   (*head) = (*head) | 0x1;
 887 }
 888 #endif // INCLUDE_JVMCI
 889 
 890 int MethodData::compute_extra_data_count(int data_size, int empty_bc_count, bool needs_speculative_traps) {
 891 #if INCLUDE_JVMCI
 892   if (ProfileTraps) {
 893     // Assume that up to 30% of the possibly trapping BCIs with no MDP will need to allocate one.
 894     int extra_data_count = MIN2(empty_bc_count, MAX2(4, (empty_bc_count * 30) / 100));
 895 
 896     // Make sure we have a minimum number of extra data slots to
 897     // allocate SpeculativeTrapData entries. We would want to have one
 898     // entry per compilation that inlines this method and for which
 899     // some type speculation assumption fails. So the room we need for
 900     // the SpeculativeTrapData entries doesn&#39;t directly depend on the
 901     // size of the method. Because it&#39;s hard to estimate, we reserve
 902     // space for an arbitrary number of entries.
 903     int spec_data_count = (needs_speculative_traps ? SpecTrapLimitExtraEntries : 0) *
 904       (SpeculativeTrapData::static_cell_count() + DataLayout::header_size_in_cells());
 905 
 906     return MAX2(extra_data_count, spec_data_count);
 907   } else {
 908     return 0;
 909   }
 910 #else // INCLUDE_JVMCI
 911   if (ProfileTraps) {
 912     // Assume that up to 3% of BCIs with no MDP will need to allocate one.
 913     int extra_data_count = (uint)(empty_bc_count * 3) / 128 + 1;
 914     // If the method is large, let the extra BCIs grow numerous (to ~1%).
 915     int one_percent_of_data
 916       = (uint)data_size / (DataLayout::header_size_in_bytes()*128);
 917     if (extra_data_count &lt; one_percent_of_data)
 918       extra_data_count = one_percent_of_data;
 919     if (extra_data_count &gt; empty_bc_count)
 920       extra_data_count = empty_bc_count;  // no need for more
 921 
 922     // Make sure we have a minimum number of extra data slots to
 923     // allocate SpeculativeTrapData entries. We would want to have one
 924     // entry per compilation that inlines this method and for which
 925     // some type speculation assumption fails. So the room we need for
 926     // the SpeculativeTrapData entries doesn&#39;t directly depend on the
 927     // size of the method. Because it&#39;s hard to estimate, we reserve
 928     // space for an arbitrary number of entries.
 929     int spec_data_count = (needs_speculative_traps ? SpecTrapLimitExtraEntries : 0) *
 930       (SpeculativeTrapData::static_cell_count() + DataLayout::header_size_in_cells());
 931 
 932     return MAX2(extra_data_count, spec_data_count);
 933   } else {
 934     return 0;
 935   }
 936 #endif // INCLUDE_JVMCI
 937 }
 938 
 939 // Compute the size of the MethodData* necessary to store
 940 // profiling information about a given method.  Size is in bytes.
 941 int MethodData::compute_allocation_size_in_bytes(const methodHandle&amp; method) {
 942   int data_size = 0;
 943   BytecodeStream stream(method);
 944   Bytecodes::Code c;
 945   int empty_bc_count = 0;  // number of bytecodes lacking data
 946   bool needs_speculative_traps = false;
 947   while ((c = stream.next()) &gt;= 0) {
 948     int size_in_bytes = compute_data_size(&amp;stream);
 949     data_size += size_in_bytes;
 950     if (size_in_bytes == 0 JVMCI_ONLY(&amp;&amp; Bytecodes::can_trap(c)))  empty_bc_count += 1;
 951     needs_speculative_traps = needs_speculative_traps || is_speculative_trap_bytecode(c);
 952   }
 953   int object_size = in_bytes(data_offset()) + data_size;
 954 
 955   // Add some extra DataLayout cells (at least one) to track stray traps.
 956   int extra_data_count = compute_extra_data_count(data_size, empty_bc_count, needs_speculative_traps);
 957   object_size += extra_data_count * DataLayout::compute_size_in_bytes(0);
 958 
 959   // Add a cell to record information about modified arguments.
 960   int arg_size = method-&gt;size_of_parameters();
 961   object_size += DataLayout::compute_size_in_bytes(arg_size+1);
 962 
 963   // Reserve room for an area of the MDO dedicated to profiling of
 964   // parameters
 965   int args_cell = ParametersTypeData::compute_cell_count(method());
 966   if (args_cell &gt; 0) {
 967     object_size += DataLayout::compute_size_in_bytes(args_cell);
 968   }
 969   return object_size;
 970 }
 971 
 972 // Compute the size of the MethodData* necessary to store
 973 // profiling information about a given method.  Size is in words
 974 int MethodData::compute_allocation_size_in_words(const methodHandle&amp; method) {
 975   int byte_size = compute_allocation_size_in_bytes(method);
 976   int word_size = align_up(byte_size, BytesPerWord) / BytesPerWord;
 977   return align_metadata_size(word_size);
 978 }
 979 
 980 // Initialize an individual data segment.  Returns the size of
 981 // the segment in bytes.
 982 int MethodData::initialize_data(BytecodeStream* stream,
 983                                        int data_index) {
 984   if (is_client_compilation_mode_vm()) {
 985     return 0;
 986   }
 987   int cell_count = -1;
 988   int tag = DataLayout::no_tag;
 989   DataLayout* data_layout = data_layout_at(data_index);
 990   Bytecodes::Code c = stream-&gt;code();
 991   switch (c) {
 992   case Bytecodes::_checkcast:
 993   case Bytecodes::_instanceof:
 994     if (TypeProfileCasts) {
 995       cell_count = ReceiverTypeData::static_cell_count();
 996       tag = DataLayout::receiver_type_data_tag;
 997     } else {
 998       cell_count = BitData::static_cell_count();
 999       tag = DataLayout::bit_data_tag;
1000     }
1001     break;
1002   case Bytecodes::_aaload:
1003   case Bytecodes::_aastore:
1004     cell_count = ArrayLoadStoreData::static_cell_count();
1005     tag = DataLayout::array_load_store_data_tag;
1006     break;
1007   case Bytecodes::_invokespecial:
1008   case Bytecodes::_invokestatic: {
1009     int counter_data_cell_count = CounterData::static_cell_count();
1010     if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
1011         profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
1012       cell_count = CallTypeData::compute_cell_count(stream);
1013     } else {
1014       cell_count = counter_data_cell_count;
1015     }
1016     if (cell_count &gt; counter_data_cell_count) {
1017       tag = DataLayout::call_type_data_tag;
1018     } else {
1019       tag = DataLayout::counter_data_tag;
1020     }
1021     break;
1022   }
1023   case Bytecodes::_goto:
1024   case Bytecodes::_goto_w:
1025   case Bytecodes::_jsr:
1026   case Bytecodes::_jsr_w:
1027     cell_count = JumpData::static_cell_count();
1028     tag = DataLayout::jump_data_tag;
1029     break;
1030   case Bytecodes::_invokevirtual:
1031   case Bytecodes::_invokeinterface: {
1032     int virtual_call_data_cell_count = VirtualCallData::static_cell_count();
1033     if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
1034         profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
1035       cell_count = VirtualCallTypeData::compute_cell_count(stream);
1036     } else {
1037       cell_count = virtual_call_data_cell_count;
1038     }
1039     if (cell_count &gt; virtual_call_data_cell_count) {
1040       tag = DataLayout::virtual_call_type_data_tag;
1041     } else {
1042       tag = DataLayout::virtual_call_data_tag;
1043     }
1044     break;
1045   }
1046   case Bytecodes::_invokedynamic: {
1047     // %%% should make a type profile for any invokedynamic that takes a ref argument
1048     int counter_data_cell_count = CounterData::static_cell_count();
1049     if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
1050         profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
1051       cell_count = CallTypeData::compute_cell_count(stream);
1052     } else {
1053       cell_count = counter_data_cell_count;
1054     }
1055     if (cell_count &gt; counter_data_cell_count) {
1056       tag = DataLayout::call_type_data_tag;
1057     } else {
1058       tag = DataLayout::counter_data_tag;
1059     }
1060     break;
1061   }
1062   case Bytecodes::_ret:
1063     cell_count = RetData::static_cell_count();
1064     tag = DataLayout::ret_data_tag;
1065     break;
1066   case Bytecodes::_ifeq:
1067   case Bytecodes::_ifne:
1068   case Bytecodes::_iflt:
1069   case Bytecodes::_ifge:
1070   case Bytecodes::_ifgt:
1071   case Bytecodes::_ifle:
1072   case Bytecodes::_if_icmpeq:
1073   case Bytecodes::_if_icmpne:
1074   case Bytecodes::_if_icmplt:
1075   case Bytecodes::_if_icmpge:
1076   case Bytecodes::_if_icmpgt:
1077   case Bytecodes::_if_icmple:
1078   case Bytecodes::_if_acmpeq:
1079   case Bytecodes::_if_acmpne:
1080   case Bytecodes::_ifnull:
1081   case Bytecodes::_ifnonnull:
1082     cell_count = BranchData::static_cell_count();
1083     tag = DataLayout::branch_data_tag;
1084     break;
1085   case Bytecodes::_lookupswitch:
1086   case Bytecodes::_tableswitch:
1087     cell_count = MultiBranchData::compute_cell_count(stream);
1088     tag = DataLayout::multi_branch_data_tag;
1089     break;
1090   default:
1091     break;
1092   }
1093   assert(tag == DataLayout::multi_branch_data_tag ||
1094          ((MethodData::profile_arguments() || MethodData::profile_return()) &amp;&amp;
1095           (tag == DataLayout::call_type_data_tag ||
1096            tag == DataLayout::counter_data_tag ||
1097            tag == DataLayout::virtual_call_type_data_tag ||
1098            tag == DataLayout::virtual_call_data_tag)) ||
1099          cell_count == bytecode_cell_count(c), &quot;cell counts must agree&quot;);
1100   if (cell_count &gt;= 0) {
1101     assert(tag != DataLayout::no_tag, &quot;bad tag&quot;);
1102     assert(bytecode_has_profile(c), &quot;agree w/ BHP&quot;);
1103     data_layout-&gt;initialize(tag, stream-&gt;bci(), cell_count);
1104     return DataLayout::compute_size_in_bytes(cell_count);
1105   } else {
1106     assert(!bytecode_has_profile(c), &quot;agree w/ !BHP&quot;);
1107     return 0;
1108   }
1109 }
1110 
1111 // Get the data at an arbitrary (sort of) data index.
1112 ProfileData* MethodData::data_at(int data_index) const {
1113   if (out_of_bounds(data_index)) {
1114     return NULL;
1115   }
1116   DataLayout* data_layout = data_layout_at(data_index);
1117   return data_layout-&gt;data_in();
1118 }
1119 
1120 ProfileData* DataLayout::data_in() {
1121   switch (tag()) {
1122   case DataLayout::no_tag:
1123   default:
1124     ShouldNotReachHere();
1125     return NULL;
1126   case DataLayout::bit_data_tag:
1127     return new BitData(this);
1128   case DataLayout::counter_data_tag:
1129     return new CounterData(this);
1130   case DataLayout::jump_data_tag:
1131     return new JumpData(this);
1132   case DataLayout::receiver_type_data_tag:
1133     return new ReceiverTypeData(this);
1134   case DataLayout::virtual_call_data_tag:
1135     return new VirtualCallData(this);
1136   case DataLayout::ret_data_tag:
1137     return new RetData(this);
1138   case DataLayout::branch_data_tag:
1139     return new BranchData(this);
1140   case DataLayout::multi_branch_data_tag:
1141     return new MultiBranchData(this);
1142   case DataLayout::arg_info_data_tag:
1143     return new ArgInfoData(this);
1144   case DataLayout::call_type_data_tag:
1145     return new CallTypeData(this);
1146   case DataLayout::virtual_call_type_data_tag:
1147     return new VirtualCallTypeData(this);
1148   case DataLayout::parameters_type_data_tag:
1149     return new ParametersTypeData(this);
1150   case DataLayout::speculative_trap_data_tag:
1151     return new SpeculativeTrapData(this);
1152   case DataLayout::array_load_store_data_tag:
1153     return new ArrayLoadStoreData(this);
1154   }
1155 }
1156 
1157 // Iteration over data.
1158 ProfileData* MethodData::next_data(ProfileData* current) const {
1159   int current_index = dp_to_di(current-&gt;dp());
1160   int next_index = current_index + current-&gt;size_in_bytes();
1161   ProfileData* next = data_at(next_index);
1162   return next;
1163 }
1164 
1165 // Give each of the data entries a chance to perform specific
1166 // data initialization.
1167 void MethodData::post_initialize(BytecodeStream* stream) {
1168   ResourceMark rm;
1169   ProfileData* data;
1170   for (data = first_data(); is_valid(data); data = next_data(data)) {
1171     stream-&gt;set_start(data-&gt;bci());
1172     stream-&gt;next();
1173     data-&gt;post_initialize(stream, this);
1174   }
1175   if (_parameters_type_data_di != no_parameters) {
1176     parameters_type_data()-&gt;post_initialize(NULL, this);
1177   }
1178 }
1179 
1180 // Initialize the MethodData* corresponding to a given method.
1181 MethodData::MethodData(const methodHandle&amp; method, int size, TRAPS)
1182   : _extra_data_lock(Mutex::leaf, &quot;MDO extra data lock&quot;),
1183     _parameters_type_data_di(parameters_uninitialized) {
1184   // Set the method back-pointer.
1185   _method = method();
1186   initialize();
1187 }
1188 
1189 void MethodData::initialize() {
1190   Thread* thread = Thread::current();
1191   NoSafepointVerifier no_safepoint;  // init function atomic wrt GC
1192   ResourceMark rm(thread);
1193 
1194   init();
1195   set_creation_mileage(mileage_of(method()));
1196 
1197   // Go through the bytecodes and allocate and initialize the
1198   // corresponding data cells.
1199   int data_size = 0;
1200   int empty_bc_count = 0;  // number of bytecodes lacking data
1201   _data[0] = 0;  // apparently not set below.
1202   BytecodeStream stream(methodHandle(thread, method()));
1203   Bytecodes::Code c;
1204   bool needs_speculative_traps = false;
1205   while ((c = stream.next()) &gt;= 0) {
1206     int size_in_bytes = initialize_data(&amp;stream, data_size);
1207     data_size += size_in_bytes;
1208     if (size_in_bytes == 0 JVMCI_ONLY(&amp;&amp; Bytecodes::can_trap(c)))  empty_bc_count += 1;
1209     needs_speculative_traps = needs_speculative_traps || is_speculative_trap_bytecode(c);
1210   }
1211   _data_size = data_size;
1212   int object_size = in_bytes(data_offset()) + data_size;
1213 
1214   // Add some extra DataLayout cells (at least one) to track stray traps.
1215   int extra_data_count = compute_extra_data_count(data_size, empty_bc_count, needs_speculative_traps);
1216   int extra_size = extra_data_count * DataLayout::compute_size_in_bytes(0);
1217 
1218   // Let&#39;s zero the space for the extra data
1219   Copy::zero_to_bytes(((address)_data) + data_size, extra_size);
1220 
1221   // Add a cell to record information about modified arguments.
1222   // Set up _args_modified array after traps cells so that
1223   // the code for traps cells works.
1224   DataLayout *dp = data_layout_at(data_size + extra_size);
1225 
1226   int arg_size = method()-&gt;size_of_parameters();
1227   dp-&gt;initialize(DataLayout::arg_info_data_tag, 0, arg_size+1);
1228 
1229   int arg_data_size = DataLayout::compute_size_in_bytes(arg_size+1);
1230   object_size += extra_size + arg_data_size;
1231 
1232   int parms_cell = ParametersTypeData::compute_cell_count(method());
1233   // If we are profiling parameters, we reserver an area near the end
1234   // of the MDO after the slots for bytecodes (because there&#39;s no bci
1235   // for method entry so they don&#39;t fit with the framework for the
1236   // profiling of bytecodes). We store the offset within the MDO of
1237   // this area (or -1 if no parameter is profiled)
1238   if (parms_cell &gt; 0) {
1239     object_size += DataLayout::compute_size_in_bytes(parms_cell);
1240     _parameters_type_data_di = data_size + extra_size + arg_data_size;
1241     DataLayout *dp = data_layout_at(data_size + extra_size + arg_data_size);
1242     dp-&gt;initialize(DataLayout::parameters_type_data_tag, 0, parms_cell);
1243   } else {
1244     _parameters_type_data_di = no_parameters;
1245   }
1246 
1247   // Set an initial hint. Don&#39;t use set_hint_di() because
1248   // first_di() may be out of bounds if data_size is 0.
1249   // In that situation, _hint_di is never used, but at
1250   // least well-defined.
1251   _hint_di = first_di();
1252 
1253   post_initialize(&amp;stream);
1254 
1255   assert(object_size == compute_allocation_size_in_bytes(methodHandle(thread, _method)), &quot;MethodData: computed size != initialized size&quot;);
1256   set_size(object_size);
1257 }
1258 
1259 void MethodData::init() {
1260   _invocation_counter.init();
1261   _backedge_counter.init();
1262   _invocation_counter_start = 0;
1263   _backedge_counter_start = 0;
1264 
1265   // Set per-method invoke- and backedge mask.
1266   double scale = 1.0;
1267   methodHandle mh(Thread::current(), _method);
1268   CompilerOracle::has_option_value(mh, &quot;CompileThresholdScaling&quot;, scale);
1269   _invoke_mask = right_n_bits(CompilerConfig::scaled_freq_log(Tier0InvokeNotifyFreqLog, scale)) &lt;&lt; InvocationCounter::count_shift;
1270   _backedge_mask = right_n_bits(CompilerConfig::scaled_freq_log(Tier0BackedgeNotifyFreqLog, scale)) &lt;&lt; InvocationCounter::count_shift;
1271 
1272   _tenure_traps = 0;
1273   _num_loops = 0;
1274   _num_blocks = 0;
1275   _would_profile = unknown;
1276 
1277 #if INCLUDE_JVMCI
1278   _jvmci_ir_size = 0;
1279   _failed_speculations = NULL;
1280 #endif
1281 
1282 #if INCLUDE_RTM_OPT
1283   _rtm_state = NoRTM; // No RTM lock eliding by default
1284   if (UseRTMLocking &amp;&amp;
1285       !CompilerOracle::has_option_string(mh, &quot;NoRTMLockEliding&quot;)) {
1286     if (CompilerOracle::has_option_string(mh, &quot;UseRTMLockEliding&quot;) || !UseRTMDeopt) {
1287       // Generate RTM lock eliding code without abort ratio calculation code.
1288       _rtm_state = UseRTM;
1289     } else if (UseRTMDeopt) {
1290       // Generate RTM lock eliding code and include abort ratio calculation
1291       // code if UseRTMDeopt is on.
1292       _rtm_state = ProfileRTM;
1293     }
1294   }
1295 #endif
1296 
1297   // Initialize flags and trap history.
1298   _nof_decompiles = 0;
1299   _nof_overflow_recompiles = 0;
1300   _nof_overflow_traps = 0;
1301   clear_escape_info();
1302   assert(sizeof(_trap_hist) % sizeof(HeapWord) == 0, &quot;align&quot;);
1303   Copy::zero_to_words((HeapWord*) &amp;_trap_hist,
1304                       sizeof(_trap_hist) / sizeof(HeapWord));
1305 }
1306 
1307 // Get a measure of how much mileage the method has on it.
1308 int MethodData::mileage_of(Method* method) {
1309   int mileage = 0;
1310   if (TieredCompilation) {
1311     mileage = MAX2(method-&gt;invocation_count(), method-&gt;backedge_count());
1312   } else {
1313     int iic = method-&gt;interpreter_invocation_count();
1314     if (mileage &lt; iic)  mileage = iic;
1315     MethodCounters* mcs = method-&gt;method_counters();
1316     if (mcs != NULL) {
1317       InvocationCounter* ic = mcs-&gt;invocation_counter();
1318       InvocationCounter* bc = mcs-&gt;backedge_counter();
1319       int icval = ic-&gt;count();
1320       if (ic-&gt;carry()) icval += CompileThreshold;
1321       if (mileage &lt; icval)  mileage = icval;
1322       int bcval = bc-&gt;count();
1323       if (bc-&gt;carry()) bcval += CompileThreshold;
1324       if (mileage &lt; bcval)  mileage = bcval;
1325     }
1326   }
1327   return mileage;
1328 }
1329 
1330 bool MethodData::is_mature() const {
1331   return CompilationPolicy::policy()-&gt;is_mature(_method);
1332 }
1333 
1334 // Translate a bci to its corresponding data index (di).
1335 address MethodData::bci_to_dp(int bci) {
1336   ResourceMark rm;
1337   ProfileData* data = data_before(bci);
1338   ProfileData* prev = NULL;
1339   for ( ; is_valid(data); data = next_data(data)) {
1340     if (data-&gt;bci() &gt;= bci) {
1341       if (data-&gt;bci() == bci)  set_hint_di(dp_to_di(data-&gt;dp()));
1342       else if (prev != NULL)   set_hint_di(dp_to_di(prev-&gt;dp()));
1343       return data-&gt;dp();
1344     }
1345     prev = data;
1346   }
1347   return (address)limit_data_position();
1348 }
1349 
1350 // Translate a bci to its corresponding data, or NULL.
1351 ProfileData* MethodData::bci_to_data(int bci) {
1352   ProfileData* data = data_before(bci);
1353   for ( ; is_valid(data); data = next_data(data)) {
1354     if (data-&gt;bci() == bci) {
1355       set_hint_di(dp_to_di(data-&gt;dp()));
1356       return data;
1357     } else if (data-&gt;bci() &gt; bci) {
1358       break;
1359     }
1360   }
1361   return bci_to_extra_data(bci, NULL, false);
1362 }
1363 
1364 DataLayout* MethodData::next_extra(DataLayout* dp) {
1365   int nb_cells = 0;
1366   switch(dp-&gt;tag()) {
1367   case DataLayout::bit_data_tag:
1368   case DataLayout::no_tag:
1369     nb_cells = BitData::static_cell_count();
1370     break;
1371   case DataLayout::speculative_trap_data_tag:
1372     nb_cells = SpeculativeTrapData::static_cell_count();
1373     break;
1374   default:
1375     fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1376   }
1377   return (DataLayout*)((address)dp + DataLayout::compute_size_in_bytes(nb_cells));
1378 }
1379 
1380 ProfileData* MethodData::bci_to_extra_data_helper(int bci, Method* m, DataLayout*&amp; dp, bool concurrent) {
1381   DataLayout* end = args_data_limit();
1382 
1383   for (;; dp = next_extra(dp)) {
1384     assert(dp &lt; end, &quot;moved past end of extra data&quot;);
1385     // No need for &quot;Atomic::load_acquire&quot; ops,
1386     // since the data structure is monotonic.
1387     switch(dp-&gt;tag()) {
1388     case DataLayout::no_tag:
1389       return NULL;
1390     case DataLayout::arg_info_data_tag:
1391       dp = end;
1392       return NULL; // ArgInfoData is at the end of extra data section.
1393     case DataLayout::bit_data_tag:
1394       if (m == NULL &amp;&amp; dp-&gt;bci() == bci) {
1395         return new BitData(dp);
1396       }
1397       break;
1398     case DataLayout::speculative_trap_data_tag:
1399       if (m != NULL) {
1400         SpeculativeTrapData* data = new SpeculativeTrapData(dp);
1401         // data-&gt;method() may be null in case of a concurrent
1402         // allocation. Maybe it&#39;s for the same method. Try to use that
1403         // entry in that case.
1404         if (dp-&gt;bci() == bci) {
1405           if (data-&gt;method() == NULL) {
1406             assert(concurrent, &quot;impossible because no concurrent allocation&quot;);
1407             return NULL;
1408           } else if (data-&gt;method() == m) {
1409             return data;
1410           }
1411         }
1412       }
1413       break;
1414     default:
1415       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1416     }
1417   }
1418   return NULL;
1419 }
1420 
1421 
1422 // Translate a bci to its corresponding extra data, or NULL.
1423 ProfileData* MethodData::bci_to_extra_data(int bci, Method* m, bool create_if_missing) {
1424   // This code assumes an entry for a SpeculativeTrapData is 2 cells
1425   assert(2*DataLayout::compute_size_in_bytes(BitData::static_cell_count()) ==
1426          DataLayout::compute_size_in_bytes(SpeculativeTrapData::static_cell_count()),
1427          &quot;code needs to be adjusted&quot;);
1428 
1429   // Do not create one of these if method has been redefined.
1430   if (m != NULL &amp;&amp; m-&gt;is_old()) {
1431     return NULL;
1432   }
1433 
1434   DataLayout* dp  = extra_data_base();
1435   DataLayout* end = args_data_limit();
1436 
1437   // Allocation in the extra data space has to be atomic because not
1438   // all entries have the same size and non atomic concurrent
1439   // allocation would result in a corrupted extra data space.
1440   ProfileData* result = bci_to_extra_data_helper(bci, m, dp, true);
1441   if (result != NULL) {
1442     return result;
1443   }
1444 
1445   if (create_if_missing &amp;&amp; dp &lt; end) {
1446     MutexLocker ml(&amp;_extra_data_lock);
1447     // Check again now that we have the lock. Another thread may
1448     // have added extra data entries.
1449     ProfileData* result = bci_to_extra_data_helper(bci, m, dp, false);
1450     if (result != NULL || dp &gt;= end) {
1451       return result;
1452     }
1453 
1454     assert(dp-&gt;tag() == DataLayout::no_tag || (dp-&gt;tag() == DataLayout::speculative_trap_data_tag &amp;&amp; m != NULL), &quot;should be free&quot;);
1455     assert(next_extra(dp)-&gt;tag() == DataLayout::no_tag || next_extra(dp)-&gt;tag() == DataLayout::arg_info_data_tag, &quot;should be free or arg info&quot;);
1456     u1 tag = m == NULL ? DataLayout::bit_data_tag : DataLayout::speculative_trap_data_tag;
1457     // SpeculativeTrapData is 2 slots. Make sure we have room.
1458     if (m != NULL &amp;&amp; next_extra(dp)-&gt;tag() != DataLayout::no_tag) {
1459       return NULL;
1460     }
1461     DataLayout temp;
1462     temp.initialize(tag, bci, 0);
1463 
1464     dp-&gt;set_header(temp.header());
1465     assert(dp-&gt;tag() == tag, &quot;sane&quot;);
1466     assert(dp-&gt;bci() == bci, &quot;no concurrent allocation&quot;);
1467     if (tag == DataLayout::bit_data_tag) {
1468       return new BitData(dp);
1469     } else {
1470       SpeculativeTrapData* data = new SpeculativeTrapData(dp);
1471       data-&gt;set_method(m);
1472       return data;
1473     }
1474   }
1475   return NULL;
1476 }
1477 
1478 ArgInfoData *MethodData::arg_info() {
1479   DataLayout* dp    = extra_data_base();
1480   DataLayout* end   = args_data_limit();
1481   for (; dp &lt; end; dp = next_extra(dp)) {
1482     if (dp-&gt;tag() == DataLayout::arg_info_data_tag)
1483       return new ArgInfoData(dp);
1484   }
1485   return NULL;
1486 }
1487 
1488 // Printing
1489 
1490 void MethodData::print_on(outputStream* st) const {
1491   assert(is_methodData(), &quot;should be method data&quot;);
1492   st-&gt;print(&quot;method data for &quot;);
1493   method()-&gt;print_value_on(st);
1494   st-&gt;cr();
1495   print_data_on(st);
1496 }
1497 
1498 void MethodData::print_value_on(outputStream* st) const {
1499   assert(is_methodData(), &quot;should be method data&quot;);
1500   st-&gt;print(&quot;method data for &quot;);
1501   method()-&gt;print_value_on(st);
1502 }
1503 
1504 void MethodData::print_data_on(outputStream* st) const {
1505   ResourceMark rm;
1506   ProfileData* data = first_data();
1507   if (_parameters_type_data_di != no_parameters) {
1508     parameters_type_data()-&gt;print_data_on(st);
1509   }
1510   for ( ; is_valid(data); data = next_data(data)) {
1511     st-&gt;print(&quot;%d&quot;, dp_to_di(data-&gt;dp()));
1512     st-&gt;fill_to(6);
1513     data-&gt;print_data_on(st, this);
1514   }
1515   st-&gt;print_cr(&quot;--- Extra data:&quot;);
1516   DataLayout* dp    = extra_data_base();
1517   DataLayout* end   = args_data_limit();
1518   for (;; dp = next_extra(dp)) {
1519     assert(dp &lt; end, &quot;moved past end of extra data&quot;);
1520     // No need for &quot;Atomic::load_acquire&quot; ops,
1521     // since the data structure is monotonic.
1522     switch(dp-&gt;tag()) {
1523     case DataLayout::no_tag:
1524       continue;
1525     case DataLayout::bit_data_tag:
1526       data = new BitData(dp);
1527       break;
1528     case DataLayout::speculative_trap_data_tag:
1529       data = new SpeculativeTrapData(dp);
1530       break;
1531     case DataLayout::arg_info_data_tag:
1532       data = new ArgInfoData(dp);
1533       dp = end; // ArgInfoData is at the end of extra data section.
1534       break;
1535     default:
1536       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1537     }
1538     st-&gt;print(&quot;%d&quot;, dp_to_di(data-&gt;dp()));
1539     st-&gt;fill_to(6);
1540     data-&gt;print_data_on(st);
1541     if (dp &gt;= end) return;
1542   }
1543 }
1544 
1545 // Verification
1546 
1547 void MethodData::verify_on(outputStream* st) {
1548   guarantee(is_methodData(), &quot;object must be method data&quot;);
1549   // guarantee(m-&gt;is_perm(), &quot;should be in permspace&quot;);
1550   this-&gt;verify_data_on(st);
1551 }
1552 
1553 void MethodData::verify_data_on(outputStream* st) {
1554   NEEDS_CLEANUP;
1555   // not yet implemented.
1556 }
1557 
1558 bool MethodData::profile_jsr292(const methodHandle&amp; m, int bci) {
1559   if (m-&gt;is_compiled_lambda_form()) {
1560     return true;
1561   }
1562 
1563   Bytecode_invoke inv(m , bci);
1564   return inv.is_invokedynamic() || inv.is_invokehandle();
1565 }
1566 
1567 bool MethodData::profile_unsafe(const methodHandle&amp; m, int bci) {
1568   Bytecode_invoke inv(m , bci);
1569   if (inv.is_invokevirtual()) {
1570     if (inv.klass() == vmSymbols::jdk_internal_misc_Unsafe() ||
1571         inv.klass() == vmSymbols::sun_misc_Unsafe()) {
1572       ResourceMark rm;
1573       char* name = inv.name()-&gt;as_C_string();
1574       if (!strncmp(name, &quot;get&quot;, 3) || !strncmp(name, &quot;put&quot;, 3)) {
1575         return true;
1576       }
1577     }
1578   }
1579   return false;
1580 }
1581 
1582 int MethodData::profile_arguments_flag() {
1583   return TypeProfileLevel % 10;
1584 }
1585 
1586 bool MethodData::profile_arguments() {
1587   return profile_arguments_flag() &gt; no_type_profile &amp;&amp; profile_arguments_flag() &lt;= type_profile_all;
1588 }
1589 
1590 bool MethodData::profile_arguments_jsr292_only() {
1591   return profile_arguments_flag() == type_profile_jsr292;
1592 }
1593 
1594 bool MethodData::profile_all_arguments() {
1595   return profile_arguments_flag() == type_profile_all;
1596 }
1597 
1598 bool MethodData::profile_arguments_for_invoke(const methodHandle&amp; m, int bci) {
1599   if (!profile_arguments()) {
1600     return false;
1601   }
1602 
1603   if (profile_all_arguments()) {
1604     return true;
1605   }
1606 
1607   if (profile_unsafe(m, bci)) {
1608     return true;
1609   }
1610 
1611   assert(profile_arguments_jsr292_only(), &quot;inconsistent&quot;);
1612   return profile_jsr292(m, bci);
1613 }
1614 
1615 int MethodData::profile_return_flag() {
1616   return (TypeProfileLevel % 100) / 10;
1617 }
1618 
1619 bool MethodData::profile_return() {
1620   return profile_return_flag() &gt; no_type_profile &amp;&amp; profile_return_flag() &lt;= type_profile_all;
1621 }
1622 
1623 bool MethodData::profile_return_jsr292_only() {
1624   return profile_return_flag() == type_profile_jsr292;
1625 }
1626 
1627 bool MethodData::profile_all_return() {
1628   return profile_return_flag() == type_profile_all;
1629 }
1630 
1631 bool MethodData::profile_return_for_invoke(const methodHandle&amp; m, int bci) {
1632   if (!profile_return()) {
1633     return false;
1634   }
1635 
1636   if (profile_all_return()) {
1637     return true;
1638   }
1639 
1640   assert(profile_return_jsr292_only(), &quot;inconsistent&quot;);
1641   return profile_jsr292(m, bci);
1642 }
1643 
1644 int MethodData::profile_parameters_flag() {
1645   return TypeProfileLevel / 100;
1646 }
1647 
1648 bool MethodData::profile_parameters() {
1649   return profile_parameters_flag() &gt; no_type_profile &amp;&amp; profile_parameters_flag() &lt;= type_profile_all;
1650 }
1651 
1652 bool MethodData::profile_parameters_jsr292_only() {
1653   return profile_parameters_flag() == type_profile_jsr292;
1654 }
1655 
1656 bool MethodData::profile_all_parameters() {
1657   return profile_parameters_flag() == type_profile_all;
1658 }
1659 
1660 bool MethodData::profile_parameters_for_method(const methodHandle&amp; m) {
1661   if (!profile_parameters()) {
1662     return false;
1663   }
1664 
1665   if (profile_all_parameters()) {
1666     return true;
1667   }
1668 
1669   assert(profile_parameters_jsr292_only(), &quot;inconsistent&quot;);
1670   return m-&gt;is_compiled_lambda_form();
1671 }
1672 
1673 void MethodData::metaspace_pointers_do(MetaspaceClosure* it) {
1674   log_trace(cds)(&quot;Iter(MethodData): %p&quot;, this);
1675   it-&gt;push(&amp;_method);
1676 }
1677 
1678 void MethodData::clean_extra_data_helper(DataLayout* dp, int shift, bool reset) {
1679   if (shift == 0) {
1680     return;
1681   }
1682   if (!reset) {
1683     // Move all cells of trap entry at dp left by &quot;shift&quot; cells
1684     intptr_t* start = (intptr_t*)dp;
1685     intptr_t* end = (intptr_t*)next_extra(dp);
1686     for (intptr_t* ptr = start; ptr &lt; end; ptr++) {
1687       *(ptr-shift) = *ptr;
1688     }
1689   } else {
1690     // Reset &quot;shift&quot; cells stopping at dp
1691     intptr_t* start = ((intptr_t*)dp) - shift;
1692     intptr_t* end = (intptr_t*)dp;
1693     for (intptr_t* ptr = start; ptr &lt; end; ptr++) {
1694       *ptr = 0;
1695     }
1696   }
1697 }
1698 
1699 // Check for entries that reference an unloaded method
1700 class CleanExtraDataKlassClosure : public CleanExtraDataClosure {
1701   bool _always_clean;
1702 public:
1703   CleanExtraDataKlassClosure(bool always_clean) : _always_clean(always_clean) {}
1704   bool is_live(Method* m) {
1705     return !(_always_clean) &amp;&amp; m-&gt;method_holder()-&gt;is_loader_alive();
1706   }
1707 };
1708 
1709 // Check for entries that reference a redefined method
1710 class CleanExtraDataMethodClosure : public CleanExtraDataClosure {
1711 public:
1712   CleanExtraDataMethodClosure() {}
1713   bool is_live(Method* m) { return !m-&gt;is_old(); }
1714 };
1715 
1716 
1717 // Remove SpeculativeTrapData entries that reference an unloaded or
1718 // redefined method
1719 void MethodData::clean_extra_data(CleanExtraDataClosure* cl) {
1720   DataLayout* dp  = extra_data_base();
1721   DataLayout* end = args_data_limit();
1722 
1723   int shift = 0;
1724   for (; dp &lt; end; dp = next_extra(dp)) {
1725     switch(dp-&gt;tag()) {
1726     case DataLayout::speculative_trap_data_tag: {
1727       SpeculativeTrapData* data = new SpeculativeTrapData(dp);
1728       Method* m = data-&gt;method();
1729       assert(m != NULL, &quot;should have a method&quot;);
1730       if (!cl-&gt;is_live(m)) {
1731         // &quot;shift&quot; accumulates the number of cells for dead
1732         // SpeculativeTrapData entries that have been seen so
1733         // far. Following entries must be shifted left by that many
1734         // cells to remove the dead SpeculativeTrapData entries.
1735         shift += (int)((intptr_t*)next_extra(dp) - (intptr_t*)dp);
1736       } else {
1737         // Shift this entry left if it follows dead
1738         // SpeculativeTrapData entries
1739         clean_extra_data_helper(dp, shift);
1740       }
1741       break;
1742     }
1743     case DataLayout::bit_data_tag:
1744       // Shift this entry left if it follows dead SpeculativeTrapData
1745       // entries
1746       clean_extra_data_helper(dp, shift);
1747       continue;
1748     case DataLayout::no_tag:
1749     case DataLayout::arg_info_data_tag:
1750       // We are at end of the live trap entries. The previous &quot;shift&quot;
1751       // cells contain entries that are either dead or were shifted
1752       // left. They need to be reset to no_tag
1753       clean_extra_data_helper(dp, shift, true);
1754       return;
1755     default:
1756       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1757     }
1758   }
1759 }
1760 
1761 // Verify there&#39;s no unloaded or redefined method referenced by a
1762 // SpeculativeTrapData entry
1763 void MethodData::verify_extra_data_clean(CleanExtraDataClosure* cl) {
1764 #ifdef ASSERT
1765   DataLayout* dp  = extra_data_base();
1766   DataLayout* end = args_data_limit();
1767 
1768   for (; dp &lt; end; dp = next_extra(dp)) {
1769     switch(dp-&gt;tag()) {
1770     case DataLayout::speculative_trap_data_tag: {
1771       SpeculativeTrapData* data = new SpeculativeTrapData(dp);
1772       Method* m = data-&gt;method();
1773       assert(m != NULL &amp;&amp; cl-&gt;is_live(m), &quot;Method should exist&quot;);
1774       break;
1775     }
1776     case DataLayout::bit_data_tag:
1777       continue;
1778     case DataLayout::no_tag:
1779     case DataLayout::arg_info_data_tag:
1780       return;
1781     default:
1782       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1783     }
1784   }
1785 #endif
1786 }
1787 
1788 void MethodData::clean_method_data(bool always_clean) {
1789   ResourceMark rm;
1790   for (ProfileData* data = first_data();
1791        is_valid(data);
1792        data = next_data(data)) {
1793     data-&gt;clean_weak_klass_links(always_clean);
1794   }
1795   ParametersTypeData* parameters = parameters_type_data();
1796   if (parameters != NULL) {
1797     parameters-&gt;clean_weak_klass_links(always_clean);
1798   }
1799 
1800   CleanExtraDataKlassClosure cl(always_clean);
1801   clean_extra_data(&amp;cl);
1802   verify_extra_data_clean(&amp;cl);
1803 }
1804 
1805 // This is called during redefinition to clean all &quot;old&quot; redefined
1806 // methods out of MethodData for all methods.
1807 void MethodData::clean_weak_method_links() {
1808   ResourceMark rm;
1809   for (ProfileData* data = first_data();
1810        is_valid(data);
1811        data = next_data(data)) {
1812     data-&gt;clean_weak_method_links();
1813   }
1814 
1815   CleanExtraDataMethodClosure cl;
1816   clean_extra_data(&amp;cl);
1817   verify_extra_data_clean(&amp;cl);
1818 }
1819 
1820 #ifdef ASSERT
1821 void MethodData::verify_clean_weak_method_links() {
1822   ResourceMark rm;
1823   for (ProfileData* data = first_data();
1824        is_valid(data);
1825        data = next_data(data)) {
1826     data-&gt;verify_clean_weak_method_links();
1827   }
1828 
1829   CleanExtraDataMethodClosure cl;
1830   verify_extra_data_clean(&amp;cl);
1831 }
1832 #endif // ASSERT
    </pre>
  </body>
</html>