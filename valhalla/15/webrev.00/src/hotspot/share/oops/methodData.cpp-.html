<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/oops/methodData.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/systemDictionary.hpp&quot;
  27 #include &quot;compiler/compilationPolicy.hpp&quot;
  28 #include &quot;compiler/compilerOracle.hpp&quot;
  29 #include &quot;interpreter/bytecode.hpp&quot;
  30 #include &quot;interpreter/bytecodeStream.hpp&quot;
  31 #include &quot;interpreter/linkResolver.hpp&quot;
  32 #include &quot;memory/metaspaceClosure.hpp&quot;
  33 #include &quot;memory/resourceArea.hpp&quot;
  34 #include &quot;oops/methodData.inline.hpp&quot;
  35 #include &quot;prims/jvmtiRedefineClasses.hpp&quot;
  36 #include &quot;runtime/arguments.hpp&quot;
  37 #include &quot;runtime/atomic.hpp&quot;
  38 #include &quot;runtime/deoptimization.hpp&quot;
  39 #include &quot;runtime/handles.inline.hpp&quot;
  40 #include &quot;runtime/orderAccess.hpp&quot;
  41 #include &quot;runtime/safepointVerifiers.hpp&quot;
  42 #include &quot;utilities/align.hpp&quot;
  43 #include &quot;utilities/copy.hpp&quot;
  44 
  45 // ==================================================================
  46 // DataLayout
  47 //
  48 // Overlay for generic profiling data.
  49 
  50 // Some types of data layouts need a length field.
  51 bool DataLayout::needs_array_len(u1 tag) {
  52   return (tag == multi_branch_data_tag) || (tag == arg_info_data_tag) || (tag == parameters_type_data_tag);
  53 }
  54 
  55 // Perform generic initialization of the data.  More specific
  56 // initialization occurs in overrides of ProfileData::post_initialize.
  57 void DataLayout::initialize(u1 tag, u2 bci, int cell_count) {
  58   _header._bits = (intptr_t)0;
  59   _header._struct._tag = tag;
  60   _header._struct._bci = bci;
  61   for (int i = 0; i &lt; cell_count; i++) {
  62     set_cell_at(i, (intptr_t)0);
  63   }
  64   if (needs_array_len(tag)) {
  65     set_cell_at(ArrayData::array_len_off_set, cell_count - 1); // -1 for header.
  66   }
  67   if (tag == call_type_data_tag) {
  68     CallTypeData::initialize(this, cell_count);
  69   } else if (tag == virtual_call_type_data_tag) {
  70     VirtualCallTypeData::initialize(this, cell_count);
  71   }
  72 }
  73 
  74 void DataLayout::clean_weak_klass_links(bool always_clean) {
  75   ResourceMark m;
  76   data_in()-&gt;clean_weak_klass_links(always_clean);
  77 }
  78 
  79 
  80 // ==================================================================
  81 // ProfileData
  82 //
  83 // A ProfileData object is created to refer to a section of profiling
  84 // data in a structured way.
  85 
  86 // Constructor for invalid ProfileData.
  87 ProfileData::ProfileData() {
  88   _data = NULL;
  89 }
  90 
  91 char* ProfileData::print_data_on_helper(const MethodData* md) const {
  92   DataLayout* dp  = md-&gt;extra_data_base();
  93   DataLayout* end = md-&gt;args_data_limit();
  94   stringStream ss;
  95   for (;; dp = MethodData::next_extra(dp)) {
  96     assert(dp &lt; end, &quot;moved past end of extra data&quot;);
  97     switch(dp-&gt;tag()) {
  98     case DataLayout::speculative_trap_data_tag:
  99       if (dp-&gt;bci() == bci()) {
 100         SpeculativeTrapData* data = new SpeculativeTrapData(dp);
 101         int trap = data-&gt;trap_state();
 102         char buf[100];
 103         ss.print(&quot;trap/&quot;);
 104         data-&gt;method()-&gt;print_short_name(&amp;ss);
 105         ss.print(&quot;(%s) &quot;, Deoptimization::format_trap_state(buf, sizeof(buf), trap));
 106       }
 107       break;
 108     case DataLayout::bit_data_tag:
 109       break;
 110     case DataLayout::no_tag:
 111     case DataLayout::arg_info_data_tag:
 112       return ss.as_string();
 113       break;
 114     default:
 115       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
 116     }
 117   }
 118   return NULL;
 119 }
 120 
 121 void ProfileData::print_data_on(outputStream* st, const MethodData* md) const {
 122   print_data_on(st, print_data_on_helper(md));
 123 }
 124 
 125 void ProfileData::print_shared(outputStream* st, const char* name, const char* extra) const {
 126   st-&gt;print(&quot;bci: %d&quot;, bci());
 127   st-&gt;fill_to(tab_width_one);
 128   st-&gt;print(&quot;%s&quot;, name);
 129   tab(st);
 130   int trap = trap_state();
 131   if (trap != 0) {
 132     char buf[100];
 133     st-&gt;print(&quot;trap(%s) &quot;, Deoptimization::format_trap_state(buf, sizeof(buf), trap));
 134   }
 135   if (extra != NULL) {
 136     st-&gt;print(&quot;%s&quot;, extra);
 137   }
 138   int flags = data()-&gt;flags();
 139   if (flags != 0) {
 140     st-&gt;print(&quot;flags(%d) %p/%d&quot;, flags, data(), in_bytes(DataLayout::flags_offset()));
 141   }
 142 }
 143 
 144 void ProfileData::tab(outputStream* st, bool first) const {
 145   st-&gt;fill_to(first ? tab_width_one : tab_width_two);
 146 }
 147 
 148 // ==================================================================
 149 // BitData
 150 //
 151 // A BitData corresponds to a one-bit flag.  This is used to indicate
 152 // whether a checkcast bytecode has seen a null value.
 153 
 154 
 155 void BitData::print_data_on(outputStream* st, const char* extra) const {
 156   print_shared(st, &quot;BitData&quot;, extra);
 157   st-&gt;cr();
 158 }
 159 
 160 // ==================================================================
 161 // CounterData
 162 //
 163 // A CounterData corresponds to a simple counter.
 164 
 165 void CounterData::print_data_on(outputStream* st, const char* extra) const {
 166   print_shared(st, &quot;CounterData&quot;, extra);
 167   st-&gt;print_cr(&quot;count(%u)&quot;, count());
 168 }
 169 
 170 // ==================================================================
 171 // JumpData
 172 //
 173 // A JumpData is used to access profiling information for a direct
 174 // branch.  It is a counter, used for counting the number of branches,
 175 // plus a data displacement, used for realigning the data pointer to
 176 // the corresponding target bci.
 177 
 178 void JumpData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 179   assert(stream-&gt;bci() == bci(), &quot;wrong pos&quot;);
 180   int target;
 181   Bytecodes::Code c = stream-&gt;code();
 182   if (c == Bytecodes::_goto_w || c == Bytecodes::_jsr_w) {
 183     target = stream-&gt;dest_w();
 184   } else {
 185     target = stream-&gt;dest();
 186   }
 187   int my_di = mdo-&gt;dp_to_di(dp());
 188   int target_di = mdo-&gt;bci_to_di(target);
 189   int offset = target_di - my_di;
 190   set_displacement(offset);
 191 }
 192 
 193 void JumpData::print_data_on(outputStream* st, const char* extra) const {
 194   print_shared(st, &quot;JumpData&quot;, extra);
 195   st-&gt;print_cr(&quot;taken(%u) displacement(%d)&quot;, taken(), displacement());
 196 }
 197 
 198 int TypeStackSlotEntries::compute_cell_count(Symbol* signature, bool include_receiver, int max) {
 199   // Parameter profiling include the receiver
 200   int args_count = include_receiver ? 1 : 0;
 201   ResourceMark rm;
 202   ReferenceArgumentCount rac(signature);
 203   args_count += rac.count();
 204   args_count = MIN2(args_count, max);
 205   return args_count * per_arg_cell_count;
 206 }
 207 
 208 int TypeEntriesAtCall::compute_cell_count(BytecodeStream* stream) {
 209   assert(Bytecodes::is_invoke(stream-&gt;code()), &quot;should be invoke&quot;);
 210   assert(TypeStackSlotEntries::per_arg_count() &gt; SingleTypeEntry::static_cell_count(), &quot;code to test for arguments/results broken&quot;);
 211   const methodHandle m = stream-&gt;method();
 212   int bci = stream-&gt;bci();
 213   Bytecode_invoke inv(m, bci);
 214   int args_cell = 0;
 215   if (MethodData::profile_arguments_for_invoke(m, bci)) {
 216     args_cell = TypeStackSlotEntries::compute_cell_count(inv.signature(), false, TypeProfileArgsLimit);
 217   }
 218   int ret_cell = 0;
 219   if (MethodData::profile_return_for_invoke(m, bci) &amp;&amp; is_reference_type(inv.result_type())) {
 220     ret_cell = SingleTypeEntry::static_cell_count();
 221   }
 222   int header_cell = 0;
 223   if (args_cell + ret_cell &gt; 0) {
 224     header_cell = header_cell_count();
 225   }
 226 
 227   return header_cell + args_cell + ret_cell;
 228 }
 229 
 230 class ArgumentOffsetComputer : public SignatureIterator {
 231 private:
 232   int _max;
 233   int _offset;
 234   GrowableArray&lt;int&gt; _offsets;
 235 
 236   friend class SignatureIterator;  // so do_parameters_on can call do_type
 237   void do_type(BasicType type) {
 238     if (is_reference_type(type) &amp;&amp; _offsets.length() &lt; _max) {
 239       _offsets.push(_offset);
 240     }
 241     _offset += parameter_type_word_count(type);
 242   }
 243 
 244  public:
 245   ArgumentOffsetComputer(Symbol* signature, int max)
 246     : SignatureIterator(signature),
 247       _max(max), _offset(0),
 248       _offsets(Thread::current(), max) {
 249     do_parameters_on(this);  // non-virtual template execution
 250   }
 251 
 252   int off_at(int i) const { return _offsets.at(i); }
 253 };
 254 
 255 void TypeStackSlotEntries::post_initialize(Symbol* signature, bool has_receiver, bool include_receiver) {
 256   ResourceMark rm;
 257   int start = 0;
 258   // Parameter profiling include the receiver
 259   if (include_receiver &amp;&amp; has_receiver) {
 260     set_stack_slot(0, 0);
 261     set_type(0, type_none());
 262     start += 1;
 263   }
 264   ArgumentOffsetComputer aos(signature, _number_of_entries-start);
 265   for (int i = start; i &lt; _number_of_entries; i++) {
 266     set_stack_slot(i, aos.off_at(i-start) + (has_receiver ? 1 : 0));
 267     set_type(i, type_none());
 268   }
 269 }
 270 
 271 void CallTypeData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 272   assert(Bytecodes::is_invoke(stream-&gt;code()), &quot;should be invoke&quot;);
 273   Bytecode_invoke inv(stream-&gt;method(), stream-&gt;bci());
 274 
 275   if (has_arguments()) {
 276 #ifdef ASSERT
 277     ResourceMark rm;
 278     ReferenceArgumentCount rac(inv.signature());
 279     int count = MIN2(rac.count(), (int)TypeProfileArgsLimit);
 280     assert(count &gt; 0, &quot;room for args type but none found?&quot;);
 281     check_number_of_arguments(count);
 282 #endif
 283     _args.post_initialize(inv.signature(), inv.has_receiver(), false);
 284   }
 285 
 286   if (has_return()) {
 287     assert(is_reference_type(inv.result_type()), &quot;room for a ret type but doesn&#39;t return obj?&quot;);
 288     _ret.post_initialize();
 289   }
 290 }
 291 
 292 void VirtualCallTypeData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 293   assert(Bytecodes::is_invoke(stream-&gt;code()), &quot;should be invoke&quot;);
 294   Bytecode_invoke inv(stream-&gt;method(), stream-&gt;bci());
 295 
 296   if (has_arguments()) {
 297 #ifdef ASSERT
 298     ResourceMark rm;
 299     ReferenceArgumentCount rac(inv.signature());
 300     int count = MIN2(rac.count(), (int)TypeProfileArgsLimit);
 301     assert(count &gt; 0, &quot;room for args type but none found?&quot;);
 302     check_number_of_arguments(count);
 303 #endif
 304     _args.post_initialize(inv.signature(), inv.has_receiver(), false);
 305   }
 306 
 307   if (has_return()) {
 308     assert(is_reference_type(inv.result_type()), &quot;room for a ret type but doesn&#39;t return obj?&quot;);
 309     _ret.post_initialize();
 310   }
 311 }
 312 
 313 void TypeStackSlotEntries::clean_weak_klass_links(bool always_clean) {
 314   for (int i = 0; i &lt; _number_of_entries; i++) {
 315     intptr_t p = type(i);
 316     Klass* k = (Klass*)klass_part(p);
 317     if (k != NULL &amp;&amp; (always_clean || !k-&gt;is_loader_alive())) {
 318       set_type(i, with_status((Klass*)NULL, p));
 319     }
 320   }
 321 }
 322 
 323 void SingleTypeEntry::clean_weak_klass_links(bool always_clean) {
 324   intptr_t p = type();
 325   Klass* k = (Klass*)klass_part(p);
 326   if (k != NULL &amp;&amp; (always_clean || !k-&gt;is_loader_alive())) {
 327     set_type(with_status((Klass*)NULL, p));
 328   }
 329 }
 330 
 331 bool TypeEntriesAtCall::return_profiling_enabled() {
 332   return MethodData::profile_return();
 333 }
 334 
 335 bool TypeEntriesAtCall::arguments_profiling_enabled() {
 336   return MethodData::profile_arguments();
 337 }
 338 
 339 void TypeEntries::print_klass(outputStream* st, intptr_t k) {
 340   if (is_type_none(k)) {
 341     st-&gt;print(&quot;none&quot;);
 342   } else if (is_type_unknown(k)) {
 343     st-&gt;print(&quot;unknown&quot;);
 344   } else {
 345     valid_klass(k)-&gt;print_value_on(st);
 346   }
 347   if (was_null_seen(k)) {
 348     st-&gt;print(&quot; (null seen)&quot;);
 349   }
 350 }
 351 
 352 void TypeStackSlotEntries::print_data_on(outputStream* st) const {
 353   for (int i = 0; i &lt; _number_of_entries; i++) {
 354     _pd-&gt;tab(st);
 355     st-&gt;print(&quot;%d: stack(%u) &quot;, i, stack_slot(i));
 356     print_klass(st, type(i));
 357     st-&gt;cr();
 358   }
 359 }
 360 
 361 void SingleTypeEntry::print_data_on(outputStream* st) const {
 362   _pd-&gt;tab(st);
 363   print_klass(st, type());
 364   st-&gt;cr();
 365 }
 366 
 367 void CallTypeData::print_data_on(outputStream* st, const char* extra) const {
 368   CounterData::print_data_on(st, extra);
 369   if (has_arguments()) {
 370     tab(st, true);
 371     st-&gt;print(&quot;argument types&quot;);
 372     _args.print_data_on(st);
 373   }
 374   if (has_return()) {
 375     tab(st, true);
 376     st-&gt;print(&quot;return type&quot;);
 377     _ret.print_data_on(st);
 378   }
 379 }
 380 
 381 void VirtualCallTypeData::print_data_on(outputStream* st, const char* extra) const {
 382   VirtualCallData::print_data_on(st, extra);
 383   if (has_arguments()) {
 384     tab(st, true);
 385     st-&gt;print(&quot;argument types&quot;);
 386     _args.print_data_on(st);
 387   }
 388   if (has_return()) {
 389     tab(st, true);
 390     st-&gt;print(&quot;return type&quot;);
 391     _ret.print_data_on(st);
 392   }
 393 }
 394 
 395 // ==================================================================
 396 // ReceiverTypeData
 397 //
 398 // A ReceiverTypeData is used to access profiling information about a
 399 // dynamic type check.  It consists of a counter which counts the total times
 400 // that the check is reached, and a series of (Klass*, count) pairs
 401 // which are used to store a type profile for the receiver of the check.
 402 
 403 void ReceiverTypeData::clean_weak_klass_links(bool always_clean) {
 404     for (uint row = 0; row &lt; row_limit(); row++) {
 405     Klass* p = receiver(row);
 406     if (p != NULL &amp;&amp; (always_clean || !p-&gt;is_loader_alive())) {
 407       clear_row(row);
 408     }
 409   }
 410 }
 411 
 412 #if INCLUDE_JVMCI
 413 void VirtualCallData::clean_weak_klass_links(bool always_clean) {
 414   ReceiverTypeData::clean_weak_klass_links(always_clean);
 415   for (uint row = 0; row &lt; method_row_limit(); row++) {
 416     Method* p = method(row);
 417     if (p != NULL &amp;&amp; (always_clean || !p-&gt;method_holder()-&gt;is_loader_alive())) {
 418       clear_method_row(row);
 419     }
 420   }
 421 }
 422 
 423 void VirtualCallData::clean_weak_method_links() {
 424   ReceiverTypeData::clean_weak_method_links();
 425   for (uint row = 0; row &lt; method_row_limit(); row++) {
 426     Method* p = method(row);
 427     if (p != NULL &amp;&amp; p-&gt;is_old()) {
 428       clear_method_row(row);
 429     }
 430   }
 431 }
 432 #endif // INCLUDE_JVMCI
 433 
 434 void ReceiverTypeData::print_receiver_data_on(outputStream* st) const {
 435   uint row;
 436   int entries = 0;
 437   for (row = 0; row &lt; row_limit(); row++) {
 438     if (receiver(row) != NULL)  entries++;
 439   }
 440 #if INCLUDE_JVMCI
 441   st-&gt;print_cr(&quot;count(%u) nonprofiled_count(%u) entries(%u)&quot;, count(), nonprofiled_count(), entries);
 442 #else
 443   st-&gt;print_cr(&quot;count(%u) entries(%u)&quot;, count(), entries);
 444 #endif
 445   int total = count();
 446   for (row = 0; row &lt; row_limit(); row++) {
 447     if (receiver(row) != NULL) {
 448       total += receiver_count(row);
 449     }
 450   }
 451   for (row = 0; row &lt; row_limit(); row++) {
 452     if (receiver(row) != NULL) {
 453       tab(st);
 454       receiver(row)-&gt;print_value_on(st);
 455       st-&gt;print_cr(&quot;(%u %4.2f)&quot;, receiver_count(row), (float) receiver_count(row) / (float) total);
 456     }
 457   }
 458 }
 459 void ReceiverTypeData::print_data_on(outputStream* st, const char* extra) const {
 460   print_shared(st, &quot;ReceiverTypeData&quot;, extra);
 461   print_receiver_data_on(st);
 462 }
 463 
 464 #if INCLUDE_JVMCI
 465 void VirtualCallData::print_method_data_on(outputStream* st) const {
 466   uint row;
 467   int entries = 0;
 468   for (row = 0; row &lt; method_row_limit(); row++) {
 469     if (method(row) != NULL) entries++;
 470   }
 471   tab(st);
 472   st-&gt;print_cr(&quot;method_entries(%u)&quot;, entries);
 473   int total = count();
 474   for (row = 0; row &lt; method_row_limit(); row++) {
 475     if (method(row) != NULL) {
 476       total += method_count(row);
 477     }
 478   }
 479   for (row = 0; row &lt; method_row_limit(); row++) {
 480     if (method(row) != NULL) {
 481       tab(st);
 482       method(row)-&gt;print_value_on(st);
 483       st-&gt;print_cr(&quot;(%u %4.2f)&quot;, method_count(row), (float) method_count(row) / (float) total);
 484     }
 485   }
 486 }
 487 #endif // INCLUDE_JVMCI
 488 
 489 void VirtualCallData::print_data_on(outputStream* st, const char* extra) const {
 490   print_shared(st, &quot;VirtualCallData&quot;, extra);
 491   print_receiver_data_on(st);
 492   print_method_data_on(st);
 493 }
 494 
 495 // ==================================================================
 496 // RetData
 497 //
 498 // A RetData is used to access profiling information for a ret bytecode.
 499 // It is composed of a count of the number of times that the ret has
 500 // been executed, followed by a series of triples of the form
 501 // (bci, count, di) which count the number of times that some bci was the
 502 // target of the ret and cache a corresponding displacement.
 503 
 504 void RetData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 505   for (uint row = 0; row &lt; row_limit(); row++) {
 506     set_bci_displacement(row, -1);
 507     set_bci(row, no_bci);
 508   }
 509   // release so other threads see a consistent state.  bci is used as
 510   // a valid flag for bci_displacement.
 511   OrderAccess::release();
 512 }
 513 
 514 // This routine needs to atomically update the RetData structure, so the
 515 // caller needs to hold the RetData_lock before it gets here.  Since taking
 516 // the lock can block (and allow GC) and since RetData is a ProfileData is a
 517 // wrapper around a derived oop, taking the lock in _this_ method will
 518 // basically cause the &#39;this&#39; pointer&#39;s _data field to contain junk after the
 519 // lock.  We require the caller to take the lock before making the ProfileData
 520 // structure.  Currently the only caller is InterpreterRuntime::update_mdp_for_ret
 521 address RetData::fixup_ret(int return_bci, MethodData* h_mdo) {
 522   // First find the mdp which corresponds to the return bci.
 523   address mdp = h_mdo-&gt;bci_to_dp(return_bci);
 524 
 525   // Now check to see if any of the cache slots are open.
 526   for (uint row = 0; row &lt; row_limit(); row++) {
 527     if (bci(row) == no_bci) {
 528       set_bci_displacement(row, mdp - dp());
 529       set_bci_count(row, DataLayout::counter_increment);
 530       // Barrier to ensure displacement is written before the bci; allows
 531       // the interpreter to read displacement without fear of race condition.
 532       release_set_bci(row, return_bci);
 533       break;
 534     }
 535   }
 536   return mdp;
 537 }
 538 
 539 void RetData::print_data_on(outputStream* st, const char* extra) const {
 540   print_shared(st, &quot;RetData&quot;, extra);
 541   uint row;
 542   int entries = 0;
 543   for (row = 0; row &lt; row_limit(); row++) {
 544     if (bci(row) != no_bci)  entries++;
 545   }
 546   st-&gt;print_cr(&quot;count(%u) entries(%u)&quot;, count(), entries);
 547   for (row = 0; row &lt; row_limit(); row++) {
 548     if (bci(row) != no_bci) {
 549       tab(st);
 550       st-&gt;print_cr(&quot;bci(%d: count(%u) displacement(%d))&quot;,
 551                    bci(row), bci_count(row), bci_displacement(row));
 552     }
 553   }
 554 }
 555 
 556 // ==================================================================
 557 // BranchData
 558 //
 559 // A BranchData is used to access profiling data for a two-way branch.
 560 // It consists of taken and not_taken counts as well as a data displacement
 561 // for the taken case.
 562 
 563 void BranchData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 564   assert(stream-&gt;bci() == bci(), &quot;wrong pos&quot;);
 565   int target = stream-&gt;dest();
 566   int my_di = mdo-&gt;dp_to_di(dp());
 567   int target_di = mdo-&gt;bci_to_di(target);
 568   int offset = target_di - my_di;
 569   set_displacement(offset);
 570 }
 571 
 572 void BranchData::print_data_on(outputStream* st, const char* extra) const {
 573   print_shared(st, &quot;BranchData&quot;, extra);
 574   st-&gt;print_cr(&quot;taken(%u) displacement(%d)&quot;,
 575                taken(), displacement());
 576   tab(st);
 577   st-&gt;print_cr(&quot;not taken(%u)&quot;, not_taken());
 578 }
 579 
 580 // ==================================================================
 581 // MultiBranchData
 582 //
 583 // A MultiBranchData is used to access profiling information for
 584 // a multi-way branch (*switch bytecodes).  It consists of a series
 585 // of (count, displacement) pairs, which count the number of times each
 586 // case was taken and specify the data displacment for each branch target.
 587 
 588 int MultiBranchData::compute_cell_count(BytecodeStream* stream) {
 589   int cell_count = 0;
 590   if (stream-&gt;code() == Bytecodes::_tableswitch) {
 591     Bytecode_tableswitch sw(stream-&gt;method()(), stream-&gt;bcp());
 592     cell_count = 1 + per_case_cell_count * (1 + sw.length()); // 1 for default
 593   } else {
 594     Bytecode_lookupswitch sw(stream-&gt;method()(), stream-&gt;bcp());
 595     cell_count = 1 + per_case_cell_count * (sw.number_of_pairs() + 1); // 1 for default
 596   }
 597   return cell_count;
 598 }
 599 
 600 void MultiBranchData::post_initialize(BytecodeStream* stream,
 601                                       MethodData* mdo) {
 602   assert(stream-&gt;bci() == bci(), &quot;wrong pos&quot;);
 603   int target;
 604   int my_di;
 605   int target_di;
 606   int offset;
 607   if (stream-&gt;code() == Bytecodes::_tableswitch) {
 608     Bytecode_tableswitch sw(stream-&gt;method()(), stream-&gt;bcp());
 609     int len = sw.length();
 610     assert(array_len() == per_case_cell_count * (len + 1), &quot;wrong len&quot;);
 611     for (int count = 0; count &lt; len; count++) {
 612       target = sw.dest_offset_at(count) + bci();
 613       my_di = mdo-&gt;dp_to_di(dp());
 614       target_di = mdo-&gt;bci_to_di(target);
 615       offset = target_di - my_di;
 616       set_displacement_at(count, offset);
 617     }
 618     target = sw.default_offset() + bci();
 619     my_di = mdo-&gt;dp_to_di(dp());
 620     target_di = mdo-&gt;bci_to_di(target);
 621     offset = target_di - my_di;
 622     set_default_displacement(offset);
 623 
 624   } else {
 625     Bytecode_lookupswitch sw(stream-&gt;method()(), stream-&gt;bcp());
 626     int npairs = sw.number_of_pairs();
 627     assert(array_len() == per_case_cell_count * (npairs + 1), &quot;wrong len&quot;);
 628     for (int count = 0; count &lt; npairs; count++) {
 629       LookupswitchPair pair = sw.pair_at(count);
 630       target = pair.offset() + bci();
 631       my_di = mdo-&gt;dp_to_di(dp());
 632       target_di = mdo-&gt;bci_to_di(target);
 633       offset = target_di - my_di;
 634       set_displacement_at(count, offset);
 635     }
 636     target = sw.default_offset() + bci();
 637     my_di = mdo-&gt;dp_to_di(dp());
 638     target_di = mdo-&gt;bci_to_di(target);
 639     offset = target_di - my_di;
 640     set_default_displacement(offset);
 641   }
 642 }
 643 
 644 void MultiBranchData::print_data_on(outputStream* st, const char* extra) const {
 645   print_shared(st, &quot;MultiBranchData&quot;, extra);
 646   st-&gt;print_cr(&quot;default_count(%u) displacement(%d)&quot;,
 647                default_count(), default_displacement());
 648   int cases = number_of_cases();
 649   for (int i = 0; i &lt; cases; i++) {
 650     tab(st);
 651     st-&gt;print_cr(&quot;count(%u) displacement(%d)&quot;,
 652                  count_at(i), displacement_at(i));
 653   }
 654 }
 655 
 656 void ArgInfoData::print_data_on(outputStream* st, const char* extra) const {
 657   print_shared(st, &quot;ArgInfoData&quot;, extra);
 658   int nargs = number_of_args();
 659   for (int i = 0; i &lt; nargs; i++) {
 660     st-&gt;print(&quot;  0x%x&quot;, arg_modified(i));
 661   }
 662   st-&gt;cr();
 663 }
 664 
 665 int ParametersTypeData::compute_cell_count(Method* m) {
 666   if (!MethodData::profile_parameters_for_method(methodHandle(Thread::current(), m))) {
 667     return 0;
 668   }
 669   int max = TypeProfileParmsLimit == -1 ? INT_MAX : TypeProfileParmsLimit;
 670   int obj_args = TypeStackSlotEntries::compute_cell_count(m-&gt;signature(), !m-&gt;is_static(), max);
 671   if (obj_args &gt; 0) {
 672     return obj_args + 1; // 1 cell for array len
 673   }
 674   return 0;
 675 }
 676 
 677 void ParametersTypeData::post_initialize(BytecodeStream* stream, MethodData* mdo) {
 678   _parameters.post_initialize(mdo-&gt;method()-&gt;signature(), !mdo-&gt;method()-&gt;is_static(), true);
 679 }
 680 
 681 bool ParametersTypeData::profiling_enabled() {
 682   return MethodData::profile_parameters();
 683 }
 684 
 685 void ParametersTypeData::print_data_on(outputStream* st, const char* extra) const {
 686   st-&gt;print(&quot;parameter types&quot;); // FIXME extra ignored?
 687   _parameters.print_data_on(st);
 688 }
 689 
 690 void SpeculativeTrapData::print_data_on(outputStream* st, const char* extra) const {
 691   print_shared(st, &quot;SpeculativeTrapData&quot;, extra);
 692   tab(st);
 693   method()-&gt;print_short_name(st);
 694   st-&gt;cr();
 695 }
 696 
 697 void ArrayLoadStoreData::print_data_on(outputStream* st, const char* extra) const {
 698   print_shared(st, &quot;ArrayLoadStore&quot;, extra);
 699   st-&gt;cr();
 700   tab(st, true);
 701   st-&gt;print(&quot;array&quot;);
 702   _array.print_data_on(st);
 703   tab(st, true);
 704   st-&gt;print(&quot;element&quot;);
 705   _element.print_data_on(st);
 706 }
 707 
 708 // ==================================================================
 709 // MethodData*
 710 //
 711 // A MethodData* holds information which has been collected about
 712 // a method.
 713 
 714 MethodData* MethodData::allocate(ClassLoaderData* loader_data, const methodHandle&amp; method, TRAPS) {
 715   int size = MethodData::compute_allocation_size_in_words(method);
 716 
 717   return new (loader_data, size, MetaspaceObj::MethodDataType, THREAD)
 718     MethodData(method, size, THREAD);
 719 }
 720 
 721 int MethodData::bytecode_cell_count(Bytecodes::Code code) {
 722   if (is_client_compilation_mode_vm()) {
 723     return no_profile_data;
 724   }
 725   switch (code) {
 726   case Bytecodes::_checkcast:
 727   case Bytecodes::_instanceof:
 728     if (TypeProfileCasts) {
 729       return ReceiverTypeData::static_cell_count();
 730     } else {
 731       return BitData::static_cell_count();
 732     }
 733   case Bytecodes::_aaload:
 734   case Bytecodes::_aastore:
 735     return ArrayLoadStoreData::static_cell_count();
 736   case Bytecodes::_invokespecial:
 737   case Bytecodes::_invokestatic:
 738     if (MethodData::profile_arguments() || MethodData::profile_return()) {
 739       return variable_cell_count;
 740     } else {
 741       return CounterData::static_cell_count();
 742     }
 743   case Bytecodes::_goto:
 744   case Bytecodes::_goto_w:
 745   case Bytecodes::_jsr:
 746   case Bytecodes::_jsr_w:
 747     return JumpData::static_cell_count();
 748   case Bytecodes::_invokevirtual:
 749   case Bytecodes::_invokeinterface:
 750     if (MethodData::profile_arguments() || MethodData::profile_return()) {
 751       return variable_cell_count;
 752     } else {
 753       return VirtualCallData::static_cell_count();
 754     }
 755   case Bytecodes::_invokedynamic:
 756     if (MethodData::profile_arguments() || MethodData::profile_return()) {
 757       return variable_cell_count;
 758     } else {
 759       return CounterData::static_cell_count();
 760     }
 761   case Bytecodes::_ret:
 762     return RetData::static_cell_count();
 763   case Bytecodes::_ifeq:
 764   case Bytecodes::_ifne:
 765   case Bytecodes::_iflt:
 766   case Bytecodes::_ifge:
 767   case Bytecodes::_ifgt:
 768   case Bytecodes::_ifle:
 769   case Bytecodes::_if_icmpeq:
 770   case Bytecodes::_if_icmpne:
 771   case Bytecodes::_if_icmplt:
 772   case Bytecodes::_if_icmpge:
 773   case Bytecodes::_if_icmpgt:
 774   case Bytecodes::_if_icmple:
 775   case Bytecodes::_if_acmpeq:
 776   case Bytecodes::_if_acmpne:
 777   case Bytecodes::_ifnull:
 778   case Bytecodes::_ifnonnull:
 779     return BranchData::static_cell_count();
 780   case Bytecodes::_lookupswitch:
 781   case Bytecodes::_tableswitch:
 782     return variable_cell_count;
 783   default:
 784     return no_profile_data;
 785   }
 786 }
 787 
 788 // Compute the size of the profiling information corresponding to
 789 // the current bytecode.
 790 int MethodData::compute_data_size(BytecodeStream* stream) {
 791   int cell_count = bytecode_cell_count(stream-&gt;code());
 792   if (cell_count == no_profile_data) {
 793     return 0;
 794   }
 795   if (cell_count == variable_cell_count) {
 796     switch (stream-&gt;code()) {
 797     case Bytecodes::_lookupswitch:
 798     case Bytecodes::_tableswitch:
 799       cell_count = MultiBranchData::compute_cell_count(stream);
 800       break;
 801     case Bytecodes::_invokespecial:
 802     case Bytecodes::_invokestatic:
 803     case Bytecodes::_invokedynamic:
 804       assert(MethodData::profile_arguments() || MethodData::profile_return(), &quot;should be collecting args profile&quot;);
 805       if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
 806           profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
 807         cell_count = CallTypeData::compute_cell_count(stream);
 808       } else {
 809         cell_count = CounterData::static_cell_count();
 810       }
 811       break;
 812     case Bytecodes::_invokevirtual:
 813     case Bytecodes::_invokeinterface: {
 814       assert(MethodData::profile_arguments() || MethodData::profile_return(), &quot;should be collecting args profile&quot;);
 815       if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
 816           profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
 817         cell_count = VirtualCallTypeData::compute_cell_count(stream);
 818       } else {
 819         cell_count = VirtualCallData::static_cell_count();
 820       }
 821       break;
 822     }
 823     default:
 824       fatal(&quot;unexpected bytecode for var length profile data&quot;);
 825     }
 826   }
 827   // Note:  cell_count might be zero, meaning that there is just
 828   //        a DataLayout header, with no extra cells.
 829   assert(cell_count &gt;= 0, &quot;sanity&quot;);
 830   return DataLayout::compute_size_in_bytes(cell_count);
 831 }
 832 
 833 bool MethodData::is_speculative_trap_bytecode(Bytecodes::Code code) {
 834   // Bytecodes for which we may use speculation
 835   switch (code) {
 836   case Bytecodes::_checkcast:
 837   case Bytecodes::_instanceof:
 838   case Bytecodes::_aaload:
 839   case Bytecodes::_aastore:
 840   case Bytecodes::_invokevirtual:
 841   case Bytecodes::_invokeinterface:
 842   case Bytecodes::_if_acmpeq:
 843   case Bytecodes::_if_acmpne:
 844   case Bytecodes::_ifnull:
 845   case Bytecodes::_ifnonnull:
 846   case Bytecodes::_invokestatic:
 847 #ifdef COMPILER2
 848     if (is_server_compilation_mode_vm()) {
 849       return UseTypeSpeculation;
 850     }
 851 #endif
 852   default:
 853     return false;
 854   }
 855   return false;
 856 }
 857 
 858 #if INCLUDE_JVMCI
 859 
 860 void* FailedSpeculation::operator new(size_t size, size_t fs_size) throw() {
 861   return CHeapObj&lt;mtCompiler&gt;::operator new(fs_size, std::nothrow);
 862 }
 863 
 864 FailedSpeculation::FailedSpeculation(address speculation, int speculation_len) : _data_len(speculation_len), _next(NULL) {
 865   memcpy(data(), speculation, speculation_len);
 866 }
 867 
 868 // A heuristic check to detect nmethods that outlive a failed speculations list.
 869 static void guarantee_failed_speculations_alive(nmethod* nm, FailedSpeculation** failed_speculations_address) {
 870   jlong head = (jlong)(address) *failed_speculations_address;
 871   if ((head &amp; 0x1) == 0x1) {
 872     stringStream st;
 873     if (nm != NULL) {
 874       st.print(&quot;%d&quot;, nm-&gt;compile_id());
 875       Method* method = nm-&gt;method();
 876       st.print_raw(&quot;{&quot;);
 877       if (method != NULL) {
 878         method-&gt;print_name(&amp;st);
 879       } else {
 880         const char* jvmci_name = nm-&gt;jvmci_name();
 881         if (jvmci_name != NULL) {
 882           st.print_raw(jvmci_name);
 883         }
 884       }
 885       st.print_raw(&quot;}&quot;);
 886     } else {
 887       st.print(&quot;&lt;unknown&gt;&quot;);
 888     }
 889     fatal(&quot;Adding to failed speculations list that appears to have been freed. Source: %s&quot;, st.as_string());
 890   }
 891 }
 892 
 893 bool FailedSpeculation::add_failed_speculation(nmethod* nm, FailedSpeculation** failed_speculations_address, address speculation, int speculation_len) {
 894   assert(failed_speculations_address != NULL, &quot;must be&quot;);
 895   size_t fs_size = sizeof(FailedSpeculation) + speculation_len;
 896   FailedSpeculation* fs = new (fs_size) FailedSpeculation(speculation, speculation_len);
 897   if (fs == NULL) {
 898     // no memory -&gt; ignore failed speculation
 899     return false;
 900   }
 901 
 902   guarantee(is_aligned(fs, sizeof(FailedSpeculation*)), &quot;FailedSpeculation objects must be pointer aligned&quot;);
 903   guarantee_failed_speculations_alive(nm, failed_speculations_address);
 904 
 905   FailedSpeculation** cursor = failed_speculations_address;
 906   do {
 907     if (*cursor == NULL) {
 908       FailedSpeculation* old_fs = Atomic::cmpxchg(cursor, (FailedSpeculation*) NULL, fs);
 909       if (old_fs == NULL) {
 910         // Successfully appended fs to end of the list
 911         return true;
 912       }
 913       cursor = old_fs-&gt;next_adr();
 914     } else {
 915       cursor = (*cursor)-&gt;next_adr();
 916     }
 917   } while (true);
 918 }
 919 
 920 void FailedSpeculation::free_failed_speculations(FailedSpeculation** failed_speculations_address) {
 921   assert(failed_speculations_address != NULL, &quot;must be&quot;);
 922   FailedSpeculation* fs = *failed_speculations_address;
 923   while (fs != NULL) {
 924     FailedSpeculation* next = fs-&gt;next();
 925     delete fs;
 926     fs = next;
 927   }
 928 
 929   // Write an unaligned value to failed_speculations_address to denote
 930   // that it is no longer a valid pointer. This is allows for the check
 931   // in add_failed_speculation against adding to a freed failed
 932   // speculations list.
 933   long* head = (long*) failed_speculations_address;
 934   (*head) = (*head) | 0x1;
 935 }
 936 #endif // INCLUDE_JVMCI
 937 
 938 int MethodData::compute_extra_data_count(int data_size, int empty_bc_count, bool needs_speculative_traps) {
 939 #if INCLUDE_JVMCI
 940   if (ProfileTraps) {
 941     // Assume that up to 30% of the possibly trapping BCIs with no MDP will need to allocate one.
 942     int extra_data_count = MIN2(empty_bc_count, MAX2(4, (empty_bc_count * 30) / 100));
 943 
 944     // Make sure we have a minimum number of extra data slots to
 945     // allocate SpeculativeTrapData entries. We would want to have one
 946     // entry per compilation that inlines this method and for which
 947     // some type speculation assumption fails. So the room we need for
 948     // the SpeculativeTrapData entries doesn&#39;t directly depend on the
 949     // size of the method. Because it&#39;s hard to estimate, we reserve
 950     // space for an arbitrary number of entries.
 951     int spec_data_count = (needs_speculative_traps ? SpecTrapLimitExtraEntries : 0) *
 952       (SpeculativeTrapData::static_cell_count() + DataLayout::header_size_in_cells());
 953 
 954     return MAX2(extra_data_count, spec_data_count);
 955   } else {
 956     return 0;
 957   }
 958 #else // INCLUDE_JVMCI
 959   if (ProfileTraps) {
 960     // Assume that up to 3% of BCIs with no MDP will need to allocate one.
 961     int extra_data_count = (uint)(empty_bc_count * 3) / 128 + 1;
 962     // If the method is large, let the extra BCIs grow numerous (to ~1%).
 963     int one_percent_of_data
 964       = (uint)data_size / (DataLayout::header_size_in_bytes()*128);
 965     if (extra_data_count &lt; one_percent_of_data)
 966       extra_data_count = one_percent_of_data;
 967     if (extra_data_count &gt; empty_bc_count)
 968       extra_data_count = empty_bc_count;  // no need for more
 969 
 970     // Make sure we have a minimum number of extra data slots to
 971     // allocate SpeculativeTrapData entries. We would want to have one
 972     // entry per compilation that inlines this method and for which
 973     // some type speculation assumption fails. So the room we need for
 974     // the SpeculativeTrapData entries doesn&#39;t directly depend on the
 975     // size of the method. Because it&#39;s hard to estimate, we reserve
 976     // space for an arbitrary number of entries.
 977     int spec_data_count = (needs_speculative_traps ? SpecTrapLimitExtraEntries : 0) *
 978       (SpeculativeTrapData::static_cell_count() + DataLayout::header_size_in_cells());
 979 
 980     return MAX2(extra_data_count, spec_data_count);
 981   } else {
 982     return 0;
 983   }
 984 #endif // INCLUDE_JVMCI
 985 }
 986 
 987 // Compute the size of the MethodData* necessary to store
 988 // profiling information about a given method.  Size is in bytes.
 989 int MethodData::compute_allocation_size_in_bytes(const methodHandle&amp; method) {
 990   int data_size = 0;
 991   BytecodeStream stream(method);
 992   Bytecodes::Code c;
 993   int empty_bc_count = 0;  // number of bytecodes lacking data
 994   bool needs_speculative_traps = false;
 995   while ((c = stream.next()) &gt;= 0) {
 996     int size_in_bytes = compute_data_size(&amp;stream);
 997     data_size += size_in_bytes;
 998     if (size_in_bytes == 0 JVMCI_ONLY(&amp;&amp; Bytecodes::can_trap(c)))  empty_bc_count += 1;
 999     needs_speculative_traps = needs_speculative_traps || is_speculative_trap_bytecode(c);
1000   }
1001   int object_size = in_bytes(data_offset()) + data_size;
1002 
1003   // Add some extra DataLayout cells (at least one) to track stray traps.
1004   int extra_data_count = compute_extra_data_count(data_size, empty_bc_count, needs_speculative_traps);
1005   object_size += extra_data_count * DataLayout::compute_size_in_bytes(0);
1006 
1007   // Add a cell to record information about modified arguments.
1008   int arg_size = method-&gt;size_of_parameters();
1009   object_size += DataLayout::compute_size_in_bytes(arg_size+1);
1010 
1011   // Reserve room for an area of the MDO dedicated to profiling of
1012   // parameters
1013   int args_cell = ParametersTypeData::compute_cell_count(method());
1014   if (args_cell &gt; 0) {
1015     object_size += DataLayout::compute_size_in_bytes(args_cell);
1016   }
1017   return object_size;
1018 }
1019 
1020 // Compute the size of the MethodData* necessary to store
1021 // profiling information about a given method.  Size is in words
1022 int MethodData::compute_allocation_size_in_words(const methodHandle&amp; method) {
1023   int byte_size = compute_allocation_size_in_bytes(method);
1024   int word_size = align_up(byte_size, BytesPerWord) / BytesPerWord;
1025   return align_metadata_size(word_size);
1026 }
1027 
1028 // Initialize an individual data segment.  Returns the size of
1029 // the segment in bytes.
1030 int MethodData::initialize_data(BytecodeStream* stream,
1031                                        int data_index) {
1032   if (is_client_compilation_mode_vm()) {
1033     return 0;
1034   }
1035   int cell_count = -1;
1036   int tag = DataLayout::no_tag;
1037   DataLayout* data_layout = data_layout_at(data_index);
1038   Bytecodes::Code c = stream-&gt;code();
1039   switch (c) {
1040   case Bytecodes::_checkcast:
1041   case Bytecodes::_instanceof:
1042     if (TypeProfileCasts) {
1043       cell_count = ReceiverTypeData::static_cell_count();
1044       tag = DataLayout::receiver_type_data_tag;
1045     } else {
1046       cell_count = BitData::static_cell_count();
1047       tag = DataLayout::bit_data_tag;
1048     }
1049     break;
1050   case Bytecodes::_aaload:
1051   case Bytecodes::_aastore:
1052     cell_count = ArrayLoadStoreData::static_cell_count();
1053     tag = DataLayout::array_load_store_data_tag;
1054     break;
1055   case Bytecodes::_invokespecial:
1056   case Bytecodes::_invokestatic: {
1057     int counter_data_cell_count = CounterData::static_cell_count();
1058     if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
1059         profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
1060       cell_count = CallTypeData::compute_cell_count(stream);
1061     } else {
1062       cell_count = counter_data_cell_count;
1063     }
1064     if (cell_count &gt; counter_data_cell_count) {
1065       tag = DataLayout::call_type_data_tag;
1066     } else {
1067       tag = DataLayout::counter_data_tag;
1068     }
1069     break;
1070   }
1071   case Bytecodes::_goto:
1072   case Bytecodes::_goto_w:
1073   case Bytecodes::_jsr:
1074   case Bytecodes::_jsr_w:
1075     cell_count = JumpData::static_cell_count();
1076     tag = DataLayout::jump_data_tag;
1077     break;
1078   case Bytecodes::_invokevirtual:
1079   case Bytecodes::_invokeinterface: {
1080     int virtual_call_data_cell_count = VirtualCallData::static_cell_count();
1081     if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
1082         profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
1083       cell_count = VirtualCallTypeData::compute_cell_count(stream);
1084     } else {
1085       cell_count = virtual_call_data_cell_count;
1086     }
1087     if (cell_count &gt; virtual_call_data_cell_count) {
1088       tag = DataLayout::virtual_call_type_data_tag;
1089     } else {
1090       tag = DataLayout::virtual_call_data_tag;
1091     }
1092     break;
1093   }
1094   case Bytecodes::_invokedynamic: {
1095     // %%% should make a type profile for any invokedynamic that takes a ref argument
1096     int counter_data_cell_count = CounterData::static_cell_count();
1097     if (profile_arguments_for_invoke(stream-&gt;method(), stream-&gt;bci()) ||
1098         profile_return_for_invoke(stream-&gt;method(), stream-&gt;bci())) {
1099       cell_count = CallTypeData::compute_cell_count(stream);
1100     } else {
1101       cell_count = counter_data_cell_count;
1102     }
1103     if (cell_count &gt; counter_data_cell_count) {
1104       tag = DataLayout::call_type_data_tag;
1105     } else {
1106       tag = DataLayout::counter_data_tag;
1107     }
1108     break;
1109   }
1110   case Bytecodes::_ret:
1111     cell_count = RetData::static_cell_count();
1112     tag = DataLayout::ret_data_tag;
1113     break;
1114   case Bytecodes::_ifeq:
1115   case Bytecodes::_ifne:
1116   case Bytecodes::_iflt:
1117   case Bytecodes::_ifge:
1118   case Bytecodes::_ifgt:
1119   case Bytecodes::_ifle:
1120   case Bytecodes::_if_icmpeq:
1121   case Bytecodes::_if_icmpne:
1122   case Bytecodes::_if_icmplt:
1123   case Bytecodes::_if_icmpge:
1124   case Bytecodes::_if_icmpgt:
1125   case Bytecodes::_if_icmple:
1126   case Bytecodes::_if_acmpeq:
1127   case Bytecodes::_if_acmpne:
1128   case Bytecodes::_ifnull:
1129   case Bytecodes::_ifnonnull:
1130     cell_count = BranchData::static_cell_count();
1131     tag = DataLayout::branch_data_tag;
1132     break;
1133   case Bytecodes::_lookupswitch:
1134   case Bytecodes::_tableswitch:
1135     cell_count = MultiBranchData::compute_cell_count(stream);
1136     tag = DataLayout::multi_branch_data_tag;
1137     break;
1138   default:
1139     break;
1140   }
1141   assert(tag == DataLayout::multi_branch_data_tag ||
1142          ((MethodData::profile_arguments() || MethodData::profile_return()) &amp;&amp;
1143           (tag == DataLayout::call_type_data_tag ||
1144            tag == DataLayout::counter_data_tag ||
1145            tag == DataLayout::virtual_call_type_data_tag ||
1146            tag == DataLayout::virtual_call_data_tag)) ||
1147          cell_count == bytecode_cell_count(c), &quot;cell counts must agree&quot;);
1148   if (cell_count &gt;= 0) {
1149     assert(tag != DataLayout::no_tag, &quot;bad tag&quot;);
1150     assert(bytecode_has_profile(c), &quot;agree w/ BHP&quot;);
1151     data_layout-&gt;initialize(tag, stream-&gt;bci(), cell_count);
1152     return DataLayout::compute_size_in_bytes(cell_count);
1153   } else {
1154     assert(!bytecode_has_profile(c), &quot;agree w/ !BHP&quot;);
1155     return 0;
1156   }
1157 }
1158 
1159 // Get the data at an arbitrary (sort of) data index.
1160 ProfileData* MethodData::data_at(int data_index) const {
1161   if (out_of_bounds(data_index)) {
1162     return NULL;
1163   }
1164   DataLayout* data_layout = data_layout_at(data_index);
1165   return data_layout-&gt;data_in();
1166 }
1167 
1168 ProfileData* DataLayout::data_in() {
1169   switch (tag()) {
1170   case DataLayout::no_tag:
1171   default:
1172     ShouldNotReachHere();
1173     return NULL;
1174   case DataLayout::bit_data_tag:
1175     return new BitData(this);
1176   case DataLayout::counter_data_tag:
1177     return new CounterData(this);
1178   case DataLayout::jump_data_tag:
1179     return new JumpData(this);
1180   case DataLayout::receiver_type_data_tag:
1181     return new ReceiverTypeData(this);
1182   case DataLayout::virtual_call_data_tag:
1183     return new VirtualCallData(this);
1184   case DataLayout::ret_data_tag:
1185     return new RetData(this);
1186   case DataLayout::branch_data_tag:
1187     return new BranchData(this);
1188   case DataLayout::multi_branch_data_tag:
1189     return new MultiBranchData(this);
1190   case DataLayout::arg_info_data_tag:
1191     return new ArgInfoData(this);
1192   case DataLayout::call_type_data_tag:
1193     return new CallTypeData(this);
1194   case DataLayout::virtual_call_type_data_tag:
1195     return new VirtualCallTypeData(this);
1196   case DataLayout::parameters_type_data_tag:
1197     return new ParametersTypeData(this);
1198   case DataLayout::speculative_trap_data_tag:
1199     return new SpeculativeTrapData(this);
1200   case DataLayout::array_load_store_data_tag:
1201     return new ArrayLoadStoreData(this);
1202   }
1203 }
1204 
1205 // Iteration over data.
1206 ProfileData* MethodData::next_data(ProfileData* current) const {
1207   int current_index = dp_to_di(current-&gt;dp());
1208   int next_index = current_index + current-&gt;size_in_bytes();
1209   ProfileData* next = data_at(next_index);
1210   return next;
1211 }
1212 
1213 // Give each of the data entries a chance to perform specific
1214 // data initialization.
1215 void MethodData::post_initialize(BytecodeStream* stream) {
1216   ResourceMark rm;
1217   ProfileData* data;
1218   for (data = first_data(); is_valid(data); data = next_data(data)) {
1219     stream-&gt;set_start(data-&gt;bci());
1220     stream-&gt;next();
1221     data-&gt;post_initialize(stream, this);
1222   }
1223   if (_parameters_type_data_di != no_parameters) {
1224     parameters_type_data()-&gt;post_initialize(NULL, this);
1225   }
1226 }
1227 
1228 // Initialize the MethodData* corresponding to a given method.
1229 MethodData::MethodData(const methodHandle&amp; method, int size, TRAPS)
1230   : _extra_data_lock(Mutex::leaf, &quot;MDO extra data lock&quot;),
1231     _parameters_type_data_di(parameters_uninitialized) {
1232   // Set the method back-pointer.
1233   _method = method();
1234   initialize();
1235 }
1236 
1237 void MethodData::initialize() {
1238   Thread* thread = Thread::current();
1239   NoSafepointVerifier no_safepoint;  // init function atomic wrt GC
1240   ResourceMark rm(thread);
1241 
1242   init();
1243   set_creation_mileage(mileage_of(method()));
1244 
1245   // Go through the bytecodes and allocate and initialize the
1246   // corresponding data cells.
1247   int data_size = 0;
1248   int empty_bc_count = 0;  // number of bytecodes lacking data
1249   _data[0] = 0;  // apparently not set below.
1250   BytecodeStream stream(methodHandle(thread, method()));
1251   Bytecodes::Code c;
1252   bool needs_speculative_traps = false;
1253   while ((c = stream.next()) &gt;= 0) {
1254     int size_in_bytes = initialize_data(&amp;stream, data_size);
1255     data_size += size_in_bytes;
1256     if (size_in_bytes == 0 JVMCI_ONLY(&amp;&amp; Bytecodes::can_trap(c)))  empty_bc_count += 1;
1257     needs_speculative_traps = needs_speculative_traps || is_speculative_trap_bytecode(c);
1258   }
1259   _data_size = data_size;
1260   int object_size = in_bytes(data_offset()) + data_size;
1261 
1262   // Add some extra DataLayout cells (at least one) to track stray traps.
1263   int extra_data_count = compute_extra_data_count(data_size, empty_bc_count, needs_speculative_traps);
1264   int extra_size = extra_data_count * DataLayout::compute_size_in_bytes(0);
1265 
1266   // Let&#39;s zero the space for the extra data
1267   Copy::zero_to_bytes(((address)_data) + data_size, extra_size);
1268 
1269   // Add a cell to record information about modified arguments.
1270   // Set up _args_modified array after traps cells so that
1271   // the code for traps cells works.
1272   DataLayout *dp = data_layout_at(data_size + extra_size);
1273 
1274   int arg_size = method()-&gt;size_of_parameters();
1275   dp-&gt;initialize(DataLayout::arg_info_data_tag, 0, arg_size+1);
1276 
1277   int arg_data_size = DataLayout::compute_size_in_bytes(arg_size+1);
1278   object_size += extra_size + arg_data_size;
1279 
1280   int parms_cell = ParametersTypeData::compute_cell_count(method());
1281   // If we are profiling parameters, we reserver an area near the end
1282   // of the MDO after the slots for bytecodes (because there&#39;s no bci
1283   // for method entry so they don&#39;t fit with the framework for the
1284   // profiling of bytecodes). We store the offset within the MDO of
1285   // this area (or -1 if no parameter is profiled)
1286   if (parms_cell &gt; 0) {
1287     object_size += DataLayout::compute_size_in_bytes(parms_cell);
1288     _parameters_type_data_di = data_size + extra_size + arg_data_size;
1289     DataLayout *dp = data_layout_at(data_size + extra_size + arg_data_size);
1290     dp-&gt;initialize(DataLayout::parameters_type_data_tag, 0, parms_cell);
1291   } else {
1292     _parameters_type_data_di = no_parameters;
1293   }
1294 
1295   // Set an initial hint. Don&#39;t use set_hint_di() because
1296   // first_di() may be out of bounds if data_size is 0.
1297   // In that situation, _hint_di is never used, but at
1298   // least well-defined.
1299   _hint_di = first_di();
1300 
1301   post_initialize(&amp;stream);
1302 
1303   assert(object_size == compute_allocation_size_in_bytes(methodHandle(thread, _method)), &quot;MethodData: computed size != initialized size&quot;);
1304   set_size(object_size);
1305 }
1306 
1307 void MethodData::init() {
1308   _invocation_counter.init();
1309   _backedge_counter.init();
1310   _invocation_counter_start = 0;
1311   _backedge_counter_start = 0;
1312 
1313   // Set per-method invoke- and backedge mask.
1314   double scale = 1.0;
1315   methodHandle mh(Thread::current(), _method);
1316   CompilerOracle::has_option_value(mh, &quot;CompileThresholdScaling&quot;, scale);
1317   _invoke_mask = right_n_bits(CompilerConfig::scaled_freq_log(Tier0InvokeNotifyFreqLog, scale)) &lt;&lt; InvocationCounter::count_shift;
1318   _backedge_mask = right_n_bits(CompilerConfig::scaled_freq_log(Tier0BackedgeNotifyFreqLog, scale)) &lt;&lt; InvocationCounter::count_shift;
1319 
1320   _tenure_traps = 0;
1321   _num_loops = 0;
1322   _num_blocks = 0;
1323   _would_profile = unknown;
1324 
1325 #if INCLUDE_JVMCI
1326   _jvmci_ir_size = 0;
1327   _failed_speculations = NULL;
1328 #endif
1329 
1330 #if INCLUDE_RTM_OPT
1331   _rtm_state = NoRTM; // No RTM lock eliding by default
1332   if (UseRTMLocking &amp;&amp;
1333       !CompilerOracle::has_option_string(mh, &quot;NoRTMLockEliding&quot;)) {
1334     if (CompilerOracle::has_option_string(mh, &quot;UseRTMLockEliding&quot;) || !UseRTMDeopt) {
1335       // Generate RTM lock eliding code without abort ratio calculation code.
1336       _rtm_state = UseRTM;
1337     } else if (UseRTMDeopt) {
1338       // Generate RTM lock eliding code and include abort ratio calculation
1339       // code if UseRTMDeopt is on.
1340       _rtm_state = ProfileRTM;
1341     }
1342   }
1343 #endif
1344 
1345   // Initialize flags and trap history.
1346   _nof_decompiles = 0;
1347   _nof_overflow_recompiles = 0;
1348   _nof_overflow_traps = 0;
1349   clear_escape_info();
1350   assert(sizeof(_trap_hist) % sizeof(HeapWord) == 0, &quot;align&quot;);
1351   Copy::zero_to_words((HeapWord*) &amp;_trap_hist,
1352                       sizeof(_trap_hist) / sizeof(HeapWord));
1353 }
1354 
1355 // Get a measure of how much mileage the method has on it.
1356 int MethodData::mileage_of(Method* method) {
1357   int mileage = 0;
1358   if (TieredCompilation) {
1359     mileage = MAX2(method-&gt;invocation_count(), method-&gt;backedge_count());
1360   } else {
1361     int iic = method-&gt;interpreter_invocation_count();
1362     if (mileage &lt; iic)  mileage = iic;
1363     MethodCounters* mcs = method-&gt;method_counters();
1364     if (mcs != NULL) {
1365       InvocationCounter* ic = mcs-&gt;invocation_counter();
1366       InvocationCounter* bc = mcs-&gt;backedge_counter();
1367       int icval = ic-&gt;count();
1368       if (ic-&gt;carry()) icval += CompileThreshold;
1369       if (mileage &lt; icval)  mileage = icval;
1370       int bcval = bc-&gt;count();
1371       if (bc-&gt;carry()) bcval += CompileThreshold;
1372       if (mileage &lt; bcval)  mileage = bcval;
1373     }
1374   }
1375   return mileage;
1376 }
1377 
1378 bool MethodData::is_mature() const {
1379   return CompilationPolicy::policy()-&gt;is_mature(_method);
1380 }
1381 
1382 // Translate a bci to its corresponding data index (di).
1383 address MethodData::bci_to_dp(int bci) {
1384   ResourceMark rm;
1385   ProfileData* data = data_before(bci);
1386   ProfileData* prev = NULL;
1387   for ( ; is_valid(data); data = next_data(data)) {
1388     if (data-&gt;bci() &gt;= bci) {
1389       if (data-&gt;bci() == bci)  set_hint_di(dp_to_di(data-&gt;dp()));
1390       else if (prev != NULL)   set_hint_di(dp_to_di(prev-&gt;dp()));
1391       return data-&gt;dp();
1392     }
1393     prev = data;
1394   }
1395   return (address)limit_data_position();
1396 }
1397 
1398 // Translate a bci to its corresponding data, or NULL.
1399 ProfileData* MethodData::bci_to_data(int bci) {
1400   ProfileData* data = data_before(bci);
1401   for ( ; is_valid(data); data = next_data(data)) {
1402     if (data-&gt;bci() == bci) {
1403       set_hint_di(dp_to_di(data-&gt;dp()));
1404       return data;
1405     } else if (data-&gt;bci() &gt; bci) {
1406       break;
1407     }
1408   }
1409   return bci_to_extra_data(bci, NULL, false);
1410 }
1411 
1412 DataLayout* MethodData::next_extra(DataLayout* dp) {
1413   int nb_cells = 0;
1414   switch(dp-&gt;tag()) {
1415   case DataLayout::bit_data_tag:
1416   case DataLayout::no_tag:
1417     nb_cells = BitData::static_cell_count();
1418     break;
1419   case DataLayout::speculative_trap_data_tag:
1420     nb_cells = SpeculativeTrapData::static_cell_count();
1421     break;
1422   default:
1423     fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1424   }
1425   return (DataLayout*)((address)dp + DataLayout::compute_size_in_bytes(nb_cells));
1426 }
1427 
1428 ProfileData* MethodData::bci_to_extra_data_helper(int bci, Method* m, DataLayout*&amp; dp, bool concurrent) {
1429   DataLayout* end = args_data_limit();
1430 
1431   for (;; dp = next_extra(dp)) {
1432     assert(dp &lt; end, &quot;moved past end of extra data&quot;);
1433     // No need for &quot;Atomic::load_acquire&quot; ops,
1434     // since the data structure is monotonic.
1435     switch(dp-&gt;tag()) {
1436     case DataLayout::no_tag:
1437       return NULL;
1438     case DataLayout::arg_info_data_tag:
1439       dp = end;
1440       return NULL; // ArgInfoData is at the end of extra data section.
1441     case DataLayout::bit_data_tag:
1442       if (m == NULL &amp;&amp; dp-&gt;bci() == bci) {
1443         return new BitData(dp);
1444       }
1445       break;
1446     case DataLayout::speculative_trap_data_tag:
1447       if (m != NULL) {
1448         SpeculativeTrapData* data = new SpeculativeTrapData(dp);
1449         // data-&gt;method() may be null in case of a concurrent
1450         // allocation. Maybe it&#39;s for the same method. Try to use that
1451         // entry in that case.
1452         if (dp-&gt;bci() == bci) {
1453           if (data-&gt;method() == NULL) {
1454             assert(concurrent, &quot;impossible because no concurrent allocation&quot;);
1455             return NULL;
1456           } else if (data-&gt;method() == m) {
1457             return data;
1458           }
1459         }
1460       }
1461       break;
1462     default:
1463       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1464     }
1465   }
1466   return NULL;
1467 }
1468 
1469 
1470 // Translate a bci to its corresponding extra data, or NULL.
1471 ProfileData* MethodData::bci_to_extra_data(int bci, Method* m, bool create_if_missing) {
1472   // This code assumes an entry for a SpeculativeTrapData is 2 cells
1473   assert(2*DataLayout::compute_size_in_bytes(BitData::static_cell_count()) ==
1474          DataLayout::compute_size_in_bytes(SpeculativeTrapData::static_cell_count()),
1475          &quot;code needs to be adjusted&quot;);
1476 
1477   // Do not create one of these if method has been redefined.
1478   if (m != NULL &amp;&amp; m-&gt;is_old()) {
1479     return NULL;
1480   }
1481 
1482   DataLayout* dp  = extra_data_base();
1483   DataLayout* end = args_data_limit();
1484 
1485   // Allocation in the extra data space has to be atomic because not
1486   // all entries have the same size and non atomic concurrent
1487   // allocation would result in a corrupted extra data space.
1488   ProfileData* result = bci_to_extra_data_helper(bci, m, dp, true);
1489   if (result != NULL) {
1490     return result;
1491   }
1492 
1493   if (create_if_missing &amp;&amp; dp &lt; end) {
1494     MutexLocker ml(&amp;_extra_data_lock);
1495     // Check again now that we have the lock. Another thread may
1496     // have added extra data entries.
1497     ProfileData* result = bci_to_extra_data_helper(bci, m, dp, false);
1498     if (result != NULL || dp &gt;= end) {
1499       return result;
1500     }
1501 
1502     assert(dp-&gt;tag() == DataLayout::no_tag || (dp-&gt;tag() == DataLayout::speculative_trap_data_tag &amp;&amp; m != NULL), &quot;should be free&quot;);
1503     assert(next_extra(dp)-&gt;tag() == DataLayout::no_tag || next_extra(dp)-&gt;tag() == DataLayout::arg_info_data_tag, &quot;should be free or arg info&quot;);
1504     u1 tag = m == NULL ? DataLayout::bit_data_tag : DataLayout::speculative_trap_data_tag;
1505     // SpeculativeTrapData is 2 slots. Make sure we have room.
1506     if (m != NULL &amp;&amp; next_extra(dp)-&gt;tag() != DataLayout::no_tag) {
1507       return NULL;
1508     }
1509     DataLayout temp;
1510     temp.initialize(tag, bci, 0);
1511 
1512     dp-&gt;set_header(temp.header());
1513     assert(dp-&gt;tag() == tag, &quot;sane&quot;);
1514     assert(dp-&gt;bci() == bci, &quot;no concurrent allocation&quot;);
1515     if (tag == DataLayout::bit_data_tag) {
1516       return new BitData(dp);
1517     } else {
1518       SpeculativeTrapData* data = new SpeculativeTrapData(dp);
1519       data-&gt;set_method(m);
1520       return data;
1521     }
1522   }
1523   return NULL;
1524 }
1525 
1526 ArgInfoData *MethodData::arg_info() {
1527   DataLayout* dp    = extra_data_base();
1528   DataLayout* end   = args_data_limit();
1529   for (; dp &lt; end; dp = next_extra(dp)) {
1530     if (dp-&gt;tag() == DataLayout::arg_info_data_tag)
1531       return new ArgInfoData(dp);
1532   }
1533   return NULL;
1534 }
1535 
1536 // Printing
1537 
1538 void MethodData::print_on(outputStream* st) const {
1539   assert(is_methodData(), &quot;should be method data&quot;);
1540   st-&gt;print(&quot;method data for &quot;);
1541   method()-&gt;print_value_on(st);
1542   st-&gt;cr();
1543   print_data_on(st);
1544 }
1545 
1546 void MethodData::print_value_on(outputStream* st) const {
1547   assert(is_methodData(), &quot;should be method data&quot;);
1548   st-&gt;print(&quot;method data for &quot;);
1549   method()-&gt;print_value_on(st);
1550 }
1551 
1552 void MethodData::print_data_on(outputStream* st) const {
1553   ResourceMark rm;
1554   ProfileData* data = first_data();
1555   if (_parameters_type_data_di != no_parameters) {
1556     parameters_type_data()-&gt;print_data_on(st);
1557   }
1558   for ( ; is_valid(data); data = next_data(data)) {
1559     st-&gt;print(&quot;%d&quot;, dp_to_di(data-&gt;dp()));
1560     st-&gt;fill_to(6);
1561     data-&gt;print_data_on(st, this);
1562   }
1563   st-&gt;print_cr(&quot;--- Extra data:&quot;);
1564   DataLayout* dp    = extra_data_base();
1565   DataLayout* end   = args_data_limit();
1566   for (;; dp = next_extra(dp)) {
1567     assert(dp &lt; end, &quot;moved past end of extra data&quot;);
1568     // No need for &quot;Atomic::load_acquire&quot; ops,
1569     // since the data structure is monotonic.
1570     switch(dp-&gt;tag()) {
1571     case DataLayout::no_tag:
1572       continue;
1573     case DataLayout::bit_data_tag:
1574       data = new BitData(dp);
1575       break;
1576     case DataLayout::speculative_trap_data_tag:
1577       data = new SpeculativeTrapData(dp);
1578       break;
1579     case DataLayout::arg_info_data_tag:
1580       data = new ArgInfoData(dp);
1581       dp = end; // ArgInfoData is at the end of extra data section.
1582       break;
1583     default:
1584       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1585     }
1586     st-&gt;print(&quot;%d&quot;, dp_to_di(data-&gt;dp()));
1587     st-&gt;fill_to(6);
1588     data-&gt;print_data_on(st);
1589     if (dp &gt;= end) return;
1590   }
1591 }
1592 
1593 // Verification
1594 
1595 void MethodData::verify_on(outputStream* st) {
1596   guarantee(is_methodData(), &quot;object must be method data&quot;);
1597   // guarantee(m-&gt;is_perm(), &quot;should be in permspace&quot;);
1598   this-&gt;verify_data_on(st);
1599 }
1600 
1601 void MethodData::verify_data_on(outputStream* st) {
1602   NEEDS_CLEANUP;
1603   // not yet implemented.
1604 }
1605 
1606 bool MethodData::profile_jsr292(const methodHandle&amp; m, int bci) {
1607   if (m-&gt;is_compiled_lambda_form()) {
1608     return true;
1609   }
1610 
1611   Bytecode_invoke inv(m , bci);
1612   return inv.is_invokedynamic() || inv.is_invokehandle();
1613 }
1614 
1615 bool MethodData::profile_unsafe(const methodHandle&amp; m, int bci) {
1616   Bytecode_invoke inv(m , bci);
1617   if (inv.is_invokevirtual()) {
1618     if (inv.klass() == vmSymbols::jdk_internal_misc_Unsafe() ||
1619         inv.klass() == vmSymbols::sun_misc_Unsafe()) {
1620       ResourceMark rm;
1621       char* name = inv.name()-&gt;as_C_string();
1622       if (!strncmp(name, &quot;get&quot;, 3) || !strncmp(name, &quot;put&quot;, 3)) {
1623         return true;
1624       }
1625     }
1626   }
1627   return false;
1628 }
1629 
1630 int MethodData::profile_arguments_flag() {
1631   return TypeProfileLevel % 10;
1632 }
1633 
1634 bool MethodData::profile_arguments() {
1635   return profile_arguments_flag() &gt; no_type_profile &amp;&amp; profile_arguments_flag() &lt;= type_profile_all;
1636 }
1637 
1638 bool MethodData::profile_arguments_jsr292_only() {
1639   return profile_arguments_flag() == type_profile_jsr292;
1640 }
1641 
1642 bool MethodData::profile_all_arguments() {
1643   return profile_arguments_flag() == type_profile_all;
1644 }
1645 
1646 bool MethodData::profile_arguments_for_invoke(const methodHandle&amp; m, int bci) {
1647   if (!profile_arguments()) {
1648     return false;
1649   }
1650 
1651   if (profile_all_arguments()) {
1652     return true;
1653   }
1654 
1655   if (profile_unsafe(m, bci)) {
1656     return true;
1657   }
1658 
1659   assert(profile_arguments_jsr292_only(), &quot;inconsistent&quot;);
1660   return profile_jsr292(m, bci);
1661 }
1662 
1663 int MethodData::profile_return_flag() {
1664   return (TypeProfileLevel % 100) / 10;
1665 }
1666 
1667 bool MethodData::profile_return() {
1668   return profile_return_flag() &gt; no_type_profile &amp;&amp; profile_return_flag() &lt;= type_profile_all;
1669 }
1670 
1671 bool MethodData::profile_return_jsr292_only() {
1672   return profile_return_flag() == type_profile_jsr292;
1673 }
1674 
1675 bool MethodData::profile_all_return() {
1676   return profile_return_flag() == type_profile_all;
1677 }
1678 
1679 bool MethodData::profile_return_for_invoke(const methodHandle&amp; m, int bci) {
1680   if (!profile_return()) {
1681     return false;
1682   }
1683 
1684   if (profile_all_return()) {
1685     return true;
1686   }
1687 
1688   assert(profile_return_jsr292_only(), &quot;inconsistent&quot;);
1689   return profile_jsr292(m, bci);
1690 }
1691 
1692 int MethodData::profile_parameters_flag() {
1693   return TypeProfileLevel / 100;
1694 }
1695 
1696 bool MethodData::profile_parameters() {
1697   return profile_parameters_flag() &gt; no_type_profile &amp;&amp; profile_parameters_flag() &lt;= type_profile_all;
1698 }
1699 
1700 bool MethodData::profile_parameters_jsr292_only() {
1701   return profile_parameters_flag() == type_profile_jsr292;
1702 }
1703 
1704 bool MethodData::profile_all_parameters() {
1705   return profile_parameters_flag() == type_profile_all;
1706 }
1707 
1708 bool MethodData::profile_parameters_for_method(const methodHandle&amp; m) {
1709   if (!profile_parameters()) {
1710     return false;
1711   }
1712 
1713   if (profile_all_parameters()) {
1714     return true;
1715   }
1716 
1717   assert(profile_parameters_jsr292_only(), &quot;inconsistent&quot;);
1718   return m-&gt;is_compiled_lambda_form();
1719 }
1720 
1721 void MethodData::metaspace_pointers_do(MetaspaceClosure* it) {
1722   log_trace(cds)(&quot;Iter(MethodData): %p&quot;, this);
1723   it-&gt;push(&amp;_method);
1724 }
1725 
1726 void MethodData::clean_extra_data_helper(DataLayout* dp, int shift, bool reset) {
1727   if (shift == 0) {
1728     return;
1729   }
1730   if (!reset) {
1731     // Move all cells of trap entry at dp left by &quot;shift&quot; cells
1732     intptr_t* start = (intptr_t*)dp;
1733     intptr_t* end = (intptr_t*)next_extra(dp);
1734     for (intptr_t* ptr = start; ptr &lt; end; ptr++) {
1735       *(ptr-shift) = *ptr;
1736     }
1737   } else {
1738     // Reset &quot;shift&quot; cells stopping at dp
1739     intptr_t* start = ((intptr_t*)dp) - shift;
1740     intptr_t* end = (intptr_t*)dp;
1741     for (intptr_t* ptr = start; ptr &lt; end; ptr++) {
1742       *ptr = 0;
1743     }
1744   }
1745 }
1746 
1747 // Check for entries that reference an unloaded method
1748 class CleanExtraDataKlassClosure : public CleanExtraDataClosure {
1749   bool _always_clean;
1750 public:
1751   CleanExtraDataKlassClosure(bool always_clean) : _always_clean(always_clean) {}
1752   bool is_live(Method* m) {
1753     return !(_always_clean) &amp;&amp; m-&gt;method_holder()-&gt;is_loader_alive();
1754   }
1755 };
1756 
1757 // Check for entries that reference a redefined method
1758 class CleanExtraDataMethodClosure : public CleanExtraDataClosure {
1759 public:
1760   CleanExtraDataMethodClosure() {}
1761   bool is_live(Method* m) { return !m-&gt;is_old(); }
1762 };
1763 
1764 
1765 // Remove SpeculativeTrapData entries that reference an unloaded or
1766 // redefined method
1767 void MethodData::clean_extra_data(CleanExtraDataClosure* cl) {
1768   DataLayout* dp  = extra_data_base();
1769   DataLayout* end = args_data_limit();
1770 
1771   int shift = 0;
1772   for (; dp &lt; end; dp = next_extra(dp)) {
1773     switch(dp-&gt;tag()) {
1774     case DataLayout::speculative_trap_data_tag: {
1775       SpeculativeTrapData* data = new SpeculativeTrapData(dp);
1776       Method* m = data-&gt;method();
1777       assert(m != NULL, &quot;should have a method&quot;);
1778       if (!cl-&gt;is_live(m)) {
1779         // &quot;shift&quot; accumulates the number of cells for dead
1780         // SpeculativeTrapData entries that have been seen so
1781         // far. Following entries must be shifted left by that many
1782         // cells to remove the dead SpeculativeTrapData entries.
1783         shift += (int)((intptr_t*)next_extra(dp) - (intptr_t*)dp);
1784       } else {
1785         // Shift this entry left if it follows dead
1786         // SpeculativeTrapData entries
1787         clean_extra_data_helper(dp, shift);
1788       }
1789       break;
1790     }
1791     case DataLayout::bit_data_tag:
1792       // Shift this entry left if it follows dead SpeculativeTrapData
1793       // entries
1794       clean_extra_data_helper(dp, shift);
1795       continue;
1796     case DataLayout::no_tag:
1797     case DataLayout::arg_info_data_tag:
1798       // We are at end of the live trap entries. The previous &quot;shift&quot;
1799       // cells contain entries that are either dead or were shifted
1800       // left. They need to be reset to no_tag
1801       clean_extra_data_helper(dp, shift, true);
1802       return;
1803     default:
1804       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1805     }
1806   }
1807 }
1808 
1809 // Verify there&#39;s no unloaded or redefined method referenced by a
1810 // SpeculativeTrapData entry
1811 void MethodData::verify_extra_data_clean(CleanExtraDataClosure* cl) {
1812 #ifdef ASSERT
1813   DataLayout* dp  = extra_data_base();
1814   DataLayout* end = args_data_limit();
1815 
1816   for (; dp &lt; end; dp = next_extra(dp)) {
1817     switch(dp-&gt;tag()) {
1818     case DataLayout::speculative_trap_data_tag: {
1819       SpeculativeTrapData* data = new SpeculativeTrapData(dp);
1820       Method* m = data-&gt;method();
1821       assert(m != NULL &amp;&amp; cl-&gt;is_live(m), &quot;Method should exist&quot;);
1822       break;
1823     }
1824     case DataLayout::bit_data_tag:
1825       continue;
1826     case DataLayout::no_tag:
1827     case DataLayout::arg_info_data_tag:
1828       return;
1829     default:
1830       fatal(&quot;unexpected tag %d&quot;, dp-&gt;tag());
1831     }
1832   }
1833 #endif
1834 }
1835 
1836 void MethodData::clean_method_data(bool always_clean) {
1837   ResourceMark rm;
1838   for (ProfileData* data = first_data();
1839        is_valid(data);
1840        data = next_data(data)) {
1841     data-&gt;clean_weak_klass_links(always_clean);
1842   }
1843   ParametersTypeData* parameters = parameters_type_data();
1844   if (parameters != NULL) {
1845     parameters-&gt;clean_weak_klass_links(always_clean);
1846   }
1847 
1848   CleanExtraDataKlassClosure cl(always_clean);
1849   clean_extra_data(&amp;cl);
1850   verify_extra_data_clean(&amp;cl);
1851 }
1852 
1853 // This is called during redefinition to clean all &quot;old&quot; redefined
1854 // methods out of MethodData for all methods.
1855 void MethodData::clean_weak_method_links() {
1856   ResourceMark rm;
1857   for (ProfileData* data = first_data();
1858        is_valid(data);
1859        data = next_data(data)) {
1860     data-&gt;clean_weak_method_links();
1861   }
1862 
1863   CleanExtraDataMethodClosure cl;
1864   clean_extra_data(&amp;cl);
1865   verify_extra_data_clean(&amp;cl);
1866 }
1867 
1868 #ifdef ASSERT
1869 void MethodData::verify_clean_weak_method_links() {
1870   ResourceMark rm;
1871   for (ProfileData* data = first_data();
1872        is_valid(data);
1873        data = next_data(data)) {
1874     data-&gt;verify_clean_weak_method_links();
1875   }
1876 
1877   CleanExtraDataMethodClosure cl;
1878   verify_extra_data_clean(&amp;cl);
1879 }
1880 #endif // ASSERT
    </pre>
  </body>
</html>