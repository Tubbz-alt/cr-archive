<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/compiler/oopMap.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;code/codeBlob.hpp&quot;
 27 #include &quot;code/codeCache.hpp&quot;
 28 #include &quot;code/nmethod.hpp&quot;
 29 #include &quot;code/scopeDesc.hpp&quot;
 30 #include &quot;compiler/oopMap.hpp&quot;
 31 #include &quot;gc/shared/collectedHeap.hpp&quot;
 32 #include &quot;memory/allocation.inline.hpp&quot;
 33 #include &quot;memory/iterator.hpp&quot;
 34 #include &quot;memory/resourceArea.hpp&quot;
 35 #include &quot;memory/universe.hpp&quot;
 36 #include &quot;oops/valueKlass.hpp&quot;
 37 #include &quot;oops/compressedOops.hpp&quot;
 38 #include &quot;runtime/frame.inline.hpp&quot;
 39 #include &quot;runtime/handles.inline.hpp&quot;
 40 #include &quot;runtime/signature.hpp&quot;
 41 #include &quot;utilities/align.hpp&quot;
 42 #include &quot;utilities/lockFreeStack.hpp&quot;
 43 #ifdef COMPILER1
 44 #include &quot;c1/c1_Defs.hpp&quot;
 45 #endif
 46 #ifdef COMPILER2
 47 #include &quot;opto/optoreg.hpp&quot;
 48 #endif
 49 
 50 // OopMapStream
 51 
 52 OopMapStream::OopMapStream(OopMap* oop_map) {
 53   _stream = new CompressedReadStream(oop_map-&gt;write_stream()-&gt;buffer());
 54   _size = oop_map-&gt;omv_count();
 55   _position = 0;
 56   _valid_omv = false;
 57 }
 58 
 59 OopMapStream::OopMapStream(const ImmutableOopMap* oop_map) {
 60   _stream = new CompressedReadStream(oop_map-&gt;data_addr());
 61   _size = oop_map-&gt;count();
 62   _position = 0;
 63   _valid_omv = false;
 64 }
 65 
 66 void OopMapStream::find_next() {
 67   if (_position++ &lt; _size) {
 68     _omv.read_from(_stream);
 69     _valid_omv = true;
 70     return;
 71   }
 72   _valid_omv = false;
 73 }
 74 
 75 
 76 // OopMap
 77 
 78 // frame_size units are stack-slots (4 bytes) NOT intptr_t; we can name odd
 79 // slots to hold 4-byte values like ints and floats in the LP64 build.
 80 OopMap::OopMap(int frame_size, int arg_count) {
 81   // OopMaps are usually quite so small, so pick a small initial size
 82   set_write_stream(new CompressedWriteStream(32));
 83   set_omv_count(0);
 84 
 85 #ifdef ASSERT
 86   _locs_length = VMRegImpl::stack2reg(0)-&gt;value() + frame_size + arg_count;
 87   _locs_used   = NEW_RESOURCE_ARRAY(OopMapValue::oop_types, _locs_length);
 88   for(int i = 0; i &lt; _locs_length; i++) _locs_used[i] = OopMapValue::unused_value;
 89 #endif
 90 }
 91 
 92 
 93 OopMap::OopMap(OopMap::DeepCopyToken, OopMap* source) {
 94   // This constructor does a deep copy
 95   // of the source OopMap.
 96   set_write_stream(new CompressedWriteStream(source-&gt;omv_count() * 2));
 97   set_omv_count(0);
 98   set_offset(source-&gt;offset());
 99 
100 #ifdef ASSERT
101   _locs_length = source-&gt;_locs_length;
102   _locs_used = NEW_RESOURCE_ARRAY(OopMapValue::oop_types, _locs_length);
103   for(int i = 0; i &lt; _locs_length; i++) _locs_used[i] = OopMapValue::unused_value;
104 #endif
105 
106   // We need to copy the entries too.
107   for (OopMapStream oms(source); !oms.is_done(); oms.next()) {
108     OopMapValue omv = oms.current();
109     omv.write_on(write_stream());
110     increment_count();
111   }
112 }
113 
114 
115 OopMap* OopMap::deep_copy() {
116   return new OopMap(_deep_copy_token, this);
117 }
118 
119 void OopMap::copy_data_to(address addr) const {
120   memcpy(addr, write_stream()-&gt;buffer(), write_stream()-&gt;position());
121 }
122 
123 int OopMap::heap_size() const {
124   int size = sizeof(OopMap);
125   int align = sizeof(void *) - 1;
126   size += write_stream()-&gt;position();
127   // Align to a reasonable ending point
128   size = ((size+align) &amp; ~align);
129   return size;
130 }
131 
132 // frame_size units are stack-slots (4 bytes) NOT intptr_t; we can name odd
133 // slots to hold 4-byte values like ints and floats in the LP64 build.
134 void OopMap::set_xxx(VMReg reg, OopMapValue::oop_types x, VMReg optional) {
135 
136   assert(reg-&gt;value() &lt; _locs_length, &quot;too big reg value for stack size&quot;);
137   assert( _locs_used[reg-&gt;value()] == OopMapValue::unused_value, &quot;cannot insert twice&quot; );
138   debug_only( _locs_used[reg-&gt;value()] = x; )
139 
140   OopMapValue o(reg, x, optional);
141   o.write_on(write_stream());
142   increment_count();
143 }
144 
145 
146 void OopMap::set_oop(VMReg reg) {
147   set_xxx(reg, OopMapValue::oop_value, VMRegImpl::Bad());
148 }
149 
150 
151 void OopMap::set_narrowoop(VMReg reg) {
152   set_xxx(reg, OopMapValue::narrowoop_value, VMRegImpl::Bad());
153 }
154 
155 
156 void OopMap::set_callee_saved(VMReg reg, VMReg caller_machine_register ) {
157   set_xxx(reg, OopMapValue::callee_saved_value, caller_machine_register);
158 }
159 
160 
161 void OopMap::set_derived_oop(VMReg reg, VMReg derived_from_local_register ) {
162   if( reg == derived_from_local_register ) {
163     // Actually an oop, derived shares storage with base,
164     set_oop(reg);
165   } else {
166     set_xxx(reg, OopMapValue::derived_oop_value, derived_from_local_register);
167   }
168 }
169 
170 // OopMapSet
171 
172 OopMapSet::OopMapSet() : _list(MinOopMapAllocation) {}
173 
174 void OopMapSet::add_gc_map(int pc_offset, OopMap *map ) {
175   map-&gt;set_offset(pc_offset);
176 
177 #ifdef ASSERT
178   if(_list.length() &gt; 0) {
179     OopMap* last = _list.last();
180     if (last-&gt;offset() == map-&gt;offset() ) {
181       fatal(&quot;OopMap inserted twice&quot;);
182     }
183     if (last-&gt;offset() &gt; map-&gt;offset()) {
184       tty-&gt;print_cr( &quot;WARNING, maps not sorted: pc[%d]=%d, pc[%d]=%d&quot;,
185                       _list.length(),last-&gt;offset(),_list.length()+1,map-&gt;offset());
186     }
187   }
188 #endif // ASSERT
189 
190   add(map);
191 }
192 
193 static void add_derived_oop(oop* base, oop* derived) {
194 #if !defined(TIERED) &amp;&amp; !INCLUDE_JVMCI
195   COMPILER1_PRESENT(ShouldNotReachHere();)
196 #endif // !defined(TIERED) &amp;&amp; !INCLUDE_JVMCI
197 #if COMPILER2_OR_JVMCI
198   DerivedPointerTable::add(derived, base);
199 #endif // COMPILER2_OR_JVMCI
200 }
201 
202 
203 #ifndef PRODUCT
204 static void trace_codeblob_maps(const frame *fr, const RegisterMap *reg_map) {
205   // Print oopmap and regmap
206   tty-&gt;print_cr(&quot;------ &quot;);
207   CodeBlob* cb = fr-&gt;cb();
208   const ImmutableOopMapSet* maps = cb-&gt;oop_maps();
209   const ImmutableOopMap* map = cb-&gt;oop_map_for_return_address(fr-&gt;pc());
210   map-&gt;print();
211   if( cb-&gt;is_nmethod() ) {
212     nmethod* nm = (nmethod*)cb;
213     // native wrappers have no scope data, it is implied
214     if (nm-&gt;is_native_method()) {
215       tty-&gt;print(&quot;bci: 0 (native)&quot;);
216     } else {
217       ScopeDesc* scope  = nm-&gt;scope_desc_at(fr-&gt;pc());
218       tty-&gt;print(&quot;bci: %d &quot;,scope-&gt;bci());
219     }
220   }
221   tty-&gt;cr();
222   fr-&gt;print_on(tty);
223   tty-&gt;print(&quot;     &quot;);
224   cb-&gt;print_value_on(tty);  tty-&gt;cr();
225   reg_map-&gt;print();
226   tty-&gt;print_cr(&quot;------ &quot;);
227 
228 }
229 #endif // PRODUCT
230 
231 void OopMapSet::oops_do(const frame *fr, const RegisterMap* reg_map, OopClosure* f) {
232   // add derived oops to a table
233   all_do(fr, reg_map, f, add_derived_oop, &amp;do_nothing_cl);
234 }
235 
236 
237 void OopMapSet::all_do(const frame *fr, const RegisterMap *reg_map,
238                        OopClosure* oop_fn, void derived_oop_fn(oop*, oop*),
239                        OopClosure* value_fn) {
240   CodeBlob* cb = fr-&gt;cb();
241   assert(cb != NULL, &quot;no codeblob&quot;);
242 
243   NOT_PRODUCT(if (TraceCodeBlobStacks) trace_codeblob_maps(fr, reg_map);)
244 
245   const ImmutableOopMap* map = cb-&gt;oop_map_for_return_address(fr-&gt;pc());
246   assert(map != NULL, &quot;no ptr map found&quot;);
247 
248   // handle derived pointers first (otherwise base pointer may be
249   // changed before derived pointer offset has been collected)
250   {
251     for (OopMapStream oms(map); !oms.is_done(); oms.next()) {
252       OopMapValue omv = oms.current();
253       if (omv.type() != OopMapValue::derived_oop_value) {
254         continue;
255       }
256 
257 #ifndef TIERED
258       COMPILER1_PRESENT(ShouldNotReachHere();)
259 #if INCLUDE_JVMCI
260       if (UseJVMCICompiler) {
261         ShouldNotReachHere();
262       }
263 #endif
264 #endif // !TIERED
265       oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(),reg_map);
266       guarantee(loc != NULL, &quot;missing saved register&quot;);
267       oop *derived_loc = loc;
268       oop *base_loc    = fr-&gt;oopmapreg_to_location(omv.content_reg(), reg_map);
269       // Ignore NULL oops and decoded NULL narrow oops which
270       // equal to CompressedOops::base() when a narrow oop
271       // implicit null check is used in compiled code.
272       // The narrow_oop_base could be NULL or be the address
273       // of the page below heap depending on compressed oops mode.
274       if (base_loc != NULL &amp;&amp; *base_loc != NULL &amp;&amp; !CompressedOops::is_base(*base_loc)) {
275         derived_oop_fn(base_loc, derived_loc);
276       }
277     }
278   }
279 
280   {
281     // We want coop and oop oop_types
282     for (OopMapStream oms(map); !oms.is_done(); oms.next()) {
283       OopMapValue omv = oms.current();
284       oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(),reg_map);
285       // It should be an error if no location can be found for a
286       // register mentioned as contained an oop of some kind.  Maybe
287       // this was allowed previously because value_value items might
288       // be missing?
289       guarantee(loc != NULL, &quot;missing saved register&quot;);
290       if ( omv.type() == OopMapValue::oop_value ) {
291         oop val = *loc;
292         if (val == NULL || CompressedOops::is_base(val)) {
293           // Ignore NULL oops and decoded NULL narrow oops which
294           // equal to CompressedOops::base() when a narrow oop
295           // implicit null check is used in compiled code.
296           // The narrow_oop_base could be NULL or be the address
297           // of the page below heap depending on compressed oops mode.
298           continue;
299         }
300 #ifdef ASSERT
301         if ((((uintptr_t)loc &amp; (sizeof(*loc)-1)) != 0) ||
302             !Universe::heap()-&gt;is_in_or_null(*loc)) {
303           tty-&gt;print_cr(&quot;# Found non oop pointer.  Dumping state at failure&quot;);
304           // try to dump out some helpful debugging information
305           trace_codeblob_maps(fr, reg_map);
306           omv.print();
307           tty-&gt;print_cr(&quot;register r&quot;);
308           omv.reg()-&gt;print();
309           tty-&gt;print_cr(&quot;loc = %p *loc = %p\n&quot;, loc, cast_from_oop&lt;address&gt;(*loc));
310           // do the real assert.
311           assert(Universe::heap()-&gt;is_in_or_null(*loc), &quot;found non oop pointer&quot;);
312         }
313 #endif // ASSERT
314         oop_fn-&gt;do_oop(loc);
315       } else if ( omv.type() == OopMapValue::narrowoop_value ) {
316         narrowOop *nl = (narrowOop*)loc;
317 #ifndef VM_LITTLE_ENDIAN
318         VMReg vmReg = omv.reg();
319         // Don&#39;t do this on SPARC float registers as they can be individually addressed
320         if (!vmReg-&gt;is_stack() SPARC_ONLY(&amp;&amp; !vmReg-&gt;is_FloatRegister())) {
321           // compressed oops in registers only take up 4 bytes of an
322           // 8 byte register but they are in the wrong part of the
323           // word so adjust loc to point at the right place.
324           nl = (narrowOop*)((address)nl + 4);
325         }
326 #endif
327         oop_fn-&gt;do_oop(nl);
328       }
329     }
330   }
331 }
332 
333 
334 // Update callee-saved register info for the following frame
335 void OopMapSet::update_register_map(const frame *fr, RegisterMap *reg_map) {
336   ResourceMark rm;
337   CodeBlob* cb = fr-&gt;cb();
338   assert(cb != NULL, &quot;no codeblob&quot;);
339 
340   // Any reg might be saved by a safepoint handler (see generate_handler_blob).
341   assert( reg_map-&gt;_update_for_id == NULL || fr-&gt;is_older(reg_map-&gt;_update_for_id),
342          &quot;already updated this map; do not &#39;update&#39; it twice!&quot; );
343   debug_only(reg_map-&gt;_update_for_id = fr-&gt;id());
344 
345   // Check if caller must update oop argument
346   assert((reg_map-&gt;include_argument_oops() ||
347           !cb-&gt;caller_must_gc_arguments(reg_map-&gt;thread())),
348          &quot;include_argument_oops should already be set&quot;);
349 
350   // Scan through oopmap and find location of all callee-saved registers
351   // (we do not do update in place, since info could be overwritten)
352 
353   address pc = fr-&gt;pc();
354   const ImmutableOopMap* map  = cb-&gt;oop_map_for_return_address(pc);
355   assert(map != NULL, &quot;no ptr map found&quot;);
356   DEBUG_ONLY(int nof_callee = 0;)
357 
358   for (OopMapStream oms(map); !oms.is_done(); oms.next()) {
359     OopMapValue omv = oms.current();
360     if (omv.type() == OopMapValue::callee_saved_value) {
361       VMReg reg = omv.content_reg();
362       oop* loc = fr-&gt;oopmapreg_to_location(omv.reg(), reg_map);
363       reg_map-&gt;set_location(reg, (address) loc);
364       DEBUG_ONLY(nof_callee++;)
365     }
366   }
367 
368   // Check that runtime stubs save all callee-saved registers
369 #ifdef COMPILER2
370   assert(cb-&gt;is_compiled_by_c1() || cb-&gt;is_compiled_by_jvmci() || !cb-&gt;is_runtime_stub() ||
371          (nof_callee &gt;= SAVED_ON_ENTRY_REG_COUNT || nof_callee &gt;= C_SAVED_ON_ENTRY_REG_COUNT),
372          &quot;must save all&quot;);
373 #endif // COMPILER2
374 }
375 
376 // Printing code is present in product build for -XX:+PrintAssembly.
377 
378 static
379 void print_register_type(OopMapValue::oop_types x, VMReg optional,
380                          outputStream* st) {
381   switch( x ) {
382   case OopMapValue::oop_value:
383     st-&gt;print(&quot;Oop&quot;);
384     break;
385   case OopMapValue::narrowoop_value:
386     st-&gt;print(&quot;NarrowOop&quot;);
387     break;
388   case OopMapValue::callee_saved_value:
389     st-&gt;print(&quot;Callers_&quot;);
390     optional-&gt;print_on(st);
391     break;
392   case OopMapValue::derived_oop_value:
393     st-&gt;print(&quot;Derived_oop_&quot;);
394     optional-&gt;print_on(st);
395     break;
396   default:
397     ShouldNotReachHere();
398   }
399 }
400 
401 void OopMapValue::print_on(outputStream* st) const {
402   reg()-&gt;print_on(st);
403   st-&gt;print(&quot;=&quot;);
404   print_register_type(type(),content_reg(),st);
405   st-&gt;print(&quot; &quot;);
406 }
407 
408 void OopMapValue::print() const { print_on(tty); }
409 
410 void ImmutableOopMap::print_on(outputStream* st) const {
411   OopMapValue omv;
412   st-&gt;print(&quot;ImmutableOopMap {&quot;);
413   for(OopMapStream oms(this); !oms.is_done(); oms.next()) {
414     omv = oms.current();
415     omv.print_on(st);
416   }
417   st-&gt;print(&quot;}&quot;);
418 }
419 
420 void ImmutableOopMap::print() const { print_on(tty); }
421 
422 void OopMap::print_on(outputStream* st) const {
423   OopMapValue omv;
424   st-&gt;print(&quot;OopMap {&quot;);
425   for(OopMapStream oms((OopMap*)this); !oms.is_done(); oms.next()) {
426     omv = oms.current();
427     omv.print_on(st);
428   }
429   // Print hex offset in addition.
430   st-&gt;print(&quot;off=%d/0x%x}&quot;, (int) offset(), (int) offset());
431 }
432 
433 void OopMap::print() const { print_on(tty); }
434 
435 void ImmutableOopMapSet::print_on(outputStream* st) const {
436   const ImmutableOopMap* last = NULL;
437   const int len = count();
438 
439   st-&gt;print_cr(&quot;ImmutableOopMapSet contains %d OopMaps&quot;, len);
440 
441   for (int i = 0; i &lt; len; i++) {
442     const ImmutableOopMapPair* pair = pair_at(i);
443     const ImmutableOopMap* map = pair-&gt;get_from(this);
444     if (map != last) {
445       st-&gt;cr();
446       map-&gt;print_on(st);
447       st-&gt;print(&quot; pc offsets: &quot;);
448     }
449     last = map;
450     st-&gt;print(&quot;%d &quot;, pair-&gt;pc_offset());
451   }
452   st-&gt;cr();
453 }
454 
455 void ImmutableOopMapSet::print() const { print_on(tty); }
456 
457 void OopMapSet::print_on(outputStream* st) const {
458   const int len = _list.length();
459 
460   st-&gt;print_cr(&quot;OopMapSet contains %d OopMaps&quot;, len);
461 
462   for( int i = 0; i &lt; len; i++) {
463     OopMap* m = at(i);
464     st-&gt;print_cr(&quot;#%d &quot;,i);
465     m-&gt;print_on(st);
466     st-&gt;cr();
467   }
468   st-&gt;cr();
469 }
470 
471 void OopMapSet::print() const { print_on(tty); }
472 
473 bool OopMap::equals(const OopMap* other) const {
474   if (other-&gt;_omv_count != _omv_count) {
475     return false;
476   }
477   if (other-&gt;write_stream()-&gt;position() != write_stream()-&gt;position()) {
478     return false;
479   }
480   if (memcmp(other-&gt;write_stream()-&gt;buffer(), write_stream()-&gt;buffer(), write_stream()-&gt;position()) != 0) {
481     return false;
482   }
483   return true;
484 }
485 
486 const ImmutableOopMap* ImmutableOopMapSet::find_map_at_offset(int pc_offset) const {
487   ImmutableOopMapPair* pairs = get_pairs();
488   ImmutableOopMapPair* last  = NULL;
489 
490   for (int i = 0; i &lt; _count; ++i) {
491     if (pairs[i].pc_offset() &gt;= pc_offset) {
492       last = &amp;pairs[i];
493       break;
494     }
495   }
496 
497   // Heal Coverity issue: potential index out of bounds access.
498   guarantee(last != NULL, &quot;last may not be null&quot;);
499   assert(last-&gt;pc_offset() == pc_offset, &quot;oopmap not found&quot;);
500   return last-&gt;get_from(this);
501 }
502 
503 const ImmutableOopMap* ImmutableOopMapPair::get_from(const ImmutableOopMapSet* set) const {
504   return set-&gt;oopmap_at_offset(_oopmap_offset);
505 }
506 
507 ImmutableOopMap::ImmutableOopMap(const OopMap* oopmap) : _count(oopmap-&gt;count()) {
508   address addr = data_addr();
509   oopmap-&gt;copy_data_to(addr);
510 }
511 
512 #ifdef ASSERT
513 int ImmutableOopMap::nr_of_bytes() const {
514   OopMapStream oms(this);
515 
516   while (!oms.is_done()) {
517     oms.next();
518   }
519   return sizeof(ImmutableOopMap) + oms.stream_position();
520 }
521 #endif
522 
523 ImmutableOopMapBuilder::ImmutableOopMapBuilder(const OopMapSet* set) : _set(set), _empty(NULL), _last(NULL), _empty_offset(-1), _last_offset(-1), _offset(0), _required(-1), _new_set(NULL) {
524   _mapping = NEW_RESOURCE_ARRAY(Mapping, _set-&gt;size());
525 }
526 
527 int ImmutableOopMapBuilder::size_for(const OopMap* map) const {
528   return align_up((int)sizeof(ImmutableOopMap) + map-&gt;data_size(), 8);
529 }
530 
531 int ImmutableOopMapBuilder::heap_size() {
532   int base = sizeof(ImmutableOopMapSet);
533   base = align_up(base, 8);
534 
535   // all of ours pc / offset pairs
536   int pairs = _set-&gt;size() * sizeof(ImmutableOopMapPair);
537   pairs = align_up(pairs, 8);
538 
539   for (int i = 0; i &lt; _set-&gt;size(); ++i) {
540     int size = 0;
541     OopMap* map = _set-&gt;at(i);
542 
543     if (is_empty(map)) {
544       /* only keep a single empty map in the set */
545       if (has_empty()) {
546         _mapping[i].set(Mapping::OOPMAP_EMPTY, _empty_offset, 0, map, _empty);
547       } else {
548         _empty_offset = _offset;
549         _empty = map;
550         size = size_for(map);
551         _mapping[i].set(Mapping::OOPMAP_NEW, _offset, size, map);
552       }
553     } else if (is_last_duplicate(map)) {
554       /* if this entry is identical to the previous one, just point it there */
555       _mapping[i].set(Mapping::OOPMAP_DUPLICATE, _last_offset, 0, map, _last);
556     } else {
557       /* not empty, not an identical copy of the previous entry */
558       size = size_for(map);
559       _mapping[i].set(Mapping::OOPMAP_NEW, _offset, size, map);
560       _last_offset = _offset;
561       _last = map;
562     }
563 
564     assert(_mapping[i]._map == map, &quot;check&quot;);
565     _offset += size;
566   }
567 
568   int total = base + pairs + _offset;
569   DEBUG_ONLY(total += 8);
570   _required = total;
571   return total;
572 }
573 
574 void ImmutableOopMapBuilder::fill_pair(ImmutableOopMapPair* pair, const OopMap* map, int offset, const ImmutableOopMapSet* set) {
575   assert(offset &lt; set-&gt;nr_of_bytes(), &quot;check&quot;);
576   new ((address) pair) ImmutableOopMapPair(map-&gt;offset(), offset);
577 }
578 
579 int ImmutableOopMapBuilder::fill_map(ImmutableOopMapPair* pair, const OopMap* map, int offset, const ImmutableOopMapSet* set) {
580   fill_pair(pair, map, offset, set);
581   address addr = (address) pair-&gt;get_from(_new_set); // location of the ImmutableOopMap
582 
583   new (addr) ImmutableOopMap(map);
584   return size_for(map);
585 }
586 
587 void ImmutableOopMapBuilder::fill(ImmutableOopMapSet* set, int sz) {
588   ImmutableOopMapPair* pairs = set-&gt;get_pairs();
589 
590   for (int i = 0; i &lt; set-&gt;count(); ++i) {
591     const OopMap* map = _mapping[i]._map;
592     ImmutableOopMapPair* pair = NULL;
593     int size = 0;
594 
595     if (_mapping[i]._kind == Mapping::OOPMAP_NEW) {
596       size = fill_map(&amp;pairs[i], map, _mapping[i]._offset, set);
597     } else if (_mapping[i]._kind == Mapping::OOPMAP_DUPLICATE || _mapping[i]._kind == Mapping::OOPMAP_EMPTY) {
598       fill_pair(&amp;pairs[i], map, _mapping[i]._offset, set);
599     }
600 
601     const ImmutableOopMap* nv = set-&gt;find_map_at_offset(map-&gt;offset());
602     assert(memcmp(map-&gt;data(), nv-&gt;data_addr(), map-&gt;data_size()) == 0, &quot;check identity&quot;);
603   }
604 }
605 
606 #ifdef ASSERT
607 void ImmutableOopMapBuilder::verify(address buffer, int size, const ImmutableOopMapSet* set) {
608   for (int i = 0; i &lt; 8; ++i) {
609     assert(buffer[size - 8 + i] == (unsigned char) 0xff, &quot;overwritten memory check&quot;);
610   }
611 
612   for (int i = 0; i &lt; set-&gt;count(); ++i) {
613     const ImmutableOopMapPair* pair = set-&gt;pair_at(i);
614     assert(pair-&gt;oopmap_offset() &lt; set-&gt;nr_of_bytes(), &quot;check size&quot;);
615     const ImmutableOopMap* map = pair-&gt;get_from(set);
616     int nr_of_bytes = map-&gt;nr_of_bytes();
617     assert(pair-&gt;oopmap_offset() + nr_of_bytes &lt;= set-&gt;nr_of_bytes(), &quot;check size + size&quot;);
618   }
619 }
620 #endif
621 
622 ImmutableOopMapSet* ImmutableOopMapBuilder::generate_into(address buffer) {
623   DEBUG_ONLY(memset(&amp;buffer[_required-8], 0xff, 8));
624 
625   _new_set = new (buffer) ImmutableOopMapSet(_set, _required);
626   fill(_new_set, _required);
627 
628   DEBUG_ONLY(verify(buffer, _required, _new_set));
629 
630   return _new_set;
631 }
632 
633 ImmutableOopMapSet* ImmutableOopMapBuilder::build() {
634   _required = heap_size();
635 
636   // We need to allocate a chunk big enough to hold the ImmutableOopMapSet and all of its ImmutableOopMaps
637   address buffer = NEW_C_HEAP_ARRAY(unsigned char, _required, mtCode);
638   return generate_into(buffer);
639 }
640 
641 ImmutableOopMapSet* ImmutableOopMapSet::build_from(const OopMapSet* oopmap_set) {
642   ResourceMark mark;
643   ImmutableOopMapBuilder builder(oopmap_set);
644   return builder.build();
645 }
646 
647 
648 //------------------------------DerivedPointerTable---------------------------
649 
650 #if COMPILER2_OR_JVMCI
651 
652 class DerivedPointerTable::Entry : public CHeapObj&lt;mtCompiler&gt; {
653   oop* _location;   // Location of derived pointer, also pointing to base
654   intptr_t _offset; // Offset from base pointer
655   Entry* volatile _next;
656 
657   static Entry* volatile* next_ptr(Entry&amp; entry) { return &amp;entry._next; }
658 
659 public:
660   Entry(oop* location, intptr_t offset) :
661     _location(location), _offset(offset), _next(NULL) {}
662 
663   oop* location() const { return _location; }
664   intptr_t offset() const { return _offset; }
665   Entry* next() const { return _next; }
666 
667   typedef LockFreeStack&lt;Entry, &amp;next_ptr&gt; List;
668   static List* _list;
669 };
670 
671 DerivedPointerTable::Entry::List* DerivedPointerTable::Entry::_list = NULL;
672 bool DerivedPointerTable::_active = false;
673 
674 bool DerivedPointerTable::is_empty() {
675   return Entry::_list == NULL || Entry::_list-&gt;empty();
676 }
677 
678 void DerivedPointerTable::clear() {
679   // The first time, we create the list.  Otherwise it should be
680   // empty.  If not, then we have probably forgotton to call
681   // update_pointers after last GC/Scavenge.
682   assert (!_active, &quot;should not be active&quot;);
683   assert(is_empty(), &quot;table not empty&quot;);
684   if (Entry::_list == NULL) {
685     void* mem = NEW_C_HEAP_OBJ(Entry::List, mtCompiler);
686     Entry::_list = ::new (mem) Entry::List();
687   }
688   _active = true;
689 }
690 
691 // Returns value of location as an int
692 inline intptr_t value_of_loc(oop *pointer) {
693   return cast_from_oop&lt;intptr_t&gt;((*pointer));
694 }
695 
696 void DerivedPointerTable::add(oop *derived_loc, oop *base_loc) {
697   assert(Universe::heap()-&gt;is_in_or_null(*base_loc), &quot;not an oop&quot;);
698   assert(derived_loc != base_loc, &quot;Base and derived in same location&quot;);
699   if (_active) {
700     assert(*derived_loc != (void*)base_loc, &quot;location already added&quot;);
701     assert(Entry::_list != NULL, &quot;list must exist&quot;);
702     intptr_t offset = value_of_loc(derived_loc) - value_of_loc(base_loc);
703     // This assert is invalid because derived pointers can be
704     // arbitrarily far away from their base.
705     // assert(offset &gt;= -1000000, &quot;wrong derived pointer info&quot;);
706 
707     if (TraceDerivedPointers) {
708       tty-&gt;print_cr(
709         &quot;Add derived pointer@&quot; INTPTR_FORMAT
710         &quot; - Derived: &quot; INTPTR_FORMAT
711         &quot; Base: &quot; INTPTR_FORMAT &quot; (@&quot; INTPTR_FORMAT &quot;) (Offset: &quot; INTX_FORMAT &quot;)&quot;,
712         p2i(derived_loc), p2i(*derived_loc), p2i(*base_loc), p2i(base_loc), offset
713       );
714     }
715     // Set derived oop location to point to base.
716     *derived_loc = (oop)base_loc;
717     Entry* entry = new Entry(derived_loc, offset);
718     Entry::_list-&gt;push(*entry);
719   }
720 }
721 
722 void DerivedPointerTable::update_pointers() {
723   assert(Entry::_list != NULL, &quot;list must exist&quot;);
724   Entry* entries = Entry::_list-&gt;pop_all();
725   while (entries != NULL) {
726     Entry* entry = entries;
727     entries = entry-&gt;next();
728     oop* derived_loc = entry-&gt;location();
729     intptr_t offset  = entry-&gt;offset();
730     // The derived oop was setup to point to location of base
731     oop base = **(oop**)derived_loc;
732     assert(Universe::heap()-&gt;is_in_or_null(base), &quot;must be an oop&quot;);
733 
734     *derived_loc = (oop)(cast_from_oop&lt;address&gt;(base) + offset);
735     assert(value_of_loc(derived_loc) - value_of_loc(&amp;base) == offset, &quot;sanity check&quot;);
736 
737     if (TraceDerivedPointers) {
738       tty-&gt;print_cr(&quot;Updating derived pointer@&quot; INTPTR_FORMAT
739                     &quot; - Derived: &quot; INTPTR_FORMAT &quot;  Base: &quot; INTPTR_FORMAT &quot; (Offset: &quot; INTX_FORMAT &quot;)&quot;,
740           p2i(derived_loc), p2i(*derived_loc), p2i(base), offset);
741     }
742 
743     // Delete entry
744     delete entry;
745   }
746   assert(Entry::_list-&gt;empty(), &quot;invariant&quot;);
747   _active = false;
748 }
749 
750 #endif // COMPILER2_OR_JVMCI
    </pre>
  </body>
</html>