<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/compile.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="classes.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/compile.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 234   #define PRINT_STAT_LINE(name, c, f) \
 235     tty-&gt;print_cr(&quot;  %4d (%4.1f%%) %s (%s)&quot;, (int)(c), ((c) * 100.0) / total, name, f);
 236   for (int index = 1 + (int)vmIntrinsics::_none; index &lt; (int)vmIntrinsics::ID_LIMIT; index++) {
 237     vmIntrinsics::ID id = (vmIntrinsics::ID) index;
 238     int   flags = _intrinsic_hist_flags[id];
 239     juint count = _intrinsic_hist_count[id];
 240     if ((flags | count) != 0) {
 241       PRINT_STAT_LINE(vmIntrinsics::name_at(id), count, format_flags(flags, flagsbuf));
 242     }
 243   }
 244   PRINT_STAT_LINE(&quot;total&quot;, total, format_flags(_intrinsic_hist_flags[vmIntrinsics::_none], flagsbuf));
 245   if (xtty != NULL)  xtty-&gt;tail(&quot;statistics&quot;);
 246 }
 247 
 248 void Compile::print_statistics() {
 249   { ttyLocker ttyl;
 250     if (xtty != NULL)  xtty-&gt;head(&quot;statistics type=&#39;opto&#39;&quot;);
 251     Parse::print_statistics();
 252     PhaseCCP::print_statistics();
 253     PhaseRegAlloc::print_statistics();
<span class="line-modified"> 254     Scheduling::print_statistics();</span>
 255     PhasePeephole::print_statistics();
 256     PhaseIdealLoop::print_statistics();
 257     if (xtty != NULL)  xtty-&gt;tail(&quot;statistics&quot;);
 258   }
 259   if (_intrinsic_hist_flags[vmIntrinsics::_none] != 0) {
 260     // put this under its own &lt;statistics&gt; element.
 261     print_intrinsic_statistics();
 262   }
 263 }
 264 #endif //PRODUCT
 265 
<span class="line-removed"> 266 // Support for bundling info</span>
<span class="line-removed"> 267 Bundle* Compile::node_bundling(const Node *n) {</span>
<span class="line-removed"> 268   assert(valid_bundle_info(n), &quot;oob&quot;);</span>
<span class="line-removed"> 269   return &amp;_node_bundling_base[n-&gt;_idx];</span>
<span class="line-removed"> 270 }</span>
<span class="line-removed"> 271 </span>
<span class="line-removed"> 272 bool Compile::valid_bundle_info(const Node *n) {</span>
<span class="line-removed"> 273   return (_node_bundling_limit &gt; n-&gt;_idx);</span>
<span class="line-removed"> 274 }</span>
<span class="line-removed"> 275 </span>
<span class="line-removed"> 276 </span>
 277 void Compile::gvn_replace_by(Node* n, Node* nn) {
 278   for (DUIterator_Last imin, i = n-&gt;last_outs(imin); i &gt;= imin; ) {
 279     Node* use = n-&gt;last_out(i);
 280     bool is_in_table = initial_gvn()-&gt;hash_delete(use);
 281     uint uses_found = 0;
 282     for (uint j = 0; j &lt; use-&gt;len(); j++) {
 283       if (use-&gt;in(j) == n) {
 284         if (j &lt; use-&gt;req())
 285           use-&gt;set_req(j, nn);
 286         else
 287           use-&gt;set_prec(j, nn);
 288         uses_found++;
 289       }
 290     }
 291     if (is_in_table) {
 292       // reinsert into table
 293       initial_gvn()-&gt;hash_find_insert(use);
 294     }
 295     record_for_igvn(use);
 296     i -= uses_found;    // we deleted 1 or more copies of this edge
</pre>
<hr />
<pre>
 411   // Remove useless Opaque4 nodes
 412   for (int i = opaque4_count() - 1; i &gt;= 0; i--) {
 413     Node* opaq = opaque4_node(i);
 414     if (!useful.member(opaq)) {
 415       remove_opaque4_node(opaq);
 416     }
 417   }
 418   // Remove useless value type nodes
 419   if (_value_type_nodes != NULL) {
 420     _value_type_nodes-&gt;remove_useless_nodes(useful.member_set());
 421   }
 422   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 423   bs-&gt;eliminate_useless_gc_barriers(useful, this);
 424   // clean up the late inline lists
 425   remove_useless_late_inlines(&amp;_string_late_inlines, useful);
 426   remove_useless_late_inlines(&amp;_boxing_late_inlines, useful);
 427   remove_useless_late_inlines(&amp;_late_inlines, useful);
 428   debug_only(verify_graph_edges(true/*check for no_dead_code*/);)
 429 }
 430 
<span class="line-removed"> 431 //------------------------------frame_size_in_words-----------------------------</span>
<span class="line-removed"> 432 // frame_slots in units of words</span>
<span class="line-removed"> 433 int Compile::frame_size_in_words() const {</span>
<span class="line-removed"> 434   // shift is 0 in LP32 and 1 in LP64</span>
<span class="line-removed"> 435   const int shift = (LogBytesPerWord - LogBytesPerInt);</span>
<span class="line-removed"> 436   int words = _frame_slots &gt;&gt; shift;</span>
<span class="line-removed"> 437   assert( words &lt;&lt; shift == _frame_slots, &quot;frame size must be properly aligned in LP64&quot; );</span>
<span class="line-removed"> 438   return words;</span>
<span class="line-removed"> 439 }</span>
<span class="line-removed"> 440 </span>
<span class="line-removed"> 441 // To bang the stack of this compiled method we use the stack size</span>
<span class="line-removed"> 442 // that the interpreter would need in case of a deoptimization. This</span>
<span class="line-removed"> 443 // removes the need to bang the stack in the deoptimization blob which</span>
<span class="line-removed"> 444 // in turn simplifies stack overflow handling.</span>
<span class="line-removed"> 445 int Compile::bang_size_in_bytes() const {</span>
<span class="line-removed"> 446   return MAX2(frame_size_in_bytes() + os::extra_bang_size_in_bytes(), _interpreter_frame_size);</span>
<span class="line-removed"> 447 }</span>
<span class="line-removed"> 448 </span>
 449 // ============================================================================
 450 //------------------------------CompileWrapper---------------------------------
 451 class CompileWrapper : public StackObj {
 452   Compile *const _compile;
 453  public:
 454   CompileWrapper(Compile* compile);
 455 
 456   ~CompileWrapper();
 457 };
 458 
 459 CompileWrapper::CompileWrapper(Compile* compile) : _compile(compile) {
 460   // the Compile* pointer is stored in the current ciEnv:
 461   ciEnv* env = compile-&gt;env();
 462   assert(env == ciEnv::current(), &quot;must already be a ciEnv active&quot;);
 463   assert(env-&gt;compiler_data() == NULL, &quot;compile already active?&quot;);
 464   env-&gt;set_compiler_data(compile);
 465   assert(compile == Compile::current(), &quot;sanity&quot;);
 466 
 467   compile-&gt;set_type_dict(NULL);
 468   compile-&gt;set_clone_map(new Dict(cmpkey, hashkey, _compile-&gt;comp_arena()));
 469   compile-&gt;clone_map().set_clone_idx(0);
 470   compile-&gt;set_type_last_size(0);
 471   compile-&gt;set_last_tf(NULL, NULL);
 472   compile-&gt;set_indexSet_arena(NULL);
 473   compile-&gt;set_indexSet_free_block_list(NULL);
 474   compile-&gt;init_type_arena();
 475   Type::Initialize(compile);
<span class="line-removed"> 476   _compile-&gt;set_scratch_buffer_blob(NULL);</span>
 477   _compile-&gt;begin_method();
 478   _compile-&gt;clone_map().set_debug(_compile-&gt;has_method() &amp;&amp; _compile-&gt;directive()-&gt;CloneMapDebugOption);
 479 }
 480 CompileWrapper::~CompileWrapper() {
 481   _compile-&gt;end_method();
<span class="line-removed"> 482   if (_compile-&gt;scratch_buffer_blob() != NULL)</span>
<span class="line-removed"> 483     BufferBlob::free(_compile-&gt;scratch_buffer_blob());</span>
 484   _compile-&gt;env()-&gt;set_compiler_data(NULL);
 485 }
 486 
 487 
 488 //----------------------------print_compile_messages---------------------------
 489 void Compile::print_compile_messages() {
 490 #ifndef PRODUCT
 491   // Check if recompiling
 492   if (_subsume_loads == false &amp;&amp; PrintOpto) {
 493     // Recompiling without allowing machine instructions to subsume loads
 494     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 495     tty-&gt;print_cr(&quot;** Bailout: Recompile without subsuming loads          **&quot;);
 496     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 497   }
 498   if (_do_escape_analysis != DoEscapeAnalysis &amp;&amp; PrintOpto) {
 499     // Recompiling without escape analysis
 500     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 501     tty-&gt;print_cr(&quot;** Bailout: Recompile without escape analysis          **&quot;);
 502     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 503   }
</pre>
<hr />
<pre>
 508     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 509   }
 510   if (C-&gt;directive()-&gt;BreakAtCompileOption) {
 511     // Open the debugger when compiling this method.
 512     tty-&gt;print(&quot;### Breaking when compiling: &quot;);
 513     method()-&gt;print_short_name();
 514     tty-&gt;cr();
 515     BREAKPOINT;
 516   }
 517 
 518   if( PrintOpto ) {
 519     if (is_osr_compilation()) {
 520       tty-&gt;print(&quot;[OSR]%3d&quot;, _compile_id);
 521     } else {
 522       tty-&gt;print(&quot;%3d&quot;, _compile_id);
 523     }
 524   }
 525 #endif
 526 }
 527 
<span class="line-removed"> 528 </span>
<span class="line-removed"> 529 //-----------------------init_scratch_buffer_blob------------------------------</span>
<span class="line-removed"> 530 // Construct a temporary BufferBlob and cache it for this compile.</span>
<span class="line-removed"> 531 void Compile::init_scratch_buffer_blob(int const_size) {</span>
<span class="line-removed"> 532   // If there is already a scratch buffer blob allocated and the</span>
<span class="line-removed"> 533   // constant section is big enough, use it.  Otherwise free the</span>
<span class="line-removed"> 534   // current and allocate a new one.</span>
<span class="line-removed"> 535   BufferBlob* blob = scratch_buffer_blob();</span>
<span class="line-removed"> 536   if ((blob != NULL) &amp;&amp; (const_size &lt;= _scratch_const_size)) {</span>
<span class="line-removed"> 537     // Use the current blob.</span>
<span class="line-removed"> 538   } else {</span>
<span class="line-removed"> 539     if (blob != NULL) {</span>
<span class="line-removed"> 540       BufferBlob::free(blob);</span>
<span class="line-removed"> 541     }</span>
<span class="line-removed"> 542 </span>
<span class="line-removed"> 543     ResourceMark rm;</span>
<span class="line-removed"> 544     _scratch_const_size = const_size;</span>
<span class="line-removed"> 545     int size = C2Compiler::initial_code_buffer_size(const_size);</span>
<span class="line-removed"> 546 #ifdef ASSERT</span>
<span class="line-removed"> 547     if (C-&gt;has_scalarized_args()) {</span>
<span class="line-removed"> 548       // Oop verification for loading object fields from scalarized value types in the new entry point requires lots of space</span>
<span class="line-removed"> 549       size += 5120;</span>
<span class="line-removed"> 550     }</span>
<span class="line-removed"> 551 #endif</span>
<span class="line-removed"> 552     blob = BufferBlob::create(&quot;Compile::scratch_buffer&quot;, size);</span>
<span class="line-removed"> 553     // Record the buffer blob for next time.</span>
<span class="line-removed"> 554     set_scratch_buffer_blob(blob);</span>
<span class="line-removed"> 555     // Have we run out of code space?</span>
<span class="line-removed"> 556     if (scratch_buffer_blob() == NULL) {</span>
<span class="line-removed"> 557       // Let CompilerBroker disable further compilations.</span>
<span class="line-removed"> 558       record_failure(&quot;Not enough space for scratch buffer in CodeCache&quot;);</span>
<span class="line-removed"> 559       return;</span>
<span class="line-removed"> 560     }</span>
<span class="line-removed"> 561   }</span>
<span class="line-removed"> 562 </span>
<span class="line-removed"> 563   // Initialize the relocation buffers</span>
<span class="line-removed"> 564   relocInfo* locs_buf = (relocInfo*) blob-&gt;content_end() - MAX_locs_size;</span>
<span class="line-removed"> 565   set_scratch_locs_memory(locs_buf);</span>
<span class="line-removed"> 566 }</span>
<span class="line-removed"> 567 </span>
<span class="line-removed"> 568 </span>
<span class="line-removed"> 569 //-----------------------scratch_emit_size-------------------------------------</span>
<span class="line-removed"> 570 // Helper function that computes size by emitting code</span>
<span class="line-removed"> 571 uint Compile::scratch_emit_size(const Node* n) {</span>
<span class="line-removed"> 572   // Start scratch_emit_size section.</span>
<span class="line-removed"> 573   set_in_scratch_emit_size(true);</span>
<span class="line-removed"> 574 </span>
<span class="line-removed"> 575   // Emit into a trash buffer and count bytes emitted.</span>
<span class="line-removed"> 576   // This is a pretty expensive way to compute a size,</span>
<span class="line-removed"> 577   // but it works well enough if seldom used.</span>
<span class="line-removed"> 578   // All common fixed-size instructions are given a size</span>
<span class="line-removed"> 579   // method by the AD file.</span>
<span class="line-removed"> 580   // Note that the scratch buffer blob and locs memory are</span>
<span class="line-removed"> 581   // allocated at the beginning of the compile task, and</span>
<span class="line-removed"> 582   // may be shared by several calls to scratch_emit_size.</span>
<span class="line-removed"> 583   // The allocation of the scratch buffer blob is particularly</span>
<span class="line-removed"> 584   // expensive, since it has to grab the code cache lock.</span>
<span class="line-removed"> 585   BufferBlob* blob = this-&gt;scratch_buffer_blob();</span>
<span class="line-removed"> 586   assert(blob != NULL, &quot;Initialize BufferBlob at start&quot;);</span>
<span class="line-removed"> 587   assert(blob-&gt;size() &gt; MAX_inst_size, &quot;sanity&quot;);</span>
<span class="line-removed"> 588   relocInfo* locs_buf = scratch_locs_memory();</span>
<span class="line-removed"> 589   address blob_begin = blob-&gt;content_begin();</span>
<span class="line-removed"> 590   address blob_end   = (address)locs_buf;</span>
<span class="line-removed"> 591   assert(blob-&gt;contains(blob_end), &quot;sanity&quot;);</span>
<span class="line-removed"> 592   CodeBuffer buf(blob_begin, blob_end - blob_begin);</span>
<span class="line-removed"> 593   buf.initialize_consts_size(_scratch_const_size);</span>
<span class="line-removed"> 594   buf.initialize_stubs_size(MAX_stubs_size);</span>
<span class="line-removed"> 595   assert(locs_buf != NULL, &quot;sanity&quot;);</span>
<span class="line-removed"> 596   int lsize = MAX_locs_size / 3;</span>
<span class="line-removed"> 597   buf.consts()-&gt;initialize_shared_locs(&amp;locs_buf[lsize * 0], lsize);</span>
<span class="line-removed"> 598   buf.insts()-&gt;initialize_shared_locs( &amp;locs_buf[lsize * 1], lsize);</span>
<span class="line-removed"> 599   buf.stubs()-&gt;initialize_shared_locs( &amp;locs_buf[lsize * 2], lsize);</span>
<span class="line-removed"> 600   // Mark as scratch buffer.</span>
<span class="line-removed"> 601   buf.consts()-&gt;set_scratch_emit();</span>
<span class="line-removed"> 602   buf.insts()-&gt;set_scratch_emit();</span>
<span class="line-removed"> 603   buf.stubs()-&gt;set_scratch_emit();</span>
<span class="line-removed"> 604 </span>
<span class="line-removed"> 605   // Do the emission.</span>
<span class="line-removed"> 606 </span>
<span class="line-removed"> 607   Label fakeL; // Fake label for branch instructions.</span>
<span class="line-removed"> 608   Label*   saveL = NULL;</span>
<span class="line-removed"> 609   uint save_bnum = 0;</span>
<span class="line-removed"> 610   bool is_branch = n-&gt;is_MachBranch();</span>
<span class="line-removed"> 611   if (is_branch) {</span>
<span class="line-removed"> 612     MacroAssembler masm(&amp;buf);</span>
<span class="line-removed"> 613     masm.bind(fakeL);</span>
<span class="line-removed"> 614     n-&gt;as_MachBranch()-&gt;save_label(&amp;saveL, &amp;save_bnum);</span>
<span class="line-removed"> 615     n-&gt;as_MachBranch()-&gt;label_set(&amp;fakeL, 0);</span>
<span class="line-removed"> 616   } else if (n-&gt;is_MachProlog()) {</span>
<span class="line-removed"> 617     saveL = ((MachPrologNode*)n)-&gt;_verified_entry;</span>
<span class="line-removed"> 618     ((MachPrologNode*)n)-&gt;_verified_entry = &amp;fakeL;</span>
<span class="line-removed"> 619   } else if (n-&gt;is_MachVEP()) {</span>
<span class="line-removed"> 620     saveL = ((MachVEPNode*)n)-&gt;_verified_entry;</span>
<span class="line-removed"> 621     ((MachVEPNode*)n)-&gt;_verified_entry = &amp;fakeL;</span>
<span class="line-removed"> 622   }</span>
<span class="line-removed"> 623 </span>
<span class="line-removed"> 624   n-&gt;emit(buf, this-&gt;regalloc());</span>
<span class="line-removed"> 625 </span>
<span class="line-removed"> 626   // Emitting into the scratch buffer should not fail</span>
<span class="line-removed"> 627   assert (!failing(), &quot;Must not have pending failure. Reason is: %s&quot;, failure_reason());</span>
<span class="line-removed"> 628 </span>
<span class="line-removed"> 629   // Restore label.</span>
<span class="line-removed"> 630   if (is_branch) {</span>
<span class="line-removed"> 631     n-&gt;as_MachBranch()-&gt;label_set(saveL, save_bnum);</span>
<span class="line-removed"> 632   } else if (n-&gt;is_MachProlog()) {</span>
<span class="line-removed"> 633     ((MachPrologNode*)n)-&gt;_verified_entry = saveL;</span>
<span class="line-removed"> 634   } else if (n-&gt;is_MachVEP()) {</span>
<span class="line-removed"> 635     ((MachVEPNode*)n)-&gt;_verified_entry = saveL;</span>
<span class="line-removed"> 636   }</span>
<span class="line-removed"> 637 </span>
<span class="line-removed"> 638   // End scratch_emit_size section.</span>
<span class="line-removed"> 639   set_in_scratch_emit_size(false);</span>
<span class="line-removed"> 640 </span>
<span class="line-removed"> 641   return buf.insts_size();</span>
<span class="line-removed"> 642 }</span>
<span class="line-removed"> 643 </span>
<span class="line-removed"> 644 </span>
 645 // ============================================================================
 646 //------------------------------Compile standard-------------------------------
 647 debug_only( int Compile::_debug_idx = 100000; )
 648 
 649 // Compile a method.  entry_bci is -1 for normal compilations and indicates
 650 // the continuation bci for on stack replacement.
 651 
 652 
<span class="line-modified"> 653 Compile::Compile( ciEnv* ci_env, C2Compiler* compiler, ciMethod* target, int osr_bci,</span>
 654                   bool subsume_loads, bool do_escape_analysis, bool eliminate_boxing, DirectiveSet* directive)
 655                 : Phase(Compiler),
 656                   _compile_id(ci_env-&gt;compile_id()),
 657                   _save_argument_registers(false),
 658                   _subsume_loads(subsume_loads),
 659                   _do_escape_analysis(do_escape_analysis),
 660                   _eliminate_boxing(eliminate_boxing),
 661                   _method(target),
 662                   _entry_bci(osr_bci),
 663                   _stub_function(NULL),
 664                   _stub_name(NULL),
 665                   _stub_entry_point(NULL),
 666                   _max_node_limit(MaxNodeLimit),
<span class="line-removed"> 667                   _orig_pc_slot(0),</span>
<span class="line-removed"> 668                   _orig_pc_slot_offset_in_bytes(0),</span>
<span class="line-removed"> 669                   _sp_inc_slot(0),</span>
<span class="line-removed"> 670                   _sp_inc_slot_offset_in_bytes(0),</span>
 671                   _inlining_progress(false),
 672                   _inlining_incrementally(false),
 673                   _do_cleanup(false),
 674                   _has_reserved_stack_access(target-&gt;has_reserved_stack_access()),
 675 #ifndef PRODUCT
 676                   _trace_opto_output(directive-&gt;TraceOptoOutputOption),
 677                   _print_ideal(directive-&gt;PrintIdealOption),
 678 #endif
 679                   _has_method_handle_invokes(false),
 680                   _clinit_barrier_on_entry(false),
 681                   _comp_arena(mtCompiler),
 682                   _barrier_set_state(BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;create_barrier_state(comp_arena())),
 683                   _env(ci_env),
 684                   _directive(directive),
 685                   _log(ci_env-&gt;log()),
 686                   _failure_reason(NULL),
 687                   _congraph(NULL),
 688 #ifndef PRODUCT
 689                   _printer(IdealGraphPrinter::printer()),
 690 #endif
</pre>
<hr />
<pre>
 692                   _dead_node_count(0),
 693                   _node_arena(mtCompiler),
 694                   _old_arena(mtCompiler),
 695                   _mach_constant_base_node(NULL),
 696                   _Compile_types(mtCompiler),
 697                   _initial_gvn(NULL),
 698                   _for_igvn(NULL),
 699                   _warm_calls(NULL),
 700                   _late_inlines(comp_arena(), 2, 0, NULL),
 701                   _string_late_inlines(comp_arena(), 2, 0, NULL),
 702                   _boxing_late_inlines(comp_arena(), 2, 0, NULL),
 703                   _late_inlines_pos(0),
 704                   _number_of_mh_late_inlines(0),
 705                   _print_inlining_stream(NULL),
 706                   _print_inlining_list(NULL),
 707                   _print_inlining_idx(0),
 708                   _print_inlining_output(NULL),
 709                   _replay_inline_data(NULL),
 710                   _java_calls(0),
 711                   _inner_loops(0),
<span class="line-modified"> 712                   _interpreter_frame_size(0),</span>
<span class="line-removed"> 713                   _node_bundling_limit(0),</span>
<span class="line-removed"> 714                   _node_bundling_base(NULL),</span>
<span class="line-removed"> 715                   _code_buffer(&quot;Compile::Fill_buffer&quot;),</span>
<span class="line-removed"> 716                   _scratch_const_size(-1),</span>
<span class="line-removed"> 717                   _in_scratch_emit_size(false)</span>
 718 #ifndef PRODUCT
 719                   , _in_dump_cnt(0)
 720 #endif
 721 {
 722   C = this;
 723 #ifndef PRODUCT
 724   if (_printer != NULL) {
 725     _printer-&gt;set_compile(this);
 726   }
 727 #endif
 728   CompileWrapper cw(this);
 729 
 730   if (CITimeVerbose) {
 731     tty-&gt;print(&quot; &quot;);
 732     target-&gt;holder()-&gt;name()-&gt;print();
 733     tty-&gt;print(&quot;.&quot;);
 734     target-&gt;print_short_name();
 735     tty-&gt;print(&quot;  &quot;);
 736   }
 737   TraceTime t1(&quot;Total compilation time&quot;, &amp;_t_totalCompilation, CITime, CITimeVerbose);
</pre>
<hr />
<pre>
 913       xtty-&gt;tail(&quot;ideal&quot;);
 914     }
 915   }
 916 #endif
 917 
 918 #ifdef ASSERT
 919   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 920   bs-&gt;verify_gc_barriers(this, BarrierSetC2::BeforeCodeGen);
 921 #endif
 922 
 923   // Dump compilation data to replay it.
 924   if (directive-&gt;DumpReplayOption) {
 925     env()-&gt;dump_replay_data(_compile_id);
 926   }
 927   if (directive-&gt;DumpInlineOption &amp;&amp; (ilt() != NULL)) {
 928     env()-&gt;dump_inline_data(_compile_id);
 929   }
 930 
 931   // Now that we know the size of all the monitors we can add a fixed slot
 932   // for the original deopt pc.
<span class="line-modified"> 933 </span>
<span class="line-removed"> 934   _orig_pc_slot = fixed_slots();</span>
<span class="line-removed"> 935   int next_slot = _orig_pc_slot + (sizeof(address) / VMRegImpl::stack_slot_size);</span>
<span class="line-removed"> 936 </span>
 937   if (needs_stack_repair()) {
 938     // One extra slot for the special stack increment value
<span class="line-removed"> 939     _sp_inc_slot = next_slot;</span>
 940     next_slot += 2;
 941   }
<span class="line-removed"> 942 </span>
 943   set_fixed_slots(next_slot);
 944 
 945   // Compute when to use implicit null checks. Used by matching trap based
 946   // nodes and NullCheck optimization.
 947   set_allowed_deopt_reasons();
 948 
 949   // Now generate code
 950   Code_Gen();
<span class="line-removed"> 951   if (failing())  return;</span>
<span class="line-removed"> 952 </span>
<span class="line-removed"> 953   // Check if we want to skip execution of all compiled code.</span>
<span class="line-removed"> 954   {</span>
<span class="line-removed"> 955 #ifndef PRODUCT</span>
<span class="line-removed"> 956     if (OptoNoExecute) {</span>
<span class="line-removed"> 957       record_method_not_compilable(&quot;+OptoNoExecute&quot;);  // Flag as failed</span>
<span class="line-removed"> 958       return;</span>
<span class="line-removed"> 959     }</span>
<span class="line-removed"> 960 #endif</span>
<span class="line-removed"> 961     TracePhase tp(&quot;install_code&quot;, &amp;timers[_t_registerMethod]);</span>
<span class="line-removed"> 962 </span>
<span class="line-removed"> 963     if (is_osr_compilation()) {</span>
<span class="line-removed"> 964       _code_offsets.set_value(CodeOffsets::Verified_Entry, 0);</span>
<span class="line-removed"> 965       _code_offsets.set_value(CodeOffsets::OSR_Entry, _first_block_size);</span>
<span class="line-removed"> 966     } else {</span>
<span class="line-removed"> 967       _code_offsets.set_value(CodeOffsets::Verified_Entry, _first_block_size);</span>
<span class="line-removed"> 968       if (_code_offsets.value(CodeOffsets::Verified_Value_Entry) == -1) {</span>
<span class="line-removed"> 969         _code_offsets.set_value(CodeOffsets::Verified_Value_Entry, _first_block_size);</span>
<span class="line-removed"> 970       }</span>
<span class="line-removed"> 971       if (_code_offsets.value(CodeOffsets::Verified_Value_Entry_RO) == -1) {</span>
<span class="line-removed"> 972         _code_offsets.set_value(CodeOffsets::Verified_Value_Entry_RO, _first_block_size);</span>
<span class="line-removed"> 973       }</span>
<span class="line-removed"> 974       if (_code_offsets.value(CodeOffsets::Entry) == -1) {</span>
<span class="line-removed"> 975         _code_offsets.set_value(CodeOffsets::Entry, _first_block_size);</span>
<span class="line-removed"> 976       }</span>
<span class="line-removed"> 977       _code_offsets.set_value(CodeOffsets::OSR_Entry, 0);</span>
<span class="line-removed"> 978     }</span>
<span class="line-removed"> 979 </span>
<span class="line-removed"> 980     env()-&gt;register_method(_method, _entry_bci,</span>
<span class="line-removed"> 981                            &amp;_code_offsets,</span>
<span class="line-removed"> 982                            _orig_pc_slot_offset_in_bytes,</span>
<span class="line-removed"> 983                            code_buffer(),</span>
<span class="line-removed"> 984                            frame_size_in_words(), _oop_map_set,</span>
<span class="line-removed"> 985                            &amp;_handler_table, &amp;_inc_table,</span>
<span class="line-removed"> 986                            compiler,</span>
<span class="line-removed"> 987                            has_unsafe_access(),</span>
<span class="line-removed"> 988                            SharedRuntime::is_wide_vector(max_vector_size()),</span>
<span class="line-removed"> 989                            rtm_state()</span>
<span class="line-removed"> 990                            );</span>
<span class="line-removed"> 991 </span>
<span class="line-removed"> 992     if (log() != NULL) // Print code cache state into compiler log</span>
<span class="line-removed"> 993       log()-&gt;code_cache_state();</span>
<span class="line-removed"> 994   }</span>
 995 }
 996 
 997 //------------------------------Compile----------------------------------------
 998 // Compile a runtime stub
 999 Compile::Compile( ciEnv* ci_env,
1000                   TypeFunc_generator generator,
1001                   address stub_function,
1002                   const char *stub_name,
1003                   int is_fancy_jump,
1004                   bool pass_tls,
1005                   bool save_arg_registers,
1006                   bool return_pc,
1007                   DirectiveSet* directive)
1008   : Phase(Compiler),
1009     _compile_id(0),
1010     _save_argument_registers(save_arg_registers),
1011     _subsume_loads(true),
1012     _do_escape_analysis(false),
1013     _eliminate_boxing(false),
1014     _method(NULL),
1015     _entry_bci(InvocationEntryBci),
1016     _stub_function(stub_function),
1017     _stub_name(stub_name),
1018     _stub_entry_point(NULL),
1019     _max_node_limit(MaxNodeLimit),
<span class="line-removed">1020     _orig_pc_slot(0),</span>
<span class="line-removed">1021     _orig_pc_slot_offset_in_bytes(0),</span>
<span class="line-removed">1022     _sp_inc_slot(0),</span>
<span class="line-removed">1023     _sp_inc_slot_offset_in_bytes(0),</span>
1024     _inlining_progress(false),
1025     _inlining_incrementally(false),
1026     _has_reserved_stack_access(false),
1027 #ifndef PRODUCT
1028     _trace_opto_output(directive-&gt;TraceOptoOutputOption),
1029     _print_ideal(directive-&gt;PrintIdealOption),
1030 #endif
1031     _has_method_handle_invokes(false),
1032     _clinit_barrier_on_entry(false),
1033     _comp_arena(mtCompiler),
1034     _barrier_set_state(BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;create_barrier_state(comp_arena())),
1035     _env(ci_env),
1036     _directive(directive),
1037     _log(ci_env-&gt;log()),
1038     _failure_reason(NULL),
1039     _congraph(NULL),
1040 #ifndef PRODUCT
1041     _printer(NULL),
1042 #endif
1043     _dead_node_list(comp_arena()),
1044     _dead_node_count(0),
1045     _node_arena(mtCompiler),
1046     _old_arena(mtCompiler),
1047     _mach_constant_base_node(NULL),
1048     _Compile_types(mtCompiler),
1049     _initial_gvn(NULL),
1050     _for_igvn(NULL),
1051     _warm_calls(NULL),
1052     _number_of_mh_late_inlines(0),
1053     _print_inlining_stream(NULL),
1054     _print_inlining_list(NULL),
1055     _print_inlining_idx(0),
1056     _print_inlining_output(NULL),
1057     _replay_inline_data(NULL),
1058     _java_calls(0),
1059     _inner_loops(0),
1060     _interpreter_frame_size(0),
<span class="line-removed">1061     _node_bundling_limit(0),</span>
<span class="line-removed">1062     _node_bundling_base(NULL),</span>
<span class="line-removed">1063     _code_buffer(&quot;Compile::Fill_buffer&quot;),</span>
1064 #ifndef PRODUCT
1065     _in_dump_cnt(0),
1066 #endif
1067     _allowed_reasons(0) {
1068   C = this;
1069 
1070   TraceTime t1(NULL, &amp;_t_totalCompilation, CITime, false);
1071   TraceTime t2(NULL, &amp;_t_stubCompilation, CITime, false);
1072 
1073 #ifndef PRODUCT
1074   set_print_assembly(PrintFrameConverterAssembly);
1075   set_parsed_irreducible_loop(false);
1076 #else
1077   set_print_assembly(false); // Must initialize.
1078 #endif
1079   set_has_irreducible_loop(false); // no loops
1080 
1081   CompileWrapper cw(this);
1082   Init(/*AliasLevel=*/ 0);
1083   init_tf((*generator)());
1084 
1085   {
1086     // The following is a dummy for the sake of GraphKit::gen_stub
1087     Unique_Node_List for_igvn(comp_arena());
1088     set_for_igvn(&amp;for_igvn);  // not used, but some GraphKit guys push on this
1089     PhaseGVN gvn(Thread::current()-&gt;resource_area(),255);
1090     set_initial_gvn(&amp;gvn);    // not significant, but GraphKit guys use it pervasively
1091     gvn.transform_no_reclaim(top());
1092 
1093     GraphKit kit;
1094     kit.gen_stub(stub_function, stub_name, is_fancy_jump, pass_tls, return_pc);
1095   }
1096 
1097   NOT_PRODUCT( verify_graph_edges(); )
<span class="line-removed">1098   Code_Gen();</span>
<span class="line-removed">1099   if (failing())  return;</span>
<span class="line-removed">1100 </span>
<span class="line-removed">1101 </span>
<span class="line-removed">1102   // Entry point will be accessed using compile-&gt;stub_entry_point();</span>
<span class="line-removed">1103   if (code_buffer() == NULL) {</span>
<span class="line-removed">1104     Matcher::soft_match_failure();</span>
<span class="line-removed">1105   } else {</span>
<span class="line-removed">1106     if (PrintAssembly &amp;&amp; (WizardMode || Verbose))</span>
<span class="line-removed">1107       tty-&gt;print_cr(&quot;### Stub::%s&quot;, stub_name);</span>
<span class="line-removed">1108 </span>
<span class="line-removed">1109     if (!failing()) {</span>
<span class="line-removed">1110       assert(_fixed_slots == 0, &quot;no fixed slots used for runtime stubs&quot;);</span>
1111 
<span class="line-modified">1112       // Make the NMethod</span>
<span class="line-removed">1113       // For now we mark the frame as never safe for profile stackwalking</span>
<span class="line-removed">1114       RuntimeStub *rs = RuntimeStub::new_runtime_stub(stub_name,</span>
<span class="line-removed">1115                                                       code_buffer(),</span>
<span class="line-removed">1116                                                       CodeOffsets::frame_never_safe,</span>
<span class="line-removed">1117                                                       // _code_offsets.value(CodeOffsets::Frame_Complete),</span>
<span class="line-removed">1118                                                       frame_size_in_words(),</span>
<span class="line-removed">1119                                                       _oop_map_set,</span>
<span class="line-removed">1120                                                       save_arg_registers);</span>
<span class="line-removed">1121       assert(rs != NULL &amp;&amp; rs-&gt;is_runtime_stub(), &quot;sanity check&quot;);</span>
<span class="line-removed">1122 </span>
<span class="line-removed">1123       _stub_entry_point = rs-&gt;entry_point();</span>
<span class="line-removed">1124     }</span>
<span class="line-removed">1125   }</span>
1126 }
1127 
1128 //------------------------------Init-------------------------------------------
1129 // Prepare for a single compilation
1130 void Compile::Init(int aliaslevel) {
1131   _unique  = 0;
1132   _regalloc = NULL;
1133 
1134   _tf      = NULL;  // filled in later
1135   _top     = NULL;  // cached later
1136   _matcher = NULL;  // filled in later
1137   _cfg     = NULL;  // filled in later
1138 
1139   IA32_ONLY( set_24_bit_selection_and_mode(true, false); )
1140 
1141   _node_note_array = NULL;
1142   _default_node_notes = NULL;
1143   DEBUG_ONLY( _modified_nodes = NULL; ) // Used in Optimize()
1144 
1145   _immutable_memory = NULL; // filled in at first inquiry
</pre>
<hr />
<pre>
1243     for (int i = 0; i &lt; grow_ats; i++)  _alias_types[i] = &amp;ats[i];
1244   }
1245   // Initialize the first few types.
1246   _alias_types[AliasIdxTop]-&gt;Init(AliasIdxTop, NULL);
1247   _alias_types[AliasIdxBot]-&gt;Init(AliasIdxBot, TypePtr::BOTTOM);
1248   _alias_types[AliasIdxRaw]-&gt;Init(AliasIdxRaw, TypeRawPtr::BOTTOM);
1249   _num_alias_types = AliasIdxRaw+1;
1250   // Zero out the alias type cache.
1251   Copy::zero_to_bytes(_alias_cache, sizeof(_alias_cache));
1252   // A NULL adr_type hits in the cache right away.  Preload the right answer.
1253   probe_alias_cache(NULL)-&gt;_index = AliasIdxTop;
1254 
1255   _intrinsics = NULL;
1256   _macro_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1257   _predicate_opaqs = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1258   _expensive_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1259   _range_check_casts = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1260   _opaque4_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1261   _value_type_nodes = new (comp_arena()) Unique_Node_List(comp_arena());
1262   register_library_intrinsics();



1263 }
1264 
1265 //---------------------------init_start----------------------------------------
1266 // Install the StartNode on this compile object.
1267 void Compile::init_start(StartNode* s) {
1268   if (failing())
1269     return; // already failing
1270   assert(s == start(), &quot;&quot;);
1271 }
1272 
1273 /**
1274  * Return the &#39;StartNode&#39;. We must not have a pending failure, since the ideal graph
1275  * can be in an inconsistent state, i.e., we can get segmentation faults when traversing
1276  * the ideal graph.
1277  */
1278 StartNode* Compile::start() const {
1279   assert (!failing(), &quot;Must not have pending failure. Reason is: %s&quot;, failure_reason());
1280   for (DUIterator_Fast imax, i = root()-&gt;fast_outs(imax); i &lt; imax; i++) {
1281     Node* start = root()-&gt;fast_out(i);
1282     if (start-&gt;is_Start()) {
</pre>
<hr />
<pre>
1870       int field_offset = flat-&gt;is_aryptr()-&gt;field_offset().get();
1871       if (elemtype-&gt;isa_valuetype() &amp;&amp;
1872           elemtype-&gt;value_klass() != NULL &amp;&amp;
1873           field_offset != Type::OffsetBot) {
1874         ciValueKlass* vk = elemtype-&gt;value_klass();
1875         field_offset += vk-&gt;first_field_offset();
1876         field = vk-&gt;get_field_by_offset(field_offset, false);
1877       }
1878     }
1879     if (flat-&gt;isa_klassptr()) {
1880       if (flat-&gt;offset() == in_bytes(Klass::super_check_offset_offset()))
1881         alias_type(idx)-&gt;set_rewritable(false);
1882       if (flat-&gt;offset() == in_bytes(Klass::modifier_flags_offset()))
1883         alias_type(idx)-&gt;set_rewritable(false);
1884       if (flat-&gt;offset() == in_bytes(Klass::access_flags_offset()))
1885         alias_type(idx)-&gt;set_rewritable(false);
1886       if (flat-&gt;offset() == in_bytes(Klass::java_mirror_offset()))
1887         alias_type(idx)-&gt;set_rewritable(false);
1888       if (flat-&gt;offset() == in_bytes(Klass::layout_helper_offset()))
1889         alias_type(idx)-&gt;set_rewritable(false);


1890     }
1891     // %%% (We would like to finalize JavaThread::threadObj_offset(),
1892     // but the base pointer type is not distinctive enough to identify
1893     // references into JavaThread.)
1894 
1895     // Check for final fields.
1896     const TypeInstPtr* tinst = flat-&gt;isa_instptr();
1897     if (tinst &amp;&amp; tinst-&gt;offset() &gt;= instanceOopDesc::base_offset_in_bytes()) {
1898       if (tinst-&gt;const_oop() != NULL &amp;&amp;
1899           tinst-&gt;klass() == ciEnv::current()-&gt;Class_klass() &amp;&amp;
1900           tinst-&gt;offset() &gt;= (tinst-&gt;klass()-&gt;as_instance_klass()-&gt;size_helper() * wordSize)) {
1901         // static field
1902         ciInstanceKlass* k = tinst-&gt;const_oop()-&gt;as_instance()-&gt;java_lang_Class_klass()-&gt;as_instance_klass();
1903         field = k-&gt;get_field_by_offset(tinst-&gt;offset(), true);
1904       } else if (tinst-&gt;klass()-&gt;is_valuetype()) {
1905         // Value type field
1906         ciValueKlass* vk = tinst-&gt;value_klass();
1907         field = vk-&gt;get_field_by_offset(tinst-&gt;offset(), false);
1908       } else {
1909         ciInstanceKlass* k = tinst-&gt;klass()-&gt;as_instance_klass();
</pre>
<hr />
<pre>
1977   if (alias_idx == AliasIdxBot)         return true;  // the universal category
1978   if (adr_type == NULL)                 return true;  // NULL serves as TypePtr::TOP
1979   if (alias_idx == AliasIdxTop)         return false; // the empty category
1980   if (adr_type-&gt;base() == Type::AnyPtr) return false; // TypePtr::BOTTOM or its twins
1981 
1982   // the only remaining possible overlap is identity
1983   int adr_idx = get_alias_index(adr_type);
1984   assert(adr_idx != AliasIdxBot &amp;&amp; adr_idx != AliasIdxTop, &quot;&quot;);
1985   assert(adr_idx == alias_idx ||
1986          (alias_type(alias_idx)-&gt;adr_type() != TypeOopPtr::BOTTOM
1987           &amp;&amp; adr_type                       != TypeOopPtr::BOTTOM),
1988          &quot;should not be testing for overlap with an unsafe pointer&quot;);
1989   return adr_idx == alias_idx;
1990 }
1991 
1992 //------------------------------can_alias--------------------------------------
1993 // True if any values of the given address type are in the given alias category.
1994 bool Compile::can_alias(const TypePtr* adr_type, int alias_idx) {
1995   if (alias_idx == AliasIdxTop)         return false; // the empty category
1996   if (adr_type == NULL)                 return false; // NULL serves as TypePtr::TOP
<span class="line-modified">1997   if (alias_idx == AliasIdxBot)         return true;  // the universal category</span>
<span class="line-modified">1998   if (adr_type-&gt;base() == Type::AnyPtr) return true;  // TypePtr::BOTTOM or its twins</span>

1999 
2000   // the only remaining possible overlap is identity
2001   int adr_idx = get_alias_index(adr_type);
2002   assert(adr_idx != AliasIdxBot &amp;&amp; adr_idx != AliasIdxTop, &quot;&quot;);
2003   return adr_idx == alias_idx;
2004 }
2005 
2006 
2007 
2008 //---------------------------pop_warm_call-------------------------------------
2009 WarmCallInfo* Compile::pop_warm_call() {
2010   WarmCallInfo* wci = _warm_calls;
2011   if (wci != NULL)  _warm_calls = wci-&gt;remove_from(wci);
2012   return wci;
2013 }
2014 
2015 //----------------------------Inline_Warm--------------------------------------
2016 int Compile::Inline_Warm() {
2017   // If there is room, try to inline some more warm call sites.
2018   // %%% Do a graph index compaction pass when we think we&#39;re out of space?
</pre>
<hr />
<pre>
2964       cfg.set_loop_alignment();
2965     }
2966     cfg.fixup_flow();
2967   }
2968 
2969   // Apply peephole optimizations
2970   if( OptoPeephole ) {
2971     TracePhase tp(&quot;peephole&quot;, &amp;timers[_t_peephole]);
2972     PhasePeephole peep( _regalloc, cfg);
2973     peep.do_transform();
2974   }
2975 
2976   // Do late expand if CPU requires this.
2977   if (Matcher::require_postalloc_expand) {
2978     TracePhase tp(&quot;postalloc_expand&quot;, &amp;timers[_t_postalloc_expand]);
2979     cfg.postalloc_expand(_regalloc);
2980   }
2981 
2982   // Convert Nodes to instruction bits in a buffer
2983   {
<span class="line-modified">2984     TraceTime tp(&quot;output&quot;, &amp;timers[_t_output], CITime);</span>
<span class="line-modified">2985     Output();</span>



2986   }
2987 
2988   print_method(PHASE_FINAL_CODE);
2989 
2990   // He&#39;s dead, Jim.
2991   _cfg     = (PhaseCFG*)((intptr_t)0xdeadbeef);
2992   _regalloc = (PhaseChaitin*)((intptr_t)0xdeadbeef);
2993 }
2994 
<span class="line-removed">2995 </span>
<span class="line-removed">2996 //------------------------------dump_asm---------------------------------------</span>
<span class="line-removed">2997 // Dump formatted assembly</span>
<span class="line-removed">2998 #if defined(SUPPORT_OPTO_ASSEMBLY)</span>
<span class="line-removed">2999 void Compile::dump_asm_on(outputStream* st, int* pcs, uint pc_limit) {</span>
<span class="line-removed">3000 </span>
<span class="line-removed">3001   int pc_digits = 3; // #chars required for pc</span>
<span class="line-removed">3002   int sb_chars  = 3; // #chars for &quot;start bundle&quot; indicator</span>
<span class="line-removed">3003   int tab_size  = 8;</span>
<span class="line-removed">3004   if (pcs != NULL) {</span>
<span class="line-removed">3005     int max_pc = 0;</span>
<span class="line-removed">3006     for (uint i = 0; i &lt; pc_limit; i++) {</span>
<span class="line-removed">3007       max_pc = (max_pc &lt; pcs[i]) ? pcs[i] : max_pc;</span>
<span class="line-removed">3008     }</span>
<span class="line-removed">3009     pc_digits  = ((max_pc &lt; 4096) ? 3 : ((max_pc &lt; 65536) ? 4 : ((max_pc &lt; 65536*256) ? 6 : 8))); // #chars required for pc</span>
<span class="line-removed">3010   }</span>
<span class="line-removed">3011   int prefix_len = ((pc_digits + sb_chars + tab_size - 1)/tab_size)*tab_size;</span>
<span class="line-removed">3012 </span>
<span class="line-removed">3013   bool cut_short = false;</span>
<span class="line-removed">3014   st-&gt;print_cr(&quot;#&quot;);</span>
<span class="line-removed">3015   st-&gt;print(&quot;#  &quot;);  _tf-&gt;dump_on(st);  st-&gt;cr();</span>
<span class="line-removed">3016   st-&gt;print_cr(&quot;#&quot;);</span>
<span class="line-removed">3017 </span>
<span class="line-removed">3018   // For all blocks</span>
<span class="line-removed">3019   int pc = 0x0;                 // Program counter</span>
<span class="line-removed">3020   char starts_bundle = &#39; &#39;;</span>
<span class="line-removed">3021   _regalloc-&gt;dump_frame();</span>
<span class="line-removed">3022 </span>
<span class="line-removed">3023   Node *n = NULL;</span>
<span class="line-removed">3024   for (uint i = 0; i &lt; _cfg-&gt;number_of_blocks(); i++) {</span>
<span class="line-removed">3025     if (VMThread::should_terminate()) {</span>
<span class="line-removed">3026       cut_short = true;</span>
<span class="line-removed">3027       break;</span>
<span class="line-removed">3028     }</span>
<span class="line-removed">3029     Block* block = _cfg-&gt;get_block(i);</span>
<span class="line-removed">3030     if (block-&gt;is_connector() &amp;&amp; !Verbose) {</span>
<span class="line-removed">3031       continue;</span>
<span class="line-removed">3032     }</span>
<span class="line-removed">3033     n = block-&gt;head();</span>
<span class="line-removed">3034     if ((pcs != NULL) &amp;&amp; (n-&gt;_idx &lt; pc_limit)) {</span>
<span class="line-removed">3035       pc = pcs[n-&gt;_idx];</span>
<span class="line-removed">3036       st-&gt;print(&quot;%*.*x&quot;, pc_digits, pc_digits, pc);</span>
<span class="line-removed">3037     }</span>
<span class="line-removed">3038     st-&gt;fill_to(prefix_len);</span>
<span class="line-removed">3039     block-&gt;dump_head(_cfg, st);</span>
<span class="line-removed">3040     if (block-&gt;is_connector()) {</span>
<span class="line-removed">3041       st-&gt;fill_to(prefix_len);</span>
<span class="line-removed">3042       st-&gt;print_cr(&quot;# Empty connector block&quot;);</span>
<span class="line-removed">3043     } else if (block-&gt;num_preds() == 2 &amp;&amp; block-&gt;pred(1)-&gt;is_CatchProj() &amp;&amp; block-&gt;pred(1)-&gt;as_CatchProj()-&gt;_con == CatchProjNode::fall_through_index) {</span>
<span class="line-removed">3044       st-&gt;fill_to(prefix_len);</span>
<span class="line-removed">3045       st-&gt;print_cr(&quot;# Block is sole successor of call&quot;);</span>
<span class="line-removed">3046     }</span>
<span class="line-removed">3047 </span>
<span class="line-removed">3048     // For all instructions</span>
<span class="line-removed">3049     Node *delay = NULL;</span>
<span class="line-removed">3050     for (uint j = 0; j &lt; block-&gt;number_of_nodes(); j++) {</span>
<span class="line-removed">3051       if (VMThread::should_terminate()) {</span>
<span class="line-removed">3052         cut_short = true;</span>
<span class="line-removed">3053         break;</span>
<span class="line-removed">3054       }</span>
<span class="line-removed">3055       n = block-&gt;get_node(j);</span>
<span class="line-removed">3056       if (valid_bundle_info(n)) {</span>
<span class="line-removed">3057         Bundle* bundle = node_bundling(n);</span>
<span class="line-removed">3058         if (bundle-&gt;used_in_unconditional_delay()) {</span>
<span class="line-removed">3059           delay = n;</span>
<span class="line-removed">3060           continue;</span>
<span class="line-removed">3061         }</span>
<span class="line-removed">3062         if (bundle-&gt;starts_bundle()) {</span>
<span class="line-removed">3063           starts_bundle = &#39;+&#39;;</span>
<span class="line-removed">3064         }</span>
<span class="line-removed">3065       }</span>
<span class="line-removed">3066 </span>
<span class="line-removed">3067       if (WizardMode) {</span>
<span class="line-removed">3068         n-&gt;dump();</span>
<span class="line-removed">3069       }</span>
<span class="line-removed">3070 </span>
<span class="line-removed">3071       if( !n-&gt;is_Region() &amp;&amp;    // Dont print in the Assembly</span>
<span class="line-removed">3072           !n-&gt;is_Phi() &amp;&amp;       // a few noisely useless nodes</span>
<span class="line-removed">3073           !n-&gt;is_Proj() &amp;&amp;</span>
<span class="line-removed">3074           !n-&gt;is_MachTemp() &amp;&amp;</span>
<span class="line-removed">3075           !n-&gt;is_SafePointScalarObject() &amp;&amp;</span>
<span class="line-removed">3076           !n-&gt;is_Catch() &amp;&amp;     // Would be nice to print exception table targets</span>
<span class="line-removed">3077           !n-&gt;is_MergeMem() &amp;&amp;  // Not very interesting</span>
<span class="line-removed">3078           !n-&gt;is_top() &amp;&amp;       // Debug info table constants</span>
<span class="line-removed">3079           !(n-&gt;is_Con() &amp;&amp; !n-&gt;is_Mach())// Debug info table constants</span>
<span class="line-removed">3080           ) {</span>
<span class="line-removed">3081         if ((pcs != NULL) &amp;&amp; (n-&gt;_idx &lt; pc_limit)) {</span>
<span class="line-removed">3082           pc = pcs[n-&gt;_idx];</span>
<span class="line-removed">3083           st-&gt;print(&quot;%*.*x&quot;, pc_digits, pc_digits, pc);</span>
<span class="line-removed">3084         } else {</span>
<span class="line-removed">3085           st-&gt;fill_to(pc_digits);</span>
<span class="line-removed">3086         }</span>
<span class="line-removed">3087         st-&gt;print(&quot; %c &quot;, starts_bundle);</span>
<span class="line-removed">3088         starts_bundle = &#39; &#39;;</span>
<span class="line-removed">3089         st-&gt;fill_to(prefix_len);</span>
<span class="line-removed">3090         n-&gt;format(_regalloc, st);</span>
<span class="line-removed">3091         st-&gt;cr();</span>
<span class="line-removed">3092       }</span>
<span class="line-removed">3093 </span>
<span class="line-removed">3094       // If we have an instruction with a delay slot, and have seen a delay,</span>
<span class="line-removed">3095       // then back up and print it</span>
<span class="line-removed">3096       if (valid_bundle_info(n) &amp;&amp; node_bundling(n)-&gt;use_unconditional_delay()) {</span>
<span class="line-removed">3097         // Coverity finding - Explicit null dereferenced.</span>
<span class="line-removed">3098         guarantee(delay != NULL, &quot;no unconditional delay instruction&quot;);</span>
<span class="line-removed">3099         if (WizardMode) delay-&gt;dump();</span>
<span class="line-removed">3100 </span>
<span class="line-removed">3101         if (node_bundling(delay)-&gt;starts_bundle())</span>
<span class="line-removed">3102           starts_bundle = &#39;+&#39;;</span>
<span class="line-removed">3103         if ((pcs != NULL) &amp;&amp; (n-&gt;_idx &lt; pc_limit)) {</span>
<span class="line-removed">3104           pc = pcs[n-&gt;_idx];</span>
<span class="line-removed">3105           st-&gt;print(&quot;%*.*x&quot;, pc_digits, pc_digits, pc);</span>
<span class="line-removed">3106         } else {</span>
<span class="line-removed">3107           st-&gt;fill_to(pc_digits);</span>
<span class="line-removed">3108         }</span>
<span class="line-removed">3109         st-&gt;print(&quot; %c &quot;, starts_bundle);</span>
<span class="line-removed">3110         starts_bundle = &#39; &#39;;</span>
<span class="line-removed">3111         st-&gt;fill_to(prefix_len);</span>
<span class="line-removed">3112         delay-&gt;format(_regalloc, st);</span>
<span class="line-removed">3113         st-&gt;cr();</span>
<span class="line-removed">3114         delay = NULL;</span>
<span class="line-removed">3115       }</span>
<span class="line-removed">3116 </span>
<span class="line-removed">3117       // Dump the exception table as well</span>
<span class="line-removed">3118       if( n-&gt;is_Catch() &amp;&amp; (Verbose || WizardMode) ) {</span>
<span class="line-removed">3119         // Print the exception table for this offset</span>
<span class="line-removed">3120         _handler_table.print_subtable_for(pc);</span>
<span class="line-removed">3121       }</span>
<span class="line-removed">3122       st-&gt;bol(); // Make sure we start on a new line</span>
<span class="line-removed">3123     }</span>
<span class="line-removed">3124     st-&gt;cr(); // one empty line between blocks</span>
<span class="line-removed">3125     assert(cut_short || delay == NULL, &quot;no unconditional delay branch&quot;);</span>
<span class="line-removed">3126   } // End of per-block dump</span>
<span class="line-removed">3127 </span>
<span class="line-removed">3128   if (cut_short)  st-&gt;print_cr(&quot;*** disassembly is cut short ***&quot;);</span>
<span class="line-removed">3129 }</span>
<span class="line-removed">3130 #endif</span>
<span class="line-removed">3131 </span>
3132 //------------------------------Final_Reshape_Counts---------------------------
3133 // This class defines counters to help identify when a method
3134 // may/must be executed using hardware with only 24-bit precision.
3135 struct Final_Reshape_Counts : public StackObj {
3136   int  _call_count;             // count non-inlined &#39;common&#39; calls
3137   int  _float_count;            // count float ops requiring 24-bit precision
3138   int  _double_count;           // count double ops requiring more precision
3139   int  _java_call_count;        // count non-inlined &#39;java&#39; calls
3140   int  _inner_loop_count;       // count loops which need alignment
3141   VectorSet _visited;           // Visitation flags
3142   Node_List _tests;             // Set of IfNodes &amp; PCTableNodes
3143 
3144   Final_Reshape_Counts() :
3145     _call_count(0), _float_count(0), _double_count(0),
3146     _java_call_count(0), _inner_loop_count(0),
3147     _visited( Thread::current()-&gt;resource_area() ) { }
3148 
3149   void inc_call_count  () { _call_count  ++; }
3150   void inc_float_count () { _float_count ++; }
3151   void inc_double_count() { _double_count++; }
</pre>
<hr />
<pre>
3835           n-&gt;subsume_by(sub, this);
3836         }
3837       }
3838     }
3839     break;
3840 
3841   case Op_LoadVector:
3842   case Op_StoreVector:
3843     break;
3844 
3845   case Op_AddReductionVI:
3846   case Op_AddReductionVL:
3847   case Op_AddReductionVF:
3848   case Op_AddReductionVD:
3849   case Op_MulReductionVI:
3850   case Op_MulReductionVL:
3851   case Op_MulReductionVF:
3852   case Op_MulReductionVD:
3853   case Op_MinReductionV:
3854   case Op_MaxReductionV:



3855     break;
3856 
3857   case Op_PackB:
3858   case Op_PackS:
3859   case Op_PackI:
3860   case Op_PackF:
3861   case Op_PackL:
3862   case Op_PackD:
3863     if (n-&gt;req()-1 &gt; 2) {
3864       // Replace many operand PackNodes with a binary tree for matching
3865       PackNode* p = (PackNode*) n;
3866       Node* btp = p-&gt;binary_tree_pack(1, n-&gt;req());
3867       n-&gt;subsume_by(btp, this);
3868     }
3869     break;
3870   case Op_Loop:
3871   case Op_CountedLoop:
3872   case Op_OuterStripMinedLoop:
3873     if (n-&gt;as_Loop()-&gt;is_inner_loop()) {
3874       frc.inc_inner_loop_count();
</pre>
<hr />
<pre>
4473   } else {
4474     _log = NULL;
4475   }
4476 
4477 #ifdef ASSERT
4478   if (PrintIdealNodeCount) {
4479     tty-&gt;print_cr(&quot;phase name=&#39;%s&#39; nodes=&#39;%d&#39; live=&#39;%d&#39; live_graph_walk=&#39;%d&#39;&quot;,
4480                   _phase_name, C-&gt;unique(), C-&gt;live_nodes(), C-&gt;count_live_nodes_by_graph_walk());
4481   }
4482 
4483   if (VerifyIdealNodeCount) {
4484     Compile::current()-&gt;print_missing_nodes();
4485   }
4486 #endif
4487 
4488   if (_log != NULL) {
4489     _log-&gt;done(&quot;phase name=&#39;%s&#39; nodes=&#39;%d&#39; live=&#39;%d&#39;&quot;, _phase_name, C-&gt;unique(), C-&gt;live_nodes());
4490   }
4491 }
4492 
<span class="line-removed">4493 //=============================================================================</span>
<span class="line-removed">4494 // Two Constant&#39;s are equal when the type and the value are equal.</span>
<span class="line-removed">4495 bool Compile::Constant::operator==(const Constant&amp; other) {</span>
<span class="line-removed">4496   if (type()          != other.type()         )  return false;</span>
<span class="line-removed">4497   if (can_be_reused() != other.can_be_reused())  return false;</span>
<span class="line-removed">4498   // For floating point values we compare the bit pattern.</span>
<span class="line-removed">4499   switch (type()) {</span>
<span class="line-removed">4500   case T_INT:</span>
<span class="line-removed">4501   case T_FLOAT:   return (_v._value.i == other._v._value.i);</span>
<span class="line-removed">4502   case T_LONG:</span>
<span class="line-removed">4503   case T_DOUBLE:  return (_v._value.j == other._v._value.j);</span>
<span class="line-removed">4504   case T_OBJECT:</span>
<span class="line-removed">4505   case T_ADDRESS: return (_v._value.l == other._v._value.l);</span>
<span class="line-removed">4506   case T_VOID:    return (_v._value.l == other._v._value.l);  // jump-table entries</span>
<span class="line-removed">4507   case T_METADATA: return (_v._metadata == other._v._metadata);</span>
<span class="line-removed">4508   default: ShouldNotReachHere(); return false;</span>
<span class="line-removed">4509   }</span>
<span class="line-removed">4510 }</span>
<span class="line-removed">4511 </span>
<span class="line-removed">4512 static int type_to_size_in_bytes(BasicType t) {</span>
<span class="line-removed">4513   switch (t) {</span>
<span class="line-removed">4514   case T_INT:     return sizeof(jint   );</span>
<span class="line-removed">4515   case T_LONG:    return sizeof(jlong  );</span>
<span class="line-removed">4516   case T_FLOAT:   return sizeof(jfloat );</span>
<span class="line-removed">4517   case T_DOUBLE:  return sizeof(jdouble);</span>
<span class="line-removed">4518   case T_METADATA: return sizeof(Metadata*);</span>
<span class="line-removed">4519     // We use T_VOID as marker for jump-table entries (labels) which</span>
<span class="line-removed">4520     // need an internal word relocation.</span>
<span class="line-removed">4521   case T_VOID:</span>
<span class="line-removed">4522   case T_ADDRESS:</span>
<span class="line-removed">4523   case T_OBJECT:  return sizeof(jobject);</span>
<span class="line-removed">4524   default:</span>
<span class="line-removed">4525     ShouldNotReachHere();</span>
<span class="line-removed">4526     return -1;</span>
<span class="line-removed">4527   }</span>
<span class="line-removed">4528 }</span>
<span class="line-removed">4529 </span>
<span class="line-removed">4530 int Compile::ConstantTable::qsort_comparator(Constant* a, Constant* b) {</span>
<span class="line-removed">4531   // sort descending</span>
<span class="line-removed">4532   if (a-&gt;freq() &gt; b-&gt;freq())  return -1;</span>
<span class="line-removed">4533   if (a-&gt;freq() &lt; b-&gt;freq())  return  1;</span>
<span class="line-removed">4534   return 0;</span>
<span class="line-removed">4535 }</span>
<span class="line-removed">4536 </span>
<span class="line-removed">4537 void Compile::ConstantTable::calculate_offsets_and_size() {</span>
<span class="line-removed">4538   // First, sort the array by frequencies.</span>
<span class="line-removed">4539   _constants.sort(qsort_comparator);</span>
<span class="line-removed">4540 </span>
<span class="line-removed">4541 #ifdef ASSERT</span>
<span class="line-removed">4542   // Make sure all jump-table entries were sorted to the end of the</span>
<span class="line-removed">4543   // array (they have a negative frequency).</span>
<span class="line-removed">4544   bool found_void = false;</span>
<span class="line-removed">4545   for (int i = 0; i &lt; _constants.length(); i++) {</span>
<span class="line-removed">4546     Constant con = _constants.at(i);</span>
<span class="line-removed">4547     if (con.type() == T_VOID)</span>
<span class="line-removed">4548       found_void = true;  // jump-tables</span>
<span class="line-removed">4549     else</span>
<span class="line-removed">4550       assert(!found_void, &quot;wrong sorting&quot;);</span>
<span class="line-removed">4551   }</span>
<span class="line-removed">4552 #endif</span>
<span class="line-removed">4553 </span>
<span class="line-removed">4554   int offset = 0;</span>
<span class="line-removed">4555   for (int i = 0; i &lt; _constants.length(); i++) {</span>
<span class="line-removed">4556     Constant* con = _constants.adr_at(i);</span>
<span class="line-removed">4557 </span>
<span class="line-removed">4558     // Align offset for type.</span>
<span class="line-removed">4559     int typesize = type_to_size_in_bytes(con-&gt;type());</span>
<span class="line-removed">4560     offset = align_up(offset, typesize);</span>
<span class="line-removed">4561     con-&gt;set_offset(offset);   // set constant&#39;s offset</span>
<span class="line-removed">4562 </span>
<span class="line-removed">4563     if (con-&gt;type() == T_VOID) {</span>
<span class="line-removed">4564       MachConstantNode* n = (MachConstantNode*) con-&gt;get_jobject();</span>
<span class="line-removed">4565       offset = offset + typesize * n-&gt;outcnt();  // expand jump-table</span>
<span class="line-removed">4566     } else {</span>
<span class="line-removed">4567       offset = offset + typesize;</span>
<span class="line-removed">4568     }</span>
<span class="line-removed">4569   }</span>
<span class="line-removed">4570 </span>
<span class="line-removed">4571   // Align size up to the next section start (which is insts; see</span>
<span class="line-removed">4572   // CodeBuffer::align_at_start).</span>
<span class="line-removed">4573   assert(_size == -1, &quot;already set?&quot;);</span>
<span class="line-removed">4574   _size = align_up(offset, (int)CodeEntryAlignment);</span>
<span class="line-removed">4575 }</span>
<span class="line-removed">4576 </span>
<span class="line-removed">4577 void Compile::ConstantTable::emit(CodeBuffer&amp; cb) {</span>
<span class="line-removed">4578   MacroAssembler _masm(&amp;cb);</span>
<span class="line-removed">4579   for (int i = 0; i &lt; _constants.length(); i++) {</span>
<span class="line-removed">4580     Constant con = _constants.at(i);</span>
<span class="line-removed">4581     address constant_addr = NULL;</span>
<span class="line-removed">4582     switch (con.type()) {</span>
<span class="line-removed">4583     case T_INT:    constant_addr = _masm.int_constant(   con.get_jint()   ); break;</span>
<span class="line-removed">4584     case T_LONG:   constant_addr = _masm.long_constant(  con.get_jlong()  ); break;</span>
<span class="line-removed">4585     case T_FLOAT:  constant_addr = _masm.float_constant( con.get_jfloat() ); break;</span>
<span class="line-removed">4586     case T_DOUBLE: constant_addr = _masm.double_constant(con.get_jdouble()); break;</span>
<span class="line-removed">4587     case T_OBJECT: {</span>
<span class="line-removed">4588       jobject obj = con.get_jobject();</span>
<span class="line-removed">4589       int oop_index = _masm.oop_recorder()-&gt;find_index(obj);</span>
<span class="line-removed">4590       constant_addr = _masm.address_constant((address) obj, oop_Relocation::spec(oop_index));</span>
<span class="line-removed">4591       break;</span>
<span class="line-removed">4592     }</span>
<span class="line-removed">4593     case T_ADDRESS: {</span>
<span class="line-removed">4594       address addr = (address) con.get_jobject();</span>
<span class="line-removed">4595       constant_addr = _masm.address_constant(addr);</span>
<span class="line-removed">4596       break;</span>
<span class="line-removed">4597     }</span>
<span class="line-removed">4598     // We use T_VOID as marker for jump-table entries (labels) which</span>
<span class="line-removed">4599     // need an internal word relocation.</span>
<span class="line-removed">4600     case T_VOID: {</span>
<span class="line-removed">4601       MachConstantNode* n = (MachConstantNode*) con.get_jobject();</span>
<span class="line-removed">4602       // Fill the jump-table with a dummy word.  The real value is</span>
<span class="line-removed">4603       // filled in later in fill_jump_table.</span>
<span class="line-removed">4604       address dummy = (address) n;</span>
<span class="line-removed">4605       constant_addr = _masm.address_constant(dummy);</span>
<span class="line-removed">4606       // Expand jump-table</span>
<span class="line-removed">4607       for (uint i = 1; i &lt; n-&gt;outcnt(); i++) {</span>
<span class="line-removed">4608         address temp_addr = _masm.address_constant(dummy + i);</span>
<span class="line-removed">4609         assert(temp_addr, &quot;consts section too small&quot;);</span>
<span class="line-removed">4610       }</span>
<span class="line-removed">4611       break;</span>
<span class="line-removed">4612     }</span>
<span class="line-removed">4613     case T_METADATA: {</span>
<span class="line-removed">4614       Metadata* obj = con.get_metadata();</span>
<span class="line-removed">4615       int metadata_index = _masm.oop_recorder()-&gt;find_index(obj);</span>
<span class="line-removed">4616       constant_addr = _masm.address_constant((address) obj, metadata_Relocation::spec(metadata_index));</span>
<span class="line-removed">4617       break;</span>
<span class="line-removed">4618     }</span>
<span class="line-removed">4619     default: ShouldNotReachHere();</span>
<span class="line-removed">4620     }</span>
<span class="line-removed">4621     assert(constant_addr, &quot;consts section too small&quot;);</span>
<span class="line-removed">4622     assert((constant_addr - _masm.code()-&gt;consts()-&gt;start()) == con.offset(),</span>
<span class="line-removed">4623             &quot;must be: %d == %d&quot;, (int) (constant_addr - _masm.code()-&gt;consts()-&gt;start()), (int)(con.offset()));</span>
<span class="line-removed">4624   }</span>
<span class="line-removed">4625 }</span>
<span class="line-removed">4626 </span>
<span class="line-removed">4627 int Compile::ConstantTable::find_offset(Constant&amp; con) const {</span>
<span class="line-removed">4628   int idx = _constants.find(con);</span>
<span class="line-removed">4629   guarantee(idx != -1, &quot;constant must be in constant table&quot;);</span>
<span class="line-removed">4630   int offset = _constants.at(idx).offset();</span>
<span class="line-removed">4631   guarantee(offset != -1, &quot;constant table not emitted yet?&quot;);</span>
<span class="line-removed">4632   return offset;</span>
<span class="line-removed">4633 }</span>
<span class="line-removed">4634 </span>
<span class="line-removed">4635 void Compile::ConstantTable::add(Constant&amp; con) {</span>
<span class="line-removed">4636   if (con.can_be_reused()) {</span>
<span class="line-removed">4637     int idx = _constants.find(con);</span>
<span class="line-removed">4638     if (idx != -1 &amp;&amp; _constants.at(idx).can_be_reused()) {</span>
<span class="line-removed">4639       _constants.adr_at(idx)-&gt;inc_freq(con.freq());  // increase the frequency by the current value</span>
<span class="line-removed">4640       return;</span>
<span class="line-removed">4641     }</span>
<span class="line-removed">4642   }</span>
<span class="line-removed">4643   (void) _constants.append(con);</span>
<span class="line-removed">4644 }</span>
<span class="line-removed">4645 </span>
<span class="line-removed">4646 Compile::Constant Compile::ConstantTable::add(MachConstantNode* n, BasicType type, jvalue value) {</span>
<span class="line-removed">4647   Block* b = Compile::current()-&gt;cfg()-&gt;get_block_for_node(n);</span>
<span class="line-removed">4648   Constant con(type, value, b-&gt;_freq);</span>
<span class="line-removed">4649   add(con);</span>
<span class="line-removed">4650   return con;</span>
<span class="line-removed">4651 }</span>
<span class="line-removed">4652 </span>
<span class="line-removed">4653 Compile::Constant Compile::ConstantTable::add(Metadata* metadata) {</span>
<span class="line-removed">4654   Constant con(metadata);</span>
<span class="line-removed">4655   add(con);</span>
<span class="line-removed">4656   return con;</span>
<span class="line-removed">4657 }</span>
<span class="line-removed">4658 </span>
<span class="line-removed">4659 Compile::Constant Compile::ConstantTable::add(MachConstantNode* n, MachOper* oper) {</span>
<span class="line-removed">4660   jvalue value;</span>
<span class="line-removed">4661   BasicType type = oper-&gt;type()-&gt;basic_type();</span>
<span class="line-removed">4662   switch (type) {</span>
<span class="line-removed">4663   case T_LONG:    value.j = oper-&gt;constantL(); break;</span>
<span class="line-removed">4664   case T_FLOAT:   value.f = oper-&gt;constantF(); break;</span>
<span class="line-removed">4665   case T_DOUBLE:  value.d = oper-&gt;constantD(); break;</span>
<span class="line-removed">4666   case T_OBJECT:</span>
<span class="line-removed">4667   case T_ADDRESS: value.l = (jobject) oper-&gt;constant(); break;</span>
<span class="line-removed">4668   case T_METADATA: return add((Metadata*)oper-&gt;constant()); break;</span>
<span class="line-removed">4669   default: guarantee(false, &quot;unhandled type: %s&quot;, type2name(type));</span>
<span class="line-removed">4670   }</span>
<span class="line-removed">4671   return add(n, type, value);</span>
<span class="line-removed">4672 }</span>
<span class="line-removed">4673 </span>
<span class="line-removed">4674 Compile::Constant Compile::ConstantTable::add_jump_table(MachConstantNode* n) {</span>
<span class="line-removed">4675   jvalue value;</span>
<span class="line-removed">4676   // We can use the node pointer here to identify the right jump-table</span>
<span class="line-removed">4677   // as this method is called from Compile::Fill_buffer right before</span>
<span class="line-removed">4678   // the MachNodes are emitted and the jump-table is filled (means the</span>
<span class="line-removed">4679   // MachNode pointers do not change anymore).</span>
<span class="line-removed">4680   value.l = (jobject) n;</span>
<span class="line-removed">4681   Constant con(T_VOID, value, next_jump_table_freq(), false);  // Labels of a jump-table cannot be reused.</span>
<span class="line-removed">4682   add(con);</span>
<span class="line-removed">4683   return con;</span>
<span class="line-removed">4684 }</span>
<span class="line-removed">4685 </span>
<span class="line-removed">4686 void Compile::ConstantTable::fill_jump_table(CodeBuffer&amp; cb, MachConstantNode* n, GrowableArray&lt;Label*&gt; labels) const {</span>
<span class="line-removed">4687   // If called from Compile::scratch_emit_size do nothing.</span>
<span class="line-removed">4688   if (Compile::current()-&gt;in_scratch_emit_size())  return;</span>
<span class="line-removed">4689 </span>
<span class="line-removed">4690   assert(labels.is_nonempty(), &quot;must be&quot;);</span>
<span class="line-removed">4691   assert((uint) labels.length() == n-&gt;outcnt(), &quot;must be equal: %d == %d&quot;, labels.length(), n-&gt;outcnt());</span>
<span class="line-removed">4692 </span>
<span class="line-removed">4693   // Since MachConstantNode::constant_offset() also contains</span>
<span class="line-removed">4694   // table_base_offset() we need to subtract the table_base_offset()</span>
<span class="line-removed">4695   // to get the plain offset into the constant table.</span>
<span class="line-removed">4696   int offset = n-&gt;constant_offset() - table_base_offset();</span>
<span class="line-removed">4697 </span>
<span class="line-removed">4698   MacroAssembler _masm(&amp;cb);</span>
<span class="line-removed">4699   address* jump_table_base = (address*) (_masm.code()-&gt;consts()-&gt;start() + offset);</span>
<span class="line-removed">4700 </span>
<span class="line-removed">4701   for (uint i = 0; i &lt; n-&gt;outcnt(); i++) {</span>
<span class="line-removed">4702     address* constant_addr = &amp;jump_table_base[i];</span>
<span class="line-removed">4703     assert(*constant_addr == (((address) n) + i), &quot;all jump-table entries must contain adjusted node pointer: &quot; INTPTR_FORMAT &quot; == &quot; INTPTR_FORMAT, p2i(*constant_addr), p2i(((address) n) + i));</span>
<span class="line-removed">4704     *constant_addr = cb.consts()-&gt;target(*labels.at(i), (address) constant_addr);</span>
<span class="line-removed">4705     cb.consts()-&gt;relocate((address) constant_addr, relocInfo::internal_word_type);</span>
<span class="line-removed">4706   }</span>
<span class="line-removed">4707 }</span>
<span class="line-removed">4708 </span>
4709 //----------------------------static_subtype_check-----------------------------
4710 // Shortcut important common cases when superklass is exact:
4711 // (0) superklass is java.lang.Object (can occur in reflective code)
4712 // (1) subklass is already limited to a subtype of superklass =&gt; always ok
4713 // (2) subklass does not overlap with superklass =&gt; always fail
4714 // (3) superklass has NO subtypes and we can check with a simple compare.
4715 int Compile::static_subtype_check(ciKlass* superk, ciKlass* subk) {
4716   if (StressReflectiveCode || superk == NULL || subk == NULL) {
4717     return SSC_full_test;       // Let caller generate the general case.
4718   }
4719 
4720   if (superk == env()-&gt;Object_klass()) {
4721     return SSC_always_true;     // (0) this test cannot fail
4722   }
4723 
4724   ciType* superelem = superk;
4725   if (superelem-&gt;is_array_klass()) {
4726     ciArrayKlass* ak = superelem-&gt;as_array_klass();
4727     superelem = superelem-&gt;as_array_klass()-&gt;base_element_type();
4728   }
</pre>
<hr />
<pre>
4736       return SSC_always_false;
4737     }
4738   }
4739 
4740   // Do not fold the subtype check to an array klass pointer comparison for [V? arrays.
4741   // [V is a subtype of [V? but the klass for [V is not equal to the klass for [V?. Perform a full test.
4742   if (superk-&gt;is_obj_array_klass() &amp;&amp; !superk-&gt;as_array_klass()-&gt;storage_properties().is_null_free() &amp;&amp; superk-&gt;as_array_klass()-&gt;element_klass()-&gt;is_valuetype()) {
4743     return SSC_full_test;
4744   }
4745   // If casting to an instance klass, it must have no subtypes
4746   if (superk-&gt;is_interface()) {
4747     // Cannot trust interfaces yet.
4748     // %%% S.B. superk-&gt;nof_implementors() == 1
4749   } else if (superelem-&gt;is_instance_klass()) {
4750     ciInstanceKlass* ik = superelem-&gt;as_instance_klass();
4751     if (!ik-&gt;has_subklass() &amp;&amp; !ik-&gt;is_interface()) {
4752       if (!ik-&gt;is_final()) {
4753         // Add a dependency if there is a chance of a later subclass.
4754         dependencies()-&gt;assert_leaf_type(ik);
4755       }
<span class="line-removed">4756       if (ik-&gt;is_abstract()) {</span>
<span class="line-removed">4757         return SSC_always_false;</span>
<span class="line-removed">4758       }</span>
4759       return SSC_easy_test;     // (3) caller can do a simple ptr comparison
4760     }
4761   } else {
4762     // A primitive array type has no subtypes.
4763     return SSC_easy_test;       // (3) caller can do a simple ptr comparison
4764   }
4765 
4766   return SSC_full_test;
4767 }
4768 
4769 Node* Compile::conv_I2X_index(PhaseGVN* phase, Node* idx, const TypeInt* sizetype, Node* ctrl) {
4770 #ifdef _LP64
4771   // The scaled index operand to AddP must be a clean 64-bit value.
4772   // Java allows a 32-bit int to be incremented to a negative
4773   // value, which appears in a 64-bit register as a large
4774   // positive number.  Using that large positive number as an
4775   // operand in pointer arithmetic has bad consequences.
4776   // On the other hand, 32-bit overflow is rare, and the possibility
4777   // can often be excluded, if we annotate the ConvI2L node with
4778   // a type assertion that its value is known to be a small positive
</pre>
</td>
<td>
<hr />
<pre>
 234   #define PRINT_STAT_LINE(name, c, f) \
 235     tty-&gt;print_cr(&quot;  %4d (%4.1f%%) %s (%s)&quot;, (int)(c), ((c) * 100.0) / total, name, f);
 236   for (int index = 1 + (int)vmIntrinsics::_none; index &lt; (int)vmIntrinsics::ID_LIMIT; index++) {
 237     vmIntrinsics::ID id = (vmIntrinsics::ID) index;
 238     int   flags = _intrinsic_hist_flags[id];
 239     juint count = _intrinsic_hist_count[id];
 240     if ((flags | count) != 0) {
 241       PRINT_STAT_LINE(vmIntrinsics::name_at(id), count, format_flags(flags, flagsbuf));
 242     }
 243   }
 244   PRINT_STAT_LINE(&quot;total&quot;, total, format_flags(_intrinsic_hist_flags[vmIntrinsics::_none], flagsbuf));
 245   if (xtty != NULL)  xtty-&gt;tail(&quot;statistics&quot;);
 246 }
 247 
 248 void Compile::print_statistics() {
 249   { ttyLocker ttyl;
 250     if (xtty != NULL)  xtty-&gt;head(&quot;statistics type=&#39;opto&#39;&quot;);
 251     Parse::print_statistics();
 252     PhaseCCP::print_statistics();
 253     PhaseRegAlloc::print_statistics();
<span class="line-modified"> 254     PhaseOutput::print_statistics();</span>
 255     PhasePeephole::print_statistics();
 256     PhaseIdealLoop::print_statistics();
 257     if (xtty != NULL)  xtty-&gt;tail(&quot;statistics&quot;);
 258   }
 259   if (_intrinsic_hist_flags[vmIntrinsics::_none] != 0) {
 260     // put this under its own &lt;statistics&gt; element.
 261     print_intrinsic_statistics();
 262   }
 263 }
 264 #endif //PRODUCT
 265 











 266 void Compile::gvn_replace_by(Node* n, Node* nn) {
 267   for (DUIterator_Last imin, i = n-&gt;last_outs(imin); i &gt;= imin; ) {
 268     Node* use = n-&gt;last_out(i);
 269     bool is_in_table = initial_gvn()-&gt;hash_delete(use);
 270     uint uses_found = 0;
 271     for (uint j = 0; j &lt; use-&gt;len(); j++) {
 272       if (use-&gt;in(j) == n) {
 273         if (j &lt; use-&gt;req())
 274           use-&gt;set_req(j, nn);
 275         else
 276           use-&gt;set_prec(j, nn);
 277         uses_found++;
 278       }
 279     }
 280     if (is_in_table) {
 281       // reinsert into table
 282       initial_gvn()-&gt;hash_find_insert(use);
 283     }
 284     record_for_igvn(use);
 285     i -= uses_found;    // we deleted 1 or more copies of this edge
</pre>
<hr />
<pre>
 400   // Remove useless Opaque4 nodes
 401   for (int i = opaque4_count() - 1; i &gt;= 0; i--) {
 402     Node* opaq = opaque4_node(i);
 403     if (!useful.member(opaq)) {
 404       remove_opaque4_node(opaq);
 405     }
 406   }
 407   // Remove useless value type nodes
 408   if (_value_type_nodes != NULL) {
 409     _value_type_nodes-&gt;remove_useless_nodes(useful.member_set());
 410   }
 411   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 412   bs-&gt;eliminate_useless_gc_barriers(useful, this);
 413   // clean up the late inline lists
 414   remove_useless_late_inlines(&amp;_string_late_inlines, useful);
 415   remove_useless_late_inlines(&amp;_boxing_late_inlines, useful);
 416   remove_useless_late_inlines(&amp;_late_inlines, useful);
 417   debug_only(verify_graph_edges(true/*check for no_dead_code*/);)
 418 }
 419 


















 420 // ============================================================================
 421 //------------------------------CompileWrapper---------------------------------
 422 class CompileWrapper : public StackObj {
 423   Compile *const _compile;
 424  public:
 425   CompileWrapper(Compile* compile);
 426 
 427   ~CompileWrapper();
 428 };
 429 
 430 CompileWrapper::CompileWrapper(Compile* compile) : _compile(compile) {
 431   // the Compile* pointer is stored in the current ciEnv:
 432   ciEnv* env = compile-&gt;env();
 433   assert(env == ciEnv::current(), &quot;must already be a ciEnv active&quot;);
 434   assert(env-&gt;compiler_data() == NULL, &quot;compile already active?&quot;);
 435   env-&gt;set_compiler_data(compile);
 436   assert(compile == Compile::current(), &quot;sanity&quot;);
 437 
 438   compile-&gt;set_type_dict(NULL);
 439   compile-&gt;set_clone_map(new Dict(cmpkey, hashkey, _compile-&gt;comp_arena()));
 440   compile-&gt;clone_map().set_clone_idx(0);
 441   compile-&gt;set_type_last_size(0);
 442   compile-&gt;set_last_tf(NULL, NULL);
 443   compile-&gt;set_indexSet_arena(NULL);
 444   compile-&gt;set_indexSet_free_block_list(NULL);
 445   compile-&gt;init_type_arena();
 446   Type::Initialize(compile);

 447   _compile-&gt;begin_method();
 448   _compile-&gt;clone_map().set_debug(_compile-&gt;has_method() &amp;&amp; _compile-&gt;directive()-&gt;CloneMapDebugOption);
 449 }
 450 CompileWrapper::~CompileWrapper() {
 451   _compile-&gt;end_method();


 452   _compile-&gt;env()-&gt;set_compiler_data(NULL);
 453 }
 454 
 455 
 456 //----------------------------print_compile_messages---------------------------
 457 void Compile::print_compile_messages() {
 458 #ifndef PRODUCT
 459   // Check if recompiling
 460   if (_subsume_loads == false &amp;&amp; PrintOpto) {
 461     // Recompiling without allowing machine instructions to subsume loads
 462     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 463     tty-&gt;print_cr(&quot;** Bailout: Recompile without subsuming loads          **&quot;);
 464     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 465   }
 466   if (_do_escape_analysis != DoEscapeAnalysis &amp;&amp; PrintOpto) {
 467     // Recompiling without escape analysis
 468     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 469     tty-&gt;print_cr(&quot;** Bailout: Recompile without escape analysis          **&quot;);
 470     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 471   }
</pre>
<hr />
<pre>
 476     tty-&gt;print_cr(&quot;*********************************************************&quot;);
 477   }
 478   if (C-&gt;directive()-&gt;BreakAtCompileOption) {
 479     // Open the debugger when compiling this method.
 480     tty-&gt;print(&quot;### Breaking when compiling: &quot;);
 481     method()-&gt;print_short_name();
 482     tty-&gt;cr();
 483     BREAKPOINT;
 484   }
 485 
 486   if( PrintOpto ) {
 487     if (is_osr_compilation()) {
 488       tty-&gt;print(&quot;[OSR]%3d&quot;, _compile_id);
 489     } else {
 490       tty-&gt;print(&quot;%3d&quot;, _compile_id);
 491     }
 492   }
 493 #endif
 494 }
 495 





















































































































 496 // ============================================================================
 497 //------------------------------Compile standard-------------------------------
 498 debug_only( int Compile::_debug_idx = 100000; )
 499 
 500 // Compile a method.  entry_bci is -1 for normal compilations and indicates
 501 // the continuation bci for on stack replacement.
 502 
 503 
<span class="line-modified"> 504 Compile::Compile( ciEnv* ci_env, ciMethod* target, int osr_bci,</span>
 505                   bool subsume_loads, bool do_escape_analysis, bool eliminate_boxing, DirectiveSet* directive)
 506                 : Phase(Compiler),
 507                   _compile_id(ci_env-&gt;compile_id()),
 508                   _save_argument_registers(false),
 509                   _subsume_loads(subsume_loads),
 510                   _do_escape_analysis(do_escape_analysis),
 511                   _eliminate_boxing(eliminate_boxing),
 512                   _method(target),
 513                   _entry_bci(osr_bci),
 514                   _stub_function(NULL),
 515                   _stub_name(NULL),
 516                   _stub_entry_point(NULL),
 517                   _max_node_limit(MaxNodeLimit),




 518                   _inlining_progress(false),
 519                   _inlining_incrementally(false),
 520                   _do_cleanup(false),
 521                   _has_reserved_stack_access(target-&gt;has_reserved_stack_access()),
 522 #ifndef PRODUCT
 523                   _trace_opto_output(directive-&gt;TraceOptoOutputOption),
 524                   _print_ideal(directive-&gt;PrintIdealOption),
 525 #endif
 526                   _has_method_handle_invokes(false),
 527                   _clinit_barrier_on_entry(false),
 528                   _comp_arena(mtCompiler),
 529                   _barrier_set_state(BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;create_barrier_state(comp_arena())),
 530                   _env(ci_env),
 531                   _directive(directive),
 532                   _log(ci_env-&gt;log()),
 533                   _failure_reason(NULL),
 534                   _congraph(NULL),
 535 #ifndef PRODUCT
 536                   _printer(IdealGraphPrinter::printer()),
 537 #endif
</pre>
<hr />
<pre>
 539                   _dead_node_count(0),
 540                   _node_arena(mtCompiler),
 541                   _old_arena(mtCompiler),
 542                   _mach_constant_base_node(NULL),
 543                   _Compile_types(mtCompiler),
 544                   _initial_gvn(NULL),
 545                   _for_igvn(NULL),
 546                   _warm_calls(NULL),
 547                   _late_inlines(comp_arena(), 2, 0, NULL),
 548                   _string_late_inlines(comp_arena(), 2, 0, NULL),
 549                   _boxing_late_inlines(comp_arena(), 2, 0, NULL),
 550                   _late_inlines_pos(0),
 551                   _number_of_mh_late_inlines(0),
 552                   _print_inlining_stream(NULL),
 553                   _print_inlining_list(NULL),
 554                   _print_inlining_idx(0),
 555                   _print_inlining_output(NULL),
 556                   _replay_inline_data(NULL),
 557                   _java_calls(0),
 558                   _inner_loops(0),
<span class="line-modified"> 559                   _interpreter_frame_size(0)</span>





 560 #ifndef PRODUCT
 561                   , _in_dump_cnt(0)
 562 #endif
 563 {
 564   C = this;
 565 #ifndef PRODUCT
 566   if (_printer != NULL) {
 567     _printer-&gt;set_compile(this);
 568   }
 569 #endif
 570   CompileWrapper cw(this);
 571 
 572   if (CITimeVerbose) {
 573     tty-&gt;print(&quot; &quot;);
 574     target-&gt;holder()-&gt;name()-&gt;print();
 575     tty-&gt;print(&quot;.&quot;);
 576     target-&gt;print_short_name();
 577     tty-&gt;print(&quot;  &quot;);
 578   }
 579   TraceTime t1(&quot;Total compilation time&quot;, &amp;_t_totalCompilation, CITime, CITimeVerbose);
</pre>
<hr />
<pre>
 755       xtty-&gt;tail(&quot;ideal&quot;);
 756     }
 757   }
 758 #endif
 759 
 760 #ifdef ASSERT
 761   BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 762   bs-&gt;verify_gc_barriers(this, BarrierSetC2::BeforeCodeGen);
 763 #endif
 764 
 765   // Dump compilation data to replay it.
 766   if (directive-&gt;DumpReplayOption) {
 767     env()-&gt;dump_replay_data(_compile_id);
 768   }
 769   if (directive-&gt;DumpInlineOption &amp;&amp; (ilt() != NULL)) {
 770     env()-&gt;dump_inline_data(_compile_id);
 771   }
 772 
 773   // Now that we know the size of all the monitors we can add a fixed slot
 774   // for the original deopt pc.
<span class="line-modified"> 775   int next_slot = fixed_slots() + (sizeof(address) / VMRegImpl::stack_slot_size);</span>



 776   if (needs_stack_repair()) {
 777     // One extra slot for the special stack increment value

 778     next_slot += 2;
 779   }

 780   set_fixed_slots(next_slot);
 781 
 782   // Compute when to use implicit null checks. Used by matching trap based
 783   // nodes and NullCheck optimization.
 784   set_allowed_deopt_reasons();
 785 
 786   // Now generate code
 787   Code_Gen();












































 788 }
 789 
 790 //------------------------------Compile----------------------------------------
 791 // Compile a runtime stub
 792 Compile::Compile( ciEnv* ci_env,
 793                   TypeFunc_generator generator,
 794                   address stub_function,
 795                   const char *stub_name,
 796                   int is_fancy_jump,
 797                   bool pass_tls,
 798                   bool save_arg_registers,
 799                   bool return_pc,
 800                   DirectiveSet* directive)
 801   : Phase(Compiler),
 802     _compile_id(0),
 803     _save_argument_registers(save_arg_registers),
 804     _subsume_loads(true),
 805     _do_escape_analysis(false),
 806     _eliminate_boxing(false),
 807     _method(NULL),
 808     _entry_bci(InvocationEntryBci),
 809     _stub_function(stub_function),
 810     _stub_name(stub_name),
 811     _stub_entry_point(NULL),
 812     _max_node_limit(MaxNodeLimit),




 813     _inlining_progress(false),
 814     _inlining_incrementally(false),
 815     _has_reserved_stack_access(false),
 816 #ifndef PRODUCT
 817     _trace_opto_output(directive-&gt;TraceOptoOutputOption),
 818     _print_ideal(directive-&gt;PrintIdealOption),
 819 #endif
 820     _has_method_handle_invokes(false),
 821     _clinit_barrier_on_entry(false),
 822     _comp_arena(mtCompiler),
 823     _barrier_set_state(BarrierSet::barrier_set()-&gt;barrier_set_c2()-&gt;create_barrier_state(comp_arena())),
 824     _env(ci_env),
 825     _directive(directive),
 826     _log(ci_env-&gt;log()),
 827     _failure_reason(NULL),
 828     _congraph(NULL),
 829 #ifndef PRODUCT
 830     _printer(NULL),
 831 #endif
 832     _dead_node_list(comp_arena()),
 833     _dead_node_count(0),
 834     _node_arena(mtCompiler),
 835     _old_arena(mtCompiler),
 836     _mach_constant_base_node(NULL),
 837     _Compile_types(mtCompiler),
 838     _initial_gvn(NULL),
 839     _for_igvn(NULL),
 840     _warm_calls(NULL),
 841     _number_of_mh_late_inlines(0),
 842     _print_inlining_stream(NULL),
 843     _print_inlining_list(NULL),
 844     _print_inlining_idx(0),
 845     _print_inlining_output(NULL),
 846     _replay_inline_data(NULL),
 847     _java_calls(0),
 848     _inner_loops(0),
 849     _interpreter_frame_size(0),



 850 #ifndef PRODUCT
 851     _in_dump_cnt(0),
 852 #endif
 853     _allowed_reasons(0) {
 854   C = this;
 855 
 856   TraceTime t1(NULL, &amp;_t_totalCompilation, CITime, false);
 857   TraceTime t2(NULL, &amp;_t_stubCompilation, CITime, false);
 858 
 859 #ifndef PRODUCT
 860   set_print_assembly(PrintFrameConverterAssembly);
 861   set_parsed_irreducible_loop(false);
 862 #else
 863   set_print_assembly(false); // Must initialize.
 864 #endif
 865   set_has_irreducible_loop(false); // no loops
 866 
 867   CompileWrapper cw(this);
 868   Init(/*AliasLevel=*/ 0);
 869   init_tf((*generator)());
 870 
 871   {
 872     // The following is a dummy for the sake of GraphKit::gen_stub
 873     Unique_Node_List for_igvn(comp_arena());
 874     set_for_igvn(&amp;for_igvn);  // not used, but some GraphKit guys push on this
 875     PhaseGVN gvn(Thread::current()-&gt;resource_area(),255);
 876     set_initial_gvn(&amp;gvn);    // not significant, but GraphKit guys use it pervasively
 877     gvn.transform_no_reclaim(top());
 878 
 879     GraphKit kit;
 880     kit.gen_stub(stub_function, stub_name, is_fancy_jump, pass_tls, return_pc);
 881   }
 882 
 883   NOT_PRODUCT( verify_graph_edges(); )













 884 
<span class="line-modified"> 885   Code_Gen();</span>













 886 }
 887 
 888 //------------------------------Init-------------------------------------------
 889 // Prepare for a single compilation
 890 void Compile::Init(int aliaslevel) {
 891   _unique  = 0;
 892   _regalloc = NULL;
 893 
 894   _tf      = NULL;  // filled in later
 895   _top     = NULL;  // cached later
 896   _matcher = NULL;  // filled in later
 897   _cfg     = NULL;  // filled in later
 898 
 899   IA32_ONLY( set_24_bit_selection_and_mode(true, false); )
 900 
 901   _node_note_array = NULL;
 902   _default_node_notes = NULL;
 903   DEBUG_ONLY( _modified_nodes = NULL; ) // Used in Optimize()
 904 
 905   _immutable_memory = NULL; // filled in at first inquiry
</pre>
<hr />
<pre>
1003     for (int i = 0; i &lt; grow_ats; i++)  _alias_types[i] = &amp;ats[i];
1004   }
1005   // Initialize the first few types.
1006   _alias_types[AliasIdxTop]-&gt;Init(AliasIdxTop, NULL);
1007   _alias_types[AliasIdxBot]-&gt;Init(AliasIdxBot, TypePtr::BOTTOM);
1008   _alias_types[AliasIdxRaw]-&gt;Init(AliasIdxRaw, TypeRawPtr::BOTTOM);
1009   _num_alias_types = AliasIdxRaw+1;
1010   // Zero out the alias type cache.
1011   Copy::zero_to_bytes(_alias_cache, sizeof(_alias_cache));
1012   // A NULL adr_type hits in the cache right away.  Preload the right answer.
1013   probe_alias_cache(NULL)-&gt;_index = AliasIdxTop;
1014 
1015   _intrinsics = NULL;
1016   _macro_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1017   _predicate_opaqs = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1018   _expensive_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1019   _range_check_casts = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1020   _opaque4_nodes = new(comp_arena()) GrowableArray&lt;Node*&gt;(comp_arena(), 8,  0, NULL);
1021   _value_type_nodes = new (comp_arena()) Unique_Node_List(comp_arena());
1022   register_library_intrinsics();
<span class="line-added">1023 #ifdef ASSERT</span>
<span class="line-added">1024   _type_verify_symmetry = true;</span>
<span class="line-added">1025 #endif</span>
1026 }
1027 
1028 //---------------------------init_start----------------------------------------
1029 // Install the StartNode on this compile object.
1030 void Compile::init_start(StartNode* s) {
1031   if (failing())
1032     return; // already failing
1033   assert(s == start(), &quot;&quot;);
1034 }
1035 
1036 /**
1037  * Return the &#39;StartNode&#39;. We must not have a pending failure, since the ideal graph
1038  * can be in an inconsistent state, i.e., we can get segmentation faults when traversing
1039  * the ideal graph.
1040  */
1041 StartNode* Compile::start() const {
1042   assert (!failing(), &quot;Must not have pending failure. Reason is: %s&quot;, failure_reason());
1043   for (DUIterator_Fast imax, i = root()-&gt;fast_outs(imax); i &lt; imax; i++) {
1044     Node* start = root()-&gt;fast_out(i);
1045     if (start-&gt;is_Start()) {
</pre>
<hr />
<pre>
1633       int field_offset = flat-&gt;is_aryptr()-&gt;field_offset().get();
1634       if (elemtype-&gt;isa_valuetype() &amp;&amp;
1635           elemtype-&gt;value_klass() != NULL &amp;&amp;
1636           field_offset != Type::OffsetBot) {
1637         ciValueKlass* vk = elemtype-&gt;value_klass();
1638         field_offset += vk-&gt;first_field_offset();
1639         field = vk-&gt;get_field_by_offset(field_offset, false);
1640       }
1641     }
1642     if (flat-&gt;isa_klassptr()) {
1643       if (flat-&gt;offset() == in_bytes(Klass::super_check_offset_offset()))
1644         alias_type(idx)-&gt;set_rewritable(false);
1645       if (flat-&gt;offset() == in_bytes(Klass::modifier_flags_offset()))
1646         alias_type(idx)-&gt;set_rewritable(false);
1647       if (flat-&gt;offset() == in_bytes(Klass::access_flags_offset()))
1648         alias_type(idx)-&gt;set_rewritable(false);
1649       if (flat-&gt;offset() == in_bytes(Klass::java_mirror_offset()))
1650         alias_type(idx)-&gt;set_rewritable(false);
1651       if (flat-&gt;offset() == in_bytes(Klass::layout_helper_offset()))
1652         alias_type(idx)-&gt;set_rewritable(false);
<span class="line-added">1653       if (flat-&gt;offset() == in_bytes(Klass::secondary_super_cache_offset()))</span>
<span class="line-added">1654         alias_type(idx)-&gt;set_rewritable(false);</span>
1655     }
1656     // %%% (We would like to finalize JavaThread::threadObj_offset(),
1657     // but the base pointer type is not distinctive enough to identify
1658     // references into JavaThread.)
1659 
1660     // Check for final fields.
1661     const TypeInstPtr* tinst = flat-&gt;isa_instptr();
1662     if (tinst &amp;&amp; tinst-&gt;offset() &gt;= instanceOopDesc::base_offset_in_bytes()) {
1663       if (tinst-&gt;const_oop() != NULL &amp;&amp;
1664           tinst-&gt;klass() == ciEnv::current()-&gt;Class_klass() &amp;&amp;
1665           tinst-&gt;offset() &gt;= (tinst-&gt;klass()-&gt;as_instance_klass()-&gt;size_helper() * wordSize)) {
1666         // static field
1667         ciInstanceKlass* k = tinst-&gt;const_oop()-&gt;as_instance()-&gt;java_lang_Class_klass()-&gt;as_instance_klass();
1668         field = k-&gt;get_field_by_offset(tinst-&gt;offset(), true);
1669       } else if (tinst-&gt;klass()-&gt;is_valuetype()) {
1670         // Value type field
1671         ciValueKlass* vk = tinst-&gt;value_klass();
1672         field = vk-&gt;get_field_by_offset(tinst-&gt;offset(), false);
1673       } else {
1674         ciInstanceKlass* k = tinst-&gt;klass()-&gt;as_instance_klass();
</pre>
<hr />
<pre>
1742   if (alias_idx == AliasIdxBot)         return true;  // the universal category
1743   if (adr_type == NULL)                 return true;  // NULL serves as TypePtr::TOP
1744   if (alias_idx == AliasIdxTop)         return false; // the empty category
1745   if (adr_type-&gt;base() == Type::AnyPtr) return false; // TypePtr::BOTTOM or its twins
1746 
1747   // the only remaining possible overlap is identity
1748   int adr_idx = get_alias_index(adr_type);
1749   assert(adr_idx != AliasIdxBot &amp;&amp; adr_idx != AliasIdxTop, &quot;&quot;);
1750   assert(adr_idx == alias_idx ||
1751          (alias_type(alias_idx)-&gt;adr_type() != TypeOopPtr::BOTTOM
1752           &amp;&amp; adr_type                       != TypeOopPtr::BOTTOM),
1753          &quot;should not be testing for overlap with an unsafe pointer&quot;);
1754   return adr_idx == alias_idx;
1755 }
1756 
1757 //------------------------------can_alias--------------------------------------
1758 // True if any values of the given address type are in the given alias category.
1759 bool Compile::can_alias(const TypePtr* adr_type, int alias_idx) {
1760   if (alias_idx == AliasIdxTop)         return false; // the empty category
1761   if (adr_type == NULL)                 return false; // NULL serves as TypePtr::TOP
<span class="line-modified">1762   // Known instance doesn&#39;t alias with bottom memory</span>
<span class="line-modified">1763   if (alias_idx == AliasIdxBot)         return !adr_type-&gt;is_known_instance();                   // the universal category</span>
<span class="line-added">1764   if (adr_type-&gt;base() == Type::AnyPtr) return !C-&gt;get_adr_type(alias_idx)-&gt;is_known_instance(); // TypePtr::BOTTOM or its twins</span>
1765 
1766   // the only remaining possible overlap is identity
1767   int adr_idx = get_alias_index(adr_type);
1768   assert(adr_idx != AliasIdxBot &amp;&amp; adr_idx != AliasIdxTop, &quot;&quot;);
1769   return adr_idx == alias_idx;
1770 }
1771 
1772 
1773 
1774 //---------------------------pop_warm_call-------------------------------------
1775 WarmCallInfo* Compile::pop_warm_call() {
1776   WarmCallInfo* wci = _warm_calls;
1777   if (wci != NULL)  _warm_calls = wci-&gt;remove_from(wci);
1778   return wci;
1779 }
1780 
1781 //----------------------------Inline_Warm--------------------------------------
1782 int Compile::Inline_Warm() {
1783   // If there is room, try to inline some more warm call sites.
1784   // %%% Do a graph index compaction pass when we think we&#39;re out of space?
</pre>
<hr />
<pre>
2730       cfg.set_loop_alignment();
2731     }
2732     cfg.fixup_flow();
2733   }
2734 
2735   // Apply peephole optimizations
2736   if( OptoPeephole ) {
2737     TracePhase tp(&quot;peephole&quot;, &amp;timers[_t_peephole]);
2738     PhasePeephole peep( _regalloc, cfg);
2739     peep.do_transform();
2740   }
2741 
2742   // Do late expand if CPU requires this.
2743   if (Matcher::require_postalloc_expand) {
2744     TracePhase tp(&quot;postalloc_expand&quot;, &amp;timers[_t_postalloc_expand]);
2745     cfg.postalloc_expand(_regalloc);
2746   }
2747 
2748   // Convert Nodes to instruction bits in a buffer
2749   {
<span class="line-modified">2750     TracePhase tp(&quot;output&quot;, &amp;timers[_t_output]);</span>
<span class="line-modified">2751     PhaseOutput output;</span>
<span class="line-added">2752     output.Output();</span>
<span class="line-added">2753     if (failing())  return;</span>
<span class="line-added">2754     output.install();</span>
2755   }
2756 
2757   print_method(PHASE_FINAL_CODE);
2758 
2759   // He&#39;s dead, Jim.
2760   _cfg     = (PhaseCFG*)((intptr_t)0xdeadbeef);
2761   _regalloc = (PhaseChaitin*)((intptr_t)0xdeadbeef);
2762 }
2763 









































































































































2764 //------------------------------Final_Reshape_Counts---------------------------
2765 // This class defines counters to help identify when a method
2766 // may/must be executed using hardware with only 24-bit precision.
2767 struct Final_Reshape_Counts : public StackObj {
2768   int  _call_count;             // count non-inlined &#39;common&#39; calls
2769   int  _float_count;            // count float ops requiring 24-bit precision
2770   int  _double_count;           // count double ops requiring more precision
2771   int  _java_call_count;        // count non-inlined &#39;java&#39; calls
2772   int  _inner_loop_count;       // count loops which need alignment
2773   VectorSet _visited;           // Visitation flags
2774   Node_List _tests;             // Set of IfNodes &amp; PCTableNodes
2775 
2776   Final_Reshape_Counts() :
2777     _call_count(0), _float_count(0), _double_count(0),
2778     _java_call_count(0), _inner_loop_count(0),
2779     _visited( Thread::current()-&gt;resource_area() ) { }
2780 
2781   void inc_call_count  () { _call_count  ++; }
2782   void inc_float_count () { _float_count ++; }
2783   void inc_double_count() { _double_count++; }
</pre>
<hr />
<pre>
3467           n-&gt;subsume_by(sub, this);
3468         }
3469       }
3470     }
3471     break;
3472 
3473   case Op_LoadVector:
3474   case Op_StoreVector:
3475     break;
3476 
3477   case Op_AddReductionVI:
3478   case Op_AddReductionVL:
3479   case Op_AddReductionVF:
3480   case Op_AddReductionVD:
3481   case Op_MulReductionVI:
3482   case Op_MulReductionVL:
3483   case Op_MulReductionVF:
3484   case Op_MulReductionVD:
3485   case Op_MinReductionV:
3486   case Op_MaxReductionV:
<span class="line-added">3487   case Op_AndReductionV:</span>
<span class="line-added">3488   case Op_OrReductionV:</span>
<span class="line-added">3489   case Op_XorReductionV:</span>
3490     break;
3491 
3492   case Op_PackB:
3493   case Op_PackS:
3494   case Op_PackI:
3495   case Op_PackF:
3496   case Op_PackL:
3497   case Op_PackD:
3498     if (n-&gt;req()-1 &gt; 2) {
3499       // Replace many operand PackNodes with a binary tree for matching
3500       PackNode* p = (PackNode*) n;
3501       Node* btp = p-&gt;binary_tree_pack(1, n-&gt;req());
3502       n-&gt;subsume_by(btp, this);
3503     }
3504     break;
3505   case Op_Loop:
3506   case Op_CountedLoop:
3507   case Op_OuterStripMinedLoop:
3508     if (n-&gt;as_Loop()-&gt;is_inner_loop()) {
3509       frc.inc_inner_loop_count();
</pre>
<hr />
<pre>
4108   } else {
4109     _log = NULL;
4110   }
4111 
4112 #ifdef ASSERT
4113   if (PrintIdealNodeCount) {
4114     tty-&gt;print_cr(&quot;phase name=&#39;%s&#39; nodes=&#39;%d&#39; live=&#39;%d&#39; live_graph_walk=&#39;%d&#39;&quot;,
4115                   _phase_name, C-&gt;unique(), C-&gt;live_nodes(), C-&gt;count_live_nodes_by_graph_walk());
4116   }
4117 
4118   if (VerifyIdealNodeCount) {
4119     Compile::current()-&gt;print_missing_nodes();
4120   }
4121 #endif
4122 
4123   if (_log != NULL) {
4124     _log-&gt;done(&quot;phase name=&#39;%s&#39; nodes=&#39;%d&#39; live=&#39;%d&#39;&quot;, _phase_name, C-&gt;unique(), C-&gt;live_nodes());
4125   }
4126 }
4127 
























































































































































































































4128 //----------------------------static_subtype_check-----------------------------
4129 // Shortcut important common cases when superklass is exact:
4130 // (0) superklass is java.lang.Object (can occur in reflective code)
4131 // (1) subklass is already limited to a subtype of superklass =&gt; always ok
4132 // (2) subklass does not overlap with superklass =&gt; always fail
4133 // (3) superklass has NO subtypes and we can check with a simple compare.
4134 int Compile::static_subtype_check(ciKlass* superk, ciKlass* subk) {
4135   if (StressReflectiveCode || superk == NULL || subk == NULL) {
4136     return SSC_full_test;       // Let caller generate the general case.
4137   }
4138 
4139   if (superk == env()-&gt;Object_klass()) {
4140     return SSC_always_true;     // (0) this test cannot fail
4141   }
4142 
4143   ciType* superelem = superk;
4144   if (superelem-&gt;is_array_klass()) {
4145     ciArrayKlass* ak = superelem-&gt;as_array_klass();
4146     superelem = superelem-&gt;as_array_klass()-&gt;base_element_type();
4147   }
</pre>
<hr />
<pre>
4155       return SSC_always_false;
4156     }
4157   }
4158 
4159   // Do not fold the subtype check to an array klass pointer comparison for [V? arrays.
4160   // [V is a subtype of [V? but the klass for [V is not equal to the klass for [V?. Perform a full test.
4161   if (superk-&gt;is_obj_array_klass() &amp;&amp; !superk-&gt;as_array_klass()-&gt;storage_properties().is_null_free() &amp;&amp; superk-&gt;as_array_klass()-&gt;element_klass()-&gt;is_valuetype()) {
4162     return SSC_full_test;
4163   }
4164   // If casting to an instance klass, it must have no subtypes
4165   if (superk-&gt;is_interface()) {
4166     // Cannot trust interfaces yet.
4167     // %%% S.B. superk-&gt;nof_implementors() == 1
4168   } else if (superelem-&gt;is_instance_klass()) {
4169     ciInstanceKlass* ik = superelem-&gt;as_instance_klass();
4170     if (!ik-&gt;has_subklass() &amp;&amp; !ik-&gt;is_interface()) {
4171       if (!ik-&gt;is_final()) {
4172         // Add a dependency if there is a chance of a later subclass.
4173         dependencies()-&gt;assert_leaf_type(ik);
4174       }



4175       return SSC_easy_test;     // (3) caller can do a simple ptr comparison
4176     }
4177   } else {
4178     // A primitive array type has no subtypes.
4179     return SSC_easy_test;       // (3) caller can do a simple ptr comparison
4180   }
4181 
4182   return SSC_full_test;
4183 }
4184 
4185 Node* Compile::conv_I2X_index(PhaseGVN* phase, Node* idx, const TypeInt* sizetype, Node* ctrl) {
4186 #ifdef _LP64
4187   // The scaled index operand to AddP must be a clean 64-bit value.
4188   // Java allows a 32-bit int to be incremented to a negative
4189   // value, which appears in a 64-bit register as a large
4190   // positive number.  Using that large positive number as an
4191   // operand in pointer arithmetic has bad consequences.
4192   // On the other hand, 32-bit overflow is rare, and the possibility
4193   // can often be excluded, if we annotate the ConvI2L node with
4194   // a type assertion that its value is known to be a small positive
</pre>
</td>
</tr>
</table>
<center><a href="classes.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="compile.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>