<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/opto/loopUnswitch.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2006, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;memory/allocation.inline.hpp&quot;
 27 #include &quot;opto/mulnode.hpp&quot;
 28 #include &quot;opto/addnode.hpp&quot;
 29 #include &quot;opto/connode.hpp&quot;
 30 #include &quot;opto/convertnode.hpp&quot;
 31 #include &quot;opto/loopnode.hpp&quot;
 32 #include &quot;opto/opaquenode.hpp&quot;
 33 #include &quot;opto/rootnode.hpp&quot;
 34 
 35 //================= Loop Unswitching =====================
 36 //
 37 // orig:                       transformed:
 38 //                               if (invariant-test) then
 39 //  predicate                      predicate
 40 //  loop                           loop
 41 //    stmt1                          stmt1
 42 //    if (invariant-test) then       stmt2
 43 //      stmt2                        stmt4
 44 //    else                         endloop
 45 //      stmt3                    else
 46 //    endif                        predicate [clone]
 47 //    stmt4                        loop [clone]
 48 //  endloop                          stmt1 [clone]
 49 //                                   stmt3
 50 //                                   stmt4 [clone]
 51 //                                 endloop
 52 //                               endif
 53 //
 54 // Note: the &quot;else&quot; clause may be empty
 55 
 56 
 57 //------------------------------policy_unswitching-----------------------------
 58 // Return TRUE or FALSE if the loop should be unswitched
 59 // (ie. clone loop with an invariant test that does not exit the loop)
 60 bool IdealLoopTree::policy_unswitching( PhaseIdealLoop *phase ) const {
 61   if (!LoopUnswitching) {
 62     return false;
 63   }
 64   if (!_head-&gt;is_Loop()) {
 65     return false;
 66   }
 67 
 68   // If nodes are depleted, some transform has miscalculated its needs.
 69   assert(!phase-&gt;exceeding_node_budget(), &quot;sanity&quot;);
 70 
 71   // check for vectorized loops, any unswitching was already applied
 72   if (_head-&gt;is_CountedLoop() &amp;&amp; _head-&gt;as_CountedLoop()-&gt;is_unroll_only()) {
 73     return false;
 74   }
 75 
 76   LoopNode* head = _head-&gt;as_Loop();
 77   if (head-&gt;unswitch_count() + 1 &gt; head-&gt;unswitch_max()) {
 78     return false;
 79   }
 80 
 81   if (head-&gt;is_flattened_arrays()) {
 82     return false;
 83   }
 84 
 85   Node_List flattened_checks;
 86   if (phase-&gt;find_unswitching_candidate(this, flattened_checks) == NULL &amp;&amp; flattened_checks.size() == 0) {
 87     return false;
 88   }
 89 
 90   // Too speculative if running low on nodes.
 91   return phase-&gt;may_require_nodes(est_loop_clone_sz(2));
 92 }
 93 
 94 //------------------------------find_unswitching_candidate-----------------------------
 95 // Find candidate &quot;if&quot; for unswitching
 96 IfNode* PhaseIdealLoop::find_unswitching_candidate(const IdealLoopTree *loop, Node_List&amp; flattened_checks) const {
 97 
 98   // Find first invariant test that doesn&#39;t exit the loop
 99   LoopNode *head = loop-&gt;_head-&gt;as_Loop();
100   IfNode* unswitch_iff = NULL;
101   Node* n = head-&gt;in(LoopNode::LoopBackControl);
102   while (n != head) {
103     Node* n_dom = idom(n);
104     if (n-&gt;is_Region()) {
105       if (n_dom-&gt;is_If()) {
106         IfNode* iff = n_dom-&gt;as_If();
107         if (iff-&gt;in(1)-&gt;is_Bool()) {
108           BoolNode* bol = iff-&gt;in(1)-&gt;as_Bool();
109           if (bol-&gt;in(1)-&gt;is_Cmp()) {
110             // If condition is invariant and not a loop exit,
111             // then found reason to unswitch.
112             if (loop-&gt;is_invariant(bol) &amp;&amp; !loop-&gt;is_loop_exit(iff)) {
113               unswitch_iff = iff;
114             }
115           }
116         }
117       }
118     }
119     n = n_dom;
120   }
121 
122   Node* array;
123   if (unswitch_iff == NULL || unswitch_iff-&gt;is_flattened_array_check(&amp;_igvn, array)) {
124     // collect all flattened array checks
125     for (uint i = 0; i &lt; loop-&gt;_body.size(); i++) {
126       Node* n = loop-&gt;_body.at(i);
127       if (n-&gt;is_If() &amp;&amp; n-&gt;as_If()-&gt;is_flattened_array_check(&amp;_igvn, array) &amp;&amp;
128           loop-&gt;is_invariant(n-&gt;in(1)) &amp;&amp;
129           !loop-&gt;is_loop_exit(n)) {
130         flattened_checks.push(n);
131       }
132     }
133     if (flattened_checks.size() &gt; 1) {
134       unswitch_iff = NULL;
135     } else {
136       flattened_checks.clear();
137     }
138   }
139 
140   return unswitch_iff;
141 }
142 
143 //------------------------------do_unswitching-----------------------------
144 // Clone loop with an invariant test (that does not exit) and
145 // insert a clone of the test that selects which version to
146 // execute.
147 void PhaseIdealLoop::do_unswitching(IdealLoopTree *loop, Node_List &amp;old_new) {
148 
149   LoopNode *head = loop-&gt;_head-&gt;as_Loop();
150   Node* entry = head-&gt;skip_strip_mined()-&gt;in(LoopNode::EntryControl);
151   if (find_predicate_insertion_point(entry, Deoptimization::Reason_loop_limit_check) != NULL
152       || (UseProfiledLoopPredicate &amp;&amp; find_predicate_insertion_point(entry, Deoptimization::Reason_profile_predicate) != NULL)
153       || (UseLoopPredicate &amp;&amp; find_predicate_insertion_point(entry, Deoptimization::Reason_predicate) != NULL)) {
154     assert(entry-&gt;is_IfProj(), &quot;sanity - must be ifProj since there is at least one predicate&quot;);
155     if (entry-&gt;outcnt() &gt; 1) {
156       // Bailout if there are loop predicates from which there are additional control dependencies (i.e. from
157       // loop entry &#39;entry&#39;) to previously partially peeled statements since this case is not handled and can lead
158       // to wrong execution. Remove this bailout, once this is fixed.
159       return;
160     }
161   }
162   // Find first invariant test that doesn&#39;t exit the loop
163   Node_List flattened_checks;
164   IfNode* unswitch_iff = find_unswitching_candidate((const IdealLoopTree *)loop, flattened_checks);
165   assert(unswitch_iff != NULL || flattened_checks.size() &gt; 0, &quot;should be at least one&quot;);
166   if (unswitch_iff == NULL) {
167     unswitch_iff = flattened_checks.at(0)-&gt;as_If();
168   }
169 
170 #ifndef PRODUCT
171   if (TraceLoopOpts) {
172     tty-&gt;print(&quot;Unswitch   %d &quot;, head-&gt;unswitch_count()+1);
173     loop-&gt;dump_head();
174   }
175 #endif
176 
177   // Need to revert back to normal loop
178   if (head-&gt;is_CountedLoop() &amp;&amp; !head-&gt;as_CountedLoop()-&gt;is_normal_loop()) {
179     head-&gt;as_CountedLoop()-&gt;set_normal_loop();
180   }
181 
182   ProjNode* proj_true = create_slow_version_of_loop(loop, old_new, unswitch_iff-&gt;Opcode(), CloneIncludesStripMined);
183 
184 #ifdef ASSERT
185   Node* uniqc = proj_true-&gt;unique_ctrl_out();
186   entry = head-&gt;skip_strip_mined()-&gt;in(LoopNode::EntryControl);
187   Node* predicate = find_predicate(entry);
188   if (predicate != NULL) {
189     entry = skip_loop_predicates(entry);
190   }
191   if (predicate != NULL &amp;&amp; UseLoopPredicate) {
192     // We may have two predicates, find first.
193     Node* n = find_predicate(entry);
194     if (n != NULL) {
195       predicate = n;
196       entry = skip_loop_predicates(entry);
197     }
198   }
199   if (predicate != NULL &amp;&amp; UseProfiledLoopPredicate) {
200     entry = find_predicate(entry);
201     if (entry != NULL) predicate = entry;
202   }
203   if (predicate != NULL) predicate = predicate-&gt;in(0);
204   assert(proj_true-&gt;is_IfTrue() &amp;&amp;
205          (predicate == NULL &amp;&amp; uniqc == head &amp;&amp; !head-&gt;is_strip_mined() ||
206           predicate == NULL &amp;&amp; uniqc == head-&gt;in(LoopNode::EntryControl) &amp;&amp; head-&gt;is_strip_mined() ||
207           predicate != NULL &amp;&amp; uniqc == predicate), &quot;by construction&quot;);
208 #endif
209   // Increment unswitch count
210   LoopNode* head_clone = old_new[head-&gt;_idx]-&gt;as_Loop();
211   int nct = head-&gt;unswitch_count() + 1;
212   head-&gt;set_unswitch_count(nct);
213   head_clone-&gt;set_unswitch_count(nct);
214   if (flattened_checks.size() &gt; 0) {
215     head-&gt;mark_flattened_arrays();
216   }
217 
218   // Add test to new &quot;if&quot; outside of loop
219   IfNode* invar_iff   = proj_true-&gt;in(0)-&gt;as_If();
220   Node* invar_iff_c   = invar_iff-&gt;in(0);
221   invar_iff-&gt;_prob    = unswitch_iff-&gt;_prob;
222   if (flattened_checks.size() &gt; 0) {
223     // Flattened array checks are used in
224     // Parse::array_store()/Parse::array_load() to switch between a
225     // legacy object array access and a flattened value array
226     // access. We want the performance impact on legacy accesses to be
227     // as small as possible so we make 2 copies of the loops: a fast
228     // one where all accesses are known to be legacy, a slow one where
229     // some accesses are to flattened arrays. Flattened array checks
230     // can be removed from the first one but not from the second one
231     // as it can have a mix of flattened/legacy accesses.
232     BoolNode* bol       = unswitch_iff-&gt;in(1)-&gt;clone()-&gt;as_Bool();
233     register_new_node(bol, invar_iff-&gt;in(0));
234     Node* cmp = bol-&gt;in(1)-&gt;clone();
235     register_new_node(cmp, invar_iff-&gt;in(0));
236     bol-&gt;set_req(1, cmp);
237     Node* in1 = NULL;
238     for (uint i = 0; i &lt; flattened_checks.size(); i++) {
239       Node* v = flattened_checks.at(i)-&gt;in(1)-&gt;in(1)-&gt;in(1);
240       if (in1 == NULL) {
241         in1 = v;
242       } else {
243         if (cmp-&gt;Opcode() == Op_CmpL) {
244           in1 = new OrLNode(in1, v);
245         } else {
246           in1 = new OrINode(in1, v);
247         }
248         register_new_node(in1, invar_iff-&gt;in(0));
249       }
250     }
251     cmp-&gt;set_req(1, in1);
252     invar_iff-&gt;set_req(1, bol);
253   } else {
254     BoolNode* bol       = unswitch_iff-&gt;in(1)-&gt;as_Bool();
255     invar_iff-&gt;set_req(1, bol);
256   }
257 
258   ProjNode* proj_false = invar_iff-&gt;proj_out(0)-&gt;as_Proj();
259 
260   // Hoist invariant casts out of each loop to the appropriate
261   // control projection.
262 
263   Node_List worklist;
264 
265   if (flattened_checks.size() &gt; 0) {
266     for (uint i = 0; i &lt; flattened_checks.size(); i++) {
267       IfNode* iff = flattened_checks.at(i)-&gt;as_If();
268       ProjNode* proj= iff-&gt;proj_out(0)-&gt;as_Proj();
269       // Copy to a worklist for easier manipulation
270       for (DUIterator_Fast jmax, j = proj-&gt;fast_outs(jmax); j &lt; jmax; j++) {
271         Node* use = proj-&gt;fast_out(j);
272         if (use-&gt;Opcode() == Op_CheckCastPP &amp;&amp; loop-&gt;is_invariant(use-&gt;in(1))) {
273           worklist.push(use);
274         }
275       }
276       ProjNode* invar_proj = invar_iff-&gt;proj_out(proj-&gt;_con)-&gt;as_Proj();
277       while (worklist.size() &gt; 0) {
278         Node* use = worklist.pop();
279         Node* nuse = use-&gt;clone();
280         nuse-&gt;set_req(0, invar_proj);
281         _igvn.replace_input_of(use, 1, nuse);
282         register_new_node(nuse, invar_proj);
283         // Same for the clone
284         Node* use_clone = old_new[use-&gt;_idx];
285         _igvn.replace_input_of(use_clone, 1, nuse);
286       }
287     }
288   } else {
289     for (DUIterator_Fast imax, i = unswitch_iff-&gt;fast_outs(imax); i &lt; imax; i++) {
290       ProjNode* proj= unswitch_iff-&gt;fast_out(i)-&gt;as_Proj();
291       // Copy to a worklist for easier manipulation
292       for (DUIterator_Fast jmax, j = proj-&gt;fast_outs(jmax); j &lt; jmax; j++) {
293         Node* use = proj-&gt;fast_out(j);
294         if (use-&gt;Opcode() == Op_CheckCastPP &amp;&amp; loop-&gt;is_invariant(use-&gt;in(1))) {
295           worklist.push(use);
296         }
297       }
298       ProjNode* invar_proj = invar_iff-&gt;proj_out(proj-&gt;_con)-&gt;as_Proj();
299       while (worklist.size() &gt; 0) {
300         Node* use = worklist.pop();
301         Node* nuse = use-&gt;clone();
302         nuse-&gt;set_req(0, invar_proj);
303         _igvn.replace_input_of(use, 1, nuse);
304         register_new_node(nuse, invar_proj);
305         // Same for the clone
306         Node* use_clone = old_new[use-&gt;_idx];
307         _igvn.replace_input_of(use_clone, 1, nuse);
308       }
309     }
310   }
311 
312   IfNode* unswitch_iff_clone = old_new[unswitch_iff-&gt;_idx]-&gt;as_If();
313   if (flattened_checks.size() &gt; 0) {
314     for (uint i = 0; i &lt; flattened_checks.size(); i++) {
315       IfNode* iff = flattened_checks.at(i)-&gt;as_If();
316       _igvn.rehash_node_delayed(iff);
317       short_circuit_if(old_new[iff-&gt;_idx]-&gt;as_If(), proj_false);
318     }
319   } else {
320     // Hardwire the control paths in the loops into if(true) and if(false)
321     _igvn.rehash_node_delayed(unswitch_iff);
322     short_circuit_if(unswitch_iff, proj_true);
323 
324     _igvn.rehash_node_delayed(unswitch_iff_clone);
325     short_circuit_if(unswitch_iff_clone, proj_false);
326   }
327 
328   // Reoptimize loops
329   loop-&gt;record_for_igvn();
330   for(int i = loop-&gt;_body.size() - 1; i &gt;= 0 ; i--) {
331     Node *n = loop-&gt;_body[i];
332     Node *n_clone = old_new[n-&gt;_idx];
333     _igvn._worklist.push(n_clone);
334   }
335 
336 #ifndef PRODUCT
337   if (TraceLoopUnswitching) {
338     tty-&gt;print_cr(&quot;Loop unswitching orig: %d @ %d  new: %d @ %d&quot;,
339                   head-&gt;_idx,                unswitch_iff-&gt;_idx,
340                   old_new[head-&gt;_idx]-&gt;_idx, unswitch_iff_clone-&gt;_idx);
341   }
342 #endif
343 
344   C-&gt;set_major_progress();
345 }
346 
347 //-------------------------create_slow_version_of_loop------------------------
348 // Create a slow version of the loop by cloning the loop
349 // and inserting an if to select fast-slow versions.
350 // Return control projection of the entry to the fast version.
351 ProjNode* PhaseIdealLoop::create_slow_version_of_loop(IdealLoopTree *loop,
352                                                       Node_List &amp;old_new,
353                                                       int opcode,
354                                                       CloneLoopMode mode) {
355   LoopNode* head  = loop-&gt;_head-&gt;as_Loop();
356   bool counted_loop = head-&gt;is_CountedLoop();
357   Node*     entry = head-&gt;skip_strip_mined()-&gt;in(LoopNode::EntryControl);
358   _igvn.rehash_node_delayed(entry);
359   IdealLoopTree* outer_loop = loop-&gt;_parent;
360 
361   head-&gt;verify_strip_mined(1);
362 
363   Node *cont      = _igvn.intcon(1);
364   set_ctrl(cont, C-&gt;root());
365   Node* opq       = new Opaque1Node(C, cont);
366   register_node(opq, outer_loop, entry, dom_depth(entry));
367   Node *bol       = new Conv2BNode(opq);
368   register_node(bol, outer_loop, entry, dom_depth(entry));
369   IfNode* iff = (opcode == Op_RangeCheck) ? new RangeCheckNode(entry, bol, PROB_MAX, COUNT_UNKNOWN) :
370     new IfNode(entry, bol, PROB_MAX, COUNT_UNKNOWN);
371   register_node(iff, outer_loop, entry, dom_depth(entry));
372   ProjNode* iffast = new IfTrueNode(iff);
373   register_node(iffast, outer_loop, iff, dom_depth(iff));
374   ProjNode* ifslow = new IfFalseNode(iff);
375   register_node(ifslow, outer_loop, iff, dom_depth(iff));
376 
377   // Clone the loop body.  The clone becomes the slow loop.  The
378   // original pre-header will (illegally) have 3 control users
379   // (old &amp; new loops &amp; new if).
380   clone_loop(loop, old_new, dom_depth(head-&gt;skip_strip_mined()), mode, iff);
381   assert(old_new[head-&gt;_idx]-&gt;is_Loop(), &quot;&quot; );
382 
383   // Fast (true) control
384   Node* iffast_pred = clone_loop_predicates(entry, iffast, !counted_loop);
385 
386   // Slow (false) control
387   Node* ifslow_pred = clone_loop_predicates(entry, ifslow, !counted_loop);
388 
389   Node* l = head-&gt;skip_strip_mined();
390   _igvn.replace_input_of(l, LoopNode::EntryControl, iffast_pred);
391   set_idom(l, iffast_pred, dom_depth(l));
392   LoopNode* slow_l = old_new[head-&gt;_idx]-&gt;as_Loop()-&gt;skip_strip_mined();
393   _igvn.replace_input_of(slow_l, LoopNode::EntryControl, ifslow_pred);
394   set_idom(slow_l, ifslow_pred, dom_depth(l));
395 
396   recompute_dom_depth();
397 
398   return iffast;
399 }
400 
401 LoopNode* PhaseIdealLoop::create_reserve_version_of_loop(IdealLoopTree *loop, CountedLoopReserveKit* lk) {
402   Node_List old_new;
403   LoopNode* head  = loop-&gt;_head-&gt;as_Loop();
404   bool counted_loop = head-&gt;is_CountedLoop();
405   Node*     entry = head-&gt;skip_strip_mined()-&gt;in(LoopNode::EntryControl);
406   _igvn.rehash_node_delayed(entry);
407   IdealLoopTree* outer_loop = head-&gt;is_strip_mined() ? loop-&gt;_parent-&gt;_parent : loop-&gt;_parent;
408 
409   ConINode* const_1 = _igvn.intcon(1);
410   set_ctrl(const_1, C-&gt;root());
411   IfNode* iff = new IfNode(entry, const_1, PROB_MAX, COUNT_UNKNOWN);
412   register_node(iff, outer_loop, entry, dom_depth(entry));
413   ProjNode* iffast = new IfTrueNode(iff);
414   register_node(iffast, outer_loop, iff, dom_depth(iff));
415   ProjNode* ifslow = new IfFalseNode(iff);
416   register_node(ifslow, outer_loop, iff, dom_depth(iff));
417 
418   // Clone the loop body.  The clone becomes the slow loop.  The
419   // original pre-header will (illegally) have 3 control users
420   // (old &amp; new loops &amp; new if).
421   clone_loop(loop, old_new, dom_depth(head), CloneIncludesStripMined, iff);
422   assert(old_new[head-&gt;_idx]-&gt;is_Loop(), &quot;&quot; );
423 
424   LoopNode* slow_head = old_new[head-&gt;_idx]-&gt;as_Loop();
425 
426 #ifndef PRODUCT
427   if (TraceLoopOpts) {
428     tty-&gt;print_cr(&quot;PhaseIdealLoop::create_reserve_version_of_loop:&quot;);
429     tty-&gt;print(&quot;\t iff = %d, &quot;, iff-&gt;_idx); iff-&gt;dump();
430     tty-&gt;print(&quot;\t iffast = %d, &quot;, iffast-&gt;_idx); iffast-&gt;dump();
431     tty-&gt;print(&quot;\t ifslow = %d, &quot;, ifslow-&gt;_idx); ifslow-&gt;dump();
432     tty-&gt;print(&quot;\t before replace_input_of: head = %d, &quot;, head-&gt;_idx); head-&gt;dump();
433     tty-&gt;print(&quot;\t before replace_input_of: slow_head = %d, &quot;, slow_head-&gt;_idx); slow_head-&gt;dump();
434   }
435 #endif
436 
437   // Fast (true) control
438   _igvn.replace_input_of(head-&gt;skip_strip_mined(), LoopNode::EntryControl, iffast);
439   // Slow (false) control
440   _igvn.replace_input_of(slow_head-&gt;skip_strip_mined(), LoopNode::EntryControl, ifslow);
441 
442   recompute_dom_depth();
443 
444   lk-&gt;set_iff(iff);
445 
446 #ifndef PRODUCT
447   if (TraceLoopOpts ) {
448     tty-&gt;print(&quot;\t after  replace_input_of: head = %d, &quot;, head-&gt;_idx); head-&gt;dump();
449     tty-&gt;print(&quot;\t after  replace_input_of: slow_head = %d, &quot;, slow_head-&gt;_idx); slow_head-&gt;dump();
450   }
451 #endif
452 
453   return slow_head-&gt;as_Loop();
454 }
455 
456 CountedLoopReserveKit::CountedLoopReserveKit(PhaseIdealLoop* phase, IdealLoopTree *loop, bool active = true) :
457   _phase(phase),
458   _lpt(loop),
459   _lp(NULL),
460   _iff(NULL),
461   _lp_reserved(NULL),
462   _has_reserved(false),
463   _use_new(false),
464   _active(active)
465   {
466     create_reserve();
467   };
468 
469 CountedLoopReserveKit::~CountedLoopReserveKit() {
470   if (!_active) {
471     return;
472   }
473 
474   if (_has_reserved &amp;&amp; !_use_new) {
475     // intcon(0)-&gt;iff-node reverts CF to the reserved copy
476     ConINode* const_0 = _phase-&gt;_igvn.intcon(0);
477     _phase-&gt;set_ctrl(const_0, _phase-&gt;C-&gt;root());
478     _iff-&gt;set_req(1, const_0);
479 
480     #ifndef PRODUCT
481       if (TraceLoopOpts) {
482         tty-&gt;print_cr(&quot;CountedLoopReserveKit::~CountedLoopReserveKit()&quot;);
483         tty-&gt;print(&quot;\t discard loop %d and revert to the reserved loop clone %d: &quot;, _lp-&gt;_idx, _lp_reserved-&gt;_idx);
484         _lp_reserved-&gt;dump();
485       }
486     #endif
487   }
488 }
489 
490 bool CountedLoopReserveKit::create_reserve() {
491   if (!_active) {
492     return false;
493   }
494 
495   if(!_lpt-&gt;_head-&gt;is_CountedLoop()) {
496     if (TraceLoopOpts) {
497       tty-&gt;print_cr(&quot;CountedLoopReserveKit::create_reserve: %d not counted loop&quot;, _lpt-&gt;_head-&gt;_idx);
498     }
499     return false;
500   }
501   CountedLoopNode *cl = _lpt-&gt;_head-&gt;as_CountedLoop();
502   if (!cl-&gt;is_valid_counted_loop()) {
503     if (TraceLoopOpts) {
504       tty-&gt;print_cr(&quot;CountedLoopReserveKit::create_reserve: %d not valid counted loop&quot;, cl-&gt;_idx);
505     }
506     return false; // skip malformed counted loop
507   }
508   if (!cl-&gt;is_main_loop()) {
509     bool loop_not_canonical = true;
510     if (cl-&gt;is_post_loop() &amp;&amp; (cl-&gt;slp_max_unroll() &gt; 0)) {
511       loop_not_canonical = false;
512     }
513     // only reject some loop forms
514     if (loop_not_canonical) {
515       if (TraceLoopOpts) {
516         tty-&gt;print_cr(&quot;CountedLoopReserveKit::create_reserve: %d not canonical loop&quot;, cl-&gt;_idx);
517       }
518       return false; // skip normal, pre, and post (conditionally) loops
519     }
520   }
521 
522   _lp = _lpt-&gt;_head-&gt;as_Loop();
523   _lp_reserved = _phase-&gt;create_reserve_version_of_loop(_lpt, this);
524 
525   if (!_lp_reserved-&gt;is_CountedLoop()) {
526     return false;
527   }
528 
529   Node* ifslow_pred = _lp_reserved-&gt;skip_strip_mined()-&gt;in(LoopNode::EntryControl);
530 
531   if (!ifslow_pred-&gt;is_IfFalse()) {
532     return false;
533   }
534 
535   Node* iff = ifslow_pred-&gt;in(0);
536   if (!iff-&gt;is_If() || iff != _iff) {
537     return false;
538   }
539 
540   if (iff-&gt;in(1)-&gt;Opcode() != Op_ConI) {
541     return false;
542   }
543 
544   return _has_reserved = true;
545 }
    </pre>
  </body>
</html>