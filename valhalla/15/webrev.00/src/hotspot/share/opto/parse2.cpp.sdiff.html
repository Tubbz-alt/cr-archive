<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/opto/parse2.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="parse1.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="phase.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/opto/parse2.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 126         Node* obj_size  = NULL;
 127         kill_dead_locals();
 128         // Re-execute flattened array load if buffering triggers deoptimization
 129         PreserveReexecuteState preexecs(this);
 130         jvms()-&gt;set_bci(_bci);
 131         jvms()-&gt;set_should_reexecute(true);
 132         inc_sp(2);
 133         Node* alloc_obj = new_instance(elem_klass, NULL, &amp;obj_size, /*deoptimize_on_exception=*/true);
 134 
 135         AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_obj, &amp;_gvn);
 136         assert(alloc-&gt;maybe_set_complete(&amp;_gvn), &quot;&quot;);
 137         alloc-&gt;initialization()-&gt;set_complete_with_arraycopy();
 138 
 139         // This membar keeps this access to an unknown flattened array
 140         // correctly ordered with other unknown and known flattened
 141         // array accesses.
 142         insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::VALUES));
 143 
 144         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 145         // Unknown value type might contain reference fields
<span class="line-modified"> 146         if (!bs-&gt;array_copy_requires_gc_barriers(false, T_OBJECT, false, BarrierSetC2::Parsing)) {</span>

 147           int base_off = sizeof(instanceOopDesc);
 148           Node* dst_base = basic_plus_adr(alloc_obj, base_off);
 149           Node* countx = obj_size;
 150           countx = _gvn.transform(new SubXNode(countx, MakeConX(base_off)));
 151           countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));
 152 
 153           assert(Klass::_lh_log2_element_size_shift == 0, &quot;use shift in place&quot;);
 154           Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));
 155           Node* elem_shift = make_load(NULL, lhp, TypeInt::INT, T_INT, MemNode::unordered);
 156           uint header = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE);
 157           Node* base  = basic_plus_adr(ary, header);
 158           idx = Compile::conv_I2X_index(&amp;_gvn, idx, TypeInt::POS, control());
 159           Node* scale = _gvn.transform(new LShiftXNode(idx, elem_shift));
 160           Node* adr = basic_plus_adr(ary, base, scale);
 161 
 162           access_clone(adr, dst_base, countx, false);
 163         } else {
 164           ideal.sync_kit(this);
 165           ideal.make_leaf_call(OptoRuntime::load_unknown_value_Type(),
 166                                CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_value),
</pre>
<hr />
<pre>
2265     record_for_igvn(eq_region);
2266     set_control(_gvn.transform(eq_region));
2267     set_i_o(_gvn.transform(eq_io_phi));
2268     set_all_memory(_gvn.transform(eq_mem_phi));
2269   }
2270 }
2271 
2272 bool Parse::path_is_suitable_for_uncommon_trap(float prob) const {
2273   // Don&#39;t want to speculate on uncommon traps when running with -Xcomp
2274   if (!UseInterpreter) {
2275     return false;
2276   }
2277   return (seems_never_taken(prob) &amp;&amp; seems_stable_comparison());
2278 }
2279 
2280 void Parse::maybe_add_predicate_after_if(Block* path) {
2281   if (path-&gt;is_SEL_head() &amp;&amp; path-&gt;preds_parsed() == 0) {
2282     // Add predicates at bci of if dominating the loop so traps can be
2283     // recorded on the if&#39;s profile data
2284     int bc_depth = repush_if_args();
<span class="line-modified">2285     add_predicate();</span>
2286     dec_sp(bc_depth);
2287     path-&gt;set_has_predicates();
2288   }
2289 }
2290 
2291 
2292 //----------------------------adjust_map_after_if------------------------------
2293 // Adjust the JVM state to reflect the result of taking this path.
2294 // Basically, it means inspecting the CmpNode controlling this
2295 // branch, seeing how it constrains a tested value, and then
2296 // deciding if it&#39;s worth our while to encode this constraint
2297 // as graph nodes in the current abstract interpretation map.
2298 void Parse::adjust_map_after_if(BoolTest::mask btest, Node* c, float prob, Block* path) {
2299   if (!c-&gt;is_Cmp()) {
2300     maybe_add_predicate_after_if(path);
2301     return;
2302   }
2303 
2304   if (stopped() || btest == BoolTest::illegal) {
2305     return;                             // nothing to do
</pre>
</td>
<td>
<hr />
<pre>
 126         Node* obj_size  = NULL;
 127         kill_dead_locals();
 128         // Re-execute flattened array load if buffering triggers deoptimization
 129         PreserveReexecuteState preexecs(this);
 130         jvms()-&gt;set_bci(_bci);
 131         jvms()-&gt;set_should_reexecute(true);
 132         inc_sp(2);
 133         Node* alloc_obj = new_instance(elem_klass, NULL, &amp;obj_size, /*deoptimize_on_exception=*/true);
 134 
 135         AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_obj, &amp;_gvn);
 136         assert(alloc-&gt;maybe_set_complete(&amp;_gvn), &quot;&quot;);
 137         alloc-&gt;initialization()-&gt;set_complete_with_arraycopy();
 138 
 139         // This membar keeps this access to an unknown flattened array
 140         // correctly ordered with other unknown and known flattened
 141         // array accesses.
 142         insert_mem_bar_volatile(Op_MemBarCPUOrder, C-&gt;get_alias_index(TypeAryPtr::VALUES));
 143 
 144         BarrierSetC2* bs = BarrierSet::barrier_set()-&gt;barrier_set_c2();
 145         // Unknown value type might contain reference fields
<span class="line-modified"> 146         if (false &amp;&amp; !bs-&gt;array_copy_requires_gc_barriers(false, T_OBJECT, false, BarrierSetC2::Parsing)) {</span>
<span class="line-added"> 147           // FIXME 8230656 also merge changes from 8238759 in</span>
 148           int base_off = sizeof(instanceOopDesc);
 149           Node* dst_base = basic_plus_adr(alloc_obj, base_off);
 150           Node* countx = obj_size;
 151           countx = _gvn.transform(new SubXNode(countx, MakeConX(base_off)));
 152           countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));
 153 
 154           assert(Klass::_lh_log2_element_size_shift == 0, &quot;use shift in place&quot;);
 155           Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));
 156           Node* elem_shift = make_load(NULL, lhp, TypeInt::INT, T_INT, MemNode::unordered);
 157           uint header = arrayOopDesc::base_offset_in_bytes(T_VALUETYPE);
 158           Node* base  = basic_plus_adr(ary, header);
 159           idx = Compile::conv_I2X_index(&amp;_gvn, idx, TypeInt::POS, control());
 160           Node* scale = _gvn.transform(new LShiftXNode(idx, elem_shift));
 161           Node* adr = basic_plus_adr(ary, base, scale);
 162 
 163           access_clone(adr, dst_base, countx, false);
 164         } else {
 165           ideal.sync_kit(this);
 166           ideal.make_leaf_call(OptoRuntime::load_unknown_value_Type(),
 167                                CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_value),
</pre>
<hr />
<pre>
2266     record_for_igvn(eq_region);
2267     set_control(_gvn.transform(eq_region));
2268     set_i_o(_gvn.transform(eq_io_phi));
2269     set_all_memory(_gvn.transform(eq_mem_phi));
2270   }
2271 }
2272 
2273 bool Parse::path_is_suitable_for_uncommon_trap(float prob) const {
2274   // Don&#39;t want to speculate on uncommon traps when running with -Xcomp
2275   if (!UseInterpreter) {
2276     return false;
2277   }
2278   return (seems_never_taken(prob) &amp;&amp; seems_stable_comparison());
2279 }
2280 
2281 void Parse::maybe_add_predicate_after_if(Block* path) {
2282   if (path-&gt;is_SEL_head() &amp;&amp; path-&gt;preds_parsed() == 0) {
2283     // Add predicates at bci of if dominating the loop so traps can be
2284     // recorded on the if&#39;s profile data
2285     int bc_depth = repush_if_args();
<span class="line-modified">2286     add_empty_predicates();</span>
2287     dec_sp(bc_depth);
2288     path-&gt;set_has_predicates();
2289   }
2290 }
2291 
2292 
2293 //----------------------------adjust_map_after_if------------------------------
2294 // Adjust the JVM state to reflect the result of taking this path.
2295 // Basically, it means inspecting the CmpNode controlling this
2296 // branch, seeing how it constrains a tested value, and then
2297 // deciding if it&#39;s worth our while to encode this constraint
2298 // as graph nodes in the current abstract interpretation map.
2299 void Parse::adjust_map_after_if(BoolTest::mask btest, Node* c, float prob, Block* path) {
2300   if (!c-&gt;is_Cmp()) {
2301     maybe_add_predicate_after_if(path);
2302     return;
2303   }
2304 
2305   if (stopped() || btest == BoolTest::illegal) {
2306     return;                             // nothing to do
</pre>
</td>
</tr>
</table>
<center><a href="parse1.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="phase.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>