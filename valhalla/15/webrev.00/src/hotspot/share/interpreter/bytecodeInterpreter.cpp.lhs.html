<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/interpreter/bytecodeInterpreter.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
<a name="1" id="anc1"></a><span class="line-modified">   2  * Copyright (c) 2002, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 // no precompiled headers
  26 #include &quot;classfile/vmSymbols.hpp&quot;
  27 #include &quot;gc/shared/collectedHeap.hpp&quot;
  28 #include &quot;gc/shared/threadLocalAllocBuffer.inline.hpp&quot;
  29 #include &quot;interpreter/bytecodeHistogram.hpp&quot;
  30 #include &quot;interpreter/bytecodeInterpreter.hpp&quot;
  31 #include &quot;interpreter/bytecodeInterpreter.inline.hpp&quot;
  32 #include &quot;interpreter/bytecodeInterpreterProfiling.hpp&quot;
  33 #include &quot;interpreter/interpreter.hpp&quot;
  34 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  35 #include &quot;logging/log.hpp&quot;
  36 #include &quot;memory/resourceArea.hpp&quot;
  37 #include &quot;memory/universe.hpp&quot;
  38 #include &quot;oops/constantPool.inline.hpp&quot;
  39 #include &quot;oops/cpCache.inline.hpp&quot;
  40 #include &quot;oops/method.inline.hpp&quot;
  41 #include &quot;oops/methodCounters.hpp&quot;
  42 #include &quot;oops/objArrayKlass.hpp&quot;
  43 #include &quot;oops/objArrayOop.inline.hpp&quot;
  44 #include &quot;oops/oop.inline.hpp&quot;
  45 #include &quot;oops/typeArrayOop.inline.hpp&quot;
  46 #include &quot;prims/jvmtiExport.hpp&quot;
  47 #include &quot;prims/jvmtiThreadState.hpp&quot;
  48 #include &quot;runtime/atomic.hpp&quot;
  49 #include &quot;runtime/biasedLocking.hpp&quot;
  50 #include &quot;runtime/frame.inline.hpp&quot;
  51 #include &quot;runtime/handles.inline.hpp&quot;
  52 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  53 #include &quot;runtime/orderAccess.hpp&quot;
  54 #include &quot;runtime/sharedRuntime.hpp&quot;
  55 #include &quot;runtime/threadCritical.hpp&quot;
  56 #include &quot;utilities/exceptions.hpp&quot;
  57 
  58 // no precompiled headers
  59 #ifdef CC_INTERP
  60 
  61 /*
  62  * USELABELS - If using GCC, then use labels for the opcode dispatching
  63  * rather -then a switch statement. This improves performance because it
  64  * gives us the opportunity to have the instructions that calculate the
  65  * next opcode to jump to be intermixed with the rest of the instructions
  66  * that implement the opcode (see UPDATE_PC_AND_TOS_AND_CONTINUE macro).
  67  */
  68 #undef USELABELS
  69 #ifdef __GNUC__
  70 /*
  71    ASSERT signifies debugging. It is much easier to step thru bytecodes if we
  72    don&#39;t use the computed goto approach.
  73 */
  74 #ifndef ASSERT
  75 #define USELABELS
  76 #endif
  77 #endif
  78 
  79 #undef CASE
  80 #ifdef USELABELS
  81 #define CASE(opcode) opc ## opcode
  82 #define DEFAULT opc_default
  83 #else
  84 #define CASE(opcode) case Bytecodes:: opcode
  85 #define DEFAULT default
  86 #endif
  87 
  88 /*
  89  * PREFETCH_OPCCODE - Some compilers do better if you prefetch the next
  90  * opcode before going back to the top of the while loop, rather then having
  91  * the top of the while loop handle it. This provides a better opportunity
  92  * for instruction scheduling. Some compilers just do this prefetch
  93  * automatically. Some actually end up with worse performance if you
  94  * force the prefetch. Solaris gcc seems to do better, but cc does worse.
  95  */
  96 #undef PREFETCH_OPCCODE
  97 #define PREFETCH_OPCCODE
  98 
  99 /*
 100   Interpreter safepoint: it is expected that the interpreter will have no live
 101   handles of its own creation live at an interpreter safepoint. Therefore we
 102   run a HandleMarkCleaner and trash all handles allocated in the call chain
 103   since the JavaCalls::call_helper invocation that initiated the chain.
 104   There really shouldn&#39;t be any handles remaining to trash but this is cheap
 105   in relation to a safepoint.
 106 */
 107 #define SAFEPOINT                                                                 \
 108     {                                                                             \
 109        /* zap freed handles rather than GC&#39;ing them */                            \
 110        HandleMarkCleaner __hmc(THREAD);                                           \
 111        CALL_VM(SafepointMechanism::block_if_requested(THREAD), handle_exception); \
 112     }
 113 
 114 /*
 115  * VM_JAVA_ERROR - Macro for throwing a java exception from
 116  * the interpreter loop. Should really be a CALL_VM but there
 117  * is no entry point to do the transition to vm so we just
 118  * do it by hand here.
 119  */
 120 #define VM_JAVA_ERROR_NO_JUMP(name, msg, note_a_trap)                             \
 121     DECACHE_STATE();                                                              \
 122     SET_LAST_JAVA_FRAME();                                                        \
 123     {                                                                             \
 124        InterpreterRuntime::note_a_trap(THREAD, istate-&gt;method(), BCI());          \
 125        ThreadInVMfromJava trans(THREAD);                                          \
 126        Exceptions::_throw_msg(THREAD, __FILE__, __LINE__, name, msg);             \
 127     }                                                                             \
 128     RESET_LAST_JAVA_FRAME();                                                      \
 129     CACHE_STATE();
 130 
 131 // Normal throw of a java error.
 132 #define VM_JAVA_ERROR(name, msg, note_a_trap)                                     \
 133     VM_JAVA_ERROR_NO_JUMP(name, msg, note_a_trap)                                 \
 134     goto handle_exception;
 135 
 136 #ifdef PRODUCT
 137 #define DO_UPDATE_INSTRUCTION_COUNT(opcode)
 138 #else
 139 #define DO_UPDATE_INSTRUCTION_COUNT(opcode)                                                          \
 140 {                                                                                                    \
 141     BytecodeCounter::_counter_value++;                                                               \
 142     BytecodeHistogram::_counters[(Bytecodes::Code)opcode]++;                                         \
 143     if (StopInterpreterAt &amp;&amp; StopInterpreterAt == BytecodeCounter::_counter_value) os::breakpoint(); \
 144     if (TraceBytecodes) {                                                                            \
 145       CALL_VM((void)InterpreterRuntime::trace_bytecode(THREAD, 0,                    \
 146                                         topOfStack[Interpreter::expr_index_at(1)],   \
 147                                         topOfStack[Interpreter::expr_index_at(2)]),  \
 148                                         handle_exception);                           \
 149     }                                                                                \
 150 }
 151 #endif
 152 
 153 #undef DEBUGGER_SINGLE_STEP_NOTIFY
 154 #ifdef VM_JVMTI
 155 /* NOTE: (kbr) This macro must be called AFTER the PC has been
 156    incremented. JvmtiExport::at_single_stepping_point() may cause a
 157    breakpoint opcode to get inserted at the current PC to allow the
 158    debugger to coalesce single-step events.
 159 
 160    As a result if we call at_single_stepping_point() we refetch opcode
 161    to get the current opcode. This will override any other prefetching
 162    that might have occurred.
 163 */
 164 #define DEBUGGER_SINGLE_STEP_NOTIFY()                                            \
 165 {                                                                                \
 166       if (_jvmti_interp_events) {                                                \
 167         if (JvmtiExport::should_post_single_step()) {                            \
 168           DECACHE_STATE();                                                       \
 169           SET_LAST_JAVA_FRAME();                                                 \
 170           ThreadInVMfromJava trans(THREAD);                                      \
 171           JvmtiExport::at_single_stepping_point(THREAD,                          \
 172                                           istate-&gt;method(),                      \
 173                                           pc);                                   \
 174           RESET_LAST_JAVA_FRAME();                                               \
 175           CACHE_STATE();                                                         \
 176           if (THREAD-&gt;pop_frame_pending() &amp;&amp;                                     \
 177               !THREAD-&gt;pop_frame_in_process()) {                                 \
 178             goto handle_Pop_Frame;                                               \
 179           }                                                                      \
 180           if (THREAD-&gt;jvmti_thread_state() &amp;&amp;                                    \
 181               THREAD-&gt;jvmti_thread_state()-&gt;is_earlyret_pending()) {             \
 182             goto handle_Early_Return;                                            \
 183           }                                                                      \
 184           opcode = *pc;                                                          \
 185         }                                                                        \
 186       }                                                                          \
 187 }
 188 #else
 189 #define DEBUGGER_SINGLE_STEP_NOTIFY()
 190 #endif
 191 
 192 /*
 193  * CONTINUE - Macro for executing the next opcode.
 194  */
 195 #undef CONTINUE
 196 #ifdef USELABELS
 197 // Have to do this dispatch this way in C++ because otherwise gcc complains about crossing an
 198 // initialization (which is is the initialization of the table pointer...)
 199 #define DISPATCH(opcode) goto *(void*)dispatch_table[opcode]
 200 #define CONTINUE {                              \
 201         opcode = *pc;                           \
 202         DO_UPDATE_INSTRUCTION_COUNT(opcode);    \
 203         DEBUGGER_SINGLE_STEP_NOTIFY();          \
 204         DISPATCH(opcode);                       \
 205     }
 206 #else
 207 #ifdef PREFETCH_OPCCODE
 208 #define CONTINUE {                              \
 209         opcode = *pc;                           \
 210         DO_UPDATE_INSTRUCTION_COUNT(opcode);    \
 211         DEBUGGER_SINGLE_STEP_NOTIFY();          \
 212         continue;                               \
 213     }
 214 #else
 215 #define CONTINUE {                              \
 216         DO_UPDATE_INSTRUCTION_COUNT(opcode);    \
 217         DEBUGGER_SINGLE_STEP_NOTIFY();          \
 218         continue;                               \
 219     }
 220 #endif
 221 #endif
 222 
 223 
 224 #define UPDATE_PC(opsize) {pc += opsize; }
 225 /*
 226  * UPDATE_PC_AND_TOS - Macro for updating the pc and topOfStack.
 227  */
 228 #undef UPDATE_PC_AND_TOS
 229 #define UPDATE_PC_AND_TOS(opsize, stack) \
 230     {pc += opsize; MORE_STACK(stack); }
 231 
 232 /*
 233  * UPDATE_PC_AND_TOS_AND_CONTINUE - Macro for updating the pc and topOfStack,
 234  * and executing the next opcode. It&#39;s somewhat similar to the combination
 235  * of UPDATE_PC_AND_TOS and CONTINUE, but with some minor optimizations.
 236  */
 237 #undef UPDATE_PC_AND_TOS_AND_CONTINUE
 238 #ifdef USELABELS
 239 #define UPDATE_PC_AND_TOS_AND_CONTINUE(opsize, stack) {         \
 240         pc += opsize; opcode = *pc; MORE_STACK(stack);          \
 241         DO_UPDATE_INSTRUCTION_COUNT(opcode);                    \
 242         DEBUGGER_SINGLE_STEP_NOTIFY();                          \
 243         DISPATCH(opcode);                                       \
 244     }
 245 
 246 #define UPDATE_PC_AND_CONTINUE(opsize) {                        \
 247         pc += opsize; opcode = *pc;                             \
 248         DO_UPDATE_INSTRUCTION_COUNT(opcode);                    \
 249         DEBUGGER_SINGLE_STEP_NOTIFY();                          \
 250         DISPATCH(opcode);                                       \
 251     }
 252 #else
 253 #ifdef PREFETCH_OPCCODE
 254 #define UPDATE_PC_AND_TOS_AND_CONTINUE(opsize, stack) {         \
 255         pc += opsize; opcode = *pc; MORE_STACK(stack);          \
 256         DO_UPDATE_INSTRUCTION_COUNT(opcode);                    \
 257         DEBUGGER_SINGLE_STEP_NOTIFY();                          \
 258         goto do_continue;                                       \
 259     }
 260 
 261 #define UPDATE_PC_AND_CONTINUE(opsize) {                        \
 262         pc += opsize; opcode = *pc;                             \
 263         DO_UPDATE_INSTRUCTION_COUNT(opcode);                    \
 264         DEBUGGER_SINGLE_STEP_NOTIFY();                          \
 265         goto do_continue;                                       \
 266     }
 267 #else
 268 #define UPDATE_PC_AND_TOS_AND_CONTINUE(opsize, stack) { \
 269         pc += opsize; MORE_STACK(stack);                \
 270         DO_UPDATE_INSTRUCTION_COUNT(opcode);            \
 271         DEBUGGER_SINGLE_STEP_NOTIFY();                  \
 272         goto do_continue;                               \
 273     }
 274 
 275 #define UPDATE_PC_AND_CONTINUE(opsize) {                \
 276         pc += opsize;                                   \
 277         DO_UPDATE_INSTRUCTION_COUNT(opcode);            \
 278         DEBUGGER_SINGLE_STEP_NOTIFY();                  \
 279         goto do_continue;                               \
 280     }
 281 #endif /* PREFETCH_OPCCODE */
 282 #endif /* USELABELS */
 283 
 284 // About to call a new method, update the save the adjusted pc and return to frame manager
 285 #define UPDATE_PC_AND_RETURN(opsize)  \
 286    DECACHE_TOS();                     \
 287    istate-&gt;set_bcp(pc+opsize);        \
 288    return;
 289 
 290 
 291 #define METHOD istate-&gt;method()
 292 #define GET_METHOD_COUNTERS(res)    \
 293   res = METHOD-&gt;method_counters();  \
 294   if (res == NULL) {                \
 295     CALL_VM(res = InterpreterRuntime::build_method_counters(THREAD, METHOD), handle_exception); \
 296   }
 297 
 298 #define OSR_REQUEST(res, branch_pc) \
 299             CALL_VM(res=InterpreterRuntime::frequency_counter_overflow(THREAD, branch_pc), handle_exception);
 300 /*
 301  * For those opcodes that need to have a GC point on a backwards branch
 302  */
 303 
 304 // Backedge counting is kind of strange. The asm interpreter will increment
 305 // the backedge counter as a separate counter but it does it&#39;s comparisons
 306 // to the sum (scaled) of invocation counter and backedge count to make
 307 // a decision. Seems kind of odd to sum them together like that
 308 
 309 // skip is delta from current bcp/bci for target, branch_pc is pre-branch bcp
 310 
 311 
 312 #define DO_BACKEDGE_CHECKS(skip, branch_pc)                                                         \
 313     if ((skip) &lt;= 0) {                                                                              \
 314       MethodCounters* mcs;                                                                          \
 315       GET_METHOD_COUNTERS(mcs);                                                                     \
 316       if (UseLoopCounter) {                                                                         \
 317         bool do_OSR = UseOnStackReplacement;                                                        \
 318         mcs-&gt;backedge_counter()-&gt;increment();                                                       \
 319         if (ProfileInterpreter) {                                                                   \
 320           BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);                                   \
 321           /* Check for overflow against MDO count. */                                               \
 322           do_OSR = do_OSR                                                                           \
 323             &amp;&amp; (mdo_last_branch_taken_count &gt;= (uint)InvocationCounter::InterpreterBackwardBranchLimit)\
 324             /* When ProfileInterpreter is on, the backedge_count comes     */                       \
 325             /* from the methodDataOop, which value does not get reset on   */                       \
 326             /* the call to frequency_counter_overflow(). To avoid          */                       \
 327             /* excessive calls to the overflow routine while the method is */                       \
 328             /* being compiled, add a second test to make sure the overflow */                       \
 329             /* function is called only once every overflow_frequency.      */                       \
 330             &amp;&amp; (!(mdo_last_branch_taken_count &amp; 1023));                                             \
 331         } else {                                                                                    \
 332           /* check for overflow of backedge counter */                                              \
 333           do_OSR = do_OSR                                                                           \
 334             &amp;&amp; mcs-&gt;invocation_counter()-&gt;reached_InvocationLimit(mcs-&gt;backedge_counter());         \
 335         }                                                                                           \
 336         if (do_OSR) {                                                                               \
 337           nmethod* osr_nmethod;                                                                     \
 338           OSR_REQUEST(osr_nmethod, branch_pc);                                                      \
 339           if (osr_nmethod != NULL &amp;&amp; osr_nmethod-&gt;is_in_use()) {                                    \
 340             intptr_t* buf;                                                                          \
 341             /* Call OSR migration with last java frame only, no checks. */                          \
 342             CALL_VM_NAKED_LJF(buf=SharedRuntime::OSR_migration_begin(THREAD));                      \
 343             istate-&gt;set_msg(do_osr);                                                                \
 344             istate-&gt;set_osr_buf((address)buf);                                                      \
 345             istate-&gt;set_osr_entry(osr_nmethod-&gt;osr_entry());                                        \
 346             return;                                                                                 \
 347           }                                                                                         \
 348         }                                                                                           \
 349       }  /* UseCompiler ... */                                                                      \
 350       SAFEPOINT;                                                                                    \
 351     }
 352 
 353 /*
 354  * For those opcodes that need to have a GC point on a backwards branch
 355  */
 356 
 357 /*
 358  * Macros for caching and flushing the interpreter state. Some local
 359  * variables need to be flushed out to the frame before we do certain
 360  * things (like pushing frames or becomming gc safe) and some need to
 361  * be recached later (like after popping a frame). We could use one
 362  * macro to cache or decache everything, but this would be less then
 363  * optimal because we don&#39;t always need to cache or decache everything
 364  * because some things we know are already cached or decached.
 365  */
 366 #undef DECACHE_TOS
 367 #undef CACHE_TOS
 368 #undef CACHE_PREV_TOS
 369 #define DECACHE_TOS()    istate-&gt;set_stack(topOfStack);
 370 
 371 #define CACHE_TOS()      topOfStack = (intptr_t *)istate-&gt;stack();
 372 
 373 #undef DECACHE_PC
 374 #undef CACHE_PC
 375 #define DECACHE_PC()    istate-&gt;set_bcp(pc);
 376 #define CACHE_PC()      pc = istate-&gt;bcp();
 377 #define CACHE_CP()      cp = istate-&gt;constants();
 378 #define CACHE_LOCALS()  locals = istate-&gt;locals();
 379 #undef CACHE_FRAME
 380 #define CACHE_FRAME()
 381 
 382 // BCI() returns the current bytecode-index.
 383 #undef  BCI
 384 #define BCI()           ((int)(intptr_t)(pc - (intptr_t)istate-&gt;method()-&gt;code_base()))
 385 
 386 /*
 387  * CHECK_NULL - Macro for throwing a NullPointerException if the object
 388  * passed is a null ref.
 389  * On some architectures/platforms it should be possible to do this implicitly
 390  */
 391 #undef CHECK_NULL
 392 #define CHECK_NULL(obj_)                                                                         \
 393         if ((obj_) == NULL) {                                                                    \
 394           VM_JAVA_ERROR(vmSymbols::java_lang_NullPointerException(), NULL, note_nullCheck_trap); \
 395         }                                                                                        \
 396         VERIFY_OOP(obj_)
 397 
 398 #define VMdoubleConstZero() 0.0
 399 #define VMdoubleConstOne() 1.0
 400 #define VMlongConstZero() (max_jlong-max_jlong)
 401 #define VMlongConstOne() ((max_jlong-max_jlong)+1)
 402 
 403 /*
 404  * Alignment
 405  */
 406 #define VMalignWordUp(val)          (((uintptr_t)(val) + 3) &amp; ~3)
 407 
 408 // Decache the interpreter state that interpreter modifies directly (i.e. GC is indirect mod)
 409 #define DECACHE_STATE() DECACHE_PC(); DECACHE_TOS();
 410 
 411 // Reload interpreter state after calling the VM or a possible GC
 412 #define CACHE_STATE()   \
 413         CACHE_TOS();    \
 414         CACHE_PC();     \
 415         CACHE_CP();     \
 416         CACHE_LOCALS();
 417 
 418 // Call the VM with last java frame only.
 419 #define CALL_VM_NAKED_LJF(func)                                    \
 420         DECACHE_STATE();                                           \
 421         SET_LAST_JAVA_FRAME();                                     \
 422         func;                                                      \
 423         RESET_LAST_JAVA_FRAME();                                   \
 424         CACHE_STATE();
 425 
 426 // Call the VM. Don&#39;t check for pending exceptions.
 427 #define CALL_VM_NOCHECK(func)                                      \
 428         CALL_VM_NAKED_LJF(func)                                    \
 429         if (THREAD-&gt;pop_frame_pending() &amp;&amp;                         \
 430             !THREAD-&gt;pop_frame_in_process()) {                     \
 431           goto handle_Pop_Frame;                                   \
 432         }                                                          \
 433         if (THREAD-&gt;jvmti_thread_state() &amp;&amp;                        \
 434             THREAD-&gt;jvmti_thread_state()-&gt;is_earlyret_pending()) { \
 435           goto handle_Early_Return;                                \
 436         }
 437 
 438 // Call the VM and check for pending exceptions
 439 #define CALL_VM(func, label) {                                     \
 440           CALL_VM_NOCHECK(func);                                   \
 441           if (THREAD-&gt;has_pending_exception()) goto label;         \
 442         }
 443 
 444 /*
 445  * BytecodeInterpreter::run(interpreterState istate)
 446  * BytecodeInterpreter::runWithChecks(interpreterState istate)
 447  *
 448  * The real deal. This is where byte codes actually get interpreted.
 449  * Basically it&#39;s a big while loop that iterates until we return from
 450  * the method passed in.
 451  *
 452  * The runWithChecks is used if JVMTI is enabled.
 453  *
 454  */
 455 #if defined(VM_JVMTI)
 456 void
 457 BytecodeInterpreter::runWithChecks(interpreterState istate) {
 458 #else
 459 void
 460 BytecodeInterpreter::run(interpreterState istate) {
 461 #endif
 462 
 463   // In order to simplify some tests based on switches set at runtime
 464   // we invoke the interpreter a single time after switches are enabled
 465   // and set simpler to to test variables rather than method calls or complex
 466   // boolean expressions.
 467 
 468   static int initialized = 0;
 469   static int checkit = 0;
 470   static intptr_t* c_addr = NULL;
 471   static intptr_t  c_value;
 472 
 473   if (checkit &amp;&amp; *c_addr != c_value) {
 474     os::breakpoint();
 475   }
 476 #ifdef VM_JVMTI
 477   static bool _jvmti_interp_events = 0;
 478 #endif
 479 
 480   static int _compiling;  // (UseCompiler || CountCompiledCalls)
 481 
 482 #ifdef ASSERT
 483   if (istate-&gt;_msg != initialize) {
 484     assert(labs(istate-&gt;_stack_base - istate-&gt;_stack_limit) == (istate-&gt;_method-&gt;max_stack() + 1), &quot;bad stack limit&quot;);
 485     IA32_ONLY(assert(istate-&gt;_stack_limit == istate-&gt;_thread-&gt;last_Java_sp() + 1, &quot;wrong&quot;));
 486   }
 487   // Verify linkages.
 488   interpreterState l = istate;
 489   do {
 490     assert(l == l-&gt;_self_link, &quot;bad link&quot;);
 491     l = l-&gt;_prev_link;
 492   } while (l != NULL);
 493   // Screwups with stack management usually cause us to overwrite istate
 494   // save a copy so we can verify it.
 495   interpreterState orig = istate;
 496 #endif
 497 
 498   intptr_t*        topOfStack = (intptr_t *)istate-&gt;stack(); /* access with STACK macros */
 499   address          pc = istate-&gt;bcp();
 500   jubyte opcode;
 501   intptr_t*        locals = istate-&gt;locals();
 502   ConstantPoolCache*    cp = istate-&gt;constants(); // method()-&gt;constants()-&gt;cache()
 503 #ifdef LOTS_OF_REGS
 504   JavaThread*      THREAD = istate-&gt;thread();
 505 #else
 506 #undef THREAD
 507 #define THREAD istate-&gt;thread()
 508 #endif
 509 
 510 #ifdef USELABELS
 511   const static void* const opclabels_data[256] = {
 512 /* 0x00 */ &amp;&amp;opc_nop,     &amp;&amp;opc_aconst_null,&amp;&amp;opc_iconst_m1,&amp;&amp;opc_iconst_0,
 513 /* 0x04 */ &amp;&amp;opc_iconst_1,&amp;&amp;opc_iconst_2,   &amp;&amp;opc_iconst_3, &amp;&amp;opc_iconst_4,
 514 /* 0x08 */ &amp;&amp;opc_iconst_5,&amp;&amp;opc_lconst_0,   &amp;&amp;opc_lconst_1, &amp;&amp;opc_fconst_0,
 515 /* 0x0C */ &amp;&amp;opc_fconst_1,&amp;&amp;opc_fconst_2,   &amp;&amp;opc_dconst_0, &amp;&amp;opc_dconst_1,
 516 
 517 /* 0x10 */ &amp;&amp;opc_bipush, &amp;&amp;opc_sipush, &amp;&amp;opc_ldc,    &amp;&amp;opc_ldc_w,
 518 /* 0x14 */ &amp;&amp;opc_ldc2_w, &amp;&amp;opc_iload,  &amp;&amp;opc_lload,  &amp;&amp;opc_fload,
 519 /* 0x18 */ &amp;&amp;opc_dload,  &amp;&amp;opc_aload,  &amp;&amp;opc_iload_0,&amp;&amp;opc_iload_1,
 520 /* 0x1C */ &amp;&amp;opc_iload_2,&amp;&amp;opc_iload_3,&amp;&amp;opc_lload_0,&amp;&amp;opc_lload_1,
 521 
 522 /* 0x20 */ &amp;&amp;opc_lload_2,&amp;&amp;opc_lload_3,&amp;&amp;opc_fload_0,&amp;&amp;opc_fload_1,
 523 /* 0x24 */ &amp;&amp;opc_fload_2,&amp;&amp;opc_fload_3,&amp;&amp;opc_dload_0,&amp;&amp;opc_dload_1,
 524 /* 0x28 */ &amp;&amp;opc_dload_2,&amp;&amp;opc_dload_3,&amp;&amp;opc_aload_0,&amp;&amp;opc_aload_1,
 525 /* 0x2C */ &amp;&amp;opc_aload_2,&amp;&amp;opc_aload_3,&amp;&amp;opc_iaload, &amp;&amp;opc_laload,
 526 
 527 /* 0x30 */ &amp;&amp;opc_faload,  &amp;&amp;opc_daload,  &amp;&amp;opc_aaload,  &amp;&amp;opc_baload,
 528 /* 0x34 */ &amp;&amp;opc_caload,  &amp;&amp;opc_saload,  &amp;&amp;opc_istore,  &amp;&amp;opc_lstore,
 529 /* 0x38 */ &amp;&amp;opc_fstore,  &amp;&amp;opc_dstore,  &amp;&amp;opc_astore,  &amp;&amp;opc_istore_0,
 530 /* 0x3C */ &amp;&amp;opc_istore_1,&amp;&amp;opc_istore_2,&amp;&amp;opc_istore_3,&amp;&amp;opc_lstore_0,
 531 
 532 /* 0x40 */ &amp;&amp;opc_lstore_1,&amp;&amp;opc_lstore_2,&amp;&amp;opc_lstore_3,&amp;&amp;opc_fstore_0,
 533 /* 0x44 */ &amp;&amp;opc_fstore_1,&amp;&amp;opc_fstore_2,&amp;&amp;opc_fstore_3,&amp;&amp;opc_dstore_0,
 534 /* 0x48 */ &amp;&amp;opc_dstore_1,&amp;&amp;opc_dstore_2,&amp;&amp;opc_dstore_3,&amp;&amp;opc_astore_0,
 535 /* 0x4C */ &amp;&amp;opc_astore_1,&amp;&amp;opc_astore_2,&amp;&amp;opc_astore_3,&amp;&amp;opc_iastore,
 536 
 537 /* 0x50 */ &amp;&amp;opc_lastore,&amp;&amp;opc_fastore,&amp;&amp;opc_dastore,&amp;&amp;opc_aastore,
 538 /* 0x54 */ &amp;&amp;opc_bastore,&amp;&amp;opc_castore,&amp;&amp;opc_sastore,&amp;&amp;opc_pop,
 539 /* 0x58 */ &amp;&amp;opc_pop2,   &amp;&amp;opc_dup,    &amp;&amp;opc_dup_x1, &amp;&amp;opc_dup_x2,
 540 /* 0x5C */ &amp;&amp;opc_dup2,   &amp;&amp;opc_dup2_x1,&amp;&amp;opc_dup2_x2,&amp;&amp;opc_swap,
 541 
 542 /* 0x60 */ &amp;&amp;opc_iadd,&amp;&amp;opc_ladd,&amp;&amp;opc_fadd,&amp;&amp;opc_dadd,
 543 /* 0x64 */ &amp;&amp;opc_isub,&amp;&amp;opc_lsub,&amp;&amp;opc_fsub,&amp;&amp;opc_dsub,
 544 /* 0x68 */ &amp;&amp;opc_imul,&amp;&amp;opc_lmul,&amp;&amp;opc_fmul,&amp;&amp;opc_dmul,
 545 /* 0x6C */ &amp;&amp;opc_idiv,&amp;&amp;opc_ldiv,&amp;&amp;opc_fdiv,&amp;&amp;opc_ddiv,
 546 
 547 /* 0x70 */ &amp;&amp;opc_irem, &amp;&amp;opc_lrem, &amp;&amp;opc_frem,&amp;&amp;opc_drem,
 548 /* 0x74 */ &amp;&amp;opc_ineg, &amp;&amp;opc_lneg, &amp;&amp;opc_fneg,&amp;&amp;opc_dneg,
 549 /* 0x78 */ &amp;&amp;opc_ishl, &amp;&amp;opc_lshl, &amp;&amp;opc_ishr,&amp;&amp;opc_lshr,
 550 /* 0x7C */ &amp;&amp;opc_iushr,&amp;&amp;opc_lushr,&amp;&amp;opc_iand,&amp;&amp;opc_land,
 551 
 552 /* 0x80 */ &amp;&amp;opc_ior, &amp;&amp;opc_lor,&amp;&amp;opc_ixor,&amp;&amp;opc_lxor,
 553 /* 0x84 */ &amp;&amp;opc_iinc,&amp;&amp;opc_i2l,&amp;&amp;opc_i2f, &amp;&amp;opc_i2d,
 554 /* 0x88 */ &amp;&amp;opc_l2i, &amp;&amp;opc_l2f,&amp;&amp;opc_l2d, &amp;&amp;opc_f2i,
 555 /* 0x8C */ &amp;&amp;opc_f2l, &amp;&amp;opc_f2d,&amp;&amp;opc_d2i, &amp;&amp;opc_d2l,
 556 
 557 /* 0x90 */ &amp;&amp;opc_d2f,  &amp;&amp;opc_i2b,  &amp;&amp;opc_i2c,  &amp;&amp;opc_i2s,
 558 /* 0x94 */ &amp;&amp;opc_lcmp, &amp;&amp;opc_fcmpl,&amp;&amp;opc_fcmpg,&amp;&amp;opc_dcmpl,
 559 /* 0x98 */ &amp;&amp;opc_dcmpg,&amp;&amp;opc_ifeq, &amp;&amp;opc_ifne, &amp;&amp;opc_iflt,
 560 /* 0x9C */ &amp;&amp;opc_ifge, &amp;&amp;opc_ifgt, &amp;&amp;opc_ifle, &amp;&amp;opc_if_icmpeq,
 561 
 562 /* 0xA0 */ &amp;&amp;opc_if_icmpne,&amp;&amp;opc_if_icmplt,&amp;&amp;opc_if_icmpge,  &amp;&amp;opc_if_icmpgt,
 563 /* 0xA4 */ &amp;&amp;opc_if_icmple,&amp;&amp;opc_if_acmpeq,&amp;&amp;opc_if_acmpne,  &amp;&amp;opc_goto,
 564 /* 0xA8 */ &amp;&amp;opc_jsr,      &amp;&amp;opc_ret,      &amp;&amp;opc_tableswitch,&amp;&amp;opc_lookupswitch,
 565 /* 0xAC */ &amp;&amp;opc_ireturn,  &amp;&amp;opc_lreturn,  &amp;&amp;opc_freturn,    &amp;&amp;opc_dreturn,
 566 
 567 /* 0xB0 */ &amp;&amp;opc_areturn,     &amp;&amp;opc_return,         &amp;&amp;opc_getstatic,    &amp;&amp;opc_putstatic,
 568 /* 0xB4 */ &amp;&amp;opc_getfield,    &amp;&amp;opc_putfield,       &amp;&amp;opc_invokevirtual,&amp;&amp;opc_invokespecial,
 569 /* 0xB8 */ &amp;&amp;opc_invokestatic,&amp;&amp;opc_invokeinterface,&amp;&amp;opc_invokedynamic,&amp;&amp;opc_new,
 570 /* 0xBC */ &amp;&amp;opc_newarray,    &amp;&amp;opc_anewarray,      &amp;&amp;opc_arraylength,  &amp;&amp;opc_athrow,
 571 
 572 /* 0xC0 */ &amp;&amp;opc_checkcast,   &amp;&amp;opc_instanceof,     &amp;&amp;opc_monitorenter, &amp;&amp;opc_monitorexit,
 573 /* 0xC4 */ &amp;&amp;opc_wide,        &amp;&amp;opc_multianewarray, &amp;&amp;opc_ifnull,       &amp;&amp;opc_ifnonnull,
 574 /* 0xC8 */ &amp;&amp;opc_goto_w,      &amp;&amp;opc_jsr_w,          &amp;&amp;opc_breakpoint,   &amp;&amp;opc_default,
 575 /* 0xCC */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 576 
 577 /* 0xD0 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 578 /* 0xD4 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 579 /* 0xD8 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 580 /* 0xDC */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 581 
 582 /* 0xE0 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,         &amp;&amp;opc_default,
 583 /* 0xE4 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_fast_aldc,    &amp;&amp;opc_fast_aldc_w,
 584 /* 0xE8 */ &amp;&amp;opc_return_register_finalizer,
 585                               &amp;&amp;opc_invokehandle,   &amp;&amp;opc_default,      &amp;&amp;opc_default,
 586 /* 0xEC */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,         &amp;&amp;opc_default,
 587 
 588 /* 0xF0 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 589 /* 0xF4 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 590 /* 0xF8 */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default,
 591 /* 0xFC */ &amp;&amp;opc_default,     &amp;&amp;opc_default,        &amp;&amp;opc_default,      &amp;&amp;opc_default
 592   };
 593   uintptr_t *dispatch_table = (uintptr_t*)&amp;opclabels_data[0];
 594 #endif /* USELABELS */
 595 
 596 #ifdef ASSERT
 597   // this will trigger a VERIFY_OOP on entry
 598   if (istate-&gt;msg() != initialize &amp;&amp; ! METHOD-&gt;is_static()) {
 599     oop rcvr = LOCALS_OBJECT(0);
 600     VERIFY_OOP(rcvr);
 601   }
 602 #endif
 603 
 604   /* QQQ this should be a stack method so we don&#39;t know actual direction */
 605   guarantee(istate-&gt;msg() == initialize ||
 606          topOfStack &gt;= istate-&gt;stack_limit() &amp;&amp;
 607          topOfStack &lt; istate-&gt;stack_base(),
 608          &quot;Stack top out of range&quot;);
 609 
 610 #ifdef CC_INTERP_PROFILE
 611   // MethodData&#39;s last branch taken count.
 612   uint mdo_last_branch_taken_count = 0;
 613 #else
 614   const uint mdo_last_branch_taken_count = 0;
 615 #endif
 616 
 617   switch (istate-&gt;msg()) {
 618     case initialize: {
 619       if (initialized++) ShouldNotReachHere(); // Only one initialize call.
 620       _compiling = (UseCompiler || CountCompiledCalls);
 621 #ifdef VM_JVMTI
 622       _jvmti_interp_events = JvmtiExport::can_post_interpreter_events();
 623 #endif
 624       return;
 625     }
 626     break;
 627     case method_entry: {
 628       THREAD-&gt;set_do_not_unlock();
 629       // count invocations
 630       assert(initialized, &quot;Interpreter not initialized&quot;);
 631       if (_compiling) {
 632         MethodCounters* mcs;
 633         GET_METHOD_COUNTERS(mcs);
 634 #if COMPILER2_OR_JVMCI
 635         if (ProfileInterpreter) {
 636           METHOD-&gt;increment_interpreter_invocation_count(THREAD);
 637         }
 638 #endif
 639         mcs-&gt;invocation_counter()-&gt;increment();
 640         if (mcs-&gt;invocation_counter()-&gt;reached_InvocationLimit(mcs-&gt;backedge_counter())) {
 641           CALL_VM((void)InterpreterRuntime::frequency_counter_overflow(THREAD, NULL), handle_exception);
 642           // We no longer retry on a counter overflow.
 643         }
 644         // Get or create profile data. Check for pending (async) exceptions.
 645         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 646         SAFEPOINT;
 647       }
 648 
 649       if ((istate-&gt;_stack_base - istate-&gt;_stack_limit) != istate-&gt;method()-&gt;max_stack() + 1) {
 650         // initialize
 651         os::breakpoint();
 652       }
 653 
 654       // Lock method if synchronized.
 655       if (METHOD-&gt;is_synchronized()) {
 656         // oop rcvr = locals[0].j.r;
 657         oop rcvr;
 658         if (METHOD-&gt;is_static()) {
 659           rcvr = METHOD-&gt;constants()-&gt;pool_holder()-&gt;java_mirror();
 660         } else {
 661           rcvr = LOCALS_OBJECT(0);
 662           VERIFY_OOP(rcvr);
 663         }
 664         // The initial monitor is ours for the taking.
 665         // Monitor not filled in frame manager any longer as this caused race condition with biased locking.
 666         BasicObjectLock* mon = &amp;istate-&gt;monitor_base()[-1];
 667         mon-&gt;set_obj(rcvr);
 668         bool success = false;
 669         uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;
 670         markWord mark = rcvr-&gt;mark();
 671         intptr_t hash = (intptr_t) markWord::no_hash;
 672         // Implies UseBiasedLocking.
 673         if (mark.has_bias_pattern()) {
 674           uintptr_t thread_ident;
 675           uintptr_t anticipated_bias_locking_value;
 676           thread_ident = (uintptr_t)istate-&gt;thread();
 677           anticipated_bias_locking_value =
 678             ((rcvr-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;
 679             ~(markWord::age_mask_in_place);
 680 
 681           if (anticipated_bias_locking_value == 0) {
 682             // Already biased towards this thread, nothing to do.
 683             if (PrintBiasedLockingStatistics) {
 684               (* BiasedLocking::biased_lock_entry_count_addr())++;
 685             }
 686             success = true;
 687           } else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {
 688             // Try to revoke bias.
 689             markWord header = rcvr-&gt;klass()-&gt;prototype_header();
 690             if (hash != markWord::no_hash) {
 691               header = header.copy_set_hash(hash);
 692             }
 693             if (rcvr-&gt;cas_set_mark(header, mark) == mark) {
 694               if (PrintBiasedLockingStatistics)
 695                 (*BiasedLocking::revoked_lock_entry_count_addr())++;
 696             }
 697           } else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) != 0) {
 698             // Try to rebias.
 699             markWord new_header( (intptr_t) rcvr-&gt;klass()-&gt;prototype_header().value() | thread_ident);
 700             if (hash != markWord::no_hash) {
 701               new_header = new_header.copy_set_hash(hash);
 702             }
 703             if (rcvr-&gt;cas_set_mark(new_header, mark) == mark) {
 704               if (PrintBiasedLockingStatistics) {
 705                 (* BiasedLocking::rebiased_lock_entry_count_addr())++;
 706               }
 707             } else {
 708               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 709             }
 710             success = true;
 711           } else {
 712             // Try to bias towards thread in case object is anonymously biased.
 713             markWord header(mark.value() &amp;
 714                             (markWord::biased_lock_mask_in_place |
 715                              markWord::age_mask_in_place | epoch_mask_in_place));
 716             if (hash != markWord::no_hash) {
 717               header = header.copy_set_hash(hash);
 718             }
 719             markWord new_header(header.value() | thread_ident);
 720             // Debugging hint.
 721             DEBUG_ONLY(mon-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)
 722             if (rcvr-&gt;cas_set_mark(new_header, header) == header) {
 723               if (PrintBiasedLockingStatistics) {
 724                 (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
 725               }
 726             } else {
 727               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 728             }
 729             success = true;
 730           }
 731         }
 732 
 733         // Traditional lightweight locking.
 734         if (!success) {
 735           markWord displaced = rcvr-&gt;mark().set_unlocked();
 736           mon-&gt;lock()-&gt;set_displaced_header(displaced);
 737           bool call_vm = UseHeavyMonitors;
 738           if (call_vm || rcvr-&gt;cas_set_mark(markWord::from_pointer(mon), displaced) != displaced) {
 739             // Is it simple recursive case?
 740             if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {
 741               mon-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));
 742             } else {
 743               CALL_VM(InterpreterRuntime::monitorenter(THREAD, mon), handle_exception);
 744             }
 745           }
 746         }
 747       }
 748       THREAD-&gt;clr_do_not_unlock();
 749 
 750       // Notify jvmti
 751 #ifdef VM_JVMTI
 752       if (_jvmti_interp_events) {
 753         // Whenever JVMTI puts a thread in interp_only_mode, method
 754         // entry/exit events are sent for that thread to track stack depth.
 755         if (THREAD-&gt;is_interp_only_mode()) {
 756           CALL_VM(InterpreterRuntime::post_method_entry(THREAD),
 757                   handle_exception);
 758         }
 759       }
 760 #endif /* VM_JVMTI */
 761 
 762       goto run;
 763     }
 764 
 765     case popping_frame: {
 766       // returned from a java call to pop the frame, restart the call
 767       // clear the message so we don&#39;t confuse ourselves later
 768       assert(THREAD-&gt;pop_frame_in_process(), &quot;wrong frame pop state&quot;);
 769       istate-&gt;set_msg(no_request);
 770       if (_compiling) {
 771         // Set MDX back to the ProfileData of the invoke bytecode that will be
 772         // restarted.
 773         SET_MDX(NULL);
 774         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 775       }
 776       THREAD-&gt;clr_pop_frame_in_process();
 777       goto run;
 778     }
 779 
 780     case method_resume: {
 781       if ((istate-&gt;_stack_base - istate-&gt;_stack_limit) != istate-&gt;method()-&gt;max_stack() + 1) {
 782         // resume
 783         os::breakpoint();
 784       }
 785       // returned from a java call, continue executing.
 786       if (THREAD-&gt;pop_frame_pending() &amp;&amp; !THREAD-&gt;pop_frame_in_process()) {
 787         goto handle_Pop_Frame;
 788       }
 789       if (THREAD-&gt;jvmti_thread_state() &amp;&amp;
 790           THREAD-&gt;jvmti_thread_state()-&gt;is_earlyret_pending()) {
 791         goto handle_Early_Return;
 792       }
 793 
 794       if (THREAD-&gt;has_pending_exception()) goto handle_exception;
 795       // Update the pc by the saved amount of the invoke bytecode size
 796       UPDATE_PC(istate-&gt;bcp_advance());
 797 
 798       if (_compiling) {
 799         // Get or create profile data. Check for pending (async) exceptions.
 800         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 801       }
 802       goto run;
 803     }
 804 
 805     case deopt_resume2: {
 806       // Returned from an opcode that will reexecute. Deopt was
 807       // a result of a PopFrame request.
 808       //
 809 
 810       if (_compiling) {
 811         // Get or create profile data. Check for pending (async) exceptions.
 812         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 813       }
 814       goto run;
 815     }
 816 
 817     case deopt_resume: {
 818       // Returned from an opcode that has completed. The stack has
 819       // the result all we need to do is skip across the bytecode
 820       // and continue (assuming there is no exception pending)
 821       //
 822       // compute continuation length
 823       //
 824       // Note: it is possible to deopt at a return_register_finalizer opcode
 825       // because this requires entering the vm to do the registering. While the
 826       // opcode is complete we can&#39;t advance because there are no more opcodes
 827       // much like trying to deopt at a poll return. In that has we simply
 828       // get out of here
 829       //
 830       if ( Bytecodes::code_at(METHOD, pc) == Bytecodes::_return_register_finalizer) {
 831         // this will do the right thing even if an exception is pending.
 832         goto handle_return;
 833       }
 834       UPDATE_PC(Bytecodes::length_at(METHOD, pc));
 835       if (THREAD-&gt;has_pending_exception()) goto handle_exception;
 836 
 837       if (_compiling) {
 838         // Get or create profile data. Check for pending (async) exceptions.
 839         BI_PROFILE_GET_OR_CREATE_METHOD_DATA(handle_exception);
 840       }
 841       goto run;
 842     }
 843     case got_monitors: {
 844       // continue locking now that we have a monitor to use
 845       // we expect to find newly allocated monitor at the &quot;top&quot; of the monitor stack.
 846       oop lockee = STACK_OBJECT(-1);
 847       VERIFY_OOP(lockee);
 848       // derefing&#39;s lockee ought to provoke implicit null check
 849       // find a free monitor
 850       BasicObjectLock* entry = (BasicObjectLock*) istate-&gt;stack_base();
 851       assert(entry-&gt;obj() == NULL, &quot;Frame manager didn&#39;t allocate the monitor&quot;);
 852       entry-&gt;set_obj(lockee);
 853       bool success = false;
 854       uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;
 855 
 856       markWord mark = lockee-&gt;mark();
 857       intptr_t hash = (intptr_t) markWord::no_hash;
 858       // implies UseBiasedLocking
 859       if (mark.has_bias_pattern()) {
 860         uintptr_t thread_ident;
 861         uintptr_t anticipated_bias_locking_value;
 862         thread_ident = (uintptr_t)istate-&gt;thread();
 863         anticipated_bias_locking_value =
 864           ((lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;
 865           ~(markWord::age_mask_in_place);
 866 
 867         if  (anticipated_bias_locking_value == 0) {
 868           // already biased towards this thread, nothing to do
 869           if (PrintBiasedLockingStatistics) {
 870             (* BiasedLocking::biased_lock_entry_count_addr())++;
 871           }
 872           success = true;
 873         } else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {
 874           // try revoke bias
 875           markWord header = lockee-&gt;klass()-&gt;prototype_header();
 876           if (hash != markWord::no_hash) {
 877             header = header.copy_set_hash(hash);
 878           }
 879           if (lockee-&gt;cas_set_mark(header, mark) == mark) {
 880             if (PrintBiasedLockingStatistics) {
 881               (*BiasedLocking::revoked_lock_entry_count_addr())++;
 882             }
 883           }
 884         } else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) !=0) {
 885           // try rebias
 886           markWord new_header( (intptr_t) lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident);
 887           if (hash != markWord::no_hash) {
 888             new_header = new_header.copy_set_hash(hash);
 889           }
 890           if (lockee-&gt;cas_set_mark(new_header, mark) == mark) {
 891             if (PrintBiasedLockingStatistics) {
 892               (* BiasedLocking::rebiased_lock_entry_count_addr())++;
 893             }
 894           } else {
 895             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 896           }
 897           success = true;
 898         } else {
 899           // try to bias towards thread in case object is anonymously biased
 900           markWord header(mark.value() &amp; (markWord::biased_lock_mask_in_place |
 901                                           markWord::age_mask_in_place | epoch_mask_in_place));
 902           if (hash != markWord::no_hash) {
 903             header = header.copy_set_hash(hash);
 904           }
 905           markWord new_header(header.value() | thread_ident);
 906           // debugging hint
 907           DEBUG_ONLY(entry-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)
 908           if (lockee-&gt;cas_set_mark(new_header, header) == header) {
 909             if (PrintBiasedLockingStatistics) {
 910               (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
 911             }
 912           } else {
 913             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 914           }
 915           success = true;
 916         }
 917       }
 918 
 919       // traditional lightweight locking
 920       if (!success) {
 921         markWord displaced = lockee-&gt;mark().set_unlocked();
 922         entry-&gt;lock()-&gt;set_displaced_header(displaced);
 923         bool call_vm = UseHeavyMonitors;
 924         if (call_vm || lockee-&gt;cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {
 925           // Is it simple recursive case?
 926           if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {
 927             entry-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));
 928           } else {
 929             CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
 930           }
 931         }
 932       }
 933       UPDATE_PC_AND_TOS(1, -1);
 934       goto run;
 935     }
 936     default: {
 937       fatal(&quot;Unexpected message from frame manager&quot;);
 938     }
 939   }
 940 
 941 run:
 942 
 943   DO_UPDATE_INSTRUCTION_COUNT(*pc)
 944   DEBUGGER_SINGLE_STEP_NOTIFY();
 945 #ifdef PREFETCH_OPCCODE
 946   opcode = *pc;  /* prefetch first opcode */
 947 #endif
 948 
 949 #ifndef USELABELS
 950   while (1)
 951 #endif
 952   {
 953 #ifndef PREFETCH_OPCCODE
 954       opcode = *pc;
 955 #endif
 956       // Seems like this happens twice per opcode. At worst this is only
 957       // need at entry to the loop.
 958       // DEBUGGER_SINGLE_STEP_NOTIFY();
 959       /* Using this labels avoids double breakpoints when quickening and
 960        * when returing from transition frames.
 961        */
 962   opcode_switch:
 963       assert(istate == orig, &quot;Corrupted istate&quot;);
 964       /* QQQ Hmm this has knowledge of direction, ought to be a stack method */
 965       assert(topOfStack &gt;= istate-&gt;stack_limit(), &quot;Stack overrun&quot;);
 966       assert(topOfStack &lt; istate-&gt;stack_base(), &quot;Stack underrun&quot;);
 967 
 968 #ifdef USELABELS
 969       DISPATCH(opcode);
 970 #else
 971       switch (opcode)
 972 #endif
 973       {
 974       CASE(_nop):
 975           UPDATE_PC_AND_CONTINUE(1);
 976 
 977           /* Push miscellaneous constants onto the stack. */
 978 
 979       CASE(_aconst_null):
 980           SET_STACK_OBJECT(NULL, 0);
 981           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
 982 
 983 #undef  OPC_CONST_n
 984 #define OPC_CONST_n(opcode, const_type, value)                          \
 985       CASE(opcode):                                                     \
 986           SET_STACK_ ## const_type(value, 0);                           \
 987           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
 988 
 989           OPC_CONST_n(_iconst_m1,   INT,       -1);
 990           OPC_CONST_n(_iconst_0,    INT,        0);
 991           OPC_CONST_n(_iconst_1,    INT,        1);
 992           OPC_CONST_n(_iconst_2,    INT,        2);
 993           OPC_CONST_n(_iconst_3,    INT,        3);
 994           OPC_CONST_n(_iconst_4,    INT,        4);
 995           OPC_CONST_n(_iconst_5,    INT,        5);
 996           OPC_CONST_n(_fconst_0,    FLOAT,      0.0);
 997           OPC_CONST_n(_fconst_1,    FLOAT,      1.0);
 998           OPC_CONST_n(_fconst_2,    FLOAT,      2.0);
 999 
1000 #undef  OPC_CONST2_n
1001 #define OPC_CONST2_n(opcname, value, key, kind)                         \
1002       CASE(_##opcname):                                                 \
1003       {                                                                 \
1004           SET_STACK_ ## kind(VM##key##Const##value(), 1);               \
1005           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);                         \
1006       }
1007          OPC_CONST2_n(dconst_0, Zero, double, DOUBLE);
1008          OPC_CONST2_n(dconst_1, One,  double, DOUBLE);
1009          OPC_CONST2_n(lconst_0, Zero, long, LONG);
1010          OPC_CONST2_n(lconst_1, One,  long, LONG);
1011 
1012          /* Load constant from constant pool: */
1013 
1014           /* Push a 1-byte signed integer value onto the stack. */
1015       CASE(_bipush):
1016           SET_STACK_INT((jbyte)(pc[1]), 0);
1017           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 1);
1018 
1019           /* Push a 2-byte signed integer constant onto the stack. */
1020       CASE(_sipush):
1021           SET_STACK_INT((int16_t)Bytes::get_Java_u2(pc + 1), 0);
1022           UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
1023 
1024           /* load from local variable */
1025 
1026       CASE(_aload):
1027           VERIFY_OOP(LOCALS_OBJECT(pc[1]));
1028           SET_STACK_OBJECT(LOCALS_OBJECT(pc[1]), 0);
1029           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 1);
1030 
1031       CASE(_iload):
1032       CASE(_fload):
1033           SET_STACK_SLOT(LOCALS_SLOT(pc[1]), 0);
1034           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 1);
1035 
1036       CASE(_lload):
1037           SET_STACK_LONG_FROM_ADDR(LOCALS_LONG_AT(pc[1]), 1);
1038           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 2);
1039 
1040       CASE(_dload):
1041           SET_STACK_DOUBLE_FROM_ADDR(LOCALS_DOUBLE_AT(pc[1]), 1);
1042           UPDATE_PC_AND_TOS_AND_CONTINUE(2, 2);
1043 
1044 #undef  OPC_LOAD_n
1045 #define OPC_LOAD_n(num)                                                 \
1046       CASE(_aload_##num):                                               \
1047           VERIFY_OOP(LOCALS_OBJECT(num));                               \
1048           SET_STACK_OBJECT(LOCALS_OBJECT(num), 0);                      \
1049           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);                         \
1050                                                                         \
1051       CASE(_iload_##num):                                               \
1052       CASE(_fload_##num):                                               \
1053           SET_STACK_SLOT(LOCALS_SLOT(num), 0);                          \
1054           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);                         \
1055                                                                         \
1056       CASE(_lload_##num):                                               \
1057           SET_STACK_LONG_FROM_ADDR(LOCALS_LONG_AT(num), 1);             \
1058           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);                         \
1059       CASE(_dload_##num):                                               \
1060           SET_STACK_DOUBLE_FROM_ADDR(LOCALS_DOUBLE_AT(num), 1);         \
1061           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1062 
1063           OPC_LOAD_n(0);
1064           OPC_LOAD_n(1);
1065           OPC_LOAD_n(2);
1066           OPC_LOAD_n(3);
1067 
1068           /* store to a local variable */
1069 
1070       CASE(_astore):
1071           astore(topOfStack, -1, locals, pc[1]);
1072           UPDATE_PC_AND_TOS_AND_CONTINUE(2, -1);
1073 
1074       CASE(_istore):
1075       CASE(_fstore):
1076           SET_LOCALS_SLOT(STACK_SLOT(-1), pc[1]);
1077           UPDATE_PC_AND_TOS_AND_CONTINUE(2, -1);
1078 
1079       CASE(_lstore):
1080           SET_LOCALS_LONG(STACK_LONG(-1), pc[1]);
1081           UPDATE_PC_AND_TOS_AND_CONTINUE(2, -2);
1082 
1083       CASE(_dstore):
1084           SET_LOCALS_DOUBLE(STACK_DOUBLE(-1), pc[1]);
1085           UPDATE_PC_AND_TOS_AND_CONTINUE(2, -2);
1086 
1087       CASE(_wide): {
1088           uint16_t reg = Bytes::get_Java_u2(pc + 2);
1089 
1090           opcode = pc[1];
1091 
1092           // Wide and it&#39;s sub-bytecode are counted as separate instructions. If we
1093           // don&#39;t account for this here, the bytecode trace skips the next bytecode.
1094           DO_UPDATE_INSTRUCTION_COUNT(opcode);
1095 
1096           switch(opcode) {
1097               case Bytecodes::_aload:
1098                   VERIFY_OOP(LOCALS_OBJECT(reg));
1099                   SET_STACK_OBJECT(LOCALS_OBJECT(reg), 0);
1100                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, 1);
1101 
1102               case Bytecodes::_iload:
1103               case Bytecodes::_fload:
1104                   SET_STACK_SLOT(LOCALS_SLOT(reg), 0);
1105                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, 1);
1106 
1107               case Bytecodes::_lload:
1108                   SET_STACK_LONG_FROM_ADDR(LOCALS_LONG_AT(reg), 1);
1109                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, 2);
1110 
1111               case Bytecodes::_dload:
1112                   SET_STACK_DOUBLE_FROM_ADDR(LOCALS_LONG_AT(reg), 1);
1113                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, 2);
1114 
1115               case Bytecodes::_astore:
1116                   astore(topOfStack, -1, locals, reg);
1117                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, -1);
1118 
1119               case Bytecodes::_istore:
1120               case Bytecodes::_fstore:
1121                   SET_LOCALS_SLOT(STACK_SLOT(-1), reg);
1122                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, -1);
1123 
1124               case Bytecodes::_lstore:
1125                   SET_LOCALS_LONG(STACK_LONG(-1), reg);
1126                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, -2);
1127 
1128               case Bytecodes::_dstore:
1129                   SET_LOCALS_DOUBLE(STACK_DOUBLE(-1), reg);
1130                   UPDATE_PC_AND_TOS_AND_CONTINUE(4, -2);
1131 
1132               case Bytecodes::_iinc: {
1133                   int16_t offset = (int16_t)Bytes::get_Java_u2(pc+4);
1134                   // Be nice to see what this generates.... QQQ
1135                   SET_LOCALS_INT(LOCALS_INT(reg) + offset, reg);
1136                   UPDATE_PC_AND_CONTINUE(6);
1137               }
1138               case Bytecodes::_ret:
1139                   // Profile ret.
1140                   BI_PROFILE_UPDATE_RET(/*bci=*/((int)(intptr_t)(LOCALS_ADDR(reg))));
1141                   // Now, update the pc.
1142                   pc = istate-&gt;method()-&gt;code_base() + (intptr_t)(LOCALS_ADDR(reg));
1143                   UPDATE_PC_AND_CONTINUE(0);
1144               default:
1145                   VM_JAVA_ERROR(vmSymbols::java_lang_InternalError(), &quot;undefined opcode&quot;, note_no_trap);
1146           }
1147       }
1148 
1149 
1150 #undef  OPC_STORE_n
1151 #define OPC_STORE_n(num)                                                \
1152       CASE(_astore_##num):                                              \
1153           astore(topOfStack, -1, locals, num);                          \
1154           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                        \
1155       CASE(_istore_##num):                                              \
1156       CASE(_fstore_##num):                                              \
1157           SET_LOCALS_SLOT(STACK_SLOT(-1), num);                         \
1158           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1159 
1160           OPC_STORE_n(0);
1161           OPC_STORE_n(1);
1162           OPC_STORE_n(2);
1163           OPC_STORE_n(3);
1164 
1165 #undef  OPC_DSTORE_n
1166 #define OPC_DSTORE_n(num)                                               \
1167       CASE(_dstore_##num):                                              \
1168           SET_LOCALS_DOUBLE(STACK_DOUBLE(-1), num);                     \
1169           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);                        \
1170       CASE(_lstore_##num):                                              \
1171           SET_LOCALS_LONG(STACK_LONG(-1), num);                         \
1172           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);
1173 
1174           OPC_DSTORE_n(0);
1175           OPC_DSTORE_n(1);
1176           OPC_DSTORE_n(2);
1177           OPC_DSTORE_n(3);
1178 
1179           /* stack pop, dup, and insert opcodes */
1180 
1181 
1182       CASE(_pop):                /* Discard the top item on the stack */
1183           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1184 
1185 
1186       CASE(_pop2):               /* Discard the top 2 items on the stack */
1187           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);
1188 
1189 
1190       CASE(_dup):               /* Duplicate the top item on the stack */
1191           dup(topOfStack);
1192           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1193 
1194       CASE(_dup2):              /* Duplicate the top 2 items on the stack */
1195           dup2(topOfStack);
1196           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1197 
1198       CASE(_dup_x1):    /* insert top word two down */
1199           dup_x1(topOfStack);
1200           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1201 
1202       CASE(_dup_x2):    /* insert top word three down  */
1203           dup_x2(topOfStack);
1204           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1205 
1206       CASE(_dup2_x1):   /* insert top 2 slots three down */
1207           dup2_x1(topOfStack);
1208           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1209 
1210       CASE(_dup2_x2):   /* insert top 2 slots four down */
1211           dup2_x2(topOfStack);
1212           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1213 
1214       CASE(_swap): {        /* swap top two elements on the stack */
1215           swap(topOfStack);
1216           UPDATE_PC_AND_CONTINUE(1);
1217       }
1218 
1219           /* Perform various binary integer operations */
1220 
1221 #undef  OPC_INT_BINARY
1222 #define OPC_INT_BINARY(opcname, opname, test)                           \
1223       CASE(_i##opcname):                                                \
1224           if (test &amp;&amp; (STACK_INT(-1) == 0)) {                           \
1225               VM_JAVA_ERROR(vmSymbols::java_lang_ArithmeticException(), \
1226                             &quot;/ by zero&quot;, note_div0Check_trap);          \
1227           }                                                             \
1228           SET_STACK_INT(VMint##opname(STACK_INT(-2),                    \
1229                                       STACK_INT(-1)),                   \
1230                                       -2);                              \
1231           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                        \
1232       CASE(_l##opcname):                                                \
1233       {                                                                 \
1234           if (test) {                                                   \
1235             jlong l1 = STACK_LONG(-1);                                  \
1236             if (VMlongEqz(l1)) {                                        \
1237               VM_JAVA_ERROR(vmSymbols::java_lang_ArithmeticException(), \
1238                             &quot;/ by long zero&quot;, note_div0Check_trap);     \
1239             }                                                           \
1240           }                                                             \
1241           /* First long at (-1,-2) next long at (-3,-4) */              \
1242           SET_STACK_LONG(VMlong##opname(STACK_LONG(-3),                 \
1243                                         STACK_LONG(-1)),                \
1244                                         -3);                            \
1245           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);                        \
1246       }
1247 
1248       OPC_INT_BINARY(add, Add, 0);
1249       OPC_INT_BINARY(sub, Sub, 0);
1250       OPC_INT_BINARY(mul, Mul, 0);
1251       OPC_INT_BINARY(and, And, 0);
1252       OPC_INT_BINARY(or,  Or,  0);
1253       OPC_INT_BINARY(xor, Xor, 0);
1254       OPC_INT_BINARY(div, Div, 1);
1255       OPC_INT_BINARY(rem, Rem, 1);
1256 
1257 
1258       /* Perform various binary floating number operations */
1259       /* On some machine/platforms/compilers div zero check can be implicit */
1260 
1261 #undef  OPC_FLOAT_BINARY
1262 #define OPC_FLOAT_BINARY(opcname, opname)                                  \
1263       CASE(_d##opcname): {                                                 \
1264           SET_STACK_DOUBLE(VMdouble##opname(STACK_DOUBLE(-3),              \
1265                                             STACK_DOUBLE(-1)),             \
1266                                             -3);                           \
1267           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -2);                           \
1268       }                                                                    \
1269       CASE(_f##opcname):                                                   \
1270           SET_STACK_FLOAT(VMfloat##opname(STACK_FLOAT(-2),                 \
1271                                           STACK_FLOAT(-1)),                \
1272                                           -2);                             \
1273           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1274 
1275 
1276      OPC_FLOAT_BINARY(add, Add);
1277      OPC_FLOAT_BINARY(sub, Sub);
1278      OPC_FLOAT_BINARY(mul, Mul);
1279      OPC_FLOAT_BINARY(div, Div);
1280      OPC_FLOAT_BINARY(rem, Rem);
1281 
1282       /* Shift operations
1283        * Shift left int and long: ishl, lshl
1284        * Logical shift right int and long w/zero extension: iushr, lushr
1285        * Arithmetic shift right int and long w/sign extension: ishr, lshr
1286        */
1287 
1288 #undef  OPC_SHIFT_BINARY
1289 #define OPC_SHIFT_BINARY(opcname, opname)                               \
1290       CASE(_i##opcname):                                                \
1291          SET_STACK_INT(VMint##opname(STACK_INT(-2),                     \
1292                                      STACK_INT(-1)),                    \
1293                                      -2);                               \
1294          UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                         \
1295       CASE(_l##opcname):                                                \
1296       {                                                                 \
1297          SET_STACK_LONG(VMlong##opname(STACK_LONG(-2),                  \
1298                                        STACK_INT(-1)),                  \
1299                                        -2);                             \
1300          UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                         \
1301       }
1302 
1303       OPC_SHIFT_BINARY(shl, Shl);
1304       OPC_SHIFT_BINARY(shr, Shr);
1305       OPC_SHIFT_BINARY(ushr, Ushr);
1306 
1307      /* Increment local variable by constant */
1308       CASE(_iinc):
1309       {
1310           // locals[pc[1]].j.i += (jbyte)(pc[2]);
1311           SET_LOCALS_INT(LOCALS_INT(pc[1]) + (jbyte)(pc[2]), pc[1]);
1312           UPDATE_PC_AND_CONTINUE(3);
1313       }
1314 
1315      /* negate the value on the top of the stack */
1316 
1317       CASE(_ineg):
1318          SET_STACK_INT(VMintNeg(STACK_INT(-1)), -1);
1319          UPDATE_PC_AND_CONTINUE(1);
1320 
1321       CASE(_fneg):
1322          SET_STACK_FLOAT(VMfloatNeg(STACK_FLOAT(-1)), -1);
1323          UPDATE_PC_AND_CONTINUE(1);
1324 
1325       CASE(_lneg):
1326       {
1327          SET_STACK_LONG(VMlongNeg(STACK_LONG(-1)), -1);
1328          UPDATE_PC_AND_CONTINUE(1);
1329       }
1330 
1331       CASE(_dneg):
1332       {
1333          SET_STACK_DOUBLE(VMdoubleNeg(STACK_DOUBLE(-1)), -1);
1334          UPDATE_PC_AND_CONTINUE(1);
1335       }
1336 
1337       /* Conversion operations */
1338 
1339       CASE(_i2f):       /* convert top of stack int to float */
1340          SET_STACK_FLOAT(VMint2Float(STACK_INT(-1)), -1);
1341          UPDATE_PC_AND_CONTINUE(1);
1342 
1343       CASE(_i2l):       /* convert top of stack int to long */
1344       {
1345           // this is ugly QQQ
1346           jlong r = VMint2Long(STACK_INT(-1));
1347           MORE_STACK(-1); // Pop
1348           SET_STACK_LONG(r, 1);
1349 
1350           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1351       }
1352 
1353       CASE(_i2d):       /* convert top of stack int to double */
1354       {
1355           // this is ugly QQQ (why cast to jlong?? )
1356           jdouble r = (jlong)STACK_INT(-1);
1357           MORE_STACK(-1); // Pop
1358           SET_STACK_DOUBLE(r, 1);
1359 
1360           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1361       }
1362 
1363       CASE(_l2i):       /* convert top of stack long to int */
1364       {
1365           jint r = VMlong2Int(STACK_LONG(-1));
1366           MORE_STACK(-2); // Pop
1367           SET_STACK_INT(r, 0);
1368           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1369       }
1370 
1371       CASE(_l2f):   /* convert top of stack long to float */
1372       {
1373           jlong r = STACK_LONG(-1);
1374           MORE_STACK(-2); // Pop
1375           SET_STACK_FLOAT(VMlong2Float(r), 0);
1376           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1377       }
1378 
1379       CASE(_l2d):       /* convert top of stack long to double */
1380       {
1381           jlong r = STACK_LONG(-1);
1382           MORE_STACK(-2); // Pop
1383           SET_STACK_DOUBLE(VMlong2Double(r), 1);
1384           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1385       }
1386 
1387       CASE(_f2i):  /* Convert top of stack float to int */
1388           SET_STACK_INT(SharedRuntime::f2i(STACK_FLOAT(-1)), -1);
1389           UPDATE_PC_AND_CONTINUE(1);
1390 
1391       CASE(_f2l):  /* convert top of stack float to long */
1392       {
1393           jlong r = SharedRuntime::f2l(STACK_FLOAT(-1));
1394           MORE_STACK(-1); // POP
1395           SET_STACK_LONG(r, 1);
1396           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1397       }
1398 
1399       CASE(_f2d):  /* convert top of stack float to double */
1400       {
1401           jfloat f;
1402           jdouble r;
1403           f = STACK_FLOAT(-1);
1404           r = (jdouble) f;
1405           MORE_STACK(-1); // POP
1406           SET_STACK_DOUBLE(r, 1);
1407           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1408       }
1409 
1410       CASE(_d2i): /* convert top of stack double to int */
1411       {
1412           jint r1 = SharedRuntime::d2i(STACK_DOUBLE(-1));
1413           MORE_STACK(-2);
1414           SET_STACK_INT(r1, 0);
1415           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1416       }
1417 
1418       CASE(_d2f): /* convert top of stack double to float */
1419       {
1420           jfloat r1 = VMdouble2Float(STACK_DOUBLE(-1));
1421           MORE_STACK(-2);
1422           SET_STACK_FLOAT(r1, 0);
1423           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1424       }
1425 
1426       CASE(_d2l): /* convert top of stack double to long */
1427       {
1428           jlong r1 = SharedRuntime::d2l(STACK_DOUBLE(-1));
1429           MORE_STACK(-2);
1430           SET_STACK_LONG(r1, 1);
1431           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 2);
1432       }
1433 
1434       CASE(_i2b):
1435           SET_STACK_INT(VMint2Byte(STACK_INT(-1)), -1);
1436           UPDATE_PC_AND_CONTINUE(1);
1437 
1438       CASE(_i2c):
1439           SET_STACK_INT(VMint2Char(STACK_INT(-1)), -1);
1440           UPDATE_PC_AND_CONTINUE(1);
1441 
1442       CASE(_i2s):
1443           SET_STACK_INT(VMint2Short(STACK_INT(-1)), -1);
1444           UPDATE_PC_AND_CONTINUE(1);
1445 
1446       /* comparison operators */
1447 
1448 
1449 #define COMPARISON_OP(name, comparison)                                      \
1450       CASE(_if_icmp##name): {                                                \
1451           const bool cmp = (STACK_INT(-2) comparison STACK_INT(-1));         \
1452           int skip = cmp                                                     \
1453                       ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;             \
1454           address branch_pc = pc;                                            \
1455           /* Profile branch. */                                              \
1456           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1457           UPDATE_PC_AND_TOS(skip, -2);                                       \
1458           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1459           CONTINUE;                                                          \
1460       }                                                                      \
1461       CASE(_if##name): {                                                     \
1462           const bool cmp = (STACK_INT(-1) comparison 0);                     \
1463           int skip = cmp                                                     \
1464                       ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;             \
1465           address branch_pc = pc;                                            \
1466           /* Profile branch. */                                              \
1467           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1468           UPDATE_PC_AND_TOS(skip, -1);                                       \
1469           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1470           CONTINUE;                                                          \
1471       }
1472 
1473 #define COMPARISON_OP2(name, comparison)                                     \
1474       COMPARISON_OP(name, comparison)                                        \
1475       CASE(_if_acmp##name): {                                                \
1476           const bool cmp = (STACK_OBJECT(-2) comparison STACK_OBJECT(-1));   \
1477           int skip = cmp                                                     \
1478                        ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;            \
1479           address branch_pc = pc;                                            \
1480           /* Profile branch. */                                              \
1481           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1482           UPDATE_PC_AND_TOS(skip, -2);                                       \
1483           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1484           CONTINUE;                                                          \
1485       }
1486 
1487 #define NULL_COMPARISON_NOT_OP(name)                                         \
1488       CASE(_if##name): {                                                     \
1489           const bool cmp = (!(STACK_OBJECT(-1) == NULL));                    \
1490           int skip = cmp                                                     \
1491                       ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;             \
1492           address branch_pc = pc;                                            \
1493           /* Profile branch. */                                              \
1494           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1495           UPDATE_PC_AND_TOS(skip, -1);                                       \
1496           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1497           CONTINUE;                                                          \
1498       }
1499 
1500 #define NULL_COMPARISON_OP(name)                                             \
1501       CASE(_if##name): {                                                     \
1502           const bool cmp = ((STACK_OBJECT(-1) == NULL));                     \
1503           int skip = cmp                                                     \
1504                       ? (int16_t)Bytes::get_Java_u2(pc + 1) : 3;             \
1505           address branch_pc = pc;                                            \
1506           /* Profile branch. */                                              \
1507           BI_PROFILE_UPDATE_BRANCH(/*is_taken=*/cmp);                        \
1508           UPDATE_PC_AND_TOS(skip, -1);                                       \
1509           DO_BACKEDGE_CHECKS(skip, branch_pc);                               \
1510           CONTINUE;                                                          \
1511       }
1512       COMPARISON_OP(lt, &lt;);
1513       COMPARISON_OP(gt, &gt;);
1514       COMPARISON_OP(le, &lt;=);
1515       COMPARISON_OP(ge, &gt;=);
1516       COMPARISON_OP2(eq, ==);  /* include ref comparison */
1517       COMPARISON_OP2(ne, !=);  /* include ref comparison */
1518       NULL_COMPARISON_OP(null);
1519       NULL_COMPARISON_NOT_OP(nonnull);
1520 
1521       /* Goto pc at specified offset in switch table. */
1522 
1523       CASE(_tableswitch): {
1524           jint* lpc  = (jint*)VMalignWordUp(pc+1);
1525           int32_t  key  = STACK_INT(-1);
1526           int32_t  low  = Bytes::get_Java_u4((address)&amp;lpc[1]);
1527           int32_t  high = Bytes::get_Java_u4((address)&amp;lpc[2]);
1528           int32_t  skip;
1529           key -= low;
1530           if (((uint32_t) key &gt; (uint32_t)(high - low))) {
1531             key = -1;
1532             skip = Bytes::get_Java_u4((address)&amp;lpc[0]);
1533           } else {
1534             skip = Bytes::get_Java_u4((address)&amp;lpc[key + 3]);
1535           }
1536           // Profile switch.
1537           BI_PROFILE_UPDATE_SWITCH(/*switch_index=*/key);
1538           // Does this really need a full backedge check (osr)?
1539           address branch_pc = pc;
1540           UPDATE_PC_AND_TOS(skip, -1);
1541           DO_BACKEDGE_CHECKS(skip, branch_pc);
1542           CONTINUE;
1543       }
1544 
1545       /* Goto pc whose table entry matches specified key. */
1546 
1547       CASE(_lookupswitch): {
1548           jint* lpc  = (jint*)VMalignWordUp(pc+1);
1549           int32_t  key  = STACK_INT(-1);
1550           int32_t  skip = Bytes::get_Java_u4((address) lpc); /* default amount */
1551           // Remember index.
1552           int      index = -1;
1553           int      newindex = 0;
1554           int32_t  npairs = Bytes::get_Java_u4((address) &amp;lpc[1]);
1555           while (--npairs &gt;= 0) {
1556             lpc += 2;
1557             if (key == (int32_t)Bytes::get_Java_u4((address)lpc)) {
1558               skip = Bytes::get_Java_u4((address)&amp;lpc[1]);
1559               index = newindex;
1560               break;
1561             }
1562             newindex += 1;
1563           }
1564           // Profile switch.
1565           BI_PROFILE_UPDATE_SWITCH(/*switch_index=*/index);
1566           address branch_pc = pc;
1567           UPDATE_PC_AND_TOS(skip, -1);
1568           DO_BACKEDGE_CHECKS(skip, branch_pc);
1569           CONTINUE;
1570       }
1571 
1572       CASE(_fcmpl):
1573       CASE(_fcmpg):
1574       {
1575           SET_STACK_INT(VMfloatCompare(STACK_FLOAT(-2),
1576                                         STACK_FLOAT(-1),
1577                                         (opcode == Bytecodes::_fcmpl ? -1 : 1)),
1578                         -2);
1579           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1580       }
1581 
1582       CASE(_dcmpl):
1583       CASE(_dcmpg):
1584       {
1585           int r = VMdoubleCompare(STACK_DOUBLE(-3),
1586                                   STACK_DOUBLE(-1),
1587                                   (opcode == Bytecodes::_dcmpl ? -1 : 1));
1588           MORE_STACK(-4); // Pop
1589           SET_STACK_INT(r, 0);
1590           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1591       }
1592 
1593       CASE(_lcmp):
1594       {
1595           int r = VMlongCompare(STACK_LONG(-3), STACK_LONG(-1));
1596           MORE_STACK(-4);
1597           SET_STACK_INT(r, 0);
1598           UPDATE_PC_AND_TOS_AND_CONTINUE(1, 1);
1599       }
1600 
1601 
1602       /* Return from a method */
1603 
1604       CASE(_areturn):
1605       CASE(_ireturn):
1606       CASE(_freturn):
1607       {
1608           // Allow a safepoint before returning to frame manager.
1609           SAFEPOINT;
1610 
1611           goto handle_return;
1612       }
1613 
1614       CASE(_lreturn):
1615       CASE(_dreturn):
1616       {
1617           // Allow a safepoint before returning to frame manager.
1618           SAFEPOINT;
1619           goto handle_return;
1620       }
1621 
1622       CASE(_return_register_finalizer): {
1623 
1624           oop rcvr = LOCALS_OBJECT(0);
1625           VERIFY_OOP(rcvr);
1626           if (rcvr-&gt;klass()-&gt;has_finalizer()) {
1627             CALL_VM(InterpreterRuntime::register_finalizer(THREAD, rcvr), handle_exception);
1628           }
1629           goto handle_return;
1630       }
1631       CASE(_return): {
1632 
1633           // Allow a safepoint before returning to frame manager.
1634           SAFEPOINT;
1635           goto handle_return;
1636       }
1637 
1638       /* Array access byte-codes */
1639 
1640       /* Every array access byte-code starts out like this */
1641 //        arrayOopDesc* arrObj = (arrayOopDesc*)STACK_OBJECT(arrayOff);
1642 #define ARRAY_INTRO(arrayOff)                                                  \
1643       arrayOop arrObj = (arrayOop)STACK_OBJECT(arrayOff);                      \
1644       jint     index  = STACK_INT(arrayOff + 1);                               \
1645       char message[jintAsStringSize];                                          \
1646       CHECK_NULL(arrObj);                                                      \
1647       if ((uint32_t)index &gt;= (uint32_t)arrObj-&gt;length()) {                     \
1648           sprintf(message, &quot;%d&quot;, index);                                       \
1649           VM_JAVA_ERROR(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), \
1650                         message, note_rangeCheck_trap);                        \
1651       }
1652 
1653       /* 32-bit loads. These handle conversion from &lt; 32-bit types */
1654 #define ARRAY_LOADTO32(T, T2, format, stackRes, extra)                                \
1655       {                                                                               \
1656           ARRAY_INTRO(-2);                                                            \
1657           (void)extra;                                                                \
1658           SET_ ## stackRes(*(T2 *)(((address) arrObj-&gt;base(T)) + index * sizeof(T2)), \
1659                            -2);                                                       \
1660           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);                                      \
1661       }
1662 
1663       /* 64-bit loads */
1664 #define ARRAY_LOADTO64(T,T2, stackRes, extra)                                              \
1665       {                                                                                    \
1666           ARRAY_INTRO(-2);                                                                 \
1667           SET_ ## stackRes(*(T2 *)(((address) arrObj-&gt;base(T)) + index * sizeof(T2)), -1); \
1668           (void)extra;                                                                     \
1669           UPDATE_PC_AND_CONTINUE(1);                                                       \
1670       }
1671 
1672       CASE(_iaload):
1673           ARRAY_LOADTO32(T_INT, jint,   &quot;%d&quot;,   STACK_INT, 0);
1674       CASE(_faload):
1675           ARRAY_LOADTO32(T_FLOAT, jfloat, &quot;%f&quot;,   STACK_FLOAT, 0);
1676       CASE(_aaload): {
1677           ARRAY_INTRO(-2);
1678           SET_STACK_OBJECT(((objArrayOop) arrObj)-&gt;obj_at(index), -2);
1679           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1680       }
1681       CASE(_baload):
1682           ARRAY_LOADTO32(T_BYTE, jbyte,  &quot;%d&quot;,   STACK_INT, 0);
1683       CASE(_caload):
1684           ARRAY_LOADTO32(T_CHAR,  jchar, &quot;%d&quot;,   STACK_INT, 0);
1685       CASE(_saload):
1686           ARRAY_LOADTO32(T_SHORT, jshort, &quot;%d&quot;,   STACK_INT, 0);
1687       CASE(_laload):
1688           ARRAY_LOADTO64(T_LONG, jlong, STACK_LONG, 0);
1689       CASE(_daload):
1690           ARRAY_LOADTO64(T_DOUBLE, jdouble, STACK_DOUBLE, 0);
1691 
1692       /* 32-bit stores. These handle conversion to &lt; 32-bit types */
1693 #define ARRAY_STOREFROM32(T, T2, format, stackSrc, extra)                            \
1694       {                                                                              \
1695           ARRAY_INTRO(-3);                                                           \
1696           (void)extra;                                                               \
1697           *(T2 *)(((address) arrObj-&gt;base(T)) + index * sizeof(T2)) = stackSrc( -1); \
1698           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -3);                                     \
1699       }
1700 
1701       /* 64-bit stores */
1702 #define ARRAY_STOREFROM64(T, T2, stackSrc, extra)                                    \
1703       {                                                                              \
1704           ARRAY_INTRO(-4);                                                           \
1705           (void)extra;                                                               \
1706           *(T2 *)(((address) arrObj-&gt;base(T)) + index * sizeof(T2)) = stackSrc( -1); \
1707           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -4);                                     \
1708       }
1709 
1710       CASE(_iastore):
1711           ARRAY_STOREFROM32(T_INT, jint,   &quot;%d&quot;,   STACK_INT, 0);
1712       CASE(_fastore):
1713           ARRAY_STOREFROM32(T_FLOAT, jfloat, &quot;%f&quot;,   STACK_FLOAT, 0);
1714       /*
1715        * This one looks different because of the assignability check
1716        */
1717       CASE(_aastore): {
1718           oop rhsObject = STACK_OBJECT(-1);
1719           VERIFY_OOP(rhsObject);
1720           ARRAY_INTRO( -3);
1721           // arrObj, index are set
1722           if (rhsObject != NULL) {
1723             /* Check assignability of rhsObject into arrObj */
1724             Klass* rhsKlass = rhsObject-&gt;klass(); // EBX (subclass)
1725             Klass* elemKlass = ObjArrayKlass::cast(arrObj-&gt;klass())-&gt;element_klass(); // superklass EAX
1726             //
1727             // Check for compatibilty. This check must not GC!!
1728             // Seems way more expensive now that we must dispatch
1729             //
1730             if (rhsKlass != elemKlass &amp;&amp; !rhsKlass-&gt;is_subtype_of(elemKlass)) { // ebx-&gt;is...
1731               // Decrement counter if subtype check failed.
1732               BI_PROFILE_SUBTYPECHECK_FAILED(rhsKlass);
1733               VM_JAVA_ERROR(vmSymbols::java_lang_ArrayStoreException(), &quot;&quot;, note_arrayCheck_trap);
1734             }
1735             // Profile checkcast with null_seen and receiver.
1736             BI_PROFILE_UPDATE_CHECKCAST(/*null_seen=*/false, rhsKlass);
1737           } else {
1738             // Profile checkcast with null_seen and receiver.
1739             BI_PROFILE_UPDATE_CHECKCAST(/*null_seen=*/true, NULL);
1740           }
1741           ((objArrayOop) arrObj)-&gt;obj_at_put(index, rhsObject);
1742           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -3);
1743       }
1744       CASE(_bastore): {
1745           ARRAY_INTRO(-3);
1746           int item = STACK_INT(-1);
1747           // if it is a T_BOOLEAN array, mask the stored value to 0/1
1748           if (arrObj-&gt;klass() == Universe::boolArrayKlassObj()) {
1749             item &amp;= 1;
1750           } else {
1751             assert(arrObj-&gt;klass() == Universe::byteArrayKlassObj(),
1752                    &quot;should be byte array otherwise&quot;);
1753           }
1754           ((typeArrayOop)arrObj)-&gt;byte_at_put(index, item);
1755           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -3);
1756       }
1757       CASE(_castore):
1758           ARRAY_STOREFROM32(T_CHAR, jchar,  &quot;%d&quot;,   STACK_INT, 0);
1759       CASE(_sastore):
1760           ARRAY_STOREFROM32(T_SHORT, jshort, &quot;%d&quot;,   STACK_INT, 0);
1761       CASE(_lastore):
1762           ARRAY_STOREFROM64(T_LONG, jlong, STACK_LONG, 0);
1763       CASE(_dastore):
1764           ARRAY_STOREFROM64(T_DOUBLE, jdouble, STACK_DOUBLE, 0);
1765 
1766       CASE(_arraylength):
1767       {
1768           arrayOop ary = (arrayOop) STACK_OBJECT(-1);
1769           CHECK_NULL(ary);
1770           SET_STACK_INT(ary-&gt;length(), -1);
1771           UPDATE_PC_AND_CONTINUE(1);
1772       }
1773 
1774       /* monitorenter and monitorexit for locking/unlocking an object */
1775 
1776       CASE(_monitorenter): {
1777         oop lockee = STACK_OBJECT(-1);
1778         // derefing&#39;s lockee ought to provoke implicit null check
1779         CHECK_NULL(lockee);
1780         // find a free monitor or one already allocated for this object
1781         // if we find a matching object then we need a new monitor
1782         // since this is recursive enter
1783         BasicObjectLock* limit = istate-&gt;monitor_base();
1784         BasicObjectLock* most_recent = (BasicObjectLock*) istate-&gt;stack_base();
1785         BasicObjectLock* entry = NULL;
1786         while (most_recent != limit ) {
1787           if (most_recent-&gt;obj() == NULL) entry = most_recent;
1788           else if (most_recent-&gt;obj() == lockee) break;
1789           most_recent++;
1790         }
1791         if (entry != NULL) {
1792           entry-&gt;set_obj(lockee);
1793           int success = false;
1794           uintptr_t epoch_mask_in_place = markWord::epoch_mask_in_place;
1795 
1796           markWord mark = lockee-&gt;mark();
1797           intptr_t hash = (intptr_t) markWord::no_hash;
1798           // implies UseBiasedLocking
1799           if (mark.has_bias_pattern()) {
1800             uintptr_t thread_ident;
1801             uintptr_t anticipated_bias_locking_value;
1802             thread_ident = (uintptr_t)istate-&gt;thread();
1803             anticipated_bias_locking_value =
1804               ((lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident) ^ mark.value()) &amp;
1805               ~(markWord::age_mask_in_place);
1806 
1807             if  (anticipated_bias_locking_value == 0) {
1808               // already biased towards this thread, nothing to do
1809               if (PrintBiasedLockingStatistics) {
1810                 (* BiasedLocking::biased_lock_entry_count_addr())++;
1811               }
1812               success = true;
1813             }
1814             else if ((anticipated_bias_locking_value &amp; markWord::biased_lock_mask_in_place) != 0) {
1815               // try revoke bias
1816               markWord header = lockee-&gt;klass()-&gt;prototype_header();
1817               if (hash != markWord::no_hash) {
1818                 header = header.copy_set_hash(hash);
1819               }
1820               if (lockee-&gt;cas_set_mark(header, mark) == mark) {
1821                 if (PrintBiasedLockingStatistics)
1822                   (*BiasedLocking::revoked_lock_entry_count_addr())++;
1823               }
1824             }
1825             else if ((anticipated_bias_locking_value &amp; epoch_mask_in_place) !=0) {
1826               // try rebias
1827               markWord new_header( (intptr_t) lockee-&gt;klass()-&gt;prototype_header().value() | thread_ident);
1828               if (hash != markWord::no_hash) {
1829                 new_header = new_header.copy_set_hash(hash);
1830               }
1831               if (lockee-&gt;cas_set_mark(new_header, mark) == mark) {
1832                 if (PrintBiasedLockingStatistics)
1833                   (* BiasedLocking::rebiased_lock_entry_count_addr())++;
1834               }
1835               else {
1836                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1837               }
1838               success = true;
1839             }
1840             else {
1841               // try to bias towards thread in case object is anonymously biased
1842               markWord header(mark.value() &amp; (markWord::biased_lock_mask_in_place |
1843                                               markWord::age_mask_in_place |
1844                                               epoch_mask_in_place));
1845               if (hash != markWord::no_hash) {
1846                 header = header.copy_set_hash(hash);
1847               }
1848               markWord new_header(header.value() | thread_ident);
1849               // debugging hint
1850               DEBUG_ONLY(entry-&gt;lock()-&gt;set_displaced_header(markWord((uintptr_t) 0xdeaddead));)
1851               if (lockee-&gt;cas_set_mark(new_header, header) == header) {
1852                 if (PrintBiasedLockingStatistics)
1853                   (* BiasedLocking::anonymously_biased_lock_entry_count_addr())++;
1854               }
1855               else {
1856                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1857               }
1858               success = true;
1859             }
1860           }
1861 
1862           // traditional lightweight locking
1863           if (!success) {
1864             markWord displaced = lockee-&gt;mark().set_unlocked();
1865             entry-&gt;lock()-&gt;set_displaced_header(displaced);
1866             bool call_vm = UseHeavyMonitors;
1867             if (call_vm || lockee-&gt;cas_set_mark(markWord::from_pointer(entry), displaced) != displaced) {
1868               // Is it simple recursive case?
1869               if (!call_vm &amp;&amp; THREAD-&gt;is_lock_owned((address) displaced.clear_lock_bits().to_pointer())) {
1870                 entry-&gt;lock()-&gt;set_displaced_header(markWord::from_pointer(NULL));
1871               } else {
1872                 CALL_VM(InterpreterRuntime::monitorenter(THREAD, entry), handle_exception);
1873               }
1874             }
1875           }
1876           UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1877         } else {
1878           istate-&gt;set_msg(more_monitors);
1879           UPDATE_PC_AND_RETURN(0); // Re-execute
1880         }
1881       }
1882 
1883       CASE(_monitorexit): {
1884         oop lockee = STACK_OBJECT(-1);
1885         CHECK_NULL(lockee);
1886         // derefing&#39;s lockee ought to provoke implicit null check
1887         // find our monitor slot
1888         BasicObjectLock* limit = istate-&gt;monitor_base();
1889         BasicObjectLock* most_recent = (BasicObjectLock*) istate-&gt;stack_base();
1890         while (most_recent != limit ) {
1891           if ((most_recent)-&gt;obj() == lockee) {
1892             BasicLock* lock = most_recent-&gt;lock();
1893             markWord header = lock-&gt;displaced_header();
1894             most_recent-&gt;set_obj(NULL);
1895             if (!lockee-&gt;mark().has_bias_pattern()) {
1896               bool call_vm = UseHeavyMonitors;
1897               // If it isn&#39;t recursive we either must swap old header or call the runtime
1898               if (header.to_pointer() != NULL || call_vm) {
1899                 markWord old_header = markWord::encode(lock);
1900                 if (call_vm || lockee-&gt;cas_set_mark(header, old_header) != old_header) {
1901                   // restore object for the slow case
1902                   most_recent-&gt;set_obj(lockee);
1903                   CALL_VM(InterpreterRuntime::monitorexit(THREAD, most_recent), handle_exception);
1904                 }
1905               }
1906             }
1907             UPDATE_PC_AND_TOS_AND_CONTINUE(1, -1);
1908           }
1909           most_recent++;
1910         }
1911         // Need to throw illegal monitor state exception
1912         CALL_VM(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD), handle_exception);
1913         ShouldNotReachHere();
1914       }
1915 
1916       /* All of the non-quick opcodes. */
1917 
1918       /* -Set clobbersCpIndex true if the quickened opcode clobbers the
1919        *  constant pool index in the instruction.
1920        */
1921       CASE(_getfield):
1922       CASE(_getstatic):
1923         {
1924           u2 index;
1925           ConstantPoolCacheEntry* cache;
1926           index = Bytes::get_native_u2(pc+1);
1927 
1928           // QQQ Need to make this as inlined as possible. Probably need to
1929           // split all the bytecode cases out so c++ compiler has a chance
1930           // for constant prop to fold everything possible away.
1931 
1932           cache = cp-&gt;entry_at(index);
1933           if (!cache-&gt;is_resolved((Bytecodes::Code)opcode)) {
1934             CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
1935                     handle_exception);
1936             cache = cp-&gt;entry_at(index);
1937           }
1938 
1939 #ifdef VM_JVMTI
1940           if (_jvmti_interp_events) {
1941             int *count_addr;
1942             oop obj;
1943             // Check to see if a field modification watch has been set
1944             // before we take the time to call into the VM.
1945             count_addr = (int *)JvmtiExport::get_field_access_count_addr();
1946             if ( *count_addr &gt; 0 ) {
1947               if ((Bytecodes::Code)opcode == Bytecodes::_getstatic) {
1948                 obj = (oop)NULL;
1949               } else {
1950                 obj = (oop) STACK_OBJECT(-1);
1951                 VERIFY_OOP(obj);
1952               }
1953               CALL_VM(InterpreterRuntime::post_field_access(THREAD,
1954                                           obj,
1955                                           cache),
1956                                           handle_exception);
1957             }
1958           }
1959 #endif /* VM_JVMTI */
1960 
1961           oop obj;
1962           if ((Bytecodes::Code)opcode == Bytecodes::_getstatic) {
1963             Klass* k = cache-&gt;f1_as_klass();
1964             obj = k-&gt;java_mirror();
1965             MORE_STACK(1);  // Assume single slot push
1966           } else {
1967             obj = (oop) STACK_OBJECT(-1);
1968             CHECK_NULL(obj);
1969           }
1970 
1971           //
1972           // Now store the result on the stack
1973           //
1974           TosState tos_type = cache-&gt;flag_state();
1975           int field_offset = cache-&gt;f2_as_index();
1976           if (cache-&gt;is_volatile()) {
1977             if (support_IRIW_for_not_multiple_copy_atomic_cpu) {
1978               OrderAccess::fence();
1979             }
1980             if (tos_type == atos) {
1981               VERIFY_OOP(obj-&gt;obj_field_acquire(field_offset));
1982               SET_STACK_OBJECT(obj-&gt;obj_field_acquire(field_offset), -1);
1983             } else if (tos_type == itos) {
1984               SET_STACK_INT(obj-&gt;int_field_acquire(field_offset), -1);
1985             } else if (tos_type == ltos) {
1986               SET_STACK_LONG(obj-&gt;long_field_acquire(field_offset), 0);
1987               MORE_STACK(1);
1988             } else if (tos_type == btos || tos_type == ztos) {
1989               SET_STACK_INT(obj-&gt;byte_field_acquire(field_offset), -1);
1990             } else if (tos_type == ctos) {
1991               SET_STACK_INT(obj-&gt;char_field_acquire(field_offset), -1);
1992             } else if (tos_type == stos) {
1993               SET_STACK_INT(obj-&gt;short_field_acquire(field_offset), -1);
1994             } else if (tos_type == ftos) {
1995               SET_STACK_FLOAT(obj-&gt;float_field_acquire(field_offset), -1);
1996             } else {
1997               SET_STACK_DOUBLE(obj-&gt;double_field_acquire(field_offset), 0);
1998               MORE_STACK(1);
1999             }
2000           } else {
2001             if (tos_type == atos) {
2002               VERIFY_OOP(obj-&gt;obj_field(field_offset));
2003               SET_STACK_OBJECT(obj-&gt;obj_field(field_offset), -1);
2004             } else if (tos_type == itos) {
2005               SET_STACK_INT(obj-&gt;int_field(field_offset), -1);
2006             } else if (tos_type == ltos) {
2007               SET_STACK_LONG(obj-&gt;long_field(field_offset), 0);
2008               MORE_STACK(1);
2009             } else if (tos_type == btos || tos_type == ztos) {
2010               SET_STACK_INT(obj-&gt;byte_field(field_offset), -1);
2011             } else if (tos_type == ctos) {
2012               SET_STACK_INT(obj-&gt;char_field(field_offset), -1);
2013             } else if (tos_type == stos) {
2014               SET_STACK_INT(obj-&gt;short_field(field_offset), -1);
2015             } else if (tos_type == ftos) {
2016               SET_STACK_FLOAT(obj-&gt;float_field(field_offset), -1);
2017             } else {
2018               SET_STACK_DOUBLE(obj-&gt;double_field(field_offset), 0);
2019               MORE_STACK(1);
2020             }
2021           }
2022 
2023           UPDATE_PC_AND_CONTINUE(3);
2024          }
2025 
2026       CASE(_putfield):
2027       CASE(_putstatic):
2028         {
2029           u2 index = Bytes::get_native_u2(pc+1);
2030           ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2031           if (!cache-&gt;is_resolved((Bytecodes::Code)opcode)) {
2032             CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2033                     handle_exception);
2034             cache = cp-&gt;entry_at(index);
2035           }
2036 
2037 #ifdef VM_JVMTI
2038           if (_jvmti_interp_events) {
2039             int *count_addr;
2040             oop obj;
2041             // Check to see if a field modification watch has been set
2042             // before we take the time to call into the VM.
2043             count_addr = (int *)JvmtiExport::get_field_modification_count_addr();
2044             if ( *count_addr &gt; 0 ) {
2045               if ((Bytecodes::Code)opcode == Bytecodes::_putstatic) {
2046                 obj = (oop)NULL;
2047               }
2048               else {
2049                 if (cache-&gt;is_long() || cache-&gt;is_double()) {
2050                   obj = (oop) STACK_OBJECT(-3);
2051                 } else {
2052                   obj = (oop) STACK_OBJECT(-2);
2053                 }
2054                 VERIFY_OOP(obj);
2055               }
2056 
2057               CALL_VM(InterpreterRuntime::post_field_modification(THREAD,
2058                                           obj,
2059                                           cache,
2060                                           (jvalue *)STACK_SLOT(-1)),
2061                                           handle_exception);
2062             }
2063           }
2064 #endif /* VM_JVMTI */
2065 
2066           // QQQ Need to make this as inlined as possible. Probably need to split all the bytecode cases
2067           // out so c++ compiler has a chance for constant prop to fold everything possible away.
2068 
2069           oop obj;
2070           int count;
2071           TosState tos_type = cache-&gt;flag_state();
2072 
2073           count = -1;
2074           if (tos_type == ltos || tos_type == dtos) {
2075             --count;
2076           }
2077           if ((Bytecodes::Code)opcode == Bytecodes::_putstatic) {
2078             Klass* k = cache-&gt;f1_as_klass();
2079             obj = k-&gt;java_mirror();
2080           } else {
2081             --count;
2082             obj = (oop) STACK_OBJECT(count);
2083             CHECK_NULL(obj);
2084           }
2085 
2086           //
2087           // Now store the result
2088           //
2089           int field_offset = cache-&gt;f2_as_index();
2090           if (cache-&gt;is_volatile()) {
2091             if (tos_type == itos) {
2092               obj-&gt;release_int_field_put(field_offset, STACK_INT(-1));
2093             } else if (tos_type == atos) {
2094               VERIFY_OOP(STACK_OBJECT(-1));
2095               obj-&gt;release_obj_field_put(field_offset, STACK_OBJECT(-1));
2096             } else if (tos_type == btos) {
2097               obj-&gt;release_byte_field_put(field_offset, STACK_INT(-1));
2098             } else if (tos_type == ztos) {
2099               int bool_field = STACK_INT(-1);  // only store LSB
2100               obj-&gt;release_byte_field_put(field_offset, (bool_field &amp; 1));
2101             } else if (tos_type == ltos) {
2102               obj-&gt;release_long_field_put(field_offset, STACK_LONG(-1));
2103             } else if (tos_type == ctos) {
2104               obj-&gt;release_char_field_put(field_offset, STACK_INT(-1));
2105             } else if (tos_type == stos) {
2106               obj-&gt;release_short_field_put(field_offset, STACK_INT(-1));
2107             } else if (tos_type == ftos) {
2108               obj-&gt;release_float_field_put(field_offset, STACK_FLOAT(-1));
2109             } else {
2110               obj-&gt;release_double_field_put(field_offset, STACK_DOUBLE(-1));
2111             }
2112             OrderAccess::storeload();
2113           } else {
2114             if (tos_type == itos) {
2115               obj-&gt;int_field_put(field_offset, STACK_INT(-1));
2116             } else if (tos_type == atos) {
2117               VERIFY_OOP(STACK_OBJECT(-1));
2118               obj-&gt;obj_field_put(field_offset, STACK_OBJECT(-1));
2119             } else if (tos_type == btos) {
2120               obj-&gt;byte_field_put(field_offset, STACK_INT(-1));
2121             } else if (tos_type == ztos) {
2122               int bool_field = STACK_INT(-1);  // only store LSB
2123               obj-&gt;byte_field_put(field_offset, (bool_field &amp; 1));
2124             } else if (tos_type == ltos) {
2125               obj-&gt;long_field_put(field_offset, STACK_LONG(-1));
2126             } else if (tos_type == ctos) {
2127               obj-&gt;char_field_put(field_offset, STACK_INT(-1));
2128             } else if (tos_type == stos) {
2129               obj-&gt;short_field_put(field_offset, STACK_INT(-1));
2130             } else if (tos_type == ftos) {
2131               obj-&gt;float_field_put(field_offset, STACK_FLOAT(-1));
2132             } else {
2133               obj-&gt;double_field_put(field_offset, STACK_DOUBLE(-1));
2134             }
2135           }
2136 
2137           UPDATE_PC_AND_TOS_AND_CONTINUE(3, count);
2138         }
2139 
2140       CASE(_new): {
2141         u2 index = Bytes::get_Java_u2(pc+1);
2142         ConstantPool* constants = istate-&gt;method()-&gt;constants();
2143         if (!constants-&gt;tag_at(index).is_unresolved_klass()) {
2144           // Make sure klass is initialized and doesn&#39;t have a finalizer
2145           Klass* entry = constants-&gt;resolved_klass_at(index);
2146           InstanceKlass* ik = InstanceKlass::cast(entry);
2147           if (ik-&gt;is_initialized() &amp;&amp; ik-&gt;can_be_fastpath_allocated() ) {
2148             size_t obj_size = ik-&gt;size_helper();
2149             oop result = NULL;
2150             // If the TLAB isn&#39;t pre-zeroed then we&#39;ll have to do it
2151             bool need_zero = !ZeroTLAB;
2152             if (UseTLAB) {
2153               result = (oop) THREAD-&gt;tlab().allocate(obj_size);
2154             }
2155             // Disable non-TLAB-based fast-path, because profiling requires that all
2156             // allocations go through InterpreterRuntime::_new() if THREAD-&gt;tlab().allocate
2157             // returns NULL.
2158 #ifndef CC_INTERP_PROFILE
2159             if (result == NULL) {
2160               need_zero = true;
2161               // Try allocate in shared eden
2162             retry:
2163               HeapWord* compare_to = *Universe::heap()-&gt;top_addr();
2164               HeapWord* new_top = compare_to + obj_size;
2165               if (new_top &lt;= *Universe::heap()-&gt;end_addr()) {
2166                 if (Atomic::cmpxchg(Universe::heap()-&gt;top_addr(), compare_to, new_top) != compare_to) {
2167                   goto retry;
2168                 }
2169                 result = (oop) compare_to;
2170               }
2171             }
2172 #endif
2173             if (result != NULL) {
2174               // Initialize object (if nonzero size and need) and then the header
2175               if (need_zero ) {
2176                 HeapWord* to_zero = cast_from_oop&lt;HeapWord*&gt;(result) + sizeof(oopDesc) / oopSize;
2177                 obj_size -= sizeof(oopDesc) / oopSize;
2178                 if (obj_size &gt; 0 ) {
2179                   memset(to_zero, 0, obj_size * HeapWordSize);
2180                 }
2181               }
2182               if (UseBiasedLocking) {
2183                 result-&gt;set_mark(ik-&gt;prototype_header());
2184               } else {
2185                 result-&gt;set_mark(markWord::prototype());
2186               }
2187               result-&gt;set_klass_gap(0);
2188               result-&gt;set_klass(ik);
2189               // Must prevent reordering of stores for object initialization
2190               // with stores that publish the new object.
2191               OrderAccess::storestore();
2192               SET_STACK_OBJECT(result, 0);
2193               UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
2194             }
2195           }
2196         }
2197         // Slow case allocation
2198         CALL_VM(InterpreterRuntime::_new(THREAD, METHOD-&gt;constants(), index),
2199                 handle_exception);
2200         // Must prevent reordering of stores for object initialization
2201         // with stores that publish the new object.
2202         OrderAccess::storestore();
2203         SET_STACK_OBJECT(THREAD-&gt;vm_result(), 0);
2204         THREAD-&gt;set_vm_result(NULL);
2205         UPDATE_PC_AND_TOS_AND_CONTINUE(3, 1);
2206       }
2207       CASE(_anewarray): {
2208         u2 index = Bytes::get_Java_u2(pc+1);
2209         jint size = STACK_INT(-1);
2210         CALL_VM(InterpreterRuntime::anewarray(THREAD, METHOD-&gt;constants(), index, size),
2211                 handle_exception);
2212         // Must prevent reordering of stores for object initialization
2213         // with stores that publish the new object.
2214         OrderAccess::storestore();
2215         SET_STACK_OBJECT(THREAD-&gt;vm_result(), -1);
2216         THREAD-&gt;set_vm_result(NULL);
2217         UPDATE_PC_AND_CONTINUE(3);
2218       }
2219       CASE(_multianewarray): {
2220         jint dims = *(pc+3);
2221         jint size = STACK_INT(-1);
2222         // stack grows down, dimensions are up!
2223         jint *dimarray =
2224                    (jint*)&amp;topOfStack[dims * Interpreter::stackElementWords+
2225                                       Interpreter::stackElementWords-1];
2226         //adjust pointer to start of stack element
2227         CALL_VM(InterpreterRuntime::multianewarray(THREAD, dimarray),
2228                 handle_exception);
2229         // Must prevent reordering of stores for object initialization
2230         // with stores that publish the new object.
2231         OrderAccess::storestore();
2232         SET_STACK_OBJECT(THREAD-&gt;vm_result(), -dims);
2233         THREAD-&gt;set_vm_result(NULL);
2234         UPDATE_PC_AND_TOS_AND_CONTINUE(4, -(dims-1));
2235       }
2236       CASE(_checkcast):
2237           if (STACK_OBJECT(-1) != NULL) {
2238             VERIFY_OOP(STACK_OBJECT(-1));
2239             u2 index = Bytes::get_Java_u2(pc+1);
2240             // Constant pool may have actual klass or unresolved klass. If it is
2241             // unresolved we must resolve it.
2242             if (METHOD-&gt;constants()-&gt;tag_at(index).is_unresolved_klass()) {
2243               CALL_VM(InterpreterRuntime::quicken_io_cc(THREAD), handle_exception);
2244             }
2245             Klass* klassOf = (Klass*) METHOD-&gt;constants()-&gt;resolved_klass_at(index);
2246             Klass* objKlass = STACK_OBJECT(-1)-&gt;klass(); // ebx
2247             //
2248             // Check for compatibilty. This check must not GC!!
2249             // Seems way more expensive now that we must dispatch.
2250             //
2251             if (objKlass != klassOf &amp;&amp; !objKlass-&gt;is_subtype_of(klassOf)) {
2252               // Decrement counter at checkcast.
2253               BI_PROFILE_SUBTYPECHECK_FAILED(objKlass);
2254               ResourceMark rm(THREAD);
2255               char* message = SharedRuntime::generate_class_cast_message(
2256                 objKlass, klassOf);
2257               VM_JAVA_ERROR(vmSymbols::java_lang_ClassCastException(), message, note_classCheck_trap);
2258             }
2259             // Profile checkcast with null_seen and receiver.
2260             BI_PROFILE_UPDATE_CHECKCAST(/*null_seen=*/false, objKlass);
2261           } else {
2262             // Profile checkcast with null_seen and receiver.
2263             BI_PROFILE_UPDATE_CHECKCAST(/*null_seen=*/true, NULL);
2264           }
2265           UPDATE_PC_AND_CONTINUE(3);
2266 
2267       CASE(_instanceof):
2268           if (STACK_OBJECT(-1) == NULL) {
2269             SET_STACK_INT(0, -1);
2270             // Profile instanceof with null_seen and receiver.
2271             BI_PROFILE_UPDATE_INSTANCEOF(/*null_seen=*/true, NULL);
2272           } else {
2273             VERIFY_OOP(STACK_OBJECT(-1));
2274             u2 index = Bytes::get_Java_u2(pc+1);
2275             // Constant pool may have actual klass or unresolved klass. If it is
2276             // unresolved we must resolve it.
2277             if (METHOD-&gt;constants()-&gt;tag_at(index).is_unresolved_klass()) {
2278               CALL_VM(InterpreterRuntime::quicken_io_cc(THREAD), handle_exception);
2279             }
2280             Klass* klassOf = (Klass*) METHOD-&gt;constants()-&gt;resolved_klass_at(index);
2281             Klass* objKlass = STACK_OBJECT(-1)-&gt;klass();
2282             //
2283             // Check for compatibilty. This check must not GC!!
2284             // Seems way more expensive now that we must dispatch.
2285             //
2286             if ( objKlass == klassOf || objKlass-&gt;is_subtype_of(klassOf)) {
2287               SET_STACK_INT(1, -1);
2288             } else {
2289               SET_STACK_INT(0, -1);
2290               // Decrement counter at checkcast.
2291               BI_PROFILE_SUBTYPECHECK_FAILED(objKlass);
2292             }
2293             // Profile instanceof with null_seen and receiver.
2294             BI_PROFILE_UPDATE_INSTANCEOF(/*null_seen=*/false, objKlass);
2295           }
2296           UPDATE_PC_AND_CONTINUE(3);
2297 
2298       CASE(_ldc_w):
2299       CASE(_ldc):
2300         {
2301           u2 index;
2302           bool wide = false;
2303           int incr = 2; // frequent case
2304           if (opcode == Bytecodes::_ldc) {
2305             index = pc[1];
2306           } else {
2307             index = Bytes::get_Java_u2(pc+1);
2308             incr = 3;
2309             wide = true;
2310           }
2311 
2312           ConstantPool* constants = METHOD-&gt;constants();
2313           switch (constants-&gt;tag_at(index).value()) {
2314           case JVM_CONSTANT_Integer:
2315             SET_STACK_INT(constants-&gt;int_at(index), 0);
2316             break;
2317 
2318           case JVM_CONSTANT_Float:
2319             SET_STACK_FLOAT(constants-&gt;float_at(index), 0);
2320             break;
2321 
2322           case JVM_CONSTANT_String:
2323             {
2324               oop result = constants-&gt;resolved_references()-&gt;obj_at(index);
2325               if (result == NULL) {
2326                 CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode), handle_exception);
2327                 SET_STACK_OBJECT(THREAD-&gt;vm_result(), 0);
2328                 THREAD-&gt;set_vm_result(NULL);
2329               } else {
2330                 VERIFY_OOP(result);
2331                 SET_STACK_OBJECT(result, 0);
2332               }
2333             break;
2334             }
2335 
2336           case JVM_CONSTANT_Class:
2337             VERIFY_OOP(constants-&gt;resolved_klass_at(index)-&gt;java_mirror());
2338             SET_STACK_OBJECT(constants-&gt;resolved_klass_at(index)-&gt;java_mirror(), 0);
2339             break;
2340 
2341           case JVM_CONSTANT_UnresolvedClass:
2342           case JVM_CONSTANT_UnresolvedClassInError:
2343             CALL_VM(InterpreterRuntime::ldc(THREAD, wide), handle_exception);
2344             SET_STACK_OBJECT(THREAD-&gt;vm_result(), 0);
2345             THREAD-&gt;set_vm_result(NULL);
2346             break;
2347 
2348           case JVM_CONSTANT_Dynamic:
2349             {
<a name="2" id="anc2"></a><span class="line-modified">2350               oop result = constants-&gt;resolved_references()-&gt;obj_at(index);</span>
<span class="line-modified">2351               if (result == NULL) {</span>
<span class="line-removed">2352                 CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode), handle_exception);</span>
<span class="line-removed">2353                 result = THREAD-&gt;vm_result();</span>
<span class="line-removed">2354               }</span>
2355               VERIFY_OOP(result);
2356 
2357               jvalue value;
2358               BasicType type = java_lang_boxing_object::get_value(result, &amp;value);
2359               switch (type) {
2360               case T_FLOAT:   SET_STACK_FLOAT(value.f, 0); break;
2361               case T_INT:     SET_STACK_INT(value.i, 0); break;
2362               case T_SHORT:   SET_STACK_INT(value.s, 0); break;
2363               case T_BYTE:    SET_STACK_INT(value.b, 0); break;
2364               case T_CHAR:    SET_STACK_INT(value.c, 0); break;
2365               case T_BOOLEAN: SET_STACK_INT(value.z, 0); break;
2366               default:  ShouldNotReachHere();
2367               }
2368 
2369               break;
2370             }
2371 
2372           default:  ShouldNotReachHere();
2373           }
2374           UPDATE_PC_AND_TOS_AND_CONTINUE(incr, 1);
2375         }
2376 
2377       CASE(_ldc2_w):
2378         {
2379           u2 index = Bytes::get_Java_u2(pc+1);
2380 
2381           ConstantPool* constants = METHOD-&gt;constants();
2382           switch (constants-&gt;tag_at(index).value()) {
2383 
2384           case JVM_CONSTANT_Long:
2385              SET_STACK_LONG(constants-&gt;long_at(index), 1);
2386             break;
2387 
2388           case JVM_CONSTANT_Double:
2389              SET_STACK_DOUBLE(constants-&gt;double_at(index), 1);
2390             break;
2391 
2392           case JVM_CONSTANT_Dynamic:
2393             {
<a name="3" id="anc3"></a><span class="line-modified">2394               oop result = constants-&gt;resolved_references()-&gt;obj_at(index);</span>
<span class="line-modified">2395               if (result == NULL) {</span>
<span class="line-removed">2396                 CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode), handle_exception);</span>
<span class="line-removed">2397                 result = THREAD-&gt;vm_result();</span>
<span class="line-removed">2398               }</span>
2399               VERIFY_OOP(result);
2400 
2401               jvalue value;
2402               BasicType type = java_lang_boxing_object::get_value(result, &amp;value);
2403               switch (type) {
2404               case T_DOUBLE: SET_STACK_DOUBLE(value.d, 1); break;
2405               case T_LONG:   SET_STACK_LONG(value.j, 1); break;
2406               default:  ShouldNotReachHere();
2407               }
2408 
2409               break;
2410             }
2411 
2412           default:  ShouldNotReachHere();
2413           }
2414           UPDATE_PC_AND_TOS_AND_CONTINUE(3, 2);
2415         }
2416 
2417       CASE(_fast_aldc_w):
2418       CASE(_fast_aldc): {
2419         u2 index;
2420         int incr;
2421         if (opcode == Bytecodes::_fast_aldc) {
2422           index = pc[1];
2423           incr = 2;
2424         } else {
2425           index = Bytes::get_native_u2(pc+1);
2426           incr = 3;
2427         }
2428 
2429         // We are resolved if the resolved_references array contains a non-null object (CallSite, etc.)
2430         // This kind of CP cache entry does not need to match the flags byte, because
2431         // there is a 1-1 relation between bytecode type and CP entry type.
2432         ConstantPool* constants = METHOD-&gt;constants();
2433         oop result = constants-&gt;resolved_references()-&gt;obj_at(index);
2434         if (result == NULL) {
2435           CALL_VM(InterpreterRuntime::resolve_ldc(THREAD, (Bytecodes::Code) opcode),
2436                   handle_exception);
2437           result = THREAD-&gt;vm_result();
2438         }
2439         if (result == Universe::the_null_sentinel())
2440           result = NULL;
2441 
2442         VERIFY_OOP(result);
2443         SET_STACK_OBJECT(result, 0);
2444         UPDATE_PC_AND_TOS_AND_CONTINUE(incr, 1);
2445       }
2446 
2447       CASE(_invokedynamic): {
2448 
2449         u4 index = Bytes::get_native_u4(pc+1);
2450         ConstantPoolCacheEntry* cache = cp-&gt;constant_pool()-&gt;invokedynamic_cp_cache_entry_at(index);
2451 
2452         // We are resolved if the resolved_references array contains a non-null object (CallSite, etc.)
2453         // This kind of CP cache entry does not need to match the flags byte, because
2454         // there is a 1-1 relation between bytecode type and CP entry type.
2455         if (! cache-&gt;is_resolved((Bytecodes::Code) opcode)) {
2456           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2457                   handle_exception);
2458           cache = cp-&gt;constant_pool()-&gt;invokedynamic_cp_cache_entry_at(index);
2459         }
2460 
2461         Method* method = cache-&gt;f1_as_method();
2462         if (VerifyOops) method-&gt;verify();
2463 
2464         if (cache-&gt;has_appendix()) {
2465           constantPoolHandle cp(THREAD, METHOD-&gt;constants());
2466           SET_STACK_OBJECT(cache-&gt;appendix_if_resolved(cp), 0);
2467           MORE_STACK(1);
2468         }
2469 
2470         istate-&gt;set_msg(call_method);
2471         istate-&gt;set_callee(method);
2472         istate-&gt;set_callee_entry_point(method-&gt;from_interpreted_entry());
2473         istate-&gt;set_bcp_advance(5);
2474 
2475         // Invokedynamic has got a call counter, just like an invokestatic -&gt; increment!
2476         BI_PROFILE_UPDATE_CALL();
2477 
2478         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2479       }
2480 
2481       CASE(_invokehandle): {
2482 
2483         u2 index = Bytes::get_native_u2(pc+1);
2484         ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2485 
2486         if (! cache-&gt;is_resolved((Bytecodes::Code) opcode)) {
2487           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2488                   handle_exception);
2489           cache = cp-&gt;entry_at(index);
2490         }
2491 
2492         Method* method = cache-&gt;f1_as_method();
2493         if (VerifyOops) method-&gt;verify();
2494 
2495         if (cache-&gt;has_appendix()) {
2496           constantPoolHandle cp(THREAD, METHOD-&gt;constants());
2497           SET_STACK_OBJECT(cache-&gt;appendix_if_resolved(cp), 0);
2498           MORE_STACK(1);
2499         }
2500 
2501         istate-&gt;set_msg(call_method);
2502         istate-&gt;set_callee(method);
2503         istate-&gt;set_callee_entry_point(method-&gt;from_interpreted_entry());
2504         istate-&gt;set_bcp_advance(3);
2505 
2506         // Invokehandle has got a call counter, just like a final call -&gt; increment!
2507         BI_PROFILE_UPDATE_FINALCALL();
2508 
2509         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2510       }
2511 
2512       CASE(_invokeinterface): {
2513         u2 index = Bytes::get_native_u2(pc+1);
2514 
2515         // QQQ Need to make this as inlined as possible. Probably need to split all the bytecode cases
2516         // out so c++ compiler has a chance for constant prop to fold everything possible away.
2517 
2518         ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2519         if (!cache-&gt;is_resolved((Bytecodes::Code)opcode)) {
2520           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2521                   handle_exception);
2522           cache = cp-&gt;entry_at(index);
2523         }
2524 
2525         istate-&gt;set_msg(call_method);
2526 
2527         // Special case of invokeinterface called for virtual method of
2528         // java.lang.Object.  See cpCache.cpp for details.
2529         Method* callee = NULL;
2530         if (cache-&gt;is_forced_virtual()) {
2531           CHECK_NULL(STACK_OBJECT(-(cache-&gt;parameter_size())));
2532           if (cache-&gt;is_vfinal()) {
2533             callee = cache-&gt;f2_as_vfinal_method();
2534             // Profile &#39;special case of invokeinterface&#39; final call.
2535             BI_PROFILE_UPDATE_FINALCALL();
2536           } else {
2537             // Get receiver.
2538             int parms = cache-&gt;parameter_size();
2539             // Same comments as invokevirtual apply here.
2540             oop rcvr = STACK_OBJECT(-parms);
2541             VERIFY_OOP(rcvr);
2542             Klass* rcvrKlass = rcvr-&gt;klass();
2543             callee = (Method*) rcvrKlass-&gt;method_at_vtable(cache-&gt;f2_as_index());
2544             // Profile &#39;special case of invokeinterface&#39; virtual call.
2545             BI_PROFILE_UPDATE_VIRTUALCALL(rcvrKlass);
2546           }
2547         } else if (cache-&gt;is_vfinal()) {
2548           // private interface method invocations
2549           //
2550           // Ensure receiver class actually implements
2551           // the resolved interface class. The link resolver
2552           // does this, but only for the first time this
2553           // interface is being called.
2554           int parms = cache-&gt;parameter_size();
2555           oop rcvr = STACK_OBJECT(-parms);
2556           CHECK_NULL(rcvr);
2557           Klass* recv_klass = rcvr-&gt;klass();
2558           Klass* resolved_klass = cache-&gt;f1_as_klass();
2559           if (!recv_klass-&gt;is_subtype_of(resolved_klass)) {
2560             ResourceMark rm(THREAD);
2561             char buf[200];
2562             jio_snprintf(buf, sizeof(buf), &quot;Class %s does not implement the requested interface %s&quot;,
2563               recv_klass-&gt;external_name(),
2564               resolved_klass-&gt;external_name());
2565             VM_JAVA_ERROR(vmSymbols::java_lang_IncompatibleClassChangeError(), buf, note_no_trap);
2566           }
2567           callee = cache-&gt;f2_as_vfinal_method();
2568         }
2569         if (callee != NULL) {
2570           istate-&gt;set_callee(callee);
2571           istate-&gt;set_callee_entry_point(callee-&gt;from_interpreted_entry());
2572 #ifdef VM_JVMTI
2573           if (JvmtiExport::can_post_interpreter_events() &amp;&amp; THREAD-&gt;is_interp_only_mode()) {
2574             istate-&gt;set_callee_entry_point(callee-&gt;interpreter_entry());
2575           }
2576 #endif /* VM_JVMTI */
2577           istate-&gt;set_bcp_advance(5);
2578           UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2579         }
2580 
2581         // this could definitely be cleaned up QQQ
2582         Method *interface_method = cache-&gt;f2_as_interface_method();
2583         InstanceKlass* iclass = interface_method-&gt;method_holder();
2584 
2585         // get receiver
2586         int parms = cache-&gt;parameter_size();
2587         oop rcvr = STACK_OBJECT(-parms);
2588         CHECK_NULL(rcvr);
2589         InstanceKlass* int2 = (InstanceKlass*) rcvr-&gt;klass();
2590 
2591         // Receiver subtype check against resolved interface klass (REFC).
2592         {
2593           Klass* refc = cache-&gt;f1_as_klass();
2594           itableOffsetEntry* scan;
2595           for (scan = (itableOffsetEntry*) int2-&gt;start_of_itable();
2596                scan-&gt;interface_klass() != NULL;
2597                scan++) {
2598             if (scan-&gt;interface_klass() == refc) {
2599               break;
2600             }
2601           }
2602           // Check that the entry is non-null.  A null entry means
2603           // that the receiver class doesn&#39;t implement the
2604           // interface, and wasn&#39;t the same as when the caller was
2605           // compiled.
2606           if (scan-&gt;interface_klass() == NULL) {
2607             VM_JAVA_ERROR(vmSymbols::java_lang_IncompatibleClassChangeError(), &quot;&quot;, note_no_trap);
2608           }
2609         }
2610 
2611         itableOffsetEntry* ki = (itableOffsetEntry*) int2-&gt;start_of_itable();
2612         int i;
2613         for ( i = 0 ; i &lt; int2-&gt;itable_length() ; i++, ki++ ) {
2614           if (ki-&gt;interface_klass() == iclass) break;
2615         }
2616         // If the interface isn&#39;t found, this class doesn&#39;t implement this
2617         // interface. The link resolver checks this but only for the first
2618         // time this interface is called.
2619         if (i == int2-&gt;itable_length()) {
2620           CALL_VM(InterpreterRuntime::throw_IncompatibleClassChangeErrorVerbose(THREAD, rcvr-&gt;klass(), iclass),
2621                   handle_exception);
2622         }
2623         int mindex = interface_method-&gt;itable_index();
2624 
2625         itableMethodEntry* im = ki-&gt;first_method_entry(rcvr-&gt;klass());
2626         callee = im[mindex].method();
2627         if (callee == NULL) {
2628           CALL_VM(InterpreterRuntime::throw_AbstractMethodErrorVerbose(THREAD, rcvr-&gt;klass(), interface_method),
2629                   handle_exception);
2630         }
2631 
2632         // Profile virtual call.
2633         BI_PROFILE_UPDATE_VIRTUALCALL(rcvr-&gt;klass());
2634 
2635         istate-&gt;set_callee(callee);
2636         istate-&gt;set_callee_entry_point(callee-&gt;from_interpreted_entry());
2637 #ifdef VM_JVMTI
2638         if (JvmtiExport::can_post_interpreter_events() &amp;&amp; THREAD-&gt;is_interp_only_mode()) {
2639           istate-&gt;set_callee_entry_point(callee-&gt;interpreter_entry());
2640         }
2641 #endif /* VM_JVMTI */
2642         istate-&gt;set_bcp_advance(5);
2643         UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2644       }
2645 
2646       CASE(_invokevirtual):
2647       CASE(_invokespecial):
2648       CASE(_invokestatic): {
2649         u2 index = Bytes::get_native_u2(pc+1);
2650 
2651         ConstantPoolCacheEntry* cache = cp-&gt;entry_at(index);
2652         // QQQ Need to make this as inlined as possible. Probably need to split all the bytecode cases
2653         // out so c++ compiler has a chance for constant prop to fold everything possible away.
2654 
2655         if (!cache-&gt;is_resolved((Bytecodes::Code)opcode)) {
2656           CALL_VM(InterpreterRuntime::resolve_from_cache(THREAD, (Bytecodes::Code)opcode),
2657                   handle_exception);
2658           cache = cp-&gt;entry_at(index);
2659         }
2660 
2661         istate-&gt;set_msg(call_method);
2662         {
2663           Method* callee;
2664           if ((Bytecodes::Code)opcode == Bytecodes::_invokevirtual) {
2665             CHECK_NULL(STACK_OBJECT(-(cache-&gt;parameter_size())));
2666             if (cache-&gt;is_vfinal()) {
2667               callee = cache-&gt;f2_as_vfinal_method();
2668               // Profile final call.
2669               BI_PROFILE_UPDATE_FINALCALL();
2670             } else {
2671               // get receiver
2672               int parms = cache-&gt;parameter_size();
2673               // this works but needs a resourcemark and seems to create a vtable on every call:
2674               // Method* callee = rcvr-&gt;klass()-&gt;vtable()-&gt;method_at(cache-&gt;f2_as_index());
2675               //
2676               // this fails with an assert
2677               // InstanceKlass* rcvrKlass = InstanceKlass::cast(STACK_OBJECT(-parms)-&gt;klass());
2678               // but this works
2679               oop rcvr = STACK_OBJECT(-parms);
2680               VERIFY_OOP(rcvr);
2681               Klass* rcvrKlass = rcvr-&gt;klass();
2682               /*
2683                 Executing this code in java.lang.String:
2684                     public String(char value[]) {
2685                           this.count = value.length;
2686                           this.value = (char[])value.clone();
2687                      }
2688 
2689                  a find on rcvr-&gt;klass() reports:
2690                  {type array char}{type array class}
2691                   - klass: {other class}
2692 
2693                   but using InstanceKlass::cast(STACK_OBJECT(-parms)-&gt;klass()) causes in assertion failure
2694                   because rcvr-&gt;klass()-&gt;is_instance_klass() == 0
2695                   However it seems to have a vtable in the right location. Huh?
2696                   Because vtables have the same offset for ArrayKlass and InstanceKlass.
2697               */
2698               callee = (Method*) rcvrKlass-&gt;method_at_vtable(cache-&gt;f2_as_index());
2699               // Profile virtual call.
2700               BI_PROFILE_UPDATE_VIRTUALCALL(rcvrKlass);
2701             }
2702           } else {
2703             if ((Bytecodes::Code)opcode == Bytecodes::_invokespecial) {
2704               CHECK_NULL(STACK_OBJECT(-(cache-&gt;parameter_size())));
2705             }
2706             callee = cache-&gt;f1_as_method();
2707 
2708             // Profile call.
2709             BI_PROFILE_UPDATE_CALL();
2710           }
2711 
2712           istate-&gt;set_callee(callee);
2713           istate-&gt;set_callee_entry_point(callee-&gt;from_interpreted_entry());
2714 #ifdef VM_JVMTI
2715           if (JvmtiExport::can_post_interpreter_events() &amp;&amp; THREAD-&gt;is_interp_only_mode()) {
2716             istate-&gt;set_callee_entry_point(callee-&gt;interpreter_entry());
2717           }
2718 #endif /* VM_JVMTI */
2719           istate-&gt;set_bcp_advance(3);
2720           UPDATE_PC_AND_RETURN(0); // I&#39;ll be back...
2721         }
2722       }
2723 
2724       /* Allocate memory for a new java object. */
2725 
2726       CASE(_newarray): {
2727         BasicType atype = (BasicType) *(pc+1);
2728         jint size = STACK_INT(-1);
2729         CALL_VM(InterpreterRuntime::newarray(THREAD, atype, size),
2730                 handle_exception);
2731         // Must prevent reordering of stores for object initialization
2732         // with stores that publish the new object.
2733         OrderAccess::storestore();
2734         SET_STACK_OBJECT(THREAD-&gt;vm_result(), -1);
2735         THREAD-&gt;set_vm_result(NULL);
2736 
2737         UPDATE_PC_AND_CONTINUE(2);
2738       }
2739 
2740       /* Throw an exception. */
2741 
2742       CASE(_athrow): {
2743           oop except_oop = STACK_OBJECT(-1);
2744           CHECK_NULL(except_oop);
2745           // set pending_exception so we use common code
2746           THREAD-&gt;set_pending_exception(except_oop, NULL, 0);
2747           goto handle_exception;
2748       }
2749 
2750       /* goto and jsr. They are exactly the same except jsr pushes
2751        * the address of the next instruction first.
2752        */
2753 
2754       CASE(_jsr): {
2755           /* push bytecode index on stack */
2756           SET_STACK_ADDR(((address)pc - (intptr_t)(istate-&gt;method()-&gt;code_base()) + 3), 0);
2757           MORE_STACK(1);
2758           /* FALL THROUGH */
2759       }
2760 
2761       CASE(_goto):
2762       {
2763           int16_t offset = (int16_t)Bytes::get_Java_u2(pc + 1);
2764           // Profile jump.
2765           BI_PROFILE_UPDATE_JUMP();
2766           address branch_pc = pc;
2767           UPDATE_PC(offset);
2768           DO_BACKEDGE_CHECKS(offset, branch_pc);
2769           CONTINUE;
2770       }
2771 
2772       CASE(_jsr_w): {
2773           /* push return address on the stack */
2774           SET_STACK_ADDR(((address)pc - (intptr_t)(istate-&gt;method()-&gt;code_base()) + 5), 0);
2775           MORE_STACK(1);
2776           /* FALL THROUGH */
2777       }
2778 
2779       CASE(_goto_w):
2780       {
2781           int32_t offset = Bytes::get_Java_u4(pc + 1);
2782           // Profile jump.
2783           BI_PROFILE_UPDATE_JUMP();
2784           address branch_pc = pc;
2785           UPDATE_PC(offset);
2786           DO_BACKEDGE_CHECKS(offset, branch_pc);
2787           CONTINUE;
2788       }
2789 
2790       /* return from a jsr or jsr_w */
2791 
2792       CASE(_ret): {
2793           // Profile ret.
2794           BI_PROFILE_UPDATE_RET(/*bci=*/((int)(intptr_t)(LOCALS_ADDR(pc[1]))));
2795           // Now, update the pc.
2796           pc = istate-&gt;method()-&gt;code_base() + (intptr_t)(LOCALS_ADDR(pc[1]));
2797           UPDATE_PC_AND_CONTINUE(0);
2798       }
2799 
2800       /* debugger breakpoint */
2801 
2802       CASE(_breakpoint): {
2803           Bytecodes::Code original_bytecode;
2804           DECACHE_STATE();
2805           SET_LAST_JAVA_FRAME();
2806           original_bytecode = InterpreterRuntime::get_original_bytecode_at(THREAD,
2807                               METHOD, pc);
2808           RESET_LAST_JAVA_FRAME();
2809           CACHE_STATE();
2810           if (THREAD-&gt;has_pending_exception()) goto handle_exception;
2811             CALL_VM(InterpreterRuntime::_breakpoint(THREAD, METHOD, pc),
2812                                                     handle_exception);
2813 
2814           opcode = (jubyte)original_bytecode;
2815           goto opcode_switch;
2816       }
2817 
2818       DEFAULT:
2819           fatal(&quot;Unimplemented opcode %d = %s&quot;, opcode,
2820                 Bytecodes::name((Bytecodes::Code)opcode));
2821           goto finish;
2822 
2823       } /* switch(opc) */
2824 
2825 
2826 #ifdef USELABELS
2827     check_for_exception:
2828 #endif
2829     {
2830       if (!THREAD-&gt;has_pending_exception()) {
2831         CONTINUE;
2832       }
2833       /* We will be gcsafe soon, so flush our state. */
2834       DECACHE_PC();
2835       goto handle_exception;
2836     }
2837   do_continue: ;
2838 
2839   } /* while (1) interpreter loop */
2840 
2841 
2842   // An exception exists in the thread state see whether this activation can handle it
2843   handle_exception: {
2844 
2845     HandleMarkCleaner __hmc(THREAD);
2846     Handle except_oop(THREAD, THREAD-&gt;pending_exception());
2847     // Prevent any subsequent HandleMarkCleaner in the VM
2848     // from freeing the except_oop handle.
2849     HandleMark __hm(THREAD);
2850 
2851     THREAD-&gt;clear_pending_exception();
2852     assert(except_oop() != NULL, &quot;No exception to process&quot;);
2853     intptr_t continuation_bci;
2854     // expression stack is emptied
2855     topOfStack = istate-&gt;stack_base() - Interpreter::stackElementWords;
2856     CALL_VM(continuation_bci = (intptr_t)InterpreterRuntime::exception_handler_for_exception(THREAD, except_oop()),
2857             handle_exception);
2858 
2859     except_oop = Handle(THREAD, THREAD-&gt;vm_result());
2860     THREAD-&gt;set_vm_result(NULL);
2861     if (continuation_bci &gt;= 0) {
2862       // Place exception on top of stack
2863       SET_STACK_OBJECT(except_oop(), 0);
2864       MORE_STACK(1);
2865       pc = METHOD-&gt;code_base() + continuation_bci;
2866       if (log_is_enabled(Info, exceptions)) {
2867         ResourceMark rm(THREAD);
2868         stringStream tempst;
2869         tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
2870                      &quot; at bci %d, continuing at %d for thread &quot; INTPTR_FORMAT,
2871                      METHOD-&gt;print_value_string(),
2872                      (int)(istate-&gt;bcp() - METHOD-&gt;code_base()),
2873                      (int)continuation_bci, p2i(THREAD));
2874         Exceptions::log_exception(except_oop, tempst.as_string());
2875       }
2876       // for AbortVMOnException flag
2877       Exceptions::debug_check_abort(except_oop);
2878 
2879       // Update profiling data.
2880       BI_PROFILE_ALIGN_TO_CURRENT_BCI();
2881       goto run;
2882     }
2883     if (log_is_enabled(Info, exceptions)) {
2884       ResourceMark rm;
2885       stringStream tempst;
2886       tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
2887              &quot; at bci %d, unwinding for thread &quot; INTPTR_FORMAT,
2888              METHOD-&gt;print_value_string(),
2889              (int)(istate-&gt;bcp() - METHOD-&gt;code_base()),
2890              p2i(THREAD));
2891       Exceptions::log_exception(except_oop, tempst.as_string());
2892     }
2893     // for AbortVMOnException flag
2894     Exceptions::debug_check_abort(except_oop);
2895 
2896     // No handler in this activation, unwind and try again
2897     THREAD-&gt;set_pending_exception(except_oop(), NULL, 0);
2898     goto handle_return;
2899   }  // handle_exception:
2900 
2901   // Return from an interpreter invocation with the result of the interpretation
2902   // on the top of the Java Stack (or a pending exception)
2903 
2904   handle_Pop_Frame: {
2905 
2906     // We don&#39;t really do anything special here except we must be aware
2907     // that we can get here without ever locking the method (if sync).
2908     // Also we skip the notification of the exit.
2909 
2910     istate-&gt;set_msg(popping_frame);
2911     // Clear pending so while the pop is in process
2912     // we don&#39;t start another one if a call_vm is done.
2913     THREAD-&gt;clr_pop_frame_pending();
2914     // Let interpreter (only) see the we&#39;re in the process of popping a frame
2915     THREAD-&gt;set_pop_frame_in_process();
2916 
2917     goto handle_return;
2918 
2919   } // handle_Pop_Frame
2920 
2921   // ForceEarlyReturn ends a method, and returns to the caller with a return value
2922   // given by the invoker of the early return.
2923   handle_Early_Return: {
2924 
2925     istate-&gt;set_msg(early_return);
2926 
2927     // Clear expression stack.
2928     topOfStack = istate-&gt;stack_base() - Interpreter::stackElementWords;
2929 
2930     JvmtiThreadState *ts = THREAD-&gt;jvmti_thread_state();
2931 
2932     // Push the value to be returned.
2933     switch (istate-&gt;method()-&gt;result_type()) {
2934       case T_BOOLEAN:
2935       case T_SHORT:
2936       case T_BYTE:
2937       case T_CHAR:
2938       case T_INT:
2939         SET_STACK_INT(ts-&gt;earlyret_value().i, 0);
2940         MORE_STACK(1);
2941         break;
2942       case T_LONG:
2943         SET_STACK_LONG(ts-&gt;earlyret_value().j, 1);
2944         MORE_STACK(2);
2945         break;
2946       case T_FLOAT:
2947         SET_STACK_FLOAT(ts-&gt;earlyret_value().f, 0);
2948         MORE_STACK(1);
2949         break;
2950       case T_DOUBLE:
2951         SET_STACK_DOUBLE(ts-&gt;earlyret_value().d, 1);
2952         MORE_STACK(2);
2953         break;
2954       case T_ARRAY:
2955       case T_OBJECT:
2956         SET_STACK_OBJECT(ts-&gt;earlyret_oop(), 0);
2957         MORE_STACK(1);
2958         break;
2959     }
2960 
2961     ts-&gt;clr_earlyret_value();
2962     ts-&gt;set_earlyret_oop(NULL);
2963     ts-&gt;clr_earlyret_pending();
2964 
2965     // Fall through to handle_return.
2966 
2967   } // handle_Early_Return
2968 
2969   handle_return: {
2970     // A storestore barrier is required to order initialization of
2971     // final fields with publishing the reference to the object that
2972     // holds the field. Without the barrier the value of final fields
2973     // can be observed to change.
2974     OrderAccess::storestore();
2975 
2976     DECACHE_STATE();
2977 
2978     bool suppress_error = istate-&gt;msg() == popping_frame || istate-&gt;msg() == early_return;
2979     bool suppress_exit_event = THREAD-&gt;has_pending_exception() || istate-&gt;msg() == popping_frame;
2980     Handle original_exception(THREAD, THREAD-&gt;pending_exception());
2981     Handle illegal_state_oop(THREAD, NULL);
2982 
2983     // We&#39;d like a HandleMark here to prevent any subsequent HandleMarkCleaner
2984     // in any following VM entries from freeing our live handles, but illegal_state_oop
2985     // isn&#39;t really allocated yet and so doesn&#39;t become live until later and
2986     // in unpredicatable places. Instead we must protect the places where we enter the
2987     // VM. It would be much simpler (and safer) if we could allocate a real handle with
2988     // a NULL oop in it and then overwrite the oop later as needed. This isn&#39;t
2989     // unfortunately isn&#39;t possible.
2990 
2991     THREAD-&gt;clear_pending_exception();
2992 
2993     //
2994     // As far as we are concerned we have returned. If we have a pending exception
2995     // that will be returned as this invocation&#39;s result. However if we get any
2996     // exception(s) while checking monitor state one of those IllegalMonitorStateExceptions
2997     // will be our final result (i.e. monitor exception trumps a pending exception).
2998     //
2999 
3000     // If we never locked the method (or really passed the point where we would have),
3001     // there is no need to unlock it (or look for other monitors), since that
3002     // could not have happened.
3003 
3004     if (THREAD-&gt;do_not_unlock()) {
3005 
3006       // Never locked, reset the flag now because obviously any caller must
3007       // have passed their point of locking for us to have gotten here.
3008 
3009       THREAD-&gt;clr_do_not_unlock();
3010     } else {
3011       // At this point we consider that we have returned. We now check that the
3012       // locks were properly block structured. If we find that they were not
3013       // used properly we will return with an illegal monitor exception.
3014       // The exception is checked by the caller not the callee since this
3015       // checking is considered to be part of the invocation and therefore
3016       // in the callers scope (JVM spec 8.13).
3017       //
3018       // Another weird thing to watch for is if the method was locked
3019       // recursively and then not exited properly. This means we must
3020       // examine all the entries in reverse time(and stack) order and
3021       // unlock as we find them. If we find the method monitor before
3022       // we are at the initial entry then we should throw an exception.
3023       // It is not clear the template based interpreter does this
3024       // correctly
3025 
3026       BasicObjectLock* base = istate-&gt;monitor_base();
3027       BasicObjectLock* end = (BasicObjectLock*) istate-&gt;stack_base();
3028       bool method_unlock_needed = METHOD-&gt;is_synchronized();
3029       // We know the initial monitor was used for the method don&#39;t check that
3030       // slot in the loop
3031       if (method_unlock_needed) base--;
3032 
3033       // Check all the monitors to see they are unlocked. Install exception if found to be locked.
3034       while (end &lt; base) {
3035         oop lockee = end-&gt;obj();
3036         if (lockee != NULL) {
3037           BasicLock* lock = end-&gt;lock();
3038           markWord header = lock-&gt;displaced_header();
3039           end-&gt;set_obj(NULL);
3040 
3041           if (!lockee-&gt;mark().has_bias_pattern()) {
3042             // If it isn&#39;t recursive we either must swap old header or call the runtime
3043             if (header.to_pointer() != NULL) {
3044               markWord old_header = markWord::encode(lock);
3045               if (lockee-&gt;cas_set_mark(header, old_header) != old_header) {
3046                 // restore object for the slow case
3047                 end-&gt;set_obj(lockee);
3048                 {
3049                   // Prevent any HandleMarkCleaner from freeing our live handles
3050                   HandleMark __hm(THREAD);
3051                   CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, end));
3052                 }
3053               }
3054             }
3055           }
3056           // One error is plenty
3057           if (illegal_state_oop() == NULL &amp;&amp; !suppress_error) {
3058             {
3059               // Prevent any HandleMarkCleaner from freeing our live handles
3060               HandleMark __hm(THREAD);
3061               CALL_VM_NOCHECK(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD));
3062             }
3063             assert(THREAD-&gt;has_pending_exception(), &quot;Lost our exception!&quot;);
3064             illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3065             THREAD-&gt;clear_pending_exception();
3066           }
3067         }
3068         end++;
3069       }
3070       // Unlock the method if needed
3071       if (method_unlock_needed) {
3072         if (base-&gt;obj() == NULL) {
3073           // The method is already unlocked this is not good.
3074           if (illegal_state_oop() == NULL &amp;&amp; !suppress_error) {
3075             {
3076               // Prevent any HandleMarkCleaner from freeing our live handles
3077               HandleMark __hm(THREAD);
3078               CALL_VM_NOCHECK(InterpreterRuntime::throw_illegal_monitor_state_exception(THREAD));
3079             }
3080             assert(THREAD-&gt;has_pending_exception(), &quot;Lost our exception!&quot;);
3081             illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3082             THREAD-&gt;clear_pending_exception();
3083           }
3084         } else {
3085           //
3086           // The initial monitor is always used for the method
3087           // However if that slot is no longer the oop for the method it was unlocked
3088           // and reused by something that wasn&#39;t unlocked!
3089           //
3090           // deopt can come in with rcvr dead because c2 knows
3091           // its value is preserved in the monitor. So we can&#39;t use locals[0] at all
3092           // and must use first monitor slot.
3093           //
3094           oop rcvr = base-&gt;obj();
3095           if (rcvr == NULL) {
3096             if (!suppress_error) {
3097               VM_JAVA_ERROR_NO_JUMP(vmSymbols::java_lang_NullPointerException(), &quot;&quot;, note_nullCheck_trap);
3098               illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3099               THREAD-&gt;clear_pending_exception();
3100             }
3101           } else if (UseHeavyMonitors) {
3102             {
3103               // Prevent any HandleMarkCleaner from freeing our live handles.
3104               HandleMark __hm(THREAD);
3105               CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, base));
3106             }
3107             if (THREAD-&gt;has_pending_exception()) {
3108               if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3109               THREAD-&gt;clear_pending_exception();
3110             }
3111           } else {
3112             BasicLock* lock = base-&gt;lock();
3113             markWord header = lock-&gt;displaced_header();
3114             base-&gt;set_obj(NULL);
3115 
3116             if (!rcvr-&gt;mark().has_bias_pattern()) {
3117               base-&gt;set_obj(NULL);
3118               // If it isn&#39;t recursive we either must swap old header or call the runtime
3119               if (header.to_pointer() != NULL) {
3120                 markWord old_header = markWord::encode(lock);
3121                 if (rcvr-&gt;cas_set_mark(header, old_header) != old_header) {
3122                   // restore object for the slow case
3123                   base-&gt;set_obj(rcvr);
3124                   {
3125                     // Prevent any HandleMarkCleaner from freeing our live handles
3126                     HandleMark __hm(THREAD);
3127                     CALL_VM_NOCHECK(InterpreterRuntime::monitorexit(THREAD, base));
3128                   }
3129                   if (THREAD-&gt;has_pending_exception()) {
3130                     if (!suppress_error) illegal_state_oop = Handle(THREAD, THREAD-&gt;pending_exception());
3131                     THREAD-&gt;clear_pending_exception();
3132                   }
3133                 }
3134               }
3135             }
3136           }
3137         }
3138       }
3139     }
3140     // Clear the do_not_unlock flag now.
3141     THREAD-&gt;clr_do_not_unlock();
3142 
3143     //
3144     // Notify jvmti/jvmdi
3145     //
3146     // NOTE: we do not notify a method_exit if we have a pending exception,
3147     // including an exception we generate for unlocking checks.  In the former
3148     // case, JVMDI has already been notified by our call for the exception handler
3149     // and in both cases as far as JVMDI is concerned we have already returned.
3150     // If we notify it again JVMDI will be all confused about how many frames
3151     // are still on the stack (4340444).
3152     //
3153     // NOTE Further! It turns out the the JVMTI spec in fact expects to see
3154     // method_exit events whenever we leave an activation unless it was done
3155     // for popframe. This is nothing like jvmdi. However we are passing the
3156     // tests at the moment (apparently because they are jvmdi based) so rather
3157     // than change this code and possibly fail tests we will leave it alone
3158     // (with this note) in anticipation of changing the vm and the tests
3159     // simultaneously.
3160 
3161 
3162     //
3163     suppress_exit_event = suppress_exit_event || illegal_state_oop() != NULL;
3164 
3165 
3166 
3167 #ifdef VM_JVMTI
3168       if (_jvmti_interp_events) {
3169         // Whenever JVMTI puts a thread in interp_only_mode, method
3170         // entry/exit events are sent for that thread to track stack depth.
3171         if ( !suppress_exit_event &amp;&amp; THREAD-&gt;is_interp_only_mode() ) {
3172           {
3173             // Prevent any HandleMarkCleaner from freeing our live handles
3174             HandleMark __hm(THREAD);
3175             CALL_VM_NOCHECK(InterpreterRuntime::post_method_exit(THREAD));
3176           }
3177         }
3178       }
3179 #endif /* VM_JVMTI */
3180 
3181     //
3182     // See if we are returning any exception
3183     // A pending exception that was pending prior to a possible popping frame
3184     // overrides the popping frame.
3185     //
3186     assert(!suppress_error || (suppress_error &amp;&amp; illegal_state_oop() == NULL), &quot;Error was not suppressed&quot;);
3187     if (illegal_state_oop() != NULL || original_exception() != NULL) {
3188       // Inform the frame manager we have no result.
3189       istate-&gt;set_msg(throwing_exception);
3190       if (illegal_state_oop() != NULL)
3191         THREAD-&gt;set_pending_exception(illegal_state_oop(), NULL, 0);
3192       else
3193         THREAD-&gt;set_pending_exception(original_exception(), NULL, 0);
3194       UPDATE_PC_AND_RETURN(0);
3195     }
3196 
3197     if (istate-&gt;msg() == popping_frame) {
3198       // Make it simpler on the assembly code and set the message for the frame pop.
3199       // returns
3200       if (istate-&gt;prev() == NULL) {
3201         // We must be returning to a deoptimized frame (because popframe only happens between
3202         // two interpreted frames). We need to save the current arguments in C heap so that
3203         // the deoptimized frame when it restarts can copy the arguments to its expression
3204         // stack and re-execute the call. We also have to notify deoptimization that this
3205         // has occurred and to pick the preserved args copy them to the deoptimized frame&#39;s
3206         // java expression stack. Yuck.
3207         //
3208         THREAD-&gt;popframe_preserve_args(in_ByteSize(METHOD-&gt;size_of_parameters() * wordSize),
3209                                 LOCALS_SLOT(METHOD-&gt;size_of_parameters() - 1));
3210         THREAD-&gt;set_popframe_condition_bit(JavaThread::popframe_force_deopt_reexecution_bit);
3211       }
3212     } else {
3213       istate-&gt;set_msg(return_from_method);
3214     }
3215 
3216     // Normal return
3217     // Advance the pc and return to frame manager
3218     UPDATE_PC_AND_RETURN(1);
3219   } /* handle_return: */
3220 
3221 // This is really a fatal error return
3222 
3223 finish:
3224   DECACHE_TOS();
3225   DECACHE_PC();
3226 
3227   return;
3228 }
3229 
3230 /*
3231  * All the code following this point is only produced once and is not present
3232  * in the JVMTI version of the interpreter
3233 */
3234 
3235 #ifndef VM_JVMTI
3236 
3237 // This constructor should only be used to contruct the object to signal
3238 // interpreter initialization. All other instances should be created by
3239 // the frame manager.
3240 BytecodeInterpreter::BytecodeInterpreter(messages msg) {
3241   if (msg != initialize) ShouldNotReachHere();
3242   _msg = msg;
3243   _self_link = this;
3244   _prev_link = NULL;
3245 }
3246 
3247 // Inline static functions for Java Stack and Local manipulation
3248 
3249 // The implementations are platform dependent. We have to worry about alignment
3250 // issues on some machines which can change on the same platform depending on
3251 // whether it is an LP64 machine also.
3252 address BytecodeInterpreter::stack_slot(intptr_t *tos, int offset) {
3253   return (address) tos[Interpreter::expr_index_at(-offset)];
3254 }
3255 
3256 jint BytecodeInterpreter::stack_int(intptr_t *tos, int offset) {
3257   return *((jint*) &amp;tos[Interpreter::expr_index_at(-offset)]);
3258 }
3259 
3260 jfloat BytecodeInterpreter::stack_float(intptr_t *tos, int offset) {
3261   return *((jfloat *) &amp;tos[Interpreter::expr_index_at(-offset)]);
3262 }
3263 
3264 oop BytecodeInterpreter::stack_object(intptr_t *tos, int offset) {
3265   return cast_to_oop(tos [Interpreter::expr_index_at(-offset)]);
3266 }
3267 
3268 jdouble BytecodeInterpreter::stack_double(intptr_t *tos, int offset) {
3269   return ((VMJavaVal64*) &amp;tos[Interpreter::expr_index_at(-offset)])-&gt;d;
3270 }
3271 
3272 jlong BytecodeInterpreter::stack_long(intptr_t *tos, int offset) {
3273   return ((VMJavaVal64 *) &amp;tos[Interpreter::expr_index_at(-offset)])-&gt;l;
3274 }
3275 
3276 // only used for value types
3277 void BytecodeInterpreter::set_stack_slot(intptr_t *tos, address value,
3278                                                         int offset) {
3279   *((address *)&amp;tos[Interpreter::expr_index_at(-offset)]) = value;
3280 }
3281 
3282 void BytecodeInterpreter::set_stack_int(intptr_t *tos, int value,
3283                                                        int offset) {
3284   *((jint *)&amp;tos[Interpreter::expr_index_at(-offset)]) = value;
3285 }
3286 
3287 void BytecodeInterpreter::set_stack_float(intptr_t *tos, jfloat value,
3288                                                          int offset) {
3289   *((jfloat *)&amp;tos[Interpreter::expr_index_at(-offset)]) = value;
3290 }
3291 
3292 void BytecodeInterpreter::set_stack_object(intptr_t *tos, oop value,
3293                                                           int offset) {
3294   *((oop *)&amp;tos[Interpreter::expr_index_at(-offset)]) = value;
3295 }
3296 
3297 // needs to be platform dep for the 32 bit platforms.
3298 void BytecodeInterpreter::set_stack_double(intptr_t *tos, jdouble value,
3299                                                           int offset) {
3300   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset)])-&gt;d = value;
3301 }
3302 
3303 void BytecodeInterpreter::set_stack_double_from_addr(intptr_t *tos,
3304                                               address addr, int offset) {
3305   (((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset)])-&gt;d =
3306                         ((VMJavaVal64*)addr)-&gt;d);
3307 }
3308 
3309 void BytecodeInterpreter::set_stack_long(intptr_t *tos, jlong value,
3310                                                         int offset) {
3311   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset+1)])-&gt;l = 0xdeedbeeb;
3312   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset)])-&gt;l = value;
3313 }
3314 
3315 void BytecodeInterpreter::set_stack_long_from_addr(intptr_t *tos,
3316                                             address addr, int offset) {
3317   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset+1)])-&gt;l = 0xdeedbeeb;
3318   ((VMJavaVal64*)&amp;tos[Interpreter::expr_index_at(-offset)])-&gt;l =
3319                         ((VMJavaVal64*)addr)-&gt;l;
3320 }
3321 
3322 // Locals
3323 
3324 address BytecodeInterpreter::locals_slot(intptr_t* locals, int offset) {
3325   return (address)locals[Interpreter::local_index_at(-offset)];
3326 }
3327 jint BytecodeInterpreter::locals_int(intptr_t* locals, int offset) {
3328   return (jint)locals[Interpreter::local_index_at(-offset)];
3329 }
3330 jfloat BytecodeInterpreter::locals_float(intptr_t* locals, int offset) {
3331   return (jfloat)locals[Interpreter::local_index_at(-offset)];
3332 }
3333 oop BytecodeInterpreter::locals_object(intptr_t* locals, int offset) {
3334   return cast_to_oop(locals[Interpreter::local_index_at(-offset)]);
3335 }
3336 jdouble BytecodeInterpreter::locals_double(intptr_t* locals, int offset) {
3337   return ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;d;
3338 }
3339 jlong BytecodeInterpreter::locals_long(intptr_t* locals, int offset) {
3340   return ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;l;
3341 }
3342 
3343 // Returns the address of locals value.
3344 address BytecodeInterpreter::locals_long_at(intptr_t* locals, int offset) {
3345   return ((address)&amp;locals[Interpreter::local_index_at(-(offset+1))]);
3346 }
3347 address BytecodeInterpreter::locals_double_at(intptr_t* locals, int offset) {
3348   return ((address)&amp;locals[Interpreter::local_index_at(-(offset+1))]);
3349 }
3350 
3351 // Used for local value or returnAddress
3352 void BytecodeInterpreter::set_locals_slot(intptr_t *locals,
3353                                    address value, int offset) {
3354   *((address*)&amp;locals[Interpreter::local_index_at(-offset)]) = value;
3355 }
3356 void BytecodeInterpreter::set_locals_int(intptr_t *locals,
3357                                    jint value, int offset) {
3358   *((jint *)&amp;locals[Interpreter::local_index_at(-offset)]) = value;
3359 }
3360 void BytecodeInterpreter::set_locals_float(intptr_t *locals,
3361                                    jfloat value, int offset) {
3362   *((jfloat *)&amp;locals[Interpreter::local_index_at(-offset)]) = value;
3363 }
3364 void BytecodeInterpreter::set_locals_object(intptr_t *locals,
3365                                    oop value, int offset) {
3366   *((oop *)&amp;locals[Interpreter::local_index_at(-offset)]) = value;
3367 }
3368 void BytecodeInterpreter::set_locals_double(intptr_t *locals,
3369                                    jdouble value, int offset) {
3370   ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;d = value;
3371 }
3372 void BytecodeInterpreter::set_locals_long(intptr_t *locals,
3373                                    jlong value, int offset) {
3374   ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;l = value;
3375 }
3376 void BytecodeInterpreter::set_locals_double_from_addr(intptr_t *locals,
3377                                    address addr, int offset) {
3378   ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;d = ((VMJavaVal64*)addr)-&gt;d;
3379 }
3380 void BytecodeInterpreter::set_locals_long_from_addr(intptr_t *locals,
3381                                    address addr, int offset) {
3382   ((VMJavaVal64*)&amp;locals[Interpreter::local_index_at(-(offset+1))])-&gt;l = ((VMJavaVal64*)addr)-&gt;l;
3383 }
3384 
3385 void BytecodeInterpreter::astore(intptr_t* tos,    int stack_offset,
3386                           intptr_t* locals, int locals_offset) {
3387   intptr_t value = tos[Interpreter::expr_index_at(-stack_offset)];
3388   locals[Interpreter::local_index_at(-locals_offset)] = value;
3389 }
3390 
3391 
3392 void BytecodeInterpreter::copy_stack_slot(intptr_t *tos, int from_offset,
3393                                    int to_offset) {
3394   tos[Interpreter::expr_index_at(-to_offset)] =
3395                       (intptr_t)tos[Interpreter::expr_index_at(-from_offset)];
3396 }
3397 
3398 void BytecodeInterpreter::dup(intptr_t *tos) {
3399   copy_stack_slot(tos, -1, 0);
3400 }
3401 void BytecodeInterpreter::dup2(intptr_t *tos) {
3402   copy_stack_slot(tos, -2, 0);
3403   copy_stack_slot(tos, -1, 1);
3404 }
3405 
3406 void BytecodeInterpreter::dup_x1(intptr_t *tos) {
3407   /* insert top word two down */
3408   copy_stack_slot(tos, -1, 0);
3409   copy_stack_slot(tos, -2, -1);
3410   copy_stack_slot(tos, 0, -2);
3411 }
3412 
3413 void BytecodeInterpreter::dup_x2(intptr_t *tos) {
3414   /* insert top word three down  */
3415   copy_stack_slot(tos, -1, 0);
3416   copy_stack_slot(tos, -2, -1);
3417   copy_stack_slot(tos, -3, -2);
3418   copy_stack_slot(tos, 0, -3);
3419 }
3420 void BytecodeInterpreter::dup2_x1(intptr_t *tos) {
3421   /* insert top 2 slots three down */
3422   copy_stack_slot(tos, -1, 1);
3423   copy_stack_slot(tos, -2, 0);
3424   copy_stack_slot(tos, -3, -1);
3425   copy_stack_slot(tos, 1, -2);
3426   copy_stack_slot(tos, 0, -3);
3427 }
3428 void BytecodeInterpreter::dup2_x2(intptr_t *tos) {
3429   /* insert top 2 slots four down */
3430   copy_stack_slot(tos, -1, 1);
3431   copy_stack_slot(tos, -2, 0);
3432   copy_stack_slot(tos, -3, -1);
3433   copy_stack_slot(tos, -4, -2);
3434   copy_stack_slot(tos, 1, -3);
3435   copy_stack_slot(tos, 0, -4);
3436 }
3437 
3438 
3439 void BytecodeInterpreter::swap(intptr_t *tos) {
3440   // swap top two elements
3441   intptr_t val = tos[Interpreter::expr_index_at(1)];
3442   // Copy -2 entry to -1
3443   copy_stack_slot(tos, -2, -1);
3444   // Store saved -1 entry into -2
3445   tos[Interpreter::expr_index_at(2)] = val;
3446 }
3447 // --------------------------------------------------------------------------------
3448 // Non-product code
3449 #ifndef PRODUCT
3450 
3451 const char* BytecodeInterpreter::C_msg(BytecodeInterpreter::messages msg) {
3452   switch (msg) {
3453      case BytecodeInterpreter::no_request:  return(&quot;no_request&quot;);
3454      case BytecodeInterpreter::initialize:  return(&quot;initialize&quot;);
3455      // status message to C++ interpreter
3456      case BytecodeInterpreter::method_entry:  return(&quot;method_entry&quot;);
3457      case BytecodeInterpreter::method_resume:  return(&quot;method_resume&quot;);
3458      case BytecodeInterpreter::got_monitors:  return(&quot;got_monitors&quot;);
3459      case BytecodeInterpreter::rethrow_exception:  return(&quot;rethrow_exception&quot;);
3460      // requests to frame manager from C++ interpreter
3461      case BytecodeInterpreter::call_method:  return(&quot;call_method&quot;);
3462      case BytecodeInterpreter::return_from_method:  return(&quot;return_from_method&quot;);
3463      case BytecodeInterpreter::more_monitors:  return(&quot;more_monitors&quot;);
3464      case BytecodeInterpreter::throwing_exception:  return(&quot;throwing_exception&quot;);
3465      case BytecodeInterpreter::popping_frame:  return(&quot;popping_frame&quot;);
3466      case BytecodeInterpreter::do_osr:  return(&quot;do_osr&quot;);
3467      // deopt
3468      case BytecodeInterpreter::deopt_resume:  return(&quot;deopt_resume&quot;);
3469      case BytecodeInterpreter::deopt_resume2:  return(&quot;deopt_resume2&quot;);
3470      default: return(&quot;BAD MSG&quot;);
3471   }
3472 }
3473 void
3474 BytecodeInterpreter::print() {
3475   tty-&gt;print_cr(&quot;thread: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_thread);
3476   tty-&gt;print_cr(&quot;bcp: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_bcp);
3477   tty-&gt;print_cr(&quot;locals: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_locals);
3478   tty-&gt;print_cr(&quot;constants: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_constants);
3479   {
3480     ResourceMark rm;
3481     char *method_name = _method-&gt;name_and_sig_as_C_string();
3482     tty-&gt;print_cr(&quot;method: &quot; INTPTR_FORMAT &quot;[ %s ]&quot;,  (uintptr_t) this-&gt;_method, method_name);
3483   }
3484   tty-&gt;print_cr(&quot;mdx: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_mdx);
3485   tty-&gt;print_cr(&quot;stack: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_stack);
3486   tty-&gt;print_cr(&quot;msg: %s&quot;, C_msg(this-&gt;_msg));
3487   tty-&gt;print_cr(&quot;result_to_call._callee: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_result._to_call._callee);
3488   tty-&gt;print_cr(&quot;result_to_call._callee_entry_point: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_result._to_call._callee_entry_point);
3489   tty-&gt;print_cr(&quot;result_to_call._bcp_advance: %d &quot;, this-&gt;_result._to_call._bcp_advance);
3490   tty-&gt;print_cr(&quot;osr._osr_buf: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_result._osr._osr_buf);
3491   tty-&gt;print_cr(&quot;osr._osr_entry: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_result._osr._osr_entry);
3492   tty-&gt;print_cr(&quot;prev_link: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_prev_link);
3493   tty-&gt;print_cr(&quot;native_mirror: &quot; INTPTR_FORMAT, (uintptr_t) p2i(this-&gt;_oop_temp));
3494   tty-&gt;print_cr(&quot;stack_base: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_stack_base);
3495   tty-&gt;print_cr(&quot;stack_limit: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_stack_limit);
3496   tty-&gt;print_cr(&quot;monitor_base: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_monitor_base);
3497 #ifdef SPARC
3498   tty-&gt;print_cr(&quot;last_Java_pc: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_last_Java_pc);
3499   tty-&gt;print_cr(&quot;frame_bottom: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_frame_bottom);
3500   tty-&gt;print_cr(&quot;&amp;native_fresult: &quot; INTPTR_FORMAT, (uintptr_t) &amp;this-&gt;_native_fresult);
3501   tty-&gt;print_cr(&quot;native_lresult: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_native_lresult);
3502 #endif
3503 #if !defined(ZERO) &amp;&amp; defined(PPC)
3504   tty-&gt;print_cr(&quot;last_Java_fp: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_last_Java_fp);
3505 #endif // !ZERO
3506   tty-&gt;print_cr(&quot;self_link: &quot; INTPTR_FORMAT, (uintptr_t) this-&gt;_self_link);
3507 }
3508 
3509 extern &quot;C&quot; {
3510   void PI(uintptr_t arg) {
3511     ((BytecodeInterpreter*)arg)-&gt;print();
3512   }
3513 }
3514 #endif // PRODUCT
3515 
3516 #endif // JVMTI
3517 #endif // CC_INTERP
<a name="4" id="anc4"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="4" type="hidden" />
</body>
</html>