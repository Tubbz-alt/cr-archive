<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="assembler_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/c1_LIRGenerator_x86.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  77 //--------------------------------------------------------------
  78 
  79 
  80 LIR_Opr LIRGenerator::exceptionOopOpr() { return FrameMap::rax_oop_opr; }
  81 LIR_Opr LIRGenerator::exceptionPcOpr()  { return FrameMap::rdx_opr; }
  82 LIR_Opr LIRGenerator::divInOpr()        { return FrameMap::rax_opr; }
  83 LIR_Opr LIRGenerator::divOutOpr()       { return FrameMap::rax_opr; }
  84 LIR_Opr LIRGenerator::remOutOpr()       { return FrameMap::rdx_opr; }
  85 LIR_Opr LIRGenerator::shiftCountOpr()   { return FrameMap::rcx_opr; }
  86 LIR_Opr LIRGenerator::syncLockOpr()     { return new_register(T_INT); }
  87 LIR_Opr LIRGenerator::syncTempOpr()     { return FrameMap::rax_opr; }
  88 LIR_Opr LIRGenerator::getThreadTemp()   { return LIR_OprFact::illegalOpr; }
  89 
  90 
  91 LIR_Opr LIRGenerator::result_register_for(ValueType* type, bool callee) {
  92   LIR_Opr opr;
  93   switch (type-&gt;tag()) {
  94     case intTag:     opr = FrameMap::rax_opr;          break;
  95     case objectTag:  opr = FrameMap::rax_oop_opr;      break;
  96     case longTag:    opr = FrameMap::long0_opr;        break;




  97     case floatTag:   opr = UseSSE &gt;= 1 ? FrameMap::xmm0_float_opr  : FrameMap::fpu0_float_opr;  break;
  98     case doubleTag:  opr = UseSSE &gt;= 2 ? FrameMap::xmm0_double_opr : FrameMap::fpu0_double_opr;  break;
<span class="line-modified">  99 </span>
 100     case addressTag:
 101     default: ShouldNotReachHere(); return LIR_OprFact::illegalOpr;
 102   }
 103 
 104   assert(opr-&gt;type_field() == as_OprType(as_BasicType(type)), &quot;type mismatch&quot;);
 105   return opr;
 106 }
 107 
 108 
 109 LIR_Opr LIRGenerator::rlock_byte(BasicType type) {
 110   LIR_Opr reg = new_register(T_INT);
 111   set_vreg_flag(reg, LIRGenerator::byte_reg);
 112   return reg;
 113 }
 114 
 115 
 116 void LIRGenerator::init_temps_for_substitutability_check(LIR_Opr&amp; tmp1, LIR_Opr&amp; tmp2) {
 117   // We just need one 32-bit temp register for x86/x64, to check whether both
 118   // oops have markWord::always_locked_pattern. See LIR_Assembler::emit_opSubstitutabilityCheck().
 119   // @temp = %r10d
</pre>
<hr />
<pre>
 359 
 360   set_result(x, round_item(reg));
 361 }
 362 
 363 
 364 // for  _fadd, _fmul, _fsub, _fdiv, _frem
 365 //      _dadd, _dmul, _dsub, _ddiv, _drem
 366 void LIRGenerator::do_ArithmeticOp_FPU(ArithmeticOp* x) {
 367   LIRItem left(x-&gt;x(),  this);
 368   LIRItem right(x-&gt;y(), this);
 369   LIRItem* left_arg  = &amp;left;
 370   LIRItem* right_arg = &amp;right;
 371   assert(!left.is_stack() || !right.is_stack(), &quot;can&#39;t both be memory operands&quot;);
 372   bool must_load_both = (x-&gt;op() == Bytecodes::_frem || x-&gt;op() == Bytecodes::_drem);
 373   if (left.is_register() || x-&gt;x()-&gt;type()-&gt;is_constant() || must_load_both) {
 374     left.load_item();
 375   } else {
 376     left.dont_load_item();
 377   }
 378 

 379   // do not load right operand if it is a constant.  only 0 and 1 are
 380   // loaded because there are special instructions for loading them
 381   // without memory access (not needed for SSE2 instructions)
 382   bool must_load_right = false;
 383   if (right.is_constant()) {
 384     LIR_Const* c = right.result()-&gt;as_constant_ptr();
 385     assert(c != NULL, &quot;invalid constant&quot;);
 386     assert(c-&gt;type() == T_FLOAT || c-&gt;type() == T_DOUBLE, &quot;invalid type&quot;);
 387 
 388     if (c-&gt;type() == T_FLOAT) {
 389       must_load_right = UseSSE &lt; 1 &amp;&amp; (c-&gt;is_one_float() || c-&gt;is_zero_float());
 390     } else {
 391       must_load_right = UseSSE &lt; 2 &amp;&amp; (c-&gt;is_one_double() || c-&gt;is_zero_double());
 392     }
 393   }

 394 
 395   if (must_load_both) {
 396     // frem and drem destroy also right operand, so move it to a new register
 397     right.set_destroys_register();
 398     right.load_item();
<span class="line-modified"> 399   } else if (right.is_register() || must_load_right) {</span>
 400     right.load_item();




 401   } else {
 402     right.dont_load_item();
 403   }
 404   LIR_Opr reg = rlock(x);
 405   LIR_Opr tmp = LIR_OprFact::illegalOpr;
 406   if (x-&gt;is_strictfp() &amp;&amp; (x-&gt;op() == Bytecodes::_dmul || x-&gt;op() == Bytecodes::_ddiv)) {
 407     tmp = new_register(T_DOUBLE);
 408   }
 409 
 410 #ifdef _LP64
 411   if (x-&gt;op() == Bytecodes::_frem || x-&gt;op() == Bytecodes::_drem) {
 412     // frem and drem are implemented as a direct call into the runtime.
 413     LIRItem left(x-&gt;x(), this);
 414     LIRItem right(x-&gt;y(), this);
 415 
 416     BasicType bt = as_BasicType(x-&gt;type());
 417     BasicTypeList signature(2);
 418     signature.append(bt);
 419     signature.append(bt);
 420     CallingConvention* cc = frame_map()-&gt;c_calling_convention(&amp;signature);
</pre>
<hr />
<pre>
 791   default:                    ShouldNotReachHere();
 792   }
 793 
 794 }
 795 
 796 
 797 void LIRGenerator::do_MathIntrinsic(Intrinsic* x) {
 798   assert(x-&gt;number_of_arguments() == 1 || (x-&gt;number_of_arguments() == 2 &amp;&amp; x-&gt;id() == vmIntrinsics::_dpow), &quot;wrong type&quot;);
 799 
 800   if (x-&gt;id() == vmIntrinsics::_dexp || x-&gt;id() == vmIntrinsics::_dlog ||
 801       x-&gt;id() == vmIntrinsics::_dpow || x-&gt;id() == vmIntrinsics::_dcos ||
 802       x-&gt;id() == vmIntrinsics::_dsin || x-&gt;id() == vmIntrinsics::_dtan ||
 803       x-&gt;id() == vmIntrinsics::_dlog10) {
 804     do_LibmIntrinsic(x);
 805     return;
 806   }
 807 
 808   LIRItem value(x-&gt;argument_at(0), this);
 809 
 810   bool use_fpu = false;

 811   if (UseSSE &lt; 2) {
 812     value.set_destroys_register();
 813   }

 814   value.load_item();
 815 
 816   LIR_Opr calc_input = value.result();
 817   LIR_Opr calc_result = rlock_result(x);
 818 
 819   LIR_Opr tmp = LIR_OprFact::illegalOpr;
 820 #ifdef _LP64
 821   if (UseAVX &gt; 2 &amp;&amp; (!VM_Version::supports_avx512vl()) &amp;&amp;
 822       (x-&gt;id() == vmIntrinsics::_dabs)) {
 823     tmp = new_register(T_DOUBLE);
 824     __ move(LIR_OprFact::doubleConst(-0.0), tmp);
 825   }
 826 #endif
 827 
 828   switch(x-&gt;id()) {
 829     case vmIntrinsics::_dabs:   __ abs  (calc_input, calc_result, tmp); break;
 830     case vmIntrinsics::_dsqrt:  __ sqrt (calc_input, calc_result, LIR_OprFact::illegalOpr); break;
 831     default:                    ShouldNotReachHere();
 832   }
 833 
</pre>
<hr />
<pre>
1582     __ volatile_move(spill, temp_double, T_LONG);
1583     __ volatile_move(temp_double, LIR_OprFact::address(address), T_LONG, info);
1584   } else {
1585     __ store(value, address, info);
1586   }
1587 }
1588 
1589 void LIRGenerator::volatile_field_load(LIR_Address* address, LIR_Opr result,
1590                                        CodeEmitInfo* info) {
1591   if (address-&gt;type() == T_LONG) {
1592     address = new LIR_Address(address-&gt;base(),
1593                               address-&gt;index(), address-&gt;scale(),
1594                               address-&gt;disp(), T_DOUBLE);
1595     // Transfer the value atomically by using FP moves.  This means
1596     // the value has to be moved between CPU and FPU registers.  In
1597     // SSE0 and SSE1 mode it has to be moved through spill slot but in
1598     // SSE2+ mode it can be moved directly.
1599     LIR_Opr temp_double = new_register(T_DOUBLE);
1600     __ volatile_move(LIR_OprFact::address(address), temp_double, T_LONG, info);
1601     __ volatile_move(temp_double, result, T_LONG);

1602     if (UseSSE &lt; 2) {
1603       // no spill slot needed in SSE2 mode because xmm-&gt;cpu register move is possible
1604       set_vreg_flag(result, must_start_in_memory);
1605     }

1606   } else {
1607     __ load(address, result, info);
1608   }
1609 }
</pre>
</td>
<td>
<hr />
<pre>
  77 //--------------------------------------------------------------
  78 
  79 
  80 LIR_Opr LIRGenerator::exceptionOopOpr() { return FrameMap::rax_oop_opr; }
  81 LIR_Opr LIRGenerator::exceptionPcOpr()  { return FrameMap::rdx_opr; }
  82 LIR_Opr LIRGenerator::divInOpr()        { return FrameMap::rax_opr; }
  83 LIR_Opr LIRGenerator::divOutOpr()       { return FrameMap::rax_opr; }
  84 LIR_Opr LIRGenerator::remOutOpr()       { return FrameMap::rdx_opr; }
  85 LIR_Opr LIRGenerator::shiftCountOpr()   { return FrameMap::rcx_opr; }
  86 LIR_Opr LIRGenerator::syncLockOpr()     { return new_register(T_INT); }
  87 LIR_Opr LIRGenerator::syncTempOpr()     { return FrameMap::rax_opr; }
  88 LIR_Opr LIRGenerator::getThreadTemp()   { return LIR_OprFact::illegalOpr; }
  89 
  90 
  91 LIR_Opr LIRGenerator::result_register_for(ValueType* type, bool callee) {
  92   LIR_Opr opr;
  93   switch (type-&gt;tag()) {
  94     case intTag:     opr = FrameMap::rax_opr;          break;
  95     case objectTag:  opr = FrameMap::rax_oop_opr;      break;
  96     case longTag:    opr = FrameMap::long0_opr;        break;
<span class="line-added">  97 #ifdef _LP64</span>
<span class="line-added">  98     case floatTag:   opr = FrameMap::xmm0_float_opr;   break;</span>
<span class="line-added">  99     case doubleTag:  opr = FrameMap::xmm0_double_opr;  break;</span>
<span class="line-added"> 100 #else</span>
 101     case floatTag:   opr = UseSSE &gt;= 1 ? FrameMap::xmm0_float_opr  : FrameMap::fpu0_float_opr;  break;
 102     case doubleTag:  opr = UseSSE &gt;= 2 ? FrameMap::xmm0_double_opr : FrameMap::fpu0_double_opr;  break;
<span class="line-modified"> 103 #endif // _LP64</span>
 104     case addressTag:
 105     default: ShouldNotReachHere(); return LIR_OprFact::illegalOpr;
 106   }
 107 
 108   assert(opr-&gt;type_field() == as_OprType(as_BasicType(type)), &quot;type mismatch&quot;);
 109   return opr;
 110 }
 111 
 112 
 113 LIR_Opr LIRGenerator::rlock_byte(BasicType type) {
 114   LIR_Opr reg = new_register(T_INT);
 115   set_vreg_flag(reg, LIRGenerator::byte_reg);
 116   return reg;
 117 }
 118 
 119 
 120 void LIRGenerator::init_temps_for_substitutability_check(LIR_Opr&amp; tmp1, LIR_Opr&amp; tmp2) {
 121   // We just need one 32-bit temp register for x86/x64, to check whether both
 122   // oops have markWord::always_locked_pattern. See LIR_Assembler::emit_opSubstitutabilityCheck().
 123   // @temp = %r10d
</pre>
<hr />
<pre>
 363 
 364   set_result(x, round_item(reg));
 365 }
 366 
 367 
 368 // for  _fadd, _fmul, _fsub, _fdiv, _frem
 369 //      _dadd, _dmul, _dsub, _ddiv, _drem
 370 void LIRGenerator::do_ArithmeticOp_FPU(ArithmeticOp* x) {
 371   LIRItem left(x-&gt;x(),  this);
 372   LIRItem right(x-&gt;y(), this);
 373   LIRItem* left_arg  = &amp;left;
 374   LIRItem* right_arg = &amp;right;
 375   assert(!left.is_stack() || !right.is_stack(), &quot;can&#39;t both be memory operands&quot;);
 376   bool must_load_both = (x-&gt;op() == Bytecodes::_frem || x-&gt;op() == Bytecodes::_drem);
 377   if (left.is_register() || x-&gt;x()-&gt;type()-&gt;is_constant() || must_load_both) {
 378     left.load_item();
 379   } else {
 380     left.dont_load_item();
 381   }
 382 
<span class="line-added"> 383 #ifndef _LP64</span>
 384   // do not load right operand if it is a constant.  only 0 and 1 are
 385   // loaded because there are special instructions for loading them
 386   // without memory access (not needed for SSE2 instructions)
 387   bool must_load_right = false;
 388   if (right.is_constant()) {
 389     LIR_Const* c = right.result()-&gt;as_constant_ptr();
 390     assert(c != NULL, &quot;invalid constant&quot;);
 391     assert(c-&gt;type() == T_FLOAT || c-&gt;type() == T_DOUBLE, &quot;invalid type&quot;);
 392 
 393     if (c-&gt;type() == T_FLOAT) {
 394       must_load_right = UseSSE &lt; 1 &amp;&amp; (c-&gt;is_one_float() || c-&gt;is_zero_float());
 395     } else {
 396       must_load_right = UseSSE &lt; 2 &amp;&amp; (c-&gt;is_one_double() || c-&gt;is_zero_double());
 397     }
 398   }
<span class="line-added"> 399 #endif // !LP64</span>
 400 
 401   if (must_load_both) {
 402     // frem and drem destroy also right operand, so move it to a new register
 403     right.set_destroys_register();
 404     right.load_item();
<span class="line-modified"> 405   } else if (right.is_register()) {</span>
 406     right.load_item();
<span class="line-added"> 407 #ifndef _LP64</span>
<span class="line-added"> 408   } else if (must_load_right) {</span>
<span class="line-added"> 409     right.load_item();</span>
<span class="line-added"> 410 #endif // !LP64</span>
 411   } else {
 412     right.dont_load_item();
 413   }
 414   LIR_Opr reg = rlock(x);
 415   LIR_Opr tmp = LIR_OprFact::illegalOpr;
 416   if (x-&gt;is_strictfp() &amp;&amp; (x-&gt;op() == Bytecodes::_dmul || x-&gt;op() == Bytecodes::_ddiv)) {
 417     tmp = new_register(T_DOUBLE);
 418   }
 419 
 420 #ifdef _LP64
 421   if (x-&gt;op() == Bytecodes::_frem || x-&gt;op() == Bytecodes::_drem) {
 422     // frem and drem are implemented as a direct call into the runtime.
 423     LIRItem left(x-&gt;x(), this);
 424     LIRItem right(x-&gt;y(), this);
 425 
 426     BasicType bt = as_BasicType(x-&gt;type());
 427     BasicTypeList signature(2);
 428     signature.append(bt);
 429     signature.append(bt);
 430     CallingConvention* cc = frame_map()-&gt;c_calling_convention(&amp;signature);
</pre>
<hr />
<pre>
 801   default:                    ShouldNotReachHere();
 802   }
 803 
 804 }
 805 
 806 
 807 void LIRGenerator::do_MathIntrinsic(Intrinsic* x) {
 808   assert(x-&gt;number_of_arguments() == 1 || (x-&gt;number_of_arguments() == 2 &amp;&amp; x-&gt;id() == vmIntrinsics::_dpow), &quot;wrong type&quot;);
 809 
 810   if (x-&gt;id() == vmIntrinsics::_dexp || x-&gt;id() == vmIntrinsics::_dlog ||
 811       x-&gt;id() == vmIntrinsics::_dpow || x-&gt;id() == vmIntrinsics::_dcos ||
 812       x-&gt;id() == vmIntrinsics::_dsin || x-&gt;id() == vmIntrinsics::_dtan ||
 813       x-&gt;id() == vmIntrinsics::_dlog10) {
 814     do_LibmIntrinsic(x);
 815     return;
 816   }
 817 
 818   LIRItem value(x-&gt;argument_at(0), this);
 819 
 820   bool use_fpu = false;
<span class="line-added"> 821 #ifndef _LP64</span>
 822   if (UseSSE &lt; 2) {
 823     value.set_destroys_register();
 824   }
<span class="line-added"> 825 #endif // !LP64</span>
 826   value.load_item();
 827 
 828   LIR_Opr calc_input = value.result();
 829   LIR_Opr calc_result = rlock_result(x);
 830 
 831   LIR_Opr tmp = LIR_OprFact::illegalOpr;
 832 #ifdef _LP64
 833   if (UseAVX &gt; 2 &amp;&amp; (!VM_Version::supports_avx512vl()) &amp;&amp;
 834       (x-&gt;id() == vmIntrinsics::_dabs)) {
 835     tmp = new_register(T_DOUBLE);
 836     __ move(LIR_OprFact::doubleConst(-0.0), tmp);
 837   }
 838 #endif
 839 
 840   switch(x-&gt;id()) {
 841     case vmIntrinsics::_dabs:   __ abs  (calc_input, calc_result, tmp); break;
 842     case vmIntrinsics::_dsqrt:  __ sqrt (calc_input, calc_result, LIR_OprFact::illegalOpr); break;
 843     default:                    ShouldNotReachHere();
 844   }
 845 
</pre>
<hr />
<pre>
1594     __ volatile_move(spill, temp_double, T_LONG);
1595     __ volatile_move(temp_double, LIR_OprFact::address(address), T_LONG, info);
1596   } else {
1597     __ store(value, address, info);
1598   }
1599 }
1600 
1601 void LIRGenerator::volatile_field_load(LIR_Address* address, LIR_Opr result,
1602                                        CodeEmitInfo* info) {
1603   if (address-&gt;type() == T_LONG) {
1604     address = new LIR_Address(address-&gt;base(),
1605                               address-&gt;index(), address-&gt;scale(),
1606                               address-&gt;disp(), T_DOUBLE);
1607     // Transfer the value atomically by using FP moves.  This means
1608     // the value has to be moved between CPU and FPU registers.  In
1609     // SSE0 and SSE1 mode it has to be moved through spill slot but in
1610     // SSE2+ mode it can be moved directly.
1611     LIR_Opr temp_double = new_register(T_DOUBLE);
1612     __ volatile_move(LIR_OprFact::address(address), temp_double, T_LONG, info);
1613     __ volatile_move(temp_double, result, T_LONG);
<span class="line-added">1614 #ifndef _LP64</span>
1615     if (UseSSE &lt; 2) {
1616       // no spill slot needed in SSE2 mode because xmm-&gt;cpu register move is possible
1617       set_vreg_flag(result, must_start_in_memory);
1618     }
<span class="line-added">1619 #endif // !LP64</span>
1620   } else {
1621     __ load(address, result, info);
1622   }
1623 }
</pre>
</td>
</tr>
</table>
<center><a href="assembler_x86.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>