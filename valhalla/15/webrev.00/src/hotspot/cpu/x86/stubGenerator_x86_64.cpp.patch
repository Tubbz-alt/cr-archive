diff a/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp b/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
--- a/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
+++ b/src/hotspot/cpu/x86/stubGenerator_x86_64.cpp
@@ -4458,11 +4458,11 @@
     __ evshufi64x2(xmmdst, xmmdst, xmmdst, 0x0, Assembler::AVX_512bit);
 
   }
 
 address generate_cipherBlockChaining_decryptVectorAESCrypt() {
-    assert(VM_Version::supports_vaes(), "need AES instructions and misaligned SSE support");
+    assert(VM_Version::supports_avx512_vaes(), "need AES instructions and misaligned SSE support");
     __ align(CodeEntryAlignment);
     StubCodeMark mark(this, "StubRoutines", "cipherBlockChaining_decryptAESCrypt");
     address start = __ pc();
 
     const Register from = c_rarg0;  // source array address
@@ -5763,11 +5763,11 @@
     __ movl(nIdx, idx);
     __ addl(nIdx, newIdx);
 
     // If vectorization is enabled, check if the number of iterations is at least 64
     // If not, then go to ShifTwo processing 2 iterations
-    if (VM_Version::supports_vbmi2()) {
+    if (VM_Version::supports_avx512_vbmi2()) {
       __ cmpptr(totalNumIter, (AVX3Threshold/64));
       __ jcc(Assembler::less, ShiftTwo);
 
       if (AVX3Threshold < 16 * 64) {
         __ cmpl(totalNumIter, 16);
@@ -5887,11 +5887,11 @@
     __ lea(newArr, Address(newArr, newIdx, Address::times_4));
     __ movl(numIterTmp, totalNumIter);
 
     // If vectorization is enabled, check if the number of iterations is at least 64
     // If not, then go to ShiftTwo shifting two numbers at a time
-    if (VM_Version::supports_vbmi2()) {
+    if (VM_Version::supports_avx512_vbmi2()) {
       __ cmpl(totalNumIter, (AVX3Threshold/64));
       __ jcc(Assembler::less, ShiftTwo);
 
       if (AVX3Threshold < 16 * 64) {
         __ cmpl(totalNumIter, 16);
@@ -6622,20 +6622,20 @@
     if (UseAESIntrinsics) {
       StubRoutines::x86::_key_shuffle_mask_addr = generate_key_shuffle_mask();  // needed by the others
       StubRoutines::_aescrypt_encryptBlock = generate_aescrypt_encryptBlock();
       StubRoutines::_aescrypt_decryptBlock = generate_aescrypt_decryptBlock();
       StubRoutines::_cipherBlockChaining_encryptAESCrypt = generate_cipherBlockChaining_encryptAESCrypt();
-      if (VM_Version::supports_vaes() &&  VM_Version::supports_avx512vl() && VM_Version::supports_avx512dq() ) {
+      if (VM_Version::supports_avx512_vaes() &&  VM_Version::supports_avx512vl() && VM_Version::supports_avx512dq() ) {
         StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptVectorAESCrypt();
         StubRoutines::_electronicCodeBook_encryptAESCrypt = generate_electronicCodeBook_encryptAESCrypt();
         StubRoutines::_electronicCodeBook_decryptAESCrypt = generate_electronicCodeBook_decryptAESCrypt();
       } else {
         StubRoutines::_cipherBlockChaining_decryptAESCrypt = generate_cipherBlockChaining_decryptAESCrypt_Parallel();
       }
     }
     if (UseAESCTRIntrinsics) {
-      if (VM_Version::supports_vaes() && VM_Version::supports_avx512bw() && VM_Version::supports_avx512vl()) {
+      if (VM_Version::supports_avx512_vaes() && VM_Version::supports_avx512bw() && VM_Version::supports_avx512vl()) {
         StubRoutines::x86::_counter_mask_addr = counter_mask_addr();
         StubRoutines::_counterMode_AESCrypt = generate_counterMode_VectorAESCrypt();
       } else {
         StubRoutines::x86::_counter_shuffle_mask_addr = generate_counter_shuffle_mask();
         StubRoutines::_counterMode_AESCrypt = generate_counterMode_AESCrypt_Parallel();
@@ -6712,11 +6712,11 @@
       StubRoutines::_squareToLen = generate_squareToLen();
     }
     if (UseMulAddIntrinsic) {
       StubRoutines::_mulAdd = generate_mulAdd();
     }
-    if (VM_Version::supports_vbmi2()) {
+    if (VM_Version::supports_avx512_vbmi2()) {
       StubRoutines::_bigIntegerRightShiftWorker = generate_bigIntegerRightShift();
       StubRoutines::_bigIntegerLeftShiftWorker = generate_bigIntegerLeftShift();
     }
 #ifndef _WINDOWS
     if (UseMontgomeryMultiplyIntrinsic) {
