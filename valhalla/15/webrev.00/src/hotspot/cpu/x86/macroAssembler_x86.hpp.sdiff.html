<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/x86/macroAssembler_x86.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="register_definitions_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/x86/macroAssembler_x86.hpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 164   void load_sized_value(Register dst, Address src, size_t size_in_bytes, bool is_signed, Register dst2 = noreg);
 165   void store_sized_value(Address dst, Register src, size_t size_in_bytes, Register src2 = noreg);
 166 
 167   // Support for inc/dec with optimal instruction selection depending on value
 168 
 169   void increment(Register reg, int value = 1) { LP64_ONLY(incrementq(reg, value)) NOT_LP64(incrementl(reg, value)) ; }
 170   void decrement(Register reg, int value = 1) { LP64_ONLY(decrementq(reg, value)) NOT_LP64(decrementl(reg, value)) ; }
 171 
 172   void decrementl(Address dst, int value = 1);
 173   void decrementl(Register reg, int value = 1);
 174 
 175   void decrementq(Register reg, int value = 1);
 176   void decrementq(Address dst, int value = 1);
 177 
 178   void incrementl(Address dst, int value = 1);
 179   void incrementl(Register reg, int value = 1);
 180 
 181   void incrementq(Register reg, int value = 1);
 182   void incrementq(Address dst, int value = 1);
 183 
<span class="line-removed"> 184 #ifdef COMPILER2</span>
<span class="line-removed"> 185   // special instructions for EVEX</span>
<span class="line-removed"> 186   void setvectmask(Register dst, Register src);</span>
<span class="line-removed"> 187   void restorevectmask();</span>
<span class="line-removed"> 188 #endif</span>
<span class="line-removed"> 189 </span>
 190   // Support optimal SSE move instructions.
 191   void movflt(XMMRegister dst, XMMRegister src) {
 192     if (dst-&gt; encoding() == src-&gt;encoding()) return;
 193     if (UseXmmRegToRegMoveAll) { movaps(dst, src); return; }
 194     else                       { movss (dst, src); return; }
 195   }
 196   void movflt(XMMRegister dst, Address src) { movss(dst, src); }
 197   void movflt(XMMRegister dst, AddressLiteral src);
 198   void movflt(Address dst, XMMRegister src) { movss(dst, src); }
 199 
 200   void movdbl(XMMRegister dst, XMMRegister src) {
 201     if (dst-&gt; encoding() == src-&gt;encoding()) return;
 202     if (UseXmmRegToRegMoveAll) { movapd(dst, src); return; }
 203     else                       { movsd (dst, src); return; }
 204   }
 205 
 206   void movdbl(XMMRegister dst, AddressLiteral src);
 207 
 208   void movdbl(XMMRegister dst, Address src) {
 209     if (UseXmmLoadAndClearUpper) { movsd (dst, src); return; }
</pre>
<hr />
<pre>
 711   void verify_tlab();
 712 
 713   // Biased locking support
 714   // lock_reg and obj_reg must be loaded up with the appropriate values.
 715   // swap_reg must be rax, and is killed.
 716   // tmp_reg is optional. If it is supplied (i.e., != noreg) it will
 717   // be killed; if not supplied, push/pop will be used internally to
 718   // allocate a temporary (inefficient, avoid if possible).
 719   // Optional slow case is for implementations (interpreter and C1) which branch to
 720   // slow case directly. Leaves condition codes set for C2&#39;s Fast_Lock node.
 721   // Returns offset of first potentially-faulting instruction for null
 722   // check info (currently consumed only by C1). If
 723   // swap_reg_contains_mark is true then returns -1 as it is assumed
 724   // the calling code has already passed any potential faults.
 725   int biased_locking_enter(Register lock_reg, Register obj_reg,
 726                            Register swap_reg, Register tmp_reg,
 727                            bool swap_reg_contains_mark,
 728                            Label&amp; done, Label* slow_case = NULL,
 729                            BiasedLockingCounters* counters = NULL);
 730   void biased_locking_exit (Register obj_reg, Register temp_reg, Label&amp; done);
<span class="line-removed"> 731 #ifdef COMPILER2</span>
<span class="line-removed"> 732   // Code used by cmpFastLock and cmpFastUnlock mach instructions in .ad file.</span>
<span class="line-removed"> 733   // See full desription in macroAssembler_x86.cpp.</span>
<span class="line-removed"> 734   void fast_lock(Register obj, Register box, Register tmp,</span>
<span class="line-removed"> 735                  Register scr, Register cx1, Register cx2,</span>
<span class="line-removed"> 736                  BiasedLockingCounters* counters,</span>
<span class="line-removed"> 737                  RTMLockingCounters* rtm_counters,</span>
<span class="line-removed"> 738                  RTMLockingCounters* stack_rtm_counters,</span>
<span class="line-removed"> 739                  Metadata* method_data,</span>
<span class="line-removed"> 740                  bool use_rtm, bool profile_rtm);</span>
<span class="line-removed"> 741   void fast_unlock(Register obj, Register box, Register tmp, bool use_rtm);</span>
<span class="line-removed"> 742 #if INCLUDE_RTM_OPT</span>
<span class="line-removed"> 743   void rtm_counters_update(Register abort_status, Register rtm_counters);</span>
<span class="line-removed"> 744   void branch_on_random_using_rdtsc(Register tmp, Register scr, int count, Label&amp; brLabel);</span>
<span class="line-removed"> 745   void rtm_abort_ratio_calculation(Register tmp, Register rtm_counters_reg,</span>
<span class="line-removed"> 746                                    RTMLockingCounters* rtm_counters,</span>
<span class="line-removed"> 747                                    Metadata* method_data);</span>
<span class="line-removed"> 748   void rtm_profiling(Register abort_status_Reg, Register rtm_counters_Reg,</span>
<span class="line-removed"> 749                      RTMLockingCounters* rtm_counters, Metadata* method_data, bool profile_rtm);</span>
<span class="line-removed"> 750   void rtm_retry_lock_on_abort(Register retry_count, Register abort_status, Label&amp; retryLabel);</span>
<span class="line-removed"> 751   void rtm_retry_lock_on_busy(Register retry_count, Register box, Register tmp, Register scr, Label&amp; retryLabel);</span>
<span class="line-removed"> 752   void rtm_stack_locking(Register obj, Register tmp, Register scr,</span>
<span class="line-removed"> 753                          Register retry_on_abort_count,</span>
<span class="line-removed"> 754                          RTMLockingCounters* stack_rtm_counters,</span>
<span class="line-removed"> 755                          Metadata* method_data, bool profile_rtm,</span>
<span class="line-removed"> 756                          Label&amp; DONE_LABEL, Label&amp; IsInflated);</span>
<span class="line-removed"> 757   void rtm_inflated_locking(Register obj, Register box, Register tmp,</span>
<span class="line-removed"> 758                             Register scr, Register retry_on_busy_count,</span>
<span class="line-removed"> 759                             Register retry_on_abort_count,</span>
<span class="line-removed"> 760                             RTMLockingCounters* rtm_counters,</span>
<span class="line-removed"> 761                             Metadata* method_data, bool profile_rtm,</span>
<span class="line-removed"> 762                             Label&amp; DONE_LABEL);</span>
<span class="line-removed"> 763 #endif</span>
<span class="line-removed"> 764 #endif</span>
 765 
 766   Condition negate_condition(Condition cond);
 767 
 768   // Instructions that use AddressLiteral operands. These instruction can handle 32bit/64bit
 769   // operands. In general the names are modified to avoid hiding the instruction in Assembler
 770   // so that we don&#39;t need to implement all the varieties in the Assembler with trivial wrappers
 771   // here in MacroAssembler. The major exception to this rule is call
 772 
 773   // Arithmetics
 774 
 775 
 776   void addptr(Address dst, int32_t src) { LP64_ONLY(addq(dst, src)) NOT_LP64(addl(dst, src)) ; }
 777   void addptr(Address dst, Register src);
 778 
 779   void addptr(Register dst, Address src) { LP64_ONLY(addq(dst, src)) NOT_LP64(addl(dst, src)); }
 780   void addptr(Register dst, int32_t src);
 781   void addptr(Register dst, Register src);
 782   void addptr(Register dst, RegisterOrConstant src) {
 783     if (src.is_constant()) addptr(dst, (int) src.as_constant());
 784     else                   addptr(dst,       src.as_register());
</pre>
<hr />
<pre>
1665   // Import other mov() methods from the parent class or else
1666   // they will be hidden by the following overriding declaration.
1667   using Assembler::movdl;
1668   using Assembler::movq;
1669   void movdl(XMMRegister dst, AddressLiteral src);
1670   void movq(XMMRegister dst, AddressLiteral src);
1671 
1672   // Can push value or effective address
1673   void pushptr(AddressLiteral src);
1674 
1675   void pushptr(Address src) { LP64_ONLY(pushq(src)) NOT_LP64(pushl(src)); }
1676   void popptr(Address src) { LP64_ONLY(popq(src)) NOT_LP64(popl(src)); }
1677 
1678   void pushoop(jobject obj);
1679   void pushklass(Metadata* obj);
1680 
1681   // sign extend as need a l to ptr sized element
1682   void movl2ptr(Register dst, Address src) { LP64_ONLY(movslq(dst, src)) NOT_LP64(movl(dst, src)); }
1683   void movl2ptr(Register dst, Register src) { LP64_ONLY(movslq(dst, src)) NOT_LP64(if (dst != src) movl(dst, src)); }
1684 
<span class="line-removed">1685 #ifdef COMPILER2</span>
<span class="line-removed">1686   // Generic instructions support for use in .ad files C2 code generation</span>
<span class="line-removed">1687   void vabsnegd(int opcode, XMMRegister dst, XMMRegister src, Register scr);</span>
<span class="line-removed">1688   void vabsnegd(int opcode, XMMRegister dst, XMMRegister src, int vector_len, Register scr);</span>
<span class="line-removed">1689   void vabsnegf(int opcode, XMMRegister dst, XMMRegister src, Register scr);</span>
<span class="line-removed">1690   void vabsnegf(int opcode, XMMRegister dst, XMMRegister src, int vector_len, Register scr);</span>
<span class="line-removed">1691   void vextendbw(bool sign, XMMRegister dst, XMMRegister src, int vector_len);</span>
<span class="line-removed">1692   void vextendbw(bool sign, XMMRegister dst, XMMRegister src);</span>
<span class="line-removed">1693   void vshiftd(int opcode, XMMRegister dst, XMMRegister src);</span>
<span class="line-removed">1694   void vshiftd(int opcode, XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);</span>
<span class="line-removed">1695   void vshiftw(int opcode, XMMRegister dst, XMMRegister src);</span>
<span class="line-removed">1696   void vshiftw(int opcode, XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);</span>
<span class="line-removed">1697   void vshiftq(int opcode, XMMRegister dst, XMMRegister src);</span>
<span class="line-removed">1698   void vshiftq(int opcode, XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);</span>
<span class="line-removed">1699 #endif</span>
1700 

1701   // C2 compiled method&#39;s prolog code.
1702   void verified_entry(Compile* C, int sp_inc = 0);
1703 
1704   enum RegState {
1705     reg_readonly,
1706     reg_writable,
1707     reg_written
1708   };
1709 
1710   int store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter = true);
1711 
1712   // Unpack all value type arguments passed as oops
1713   void unpack_value_args(Compile* C, bool receiver_only);
1714   bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset);
1715   bool unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to, int&amp; to_index,
1716                            RegState reg_state[], int ret_off, int extra_stack_offset);
1717   bool pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,
1718                          VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],
1719                          int ret_off, int extra_stack_offset);
1720   void remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset);
1721 
1722   void shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,
1723                           BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,
1724                           int args_passed, int args_on_stack, VMRegPair* regs,
1725                           int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc);
1726   bool shuffle_value_args_spill(bool is_packing,  const GrowableArray&lt;SigEntry&gt;* sig_cc, int sig_cc_index,
1727                                 VMRegPair* regs_from, int from_index, int regs_from_count,
1728                                 RegState* reg_state, int sp_inc, int extra_stack_offset);
1729   VMReg spill_reg_for(VMReg reg);
1730 
1731   // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39;;
1732   // if &#39;is_large&#39; is set, do not try to produce short loop
1733   void clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only);
1734 
1735   // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
1736   void xmm_clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp);
1737 
<span class="line-removed">1738 #ifdef COMPILER2</span>
<span class="line-removed">1739   void string_indexof_char(Register str1, Register cnt1, Register ch, Register result,</span>
<span class="line-removed">1740                            XMMRegister vec1, XMMRegister vec2, XMMRegister vec3, Register tmp);</span>
<span class="line-removed">1741 </span>
<span class="line-removed">1742   // IndexOf strings.</span>
<span class="line-removed">1743   // Small strings are loaded through stack if they cross page boundary.</span>
<span class="line-removed">1744   void string_indexof(Register str1, Register str2,</span>
<span class="line-removed">1745                       Register cnt1, Register cnt2,</span>
<span class="line-removed">1746                       int int_cnt2,  Register result,</span>
<span class="line-removed">1747                       XMMRegister vec, Register tmp,</span>
<span class="line-removed">1748                       int ae);</span>
<span class="line-removed">1749 </span>
<span class="line-removed">1750   // IndexOf for constant substrings with size &gt;= 8 elements</span>
<span class="line-removed">1751   // which don&#39;t need to be loaded through stack.</span>
<span class="line-removed">1752   void string_indexofC8(Register str1, Register str2,</span>
<span class="line-removed">1753                       Register cnt1, Register cnt2,</span>
<span class="line-removed">1754                       int int_cnt2,  Register result,</span>
<span class="line-removed">1755                       XMMRegister vec, Register tmp,</span>
<span class="line-removed">1756                       int ae);</span>
<span class="line-removed">1757 </span>
<span class="line-removed">1758     // Smallest code: we don&#39;t need to load through stack,</span>
<span class="line-removed">1759     // check string tail.</span>
<span class="line-removed">1760 </span>
<span class="line-removed">1761   // helper function for string_compare</span>
<span class="line-removed">1762   void load_next_elements(Register elem1, Register elem2, Register str1, Register str2,</span>
<span class="line-removed">1763                           Address::ScaleFactor scale, Address::ScaleFactor scale1,</span>
<span class="line-removed">1764                           Address::ScaleFactor scale2, Register index, int ae);</span>
<span class="line-removed">1765   // Compare strings.</span>
<span class="line-removed">1766   void string_compare(Register str1, Register str2,</span>
<span class="line-removed">1767                       Register cnt1, Register cnt2, Register result,</span>
<span class="line-removed">1768                       XMMRegister vec1, int ae);</span>
<span class="line-removed">1769 </span>
<span class="line-removed">1770   // Search for Non-ASCII character (Negative byte value) in a byte array,</span>
<span class="line-removed">1771   // return true if it has any and false otherwise.</span>
<span class="line-removed">1772   void has_negatives(Register ary1, Register len,</span>
<span class="line-removed">1773                      Register result, Register tmp1,</span>
<span class="line-removed">1774                      XMMRegister vec1, XMMRegister vec2);</span>
<span class="line-removed">1775 </span>
<span class="line-removed">1776   // Compare char[] or byte[] arrays.</span>
<span class="line-removed">1777   void arrays_equals(bool is_array_equ, Register ary1, Register ary2,</span>
<span class="line-removed">1778                      Register limit, Register result, Register chr,</span>
<span class="line-removed">1779                      XMMRegister vec1, XMMRegister vec2, bool is_char);</span>
<span class="line-removed">1780 </span>
<span class="line-removed">1781 #endif</span>
<span class="line-removed">1782 </span>
1783   // Fill primitive arrays
1784   void generate_fill(BasicType t, bool aligned,
1785                      Register to, Register value, Register count,
1786                      Register rtmp, XMMRegister xtmp);
1787 
1788   void encode_iso_array(Register src, Register dst, Register len,
1789                         XMMRegister tmp1, XMMRegister tmp2, XMMRegister tmp3,
1790                         XMMRegister tmp4, Register tmp5, Register result);
1791 
1792 #ifdef _LP64
1793   void add2_with_carry(Register dest_hi, Register dest_lo, Register src1, Register src2);
1794   void multiply_64_x_64_loop(Register x, Register xstart, Register x_xstart,
1795                              Register y, Register y_idx, Register z,
1796                              Register carry, Register product,
1797                              Register idx, Register kdx);
1798   void multiply_add_128_x_128(Register x_xstart, Register y, Register z,
1799                               Register yz_idx, Register idx,
1800                               Register carry, Register product, int offset);
1801   void multiply_128_x_128_bmi2_loop(Register y, Register z,
1802                                     Register carry, Register carry2,
</pre>
</td>
<td>
<hr />
<pre>
 164   void load_sized_value(Register dst, Address src, size_t size_in_bytes, bool is_signed, Register dst2 = noreg);
 165   void store_sized_value(Address dst, Register src, size_t size_in_bytes, Register src2 = noreg);
 166 
 167   // Support for inc/dec with optimal instruction selection depending on value
 168 
 169   void increment(Register reg, int value = 1) { LP64_ONLY(incrementq(reg, value)) NOT_LP64(incrementl(reg, value)) ; }
 170   void decrement(Register reg, int value = 1) { LP64_ONLY(decrementq(reg, value)) NOT_LP64(decrementl(reg, value)) ; }
 171 
 172   void decrementl(Address dst, int value = 1);
 173   void decrementl(Register reg, int value = 1);
 174 
 175   void decrementq(Register reg, int value = 1);
 176   void decrementq(Address dst, int value = 1);
 177 
 178   void incrementl(Address dst, int value = 1);
 179   void incrementl(Register reg, int value = 1);
 180 
 181   void incrementq(Register reg, int value = 1);
 182   void incrementq(Address dst, int value = 1);
 183 






 184   // Support optimal SSE move instructions.
 185   void movflt(XMMRegister dst, XMMRegister src) {
 186     if (dst-&gt; encoding() == src-&gt;encoding()) return;
 187     if (UseXmmRegToRegMoveAll) { movaps(dst, src); return; }
 188     else                       { movss (dst, src); return; }
 189   }
 190   void movflt(XMMRegister dst, Address src) { movss(dst, src); }
 191   void movflt(XMMRegister dst, AddressLiteral src);
 192   void movflt(Address dst, XMMRegister src) { movss(dst, src); }
 193 
 194   void movdbl(XMMRegister dst, XMMRegister src) {
 195     if (dst-&gt; encoding() == src-&gt;encoding()) return;
 196     if (UseXmmRegToRegMoveAll) { movapd(dst, src); return; }
 197     else                       { movsd (dst, src); return; }
 198   }
 199 
 200   void movdbl(XMMRegister dst, AddressLiteral src);
 201 
 202   void movdbl(XMMRegister dst, Address src) {
 203     if (UseXmmLoadAndClearUpper) { movsd (dst, src); return; }
</pre>
<hr />
<pre>
 705   void verify_tlab();
 706 
 707   // Biased locking support
 708   // lock_reg and obj_reg must be loaded up with the appropriate values.
 709   // swap_reg must be rax, and is killed.
 710   // tmp_reg is optional. If it is supplied (i.e., != noreg) it will
 711   // be killed; if not supplied, push/pop will be used internally to
 712   // allocate a temporary (inefficient, avoid if possible).
 713   // Optional slow case is for implementations (interpreter and C1) which branch to
 714   // slow case directly. Leaves condition codes set for C2&#39;s Fast_Lock node.
 715   // Returns offset of first potentially-faulting instruction for null
 716   // check info (currently consumed only by C1). If
 717   // swap_reg_contains_mark is true then returns -1 as it is assumed
 718   // the calling code has already passed any potential faults.
 719   int biased_locking_enter(Register lock_reg, Register obj_reg,
 720                            Register swap_reg, Register tmp_reg,
 721                            bool swap_reg_contains_mark,
 722                            Label&amp; done, Label* slow_case = NULL,
 723                            BiasedLockingCounters* counters = NULL);
 724   void biased_locking_exit (Register obj_reg, Register temp_reg, Label&amp; done);


































 725 
 726   Condition negate_condition(Condition cond);
 727 
 728   // Instructions that use AddressLiteral operands. These instruction can handle 32bit/64bit
 729   // operands. In general the names are modified to avoid hiding the instruction in Assembler
 730   // so that we don&#39;t need to implement all the varieties in the Assembler with trivial wrappers
 731   // here in MacroAssembler. The major exception to this rule is call
 732 
 733   // Arithmetics
 734 
 735 
 736   void addptr(Address dst, int32_t src) { LP64_ONLY(addq(dst, src)) NOT_LP64(addl(dst, src)) ; }
 737   void addptr(Address dst, Register src);
 738 
 739   void addptr(Register dst, Address src) { LP64_ONLY(addq(dst, src)) NOT_LP64(addl(dst, src)); }
 740   void addptr(Register dst, int32_t src);
 741   void addptr(Register dst, Register src);
 742   void addptr(Register dst, RegisterOrConstant src) {
 743     if (src.is_constant()) addptr(dst, (int) src.as_constant());
 744     else                   addptr(dst,       src.as_register());
</pre>
<hr />
<pre>
1625   // Import other mov() methods from the parent class or else
1626   // they will be hidden by the following overriding declaration.
1627   using Assembler::movdl;
1628   using Assembler::movq;
1629   void movdl(XMMRegister dst, AddressLiteral src);
1630   void movq(XMMRegister dst, AddressLiteral src);
1631 
1632   // Can push value or effective address
1633   void pushptr(AddressLiteral src);
1634 
1635   void pushptr(Address src) { LP64_ONLY(pushq(src)) NOT_LP64(pushl(src)); }
1636   void popptr(Address src) { LP64_ONLY(popq(src)) NOT_LP64(popl(src)); }
1637 
1638   void pushoop(jobject obj);
1639   void pushklass(Metadata* obj);
1640 
1641   // sign extend as need a l to ptr sized element
1642   void movl2ptr(Register dst, Address src) { LP64_ONLY(movslq(dst, src)) NOT_LP64(movl(dst, src)); }
1643   void movl2ptr(Register dst, Register src) { LP64_ONLY(movslq(dst, src)) NOT_LP64(if (dst != src) movl(dst, src)); }
1644 















1645 
<span class="line-added">1646  public:</span>
1647   // C2 compiled method&#39;s prolog code.
1648   void verified_entry(Compile* C, int sp_inc = 0);
1649 
1650   enum RegState {
1651     reg_readonly,
1652     reg_writable,
1653     reg_written
1654   };
1655 
1656   int store_value_type_fields_to_buf(ciValueKlass* vk, bool from_interpreter = true);
1657 
1658   // Unpack all value type arguments passed as oops
1659   void unpack_value_args(Compile* C, bool receiver_only);
1660   bool move_helper(VMReg from, VMReg to, BasicType bt, RegState reg_state[], int ret_off, int extra_stack_offset);
1661   bool unpack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, VMReg from, VMRegPair* regs_to, int&amp; to_index,
1662                            RegState reg_state[], int ret_off, int extra_stack_offset);
1663   bool pack_value_helper(const GrowableArray&lt;SigEntry&gt;* sig, int&amp; sig_index, int vtarg_index,
1664                          VMReg to, VMRegPair* regs_from, int regs_from_count, int&amp; from_index, RegState reg_state[],
1665                          int ret_off, int extra_stack_offset);
1666   void remove_frame(int initial_framesize, bool needs_stack_repair, int sp_inc_offset);
1667 
1668   void shuffle_value_args(bool is_packing, bool receiver_only, int extra_stack_offset,
1669                           BasicType* sig_bt, const GrowableArray&lt;SigEntry&gt;* sig_cc,
1670                           int args_passed, int args_on_stack, VMRegPair* regs,
1671                           int args_passed_to, int args_on_stack_to, VMRegPair* regs_to, int sp_inc);
1672   bool shuffle_value_args_spill(bool is_packing,  const GrowableArray&lt;SigEntry&gt;* sig_cc, int sig_cc_index,
1673                                 VMRegPair* regs_from, int from_index, int regs_from_count,
1674                                 RegState* reg_state, int sp_inc, int extra_stack_offset);
1675   VMReg spill_reg_for(VMReg reg);
1676 
1677   // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39;;
1678   // if &#39;is_large&#39; is set, do not try to produce short loop
1679   void clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp, bool is_large, bool word_copy_only);
1680 
1681   // clear memory of size &#39;cnt&#39; qwords, starting at &#39;base&#39; using XMM/YMM registers
1682   void xmm_clear_mem(Register base, Register cnt, Register val, XMMRegister xtmp);
1683 













































1684   // Fill primitive arrays
1685   void generate_fill(BasicType t, bool aligned,
1686                      Register to, Register value, Register count,
1687                      Register rtmp, XMMRegister xtmp);
1688 
1689   void encode_iso_array(Register src, Register dst, Register len,
1690                         XMMRegister tmp1, XMMRegister tmp2, XMMRegister tmp3,
1691                         XMMRegister tmp4, Register tmp5, Register result);
1692 
1693 #ifdef _LP64
1694   void add2_with_carry(Register dest_hi, Register dest_lo, Register src1, Register src2);
1695   void multiply_64_x_64_loop(Register x, Register xstart, Register x_xstart,
1696                              Register y, Register y_idx, Register z,
1697                              Register carry, Register product,
1698                              Register idx, Register kdx);
1699   void multiply_add_128_x_128(Register x_xstart, Register y, Register z,
1700                               Register yz_idx, Register idx,
1701                               Register carry, Register product, int offset);
1702   void multiply_128_x_128_bmi2_loop(Register y, Register z,
1703                                     Register carry, Register carry2,
</pre>
</td>
</tr>
</table>
<center><a href="macroAssembler_x86.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="register_definitions_x86.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>