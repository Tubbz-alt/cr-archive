<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/cpu/arm/arm.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2008, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    4 //
    5 // This code is free software; you can redistribute it and/or modify it
    6 // under the terms of the GNU General Public License version 2 only, as
    7 // published by the Free Software Foundation.
    8 //
    9 // This code is distributed in the hope that it will be useful, but WITHOUT
   10 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   11 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   12 // version 2 for more details (a copy is included in the LICENSE file that
   13 // accompanied this code).
   14 //
   15 // You should have received a copy of the GNU General Public License version
   16 // 2 along with this work; if not, write to the Free Software Foundation,
   17 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   18 //
   19 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   20 // or visit www.oracle.com if you need additional information or have any
   21 // questions.
   22 //
   23 
   24 // ARM Architecture Description File
   25 
   26 //----------DEFINITION BLOCK---------------------------------------------------
   27 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
   28 // Current support includes integer values in the range [0, 0x7FFFFFFF]
   29 // Format:
   30 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
   31 // Generated Code in ad_&lt;arch&gt;.hpp
   32 //        #define  &lt;name&gt;   (&lt;expression&gt;)
   33 //        // value == &lt;int_value&gt;
   34 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
   35 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
   36 //
   37 definitions %{
   38 // The default cost (of an ALU instruction).
   39   int_def DEFAULT_COST      (    100,     100);
   40   int_def HUGE_COST         (1000000, 1000000);
   41 
   42 // Memory refs are twice as expensive as run-of-the-mill.
   43   int_def MEMORY_REF_COST   (    200, DEFAULT_COST * 2);
   44 
   45 // Branches are even more expensive.
   46   int_def BRANCH_COST       (    300, DEFAULT_COST * 3);
   47   int_def CALL_COST         (    300, DEFAULT_COST * 3);
   48 %}
   49 
   50 
   51 //----------SOURCE BLOCK-------------------------------------------------------
   52 // This is a block of C++ code which provides values, functions, and
   53 // definitions necessary in the rest of the architecture description
   54 source_hpp %{
   55 // Header information of the source block.
   56 // Method declarations/definitions which are used outside
   57 // the ad-scope can conveniently be defined here.
   58 //
   59 // To keep related declarations/definitions/uses close together,
   60 // we switch between source %{ }% and source_hpp %{ }% freely as needed.
   61 
   62 // Does destination need to be loaded in a register then passed to a
   63 // branch instruction?
   64 extern bool maybe_far_call(const CallNode *n);
   65 extern bool maybe_far_call(const MachCallNode *n);
   66 static inline bool cache_reachable() {
   67   return MacroAssembler::_cache_fully_reachable();
   68 }
   69 
   70 #define ldr_32 ldr
   71 #define str_32 str
   72 #define tst_32 tst
   73 #define teq_32 teq
   74 #if 1
   75 extern bool PrintOptoAssembly;
   76 #endif
   77 
   78 class c2 {
   79 public:
   80   static OptoRegPair return_value(int ideal_reg);
   81 };
   82 
   83 class CallStubImpl {
   84 
   85   //--------------------------------------------------------------
   86   //---&lt;  Used for optimization in Compile::Shorten_branches  &gt;---
   87   //--------------------------------------------------------------
   88 
   89  public:
   90   // Size of call trampoline stub.
   91   static uint size_call_trampoline() {
   92     return 0; // no call trampolines on this platform
   93   }
   94 
   95   // number of relocations needed by a call trampoline stub
   96   static uint reloc_call_trampoline() {
   97     return 0; // no call trampolines on this platform
   98   }
   99 };
  100 
  101 class HandlerImpl {
  102 
  103  public:
  104 
  105   static int emit_exception_handler(CodeBuffer &amp;cbuf);
  106   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
  107 
  108   static uint size_exception_handler() {
  109     return ( 3 * 4 );
  110   }
  111 
  112 
  113   static uint size_deopt_handler() {
  114     return ( 9 * 4 );
  115   }
  116 
  117 };
  118 
  119 %}
  120 
  121 source %{
  122 #define __ _masm.
  123 
  124 static FloatRegister reg_to_FloatRegister_object(int register_encoding);
  125 static Register reg_to_register_object(int register_encoding);
  126 
  127 
  128 // ****************************************************************************
  129 
  130 // REQUIRED FUNCTIONALITY
  131 
  132 // Indicate if the safepoint node needs the polling page as an input.
  133 // Since ARM does not have absolute addressing, it does.
  134 bool SafePointNode::needs_polling_address_input() {
  135   return true;
  136 }
  137 
  138 // emit an interrupt that is caught by the debugger (for debugging compiler)
  139 void emit_break(CodeBuffer &amp;cbuf) {
  140   C2_MacroAssembler _masm(&amp;cbuf);
  141   __ breakpoint();
  142 }
  143 
  144 #ifndef PRODUCT
  145 void MachBreakpointNode::format( PhaseRegAlloc *, outputStream *st ) const {
  146   st-&gt;print(&quot;TA&quot;);
  147 }
  148 #endif
  149 
  150 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  151   emit_break(cbuf);
  152 }
  153 
  154 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
  155   return MachNode::size(ra_);
  156 }
  157 
  158 
  159 void emit_nop(CodeBuffer &amp;cbuf) {
  160   C2_MacroAssembler _masm(&amp;cbuf);
  161   __ nop();
  162 }
  163 
  164 
  165 void emit_call_reloc(CodeBuffer &amp;cbuf, const MachCallNode *n, MachOper *m, RelocationHolder const&amp; rspec) {
  166   int ret_addr_offset0 = n-&gt;as_MachCall()-&gt;ret_addr_offset();
  167   int call_site_offset = cbuf.insts()-&gt;mark_off();
  168   C2_MacroAssembler _masm(&amp;cbuf);
  169   __ set_inst_mark(); // needed in emit_to_interp_stub() to locate the call
  170   address target = (address)m-&gt;method();
  171   assert(n-&gt;as_MachCall()-&gt;entry_point() == target, &quot;sanity&quot;);
  172   assert(maybe_far_call(n) == !__ reachable_from_cache(target), &quot;sanity&quot;);
  173   assert(cache_reachable() == __ cache_fully_reachable(), &quot;sanity&quot;);
  174 
  175   assert(target != NULL, &quot;need real address&quot;);
  176 
  177   int ret_addr_offset = -1;
  178   if (rspec.type() == relocInfo::runtime_call_type) {
  179     __ call(target, rspec);
  180     ret_addr_offset = __ offset();
  181   } else {
  182     // scratches Rtemp
  183     ret_addr_offset = __ patchable_call(target, rspec, true);
  184   }
  185   assert(ret_addr_offset - call_site_offset == ret_addr_offset0, &quot;fix ret_addr_offset()&quot;);
  186 }
  187 
  188 //=============================================================================
  189 // REQUIRED FUNCTIONALITY for encoding
  190 void emit_lo(CodeBuffer &amp;cbuf, int val) {  }
  191 void emit_hi(CodeBuffer &amp;cbuf, int val) {  }
  192 
  193 
  194 //=============================================================================
  195 const RegMask&amp; MachConstantBaseNode::_out_RegMask = PTR_REG_mask();
  196 
  197 int ConstantTable::calculate_table_base_offset() const {
  198   int offset = -(size() / 2);
  199   // flds, fldd: 8-bit  offset multiplied by 4: +/- 1024
  200   // ldr, ldrb : 12-bit offset:                 +/- 4096
  201   if (!Assembler::is_simm10(offset)) {
  202     offset = Assembler::min_simm10();
  203   }
  204   return offset;
  205 }
  206 
  207 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
  208 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
  209   ShouldNotReachHere();
  210 }
  211 
  212 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
  213   Compile* C = ra_-&gt;C;
  214   ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
  215   C2_MacroAssembler _masm(&amp;cbuf);
  216 
  217   Register r = as_Register(ra_-&gt;get_encode(this));
  218   CodeSection* consts_section = __ code()-&gt;consts();
  219   int consts_size = consts_section-&gt;align_at_start(consts_section-&gt;size());
  220   assert(constant_table.size() == consts_size, &quot;must be: %d == %d&quot;, constant_table.size(), consts_size);
  221 
  222   // Materialize the constant table base.
  223   address baseaddr = consts_section-&gt;start() + -(constant_table.table_base_offset());
  224   RelocationHolder rspec = internal_word_Relocation::spec(baseaddr);
  225   __ mov_address(r, baseaddr, rspec);
  226 }
  227 
  228 uint MachConstantBaseNode::size(PhaseRegAlloc*) const {
  229   return 8;
  230 }
  231 
  232 #ifndef PRODUCT
  233 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
  234   char reg[128];
  235   ra_-&gt;dump_register(this, reg);
  236   st-&gt;print(&quot;MOV_SLOW    &amp;constanttable,%s\t! constant table base&quot;, reg);
  237 }
  238 #endif
  239 
  240 #ifndef PRODUCT
  241 void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  242   Compile* C = ra_-&gt;C;
  243 
  244   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  245     st-&gt;print_cr(&quot;NOP&quot;); st-&gt;print(&quot;\t&quot;);
  246   }
  247 
  248   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();
  249   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
  250   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
  251   // Remove two words for return addr and rbp,
  252   framesize -= 2*wordSize;
  253   bangsize -= 2*wordSize;
  254 
  255   // Calls to C2R adapters often do not accept exceptional returns.
  256   // We require that their callers must bang for them.  But be careful, because
  257   // some VM calls (such as call site linkage) can use several kilobytes of
  258   // stack.  But the stack safety zone should account for that.
  259   // See bugs 4446381, 4468289, 4497237.
  260   if (C-&gt;output()-&gt;need_stack_bang(bangsize)) {
  261     st-&gt;print_cr(&quot;! stack bang (%d bytes)&quot;, bangsize); st-&gt;print(&quot;\t&quot;);
  262   }
  263   st-&gt;print_cr(&quot;PUSH   R_FP|R_LR_LR&quot;); st-&gt;print(&quot;\t&quot;);
  264   if (framesize != 0) {
  265     st-&gt;print   (&quot;SUB    R_SP, R_SP, &quot; SIZE_FORMAT,framesize);
  266   }
  267 }
  268 #endif
  269 
  270 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  271   Compile* C = ra_-&gt;C;
  272   C2_MacroAssembler _masm(&amp;cbuf);
  273 
  274   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  275     __ nop();
  276   }
  277 
  278   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();
  279   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
  280   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
  281   // Remove two words for return addr and fp,
  282   framesize -= 2*wordSize;
  283   bangsize -= 2*wordSize;
  284 
  285   // Calls to C2R adapters often do not accept exceptional returns.
  286   // We require that their callers must bang for them.  But be careful, because
  287   // some VM calls (such as call site linkage) can use several kilobytes of
  288   // stack.  But the stack safety zone should account for that.
  289   // See bugs 4446381, 4468289, 4497237.
  290   if (C-&gt;output()-&gt;need_stack_bang(bangsize)) {
  291     __ arm_stack_overflow_check(bangsize, Rtemp);
  292   }
  293 
  294   __ raw_push(FP, LR);
  295   if (framesize != 0) {
  296     __ sub_slow(SP, SP, framesize);
  297   }
  298 
  299   // offset from scratch buffer is not valid
  300   if (strcmp(cbuf.name(), &quot;Compile::Fill_buffer&quot;) == 0) {
  301     C-&gt;output()-&gt;set_frame_complete( __ offset() );
  302   }
  303 
  304   if (C-&gt;has_mach_constant_base_node()) {
  305     // NOTE: We set the table base offset here because users might be
  306     // emitted before MachConstantBaseNode.
  307     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
  308     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
  309   }
  310 }
  311 
  312 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
  313   return MachNode::size(ra_);
  314 }
  315 
  316 int MachPrologNode::reloc() const {
  317   return 10; // a large enough number
  318 }
  319 
  320 //=============================================================================
  321 #ifndef PRODUCT
  322 void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  323   Compile* C = ra_-&gt;C;
  324 
  325   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();
  326   framesize -= 2*wordSize;
  327 
  328   if (framesize != 0) {
  329     st-&gt;print(&quot;ADD    R_SP, R_SP, &quot; SIZE_FORMAT &quot;\n\t&quot;,framesize);
  330   }
  331   st-&gt;print(&quot;POP    R_FP|R_LR_LR&quot;);
  332 
  333   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
  334     st-&gt;print(&quot;\n\t&quot;);
  335     st-&gt;print(&quot;MOV    Rtemp, #PollAddr\t! Load Polling address\n\t&quot;);
  336     st-&gt;print(&quot;LDR    Rtemp,[Rtemp]\t!Poll for Safepointing&quot;);
  337   }
  338 }
  339 #endif
  340 
  341 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  342   C2_MacroAssembler _masm(&amp;cbuf);
  343   Compile* C = ra_-&gt;C;
  344 
  345   size_t framesize = C-&gt;output()-&gt;frame_size_in_bytes();
  346   framesize -= 2*wordSize;
  347   if (framesize != 0) {
  348     __ add_slow(SP, SP, framesize);
  349   }
  350   __ raw_pop(FP, LR);
  351 
  352   // If this does safepoint polling, then do it here
  353   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
  354     __ read_polling_page(Rtemp, relocInfo::poll_return_type);
  355   }
  356 }
  357 
  358 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  359   return MachNode::size(ra_);
  360 }
  361 
  362 int MachEpilogNode::reloc() const {
  363   return 16; // a large enough number
  364 }
  365 
  366 const Pipeline * MachEpilogNode::pipeline() const {
  367   return MachNode::pipeline_class();
  368 }
  369 
  370 int MachEpilogNode::safepoint_offset() const {
  371   assert( do_polling(), &quot;no return for this epilog node&quot;);
  372   //  return MacroAssembler::size_of_sethi(os::get_polling_page());
  373   Unimplemented();
  374   return 0;
  375 }
  376 
  377 //=============================================================================
  378 
  379 // Figure out which register class each belongs in: rc_int, rc_float, rc_stack
  380 enum RC { rc_bad, rc_int, rc_float, rc_stack };
  381 static enum RC rc_class( OptoReg::Name reg ) {
  382   if (!OptoReg::is_valid(reg)) return rc_bad;
  383   if (OptoReg::is_stack(reg)) return rc_stack;
  384   VMReg r = OptoReg::as_VMReg(reg);
  385   if (r-&gt;is_Register()) return rc_int;
  386   assert(r-&gt;is_FloatRegister(), &quot;must be&quot;);
  387   return rc_float;
  388 }
  389 
  390 static inline bool is_iRegLd_memhd(OptoReg::Name src_first, OptoReg::Name src_second, int offset) {
  391   int rlo = Matcher::_regEncode[src_first];
  392   int rhi = Matcher::_regEncode[src_second];
  393   if (!((rlo&amp;1)==0 &amp;&amp; (rlo+1 == rhi))) {
  394     tty-&gt;print_cr(&quot;CAUGHT BAD LDRD/STRD&quot;);
  395   }
  396   return (rlo&amp;1)==0 &amp;&amp; (rlo+1 == rhi) &amp;&amp; is_memoryHD(offset);
  397 }
  398 
  399 uint MachSpillCopyNode::implementation( CodeBuffer *cbuf,
  400                                         PhaseRegAlloc *ra_,
  401                                         bool do_size,
  402                                         outputStream* st ) const {
  403   // Get registers to move
  404   OptoReg::Name src_second = ra_-&gt;get_reg_second(in(1));
  405   OptoReg::Name src_first = ra_-&gt;get_reg_first(in(1));
  406   OptoReg::Name dst_second = ra_-&gt;get_reg_second(this );
  407   OptoReg::Name dst_first = ra_-&gt;get_reg_first(this );
  408 
  409   enum RC src_second_rc = rc_class(src_second);
  410   enum RC src_first_rc = rc_class(src_first);
  411   enum RC dst_second_rc = rc_class(dst_second);
  412   enum RC dst_first_rc = rc_class(dst_first);
  413 
  414   assert( OptoReg::is_valid(src_first) &amp;&amp; OptoReg::is_valid(dst_first), &quot;must move at least 1 register&quot; );
  415 
  416   // Generate spill code!
  417   int size = 0;
  418 
  419   if (src_first == dst_first &amp;&amp; src_second == dst_second)
  420     return size;            // Self copy, no move
  421 
  422 #ifdef TODO
  423   if (bottom_type()-&gt;isa_vect() != NULL) {
  424   }
  425 #endif
  426 
  427   // Shared code does not expect instruction set capability based bailouts here.
  428   // Handle offset unreachable bailout with minimal change in shared code.
  429   // Bailout only for real instruction emit.
  430   // This requires a single comment change in shared code. ( see output.cpp &quot;Normal&quot; instruction case )
  431 
  432   C2_MacroAssembler _masm(cbuf);
  433 
  434   // --------------------------------------
  435   // Check for mem-mem move.  Load into unused float registers and fall into
  436   // the float-store case.
  437   if (src_first_rc == rc_stack &amp;&amp; dst_first_rc == rc_stack) {
  438     int offset = ra_-&gt;reg2offset(src_first);
  439     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  440       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  441       return 0;
  442     } else {
  443       if (src_second_rc != rc_bad) {
  444         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  445         src_first     = OptoReg::Name(R_mem_copy_lo_num);
  446         src_second    = OptoReg::Name(R_mem_copy_hi_num);
  447         src_first_rc  = rc_float;
  448         src_second_rc = rc_float;
  449         if (cbuf) {
  450           __ ldr_double(Rmemcopy, Address(SP, offset));
  451         } else if (!do_size) {
  452           st-&gt;print(LDR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  453         }
  454       } else {
  455         src_first     = OptoReg::Name(R_mem_copy_lo_num);
  456         src_first_rc  = rc_float;
  457         if (cbuf) {
  458           __ ldr_float(Rmemcopy, Address(SP, offset));
  459         } else if (!do_size) {
  460           st-&gt;print(LDR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  461         }
  462       }
  463       size += 4;
  464     }
  465   }
  466 
  467   if (src_second_rc == rc_stack &amp;&amp; dst_second_rc == rc_stack) {
  468     Unimplemented();
  469   }
  470 
  471   // --------------------------------------
  472   // Check for integer reg-reg copy
  473   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_int) {
  474     // Else normal reg-reg copy
  475     assert( src_second != dst_first, &quot;smashed second before evacuating it&quot; );
  476     if (cbuf) {
  477       __ mov(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]));
  478 #ifndef PRODUCT
  479     } else if (!do_size) {
  480       st-&gt;print(&quot;MOV    R_%s, R_%s\t# spill&quot;,
  481                 Matcher::regName[dst_first],
  482                 Matcher::regName[src_first]);
  483 #endif
  484     }
  485     size += 4;
  486   }
  487 
  488   // Check for integer store
  489   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_stack) {
  490     int offset = ra_-&gt;reg2offset(dst_first);
  491     if (cbuf &amp;&amp; !is_memoryI(offset)) {
  492       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  493       return 0;
  494     } else {
  495       if (src_second_rc != rc_bad &amp;&amp; is_iRegLd_memhd(src_first, src_second, offset)) {
  496         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  497         if (cbuf) {
  498           __ str_64(reg_to_register_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  499 #ifndef PRODUCT
  500         } else if (!do_size) {
  501           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  502           st-&gt;print(STR_64 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first), offset);
  503 #endif
  504         }
  505         return size + 4;
  506       } else {
  507         if (cbuf) {
  508           __ str_32(reg_to_register_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  509 #ifndef PRODUCT
  510         } else if (!do_size) {
  511           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  512           st-&gt;print(STR_32 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first), offset);
  513 #endif
  514         }
  515       }
  516     }
  517     size += 4;
  518   }
  519 
  520   // Check for integer load
  521   if (dst_first_rc == rc_int &amp;&amp; src_first_rc == rc_stack) {
  522     int offset = ra_-&gt;reg2offset(src_first);
  523     if (cbuf &amp;&amp; !is_memoryI(offset)) {
  524       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  525       return 0;
  526     } else {
  527       if (src_second_rc != rc_bad &amp;&amp; is_iRegLd_memhd(dst_first, dst_second, offset)) {
  528         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  529         if (cbuf) {
  530           __ ldr_64(reg_to_register_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  531 #ifndef PRODUCT
  532         } else if (!do_size) {
  533           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  534           st-&gt;print(LDR_64 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first), offset);
  535 #endif
  536         }
  537         return size + 4;
  538       } else {
  539         if (cbuf) {
  540           __ ldr_32(reg_to_register_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  541 #ifndef PRODUCT
  542         } else if (!do_size) {
  543           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  544           st-&gt;print(LDR_32 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first), offset);
  545 #endif
  546         }
  547       }
  548     }
  549     size += 4;
  550   }
  551 
  552   // Check for float reg-reg copy
  553   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_float) {
  554     if (src_second_rc != rc_bad) {
  555       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  556       if (cbuf) {
  557       __ mov_double(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  558 #ifndef PRODUCT
  559       } else if (!do_size) {
  560         st-&gt;print(MOV_DOUBLE &quot;    R_%s, R_%s\t# spill&quot;,
  561                   Matcher::regName[dst_first],
  562                   Matcher::regName[src_first]);
  563 #endif
  564       }
  565       return 4;
  566     }
  567     if (cbuf) {
  568       __ mov_float(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  569 #ifndef PRODUCT
  570     } else if (!do_size) {
  571       st-&gt;print(MOV_FLOAT &quot;    R_%s, R_%s\t# spill&quot;,
  572                 Matcher::regName[dst_first],
  573                 Matcher::regName[src_first]);
  574 #endif
  575     }
  576     size = 4;
  577   }
  578 
  579   // Check for float store
  580   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_stack) {
  581     int offset = ra_-&gt;reg2offset(dst_first);
  582     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  583       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  584       return 0;
  585     } else {
  586       // Further check for aligned-adjacent pair, so we can use a double store
  587       if (src_second_rc != rc_bad) {
  588         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers and stack slots must be aligned/contiguous&quot;);
  589         if (cbuf) {
  590           __ str_double(reg_to_FloatRegister_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  591 #ifndef PRODUCT
  592         } else if (!do_size) {
  593           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  594           st-&gt;print(STR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  595 #endif
  596         }
  597         return size + 4;
  598       } else {
  599         if (cbuf) {
  600           __ str_float(reg_to_FloatRegister_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  601 #ifndef PRODUCT
  602         } else if (!do_size) {
  603           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  604           st-&gt;print(STR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  605 #endif
  606         }
  607       }
  608     }
  609     size += 4;
  610   }
  611 
  612   // Check for float load
  613   if (dst_first_rc == rc_float &amp;&amp; src_first_rc == rc_stack) {
  614     int offset = ra_-&gt;reg2offset(src_first);
  615     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  616       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  617       return 0;
  618     } else {
  619       // Further check for aligned-adjacent pair, so we can use a double store
  620       if (src_second_rc != rc_bad) {
  621         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers and stack slots must be aligned/contiguous&quot;);
  622         if (cbuf) {
  623           __ ldr_double(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  624 #ifndef PRODUCT
  625         } else if (!do_size) {
  626           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  627           st-&gt;print(LDR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first),offset);
  628 #endif
  629         }
  630         return size + 4;
  631       } else {
  632         if (cbuf) {
  633           __ ldr_float(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  634 #ifndef PRODUCT
  635         } else if (!do_size) {
  636           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  637           st-&gt;print(LDR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first),offset);
  638 #endif
  639         }
  640       }
  641     }
  642     size += 4;
  643   }
  644 
  645   // check for int reg -&gt; float reg move
  646   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_float) {
  647     // Further check for aligned-adjacent pair, so we can use a single instruction
  648     if (src_second_rc != rc_bad) {
  649       assert((dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  650       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  651       assert(src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_float, &quot;unsupported&quot;);
  652       if (cbuf) {
  653         __ fmdrr(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]), reg_to_register_object(Matcher::_regEncode[src_second]));
  654 #ifndef PRODUCT
  655       } else if (!do_size) {
  656         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  657         st-&gt;print(&quot;FMDRR   R_%s, R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first), OptoReg::regname(src_second));
  658 #endif
  659       }
  660       return size + 4;
  661     } else {
  662       if (cbuf) {
  663         __ fmsr(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]));
  664 #ifndef PRODUCT
  665       } else if (!do_size) {
  666         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  667         st-&gt;print(FMSR &quot;   R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first));
  668 #endif
  669       }
  670       size += 4;
  671     }
  672   }
  673 
  674   // check for float reg -&gt; int reg move
  675   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_int) {
  676     // Further check for aligned-adjacent pair, so we can use a single instruction
  677     if (src_second_rc != rc_bad) {
  678       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  679       assert((dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  680       assert(src_second_rc == rc_float &amp;&amp; dst_second_rc == rc_int, &quot;unsupported&quot;);
  681       if (cbuf) {
  682         __ fmrrd(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[dst_second]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  683 #ifndef PRODUCT
  684       } else if (!do_size) {
  685         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  686         st-&gt;print(&quot;FMRRD   R_%s, R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(dst_second), OptoReg::regname(src_first));
  687 #endif
  688       }
  689       return size + 4;
  690     } else {
  691       if (cbuf) {
  692         __ fmrs(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  693 #ifndef PRODUCT
  694       } else if (!do_size) {
  695         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  696         st-&gt;print(FMRS &quot;   R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first));
  697 #endif
  698       }
  699       size += 4;
  700     }
  701   }
  702 
  703   // --------------------------------------------------------------------
  704   // Check for hi bits still needing moving.  Only happens for misaligned
  705   // arguments to native calls.
  706   if (src_second == dst_second)
  707     return size;               // Self copy; no move
  708   assert( src_second_rc != rc_bad &amp;&amp; dst_second_rc != rc_bad, &quot;src_second &amp; dst_second cannot be Bad&quot; );
  709 
  710   // Check for integer reg-reg copy.  Hi bits are stuck up in the top
  711   // 32-bits of a 64-bit register, but are needed in low bits of another
  712   // register (else it&#39;s a hi-bits-to-hi-bits copy which should have
  713   // happened already as part of a 64-bit move)
  714   if (src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_int) {
  715     if (cbuf) {
  716       __ mov(reg_to_register_object(Matcher::_regEncode[dst_second]), reg_to_register_object(Matcher::_regEncode[src_second]));
  717 #ifndef PRODUCT
  718     } else if (!do_size) {
  719       if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  720       st-&gt;print(&quot;MOV    R_%s, R_%s\t# spill high&quot;,
  721                 Matcher::regName[dst_second],
  722                 Matcher::regName[src_second]);
  723 #endif
  724     }
  725     return size+4;
  726   }
  727 
  728   // Check for high word integer store
  729   if (src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_stack) {
  730     int offset = ra_-&gt;reg2offset(dst_second);
  731 
  732     if (cbuf &amp;&amp; !is_memoryP(offset)) {
  733       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  734       return 0;
  735     } else {
  736       if (cbuf) {
  737         __ str(reg_to_register_object(Matcher::_regEncode[src_second]), Address(SP, offset));
  738 #ifndef PRODUCT
  739       } else if (!do_size) {
  740         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  741         st-&gt;print(&quot;STR   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_second), offset);
  742 #endif
  743       }
  744     }
  745     return size + 4;
  746   }
  747 
  748   // Check for high word integer load
  749   if (dst_second_rc == rc_int &amp;&amp; src_second_rc == rc_stack) {
  750     int offset = ra_-&gt;reg2offset(src_second);
  751     if (cbuf &amp;&amp; !is_memoryP(offset)) {
  752       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  753       return 0;
  754     } else {
  755       if (cbuf) {
  756         __ ldr(reg_to_register_object(Matcher::_regEncode[dst_second]), Address(SP, offset));
  757 #ifndef PRODUCT
  758       } else if (!do_size) {
  759         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  760         st-&gt;print(&quot;LDR   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_second), offset);
  761 #endif
  762       }
  763     }
  764     return size + 4;
  765   }
  766 
  767   Unimplemented();
  768   return 0; // Mute compiler
  769 }
  770 
  771 #ifndef PRODUCT
  772 void MachSpillCopyNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  773   implementation( NULL, ra_, false, st );
  774 }
  775 #endif
  776 
  777 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  778   implementation( &amp;cbuf, ra_, false, NULL );
  779 }
  780 
  781 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
  782   return implementation( NULL, ra_, true, NULL );
  783 }
  784 
  785 //=============================================================================
  786 #ifndef PRODUCT
  787 void MachNopNode::format( PhaseRegAlloc *, outputStream *st ) const {
  788   st-&gt;print(&quot;NOP \t# %d bytes pad for loops and calls&quot;, 4 * _count);
  789 }
  790 #endif
  791 
  792 void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc * ) const {
  793   C2_MacroAssembler _masm(&amp;cbuf);
  794   for(int i = 0; i &lt; _count; i += 1) {
  795     __ nop();
  796   }
  797 }
  798 
  799 uint MachNopNode::size(PhaseRegAlloc *ra_) const {
  800   return 4 * _count;
  801 }
  802 
  803 
  804 //=============================================================================
  805 #ifndef PRODUCT
  806 void BoxLockNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  807   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
  808   int reg = ra_-&gt;get_reg_first(this);
  809   st-&gt;print(&quot;ADD    %s,R_SP+#%d&quot;,Matcher::regName[reg], offset);
  810 }
  811 #endif
  812 
  813 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  814   C2_MacroAssembler _masm(&amp;cbuf);
  815   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
  816   int reg = ra_-&gt;get_encode(this);
  817   Register dst = reg_to_register_object(reg);
  818 
  819   if (is_aimm(offset)) {
  820     __ add(dst, SP, offset);
  821   } else {
  822     __ mov_slow(dst, offset);
  823     __ add(dst, SP, dst);
  824   }
  825 }
  826 
  827 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
  828   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
  829   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
  830   return ra_-&gt;C-&gt;output()-&gt;scratch_emit_size(this);
  831 }
  832 
  833 //=============================================================================
  834 #ifndef PRODUCT
  835 #define R_RTEMP &quot;R_R12&quot;
  836 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  837   st-&gt;print_cr(&quot;\nUEP:&quot;);
  838   if (UseCompressedClassPointers) {
  839     st-&gt;print_cr(&quot;\tLDR_w &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  840     st-&gt;print_cr(&quot;\tdecode_klass &quot; R_RTEMP);
  841   } else {
  842     st-&gt;print_cr(&quot;\tLDR   &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  843   }
  844   st-&gt;print_cr(&quot;\tCMP   &quot; R_RTEMP &quot;,R_R8&quot; );
  845   st-&gt;print   (&quot;\tB.NE  SharedRuntime::handle_ic_miss_stub&quot;);
  846 }
  847 #endif
  848 
  849 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  850   C2_MacroAssembler _masm(&amp;cbuf);
  851   Register iCache  = reg_to_register_object(Matcher::inline_cache_reg_encode());
  852   assert(iCache == Ricklass, &quot;should be&quot;);
  853   Register receiver = R0;
  854 
  855   __ load_klass(Rtemp, receiver);
  856   __ cmp(Rtemp, iCache);
  857   __ jump(SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type, noreg, ne);
  858 }
  859 
  860 uint MachUEPNode::size(PhaseRegAlloc *ra_) const {
  861   return MachNode::size(ra_);
  862 }
  863 
  864 
  865 //=============================================================================
  866 
  867 // Emit exception handler code.
  868 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf) {
  869   C2_MacroAssembler _masm(&amp;cbuf);
  870 
  871   address base = __ start_a_stub(size_exception_handler());
  872   if (base == NULL) {
  873     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
  874     return 0;  // CodeBuffer::expand failed
  875   }
  876 
  877   int offset = __ offset();
  878 
  879   // OK to trash LR, because exception blob will kill it
  880   __ jump(OptoRuntime::exception_blob()-&gt;entry_point(), relocInfo::runtime_call_type, LR_tmp);
  881 
  882   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
  883 
  884   __ end_a_stub();
  885 
  886   return offset;
  887 }
  888 
  889 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf) {
  890   // Can&#39;t use any of the current frame&#39;s registers as we may have deopted
  891   // at a poll and everything can be live.
  892   C2_MacroAssembler _masm(&amp;cbuf);
  893 
  894   address base = __ start_a_stub(size_deopt_handler());
  895   if (base == NULL) {
  896     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
  897     return 0;  // CodeBuffer::expand failed
  898   }
  899 
  900   int offset = __ offset();
  901   address deopt_pc = __ pc();
  902 
  903   __ sub(SP, SP, wordSize); // make room for saved PC
  904   __ push(LR); // save LR that may be live when we get here
  905   __ mov_relative_address(LR, deopt_pc);
  906   __ str(LR, Address(SP, wordSize)); // save deopt PC
  907   __ pop(LR); // restore LR
  908   __ jump(SharedRuntime::deopt_blob()-&gt;unpack(), relocInfo::runtime_call_type, noreg);
  909 
  910   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
  911 
  912   __ end_a_stub();
  913   return offset;
  914 }
  915 
  916 const bool Matcher::match_rule_supported(int opcode) {
  917   if (!has_match_rule(opcode))
  918     return false;
  919 
  920   switch (opcode) {
  921   case Op_PopCountI:
  922   case Op_PopCountL:
  923     if (!UsePopCountInstruction)
  924       return false;
  925     break;
  926   case Op_LShiftCntV:
  927   case Op_RShiftCntV:
  928   case Op_AddVB:
  929   case Op_AddVS:
  930   case Op_AddVI:
  931   case Op_AddVL:
  932   case Op_SubVB:
  933   case Op_SubVS:
  934   case Op_SubVI:
  935   case Op_SubVL:
  936   case Op_MulVS:
  937   case Op_MulVI:
  938   case Op_LShiftVB:
  939   case Op_LShiftVS:
  940   case Op_LShiftVI:
  941   case Op_LShiftVL:
  942   case Op_RShiftVB:
  943   case Op_RShiftVS:
  944   case Op_RShiftVI:
  945   case Op_RShiftVL:
  946   case Op_URShiftVB:
  947   case Op_URShiftVS:
  948   case Op_URShiftVI:
  949   case Op_URShiftVL:
  950   case Op_AndV:
  951   case Op_OrV:
  952   case Op_XorV:
  953     return VM_Version::has_simd();
  954   case Op_LoadVector:
  955   case Op_StoreVector:
  956   case Op_AddVF:
  957   case Op_SubVF:
  958   case Op_MulVF:
  959     return VM_Version::has_vfp() || VM_Version::has_simd();
  960   case Op_AddVD:
  961   case Op_SubVD:
  962   case Op_MulVD:
  963   case Op_DivVF:
  964   case Op_DivVD:
  965     return VM_Version::has_vfp();
  966   }
  967 
  968   return true;  // Per default match rules are supported.
  969 }
  970 
  971 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
  972 
  973   // TODO
  974   // identify extra cases that we might want to provide match rules for
  975   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
  976   bool ret_value = match_rule_supported(opcode);
  977   // Add rules here.
  978 
  979   return ret_value;  // Per default match rules are supported.
  980 }
  981 
  982 const bool Matcher::has_predicated_vectors(void) {
  983   return false;
  984 }
  985 
  986 const int Matcher::float_pressure(int default_pressure_threshold) {
  987   return default_pressure_threshold;
  988 }
  989 
  990 int Matcher::regnum_to_fpu_offset(int regnum) {
  991   return regnum - 32; // The FP registers are in the second chunk
  992 }
  993 
  994 // Vector width in bytes
  995 const int Matcher::vector_width_in_bytes(BasicType bt) {
  996   return MaxVectorSize;
  997 }
  998 
  999 // Vector ideal reg corresponding to specified size in bytes
 1000 const uint Matcher::vector_ideal_reg(int size) {
 1001   assert(MaxVectorSize &gt;= size, &quot;&quot;);
 1002   switch(size) {
 1003     case  8: return Op_VecD;
 1004     case 16: return Op_VecX;
 1005   }
 1006   ShouldNotReachHere();
 1007   return 0;
 1008 }
 1009 
 1010 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 1011   return vector_ideal_reg(size);
 1012 }
 1013 
 1014 // Limits on vector size (number of elements) loaded into vector.
 1015 const int Matcher::max_vector_size(const BasicType bt) {
 1016   assert(is_java_primitive(bt), &quot;only primitive type vectors&quot;);
 1017   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 1018 }
 1019 
 1020 const int Matcher::min_vector_size(const BasicType bt) {
 1021   assert(is_java_primitive(bt), &quot;only primitive type vectors&quot;);
 1022   return 8/type2aelembytes(bt);
 1023 }
 1024 
 1025 // ARM doesn&#39;t support misaligned vectors store/load.
 1026 const bool Matcher::misaligned_vectors_ok() {
 1027   return false;
 1028 }
 1029 
 1030 // ARM doesn&#39;t support AES intrinsics
 1031 const bool Matcher::pass_original_key_for_aes() {
 1032   return false;
 1033 }
 1034 
 1035 const bool Matcher::convL2FSupported(void) {
 1036   return false;
 1037 }
 1038 
 1039 // Is this branch offset short enough that a short branch can be used?
 1040 //
 1041 // NOTE: If the platform does not provide any short branch variants, then
 1042 //       this method should return false for offset 0.
 1043 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 1044   // The passed offset is relative to address of the branch.
 1045   // On ARM a branch displacement is calculated relative to address
 1046   // of the branch + 8.
 1047   //
 1048   // offset -= 8;
 1049   // return (Assembler::is_simm24(offset));
 1050   return false;
 1051 }
 1052 
 1053 const bool Matcher::isSimpleConstant64(jlong value) {
 1054   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 1055   return false;
 1056 }
 1057 
 1058 // No scaling for the parameter the ClearArray node.
 1059 const bool Matcher::init_array_count_is_in_bytes = true;
 1060 
 1061 // Needs 2 CMOV&#39;s for longs.
 1062 const int Matcher::long_cmove_cost() { return 2; }
 1063 
 1064 // CMOVF/CMOVD are expensive on ARM.
 1065 const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }
 1066 
 1067 // Does the CPU require late expand (see block.cpp for description of late expand)?
 1068 const bool Matcher::require_postalloc_expand = false;
 1069 
 1070 // Do we need to mask the count passed to shift instructions or does
 1071 // the cpu only look at the lower 5/6 bits anyway?
 1072 // FIXME: does this handle vector shifts as well?
 1073 const bool Matcher::need_masked_shift_count = true;
 1074 
 1075 const bool Matcher::convi2l_type_required = true;
 1076 
 1077 // No support for generic vector operands.
 1078 const bool Matcher::supports_generic_vector_operands  = false;
 1079 
 1080 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 1081   ShouldNotReachHere(); // generic vector operands not supported
 1082   return NULL;
 1083 }
 1084 
 1085 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 1086   ShouldNotReachHere();  // generic vector operands not supported
 1087   return false;
 1088 }
 1089 
 1090 bool Matcher::is_generic_vector(MachOper* opnd)  {
 1091   ShouldNotReachHere();  // generic vector operands not supported
 1092   return false;
 1093 }
 1094 
 1095 // Should the Matcher clone shifts on addressing modes, expecting them
 1096 // to be subsumed into complex addressing expressions or compute them
 1097 // into registers?
 1098 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 1099   return clone_base_plus_offset_address(m, mstack, address_visited);
 1100 }
 1101 
 1102 void Compile::reshape_address(AddPNode* addp) {
 1103 }
 1104 
 1105 bool Matcher::narrow_oop_use_complex_address() {
 1106   NOT_LP64(ShouldNotCallThis());
 1107   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1108   return false;
 1109 }
 1110 
 1111 bool Matcher::narrow_klass_use_complex_address() {
 1112   NOT_LP64(ShouldNotCallThis());
 1113   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1114   return false;
 1115 }
 1116 
 1117 bool Matcher::const_oop_prefer_decode() {
 1118   NOT_LP64(ShouldNotCallThis());
 1119   return true;
 1120 }
 1121 
 1122 bool Matcher::const_klass_prefer_decode() {
 1123   NOT_LP64(ShouldNotCallThis());
 1124   return true;
 1125 }
 1126 
 1127 // Is it better to copy float constants, or load them directly from memory?
 1128 // Intel can load a float constant from a direct address, requiring no
 1129 // extra registers.  Most RISCs will have to materialize an address into a
 1130 // register first, so they would do better to copy the constant from stack.
 1131 const bool Matcher::rematerialize_float_constants = false;
 1132 
 1133 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1134 // needed.  Else we split the double into 2 integer pieces and move it
 1135 // piece-by-piece.  Only happens when passing doubles into C code as the
 1136 // Java calling convention forces doubles to be aligned.
 1137 const bool Matcher::misaligned_doubles_ok = false;
 1138 
 1139 // No-op on ARM.
 1140 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1141 }
 1142 
 1143 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 1144 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1145 
 1146 // Are floats converted to double when stored to stack during deoptimization?
 1147 // ARM does not handle callee-save floats.
 1148 bool Matcher::float_in_double() {
 1149   return false;
 1150 }
 1151 
 1152 // Do ints take an entire long register or just half?
 1153 // Note that we if-def off of _LP64.
 1154 // The relevant question is how the int is callee-saved.  In _LP64
 1155 // the whole long is written but de-opt&#39;ing will have to extract
 1156 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1157 #ifdef _LP64
 1158 const bool Matcher::int_in_long = true;
 1159 #else
 1160 const bool Matcher::int_in_long = false;
 1161 #endif
 1162 
 1163 // Return whether or not this register is ever used as an argument.  This
 1164 // function is used on startup to build the trampoline stubs in generateOptoStub.
 1165 // Registers not mentioned will be killed by the VM call in the trampoline, and
 1166 // arguments in those registers not be available to the callee.
 1167 bool Matcher::can_be_java_arg( int reg ) {
 1168   if (reg == R_R0_num ||
 1169       reg == R_R1_num ||
 1170       reg == R_R2_num ||
 1171       reg == R_R3_num) return true;
 1172 
 1173   if (reg &gt;= R_S0_num &amp;&amp;
 1174       reg &lt;= R_S13_num) return true;
 1175   return false;
 1176 }
 1177 
 1178 bool Matcher::is_spillable_arg( int reg ) {
 1179   return can_be_java_arg(reg);
 1180 }
 1181 
 1182 bool Matcher::use_asm_for_ldiv_by_con( jlong divisor ) {
 1183   return false;
 1184 }
 1185 
 1186 // Register for DIVI projection of divmodI
 1187 RegMask Matcher::divI_proj_mask() {
 1188   ShouldNotReachHere();
 1189   return RegMask();
 1190 }
 1191 
 1192 // Register for MODI projection of divmodI
 1193 RegMask Matcher::modI_proj_mask() {
 1194   ShouldNotReachHere();
 1195   return RegMask();
 1196 }
 1197 
 1198 // Register for DIVL projection of divmodL
 1199 RegMask Matcher::divL_proj_mask() {
 1200   ShouldNotReachHere();
 1201   return RegMask();
 1202 }
 1203 
 1204 // Register for MODL projection of divmodL
 1205 RegMask Matcher::modL_proj_mask() {
 1206   ShouldNotReachHere();
 1207   return RegMask();
 1208 }
 1209 
 1210 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 1211   return FP_REGP_mask();
 1212 }
 1213 
 1214 bool maybe_far_call(const CallNode *n) {
 1215   return !MacroAssembler::_reachable_from_cache(n-&gt;as_Call()-&gt;entry_point());
 1216 }
 1217 
 1218 bool maybe_far_call(const MachCallNode *n) {
 1219   return !MacroAssembler::_reachable_from_cache(n-&gt;as_MachCall()-&gt;entry_point());
 1220 }
 1221 
 1222 %}
 1223 
 1224 //----------ENCODING BLOCK-----------------------------------------------------
 1225 // This block specifies the encoding classes used by the compiler to output
 1226 // byte streams.  Encoding classes are parameterized macros used by
 1227 // Machine Instruction Nodes in order to generate the bit encoding of the
 1228 // instruction.  Operands specify their base encoding interface with the
 1229 // interface keyword.  There are currently supported four interfaces,
 1230 // REG_INTER, CONST_INTER, MEMORY_INTER, &amp; COND_INTER.  REG_INTER causes an
 1231 // operand to generate a function which returns its register number when
 1232 // queried.   CONST_INTER causes an operand to generate a function which
 1233 // returns the value of the constant when queried.  MEMORY_INTER causes an
 1234 // operand to generate four functions which return the Base Register, the
 1235 // Index Register, the Scale Value, and the Offset Value of the operand when
 1236 // queried.  COND_INTER causes an operand to generate six functions which
 1237 // return the encoding code (ie - encoding bits for the instruction)
 1238 // associated with each basic boolean condition for a conditional instruction.
 1239 //
 1240 // Instructions specify two basic values for encoding.  Again, a function
 1241 // is available to check if the constant displacement is an oop. They use the
 1242 // ins_encode keyword to specify their encoding classes (which must be
 1243 // a sequence of enc_class names, and their parameters, specified in
 1244 // the encoding block), and they use the
 1245 // opcode keyword to specify, in order, their primary, secondary, and
 1246 // tertiary opcode.  Only the opcode sections which a particular instruction
 1247 // needs for encoding need to be specified.
 1248 encode %{
 1249   enc_class call_epilog %{
 1250     // nothing
 1251   %}
 1252 
 1253   enc_class Java_To_Runtime (method meth) %{
 1254     // CALL directly to the runtime
 1255     emit_call_reloc(cbuf, as_MachCall(), $meth, runtime_call_Relocation::spec());
 1256   %}
 1257 
 1258   enc_class Java_Static_Call (method meth) %{
 1259     // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
 1260     // who we intended to call.
 1261 
 1262     if ( !_method) {
 1263       emit_call_reloc(cbuf, as_MachCall(), $meth, runtime_call_Relocation::spec());
 1264     } else {
 1265       int method_index = resolved_method_index(cbuf);
 1266       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 1267                                                   : static_call_Relocation::spec(method_index);
 1268       emit_call_reloc(cbuf, as_MachCall(), $meth, rspec);
 1269 
 1270       // Emit stubs for static call.
 1271       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 1272       if (stub == NULL) {
 1273         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 1274         return;
 1275       }
 1276     }
 1277   %}
 1278 
 1279   enc_class save_last_PC %{
 1280     // preserve mark
 1281     address mark = cbuf.insts()-&gt;mark();
 1282     debug_only(int off0 = cbuf.insts_size());
 1283     C2_MacroAssembler _masm(&amp;cbuf);
 1284     int ret_addr_offset = as_MachCall()-&gt;ret_addr_offset();
 1285     __ adr(LR, mark + ret_addr_offset);
 1286     __ str(LR, Address(Rthread, JavaThread::last_Java_pc_offset()));
 1287     debug_only(int off1 = cbuf.insts_size());
 1288     assert(off1 - off0 == 2 * Assembler::InstructionSize, &quot;correct size prediction&quot;);
 1289     // restore mark
 1290     cbuf.insts()-&gt;set_mark(mark);
 1291   %}
 1292 
 1293   enc_class preserve_SP %{
 1294     // preserve mark
 1295     address mark = cbuf.insts()-&gt;mark();
 1296     debug_only(int off0 = cbuf.insts_size());
 1297     C2_MacroAssembler _masm(&amp;cbuf);
 1298     // FP is preserved across all calls, even compiled calls.
 1299     // Use it to preserve SP in places where the callee might change the SP.
 1300     __ mov(Rmh_SP_save, SP);
 1301     debug_only(int off1 = cbuf.insts_size());
 1302     assert(off1 - off0 == 4, &quot;correct size prediction&quot;);
 1303     // restore mark
 1304     cbuf.insts()-&gt;set_mark(mark);
 1305   %}
 1306 
 1307   enc_class restore_SP %{
 1308     C2_MacroAssembler _masm(&amp;cbuf);
 1309     __ mov(SP, Rmh_SP_save);
 1310   %}
 1311 
 1312   enc_class Java_Dynamic_Call (method meth) %{
 1313     C2_MacroAssembler _masm(&amp;cbuf);
 1314     Register R8_ic_reg = reg_to_register_object(Matcher::inline_cache_reg_encode());
 1315     assert(R8_ic_reg == Ricklass, &quot;should be&quot;);
 1316     __ set_inst_mark();
 1317     __ movw(R8_ic_reg, ((unsigned int)Universe::non_oop_word()) &amp; 0xffff);
 1318     __ movt(R8_ic_reg, ((unsigned int)Universe::non_oop_word()) &gt;&gt; 16);
 1319     address  virtual_call_oop_addr = __ inst_mark();
 1320     // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
 1321     // who we intended to call.
 1322     int method_index = resolved_method_index(cbuf);
 1323     __ relocate(virtual_call_Relocation::spec(virtual_call_oop_addr, method_index));
 1324     emit_call_reloc(cbuf, as_MachCall(), $meth, RelocationHolder::none);
 1325   %}
 1326 
 1327   enc_class LdReplImmI(immI src, regD dst, iRegI tmp, int cnt, int wth) %{
 1328     // FIXME: load from constant table?
 1329     // Load a constant replicated &quot;count&quot; times with width &quot;width&quot;
 1330     int count = $cnt$$constant;
 1331     int width = $wth$$constant;
 1332     assert(count*width == 4, &quot;sanity&quot;);
 1333     int val = $src$$constant;
 1334     if (width &lt; 4) {
 1335       int bit_width = width * 8;
 1336       val &amp;= (((int)1) &lt;&lt; bit_width) - 1; // mask off sign bits
 1337       for (int i = 0; i &lt; count - 1; i++) {
 1338         val |= (val &lt;&lt; bit_width);
 1339       }
 1340     }
 1341     C2_MacroAssembler _masm(&amp;cbuf);
 1342 
 1343     if (val == -1) {
 1344       __ mvn($tmp$$Register, 0);
 1345     } else if (val == 0) {
 1346       __ mov($tmp$$Register, 0);
 1347     } else {
 1348       __ movw($tmp$$Register, val &amp; 0xffff);
 1349       __ movt($tmp$$Register, (unsigned int)val &gt;&gt; 16);
 1350     }
 1351     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 1352   %}
 1353 
 1354   enc_class LdReplImmF(immF src, regD dst, iRegI tmp) %{
 1355     // Replicate float con 2 times and pack into vector (8 bytes) in regD.
 1356     float fval = $src$$constant;
 1357     int val = *((int*)&amp;fval);
 1358     C2_MacroAssembler _masm(&amp;cbuf);
 1359 
 1360     if (val == -1) {
 1361       __ mvn($tmp$$Register, 0);
 1362     } else if (val == 0) {
 1363       __ mov($tmp$$Register, 0);
 1364     } else {
 1365       __ movw($tmp$$Register, val &amp; 0xffff);
 1366       __ movt($tmp$$Register, (unsigned int)val &gt;&gt; 16);
 1367     }
 1368     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 1369   %}
 1370 
 1371   enc_class enc_String_Compare(R0RegP str1, R1RegP str2, R2RegI cnt1, R3RegI cnt2, iRegI result, iRegI tmp1, iRegI tmp2) %{
 1372     Label Ldone, Lloop;
 1373     C2_MacroAssembler _masm(&amp;cbuf);
 1374 
 1375     Register   str1_reg = $str1$$Register;
 1376     Register   str2_reg = $str2$$Register;
 1377     Register   cnt1_reg = $cnt1$$Register; // int
 1378     Register   cnt2_reg = $cnt2$$Register; // int
 1379     Register   tmp1_reg = $tmp1$$Register;
 1380     Register   tmp2_reg = $tmp2$$Register;
 1381     Register result_reg = $result$$Register;
 1382 
 1383     assert_different_registers(str1_reg, str2_reg, cnt1_reg, cnt2_reg, tmp1_reg, tmp2_reg);
 1384 
 1385     // Compute the minimum of the string lengths(str1_reg) and the
 1386     // difference of the string lengths (stack)
 1387 
 1388     // See if the lengths are different, and calculate min in str1_reg.
 1389     // Stash diff in tmp2 in case we need it for a tie-breaker.
 1390     __ subs_32(tmp2_reg, cnt1_reg, cnt2_reg);
 1391     __ mov(cnt1_reg, AsmOperand(cnt1_reg, lsl, exact_log2(sizeof(jchar)))); // scale the limit
 1392     __ mov(cnt1_reg, AsmOperand(cnt2_reg, lsl, exact_log2(sizeof(jchar))), pl); // scale the limit
 1393 
 1394     // reallocate cnt1_reg, cnt2_reg, result_reg
 1395     // Note:  limit_reg holds the string length pre-scaled by 2
 1396     Register limit_reg = cnt1_reg;
 1397     Register  chr2_reg = cnt2_reg;
 1398     Register  chr1_reg = tmp1_reg;
 1399     // str{12} are the base pointers
 1400 
 1401     // Is the minimum length zero?
 1402     __ cmp_32(limit_reg, 0);
 1403     if (result_reg != tmp2_reg) {
 1404       __ mov(result_reg, tmp2_reg, eq);
 1405     }
 1406     __ b(Ldone, eq);
 1407 
 1408     // Load first characters
 1409     __ ldrh(chr1_reg, Address(str1_reg, 0));
 1410     __ ldrh(chr2_reg, Address(str2_reg, 0));
 1411 
 1412     // Compare first characters
 1413     __ subs(chr1_reg, chr1_reg, chr2_reg);
 1414     if (result_reg != chr1_reg) {
 1415       __ mov(result_reg, chr1_reg, ne);
 1416     }
 1417     __ b(Ldone, ne);
 1418 
 1419     {
 1420       // Check after comparing first character to see if strings are equivalent
 1421       // Check if the strings start at same location
 1422       __ cmp(str1_reg, str2_reg);
 1423       // Check if the length difference is zero
 1424       __ cond_cmp(tmp2_reg, 0, eq);
 1425       __ mov(result_reg, 0, eq); // result is zero
 1426       __ b(Ldone, eq);
 1427       // Strings might not be equal
 1428     }
 1429 
 1430     __ subs(chr1_reg, limit_reg, 1 * sizeof(jchar));
 1431     if (result_reg != tmp2_reg) {
 1432       __ mov(result_reg, tmp2_reg, eq);
 1433     }
 1434     __ b(Ldone, eq);
 1435 
 1436     // Shift str1_reg and str2_reg to the end of the arrays, negate limit
 1437     __ add(str1_reg, str1_reg, limit_reg);
 1438     __ add(str2_reg, str2_reg, limit_reg);
 1439     __ neg(limit_reg, chr1_reg);  // limit = -(limit-2)
 1440 
 1441     // Compare the rest of the characters
 1442     __ bind(Lloop);
 1443     __ ldrh(chr1_reg, Address(str1_reg, limit_reg));
 1444     __ ldrh(chr2_reg, Address(str2_reg, limit_reg));
 1445     __ subs(chr1_reg, chr1_reg, chr2_reg);
 1446     if (result_reg != chr1_reg) {
 1447       __ mov(result_reg, chr1_reg, ne);
 1448     }
 1449     __ b(Ldone, ne);
 1450 
 1451     __ adds(limit_reg, limit_reg, sizeof(jchar));
 1452     __ b(Lloop, ne);
 1453 
 1454     // If strings are equal up to min length, return the length difference.
 1455     if (result_reg != tmp2_reg) {
 1456       __ mov(result_reg, tmp2_reg);
 1457     }
 1458 
 1459     // Otherwise, return the difference between the first mismatched chars.
 1460     __ bind(Ldone);
 1461   %}
 1462 
 1463   enc_class enc_String_Equals(R0RegP str1, R1RegP str2, R2RegI cnt, iRegI result, iRegI tmp1, iRegI tmp2) %{
 1464     Label Lchar, Lchar_loop, Ldone, Lequal;
 1465     C2_MacroAssembler _masm(&amp;cbuf);
 1466 
 1467     Register   str1_reg = $str1$$Register;
 1468     Register   str2_reg = $str2$$Register;
 1469     Register    cnt_reg = $cnt$$Register; // int
 1470     Register   tmp1_reg = $tmp1$$Register;
 1471     Register   tmp2_reg = $tmp2$$Register;
 1472     Register result_reg = $result$$Register;
 1473 
 1474     assert_different_registers(str1_reg, str2_reg, cnt_reg, tmp1_reg, tmp2_reg, result_reg);
 1475 
 1476     __ cmp(str1_reg, str2_reg); //same char[] ?
 1477     __ b(Lequal, eq);
 1478 
 1479     __ cbz_32(cnt_reg, Lequal); // count == 0
 1480 
 1481     //rename registers
 1482     Register limit_reg = cnt_reg;
 1483     Register  chr1_reg = tmp1_reg;
 1484     Register  chr2_reg = tmp2_reg;
 1485 
 1486     __ logical_shift_left(limit_reg, limit_reg, exact_log2(sizeof(jchar)));
 1487 
 1488     //check for alignment and position the pointers to the ends
 1489     __ orr(chr1_reg, str1_reg, str2_reg);
 1490     __ tst(chr1_reg, 0x3);
 1491 
 1492     // notZero means at least one not 4-byte aligned.
 1493     // We could optimize the case when both arrays are not aligned
 1494     // but it is not frequent case and it requires additional checks.
 1495     __ b(Lchar, ne);
 1496 
 1497     // Compare char[] arrays aligned to 4 bytes.
 1498     __ char_arrays_equals(str1_reg, str2_reg, limit_reg, result_reg,
 1499                           chr1_reg, chr2_reg, Ldone);
 1500 
 1501     __ b(Lequal); // equal
 1502 
 1503     // char by char compare
 1504     __ bind(Lchar);
 1505     __ mov(result_reg, 0);
 1506     __ add(str1_reg, limit_reg, str1_reg);
 1507     __ add(str2_reg, limit_reg, str2_reg);
 1508     __ neg(limit_reg, limit_reg); //negate count
 1509 
 1510     // Lchar_loop
 1511     __ bind(Lchar_loop);
 1512     __ ldrh(chr1_reg, Address(str1_reg, limit_reg));
 1513     __ ldrh(chr2_reg, Address(str2_reg, limit_reg));
 1514     __ cmp(chr1_reg, chr2_reg);
 1515     __ b(Ldone, ne);
 1516     __ adds(limit_reg, limit_reg, sizeof(jchar));
 1517     __ b(Lchar_loop, ne);
 1518 
 1519     __ bind(Lequal);
 1520     __ mov(result_reg, 1);  //equal
 1521 
 1522     __ bind(Ldone);
 1523   %}
 1524 
 1525   enc_class enc_Array_Equals(R0RegP ary1, R1RegP ary2, iRegI tmp1, iRegI tmp2, iRegI tmp3, iRegI result) %{
 1526     Label Ldone, Lloop, Lequal;
 1527     C2_MacroAssembler _masm(&amp;cbuf);
 1528 
 1529     Register   ary1_reg = $ary1$$Register;
 1530     Register   ary2_reg = $ary2$$Register;
 1531     Register   tmp1_reg = $tmp1$$Register;
 1532     Register   tmp2_reg = $tmp2$$Register;
 1533     Register   tmp3_reg = $tmp3$$Register;
 1534     Register result_reg = $result$$Register;
 1535 
 1536     assert_different_registers(ary1_reg, ary2_reg, tmp1_reg, tmp2_reg, tmp3_reg, result_reg);
 1537 
 1538     int length_offset  = arrayOopDesc::length_offset_in_bytes();
 1539     int base_offset    = arrayOopDesc::base_offset_in_bytes(T_CHAR);
 1540 
 1541     // return true if the same array
 1542     __ teq(ary1_reg, ary2_reg);
 1543     __ mov(result_reg, 1, eq);
 1544     __ b(Ldone, eq); // equal
 1545 
 1546     __ tst(ary1_reg, ary1_reg);
 1547     __ mov(result_reg, 0, eq);
 1548     __ b(Ldone, eq);    // not equal
 1549 
 1550     __ tst(ary2_reg, ary2_reg);
 1551     __ mov(result_reg, 0, eq);
 1552     __ b(Ldone, eq);    // not equal
 1553 
 1554     //load the lengths of arrays
 1555     __ ldr_s32(tmp1_reg, Address(ary1_reg, length_offset)); // int
 1556     __ ldr_s32(tmp2_reg, Address(ary2_reg, length_offset)); // int
 1557 
 1558     // return false if the two arrays are not equal length
 1559     __ teq_32(tmp1_reg, tmp2_reg);
 1560     __ mov(result_reg, 0, ne);
 1561     __ b(Ldone, ne);    // not equal
 1562 
 1563     __ tst(tmp1_reg, tmp1_reg);
 1564     __ mov(result_reg, 1, eq);
 1565     __ b(Ldone, eq);    // zero-length arrays are equal
 1566 
 1567     // load array addresses
 1568     __ add(ary1_reg, ary1_reg, base_offset);
 1569     __ add(ary2_reg, ary2_reg, base_offset);
 1570 
 1571     // renaming registers
 1572     Register chr1_reg  =  tmp3_reg;   // for characters in ary1
 1573     Register chr2_reg  =  tmp2_reg;   // for characters in ary2
 1574     Register limit_reg =  tmp1_reg;   // length
 1575 
 1576     // set byte count
 1577     __ logical_shift_left_32(limit_reg, limit_reg, exact_log2(sizeof(jchar)));
 1578 
 1579     // Compare char[] arrays aligned to 4 bytes.
 1580     __ char_arrays_equals(ary1_reg, ary2_reg, limit_reg, result_reg,
 1581                           chr1_reg, chr2_reg, Ldone);
 1582     __ bind(Lequal);
 1583     __ mov(result_reg, 1);  //equal
 1584 
 1585     __ bind(Ldone);
 1586     %}
 1587 %}
 1588 
 1589 //----------FRAME--------------------------------------------------------------
 1590 // Definition of frame structure and management information.
 1591 //
 1592 //  S T A C K   L A Y O U T    Allocators stack-slot number
 1593 //                             |   (to get allocators register number
 1594 //  G  Owned by    |        |  v    add VMRegImpl::stack0)
 1595 //  r   CALLER     |        |
 1596 //  o     |        +--------+      pad to even-align allocators stack-slot
 1597 //  w     V        |  pad0  |        numbers; owned by CALLER
 1598 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 1599 //  h     ^        |   in   |  5
 1600 //        |        |  args  |  4   Holes in incoming args owned by SELF
 1601 //  |     |        |        |  3
 1602 //  |     |        +--------+
 1603 //  V     |        | old out|      Empty on Intel, window on Sparc
 1604 //        |    old |preserve|      Must be even aligned.
 1605 //        |     SP-+--------+----&gt; Matcher::_old_SP, 8 (or 16 in LP64)-byte aligned
 1606 //        |        |   in   |  3   area for Intel ret address
 1607 //     Owned by    |preserve|      Empty on Sparc.
 1608 //       SELF      +--------+
 1609 //        |        |  pad2  |  2   pad to align old SP
 1610 //        |        +--------+  1
 1611 //        |        | locks  |  0
 1612 //        |        +--------+----&gt; VMRegImpl::stack0, 8 (or 16 in LP64)-byte aligned
 1613 //        |        |  pad1  | 11   pad to align new SP
 1614 //        |        +--------+
 1615 //        |        |        | 10
 1616 //        |        | spills |  9   spills
 1617 //        V        |        |  8   (pad0 slot for callee)
 1618 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 1619 //        ^        |  out   |  7
 1620 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 1621 //     Owned by    +--------+
 1622 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 1623 //        |    new |preserve|      Must be even-aligned.
 1624 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 1625 //        |        |        |
 1626 //
 1627 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 1628 //         known from SELF&#39;s arguments and the Java calling convention.
 1629 //         Region 6-7 is determined per call site.
 1630 // Note 2: If the calling convention leaves holes in the incoming argument
 1631 //         area, those holes are owned by SELF.  Holes in the outgoing area
 1632 //         are owned by the CALLEE.  Holes should not be nessecary in the
 1633 //         incoming area, as the Java calling convention is completely under
 1634 //         the control of the AD file.  Doubles can be sorted and packed to
 1635 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 1636 //         varargs C calling conventions.
 1637 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 1638 //         even aligned with pad0 as needed.
 1639 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 1640 //         region 6-11 is even aligned; it may be padded out more so that
 1641 //         the region from SP to FP meets the minimum stack alignment.
 1642 
 1643 frame %{
 1644   // What direction does stack grow in (assumed to be same for native &amp; Java)
 1645   stack_direction(TOWARDS_LOW);
 1646 
 1647   // These two registers define part of the calling convention
 1648   // between compiled code and the interpreter.
 1649   inline_cache_reg(R_Ricklass);          // Inline Cache Register or Method* for I2C
 1650   interpreter_method_oop_reg(R_Rmethod); // Method Oop Register when calling interpreter
 1651 
 1652   // Optional: name the operand used by cisc-spilling to access [stack_pointer + offset]
 1653   cisc_spilling_operand_name(indOffset);
 1654 
 1655   // Number of stack slots consumed by a Monitor enter
 1656   sync_stack_slots(1 * VMRegImpl::slots_per_word);
 1657 
 1658   // Compiled code&#39;s Frame Pointer
 1659   frame_pointer(R_R13);
 1660 
 1661   // Stack alignment requirement
 1662   stack_alignment(StackAlignmentInBytes);
 1663   //  LP64: Alignment size in bytes (128-bit -&gt; 16 bytes)
 1664   // !LP64: Alignment size in bytes (64-bit  -&gt;  8 bytes)
 1665 
 1666   // Number of stack slots between incoming argument block and the start of
 1667   // a new frame.  The PROLOG must add this many slots to the stack.  The
 1668   // EPILOG must remove this many slots.
 1669   // FP + LR
 1670   in_preserve_stack_slots(2 * VMRegImpl::slots_per_word);
 1671 
 1672   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 1673   // for calls to C.  Supports the var-args backing area for register parms.
 1674   // ADLC doesn&#39;t support parsing expressions, so I folded the math by hand.
 1675   varargs_C_out_slots_killed( 0);
 1676 
 1677   // The after-PROLOG location of the return address.  Location of
 1678   // return address specifies a type (REG or STACK) and a number
 1679   // representing the register number (i.e. - use a register name) or
 1680   // stack slot.
 1681   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 1682   // Otherwise, it is above the locks and verification slot and alignment word
 1683   return_addr(STACK - 1*VMRegImpl::slots_per_word +
 1684               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 1685                         Compile::current()-&gt;fixed_slots()),
 1686                        stack_alignment_in_slots()));
 1687 
 1688   // Body of function which returns an OptoRegs array locating
 1689   // arguments either in registers or in stack slots for calling
 1690   // java
 1691   calling_convention %{
 1692     (void) SharedRuntime::java_calling_convention(sig_bt, regs, length, is_outgoing);
 1693 
 1694   %}
 1695 
 1696   // Body of function which returns an OptoRegs array locating
 1697   // arguments either in registers or in stack slots for callin
 1698   // C.
 1699   c_calling_convention %{
 1700     // This is obviously always outgoing
 1701     (void) SharedRuntime::c_calling_convention(sig_bt, regs, /*regs2=*/NULL, length);
 1702   %}
 1703 
 1704   // Location of compiled Java return values.  Same as C
 1705   return_value %{
 1706     return c2::return_value(ideal_reg);
 1707   %}
 1708 
 1709 %}
 1710 
 1711 //----------ATTRIBUTES---------------------------------------------------------
 1712 //----------Instruction Attributes---------------------------------------------
 1713 ins_attrib ins_cost(DEFAULT_COST); // Required cost attribute
 1714 ins_attrib ins_size(32);           // Required size attribute (in bits)
 1715 ins_attrib ins_short_branch(0);    // Required flag: is this instruction a
 1716                                    // non-matching short branch variant of some
 1717                                                             // long branch?
 1718 
 1719 //----------OPERANDS-----------------------------------------------------------
 1720 // Operand definitions must precede instruction definitions for correct parsing
 1721 // in the ADLC because operands constitute user defined types which are used in
 1722 // instruction definitions.
 1723 
 1724 //----------Simple Operands----------------------------------------------------
 1725 // Immediate Operands
 1726 // Integer Immediate: 32-bit
 1727 operand immI() %{
 1728   match(ConI);
 1729 
 1730   op_cost(0);
 1731   // formats are generated automatically for constants and base registers
 1732   format %{ %}
 1733   interface(CONST_INTER);
 1734 %}
 1735 
 1736 // Integer Immediate: 8-bit unsigned - for VMOV
 1737 operand immU8() %{
 1738   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 255));
 1739   match(ConI);
 1740   op_cost(0);
 1741 
 1742   format %{ %}
 1743   interface(CONST_INTER);
 1744 %}
 1745 
 1746 // Integer Immediate: 16-bit
 1747 operand immI16() %{
 1748   predicate((n-&gt;get_int() &gt;&gt; 16) == 0 &amp;&amp; VM_Version::supports_movw());
 1749   match(ConI);
 1750   op_cost(0);
 1751 
 1752   format %{ %}
 1753   interface(CONST_INTER);
 1754 %}
 1755 
 1756 // Integer Immediate: offset for half and double word loads and stores
 1757 operand immIHD() %{
 1758   predicate(is_memoryHD(n-&gt;get_int()));
 1759   match(ConI);
 1760   op_cost(0);
 1761   format %{ %}
 1762   interface(CONST_INTER);
 1763 %}
 1764 
 1765 // Integer Immediate: offset for fp loads and stores
 1766 operand immIFP() %{
 1767   predicate(is_memoryfp(n-&gt;get_int()) &amp;&amp; ((n-&gt;get_int() &amp; 3) == 0));
 1768   match(ConI);
 1769   op_cost(0);
 1770 
 1771   format %{ %}
 1772   interface(CONST_INTER);
 1773 %}
 1774 
 1775 // Valid scale values for addressing modes and shifts
 1776 operand immU5() %{
 1777   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 31));
 1778   match(ConI);
 1779   op_cost(0);
 1780 
 1781   format %{ %}
 1782   interface(CONST_INTER);
 1783 %}
 1784 
 1785 // Integer Immediate: 6-bit
 1786 operand immU6Big() %{
 1787   predicate(n-&gt;get_int() &gt;= 32 &amp;&amp; n-&gt;get_int() &lt;= 63);
 1788   match(ConI);
 1789   op_cost(0);
 1790   format %{ %}
 1791   interface(CONST_INTER);
 1792 %}
 1793 
 1794 // Integer Immediate: 0-bit
 1795 operand immI0() %{
 1796   predicate(n-&gt;get_int() == 0);
 1797   match(ConI);
 1798   op_cost(0);
 1799 
 1800   format %{ %}
 1801   interface(CONST_INTER);
 1802 %}
 1803 
 1804 // Integer Immediate: the value 1
 1805 operand immI_1() %{
 1806   predicate(n-&gt;get_int() == 1);
 1807   match(ConI);
 1808   op_cost(0);
 1809 
 1810   format %{ %}
 1811   interface(CONST_INTER);
 1812 %}
 1813 
 1814 // Integer Immediate: the value 2
 1815 operand immI_2() %{
 1816   predicate(n-&gt;get_int() == 2);
 1817   match(ConI);
 1818   op_cost(0);
 1819 
 1820   format %{ %}
 1821   interface(CONST_INTER);
 1822 %}
 1823 
 1824 // Integer Immediate: the value 3
 1825 operand immI_3() %{
 1826   predicate(n-&gt;get_int() == 3);
 1827   match(ConI);
 1828   op_cost(0);
 1829 
 1830   format %{ %}
 1831   interface(CONST_INTER);
 1832 %}
 1833 
 1834 // Integer Immediate: the value 4
 1835 operand immI_4() %{
 1836   predicate(n-&gt;get_int() == 4);
 1837   match(ConI);
 1838   op_cost(0);
 1839 
 1840   format %{ %}
 1841   interface(CONST_INTER);
 1842 %}
 1843 
 1844 // Integer Immediate: the value 8
 1845 operand immI_8() %{
 1846   predicate(n-&gt;get_int() == 8);
 1847   match(ConI);
 1848   op_cost(0);
 1849 
 1850   format %{ %}
 1851   interface(CONST_INTER);
 1852 %}
 1853 
 1854 // Int Immediate non-negative
 1855 operand immU31()
 1856 %{
 1857   predicate(n-&gt;get_int() &gt;= 0);
 1858   match(ConI);
 1859 
 1860   op_cost(0);
 1861   format %{ %}
 1862   interface(CONST_INTER);
 1863 %}
 1864 
 1865 // Integer Immediate: the values 32-63
 1866 operand immI_32_63() %{
 1867   predicate(n-&gt;get_int() &gt;= 32 &amp;&amp; n-&gt;get_int() &lt;= 63);
 1868   match(ConI);
 1869   op_cost(0);
 1870 
 1871   format %{ %}
 1872   interface(CONST_INTER);
 1873 %}
 1874 
 1875 // Immediates for special shifts (sign extend)
 1876 
 1877 // Integer Immediate: the value 16
 1878 operand immI_16() %{
 1879   predicate(n-&gt;get_int() == 16);
 1880   match(ConI);
 1881   op_cost(0);
 1882 
 1883   format %{ %}
 1884   interface(CONST_INTER);
 1885 %}
 1886 
 1887 // Integer Immediate: the value 24
 1888 operand immI_24() %{
 1889   predicate(n-&gt;get_int() == 24);
 1890   match(ConI);
 1891   op_cost(0);
 1892 
 1893   format %{ %}
 1894   interface(CONST_INTER);
 1895 %}
 1896 
 1897 // Integer Immediate: the value 255
 1898 operand immI_255() %{
 1899   predicate( n-&gt;get_int() == 255 );
 1900   match(ConI);
 1901   op_cost(0);
 1902 
 1903   format %{ %}
 1904   interface(CONST_INTER);
 1905 %}
 1906 
 1907 // Integer Immediate: the value 65535
 1908 operand immI_65535() %{
 1909   predicate(n-&gt;get_int() == 65535);
 1910   match(ConI);
 1911   op_cost(0);
 1912 
 1913   format %{ %}
 1914   interface(CONST_INTER);
 1915 %}
 1916 
 1917 // Integer Immediates for arithmetic instructions
 1918 
 1919 operand aimmI() %{
 1920   predicate(is_aimm(n-&gt;get_int()));
 1921   match(ConI);
 1922   op_cost(0);
 1923 
 1924   format %{ %}
 1925   interface(CONST_INTER);
 1926 %}
 1927 
 1928 operand aimmIneg() %{
 1929   predicate(is_aimm(-n-&gt;get_int()));
 1930   match(ConI);
 1931   op_cost(0);
 1932 
 1933   format %{ %}
 1934   interface(CONST_INTER);
 1935 %}
 1936 
 1937 operand aimmU31() %{
 1938   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; is_aimm(n-&gt;get_int()));
 1939   match(ConI);
 1940   op_cost(0);
 1941 
 1942   format %{ %}
 1943   interface(CONST_INTER);
 1944 %}
 1945 
 1946 // Integer Immediates for logical instructions
 1947 
 1948 operand limmI() %{
 1949   predicate(is_limmI(n-&gt;get_int()));
 1950   match(ConI);
 1951   op_cost(0);
 1952 
 1953   format %{ %}
 1954   interface(CONST_INTER);
 1955 %}
 1956 
 1957 operand limmIlow8() %{
 1958   predicate(is_limmI_low(n-&gt;get_int(), 8));
 1959   match(ConI);
 1960   op_cost(0);
 1961 
 1962   format %{ %}
 1963   interface(CONST_INTER);
 1964 %}
 1965 
 1966 operand limmU31() %{
 1967   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; is_limmI(n-&gt;get_int()));
 1968   match(ConI);
 1969   op_cost(0);
 1970 
 1971   format %{ %}
 1972   interface(CONST_INTER);
 1973 %}
 1974 
 1975 operand limmIn() %{
 1976   predicate(is_limmI(~n-&gt;get_int()));
 1977   match(ConI);
 1978   op_cost(0);
 1979 
 1980   format %{ %}
 1981   interface(CONST_INTER);
 1982 %}
 1983 
 1984 
 1985 // Long Immediate: the value FF
 1986 operand immL_FF() %{
 1987   predicate( n-&gt;get_long() == 0xFFL );
 1988   match(ConL);
 1989   op_cost(0);
 1990 
 1991   format %{ %}
 1992   interface(CONST_INTER);
 1993 %}
 1994 
 1995 // Long Immediate: the value FFFF
 1996 operand immL_FFFF() %{
 1997   predicate( n-&gt;get_long() == 0xFFFFL );
 1998   match(ConL);
 1999   op_cost(0);
 2000 
 2001   format %{ %}
 2002   interface(CONST_INTER);
 2003 %}
 2004 
 2005 // Pointer Immediate: 32 or 64-bit
 2006 operand immP() %{
 2007   match(ConP);
 2008 
 2009   op_cost(5);
 2010   // formats are generated automatically for constants and base registers
 2011   format %{ %}
 2012   interface(CONST_INTER);
 2013 %}
 2014 
 2015 operand immP0() %{
 2016   predicate(n-&gt;get_ptr() == 0);
 2017   match(ConP);
 2018   op_cost(0);
 2019 
 2020   format %{ %}
 2021   interface(CONST_INTER);
 2022 %}
 2023 
 2024 operand immP_poll() %{
 2025   predicate(n-&gt;get_ptr() != 0 &amp;&amp; n-&gt;get_ptr() == (intptr_t)os::get_polling_page());
 2026   match(ConP);
 2027 
 2028   // formats are generated automatically for constants and base registers
 2029   format %{ %}
 2030   interface(CONST_INTER);
 2031 %}
 2032 
 2033 // Pointer Immediate
 2034 operand immN()
 2035 %{
 2036   match(ConN);
 2037 
 2038   op_cost(10);
 2039   format %{ %}
 2040   interface(CONST_INTER);
 2041 %}
 2042 
 2043 operand immNKlass()
 2044 %{
 2045   match(ConNKlass);
 2046 
 2047   op_cost(10);
 2048   format %{ %}
 2049   interface(CONST_INTER);
 2050 %}
 2051 
 2052 // NULL Pointer Immediate
 2053 operand immN0()
 2054 %{
 2055   predicate(n-&gt;get_narrowcon() == 0);
 2056   match(ConN);
 2057 
 2058   op_cost(0);
 2059   format %{ %}
 2060   interface(CONST_INTER);
 2061 %}
 2062 
 2063 operand immL() %{
 2064   match(ConL);
 2065   op_cost(40);
 2066   // formats are generated automatically for constants and base registers
 2067   format %{ %}
 2068   interface(CONST_INTER);
 2069 %}
 2070 
 2071 operand immL0() %{
 2072   predicate(n-&gt;get_long() == 0L);
 2073   match(ConL);
 2074   op_cost(0);
 2075   // formats are generated automatically for constants and base registers
 2076   format %{ %}
 2077   interface(CONST_INTER);
 2078 %}
 2079 
 2080 // Long Immediate: 16-bit
 2081 operand immL16() %{
 2082   predicate(n-&gt;get_long() &gt;= 0 &amp;&amp; n-&gt;get_long() &lt; (1&lt;&lt;16)  &amp;&amp; VM_Version::supports_movw());
 2083   match(ConL);
 2084   op_cost(0);
 2085 
 2086   format %{ %}
 2087   interface(CONST_INTER);
 2088 %}
 2089 
 2090 // Long Immediate: low 32-bit mask
 2091 operand immL_32bits() %{
 2092   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 2093   match(ConL);
 2094   op_cost(0);
 2095 
 2096   format %{ %}
 2097   interface(CONST_INTER);
 2098 %}
 2099 
 2100 // Double Immediate
 2101 operand immD() %{
 2102   match(ConD);
 2103 
 2104   op_cost(40);
 2105   format %{ %}
 2106   interface(CONST_INTER);
 2107 %}
 2108 
 2109 // Double Immediate: +0.0d.
 2110 operand immD0() %{
 2111   predicate(jlong_cast(n-&gt;getd()) == 0);
 2112 
 2113   match(ConD);
 2114   op_cost(0);
 2115   format %{ %}
 2116   interface(CONST_INTER);
 2117 %}
 2118 
 2119 operand imm8D() %{
 2120   predicate(Assembler::double_num(n-&gt;getd()).can_be_imm8());
 2121   match(ConD);
 2122 
 2123   op_cost(0);
 2124   format %{ %}
 2125   interface(CONST_INTER);
 2126 %}
 2127 
 2128 // Float Immediate
 2129 operand immF() %{
 2130   match(ConF);
 2131 
 2132   op_cost(20);
 2133   format %{ %}
 2134   interface(CONST_INTER);
 2135 %}
 2136 
 2137 // Float Immediate: +0.0f
 2138 operand immF0() %{
 2139   predicate(jint_cast(n-&gt;getf()) == 0);
 2140   match(ConF);
 2141 
 2142   op_cost(0);
 2143   format %{ %}
 2144   interface(CONST_INTER);
 2145 %}
 2146 
 2147 // Float Immediate: encoded as 8 bits
 2148 operand imm8F() %{
 2149   predicate(Assembler::float_num(n-&gt;getf()).can_be_imm8());
 2150   match(ConF);
 2151 
 2152   op_cost(0);
 2153   format %{ %}
 2154   interface(CONST_INTER);
 2155 %}
 2156 
 2157 // Integer Register Operands
 2158 // Integer Register
 2159 operand iRegI() %{
 2160   constraint(ALLOC_IN_RC(int_reg));
 2161   match(RegI);
 2162   match(R0RegI);
 2163   match(R1RegI);
 2164   match(R2RegI);
 2165   match(R3RegI);
 2166   match(R12RegI);
 2167 
 2168   format %{ %}
 2169   interface(REG_INTER);
 2170 %}
 2171 
 2172 // Pointer Register
 2173 operand iRegP() %{
 2174   constraint(ALLOC_IN_RC(ptr_reg));
 2175   match(RegP);
 2176   match(R0RegP);
 2177   match(R1RegP);
 2178   match(R2RegP);
 2179   match(RExceptionRegP);
 2180   match(R8RegP);
 2181   match(R9RegP);
 2182   match(RthreadRegP); // FIXME: move to sp_ptr_RegP?
 2183   match(R12RegP);
 2184   match(LRRegP);
 2185 
 2186   match(sp_ptr_RegP);
 2187   match(store_ptr_RegP);
 2188 
 2189   format %{ %}
 2190   interface(REG_INTER);
 2191 %}
 2192 
 2193 // GPRs + Rthread + SP
 2194 operand sp_ptr_RegP() %{
 2195   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2196   match(RegP);
 2197   match(iRegP);
 2198   match(SPRegP); // FIXME: check cost
 2199 
 2200   format %{ %}
 2201   interface(REG_INTER);
 2202 %}
 2203 
 2204 
 2205 operand R0RegP() %{
 2206   constraint(ALLOC_IN_RC(R0_regP));
 2207   match(iRegP);
 2208 
 2209   format %{ %}
 2210   interface(REG_INTER);
 2211 %}
 2212 
 2213 operand R1RegP() %{
 2214   constraint(ALLOC_IN_RC(R1_regP));
 2215   match(iRegP);
 2216 
 2217   format %{ %}
 2218   interface(REG_INTER);
 2219 %}
 2220 
 2221 operand R8RegP() %{
 2222   constraint(ALLOC_IN_RC(R8_regP));
 2223   match(iRegP);
 2224 
 2225   format %{ %}
 2226   interface(REG_INTER);
 2227 %}
 2228 
 2229 operand R9RegP() %{
 2230   constraint(ALLOC_IN_RC(R9_regP));
 2231   match(iRegP);
 2232 
 2233   format %{ %}
 2234   interface(REG_INTER);
 2235 %}
 2236 
 2237 operand R12RegP() %{
 2238   constraint(ALLOC_IN_RC(R12_regP));
 2239   match(iRegP);
 2240 
 2241   format %{ %}
 2242   interface(REG_INTER);
 2243 %}
 2244 
 2245 operand R2RegP() %{
 2246   constraint(ALLOC_IN_RC(R2_regP));
 2247   match(iRegP);
 2248 
 2249   format %{ %}
 2250   interface(REG_INTER);
 2251 %}
 2252 
 2253 operand RExceptionRegP() %{
 2254   constraint(ALLOC_IN_RC(Rexception_regP));
 2255   match(iRegP);
 2256 
 2257   format %{ %}
 2258   interface(REG_INTER);
 2259 %}
 2260 
 2261 operand RthreadRegP() %{
 2262   constraint(ALLOC_IN_RC(Rthread_regP));
 2263   match(iRegP);
 2264 
 2265   format %{ %}
 2266   interface(REG_INTER);
 2267 %}
 2268 
 2269 operand IPRegP() %{
 2270   constraint(ALLOC_IN_RC(IP_regP));
 2271   match(iRegP);
 2272 
 2273   format %{ %}
 2274   interface(REG_INTER);
 2275 %}
 2276 
 2277 operand SPRegP() %{
 2278   constraint(ALLOC_IN_RC(SP_regP));
 2279   match(iRegP);
 2280 
 2281   format %{ %}
 2282   interface(REG_INTER);
 2283 %}
 2284 
 2285 operand LRRegP() %{
 2286   constraint(ALLOC_IN_RC(LR_regP));
 2287   match(iRegP);
 2288 
 2289   format %{ %}
 2290   interface(REG_INTER);
 2291 %}
 2292 
 2293 operand R0RegI() %{
 2294   constraint(ALLOC_IN_RC(R0_regI));
 2295   match(iRegI);
 2296 
 2297   format %{ %}
 2298   interface(REG_INTER);
 2299 %}
 2300 
 2301 operand R1RegI() %{
 2302   constraint(ALLOC_IN_RC(R1_regI));
 2303   match(iRegI);
 2304 
 2305   format %{ %}
 2306   interface(REG_INTER);
 2307 %}
 2308 
 2309 operand R2RegI() %{
 2310   constraint(ALLOC_IN_RC(R2_regI));
 2311   match(iRegI);
 2312 
 2313   format %{ %}
 2314   interface(REG_INTER);
 2315 %}
 2316 
 2317 operand R3RegI() %{
 2318   constraint(ALLOC_IN_RC(R3_regI));
 2319   match(iRegI);
 2320 
 2321   format %{ %}
 2322   interface(REG_INTER);
 2323 %}
 2324 
 2325 operand R12RegI() %{
 2326   constraint(ALLOC_IN_RC(R12_regI));
 2327   match(iRegI);
 2328 
 2329   format %{ %}
 2330   interface(REG_INTER);
 2331 %}
 2332 
 2333 // Long Register
 2334 operand iRegL() %{
 2335   constraint(ALLOC_IN_RC(long_reg));
 2336   match(RegL);
 2337   match(R0R1RegL);
 2338   match(R2R3RegL);
 2339 //match(iRegLex);
 2340 
 2341   format %{ %}
 2342   interface(REG_INTER);
 2343 %}
 2344 
 2345 operand iRegLd() %{
 2346   constraint(ALLOC_IN_RC(long_reg_align));
 2347   match(iRegL); // FIXME: allows unaligned R11/R12?
 2348 
 2349   format %{ %}
 2350   interface(REG_INTER);
 2351 %}
 2352 
 2353 // first long arg, or return value
 2354 operand R0R1RegL() %{
 2355   constraint(ALLOC_IN_RC(R0R1_regL));
 2356   match(iRegL);
 2357 
 2358   format %{ %}
 2359   interface(REG_INTER);
 2360 %}
 2361 
 2362 operand R2R3RegL() %{
 2363   constraint(ALLOC_IN_RC(R2R3_regL));
 2364   match(iRegL);
 2365 
 2366   format %{ %}
 2367   interface(REG_INTER);
 2368 %}
 2369 
 2370 // Condition Code Flag Register
 2371 operand flagsReg() %{
 2372   constraint(ALLOC_IN_RC(int_flags));
 2373   match(RegFlags);
 2374 
 2375   format %{ &quot;apsr&quot; %}
 2376   interface(REG_INTER);
 2377 %}
 2378 
 2379 // Result of compare to 0 (TST)
 2380 operand flagsReg_EQNELTGE() %{
 2381   constraint(ALLOC_IN_RC(int_flags));
 2382   match(RegFlags);
 2383 
 2384   format %{ &quot;apsr_EQNELTGE&quot; %}
 2385   interface(REG_INTER);
 2386 %}
 2387 
 2388 // Condition Code Register, unsigned comparisons.
 2389 operand flagsRegU() %{
 2390   constraint(ALLOC_IN_RC(int_flags));
 2391   match(RegFlags);
 2392 #ifdef TODO
 2393   match(RegFlagsP);
 2394 #endif
 2395 
 2396   format %{ &quot;apsr_U&quot; %}
 2397   interface(REG_INTER);
 2398 %}
 2399 
 2400 // Condition Code Register, pointer comparisons.
 2401 operand flagsRegP() %{
 2402   constraint(ALLOC_IN_RC(int_flags));
 2403   match(RegFlags);
 2404 
 2405   format %{ &quot;apsr_P&quot; %}
 2406   interface(REG_INTER);
 2407 %}
 2408 
 2409 // Condition Code Register, long comparisons.
 2410 operand flagsRegL_LTGE() %{
 2411   constraint(ALLOC_IN_RC(int_flags));
 2412   match(RegFlags);
 2413 
 2414   format %{ &quot;apsr_L_LTGE&quot; %}
 2415   interface(REG_INTER);
 2416 %}
 2417 
 2418 operand flagsRegL_EQNE() %{
 2419   constraint(ALLOC_IN_RC(int_flags));
 2420   match(RegFlags);
 2421 
 2422   format %{ &quot;apsr_L_EQNE&quot; %}
 2423   interface(REG_INTER);
 2424 %}
 2425 
 2426 operand flagsRegL_LEGT() %{
 2427   constraint(ALLOC_IN_RC(int_flags));
 2428   match(RegFlags);
 2429 
 2430   format %{ &quot;apsr_L_LEGT&quot; %}
 2431   interface(REG_INTER);
 2432 %}
 2433 
 2434 operand flagsRegUL_LTGE() %{
 2435   constraint(ALLOC_IN_RC(int_flags));
 2436   match(RegFlags);
 2437 
 2438   format %{ &quot;apsr_UL_LTGE&quot; %}
 2439   interface(REG_INTER);
 2440 %}
 2441 
 2442 operand flagsRegUL_EQNE() %{
 2443   constraint(ALLOC_IN_RC(int_flags));
 2444   match(RegFlags);
 2445 
 2446   format %{ &quot;apsr_UL_EQNE&quot; %}
 2447   interface(REG_INTER);
 2448 %}
 2449 
 2450 operand flagsRegUL_LEGT() %{
 2451   constraint(ALLOC_IN_RC(int_flags));
 2452   match(RegFlags);
 2453 
 2454   format %{ &quot;apsr_UL_LEGT&quot; %}
 2455   interface(REG_INTER);
 2456 %}
 2457 
 2458 // Condition Code Register, floating comparisons, unordered same as &quot;less&quot;.
 2459 operand flagsRegF() %{
 2460   constraint(ALLOC_IN_RC(float_flags));
 2461   match(RegFlags);
 2462 
 2463   format %{ &quot;fpscr_F&quot; %}
 2464   interface(REG_INTER);
 2465 %}
 2466 
 2467 // Vectors
 2468 operand vecD() %{
 2469   constraint(ALLOC_IN_RC(actual_dflt_reg));
 2470   match(VecD);
 2471 
 2472   format %{ %}
 2473   interface(REG_INTER);
 2474 %}
 2475 
 2476 operand vecX() %{
 2477   constraint(ALLOC_IN_RC(vectorx_reg));
 2478   match(VecX);
 2479 
 2480   format %{ %}
 2481   interface(REG_INTER);
 2482 %}
 2483 
 2484 operand regD() %{
 2485   constraint(ALLOC_IN_RC(actual_dflt_reg));
 2486   match(RegD);
 2487   match(regD_low);
 2488 
 2489   format %{ %}
 2490   interface(REG_INTER);
 2491 %}
 2492 
 2493 operand regF() %{
 2494   constraint(ALLOC_IN_RC(sflt_reg));
 2495   match(RegF);
 2496 
 2497   format %{ %}
 2498   interface(REG_INTER);
 2499 %}
 2500 
 2501 operand regD_low() %{
 2502   constraint(ALLOC_IN_RC(dflt_low_reg));
 2503   match(RegD);
 2504 
 2505   format %{ %}
 2506   interface(REG_INTER);
 2507 %}
 2508 
 2509 // Special Registers
 2510 
 2511 // Method Register
 2512 operand inline_cache_regP(iRegP reg) %{
 2513   constraint(ALLOC_IN_RC(Ricklass_regP));
 2514   match(reg);
 2515   format %{ %}
 2516   interface(REG_INTER);
 2517 %}
 2518 
 2519 operand interpreter_method_oop_regP(iRegP reg) %{
 2520   constraint(ALLOC_IN_RC(Rmethod_regP));
 2521   match(reg);
 2522   format %{ %}
 2523   interface(REG_INTER);
 2524 %}
 2525 
 2526 
 2527 //----------Complex Operands---------------------------------------------------
 2528 // Indirect Memory Reference
 2529 operand indirect(sp_ptr_RegP reg) %{
 2530   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2531   match(reg);
 2532 
 2533   op_cost(100);
 2534   format %{ &quot;[$reg]&quot; %}
 2535   interface(MEMORY_INTER) %{
 2536     base($reg);
 2537     index(0xf); // PC =&gt; no index
 2538     scale(0x0);
 2539     disp(0x0);
 2540   %}
 2541 %}
 2542 
 2543 
 2544 // Indirect with Offset in ]-4096, 4096[
 2545 operand indOffset12(sp_ptr_RegP reg, immI12 offset) %{
 2546   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2547   match(AddP reg offset);
 2548 
 2549   op_cost(100);
 2550   format %{ &quot;[$reg + $offset]&quot; %}
 2551   interface(MEMORY_INTER) %{
 2552     base($reg);
 2553     index(0xf); // PC =&gt; no index
 2554     scale(0x0);
 2555     disp($offset);
 2556   %}
 2557 %}
 2558 
 2559 // Indirect with offset for float load/store
 2560 operand indOffsetFP(sp_ptr_RegP reg, immIFP offset) %{
 2561   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2562   match(AddP reg offset);
 2563 
 2564   op_cost(100);
 2565   format %{ &quot;[$reg + $offset]&quot; %}
 2566   interface(MEMORY_INTER) %{
 2567     base($reg);
 2568     index(0xf); // PC =&gt; no index
 2569     scale(0x0);
 2570     disp($offset);
 2571   %}
 2572 %}
 2573 
 2574 // Indirect with Offset for half and double words
 2575 operand indOffsetHD(sp_ptr_RegP reg, immIHD offset) %{
 2576   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2577   match(AddP reg offset);
 2578 
 2579   op_cost(100);
 2580   format %{ &quot;[$reg + $offset]&quot; %}
 2581   interface(MEMORY_INTER) %{
 2582     base($reg);
 2583     index(0xf); // PC =&gt; no index
 2584     scale(0x0);
 2585     disp($offset);
 2586   %}
 2587 %}
 2588 
 2589 // Indirect with Offset and Offset+4 in ]-1024, 1024[
 2590 operand indOffsetFPx2(sp_ptr_RegP reg, immX10x2 offset) %{
 2591   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2592   match(AddP reg offset);
 2593 
 2594   op_cost(100);
 2595   format %{ &quot;[$reg + $offset]&quot; %}
 2596   interface(MEMORY_INTER) %{
 2597     base($reg);
 2598     index(0xf); // PC =&gt; no index
 2599     scale(0x0);
 2600     disp($offset);
 2601   %}
 2602 %}
 2603 
 2604 // Indirect with Offset and Offset+4 in ]-4096, 4096[
 2605 operand indOffset12x2(sp_ptr_RegP reg, immI12x2 offset) %{
 2606   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2607   match(AddP reg offset);
 2608 
 2609   op_cost(100);
 2610   format %{ &quot;[$reg + $offset]&quot; %}
 2611   interface(MEMORY_INTER) %{
 2612     base($reg);
 2613     index(0xf); // PC =&gt; no index
 2614     scale(0x0);
 2615     disp($offset);
 2616   %}
 2617 %}
 2618 
 2619 // Indirect with Register Index
 2620 operand indIndex(iRegP addr, iRegX index) %{
 2621   constraint(ALLOC_IN_RC(ptr_reg));
 2622   match(AddP addr index);
 2623 
 2624   op_cost(100);
 2625   format %{ &quot;[$addr + $index]&quot; %}
 2626   interface(MEMORY_INTER) %{
 2627     base($addr);
 2628     index($index);
 2629     scale(0x0);
 2630     disp(0x0);
 2631   %}
 2632 %}
 2633 
 2634 // Indirect Memory Times Scale Plus Index Register
 2635 operand indIndexScale(iRegP addr, iRegX index, immU5 scale) %{
 2636   constraint(ALLOC_IN_RC(ptr_reg));
 2637   match(AddP addr (LShiftX index scale));
 2638 
 2639   op_cost(100);
 2640   format %{&quot;[$addr + $index &lt;&lt; $scale]&quot; %}
 2641   interface(MEMORY_INTER) %{
 2642     base($addr);
 2643     index($index);
 2644     scale($scale);
 2645     disp(0x0);
 2646   %}
 2647 %}
 2648 
 2649 // Operands for expressing Control Flow
 2650 // NOTE:  Label is a predefined operand which should not be redefined in
 2651 //        the AD file.  It is generically handled within the ADLC.
 2652 
 2653 //----------Conditional Branch Operands----------------------------------------
 2654 // Comparison Op  - This is the operation of the comparison, and is limited to
 2655 //                  the following set of codes:
 2656 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 2657 //
 2658 // Other attributes of the comparison, such as unsignedness, are specified
 2659 // by the comparison instruction that sets a condition code flags register.
 2660 // That result is represented by a flags operand whose subtype is appropriate
 2661 // to the unsignedness (etc.) of the comparison.
 2662 //
 2663 // Later, the instruction which matches both the Comparison Op (a Bool) and
 2664 // the flags (produced by the Cmp) specifies the coding of the comparison op
 2665 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 2666 
 2667 operand cmpOp() %{
 2668   match(Bool);
 2669 
 2670   format %{ &quot;&quot; %}
 2671   interface(COND_INTER) %{
 2672     equal(0x0);
 2673     not_equal(0x1);
 2674     less(0xb);
 2675     greater_equal(0xa);
 2676     less_equal(0xd);
 2677     greater(0xc);
 2678     overflow(0x0); // unsupported/unimplemented
 2679     no_overflow(0x0); // unsupported/unimplemented
 2680   %}
 2681 %}
 2682 
 2683 // integer comparison with 0, signed
 2684 operand cmpOp0() %{
 2685   match(Bool);
 2686 
 2687   format %{ &quot;&quot; %}
 2688   interface(COND_INTER) %{
 2689     equal(0x0);
 2690     not_equal(0x1);
 2691     less(0x4);
 2692     greater_equal(0x5);
 2693     less_equal(0xd); // unsupported
 2694     greater(0xc); // unsupported
 2695     overflow(0x0); // unsupported/unimplemented
 2696     no_overflow(0x0); // unsupported/unimplemented
 2697   %}
 2698 %}
 2699 
 2700 // Comparison Op, unsigned
 2701 operand cmpOpU() %{
 2702   match(Bool);
 2703 
 2704   format %{ &quot;u&quot; %}
 2705   interface(COND_INTER) %{
 2706     equal(0x0);
 2707     not_equal(0x1);
 2708     less(0x3);
 2709     greater_equal(0x2);
 2710     less_equal(0x9);
 2711     greater(0x8);
 2712     overflow(0x0); // unsupported/unimplemented
 2713     no_overflow(0x0); // unsupported/unimplemented
 2714   %}
 2715 %}
 2716 
 2717 // Comparison Op, pointer (same as unsigned)
 2718 operand cmpOpP() %{
 2719   match(Bool);
 2720 
 2721   format %{ &quot;p&quot; %}
 2722   interface(COND_INTER) %{
 2723     equal(0x0);
 2724     not_equal(0x1);
 2725     less(0x3);
 2726     greater_equal(0x2);
 2727     less_equal(0x9);
 2728     greater(0x8);
 2729     overflow(0x0); // unsupported/unimplemented
 2730     no_overflow(0x0); // unsupported/unimplemented
 2731   %}
 2732 %}
 2733 
 2734 operand cmpOpL() %{
 2735   match(Bool);
 2736 
 2737   format %{ &quot;L&quot; %}
 2738   interface(COND_INTER) %{
 2739     equal(0x0);
 2740     not_equal(0x1);
 2741     less(0xb);
 2742     greater_equal(0xa);
 2743     less_equal(0xd);
 2744     greater(0xc);
 2745     overflow(0x0); // unsupported/unimplemented
 2746     no_overflow(0x0); // unsupported/unimplemented
 2747   %}
 2748 %}
 2749 
 2750 operand cmpOpL_commute() %{
 2751   match(Bool);
 2752 
 2753   format %{ &quot;L&quot; %}
 2754   interface(COND_INTER) %{
 2755     equal(0x0);
 2756     not_equal(0x1);
 2757     less(0xc);
 2758     greater_equal(0xd);
 2759     less_equal(0xa);
 2760     greater(0xb);
 2761     overflow(0x0); // unsupported/unimplemented
 2762     no_overflow(0x0); // unsupported/unimplemented
 2763   %}
 2764 %}
 2765 
 2766 operand cmpOpUL() %{
 2767   match(Bool);
 2768 
 2769   format %{ &quot;UL&quot; %}
 2770   interface(COND_INTER) %{
 2771     equal(0x0);
 2772     not_equal(0x1);
 2773     less(0x3);
 2774     greater_equal(0x2);
 2775     less_equal(0x9);
 2776     greater(0x8);
 2777     overflow(0x0); // unsupported/unimplemented
 2778     no_overflow(0x0); // unsupported/unimplemented
 2779   %}
 2780 %}
 2781 
 2782 operand cmpOpUL_commute() %{
 2783   match(Bool);
 2784 
 2785   format %{ &quot;UL&quot; %}
 2786   interface(COND_INTER) %{
 2787     equal(0x0);
 2788     not_equal(0x1);
 2789     less(0x8);
 2790     greater_equal(0x9);
 2791     less_equal(0x2);
 2792     greater(0x3);
 2793     overflow(0x0); // unsupported/unimplemented
 2794     no_overflow(0x0); // unsupported/unimplemented
 2795   %}
 2796 %}
 2797 
 2798 
 2799 //----------OPERAND CLASSES----------------------------------------------------
 2800 // Operand Classes are groups of operands that are used to simplify
 2801 // instruction definitions by not requiring the AD writer to specify separate
 2802 // instructions for every form of operand when the instruction accepts
 2803 // multiple operand types with the same basic encoding and format.  The classic
 2804 // case of this is memory operands.
 2805 
 2806 opclass memoryI ( indirect, indOffset12, indIndex, indIndexScale );
 2807 opclass memoryP ( indirect, indOffset12, indIndex, indIndexScale );
 2808 opclass memoryF ( indirect, indOffsetFP );
 2809 opclass memoryF2 ( indirect, indOffsetFPx2 );
 2810 opclass memoryD ( indirect, indOffsetFP );
 2811 opclass memoryfp( indirect, indOffsetFP );
 2812 opclass memoryB ( indirect, indIndex, indOffsetHD );
 2813 opclass memoryS ( indirect, indIndex, indOffsetHD );
 2814 opclass memoryL ( indirect, indIndex, indOffsetHD );
 2815 
 2816 opclass memoryScaledI(indIndexScale);
 2817 opclass memoryScaledP(indIndexScale);
 2818 
 2819 // when ldrex/strex is used:
 2820 opclass memoryex ( indirect );
 2821 opclass indIndexMemory( indIndex );
 2822 opclass memorylong ( indirect, indOffset12x2 );
 2823 opclass memoryvld ( indirect /* , write back mode not implemented */ );
 2824 
 2825 //----------PIPELINE-----------------------------------------------------------
 2826 pipeline %{
 2827 
 2828 //----------ATTRIBUTES---------------------------------------------------------
 2829 attributes %{
 2830   fixed_size_instructions;           // Fixed size instructions
 2831   max_instructions_per_bundle = 4;   // Up to 4 instructions per bundle
 2832   instruction_unit_size = 4;         // An instruction is 4 bytes long
 2833   instruction_fetch_unit_size = 16;  // The processor fetches one line
 2834   instruction_fetch_units = 1;       // of 16 bytes
 2835 
 2836   // List of nop instructions
 2837   nops( Nop_A0, Nop_A1, Nop_MS, Nop_FA, Nop_BR );
 2838 %}
 2839 
 2840 //----------RESOURCES----------------------------------------------------------
 2841 // Resources are the functional units available to the machine
 2842 resources(A0, A1, MS, BR, FA, FM, IDIV, FDIV, IALU = A0 | A1);
 2843 
 2844 //----------PIPELINE DESCRIPTION-----------------------------------------------
 2845 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 2846 
 2847 pipe_desc(A, P, F, B, I, J, S, R, E, C, M, W, X, T, D);
 2848 
 2849 //----------PIPELINE CLASSES---------------------------------------------------
 2850 // Pipeline Classes describe the stages in which input and output are
 2851 // referenced by the hardware pipeline.
 2852 
 2853 // Integer ALU reg-reg operation
 2854 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 2855     single_instruction;
 2856     dst   : E(write);
 2857     src1  : R(read);
 2858     src2  : R(read);
 2859     IALU  : R;
 2860 %}
 2861 
 2862 // Integer ALU reg-reg long operation
 2863 pipe_class ialu_reg_reg_2(iRegL dst, iRegL src1, iRegL src2) %{
 2864     instruction_count(2);
 2865     dst   : E(write);
 2866     src1  : R(read);
 2867     src2  : R(read);
 2868     IALU  : R;
 2869     IALU  : R;
 2870 %}
 2871 
 2872 // Integer ALU reg-reg long dependent operation
 2873 pipe_class ialu_reg_reg_2_dep(iRegL dst, iRegL src1, iRegL src2, flagsReg cr) %{
 2874     instruction_count(1); multiple_bundles;
 2875     dst   : E(write);
 2876     src1  : R(read);
 2877     src2  : R(read);
 2878     cr    : E(write);
 2879     IALU  : R(2);
 2880 %}
 2881 
 2882 // Integer ALU reg-imm operaion
 2883 pipe_class ialu_reg_imm(iRegI dst, iRegI src1) %{
 2884     single_instruction;
 2885     dst   : E(write);
 2886     src1  : R(read);
 2887     IALU  : R;
 2888 %}
 2889 
 2890 // Integer ALU reg-reg operation with condition code
 2891 pipe_class ialu_cc_reg_reg(iRegI dst, iRegI src1, iRegI src2, flagsReg cr) %{
 2892     single_instruction;
 2893     dst   : E(write);
 2894     cr    : E(write);
 2895     src1  : R(read);
 2896     src2  : R(read);
 2897     IALU  : R;
 2898 %}
 2899 
 2900 // Integer ALU zero-reg operation
 2901 pipe_class ialu_zero_reg(iRegI dst, immI0 zero, iRegI src2) %{
 2902     single_instruction;
 2903     dst   : E(write);
 2904     src2  : R(read);
 2905     IALU  : R;
 2906 %}
 2907 
 2908 // Integer ALU zero-reg operation with condition code only
 2909 pipe_class ialu_cconly_zero_reg(flagsReg cr, iRegI src) %{
 2910     single_instruction;
 2911     cr    : E(write);
 2912     src   : R(read);
 2913     IALU  : R;
 2914 %}
 2915 
 2916 // Integer ALU reg-reg operation with condition code only
 2917 pipe_class ialu_cconly_reg_reg(flagsReg cr, iRegI src1, iRegI src2) %{
 2918     single_instruction;
 2919     cr    : E(write);
 2920     src1  : R(read);
 2921     src2  : R(read);
 2922     IALU  : R;
 2923 %}
 2924 
 2925 // Integer ALU reg-imm operation with condition code only
 2926 pipe_class ialu_cconly_reg_imm(flagsReg cr, iRegI src1) %{
 2927     single_instruction;
 2928     cr    : E(write);
 2929     src1  : R(read);
 2930     IALU  : R;
 2931 %}
 2932 
 2933 // Integer ALU reg-reg-zero operation with condition code only
 2934 pipe_class ialu_cconly_reg_reg_zero(flagsReg cr, iRegI src1, iRegI src2, immI0 zero) %{
 2935     single_instruction;
 2936     cr    : E(write);
 2937     src1  : R(read);
 2938     src2  : R(read);
 2939     IALU  : R;
 2940 %}
 2941 
 2942 // Integer ALU reg-imm-zero operation with condition code only
 2943 pipe_class ialu_cconly_reg_imm_zero(flagsReg cr, iRegI src1, immI0 zero) %{
 2944     single_instruction;
 2945     cr    : E(write);
 2946     src1  : R(read);
 2947     IALU  : R;
 2948 %}
 2949 
 2950 // Integer ALU reg-reg operation with condition code, src1 modified
 2951 pipe_class ialu_cc_rwreg_reg(flagsReg cr, iRegI src1, iRegI src2) %{
 2952     single_instruction;
 2953     cr    : E(write);
 2954     src1  : E(write);
 2955     src1  : R(read);
 2956     src2  : R(read);
 2957     IALU  : R;
 2958 %}
 2959 
 2960 pipe_class cmpL_reg(iRegI dst, iRegL src1, iRegL src2, flagsReg cr ) %{
 2961     multiple_bundles;
 2962     dst   : E(write)+4;
 2963     cr    : E(write);
 2964     src1  : R(read);
 2965     src2  : R(read);
 2966     IALU  : R(3);
 2967     BR    : R(2);
 2968 %}
 2969 
 2970 // Integer ALU operation
 2971 pipe_class ialu_none(iRegI dst) %{
 2972     single_instruction;
 2973     dst   : E(write);
 2974     IALU  : R;
 2975 %}
 2976 
 2977 // Integer ALU reg operation
 2978 pipe_class ialu_reg(iRegI dst, iRegI src) %{
 2979     single_instruction; may_have_no_code;
 2980     dst   : E(write);
 2981     src   : R(read);
 2982     IALU  : R;
 2983 %}
 2984 
 2985 // Integer ALU reg conditional operation
 2986 // This instruction has a 1 cycle stall, and cannot execute
 2987 // in the same cycle as the instruction setting the condition
 2988 // code. We kludge this by pretending to read the condition code
 2989 // 1 cycle earlier, and by marking the functional units as busy
 2990 // for 2 cycles with the result available 1 cycle later than
 2991 // is really the case.
 2992 pipe_class ialu_reg_flags( iRegI op2_out, iRegI op2_in, iRegI op1, flagsReg cr ) %{
 2993     single_instruction;
 2994     op2_out : C(write);
 2995     op1     : R(read);
 2996     cr      : R(read);       // This is really E, with a 1 cycle stall
 2997     BR      : R(2);
 2998     MS      : R(2);
 2999 %}
 3000 
 3001 // Integer ALU reg operation
 3002 pipe_class ialu_move_reg_L_to_I(iRegI dst, iRegL src) %{
 3003     single_instruction; may_have_no_code;
 3004     dst   : E(write);
 3005     src   : R(read);
 3006     IALU  : R;
 3007 %}
 3008 pipe_class ialu_move_reg_I_to_L(iRegL dst, iRegI src) %{
 3009     single_instruction; may_have_no_code;
 3010     dst   : E(write);
 3011     src   : R(read);
 3012     IALU  : R;
 3013 %}
 3014 
 3015 // Two integer ALU reg operations
 3016 pipe_class ialu_reg_2(iRegL dst, iRegL src) %{
 3017     instruction_count(2);
 3018     dst   : E(write);
 3019     src   : R(read);
 3020     A0    : R;
 3021     A1    : R;
 3022 %}
 3023 
 3024 // Two integer ALU reg operations
 3025 pipe_class ialu_move_reg_L_to_L(iRegL dst, iRegL src) %{
 3026     instruction_count(2); may_have_no_code;
 3027     dst   : E(write);
 3028     src   : R(read);
 3029     A0    : R;
 3030     A1    : R;
 3031 %}
 3032 
 3033 // Integer ALU imm operation
 3034 pipe_class ialu_imm(iRegI dst) %{
 3035     single_instruction;
 3036     dst   : E(write);
 3037     IALU  : R;
 3038 %}
 3039 
 3040 pipe_class ialu_imm_n(iRegI dst) %{
 3041     single_instruction;
 3042     dst   : E(write);
 3043     IALU  : R;
 3044 %}
 3045 
 3046 // Integer ALU reg-reg with carry operation
 3047 pipe_class ialu_reg_reg_cy(iRegI dst, iRegI src1, iRegI src2, iRegI cy) %{
 3048     single_instruction;
 3049     dst   : E(write);
 3050     src1  : R(read);
 3051     src2  : R(read);
 3052     IALU  : R;
 3053 %}
 3054 
 3055 // Integer ALU cc operation
 3056 pipe_class ialu_cc(iRegI dst, flagsReg cc) %{
 3057     single_instruction;
 3058     dst   : E(write);
 3059     cc    : R(read);
 3060     IALU  : R;
 3061 %}
 3062 
 3063 // Integer ALU cc / second IALU operation
 3064 pipe_class ialu_reg_ialu( iRegI dst, iRegI src ) %{
 3065     instruction_count(1); multiple_bundles;
 3066     dst   : E(write)+1;
 3067     src   : R(read);
 3068     IALU  : R;
 3069 %}
 3070 
 3071 // Integer ALU cc / second IALU operation
 3072 pipe_class ialu_reg_reg_ialu( iRegI dst, iRegI p, iRegI q ) %{
 3073     instruction_count(1); multiple_bundles;
 3074     dst   : E(write)+1;
 3075     p     : R(read);
 3076     q     : R(read);
 3077     IALU  : R;
 3078 %}
 3079 
 3080 // Integer ALU hi-lo-reg operation
 3081 pipe_class ialu_hi_lo_reg(iRegI dst, immI src) %{
 3082     instruction_count(1); multiple_bundles;
 3083     dst   : E(write)+1;
 3084     IALU  : R(2);
 3085 %}
 3086 
 3087 // Long Constant
 3088 pipe_class loadConL( iRegL dst, immL src ) %{
 3089     instruction_count(2); multiple_bundles;
 3090     dst   : E(write)+1;
 3091     IALU  : R(2);
 3092     IALU  : R(2);
 3093 %}
 3094 
 3095 // Pointer Constant
 3096 pipe_class loadConP( iRegP dst, immP src ) %{
 3097     instruction_count(0); multiple_bundles;
 3098     fixed_latency(6);
 3099 %}
 3100 
 3101 // Polling Address
 3102 pipe_class loadConP_poll( iRegP dst, immP_poll src ) %{
 3103     dst   : E(write);
 3104     IALU  : R;
 3105 %}
 3106 
 3107 // Long Constant small
 3108 pipe_class loadConLlo( iRegL dst, immL src ) %{
 3109     instruction_count(2);
 3110     dst   : E(write);
 3111     IALU  : R;
 3112     IALU  : R;
 3113 %}
 3114 
 3115 // [PHH] This is wrong for 64-bit.  See LdImmF/D.
 3116 pipe_class loadConFD(regF dst, immF src, iRegP tmp) %{
 3117     instruction_count(1); multiple_bundles;
 3118     src   : R(read);
 3119     dst   : M(write)+1;
 3120     IALU  : R;
 3121     MS    : E;
 3122 %}
 3123 
 3124 // Integer ALU nop operation
 3125 pipe_class ialu_nop() %{
 3126     single_instruction;
 3127     IALU  : R;
 3128 %}
 3129 
 3130 // Integer ALU nop operation
 3131 pipe_class ialu_nop_A0() %{
 3132     single_instruction;
 3133     A0    : R;
 3134 %}
 3135 
 3136 // Integer ALU nop operation
 3137 pipe_class ialu_nop_A1() %{
 3138     single_instruction;
 3139     A1    : R;
 3140 %}
 3141 
 3142 // Integer Multiply reg-reg operation
 3143 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 3144     single_instruction;
 3145     dst   : E(write);
 3146     src1  : R(read);
 3147     src2  : R(read);
 3148     MS    : R(5);
 3149 %}
 3150 
 3151 pipe_class mulL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 3152     single_instruction;
 3153     dst   : E(write)+4;
 3154     src1  : R(read);
 3155     src2  : R(read);
 3156     MS    : R(6);
 3157 %}
 3158 
 3159 // Integer Divide reg-reg
 3160 pipe_class sdiv_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI temp, flagsReg cr) %{
 3161     instruction_count(1); multiple_bundles;
 3162     dst   : E(write);
 3163     temp  : E(write);
 3164     src1  : R(read);
 3165     src2  : R(read);
 3166     temp  : R(read);
 3167     MS    : R(38);
 3168 %}
 3169 
 3170 // Long Divide
 3171 pipe_class divL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 3172     dst  : E(write)+71;
 3173     src1 : R(read);
 3174     src2 : R(read)+1;
 3175     MS   : R(70);
 3176 %}
 3177 
 3178 // Floating Point Add Float
 3179 pipe_class faddF_reg_reg(regF dst, regF src1, regF src2) %{
 3180     single_instruction;
 3181     dst   : X(write);
 3182     src1  : E(read);
 3183     src2  : E(read);
 3184     FA    : R;
 3185 %}
 3186 
 3187 // Floating Point Add Double
 3188 pipe_class faddD_reg_reg(regD dst, regD src1, regD src2) %{
 3189     single_instruction;
 3190     dst   : X(write);
 3191     src1  : E(read);
 3192     src2  : E(read);
 3193     FA    : R;
 3194 %}
 3195 
 3196 // Floating Point Conditional Move based on integer flags
 3197 pipe_class int_conditional_float_move (cmpOp cmp, flagsReg cr, regF dst, regF src) %{
 3198     single_instruction;
 3199     dst   : X(write);
 3200     src   : E(read);
 3201     cr    : R(read);
 3202     FA    : R(2);
 3203     BR    : R(2);
 3204 %}
 3205 
 3206 // Floating Point Conditional Move based on integer flags
 3207 pipe_class int_conditional_double_move (cmpOp cmp, flagsReg cr, regD dst, regD src) %{
 3208     single_instruction;
 3209     dst   : X(write);
 3210     src   : E(read);
 3211     cr    : R(read);
 3212     FA    : R(2);
 3213     BR    : R(2);
 3214 %}
 3215 
 3216 // Floating Point Multiply Float
 3217 pipe_class fmulF_reg_reg(regF dst, regF src1, regF src2) %{
 3218     single_instruction;
 3219     dst   : X(write);
 3220     src1  : E(read);
 3221     src2  : E(read);
 3222     FM    : R;
 3223 %}
 3224 
 3225 // Floating Point Multiply Double
 3226 pipe_class fmulD_reg_reg(regD dst, regD src1, regD src2) %{
 3227     single_instruction;
 3228     dst   : X(write);
 3229     src1  : E(read);
 3230     src2  : E(read);
 3231     FM    : R;
 3232 %}
 3233 
 3234 // Floating Point Divide Float
 3235 pipe_class fdivF_reg_reg(regF dst, regF src1, regF src2) %{
 3236     single_instruction;
 3237     dst   : X(write);
 3238     src1  : E(read);
 3239     src2  : E(read);
 3240     FM    : R;
 3241     FDIV  : C(14);
 3242 %}
 3243 
 3244 // Floating Point Divide Double
 3245 pipe_class fdivD_reg_reg(regD dst, regD src1, regD src2) %{
 3246     single_instruction;
 3247     dst   : X(write);
 3248     src1  : E(read);
 3249     src2  : E(read);
 3250     FM    : R;
 3251     FDIV  : C(17);
 3252 %}
 3253 
 3254 // Floating Point Move/Negate/Abs Float
 3255 pipe_class faddF_reg(regF dst, regF src) %{
 3256     single_instruction;
 3257     dst   : W(write);
 3258     src   : E(read);
 3259     FA    : R(1);
 3260 %}
 3261 
 3262 // Floating Point Move/Negate/Abs Double
 3263 pipe_class faddD_reg(regD dst, regD src) %{
 3264     single_instruction;
 3265     dst   : W(write);
 3266     src   : E(read);
 3267     FA    : R;
 3268 %}
 3269 
 3270 // Floating Point Convert F-&gt;D
 3271 pipe_class fcvtF2D(regD dst, regF src) %{
 3272     single_instruction;
 3273     dst   : X(write);
 3274     src   : E(read);
 3275     FA    : R;
 3276 %}
 3277 
 3278 // Floating Point Convert I-&gt;D
 3279 pipe_class fcvtI2D(regD dst, regF src) %{
 3280     single_instruction;
 3281     dst   : X(write);
 3282     src   : E(read);
 3283     FA    : R;
 3284 %}
 3285 
 3286 // Floating Point Convert LHi-&gt;D
 3287 pipe_class fcvtLHi2D(regD dst, regD src) %{
 3288     single_instruction;
 3289     dst   : X(write);
 3290     src   : E(read);
 3291     FA    : R;
 3292 %}
 3293 
 3294 // Floating Point Convert L-&gt;D
 3295 pipe_class fcvtL2D(regD dst, iRegL src) %{
 3296     single_instruction;
 3297     dst   : X(write);
 3298     src   : E(read);
 3299     FA    : R;
 3300 %}
 3301 
 3302 // Floating Point Convert L-&gt;F
 3303 pipe_class fcvtL2F(regF dst, iRegL src) %{
 3304     single_instruction;
 3305     dst   : X(write);
 3306     src   : E(read);
 3307     FA    : R;
 3308 %}
 3309 
 3310 // Floating Point Convert D-&gt;F
 3311 pipe_class fcvtD2F(regD dst, regF src) %{
 3312     single_instruction;
 3313     dst   : X(write);
 3314     src   : E(read);
 3315     FA    : R;
 3316 %}
 3317 
 3318 // Floating Point Convert I-&gt;L
 3319 pipe_class fcvtI2L(regD dst, regF src) %{
 3320     single_instruction;
 3321     dst   : X(write);
 3322     src   : E(read);
 3323     FA    : R;
 3324 %}
 3325 
 3326 // Floating Point Convert D-&gt;F
 3327 pipe_class fcvtD2I(iRegI dst, regD src, flagsReg cr) %{
 3328     instruction_count(1); multiple_bundles;
 3329     dst   : X(write)+6;
 3330     src   : E(read);
 3331     FA    : R;
 3332 %}
 3333 
 3334 // Floating Point Convert D-&gt;L
 3335 pipe_class fcvtD2L(regD dst, regD src, flagsReg cr) %{
 3336     instruction_count(1); multiple_bundles;
 3337     dst   : X(write)+6;
 3338     src   : E(read);
 3339     FA    : R;
 3340 %}
 3341 
 3342 // Floating Point Convert F-&gt;I
 3343 pipe_class fcvtF2I(regF dst, regF src, flagsReg cr) %{
 3344     instruction_count(1); multiple_bundles;
 3345     dst   : X(write)+6;
 3346     src   : E(read);
 3347     FA    : R;
 3348 %}
 3349 
 3350 // Floating Point Convert F-&gt;L
 3351 pipe_class fcvtF2L(regD dst, regF src, flagsReg cr) %{
 3352     instruction_count(1); multiple_bundles;
 3353     dst   : X(write)+6;
 3354     src   : E(read);
 3355     FA    : R;
 3356 %}
 3357 
 3358 // Floating Point Convert I-&gt;F
 3359 pipe_class fcvtI2F(regF dst, regF src) %{
 3360     single_instruction;
 3361     dst   : X(write);
 3362     src   : E(read);
 3363     FA    : R;
 3364 %}
 3365 
 3366 // Floating Point Compare
 3367 pipe_class faddF_fcc_reg_reg_zero(flagsRegF cr, regF src1, regF src2, immI0 zero) %{
 3368     single_instruction;
 3369     cr    : X(write);
 3370     src1  : E(read);
 3371     src2  : E(read);
 3372     FA    : R;
 3373 %}
 3374 
 3375 // Floating Point Compare
 3376 pipe_class faddD_fcc_reg_reg_zero(flagsRegF cr, regD src1, regD src2, immI0 zero) %{
 3377     single_instruction;
 3378     cr    : X(write);
 3379     src1  : E(read);
 3380     src2  : E(read);
 3381     FA    : R;
 3382 %}
 3383 
 3384 // Floating Add Nop
 3385 pipe_class fadd_nop() %{
 3386     single_instruction;
 3387     FA  : R;
 3388 %}
 3389 
 3390 // Integer Store to Memory
 3391 pipe_class istore_mem_reg(memoryI mem, iRegI src) %{
 3392     single_instruction;
 3393     mem   : R(read);
 3394     src   : C(read);
 3395     MS    : R;
 3396 %}
 3397 
 3398 // Integer Store to Memory
 3399 pipe_class istore_mem_spORreg(memoryI mem, sp_ptr_RegP src) %{
 3400     single_instruction;
 3401     mem   : R(read);
 3402     src   : C(read);
 3403     MS    : R;
 3404 %}
 3405 
 3406 // Float Store
 3407 pipe_class fstoreF_mem_reg(memoryF mem, RegF src) %{
 3408     single_instruction;
 3409     mem : R(read);
 3410     src : C(read);
 3411     MS  : R;
 3412 %}
 3413 
 3414 // Float Store
 3415 pipe_class fstoreF_mem_zero(memoryF mem, immF0 src) %{
 3416     single_instruction;
 3417     mem : R(read);
 3418     MS  : R;
 3419 %}
 3420 
 3421 // Double Store
 3422 pipe_class fstoreD_mem_reg(memoryD mem, RegD src) %{
 3423     instruction_count(1);
 3424     mem : R(read);
 3425     src : C(read);
 3426     MS  : R;
 3427 %}
 3428 
 3429 // Double Store
 3430 pipe_class fstoreD_mem_zero(memoryD mem, immD0 src) %{
 3431     single_instruction;
 3432     mem : R(read);
 3433     MS  : R;
 3434 %}
 3435 
 3436 // Integer Load (when sign bit propagation not needed)
 3437 pipe_class iload_mem(iRegI dst, memoryI mem) %{
 3438     single_instruction;
 3439     mem : R(read);
 3440     dst : C(write);
 3441     MS  : R;
 3442 %}
 3443 
 3444 // Integer Load (when sign bit propagation or masking is needed)
 3445 pipe_class iload_mask_mem(iRegI dst, memoryI mem) %{
 3446     single_instruction;
 3447     mem : R(read);
 3448     dst : M(write);
 3449     MS  : R;
 3450 %}
 3451 
 3452 // Float Load
 3453 pipe_class floadF_mem(regF dst, memoryF mem) %{
 3454     single_instruction;
 3455     mem : R(read);
 3456     dst : M(write);
 3457     MS  : R;
 3458 %}
 3459 
 3460 // Float Load
 3461 pipe_class floadD_mem(regD dst, memoryD mem) %{
 3462     instruction_count(1); multiple_bundles; // Again, unaligned argument is only multiple case
 3463     mem : R(read);
 3464     dst : M(write);
 3465     MS  : R;
 3466 %}
 3467 
 3468 // Memory Nop
 3469 pipe_class mem_nop() %{
 3470     single_instruction;
 3471     MS  : R;
 3472 %}
 3473 
 3474 pipe_class sethi(iRegP dst, immI src) %{
 3475     single_instruction;
 3476     dst  : E(write);
 3477     IALU : R;
 3478 %}
 3479 
 3480 pipe_class loadPollP(iRegP poll) %{
 3481     single_instruction;
 3482     poll : R(read);
 3483     MS   : R;
 3484 %}
 3485 
 3486 pipe_class br(Universe br, label labl) %{
 3487     single_instruction_with_delay_slot;
 3488     BR  : R;
 3489 %}
 3490 
 3491 pipe_class br_cc(Universe br, cmpOp cmp, flagsReg cr, label labl) %{
 3492     single_instruction_with_delay_slot;
 3493     cr    : E(read);
 3494     BR    : R;
 3495 %}
 3496 
 3497 pipe_class br_reg(Universe br, cmpOp cmp, iRegI op1, label labl) %{
 3498     single_instruction_with_delay_slot;
 3499     op1 : E(read);
 3500     BR  : R;
 3501     MS  : R;
 3502 %}
 3503 
 3504 pipe_class br_nop() %{
 3505     single_instruction;
 3506     BR  : R;
 3507 %}
 3508 
 3509 pipe_class simple_call(method meth) %{
 3510     instruction_count(2); multiple_bundles; force_serialization;
 3511     fixed_latency(100);
 3512     BR  : R(1);
 3513     MS  : R(1);
 3514     A0  : R(1);
 3515 %}
 3516 
 3517 pipe_class compiled_call(method meth) %{
 3518     instruction_count(1); multiple_bundles; force_serialization;
 3519     fixed_latency(100);
 3520     MS  : R(1);
 3521 %}
 3522 
 3523 pipe_class call(method meth) %{
 3524     instruction_count(0); multiple_bundles; force_serialization;
 3525     fixed_latency(100);
 3526 %}
 3527 
 3528 pipe_class tail_call(Universe ignore, label labl) %{
 3529     single_instruction; has_delay_slot;
 3530     fixed_latency(100);
 3531     BR  : R(1);
 3532     MS  : R(1);
 3533 %}
 3534 
 3535 pipe_class ret(Universe ignore) %{
 3536     single_instruction; has_delay_slot;
 3537     BR  : R(1);
 3538     MS  : R(1);
 3539 %}
 3540 
 3541 // The real do-nothing guy
 3542 pipe_class empty( ) %{
 3543     instruction_count(0);
 3544 %}
 3545 
 3546 pipe_class long_memory_op() %{
 3547     instruction_count(0); multiple_bundles; force_serialization;
 3548     fixed_latency(25);
 3549     MS  : R(1);
 3550 %}
 3551 
 3552 // Check-cast
 3553 pipe_class partial_subtype_check_pipe(Universe ignore, iRegP array, iRegP match ) %{
 3554     array : R(read);
 3555     match  : R(read);
 3556     IALU   : R(2);
 3557     BR     : R(2);
 3558     MS     : R;
 3559 %}
 3560 
 3561 // Convert FPU flags into +1,0,-1
 3562 pipe_class floating_cmp( iRegI dst, regF src1, regF src2 ) %{
 3563     src1  : E(read);
 3564     src2  : E(read);
 3565     dst   : E(write);
 3566     FA    : R;
 3567     MS    : R(2);
 3568     BR    : R(2);
 3569 %}
 3570 
 3571 // Compare for p &lt; q, and conditionally add y
 3572 pipe_class cadd_cmpltmask( iRegI p, iRegI q, iRegI y ) %{
 3573     p     : E(read);
 3574     q     : E(read);
 3575     y     : E(read);
 3576     IALU  : R(3)
 3577 %}
 3578 
 3579 // Perform a compare, then move conditionally in a branch delay slot.
 3580 pipe_class min_max( iRegI src2, iRegI srcdst ) %{
 3581     src2   : E(read);
 3582     srcdst : E(read);
 3583     IALU   : R;
 3584     BR     : R;
 3585 %}
 3586 
 3587 // Define the class for the Nop node
 3588 define %{
 3589    MachNop = ialu_nop;
 3590 %}
 3591 
 3592 %}
 3593 
 3594 //----------INSTRUCTIONS-------------------------------------------------------
 3595 
 3596 //------------Special Nop instructions for bundling - no match rules-----------
 3597 // Nop using the A0 functional unit
 3598 instruct Nop_A0() %{
 3599   ins_pipe(ialu_nop_A0);
 3600 %}
 3601 
 3602 // Nop using the A1 functional unit
 3603 instruct Nop_A1( ) %{
 3604   ins_pipe(ialu_nop_A1);
 3605 %}
 3606 
 3607 // Nop using the memory functional unit
 3608 instruct Nop_MS( ) %{
 3609   ins_pipe(mem_nop);
 3610 %}
 3611 
 3612 // Nop using the floating add functional unit
 3613 instruct Nop_FA( ) %{
 3614   ins_pipe(fadd_nop);
 3615 %}
 3616 
 3617 // Nop using the branch functional unit
 3618 instruct Nop_BR( ) %{
 3619   ins_pipe(br_nop);
 3620 %}
 3621 
 3622 //----------Load/Store/Move Instructions---------------------------------------
 3623 //----------Load Instructions--------------------------------------------------
 3624 // Load Byte (8bit signed)
 3625 instruct loadB(iRegI dst, memoryB mem) %{
 3626   match(Set dst (LoadB mem));
 3627   ins_cost(MEMORY_REF_COST);
 3628 
 3629   size(4);
 3630   format %{ &quot;LDRSB   $dst,$mem\t! byte -&gt; int&quot; %}
 3631   ins_encode %{
 3632     __ ldrsb($dst$$Register, $mem$$Address);
 3633   %}
 3634   ins_pipe(iload_mask_mem);
 3635 %}
 3636 
 3637 // Load Byte (8bit signed) into a Long Register
 3638 instruct loadB2L(iRegL dst, memoryB mem) %{
 3639   match(Set dst (ConvI2L (LoadB mem)));
 3640   ins_cost(MEMORY_REF_COST);
 3641 
 3642   size(8);
 3643   format %{ &quot;LDRSB $dst.lo,$mem\t! byte -&gt; long\n\t&quot;
 3644             &quot;ASR   $dst.hi,$dst.lo,31&quot; %}
 3645   ins_encode %{
 3646     __ ldrsb($dst$$Register, $mem$$Address);
 3647     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3648   %}
 3649   ins_pipe(iload_mask_mem);
 3650 %}
 3651 
 3652 // Load Unsigned Byte (8bit UNsigned) into an int reg
 3653 instruct loadUB(iRegI dst, memoryB mem) %{
 3654   match(Set dst (LoadUB mem));
 3655   ins_cost(MEMORY_REF_COST);
 3656 
 3657   size(4);
 3658   format %{ &quot;LDRB   $dst,$mem\t! ubyte -&gt; int&quot; %}
 3659   ins_encode %{
 3660     __ ldrb($dst$$Register, $mem$$Address);
 3661   %}
 3662   ins_pipe(iload_mem);
 3663 %}
 3664 
 3665 // Load Unsigned Byte (8bit UNsigned) into a Long Register
 3666 instruct loadUB2L(iRegL dst, memoryB mem) %{
 3667   match(Set dst (ConvI2L (LoadUB mem)));
 3668   ins_cost(MEMORY_REF_COST);
 3669 
 3670   size(8);
 3671   format %{ &quot;LDRB  $dst.lo,$mem\t! ubyte -&gt; long\n\t&quot;
 3672             &quot;MOV   $dst.hi,0&quot; %}
 3673   ins_encode %{
 3674     __ ldrb($dst$$Register, $mem$$Address);
 3675     __ mov($dst$$Register-&gt;successor(), 0);
 3676   %}
 3677   ins_pipe(iload_mem);
 3678 %}
 3679 
 3680 // Load Unsigned Byte (8 bit UNsigned) with immediate mask into Long Register
 3681 instruct loadUB2L_limmI(iRegL dst, memoryB mem, limmIlow8 mask) %{
 3682   match(Set dst (ConvI2L (AndI (LoadUB mem) mask)));
 3683 
 3684   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3685   size(12);
 3686   format %{ &quot;LDRB  $dst.lo,$mem\t! ubyte -&gt; long\n\t&quot;
 3687             &quot;MOV   $dst.hi,0\n\t&quot;
 3688             &quot;AND  $dst.lo,$dst.lo,$mask&quot; %}
 3689   ins_encode %{
 3690     __ ldrb($dst$$Register, $mem$$Address);
 3691     __ mov($dst$$Register-&gt;successor(), 0);
 3692     __ andr($dst$$Register, $dst$$Register, limmI_low($mask$$constant, 8));
 3693   %}
 3694   ins_pipe(iload_mem);
 3695 %}
 3696 
 3697 // Load Short (16bit signed)
 3698 
 3699 instruct loadS(iRegI dst, memoryS mem) %{
 3700   match(Set dst (LoadS mem));
 3701   ins_cost(MEMORY_REF_COST);
 3702 
 3703   size(4);
 3704   format %{ &quot;LDRSH   $dst,$mem\t! short&quot; %}
 3705   ins_encode %{
 3706     __ ldrsh($dst$$Register, $mem$$Address);
 3707   %}
 3708   ins_pipe(iload_mask_mem);
 3709 %}
 3710 
 3711 // Load Short (16 bit signed) to Byte (8 bit signed)
 3712 instruct loadS2B(iRegI dst, memoryS mem, immI_24 twentyfour) %{
 3713   match(Set dst (RShiftI (LShiftI (LoadS mem) twentyfour) twentyfour));
 3714   ins_cost(MEMORY_REF_COST);
 3715 
 3716   size(4);
 3717 
 3718   format %{ &quot;LDRSB   $dst,$mem\t! short -&gt; byte&quot; %}
 3719   ins_encode %{
 3720     __ ldrsb($dst$$Register, $mem$$Address);
 3721   %}
 3722   ins_pipe(iload_mask_mem);
 3723 %}
 3724 
 3725 // Load Short (16bit signed) into a Long Register
 3726 instruct loadS2L(iRegL dst, memoryS mem) %{
 3727   match(Set dst (ConvI2L (LoadS mem)));
 3728   ins_cost(MEMORY_REF_COST);
 3729 
 3730   size(8);
 3731   format %{ &quot;LDRSH $dst.lo,$mem\t! short -&gt; long\n\t&quot;
 3732             &quot;ASR   $dst.hi,$dst.lo,31&quot; %}
 3733   ins_encode %{
 3734     __ ldrsh($dst$$Register, $mem$$Address);
 3735     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3736   %}
 3737   ins_pipe(iload_mask_mem);
 3738 %}
 3739 
 3740 // Load Unsigned Short/Char (16bit UNsigned)
 3741 
 3742 
 3743 instruct loadUS(iRegI dst, memoryS mem) %{
 3744   match(Set dst (LoadUS mem));
 3745   ins_cost(MEMORY_REF_COST);
 3746 
 3747   size(4);
 3748   format %{ &quot;LDRH   $dst,$mem\t! ushort/char&quot; %}
 3749   ins_encode %{
 3750     __ ldrh($dst$$Register, $mem$$Address);
 3751   %}
 3752   ins_pipe(iload_mem);
 3753 %}
 3754 
 3755 // Load Unsigned Short/Char (16 bit UNsigned) to Byte (8 bit signed)
 3756 instruct loadUS2B(iRegI dst, memoryB mem, immI_24 twentyfour) %{
 3757   match(Set dst (RShiftI (LShiftI (LoadUS mem) twentyfour) twentyfour));
 3758   ins_cost(MEMORY_REF_COST);
 3759 
 3760   size(4);
 3761   format %{ &quot;LDRSB   $dst,$mem\t! ushort -&gt; byte&quot; %}
 3762   ins_encode %{
 3763     __ ldrsb($dst$$Register, $mem$$Address);
 3764   %}
 3765   ins_pipe(iload_mask_mem);
 3766 %}
 3767 
 3768 // Load Unsigned Short/Char (16bit UNsigned) into a Long Register
 3769 instruct loadUS2L(iRegL dst, memoryS mem) %{
 3770   match(Set dst (ConvI2L (LoadUS mem)));
 3771   ins_cost(MEMORY_REF_COST);
 3772 
 3773   size(8);
 3774   format %{ &quot;LDRH  $dst.lo,$mem\t! short -&gt; long\n\t&quot;
 3775             &quot;MOV   $dst.hi, 0&quot; %}
 3776   ins_encode %{
 3777     __ ldrh($dst$$Register, $mem$$Address);
 3778     __ mov($dst$$Register-&gt;successor(), 0);
 3779   %}
 3780   ins_pipe(iload_mem);
 3781 %}
 3782 
 3783 // Load Unsigned Short/Char (16bit UNsigned) with mask 0xFF into a Long Register
 3784 instruct loadUS2L_immI_255(iRegL dst, memoryB mem, immI_255 mask) %{
 3785   match(Set dst (ConvI2L (AndI (LoadUS mem) mask)));
 3786   ins_cost(MEMORY_REF_COST);
 3787 
 3788   size(8);
 3789   format %{ &quot;LDRB  $dst.lo,$mem\t! \n\t&quot;
 3790             &quot;MOV   $dst.hi, 0&quot; %}
 3791   ins_encode %{
 3792     __ ldrb($dst$$Register, $mem$$Address);
 3793     __ mov($dst$$Register-&gt;successor(), 0);
 3794   %}
 3795   ins_pipe(iload_mem);
 3796 %}
 3797 
 3798 // Load Unsigned Short/Char (16bit UNsigned) with a immediate mask into a Long Register
 3799 instruct loadUS2L_limmI(iRegL dst, memoryS mem, limmI mask) %{
 3800   match(Set dst (ConvI2L (AndI (LoadUS mem) mask)));
 3801   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3802 
 3803   size(12);
 3804   format %{ &quot;LDRH   $dst,$mem\t! ushort/char &amp; mask -&gt; long\n\t&quot;
 3805             &quot;MOV    $dst.hi, 0\n\t&quot;
 3806             &quot;AND    $dst,$dst,$mask&quot; %}
 3807   ins_encode %{
 3808     __ ldrh($dst$$Register, $mem$$Address);
 3809     __ mov($dst$$Register-&gt;successor(), 0);
 3810     __ andr($dst$$Register, $dst$$Register, $mask$$constant);
 3811   %}
 3812   ins_pipe(iload_mem);
 3813 %}
 3814 
 3815 // Load Integer
 3816 
 3817 
 3818 instruct loadI(iRegI dst, memoryI mem) %{
 3819   match(Set dst (LoadI mem));
 3820   ins_cost(MEMORY_REF_COST);
 3821 
 3822   size(4);
 3823   format %{ &quot;ldr_s32 $dst,$mem\t! int&quot; %}
 3824   ins_encode %{
 3825     __ ldr_s32($dst$$Register, $mem$$Address);
 3826   %}
 3827   ins_pipe(iload_mem);
 3828 %}
 3829 
 3830 // Load Integer to Byte (8 bit signed)
 3831 instruct loadI2B(iRegI dst, memoryS mem, immI_24 twentyfour) %{
 3832   match(Set dst (RShiftI (LShiftI (LoadI mem) twentyfour) twentyfour));
 3833   ins_cost(MEMORY_REF_COST);
 3834 
 3835   size(4);
 3836 
 3837   format %{ &quot;LDRSB   $dst,$mem\t! int -&gt; byte&quot; %}
 3838   ins_encode %{
 3839     __ ldrsb($dst$$Register, $mem$$Address);
 3840   %}
 3841   ins_pipe(iload_mask_mem);
 3842 %}
 3843 
 3844 // Load Integer to Unsigned Byte (8 bit UNsigned)
 3845 instruct loadI2UB(iRegI dst, memoryB mem, immI_255 mask) %{
 3846   match(Set dst (AndI (LoadI mem) mask));
 3847   ins_cost(MEMORY_REF_COST);
 3848 
 3849   size(4);
 3850 
 3851   format %{ &quot;LDRB   $dst,$mem\t! int -&gt; ubyte&quot; %}
 3852   ins_encode %{
 3853     __ ldrb($dst$$Register, $mem$$Address);
 3854   %}
 3855   ins_pipe(iload_mask_mem);
 3856 %}
 3857 
 3858 // Load Integer to Short (16 bit signed)
 3859 instruct loadI2S(iRegI dst, memoryS mem, immI_16 sixteen) %{
 3860   match(Set dst (RShiftI (LShiftI (LoadI mem) sixteen) sixteen));
 3861   ins_cost(MEMORY_REF_COST);
 3862 
 3863   size(4);
 3864   format %{ &quot;LDRSH   $dst,$mem\t! int -&gt; short&quot; %}
 3865   ins_encode %{
 3866     __ ldrsh($dst$$Register, $mem$$Address);
 3867   %}
 3868   ins_pipe(iload_mask_mem);
 3869 %}
 3870 
 3871 // Load Integer to Unsigned Short (16 bit UNsigned)
 3872 instruct loadI2US(iRegI dst, memoryS mem, immI_65535 mask) %{
 3873   match(Set dst (AndI (LoadI mem) mask));
 3874   ins_cost(MEMORY_REF_COST);
 3875 
 3876   size(4);
 3877   format %{ &quot;LDRH   $dst,$mem\t! int -&gt; ushort/char&quot; %}
 3878   ins_encode %{
 3879     __ ldrh($dst$$Register, $mem$$Address);
 3880   %}
 3881   ins_pipe(iload_mask_mem);
 3882 %}
 3883 
 3884 // Load Integer into a Long Register
 3885 instruct loadI2L(iRegL dst, memoryI mem) %{
 3886   match(Set dst (ConvI2L (LoadI mem)));
 3887   ins_cost(MEMORY_REF_COST);
 3888 
 3889   size(8);
 3890   format %{ &quot;LDR   $dst.lo,$mem\t! int -&gt; long\n\t&quot;
 3891             &quot;ASR   $dst.hi,$dst.lo,31\t! int-&gt;long&quot; %}
 3892   ins_encode %{
 3893     __ ldr($dst$$Register, $mem$$Address);
 3894     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3895   %}
 3896   ins_pipe(iload_mask_mem);
 3897 %}
 3898 
 3899 // Load Integer with mask 0xFF into a Long Register
 3900 instruct loadI2L_immI_255(iRegL dst, memoryB mem, immI_255 mask) %{
 3901   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3902   ins_cost(MEMORY_REF_COST);
 3903 
 3904   size(8);
 3905   format %{ &quot;LDRB   $dst.lo,$mem\t! int &amp; 0xFF -&gt; long\n\t&quot;
 3906             &quot;MOV    $dst.hi, 0&quot; %}
 3907   ins_encode %{
 3908     __ ldrb($dst$$Register, $mem$$Address);
 3909     __ mov($dst$$Register-&gt;successor(), 0);
 3910   %}
 3911   ins_pipe(iload_mem);
 3912 %}
 3913 
 3914 // Load Integer with mask 0xFFFF into a Long Register
 3915 instruct loadI2L_immI_65535(iRegL dst, memoryS mem, immI_65535 mask) %{
 3916   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3917   ins_cost(MEMORY_REF_COST);
 3918 
 3919   size(8);
 3920   format %{ &quot;LDRH   $dst,$mem\t! int &amp; 0xFFFF -&gt; long\n\t&quot;
 3921             &quot;MOV    $dst.hi, 0&quot; %}
 3922   ins_encode %{
 3923     __ ldrh($dst$$Register, $mem$$Address);
 3924     __ mov($dst$$Register-&gt;successor(), 0);
 3925   %}
 3926   ins_pipe(iload_mask_mem);
 3927 %}
 3928 
 3929 // Load Integer with a 31-bit immediate mask into a Long Register
 3930 instruct loadI2L_limmU31(iRegL dst, memoryI mem, limmU31 mask) %{
 3931   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3932   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3933 
 3934   size(12);
 3935   format %{ &quot;LDR   $dst.lo,$mem\t! int -&gt; long\n\t&quot;
 3936             &quot;MOV    $dst.hi, 0\n\t&quot;
 3937             &quot;AND   $dst,$dst,$mask&quot; %}
 3938 
 3939   ins_encode %{
 3940     __ ldr($dst$$Register, $mem$$Address);
 3941     __ mov($dst$$Register-&gt;successor(), 0);
 3942     __ andr($dst$$Register, $dst$$Register, $mask$$constant);
 3943   %}
 3944   ins_pipe(iload_mem);
 3945 %}
 3946 
 3947 // Load Integer with a 31-bit mask into a Long Register
 3948 // FIXME: use iRegI mask, remove tmp?
 3949 instruct loadI2L_immU31(iRegL dst, memoryI mem, immU31 mask, iRegI tmp) %{
 3950   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3951   effect(TEMP dst, TEMP tmp);
 3952 
 3953   ins_cost(MEMORY_REF_COST + 4*DEFAULT_COST);
 3954   size(20);
 3955   format %{ &quot;LDR      $mem,$dst\t! int &amp; 31-bit mask -&gt; long\n\t&quot;
 3956             &quot;MOV      $dst.hi, 0\n\t&quot;
 3957             &quot;MOV_SLOW $tmp,$mask\n\t&quot;
 3958             &quot;AND      $dst,$tmp,$dst&quot; %}
 3959   ins_encode %{
 3960     __ ldr($dst$$Register, $mem$$Address);
 3961     __ mov($dst$$Register-&gt;successor(), 0);
 3962     __ mov_slow($tmp$$Register, $mask$$constant);
 3963     __ andr($dst$$Register, $dst$$Register, $tmp$$Register);
 3964   %}
 3965   ins_pipe(iload_mem);
 3966 %}
 3967 
 3968 // Load Unsigned Integer into a Long Register
 3969 instruct loadUI2L(iRegL dst, memoryI mem, immL_32bits mask) %{
 3970   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 3971   ins_cost(MEMORY_REF_COST);
 3972 
 3973   size(8);
 3974   format %{ &quot;LDR   $dst.lo,$mem\t! uint -&gt; long\n\t&quot;
 3975             &quot;MOV   $dst.hi,0&quot; %}
 3976   ins_encode %{
 3977     __ ldr($dst$$Register, $mem$$Address);
 3978     __ mov($dst$$Register-&gt;successor(), 0);
 3979   %}
 3980   ins_pipe(iload_mem);
 3981 %}
 3982 
 3983 // Load Long
 3984 
 3985 
 3986 instruct loadL(iRegLd dst, memoryL mem ) %{
 3987   predicate(!((LoadLNode*)n)-&gt;require_atomic_access());
 3988   match(Set dst (LoadL mem));
 3989   effect(TEMP dst);
 3990   ins_cost(MEMORY_REF_COST);
 3991 
 3992   size(4);
 3993   format %{ &quot;ldr_64  $dst,$mem\t! long&quot; %}
 3994   ins_encode %{
 3995     __ ldr_64($dst$$Register, $mem$$Address);
 3996   %}
 3997   ins_pipe(iload_mem);
 3998 %}
 3999 
 4000 instruct loadL_2instr(iRegL dst, memorylong mem ) %{
 4001   predicate(!((LoadLNode*)n)-&gt;require_atomic_access());
 4002   match(Set dst (LoadL mem));
 4003   ins_cost(MEMORY_REF_COST + DEFAULT_COST);
 4004 
 4005   size(8);
 4006   format %{ &quot;LDR    $dst.lo,$mem \t! long order of instrs reversed if $dst.lo == base($mem)\n\t&quot;
 4007             &quot;LDR    $dst.hi,$mem+4 or $mem&quot; %}
 4008   ins_encode %{
 4009     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4010     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4011 
 4012     if ($dst$$Register == reg_to_register_object($mem$$base)) {
 4013       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4014       __ ldr($dst$$Register, Amemlo);
 4015     } else {
 4016       __ ldr($dst$$Register, Amemlo);
 4017       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4018     }
 4019   %}
 4020   ins_pipe(iload_mem);
 4021 %}
 4022 
 4023 instruct loadL_volatile(iRegL dst, indirect mem ) %{
 4024   predicate(((LoadLNode*)n)-&gt;require_atomic_access());
 4025   match(Set dst (LoadL mem));
 4026   ins_cost(MEMORY_REF_COST);
 4027 
 4028   size(4);
 4029   format %{ &quot;LDMIA    $dst,$mem\t! long&quot; %}
 4030   ins_encode %{
 4031     // FIXME: why is ldmia considered atomic?  Should be ldrexd
 4032     RegisterSet set($dst$$Register);
 4033     set = set | reg_to_register_object($dst$$reg + 1);
 4034     __ ldmia(reg_to_register_object($mem$$base), set);
 4035   %}
 4036   ins_pipe(iload_mem);
 4037 %}
 4038 
 4039 instruct loadL_volatile_fp(iRegL dst, memoryD mem ) %{
 4040   predicate(((LoadLNode*)n)-&gt;require_atomic_access());
 4041   match(Set dst (LoadL mem));
 4042   ins_cost(MEMORY_REF_COST);
 4043 
 4044   size(8);
 4045   format %{ &quot;FLDD      S14, $mem&quot;
 4046             &quot;FMRRD    $dst, S14\t! long \n&#39;t&quot; %}
 4047   ins_encode %{
 4048     __ fldd(S14, $mem$$Address);
 4049     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), S14);
 4050   %}
 4051   ins_pipe(iload_mem);
 4052 %}
 4053 
 4054 instruct loadL_unaligned(iRegL dst, memorylong mem ) %{
 4055   match(Set dst (LoadL_unaligned mem));
 4056   ins_cost(MEMORY_REF_COST);
 4057 
 4058   size(8);
 4059   format %{ &quot;LDR    $dst.lo,$mem\t! long order of instrs reversed if $dst.lo == base($mem)\n\t&quot;
 4060             &quot;LDR    $dst.hi,$mem+4&quot; %}
 4061   ins_encode %{
 4062     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4063     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4064 
 4065     if ($dst$$Register == reg_to_register_object($mem$$base)) {
 4066       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4067       __ ldr($dst$$Register, Amemlo);
 4068     } else {
 4069       __ ldr($dst$$Register, Amemlo);
 4070       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4071     }
 4072   %}
 4073   ins_pipe(iload_mem);
 4074 %}
 4075 
 4076 // Load Range
 4077 instruct loadRange(iRegI dst, memoryI mem) %{
 4078   match(Set dst (LoadRange mem));
 4079   ins_cost(MEMORY_REF_COST);
 4080 
 4081   size(4);
 4082   format %{ &quot;LDR_u32 $dst,$mem\t! range&quot; %}
 4083   ins_encode %{
 4084     __ ldr_u32($dst$$Register, $mem$$Address);
 4085   %}
 4086   ins_pipe(iload_mem);
 4087 %}
 4088 
 4089 // Load Pointer
 4090 
 4091 
 4092 instruct loadP(iRegP dst, memoryP mem) %{
 4093   match(Set dst (LoadP mem));
 4094   ins_cost(MEMORY_REF_COST);
 4095   size(4);
 4096 
 4097   format %{ &quot;LDR   $dst,$mem\t! ptr&quot; %}
 4098   ins_encode %{
 4099     __ ldr($dst$$Register, $mem$$Address);
 4100   %}
 4101   ins_pipe(iload_mem);
 4102 %}
 4103 
 4104 #ifdef XXX
 4105 // FIXME XXXX
 4106 //instruct loadSP(iRegP dst, memoryP mem) %{
 4107 instruct loadSP(SPRegP dst, memoryP mem, iRegP tmp) %{
 4108   match(Set dst (LoadP mem));
 4109   effect(TEMP tmp);
 4110   ins_cost(MEMORY_REF_COST+1);
 4111   size(8);
 4112 
 4113   format %{ &quot;LDR   $tmp,$mem\t! ptr\n\t&quot;
 4114             &quot;MOV   $dst,$tmp\t! ptr&quot; %}
 4115   ins_encode %{
 4116     __ ldr($tmp$$Register, $mem$$Address);
 4117     __ mov($dst$$Register, $tmp$$Register);
 4118   %}
 4119   ins_pipe(iload_mem);
 4120 %}
 4121 #endif
 4122 
 4123 #ifdef _LP64
 4124 // Load Compressed Pointer
 4125 
 4126 // XXX This variant shouldn&#39;t be necessary if 6217251 is implemented
 4127 instruct loadNoff(iRegN dst, memoryScaledI mem, aimmX off, iRegP tmp) %{
 4128   match(Set dst (LoadN (AddP mem off)));
 4129   ins_cost(MEMORY_REF_COST + DEFAULT_COST); // assume shift/sign-extend is free
 4130   effect(TEMP tmp);
 4131   size(4 * 2);
 4132 
 4133   format %{ &quot;ldr_u32 $dst,$mem+$off\t! compressed ptr temp=$tmp&quot; %}
 4134   ins_encode %{
 4135     Register base = reg_to_register_object($mem$$base);
 4136     __ add($tmp$$Register, base, $off$$constant);
 4137     Address nmem = Address::make_raw($tmp$$reg, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4138     __ ldr_u32($dst$$Register, nmem);
 4139   %}
 4140   ins_pipe(iload_mem);
 4141 %}
 4142 
 4143 instruct loadN(iRegN dst, memoryI mem) %{
 4144   match(Set dst (LoadN mem));
 4145   ins_cost(MEMORY_REF_COST);
 4146   size(4);
 4147 
 4148   format %{ &quot;ldr_u32 $dst,$mem\t! compressed ptr&quot; %}
 4149   ins_encode %{
 4150     __ ldr_u32($dst$$Register, $mem$$Address);
 4151   %}
 4152   ins_pipe(iload_mem);
 4153 %}
 4154 #endif
 4155 
 4156 // Load Klass Pointer
 4157 instruct loadKlass(iRegP dst, memoryI mem) %{
 4158   match(Set dst (LoadKlass mem));
 4159   ins_cost(MEMORY_REF_COST);
 4160   size(4);
 4161 
 4162   format %{ &quot;LDR   $dst,$mem\t! klass ptr&quot; %}
 4163   ins_encode %{
 4164     __ ldr($dst$$Register, $mem$$Address);
 4165   %}
 4166   ins_pipe(iload_mem);
 4167 %}
 4168 
 4169 #ifdef _LP64
 4170 // Load narrow Klass Pointer
 4171 instruct loadNKlass(iRegN dst, memoryI mem) %{
 4172   match(Set dst (LoadNKlass mem));
 4173   ins_cost(MEMORY_REF_COST);
 4174   size(4);
 4175 
 4176   format %{ &quot;ldr_u32 $dst,$mem\t! compressed klass ptr&quot; %}
 4177   ins_encode %{
 4178     __ ldr_u32($dst$$Register, $mem$$Address);
 4179   %}
 4180   ins_pipe(iload_mem);
 4181 %}
 4182 #endif
 4183 
 4184 
 4185 instruct loadD(regD dst, memoryD mem) %{
 4186   match(Set dst (LoadD mem));
 4187   ins_cost(MEMORY_REF_COST);
 4188 
 4189   size(4);
 4190   // FIXME: needs to be atomic, but  ARMv7 A.R.M. guarantees
 4191   // only LDREXD and STREXD are 64-bit single-copy atomic
 4192   format %{ &quot;FLDD   $dst,$mem&quot; %}
 4193   ins_encode %{
 4194     __ ldr_double($dst$$FloatRegister, $mem$$Address);
 4195   %}
 4196   ins_pipe(floadD_mem);
 4197 %}
 4198 
 4199 // Load Double - UNaligned
 4200 instruct loadD_unaligned(regD_low dst, memoryF2 mem ) %{
 4201   match(Set dst (LoadD_unaligned mem));
 4202   ins_cost(MEMORY_REF_COST*2+DEFAULT_COST);
 4203   size(8);
 4204   format %{ &quot;FLDS    $dst.lo,$mem\t! misaligned double\n&quot;
 4205           &quot;\tFLDS    $dst.hi,$mem+4\t!&quot; %}
 4206   ins_encode %{
 4207     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4208     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4209       __ flds($dst$$FloatRegister, Amemlo);
 4210       __ flds($dst$$FloatRegister-&gt;successor(), Amemhi);
 4211   %}
 4212   ins_pipe(iload_mem);
 4213 %}
 4214 
 4215 
 4216 instruct loadF(regF dst, memoryF mem) %{
 4217   match(Set dst (LoadF mem));
 4218 
 4219   ins_cost(MEMORY_REF_COST);
 4220   size(4);
 4221   format %{ &quot;FLDS    $dst,$mem&quot; %}
 4222   ins_encode %{
 4223     __ ldr_float($dst$$FloatRegister, $mem$$Address);
 4224   %}
 4225   ins_pipe(floadF_mem);
 4226 %}
 4227 
 4228 
 4229 // // Load Constant
 4230 instruct loadConI( iRegI dst, immI src ) %{
 4231   match(Set dst src);
 4232   ins_cost(DEFAULT_COST * 3/2);
 4233   format %{ &quot;MOV_SLOW    $dst, $src&quot; %}
 4234   ins_encode %{
 4235     __ mov_slow($dst$$Register, $src$$constant);
 4236   %}
 4237   ins_pipe(ialu_hi_lo_reg);
 4238 %}
 4239 
 4240 instruct loadConIMov( iRegI dst, immIMov src ) %{
 4241   match(Set dst src);
 4242   size(4);
 4243   format %{ &quot;MOV    $dst, $src&quot; %}
 4244   ins_encode %{
 4245     __ mov($dst$$Register, $src$$constant);
 4246   %}
 4247   ins_pipe(ialu_imm);
 4248 %}
 4249 
 4250 instruct loadConIMovn( iRegI dst, immIRotn src ) %{
 4251   match(Set dst src);
 4252   size(4);
 4253   format %{ &quot;MVN    $dst, ~$src&quot; %}
 4254   ins_encode %{
 4255     __ mvn($dst$$Register, ~$src$$constant);
 4256   %}
 4257   ins_pipe(ialu_imm_n);
 4258 %}
 4259 
 4260 instruct loadConI16( iRegI dst, immI16 src ) %{
 4261   match(Set dst src);
 4262   size(4);
 4263   format %{ &quot;MOVW    $dst, $src&quot; %}
 4264   ins_encode %{
 4265     __ movw($dst$$Register, $src$$constant);
 4266   %}
 4267   ins_pipe(ialu_imm_n);
 4268 %}
 4269 
 4270 instruct loadConP(iRegP dst, immP src) %{
 4271   match(Set dst src);
 4272   ins_cost(DEFAULT_COST * 3/2);
 4273   format %{ &quot;MOV_SLOW    $dst,$src\t!ptr&quot; %}
 4274   ins_encode %{
 4275     relocInfo::relocType constant_reloc = _opnds[1]-&gt;constant_reloc();
 4276     intptr_t val = $src$$constant;
 4277     if (constant_reloc == relocInfo::oop_type) {
 4278       __ mov_oop($dst$$Register, (jobject)val);
 4279     } else if (constant_reloc == relocInfo::metadata_type) {
 4280       __ mov_metadata($dst$$Register, (Metadata*)val);
 4281     } else {
 4282       __ mov_slow($dst$$Register, val);
 4283     }
 4284   %}
 4285   ins_pipe(loadConP);
 4286 %}
 4287 
 4288 
 4289 instruct loadConP_poll(iRegP dst, immP_poll src) %{
 4290   match(Set dst src);
 4291   ins_cost(DEFAULT_COST);
 4292   format %{ &quot;MOV_SLOW    $dst,$src\t!ptr&quot; %}
 4293   ins_encode %{
 4294       __ mov_slow($dst$$Register, $src$$constant);
 4295   %}
 4296   ins_pipe(loadConP_poll);
 4297 %}
 4298 
 4299 instruct loadConL(iRegL dst, immL src) %{
 4300   match(Set dst src);
 4301   ins_cost(DEFAULT_COST * 4);
 4302   format %{ &quot;MOV_SLOW   $dst.lo, $src &amp; 0x0FFFFFFFFL \t! long\n\t&quot;
 4303             &quot;MOV_SLOW   $dst.hi, $src &gt;&gt; 32&quot; %}
 4304   ins_encode %{
 4305     __ mov_slow(reg_to_register_object($dst$$reg), $src$$constant &amp; 0x0FFFFFFFFL);
 4306     __ mov_slow(reg_to_register_object($dst$$reg + 1), ((julong)($src$$constant)) &gt;&gt; 32);
 4307   %}
 4308   ins_pipe(loadConL);
 4309 %}
 4310 
 4311 instruct loadConL16( iRegL dst, immL16 src ) %{
 4312   match(Set dst src);
 4313   ins_cost(DEFAULT_COST * 2);
 4314 
 4315   size(8);
 4316   format %{ &quot;MOVW    $dst.lo, $src \n\t&quot;
 4317             &quot;MOVW    $dst.hi, 0 \n\t&quot; %}
 4318   ins_encode %{
 4319     __ movw($dst$$Register, $src$$constant);
 4320     __ movw($dst$$Register-&gt;successor(), 0);
 4321   %}
 4322   ins_pipe(ialu_imm);
 4323 %}
 4324 
 4325 instruct loadConF_imm8(regF dst, imm8F src) %{
 4326   match(Set dst src);
 4327   ins_cost(DEFAULT_COST);
 4328   size(4);
 4329 
 4330   format %{ &quot;FCONSTS      $dst, $src&quot;%}
 4331 
 4332   ins_encode %{
 4333     __ fconsts($dst$$FloatRegister, Assembler::float_num($src$$constant).imm8());
 4334   %}
 4335   ins_pipe(loadConFD); // FIXME
 4336 %}
 4337 
 4338 
 4339 instruct loadConF(regF dst, immF src, iRegI tmp) %{
 4340   match(Set dst src);
 4341   ins_cost(DEFAULT_COST * 2);
 4342   effect(TEMP tmp);
 4343   size(3*4);
 4344 
 4345   format %{ &quot;MOV_SLOW  $tmp, $src\n\t&quot;
 4346             &quot;FMSR      $dst, $tmp&quot;%}
 4347 
 4348   ins_encode %{
 4349     // FIXME revisit once 6961697 is in
 4350     union {
 4351       jfloat f;
 4352       int i;
 4353     } v;
 4354     v.f = $src$$constant;
 4355     __ mov_slow($tmp$$Register, v.i);
 4356     __ fmsr($dst$$FloatRegister, $tmp$$Register);
 4357   %}
 4358   ins_pipe(loadConFD); // FIXME
 4359 %}
 4360 
 4361 instruct loadConD_imm8(regD dst, imm8D src) %{
 4362   match(Set dst src);
 4363   ins_cost(DEFAULT_COST);
 4364   size(4);
 4365 
 4366   format %{ &quot;FCONSTD      $dst, $src&quot;%}
 4367 
 4368   ins_encode %{
 4369     __ fconstd($dst$$FloatRegister, Assembler::double_num($src$$constant).imm8());
 4370   %}
 4371   ins_pipe(loadConFD); // FIXME
 4372 %}
 4373 
 4374 instruct loadConD(regD dst, immD src, iRegP tmp) %{
 4375   match(Set dst src);
 4376   effect(TEMP tmp);
 4377   ins_cost(MEMORY_REF_COST);
 4378   format %{ &quot;FLDD  $dst, [$constanttablebase + $constantoffset]\t! load from constant table: double=$src&quot; %}
 4379 
 4380   ins_encode %{
 4381     Register r = $constanttablebase;
 4382     int offset  = $constantoffset($src);
 4383     if (!is_memoryD(offset)) {                // can&#39;t use a predicate
 4384                                               // in load constant instructs
 4385       __ add_slow($tmp$$Register, r, offset);
 4386       r = $tmp$$Register;
 4387       offset = 0;
 4388     }
 4389     __ ldr_double($dst$$FloatRegister, Address(r, offset));
 4390   %}
 4391   ins_pipe(loadConFD);
 4392 %}
 4393 
 4394 // Prefetch instructions.
 4395 // Must be safe to execute with invalid address (cannot fault).
 4396 
 4397 instruct prefetchAlloc_mp( memoryP mem ) %{
 4398   predicate(VM_Version::has_multiprocessing_extensions());
 4399   match( PrefetchAllocation mem );
 4400   ins_cost(MEMORY_REF_COST);
 4401   size(4);
 4402 
 4403   format %{ &quot;PLDW $mem\t! Prefetch allocation&quot; %}
 4404   ins_encode %{
 4405     __ pldw($mem$$Address);
 4406   %}
 4407   ins_pipe(iload_mem);
 4408 %}
 4409 
 4410 instruct prefetchAlloc_sp( memoryP mem ) %{
 4411   predicate(!VM_Version::has_multiprocessing_extensions());
 4412   match( PrefetchAllocation mem );
 4413   ins_cost(MEMORY_REF_COST);
 4414   size(4);
 4415 
 4416   format %{ &quot;PLD $mem\t! Prefetch allocation&quot; %}
 4417   ins_encode %{
 4418     __ pld($mem$$Address);
 4419   %}
 4420   ins_pipe(iload_mem);
 4421 %}
 4422 
 4423 
 4424 //----------Store Instructions-------------------------------------------------
 4425 // Store Byte
 4426 instruct storeB(memoryB mem, store_RegI src) %{
 4427   match(Set mem (StoreB mem src));
 4428   ins_cost(MEMORY_REF_COST);
 4429 
 4430   size(4);
 4431   format %{ &quot;STRB    $src,$mem\t! byte&quot; %}
 4432   ins_encode %{
 4433     __ strb($src$$Register, $mem$$Address);
 4434   %}
 4435   ins_pipe(istore_mem_reg);
 4436 %}
 4437 
 4438 instruct storeCM(memoryB mem, store_RegI src) %{
 4439   match(Set mem (StoreCM mem src));
 4440   ins_cost(MEMORY_REF_COST);
 4441 
 4442   size(4);
 4443   format %{ &quot;STRB    $src,$mem\t! CMS card-mark byte&quot; %}
 4444   ins_encode %{
 4445     __ strb($src$$Register, $mem$$Address);
 4446   %}
 4447   ins_pipe(istore_mem_reg);
 4448 %}
 4449 
 4450 // Store Char/Short
 4451 
 4452 
 4453 instruct storeC(memoryS mem, store_RegI src) %{
 4454   match(Set mem (StoreC mem src));
 4455   ins_cost(MEMORY_REF_COST);
 4456 
 4457   size(4);
 4458   format %{ &quot;STRH    $src,$mem\t! short&quot; %}
 4459   ins_encode %{
 4460     __ strh($src$$Register, $mem$$Address);
 4461   %}
 4462   ins_pipe(istore_mem_reg);
 4463 %}
 4464 
 4465 // Store Integer
 4466 
 4467 
 4468 instruct storeI(memoryI mem, store_RegI src) %{
 4469   match(Set mem (StoreI mem src));
 4470   ins_cost(MEMORY_REF_COST);
 4471 
 4472   size(4);
 4473   format %{ &quot;str_32 $src,$mem&quot; %}
 4474   ins_encode %{
 4475     __ str_32($src$$Register, $mem$$Address);
 4476   %}
 4477   ins_pipe(istore_mem_reg);
 4478 %}
 4479 
 4480 // Store Long
 4481 
 4482 
 4483 instruct storeL(memoryL mem, store_RegLd src) %{
 4484   predicate(!((StoreLNode*)n)-&gt;require_atomic_access());
 4485   match(Set mem (StoreL mem src));
 4486   ins_cost(MEMORY_REF_COST);
 4487 
 4488   size(4);
 4489   format %{ &quot;str_64  $src,$mem\t! long\n\t&quot; %}
 4490 
 4491   ins_encode %{
 4492     __ str_64($src$$Register, $mem$$Address);
 4493   %}
 4494   ins_pipe(istore_mem_reg);
 4495 %}
 4496 
 4497 instruct storeL_2instr(memorylong mem, iRegL src) %{
 4498   predicate(!((StoreLNode*)n)-&gt;require_atomic_access());
 4499   match(Set mem (StoreL mem src));
 4500   ins_cost(MEMORY_REF_COST + DEFAULT_COST);
 4501 
 4502   size(8);
 4503   format %{ &quot;STR    $src.lo,$mem\t! long\n\t&quot;
 4504             &quot;STR    $src.hi,$mem+4&quot; %}
 4505 
 4506   ins_encode %{
 4507     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4508     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4509     __ str($src$$Register, Amemlo);
 4510     __ str($src$$Register-&gt;successor(), Amemhi);
 4511   %}
 4512   ins_pipe(istore_mem_reg);
 4513 %}
 4514 
 4515 instruct storeL_volatile(indirect mem, iRegL src) %{
 4516   predicate(((StoreLNode*)n)-&gt;require_atomic_access());
 4517   match(Set mem (StoreL mem src));
 4518   ins_cost(MEMORY_REF_COST);
 4519   size(4);
 4520   format %{ &quot;STMIA    $src,$mem\t! long&quot; %}
 4521   ins_encode %{
 4522     // FIXME: why is stmia considered atomic?  Should be strexd
 4523     RegisterSet set($src$$Register);
 4524     set = set | reg_to_register_object($src$$reg + 1);
 4525     __ stmia(reg_to_register_object($mem$$base), set);
 4526   %}
 4527   ins_pipe(istore_mem_reg);
 4528 %}
 4529 
 4530 instruct storeL_volatile_fp(memoryD mem, iRegL src) %{
 4531   predicate(((StoreLNode*)n)-&gt;require_atomic_access());
 4532   match(Set mem (StoreL mem src));
 4533   ins_cost(MEMORY_REF_COST);
 4534   size(8);
 4535   format %{ &quot;FMDRR    S14, $src\t! long \n\t&quot;
 4536             &quot;FSTD     S14, $mem&quot; %}
 4537   ins_encode %{
 4538     __ fmdrr(S14, $src$$Register, $src$$Register-&gt;successor());
 4539     __ fstd(S14, $mem$$Address);
 4540   %}
 4541   ins_pipe(istore_mem_reg);
 4542 %}
 4543 
 4544 #ifdef XXX
 4545 // Move SP Pointer
 4546 //instruct movSP(sp_ptr_RegP dst, SPRegP src) %{
 4547 //instruct movSP(iRegP dst, SPRegP src) %{
 4548 instruct movSP(store_ptr_RegP dst, SPRegP src) %{
 4549   match(Set dst src);
 4550 //predicate(!_kids[1]-&gt;_leaf-&gt;is_Proj() || _kids[1]-&gt;_leaf-&gt;as_Proj()-&gt;_con == TypeFunc::FramePtr);
 4551   ins_cost(MEMORY_REF_COST);
 4552   size(4);
 4553 
 4554   format %{ &quot;MOV    $dst,$src\t! SP ptr\n\t&quot; %}
 4555   ins_encode %{
 4556     assert(false, &quot;XXX1 got here&quot;);
 4557     __ mov($dst$$Register, SP);
 4558     __ mov($dst$$Register, $src$$Register);
 4559   %}
 4560   ins_pipe(ialu_reg);
 4561 %}
 4562 #endif
 4563 
 4564 
 4565 // Store Pointer
 4566 
 4567 
 4568 instruct storeP(memoryP mem, store_ptr_RegP src) %{
 4569   match(Set mem (StoreP mem src));
 4570   ins_cost(MEMORY_REF_COST);
 4571   size(4);
 4572 
 4573   format %{ &quot;STR    $src,$mem\t! ptr&quot; %}
 4574   ins_encode %{
 4575     __ str($src$$Register, $mem$$Address);
 4576   %}
 4577   ins_pipe(istore_mem_spORreg);
 4578 %}
 4579 
 4580 
 4581 #ifdef _LP64
 4582 // Store Compressed Pointer
 4583 
 4584 
 4585 instruct storeN(memoryI mem, store_RegN src) %{
 4586   match(Set mem (StoreN mem src));
 4587   ins_cost(MEMORY_REF_COST);
 4588   size(4);
 4589 
 4590   format %{ &quot;str_32 $src,$mem\t! compressed ptr&quot; %}
 4591   ins_encode %{
 4592     __ str_32($src$$Register, $mem$$Address);
 4593   %}
 4594   ins_pipe(istore_mem_reg);
 4595 %}
 4596 
 4597 
 4598 // Store Compressed Klass Pointer
 4599 instruct storeNKlass(memoryI mem, store_RegN src) %{
 4600   match(Set mem (StoreNKlass mem src));
 4601   ins_cost(MEMORY_REF_COST);
 4602   size(4);
 4603 
 4604   format %{ &quot;str_32 $src,$mem\t! compressed klass ptr&quot; %}
 4605   ins_encode %{
 4606     __ str_32($src$$Register, $mem$$Address);
 4607   %}
 4608   ins_pipe(istore_mem_reg);
 4609 %}
 4610 #endif
 4611 
 4612 // Store Double
 4613 
 4614 
 4615 instruct storeD(memoryD mem, regD src) %{
 4616   match(Set mem (StoreD mem src));
 4617   ins_cost(MEMORY_REF_COST);
 4618 
 4619   size(4);
 4620   // FIXME: needs to be atomic, but  ARMv7 A.R.M. guarantees
 4621   // only LDREXD and STREXD are 64-bit single-copy atomic
 4622   format %{ &quot;FSTD   $src,$mem&quot; %}
 4623   ins_encode %{
 4624     __ str_double($src$$FloatRegister, $mem$$Address);
 4625   %}
 4626   ins_pipe(fstoreD_mem_reg);
 4627 %}
 4628 
 4629 
 4630 // Store Float
 4631 
 4632 
 4633 instruct storeF( memoryF mem, regF src) %{
 4634   match(Set mem (StoreF mem src));
 4635   ins_cost(MEMORY_REF_COST);
 4636 
 4637   size(4);
 4638   format %{ &quot;FSTS    $src,$mem&quot; %}
 4639   ins_encode %{
 4640     __ str_float($src$$FloatRegister, $mem$$Address);
 4641   %}
 4642   ins_pipe(fstoreF_mem_reg);
 4643 %}
 4644 
 4645 
 4646 //----------MemBar Instructions-----------------------------------------------
 4647 // Memory barrier flavors
 4648 
 4649 // pattern-match out unnecessary membars
 4650 instruct membar_storestore() %{
 4651   match(MemBarStoreStore);
 4652   ins_cost(4*MEMORY_REF_COST);
 4653 
 4654   size(4);
 4655   format %{ &quot;MEMBAR-storestore&quot; %}
 4656   ins_encode %{
 4657     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::StoreStore), noreg);
 4658   %}
 4659   ins_pipe(long_memory_op);
 4660 %}
 4661 
 4662 instruct membar_acquire() %{
 4663   match(MemBarAcquire);
 4664   match(LoadFence);
 4665   ins_cost(4*MEMORY_REF_COST);
 4666 
 4667   size(4);
 4668   format %{ &quot;MEMBAR-acquire&quot; %}
 4669   ins_encode %{
 4670     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::LoadLoad | MacroAssembler::LoadStore), noreg);
 4671   %}
 4672   ins_pipe(long_memory_op);
 4673 %}
 4674 
 4675 instruct membar_acquire_lock() %{
 4676   match(MemBarAcquireLock);
 4677   ins_cost(0);
 4678 
 4679   size(0);
 4680   format %{ &quot;!MEMBAR-acquire (CAS in prior FastLock so empty encoding)&quot; %}
 4681   ins_encode( );
 4682   ins_pipe(empty);
 4683 %}
 4684 
 4685 instruct membar_release() %{
 4686   match(MemBarRelease);
 4687   match(StoreFence);
 4688   ins_cost(4*MEMORY_REF_COST);
 4689 
 4690   size(4);
 4691   format %{ &quot;MEMBAR-release&quot; %}
 4692   ins_encode %{
 4693     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::StoreStore | MacroAssembler::LoadStore), noreg);
 4694   %}
 4695   ins_pipe(long_memory_op);
 4696 %}
 4697 
 4698 instruct membar_release_lock() %{
 4699   match(MemBarReleaseLock);
 4700   ins_cost(0);
 4701 
 4702   size(0);
 4703   format %{ &quot;!MEMBAR-release (CAS in succeeding FastUnlock so empty encoding)&quot; %}
 4704   ins_encode( );
 4705   ins_pipe(empty);
 4706 %}
 4707 
 4708 instruct membar_volatile() %{
 4709   match(MemBarVolatile);
 4710   ins_cost(4*MEMORY_REF_COST);
 4711 
 4712   size(4);
 4713   format %{ &quot;MEMBAR-volatile&quot; %}
 4714   ins_encode %{
 4715     __ membar(MacroAssembler::StoreLoad, noreg);
 4716   %}
 4717   ins_pipe(long_memory_op);
 4718 %}
 4719 
 4720 instruct unnecessary_membar_volatile() %{
 4721   match(MemBarVolatile);
 4722   predicate(Matcher::post_store_load_barrier(n));
 4723   ins_cost(0);
 4724 
 4725   size(0);
 4726   format %{ &quot;!MEMBAR-volatile (unnecessary so empty encoding)&quot; %}
 4727   ins_encode( );
 4728   ins_pipe(empty);
 4729 %}
 4730 
 4731 //----------Register Move Instructions-----------------------------------------
 4732 // instruct roundDouble_nop(regD dst) %{
 4733 //   match(Set dst (RoundDouble dst));
 4734 //   ins_pipe(empty);
 4735 // %}
 4736 
 4737 
 4738 // instruct roundFloat_nop(regF dst) %{
 4739 //   match(Set dst (RoundFloat dst));
 4740 //   ins_pipe(empty);
 4741 // %}
 4742 
 4743 
 4744 
 4745 // Cast Index to Pointer for unsafe natives
 4746 instruct castX2P(iRegX src, iRegP dst) %{
 4747   match(Set dst (CastX2P src));
 4748 
 4749   format %{ &quot;MOV    $dst,$src\t! IntX-&gt;Ptr if $dst != $src&quot; %}
 4750   ins_encode %{
 4751     if ($dst$$Register !=  $src$$Register) {
 4752       __ mov($dst$$Register, $src$$Register);
 4753     }
 4754   %}
 4755   ins_pipe(ialu_reg);
 4756 %}
 4757 
 4758 // Cast Pointer to Index for unsafe natives
 4759 instruct castP2X(iRegP src, iRegX dst) %{
 4760   match(Set dst (CastP2X src));
 4761 
 4762   format %{ &quot;MOV    $dst,$src\t! Ptr-&gt;IntX if $dst != $src&quot; %}
 4763   ins_encode %{
 4764     if ($dst$$Register !=  $src$$Register) {
 4765       __ mov($dst$$Register, $src$$Register);
 4766     }
 4767   %}
 4768   ins_pipe(ialu_reg);
 4769 %}
 4770 
 4771 //----------Conditional Move---------------------------------------------------
 4772 // Conditional move
 4773 instruct cmovIP_reg(cmpOpP cmp, flagsRegP pcc, iRegI dst, iRegI src) %{
 4774   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4775   ins_cost(150);
 4776   size(4);
 4777   format %{ &quot;MOV$cmp  $dst,$src\t! int&quot; %}
 4778   ins_encode %{
 4779     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4780   %}
 4781   ins_pipe(ialu_reg);
 4782 %}
 4783 
 4784 
 4785 instruct cmovIP_immMov(cmpOpP cmp, flagsRegP pcc, iRegI dst, immIMov src) %{
 4786   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4787   ins_cost(140);
 4788   size(4);
 4789   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4790   ins_encode %{
 4791     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4792   %}
 4793   ins_pipe(ialu_imm);
 4794 %}
 4795 
 4796 instruct cmovIP_imm16(cmpOpP cmp, flagsRegP pcc, iRegI dst, immI16 src) %{
 4797   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4798   ins_cost(140);
 4799   size(4);
 4800   format %{ &quot;MOVw$cmp  $dst,$src&quot; %}
 4801   ins_encode %{
 4802     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4803   %}
 4804   ins_pipe(ialu_imm);
 4805 %}
 4806 
 4807 instruct cmovI_reg(cmpOp cmp, flagsReg icc, iRegI dst, iRegI src) %{
 4808   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4809   ins_cost(150);
 4810   size(4);
 4811   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4812   ins_encode %{
 4813     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4814   %}
 4815   ins_pipe(ialu_reg);
 4816 %}
 4817 
 4818 
 4819 instruct cmovI_immMov(cmpOp cmp, flagsReg icc, iRegI dst, immIMov src) %{
 4820   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4821   ins_cost(140);
 4822   size(4);
 4823   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4824   ins_encode %{
 4825     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4826   %}
 4827   ins_pipe(ialu_imm);
 4828 %}
 4829 
 4830 instruct cmovII_imm16(cmpOp cmp, flagsReg icc, iRegI dst, immI16 src) %{
 4831   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4832   ins_cost(140);
 4833   size(4);
 4834   format %{ &quot;MOVw$cmp  $dst,$src&quot; %}
 4835   ins_encode %{
 4836     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4837   %}
 4838   ins_pipe(ialu_imm);
 4839 %}
 4840 
 4841 instruct cmovII_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, iRegI src) %{
 4842   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4843   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4844             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4845             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4846             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4847   ins_cost(150);
 4848   size(4);
 4849   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4850   ins_encode %{
 4851     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4852   %}
 4853   ins_pipe(ialu_reg);
 4854 %}
 4855 
 4856 instruct cmovII_immMov_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, immIMov src) %{
 4857   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4858   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4859             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4860             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4861             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4862   ins_cost(140);
 4863   size(4);
 4864   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4865   ins_encode %{
 4866     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4867   %}
 4868   ins_pipe(ialu_imm);
 4869 %}
 4870 
 4871 instruct cmovII_imm16_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, immI16 src) %{
 4872   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4873   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4874             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4875             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4876             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4877   ins_cost(140);
 4878   size(4);
 4879   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 4880   ins_encode %{
 4881     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4882   %}
 4883   ins_pipe(ialu_imm);
 4884 %}
 4885 
 4886 instruct cmovIIu_reg(cmpOpU cmp, flagsRegU icc, iRegI dst, iRegI src) %{
 4887   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4888   ins_cost(150);
 4889   size(4);
 4890   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4891   ins_encode %{
 4892     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4893   %}
 4894   ins_pipe(ialu_reg);
 4895 %}
 4896 
 4897 instruct cmovIIu_immMov(cmpOpU cmp, flagsRegU icc, iRegI dst, immIMov src) %{
 4898   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4899   ins_cost(140);
 4900   size(4);
 4901   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4902   ins_encode %{
 4903     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4904   %}
 4905   ins_pipe(ialu_imm);
 4906 %}
 4907 
 4908 instruct cmovIIu_imm16(cmpOpU cmp, flagsRegU icc, iRegI dst, immI16 src) %{
 4909   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4910   ins_cost(140);
 4911   size(4);
 4912   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 4913   ins_encode %{
 4914     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4915   %}
 4916   ins_pipe(ialu_imm);
 4917 %}
 4918 
 4919 // Conditional move
 4920 instruct cmovPP_reg(cmpOpP cmp, flagsRegP pcc, iRegP dst, iRegP src) %{
 4921   match(Set dst (CMoveP (Binary cmp pcc) (Binary dst src)));
 4922   ins_cost(150);
 4923   size(4);
 4924   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4925   ins_encode %{
 4926     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4927   %}
 4928   ins_pipe(ialu_reg);
 4929 %}
 4930 
 4931 instruct cmovPP_imm(cmpOpP cmp, flagsRegP pcc, iRegP dst, immP0 src) %{
 4932   match(Set dst (CMoveP (Binary cmp pcc) (Binary dst src)));
 4933   ins_cost(140);
 4934   size(4);
 4935   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4936   ins_encode %{
 4937     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4938   %}
 4939   ins_pipe(ialu_imm);
 4940 %}
 4941 
 4942 // This instruction also works with CmpN so we don&#39;t need cmovPN_reg.
 4943 instruct cmovPI_reg(cmpOp cmp, flagsReg icc, iRegP dst, iRegP src) %{
 4944   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4945   ins_cost(150);
 4946 
 4947   size(4);
 4948   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4949   ins_encode %{
 4950     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4951   %}
 4952   ins_pipe(ialu_reg);
 4953 %}
 4954 
 4955 instruct cmovPI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegP dst, iRegP src) %{
 4956   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4957   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4958             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4959             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4960             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4961   ins_cost(150);
 4962 
 4963   size(4);
 4964   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4965   ins_encode %{
 4966     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4967   %}
 4968   ins_pipe(ialu_reg);
 4969 %}
 4970 
 4971 instruct cmovPIu_reg(cmpOpU cmp, flagsRegU icc, iRegP dst, iRegP src) %{
 4972   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4973   ins_cost(150);
 4974 
 4975   size(4);
 4976   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4977   ins_encode %{
 4978     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4979   %}
 4980   ins_pipe(ialu_reg);
 4981 %}
 4982 
 4983 instruct cmovPI_imm(cmpOp cmp, flagsReg icc, iRegP dst, immP0 src) %{
 4984   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4985   ins_cost(140);
 4986 
 4987   size(4);
 4988   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4989   ins_encode %{
 4990     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4991   %}
 4992   ins_pipe(ialu_imm);
 4993 %}
 4994 
 4995 instruct cmovPI_imm_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegP dst, immP0 src) %{
 4996   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4997   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4998             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4999             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5000             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5001   ins_cost(140);
 5002 
 5003   size(4);
 5004   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 5005   ins_encode %{
 5006     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5007   %}
 5008   ins_pipe(ialu_imm);
 5009 %}
 5010 
 5011 instruct cmovPIu_imm(cmpOpU cmp, flagsRegU icc, iRegP dst, immP0 src) %{
 5012   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 5013   ins_cost(140);
 5014 
 5015   size(4);
 5016   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 5017   ins_encode %{
 5018     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5019   %}
 5020   ins_pipe(ialu_imm);
 5021 %}
 5022 
 5023 
 5024 // Conditional move
 5025 instruct cmovFP_reg(cmpOpP cmp, flagsRegP pcc, regF dst, regF src) %{
 5026   match(Set dst (CMoveF (Binary cmp pcc) (Binary dst src)));
 5027   ins_cost(150);
 5028   size(4);
 5029   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5030   ins_encode %{
 5031     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5032   %}
 5033   ins_pipe(int_conditional_float_move);
 5034 %}
 5035 
 5036 instruct cmovFI_reg(cmpOp cmp, flagsReg icc, regF dst, regF src) %{
 5037   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5038   ins_cost(150);
 5039 
 5040   size(4);
 5041   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5042   ins_encode %{
 5043     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5044   %}
 5045   ins_pipe(int_conditional_float_move);
 5046 %}
 5047 
 5048 instruct cmovFI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, regF dst, regF src) %{
 5049   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5050   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5051             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5052             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5053             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5054   ins_cost(150);
 5055 
 5056   size(4);
 5057   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5058   ins_encode %{
 5059     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5060   %}
 5061   ins_pipe(int_conditional_float_move);
 5062 %}
 5063 
 5064 instruct cmovFIu_reg(cmpOpU cmp, flagsRegU icc, regF dst, regF src) %{
 5065   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5066   ins_cost(150);
 5067 
 5068   size(4);
 5069   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5070   ins_encode %{
 5071     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5072   %}
 5073   ins_pipe(int_conditional_float_move);
 5074 %}
 5075 
 5076 // Conditional move
 5077 instruct cmovDP_reg(cmpOpP cmp, flagsRegP pcc, regD dst, regD src) %{
 5078   match(Set dst (CMoveD (Binary cmp pcc) (Binary dst src)));
 5079   ins_cost(150);
 5080   size(4);
 5081   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5082   ins_encode %{
 5083     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5084   %}
 5085   ins_pipe(int_conditional_double_move);
 5086 %}
 5087 
 5088 instruct cmovDI_reg(cmpOp cmp, flagsReg icc, regD dst, regD src) %{
 5089   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5090   ins_cost(150);
 5091 
 5092   size(4);
 5093   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5094   ins_encode %{
 5095     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5096   %}
 5097   ins_pipe(int_conditional_double_move);
 5098 %}
 5099 
 5100 instruct cmovDI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, regD dst, regD src) %{
 5101   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5102   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5103   ins_cost(150);
 5104 
 5105   size(4);
 5106   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5107   ins_encode %{
 5108     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5109   %}
 5110   ins_pipe(int_conditional_double_move);
 5111 %}
 5112 
 5113 instruct cmovDIu_reg(cmpOpU cmp, flagsRegU icc, regD dst, regD src) %{
 5114   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5115   ins_cost(150);
 5116 
 5117   size(4);
 5118   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5119   ins_encode %{
 5120     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5121   %}
 5122   ins_pipe(int_conditional_double_move);
 5123 %}
 5124 
 5125 // Conditional move
 5126 instruct cmovLP_reg(cmpOpP cmp, flagsRegP pcc, iRegL dst, iRegL src) %{
 5127   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5128   ins_cost(150);
 5129 
 5130   size(8);
 5131   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5132             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5133   ins_encode %{
 5134     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5135     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5136   %}
 5137   ins_pipe(ialu_reg);
 5138 %}
 5139 
 5140 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5141 // (hi($con$$constant), lo($con$$constant)) becomes
 5142 instruct cmovLP_immRot(cmpOpP cmp, flagsRegP pcc, iRegL dst, immLlowRot src) %{
 5143   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5144   ins_cost(140);
 5145 
 5146   size(8);
 5147   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5148             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5149   ins_encode %{
 5150     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5151     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5152   %}
 5153   ins_pipe(ialu_imm);
 5154 %}
 5155 
 5156 instruct cmovLP_imm16(cmpOpP cmp, flagsRegP pcc, iRegL dst, immL16 src) %{
 5157   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5158   ins_cost(140);
 5159 
 5160   size(8);
 5161   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5162             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5163   ins_encode %{
 5164     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5165     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5166   %}
 5167   ins_pipe(ialu_imm);
 5168 %}
 5169 
 5170 instruct cmovLI_reg(cmpOp cmp, flagsReg icc, iRegL dst, iRegL src) %{
 5171   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5172   ins_cost(150);
 5173 
 5174   size(8);
 5175   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5176             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5177   ins_encode %{
 5178     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5179     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5180   %}
 5181   ins_pipe(ialu_reg);
 5182 %}
 5183 
 5184 instruct cmovLI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, iRegL src) %{
 5185   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5186   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5187             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5188             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5189             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5190   ins_cost(150);
 5191 
 5192   size(8);
 5193   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5194             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5195   ins_encode %{
 5196     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5197     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5198   %}
 5199   ins_pipe(ialu_reg);
 5200 %}
 5201 
 5202 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5203 // (hi($con$$constant), lo($con$$constant)) becomes
 5204 instruct cmovLI_immRot(cmpOp cmp, flagsReg icc, iRegL dst, immLlowRot src) %{
 5205   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5206   ins_cost(140);
 5207 
 5208   size(8);
 5209   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5210             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5211   ins_encode %{
 5212     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5213     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5214   %}
 5215   ins_pipe(ialu_imm);
 5216 %}
 5217 
 5218 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5219 // (hi($con$$constant), lo($con$$constant)) becomes
 5220 instruct cmovLI_immRot_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, immLlowRot src) %{
 5221   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5222   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5223             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5224             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5225             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5226   ins_cost(140);
 5227 
 5228   size(8);
 5229   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5230             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5231   ins_encode %{
 5232     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5233     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5234   %}
 5235   ins_pipe(ialu_imm);
 5236 %}
 5237 
 5238 instruct cmovLI_imm16(cmpOp cmp, flagsReg icc, iRegL dst, immL16 src) %{
 5239   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5240   ins_cost(140);
 5241 
 5242   size(8);
 5243   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5244             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5245   ins_encode %{
 5246     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5247     __ movw($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5248   %}
 5249   ins_pipe(ialu_imm);
 5250 %}
 5251 
 5252 instruct cmovLI_imm16_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, immL16 src) %{
 5253   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5254   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5255             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5256             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5257             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5258   ins_cost(140);
 5259 
 5260   size(8);
 5261   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5262             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5263   ins_encode %{
 5264     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5265     __ movw($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5266   %}
 5267   ins_pipe(ialu_imm);
 5268 %}
 5269 
 5270 instruct cmovLIu_reg(cmpOpU cmp, flagsRegU icc, iRegL dst, iRegL src) %{
 5271   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5272   ins_cost(150);
 5273 
 5274   size(8);
 5275   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5276             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5277   ins_encode %{
 5278     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5279     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5280   %}
 5281   ins_pipe(ialu_reg);
 5282 %}
 5283 
 5284 
 5285 //----------OS and Locking Instructions----------------------------------------
 5286 
 5287 // This name is KNOWN by the ADLC and cannot be changed.
 5288 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
 5289 // for this guy.
 5290 instruct tlsLoadP(RthreadRegP dst) %{
 5291   match(Set dst (ThreadLocal));
 5292 
 5293   size(0);
 5294   ins_cost(0);
 5295   format %{ &quot;! TLS is in $dst&quot; %}
 5296   ins_encode( /*empty encoding*/ );
 5297   ins_pipe(ialu_none);
 5298 %}
 5299 
 5300 instruct checkCastPP( iRegP dst ) %{
 5301   match(Set dst (CheckCastPP dst));
 5302 
 5303   size(0);
 5304   format %{ &quot;! checkcastPP of $dst&quot; %}
 5305   ins_encode( /*empty encoding*/ );
 5306   ins_pipe(empty);
 5307 %}
 5308 
 5309 
 5310 instruct castPP( iRegP dst ) %{
 5311   match(Set dst (CastPP dst));
 5312   format %{ &quot;! castPP of $dst&quot; %}
 5313   ins_encode( /*empty encoding*/ );
 5314   ins_pipe(empty);
 5315 %}
 5316 
 5317 instruct castII( iRegI dst ) %{
 5318   match(Set dst (CastII dst));
 5319   format %{ &quot;! castII of $dst&quot; %}
 5320   ins_encode( /*empty encoding*/ );
 5321   ins_cost(0);
 5322   ins_pipe(empty);
 5323 %}
 5324 
 5325 instruct castLL( iRegL dst ) %{
 5326   match(Set dst (CastLL dst));
 5327   format %{ &quot;! castLL of $dst&quot; %}
 5328   ins_encode( /*empty encoding*/ );
 5329   ins_cost(0);
 5330   ins_pipe(empty);
 5331 %}
 5332 
 5333 //----------Arithmetic Instructions--------------------------------------------
 5334 // Addition Instructions
 5335 // Register Addition
 5336 instruct addI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 5337   match(Set dst (AddI src1 src2));
 5338 
 5339   size(4);
 5340   format %{ &quot;add_32 $dst,$src1,$src2\t! int&quot; %}
 5341   ins_encode %{
 5342     __ add_32($dst$$Register, $src1$$Register, $src2$$Register);
 5343   %}
 5344   ins_pipe(ialu_reg_reg);
 5345 %}
 5346 
 5347 instruct addshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5348   match(Set dst (AddI (LShiftI src1 src2) src3));
 5349 
 5350   size(4);
 5351   format %{ &quot;add_32 $dst,$src3,$src1&lt;&lt;$src2\t! int&quot; %}
 5352   ins_encode %{
 5353     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 5354   %}
 5355   ins_pipe(ialu_reg_reg);
 5356 %}
 5357 
 5358 
 5359 instruct addshlI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5360   match(Set dst (AddI (LShiftI src1 src2) src3));
 5361 
 5362   size(4);
 5363   format %{ &quot;add_32 $dst,$src3,$src1&lt;&lt;$src2\t! int&quot; %}
 5364   ins_encode %{
 5365     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 5366   %}
 5367   ins_pipe(ialu_reg_reg);
 5368 %}
 5369 
 5370 instruct addsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5371   match(Set dst (AddI (RShiftI src1 src2) src3));
 5372 
 5373   size(4);
 5374   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;$src2\t! int&quot; %}
 5375   ins_encode %{
 5376     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 5377   %}
 5378   ins_pipe(ialu_reg_reg);
 5379 %}
 5380 
 5381 instruct addsarI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5382   match(Set dst (AddI (RShiftI src1 src2) src3));
 5383 
 5384   size(4);
 5385   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;$src2\t! int&quot; %}
 5386   ins_encode %{
 5387     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 5388   %}
 5389   ins_pipe(ialu_reg_reg);
 5390 %}
 5391 
 5392 instruct addshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5393   match(Set dst (AddI (URShiftI src1 src2) src3));
 5394 
 5395   size(4);
 5396   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;&gt;$src2\t! int&quot; %}
 5397   ins_encode %{
 5398     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 5399   %}
 5400   ins_pipe(ialu_reg_reg);
 5401 %}
 5402 
 5403 instruct addshrI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5404   match(Set dst (AddI (URShiftI src1 src2) src3));
 5405 
 5406   size(4);
 5407   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;&gt;$src2\t! int&quot; %}
 5408   ins_encode %{
 5409     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 5410   %}
 5411   ins_pipe(ialu_reg_reg);
 5412 %}
 5413 
 5414 // Immediate Addition
 5415 instruct addI_reg_aimmI(iRegI dst, iRegI src1, aimmI src2) %{
 5416   match(Set dst (AddI src1 src2));
 5417 
 5418   size(4);
 5419   format %{ &quot;add_32 $dst,$src1,$src2\t! int&quot; %}
 5420   ins_encode %{
 5421     __ add_32($dst$$Register, $src1$$Register, $src2$$constant);
 5422   %}
 5423   ins_pipe(ialu_reg_imm);
 5424 %}
 5425 
 5426 // Pointer Register Addition
 5427 instruct addP_reg_reg(iRegP dst, iRegP src1, iRegX src2) %{
 5428   match(Set dst (AddP src1 src2));
 5429 
 5430   size(4);
 5431   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5432   ins_encode %{
 5433     __ add($dst$$Register, $src1$$Register, $src2$$Register);
 5434   %}
 5435   ins_pipe(ialu_reg_reg);
 5436 %}
 5437 
 5438 
 5439 // shifted iRegX operand
 5440 operand shiftedX(iRegX src2, shimmX src3) %{
 5441 //constraint(ALLOC_IN_RC(sp_ptr_reg));
 5442   match(LShiftX src2 src3);
 5443 
 5444   op_cost(1);
 5445   format %{ &quot;$src2 &lt;&lt; $src3&quot; %}
 5446   interface(MEMORY_INTER) %{
 5447     base($src2);
 5448     index(0xff);
 5449     scale($src3);
 5450     disp(0x0);
 5451   %}
 5452 %}
 5453 
 5454 instruct addshlP_reg_reg_imm(iRegP dst, iRegP src1, shiftedX src2) %{
 5455   match(Set dst (AddP src1 src2));
 5456 
 5457   ins_cost(DEFAULT_COST * 3/2);
 5458   size(4);
 5459   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5460   ins_encode %{
 5461     Register base = reg_to_register_object($src2$$base);
 5462     __ add($dst$$Register, $src1$$Register, AsmOperand(base, lsl, $src2$$scale));
 5463   %}
 5464   ins_pipe(ialu_reg_reg);
 5465 %}
 5466 
 5467 // Pointer Immediate Addition
 5468 instruct addP_reg_aimmX(iRegP dst, iRegP src1, aimmX src2) %{
 5469   match(Set dst (AddP src1 src2));
 5470 
 5471   size(4);
 5472   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5473   ins_encode %{
 5474     __ add($dst$$Register, $src1$$Register, $src2$$constant);
 5475   %}
 5476   ins_pipe(ialu_reg_imm);
 5477 %}
 5478 
 5479 // Long Addition
 5480 instruct addL_reg_reg(iRegL dst, iRegL src1, iRegL src2, flagsReg ccr) %{
 5481   match(Set dst (AddL src1 src2));
 5482   effect(KILL ccr);
 5483   size(8);
 5484   format %{ &quot;ADDS    $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 5485             &quot;ADC     $dst.hi,$src1.hi,$src2.hi&quot; %}
 5486   ins_encode %{
 5487     __ adds($dst$$Register, $src1$$Register, $src2$$Register);
 5488     __ adc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 5489   %}
 5490   ins_pipe(ialu_reg_reg);
 5491 %}
 5492 
 5493 // TODO
 5494 
 5495 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5496 // (hi($con$$constant), lo($con$$constant)) becomes
 5497 instruct addL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con, flagsReg ccr) %{
 5498   match(Set dst (AddL src1 con));
 5499   effect(KILL ccr);
 5500   size(8);
 5501   format %{ &quot;ADDS    $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 5502             &quot;ADC     $dst.hi,$src1.hi,0&quot; %}
 5503   ins_encode %{
 5504     __ adds($dst$$Register, $src1$$Register, $con$$constant);
 5505     __ adc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 5506   %}
 5507   ins_pipe(ialu_reg_imm);
 5508 %}
 5509 
 5510 //----------Conditional_store--------------------------------------------------
 5511 // Conditional-store of the updated heap-top.
 5512 // Used during allocation of the shared heap.
 5513 // Sets flags (EQ) on success.
 5514 
 5515 // LoadP-locked.
 5516 instruct loadPLocked(iRegP dst, memoryex mem) %{
 5517   match(Set dst (LoadPLocked mem));
 5518   size(4);
 5519   format %{ &quot;LDREX  $dst,$mem&quot; %}
 5520   ins_encode %{
 5521     __ ldrex($dst$$Register,$mem$$Address);
 5522   %}
 5523   ins_pipe(iload_mem);
 5524 %}
 5525 
 5526 instruct storePConditional( memoryex heap_top_ptr, iRegP oldval, iRegP newval, iRegI tmp, flagsRegP pcc ) %{
 5527   predicate(_kids[1]-&gt;_kids[0]-&gt;_leaf-&gt;Opcode() == Op_LoadPLocked); // only works in conjunction with a LoadPLocked node
 5528   match(Set pcc (StorePConditional heap_top_ptr (Binary oldval newval)));
 5529   effect( TEMP tmp );
 5530   size(8);
 5531   format %{ &quot;STREX  $tmp,$newval,$heap_top_ptr\n\t&quot;
 5532             &quot;CMP    $tmp, 0&quot; %}
 5533   ins_encode %{
 5534     __ strex($tmp$$Register, $newval$$Register, $heap_top_ptr$$Address);
 5535     __ cmp($tmp$$Register, 0);
 5536   %}
 5537   ins_pipe( long_memory_op );
 5538 %}
 5539 
 5540 // Conditional-store of an intx value.
 5541 instruct storeXConditional( memoryex mem, iRegX oldval, iRegX newval, iRegX tmp, flagsReg icc ) %{
 5542   match(Set icc (StoreIConditional mem (Binary oldval newval)));
 5543   effect( TEMP tmp );
 5544   size(28);
 5545   format %{ &quot;loop: \n\t&quot;
 5546             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem], DOESN&#39;T set $newval=[$mem] in any case\n\t&quot;
 5547             &quot;XORS     $tmp,$tmp, $oldval\n\t&quot;
 5548             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5549             &quot;CMP.eq   $tmp, 1 \n\t&quot;
 5550             &quot;B.eq     loop \n\t&quot;
 5551             &quot;TEQ      $tmp, 0\n\t&quot;
 5552             &quot;membar   LoadStore|LoadLoad&quot; %}
 5553   ins_encode %{
 5554     Label loop;
 5555     __ bind(loop);
 5556     __ ldrex($tmp$$Register, $mem$$Address);
 5557     __ eors($tmp$$Register, $tmp$$Register, $oldval$$Register);
 5558     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5559     __ cmp($tmp$$Register, 1, eq);
 5560     __ b(loop, eq);
 5561     __ teq($tmp$$Register, 0);
 5562     // used by biased locking only. Requires a membar.
 5563     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::LoadStore | MacroAssembler::LoadLoad), noreg);
 5564   %}
 5565   ins_pipe( long_memory_op );
 5566 %}
 5567 
 5568 // No flag versions for CompareAndSwap{P,I,L} because matcher can&#39;t match them
 5569 
 5570 instruct compareAndSwapL_bool(memoryex mem, iRegL oldval, iRegLd newval, iRegI res, iRegLd tmp, flagsReg ccr ) %{
 5571   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 5572   effect( KILL ccr, TEMP tmp);
 5573   size(32);
 5574   format %{ &quot;loop: \n\t&quot;
 5575             &quot;LDREXD   $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5576             &quot;CMP      $tmp.lo, $oldval.lo\n\t&quot;
 5577             &quot;CMP.eq   $tmp.hi, $oldval.hi\n\t&quot;
 5578             &quot;STREXD.eq $tmp, $newval, $mem\n\t&quot;
 5579             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5580             &quot;XORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5581             &quot;B.eq     loop \n\t&quot;
 5582             &quot;MOV      $res, $tmp&quot; %}
 5583   ins_encode %{
 5584     Label loop;
 5585     __ bind(loop);
 5586     __ ldrexd($tmp$$Register, $mem$$Address);
 5587     __ cmp($tmp$$Register, $oldval$$Register);
 5588     __ cmp($tmp$$Register-&gt;successor(), $oldval$$Register-&gt;successor(), eq);
 5589     __ strexd($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5590     __ mov($tmp$$Register, 0, ne);
 5591     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5592     __ b(loop, eq);
 5593     __ mov($res$$Register, $tmp$$Register);
 5594   %}
 5595   ins_pipe( long_memory_op );
 5596 %}
 5597 
 5598 
 5599 instruct compareAndSwapI_bool(memoryex mem, iRegI oldval, iRegI newval, iRegI res, iRegI tmp, flagsReg ccr ) %{
 5600   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 5601   effect( KILL ccr, TEMP tmp);
 5602   size(28);
 5603   format %{ &quot;loop: \n\t&quot;
 5604             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5605             &quot;CMP      $tmp, $oldval\n\t&quot;
 5606             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5607             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5608             &quot;XORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5609             &quot;B.eq     loop \n\t&quot;
 5610             &quot;MOV      $res, $tmp&quot; %}
 5611 
 5612   ins_encode %{
 5613     Label loop;
 5614     __ bind(loop);
 5615     __ ldrex($tmp$$Register,$mem$$Address);
 5616     __ cmp($tmp$$Register, $oldval$$Register);
 5617     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5618     __ mov($tmp$$Register, 0, ne);
 5619     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5620     __ b(loop, eq);
 5621     __ mov($res$$Register, $tmp$$Register);
 5622   %}
 5623   ins_pipe( long_memory_op );
 5624 %}
 5625 
 5626 instruct compareAndSwapP_bool(memoryex mem, iRegP oldval, iRegP newval, iRegI res, iRegI tmp, flagsReg ccr ) %{
 5627   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 5628   effect( KILL ccr, TEMP tmp);
 5629   size(28);
 5630   format %{ &quot;loop: \n\t&quot;
 5631             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5632             &quot;CMP      $tmp, $oldval\n\t&quot;
 5633             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5634             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5635             &quot;EORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5636             &quot;B.eq     loop \n\t&quot;
 5637             &quot;MOV      $res, $tmp&quot; %}
 5638 
 5639   ins_encode %{
 5640     Label loop;
 5641     __ bind(loop);
 5642     __ ldrex($tmp$$Register,$mem$$Address);
 5643     __ cmp($tmp$$Register, $oldval$$Register);
 5644     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5645     __ mov($tmp$$Register, 0, ne);
 5646     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5647     __ b(loop, eq);
 5648     __ mov($res$$Register, $tmp$$Register);
 5649   %}
 5650   ins_pipe( long_memory_op );
 5651 %}
 5652 
 5653 instruct xaddI_aimmI_no_res(memoryex mem, aimmI add, Universe dummy, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5654   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5655   match(Set dummy (GetAndAddI mem add));
 5656   effect(KILL ccr, TEMP tmp1, TEMP tmp2);
 5657   size(20);
 5658   format %{ &quot;loop: \n\t&quot;
 5659             &quot;LDREX    $tmp1, $mem\n\t&quot;
 5660             &quot;ADD      $tmp1, $tmp1, $add\n\t&quot;
 5661             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5662             &quot;CMP      $tmp2, 0 \n\t&quot;
 5663             &quot;B.ne     loop \n\t&quot; %}
 5664 
 5665   ins_encode %{
 5666     Label loop;
 5667     __ bind(loop);
 5668     __ ldrex($tmp1$$Register,$mem$$Address);
 5669     __ add($tmp1$$Register, $tmp1$$Register, $add$$constant);
 5670     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5671     __ cmp($tmp2$$Register, 0);
 5672     __ b(loop, ne);
 5673   %}
 5674   ins_pipe( long_memory_op );
 5675 %}
 5676 
 5677 instruct xaddI_reg_no_res(memoryex mem, iRegI add, Universe dummy, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5678   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5679   match(Set dummy (GetAndAddI mem add));
 5680   effect(KILL ccr, TEMP tmp1, TEMP tmp2);
 5681   size(20);
 5682   format %{ &quot;loop: \n\t&quot;
 5683             &quot;LDREX    $tmp1, $mem\n\t&quot;
 5684             &quot;ADD      $tmp1, $tmp1, $add\n\t&quot;
 5685             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5686             &quot;CMP      $tmp2, 0 \n\t&quot;
 5687             &quot;B.ne     loop \n\t&quot; %}
 5688 
 5689   ins_encode %{
 5690     Label loop;
 5691     __ bind(loop);
 5692     __ ldrex($tmp1$$Register,$mem$$Address);
 5693     __ add($tmp1$$Register, $tmp1$$Register, $add$$Register);
 5694     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5695     __ cmp($tmp2$$Register, 0);
 5696     __ b(loop, ne);
 5697   %}
 5698   ins_pipe( long_memory_op );
 5699 %}
 5700 
 5701 instruct xaddI_aimmI(memoryex mem, aimmI add, iRegI res, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5702   match(Set res (GetAndAddI mem add));
 5703   effect(KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5704   size(20);
 5705   format %{ &quot;loop: \n\t&quot;
 5706             &quot;LDREX    $res, $mem\n\t&quot;
 5707             &quot;ADD      $tmp1, $res, $add\n\t&quot;
 5708             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5709             &quot;CMP      $tmp2, 0 \n\t&quot;
 5710             &quot;B.ne     loop \n\t&quot; %}
 5711 
 5712   ins_encode %{
 5713     Label loop;
 5714     __ bind(loop);
 5715     __ ldrex($res$$Register,$mem$$Address);
 5716     __ add($tmp1$$Register, $res$$Register, $add$$constant);
 5717     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5718     __ cmp($tmp2$$Register, 0);
 5719     __ b(loop, ne);
 5720   %}
 5721   ins_pipe( long_memory_op );
 5722 %}
 5723 
 5724 instruct xaddI_reg(memoryex mem, iRegI add, iRegI res, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5725   match(Set res (GetAndAddI mem add));
 5726   effect(KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5727   size(20);
 5728   format %{ &quot;loop: \n\t&quot;
 5729             &quot;LDREX    $res, $mem\n\t&quot;
 5730             &quot;ADD      $tmp1, $res, $add\n\t&quot;
 5731             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5732             &quot;CMP      $tmp2, 0 \n\t&quot;
 5733             &quot;B.ne     loop \n\t&quot; %}
 5734 
 5735   ins_encode %{
 5736     Label loop;
 5737     __ bind(loop);
 5738     __ ldrex($res$$Register,$mem$$Address);
 5739     __ add($tmp1$$Register, $res$$Register, $add$$Register);
 5740     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5741     __ cmp($tmp2$$Register, 0);
 5742     __ b(loop, ne);
 5743   %}
 5744   ins_pipe( long_memory_op );
 5745 %}
 5746 
 5747 instruct xaddL_reg_no_res(memoryex mem, iRegL add, Universe dummy, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5748   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5749   match(Set dummy (GetAndAddL mem add));
 5750   effect( KILL ccr, TEMP tmp1, TEMP tmp2);
 5751   size(24);
 5752   format %{ &quot;loop: \n\t&quot;
 5753             &quot;LDREXD   $tmp1, $mem\n\t&quot;
 5754             &quot;ADDS     $tmp1.lo, $tmp1.lo, $add.lo\n\t&quot;
 5755             &quot;ADC      $tmp1.hi, $tmp1.hi, $add.hi\n\t&quot;
 5756             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5757             &quot;CMP      $tmp2, 0 \n\t&quot;
 5758             &quot;B.ne     loop \n\t&quot; %}
 5759 
 5760   ins_encode %{
 5761     Label loop;
 5762     __ bind(loop);
 5763     __ ldrexd($tmp1$$Register, $mem$$Address);
 5764     __ adds($tmp1$$Register, $tmp1$$Register, $add$$Register);
 5765     __ adc($tmp1$$Register-&gt;successor(), $tmp1$$Register-&gt;successor(), $add$$Register-&gt;successor());
 5766     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5767     __ cmp($tmp2$$Register, 0);
 5768     __ b(loop, ne);
 5769   %}
 5770   ins_pipe( long_memory_op );
 5771 %}
 5772 
 5773 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5774 // (hi($con$$constant), lo($con$$constant)) becomes
 5775 instruct xaddL_immRot_no_res(memoryex mem, immLlowRot add, Universe dummy, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5776   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5777   match(Set dummy (GetAndAddL mem add));
 5778   effect( KILL ccr, TEMP tmp1, TEMP tmp2);
 5779   size(24);
 5780   format %{ &quot;loop: \n\t&quot;
 5781             &quot;LDREXD   $tmp1, $mem\n\t&quot;
 5782             &quot;ADDS     $tmp1.lo, $tmp1.lo, $add\n\t&quot;
 5783             &quot;ADC      $tmp1.hi, $tmp1.hi, 0\n\t&quot;
 5784             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5785             &quot;CMP      $tmp2, 0 \n\t&quot;
 5786             &quot;B.ne     loop \n\t&quot; %}
 5787 
 5788   ins_encode %{
 5789     Label loop;
 5790     __ bind(loop);
 5791     __ ldrexd($tmp1$$Register, $mem$$Address);
 5792     __ adds($tmp1$$Register, $tmp1$$Register, $add$$constant);
 5793     __ adc($tmp1$$Register-&gt;successor(), $tmp1$$Register-&gt;successor(), 0);
 5794     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5795     __ cmp($tmp2$$Register, 0);
 5796     __ b(loop, ne);
 5797   %}
 5798   ins_pipe( long_memory_op );
 5799 %}
 5800 
 5801 instruct xaddL_reg(memoryex mem, iRegL add, iRegLd res, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5802   match(Set res (GetAndAddL mem add));
 5803   effect( KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5804   size(24);
 5805   format %{ &quot;loop: \n\t&quot;
 5806             &quot;LDREXD   $res, $mem\n\t&quot;
 5807             &quot;ADDS     $tmp1.lo, $res.lo, $add.lo\n\t&quot;
 5808             &quot;ADC      $tmp1.hi, $res.hi, $add.hi\n\t&quot;
 5809             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5810             &quot;CMP      $tmp2, 0 \n\t&quot;
 5811             &quot;B.ne     loop \n\t&quot; %}
 5812 
 5813   ins_encode %{
 5814     Label loop;
 5815     __ bind(loop);
 5816     __ ldrexd($res$$Register, $mem$$Address);
 5817     __ adds($tmp1$$Register, $res$$Register, $add$$Register);
 5818     __ adc($tmp1$$Register-&gt;successor(), $res$$Register-&gt;successor(), $add$$Register-&gt;successor());
 5819     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5820     __ cmp($tmp2$$Register, 0);
 5821     __ b(loop, ne);
 5822   %}
 5823   ins_pipe( long_memory_op );
 5824 %}
 5825 
 5826 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5827 // (hi($con$$constant), lo($con$$constant)) becomes
 5828 instruct xaddL_immRot(memoryex mem, immLlowRot add, iRegLd res, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5829   match(Set res (GetAndAddL mem add));
 5830   effect( KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5831   size(24);
 5832   format %{ &quot;loop: \n\t&quot;
 5833             &quot;LDREXD   $res, $mem\n\t&quot;
 5834             &quot;ADDS     $tmp1.lo, $res.lo, $add\n\t&quot;
 5835             &quot;ADC      $tmp1.hi, $res.hi, 0\n\t&quot;
 5836             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5837             &quot;CMP      $tmp2, 0 \n\t&quot;
 5838             &quot;B.ne     loop \n\t&quot; %}
 5839 
 5840   ins_encode %{
 5841     Label loop;
 5842     __ bind(loop);
 5843     __ ldrexd($res$$Register, $mem$$Address);
 5844     __ adds($tmp1$$Register, $res$$Register, $add$$constant);
 5845     __ adc($tmp1$$Register-&gt;successor(), $res$$Register-&gt;successor(), 0);
 5846     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5847     __ cmp($tmp2$$Register, 0);
 5848     __ b(loop, ne);
 5849   %}
 5850   ins_pipe( long_memory_op );
 5851 %}
 5852 
 5853 instruct xchgI(memoryex mem, iRegI newval, iRegI res, iRegI tmp, flagsReg ccr) %{
 5854   match(Set res (GetAndSetI mem newval));
 5855   effect(KILL ccr, TEMP tmp, TEMP res);
 5856   size(16);
 5857   format %{ &quot;loop: \n\t&quot;
 5858             &quot;LDREX    $res, $mem\n\t&quot;
 5859             &quot;STREX    $tmp, $newval, $mem\n\t&quot;
 5860             &quot;CMP      $tmp, 0 \n\t&quot;
 5861             &quot;B.ne     loop \n\t&quot; %}
 5862 
 5863   ins_encode %{
 5864     Label loop;
 5865     __ bind(loop);
 5866     __ ldrex($res$$Register,$mem$$Address);
 5867     __ strex($tmp$$Register, $newval$$Register, $mem$$Address);
 5868     __ cmp($tmp$$Register, 0);
 5869     __ b(loop, ne);
 5870   %}
 5871   ins_pipe( long_memory_op );
 5872 %}
 5873 
 5874 instruct xchgL(memoryex mem, iRegLd newval, iRegLd res, iRegI tmp, flagsReg ccr) %{
 5875   match(Set res (GetAndSetL mem newval));
 5876   effect( KILL ccr, TEMP tmp, TEMP res);
 5877   size(16);
 5878   format %{ &quot;loop: \n\t&quot;
 5879             &quot;LDREXD   $res, $mem\n\t&quot;
 5880             &quot;STREXD   $tmp, $newval, $mem\n\t&quot;
 5881             &quot;CMP      $tmp, 0 \n\t&quot;
 5882             &quot;B.ne     loop \n\t&quot; %}
 5883 
 5884   ins_encode %{
 5885     Label loop;
 5886     __ bind(loop);
 5887     __ ldrexd($res$$Register, $mem$$Address);
 5888     __ strexd($tmp$$Register, $newval$$Register, $mem$$Address);
 5889     __ cmp($tmp$$Register, 0);
 5890     __ b(loop, ne);
 5891   %}
 5892   ins_pipe( long_memory_op );
 5893 %}
 5894 
 5895 instruct xchgP(memoryex mem, iRegP newval, iRegP res, iRegI tmp, flagsReg ccr) %{
 5896   match(Set res (GetAndSetP mem newval));
 5897   effect(KILL ccr, TEMP tmp, TEMP res);
 5898   size(16);
 5899   format %{ &quot;loop: \n\t&quot;
 5900             &quot;LDREX    $res, $mem\n\t&quot;
 5901             &quot;STREX    $tmp, $newval, $mem\n\t&quot;
 5902             &quot;CMP      $tmp, 0 \n\t&quot;
 5903             &quot;B.ne     loop \n\t&quot; %}
 5904 
 5905   ins_encode %{
 5906     Label loop;
 5907     __ bind(loop);
 5908     __ ldrex($res$$Register,$mem$$Address);
 5909     __ strex($tmp$$Register, $newval$$Register, $mem$$Address);
 5910     __ cmp($tmp$$Register, 0);
 5911     __ b(loop, ne);
 5912   %}
 5913   ins_pipe( long_memory_op );
 5914 %}
 5915 
 5916 //---------------------
 5917 // Subtraction Instructions
 5918 // Register Subtraction
 5919 instruct subI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 5920   match(Set dst (SubI src1 src2));
 5921 
 5922   size(4);
 5923   format %{ &quot;sub_32 $dst,$src1,$src2\t! int&quot; %}
 5924   ins_encode %{
 5925     __ sub_32($dst$$Register, $src1$$Register, $src2$$Register);
 5926   %}
 5927   ins_pipe(ialu_reg_reg);
 5928 %}
 5929 
 5930 instruct subshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5931   match(Set dst (SubI src1 (LShiftI src2 src3)));
 5932 
 5933   size(4);
 5934   format %{ &quot;SUB    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 5935   ins_encode %{
 5936     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 5937   %}
 5938   ins_pipe(ialu_reg_reg);
 5939 %}
 5940 
 5941 instruct subshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5942   match(Set dst (SubI src1 (LShiftI src2 src3)));
 5943 
 5944   size(4);
 5945   format %{ &quot;sub_32 $dst,$src1,$src2&lt;&lt;$src3\t! int&quot; %}
 5946   ins_encode %{
 5947     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 5948   %}
 5949   ins_pipe(ialu_reg_reg);
 5950 %}
 5951 
 5952 instruct subsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5953   match(Set dst (SubI src1 (RShiftI src2 src3)));
 5954 
 5955   size(4);
 5956   format %{ &quot;SUB    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 5957   ins_encode %{
 5958     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 5959   %}
 5960   ins_pipe(ialu_reg_reg);
 5961 %}
 5962 
 5963 instruct subsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5964   match(Set dst (SubI src1 (RShiftI src2 src3)));
 5965 
 5966   size(4);
 5967   format %{ &quot;sub_32 $dst,$src1,$src2&gt;&gt;$src3\t! int&quot; %}
 5968   ins_encode %{
 5969     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 5970   %}
 5971   ins_pipe(ialu_reg_reg);
 5972 %}
 5973 
 5974 instruct subshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5975   match(Set dst (SubI src1 (URShiftI src2 src3)));
 5976 
 5977   size(4);
 5978   format %{ &quot;SUB    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 5979   ins_encode %{
 5980     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 5981   %}
 5982   ins_pipe(ialu_reg_reg);
 5983 %}
 5984 
 5985 instruct subshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5986   match(Set dst (SubI src1 (URShiftI src2 src3)));
 5987 
 5988   size(4);
 5989   format %{ &quot;sub_32 $dst,$src1,$src2&gt;&gt;&gt;$src3\t! int&quot; %}
 5990   ins_encode %{
 5991     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 5992   %}
 5993   ins_pipe(ialu_reg_reg);
 5994 %}
 5995 
 5996 instruct rsbshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5997   match(Set dst (SubI (LShiftI src1 src2) src3));
 5998 
 5999   size(4);
 6000   format %{ &quot;RSB    $dst,$src3,$src1&lt;&lt;$src2&quot; %}
 6001   ins_encode %{
 6002     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6003   %}
 6004   ins_pipe(ialu_reg_reg);
 6005 %}
 6006 
 6007 instruct rsbshlI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6008   match(Set dst (SubI (LShiftI src1 src2) src3));
 6009 
 6010   size(4);
 6011   format %{ &quot;RSB    $dst,$src3,$src1&lt;&lt;$src2&quot; %}
 6012   ins_encode %{
 6013     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 6014   %}
 6015   ins_pipe(ialu_reg_reg);
 6016 %}
 6017 
 6018 instruct rsbsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6019   match(Set dst (SubI (RShiftI src1 src2) src3));
 6020 
 6021   size(4);
 6022   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;$src2&quot; %}
 6023   ins_encode %{
 6024     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 6025   %}
 6026   ins_pipe(ialu_reg_reg);
 6027 %}
 6028 
 6029 instruct rsbsarI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6030   match(Set dst (SubI (RShiftI src1 src2) src3));
 6031 
 6032   size(4);
 6033   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;$src2&quot; %}
 6034   ins_encode %{
 6035     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 6036   %}
 6037   ins_pipe(ialu_reg_reg);
 6038 %}
 6039 
 6040 instruct rsbshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6041   match(Set dst (SubI (URShiftI src1 src2) src3));
 6042 
 6043   size(4);
 6044   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;&gt;$src2&quot; %}
 6045   ins_encode %{
 6046     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6047   %}
 6048   ins_pipe(ialu_reg_reg);
 6049 %}
 6050 
 6051 instruct rsbshrI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6052   match(Set dst (SubI (URShiftI src1 src2) src3));
 6053 
 6054   size(4);
 6055   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;&gt;$src2&quot; %}
 6056   ins_encode %{
 6057     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6058   %}
 6059   ins_pipe(ialu_reg_reg);
 6060 %}
 6061 
 6062 // Immediate Subtraction
 6063 instruct subI_reg_aimmI(iRegI dst, iRegI src1, aimmI src2) %{
 6064   match(Set dst (SubI src1 src2));
 6065 
 6066   size(4);
 6067   format %{ &quot;sub_32 $dst,$src1,$src2\t! int&quot; %}
 6068   ins_encode %{
 6069     __ sub_32($dst$$Register, $src1$$Register, $src2$$constant);
 6070   %}
 6071   ins_pipe(ialu_reg_imm);
 6072 %}
 6073 
 6074 instruct subI_reg_immRotneg(iRegI dst, iRegI src1, aimmIneg src2) %{
 6075   match(Set dst (AddI src1 src2));
 6076 
 6077   size(4);
 6078   format %{ &quot;sub_32 $dst,$src1,-($src2)\t! int&quot; %}
 6079   ins_encode %{
 6080     __ sub_32($dst$$Register, $src1$$Register, -$src2$$constant);
 6081   %}
 6082   ins_pipe(ialu_reg_imm);
 6083 %}
 6084 
 6085 instruct subI_immRot_reg(iRegI dst, immIRot src1, iRegI src2) %{
 6086   match(Set dst (SubI src1 src2));
 6087 
 6088   size(4);
 6089   format %{ &quot;RSB    $dst,$src2,src1&quot; %}
 6090   ins_encode %{
 6091     __ rsb($dst$$Register, $src2$$Register, $src1$$constant);
 6092   %}
 6093   ins_pipe(ialu_zero_reg);
 6094 %}
 6095 
 6096 // Register Subtraction
 6097 instruct subL_reg_reg(iRegL dst, iRegL src1, iRegL src2, flagsReg icc ) %{
 6098   match(Set dst (SubL src1 src2));
 6099   effect (KILL icc);
 6100 
 6101   size(8);
 6102   format %{ &quot;SUBS   $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 6103             &quot;SBC    $dst.hi,$src1.hi,$src2.hi&quot; %}
 6104   ins_encode %{
 6105     __ subs($dst$$Register, $src1$$Register, $src2$$Register);
 6106     __ sbc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 6107   %}
 6108   ins_pipe(ialu_reg_reg);
 6109 %}
 6110 
 6111 // TODO
 6112 
 6113 // Immediate Subtraction
 6114 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 6115 // (hi($con$$constant), lo($con$$constant)) becomes
 6116 instruct subL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con, flagsReg icc) %{
 6117   match(Set dst (SubL src1 con));
 6118   effect (KILL icc);
 6119 
 6120   size(8);
 6121   format %{ &quot;SUB    $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 6122             &quot;SBC    $dst.hi,$src1.hi,0&quot; %}
 6123   ins_encode %{
 6124     __ subs($dst$$Register, $src1$$Register, $con$$constant);
 6125     __ sbc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 6126   %}
 6127   ins_pipe(ialu_reg_imm);
 6128 %}
 6129 
 6130 // Long negation
 6131 instruct negL_reg_reg(iRegL dst, immL0 zero, iRegL src2, flagsReg icc) %{
 6132   match(Set dst (SubL zero src2));
 6133   effect (KILL icc);
 6134 
 6135   size(8);
 6136   format %{ &quot;RSBS   $dst.lo,$src2.lo,0\t! long\n\t&quot;
 6137             &quot;RSC    $dst.hi,$src2.hi,0&quot; %}
 6138   ins_encode %{
 6139     __ rsbs($dst$$Register, $src2$$Register, 0);
 6140     __ rsc($dst$$Register-&gt;successor(), $src2$$Register-&gt;successor(), 0);
 6141   %}
 6142   ins_pipe(ialu_zero_reg);
 6143 %}
 6144 
 6145 // Multiplication Instructions
 6146 // Integer Multiplication
 6147 // Register Multiplication
 6148 instruct mulI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6149   match(Set dst (MulI src1 src2));
 6150 
 6151   size(4);
 6152   format %{ &quot;mul_32 $dst,$src1,$src2&quot; %}
 6153   ins_encode %{
 6154     __ mul_32($dst$$Register, $src1$$Register, $src2$$Register);
 6155   %}
 6156   ins_pipe(imul_reg_reg);
 6157 %}
 6158 
 6159 instruct mulL_lo1_hi2(iRegL dst, iRegL src1, iRegL src2) %{
 6160   effect(DEF dst, USE src1, USE src2);
 6161   size(4);
 6162   format %{ &quot;MUL  $dst.hi,$src1.lo,$src2.hi\t! long&quot; %}
 6163   ins_encode %{
 6164     __ mul($dst$$Register-&gt;successor(), $src1$$Register, $src2$$Register-&gt;successor());
 6165   %}
 6166   ins_pipe(imul_reg_reg);
 6167 %}
 6168 
 6169 instruct mulL_hi1_lo2(iRegL dst, iRegL src1, iRegL src2) %{
 6170   effect(USE_DEF dst, USE src1, USE src2);
 6171   size(8);
 6172   format %{ &quot;MLA  $dst.hi,$src1.hi,$src2.lo,$dst.hi\t! long\n\t&quot;
 6173             &quot;MOV  $dst.lo, 0&quot;%}
 6174   ins_encode %{
 6175     __ mla($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register, $dst$$Register-&gt;successor());
 6176     __ mov($dst$$Register, 0);
 6177   %}
 6178   ins_pipe(imul_reg_reg);
 6179 %}
 6180 
 6181 instruct mulL_lo1_lo2(iRegL dst, iRegL src1, iRegL src2) %{
 6182   effect(USE_DEF dst, USE src1, USE src2);
 6183   size(4);
 6184   format %{ &quot;UMLAL  $dst.lo,$dst.hi,$src1,$src2\t! long&quot; %}
 6185   ins_encode %{
 6186     __ umlal($dst$$Register, $dst$$Register-&gt;successor(), $src1$$Register, $src2$$Register);
 6187   %}
 6188   ins_pipe(imul_reg_reg);
 6189 %}
 6190 
 6191 instruct mulL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6192   match(Set dst (MulL src1 src2));
 6193 
 6194   expand %{
 6195     mulL_lo1_hi2(dst, src1, src2);
 6196     mulL_hi1_lo2(dst, src1, src2);
 6197     mulL_lo1_lo2(dst, src1, src2);
 6198   %}
 6199 %}
 6200 
 6201 // Integer Division
 6202 // Register Division
 6203 instruct divI_reg_reg(R1RegI dst, R0RegI src1, R2RegI src2, LRRegP lr, flagsReg ccr) %{
 6204   match(Set dst (DivI src1 src2));
 6205   effect( KILL ccr, KILL src1, KILL src2, KILL lr);
 6206   ins_cost((2+71)*DEFAULT_COST);
 6207 
 6208   format %{ &quot;DIV   $dst,$src1,$src2 ! call to StubRoutines::Arm::idiv_irem_entry()&quot; %}
 6209   ins_encode %{
 6210     __ call(StubRoutines::Arm::idiv_irem_entry(), relocInfo::runtime_call_type);
 6211   %}
 6212   ins_pipe(sdiv_reg_reg);
 6213 %}
 6214 
 6215 // Register Long Division
 6216 instruct divL_reg_reg(R0R1RegL dst, R2R3RegL src1, R0R1RegL src2) %{
 6217   match(Set dst (DivL src1 src2));
 6218   effect(CALL);
 6219   ins_cost(DEFAULT_COST*71);
 6220   format %{ &quot;DIVL  $src1,$src2,$dst\t! long ! call to SharedRuntime::ldiv&quot; %}
 6221   ins_encode %{
 6222     address target = CAST_FROM_FN_PTR(address, SharedRuntime::ldiv);
 6223     __ call(target, relocInfo::runtime_call_type);
 6224   %}
 6225   ins_pipe(divL_reg_reg);
 6226 %}
 6227 
 6228 // Integer Remainder
 6229 // Register Remainder
 6230 instruct modI_reg_reg(R0RegI dst, R0RegI src1, R2RegI src2, R1RegI temp, LRRegP lr, flagsReg ccr ) %{
 6231   match(Set dst (ModI src1 src2));
 6232   effect( KILL ccr, KILL temp, KILL src2, KILL lr);
 6233 
 6234   format %{ &quot;MODI   $dst,$src1,$src2\t ! call to StubRoutines::Arm::idiv_irem_entry&quot; %}
 6235   ins_encode %{
 6236     __ call(StubRoutines::Arm::idiv_irem_entry(), relocInfo::runtime_call_type);
 6237   %}
 6238   ins_pipe(sdiv_reg_reg);
 6239 %}
 6240 
 6241 // Register Long Remainder
 6242 instruct modL_reg_reg(R0R1RegL dst, R2R3RegL src1, R0R1RegL src2) %{
 6243   match(Set dst (ModL src1 src2));
 6244   effect(CALL);
 6245   ins_cost(MEMORY_REF_COST); // FIXME
 6246   format %{ &quot;modL    $dst,$src1,$src2\t ! call to SharedRuntime::lrem&quot; %}
 6247   ins_encode %{
 6248     address target = CAST_FROM_FN_PTR(address, SharedRuntime::lrem);
 6249     __ call(target, relocInfo::runtime_call_type);
 6250   %}
 6251   ins_pipe(divL_reg_reg);
 6252 %}
 6253 
 6254 // Integer Shift Instructions
 6255 
 6256 // Register Shift Left
 6257 instruct shlI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6258   match(Set dst (LShiftI src1 src2));
 6259 
 6260   size(4);
 6261   format %{ &quot;LSL  $dst,$src1,$src2 \n\t&quot; %}
 6262   ins_encode %{
 6263     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6264   %}
 6265   ins_pipe(ialu_reg_reg);
 6266 %}
 6267 
 6268 // Register Shift Left Immediate
 6269 instruct shlI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6270   match(Set dst (LShiftI src1 src2));
 6271 
 6272   size(4);
 6273   format %{ &quot;LSL    $dst,$src1,$src2\t! int&quot; %}
 6274   ins_encode %{
 6275     __ logical_shift_left($dst$$Register, $src1$$Register, $src2$$constant);
 6276   %}
 6277   ins_pipe(ialu_reg_imm);
 6278 %}
 6279 
 6280 instruct shlL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6281   effect(USE_DEF dst, USE src1, USE src2);
 6282   size(4);
 6283   format %{&quot;OR  $dst.hi,$dst.hi,($src1.hi &lt;&lt; $src2)&quot;  %}
 6284   ins_encode %{
 6285     __ orr($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsl, $src2$$Register));
 6286   %}
 6287   ins_pipe(ialu_reg_reg);
 6288 %}
 6289 
 6290 instruct shlL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6291   effect(USE_DEF dst, USE src1, USE src2);
 6292   size(4);
 6293   format %{ &quot;LSL  $dst.lo,$src1.lo,$src2 \n\t&quot; %}
 6294   ins_encode %{
 6295     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6296   %}
 6297   ins_pipe(ialu_reg_reg);
 6298 %}
 6299 
 6300 instruct shlL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6301   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6302   size(16);
 6303   format %{ &quot;SUBS  $dst.hi,$src2,32 \n\t&quot;
 6304             &quot;LSLpl $dst.hi,$src1.lo,$dst.hi \n\t&quot;
 6305             &quot;RSBmi $dst.hi,$dst.hi,0 \n\t&quot;
 6306             &quot;LSRmi $dst.hi,$src1.lo,$dst.hi&quot; %}
 6307 
 6308   ins_encode %{
 6309     // $src1$$Register and $dst$$Register-&gt;successor() can&#39;t be the same
 6310     __ subs($dst$$Register-&gt;successor(), $src2$$Register, 32);
 6311     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsl, $dst$$Register-&gt;successor()), pl);
 6312     __ rsb($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), 0, mi);
 6313     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsr, $dst$$Register-&gt;successor()), mi);
 6314   %}
 6315   ins_pipe(ialu_reg_reg);
 6316 %}
 6317 
 6318 instruct shlL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6319   match(Set dst (LShiftL src1 src2));
 6320 
 6321   expand %{
 6322     flagsReg ccr;
 6323     shlL_reg_reg_overlap(dst, src1, src2, ccr);
 6324     shlL_reg_reg_merge_hi(dst, src1, src2);
 6325     shlL_reg_reg_merge_lo(dst, src1, src2);
 6326   %}
 6327 %}
 6328 
 6329 // Register Shift Left Immediate
 6330 instruct shlL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6331   match(Set dst (LShiftL src1 src2));
 6332 
 6333   size(8);
 6334   format %{ &quot;LSL   $dst.hi,$src1.lo,$src2-32\t! or mov if $src2==32\n\t&quot;
 6335             &quot;MOV   $dst.lo, 0&quot; %}
 6336   ins_encode %{
 6337     if ($src2$$constant == 32) {
 6338       __ mov($dst$$Register-&gt;successor(), $src1$$Register);
 6339     } else {
 6340       __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsl, $src2$$constant-32));
 6341     }
 6342     __ mov($dst$$Register, 0);
 6343   %}
 6344   ins_pipe(ialu_reg_imm);
 6345 %}
 6346 
 6347 instruct shlL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6348   match(Set dst (LShiftL src1 src2));
 6349 
 6350   size(12);
 6351   format %{ &quot;LSL   $dst.hi,$src1.lo,$src2\n\t&quot;
 6352             &quot;OR    $dst.hi, $dst.hi, $src1.lo &gt;&gt; 32-$src2\n\t&quot;
 6353             &quot;LSL   $dst.lo,$src1.lo,$src2&quot; %}
 6354   ins_encode %{
 6355     // The order of the following 3 instructions matters: src1.lo and
 6356     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6357     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsl, $src2$$constant));
 6358     __ orr($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsr, 32-$src2$$constant));
 6359     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 6360   %}
 6361   ins_pipe(ialu_reg_imm);
 6362 %}
 6363 
 6364 // Register Arithmetic Shift Right
 6365 instruct sarI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6366   match(Set dst (RShiftI src1 src2));
 6367   size(4);
 6368   format %{ &quot;ASR    $dst,$src1,$src2\t! int&quot; %}
 6369   ins_encode %{
 6370     __ mov($dst$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 6371   %}
 6372   ins_pipe(ialu_reg_reg);
 6373 %}
 6374 
 6375 // Register Arithmetic Shift Right Immediate
 6376 instruct sarI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6377   match(Set dst (RShiftI src1 src2));
 6378 
 6379   size(4);
 6380   format %{ &quot;ASR    $dst,$src1,$src2&quot; %}
 6381   ins_encode %{
 6382     __ mov($dst$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 6383   %}
 6384   ins_pipe(ialu_reg_imm);
 6385 %}
 6386 
 6387 // Register Shift Right Arithmetic Long
 6388 instruct sarL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6389   effect(USE_DEF dst, USE src1, USE src2);
 6390   size(4);
 6391   format %{ &quot;OR  $dst.lo,$dst.lo,($src1.lo &gt;&gt; $src2)&quot;  %}
 6392   ins_encode %{
 6393     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6394   %}
 6395   ins_pipe(ialu_reg_reg);
 6396 %}
 6397 
 6398 instruct sarL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6399   effect(USE_DEF dst, USE src1, USE src2);
 6400   size(4);
 6401   format %{ &quot;ASR  $dst.hi,$src1.hi,$src2 \n\t&quot; %}
 6402   ins_encode %{
 6403     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$Register));
 6404   %}
 6405   ins_pipe(ialu_reg_reg);
 6406 %}
 6407 
 6408 instruct sarL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6409   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6410   size(16);
 6411   format %{ &quot;SUBS  $dst.lo,$src2,32 \n\t&quot;
 6412             &quot;ASRpl $dst.lo,$src1.hi,$dst.lo \n\t&quot;
 6413             &quot;RSBmi $dst.lo,$dst.lo,0 \n\t&quot;
 6414             &quot;LSLmi $dst.lo,$src1.hi,$dst.lo&quot; %}
 6415 
 6416   ins_encode %{
 6417     // $src1$$Register-&gt;successor() and $dst$$Register can&#39;t be the same
 6418     __ subs($dst$$Register, $src2$$Register, 32);
 6419     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), asr, $dst$$Register), pl);
 6420     __ rsb($dst$$Register, $dst$$Register, 0, mi);
 6421     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, $dst$$Register), mi);
 6422   %}
 6423   ins_pipe(ialu_reg_reg);
 6424 %}
 6425 
 6426 instruct sarL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6427   match(Set dst (RShiftL src1 src2));
 6428 
 6429   expand %{
 6430     flagsReg ccr;
 6431     sarL_reg_reg_overlap(dst, src1, src2, ccr);
 6432     sarL_reg_reg_merge_lo(dst, src1, src2);
 6433     sarL_reg_reg_merge_hi(dst, src1, src2);
 6434   %}
 6435 %}
 6436 
 6437 // Register Shift Left Immediate
 6438 instruct sarL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6439   match(Set dst (RShiftL src1 src2));
 6440 
 6441   size(8);
 6442   format %{ &quot;ASR   $dst.lo,$src1.hi,$src2-32\t! or mov if $src2==32\n\t&quot;
 6443             &quot;ASR   $dst.hi,$src1.hi, $src2&quot; %}
 6444   ins_encode %{
 6445     if ($src2$$constant == 32) {
 6446       __ mov($dst$$Register, $src1$$Register-&gt;successor());
 6447     } else{
 6448       __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$constant-32));
 6449     }
 6450     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, 0));
 6451   %}
 6452 
 6453   ins_pipe(ialu_reg_imm);
 6454 %}
 6455 
 6456 instruct sarL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6457   match(Set dst (RShiftL src1 src2));
 6458   size(12);
 6459   format %{ &quot;LSR   $dst.lo,$src1.lo,$src2\n\t&quot;
 6460             &quot;OR    $dst.lo, $dst.lo, $src1.hi &lt;&lt; 32-$src2\n\t&quot;
 6461             &quot;ASR   $dst.hi,$src1.hi,$src2&quot; %}
 6462   ins_encode %{
 6463     // The order of the following 3 instructions matters: src1.lo and
 6464     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6465     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6466     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, 32-$src2$$constant));
 6467     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$constant));
 6468   %}
 6469   ins_pipe(ialu_reg_imm);
 6470 %}
 6471 
 6472 // Register Shift Right
 6473 instruct shrI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6474   match(Set dst (URShiftI src1 src2));
 6475   size(4);
 6476   format %{ &quot;LSR    $dst,$src1,$src2\t! int&quot; %}
 6477   ins_encode %{
 6478     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6479   %}
 6480   ins_pipe(ialu_reg_reg);
 6481 %}
 6482 
 6483 // Register Shift Right Immediate
 6484 instruct shrI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6485   match(Set dst (URShiftI src1 src2));
 6486 
 6487   size(4);
 6488   format %{ &quot;LSR    $dst,$src1,$src2&quot; %}
 6489   ins_encode %{
 6490     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6491   %}
 6492   ins_pipe(ialu_reg_imm);
 6493 %}
 6494 
 6495 // Register Shift Right
 6496 instruct shrL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6497   effect(USE_DEF dst, USE src1, USE src2);
 6498   size(4);
 6499   format %{ &quot;OR   $dst.lo,$dst,($src1.lo &gt;&gt;&gt; $src2)&quot;  %}
 6500   ins_encode %{
 6501     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6502   %}
 6503   ins_pipe(ialu_reg_reg);
 6504 %}
 6505 
 6506 instruct shrL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6507   effect(USE_DEF dst, USE src1, USE src2);
 6508   size(4);
 6509   format %{ &quot;LSR  $dst.hi,$src1.hi,$src2 \n\t&quot; %}
 6510   ins_encode %{
 6511     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$Register));
 6512   %}
 6513   ins_pipe(ialu_reg_reg);
 6514 %}
 6515 
 6516 instruct shrL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6517   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6518   size(16);
 6519   format %{ &quot;SUBS  $dst,$src2,32 \n\t&quot;
 6520             &quot;LSRpl $dst,$src1.hi,$dst \n\t&quot;
 6521             &quot;RSBmi $dst,$dst,0 \n\t&quot;
 6522             &quot;LSLmi $dst,$src1.hi,$dst&quot; %}
 6523 
 6524   ins_encode %{
 6525     // $src1$$Register-&gt;successor() and $dst$$Register can&#39;t be the same
 6526     __ subs($dst$$Register, $src2$$Register, 32);
 6527     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsr, $dst$$Register), pl);
 6528     __ rsb($dst$$Register, $dst$$Register, 0, mi);
 6529     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, $dst$$Register), mi);
 6530   %}
 6531   ins_pipe(ialu_reg_reg);
 6532 %}
 6533 
 6534 instruct shrL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6535   match(Set dst (URShiftL src1 src2));
 6536 
 6537   expand %{
 6538     flagsReg ccr;
 6539     shrL_reg_reg_overlap(dst, src1, src2, ccr);
 6540     shrL_reg_reg_merge_lo(dst, src1, src2);
 6541     shrL_reg_reg_merge_hi(dst, src1, src2);
 6542   %}
 6543 %}
 6544 
 6545 // Register Shift Right Immediate
 6546 instruct shrL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6547   match(Set dst (URShiftL src1 src2));
 6548 
 6549   size(8);
 6550   format %{ &quot;LSR   $dst.lo,$src1.hi,$src2-32\t! or mov if $src2==32\n\t&quot;
 6551             &quot;MOV   $dst.hi, 0&quot; %}
 6552   ins_encode %{
 6553     if ($src2$$constant == 32) {
 6554       __ mov($dst$$Register, $src1$$Register-&gt;successor());
 6555     } else {
 6556       __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$constant-32));
 6557     }
 6558     __ mov($dst$$Register-&gt;successor(), 0);
 6559   %}
 6560 
 6561   ins_pipe(ialu_reg_imm);
 6562 %}
 6563 
 6564 instruct shrL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6565   match(Set dst (URShiftL src1 src2));
 6566 
 6567   size(12);
 6568   format %{ &quot;LSR   $dst.lo,$src1.lo,$src2\n\t&quot;
 6569             &quot;OR    $dst.lo, $dst.lo, $src1.hi &lt;&lt; 32-$src2\n\t&quot;
 6570             &quot;LSR   $dst.hi,$src1.hi,$src2&quot; %}
 6571   ins_encode %{
 6572     // The order of the following 3 instructions matters: src1.lo and
 6573     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6574     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6575     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, 32-$src2$$constant));
 6576     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$constant));
 6577   %}
 6578   ins_pipe(ialu_reg_imm);
 6579 %}
 6580 
 6581 
 6582 instruct shrP_reg_imm5(iRegX dst, iRegP src1, immU5 src2) %{
 6583   match(Set dst (URShiftI (CastP2X src1) src2));
 6584   size(4);
 6585   format %{ &quot;LSR    $dst,$src1,$src2\t! Cast ptr $src1 to int and shift&quot; %}
 6586   ins_encode %{
 6587     __ logical_shift_right($dst$$Register, $src1$$Register, $src2$$constant);
 6588   %}
 6589   ins_pipe(ialu_reg_imm);
 6590 %}
 6591 
 6592 //----------Floating Point Arithmetic Instructions-----------------------------
 6593 
 6594 //  Add float single precision
 6595 instruct addF_reg_reg(regF dst, regF src1, regF src2) %{
 6596   match(Set dst (AddF src1 src2));
 6597 
 6598   size(4);
 6599   format %{ &quot;FADDS  $dst,$src1,$src2&quot; %}
 6600   ins_encode %{
 6601     __ add_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6602   %}
 6603 
 6604   ins_pipe(faddF_reg_reg);
 6605 %}
 6606 
 6607 //  Add float double precision
 6608 instruct addD_reg_reg(regD dst, regD src1, regD src2) %{
 6609   match(Set dst (AddD src1 src2));
 6610 
 6611   size(4);
 6612   format %{ &quot;FADDD  $dst,$src1,$src2&quot; %}
 6613   ins_encode %{
 6614     __ add_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6615   %}
 6616 
 6617   ins_pipe(faddD_reg_reg);
 6618 %}
 6619 
 6620 //  Sub float single precision
 6621 instruct subF_reg_reg(regF dst, regF src1, regF src2) %{
 6622   match(Set dst (SubF src1 src2));
 6623 
 6624   size(4);
 6625   format %{ &quot;FSUBS  $dst,$src1,$src2&quot; %}
 6626   ins_encode %{
 6627     __ sub_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6628   %}
 6629   ins_pipe(faddF_reg_reg);
 6630 %}
 6631 
 6632 //  Sub float double precision
 6633 instruct subD_reg_reg(regD dst, regD src1, regD src2) %{
 6634   match(Set dst (SubD src1 src2));
 6635 
 6636   size(4);
 6637   format %{ &quot;FSUBD  $dst,$src1,$src2&quot; %}
 6638   ins_encode %{
 6639     __ sub_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6640   %}
 6641   ins_pipe(faddD_reg_reg);
 6642 %}
 6643 
 6644 //  Mul float single precision
 6645 instruct mulF_reg_reg(regF dst, regF src1, regF src2) %{
 6646   match(Set dst (MulF src1 src2));
 6647 
 6648   size(4);
 6649   format %{ &quot;FMULS  $dst,$src1,$src2&quot; %}
 6650   ins_encode %{
 6651     __ mul_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6652   %}
 6653 
 6654   ins_pipe(fmulF_reg_reg);
 6655 %}
 6656 
 6657 //  Mul float double precision
 6658 instruct mulD_reg_reg(regD dst, regD src1, regD src2) %{
 6659   match(Set dst (MulD src1 src2));
 6660 
 6661   size(4);
 6662   format %{ &quot;FMULD  $dst,$src1,$src2&quot; %}
 6663   ins_encode %{
 6664     __ mul_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6665   %}
 6666 
 6667   ins_pipe(fmulD_reg_reg);
 6668 %}
 6669 
 6670 //  Div float single precision
 6671 instruct divF_reg_reg(regF dst, regF src1, regF src2) %{
 6672   match(Set dst (DivF src1 src2));
 6673 
 6674   size(4);
 6675   format %{ &quot;FDIVS  $dst,$src1,$src2&quot; %}
 6676   ins_encode %{
 6677     __ div_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6678   %}
 6679 
 6680   ins_pipe(fdivF_reg_reg);
 6681 %}
 6682 
 6683 //  Div float double precision
 6684 instruct divD_reg_reg(regD dst, regD src1, regD src2) %{
 6685   match(Set dst (DivD src1 src2));
 6686 
 6687   size(4);
 6688   format %{ &quot;FDIVD  $dst,$src1,$src2&quot; %}
 6689   ins_encode %{
 6690     __ div_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6691   %}
 6692 
 6693   ins_pipe(fdivD_reg_reg);
 6694 %}
 6695 
 6696 //  Absolute float double precision
 6697 instruct absD_reg(regD dst, regD src) %{
 6698   match(Set dst (AbsD src));
 6699 
 6700   size(4);
 6701   format %{ &quot;FABSd  $dst,$src&quot; %}
 6702   ins_encode %{
 6703     __ abs_double($dst$$FloatRegister, $src$$FloatRegister);
 6704   %}
 6705   ins_pipe(faddD_reg);
 6706 %}
 6707 
 6708 //  Absolute float single precision
 6709 instruct absF_reg(regF dst, regF src) %{
 6710   match(Set dst (AbsF src));
 6711   format %{ &quot;FABSs  $dst,$src&quot; %}
 6712   ins_encode %{
 6713     __ abs_float($dst$$FloatRegister, $src$$FloatRegister);
 6714   %}
 6715   ins_pipe(faddF_reg);
 6716 %}
 6717 
 6718 instruct negF_reg(regF dst, regF src) %{
 6719   match(Set dst (NegF src));
 6720 
 6721   size(4);
 6722   format %{ &quot;FNEGs  $dst,$src&quot; %}
 6723   ins_encode %{
 6724     __ neg_float($dst$$FloatRegister, $src$$FloatRegister);
 6725   %}
 6726   ins_pipe(faddF_reg);
 6727 %}
 6728 
 6729 instruct negD_reg(regD dst, regD src) %{
 6730   match(Set dst (NegD src));
 6731 
 6732   format %{ &quot;FNEGd  $dst,$src&quot; %}
 6733   ins_encode %{
 6734     __ neg_double($dst$$FloatRegister, $src$$FloatRegister);
 6735   %}
 6736   ins_pipe(faddD_reg);
 6737 %}
 6738 
 6739 //  Sqrt float double precision
 6740 instruct sqrtF_reg_reg(regF dst, regF src) %{
 6741   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
 6742 
 6743   size(4);
 6744   format %{ &quot;FSQRTS $dst,$src&quot; %}
 6745   ins_encode %{
 6746     __ sqrt_float($dst$$FloatRegister, $src$$FloatRegister);
 6747   %}
 6748   ins_pipe(fdivF_reg_reg);
 6749 %}
 6750 
 6751 //  Sqrt float double precision
 6752 instruct sqrtD_reg_reg(regD dst, regD src) %{
 6753   match(Set dst (SqrtD src));
 6754 
 6755   size(4);
 6756   format %{ &quot;FSQRTD $dst,$src&quot; %}
 6757   ins_encode %{
 6758     __ sqrt_double($dst$$FloatRegister, $src$$FloatRegister);
 6759   %}
 6760   ins_pipe(fdivD_reg_reg);
 6761 %}
 6762 
 6763 //----------Logical Instructions-----------------------------------------------
 6764 // And Instructions
 6765 // Register And
 6766 instruct andI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6767   match(Set dst (AndI src1 src2));
 6768 
 6769   size(4);
 6770   format %{ &quot;and_32 $dst,$src1,$src2&quot; %}
 6771   ins_encode %{
 6772     __ and_32($dst$$Register, $src1$$Register, $src2$$Register);
 6773   %}
 6774   ins_pipe(ialu_reg_reg);
 6775 %}
 6776 
 6777 instruct andshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6778   match(Set dst (AndI src1 (LShiftI src2 src3)));
 6779 
 6780   size(4);
 6781   format %{ &quot;AND    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6782   ins_encode %{
 6783     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 6784   %}
 6785   ins_pipe(ialu_reg_reg);
 6786 %}
 6787 
 6788 instruct andshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6789   match(Set dst (AndI src1 (LShiftI src2 src3)));
 6790 
 6791   size(4);
 6792   format %{ &quot;and_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6793   ins_encode %{
 6794     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 6795   %}
 6796   ins_pipe(ialu_reg_reg);
 6797 %}
 6798 
 6799 instruct andsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6800   match(Set dst (AndI src1 (RShiftI src2 src3)));
 6801 
 6802   size(4);
 6803   format %{ &quot;AND    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6804   ins_encode %{
 6805     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 6806   %}
 6807   ins_pipe(ialu_reg_reg);
 6808 %}
 6809 
 6810 instruct andsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6811   match(Set dst (AndI src1 (RShiftI src2 src3)));
 6812 
 6813   size(4);
 6814   format %{ &quot;and_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6815   ins_encode %{
 6816     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 6817   %}
 6818   ins_pipe(ialu_reg_reg);
 6819 %}
 6820 
 6821 instruct andshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6822   match(Set dst (AndI src1 (URShiftI src2 src3)));
 6823 
 6824   size(4);
 6825   format %{ &quot;AND    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6826   ins_encode %{
 6827     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 6828   %}
 6829   ins_pipe(ialu_reg_reg);
 6830 %}
 6831 
 6832 instruct andshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6833   match(Set dst (AndI src1 (URShiftI src2 src3)));
 6834 
 6835   size(4);
 6836   format %{ &quot;and_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6837   ins_encode %{
 6838     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 6839   %}
 6840   ins_pipe(ialu_reg_reg);
 6841 %}
 6842 
 6843 // Immediate And
 6844 instruct andI_reg_limm(iRegI dst, iRegI src1, limmI src2) %{
 6845   match(Set dst (AndI src1 src2));
 6846 
 6847   size(4);
 6848   format %{ &quot;and_32 $dst,$src1,$src2\t! int&quot; %}
 6849   ins_encode %{
 6850     __ and_32($dst$$Register, $src1$$Register, $src2$$constant);
 6851   %}
 6852   ins_pipe(ialu_reg_imm);
 6853 %}
 6854 
 6855 instruct andI_reg_limmn(iRegI dst, iRegI src1, limmIn src2) %{
 6856   match(Set dst (AndI src1 src2));
 6857 
 6858   size(4);
 6859   format %{ &quot;bic    $dst,$src1,~$src2\t! int&quot; %}
 6860   ins_encode %{
 6861     __ bic($dst$$Register, $src1$$Register, ~$src2$$constant);
 6862   %}
 6863   ins_pipe(ialu_reg_imm);
 6864 %}
 6865 
 6866 // Register And Long
 6867 instruct andL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6868   match(Set dst (AndL src1 src2));
 6869 
 6870   ins_cost(DEFAULT_COST);
 6871   size(8);
 6872   format %{ &quot;AND    $dst,$src1,$src2\t! long&quot; %}
 6873   ins_encode %{
 6874     __ andr($dst$$Register, $src1$$Register, $src2$$Register);
 6875     __ andr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 6876   %}
 6877   ins_pipe(ialu_reg_reg);
 6878 %}
 6879 
 6880 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 6881 // (hi($con$$constant), lo($con$$constant)) becomes
 6882 instruct andL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 6883   match(Set dst (AndL src1 con));
 6884   ins_cost(DEFAULT_COST);
 6885   size(8);
 6886   format %{ &quot;AND    $dst,$src1,$con\t! long&quot; %}
 6887   ins_encode %{
 6888     __ andr($dst$$Register, $src1$$Register, $con$$constant);
 6889     __ andr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 6890   %}
 6891   ins_pipe(ialu_reg_imm);
 6892 %}
 6893 
 6894 // Or Instructions
 6895 // Register Or
 6896 instruct orI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6897   match(Set dst (OrI src1 src2));
 6898 
 6899   size(4);
 6900   format %{ &quot;orr_32 $dst,$src1,$src2\t! int&quot; %}
 6901   ins_encode %{
 6902     __ orr_32($dst$$Register, $src1$$Register, $src2$$Register);
 6903   %}
 6904   ins_pipe(ialu_reg_reg);
 6905 %}
 6906 
 6907 instruct orshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6908   match(Set dst (OrI src1 (LShiftI src2 src3)));
 6909 
 6910   size(4);
 6911   format %{ &quot;OR    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6912   ins_encode %{
 6913     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 6914   %}
 6915   ins_pipe(ialu_reg_reg);
 6916 %}
 6917 
 6918 instruct orshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6919   match(Set dst (OrI src1 (LShiftI src2 src3)));
 6920 
 6921   size(4);
 6922   format %{ &quot;orr_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6923   ins_encode %{
 6924     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 6925   %}
 6926   ins_pipe(ialu_reg_reg);
 6927 %}
 6928 
 6929 instruct orsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6930   match(Set dst (OrI src1 (RShiftI src2 src3)));
 6931 
 6932   size(4);
 6933   format %{ &quot;OR    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6934   ins_encode %{
 6935     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 6936   %}
 6937   ins_pipe(ialu_reg_reg);
 6938 %}
 6939 
 6940 instruct orsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6941   match(Set dst (OrI src1 (RShiftI src2 src3)));
 6942 
 6943   size(4);
 6944   format %{ &quot;orr_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6945   ins_encode %{
 6946     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 6947   %}
 6948   ins_pipe(ialu_reg_reg);
 6949 %}
 6950 
 6951 instruct orshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6952   match(Set dst (OrI src1 (URShiftI src2 src3)));
 6953 
 6954   size(4);
 6955   format %{ &quot;OR    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6956   ins_encode %{
 6957     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 6958   %}
 6959   ins_pipe(ialu_reg_reg);
 6960 %}
 6961 
 6962 instruct orshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6963   match(Set dst (OrI src1 (URShiftI src2 src3)));
 6964 
 6965   size(4);
 6966   format %{ &quot;orr_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6967   ins_encode %{
 6968     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 6969   %}
 6970   ins_pipe(ialu_reg_reg);
 6971 %}
 6972 
 6973 // Immediate Or
 6974 instruct orI_reg_limm(iRegI dst, iRegI src1, limmI src2) %{
 6975   match(Set dst (OrI src1 src2));
 6976 
 6977   size(4);
 6978   format %{ &quot;orr_32  $dst,$src1,$src2&quot; %}
 6979   ins_encode %{
 6980     __ orr_32($dst$$Register, $src1$$Register, $src2$$constant);
 6981   %}
 6982   ins_pipe(ialu_reg_imm);
 6983 %}
 6984 // TODO: orn_32 with limmIn
 6985 
 6986 // Register Or Long
 6987 instruct orL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6988   match(Set dst (OrL src1 src2));
 6989 
 6990   ins_cost(DEFAULT_COST);
 6991   size(8);
 6992   format %{ &quot;OR     $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 6993             &quot;OR     $dst.hi,$src1.hi,$src2.hi&quot; %}
 6994   ins_encode %{
 6995     __ orr($dst$$Register, $src1$$Register, $src2$$Register);
 6996     __ orr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 6997   %}
 6998   ins_pipe(ialu_reg_reg);
 6999 %}
 7000 
 7001 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7002 // (hi($con$$constant), lo($con$$constant)) becomes
 7003 instruct orL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 7004   match(Set dst (OrL src1 con));
 7005   ins_cost(DEFAULT_COST);
 7006   size(8);
 7007   format %{ &quot;OR     $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 7008             &quot;OR     $dst.hi,$src1.hi,$con&quot; %}
 7009   ins_encode %{
 7010     __ orr($dst$$Register, $src1$$Register, $con$$constant);
 7011     __ orr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 7012   %}
 7013   ins_pipe(ialu_reg_imm);
 7014 %}
 7015 
 7016 #ifdef TODO
 7017 // Use SPRegP to match Rthread (TLS register) without spilling.
 7018 // Use store_ptr_RegP to match Rthread (TLS register) without spilling.
 7019 // Use sp_ptr_RegP to match Rthread (TLS register) without spilling.
 7020 instruct orI_reg_castP2X(iRegI dst, iRegI src1, sp_ptr_RegP src2) %{
 7021   match(Set dst (OrI src1 (CastP2X src2)));
 7022   size(4);
 7023   format %{ &quot;OR     $dst,$src1,$src2&quot; %}
 7024   ins_encode %{
 7025     __ orr($dst$$Register, $src1$$Register, $src2$$Register);
 7026   %}
 7027   ins_pipe(ialu_reg_reg);
 7028 %}
 7029 #endif
 7030 
 7031 // Xor Instructions
 7032 // Register Xor
 7033 instruct xorI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 7034   match(Set dst (XorI src1 src2));
 7035 
 7036   size(4);
 7037   format %{ &quot;eor_32 $dst,$src1,$src2&quot; %}
 7038   ins_encode %{
 7039     __ eor_32($dst$$Register, $src1$$Register, $src2$$Register);
 7040   %}
 7041   ins_pipe(ialu_reg_reg);
 7042 %}
 7043 
 7044 instruct xorshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7045   match(Set dst (XorI src1 (LShiftI src2 src3)));
 7046 
 7047   size(4);
 7048   format %{ &quot;XOR    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 7049   ins_encode %{
 7050     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 7051   %}
 7052   ins_pipe(ialu_reg_reg);
 7053 %}
 7054 
 7055 instruct xorshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7056   match(Set dst (XorI src1 (LShiftI src2 src3)));
 7057 
 7058   size(4);
 7059   format %{ &quot;eor_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 7060   ins_encode %{
 7061     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 7062   %}
 7063   ins_pipe(ialu_reg_reg);
 7064 %}
 7065 
 7066 instruct xorsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7067   match(Set dst (XorI src1 (RShiftI src2 src3)));
 7068 
 7069   size(4);
 7070   format %{ &quot;XOR    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 7071   ins_encode %{
 7072     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 7073   %}
 7074   ins_pipe(ialu_reg_reg);
 7075 %}
 7076 
 7077 instruct xorsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7078   match(Set dst (XorI src1 (RShiftI src2 src3)));
 7079 
 7080   size(4);
 7081   format %{ &quot;eor_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 7082   ins_encode %{
 7083     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 7084   %}
 7085   ins_pipe(ialu_reg_reg);
 7086 %}
 7087 
 7088 instruct xorshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7089   match(Set dst (XorI src1 (URShiftI src2 src3)));
 7090 
 7091   size(4);
 7092   format %{ &quot;XOR    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 7093   ins_encode %{
 7094     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 7095   %}
 7096   ins_pipe(ialu_reg_reg);
 7097 %}
 7098 
 7099 instruct xorshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7100   match(Set dst (XorI src1 (URShiftI src2 src3)));
 7101 
 7102   size(4);
 7103   format %{ &quot;eor_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 7104   ins_encode %{
 7105     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 7106   %}
 7107   ins_pipe(ialu_reg_reg);
 7108 %}
 7109 
 7110 // Immediate Xor
 7111 instruct xorI_reg_imm(iRegI dst, iRegI src1, limmI src2) %{
 7112   match(Set dst (XorI src1 src2));
 7113 
 7114   size(4);
 7115   format %{ &quot;eor_32 $dst,$src1,$src2&quot; %}
 7116   ins_encode %{
 7117     __ eor_32($dst$$Register, $src1$$Register, $src2$$constant);
 7118   %}
 7119   ins_pipe(ialu_reg_imm);
 7120 %}
 7121 
 7122 // Register Xor Long
 7123 instruct xorL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 7124   match(Set dst (XorL src1 src2));
 7125   ins_cost(DEFAULT_COST);
 7126   size(8);
 7127   format %{ &quot;XOR     $dst.hi,$src1.hi,$src2.hi\t! long\n\t&quot;
 7128             &quot;XOR     $dst.lo,$src1.lo,$src2.lo\t! long&quot; %}
 7129   ins_encode %{
 7130     __ eor($dst$$Register, $src1$$Register, $src2$$Register);
 7131     __ eor($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 7132   %}
 7133   ins_pipe(ialu_reg_reg);
 7134 %}
 7135 
 7136 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7137 // (hi($con$$constant), lo($con$$constant)) becomes
 7138 instruct xorL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 7139   match(Set dst (XorL src1 con));
 7140   ins_cost(DEFAULT_COST);
 7141   size(8);
 7142   format %{ &quot;XOR     $dst.hi,$src1.hi,$con\t! long\n\t&quot;
 7143             &quot;XOR     $dst.lo,$src1.lo,0\t! long&quot; %}
 7144   ins_encode %{
 7145     __ eor($dst$$Register, $src1$$Register, $con$$constant);
 7146     __ eor($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 7147   %}
 7148   ins_pipe(ialu_reg_imm);
 7149 %}
 7150 
 7151 //----------Convert to Boolean-------------------------------------------------
 7152 instruct convI2B( iRegI dst, iRegI src, flagsReg ccr ) %{
 7153   match(Set dst (Conv2B src));
 7154   effect(KILL ccr);
 7155   size(12);
 7156   ins_cost(DEFAULT_COST*2);
 7157   format %{ &quot;TST    $src,$src \n\t&quot;
 7158             &quot;MOV    $dst, 0   \n\t&quot;
 7159             &quot;MOV.ne $dst, 1&quot; %}
 7160   ins_encode %{ // FIXME: can do better?
 7161     __ tst($src$$Register, $src$$Register);
 7162     __ mov($dst$$Register, 0);
 7163     __ mov($dst$$Register, 1, ne);
 7164   %}
 7165   ins_pipe(ialu_reg_ialu);
 7166 %}
 7167 
 7168 instruct convP2B( iRegI dst, iRegP src, flagsReg ccr ) %{
 7169   match(Set dst (Conv2B src));
 7170   effect(KILL ccr);
 7171   size(12);
 7172   ins_cost(DEFAULT_COST*2);
 7173   format %{ &quot;TST    $src,$src \n\t&quot;
 7174             &quot;MOV    $dst, 0   \n\t&quot;
 7175             &quot;MOV.ne $dst, 1&quot; %}
 7176   ins_encode %{
 7177     __ tst($src$$Register, $src$$Register);
 7178     __ mov($dst$$Register, 0);
 7179     __ mov($dst$$Register, 1, ne);
 7180   %}
 7181   ins_pipe(ialu_reg_ialu);
 7182 %}
 7183 
 7184 instruct cmpLTMask_reg_reg( iRegI dst, iRegI p, iRegI q, flagsReg ccr ) %{
 7185   match(Set dst (CmpLTMask p q));
 7186   effect( KILL ccr );
 7187   ins_cost(DEFAULT_COST*3);
 7188   format %{ &quot;CMP    $p,$q\n\t&quot;
 7189             &quot;MOV    $dst, #0\n\t&quot;
 7190             &quot;MOV.lt $dst, #-1&quot; %}
 7191   ins_encode %{
 7192     __ cmp($p$$Register, $q$$Register);
 7193     __ mov($dst$$Register, 0);
 7194     __ mvn($dst$$Register, 0, lt);
 7195   %}
 7196   ins_pipe(ialu_reg_reg_ialu);
 7197 %}
 7198 
 7199 instruct cmpLTMask_reg_imm( iRegI dst, iRegI p, aimmI q, flagsReg ccr ) %{
 7200   match(Set dst (CmpLTMask p q));
 7201   effect( KILL ccr );
 7202   ins_cost(DEFAULT_COST*3);
 7203   format %{ &quot;CMP    $p,$q\n\t&quot;
 7204             &quot;MOV    $dst, #0\n\t&quot;
 7205             &quot;MOV.lt $dst, #-1&quot; %}
 7206   ins_encode %{
 7207     __ cmp($p$$Register, $q$$constant);
 7208     __ mov($dst$$Register, 0);
 7209     __ mvn($dst$$Register, 0, lt);
 7210   %}
 7211   ins_pipe(ialu_reg_reg_ialu);
 7212 %}
 7213 
 7214 instruct cadd_cmpLTMask3( iRegI p, iRegI q, iRegI y, iRegI z, flagsReg ccr ) %{
 7215   match(Set z (AddI (AndI (CmpLTMask p q) y) z));
 7216   effect( KILL ccr );
 7217   ins_cost(DEFAULT_COST*2);
 7218   format %{ &quot;CMP    $p,$q\n\t&quot;
 7219             &quot;ADD.lt $z,$y,$z&quot; %}
 7220   ins_encode %{
 7221     __ cmp($p$$Register, $q$$Register);
 7222     __ add($z$$Register, $y$$Register, $z$$Register, lt);
 7223   %}
 7224   ins_pipe( cadd_cmpltmask );
 7225 %}
 7226 
 7227 // FIXME: remove unused &quot;dst&quot;
 7228 instruct cadd_cmpLTMask4( iRegI dst, iRegI p, aimmI q, iRegI y, iRegI z, flagsReg ccr ) %{
 7229   match(Set z (AddI (AndI (CmpLTMask p q) y) z));
 7230   effect( KILL ccr );
 7231   ins_cost(DEFAULT_COST*2);
 7232   format %{ &quot;CMP    $p,$q\n\t&quot;
 7233             &quot;ADD.lt $z,$y,$z&quot; %}
 7234   ins_encode %{
 7235     __ cmp($p$$Register, $q$$constant);
 7236     __ add($z$$Register, $y$$Register, $z$$Register, lt);
 7237   %}
 7238   ins_pipe( cadd_cmpltmask );
 7239 %}
 7240 
 7241 instruct cadd_cmpLTMask( iRegI p, iRegI q, iRegI y, flagsReg ccr ) %{
 7242   match(Set p (AddI (AndI (CmpLTMask p q) y) (SubI p q)));
 7243   effect( KILL ccr );
 7244   ins_cost(DEFAULT_COST*2);
 7245   format %{ &quot;SUBS   $p,$p,$q\n\t&quot;
 7246             &quot;ADD.lt $p,$y,$p&quot; %}
 7247   ins_encode %{
 7248     __ subs($p$$Register, $p$$Register, $q$$Register);
 7249     __ add($p$$Register, $y$$Register, $p$$Register, lt);
 7250   %}
 7251   ins_pipe( cadd_cmpltmask );
 7252 %}
 7253 
 7254 //----------Arithmetic Conversion Instructions---------------------------------
 7255 // The conversions operations are all Alpha sorted.  Please keep it that way!
 7256 
 7257 instruct convD2F_reg(regF dst, regD src) %{
 7258   match(Set dst (ConvD2F src));
 7259   size(4);
 7260   format %{ &quot;FCVTSD  $dst,$src&quot; %}
 7261   ins_encode %{
 7262     __ convert_d2f($dst$$FloatRegister, $src$$FloatRegister);
 7263   %}
 7264   ins_pipe(fcvtD2F);
 7265 %}
 7266 
 7267 // Convert a double to an int in a float register.
 7268 // If the double is a NAN, stuff a zero in instead.
 7269 
 7270 instruct convD2I_reg_reg(iRegI dst, regD src, regF tmp) %{
 7271   match(Set dst (ConvD2I src));
 7272   effect( TEMP tmp );
 7273   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7274   format %{ &quot;FTOSIZD  $tmp,$src\n\t&quot;
 7275             &quot;FMRS     $dst, $tmp&quot; %}
 7276   ins_encode %{
 7277     __ ftosizd($tmp$$FloatRegister, $src$$FloatRegister);
 7278     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 7279   %}
 7280   ins_pipe(fcvtD2I);
 7281 %}
 7282 
 7283 // Convert a double to a long in a double register.
 7284 // If the double is a NAN, stuff a zero in instead.
 7285 
 7286 // Double to Long conversion
 7287 instruct convD2L_reg(R0R1RegL dst, regD src) %{
 7288   match(Set dst (ConvD2L src));
 7289   effect(CALL);
 7290   ins_cost(MEMORY_REF_COST); // FIXME
 7291   format %{ &quot;convD2L    $dst,$src\t ! call to SharedRuntime::d2l&quot; %}
 7292   ins_encode %{
 7293 #ifndef __ABI_HARD__
 7294     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), $src$$FloatRegister);
 7295 #else
 7296     if ($src$$FloatRegister != D0) {
 7297       __ mov_double(D0, $src$$FloatRegister);
 7298     }
 7299 #endif
 7300     address target = CAST_FROM_FN_PTR(address, SharedRuntime::d2l);
 7301     __ call(target, relocInfo::runtime_call_type);
 7302   %}
 7303   ins_pipe(fcvtD2L);
 7304 %}
 7305 
 7306 instruct convF2D_reg(regD dst, regF src) %{
 7307   match(Set dst (ConvF2D src));
 7308   size(4);
 7309   format %{ &quot;FCVTDS  $dst,$src&quot; %}
 7310   ins_encode %{
 7311     __ convert_f2d($dst$$FloatRegister, $src$$FloatRegister);
 7312   %}
 7313   ins_pipe(fcvtF2D);
 7314 %}
 7315 
 7316 instruct convF2I_reg_reg(iRegI dst, regF src, regF tmp) %{
 7317   match(Set dst (ConvF2I src));
 7318   effect( TEMP tmp );
 7319   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7320   size(8);
 7321   format %{ &quot;FTOSIZS  $tmp,$src\n\t&quot;
 7322             &quot;FMRS     $dst, $tmp&quot; %}
 7323   ins_encode %{
 7324     __ ftosizs($tmp$$FloatRegister, $src$$FloatRegister);
 7325     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 7326   %}
 7327   ins_pipe(fcvtF2I);
 7328 %}
 7329 
 7330 // Float to Long conversion
 7331 instruct convF2L_reg(R0R1RegL dst, regF src, R0RegI arg1) %{
 7332   match(Set dst (ConvF2L src));
 7333   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7334   effect(CALL);
 7335   format %{ &quot;convF2L  $dst,$src\t! call to SharedRuntime::f2l&quot; %}
 7336   ins_encode %{
 7337 #ifndef __ABI_HARD__
 7338     __ fmrs($arg1$$Register, $src$$FloatRegister);
 7339 #else
 7340     if($src$$FloatRegister != S0) {
 7341       __ mov_float(S0, $src$$FloatRegister);
 7342     }
 7343 #endif
 7344     address target = CAST_FROM_FN_PTR(address, SharedRuntime::f2l);
 7345     __ call(target, relocInfo::runtime_call_type);
 7346   %}
 7347   ins_pipe(fcvtF2L);
 7348 %}
 7349 
 7350 instruct convI2D_reg_reg(iRegI src, regD_low dst) %{
 7351   match(Set dst (ConvI2D src));
 7352   ins_cost(DEFAULT_COST + MEMORY_REF_COST); // FIXME
 7353   size(8);
 7354   format %{ &quot;FMSR     $dst,$src \n\t&quot;
 7355             &quot;FSITOD   $dst $dst&quot;%}
 7356   ins_encode %{
 7357       __ fmsr($dst$$FloatRegister, $src$$Register);
 7358       __ fsitod($dst$$FloatRegister, $dst$$FloatRegister);
 7359   %}
 7360   ins_pipe(fcvtI2D);
 7361 %}
 7362 
 7363 instruct convI2F_reg_reg( regF dst, iRegI src ) %{
 7364   match(Set dst (ConvI2F src));
 7365   ins_cost(DEFAULT_COST + MEMORY_REF_COST); // FIXME
 7366   size(8);
 7367   format %{ &quot;FMSR     $dst,$src \n\t&quot;
 7368             &quot;FSITOS   $dst, $dst&quot;%}
 7369   ins_encode %{
 7370       __ fmsr($dst$$FloatRegister, $src$$Register);
 7371       __ fsitos($dst$$FloatRegister, $dst$$FloatRegister);
 7372   %}
 7373   ins_pipe(fcvtI2F);
 7374 %}
 7375 
 7376 instruct convI2L_reg(iRegL dst, iRegI src) %{
 7377   match(Set dst (ConvI2L src));
 7378   size(8);
 7379   format %{ &quot;MOV    $dst.lo, $src \n\t&quot;
 7380             &quot;ASR    $dst.hi,$src,31\t! int-&gt;long&quot; %}
 7381   ins_encode %{
 7382     __ mov($dst$$Register, $src$$Register);
 7383     __ mov($dst$$Register-&gt;successor(), AsmOperand($src$$Register, asr, 31));
 7384   %}
 7385   ins_pipe(ialu_reg_reg);
 7386 %}
 7387 
 7388 // Zero-extend convert int to long
 7389 instruct convI2L_reg_zex(iRegL dst, iRegI src, immL_32bits mask ) %{
 7390   match(Set dst (AndL (ConvI2L src) mask) );
 7391   size(8);
 7392   format %{ &quot;MOV    $dst.lo,$src.lo\t! zero-extend int to long\n\t&quot;
 7393             &quot;MOV    $dst.hi, 0&quot;%}
 7394   ins_encode %{
 7395     __ mov($dst$$Register, $src$$Register);
 7396     __ mov($dst$$Register-&gt;successor(), 0);
 7397   %}
 7398   ins_pipe(ialu_reg_reg);
 7399 %}
 7400 
 7401 // Zero-extend long
 7402 instruct zerox_long(iRegL dst, iRegL src, immL_32bits mask ) %{
 7403   match(Set dst (AndL src mask) );
 7404   size(8);
 7405   format %{ &quot;MOV    $dst.lo,$src.lo\t! zero-extend long\n\t&quot;
 7406             &quot;MOV    $dst.hi, 0&quot;%}
 7407   ins_encode %{
 7408     __ mov($dst$$Register, $src$$Register);
 7409     __ mov($dst$$Register-&gt;successor(), 0);
 7410   %}
 7411   ins_pipe(ialu_reg_reg);
 7412 %}
 7413 
 7414 instruct MoveF2I_reg_reg(iRegI dst, regF src) %{
 7415   match(Set dst (MoveF2I src));
 7416   effect(DEF dst, USE src);
 7417   ins_cost(MEMORY_REF_COST); // FIXME
 7418 
 7419   size(4);
 7420   format %{ &quot;FMRS   $dst,$src\t! MoveF2I&quot; %}
 7421   ins_encode %{
 7422     __ fmrs($dst$$Register, $src$$FloatRegister);
 7423   %}
 7424   ins_pipe(iload_mem); // FIXME
 7425 %}
 7426 
 7427 instruct MoveI2F_reg_reg(regF dst, iRegI src) %{
 7428   match(Set dst (MoveI2F src));
 7429   ins_cost(MEMORY_REF_COST); // FIXME
 7430 
 7431   size(4);
 7432   format %{ &quot;FMSR   $dst,$src\t! MoveI2F&quot; %}
 7433   ins_encode %{
 7434     __ fmsr($dst$$FloatRegister, $src$$Register);
 7435   %}
 7436   ins_pipe(iload_mem); // FIXME
 7437 %}
 7438 
 7439 instruct MoveD2L_reg_reg(iRegL dst, regD src) %{
 7440   match(Set dst (MoveD2L src));
 7441   effect(DEF dst, USE src);
 7442   ins_cost(MEMORY_REF_COST); // FIXME
 7443 
 7444   size(4);
 7445   format %{ &quot;FMRRD    $dst,$src\t! MoveD2L&quot; %}
 7446   ins_encode %{
 7447     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), $src$$FloatRegister);
 7448   %}
 7449   ins_pipe(iload_mem); // FIXME
 7450 %}
 7451 
 7452 instruct MoveL2D_reg_reg(regD dst, iRegL src) %{
 7453   match(Set dst (MoveL2D src));
 7454   effect(DEF dst, USE src);
 7455   ins_cost(MEMORY_REF_COST); // FIXME
 7456 
 7457   size(4);
 7458   format %{ &quot;FMDRR   $dst,$src\t! MoveL2D&quot; %}
 7459   ins_encode %{
 7460     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 7461   %}
 7462   ins_pipe(ialu_reg_reg); // FIXME
 7463 %}
 7464 
 7465 //-----------
 7466 // Long to Double conversion
 7467 
 7468 // Magic constant, 0x43300000
 7469 instruct loadConI_x43300000(iRegI dst) %{
 7470   effect(DEF dst);
 7471   size(8);
 7472   format %{ &quot;MOV_SLOW  $dst,0x43300000\t! 2^52&quot; %}
 7473   ins_encode %{
 7474     __ mov_slow($dst$$Register, 0x43300000);
 7475   %}
 7476   ins_pipe(ialu_none);
 7477 %}
 7478 
 7479 // Magic constant, 0x41f00000
 7480 instruct loadConI_x41f00000(iRegI dst) %{
 7481   effect(DEF dst);
 7482   size(8);
 7483   format %{ &quot;MOV_SLOW  $dst, 0x41f00000\t! 2^32&quot; %}
 7484   ins_encode %{
 7485     __ mov_slow($dst$$Register, 0x41f00000);
 7486   %}
 7487   ins_pipe(ialu_none);
 7488 %}
 7489 
 7490 instruct loadConI_x0(iRegI dst) %{
 7491   effect(DEF dst);
 7492   size(4);
 7493   format %{ &quot;MOV  $dst, 0x0\t! 0&quot; %}
 7494   ins_encode %{
 7495     __ mov($dst$$Register, 0);
 7496   %}
 7497   ins_pipe(ialu_none);
 7498 %}
 7499 
 7500 // Construct a double from two float halves
 7501 instruct regDHi_regDLo_to_regD(regD_low dst, regD_low src1, regD_low src2) %{
 7502   effect(DEF dst, USE src1, USE src2);
 7503   size(8);
 7504   format %{ &quot;FCPYS  $dst.hi,$src1.hi\n\t&quot;
 7505             &quot;FCPYS  $dst.lo,$src2.lo&quot; %}
 7506   ins_encode %{
 7507     __ fcpys($dst$$FloatRegister-&gt;successor(), $src1$$FloatRegister-&gt;successor());
 7508     __ fcpys($dst$$FloatRegister, $src2$$FloatRegister);
 7509   %}
 7510   ins_pipe(faddD_reg_reg);
 7511 %}
 7512 
 7513 // Convert integer in high half of a double register (in the lower half of
 7514 // the double register file) to double
 7515 instruct convI2D_regDHi_regD(regD dst, regD_low src) %{
 7516   effect(DEF dst, USE src);
 7517   size(4);
 7518   format %{ &quot;FSITOD  $dst,$src&quot; %}
 7519   ins_encode %{
 7520     __ fsitod($dst$$FloatRegister, $src$$FloatRegister-&gt;successor());
 7521   %}
 7522   ins_pipe(fcvtLHi2D);
 7523 %}
 7524 
 7525 // Add float double precision
 7526 instruct addD_regD_regD(regD dst, regD src1, regD src2) %{
 7527   effect(DEF dst, USE src1, USE src2);
 7528   size(4);
 7529   format %{ &quot;FADDD  $dst,$src1,$src2&quot; %}
 7530   ins_encode %{
 7531     __ add_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7532   %}
 7533   ins_pipe(faddD_reg_reg);
 7534 %}
 7535 
 7536 // Sub float double precision
 7537 instruct subD_regD_regD(regD dst, regD src1, regD src2) %{
 7538   effect(DEF dst, USE src1, USE src2);
 7539   size(4);
 7540   format %{ &quot;FSUBD  $dst,$src1,$src2&quot; %}
 7541   ins_encode %{
 7542     __ sub_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7543   %}
 7544   ins_pipe(faddD_reg_reg);
 7545 %}
 7546 
 7547 // Mul float double precision
 7548 instruct mulD_regD_regD(regD dst, regD src1, regD src2) %{
 7549   effect(DEF dst, USE src1, USE src2);
 7550   size(4);
 7551   format %{ &quot;FMULD  $dst,$src1,$src2&quot; %}
 7552   ins_encode %{
 7553     __ mul_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7554   %}
 7555   ins_pipe(fmulD_reg_reg);
 7556 %}
 7557 
 7558 instruct regL_to_regD(regD dst, iRegL src) %{
 7559   // No match rule to avoid chain rule match.
 7560   effect(DEF dst, USE src);
 7561   ins_cost(MEMORY_REF_COST);
 7562   size(4);
 7563   format %{ &quot;FMDRR   $dst,$src\t! regL to regD&quot; %}
 7564   ins_encode %{
 7565     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 7566   %}
 7567   ins_pipe(ialu_reg_reg); // FIXME
 7568 %}
 7569 
 7570 instruct regI_regI_to_regD(regD dst, iRegI src1, iRegI src2) %{
 7571   // No match rule to avoid chain rule match.
 7572   effect(DEF dst, USE src1, USE src2);
 7573   ins_cost(MEMORY_REF_COST);
 7574   size(4);
 7575   format %{ &quot;FMDRR   $dst,$src1,$src2\t! regI,regI to regD&quot; %}
 7576   ins_encode %{
 7577     __ fmdrr($dst$$FloatRegister, $src1$$Register, $src2$$Register);
 7578   %}
 7579   ins_pipe(ialu_reg_reg); // FIXME
 7580 %}
 7581 
 7582 instruct convL2D_reg_slow_fxtof(regD dst, iRegL src) %{
 7583   match(Set dst (ConvL2D src));
 7584   ins_cost(DEFAULT_COST*8 + MEMORY_REF_COST*6); // FIXME
 7585 
 7586   expand %{
 7587     regD_low   tmpsrc;
 7588     iRegI      ix43300000;
 7589     iRegI      ix41f00000;
 7590     iRegI      ix0;
 7591     regD_low   dx43300000;
 7592     regD       dx41f00000;
 7593     regD       tmp1;
 7594     regD_low   tmp2;
 7595     regD       tmp3;
 7596     regD       tmp4;
 7597 
 7598     regL_to_regD(tmpsrc, src);
 7599 
 7600     loadConI_x43300000(ix43300000);
 7601     loadConI_x41f00000(ix41f00000);
 7602     loadConI_x0(ix0);
 7603 
 7604     regI_regI_to_regD(dx43300000, ix0, ix43300000);
 7605     regI_regI_to_regD(dx41f00000, ix0, ix41f00000);
 7606 
 7607     convI2D_regDHi_regD(tmp1, tmpsrc);
 7608     regDHi_regDLo_to_regD(tmp2, dx43300000, tmpsrc);
 7609     subD_regD_regD(tmp3, tmp2, dx43300000);
 7610     mulD_regD_regD(tmp4, tmp1, dx41f00000);
 7611     addD_regD_regD(dst, tmp3, tmp4);
 7612   %}
 7613 %}
 7614 
 7615 instruct convL2I_reg(iRegI dst, iRegL src) %{
 7616   match(Set dst (ConvL2I src));
 7617   size(4);
 7618   format %{ &quot;MOV    $dst,$src.lo\t! long-&gt;int&quot; %}
 7619   ins_encode %{
 7620     __ mov($dst$$Register, $src$$Register);
 7621   %}
 7622   ins_pipe(ialu_move_reg_I_to_L);
 7623 %}
 7624 
 7625 // Register Shift Right Immediate
 7626 instruct shrL_reg_imm6_L2I(iRegI dst, iRegL src, immI_32_63 cnt) %{
 7627   match(Set dst (ConvL2I (RShiftL src cnt)));
 7628   size(4);
 7629   format %{ &quot;ASR    $dst,$src.hi,($cnt - 32)\t! long-&gt;int or mov if $cnt==32&quot; %}
 7630   ins_encode %{
 7631     if ($cnt$$constant == 32) {
 7632       __ mov($dst$$Register, $src$$Register-&gt;successor());
 7633     } else {
 7634       __ mov($dst$$Register, AsmOperand($src$$Register-&gt;successor(), asr, $cnt$$constant - 32));
 7635     }
 7636   %}
 7637   ins_pipe(ialu_reg_imm);
 7638 %}
 7639 
 7640 
 7641 //----------Control Flow Instructions------------------------------------------
 7642 // Compare Instructions
 7643 // Compare Integers
 7644 instruct compI_iReg(flagsReg icc, iRegI op1, iRegI op2) %{
 7645   match(Set icc (CmpI op1 op2));
 7646   effect( DEF icc, USE op1, USE op2 );
 7647 
 7648   size(4);
 7649   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7650   ins_encode %{
 7651     __ cmp_32($op1$$Register, $op2$$Register);
 7652   %}
 7653   ins_pipe(ialu_cconly_reg_reg);
 7654 %}
 7655 
 7656 #ifdef _LP64
 7657 // Compare compressed pointers
 7658 instruct compN_reg2(flagsRegU icc, iRegN op1, iRegN op2) %{
 7659   match(Set icc (CmpN op1 op2));
 7660   effect( DEF icc, USE op1, USE op2 );
 7661 
 7662   size(4);
 7663   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7664   ins_encode %{
 7665     __ cmp_32($op1$$Register, $op2$$Register);
 7666   %}
 7667   ins_pipe(ialu_cconly_reg_reg);
 7668 %}
 7669 #endif
 7670 
 7671 instruct compU_iReg(flagsRegU icc, iRegI op1, iRegI op2) %{
 7672   match(Set icc (CmpU op1 op2));
 7673 
 7674   size(4);
 7675   format %{ &quot;cmp_32 $op1,$op2\t! unsigned int&quot; %}
 7676   ins_encode %{
 7677     __ cmp_32($op1$$Register, $op2$$Register);
 7678   %}
 7679   ins_pipe(ialu_cconly_reg_reg);
 7680 %}
 7681 
 7682 instruct compI_iReg_immneg(flagsReg icc, iRegI op1, aimmIneg op2) %{
 7683   match(Set icc (CmpI op1 op2));
 7684   effect( DEF icc, USE op1 );
 7685 
 7686   size(4);
 7687   format %{ &quot;cmn_32 $op1,-$op2\t! int&quot; %}
 7688   ins_encode %{
 7689     __ cmn_32($op1$$Register, -$op2$$constant);
 7690   %}
 7691   ins_pipe(ialu_cconly_reg_imm);
 7692 %}
 7693 
 7694 instruct compI_iReg_imm(flagsReg icc, iRegI op1, aimmI op2) %{
 7695   match(Set icc (CmpI op1 op2));
 7696   effect( DEF icc, USE op1 );
 7697 
 7698   size(4);
 7699   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7700   ins_encode %{
 7701     __ cmp_32($op1$$Register, $op2$$constant);
 7702   %}
 7703   ins_pipe(ialu_cconly_reg_imm);
 7704 %}
 7705 
 7706 instruct testI_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immI0 zero ) %{
 7707   match(Set icc (CmpI (AndI op1 op2) zero));
 7708   size(4);
 7709   format %{ &quot;tst_32 $op2,$op1&quot; %}
 7710 
 7711   ins_encode %{
 7712     __ tst_32($op1$$Register, $op2$$Register);
 7713   %}
 7714   ins_pipe(ialu_cconly_reg_reg_zero);
 7715 %}
 7716 
 7717 instruct testshlI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7718   match(Set icc (CmpI (AndI op1 (LShiftI op2 op3)) zero));
 7719   size(4);
 7720   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7721 
 7722   ins_encode %{
 7723     __ tst($op1$$Register, AsmOperand($op2$$Register, lsl, $op3$$Register));
 7724   %}
 7725   ins_pipe(ialu_cconly_reg_reg_zero);
 7726 %}
 7727 
 7728 instruct testshlI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7729   match(Set icc (CmpI (AndI op1 (LShiftI op2 op3)) zero));
 7730   size(4);
 7731   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7732 
 7733   ins_encode %{
 7734     __ tst_32($op1$$Register, AsmOperand($op2$$Register, lsl, $op3$$constant));
 7735   %}
 7736   ins_pipe(ialu_cconly_reg_reg_zero);
 7737 %}
 7738 
 7739 instruct testsarI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7740   match(Set icc (CmpI (AndI op1 (RShiftI op2 op3)) zero));
 7741   size(4);
 7742   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7743 
 7744   ins_encode %{
 7745     __ tst($op1$$Register, AsmOperand($op2$$Register, asr, $op3$$Register));
 7746   %}
 7747   ins_pipe(ialu_cconly_reg_reg_zero);
 7748 %}
 7749 
 7750 instruct testsarI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7751   match(Set icc (CmpI (AndI op1 (RShiftI op2 op3)) zero));
 7752   size(4);
 7753   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7754 
 7755   ins_encode %{
 7756     __ tst_32($op1$$Register, AsmOperand($op2$$Register, asr, $op3$$constant));
 7757   %}
 7758   ins_pipe(ialu_cconly_reg_reg_zero);
 7759 %}
 7760 
 7761 instruct testshrI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7762   match(Set icc (CmpI (AndI op1 (URShiftI op2 op3)) zero));
 7763   size(4);
 7764   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7765 
 7766   ins_encode %{
 7767     __ tst($op1$$Register, AsmOperand($op2$$Register, lsr, $op3$$Register));
 7768   %}
 7769   ins_pipe(ialu_cconly_reg_reg_zero);
 7770 %}
 7771 
 7772 instruct testshrI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7773   match(Set icc (CmpI (AndI op1 (URShiftI op2 op3)) zero));
 7774   size(4);
 7775   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7776 
 7777   ins_encode %{
 7778     __ tst_32($op1$$Register, AsmOperand($op2$$Register, lsr, $op3$$constant));
 7779   %}
 7780   ins_pipe(ialu_cconly_reg_reg_zero);
 7781 %}
 7782 
 7783 instruct testI_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, limmI op2, immI0 zero ) %{
 7784   match(Set icc (CmpI (AndI op1 op2) zero));
 7785   size(4);
 7786   format %{ &quot;tst_32 $op2,$op1&quot; %}
 7787 
 7788   ins_encode %{
 7789     __ tst_32($op1$$Register, $op2$$constant);
 7790   %}
 7791   ins_pipe(ialu_cconly_reg_imm_zero);
 7792 %}
 7793 
 7794 instruct compL_reg_reg_LTGE(flagsRegL_LTGE xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7795   match(Set xcc (CmpL op1 op2));
 7796   effect( DEF xcc, USE op1, USE op2, TEMP tmp );
 7797 
 7798   size(8);
 7799   format %{ &quot;SUBS    $tmp,$op1.low,$op2.low\t\t! long\n\t&quot;
 7800             &quot;SBCS    $tmp,$op1.hi,$op2.hi&quot; %}
 7801   ins_encode %{
 7802     __ subs($tmp$$Register, $op1$$Register, $op2$$Register);
 7803     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7804   %}
 7805   ins_pipe(ialu_cconly_reg_reg);
 7806 %}
 7807 
 7808 instruct compUL_reg_reg_LTGE(flagsRegUL_LTGE xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7809   match(Set xcc (CmpUL op1 op2));
 7810   effect(DEF xcc, USE op1, USE op2, TEMP tmp);
 7811 
 7812   size(8);
 7813   format %{ &quot;SUBS    $tmp,$op1.low,$op2.low\t\t! unsigned long\n\t&quot;
 7814             &quot;SBCS    $tmp,$op1.hi,$op2.hi&quot; %}
 7815   ins_encode %{
 7816     __ subs($tmp$$Register, $op1$$Register, $op2$$Register);
 7817     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7818   %}
 7819   ins_pipe(ialu_cconly_reg_reg);
 7820 %}
 7821 
 7822 instruct compL_reg_reg_EQNE(flagsRegL_EQNE xcc, iRegL op1, iRegL op2) %{
 7823   match(Set xcc (CmpL op1 op2));
 7824   effect( DEF xcc, USE op1, USE op2 );
 7825 
 7826   size(8);
 7827   format %{ &quot;TEQ    $op1.hi,$op2.hi\t\t! long\n\t&quot;
 7828             &quot;TEQ.eq $op1.lo,$op2.lo&quot; %}
 7829   ins_encode %{
 7830     __ teq($op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7831     __ teq($op1$$Register, $op2$$Register, eq);
 7832   %}
 7833   ins_pipe(ialu_cconly_reg_reg);
 7834 %}
 7835 
 7836 instruct compL_reg_reg_LEGT(flagsRegL_LEGT xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7837   match(Set xcc (CmpL op1 op2));
 7838   effect( DEF xcc, USE op1, USE op2, TEMP tmp );
 7839 
 7840   size(8);
 7841   format %{ &quot;SUBS    $tmp,$op2.low,$op1.low\t\t! long\n\t&quot;
 7842             &quot;SBCS    $tmp,$op2.hi,$op1.hi&quot; %}
 7843   ins_encode %{
 7844     __ subs($tmp$$Register, $op2$$Register, $op1$$Register);
 7845     __ sbcs($tmp$$Register-&gt;successor(), $op2$$Register-&gt;successor(), $op1$$Register-&gt;successor());
 7846   %}
 7847   ins_pipe(ialu_cconly_reg_reg);
 7848 %}
 7849 
 7850 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7851 // (hi($con$$constant), lo($con$$constant)) becomes
 7852 instruct compL_reg_con_LTGE(flagsRegL_LTGE xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7853   match(Set xcc (CmpL op1 con));
 7854   effect( DEF xcc, USE op1, USE con, TEMP tmp );
 7855 
 7856   size(8);
 7857   format %{ &quot;SUBS    $tmp,$op1.low,$con\t\t! long\n\t&quot;
 7858             &quot;SBCS    $tmp,$op1.hi,0&quot; %}
 7859   ins_encode %{
 7860     __ subs($tmp$$Register, $op1$$Register, $con$$constant);
 7861     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7862   %}
 7863 
 7864   ins_pipe(ialu_cconly_reg_reg);
 7865 %}
 7866 
 7867 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7868 // (hi($con$$constant), lo($con$$constant)) becomes
 7869 instruct compL_reg_con_EQNE(flagsRegL_EQNE xcc, iRegL op1, immLlowRot con) %{
 7870   match(Set xcc (CmpL op1 con));
 7871   effect( DEF xcc, USE op1, USE con );
 7872 
 7873   size(8);
 7874   format %{ &quot;TEQ    $op1.hi,0\t\t! long\n\t&quot;
 7875             &quot;TEQ.eq $op1.lo,$con&quot; %}
 7876   ins_encode %{
 7877     __ teq($op1$$Register-&gt;successor(), 0);
 7878     __ teq($op1$$Register, $con$$constant, eq);
 7879   %}
 7880 
 7881   ins_pipe(ialu_cconly_reg_reg);
 7882 %}
 7883 
 7884 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7885 // (hi($con$$constant), lo($con$$constant)) becomes
 7886 instruct compL_reg_con_LEGT(flagsRegL_LEGT xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7887   match(Set xcc (CmpL op1 con));
 7888   effect( DEF xcc, USE op1, USE con, TEMP tmp );
 7889 
 7890   size(8);
 7891   format %{ &quot;RSBS    $tmp,$op1.low,$con\t\t! long\n\t&quot;
 7892             &quot;RSCS    $tmp,$op1.hi,0&quot; %}
 7893   ins_encode %{
 7894     __ rsbs($tmp$$Register, $op1$$Register, $con$$constant);
 7895     __ rscs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7896   %}
 7897 
 7898   ins_pipe(ialu_cconly_reg_reg);
 7899 %}
 7900 
 7901 instruct compUL_reg_reg_EQNE(flagsRegUL_EQNE xcc, iRegL op1, iRegL op2) %{
 7902   match(Set xcc (CmpUL op1 op2));
 7903   effect(DEF xcc, USE op1, USE op2);
 7904 
 7905   size(8);
 7906   format %{ &quot;TEQ    $op1.hi,$op2.hi\t\t! unsigned long\n\t&quot;
 7907             &quot;TEQ.eq $op1.lo,$op2.lo&quot; %}
 7908   ins_encode %{
 7909     __ teq($op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7910     __ teq($op1$$Register, $op2$$Register, eq);
 7911   %}
 7912   ins_pipe(ialu_cconly_reg_reg);
 7913 %}
 7914 
 7915 instruct compUL_reg_reg_LEGT(flagsRegUL_LEGT xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7916   match(Set xcc (CmpUL op1 op2));
 7917   effect(DEF xcc, USE op1, USE op2, TEMP tmp);
 7918 
 7919   size(8);
 7920   format %{ &quot;SUBS    $tmp,$op2.low,$op1.low\t\t! unsigned long\n\t&quot;
 7921             &quot;SBCS    $tmp,$op2.hi,$op1.hi&quot; %}
 7922   ins_encode %{
 7923     __ subs($tmp$$Register, $op2$$Register, $op1$$Register);
 7924     __ sbcs($tmp$$Register-&gt;successor(), $op2$$Register-&gt;successor(), $op1$$Register-&gt;successor());
 7925   %}
 7926   ins_pipe(ialu_cconly_reg_reg);
 7927 %}
 7928 
 7929 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7930 // (hi($con$$constant), lo($con$$constant)) becomes
 7931 instruct compUL_reg_con_LTGE(flagsRegUL_LTGE xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7932   match(Set xcc (CmpUL op1 con));
 7933   effect(DEF xcc, USE op1, USE con, TEMP tmp);
 7934 
 7935   size(8);
 7936   format %{ &quot;SUBS    $tmp,$op1.low,$con\t\t! unsigned long\n\t&quot;
 7937             &quot;SBCS    $tmp,$op1.hi,0&quot; %}
 7938   ins_encode %{
 7939     __ subs($tmp$$Register, $op1$$Register, $con$$constant);
 7940     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7941   %}
 7942 
 7943   ins_pipe(ialu_cconly_reg_reg);
 7944 %}
 7945 
 7946 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7947 // (hi($con$$constant), lo($con$$constant)) becomes
 7948 instruct compUL_reg_con_EQNE(flagsRegUL_EQNE xcc, iRegL op1, immLlowRot con) %{
 7949   match(Set xcc (CmpUL op1 con));
 7950   effect(DEF xcc, USE op1, USE con);
 7951 
 7952   size(8);
 7953   format %{ &quot;TEQ    $op1.hi,0\t\t! unsigned long\n\t&quot;
 7954             &quot;TEQ.eq $op1.lo,$con&quot; %}
 7955   ins_encode %{
 7956     __ teq($op1$$Register-&gt;successor(), 0);
 7957     __ teq($op1$$Register, $con$$constant, eq);
 7958   %}
 7959 
 7960   ins_pipe(ialu_cconly_reg_reg);
 7961 %}
 7962 
 7963 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7964 // (hi($con$$constant), lo($con$$constant)) becomes
 7965 instruct compUL_reg_con_LEGT(flagsRegUL_LEGT xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7966   match(Set xcc (CmpUL op1 con));
 7967   effect(DEF xcc, USE op1, USE con, TEMP tmp);
 7968 
 7969   size(8);
 7970   format %{ &quot;RSBS    $tmp,$op1.low,$con\t\t! unsigned long\n\t&quot;
 7971             &quot;RSCS    $tmp,$op1.hi,0&quot; %}
 7972   ins_encode %{
 7973     __ rsbs($tmp$$Register, $op1$$Register, $con$$constant);
 7974     __ rscs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7975   %}
 7976 
 7977   ins_pipe(ialu_cconly_reg_reg);
 7978 %}
 7979 
 7980 /* instruct testL_reg_reg(flagsRegL xcc, iRegL op1, iRegL op2, immL0 zero) %{ */
 7981 /*   match(Set xcc (CmpL (AndL op1 op2) zero)); */
 7982 /*   ins_encode %{ */
 7983 /*     __ stop(&quot;testL_reg_reg unimplemented&quot;); */
 7984 /*   %} */
 7985 /*   ins_pipe(ialu_cconly_reg_reg); */
 7986 /* %} */
 7987 
 7988 /* // useful for checking the alignment of a pointer: */
 7989 /* instruct testL_reg_con(flagsRegL xcc, iRegL op1, immLlowRot con, immL0 zero) %{ */
 7990 /*   match(Set xcc (CmpL (AndL op1 con) zero)); */
 7991 /*   ins_encode %{ */
 7992 /*     __ stop(&quot;testL_reg_con unimplemented&quot;); */
 7993 /*   %} */
 7994 /*   ins_pipe(ialu_cconly_reg_reg); */
 7995 /* %} */
 7996 
 7997 instruct compU_iReg_imm(flagsRegU icc, iRegI op1, aimmU31 op2 ) %{
 7998   match(Set icc (CmpU op1 op2));
 7999 
 8000   size(4);
 8001   format %{ &quot;cmp_32 $op1,$op2\t! unsigned&quot; %}
 8002   ins_encode %{
 8003     __ cmp_32($op1$$Register, $op2$$constant);
 8004   %}
 8005   ins_pipe(ialu_cconly_reg_imm);
 8006 %}
 8007 
 8008 // Compare Pointers
 8009 instruct compP_iRegP(flagsRegP pcc, iRegP op1, iRegP op2 ) %{
 8010   match(Set pcc (CmpP op1 op2));
 8011 
 8012   size(4);
 8013   format %{ &quot;CMP    $op1,$op2\t! ptr&quot; %}
 8014   ins_encode %{
 8015     __ cmp($op1$$Register, $op2$$Register);
 8016   %}
 8017   ins_pipe(ialu_cconly_reg_reg);
 8018 %}
 8019 
 8020 instruct compP_iRegP_imm(flagsRegP pcc, iRegP op1, aimmP op2 ) %{
 8021   match(Set pcc (CmpP op1 op2));
 8022 
 8023   size(4);
 8024   format %{ &quot;CMP    $op1,$op2\t! ptr&quot; %}
 8025   ins_encode %{
 8026     assert($op2$$constant == 0 || _opnds[2]-&gt;constant_reloc() == relocInfo::none, &quot;reloc in cmp?&quot;);
 8027     __ cmp($op1$$Register, $op2$$constant);
 8028   %}
 8029   ins_pipe(ialu_cconly_reg_imm);
 8030 %}
 8031 
 8032 //----------Max and Min--------------------------------------------------------
 8033 // Min Instructions
 8034 // Conditional move for min
 8035 instruct cmovI_reg_lt( iRegI op2, iRegI op1, flagsReg icc ) %{
 8036   effect( USE_DEF op2, USE op1, USE icc );
 8037 
 8038   size(4);
 8039   format %{ &quot;MOV.lt  $op2,$op1\t! min&quot; %}
 8040   ins_encode %{
 8041     __ mov($op2$$Register, $op1$$Register, lt);
 8042   %}
 8043   ins_pipe(ialu_reg_flags);
 8044 %}
 8045 
 8046 // Min Register with Register.
 8047 instruct minI_eReg(iRegI op1, iRegI op2) %{
 8048   match(Set op2 (MinI op1 op2));
 8049   ins_cost(DEFAULT_COST*2);
 8050   expand %{
 8051     flagsReg icc;
 8052     compI_iReg(icc,op1,op2);
 8053     cmovI_reg_lt(op2,op1,icc);
 8054   %}
 8055 %}
 8056 
 8057 // Max Instructions
 8058 // Conditional move for max
 8059 instruct cmovI_reg_gt( iRegI op2, iRegI op1, flagsReg icc ) %{
 8060   effect( USE_DEF op2, USE op1, USE icc );
 8061   format %{ &quot;MOV.gt  $op2,$op1\t! max&quot; %}
 8062   ins_encode %{
 8063     __ mov($op2$$Register, $op1$$Register, gt);
 8064   %}
 8065   ins_pipe(ialu_reg_flags);
 8066 %}
 8067 
 8068 // Max Register with Register
 8069 instruct maxI_eReg(iRegI op1, iRegI op2) %{
 8070   match(Set op2 (MaxI op1 op2));
 8071   ins_cost(DEFAULT_COST*2);
 8072   expand %{
 8073     flagsReg icc;
 8074     compI_iReg(icc,op1,op2);
 8075     cmovI_reg_gt(op2,op1,icc);
 8076   %}
 8077 %}
 8078 
 8079 
 8080 //----------Float Compares----------------------------------------------------
 8081 // Compare floating, generate condition code
 8082 instruct cmpF_cc(flagsRegF fcc, flagsReg icc, regF src1, regF src2) %{
 8083   match(Set icc (CmpF src1 src2));
 8084   effect(KILL fcc);
 8085 
 8086   size(8);
 8087   format %{ &quot;FCMPs  $src1,$src2\n\t&quot;
 8088             &quot;FMSTAT&quot; %}
 8089   ins_encode %{
 8090     __ fcmps($src1$$FloatRegister, $src2$$FloatRegister);
 8091     __ fmstat();
 8092   %}
 8093   ins_pipe(faddF_fcc_reg_reg_zero);
 8094 %}
 8095 
 8096 instruct cmpF0_cc(flagsRegF fcc, flagsReg icc, regF src1, immF0 src2) %{
 8097   match(Set icc (CmpF src1 src2));
 8098   effect(KILL fcc);
 8099 
 8100   size(8);
 8101   format %{ &quot;FCMPs  $src1,$src2\n\t&quot;
 8102             &quot;FMSTAT&quot; %}
 8103   ins_encode %{
 8104     __ fcmpzs($src1$$FloatRegister);
 8105     __ fmstat();
 8106   %}
 8107   ins_pipe(faddF_fcc_reg_reg_zero);
 8108 %}
 8109 
 8110 instruct cmpD_cc(flagsRegF fcc, flagsReg icc, regD src1, regD src2) %{
 8111   match(Set icc (CmpD src1 src2));
 8112   effect(KILL fcc);
 8113 
 8114   size(8);
 8115   format %{ &quot;FCMPd  $src1,$src2 \n\t&quot;
 8116             &quot;FMSTAT&quot; %}
 8117   ins_encode %{
 8118     __ fcmpd($src1$$FloatRegister, $src2$$FloatRegister);
 8119     __ fmstat();
 8120   %}
 8121   ins_pipe(faddD_fcc_reg_reg_zero);
 8122 %}
 8123 
 8124 instruct cmpD0_cc(flagsRegF fcc, flagsReg icc, regD src1, immD0 src2) %{
 8125   match(Set icc (CmpD src1 src2));
 8126   effect(KILL fcc);
 8127 
 8128   size(8);
 8129   format %{ &quot;FCMPZd  $src1,$src2 \n\t&quot;
 8130             &quot;FMSTAT&quot; %}
 8131   ins_encode %{
 8132     __ fcmpzd($src1$$FloatRegister);
 8133     __ fmstat();
 8134   %}
 8135   ins_pipe(faddD_fcc_reg_reg_zero);
 8136 %}
 8137 
 8138 // Compare floating, generate -1,0,1
 8139 instruct cmpF_reg(iRegI dst, regF src1, regF src2, flagsRegF fcc) %{
 8140   match(Set dst (CmpF3 src1 src2));
 8141   effect(KILL fcc);
 8142   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8143   size(20);
 8144   // same number of instructions as code using conditional moves but
 8145   // doesn&#39;t kill integer condition register
 8146   format %{ &quot;FCMPs  $dst,$src1,$src2 \n\t&quot;
 8147             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8148             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8149             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8150             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8151   ins_encode %{
 8152     __ fcmps($src1$$FloatRegister, $src2$$FloatRegister);
 8153     __ floating_cmp($dst$$Register);
 8154   %}
 8155   ins_pipe( floating_cmp );
 8156 %}
 8157 
 8158 instruct cmpF0_reg(iRegI dst, regF src1, immF0 src2, flagsRegF fcc) %{
 8159   match(Set dst (CmpF3 src1 src2));
 8160   effect(KILL fcc);
 8161   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8162   size(20);
 8163   // same number of instructions as code using conditional moves but
 8164   // doesn&#39;t kill integer condition register
 8165   format %{ &quot;FCMPZs $dst,$src1,$src2 \n\t&quot;
 8166             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8167             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8168             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8169             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8170   ins_encode %{
 8171     __ fcmpzs($src1$$FloatRegister);
 8172     __ floating_cmp($dst$$Register);
 8173   %}
 8174   ins_pipe( floating_cmp );
 8175 %}
 8176 
 8177 instruct cmpD_reg(iRegI dst, regD src1, regD src2, flagsRegF fcc) %{
 8178   match(Set dst (CmpD3 src1 src2));
 8179   effect(KILL fcc);
 8180   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8181   size(20);
 8182   // same number of instructions as code using conditional moves but
 8183   // doesn&#39;t kill integer condition register
 8184   format %{ &quot;FCMPd  $dst,$src1,$src2 \n\t&quot;
 8185             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8186             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8187             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8188             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8189   ins_encode %{
 8190     __ fcmpd($src1$$FloatRegister, $src2$$FloatRegister);
 8191     __ floating_cmp($dst$$Register);
 8192   %}
 8193   ins_pipe( floating_cmp );
 8194 %}
 8195 
 8196 instruct cmpD0_reg(iRegI dst, regD src1, immD0 src2, flagsRegF fcc) %{
 8197   match(Set dst (CmpD3 src1 src2));
 8198   effect(KILL fcc);
 8199   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8200   size(20);
 8201   // same number of instructions as code using conditional moves but
 8202   // doesn&#39;t kill integer condition register
 8203   format %{ &quot;FCMPZd $dst,$src1,$src2 \n\t&quot;
 8204             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8205             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8206             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8207             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8208   ins_encode %{
 8209     __ fcmpzd($src1$$FloatRegister);
 8210     __ floating_cmp($dst$$Register);
 8211   %}
 8212   ins_pipe( floating_cmp );
 8213 %}
 8214 
 8215 //----------Branches---------------------------------------------------------
 8216 // Jump
 8217 // (compare &#39;operand indIndex&#39; and &#39;instruct addP_reg_reg&#39; above)
 8218 // FIXME
 8219 instruct jumpXtnd(iRegX switch_val, iRegP tmp) %{
 8220   match(Jump switch_val);
 8221   effect(TEMP tmp);
 8222   ins_cost(350);
 8223   format %{  &quot;ADD    $tmp, $constanttablebase, $switch_val\n\t&quot;
 8224              &quot;LDR    $tmp,[$tmp + $constantoffset]\n\t&quot;
 8225              &quot;BX     $tmp&quot; %}
 8226   size(20);
 8227   ins_encode %{
 8228     Register table_reg;
 8229     Register label_reg = $tmp$$Register;
 8230     if (constant_offset() == 0) {
 8231       table_reg = $constanttablebase;
 8232       __ ldr(label_reg, Address(table_reg, $switch_val$$Register));
 8233     } else {
 8234       table_reg = $tmp$$Register;
 8235       int offset = $constantoffset;
 8236       if (is_memoryP(offset)) {
 8237         __ add(table_reg, $constanttablebase, $switch_val$$Register);
 8238         __ ldr(label_reg, Address(table_reg, offset));
 8239       } else {
 8240         __ mov_slow(table_reg, $constantoffset);
 8241         __ add(table_reg, $constanttablebase, table_reg);
 8242         __ ldr(label_reg, Address(table_reg, $switch_val$$Register));
 8243       }
 8244     }
 8245     __ jump(label_reg); // ldr + b better than ldr to PC for branch predictor?
 8246     //    __ ldr(PC, Address($table$$Register, $switch_val$$Register));
 8247   %}
 8248   ins_pipe(ialu_reg_reg);
 8249 %}
 8250 
 8251 // // Direct Branch.
 8252 instruct branch(label labl) %{
 8253   match(Goto);
 8254   effect(USE labl);
 8255 
 8256   size(4);
 8257   ins_cost(BRANCH_COST);
 8258   format %{ &quot;B     $labl&quot; %}
 8259   ins_encode %{
 8260     __ b(*($labl$$label));
 8261   %}
 8262   ins_pipe(br);
 8263 %}
 8264 
 8265 // Conditional Direct Branch
 8266 instruct branchCon(cmpOp cmp, flagsReg icc, label labl) %{
 8267   match(If cmp icc);
 8268   effect(USE labl);
 8269 
 8270   size(4);
 8271   ins_cost(BRANCH_COST);
 8272   format %{ &quot;B$cmp   $icc,$labl&quot; %}
 8273   ins_encode %{
 8274     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8275   %}
 8276   ins_pipe(br_cc);
 8277 %}
 8278 
 8279 #ifdef ARM
 8280 instruct branchCon_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, label labl) %{
 8281   match(If cmp icc);
 8282   effect(USE labl);
 8283   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 8284 
 8285   size(4);
 8286   ins_cost(BRANCH_COST);
 8287   format %{ &quot;B$cmp   $icc,$labl&quot; %}
 8288   ins_encode %{
 8289     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8290   %}
 8291   ins_pipe(br_cc);
 8292 %}
 8293 #endif
 8294 
 8295 
 8296 instruct branchConU(cmpOpU cmp, flagsRegU icc, label labl) %{
 8297   match(If cmp icc);
 8298   effect(USE labl);
 8299 
 8300   size(4);
 8301   ins_cost(BRANCH_COST);
 8302   format %{ &quot;B$cmp  $icc,$labl&quot; %}
 8303   ins_encode %{
 8304     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8305   %}
 8306   ins_pipe(br_cc);
 8307 %}
 8308 
 8309 instruct branchConP(cmpOpP cmp, flagsRegP pcc, label labl) %{
 8310   match(If cmp pcc);
 8311   effect(USE labl);
 8312 
 8313   size(4);
 8314   ins_cost(BRANCH_COST);
 8315   format %{ &quot;B$cmp  $pcc,$labl&quot; %}
 8316   ins_encode %{
 8317     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8318   %}
 8319   ins_pipe(br_cc);
 8320 %}
 8321 
 8322 instruct branchConL_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, label labl) %{
 8323   match(If cmp xcc);
 8324   effect(USE labl);
 8325   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8326 
 8327   size(4);
 8328   ins_cost(BRANCH_COST);
 8329   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8330   ins_encode %{
 8331     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8332   %}
 8333   ins_pipe(br_cc);
 8334 %}
 8335 
 8336 instruct branchConL_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, label labl) %{
 8337   match(If cmp xcc);
 8338   effect(USE labl);
 8339   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8340 
 8341   size(4);
 8342   ins_cost(BRANCH_COST);
 8343   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8344   ins_encode %{
 8345     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8346   %}
 8347   ins_pipe(br_cc);
 8348 %}
 8349 
 8350 instruct branchConL_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, label labl) %{
 8351   match(If cmp xcc);
 8352   effect(USE labl);
 8353   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le );
 8354 
 8355   size(4);
 8356   ins_cost(BRANCH_COST);
 8357   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8358   ins_encode %{
 8359     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8360   %}
 8361   ins_pipe(br_cc);
 8362 %}
 8363 
 8364 instruct branchConUL_LTGE(cmpOpUL cmp, flagsRegUL_LTGE xcc, label labl) %{
 8365   match(If cmp xcc);
 8366   effect(USE labl);
 8367   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 8368 
 8369   size(4);
 8370   ins_cost(BRANCH_COST);
 8371   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8372   ins_encode %{
 8373     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8374   %}
 8375   ins_pipe(br_cc);
 8376 %}
 8377 
 8378 instruct branchConUL_EQNE(cmpOpUL cmp, flagsRegUL_EQNE xcc, label labl) %{
 8379   match(If cmp xcc);
 8380   effect(USE labl);
 8381   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne);
 8382 
 8383   size(4);
 8384   ins_cost(BRANCH_COST);
 8385   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8386   ins_encode %{
 8387     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8388   %}
 8389   ins_pipe(br_cc);
 8390 %}
 8391 
 8392 instruct branchConUL_LEGT(cmpOpUL_commute cmp, flagsRegUL_LEGT xcc, label labl) %{
 8393   match(If cmp xcc);
 8394   effect(USE labl);
 8395   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le);
 8396 
 8397   size(4);
 8398   ins_cost(BRANCH_COST);
 8399   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8400   ins_encode %{
 8401     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8402   %}
 8403   ins_pipe(br_cc);
 8404 %}
 8405 
 8406 instruct branchLoopEnd(cmpOp cmp, flagsReg icc, label labl) %{
 8407   match(CountedLoopEnd cmp icc);
 8408   effect(USE labl);
 8409 
 8410   size(4);
 8411   ins_cost(BRANCH_COST);
 8412   format %{ &quot;B$cmp   $icc,$labl\t! Loop end&quot; %}
 8413   ins_encode %{
 8414     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8415   %}
 8416   ins_pipe(br_cc);
 8417 %}
 8418 
 8419 // instruct branchLoopEndU(cmpOpU cmp, flagsRegU icc, label labl) %{
 8420 //   match(CountedLoopEnd cmp icc);
 8421 //   ins_pipe(br_cc);
 8422 // %}
 8423 
 8424 // ============================================================================
 8425 // Long Compare
 8426 //
 8427 // Currently we hold longs in 2 registers.  Comparing such values efficiently
 8428 // is tricky.  The flavor of compare used depends on whether we are testing
 8429 // for LT, LE, or EQ.  For a simple LT test we can check just the sign bit.
 8430 // The GE test is the negated LT test.  The LE test can be had by commuting
 8431 // the operands (yielding a GE test) and then negating; negate again for the
 8432 // GT test.  The EQ test is done by ORcc&#39;ing the high and low halves, and the
 8433 // NE test is negated from that.
 8434 
 8435 // Due to a shortcoming in the ADLC, it mixes up expressions like:
 8436 // (foo (CmpI (CmpL X Y) 0)) and (bar (CmpI (CmpL X 0L) 0)).  Note the
 8437 // difference between &#39;Y&#39; and &#39;0L&#39;.  The tree-matches for the CmpI sections
 8438 // are collapsed internally in the ADLC&#39;s dfa-gen code.  The match for
 8439 // (CmpI (CmpL X Y) 0) is silently replaced with (CmpI (CmpL X 0L) 0) and the
 8440 // foo match ends up with the wrong leaf.  One fix is to not match both
 8441 // reg-reg and reg-zero forms of long-compare.  This is unfortunate because
 8442 // both forms beat the trinary form of long-compare and both are very useful
 8443 // on Intel which has so few registers.
 8444 
 8445 // instruct branchCon_long(cmpOp cmp, flagsRegL xcc, label labl) %{
 8446 //   match(If cmp xcc);
 8447 //   ins_pipe(br_cc);
 8448 // %}
 8449 
 8450 // Manifest a CmpL3 result in an integer register.  Very painful.
 8451 // This is the test to avoid.
 8452 instruct cmpL3_reg_reg(iRegI dst, iRegL src1, iRegL src2, flagsReg ccr ) %{
 8453   match(Set dst (CmpL3 src1 src2) );
 8454   effect( KILL ccr );
 8455   ins_cost(6*DEFAULT_COST); // FIXME
 8456   size(32);
 8457   format %{
 8458       &quot;CMP    $src1.hi, $src2.hi\t\t! long\n&quot;
 8459     &quot;\tMOV.gt $dst, 1\n&quot;
 8460     &quot;\tmvn.lt $dst, 0\n&quot;
 8461     &quot;\tB.ne   done\n&quot;
 8462     &quot;\tSUBS   $dst, $src1.lo, $src2.lo\n&quot;
 8463     &quot;\tMOV.hi $dst, 1\n&quot;
 8464     &quot;\tmvn.lo $dst, 0\n&quot;
 8465     &quot;done:&quot;     %}
 8466   ins_encode %{
 8467     Label done;
 8468     __ cmp($src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 8469     __ mov($dst$$Register, 1, gt);
 8470     __ mvn($dst$$Register, 0, lt);
 8471     __ b(done, ne);
 8472     __ subs($dst$$Register, $src1$$Register, $src2$$Register);
 8473     __ mov($dst$$Register, 1, hi);
 8474     __ mvn($dst$$Register, 0, lo);
 8475     __ bind(done);
 8476   %}
 8477   ins_pipe(cmpL_reg);
 8478 %}
 8479 
 8480 // Conditional move
 8481 instruct cmovLL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegL dst, iRegL src) %{
 8482   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8483   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8484 
 8485   ins_cost(150);
 8486   size(8);
 8487   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8488             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8489   ins_encode %{
 8490     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8491     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8492   %}
 8493   ins_pipe(ialu_reg);
 8494 %}
 8495 
 8496 instruct cmovLL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegL dst, iRegL src) %{
 8497   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8498   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8499 
 8500   ins_cost(150);
 8501   size(8);
 8502   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8503             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8504   ins_encode %{
 8505     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8506     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8507   %}
 8508   ins_pipe(ialu_reg);
 8509 %}
 8510 
 8511 instruct cmovLL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegL dst, iRegL src) %{
 8512   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8513   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8514 
 8515   ins_cost(150);
 8516   size(8);
 8517   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8518             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8519   ins_encode %{
 8520     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8521     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8522   %}
 8523   ins_pipe(ialu_reg);
 8524 %}
 8525 
 8526 instruct cmovLL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegL dst, immL0 src) %{
 8527   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8528   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8529   ins_cost(140);
 8530   size(8);
 8531   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8532             &quot;MOV$cmp  $dst,0&quot; %}
 8533   ins_encode %{
 8534     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8535     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8536   %}
 8537   ins_pipe(ialu_imm);
 8538 %}
 8539 
 8540 instruct cmovLL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegL dst, immL0 src) %{
 8541   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8542   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8543   ins_cost(140);
 8544   size(8);
 8545   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8546             &quot;MOV$cmp  $dst,0&quot; %}
 8547   ins_encode %{
 8548     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8549     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8550   %}
 8551   ins_pipe(ialu_imm);
 8552 %}
 8553 
 8554 instruct cmovLL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegL dst, immL0 src) %{
 8555   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8556   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8557   ins_cost(140);
 8558   size(8);
 8559   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8560             &quot;MOV$cmp  $dst,0&quot; %}
 8561   ins_encode %{
 8562     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8563     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8564   %}
 8565   ins_pipe(ialu_imm);
 8566 %}
 8567 
 8568 instruct cmovIL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegI dst, iRegI src) %{
 8569   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8570   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8571 
 8572   ins_cost(150);
 8573   size(4);
 8574   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8575   ins_encode %{
 8576     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8577   %}
 8578   ins_pipe(ialu_reg);
 8579 %}
 8580 
 8581 instruct cmovIL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegI dst, iRegI src) %{
 8582   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8583   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8584 
 8585   ins_cost(150);
 8586   size(4);
 8587   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8588   ins_encode %{
 8589     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8590   %}
 8591   ins_pipe(ialu_reg);
 8592 %}
 8593 
 8594 instruct cmovIL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegI dst, iRegI src) %{
 8595   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8596   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8597 
 8598   ins_cost(150);
 8599   size(4);
 8600   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8601   ins_encode %{
 8602     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8603   %}
 8604   ins_pipe(ialu_reg);
 8605 %}
 8606 
 8607 instruct cmovIL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegI dst, immI16 src) %{
 8608   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8609   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8610 
 8611   ins_cost(140);
 8612   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8613   ins_encode %{
 8614     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8615   %}
 8616   ins_pipe(ialu_imm);
 8617 %}
 8618 
 8619 instruct cmovIL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegI dst, immI16 src) %{
 8620   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8621   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8622 
 8623   ins_cost(140);
 8624   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8625   ins_encode %{
 8626     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8627   %}
 8628   ins_pipe(ialu_imm);
 8629 %}
 8630 
 8631 instruct cmovIL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegI dst, immI16 src) %{
 8632   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8633   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8634 
 8635   ins_cost(140);
 8636   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8637   ins_encode %{
 8638     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8639   %}
 8640   ins_pipe(ialu_imm);
 8641 %}
 8642 
 8643 instruct cmovPL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegP dst, iRegP src) %{
 8644   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8645   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8646 
 8647   ins_cost(150);
 8648   size(4);
 8649   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8650   ins_encode %{
 8651     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8652   %}
 8653   ins_pipe(ialu_reg);
 8654 %}
 8655 
 8656 instruct cmovPL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegP dst, iRegP src) %{
 8657   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8658   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8659 
 8660   ins_cost(150);
 8661   size(4);
 8662   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8663   ins_encode %{
 8664     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8665   %}
 8666   ins_pipe(ialu_reg);
 8667 %}
 8668 
 8669 instruct cmovPL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegP dst, iRegP src) %{
 8670   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8671   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8672 
 8673   ins_cost(150);
 8674   size(4);
 8675   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8676   ins_encode %{
 8677     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8678   %}
 8679   ins_pipe(ialu_reg);
 8680 %}
 8681 
 8682 instruct cmovPL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegP dst, immP0 src) %{
 8683   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8684   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8685 
 8686   ins_cost(140);
 8687   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8688   ins_encode %{
 8689     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8690   %}
 8691   ins_pipe(ialu_imm);
 8692 %}
 8693 
 8694 instruct cmovPL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegP dst, immP0 src) %{
 8695   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8696   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8697 
 8698   ins_cost(140);
 8699   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8700   ins_encode %{
 8701     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8702   %}
 8703   ins_pipe(ialu_imm);
 8704 %}
 8705 
 8706 instruct cmovPL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegP dst, immP0 src) %{
 8707   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8708   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8709 
 8710   ins_cost(140);
 8711   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8712   ins_encode %{
 8713     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8714   %}
 8715   ins_pipe(ialu_imm);
 8716 %}
 8717 
 8718 instruct cmovFL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, regF dst, regF src) %{
 8719   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8720   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8721   ins_cost(150);
 8722   size(4);
 8723   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8724   ins_encode %{
 8725     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8726   %}
 8727   ins_pipe(int_conditional_float_move);
 8728 %}
 8729 
 8730 instruct cmovFL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, regF dst, regF src) %{
 8731   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8732   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8733   ins_cost(150);
 8734   size(4);
 8735   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8736   ins_encode %{
 8737     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8738   %}
 8739   ins_pipe(int_conditional_float_move);
 8740 %}
 8741 
 8742 instruct cmovFL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, regF dst, regF src) %{
 8743   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8744   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8745   ins_cost(150);
 8746   size(4);
 8747   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8748   ins_encode %{
 8749     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8750   %}
 8751   ins_pipe(int_conditional_float_move);
 8752 %}
 8753 
 8754 instruct cmovDL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, regD dst, regD src) %{
 8755   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8756   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8757 
 8758   ins_cost(150);
 8759   size(4);
 8760   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8761   ins_encode %{
 8762     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8763   %}
 8764   ins_pipe(int_conditional_float_move);
 8765 %}
 8766 
 8767 instruct cmovDL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, regD dst, regD src) %{
 8768   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8769   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8770 
 8771   ins_cost(150);
 8772   size(4);
 8773   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8774   ins_encode %{
 8775     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8776   %}
 8777   ins_pipe(int_conditional_float_move);
 8778 %}
 8779 
 8780 instruct cmovDL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, regD dst, regD src) %{
 8781   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8782   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8783 
 8784   ins_cost(150);
 8785   size(4);
 8786   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8787   ins_encode %{
 8788     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8789   %}
 8790   ins_pipe(int_conditional_float_move);
 8791 %}
 8792 
 8793 // ============================================================================
 8794 // Safepoint Instruction
 8795 // rather than KILL R12, it would be better to use any reg as
 8796 // TEMP. Can&#39;t do that at this point because it crashes the compiler
 8797 instruct safePoint_poll(iRegP poll, R12RegI tmp, flagsReg icc) %{
 8798   match(SafePoint poll);
 8799   effect(USE poll, KILL tmp, KILL icc);
 8800 
 8801   size(4);
 8802   format %{ &quot;LDR   $tmp,[$poll]\t! Safepoint: poll for GC&quot; %}
 8803   ins_encode %{
 8804     __ relocate(relocInfo::poll_type);
 8805     __ ldr($tmp$$Register, Address($poll$$Register));
 8806   %}
 8807   ins_pipe(loadPollP);
 8808 %}
 8809 
 8810 
 8811 // ============================================================================
 8812 // Call Instructions
 8813 // Call Java Static Instruction
 8814 instruct CallStaticJavaDirect( method meth ) %{
 8815   match(CallStaticJava);
 8816   predicate(! ((CallStaticJavaNode*)n)-&gt;is_method_handle_invoke());
 8817   effect(USE meth);
 8818 
 8819   ins_cost(CALL_COST);
 8820   format %{ &quot;CALL,static ==&gt; &quot; %}
 8821   ins_encode( Java_Static_Call( meth ), call_epilog );
 8822   ins_pipe(simple_call);
 8823 %}
 8824 
 8825 // Call Java Static Instruction (method handle version)
 8826 instruct CallStaticJavaHandle( method meth ) %{
 8827   match(CallStaticJava);
 8828   predicate(((CallStaticJavaNode*)n)-&gt;is_method_handle_invoke());
 8829   effect(USE meth);
 8830   // FP is saved by all callees (for interpreter stack correction).
 8831   // We use it here for a similar purpose, in {preserve,restore}_FP.
 8832 
 8833   ins_cost(CALL_COST);
 8834   format %{ &quot;CALL,static/MethodHandle ==&gt; &quot; %}
 8835   ins_encode( preserve_SP, Java_Static_Call( meth ), restore_SP, call_epilog );
 8836   ins_pipe(simple_call);
 8837 %}
 8838 
 8839 // Call Java Dynamic Instruction
 8840 instruct CallDynamicJavaDirect( method meth ) %{
 8841   match(CallDynamicJava);
 8842   effect(USE meth);
 8843 
 8844   ins_cost(CALL_COST);
 8845   format %{ &quot;MOV_OOP    (empty),R_R8\n\t&quot;
 8846             &quot;CALL,dynamic  ; NOP ==&gt; &quot; %}
 8847   ins_encode( Java_Dynamic_Call( meth ), call_epilog );
 8848   ins_pipe(call);
 8849 %}
 8850 
 8851 // Call Runtime Instruction
 8852 instruct CallRuntimeDirect(method meth) %{
 8853   match(CallRuntime);
 8854   effect(USE meth);
 8855   ins_cost(CALL_COST);
 8856   format %{ &quot;CALL,runtime&quot; %}
 8857   ins_encode( Java_To_Runtime( meth ),
 8858               call_epilog );
 8859   ins_pipe(simple_call);
 8860 %}
 8861 
 8862 // Call runtime without safepoint - same as CallRuntime
 8863 instruct CallLeafDirect(method meth) %{
 8864   match(CallLeaf);
 8865   effect(USE meth);
 8866   ins_cost(CALL_COST);
 8867   format %{ &quot;CALL,runtime leaf&quot; %}
 8868   // TODO: ned save_last_PC here?
 8869   ins_encode( Java_To_Runtime( meth ),
 8870               call_epilog );
 8871   ins_pipe(simple_call);
 8872 %}
 8873 
 8874 // Call runtime without safepoint - same as CallLeaf
 8875 instruct CallLeafNoFPDirect(method meth) %{
 8876   match(CallLeafNoFP);
 8877   effect(USE meth);
 8878   ins_cost(CALL_COST);
 8879   format %{ &quot;CALL,runtime leaf nofp&quot; %}
 8880   // TODO: ned save_last_PC here?
 8881   ins_encode( Java_To_Runtime( meth ),
 8882               call_epilog );
 8883   ins_pipe(simple_call);
 8884 %}
 8885 
 8886 // Tail Call; Jump from runtime stub to Java code.
 8887 // Also known as an &#39;interprocedural jump&#39;.
 8888 // Target of jump will eventually return to caller.
 8889 // TailJump below removes the return address.
 8890 instruct TailCalljmpInd(IPRegP jump_target, inline_cache_regP method_oop) %{
 8891   match(TailCall jump_target method_oop );
 8892 
 8893   ins_cost(CALL_COST);
 8894   format %{ &quot;MOV    Rexception_pc, LR\n\t&quot;
 8895             &quot;jump   $jump_target  \t! $method_oop holds method oop&quot; %}
 8896   ins_encode %{
 8897     __ mov(Rexception_pc, LR);   // this is used only to call
 8898                                  // StubRoutines::forward_exception_entry()
 8899                                  // which expects PC of exception in
 8900                                  // R5. FIXME?
 8901     __ jump($jump_target$$Register);
 8902   %}
 8903   ins_pipe(tail_call);
 8904 %}
 8905 
 8906 
 8907 // Return Instruction
 8908 instruct Ret() %{
 8909   match(Return);
 8910 
 8911   format %{ &quot;ret LR&quot; %}
 8912 
 8913   ins_encode %{
 8914     __ ret(LR);
 8915   %}
 8916 
 8917   ins_pipe(br);
 8918 %}
 8919 
 8920 
 8921 // Tail Jump; remove the return address; jump to target.
 8922 // TailCall above leaves the return address around.
 8923 // TailJump is used in only one place, the rethrow_Java stub (fancy_jump=2).
 8924 // ex_oop (Exception Oop) is needed in %o0 at the jump. As there would be a
 8925 // &quot;restore&quot; before this instruction (in Epilogue), we need to materialize it
 8926 // in %i0.
 8927 instruct tailjmpInd(IPRegP jump_target, RExceptionRegP ex_oop) %{
 8928   match( TailJump jump_target ex_oop );
 8929   ins_cost(CALL_COST);
 8930   format %{ &quot;MOV    Rexception_pc, LR\n\t&quot;
 8931             &quot;jump   $jump_target \t! $ex_oop holds exc. oop&quot; %}
 8932   ins_encode %{
 8933     __ mov(Rexception_pc, LR);
 8934     __ jump($jump_target$$Register);
 8935   %}
 8936   ins_pipe(tail_call);
 8937 %}
 8938 
 8939 // Create exception oop: created by stack-crawling runtime code.
 8940 // Created exception is now available to this handler, and is setup
 8941 // just prior to jumping to this handler.  No code emitted.
 8942 instruct CreateException( RExceptionRegP ex_oop )
 8943 %{
 8944   match(Set ex_oop (CreateEx));
 8945   ins_cost(0);
 8946 
 8947   size(0);
 8948   // use the following format syntax
 8949   format %{ &quot;! exception oop is in Rexception_obj; no code emitted&quot; %}
 8950   ins_encode();
 8951   ins_pipe(empty);
 8952 %}
 8953 
 8954 
 8955 // Rethrow exception:
 8956 // The exception oop will come in the first argument position.
 8957 // Then JUMP (not call) to the rethrow stub code.
 8958 instruct RethrowException()
 8959 %{
 8960   match(Rethrow);
 8961   ins_cost(CALL_COST);
 8962 
 8963   // use the following format syntax
 8964   format %{ &quot;b    rethrow_stub&quot; %}
 8965   ins_encode %{
 8966     Register scratch = R1_tmp;
 8967     assert_different_registers(scratch, c_rarg0, LR);
 8968     __ jump(OptoRuntime::rethrow_stub(), relocInfo::runtime_call_type, scratch);
 8969   %}
 8970   ins_pipe(tail_call);
 8971 %}
 8972 
 8973 
 8974 // Die now
 8975 instruct ShouldNotReachHere( )
 8976 %{
 8977   match(Halt);
 8978   ins_cost(CALL_COST);
 8979 
 8980   size(4);
 8981   // Use the following format syntax
 8982   format %{ &quot;ShouldNotReachHere&quot; %}
 8983   ins_encode %{
 8984     __ udf(0xdead);
 8985   %}
 8986   ins_pipe(tail_call);
 8987 %}
 8988 
 8989 // ============================================================================
 8990 // The 2nd slow-half of a subtype check.  Scan the subklass&#39;s 2ndary superklass
 8991 // array for an instance of the superklass.  Set a hidden internal cache on a
 8992 // hit (cache is checked with exposed code in gen_subtype_check()).  Return
 8993 // not zero for a miss or zero for a hit.  The encoding ALSO sets flags.
 8994 instruct partialSubtypeCheck( R0RegP index, R1RegP sub, R2RegP super, flagsRegP pcc, LRRegP lr ) %{
 8995   match(Set index (PartialSubtypeCheck sub super));
 8996   effect( KILL pcc, KILL lr );
 8997   ins_cost(DEFAULT_COST*10);
 8998   format %{ &quot;CALL   PartialSubtypeCheck&quot; %}
 8999   ins_encode %{
 9000     __ call(StubRoutines::Arm::partial_subtype_check(), relocInfo::runtime_call_type);
 9001   %}
 9002   ins_pipe(partial_subtype_check_pipe);
 9003 %}
 9004 
 9005 /* instruct partialSubtypeCheck_vs_zero( flagsRegP pcc, o1RegP sub, o2RegP super, immP0 zero, o0RegP idx, o7RegP o7 ) %{ */
 9006 /*   match(Set pcc (CmpP (PartialSubtypeCheck sub super) zero)); */
 9007 /*   ins_pipe(partial_subtype_check_pipe); */
 9008 /* %} */
 9009 
 9010 
 9011 // ============================================================================
 9012 // inlined locking and unlocking
 9013 
 9014 instruct cmpFastLock(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2, iRegP scratch )
 9015 %{
 9016   match(Set pcc (FastLock object box));
 9017   predicate(!(UseBiasedLocking &amp;&amp; !UseOptoBiasInlining));
 9018 
 9019   effect(TEMP scratch, TEMP scratch2);
 9020   ins_cost(DEFAULT_COST*3);
 9021 
 9022   format %{ &quot;FASTLOCK  $object, $box; KILL $scratch, $scratch2&quot; %}
 9023   ins_encode %{
 9024     __ fast_lock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register);
 9025   %}
 9026   ins_pipe(long_memory_op);
 9027 %}
 9028 
 9029 instruct cmpFastLock_noBiasInline(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2,
 9030                                   iRegP scratch, iRegP scratch3) %{
 9031   match(Set pcc (FastLock object box));
 9032   predicate(UseBiasedLocking &amp;&amp; !UseOptoBiasInlining);
 9033 
 9034   effect(TEMP scratch, TEMP scratch2, TEMP scratch3);
 9035   ins_cost(DEFAULT_COST*5);
 9036 
 9037   format %{ &quot;FASTLOCK  $object, $box; KILL $scratch, $scratch2, $scratch3&quot; %}
 9038   ins_encode %{
 9039     __ fast_lock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register, $scratch3$$Register);
 9040   %}
 9041   ins_pipe(long_memory_op);
 9042 %}
 9043 
 9044 
 9045 instruct cmpFastUnlock(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2, iRegP scratch ) %{
 9046   match(Set pcc (FastUnlock object box));
 9047   effect(TEMP scratch, TEMP scratch2);
 9048   ins_cost(100);
 9049 
 9050   format %{ &quot;FASTUNLOCK  $object, $box; KILL $scratch, $scratch2&quot; %}
 9051   ins_encode %{
 9052     __ fast_unlock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register);
 9053   %}
 9054   ins_pipe(long_memory_op);
 9055 %}
 9056 
 9057 // Count and Base registers are fixed because the allocator cannot
 9058 // kill unknown registers.  The encodings are generic.
 9059 instruct clear_array(iRegX cnt, iRegP base, iRegI temp, iRegX zero, Universe dummy, flagsReg cpsr) %{
 9060   match(Set dummy (ClearArray cnt base));
 9061   effect(TEMP temp, TEMP zero, KILL cpsr);
 9062   ins_cost(300);
 9063   format %{ &quot;MOV    $zero,0\n&quot;
 9064       &quot;        MOV    $temp,$cnt\n&quot;
 9065       &quot;loop:   SUBS   $temp,$temp,4\t! Count down a dword of bytes\n&quot;
 9066       &quot;        STR.ge $zero,[$base+$temp]\t! delay slot&quot;
 9067       &quot;        B.gt   loop\t\t! Clearing loop\n&quot; %}
 9068   ins_encode %{
 9069     __ mov($zero$$Register, 0);
 9070     __ mov($temp$$Register, $cnt$$Register);
 9071     Label(loop);
 9072     __ bind(loop);
 9073     __ subs($temp$$Register, $temp$$Register, 4);
 9074     __ str($zero$$Register, Address($base$$Register, $temp$$Register), ge);
 9075     __ b(loop, gt);
 9076   %}
 9077   ins_pipe(long_memory_op);
 9078 %}
 9079 
 9080 #ifdef XXX
 9081 // FIXME: Why R0/R1/R2/R3?
 9082 instruct string_compare(R0RegP str1, R1RegP str2, R2RegI cnt1, R3RegI cnt2, iRegI result,
 9083                         iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 9084   predicate(!CompactStrings);
 9085   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
 9086   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL ccr, TEMP tmp1, TEMP tmp2);
 9087   ins_cost(300);
 9088   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   // TEMP $tmp1, $tmp2&quot; %}
 9089   ins_encode( enc_String_Compare(str1, str2, cnt1, cnt2, result, tmp1, tmp2) );
 9090 
 9091   ins_pipe(long_memory_op);
 9092 %}
 9093 
 9094 // FIXME: Why R0/R1/R2?
 9095 instruct string_equals(R0RegP str1, R1RegP str2, R2RegI cnt, iRegI result, iRegI tmp1, iRegI tmp2,
 9096                        flagsReg ccr) %{
 9097   predicate(!CompactStrings);
 9098   match(Set result (StrEquals (Binary str1 str2) cnt));
 9099   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, TEMP tmp1, TEMP tmp2, TEMP result, KILL ccr);
 9100 
 9101   ins_cost(300);
 9102   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result   // TEMP $tmp1, $tmp2&quot; %}
 9103   ins_encode( enc_String_Equals(str1, str2, cnt, result, tmp1, tmp2) );
 9104   ins_pipe(long_memory_op);
 9105 %}
 9106 
 9107 // FIXME: Why R0/R1?
 9108 instruct array_equals(R0RegP ary1, R1RegP ary2, iRegI tmp1, iRegI tmp2, iRegI tmp3, iRegI result,
 9109                       flagsReg ccr) %{
 9110   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
 9111   match(Set result (AryEq ary1 ary2));
 9112   effect(USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP result, KILL ccr);
 9113 
 9114   ins_cost(300);
 9115   format %{ &quot;Array Equals $ary1,$ary2 -&gt; $result   // TEMP $tmp1,$tmp2,$tmp3&quot; %}
 9116   ins_encode( enc_Array_Equals(ary1, ary2, tmp1, tmp2, tmp3, result));
 9117   ins_pipe(long_memory_op);
 9118 %}
 9119 #endif
 9120 
 9121 //---------- Zeros Count Instructions ------------------------------------------
 9122 
 9123 instruct countLeadingZerosI(iRegI dst, iRegI src) %{
 9124   match(Set dst (CountLeadingZerosI src));
 9125   size(4);
 9126   format %{ &quot;CLZ_32 $dst,$src&quot; %}
 9127   ins_encode %{
 9128     __ clz_32($dst$$Register, $src$$Register);
 9129   %}
 9130   ins_pipe(ialu_reg);
 9131 %}
 9132 
 9133 instruct countLeadingZerosL(iRegI dst, iRegL src, iRegI tmp, flagsReg ccr) %{
 9134   match(Set dst (CountLeadingZerosL src));
 9135   effect(TEMP tmp, TEMP dst, KILL ccr);
 9136   size(16);
 9137   format %{ &quot;CLZ    $dst,$src.hi\n\t&quot;
 9138             &quot;TEQ    $dst,32\n\t&quot;
 9139             &quot;CLZ.eq $tmp,$src.lo\n\t&quot;
 9140             &quot;ADD.eq $dst, $dst, $tmp\n\t&quot; %}
 9141   ins_encode %{
 9142     __ clz($dst$$Register, $src$$Register-&gt;successor());
 9143     __ teq($dst$$Register, 32);
 9144     __ clz($tmp$$Register, $src$$Register, eq);
 9145     __ add($dst$$Register, $dst$$Register, $tmp$$Register, eq);
 9146   %}
 9147   ins_pipe(ialu_reg);
 9148 %}
 9149 
 9150 instruct countTrailingZerosI(iRegI dst, iRegI src, iRegI tmp) %{
 9151   match(Set dst (CountTrailingZerosI src));
 9152   effect(TEMP tmp);
 9153   size(8);
 9154   format %{ &quot;RBIT_32 $tmp, $src\n\t&quot;
 9155             &quot;CLZ_32  $dst,$tmp&quot; %}
 9156   ins_encode %{
 9157     __ rbit_32($tmp$$Register, $src$$Register);
 9158     __ clz_32($dst$$Register, $tmp$$Register);
 9159   %}
 9160   ins_pipe(ialu_reg);
 9161 %}
 9162 
 9163 instruct countTrailingZerosL(iRegI dst, iRegL src, iRegI tmp, flagsReg ccr) %{
 9164   match(Set dst (CountTrailingZerosL src));
 9165   effect(TEMP tmp, TEMP dst, KILL ccr);
 9166   size(24);
 9167   format %{ &quot;RBIT   $tmp,$src.lo\n\t&quot;
 9168             &quot;CLZ    $dst,$tmp\n\t&quot;
 9169             &quot;TEQ    $dst,32\n\t&quot;
 9170             &quot;RBIT   $tmp,$src.hi\n\t&quot;
 9171             &quot;CLZ.eq $tmp,$tmp\n\t&quot;
 9172             &quot;ADD.eq $dst,$dst,$tmp\n\t&quot; %}
 9173   ins_encode %{
 9174     __ rbit($tmp$$Register, $src$$Register);
 9175     __ clz($dst$$Register, $tmp$$Register);
 9176     __ teq($dst$$Register, 32);
 9177     __ rbit($tmp$$Register, $src$$Register-&gt;successor());
 9178     __ clz($tmp$$Register, $tmp$$Register, eq);
 9179     __ add($dst$$Register, $dst$$Register, $tmp$$Register, eq);
 9180   %}
 9181   ins_pipe(ialu_reg);
 9182 %}
 9183 
 9184 
 9185 //---------- Population Count Instructions -------------------------------------
 9186 
 9187 instruct popCountI(iRegI dst, iRegI src, regD_low tmp) %{
 9188   predicate(UsePopCountInstruction);
 9189   match(Set dst (PopCountI src));
 9190   effect(TEMP tmp);
 9191 
 9192   format %{ &quot;FMSR       $tmp,$src\n\t&quot;
 9193             &quot;VCNT.8     $tmp,$tmp\n\t&quot;
 9194             &quot;VPADDL.U8  $tmp,$tmp\n\t&quot;
 9195             &quot;VPADDL.U16 $tmp,$tmp\n\t&quot;
 9196             &quot;FMRS       $dst,$tmp&quot; %}
 9197   size(20);
 9198 
 9199   ins_encode %{
 9200     __ fmsr($tmp$$FloatRegister, $src$$Register);
 9201     __ vcnt($tmp$$FloatRegister, $tmp$$FloatRegister);
 9202     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 8, 0);
 9203     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 16, 0);
 9204     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 9205   %}
 9206   ins_pipe(ialu_reg); // FIXME
 9207 %}
 9208 
 9209 // Note: Long.bitCount(long) returns an int.
 9210 instruct popCountL(iRegI dst, iRegL src, regD_low tmp) %{
 9211   predicate(UsePopCountInstruction);
 9212   match(Set dst (PopCountL src));
 9213   effect(TEMP tmp);
 9214 
 9215   format %{ &quot;FMDRR       $tmp,$src.lo,$src.hi\n\t&quot;
 9216             &quot;VCNT.8      $tmp,$tmp\n\t&quot;
 9217             &quot;VPADDL.U8   $tmp,$tmp\n\t&quot;
 9218             &quot;VPADDL.U16  $tmp,$tmp\n\t&quot;
 9219             &quot;VPADDL.U32  $tmp,$tmp\n\t&quot;
 9220             &quot;FMRS        $dst,$tmp&quot; %}
 9221 
 9222   size(32);
 9223 
 9224   ins_encode %{
 9225     __ fmdrr($tmp$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 9226     __ vcnt($tmp$$FloatRegister, $tmp$$FloatRegister);
 9227     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 8, 0);
 9228     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 16, 0);
 9229     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 32, 0);
 9230     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 9231   %}
 9232   ins_pipe(ialu_reg);
 9233 %}
 9234 
 9235 
 9236 // ============================================================================
 9237 //------------Bytes reverse--------------------------------------------------
 9238 
 9239 instruct bytes_reverse_int(iRegI dst, iRegI src) %{
 9240   match(Set dst (ReverseBytesI src));
 9241 
 9242   size(4);
 9243   format %{ &quot;REV32 $dst,$src&quot; %}
 9244   ins_encode %{
 9245     __ rev($dst$$Register, $src$$Register);
 9246   %}
 9247   ins_pipe( iload_mem ); // FIXME
 9248 %}
 9249 
 9250 instruct bytes_reverse_long(iRegL dst, iRegL src) %{
 9251   match(Set dst (ReverseBytesL src));
 9252   effect(TEMP dst);
 9253   size(8);
 9254   format %{ &quot;REV $dst.lo,$src.lo\n\t&quot;
 9255             &quot;REV $dst.hi,$src.hi&quot; %}
 9256   ins_encode %{
 9257     __ rev($dst$$Register, $src$$Register-&gt;successor());
 9258     __ rev($dst$$Register-&gt;successor(), $src$$Register);
 9259   %}
 9260   ins_pipe( iload_mem ); // FIXME
 9261 %}
 9262 
 9263 instruct bytes_reverse_unsigned_short(iRegI dst, iRegI src) %{
 9264   match(Set dst (ReverseBytesUS src));
 9265   size(4);
 9266   format %{ &quot;REV16 $dst,$src&quot; %}
 9267   ins_encode %{
 9268     __ rev16($dst$$Register, $src$$Register);
 9269   %}
 9270   ins_pipe( iload_mem ); // FIXME
 9271 %}
 9272 
 9273 instruct bytes_reverse_short(iRegI dst, iRegI src) %{
 9274   match(Set dst (ReverseBytesS src));
 9275   size(4);
 9276   format %{ &quot;REVSH $dst,$src&quot; %}
 9277   ins_encode %{
 9278     __ revsh($dst$$Register, $src$$Register);
 9279   %}
 9280   ins_pipe( iload_mem ); // FIXME
 9281 %}
 9282 
 9283 
 9284 // ====================VECTOR INSTRUCTIONS=====================================
 9285 
 9286 // Load Aligned Packed values into a Double Register
 9287 instruct loadV8(vecD dst, memoryD mem) %{
 9288   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
 9289   match(Set dst (LoadVector mem));
 9290   ins_cost(MEMORY_REF_COST);
 9291   size(4);
 9292   format %{ &quot;FLDD   $mem,$dst\t! load vector (8 bytes)&quot; %}
 9293   ins_encode %{
 9294     __ ldr_double($dst$$FloatRegister, $mem$$Address);
 9295   %}
 9296   ins_pipe(floadD_mem);
 9297 %}
 9298 
 9299 // Load Aligned Packed values into a Double Register Pair
 9300 instruct loadV16(vecX dst, memoryvld mem) %{
 9301   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
 9302   match(Set dst (LoadVector mem));
 9303   ins_cost(MEMORY_REF_COST);
 9304   size(4);
 9305   format %{ &quot;VLD1   $mem,$dst.Q\t! load vector (16 bytes)&quot; %}
 9306   ins_encode %{
 9307     __ vld1($dst$$FloatRegister, $mem$$Address, MacroAssembler::VELEM_SIZE_16, 128);
 9308   %}
 9309   ins_pipe(floadD_mem); // FIXME
 9310 %}
 9311 
 9312 // Store Vector in Double register to memory
 9313 instruct storeV8(memoryD mem, vecD src) %{
 9314   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
 9315   match(Set mem (StoreVector mem src));
 9316   ins_cost(MEMORY_REF_COST);
 9317   size(4);
 9318   format %{ &quot;FSTD   $src,$mem\t! store vector (8 bytes)&quot; %}
 9319   ins_encode %{
 9320     __ str_double($src$$FloatRegister, $mem$$Address);
 9321   %}
 9322   ins_pipe(fstoreD_mem_reg);
 9323 %}
 9324 
 9325 // Store Vector in Double Register Pair to memory
 9326 instruct storeV16(memoryvld mem, vecX src) %{
 9327   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
 9328   match(Set mem (StoreVector mem src));
 9329   ins_cost(MEMORY_REF_COST);
 9330   size(4);
 9331   format %{ &quot;VST1   $src,$mem\t! store vector (16 bytes)&quot; %}
 9332   ins_encode %{
 9333     __ vst1($src$$FloatRegister, $mem$$Address, MacroAssembler::VELEM_SIZE_16, 128);
 9334   %}
 9335   ins_pipe(fstoreD_mem_reg); // FIXME
 9336 %}
 9337 
 9338 // Replicate scalar to packed byte values in Double register
 9339 instruct Repl8B_reg(vecD dst, iRegI src, iRegI tmp) %{
 9340   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9341   match(Set dst (ReplicateB src));
 9342   ins_cost(DEFAULT_COST*4);
 9343   effect(TEMP tmp);
 9344   size(16);
 9345 
 9346   // FIXME: could use PKH instruction instead?
 9347   format %{ &quot;LSL      $tmp, $src, 24 \n\t&quot;
 9348             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 8) \n\t&quot;
 9349             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 16) \n\t&quot;
 9350             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9351   ins_encode %{
 9352     __ mov($tmp$$Register, AsmOperand($src$$Register, lsl, 24));
 9353     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 8));
 9354     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 16));
 9355     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9356   %}
 9357   ins_pipe(ialu_reg); // FIXME
 9358 %}
 9359 
 9360 // Replicate scalar to packed byte values in Double register
 9361 instruct Repl8B_reg_simd(vecD dst, iRegI src) %{
 9362   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9363   match(Set dst (ReplicateB src));
 9364   size(4);
 9365 
 9366   format %{ &quot;VDUP.8 $dst,$src\t&quot; %}
 9367   ins_encode %{
 9368     bool quad = false;
 9369     __ vdupI($dst$$FloatRegister, $src$$Register,
 9370              MacroAssembler::VELEM_SIZE_8, quad);
 9371   %}
 9372   ins_pipe(ialu_reg); // FIXME
 9373 %}
 9374 
 9375 // Replicate scalar to packed byte values in Double register pair
 9376 instruct Repl16B_reg(vecX dst, iRegI src) %{
 9377   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
 9378   match(Set dst (ReplicateB src));
 9379   size(4);
 9380 
 9381   format %{ &quot;VDUP.8 $dst.Q,$src\t&quot; %}
 9382   ins_encode %{
 9383     bool quad = true;
 9384     __ vdupI($dst$$FloatRegister, $src$$Register,
 9385              MacroAssembler::VELEM_SIZE_8, quad);
 9386   %}
 9387   ins_pipe(ialu_reg); // FIXME
 9388 %}
 9389 
 9390 // Replicate scalar constant to packed byte values in Double register
 9391 instruct Repl8B_immI(vecD dst, immI src, iRegI tmp) %{
 9392   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9393   match(Set dst (ReplicateB src));
 9394   ins_cost(DEFAULT_COST*2);
 9395   effect(TEMP tmp);
 9396   size(12);
 9397 
 9398   format %{ &quot;MOV      $tmp, Repl4($src))\n\t&quot;
 9399             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9400   ins_encode( LdReplImmI(src, dst, tmp, (4), (1)) );
 9401   ins_pipe(loadConFD); // FIXME
 9402 %}
 9403 
 9404 // Replicate scalar constant to packed byte values in Double register
 9405 // TODO: support negative constants with MVNI?
 9406 instruct Repl8B_immU8(vecD dst, immU8 src) %{
 9407   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9408   match(Set dst (ReplicateB src));
 9409   size(4);
 9410 
 9411   format %{ &quot;VMOV.U8  $dst,$src&quot; %}
 9412   ins_encode %{
 9413     bool quad = false;
 9414     __ vmovI($dst$$FloatRegister, $src$$constant,
 9415              MacroAssembler::VELEM_SIZE_8, quad);
 9416   %}
 9417   ins_pipe(loadConFD); // FIXME
 9418 %}
 9419 
 9420 // Replicate scalar constant to packed byte values in Double register pair
 9421 instruct Repl16B_immU8(vecX dst, immU8 src) %{
 9422   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9423   match(Set dst (ReplicateB src));
 9424   size(4);
 9425 
 9426   format %{ &quot;VMOV.U8  $dst.Q,$src&quot; %}
 9427   ins_encode %{
 9428     bool quad = true;
 9429     __ vmovI($dst$$FloatRegister, $src$$constant,
 9430              MacroAssembler::VELEM_SIZE_8, quad);
 9431   %}
 9432   ins_pipe(loadConFD); // FIXME
 9433 %}
 9434 
 9435 // Replicate scalar to packed short/char values into Double register
 9436 instruct Repl4S_reg(vecD dst, iRegI src, iRegI tmp) %{
 9437   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9438   match(Set dst (ReplicateS src));
 9439   ins_cost(DEFAULT_COST*3);
 9440   effect(TEMP tmp);
 9441   size(12);
 9442 
 9443   // FIXME: could use PKH instruction instead?
 9444   format %{ &quot;LSL      $tmp, $src, 16 \n\t&quot;
 9445             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 16) \n\t&quot;
 9446             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9447   ins_encode %{
 9448     __ mov($tmp$$Register, AsmOperand($src$$Register, lsl, 16));
 9449     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 16));
 9450     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9451   %}
 9452   ins_pipe(ialu_reg); // FIXME
 9453 %}
 9454 
 9455 // Replicate scalar to packed byte values in Double register
 9456 instruct Repl4S_reg_simd(vecD dst, iRegI src) %{
 9457   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9458   match(Set dst (ReplicateS src));
 9459   size(4);
 9460 
 9461   format %{ &quot;VDUP.16 $dst,$src\t&quot; %}
 9462   ins_encode %{
 9463     bool quad = false;
 9464     __ vdupI($dst$$FloatRegister, $src$$Register,
 9465              MacroAssembler::VELEM_SIZE_16, quad);
 9466   %}
 9467   ins_pipe(ialu_reg); // FIXME
 9468 %}
 9469 
 9470 // Replicate scalar to packed byte values in Double register pair
 9471 instruct Repl8S_reg(vecX dst, iRegI src) %{
 9472   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9473   match(Set dst (ReplicateS src));
 9474   size(4);
 9475 
 9476   format %{ &quot;VDUP.16 $dst.Q,$src\t&quot; %}
 9477   ins_encode %{
 9478     bool quad = true;
 9479     __ vdupI($dst$$FloatRegister, $src$$Register,
 9480              MacroAssembler::VELEM_SIZE_16, quad);
 9481   %}
 9482   ins_pipe(ialu_reg); // FIXME
 9483 %}
 9484 
 9485 
 9486 // Replicate scalar constant to packed short/char values in Double register
 9487 instruct Repl4S_immI(vecD dst, immI src, iRegP tmp) %{
 9488   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9489   match(Set dst (ReplicateS src));
 9490   effect(TEMP tmp);
 9491   size(12);
 9492   ins_cost(DEFAULT_COST*4); // FIXME
 9493 
 9494   format %{ &quot;MOV      $tmp, Repl2($src))\n\t&quot;
 9495             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9496   ins_encode( LdReplImmI(src, dst, tmp, (2), (2)) );
 9497   ins_pipe(loadConFD); // FIXME
 9498 %}
 9499 
 9500 // Replicate scalar constant to packed byte values in Double register
 9501 instruct Repl4S_immU8(vecD dst, immU8 src) %{
 9502   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9503   match(Set dst (ReplicateS src));
 9504   size(4);
 9505 
 9506   format %{ &quot;VMOV.U16  $dst,$src&quot; %}
 9507   ins_encode %{
 9508     bool quad = false;
 9509     __ vmovI($dst$$FloatRegister, $src$$constant,
 9510              MacroAssembler::VELEM_SIZE_16, quad);
 9511   %}
 9512   ins_pipe(loadConFD); // FIXME
 9513 %}
 9514 
 9515 // Replicate scalar constant to packed byte values in Double register pair
 9516 instruct Repl8S_immU8(vecX dst, immU8 src) %{
 9517   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9518   match(Set dst (ReplicateS src));
 9519   size(4);
 9520 
 9521   format %{ &quot;VMOV.U16  $dst.Q,$src&quot; %}
 9522   ins_encode %{
 9523     bool quad = true;
 9524     __ vmovI($dst$$FloatRegister, $src$$constant,
 9525              MacroAssembler::VELEM_SIZE_16, quad);
 9526   %}
 9527   ins_pipe(loadConFD); // FIXME
 9528 %}
 9529 
 9530 // Replicate scalar to packed int values in Double register
 9531 instruct Repl2I_reg(vecD dst, iRegI src) %{
 9532   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9533   match(Set dst (ReplicateI src));
 9534   size(4);
 9535 
 9536   format %{ &quot;FMDRR    $dst,$src,$src\t&quot; %}
 9537   ins_encode %{
 9538     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9539   %}
 9540   ins_pipe(ialu_reg); // FIXME
 9541 %}
 9542 
 9543 // Replicate scalar to packed int values in Double register pair
 9544 instruct Repl4I_reg(vecX dst, iRegI src) %{
 9545   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9546   match(Set dst (ReplicateI src));
 9547   ins_cost(DEFAULT_COST*2);
 9548   size(8);
 9549 
 9550   format %{ &quot;FMDRR    $dst.lo,$src,$src\n\t&quot;
 9551             &quot;FMDRR    $dst.hi,$src,$src&quot; %}
 9552 
 9553   ins_encode %{
 9554     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9555     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9556              $src$$Register, $src$$Register);
 9557   %}
 9558   ins_pipe(ialu_reg); // FIXME
 9559 %}
 9560 
 9561 // Replicate scalar to packed int values in Double register
 9562 instruct Repl2I_reg_simd(vecD dst, iRegI src) %{
 9563   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9564   match(Set dst (ReplicateI src));
 9565   size(4);
 9566 
 9567   format %{ &quot;VDUP.32 $dst.D,$src\t&quot; %}
 9568   ins_encode %{
 9569     bool quad = false;
 9570     __ vdupI($dst$$FloatRegister, $src$$Register,
 9571              MacroAssembler::VELEM_SIZE_32, quad);
 9572   %}
 9573   ins_pipe(ialu_reg); // FIXME
 9574 %}
 9575 
 9576 // Replicate scalar to packed int values in Double register pair
 9577 instruct Repl4I_reg_simd(vecX dst, iRegI src) %{
 9578   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9579   match(Set dst (ReplicateI src));
 9580   size(4);
 9581 
 9582   format %{ &quot;VDUP.32 $dst.Q,$src\t&quot; %}
 9583   ins_encode %{
 9584     bool quad = true;
 9585     __ vdupI($dst$$FloatRegister, $src$$Register,
 9586              MacroAssembler::VELEM_SIZE_32, quad);
 9587   %}
 9588   ins_pipe(ialu_reg); // FIXME
 9589 %}
 9590 
 9591 
 9592 // Replicate scalar zero constant to packed int values in Double register
 9593 instruct Repl2I_immI(vecD dst, immI src, iRegI tmp) %{
 9594   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9595   match(Set dst (ReplicateI src));
 9596   effect(TEMP tmp);
 9597   size(12);
 9598   ins_cost(DEFAULT_COST*4); // FIXME
 9599 
 9600   format %{ &quot;MOV      $tmp, Repl1($src))\n\t&quot;
 9601             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9602   ins_encode( LdReplImmI(src, dst, tmp, (1), (4)) );
 9603   ins_pipe(loadConFD); // FIXME
 9604 %}
 9605 
 9606 // Replicate scalar constant to packed byte values in Double register
 9607 instruct Repl2I_immU8(vecD dst, immU8 src) %{
 9608   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9609   match(Set dst (ReplicateI src));
 9610   size(4);
 9611 
 9612   format %{ &quot;VMOV.I32  $dst.D,$src&quot; %}
 9613   ins_encode %{
 9614     bool quad = false;
 9615     __ vmovI($dst$$FloatRegister, $src$$constant,
 9616              MacroAssembler::VELEM_SIZE_32, quad);
 9617   %}
 9618   ins_pipe(loadConFD); // FIXME
 9619 %}
 9620 
 9621 // Replicate scalar constant to packed byte values in Double register pair
 9622 instruct Repl4I_immU8(vecX dst, immU8 src) %{
 9623   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9624   match(Set dst (ReplicateI src));
 9625   size(4);
 9626 
 9627   format %{ &quot;VMOV.I32  $dst.Q,$src&quot; %}
 9628   ins_encode %{
 9629     bool quad = true;
 9630     __ vmovI($dst$$FloatRegister, $src$$constant,
 9631              MacroAssembler::VELEM_SIZE_32, quad);
 9632   %}
 9633   ins_pipe(loadConFD); // FIXME
 9634 %}
 9635 
 9636 // Replicate scalar to packed byte values in Double register pair
 9637 instruct Repl2L_reg(vecX dst, iRegL src) %{
 9638   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9639   match(Set dst (ReplicateL src));
 9640   size(8);
 9641   ins_cost(DEFAULT_COST*2); // FIXME
 9642 
 9643   format %{ &quot;FMDRR $dst.D,$src.lo,$src.hi\t\n&quot;
 9644             &quot;FMDRR $dst.D.next,$src.lo,$src.hi&quot; %}
 9645   ins_encode %{
 9646     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 9647     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9648              $src$$Register, $src$$Register-&gt;successor());
 9649   %}
 9650   ins_pipe(ialu_reg); // FIXME
 9651 %}
 9652 
 9653 
 9654 // Replicate scalar to packed float values in Double register
 9655 instruct Repl2F_regI(vecD dst, iRegI src) %{
 9656   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9657   match(Set dst (ReplicateF src));
 9658   size(4);
 9659 
 9660   format %{ &quot;FMDRR    $dst.D,$src,$src\t&quot; %}
 9661   ins_encode %{
 9662     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9663   %}
 9664   ins_pipe(ialu_reg); // FIXME
 9665 %}
 9666 
 9667 // Replicate scalar to packed float values in Double register
 9668 instruct Repl2F_reg_vfp(vecD dst, regF src) %{
 9669   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9670   match(Set dst (ReplicateF src));
 9671   size(4*2);
 9672   ins_cost(DEFAULT_COST*2); // FIXME
 9673 
 9674   expand %{
 9675     iRegI tmp;
 9676     MoveF2I_reg_reg(tmp, src);
 9677     Repl2F_regI(dst,tmp);
 9678   %}
 9679 %}
 9680 
 9681 // Replicate scalar to packed float values in Double register
 9682 instruct Repl2F_reg_simd(vecD dst, regF src) %{
 9683   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9684   match(Set dst (ReplicateF src));
 9685   size(4);
 9686   ins_cost(DEFAULT_COST); // FIXME
 9687 
 9688   format %{ &quot;VDUP.32  $dst.D,$src.D\t&quot; %}
 9689   ins_encode %{
 9690     bool quad = false;
 9691     __ vdupF($dst$$FloatRegister, $src$$FloatRegister, quad);
 9692   %}
 9693   ins_pipe(ialu_reg); // FIXME
 9694 %}
 9695 
 9696 // Replicate scalar to packed float values in Double register pair
 9697 instruct Repl4F_reg(vecX dst, regF src, iRegI tmp) %{
 9698   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9699   match(Set dst (ReplicateF src));
 9700   effect(TEMP tmp);
 9701   size(4*3);
 9702   ins_cost(DEFAULT_COST*3); // FIXME
 9703 
 9704   format %{ &quot;FMRS     $tmp,$src\n\t&quot;
 9705             &quot;FMDRR    $dst.D,$tmp,$tmp\n\t&quot;
 9706             &quot;FMDRR    $dst.D.next,$tmp,$tmp\t&quot; %}
 9707   ins_encode %{
 9708     __ fmrs($tmp$$Register, $src$$FloatRegister);
 9709     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9710     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9711              $tmp$$Register, $tmp$$Register);
 9712   %}
 9713   ins_pipe(ialu_reg); // FIXME
 9714 %}
 9715 
 9716 // Replicate scalar to packed float values in Double register pair
 9717 instruct Repl4F_reg_simd(vecX dst, regF src) %{
 9718   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9719   match(Set dst (ReplicateF src));
 9720   size(4);
 9721   ins_cost(DEFAULT_COST); // FIXME
 9722 
 9723   format %{ &quot;VDUP.32  $dst.Q,$src.D\t&quot; %}
 9724   ins_encode %{
 9725     bool quad = true;
 9726     __ vdupF($dst$$FloatRegister, $src$$FloatRegister, quad);
 9727   %}
 9728   ins_pipe(ialu_reg); // FIXME
 9729 %}
 9730 
 9731 // Replicate scalar zero constant to packed float values in Double register
 9732 instruct Repl2F_immI(vecD dst, immF src, iRegI tmp) %{
 9733   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9734   match(Set dst (ReplicateF src));
 9735   effect(TEMP tmp);
 9736   size(12);
 9737   ins_cost(DEFAULT_COST*4); // FIXME
 9738 
 9739   format %{ &quot;MOV      $tmp, Repl1($src))\n\t&quot;
 9740             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9741   ins_encode( LdReplImmF(src, dst, tmp) );
 9742   ins_pipe(loadConFD); // FIXME
 9743 %}
 9744 
 9745 // Replicate scalar to packed double float values in Double register pair
 9746 instruct Repl2D_reg(vecX dst, regD src) %{
 9747   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9748   match(Set dst (ReplicateD src));
 9749   size(4*2);
 9750   ins_cost(DEFAULT_COST*2); // FIXME
 9751 
 9752   format %{ &quot;FCPYD    $dst.D.a,$src\n\t&quot;
 9753             &quot;FCPYD    $dst.D.b,$src\t&quot; %}
 9754   ins_encode %{
 9755     FloatRegister dsta = $dst$$FloatRegister;
 9756     FloatRegister src = $src$$FloatRegister;
 9757     __ fcpyd(dsta, src);
 9758     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
 9759     __ fcpyd(dstb, src);
 9760   %}
 9761   ins_pipe(ialu_reg); // FIXME
 9762 %}
 9763 
 9764 // ====================VECTOR ARITHMETIC=======================================
 9765 
 9766 // --------------------------------- ADD --------------------------------------
 9767 
 9768 // Bytes vector add
 9769 instruct vadd8B_reg(vecD dst, vecD src1, vecD src2) %{
 9770   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9771   match(Set dst (AddVB src1 src2));
 9772   format %{ &quot;VADD.I8 $dst,$src1,$src2\t! add packed8B&quot; %}
 9773   size(4);
 9774   ins_encode %{
 9775     bool quad = false;
 9776     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9777              MacroAssembler::VELEM_SIZE_8, quad);
 9778   %}
 9779   ins_pipe( ialu_reg_reg ); // FIXME
 9780 %}
 9781 
 9782 instruct vadd16B_reg(vecX dst, vecX src1, vecX src2) %{
 9783   predicate(n-&gt;as_Vector()-&gt;length() == 16);
 9784   match(Set dst (AddVB src1 src2));
 9785   size(4);
 9786   format %{ &quot;VADD.I8 $dst.Q,$src1.Q,$src2.Q\t! add packed16B&quot; %}
 9787   ins_encode %{
 9788     bool quad = true;
 9789     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9790              MacroAssembler::VELEM_SIZE_8, quad);
 9791   %}
 9792   ins_pipe( ialu_reg_reg ); // FIXME
 9793 %}
 9794 
 9795 // Shorts/Chars vector add
 9796 instruct vadd4S_reg(vecD dst, vecD src1, vecD src2) %{
 9797   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9798   match(Set dst (AddVS src1 src2));
 9799   size(4);
 9800   format %{ &quot;VADD.I16 $dst,$src1,$src2\t! add packed4S&quot; %}
 9801   ins_encode %{
 9802     bool quad = false;
 9803     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9804              MacroAssembler::VELEM_SIZE_16, quad);
 9805   %}
 9806   ins_pipe( ialu_reg_reg ); // FIXME
 9807 %}
 9808 
 9809 instruct vadd8S_reg(vecX dst, vecX src1, vecX src2) %{
 9810   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9811   match(Set dst (AddVS src1 src2));
 9812   size(4);
 9813   format %{ &quot;VADD.I16 $dst.Q,$src1.Q,$src2.Q\t! add packed8S&quot; %}
 9814   ins_encode %{
 9815     bool quad = true;
 9816     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9817              MacroAssembler::VELEM_SIZE_16, quad);
 9818   %}
 9819   ins_pipe( ialu_reg_reg ); // FIXME
 9820 %}
 9821 
 9822 // Integers vector add
 9823 instruct vadd2I_reg(vecD dst, vecD src1, vecD src2) %{
 9824   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9825   match(Set dst (AddVI src1 src2));
 9826   size(4);
 9827   format %{ &quot;VADD.I32 $dst.D,$src1.D,$src2.D\t! add packed2I&quot; %}
 9828   ins_encode %{
 9829     bool quad = false;
 9830     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9831              MacroAssembler::VELEM_SIZE_32, quad);
 9832   %}
 9833   ins_pipe( ialu_reg_reg ); // FIXME
 9834 %}
 9835 
 9836 instruct vadd4I_reg(vecX dst, vecX src1, vecX src2) %{
 9837   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9838   match(Set dst (AddVI src1 src2));
 9839   size(4);
 9840   format %{ &quot;VADD.I32 $dst.Q,$src1.Q,$src2.Q\t! add packed4I&quot; %}
 9841   ins_encode %{
 9842     bool quad = true;
 9843     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9844              MacroAssembler::VELEM_SIZE_32, quad);
 9845   %}
 9846   ins_pipe( ialu_reg_reg ); // FIXME
 9847 %}
 9848 
 9849 // Longs vector add
 9850 instruct vadd2L_reg(vecX dst, vecX src1, vecX src2) %{
 9851   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9852   match(Set dst (AddVL src1 src2));
 9853   size(4);
 9854   format %{ &quot;VADD.I64 $dst.Q,$src1.Q,$src2.Q\t! add packed2L&quot; %}
 9855   ins_encode %{
 9856     bool quad = true;
 9857     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9858              MacroAssembler::VELEM_SIZE_64, quad);
 9859   %}
 9860   ins_pipe( ialu_reg_reg ); // FIXME
 9861 %}
 9862 
 9863 // Floats vector add
 9864 instruct vadd2F_reg(vecD dst, vecD src1, vecD src2) %{
 9865   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
 9866   match(Set dst (AddVF src1 src2));
 9867   size(4);
 9868   format %{ &quot;VADD.F32 $dst,$src1,$src2\t! add packed2F&quot; %}
 9869   ins_encode %{
 9870     bool quad = false;
 9871     __ vaddF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9872              MacroAssembler::VFA_SIZE_F32, quad);
 9873   %}
 9874   ins_pipe( faddD_reg_reg ); // FIXME
 9875 %}
 9876 
 9877 instruct vadd2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
 9878   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
 9879   match(Set dst (AddVF src1 src2));
 9880   ins_cost(DEFAULT_COST*2); // FIXME
 9881 
 9882   size(4*2);
 9883   format %{ &quot;FADDS  $dst.a,$src1.a,$src2.a\n\t&quot;
 9884             &quot;FADDS  $dst.b,$src1.b,$src2.b&quot; %}
 9885   ins_encode %{
 9886     __ add_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 9887     __ add_float($dst$$FloatRegister-&gt;successor(),
 9888              $src1$$FloatRegister-&gt;successor(),
 9889              $src2$$FloatRegister-&gt;successor());
 9890   %}
 9891 
 9892   ins_pipe(faddF_reg_reg); // FIXME
 9893 %}
 9894 
 9895 instruct vadd4F_reg_simd(vecX dst, vecX src1, vecX src2) %{
 9896   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
 9897   match(Set dst (AddVF src1 src2));
 9898   size(4);
 9899   format %{ &quot;VADD.F32 $dst.Q,$src1.Q,$src2.Q\t! add packed4F&quot; %}
 9900   ins_encode %{
 9901     bool quad = true;
 9902     __ vaddF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9903              MacroAssembler::VFA_SIZE_F32, quad);
 9904   %}
 9905   ins_pipe( faddD_reg_reg ); // FIXME
 9906 %}
 9907 
 9908 instruct vadd4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
 9909   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
 9910   match(Set dst (AddVF src1 src2));
 9911   size(4*4);
 9912   ins_cost(DEFAULT_COST*4); // FIXME
 9913 
 9914   format %{ &quot;FADDS  $dst.a,$src1.a,$src2.a\n\t&quot;
 9915             &quot;FADDS  $dst.b,$src1.b,$src2.b\n\t&quot;
 9916             &quot;FADDS  $dst.c,$src1.c,$src2.c\n\t&quot;
 9917             &quot;FADDS  $dst.d,$src1.d,$src2.d&quot; %}
 9918 
 9919   ins_encode %{
 9920     FloatRegister dsta = $dst$$FloatRegister;
 9921     FloatRegister src1a = $src1$$FloatRegister;
 9922     FloatRegister src2a = $src2$$FloatRegister;
 9923     __ add_float(dsta, src1a, src2a);
 9924     FloatRegister dstb = dsta-&gt;successor();
 9925     FloatRegister src1b = src1a-&gt;successor();
 9926     FloatRegister src2b = src2a-&gt;successor();
 9927     __ add_float(dstb, src1b, src2b);
 9928     FloatRegister dstc = dstb-&gt;successor();
 9929     FloatRegister src1c = src1b-&gt;successor();
 9930     FloatRegister src2c = src2b-&gt;successor();
 9931     __ add_float(dstc, src1c, src2c);
 9932     FloatRegister dstd = dstc-&gt;successor();
 9933     FloatRegister src1d = src1c-&gt;successor();
 9934     FloatRegister src2d = src2c-&gt;successor();
 9935     __ add_float(dstd, src1d, src2d);
 9936   %}
 9937 
 9938   ins_pipe(faddF_reg_reg); // FIXME
 9939 %}
 9940 
 9941 instruct vadd2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
 9942   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9943   match(Set dst (AddVD src1 src2));
 9944   size(4*2);
 9945   ins_cost(DEFAULT_COST*2); // FIXME
 9946 
 9947   format %{ &quot;FADDD  $dst.a,$src1.a,$src2.a\n\t&quot;
 9948             &quot;FADDD  $dst.b,$src1.b,$src2.b&quot; %}
 9949 
 9950   ins_encode %{
 9951     FloatRegister dsta = $dst$$FloatRegister;
 9952     FloatRegister src1a = $src1$$FloatRegister;
 9953     FloatRegister src2a = $src2$$FloatRegister;
 9954     __ add_double(dsta, src1a, src2a);
 9955     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
 9956     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
 9957     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
 9958     __ add_double(dstb, src1b, src2b);
 9959   %}
 9960 
 9961   ins_pipe(faddF_reg_reg); // FIXME
 9962 %}
 9963 
 9964 
 9965 // Bytes vector sub
 9966 instruct vsub8B_reg(vecD dst, vecD src1, vecD src2) %{
 9967   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9968   match(Set dst (SubVB src1 src2));
 9969   size(4);
 9970   format %{ &quot;VSUB.I8 $dst,$src1,$src2\t! sub packed8B&quot; %}
 9971   ins_encode %{
 9972     bool quad = false;
 9973     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9974              MacroAssembler::VELEM_SIZE_8, quad);
 9975   %}
 9976   ins_pipe( ialu_reg_reg ); // FIXME
 9977 %}
 9978 
 9979 instruct vsub16B_reg(vecX dst, vecX src1, vecX src2) %{
 9980   predicate(n-&gt;as_Vector()-&gt;length() == 16);
 9981   match(Set dst (SubVB src1 src2));
 9982   size(4);
 9983   format %{ &quot;VSUB.I8 $dst.Q,$src1.Q,$src2.Q\t! sub packed16B&quot; %}
 9984   ins_encode %{
 9985     bool quad = true;
 9986     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9987              MacroAssembler::VELEM_SIZE_8, quad);
 9988   %}
 9989   ins_pipe( ialu_reg_reg ); // FIXME
 9990 %}
 9991 
 9992 // Shorts/Chars vector sub
 9993 instruct vsub4S_reg(vecD dst, vecD src1, vecD src2) %{
 9994   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9995   match(Set dst (SubVS src1 src2));
 9996   size(4);
 9997   format %{ &quot;VSUB.I16 $dst,$src1,$src2\t! sub packed4S&quot; %}
 9998   ins_encode %{
 9999     bool quad = false;
10000     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10001              MacroAssembler::VELEM_SIZE_16, quad);
10002   %}
10003   ins_pipe( ialu_reg_reg ); // FIXME
10004 %}
10005 
10006 instruct vsub16S_reg(vecX dst, vecX src1, vecX src2) %{
10007   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10008   match(Set dst (SubVS src1 src2));
10009   size(4);
10010   format %{ &quot;VSUB.I16 $dst.Q,$src1.Q,$src2.Q\t! sub packed8S&quot; %}
10011   ins_encode %{
10012     bool quad = true;
10013     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10014              MacroAssembler::VELEM_SIZE_16, quad);
10015   %}
10016   ins_pipe( ialu_reg_reg ); // FIXME
10017 %}
10018 
10019 // Integers vector sub
10020 instruct vsub2I_reg(vecD dst, vecD src1, vecD src2) %{
10021   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10022   match(Set dst (SubVI src1 src2));
10023   size(4);
10024   format %{ &quot;VSUB.I32 $dst,$src1,$src2\t! sub packed2I&quot; %}
10025   ins_encode %{
10026     bool quad = false;
10027     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10028              MacroAssembler::VELEM_SIZE_32, quad);
10029   %}
10030   ins_pipe( ialu_reg_reg ); // FIXME
10031 %}
10032 
10033 instruct vsub4I_reg(vecX dst, vecX src1, vecX src2) %{
10034   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10035   match(Set dst (SubVI src1 src2));
10036   size(4);
10037   format %{ &quot;VSUB.I32 $dst.Q,$src1.Q,$src2.Q\t! sub packed4I&quot; %}
10038   ins_encode %{
10039     bool quad = true;
10040     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10041              MacroAssembler::VELEM_SIZE_32, quad);
10042   %}
10043   ins_pipe( ialu_reg_reg ); // FIXME
10044 %}
10045 
10046 // Longs vector sub
10047 instruct vsub2L_reg(vecX dst, vecX src1, vecX src2) %{
10048   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10049   match(Set dst (SubVL src1 src2));
10050   size(4);
10051   format %{ &quot;VSUB.I64 $dst.Q,$src1.Q,$src2.Q\t! sub packed2L&quot; %}
10052   ins_encode %{
10053     bool quad = true;
10054     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10055              MacroAssembler::VELEM_SIZE_64, quad);
10056   %}
10057   ins_pipe( ialu_reg_reg ); // FIXME
10058 %}
10059 
10060 // Floats vector sub
10061 instruct vsub2F_reg(vecD dst, vecD src1, vecD src2) %{
10062   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
10063   match(Set dst (SubVF src1 src2));
10064   size(4);
10065   format %{ &quot;VSUB.F32 $dst,$src1,$src2\t! sub packed2F&quot; %}
10066   ins_encode %{
10067     bool quad = false;
10068     __ vsubF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10069              MacroAssembler::VFA_SIZE_F32, quad);
10070   %}
10071   ins_pipe( faddF_reg_reg ); // FIXME
10072 %}
10073 
10074 instruct vsub2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10075   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
10076   match(Set dst (SubVF src1 src2));
10077   size(4*2);
10078   ins_cost(DEFAULT_COST*2); // FIXME
10079 
10080   format %{ &quot;FSUBS  $dst.a,$src1.a,$src2.a\n\t&quot;
10081             &quot;FSUBS  $dst.b,$src1.b,$src2.b&quot; %}
10082 
10083   ins_encode %{
10084     FloatRegister dsta = $dst$$FloatRegister;
10085     FloatRegister src1a = $src1$$FloatRegister;
10086     FloatRegister src2a = $src2$$FloatRegister;
10087     __ sub_float(dsta, src1a, src2a);
10088     FloatRegister dstb = dsta-&gt;successor();
10089     FloatRegister src1b = src1a-&gt;successor();
10090     FloatRegister src2b = src2a-&gt;successor();
10091     __ sub_float(dstb, src1b, src2b);
10092   %}
10093 
10094   ins_pipe(faddF_reg_reg); // FIXME
10095 %}
10096 
10097 
10098 instruct vsub4F_reg(vecX dst, vecX src1, vecX src2) %{
10099   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
10100   match(Set dst (SubVF src1 src2));
10101   size(4);
10102   format %{ &quot;VSUB.F32 $dst.Q,$src1.Q,$src2.Q\t! sub packed4F&quot; %}
10103   ins_encode %{
10104     bool quad = true;
10105     __ vsubF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10106              MacroAssembler::VFA_SIZE_F32, quad);
10107   %}
10108   ins_pipe( faddF_reg_reg ); // FIXME
10109 %}
10110 
10111 instruct vsub4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10112   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
10113   match(Set dst (SubVF src1 src2));
10114   size(4*4);
10115   ins_cost(DEFAULT_COST*4); // FIXME
10116 
10117   format %{ &quot;FSUBS  $dst.a,$src1.a,$src2.a\n\t&quot;
10118             &quot;FSUBS  $dst.b,$src1.b,$src2.b\n\t&quot;
10119             &quot;FSUBS  $dst.c,$src1.c,$src2.c\n\t&quot;
10120             &quot;FSUBS  $dst.d,$src1.d,$src2.d&quot; %}
10121 
10122   ins_encode %{
10123     FloatRegister dsta = $dst$$FloatRegister;
10124     FloatRegister src1a = $src1$$FloatRegister;
10125     FloatRegister src2a = $src2$$FloatRegister;
10126     __ sub_float(dsta, src1a, src2a);
10127     FloatRegister dstb = dsta-&gt;successor();
10128     FloatRegister src1b = src1a-&gt;successor();
10129     FloatRegister src2b = src2a-&gt;successor();
10130     __ sub_float(dstb, src1b, src2b);
10131     FloatRegister dstc = dstb-&gt;successor();
10132     FloatRegister src1c = src1b-&gt;successor();
10133     FloatRegister src2c = src2b-&gt;successor();
10134     __ sub_float(dstc, src1c, src2c);
10135     FloatRegister dstd = dstc-&gt;successor();
10136     FloatRegister src1d = src1c-&gt;successor();
10137     FloatRegister src2d = src2c-&gt;successor();
10138     __ sub_float(dstd, src1d, src2d);
10139   %}
10140 
10141   ins_pipe(faddF_reg_reg); // FIXME
10142 %}
10143 
10144 instruct vsub2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10145   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10146   match(Set dst (SubVD src1 src2));
10147   size(4*2);
10148   ins_cost(DEFAULT_COST*2); // FIXME
10149 
10150   format %{ &quot;FSUBD  $dst.a,$src1.a,$src2.a\n\t&quot;
10151             &quot;FSUBD  $dst.b,$src1.b,$src2.b&quot; %}
10152 
10153   ins_encode %{
10154     FloatRegister dsta = $dst$$FloatRegister;
10155     FloatRegister src1a = $src1$$FloatRegister;
10156     FloatRegister src2a = $src2$$FloatRegister;
10157     __ sub_double(dsta, src1a, src2a);
10158     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10159     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10160     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10161     __ sub_double(dstb, src1b, src2b);
10162   %}
10163 
10164   ins_pipe(faddF_reg_reg); // FIXME
10165 %}
10166 
10167 // Shorts/Chars vector mul
10168 instruct vmul4S_reg(vecD dst, vecD src1, vecD src2) %{
10169   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10170   match(Set dst (MulVS src1 src2));
10171   size(4);
10172   format %{ &quot;VMUL.I16 $dst,$src1,$src2\t! mul packed4S&quot; %}
10173   ins_encode %{
10174     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10175              MacroAssembler::VELEM_SIZE_16, 0);
10176   %}
10177   ins_pipe( ialu_reg_reg ); // FIXME
10178 %}
10179 
10180 instruct vmul8S_reg(vecX dst, vecX src1, vecX src2) %{
10181   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10182   match(Set dst (MulVS src1 src2));
10183   size(4);
10184   format %{ &quot;VMUL.I16 $dst.Q,$src1.Q,$src2.Q\t! mul packed8S&quot; %}
10185   ins_encode %{
10186     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10187              MacroAssembler::VELEM_SIZE_16, 1);
10188   %}
10189   ins_pipe( ialu_reg_reg ); // FIXME
10190 %}
10191 
10192 // Integers vector mul
10193 instruct vmul2I_reg(vecD dst, vecD src1, vecD src2) %{
10194   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10195   match(Set dst (MulVI src1 src2));
10196   size(4);
10197   format %{ &quot;VMUL.I32 $dst,$src1,$src2\t! mul packed2I&quot; %}
10198   ins_encode %{
10199     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10200              MacroAssembler::VELEM_SIZE_32, 0);
10201   %}
10202   ins_pipe( ialu_reg_reg ); // FIXME
10203 %}
10204 
10205 instruct vmul4I_reg(vecX dst, vecX src1, vecX src2) %{
10206   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10207   match(Set dst (MulVI src1 src2));
10208   size(4);
10209   format %{ &quot;VMUL.I32 $dst.Q,$src1.Q,$src2.Q\t! mul packed4I&quot; %}
10210   ins_encode %{
10211     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10212              MacroAssembler::VELEM_SIZE_32, 1);
10213   %}
10214   ins_pipe( ialu_reg_reg ); // FIXME
10215 %}
10216 
10217 // Floats vector mul
10218 instruct vmul2F_reg(vecD dst, vecD src1, vecD src2) %{
10219   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
10220   match(Set dst (MulVF src1 src2));
10221   size(4);
10222   format %{ &quot;VMUL.F32 $dst,$src1,$src2\t! mul packed2F&quot; %}
10223   ins_encode %{
10224     __ vmulF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10225              MacroAssembler::VFA_SIZE_F32, 0);
10226   %}
10227   ins_pipe( fmulF_reg_reg ); // FIXME
10228 %}
10229 
10230 instruct vmul2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10231   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
10232   match(Set dst (MulVF src1 src2));
10233   size(4*2);
10234   ins_cost(DEFAULT_COST*2); // FIXME
10235 
10236   format %{ &quot;FMULS  $dst.a,$src1.a,$src2.a\n\t&quot;
10237             &quot;FMULS  $dst.b,$src1.b,$src2.b&quot; %}
10238   ins_encode %{
10239     __ mul_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
10240     __ mul_float($dst$$FloatRegister-&gt;successor(),
10241              $src1$$FloatRegister-&gt;successor(),
10242              $src2$$FloatRegister-&gt;successor());
10243   %}
10244 
10245   ins_pipe(fmulF_reg_reg); // FIXME
10246 %}
10247 
10248 instruct vmul4F_reg(vecX dst, vecX src1, vecX src2) %{
10249   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
10250   match(Set dst (MulVF src1 src2));
10251   size(4);
10252   format %{ &quot;VMUL.F32 $dst.Q,$src1.Q,$src2.Q\t! mul packed4F&quot; %}
10253   ins_encode %{
10254     __ vmulF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10255              MacroAssembler::VFA_SIZE_F32, 1);
10256   %}
10257   ins_pipe( fmulF_reg_reg ); // FIXME
10258 %}
10259 
10260 instruct vmul4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10261   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
10262   match(Set dst (MulVF src1 src2));
10263   size(4*4);
10264   ins_cost(DEFAULT_COST*4); // FIXME
10265 
10266   format %{ &quot;FMULS  $dst.a,$src1.a,$src2.a\n\t&quot;
10267             &quot;FMULS  $dst.b,$src1.b,$src2.b\n\t&quot;
10268             &quot;FMULS  $dst.c,$src1.c,$src2.c\n\t&quot;
10269             &quot;FMULS  $dst.d,$src1.d,$src2.d&quot; %}
10270 
10271   ins_encode %{
10272     FloatRegister dsta = $dst$$FloatRegister;
10273     FloatRegister src1a = $src1$$FloatRegister;
10274     FloatRegister src2a = $src2$$FloatRegister;
10275     __ mul_float(dsta, src1a, src2a);
10276     FloatRegister dstb = dsta-&gt;successor();
10277     FloatRegister src1b = src1a-&gt;successor();
10278     FloatRegister src2b = src2a-&gt;successor();
10279     __ mul_float(dstb, src1b, src2b);
10280     FloatRegister dstc = dstb-&gt;successor();
10281     FloatRegister src1c = src1b-&gt;successor();
10282     FloatRegister src2c = src2b-&gt;successor();
10283     __ mul_float(dstc, src1c, src2c);
10284     FloatRegister dstd = dstc-&gt;successor();
10285     FloatRegister src1d = src1c-&gt;successor();
10286     FloatRegister src2d = src2c-&gt;successor();
10287     __ mul_float(dstd, src1d, src2d);
10288   %}
10289 
10290   ins_pipe(fmulF_reg_reg); // FIXME
10291 %}
10292 
10293 instruct vmul2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10294   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10295   match(Set dst (MulVD src1 src2));
10296   size(4*2);
10297   ins_cost(DEFAULT_COST*2); // FIXME
10298 
10299   format %{ &quot;FMULD  $dst.D.a,$src1.D.a,$src2.D.a\n\t&quot;
10300             &quot;FMULD  $dst.D.b,$src1.D.b,$src2.D.b&quot; %}
10301   ins_encode %{
10302     FloatRegister dsta = $dst$$FloatRegister;
10303     FloatRegister src1a = $src1$$FloatRegister;
10304     FloatRegister src2a = $src2$$FloatRegister;
10305     __ mul_double(dsta, src1a, src2a);
10306     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10307     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10308     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10309     __ mul_double(dstb, src1b, src2b);
10310   %}
10311 
10312   ins_pipe(fmulD_reg_reg); // FIXME
10313 %}
10314 
10315 
10316 // Floats vector div
10317 instruct vdiv2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10318   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10319   match(Set dst (DivVF src1 src2));
10320   size(4*2);
10321   ins_cost(DEFAULT_COST*2); // FIXME
10322 
10323   format %{ &quot;FDIVS  $dst.a,$src1.a,$src2.a\n\t&quot;
10324             &quot;FDIVS  $dst.b,$src1.b,$src2.b&quot; %}
10325   ins_encode %{
10326     __ div_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
10327     __ div_float($dst$$FloatRegister-&gt;successor(),
10328              $src1$$FloatRegister-&gt;successor(),
10329              $src2$$FloatRegister-&gt;successor());
10330   %}
10331 
10332   ins_pipe(fdivF_reg_reg); // FIXME
10333 %}
10334 
10335 instruct vdiv4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10336   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10337   match(Set dst (DivVF src1 src2));
10338   size(4*4);
10339   ins_cost(DEFAULT_COST*4); // FIXME
10340 
10341   format %{ &quot;FDIVS  $dst.a,$src1.a,$src2.a\n\t&quot;
10342             &quot;FDIVS  $dst.b,$src1.b,$src2.b\n\t&quot;
10343             &quot;FDIVS  $dst.c,$src1.c,$src2.c\n\t&quot;
10344             &quot;FDIVS  $dst.d,$src1.d,$src2.d&quot; %}
10345 
10346   ins_encode %{
10347     FloatRegister dsta = $dst$$FloatRegister;
10348     FloatRegister src1a = $src1$$FloatRegister;
10349     FloatRegister src2a = $src2$$FloatRegister;
10350     __ div_float(dsta, src1a, src2a);
10351     FloatRegister dstb = dsta-&gt;successor();
10352     FloatRegister src1b = src1a-&gt;successor();
10353     FloatRegister src2b = src2a-&gt;successor();
10354     __ div_float(dstb, src1b, src2b);
10355     FloatRegister dstc = dstb-&gt;successor();
10356     FloatRegister src1c = src1b-&gt;successor();
10357     FloatRegister src2c = src2b-&gt;successor();
10358     __ div_float(dstc, src1c, src2c);
10359     FloatRegister dstd = dstc-&gt;successor();
10360     FloatRegister src1d = src1c-&gt;successor();
10361     FloatRegister src2d = src2c-&gt;successor();
10362     __ div_float(dstd, src1d, src2d);
10363   %}
10364 
10365   ins_pipe(fdivF_reg_reg); // FIXME
10366 %}
10367 
10368 instruct vdiv2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10369   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10370   match(Set dst (DivVD src1 src2));
10371   size(4*2);
10372   ins_cost(DEFAULT_COST*2); // FIXME
10373 
10374   format %{ &quot;FDIVD  $dst.D.a,$src1.D.a,$src2.D.a\n\t&quot;
10375             &quot;FDIVD  $dst.D.b,$src1.D.b,$src2.D.b&quot; %}
10376   ins_encode %{
10377     FloatRegister dsta = $dst$$FloatRegister;
10378     FloatRegister src1a = $src1$$FloatRegister;
10379     FloatRegister src2a = $src2$$FloatRegister;
10380     __ div_double(dsta, src1a, src2a);
10381     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10382     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10383     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10384     __ div_double(dstb, src1b, src2b);
10385   %}
10386 
10387   ins_pipe(fdivD_reg_reg); // FIXME
10388 %}
10389 
10390 // --------------------------------- NEG --------------------------------------
10391 
10392 instruct vneg8B_reg(vecD dst, vecD src) %{
10393   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
10394   effect(DEF dst, USE src);
10395   size(4);
10396   ins_cost(DEFAULT_COST); // FIXME
10397   format %{ &quot;VNEG.S8 $dst.D,$src.D\t! neg packed8B&quot; %}
10398   ins_encode %{
10399     bool quad = false;
10400     __ vnegI($dst$$FloatRegister, $src$$FloatRegister,
10401               MacroAssembler::VELEM_SIZE_8, quad);
10402   %}
10403   ins_pipe( ialu_reg_reg ); // FIXME
10404 %}
10405 
10406 instruct vneg16B_reg(vecX dst, vecX src) %{
10407   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
10408   effect(DEF dst, USE src);
10409   size(4);
10410   ins_cost(DEFAULT_COST); // FIXME
10411   format %{ &quot;VNEG.S8 $dst.Q,$src.Q\t! neg0 packed16B&quot; %}
10412   ins_encode %{
10413     bool _float = false;
10414     bool quad = true;
10415     __ vnegI($dst$$FloatRegister, $src$$FloatRegister,
10416               MacroAssembler::VELEM_SIZE_8, quad);
10417   %}
10418   ins_pipe( ialu_reg_reg ); // FIXME
10419 %}
10420 
10421 // ------------------------------ Shift ---------------------------------------
10422 
10423 instruct vslcntD(vecD dst, iRegI cnt) %{
10424   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
10425   match(Set dst (LShiftCntV cnt));
10426   size(4);
10427   ins_cost(DEFAULT_COST); // FIXME
10428   expand %{
10429     Repl8B_reg_simd(dst, cnt);
10430   %}
10431 %}
10432 
10433 instruct vslcntX(vecX dst, iRegI cnt) %{
10434   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
10435   match(Set dst (LShiftCntV cnt));
10436   size(4);
10437   ins_cost(DEFAULT_COST); // FIXME
10438   expand %{
10439     Repl16B_reg(dst, cnt);
10440   %}
10441 %}
10442 
10443 // Low bits of vector &quot;shift&quot; elements are used, so it
10444 // doesn&#39;t matter if we treat it as ints or bytes here.
10445 instruct vsrcntD(vecD dst, iRegI cnt) %{
10446   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
10447   match(Set dst (RShiftCntV cnt));
10448   size(4*2);
10449   ins_cost(DEFAULT_COST*2); // FIXME
10450 
10451   format %{ &quot;VDUP.8 $dst.D,$cnt\n\t&quot;
10452             &quot;VNEG.S8 $dst.D,$dst.D\t! neg packed8B&quot; %}
10453   ins_encode %{
10454     bool quad = false;
10455     __ vdupI($dst$$FloatRegister, $cnt$$Register,
10456              MacroAssembler::VELEM_SIZE_8, quad);
10457     __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,
10458               MacroAssembler::VELEM_SIZE_8, quad);
10459   %}
10460   ins_pipe( ialu_reg_reg ); // FIXME
10461 %}
10462 
10463 instruct vsrcntX(vecX dst, iRegI cnt) %{
10464   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
10465   match(Set dst (RShiftCntV cnt));
10466   size(4*2);
10467   ins_cost(DEFAULT_COST*2); // FIXME
10468   format %{ &quot;VDUP.8 $dst.Q,$cnt\n\t&quot;
10469             &quot;VNEG.S8 $dst.Q,$dst.Q\t! neg packed16B&quot; %}
10470   ins_encode %{
10471     bool quad = true;
10472     __ vdupI($dst$$FloatRegister, $cnt$$Register,
10473              MacroAssembler::VELEM_SIZE_8, quad);
10474     __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,
10475               MacroAssembler::VELEM_SIZE_8, quad);
10476   %}
10477   ins_pipe( ialu_reg_reg ); // FIXME
10478 %}
10479 
10480 // Byte vector logical left/right shift based on sign
10481 instruct vsh8B_reg(vecD dst, vecD src, vecD shift) %{
10482   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10483   effect(DEF dst, USE src, USE shift);
10484   size(4);
10485   ins_cost(DEFAULT_COST); // FIXME
10486   format %{
10487     &quot;VSHL.U8 $dst.D,$src.D,$shift.D\t! logical left/right shift packed8B&quot;
10488   %}
10489   ins_encode %{
10490     bool quad = false;
10491     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10492               MacroAssembler::VELEM_SIZE_8, quad);
10493   %}
10494   ins_pipe( ialu_reg_reg ); // FIXME
10495 %}
10496 
10497 instruct vsh16B_reg(vecX dst, vecX src, vecX shift) %{
10498   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10499   effect(DEF dst, USE src, USE shift);
10500   size(4);
10501   ins_cost(DEFAULT_COST); // FIXME
10502   format %{
10503     &quot;VSHL.U8 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed16B&quot;
10504   %}
10505   ins_encode %{
10506     bool quad = true;
10507     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10508               MacroAssembler::VELEM_SIZE_8, quad);
10509   %}
10510   ins_pipe( ialu_reg_reg ); // FIXME
10511 %}
10512 
10513 // Shorts/Char vector logical left/right shift based on sign
10514 instruct vsh4S_reg(vecD dst, vecD src, vecD shift) %{
10515   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10516   effect(DEF dst, USE src, USE shift);
10517   size(4);
10518   ins_cost(DEFAULT_COST); // FIXME
10519   format %{
10520     &quot;VSHL.U16 $dst.D,$src.D,$shift.D\t! logical left/right shift packed4S&quot;
10521   %}
10522   ins_encode %{
10523     bool quad = false;
10524     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10525               MacroAssembler::VELEM_SIZE_16, quad);
10526   %}
10527   ins_pipe( ialu_reg_reg ); // FIXME
10528 %}
10529 
10530 instruct vsh8S_reg(vecX dst, vecX src, vecX shift) %{
10531   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10532   effect(DEF dst, USE src, USE shift);
10533   size(4);
10534   ins_cost(DEFAULT_COST); // FIXME
10535   format %{
10536     &quot;VSHL.U16 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed8S&quot;
10537   %}
10538   ins_encode %{
10539     bool quad = true;
10540     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10541               MacroAssembler::VELEM_SIZE_16, quad);
10542   %}
10543   ins_pipe( ialu_reg_reg ); // FIXME
10544 %}
10545 
10546 // Integers vector logical left/right shift based on sign
10547 instruct vsh2I_reg(vecD dst, vecD src, vecD shift) %{
10548   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10549   effect(DEF dst, USE src, USE shift);
10550   size(4);
10551   ins_cost(DEFAULT_COST); // FIXME
10552   format %{
10553     &quot;VSHL.U32 $dst.D,$src.D,$shift.D\t! logical left/right shift packed2I&quot;
10554   %}
10555   ins_encode %{
10556     bool quad = false;
10557     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10558               MacroAssembler::VELEM_SIZE_32, quad);
10559   %}
10560   ins_pipe( ialu_reg_reg ); // FIXME
10561 %}
10562 
10563 instruct vsh4I_reg(vecX dst, vecX src, vecX shift) %{
10564   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10565   effect(DEF dst, USE src, USE shift);
10566   size(4);
10567   ins_cost(DEFAULT_COST); // FIXME
10568   format %{
10569     &quot;VSHL.U32 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed4I&quot;
10570   %}
10571   ins_encode %{
10572     bool quad = true;
10573     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10574               MacroAssembler::VELEM_SIZE_32, quad);
10575   %}
10576   ins_pipe( ialu_reg_reg ); // FIXME
10577 %}
10578 
10579 // Longs vector logical left/right shift based on sign
10580 instruct vsh2L_reg(vecX dst, vecX src, vecX shift) %{
10581   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10582   effect(DEF dst, USE src, USE shift);
10583   size(4);
10584   ins_cost(DEFAULT_COST); // FIXME
10585   format %{
10586     &quot;VSHL.U64 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed2L&quot;
10587   %}
10588   ins_encode %{
10589     bool quad = true;
10590     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10591               MacroAssembler::VELEM_SIZE_64, quad);
10592   %}
10593   ins_pipe( ialu_reg_reg ); // FIXME
10594 %}
10595 
10596 // ------------------------------ LeftShift -----------------------------------
10597 
10598 // Byte vector left shift
10599 instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{
10600   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10601   match(Set dst (LShiftVB src shift));
10602   size(4*1);
10603   ins_cost(DEFAULT_COST*1); // FIXME
10604   expand %{
10605     vsh8B_reg(dst, src, shift);
10606   %}
10607 %}
10608 
10609 instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{
10610   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10611   match(Set dst (LShiftVB src shift));
10612   size(4*1);
10613   ins_cost(DEFAULT_COST*1); // FIXME
10614   expand %{
10615     vsh16B_reg(dst, src, shift);
10616   %}
10617 %}
10618 
10619 instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{
10620   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10621   match(Set dst (LShiftVB src (LShiftCntV shift)));
10622   size(4);
10623   ins_cost(DEFAULT_COST); // FIXME
10624   format %{
10625     &quot;VSHL.I8 $dst.D,$src.D,$shift\t! logical left shift packed8B&quot;
10626   %}
10627   ins_encode %{
10628     bool quad = false;
10629     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10630              quad);
10631   %}
10632   ins_pipe( ialu_reg_reg ); // FIXME
10633 %}
10634 
10635 instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{
10636   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10637   match(Set dst (LShiftVB src (LShiftCntV shift)));
10638   size(4);
10639   ins_cost(DEFAULT_COST); // FIXME
10640   format %{
10641     &quot;VSHL.I8 $dst.Q,$src.Q,$shift\t! logical left shift packed16B&quot;
10642   %}
10643   ins_encode %{
10644     bool quad = true;
10645     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10646              quad);
10647   %}
10648   ins_pipe( ialu_reg_reg ); // FIXME
10649 %}
10650 
10651 // Shorts/Chars vector logical left/right shift
10652 instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{
10653   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10654   match(Set dst (LShiftVS src shift));
10655   match(Set dst (URShiftVS src shift));
10656   size(4*1);
10657   ins_cost(DEFAULT_COST*1); // FIXME
10658   expand %{
10659     vsh4S_reg(dst, src, shift);
10660   %}
10661 %}
10662 
10663 instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{
10664   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10665   match(Set dst (LShiftVS src shift));
10666   match(Set dst (URShiftVS src shift));
10667   size(4*1);
10668   ins_cost(DEFAULT_COST*1); // FIXME
10669   expand %{
10670     vsh8S_reg(dst, src, shift);
10671   %}
10672 %}
10673 
10674 instruct vsl4S_immI(vecD dst, vecD src, immI shift) %{
10675   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10676   match(Set dst (LShiftVS src (LShiftCntV shift)));
10677   size(4);
10678   ins_cost(DEFAULT_COST); // FIXME
10679   format %{
10680     &quot;VSHL.I16 $dst.D,$src.D,$shift\t! logical left shift packed4S&quot;
10681   %}
10682   ins_encode %{
10683     bool quad = false;
10684     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10685              quad);
10686   %}
10687   ins_pipe( ialu_reg_reg ); // FIXME
10688 %}
10689 
10690 instruct vsl8S_immI(vecX dst, vecX src, immI shift) %{
10691   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10692   match(Set dst (LShiftVS src shift));
10693   size(4);
10694   ins_cost(DEFAULT_COST); // FIXME
10695   format %{
10696     &quot;VSHL.I16 $dst.Q,$src.Q,$shift\t! logical left shift packed8S&quot;
10697   %}
10698   ins_encode %{
10699     bool quad = true;
10700     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10701              quad);
10702   %}
10703   ins_pipe( ialu_reg_reg ); // FIXME
10704 %}
10705 
10706 // Integers vector logical left/right shift
10707 instruct vsl2I_reg(vecD dst, vecD src, vecD shift) %{
10708   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10709   match(Set dst (LShiftVI src shift));
10710   match(Set dst (URShiftVI src shift));
10711   size(4*1);
10712   ins_cost(DEFAULT_COST*1); // FIXME
10713   expand %{
10714     vsh2I_reg(dst, src, shift);
10715   %}
10716 %}
10717 
10718 instruct vsl4I_reg(vecX dst, vecX src, vecX shift) %{
10719   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10720   match(Set dst (LShiftVI src shift));
10721   match(Set dst (URShiftVI src shift));
10722   size(4*1);
10723   ins_cost(DEFAULT_COST*1); // FIXME
10724   expand %{
10725     vsh4I_reg(dst, src, shift);
10726   %}
10727 %}
10728 
10729 instruct vsl2I_immI(vecD dst, vecD src, immI shift) %{
10730   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10731   match(Set dst (LShiftVI src (LShiftCntV shift)));
10732   size(4);
10733   ins_cost(DEFAULT_COST); // FIXME
10734   format %{
10735     &quot;VSHL.I32 $dst.D,$src.D,$shift\t! logical left shift packed2I&quot;
10736   %}
10737   ins_encode %{
10738     bool quad = false;
10739     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10740              quad);
10741   %}
10742   ins_pipe( ialu_reg_reg ); // FIXME
10743 %}
10744 
10745 instruct vsl4I_immI(vecX dst, vecX src, immI shift) %{
10746   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10747   match(Set dst (LShiftVI src (LShiftCntV shift)));
10748   size(4);
10749   ins_cost(DEFAULT_COST); // FIXME
10750   format %{
10751     &quot;VSHL.I32 $dst.Q,$src.Q,$shift\t! logical left shift packed4I&quot;
10752   %}
10753   ins_encode %{
10754     bool quad = true;
10755     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10756              quad);
10757   %}
10758   ins_pipe( ialu_reg_reg ); // FIXME
10759 %}
10760 
10761 // Longs vector logical left/right shift
10762 instruct vsl2L_reg(vecX dst, vecX src, vecX shift) %{
10763   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10764   match(Set dst (LShiftVL src shift));
10765   match(Set dst (URShiftVL src shift));
10766   size(4*1);
10767   ins_cost(DEFAULT_COST*1); // FIXME
10768   expand %{
10769     vsh2L_reg(dst, src, shift);
10770   %}
10771 %}
10772 
10773 instruct vsl2L_immI(vecX dst, vecX src, immI shift) %{
10774   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10775   match(Set dst (LShiftVL src (LShiftCntV shift)));
10776   size(4);
10777   ins_cost(DEFAULT_COST); // FIXME
10778   format %{
10779     &quot;VSHL.I64 $dst.Q,$src.Q,$shift\t! logical left shift packed2L&quot;
10780   %}
10781   ins_encode %{
10782     bool quad = true;
10783     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10784              quad);
10785   %}
10786   ins_pipe( ialu_reg_reg ); // FIXME
10787 %}
10788 
10789 // ----------------------- LogicalRightShift -----------------------------------
10790 
10791 // Bytes/Shorts vector logical right shift produces incorrect Java result
10792 // for negative data because java code convert short value into int with
10793 // sign extension before a shift.
10794 
10795 // Chars vector logical right shift
10796 instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{
10797   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10798   match(Set dst (URShiftVS src (RShiftCntV shift)));
10799   size(4);
10800   ins_cost(DEFAULT_COST); // FIXME
10801   format %{
10802     &quot;VSHR.U16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
10803   %}
10804   ins_encode %{
10805     bool quad = false;
10806     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10807              quad);
10808   %}
10809   ins_pipe( ialu_reg_reg ); // FIXME
10810 %}
10811 
10812 instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{
10813   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10814   match(Set dst (URShiftVS src (RShiftCntV shift)));
10815   size(4);
10816   ins_cost(DEFAULT_COST); // FIXME
10817   format %{
10818     &quot;VSHR.U16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
10819   %}
10820   ins_encode %{
10821     bool quad = true;
10822     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10823              quad);
10824   %}
10825   ins_pipe( ialu_reg_reg ); // FIXME
10826 %}
10827 
10828 // Integers vector logical right shift
10829 instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{
10830   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10831   match(Set dst (URShiftVI src (RShiftCntV shift)));
10832   size(4);
10833   ins_cost(DEFAULT_COST); // FIXME
10834   format %{
10835     &quot;VSHR.U32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
10836   %}
10837   ins_encode %{
10838     bool quad = false;
10839     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10840              quad);
10841   %}
10842   ins_pipe( ialu_reg_reg ); // FIXME
10843 %}
10844 
10845 instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{
10846   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10847   match(Set dst (URShiftVI src (RShiftCntV shift)));
10848   size(4);
10849   ins_cost(DEFAULT_COST); // FIXME
10850   format %{
10851     &quot;VSHR.U32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
10852   %}
10853   ins_encode %{
10854     bool quad = true;
10855     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10856              quad);
10857   %}
10858   ins_pipe( ialu_reg_reg ); // FIXME
10859 %}
10860 
10861 // Longs vector logical right shift
10862 instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{
10863   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10864   match(Set dst (URShiftVL src (RShiftCntV shift)));
10865   size(4);
10866   ins_cost(DEFAULT_COST); // FIXME
10867   format %{
10868     &quot;VSHR.U64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
10869   %}
10870   ins_encode %{
10871     bool quad = true;
10872     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10873              quad);
10874   %}
10875   ins_pipe( ialu_reg_reg ); // FIXME
10876 %}
10877 
10878 // ------------------- ArithmeticRightShift -----------------------------------
10879 
10880 // Bytes vector arithmetic left/right shift based on sign
10881 instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{
10882   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10883   effect(DEF dst, USE src, USE shift);
10884   size(4);
10885   ins_cost(DEFAULT_COST); // FIXME
10886   format %{
10887     &quot;VSHL.S8 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed8B&quot;
10888   %}
10889   ins_encode %{
10890     bool quad = false;
10891     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10892               MacroAssembler::VELEM_SIZE_8, quad);
10893   %}
10894   ins_pipe( ialu_reg_reg ); // FIXME
10895 %}
10896 
10897 instruct vsha16B_reg(vecX dst, vecX src, vecX shift) %{
10898   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10899   effect(DEF dst, USE src, USE shift);
10900   size(4);
10901   ins_cost(DEFAULT_COST); // FIXME
10902   format %{
10903     &quot;VSHL.S8 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed16B&quot;
10904   %}
10905   ins_encode %{
10906     bool quad = true;
10907     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10908               MacroAssembler::VELEM_SIZE_8, quad);
10909   %}
10910   ins_pipe( ialu_reg_reg ); // FIXME
10911 %}
10912 
10913 // Shorts vector arithmetic left/right shift based on sign
10914 instruct vsha4S_reg(vecD dst, vecD src, vecD shift) %{
10915   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10916   effect(DEF dst, USE src, USE shift);
10917   size(4);
10918   ins_cost(DEFAULT_COST); // FIXME
10919   format %{
10920     &quot;VSHL.S16 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed4S&quot;
10921   %}
10922   ins_encode %{
10923     bool quad = false;
10924     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10925               MacroAssembler::VELEM_SIZE_16, quad);
10926   %}
10927   ins_pipe( ialu_reg_reg ); // FIXME
10928 %}
10929 
10930 instruct vsha8S_reg(vecX dst, vecX src, vecX shift) %{
10931   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10932   effect(DEF dst, USE src, USE shift);
10933   size(4);
10934   ins_cost(DEFAULT_COST); // FIXME
10935   format %{
10936     &quot;VSHL.S16 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed8S&quot;
10937   %}
10938   ins_encode %{
10939     bool quad = true;
10940     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10941               MacroAssembler::VELEM_SIZE_16, quad);
10942   %}
10943   ins_pipe( ialu_reg_reg ); // FIXME
10944 %}
10945 
10946 // Integers vector arithmetic left/right shift based on sign
10947 instruct vsha2I_reg(vecD dst, vecD src, vecD shift) %{
10948   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10949   effect(DEF dst, USE src, USE shift);
10950   size(4);
10951   ins_cost(DEFAULT_COST); // FIXME
10952   format %{
10953     &quot;VSHL.S32 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed2I&quot;
10954   %}
10955   ins_encode %{
10956     bool quad = false;
10957     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10958               MacroAssembler::VELEM_SIZE_32, quad);
10959   %}
10960   ins_pipe( ialu_reg_reg ); // FIXME
10961 %}
10962 
10963 instruct vsha4I_reg(vecX dst, vecX src, vecX shift) %{
10964   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10965   effect(DEF dst, USE src, USE shift);
10966   size(4);
10967   ins_cost(DEFAULT_COST); // FIXME
10968   format %{
10969     &quot;VSHL.S32 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed4I&quot;
10970   %}
10971   ins_encode %{
10972     bool quad = true;
10973     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10974               MacroAssembler::VELEM_SIZE_32, quad);
10975   %}
10976   ins_pipe( ialu_reg_reg ); // FIXME
10977 %}
10978 
10979 // Longs vector arithmetic left/right shift based on sign
10980 instruct vsha2L_reg(vecX dst, vecX src, vecX shift) %{
10981   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10982   effect(DEF dst, USE src, USE shift);
10983   size(4);
10984   ins_cost(DEFAULT_COST); // FIXME
10985   format %{
10986     &quot;VSHL.S64 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed2L&quot;
10987   %}
10988   ins_encode %{
10989     bool quad = true;
10990     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10991               MacroAssembler::VELEM_SIZE_64, quad);
10992   %}
10993   ins_pipe( ialu_reg_reg ); // FIXME
10994 %}
10995 
10996 // Byte vector arithmetic right shift
10997 
10998 instruct vsra8B_reg(vecD dst, vecD src, vecD shift) %{
10999   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11000   match(Set dst (RShiftVB src shift));
11001   size(4);
11002   ins_cost(DEFAULT_COST); // FIXME
11003   expand %{
11004     vsha8B_reg(dst, src, shift);
11005   %}
11006 %}
11007 
11008 instruct vsrl16B_reg(vecX dst, vecX src, vecX shift) %{
11009   predicate(n-&gt;as_Vector()-&gt;length() == 16);
11010   match(Set dst (RShiftVB src shift));
11011   size(4);
11012   ins_cost(DEFAULT_COST); // FIXME
11013   expand %{
11014     vsha16B_reg(dst, src, shift);
11015   %}
11016 %}
11017 
11018 instruct vsrl8B_immI(vecD dst, vecD src, immI shift) %{
11019   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11020   match(Set dst (RShiftVB src shift));
11021   size(4);
11022   ins_cost(DEFAULT_COST); // FIXME
11023   format %{
11024     &quot;VSHR.S8 $dst.D,$src.D,$shift\t! logical right shift packed8B&quot;
11025   %}
11026   ins_encode %{
11027     bool quad = false;
11028     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
11029              quad);
11030   %}
11031   ins_pipe( ialu_reg_reg ); // FIXME
11032 %}
11033 
11034 instruct vsrl16B_immI(vecX dst, vecX src, immI shift) %{
11035   predicate(n-&gt;as_Vector()-&gt;length() == 16);
11036   match(Set dst (RShiftVB src shift));
11037   size(4);
11038   ins_cost(DEFAULT_COST); // FIXME
11039   format %{
11040     &quot;VSHR.S8 $dst.Q,$src.Q,$shift\t! logical right shift packed16B&quot;
11041   %}
11042   ins_encode %{
11043     bool quad = true;
11044     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
11045              quad);
11046   %}
11047   ins_pipe( ialu_reg_reg ); // FIXME
11048 %}
11049 
11050 // Shorts vector arithmetic right shift
11051 instruct vsra4S_reg(vecD dst, vecD src, vecD shift) %{
11052   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11053   match(Set dst (RShiftVS src shift));
11054   size(4);
11055   ins_cost(DEFAULT_COST); // FIXME
11056   expand %{
11057     vsha4S_reg(dst, src, shift);
11058   %}
11059 %}
11060 
11061 instruct vsra8S_reg(vecX dst, vecX src, vecX shift) %{
11062   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11063   match(Set dst (RShiftVS src shift));
11064   size(4);
11065   ins_cost(DEFAULT_COST); // FIXME
11066   expand %{
11067     vsha8S_reg(dst, src, shift);
11068   %}
11069 %}
11070 
11071 instruct vsra4S_immI(vecD dst, vecD src, immI shift) %{
11072   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11073   match(Set dst (RShiftVS src shift));
11074   size(4);
11075   ins_cost(DEFAULT_COST); // FIXME
11076   format %{
11077     &quot;VSHR.S16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
11078   %}
11079   ins_encode %{
11080     bool quad = false;
11081     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
11082              quad);
11083   %}
11084   ins_pipe( ialu_reg_reg ); // FIXME
11085 %}
11086 
11087 instruct vsra8S_immI(vecX dst, vecX src, immI shift) %{
11088   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11089   match(Set dst (RShiftVS src shift));
11090   size(4);
11091   ins_cost(DEFAULT_COST); // FIXME
11092   format %{
11093     &quot;VSHR.S16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
11094   %}
11095   ins_encode %{
11096     bool quad = true;
11097     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
11098              quad);
11099   %}
11100   ins_pipe( ialu_reg_reg ); // FIXME
11101 %}
11102 
11103 // Integers vector arithmetic right shift
11104 instruct vsra2I_reg(vecD dst, vecD src, vecD shift) %{
11105   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11106   match(Set dst (RShiftVI src shift));
11107   size(4);
11108   ins_cost(DEFAULT_COST); // FIXME
11109   expand %{
11110     vsha2I_reg(dst, src, shift);
11111   %}
11112 %}
11113 
11114 instruct vsra4I_reg(vecX dst, vecX src, vecX shift) %{
11115   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11116   match(Set dst (RShiftVI src shift));
11117   size(4);
11118   ins_cost(DEFAULT_COST); // FIXME
11119   expand %{
11120     vsha4I_reg(dst, src, shift);
11121   %}
11122 %}
11123 
11124 instruct vsra2I_immI(vecD dst, vecD src, immI shift) %{
11125   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11126   match(Set dst (RShiftVI src shift));
11127   size(4);
11128   ins_cost(DEFAULT_COST); // FIXME
11129   format %{
11130     &quot;VSHR.S32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
11131   %}
11132   ins_encode %{
11133     bool quad = false;
11134     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
11135              quad);
11136   %}
11137   ins_pipe( ialu_reg_reg ); // FIXME
11138 %}
11139 
11140 instruct vsra4I_immI(vecX dst, vecX src, immI shift) %{
11141   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11142   match(Set dst (RShiftVI src shift));
11143   size(4);
11144   ins_cost(DEFAULT_COST); // FIXME
11145   format %{
11146     &quot;VSHR.S32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
11147   %}
11148   ins_encode %{
11149     bool quad = true;
11150     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
11151              quad);
11152   %}
11153   ins_pipe( ialu_reg_reg ); // FIXME
11154 %}
11155 
11156 // Longs vector arithmetic right shift
11157 instruct vsra2L_reg(vecX dst, vecX src, vecX shift) %{
11158   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11159   match(Set dst (RShiftVL src shift));
11160   size(4);
11161   ins_cost(DEFAULT_COST); // FIXME
11162   expand %{
11163     vsha2L_reg(dst, src, shift);
11164   %}
11165 %}
11166 
11167 instruct vsra2L_immI(vecX dst, vecX src, immI shift) %{
11168   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11169   match(Set dst (RShiftVL src shift));
11170   size(4);
11171   ins_cost(DEFAULT_COST); // FIXME
11172   format %{
11173     &quot;VSHR.S64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
11174   %}
11175   ins_encode %{
11176     bool quad = true;
11177     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
11178              quad);
11179   %}
11180   ins_pipe( ialu_reg_reg ); // FIXME
11181 %}
11182 
11183 // --------------------------------- AND --------------------------------------
11184 
11185 instruct vandD(vecD dst, vecD src1, vecD src2) %{
11186   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11187   match(Set dst (AndV src1 src2));
11188   format %{ &quot;VAND    $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11189   ins_encode %{
11190     bool quad = false;
11191     __ vandI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11192              quad);
11193   %}
11194   ins_pipe( ialu_reg_reg ); // FIXME
11195 %}
11196 
11197 instruct vandX(vecX dst, vecX src1, vecX src2) %{
11198   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11199   match(Set dst (AndV src1 src2));
11200   format %{ &quot;VAND    $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11201   ins_encode %{
11202     bool quad = true;
11203     __ vandI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11204              quad);
11205   %}
11206   ins_pipe( ialu_reg_reg ); // FIXME
11207 %}
11208 
11209 // --------------------------------- OR ---------------------------------------
11210 
11211 instruct vorD(vecD dst, vecD src1, vecD src2) %{
11212   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11213   match(Set dst (OrV src1 src2));
11214   format %{ &quot;VOR     $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11215   ins_encode %{
11216     bool quad = false;
11217     __ vorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11218             quad);
11219   %}
11220   ins_pipe( ialu_reg_reg ); // FIXME
11221 %}
11222 
11223 instruct vorX(vecX dst, vecX src1, vecX src2) %{
11224   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11225   match(Set dst (OrV src1 src2));
11226   format %{ &quot;VOR     $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11227   ins_encode %{
11228     bool quad = true;
11229     __ vorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11230             quad);
11231   %}
11232   ins_pipe( ialu_reg_reg ); // FIXME
11233 %}
11234 
11235 // --------------------------------- XOR --------------------------------------
11236 
11237 instruct vxorD(vecD dst, vecD src1, vecD src2) %{
11238   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11239   match(Set dst (XorV src1 src2));
11240   format %{ &quot;VXOR    $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11241   ins_encode %{
11242     bool quad = false;
11243     __ vxorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11244              quad);
11245   %}
11246   ins_pipe( ialu_reg_reg ); // FIXME
11247 %}
11248 
11249 instruct vxorX(vecX dst, vecX src1, vecX src2) %{
11250   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11251   match(Set dst (XorV src1 src2));
11252   format %{ &quot;VXOR    $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11253   ins_encode %{
11254     bool quad = true;
11255     __ vxorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11256              quad);
11257   %}
11258   ins_pipe( ialu_reg_reg ); // FIXME
11259 %}
11260 
11261 
11262 //----------PEEPHOLE RULES-----------------------------------------------------
11263 // These must follow all instruction definitions as they use the names
11264 // defined in the instructions definitions.
11265 //
11266 // peepmatch ( root_instr_name [preceding_instruction]* );
11267 //
11268 // peepconstraint %{
11269 // (instruction_number.operand_name relational_op instruction_number.operand_name
11270 //  [, ...] );
11271 // // instruction numbers are zero-based using left to right order in peepmatch
11272 //
11273 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
11274 // // provide an instruction_number.operand_name for each operand that appears
11275 // // in the replacement instruction&#39;s match rule
11276 //
11277 // ---------VM FLAGS---------------------------------------------------------
11278 //
11279 // All peephole optimizations can be turned off using -XX:-OptoPeephole
11280 //
11281 // Each peephole rule is given an identifying number starting with zero and
11282 // increasing by one in the order seen by the parser.  An individual peephole
11283 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
11284 // on the command-line.
11285 //
11286 // ---------CURRENT LIMITATIONS----------------------------------------------
11287 //
11288 // Only match adjacent instructions in same basic block
11289 // Only equality constraints
11290 // Only constraints between operands, not (0.dest_reg == EAX_enc)
11291 // Only one replacement instruction
11292 //
11293 // ---------EXAMPLE----------------------------------------------------------
11294 //
11295 // // pertinent parts of existing instructions in architecture description
11296 // instruct movI(eRegI dst, eRegI src) %{
11297 //   match(Set dst (CopyI src));
11298 // %}
11299 //
11300 // instruct incI_eReg(eRegI dst, immI1 src, eFlagsReg cr) %{
11301 //   match(Set dst (AddI dst src));
11302 //   effect(KILL cr);
11303 // %}
11304 //
11305 // // Change (inc mov) to lea
11306 // peephole %{
11307 //   // increment preceeded by register-register move
11308 //   peepmatch ( incI_eReg movI );
11309 //   // require that the destination register of the increment
11310 //   // match the destination register of the move
11311 //   peepconstraint ( 0.dst == 1.dst );
11312 //   // construct a replacement instruction that sets
11313 //   // the destination to ( move&#39;s source register + one )
11314 //   peepreplace ( incI_eReg_immI1( 0.dst 1.src 0.src ) );
11315 // %}
11316 //
11317 
11318 // // Change load of spilled value to only a spill
11319 // instruct storeI(memory mem, eRegI src) %{
11320 //   match(Set mem (StoreI mem src));
11321 // %}
11322 //
11323 // instruct loadI(eRegI dst, memory mem) %{
11324 //   match(Set dst (LoadI mem));
11325 // %}
11326 //
11327 // peephole %{
11328 //   peepmatch ( loadI storeI );
11329 //   peepconstraint ( 1.src == 0.dst, 1.mem == 0.mem );
11330 //   peepreplace ( storeI( 1.mem 1.mem 1.src ) );
11331 // %}
11332 
11333 //----------SMARTSPILL RULES---------------------------------------------------
11334 // These must follow all instruction definitions as they use the names
11335 // defined in the instructions definitions.
11336 //
11337 // ARM will probably not have any of these rules due to RISC instruction set.
11338 
11339 //----------PIPELINE-----------------------------------------------------------
11340 // Rules which define the behavior of the target architectures pipeline.
    </pre>
  </body>
</html>