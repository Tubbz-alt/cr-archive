diff a/src/hotspot/cpu/ppc/ppc.ad b/src/hotspot/cpu/ppc/ppc.ad
--- a/src/hotspot/cpu/ppc/ppc.ad
+++ b/src/hotspot/cpu/ppc/ppc.ad
@@ -1142,11 +1142,11 @@
 
 //=============================================================================
 
 // Emit an interrupt that is caught by the debugger (for debugging compiler).
 void emit_break(CodeBuffer &cbuf) {
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
   __ illtrap();
 }
 
 #ifndef PRODUCT
 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
@@ -1163,11 +1163,11 @@
 }
 
 //=============================================================================
 
 void emit_nop(CodeBuffer &cbuf) {
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
   __ nop();
 }
 
 static inline void emit_long(CodeBuffer &cbuf, int value) {
   *((int*)(cbuf.insts_end())) = value;
@@ -1182,16 +1182,18 @@
 
 //--------------------------------------------------------------
 //---<  Used for optimization in Compile::Shorten_branches  >---
 //--------------------------------------------------------------
 
+class C2_MacroAssembler;
+
 class CallStubImpl {
 
  public:
 
   // Emit call stub, compiled java to interpreter.
-  static void emit_trampoline_stub(MacroAssembler &_masm, int destination_toc_offset, int insts_call_instruction_offset);
+  static void emit_trampoline_stub(C2_MacroAssembler &_masm, int destination_toc_offset, int insts_call_instruction_offset);
 
   // Size of call trampoline stub.
   // This doesn't need to be accurate to the byte, but it
   // must be larger than or equal to the real size of the stub.
   static uint size_call_trampoline() {
@@ -1218,11 +1220,11 @@
 //
 // Related trampoline stub for this call-site in the stub section:
 //   load the call target from the constant pool
 //   branch via CTR (LR/link still points to the call-site above)
 
-void CallStubImpl::emit_trampoline_stub(MacroAssembler &_masm, int destination_toc_offset, int insts_call_instruction_offset) {
+void CallStubImpl::emit_trampoline_stub(C2_MacroAssembler &_masm, int destination_toc_offset, int insts_call_instruction_offset) {
   address stub = __ emit_trampoline_stub(destination_toc_offset, insts_call_instruction_offset);
   if (stub == NULL) {
     ciEnv::current()->record_out_of_memory_failure();
   }
 }
@@ -1249,11 +1251,11 @@
 // Emit a branch-and-link instruction that branches to a trampoline.
 // - Remember the offset of the branch-and-link instruction.
 // - Add a relocation at the branch-and-link instruction.
 // - Emit a branch-and-link.
 // - Remember the return pc offset.
-EmitCallOffsets emit_call_with_trampoline_stub(MacroAssembler &_masm, address entry_point, relocInfo::relocType rtype) {
+EmitCallOffsets emit_call_with_trampoline_stub(C2_MacroAssembler &_masm, address entry_point, relocInfo::relocType rtype) {
   EmitCallOffsets offsets = { -1, -1 };
   const int start_offset = __ offset();
   offsets.insts_call_instruction_offset = __ offset();
 
   // No entry point given, use the current pc.
@@ -1295,11 +1297,11 @@
 }
 
 //=============================================================================
 
 const RegMask& MachConstantBaseNode::_out_RegMask = BITS64_CONSTANT_TABLE_BASE_mask();
-int Compile::ConstantTable::calculate_table_base_offset() const {
+int ConstantTable::calculate_table_base_offset() const {
   return 0;  // absolute addressing, no offset
 }
 
 bool MachConstantBaseNode::requires_postalloc_expand() const { return true; }
 void MachConstantBaseNode::postalloc_expand(GrowableArray <Node *> *nodes, PhaseRegAlloc *ra_) {
@@ -1336,14 +1338,14 @@
 //=============================================================================
 
 #ifndef PRODUCT
 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
   Compile* C = ra_->C;
-  const long framesize = C->frame_slots() << LogBytesPerInt;
+  const long framesize = C->output()->frame_slots() << LogBytesPerInt;
 
   st->print("PROLOG\n\t");
-  if (C->need_stack_bang(framesize)) {
+  if (C->output()->need_stack_bang(framesize)) {
     st->print("stack_overflow_check\n\t");
   }
 
   if (!false /* TODO: PPC port C->is_frameless_method()*/) {
     st->print("save return pc\n\t");
@@ -1377,13 +1379,13 @@
                   Unimplemented()
 #endif
 
 void MachPrologNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
   Compile* C = ra_->C;
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
 
-  const long framesize = C->frame_size_in_bytes();
+  const long framesize = C->output()->frame_size_in_bytes();
   assert(framesize % (2 * wordSize) == 0, "must preserve 2*wordSize alignment");
 
   const bool method_is_frameless      = false /* TODO: PPC port C->is_frameless_method()*/;
 
   const Register return_pc            = R20; // Must match return_addr() in frame section.
@@ -1424,13 +1426,13 @@
   // We require that their callers must bang for them. But be
   // careful, because some VM calls (such as call site linkage) can
   // use several kilobytes of stack. But the stack safety zone should
   // account for that. See bugs 4446381, 4468289, 4497237.
 
-  int bangsize = C->bang_size_in_bytes();
+  int bangsize = C->output()->bang_size_in_bytes();
   assert(bangsize >= framesize || bangsize <= 0, "stack bang size incorrect");
-  if (C->need_stack_bang(bangsize) && UseStackBanging) {
+  if (C->output()->need_stack_bang(bangsize) && UseStackBanging) {
     // Unfortunately we cannot use the function provided in
     // assembler.cpp as we have to emulate the pipes. So I had to
     // insert the code of generate_stack_overflow_check(), see
     // assembler.cpp for some illuminative comments.
     const int page_size = os::vm_page_size();
@@ -1480,11 +1482,11 @@
       }
 
       bang_offset += page_size;
     }
     // R11 trashed
-  } // C->need_stack_bang(framesize) && UseStackBanging
+  } // C->output()->need_stack_bang(framesize) && UseStackBanging
 
   unsigned int bytes = (unsigned int)framesize;
   long offset = Assembler::align_addr(bytes, frame::alignment_in_bytes);
   ciMethod *currMethod = C->method();
 
@@ -1535,11 +1537,11 @@
   if (!method_is_frameless) {
     // Save return pc.
     ___(std) std(return_pc, _abi(lr), callers_sp);
   }
 
-  C->set_frame_complete(cbuf.insts_size());
+  C->output()->set_frame_complete(cbuf.insts_size());
 }
 #undef ___
 #undef ___stop
 #undef ___advance
 
@@ -1569,13 +1571,13 @@
 }
 #endif
 
 void MachEpilogNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
   Compile* C = ra_->C;
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
 
-  const long framesize = ((long)C->frame_slots()) << LogBytesPerInt;
+  const long framesize = ((long)C->output()->frame_slots()) << LogBytesPerInt;
   assert(framesize >= 0, "negative frame-size?");
 
   const bool method_needs_polling = do_polling() && C->is_method_compilation();
   const bool method_is_frameless  = false /* TODO: PPC port C->is_frameless_method()*/;
   const Register return_pc        = R31;  // Must survive C-call to enable_stack_reserved_zone().
@@ -1635,11 +1637,11 @@
   return 0;
 }
 
 #if 0 // TODO: PPC port
 void MachLoadPollAddrLateNode::emit(CodeBuffer& cbuf, PhaseRegAlloc* ra_) const {
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
   if (LoadPollAddressFromThread) {
     _masm.ld(R11, in_bytes(JavaThread::poll_address_offset()), R16_thread);
   } else {
     _masm.nop();
   }
@@ -1752,11 +1754,11 @@
     // Memory->Memory Spill.
     if (src_lo_rc == rc_stack && dst_lo_rc == rc_stack) {
       int src_offset = ra_->reg2offset(src_lo);
       int dst_offset = ra_->reg2offset(dst_lo);
       if (cbuf) {
-        MacroAssembler _masm(cbuf);
+        C2_MacroAssembler _masm(cbuf);
         __ ld(R0, src_offset, R1_SP);
         __ std(R0, dst_offset, R1_SP);
         __ ld(R0, src_offset+8, R1_SP);
         __ std(R0, dst_offset+8, R1_SP);
       }
@@ -1765,33 +1767,33 @@
     // VectorSRegister->Memory Spill.
     else if (src_lo_rc == rc_vs && dst_lo_rc == rc_stack) {
       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
       int dst_offset = ra_->reg2offset(dst_lo);
       if (cbuf) {
-        MacroAssembler _masm(cbuf);
+        C2_MacroAssembler _masm(cbuf);
         __ addi(R0, R1_SP, dst_offset);
         __ stxvd2x(Rsrc, R0);
       }
       size += 8;
     }
     // Memory->VectorSRegister Spill.
     else if (src_lo_rc == rc_stack && dst_lo_rc == rc_vs) {
       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
       int src_offset = ra_->reg2offset(src_lo);
       if (cbuf) {
-        MacroAssembler _masm(cbuf);
+        C2_MacroAssembler _masm(cbuf);
         __ addi(R0, R1_SP, src_offset);
         __ lxvd2x(Rdst, R0);
       }
       size += 8;
     }
     // VectorSRegister->VectorSRegister.
     else if (src_lo_rc == rc_vs && dst_lo_rc == rc_vs) {
       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
       if (cbuf) {
-        MacroAssembler _masm(cbuf);
+        C2_MacroAssembler _masm(cbuf);
         __ xxlor(Rdst, Rsrc, Rsrc);
       }
       size += 4;
     }
     else {
@@ -1831,11 +1833,11 @@
       Register Rsrc = as_Register(Matcher::_regEncode[src_lo]);
       Register Rdst = as_Register(Matcher::_regEncode[dst_lo]);
       size = (Rsrc != Rdst) ? 4 : 0;
 
       if (cbuf) {
-        MacroAssembler _masm(cbuf);
+        C2_MacroAssembler _masm(cbuf);
         if (size) {
           __ mr(Rdst, Rsrc);
         }
       }
 #ifndef PRODUCT
@@ -1877,11 +1879,11 @@
   }
 
   // Check for float reg-reg copy.
   if (src_lo_rc == rc_float && dst_lo_rc == rc_float) {
     if (cbuf) {
-      MacroAssembler _masm(cbuf);
+      C2_MacroAssembler _masm(cbuf);
       FloatRegister Rsrc = as_FloatRegister(Matcher::_regEncode[src_lo]);
       FloatRegister Rdst = as_FloatRegister(Matcher::_regEncode[dst_lo]);
       __ fmr(Rdst, Rsrc);
     }
 #ifndef PRODUCT
@@ -2047,11 +2049,11 @@
   st->print("NOP \t// %d nops to pad for loops.", _count);
 }
 #endif
 
 void MachNopNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *) const {
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
   // _count contains the number of nops needed for padding.
   for (int i = 0; i < _count; i++) {
     __ nop();
   }
 }
@@ -2068,11 +2070,11 @@
   st->print("ADDI    %s, SP, %d \t// box node", reg_str, offset);
 }
 #endif
 
 void BoxLockNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
 
   int offset = ra_->reg2offset(in_RegMask(0).find_first_elem());
   int reg    = ra_->get_encode(this);
 
   if (Assembler::is_simm(offset, 16)) {
@@ -2094,11 +2096,11 @@
 }
 #endif
 
 void MachUEPNode::emit(CodeBuffer &cbuf, PhaseRegAlloc *ra_) const {
   // This is the unverified entry point.
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
 
   // Inline_cache contains a klass.
   Register ic_klass       = as_Register(Matcher::inline_cache_reg_encode());
   Register receiver_klass = R12_scratch2;  // tmp
 
@@ -2177,11 +2179,11 @@
 %} // end source_hpp
 
 source %{
 
 int HandlerImpl::emit_exception_handler(CodeBuffer &cbuf) {
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
 
   address base = __ start_a_stub(size_exception_handler());
   if (base == NULL) return 0; // CodeBuffer::expand failed
 
   int offset = __ offset();
@@ -2194,11 +2196,11 @@
 }
 
 // The deopt_handler is like the exception handler, but it calls to
 // the deoptimization blob instead of jumping to the exception blob.
 int HandlerImpl::emit_deopt_handler(CodeBuffer& cbuf) {
-  MacroAssembler _masm(&cbuf);
+  C2_MacroAssembler _masm(&cbuf);
 
   address base = __ start_a_stub(size_deopt_handler());
   if (base == NULL) return 0; // CodeBuffer::expand failed
 
   int offset = __ offset();
@@ -2658,111 +2660,111 @@
 // tertiary opcode. Only the opcode sections which a particular instruction
 // needs for encoding need to be specified.
 encode %{
   enc_class enc_unimplemented %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     __ unimplemented("Unimplemented mach node encoding in AD file.", 13);
   %}
 
   enc_class enc_untested %{
 #ifdef ASSERT
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     __ untested("Untested mach node encoding in AD file.");
 #else
     // TODO: PPC port $archOpcode(ppc64Opcode_none);
 #endif
   %}
 
   enc_class enc_lbz(iRegIdst dst, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_lbz);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
   %}
 
   // Load acquire.
   enc_class enc_lbz_ac(iRegIdst dst, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
     __ twi_0($dst$$Register);
     __ isync();
   %}
 
   enc_class enc_lhz(iRegIdst dst, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_lhz);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
   %}
 
   // Load acquire.
   enc_class enc_lhz_ac(iRegIdst dst, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
     __ twi_0($dst$$Register);
     __ isync();
   %}
 
   enc_class enc_lwz(iRegIdst dst, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_lwz);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
   %}
 
   // Load acquire.
   enc_class enc_lwz_ac(iRegIdst dst, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
     __ twi_0($dst$$Register);
     __ isync();
   %}
 
   enc_class enc_ld(iRegLdst dst, memoryAlg4 mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     // Operand 'ds' requires 4-alignment.
     assert((Idisp & 0x3) == 0, "unaligned offset");
     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
   %}
 
   // Load acquire.
   enc_class enc_ld_ac(iRegLdst dst, memoryAlg4 mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     // Operand 'ds' requires 4-alignment.
     assert((Idisp & 0x3) == 0, "unaligned offset");
     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
     __ twi_0($dst$$Register);
     __ isync();
   %}
 
   enc_class enc_lfd(RegF dst, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_lfd);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ lfd($dst$$FloatRegister, Idisp, $mem$$base$$Register);
   %}
 
   enc_class enc_load_long_constL(iRegLdst dst, immL src, iRegLdst toc) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int toc_offset = 0;
 
     address const_toc_addr;
     // Create a non-oop constant, no relocation needed.
     // If it is an IC, it has a virtual_call_Relocation.
@@ -2782,13 +2784,13 @@
   %}
 
   enc_class enc_load_long_constL_hi(iRegLdst dst, iRegLdst toc, immL src) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
 
-    if (!ra_->C->in_scratch_emit_size()) {
+    if (!ra_->C->output()->in_scratch_emit_size()) {
       address const_toc_addr;
       // Create a non-oop constant, no relocation needed.
       // If it is an IC, it has a virtual_call_Relocation.
       const_toc_addr = __ long_constant((jlong)$src$$constant);
       if (const_toc_addr == NULL) {
@@ -3017,11 +3019,11 @@
   %}
 
   enc_class enc_load_long_constP(iRegLdst dst, immP src, iRegLdst toc) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int toc_offset = 0;
 
     intptr_t val = $src$$constant;
     relocInfo::relocType constant_reloc = $src->constant_reloc();  // src
     address const_toc_addr;
@@ -3050,12 +3052,12 @@
   %}
 
   enc_class enc_load_long_constP_hi(iRegLdst dst, immP src, iRegLdst toc) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 
-    MacroAssembler _masm(&cbuf);
-    if (!ra_->C->in_scratch_emit_size()) {
+    C2_MacroAssembler _masm(&cbuf);
+    if (!ra_->C->output()->in_scratch_emit_size()) {
       intptr_t val = $src$$constant;
       relocInfo::relocType constant_reloc = $src->constant_reloc();  // src
       address const_toc_addr;
       if (constant_reloc == relocInfo::oop_type) {
         // Create an oop constant and a corresponding relocation.
@@ -3184,34 +3186,34 @@
     nodes->push(m2);
   %}
 
   enc_class enc_stw(iRegIsrc src, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_stw);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ stw($src$$Register, Idisp, $mem$$base$$Register);
   %}
 
   enc_class enc_std(iRegIsrc src, memoryAlg4 mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_std);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     // Operand 'ds' requires 4-alignment.
     assert((Idisp & 0x3) == 0, "unaligned offset");
     __ std($src$$Register, Idisp, $mem$$base$$Register);
   %}
 
   enc_class enc_stfs(RegF src, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_stfs);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ stfs($src$$FloatRegister, Idisp, $mem$$base$$Register);
   %}
 
   enc_class enc_stfd(RegF src, memory mem) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_stfd);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     __ stfd($src$$FloatRegister, Idisp, $mem$$base$$Register);
   %}
 
   // Use release_store for card-marking to ensure that previous
@@ -3228,11 +3230,11 @@
     // __ beq(CCRfixed, skip_release);
     // __ release();
     // __ bind(skip_release);
     // __ stb(card mark);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     Label skip_storestore;
 
 #if 0 // TODO: PPC port
     // Check CMSCollectorCardTableBarrierSetBSExt::_requires_release and do the
     // StoreStore barrier conditionally.
@@ -3449,11 +3451,11 @@
   %}
 
   enc_class enc_cmove_reg(iRegIdst dst, flagsRegSrc crx, iRegIsrc src, cmpOp cmp) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int cc        = $cmp$$cmpcode;
     int flags_reg = $crx$$reg;
     Label done;
     assert((Assembler::bcondCRbiIs1 & ~Assembler::bcondCRbiIs0) == 8, "check encoding");
     // Branch if not (cmp crx).
@@ -3464,11 +3466,11 @@
   %}
 
   enc_class enc_cmove_imm(iRegIdst dst, flagsRegSrc crx, immI16 src, cmpOp cmp) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     Label done;
     assert((Assembler::bcondCRbiIs1 & ~Assembler::bcondCRbiIs0) == 8, "check encoding");
     // Branch if not (cmp crx).
     __ bc(cc_to_inverse_boint($cmp$$cmpcode), cc_to_biint($cmp$$cmpcode, $crx$$reg), done);
     __ li($dst$$Register, $src$$constant);
@@ -3478,18 +3480,18 @@
 
   // This enc_class is needed so that scheduler gets proper
   // input mapping for latency computation.
   enc_class enc_andc(iRegIdst dst, iRegIsrc src1, iRegIsrc src2) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_andc);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     __ andc($dst$$Register, $src1$$Register, $src2$$Register);
   %}
 
   enc_class enc_convI2B_regI__cmove(iRegIdst dst, iRegIsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
 
     Label done;
     __ cmpwi($crx$$CondRegister, $src$$Register, 0);
     __ li($dst$$Register, $zero$$constant);
     __ beq($crx$$CondRegister, done);
@@ -3498,11 +3500,11 @@
   %}
 
   enc_class enc_convP2B_regP__cmove(iRegIdst dst, iRegPsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
 
     Label done;
     __ cmpdi($crx$$CondRegister, $src$$Register, 0);
     __ li($dst$$Register, $zero$$constant);
     __ beq($crx$$CondRegister, done);
@@ -3511,11 +3513,11 @@
   %}
 
   enc_class enc_cmove_bso_stackSlotL(iRegLdst dst, flagsRegSrc crx, stackSlotL mem ) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
     Label done;
     __ bso($crx$$CondRegister, done);
     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
     // TODO PPC port __ endgroup_if_needed(_size == 12);
@@ -3523,22 +3525,22 @@
   %}
 
   enc_class enc_cmove_bso_reg(iRegLdst dst, flagsRegSrc crx, regD src) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     Label done;
     __ bso($crx$$CondRegister, done);
     __ mffprd($dst$$Register, $src$$FloatRegister);
     // TODO PPC port __ endgroup_if_needed(_size == 12);
     __ bind(done);
   %}
 
   enc_class enc_bc(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     Label d;   // dummy
     __ bind(d);
     Label* p = ($lbl$$label);
     // `p' is `NULL' when this encoding class is used only to
     // determine the size of the encoded instruction.
@@ -3564,11 +3566,11 @@
   enc_class enc_bc_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
     // The scheduler doesn't know about branch shortening, so we set the opcode
     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     Label d;    // dummy
     __ bind(d);
     Label* p = ($lbl$$label);
     // `p' is `NULL' when this encoding class is used only to
     // determine the size of the encoded instruction.
@@ -3596,11 +3598,11 @@
   enc_class enc_bc_short_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
     // The scheduler doesn't know about branch shortening, so we set the opcode
     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     Label d;   // dummy
     __ bind(d);
     Label* p = ($lbl$$label);
     // `p' is `NULL' when this encoding class is used only to
     // determine the size of the encoded instruction.
@@ -3681,11 +3683,11 @@
   enc_class enc_poll(immI dst, iRegLdst poll) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
     // Fake operand dst needed for PPC scheduler.
     assert($dst$$constant == 0x0, "dst must be 0x0");
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     // Mark the code position where the load from the safepoint
     // polling page was emitted as relocInfo::poll_type.
     __ relocate(relocInfo::poll_type);
     __ load_from_polling_page($poll$$Register);
   %}
@@ -3737,11 +3739,11 @@
   //
   // Usage of r1 and r2 in the stubs allows to distinguish them.
   enc_class enc_java_static_call(method meth) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     address entry_point = (address)$meth$$method;
 
     if (!_method) {
       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
       emit_call_with_trampoline_stub(_masm, entry_point, relocInfo::runtime_call_type);
@@ -3787,13 +3789,13 @@
 
   // Second node of expanded dynamic call - the call.
   enc_class enc_java_dynamic_call_sched(method meth) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
 
-    if (!ra_->C->in_scratch_emit_size()) {
+    if (!ra_->C->output()->in_scratch_emit_size()) {
       // Create a call trampoline stub for the given method.
       const address entry_point = !($meth$$method) ? 0 : (address)$meth$$method;
       const address entry_point_const = __ address_constant(entry_point, RelocationHolder::none);
       if (entry_point_const == NULL) {
         ciEnv::current()->record_out_of_memory_failure();
@@ -3890,11 +3892,11 @@
   // Compound version of call dynamic
   // Toc is only passed so that it can be used in ins_encode statement.
   // In the code we have to use $constanttablebase.
   enc_class enc_java_dynamic_call(method meth, iRegLdst toc) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     int start_offset = __ offset();
 
     Register Rtoc = (ra_) ? $constanttablebase : R2_TOC;
 #if 0
     int vtable_index = this->_vtable_index;
@@ -3949,11 +3951,11 @@
 
   // a runtime call
   enc_class enc_java_to_runtime_call (method meth) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     const address start_pc = __ pc();
 
 #if defined(ABI_ELFv2)
     address entry= !($meth$$method) ? NULL : (address)$meth$$method;
     __ call_c(entry, relocInfo::runtime_call_type);
@@ -3982,11 +3984,11 @@
   // Move to ctr for leaf call.
   // This enc_class is needed so that scheduler gets proper
   // input mapping for latency computation.
   enc_class enc_leaf_call_mtctr(iRegLsrc src) %{
     // TODO: PPC port $archOpcode(ppc64Opcode_mtctr);
-    MacroAssembler _masm(&cbuf);
+    C2_MacroAssembler _masm(&cbuf);
     __ mtctr($src$$Register);
   %}
 
   // Postalloc expand emitter for runtime leaf calls.
   enc_class postalloc_expand_java_to_runtime_call(method meth, iRegLdst toc) %{
@@ -6283,11 +6285,11 @@
 
   format %{ "LD      $dst, offset, $base \t// load long $src from TOC (lo)" %}
   size(4);
   ins_encode %{
     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
-    int offset = ra_->C->in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node->_const_toc_offset;
+    int offset = ra_->C->output()->in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node->_const_toc_offset;
     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
   %}
   ins_pipe(pipe_class_memory);
 %}
 
@@ -6568,11 +6570,11 @@
 
   format %{ "LD      $dst, offset, $base \t// load ptr $src from TOC (lo)" %}
   size(4);
   ins_encode %{
     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
-    int offset = ra_->C->in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node->_const_toc_offset;
+    int offset = ra_->C->output()->in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node->_const_toc_offset;
     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
   %}
   ins_pipe(pipe_class_memory);
 %}
 
