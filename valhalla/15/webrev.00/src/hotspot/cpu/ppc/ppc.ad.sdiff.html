<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/ppc/ppc.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="macroAssembler_ppc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="templateTable_ppc_64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/ppc/ppc.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 1127 //=============================================================================
 1128 
 1129 // Compute padding required for nodes which need alignment. The padding
 1130 // is the number of bytes (not instructions) which will be inserted before
 1131 // the instruction. The padding must match the size of a NOP instruction.
 1132 
 1133 // Currently not used on this platform.
 1134 
 1135 //=============================================================================
 1136 
 1137 // Indicate if the safepoint node needs the polling page as an input.
 1138 bool SafePointNode::needs_polling_address_input() {
 1139   // The address is loaded from thread by a seperate node.
 1140   return true;
 1141 }
 1142 
 1143 //=============================================================================
 1144 
 1145 // Emit an interrupt that is caught by the debugger (for debugging compiler).
 1146 void emit_break(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 1147   MacroAssembler _masm(&amp;cbuf);</span>
 1148   __ illtrap();
 1149 }
 1150 
 1151 #ifndef PRODUCT
 1152 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1153   st-&gt;print(&quot;BREAKPOINT&quot;);
 1154 }
 1155 #endif
 1156 
 1157 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1158   emit_break(cbuf);
 1159 }
 1160 
 1161 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1162   return MachNode::size(ra_);
 1163 }
 1164 
 1165 //=============================================================================
 1166 
 1167 void emit_nop(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 1168   MacroAssembler _masm(&amp;cbuf);</span>
 1169   __ nop();
 1170 }
 1171 
 1172 static inline void emit_long(CodeBuffer &amp;cbuf, int value) {
 1173   *((int*)(cbuf.insts_end())) = value;
 1174   cbuf.set_insts_end(cbuf.insts_end() + BytesPerInstWord);
 1175 }
 1176 
 1177 //=============================================================================
 1178 
 1179 %} // interrupt source
 1180 
 1181 source_hpp %{ // Header information of the source block.
 1182 
 1183 //--------------------------------------------------------------
 1184 //---&lt;  Used for optimization in Compile::Shorten_branches  &gt;---
 1185 //--------------------------------------------------------------
 1186 


 1187 class CallStubImpl {
 1188 
 1189  public:
 1190 
 1191   // Emit call stub, compiled java to interpreter.
<span class="line-modified"> 1192   static void emit_trampoline_stub(MacroAssembler &amp;_masm, int destination_toc_offset, int insts_call_instruction_offset);</span>
 1193 
 1194   // Size of call trampoline stub.
 1195   // This doesn&#39;t need to be accurate to the byte, but it
 1196   // must be larger than or equal to the real size of the stub.
 1197   static uint size_call_trampoline() {
 1198     return MacroAssembler::trampoline_stub_size;
 1199   }
 1200 
 1201   // number of relocations needed by a call trampoline stub
 1202   static uint reloc_call_trampoline() {
 1203     return 5;
 1204   }
 1205 
 1206 };
 1207 
 1208 %} // end source_hpp
 1209 
 1210 source %{
 1211 
 1212 // Emit a trampoline stub for a call to a target which is too far away.
 1213 //
 1214 // code sequences:
 1215 //
 1216 // call-site:
 1217 //   branch-and-link to &lt;destination&gt; or &lt;trampoline stub&gt;
 1218 //
 1219 // Related trampoline stub for this call-site in the stub section:
 1220 //   load the call target from the constant pool
 1221 //   branch via CTR (LR/link still points to the call-site above)
 1222 
<span class="line-modified"> 1223 void CallStubImpl::emit_trampoline_stub(MacroAssembler &amp;_masm, int destination_toc_offset, int insts_call_instruction_offset) {</span>
 1224   address stub = __ emit_trampoline_stub(destination_toc_offset, insts_call_instruction_offset);
 1225   if (stub == NULL) {
 1226     ciEnv::current()-&gt;record_out_of_memory_failure();
 1227   }
 1228 }
 1229 
 1230 //=============================================================================
 1231 
 1232 // Emit an inline branch-and-link call and a related trampoline stub.
 1233 //
 1234 // code sequences:
 1235 //
 1236 // call-site:
 1237 //   branch-and-link to &lt;destination&gt; or &lt;trampoline stub&gt;
 1238 //
 1239 // Related trampoline stub for this call-site in the stub section:
 1240 //   load the call target from the constant pool
 1241 //   branch via CTR (LR/link still points to the call-site above)
 1242 //
 1243 
 1244 typedef struct {
 1245   int insts_call_instruction_offset;
 1246   int ret_addr_offset;
 1247 } EmitCallOffsets;
 1248 
 1249 // Emit a branch-and-link instruction that branches to a trampoline.
 1250 // - Remember the offset of the branch-and-link instruction.
 1251 // - Add a relocation at the branch-and-link instruction.
 1252 // - Emit a branch-and-link.
 1253 // - Remember the return pc offset.
<span class="line-modified"> 1254 EmitCallOffsets emit_call_with_trampoline_stub(MacroAssembler &amp;_masm, address entry_point, relocInfo::relocType rtype) {</span>
 1255   EmitCallOffsets offsets = { -1, -1 };
 1256   const int start_offset = __ offset();
 1257   offsets.insts_call_instruction_offset = __ offset();
 1258 
 1259   // No entry point given, use the current pc.
 1260   if (entry_point == NULL) entry_point = __ pc();
 1261 
 1262   // Put the entry point as a constant into the constant pool.
 1263   const address entry_point_toc_addr   = __ address_constant(entry_point, RelocationHolder::none);
 1264   if (entry_point_toc_addr == NULL) {
 1265     ciEnv::current()-&gt;record_out_of_memory_failure();
 1266     return offsets;
 1267   }
 1268   const int     entry_point_toc_offset = __ offset_to_method_toc(entry_point_toc_addr);
 1269 
 1270   // Emit the trampoline stub which will be related to the branch-and-link below.
 1271   CallStubImpl::emit_trampoline_stub(_masm, entry_point_toc_offset, offsets.insts_call_instruction_offset);
 1272   if (ciEnv::current()-&gt;failing()) { return offsets; } // Code cache may be full.
 1273   __ relocate(rtype);
 1274 
</pre>
<hr />
<pre>
 1280   offsets.ret_addr_offset = __ offset() - start_offset;
 1281 
 1282   return offsets;
 1283 }
 1284 
 1285 //=============================================================================
 1286 
 1287 // Factory for creating loadConL* nodes for large/small constant pool.
 1288 
 1289 static inline jlong replicate_immF(float con) {
 1290   // Replicate float con 2 times and pack into vector.
 1291   int val = *((int*)&amp;con);
 1292   jlong lval = val;
 1293   lval = (lval &lt;&lt; 32) | (lval &amp; 0xFFFFFFFFl);
 1294   return lval;
 1295 }
 1296 
 1297 //=============================================================================
 1298 
 1299 const RegMask&amp; MachConstantBaseNode::_out_RegMask = BITS64_CONSTANT_TABLE_BASE_mask();
<span class="line-modified"> 1300 int Compile::ConstantTable::calculate_table_base_offset() const {</span>
 1301   return 0;  // absolute addressing, no offset
 1302 }
 1303 
 1304 bool MachConstantBaseNode::requires_postalloc_expand() const { return true; }
 1305 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1306   iRegPdstOper *op_dst = new iRegPdstOper();
 1307   MachNode *m1 = new loadToc_hiNode();
 1308   MachNode *m2 = new loadToc_loNode();
 1309 
 1310   m1-&gt;add_req(NULL);
 1311   m2-&gt;add_req(NULL, m1);
 1312   m1-&gt;_opnds[0] = op_dst;
 1313   m2-&gt;_opnds[0] = op_dst;
 1314   m2-&gt;_opnds[1] = op_dst;
 1315   ra_-&gt;set_pair(m1-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 1316   ra_-&gt;set_pair(m2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 1317   nodes-&gt;push(m1);
 1318   nodes-&gt;push(m2);
 1319 }
 1320 
 1321 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1322   // Is postalloc expanded.
 1323   ShouldNotReachHere();
 1324 }
 1325 
 1326 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1327   return 0;
 1328 }
 1329 
 1330 #ifndef PRODUCT
 1331 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1332   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1333 }
 1334 #endif
 1335 
 1336 //=============================================================================
 1337 
 1338 #ifndef PRODUCT
 1339 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1340   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1341   const long framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1342 
 1343   st-&gt;print(&quot;PROLOG\n\t&quot;);
<span class="line-modified"> 1344   if (C-&gt;need_stack_bang(framesize)) {</span>
 1345     st-&gt;print(&quot;stack_overflow_check\n\t&quot;);
 1346   }
 1347 
 1348   if (!false /* TODO: PPC port C-&gt;is_frameless_method()*/) {
 1349     st-&gt;print(&quot;save return pc\n\t&quot;);
 1350     st-&gt;print(&quot;push frame %ld\n\t&quot;, -framesize);
 1351   }
 1352 }
 1353 #endif
 1354 
 1355 // Macro used instead of the common __ to emulate the pipes of PPC.
 1356 // Instead of e.g. __ ld(...) one hase to write ___(ld) ld(...) This enables the
 1357 // micro scheduler to cope with &quot;hand written&quot; assembler like in the prolog. Though
 1358 // still no scheduling of this code is possible, the micro scheduler is aware of the
 1359 // code and can update its internal data. The following mechanism is used to achieve this:
 1360 // The micro scheduler calls size() of each compound node during scheduling. size() does a
 1361 // dummy emit and only during this dummy emit C-&gt;hb_scheduling() is not NULL.
 1362 #if 0 // TODO: PPC port
 1363 #define ___(op) if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                    \
 1364                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;PdEmulatePipe(ppc64Opcode_##op); \
 1365                 _masm.
 1366 #define ___stop if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                    \
 1367                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;PdEmulatePipe(archOpcode_none)
 1368 #define ___advance if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                 \
 1369                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;advance_offset
 1370 #else
 1371 #define ___(op) if (UsePower6SchedulerPPC64)                                          \
 1372                   Unimplemented();                                                    \
 1373                 _masm.
 1374 #define ___stop if (UsePower6SchedulerPPC64)                                          \
 1375                   Unimplemented()
 1376 #define ___advance if (UsePower6SchedulerPPC64)                                       \
 1377                   Unimplemented()
 1378 #endif
 1379 
 1380 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1381   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1382   MacroAssembler _masm(&amp;cbuf);</span>
 1383 
<span class="line-modified"> 1384   const long framesize = C-&gt;frame_size_in_bytes();</span>
 1385   assert(framesize % (2 * wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1386 
 1387   const bool method_is_frameless      = false /* TODO: PPC port C-&gt;is_frameless_method()*/;
 1388 
 1389   const Register return_pc            = R20; // Must match return_addr() in frame section.
 1390   const Register callers_sp           = R21;
 1391   const Register push_frame_temp      = R22;
 1392   const Register toc_temp             = R23;
 1393   assert_different_registers(R11, return_pc, callers_sp, push_frame_temp, toc_temp);
 1394 
 1395   if (method_is_frameless) {
 1396     // Add nop at beginning of all frameless methods to prevent any
 1397     // oop instructions from getting overwritten by make_not_entrant
 1398     // (patching attempt would fail).
 1399     ___(nop) nop();
 1400   } else {
 1401     // Get return pc.
 1402     ___(mflr) mflr(return_pc);
 1403   }
 1404 
</pre>
<hr />
<pre>
 1409     Register klass = toc_temp;
 1410 
 1411     // Notify OOP recorder (don&#39;t need the relocation)
 1412     AddressLiteral md = __ constant_metadata_address(C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1413     __ load_const_optimized(klass, md.value(), R0);
 1414     __ clinit_barrier(klass, R16_thread, &amp;L_skip_barrier /*L_fast_path*/);
 1415 
 1416     __ load_const_optimized(klass, SharedRuntime::get_handle_wrong_method_stub(), R0);
 1417     __ mtctr(klass);
 1418     __ bctr();
 1419 
 1420     __ bind(L_skip_barrier);
 1421   }
 1422 
 1423   // Calls to C2R adapters often do not accept exceptional returns.
 1424   // We require that their callers must bang for them. But be
 1425   // careful, because some VM calls (such as call site linkage) can
 1426   // use several kilobytes of stack. But the stack safety zone should
 1427   // account for that. See bugs 4446381, 4468289, 4497237.
 1428 
<span class="line-modified"> 1429   int bangsize = C-&gt;bang_size_in_bytes();</span>
 1430   assert(bangsize &gt;= framesize || bangsize &lt;= 0, &quot;stack bang size incorrect&quot;);
<span class="line-modified"> 1431   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging) {</span>
 1432     // Unfortunately we cannot use the function provided in
 1433     // assembler.cpp as we have to emulate the pipes. So I had to
 1434     // insert the code of generate_stack_overflow_check(), see
 1435     // assembler.cpp for some illuminative comments.
 1436     const int page_size = os::vm_page_size();
 1437     int bang_end = JavaThread::stack_shadow_zone_size();
 1438 
 1439     // This is how far the previous frame&#39;s stack banging extended.
 1440     const int bang_end_safe = bang_end;
 1441 
 1442     if (bangsize &gt; page_size) {
 1443       bang_end += bangsize;
 1444     }
 1445 
 1446     int bang_offset = bang_end_safe;
 1447 
 1448     while (bang_offset &lt;= bang_end) {
 1449       // Need at least one stack bang at end of shadow zone.
 1450 
 1451       // Again I had to copy code, this time from assembler_ppc.cpp,
</pre>
<hr />
<pre>
 1465         }
 1466       } else if (Assembler::is_simm(stdoffset, 31)) {
 1467         // Use largeoffset calculations for addis &amp; ld/std.
 1468         const int hi = MacroAssembler::largeoffset_si16_si16_hi(stdoffset);
 1469         const int lo = MacroAssembler::largeoffset_si16_si16_lo(stdoffset);
 1470 
 1471         Register tmp = R11;
 1472         ___(addis) addis(tmp, R1_SP, hi);
 1473         if (UseLoadInstructionsForStackBangingPPC64) {
 1474           ___(ld) ld(R0, lo, tmp);
 1475         } else {
 1476           ___(std) std(R0, lo, tmp);
 1477         }
 1478       } else {
 1479         ShouldNotReachHere();
 1480       }
 1481 
 1482       bang_offset += page_size;
 1483     }
 1484     // R11 trashed
<span class="line-modified"> 1485   } // C-&gt;need_stack_bang(framesize) &amp;&amp; UseStackBanging</span>
 1486 
 1487   unsigned int bytes = (unsigned int)framesize;
 1488   long offset = Assembler::align_addr(bytes, frame::alignment_in_bytes);
 1489   ciMethod *currMethod = C-&gt;method();
 1490 
 1491   // Optimized version for most common case.
 1492   if (UsePower6SchedulerPPC64 &amp;&amp;
 1493       !method_is_frameless &amp;&amp; Assembler::is_simm((int)(-offset), 16) &amp;&amp;
 1494       !(false /* ConstantsALot TODO: PPC port*/)) {
 1495     ___(or) mr(callers_sp, R1_SP);
 1496     ___(std) std(return_pc, _abi(lr), R1_SP);
 1497     ___(stdu) stdu(R1_SP, -offset, R1_SP);
 1498     return;
 1499   }
 1500 
 1501   if (!method_is_frameless) {
 1502     // Get callers sp.
 1503     ___(or) mr(callers_sp, R1_SP);
 1504 
 1505     // Push method&#39;s frame, modifies SP.
</pre>
<hr />
<pre>
 1520       ___(ori)    ori( tmp, tmp, (x &amp; 0x0000ffff));
 1521 
 1522       ___(stdux) stdux(R1_SP, R1_SP, tmp);
 1523     }
 1524   }
 1525 #if 0 // TODO: PPC port
 1526   // For testing large constant pools, emit a lot of constants to constant pool.
 1527   // &quot;Randomize&quot; const_size.
 1528   if (ConstantsALot) {
 1529     const int num_consts = const_size();
 1530     for (int i = 0; i &lt; num_consts; i++) {
 1531       __ long_constant(0xB0B5B00BBABE);
 1532     }
 1533   }
 1534 #endif
 1535   if (!method_is_frameless) {
 1536     // Save return pc.
 1537     ___(std) std(return_pc, _abi(lr), callers_sp);
 1538   }
 1539 
<span class="line-modified"> 1540   C-&gt;set_frame_complete(cbuf.insts_size());</span>
 1541 }
 1542 #undef ___
 1543 #undef ___stop
 1544 #undef ___advance
 1545 
 1546 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
 1547   // Variable size. determine dynamically.
 1548   return MachNode::size(ra_);
 1549 }
 1550 
 1551 int MachPrologNode::reloc() const {
 1552   // Return number of relocatable values contained in this instruction.
 1553   return 1; // 1 reloc entry for load_const(toc).
 1554 }
 1555 
 1556 //=============================================================================
 1557 
 1558 #ifndef PRODUCT
 1559 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1560   Compile* C = ra_-&gt;C;
 1561 
 1562   st-&gt;print(&quot;EPILOG\n\t&quot;);
 1563   st-&gt;print(&quot;restore return pc\n\t&quot;);
 1564   st-&gt;print(&quot;pop frame\n\t&quot;);
 1565 
 1566   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1567     st-&gt;print(&quot;touch polling page\n\t&quot;);
 1568   }
 1569 }
 1570 #endif
 1571 
 1572 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1573   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1574   MacroAssembler _masm(&amp;cbuf);</span>
 1575 
<span class="line-modified"> 1576   const long framesize = ((long)C-&gt;frame_slots()) &lt;&lt; LogBytesPerInt;</span>
 1577   assert(framesize &gt;= 0, &quot;negative frame-size?&quot;);
 1578 
 1579   const bool method_needs_polling = do_polling() &amp;&amp; C-&gt;is_method_compilation();
 1580   const bool method_is_frameless  = false /* TODO: PPC port C-&gt;is_frameless_method()*/;
 1581   const Register return_pc        = R31;  // Must survive C-call to enable_stack_reserved_zone().
 1582   const Register polling_page     = R12;
 1583 
 1584   if (!method_is_frameless) {
 1585     // Restore return pc relative to callers&#39; sp.
 1586     __ ld(return_pc, ((int)framesize) + _abi(lr), R1_SP);
 1587   }
 1588 
 1589   if (method_needs_polling) {
 1590     if (SafepointMechanism::uses_thread_local_poll()) {
 1591       __ ld(polling_page, in_bytes(JavaThread::polling_page_offset()), R16_thread);
 1592     } else {
 1593       __ load_const_optimized(polling_page, (long)(address) os::get_polling_page());
 1594     }
 1595   }
 1596 
</pre>
<hr />
<pre>
 1620 
 1621 int MachEpilogNode::reloc() const {
 1622   // Return number of relocatable values contained in this instruction.
 1623   return 1; // 1 for load_from_polling_page.
 1624 }
 1625 
 1626 const Pipeline * MachEpilogNode::pipeline() const {
 1627   return MachNode::pipeline_class();
 1628 }
 1629 
 1630 // This method seems to be obsolete. It is declared in machnode.hpp
 1631 // and defined in all *.ad files, but it is never called. Should we
 1632 // get rid of it?
 1633 int MachEpilogNode::safepoint_offset() const {
 1634   assert(do_polling(), &quot;no return for this epilog node&quot;);
 1635   return 0;
 1636 }
 1637 
 1638 #if 0 // TODO: PPC port
 1639 void MachLoadPollAddrLateNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
<span class="line-modified"> 1640   MacroAssembler _masm(&amp;cbuf);</span>
 1641   if (LoadPollAddressFromThread) {
 1642     _masm.ld(R11, in_bytes(JavaThread::poll_address_offset()), R16_thread);
 1643   } else {
 1644     _masm.nop();
 1645   }
 1646 }
 1647 
 1648 uint MachLoadPollAddrLateNode::size(PhaseRegAlloc* ra_) const {
 1649   if (LoadPollAddressFromThread) {
 1650     return 4;
 1651   } else {
 1652     return 4;
 1653   }
 1654 }
 1655 
 1656 #ifndef PRODUCT
 1657 void MachLoadPollAddrLateNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1658   st-&gt;print_cr(&quot; LD R11, PollAddressOffset, R16_thread \t// LoadPollAddressFromThread&quot;);
 1659 }
 1660 #endif
</pre>
<hr />
<pre>
 1737   enum RC dst_hi_rc = rc_class(dst_hi);
 1738   enum RC dst_lo_rc = rc_class(dst_lo);
 1739 
 1740   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1741   if (src_hi != OptoReg::Bad)
 1742     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1743            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1744            &quot;expected aligned-adjacent pairs&quot;);
 1745   // Generate spill code!
 1746   int size = 0;
 1747 
 1748   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi)
 1749     return size;            // Self copy, no move.
 1750 
 1751   if (bottom_type()-&gt;isa_vect() != NULL &amp;&amp; ideal_reg() == Op_VecX) {
 1752     // Memory-&gt;Memory Spill.
 1753     if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1754       int src_offset = ra_-&gt;reg2offset(src_lo);
 1755       int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1756       if (cbuf) {
<span class="line-modified"> 1757         MacroAssembler _masm(cbuf);</span>
 1758         __ ld(R0, src_offset, R1_SP);
 1759         __ std(R0, dst_offset, R1_SP);
 1760         __ ld(R0, src_offset+8, R1_SP);
 1761         __ std(R0, dst_offset+8, R1_SP);
 1762       }
 1763       size += 16;
 1764     }
 1765     // VectorSRegister-&gt;Memory Spill.
 1766     else if (src_lo_rc == rc_vs &amp;&amp; dst_lo_rc == rc_stack) {
 1767       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
 1768       int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1769       if (cbuf) {
<span class="line-modified"> 1770         MacroAssembler _masm(cbuf);</span>
 1771         __ addi(R0, R1_SP, dst_offset);
 1772         __ stxvd2x(Rsrc, R0);
 1773       }
 1774       size += 8;
 1775     }
 1776     // Memory-&gt;VectorSRegister Spill.
 1777     else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_vs) {
 1778       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
 1779       int src_offset = ra_-&gt;reg2offset(src_lo);
 1780       if (cbuf) {
<span class="line-modified"> 1781         MacroAssembler _masm(cbuf);</span>
 1782         __ addi(R0, R1_SP, src_offset);
 1783         __ lxvd2x(Rdst, R0);
 1784       }
 1785       size += 8;
 1786     }
 1787     // VectorSRegister-&gt;VectorSRegister.
 1788     else if (src_lo_rc == rc_vs &amp;&amp; dst_lo_rc == rc_vs) {
 1789       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
 1790       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
 1791       if (cbuf) {
<span class="line-modified"> 1792         MacroAssembler _masm(cbuf);</span>
 1793         __ xxlor(Rdst, Rsrc, Rsrc);
 1794       }
 1795       size += 4;
 1796     }
 1797     else {
 1798       ShouldNotReachHere(); // No VSR spill.
 1799     }
 1800     return size;
 1801   }
 1802 
 1803   // --------------------------------------
 1804   // Memory-&gt;Memory Spill. Use R0 to hold the value.
 1805   if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1806     int src_offset = ra_-&gt;reg2offset(src_lo);
 1807     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1808     if (src_hi != OptoReg::Bad) {
 1809       assert(src_hi_rc==rc_stack &amp;&amp; dst_hi_rc==rc_stack,
 1810              &quot;expected same type of move for high parts&quot;);
 1811       size += ld_st_helper(cbuf, &quot;LD  &quot;, Assembler::LD_OPCODE,  R0_num, src_offset, !do_size, C, st);
 1812       if (!cbuf &amp;&amp; !do_size) st-&gt;print(&quot;\n\t&quot;);
</pre>
<hr />
<pre>
 1816       if (!cbuf &amp;&amp; !do_size) st-&gt;print(&quot;\n\t&quot;);
 1817       size += ld_st_helper(cbuf, &quot;STW &quot;, Assembler::STW_OPCODE, R0_num, dst_offset, !do_size, C, st);
 1818     }
 1819     return size;
 1820   }
 1821 
 1822   // --------------------------------------
 1823   // Check for float-&gt;int copy; requires a trip through memory.
 1824   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_int) {
 1825     Unimplemented();
 1826   }
 1827 
 1828   // --------------------------------------
 1829   // Check for integer reg-reg copy.
 1830   if (src_lo_rc == rc_int &amp;&amp; dst_lo_rc == rc_int) {
 1831       Register Rsrc = as_Register(Matcher::_regEncode[src_lo]);
 1832       Register Rdst = as_Register(Matcher::_regEncode[dst_lo]);
 1833       size = (Rsrc != Rdst) ? 4 : 0;
 1834 
 1835       if (cbuf) {
<span class="line-modified"> 1836         MacroAssembler _masm(cbuf);</span>
 1837         if (size) {
 1838           __ mr(Rdst, Rsrc);
 1839         }
 1840       }
 1841 #ifndef PRODUCT
 1842       else if (!do_size) {
 1843         if (size) {
 1844           st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;MR&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1845         } else {
 1846           st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;MR-NOP&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1847         }
 1848       }
 1849 #endif
 1850       return size;
 1851   }
 1852 
 1853   // Check for integer store.
 1854   if (src_lo_rc == rc_int &amp;&amp; dst_lo_rc == rc_stack) {
 1855     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1856     if (src_hi != OptoReg::Bad) {
</pre>
<hr />
<pre>
 1862     }
 1863     return size;
 1864   }
 1865 
 1866   // Check for integer load.
 1867   if (dst_lo_rc == rc_int &amp;&amp; src_lo_rc == rc_stack) {
 1868     int src_offset = ra_-&gt;reg2offset(src_lo);
 1869     if (src_hi != OptoReg::Bad) {
 1870       assert(dst_hi_rc==rc_int &amp;&amp; src_hi_rc==rc_stack,
 1871              &quot;expected same type of move for high parts&quot;);
 1872       size += ld_st_helper(cbuf, &quot;LD  &quot;, Assembler::LD_OPCODE, dst_lo, src_offset, !do_size, C, st);
 1873     } else {
 1874       size += ld_st_helper(cbuf, &quot;LWZ &quot;, Assembler::LWZ_OPCODE, dst_lo, src_offset, !do_size, C, st);
 1875     }
 1876     return size;
 1877   }
 1878 
 1879   // Check for float reg-reg copy.
 1880   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1881     if (cbuf) {
<span class="line-modified"> 1882       MacroAssembler _masm(cbuf);</span>
 1883       FloatRegister Rsrc = as_FloatRegister(Matcher::_regEncode[src_lo]);
 1884       FloatRegister Rdst = as_FloatRegister(Matcher::_regEncode[dst_lo]);
 1885       __ fmr(Rdst, Rsrc);
 1886     }
 1887 #ifndef PRODUCT
 1888     else if (!do_size) {
 1889       st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;FMR&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1890     }
 1891 #endif
 1892     return 4;
 1893   }
 1894 
 1895   // Check for float store.
 1896   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1897     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1898     if (src_hi != OptoReg::Bad) {
 1899       assert(src_hi_rc==rc_float &amp;&amp; dst_hi_rc==rc_stack,
 1900              &quot;expected same type of move for high parts&quot;);
 1901       size += ld_st_helper(cbuf, &quot;STFD&quot;, Assembler::STFD_OPCODE, src_lo, dst_offset, !do_size, C, st);
 1902     } else {
</pre>
<hr />
<pre>
 2032 
 2033   // --------------------------------------------------------------------
 2034   // Check for hi bits still needing moving. Only happens for misaligned
 2035   // arguments to native calls.
 2036   if (src_hi == dst_hi) {
 2037     return ppc64Opcode_none;               // Self copy; no move.
 2038   }
 2039 
 2040   ShouldNotReachHere();
 2041   return ppc64Opcode_undefined;
 2042 }
 2043 #endif // PPC port
 2044 
 2045 #ifndef PRODUCT
 2046 void MachNopNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2047   st-&gt;print(&quot;NOP \t// %d nops to pad for loops.&quot;, _count);
 2048 }
 2049 #endif
 2050 
 2051 void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *) const {
<span class="line-modified"> 2052   MacroAssembler _masm(&amp;cbuf);</span>
 2053   // _count contains the number of nops needed for padding.
 2054   for (int i = 0; i &lt; _count; i++) {
 2055     __ nop();
 2056   }
 2057 }
 2058 
 2059 uint MachNopNode::size(PhaseRegAlloc *ra_) const {
 2060   return _count * 4;
 2061 }
 2062 
 2063 #ifndef PRODUCT
 2064 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2065   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 2066   char reg_str[128];
 2067   ra_-&gt;dump_register(this, reg_str);
 2068   st-&gt;print(&quot;ADDI    %s, SP, %d \t// box node&quot;, reg_str, offset);
 2069 }
 2070 #endif
 2071 
 2072 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 2073   MacroAssembler _masm(&amp;cbuf);</span>
 2074 
 2075   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 2076   int reg    = ra_-&gt;get_encode(this);
 2077 
 2078   if (Assembler::is_simm(offset, 16)) {
 2079     __ addi(as_Register(reg), R1, offset);
 2080   } else {
 2081     ShouldNotReachHere();
 2082   }
 2083 }
 2084 
 2085 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 2086   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 2087   return 4;
 2088 }
 2089 
 2090 #ifndef PRODUCT
 2091 void MachUEPNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2092   st-&gt;print_cr(&quot;---- MachUEPNode ----&quot;);
 2093   st-&gt;print_cr(&quot;...&quot;);
 2094 }
 2095 #endif
 2096 
 2097 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 2098   // This is the unverified entry point.
<span class="line-modified"> 2099   MacroAssembler _masm(&amp;cbuf);</span>
 2100 
 2101   // Inline_cache contains a klass.
 2102   Register ic_klass       = as_Register(Matcher::inline_cache_reg_encode());
 2103   Register receiver_klass = R12_scratch2;  // tmp
 2104 
 2105   assert_different_registers(ic_klass, receiver_klass, R11_scratch1, R3_ARG1);
 2106   assert(R11_scratch1 == R11, &quot;need prologue scratch register&quot;);
 2107 
 2108   // Check for NULL argument if we don&#39;t have implicit null checks.
 2109   if (!ImplicitNullChecks || !os::zero_page_read_protected()) {
 2110     if (TrapBasedNullChecks) {
 2111       __ trap_null_check(R3_ARG1);
 2112     } else {
 2113       Label valid;
 2114       __ cmpdi(CCR0, R3_ARG1, 0);
 2115       __ bne_predict_taken(CCR0, valid);
 2116       // We have a null argument, branch to ic_miss_stub.
 2117       __ b64_patchable((address)SharedRuntime::get_ic_miss_stub(),
 2118                            relocInfo::runtime_call_type);
 2119       __ bind(valid);
</pre>
<hr />
<pre>
 2162   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 2163   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 2164 
 2165   static uint size_exception_handler() {
 2166     // The exception_handler is a b64_patchable.
 2167     return MacroAssembler::b64_patchable_size;
 2168   }
 2169 
 2170   static uint size_deopt_handler() {
 2171     // The deopt_handler is a bl64_patchable.
 2172     return MacroAssembler::bl64_patchable_size;
 2173   }
 2174 
 2175 };
 2176 
 2177 %} // end source_hpp
 2178 
 2179 source %{
 2180 
 2181 int HandlerImpl::emit_exception_handler(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 2182   MacroAssembler _masm(&amp;cbuf);</span>
 2183 
 2184   address base = __ start_a_stub(size_exception_handler());
 2185   if (base == NULL) return 0; // CodeBuffer::expand failed
 2186 
 2187   int offset = __ offset();
 2188   __ b64_patchable((address)OptoRuntime::exception_blob()-&gt;content_begin(),
 2189                        relocInfo::runtime_call_type);
 2190   assert(__ offset() - offset == (int)size_exception_handler(), &quot;must be fixed size&quot;);
 2191   __ end_a_stub();
 2192 
 2193   return offset;
 2194 }
 2195 
 2196 // The deopt_handler is like the exception handler, but it calls to
 2197 // the deoptimization blob instead of jumping to the exception blob.
 2198 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf) {
<span class="line-modified"> 2199   MacroAssembler _masm(&amp;cbuf);</span>
 2200 
 2201   address base = __ start_a_stub(size_deopt_handler());
 2202   if (base == NULL) return 0; // CodeBuffer::expand failed
 2203 
 2204   int offset = __ offset();
 2205   __ bl64_patchable((address)SharedRuntime::deopt_blob()-&gt;unpack(),
 2206                         relocInfo::runtime_call_type);
 2207   assert(__ offset() - offset == (int) size_deopt_handler(), &quot;must be fixed size&quot;);
 2208   __ end_a_stub();
 2209 
 2210   return offset;
 2211 }
 2212 
 2213 //=============================================================================
 2214 
 2215 // Use a frame slots bias for frameless methods if accessing the stack.
 2216 static int frame_slots_bias(int reg_enc, PhaseRegAlloc* ra_) {
 2217   if (as_Register(reg_enc) == R1_SP) {
 2218     return 0; // TODO: PPC port ra_-&gt;C-&gt;frame_slots_sp_bias_in_bytes();
 2219   }
</pre>
<hr />
<pre>
 2643 // operand to generate a function which returns its register number when
 2644 // queried. CONST_INTER causes an operand to generate a function which
 2645 // returns the value of the constant when queried. MEMORY_INTER causes an
 2646 // operand to generate four functions which return the Base Register, the
 2647 // Index Register, the Scale Value, and the Offset Value of the operand when
 2648 // queried. COND_INTER causes an operand to generate six functions which
 2649 // return the encoding code (ie - encoding bits for the instruction)
 2650 // associated with each basic boolean condition for a conditional instruction.
 2651 //
 2652 // Instructions specify two basic values for encoding. Again, a function
 2653 // is available to check if the constant displacement is an oop. They use the
 2654 // ins_encode keyword to specify their encoding classes (which must be
 2655 // a sequence of enc_class names, and their parameters, specified in
 2656 // the encoding block), and they use the
 2657 // opcode keyword to specify, in order, their primary, secondary, and
 2658 // tertiary opcode. Only the opcode sections which a particular instruction
 2659 // needs for encoding need to be specified.
 2660 encode %{
 2661   enc_class enc_unimplemented %{
 2662     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2663     MacroAssembler _masm(&amp;cbuf);</span>
 2664     __ unimplemented(&quot;Unimplemented mach node encoding in AD file.&quot;, 13);
 2665   %}
 2666 
 2667   enc_class enc_untested %{
 2668 #ifdef ASSERT
 2669     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2670     MacroAssembler _masm(&amp;cbuf);</span>
 2671     __ untested(&quot;Untested mach node encoding in AD file.&quot;);
 2672 #else
 2673     // TODO: PPC port $archOpcode(ppc64Opcode_none);
 2674 #endif
 2675   %}
 2676 
 2677   enc_class enc_lbz(iRegIdst dst, memory mem) %{
 2678     // TODO: PPC port $archOpcode(ppc64Opcode_lbz);
<span class="line-modified"> 2679     MacroAssembler _masm(&amp;cbuf);</span>
 2680     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2681     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
 2682   %}
 2683 
 2684   // Load acquire.
 2685   enc_class enc_lbz_ac(iRegIdst dst, memory mem) %{
 2686     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2687     MacroAssembler _masm(&amp;cbuf);</span>
 2688     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2689     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
 2690     __ twi_0($dst$$Register);
 2691     __ isync();
 2692   %}
 2693 
 2694   enc_class enc_lhz(iRegIdst dst, memory mem) %{
 2695     // TODO: PPC port $archOpcode(ppc64Opcode_lhz);
 2696 
<span class="line-modified"> 2697     MacroAssembler _masm(&amp;cbuf);</span>
 2698     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2699     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
 2700   %}
 2701 
 2702   // Load acquire.
 2703   enc_class enc_lhz_ac(iRegIdst dst, memory mem) %{
 2704     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 2705 
<span class="line-modified"> 2706     MacroAssembler _masm(&amp;cbuf);</span>
 2707     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2708     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
 2709     __ twi_0($dst$$Register);
 2710     __ isync();
 2711   %}
 2712 
 2713   enc_class enc_lwz(iRegIdst dst, memory mem) %{
 2714     // TODO: PPC port $archOpcode(ppc64Opcode_lwz);
 2715 
<span class="line-modified"> 2716     MacroAssembler _masm(&amp;cbuf);</span>
 2717     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2718     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
 2719   %}
 2720 
 2721   // Load acquire.
 2722   enc_class enc_lwz_ac(iRegIdst dst, memory mem) %{
 2723     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 2724 
<span class="line-modified"> 2725     MacroAssembler _masm(&amp;cbuf);</span>
 2726     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2727     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
 2728     __ twi_0($dst$$Register);
 2729     __ isync();
 2730   %}
 2731 
 2732   enc_class enc_ld(iRegLdst dst, memoryAlg4 mem) %{
 2733     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 2734     MacroAssembler _masm(&amp;cbuf);</span>
 2735     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2736     // Operand &#39;ds&#39; requires 4-alignment.
 2737     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 2738     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 2739   %}
 2740 
 2741   // Load acquire.
 2742   enc_class enc_ld_ac(iRegLdst dst, memoryAlg4 mem) %{
 2743     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2744     MacroAssembler _masm(&amp;cbuf);</span>
 2745     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2746     // Operand &#39;ds&#39; requires 4-alignment.
 2747     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 2748     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 2749     __ twi_0($dst$$Register);
 2750     __ isync();
 2751   %}
 2752 
 2753   enc_class enc_lfd(RegF dst, memory mem) %{
 2754     // TODO: PPC port $archOpcode(ppc64Opcode_lfd);
<span class="line-modified"> 2755     MacroAssembler _masm(&amp;cbuf);</span>
 2756     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2757     __ lfd($dst$$FloatRegister, Idisp, $mem$$base$$Register);
 2758   %}
 2759 
 2760   enc_class enc_load_long_constL(iRegLdst dst, immL src, iRegLdst toc) %{
 2761     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 2762 
<span class="line-modified"> 2763     MacroAssembler _masm(&amp;cbuf);</span>
 2764     int toc_offset = 0;
 2765 
 2766     address const_toc_addr;
 2767     // Create a non-oop constant, no relocation needed.
 2768     // If it is an IC, it has a virtual_call_Relocation.
 2769     const_toc_addr = __ long_constant((jlong)$src$$constant);
 2770     if (const_toc_addr == NULL) {
 2771       ciEnv::current()-&gt;record_out_of_memory_failure();
 2772       return;
 2773     }
 2774 
 2775     // Get the constant&#39;s TOC offset.
 2776     toc_offset = __ offset_to_method_toc(const_toc_addr);
 2777 
 2778     // Keep the current instruction offset in mind.
 2779     ((loadConLNode*)this)-&gt;_cbuf_insts_offset = __ offset();
 2780 
 2781     __ ld($dst$$Register, toc_offset, $toc$$Register);
 2782   %}
 2783 
 2784   enc_class enc_load_long_constL_hi(iRegLdst dst, iRegLdst toc, immL src) %{
 2785     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 2786 
<span class="line-modified"> 2787     MacroAssembler _masm(&amp;cbuf);</span>
 2788 
<span class="line-modified"> 2789     if (!ra_-&gt;C-&gt;in_scratch_emit_size()) {</span>
 2790       address const_toc_addr;
 2791       // Create a non-oop constant, no relocation needed.
 2792       // If it is an IC, it has a virtual_call_Relocation.
 2793       const_toc_addr = __ long_constant((jlong)$src$$constant);
 2794       if (const_toc_addr == NULL) {
 2795         ciEnv::current()-&gt;record_out_of_memory_failure();
 2796         return;
 2797       }
 2798 
 2799       // Get the constant&#39;s TOC offset.
 2800       const int toc_offset = __ offset_to_method_toc(const_toc_addr);
 2801       // Store the toc offset of the constant.
 2802       ((loadConL_hiNode*)this)-&gt;_const_toc_offset = toc_offset;
 2803 
 2804       // Also keep the current instruction offset in mind.
 2805       ((loadConL_hiNode*)this)-&gt;_cbuf_insts_offset = __ offset();
 2806     }
 2807 
 2808     __ addis($dst$$Register, $toc$$Register, MacroAssembler::largeoffset_si16_si16_hi(_const_toc_offset));
 2809   %}
</pre>
<hr />
<pre>
 3002   // Enc_class needed as consttanttablebase is not supported by postalloc
 3003   // expand.
 3004   enc_class postalloc_expand_load_long_constant(iRegLdst dst, immL src, iRegLdst toc) %{
 3005     // Create new nodes.
 3006     loadConLNodesTuple loadConLNodes =
 3007       loadConLNodesTuple_create(ra_, n_toc, op_src,
 3008                                 ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3009 
 3010     // Push new nodes.
 3011     if (loadConLNodes._large_hi) nodes-&gt;push(loadConLNodes._large_hi);
 3012     if (loadConLNodes._last)     nodes-&gt;push(loadConLNodes._last);
 3013 
 3014     // some asserts
 3015     assert(nodes-&gt;length() &gt;= 1, &quot;must have created at least 1 node&quot;);
 3016     assert(loadConLNodes._last-&gt;bottom_type()-&gt;isa_long(), &quot;must be long&quot;);
 3017   %}
 3018 
 3019   enc_class enc_load_long_constP(iRegLdst dst, immP src, iRegLdst toc) %{
 3020     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 3021 
<span class="line-modified"> 3022     MacroAssembler _masm(&amp;cbuf);</span>
 3023     int toc_offset = 0;
 3024 
 3025     intptr_t val = $src$$constant;
 3026     relocInfo::relocType constant_reloc = $src-&gt;constant_reloc();  // src
 3027     address const_toc_addr;
 3028     if (constant_reloc == relocInfo::oop_type) {
 3029       // Create an oop constant and a corresponding relocation.
 3030       AddressLiteral a = __ allocate_oop_address((jobject)val);
 3031       const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3032       __ relocate(a.rspec());
 3033     } else if (constant_reloc == relocInfo::metadata_type) {
 3034       AddressLiteral a = __ constant_metadata_address((Metadata *)val);
 3035       const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3036       __ relocate(a.rspec());
 3037     } else {
 3038       // Create a non-oop constant, no relocation needed.
 3039       const_toc_addr = __ long_constant((jlong)$src$$constant);
 3040     }
 3041 
 3042     if (const_toc_addr == NULL) {
 3043       ciEnv::current()-&gt;record_out_of_memory_failure();
 3044       return;
 3045     }
 3046     // Get the constant&#39;s TOC offset.
 3047     toc_offset = __ offset_to_method_toc(const_toc_addr);
 3048 
 3049     __ ld($dst$$Register, toc_offset, $toc$$Register);
 3050   %}
 3051 
 3052   enc_class enc_load_long_constP_hi(iRegLdst dst, immP src, iRegLdst toc) %{
 3053     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 3054 
<span class="line-modified"> 3055     MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 3056     if (!ra_-&gt;C-&gt;in_scratch_emit_size()) {</span>
 3057       intptr_t val = $src$$constant;
 3058       relocInfo::relocType constant_reloc = $src-&gt;constant_reloc();  // src
 3059       address const_toc_addr;
 3060       if (constant_reloc == relocInfo::oop_type) {
 3061         // Create an oop constant and a corresponding relocation.
 3062         AddressLiteral a = __ allocate_oop_address((jobject)val);
 3063         const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3064         __ relocate(a.rspec());
 3065       } else if (constant_reloc == relocInfo::metadata_type) {
 3066         AddressLiteral a = __ constant_metadata_address((Metadata *)val);
 3067         const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3068         __ relocate(a.rspec());
 3069       } else {  // non-oop pointers, e.g. card mark base, heap top
 3070         // Create a non-oop constant, no relocation needed.
 3071         const_toc_addr = __ long_constant((jlong)$src$$constant);
 3072       }
 3073 
 3074       if (const_toc_addr == NULL) {
 3075         ciEnv::current()-&gt;record_out_of_memory_failure();
 3076         return;
</pre>
<hr />
<pre>
 3169     if (large_constant_pool) {
 3170       m2 = new loadConDCompNode();
 3171     } else {
 3172       m2 = new loadConDNode();
 3173     }
 3174     // inputs for new nodes
 3175     m2-&gt;add_req(NULL, n_toc);
 3176 
 3177     // operands for new nodes
 3178     m2-&gt;_opnds[0] = op_dst;
 3179     m2-&gt;_opnds[1] = op_src;
 3180     m2-&gt;_opnds[2] = new iRegPdstOper(); // constanttablebase
 3181 
 3182     // register allocation for new nodes
 3183     ra_-&gt;set_pair(m2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3184     nodes-&gt;push(m2);
 3185   %}
 3186 
 3187   enc_class enc_stw(iRegIsrc src, memory mem) %{
 3188     // TODO: PPC port $archOpcode(ppc64Opcode_stw);
<span class="line-modified"> 3189     MacroAssembler _masm(&amp;cbuf);</span>
 3190     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3191     __ stw($src$$Register, Idisp, $mem$$base$$Register);
 3192   %}
 3193 
 3194   enc_class enc_std(iRegIsrc src, memoryAlg4 mem) %{
 3195     // TODO: PPC port $archOpcode(ppc64Opcode_std);
<span class="line-modified"> 3196     MacroAssembler _masm(&amp;cbuf);</span>
 3197     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3198     // Operand &#39;ds&#39; requires 4-alignment.
 3199     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 3200     __ std($src$$Register, Idisp, $mem$$base$$Register);
 3201   %}
 3202 
 3203   enc_class enc_stfs(RegF src, memory mem) %{
 3204     // TODO: PPC port $archOpcode(ppc64Opcode_stfs);
<span class="line-modified"> 3205     MacroAssembler _masm(&amp;cbuf);</span>
 3206     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3207     __ stfs($src$$FloatRegister, Idisp, $mem$$base$$Register);
 3208   %}
 3209 
 3210   enc_class enc_stfd(RegF src, memory mem) %{
 3211     // TODO: PPC port $archOpcode(ppc64Opcode_stfd);
<span class="line-modified"> 3212     MacroAssembler _masm(&amp;cbuf);</span>
 3213     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3214     __ stfd($src$$FloatRegister, Idisp, $mem$$base$$Register);
 3215   %}
 3216 
 3217   // Use release_store for card-marking to ensure that previous
 3218   // oop-stores are visible before the card-mark change.
 3219   enc_class enc_cms_card_mark(memory mem, iRegLdst releaseFieldAddr, flagsReg crx) %{
 3220     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3221     // FIXME: Implement this as a cmove and use a fixed condition code
 3222     // register which is written on every transition to compiled code,
 3223     // e.g. in call-stub and when returning from runtime stubs.
 3224     //
 3225     // Proposed code sequence for the cmove implementation:
 3226     //
 3227     // Label skip_release;
 3228     // __ beq(CCRfixed, skip_release);
 3229     // __ release();
 3230     // __ bind(skip_release);
 3231     // __ stb(card mark);
 3232 
<span class="line-modified"> 3233     MacroAssembler _masm(&amp;cbuf);</span>
 3234     Label skip_storestore;
 3235 
 3236 #if 0 // TODO: PPC port
 3237     // Check CMSCollectorCardTableBarrierSetBSExt::_requires_release and do the
 3238     // StoreStore barrier conditionally.
 3239     __ lwz(R0, 0, $releaseFieldAddr$$Register);
 3240     __ cmpwi($crx$$CondRegister, R0, 0);
 3241     __ beq_predict_taken($crx$$CondRegister, skip_storestore);
 3242 #endif
 3243     __ li(R0, 0);
 3244     __ membar(Assembler::StoreStore);
 3245 #if 0 // TODO: PPC port
 3246     __ bind(skip_storestore);
 3247 #endif
 3248 
 3249     // Do the store.
 3250     if ($mem$$index == 0) {
 3251       __ stb(R0, $mem$$disp, $mem$$base$$Register);
 3252     } else {
 3253       assert(0 == $mem$$disp, &quot;no displacement possible with indexed load/stores on ppc&quot;);
</pre>
<hr />
<pre>
 3434     n1-&gt;_bottom_type = _bottom_type;
 3435 
 3436     decodeN_addNode *n2 = new decodeN_addNode();
 3437     n2-&gt;add_req(n_region, n1);
 3438     n2-&gt;_opnds[0] = op_dst;
 3439     n2-&gt;_opnds[1] = op_dst;
 3440     n2-&gt;_bottom_type = _bottom_type;
 3441     ra_-&gt;set_pair(n1-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3442     ra_-&gt;set_pair(n2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3443 
 3444     assert(ra_-&gt;is_oop(this) == true, &quot;A decodeN node must produce an oop!&quot;);
 3445     ra_-&gt;set_oop(n2, true);
 3446 
 3447     nodes-&gt;push(n1);
 3448     nodes-&gt;push(n2);
 3449   %}
 3450 
 3451   enc_class enc_cmove_reg(iRegIdst dst, flagsRegSrc crx, iRegIsrc src, cmpOp cmp) %{
 3452     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3453 
<span class="line-modified"> 3454     MacroAssembler _masm(&amp;cbuf);</span>
 3455     int cc        = $cmp$$cmpcode;
 3456     int flags_reg = $crx$$reg;
 3457     Label done;
 3458     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3459     // Branch if not (cmp crx).
 3460     __ bc(cc_to_inverse_boint(cc), cc_to_biint(cc, flags_reg), done);
 3461     __ mr($dst$$Register, $src$$Register);
 3462     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3463     __ bind(done);
 3464   %}
 3465 
 3466   enc_class enc_cmove_imm(iRegIdst dst, flagsRegSrc crx, immI16 src, cmpOp cmp) %{
 3467     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3468 
<span class="line-modified"> 3469     MacroAssembler _masm(&amp;cbuf);</span>
 3470     Label done;
 3471     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3472     // Branch if not (cmp crx).
 3473     __ bc(cc_to_inverse_boint($cmp$$cmpcode), cc_to_biint($cmp$$cmpcode, $crx$$reg), done);
 3474     __ li($dst$$Register, $src$$constant);
 3475     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3476     __ bind(done);
 3477   %}
 3478 
 3479   // This enc_class is needed so that scheduler gets proper
 3480   // input mapping for latency computation.
 3481   enc_class enc_andc(iRegIdst dst, iRegIsrc src1, iRegIsrc src2) %{
 3482     // TODO: PPC port $archOpcode(ppc64Opcode_andc);
<span class="line-modified"> 3483     MacroAssembler _masm(&amp;cbuf);</span>
 3484     __ andc($dst$$Register, $src1$$Register, $src2$$Register);
 3485   %}
 3486 
 3487   enc_class enc_convI2B_regI__cmove(iRegIdst dst, iRegIsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
 3488     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3489 
<span class="line-modified"> 3490     MacroAssembler _masm(&amp;cbuf);</span>
 3491 
 3492     Label done;
 3493     __ cmpwi($crx$$CondRegister, $src$$Register, 0);
 3494     __ li($dst$$Register, $zero$$constant);
 3495     __ beq($crx$$CondRegister, done);
 3496     __ li($dst$$Register, $notzero$$constant);
 3497     __ bind(done);
 3498   %}
 3499 
 3500   enc_class enc_convP2B_regP__cmove(iRegIdst dst, iRegPsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
 3501     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3502 
<span class="line-modified"> 3503     MacroAssembler _masm(&amp;cbuf);</span>
 3504 
 3505     Label done;
 3506     __ cmpdi($crx$$CondRegister, $src$$Register, 0);
 3507     __ li($dst$$Register, $zero$$constant);
 3508     __ beq($crx$$CondRegister, done);
 3509     __ li($dst$$Register, $notzero$$constant);
 3510     __ bind(done);
 3511   %}
 3512 
 3513   enc_class enc_cmove_bso_stackSlotL(iRegLdst dst, flagsRegSrc crx, stackSlotL mem ) %{
 3514     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3515 
<span class="line-modified"> 3516     MacroAssembler _masm(&amp;cbuf);</span>
 3517     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3518     Label done;
 3519     __ bso($crx$$CondRegister, done);
 3520     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 3521     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3522     __ bind(done);
 3523   %}
 3524 
 3525   enc_class enc_cmove_bso_reg(iRegLdst dst, flagsRegSrc crx, regD src) %{
 3526     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3527 
<span class="line-modified"> 3528     MacroAssembler _masm(&amp;cbuf);</span>
 3529     Label done;
 3530     __ bso($crx$$CondRegister, done);
 3531     __ mffprd($dst$$Register, $src$$FloatRegister);
 3532     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3533     __ bind(done);
 3534   %}
 3535 
 3536   enc_class enc_bc(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3537     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3538 
<span class="line-modified"> 3539     MacroAssembler _masm(&amp;cbuf);</span>
 3540     Label d;   // dummy
 3541     __ bind(d);
 3542     Label* p = ($lbl$$label);
 3543     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3544     // determine the size of the encoded instruction.
 3545     Label&amp; l = (NULL == p)? d : *(p);
 3546     int cc = $cmp$$cmpcode;
 3547     int flags_reg = $crx$$reg;
 3548     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3549     int bhint = Assembler::bhintNoHint;
 3550 
 3551     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3552       if (_prob &lt;= PROB_NEVER) {
 3553         bhint = Assembler::bhintIsNotTaken;
 3554       } else if (_prob &gt;= PROB_ALWAYS) {
 3555         bhint = Assembler::bhintIsTaken;
 3556       }
 3557     }
 3558 
 3559     __ bc(Assembler::add_bhint_to_boint(bhint, cc_to_boint(cc)),
 3560           cc_to_biint(cc, flags_reg),
 3561           l);
 3562   %}
 3563 
 3564   enc_class enc_bc_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3565     // The scheduler doesn&#39;t know about branch shortening, so we set the opcode
 3566     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
 3567     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3568 
<span class="line-modified"> 3569     MacroAssembler _masm(&amp;cbuf);</span>
 3570     Label d;    // dummy
 3571     __ bind(d);
 3572     Label* p = ($lbl$$label);
 3573     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3574     // determine the size of the encoded instruction.
 3575     Label&amp; l = (NULL == p)? d : *(p);
 3576     int cc = $cmp$$cmpcode;
 3577     int flags_reg = $crx$$reg;
 3578     int bhint = Assembler::bhintNoHint;
 3579 
 3580     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3581       if (_prob &lt;= PROB_NEVER) {
 3582         bhint = Assembler::bhintIsNotTaken;
 3583       } else if (_prob &gt;= PROB_ALWAYS) {
 3584         bhint = Assembler::bhintIsTaken;
 3585       }
 3586     }
 3587 
 3588     // Tell the conditional far branch to optimize itself when being relocated.
 3589     __ bc_far(Assembler::add_bhint_to_boint(bhint, cc_to_boint(cc)),
 3590                   cc_to_biint(cc, flags_reg),
 3591                   l,
 3592                   MacroAssembler::bc_far_optimize_on_relocate);
 3593   %}
 3594 
 3595   // Branch used with Power6 scheduling (can be shortened without changing the node).
 3596   enc_class enc_bc_short_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3597     // The scheduler doesn&#39;t know about branch shortening, so we set the opcode
 3598     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
 3599     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3600 
<span class="line-modified"> 3601     MacroAssembler _masm(&amp;cbuf);</span>
 3602     Label d;   // dummy
 3603     __ bind(d);
 3604     Label* p = ($lbl$$label);
 3605     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3606     // determine the size of the encoded instruction.
 3607     Label&amp; l = (NULL == p)? d : *(p);
 3608     int cc = $cmp$$cmpcode;
 3609     int flags_reg = $crx$$reg;
 3610     int bhint = Assembler::bhintNoHint;
 3611 
 3612     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3613       if (_prob &lt;= PROB_NEVER) {
 3614         bhint = Assembler::bhintIsNotTaken;
 3615       } else if (_prob &gt;= PROB_ALWAYS) {
 3616         bhint = Assembler::bhintIsTaken;
 3617       }
 3618     }
 3619 
 3620 #if 0 // TODO: PPC port
 3621     if (_size == 8) {
</pre>
<hr />
<pre>
 3666       loadConLReplicatedNodesTuple_create(C, ra_, n_toc, op_repl, op_dst, op_zero,
 3667                                 ra_-&gt;get_reg_second(n_tmp), ra_-&gt;get_reg_first(n_tmp),
 3668                                 ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3669 
 3670     // Push new nodes.
 3671     if (loadConLNodes._large_hi) { nodes-&gt;push(loadConLNodes._large_hi); }
 3672     if (loadConLNodes._large_lo) { nodes-&gt;push(loadConLNodes._large_lo); }
 3673     if (loadConLNodes._moved)    { nodes-&gt;push(loadConLNodes._moved); }
 3674     if (loadConLNodes._last)     { nodes-&gt;push(loadConLNodes._last); }
 3675 
 3676     assert(nodes-&gt;length() &gt;= 1, &quot;must have created at least 1 node&quot;);
 3677   %}
 3678 
 3679   // This enc_class is needed so that scheduler gets proper
 3680   // input mapping for latency computation.
 3681   enc_class enc_poll(immI dst, iRegLdst poll) %{
 3682     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 3683     // Fake operand dst needed for PPC scheduler.
 3684     assert($dst$$constant == 0x0, &quot;dst must be 0x0&quot;);
 3685 
<span class="line-modified"> 3686     MacroAssembler _masm(&amp;cbuf);</span>
 3687     // Mark the code position where the load from the safepoint
 3688     // polling page was emitted as relocInfo::poll_type.
 3689     __ relocate(relocInfo::poll_type);
 3690     __ load_from_polling_page($poll$$Register);
 3691   %}
 3692 
 3693   // A Java static call or a runtime call.
 3694   //
 3695   // Branch-and-link relative to a trampoline.
 3696   // The trampoline loads the target address and does a long branch to there.
 3697   // In case we call java, the trampoline branches to a interpreter_stub
 3698   // which loads the inline cache and the real call target from the constant pool.
 3699   //
 3700   // This basically looks like this:
 3701   //
 3702   // &gt;&gt;&gt;&gt; consts      -+  -+
 3703   //                   |   |- offset1
 3704   // [call target1]    | &lt;-+
 3705   // [IC cache]        |- offset2
 3706   // [call target2] &lt;--+
</pre>
<hr />
<pre>
 3722   //   r1 = toc
 3723   //   ICreg = [r1 + IC_offset]         // Load IC from const section
 3724   //   r1    = [r1 + offset2]           // Load call target2 from const section
 3725   //   mtctr r1
 3726   //   bctr
 3727   //
 3728   // &lt;&lt;&lt;&lt; stubs
 3729   //
 3730   // The call instruction in the code either
 3731   // - Branches directly to a compiled method if the offset is encodable in instruction.
 3732   // - Branches to the trampoline stub if the offset to the compiled method is not encodable.
 3733   // - Branches to the compiled_to_interp stub if the target is interpreted.
 3734   //
 3735   // Further there are three relocations from the loads to the constants in
 3736   // the constant section.
 3737   //
 3738   // Usage of r1 and r2 in the stubs allows to distinguish them.
 3739   enc_class enc_java_static_call(method meth) %{
 3740     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 3741 
<span class="line-modified"> 3742     MacroAssembler _masm(&amp;cbuf);</span>
 3743     address entry_point = (address)$meth$$method;
 3744 
 3745     if (!_method) {
 3746       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3747       emit_call_with_trampoline_stub(_masm, entry_point, relocInfo::runtime_call_type);
 3748     } else {
 3749       // Remember the offset not the address.
 3750       const int start_offset = __ offset();
 3751 
 3752       // The trampoline stub.
 3753       // No entry point given, use the current pc.
 3754       // Make sure branch fits into
 3755       if (entry_point == 0) entry_point = __ pc();
 3756 
 3757       // Put the entry point as a constant into the constant pool.
 3758       const address entry_point_toc_addr = __ address_constant(entry_point, RelocationHolder::none);
 3759       if (entry_point_toc_addr == NULL) {
 3760         ciEnv::current()-&gt;record_out_of_memory_failure();
 3761         return;
 3762       }
</pre>
<hr />
<pre>
 3772       // The real call.
 3773       // Note: At this point we do not have the address of the trampoline
 3774       // stub, and the entry point might be too far away for bl, so __ pc()
 3775       // serves as dummy and the bl will be patched later.
 3776       cbuf.set_insts_mark();
 3777       __ bl(__ pc());  // Emits a relocation.
 3778 
 3779       // The stub for call to interpreter.
 3780       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3781       if (stub == NULL) {
 3782         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3783         return;
 3784       }
 3785     }
 3786   %}
 3787 
 3788   // Second node of expanded dynamic call - the call.
 3789   enc_class enc_java_dynamic_call_sched(method meth) %{
 3790     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 3791 
<span class="line-modified"> 3792     MacroAssembler _masm(&amp;cbuf);</span>
 3793 
<span class="line-modified"> 3794     if (!ra_-&gt;C-&gt;in_scratch_emit_size()) {</span>
 3795       // Create a call trampoline stub for the given method.
 3796       const address entry_point = !($meth$$method) ? 0 : (address)$meth$$method;
 3797       const address entry_point_const = __ address_constant(entry_point, RelocationHolder::none);
 3798       if (entry_point_const == NULL) {
 3799         ciEnv::current()-&gt;record_out_of_memory_failure();
 3800         return;
 3801       }
 3802       const int entry_point_const_toc_offset = __ offset_to_method_toc(entry_point_const);
 3803       CallStubImpl::emit_trampoline_stub(_masm, entry_point_const_toc_offset, __ offset());
 3804       if (ra_-&gt;C-&gt;env()-&gt;failing()) { return; } // Code cache may be full.
 3805 
 3806       // Build relocation at call site with ic position as data.
 3807       assert((_load_ic_hi_node != NULL &amp;&amp; _load_ic_node == NULL) ||
 3808              (_load_ic_hi_node == NULL &amp;&amp; _load_ic_node != NULL),
 3809              &quot;must have one, but can&#39;t have both&quot;);
 3810       assert((_load_ic_hi_node != NULL &amp;&amp; _load_ic_hi_node-&gt;_cbuf_insts_offset != -1) ||
 3811              (_load_ic_node != NULL    &amp;&amp; _load_ic_node-&gt;_cbuf_insts_offset != -1),
 3812              &quot;must contain instruction offset&quot;);
 3813       const int virtual_call_oop_addr_offset = _load_ic_hi_node != NULL
 3814         ? _load_ic_hi_node-&gt;_cbuf_insts_offset
</pre>
<hr />
<pre>
 3875     call-&gt;_load_ic_node    = loadConLNodes_IC._small;
 3876 
 3877     // Operands for new nodes.
 3878     call-&gt;_opnds[0] = _opnds[0];
 3879     call-&gt;_opnds[1] = _opnds[1];
 3880 
 3881     // Only the inline cache is associated with a register.
 3882     assert(Matcher::inline_cache_reg() == OptoReg::Name(R19_num), &quot;ic reg should be R19&quot;);
 3883 
 3884     // Push new nodes.
 3885     if (loadConLNodes_IC._large_hi) nodes-&gt;push(loadConLNodes_IC._large_hi);
 3886     if (loadConLNodes_IC._last)     nodes-&gt;push(loadConLNodes_IC._last);
 3887     nodes-&gt;push(call);
 3888   %}
 3889 
 3890   // Compound version of call dynamic
 3891   // Toc is only passed so that it can be used in ins_encode statement.
 3892   // In the code we have to use $constanttablebase.
 3893   enc_class enc_java_dynamic_call(method meth, iRegLdst toc) %{
 3894     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 3895     MacroAssembler _masm(&amp;cbuf);</span>
 3896     int start_offset = __ offset();
 3897 
 3898     Register Rtoc = (ra_) ? $constanttablebase : R2_TOC;
 3899 #if 0
 3900     int vtable_index = this-&gt;_vtable_index;
 3901     if (_vtable_index &lt; 0) {
 3902       // Must be invalid_vtable_index, not nonvirtual_vtable_index.
 3903       assert(_vtable_index == Method::invalid_vtable_index, &quot;correct sentinel value&quot;);
 3904       Register ic_reg = as_Register(Matcher::inline_cache_reg_encode());
 3905 
 3906       // Virtual call relocation will point to ic load.
 3907       address virtual_call_meta_addr = __ pc();
 3908       // Load a clear inline cache.
 3909       AddressLiteral empty_ic((address) Universe::non_oop_word());
 3910       bool success = __ load_const_from_method_toc(ic_reg, empty_ic, Rtoc, /*fixed_size*/ true);
 3911       if (!success) {
 3912         ciEnv::current()-&gt;record_out_of_memory_failure();
 3913         return;
 3914       }
 3915       // CALL to fixup routine.  Fixup routine uses ScopeDesc info
</pre>
<hr />
<pre>
 3934       // null. However it may very well end up in handle_wrong_method
 3935       // if the method is abstract for the particular class.
 3936       __ ld(R11_scratch1, in_bytes(Method::from_compiled_offset()), R19_method);
 3937       // Call target. Either compiled code or C2I adapter.
 3938       __ mtctr(R11_scratch1);
 3939       __ bctrl();
 3940       if (((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset() != __ offset() - start_offset) {
 3941         tty-&gt;print(&quot; %d, %d\n&quot;, ((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset(),__ offset() - start_offset);
 3942       }
 3943       assert(((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset() == __ offset() - start_offset,
 3944              &quot;Fix constant in ret_addr_offset()&quot;);
 3945     }
 3946 #endif
 3947     Unimplemented();  // ret_addr_offset not yet fixed. Depends on compressed oops (load klass!).
 3948   %}
 3949 
 3950   // a runtime call
 3951   enc_class enc_java_to_runtime_call (method meth) %{
 3952     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3953 
<span class="line-modified"> 3954     MacroAssembler _masm(&amp;cbuf);</span>
 3955     const address start_pc = __ pc();
 3956 
 3957 #if defined(ABI_ELFv2)
 3958     address entry= !($meth$$method) ? NULL : (address)$meth$$method;
 3959     __ call_c(entry, relocInfo::runtime_call_type);
 3960 #else
 3961     // The function we&#39;re going to call.
 3962     FunctionDescriptor fdtemp;
 3963     const FunctionDescriptor* fd = !($meth$$method) ? &amp;fdtemp : (FunctionDescriptor*)$meth$$method;
 3964 
 3965     Register Rtoc = R12_scratch2;
 3966     // Calculate the method&#39;s TOC.
 3967     __ calculate_address_from_global_toc(Rtoc, __ method_toc());
 3968     // Put entry, env, toc into the constant pool, this needs up to 3 constant
 3969     // pool entries; call_c_using_toc will optimize the call.
 3970     bool success = __ call_c_using_toc(fd, relocInfo::runtime_call_type, Rtoc);
 3971     if (!success) {
 3972       ciEnv::current()-&gt;record_out_of_memory_failure();
 3973       return;
 3974     }
 3975 #endif
 3976 
 3977     // Check the ret_addr_offset.
 3978     assert(((MachCallRuntimeNode*)this)-&gt;ret_addr_offset() ==  __ last_calls_return_pc() - start_pc,
 3979            &quot;Fix constant in ret_addr_offset()&quot;);
 3980   %}
 3981 
 3982   // Move to ctr for leaf call.
 3983   // This enc_class is needed so that scheduler gets proper
 3984   // input mapping for latency computation.
 3985   enc_class enc_leaf_call_mtctr(iRegLsrc src) %{
 3986     // TODO: PPC port $archOpcode(ppc64Opcode_mtctr);
<span class="line-modified"> 3987     MacroAssembler _masm(&amp;cbuf);</span>
 3988     __ mtctr($src$$Register);
 3989   %}
 3990 
 3991   // Postalloc expand emitter for runtime leaf calls.
 3992   enc_class postalloc_expand_java_to_runtime_call(method meth, iRegLdst toc) %{
 3993     loadConLNodesTuple loadConLNodes_Entry;
 3994 #if defined(ABI_ELFv2)
 3995     jlong entry_address = (jlong) this-&gt;entry_point();
 3996     assert(entry_address, &quot;need address here&quot;);
 3997     loadConLNodes_Entry = loadConLNodesTuple_create(ra_, n_toc, new immLOper(entry_address),
 3998                                                     OptoReg::Name(R12_H_num), OptoReg::Name(R12_num));
 3999 #else
 4000     // Get the struct that describes the function we are about to call.
 4001     FunctionDescriptor* fd = (FunctionDescriptor*) this-&gt;entry_point();
 4002     assert(fd, &quot;need fd here&quot;);
 4003     jlong entry_address = (jlong) fd-&gt;entry();
 4004     // new nodes
 4005     loadConLNodesTuple loadConLNodes_Env;
 4006     loadConLNodesTuple loadConLNodes_Toc;
 4007 
</pre>
<hr />
<pre>
 6268   ins_field_cbuf_insts_offset(int);
 6269 
 6270   format %{ &quot;ADDIS   $dst, $toc, offset \t// load long $src from TOC (hi)&quot; %}
 6271   size(4);
 6272   ins_encode( enc_load_long_constL_hi(dst, toc, src) );
 6273   ins_pipe(pipe_class_default);
 6274 %}
 6275 
 6276 // Expand node for constant pool load: large offset.
 6277 // No constant pool entries required.
 6278 instruct loadConL_lo(iRegLdst dst, immL src, iRegLdst base) %{
 6279   effect(DEF dst, USE src, USE base);
 6280   predicate(false);
 6281 
 6282   ins_field_const_toc_offset_hi_node(loadConL_hiNode*);
 6283 
 6284   format %{ &quot;LD      $dst, offset, $base \t// load long $src from TOC (lo)&quot; %}
 6285   size(4);
 6286   ins_encode %{
 6287     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 6288     int offset = ra_-&gt;C-&gt;in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node-&gt;_const_toc_offset;</span>
 6289     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
 6290   %}
 6291   ins_pipe(pipe_class_memory);
 6292 %}
 6293 
 6294 // Load long constant from constant table. Expand in case of
 6295 // offset &gt; 16 bit is needed.
 6296 // Adlc adds toc node MachConstantTableBase.
 6297 instruct loadConL_Ex(iRegLdst dst, immL src) %{
 6298   match(Set dst src);
 6299   ins_cost(MEMORY_REF_COST);
 6300 
 6301   format %{ &quot;LD      $dst, offset, $constanttablebase\t// load long $src from table, postalloc expanded&quot; %}
 6302   // We can not inline the enc_class for the expand as that does not support constanttablebase.
 6303   postalloc_expand( postalloc_expand_load_long_constant(dst, src, constanttablebase) );
 6304 %}
 6305 
 6306 // Load NULL as compressed oop.
 6307 instruct loadConN0(iRegNdst dst, immN_0 src) %{
 6308   match(Set dst src);
</pre>
<hr />
<pre>
 6553   ins_num_consts(1);
 6554   ins_field_const_toc_offset(int);
 6555 
 6556   format %{ &quot;ADDIS   $dst, $toc, offset \t// load ptr $src from TOC (hi)&quot; %}
 6557   size(4);
 6558   ins_encode( enc_load_long_constP_hi(dst, src, toc) );
 6559   ins_pipe(pipe_class_default);
 6560 %}
 6561 
 6562 // Expand node for constant pool load: large offset.
 6563 instruct loadConP_lo(iRegPdst dst, immP_NM src, iRegLdst base) %{
 6564   match(Set dst src);
 6565   effect(TEMP base);
 6566 
 6567   ins_field_const_toc_offset_hi_node(loadConP_hiNode*);
 6568 
 6569   format %{ &quot;LD      $dst, offset, $base \t// load ptr $src from TOC (lo)&quot; %}
 6570   size(4);
 6571   ins_encode %{
 6572     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 6573     int offset = ra_-&gt;C-&gt;in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node-&gt;_const_toc_offset;</span>
 6574     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
 6575   %}
 6576   ins_pipe(pipe_class_memory);
 6577 %}
 6578 
 6579 // Load pointer constant from constant table. Expand in case an
 6580 // offset &gt; 16 bit is needed.
 6581 // Adlc adds toc node MachConstantTableBase.
 6582 instruct loadConP_Ex(iRegPdst dst, immP src) %{
 6583   match(Set dst src);
 6584   ins_cost(MEMORY_REF_COST);
 6585 
 6586   // This rule does not use &quot;expand&quot; because then
 6587   // the result type is not known to be an Oop.  An ADLC
 6588   // enhancement will be needed to make that work - not worth it!
 6589 
 6590   // If this instruction rematerializes, it prolongs the live range
 6591   // of the toc node, causing illegal graphs.
 6592   // assert(edge_from_to(_reg_node[reg_lo],def)) fails in verify_good_schedule().
 6593   ins_cannot_rematerialize(true);
</pre>
</td>
<td>
<hr />
<pre>
 1127 //=============================================================================
 1128 
 1129 // Compute padding required for nodes which need alignment. The padding
 1130 // is the number of bytes (not instructions) which will be inserted before
 1131 // the instruction. The padding must match the size of a NOP instruction.
 1132 
 1133 // Currently not used on this platform.
 1134 
 1135 //=============================================================================
 1136 
 1137 // Indicate if the safepoint node needs the polling page as an input.
 1138 bool SafePointNode::needs_polling_address_input() {
 1139   // The address is loaded from thread by a seperate node.
 1140   return true;
 1141 }
 1142 
 1143 //=============================================================================
 1144 
 1145 // Emit an interrupt that is caught by the debugger (for debugging compiler).
 1146 void emit_break(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 1147   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1148   __ illtrap();
 1149 }
 1150 
 1151 #ifndef PRODUCT
 1152 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1153   st-&gt;print(&quot;BREAKPOINT&quot;);
 1154 }
 1155 #endif
 1156 
 1157 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1158   emit_break(cbuf);
 1159 }
 1160 
 1161 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1162   return MachNode::size(ra_);
 1163 }
 1164 
 1165 //=============================================================================
 1166 
 1167 void emit_nop(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 1168   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1169   __ nop();
 1170 }
 1171 
 1172 static inline void emit_long(CodeBuffer &amp;cbuf, int value) {
 1173   *((int*)(cbuf.insts_end())) = value;
 1174   cbuf.set_insts_end(cbuf.insts_end() + BytesPerInstWord);
 1175 }
 1176 
 1177 //=============================================================================
 1178 
 1179 %} // interrupt source
 1180 
 1181 source_hpp %{ // Header information of the source block.
 1182 
 1183 //--------------------------------------------------------------
 1184 //---&lt;  Used for optimization in Compile::Shorten_branches  &gt;---
 1185 //--------------------------------------------------------------
 1186 
<span class="line-added"> 1187 class C2_MacroAssembler;</span>
<span class="line-added"> 1188 </span>
 1189 class CallStubImpl {
 1190 
 1191  public:
 1192 
 1193   // Emit call stub, compiled java to interpreter.
<span class="line-modified"> 1194   static void emit_trampoline_stub(C2_MacroAssembler &amp;_masm, int destination_toc_offset, int insts_call_instruction_offset);</span>
 1195 
 1196   // Size of call trampoline stub.
 1197   // This doesn&#39;t need to be accurate to the byte, but it
 1198   // must be larger than or equal to the real size of the stub.
 1199   static uint size_call_trampoline() {
 1200     return MacroAssembler::trampoline_stub_size;
 1201   }
 1202 
 1203   // number of relocations needed by a call trampoline stub
 1204   static uint reloc_call_trampoline() {
 1205     return 5;
 1206   }
 1207 
 1208 };
 1209 
 1210 %} // end source_hpp
 1211 
 1212 source %{
 1213 
 1214 // Emit a trampoline stub for a call to a target which is too far away.
 1215 //
 1216 // code sequences:
 1217 //
 1218 // call-site:
 1219 //   branch-and-link to &lt;destination&gt; or &lt;trampoline stub&gt;
 1220 //
 1221 // Related trampoline stub for this call-site in the stub section:
 1222 //   load the call target from the constant pool
 1223 //   branch via CTR (LR/link still points to the call-site above)
 1224 
<span class="line-modified"> 1225 void CallStubImpl::emit_trampoline_stub(C2_MacroAssembler &amp;_masm, int destination_toc_offset, int insts_call_instruction_offset) {</span>
 1226   address stub = __ emit_trampoline_stub(destination_toc_offset, insts_call_instruction_offset);
 1227   if (stub == NULL) {
 1228     ciEnv::current()-&gt;record_out_of_memory_failure();
 1229   }
 1230 }
 1231 
 1232 //=============================================================================
 1233 
 1234 // Emit an inline branch-and-link call and a related trampoline stub.
 1235 //
 1236 // code sequences:
 1237 //
 1238 // call-site:
 1239 //   branch-and-link to &lt;destination&gt; or &lt;trampoline stub&gt;
 1240 //
 1241 // Related trampoline stub for this call-site in the stub section:
 1242 //   load the call target from the constant pool
 1243 //   branch via CTR (LR/link still points to the call-site above)
 1244 //
 1245 
 1246 typedef struct {
 1247   int insts_call_instruction_offset;
 1248   int ret_addr_offset;
 1249 } EmitCallOffsets;
 1250 
 1251 // Emit a branch-and-link instruction that branches to a trampoline.
 1252 // - Remember the offset of the branch-and-link instruction.
 1253 // - Add a relocation at the branch-and-link instruction.
 1254 // - Emit a branch-and-link.
 1255 // - Remember the return pc offset.
<span class="line-modified"> 1256 EmitCallOffsets emit_call_with_trampoline_stub(C2_MacroAssembler &amp;_masm, address entry_point, relocInfo::relocType rtype) {</span>
 1257   EmitCallOffsets offsets = { -1, -1 };
 1258   const int start_offset = __ offset();
 1259   offsets.insts_call_instruction_offset = __ offset();
 1260 
 1261   // No entry point given, use the current pc.
 1262   if (entry_point == NULL) entry_point = __ pc();
 1263 
 1264   // Put the entry point as a constant into the constant pool.
 1265   const address entry_point_toc_addr   = __ address_constant(entry_point, RelocationHolder::none);
 1266   if (entry_point_toc_addr == NULL) {
 1267     ciEnv::current()-&gt;record_out_of_memory_failure();
 1268     return offsets;
 1269   }
 1270   const int     entry_point_toc_offset = __ offset_to_method_toc(entry_point_toc_addr);
 1271 
 1272   // Emit the trampoline stub which will be related to the branch-and-link below.
 1273   CallStubImpl::emit_trampoline_stub(_masm, entry_point_toc_offset, offsets.insts_call_instruction_offset);
 1274   if (ciEnv::current()-&gt;failing()) { return offsets; } // Code cache may be full.
 1275   __ relocate(rtype);
 1276 
</pre>
<hr />
<pre>
 1282   offsets.ret_addr_offset = __ offset() - start_offset;
 1283 
 1284   return offsets;
 1285 }
 1286 
 1287 //=============================================================================
 1288 
 1289 // Factory for creating loadConL* nodes for large/small constant pool.
 1290 
 1291 static inline jlong replicate_immF(float con) {
 1292   // Replicate float con 2 times and pack into vector.
 1293   int val = *((int*)&amp;con);
 1294   jlong lval = val;
 1295   lval = (lval &lt;&lt; 32) | (lval &amp; 0xFFFFFFFFl);
 1296   return lval;
 1297 }
 1298 
 1299 //=============================================================================
 1300 
 1301 const RegMask&amp; MachConstantBaseNode::_out_RegMask = BITS64_CONSTANT_TABLE_BASE_mask();
<span class="line-modified"> 1302 int ConstantTable::calculate_table_base_offset() const {</span>
 1303   return 0;  // absolute addressing, no offset
 1304 }
 1305 
 1306 bool MachConstantBaseNode::requires_postalloc_expand() const { return true; }
 1307 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1308   iRegPdstOper *op_dst = new iRegPdstOper();
 1309   MachNode *m1 = new loadToc_hiNode();
 1310   MachNode *m2 = new loadToc_loNode();
 1311 
 1312   m1-&gt;add_req(NULL);
 1313   m2-&gt;add_req(NULL, m1);
 1314   m1-&gt;_opnds[0] = op_dst;
 1315   m2-&gt;_opnds[0] = op_dst;
 1316   m2-&gt;_opnds[1] = op_dst;
 1317   ra_-&gt;set_pair(m1-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 1318   ra_-&gt;set_pair(m2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 1319   nodes-&gt;push(m1);
 1320   nodes-&gt;push(m2);
 1321 }
 1322 
 1323 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1324   // Is postalloc expanded.
 1325   ShouldNotReachHere();
 1326 }
 1327 
 1328 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1329   return 0;
 1330 }
 1331 
 1332 #ifndef PRODUCT
 1333 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1334   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1335 }
 1336 #endif
 1337 
 1338 //=============================================================================
 1339 
 1340 #ifndef PRODUCT
 1341 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1342   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1343   const long framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1344 
 1345   st-&gt;print(&quot;PROLOG\n\t&quot;);
<span class="line-modified"> 1346   if (C-&gt;output()-&gt;need_stack_bang(framesize)) {</span>
 1347     st-&gt;print(&quot;stack_overflow_check\n\t&quot;);
 1348   }
 1349 
 1350   if (!false /* TODO: PPC port C-&gt;is_frameless_method()*/) {
 1351     st-&gt;print(&quot;save return pc\n\t&quot;);
 1352     st-&gt;print(&quot;push frame %ld\n\t&quot;, -framesize);
 1353   }
 1354 }
 1355 #endif
 1356 
 1357 // Macro used instead of the common __ to emulate the pipes of PPC.
 1358 // Instead of e.g. __ ld(...) one hase to write ___(ld) ld(...) This enables the
 1359 // micro scheduler to cope with &quot;hand written&quot; assembler like in the prolog. Though
 1360 // still no scheduling of this code is possible, the micro scheduler is aware of the
 1361 // code and can update its internal data. The following mechanism is used to achieve this:
 1362 // The micro scheduler calls size() of each compound node during scheduling. size() does a
 1363 // dummy emit and only during this dummy emit C-&gt;hb_scheduling() is not NULL.
 1364 #if 0 // TODO: PPC port
 1365 #define ___(op) if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                    \
 1366                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;PdEmulatePipe(ppc64Opcode_##op); \
 1367                 _masm.
 1368 #define ___stop if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                    \
 1369                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;PdEmulatePipe(archOpcode_none)
 1370 #define ___advance if (UsePower6SchedulerPPC64 &amp;&amp; C-&gt;hb_scheduling())                 \
 1371                   C-&gt;hb_scheduling()-&gt;_pdScheduling-&gt;advance_offset
 1372 #else
 1373 #define ___(op) if (UsePower6SchedulerPPC64)                                          \
 1374                   Unimplemented();                                                    \
 1375                 _masm.
 1376 #define ___stop if (UsePower6SchedulerPPC64)                                          \
 1377                   Unimplemented()
 1378 #define ___advance if (UsePower6SchedulerPPC64)                                       \
 1379                   Unimplemented()
 1380 #endif
 1381 
 1382 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1383   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1384   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1385 
<span class="line-modified"> 1386   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();</span>
 1387   assert(framesize % (2 * wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1388 
 1389   const bool method_is_frameless      = false /* TODO: PPC port C-&gt;is_frameless_method()*/;
 1390 
 1391   const Register return_pc            = R20; // Must match return_addr() in frame section.
 1392   const Register callers_sp           = R21;
 1393   const Register push_frame_temp      = R22;
 1394   const Register toc_temp             = R23;
 1395   assert_different_registers(R11, return_pc, callers_sp, push_frame_temp, toc_temp);
 1396 
 1397   if (method_is_frameless) {
 1398     // Add nop at beginning of all frameless methods to prevent any
 1399     // oop instructions from getting overwritten by make_not_entrant
 1400     // (patching attempt would fail).
 1401     ___(nop) nop();
 1402   } else {
 1403     // Get return pc.
 1404     ___(mflr) mflr(return_pc);
 1405   }
 1406 
</pre>
<hr />
<pre>
 1411     Register klass = toc_temp;
 1412 
 1413     // Notify OOP recorder (don&#39;t need the relocation)
 1414     AddressLiteral md = __ constant_metadata_address(C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1415     __ load_const_optimized(klass, md.value(), R0);
 1416     __ clinit_barrier(klass, R16_thread, &amp;L_skip_barrier /*L_fast_path*/);
 1417 
 1418     __ load_const_optimized(klass, SharedRuntime::get_handle_wrong_method_stub(), R0);
 1419     __ mtctr(klass);
 1420     __ bctr();
 1421 
 1422     __ bind(L_skip_barrier);
 1423   }
 1424 
 1425   // Calls to C2R adapters often do not accept exceptional returns.
 1426   // We require that their callers must bang for them. But be
 1427   // careful, because some VM calls (such as call site linkage) can
 1428   // use several kilobytes of stack. But the stack safety zone should
 1429   // account for that. See bugs 4446381, 4468289, 4497237.
 1430 
<span class="line-modified"> 1431   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();</span>
 1432   assert(bangsize &gt;= framesize || bangsize &lt;= 0, &quot;stack bang size incorrect&quot;);
<span class="line-modified"> 1433   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging) {</span>
 1434     // Unfortunately we cannot use the function provided in
 1435     // assembler.cpp as we have to emulate the pipes. So I had to
 1436     // insert the code of generate_stack_overflow_check(), see
 1437     // assembler.cpp for some illuminative comments.
 1438     const int page_size = os::vm_page_size();
 1439     int bang_end = JavaThread::stack_shadow_zone_size();
 1440 
 1441     // This is how far the previous frame&#39;s stack banging extended.
 1442     const int bang_end_safe = bang_end;
 1443 
 1444     if (bangsize &gt; page_size) {
 1445       bang_end += bangsize;
 1446     }
 1447 
 1448     int bang_offset = bang_end_safe;
 1449 
 1450     while (bang_offset &lt;= bang_end) {
 1451       // Need at least one stack bang at end of shadow zone.
 1452 
 1453       // Again I had to copy code, this time from assembler_ppc.cpp,
</pre>
<hr />
<pre>
 1467         }
 1468       } else if (Assembler::is_simm(stdoffset, 31)) {
 1469         // Use largeoffset calculations for addis &amp; ld/std.
 1470         const int hi = MacroAssembler::largeoffset_si16_si16_hi(stdoffset);
 1471         const int lo = MacroAssembler::largeoffset_si16_si16_lo(stdoffset);
 1472 
 1473         Register tmp = R11;
 1474         ___(addis) addis(tmp, R1_SP, hi);
 1475         if (UseLoadInstructionsForStackBangingPPC64) {
 1476           ___(ld) ld(R0, lo, tmp);
 1477         } else {
 1478           ___(std) std(R0, lo, tmp);
 1479         }
 1480       } else {
 1481         ShouldNotReachHere();
 1482       }
 1483 
 1484       bang_offset += page_size;
 1485     }
 1486     // R11 trashed
<span class="line-modified"> 1487   } // C-&gt;output()-&gt;need_stack_bang(framesize) &amp;&amp; UseStackBanging</span>
 1488 
 1489   unsigned int bytes = (unsigned int)framesize;
 1490   long offset = Assembler::align_addr(bytes, frame::alignment_in_bytes);
 1491   ciMethod *currMethod = C-&gt;method();
 1492 
 1493   // Optimized version for most common case.
 1494   if (UsePower6SchedulerPPC64 &amp;&amp;
 1495       !method_is_frameless &amp;&amp; Assembler::is_simm((int)(-offset), 16) &amp;&amp;
 1496       !(false /* ConstantsALot TODO: PPC port*/)) {
 1497     ___(or) mr(callers_sp, R1_SP);
 1498     ___(std) std(return_pc, _abi(lr), R1_SP);
 1499     ___(stdu) stdu(R1_SP, -offset, R1_SP);
 1500     return;
 1501   }
 1502 
 1503   if (!method_is_frameless) {
 1504     // Get callers sp.
 1505     ___(or) mr(callers_sp, R1_SP);
 1506 
 1507     // Push method&#39;s frame, modifies SP.
</pre>
<hr />
<pre>
 1522       ___(ori)    ori( tmp, tmp, (x &amp; 0x0000ffff));
 1523 
 1524       ___(stdux) stdux(R1_SP, R1_SP, tmp);
 1525     }
 1526   }
 1527 #if 0 // TODO: PPC port
 1528   // For testing large constant pools, emit a lot of constants to constant pool.
 1529   // &quot;Randomize&quot; const_size.
 1530   if (ConstantsALot) {
 1531     const int num_consts = const_size();
 1532     for (int i = 0; i &lt; num_consts; i++) {
 1533       __ long_constant(0xB0B5B00BBABE);
 1534     }
 1535   }
 1536 #endif
 1537   if (!method_is_frameless) {
 1538     // Save return pc.
 1539     ___(std) std(return_pc, _abi(lr), callers_sp);
 1540   }
 1541 
<span class="line-modified"> 1542   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());</span>
 1543 }
 1544 #undef ___
 1545 #undef ___stop
 1546 #undef ___advance
 1547 
 1548 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
 1549   // Variable size. determine dynamically.
 1550   return MachNode::size(ra_);
 1551 }
 1552 
 1553 int MachPrologNode::reloc() const {
 1554   // Return number of relocatable values contained in this instruction.
 1555   return 1; // 1 reloc entry for load_const(toc).
 1556 }
 1557 
 1558 //=============================================================================
 1559 
 1560 #ifndef PRODUCT
 1561 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1562   Compile* C = ra_-&gt;C;
 1563 
 1564   st-&gt;print(&quot;EPILOG\n\t&quot;);
 1565   st-&gt;print(&quot;restore return pc\n\t&quot;);
 1566   st-&gt;print(&quot;pop frame\n\t&quot;);
 1567 
 1568   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1569     st-&gt;print(&quot;touch polling page\n\t&quot;);
 1570   }
 1571 }
 1572 #endif
 1573 
 1574 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1575   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1576   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1577 
<span class="line-modified"> 1578   const long framesize = ((long)C-&gt;output()-&gt;frame_slots()) &lt;&lt; LogBytesPerInt;</span>
 1579   assert(framesize &gt;= 0, &quot;negative frame-size?&quot;);
 1580 
 1581   const bool method_needs_polling = do_polling() &amp;&amp; C-&gt;is_method_compilation();
 1582   const bool method_is_frameless  = false /* TODO: PPC port C-&gt;is_frameless_method()*/;
 1583   const Register return_pc        = R31;  // Must survive C-call to enable_stack_reserved_zone().
 1584   const Register polling_page     = R12;
 1585 
 1586   if (!method_is_frameless) {
 1587     // Restore return pc relative to callers&#39; sp.
 1588     __ ld(return_pc, ((int)framesize) + _abi(lr), R1_SP);
 1589   }
 1590 
 1591   if (method_needs_polling) {
 1592     if (SafepointMechanism::uses_thread_local_poll()) {
 1593       __ ld(polling_page, in_bytes(JavaThread::polling_page_offset()), R16_thread);
 1594     } else {
 1595       __ load_const_optimized(polling_page, (long)(address) os::get_polling_page());
 1596     }
 1597   }
 1598 
</pre>
<hr />
<pre>
 1622 
 1623 int MachEpilogNode::reloc() const {
 1624   // Return number of relocatable values contained in this instruction.
 1625   return 1; // 1 for load_from_polling_page.
 1626 }
 1627 
 1628 const Pipeline * MachEpilogNode::pipeline() const {
 1629   return MachNode::pipeline_class();
 1630 }
 1631 
 1632 // This method seems to be obsolete. It is declared in machnode.hpp
 1633 // and defined in all *.ad files, but it is never called. Should we
 1634 // get rid of it?
 1635 int MachEpilogNode::safepoint_offset() const {
 1636   assert(do_polling(), &quot;no return for this epilog node&quot;);
 1637   return 0;
 1638 }
 1639 
 1640 #if 0 // TODO: PPC port
 1641 void MachLoadPollAddrLateNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
<span class="line-modified"> 1642   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1643   if (LoadPollAddressFromThread) {
 1644     _masm.ld(R11, in_bytes(JavaThread::poll_address_offset()), R16_thread);
 1645   } else {
 1646     _masm.nop();
 1647   }
 1648 }
 1649 
 1650 uint MachLoadPollAddrLateNode::size(PhaseRegAlloc* ra_) const {
 1651   if (LoadPollAddressFromThread) {
 1652     return 4;
 1653   } else {
 1654     return 4;
 1655   }
 1656 }
 1657 
 1658 #ifndef PRODUCT
 1659 void MachLoadPollAddrLateNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1660   st-&gt;print_cr(&quot; LD R11, PollAddressOffset, R16_thread \t// LoadPollAddressFromThread&quot;);
 1661 }
 1662 #endif
</pre>
<hr />
<pre>
 1739   enum RC dst_hi_rc = rc_class(dst_hi);
 1740   enum RC dst_lo_rc = rc_class(dst_lo);
 1741 
 1742   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1743   if (src_hi != OptoReg::Bad)
 1744     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1745            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1746            &quot;expected aligned-adjacent pairs&quot;);
 1747   // Generate spill code!
 1748   int size = 0;
 1749 
 1750   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi)
 1751     return size;            // Self copy, no move.
 1752 
 1753   if (bottom_type()-&gt;isa_vect() != NULL &amp;&amp; ideal_reg() == Op_VecX) {
 1754     // Memory-&gt;Memory Spill.
 1755     if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1756       int src_offset = ra_-&gt;reg2offset(src_lo);
 1757       int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1758       if (cbuf) {
<span class="line-modified"> 1759         C2_MacroAssembler _masm(cbuf);</span>
 1760         __ ld(R0, src_offset, R1_SP);
 1761         __ std(R0, dst_offset, R1_SP);
 1762         __ ld(R0, src_offset+8, R1_SP);
 1763         __ std(R0, dst_offset+8, R1_SP);
 1764       }
 1765       size += 16;
 1766     }
 1767     // VectorSRegister-&gt;Memory Spill.
 1768     else if (src_lo_rc == rc_vs &amp;&amp; dst_lo_rc == rc_stack) {
 1769       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
 1770       int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1771       if (cbuf) {
<span class="line-modified"> 1772         C2_MacroAssembler _masm(cbuf);</span>
 1773         __ addi(R0, R1_SP, dst_offset);
 1774         __ stxvd2x(Rsrc, R0);
 1775       }
 1776       size += 8;
 1777     }
 1778     // Memory-&gt;VectorSRegister Spill.
 1779     else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_vs) {
 1780       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
 1781       int src_offset = ra_-&gt;reg2offset(src_lo);
 1782       if (cbuf) {
<span class="line-modified"> 1783         C2_MacroAssembler _masm(cbuf);</span>
 1784         __ addi(R0, R1_SP, src_offset);
 1785         __ lxvd2x(Rdst, R0);
 1786       }
 1787       size += 8;
 1788     }
 1789     // VectorSRegister-&gt;VectorSRegister.
 1790     else if (src_lo_rc == rc_vs &amp;&amp; dst_lo_rc == rc_vs) {
 1791       VectorSRegister Rsrc = as_VectorSRegister(Matcher::_regEncode[src_lo]);
 1792       VectorSRegister Rdst = as_VectorSRegister(Matcher::_regEncode[dst_lo]);
 1793       if (cbuf) {
<span class="line-modified"> 1794         C2_MacroAssembler _masm(cbuf);</span>
 1795         __ xxlor(Rdst, Rsrc, Rsrc);
 1796       }
 1797       size += 4;
 1798     }
 1799     else {
 1800       ShouldNotReachHere(); // No VSR spill.
 1801     }
 1802     return size;
 1803   }
 1804 
 1805   // --------------------------------------
 1806   // Memory-&gt;Memory Spill. Use R0 to hold the value.
 1807   if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1808     int src_offset = ra_-&gt;reg2offset(src_lo);
 1809     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1810     if (src_hi != OptoReg::Bad) {
 1811       assert(src_hi_rc==rc_stack &amp;&amp; dst_hi_rc==rc_stack,
 1812              &quot;expected same type of move for high parts&quot;);
 1813       size += ld_st_helper(cbuf, &quot;LD  &quot;, Assembler::LD_OPCODE,  R0_num, src_offset, !do_size, C, st);
 1814       if (!cbuf &amp;&amp; !do_size) st-&gt;print(&quot;\n\t&quot;);
</pre>
<hr />
<pre>
 1818       if (!cbuf &amp;&amp; !do_size) st-&gt;print(&quot;\n\t&quot;);
 1819       size += ld_st_helper(cbuf, &quot;STW &quot;, Assembler::STW_OPCODE, R0_num, dst_offset, !do_size, C, st);
 1820     }
 1821     return size;
 1822   }
 1823 
 1824   // --------------------------------------
 1825   // Check for float-&gt;int copy; requires a trip through memory.
 1826   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_int) {
 1827     Unimplemented();
 1828   }
 1829 
 1830   // --------------------------------------
 1831   // Check for integer reg-reg copy.
 1832   if (src_lo_rc == rc_int &amp;&amp; dst_lo_rc == rc_int) {
 1833       Register Rsrc = as_Register(Matcher::_regEncode[src_lo]);
 1834       Register Rdst = as_Register(Matcher::_regEncode[dst_lo]);
 1835       size = (Rsrc != Rdst) ? 4 : 0;
 1836 
 1837       if (cbuf) {
<span class="line-modified"> 1838         C2_MacroAssembler _masm(cbuf);</span>
 1839         if (size) {
 1840           __ mr(Rdst, Rsrc);
 1841         }
 1842       }
 1843 #ifndef PRODUCT
 1844       else if (!do_size) {
 1845         if (size) {
 1846           st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;MR&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1847         } else {
 1848           st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;MR-NOP&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1849         }
 1850       }
 1851 #endif
 1852       return size;
 1853   }
 1854 
 1855   // Check for integer store.
 1856   if (src_lo_rc == rc_int &amp;&amp; dst_lo_rc == rc_stack) {
 1857     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1858     if (src_hi != OptoReg::Bad) {
</pre>
<hr />
<pre>
 1864     }
 1865     return size;
 1866   }
 1867 
 1868   // Check for integer load.
 1869   if (dst_lo_rc == rc_int &amp;&amp; src_lo_rc == rc_stack) {
 1870     int src_offset = ra_-&gt;reg2offset(src_lo);
 1871     if (src_hi != OptoReg::Bad) {
 1872       assert(dst_hi_rc==rc_int &amp;&amp; src_hi_rc==rc_stack,
 1873              &quot;expected same type of move for high parts&quot;);
 1874       size += ld_st_helper(cbuf, &quot;LD  &quot;, Assembler::LD_OPCODE, dst_lo, src_offset, !do_size, C, st);
 1875     } else {
 1876       size += ld_st_helper(cbuf, &quot;LWZ &quot;, Assembler::LWZ_OPCODE, dst_lo, src_offset, !do_size, C, st);
 1877     }
 1878     return size;
 1879   }
 1880 
 1881   // Check for float reg-reg copy.
 1882   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1883     if (cbuf) {
<span class="line-modified"> 1884       C2_MacroAssembler _masm(cbuf);</span>
 1885       FloatRegister Rsrc = as_FloatRegister(Matcher::_regEncode[src_lo]);
 1886       FloatRegister Rdst = as_FloatRegister(Matcher::_regEncode[dst_lo]);
 1887       __ fmr(Rdst, Rsrc);
 1888     }
 1889 #ifndef PRODUCT
 1890     else if (!do_size) {
 1891       st-&gt;print(&quot;%-7s %s, %s \t// spill copy&quot;, &quot;FMR&quot;, Matcher::regName[dst_lo], Matcher::regName[src_lo]);
 1892     }
 1893 #endif
 1894     return 4;
 1895   }
 1896 
 1897   // Check for float store.
 1898   if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1899     int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1900     if (src_hi != OptoReg::Bad) {
 1901       assert(src_hi_rc==rc_float &amp;&amp; dst_hi_rc==rc_stack,
 1902              &quot;expected same type of move for high parts&quot;);
 1903       size += ld_st_helper(cbuf, &quot;STFD&quot;, Assembler::STFD_OPCODE, src_lo, dst_offset, !do_size, C, st);
 1904     } else {
</pre>
<hr />
<pre>
 2034 
 2035   // --------------------------------------------------------------------
 2036   // Check for hi bits still needing moving. Only happens for misaligned
 2037   // arguments to native calls.
 2038   if (src_hi == dst_hi) {
 2039     return ppc64Opcode_none;               // Self copy; no move.
 2040   }
 2041 
 2042   ShouldNotReachHere();
 2043   return ppc64Opcode_undefined;
 2044 }
 2045 #endif // PPC port
 2046 
 2047 #ifndef PRODUCT
 2048 void MachNopNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2049   st-&gt;print(&quot;NOP \t// %d nops to pad for loops.&quot;, _count);
 2050 }
 2051 #endif
 2052 
 2053 void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *) const {
<span class="line-modified"> 2054   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2055   // _count contains the number of nops needed for padding.
 2056   for (int i = 0; i &lt; _count; i++) {
 2057     __ nop();
 2058   }
 2059 }
 2060 
 2061 uint MachNopNode::size(PhaseRegAlloc *ra_) const {
 2062   return _count * 4;
 2063 }
 2064 
 2065 #ifndef PRODUCT
 2066 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2067   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 2068   char reg_str[128];
 2069   ra_-&gt;dump_register(this, reg_str);
 2070   st-&gt;print(&quot;ADDI    %s, SP, %d \t// box node&quot;, reg_str, offset);
 2071 }
 2072 #endif
 2073 
 2074 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 2075   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2076 
 2077   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 2078   int reg    = ra_-&gt;get_encode(this);
 2079 
 2080   if (Assembler::is_simm(offset, 16)) {
 2081     __ addi(as_Register(reg), R1, offset);
 2082   } else {
 2083     ShouldNotReachHere();
 2084   }
 2085 }
 2086 
 2087 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 2088   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 2089   return 4;
 2090 }
 2091 
 2092 #ifndef PRODUCT
 2093 void MachUEPNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 2094   st-&gt;print_cr(&quot;---- MachUEPNode ----&quot;);
 2095   st-&gt;print_cr(&quot;...&quot;);
 2096 }
 2097 #endif
 2098 
 2099 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 2100   // This is the unverified entry point.
<span class="line-modified"> 2101   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2102 
 2103   // Inline_cache contains a klass.
 2104   Register ic_klass       = as_Register(Matcher::inline_cache_reg_encode());
 2105   Register receiver_klass = R12_scratch2;  // tmp
 2106 
 2107   assert_different_registers(ic_klass, receiver_klass, R11_scratch1, R3_ARG1);
 2108   assert(R11_scratch1 == R11, &quot;need prologue scratch register&quot;);
 2109 
 2110   // Check for NULL argument if we don&#39;t have implicit null checks.
 2111   if (!ImplicitNullChecks || !os::zero_page_read_protected()) {
 2112     if (TrapBasedNullChecks) {
 2113       __ trap_null_check(R3_ARG1);
 2114     } else {
 2115       Label valid;
 2116       __ cmpdi(CCR0, R3_ARG1, 0);
 2117       __ bne_predict_taken(CCR0, valid);
 2118       // We have a null argument, branch to ic_miss_stub.
 2119       __ b64_patchable((address)SharedRuntime::get_ic_miss_stub(),
 2120                            relocInfo::runtime_call_type);
 2121       __ bind(valid);
</pre>
<hr />
<pre>
 2164   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 2165   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 2166 
 2167   static uint size_exception_handler() {
 2168     // The exception_handler is a b64_patchable.
 2169     return MacroAssembler::b64_patchable_size;
 2170   }
 2171 
 2172   static uint size_deopt_handler() {
 2173     // The deopt_handler is a bl64_patchable.
 2174     return MacroAssembler::bl64_patchable_size;
 2175   }
 2176 
 2177 };
 2178 
 2179 %} // end source_hpp
 2180 
 2181 source %{
 2182 
 2183 int HandlerImpl::emit_exception_handler(CodeBuffer &amp;cbuf) {
<span class="line-modified"> 2184   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2185 
 2186   address base = __ start_a_stub(size_exception_handler());
 2187   if (base == NULL) return 0; // CodeBuffer::expand failed
 2188 
 2189   int offset = __ offset();
 2190   __ b64_patchable((address)OptoRuntime::exception_blob()-&gt;content_begin(),
 2191                        relocInfo::runtime_call_type);
 2192   assert(__ offset() - offset == (int)size_exception_handler(), &quot;must be fixed size&quot;);
 2193   __ end_a_stub();
 2194 
 2195   return offset;
 2196 }
 2197 
 2198 // The deopt_handler is like the exception handler, but it calls to
 2199 // the deoptimization blob instead of jumping to the exception blob.
 2200 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf) {
<span class="line-modified"> 2201   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2202 
 2203   address base = __ start_a_stub(size_deopt_handler());
 2204   if (base == NULL) return 0; // CodeBuffer::expand failed
 2205 
 2206   int offset = __ offset();
 2207   __ bl64_patchable((address)SharedRuntime::deopt_blob()-&gt;unpack(),
 2208                         relocInfo::runtime_call_type);
 2209   assert(__ offset() - offset == (int) size_deopt_handler(), &quot;must be fixed size&quot;);
 2210   __ end_a_stub();
 2211 
 2212   return offset;
 2213 }
 2214 
 2215 //=============================================================================
 2216 
 2217 // Use a frame slots bias for frameless methods if accessing the stack.
 2218 static int frame_slots_bias(int reg_enc, PhaseRegAlloc* ra_) {
 2219   if (as_Register(reg_enc) == R1_SP) {
 2220     return 0; // TODO: PPC port ra_-&gt;C-&gt;frame_slots_sp_bias_in_bytes();
 2221   }
</pre>
<hr />
<pre>
 2645 // operand to generate a function which returns its register number when
 2646 // queried. CONST_INTER causes an operand to generate a function which
 2647 // returns the value of the constant when queried. MEMORY_INTER causes an
 2648 // operand to generate four functions which return the Base Register, the
 2649 // Index Register, the Scale Value, and the Offset Value of the operand when
 2650 // queried. COND_INTER causes an operand to generate six functions which
 2651 // return the encoding code (ie - encoding bits for the instruction)
 2652 // associated with each basic boolean condition for a conditional instruction.
 2653 //
 2654 // Instructions specify two basic values for encoding. Again, a function
 2655 // is available to check if the constant displacement is an oop. They use the
 2656 // ins_encode keyword to specify their encoding classes (which must be
 2657 // a sequence of enc_class names, and their parameters, specified in
 2658 // the encoding block), and they use the
 2659 // opcode keyword to specify, in order, their primary, secondary, and
 2660 // tertiary opcode. Only the opcode sections which a particular instruction
 2661 // needs for encoding need to be specified.
 2662 encode %{
 2663   enc_class enc_unimplemented %{
 2664     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2665     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2666     __ unimplemented(&quot;Unimplemented mach node encoding in AD file.&quot;, 13);
 2667   %}
 2668 
 2669   enc_class enc_untested %{
 2670 #ifdef ASSERT
 2671     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2672     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2673     __ untested(&quot;Untested mach node encoding in AD file.&quot;);
 2674 #else
 2675     // TODO: PPC port $archOpcode(ppc64Opcode_none);
 2676 #endif
 2677   %}
 2678 
 2679   enc_class enc_lbz(iRegIdst dst, memory mem) %{
 2680     // TODO: PPC port $archOpcode(ppc64Opcode_lbz);
<span class="line-modified"> 2681     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2682     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2683     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
 2684   %}
 2685 
 2686   // Load acquire.
 2687   enc_class enc_lbz_ac(iRegIdst dst, memory mem) %{
 2688     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2689     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2690     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2691     __ lbz($dst$$Register, Idisp, $mem$$base$$Register);
 2692     __ twi_0($dst$$Register);
 2693     __ isync();
 2694   %}
 2695 
 2696   enc_class enc_lhz(iRegIdst dst, memory mem) %{
 2697     // TODO: PPC port $archOpcode(ppc64Opcode_lhz);
 2698 
<span class="line-modified"> 2699     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2700     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2701     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
 2702   %}
 2703 
 2704   // Load acquire.
 2705   enc_class enc_lhz_ac(iRegIdst dst, memory mem) %{
 2706     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 2707 
<span class="line-modified"> 2708     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2709     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2710     __ lhz($dst$$Register, Idisp, $mem$$base$$Register);
 2711     __ twi_0($dst$$Register);
 2712     __ isync();
 2713   %}
 2714 
 2715   enc_class enc_lwz(iRegIdst dst, memory mem) %{
 2716     // TODO: PPC port $archOpcode(ppc64Opcode_lwz);
 2717 
<span class="line-modified"> 2718     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2719     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2720     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
 2721   %}
 2722 
 2723   // Load acquire.
 2724   enc_class enc_lwz_ac(iRegIdst dst, memory mem) %{
 2725     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 2726 
<span class="line-modified"> 2727     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2728     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2729     __ lwz($dst$$Register, Idisp, $mem$$base$$Register);
 2730     __ twi_0($dst$$Register);
 2731     __ isync();
 2732   %}
 2733 
 2734   enc_class enc_ld(iRegLdst dst, memoryAlg4 mem) %{
 2735     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 2736     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2737     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2738     // Operand &#39;ds&#39; requires 4-alignment.
 2739     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 2740     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 2741   %}
 2742 
 2743   // Load acquire.
 2744   enc_class enc_ld_ac(iRegLdst dst, memoryAlg4 mem) %{
 2745     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 2746     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2747     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2748     // Operand &#39;ds&#39; requires 4-alignment.
 2749     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 2750     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 2751     __ twi_0($dst$$Register);
 2752     __ isync();
 2753   %}
 2754 
 2755   enc_class enc_lfd(RegF dst, memory mem) %{
 2756     // TODO: PPC port $archOpcode(ppc64Opcode_lfd);
<span class="line-modified"> 2757     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2758     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 2759     __ lfd($dst$$FloatRegister, Idisp, $mem$$base$$Register);
 2760   %}
 2761 
 2762   enc_class enc_load_long_constL(iRegLdst dst, immL src, iRegLdst toc) %{
 2763     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 2764 
<span class="line-modified"> 2765     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2766     int toc_offset = 0;
 2767 
 2768     address const_toc_addr;
 2769     // Create a non-oop constant, no relocation needed.
 2770     // If it is an IC, it has a virtual_call_Relocation.
 2771     const_toc_addr = __ long_constant((jlong)$src$$constant);
 2772     if (const_toc_addr == NULL) {
 2773       ciEnv::current()-&gt;record_out_of_memory_failure();
 2774       return;
 2775     }
 2776 
 2777     // Get the constant&#39;s TOC offset.
 2778     toc_offset = __ offset_to_method_toc(const_toc_addr);
 2779 
 2780     // Keep the current instruction offset in mind.
 2781     ((loadConLNode*)this)-&gt;_cbuf_insts_offset = __ offset();
 2782 
 2783     __ ld($dst$$Register, toc_offset, $toc$$Register);
 2784   %}
 2785 
 2786   enc_class enc_load_long_constL_hi(iRegLdst dst, iRegLdst toc, immL src) %{
 2787     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 2788 
<span class="line-modified"> 2789     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2790 
<span class="line-modified"> 2791     if (!ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size()) {</span>
 2792       address const_toc_addr;
 2793       // Create a non-oop constant, no relocation needed.
 2794       // If it is an IC, it has a virtual_call_Relocation.
 2795       const_toc_addr = __ long_constant((jlong)$src$$constant);
 2796       if (const_toc_addr == NULL) {
 2797         ciEnv::current()-&gt;record_out_of_memory_failure();
 2798         return;
 2799       }
 2800 
 2801       // Get the constant&#39;s TOC offset.
 2802       const int toc_offset = __ offset_to_method_toc(const_toc_addr);
 2803       // Store the toc offset of the constant.
 2804       ((loadConL_hiNode*)this)-&gt;_const_toc_offset = toc_offset;
 2805 
 2806       // Also keep the current instruction offset in mind.
 2807       ((loadConL_hiNode*)this)-&gt;_cbuf_insts_offset = __ offset();
 2808     }
 2809 
 2810     __ addis($dst$$Register, $toc$$Register, MacroAssembler::largeoffset_si16_si16_hi(_const_toc_offset));
 2811   %}
</pre>
<hr />
<pre>
 3004   // Enc_class needed as consttanttablebase is not supported by postalloc
 3005   // expand.
 3006   enc_class postalloc_expand_load_long_constant(iRegLdst dst, immL src, iRegLdst toc) %{
 3007     // Create new nodes.
 3008     loadConLNodesTuple loadConLNodes =
 3009       loadConLNodesTuple_create(ra_, n_toc, op_src,
 3010                                 ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3011 
 3012     // Push new nodes.
 3013     if (loadConLNodes._large_hi) nodes-&gt;push(loadConLNodes._large_hi);
 3014     if (loadConLNodes._last)     nodes-&gt;push(loadConLNodes._last);
 3015 
 3016     // some asserts
 3017     assert(nodes-&gt;length() &gt;= 1, &quot;must have created at least 1 node&quot;);
 3018     assert(loadConLNodes._last-&gt;bottom_type()-&gt;isa_long(), &quot;must be long&quot;);
 3019   %}
 3020 
 3021   enc_class enc_load_long_constP(iRegLdst dst, immP src, iRegLdst toc) %{
 3022     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 3023 
<span class="line-modified"> 3024     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3025     int toc_offset = 0;
 3026 
 3027     intptr_t val = $src$$constant;
 3028     relocInfo::relocType constant_reloc = $src-&gt;constant_reloc();  // src
 3029     address const_toc_addr;
 3030     if (constant_reloc == relocInfo::oop_type) {
 3031       // Create an oop constant and a corresponding relocation.
 3032       AddressLiteral a = __ allocate_oop_address((jobject)val);
 3033       const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3034       __ relocate(a.rspec());
 3035     } else if (constant_reloc == relocInfo::metadata_type) {
 3036       AddressLiteral a = __ constant_metadata_address((Metadata *)val);
 3037       const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3038       __ relocate(a.rspec());
 3039     } else {
 3040       // Create a non-oop constant, no relocation needed.
 3041       const_toc_addr = __ long_constant((jlong)$src$$constant);
 3042     }
 3043 
 3044     if (const_toc_addr == NULL) {
 3045       ciEnv::current()-&gt;record_out_of_memory_failure();
 3046       return;
 3047     }
 3048     // Get the constant&#39;s TOC offset.
 3049     toc_offset = __ offset_to_method_toc(const_toc_addr);
 3050 
 3051     __ ld($dst$$Register, toc_offset, $toc$$Register);
 3052   %}
 3053 
 3054   enc_class enc_load_long_constP_hi(iRegLdst dst, immP src, iRegLdst toc) %{
 3055     // TODO: PPC port $archOpcode(ppc64Opcode_addis);
 3056 
<span class="line-modified"> 3057     C2_MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 3058     if (!ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size()) {</span>
 3059       intptr_t val = $src$$constant;
 3060       relocInfo::relocType constant_reloc = $src-&gt;constant_reloc();  // src
 3061       address const_toc_addr;
 3062       if (constant_reloc == relocInfo::oop_type) {
 3063         // Create an oop constant and a corresponding relocation.
 3064         AddressLiteral a = __ allocate_oop_address((jobject)val);
 3065         const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3066         __ relocate(a.rspec());
 3067       } else if (constant_reloc == relocInfo::metadata_type) {
 3068         AddressLiteral a = __ constant_metadata_address((Metadata *)val);
 3069         const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);
 3070         __ relocate(a.rspec());
 3071       } else {  // non-oop pointers, e.g. card mark base, heap top
 3072         // Create a non-oop constant, no relocation needed.
 3073         const_toc_addr = __ long_constant((jlong)$src$$constant);
 3074       }
 3075 
 3076       if (const_toc_addr == NULL) {
 3077         ciEnv::current()-&gt;record_out_of_memory_failure();
 3078         return;
</pre>
<hr />
<pre>
 3171     if (large_constant_pool) {
 3172       m2 = new loadConDCompNode();
 3173     } else {
 3174       m2 = new loadConDNode();
 3175     }
 3176     // inputs for new nodes
 3177     m2-&gt;add_req(NULL, n_toc);
 3178 
 3179     // operands for new nodes
 3180     m2-&gt;_opnds[0] = op_dst;
 3181     m2-&gt;_opnds[1] = op_src;
 3182     m2-&gt;_opnds[2] = new iRegPdstOper(); // constanttablebase
 3183 
 3184     // register allocation for new nodes
 3185     ra_-&gt;set_pair(m2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3186     nodes-&gt;push(m2);
 3187   %}
 3188 
 3189   enc_class enc_stw(iRegIsrc src, memory mem) %{
 3190     // TODO: PPC port $archOpcode(ppc64Opcode_stw);
<span class="line-modified"> 3191     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3192     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3193     __ stw($src$$Register, Idisp, $mem$$base$$Register);
 3194   %}
 3195 
 3196   enc_class enc_std(iRegIsrc src, memoryAlg4 mem) %{
 3197     // TODO: PPC port $archOpcode(ppc64Opcode_std);
<span class="line-modified"> 3198     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3199     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3200     // Operand &#39;ds&#39; requires 4-alignment.
 3201     assert((Idisp &amp; 0x3) == 0, &quot;unaligned offset&quot;);
 3202     __ std($src$$Register, Idisp, $mem$$base$$Register);
 3203   %}
 3204 
 3205   enc_class enc_stfs(RegF src, memory mem) %{
 3206     // TODO: PPC port $archOpcode(ppc64Opcode_stfs);
<span class="line-modified"> 3207     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3208     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3209     __ stfs($src$$FloatRegister, Idisp, $mem$$base$$Register);
 3210   %}
 3211 
 3212   enc_class enc_stfd(RegF src, memory mem) %{
 3213     // TODO: PPC port $archOpcode(ppc64Opcode_stfd);
<span class="line-modified"> 3214     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3215     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3216     __ stfd($src$$FloatRegister, Idisp, $mem$$base$$Register);
 3217   %}
 3218 
 3219   // Use release_store for card-marking to ensure that previous
 3220   // oop-stores are visible before the card-mark change.
 3221   enc_class enc_cms_card_mark(memory mem, iRegLdst releaseFieldAddr, flagsReg crx) %{
 3222     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3223     // FIXME: Implement this as a cmove and use a fixed condition code
 3224     // register which is written on every transition to compiled code,
 3225     // e.g. in call-stub and when returning from runtime stubs.
 3226     //
 3227     // Proposed code sequence for the cmove implementation:
 3228     //
 3229     // Label skip_release;
 3230     // __ beq(CCRfixed, skip_release);
 3231     // __ release();
 3232     // __ bind(skip_release);
 3233     // __ stb(card mark);
 3234 
<span class="line-modified"> 3235     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3236     Label skip_storestore;
 3237 
 3238 #if 0 // TODO: PPC port
 3239     // Check CMSCollectorCardTableBarrierSetBSExt::_requires_release and do the
 3240     // StoreStore barrier conditionally.
 3241     __ lwz(R0, 0, $releaseFieldAddr$$Register);
 3242     __ cmpwi($crx$$CondRegister, R0, 0);
 3243     __ beq_predict_taken($crx$$CondRegister, skip_storestore);
 3244 #endif
 3245     __ li(R0, 0);
 3246     __ membar(Assembler::StoreStore);
 3247 #if 0 // TODO: PPC port
 3248     __ bind(skip_storestore);
 3249 #endif
 3250 
 3251     // Do the store.
 3252     if ($mem$$index == 0) {
 3253       __ stb(R0, $mem$$disp, $mem$$base$$Register);
 3254     } else {
 3255       assert(0 == $mem$$disp, &quot;no displacement possible with indexed load/stores on ppc&quot;);
</pre>
<hr />
<pre>
 3436     n1-&gt;_bottom_type = _bottom_type;
 3437 
 3438     decodeN_addNode *n2 = new decodeN_addNode();
 3439     n2-&gt;add_req(n_region, n1);
 3440     n2-&gt;_opnds[0] = op_dst;
 3441     n2-&gt;_opnds[1] = op_dst;
 3442     n2-&gt;_bottom_type = _bottom_type;
 3443     ra_-&gt;set_pair(n1-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3444     ra_-&gt;set_pair(n2-&gt;_idx, ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3445 
 3446     assert(ra_-&gt;is_oop(this) == true, &quot;A decodeN node must produce an oop!&quot;);
 3447     ra_-&gt;set_oop(n2, true);
 3448 
 3449     nodes-&gt;push(n1);
 3450     nodes-&gt;push(n2);
 3451   %}
 3452 
 3453   enc_class enc_cmove_reg(iRegIdst dst, flagsRegSrc crx, iRegIsrc src, cmpOp cmp) %{
 3454     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3455 
<span class="line-modified"> 3456     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3457     int cc        = $cmp$$cmpcode;
 3458     int flags_reg = $crx$$reg;
 3459     Label done;
 3460     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3461     // Branch if not (cmp crx).
 3462     __ bc(cc_to_inverse_boint(cc), cc_to_biint(cc, flags_reg), done);
 3463     __ mr($dst$$Register, $src$$Register);
 3464     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3465     __ bind(done);
 3466   %}
 3467 
 3468   enc_class enc_cmove_imm(iRegIdst dst, flagsRegSrc crx, immI16 src, cmpOp cmp) %{
 3469     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3470 
<span class="line-modified"> 3471     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3472     Label done;
 3473     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3474     // Branch if not (cmp crx).
 3475     __ bc(cc_to_inverse_boint($cmp$$cmpcode), cc_to_biint($cmp$$cmpcode, $crx$$reg), done);
 3476     __ li($dst$$Register, $src$$constant);
 3477     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3478     __ bind(done);
 3479   %}
 3480 
 3481   // This enc_class is needed so that scheduler gets proper
 3482   // input mapping for latency computation.
 3483   enc_class enc_andc(iRegIdst dst, iRegIsrc src1, iRegIsrc src2) %{
 3484     // TODO: PPC port $archOpcode(ppc64Opcode_andc);
<span class="line-modified"> 3485     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3486     __ andc($dst$$Register, $src1$$Register, $src2$$Register);
 3487   %}
 3488 
 3489   enc_class enc_convI2B_regI__cmove(iRegIdst dst, iRegIsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
 3490     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3491 
<span class="line-modified"> 3492     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3493 
 3494     Label done;
 3495     __ cmpwi($crx$$CondRegister, $src$$Register, 0);
 3496     __ li($dst$$Register, $zero$$constant);
 3497     __ beq($crx$$CondRegister, done);
 3498     __ li($dst$$Register, $notzero$$constant);
 3499     __ bind(done);
 3500   %}
 3501 
 3502   enc_class enc_convP2B_regP__cmove(iRegIdst dst, iRegPsrc src, flagsReg crx, immI16 zero, immI16 notzero) %{
 3503     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3504 
<span class="line-modified"> 3505     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3506 
 3507     Label done;
 3508     __ cmpdi($crx$$CondRegister, $src$$Register, 0);
 3509     __ li($dst$$Register, $zero$$constant);
 3510     __ beq($crx$$CondRegister, done);
 3511     __ li($dst$$Register, $notzero$$constant);
 3512     __ bind(done);
 3513   %}
 3514 
 3515   enc_class enc_cmove_bso_stackSlotL(iRegLdst dst, flagsRegSrc crx, stackSlotL mem ) %{
 3516     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3517 
<span class="line-modified"> 3518     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3519     int Idisp = $mem$$disp + frame_slots_bias($mem$$base, ra_);
 3520     Label done;
 3521     __ bso($crx$$CondRegister, done);
 3522     __ ld($dst$$Register, Idisp, $mem$$base$$Register);
 3523     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3524     __ bind(done);
 3525   %}
 3526 
 3527   enc_class enc_cmove_bso_reg(iRegLdst dst, flagsRegSrc crx, regD src) %{
 3528     // TODO: PPC port $archOpcode(ppc64Opcode_cmove);
 3529 
<span class="line-modified"> 3530     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3531     Label done;
 3532     __ bso($crx$$CondRegister, done);
 3533     __ mffprd($dst$$Register, $src$$FloatRegister);
 3534     // TODO PPC port __ endgroup_if_needed(_size == 12);
 3535     __ bind(done);
 3536   %}
 3537 
 3538   enc_class enc_bc(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3539     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3540 
<span class="line-modified"> 3541     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3542     Label d;   // dummy
 3543     __ bind(d);
 3544     Label* p = ($lbl$$label);
 3545     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3546     // determine the size of the encoded instruction.
 3547     Label&amp; l = (NULL == p)? d : *(p);
 3548     int cc = $cmp$$cmpcode;
 3549     int flags_reg = $crx$$reg;
 3550     assert((Assembler::bcondCRbiIs1 &amp; ~Assembler::bcondCRbiIs0) == 8, &quot;check encoding&quot;);
 3551     int bhint = Assembler::bhintNoHint;
 3552 
 3553     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3554       if (_prob &lt;= PROB_NEVER) {
 3555         bhint = Assembler::bhintIsNotTaken;
 3556       } else if (_prob &gt;= PROB_ALWAYS) {
 3557         bhint = Assembler::bhintIsTaken;
 3558       }
 3559     }
 3560 
 3561     __ bc(Assembler::add_bhint_to_boint(bhint, cc_to_boint(cc)),
 3562           cc_to_biint(cc, flags_reg),
 3563           l);
 3564   %}
 3565 
 3566   enc_class enc_bc_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3567     // The scheduler doesn&#39;t know about branch shortening, so we set the opcode
 3568     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
 3569     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3570 
<span class="line-modified"> 3571     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3572     Label d;    // dummy
 3573     __ bind(d);
 3574     Label* p = ($lbl$$label);
 3575     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3576     // determine the size of the encoded instruction.
 3577     Label&amp; l = (NULL == p)? d : *(p);
 3578     int cc = $cmp$$cmpcode;
 3579     int flags_reg = $crx$$reg;
 3580     int bhint = Assembler::bhintNoHint;
 3581 
 3582     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3583       if (_prob &lt;= PROB_NEVER) {
 3584         bhint = Assembler::bhintIsNotTaken;
 3585       } else if (_prob &gt;= PROB_ALWAYS) {
 3586         bhint = Assembler::bhintIsTaken;
 3587       }
 3588     }
 3589 
 3590     // Tell the conditional far branch to optimize itself when being relocated.
 3591     __ bc_far(Assembler::add_bhint_to_boint(bhint, cc_to_boint(cc)),
 3592                   cc_to_biint(cc, flags_reg),
 3593                   l,
 3594                   MacroAssembler::bc_far_optimize_on_relocate);
 3595   %}
 3596 
 3597   // Branch used with Power6 scheduling (can be shortened without changing the node).
 3598   enc_class enc_bc_short_far(flagsRegSrc crx, cmpOp cmp, Label lbl) %{
 3599     // The scheduler doesn&#39;t know about branch shortening, so we set the opcode
 3600     // to ppc64Opcode_bc in order to hide this detail from the scheduler.
 3601     // TODO: PPC port $archOpcode(ppc64Opcode_bc);
 3602 
<span class="line-modified"> 3603     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3604     Label d;   // dummy
 3605     __ bind(d);
 3606     Label* p = ($lbl$$label);
 3607     // `p&#39; is `NULL&#39; when this encoding class is used only to
 3608     // determine the size of the encoded instruction.
 3609     Label&amp; l = (NULL == p)? d : *(p);
 3610     int cc = $cmp$$cmpcode;
 3611     int flags_reg = $crx$$reg;
 3612     int bhint = Assembler::bhintNoHint;
 3613 
 3614     if (UseStaticBranchPredictionForUncommonPathsPPC64) {
 3615       if (_prob &lt;= PROB_NEVER) {
 3616         bhint = Assembler::bhintIsNotTaken;
 3617       } else if (_prob &gt;= PROB_ALWAYS) {
 3618         bhint = Assembler::bhintIsTaken;
 3619       }
 3620     }
 3621 
 3622 #if 0 // TODO: PPC port
 3623     if (_size == 8) {
</pre>
<hr />
<pre>
 3668       loadConLReplicatedNodesTuple_create(C, ra_, n_toc, op_repl, op_dst, op_zero,
 3669                                 ra_-&gt;get_reg_second(n_tmp), ra_-&gt;get_reg_first(n_tmp),
 3670                                 ra_-&gt;get_reg_second(this), ra_-&gt;get_reg_first(this));
 3671 
 3672     // Push new nodes.
 3673     if (loadConLNodes._large_hi) { nodes-&gt;push(loadConLNodes._large_hi); }
 3674     if (loadConLNodes._large_lo) { nodes-&gt;push(loadConLNodes._large_lo); }
 3675     if (loadConLNodes._moved)    { nodes-&gt;push(loadConLNodes._moved); }
 3676     if (loadConLNodes._last)     { nodes-&gt;push(loadConLNodes._last); }
 3677 
 3678     assert(nodes-&gt;length() &gt;= 1, &quot;must have created at least 1 node&quot;);
 3679   %}
 3680 
 3681   // This enc_class is needed so that scheduler gets proper
 3682   // input mapping for latency computation.
 3683   enc_class enc_poll(immI dst, iRegLdst poll) %{
 3684     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
 3685     // Fake operand dst needed for PPC scheduler.
 3686     assert($dst$$constant == 0x0, &quot;dst must be 0x0&quot;);
 3687 
<span class="line-modified"> 3688     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3689     // Mark the code position where the load from the safepoint
 3690     // polling page was emitted as relocInfo::poll_type.
 3691     __ relocate(relocInfo::poll_type);
 3692     __ load_from_polling_page($poll$$Register);
 3693   %}
 3694 
 3695   // A Java static call or a runtime call.
 3696   //
 3697   // Branch-and-link relative to a trampoline.
 3698   // The trampoline loads the target address and does a long branch to there.
 3699   // In case we call java, the trampoline branches to a interpreter_stub
 3700   // which loads the inline cache and the real call target from the constant pool.
 3701   //
 3702   // This basically looks like this:
 3703   //
 3704   // &gt;&gt;&gt;&gt; consts      -+  -+
 3705   //                   |   |- offset1
 3706   // [call target1]    | &lt;-+
 3707   // [IC cache]        |- offset2
 3708   // [call target2] &lt;--+
</pre>
<hr />
<pre>
 3724   //   r1 = toc
 3725   //   ICreg = [r1 + IC_offset]         // Load IC from const section
 3726   //   r1    = [r1 + offset2]           // Load call target2 from const section
 3727   //   mtctr r1
 3728   //   bctr
 3729   //
 3730   // &lt;&lt;&lt;&lt; stubs
 3731   //
 3732   // The call instruction in the code either
 3733   // - Branches directly to a compiled method if the offset is encodable in instruction.
 3734   // - Branches to the trampoline stub if the offset to the compiled method is not encodable.
 3735   // - Branches to the compiled_to_interp stub if the target is interpreted.
 3736   //
 3737   // Further there are three relocations from the loads to the constants in
 3738   // the constant section.
 3739   //
 3740   // Usage of r1 and r2 in the stubs allows to distinguish them.
 3741   enc_class enc_java_static_call(method meth) %{
 3742     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 3743 
<span class="line-modified"> 3744     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3745     address entry_point = (address)$meth$$method;
 3746 
 3747     if (!_method) {
 3748       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3749       emit_call_with_trampoline_stub(_masm, entry_point, relocInfo::runtime_call_type);
 3750     } else {
 3751       // Remember the offset not the address.
 3752       const int start_offset = __ offset();
 3753 
 3754       // The trampoline stub.
 3755       // No entry point given, use the current pc.
 3756       // Make sure branch fits into
 3757       if (entry_point == 0) entry_point = __ pc();
 3758 
 3759       // Put the entry point as a constant into the constant pool.
 3760       const address entry_point_toc_addr = __ address_constant(entry_point, RelocationHolder::none);
 3761       if (entry_point_toc_addr == NULL) {
 3762         ciEnv::current()-&gt;record_out_of_memory_failure();
 3763         return;
 3764       }
</pre>
<hr />
<pre>
 3774       // The real call.
 3775       // Note: At this point we do not have the address of the trampoline
 3776       // stub, and the entry point might be too far away for bl, so __ pc()
 3777       // serves as dummy and the bl will be patched later.
 3778       cbuf.set_insts_mark();
 3779       __ bl(__ pc());  // Emits a relocation.
 3780 
 3781       // The stub for call to interpreter.
 3782       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3783       if (stub == NULL) {
 3784         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3785         return;
 3786       }
 3787     }
 3788   %}
 3789 
 3790   // Second node of expanded dynamic call - the call.
 3791   enc_class enc_java_dynamic_call_sched(method meth) %{
 3792     // TODO: PPC port $archOpcode(ppc64Opcode_bl);
 3793 
<span class="line-modified"> 3794     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3795 
<span class="line-modified"> 3796     if (!ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size()) {</span>
 3797       // Create a call trampoline stub for the given method.
 3798       const address entry_point = !($meth$$method) ? 0 : (address)$meth$$method;
 3799       const address entry_point_const = __ address_constant(entry_point, RelocationHolder::none);
 3800       if (entry_point_const == NULL) {
 3801         ciEnv::current()-&gt;record_out_of_memory_failure();
 3802         return;
 3803       }
 3804       const int entry_point_const_toc_offset = __ offset_to_method_toc(entry_point_const);
 3805       CallStubImpl::emit_trampoline_stub(_masm, entry_point_const_toc_offset, __ offset());
 3806       if (ra_-&gt;C-&gt;env()-&gt;failing()) { return; } // Code cache may be full.
 3807 
 3808       // Build relocation at call site with ic position as data.
 3809       assert((_load_ic_hi_node != NULL &amp;&amp; _load_ic_node == NULL) ||
 3810              (_load_ic_hi_node == NULL &amp;&amp; _load_ic_node != NULL),
 3811              &quot;must have one, but can&#39;t have both&quot;);
 3812       assert((_load_ic_hi_node != NULL &amp;&amp; _load_ic_hi_node-&gt;_cbuf_insts_offset != -1) ||
 3813              (_load_ic_node != NULL    &amp;&amp; _load_ic_node-&gt;_cbuf_insts_offset != -1),
 3814              &quot;must contain instruction offset&quot;);
 3815       const int virtual_call_oop_addr_offset = _load_ic_hi_node != NULL
 3816         ? _load_ic_hi_node-&gt;_cbuf_insts_offset
</pre>
<hr />
<pre>
 3877     call-&gt;_load_ic_node    = loadConLNodes_IC._small;
 3878 
 3879     // Operands for new nodes.
 3880     call-&gt;_opnds[0] = _opnds[0];
 3881     call-&gt;_opnds[1] = _opnds[1];
 3882 
 3883     // Only the inline cache is associated with a register.
 3884     assert(Matcher::inline_cache_reg() == OptoReg::Name(R19_num), &quot;ic reg should be R19&quot;);
 3885 
 3886     // Push new nodes.
 3887     if (loadConLNodes_IC._large_hi) nodes-&gt;push(loadConLNodes_IC._large_hi);
 3888     if (loadConLNodes_IC._last)     nodes-&gt;push(loadConLNodes_IC._last);
 3889     nodes-&gt;push(call);
 3890   %}
 3891 
 3892   // Compound version of call dynamic
 3893   // Toc is only passed so that it can be used in ins_encode statement.
 3894   // In the code we have to use $constanttablebase.
 3895   enc_class enc_java_dynamic_call(method meth, iRegLdst toc) %{
 3896     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
<span class="line-modified"> 3897     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3898     int start_offset = __ offset();
 3899 
 3900     Register Rtoc = (ra_) ? $constanttablebase : R2_TOC;
 3901 #if 0
 3902     int vtable_index = this-&gt;_vtable_index;
 3903     if (_vtable_index &lt; 0) {
 3904       // Must be invalid_vtable_index, not nonvirtual_vtable_index.
 3905       assert(_vtable_index == Method::invalid_vtable_index, &quot;correct sentinel value&quot;);
 3906       Register ic_reg = as_Register(Matcher::inline_cache_reg_encode());
 3907 
 3908       // Virtual call relocation will point to ic load.
 3909       address virtual_call_meta_addr = __ pc();
 3910       // Load a clear inline cache.
 3911       AddressLiteral empty_ic((address) Universe::non_oop_word());
 3912       bool success = __ load_const_from_method_toc(ic_reg, empty_ic, Rtoc, /*fixed_size*/ true);
 3913       if (!success) {
 3914         ciEnv::current()-&gt;record_out_of_memory_failure();
 3915         return;
 3916       }
 3917       // CALL to fixup routine.  Fixup routine uses ScopeDesc info
</pre>
<hr />
<pre>
 3936       // null. However it may very well end up in handle_wrong_method
 3937       // if the method is abstract for the particular class.
 3938       __ ld(R11_scratch1, in_bytes(Method::from_compiled_offset()), R19_method);
 3939       // Call target. Either compiled code or C2I adapter.
 3940       __ mtctr(R11_scratch1);
 3941       __ bctrl();
 3942       if (((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset() != __ offset() - start_offset) {
 3943         tty-&gt;print(&quot; %d, %d\n&quot;, ((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset(),__ offset() - start_offset);
 3944       }
 3945       assert(((MachCallDynamicJavaNode*)this)-&gt;ret_addr_offset() == __ offset() - start_offset,
 3946              &quot;Fix constant in ret_addr_offset()&quot;);
 3947     }
 3948 #endif
 3949     Unimplemented();  // ret_addr_offset not yet fixed. Depends on compressed oops (load klass!).
 3950   %}
 3951 
 3952   // a runtime call
 3953   enc_class enc_java_to_runtime_call (method meth) %{
 3954     // TODO: PPC port $archOpcode(ppc64Opcode_compound);
 3955 
<span class="line-modified"> 3956     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3957     const address start_pc = __ pc();
 3958 
 3959 #if defined(ABI_ELFv2)
 3960     address entry= !($meth$$method) ? NULL : (address)$meth$$method;
 3961     __ call_c(entry, relocInfo::runtime_call_type);
 3962 #else
 3963     // The function we&#39;re going to call.
 3964     FunctionDescriptor fdtemp;
 3965     const FunctionDescriptor* fd = !($meth$$method) ? &amp;fdtemp : (FunctionDescriptor*)$meth$$method;
 3966 
 3967     Register Rtoc = R12_scratch2;
 3968     // Calculate the method&#39;s TOC.
 3969     __ calculate_address_from_global_toc(Rtoc, __ method_toc());
 3970     // Put entry, env, toc into the constant pool, this needs up to 3 constant
 3971     // pool entries; call_c_using_toc will optimize the call.
 3972     bool success = __ call_c_using_toc(fd, relocInfo::runtime_call_type, Rtoc);
 3973     if (!success) {
 3974       ciEnv::current()-&gt;record_out_of_memory_failure();
 3975       return;
 3976     }
 3977 #endif
 3978 
 3979     // Check the ret_addr_offset.
 3980     assert(((MachCallRuntimeNode*)this)-&gt;ret_addr_offset() ==  __ last_calls_return_pc() - start_pc,
 3981            &quot;Fix constant in ret_addr_offset()&quot;);
 3982   %}
 3983 
 3984   // Move to ctr for leaf call.
 3985   // This enc_class is needed so that scheduler gets proper
 3986   // input mapping for latency computation.
 3987   enc_class enc_leaf_call_mtctr(iRegLsrc src) %{
 3988     // TODO: PPC port $archOpcode(ppc64Opcode_mtctr);
<span class="line-modified"> 3989     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3990     __ mtctr($src$$Register);
 3991   %}
 3992 
 3993   // Postalloc expand emitter for runtime leaf calls.
 3994   enc_class postalloc_expand_java_to_runtime_call(method meth, iRegLdst toc) %{
 3995     loadConLNodesTuple loadConLNodes_Entry;
 3996 #if defined(ABI_ELFv2)
 3997     jlong entry_address = (jlong) this-&gt;entry_point();
 3998     assert(entry_address, &quot;need address here&quot;);
 3999     loadConLNodes_Entry = loadConLNodesTuple_create(ra_, n_toc, new immLOper(entry_address),
 4000                                                     OptoReg::Name(R12_H_num), OptoReg::Name(R12_num));
 4001 #else
 4002     // Get the struct that describes the function we are about to call.
 4003     FunctionDescriptor* fd = (FunctionDescriptor*) this-&gt;entry_point();
 4004     assert(fd, &quot;need fd here&quot;);
 4005     jlong entry_address = (jlong) fd-&gt;entry();
 4006     // new nodes
 4007     loadConLNodesTuple loadConLNodes_Env;
 4008     loadConLNodesTuple loadConLNodes_Toc;
 4009 
</pre>
<hr />
<pre>
 6270   ins_field_cbuf_insts_offset(int);
 6271 
 6272   format %{ &quot;ADDIS   $dst, $toc, offset \t// load long $src from TOC (hi)&quot; %}
 6273   size(4);
 6274   ins_encode( enc_load_long_constL_hi(dst, toc, src) );
 6275   ins_pipe(pipe_class_default);
 6276 %}
 6277 
 6278 // Expand node for constant pool load: large offset.
 6279 // No constant pool entries required.
 6280 instruct loadConL_lo(iRegLdst dst, immL src, iRegLdst base) %{
 6281   effect(DEF dst, USE src, USE base);
 6282   predicate(false);
 6283 
 6284   ins_field_const_toc_offset_hi_node(loadConL_hiNode*);
 6285 
 6286   format %{ &quot;LD      $dst, offset, $base \t// load long $src from TOC (lo)&quot; %}
 6287   size(4);
 6288   ins_encode %{
 6289     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 6290     int offset = ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node-&gt;_const_toc_offset;</span>
 6291     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
 6292   %}
 6293   ins_pipe(pipe_class_memory);
 6294 %}
 6295 
 6296 // Load long constant from constant table. Expand in case of
 6297 // offset &gt; 16 bit is needed.
 6298 // Adlc adds toc node MachConstantTableBase.
 6299 instruct loadConL_Ex(iRegLdst dst, immL src) %{
 6300   match(Set dst src);
 6301   ins_cost(MEMORY_REF_COST);
 6302 
 6303   format %{ &quot;LD      $dst, offset, $constanttablebase\t// load long $src from table, postalloc expanded&quot; %}
 6304   // We can not inline the enc_class for the expand as that does not support constanttablebase.
 6305   postalloc_expand( postalloc_expand_load_long_constant(dst, src, constanttablebase) );
 6306 %}
 6307 
 6308 // Load NULL as compressed oop.
 6309 instruct loadConN0(iRegNdst dst, immN_0 src) %{
 6310   match(Set dst src);
</pre>
<hr />
<pre>
 6555   ins_num_consts(1);
 6556   ins_field_const_toc_offset(int);
 6557 
 6558   format %{ &quot;ADDIS   $dst, $toc, offset \t// load ptr $src from TOC (hi)&quot; %}
 6559   size(4);
 6560   ins_encode( enc_load_long_constP_hi(dst, src, toc) );
 6561   ins_pipe(pipe_class_default);
 6562 %}
 6563 
 6564 // Expand node for constant pool load: large offset.
 6565 instruct loadConP_lo(iRegPdst dst, immP_NM src, iRegLdst base) %{
 6566   match(Set dst src);
 6567   effect(TEMP base);
 6568 
 6569   ins_field_const_toc_offset_hi_node(loadConP_hiNode*);
 6570 
 6571   format %{ &quot;LD      $dst, offset, $base \t// load ptr $src from TOC (lo)&quot; %}
 6572   size(4);
 6573   ins_encode %{
 6574     // TODO: PPC port $archOpcode(ppc64Opcode_ld);
<span class="line-modified"> 6575     int offset = ra_-&gt;C-&gt;output()-&gt;in_scratch_emit_size() ? 0 : _const_toc_offset_hi_node-&gt;_const_toc_offset;</span>
 6576     __ ld($dst$$Register, MacroAssembler::largeoffset_si16_si16_lo(offset), $base$$Register);
 6577   %}
 6578   ins_pipe(pipe_class_memory);
 6579 %}
 6580 
 6581 // Load pointer constant from constant table. Expand in case an
 6582 // offset &gt; 16 bit is needed.
 6583 // Adlc adds toc node MachConstantTableBase.
 6584 instruct loadConP_Ex(iRegPdst dst, immP src) %{
 6585   match(Set dst src);
 6586   ins_cost(MEMORY_REF_COST);
 6587 
 6588   // This rule does not use &quot;expand&quot; because then
 6589   // the result type is not known to be an Oop.  An ADLC
 6590   // enhancement will be needed to make that work - not worth it!
 6591 
 6592   // If this instruction rematerializes, it prolongs the live range
 6593   // of the toc node, causing illegal graphs.
 6594   // assert(edge_from_to(_reg_node[reg_lo],def)) fails in verify_good_schedule().
 6595   ins_cannot_rematerialize(true);
</pre>
</td>
</tr>
</table>
<center><a href="macroAssembler_ppc.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="templateTable_ppc_64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>