<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/c1_LIRAssembler_aarch64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
</pre>
<hr />
<pre>
 417   __ ldr(r0, Address(rthread, JavaThread::exception_oop_offset()));
 418   __ str(zr, Address(rthread, JavaThread::exception_oop_offset()));
 419   __ str(zr, Address(rthread, JavaThread::exception_pc_offset()));
 420 
 421   __ bind(_unwind_handler_entry);
 422   __ verify_not_null_oop(r0);
 423   if (method()-&gt;is_synchronized() || compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 424     __ mov(r19, r0);  // Preserve the exception
 425   }
 426 
 427   // Preform needed unlocking
 428   MonitorExitStub* stub = NULL;
 429   if (method()-&gt;is_synchronized()) {
 430     monitor_address(0, FrameMap::r0_opr);
 431     stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);
 432     __ unlock_object(r5, r4, r0, *stub-&gt;entry());
 433     __ bind(*stub-&gt;continuation());
 434   }
 435 
 436   if (compilation()-&gt;env()-&gt;dtrace_method_probes()) {
<span class="line-modified"> 437     __ call_Unimplemented();</span>
<span class="line-modified"> 438 #if 0</span>
<span class="line-modified"> 439     __ movptr(Address(rsp, 0), rax);</span>
<span class="line-removed"> 440     __ mov_metadata(Address(rsp, sizeof(void*)), method()-&gt;constant_encoding());</span>
<span class="line-removed"> 441     __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit)));</span>
<span class="line-removed"> 442 #endif</span>
 443   }
 444 
 445   if (method()-&gt;is_synchronized() || compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 446     __ mov(r0, r19);  // Restore the exception
 447   }
 448 
 449   // remove the activation and dispatch to the unwind handler
 450   __ block_comment(&quot;remove_frame and dispatch to the unwind handler&quot;);
 451   __ remove_frame(initial_frame_size_in_bytes(), needs_stack_repair());
 452   __ far_jump(RuntimeAddress(Runtime1::entry_for(Runtime1::unwind_exception_id)));
 453 
 454   // Emit the slow path assembly
 455   if (stub != NULL) {
 456     stub-&gt;emit_code(this);
 457   }
 458 
 459   return offset;
 460 }
 461 
 462 
</pre>
<hr />
<pre>
 675 void LIR_Assembler::const2mem(LIR_Opr src, LIR_Opr dest, BasicType type, CodeEmitInfo* info, bool wide) {
 676   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 677   LIR_Const* c = src-&gt;as_constant_ptr();
 678   LIR_Address* to_addr = dest-&gt;as_address_ptr();
 679 
 680   void (Assembler::* insn)(Register Rt, const Address &amp;adr);
 681 
 682   switch (type) {
 683   case T_ADDRESS:
 684     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 685     insn = &amp;Assembler::str;
 686     break;
 687   case T_LONG:
 688     assert(c-&gt;as_jlong() == 0, &quot;should be&quot;);
 689     insn = &amp;Assembler::str;
 690     break;
 691   case T_INT:
 692     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 693     insn = &amp;Assembler::strw;
 694     break;
<span class="line-modified"> 695   case T_VALUETYPE: </span>
 696   case T_OBJECT:
 697   case T_ARRAY:
 698     // Non-null case is not handled on aarch64 but handled on x86
 699     // FIXME: do we need to add it here?
 700     assert(c-&gt;as_jobject() == 0, &quot;should be&quot;);
 701     if (UseCompressedOops &amp;&amp; !wide) {
 702       insn = &amp;Assembler::strw;
 703     } else {
 704       insn = &amp;Assembler::str;
 705     }
 706     break;
 707   case T_CHAR:
 708   case T_SHORT:
 709     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 710     insn = &amp;Assembler::strh;
 711     break;
 712   case T_BOOLEAN:
 713   case T_BYTE:
 714     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 715     insn = &amp;Assembler::strb;
</pre>
<hr />
<pre>
 938   add_call_info_here(info);
 939 }
 940 
 941 void LIR_Assembler::stack2stack(LIR_Opr src, LIR_Opr dest, BasicType type) {
 942 
 943   LIR_Opr temp;
 944   if (type == T_LONG || type == T_DOUBLE)
 945     temp = FrameMap::rscratch1_long_opr;
 946   else
 947     temp = FrameMap::rscratch1_opr;
 948 
 949   stack2reg(src, temp, src-&gt;type());
 950   reg2stack(temp, dest, dest-&gt;type(), false);
 951 }
 952 
 953 
 954 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
 955   LIR_Address* addr = src-&gt;as_address_ptr();
 956   LIR_Address* from_addr = src-&gt;as_address_ptr();
 957 
<span class="line-modified"> 958   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_VALUETYPE) { </span>
 959     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
 960   }
 961 
 962   if (patch_code != lir_patch_none) {
 963     deoptimize_trap(info);
 964     return;
 965   }
 966 
 967   if (info != NULL) {
 968     add_debug_info_for_null_check_here(info);
 969   }
 970   int null_check_here = code_offset();
 971   switch (type) {
 972     case T_FLOAT: {
 973       __ ldrs(dest-&gt;as_float_reg(), as_Address(from_addr));
 974       break;
 975     }
 976 
 977     case T_DOUBLE: {
 978       __ ldrd(dest-&gt;as_double_reg(), as_Address(from_addr));
</pre>
<hr />
<pre>
1620   }
1621 
1622 
1623   ciKlass* left_klass = op-&gt;left_klass();
1624   ciKlass* right_klass = op-&gt;right_klass();
1625 
1626   // (2) Value object check -- if either of the operands is not a value object,
1627   //     they are not substitutable. We do this only if we are not sure that the
1628   //     operands are value objects
1629   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.
1630       !left_klass-&gt;is_valuetype() || !right_klass-&gt;is_valuetype()) {
1631     Register tmp1  = rscratch1; /* op-&gt;tmp1()-&gt;as_register(); */
1632     Register tmp2  = rscratch2; /* op-&gt;tmp2()-&gt;as_register(); */
1633 
1634     __ mov(tmp1, (intptr_t)markWord::always_locked_pattern);
1635 
1636     __ ldr(tmp2, Address(left, oopDesc::mark_offset_in_bytes()));
1637     __ andr(tmp1, tmp1, tmp2);
1638 
1639     __ ldr(tmp2, Address(right, oopDesc::mark_offset_in_bytes()));
<span class="line-modified">1640     __ andr(tmp1, tmp1, tmp2); </span>
1641 
1642     __ mov(tmp2, (intptr_t)markWord::always_locked_pattern);
<span class="line-modified">1643     __ cmp(tmp1, tmp2); </span>
1644     __ br(Assembler::NE, L_oops_not_equal);
1645   }
1646 
1647   // (3) Same klass check: if the operands are of different klasses, they are not substitutable.
1648   if (left_klass != NULL &amp;&amp; left_klass-&gt;is_valuetype() &amp;&amp; left_klass == right_klass) {
1649     // No need to load klass -- the operands are statically known to be the same value klass.
1650     __ b(*op-&gt;stub()-&gt;entry());
1651   } else {
1652     Register left_klass_op = op-&gt;left_klass_op()-&gt;as_register();
1653     Register right_klass_op = op-&gt;right_klass_op()-&gt;as_register();
1654 
1655     if (UseCompressedOops) {
1656       __ ldrw(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));
1657       __ ldrw(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));
1658       __ cmpw(left_klass_op, right_klass_op);
1659     } else {
1660       __ ldr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));
1661       __ ldr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));
1662       __ cmp(left_klass_op, right_klass_op);
1663     }
</pre>
<hr />
<pre>
2285   __ b(_unwind_handler_entry);
2286 }
2287 
2288 
2289 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, LIR_Opr count, LIR_Opr dest, LIR_Opr tmp) {
2290   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2291   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2292 
2293   switch (left-&gt;type()) {
2294     case T_INT: {
2295       switch (code) {
2296       case lir_shl:  __ lslvw (dreg, lreg, count-&gt;as_register()); break;
2297       case lir_shr:  __ asrvw (dreg, lreg, count-&gt;as_register()); break;
2298       case lir_ushr: __ lsrvw (dreg, lreg, count-&gt;as_register()); break;
2299       default:
2300         ShouldNotReachHere();
2301         break;
2302       }
2303       break;
2304     case T_LONG:
<span class="line-modified">2305     case T_VALUETYPE: </span>
2306     case T_ADDRESS:
2307     case T_OBJECT:
2308       switch (code) {
2309       case lir_shl:  __ lslv (dreg, lreg, count-&gt;as_register()); break;
2310       case lir_shr:  __ asrv (dreg, lreg, count-&gt;as_register()); break;
2311       case lir_ushr: __ lsrv (dreg, lreg, count-&gt;as_register()); break;
2312       default:
2313         ShouldNotReachHere();
2314         break;
2315       }
2316       break;
2317     default:
2318       ShouldNotReachHere();
2319       break;
2320     }
2321   }
2322 }
2323 
2324 
2325 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, jint count, LIR_Opr dest) {
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   3  * Copyright (c) 2014, Red Hat Inc. All rights reserved.
   4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   5  *
   6  * This code is free software; you can redistribute it and/or modify it
   7  * under the terms of the GNU General Public License version 2 only, as
   8  * published by the Free Software Foundation.
   9  *
  10  * This code is distributed in the hope that it will be useful, but WITHOUT
  11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  13  * version 2 for more details (a copy is included in the LICENSE file that
  14  * accompanied this code).
  15  *
  16  * You should have received a copy of the GNU General Public License version
  17  * 2 along with this work; if not, write to the Free Software Foundation,
  18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  19  *
  20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  21  * or visit www.oracle.com if you need additional information or have any
  22  * questions.
</pre>
<hr />
<pre>
 417   __ ldr(r0, Address(rthread, JavaThread::exception_oop_offset()));
 418   __ str(zr, Address(rthread, JavaThread::exception_oop_offset()));
 419   __ str(zr, Address(rthread, JavaThread::exception_pc_offset()));
 420 
 421   __ bind(_unwind_handler_entry);
 422   __ verify_not_null_oop(r0);
 423   if (method()-&gt;is_synchronized() || compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 424     __ mov(r19, r0);  // Preserve the exception
 425   }
 426 
 427   // Preform needed unlocking
 428   MonitorExitStub* stub = NULL;
 429   if (method()-&gt;is_synchronized()) {
 430     monitor_address(0, FrameMap::r0_opr);
 431     stub = new MonitorExitStub(FrameMap::r0_opr, true, 0);
 432     __ unlock_object(r5, r4, r0, *stub-&gt;entry());
 433     __ bind(*stub-&gt;continuation());
 434   }
 435 
 436   if (compilation()-&gt;env()-&gt;dtrace_method_probes()) {
<span class="line-modified"> 437     __ mov(c_rarg0, rthread);</span>
<span class="line-modified"> 438     __ mov_metadata(c_rarg1, method()-&gt;constant_encoding());</span>
<span class="line-modified"> 439     __ call_VM_leaf(CAST_FROM_FN_PTR(address, SharedRuntime::dtrace_method_exit), c_rarg0, c_rarg1);</span>



 440   }
 441 
 442   if (method()-&gt;is_synchronized() || compilation()-&gt;env()-&gt;dtrace_method_probes()) {
 443     __ mov(r0, r19);  // Restore the exception
 444   }
 445 
 446   // remove the activation and dispatch to the unwind handler
 447   __ block_comment(&quot;remove_frame and dispatch to the unwind handler&quot;);
 448   __ remove_frame(initial_frame_size_in_bytes(), needs_stack_repair());
 449   __ far_jump(RuntimeAddress(Runtime1::entry_for(Runtime1::unwind_exception_id)));
 450 
 451   // Emit the slow path assembly
 452   if (stub != NULL) {
 453     stub-&gt;emit_code(this);
 454   }
 455 
 456   return offset;
 457 }
 458 
 459 
</pre>
<hr />
<pre>
 672 void LIR_Assembler::const2mem(LIR_Opr src, LIR_Opr dest, BasicType type, CodeEmitInfo* info, bool wide) {
 673   assert(src-&gt;is_constant(), &quot;should not call otherwise&quot;);
 674   LIR_Const* c = src-&gt;as_constant_ptr();
 675   LIR_Address* to_addr = dest-&gt;as_address_ptr();
 676 
 677   void (Assembler::* insn)(Register Rt, const Address &amp;adr);
 678 
 679   switch (type) {
 680   case T_ADDRESS:
 681     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 682     insn = &amp;Assembler::str;
 683     break;
 684   case T_LONG:
 685     assert(c-&gt;as_jlong() == 0, &quot;should be&quot;);
 686     insn = &amp;Assembler::str;
 687     break;
 688   case T_INT:
 689     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 690     insn = &amp;Assembler::strw;
 691     break;
<span class="line-modified"> 692   case T_VALUETYPE:</span>
 693   case T_OBJECT:
 694   case T_ARRAY:
 695     // Non-null case is not handled on aarch64 but handled on x86
 696     // FIXME: do we need to add it here?
 697     assert(c-&gt;as_jobject() == 0, &quot;should be&quot;);
 698     if (UseCompressedOops &amp;&amp; !wide) {
 699       insn = &amp;Assembler::strw;
 700     } else {
 701       insn = &amp;Assembler::str;
 702     }
 703     break;
 704   case T_CHAR:
 705   case T_SHORT:
 706     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 707     insn = &amp;Assembler::strh;
 708     break;
 709   case T_BOOLEAN:
 710   case T_BYTE:
 711     assert(c-&gt;as_jint() == 0, &quot;should be&quot;);
 712     insn = &amp;Assembler::strb;
</pre>
<hr />
<pre>
 935   add_call_info_here(info);
 936 }
 937 
 938 void LIR_Assembler::stack2stack(LIR_Opr src, LIR_Opr dest, BasicType type) {
 939 
 940   LIR_Opr temp;
 941   if (type == T_LONG || type == T_DOUBLE)
 942     temp = FrameMap::rscratch1_long_opr;
 943   else
 944     temp = FrameMap::rscratch1_opr;
 945 
 946   stack2reg(src, temp, src-&gt;type());
 947   reg2stack(temp, dest, dest-&gt;type(), false);
 948 }
 949 
 950 
 951 void LIR_Assembler::mem2reg(LIR_Opr src, LIR_Opr dest, BasicType type, LIR_PatchCode patch_code, CodeEmitInfo* info, bool wide, bool /* unaligned */) {
 952   LIR_Address* addr = src-&gt;as_address_ptr();
 953   LIR_Address* from_addr = src-&gt;as_address_ptr();
 954 
<span class="line-modified"> 955   if (addr-&gt;base()-&gt;type() == T_OBJECT || addr-&gt;base()-&gt;type() == T_VALUETYPE) {</span>
 956     __ verify_oop(addr-&gt;base()-&gt;as_pointer_register());
 957   }
 958 
 959   if (patch_code != lir_patch_none) {
 960     deoptimize_trap(info);
 961     return;
 962   }
 963 
 964   if (info != NULL) {
 965     add_debug_info_for_null_check_here(info);
 966   }
 967   int null_check_here = code_offset();
 968   switch (type) {
 969     case T_FLOAT: {
 970       __ ldrs(dest-&gt;as_float_reg(), as_Address(from_addr));
 971       break;
 972     }
 973 
 974     case T_DOUBLE: {
 975       __ ldrd(dest-&gt;as_double_reg(), as_Address(from_addr));
</pre>
<hr />
<pre>
1617   }
1618 
1619 
1620   ciKlass* left_klass = op-&gt;left_klass();
1621   ciKlass* right_klass = op-&gt;right_klass();
1622 
1623   // (2) Value object check -- if either of the operands is not a value object,
1624   //     they are not substitutable. We do this only if we are not sure that the
1625   //     operands are value objects
1626   if ((left_klass == NULL || right_klass == NULL) ||// The klass is still unloaded, or came from a Phi node.
1627       !left_klass-&gt;is_valuetype() || !right_klass-&gt;is_valuetype()) {
1628     Register tmp1  = rscratch1; /* op-&gt;tmp1()-&gt;as_register(); */
1629     Register tmp2  = rscratch2; /* op-&gt;tmp2()-&gt;as_register(); */
1630 
1631     __ mov(tmp1, (intptr_t)markWord::always_locked_pattern);
1632 
1633     __ ldr(tmp2, Address(left, oopDesc::mark_offset_in_bytes()));
1634     __ andr(tmp1, tmp1, tmp2);
1635 
1636     __ ldr(tmp2, Address(right, oopDesc::mark_offset_in_bytes()));
<span class="line-modified">1637     __ andr(tmp1, tmp1, tmp2);</span>
1638 
1639     __ mov(tmp2, (intptr_t)markWord::always_locked_pattern);
<span class="line-modified">1640     __ cmp(tmp1, tmp2);</span>
1641     __ br(Assembler::NE, L_oops_not_equal);
1642   }
1643 
1644   // (3) Same klass check: if the operands are of different klasses, they are not substitutable.
1645   if (left_klass != NULL &amp;&amp; left_klass-&gt;is_valuetype() &amp;&amp; left_klass == right_klass) {
1646     // No need to load klass -- the operands are statically known to be the same value klass.
1647     __ b(*op-&gt;stub()-&gt;entry());
1648   } else {
1649     Register left_klass_op = op-&gt;left_klass_op()-&gt;as_register();
1650     Register right_klass_op = op-&gt;right_klass_op()-&gt;as_register();
1651 
1652     if (UseCompressedOops) {
1653       __ ldrw(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));
1654       __ ldrw(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));
1655       __ cmpw(left_klass_op, right_klass_op);
1656     } else {
1657       __ ldr(left_klass_op,  Address(left,  oopDesc::klass_offset_in_bytes()));
1658       __ ldr(right_klass_op, Address(right, oopDesc::klass_offset_in_bytes()));
1659       __ cmp(left_klass_op, right_klass_op);
1660     }
</pre>
<hr />
<pre>
2282   __ b(_unwind_handler_entry);
2283 }
2284 
2285 
2286 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, LIR_Opr count, LIR_Opr dest, LIR_Opr tmp) {
2287   Register lreg = left-&gt;is_single_cpu() ? left-&gt;as_register() : left-&gt;as_register_lo();
2288   Register dreg = dest-&gt;is_single_cpu() ? dest-&gt;as_register() : dest-&gt;as_register_lo();
2289 
2290   switch (left-&gt;type()) {
2291     case T_INT: {
2292       switch (code) {
2293       case lir_shl:  __ lslvw (dreg, lreg, count-&gt;as_register()); break;
2294       case lir_shr:  __ asrvw (dreg, lreg, count-&gt;as_register()); break;
2295       case lir_ushr: __ lsrvw (dreg, lreg, count-&gt;as_register()); break;
2296       default:
2297         ShouldNotReachHere();
2298         break;
2299       }
2300       break;
2301     case T_LONG:
<span class="line-modified">2302     case T_VALUETYPE:</span>
2303     case T_ADDRESS:
2304     case T_OBJECT:
2305       switch (code) {
2306       case lir_shl:  __ lslv (dreg, lreg, count-&gt;as_register()); break;
2307       case lir_shr:  __ asrv (dreg, lreg, count-&gt;as_register()); break;
2308       case lir_ushr: __ lsrv (dreg, lreg, count-&gt;as_register()); break;
2309       default:
2310         ShouldNotReachHere();
2311         break;
2312       }
2313       break;
2314     default:
2315       ShouldNotReachHere();
2316       break;
2317     }
2318   }
2319 }
2320 
2321 
2322 void LIR_Assembler::shift_op(LIR_Code code, LIR_Opr left, jint count, LIR_Opr dest) {
</pre>
</td>
</tr>
</table>
<center><a href="aarch64.ad.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_Runtime1_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>