<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030  bool is_CAS(int opcode, bool maybe_volatile);
 1031 
 1032   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1033 
 1034   bool unnecessary_acquire(const Node *barrier);
 1035   bool needs_acquiring_load(const Node *load);
 1036 
 1037   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1038 
 1039   bool unnecessary_release(const Node *barrier);
 1040   bool unnecessary_volatile(const Node *barrier);
 1041   bool needs_releasing_store(const Node *store);
 1042 
 1043   // predicate controlling translation of CompareAndSwapX
 1044   bool needs_acquiring_load_exclusive(const Node *load);
 1045 
 1046   // predicate controlling addressing modes
 1047   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1048 %}
 1049 
 1050 source %{
 1051 
 1052   // Derived RegMask with conditionally allocatable registers
 1053 
 1054   RegMask _ANY_REG32_mask;
 1055   RegMask _ANY_REG_mask;
 1056   RegMask _PTR_REG_mask;
 1057   RegMask _NO_SPECIAL_REG32_mask;
 1058   RegMask _NO_SPECIAL_REG_mask;
 1059   RegMask _NO_SPECIAL_PTR_REG_mask;
 1060 
 1061   void reg_mask_init() {
 1062     // We derive below RegMask(s) from the ones which are auto-generated from
 1063     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1064     // registers conditionally reserved.
 1065 
 1066     _ANY_REG32_mask = _ALL_REG32_mask;
 1067     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1068 
 1069     _ANY_REG_mask = _ALL_REG_mask;
 1070 
 1071     _PTR_REG_mask = _ALL_REG_mask;
 1072 
 1073     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1074     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1075 
 1076     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1077     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1078 
 1079     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1080     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1081 
 1082     // r27 is not allocatable when compressed oops is on, compressed klass
 1083     // pointers doesn&#39;t use r27 after JDK-8234794
 1084     if (UseCompressedOops) {
 1085       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1086       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1087       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1088     }
 1089 
 1090     // r29 is not allocatable when PreserveFramePointer is on
 1091     if (PreserveFramePointer) {
 1092       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1093       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1094       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1095     }
 1096   }
 1097 
 1098   // Optimizaton of volatile gets and puts
 1099   // -------------------------------------
 1100   //
 1101   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1102   // use to implement volatile reads and writes. For a volatile read
 1103   // we simply need
 1104   //
 1105   //   ldar&lt;x&gt;
 1106   //
 1107   // and for a volatile write we need
 1108   //
 1109   //   stlr&lt;x&gt;
 1110   //
 1111   // Alternatively, we can implement them by pairing a normal
 1112   // load/store with a memory barrier. For a volatile read we need
 1113   //
 1114   //   ldr&lt;x&gt;
 1115   //   dmb ishld
 1116   //
 1117   // for a volatile write
 1118   //
 1119   //   dmb ish
 1120   //   str&lt;x&gt;
 1121   //   dmb ish
 1122   //
 1123   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1124   // sequences. These are normally translated to an instruction
 1125   // sequence like the following
 1126   //
 1127   //   dmb      ish
 1128   // retry:
 1129   //   ldxr&lt;x&gt;   rval raddr
 1130   //   cmp       rval rold
 1131   //   b.ne done
 1132   //   stlxr&lt;x&gt;  rval, rnew, rold
 1133   //   cbnz      rval retry
 1134   // done:
 1135   //   cset      r0, eq
 1136   //   dmb ishld
 1137   //
 1138   // Note that the exclusive store is already using an stlxr
 1139   // instruction. That is required to ensure visibility to other
 1140   // threads of the exclusive write (assuming it succeeds) before that
 1141   // of any subsequent writes.
 1142   //
 1143   // The following instruction sequence is an improvement on the above
 1144   //
 1145   // retry:
 1146   //   ldaxr&lt;x&gt;  rval raddr
 1147   //   cmp       rval rold
 1148   //   b.ne done
 1149   //   stlxr&lt;x&gt;  rval, rnew, rold
 1150   //   cbnz      rval retry
 1151   // done:
 1152   //   cset      r0, eq
 1153   //
 1154   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1155   // visibility of prior writes in the case that the swap is
 1156   // successful. Crucially we don&#39;t have to worry about the case where
 1157   // the swap is not successful since no valid program should be
 1158   // relying on visibility of prior changes by the attempting thread
 1159   // in the case where the CAS fails.
 1160   //
 1161   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1162   // an ldaxr instruction since that will provide all the guarantees we
 1163   // require regarding observation of changes made by other threads
 1164   // before any change to the CAS address observed by the load.
 1165   //
 1166   // In order to generate the desired instruction sequence we need to
 1167   // be able to identify specific &#39;signature&#39; ideal graph node
 1168   // sequences which i) occur as a translation of a volatile reads or
 1169   // writes or CAS operations and ii) do not occur through any other
 1170   // translation or graph transformation. We can then provide
 1171   // alternative aldc matching rules which translate these node
 1172   // sequences to the desired machine code sequences. Selection of the
 1173   // alternative rules can be implemented by predicates which identify
 1174   // the relevant node sequences.
 1175   //
 1176   // The ideal graph generator translates a volatile read to the node
 1177   // sequence
 1178   //
 1179   //   LoadX[mo_acquire]
 1180   //   MemBarAcquire
 1181   //
 1182   // As a special case when using the compressed oops optimization we
 1183   // may also see this variant
 1184   //
 1185   //   LoadN[mo_acquire]
 1186   //   DecodeN
 1187   //   MemBarAcquire
 1188   //
 1189   // A volatile write is translated to the node sequence
 1190   //
 1191   //   MemBarRelease
 1192   //   StoreX[mo_release] {CardMark}-optional
 1193   //   MemBarVolatile
 1194   //
 1195   // n.b. the above node patterns are generated with a strict
 1196   // &#39;signature&#39; configuration of input and output dependencies (see
 1197   // the predicates below for exact details). The card mark may be as
 1198   // simple as a few extra nodes or, in a few GC configurations, may
 1199   // include more complex control flow between the leading and
 1200   // trailing memory barriers. However, whatever the card mark
 1201   // configuration these signatures are unique to translated volatile
 1202   // reads/stores -- they will not appear as a result of any other
 1203   // bytecode translation or inlining nor as a consequence of
 1204   // optimizing transforms.
 1205   //
 1206   // We also want to catch inlined unsafe volatile gets and puts and
 1207   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1208   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1209   //
 1210   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1211   // normal volatile put node sequence containing an extra cpuorder
 1212   // membar
 1213   //
 1214   //   MemBarRelease
 1215   //   MemBarCPUOrder
 1216   //   StoreX[mo_release] {CardMark}-optional
 1217   //   MemBarCPUOrder
 1218   //   MemBarVolatile
 1219   //
 1220   // n.b. as an aside, a cpuorder membar is not itself subject to
 1221   // matching and translation by adlc rules.  However, the rule
 1222   // predicates need to detect its presence in order to correctly
 1223   // select the desired adlc rules.
 1224   //
 1225   // Inlined unsafe volatile gets manifest as a slightly different
 1226   // node sequence to a normal volatile get because of the
 1227   // introduction of some CPUOrder memory barriers to bracket the
 1228   // Load. However, but the same basic skeleton of a LoadX feeding a
 1229   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1230   // present
 1231   //
 1232   //   MemBarCPUOrder
 1233   //        ||       \\
 1234   //   MemBarCPUOrder LoadX[mo_acquire]
 1235   //        ||            |
 1236   //        ||       {DecodeN} optional
 1237   //        ||       /
 1238   //     MemBarAcquire
 1239   //
 1240   // In this case the acquire membar does not directly depend on the
 1241   // load. However, we can be sure that the load is generated from an
 1242   // inlined unsafe volatile get if we see it dependent on this unique
 1243   // sequence of membar nodes. Similarly, given an acquire membar we
 1244   // can know that it was added because of an inlined unsafe volatile
 1245   // get if it is fed and feeds a cpuorder membar and if its feed
 1246   // membar also feeds an acquiring load.
 1247   //
 1248   // Finally an inlined (Unsafe) CAS operation is translated to the
 1249   // following ideal graph
 1250   //
 1251   //   MemBarRelease
 1252   //   MemBarCPUOrder
 1253   //   CompareAndSwapX {CardMark}-optional
 1254   //   MemBarCPUOrder
 1255   //   MemBarAcquire
 1256   //
 1257   // So, where we can identify these volatile read and write
 1258   // signatures we can choose to plant either of the above two code
 1259   // sequences. For a volatile read we can simply plant a normal
 1260   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1261   // also choose to inhibit translation of the MemBarAcquire and
 1262   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1263   //
 1264   // When we recognise a volatile store signature we can choose to
 1265   // plant at a dmb ish as a translation for the MemBarRelease, a
 1266   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1267   // Alternatively, we can inhibit translation of the MemBarRelease
 1268   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1269   // instruction.
 1270   //
 1271   // when we recognise a CAS signature we can choose to plant a dmb
 1272   // ish as a translation for the MemBarRelease, the conventional
 1273   // macro-instruction sequence for the CompareAndSwap node (which
 1274   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1275   // Alternatively, we can elide generation of the dmb instructions
 1276   // and plant the alternative CompareAndSwap macro-instruction
 1277   // sequence (which uses ldaxr&lt;x&gt;).
 1278   //
 1279   // Of course, the above only applies when we see these signature
 1280   // configurations. We still want to plant dmb instructions in any
 1281   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1282   // MemBarVolatile. For example, at the end of a constructor which
 1283   // writes final/volatile fields we will see a MemBarRelease
 1284   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1285   // constructed object being visible without making the
 1286   // final/volatile field writes visible.
 1287   //
 1288   // n.b. the translation rules below which rely on detection of the
 1289   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1290   // If we see anything other than the signature configurations we
 1291   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1292   // and translate acquire, release and volatile membars to the
 1293   // relevant dmb instructions.
 1294   //
 1295 
 1296   // is_CAS(int opcode, bool maybe_volatile)
 1297   //
 1298   // return true if opcode is one of the possible CompareAndSwapX
 1299   // values otherwise false.
 1300 
 1301   bool is_CAS(int opcode, bool maybe_volatile)
 1302   {
 1303     switch(opcode) {
 1304       // We handle these
 1305     case Op_CompareAndSwapI:
 1306     case Op_CompareAndSwapL:
 1307     case Op_CompareAndSwapP:
 1308     case Op_CompareAndSwapN:
 1309     case Op_ShenandoahCompareAndSwapP:
 1310     case Op_ShenandoahCompareAndSwapN:
 1311     case Op_CompareAndSwapB:
 1312     case Op_CompareAndSwapS:
 1313     case Op_GetAndSetI:
 1314     case Op_GetAndSetL:
 1315     case Op_GetAndSetP:
 1316     case Op_GetAndSetN:
 1317     case Op_GetAndAddI:
 1318     case Op_GetAndAddL:
 1319       return true;
 1320     case Op_CompareAndExchangeI:
 1321     case Op_CompareAndExchangeN:
 1322     case Op_CompareAndExchangeB:
 1323     case Op_CompareAndExchangeS:
 1324     case Op_CompareAndExchangeL:
 1325     case Op_CompareAndExchangeP:
 1326     case Op_WeakCompareAndSwapB:
 1327     case Op_WeakCompareAndSwapS:
 1328     case Op_WeakCompareAndSwapI:
 1329     case Op_WeakCompareAndSwapL:
 1330     case Op_WeakCompareAndSwapP:
 1331     case Op_WeakCompareAndSwapN:
 1332     case Op_ShenandoahWeakCompareAndSwapP:
 1333     case Op_ShenandoahWeakCompareAndSwapN:
 1334     case Op_ShenandoahCompareAndExchangeP:
 1335     case Op_ShenandoahCompareAndExchangeN:
 1336       return maybe_volatile;
 1337     default:
 1338       return false;
 1339     }
 1340   }
 1341 
 1342   // helper to determine the maximum number of Phi nodes we may need to
 1343   // traverse when searching from a card mark membar for the merge mem
 1344   // feeding a trailing membar or vice versa
 1345 
 1346 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1347 
 1348 bool unnecessary_acquire(const Node *barrier)
 1349 {
 1350   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1351 
 1352   if (UseBarriersForVolatile) {
 1353     // we need to plant a dmb
 1354     return false;
 1355   }
 1356 
 1357   MemBarNode* mb = barrier-&gt;as_MemBar();
 1358 
 1359   if (mb-&gt;trailing_load()) {
 1360     return true;
 1361   }
 1362 
 1363   if (mb-&gt;trailing_load_store()) {
 1364     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1365     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1366     return is_CAS(load_store-&gt;Opcode(), true);
 1367   }
 1368 
 1369   return false;
 1370 }
 1371 
 1372 bool needs_acquiring_load(const Node *n)
 1373 {
 1374   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1375   if (UseBarriersForVolatile) {
 1376     // we use a normal load and a dmb
 1377     return false;
 1378   }
 1379 
 1380   LoadNode *ld = n-&gt;as_Load();
 1381 
 1382   return ld-&gt;is_acquire();
 1383 }
 1384 
 1385 bool unnecessary_release(const Node *n)
 1386 {
 1387   assert((n-&gt;is_MemBar() &amp;&amp;
 1388 	  n-&gt;Opcode() == Op_MemBarRelease),
 1389 	 &quot;expecting a release membar&quot;);
 1390 
 1391   if (UseBarriersForVolatile) {
 1392     // we need to plant a dmb
 1393     return false;
 1394   }
 1395 
 1396   MemBarNode *barrier = n-&gt;as_MemBar();
 1397   if (!barrier-&gt;leading()) {
 1398     return false;
 1399   } else {
 1400     Node* trailing = barrier-&gt;trailing_membar();
 1401     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1402     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1403     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1404 
 1405     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1406     if (mem-&gt;is_Store()) {
 1407       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1408       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1409       return true;
 1410     } else {
 1411       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1412       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1413       return is_CAS(mem-&gt;Opcode(), true);
 1414     }
 1415   }
 1416   return false;
 1417 }
 1418 
 1419 bool unnecessary_volatile(const Node *n)
 1420 {
 1421   // assert n-&gt;is_MemBar();
 1422   if (UseBarriersForVolatile) {
 1423     // we need to plant a dmb
 1424     return false;
 1425   }
 1426 
 1427   MemBarNode *mbvol = n-&gt;as_MemBar();
 1428 
 1429   bool release = mbvol-&gt;trailing_store();
 1430   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1431 #ifdef ASSERT
 1432   if (release) {
 1433     Node* leading = mbvol-&gt;leading_membar();
 1434     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1435     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1436     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1437   }
 1438 #endif
 1439 
 1440   return release;
 1441 }
 1442 
 1443 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1444 
 1445 bool needs_releasing_store(const Node *n)
 1446 {
 1447   // assert n-&gt;is_Store();
 1448   if (UseBarriersForVolatile) {
 1449     // we use a normal store and dmb combination
 1450     return false;
 1451   }
 1452 
 1453   StoreNode *st = n-&gt;as_Store();
 1454 
 1455   return st-&gt;trailing_membar() != NULL;
 1456 }
 1457 
 1458 // predicate controlling translation of CAS
 1459 //
 1460 // returns true if CAS needs to use an acquiring load otherwise false
 1461 
 1462 bool needs_acquiring_load_exclusive(const Node *n)
 1463 {
 1464   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1465   if (UseBarriersForVolatile) {
 1466     return false;
 1467   }
 1468 
 1469   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1470   if (is_CAS(n-&gt;Opcode(), false)) {
 1471     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1472   } else {
 1473     return ldst-&gt;trailing_membar() != NULL;
 1474   }
 1475 
 1476   // so we can just return true here
 1477   return true;
 1478 }
 1479 
 1480 #define __ _masm.
 1481 
 1482 // advance declarations for helper functions to convert register
 1483 // indices to register objects
 1484 
 1485 // the ad file has to provide implementations of certain methods
 1486 // expected by the generic code
 1487 //
 1488 // REQUIRED FUNCTIONALITY
 1489 
 1490 //=============================================================================
 1491 
 1492 // !!!!! Special hack to get all types of calls to specify the byte offset
 1493 //       from the start of the call to the point where the return address
 1494 //       will point.
 1495 
 1496 int MachCallStaticJavaNode::ret_addr_offset()
 1497 {
 1498   // call should be a simple bl
 1499   int off = 4;
 1500   return off;
 1501 }
 1502 
 1503 int MachCallDynamicJavaNode::ret_addr_offset()
 1504 {
 1505   return 16; // movz, movk, movk, bl
 1506 }
 1507 
 1508 int MachCallRuntimeNode::ret_addr_offset() {
 1509   // for generated stubs the call will be
 1510   //   far_call(addr)
 1511   // for real runtime callouts it will be six instructions
 1512   // see aarch64_enc_java_to_runtime
 1513   //   adr(rscratch2, retaddr)
 1514   //   lea(rscratch1, RuntimeAddress(addr)
 1515   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1516   //   blr(rscratch1)
 1517   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1518   if (cb) {
 1519     return MacroAssembler::far_branch_size();
 1520   } else {
 1521     return 6 * NativeInstruction::instruction_size;
 1522   }
 1523 }
 1524 
 1525 // Indicate if the safepoint node needs the polling page as an input
 1526 
 1527 // the shared code plants the oop data at the start of the generated
 1528 // code for the safepoint node and that needs ot be at the load
 1529 // instruction itself. so we cannot plant a mov of the safepoint poll
 1530 // address followed by a load. setting this to true means the mov is
 1531 // scheduled as a prior instruction. that&#39;s better for scheduling
 1532 // anyway.
 1533 
 1534 bool SafePointNode::needs_polling_address_input()
 1535 {
 1536   return true;
 1537 }
 1538 
 1539 //=============================================================================
 1540 
 1541 #ifndef PRODUCT
 1542 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1543   st-&gt;print(&quot;BREAKPOINT&quot;);
 1544 }
 1545 #endif
 1546 
 1547 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<a name="1" id="anc1"></a><span class="line-modified"> 1548   MacroAssembler _masm(&amp;cbuf);</span>
 1549   __ brk(0);
 1550 }
 1551 
 1552 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1553   return MachNode::size(ra_);
 1554 }
 1555 
 1556 //=============================================================================
 1557 
 1558 #ifndef PRODUCT
 1559   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1560     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1561   }
 1562 #endif
 1563 
 1564   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
<a name="2" id="anc2"></a><span class="line-modified"> 1565     MacroAssembler _masm(&amp;cbuf);</span>
 1566     for (int i = 0; i &lt; _count; i++) {
 1567       __ nop();
 1568     }
 1569   }
 1570 
 1571   uint MachNopNode::size(PhaseRegAlloc*) const {
 1572     return _count * NativeInstruction::instruction_size;
 1573   }
 1574 
 1575 //=============================================================================
 1576 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1577 
<a name="3" id="anc3"></a><span class="line-modified"> 1578 int Compile::ConstantTable::calculate_table_base_offset() const {</span>
 1579   return 0;  // absolute addressing, no offset
 1580 }
 1581 
 1582 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1583 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1584   ShouldNotReachHere();
 1585 }
 1586 
 1587 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1588   // Empty encoding
 1589 }
 1590 
 1591 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1592   return 0;
 1593 }
 1594 
 1595 #ifndef PRODUCT
 1596 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1597   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1598 }
 1599 #endif
 1600 
 1601 #ifndef PRODUCT
 1602 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1603   Compile* C = ra_-&gt;C;
 1604 
<a name="4" id="anc4"></a><span class="line-modified"> 1605   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1606 
<a name="5" id="anc5"></a><span class="line-modified"> 1607   if (C-&gt;need_stack_bang(framesize))</span>
 1608     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1609 
 1610   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1611     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1612     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1613     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1614   } else {
 1615     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1616     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1617     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1618     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1619   }
 1620 }
 1621 #endif
 1622 
 1623 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1624   Compile* C = ra_-&gt;C;
<a name="6" id="anc6"></a><span class="line-modified"> 1625   MacroAssembler _masm(&amp;cbuf);</span>
 1626 
 1627   __ verified_entry(C, 0);
 1628   __ bind(*_verified_entry);
 1629 
<a name="7" id="anc7"></a><span class="line-modified"> 1630   C-&gt;set_frame_complete(cbuf.insts_size());</span>
 1631 
 1632   if (C-&gt;has_mach_constant_base_node()) {
 1633     // NOTE: We set the table base offset here because users might be
 1634     // emitted before MachConstantBaseNode.
<a name="8" id="anc8"></a><span class="line-modified"> 1635     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();</span>
 1636     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1637   }
 1638 }
 1639 
 1640 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1641 {
 1642   return MachNode::size(ra_); // too many variables; just compute it
 1643                               // the hard way
 1644 }
 1645 
 1646 int MachPrologNode::reloc() const
 1647 {
 1648   return 0;
 1649 }
 1650 
 1651 //=============================================================================
 1652 
 1653 #ifndef PRODUCT
 1654 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1655   Compile* C = ra_-&gt;C;
<a name="9" id="anc9"></a><span class="line-modified"> 1656   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1657 
 1658   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1659 
 1660   if (framesize == 0) {
 1661     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1662   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1663     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1664     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1665   } else {
 1666     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1667     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1668     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1669   }
 1670 
 1671   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1672     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1673     st-&gt;print(&quot;mov  rscratch1, #0x%lx\n\t&quot;, p2i(os::get_polling_page()));
 1674     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1675   }
 1676 }
 1677 #endif
 1678 
 1679 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1680   Compile* C = ra_-&gt;C;
<a name="10" id="anc10"></a><span class="line-modified"> 1681   MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 1682   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1683 
 1684   __ remove_frame(framesize);
 1685 
 1686   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1687     __ reserved_stack_check();
 1688   }
 1689 
 1690   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1691     __ read_polling_page(rscratch1, os::get_polling_page(), relocInfo::poll_return_type);
 1692   }
 1693 }
 1694 
 1695 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1696   // Variable size. Determine dynamically.
 1697   return MachNode::size(ra_);
 1698 }
 1699 
 1700 int MachEpilogNode::reloc() const {
 1701   // Return number of relocatable values contained in this instruction.
 1702   return 1; // 1 for polling page.
 1703 }
 1704 
 1705 const Pipeline * MachEpilogNode::pipeline() const {
 1706   return MachNode::pipeline_class();
 1707 }
 1708 
 1709 // This method seems to be obsolete. It is declared in machnode.hpp
 1710 // and defined in all *.ad files, but it is never called. Should we
 1711 // get rid of it?
 1712 int MachEpilogNode::safepoint_offset() const {
 1713   assert(do_polling(), &quot;no return for this epilog node&quot;);
 1714   return 4;
 1715 }
 1716 
 1717 //=============================================================================
 1718 
 1719 // Figure out which register class each belongs in: rc_int, rc_float or
 1720 // rc_stack.
 1721 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1722 
 1723 static enum RC rc_class(OptoReg::Name reg) {
 1724 
 1725   if (reg == OptoReg::Bad) {
 1726     return rc_bad;
 1727   }
 1728 
 1729   // we have 30 int registers * 2 halves
 1730   // (rscratch1 and rscratch2 are omitted)
 1731   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1732 
 1733   if (reg &lt; slots_of_int_registers) {
 1734     return rc_int;
 1735   }
 1736 
 1737   // we have 32 float register * 4 halves
 1738   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1739     return rc_float;
 1740   }
 1741 
 1742   // Between float regs &amp; stack is the flags regs.
 1743   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1744 
 1745   return rc_stack;
 1746 }
 1747 
 1748 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1749   Compile* C = ra_-&gt;C;
 1750 
 1751   // Get registers to move.
 1752   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1753   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1754   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1755   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1756 
 1757   enum RC src_hi_rc = rc_class(src_hi);
 1758   enum RC src_lo_rc = rc_class(src_lo);
 1759   enum RC dst_hi_rc = rc_class(dst_hi);
 1760   enum RC dst_lo_rc = rc_class(dst_lo);
 1761 
 1762   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1763 
 1764   if (src_hi != OptoReg::Bad) {
 1765     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1766            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1767            &quot;expected aligned-adjacent pairs&quot;);
 1768   }
 1769 
 1770   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1771     return 0;            // Self copy, no move.
 1772   }
 1773 
 1774   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1775               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1776   int src_offset = ra_-&gt;reg2offset(src_lo);
 1777   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1778 
 1779   if (bottom_type()-&gt;isa_vect() != NULL) {
 1780     uint ireg = ideal_reg();
 1781     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1782     if (cbuf) {
<a name="11" id="anc11"></a><span class="line-modified"> 1783       MacroAssembler _masm(cbuf);</span>
 1784       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1785       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1786         // stack-&gt;stack
 1787         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1788         if (ireg == Op_VecD) {
 1789           __ unspill(rscratch1, true, src_offset);
 1790           __ spill(rscratch1, true, dst_offset);
 1791         } else {
 1792           __ spill_copy128(src_offset, dst_offset);
 1793         }
 1794       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1795         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1796                ireg == Op_VecD ? __ T8B : __ T16B,
 1797                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1798       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1799         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1800                        ireg == Op_VecD ? __ D : __ Q,
 1801                        ra_-&gt;reg2offset(dst_lo));
 1802       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1803         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1804                        ireg == Op_VecD ? __ D : __ Q,
 1805                        ra_-&gt;reg2offset(src_lo));
 1806       } else {
 1807         ShouldNotReachHere();
 1808       }
 1809     }
 1810   } else if (cbuf) {
<a name="12" id="anc12"></a><span class="line-modified"> 1811     MacroAssembler _masm(cbuf);</span>
 1812     switch (src_lo_rc) {
 1813     case rc_int:
 1814       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1815         if (is64) {
 1816             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1817                    as_Register(Matcher::_regEncode[src_lo]));
 1818         } else {
<a name="13" id="anc13"></a><span class="line-modified"> 1819             MacroAssembler _masm(cbuf);</span>
 1820             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1821                     as_Register(Matcher::_regEncode[src_lo]));
 1822         }
 1823       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1824         if (is64) {
 1825             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1826                      as_Register(Matcher::_regEncode[src_lo]));
 1827         } else {
 1828             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1829                      as_Register(Matcher::_regEncode[src_lo]));
 1830         }
 1831       } else {                    // gpr --&gt; stack spill
 1832         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1833         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1834       }
 1835       break;
 1836     case rc_float:
 1837       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1838         if (is64) {
 1839             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1840                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1841         } else {
 1842             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1843                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1844         }
 1845       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1846           if (cbuf) {
 1847             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1848                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1849         } else {
 1850             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1851                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1852         }
 1853       } else {                    // fpr --&gt; stack spill
 1854         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1855         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1856                  is64 ? __ D : __ S, dst_offset);
 1857       }
 1858       break;
 1859     case rc_stack:
 1860       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1861         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1862       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1863         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1864                    is64 ? __ D : __ S, src_offset);
 1865       } else {                    // stack --&gt; stack copy
 1866         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1867         __ unspill(rscratch1, is64, src_offset);
 1868         __ spill(rscratch1, is64, dst_offset);
 1869       }
 1870       break;
 1871     default:
 1872       assert(false, &quot;bad rc_class for spill&quot;);
 1873       ShouldNotReachHere();
 1874     }
 1875   }
 1876 
 1877   if (st) {
 1878     st-&gt;print(&quot;spill &quot;);
 1879     if (src_lo_rc == rc_stack) {
 1880       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1881     } else {
 1882       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1883     }
 1884     if (dst_lo_rc == rc_stack) {
 1885       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1886     } else {
 1887       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1888     }
 1889     if (bottom_type()-&gt;isa_vect() != NULL) {
 1890       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1891     } else {
 1892       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1893     }
 1894   }
 1895 
 1896   return 0;
 1897 
 1898 }
 1899 
 1900 #ifndef PRODUCT
 1901 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1902   if (!ra_)
 1903     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1904   else
 1905     implementation(NULL, ra_, false, st);
 1906 }
 1907 #endif
 1908 
 1909 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1910   implementation(&amp;cbuf, ra_, false, NULL);
 1911 }
 1912 
 1913 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1914   return MachNode::size(ra_);
 1915 }
 1916 
 1917 //=============================================================================
 1918 
 1919 #ifndef PRODUCT
 1920 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1921   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1922   int reg = ra_-&gt;get_reg_first(this);
 1923   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1924             Matcher::regName[reg], offset);
 1925 }
 1926 #endif
 1927 
 1928 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<a name="14" id="anc14"></a><span class="line-modified"> 1929   MacroAssembler _masm(&amp;cbuf);</span>
 1930 
 1931   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1932   int reg    = ra_-&gt;get_encode(this);
 1933 
 1934   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1935     __ add(as_Register(reg), sp, offset);
 1936   } else {
 1937     ShouldNotReachHere();
 1938   }
 1939 }
 1940 
 1941 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1942   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1943   return 4;
 1944 }
 1945 
 1946 ///=============================================================================
 1947 #ifndef PRODUCT
 1948 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1949 {
 1950   st-&gt;print_cr(&quot;# MachVEPNode&quot;);
 1951   if (!_verified) {
 1952     st-&gt;print_cr(&quot;\t load_class&quot;);
 1953   } else {
 1954     st-&gt;print_cr(&quot;\t unpack_value_arg&quot;);
 1955   }
 1956 }
 1957 #endif
 1958 
 1959 void MachVEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1960 {
 1961   MacroAssembler _masm(&amp;cbuf);
 1962 
 1963   if (!_verified) {
 1964     Label skip;
 1965     __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 1966     __ br(Assembler::EQ, skip);
 1967       __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 1968     __ bind(skip);
 1969 
 1970   } else {
 1971     // Unpack value type args passed as oop and then jump to
 1972     // the verified entry point (skipping the unverified entry).
 1973     __ unpack_value_args(ra_-&gt;C, _receiver_only);
 1974     __ b(*_verified_entry);
 1975   }
 1976 }
 1977 
 1978 
 1979 uint MachVEPNode::size(PhaseRegAlloc* ra_) const
 1980 {
 1981   return MachNode::size(ra_); // too many variables; just compute it the hard way
 1982 }
 1983 
 1984 
 1985 //=============================================================================
 1986 #ifndef PRODUCT
 1987 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1988 {
 1989   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1990   if (UseCompressedClassPointers) {
 1991     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1992     if (CompressedKlassPointers::shift() != 0) {
 1993       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1994     }
 1995   } else {
 1996    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1997   }
 1998   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1999   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2000 }
 2001 #endif
 2002 
 2003 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2004 {
 2005   // This is the unverified entry point.
<a name="15" id="anc15"></a><span class="line-modified"> 2006   MacroAssembler _masm(&amp;cbuf);</span>
 2007   Label skip;
 2008 
 2009   // UseCompressedClassPointers logic are inside cmp_klass
 2010   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2011 
 2012   // TODO
 2013   // can we avoid this skip and still use a reloc?
 2014   __ br(Assembler::EQ, skip);
 2015   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2016   __ bind(skip);
 2017 }
 2018 
 2019 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2020 {
 2021   return MachNode::size(ra_);
 2022 }
 2023 
 2024 // REQUIRED EMIT CODE
 2025 
 2026 //=============================================================================
 2027 
 2028 // Emit exception handler code.
 2029 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2030 {
 2031   // mov rscratch1 #exception_blob_entry_point
 2032   // br rscratch1
 2033   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2034   // That&#39;s why we must use the macroassembler to generate a handler.
<a name="16" id="anc16"></a><span class="line-modified"> 2035   MacroAssembler _masm(&amp;cbuf);</span>
 2036   address base = __ start_a_stub(size_exception_handler());
 2037   if (base == NULL) {
 2038     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2039     return 0;  // CodeBuffer::expand failed
 2040   }
 2041   int offset = __ offset();
 2042   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2043   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2044   __ end_a_stub();
 2045   return offset;
 2046 }
 2047 
 2048 // Emit deopt handler code.
 2049 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2050 {
 2051   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2052   // That&#39;s why we must use the macroassembler to generate a handler.
<a name="17" id="anc17"></a><span class="line-modified"> 2053   MacroAssembler _masm(&amp;cbuf);</span>
 2054   address base = __ start_a_stub(size_deopt_handler());
 2055   if (base == NULL) {
 2056     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2057     return 0;  // CodeBuffer::expand failed
 2058   }
 2059   int offset = __ offset();
 2060 
 2061   __ adr(lr, __ pc());
 2062   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2063 
 2064   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2065   __ end_a_stub();
 2066   return offset;
 2067 }
 2068 
 2069 // REQUIRED MATCHER CODE
 2070 
 2071 //=============================================================================
 2072 
 2073 const bool Matcher::match_rule_supported(int opcode) {
 2074   if (!has_match_rule(opcode))
 2075     return false;
 2076 
 2077   bool ret_value = true;
 2078   switch (opcode) {
 2079     case Op_CacheWB:
 2080     case Op_CacheWBPreSync:
 2081     case Op_CacheWBPostSync:
 2082       if (!VM_Version::supports_data_cache_line_flush()) {
 2083         ret_value = false;
 2084       }
 2085       break;
 2086   }
 2087 
 2088   return ret_value; // Per default match rules are supported.
 2089 }
 2090 
 2091 // Identify extra cases that we might want to provide match rules for vector nodes and
 2092 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2093 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2094   if (!match_rule_supported(opcode)) {
 2095     return false;
 2096   }
 2097 
 2098   // Special cases which require vector length
 2099   switch (opcode) {
 2100     case Op_MulAddVS2VI: {
 2101       if (vlen != 4) {
 2102         return false;
 2103       }
 2104       break;
 2105     }
 2106   }
 2107 
 2108   return true; // Per default match rules are supported.
 2109 }
 2110 
 2111 const bool Matcher::has_predicated_vectors(void) {
 2112   return false;
 2113 }
 2114 
 2115 const int Matcher::float_pressure(int default_pressure_threshold) {
 2116   return default_pressure_threshold;
 2117 }
 2118 
 2119 int Matcher::regnum_to_fpu_offset(int regnum)
 2120 {
 2121   Unimplemented();
 2122   return 0;
 2123 }
 2124 
 2125 // Is this branch offset short enough that a short branch can be used?
 2126 //
 2127 // NOTE: If the platform does not provide any short branch variants, then
 2128 //       this method should return false for offset 0.
 2129 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2130   // The passed offset is relative to address of the branch.
 2131 
 2132   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2133 }
 2134 
 2135 const bool Matcher::isSimpleConstant64(jlong value) {
 2136   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2137   // Probably always true, even if a temp register is required.
 2138   return true;
 2139 }
 2140 
 2141 // true just means we have fast l2f conversion
 2142 const bool Matcher::convL2FSupported(void) {
 2143   return true;
 2144 }
 2145 
 2146 // Vector width in bytes.
 2147 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2148   int size = MIN2(16,(int)MaxVectorSize);
 2149   // Minimum 2 values in vector
 2150   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2151   // But never &lt; 4
 2152   if (size &lt; 4) size = 0;
 2153   return size;
 2154 }
 2155 
 2156 // Limits on vector size (number of elements) loaded into vector.
 2157 const int Matcher::max_vector_size(const BasicType bt) {
 2158   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2159 }
 2160 const int Matcher::min_vector_size(const BasicType bt) {
 2161 //  For the moment limit the vector size to 8 bytes
 2162     int size = 8 / type2aelembytes(bt);
 2163     if (size &lt; 2) size = 2;
 2164     return size;
 2165 }
 2166 
 2167 // Vector ideal reg.
 2168 const uint Matcher::vector_ideal_reg(int len) {
 2169   switch(len) {
 2170     case  8: return Op_VecD;
 2171     case 16: return Op_VecX;
 2172   }
 2173   ShouldNotReachHere();
 2174   return 0;
 2175 }
 2176 
 2177 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 2178   switch(size) {
 2179     case  8: return Op_VecD;
 2180     case 16: return Op_VecX;
 2181   }
 2182   ShouldNotReachHere();
 2183   return 0;
 2184 }
 2185 
 2186 // AES support not yet implemented
 2187 const bool Matcher::pass_original_key_for_aes() {
 2188   return false;
 2189 }
 2190 
 2191 // aarch64 supports misaligned vectors store/load.
 2192 const bool Matcher::misaligned_vectors_ok() {
 2193   return true;
 2194 }
 2195 
 2196 // false =&gt; size gets scaled to BytesPerLong, ok.
 2197 const bool Matcher::init_array_count_is_in_bytes = false;
 2198 
 2199 // Use conditional move (CMOVL)
 2200 const int Matcher::long_cmove_cost() {
 2201   // long cmoves are no more expensive than int cmoves
 2202   return 0;
 2203 }
 2204 
 2205 const int Matcher::float_cmove_cost() {
 2206   // float cmoves are no more expensive than int cmoves
 2207   return 0;
 2208 }
 2209 
 2210 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2211 const bool Matcher::require_postalloc_expand = false;
 2212 
 2213 // Do we need to mask the count passed to shift instructions or does
 2214 // the cpu only look at the lower 5/6 bits anyway?
 2215 const bool Matcher::need_masked_shift_count = false;
 2216 
 2217 // No support for generic vector operands.
 2218 const bool Matcher::supports_generic_vector_operands  = false;
 2219 
 2220 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2221   ShouldNotReachHere(); // generic vector operands not supported
 2222   return NULL;
 2223 }
 2224 
 2225 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2226   ShouldNotReachHere();  // generic vector operands not supported
 2227   return false;
 2228 }
 2229 
 2230 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2231   ShouldNotReachHere();  // generic vector operands not supported
 2232   return false;
 2233 }
 2234 
 2235 // This affects two different things:
 2236 //  - how Decode nodes are matched
 2237 //  - how ImplicitNullCheck opportunities are recognized
 2238 // If true, the matcher will try to remove all Decodes and match them
 2239 // (as operands) into nodes. NullChecks are not prepared to deal with
 2240 // Decodes by final_graph_reshaping().
 2241 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2242 // for a NullCheck. The matcher matches the Decode node into a register.
 2243 // Implicit_null_check optimization moves the Decode along with the
 2244 // memory operation back up before the NullCheck.
 2245 bool Matcher::narrow_oop_use_complex_address() {
 2246   return CompressedOops::shift() == 0;
 2247 }
 2248 
 2249 bool Matcher::narrow_klass_use_complex_address() {
 2250 // TODO
 2251 // decide whether we need to set this to true
 2252   return false;
 2253 }
 2254 
 2255 bool Matcher::const_oop_prefer_decode() {
 2256   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2257   return CompressedOops::base() == NULL;
 2258 }
 2259 
 2260 bool Matcher::const_klass_prefer_decode() {
 2261   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2262   return CompressedKlassPointers::base() == NULL;
 2263 }
 2264 
 2265 // Is it better to copy float constants, or load them directly from
 2266 // memory?  Intel can load a float constant from a direct address,
 2267 // requiring no extra registers.  Most RISCs will have to materialize
 2268 // an address into a register first, so they would do better to copy
 2269 // the constant from stack.
 2270 const bool Matcher::rematerialize_float_constants = false;
 2271 
 2272 // If CPU can load and store mis-aligned doubles directly then no
 2273 // fixup is needed.  Else we split the double into 2 integer pieces
 2274 // and move it piece-by-piece.  Only happens when passing doubles into
 2275 // C code as the Java calling convention forces doubles to be aligned.
 2276 const bool Matcher::misaligned_doubles_ok = true;
 2277 
 2278 // No-op on amd64
 2279 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2280   Unimplemented();
 2281 }
 2282 
 2283 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2284 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2285 
 2286 // Are floats converted to double when stored to stack during
 2287 // deoptimization?
 2288 bool Matcher::float_in_double() { return false; }
 2289 
 2290 // Do ints take an entire long register or just half?
 2291 // The relevant question is how the int is callee-saved:
 2292 // the whole long is written but de-opt&#39;ing will have to extract
 2293 // the relevant 32 bits.
 2294 const bool Matcher::int_in_long = true;
 2295 
 2296 // Return whether or not this register is ever used as an argument.
 2297 // This function is used on startup to build the trampoline stubs in
 2298 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2299 // call in the trampoline, and arguments in those registers not be
 2300 // available to the callee.
 2301 bool Matcher::can_be_java_arg(int reg)
 2302 {
 2303   return
 2304     reg ==  R0_num || reg == R0_H_num ||
 2305     reg ==  R1_num || reg == R1_H_num ||
 2306     reg ==  R2_num || reg == R2_H_num ||
 2307     reg ==  R3_num || reg == R3_H_num ||
 2308     reg ==  R4_num || reg == R4_H_num ||
 2309     reg ==  R5_num || reg == R5_H_num ||
 2310     reg ==  R6_num || reg == R6_H_num ||
 2311     reg ==  R7_num || reg == R7_H_num ||
 2312     reg ==  V0_num || reg == V0_H_num ||
 2313     reg ==  V1_num || reg == V1_H_num ||
 2314     reg ==  V2_num || reg == V2_H_num ||
 2315     reg ==  V3_num || reg == V3_H_num ||
 2316     reg ==  V4_num || reg == V4_H_num ||
 2317     reg ==  V5_num || reg == V5_H_num ||
 2318     reg ==  V6_num || reg == V6_H_num ||
 2319     reg ==  V7_num || reg == V7_H_num;
 2320 }
 2321 
 2322 bool Matcher::is_spillable_arg(int reg)
 2323 {
 2324   return can_be_java_arg(reg);
 2325 }
 2326 
 2327 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2328   return false;
 2329 }
 2330 
 2331 RegMask Matcher::divI_proj_mask() {
 2332   ShouldNotReachHere();
 2333   return RegMask();
 2334 }
 2335 
 2336 // Register for MODI projection of divmodI.
 2337 RegMask Matcher::modI_proj_mask() {
 2338   ShouldNotReachHere();
 2339   return RegMask();
 2340 }
 2341 
 2342 // Register for DIVL projection of divmodL.
 2343 RegMask Matcher::divL_proj_mask() {
 2344   ShouldNotReachHere();
 2345   return RegMask();
 2346 }
 2347 
 2348 // Register for MODL projection of divmodL.
 2349 RegMask Matcher::modL_proj_mask() {
 2350   ShouldNotReachHere();
 2351   return RegMask();
 2352 }
 2353 
 2354 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2355   return FP_REG_mask();
 2356 }
 2357 
 2358 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2359   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2360     Node* u = addp-&gt;fast_out(i);
 2361     if (u-&gt;is_Mem()) {
 2362       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2363       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2364       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2365         return false;
 2366       }
 2367     }
 2368   }
 2369   return true;
 2370 }
 2371 
 2372 const bool Matcher::convi2l_type_required = false;
 2373 
 2374 // Should the Matcher clone shifts on addressing modes, expecting them
 2375 // to be subsumed into complex addressing expressions or compute them
 2376 // into registers?
 2377 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2378   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2379     return true;
 2380   }
 2381 
 2382   Node *off = m-&gt;in(AddPNode::Offset);
 2383   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2384       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2385       // Are there other uses besides address expressions?
 2386       !is_visited(off)) {
 2387     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2388     mstack.push(off-&gt;in(2), Visit);
 2389     Node *conv = off-&gt;in(1);
 2390     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2391         // Are there other uses besides address expressions?
 2392         !is_visited(conv)) {
 2393       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2394       mstack.push(conv-&gt;in(1), Pre_Visit);
 2395     } else {
 2396       mstack.push(conv, Pre_Visit);
 2397     }
 2398     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2399     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2400     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2401     return true;
 2402   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2403              // Are there other uses besides address expressions?
 2404              !is_visited(off)) {
 2405     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2406     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2407     mstack.push(off-&gt;in(1), Pre_Visit);
 2408     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2409     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2410     return true;
 2411   }
 2412   return false;
 2413 }
 2414 
 2415 void Compile::reshape_address(AddPNode* addp) {
 2416 }
 2417 
 2418 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
<a name="18" id="anc18"></a><span class="line-modified"> 2419   MacroAssembler _masm(&amp;cbuf);                                          \</span>
 2420   {                                                                     \
 2421     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2422     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2423     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2424     __ INSN(REG, as_Register(BASE));                                    \
 2425   }
 2426 
 2427 
 2428 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2429   {
 2430     Address::extend scale;
 2431 
 2432     // Hooboy, this is fugly.  We need a way to communicate to the
 2433     // encoder that the index needs to be sign extended, so we have to
 2434     // enumerate all the cases.
 2435     switch (opcode) {
 2436     case INDINDEXSCALEDI2L:
 2437     case INDINDEXSCALEDI2LN:
 2438     case INDINDEXI2L:
 2439     case INDINDEXI2LN:
 2440       scale = Address::sxtw(size);
 2441       break;
 2442     default:
 2443       scale = Address::lsl(size);
 2444     }
 2445 
 2446     if (index == -1) {
 2447       return Address(base, disp);
 2448     } else {
 2449       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2450       return Address(base, as_Register(index), scale);
 2451     }
 2452   }
 2453 
 2454 
 2455 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2456 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2457 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2458 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2459                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2460 
 2461   // Used for all non-volatile memory accesses.  The use of
 2462   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2463   // offsets is something of a kludge.
<a name="19" id="anc19"></a><span class="line-modified"> 2464   static void loadStore(MacroAssembler masm, mem_insn insn,</span>
 2465                         Register reg, int opcode,
 2466                         Register base, int index, int scale, int disp,
 2467                         int size_in_memory)
 2468   {
 2469     Address addr = mem2address(opcode, base, index, scale, disp);
 2470     if (addr.getMode() == Address::base_plus_offset) {
 2471       /* If we get an out-of-range offset it is a bug in the compiler,
 2472          so we assert here. */
 2473       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2474              &quot;c2 compiler bug&quot;);
 2475       /* Fix up any out-of-range offsets. */
 2476       assert_different_registers(rscratch1, base);
 2477       assert_different_registers(rscratch1, reg);
 2478       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2479     }
 2480     (masm.*insn)(reg, addr);
 2481   }
 2482 
<a name="20" id="anc20"></a><span class="line-modified"> 2483   static void loadStore(MacroAssembler masm, mem_float_insn insn,</span>
 2484                         FloatRegister reg, int opcode,
 2485                         Register base, int index, int size, int disp,
 2486                         int size_in_memory)
 2487   {
 2488     Address::extend scale;
 2489 
 2490     switch (opcode) {
 2491     case INDINDEXSCALEDI2L:
 2492     case INDINDEXSCALEDI2LN:
 2493       scale = Address::sxtw(size);
 2494       break;
 2495     default:
 2496       scale = Address::lsl(size);
 2497     }
 2498 
 2499     if (index == -1) {
 2500       /* If we get an out-of-range offset it is a bug in the compiler,
 2501          so we assert here. */
 2502       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2503       /* Fix up any out-of-range offsets. */
 2504       assert_different_registers(rscratch1, base);
 2505       Address addr = Address(base, disp);
 2506       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2507       (masm.*insn)(reg, addr);
 2508     } else {
 2509       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2510       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2511     }
 2512   }
 2513 
<a name="21" id="anc21"></a><span class="line-modified"> 2514   static void loadStore(MacroAssembler masm, mem_vector_insn insn,</span>
 2515                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2516                         int opcode, Register base, int index, int size, int disp)
 2517   {
 2518     if (index == -1) {
 2519       (masm.*insn)(reg, T, Address(base, disp));
 2520     } else {
 2521       assert(disp == 0, &quot;unsupported address mode&quot;);
 2522       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2523     }
 2524   }
 2525 
 2526 %}
 2527 
 2528 
 2529 
 2530 //----------ENCODING BLOCK-----------------------------------------------------
 2531 // This block specifies the encoding classes used by the compiler to
 2532 // output byte streams.  Encoding classes are parameterized macros
 2533 // used by Machine Instruction Nodes in order to generate the bit
 2534 // encoding of the instruction.  Operands specify their base encoding
 2535 // interface with the interface keyword.  There are currently
 2536 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2537 // COND_INTER.  REG_INTER causes an operand to generate a function
 2538 // which returns its register number when queried.  CONST_INTER causes
 2539 // an operand to generate a function which returns the value of the
 2540 // constant when queried.  MEMORY_INTER causes an operand to generate
 2541 // four functions which return the Base Register, the Index Register,
 2542 // the Scale Value, and the Offset Value of the operand when queried.
 2543 // COND_INTER causes an operand to generate six functions which return
 2544 // the encoding code (ie - encoding bits for the instruction)
 2545 // associated with each basic boolean condition for a conditional
 2546 // instruction.
 2547 //
 2548 // Instructions specify two basic values for encoding.  Again, a
 2549 // function is available to check if the constant displacement is an
 2550 // oop. They use the ins_encode keyword to specify their encoding
 2551 // classes (which must be a sequence of enc_class names, and their
 2552 // parameters, specified in the encoding block), and they use the
 2553 // opcode keyword to specify, in order, their primary, secondary, and
 2554 // tertiary opcode.  Only the opcode sections which a particular
 2555 // instruction needs for encoding need to be specified.
 2556 encode %{
 2557   // Build emit functions for each basic byte or larger field in the
 2558   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2559   // from C++ code in the enc_class source block.  Emit functions will
 2560   // live in the main source block for now.  In future, we can
 2561   // generalize this by adding a syntax that specifies the sizes of
 2562   // fields in an order, so that the adlc can build the emit functions
 2563   // automagically
 2564 
 2565   // catch all for unimplemented encodings
 2566   enc_class enc_unimplemented %{
<a name="22" id="anc22"></a><span class="line-modified"> 2567     MacroAssembler _masm(&amp;cbuf);</span>
 2568     __ unimplemented(&quot;C2 catch all&quot;);
 2569   %}
 2570 
 2571   // BEGIN Non-volatile memory access
 2572 
 2573   // This encoding class is generated automatically from ad_encode.m4.
 2574   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2575   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2576     Register dst_reg = as_Register($dst$$reg);
<a name="23" id="anc23"></a><span class="line-modified"> 2577     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),</span>
 2578                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2579   %}
 2580 
 2581   // This encoding class is generated automatically from ad_encode.m4.
 2582   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2583   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2584     Register dst_reg = as_Register($dst$$reg);
<a name="24" id="anc24"></a><span class="line-modified"> 2585     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),</span>
 2586                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2587   %}
 2588 
 2589   // This encoding class is generated automatically from ad_encode.m4.
 2590   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2591   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2592     Register dst_reg = as_Register($dst$$reg);
<a name="25" id="anc25"></a><span class="line-modified"> 2593     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2594                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2595   %}
 2596 
 2597   // This encoding class is generated automatically from ad_encode.m4.
 2598   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2599   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2600     Register dst_reg = as_Register($dst$$reg);
<a name="26" id="anc26"></a><span class="line-modified"> 2601     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2602                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2603   %}
 2604 
 2605   // This encoding class is generated automatically from ad_encode.m4.
 2606   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2607   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2608     Register dst_reg = as_Register($dst$$reg);
<a name="27" id="anc27"></a><span class="line-modified"> 2609     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),</span>
 2610                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2611   %}
 2612 
 2613   // This encoding class is generated automatically from ad_encode.m4.
 2614   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2615   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2616     Register dst_reg = as_Register($dst$$reg);
<a name="28" id="anc28"></a><span class="line-modified"> 2617     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),</span>
 2618                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2619   %}
 2620 
 2621   // This encoding class is generated automatically from ad_encode.m4.
 2622   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2623   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2624     Register dst_reg = as_Register($dst$$reg);
<a name="29" id="anc29"></a><span class="line-modified"> 2625     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2626                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2627   %}
 2628 
 2629   // This encoding class is generated automatically from ad_encode.m4.
 2630   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2631   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2632     Register dst_reg = as_Register($dst$$reg);
<a name="30" id="anc30"></a><span class="line-modified"> 2633     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2634                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2635   %}
 2636 
 2637   // This encoding class is generated automatically from ad_encode.m4.
 2638   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2639   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2640     Register dst_reg = as_Register($dst$$reg);
<a name="31" id="anc31"></a><span class="line-modified"> 2641     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2642                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2643   %}
 2644 
 2645   // This encoding class is generated automatically from ad_encode.m4.
 2646   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2647   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2648     Register dst_reg = as_Register($dst$$reg);
<a name="32" id="anc32"></a><span class="line-modified"> 2649     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2650                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2651   %}
 2652 
 2653   // This encoding class is generated automatically from ad_encode.m4.
 2654   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2655   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2656     Register dst_reg = as_Register($dst$$reg);
<a name="33" id="anc33"></a><span class="line-modified"> 2657     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),</span>
 2658                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2659   %}
 2660 
 2661   // This encoding class is generated automatically from ad_encode.m4.
 2662   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2663   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2664     Register dst_reg = as_Register($dst$$reg);
<a name="34" id="anc34"></a><span class="line-modified"> 2665     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),</span>
 2666                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2667   %}
 2668 
 2669   // This encoding class is generated automatically from ad_encode.m4.
 2670   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2671   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2672     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<a name="35" id="anc35"></a><span class="line-modified"> 2673     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),</span>
 2674                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2675   %}
 2676 
 2677   // This encoding class is generated automatically from ad_encode.m4.
 2678   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2679   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2680     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<a name="36" id="anc36"></a><span class="line-modified"> 2681     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),</span>
 2682                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2683   %}
 2684 
 2685   // This encoding class is generated automatically from ad_encode.m4.
 2686   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2687   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2688     Register src_reg = as_Register($src$$reg);
<a name="37" id="anc37"></a><span class="line-modified"> 2689     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),</span>
 2690                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2691   %}
 2692 
 2693   // This encoding class is generated automatically from ad_encode.m4.
 2694   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2695   enc_class aarch64_enc_strb0(memory1 mem) %{
<a name="38" id="anc38"></a><span class="line-modified"> 2696     MacroAssembler _masm(&amp;cbuf);</span>
 2697     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2698                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2699   %}
 2700 
 2701   // This encoding class is generated automatically from ad_encode.m4.
 2702   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2703   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2704     Register src_reg = as_Register($src$$reg);
<a name="39" id="anc39"></a><span class="line-modified"> 2705     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),</span>
 2706                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2707   %}
 2708 
 2709   // This encoding class is generated automatically from ad_encode.m4.
 2710   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2711   enc_class aarch64_enc_strh0(memory2 mem) %{
<a name="40" id="anc40"></a><span class="line-modified"> 2712     MacroAssembler _masm(&amp;cbuf);</span>
 2713     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2714                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2715   %}
 2716 
 2717   // This encoding class is generated automatically from ad_encode.m4.
 2718   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2719   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2720     Register src_reg = as_Register($src$$reg);
<a name="41" id="anc41"></a><span class="line-modified"> 2721     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),</span>
 2722                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2723   %}
 2724 
 2725   // This encoding class is generated automatically from ad_encode.m4.
 2726   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2727   enc_class aarch64_enc_strw0(memory4 mem) %{
<a name="42" id="anc42"></a><span class="line-modified"> 2728     MacroAssembler _masm(&amp;cbuf);</span>
 2729     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2730                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2731   %}
 2732 
 2733   // This encoding class is generated automatically from ad_encode.m4.
 2734   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2735   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2736     Register src_reg = as_Register($src$$reg);
 2737     // we sometimes get asked to store the stack pointer into the
 2738     // current thread -- we cannot do that directly on AArch64
 2739     if (src_reg == r31_sp) {
<a name="43" id="anc43"></a><span class="line-modified"> 2740       MacroAssembler _masm(&amp;cbuf);</span>
 2741       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2742       __ mov(rscratch2, sp);
 2743       src_reg = rscratch2;
 2744     }
<a name="44" id="anc44"></a><span class="line-modified"> 2745     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),</span>
 2746                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2747   %}
 2748 
 2749   // This encoding class is generated automatically from ad_encode.m4.
 2750   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2751   enc_class aarch64_enc_str0(memory8 mem) %{
<a name="45" id="anc45"></a><span class="line-modified"> 2752     MacroAssembler _masm(&amp;cbuf);</span>
 2753     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2754                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2755   %}
 2756 
 2757   // This encoding class is generated automatically from ad_encode.m4.
 2758   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2759   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2760     FloatRegister src_reg = as_FloatRegister($src$$reg);
<a name="46" id="anc46"></a><span class="line-modified"> 2761     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),</span>
 2762                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2763   %}
 2764 
 2765   // This encoding class is generated automatically from ad_encode.m4.
 2766   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2767   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2768     FloatRegister src_reg = as_FloatRegister($src$$reg);
<a name="47" id="anc47"></a><span class="line-modified"> 2769     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),</span>
 2770                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2771   %}
 2772 
 2773   // This encoding class is generated automatically from ad_encode.m4.
 2774   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2775   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
<a name="48" id="anc48"></a><span class="line-modified"> 2776     MacroAssembler _masm(&amp;cbuf);</span>
 2777     address con = (address)$src$$constant;
 2778     // need to do this the hard way until we can manage relocs
 2779     // for 32 bit constants
 2780     __ movoop(rscratch2, (jobject)con);
 2781     if (con) __ encode_heap_oop_not_null(rscratch2);
 2782     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2783                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2784   %}
 2785 
 2786   // This encoding class is generated automatically from ad_encode.m4.
 2787   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2788   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
<a name="49" id="anc49"></a><span class="line-modified"> 2789     MacroAssembler _masm(&amp;cbuf);</span>
 2790     address con = (address)$src$$constant;
 2791     // need to do this the hard way until we can manage relocs
 2792     // for 32 bit constants
 2793     __ movoop(rscratch2, (jobject)con);
 2794     __ encode_klass_not_null(rscratch2);
 2795     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2796                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2797   %}
 2798 
 2799   // This encoding class is generated automatically from ad_encode.m4.
 2800   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2801   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
<a name="50" id="anc50"></a><span class="line-modified"> 2802       MacroAssembler _masm(&amp;cbuf);</span>
 2803       __ membar(Assembler::StoreStore);
 2804       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2805                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2806   %}
 2807 
 2808   // END Non-volatile memory access
 2809 
 2810   // Vector loads and stores
 2811   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2812     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<a name="51" id="anc51"></a><span class="line-modified"> 2813     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,</span>
 2814        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2815   %}
 2816 
 2817   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2818     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<a name="52" id="anc52"></a><span class="line-modified"> 2819     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,</span>
 2820        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2821   %}
 2822 
 2823   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2824     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<a name="53" id="anc53"></a><span class="line-modified"> 2825     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,</span>
 2826        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2827   %}
 2828 
 2829   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2830     FloatRegister src_reg = as_FloatRegister($src$$reg);
<a name="54" id="anc54"></a><span class="line-modified"> 2831     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,</span>
 2832        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2833   %}
 2834 
 2835   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2836     FloatRegister src_reg = as_FloatRegister($src$$reg);
<a name="55" id="anc55"></a><span class="line-modified"> 2837     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,</span>
 2838        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2839   %}
 2840 
 2841   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2842     FloatRegister src_reg = as_FloatRegister($src$$reg);
<a name="56" id="anc56"></a><span class="line-modified"> 2843     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,</span>
 2844        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2845   %}
 2846 
 2847   // volatile loads and stores
 2848 
 2849   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2850     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2851                  rscratch1, stlrb);
 2852   %}
 2853 
 2854   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2855     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2856                  rscratch1, stlrh);
 2857   %}
 2858 
 2859   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2860     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2861                  rscratch1, stlrw);
 2862   %}
 2863 
 2864 
 2865   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2866     Register dst_reg = as_Register($dst$$reg);
 2867     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2868              rscratch1, ldarb);
 2869     __ sxtbw(dst_reg, dst_reg);
 2870   %}
 2871 
 2872   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2873     Register dst_reg = as_Register($dst$$reg);
 2874     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2875              rscratch1, ldarb);
 2876     __ sxtb(dst_reg, dst_reg);
 2877   %}
 2878 
 2879   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2880     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2881              rscratch1, ldarb);
 2882   %}
 2883 
 2884   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2885     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2886              rscratch1, ldarb);
 2887   %}
 2888 
 2889   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2890     Register dst_reg = as_Register($dst$$reg);
 2891     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2892              rscratch1, ldarh);
 2893     __ sxthw(dst_reg, dst_reg);
 2894   %}
 2895 
 2896   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2897     Register dst_reg = as_Register($dst$$reg);
 2898     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2899              rscratch1, ldarh);
 2900     __ sxth(dst_reg, dst_reg);
 2901   %}
 2902 
 2903   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2904     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2905              rscratch1, ldarh);
 2906   %}
 2907 
 2908   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2909     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2910              rscratch1, ldarh);
 2911   %}
 2912 
 2913   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2914     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2915              rscratch1, ldarw);
 2916   %}
 2917 
 2918   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2919     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2920              rscratch1, ldarw);
 2921   %}
 2922 
 2923   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2924     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2925              rscratch1, ldar);
 2926   %}
 2927 
 2928   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2929     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930              rscratch1, ldarw);
 2931     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2935     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2936              rscratch1, ldar);
 2937     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2938   %}
 2939 
 2940   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2941     Register src_reg = as_Register($src$$reg);
 2942     // we sometimes get asked to store the stack pointer into the
 2943     // current thread -- we cannot do that directly on AArch64
 2944     if (src_reg == r31_sp) {
<a name="57" id="anc57"></a><span class="line-modified"> 2945         MacroAssembler _masm(&amp;cbuf);</span>
 2946       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2947       __ mov(rscratch2, sp);
 2948       src_reg = rscratch2;
 2949     }
 2950     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2951                  rscratch1, stlr);
 2952   %}
 2953 
 2954   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2955     {
<a name="58" id="anc58"></a><span class="line-modified"> 2956       MacroAssembler _masm(&amp;cbuf);</span>
 2957       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2958       __ fmovs(rscratch2, src_reg);
 2959     }
 2960     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2961                  rscratch1, stlrw);
 2962   %}
 2963 
 2964   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2965     {
<a name="59" id="anc59"></a><span class="line-modified"> 2966       MacroAssembler _masm(&amp;cbuf);</span>
 2967       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2968       __ fmovd(rscratch2, src_reg);
 2969     }
 2970     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2971                  rscratch1, stlr);
 2972   %}
 2973 
 2974   // synchronized read/update encodings
 2975 
 2976   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
<a name="60" id="anc60"></a><span class="line-modified"> 2977     MacroAssembler _masm(&amp;cbuf);</span>
 2978     Register dst_reg = as_Register($dst$$reg);
 2979     Register base = as_Register($mem$$base);
 2980     int index = $mem$$index;
 2981     int scale = $mem$$scale;
 2982     int disp = $mem$$disp;
 2983     if (index == -1) {
 2984        if (disp != 0) {
 2985         __ lea(rscratch1, Address(base, disp));
 2986         __ ldaxr(dst_reg, rscratch1);
 2987       } else {
 2988         // TODO
 2989         // should we ever get anything other than this case?
 2990         __ ldaxr(dst_reg, base);
 2991       }
 2992     } else {
 2993       Register index_reg = as_Register(index);
 2994       if (disp == 0) {
 2995         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2996         __ ldaxr(dst_reg, rscratch1);
 2997       } else {
 2998         __ lea(rscratch1, Address(base, disp));
 2999         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3000         __ ldaxr(dst_reg, rscratch1);
 3001       }
 3002     }
 3003   %}
 3004 
 3005   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
<a name="61" id="anc61"></a><span class="line-modified"> 3006     MacroAssembler _masm(&amp;cbuf);</span>
 3007     Register src_reg = as_Register($src$$reg);
 3008     Register base = as_Register($mem$$base);
 3009     int index = $mem$$index;
 3010     int scale = $mem$$scale;
 3011     int disp = $mem$$disp;
 3012     if (index == -1) {
 3013        if (disp != 0) {
 3014         __ lea(rscratch2, Address(base, disp));
 3015         __ stlxr(rscratch1, src_reg, rscratch2);
 3016       } else {
 3017         // TODO
 3018         // should we ever get anything other than this case?
 3019         __ stlxr(rscratch1, src_reg, base);
 3020       }
 3021     } else {
 3022       Register index_reg = as_Register(index);
 3023       if (disp == 0) {
 3024         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3025         __ stlxr(rscratch1, src_reg, rscratch2);
 3026       } else {
 3027         __ lea(rscratch2, Address(base, disp));
 3028         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3029         __ stlxr(rscratch1, src_reg, rscratch2);
 3030       }
 3031     }
 3032     __ cmpw(rscratch1, zr);
 3033   %}
 3034 
 3035   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<a name="62" id="anc62"></a><span class="line-modified"> 3036     MacroAssembler _masm(&amp;cbuf);</span>
 3037     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3038     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3039                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3040                /*weak*/ false, noreg);
 3041   %}
 3042 
 3043   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<a name="63" id="anc63"></a><span class="line-modified"> 3044     MacroAssembler _masm(&amp;cbuf);</span>
 3045     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3046     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3047                Assembler::word, /*acquire*/ false, /*release*/ true,
 3048                /*weak*/ false, noreg);
 3049   %}
 3050 
 3051   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<a name="64" id="anc64"></a><span class="line-modified"> 3052     MacroAssembler _masm(&amp;cbuf);</span>
 3053     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3054     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3055                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3056                /*weak*/ false, noreg);
 3057   %}
 3058 
 3059   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<a name="65" id="anc65"></a><span class="line-modified"> 3060     MacroAssembler _masm(&amp;cbuf);</span>
 3061     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3062     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3063                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3064                /*weak*/ false, noreg);
 3065   %}
 3066 
 3067 
 3068   // The only difference between aarch64_enc_cmpxchg and
 3069   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3070   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3071   // lock.
 3072   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<a name="66" id="anc66"></a><span class="line-modified"> 3073     MacroAssembler _masm(&amp;cbuf);</span>
 3074     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3075     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3076                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3077                /*weak*/ false, noreg);
 3078   %}
 3079 
 3080   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<a name="67" id="anc67"></a><span class="line-modified"> 3081     MacroAssembler _masm(&amp;cbuf);</span>
 3082     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3083     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3084                Assembler::word, /*acquire*/ true, /*release*/ true,
 3085                /*weak*/ false, noreg);
 3086   %}
 3087 
 3088   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<a name="68" id="anc68"></a><span class="line-modified"> 3089     MacroAssembler _masm(&amp;cbuf);</span>
 3090     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3091     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3092                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3093                /*weak*/ false, noreg);
 3094   %}
 3095 
 3096   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<a name="69" id="anc69"></a><span class="line-modified"> 3097     MacroAssembler _masm(&amp;cbuf);</span>
 3098     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3099     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3100                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3101                /*weak*/ false, noreg);
 3102   %}
 3103 
 3104   // auxiliary used for CompareAndSwapX to set result register
 3105   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
<a name="70" id="anc70"></a><span class="line-modified"> 3106     MacroAssembler _masm(&amp;cbuf);</span>
 3107     Register res_reg = as_Register($res$$reg);
 3108     __ cset(res_reg, Assembler::EQ);
 3109   %}
 3110 
 3111   // prefetch encodings
 3112 
 3113   enc_class aarch64_enc_prefetchw(memory mem) %{
<a name="71" id="anc71"></a><span class="line-modified"> 3114     MacroAssembler _masm(&amp;cbuf);</span>
 3115     Register base = as_Register($mem$$base);
 3116     int index = $mem$$index;
 3117     int scale = $mem$$scale;
 3118     int disp = $mem$$disp;
 3119     if (index == -1) {
 3120       __ prfm(Address(base, disp), PSTL1KEEP);
 3121     } else {
 3122       Register index_reg = as_Register(index);
 3123       if (disp == 0) {
 3124         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3125       } else {
 3126         __ lea(rscratch1, Address(base, disp));
 3127 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3128       }
 3129     }
 3130   %}
 3131 
 3132   /// mov envcodings
 3133 
 3134   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
<a name="72" id="anc72"></a><span class="line-modified"> 3135     MacroAssembler _masm(&amp;cbuf);</span>
 3136     u_int32_t con = (u_int32_t)$src$$constant;
 3137     Register dst_reg = as_Register($dst$$reg);
 3138     if (con == 0) {
 3139       __ movw(dst_reg, zr);
 3140     } else {
 3141       __ movw(dst_reg, con);
 3142     }
 3143   %}
 3144 
 3145   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
<a name="73" id="anc73"></a><span class="line-modified"> 3146     MacroAssembler _masm(&amp;cbuf);</span>
 3147     Register dst_reg = as_Register($dst$$reg);
 3148     u_int64_t con = (u_int64_t)$src$$constant;
 3149     if (con == 0) {
 3150       __ mov(dst_reg, zr);
 3151     } else {
 3152       __ mov(dst_reg, con);
 3153     }
 3154   %}
 3155 
 3156   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
<a name="74" id="anc74"></a><span class="line-modified"> 3157     MacroAssembler _masm(&amp;cbuf);</span>
 3158     Register dst_reg = as_Register($dst$$reg);
 3159     address con = (address)$src$$constant;
 3160     if (con == NULL || con == (address)1) {
 3161       ShouldNotReachHere();
 3162     } else {
 3163       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3164       if (rtype == relocInfo::oop_type) {
 3165         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3166       } else if (rtype == relocInfo::metadata_type) {
 3167         __ mov_metadata(dst_reg, (Metadata*)con);
 3168       } else {
 3169         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3170         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3171           __ mov(dst_reg, con);
 3172         } else {
 3173           unsigned long offset;
 3174           __ adrp(dst_reg, con, offset);
 3175           __ add(dst_reg, dst_reg, offset);
 3176         }
 3177       }
 3178     }
 3179   %}
 3180 
 3181   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
<a name="75" id="anc75"></a><span class="line-modified"> 3182     MacroAssembler _masm(&amp;cbuf);</span>
 3183     Register dst_reg = as_Register($dst$$reg);
 3184     __ mov(dst_reg, zr);
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
<a name="76" id="anc76"></a><span class="line-modified"> 3188     MacroAssembler _masm(&amp;cbuf);</span>
 3189     Register dst_reg = as_Register($dst$$reg);
 3190     __ mov(dst_reg, (u_int64_t)1);
 3191   %}
 3192 
 3193   enc_class aarch64_enc_mov_poll_page(iRegP dst, immPollPage src) %{
<a name="77" id="anc77"></a><span class="line-modified"> 3194     MacroAssembler _masm(&amp;cbuf);</span>
 3195     address page = (address)$src$$constant;
 3196     Register dst_reg = as_Register($dst$$reg);
 3197     unsigned long off;
 3198     __ adrp(dst_reg, Address(page, relocInfo::poll_type), off);
 3199     assert(off == 0, &quot;assumed offset == 0&quot;);
 3200   %}
 3201 
 3202   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
<a name="78" id="anc78"></a><span class="line-modified"> 3203     MacroAssembler _masm(&amp;cbuf);</span>
 3204     __ load_byte_map_base($dst$$Register);
 3205   %}
 3206 
 3207   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
<a name="79" id="anc79"></a><span class="line-modified"> 3208     MacroAssembler _masm(&amp;cbuf);</span>
 3209     Register dst_reg = as_Register($dst$$reg);
 3210     address con = (address)$src$$constant;
 3211     if (con == NULL) {
 3212       ShouldNotReachHere();
 3213     } else {
 3214       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3215       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3216       __ set_narrow_oop(dst_reg, (jobject)con);
 3217     }
 3218   %}
 3219 
 3220   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
<a name="80" id="anc80"></a><span class="line-modified"> 3221     MacroAssembler _masm(&amp;cbuf);</span>
 3222     Register dst_reg = as_Register($dst$$reg);
 3223     __ mov(dst_reg, zr);
 3224   %}
 3225 
 3226   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
<a name="81" id="anc81"></a><span class="line-modified"> 3227     MacroAssembler _masm(&amp;cbuf);</span>
 3228     Register dst_reg = as_Register($dst$$reg);
 3229     address con = (address)$src$$constant;
 3230     if (con == NULL) {
 3231       ShouldNotReachHere();
 3232     } else {
 3233       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3234       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3235       __ set_narrow_klass(dst_reg, (Klass *)con);
 3236     }
 3237   %}
 3238 
 3239   // arithmetic encodings
 3240 
 3241   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
<a name="82" id="anc82"></a><span class="line-modified"> 3242     MacroAssembler _masm(&amp;cbuf);</span>
 3243     Register dst_reg = as_Register($dst$$reg);
 3244     Register src_reg = as_Register($src1$$reg);
 3245     int32_t con = (int32_t)$src2$$constant;
 3246     // add has primary == 0, subtract has primary == 1
 3247     if ($primary) { con = -con; }
 3248     if (con &lt; 0) {
 3249       __ subw(dst_reg, src_reg, -con);
 3250     } else {
 3251       __ addw(dst_reg, src_reg, con);
 3252     }
 3253   %}
 3254 
 3255   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
<a name="83" id="anc83"></a><span class="line-modified"> 3256     MacroAssembler _masm(&amp;cbuf);</span>
 3257     Register dst_reg = as_Register($dst$$reg);
 3258     Register src_reg = as_Register($src1$$reg);
 3259     int32_t con = (int32_t)$src2$$constant;
 3260     // add has primary == 0, subtract has primary == 1
 3261     if ($primary) { con = -con; }
 3262     if (con &lt; 0) {
 3263       __ sub(dst_reg, src_reg, -con);
 3264     } else {
 3265       __ add(dst_reg, src_reg, con);
 3266     }
 3267   %}
 3268 
 3269   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
<a name="84" id="anc84"></a><span class="line-modified"> 3270     MacroAssembler _masm(&amp;cbuf);</span>
 3271    Register dst_reg = as_Register($dst$$reg);
 3272    Register src1_reg = as_Register($src1$$reg);
 3273    Register src2_reg = as_Register($src2$$reg);
 3274     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3275   %}
 3276 
 3277   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
<a name="85" id="anc85"></a><span class="line-modified"> 3278     MacroAssembler _masm(&amp;cbuf);</span>
 3279    Register dst_reg = as_Register($dst$$reg);
 3280    Register src1_reg = as_Register($src1$$reg);
 3281    Register src2_reg = as_Register($src2$$reg);
 3282     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3283   %}
 3284 
 3285   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
<a name="86" id="anc86"></a><span class="line-modified"> 3286     MacroAssembler _masm(&amp;cbuf);</span>
 3287    Register dst_reg = as_Register($dst$$reg);
 3288    Register src1_reg = as_Register($src1$$reg);
 3289    Register src2_reg = as_Register($src2$$reg);
 3290     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3291   %}
 3292 
 3293   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
<a name="87" id="anc87"></a><span class="line-modified"> 3294     MacroAssembler _masm(&amp;cbuf);</span>
 3295    Register dst_reg = as_Register($dst$$reg);
 3296    Register src1_reg = as_Register($src1$$reg);
 3297    Register src2_reg = as_Register($src2$$reg);
 3298     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3299   %}
 3300 
 3301   // compare instruction encodings
 3302 
 3303   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
<a name="88" id="anc88"></a><span class="line-modified"> 3304     MacroAssembler _masm(&amp;cbuf);</span>
 3305     Register reg1 = as_Register($src1$$reg);
 3306     Register reg2 = as_Register($src2$$reg);
 3307     __ cmpw(reg1, reg2);
 3308   %}
 3309 
 3310   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
<a name="89" id="anc89"></a><span class="line-modified"> 3311     MacroAssembler _masm(&amp;cbuf);</span>
 3312     Register reg = as_Register($src1$$reg);
 3313     int32_t val = $src2$$constant;
 3314     if (val &gt;= 0) {
 3315       __ subsw(zr, reg, val);
 3316     } else {
 3317       __ addsw(zr, reg, -val);
 3318     }
 3319   %}
 3320 
 3321   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
<a name="90" id="anc90"></a><span class="line-modified"> 3322     MacroAssembler _masm(&amp;cbuf);</span>
 3323     Register reg1 = as_Register($src1$$reg);
 3324     u_int32_t val = (u_int32_t)$src2$$constant;
 3325     __ movw(rscratch1, val);
 3326     __ cmpw(reg1, rscratch1);
 3327   %}
 3328 
 3329   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
<a name="91" id="anc91"></a><span class="line-modified"> 3330     MacroAssembler _masm(&amp;cbuf);</span>
 3331     Register reg1 = as_Register($src1$$reg);
 3332     Register reg2 = as_Register($src2$$reg);
 3333     __ cmp(reg1, reg2);
 3334   %}
 3335 
 3336   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
<a name="92" id="anc92"></a><span class="line-modified"> 3337     MacroAssembler _masm(&amp;cbuf);</span>
 3338     Register reg = as_Register($src1$$reg);
 3339     int64_t val = $src2$$constant;
 3340     if (val &gt;= 0) {
 3341       __ subs(zr, reg, val);
 3342     } else if (val != -val) {
 3343       __ adds(zr, reg, -val);
 3344     } else {
 3345     // aargh, Long.MIN_VALUE is a special case
 3346       __ orr(rscratch1, zr, (u_int64_t)val);
 3347       __ subs(zr, reg, rscratch1);
 3348     }
 3349   %}
 3350 
 3351   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
<a name="93" id="anc93"></a><span class="line-modified"> 3352     MacroAssembler _masm(&amp;cbuf);</span>
 3353     Register reg1 = as_Register($src1$$reg);
 3354     u_int64_t val = (u_int64_t)$src2$$constant;
 3355     __ mov(rscratch1, val);
 3356     __ cmp(reg1, rscratch1);
 3357   %}
 3358 
 3359   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
<a name="94" id="anc94"></a><span class="line-modified"> 3360     MacroAssembler _masm(&amp;cbuf);</span>
 3361     Register reg1 = as_Register($src1$$reg);
 3362     Register reg2 = as_Register($src2$$reg);
 3363     __ cmp(reg1, reg2);
 3364   %}
 3365 
 3366   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
<a name="95" id="anc95"></a><span class="line-modified"> 3367     MacroAssembler _masm(&amp;cbuf);</span>
 3368     Register reg1 = as_Register($src1$$reg);
 3369     Register reg2 = as_Register($src2$$reg);
 3370     __ cmpw(reg1, reg2);
 3371   %}
 3372 
 3373   enc_class aarch64_enc_testp(iRegP src) %{
<a name="96" id="anc96"></a><span class="line-modified"> 3374     MacroAssembler _masm(&amp;cbuf);</span>
 3375     Register reg = as_Register($src$$reg);
 3376     __ cmp(reg, zr);
 3377   %}
 3378 
 3379   enc_class aarch64_enc_testn(iRegN src) %{
<a name="97" id="anc97"></a><span class="line-modified"> 3380     MacroAssembler _masm(&amp;cbuf);</span>
 3381     Register reg = as_Register($src$$reg);
 3382     __ cmpw(reg, zr);
 3383   %}
 3384 
 3385   enc_class aarch64_enc_b(label lbl) %{
<a name="98" id="anc98"></a><span class="line-modified"> 3386     MacroAssembler _masm(&amp;cbuf);</span>
 3387     Label *L = $lbl$$label;
 3388     __ b(*L);
 3389   %}
 3390 
 3391   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
<a name="99" id="anc99"></a><span class="line-modified"> 3392     MacroAssembler _masm(&amp;cbuf);</span>
 3393     Label *L = $lbl$$label;
 3394     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3395   %}
 3396 
 3397   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
<a name="100" id="anc100"></a><span class="line-modified"> 3398     MacroAssembler _masm(&amp;cbuf);</span>
 3399     Label *L = $lbl$$label;
 3400     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3401   %}
 3402 
 3403   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3404   %{
 3405      Register sub_reg = as_Register($sub$$reg);
 3406      Register super_reg = as_Register($super$$reg);
 3407      Register temp_reg = as_Register($temp$$reg);
 3408      Register result_reg = as_Register($result$$reg);
 3409 
 3410      Label miss;
<a name="101" id="anc101"></a><span class="line-modified"> 3411      MacroAssembler _masm(&amp;cbuf);</span>
 3412      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3413                                      NULL, &amp;miss,
 3414                                      /*set_cond_codes:*/ true);
 3415      if ($primary) {
 3416        __ mov(result_reg, zr);
 3417      }
 3418      __ bind(miss);
 3419   %}
 3420 
 3421   enc_class aarch64_enc_java_static_call(method meth) %{
<a name="102" id="anc102"></a><span class="line-modified"> 3422     MacroAssembler _masm(&amp;cbuf);</span>
 3423 
 3424     address addr = (address)$meth$$method;
 3425     address call;
 3426     if (!_method) {
 3427       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3428       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3429     } else {
 3430       int method_index = resolved_method_index(cbuf);
 3431       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3432                                                   : static_call_Relocation::spec(method_index);
 3433       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3434 
 3435       // Emit stub for static call
 3436       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3437       if (stub == NULL) {
 3438         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3439         return;
 3440       }
 3441     }
 3442     if (call == NULL) {
 3443       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3444       return;
 3445     }
 3446   %}
 3447 
 3448   enc_class aarch64_enc_java_dynamic_call(method meth) %{
<a name="103" id="anc103"></a><span class="line-modified"> 3449     MacroAssembler _masm(&amp;cbuf);</span>
 3450     int method_index = resolved_method_index(cbuf);
 3451     address call = __ ic_call((address)$meth$$method, method_index);
 3452     if (call == NULL) {
 3453       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3454       return;
 3455     }
 3456   %}
 3457 
 3458   enc_class aarch64_enc_call_epilog() %{
<a name="104" id="anc104"></a><span class="line-modified"> 3459     MacroAssembler _masm(&amp;cbuf);</span>
 3460     if (VerifyStackAtCalls) {
 3461       // Check that stack depth is unchanged: find majik cookie on stack
 3462       __ call_Unimplemented();
 3463     }
 3464   %}
 3465 
 3466   enc_class aarch64_enc_java_to_runtime(method meth) %{
<a name="105" id="anc105"></a><span class="line-modified"> 3467     MacroAssembler _masm(&amp;cbuf);</span>
 3468 
 3469     // some calls to generated routines (arraycopy code) are scheduled
 3470     // by C2 as runtime calls. if so we can call them using a br (they
 3471     // will be in a reachable segment) otherwise we have to use a blr
 3472     // which loads the absolute address into a register.
 3473     address entry = (address)$meth$$method;
 3474     CodeBlob *cb = CodeCache::find_blob(entry);
 3475     if (cb) {
 3476       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3477       if (call == NULL) {
 3478         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3479         return;
 3480       }
 3481     } else {
 3482       Label retaddr;
 3483       __ adr(rscratch2, retaddr);
 3484       __ lea(rscratch1, RuntimeAddress(entry));
 3485       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3486       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3487       __ blr(rscratch1);
 3488       __ bind(retaddr);
 3489       __ add(sp, sp, 2 * wordSize);
 3490     }
 3491   %}
 3492 
 3493   enc_class aarch64_enc_rethrow() %{
<a name="106" id="anc106"></a><span class="line-modified"> 3494     MacroAssembler _masm(&amp;cbuf);</span>
 3495     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3496   %}
 3497 
 3498   enc_class aarch64_enc_ret() %{
<a name="107" id="anc107"></a><span class="line-modified"> 3499     MacroAssembler _masm(&amp;cbuf);</span>
 3500     __ ret(lr);
 3501   %}
 3502 
 3503   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
<a name="108" id="anc108"></a><span class="line-modified"> 3504     MacroAssembler _masm(&amp;cbuf);</span>
 3505     Register target_reg = as_Register($jump_target$$reg);
 3506     __ br(target_reg);
 3507   %}
 3508 
 3509   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
<a name="109" id="anc109"></a><span class="line-modified"> 3510     MacroAssembler _masm(&amp;cbuf);</span>
 3511     Register target_reg = as_Register($jump_target$$reg);
 3512     // exception oop should be in r0
 3513     // ret addr has been popped into lr
 3514     // callee expects it in r3
 3515     __ mov(r3, lr);
 3516     __ br(target_reg);
 3517   %}
 3518 
 3519   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<a name="110" id="anc110"></a><span class="line-modified"> 3520     MacroAssembler _masm(&amp;cbuf);</span>
 3521     Register oop = as_Register($object$$reg);
 3522     Register box = as_Register($box$$reg);
 3523     Register disp_hdr = as_Register($tmp$$reg);
 3524     Register tmp = as_Register($tmp2$$reg);
 3525     Label cont;
 3526     Label object_has_monitor;
 3527     Label cas_failed;
 3528 
 3529     assert_different_registers(oop, box, tmp, disp_hdr);
 3530 
 3531     // Load markWord from object into displaced_header.
 3532     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3533 
 3534     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3535       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3536     }
 3537 
 3538     // Check for existing monitor
 3539     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3540 
 3541     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3542     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3543 
 3544     // Initialize the box. (Must happen before we update the object mark!)
 3545     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3546 
 3547     // Compare object markWord with an unlocked value (tmp) and if
 3548     // equal exchange the stack address of our box with object markWord.
 3549     // On failure disp_hdr contains the possibly locked markWord.
 3550     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3551                /*release*/ true, /*weak*/ false, disp_hdr);
 3552     __ br(Assembler::EQ, cont);
 3553 
 3554     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3555 
 3556     // If the compare-and-exchange succeeded, then we found an unlocked
 3557     // object, will have now locked it will continue at label cont
 3558 
 3559     __ bind(cas_failed);
 3560     // We did not see an unlocked object so try the fast recursive case.
 3561 
 3562     // Check if the owner is self by comparing the value in the
 3563     // markWord of object (disp_hdr) with the stack pointer.
 3564     __ mov(rscratch1, sp);
 3565     __ sub(disp_hdr, disp_hdr, rscratch1);
 3566     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3567     // If condition is true we are cont and hence we can store 0 as the
 3568     // displaced header in the box, which indicates that it is a recursive lock.
 3569     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3570     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3571 
 3572     __ b(cont);
 3573 
 3574     // Handle existing monitor.
 3575     __ bind(object_has_monitor);
 3576 
 3577     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3578     // otherwise m-&gt;owner may contain a thread or a stack address.
 3579     //
 3580     // Try to CAS m-&gt;owner from NULL to current thread.
 3581     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3582     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3583                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3584 
 3585     // Store a non-null value into the box to avoid looking like a re-entrant
 3586     // lock. The fast-path monitor unlock code checks for
 3587     // markWord::monitor_value so use markWord::unused_mark which has the
 3588     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3589     __ mov(tmp, (address)markWord::unused_mark().value());
 3590     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3591 
 3592     __ bind(cont);
 3593     // flag == EQ indicates success
 3594     // flag == NE indicates failure
 3595   %}
 3596 
 3597   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<a name="111" id="anc111"></a><span class="line-modified"> 3598     MacroAssembler _masm(&amp;cbuf);</span>
 3599     Register oop = as_Register($object$$reg);
 3600     Register box = as_Register($box$$reg);
 3601     Register disp_hdr = as_Register($tmp$$reg);
 3602     Register tmp = as_Register($tmp2$$reg);
 3603     Label cont;
 3604     Label object_has_monitor;
 3605 
 3606     assert_different_registers(oop, box, tmp, disp_hdr);
 3607 
 3608     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3609       __ biased_locking_exit(oop, tmp, cont);
 3610     }
 3611 
 3612     // Find the lock address and load the displaced header from the stack.
 3613     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3614 
 3615     // If the displaced header is 0, we have a recursive unlock.
 3616     __ cmp(disp_hdr, zr);
 3617     __ br(Assembler::EQ, cont);
 3618 
 3619     // Handle existing monitor.
 3620     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3621     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3622 
 3623     // Check if it is still a light weight lock, this is is true if we
 3624     // see the stack address of the basicLock in the markWord of the
 3625     // object.
 3626 
 3627     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3628                /*release*/ true, /*weak*/ false, tmp);
 3629     __ b(cont);
 3630 
 3631     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3632 
 3633     // Handle existing monitor.
 3634     __ bind(object_has_monitor);
 3635     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3636     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3637     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3638     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3639     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3640     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3641     __ cmp(rscratch1, zr); // Sets flags for result
 3642     __ br(Assembler::NE, cont);
 3643 
 3644     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3645     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3646     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3647     __ cmp(rscratch1, zr); // Sets flags for result
 3648     __ cbnz(rscratch1, cont);
 3649     // need a release store here
 3650     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3651     __ stlr(zr, tmp); // set unowned
 3652 
 3653     __ bind(cont);
 3654     // flag == EQ indicates success
 3655     // flag == NE indicates failure
 3656   %}
 3657 
 3658 %}
 3659 
 3660 //----------FRAME--------------------------------------------------------------
 3661 // Definition of frame structure and management information.
 3662 //
 3663 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3664 //                             |   (to get allocators register number
 3665 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3666 //  r   CALLER     |        |
 3667 //  o     |        +--------+      pad to even-align allocators stack-slot
 3668 //  w     V        |  pad0  |        numbers; owned by CALLER
 3669 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3670 //  h     ^        |   in   |  5
 3671 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3672 //  |     |        |        |  3
 3673 //  |     |        +--------+
 3674 //  V     |        | old out|      Empty on Intel, window on Sparc
 3675 //        |    old |preserve|      Must be even aligned.
 3676 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3677 //        |        |   in   |  3   area for Intel ret address
 3678 //     Owned by    |preserve|      Empty on Sparc.
 3679 //       SELF      +--------+
 3680 //        |        |  pad2  |  2   pad to align old SP
 3681 //        |        +--------+  1
 3682 //        |        | locks  |  0
 3683 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3684 //        |        |  pad1  | 11   pad to align new SP
 3685 //        |        +--------+
 3686 //        |        |        | 10
 3687 //        |        | spills |  9   spills
 3688 //        V        |        |  8   (pad0 slot for callee)
 3689 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3690 //        ^        |  out   |  7
 3691 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3692 //     Owned by    +--------+
 3693 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3694 //        |    new |preserve|      Must be even-aligned.
 3695 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3696 //        |        |        |
 3697 //
 3698 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3699 //         known from SELF&#39;s arguments and the Java calling convention.
 3700 //         Region 6-7 is determined per call site.
 3701 // Note 2: If the calling convention leaves holes in the incoming argument
 3702 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3703 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3704 //         incoming area, as the Java calling convention is completely under
 3705 //         the control of the AD file.  Doubles can be sorted and packed to
 3706 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3707 //         varargs C calling conventions.
 3708 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3709 //         even aligned with pad0 as needed.
 3710 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3711 //           (the latter is true on Intel but is it false on AArch64?)
 3712 //         region 6-11 is even aligned; it may be padded out more so that
 3713 //         the region from SP to FP meets the minimum stack alignment.
 3714 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3715 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3716 //         SP meets the minimum alignment.
 3717 
 3718 frame %{
 3719   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3720   stack_direction(TOWARDS_LOW);
 3721 
 3722   // These three registers define part of the calling convention
 3723   // between compiled code and the interpreter.
 3724 
 3725   // Inline Cache Register or methodOop for I2C.
 3726   inline_cache_reg(R12);
 3727 
 3728   // Method Oop Register when calling interpreter.
 3729   interpreter_method_oop_reg(R12);
 3730 
 3731   // Number of stack slots consumed by locking an object
 3732   sync_stack_slots(2);
 3733 
 3734   // Compiled code&#39;s Frame Pointer
 3735   frame_pointer(R31);
 3736 
 3737   // Interpreter stores its frame pointer in a register which is
 3738   // stored to the stack by I2CAdaptors.
 3739   // I2CAdaptors convert from interpreted java to compiled java.
 3740   interpreter_frame_pointer(R29);
 3741 
 3742   // Stack alignment requirement
 3743   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3744 
 3745   // Number of stack slots between incoming argument block and the start of
 3746   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3747   // EPILOG must remove this many slots. aarch64 needs two slots for
 3748   // return address and fp.
 3749   // TODO think this is correct but check
 3750   in_preserve_stack_slots(4);
 3751 
 3752   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3753   // for calls to C.  Supports the var-args backing area for register parms.
 3754   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3755 
 3756   // The after-PROLOG location of the return address.  Location of
 3757   // return address specifies a type (REG or STACK) and a number
 3758   // representing the register number (i.e. - use a register name) or
 3759   // stack slot.
 3760   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3761   // Otherwise, it is above the locks and verification slot and alignment word
 3762   // TODO this may well be correct but need to check why that - 2 is there
 3763   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3764   // which folds in the space used for monitors
 3765   return_addr(STACK - 2 +
 3766               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3767                         Compile::current()-&gt;fixed_slots()),
 3768                        stack_alignment_in_slots()));
 3769 
 3770   // Body of function which returns an integer array locating
 3771   // arguments either in registers or in stack slots.  Passed an array
 3772   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3773   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3774   // arguments for a CALLEE.  Incoming stack arguments are
 3775   // automatically biased by the preserve_stack_slots field above.
 3776 
 3777   calling_convention
 3778   %{
 3779     // No difference between ingoing/outgoing just pass false
 3780     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3781   %}
 3782 
 3783   c_calling_convention
 3784   %{
 3785     // This is obviously always outgoing
 3786     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3787   %}
 3788 
 3789   // Location of compiled Java return values.  Same as C for now.
 3790   return_value
 3791   %{
 3792     // TODO do we allow ideal_reg == Op_RegN???
 3793     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3794            &quot;only return normal values&quot;);
 3795 
 3796     static const int lo[Op_RegL + 1] = { // enum name
 3797       0,                                 // Op_Node
 3798       0,                                 // Op_Set
 3799       R0_num,                            // Op_RegN
 3800       R0_num,                            // Op_RegI
 3801       R0_num,                            // Op_RegP
 3802       V0_num,                            // Op_RegF
 3803       V0_num,                            // Op_RegD
 3804       R0_num                             // Op_RegL
 3805     };
 3806 
 3807     static const int hi[Op_RegL + 1] = { // enum name
 3808       0,                                 // Op_Node
 3809       0,                                 // Op_Set
 3810       OptoReg::Bad,                      // Op_RegN
 3811       OptoReg::Bad,                      // Op_RegI
 3812       R0_H_num,                          // Op_RegP
 3813       OptoReg::Bad,                      // Op_RegF
 3814       V0_H_num,                          // Op_RegD
 3815       R0_H_num                           // Op_RegL
 3816     };
 3817 
 3818     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3819   %}
 3820 %}
 3821 
 3822 //----------ATTRIBUTES---------------------------------------------------------
 3823 //----------Operand Attributes-------------------------------------------------
 3824 op_attrib op_cost(1);        // Required cost attribute
 3825 
 3826 //----------Instruction Attributes---------------------------------------------
 3827 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3828 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3829 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3830                                 // a non-matching short branch variant
 3831                                 // of some long branch?
 3832 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3833                                 // be a power of 2) specifies the
 3834                                 // alignment that some part of the
 3835                                 // instruction (not necessarily the
 3836                                 // start) requires.  If &gt; 1, a
 3837                                 // compute_padding() function must be
 3838                                 // provided for the instruction
 3839 
 3840 //----------OPERANDS-----------------------------------------------------------
 3841 // Operand definitions must precede instruction definitions for correct parsing
 3842 // in the ADLC because operands constitute user defined types which are used in
 3843 // instruction definitions.
 3844 
 3845 //----------Simple Operands----------------------------------------------------
 3846 
 3847 // Integer operands 32 bit
 3848 // 32 bit immediate
 3849 operand immI()
 3850 %{
 3851   match(ConI);
 3852 
 3853   op_cost(0);
 3854   format %{ %}
 3855   interface(CONST_INTER);
 3856 %}
 3857 
 3858 // 32 bit zero
 3859 operand immI0()
 3860 %{
 3861   predicate(n-&gt;get_int() == 0);
 3862   match(ConI);
 3863 
 3864   op_cost(0);
 3865   format %{ %}
 3866   interface(CONST_INTER);
 3867 %}
 3868 
 3869 // 32 bit unit increment
 3870 operand immI_1()
 3871 %{
 3872   predicate(n-&gt;get_int() == 1);
 3873   match(ConI);
 3874 
 3875   op_cost(0);
 3876   format %{ %}
 3877   interface(CONST_INTER);
 3878 %}
 3879 
 3880 // 32 bit unit decrement
 3881 operand immI_M1()
 3882 %{
 3883   predicate(n-&gt;get_int() == -1);
 3884   match(ConI);
 3885 
 3886   op_cost(0);
 3887   format %{ %}
 3888   interface(CONST_INTER);
 3889 %}
 3890 
 3891 // Shift values for add/sub extension shift
 3892 operand immIExt()
 3893 %{
 3894   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3895   match(ConI);
 3896 
 3897   op_cost(0);
 3898   format %{ %}
 3899   interface(CONST_INTER);
 3900 %}
 3901 
 3902 operand immI_le_4()
 3903 %{
 3904   predicate(n-&gt;get_int() &lt;= 4);
 3905   match(ConI);
 3906 
 3907   op_cost(0);
 3908   format %{ %}
 3909   interface(CONST_INTER);
 3910 %}
 3911 
 3912 operand immI_31()
 3913 %{
 3914   predicate(n-&gt;get_int() == 31);
 3915   match(ConI);
 3916 
 3917   op_cost(0);
 3918   format %{ %}
 3919   interface(CONST_INTER);
 3920 %}
 3921 
 3922 operand immI_8()
 3923 %{
 3924   predicate(n-&gt;get_int() == 8);
 3925   match(ConI);
 3926 
 3927   op_cost(0);
 3928   format %{ %}
 3929   interface(CONST_INTER);
 3930 %}
 3931 
 3932 operand immI_16()
 3933 %{
 3934   predicate(n-&gt;get_int() == 16);
 3935   match(ConI);
 3936 
 3937   op_cost(0);
 3938   format %{ %}
 3939   interface(CONST_INTER);
 3940 %}
 3941 
 3942 operand immI_24()
 3943 %{
 3944   predicate(n-&gt;get_int() == 24);
 3945   match(ConI);
 3946 
 3947   op_cost(0);
 3948   format %{ %}
 3949   interface(CONST_INTER);
 3950 %}
 3951 
 3952 operand immI_32()
 3953 %{
 3954   predicate(n-&gt;get_int() == 32);
 3955   match(ConI);
 3956 
 3957   op_cost(0);
 3958   format %{ %}
 3959   interface(CONST_INTER);
 3960 %}
 3961 
 3962 operand immI_48()
 3963 %{
 3964   predicate(n-&gt;get_int() == 48);
 3965   match(ConI);
 3966 
 3967   op_cost(0);
 3968   format %{ %}
 3969   interface(CONST_INTER);
 3970 %}
 3971 
 3972 operand immI_56()
 3973 %{
 3974   predicate(n-&gt;get_int() == 56);
 3975   match(ConI);
 3976 
 3977   op_cost(0);
 3978   format %{ %}
 3979   interface(CONST_INTER);
 3980 %}
 3981 
 3982 operand immI_63()
 3983 %{
 3984   predicate(n-&gt;get_int() == 63);
 3985   match(ConI);
 3986 
 3987   op_cost(0);
 3988   format %{ %}
 3989   interface(CONST_INTER);
 3990 %}
 3991 
 3992 operand immI_64()
 3993 %{
 3994   predicate(n-&gt;get_int() == 64);
 3995   match(ConI);
 3996 
 3997   op_cost(0);
 3998   format %{ %}
 3999   interface(CONST_INTER);
 4000 %}
 4001 
 4002 operand immI_255()
 4003 %{
 4004   predicate(n-&gt;get_int() == 255);
 4005   match(ConI);
 4006 
 4007   op_cost(0);
 4008   format %{ %}
 4009   interface(CONST_INTER);
 4010 %}
 4011 
 4012 operand immI_65535()
 4013 %{
 4014   predicate(n-&gt;get_int() == 65535);
 4015   match(ConI);
 4016 
 4017   op_cost(0);
 4018   format %{ %}
 4019   interface(CONST_INTER);
 4020 %}
 4021 
 4022 operand immL_255()
 4023 %{
 4024   predicate(n-&gt;get_long() == 255L);
 4025   match(ConL);
 4026 
 4027   op_cost(0);
 4028   format %{ %}
 4029   interface(CONST_INTER);
 4030 %}
 4031 
 4032 operand immL_65535()
 4033 %{
 4034   predicate(n-&gt;get_long() == 65535L);
 4035   match(ConL);
 4036 
 4037   op_cost(0);
 4038   format %{ %}
 4039   interface(CONST_INTER);
 4040 %}
 4041 
 4042 operand immL_4294967295()
 4043 %{
 4044   predicate(n-&gt;get_long() == 4294967295L);
 4045   match(ConL);
 4046 
 4047   op_cost(0);
 4048   format %{ %}
 4049   interface(CONST_INTER);
 4050 %}
 4051 
 4052 operand immL_bitmask()
 4053 %{
 4054   predicate((n-&gt;get_long() != 0)
 4055             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4056             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4057   match(ConL);
 4058 
 4059   op_cost(0);
 4060   format %{ %}
 4061   interface(CONST_INTER);
 4062 %}
 4063 
 4064 operand immI_bitmask()
 4065 %{
 4066   predicate((n-&gt;get_int() != 0)
 4067             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4068             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4069   match(ConI);
 4070 
 4071   op_cost(0);
 4072   format %{ %}
 4073   interface(CONST_INTER);
 4074 %}
 4075 
 4076 // Scale values for scaled offset addressing modes (up to long but not quad)
 4077 operand immIScale()
 4078 %{
 4079   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4080   match(ConI);
 4081 
 4082   op_cost(0);
 4083   format %{ %}
 4084   interface(CONST_INTER);
 4085 %}
 4086 
 4087 // 26 bit signed offset -- for pc-relative branches
 4088 operand immI26()
 4089 %{
 4090   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4091   match(ConI);
 4092 
 4093   op_cost(0);
 4094   format %{ %}
 4095   interface(CONST_INTER);
 4096 %}
 4097 
 4098 // 19 bit signed offset -- for pc-relative loads
 4099 operand immI19()
 4100 %{
 4101   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4102   match(ConI);
 4103 
 4104   op_cost(0);
 4105   format %{ %}
 4106   interface(CONST_INTER);
 4107 %}
 4108 
 4109 // 12 bit unsigned offset -- for base plus immediate loads
 4110 operand immIU12()
 4111 %{
 4112   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4113   match(ConI);
 4114 
 4115   op_cost(0);
 4116   format %{ %}
 4117   interface(CONST_INTER);
 4118 %}
 4119 
 4120 operand immLU12()
 4121 %{
 4122   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4123   match(ConL);
 4124 
 4125   op_cost(0);
 4126   format %{ %}
 4127   interface(CONST_INTER);
 4128 %}
 4129 
 4130 // Offset for scaled or unscaled immediate loads and stores
 4131 operand immIOffset()
 4132 %{
 4133   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4134   match(ConI);
 4135 
 4136   op_cost(0);
 4137   format %{ %}
 4138   interface(CONST_INTER);
 4139 %}
 4140 
 4141 operand immIOffset1()
 4142 %{
 4143   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4144   match(ConI);
 4145 
 4146   op_cost(0);
 4147   format %{ %}
 4148   interface(CONST_INTER);
 4149 %}
 4150 
 4151 operand immIOffset2()
 4152 %{
 4153   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4154   match(ConI);
 4155 
 4156   op_cost(0);
 4157   format %{ %}
 4158   interface(CONST_INTER);
 4159 %}
 4160 
 4161 operand immIOffset4()
 4162 %{
 4163   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4164   match(ConI);
 4165 
 4166   op_cost(0);
 4167   format %{ %}
 4168   interface(CONST_INTER);
 4169 %}
 4170 
 4171 operand immIOffset8()
 4172 %{
 4173   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4174   match(ConI);
 4175 
 4176   op_cost(0);
 4177   format %{ %}
 4178   interface(CONST_INTER);
 4179 %}
 4180 
 4181 operand immIOffset16()
 4182 %{
 4183   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4184   match(ConI);
 4185 
 4186   op_cost(0);
 4187   format %{ %}
 4188   interface(CONST_INTER);
 4189 %}
 4190 
 4191 operand immLoffset()
 4192 %{
 4193   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4194   match(ConL);
 4195 
 4196   op_cost(0);
 4197   format %{ %}
 4198   interface(CONST_INTER);
 4199 %}
 4200 
 4201 operand immLoffset1()
 4202 %{
 4203   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4204   match(ConL);
 4205 
 4206   op_cost(0);
 4207   format %{ %}
 4208   interface(CONST_INTER);
 4209 %}
 4210 
 4211 operand immLoffset2()
 4212 %{
 4213   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4214   match(ConL);
 4215 
 4216   op_cost(0);
 4217   format %{ %}
 4218   interface(CONST_INTER);
 4219 %}
 4220 
 4221 operand immLoffset4()
 4222 %{
 4223   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4224   match(ConL);
 4225 
 4226   op_cost(0);
 4227   format %{ %}
 4228   interface(CONST_INTER);
 4229 %}
 4230 
 4231 operand immLoffset8()
 4232 %{
 4233   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4234   match(ConL);
 4235 
 4236   op_cost(0);
 4237   format %{ %}
 4238   interface(CONST_INTER);
 4239 %}
 4240 
 4241 operand immLoffset16()
 4242 %{
 4243   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4244   match(ConL);
 4245 
 4246   op_cost(0);
 4247   format %{ %}
 4248   interface(CONST_INTER);
 4249 %}
 4250 
 4251 // 32 bit integer valid for add sub immediate
 4252 operand immIAddSub()
 4253 %{
 4254   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4255   match(ConI);
 4256   op_cost(0);
 4257   format %{ %}
 4258   interface(CONST_INTER);
 4259 %}
 4260 
 4261 // 32 bit unsigned integer valid for logical immediate
 4262 // TODO -- check this is right when e.g the mask is 0x80000000
 4263 operand immILog()
 4264 %{
 4265   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4266   match(ConI);
 4267 
 4268   op_cost(0);
 4269   format %{ %}
 4270   interface(CONST_INTER);
 4271 %}
 4272 
 4273 // Integer operands 64 bit
 4274 // 64 bit immediate
 4275 operand immL()
 4276 %{
 4277   match(ConL);
 4278 
 4279   op_cost(0);
 4280   format %{ %}
 4281   interface(CONST_INTER);
 4282 %}
 4283 
 4284 // 64 bit zero
 4285 operand immL0()
 4286 %{
 4287   predicate(n-&gt;get_long() == 0);
 4288   match(ConL);
 4289 
 4290   op_cost(0);
 4291   format %{ %}
 4292   interface(CONST_INTER);
 4293 %}
 4294 
 4295 // 64 bit unit increment
 4296 operand immL_1()
 4297 %{
 4298   predicate(n-&gt;get_long() == 1);
 4299   match(ConL);
 4300 
 4301   op_cost(0);
 4302   format %{ %}
 4303   interface(CONST_INTER);
 4304 %}
 4305 
 4306 // 64 bit unit decrement
 4307 operand immL_M1()
 4308 %{
 4309   predicate(n-&gt;get_long() == -1);
 4310   match(ConL);
 4311 
 4312   op_cost(0);
 4313   format %{ %}
 4314   interface(CONST_INTER);
 4315 %}
 4316 
 4317 // 32 bit offset of pc in thread anchor
 4318 
 4319 operand immL_pc_off()
 4320 %{
 4321   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4322                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4323   match(ConL);
 4324 
 4325   op_cost(0);
 4326   format %{ %}
 4327   interface(CONST_INTER);
 4328 %}
 4329 
 4330 // 64 bit integer valid for add sub immediate
 4331 operand immLAddSub()
 4332 %{
 4333   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4334   match(ConL);
 4335   op_cost(0);
 4336   format %{ %}
 4337   interface(CONST_INTER);
 4338 %}
 4339 
 4340 // 64 bit integer valid for logical immediate
 4341 operand immLLog()
 4342 %{
 4343   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4344   match(ConL);
 4345   op_cost(0);
 4346   format %{ %}
 4347   interface(CONST_INTER);
 4348 %}
 4349 
 4350 // Long Immediate: low 32-bit mask
 4351 operand immL_32bits()
 4352 %{
 4353   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4354   match(ConL);
 4355   op_cost(0);
 4356   format %{ %}
 4357   interface(CONST_INTER);
 4358 %}
 4359 
 4360 // Pointer operands
 4361 // Pointer Immediate
 4362 operand immP()
 4363 %{
 4364   match(ConP);
 4365 
 4366   op_cost(0);
 4367   format %{ %}
 4368   interface(CONST_INTER);
 4369 %}
 4370 
 4371 // NULL Pointer Immediate
 4372 operand immP0()
 4373 %{
 4374   predicate(n-&gt;get_ptr() == 0);
 4375   match(ConP);
 4376 
 4377   op_cost(0);
 4378   format %{ %}
 4379   interface(CONST_INTER);
 4380 %}
 4381 
 4382 // Pointer Immediate One
 4383 // this is used in object initialization (initial object header)
 4384 operand immP_1()
 4385 %{
 4386   predicate(n-&gt;get_ptr() == 1);
 4387   match(ConP);
 4388 
 4389   op_cost(0);
 4390   format %{ %}
 4391   interface(CONST_INTER);
 4392 %}
 4393 
 4394 // Polling Page Pointer Immediate
 4395 operand immPollPage()
 4396 %{
 4397   predicate((address)n-&gt;get_ptr() == os::get_polling_page());
 4398   match(ConP);
 4399 
 4400   op_cost(0);
 4401   format %{ %}
 4402   interface(CONST_INTER);
 4403 %}
 4404 
 4405 // Card Table Byte Map Base
 4406 operand immByteMapBase()
 4407 %{
 4408   // Get base of card map
 4409   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4410             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4411   match(ConP);
 4412 
 4413   op_cost(0);
 4414   format %{ %}
 4415   interface(CONST_INTER);
 4416 %}
 4417 
 4418 // Pointer Immediate Minus One
 4419 // this is used when we want to write the current PC to the thread anchor
 4420 operand immP_M1()
 4421 %{
 4422   predicate(n-&gt;get_ptr() == -1);
 4423   match(ConP);
 4424 
 4425   op_cost(0);
 4426   format %{ %}
 4427   interface(CONST_INTER);
 4428 %}
 4429 
 4430 // Pointer Immediate Minus Two
 4431 // this is used when we want to write the current PC to the thread anchor
 4432 operand immP_M2()
 4433 %{
 4434   predicate(n-&gt;get_ptr() == -2);
 4435   match(ConP);
 4436 
 4437   op_cost(0);
 4438   format %{ %}
 4439   interface(CONST_INTER);
 4440 %}
 4441 
 4442 // Float and Double operands
 4443 // Double Immediate
 4444 operand immD()
 4445 %{
 4446   match(ConD);
 4447   op_cost(0);
 4448   format %{ %}
 4449   interface(CONST_INTER);
 4450 %}
 4451 
 4452 // Double Immediate: +0.0d
 4453 operand immD0()
 4454 %{
 4455   predicate(jlong_cast(n-&gt;getd()) == 0);
 4456   match(ConD);
 4457 
 4458   op_cost(0);
 4459   format %{ %}
 4460   interface(CONST_INTER);
 4461 %}
 4462 
 4463 // constant &#39;double +0.0&#39;.
 4464 operand immDPacked()
 4465 %{
 4466   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4467   match(ConD);
 4468   op_cost(0);
 4469   format %{ %}
 4470   interface(CONST_INTER);
 4471 %}
 4472 
 4473 // Float Immediate
 4474 operand immF()
 4475 %{
 4476   match(ConF);
 4477   op_cost(0);
 4478   format %{ %}
 4479   interface(CONST_INTER);
 4480 %}
 4481 
 4482 // Float Immediate: +0.0f.
 4483 operand immF0()
 4484 %{
 4485   predicate(jint_cast(n-&gt;getf()) == 0);
 4486   match(ConF);
 4487 
 4488   op_cost(0);
 4489   format %{ %}
 4490   interface(CONST_INTER);
 4491 %}
 4492 
 4493 //
 4494 operand immFPacked()
 4495 %{
 4496   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4497   match(ConF);
 4498   op_cost(0);
 4499   format %{ %}
 4500   interface(CONST_INTER);
 4501 %}
 4502 
 4503 // Narrow pointer operands
 4504 // Narrow Pointer Immediate
 4505 operand immN()
 4506 %{
 4507   match(ConN);
 4508 
 4509   op_cost(0);
 4510   format %{ %}
 4511   interface(CONST_INTER);
 4512 %}
 4513 
 4514 // Narrow NULL Pointer Immediate
 4515 operand immN0()
 4516 %{
 4517   predicate(n-&gt;get_narrowcon() == 0);
 4518   match(ConN);
 4519 
 4520   op_cost(0);
 4521   format %{ %}
 4522   interface(CONST_INTER);
 4523 %}
 4524 
 4525 operand immNKlass()
 4526 %{
 4527   match(ConNKlass);
 4528 
 4529   op_cost(0);
 4530   format %{ %}
 4531   interface(CONST_INTER);
 4532 %}
 4533 
 4534 // Integer 32 bit Register Operands
 4535 // Integer 32 bitRegister (excludes SP)
 4536 operand iRegI()
 4537 %{
 4538   constraint(ALLOC_IN_RC(any_reg32));
 4539   match(RegI);
 4540   match(iRegINoSp);
 4541   op_cost(0);
 4542   format %{ %}
 4543   interface(REG_INTER);
 4544 %}
 4545 
 4546 // Integer 32 bit Register not Special
 4547 operand iRegINoSp()
 4548 %{
 4549   constraint(ALLOC_IN_RC(no_special_reg32));
 4550   match(RegI);
 4551   op_cost(0);
 4552   format %{ %}
 4553   interface(REG_INTER);
 4554 %}
 4555 
 4556 // Integer 64 bit Register Operands
 4557 // Integer 64 bit Register (includes SP)
 4558 operand iRegL()
 4559 %{
 4560   constraint(ALLOC_IN_RC(any_reg));
 4561   match(RegL);
 4562   match(iRegLNoSp);
 4563   op_cost(0);
 4564   format %{ %}
 4565   interface(REG_INTER);
 4566 %}
 4567 
 4568 // Integer 64 bit Register not Special
 4569 operand iRegLNoSp()
 4570 %{
 4571   constraint(ALLOC_IN_RC(no_special_reg));
 4572   match(RegL);
 4573   match(iRegL_R0);
 4574   format %{ %}
 4575   interface(REG_INTER);
 4576 %}
 4577 
 4578 // Pointer Register Operands
 4579 // Pointer Register
 4580 operand iRegP()
 4581 %{
 4582   constraint(ALLOC_IN_RC(ptr_reg));
 4583   match(RegP);
 4584   match(iRegPNoSp);
 4585   match(iRegP_R0);
 4586   //match(iRegP_R2);
 4587   //match(iRegP_R4);
 4588   //match(iRegP_R5);
 4589   match(thread_RegP);
 4590   op_cost(0);
 4591   format %{ %}
 4592   interface(REG_INTER);
 4593 %}
 4594 
 4595 // Pointer 64 bit Register not Special
 4596 operand iRegPNoSp()
 4597 %{
 4598   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4599   match(RegP);
 4600   // match(iRegP);
 4601   // match(iRegP_R0);
 4602   // match(iRegP_R2);
 4603   // match(iRegP_R4);
 4604   // match(iRegP_R5);
 4605   // match(thread_RegP);
 4606   op_cost(0);
 4607   format %{ %}
 4608   interface(REG_INTER);
 4609 %}
 4610 
 4611 // Pointer 64 bit Register R0 only
 4612 operand iRegP_R0()
 4613 %{
 4614   constraint(ALLOC_IN_RC(r0_reg));
 4615   match(RegP);
 4616   // match(iRegP);
 4617   match(iRegPNoSp);
 4618   op_cost(0);
 4619   format %{ %}
 4620   interface(REG_INTER);
 4621 %}
 4622 
 4623 // Pointer 64 bit Register R1 only
 4624 operand iRegP_R1()
 4625 %{
 4626   constraint(ALLOC_IN_RC(r1_reg));
 4627   match(RegP);
 4628   // match(iRegP);
 4629   match(iRegPNoSp);
 4630   op_cost(0);
 4631   format %{ %}
 4632   interface(REG_INTER);
 4633 %}
 4634 
 4635 // Pointer 64 bit Register R2 only
 4636 operand iRegP_R2()
 4637 %{
 4638   constraint(ALLOC_IN_RC(r2_reg));
 4639   match(RegP);
 4640   // match(iRegP);
 4641   match(iRegPNoSp);
 4642   op_cost(0);
 4643   format %{ %}
 4644   interface(REG_INTER);
 4645 %}
 4646 
 4647 // Pointer 64 bit Register R3 only
 4648 operand iRegP_R3()
 4649 %{
 4650   constraint(ALLOC_IN_RC(r3_reg));
 4651   match(RegP);
 4652   // match(iRegP);
 4653   match(iRegPNoSp);
 4654   op_cost(0);
 4655   format %{ %}
 4656   interface(REG_INTER);
 4657 %}
 4658 
 4659 // Pointer 64 bit Register R4 only
 4660 operand iRegP_R4()
 4661 %{
 4662   constraint(ALLOC_IN_RC(r4_reg));
 4663   match(RegP);
 4664   // match(iRegP);
 4665   match(iRegPNoSp);
 4666   op_cost(0);
 4667   format %{ %}
 4668   interface(REG_INTER);
 4669 %}
 4670 
 4671 // Pointer 64 bit Register R5 only
 4672 operand iRegP_R5()
 4673 %{
 4674   constraint(ALLOC_IN_RC(r5_reg));
 4675   match(RegP);
 4676   // match(iRegP);
 4677   match(iRegPNoSp);
 4678   op_cost(0);
 4679   format %{ %}
 4680   interface(REG_INTER);
 4681 %}
 4682 
 4683 // Pointer 64 bit Register R10 only
 4684 operand iRegP_R10()
 4685 %{
 4686   constraint(ALLOC_IN_RC(r10_reg));
 4687   match(RegP);
 4688   // match(iRegP);
 4689   match(iRegPNoSp);
 4690   op_cost(0);
 4691   format %{ %}
 4692   interface(REG_INTER);
 4693 %}
 4694 
 4695 // Long 64 bit Register R0 only
 4696 operand iRegL_R0()
 4697 %{
 4698   constraint(ALLOC_IN_RC(r0_reg));
 4699   match(RegL);
 4700   match(iRegLNoSp);
 4701   op_cost(0);
 4702   format %{ %}
 4703   interface(REG_INTER);
 4704 %}
 4705 
 4706 // Long 64 bit Register R2 only
 4707 operand iRegL_R2()
 4708 %{
 4709   constraint(ALLOC_IN_RC(r2_reg));
 4710   match(RegL);
 4711   match(iRegLNoSp);
 4712   op_cost(0);
 4713   format %{ %}
 4714   interface(REG_INTER);
 4715 %}
 4716 
 4717 // Long 64 bit Register R3 only
 4718 operand iRegL_R3()
 4719 %{
 4720   constraint(ALLOC_IN_RC(r3_reg));
 4721   match(RegL);
 4722   match(iRegLNoSp);
 4723   op_cost(0);
 4724   format %{ %}
 4725   interface(REG_INTER);
 4726 %}
 4727 
 4728 // Long 64 bit Register R11 only
 4729 operand iRegL_R11()
 4730 %{
 4731   constraint(ALLOC_IN_RC(r11_reg));
 4732   match(RegL);
 4733   match(iRegLNoSp);
 4734   op_cost(0);
 4735   format %{ %}
 4736   interface(REG_INTER);
 4737 %}
 4738 
 4739 // Pointer 64 bit Register FP only
 4740 operand iRegP_FP()
 4741 %{
 4742   constraint(ALLOC_IN_RC(fp_reg));
 4743   match(RegP);
 4744   // match(iRegP);
 4745   op_cost(0);
 4746   format %{ %}
 4747   interface(REG_INTER);
 4748 %}
 4749 
 4750 // Register R0 only
 4751 operand iRegI_R0()
 4752 %{
 4753   constraint(ALLOC_IN_RC(int_r0_reg));
 4754   match(RegI);
 4755   match(iRegINoSp);
 4756   op_cost(0);
 4757   format %{ %}
 4758   interface(REG_INTER);
 4759 %}
 4760 
 4761 // Register R2 only
 4762 operand iRegI_R2()
 4763 %{
 4764   constraint(ALLOC_IN_RC(int_r2_reg));
 4765   match(RegI);
 4766   match(iRegINoSp);
 4767   op_cost(0);
 4768   format %{ %}
 4769   interface(REG_INTER);
 4770 %}
 4771 
 4772 // Register R3 only
 4773 operand iRegI_R3()
 4774 %{
 4775   constraint(ALLOC_IN_RC(int_r3_reg));
 4776   match(RegI);
 4777   match(iRegINoSp);
 4778   op_cost(0);
 4779   format %{ %}
 4780   interface(REG_INTER);
 4781 %}
 4782 
 4783 
 4784 // Register R4 only
 4785 operand iRegI_R4()
 4786 %{
 4787   constraint(ALLOC_IN_RC(int_r4_reg));
 4788   match(RegI);
 4789   match(iRegINoSp);
 4790   op_cost(0);
 4791   format %{ %}
 4792   interface(REG_INTER);
 4793 %}
 4794 
 4795 
 4796 // Pointer Register Operands
 4797 // Narrow Pointer Register
 4798 operand iRegN()
 4799 %{
 4800   constraint(ALLOC_IN_RC(any_reg32));
 4801   match(RegN);
 4802   match(iRegNNoSp);
 4803   op_cost(0);
 4804   format %{ %}
 4805   interface(REG_INTER);
 4806 %}
 4807 
 4808 operand iRegN_R0()
 4809 %{
 4810   constraint(ALLOC_IN_RC(r0_reg));
 4811   match(iRegN);
 4812   op_cost(0);
 4813   format %{ %}
 4814   interface(REG_INTER);
 4815 %}
 4816 
 4817 operand iRegN_R2()
 4818 %{
 4819   constraint(ALLOC_IN_RC(r2_reg));
 4820   match(iRegN);
 4821   op_cost(0);
 4822   format %{ %}
 4823   interface(REG_INTER);
 4824 %}
 4825 
 4826 operand iRegN_R3()
 4827 %{
 4828   constraint(ALLOC_IN_RC(r3_reg));
 4829   match(iRegN);
 4830   op_cost(0);
 4831   format %{ %}
 4832   interface(REG_INTER);
 4833 %}
 4834 
 4835 // Integer 64 bit Register not Special
 4836 operand iRegNNoSp()
 4837 %{
 4838   constraint(ALLOC_IN_RC(no_special_reg32));
 4839   match(RegN);
 4840   op_cost(0);
 4841   format %{ %}
 4842   interface(REG_INTER);
 4843 %}
 4844 
 4845 // heap base register -- used for encoding immN0
 4846 
 4847 operand iRegIHeapbase()
 4848 %{
 4849   constraint(ALLOC_IN_RC(heapbase_reg));
 4850   match(RegI);
 4851   op_cost(0);
 4852   format %{ %}
 4853   interface(REG_INTER);
 4854 %}
 4855 
 4856 // Float Register
 4857 // Float register operands
 4858 operand vRegF()
 4859 %{
 4860   constraint(ALLOC_IN_RC(float_reg));
 4861   match(RegF);
 4862 
 4863   op_cost(0);
 4864   format %{ %}
 4865   interface(REG_INTER);
 4866 %}
 4867 
 4868 // Double Register
 4869 // Double register operands
 4870 operand vRegD()
 4871 %{
 4872   constraint(ALLOC_IN_RC(double_reg));
 4873   match(RegD);
 4874 
 4875   op_cost(0);
 4876   format %{ %}
 4877   interface(REG_INTER);
 4878 %}
 4879 
 4880 operand vecD()
 4881 %{
 4882   constraint(ALLOC_IN_RC(vectord_reg));
 4883   match(VecD);
 4884 
 4885   op_cost(0);
 4886   format %{ %}
 4887   interface(REG_INTER);
 4888 %}
 4889 
 4890 operand vecX()
 4891 %{
 4892   constraint(ALLOC_IN_RC(vectorx_reg));
 4893   match(VecX);
 4894 
 4895   op_cost(0);
 4896   format %{ %}
 4897   interface(REG_INTER);
 4898 %}
 4899 
 4900 operand vRegD_V0()
 4901 %{
 4902   constraint(ALLOC_IN_RC(v0_reg));
 4903   match(RegD);
 4904   op_cost(0);
 4905   format %{ %}
 4906   interface(REG_INTER);
 4907 %}
 4908 
 4909 operand vRegD_V1()
 4910 %{
 4911   constraint(ALLOC_IN_RC(v1_reg));
 4912   match(RegD);
 4913   op_cost(0);
 4914   format %{ %}
 4915   interface(REG_INTER);
 4916 %}
 4917 
 4918 operand vRegD_V2()
 4919 %{
 4920   constraint(ALLOC_IN_RC(v2_reg));
 4921   match(RegD);
 4922   op_cost(0);
 4923   format %{ %}
 4924   interface(REG_INTER);
 4925 %}
 4926 
 4927 operand vRegD_V3()
 4928 %{
 4929   constraint(ALLOC_IN_RC(v3_reg));
 4930   match(RegD);
 4931   op_cost(0);
 4932   format %{ %}
 4933   interface(REG_INTER);
 4934 %}
 4935 
 4936 operand vRegD_V4()
 4937 %{
 4938   constraint(ALLOC_IN_RC(v4_reg));
 4939   match(RegD);
 4940   op_cost(0);
 4941   format %{ %}
 4942   interface(REG_INTER);
 4943 %}
 4944 
 4945 operand vRegD_V5()
 4946 %{
 4947   constraint(ALLOC_IN_RC(v5_reg));
 4948   match(RegD);
 4949   op_cost(0);
 4950   format %{ %}
 4951   interface(REG_INTER);
 4952 %}
 4953 
 4954 operand vRegD_V6()
 4955 %{
 4956   constraint(ALLOC_IN_RC(v6_reg));
 4957   match(RegD);
 4958   op_cost(0);
 4959   format %{ %}
 4960   interface(REG_INTER);
 4961 %}
 4962 
 4963 operand vRegD_V7()
 4964 %{
 4965   constraint(ALLOC_IN_RC(v7_reg));
 4966   match(RegD);
 4967   op_cost(0);
 4968   format %{ %}
 4969   interface(REG_INTER);
 4970 %}
 4971 
 4972 operand vRegD_V8()
 4973 %{
 4974   constraint(ALLOC_IN_RC(v8_reg));
 4975   match(RegD);
 4976   op_cost(0);
 4977   format %{ %}
 4978   interface(REG_INTER);
 4979 %}
 4980 
 4981 operand vRegD_V9()
 4982 %{
 4983   constraint(ALLOC_IN_RC(v9_reg));
 4984   match(RegD);
 4985   op_cost(0);
 4986   format %{ %}
 4987   interface(REG_INTER);
 4988 %}
 4989 
 4990 operand vRegD_V10()
 4991 %{
 4992   constraint(ALLOC_IN_RC(v10_reg));
 4993   match(RegD);
 4994   op_cost(0);
 4995   format %{ %}
 4996   interface(REG_INTER);
 4997 %}
 4998 
 4999 operand vRegD_V11()
 5000 %{
 5001   constraint(ALLOC_IN_RC(v11_reg));
 5002   match(RegD);
 5003   op_cost(0);
 5004   format %{ %}
 5005   interface(REG_INTER);
 5006 %}
 5007 
 5008 operand vRegD_V12()
 5009 %{
 5010   constraint(ALLOC_IN_RC(v12_reg));
 5011   match(RegD);
 5012   op_cost(0);
 5013   format %{ %}
 5014   interface(REG_INTER);
 5015 %}
 5016 
 5017 operand vRegD_V13()
 5018 %{
 5019   constraint(ALLOC_IN_RC(v13_reg));
 5020   match(RegD);
 5021   op_cost(0);
 5022   format %{ %}
 5023   interface(REG_INTER);
 5024 %}
 5025 
 5026 operand vRegD_V14()
 5027 %{
 5028   constraint(ALLOC_IN_RC(v14_reg));
 5029   match(RegD);
 5030   op_cost(0);
 5031   format %{ %}
 5032   interface(REG_INTER);
 5033 %}
 5034 
 5035 operand vRegD_V15()
 5036 %{
 5037   constraint(ALLOC_IN_RC(v15_reg));
 5038   match(RegD);
 5039   op_cost(0);
 5040   format %{ %}
 5041   interface(REG_INTER);
 5042 %}
 5043 
 5044 operand vRegD_V16()
 5045 %{
 5046   constraint(ALLOC_IN_RC(v16_reg));
 5047   match(RegD);
 5048   op_cost(0);
 5049   format %{ %}
 5050   interface(REG_INTER);
 5051 %}
 5052 
 5053 operand vRegD_V17()
 5054 %{
 5055   constraint(ALLOC_IN_RC(v17_reg));
 5056   match(RegD);
 5057   op_cost(0);
 5058   format %{ %}
 5059   interface(REG_INTER);
 5060 %}
 5061 
 5062 operand vRegD_V18()
 5063 %{
 5064   constraint(ALLOC_IN_RC(v18_reg));
 5065   match(RegD);
 5066   op_cost(0);
 5067   format %{ %}
 5068   interface(REG_INTER);
 5069 %}
 5070 
 5071 operand vRegD_V19()
 5072 %{
 5073   constraint(ALLOC_IN_RC(v19_reg));
 5074   match(RegD);
 5075   op_cost(0);
 5076   format %{ %}
 5077   interface(REG_INTER);
 5078 %}
 5079 
 5080 operand vRegD_V20()
 5081 %{
 5082   constraint(ALLOC_IN_RC(v20_reg));
 5083   match(RegD);
 5084   op_cost(0);
 5085   format %{ %}
 5086   interface(REG_INTER);
 5087 %}
 5088 
 5089 operand vRegD_V21()
 5090 %{
 5091   constraint(ALLOC_IN_RC(v21_reg));
 5092   match(RegD);
 5093   op_cost(0);
 5094   format %{ %}
 5095   interface(REG_INTER);
 5096 %}
 5097 
 5098 operand vRegD_V22()
 5099 %{
 5100   constraint(ALLOC_IN_RC(v22_reg));
 5101   match(RegD);
 5102   op_cost(0);
 5103   format %{ %}
 5104   interface(REG_INTER);
 5105 %}
 5106 
 5107 operand vRegD_V23()
 5108 %{
 5109   constraint(ALLOC_IN_RC(v23_reg));
 5110   match(RegD);
 5111   op_cost(0);
 5112   format %{ %}
 5113   interface(REG_INTER);
 5114 %}
 5115 
 5116 operand vRegD_V24()
 5117 %{
 5118   constraint(ALLOC_IN_RC(v24_reg));
 5119   match(RegD);
 5120   op_cost(0);
 5121   format %{ %}
 5122   interface(REG_INTER);
 5123 %}
 5124 
 5125 operand vRegD_V25()
 5126 %{
 5127   constraint(ALLOC_IN_RC(v25_reg));
 5128   match(RegD);
 5129   op_cost(0);
 5130   format %{ %}
 5131   interface(REG_INTER);
 5132 %}
 5133 
 5134 operand vRegD_V26()
 5135 %{
 5136   constraint(ALLOC_IN_RC(v26_reg));
 5137   match(RegD);
 5138   op_cost(0);
 5139   format %{ %}
 5140   interface(REG_INTER);
 5141 %}
 5142 
 5143 operand vRegD_V27()
 5144 %{
 5145   constraint(ALLOC_IN_RC(v27_reg));
 5146   match(RegD);
 5147   op_cost(0);
 5148   format %{ %}
 5149   interface(REG_INTER);
 5150 %}
 5151 
 5152 operand vRegD_V28()
 5153 %{
 5154   constraint(ALLOC_IN_RC(v28_reg));
 5155   match(RegD);
 5156   op_cost(0);
 5157   format %{ %}
 5158   interface(REG_INTER);
 5159 %}
 5160 
 5161 operand vRegD_V29()
 5162 %{
 5163   constraint(ALLOC_IN_RC(v29_reg));
 5164   match(RegD);
 5165   op_cost(0);
 5166   format %{ %}
 5167   interface(REG_INTER);
 5168 %}
 5169 
 5170 operand vRegD_V30()
 5171 %{
 5172   constraint(ALLOC_IN_RC(v30_reg));
 5173   match(RegD);
 5174   op_cost(0);
 5175   format %{ %}
 5176   interface(REG_INTER);
 5177 %}
 5178 
 5179 operand vRegD_V31()
 5180 %{
 5181   constraint(ALLOC_IN_RC(v31_reg));
 5182   match(RegD);
 5183   op_cost(0);
 5184   format %{ %}
 5185   interface(REG_INTER);
 5186 %}
 5187 
 5188 // Flags register, used as output of signed compare instructions
 5189 
 5190 // note that on AArch64 we also use this register as the output for
 5191 // for floating point compare instructions (CmpF CmpD). this ensures
 5192 // that ordered inequality tests use GT, GE, LT or LE none of which
 5193 // pass through cases where the result is unordered i.e. one or both
 5194 // inputs to the compare is a NaN. this means that the ideal code can
 5195 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5196 // (where the comparison should always fail). EQ and NE tests are
 5197 // always generated in ideal code so that unordered folds into the NE
 5198 // case, matching the behaviour of AArch64 NE.
 5199 //
 5200 // This differs from x86 where the outputs of FP compares use a
 5201 // special FP flags registers and where compares based on this
 5202 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5203 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5204 // to explicitly handle the unordered case in branches. x86 also has
 5205 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5206 
 5207 operand rFlagsReg()
 5208 %{
 5209   constraint(ALLOC_IN_RC(int_flags));
 5210   match(RegFlags);
 5211 
 5212   op_cost(0);
 5213   format %{ &quot;RFLAGS&quot; %}
 5214   interface(REG_INTER);
 5215 %}
 5216 
 5217 // Flags register, used as output of unsigned compare instructions
 5218 operand rFlagsRegU()
 5219 %{
 5220   constraint(ALLOC_IN_RC(int_flags));
 5221   match(RegFlags);
 5222 
 5223   op_cost(0);
 5224   format %{ &quot;RFLAGSU&quot; %}
 5225   interface(REG_INTER);
 5226 %}
 5227 
 5228 // Special Registers
 5229 
 5230 // Method Register
 5231 operand inline_cache_RegP(iRegP reg)
 5232 %{
 5233   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5234   match(reg);
 5235   match(iRegPNoSp);
 5236   op_cost(0);
 5237   format %{ %}
 5238   interface(REG_INTER);
 5239 %}
 5240 
 5241 operand interpreter_method_oop_RegP(iRegP reg)
 5242 %{
 5243   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5244   match(reg);
 5245   match(iRegPNoSp);
 5246   op_cost(0);
 5247   format %{ %}
 5248   interface(REG_INTER);
 5249 %}
 5250 
 5251 // Thread Register
 5252 operand thread_RegP(iRegP reg)
 5253 %{
 5254   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5255   match(reg);
 5256   op_cost(0);
 5257   format %{ %}
 5258   interface(REG_INTER);
 5259 %}
 5260 
 5261 operand lr_RegP(iRegP reg)
 5262 %{
 5263   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5264   match(reg);
 5265   op_cost(0);
 5266   format %{ %}
 5267   interface(REG_INTER);
 5268 %}
 5269 
 5270 //----------Memory Operands----------------------------------------------------
 5271 
 5272 operand indirect(iRegP reg)
 5273 %{
 5274   constraint(ALLOC_IN_RC(ptr_reg));
 5275   match(reg);
 5276   op_cost(0);
 5277   format %{ &quot;[$reg]&quot; %}
 5278   interface(MEMORY_INTER) %{
 5279     base($reg);
 5280     index(0xffffffff);
 5281     scale(0x0);
 5282     disp(0x0);
 5283   %}
 5284 %}
 5285 
 5286 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5287 %{
 5288   constraint(ALLOC_IN_RC(ptr_reg));
 5289   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5290   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5291   op_cost(0);
 5292   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5293   interface(MEMORY_INTER) %{
 5294     base($reg);
 5295     index($ireg);
 5296     scale($scale);
 5297     disp(0x0);
 5298   %}
 5299 %}
 5300 
 5301 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5302 %{
 5303   constraint(ALLOC_IN_RC(ptr_reg));
 5304   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5305   match(AddP reg (LShiftL lreg scale));
 5306   op_cost(0);
 5307   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5308   interface(MEMORY_INTER) %{
 5309     base($reg);
 5310     index($lreg);
 5311     scale($scale);
 5312     disp(0x0);
 5313   %}
 5314 %}
 5315 
 5316 operand indIndexI2L(iRegP reg, iRegI ireg)
 5317 %{
 5318   constraint(ALLOC_IN_RC(ptr_reg));
 5319   match(AddP reg (ConvI2L ireg));
 5320   op_cost(0);
 5321   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5322   interface(MEMORY_INTER) %{
 5323     base($reg);
 5324     index($ireg);
 5325     scale(0x0);
 5326     disp(0x0);
 5327   %}
 5328 %}
 5329 
 5330 operand indIndex(iRegP reg, iRegL lreg)
 5331 %{
 5332   constraint(ALLOC_IN_RC(ptr_reg));
 5333   match(AddP reg lreg);
 5334   op_cost(0);
 5335   format %{ &quot;$reg, $lreg&quot; %}
 5336   interface(MEMORY_INTER) %{
 5337     base($reg);
 5338     index($lreg);
 5339     scale(0x0);
 5340     disp(0x0);
 5341   %}
 5342 %}
 5343 
 5344 operand indOffI(iRegP reg, immIOffset off)
 5345 %{
 5346   constraint(ALLOC_IN_RC(ptr_reg));
 5347   match(AddP reg off);
 5348   op_cost(0);
 5349   format %{ &quot;[$reg, $off]&quot; %}
 5350   interface(MEMORY_INTER) %{
 5351     base($reg);
 5352     index(0xffffffff);
 5353     scale(0x0);
 5354     disp($off);
 5355   %}
 5356 %}
 5357 
 5358 operand indOffI1(iRegP reg, immIOffset1 off)
 5359 %{
 5360   constraint(ALLOC_IN_RC(ptr_reg));
 5361   match(AddP reg off);
 5362   op_cost(0);
 5363   format %{ &quot;[$reg, $off]&quot; %}
 5364   interface(MEMORY_INTER) %{
 5365     base($reg);
 5366     index(0xffffffff);
 5367     scale(0x0);
 5368     disp($off);
 5369   %}
 5370 %}
 5371 
 5372 operand indOffI2(iRegP reg, immIOffset2 off)
 5373 %{
 5374   constraint(ALLOC_IN_RC(ptr_reg));
 5375   match(AddP reg off);
 5376   op_cost(0);
 5377   format %{ &quot;[$reg, $off]&quot; %}
 5378   interface(MEMORY_INTER) %{
 5379     base($reg);
 5380     index(0xffffffff);
 5381     scale(0x0);
 5382     disp($off);
 5383   %}
 5384 %}
 5385 
 5386 operand indOffI4(iRegP reg, immIOffset4 off)
 5387 %{
 5388   constraint(ALLOC_IN_RC(ptr_reg));
 5389   match(AddP reg off);
 5390   op_cost(0);
 5391   format %{ &quot;[$reg, $off]&quot; %}
 5392   interface(MEMORY_INTER) %{
 5393     base($reg);
 5394     index(0xffffffff);
 5395     scale(0x0);
 5396     disp($off);
 5397   %}
 5398 %}
 5399 
 5400 operand indOffI8(iRegP reg, immIOffset8 off)
 5401 %{
 5402   constraint(ALLOC_IN_RC(ptr_reg));
 5403   match(AddP reg off);
 5404   op_cost(0);
 5405   format %{ &quot;[$reg, $off]&quot; %}
 5406   interface(MEMORY_INTER) %{
 5407     base($reg);
 5408     index(0xffffffff);
 5409     scale(0x0);
 5410     disp($off);
 5411   %}
 5412 %}
 5413 
 5414 operand indOffI16(iRegP reg, immIOffset16 off)
 5415 %{
 5416   constraint(ALLOC_IN_RC(ptr_reg));
 5417   match(AddP reg off);
 5418   op_cost(0);
 5419   format %{ &quot;[$reg, $off]&quot; %}
 5420   interface(MEMORY_INTER) %{
 5421     base($reg);
 5422     index(0xffffffff);
 5423     scale(0x0);
 5424     disp($off);
 5425   %}
 5426 %}
 5427 
 5428 operand indOffL(iRegP reg, immLoffset off)
 5429 %{
 5430   constraint(ALLOC_IN_RC(ptr_reg));
 5431   match(AddP reg off);
 5432   op_cost(0);
 5433   format %{ &quot;[$reg, $off]&quot; %}
 5434   interface(MEMORY_INTER) %{
 5435     base($reg);
 5436     index(0xffffffff);
 5437     scale(0x0);
 5438     disp($off);
 5439   %}
 5440 %}
 5441 
 5442 operand indOffL1(iRegP reg, immLoffset1 off)
 5443 %{
 5444   constraint(ALLOC_IN_RC(ptr_reg));
 5445   match(AddP reg off);
 5446   op_cost(0);
 5447   format %{ &quot;[$reg, $off]&quot; %}
 5448   interface(MEMORY_INTER) %{
 5449     base($reg);
 5450     index(0xffffffff);
 5451     scale(0x0);
 5452     disp($off);
 5453   %}
 5454 %}
 5455 
 5456 operand indOffL2(iRegP reg, immLoffset2 off)
 5457 %{
 5458   constraint(ALLOC_IN_RC(ptr_reg));
 5459   match(AddP reg off);
 5460   op_cost(0);
 5461   format %{ &quot;[$reg, $off]&quot; %}
 5462   interface(MEMORY_INTER) %{
 5463     base($reg);
 5464     index(0xffffffff);
 5465     scale(0x0);
 5466     disp($off);
 5467   %}
 5468 %}
 5469 
 5470 operand indOffL4(iRegP reg, immLoffset4 off)
 5471 %{
 5472   constraint(ALLOC_IN_RC(ptr_reg));
 5473   match(AddP reg off);
 5474   op_cost(0);
 5475   format %{ &quot;[$reg, $off]&quot; %}
 5476   interface(MEMORY_INTER) %{
 5477     base($reg);
 5478     index(0xffffffff);
 5479     scale(0x0);
 5480     disp($off);
 5481   %}
 5482 %}
 5483 
 5484 operand indOffL8(iRegP reg, immLoffset8 off)
 5485 %{
 5486   constraint(ALLOC_IN_RC(ptr_reg));
 5487   match(AddP reg off);
 5488   op_cost(0);
 5489   format %{ &quot;[$reg, $off]&quot; %}
 5490   interface(MEMORY_INTER) %{
 5491     base($reg);
 5492     index(0xffffffff);
 5493     scale(0x0);
 5494     disp($off);
 5495   %}
 5496 %}
 5497 
 5498 operand indOffL16(iRegP reg, immLoffset16 off)
 5499 %{
 5500   constraint(ALLOC_IN_RC(ptr_reg));
 5501   match(AddP reg off);
 5502   op_cost(0);
 5503   format %{ &quot;[$reg, $off]&quot; %}
 5504   interface(MEMORY_INTER) %{
 5505     base($reg);
 5506     index(0xffffffff);
 5507     scale(0x0);
 5508     disp($off);
 5509   %}
 5510 %}
 5511 
 5512 operand indirectN(iRegN reg)
 5513 %{
 5514   predicate(CompressedOops::shift() == 0);
 5515   constraint(ALLOC_IN_RC(ptr_reg));
 5516   match(DecodeN reg);
 5517   op_cost(0);
 5518   format %{ &quot;[$reg]\t# narrow&quot; %}
 5519   interface(MEMORY_INTER) %{
 5520     base($reg);
 5521     index(0xffffffff);
 5522     scale(0x0);
 5523     disp(0x0);
 5524   %}
 5525 %}
 5526 
 5527 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5528 %{
 5529   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5530   constraint(ALLOC_IN_RC(ptr_reg));
 5531   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5532   op_cost(0);
 5533   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5534   interface(MEMORY_INTER) %{
 5535     base($reg);
 5536     index($ireg);
 5537     scale($scale);
 5538     disp(0x0);
 5539   %}
 5540 %}
 5541 
 5542 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5543 %{
 5544   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5545   constraint(ALLOC_IN_RC(ptr_reg));
 5546   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5547   op_cost(0);
 5548   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5549   interface(MEMORY_INTER) %{
 5550     base($reg);
 5551     index($lreg);
 5552     scale($scale);
 5553     disp(0x0);
 5554   %}
 5555 %}
 5556 
 5557 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5558 %{
 5559   predicate(CompressedOops::shift() == 0);
 5560   constraint(ALLOC_IN_RC(ptr_reg));
 5561   match(AddP (DecodeN reg) (ConvI2L ireg));
 5562   op_cost(0);
 5563   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5564   interface(MEMORY_INTER) %{
 5565     base($reg);
 5566     index($ireg);
 5567     scale(0x0);
 5568     disp(0x0);
 5569   %}
 5570 %}
 5571 
 5572 operand indIndexN(iRegN reg, iRegL lreg)
 5573 %{
 5574   predicate(CompressedOops::shift() == 0);
 5575   constraint(ALLOC_IN_RC(ptr_reg));
 5576   match(AddP (DecodeN reg) lreg);
 5577   op_cost(0);
 5578   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5579   interface(MEMORY_INTER) %{
 5580     base($reg);
 5581     index($lreg);
 5582     scale(0x0);
 5583     disp(0x0);
 5584   %}
 5585 %}
 5586 
 5587 operand indOffIN(iRegN reg, immIOffset off)
 5588 %{
 5589   predicate(CompressedOops::shift() == 0);
 5590   constraint(ALLOC_IN_RC(ptr_reg));
 5591   match(AddP (DecodeN reg) off);
 5592   op_cost(0);
 5593   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5594   interface(MEMORY_INTER) %{
 5595     base($reg);
 5596     index(0xffffffff);
 5597     scale(0x0);
 5598     disp($off);
 5599   %}
 5600 %}
 5601 
 5602 operand indOffLN(iRegN reg, immLoffset off)
 5603 %{
 5604   predicate(CompressedOops::shift() == 0);
 5605   constraint(ALLOC_IN_RC(ptr_reg));
 5606   match(AddP (DecodeN reg) off);
 5607   op_cost(0);
 5608   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5609   interface(MEMORY_INTER) %{
 5610     base($reg);
 5611     index(0xffffffff);
 5612     scale(0x0);
 5613     disp($off);
 5614   %}
 5615 %}
 5616 
 5617 
 5618 
 5619 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5620 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5621 %{
 5622   constraint(ALLOC_IN_RC(ptr_reg));
 5623   match(AddP reg off);
 5624   op_cost(0);
 5625   format %{ &quot;[$reg, $off]&quot; %}
 5626   interface(MEMORY_INTER) %{
 5627     base($reg);
 5628     index(0xffffffff);
 5629     scale(0x0);
 5630     disp($off);
 5631   %}
 5632 %}
 5633 
 5634 //----------Special Memory Operands--------------------------------------------
 5635 // Stack Slot Operand - This operand is used for loading and storing temporary
 5636 //                      values on the stack where a match requires a value to
 5637 //                      flow through memory.
 5638 operand stackSlotP(sRegP reg)
 5639 %{
 5640   constraint(ALLOC_IN_RC(stack_slots));
 5641   op_cost(100);
 5642   // No match rule because this operand is only generated in matching
 5643   // match(RegP);
 5644   format %{ &quot;[$reg]&quot; %}
 5645   interface(MEMORY_INTER) %{
 5646     base(0x1e);  // RSP
 5647     index(0x0);  // No Index
 5648     scale(0x0);  // No Scale
 5649     disp($reg);  // Stack Offset
 5650   %}
 5651 %}
 5652 
 5653 operand stackSlotI(sRegI reg)
 5654 %{
 5655   constraint(ALLOC_IN_RC(stack_slots));
 5656   // No match rule because this operand is only generated in matching
 5657   // match(RegI);
 5658   format %{ &quot;[$reg]&quot; %}
 5659   interface(MEMORY_INTER) %{
 5660     base(0x1e);  // RSP
 5661     index(0x0);  // No Index
 5662     scale(0x0);  // No Scale
 5663     disp($reg);  // Stack Offset
 5664   %}
 5665 %}
 5666 
 5667 operand stackSlotF(sRegF reg)
 5668 %{
 5669   constraint(ALLOC_IN_RC(stack_slots));
 5670   // No match rule because this operand is only generated in matching
 5671   // match(RegF);
 5672   format %{ &quot;[$reg]&quot; %}
 5673   interface(MEMORY_INTER) %{
 5674     base(0x1e);  // RSP
 5675     index(0x0);  // No Index
 5676     scale(0x0);  // No Scale
 5677     disp($reg);  // Stack Offset
 5678   %}
 5679 %}
 5680 
 5681 operand stackSlotD(sRegD reg)
 5682 %{
 5683   constraint(ALLOC_IN_RC(stack_slots));
 5684   // No match rule because this operand is only generated in matching
 5685   // match(RegD);
 5686   format %{ &quot;[$reg]&quot; %}
 5687   interface(MEMORY_INTER) %{
 5688     base(0x1e);  // RSP
 5689     index(0x0);  // No Index
 5690     scale(0x0);  // No Scale
 5691     disp($reg);  // Stack Offset
 5692   %}
 5693 %}
 5694 
 5695 operand stackSlotL(sRegL reg)
 5696 %{
 5697   constraint(ALLOC_IN_RC(stack_slots));
 5698   // No match rule because this operand is only generated in matching
 5699   // match(RegL);
 5700   format %{ &quot;[$reg]&quot; %}
 5701   interface(MEMORY_INTER) %{
 5702     base(0x1e);  // RSP
 5703     index(0x0);  // No Index
 5704     scale(0x0);  // No Scale
 5705     disp($reg);  // Stack Offset
 5706   %}
 5707 %}
 5708 
 5709 // Operands for expressing Control Flow
 5710 // NOTE: Label is a predefined operand which should not be redefined in
 5711 //       the AD file. It is generically handled within the ADLC.
 5712 
 5713 //----------Conditional Branch Operands----------------------------------------
 5714 // Comparison Op  - This is the operation of the comparison, and is limited to
 5715 //                  the following set of codes:
 5716 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5717 //
 5718 // Other attributes of the comparison, such as unsignedness, are specified
 5719 // by the comparison instruction that sets a condition code flags register.
 5720 // That result is represented by a flags operand whose subtype is appropriate
 5721 // to the unsignedness (etc.) of the comparison.
 5722 //
 5723 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5724 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5725 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5726 
 5727 // used for signed integral comparisons and fp comparisons
 5728 
 5729 operand cmpOp()
 5730 %{
 5731   match(Bool);
 5732 
 5733   format %{ &quot;&quot; %}
 5734   interface(COND_INTER) %{
 5735     equal(0x0, &quot;eq&quot;);
 5736     not_equal(0x1, &quot;ne&quot;);
 5737     less(0xb, &quot;lt&quot;);
 5738     greater_equal(0xa, &quot;ge&quot;);
 5739     less_equal(0xd, &quot;le&quot;);
 5740     greater(0xc, &quot;gt&quot;);
 5741     overflow(0x6, &quot;vs&quot;);
 5742     no_overflow(0x7, &quot;vc&quot;);
 5743   %}
 5744 %}
 5745 
 5746 // used for unsigned integral comparisons
 5747 
 5748 operand cmpOpU()
 5749 %{
 5750   match(Bool);
 5751 
 5752   format %{ &quot;&quot; %}
 5753   interface(COND_INTER) %{
 5754     equal(0x0, &quot;eq&quot;);
 5755     not_equal(0x1, &quot;ne&quot;);
 5756     less(0x3, &quot;lo&quot;);
 5757     greater_equal(0x2, &quot;hs&quot;);
 5758     less_equal(0x9, &quot;ls&quot;);
 5759     greater(0x8, &quot;hi&quot;);
 5760     overflow(0x6, &quot;vs&quot;);
 5761     no_overflow(0x7, &quot;vc&quot;);
 5762   %}
 5763 %}
 5764 
 5765 // used for certain integral comparisons which can be
 5766 // converted to cbxx or tbxx instructions
 5767 
 5768 operand cmpOpEqNe()
 5769 %{
 5770   match(Bool);
 5771   op_cost(0);
 5772   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5773             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5774 
 5775   format %{ &quot;&quot; %}
 5776   interface(COND_INTER) %{
 5777     equal(0x0, &quot;eq&quot;);
 5778     not_equal(0x1, &quot;ne&quot;);
 5779     less(0xb, &quot;lt&quot;);
 5780     greater_equal(0xa, &quot;ge&quot;);
 5781     less_equal(0xd, &quot;le&quot;);
 5782     greater(0xc, &quot;gt&quot;);
 5783     overflow(0x6, &quot;vs&quot;);
 5784     no_overflow(0x7, &quot;vc&quot;);
 5785   %}
 5786 %}
 5787 
 5788 // used for certain integral comparisons which can be
 5789 // converted to cbxx or tbxx instructions
 5790 
 5791 operand cmpOpLtGe()
 5792 %{
 5793   match(Bool);
 5794   op_cost(0);
 5795 
 5796   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5797             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5798 
 5799   format %{ &quot;&quot; %}
 5800   interface(COND_INTER) %{
 5801     equal(0x0, &quot;eq&quot;);
 5802     not_equal(0x1, &quot;ne&quot;);
 5803     less(0xb, &quot;lt&quot;);
 5804     greater_equal(0xa, &quot;ge&quot;);
 5805     less_equal(0xd, &quot;le&quot;);
 5806     greater(0xc, &quot;gt&quot;);
 5807     overflow(0x6, &quot;vs&quot;);
 5808     no_overflow(0x7, &quot;vc&quot;);
 5809   %}
 5810 %}
 5811 
 5812 // used for certain unsigned integral comparisons which can be
 5813 // converted to cbxx or tbxx instructions
 5814 
 5815 operand cmpOpUEqNeLtGe()
 5816 %{
 5817   match(Bool);
 5818   op_cost(0);
 5819 
 5820   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5821             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5822             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5823             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5824 
 5825   format %{ &quot;&quot; %}
 5826   interface(COND_INTER) %{
 5827     equal(0x0, &quot;eq&quot;);
 5828     not_equal(0x1, &quot;ne&quot;);
 5829     less(0xb, &quot;lt&quot;);
 5830     greater_equal(0xa, &quot;ge&quot;);
 5831     less_equal(0xd, &quot;le&quot;);
 5832     greater(0xc, &quot;gt&quot;);
 5833     overflow(0x6, &quot;vs&quot;);
 5834     no_overflow(0x7, &quot;vc&quot;);
 5835   %}
 5836 %}
 5837 
 5838 // Special operand allowing long args to int ops to be truncated for free
 5839 
 5840 operand iRegL2I(iRegL reg) %{
 5841 
 5842   op_cost(0);
 5843 
 5844   match(ConvL2I reg);
 5845 
 5846   format %{ &quot;l2i($reg)&quot; %}
 5847 
 5848   interface(REG_INTER)
 5849 %}
 5850 
 5851 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5852 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5853 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5854 
 5855 //----------OPERAND CLASSES----------------------------------------------------
 5856 // Operand Classes are groups of operands that are used as to simplify
 5857 // instruction definitions by not requiring the AD writer to specify
 5858 // separate instructions for every form of operand when the
 5859 // instruction accepts multiple operand types with the same basic
 5860 // encoding and format. The classic case of this is memory operands.
 5861 
 5862 // memory is used to define read/write location for load/store
 5863 // instruction defs. we can turn a memory op into an Address
 5864 
 5865 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5866                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5867 
 5868 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5869                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5870 
 5871 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5872                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5873 
 5874 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5875                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5876 
 5877 // All of the memory operands. For the pipeline description.
 5878 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5879                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5880                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5881 
 5882 
 5883 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5884 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5885 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5886 // can be elided because the 32-bit instruction will just employ the
 5887 // lower 32 bits anyway.
 5888 //
 5889 // n.b. this does not elide all L2I conversions. if the truncated
 5890 // value is consumed by more than one operation then the ConvL2I
 5891 // cannot be bundled into the consuming nodes so an l2i gets planted
 5892 // (actually a movw $dst $src) and the downstream instructions consume
 5893 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5894 // movw is actually redundant but its not too costly.
 5895 
 5896 opclass iRegIorL2I(iRegI, iRegL2I);
 5897 
 5898 //----------PIPELINE-----------------------------------------------------------
 5899 // Rules which define the behavior of the target architectures pipeline.
 5900 
 5901 // For specific pipelines, eg A53, define the stages of that pipeline
 5902 //pipe_desc(ISS, EX1, EX2, WR);
 5903 #define ISS S0
 5904 #define EX1 S1
 5905 #define EX2 S2
 5906 #define WR  S3
 5907 
 5908 // Integer ALU reg operation
 5909 pipeline %{
 5910 
 5911 attributes %{
 5912   // ARM instructions are of fixed length
 5913   fixed_size_instructions;        // Fixed size instructions TODO does
 5914   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5915   // ARM instructions come in 32-bit word units
 5916   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5917   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5918   instruction_fetch_units = 1;       // of 64 bytes
 5919 
 5920   // List of nop instructions
 5921   nops( MachNop );
 5922 %}
 5923 
 5924 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5925 // or description. we do use pipeline classes to introduce fixed
 5926 // latencies
 5927 
 5928 //----------RESOURCES----------------------------------------------------------
 5929 // Resources are the functional units available to the machine
 5930 
 5931 resources( INS0, INS1, INS01 = INS0 | INS1,
 5932            ALU0, ALU1, ALU = ALU0 | ALU1,
 5933            MAC,
 5934            DIV,
 5935            BRANCH,
 5936            LDST,
 5937            NEON_FP);
 5938 
 5939 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5940 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5941 
 5942 // Define the pipeline as a generic 6 stage pipeline
 5943 pipe_desc(S0, S1, S2, S3, S4, S5);
 5944 
 5945 //----------PIPELINE CLASSES---------------------------------------------------
 5946 // Pipeline Classes describe the stages in which input and output are
 5947 // referenced by the hardware pipeline.
 5948 
 5949 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5950 %{
 5951   single_instruction;
 5952   src1   : S1(read);
 5953   src2   : S2(read);
 5954   dst    : S5(write);
 5955   INS01  : ISS;
 5956   NEON_FP : S5;
 5957 %}
 5958 
 5959 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5960 %{
 5961   single_instruction;
 5962   src1   : S1(read);
 5963   src2   : S2(read);
 5964   dst    : S5(write);
 5965   INS01  : ISS;
 5966   NEON_FP : S5;
 5967 %}
 5968 
 5969 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5970 %{
 5971   single_instruction;
 5972   src    : S1(read);
 5973   dst    : S5(write);
 5974   INS01  : ISS;
 5975   NEON_FP : S5;
 5976 %}
 5977 
 5978 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5979 %{
 5980   single_instruction;
 5981   src    : S1(read);
 5982   dst    : S5(write);
 5983   INS01  : ISS;
 5984   NEON_FP : S5;
 5985 %}
 5986 
 5987 pipe_class fp_d2f(vRegF dst, vRegD src)
 5988 %{
 5989   single_instruction;
 5990   src    : S1(read);
 5991   dst    : S5(write);
 5992   INS01  : ISS;
 5993   NEON_FP : S5;
 5994 %}
 5995 
 5996 pipe_class fp_f2d(vRegD dst, vRegF src)
 5997 %{
 5998   single_instruction;
 5999   src    : S1(read);
 6000   dst    : S5(write);
 6001   INS01  : ISS;
 6002   NEON_FP : S5;
 6003 %}
 6004 
 6005 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 6006 %{
 6007   single_instruction;
 6008   src    : S1(read);
 6009   dst    : S5(write);
 6010   INS01  : ISS;
 6011   NEON_FP : S5;
 6012 %}
 6013 
 6014 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6015 %{
 6016   single_instruction;
 6017   src    : S1(read);
 6018   dst    : S5(write);
 6019   INS01  : ISS;
 6020   NEON_FP : S5;
 6021 %}
 6022 
 6023 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6024 %{
 6025   single_instruction;
 6026   src    : S1(read);
 6027   dst    : S5(write);
 6028   INS01  : ISS;
 6029   NEON_FP : S5;
 6030 %}
 6031 
 6032 pipe_class fp_l2f(vRegF dst, iRegL src)
 6033 %{
 6034   single_instruction;
 6035   src    : S1(read);
 6036   dst    : S5(write);
 6037   INS01  : ISS;
 6038   NEON_FP : S5;
 6039 %}
 6040 
 6041 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6042 %{
 6043   single_instruction;
 6044   src    : S1(read);
 6045   dst    : S5(write);
 6046   INS01  : ISS;
 6047   NEON_FP : S5;
 6048 %}
 6049 
 6050 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6051 %{
 6052   single_instruction;
 6053   src    : S1(read);
 6054   dst    : S5(write);
 6055   INS01  : ISS;
 6056   NEON_FP : S5;
 6057 %}
 6058 
 6059 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6060 %{
 6061   single_instruction;
 6062   src    : S1(read);
 6063   dst    : S5(write);
 6064   INS01  : ISS;
 6065   NEON_FP : S5;
 6066 %}
 6067 
 6068 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6069 %{
 6070   single_instruction;
 6071   src    : S1(read);
 6072   dst    : S5(write);
 6073   INS01  : ISS;
 6074   NEON_FP : S5;
 6075 %}
 6076 
 6077 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6078 %{
 6079   single_instruction;
 6080   src1   : S1(read);
 6081   src2   : S2(read);
 6082   dst    : S5(write);
 6083   INS0   : ISS;
 6084   NEON_FP : S5;
 6085 %}
 6086 
 6087 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6088 %{
 6089   single_instruction;
 6090   src1   : S1(read);
 6091   src2   : S2(read);
 6092   dst    : S5(write);
 6093   INS0   : ISS;
 6094   NEON_FP : S5;
 6095 %}
 6096 
 6097 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6098 %{
 6099   single_instruction;
 6100   cr     : S1(read);
 6101   src1   : S1(read);
 6102   src2   : S1(read);
 6103   dst    : S3(write);
 6104   INS01  : ISS;
 6105   NEON_FP : S3;
 6106 %}
 6107 
 6108 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6109 %{
 6110   single_instruction;
 6111   cr     : S1(read);
 6112   src1   : S1(read);
 6113   src2   : S1(read);
 6114   dst    : S3(write);
 6115   INS01  : ISS;
 6116   NEON_FP : S3;
 6117 %}
 6118 
 6119 pipe_class fp_imm_s(vRegF dst)
 6120 %{
 6121   single_instruction;
 6122   dst    : S3(write);
 6123   INS01  : ISS;
 6124   NEON_FP : S3;
 6125 %}
 6126 
 6127 pipe_class fp_imm_d(vRegD dst)
 6128 %{
 6129   single_instruction;
 6130   dst    : S3(write);
 6131   INS01  : ISS;
 6132   NEON_FP : S3;
 6133 %}
 6134 
 6135 pipe_class fp_load_constant_s(vRegF dst)
 6136 %{
 6137   single_instruction;
 6138   dst    : S4(write);
 6139   INS01  : ISS;
 6140   NEON_FP : S4;
 6141 %}
 6142 
 6143 pipe_class fp_load_constant_d(vRegD dst)
 6144 %{
 6145   single_instruction;
 6146   dst    : S4(write);
 6147   INS01  : ISS;
 6148   NEON_FP : S4;
 6149 %}
 6150 
 6151 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6152 %{
 6153   single_instruction;
 6154   dst    : S5(write);
 6155   src1   : S1(read);
 6156   src2   : S1(read);
 6157   INS01  : ISS;
 6158   NEON_FP : S5;
 6159 %}
 6160 
 6161 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6162 %{
 6163   single_instruction;
 6164   dst    : S5(write);
 6165   src1   : S1(read);
 6166   src2   : S1(read);
 6167   INS0   : ISS;
 6168   NEON_FP : S5;
 6169 %}
 6170 
 6171 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6172 %{
 6173   single_instruction;
 6174   dst    : S5(write);
 6175   src1   : S1(read);
 6176   src2   : S1(read);
 6177   dst    : S1(read);
 6178   INS01  : ISS;
 6179   NEON_FP : S5;
 6180 %}
 6181 
 6182 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6183 %{
 6184   single_instruction;
 6185   dst    : S5(write);
 6186   src1   : S1(read);
 6187   src2   : S1(read);
 6188   dst    : S1(read);
 6189   INS0   : ISS;
 6190   NEON_FP : S5;
 6191 %}
 6192 
 6193 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6194 %{
 6195   single_instruction;
 6196   dst    : S4(write);
 6197   src1   : S2(read);
 6198   src2   : S2(read);
 6199   INS01  : ISS;
 6200   NEON_FP : S4;
 6201 %}
 6202 
 6203 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6204 %{
 6205   single_instruction;
 6206   dst    : S4(write);
 6207   src1   : S2(read);
 6208   src2   : S2(read);
 6209   INS0   : ISS;
 6210   NEON_FP : S4;
 6211 %}
 6212 
 6213 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6214 %{
 6215   single_instruction;
 6216   dst    : S3(write);
 6217   src1   : S2(read);
 6218   src2   : S2(read);
 6219   INS01  : ISS;
 6220   NEON_FP : S3;
 6221 %}
 6222 
 6223 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6224 %{
 6225   single_instruction;
 6226   dst    : S3(write);
 6227   src1   : S2(read);
 6228   src2   : S2(read);
 6229   INS0   : ISS;
 6230   NEON_FP : S3;
 6231 %}
 6232 
 6233 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6234 %{
 6235   single_instruction;
 6236   dst    : S3(write);
 6237   src    : S1(read);
 6238   shift  : S1(read);
 6239   INS01  : ISS;
 6240   NEON_FP : S3;
 6241 %}
 6242 
 6243 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6244 %{
 6245   single_instruction;
 6246   dst    : S3(write);
 6247   src    : S1(read);
 6248   shift  : S1(read);
 6249   INS0   : ISS;
 6250   NEON_FP : S3;
 6251 %}
 6252 
 6253 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6254 %{
 6255   single_instruction;
 6256   dst    : S3(write);
 6257   src    : S1(read);
 6258   INS01  : ISS;
 6259   NEON_FP : S3;
 6260 %}
 6261 
 6262 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6263 %{
 6264   single_instruction;
 6265   dst    : S3(write);
 6266   src    : S1(read);
 6267   INS0   : ISS;
 6268   NEON_FP : S3;
 6269 %}
 6270 
 6271 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6272 %{
 6273   single_instruction;
 6274   dst    : S5(write);
 6275   src1   : S1(read);
 6276   src2   : S1(read);
 6277   INS01  : ISS;
 6278   NEON_FP : S5;
 6279 %}
 6280 
 6281 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6282 %{
 6283   single_instruction;
 6284   dst    : S5(write);
 6285   src1   : S1(read);
 6286   src2   : S1(read);
 6287   INS0   : ISS;
 6288   NEON_FP : S5;
 6289 %}
 6290 
 6291 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6292 %{
 6293   single_instruction;
 6294   dst    : S5(write);
 6295   src1   : S1(read);
 6296   src2   : S1(read);
 6297   INS0   : ISS;
 6298   NEON_FP : S5;
 6299 %}
 6300 
 6301 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6302 %{
 6303   single_instruction;
 6304   dst    : S5(write);
 6305   src1   : S1(read);
 6306   src2   : S1(read);
 6307   INS0   : ISS;
 6308   NEON_FP : S5;
 6309 %}
 6310 
 6311 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6312 %{
 6313   single_instruction;
 6314   dst    : S5(write);
 6315   src    : S1(read);
 6316   INS0   : ISS;
 6317   NEON_FP : S5;
 6318 %}
 6319 
 6320 pipe_class vunop_fp64(vecD dst, vecD src)
 6321 %{
 6322   single_instruction;
 6323   dst    : S5(write);
 6324   src    : S1(read);
 6325   INS01  : ISS;
 6326   NEON_FP : S5;
 6327 %}
 6328 
 6329 pipe_class vunop_fp128(vecX dst, vecX src)
 6330 %{
 6331   single_instruction;
 6332   dst    : S5(write);
 6333   src    : S1(read);
 6334   INS0   : ISS;
 6335   NEON_FP : S5;
 6336 %}
 6337 
 6338 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6339 %{
 6340   single_instruction;
 6341   dst    : S3(write);
 6342   src    : S1(read);
 6343   INS01  : ISS;
 6344   NEON_FP : S3;
 6345 %}
 6346 
 6347 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6348 %{
 6349   single_instruction;
 6350   dst    : S3(write);
 6351   src    : S1(read);
 6352   INS01  : ISS;
 6353   NEON_FP : S3;
 6354 %}
 6355 
 6356 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6357 %{
 6358   single_instruction;
 6359   dst    : S3(write);
 6360   src    : S1(read);
 6361   INS01  : ISS;
 6362   NEON_FP : S3;
 6363 %}
 6364 
 6365 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6366 %{
 6367   single_instruction;
 6368   dst    : S3(write);
 6369   src    : S1(read);
 6370   INS01  : ISS;
 6371   NEON_FP : S3;
 6372 %}
 6373 
 6374 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6375 %{
 6376   single_instruction;
 6377   dst    : S3(write);
 6378   src    : S1(read);
 6379   INS01  : ISS;
 6380   NEON_FP : S3;
 6381 %}
 6382 
 6383 pipe_class vmovi_reg_imm64(vecD dst)
 6384 %{
 6385   single_instruction;
 6386   dst    : S3(write);
 6387   INS01  : ISS;
 6388   NEON_FP : S3;
 6389 %}
 6390 
 6391 pipe_class vmovi_reg_imm128(vecX dst)
 6392 %{
 6393   single_instruction;
 6394   dst    : S3(write);
 6395   INS0   : ISS;
 6396   NEON_FP : S3;
 6397 %}
 6398 
 6399 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6400 %{
 6401   single_instruction;
 6402   dst    : S5(write);
 6403   mem    : ISS(read);
 6404   INS01  : ISS;
 6405   NEON_FP : S3;
 6406 %}
 6407 
 6408 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6409 %{
 6410   single_instruction;
 6411   dst    : S5(write);
 6412   mem    : ISS(read);
 6413   INS01  : ISS;
 6414   NEON_FP : S3;
 6415 %}
 6416 
 6417 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6418 %{
 6419   single_instruction;
 6420   mem    : ISS(read);
 6421   src    : S2(read);
 6422   INS01  : ISS;
 6423   NEON_FP : S3;
 6424 %}
 6425 
 6426 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6427 %{
 6428   single_instruction;
 6429   mem    : ISS(read);
 6430   src    : S2(read);
 6431   INS01  : ISS;
 6432   NEON_FP : S3;
 6433 %}
 6434 
 6435 //------- Integer ALU operations --------------------------
 6436 
 6437 // Integer ALU reg-reg operation
 6438 // Operands needed in EX1, result generated in EX2
 6439 // Eg.  ADD     x0, x1, x2
 6440 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6441 %{
 6442   single_instruction;
 6443   dst    : EX2(write);
 6444   src1   : EX1(read);
 6445   src2   : EX1(read);
 6446   INS01  : ISS; // Dual issue as instruction 0 or 1
 6447   ALU    : EX2;
 6448 %}
 6449 
 6450 // Integer ALU reg-reg operation with constant shift
 6451 // Shifted register must be available in LATE_ISS instead of EX1
 6452 // Eg.  ADD     x0, x1, x2, LSL #2
 6453 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6454 %{
 6455   single_instruction;
 6456   dst    : EX2(write);
 6457   src1   : EX1(read);
 6458   src2   : ISS(read);
 6459   INS01  : ISS;
 6460   ALU    : EX2;
 6461 %}
 6462 
 6463 // Integer ALU reg operation with constant shift
 6464 // Eg.  LSL     x0, x1, #shift
 6465 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6466 %{
 6467   single_instruction;
 6468   dst    : EX2(write);
 6469   src1   : ISS(read);
 6470   INS01  : ISS;
 6471   ALU    : EX2;
 6472 %}
 6473 
 6474 // Integer ALU reg-reg operation with variable shift
 6475 // Both operands must be available in LATE_ISS instead of EX1
 6476 // Result is available in EX1 instead of EX2
 6477 // Eg.  LSLV    x0, x1, x2
 6478 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6479 %{
 6480   single_instruction;
 6481   dst    : EX1(write);
 6482   src1   : ISS(read);
 6483   src2   : ISS(read);
 6484   INS01  : ISS;
 6485   ALU    : EX1;
 6486 %}
 6487 
 6488 // Integer ALU reg-reg operation with extract
 6489 // As for _vshift above, but result generated in EX2
 6490 // Eg.  EXTR    x0, x1, x2, #N
 6491 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6492 %{
 6493   single_instruction;
 6494   dst    : EX2(write);
 6495   src1   : ISS(read);
 6496   src2   : ISS(read);
 6497   INS1   : ISS; // Can only dual issue as Instruction 1
 6498   ALU    : EX1;
 6499 %}
 6500 
 6501 // Integer ALU reg operation
 6502 // Eg.  NEG     x0, x1
 6503 pipe_class ialu_reg(iRegI dst, iRegI src)
 6504 %{
 6505   single_instruction;
 6506   dst    : EX2(write);
 6507   src    : EX1(read);
 6508   INS01  : ISS;
 6509   ALU    : EX2;
 6510 %}
 6511 
 6512 // Integer ALU reg mmediate operation
 6513 // Eg.  ADD     x0, x1, #N
 6514 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6515 %{
 6516   single_instruction;
 6517   dst    : EX2(write);
 6518   src1   : EX1(read);
 6519   INS01  : ISS;
 6520   ALU    : EX2;
 6521 %}
 6522 
 6523 // Integer ALU immediate operation (no source operands)
 6524 // Eg.  MOV     x0, #N
 6525 pipe_class ialu_imm(iRegI dst)
 6526 %{
 6527   single_instruction;
 6528   dst    : EX1(write);
 6529   INS01  : ISS;
 6530   ALU    : EX1;
 6531 %}
 6532 
 6533 //------- Compare operation -------------------------------
 6534 
 6535 // Compare reg-reg
 6536 // Eg.  CMP     x0, x1
 6537 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6538 %{
 6539   single_instruction;
 6540 //  fixed_latency(16);
 6541   cr     : EX2(write);
 6542   op1    : EX1(read);
 6543   op2    : EX1(read);
 6544   INS01  : ISS;
 6545   ALU    : EX2;
 6546 %}
 6547 
 6548 // Compare reg-reg
 6549 // Eg.  CMP     x0, #N
 6550 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6551 %{
 6552   single_instruction;
 6553 //  fixed_latency(16);
 6554   cr     : EX2(write);
 6555   op1    : EX1(read);
 6556   INS01  : ISS;
 6557   ALU    : EX2;
 6558 %}
 6559 
 6560 //------- Conditional instructions ------------------------
 6561 
 6562 // Conditional no operands
 6563 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6564 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6565 %{
 6566   single_instruction;
 6567   cr     : EX1(read);
 6568   dst    : EX2(write);
 6569   INS01  : ISS;
 6570   ALU    : EX2;
 6571 %}
 6572 
 6573 // Conditional 2 operand
 6574 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6575 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6576 %{
 6577   single_instruction;
 6578   cr     : EX1(read);
 6579   src1   : EX1(read);
 6580   src2   : EX1(read);
 6581   dst    : EX2(write);
 6582   INS01  : ISS;
 6583   ALU    : EX2;
 6584 %}
 6585 
 6586 // Conditional 2 operand
 6587 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6588 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6589 %{
 6590   single_instruction;
 6591   cr     : EX1(read);
 6592   src    : EX1(read);
 6593   dst    : EX2(write);
 6594   INS01  : ISS;
 6595   ALU    : EX2;
 6596 %}
 6597 
 6598 //------- Multiply pipeline operations --------------------
 6599 
 6600 // Multiply reg-reg
 6601 // Eg.  MUL     w0, w1, w2
 6602 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6603 %{
 6604   single_instruction;
 6605   dst    : WR(write);
 6606   src1   : ISS(read);
 6607   src2   : ISS(read);
 6608   INS01  : ISS;
 6609   MAC    : WR;
 6610 %}
 6611 
 6612 // Multiply accumulate
 6613 // Eg.  MADD    w0, w1, w2, w3
 6614 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6615 %{
 6616   single_instruction;
 6617   dst    : WR(write);
 6618   src1   : ISS(read);
 6619   src2   : ISS(read);
 6620   src3   : ISS(read);
 6621   INS01  : ISS;
 6622   MAC    : WR;
 6623 %}
 6624 
 6625 // Eg.  MUL     w0, w1, w2
 6626 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6627 %{
 6628   single_instruction;
 6629   fixed_latency(3); // Maximum latency for 64 bit mul
 6630   dst    : WR(write);
 6631   src1   : ISS(read);
 6632   src2   : ISS(read);
 6633   INS01  : ISS;
 6634   MAC    : WR;
 6635 %}
 6636 
 6637 // Multiply accumulate
 6638 // Eg.  MADD    w0, w1, w2, w3
 6639 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6640 %{
 6641   single_instruction;
 6642   fixed_latency(3); // Maximum latency for 64 bit mul
 6643   dst    : WR(write);
 6644   src1   : ISS(read);
 6645   src2   : ISS(read);
 6646   src3   : ISS(read);
 6647   INS01  : ISS;
 6648   MAC    : WR;
 6649 %}
 6650 
 6651 //------- Divide pipeline operations --------------------
 6652 
 6653 // Eg.  SDIV    w0, w1, w2
 6654 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6655 %{
 6656   single_instruction;
 6657   fixed_latency(8); // Maximum latency for 32 bit divide
 6658   dst    : WR(write);
 6659   src1   : ISS(read);
 6660   src2   : ISS(read);
 6661   INS0   : ISS; // Can only dual issue as instruction 0
 6662   DIV    : WR;
 6663 %}
 6664 
 6665 // Eg.  SDIV    x0, x1, x2
 6666 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6667 %{
 6668   single_instruction;
 6669   fixed_latency(16); // Maximum latency for 64 bit divide
 6670   dst    : WR(write);
 6671   src1   : ISS(read);
 6672   src2   : ISS(read);
 6673   INS0   : ISS; // Can only dual issue as instruction 0
 6674   DIV    : WR;
 6675 %}
 6676 
 6677 //------- Load pipeline operations ------------------------
 6678 
 6679 // Load - prefetch
 6680 // Eg.  PFRM    &lt;mem&gt;
 6681 pipe_class iload_prefetch(memory mem)
 6682 %{
 6683   single_instruction;
 6684   mem    : ISS(read);
 6685   INS01  : ISS;
 6686   LDST   : WR;
 6687 %}
 6688 
 6689 // Load - reg, mem
 6690 // Eg.  LDR     x0, &lt;mem&gt;
 6691 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6692 %{
 6693   single_instruction;
 6694   dst    : WR(write);
 6695   mem    : ISS(read);
 6696   INS01  : ISS;
 6697   LDST   : WR;
 6698 %}
 6699 
 6700 // Load - reg, reg
 6701 // Eg.  LDR     x0, [sp, x1]
 6702 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6703 %{
 6704   single_instruction;
 6705   dst    : WR(write);
 6706   src    : ISS(read);
 6707   INS01  : ISS;
 6708   LDST   : WR;
 6709 %}
 6710 
 6711 //------- Store pipeline operations -----------------------
 6712 
 6713 // Store - zr, mem
 6714 // Eg.  STR     zr, &lt;mem&gt;
 6715 pipe_class istore_mem(memory mem)
 6716 %{
 6717   single_instruction;
 6718   mem    : ISS(read);
 6719   INS01  : ISS;
 6720   LDST   : WR;
 6721 %}
 6722 
 6723 // Store - reg, mem
 6724 // Eg.  STR     x0, &lt;mem&gt;
 6725 pipe_class istore_reg_mem(iRegI src, memory mem)
 6726 %{
 6727   single_instruction;
 6728   mem    : ISS(read);
 6729   src    : EX2(read);
 6730   INS01  : ISS;
 6731   LDST   : WR;
 6732 %}
 6733 
 6734 // Store - reg, reg
 6735 // Eg. STR      x0, [sp, x1]
 6736 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6737 %{
 6738   single_instruction;
 6739   dst    : ISS(read);
 6740   src    : EX2(read);
 6741   INS01  : ISS;
 6742   LDST   : WR;
 6743 %}
 6744 
 6745 //------- Store pipeline operations -----------------------
 6746 
 6747 // Branch
 6748 pipe_class pipe_branch()
 6749 %{
 6750   single_instruction;
 6751   INS01  : ISS;
 6752   BRANCH : EX1;
 6753 %}
 6754 
 6755 // Conditional branch
 6756 pipe_class pipe_branch_cond(rFlagsReg cr)
 6757 %{
 6758   single_instruction;
 6759   cr     : EX1(read);
 6760   INS01  : ISS;
 6761   BRANCH : EX1;
 6762 %}
 6763 
 6764 // Compare &amp; Branch
 6765 // EG.  CBZ/CBNZ
 6766 pipe_class pipe_cmp_branch(iRegI op1)
 6767 %{
 6768   single_instruction;
 6769   op1    : EX1(read);
 6770   INS01  : ISS;
 6771   BRANCH : EX1;
 6772 %}
 6773 
 6774 //------- Synchronisation operations ----------------------
 6775 
 6776 // Any operation requiring serialization.
 6777 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6778 pipe_class pipe_serial()
 6779 %{
 6780   single_instruction;
 6781   force_serialization;
 6782   fixed_latency(16);
 6783   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6784   LDST   : WR;
 6785 %}
 6786 
 6787 // Generic big/slow expanded idiom - also serialized
 6788 pipe_class pipe_slow()
 6789 %{
 6790   instruction_count(10);
 6791   multiple_bundles;
 6792   force_serialization;
 6793   fixed_latency(16);
 6794   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6795   LDST   : WR;
 6796 %}
 6797 
 6798 // Empty pipeline class
 6799 pipe_class pipe_class_empty()
 6800 %{
 6801   single_instruction;
 6802   fixed_latency(0);
 6803 %}
 6804 
 6805 // Default pipeline class.
 6806 pipe_class pipe_class_default()
 6807 %{
 6808   single_instruction;
 6809   fixed_latency(2);
 6810 %}
 6811 
 6812 // Pipeline class for compares.
 6813 pipe_class pipe_class_compare()
 6814 %{
 6815   single_instruction;
 6816   fixed_latency(16);
 6817 %}
 6818 
 6819 // Pipeline class for memory operations.
 6820 pipe_class pipe_class_memory()
 6821 %{
 6822   single_instruction;
 6823   fixed_latency(16);
 6824 %}
 6825 
 6826 // Pipeline class for call.
 6827 pipe_class pipe_class_call()
 6828 %{
 6829   single_instruction;
 6830   fixed_latency(100);
 6831 %}
 6832 
 6833 // Define the class for the Nop node.
 6834 define %{
 6835    MachNop = pipe_class_empty;
 6836 %}
 6837 
 6838 %}
 6839 //----------INSTRUCTIONS-------------------------------------------------------
 6840 //
 6841 // match      -- States which machine-independent subtree may be replaced
 6842 //               by this instruction.
 6843 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6844 //               selection to identify a minimum cost tree of machine
 6845 //               instructions that matches a tree of machine-independent
 6846 //               instructions.
 6847 // format     -- A string providing the disassembly for this instruction.
 6848 //               The value of an instruction&#39;s operand may be inserted
 6849 //               by referring to it with a &#39;$&#39; prefix.
 6850 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6851 //               to within an encode class as $primary, $secondary, and $tertiary
 6852 //               rrspectively.  The primary opcode is commonly used to
 6853 //               indicate the type of machine instruction, while secondary
 6854 //               and tertiary are often used for prefix options or addressing
 6855 //               modes.
 6856 // ins_encode -- A list of encode classes with parameters. The encode class
 6857 //               name must have been defined in an &#39;enc_class&#39; specification
 6858 //               in the encode section of the architecture description.
 6859 
 6860 // ============================================================================
 6861 // Memory (Load/Store) Instructions
 6862 
 6863 // Load Instructions
 6864 
 6865 // Load Byte (8 bit signed)
 6866 instruct loadB(iRegINoSp dst, memory1 mem)
 6867 %{
 6868   match(Set dst (LoadB mem));
 6869   predicate(!needs_acquiring_load(n));
 6870 
 6871   ins_cost(4 * INSN_COST);
 6872   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6873 
 6874   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6875 
 6876   ins_pipe(iload_reg_mem);
 6877 %}
 6878 
 6879 // Load Byte (8 bit signed) into long
 6880 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6881 %{
 6882   match(Set dst (ConvI2L (LoadB mem)));
 6883   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6884 
 6885   ins_cost(4 * INSN_COST);
 6886   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6887 
 6888   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6889 
 6890   ins_pipe(iload_reg_mem);
 6891 %}
 6892 
 6893 // Load Byte (8 bit unsigned)
 6894 instruct loadUB(iRegINoSp dst, memory1 mem)
 6895 %{
 6896   match(Set dst (LoadUB mem));
 6897   predicate(!needs_acquiring_load(n));
 6898 
 6899   ins_cost(4 * INSN_COST);
 6900   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6901 
 6902   ins_encode(aarch64_enc_ldrb(dst, mem));
 6903 
 6904   ins_pipe(iload_reg_mem);
 6905 %}
 6906 
 6907 // Load Byte (8 bit unsigned) into long
 6908 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6909 %{
 6910   match(Set dst (ConvI2L (LoadUB mem)));
 6911   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6912 
 6913   ins_cost(4 * INSN_COST);
 6914   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6915 
 6916   ins_encode(aarch64_enc_ldrb(dst, mem));
 6917 
 6918   ins_pipe(iload_reg_mem);
 6919 %}
 6920 
 6921 // Load Short (16 bit signed)
 6922 instruct loadS(iRegINoSp dst, memory2 mem)
 6923 %{
 6924   match(Set dst (LoadS mem));
 6925   predicate(!needs_acquiring_load(n));
 6926 
 6927   ins_cost(4 * INSN_COST);
 6928   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6929 
 6930   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6931 
 6932   ins_pipe(iload_reg_mem);
 6933 %}
 6934 
 6935 // Load Short (16 bit signed) into long
 6936 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6937 %{
 6938   match(Set dst (ConvI2L (LoadS mem)));
 6939   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6940 
 6941   ins_cost(4 * INSN_COST);
 6942   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6943 
 6944   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6945 
 6946   ins_pipe(iload_reg_mem);
 6947 %}
 6948 
 6949 // Load Char (16 bit unsigned)
 6950 instruct loadUS(iRegINoSp dst, memory2 mem)
 6951 %{
 6952   match(Set dst (LoadUS mem));
 6953   predicate(!needs_acquiring_load(n));
 6954 
 6955   ins_cost(4 * INSN_COST);
 6956   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6957 
 6958   ins_encode(aarch64_enc_ldrh(dst, mem));
 6959 
 6960   ins_pipe(iload_reg_mem);
 6961 %}
 6962 
 6963 // Load Short/Char (16 bit unsigned) into long
 6964 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6965 %{
 6966   match(Set dst (ConvI2L (LoadUS mem)));
 6967   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6968 
 6969   ins_cost(4 * INSN_COST);
 6970   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6971 
 6972   ins_encode(aarch64_enc_ldrh(dst, mem));
 6973 
 6974   ins_pipe(iload_reg_mem);
 6975 %}
 6976 
 6977 // Load Integer (32 bit signed)
 6978 instruct loadI(iRegINoSp dst, memory4 mem)
 6979 %{
 6980   match(Set dst (LoadI mem));
 6981   predicate(!needs_acquiring_load(n));
 6982 
 6983   ins_cost(4 * INSN_COST);
 6984   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6985 
 6986   ins_encode(aarch64_enc_ldrw(dst, mem));
 6987 
 6988   ins_pipe(iload_reg_mem);
 6989 %}
 6990 
 6991 // Load Integer (32 bit signed) into long
 6992 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6993 %{
 6994   match(Set dst (ConvI2L (LoadI mem)));
 6995   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6996 
 6997   ins_cost(4 * INSN_COST);
 6998   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6999 
 7000   ins_encode(aarch64_enc_ldrsw(dst, mem));
 7001 
 7002   ins_pipe(iload_reg_mem);
 7003 %}
 7004 
 7005 // Load Integer (32 bit unsigned) into long
 7006 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 7007 %{
 7008   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7009   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 7010 
 7011   ins_cost(4 * INSN_COST);
 7012   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7013 
 7014   ins_encode(aarch64_enc_ldrw(dst, mem));
 7015 
 7016   ins_pipe(iload_reg_mem);
 7017 %}
 7018 
 7019 // Load Long (64 bit signed)
 7020 instruct loadL(iRegLNoSp dst, memory8 mem)
 7021 %{
 7022   match(Set dst (LoadL mem));
 7023   predicate(!needs_acquiring_load(n));
 7024 
 7025   ins_cost(4 * INSN_COST);
 7026   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7027 
 7028   ins_encode(aarch64_enc_ldr(dst, mem));
 7029 
 7030   ins_pipe(iload_reg_mem);
 7031 %}
 7032 
 7033 // Load Range
 7034 instruct loadRange(iRegINoSp dst, memory4 mem)
 7035 %{
 7036   match(Set dst (LoadRange mem));
 7037 
 7038   ins_cost(4 * INSN_COST);
 7039   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7040 
 7041   ins_encode(aarch64_enc_ldrw(dst, mem));
 7042 
 7043   ins_pipe(iload_reg_mem);
 7044 %}
 7045 
 7046 // Load Pointer
 7047 instruct loadP(iRegPNoSp dst, memory8 mem)
 7048 %{
 7049   match(Set dst (LoadP mem));
 7050   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7051 
 7052   ins_cost(4 * INSN_COST);
 7053   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7054 
 7055   ins_encode(aarch64_enc_ldr(dst, mem));
 7056 
 7057   ins_pipe(iload_reg_mem);
 7058 %}
 7059 
 7060 // Load Compressed Pointer
 7061 instruct loadN(iRegNNoSp dst, memory4 mem)
 7062 %{
 7063   match(Set dst (LoadN mem));
 7064   predicate(!needs_acquiring_load(n));
 7065 
 7066   ins_cost(4 * INSN_COST);
 7067   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7068 
 7069   ins_encode(aarch64_enc_ldrw(dst, mem));
 7070 
 7071   ins_pipe(iload_reg_mem);
 7072 %}
 7073 
 7074 // Load Klass Pointer
 7075 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7076 %{
 7077   match(Set dst (LoadKlass mem));
 7078   predicate(!needs_acquiring_load(n));
 7079 
 7080   ins_cost(4 * INSN_COST);
 7081   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7082 
 7083   ins_encode(aarch64_enc_ldr(dst, mem));
 7084 
 7085   ins_pipe(iload_reg_mem);
 7086 %}
 7087 
 7088 // Load Narrow Klass Pointer
 7089 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7090 %{
 7091   match(Set dst (LoadNKlass mem));
 7092   predicate(!needs_acquiring_load(n));
 7093 
 7094   ins_cost(4 * INSN_COST);
 7095   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7096 
 7097   ins_encode(aarch64_enc_ldrw(dst, mem));
 7098 
 7099   ins_pipe(iload_reg_mem);
 7100 %}
 7101 
 7102 // Load Float
 7103 instruct loadF(vRegF dst, memory4 mem)
 7104 %{
 7105   match(Set dst (LoadF mem));
 7106   predicate(!needs_acquiring_load(n));
 7107 
 7108   ins_cost(4 * INSN_COST);
 7109   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7110 
 7111   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7112 
 7113   ins_pipe(pipe_class_memory);
 7114 %}
 7115 
 7116 // Load Double
 7117 instruct loadD(vRegD dst, memory8 mem)
 7118 %{
 7119   match(Set dst (LoadD mem));
 7120   predicate(!needs_acquiring_load(n));
 7121 
 7122   ins_cost(4 * INSN_COST);
 7123   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7124 
 7125   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7126 
 7127   ins_pipe(pipe_class_memory);
 7128 %}
 7129 
 7130 
 7131 // Load Int Constant
 7132 instruct loadConI(iRegINoSp dst, immI src)
 7133 %{
 7134   match(Set dst src);
 7135 
 7136   ins_cost(INSN_COST);
 7137   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7138 
 7139   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7140 
 7141   ins_pipe(ialu_imm);
 7142 %}
 7143 
 7144 // Load Long Constant
 7145 instruct loadConL(iRegLNoSp dst, immL src)
 7146 %{
 7147   match(Set dst src);
 7148 
 7149   ins_cost(INSN_COST);
 7150   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7151 
 7152   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7153 
 7154   ins_pipe(ialu_imm);
 7155 %}
 7156 
 7157 // Load Pointer Constant
 7158 
 7159 instruct loadConP(iRegPNoSp dst, immP con)
 7160 %{
 7161   match(Set dst con);
 7162 
 7163   ins_cost(INSN_COST * 4);
 7164   format %{
 7165     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7166   %}
 7167 
 7168   ins_encode(aarch64_enc_mov_p(dst, con));
 7169 
 7170   ins_pipe(ialu_imm);
 7171 %}
 7172 
 7173 // Load Null Pointer Constant
 7174 
 7175 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7176 %{
 7177   match(Set dst con);
 7178 
 7179   ins_cost(INSN_COST);
 7180   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7181 
 7182   ins_encode(aarch64_enc_mov_p0(dst, con));
 7183 
 7184   ins_pipe(ialu_imm);
 7185 %}
 7186 
 7187 // Load Pointer Constant One
 7188 
 7189 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7190 %{
 7191   match(Set dst con);
 7192 
 7193   ins_cost(INSN_COST);
 7194   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7195 
 7196   ins_encode(aarch64_enc_mov_p1(dst, con));
 7197 
 7198   ins_pipe(ialu_imm);
 7199 %}
 7200 
 7201 // Load Poll Page Constant
 7202 
 7203 instruct loadConPollPage(iRegPNoSp dst, immPollPage con)
 7204 %{
 7205   match(Set dst con);
 7206 
 7207   ins_cost(INSN_COST);
 7208   format %{ &quot;adr  $dst, $con\t# Poll Page Ptr&quot; %}
 7209 
 7210   ins_encode(aarch64_enc_mov_poll_page(dst, con));
 7211 
 7212   ins_pipe(ialu_imm);
 7213 %}
 7214 
 7215 // Load Byte Map Base Constant
 7216 
 7217 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7218 %{
 7219   match(Set dst con);
 7220 
 7221   ins_cost(INSN_COST);
 7222   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7223 
 7224   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7225 
 7226   ins_pipe(ialu_imm);
 7227 %}
 7228 
 7229 // Load Narrow Pointer Constant
 7230 
 7231 instruct loadConN(iRegNNoSp dst, immN con)
 7232 %{
 7233   match(Set dst con);
 7234 
 7235   ins_cost(INSN_COST * 4);
 7236   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7237 
 7238   ins_encode(aarch64_enc_mov_n(dst, con));
 7239 
 7240   ins_pipe(ialu_imm);
 7241 %}
 7242 
 7243 // Load Narrow Null Pointer Constant
 7244 
 7245 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7246 %{
 7247   match(Set dst con);
 7248 
 7249   ins_cost(INSN_COST);
 7250   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7251 
 7252   ins_encode(aarch64_enc_mov_n0(dst, con));
 7253 
 7254   ins_pipe(ialu_imm);
 7255 %}
 7256 
 7257 // Load Narrow Klass Constant
 7258 
 7259 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7260 %{
 7261   match(Set dst con);
 7262 
 7263   ins_cost(INSN_COST);
 7264   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7265 
 7266   ins_encode(aarch64_enc_mov_nk(dst, con));
 7267 
 7268   ins_pipe(ialu_imm);
 7269 %}
 7270 
 7271 // Load Packed Float Constant
 7272 
 7273 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7274   match(Set dst con);
 7275   ins_cost(INSN_COST * 4);
 7276   format %{ &quot;fmovs  $dst, $con&quot;%}
 7277   ins_encode %{
 7278     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7279   %}
 7280 
 7281   ins_pipe(fp_imm_s);
 7282 %}
 7283 
 7284 // Load Float Constant
 7285 
 7286 instruct loadConF(vRegF dst, immF con) %{
 7287   match(Set dst con);
 7288 
 7289   ins_cost(INSN_COST * 4);
 7290 
 7291   format %{
 7292     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7293   %}
 7294 
 7295   ins_encode %{
 7296     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7297   %}
 7298 
 7299   ins_pipe(fp_load_constant_s);
 7300 %}
 7301 
 7302 // Load Packed Double Constant
 7303 
 7304 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7305   match(Set dst con);
 7306   ins_cost(INSN_COST);
 7307   format %{ &quot;fmovd  $dst, $con&quot;%}
 7308   ins_encode %{
 7309     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7310   %}
 7311 
 7312   ins_pipe(fp_imm_d);
 7313 %}
 7314 
 7315 // Load Double Constant
 7316 
 7317 instruct loadConD(vRegD dst, immD con) %{
 7318   match(Set dst con);
 7319 
 7320   ins_cost(INSN_COST * 5);
 7321   format %{
 7322     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7323   %}
 7324 
 7325   ins_encode %{
 7326     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7327   %}
 7328 
 7329   ins_pipe(fp_load_constant_d);
 7330 %}
 7331 
 7332 // Store Instructions
 7333 
 7334 // Store CMS card-mark Immediate
 7335 instruct storeimmCM0(immI0 zero, memory1 mem)
 7336 %{
 7337   match(Set mem (StoreCM mem zero));
 7338 
 7339   ins_cost(INSN_COST);
 7340   format %{ &quot;storestore (elided)\n\t&quot;
 7341             &quot;strb zr, $mem\t# byte&quot; %}
 7342 
 7343   ins_encode(aarch64_enc_strb0(mem));
 7344 
 7345   ins_pipe(istore_mem);
 7346 %}
 7347 
 7348 // Store CMS card-mark Immediate with intervening StoreStore
 7349 // needed when using CMS with no conditional card marking
 7350 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7351 %{
 7352   match(Set mem (StoreCM mem zero));
 7353 
 7354   ins_cost(INSN_COST * 2);
 7355   format %{ &quot;storestore\n\t&quot;
 7356             &quot;dmb ishst&quot;
 7357             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7358 
 7359   ins_encode(aarch64_enc_strb0_ordered(mem));
 7360 
 7361   ins_pipe(istore_mem);
 7362 %}
 7363 
 7364 // Store Byte
 7365 instruct storeB(iRegIorL2I src, memory1 mem)
 7366 %{
 7367   match(Set mem (StoreB mem src));
 7368   predicate(!needs_releasing_store(n));
 7369 
 7370   ins_cost(INSN_COST);
 7371   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7372 
 7373   ins_encode(aarch64_enc_strb(src, mem));
 7374 
 7375   ins_pipe(istore_reg_mem);
 7376 %}
 7377 
 7378 
 7379 instruct storeimmB0(immI0 zero, memory1 mem)
 7380 %{
 7381   match(Set mem (StoreB mem zero));
 7382   predicate(!needs_releasing_store(n));
 7383 
 7384   ins_cost(INSN_COST);
 7385   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7386 
 7387   ins_encode(aarch64_enc_strb0(mem));
 7388 
 7389   ins_pipe(istore_mem);
 7390 %}
 7391 
 7392 // Store Char/Short
 7393 instruct storeC(iRegIorL2I src, memory2 mem)
 7394 %{
 7395   match(Set mem (StoreC mem src));
 7396   predicate(!needs_releasing_store(n));
 7397 
 7398   ins_cost(INSN_COST);
 7399   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7400 
 7401   ins_encode(aarch64_enc_strh(src, mem));
 7402 
 7403   ins_pipe(istore_reg_mem);
 7404 %}
 7405 
 7406 instruct storeimmC0(immI0 zero, memory2 mem)
 7407 %{
 7408   match(Set mem (StoreC mem zero));
 7409   predicate(!needs_releasing_store(n));
 7410 
 7411   ins_cost(INSN_COST);
 7412   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7413 
 7414   ins_encode(aarch64_enc_strh0(mem));
 7415 
 7416   ins_pipe(istore_mem);
 7417 %}
 7418 
 7419 // Store Integer
 7420 
 7421 instruct storeI(iRegIorL2I src, memory4 mem)
 7422 %{
 7423   match(Set mem(StoreI mem src));
 7424   predicate(!needs_releasing_store(n));
 7425 
 7426   ins_cost(INSN_COST);
 7427   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7428 
 7429   ins_encode(aarch64_enc_strw(src, mem));
 7430 
 7431   ins_pipe(istore_reg_mem);
 7432 %}
 7433 
 7434 instruct storeimmI0(immI0 zero, memory4 mem)
 7435 %{
 7436   match(Set mem(StoreI mem zero));
 7437   predicate(!needs_releasing_store(n));
 7438 
 7439   ins_cost(INSN_COST);
 7440   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7441 
 7442   ins_encode(aarch64_enc_strw0(mem));
 7443 
 7444   ins_pipe(istore_mem);
 7445 %}
 7446 
 7447 // Store Long (64 bit signed)
 7448 instruct storeL(iRegL src, memory8 mem)
 7449 %{
 7450   match(Set mem (StoreL mem src));
 7451   predicate(!needs_releasing_store(n));
 7452 
 7453   ins_cost(INSN_COST);
 7454   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7455 
 7456   ins_encode(aarch64_enc_str(src, mem));
 7457 
 7458   ins_pipe(istore_reg_mem);
 7459 %}
 7460 
 7461 // Store Long (64 bit signed)
 7462 instruct storeimmL0(immL0 zero, memory8 mem)
 7463 %{
 7464   match(Set mem (StoreL mem zero));
 7465   predicate(!needs_releasing_store(n));
 7466 
 7467   ins_cost(INSN_COST);
 7468   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7469 
 7470   ins_encode(aarch64_enc_str0(mem));
 7471 
 7472   ins_pipe(istore_mem);
 7473 %}
 7474 
 7475 // Store Pointer
 7476 instruct storeP(iRegP src, memory8 mem)
 7477 %{
 7478   match(Set mem (StoreP mem src));
 7479   predicate(!needs_releasing_store(n));
 7480 
 7481   ins_cost(INSN_COST);
 7482   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7483 
 7484   ins_encode(aarch64_enc_str(src, mem));
 7485 
 7486   ins_pipe(istore_reg_mem);
 7487 %}
 7488 
 7489 // Store Pointer
 7490 instruct storeimmP0(immP0 zero, memory8 mem)
 7491 %{
 7492   match(Set mem (StoreP mem zero));
 7493   predicate(!needs_releasing_store(n));
 7494 
 7495   ins_cost(INSN_COST);
 7496   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7497 
 7498   ins_encode(aarch64_enc_str0(mem));
 7499 
 7500   ins_pipe(istore_mem);
 7501 %}
 7502 
 7503 // Store Compressed Pointer
 7504 instruct storeN(iRegN src, memory4 mem)
 7505 %{
 7506   match(Set mem (StoreN mem src));
 7507   predicate(!needs_releasing_store(n));
 7508 
 7509   ins_cost(INSN_COST);
 7510   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7511 
 7512   ins_encode(aarch64_enc_strw(src, mem));
 7513 
 7514   ins_pipe(istore_reg_mem);
 7515 %}
 7516 
 7517 instruct storeImmN0(iRegIHeapbase heapbase, immN0 zero, memory4 mem)
 7518 %{
 7519   match(Set mem (StoreN mem zero));
 7520   predicate(CompressedOops::base() == NULL &amp;&amp;
 7521             CompressedKlassPointers::base() == NULL &amp;&amp;
 7522             (!needs_releasing_store(n)));
 7523 
 7524   ins_cost(INSN_COST);
 7525   format %{ &quot;strw  rheapbase, $mem\t# compressed ptr (rheapbase==0)&quot; %}
 7526 
 7527   ins_encode(aarch64_enc_strw(heapbase, mem));
 7528 
 7529   ins_pipe(istore_reg_mem);
 7530 %}
 7531 
 7532 // Store Float
 7533 instruct storeF(vRegF src, memory4 mem)
 7534 %{
 7535   match(Set mem (StoreF mem src));
 7536   predicate(!needs_releasing_store(n));
 7537 
 7538   ins_cost(INSN_COST);
 7539   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7540 
 7541   ins_encode( aarch64_enc_strs(src, mem) );
 7542 
 7543   ins_pipe(pipe_class_memory);
 7544 %}
 7545 
 7546 // TODO
 7547 // implement storeImmF0 and storeFImmPacked
 7548 
 7549 // Store Double
 7550 instruct storeD(vRegD src, memory8 mem)
 7551 %{
 7552   match(Set mem (StoreD mem src));
 7553   predicate(!needs_releasing_store(n));
 7554 
 7555   ins_cost(INSN_COST);
 7556   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7557 
 7558   ins_encode( aarch64_enc_strd(src, mem) );
 7559 
 7560   ins_pipe(pipe_class_memory);
 7561 %}
 7562 
 7563 // Store Compressed Klass Pointer
 7564 instruct storeNKlass(iRegN src, memory4 mem)
 7565 %{
 7566   predicate(!needs_releasing_store(n));
 7567   match(Set mem (StoreNKlass mem src));
 7568 
 7569   ins_cost(INSN_COST);
 7570   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7571 
 7572   ins_encode(aarch64_enc_strw(src, mem));
 7573 
 7574   ins_pipe(istore_reg_mem);
 7575 %}
 7576 
 7577 // TODO
 7578 // implement storeImmD0 and storeDImmPacked
 7579 
 7580 // prefetch instructions
 7581 // Must be safe to execute with invalid address (cannot fault).
 7582 
 7583 instruct prefetchalloc( memory8 mem ) %{
 7584   match(PrefetchAllocation mem);
 7585 
 7586   ins_cost(INSN_COST);
 7587   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7588 
 7589   ins_encode( aarch64_enc_prefetchw(mem) );
 7590 
 7591   ins_pipe(iload_prefetch);
 7592 %}
 7593 
 7594 //  ---------------- volatile loads and stores ----------------
 7595 
 7596 // Load Byte (8 bit signed)
 7597 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7598 %{
 7599   match(Set dst (LoadB mem));
 7600 
 7601   ins_cost(VOLATILE_REF_COST);
 7602   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7603 
 7604   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7605 
 7606   ins_pipe(pipe_serial);
 7607 %}
 7608 
 7609 // Load Byte (8 bit signed) into long
 7610 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7611 %{
 7612   match(Set dst (ConvI2L (LoadB mem)));
 7613 
 7614   ins_cost(VOLATILE_REF_COST);
 7615   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7616 
 7617   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7618 
 7619   ins_pipe(pipe_serial);
 7620 %}
 7621 
 7622 // Load Byte (8 bit unsigned)
 7623 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7624 %{
 7625   match(Set dst (LoadUB mem));
 7626 
 7627   ins_cost(VOLATILE_REF_COST);
 7628   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7629 
 7630   ins_encode(aarch64_enc_ldarb(dst, mem));
 7631 
 7632   ins_pipe(pipe_serial);
 7633 %}
 7634 
 7635 // Load Byte (8 bit unsigned) into long
 7636 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7637 %{
 7638   match(Set dst (ConvI2L (LoadUB mem)));
 7639 
 7640   ins_cost(VOLATILE_REF_COST);
 7641   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7642 
 7643   ins_encode(aarch64_enc_ldarb(dst, mem));
 7644 
 7645   ins_pipe(pipe_serial);
 7646 %}
 7647 
 7648 // Load Short (16 bit signed)
 7649 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7650 %{
 7651   match(Set dst (LoadS mem));
 7652 
 7653   ins_cost(VOLATILE_REF_COST);
 7654   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7655 
 7656   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7657 
 7658   ins_pipe(pipe_serial);
 7659 %}
 7660 
 7661 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7662 %{
 7663   match(Set dst (LoadUS mem));
 7664 
 7665   ins_cost(VOLATILE_REF_COST);
 7666   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7667 
 7668   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7669 
 7670   ins_pipe(pipe_serial);
 7671 %}
 7672 
 7673 // Load Short/Char (16 bit unsigned) into long
 7674 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7675 %{
 7676   match(Set dst (ConvI2L (LoadUS mem)));
 7677 
 7678   ins_cost(VOLATILE_REF_COST);
 7679   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7680 
 7681   ins_encode(aarch64_enc_ldarh(dst, mem));
 7682 
 7683   ins_pipe(pipe_serial);
 7684 %}
 7685 
 7686 // Load Short/Char (16 bit signed) into long
 7687 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7688 %{
 7689   match(Set dst (ConvI2L (LoadS mem)));
 7690 
 7691   ins_cost(VOLATILE_REF_COST);
 7692   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7693 
 7694   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7695 
 7696   ins_pipe(pipe_serial);
 7697 %}
 7698 
 7699 // Load Integer (32 bit signed)
 7700 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7701 %{
 7702   match(Set dst (LoadI mem));
 7703 
 7704   ins_cost(VOLATILE_REF_COST);
 7705   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7706 
 7707   ins_encode(aarch64_enc_ldarw(dst, mem));
 7708 
 7709   ins_pipe(pipe_serial);
 7710 %}
 7711 
 7712 // Load Integer (32 bit unsigned) into long
 7713 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7714 %{
 7715   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7716 
 7717   ins_cost(VOLATILE_REF_COST);
 7718   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7719 
 7720   ins_encode(aarch64_enc_ldarw(dst, mem));
 7721 
 7722   ins_pipe(pipe_serial);
 7723 %}
 7724 
 7725 // Load Long (64 bit signed)
 7726 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7727 %{
 7728   match(Set dst (LoadL mem));
 7729 
 7730   ins_cost(VOLATILE_REF_COST);
 7731   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7732 
 7733   ins_encode(aarch64_enc_ldar(dst, mem));
 7734 
 7735   ins_pipe(pipe_serial);
 7736 %}
 7737 
 7738 // Load Pointer
 7739 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7740 %{
 7741   match(Set dst (LoadP mem));
 7742   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7743 
 7744   ins_cost(VOLATILE_REF_COST);
 7745   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7746 
 7747   ins_encode(aarch64_enc_ldar(dst, mem));
 7748 
 7749   ins_pipe(pipe_serial);
 7750 %}
 7751 
 7752 // Load Compressed Pointer
 7753 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7754 %{
 7755   match(Set dst (LoadN mem));
 7756 
 7757   ins_cost(VOLATILE_REF_COST);
 7758   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7759 
 7760   ins_encode(aarch64_enc_ldarw(dst, mem));
 7761 
 7762   ins_pipe(pipe_serial);
 7763 %}
 7764 
 7765 // Load Float
 7766 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7767 %{
 7768   match(Set dst (LoadF mem));
 7769 
 7770   ins_cost(VOLATILE_REF_COST);
 7771   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7772 
 7773   ins_encode( aarch64_enc_fldars(dst, mem) );
 7774 
 7775   ins_pipe(pipe_serial);
 7776 %}
 7777 
 7778 // Load Double
 7779 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7780 %{
 7781   match(Set dst (LoadD mem));
 7782 
 7783   ins_cost(VOLATILE_REF_COST);
 7784   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7785 
 7786   ins_encode( aarch64_enc_fldard(dst, mem) );
 7787 
 7788   ins_pipe(pipe_serial);
 7789 %}
 7790 
 7791 // Store Byte
 7792 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7793 %{
 7794   match(Set mem (StoreB mem src));
 7795 
 7796   ins_cost(VOLATILE_REF_COST);
 7797   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7798 
 7799   ins_encode(aarch64_enc_stlrb(src, mem));
 7800 
 7801   ins_pipe(pipe_class_memory);
 7802 %}
 7803 
 7804 // Store Char/Short
 7805 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7806 %{
 7807   match(Set mem (StoreC mem src));
 7808 
 7809   ins_cost(VOLATILE_REF_COST);
 7810   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7811 
 7812   ins_encode(aarch64_enc_stlrh(src, mem));
 7813 
 7814   ins_pipe(pipe_class_memory);
 7815 %}
 7816 
 7817 // Store Integer
 7818 
 7819 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7820 %{
 7821   match(Set mem(StoreI mem src));
 7822 
 7823   ins_cost(VOLATILE_REF_COST);
 7824   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7825 
 7826   ins_encode(aarch64_enc_stlrw(src, mem));
 7827 
 7828   ins_pipe(pipe_class_memory);
 7829 %}
 7830 
 7831 // Store Long (64 bit signed)
 7832 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7833 %{
 7834   match(Set mem (StoreL mem src));
 7835 
 7836   ins_cost(VOLATILE_REF_COST);
 7837   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7838 
 7839   ins_encode(aarch64_enc_stlr(src, mem));
 7840 
 7841   ins_pipe(pipe_class_memory);
 7842 %}
 7843 
 7844 // Store Pointer
 7845 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7846 %{
 7847   match(Set mem (StoreP mem src));
 7848 
 7849   ins_cost(VOLATILE_REF_COST);
 7850   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7851 
 7852   ins_encode(aarch64_enc_stlr(src, mem));
 7853 
 7854   ins_pipe(pipe_class_memory);
 7855 %}
 7856 
 7857 // Store Compressed Pointer
 7858 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7859 %{
 7860   match(Set mem (StoreN mem src));
 7861 
 7862   ins_cost(VOLATILE_REF_COST);
 7863   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7864 
 7865   ins_encode(aarch64_enc_stlrw(src, mem));
 7866 
 7867   ins_pipe(pipe_class_memory);
 7868 %}
 7869 
 7870 // Store Float
 7871 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7872 %{
 7873   match(Set mem (StoreF mem src));
 7874 
 7875   ins_cost(VOLATILE_REF_COST);
 7876   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7877 
 7878   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7879 
 7880   ins_pipe(pipe_class_memory);
 7881 %}
 7882 
 7883 // TODO
 7884 // implement storeImmF0 and storeFImmPacked
 7885 
 7886 // Store Double
 7887 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7888 %{
 7889   match(Set mem (StoreD mem src));
 7890 
 7891   ins_cost(VOLATILE_REF_COST);
 7892   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7893 
 7894   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7895 
 7896   ins_pipe(pipe_class_memory);
 7897 %}
 7898 
 7899 //  ---------------- end of volatile loads and stores ----------------
 7900 
 7901 instruct cacheWB(indirect addr)
 7902 %{
 7903   predicate(VM_Version::supports_data_cache_line_flush());
 7904   match(CacheWB addr);
 7905 
 7906   ins_cost(100);
 7907   format %{&quot;cache wb $addr&quot; %}
 7908   ins_encode %{
 7909     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7910     assert($addr$$disp == 0, &quot;should be&quot;);
 7911     __ cache_wb(Address($addr$$base$$Register, 0));
 7912   %}
 7913   ins_pipe(pipe_slow); // XXX
 7914 %}
 7915 
 7916 instruct cacheWBPreSync()
 7917 %{
 7918   predicate(VM_Version::supports_data_cache_line_flush());
 7919   match(CacheWBPreSync);
 7920 
 7921   ins_cost(100);
 7922   format %{&quot;cache wb presync&quot; %}
 7923   ins_encode %{
 7924     __ cache_wbsync(true);
 7925   %}
 7926   ins_pipe(pipe_slow); // XXX
 7927 %}
 7928 
 7929 instruct cacheWBPostSync()
 7930 %{
 7931   predicate(VM_Version::supports_data_cache_line_flush());
 7932   match(CacheWBPostSync);
 7933 
 7934   ins_cost(100);
 7935   format %{&quot;cache wb postsync&quot; %}
 7936   ins_encode %{
 7937     __ cache_wbsync(false);
 7938   %}
 7939   ins_pipe(pipe_slow); // XXX
 7940 %}
 7941 
 7942 // ============================================================================
 7943 // BSWAP Instructions
 7944 
 7945 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7946   match(Set dst (ReverseBytesI src));
 7947 
 7948   ins_cost(INSN_COST);
 7949   format %{ &quot;revw  $dst, $src&quot; %}
 7950 
 7951   ins_encode %{
 7952     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7953   %}
 7954 
 7955   ins_pipe(ialu_reg);
 7956 %}
 7957 
 7958 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7959   match(Set dst (ReverseBytesL src));
 7960 
 7961   ins_cost(INSN_COST);
 7962   format %{ &quot;rev  $dst, $src&quot; %}
 7963 
 7964   ins_encode %{
 7965     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7966   %}
 7967 
 7968   ins_pipe(ialu_reg);
 7969 %}
 7970 
 7971 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7972   match(Set dst (ReverseBytesUS src));
 7973 
 7974   ins_cost(INSN_COST);
 7975   format %{ &quot;rev16w  $dst, $src&quot; %}
 7976 
 7977   ins_encode %{
 7978     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7979   %}
 7980 
 7981   ins_pipe(ialu_reg);
 7982 %}
 7983 
 7984 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7985   match(Set dst (ReverseBytesS src));
 7986 
 7987   ins_cost(INSN_COST);
 7988   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7989             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7990 
 7991   ins_encode %{
 7992     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7993     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7994   %}
 7995 
 7996   ins_pipe(ialu_reg);
 7997 %}
 7998 
 7999 // ============================================================================
 8000 // Zero Count Instructions
 8001 
 8002 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8003   match(Set dst (CountLeadingZerosI src));
 8004 
 8005   ins_cost(INSN_COST);
 8006   format %{ &quot;clzw  $dst, $src&quot; %}
 8007   ins_encode %{
 8008     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 8009   %}
 8010 
 8011   ins_pipe(ialu_reg);
 8012 %}
 8013 
 8014 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 8015   match(Set dst (CountLeadingZerosL src));
 8016 
 8017   ins_cost(INSN_COST);
 8018   format %{ &quot;clz   $dst, $src&quot; %}
 8019   ins_encode %{
 8020     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 8021   %}
 8022 
 8023   ins_pipe(ialu_reg);
 8024 %}
 8025 
 8026 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8027   match(Set dst (CountTrailingZerosI src));
 8028 
 8029   ins_cost(INSN_COST * 2);
 8030   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8031             &quot;clzw   $dst, $dst&quot; %}
 8032   ins_encode %{
 8033     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8034     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8035   %}
 8036 
 8037   ins_pipe(ialu_reg);
 8038 %}
 8039 
 8040 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8041   match(Set dst (CountTrailingZerosL src));
 8042 
 8043   ins_cost(INSN_COST * 2);
 8044   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8045             &quot;clz    $dst, $dst&quot; %}
 8046   ins_encode %{
 8047     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8048     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8049   %}
 8050 
 8051   ins_pipe(ialu_reg);
 8052 %}
 8053 
 8054 //---------- Population Count Instructions -------------------------------------
 8055 //
 8056 
 8057 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8058   predicate(UsePopCountInstruction);
 8059   match(Set dst (PopCountI src));
 8060   effect(TEMP tmp);
 8061   ins_cost(INSN_COST * 13);
 8062 
 8063   format %{ &quot;movw   $src, $src\n\t&quot;
 8064             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8065             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8066             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8067             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8068   ins_encode %{
 8069     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8070     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8071     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8072     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8073     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8074   %}
 8075 
 8076   ins_pipe(pipe_class_default);
 8077 %}
 8078 
 8079 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8080   predicate(UsePopCountInstruction);
 8081   match(Set dst (PopCountI (LoadI mem)));
 8082   effect(TEMP tmp);
 8083   ins_cost(INSN_COST * 13);
 8084 
 8085   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8086             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8087             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8088             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8089   ins_encode %{
 8090     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<a name="112" id="anc112"></a><span class="line-modified"> 8091     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),</span>
 8092               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8093     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8094     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8095     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8096   %}
 8097 
 8098   ins_pipe(pipe_class_default);
 8099 %}
 8100 
 8101 // Note: Long.bitCount(long) returns an int.
 8102 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8103   predicate(UsePopCountInstruction);
 8104   match(Set dst (PopCountL src));
 8105   effect(TEMP tmp);
 8106   ins_cost(INSN_COST * 13);
 8107 
 8108   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8109             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8110             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8111             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8112   ins_encode %{
 8113     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8114     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8115     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8116     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8117   %}
 8118 
 8119   ins_pipe(pipe_class_default);
 8120 %}
 8121 
 8122 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8123   predicate(UsePopCountInstruction);
 8124   match(Set dst (PopCountL (LoadL mem)));
 8125   effect(TEMP tmp);
 8126   ins_cost(INSN_COST * 13);
 8127 
 8128   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8129             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8130             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8131             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8132   ins_encode %{
 8133     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<a name="113" id="anc113"></a><span class="line-modified"> 8134     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),</span>
 8135               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8136     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8137     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8138     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8139   %}
 8140 
 8141   ins_pipe(pipe_class_default);
 8142 %}
 8143 
 8144 // ============================================================================
 8145 // MemBar Instruction
 8146 
 8147 instruct load_fence() %{
 8148   match(LoadFence);
 8149   ins_cost(VOLATILE_REF_COST);
 8150 
 8151   format %{ &quot;load_fence&quot; %}
 8152 
 8153   ins_encode %{
 8154     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8155   %}
 8156   ins_pipe(pipe_serial);
 8157 %}
 8158 
 8159 instruct unnecessary_membar_acquire() %{
 8160   predicate(unnecessary_acquire(n));
 8161   match(MemBarAcquire);
 8162   ins_cost(0);
 8163 
 8164   format %{ &quot;membar_acquire (elided)&quot; %}
 8165 
 8166   ins_encode %{
 8167     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8168   %}
 8169 
 8170   ins_pipe(pipe_class_empty);
 8171 %}
 8172 
 8173 instruct membar_acquire() %{
 8174   match(MemBarAcquire);
 8175   ins_cost(VOLATILE_REF_COST);
 8176 
 8177   format %{ &quot;membar_acquire\n\t&quot;
 8178             &quot;dmb ish&quot; %}
 8179 
 8180   ins_encode %{
 8181     __ block_comment(&quot;membar_acquire&quot;);
 8182     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8183   %}
 8184 
 8185   ins_pipe(pipe_serial);
 8186 %}
 8187 
 8188 
 8189 instruct membar_acquire_lock() %{
 8190   match(MemBarAcquireLock);
 8191   ins_cost(VOLATILE_REF_COST);
 8192 
 8193   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8194 
 8195   ins_encode %{
 8196     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8197   %}
 8198 
 8199   ins_pipe(pipe_serial);
 8200 %}
 8201 
 8202 instruct store_fence() %{
 8203   match(StoreFence);
 8204   ins_cost(VOLATILE_REF_COST);
 8205 
 8206   format %{ &quot;store_fence&quot; %}
 8207 
 8208   ins_encode %{
 8209     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8210   %}
 8211   ins_pipe(pipe_serial);
 8212 %}
 8213 
 8214 instruct unnecessary_membar_release() %{
 8215   predicate(unnecessary_release(n));
 8216   match(MemBarRelease);
 8217   ins_cost(0);
 8218 
 8219   format %{ &quot;membar_release (elided)&quot; %}
 8220 
 8221   ins_encode %{
 8222     __ block_comment(&quot;membar_release (elided)&quot;);
 8223   %}
 8224   ins_pipe(pipe_serial);
 8225 %}
 8226 
 8227 instruct membar_release() %{
 8228   match(MemBarRelease);
 8229   ins_cost(VOLATILE_REF_COST);
 8230 
 8231   format %{ &quot;membar_release\n\t&quot;
 8232             &quot;dmb ish&quot; %}
 8233 
 8234   ins_encode %{
 8235     __ block_comment(&quot;membar_release&quot;);
 8236     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8237   %}
 8238   ins_pipe(pipe_serial);
 8239 %}
 8240 
 8241 instruct membar_storestore() %{
 8242   match(MemBarStoreStore);
 8243   ins_cost(VOLATILE_REF_COST);
 8244 
 8245   format %{ &quot;MEMBAR-store-store&quot; %}
 8246 
 8247   ins_encode %{
 8248     __ membar(Assembler::StoreStore);
 8249   %}
 8250   ins_pipe(pipe_serial);
 8251 %}
 8252 
 8253 instruct membar_release_lock() %{
 8254   match(MemBarReleaseLock);
 8255   ins_cost(VOLATILE_REF_COST);
 8256 
 8257   format %{ &quot;membar_release_lock (elided)&quot; %}
 8258 
 8259   ins_encode %{
 8260     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8261   %}
 8262 
 8263   ins_pipe(pipe_serial);
 8264 %}
 8265 
 8266 instruct unnecessary_membar_volatile() %{
 8267   predicate(unnecessary_volatile(n));
 8268   match(MemBarVolatile);
 8269   ins_cost(0);
 8270 
 8271   format %{ &quot;membar_volatile (elided)&quot; %}
 8272 
 8273   ins_encode %{
 8274     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8275   %}
 8276 
 8277   ins_pipe(pipe_serial);
 8278 %}
 8279 
 8280 instruct membar_volatile() %{
 8281   match(MemBarVolatile);
 8282   ins_cost(VOLATILE_REF_COST*100);
 8283 
 8284   format %{ &quot;membar_volatile\n\t&quot;
 8285              &quot;dmb ish&quot;%}
 8286 
 8287   ins_encode %{
 8288     __ block_comment(&quot;membar_volatile&quot;);
 8289     __ membar(Assembler::StoreLoad);
 8290   %}
 8291 
 8292   ins_pipe(pipe_serial);
 8293 %}
 8294 
 8295 // ============================================================================
 8296 // Cast/Convert Instructions
 8297 
 8298 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8299   match(Set dst (CastX2P src));
 8300 
 8301   ins_cost(INSN_COST);
 8302   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8303 
 8304   ins_encode %{
 8305     if ($dst$$reg != $src$$reg) {
 8306       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8307     }
 8308   %}
 8309 
 8310   ins_pipe(ialu_reg);
 8311 %}
 8312 
 8313 instruct castN2X(iRegLNoSp dst, iRegN src) %{
 8314   match(Set dst (CastP2X src));
 8315 
 8316   ins_cost(INSN_COST);
 8317   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8318 
 8319   ins_encode %{
 8320     if ($dst$$reg != $src$$reg) {
 8321       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8322     }
 8323   %}
 8324 
 8325   ins_pipe(ialu_reg);
 8326 %}
 8327 
 8328 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8329   match(Set dst (CastP2X src));
 8330 
 8331   ins_cost(INSN_COST);
 8332   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8333 
 8334   ins_encode %{
 8335     if ($dst$$reg != $src$$reg) {
 8336       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8337     }
 8338   %}
 8339 
 8340   ins_pipe(ialu_reg);
 8341 %}
 8342 
 8343 instruct castN2I(iRegINoSp dst, iRegN src) %{
 8344   match(Set dst (CastN2I src));
 8345 
 8346   ins_cost(INSN_COST);
 8347   format %{ &quot;movw $dst, $src\t# compressed ptr -&gt; int&quot; %}
 8348 
 8349   ins_encode %{
 8350     if ($dst$$reg != $src$$reg) {
 8351       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8352     }
 8353   %}
 8354 
 8355   ins_pipe(ialu_reg);
 8356 %}
 8357 
 8358 instruct castI2N(iRegNNoSp dst, iRegI src) %{
 8359   match(Set dst (CastI2N src));
 8360 
 8361   ins_cost(INSN_COST);
 8362   format %{ &quot;movw $dst, $src\t# int -&gt; compressed ptr&quot; %}
 8363 
 8364   ins_encode %{
 8365     if ($dst$$reg != $src$$reg) {
 8366       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8367     }
 8368   %}
 8369 
 8370   ins_pipe(ialu_reg);
 8371 %}
 8372 
 8373 
 8374 // Convert oop into int for vectors alignment masking
 8375 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8376   match(Set dst (ConvL2I (CastP2X src)));
 8377 
 8378   ins_cost(INSN_COST);
 8379   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8380   ins_encode %{
 8381     __ movw($dst$$Register, $src$$Register);
 8382   %}
 8383 
 8384   ins_pipe(ialu_reg);
 8385 %}
 8386 
 8387 // Convert compressed oop into int for vectors alignment masking
 8388 // in case of 32bit oops (heap &lt; 4Gb).
 8389 instruct convN2I(iRegINoSp dst, iRegN src)
 8390 %{
 8391   predicate(CompressedOops::shift() == 0);
 8392   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8393 
 8394   ins_cost(INSN_COST);
 8395   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8396   ins_encode %{
 8397     __ movw($dst$$Register, $src$$Register);
 8398   %}
 8399 
 8400   ins_pipe(ialu_reg);
 8401 %}
 8402 
 8403 
 8404 // Convert oop pointer into compressed form
 8405 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8406   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8407   match(Set dst (EncodeP src));
 8408   effect(KILL cr);
 8409   ins_cost(INSN_COST * 3);
 8410   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8411   ins_encode %{
 8412     Register s = $src$$Register;
 8413     Register d = $dst$$Register;
 8414     __ encode_heap_oop(d, s);
 8415   %}
 8416   ins_pipe(ialu_reg);
 8417 %}
 8418 
 8419 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8420   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8421   match(Set dst (EncodeP src));
 8422   ins_cost(INSN_COST * 3);
 8423   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8424   ins_encode %{
 8425     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8426   %}
 8427   ins_pipe(ialu_reg);
 8428 %}
 8429 
 8430 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8431   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8432             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8433   match(Set dst (DecodeN src));
 8434   ins_cost(INSN_COST * 3);
 8435   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8436   ins_encode %{
 8437     Register s = $src$$Register;
 8438     Register d = $dst$$Register;
 8439     __ decode_heap_oop(d, s);
 8440   %}
 8441   ins_pipe(ialu_reg);
 8442 %}
 8443 
 8444 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8445   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8446             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8447   match(Set dst (DecodeN src));
 8448   ins_cost(INSN_COST * 3);
 8449   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8450   ins_encode %{
 8451     Register s = $src$$Register;
 8452     Register d = $dst$$Register;
 8453     __ decode_heap_oop_not_null(d, s);
 8454   %}
 8455   ins_pipe(ialu_reg);
 8456 %}
 8457 
 8458 // n.b. AArch64 implementations of encode_klass_not_null and
 8459 // decode_klass_not_null do not modify the flags register so, unlike
 8460 // Intel, we don&#39;t kill CR as a side effect here
 8461 
 8462 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8463   match(Set dst (EncodePKlass src));
 8464 
 8465   ins_cost(INSN_COST * 3);
 8466   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8467 
 8468   ins_encode %{
 8469     Register src_reg = as_Register($src$$reg);
 8470     Register dst_reg = as_Register($dst$$reg);
 8471     __ encode_klass_not_null(dst_reg, src_reg);
 8472   %}
 8473 
 8474    ins_pipe(ialu_reg);
 8475 %}
 8476 
 8477 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8478   match(Set dst (DecodeNKlass src));
 8479 
 8480   ins_cost(INSN_COST * 3);
 8481   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8482 
 8483   ins_encode %{
 8484     Register src_reg = as_Register($src$$reg);
 8485     Register dst_reg = as_Register($dst$$reg);
 8486     if (dst_reg != src_reg) {
 8487       __ decode_klass_not_null(dst_reg, src_reg);
 8488     } else {
 8489       __ decode_klass_not_null(dst_reg);
 8490     }
 8491   %}
 8492 
 8493    ins_pipe(ialu_reg);
 8494 %}
 8495 
 8496 instruct checkCastPP(iRegPNoSp dst)
 8497 %{
 8498   match(Set dst (CheckCastPP dst));
 8499 
 8500   size(0);
 8501   format %{ &quot;# checkcastPP of $dst&quot; %}
 8502   ins_encode(/* empty encoding */);
 8503   ins_pipe(pipe_class_empty);
 8504 %}
 8505 
 8506 instruct castPP(iRegPNoSp dst)
 8507 %{
 8508   match(Set dst (CastPP dst));
 8509 
 8510   size(0);
 8511   format %{ &quot;# castPP of $dst&quot; %}
 8512   ins_encode(/* empty encoding */);
 8513   ins_pipe(pipe_class_empty);
 8514 %}
 8515 
 8516 instruct castII(iRegI dst)
 8517 %{
 8518   match(Set dst (CastII dst));
 8519 
 8520   size(0);
 8521   format %{ &quot;# castII of $dst&quot; %}
 8522   ins_encode(/* empty encoding */);
 8523   ins_cost(0);
 8524   ins_pipe(pipe_class_empty);
 8525 %}
 8526 
 8527 instruct castLL(iRegL dst)
 8528 %{
 8529   match(Set dst (CastLL dst));
 8530 
 8531   size(0);
 8532   format %{ &quot;# castLL of $dst&quot; %}
 8533   ins_encode(/* empty encoding */);
 8534   ins_cost(0);
 8535   ins_pipe(pipe_class_empty);
 8536 %}
 8537 
 8538 // ============================================================================
 8539 // Atomic operation instructions
 8540 //
 8541 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8542 // Store{PIL}Conditional instructions using a normal load for the
 8543 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8544 //
 8545 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8546 // pair to lock object allocations from Eden space when not using
 8547 // TLABs.
 8548 //
 8549 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8550 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8551 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8552 // only for 64-bit.
 8553 //
 8554 // We implement LoadPLocked and StorePLocked instructions using,
 8555 // respectively the AArch64 hw load-exclusive and store-conditional
 8556 // instructions. Whereas we must implement each of
 8557 // Store{IL}Conditional using a CAS which employs a pair of
 8558 // instructions comprising a load-exclusive followed by a
 8559 // store-conditional.
 8560 
 8561 
 8562 // Locked-load (linked load) of the current heap-top
 8563 // used when updating the eden heap top
 8564 // implemented using ldaxr on AArch64
 8565 
 8566 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8567 %{
 8568   match(Set dst (LoadPLocked mem));
 8569 
 8570   ins_cost(VOLATILE_REF_COST);
 8571 
 8572   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8573 
 8574   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8575 
 8576   ins_pipe(pipe_serial);
 8577 %}
 8578 
 8579 // Conditional-store of the updated heap-top.
 8580 // Used during allocation of the shared heap.
 8581 // Sets flag (EQ) on success.
 8582 // implemented using stlxr on AArch64.
 8583 
 8584 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8585 %{
 8586   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8587 
 8588   ins_cost(VOLATILE_REF_COST);
 8589 
 8590  // TODO
 8591  // do we need to do a store-conditional release or can we just use a
 8592  // plain store-conditional?
 8593 
 8594   format %{
 8595     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8596     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8597   %}
 8598 
 8599   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8600 
 8601   ins_pipe(pipe_serial);
 8602 %}
 8603 
 8604 
 8605 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8606 // when attempting to rebias a lock towards the current thread.  We
 8607 // must use the acquire form of cmpxchg in order to guarantee acquire
 8608 // semantics in this case.
 8609 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8610 %{
 8611   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8612 
 8613   ins_cost(VOLATILE_REF_COST);
 8614 
 8615   format %{
 8616     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8617     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8618   %}
 8619 
 8620   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8621 
 8622   ins_pipe(pipe_slow);
 8623 %}
 8624 
 8625 // storeIConditional also has acquire semantics, for no better reason
 8626 // than matching storeLConditional.  At the time of writing this
 8627 // comment storeIConditional was not used anywhere by AArch64.
 8628 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8629 %{
 8630   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8631 
 8632   ins_cost(VOLATILE_REF_COST);
 8633 
 8634   format %{
 8635     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8636     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8637   %}
 8638 
 8639   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8640 
 8641   ins_pipe(pipe_slow);
 8642 %}
 8643 
 8644 // standard CompareAndSwapX when we are using barriers
 8645 // these have higher priority than the rules selected by a predicate
 8646 
 8647 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8648 // can&#39;t match them
 8649 
 8650 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8651 
 8652   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8653   ins_cost(2 * VOLATILE_REF_COST);
 8654 
 8655   effect(KILL cr);
 8656 
 8657   format %{
 8658     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8659     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8660   %}
 8661 
 8662   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8663             aarch64_enc_cset_eq(res));
 8664 
 8665   ins_pipe(pipe_slow);
 8666 %}
 8667 
 8668 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8669 
 8670   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8671   ins_cost(2 * VOLATILE_REF_COST);
 8672 
 8673   effect(KILL cr);
 8674 
 8675   format %{
 8676     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8677     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8678   %}
 8679 
 8680   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8681             aarch64_enc_cset_eq(res));
 8682 
 8683   ins_pipe(pipe_slow);
 8684 %}
 8685 
 8686 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8687 
 8688   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8689   ins_cost(2 * VOLATILE_REF_COST);
 8690 
 8691   effect(KILL cr);
 8692 
 8693  format %{
 8694     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8695     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8696  %}
 8697 
 8698  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8699             aarch64_enc_cset_eq(res));
 8700 
 8701   ins_pipe(pipe_slow);
 8702 %}
 8703 
 8704 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8705 
 8706   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8707   ins_cost(2 * VOLATILE_REF_COST);
 8708 
 8709   effect(KILL cr);
 8710 
 8711  format %{
 8712     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8713     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8714  %}
 8715 
 8716  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8717             aarch64_enc_cset_eq(res));
 8718 
 8719   ins_pipe(pipe_slow);
 8720 %}
 8721 
 8722 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8723 
 8724   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8725   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8726   ins_cost(2 * VOLATILE_REF_COST);
 8727 
 8728   effect(KILL cr);
 8729 
 8730  format %{
 8731     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8732     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8733  %}
 8734 
 8735  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8736             aarch64_enc_cset_eq(res));
 8737 
 8738   ins_pipe(pipe_slow);
 8739 %}
 8740 
 8741 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8742 
 8743   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8744   ins_cost(2 * VOLATILE_REF_COST);
 8745 
 8746   effect(KILL cr);
 8747 
 8748  format %{
 8749     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8750     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8751  %}
 8752 
 8753  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8754             aarch64_enc_cset_eq(res));
 8755 
 8756   ins_pipe(pipe_slow);
 8757 %}
 8758 
 8759 // alternative CompareAndSwapX when we are eliding barriers
 8760 
 8761 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8762 
 8763   predicate(needs_acquiring_load_exclusive(n));
 8764   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8765   ins_cost(VOLATILE_REF_COST);
 8766 
 8767   effect(KILL cr);
 8768 
 8769   format %{
 8770     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8771     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8772   %}
 8773 
 8774   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8775             aarch64_enc_cset_eq(res));
 8776 
 8777   ins_pipe(pipe_slow);
 8778 %}
 8779 
 8780 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8781 
 8782   predicate(needs_acquiring_load_exclusive(n));
 8783   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8784   ins_cost(VOLATILE_REF_COST);
 8785 
 8786   effect(KILL cr);
 8787 
 8788   format %{
 8789     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8790     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8791   %}
 8792 
 8793   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8794             aarch64_enc_cset_eq(res));
 8795 
 8796   ins_pipe(pipe_slow);
 8797 %}
 8798 
 8799 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8800 
 8801   predicate(needs_acquiring_load_exclusive(n));
 8802   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8803   ins_cost(VOLATILE_REF_COST);
 8804 
 8805   effect(KILL cr);
 8806 
 8807  format %{
 8808     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8809     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8810  %}
 8811 
 8812  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8813             aarch64_enc_cset_eq(res));
 8814 
 8815   ins_pipe(pipe_slow);
 8816 %}
 8817 
 8818 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8819 
 8820   predicate(needs_acquiring_load_exclusive(n));
 8821   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8822   ins_cost(VOLATILE_REF_COST);
 8823 
 8824   effect(KILL cr);
 8825 
 8826  format %{
 8827     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8828     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8829  %}
 8830 
 8831  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8832             aarch64_enc_cset_eq(res));
 8833 
 8834   ins_pipe(pipe_slow);
 8835 %}
 8836 
 8837 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8838 
 8839   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8840   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8841   ins_cost(VOLATILE_REF_COST);
 8842 
 8843   effect(KILL cr);
 8844 
 8845  format %{
 8846     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8847     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8848  %}
 8849 
 8850  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8851             aarch64_enc_cset_eq(res));
 8852 
 8853   ins_pipe(pipe_slow);
 8854 %}
 8855 
 8856 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8857 
 8858   predicate(needs_acquiring_load_exclusive(n));
 8859   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8860   ins_cost(VOLATILE_REF_COST);
 8861 
 8862   effect(KILL cr);
 8863 
 8864  format %{
 8865     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8866     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8867  %}
 8868 
 8869  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8870             aarch64_enc_cset_eq(res));
 8871 
 8872   ins_pipe(pipe_slow);
 8873 %}
 8874 
 8875 
 8876 // ---------------------------------------------------------------------
 8877 
 8878 
 8879 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8880 
 8881 // Sundry CAS operations.  Note that release is always true,
 8882 // regardless of the memory ordering of the CAS.  This is because we
 8883 // need the volatile case to be sequentially consistent but there is
 8884 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8885 // can&#39;t check the type of memory ordering here, so we always emit a
 8886 // STLXR.
 8887 
 8888 // This section is generated from aarch64_ad_cas.m4
 8889 
 8890 
 8891 
 8892 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8893   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8894   ins_cost(2 * VOLATILE_REF_COST);
 8895   effect(TEMP_DEF res, KILL cr);
 8896   format %{
 8897     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8898   %}
 8899   ins_encode %{
 8900     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8901                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8902                /*weak*/ false, $res$$Register);
 8903     __ sxtbw($res$$Register, $res$$Register);
 8904   %}
 8905   ins_pipe(pipe_slow);
 8906 %}
 8907 
 8908 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8909   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8910   ins_cost(2 * VOLATILE_REF_COST);
 8911   effect(TEMP_DEF res, KILL cr);
 8912   format %{
 8913     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8914   %}
 8915   ins_encode %{
 8916     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8917                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8918                /*weak*/ false, $res$$Register);
 8919     __ sxthw($res$$Register, $res$$Register);
 8920   %}
 8921   ins_pipe(pipe_slow);
 8922 %}
 8923 
 8924 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8925   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8926   ins_cost(2 * VOLATILE_REF_COST);
 8927   effect(TEMP_DEF res, KILL cr);
 8928   format %{
 8929     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8930   %}
 8931   ins_encode %{
 8932     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8933                Assembler::word, /*acquire*/ false, /*release*/ true,
 8934                /*weak*/ false, $res$$Register);
 8935   %}
 8936   ins_pipe(pipe_slow);
 8937 %}
 8938 
 8939 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8940   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8941   ins_cost(2 * VOLATILE_REF_COST);
 8942   effect(TEMP_DEF res, KILL cr);
 8943   format %{
 8944     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8945   %}
 8946   ins_encode %{
 8947     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8948                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8949                /*weak*/ false, $res$$Register);
 8950   %}
 8951   ins_pipe(pipe_slow);
 8952 %}
 8953 
 8954 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8955   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8956   ins_cost(2 * VOLATILE_REF_COST);
 8957   effect(TEMP_DEF res, KILL cr);
 8958   format %{
 8959     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8960   %}
 8961   ins_encode %{
 8962     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8963                Assembler::word, /*acquire*/ false, /*release*/ true,
 8964                /*weak*/ false, $res$$Register);
 8965   %}
 8966   ins_pipe(pipe_slow);
 8967 %}
 8968 
 8969 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8970   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8971   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8972   ins_cost(2 * VOLATILE_REF_COST);
 8973   effect(TEMP_DEF res, KILL cr);
 8974   format %{
 8975     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8976   %}
 8977   ins_encode %{
 8978     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8979                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8980                /*weak*/ false, $res$$Register);
 8981   %}
 8982   ins_pipe(pipe_slow);
 8983 %}
 8984 
 8985 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8986   predicate(needs_acquiring_load_exclusive(n));
 8987   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8988   ins_cost(VOLATILE_REF_COST);
 8989   effect(TEMP_DEF res, KILL cr);
 8990   format %{
 8991     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8992   %}
 8993   ins_encode %{
 8994     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8995                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8996                /*weak*/ false, $res$$Register);
 8997     __ sxtbw($res$$Register, $res$$Register);
 8998   %}
 8999   ins_pipe(pipe_slow);
 9000 %}
 9001 
 9002 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9003   predicate(needs_acquiring_load_exclusive(n));
 9004   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 9005   ins_cost(VOLATILE_REF_COST);
 9006   effect(TEMP_DEF res, KILL cr);
 9007   format %{
 9008     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9009   %}
 9010   ins_encode %{
 9011     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9012                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9013                /*weak*/ false, $res$$Register);
 9014     __ sxthw($res$$Register, $res$$Register);
 9015   %}
 9016   ins_pipe(pipe_slow);
 9017 %}
 9018 
 9019 
 9020 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9021   predicate(needs_acquiring_load_exclusive(n));
 9022   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 9023   ins_cost(VOLATILE_REF_COST);
 9024   effect(TEMP_DEF res, KILL cr);
 9025   format %{
 9026     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9027   %}
 9028   ins_encode %{
 9029     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9030                Assembler::word, /*acquire*/ true, /*release*/ true,
 9031                /*weak*/ false, $res$$Register);
 9032   %}
 9033   ins_pipe(pipe_slow);
 9034 %}
 9035 
 9036 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9037   predicate(needs_acquiring_load_exclusive(n));
 9038   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 9039   ins_cost(VOLATILE_REF_COST);
 9040   effect(TEMP_DEF res, KILL cr);
 9041   format %{
 9042     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9043   %}
 9044   ins_encode %{
 9045     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9046                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9047                /*weak*/ false, $res$$Register);
 9048   %}
 9049   ins_pipe(pipe_slow);
 9050 %}
 9051 
 9052 
 9053 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9054   predicate(needs_acquiring_load_exclusive(n));
 9055   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 9056   ins_cost(VOLATILE_REF_COST);
 9057   effect(TEMP_DEF res, KILL cr);
 9058   format %{
 9059     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9060   %}
 9061   ins_encode %{
 9062     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9063                Assembler::word, /*acquire*/ true, /*release*/ true,
 9064                /*weak*/ false, $res$$Register);
 9065   %}
 9066   ins_pipe(pipe_slow);
 9067 %}
 9068 
 9069 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9070   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9071   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9072   ins_cost(VOLATILE_REF_COST);
 9073   effect(TEMP_DEF res, KILL cr);
 9074   format %{
 9075     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9076   %}
 9077   ins_encode %{
 9078     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9079                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9080                /*weak*/ false, $res$$Register);
 9081   %}
 9082   ins_pipe(pipe_slow);
 9083 %}
 9084 
 9085 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9086   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9087   ins_cost(2 * VOLATILE_REF_COST);
 9088   effect(KILL cr);
 9089   format %{
 9090     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9091     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9092   %}
 9093   ins_encode %{
 9094     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9095                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9096                /*weak*/ true, noreg);
 9097     __ csetw($res$$Register, Assembler::EQ);
 9098   %}
 9099   ins_pipe(pipe_slow);
 9100 %}
 9101 
 9102 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9103   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9104   ins_cost(2 * VOLATILE_REF_COST);
 9105   effect(KILL cr);
 9106   format %{
 9107     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9108     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9109   %}
 9110   ins_encode %{
 9111     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9112                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9113                /*weak*/ true, noreg);
 9114     __ csetw($res$$Register, Assembler::EQ);
 9115   %}
 9116   ins_pipe(pipe_slow);
 9117 %}
 9118 
 9119 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9120   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9121   ins_cost(2 * VOLATILE_REF_COST);
 9122   effect(KILL cr);
 9123   format %{
 9124     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9125     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9126   %}
 9127   ins_encode %{
 9128     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9129                Assembler::word, /*acquire*/ false, /*release*/ true,
 9130                /*weak*/ true, noreg);
 9131     __ csetw($res$$Register, Assembler::EQ);
 9132   %}
 9133   ins_pipe(pipe_slow);
 9134 %}
 9135 
 9136 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9137   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9138   ins_cost(2 * VOLATILE_REF_COST);
 9139   effect(KILL cr);
 9140   format %{
 9141     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9142     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9143   %}
 9144   ins_encode %{
 9145     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9146                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9147                /*weak*/ true, noreg);
 9148     __ csetw($res$$Register, Assembler::EQ);
 9149   %}
 9150   ins_pipe(pipe_slow);
 9151 %}
 9152 
 9153 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9154   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9155   ins_cost(2 * VOLATILE_REF_COST);
 9156   effect(KILL cr);
 9157   format %{
 9158     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9159     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9160   %}
 9161   ins_encode %{
 9162     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9163                Assembler::word, /*acquire*/ false, /*release*/ true,
 9164                /*weak*/ true, noreg);
 9165     __ csetw($res$$Register, Assembler::EQ);
 9166   %}
 9167   ins_pipe(pipe_slow);
 9168 %}
 9169 
 9170 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9171   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9172   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9173   ins_cost(2 * VOLATILE_REF_COST);
 9174   effect(KILL cr);
 9175   format %{
 9176     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9177     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9178   %}
 9179   ins_encode %{
 9180     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9181                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9182                /*weak*/ true, noreg);
 9183     __ csetw($res$$Register, Assembler::EQ);
 9184   %}
 9185   ins_pipe(pipe_slow);
 9186 %}
 9187 
 9188 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9189   predicate(needs_acquiring_load_exclusive(n));
 9190   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9191   ins_cost(VOLATILE_REF_COST);
 9192   effect(KILL cr);
 9193   format %{
 9194     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9195     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9196   %}
 9197   ins_encode %{
 9198     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9199                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9200                /*weak*/ true, noreg);
 9201     __ csetw($res$$Register, Assembler::EQ);
 9202   %}
 9203   ins_pipe(pipe_slow);
 9204 %}
 9205 
 9206 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9207   predicate(needs_acquiring_load_exclusive(n));
 9208   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9209   ins_cost(VOLATILE_REF_COST);
 9210   effect(KILL cr);
 9211   format %{
 9212     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9213     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9214   %}
 9215   ins_encode %{
 9216     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9217                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9218                /*weak*/ true, noreg);
 9219     __ csetw($res$$Register, Assembler::EQ);
 9220   %}
 9221   ins_pipe(pipe_slow);
 9222 %}
 9223 
 9224 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9225   predicate(needs_acquiring_load_exclusive(n));
 9226   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9227   ins_cost(VOLATILE_REF_COST);
 9228   effect(KILL cr);
 9229   format %{
 9230     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9231     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9232   %}
 9233   ins_encode %{
 9234     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9235                Assembler::word, /*acquire*/ true, /*release*/ true,
 9236                /*weak*/ true, noreg);
 9237     __ csetw($res$$Register, Assembler::EQ);
 9238   %}
 9239   ins_pipe(pipe_slow);
 9240 %}
 9241 
 9242 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9243   predicate(needs_acquiring_load_exclusive(n));
 9244   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9245   ins_cost(VOLATILE_REF_COST);
 9246   effect(KILL cr);
 9247   format %{
 9248     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9249     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9250   %}
 9251   ins_encode %{
 9252     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9253                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9254                /*weak*/ true, noreg);
 9255     __ csetw($res$$Register, Assembler::EQ);
 9256   %}
 9257   ins_pipe(pipe_slow);
 9258 %}
 9259 
 9260 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9261   predicate(needs_acquiring_load_exclusive(n));
 9262   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9263   ins_cost(VOLATILE_REF_COST);
 9264   effect(KILL cr);
 9265   format %{
 9266     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9267     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9268   %}
 9269   ins_encode %{
 9270     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9271                Assembler::word, /*acquire*/ true, /*release*/ true,
 9272                /*weak*/ true, noreg);
 9273     __ csetw($res$$Register, Assembler::EQ);
 9274   %}
 9275   ins_pipe(pipe_slow);
 9276 %}
 9277 
 9278 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9279   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9280   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9281   ins_cost(VOLATILE_REF_COST);
 9282   effect(KILL cr);
 9283   format %{
 9284     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9285     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9286   %}
 9287   ins_encode %{
 9288     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9289                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9290                /*weak*/ true, noreg);
 9291     __ csetw($res$$Register, Assembler::EQ);
 9292   %}
 9293   ins_pipe(pipe_slow);
 9294 %}
 9295 
 9296 // END This section of the file is automatically generated. Do not edit --------------
 9297 // ---------------------------------------------------------------------
 9298 
 9299 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9300   match(Set prev (GetAndSetI mem newv));
 9301   ins_cost(2 * VOLATILE_REF_COST);
 9302   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9303   ins_encode %{
 9304     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9305   %}
 9306   ins_pipe(pipe_serial);
 9307 %}
 9308 
 9309 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9310   match(Set prev (GetAndSetL mem newv));
 9311   ins_cost(2 * VOLATILE_REF_COST);
 9312   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9313   ins_encode %{
 9314     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9315   %}
 9316   ins_pipe(pipe_serial);
 9317 %}
 9318 
 9319 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9320   match(Set prev (GetAndSetN mem newv));
 9321   ins_cost(2 * VOLATILE_REF_COST);
 9322   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9323   ins_encode %{
 9324     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9325   %}
 9326   ins_pipe(pipe_serial);
 9327 %}
 9328 
 9329 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9330   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9331   match(Set prev (GetAndSetP mem newv));
 9332   ins_cost(2 * VOLATILE_REF_COST);
 9333   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9334   ins_encode %{
 9335     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9336   %}
 9337   ins_pipe(pipe_serial);
 9338 %}
 9339 
 9340 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9341   predicate(needs_acquiring_load_exclusive(n));
 9342   match(Set prev (GetAndSetI mem newv));
 9343   ins_cost(VOLATILE_REF_COST);
 9344   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9345   ins_encode %{
 9346     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9347   %}
 9348   ins_pipe(pipe_serial);
 9349 %}
 9350 
 9351 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9352   predicate(needs_acquiring_load_exclusive(n));
 9353   match(Set prev (GetAndSetL mem newv));
 9354   ins_cost(VOLATILE_REF_COST);
 9355   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9356   ins_encode %{
 9357     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9358   %}
 9359   ins_pipe(pipe_serial);
 9360 %}
 9361 
 9362 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9363   predicate(needs_acquiring_load_exclusive(n));
 9364   match(Set prev (GetAndSetN mem newv));
 9365   ins_cost(VOLATILE_REF_COST);
 9366   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9367   ins_encode %{
 9368     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9369   %}
 9370   ins_pipe(pipe_serial);
 9371 %}
 9372 
 9373 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9374   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9375   match(Set prev (GetAndSetP mem newv));
 9376   ins_cost(VOLATILE_REF_COST);
 9377   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9378   ins_encode %{
 9379     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9380   %}
 9381   ins_pipe(pipe_serial);
 9382 %}
 9383 
 9384 
 9385 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9386   match(Set newval (GetAndAddL mem incr));
 9387   ins_cost(2 * VOLATILE_REF_COST + 1);
 9388   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9389   ins_encode %{
 9390     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9391   %}
 9392   ins_pipe(pipe_serial);
 9393 %}
 9394 
 9395 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9396   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9397   match(Set dummy (GetAndAddL mem incr));
 9398   ins_cost(2 * VOLATILE_REF_COST);
 9399   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9400   ins_encode %{
 9401     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9402   %}
 9403   ins_pipe(pipe_serial);
 9404 %}
 9405 
 9406 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9407   match(Set newval (GetAndAddL mem incr));
 9408   ins_cost(2 * VOLATILE_REF_COST + 1);
 9409   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9410   ins_encode %{
 9411     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9412   %}
 9413   ins_pipe(pipe_serial);
 9414 %}
 9415 
 9416 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9417   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9418   match(Set dummy (GetAndAddL mem incr));
 9419   ins_cost(2 * VOLATILE_REF_COST);
 9420   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9421   ins_encode %{
 9422     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9423   %}
 9424   ins_pipe(pipe_serial);
 9425 %}
 9426 
 9427 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9428   match(Set newval (GetAndAddI mem incr));
 9429   ins_cost(2 * VOLATILE_REF_COST + 1);
 9430   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9431   ins_encode %{
 9432     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9433   %}
 9434   ins_pipe(pipe_serial);
 9435 %}
 9436 
 9437 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9438   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9439   match(Set dummy (GetAndAddI mem incr));
 9440   ins_cost(2 * VOLATILE_REF_COST);
 9441   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9442   ins_encode %{
 9443     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9444   %}
 9445   ins_pipe(pipe_serial);
 9446 %}
 9447 
 9448 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9449   match(Set newval (GetAndAddI mem incr));
 9450   ins_cost(2 * VOLATILE_REF_COST + 1);
 9451   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9452   ins_encode %{
 9453     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9454   %}
 9455   ins_pipe(pipe_serial);
 9456 %}
 9457 
 9458 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9459   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9460   match(Set dummy (GetAndAddI mem incr));
 9461   ins_cost(2 * VOLATILE_REF_COST);
 9462   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9463   ins_encode %{
 9464     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9465   %}
 9466   ins_pipe(pipe_serial);
 9467 %}
 9468 
 9469 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9470   predicate(needs_acquiring_load_exclusive(n));
 9471   match(Set newval (GetAndAddL mem incr));
 9472   ins_cost(VOLATILE_REF_COST + 1);
 9473   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9474   ins_encode %{
 9475     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9476   %}
 9477   ins_pipe(pipe_serial);
 9478 %}
 9479 
 9480 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9481   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9482   match(Set dummy (GetAndAddL mem incr));
 9483   ins_cost(VOLATILE_REF_COST);
 9484   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9485   ins_encode %{
 9486     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9487   %}
 9488   ins_pipe(pipe_serial);
 9489 %}
 9490 
 9491 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9492   predicate(needs_acquiring_load_exclusive(n));
 9493   match(Set newval (GetAndAddL mem incr));
 9494   ins_cost(VOLATILE_REF_COST + 1);
 9495   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9496   ins_encode %{
 9497     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9498   %}
 9499   ins_pipe(pipe_serial);
 9500 %}
 9501 
 9502 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9503   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9504   match(Set dummy (GetAndAddL mem incr));
 9505   ins_cost(VOLATILE_REF_COST);
 9506   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9507   ins_encode %{
 9508     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9509   %}
 9510   ins_pipe(pipe_serial);
 9511 %}
 9512 
 9513 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9514   predicate(needs_acquiring_load_exclusive(n));
 9515   match(Set newval (GetAndAddI mem incr));
 9516   ins_cost(VOLATILE_REF_COST + 1);
 9517   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9518   ins_encode %{
 9519     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9520   %}
 9521   ins_pipe(pipe_serial);
 9522 %}
 9523 
 9524 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9525   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9526   match(Set dummy (GetAndAddI mem incr));
 9527   ins_cost(VOLATILE_REF_COST);
 9528   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9529   ins_encode %{
 9530     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9531   %}
 9532   ins_pipe(pipe_serial);
 9533 %}
 9534 
 9535 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9536   predicate(needs_acquiring_load_exclusive(n));
 9537   match(Set newval (GetAndAddI mem incr));
 9538   ins_cost(VOLATILE_REF_COST + 1);
 9539   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9540   ins_encode %{
 9541     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9542   %}
 9543   ins_pipe(pipe_serial);
 9544 %}
 9545 
 9546 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9547   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9548   match(Set dummy (GetAndAddI mem incr));
 9549   ins_cost(VOLATILE_REF_COST);
 9550   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9551   ins_encode %{
 9552     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9553   %}
 9554   ins_pipe(pipe_serial);
 9555 %}
 9556 
 9557 // Manifest a CmpL result in an integer register.
 9558 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9559 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9560 %{
 9561   match(Set dst (CmpL3 src1 src2));
 9562   effect(KILL flags);
 9563 
 9564   ins_cost(INSN_COST * 6);
 9565   format %{
 9566       &quot;cmp $src1, $src2&quot;
 9567       &quot;csetw $dst, ne&quot;
 9568       &quot;cnegw $dst, lt&quot;
 9569   %}
 9570   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9571   ins_encode %{
 9572     __ cmp($src1$$Register, $src2$$Register);
 9573     __ csetw($dst$$Register, Assembler::NE);
 9574     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9575   %}
 9576 
 9577   ins_pipe(pipe_class_default);
 9578 %}
 9579 
 9580 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9581 %{
 9582   match(Set dst (CmpL3 src1 src2));
 9583   effect(KILL flags);
 9584 
 9585   ins_cost(INSN_COST * 6);
 9586   format %{
 9587       &quot;cmp $src1, $src2&quot;
 9588       &quot;csetw $dst, ne&quot;
 9589       &quot;cnegw $dst, lt&quot;
 9590   %}
 9591   ins_encode %{
 9592     int32_t con = (int32_t)$src2$$constant;
 9593      if (con &lt; 0) {
 9594       __ adds(zr, $src1$$Register, -con);
 9595     } else {
 9596       __ subs(zr, $src1$$Register, con);
 9597     }
 9598     __ csetw($dst$$Register, Assembler::NE);
 9599     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9600   %}
 9601 
 9602   ins_pipe(pipe_class_default);
 9603 %}
 9604 
 9605 // ============================================================================
 9606 // Conditional Move Instructions
 9607 
 9608 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9609 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9610 // define an op class which merged both inputs and use it to type the
 9611 // argument to a single rule. unfortunatelyt his fails because the
 9612 // opclass does not live up to the COND_INTER interface of its
 9613 // component operands. When the generic code tries to negate the
 9614 // operand it ends up running the generci Machoper::negate method
 9615 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9616 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9617 
 9618 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9619   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9620 
 9621   ins_cost(INSN_COST * 2);
 9622   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9623 
 9624   ins_encode %{
 9625     __ cselw(as_Register($dst$$reg),
 9626              as_Register($src2$$reg),
 9627              as_Register($src1$$reg),
 9628              (Assembler::Condition)$cmp$$cmpcode);
 9629   %}
 9630 
 9631   ins_pipe(icond_reg_reg);
 9632 %}
 9633 
 9634 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9635   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9636 
 9637   ins_cost(INSN_COST * 2);
 9638   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9639 
 9640   ins_encode %{
 9641     __ cselw(as_Register($dst$$reg),
 9642              as_Register($src2$$reg),
 9643              as_Register($src1$$reg),
 9644              (Assembler::Condition)$cmp$$cmpcode);
 9645   %}
 9646 
 9647   ins_pipe(icond_reg_reg);
 9648 %}
 9649 
 9650 // special cases where one arg is zero
 9651 
 9652 // n.b. this is selected in preference to the rule above because it
 9653 // avoids loading constant 0 into a source register
 9654 
 9655 // TODO
 9656 // we ought only to be able to cull one of these variants as the ideal
 9657 // transforms ought always to order the zero consistently (to left/right?)
 9658 
 9659 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9660   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9661 
 9662   ins_cost(INSN_COST * 2);
 9663   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9664 
 9665   ins_encode %{
 9666     __ cselw(as_Register($dst$$reg),
 9667              as_Register($src$$reg),
 9668              zr,
 9669              (Assembler::Condition)$cmp$$cmpcode);
 9670   %}
 9671 
 9672   ins_pipe(icond_reg);
 9673 %}
 9674 
 9675 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9676   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9677 
 9678   ins_cost(INSN_COST * 2);
 9679   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9680 
 9681   ins_encode %{
 9682     __ cselw(as_Register($dst$$reg),
 9683              as_Register($src$$reg),
 9684              zr,
 9685              (Assembler::Condition)$cmp$$cmpcode);
 9686   %}
 9687 
 9688   ins_pipe(icond_reg);
 9689 %}
 9690 
 9691 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9692   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9693 
 9694   ins_cost(INSN_COST * 2);
 9695   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9696 
 9697   ins_encode %{
 9698     __ cselw(as_Register($dst$$reg),
 9699              zr,
 9700              as_Register($src$$reg),
 9701              (Assembler::Condition)$cmp$$cmpcode);
 9702   %}
 9703 
 9704   ins_pipe(icond_reg);
 9705 %}
 9706 
 9707 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9708   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9709 
 9710   ins_cost(INSN_COST * 2);
 9711   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9712 
 9713   ins_encode %{
 9714     __ cselw(as_Register($dst$$reg),
 9715              zr,
 9716              as_Register($src$$reg),
 9717              (Assembler::Condition)$cmp$$cmpcode);
 9718   %}
 9719 
 9720   ins_pipe(icond_reg);
 9721 %}
 9722 
 9723 // special case for creating a boolean 0 or 1
 9724 
 9725 // n.b. this is selected in preference to the rule above because it
 9726 // avoids loading constants 0 and 1 into a source register
 9727 
 9728 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9729   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9730 
 9731   ins_cost(INSN_COST * 2);
 9732   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9733 
 9734   ins_encode %{
 9735     // equivalently
 9736     // cset(as_Register($dst$$reg),
 9737     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9738     __ csincw(as_Register($dst$$reg),
 9739              zr,
 9740              zr,
 9741              (Assembler::Condition)$cmp$$cmpcode);
 9742   %}
 9743 
 9744   ins_pipe(icond_none);
 9745 %}
 9746 
 9747 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9748   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9749 
 9750   ins_cost(INSN_COST * 2);
 9751   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9752 
 9753   ins_encode %{
 9754     // equivalently
 9755     // cset(as_Register($dst$$reg),
 9756     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9757     __ csincw(as_Register($dst$$reg),
 9758              zr,
 9759              zr,
 9760              (Assembler::Condition)$cmp$$cmpcode);
 9761   %}
 9762 
 9763   ins_pipe(icond_none);
 9764 %}
 9765 
 9766 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9767   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9768 
 9769   ins_cost(INSN_COST * 2);
 9770   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9771 
 9772   ins_encode %{
 9773     __ csel(as_Register($dst$$reg),
 9774             as_Register($src2$$reg),
 9775             as_Register($src1$$reg),
 9776             (Assembler::Condition)$cmp$$cmpcode);
 9777   %}
 9778 
 9779   ins_pipe(icond_reg_reg);
 9780 %}
 9781 
 9782 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9783   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9784 
 9785   ins_cost(INSN_COST * 2);
 9786   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9787 
 9788   ins_encode %{
 9789     __ csel(as_Register($dst$$reg),
 9790             as_Register($src2$$reg),
 9791             as_Register($src1$$reg),
 9792             (Assembler::Condition)$cmp$$cmpcode);
 9793   %}
 9794 
 9795   ins_pipe(icond_reg_reg);
 9796 %}
 9797 
 9798 // special cases where one arg is zero
 9799 
 9800 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9801   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9802 
 9803   ins_cost(INSN_COST * 2);
 9804   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9805 
 9806   ins_encode %{
 9807     __ csel(as_Register($dst$$reg),
 9808             zr,
 9809             as_Register($src$$reg),
 9810             (Assembler::Condition)$cmp$$cmpcode);
 9811   %}
 9812 
 9813   ins_pipe(icond_reg);
 9814 %}
 9815 
 9816 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9817   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9818 
 9819   ins_cost(INSN_COST * 2);
 9820   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9821 
 9822   ins_encode %{
 9823     __ csel(as_Register($dst$$reg),
 9824             zr,
 9825             as_Register($src$$reg),
 9826             (Assembler::Condition)$cmp$$cmpcode);
 9827   %}
 9828 
 9829   ins_pipe(icond_reg);
 9830 %}
 9831 
 9832 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9833   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9834 
 9835   ins_cost(INSN_COST * 2);
 9836   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9837 
 9838   ins_encode %{
 9839     __ csel(as_Register($dst$$reg),
 9840             as_Register($src$$reg),
 9841             zr,
 9842             (Assembler::Condition)$cmp$$cmpcode);
 9843   %}
 9844 
 9845   ins_pipe(icond_reg);
 9846 %}
 9847 
 9848 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9849   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9850 
 9851   ins_cost(INSN_COST * 2);
 9852   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9853 
 9854   ins_encode %{
 9855     __ csel(as_Register($dst$$reg),
 9856             as_Register($src$$reg),
 9857             zr,
 9858             (Assembler::Condition)$cmp$$cmpcode);
 9859   %}
 9860 
 9861   ins_pipe(icond_reg);
 9862 %}
 9863 
 9864 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9865   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9866 
 9867   ins_cost(INSN_COST * 2);
 9868   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9869 
 9870   ins_encode %{
 9871     __ csel(as_Register($dst$$reg),
 9872             as_Register($src2$$reg),
 9873             as_Register($src1$$reg),
 9874             (Assembler::Condition)$cmp$$cmpcode);
 9875   %}
 9876 
 9877   ins_pipe(icond_reg_reg);
 9878 %}
 9879 
 9880 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9881   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9882 
 9883   ins_cost(INSN_COST * 2);
 9884   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9885 
 9886   ins_encode %{
 9887     __ csel(as_Register($dst$$reg),
 9888             as_Register($src2$$reg),
 9889             as_Register($src1$$reg),
 9890             (Assembler::Condition)$cmp$$cmpcode);
 9891   %}
 9892 
 9893   ins_pipe(icond_reg_reg);
 9894 %}
 9895 
 9896 // special cases where one arg is zero
 9897 
 9898 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9899   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9900 
 9901   ins_cost(INSN_COST * 2);
 9902   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9903 
 9904   ins_encode %{
 9905     __ csel(as_Register($dst$$reg),
 9906             zr,
 9907             as_Register($src$$reg),
 9908             (Assembler::Condition)$cmp$$cmpcode);
 9909   %}
 9910 
 9911   ins_pipe(icond_reg);
 9912 %}
 9913 
 9914 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9915   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9916 
 9917   ins_cost(INSN_COST * 2);
 9918   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9919 
 9920   ins_encode %{
 9921     __ csel(as_Register($dst$$reg),
 9922             zr,
 9923             as_Register($src$$reg),
 9924             (Assembler::Condition)$cmp$$cmpcode);
 9925   %}
 9926 
 9927   ins_pipe(icond_reg);
 9928 %}
 9929 
 9930 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9931   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9932 
 9933   ins_cost(INSN_COST * 2);
 9934   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9935 
 9936   ins_encode %{
 9937     __ csel(as_Register($dst$$reg),
 9938             as_Register($src$$reg),
 9939             zr,
 9940             (Assembler::Condition)$cmp$$cmpcode);
 9941   %}
 9942 
 9943   ins_pipe(icond_reg);
 9944 %}
 9945 
 9946 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9947   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9948 
 9949   ins_cost(INSN_COST * 2);
 9950   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9951 
 9952   ins_encode %{
 9953     __ csel(as_Register($dst$$reg),
 9954             as_Register($src$$reg),
 9955             zr,
 9956             (Assembler::Condition)$cmp$$cmpcode);
 9957   %}
 9958 
 9959   ins_pipe(icond_reg);
 9960 %}
 9961 
 9962 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9963   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9964 
 9965   ins_cost(INSN_COST * 2);
 9966   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9967 
 9968   ins_encode %{
 9969     __ cselw(as_Register($dst$$reg),
 9970              as_Register($src2$$reg),
 9971              as_Register($src1$$reg),
 9972              (Assembler::Condition)$cmp$$cmpcode);
 9973   %}
 9974 
 9975   ins_pipe(icond_reg_reg);
 9976 %}
 9977 
 9978 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9979   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9980 
 9981   ins_cost(INSN_COST * 2);
 9982   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9983 
 9984   ins_encode %{
 9985     __ cselw(as_Register($dst$$reg),
 9986              as_Register($src2$$reg),
 9987              as_Register($src1$$reg),
 9988              (Assembler::Condition)$cmp$$cmpcode);
 9989   %}
 9990 
 9991   ins_pipe(icond_reg_reg);
 9992 %}
 9993 
 9994 // special cases where one arg is zero
 9995 
 9996 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9997   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9998 
 9999   ins_cost(INSN_COST * 2);
10000   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
10001 
10002   ins_encode %{
10003     __ cselw(as_Register($dst$$reg),
10004              zr,
10005              as_Register($src$$reg),
10006              (Assembler::Condition)$cmp$$cmpcode);
10007   %}
10008 
10009   ins_pipe(icond_reg);
10010 %}
10011 
10012 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
10013   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
10014 
10015   ins_cost(INSN_COST * 2);
10016   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
10017 
10018   ins_encode %{
10019     __ cselw(as_Register($dst$$reg),
10020              zr,
10021              as_Register($src$$reg),
10022              (Assembler::Condition)$cmp$$cmpcode);
10023   %}
10024 
10025   ins_pipe(icond_reg);
10026 %}
10027 
10028 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10029   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10030 
10031   ins_cost(INSN_COST * 2);
10032   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
10033 
10034   ins_encode %{
10035     __ cselw(as_Register($dst$$reg),
10036              as_Register($src$$reg),
10037              zr,
10038              (Assembler::Condition)$cmp$$cmpcode);
10039   %}
10040 
10041   ins_pipe(icond_reg);
10042 %}
10043 
10044 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10045   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10046 
10047   ins_cost(INSN_COST * 2);
10048   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
10049 
10050   ins_encode %{
10051     __ cselw(as_Register($dst$$reg),
10052              as_Register($src$$reg),
10053              zr,
10054              (Assembler::Condition)$cmp$$cmpcode);
10055   %}
10056 
10057   ins_pipe(icond_reg);
10058 %}
10059 
10060 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10061 %{
10062   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10063 
10064   ins_cost(INSN_COST * 3);
10065 
10066   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10067   ins_encode %{
10068     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10069     __ fcsels(as_FloatRegister($dst$$reg),
10070               as_FloatRegister($src2$$reg),
10071               as_FloatRegister($src1$$reg),
10072               cond);
10073   %}
10074 
10075   ins_pipe(fp_cond_reg_reg_s);
10076 %}
10077 
10078 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10079 %{
10080   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10081 
10082   ins_cost(INSN_COST * 3);
10083 
10084   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10085   ins_encode %{
10086     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10087     __ fcsels(as_FloatRegister($dst$$reg),
10088               as_FloatRegister($src2$$reg),
10089               as_FloatRegister($src1$$reg),
10090               cond);
10091   %}
10092 
10093   ins_pipe(fp_cond_reg_reg_s);
10094 %}
10095 
10096 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10097 %{
10098   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10099 
10100   ins_cost(INSN_COST * 3);
10101 
10102   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10103   ins_encode %{
10104     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10105     __ fcseld(as_FloatRegister($dst$$reg),
10106               as_FloatRegister($src2$$reg),
10107               as_FloatRegister($src1$$reg),
10108               cond);
10109   %}
10110 
10111   ins_pipe(fp_cond_reg_reg_d);
10112 %}
10113 
10114 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10115 %{
10116   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10117 
10118   ins_cost(INSN_COST * 3);
10119 
10120   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10121   ins_encode %{
10122     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10123     __ fcseld(as_FloatRegister($dst$$reg),
10124               as_FloatRegister($src2$$reg),
10125               as_FloatRegister($src1$$reg),
10126               cond);
10127   %}
10128 
10129   ins_pipe(fp_cond_reg_reg_d);
10130 %}
10131 
10132 // ============================================================================
10133 // Arithmetic Instructions
10134 //
10135 
10136 // Integer Addition
10137 
10138 // TODO
10139 // these currently employ operations which do not set CR and hence are
10140 // not flagged as killing CR but we would like to isolate the cases
10141 // where we want to set flags from those where we don&#39;t. need to work
10142 // out how to do that.
10143 
10144 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10145   match(Set dst (AddI src1 src2));
10146 
10147   ins_cost(INSN_COST);
10148   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10149 
10150   ins_encode %{
10151     __ addw(as_Register($dst$$reg),
10152             as_Register($src1$$reg),
10153             as_Register($src2$$reg));
10154   %}
10155 
10156   ins_pipe(ialu_reg_reg);
10157 %}
10158 
10159 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10160   match(Set dst (AddI src1 src2));
10161 
10162   ins_cost(INSN_COST);
10163   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10164 
10165   // use opcode to indicate that this is an add not a sub
10166   opcode(0x0);
10167 
10168   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10169 
10170   ins_pipe(ialu_reg_imm);
10171 %}
10172 
10173 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10174   match(Set dst (AddI (ConvL2I src1) src2));
10175 
10176   ins_cost(INSN_COST);
10177   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10178 
10179   // use opcode to indicate that this is an add not a sub
10180   opcode(0x0);
10181 
10182   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10183 
10184   ins_pipe(ialu_reg_imm);
10185 %}
10186 
10187 // Pointer Addition
10188 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10189   match(Set dst (AddP src1 src2));
10190 
10191   ins_cost(INSN_COST);
10192   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10193 
10194   ins_encode %{
10195     __ add(as_Register($dst$$reg),
10196            as_Register($src1$$reg),
10197            as_Register($src2$$reg));
10198   %}
10199 
10200   ins_pipe(ialu_reg_reg);
10201 %}
10202 
10203 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10204   match(Set dst (AddP src1 (ConvI2L src2)));
10205 
10206   ins_cost(1.9 * INSN_COST);
10207   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10208 
10209   ins_encode %{
10210     __ add(as_Register($dst$$reg),
10211            as_Register($src1$$reg),
10212            as_Register($src2$$reg), ext::sxtw);
10213   %}
10214 
10215   ins_pipe(ialu_reg_reg);
10216 %}
10217 
10218 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10219   match(Set dst (AddP src1 (LShiftL src2 scale)));
10220 
10221   ins_cost(1.9 * INSN_COST);
10222   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10223 
10224   ins_encode %{
10225     __ lea(as_Register($dst$$reg),
10226            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10227                    Address::lsl($scale$$constant)));
10228   %}
10229 
10230   ins_pipe(ialu_reg_reg_shift);
10231 %}
10232 
10233 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10234   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10235 
10236   ins_cost(1.9 * INSN_COST);
10237   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10238 
10239   ins_encode %{
10240     __ lea(as_Register($dst$$reg),
10241            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10242                    Address::sxtw($scale$$constant)));
10243   %}
10244 
10245   ins_pipe(ialu_reg_reg_shift);
10246 %}
10247 
10248 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10249   match(Set dst (LShiftL (ConvI2L src) scale));
10250 
10251   ins_cost(INSN_COST);
10252   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10253 
10254   ins_encode %{
10255     __ sbfiz(as_Register($dst$$reg),
10256           as_Register($src$$reg),
10257           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10258   %}
10259 
10260   ins_pipe(ialu_reg_shift);
10261 %}
10262 
10263 // Pointer Immediate Addition
10264 // n.b. this needs to be more expensive than using an indirect memory
10265 // operand
10266 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10267   match(Set dst (AddP src1 src2));
10268 
10269   ins_cost(INSN_COST);
10270   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10271 
10272   // use opcode to indicate that this is an add not a sub
10273   opcode(0x0);
10274 
10275   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10276 
10277   ins_pipe(ialu_reg_imm);
10278 %}
10279 
10280 // Long Addition
10281 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10282 
10283   match(Set dst (AddL src1 src2));
10284 
10285   ins_cost(INSN_COST);
10286   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10287 
10288   ins_encode %{
10289     __ add(as_Register($dst$$reg),
10290            as_Register($src1$$reg),
10291            as_Register($src2$$reg));
10292   %}
10293 
10294   ins_pipe(ialu_reg_reg);
10295 %}
10296 
10297 // No constant pool entries requiredLong Immediate Addition.
10298 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10299   match(Set dst (AddL src1 src2));
10300 
10301   ins_cost(INSN_COST);
10302   format %{ &quot;add $dst, $src1, $src2&quot; %}
10303 
10304   // use opcode to indicate that this is an add not a sub
10305   opcode(0x0);
10306 
10307   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10308 
10309   ins_pipe(ialu_reg_imm);
10310 %}
10311 
10312 // Integer Subtraction
10313 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10314   match(Set dst (SubI src1 src2));
10315 
10316   ins_cost(INSN_COST);
10317   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10318 
10319   ins_encode %{
10320     __ subw(as_Register($dst$$reg),
10321             as_Register($src1$$reg),
10322             as_Register($src2$$reg));
10323   %}
10324 
10325   ins_pipe(ialu_reg_reg);
10326 %}
10327 
10328 // Immediate Subtraction
10329 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10330   match(Set dst (SubI src1 src2));
10331 
10332   ins_cost(INSN_COST);
10333   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10334 
10335   // use opcode to indicate that this is a sub not an add
10336   opcode(0x1);
10337 
10338   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10339 
10340   ins_pipe(ialu_reg_imm);
10341 %}
10342 
10343 // Long Subtraction
10344 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10345 
10346   match(Set dst (SubL src1 src2));
10347 
10348   ins_cost(INSN_COST);
10349   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10350 
10351   ins_encode %{
10352     __ sub(as_Register($dst$$reg),
10353            as_Register($src1$$reg),
10354            as_Register($src2$$reg));
10355   %}
10356 
10357   ins_pipe(ialu_reg_reg);
10358 %}
10359 
10360 // No constant pool entries requiredLong Immediate Subtraction.
10361 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10362   match(Set dst (SubL src1 src2));
10363 
10364   ins_cost(INSN_COST);
10365   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10366 
10367   // use opcode to indicate that this is a sub not an add
10368   opcode(0x1);
10369 
10370   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10371 
10372   ins_pipe(ialu_reg_imm);
10373 %}
10374 
10375 // Integer Negation (special case for sub)
10376 
10377 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10378   match(Set dst (SubI zero src));
10379 
10380   ins_cost(INSN_COST);
10381   format %{ &quot;negw $dst, $src\t# int&quot; %}
10382 
10383   ins_encode %{
10384     __ negw(as_Register($dst$$reg),
10385             as_Register($src$$reg));
10386   %}
10387 
10388   ins_pipe(ialu_reg);
10389 %}
10390 
10391 // Long Negation
10392 
10393 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10394   match(Set dst (SubL zero src));
10395 
10396   ins_cost(INSN_COST);
10397   format %{ &quot;neg $dst, $src\t# long&quot; %}
10398 
10399   ins_encode %{
10400     __ neg(as_Register($dst$$reg),
10401            as_Register($src$$reg));
10402   %}
10403 
10404   ins_pipe(ialu_reg);
10405 %}
10406 
10407 // Integer Multiply
10408 
10409 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10410   match(Set dst (MulI src1 src2));
10411 
10412   ins_cost(INSN_COST * 3);
10413   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10414 
10415   ins_encode %{
10416     __ mulw(as_Register($dst$$reg),
10417             as_Register($src1$$reg),
10418             as_Register($src2$$reg));
10419   %}
10420 
10421   ins_pipe(imul_reg_reg);
10422 %}
10423 
10424 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10425   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10426 
10427   ins_cost(INSN_COST * 3);
10428   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10429 
10430   ins_encode %{
10431     __ smull(as_Register($dst$$reg),
10432              as_Register($src1$$reg),
10433              as_Register($src2$$reg));
10434   %}
10435 
10436   ins_pipe(imul_reg_reg);
10437 %}
10438 
10439 // Long Multiply
10440 
10441 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10442   match(Set dst (MulL src1 src2));
10443 
10444   ins_cost(INSN_COST * 5);
10445   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10446 
10447   ins_encode %{
10448     __ mul(as_Register($dst$$reg),
10449            as_Register($src1$$reg),
10450            as_Register($src2$$reg));
10451   %}
10452 
10453   ins_pipe(lmul_reg_reg);
10454 %}
10455 
10456 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10457 %{
10458   match(Set dst (MulHiL src1 src2));
10459 
10460   ins_cost(INSN_COST * 7);
10461   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10462 
10463   ins_encode %{
10464     __ smulh(as_Register($dst$$reg),
10465              as_Register($src1$$reg),
10466              as_Register($src2$$reg));
10467   %}
10468 
10469   ins_pipe(lmul_reg_reg);
10470 %}
10471 
10472 // Combined Integer Multiply &amp; Add/Sub
10473 
10474 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10475   match(Set dst (AddI src3 (MulI src1 src2)));
10476 
10477   ins_cost(INSN_COST * 3);
10478   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10479 
10480   ins_encode %{
10481     __ maddw(as_Register($dst$$reg),
10482              as_Register($src1$$reg),
10483              as_Register($src2$$reg),
10484              as_Register($src3$$reg));
10485   %}
10486 
10487   ins_pipe(imac_reg_reg);
10488 %}
10489 
10490 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10491   match(Set dst (SubI src3 (MulI src1 src2)));
10492 
10493   ins_cost(INSN_COST * 3);
10494   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10495 
10496   ins_encode %{
10497     __ msubw(as_Register($dst$$reg),
10498              as_Register($src1$$reg),
10499              as_Register($src2$$reg),
10500              as_Register($src3$$reg));
10501   %}
10502 
10503   ins_pipe(imac_reg_reg);
10504 %}
10505 
10506 // Combined Integer Multiply &amp; Neg
10507 
10508 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10509   match(Set dst (MulI (SubI zero src1) src2));
10510   match(Set dst (MulI src1 (SubI zero src2)));
10511 
10512   ins_cost(INSN_COST * 3);
10513   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10514 
10515   ins_encode %{
10516     __ mnegw(as_Register($dst$$reg),
10517              as_Register($src1$$reg),
10518              as_Register($src2$$reg));
10519   %}
10520 
10521   ins_pipe(imac_reg_reg);
10522 %}
10523 
10524 // Combined Long Multiply &amp; Add/Sub
10525 
10526 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10527   match(Set dst (AddL src3 (MulL src1 src2)));
10528 
10529   ins_cost(INSN_COST * 5);
10530   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10531 
10532   ins_encode %{
10533     __ madd(as_Register($dst$$reg),
10534             as_Register($src1$$reg),
10535             as_Register($src2$$reg),
10536             as_Register($src3$$reg));
10537   %}
10538 
10539   ins_pipe(lmac_reg_reg);
10540 %}
10541 
10542 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10543   match(Set dst (SubL src3 (MulL src1 src2)));
10544 
10545   ins_cost(INSN_COST * 5);
10546   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10547 
10548   ins_encode %{
10549     __ msub(as_Register($dst$$reg),
10550             as_Register($src1$$reg),
10551             as_Register($src2$$reg),
10552             as_Register($src3$$reg));
10553   %}
10554 
10555   ins_pipe(lmac_reg_reg);
10556 %}
10557 
10558 // Combined Long Multiply &amp; Neg
10559 
10560 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10561   match(Set dst (MulL (SubL zero src1) src2));
10562   match(Set dst (MulL src1 (SubL zero src2)));
10563 
10564   ins_cost(INSN_COST * 5);
10565   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10566 
10567   ins_encode %{
10568     __ mneg(as_Register($dst$$reg),
10569             as_Register($src1$$reg),
10570             as_Register($src2$$reg));
10571   %}
10572 
10573   ins_pipe(lmac_reg_reg);
10574 %}
10575 
10576 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10577 
10578 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10579   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10580 
10581   ins_cost(INSN_COST * 3);
10582   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10583 
10584   ins_encode %{
10585     __ smaddl(as_Register($dst$$reg),
10586               as_Register($src1$$reg),
10587               as_Register($src2$$reg),
10588               as_Register($src3$$reg));
10589   %}
10590 
10591   ins_pipe(imac_reg_reg);
10592 %}
10593 
10594 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10595   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10596 
10597   ins_cost(INSN_COST * 3);
10598   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10599 
10600   ins_encode %{
10601     __ smsubl(as_Register($dst$$reg),
10602               as_Register($src1$$reg),
10603               as_Register($src2$$reg),
10604               as_Register($src3$$reg));
10605   %}
10606 
10607   ins_pipe(imac_reg_reg);
10608 %}
10609 
10610 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10611   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10612   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10613 
10614   ins_cost(INSN_COST * 3);
10615   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10616 
10617   ins_encode %{
10618     __ smnegl(as_Register($dst$$reg),
10619               as_Register($src1$$reg),
10620               as_Register($src2$$reg));
10621   %}
10622 
10623   ins_pipe(imac_reg_reg);
10624 %}
10625 
10626 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10627 
10628 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10629   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10630 
10631   ins_cost(INSN_COST * 5);
10632   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10633             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10634 
10635   ins_encode %{
10636     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10637     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10638 
10639   ins_pipe(imac_reg_reg);
10640 %}
10641 
10642 // Integer Divide
10643 
10644 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10645   match(Set dst (DivI src1 src2));
10646 
10647   ins_cost(INSN_COST * 19);
10648   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10649 
10650   ins_encode(aarch64_enc_divw(dst, src1, src2));
10651   ins_pipe(idiv_reg_reg);
10652 %}
10653 
10654 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10655   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10656   ins_cost(INSN_COST);
10657   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10658   ins_encode %{
10659     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10660   %}
10661   ins_pipe(ialu_reg_shift);
10662 %}
10663 
10664 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10665   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10666   ins_cost(INSN_COST);
10667   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10668 
10669   ins_encode %{
10670     __ addw(as_Register($dst$$reg),
10671               as_Register($src$$reg),
10672               as_Register($src$$reg),
10673               Assembler::LSR, 31);
10674   %}
10675   ins_pipe(ialu_reg);
10676 %}
10677 
10678 // Long Divide
10679 
10680 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10681   match(Set dst (DivL src1 src2));
10682 
10683   ins_cost(INSN_COST * 35);
10684   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10685 
10686   ins_encode(aarch64_enc_div(dst, src1, src2));
10687   ins_pipe(ldiv_reg_reg);
10688 %}
10689 
10690 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10691   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10692   ins_cost(INSN_COST);
10693   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10694   ins_encode %{
10695     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10696   %}
10697   ins_pipe(ialu_reg_shift);
10698 %}
10699 
10700 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10701   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10702   ins_cost(INSN_COST);
10703   format %{ &quot;add $dst, $src, $div1&quot; %}
10704 
10705   ins_encode %{
10706     __ add(as_Register($dst$$reg),
10707               as_Register($src$$reg),
10708               as_Register($src$$reg),
10709               Assembler::LSR, 63);
10710   %}
10711   ins_pipe(ialu_reg);
10712 %}
10713 
10714 // Integer Remainder
10715 
10716 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10717   match(Set dst (ModI src1 src2));
10718 
10719   ins_cost(INSN_COST * 22);
10720   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10721             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10722 
10723   ins_encode(aarch64_enc_modw(dst, src1, src2));
10724   ins_pipe(idiv_reg_reg);
10725 %}
10726 
10727 // Long Remainder
10728 
10729 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10730   match(Set dst (ModL src1 src2));
10731 
10732   ins_cost(INSN_COST * 38);
10733   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10734             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10735 
10736   ins_encode(aarch64_enc_mod(dst, src1, src2));
10737   ins_pipe(ldiv_reg_reg);
10738 %}
10739 
10740 // Integer Shifts
10741 
10742 // Shift Left Register
10743 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10744   match(Set dst (LShiftI src1 src2));
10745 
10746   ins_cost(INSN_COST * 2);
10747   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10748 
10749   ins_encode %{
10750     __ lslvw(as_Register($dst$$reg),
10751              as_Register($src1$$reg),
10752              as_Register($src2$$reg));
10753   %}
10754 
10755   ins_pipe(ialu_reg_reg_vshift);
10756 %}
10757 
10758 // Shift Left Immediate
10759 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10760   match(Set dst (LShiftI src1 src2));
10761 
10762   ins_cost(INSN_COST);
10763   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10764 
10765   ins_encode %{
10766     __ lslw(as_Register($dst$$reg),
10767             as_Register($src1$$reg),
10768             $src2$$constant &amp; 0x1f);
10769   %}
10770 
10771   ins_pipe(ialu_reg_shift);
10772 %}
10773 
10774 // Shift Right Logical Register
10775 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10776   match(Set dst (URShiftI src1 src2));
10777 
10778   ins_cost(INSN_COST * 2);
10779   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10780 
10781   ins_encode %{
10782     __ lsrvw(as_Register($dst$$reg),
10783              as_Register($src1$$reg),
10784              as_Register($src2$$reg));
10785   %}
10786 
10787   ins_pipe(ialu_reg_reg_vshift);
10788 %}
10789 
10790 // Shift Right Logical Immediate
10791 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10792   match(Set dst (URShiftI src1 src2));
10793 
10794   ins_cost(INSN_COST);
10795   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10796 
10797   ins_encode %{
10798     __ lsrw(as_Register($dst$$reg),
10799             as_Register($src1$$reg),
10800             $src2$$constant &amp; 0x1f);
10801   %}
10802 
10803   ins_pipe(ialu_reg_shift);
10804 %}
10805 
10806 // Shift Right Arithmetic Register
10807 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10808   match(Set dst (RShiftI src1 src2));
10809 
10810   ins_cost(INSN_COST * 2);
10811   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10812 
10813   ins_encode %{
10814     __ asrvw(as_Register($dst$$reg),
10815              as_Register($src1$$reg),
10816              as_Register($src2$$reg));
10817   %}
10818 
10819   ins_pipe(ialu_reg_reg_vshift);
10820 %}
10821 
10822 // Shift Right Arithmetic Immediate
10823 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10824   match(Set dst (RShiftI src1 src2));
10825 
10826   ins_cost(INSN_COST);
10827   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10828 
10829   ins_encode %{
10830     __ asrw(as_Register($dst$$reg),
10831             as_Register($src1$$reg),
10832             $src2$$constant &amp; 0x1f);
10833   %}
10834 
10835   ins_pipe(ialu_reg_shift);
10836 %}
10837 
10838 // Combined Int Mask and Right Shift (using UBFM)
10839 // TODO
10840 
10841 // Long Shifts
10842 
10843 // Shift Left Register
10844 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10845   match(Set dst (LShiftL src1 src2));
10846 
10847   ins_cost(INSN_COST * 2);
10848   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10849 
10850   ins_encode %{
10851     __ lslv(as_Register($dst$$reg),
10852             as_Register($src1$$reg),
10853             as_Register($src2$$reg));
10854   %}
10855 
10856   ins_pipe(ialu_reg_reg_vshift);
10857 %}
10858 
10859 // Shift Left Immediate
10860 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10861   match(Set dst (LShiftL src1 src2));
10862 
10863   ins_cost(INSN_COST);
10864   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10865 
10866   ins_encode %{
10867     __ lsl(as_Register($dst$$reg),
10868             as_Register($src1$$reg),
10869             $src2$$constant &amp; 0x3f);
10870   %}
10871 
10872   ins_pipe(ialu_reg_shift);
10873 %}
10874 
10875 // Shift Right Logical Register
10876 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10877   match(Set dst (URShiftL src1 src2));
10878 
10879   ins_cost(INSN_COST * 2);
10880   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10881 
10882   ins_encode %{
10883     __ lsrv(as_Register($dst$$reg),
10884             as_Register($src1$$reg),
10885             as_Register($src2$$reg));
10886   %}
10887 
10888   ins_pipe(ialu_reg_reg_vshift);
10889 %}
10890 
10891 // Shift Right Logical Immediate
10892 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10893   match(Set dst (URShiftL src1 src2));
10894 
10895   ins_cost(INSN_COST);
10896   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10897 
10898   ins_encode %{
10899     __ lsr(as_Register($dst$$reg),
10900            as_Register($src1$$reg),
10901            $src2$$constant &amp; 0x3f);
10902   %}
10903 
10904   ins_pipe(ialu_reg_shift);
10905 %}
10906 
10907 // A special-case pattern for card table stores.
10908 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10909   match(Set dst (URShiftL (CastP2X src1) src2));
10910 
10911   ins_cost(INSN_COST);
10912   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10913 
10914   ins_encode %{
10915     __ lsr(as_Register($dst$$reg),
10916            as_Register($src1$$reg),
10917            $src2$$constant &amp; 0x3f);
10918   %}
10919 
10920   ins_pipe(ialu_reg_shift);
10921 %}
10922 
10923 // Shift Right Arithmetic Register
10924 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10925   match(Set dst (RShiftL src1 src2));
10926 
10927   ins_cost(INSN_COST * 2);
10928   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10929 
10930   ins_encode %{
10931     __ asrv(as_Register($dst$$reg),
10932             as_Register($src1$$reg),
10933             as_Register($src2$$reg));
10934   %}
10935 
10936   ins_pipe(ialu_reg_reg_vshift);
10937 %}
10938 
10939 // Shift Right Arithmetic Immediate
10940 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10941   match(Set dst (RShiftL src1 src2));
10942 
10943   ins_cost(INSN_COST);
10944   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10945 
10946   ins_encode %{
10947     __ asr(as_Register($dst$$reg),
10948            as_Register($src1$$reg),
10949            $src2$$constant &amp; 0x3f);
10950   %}
10951 
10952   ins_pipe(ialu_reg_shift);
10953 %}
10954 
10955 // BEGIN This section of the file is automatically generated. Do not edit --------------
10956 
10957 instruct regL_not_reg(iRegLNoSp dst,
10958                          iRegL src1, immL_M1 m1,
10959                          rFlagsReg cr) %{
10960   match(Set dst (XorL src1 m1));
10961   ins_cost(INSN_COST);
10962   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10963 
10964   ins_encode %{
10965     __ eon(as_Register($dst$$reg),
10966               as_Register($src1$$reg),
10967               zr,
10968               Assembler::LSL, 0);
10969   %}
10970 
10971   ins_pipe(ialu_reg);
10972 %}
10973 instruct regI_not_reg(iRegINoSp dst,
10974                          iRegIorL2I src1, immI_M1 m1,
10975                          rFlagsReg cr) %{
10976   match(Set dst (XorI src1 m1));
10977   ins_cost(INSN_COST);
10978   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10979 
10980   ins_encode %{
10981     __ eonw(as_Register($dst$$reg),
10982               as_Register($src1$$reg),
10983               zr,
10984               Assembler::LSL, 0);
10985   %}
10986 
10987   ins_pipe(ialu_reg);
10988 %}
10989 
10990 instruct AndI_reg_not_reg(iRegINoSp dst,
10991                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10992                          rFlagsReg cr) %{
10993   match(Set dst (AndI src1 (XorI src2 m1)));
10994   ins_cost(INSN_COST);
10995   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10996 
10997   ins_encode %{
10998     __ bicw(as_Register($dst$$reg),
10999               as_Register($src1$$reg),
11000               as_Register($src2$$reg),
11001               Assembler::LSL, 0);
11002   %}
11003 
11004   ins_pipe(ialu_reg_reg);
11005 %}
11006 
11007 instruct AndL_reg_not_reg(iRegLNoSp dst,
11008                          iRegL src1, iRegL src2, immL_M1 m1,
11009                          rFlagsReg cr) %{
11010   match(Set dst (AndL src1 (XorL src2 m1)));
11011   ins_cost(INSN_COST);
11012   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
11013 
11014   ins_encode %{
11015     __ bic(as_Register($dst$$reg),
11016               as_Register($src1$$reg),
11017               as_Register($src2$$reg),
11018               Assembler::LSL, 0);
11019   %}
11020 
11021   ins_pipe(ialu_reg_reg);
11022 %}
11023 
11024 instruct OrI_reg_not_reg(iRegINoSp dst,
11025                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11026                          rFlagsReg cr) %{
11027   match(Set dst (OrI src1 (XorI src2 m1)));
11028   ins_cost(INSN_COST);
11029   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
11030 
11031   ins_encode %{
11032     __ ornw(as_Register($dst$$reg),
11033               as_Register($src1$$reg),
11034               as_Register($src2$$reg),
11035               Assembler::LSL, 0);
11036   %}
11037 
11038   ins_pipe(ialu_reg_reg);
11039 %}
11040 
11041 instruct OrL_reg_not_reg(iRegLNoSp dst,
11042                          iRegL src1, iRegL src2, immL_M1 m1,
11043                          rFlagsReg cr) %{
11044   match(Set dst (OrL src1 (XorL src2 m1)));
11045   ins_cost(INSN_COST);
11046   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
11047 
11048   ins_encode %{
11049     __ orn(as_Register($dst$$reg),
11050               as_Register($src1$$reg),
11051               as_Register($src2$$reg),
11052               Assembler::LSL, 0);
11053   %}
11054 
11055   ins_pipe(ialu_reg_reg);
11056 %}
11057 
11058 instruct XorI_reg_not_reg(iRegINoSp dst,
11059                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
11060                          rFlagsReg cr) %{
11061   match(Set dst (XorI m1 (XorI src2 src1)));
11062   ins_cost(INSN_COST);
11063   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
11064 
11065   ins_encode %{
11066     __ eonw(as_Register($dst$$reg),
11067               as_Register($src1$$reg),
11068               as_Register($src2$$reg),
11069               Assembler::LSL, 0);
11070   %}
11071 
11072   ins_pipe(ialu_reg_reg);
11073 %}
11074 
11075 instruct XorL_reg_not_reg(iRegLNoSp dst,
11076                          iRegL src1, iRegL src2, immL_M1 m1,
11077                          rFlagsReg cr) %{
11078   match(Set dst (XorL m1 (XorL src2 src1)));
11079   ins_cost(INSN_COST);
11080   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11081 
11082   ins_encode %{
11083     __ eon(as_Register($dst$$reg),
11084               as_Register($src1$$reg),
11085               as_Register($src2$$reg),
11086               Assembler::LSL, 0);
11087   %}
11088 
11089   ins_pipe(ialu_reg_reg);
11090 %}
11091 
11092 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11093                          iRegIorL2I src1, iRegIorL2I src2,
11094                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11095   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11096   ins_cost(1.9 * INSN_COST);
11097   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11098 
11099   ins_encode %{
11100     __ bicw(as_Register($dst$$reg),
11101               as_Register($src1$$reg),
11102               as_Register($src2$$reg),
11103               Assembler::LSR,
11104               $src3$$constant &amp; 0x1f);
11105   %}
11106 
11107   ins_pipe(ialu_reg_reg_shift);
11108 %}
11109 
11110 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11111                          iRegL src1, iRegL src2,
11112                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11113   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11114   ins_cost(1.9 * INSN_COST);
11115   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11116 
11117   ins_encode %{
11118     __ bic(as_Register($dst$$reg),
11119               as_Register($src1$$reg),
11120               as_Register($src2$$reg),
11121               Assembler::LSR,
11122               $src3$$constant &amp; 0x3f);
11123   %}
11124 
11125   ins_pipe(ialu_reg_reg_shift);
11126 %}
11127 
11128 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11129                          iRegIorL2I src1, iRegIorL2I src2,
11130                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11131   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11132   ins_cost(1.9 * INSN_COST);
11133   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11134 
11135   ins_encode %{
11136     __ bicw(as_Register($dst$$reg),
11137               as_Register($src1$$reg),
11138               as_Register($src2$$reg),
11139               Assembler::ASR,
11140               $src3$$constant &amp; 0x1f);
11141   %}
11142 
11143   ins_pipe(ialu_reg_reg_shift);
11144 %}
11145 
11146 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11147                          iRegL src1, iRegL src2,
11148                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11149   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11150   ins_cost(1.9 * INSN_COST);
11151   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11152 
11153   ins_encode %{
11154     __ bic(as_Register($dst$$reg),
11155               as_Register($src1$$reg),
11156               as_Register($src2$$reg),
11157               Assembler::ASR,
11158               $src3$$constant &amp; 0x3f);
11159   %}
11160 
11161   ins_pipe(ialu_reg_reg_shift);
11162 %}
11163 
11164 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11165                          iRegIorL2I src1, iRegIorL2I src2,
11166                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11167   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11168   ins_cost(1.9 * INSN_COST);
11169   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11170 
11171   ins_encode %{
11172     __ bicw(as_Register($dst$$reg),
11173               as_Register($src1$$reg),
11174               as_Register($src2$$reg),
11175               Assembler::LSL,
11176               $src3$$constant &amp; 0x1f);
11177   %}
11178 
11179   ins_pipe(ialu_reg_reg_shift);
11180 %}
11181 
11182 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11183                          iRegL src1, iRegL src2,
11184                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11185   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11186   ins_cost(1.9 * INSN_COST);
11187   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11188 
11189   ins_encode %{
11190     __ bic(as_Register($dst$$reg),
11191               as_Register($src1$$reg),
11192               as_Register($src2$$reg),
11193               Assembler::LSL,
11194               $src3$$constant &amp; 0x3f);
11195   %}
11196 
11197   ins_pipe(ialu_reg_reg_shift);
11198 %}
11199 
11200 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11201                          iRegIorL2I src1, iRegIorL2I src2,
11202                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11203   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11204   ins_cost(1.9 * INSN_COST);
11205   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11206 
11207   ins_encode %{
11208     __ eonw(as_Register($dst$$reg),
11209               as_Register($src1$$reg),
11210               as_Register($src2$$reg),
11211               Assembler::LSR,
11212               $src3$$constant &amp; 0x1f);
11213   %}
11214 
11215   ins_pipe(ialu_reg_reg_shift);
11216 %}
11217 
11218 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11219                          iRegL src1, iRegL src2,
11220                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11221   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11222   ins_cost(1.9 * INSN_COST);
11223   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11224 
11225   ins_encode %{
11226     __ eon(as_Register($dst$$reg),
11227               as_Register($src1$$reg),
11228               as_Register($src2$$reg),
11229               Assembler::LSR,
11230               $src3$$constant &amp; 0x3f);
11231   %}
11232 
11233   ins_pipe(ialu_reg_reg_shift);
11234 %}
11235 
11236 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11237                          iRegIorL2I src1, iRegIorL2I src2,
11238                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11239   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11240   ins_cost(1.9 * INSN_COST);
11241   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11242 
11243   ins_encode %{
11244     __ eonw(as_Register($dst$$reg),
11245               as_Register($src1$$reg),
11246               as_Register($src2$$reg),
11247               Assembler::ASR,
11248               $src3$$constant &amp; 0x1f);
11249   %}
11250 
11251   ins_pipe(ialu_reg_reg_shift);
11252 %}
11253 
11254 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11255                          iRegL src1, iRegL src2,
11256                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11257   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11258   ins_cost(1.9 * INSN_COST);
11259   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11260 
11261   ins_encode %{
11262     __ eon(as_Register($dst$$reg),
11263               as_Register($src1$$reg),
11264               as_Register($src2$$reg),
11265               Assembler::ASR,
11266               $src3$$constant &amp; 0x3f);
11267   %}
11268 
11269   ins_pipe(ialu_reg_reg_shift);
11270 %}
11271 
11272 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11273                          iRegIorL2I src1, iRegIorL2I src2,
11274                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11275   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11276   ins_cost(1.9 * INSN_COST);
11277   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11278 
11279   ins_encode %{
11280     __ eonw(as_Register($dst$$reg),
11281               as_Register($src1$$reg),
11282               as_Register($src2$$reg),
11283               Assembler::LSL,
11284               $src3$$constant &amp; 0x1f);
11285   %}
11286 
11287   ins_pipe(ialu_reg_reg_shift);
11288 %}
11289 
11290 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11291                          iRegL src1, iRegL src2,
11292                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11293   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11294   ins_cost(1.9 * INSN_COST);
11295   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11296 
11297   ins_encode %{
11298     __ eon(as_Register($dst$$reg),
11299               as_Register($src1$$reg),
11300               as_Register($src2$$reg),
11301               Assembler::LSL,
11302               $src3$$constant &amp; 0x3f);
11303   %}
11304 
11305   ins_pipe(ialu_reg_reg_shift);
11306 %}
11307 
11308 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11309                          iRegIorL2I src1, iRegIorL2I src2,
11310                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11311   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11312   ins_cost(1.9 * INSN_COST);
11313   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11314 
11315   ins_encode %{
11316     __ ornw(as_Register($dst$$reg),
11317               as_Register($src1$$reg),
11318               as_Register($src2$$reg),
11319               Assembler::LSR,
11320               $src3$$constant &amp; 0x1f);
11321   %}
11322 
11323   ins_pipe(ialu_reg_reg_shift);
11324 %}
11325 
11326 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11327                          iRegL src1, iRegL src2,
11328                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11329   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11330   ins_cost(1.9 * INSN_COST);
11331   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11332 
11333   ins_encode %{
11334     __ orn(as_Register($dst$$reg),
11335               as_Register($src1$$reg),
11336               as_Register($src2$$reg),
11337               Assembler::LSR,
11338               $src3$$constant &amp; 0x3f);
11339   %}
11340 
11341   ins_pipe(ialu_reg_reg_shift);
11342 %}
11343 
11344 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11345                          iRegIorL2I src1, iRegIorL2I src2,
11346                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11347   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11348   ins_cost(1.9 * INSN_COST);
11349   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11350 
11351   ins_encode %{
11352     __ ornw(as_Register($dst$$reg),
11353               as_Register($src1$$reg),
11354               as_Register($src2$$reg),
11355               Assembler::ASR,
11356               $src3$$constant &amp; 0x1f);
11357   %}
11358 
11359   ins_pipe(ialu_reg_reg_shift);
11360 %}
11361 
11362 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11363                          iRegL src1, iRegL src2,
11364                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11365   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11366   ins_cost(1.9 * INSN_COST);
11367   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11368 
11369   ins_encode %{
11370     __ orn(as_Register($dst$$reg),
11371               as_Register($src1$$reg),
11372               as_Register($src2$$reg),
11373               Assembler::ASR,
11374               $src3$$constant &amp; 0x3f);
11375   %}
11376 
11377   ins_pipe(ialu_reg_reg_shift);
11378 %}
11379 
11380 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11381                          iRegIorL2I src1, iRegIorL2I src2,
11382                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11383   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11384   ins_cost(1.9 * INSN_COST);
11385   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11386 
11387   ins_encode %{
11388     __ ornw(as_Register($dst$$reg),
11389               as_Register($src1$$reg),
11390               as_Register($src2$$reg),
11391               Assembler::LSL,
11392               $src3$$constant &amp; 0x1f);
11393   %}
11394 
11395   ins_pipe(ialu_reg_reg_shift);
11396 %}
11397 
11398 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11399                          iRegL src1, iRegL src2,
11400                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11401   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11402   ins_cost(1.9 * INSN_COST);
11403   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11404 
11405   ins_encode %{
11406     __ orn(as_Register($dst$$reg),
11407               as_Register($src1$$reg),
11408               as_Register($src2$$reg),
11409               Assembler::LSL,
11410               $src3$$constant &amp; 0x3f);
11411   %}
11412 
11413   ins_pipe(ialu_reg_reg_shift);
11414 %}
11415 
11416 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11417                          iRegIorL2I src1, iRegIorL2I src2,
11418                          immI src3, rFlagsReg cr) %{
11419   match(Set dst (AndI src1 (URShiftI src2 src3)));
11420 
11421   ins_cost(1.9 * INSN_COST);
11422   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11423 
11424   ins_encode %{
11425     __ andw(as_Register($dst$$reg),
11426               as_Register($src1$$reg),
11427               as_Register($src2$$reg),
11428               Assembler::LSR,
11429               $src3$$constant &amp; 0x1f);
11430   %}
11431 
11432   ins_pipe(ialu_reg_reg_shift);
11433 %}
11434 
11435 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11436                          iRegL src1, iRegL src2,
11437                          immI src3, rFlagsReg cr) %{
11438   match(Set dst (AndL src1 (URShiftL src2 src3)));
11439 
11440   ins_cost(1.9 * INSN_COST);
11441   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11442 
11443   ins_encode %{
11444     __ andr(as_Register($dst$$reg),
11445               as_Register($src1$$reg),
11446               as_Register($src2$$reg),
11447               Assembler::LSR,
11448               $src3$$constant &amp; 0x3f);
11449   %}
11450 
11451   ins_pipe(ialu_reg_reg_shift);
11452 %}
11453 
11454 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11455                          iRegIorL2I src1, iRegIorL2I src2,
11456                          immI src3, rFlagsReg cr) %{
11457   match(Set dst (AndI src1 (RShiftI src2 src3)));
11458 
11459   ins_cost(1.9 * INSN_COST);
11460   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11461 
11462   ins_encode %{
11463     __ andw(as_Register($dst$$reg),
11464               as_Register($src1$$reg),
11465               as_Register($src2$$reg),
11466               Assembler::ASR,
11467               $src3$$constant &amp; 0x1f);
11468   %}
11469 
11470   ins_pipe(ialu_reg_reg_shift);
11471 %}
11472 
11473 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11474                          iRegL src1, iRegL src2,
11475                          immI src3, rFlagsReg cr) %{
11476   match(Set dst (AndL src1 (RShiftL src2 src3)));
11477 
11478   ins_cost(1.9 * INSN_COST);
11479   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11480 
11481   ins_encode %{
11482     __ andr(as_Register($dst$$reg),
11483               as_Register($src1$$reg),
11484               as_Register($src2$$reg),
11485               Assembler::ASR,
11486               $src3$$constant &amp; 0x3f);
11487   %}
11488 
11489   ins_pipe(ialu_reg_reg_shift);
11490 %}
11491 
11492 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11493                          iRegIorL2I src1, iRegIorL2I src2,
11494                          immI src3, rFlagsReg cr) %{
11495   match(Set dst (AndI src1 (LShiftI src2 src3)));
11496 
11497   ins_cost(1.9 * INSN_COST);
11498   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11499 
11500   ins_encode %{
11501     __ andw(as_Register($dst$$reg),
11502               as_Register($src1$$reg),
11503               as_Register($src2$$reg),
11504               Assembler::LSL,
11505               $src3$$constant &amp; 0x1f);
11506   %}
11507 
11508   ins_pipe(ialu_reg_reg_shift);
11509 %}
11510 
11511 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11512                          iRegL src1, iRegL src2,
11513                          immI src3, rFlagsReg cr) %{
11514   match(Set dst (AndL src1 (LShiftL src2 src3)));
11515 
11516   ins_cost(1.9 * INSN_COST);
11517   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11518 
11519   ins_encode %{
11520     __ andr(as_Register($dst$$reg),
11521               as_Register($src1$$reg),
11522               as_Register($src2$$reg),
11523               Assembler::LSL,
11524               $src3$$constant &amp; 0x3f);
11525   %}
11526 
11527   ins_pipe(ialu_reg_reg_shift);
11528 %}
11529 
11530 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11531                          iRegIorL2I src1, iRegIorL2I src2,
11532                          immI src3, rFlagsReg cr) %{
11533   match(Set dst (XorI src1 (URShiftI src2 src3)));
11534 
11535   ins_cost(1.9 * INSN_COST);
11536   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11537 
11538   ins_encode %{
11539     __ eorw(as_Register($dst$$reg),
11540               as_Register($src1$$reg),
11541               as_Register($src2$$reg),
11542               Assembler::LSR,
11543               $src3$$constant &amp; 0x1f);
11544   %}
11545 
11546   ins_pipe(ialu_reg_reg_shift);
11547 %}
11548 
11549 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11550                          iRegL src1, iRegL src2,
11551                          immI src3, rFlagsReg cr) %{
11552   match(Set dst (XorL src1 (URShiftL src2 src3)));
11553 
11554   ins_cost(1.9 * INSN_COST);
11555   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11556 
11557   ins_encode %{
11558     __ eor(as_Register($dst$$reg),
11559               as_Register($src1$$reg),
11560               as_Register($src2$$reg),
11561               Assembler::LSR,
11562               $src3$$constant &amp; 0x3f);
11563   %}
11564 
11565   ins_pipe(ialu_reg_reg_shift);
11566 %}
11567 
11568 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11569                          iRegIorL2I src1, iRegIorL2I src2,
11570                          immI src3, rFlagsReg cr) %{
11571   match(Set dst (XorI src1 (RShiftI src2 src3)));
11572 
11573   ins_cost(1.9 * INSN_COST);
11574   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11575 
11576   ins_encode %{
11577     __ eorw(as_Register($dst$$reg),
11578               as_Register($src1$$reg),
11579               as_Register($src2$$reg),
11580               Assembler::ASR,
11581               $src3$$constant &amp; 0x1f);
11582   %}
11583 
11584   ins_pipe(ialu_reg_reg_shift);
11585 %}
11586 
11587 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11588                          iRegL src1, iRegL src2,
11589                          immI src3, rFlagsReg cr) %{
11590   match(Set dst (XorL src1 (RShiftL src2 src3)));
11591 
11592   ins_cost(1.9 * INSN_COST);
11593   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11594 
11595   ins_encode %{
11596     __ eor(as_Register($dst$$reg),
11597               as_Register($src1$$reg),
11598               as_Register($src2$$reg),
11599               Assembler::ASR,
11600               $src3$$constant &amp; 0x3f);
11601   %}
11602 
11603   ins_pipe(ialu_reg_reg_shift);
11604 %}
11605 
11606 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11607                          iRegIorL2I src1, iRegIorL2I src2,
11608                          immI src3, rFlagsReg cr) %{
11609   match(Set dst (XorI src1 (LShiftI src2 src3)));
11610 
11611   ins_cost(1.9 * INSN_COST);
11612   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11613 
11614   ins_encode %{
11615     __ eorw(as_Register($dst$$reg),
11616               as_Register($src1$$reg),
11617               as_Register($src2$$reg),
11618               Assembler::LSL,
11619               $src3$$constant &amp; 0x1f);
11620   %}
11621 
11622   ins_pipe(ialu_reg_reg_shift);
11623 %}
11624 
11625 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11626                          iRegL src1, iRegL src2,
11627                          immI src3, rFlagsReg cr) %{
11628   match(Set dst (XorL src1 (LShiftL src2 src3)));
11629 
11630   ins_cost(1.9 * INSN_COST);
11631   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11632 
11633   ins_encode %{
11634     __ eor(as_Register($dst$$reg),
11635               as_Register($src1$$reg),
11636               as_Register($src2$$reg),
11637               Assembler::LSL,
11638               $src3$$constant &amp; 0x3f);
11639   %}
11640 
11641   ins_pipe(ialu_reg_reg_shift);
11642 %}
11643 
11644 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11645                          iRegIorL2I src1, iRegIorL2I src2,
11646                          immI src3, rFlagsReg cr) %{
11647   match(Set dst (OrI src1 (URShiftI src2 src3)));
11648 
11649   ins_cost(1.9 * INSN_COST);
11650   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11651 
11652   ins_encode %{
11653     __ orrw(as_Register($dst$$reg),
11654               as_Register($src1$$reg),
11655               as_Register($src2$$reg),
11656               Assembler::LSR,
11657               $src3$$constant &amp; 0x1f);
11658   %}
11659 
11660   ins_pipe(ialu_reg_reg_shift);
11661 %}
11662 
11663 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11664                          iRegL src1, iRegL src2,
11665                          immI src3, rFlagsReg cr) %{
11666   match(Set dst (OrL src1 (URShiftL src2 src3)));
11667 
11668   ins_cost(1.9 * INSN_COST);
11669   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11670 
11671   ins_encode %{
11672     __ orr(as_Register($dst$$reg),
11673               as_Register($src1$$reg),
11674               as_Register($src2$$reg),
11675               Assembler::LSR,
11676               $src3$$constant &amp; 0x3f);
11677   %}
11678 
11679   ins_pipe(ialu_reg_reg_shift);
11680 %}
11681 
11682 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11683                          iRegIorL2I src1, iRegIorL2I src2,
11684                          immI src3, rFlagsReg cr) %{
11685   match(Set dst (OrI src1 (RShiftI src2 src3)));
11686 
11687   ins_cost(1.9 * INSN_COST);
11688   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11689 
11690   ins_encode %{
11691     __ orrw(as_Register($dst$$reg),
11692               as_Register($src1$$reg),
11693               as_Register($src2$$reg),
11694               Assembler::ASR,
11695               $src3$$constant &amp; 0x1f);
11696   %}
11697 
11698   ins_pipe(ialu_reg_reg_shift);
11699 %}
11700 
11701 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11702                          iRegL src1, iRegL src2,
11703                          immI src3, rFlagsReg cr) %{
11704   match(Set dst (OrL src1 (RShiftL src2 src3)));
11705 
11706   ins_cost(1.9 * INSN_COST);
11707   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11708 
11709   ins_encode %{
11710     __ orr(as_Register($dst$$reg),
11711               as_Register($src1$$reg),
11712               as_Register($src2$$reg),
11713               Assembler::ASR,
11714               $src3$$constant &amp; 0x3f);
11715   %}
11716 
11717   ins_pipe(ialu_reg_reg_shift);
11718 %}
11719 
11720 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11721                          iRegIorL2I src1, iRegIorL2I src2,
11722                          immI src3, rFlagsReg cr) %{
11723   match(Set dst (OrI src1 (LShiftI src2 src3)));
11724 
11725   ins_cost(1.9 * INSN_COST);
11726   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11727 
11728   ins_encode %{
11729     __ orrw(as_Register($dst$$reg),
11730               as_Register($src1$$reg),
11731               as_Register($src2$$reg),
11732               Assembler::LSL,
11733               $src3$$constant &amp; 0x1f);
11734   %}
11735 
11736   ins_pipe(ialu_reg_reg_shift);
11737 %}
11738 
11739 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11740                          iRegL src1, iRegL src2,
11741                          immI src3, rFlagsReg cr) %{
11742   match(Set dst (OrL src1 (LShiftL src2 src3)));
11743 
11744   ins_cost(1.9 * INSN_COST);
11745   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11746 
11747   ins_encode %{
11748     __ orr(as_Register($dst$$reg),
11749               as_Register($src1$$reg),
11750               as_Register($src2$$reg),
11751               Assembler::LSL,
11752               $src3$$constant &amp; 0x3f);
11753   %}
11754 
11755   ins_pipe(ialu_reg_reg_shift);
11756 %}
11757 
11758 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11759                          iRegIorL2I src1, iRegIorL2I src2,
11760                          immI src3, rFlagsReg cr) %{
11761   match(Set dst (AddI src1 (URShiftI src2 src3)));
11762 
11763   ins_cost(1.9 * INSN_COST);
11764   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11765 
11766   ins_encode %{
11767     __ addw(as_Register($dst$$reg),
11768               as_Register($src1$$reg),
11769               as_Register($src2$$reg),
11770               Assembler::LSR,
11771               $src3$$constant &amp; 0x1f);
11772   %}
11773 
11774   ins_pipe(ialu_reg_reg_shift);
11775 %}
11776 
11777 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11778                          iRegL src1, iRegL src2,
11779                          immI src3, rFlagsReg cr) %{
11780   match(Set dst (AddL src1 (URShiftL src2 src3)));
11781 
11782   ins_cost(1.9 * INSN_COST);
11783   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11784 
11785   ins_encode %{
11786     __ add(as_Register($dst$$reg),
11787               as_Register($src1$$reg),
11788               as_Register($src2$$reg),
11789               Assembler::LSR,
11790               $src3$$constant &amp; 0x3f);
11791   %}
11792 
11793   ins_pipe(ialu_reg_reg_shift);
11794 %}
11795 
11796 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11797                          iRegIorL2I src1, iRegIorL2I src2,
11798                          immI src3, rFlagsReg cr) %{
11799   match(Set dst (AddI src1 (RShiftI src2 src3)));
11800 
11801   ins_cost(1.9 * INSN_COST);
11802   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11803 
11804   ins_encode %{
11805     __ addw(as_Register($dst$$reg),
11806               as_Register($src1$$reg),
11807               as_Register($src2$$reg),
11808               Assembler::ASR,
11809               $src3$$constant &amp; 0x1f);
11810   %}
11811 
11812   ins_pipe(ialu_reg_reg_shift);
11813 %}
11814 
11815 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11816                          iRegL src1, iRegL src2,
11817                          immI src3, rFlagsReg cr) %{
11818   match(Set dst (AddL src1 (RShiftL src2 src3)));
11819 
11820   ins_cost(1.9 * INSN_COST);
11821   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11822 
11823   ins_encode %{
11824     __ add(as_Register($dst$$reg),
11825               as_Register($src1$$reg),
11826               as_Register($src2$$reg),
11827               Assembler::ASR,
11828               $src3$$constant &amp; 0x3f);
11829   %}
11830 
11831   ins_pipe(ialu_reg_reg_shift);
11832 %}
11833 
11834 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11835                          iRegIorL2I src1, iRegIorL2I src2,
11836                          immI src3, rFlagsReg cr) %{
11837   match(Set dst (AddI src1 (LShiftI src2 src3)));
11838 
11839   ins_cost(1.9 * INSN_COST);
11840   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11841 
11842   ins_encode %{
11843     __ addw(as_Register($dst$$reg),
11844               as_Register($src1$$reg),
11845               as_Register($src2$$reg),
11846               Assembler::LSL,
11847               $src3$$constant &amp; 0x1f);
11848   %}
11849 
11850   ins_pipe(ialu_reg_reg_shift);
11851 %}
11852 
11853 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11854                          iRegL src1, iRegL src2,
11855                          immI src3, rFlagsReg cr) %{
11856   match(Set dst (AddL src1 (LShiftL src2 src3)));
11857 
11858   ins_cost(1.9 * INSN_COST);
11859   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11860 
11861   ins_encode %{
11862     __ add(as_Register($dst$$reg),
11863               as_Register($src1$$reg),
11864               as_Register($src2$$reg),
11865               Assembler::LSL,
11866               $src3$$constant &amp; 0x3f);
11867   %}
11868 
11869   ins_pipe(ialu_reg_reg_shift);
11870 %}
11871 
11872 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11873                          iRegIorL2I src1, iRegIorL2I src2,
11874                          immI src3, rFlagsReg cr) %{
11875   match(Set dst (SubI src1 (URShiftI src2 src3)));
11876 
11877   ins_cost(1.9 * INSN_COST);
11878   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11879 
11880   ins_encode %{
11881     __ subw(as_Register($dst$$reg),
11882               as_Register($src1$$reg),
11883               as_Register($src2$$reg),
11884               Assembler::LSR,
11885               $src3$$constant &amp; 0x1f);
11886   %}
11887 
11888   ins_pipe(ialu_reg_reg_shift);
11889 %}
11890 
11891 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11892                          iRegL src1, iRegL src2,
11893                          immI src3, rFlagsReg cr) %{
11894   match(Set dst (SubL src1 (URShiftL src2 src3)));
11895 
11896   ins_cost(1.9 * INSN_COST);
11897   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11898 
11899   ins_encode %{
11900     __ sub(as_Register($dst$$reg),
11901               as_Register($src1$$reg),
11902               as_Register($src2$$reg),
11903               Assembler::LSR,
11904               $src3$$constant &amp; 0x3f);
11905   %}
11906 
11907   ins_pipe(ialu_reg_reg_shift);
11908 %}
11909 
11910 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11911                          iRegIorL2I src1, iRegIorL2I src2,
11912                          immI src3, rFlagsReg cr) %{
11913   match(Set dst (SubI src1 (RShiftI src2 src3)));
11914 
11915   ins_cost(1.9 * INSN_COST);
11916   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11917 
11918   ins_encode %{
11919     __ subw(as_Register($dst$$reg),
11920               as_Register($src1$$reg),
11921               as_Register($src2$$reg),
11922               Assembler::ASR,
11923               $src3$$constant &amp; 0x1f);
11924   %}
11925 
11926   ins_pipe(ialu_reg_reg_shift);
11927 %}
11928 
11929 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11930                          iRegL src1, iRegL src2,
11931                          immI src3, rFlagsReg cr) %{
11932   match(Set dst (SubL src1 (RShiftL src2 src3)));
11933 
11934   ins_cost(1.9 * INSN_COST);
11935   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11936 
11937   ins_encode %{
11938     __ sub(as_Register($dst$$reg),
11939               as_Register($src1$$reg),
11940               as_Register($src2$$reg),
11941               Assembler::ASR,
11942               $src3$$constant &amp; 0x3f);
11943   %}
11944 
11945   ins_pipe(ialu_reg_reg_shift);
11946 %}
11947 
11948 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11949                          iRegIorL2I src1, iRegIorL2I src2,
11950                          immI src3, rFlagsReg cr) %{
11951   match(Set dst (SubI src1 (LShiftI src2 src3)));
11952 
11953   ins_cost(1.9 * INSN_COST);
11954   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11955 
11956   ins_encode %{
11957     __ subw(as_Register($dst$$reg),
11958               as_Register($src1$$reg),
11959               as_Register($src2$$reg),
11960               Assembler::LSL,
11961               $src3$$constant &amp; 0x1f);
11962   %}
11963 
11964   ins_pipe(ialu_reg_reg_shift);
11965 %}
11966 
11967 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11968                          iRegL src1, iRegL src2,
11969                          immI src3, rFlagsReg cr) %{
11970   match(Set dst (SubL src1 (LShiftL src2 src3)));
11971 
11972   ins_cost(1.9 * INSN_COST);
11973   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11974 
11975   ins_encode %{
11976     __ sub(as_Register($dst$$reg),
11977               as_Register($src1$$reg),
11978               as_Register($src2$$reg),
11979               Assembler::LSL,
11980               $src3$$constant &amp; 0x3f);
11981   %}
11982 
11983   ins_pipe(ialu_reg_reg_shift);
11984 %}
11985 
11986 
11987 
11988 // Shift Left followed by Shift Right.
11989 // This idiom is used by the compiler for the i2b bytecode etc.
11990 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11991 %{
11992   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11993   ins_cost(INSN_COST * 2);
11994   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11995   ins_encode %{
11996     int lshift = $lshift_count$$constant &amp; 63;
11997     int rshift = $rshift_count$$constant &amp; 63;
11998     int s = 63 - lshift;
11999     int r = (rshift - lshift) &amp; 63;
12000     __ sbfm(as_Register($dst$$reg),
12001             as_Register($src$$reg),
12002             r, s);
12003   %}
12004 
12005   ins_pipe(ialu_reg_shift);
12006 %}
12007 
12008 // Shift Left followed by Shift Right.
12009 // This idiom is used by the compiler for the i2b bytecode etc.
12010 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12011 %{
12012   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
12013   ins_cost(INSN_COST * 2);
12014   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12015   ins_encode %{
12016     int lshift = $lshift_count$$constant &amp; 31;
12017     int rshift = $rshift_count$$constant &amp; 31;
12018     int s = 31 - lshift;
12019     int r = (rshift - lshift) &amp; 31;
12020     __ sbfmw(as_Register($dst$$reg),
12021             as_Register($src$$reg),
12022             r, s);
12023   %}
12024 
12025   ins_pipe(ialu_reg_shift);
12026 %}
12027 
12028 // Shift Left followed by Shift Right.
12029 // This idiom is used by the compiler for the i2b bytecode etc.
12030 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
12031 %{
12032   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
12033   ins_cost(INSN_COST * 2);
12034   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
12035   ins_encode %{
12036     int lshift = $lshift_count$$constant &amp; 63;
12037     int rshift = $rshift_count$$constant &amp; 63;
12038     int s = 63 - lshift;
12039     int r = (rshift - lshift) &amp; 63;
12040     __ ubfm(as_Register($dst$$reg),
12041             as_Register($src$$reg),
12042             r, s);
12043   %}
12044 
12045   ins_pipe(ialu_reg_shift);
12046 %}
12047 
12048 // Shift Left followed by Shift Right.
12049 // This idiom is used by the compiler for the i2b bytecode etc.
12050 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
12051 %{
12052   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
12053   ins_cost(INSN_COST * 2);
12054   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
12055   ins_encode %{
12056     int lshift = $lshift_count$$constant &amp; 31;
12057     int rshift = $rshift_count$$constant &amp; 31;
12058     int s = 31 - lshift;
12059     int r = (rshift - lshift) &amp; 31;
12060     __ ubfmw(as_Register($dst$$reg),
12061             as_Register($src$$reg),
12062             r, s);
12063   %}
12064 
12065   ins_pipe(ialu_reg_shift);
12066 %}
12067 // Bitfield extract with shift &amp; mask
12068 
12069 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12070 %{
12071   match(Set dst (AndI (URShiftI src rshift) mask));
12072   // Make sure we are not going to exceed what ubfxw can do.
12073   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12074 
12075   ins_cost(INSN_COST);
12076   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12077   ins_encode %{
12078     int rshift = $rshift$$constant &amp; 31;
12079     long mask = $mask$$constant;
12080     int width = exact_log2(mask+1);
12081     __ ubfxw(as_Register($dst$$reg),
12082             as_Register($src$$reg), rshift, width);
12083   %}
12084   ins_pipe(ialu_reg_shift);
12085 %}
12086 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12087 %{
12088   match(Set dst (AndL (URShiftL src rshift) mask));
12089   // Make sure we are not going to exceed what ubfx can do.
12090   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12091 
12092   ins_cost(INSN_COST);
12093   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12094   ins_encode %{
12095     int rshift = $rshift$$constant &amp; 63;
12096     long mask = $mask$$constant;
12097     int width = exact_log2_long(mask+1);
12098     __ ubfx(as_Register($dst$$reg),
12099             as_Register($src$$reg), rshift, width);
12100   %}
12101   ins_pipe(ialu_reg_shift);
12102 %}
12103 
12104 // We can use ubfx when extending an And with a mask when we know mask
12105 // is positive.  We know that because immI_bitmask guarantees it.
12106 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12107 %{
12108   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12109   // Make sure we are not going to exceed what ubfxw can do.
12110   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12111 
12112   ins_cost(INSN_COST * 2);
12113   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12114   ins_encode %{
12115     int rshift = $rshift$$constant &amp; 31;
12116     long mask = $mask$$constant;
12117     int width = exact_log2(mask+1);
12118     __ ubfx(as_Register($dst$$reg),
12119             as_Register($src$$reg), rshift, width);
12120   %}
12121   ins_pipe(ialu_reg_shift);
12122 %}
12123 
12124 // We can use ubfiz when masking by a positive number and then left shifting the result.
12125 // We know that the mask is positive because immI_bitmask guarantees it.
12126 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12127 %{
12128   match(Set dst (LShiftI (AndI src mask) lshift));
12129   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12130 
12131   ins_cost(INSN_COST);
12132   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12133   ins_encode %{
12134     int lshift = $lshift$$constant &amp; 31;
12135     long mask = $mask$$constant;
12136     int width = exact_log2(mask+1);
12137     __ ubfizw(as_Register($dst$$reg),
12138           as_Register($src$$reg), lshift, width);
12139   %}
12140   ins_pipe(ialu_reg_shift);
12141 %}
12142 // We can use ubfiz when masking by a positive number and then left shifting the result.
12143 // We know that the mask is positive because immL_bitmask guarantees it.
12144 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12145 %{
12146   match(Set dst (LShiftL (AndL src mask) lshift));
12147   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12148 
12149   ins_cost(INSN_COST);
12150   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12151   ins_encode %{
12152     int lshift = $lshift$$constant &amp; 63;
12153     long mask = $mask$$constant;
12154     int width = exact_log2_long(mask+1);
12155     __ ubfiz(as_Register($dst$$reg),
12156           as_Register($src$$reg), lshift, width);
12157   %}
12158   ins_pipe(ialu_reg_shift);
12159 %}
12160 
12161 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12162 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12163 %{
12164   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12165   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12166 
12167   ins_cost(INSN_COST);
12168   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12169   ins_encode %{
12170     int lshift = $lshift$$constant &amp; 63;
12171     long mask = $mask$$constant;
12172     int width = exact_log2(mask+1);
12173     __ ubfiz(as_Register($dst$$reg),
12174              as_Register($src$$reg), lshift, width);
12175   %}
12176   ins_pipe(ialu_reg_shift);
12177 %}
12178 
12179 // Rotations
12180 
12181 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12182 %{
12183   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12184   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12185 
12186   ins_cost(INSN_COST);
12187   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12188 
12189   ins_encode %{
12190     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12191             $rshift$$constant &amp; 63);
12192   %}
12193   ins_pipe(ialu_reg_reg_extr);
12194 %}
12195 
12196 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12197 %{
12198   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12199   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12200 
12201   ins_cost(INSN_COST);
12202   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12203 
12204   ins_encode %{
12205     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12206             $rshift$$constant &amp; 31);
12207   %}
12208   ins_pipe(ialu_reg_reg_extr);
12209 %}
12210 
12211 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12212 %{
12213   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12214   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12215 
12216   ins_cost(INSN_COST);
12217   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12218 
12219   ins_encode %{
12220     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12221             $rshift$$constant &amp; 63);
12222   %}
12223   ins_pipe(ialu_reg_reg_extr);
12224 %}
12225 
12226 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12227 %{
12228   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12229   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12230 
12231   ins_cost(INSN_COST);
12232   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12233 
12234   ins_encode %{
12235     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12236             $rshift$$constant &amp; 31);
12237   %}
12238   ins_pipe(ialu_reg_reg_extr);
12239 %}
12240 
12241 
12242 // rol expander
12243 
12244 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12245 %{
12246   effect(DEF dst, USE src, USE shift);
12247 
12248   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12249   ins_cost(INSN_COST * 3);
12250   ins_encode %{
12251     __ subw(rscratch1, zr, as_Register($shift$$reg));
12252     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12253             rscratch1);
12254     %}
12255   ins_pipe(ialu_reg_reg_vshift);
12256 %}
12257 
12258 // rol expander
12259 
12260 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12261 %{
12262   effect(DEF dst, USE src, USE shift);
12263 
12264   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12265   ins_cost(INSN_COST * 3);
12266   ins_encode %{
12267     __ subw(rscratch1, zr, as_Register($shift$$reg));
12268     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12269             rscratch1);
12270     %}
12271   ins_pipe(ialu_reg_reg_vshift);
12272 %}
12273 
12274 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12275 %{
12276   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12277 
12278   expand %{
12279     rolL_rReg(dst, src, shift, cr);
12280   %}
12281 %}
12282 
12283 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12284 %{
12285   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12286 
12287   expand %{
12288     rolL_rReg(dst, src, shift, cr);
12289   %}
12290 %}
12291 
12292 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12293 %{
12294   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12295 
12296   expand %{
12297     rolI_rReg(dst, src, shift, cr);
12298   %}
12299 %}
12300 
12301 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12302 %{
12303   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12304 
12305   expand %{
12306     rolI_rReg(dst, src, shift, cr);
12307   %}
12308 %}
12309 
12310 // ror expander
12311 
12312 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12313 %{
12314   effect(DEF dst, USE src, USE shift);
12315 
12316   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12317   ins_cost(INSN_COST);
12318   ins_encode %{
12319     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12320             as_Register($shift$$reg));
12321     %}
12322   ins_pipe(ialu_reg_reg_vshift);
12323 %}
12324 
12325 // ror expander
12326 
12327 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12328 %{
12329   effect(DEF dst, USE src, USE shift);
12330 
12331   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12332   ins_cost(INSN_COST);
12333   ins_encode %{
12334     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12335             as_Register($shift$$reg));
12336     %}
12337   ins_pipe(ialu_reg_reg_vshift);
12338 %}
12339 
12340 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12341 %{
12342   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12343 
12344   expand %{
12345     rorL_rReg(dst, src, shift, cr);
12346   %}
12347 %}
12348 
12349 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12350 %{
12351   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12352 
12353   expand %{
12354     rorL_rReg(dst, src, shift, cr);
12355   %}
12356 %}
12357 
12358 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12359 %{
12360   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12361 
12362   expand %{
12363     rorI_rReg(dst, src, shift, cr);
12364   %}
12365 %}
12366 
12367 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12368 %{
12369   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12370 
12371   expand %{
12372     rorI_rReg(dst, src, shift, cr);
12373   %}
12374 %}
12375 
12376 // Add/subtract (extended)
12377 
12378 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12379 %{
12380   match(Set dst (AddL src1 (ConvI2L src2)));
12381   ins_cost(INSN_COST);
12382   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12383 
12384    ins_encode %{
12385      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12386             as_Register($src2$$reg), ext::sxtw);
12387    %}
12388   ins_pipe(ialu_reg_reg);
12389 %};
12390 
12391 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12392 %{
12393   match(Set dst (SubL src1 (ConvI2L src2)));
12394   ins_cost(INSN_COST);
12395   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12396 
12397    ins_encode %{
12398      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12399             as_Register($src2$$reg), ext::sxtw);
12400    %}
12401   ins_pipe(ialu_reg_reg);
12402 %};
12403 
12404 
12405 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12406 %{
12407   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12408   ins_cost(INSN_COST);
12409   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12410 
12411    ins_encode %{
12412      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12413             as_Register($src2$$reg), ext::sxth);
12414    %}
12415   ins_pipe(ialu_reg_reg);
12416 %}
12417 
12418 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12419 %{
12420   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12421   ins_cost(INSN_COST);
12422   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12423 
12424    ins_encode %{
12425      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12426             as_Register($src2$$reg), ext::sxtb);
12427    %}
12428   ins_pipe(ialu_reg_reg);
12429 %}
12430 
12431 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12432 %{
12433   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12434   ins_cost(INSN_COST);
12435   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12436 
12437    ins_encode %{
12438      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12439             as_Register($src2$$reg), ext::uxtb);
12440    %}
12441   ins_pipe(ialu_reg_reg);
12442 %}
12443 
12444 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12445 %{
12446   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12447   ins_cost(INSN_COST);
12448   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12449 
12450    ins_encode %{
12451      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12452             as_Register($src2$$reg), ext::sxth);
12453    %}
12454   ins_pipe(ialu_reg_reg);
12455 %}
12456 
12457 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12458 %{
12459   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12460   ins_cost(INSN_COST);
12461   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12462 
12463    ins_encode %{
12464      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12465             as_Register($src2$$reg), ext::sxtw);
12466    %}
12467   ins_pipe(ialu_reg_reg);
12468 %}
12469 
12470 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12471 %{
12472   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12473   ins_cost(INSN_COST);
12474   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12475 
12476    ins_encode %{
12477      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12478             as_Register($src2$$reg), ext::sxtb);
12479    %}
12480   ins_pipe(ialu_reg_reg);
12481 %}
12482 
12483 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12484 %{
12485   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12486   ins_cost(INSN_COST);
12487   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12488 
12489    ins_encode %{
12490      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12491             as_Register($src2$$reg), ext::uxtb);
12492    %}
12493   ins_pipe(ialu_reg_reg);
12494 %}
12495 
12496 
12497 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12498 %{
12499   match(Set dst (AddI src1 (AndI src2 mask)));
12500   ins_cost(INSN_COST);
12501   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12502 
12503    ins_encode %{
12504      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12505             as_Register($src2$$reg), ext::uxtb);
12506    %}
12507   ins_pipe(ialu_reg_reg);
12508 %}
12509 
12510 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12511 %{
12512   match(Set dst (AddI src1 (AndI src2 mask)));
12513   ins_cost(INSN_COST);
12514   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12515 
12516    ins_encode %{
12517      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12518             as_Register($src2$$reg), ext::uxth);
12519    %}
12520   ins_pipe(ialu_reg_reg);
12521 %}
12522 
12523 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12524 %{
12525   match(Set dst (AddL src1 (AndL src2 mask)));
12526   ins_cost(INSN_COST);
12527   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12528 
12529    ins_encode %{
12530      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12531             as_Register($src2$$reg), ext::uxtb);
12532    %}
12533   ins_pipe(ialu_reg_reg);
12534 %}
12535 
12536 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12537 %{
12538   match(Set dst (AddL src1 (AndL src2 mask)));
12539   ins_cost(INSN_COST);
12540   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12541 
12542    ins_encode %{
12543      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12544             as_Register($src2$$reg), ext::uxth);
12545    %}
12546   ins_pipe(ialu_reg_reg);
12547 %}
12548 
12549 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12550 %{
12551   match(Set dst (AddL src1 (AndL src2 mask)));
12552   ins_cost(INSN_COST);
12553   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12554 
12555    ins_encode %{
12556      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12557             as_Register($src2$$reg), ext::uxtw);
12558    %}
12559   ins_pipe(ialu_reg_reg);
12560 %}
12561 
12562 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12563 %{
12564   match(Set dst (SubI src1 (AndI src2 mask)));
12565   ins_cost(INSN_COST);
12566   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12567 
12568    ins_encode %{
12569      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12570             as_Register($src2$$reg), ext::uxtb);
12571    %}
12572   ins_pipe(ialu_reg_reg);
12573 %}
12574 
12575 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12576 %{
12577   match(Set dst (SubI src1 (AndI src2 mask)));
12578   ins_cost(INSN_COST);
12579   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12580 
12581    ins_encode %{
12582      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12583             as_Register($src2$$reg), ext::uxth);
12584    %}
12585   ins_pipe(ialu_reg_reg);
12586 %}
12587 
12588 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12589 %{
12590   match(Set dst (SubL src1 (AndL src2 mask)));
12591   ins_cost(INSN_COST);
12592   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12593 
12594    ins_encode %{
12595      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12596             as_Register($src2$$reg), ext::uxtb);
12597    %}
12598   ins_pipe(ialu_reg_reg);
12599 %}
12600 
12601 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12602 %{
12603   match(Set dst (SubL src1 (AndL src2 mask)));
12604   ins_cost(INSN_COST);
12605   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12606 
12607    ins_encode %{
12608      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12609             as_Register($src2$$reg), ext::uxth);
12610    %}
12611   ins_pipe(ialu_reg_reg);
12612 %}
12613 
12614 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12615 %{
12616   match(Set dst (SubL src1 (AndL src2 mask)));
12617   ins_cost(INSN_COST);
12618   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12619 
12620    ins_encode %{
12621      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12622             as_Register($src2$$reg), ext::uxtw);
12623    %}
12624   ins_pipe(ialu_reg_reg);
12625 %}
12626 
12627 
12628 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12629 %{
12630   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12631   ins_cost(1.9 * INSN_COST);
12632   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12633 
12634    ins_encode %{
12635      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12636             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12637    %}
12638   ins_pipe(ialu_reg_reg_shift);
12639 %}
12640 
12641 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12642 %{
12643   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12644   ins_cost(1.9 * INSN_COST);
12645   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12646 
12647    ins_encode %{
12648      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12649             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12650    %}
12651   ins_pipe(ialu_reg_reg_shift);
12652 %}
12653 
12654 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12655 %{
12656   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12657   ins_cost(1.9 * INSN_COST);
12658   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12659 
12660    ins_encode %{
12661      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12662             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12663    %}
12664   ins_pipe(ialu_reg_reg_shift);
12665 %}
12666 
12667 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12668 %{
12669   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12670   ins_cost(1.9 * INSN_COST);
12671   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12672 
12673    ins_encode %{
12674      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12675             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12676    %}
12677   ins_pipe(ialu_reg_reg_shift);
12678 %}
12679 
12680 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12681 %{
12682   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12683   ins_cost(1.9 * INSN_COST);
12684   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12685 
12686    ins_encode %{
12687      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12688             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12689    %}
12690   ins_pipe(ialu_reg_reg_shift);
12691 %}
12692 
12693 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12694 %{
12695   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12696   ins_cost(1.9 * INSN_COST);
12697   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12698 
12699    ins_encode %{
12700      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12701             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12702    %}
12703   ins_pipe(ialu_reg_reg_shift);
12704 %}
12705 
12706 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12707 %{
12708   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12709   ins_cost(1.9 * INSN_COST);
12710   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12711 
12712    ins_encode %{
12713      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12714             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12715    %}
12716   ins_pipe(ialu_reg_reg_shift);
12717 %}
12718 
12719 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12720 %{
12721   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12722   ins_cost(1.9 * INSN_COST);
12723   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12724 
12725    ins_encode %{
12726      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12727             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12728    %}
12729   ins_pipe(ialu_reg_reg_shift);
12730 %}
12731 
12732 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12733 %{
12734   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12735   ins_cost(1.9 * INSN_COST);
12736   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12737 
12738    ins_encode %{
12739      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12740             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12741    %}
12742   ins_pipe(ialu_reg_reg_shift);
12743 %}
12744 
12745 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12746 %{
12747   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12748   ins_cost(1.9 * INSN_COST);
12749   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12750 
12751    ins_encode %{
12752      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12753             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12754    %}
12755   ins_pipe(ialu_reg_reg_shift);
12756 %}
12757 
12758 
12759 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12760 %{
12761   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12762   ins_cost(1.9 * INSN_COST);
12763   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12764 
12765    ins_encode %{
12766      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12767             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12768    %}
12769   ins_pipe(ialu_reg_reg_shift);
12770 %};
12771 
12772 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12773 %{
12774   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12775   ins_cost(1.9 * INSN_COST);
12776   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12777 
12778    ins_encode %{
12779      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12780             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12781    %}
12782   ins_pipe(ialu_reg_reg_shift);
12783 %};
12784 
12785 
12786 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12787 %{
12788   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12789   ins_cost(1.9 * INSN_COST);
12790   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12791 
12792    ins_encode %{
12793      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12794             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12795    %}
12796   ins_pipe(ialu_reg_reg_shift);
12797 %}
12798 
12799 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12800 %{
12801   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12802   ins_cost(1.9 * INSN_COST);
12803   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12804 
12805    ins_encode %{
12806      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12807             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12808    %}
12809   ins_pipe(ialu_reg_reg_shift);
12810 %}
12811 
12812 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12813 %{
12814   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12815   ins_cost(1.9 * INSN_COST);
12816   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12817 
12818    ins_encode %{
12819      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12820             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12821    %}
12822   ins_pipe(ialu_reg_reg_shift);
12823 %}
12824 
12825 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12826 %{
12827   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12828   ins_cost(1.9 * INSN_COST);
12829   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12830 
12831    ins_encode %{
12832      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12833             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12834    %}
12835   ins_pipe(ialu_reg_reg_shift);
12836 %}
12837 
12838 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12839 %{
12840   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12841   ins_cost(1.9 * INSN_COST);
12842   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12843 
12844    ins_encode %{
12845      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12846             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12847    %}
12848   ins_pipe(ialu_reg_reg_shift);
12849 %}
12850 
12851 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12852 %{
12853   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12854   ins_cost(1.9 * INSN_COST);
12855   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12856 
12857    ins_encode %{
12858      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12859             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12860    %}
12861   ins_pipe(ialu_reg_reg_shift);
12862 %}
12863 
12864 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12865 %{
12866   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12867   ins_cost(1.9 * INSN_COST);
12868   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12869 
12870    ins_encode %{
12871      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12872             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12873    %}
12874   ins_pipe(ialu_reg_reg_shift);
12875 %}
12876 
12877 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12878 %{
12879   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12880   ins_cost(1.9 * INSN_COST);
12881   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12882 
12883    ins_encode %{
12884      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12885             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12886    %}
12887   ins_pipe(ialu_reg_reg_shift);
12888 %}
12889 
12890 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12891 %{
12892   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12893   ins_cost(1.9 * INSN_COST);
12894   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12895 
12896    ins_encode %{
12897      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12898             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12899    %}
12900   ins_pipe(ialu_reg_reg_shift);
12901 %}
12902 
12903 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12904 %{
12905   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12906   ins_cost(1.9 * INSN_COST);
12907   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12908 
12909    ins_encode %{
12910      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12911             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12912    %}
12913   ins_pipe(ialu_reg_reg_shift);
12914 %}
12915 // END This section of the file is automatically generated. Do not edit --------------
12916 
12917 // ============================================================================
12918 // Floating Point Arithmetic Instructions
12919 
12920 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12921   match(Set dst (AddF src1 src2));
12922 
12923   ins_cost(INSN_COST * 5);
12924   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12925 
12926   ins_encode %{
12927     __ fadds(as_FloatRegister($dst$$reg),
12928              as_FloatRegister($src1$$reg),
12929              as_FloatRegister($src2$$reg));
12930   %}
12931 
12932   ins_pipe(fp_dop_reg_reg_s);
12933 %}
12934 
12935 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12936   match(Set dst (AddD src1 src2));
12937 
12938   ins_cost(INSN_COST * 5);
12939   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12940 
12941   ins_encode %{
12942     __ faddd(as_FloatRegister($dst$$reg),
12943              as_FloatRegister($src1$$reg),
12944              as_FloatRegister($src2$$reg));
12945   %}
12946 
12947   ins_pipe(fp_dop_reg_reg_d);
12948 %}
12949 
12950 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12951   match(Set dst (SubF src1 src2));
12952 
12953   ins_cost(INSN_COST * 5);
12954   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12955 
12956   ins_encode %{
12957     __ fsubs(as_FloatRegister($dst$$reg),
12958              as_FloatRegister($src1$$reg),
12959              as_FloatRegister($src2$$reg));
12960   %}
12961 
12962   ins_pipe(fp_dop_reg_reg_s);
12963 %}
12964 
12965 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12966   match(Set dst (SubD src1 src2));
12967 
12968   ins_cost(INSN_COST * 5);
12969   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12970 
12971   ins_encode %{
12972     __ fsubd(as_FloatRegister($dst$$reg),
12973              as_FloatRegister($src1$$reg),
12974              as_FloatRegister($src2$$reg));
12975   %}
12976 
12977   ins_pipe(fp_dop_reg_reg_d);
12978 %}
12979 
12980 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12981   match(Set dst (MulF src1 src2));
12982 
12983   ins_cost(INSN_COST * 6);
12984   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12985 
12986   ins_encode %{
12987     __ fmuls(as_FloatRegister($dst$$reg),
12988              as_FloatRegister($src1$$reg),
12989              as_FloatRegister($src2$$reg));
12990   %}
12991 
12992   ins_pipe(fp_dop_reg_reg_s);
12993 %}
12994 
12995 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12996   match(Set dst (MulD src1 src2));
12997 
12998   ins_cost(INSN_COST * 6);
12999   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
13000 
13001   ins_encode %{
13002     __ fmuld(as_FloatRegister($dst$$reg),
13003              as_FloatRegister($src1$$reg),
13004              as_FloatRegister($src2$$reg));
13005   %}
13006 
13007   ins_pipe(fp_dop_reg_reg_d);
13008 %}
13009 
13010 // src1 * src2 + src3
13011 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13012   predicate(UseFMA);
13013   match(Set dst (FmaF src3 (Binary src1 src2)));
13014 
13015   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
13016 
13017   ins_encode %{
13018     __ fmadds(as_FloatRegister($dst$$reg),
13019              as_FloatRegister($src1$$reg),
13020              as_FloatRegister($src2$$reg),
13021              as_FloatRegister($src3$$reg));
13022   %}
13023 
13024   ins_pipe(pipe_class_default);
13025 %}
13026 
13027 // src1 * src2 + src3
13028 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13029   predicate(UseFMA);
13030   match(Set dst (FmaD src3 (Binary src1 src2)));
13031 
13032   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
13033 
13034   ins_encode %{
13035     __ fmaddd(as_FloatRegister($dst$$reg),
13036              as_FloatRegister($src1$$reg),
13037              as_FloatRegister($src2$$reg),
13038              as_FloatRegister($src3$$reg));
13039   %}
13040 
13041   ins_pipe(pipe_class_default);
13042 %}
13043 
13044 // -src1 * src2 + src3
13045 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13046   predicate(UseFMA);
13047   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
13048   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
13049 
13050   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
13051 
13052   ins_encode %{
13053     __ fmsubs(as_FloatRegister($dst$$reg),
13054               as_FloatRegister($src1$$reg),
13055               as_FloatRegister($src2$$reg),
13056               as_FloatRegister($src3$$reg));
13057   %}
13058 
13059   ins_pipe(pipe_class_default);
13060 %}
13061 
13062 // -src1 * src2 + src3
13063 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13064   predicate(UseFMA);
13065   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
13066   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
13067 
13068   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13069 
13070   ins_encode %{
13071     __ fmsubd(as_FloatRegister($dst$$reg),
13072               as_FloatRegister($src1$$reg),
13073               as_FloatRegister($src2$$reg),
13074               as_FloatRegister($src3$$reg));
13075   %}
13076 
13077   ins_pipe(pipe_class_default);
13078 %}
13079 
13080 // -src1 * src2 - src3
13081 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13082   predicate(UseFMA);
13083   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13084   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13085 
13086   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13087 
13088   ins_encode %{
13089     __ fnmadds(as_FloatRegister($dst$$reg),
13090                as_FloatRegister($src1$$reg),
13091                as_FloatRegister($src2$$reg),
13092                as_FloatRegister($src3$$reg));
13093   %}
13094 
13095   ins_pipe(pipe_class_default);
13096 %}
13097 
13098 // -src1 * src2 - src3
13099 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13100   predicate(UseFMA);
13101   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13102   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13103 
13104   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13105 
13106   ins_encode %{
13107     __ fnmaddd(as_FloatRegister($dst$$reg),
13108                as_FloatRegister($src1$$reg),
13109                as_FloatRegister($src2$$reg),
13110                as_FloatRegister($src3$$reg));
13111   %}
13112 
13113   ins_pipe(pipe_class_default);
13114 %}
13115 
13116 // src1 * src2 - src3
13117 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13118   predicate(UseFMA);
13119   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13120 
13121   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13122 
13123   ins_encode %{
13124     __ fnmsubs(as_FloatRegister($dst$$reg),
13125                as_FloatRegister($src1$$reg),
13126                as_FloatRegister($src2$$reg),
13127                as_FloatRegister($src3$$reg));
13128   %}
13129 
13130   ins_pipe(pipe_class_default);
13131 %}
13132 
13133 // src1 * src2 - src3
13134 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13135   predicate(UseFMA);
13136   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13137 
13138   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13139 
13140   ins_encode %{
13141   // n.b. insn name should be fnmsubd
13142     __ fnmsub(as_FloatRegister($dst$$reg),
13143               as_FloatRegister($src1$$reg),
13144               as_FloatRegister($src2$$reg),
13145               as_FloatRegister($src3$$reg));
13146   %}
13147 
13148   ins_pipe(pipe_class_default);
13149 %}
13150 
13151 
13152 // Math.max(FF)F
13153 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13154   match(Set dst (MaxF src1 src2));
13155 
13156   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13157   ins_encode %{
13158     __ fmaxs(as_FloatRegister($dst$$reg),
13159              as_FloatRegister($src1$$reg),
13160              as_FloatRegister($src2$$reg));
13161   %}
13162 
13163   ins_pipe(fp_dop_reg_reg_s);
13164 %}
13165 
13166 // Math.min(FF)F
13167 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13168   match(Set dst (MinF src1 src2));
13169 
13170   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13171   ins_encode %{
13172     __ fmins(as_FloatRegister($dst$$reg),
13173              as_FloatRegister($src1$$reg),
13174              as_FloatRegister($src2$$reg));
13175   %}
13176 
13177   ins_pipe(fp_dop_reg_reg_s);
13178 %}
13179 
13180 // Math.max(DD)D
13181 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13182   match(Set dst (MaxD src1 src2));
13183 
13184   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13185   ins_encode %{
13186     __ fmaxd(as_FloatRegister($dst$$reg),
13187              as_FloatRegister($src1$$reg),
13188              as_FloatRegister($src2$$reg));
13189   %}
13190 
13191   ins_pipe(fp_dop_reg_reg_d);
13192 %}
13193 
13194 // Math.min(DD)D
13195 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13196   match(Set dst (MinD src1 src2));
13197 
13198   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13199   ins_encode %{
13200     __ fmind(as_FloatRegister($dst$$reg),
13201              as_FloatRegister($src1$$reg),
13202              as_FloatRegister($src2$$reg));
13203   %}
13204 
13205   ins_pipe(fp_dop_reg_reg_d);
13206 %}
13207 
13208 
13209 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13210   match(Set dst (DivF src1  src2));
13211 
13212   ins_cost(INSN_COST * 18);
13213   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13214 
13215   ins_encode %{
13216     __ fdivs(as_FloatRegister($dst$$reg),
13217              as_FloatRegister($src1$$reg),
13218              as_FloatRegister($src2$$reg));
13219   %}
13220 
13221   ins_pipe(fp_div_s);
13222 %}
13223 
13224 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13225   match(Set dst (DivD src1  src2));
13226 
13227   ins_cost(INSN_COST * 32);
13228   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13229 
13230   ins_encode %{
13231     __ fdivd(as_FloatRegister($dst$$reg),
13232              as_FloatRegister($src1$$reg),
13233              as_FloatRegister($src2$$reg));
13234   %}
13235 
13236   ins_pipe(fp_div_d);
13237 %}
13238 
13239 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13240   match(Set dst (NegF src));
13241 
13242   ins_cost(INSN_COST * 3);
13243   format %{ &quot;fneg   $dst, $src&quot; %}
13244 
13245   ins_encode %{
13246     __ fnegs(as_FloatRegister($dst$$reg),
13247              as_FloatRegister($src$$reg));
13248   %}
13249 
13250   ins_pipe(fp_uop_s);
13251 %}
13252 
13253 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13254   match(Set dst (NegD src));
13255 
13256   ins_cost(INSN_COST * 3);
13257   format %{ &quot;fnegd   $dst, $src&quot; %}
13258 
13259   ins_encode %{
13260     __ fnegd(as_FloatRegister($dst$$reg),
13261              as_FloatRegister($src$$reg));
13262   %}
13263 
13264   ins_pipe(fp_uop_d);
13265 %}
13266 
13267 instruct absF_reg(vRegF dst, vRegF src) %{
13268   match(Set dst (AbsF src));
13269 
13270   ins_cost(INSN_COST * 3);
13271   format %{ &quot;fabss   $dst, $src&quot; %}
13272   ins_encode %{
13273     __ fabss(as_FloatRegister($dst$$reg),
13274              as_FloatRegister($src$$reg));
13275   %}
13276 
13277   ins_pipe(fp_uop_s);
13278 %}
13279 
13280 instruct absD_reg(vRegD dst, vRegD src) %{
13281   match(Set dst (AbsD src));
13282 
13283   ins_cost(INSN_COST * 3);
13284   format %{ &quot;fabsd   $dst, $src&quot; %}
13285   ins_encode %{
13286     __ fabsd(as_FloatRegister($dst$$reg),
13287              as_FloatRegister($src$$reg));
13288   %}
13289 
13290   ins_pipe(fp_uop_d);
13291 %}
13292 
13293 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13294   match(Set dst (SqrtD src));
13295 
13296   ins_cost(INSN_COST * 50);
13297   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13298   ins_encode %{
13299     __ fsqrtd(as_FloatRegister($dst$$reg),
13300              as_FloatRegister($src$$reg));
13301   %}
13302 
13303   ins_pipe(fp_div_s);
13304 %}
13305 
13306 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13307   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13308 
13309   ins_cost(INSN_COST * 50);
13310   format %{ &quot;fsqrts  $dst, $src&quot; %}
13311   ins_encode %{
13312     __ fsqrts(as_FloatRegister($dst$$reg),
13313              as_FloatRegister($src$$reg));
13314   %}
13315 
13316   ins_pipe(fp_div_d);
13317 %}
13318 
13319 // Math.rint, floor, ceil
13320 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13321   match(Set dst (RoundDoubleMode src rmode));
13322   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13323   ins_encode %{
13324     switch ($rmode$$constant) {
13325       case RoundDoubleModeNode::rmode_rint:
13326         __ frintnd(as_FloatRegister($dst$$reg),
13327                    as_FloatRegister($src$$reg));
13328         break;
13329       case RoundDoubleModeNode::rmode_floor:
13330         __ frintmd(as_FloatRegister($dst$$reg),
13331                    as_FloatRegister($src$$reg));
13332         break;
13333       case RoundDoubleModeNode::rmode_ceil:
13334         __ frintpd(as_FloatRegister($dst$$reg),
13335                    as_FloatRegister($src$$reg));
13336         break;
13337     }
13338   %}
13339   ins_pipe(fp_uop_d);
13340 %}
13341 
13342 // ============================================================================
13343 // Logical Instructions
13344 
13345 // Integer Logical Instructions
13346 
13347 // And Instructions
13348 
13349 
13350 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13351   match(Set dst (AndI src1 src2));
13352 
13353   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13354 
13355   ins_cost(INSN_COST);
13356   ins_encode %{
13357     __ andw(as_Register($dst$$reg),
13358             as_Register($src1$$reg),
13359             as_Register($src2$$reg));
13360   %}
13361 
13362   ins_pipe(ialu_reg_reg);
13363 %}
13364 
13365 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13366   match(Set dst (AndI src1 src2));
13367 
13368   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13369 
13370   ins_cost(INSN_COST);
13371   ins_encode %{
13372     __ andw(as_Register($dst$$reg),
13373             as_Register($src1$$reg),
13374             (unsigned long)($src2$$constant));
13375   %}
13376 
13377   ins_pipe(ialu_reg_imm);
13378 %}
13379 
13380 // Or Instructions
13381 
13382 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13383   match(Set dst (OrI src1 src2));
13384 
13385   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13386 
13387   ins_cost(INSN_COST);
13388   ins_encode %{
13389     __ orrw(as_Register($dst$$reg),
13390             as_Register($src1$$reg),
13391             as_Register($src2$$reg));
13392   %}
13393 
13394   ins_pipe(ialu_reg_reg);
13395 %}
13396 
13397 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13398   match(Set dst (OrI src1 src2));
13399 
13400   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13401 
13402   ins_cost(INSN_COST);
13403   ins_encode %{
13404     __ orrw(as_Register($dst$$reg),
13405             as_Register($src1$$reg),
13406             (unsigned long)($src2$$constant));
13407   %}
13408 
13409   ins_pipe(ialu_reg_imm);
13410 %}
13411 
13412 // Xor Instructions
13413 
13414 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13415   match(Set dst (XorI src1 src2));
13416 
13417   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13418 
13419   ins_cost(INSN_COST);
13420   ins_encode %{
13421     __ eorw(as_Register($dst$$reg),
13422             as_Register($src1$$reg),
13423             as_Register($src2$$reg));
13424   %}
13425 
13426   ins_pipe(ialu_reg_reg);
13427 %}
13428 
13429 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13430   match(Set dst (XorI src1 src2));
13431 
13432   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13433 
13434   ins_cost(INSN_COST);
13435   ins_encode %{
13436     __ eorw(as_Register($dst$$reg),
13437             as_Register($src1$$reg),
13438             (unsigned long)($src2$$constant));
13439   %}
13440 
13441   ins_pipe(ialu_reg_imm);
13442 %}
13443 
13444 // Long Logical Instructions
13445 // TODO
13446 
13447 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13448   match(Set dst (AndL src1 src2));
13449 
13450   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13451 
13452   ins_cost(INSN_COST);
13453   ins_encode %{
13454     __ andr(as_Register($dst$$reg),
13455             as_Register($src1$$reg),
13456             as_Register($src2$$reg));
13457   %}
13458 
13459   ins_pipe(ialu_reg_reg);
13460 %}
13461 
13462 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13463   match(Set dst (AndL src1 src2));
13464 
13465   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13466 
13467   ins_cost(INSN_COST);
13468   ins_encode %{
13469     __ andr(as_Register($dst$$reg),
13470             as_Register($src1$$reg),
13471             (unsigned long)($src2$$constant));
13472   %}
13473 
13474   ins_pipe(ialu_reg_imm);
13475 %}
13476 
13477 // Or Instructions
13478 
13479 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13480   match(Set dst (OrL src1 src2));
13481 
13482   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13483 
13484   ins_cost(INSN_COST);
13485   ins_encode %{
13486     __ orr(as_Register($dst$$reg),
13487            as_Register($src1$$reg),
13488            as_Register($src2$$reg));
13489   %}
13490 
13491   ins_pipe(ialu_reg_reg);
13492 %}
13493 
13494 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13495   match(Set dst (OrL src1 src2));
13496 
13497   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13498 
13499   ins_cost(INSN_COST);
13500   ins_encode %{
13501     __ orr(as_Register($dst$$reg),
13502            as_Register($src1$$reg),
13503            (unsigned long)($src2$$constant));
13504   %}
13505 
13506   ins_pipe(ialu_reg_imm);
13507 %}
13508 
13509 // Xor Instructions
13510 
13511 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13512   match(Set dst (XorL src1 src2));
13513 
13514   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13515 
13516   ins_cost(INSN_COST);
13517   ins_encode %{
13518     __ eor(as_Register($dst$$reg),
13519            as_Register($src1$$reg),
13520            as_Register($src2$$reg));
13521   %}
13522 
13523   ins_pipe(ialu_reg_reg);
13524 %}
13525 
13526 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13527   match(Set dst (XorL src1 src2));
13528 
13529   ins_cost(INSN_COST);
13530   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13531 
13532   ins_encode %{
13533     __ eor(as_Register($dst$$reg),
13534            as_Register($src1$$reg),
13535            (unsigned long)($src2$$constant));
13536   %}
13537 
13538   ins_pipe(ialu_reg_imm);
13539 %}
13540 
13541 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13542 %{
13543   match(Set dst (ConvI2L src));
13544 
13545   ins_cost(INSN_COST);
13546   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13547   ins_encode %{
13548     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13549   %}
13550   ins_pipe(ialu_reg_shift);
13551 %}
13552 
13553 // this pattern occurs in bigmath arithmetic
13554 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13555 %{
13556   match(Set dst (AndL (ConvI2L src) mask));
13557 
13558   ins_cost(INSN_COST);
13559   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13560   ins_encode %{
13561     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13562   %}
13563 
13564   ins_pipe(ialu_reg_shift);
13565 %}
13566 
13567 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13568   match(Set dst (ConvL2I src));
13569 
13570   ins_cost(INSN_COST);
13571   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13572 
13573   ins_encode %{
13574     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13575   %}
13576 
13577   ins_pipe(ialu_reg);
13578 %}
13579 
13580 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13581 %{
13582   match(Set dst (Conv2B src));
13583   effect(KILL cr);
13584 
13585   format %{
13586     &quot;cmpw $src, zr\n\t&quot;
13587     &quot;cset $dst, ne&quot;
13588   %}
13589 
13590   ins_encode %{
13591     __ cmpw(as_Register($src$$reg), zr);
13592     __ cset(as_Register($dst$$reg), Assembler::NE);
13593   %}
13594 
13595   ins_pipe(ialu_reg);
13596 %}
13597 
13598 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13599 %{
13600   match(Set dst (Conv2B src));
13601   effect(KILL cr);
13602 
13603   format %{
13604     &quot;cmp  $src, zr\n\t&quot;
13605     &quot;cset $dst, ne&quot;
13606   %}
13607 
13608   ins_encode %{
13609     __ cmp(as_Register($src$$reg), zr);
13610     __ cset(as_Register($dst$$reg), Assembler::NE);
13611   %}
13612 
13613   ins_pipe(ialu_reg);
13614 %}
13615 
13616 instruct convD2F_reg(vRegF dst, vRegD src) %{
13617   match(Set dst (ConvD2F src));
13618 
13619   ins_cost(INSN_COST * 5);
13620   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13621 
13622   ins_encode %{
13623     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13624   %}
13625 
13626   ins_pipe(fp_d2f);
13627 %}
13628 
13629 instruct convF2D_reg(vRegD dst, vRegF src) %{
13630   match(Set dst (ConvF2D src));
13631 
13632   ins_cost(INSN_COST * 5);
13633   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13634 
13635   ins_encode %{
13636     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13637   %}
13638 
13639   ins_pipe(fp_f2d);
13640 %}
13641 
13642 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13643   match(Set dst (ConvF2I src));
13644 
13645   ins_cost(INSN_COST * 5);
13646   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13647 
13648   ins_encode %{
13649     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13650   %}
13651 
13652   ins_pipe(fp_f2i);
13653 %}
13654 
13655 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13656   match(Set dst (ConvF2L src));
13657 
13658   ins_cost(INSN_COST * 5);
13659   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13660 
13661   ins_encode %{
13662     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13663   %}
13664 
13665   ins_pipe(fp_f2l);
13666 %}
13667 
13668 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13669   match(Set dst (ConvI2F src));
13670 
13671   ins_cost(INSN_COST * 5);
13672   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13673 
13674   ins_encode %{
13675     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13676   %}
13677 
13678   ins_pipe(fp_i2f);
13679 %}
13680 
13681 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13682   match(Set dst (ConvL2F src));
13683 
13684   ins_cost(INSN_COST * 5);
13685   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13686 
13687   ins_encode %{
13688     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13689   %}
13690 
13691   ins_pipe(fp_l2f);
13692 %}
13693 
13694 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13695   match(Set dst (ConvD2I src));
13696 
13697   ins_cost(INSN_COST * 5);
13698   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13699 
13700   ins_encode %{
13701     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13702   %}
13703 
13704   ins_pipe(fp_d2i);
13705 %}
13706 
13707 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13708   match(Set dst (ConvD2L src));
13709 
13710   ins_cost(INSN_COST * 5);
13711   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13712 
13713   ins_encode %{
13714     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13715   %}
13716 
13717   ins_pipe(fp_d2l);
13718 %}
13719 
13720 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13721   match(Set dst (ConvI2D src));
13722 
13723   ins_cost(INSN_COST * 5);
13724   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13725 
13726   ins_encode %{
13727     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13728   %}
13729 
13730   ins_pipe(fp_i2d);
13731 %}
13732 
13733 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13734   match(Set dst (ConvL2D src));
13735 
13736   ins_cost(INSN_COST * 5);
13737   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13738 
13739   ins_encode %{
13740     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13741   %}
13742 
13743   ins_pipe(fp_l2d);
13744 %}
13745 
13746 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13747 
13748 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13749 
13750   match(Set dst (MoveF2I src));
13751 
13752   effect(DEF dst, USE src);
13753 
13754   ins_cost(4 * INSN_COST);
13755 
13756   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13757 
13758   ins_encode %{
13759     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13760   %}
13761 
13762   ins_pipe(iload_reg_reg);
13763 
13764 %}
13765 
13766 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13767 
13768   match(Set dst (MoveI2F src));
13769 
13770   effect(DEF dst, USE src);
13771 
13772   ins_cost(4 * INSN_COST);
13773 
13774   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13775 
13776   ins_encode %{
13777     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13778   %}
13779 
13780   ins_pipe(pipe_class_memory);
13781 
13782 %}
13783 
13784 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13785 
13786   match(Set dst (MoveD2L src));
13787 
13788   effect(DEF dst, USE src);
13789 
13790   ins_cost(4 * INSN_COST);
13791 
13792   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13793 
13794   ins_encode %{
13795     __ ldr($dst$$Register, Address(sp, $src$$disp));
13796   %}
13797 
13798   ins_pipe(iload_reg_reg);
13799 
13800 %}
13801 
13802 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13803 
13804   match(Set dst (MoveL2D src));
13805 
13806   effect(DEF dst, USE src);
13807 
13808   ins_cost(4 * INSN_COST);
13809 
13810   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13811 
13812   ins_encode %{
13813     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13814   %}
13815 
13816   ins_pipe(pipe_class_memory);
13817 
13818 %}
13819 
13820 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13821 
13822   match(Set dst (MoveF2I src));
13823 
13824   effect(DEF dst, USE src);
13825 
13826   ins_cost(INSN_COST);
13827 
13828   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13829 
13830   ins_encode %{
13831     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13832   %}
13833 
13834   ins_pipe(pipe_class_memory);
13835 
13836 %}
13837 
13838 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13839 
13840   match(Set dst (MoveI2F src));
13841 
13842   effect(DEF dst, USE src);
13843 
13844   ins_cost(INSN_COST);
13845 
13846   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13847 
13848   ins_encode %{
13849     __ strw($src$$Register, Address(sp, $dst$$disp));
13850   %}
13851 
13852   ins_pipe(istore_reg_reg);
13853 
13854 %}
13855 
13856 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13857 
13858   match(Set dst (MoveD2L src));
13859 
13860   effect(DEF dst, USE src);
13861 
13862   ins_cost(INSN_COST);
13863 
13864   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13865 
13866   ins_encode %{
13867     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13868   %}
13869 
13870   ins_pipe(pipe_class_memory);
13871 
13872 %}
13873 
13874 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13875 
13876   match(Set dst (MoveL2D src));
13877 
13878   effect(DEF dst, USE src);
13879 
13880   ins_cost(INSN_COST);
13881 
13882   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13883 
13884   ins_encode %{
13885     __ str($src$$Register, Address(sp, $dst$$disp));
13886   %}
13887 
13888   ins_pipe(istore_reg_reg);
13889 
13890 %}
13891 
13892 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13893 
13894   match(Set dst (MoveF2I src));
13895 
13896   effect(DEF dst, USE src);
13897 
13898   ins_cost(INSN_COST);
13899 
13900   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13901 
13902   ins_encode %{
13903     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13904   %}
13905 
13906   ins_pipe(fp_f2i);
13907 
13908 %}
13909 
13910 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13911 
13912   match(Set dst (MoveI2F src));
13913 
13914   effect(DEF dst, USE src);
13915 
13916   ins_cost(INSN_COST);
13917 
13918   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13919 
13920   ins_encode %{
13921     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13922   %}
13923 
13924   ins_pipe(fp_i2f);
13925 
13926 %}
13927 
13928 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13929 
13930   match(Set dst (MoveD2L src));
13931 
13932   effect(DEF dst, USE src);
13933 
13934   ins_cost(INSN_COST);
13935 
13936   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13937 
13938   ins_encode %{
13939     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13940   %}
13941 
13942   ins_pipe(fp_d2l);
13943 
13944 %}
13945 
13946 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13947 
13948   match(Set dst (MoveL2D src));
13949 
13950   effect(DEF dst, USE src);
13951 
13952   ins_cost(INSN_COST);
13953 
13954   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13955 
13956   ins_encode %{
13957     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13958   %}
13959 
13960   ins_pipe(fp_l2d);
13961 
13962 %}
13963 
13964 // ============================================================================
13965 // clearing of an array
13966 
13967 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)
13968 %{
13969   match(Set dummy (ClearArray (Binary cnt base) val));
13970   effect(USE_KILL cnt, USE_KILL base);
13971 
13972   ins_cost(4 * INSN_COST);
13973   format %{ &quot;ClearArray $cnt, $base, $val&quot; %}
13974 
13975   ins_encode %{
13976     __ fill_words($base$$Register, $cnt$$Register, $val$$Register);
13977   %}
13978 
13979   ins_pipe(pipe_class_memory);
13980 %}
13981 
13982 // ============================================================================
13983 // Overflow Math Instructions
13984 
13985 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13986 %{
13987   match(Set cr (OverflowAddI op1 op2));
13988 
13989   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13990   ins_cost(INSN_COST);
13991   ins_encode %{
13992     __ cmnw($op1$$Register, $op2$$Register);
13993   %}
13994 
13995   ins_pipe(icmp_reg_reg);
13996 %}
13997 
13998 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13999 %{
14000   match(Set cr (OverflowAddI op1 op2));
14001 
14002   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
14003   ins_cost(INSN_COST);
14004   ins_encode %{
14005     __ cmnw($op1$$Register, $op2$$constant);
14006   %}
14007 
14008   ins_pipe(icmp_reg_imm);
14009 %}
14010 
14011 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14012 %{
14013   match(Set cr (OverflowAddL op1 op2));
14014 
14015   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14016   ins_cost(INSN_COST);
14017   ins_encode %{
14018     __ cmn($op1$$Register, $op2$$Register);
14019   %}
14020 
14021   ins_pipe(icmp_reg_reg);
14022 %}
14023 
14024 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14025 %{
14026   match(Set cr (OverflowAddL op1 op2));
14027 
14028   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
14029   ins_cost(INSN_COST);
14030   ins_encode %{
14031     __ cmn($op1$$Register, $op2$$constant);
14032   %}
14033 
14034   ins_pipe(icmp_reg_imm);
14035 %}
14036 
14037 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14038 %{
14039   match(Set cr (OverflowSubI op1 op2));
14040 
14041   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14042   ins_cost(INSN_COST);
14043   ins_encode %{
14044     __ cmpw($op1$$Register, $op2$$Register);
14045   %}
14046 
14047   ins_pipe(icmp_reg_reg);
14048 %}
14049 
14050 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14051 %{
14052   match(Set cr (OverflowSubI op1 op2));
14053 
14054   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14055   ins_cost(INSN_COST);
14056   ins_encode %{
14057     __ cmpw($op1$$Register, $op2$$constant);
14058   %}
14059 
14060   ins_pipe(icmp_reg_imm);
14061 %}
14062 
14063 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14064 %{
14065   match(Set cr (OverflowSubL op1 op2));
14066 
14067   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14068   ins_cost(INSN_COST);
14069   ins_encode %{
14070     __ cmp($op1$$Register, $op2$$Register);
14071   %}
14072 
14073   ins_pipe(icmp_reg_reg);
14074 %}
14075 
14076 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14077 %{
14078   match(Set cr (OverflowSubL op1 op2));
14079 
14080   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14081   ins_cost(INSN_COST);
14082   ins_encode %{
14083     __ subs(zr, $op1$$Register, $op2$$constant);
14084   %}
14085 
14086   ins_pipe(icmp_reg_imm);
14087 %}
14088 
14089 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14090 %{
14091   match(Set cr (OverflowSubI zero op1));
14092 
14093   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14094   ins_cost(INSN_COST);
14095   ins_encode %{
14096     __ cmpw(zr, $op1$$Register);
14097   %}
14098 
14099   ins_pipe(icmp_reg_imm);
14100 %}
14101 
14102 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14103 %{
14104   match(Set cr (OverflowSubL zero op1));
14105 
14106   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14107   ins_cost(INSN_COST);
14108   ins_encode %{
14109     __ cmp(zr, $op1$$Register);
14110   %}
14111 
14112   ins_pipe(icmp_reg_imm);
14113 %}
14114 
14115 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14116 %{
14117   match(Set cr (OverflowMulI op1 op2));
14118 
14119   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14120             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14121             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14122             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14123             &quot;cmpw  rscratch1, #1&quot; %}
14124   ins_cost(5 * INSN_COST);
14125   ins_encode %{
14126     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14127     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14128     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14129     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14130     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14131   %}
14132 
14133   ins_pipe(pipe_slow);
14134 %}
14135 
14136 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14137 %{
14138   match(If cmp (OverflowMulI op1 op2));
14139   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14140             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14141   effect(USE labl, KILL cr);
14142 
14143   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14144             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14145             &quot;b$cmp   $labl&quot; %}
14146   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14147   ins_encode %{
14148     Label* L = $labl$$label;
14149     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14150     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14151     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14152     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14153   %}
14154 
14155   ins_pipe(pipe_serial);
14156 %}
14157 
14158 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14159 %{
14160   match(Set cr (OverflowMulL op1 op2));
14161 
14162   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14163             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14164             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14165             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14166             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14167             &quot;cmpw  rscratch1, #1&quot; %}
14168   ins_cost(6 * INSN_COST);
14169   ins_encode %{
14170     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14171     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14172     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14173     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14174     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14175     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14176   %}
14177 
14178   ins_pipe(pipe_slow);
14179 %}
14180 
14181 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14182 %{
14183   match(If cmp (OverflowMulL op1 op2));
14184   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14185             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14186   effect(USE labl, KILL cr);
14187 
14188   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14189             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14190             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14191             &quot;b$cmp $labl&quot; %}
14192   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14193   ins_encode %{
14194     Label* L = $labl$$label;
14195     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14196     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14197     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14198     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14199     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14200   %}
14201 
14202   ins_pipe(pipe_serial);
14203 %}
14204 
14205 // ============================================================================
14206 // Compare Instructions
14207 
14208 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14209 %{
14210   match(Set cr (CmpI op1 op2));
14211 
14212   effect(DEF cr, USE op1, USE op2);
14213 
14214   ins_cost(INSN_COST);
14215   format %{ &quot;cmpw  $op1, $op2&quot; %}
14216 
14217   ins_encode(aarch64_enc_cmpw(op1, op2));
14218 
14219   ins_pipe(icmp_reg_reg);
14220 %}
14221 
14222 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14223 %{
14224   match(Set cr (CmpI op1 zero));
14225 
14226   effect(DEF cr, USE op1);
14227 
14228   ins_cost(INSN_COST);
14229   format %{ &quot;cmpw $op1, 0&quot; %}
14230 
14231   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14232 
14233   ins_pipe(icmp_reg_imm);
14234 %}
14235 
14236 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14237 %{
14238   match(Set cr (CmpI op1 op2));
14239 
14240   effect(DEF cr, USE op1);
14241 
14242   ins_cost(INSN_COST);
14243   format %{ &quot;cmpw  $op1, $op2&quot; %}
14244 
14245   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14246 
14247   ins_pipe(icmp_reg_imm);
14248 %}
14249 
14250 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14251 %{
14252   match(Set cr (CmpI op1 op2));
14253 
14254   effect(DEF cr, USE op1);
14255 
14256   ins_cost(INSN_COST * 2);
14257   format %{ &quot;cmpw  $op1, $op2&quot; %}
14258 
14259   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14260 
14261   ins_pipe(icmp_reg_imm);
14262 %}
14263 
14264 // Unsigned compare Instructions; really, same as signed compare
14265 // except it should only be used to feed an If or a CMovI which takes a
14266 // cmpOpU.
14267 
14268 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14269 %{
14270   match(Set cr (CmpU op1 op2));
14271 
14272   effect(DEF cr, USE op1, USE op2);
14273 
14274   ins_cost(INSN_COST);
14275   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14276 
14277   ins_encode(aarch64_enc_cmpw(op1, op2));
14278 
14279   ins_pipe(icmp_reg_reg);
14280 %}
14281 
14282 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14283 %{
14284   match(Set cr (CmpU op1 zero));
14285 
14286   effect(DEF cr, USE op1);
14287 
14288   ins_cost(INSN_COST);
14289   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14290 
14291   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14292 
14293   ins_pipe(icmp_reg_imm);
14294 %}
14295 
14296 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14297 %{
14298   match(Set cr (CmpU op1 op2));
14299 
14300   effect(DEF cr, USE op1);
14301 
14302   ins_cost(INSN_COST);
14303   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14304 
14305   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14306 
14307   ins_pipe(icmp_reg_imm);
14308 %}
14309 
14310 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14311 %{
14312   match(Set cr (CmpU op1 op2));
14313 
14314   effect(DEF cr, USE op1);
14315 
14316   ins_cost(INSN_COST * 2);
14317   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14318 
14319   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14320 
14321   ins_pipe(icmp_reg_imm);
14322 %}
14323 
14324 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14325 %{
14326   match(Set cr (CmpL op1 op2));
14327 
14328   effect(DEF cr, USE op1, USE op2);
14329 
14330   ins_cost(INSN_COST);
14331   format %{ &quot;cmp  $op1, $op2&quot; %}
14332 
14333   ins_encode(aarch64_enc_cmp(op1, op2));
14334 
14335   ins_pipe(icmp_reg_reg);
14336 %}
14337 
14338 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14339 %{
14340   match(Set cr (CmpL op1 zero));
14341 
14342   effect(DEF cr, USE op1);
14343 
14344   ins_cost(INSN_COST);
14345   format %{ &quot;tst  $op1&quot; %}
14346 
14347   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14348 
14349   ins_pipe(icmp_reg_imm);
14350 %}
14351 
14352 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14353 %{
14354   match(Set cr (CmpL op1 op2));
14355 
14356   effect(DEF cr, USE op1);
14357 
14358   ins_cost(INSN_COST);
14359   format %{ &quot;cmp  $op1, $op2&quot; %}
14360 
14361   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14362 
14363   ins_pipe(icmp_reg_imm);
14364 %}
14365 
14366 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14367 %{
14368   match(Set cr (CmpL op1 op2));
14369 
14370   effect(DEF cr, USE op1);
14371 
14372   ins_cost(INSN_COST * 2);
14373   format %{ &quot;cmp  $op1, $op2&quot; %}
14374 
14375   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14376 
14377   ins_pipe(icmp_reg_imm);
14378 %}
14379 
14380 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14381 %{
14382   match(Set cr (CmpUL op1 op2));
14383 
14384   effect(DEF cr, USE op1, USE op2);
14385 
14386   ins_cost(INSN_COST);
14387   format %{ &quot;cmp  $op1, $op2&quot; %}
14388 
14389   ins_encode(aarch64_enc_cmp(op1, op2));
14390 
14391   ins_pipe(icmp_reg_reg);
14392 %}
14393 
14394 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14395 %{
14396   match(Set cr (CmpUL op1 zero));
14397 
14398   effect(DEF cr, USE op1);
14399 
14400   ins_cost(INSN_COST);
14401   format %{ &quot;tst  $op1&quot; %}
14402 
14403   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14404 
14405   ins_pipe(icmp_reg_imm);
14406 %}
14407 
14408 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14409 %{
14410   match(Set cr (CmpUL op1 op2));
14411 
14412   effect(DEF cr, USE op1);
14413 
14414   ins_cost(INSN_COST);
14415   format %{ &quot;cmp  $op1, $op2&quot; %}
14416 
14417   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14418 
14419   ins_pipe(icmp_reg_imm);
14420 %}
14421 
14422 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14423 %{
14424   match(Set cr (CmpUL op1 op2));
14425 
14426   effect(DEF cr, USE op1);
14427 
14428   ins_cost(INSN_COST * 2);
14429   format %{ &quot;cmp  $op1, $op2&quot; %}
14430 
14431   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14432 
14433   ins_pipe(icmp_reg_imm);
14434 %}
14435 
14436 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14437 %{
14438   match(Set cr (CmpP op1 op2));
14439 
14440   effect(DEF cr, USE op1, USE op2);
14441 
14442   ins_cost(INSN_COST);
14443   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14444 
14445   ins_encode(aarch64_enc_cmpp(op1, op2));
14446 
14447   ins_pipe(icmp_reg_reg);
14448 %}
14449 
14450 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14451 %{
14452   match(Set cr (CmpN op1 op2));
14453 
14454   effect(DEF cr, USE op1, USE op2);
14455 
14456   ins_cost(INSN_COST);
14457   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14458 
14459   ins_encode(aarch64_enc_cmpn(op1, op2));
14460 
14461   ins_pipe(icmp_reg_reg);
14462 %}
14463 
14464 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14465 %{
14466   match(Set cr (CmpP op1 zero));
14467 
14468   effect(DEF cr, USE op1, USE zero);
14469 
14470   ins_cost(INSN_COST);
14471   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14472 
14473   ins_encode(aarch64_enc_testp(op1));
14474 
14475   ins_pipe(icmp_reg_imm);
14476 %}
14477 
14478 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14479 %{
14480   match(Set cr (CmpN op1 zero));
14481 
14482   effect(DEF cr, USE op1, USE zero);
14483 
14484   ins_cost(INSN_COST);
14485   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14486 
14487   ins_encode(aarch64_enc_testn(op1));
14488 
14489   ins_pipe(icmp_reg_imm);
14490 %}
14491 
14492 // FP comparisons
14493 //
14494 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14495 // using normal cmpOp. See declaration of rFlagsReg for details.
14496 
14497 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14498 %{
14499   match(Set cr (CmpF src1 src2));
14500 
14501   ins_cost(3 * INSN_COST);
14502   format %{ &quot;fcmps $src1, $src2&quot; %}
14503 
14504   ins_encode %{
14505     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14506   %}
14507 
14508   ins_pipe(pipe_class_compare);
14509 %}
14510 
14511 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14512 %{
14513   match(Set cr (CmpF src1 src2));
14514 
14515   ins_cost(3 * INSN_COST);
14516   format %{ &quot;fcmps $src1, 0.0&quot; %}
14517 
14518   ins_encode %{
14519     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14520   %}
14521 
14522   ins_pipe(pipe_class_compare);
14523 %}
14524 // FROM HERE
14525 
14526 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14527 %{
14528   match(Set cr (CmpD src1 src2));
14529 
14530   ins_cost(3 * INSN_COST);
14531   format %{ &quot;fcmpd $src1, $src2&quot; %}
14532 
14533   ins_encode %{
14534     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14535   %}
14536 
14537   ins_pipe(pipe_class_compare);
14538 %}
14539 
14540 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14541 %{
14542   match(Set cr (CmpD src1 src2));
14543 
14544   ins_cost(3 * INSN_COST);
14545   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14546 
14547   ins_encode %{
14548     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14549   %}
14550 
14551   ins_pipe(pipe_class_compare);
14552 %}
14553 
14554 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14555 %{
14556   match(Set dst (CmpF3 src1 src2));
14557   effect(KILL cr);
14558 
14559   ins_cost(5 * INSN_COST);
14560   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14561             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14562             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14563   %}
14564 
14565   ins_encode %{
14566     Label done;
14567     FloatRegister s1 = as_FloatRegister($src1$$reg);
14568     FloatRegister s2 = as_FloatRegister($src2$$reg);
14569     Register d = as_Register($dst$$reg);
14570     __ fcmps(s1, s2);
14571     // installs 0 if EQ else -1
14572     __ csinvw(d, zr, zr, Assembler::EQ);
14573     // keeps -1 if less or unordered else installs 1
14574     __ csnegw(d, d, d, Assembler::LT);
14575     __ bind(done);
14576   %}
14577 
14578   ins_pipe(pipe_class_default);
14579 
14580 %}
14581 
14582 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14583 %{
14584   match(Set dst (CmpD3 src1 src2));
14585   effect(KILL cr);
14586 
14587   ins_cost(5 * INSN_COST);
14588   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14589             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14590             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14591   %}
14592 
14593   ins_encode %{
14594     Label done;
14595     FloatRegister s1 = as_FloatRegister($src1$$reg);
14596     FloatRegister s2 = as_FloatRegister($src2$$reg);
14597     Register d = as_Register($dst$$reg);
14598     __ fcmpd(s1, s2);
14599     // installs 0 if EQ else -1
14600     __ csinvw(d, zr, zr, Assembler::EQ);
14601     // keeps -1 if less or unordered else installs 1
14602     __ csnegw(d, d, d, Assembler::LT);
14603     __ bind(done);
14604   %}
14605   ins_pipe(pipe_class_default);
14606 
14607 %}
14608 
14609 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14610 %{
14611   match(Set dst (CmpF3 src1 zero));
14612   effect(KILL cr);
14613 
14614   ins_cost(5 * INSN_COST);
14615   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14616             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14617             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14618   %}
14619 
14620   ins_encode %{
14621     Label done;
14622     FloatRegister s1 = as_FloatRegister($src1$$reg);
14623     Register d = as_Register($dst$$reg);
14624     __ fcmps(s1, 0.0);
14625     // installs 0 if EQ else -1
14626     __ csinvw(d, zr, zr, Assembler::EQ);
14627     // keeps -1 if less or unordered else installs 1
14628     __ csnegw(d, d, d, Assembler::LT);
14629     __ bind(done);
14630   %}
14631 
14632   ins_pipe(pipe_class_default);
14633 
14634 %}
14635 
14636 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14637 %{
14638   match(Set dst (CmpD3 src1 zero));
14639   effect(KILL cr);
14640 
14641   ins_cost(5 * INSN_COST);
14642   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14643             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14644             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14645   %}
14646 
14647   ins_encode %{
14648     Label done;
14649     FloatRegister s1 = as_FloatRegister($src1$$reg);
14650     Register d = as_Register($dst$$reg);
14651     __ fcmpd(s1, 0.0);
14652     // installs 0 if EQ else -1
14653     __ csinvw(d, zr, zr, Assembler::EQ);
14654     // keeps -1 if less or unordered else installs 1
14655     __ csnegw(d, d, d, Assembler::LT);
14656     __ bind(done);
14657   %}
14658   ins_pipe(pipe_class_default);
14659 
14660 %}
14661 
14662 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14663 %{
14664   match(Set dst (CmpLTMask p q));
14665   effect(KILL cr);
14666 
14667   ins_cost(3 * INSN_COST);
14668 
14669   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14670             &quot;csetw $dst, lt\n\t&quot;
14671             &quot;subw $dst, zr, $dst&quot;
14672   %}
14673 
14674   ins_encode %{
14675     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14676     __ csetw(as_Register($dst$$reg), Assembler::LT);
14677     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14678   %}
14679 
14680   ins_pipe(ialu_reg_reg);
14681 %}
14682 
14683 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14684 %{
14685   match(Set dst (CmpLTMask src zero));
14686   effect(KILL cr);
14687 
14688   ins_cost(INSN_COST);
14689 
14690   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14691 
14692   ins_encode %{
14693     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14694   %}
14695 
14696   ins_pipe(ialu_reg_shift);
14697 %}
14698 
14699 // ============================================================================
14700 // Max and Min
14701 
14702 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14703 %{
14704   effect( DEF dst, USE src1, USE src2, USE cr );
14705 
14706   ins_cost(INSN_COST * 2);
14707   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14708 
14709   ins_encode %{
14710     __ cselw(as_Register($dst$$reg),
14711              as_Register($src1$$reg),
14712              as_Register($src2$$reg),
14713              Assembler::LT);
14714   %}
14715 
14716   ins_pipe(icond_reg_reg);
14717 %}
14718 
14719 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14720 %{
14721   match(Set dst (MinI src1 src2));
14722   ins_cost(INSN_COST * 3);
14723 
14724   expand %{
14725     rFlagsReg cr;
14726     compI_reg_reg(cr, src1, src2);
14727     cmovI_reg_reg_lt(dst, src1, src2, cr);
14728   %}
14729 
14730 %}
14731 // FROM HERE
14732 
14733 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14734 %{
14735   effect( DEF dst, USE src1, USE src2, USE cr );
14736 
14737   ins_cost(INSN_COST * 2);
14738   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14739 
14740   ins_encode %{
14741     __ cselw(as_Register($dst$$reg),
14742              as_Register($src1$$reg),
14743              as_Register($src2$$reg),
14744              Assembler::GT);
14745   %}
14746 
14747   ins_pipe(icond_reg_reg);
14748 %}
14749 
14750 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14751 %{
14752   match(Set dst (MaxI src1 src2));
14753   ins_cost(INSN_COST * 3);
14754   expand %{
14755     rFlagsReg cr;
14756     compI_reg_reg(cr, src1, src2);
14757     cmovI_reg_reg_gt(dst, src1, src2, cr);
14758   %}
14759 %}
14760 
14761 // ============================================================================
14762 // Branch Instructions
14763 
14764 // Direct Branch.
14765 instruct branch(label lbl)
14766 %{
14767   match(Goto);
14768 
14769   effect(USE lbl);
14770 
14771   ins_cost(BRANCH_COST);
14772   format %{ &quot;b  $lbl&quot; %}
14773 
14774   ins_encode(aarch64_enc_b(lbl));
14775 
14776   ins_pipe(pipe_branch);
14777 %}
14778 
14779 // Conditional Near Branch
14780 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14781 %{
14782   // Same match rule as `branchConFar&#39;.
14783   match(If cmp cr);
14784 
14785   effect(USE lbl);
14786 
14787   ins_cost(BRANCH_COST);
14788   // If set to 1 this indicates that the current instruction is a
14789   // short variant of a long branch. This avoids using this
14790   // instruction in first-pass matching. It will then only be used in
14791   // the `Shorten_branches&#39; pass.
14792   // ins_short_branch(1);
14793   format %{ &quot;b$cmp  $lbl&quot; %}
14794 
14795   ins_encode(aarch64_enc_br_con(cmp, lbl));
14796 
14797   ins_pipe(pipe_branch_cond);
14798 %}
14799 
14800 // Conditional Near Branch Unsigned
14801 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14802 %{
14803   // Same match rule as `branchConFar&#39;.
14804   match(If cmp cr);
14805 
14806   effect(USE lbl);
14807 
14808   ins_cost(BRANCH_COST);
14809   // If set to 1 this indicates that the current instruction is a
14810   // short variant of a long branch. This avoids using this
14811   // instruction in first-pass matching. It will then only be used in
14812   // the `Shorten_branches&#39; pass.
14813   // ins_short_branch(1);
14814   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14815 
14816   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14817 
14818   ins_pipe(pipe_branch_cond);
14819 %}
14820 
14821 // Make use of CBZ and CBNZ.  These instructions, as well as being
14822 // shorter than (cmp; branch), have the additional benefit of not
14823 // killing the flags.
14824 
14825 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14826   match(If cmp (CmpI op1 op2));
14827   effect(USE labl);
14828 
14829   ins_cost(BRANCH_COST);
14830   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14831   ins_encode %{
14832     Label* L = $labl$$label;
14833     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14834     if (cond == Assembler::EQ)
14835       __ cbzw($op1$$Register, *L);
14836     else
14837       __ cbnzw($op1$$Register, *L);
14838   %}
14839   ins_pipe(pipe_cmp_branch);
14840 %}
14841 
14842 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14843   match(If cmp (CmpL op1 op2));
14844   effect(USE labl);
14845 
14846   ins_cost(BRANCH_COST);
14847   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14848   ins_encode %{
14849     Label* L = $labl$$label;
14850     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14851     if (cond == Assembler::EQ)
14852       __ cbz($op1$$Register, *L);
14853     else
14854       __ cbnz($op1$$Register, *L);
14855   %}
14856   ins_pipe(pipe_cmp_branch);
14857 %}
14858 
14859 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14860   match(If cmp (CmpP op1 op2));
14861   effect(USE labl);
14862 
14863   ins_cost(BRANCH_COST);
14864   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14865   ins_encode %{
14866     Label* L = $labl$$label;
14867     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14868     if (cond == Assembler::EQ)
14869       __ cbz($op1$$Register, *L);
14870     else
14871       __ cbnz($op1$$Register, *L);
14872   %}
14873   ins_pipe(pipe_cmp_branch);
14874 %}
14875 
14876 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14877   match(If cmp (CmpN op1 op2));
14878   effect(USE labl);
14879 
14880   ins_cost(BRANCH_COST);
14881   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14882   ins_encode %{
14883     Label* L = $labl$$label;
14884     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14885     if (cond == Assembler::EQ)
14886       __ cbzw($op1$$Register, *L);
14887     else
14888       __ cbnzw($op1$$Register, *L);
14889   %}
14890   ins_pipe(pipe_cmp_branch);
14891 %}
14892 
14893 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14894   match(If cmp (CmpP (DecodeN oop) zero));
14895   effect(USE labl);
14896 
14897   ins_cost(BRANCH_COST);
14898   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14899   ins_encode %{
14900     Label* L = $labl$$label;
14901     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14902     if (cond == Assembler::EQ)
14903       __ cbzw($oop$$Register, *L);
14904     else
14905       __ cbnzw($oop$$Register, *L);
14906   %}
14907   ins_pipe(pipe_cmp_branch);
14908 %}
14909 
14910 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14911   match(If cmp (CmpU op1 op2));
14912   effect(USE labl);
14913 
14914   ins_cost(BRANCH_COST);
14915   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14916   ins_encode %{
14917     Label* L = $labl$$label;
14918     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14919     if (cond == Assembler::EQ || cond == Assembler::LS)
14920       __ cbzw($op1$$Register, *L);
14921     else
14922       __ cbnzw($op1$$Register, *L);
14923   %}
14924   ins_pipe(pipe_cmp_branch);
14925 %}
14926 
14927 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14928   match(If cmp (CmpUL op1 op2));
14929   effect(USE labl);
14930 
14931   ins_cost(BRANCH_COST);
14932   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14933   ins_encode %{
14934     Label* L = $labl$$label;
14935     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14936     if (cond == Assembler::EQ || cond == Assembler::LS)
14937       __ cbz($op1$$Register, *L);
14938     else
14939       __ cbnz($op1$$Register, *L);
14940   %}
14941   ins_pipe(pipe_cmp_branch);
14942 %}
14943 
14944 // Test bit and Branch
14945 
14946 // Patterns for short (&lt; 32KiB) variants
14947 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14948   match(If cmp (CmpL op1 op2));
14949   effect(USE labl);
14950 
14951   ins_cost(BRANCH_COST);
14952   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14953   ins_encode %{
14954     Label* L = $labl$$label;
14955     Assembler::Condition cond =
14956       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14957     __ tbr(cond, $op1$$Register, 63, *L);
14958   %}
14959   ins_pipe(pipe_cmp_branch);
14960   ins_short_branch(1);
14961 %}
14962 
14963 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14964   match(If cmp (CmpI op1 op2));
14965   effect(USE labl);
14966 
14967   ins_cost(BRANCH_COST);
14968   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14969   ins_encode %{
14970     Label* L = $labl$$label;
14971     Assembler::Condition cond =
14972       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14973     __ tbr(cond, $op1$$Register, 31, *L);
14974   %}
14975   ins_pipe(pipe_cmp_branch);
14976   ins_short_branch(1);
14977 %}
14978 
14979 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14980   match(If cmp (CmpL (AndL op1 op2) op3));
<a name="114" id="anc114"></a><span class="line-modified">14981   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
14982   effect(USE labl);
14983 
14984   ins_cost(BRANCH_COST);
14985   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14986   ins_encode %{
14987     Label* L = $labl$$label;
14988     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<a name="115" id="anc115"></a><span class="line-modified">14989     int bit = exact_log2($op2$$constant);</span>
14990     __ tbr(cond, $op1$$Register, bit, *L);
14991   %}
14992   ins_pipe(pipe_cmp_branch);
14993   ins_short_branch(1);
14994 %}
14995 
14996 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14997   match(If cmp (CmpI (AndI op1 op2) op3));
<a name="116" id="anc116"></a><span class="line-modified">14998   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
14999   effect(USE labl);
15000 
15001   ins_cost(BRANCH_COST);
15002   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15003   ins_encode %{
15004     Label* L = $labl$$label;
15005     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<a name="117" id="anc117"></a><span class="line-modified">15006     int bit = exact_log2($op2$$constant);</span>
15007     __ tbr(cond, $op1$$Register, bit, *L);
15008   %}
15009   ins_pipe(pipe_cmp_branch);
15010   ins_short_branch(1);
15011 %}
15012 
15013 // And far variants
15014 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15015   match(If cmp (CmpL op1 op2));
15016   effect(USE labl);
15017 
15018   ins_cost(BRANCH_COST);
15019   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15020   ins_encode %{
15021     Label* L = $labl$$label;
15022     Assembler::Condition cond =
15023       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15024     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15025   %}
15026   ins_pipe(pipe_cmp_branch);
15027 %}
15028 
15029 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15030   match(If cmp (CmpI op1 op2));
15031   effect(USE labl);
15032 
15033   ins_cost(BRANCH_COST);
15034   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15035   ins_encode %{
15036     Label* L = $labl$$label;
15037     Assembler::Condition cond =
15038       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15039     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15040   %}
15041   ins_pipe(pipe_cmp_branch);
15042 %}
15043 
15044 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15045   match(If cmp (CmpL (AndL op1 op2) op3));
<a name="118" id="anc118"></a><span class="line-modified">15046   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
15047   effect(USE labl);
15048 
15049   ins_cost(BRANCH_COST);
15050   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15051   ins_encode %{
15052     Label* L = $labl$$label;
15053     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<a name="119" id="anc119"></a><span class="line-modified">15054     int bit = exact_log2($op2$$constant);</span>
15055     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15056   %}
15057   ins_pipe(pipe_cmp_branch);
15058 %}
15059 
15060 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15061   match(If cmp (CmpI (AndI op1 op2) op3));
<a name="120" id="anc120"></a><span class="line-modified">15062   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
15063   effect(USE labl);
15064 
15065   ins_cost(BRANCH_COST);
15066   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15067   ins_encode %{
15068     Label* L = $labl$$label;
15069     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<a name="121" id="anc121"></a><span class="line-modified">15070     int bit = exact_log2($op2$$constant);</span>
15071     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15072   %}
15073   ins_pipe(pipe_cmp_branch);
15074 %}
15075 
15076 // Test bits
15077 
15078 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15079   match(Set cr (CmpL (AndL op1 op2) op3));
15080   predicate(Assembler::operand_valid_for_logical_immediate
15081             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15082 
15083   ins_cost(INSN_COST);
15084   format %{ &quot;tst $op1, $op2 # long&quot; %}
15085   ins_encode %{
15086     __ tst($op1$$Register, $op2$$constant);
15087   %}
15088   ins_pipe(ialu_reg_reg);
15089 %}
15090 
15091 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15092   match(Set cr (CmpI (AndI op1 op2) op3));
15093   predicate(Assembler::operand_valid_for_logical_immediate
15094             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15095 
15096   ins_cost(INSN_COST);
15097   format %{ &quot;tst $op1, $op2 # int&quot; %}
15098   ins_encode %{
15099     __ tstw($op1$$Register, $op2$$constant);
15100   %}
15101   ins_pipe(ialu_reg_reg);
15102 %}
15103 
15104 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15105   match(Set cr (CmpL (AndL op1 op2) op3));
15106 
15107   ins_cost(INSN_COST);
15108   format %{ &quot;tst $op1, $op2 # long&quot; %}
15109   ins_encode %{
15110     __ tst($op1$$Register, $op2$$Register);
15111   %}
15112   ins_pipe(ialu_reg_reg);
15113 %}
15114 
15115 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15116   match(Set cr (CmpI (AndI op1 op2) op3));
15117 
15118   ins_cost(INSN_COST);
15119   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15120   ins_encode %{
15121     __ tstw($op1$$Register, $op2$$Register);
15122   %}
15123   ins_pipe(ialu_reg_reg);
15124 %}
15125 
15126 
15127 // Conditional Far Branch
15128 // Conditional Far Branch Unsigned
15129 // TODO: fixme
15130 
15131 // counted loop end branch near
15132 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15133 %{
15134   match(CountedLoopEnd cmp cr);
15135 
15136   effect(USE lbl);
15137 
15138   ins_cost(BRANCH_COST);
15139   // short variant.
15140   // ins_short_branch(1);
15141   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15142 
15143   ins_encode(aarch64_enc_br_con(cmp, lbl));
15144 
15145   ins_pipe(pipe_branch);
15146 %}
15147 
15148 // counted loop end branch near Unsigned
15149 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15150 %{
15151   match(CountedLoopEnd cmp cr);
15152 
15153   effect(USE lbl);
15154 
15155   ins_cost(BRANCH_COST);
15156   // short variant.
15157   // ins_short_branch(1);
15158   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15159 
15160   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15161 
15162   ins_pipe(pipe_branch);
15163 %}
15164 
15165 // counted loop end branch far
15166 // counted loop end branch far unsigned
15167 // TODO: fixme
15168 
15169 // ============================================================================
15170 // inlined locking and unlocking
15171 
15172 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15173 %{
15174   match(Set cr (FastLock object box));
15175   effect(TEMP tmp, TEMP tmp2);
15176 
15177   // TODO
15178   // identify correct cost
15179   ins_cost(5 * INSN_COST);
15180   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15181 
15182   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15183 
15184   ins_pipe(pipe_serial);
15185 %}
15186 
15187 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15188 %{
15189   match(Set cr (FastUnlock object box));
15190   effect(TEMP tmp, TEMP tmp2);
15191 
15192   ins_cost(5 * INSN_COST);
15193   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15194 
15195   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15196 
15197   ins_pipe(pipe_serial);
15198 %}
15199 
15200 
15201 // ============================================================================
15202 // Safepoint Instructions
15203 
15204 // TODO
15205 // provide a near and far version of this code
15206 
15207 instruct safePoint(rFlagsReg cr, iRegP poll)
15208 %{
15209   match(SafePoint poll);
15210   effect(KILL cr);
15211 
15212   format %{
15213     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15214   %}
15215   ins_encode %{
15216     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15217   %}
15218   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15219 %}
15220 
15221 
15222 // ============================================================================
15223 // Procedure Call/Return Instructions
15224 
15225 // Call Java Static Instruction
15226 
15227 instruct CallStaticJavaDirect(method meth)
15228 %{
15229   match(CallStaticJava);
15230 
15231   effect(USE meth);
15232 
15233   ins_cost(CALL_COST);
15234 
15235   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15236 
15237   ins_encode( aarch64_enc_java_static_call(meth),
15238               aarch64_enc_call_epilog );
15239 
15240   ins_pipe(pipe_class_call);
15241 %}
15242 
15243 // TO HERE
15244 
15245 // Call Java Dynamic Instruction
15246 instruct CallDynamicJavaDirect(method meth)
15247 %{
15248   match(CallDynamicJava);
15249 
15250   effect(USE meth);
15251 
15252   ins_cost(CALL_COST);
15253 
15254   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15255 
15256   ins_encode( aarch64_enc_java_dynamic_call(meth),
15257                aarch64_enc_call_epilog );
15258 
15259   ins_pipe(pipe_class_call);
15260 %}
15261 
15262 // Call Runtime Instruction
15263 
15264 instruct CallRuntimeDirect(method meth)
15265 %{
15266   match(CallRuntime);
15267 
15268   effect(USE meth);
15269 
15270   ins_cost(CALL_COST);
15271 
15272   format %{ &quot;CALL, runtime $meth&quot; %}
15273 
15274   ins_encode( aarch64_enc_java_to_runtime(meth) );
15275 
15276   ins_pipe(pipe_class_call);
15277 %}
15278 
15279 // Call Runtime Instruction
15280 
15281 instruct CallLeafDirect(method meth)
15282 %{
15283   match(CallLeaf);
15284 
15285   effect(USE meth);
15286 
15287   ins_cost(CALL_COST);
15288 
15289   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15290 
15291   ins_encode( aarch64_enc_java_to_runtime(meth) );
15292 
15293   ins_pipe(pipe_class_call);
15294 %}
15295 
15296 // Call Runtime Instruction
15297 
15298 instruct CallLeafNoFPDirect(method meth)
15299 %{
15300   match(CallLeafNoFP);
15301 
15302   effect(USE meth);
15303 
15304   ins_cost(CALL_COST);
15305 
15306   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15307 
15308   ins_encode( aarch64_enc_java_to_runtime(meth) );
15309 
15310   ins_pipe(pipe_class_call);
15311 %}
15312 
15313 // Tail Call; Jump from runtime stub to Java code.
15314 // Also known as an &#39;interprocedural jump&#39;.
15315 // Target of jump will eventually return to caller.
15316 // TailJump below removes the return address.
15317 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15318 %{
15319   match(TailCall jump_target method_oop);
15320 
15321   ins_cost(CALL_COST);
15322 
15323   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15324 
15325   ins_encode(aarch64_enc_tail_call(jump_target));
15326 
15327   ins_pipe(pipe_class_call);
15328 %}
15329 
15330 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15331 %{
15332   match(TailJump jump_target ex_oop);
15333 
15334   ins_cost(CALL_COST);
15335 
15336   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15337 
15338   ins_encode(aarch64_enc_tail_jmp(jump_target));
15339 
15340   ins_pipe(pipe_class_call);
15341 %}
15342 
15343 // Create exception oop: created by stack-crawling runtime code.
15344 // Created exception is now available to this handler, and is setup
15345 // just prior to jumping to this handler. No code emitted.
15346 // TODO check
15347 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15348 instruct CreateException(iRegP_R0 ex_oop)
15349 %{
15350   match(Set ex_oop (CreateEx));
15351 
15352   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15353 
15354   size(0);
15355 
15356   ins_encode( /*empty*/ );
15357 
15358   ins_pipe(pipe_class_empty);
15359 %}
15360 
15361 // Rethrow exception: The exception oop will come in the first
15362 // argument position. Then JUMP (not call) to the rethrow stub code.
15363 instruct RethrowException() %{
15364   match(Rethrow);
15365   ins_cost(CALL_COST);
15366 
15367   format %{ &quot;b rethrow_stub&quot; %}
15368 
15369   ins_encode( aarch64_enc_rethrow() );
15370 
15371   ins_pipe(pipe_class_call);
15372 %}
15373 
15374 
15375 // Return Instruction
15376 // epilog node loads ret address into lr as part of frame pop
15377 instruct Ret()
15378 %{
15379   match(Return);
15380 
15381   format %{ &quot;ret\t// return register&quot; %}
15382 
15383   ins_encode( aarch64_enc_ret() );
15384 
15385   ins_pipe(pipe_branch);
15386 %}
15387 
15388 // Die now.
15389 instruct ShouldNotReachHere() %{
15390   match(Halt);
15391 
15392   ins_cost(CALL_COST);
15393   format %{ &quot;ShouldNotReachHere&quot; %}
15394 
15395   ins_encode %{
15396     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15397     // return true
15398     __ dpcs1(0xdead + 1);
15399   %}
15400 
15401   ins_pipe(pipe_class_default);
15402 %}
15403 
15404 // ============================================================================
15405 // Partial Subtype Check
15406 //
15407 // superklass array for an instance of the superklass.  Set a hidden
15408 // internal cache on a hit (cache is checked with exposed code in
15409 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15410 // encoding ALSO sets flags.
15411 
15412 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15413 %{
15414   match(Set result (PartialSubtypeCheck sub super));
15415   effect(KILL cr, KILL temp);
15416 
15417   ins_cost(1100);  // slightly larger than the next version
15418   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15419 
15420   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15421 
15422   opcode(0x1); // Force zero of result reg on hit
15423 
15424   ins_pipe(pipe_class_memory);
15425 %}
15426 
15427 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15428 %{
15429   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15430   effect(KILL temp, KILL result);
15431 
15432   ins_cost(1100);  // slightly larger than the next version
15433   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15434 
15435   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15436 
15437   opcode(0x0); // Don&#39;t zero result reg on hit
15438 
15439   ins_pipe(pipe_class_memory);
15440 %}
15441 
15442 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15443                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15444 %{
15445   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15446   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15447   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15448 
15449   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15450   ins_encode %{
15451     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15452     __ string_compare($str1$$Register, $str2$$Register,
15453                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15454                       $tmp1$$Register, $tmp2$$Register,
15455                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15456   %}
15457   ins_pipe(pipe_class_memory);
15458 %}
15459 
15460 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15461                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15462 %{
15463   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15464   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15465   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15466 
15467   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15468   ins_encode %{
15469     __ string_compare($str1$$Register, $str2$$Register,
15470                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15471                       $tmp1$$Register, $tmp2$$Register,
15472                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15473   %}
15474   ins_pipe(pipe_class_memory);
15475 %}
15476 
15477 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15478                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15479                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15480 %{
15481   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15482   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15483   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15484          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15485 
15486   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15487   ins_encode %{
15488     __ string_compare($str1$$Register, $str2$$Register,
15489                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15490                       $tmp1$$Register, $tmp2$$Register,
15491                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15492                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15493   %}
15494   ins_pipe(pipe_class_memory);
15495 %}
15496 
15497 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15498                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15499                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15500 %{
15501   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15502   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15503   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15504          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15505 
15506   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15507   ins_encode %{
15508     __ string_compare($str1$$Register, $str2$$Register,
15509                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15510                       $tmp1$$Register, $tmp2$$Register,
15511                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15512                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15513   %}
15514   ins_pipe(pipe_class_memory);
15515 %}
15516 
15517 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15518        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15519        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15520 %{
15521   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15522   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15523   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15524          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15525   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15526 
15527   ins_encode %{
15528     __ string_indexof($str1$$Register, $str2$$Register,
15529                       $cnt1$$Register, $cnt2$$Register,
15530                       $tmp1$$Register, $tmp2$$Register,
15531                       $tmp3$$Register, $tmp4$$Register,
15532                       $tmp5$$Register, $tmp6$$Register,
15533                       -1, $result$$Register, StrIntrinsicNode::UU);
15534   %}
15535   ins_pipe(pipe_class_memory);
15536 %}
15537 
15538 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15539        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15540        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15541 %{
15542   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15543   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15544   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15545          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15546   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15547 
15548   ins_encode %{
15549     __ string_indexof($str1$$Register, $str2$$Register,
15550                       $cnt1$$Register, $cnt2$$Register,
15551                       $tmp1$$Register, $tmp2$$Register,
15552                       $tmp3$$Register, $tmp4$$Register,
15553                       $tmp5$$Register, $tmp6$$Register,
15554                       -1, $result$$Register, StrIntrinsicNode::LL);
15555   %}
15556   ins_pipe(pipe_class_memory);
15557 %}
15558 
15559 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15560        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15561        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15562 %{
15563   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15564   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15565   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15566          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15567   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15568 
15569   ins_encode %{
15570     __ string_indexof($str1$$Register, $str2$$Register,
15571                       $cnt1$$Register, $cnt2$$Register,
15572                       $tmp1$$Register, $tmp2$$Register,
15573                       $tmp3$$Register, $tmp4$$Register,
15574                       $tmp5$$Register, $tmp6$$Register,
15575                       -1, $result$$Register, StrIntrinsicNode::UL);
15576   %}
15577   ins_pipe(pipe_class_memory);
15578 %}
15579 
15580 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15581                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15582                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15583 %{
15584   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15585   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15586   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15587          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15588   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15589 
15590   ins_encode %{
15591     int icnt2 = (int)$int_cnt2$$constant;
15592     __ string_indexof($str1$$Register, $str2$$Register,
15593                       $cnt1$$Register, zr,
15594                       $tmp1$$Register, $tmp2$$Register,
15595                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15596                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15597   %}
15598   ins_pipe(pipe_class_memory);
15599 %}
15600 
15601 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15602                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15603                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15604 %{
15605   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15606   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15607   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15608          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15609   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15610 
15611   ins_encode %{
15612     int icnt2 = (int)$int_cnt2$$constant;
15613     __ string_indexof($str1$$Register, $str2$$Register,
15614                       $cnt1$$Register, zr,
15615                       $tmp1$$Register, $tmp2$$Register,
15616                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15617                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15618   %}
15619   ins_pipe(pipe_class_memory);
15620 %}
15621 
15622 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15623                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15624                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15625 %{
15626   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15627   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15628   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15629          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15630   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15631 
15632   ins_encode %{
15633     int icnt2 = (int)$int_cnt2$$constant;
15634     __ string_indexof($str1$$Register, $str2$$Register,
15635                       $cnt1$$Register, zr,
15636                       $tmp1$$Register, $tmp2$$Register,
15637                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15638                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15639   %}
15640   ins_pipe(pipe_class_memory);
15641 %}
15642 
15643 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15644                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15645                               iRegINoSp tmp3, rFlagsReg cr)
15646 %{
15647   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15648   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15649          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15650 
15651   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15652 
15653   ins_encode %{
15654     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15655                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15656                            $tmp3$$Register);
15657   %}
15658   ins_pipe(pipe_class_memory);
15659 %}
15660 
15661 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15662                         iRegI_R0 result, rFlagsReg cr)
15663 %{
15664   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15665   match(Set result (StrEquals (Binary str1 str2) cnt));
15666   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15667 
15668   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15669   ins_encode %{
15670     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15671     __ string_equals($str1$$Register, $str2$$Register,
15672                      $result$$Register, $cnt$$Register, 1);
15673   %}
15674   ins_pipe(pipe_class_memory);
15675 %}
15676 
15677 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15678                         iRegI_R0 result, rFlagsReg cr)
15679 %{
15680   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15681   match(Set result (StrEquals (Binary str1 str2) cnt));
15682   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15683 
15684   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15685   ins_encode %{
15686     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15687     __ string_equals($str1$$Register, $str2$$Register,
15688                      $result$$Register, $cnt$$Register, 2);
15689   %}
15690   ins_pipe(pipe_class_memory);
15691 %}
15692 
15693 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15694                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15695                        iRegP_R10 tmp, rFlagsReg cr)
15696 %{
15697   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15698   match(Set result (AryEq ary1 ary2));
15699   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15700 
15701   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15702   ins_encode %{
15703     __ arrays_equals($ary1$$Register, $ary2$$Register,
15704                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15705                      $result$$Register, $tmp$$Register, 1);
15706     %}
15707   ins_pipe(pipe_class_memory);
15708 %}
15709 
15710 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15711                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15712                        iRegP_R10 tmp, rFlagsReg cr)
15713 %{
15714   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15715   match(Set result (AryEq ary1 ary2));
15716   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15717 
15718   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15719   ins_encode %{
15720     __ arrays_equals($ary1$$Register, $ary2$$Register,
15721                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15722                      $result$$Register, $tmp$$Register, 2);
15723   %}
15724   ins_pipe(pipe_class_memory);
15725 %}
15726 
15727 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15728 %{
15729   match(Set result (HasNegatives ary1 len));
15730   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15731   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15732   ins_encode %{
15733     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15734   %}
15735   ins_pipe( pipe_slow );
15736 %}
15737 
15738 // fast char[] to byte[] compression
15739 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15740                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15741                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15742                          iRegI_R0 result, rFlagsReg cr)
15743 %{
15744   match(Set result (StrCompressedCopy src (Binary dst len)));
15745   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15746 
15747   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15748   ins_encode %{
15749     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15750                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15751                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15752                            $result$$Register);
15753   %}
15754   ins_pipe( pipe_slow );
15755 %}
15756 
15757 // fast byte[] to char[] inflation
15758 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15759                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15760 %{
15761   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15762   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15763 
15764   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15765   ins_encode %{
15766     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15767                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15768   %}
15769   ins_pipe(pipe_class_memory);
15770 %}
15771 
15772 // encode char[] to byte[] in ISO_8859_1
15773 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15774                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15775                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15776                           iRegI_R0 result, rFlagsReg cr)
15777 %{
15778   match(Set result (EncodeISOArray src (Binary dst len)));
15779   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15780          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15781 
15782   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15783   ins_encode %{
15784     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15785          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15786          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15787   %}
15788   ins_pipe( pipe_class_memory );
15789 %}
15790 
15791 // ============================================================================
15792 // This name is KNOWN by the ADLC and cannot be changed.
15793 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15794 // for this guy.
15795 instruct tlsLoadP(thread_RegP dst)
15796 %{
15797   match(Set dst (ThreadLocal));
15798 
15799   ins_cost(0);
15800 
15801   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15802 
15803   size(0);
15804 
15805   ins_encode( /*empty*/ );
15806 
15807   ins_pipe(pipe_class_empty);
15808 %}
15809 
15810 // ====================VECTOR INSTRUCTIONS=====================================
15811 
15812 // Load vector (32 bits)
15813 instruct loadV4(vecD dst, vmem4 mem)
15814 %{
15815   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15816   match(Set dst (LoadVector mem));
15817   ins_cost(4 * INSN_COST);
15818   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15819   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15820   ins_pipe(vload_reg_mem64);
15821 %}
15822 
15823 // Load vector (64 bits)
15824 instruct loadV8(vecD dst, vmem8 mem)
15825 %{
15826   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15827   match(Set dst (LoadVector mem));
15828   ins_cost(4 * INSN_COST);
15829   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15830   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15831   ins_pipe(vload_reg_mem64);
15832 %}
15833 
15834 // Load Vector (128 bits)
15835 instruct loadV16(vecX dst, vmem16 mem)
15836 %{
15837   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15838   match(Set dst (LoadVector mem));
15839   ins_cost(4 * INSN_COST);
15840   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15841   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15842   ins_pipe(vload_reg_mem128);
15843 %}
15844 
15845 // Store Vector (32 bits)
15846 instruct storeV4(vecD src, vmem4 mem)
15847 %{
15848   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15849   match(Set mem (StoreVector mem src));
15850   ins_cost(4 * INSN_COST);
15851   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15852   ins_encode( aarch64_enc_strvS(src, mem) );
15853   ins_pipe(vstore_reg_mem64);
15854 %}
15855 
15856 // Store Vector (64 bits)
15857 instruct storeV8(vecD src, vmem8 mem)
15858 %{
15859   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15860   match(Set mem (StoreVector mem src));
15861   ins_cost(4 * INSN_COST);
15862   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15863   ins_encode( aarch64_enc_strvD(src, mem) );
15864   ins_pipe(vstore_reg_mem64);
15865 %}
15866 
15867 // Store Vector (128 bits)
15868 instruct storeV16(vecX src, vmem16 mem)
15869 %{
15870   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15871   match(Set mem (StoreVector mem src));
15872   ins_cost(4 * INSN_COST);
15873   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15874   ins_encode( aarch64_enc_strvQ(src, mem) );
15875   ins_pipe(vstore_reg_mem128);
15876 %}
15877 
15878 instruct replicate8B(vecD dst, iRegIorL2I src)
15879 %{
15880   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15881             n-&gt;as_Vector()-&gt;length() == 8);
15882   match(Set dst (ReplicateB src));
15883   ins_cost(INSN_COST);
15884   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15885   ins_encode %{
15886     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15887   %}
15888   ins_pipe(vdup_reg_reg64);
15889 %}
15890 
15891 instruct replicate16B(vecX dst, iRegIorL2I src)
15892 %{
15893   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15894   match(Set dst (ReplicateB src));
15895   ins_cost(INSN_COST);
15896   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15897   ins_encode %{
15898     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15899   %}
15900   ins_pipe(vdup_reg_reg128);
15901 %}
15902 
15903 instruct replicate8B_imm(vecD dst, immI con)
15904 %{
15905   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15906             n-&gt;as_Vector()-&gt;length() == 8);
15907   match(Set dst (ReplicateB con));
15908   ins_cost(INSN_COST);
15909   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15910   ins_encode %{
15911     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15912   %}
15913   ins_pipe(vmovi_reg_imm64);
15914 %}
15915 
15916 instruct replicate16B_imm(vecX dst, immI con)
15917 %{
15918   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15919   match(Set dst (ReplicateB con));
15920   ins_cost(INSN_COST);
15921   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15922   ins_encode %{
15923     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15924   %}
15925   ins_pipe(vmovi_reg_imm128);
15926 %}
15927 
15928 instruct replicate4S(vecD dst, iRegIorL2I src)
15929 %{
15930   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15931             n-&gt;as_Vector()-&gt;length() == 4);
15932   match(Set dst (ReplicateS src));
15933   ins_cost(INSN_COST);
15934   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15935   ins_encode %{
15936     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15937   %}
15938   ins_pipe(vdup_reg_reg64);
15939 %}
15940 
15941 instruct replicate8S(vecX dst, iRegIorL2I src)
15942 %{
15943   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15944   match(Set dst (ReplicateS src));
15945   ins_cost(INSN_COST);
15946   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15947   ins_encode %{
15948     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15949   %}
15950   ins_pipe(vdup_reg_reg128);
15951 %}
15952 
15953 instruct replicate4S_imm(vecD dst, immI con)
15954 %{
15955   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15956             n-&gt;as_Vector()-&gt;length() == 4);
15957   match(Set dst (ReplicateS con));
15958   ins_cost(INSN_COST);
15959   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15960   ins_encode %{
15961     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15962   %}
15963   ins_pipe(vmovi_reg_imm64);
15964 %}
15965 
15966 instruct replicate8S_imm(vecX dst, immI con)
15967 %{
15968   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15969   match(Set dst (ReplicateS con));
15970   ins_cost(INSN_COST);
15971   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15972   ins_encode %{
15973     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15974   %}
15975   ins_pipe(vmovi_reg_imm128);
15976 %}
15977 
15978 instruct replicate2I(vecD dst, iRegIorL2I src)
15979 %{
15980   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15981   match(Set dst (ReplicateI src));
15982   ins_cost(INSN_COST);
15983   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15984   ins_encode %{
15985     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15986   %}
15987   ins_pipe(vdup_reg_reg64);
15988 %}
15989 
15990 instruct replicate4I(vecX dst, iRegIorL2I src)
15991 %{
15992   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15993   match(Set dst (ReplicateI src));
15994   ins_cost(INSN_COST);
15995   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15996   ins_encode %{
15997     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15998   %}
15999   ins_pipe(vdup_reg_reg128);
16000 %}
16001 
16002 instruct replicate2I_imm(vecD dst, immI con)
16003 %{
16004   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16005   match(Set dst (ReplicateI con));
16006   ins_cost(INSN_COST);
16007   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
16008   ins_encode %{
16009     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
16010   %}
16011   ins_pipe(vmovi_reg_imm64);
16012 %}
16013 
16014 instruct replicate4I_imm(vecX dst, immI con)
16015 %{
16016   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16017   match(Set dst (ReplicateI con));
16018   ins_cost(INSN_COST);
16019   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
16020   ins_encode %{
16021     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
16022   %}
16023   ins_pipe(vmovi_reg_imm128);
16024 %}
16025 
16026 instruct replicate2L(vecX dst, iRegL src)
16027 %{
16028   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16029   match(Set dst (ReplicateL src));
16030   ins_cost(INSN_COST);
16031   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
16032   ins_encode %{
16033     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
16034   %}
16035   ins_pipe(vdup_reg_reg128);
16036 %}
16037 
16038 instruct replicate2L_zero(vecX dst, immI0 zero)
16039 %{
16040   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16041   match(Set dst (ReplicateI zero));
16042   ins_cost(INSN_COST);
16043   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16044   ins_encode %{
16045     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16046            as_FloatRegister($dst$$reg),
16047            as_FloatRegister($dst$$reg));
16048   %}
16049   ins_pipe(vmovi_reg_imm128);
16050 %}
16051 
16052 instruct replicate2F(vecD dst, vRegF src)
16053 %{
16054   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16055   match(Set dst (ReplicateF src));
16056   ins_cost(INSN_COST);
16057   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16058   ins_encode %{
16059     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16060            as_FloatRegister($src$$reg));
16061   %}
16062   ins_pipe(vdup_reg_freg64);
16063 %}
16064 
16065 instruct replicate4F(vecX dst, vRegF src)
16066 %{
16067   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16068   match(Set dst (ReplicateF src));
16069   ins_cost(INSN_COST);
16070   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16071   ins_encode %{
16072     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16073            as_FloatRegister($src$$reg));
16074   %}
16075   ins_pipe(vdup_reg_freg128);
16076 %}
16077 
16078 instruct replicate2D(vecX dst, vRegD src)
16079 %{
16080   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16081   match(Set dst (ReplicateD src));
16082   ins_cost(INSN_COST);
16083   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16084   ins_encode %{
16085     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16086            as_FloatRegister($src$$reg));
16087   %}
16088   ins_pipe(vdup_reg_dreg128);
16089 %}
16090 
16091 // ====================REDUCTION ARITHMETIC====================================
16092 
16093 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16094 %{
16095   match(Set dst (AddReductionVI src1 src2));
16096   ins_cost(INSN_COST);
16097   effect(TEMP tmp, TEMP tmp2);
16098   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16099             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
16100             &quot;addw  $dst, $src1, $tmp\n\t&quot;
16101             &quot;addw  $dst, $dst, $tmp2\t add reduction2i&quot;
16102   %}
16103   ins_encode %{
16104     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16105     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16106     __ addw($dst$$Register, $src1$$Register, $tmp$$Register);
16107     __ addw($dst$$Register, $dst$$Register, $tmp2$$Register);
16108   %}
16109   ins_pipe(pipe_class_default);
16110 %}
16111 
16112 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16113 %{
16114   match(Set dst (AddReductionVI src1 src2));
16115   ins_cost(INSN_COST);
16116   effect(TEMP tmp, TEMP tmp2);
16117   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16118             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16119             &quot;addw  $dst, $tmp2, $src1\t add reduction4i&quot;
16120   %}
16121   ins_encode %{
16122     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16123             as_FloatRegister($src2$$reg));
16124     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16125     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16126   %}
16127   ins_pipe(pipe_class_default);
16128 %}
16129 
16130 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16131 %{
16132   match(Set dst (MulReductionVI src1 src2));
16133   ins_cost(INSN_COST);
16134   effect(TEMP tmp, TEMP dst);
16135   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16136             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16137             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
16138             &quot;mul   $dst, $tmp, $dst\t mul reduction2i\n\t&quot;
16139   %}
16140   ins_encode %{
16141     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16142     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16143     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16144     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16145   %}
16146   ins_pipe(pipe_class_default);
16147 %}
16148 
16149 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16150 %{
16151   match(Set dst (MulReductionVI src1 src2));
16152   ins_cost(INSN_COST);
16153   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16154   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16155             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16156             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16157             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16158             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
16159             &quot;mul   $dst, $tmp2, $dst\t mul reduction4i\n\t&quot;
16160   %}
16161   ins_encode %{
16162     __ ins(as_FloatRegister($tmp$$reg), __ D,
16163            as_FloatRegister($src2$$reg), 0, 1);
16164     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16165            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16166     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16167     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16168     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16169     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16170   %}
16171   ins_pipe(pipe_class_default);
16172 %}
16173 
16174 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16175 %{
16176   match(Set dst (AddReductionVF src1 src2));
16177   ins_cost(INSN_COST);
16178   effect(TEMP tmp, TEMP dst);
16179   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16180             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16181             &quot;fadds $dst, $dst, $tmp\t add reduction2f&quot;
16182   %}
16183   ins_encode %{
16184     __ fadds(as_FloatRegister($dst$$reg),
16185              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16186     __ ins(as_FloatRegister($tmp$$reg), __ S,
16187            as_FloatRegister($src2$$reg), 0, 1);
16188     __ fadds(as_FloatRegister($dst$$reg),
16189              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16190   %}
16191   ins_pipe(pipe_class_default);
16192 %}
16193 
16194 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16195 %{
16196   match(Set dst (AddReductionVF src1 src2));
16197   ins_cost(INSN_COST);
16198   effect(TEMP tmp, TEMP dst);
16199   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16200             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16201             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16202             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16203             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16204             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16205             &quot;fadds $dst, $dst, $tmp\t add reduction4f&quot;
16206   %}
16207   ins_encode %{
16208     __ fadds(as_FloatRegister($dst$$reg),
16209              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16210     __ ins(as_FloatRegister($tmp$$reg), __ S,
16211            as_FloatRegister($src2$$reg), 0, 1);
16212     __ fadds(as_FloatRegister($dst$$reg),
16213              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16214     __ ins(as_FloatRegister($tmp$$reg), __ S,
16215            as_FloatRegister($src2$$reg), 0, 2);
16216     __ fadds(as_FloatRegister($dst$$reg),
16217              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16218     __ ins(as_FloatRegister($tmp$$reg), __ S,
16219            as_FloatRegister($src2$$reg), 0, 3);
16220     __ fadds(as_FloatRegister($dst$$reg),
16221              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16222   %}
16223   ins_pipe(pipe_class_default);
16224 %}
16225 
16226 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16227 %{
16228   match(Set dst (MulReductionVF src1 src2));
16229   ins_cost(INSN_COST);
16230   effect(TEMP tmp, TEMP dst);
16231   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16232             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16233             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16234   %}
16235   ins_encode %{
16236     __ fmuls(as_FloatRegister($dst$$reg),
16237              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16238     __ ins(as_FloatRegister($tmp$$reg), __ S,
16239            as_FloatRegister($src2$$reg), 0, 1);
16240     __ fmuls(as_FloatRegister($dst$$reg),
16241              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16242   %}
16243   ins_pipe(pipe_class_default);
16244 %}
16245 
16246 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16247 %{
16248   match(Set dst (MulReductionVF src1 src2));
16249   ins_cost(INSN_COST);
16250   effect(TEMP tmp, TEMP dst);
16251   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16252             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16253             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16254             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16255             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16256             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16257             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16258   %}
16259   ins_encode %{
16260     __ fmuls(as_FloatRegister($dst$$reg),
16261              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16262     __ ins(as_FloatRegister($tmp$$reg), __ S,
16263            as_FloatRegister($src2$$reg), 0, 1);
16264     __ fmuls(as_FloatRegister($dst$$reg),
16265              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16266     __ ins(as_FloatRegister($tmp$$reg), __ S,
16267            as_FloatRegister($src2$$reg), 0, 2);
16268     __ fmuls(as_FloatRegister($dst$$reg),
16269              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16270     __ ins(as_FloatRegister($tmp$$reg), __ S,
16271            as_FloatRegister($src2$$reg), 0, 3);
16272     __ fmuls(as_FloatRegister($dst$$reg),
16273              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16274   %}
16275   ins_pipe(pipe_class_default);
16276 %}
16277 
16278 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16279 %{
16280   match(Set dst (AddReductionVD src1 src2));
16281   ins_cost(INSN_COST);
16282   effect(TEMP tmp, TEMP dst);
16283   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16284             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16285             &quot;faddd $dst, $dst, $tmp\t add reduction2d&quot;
16286   %}
16287   ins_encode %{
16288     __ faddd(as_FloatRegister($dst$$reg),
16289              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16290     __ ins(as_FloatRegister($tmp$$reg), __ D,
16291            as_FloatRegister($src2$$reg), 0, 1);
16292     __ faddd(as_FloatRegister($dst$$reg),
16293              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16294   %}
16295   ins_pipe(pipe_class_default);
16296 %}
16297 
16298 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16299 %{
16300   match(Set dst (MulReductionVD src1 src2));
16301   ins_cost(INSN_COST);
16302   effect(TEMP tmp, TEMP dst);
16303   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16304             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16305             &quot;fmuld $dst, $dst, $tmp\t add reduction2d&quot;
16306   %}
16307   ins_encode %{
16308     __ fmuld(as_FloatRegister($dst$$reg),
16309              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16310     __ ins(as_FloatRegister($tmp$$reg), __ D,
16311            as_FloatRegister($src2$$reg), 0, 1);
16312     __ fmuld(as_FloatRegister($dst$$reg),
16313              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16314   %}
16315   ins_pipe(pipe_class_default);
16316 %}
16317 
16318 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16319   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16320   match(Set dst (MaxReductionV src1 src2));
16321   ins_cost(INSN_COST);
16322   effect(TEMP_DEF dst, TEMP tmp);
16323   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16324             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16325             &quot;fmaxs $dst, $dst, $tmp\t max reduction2F&quot; %}
16326   ins_encode %{
16327     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16328     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16329     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16330   %}
16331   ins_pipe(pipe_class_default);
16332 %}
16333 
16334 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16335   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16336   match(Set dst (MaxReductionV src1 src2));
16337   ins_cost(INSN_COST);
16338   effect(TEMP_DEF dst);
16339   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
16340             &quot;fmaxs $dst, $dst, $src1\t max reduction4F&quot; %}
16341   ins_encode %{
16342     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16343     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16344   %}
16345   ins_pipe(pipe_class_default);
16346 %}
16347 
16348 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16349   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16350   match(Set dst (MaxReductionV src1 src2));
16351   ins_cost(INSN_COST);
16352   effect(TEMP_DEF dst, TEMP tmp);
16353   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16354             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16355             &quot;fmaxd $dst, $dst, $tmp\t max reduction2D&quot; %}
16356   ins_encode %{
16357     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16358     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16359     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16360   %}
16361   ins_pipe(pipe_class_default);
16362 %}
16363 
16364 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16365   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16366   match(Set dst (MinReductionV src1 src2));
16367   ins_cost(INSN_COST);
16368   effect(TEMP_DEF dst, TEMP tmp);
16369   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16370             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16371             &quot;fmins $dst, $dst, $tmp\t min reduction2F&quot; %}
16372   ins_encode %{
16373     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16374     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16375     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16376   %}
16377   ins_pipe(pipe_class_default);
16378 %}
16379 
16380 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16381   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16382   match(Set dst (MinReductionV src1 src2));
16383   ins_cost(INSN_COST);
16384   effect(TEMP_DEF dst);
16385   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
16386             &quot;fmins $dst, $dst, $src1\t min reduction4F&quot; %}
16387   ins_encode %{
16388     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16389     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16390   %}
16391   ins_pipe(pipe_class_default);
16392 %}
16393 
16394 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16395   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16396   match(Set dst (MinReductionV src1 src2));
16397   ins_cost(INSN_COST);
16398   effect(TEMP_DEF dst, TEMP tmp);
16399   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16400             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16401             &quot;fmind $dst, $dst, $tmp\t min reduction2D&quot; %}
16402   ins_encode %{
16403     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16404     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16405     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16406   %}
16407   ins_pipe(pipe_class_default);
16408 %}
16409 
16410 // ====================VECTOR ARITHMETIC=======================================
16411 
16412 // --------------------------------- ADD --------------------------------------
16413 
16414 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16415 %{
16416   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16417             n-&gt;as_Vector()-&gt;length() == 8);
16418   match(Set dst (AddVB src1 src2));
16419   ins_cost(INSN_COST);
16420   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16421   ins_encode %{
16422     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16423             as_FloatRegister($src1$$reg),
16424             as_FloatRegister($src2$$reg));
16425   %}
16426   ins_pipe(vdop64);
16427 %}
16428 
16429 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16430 %{
16431   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16432   match(Set dst (AddVB src1 src2));
16433   ins_cost(INSN_COST);
16434   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16435   ins_encode %{
16436     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16437             as_FloatRegister($src1$$reg),
16438             as_FloatRegister($src2$$reg));
16439   %}
16440   ins_pipe(vdop128);
16441 %}
16442 
16443 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16444 %{
16445   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16446             n-&gt;as_Vector()-&gt;length() == 4);
16447   match(Set dst (AddVS src1 src2));
16448   ins_cost(INSN_COST);
16449   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16450   ins_encode %{
16451     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16452             as_FloatRegister($src1$$reg),
16453             as_FloatRegister($src2$$reg));
16454   %}
16455   ins_pipe(vdop64);
16456 %}
16457 
16458 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16459 %{
16460   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16461   match(Set dst (AddVS src1 src2));
16462   ins_cost(INSN_COST);
16463   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16464   ins_encode %{
16465     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16466             as_FloatRegister($src1$$reg),
16467             as_FloatRegister($src2$$reg));
16468   %}
16469   ins_pipe(vdop128);
16470 %}
16471 
16472 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16473 %{
16474   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16475   match(Set dst (AddVI src1 src2));
16476   ins_cost(INSN_COST);
16477   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16478   ins_encode %{
16479     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16480             as_FloatRegister($src1$$reg),
16481             as_FloatRegister($src2$$reg));
16482   %}
16483   ins_pipe(vdop64);
16484 %}
16485 
16486 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16487 %{
16488   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16489   match(Set dst (AddVI src1 src2));
16490   ins_cost(INSN_COST);
16491   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16492   ins_encode %{
16493     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16494             as_FloatRegister($src1$$reg),
16495             as_FloatRegister($src2$$reg));
16496   %}
16497   ins_pipe(vdop128);
16498 %}
16499 
16500 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16501 %{
16502   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16503   match(Set dst (AddVL src1 src2));
16504   ins_cost(INSN_COST);
16505   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16506   ins_encode %{
16507     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16508             as_FloatRegister($src1$$reg),
16509             as_FloatRegister($src2$$reg));
16510   %}
16511   ins_pipe(vdop128);
16512 %}
16513 
16514 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16515 %{
16516   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16517   match(Set dst (AddVF src1 src2));
16518   ins_cost(INSN_COST);
16519   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16520   ins_encode %{
16521     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16522             as_FloatRegister($src1$$reg),
16523             as_FloatRegister($src2$$reg));
16524   %}
16525   ins_pipe(vdop_fp64);
16526 %}
16527 
16528 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16529 %{
16530   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16531   match(Set dst (AddVF src1 src2));
16532   ins_cost(INSN_COST);
16533   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16534   ins_encode %{
16535     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16536             as_FloatRegister($src1$$reg),
16537             as_FloatRegister($src2$$reg));
16538   %}
16539   ins_pipe(vdop_fp128);
16540 %}
16541 
16542 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16543 %{
16544   match(Set dst (AddVD src1 src2));
16545   ins_cost(INSN_COST);
16546   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16547   ins_encode %{
16548     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16549             as_FloatRegister($src1$$reg),
16550             as_FloatRegister($src2$$reg));
16551   %}
16552   ins_pipe(vdop_fp128);
16553 %}
16554 
16555 // --------------------------------- SUB --------------------------------------
16556 
16557 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16558 %{
16559   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16560             n-&gt;as_Vector()-&gt;length() == 8);
16561   match(Set dst (SubVB src1 src2));
16562   ins_cost(INSN_COST);
16563   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16564   ins_encode %{
16565     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16566             as_FloatRegister($src1$$reg),
16567             as_FloatRegister($src2$$reg));
16568   %}
16569   ins_pipe(vdop64);
16570 %}
16571 
16572 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16573 %{
16574   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16575   match(Set dst (SubVB src1 src2));
16576   ins_cost(INSN_COST);
16577   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16578   ins_encode %{
16579     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16580             as_FloatRegister($src1$$reg),
16581             as_FloatRegister($src2$$reg));
16582   %}
16583   ins_pipe(vdop128);
16584 %}
16585 
16586 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16587 %{
16588   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16589             n-&gt;as_Vector()-&gt;length() == 4);
16590   match(Set dst (SubVS src1 src2));
16591   ins_cost(INSN_COST);
16592   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16593   ins_encode %{
16594     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16595             as_FloatRegister($src1$$reg),
16596             as_FloatRegister($src2$$reg));
16597   %}
16598   ins_pipe(vdop64);
16599 %}
16600 
16601 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16602 %{
16603   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16604   match(Set dst (SubVS src1 src2));
16605   ins_cost(INSN_COST);
16606   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16607   ins_encode %{
16608     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16609             as_FloatRegister($src1$$reg),
16610             as_FloatRegister($src2$$reg));
16611   %}
16612   ins_pipe(vdop128);
16613 %}
16614 
16615 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16616 %{
16617   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16618   match(Set dst (SubVI src1 src2));
16619   ins_cost(INSN_COST);
16620   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16621   ins_encode %{
16622     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16623             as_FloatRegister($src1$$reg),
16624             as_FloatRegister($src2$$reg));
16625   %}
16626   ins_pipe(vdop64);
16627 %}
16628 
16629 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16630 %{
16631   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16632   match(Set dst (SubVI src1 src2));
16633   ins_cost(INSN_COST);
16634   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16635   ins_encode %{
16636     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16637             as_FloatRegister($src1$$reg),
16638             as_FloatRegister($src2$$reg));
16639   %}
16640   ins_pipe(vdop128);
16641 %}
16642 
16643 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16644 %{
16645   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16646   match(Set dst (SubVL src1 src2));
16647   ins_cost(INSN_COST);
16648   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16649   ins_encode %{
16650     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16651             as_FloatRegister($src1$$reg),
16652             as_FloatRegister($src2$$reg));
16653   %}
16654   ins_pipe(vdop128);
16655 %}
16656 
16657 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16658 %{
16659   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16660   match(Set dst (SubVF src1 src2));
16661   ins_cost(INSN_COST);
16662   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16663   ins_encode %{
16664     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16665             as_FloatRegister($src1$$reg),
16666             as_FloatRegister($src2$$reg));
16667   %}
16668   ins_pipe(vdop_fp64);
16669 %}
16670 
16671 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16672 %{
16673   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16674   match(Set dst (SubVF src1 src2));
16675   ins_cost(INSN_COST);
16676   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16677   ins_encode %{
16678     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16679             as_FloatRegister($src1$$reg),
16680             as_FloatRegister($src2$$reg));
16681   %}
16682   ins_pipe(vdop_fp128);
16683 %}
16684 
16685 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16686 %{
16687   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16688   match(Set dst (SubVD src1 src2));
16689   ins_cost(INSN_COST);
16690   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16691   ins_encode %{
16692     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16693             as_FloatRegister($src1$$reg),
16694             as_FloatRegister($src2$$reg));
16695   %}
16696   ins_pipe(vdop_fp128);
16697 %}
16698 
16699 // --------------------------------- MUL --------------------------------------
16700 
16701 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16702 %{
16703   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16704             n-&gt;as_Vector()-&gt;length() == 4);
16705   match(Set dst (MulVS src1 src2));
16706   ins_cost(INSN_COST);
16707   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16708   ins_encode %{
16709     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16710             as_FloatRegister($src1$$reg),
16711             as_FloatRegister($src2$$reg));
16712   %}
16713   ins_pipe(vmul64);
16714 %}
16715 
16716 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16717 %{
16718   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16719   match(Set dst (MulVS src1 src2));
16720   ins_cost(INSN_COST);
16721   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16722   ins_encode %{
16723     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16724             as_FloatRegister($src1$$reg),
16725             as_FloatRegister($src2$$reg));
16726   %}
16727   ins_pipe(vmul128);
16728 %}
16729 
16730 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16731 %{
16732   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16733   match(Set dst (MulVI src1 src2));
16734   ins_cost(INSN_COST);
16735   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16736   ins_encode %{
16737     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16738             as_FloatRegister($src1$$reg),
16739             as_FloatRegister($src2$$reg));
16740   %}
16741   ins_pipe(vmul64);
16742 %}
16743 
16744 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16745 %{
16746   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16747   match(Set dst (MulVI src1 src2));
16748   ins_cost(INSN_COST);
16749   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16750   ins_encode %{
16751     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16752             as_FloatRegister($src1$$reg),
16753             as_FloatRegister($src2$$reg));
16754   %}
16755   ins_pipe(vmul128);
16756 %}
16757 
16758 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16759 %{
16760   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16761   match(Set dst (MulVF src1 src2));
16762   ins_cost(INSN_COST);
16763   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16764   ins_encode %{
16765     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16766             as_FloatRegister($src1$$reg),
16767             as_FloatRegister($src2$$reg));
16768   %}
16769   ins_pipe(vmuldiv_fp64);
16770 %}
16771 
16772 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16773 %{
16774   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16775   match(Set dst (MulVF src1 src2));
16776   ins_cost(INSN_COST);
16777   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16778   ins_encode %{
16779     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16780             as_FloatRegister($src1$$reg),
16781             as_FloatRegister($src2$$reg));
16782   %}
16783   ins_pipe(vmuldiv_fp128);
16784 %}
16785 
16786 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16787 %{
16788   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16789   match(Set dst (MulVD src1 src2));
16790   ins_cost(INSN_COST);
16791   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16792   ins_encode %{
16793     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16794             as_FloatRegister($src1$$reg),
16795             as_FloatRegister($src2$$reg));
16796   %}
16797   ins_pipe(vmuldiv_fp128);
16798 %}
16799 
16800 // --------------------------------- MLA --------------------------------------
16801 
16802 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16803 %{
16804   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16805             n-&gt;as_Vector()-&gt;length() == 4);
16806   match(Set dst (AddVS dst (MulVS src1 src2)));
16807   ins_cost(INSN_COST);
16808   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16809   ins_encode %{
16810     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16811             as_FloatRegister($src1$$reg),
16812             as_FloatRegister($src2$$reg));
16813   %}
16814   ins_pipe(vmla64);
16815 %}
16816 
16817 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16818 %{
16819   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16820   match(Set dst (AddVS dst (MulVS src1 src2)));
16821   ins_cost(INSN_COST);
16822   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16823   ins_encode %{
16824     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16825             as_FloatRegister($src1$$reg),
16826             as_FloatRegister($src2$$reg));
16827   %}
16828   ins_pipe(vmla128);
16829 %}
16830 
16831 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16832 %{
16833   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16834   match(Set dst (AddVI dst (MulVI src1 src2)));
16835   ins_cost(INSN_COST);
16836   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16837   ins_encode %{
16838     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16839             as_FloatRegister($src1$$reg),
16840             as_FloatRegister($src2$$reg));
16841   %}
16842   ins_pipe(vmla64);
16843 %}
16844 
16845 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16846 %{
16847   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16848   match(Set dst (AddVI dst (MulVI src1 src2)));
16849   ins_cost(INSN_COST);
16850   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16851   ins_encode %{
16852     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16853             as_FloatRegister($src1$$reg),
16854             as_FloatRegister($src2$$reg));
16855   %}
16856   ins_pipe(vmla128);
16857 %}
16858 
16859 // dst + src1 * src2
16860 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16861   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16862   match(Set dst (FmaVF  dst (Binary src1 src2)));
16863   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16864   ins_cost(INSN_COST);
16865   ins_encode %{
16866     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16867             as_FloatRegister($src1$$reg),
16868             as_FloatRegister($src2$$reg));
16869   %}
16870   ins_pipe(vmuldiv_fp64);
16871 %}
16872 
16873 // dst + src1 * src2
16874 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16875   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16876   match(Set dst (FmaVF  dst (Binary src1 src2)));
16877   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16878   ins_cost(INSN_COST);
16879   ins_encode %{
16880     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16881             as_FloatRegister($src1$$reg),
16882             as_FloatRegister($src2$$reg));
16883   %}
16884   ins_pipe(vmuldiv_fp128);
16885 %}
16886 
16887 // dst + src1 * src2
16888 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16889   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16890   match(Set dst (FmaVD  dst (Binary src1 src2)));
16891   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16892   ins_cost(INSN_COST);
16893   ins_encode %{
16894     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16895             as_FloatRegister($src1$$reg),
16896             as_FloatRegister($src2$$reg));
16897   %}
16898   ins_pipe(vmuldiv_fp128);
16899 %}
16900 
16901 // --------------------------------- MLS --------------------------------------
16902 
16903 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16904 %{
16905   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16906             n-&gt;as_Vector()-&gt;length() == 4);
16907   match(Set dst (SubVS dst (MulVS src1 src2)));
16908   ins_cost(INSN_COST);
16909   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16910   ins_encode %{
16911     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16912             as_FloatRegister($src1$$reg),
16913             as_FloatRegister($src2$$reg));
16914   %}
16915   ins_pipe(vmla64);
16916 %}
16917 
16918 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16919 %{
16920   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16921   match(Set dst (SubVS dst (MulVS src1 src2)));
16922   ins_cost(INSN_COST);
16923   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16924   ins_encode %{
16925     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16926             as_FloatRegister($src1$$reg),
16927             as_FloatRegister($src2$$reg));
16928   %}
16929   ins_pipe(vmla128);
16930 %}
16931 
16932 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16933 %{
16934   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16935   match(Set dst (SubVI dst (MulVI src1 src2)));
16936   ins_cost(INSN_COST);
16937   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16938   ins_encode %{
16939     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16940             as_FloatRegister($src1$$reg),
16941             as_FloatRegister($src2$$reg));
16942   %}
16943   ins_pipe(vmla64);
16944 %}
16945 
16946 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16947 %{
16948   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16949   match(Set dst (SubVI dst (MulVI src1 src2)));
16950   ins_cost(INSN_COST);
16951   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16952   ins_encode %{
16953     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16954             as_FloatRegister($src1$$reg),
16955             as_FloatRegister($src2$$reg));
16956   %}
16957   ins_pipe(vmla128);
16958 %}
16959 
16960 // dst - src1 * src2
16961 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16962   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16963   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16964   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16965   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16966   ins_cost(INSN_COST);
16967   ins_encode %{
16968     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16969             as_FloatRegister($src1$$reg),
16970             as_FloatRegister($src2$$reg));
16971   %}
16972   ins_pipe(vmuldiv_fp64);
16973 %}
16974 
16975 // dst - src1 * src2
16976 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16977   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16978   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16979   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16980   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16981   ins_cost(INSN_COST);
16982   ins_encode %{
16983     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16984             as_FloatRegister($src1$$reg),
16985             as_FloatRegister($src2$$reg));
16986   %}
16987   ins_pipe(vmuldiv_fp128);
16988 %}
16989 
16990 // dst - src1 * src2
16991 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16992   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16993   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16994   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16995   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16996   ins_cost(INSN_COST);
16997   ins_encode %{
16998     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16999             as_FloatRegister($src1$$reg),
17000             as_FloatRegister($src2$$reg));
17001   %}
17002   ins_pipe(vmuldiv_fp128);
17003 %}
17004 
17005 // --------------- Vector Multiply-Add Shorts into Integer --------------------
17006 
17007 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
17008   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
17009   match(Set dst (MulAddVS2VI src1 src2));
17010   ins_cost(INSN_COST);
<a name="122" id="anc122"></a><span class="line-modified">17011   effect(TEMP tmp);</span>
17012   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
17013             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
17014             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17015   ins_encode %{
17016     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17017               as_FloatRegister($src1$$reg),
17018               as_FloatRegister($src2$$reg));
17019     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17020               as_FloatRegister($src1$$reg),
17021               as_FloatRegister($src2$$reg));
17022     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17023              as_FloatRegister($tmp$$reg),
17024              as_FloatRegister($dst$$reg));
17025   %}
17026   ins_pipe(vmuldiv_fp128);
17027 %}
17028 
17029 // --------------------------------- DIV --------------------------------------
17030 
17031 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
17032 %{
17033   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17034   match(Set dst (DivVF src1 src2));
17035   ins_cost(INSN_COST);
17036   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17037   ins_encode %{
17038     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17039             as_FloatRegister($src1$$reg),
17040             as_FloatRegister($src2$$reg));
17041   %}
17042   ins_pipe(vmuldiv_fp64);
17043 %}
17044 
17045 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17046 %{
17047   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17048   match(Set dst (DivVF src1 src2));
17049   ins_cost(INSN_COST);
17050   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17051   ins_encode %{
17052     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17053             as_FloatRegister($src1$$reg),
17054             as_FloatRegister($src2$$reg));
17055   %}
17056   ins_pipe(vmuldiv_fp128);
17057 %}
17058 
17059 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17060 %{
17061   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17062   match(Set dst (DivVD src1 src2));
17063   ins_cost(INSN_COST);
17064   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17065   ins_encode %{
17066     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17067             as_FloatRegister($src1$$reg),
17068             as_FloatRegister($src2$$reg));
17069   %}
17070   ins_pipe(vmuldiv_fp128);
17071 %}
17072 
17073 // --------------------------------- SQRT -------------------------------------
17074 
17075 instruct vsqrt2D(vecX dst, vecX src)
17076 %{
17077   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17078   match(Set dst (SqrtVD src));
17079   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17080   ins_encode %{
17081     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17082              as_FloatRegister($src$$reg));
17083   %}
17084   ins_pipe(vsqrt_fp128);
17085 %}
17086 
17087 // --------------------------------- ABS --------------------------------------
17088 
17089 instruct vabs2F(vecD dst, vecD src)
17090 %{
17091   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17092   match(Set dst (AbsVF src));
17093   ins_cost(INSN_COST * 3);
17094   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17095   ins_encode %{
17096     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17097             as_FloatRegister($src$$reg));
17098   %}
17099   ins_pipe(vunop_fp64);
17100 %}
17101 
17102 instruct vabs4F(vecX dst, vecX src)
17103 %{
17104   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17105   match(Set dst (AbsVF src));
17106   ins_cost(INSN_COST * 3);
17107   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17108   ins_encode %{
17109     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17110             as_FloatRegister($src$$reg));
17111   %}
17112   ins_pipe(vunop_fp128);
17113 %}
17114 
17115 instruct vabs2D(vecX dst, vecX src)
17116 %{
17117   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17118   match(Set dst (AbsVD src));
17119   ins_cost(INSN_COST * 3);
17120   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17121   ins_encode %{
17122     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17123             as_FloatRegister($src$$reg));
17124   %}
17125   ins_pipe(vunop_fp128);
17126 %}
17127 
17128 // --------------------------------- NEG --------------------------------------
17129 
17130 instruct vneg2F(vecD dst, vecD src)
17131 %{
17132   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17133   match(Set dst (NegVF src));
17134   ins_cost(INSN_COST * 3);
17135   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17136   ins_encode %{
17137     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17138             as_FloatRegister($src$$reg));
17139   %}
17140   ins_pipe(vunop_fp64);
17141 %}
17142 
17143 instruct vneg4F(vecX dst, vecX src)
17144 %{
17145   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17146   match(Set dst (NegVF src));
17147   ins_cost(INSN_COST * 3);
17148   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17149   ins_encode %{
17150     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17151             as_FloatRegister($src$$reg));
17152   %}
17153   ins_pipe(vunop_fp128);
17154 %}
17155 
17156 instruct vneg2D(vecX dst, vecX src)
17157 %{
17158   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17159   match(Set dst (NegVD src));
17160   ins_cost(INSN_COST * 3);
17161   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17162   ins_encode %{
17163     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17164             as_FloatRegister($src$$reg));
17165   %}
17166   ins_pipe(vunop_fp128);
17167 %}
17168 
17169 // --------------------------------- AND --------------------------------------
17170 
17171 instruct vand8B(vecD dst, vecD src1, vecD src2)
17172 %{
17173   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17174             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17175   match(Set dst (AndV src1 src2));
17176   ins_cost(INSN_COST);
17177   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17178   ins_encode %{
17179     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17180             as_FloatRegister($src1$$reg),
17181             as_FloatRegister($src2$$reg));
17182   %}
17183   ins_pipe(vlogical64);
17184 %}
17185 
17186 instruct vand16B(vecX dst, vecX src1, vecX src2)
17187 %{
17188   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17189   match(Set dst (AndV src1 src2));
17190   ins_cost(INSN_COST);
17191   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17192   ins_encode %{
17193     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17194             as_FloatRegister($src1$$reg),
17195             as_FloatRegister($src2$$reg));
17196   %}
17197   ins_pipe(vlogical128);
17198 %}
17199 
17200 // --------------------------------- OR ---------------------------------------
17201 
17202 instruct vor8B(vecD dst, vecD src1, vecD src2)
17203 %{
17204   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17205             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17206   match(Set dst (OrV src1 src2));
17207   ins_cost(INSN_COST);
17208   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17209   ins_encode %{
17210     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17211             as_FloatRegister($src1$$reg),
17212             as_FloatRegister($src2$$reg));
17213   %}
17214   ins_pipe(vlogical64);
17215 %}
17216 
17217 instruct vor16B(vecX dst, vecX src1, vecX src2)
17218 %{
17219   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17220   match(Set dst (OrV src1 src2));
17221   ins_cost(INSN_COST);
17222   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17223   ins_encode %{
17224     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17225             as_FloatRegister($src1$$reg),
17226             as_FloatRegister($src2$$reg));
17227   %}
17228   ins_pipe(vlogical128);
17229 %}
17230 
17231 // --------------------------------- XOR --------------------------------------
17232 
17233 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17234 %{
17235   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17236             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17237   match(Set dst (XorV src1 src2));
17238   ins_cost(INSN_COST);
17239   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17240   ins_encode %{
17241     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17242             as_FloatRegister($src1$$reg),
17243             as_FloatRegister($src2$$reg));
17244   %}
17245   ins_pipe(vlogical64);
17246 %}
17247 
17248 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17249 %{
17250   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17251   match(Set dst (XorV src1 src2));
17252   ins_cost(INSN_COST);
17253   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17254   ins_encode %{
17255     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17256             as_FloatRegister($src1$$reg),
17257             as_FloatRegister($src2$$reg));
17258   %}
17259   ins_pipe(vlogical128);
17260 %}
17261 
17262 // ------------------------------ Shift ---------------------------------------
17263 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17264   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17265   match(Set dst (LShiftCntV cnt));
17266   match(Set dst (RShiftCntV cnt));
17267   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17268   ins_encode %{
17269     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17270   %}
17271   ins_pipe(vdup_reg_reg64);
17272 %}
17273 
17274 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17275   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17276   match(Set dst (LShiftCntV cnt));
17277   match(Set dst (RShiftCntV cnt));
17278   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17279   ins_encode %{
17280     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17281   %}
17282   ins_pipe(vdup_reg_reg128);
17283 %}
17284 
17285 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17286   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17287             n-&gt;as_Vector()-&gt;length() == 8);
17288   match(Set dst (LShiftVB src shift));
17289   ins_cost(INSN_COST);
17290   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17291   ins_encode %{
17292     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17293             as_FloatRegister($src$$reg),
17294             as_FloatRegister($shift$$reg));
17295   %}
17296   ins_pipe(vshift64);
17297 %}
17298 
17299 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17300   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17301   match(Set dst (LShiftVB src shift));
17302   ins_cost(INSN_COST);
17303   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17304   ins_encode %{
17305     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17306             as_FloatRegister($src$$reg),
17307             as_FloatRegister($shift$$reg));
17308   %}
17309   ins_pipe(vshift128);
17310 %}
17311 
17312 // Right shifts with vector shift count on aarch64 SIMD are implemented
17313 // as left shift by negative shift count.
17314 // There are two cases for vector shift count.
17315 //
17316 // Case 1: The vector shift count is from replication.
17317 //        |            |
17318 //    LoadVector  RShiftCntV
17319 //        |       /
17320 //     RShiftVI
17321 // Note: In inner loop, multiple neg instructions are used, which can be
17322 // moved to outer loop and merge into one neg instruction.
17323 //
17324 // Case 2: The vector shift count is from loading.
17325 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17326 // panama/vectorIntrinsics(JEP 338: Vector API).
17327 //        |            |
17328 //    LoadVector  LoadVector
17329 //        |       /
17330 //     RShiftVI
17331 //
17332 
17333 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17334   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17335             n-&gt;as_Vector()-&gt;length() == 8);
17336   match(Set dst (RShiftVB src shift));
17337   ins_cost(INSN_COST);
17338   effect(TEMP tmp);
17339   format %{ &quot;negr  $tmp,$shift\t&quot;
17340             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17341   ins_encode %{
17342     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17343             as_FloatRegister($shift$$reg));
17344     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17345             as_FloatRegister($src$$reg),
17346             as_FloatRegister($tmp$$reg));
17347   %}
17348   ins_pipe(vshift64);
17349 %}
17350 
17351 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17352   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17353   match(Set dst (RShiftVB src shift));
17354   ins_cost(INSN_COST);
17355   effect(TEMP tmp);
17356   format %{ &quot;negr  $tmp,$shift\t&quot;
17357             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17358   ins_encode %{
17359     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17360             as_FloatRegister($shift$$reg));
17361     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17362             as_FloatRegister($src$$reg),
17363             as_FloatRegister($tmp$$reg));
17364   %}
17365   ins_pipe(vshift128);
17366 %}
17367 
17368 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17369   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17370             n-&gt;as_Vector()-&gt;length() == 8);
17371   match(Set dst (URShiftVB src shift));
17372   ins_cost(INSN_COST);
17373   effect(TEMP tmp);
17374   format %{ &quot;negr  $tmp,$shift\t&quot;
17375             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17376   ins_encode %{
17377     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17378             as_FloatRegister($shift$$reg));
17379     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17380             as_FloatRegister($src$$reg),
17381             as_FloatRegister($tmp$$reg));
17382   %}
17383   ins_pipe(vshift64);
17384 %}
17385 
17386 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17387   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17388   match(Set dst (URShiftVB src shift));
17389   ins_cost(INSN_COST);
17390   effect(TEMP tmp);
17391   format %{ &quot;negr  $tmp,$shift\t&quot;
17392             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17393   ins_encode %{
17394     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17395             as_FloatRegister($shift$$reg));
17396     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17397             as_FloatRegister($src$$reg),
17398             as_FloatRegister($tmp$$reg));
17399   %}
17400   ins_pipe(vshift128);
17401 %}
17402 
17403 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17404   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17405             n-&gt;as_Vector()-&gt;length() == 8);
17406   match(Set dst (LShiftVB src (LShiftCntV shift)));
17407   ins_cost(INSN_COST);
17408   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17409   ins_encode %{
17410     int sh = (int)$shift$$constant;
17411     if (sh &gt;= 8) {
17412       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17413              as_FloatRegister($src$$reg),
17414              as_FloatRegister($src$$reg));
17415     } else {
17416       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17417              as_FloatRegister($src$$reg), sh);
17418     }
17419   %}
17420   ins_pipe(vshift64_imm);
17421 %}
17422 
17423 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17424   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17425   match(Set dst (LShiftVB src (LShiftCntV shift)));
17426   ins_cost(INSN_COST);
17427   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17428   ins_encode %{
17429     int sh = (int)$shift$$constant;
17430     if (sh &gt;= 8) {
17431       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17432              as_FloatRegister($src$$reg),
17433              as_FloatRegister($src$$reg));
17434     } else {
17435       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17436              as_FloatRegister($src$$reg), sh);
17437     }
17438   %}
17439   ins_pipe(vshift128_imm);
17440 %}
17441 
17442 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17443   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17444             n-&gt;as_Vector()-&gt;length() == 8);
17445   match(Set dst (RShiftVB src (RShiftCntV shift)));
17446   ins_cost(INSN_COST);
17447   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17448   ins_encode %{
17449     int sh = (int)$shift$$constant;
17450     if (sh &gt;= 8) sh = 7;
17451     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17452            as_FloatRegister($src$$reg), sh);
17453   %}
17454   ins_pipe(vshift64_imm);
17455 %}
17456 
17457 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17458   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17459   match(Set dst (RShiftVB src (RShiftCntV shift)));
17460   ins_cost(INSN_COST);
17461   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17462   ins_encode %{
17463     int sh = (int)$shift$$constant;
17464     if (sh &gt;= 8) sh = 7;
17465     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17466            as_FloatRegister($src$$reg), sh);
17467   %}
17468   ins_pipe(vshift128_imm);
17469 %}
17470 
17471 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17472   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17473             n-&gt;as_Vector()-&gt;length() == 8);
17474   match(Set dst (URShiftVB src (RShiftCntV shift)));
17475   ins_cost(INSN_COST);
17476   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17477   ins_encode %{
17478     int sh = (int)$shift$$constant;
17479     if (sh &gt;= 8) {
17480       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17481              as_FloatRegister($src$$reg),
17482              as_FloatRegister($src$$reg));
17483     } else {
17484       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17485              as_FloatRegister($src$$reg), sh);
17486     }
17487   %}
17488   ins_pipe(vshift64_imm);
17489 %}
17490 
17491 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17492   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17493   match(Set dst (URShiftVB src (RShiftCntV shift)));
17494   ins_cost(INSN_COST);
17495   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17496   ins_encode %{
17497     int sh = (int)$shift$$constant;
17498     if (sh &gt;= 8) {
17499       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17500              as_FloatRegister($src$$reg),
17501              as_FloatRegister($src$$reg));
17502     } else {
17503       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17504              as_FloatRegister($src$$reg), sh);
17505     }
17506   %}
17507   ins_pipe(vshift128_imm);
17508 %}
17509 
17510 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17511   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17512             n-&gt;as_Vector()-&gt;length() == 4);
17513   match(Set dst (LShiftVS src shift));
17514   ins_cost(INSN_COST);
17515   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17516   ins_encode %{
17517     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17518             as_FloatRegister($src$$reg),
17519             as_FloatRegister($shift$$reg));
17520   %}
17521   ins_pipe(vshift64);
17522 %}
17523 
17524 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17525   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17526   match(Set dst (LShiftVS src shift));
17527   ins_cost(INSN_COST);
17528   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17529   ins_encode %{
17530     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17531             as_FloatRegister($src$$reg),
17532             as_FloatRegister($shift$$reg));
17533   %}
17534   ins_pipe(vshift128);
17535 %}
17536 
17537 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17538   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17539             n-&gt;as_Vector()-&gt;length() == 4);
17540   match(Set dst (RShiftVS src shift));
17541   ins_cost(INSN_COST);
17542   effect(TEMP tmp);
17543   format %{ &quot;negr  $tmp,$shift\t&quot;
17544             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17545   ins_encode %{
17546     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17547             as_FloatRegister($shift$$reg));
17548     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17549             as_FloatRegister($src$$reg),
17550             as_FloatRegister($tmp$$reg));
17551   %}
17552   ins_pipe(vshift64);
17553 %}
17554 
17555 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17556   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17557   match(Set dst (RShiftVS src shift));
17558   ins_cost(INSN_COST);
17559   effect(TEMP tmp);
17560   format %{ &quot;negr  $tmp,$shift\t&quot;
17561             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17562   ins_encode %{
17563     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17564             as_FloatRegister($shift$$reg));
17565     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17566             as_FloatRegister($src$$reg),
17567             as_FloatRegister($tmp$$reg));
17568   %}
17569   ins_pipe(vshift128);
17570 %}
17571 
17572 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17573   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17574             n-&gt;as_Vector()-&gt;length() == 4);
17575   match(Set dst (URShiftVS src shift));
17576   ins_cost(INSN_COST);
17577   effect(TEMP tmp);
17578   format %{ &quot;negr  $tmp,$shift\t&quot;
17579             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17580   ins_encode %{
17581     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17582             as_FloatRegister($shift$$reg));
17583     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17584             as_FloatRegister($src$$reg),
17585             as_FloatRegister($tmp$$reg));
17586   %}
17587   ins_pipe(vshift64);
17588 %}
17589 
17590 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17591   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17592   match(Set dst (URShiftVS src shift));
17593   ins_cost(INSN_COST);
17594   effect(TEMP tmp);
17595   format %{ &quot;negr  $tmp,$shift\t&quot;
17596             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17597   ins_encode %{
17598     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17599             as_FloatRegister($shift$$reg));
17600     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17601             as_FloatRegister($src$$reg),
17602             as_FloatRegister($tmp$$reg));
17603   %}
17604   ins_pipe(vshift128);
17605 %}
17606 
17607 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17608   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17609             n-&gt;as_Vector()-&gt;length() == 4);
17610   match(Set dst (LShiftVS src (LShiftCntV shift)));
17611   ins_cost(INSN_COST);
17612   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17613   ins_encode %{
17614     int sh = (int)$shift$$constant;
17615     if (sh &gt;= 16) {
17616       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17617              as_FloatRegister($src$$reg),
17618              as_FloatRegister($src$$reg));
17619     } else {
17620       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17621              as_FloatRegister($src$$reg), sh);
17622     }
17623   %}
17624   ins_pipe(vshift64_imm);
17625 %}
17626 
17627 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17628   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17629   match(Set dst (LShiftVS src (LShiftCntV shift)));
17630   ins_cost(INSN_COST);
17631   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17632   ins_encode %{
17633     int sh = (int)$shift$$constant;
17634     if (sh &gt;= 16) {
17635       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17636              as_FloatRegister($src$$reg),
17637              as_FloatRegister($src$$reg));
17638     } else {
17639       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17640              as_FloatRegister($src$$reg), sh);
17641     }
17642   %}
17643   ins_pipe(vshift128_imm);
17644 %}
17645 
17646 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17647   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17648             n-&gt;as_Vector()-&gt;length() == 4);
17649   match(Set dst (RShiftVS src (LShiftCntV shift)));
17650   ins_cost(INSN_COST);
17651   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17652   ins_encode %{
17653     int sh = (int)$shift$$constant;
17654     if (sh &gt;= 16) sh = 15;
17655     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17656            as_FloatRegister($src$$reg), sh);
17657   %}
17658   ins_pipe(vshift64_imm);
17659 %}
17660 
17661 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17662   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17663   match(Set dst (RShiftVS src (LShiftCntV shift)));
17664   ins_cost(INSN_COST);
17665   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17666   ins_encode %{
17667     int sh = (int)$shift$$constant;
17668     if (sh &gt;= 16) sh = 15;
17669     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17670            as_FloatRegister($src$$reg), sh);
17671   %}
17672   ins_pipe(vshift128_imm);
17673 %}
17674 
17675 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17676   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17677             n-&gt;as_Vector()-&gt;length() == 4);
17678   match(Set dst (URShiftVS src (RShiftCntV shift)));
17679   ins_cost(INSN_COST);
17680   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17681   ins_encode %{
17682     int sh = (int)$shift$$constant;
17683     if (sh &gt;= 16) {
17684       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17685              as_FloatRegister($src$$reg),
17686              as_FloatRegister($src$$reg));
17687     } else {
17688       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17689              as_FloatRegister($src$$reg), sh);
17690     }
17691   %}
17692   ins_pipe(vshift64_imm);
17693 %}
17694 
17695 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17696   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17697   match(Set dst (URShiftVS src (RShiftCntV shift)));
17698   ins_cost(INSN_COST);
17699   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17700   ins_encode %{
17701     int sh = (int)$shift$$constant;
17702     if (sh &gt;= 16) {
17703       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17704              as_FloatRegister($src$$reg),
17705              as_FloatRegister($src$$reg));
17706     } else {
17707       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17708              as_FloatRegister($src$$reg), sh);
17709     }
17710   %}
17711   ins_pipe(vshift128_imm);
17712 %}
17713 
17714 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17715   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17716   match(Set dst (LShiftVI src shift));
17717   ins_cost(INSN_COST);
17718   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17719   ins_encode %{
17720     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17721             as_FloatRegister($src$$reg),
17722             as_FloatRegister($shift$$reg));
17723   %}
17724   ins_pipe(vshift64);
17725 %}
17726 
17727 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17728   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17729   match(Set dst (LShiftVI src shift));
17730   ins_cost(INSN_COST);
17731   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17732   ins_encode %{
17733     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17734             as_FloatRegister($src$$reg),
17735             as_FloatRegister($shift$$reg));
17736   %}
17737   ins_pipe(vshift128);
17738 %}
17739 
17740 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17741   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17742   match(Set dst (RShiftVI src shift));
17743   ins_cost(INSN_COST);
17744   effect(TEMP tmp);
17745   format %{ &quot;negr  $tmp,$shift\t&quot;
17746             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17747   ins_encode %{
17748     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17749             as_FloatRegister($shift$$reg));
17750     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17751             as_FloatRegister($src$$reg),
17752             as_FloatRegister($tmp$$reg));
17753   %}
17754   ins_pipe(vshift64);
17755 %}
17756 
17757 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17758   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17759   match(Set dst (RShiftVI src shift));
17760   ins_cost(INSN_COST);
17761   effect(TEMP tmp);
17762   format %{ &quot;negr  $tmp,$shift\t&quot;
17763             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17764   ins_encode %{
17765     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17766             as_FloatRegister($shift$$reg));
17767     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17768             as_FloatRegister($src$$reg),
17769             as_FloatRegister($tmp$$reg));
17770   %}
17771   ins_pipe(vshift128);
17772 %}
17773 
17774 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17775   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17776   match(Set dst (URShiftVI src shift));
17777   ins_cost(INSN_COST);
17778   effect(TEMP tmp);
17779   format %{ &quot;negr  $tmp,$shift\t&quot;
17780             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17781   ins_encode %{
17782     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17783             as_FloatRegister($shift$$reg));
17784     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17785             as_FloatRegister($src$$reg),
17786             as_FloatRegister($tmp$$reg));
17787   %}
17788   ins_pipe(vshift64);
17789 %}
17790 
17791 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17792   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17793   match(Set dst (URShiftVI src shift));
17794   ins_cost(INSN_COST);
17795   effect(TEMP tmp);
17796   format %{ &quot;negr  $tmp,$shift\t&quot;
17797             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17798   ins_encode %{
17799     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17800             as_FloatRegister($shift$$reg));
17801     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17802             as_FloatRegister($src$$reg),
17803             as_FloatRegister($tmp$$reg));
17804   %}
17805   ins_pipe(vshift128);
17806 %}
17807 
17808 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17809   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17810   match(Set dst (LShiftVI src (LShiftCntV shift)));
17811   ins_cost(INSN_COST);
17812   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17813   ins_encode %{
17814     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17815            as_FloatRegister($src$$reg),
17816            (int)$shift$$constant);
17817   %}
17818   ins_pipe(vshift64_imm);
17819 %}
17820 
17821 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17822   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17823   match(Set dst (LShiftVI src (LShiftCntV shift)));
17824   ins_cost(INSN_COST);
17825   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17826   ins_encode %{
17827     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17828            as_FloatRegister($src$$reg),
17829            (int)$shift$$constant);
17830   %}
17831   ins_pipe(vshift128_imm);
17832 %}
17833 
17834 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17835   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17836   match(Set dst (RShiftVI src (RShiftCntV shift)));
17837   ins_cost(INSN_COST);
17838   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17839   ins_encode %{
17840     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17841             as_FloatRegister($src$$reg),
17842             (int)$shift$$constant);
17843   %}
17844   ins_pipe(vshift64_imm);
17845 %}
17846 
17847 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17848   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17849   match(Set dst (RShiftVI src (RShiftCntV shift)));
17850   ins_cost(INSN_COST);
17851   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17852   ins_encode %{
17853     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17854             as_FloatRegister($src$$reg),
17855             (int)$shift$$constant);
17856   %}
17857   ins_pipe(vshift128_imm);
17858 %}
17859 
17860 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17861   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17862   match(Set dst (URShiftVI src (RShiftCntV shift)));
17863   ins_cost(INSN_COST);
17864   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17865   ins_encode %{
17866     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17867             as_FloatRegister($src$$reg),
17868             (int)$shift$$constant);
17869   %}
17870   ins_pipe(vshift64_imm);
17871 %}
17872 
17873 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17874   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17875   match(Set dst (URShiftVI src (RShiftCntV shift)));
17876   ins_cost(INSN_COST);
17877   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17878   ins_encode %{
17879     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17880             as_FloatRegister($src$$reg),
17881             (int)$shift$$constant);
17882   %}
17883   ins_pipe(vshift128_imm);
17884 %}
17885 
17886 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17887   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17888   match(Set dst (LShiftVL src shift));
17889   ins_cost(INSN_COST);
17890   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17891   ins_encode %{
17892     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17893             as_FloatRegister($src$$reg),
17894             as_FloatRegister($shift$$reg));
17895   %}
17896   ins_pipe(vshift128);
17897 %}
17898 
17899 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17900   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17901   match(Set dst (RShiftVL src shift));
17902   ins_cost(INSN_COST);
17903   effect(TEMP tmp);
17904   format %{ &quot;negr  $tmp,$shift\t&quot;
17905             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17906   ins_encode %{
17907     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17908             as_FloatRegister($shift$$reg));
17909     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17910             as_FloatRegister($src$$reg),
17911             as_FloatRegister($tmp$$reg));
17912   %}
17913   ins_pipe(vshift128);
17914 %}
17915 
17916 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17917   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17918   match(Set dst (URShiftVL src shift));
17919   ins_cost(INSN_COST);
17920   effect(TEMP tmp);
17921   format %{ &quot;negr  $tmp,$shift\t&quot;
17922             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17923   ins_encode %{
17924     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17925             as_FloatRegister($shift$$reg));
17926     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17927             as_FloatRegister($src$$reg),
17928             as_FloatRegister($tmp$$reg));
17929   %}
17930   ins_pipe(vshift128);
17931 %}
17932 
17933 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17934   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17935   match(Set dst (LShiftVL src (LShiftCntV shift)));
17936   ins_cost(INSN_COST);
17937   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17938   ins_encode %{
17939     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17940            as_FloatRegister($src$$reg),
17941            (int)$shift$$constant);
17942   %}
17943   ins_pipe(vshift128_imm);
17944 %}
17945 
17946 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17947   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17948   match(Set dst (RShiftVL src (RShiftCntV shift)));
17949   ins_cost(INSN_COST);
17950   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17951   ins_encode %{
17952     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17953             as_FloatRegister($src$$reg),
17954             (int)$shift$$constant);
17955   %}
17956   ins_pipe(vshift128_imm);
17957 %}
17958 
17959 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17960   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17961   match(Set dst (URShiftVL src (RShiftCntV shift)));
17962   ins_cost(INSN_COST);
17963   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17964   ins_encode %{
17965     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17966             as_FloatRegister($src$$reg),
17967             (int)$shift$$constant);
17968   %}
17969   ins_pipe(vshift128_imm);
17970 %}
17971 
17972 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17973 %{
17974   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17975   match(Set dst (MaxV src1 src2));
17976   ins_cost(INSN_COST);
17977   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17978   ins_encode %{
17979     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17980             as_FloatRegister($src1$$reg),
17981             as_FloatRegister($src2$$reg));
17982   %}
17983   ins_pipe(vdop_fp64);
17984 %}
17985 
17986 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17987 %{
17988   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17989   match(Set dst (MaxV src1 src2));
17990   ins_cost(INSN_COST);
17991   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17992   ins_encode %{
17993     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17994             as_FloatRegister($src1$$reg),
17995             as_FloatRegister($src2$$reg));
17996   %}
17997   ins_pipe(vdop_fp128);
17998 %}
17999 
18000 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18001 %{
18002   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18003   match(Set dst (MaxV src1 src2));
18004   ins_cost(INSN_COST);
18005   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18006   ins_encode %{
18007     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18008             as_FloatRegister($src1$$reg),
18009             as_FloatRegister($src2$$reg));
18010   %}
18011   ins_pipe(vdop_fp128);
18012 %}
18013 
18014 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18015 %{
18016   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18017   match(Set dst (MinV src1 src2));
18018   ins_cost(INSN_COST);
18019   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18020   ins_encode %{
18021     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18022             as_FloatRegister($src1$$reg),
18023             as_FloatRegister($src2$$reg));
18024   %}
18025   ins_pipe(vdop_fp64);
18026 %}
18027 
18028 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18029 %{
18030   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18031   match(Set dst (MinV src1 src2));
18032   ins_cost(INSN_COST);
18033   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18034   ins_encode %{
18035     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18036             as_FloatRegister($src1$$reg),
18037             as_FloatRegister($src2$$reg));
18038   %}
18039   ins_pipe(vdop_fp128);
18040 %}
18041 
18042 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18043 %{
18044   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18045   match(Set dst (MinV src1 src2));
18046   ins_cost(INSN_COST);
18047   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18048   ins_encode %{
18049     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18050             as_FloatRegister($src1$$reg),
18051             as_FloatRegister($src2$$reg));
18052   %}
18053   ins_pipe(vdop_fp128);
18054 %}
18055 
18056 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18057   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18058   match(Set dst (RoundDoubleModeV src rmode));
18059   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18060   ins_encode %{
18061     switch ($rmode$$constant) {
18062       case RoundDoubleModeNode::rmode_rint:
18063         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18064                   as_FloatRegister($src$$reg));
18065         break;
18066       case RoundDoubleModeNode::rmode_floor:
18067         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18068                   as_FloatRegister($src$$reg));
18069         break;
18070       case RoundDoubleModeNode::rmode_ceil:
18071         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18072                   as_FloatRegister($src$$reg));
18073         break;
18074     }
18075   %}
18076   ins_pipe(vdop_fp128);
18077 %}
18078 
18079 //----------PEEPHOLE RULES-----------------------------------------------------
18080 // These must follow all instruction definitions as they use the names
18081 // defined in the instructions definitions.
18082 //
18083 // peepmatch ( root_instr_name [preceding_instruction]* );
18084 //
18085 // peepconstraint %{
18086 // (instruction_number.operand_name relational_op instruction_number.operand_name
18087 //  [, ...] );
18088 // // instruction numbers are zero-based using left to right order in peepmatch
18089 //
18090 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18091 // // provide an instruction_number.operand_name for each operand that appears
18092 // // in the replacement instruction&#39;s match rule
18093 //
18094 // ---------VM FLAGS---------------------------------------------------------
18095 //
18096 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18097 //
18098 // Each peephole rule is given an identifying number starting with zero and
18099 // increasing by one in the order seen by the parser.  An individual peephole
18100 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18101 // on the command-line.
18102 //
18103 // ---------CURRENT LIMITATIONS----------------------------------------------
18104 //
18105 // Only match adjacent instructions in same basic block
18106 // Only equality constraints
18107 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18108 // Only one replacement instruction
18109 //
18110 // ---------EXAMPLE----------------------------------------------------------
18111 //
18112 // // pertinent parts of existing instructions in architecture description
18113 // instruct movI(iRegINoSp dst, iRegI src)
18114 // %{
18115 //   match(Set dst (CopyI src));
18116 // %}
18117 //
18118 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18119 // %{
18120 //   match(Set dst (AddI dst src));
18121 //   effect(KILL cr);
18122 // %}
18123 //
18124 // // Change (inc mov) to lea
18125 // peephole %{
18126 //   // increment preceeded by register-register move
18127 //   peepmatch ( incI_iReg movI );
18128 //   // require that the destination register of the increment
18129 //   // match the destination register of the move
18130 //   peepconstraint ( 0.dst == 1.dst );
18131 //   // construct a replacement instruction that sets
18132 //   // the destination to ( move&#39;s source register + one )
18133 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18134 // %}
18135 //
18136 
18137 // Implementation no longer uses movX instructions since
18138 // machine-independent system no longer uses CopyX nodes.
18139 //
18140 // peephole
18141 // %{
18142 //   peepmatch (incI_iReg movI);
18143 //   peepconstraint (0.dst == 1.dst);
18144 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18145 // %}
18146 
18147 // peephole
18148 // %{
18149 //   peepmatch (decI_iReg movI);
18150 //   peepconstraint (0.dst == 1.dst);
18151 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18152 // %}
18153 
18154 // peephole
18155 // %{
18156 //   peepmatch (addI_iReg_imm movI);
18157 //   peepconstraint (0.dst == 1.dst);
18158 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18159 // %}
18160 
18161 // peephole
18162 // %{
18163 //   peepmatch (incL_iReg movL);
18164 //   peepconstraint (0.dst == 1.dst);
18165 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18166 // %}
18167 
18168 // peephole
18169 // %{
18170 //   peepmatch (decL_iReg movL);
18171 //   peepconstraint (0.dst == 1.dst);
18172 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18173 // %}
18174 
18175 // peephole
18176 // %{
18177 //   peepmatch (addL_iReg_imm movL);
18178 //   peepconstraint (0.dst == 1.dst);
18179 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18180 // %}
18181 
18182 // peephole
18183 // %{
18184 //   peepmatch (addP_iReg_imm movP);
18185 //   peepconstraint (0.dst == 1.dst);
18186 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18187 // %}
18188 
18189 // // Change load of spilled value to only a spill
18190 // instruct storeI(memory mem, iRegI src)
18191 // %{
18192 //   match(Set mem (StoreI mem src));
18193 // %}
18194 //
18195 // instruct loadI(iRegINoSp dst, memory mem)
18196 // %{
18197 //   match(Set dst (LoadI mem));
18198 // %}
18199 //
18200 
18201 //----------SMARTSPILL RULES---------------------------------------------------
18202 // These must follow all instruction definitions as they use the names
18203 // defined in the instructions definitions.
18204 
18205 // Local Variables:
18206 // mode: c++
18207 // End:
<a name="123" id="anc123"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="123" type="hidden" />
</body>
</html>