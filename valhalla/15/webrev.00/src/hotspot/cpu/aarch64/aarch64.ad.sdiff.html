<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="../../../demo/share/jfc/TableExample/TableSorter.java.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/cpu/aarch64/aarch64.ad</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 1528 // code for the safepoint node and that needs ot be at the load
 1529 // instruction itself. so we cannot plant a mov of the safepoint poll
 1530 // address followed by a load. setting this to true means the mov is
 1531 // scheduled as a prior instruction. that&#39;s better for scheduling
 1532 // anyway.
 1533 
 1534 bool SafePointNode::needs_polling_address_input()
 1535 {
 1536   return true;
 1537 }
 1538 
 1539 //=============================================================================
 1540 
 1541 #ifndef PRODUCT
 1542 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1543   st-&gt;print(&quot;BREAKPOINT&quot;);
 1544 }
 1545 #endif
 1546 
 1547 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 1548   MacroAssembler _masm(&amp;cbuf);</span>
 1549   __ brk(0);
 1550 }
 1551 
 1552 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1553   return MachNode::size(ra_);
 1554 }
 1555 
 1556 //=============================================================================
 1557 
 1558 #ifndef PRODUCT
 1559   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1560     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1561   }
 1562 #endif
 1563 
 1564   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
<span class="line-modified"> 1565     MacroAssembler _masm(&amp;cbuf);</span>
 1566     for (int i = 0; i &lt; _count; i++) {
 1567       __ nop();
 1568     }
 1569   }
 1570 
 1571   uint MachNopNode::size(PhaseRegAlloc*) const {
 1572     return _count * NativeInstruction::instruction_size;
 1573   }
 1574 
 1575 //=============================================================================
 1576 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1577 
<span class="line-modified"> 1578 int Compile::ConstantTable::calculate_table_base_offset() const {</span>
 1579   return 0;  // absolute addressing, no offset
 1580 }
 1581 
 1582 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1583 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1584   ShouldNotReachHere();
 1585 }
 1586 
 1587 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1588   // Empty encoding
 1589 }
 1590 
 1591 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1592   return 0;
 1593 }
 1594 
 1595 #ifndef PRODUCT
 1596 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1597   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1598 }
 1599 #endif
 1600 
 1601 #ifndef PRODUCT
 1602 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1603   Compile* C = ra_-&gt;C;
 1604 
<span class="line-modified"> 1605   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1606 
<span class="line-modified"> 1607   if (C-&gt;need_stack_bang(framesize))</span>
 1608     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1609 
 1610   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1611     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1612     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1613     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1614   } else {
 1615     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1616     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1617     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1618     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1619   }
 1620 }
 1621 #endif
 1622 
 1623 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1624   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1625   MacroAssembler _masm(&amp;cbuf);</span>
 1626 
 1627   __ verified_entry(C, 0);
 1628   __ bind(*_verified_entry);
 1629 
<span class="line-modified"> 1630   C-&gt;set_frame_complete(cbuf.insts_size());</span>
 1631 
 1632   if (C-&gt;has_mach_constant_base_node()) {
 1633     // NOTE: We set the table base offset here because users might be
 1634     // emitted before MachConstantBaseNode.
<span class="line-modified"> 1635     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();</span>
 1636     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1637   }
 1638 }
 1639 
 1640 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1641 {
 1642   return MachNode::size(ra_); // too many variables; just compute it
 1643                               // the hard way
 1644 }
 1645 
 1646 int MachPrologNode::reloc() const
 1647 {
 1648   return 0;
 1649 }
 1650 
 1651 //=============================================================================
 1652 
 1653 #ifndef PRODUCT
 1654 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1655   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1656   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1657 
 1658   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1659 
 1660   if (framesize == 0) {
 1661     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1662   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1663     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1664     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1665   } else {
 1666     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1667     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1668     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1669   }
 1670 
 1671   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1672     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1673     st-&gt;print(&quot;mov  rscratch1, #0x%lx\n\t&quot;, p2i(os::get_polling_page()));
 1674     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1675   }
 1676 }
 1677 #endif
 1678 
 1679 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1680   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1681   MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 1682   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1683 
 1684   __ remove_frame(framesize);
 1685 
 1686   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1687     __ reserved_stack_check();
 1688   }
 1689 
 1690   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1691     __ read_polling_page(rscratch1, os::get_polling_page(), relocInfo::poll_return_type);
 1692   }
 1693 }
 1694 
 1695 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1696   // Variable size. Determine dynamically.
 1697   return MachNode::size(ra_);
 1698 }
 1699 
 1700 int MachEpilogNode::reloc() const {
 1701   // Return number of relocatable values contained in this instruction.
 1702   return 1; // 1 for polling page.
</pre>
<hr />
<pre>
 1763 
 1764   if (src_hi != OptoReg::Bad) {
 1765     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1766            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1767            &quot;expected aligned-adjacent pairs&quot;);
 1768   }
 1769 
 1770   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1771     return 0;            // Self copy, no move.
 1772   }
 1773 
 1774   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1775               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1776   int src_offset = ra_-&gt;reg2offset(src_lo);
 1777   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1778 
 1779   if (bottom_type()-&gt;isa_vect() != NULL) {
 1780     uint ireg = ideal_reg();
 1781     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1782     if (cbuf) {
<span class="line-modified"> 1783       MacroAssembler _masm(cbuf);</span>
 1784       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1785       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1786         // stack-&gt;stack
 1787         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1788         if (ireg == Op_VecD) {
 1789           __ unspill(rscratch1, true, src_offset);
 1790           __ spill(rscratch1, true, dst_offset);
 1791         } else {
 1792           __ spill_copy128(src_offset, dst_offset);
 1793         }
 1794       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1795         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1796                ireg == Op_VecD ? __ T8B : __ T16B,
 1797                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1798       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1799         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1800                        ireg == Op_VecD ? __ D : __ Q,
 1801                        ra_-&gt;reg2offset(dst_lo));
 1802       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1803         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1804                        ireg == Op_VecD ? __ D : __ Q,
 1805                        ra_-&gt;reg2offset(src_lo));
 1806       } else {
 1807         ShouldNotReachHere();
 1808       }
 1809     }
 1810   } else if (cbuf) {
<span class="line-modified"> 1811     MacroAssembler _masm(cbuf);</span>
 1812     switch (src_lo_rc) {
 1813     case rc_int:
 1814       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1815         if (is64) {
 1816             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1817                    as_Register(Matcher::_regEncode[src_lo]));
 1818         } else {
<span class="line-modified"> 1819             MacroAssembler _masm(cbuf);</span>
 1820             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1821                     as_Register(Matcher::_regEncode[src_lo]));
 1822         }
 1823       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1824         if (is64) {
 1825             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1826                      as_Register(Matcher::_regEncode[src_lo]));
 1827         } else {
 1828             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1829                      as_Register(Matcher::_regEncode[src_lo]));
 1830         }
 1831       } else {                    // gpr --&gt; stack spill
 1832         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1833         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1834       }
 1835       break;
 1836     case rc_float:
 1837       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1838         if (is64) {
 1839             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
</pre>
<hr />
<pre>
 1909 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1910   implementation(&amp;cbuf, ra_, false, NULL);
 1911 }
 1912 
 1913 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1914   return MachNode::size(ra_);
 1915 }
 1916 
 1917 //=============================================================================
 1918 
 1919 #ifndef PRODUCT
 1920 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1921   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1922   int reg = ra_-&gt;get_reg_first(this);
 1923   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1924             Matcher::regName[reg], offset);
 1925 }
 1926 #endif
 1927 
 1928 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 1929   MacroAssembler _masm(&amp;cbuf);</span>
 1930 
 1931   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1932   int reg    = ra_-&gt;get_encode(this);
 1933 
 1934   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1935     __ add(as_Register(reg), sp, offset);
 1936   } else {
 1937     ShouldNotReachHere();
 1938   }
 1939 }
 1940 
 1941 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1942   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1943   return 4;
 1944 }
 1945 
 1946 ///=============================================================================
 1947 #ifndef PRODUCT
 1948 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1949 {
</pre>
<hr />
<pre>
 1986 #ifndef PRODUCT
 1987 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1988 {
 1989   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1990   if (UseCompressedClassPointers) {
 1991     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1992     if (CompressedKlassPointers::shift() != 0) {
 1993       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1994     }
 1995   } else {
 1996    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1997   }
 1998   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1999   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2000 }
 2001 #endif
 2002 
 2003 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2004 {
 2005   // This is the unverified entry point.
<span class="line-modified"> 2006   MacroAssembler _masm(&amp;cbuf);</span>
 2007   Label skip;
 2008 
 2009   // UseCompressedClassPointers logic are inside cmp_klass
 2010   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2011 
 2012   // TODO
 2013   // can we avoid this skip and still use a reloc?
 2014   __ br(Assembler::EQ, skip);
 2015   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2016   __ bind(skip);
 2017 }
 2018 
 2019 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2020 {
 2021   return MachNode::size(ra_);
 2022 }
 2023 
 2024 // REQUIRED EMIT CODE
 2025 
 2026 //=============================================================================
 2027 
 2028 // Emit exception handler code.
 2029 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2030 {
 2031   // mov rscratch1 #exception_blob_entry_point
 2032   // br rscratch1
 2033   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2034   // That&#39;s why we must use the macroassembler to generate a handler.
<span class="line-modified"> 2035   MacroAssembler _masm(&amp;cbuf);</span>
 2036   address base = __ start_a_stub(size_exception_handler());
 2037   if (base == NULL) {
 2038     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2039     return 0;  // CodeBuffer::expand failed
 2040   }
 2041   int offset = __ offset();
 2042   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2043   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2044   __ end_a_stub();
 2045   return offset;
 2046 }
 2047 
 2048 // Emit deopt handler code.
 2049 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2050 {
 2051   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2052   // That&#39;s why we must use the macroassembler to generate a handler.
<span class="line-modified"> 2053   MacroAssembler _masm(&amp;cbuf);</span>
 2054   address base = __ start_a_stub(size_deopt_handler());
 2055   if (base == NULL) {
 2056     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2057     return 0;  // CodeBuffer::expand failed
 2058   }
 2059   int offset = __ offset();
 2060 
 2061   __ adr(lr, __ pc());
 2062   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2063 
 2064   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2065   __ end_a_stub();
 2066   return offset;
 2067 }
 2068 
 2069 // REQUIRED MATCHER CODE
 2070 
 2071 //=============================================================================
 2072 
 2073 const bool Matcher::match_rule_supported(int opcode) {
</pre>
<hr />
<pre>
 2399     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2400     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2401     return true;
 2402   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2403              // Are there other uses besides address expressions?
 2404              !is_visited(off)) {
 2405     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2406     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2407     mstack.push(off-&gt;in(1), Pre_Visit);
 2408     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2409     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2410     return true;
 2411   }
 2412   return false;
 2413 }
 2414 
 2415 void Compile::reshape_address(AddPNode* addp) {
 2416 }
 2417 
 2418 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
<span class="line-modified"> 2419   MacroAssembler _masm(&amp;cbuf);                                          \</span>
 2420   {                                                                     \
 2421     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2422     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2423     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2424     __ INSN(REG, as_Register(BASE));                                    \
 2425   }
 2426 
 2427 
 2428 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2429   {
 2430     Address::extend scale;
 2431 
 2432     // Hooboy, this is fugly.  We need a way to communicate to the
 2433     // encoder that the index needs to be sign extended, so we have to
 2434     // enumerate all the cases.
 2435     switch (opcode) {
 2436     case INDINDEXSCALEDI2L:
 2437     case INDINDEXSCALEDI2LN:
 2438     case INDINDEXI2L:
 2439     case INDINDEXI2LN:
</pre>
<hr />
<pre>
 2444     }
 2445 
 2446     if (index == -1) {
 2447       return Address(base, disp);
 2448     } else {
 2449       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2450       return Address(base, as_Register(index), scale);
 2451     }
 2452   }
 2453 
 2454 
 2455 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2456 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2457 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2458 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2459                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2460 
 2461   // Used for all non-volatile memory accesses.  The use of
 2462   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2463   // offsets is something of a kludge.
<span class="line-modified"> 2464   static void loadStore(MacroAssembler masm, mem_insn insn,</span>
 2465                         Register reg, int opcode,
 2466                         Register base, int index, int scale, int disp,
 2467                         int size_in_memory)
 2468   {
 2469     Address addr = mem2address(opcode, base, index, scale, disp);
 2470     if (addr.getMode() == Address::base_plus_offset) {
 2471       /* If we get an out-of-range offset it is a bug in the compiler,
 2472          so we assert here. */
 2473       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2474              &quot;c2 compiler bug&quot;);
 2475       /* Fix up any out-of-range offsets. */
 2476       assert_different_registers(rscratch1, base);
 2477       assert_different_registers(rscratch1, reg);
 2478       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2479     }
 2480     (masm.*insn)(reg, addr);
 2481   }
 2482 
<span class="line-modified"> 2483   static void loadStore(MacroAssembler masm, mem_float_insn insn,</span>
 2484                         FloatRegister reg, int opcode,
 2485                         Register base, int index, int size, int disp,
 2486                         int size_in_memory)
 2487   {
 2488     Address::extend scale;
 2489 
 2490     switch (opcode) {
 2491     case INDINDEXSCALEDI2L:
 2492     case INDINDEXSCALEDI2LN:
 2493       scale = Address::sxtw(size);
 2494       break;
 2495     default:
 2496       scale = Address::lsl(size);
 2497     }
 2498 
 2499     if (index == -1) {
 2500       /* If we get an out-of-range offset it is a bug in the compiler,
 2501          so we assert here. */
 2502       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2503       /* Fix up any out-of-range offsets. */
 2504       assert_different_registers(rscratch1, base);
 2505       Address addr = Address(base, disp);
 2506       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2507       (masm.*insn)(reg, addr);
 2508     } else {
 2509       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2510       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2511     }
 2512   }
 2513 
<span class="line-modified"> 2514   static void loadStore(MacroAssembler masm, mem_vector_insn insn,</span>
 2515                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2516                         int opcode, Register base, int index, int size, int disp)
 2517   {
 2518     if (index == -1) {
 2519       (masm.*insn)(reg, T, Address(base, disp));
 2520     } else {
 2521       assert(disp == 0, &quot;unsupported address mode&quot;);
 2522       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2523     }
 2524   }
 2525 
 2526 %}
 2527 
 2528 
 2529 
 2530 //----------ENCODING BLOCK-----------------------------------------------------
 2531 // This block specifies the encoding classes used by the compiler to
 2532 // output byte streams.  Encoding classes are parameterized macros
 2533 // used by Machine Instruction Nodes in order to generate the bit
 2534 // encoding of the instruction.  Operands specify their base encoding
</pre>
<hr />
<pre>
 2547 //
 2548 // Instructions specify two basic values for encoding.  Again, a
 2549 // function is available to check if the constant displacement is an
 2550 // oop. They use the ins_encode keyword to specify their encoding
 2551 // classes (which must be a sequence of enc_class names, and their
 2552 // parameters, specified in the encoding block), and they use the
 2553 // opcode keyword to specify, in order, their primary, secondary, and
 2554 // tertiary opcode.  Only the opcode sections which a particular
 2555 // instruction needs for encoding need to be specified.
 2556 encode %{
 2557   // Build emit functions for each basic byte or larger field in the
 2558   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2559   // from C++ code in the enc_class source block.  Emit functions will
 2560   // live in the main source block for now.  In future, we can
 2561   // generalize this by adding a syntax that specifies the sizes of
 2562   // fields in an order, so that the adlc can build the emit functions
 2563   // automagically
 2564 
 2565   // catch all for unimplemented encodings
 2566   enc_class enc_unimplemented %{
<span class="line-modified"> 2567     MacroAssembler _masm(&amp;cbuf);</span>
 2568     __ unimplemented(&quot;C2 catch all&quot;);
 2569   %}
 2570 
 2571   // BEGIN Non-volatile memory access
 2572 
 2573   // This encoding class is generated automatically from ad_encode.m4.
 2574   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2575   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2576     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2577     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),</span>
 2578                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2579   %}
 2580 
 2581   // This encoding class is generated automatically from ad_encode.m4.
 2582   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2583   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2584     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2585     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),</span>
 2586                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2587   %}
 2588 
 2589   // This encoding class is generated automatically from ad_encode.m4.
 2590   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2591   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2592     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2593     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2594                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2595   %}
 2596 
 2597   // This encoding class is generated automatically from ad_encode.m4.
 2598   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2599   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2600     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2601     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2602                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2603   %}
 2604 
 2605   // This encoding class is generated automatically from ad_encode.m4.
 2606   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2607   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2608     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2609     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),</span>
 2610                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2611   %}
 2612 
 2613   // This encoding class is generated automatically from ad_encode.m4.
 2614   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2615   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2616     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2617     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),</span>
 2618                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2619   %}
 2620 
 2621   // This encoding class is generated automatically from ad_encode.m4.
 2622   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2623   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2624     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2625     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2626                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2627   %}
 2628 
 2629   // This encoding class is generated automatically from ad_encode.m4.
 2630   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2631   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2632     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2633     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2634                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2635   %}
 2636 
 2637   // This encoding class is generated automatically from ad_encode.m4.
 2638   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2639   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2640     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2641     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2642                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2643   %}
 2644 
 2645   // This encoding class is generated automatically from ad_encode.m4.
 2646   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2647   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2648     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2649     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2650                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2651   %}
 2652 
 2653   // This encoding class is generated automatically from ad_encode.m4.
 2654   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2655   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2656     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2657     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),</span>
 2658                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2659   %}
 2660 
 2661   // This encoding class is generated automatically from ad_encode.m4.
 2662   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2663   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2664     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2665     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),</span>
 2666                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2667   %}
 2668 
 2669   // This encoding class is generated automatically from ad_encode.m4.
 2670   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2671   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2672     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2673     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),</span>
 2674                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2675   %}
 2676 
 2677   // This encoding class is generated automatically from ad_encode.m4.
 2678   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2679   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2680     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2681     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),</span>
 2682                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2683   %}
 2684 
 2685   // This encoding class is generated automatically from ad_encode.m4.
 2686   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2687   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2688     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2689     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),</span>
 2690                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2691   %}
 2692 
 2693   // This encoding class is generated automatically from ad_encode.m4.
 2694   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2695   enc_class aarch64_enc_strb0(memory1 mem) %{
<span class="line-modified"> 2696     MacroAssembler _masm(&amp;cbuf);</span>
 2697     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2698                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2699   %}
 2700 
 2701   // This encoding class is generated automatically from ad_encode.m4.
 2702   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2703   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2704     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2705     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),</span>
 2706                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2707   %}
 2708 
 2709   // This encoding class is generated automatically from ad_encode.m4.
 2710   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2711   enc_class aarch64_enc_strh0(memory2 mem) %{
<span class="line-modified"> 2712     MacroAssembler _masm(&amp;cbuf);</span>
 2713     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2714                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2715   %}
 2716 
 2717   // This encoding class is generated automatically from ad_encode.m4.
 2718   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2719   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2720     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2721     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),</span>
 2722                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2723   %}
 2724 
 2725   // This encoding class is generated automatically from ad_encode.m4.
 2726   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2727   enc_class aarch64_enc_strw0(memory4 mem) %{
<span class="line-modified"> 2728     MacroAssembler _masm(&amp;cbuf);</span>
 2729     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2730                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2731   %}
 2732 
 2733   // This encoding class is generated automatically from ad_encode.m4.
 2734   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2735   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2736     Register src_reg = as_Register($src$$reg);
 2737     // we sometimes get asked to store the stack pointer into the
 2738     // current thread -- we cannot do that directly on AArch64
 2739     if (src_reg == r31_sp) {
<span class="line-modified"> 2740       MacroAssembler _masm(&amp;cbuf);</span>
 2741       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2742       __ mov(rscratch2, sp);
 2743       src_reg = rscratch2;
 2744     }
<span class="line-modified"> 2745     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),</span>
 2746                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2747   %}
 2748 
 2749   // This encoding class is generated automatically from ad_encode.m4.
 2750   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2751   enc_class aarch64_enc_str0(memory8 mem) %{
<span class="line-modified"> 2752     MacroAssembler _masm(&amp;cbuf);</span>
 2753     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2754                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2755   %}
 2756 
 2757   // This encoding class is generated automatically from ad_encode.m4.
 2758   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2759   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2760     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2761     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),</span>
 2762                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2763   %}
 2764 
 2765   // This encoding class is generated automatically from ad_encode.m4.
 2766   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2767   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2768     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2769     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),</span>
 2770                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2771   %}
 2772 
 2773   // This encoding class is generated automatically from ad_encode.m4.
 2774   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2775   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
<span class="line-modified"> 2776     MacroAssembler _masm(&amp;cbuf);</span>
 2777     address con = (address)$src$$constant;
 2778     // need to do this the hard way until we can manage relocs
 2779     // for 32 bit constants
 2780     __ movoop(rscratch2, (jobject)con);
 2781     if (con) __ encode_heap_oop_not_null(rscratch2);
 2782     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2783                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2784   %}
 2785 
 2786   // This encoding class is generated automatically from ad_encode.m4.
 2787   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2788   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
<span class="line-modified"> 2789     MacroAssembler _masm(&amp;cbuf);</span>
 2790     address con = (address)$src$$constant;
 2791     // need to do this the hard way until we can manage relocs
 2792     // for 32 bit constants
 2793     __ movoop(rscratch2, (jobject)con);
 2794     __ encode_klass_not_null(rscratch2);
 2795     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2796                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2797   %}
 2798 
 2799   // This encoding class is generated automatically from ad_encode.m4.
 2800   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2801   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
<span class="line-modified"> 2802       MacroAssembler _masm(&amp;cbuf);</span>
 2803       __ membar(Assembler::StoreStore);
 2804       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2805                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2806   %}
 2807 
 2808   // END Non-volatile memory access
 2809 
 2810   // Vector loads and stores
 2811   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2812     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2813     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,</span>
 2814        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2815   %}
 2816 
 2817   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2818     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2819     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,</span>
 2820        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2821   %}
 2822 
 2823   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2824     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2825     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,</span>
 2826        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2827   %}
 2828 
 2829   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2830     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2831     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,</span>
 2832        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2833   %}
 2834 
 2835   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2836     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2837     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,</span>
 2838        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2839   %}
 2840 
 2841   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2842     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2843     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,</span>
 2844        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2845   %}
 2846 
 2847   // volatile loads and stores
 2848 
 2849   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2850     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2851                  rscratch1, stlrb);
 2852   %}
 2853 
 2854   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2855     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2856                  rscratch1, stlrh);
 2857   %}
 2858 
 2859   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2860     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2861                  rscratch1, stlrw);
 2862   %}
 2863 
</pre>
<hr />
<pre>
 2925              rscratch1, ldar);
 2926   %}
 2927 
 2928   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2929     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930              rscratch1, ldarw);
 2931     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2935     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2936              rscratch1, ldar);
 2937     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2938   %}
 2939 
 2940   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2941     Register src_reg = as_Register($src$$reg);
 2942     // we sometimes get asked to store the stack pointer into the
 2943     // current thread -- we cannot do that directly on AArch64
 2944     if (src_reg == r31_sp) {
<span class="line-modified"> 2945         MacroAssembler _masm(&amp;cbuf);</span>
 2946       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2947       __ mov(rscratch2, sp);
 2948       src_reg = rscratch2;
 2949     }
 2950     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2951                  rscratch1, stlr);
 2952   %}
 2953 
 2954   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2955     {
<span class="line-modified"> 2956       MacroAssembler _masm(&amp;cbuf);</span>
 2957       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2958       __ fmovs(rscratch2, src_reg);
 2959     }
 2960     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2961                  rscratch1, stlrw);
 2962   %}
 2963 
 2964   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2965     {
<span class="line-modified"> 2966       MacroAssembler _masm(&amp;cbuf);</span>
 2967       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2968       __ fmovd(rscratch2, src_reg);
 2969     }
 2970     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2971                  rscratch1, stlr);
 2972   %}
 2973 
 2974   // synchronized read/update encodings
 2975 
 2976   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
<span class="line-modified"> 2977     MacroAssembler _masm(&amp;cbuf);</span>
 2978     Register dst_reg = as_Register($dst$$reg);
 2979     Register base = as_Register($mem$$base);
 2980     int index = $mem$$index;
 2981     int scale = $mem$$scale;
 2982     int disp = $mem$$disp;
 2983     if (index == -1) {
 2984        if (disp != 0) {
 2985         __ lea(rscratch1, Address(base, disp));
 2986         __ ldaxr(dst_reg, rscratch1);
 2987       } else {
 2988         // TODO
 2989         // should we ever get anything other than this case?
 2990         __ ldaxr(dst_reg, base);
 2991       }
 2992     } else {
 2993       Register index_reg = as_Register(index);
 2994       if (disp == 0) {
 2995         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2996         __ ldaxr(dst_reg, rscratch1);
 2997       } else {
 2998         __ lea(rscratch1, Address(base, disp));
 2999         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3000         __ ldaxr(dst_reg, rscratch1);
 3001       }
 3002     }
 3003   %}
 3004 
 3005   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
<span class="line-modified"> 3006     MacroAssembler _masm(&amp;cbuf);</span>
 3007     Register src_reg = as_Register($src$$reg);
 3008     Register base = as_Register($mem$$base);
 3009     int index = $mem$$index;
 3010     int scale = $mem$$scale;
 3011     int disp = $mem$$disp;
 3012     if (index == -1) {
 3013        if (disp != 0) {
 3014         __ lea(rscratch2, Address(base, disp));
 3015         __ stlxr(rscratch1, src_reg, rscratch2);
 3016       } else {
 3017         // TODO
 3018         // should we ever get anything other than this case?
 3019         __ stlxr(rscratch1, src_reg, base);
 3020       }
 3021     } else {
 3022       Register index_reg = as_Register(index);
 3023       if (disp == 0) {
 3024         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3025         __ stlxr(rscratch1, src_reg, rscratch2);
 3026       } else {
 3027         __ lea(rscratch2, Address(base, disp));
 3028         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3029         __ stlxr(rscratch1, src_reg, rscratch2);
 3030       }
 3031     }
 3032     __ cmpw(rscratch1, zr);
 3033   %}
 3034 
 3035   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<span class="line-modified"> 3036     MacroAssembler _masm(&amp;cbuf);</span>
 3037     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3038     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3039                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3040                /*weak*/ false, noreg);
 3041   %}
 3042 
 3043   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3044     MacroAssembler _masm(&amp;cbuf);</span>
 3045     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3046     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3047                Assembler::word, /*acquire*/ false, /*release*/ true,
 3048                /*weak*/ false, noreg);
 3049   %}
 3050 
 3051   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3052     MacroAssembler _masm(&amp;cbuf);</span>
 3053     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3054     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3055                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3056                /*weak*/ false, noreg);
 3057   %}
 3058 
 3059   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3060     MacroAssembler _masm(&amp;cbuf);</span>
 3061     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3062     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3063                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3064                /*weak*/ false, noreg);
 3065   %}
 3066 
 3067 
 3068   // The only difference between aarch64_enc_cmpxchg and
 3069   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3070   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3071   // lock.
 3072   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<span class="line-modified"> 3073     MacroAssembler _masm(&amp;cbuf);</span>
 3074     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3075     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3076                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3077                /*weak*/ false, noreg);
 3078   %}
 3079 
 3080   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3081     MacroAssembler _masm(&amp;cbuf);</span>
 3082     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3083     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3084                Assembler::word, /*acquire*/ true, /*release*/ true,
 3085                /*weak*/ false, noreg);
 3086   %}
 3087 
 3088   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3089     MacroAssembler _masm(&amp;cbuf);</span>
 3090     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3091     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3092                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3093                /*weak*/ false, noreg);
 3094   %}
 3095 
 3096   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3097     MacroAssembler _masm(&amp;cbuf);</span>
 3098     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3099     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3100                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3101                /*weak*/ false, noreg);
 3102   %}
 3103 
 3104   // auxiliary used for CompareAndSwapX to set result register
 3105   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
<span class="line-modified"> 3106     MacroAssembler _masm(&amp;cbuf);</span>
 3107     Register res_reg = as_Register($res$$reg);
 3108     __ cset(res_reg, Assembler::EQ);
 3109   %}
 3110 
 3111   // prefetch encodings
 3112 
 3113   enc_class aarch64_enc_prefetchw(memory mem) %{
<span class="line-modified"> 3114     MacroAssembler _masm(&amp;cbuf);</span>
 3115     Register base = as_Register($mem$$base);
 3116     int index = $mem$$index;
 3117     int scale = $mem$$scale;
 3118     int disp = $mem$$disp;
 3119     if (index == -1) {
 3120       __ prfm(Address(base, disp), PSTL1KEEP);
 3121     } else {
 3122       Register index_reg = as_Register(index);
 3123       if (disp == 0) {
 3124         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3125       } else {
 3126         __ lea(rscratch1, Address(base, disp));
 3127 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3128       }
 3129     }
 3130   %}
 3131 
 3132   /// mov envcodings
 3133 
 3134   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
<span class="line-modified"> 3135     MacroAssembler _masm(&amp;cbuf);</span>
 3136     u_int32_t con = (u_int32_t)$src$$constant;
 3137     Register dst_reg = as_Register($dst$$reg);
 3138     if (con == 0) {
 3139       __ movw(dst_reg, zr);
 3140     } else {
 3141       __ movw(dst_reg, con);
 3142     }
 3143   %}
 3144 
 3145   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
<span class="line-modified"> 3146     MacroAssembler _masm(&amp;cbuf);</span>
 3147     Register dst_reg = as_Register($dst$$reg);
 3148     u_int64_t con = (u_int64_t)$src$$constant;
 3149     if (con == 0) {
 3150       __ mov(dst_reg, zr);
 3151     } else {
 3152       __ mov(dst_reg, con);
 3153     }
 3154   %}
 3155 
 3156   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
<span class="line-modified"> 3157     MacroAssembler _masm(&amp;cbuf);</span>
 3158     Register dst_reg = as_Register($dst$$reg);
 3159     address con = (address)$src$$constant;
 3160     if (con == NULL || con == (address)1) {
 3161       ShouldNotReachHere();
 3162     } else {
 3163       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3164       if (rtype == relocInfo::oop_type) {
 3165         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3166       } else if (rtype == relocInfo::metadata_type) {
 3167         __ mov_metadata(dst_reg, (Metadata*)con);
 3168       } else {
 3169         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3170         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3171           __ mov(dst_reg, con);
 3172         } else {
 3173           unsigned long offset;
 3174           __ adrp(dst_reg, con, offset);
 3175           __ add(dst_reg, dst_reg, offset);
 3176         }
 3177       }
 3178     }
 3179   %}
 3180 
 3181   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
<span class="line-modified"> 3182     MacroAssembler _masm(&amp;cbuf);</span>
 3183     Register dst_reg = as_Register($dst$$reg);
 3184     __ mov(dst_reg, zr);
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
<span class="line-modified"> 3188     MacroAssembler _masm(&amp;cbuf);</span>
 3189     Register dst_reg = as_Register($dst$$reg);
 3190     __ mov(dst_reg, (u_int64_t)1);
 3191   %}
 3192 
 3193   enc_class aarch64_enc_mov_poll_page(iRegP dst, immPollPage src) %{
<span class="line-modified"> 3194     MacroAssembler _masm(&amp;cbuf);</span>
 3195     address page = (address)$src$$constant;
 3196     Register dst_reg = as_Register($dst$$reg);
 3197     unsigned long off;
 3198     __ adrp(dst_reg, Address(page, relocInfo::poll_type), off);
 3199     assert(off == 0, &quot;assumed offset == 0&quot;);
 3200   %}
 3201 
 3202   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
<span class="line-modified"> 3203     MacroAssembler _masm(&amp;cbuf);</span>
 3204     __ load_byte_map_base($dst$$Register);
 3205   %}
 3206 
 3207   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
<span class="line-modified"> 3208     MacroAssembler _masm(&amp;cbuf);</span>
 3209     Register dst_reg = as_Register($dst$$reg);
 3210     address con = (address)$src$$constant;
 3211     if (con == NULL) {
 3212       ShouldNotReachHere();
 3213     } else {
 3214       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3215       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3216       __ set_narrow_oop(dst_reg, (jobject)con);
 3217     }
 3218   %}
 3219 
 3220   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
<span class="line-modified"> 3221     MacroAssembler _masm(&amp;cbuf);</span>
 3222     Register dst_reg = as_Register($dst$$reg);
 3223     __ mov(dst_reg, zr);
 3224   %}
 3225 
 3226   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
<span class="line-modified"> 3227     MacroAssembler _masm(&amp;cbuf);</span>
 3228     Register dst_reg = as_Register($dst$$reg);
 3229     address con = (address)$src$$constant;
 3230     if (con == NULL) {
 3231       ShouldNotReachHere();
 3232     } else {
 3233       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3234       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3235       __ set_narrow_klass(dst_reg, (Klass *)con);
 3236     }
 3237   %}
 3238 
 3239   // arithmetic encodings
 3240 
 3241   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
<span class="line-modified"> 3242     MacroAssembler _masm(&amp;cbuf);</span>
 3243     Register dst_reg = as_Register($dst$$reg);
 3244     Register src_reg = as_Register($src1$$reg);
 3245     int32_t con = (int32_t)$src2$$constant;
 3246     // add has primary == 0, subtract has primary == 1
 3247     if ($primary) { con = -con; }
 3248     if (con &lt; 0) {
 3249       __ subw(dst_reg, src_reg, -con);
 3250     } else {
 3251       __ addw(dst_reg, src_reg, con);
 3252     }
 3253   %}
 3254 
 3255   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
<span class="line-modified"> 3256     MacroAssembler _masm(&amp;cbuf);</span>
 3257     Register dst_reg = as_Register($dst$$reg);
 3258     Register src_reg = as_Register($src1$$reg);
 3259     int32_t con = (int32_t)$src2$$constant;
 3260     // add has primary == 0, subtract has primary == 1
 3261     if ($primary) { con = -con; }
 3262     if (con &lt; 0) {
 3263       __ sub(dst_reg, src_reg, -con);
 3264     } else {
 3265       __ add(dst_reg, src_reg, con);
 3266     }
 3267   %}
 3268 
 3269   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3270     MacroAssembler _masm(&amp;cbuf);</span>
 3271    Register dst_reg = as_Register($dst$$reg);
 3272    Register src1_reg = as_Register($src1$$reg);
 3273    Register src2_reg = as_Register($src2$$reg);
 3274     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3275   %}
 3276 
 3277   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3278     MacroAssembler _masm(&amp;cbuf);</span>
 3279    Register dst_reg = as_Register($dst$$reg);
 3280    Register src1_reg = as_Register($src1$$reg);
 3281    Register src2_reg = as_Register($src2$$reg);
 3282     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3283   %}
 3284 
 3285   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3286     MacroAssembler _masm(&amp;cbuf);</span>
 3287    Register dst_reg = as_Register($dst$$reg);
 3288    Register src1_reg = as_Register($src1$$reg);
 3289    Register src2_reg = as_Register($src2$$reg);
 3290     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3291   %}
 3292 
 3293   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3294     MacroAssembler _masm(&amp;cbuf);</span>
 3295    Register dst_reg = as_Register($dst$$reg);
 3296    Register src1_reg = as_Register($src1$$reg);
 3297    Register src2_reg = as_Register($src2$$reg);
 3298     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3299   %}
 3300 
 3301   // compare instruction encodings
 3302 
 3303   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
<span class="line-modified"> 3304     MacroAssembler _masm(&amp;cbuf);</span>
 3305     Register reg1 = as_Register($src1$$reg);
 3306     Register reg2 = as_Register($src2$$reg);
 3307     __ cmpw(reg1, reg2);
 3308   %}
 3309 
 3310   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
<span class="line-modified"> 3311     MacroAssembler _masm(&amp;cbuf);</span>
 3312     Register reg = as_Register($src1$$reg);
 3313     int32_t val = $src2$$constant;
 3314     if (val &gt;= 0) {
 3315       __ subsw(zr, reg, val);
 3316     } else {
 3317       __ addsw(zr, reg, -val);
 3318     }
 3319   %}
 3320 
 3321   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
<span class="line-modified"> 3322     MacroAssembler _masm(&amp;cbuf);</span>
 3323     Register reg1 = as_Register($src1$$reg);
 3324     u_int32_t val = (u_int32_t)$src2$$constant;
 3325     __ movw(rscratch1, val);
 3326     __ cmpw(reg1, rscratch1);
 3327   %}
 3328 
 3329   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
<span class="line-modified"> 3330     MacroAssembler _masm(&amp;cbuf);</span>
 3331     Register reg1 = as_Register($src1$$reg);
 3332     Register reg2 = as_Register($src2$$reg);
 3333     __ cmp(reg1, reg2);
 3334   %}
 3335 
 3336   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
<span class="line-modified"> 3337     MacroAssembler _masm(&amp;cbuf);</span>
 3338     Register reg = as_Register($src1$$reg);
 3339     int64_t val = $src2$$constant;
 3340     if (val &gt;= 0) {
 3341       __ subs(zr, reg, val);
 3342     } else if (val != -val) {
 3343       __ adds(zr, reg, -val);
 3344     } else {
 3345     // aargh, Long.MIN_VALUE is a special case
 3346       __ orr(rscratch1, zr, (u_int64_t)val);
 3347       __ subs(zr, reg, rscratch1);
 3348     }
 3349   %}
 3350 
 3351   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
<span class="line-modified"> 3352     MacroAssembler _masm(&amp;cbuf);</span>
 3353     Register reg1 = as_Register($src1$$reg);
 3354     u_int64_t val = (u_int64_t)$src2$$constant;
 3355     __ mov(rscratch1, val);
 3356     __ cmp(reg1, rscratch1);
 3357   %}
 3358 
 3359   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
<span class="line-modified"> 3360     MacroAssembler _masm(&amp;cbuf);</span>
 3361     Register reg1 = as_Register($src1$$reg);
 3362     Register reg2 = as_Register($src2$$reg);
 3363     __ cmp(reg1, reg2);
 3364   %}
 3365 
 3366   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
<span class="line-modified"> 3367     MacroAssembler _masm(&amp;cbuf);</span>
 3368     Register reg1 = as_Register($src1$$reg);
 3369     Register reg2 = as_Register($src2$$reg);
 3370     __ cmpw(reg1, reg2);
 3371   %}
 3372 
 3373   enc_class aarch64_enc_testp(iRegP src) %{
<span class="line-modified"> 3374     MacroAssembler _masm(&amp;cbuf);</span>
 3375     Register reg = as_Register($src$$reg);
 3376     __ cmp(reg, zr);
 3377   %}
 3378 
 3379   enc_class aarch64_enc_testn(iRegN src) %{
<span class="line-modified"> 3380     MacroAssembler _masm(&amp;cbuf);</span>
 3381     Register reg = as_Register($src$$reg);
 3382     __ cmpw(reg, zr);
 3383   %}
 3384 
 3385   enc_class aarch64_enc_b(label lbl) %{
<span class="line-modified"> 3386     MacroAssembler _masm(&amp;cbuf);</span>
 3387     Label *L = $lbl$$label;
 3388     __ b(*L);
 3389   %}
 3390 
 3391   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
<span class="line-modified"> 3392     MacroAssembler _masm(&amp;cbuf);</span>
 3393     Label *L = $lbl$$label;
 3394     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3395   %}
 3396 
 3397   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
<span class="line-modified"> 3398     MacroAssembler _masm(&amp;cbuf);</span>
 3399     Label *L = $lbl$$label;
 3400     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3401   %}
 3402 
 3403   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3404   %{
 3405      Register sub_reg = as_Register($sub$$reg);
 3406      Register super_reg = as_Register($super$$reg);
 3407      Register temp_reg = as_Register($temp$$reg);
 3408      Register result_reg = as_Register($result$$reg);
 3409 
 3410      Label miss;
<span class="line-modified"> 3411      MacroAssembler _masm(&amp;cbuf);</span>
 3412      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3413                                      NULL, &amp;miss,
 3414                                      /*set_cond_codes:*/ true);
 3415      if ($primary) {
 3416        __ mov(result_reg, zr);
 3417      }
 3418      __ bind(miss);
 3419   %}
 3420 
 3421   enc_class aarch64_enc_java_static_call(method meth) %{
<span class="line-modified"> 3422     MacroAssembler _masm(&amp;cbuf);</span>
 3423 
 3424     address addr = (address)$meth$$method;
 3425     address call;
 3426     if (!_method) {
 3427       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3428       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3429     } else {
 3430       int method_index = resolved_method_index(cbuf);
 3431       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3432                                                   : static_call_Relocation::spec(method_index);
 3433       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3434 
 3435       // Emit stub for static call
 3436       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3437       if (stub == NULL) {
 3438         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3439         return;
 3440       }
 3441     }
 3442     if (call == NULL) {
 3443       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3444       return;
 3445     }
 3446   %}
 3447 
 3448   enc_class aarch64_enc_java_dynamic_call(method meth) %{
<span class="line-modified"> 3449     MacroAssembler _masm(&amp;cbuf);</span>
 3450     int method_index = resolved_method_index(cbuf);
 3451     address call = __ ic_call((address)$meth$$method, method_index);
 3452     if (call == NULL) {
 3453       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3454       return;
 3455     }
 3456   %}
 3457 
 3458   enc_class aarch64_enc_call_epilog() %{
<span class="line-modified"> 3459     MacroAssembler _masm(&amp;cbuf);</span>
 3460     if (VerifyStackAtCalls) {
 3461       // Check that stack depth is unchanged: find majik cookie on stack
 3462       __ call_Unimplemented();
 3463     }
 3464   %}
 3465 
 3466   enc_class aarch64_enc_java_to_runtime(method meth) %{
<span class="line-modified"> 3467     MacroAssembler _masm(&amp;cbuf);</span>
 3468 
 3469     // some calls to generated routines (arraycopy code) are scheduled
 3470     // by C2 as runtime calls. if so we can call them using a br (they
 3471     // will be in a reachable segment) otherwise we have to use a blr
 3472     // which loads the absolute address into a register.
 3473     address entry = (address)$meth$$method;
 3474     CodeBlob *cb = CodeCache::find_blob(entry);
 3475     if (cb) {
 3476       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3477       if (call == NULL) {
 3478         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3479         return;
 3480       }
 3481     } else {
 3482       Label retaddr;
 3483       __ adr(rscratch2, retaddr);
 3484       __ lea(rscratch1, RuntimeAddress(entry));
 3485       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3486       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3487       __ blr(rscratch1);
 3488       __ bind(retaddr);
 3489       __ add(sp, sp, 2 * wordSize);
 3490     }
 3491   %}
 3492 
 3493   enc_class aarch64_enc_rethrow() %{
<span class="line-modified"> 3494     MacroAssembler _masm(&amp;cbuf);</span>
 3495     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3496   %}
 3497 
 3498   enc_class aarch64_enc_ret() %{
<span class="line-modified"> 3499     MacroAssembler _masm(&amp;cbuf);</span>
 3500     __ ret(lr);
 3501   %}
 3502 
 3503   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
<span class="line-modified"> 3504     MacroAssembler _masm(&amp;cbuf);</span>
 3505     Register target_reg = as_Register($jump_target$$reg);
 3506     __ br(target_reg);
 3507   %}
 3508 
 3509   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
<span class="line-modified"> 3510     MacroAssembler _masm(&amp;cbuf);</span>
 3511     Register target_reg = as_Register($jump_target$$reg);
 3512     // exception oop should be in r0
 3513     // ret addr has been popped into lr
 3514     // callee expects it in r3
 3515     __ mov(r3, lr);
 3516     __ br(target_reg);
 3517   %}
 3518 
 3519   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<span class="line-modified"> 3520     MacroAssembler _masm(&amp;cbuf);</span>
 3521     Register oop = as_Register($object$$reg);
 3522     Register box = as_Register($box$$reg);
 3523     Register disp_hdr = as_Register($tmp$$reg);
 3524     Register tmp = as_Register($tmp2$$reg);
 3525     Label cont;
 3526     Label object_has_monitor;
 3527     Label cas_failed;
 3528 
 3529     assert_different_registers(oop, box, tmp, disp_hdr);
 3530 
 3531     // Load markWord from object into displaced_header.
 3532     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3533 
 3534     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3535       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3536     }
 3537 
 3538     // Check for existing monitor
 3539     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3540 
</pre>
<hr />
<pre>
 3578     // otherwise m-&gt;owner may contain a thread or a stack address.
 3579     //
 3580     // Try to CAS m-&gt;owner from NULL to current thread.
 3581     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3582     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3583                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3584 
 3585     // Store a non-null value into the box to avoid looking like a re-entrant
 3586     // lock. The fast-path monitor unlock code checks for
 3587     // markWord::monitor_value so use markWord::unused_mark which has the
 3588     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3589     __ mov(tmp, (address)markWord::unused_mark().value());
 3590     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3591 
 3592     __ bind(cont);
 3593     // flag == EQ indicates success
 3594     // flag == NE indicates failure
 3595   %}
 3596 
 3597   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<span class="line-modified"> 3598     MacroAssembler _masm(&amp;cbuf);</span>
 3599     Register oop = as_Register($object$$reg);
 3600     Register box = as_Register($box$$reg);
 3601     Register disp_hdr = as_Register($tmp$$reg);
 3602     Register tmp = as_Register($tmp2$$reg);
 3603     Label cont;
 3604     Label object_has_monitor;
 3605 
 3606     assert_different_registers(oop, box, tmp, disp_hdr);
 3607 
 3608     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3609       __ biased_locking_exit(oop, tmp, cont);
 3610     }
 3611 
 3612     // Find the lock address and load the displaced header from the stack.
 3613     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3614 
 3615     // If the displaced header is 0, we have a recursive unlock.
 3616     __ cmp(disp_hdr, zr);
 3617     __ br(Assembler::EQ, cont);
 3618 
</pre>
<hr />
<pre>
 8071     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8072     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8073     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8074   %}
 8075 
 8076   ins_pipe(pipe_class_default);
 8077 %}
 8078 
 8079 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8080   predicate(UsePopCountInstruction);
 8081   match(Set dst (PopCountI (LoadI mem)));
 8082   effect(TEMP tmp);
 8083   ins_cost(INSN_COST * 13);
 8084 
 8085   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8086             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8087             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8088             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8089   ins_encode %{
 8090     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<span class="line-modified"> 8091     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),</span>
 8092               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8093     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8094     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8095     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8096   %}
 8097 
 8098   ins_pipe(pipe_class_default);
 8099 %}
 8100 
 8101 // Note: Long.bitCount(long) returns an int.
 8102 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8103   predicate(UsePopCountInstruction);
 8104   match(Set dst (PopCountL src));
 8105   effect(TEMP tmp);
 8106   ins_cost(INSN_COST * 13);
 8107 
 8108   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8109             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8110             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8111             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
</pre>
<hr />
<pre>
 8114     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8115     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8116     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8117   %}
 8118 
 8119   ins_pipe(pipe_class_default);
 8120 %}
 8121 
 8122 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8123   predicate(UsePopCountInstruction);
 8124   match(Set dst (PopCountL (LoadL mem)));
 8125   effect(TEMP tmp);
 8126   ins_cost(INSN_COST * 13);
 8127 
 8128   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8129             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8130             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8131             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8132   ins_encode %{
 8133     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<span class="line-modified"> 8134     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),</span>
 8135               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8136     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8137     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8138     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8139   %}
 8140 
 8141   ins_pipe(pipe_class_default);
 8142 %}
 8143 
 8144 // ============================================================================
 8145 // MemBar Instruction
 8146 
 8147 instruct load_fence() %{
 8148   match(LoadFence);
 8149   ins_cost(VOLATILE_REF_COST);
 8150 
 8151   format %{ &quot;load_fence&quot; %}
 8152 
 8153   ins_encode %{
 8154     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
</pre>
<hr />
<pre>
14961 %}
14962 
14963 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14964   match(If cmp (CmpI op1 op2));
14965   effect(USE labl);
14966 
14967   ins_cost(BRANCH_COST);
14968   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14969   ins_encode %{
14970     Label* L = $labl$$label;
14971     Assembler::Condition cond =
14972       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14973     __ tbr(cond, $op1$$Register, 31, *L);
14974   %}
14975   ins_pipe(pipe_cmp_branch);
14976   ins_short_branch(1);
14977 %}
14978 
14979 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14980   match(If cmp (CmpL (AndL op1 op2) op3));
<span class="line-modified">14981   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
14982   effect(USE labl);
14983 
14984   ins_cost(BRANCH_COST);
14985   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14986   ins_encode %{
14987     Label* L = $labl$$label;
14988     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">14989     int bit = exact_log2($op2$$constant);</span>
14990     __ tbr(cond, $op1$$Register, bit, *L);
14991   %}
14992   ins_pipe(pipe_cmp_branch);
14993   ins_short_branch(1);
14994 %}
14995 
14996 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14997   match(If cmp (CmpI (AndI op1 op2) op3));
<span class="line-modified">14998   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
14999   effect(USE labl);
15000 
15001   ins_cost(BRANCH_COST);
15002   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15003   ins_encode %{
15004     Label* L = $labl$$label;
15005     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15006     int bit = exact_log2($op2$$constant);</span>
15007     __ tbr(cond, $op1$$Register, bit, *L);
15008   %}
15009   ins_pipe(pipe_cmp_branch);
15010   ins_short_branch(1);
15011 %}
15012 
15013 // And far variants
15014 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15015   match(If cmp (CmpL op1 op2));
15016   effect(USE labl);
15017 
15018   ins_cost(BRANCH_COST);
15019   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15020   ins_encode %{
15021     Label* L = $labl$$label;
15022     Assembler::Condition cond =
15023       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15024     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15025   %}
15026   ins_pipe(pipe_cmp_branch);
15027 %}
15028 
15029 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15030   match(If cmp (CmpI op1 op2));
15031   effect(USE labl);
15032 
15033   ins_cost(BRANCH_COST);
15034   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15035   ins_encode %{
15036     Label* L = $labl$$label;
15037     Assembler::Condition cond =
15038       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15039     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15040   %}
15041   ins_pipe(pipe_cmp_branch);
15042 %}
15043 
15044 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15045   match(If cmp (CmpL (AndL op1 op2) op3));
<span class="line-modified">15046   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
15047   effect(USE labl);
15048 
15049   ins_cost(BRANCH_COST);
15050   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15051   ins_encode %{
15052     Label* L = $labl$$label;
15053     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15054     int bit = exact_log2($op2$$constant);</span>
15055     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15056   %}
15057   ins_pipe(pipe_cmp_branch);
15058 %}
15059 
15060 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15061   match(If cmp (CmpI (AndI op1 op2) op3));
<span class="line-modified">15062   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
15063   effect(USE labl);
15064 
15065   ins_cost(BRANCH_COST);
15066   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15067   ins_encode %{
15068     Label* L = $labl$$label;
15069     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15070     int bit = exact_log2($op2$$constant);</span>
15071     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15072   %}
15073   ins_pipe(pipe_cmp_branch);
15074 %}
15075 
15076 // Test bits
15077 
15078 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15079   match(Set cr (CmpL (AndL op1 op2) op3));
15080   predicate(Assembler::operand_valid_for_logical_immediate
15081             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15082 
15083   ins_cost(INSN_COST);
15084   format %{ &quot;tst $op1, $op2 # long&quot; %}
15085   ins_encode %{
15086     __ tst($op1$$Register, $op2$$constant);
15087   %}
15088   ins_pipe(ialu_reg_reg);
15089 %}
15090 
</pre>
<hr />
<pre>
16991 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16992   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16993   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16994   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16995   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16996   ins_cost(INSN_COST);
16997   ins_encode %{
16998     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16999             as_FloatRegister($src1$$reg),
17000             as_FloatRegister($src2$$reg));
17001   %}
17002   ins_pipe(vmuldiv_fp128);
17003 %}
17004 
17005 // --------------- Vector Multiply-Add Shorts into Integer --------------------
17006 
17007 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
17008   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
17009   match(Set dst (MulAddVS2VI src1 src2));
17010   ins_cost(INSN_COST);
<span class="line-modified">17011   effect(TEMP tmp);</span>
17012   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
17013             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
17014             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17015   ins_encode %{
17016     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17017               as_FloatRegister($src1$$reg),
17018               as_FloatRegister($src2$$reg));
17019     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17020               as_FloatRegister($src1$$reg),
17021               as_FloatRegister($src2$$reg));
17022     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17023              as_FloatRegister($tmp$$reg),
17024              as_FloatRegister($dst$$reg));
17025   %}
17026   ins_pipe(vmuldiv_fp128);
17027 %}
17028 
17029 // --------------------------------- DIV --------------------------------------
17030 
17031 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
</pre>
</td>
<td>
<hr />
<pre>
 1528 // code for the safepoint node and that needs ot be at the load
 1529 // instruction itself. so we cannot plant a mov of the safepoint poll
 1530 // address followed by a load. setting this to true means the mov is
 1531 // scheduled as a prior instruction. that&#39;s better for scheduling
 1532 // anyway.
 1533 
 1534 bool SafePointNode::needs_polling_address_input()
 1535 {
 1536   return true;
 1537 }
 1538 
 1539 //=============================================================================
 1540 
 1541 #ifndef PRODUCT
 1542 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1543   st-&gt;print(&quot;BREAKPOINT&quot;);
 1544 }
 1545 #endif
 1546 
 1547 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 1548   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1549   __ brk(0);
 1550 }
 1551 
 1552 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1553   return MachNode::size(ra_);
 1554 }
 1555 
 1556 //=============================================================================
 1557 
 1558 #ifndef PRODUCT
 1559   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1560     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1561   }
 1562 #endif
 1563 
 1564   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
<span class="line-modified"> 1565     C2_MacroAssembler _masm(&amp;cbuf);</span>
 1566     for (int i = 0; i &lt; _count; i++) {
 1567       __ nop();
 1568     }
 1569   }
 1570 
 1571   uint MachNopNode::size(PhaseRegAlloc*) const {
 1572     return _count * NativeInstruction::instruction_size;
 1573   }
 1574 
 1575 //=============================================================================
 1576 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1577 
<span class="line-modified"> 1578 int ConstantTable::calculate_table_base_offset() const {</span>
 1579   return 0;  // absolute addressing, no offset
 1580 }
 1581 
 1582 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1583 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1584   ShouldNotReachHere();
 1585 }
 1586 
 1587 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1588   // Empty encoding
 1589 }
 1590 
 1591 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1592   return 0;
 1593 }
 1594 
 1595 #ifndef PRODUCT
 1596 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1597   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1598 }
 1599 #endif
 1600 
 1601 #ifndef PRODUCT
 1602 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1603   Compile* C = ra_-&gt;C;
 1604 
<span class="line-modified"> 1605   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1606 
<span class="line-modified"> 1607   if (C-&gt;output()-&gt;need_stack_bang(framesize))</span>
 1608     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1609 
 1610   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1611     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1612     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1613     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1614   } else {
 1615     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1616     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1617     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1618     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1619   }
 1620 }
 1621 #endif
 1622 
 1623 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1624   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1625   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1626 
 1627   __ verified_entry(C, 0);
 1628   __ bind(*_verified_entry);
 1629 
<span class="line-modified"> 1630   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());</span>
 1631 
 1632   if (C-&gt;has_mach_constant_base_node()) {
 1633     // NOTE: We set the table base offset here because users might be
 1634     // emitted before MachConstantBaseNode.
<span class="line-modified"> 1635     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();</span>
 1636     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1637   }
 1638 }
 1639 
 1640 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1641 {
 1642   return MachNode::size(ra_); // too many variables; just compute it
 1643                               // the hard way
 1644 }
 1645 
 1646 int MachPrologNode::reloc() const
 1647 {
 1648   return 0;
 1649 }
 1650 
 1651 //=============================================================================
 1652 
 1653 #ifndef PRODUCT
 1654 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1655   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1656   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1657 
 1658   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1659 
 1660   if (framesize == 0) {
 1661     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1662   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1663     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1664     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1665   } else {
 1666     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1667     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1668     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1669   }
 1670 
 1671   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1672     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1673     st-&gt;print(&quot;mov  rscratch1, #0x%lx\n\t&quot;, p2i(os::get_polling_page()));
 1674     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1675   }
 1676 }
 1677 #endif
 1678 
 1679 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1680   Compile* C = ra_-&gt;C;
<span class="line-modified"> 1681   C2_MacroAssembler _masm(&amp;cbuf);</span>
<span class="line-modified"> 1682   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;</span>
 1683 
 1684   __ remove_frame(framesize);
 1685 
 1686   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1687     __ reserved_stack_check();
 1688   }
 1689 
 1690   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1691     __ read_polling_page(rscratch1, os::get_polling_page(), relocInfo::poll_return_type);
 1692   }
 1693 }
 1694 
 1695 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1696   // Variable size. Determine dynamically.
 1697   return MachNode::size(ra_);
 1698 }
 1699 
 1700 int MachEpilogNode::reloc() const {
 1701   // Return number of relocatable values contained in this instruction.
 1702   return 1; // 1 for polling page.
</pre>
<hr />
<pre>
 1763 
 1764   if (src_hi != OptoReg::Bad) {
 1765     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1766            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1767            &quot;expected aligned-adjacent pairs&quot;);
 1768   }
 1769 
 1770   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1771     return 0;            // Self copy, no move.
 1772   }
 1773 
 1774   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1775               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1776   int src_offset = ra_-&gt;reg2offset(src_lo);
 1777   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1778 
 1779   if (bottom_type()-&gt;isa_vect() != NULL) {
 1780     uint ireg = ideal_reg();
 1781     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1782     if (cbuf) {
<span class="line-modified"> 1783       C2_MacroAssembler _masm(cbuf);</span>
 1784       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1785       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1786         // stack-&gt;stack
 1787         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1788         if (ireg == Op_VecD) {
 1789           __ unspill(rscratch1, true, src_offset);
 1790           __ spill(rscratch1, true, dst_offset);
 1791         } else {
 1792           __ spill_copy128(src_offset, dst_offset);
 1793         }
 1794       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1795         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1796                ireg == Op_VecD ? __ T8B : __ T16B,
 1797                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1798       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1799         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1800                        ireg == Op_VecD ? __ D : __ Q,
 1801                        ra_-&gt;reg2offset(dst_lo));
 1802       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1803         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1804                        ireg == Op_VecD ? __ D : __ Q,
 1805                        ra_-&gt;reg2offset(src_lo));
 1806       } else {
 1807         ShouldNotReachHere();
 1808       }
 1809     }
 1810   } else if (cbuf) {
<span class="line-modified"> 1811     C2_MacroAssembler _masm(cbuf);</span>
 1812     switch (src_lo_rc) {
 1813     case rc_int:
 1814       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1815         if (is64) {
 1816             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1817                    as_Register(Matcher::_regEncode[src_lo]));
 1818         } else {
<span class="line-modified"> 1819             C2_MacroAssembler _masm(cbuf);</span>
 1820             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1821                     as_Register(Matcher::_regEncode[src_lo]));
 1822         }
 1823       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1824         if (is64) {
 1825             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1826                      as_Register(Matcher::_regEncode[src_lo]));
 1827         } else {
 1828             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1829                      as_Register(Matcher::_regEncode[src_lo]));
 1830         }
 1831       } else {                    // gpr --&gt; stack spill
 1832         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1833         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1834       }
 1835       break;
 1836     case rc_float:
 1837       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1838         if (is64) {
 1839             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
</pre>
<hr />
<pre>
 1909 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1910   implementation(&amp;cbuf, ra_, false, NULL);
 1911 }
 1912 
 1913 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1914   return MachNode::size(ra_);
 1915 }
 1916 
 1917 //=============================================================================
 1918 
 1919 #ifndef PRODUCT
 1920 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1921   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1922   int reg = ra_-&gt;get_reg_first(this);
 1923   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1924             Matcher::regName[reg], offset);
 1925 }
 1926 #endif
 1927 
 1928 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
<span class="line-modified"> 1929   C2_MacroAssembler _masm(&amp;cbuf);</span>
 1930 
 1931   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1932   int reg    = ra_-&gt;get_encode(this);
 1933 
 1934   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1935     __ add(as_Register(reg), sp, offset);
 1936   } else {
 1937     ShouldNotReachHere();
 1938   }
 1939 }
 1940 
 1941 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1942   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1943   return 4;
 1944 }
 1945 
 1946 ///=============================================================================
 1947 #ifndef PRODUCT
 1948 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1949 {
</pre>
<hr />
<pre>
 1986 #ifndef PRODUCT
 1987 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1988 {
 1989   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1990   if (UseCompressedClassPointers) {
 1991     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1992     if (CompressedKlassPointers::shift() != 0) {
 1993       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1994     }
 1995   } else {
 1996    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1997   }
 1998   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1999   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2000 }
 2001 #endif
 2002 
 2003 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2004 {
 2005   // This is the unverified entry point.
<span class="line-modified"> 2006   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2007   Label skip;
 2008 
 2009   // UseCompressedClassPointers logic are inside cmp_klass
 2010   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2011 
 2012   // TODO
 2013   // can we avoid this skip and still use a reloc?
 2014   __ br(Assembler::EQ, skip);
 2015   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2016   __ bind(skip);
 2017 }
 2018 
 2019 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2020 {
 2021   return MachNode::size(ra_);
 2022 }
 2023 
 2024 // REQUIRED EMIT CODE
 2025 
 2026 //=============================================================================
 2027 
 2028 // Emit exception handler code.
 2029 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2030 {
 2031   // mov rscratch1 #exception_blob_entry_point
 2032   // br rscratch1
 2033   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2034   // That&#39;s why we must use the macroassembler to generate a handler.
<span class="line-modified"> 2035   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2036   address base = __ start_a_stub(size_exception_handler());
 2037   if (base == NULL) {
 2038     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2039     return 0;  // CodeBuffer::expand failed
 2040   }
 2041   int offset = __ offset();
 2042   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2043   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2044   __ end_a_stub();
 2045   return offset;
 2046 }
 2047 
 2048 // Emit deopt handler code.
 2049 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2050 {
 2051   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2052   // That&#39;s why we must use the macroassembler to generate a handler.
<span class="line-modified"> 2053   C2_MacroAssembler _masm(&amp;cbuf);</span>
 2054   address base = __ start_a_stub(size_deopt_handler());
 2055   if (base == NULL) {
 2056     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2057     return 0;  // CodeBuffer::expand failed
 2058   }
 2059   int offset = __ offset();
 2060 
 2061   __ adr(lr, __ pc());
 2062   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2063 
 2064   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2065   __ end_a_stub();
 2066   return offset;
 2067 }
 2068 
 2069 // REQUIRED MATCHER CODE
 2070 
 2071 //=============================================================================
 2072 
 2073 const bool Matcher::match_rule_supported(int opcode) {
</pre>
<hr />
<pre>
 2399     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2400     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2401     return true;
 2402   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2403              // Are there other uses besides address expressions?
 2404              !is_visited(off)) {
 2405     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2406     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2407     mstack.push(off-&gt;in(1), Pre_Visit);
 2408     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2409     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2410     return true;
 2411   }
 2412   return false;
 2413 }
 2414 
 2415 void Compile::reshape_address(AddPNode* addp) {
 2416 }
 2417 
 2418 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
<span class="line-modified"> 2419   C2_MacroAssembler _masm(&amp;cbuf);                                       \</span>
 2420   {                                                                     \
 2421     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2422     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2423     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2424     __ INSN(REG, as_Register(BASE));                                    \
 2425   }
 2426 
 2427 
 2428 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2429   {
 2430     Address::extend scale;
 2431 
 2432     // Hooboy, this is fugly.  We need a way to communicate to the
 2433     // encoder that the index needs to be sign extended, so we have to
 2434     // enumerate all the cases.
 2435     switch (opcode) {
 2436     case INDINDEXSCALEDI2L:
 2437     case INDINDEXSCALEDI2LN:
 2438     case INDINDEXI2L:
 2439     case INDINDEXI2LN:
</pre>
<hr />
<pre>
 2444     }
 2445 
 2446     if (index == -1) {
 2447       return Address(base, disp);
 2448     } else {
 2449       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2450       return Address(base, as_Register(index), scale);
 2451     }
 2452   }
 2453 
 2454 
 2455 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2456 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2457 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2458 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2459                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2460 
 2461   // Used for all non-volatile memory accesses.  The use of
 2462   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2463   // offsets is something of a kludge.
<span class="line-modified"> 2464   static void loadStore(C2_MacroAssembler masm, mem_insn insn,</span>
 2465                         Register reg, int opcode,
 2466                         Register base, int index, int scale, int disp,
 2467                         int size_in_memory)
 2468   {
 2469     Address addr = mem2address(opcode, base, index, scale, disp);
 2470     if (addr.getMode() == Address::base_plus_offset) {
 2471       /* If we get an out-of-range offset it is a bug in the compiler,
 2472          so we assert here. */
 2473       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2474              &quot;c2 compiler bug&quot;);
 2475       /* Fix up any out-of-range offsets. */
 2476       assert_different_registers(rscratch1, base);
 2477       assert_different_registers(rscratch1, reg);
 2478       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2479     }
 2480     (masm.*insn)(reg, addr);
 2481   }
 2482 
<span class="line-modified"> 2483   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,</span>
 2484                         FloatRegister reg, int opcode,
 2485                         Register base, int index, int size, int disp,
 2486                         int size_in_memory)
 2487   {
 2488     Address::extend scale;
 2489 
 2490     switch (opcode) {
 2491     case INDINDEXSCALEDI2L:
 2492     case INDINDEXSCALEDI2LN:
 2493       scale = Address::sxtw(size);
 2494       break;
 2495     default:
 2496       scale = Address::lsl(size);
 2497     }
 2498 
 2499     if (index == -1) {
 2500       /* If we get an out-of-range offset it is a bug in the compiler,
 2501          so we assert here. */
 2502       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2503       /* Fix up any out-of-range offsets. */
 2504       assert_different_registers(rscratch1, base);
 2505       Address addr = Address(base, disp);
 2506       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2507       (masm.*insn)(reg, addr);
 2508     } else {
 2509       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2510       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2511     }
 2512   }
 2513 
<span class="line-modified"> 2514   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,</span>
 2515                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2516                         int opcode, Register base, int index, int size, int disp)
 2517   {
 2518     if (index == -1) {
 2519       (masm.*insn)(reg, T, Address(base, disp));
 2520     } else {
 2521       assert(disp == 0, &quot;unsupported address mode&quot;);
 2522       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2523     }
 2524   }
 2525 
 2526 %}
 2527 
 2528 
 2529 
 2530 //----------ENCODING BLOCK-----------------------------------------------------
 2531 // This block specifies the encoding classes used by the compiler to
 2532 // output byte streams.  Encoding classes are parameterized macros
 2533 // used by Machine Instruction Nodes in order to generate the bit
 2534 // encoding of the instruction.  Operands specify their base encoding
</pre>
<hr />
<pre>
 2547 //
 2548 // Instructions specify two basic values for encoding.  Again, a
 2549 // function is available to check if the constant displacement is an
 2550 // oop. They use the ins_encode keyword to specify their encoding
 2551 // classes (which must be a sequence of enc_class names, and their
 2552 // parameters, specified in the encoding block), and they use the
 2553 // opcode keyword to specify, in order, their primary, secondary, and
 2554 // tertiary opcode.  Only the opcode sections which a particular
 2555 // instruction needs for encoding need to be specified.
 2556 encode %{
 2557   // Build emit functions for each basic byte or larger field in the
 2558   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2559   // from C++ code in the enc_class source block.  Emit functions will
 2560   // live in the main source block for now.  In future, we can
 2561   // generalize this by adding a syntax that specifies the sizes of
 2562   // fields in an order, so that the adlc can build the emit functions
 2563   // automagically
 2564 
 2565   // catch all for unimplemented encodings
 2566   enc_class enc_unimplemented %{
<span class="line-modified"> 2567     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2568     __ unimplemented(&quot;C2 catch all&quot;);
 2569   %}
 2570 
 2571   // BEGIN Non-volatile memory access
 2572 
 2573   // This encoding class is generated automatically from ad_encode.m4.
 2574   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2575   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2576     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2577     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),</span>
 2578                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2579   %}
 2580 
 2581   // This encoding class is generated automatically from ad_encode.m4.
 2582   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2583   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2584     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2585     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),</span>
 2586                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2587   %}
 2588 
 2589   // This encoding class is generated automatically from ad_encode.m4.
 2590   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2591   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2592     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2593     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2594                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2595   %}
 2596 
 2597   // This encoding class is generated automatically from ad_encode.m4.
 2598   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2599   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2600     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2601     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),</span>
 2602                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2603   %}
 2604 
 2605   // This encoding class is generated automatically from ad_encode.m4.
 2606   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2607   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2608     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2609     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),</span>
 2610                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2611   %}
 2612 
 2613   // This encoding class is generated automatically from ad_encode.m4.
 2614   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2615   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2616     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2617     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),</span>
 2618                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2619   %}
 2620 
 2621   // This encoding class is generated automatically from ad_encode.m4.
 2622   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2623   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2624     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2625     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2626                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2627   %}
 2628 
 2629   // This encoding class is generated automatically from ad_encode.m4.
 2630   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2631   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2632     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2633     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),</span>
 2634                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2635   %}
 2636 
 2637   // This encoding class is generated automatically from ad_encode.m4.
 2638   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2639   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2640     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2641     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2642                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2643   %}
 2644 
 2645   // This encoding class is generated automatically from ad_encode.m4.
 2646   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2647   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2648     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2649     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),</span>
 2650                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2651   %}
 2652 
 2653   // This encoding class is generated automatically from ad_encode.m4.
 2654   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2655   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2656     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2657     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),</span>
 2658                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2659   %}
 2660 
 2661   // This encoding class is generated automatically from ad_encode.m4.
 2662   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2663   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2664     Register dst_reg = as_Register($dst$$reg);
<span class="line-modified"> 2665     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),</span>
 2666                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2667   %}
 2668 
 2669   // This encoding class is generated automatically from ad_encode.m4.
 2670   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2671   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2672     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2673     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),</span>
 2674                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2675   %}
 2676 
 2677   // This encoding class is generated automatically from ad_encode.m4.
 2678   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2679   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2680     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2681     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),</span>
 2682                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2683   %}
 2684 
 2685   // This encoding class is generated automatically from ad_encode.m4.
 2686   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2687   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2688     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2689     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),</span>
 2690                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2691   %}
 2692 
 2693   // This encoding class is generated automatically from ad_encode.m4.
 2694   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2695   enc_class aarch64_enc_strb0(memory1 mem) %{
<span class="line-modified"> 2696     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2697     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2698                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2699   %}
 2700 
 2701   // This encoding class is generated automatically from ad_encode.m4.
 2702   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2703   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2704     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2705     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),</span>
 2706                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2707   %}
 2708 
 2709   // This encoding class is generated automatically from ad_encode.m4.
 2710   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2711   enc_class aarch64_enc_strh0(memory2 mem) %{
<span class="line-modified"> 2712     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2713     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2714                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2715   %}
 2716 
 2717   // This encoding class is generated automatically from ad_encode.m4.
 2718   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2719   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2720     Register src_reg = as_Register($src$$reg);
<span class="line-modified"> 2721     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),</span>
 2722                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2723   %}
 2724 
 2725   // This encoding class is generated automatically from ad_encode.m4.
 2726   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2727   enc_class aarch64_enc_strw0(memory4 mem) %{
<span class="line-modified"> 2728     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2729     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2730                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2731   %}
 2732 
 2733   // This encoding class is generated automatically from ad_encode.m4.
 2734   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2735   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2736     Register src_reg = as_Register($src$$reg);
 2737     // we sometimes get asked to store the stack pointer into the
 2738     // current thread -- we cannot do that directly on AArch64
 2739     if (src_reg == r31_sp) {
<span class="line-modified"> 2740       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2741       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2742       __ mov(rscratch2, sp);
 2743       src_reg = rscratch2;
 2744     }
<span class="line-modified"> 2745     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),</span>
 2746                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2747   %}
 2748 
 2749   // This encoding class is generated automatically from ad_encode.m4.
 2750   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2751   enc_class aarch64_enc_str0(memory8 mem) %{
<span class="line-modified"> 2752     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2753     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2754                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2755   %}
 2756 
 2757   // This encoding class is generated automatically from ad_encode.m4.
 2758   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2759   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2760     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2761     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),</span>
 2762                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2763   %}
 2764 
 2765   // This encoding class is generated automatically from ad_encode.m4.
 2766   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2767   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2768     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2769     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),</span>
 2770                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2771   %}
 2772 
 2773   // This encoding class is generated automatically from ad_encode.m4.
 2774   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2775   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
<span class="line-modified"> 2776     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2777     address con = (address)$src$$constant;
 2778     // need to do this the hard way until we can manage relocs
 2779     // for 32 bit constants
 2780     __ movoop(rscratch2, (jobject)con);
 2781     if (con) __ encode_heap_oop_not_null(rscratch2);
 2782     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2783                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2784   %}
 2785 
 2786   // This encoding class is generated automatically from ad_encode.m4.
 2787   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2788   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
<span class="line-modified"> 2789     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2790     address con = (address)$src$$constant;
 2791     // need to do this the hard way until we can manage relocs
 2792     // for 32 bit constants
 2793     __ movoop(rscratch2, (jobject)con);
 2794     __ encode_klass_not_null(rscratch2);
 2795     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2796                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2797   %}
 2798 
 2799   // This encoding class is generated automatically from ad_encode.m4.
 2800   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2801   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
<span class="line-modified"> 2802       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2803       __ membar(Assembler::StoreStore);
 2804       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2805                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2806   %}
 2807 
 2808   // END Non-volatile memory access
 2809 
 2810   // Vector loads and stores
 2811   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2812     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2813     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,</span>
 2814        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2815   %}
 2816 
 2817   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2818     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2819     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,</span>
 2820        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2821   %}
 2822 
 2823   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2824     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
<span class="line-modified"> 2825     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,</span>
 2826        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2827   %}
 2828 
 2829   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2830     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2831     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,</span>
 2832        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2833   %}
 2834 
 2835   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2836     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2837     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,</span>
 2838        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2839   %}
 2840 
 2841   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2842     FloatRegister src_reg = as_FloatRegister($src$$reg);
<span class="line-modified"> 2843     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,</span>
 2844        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2845   %}
 2846 
 2847   // volatile loads and stores
 2848 
 2849   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2850     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2851                  rscratch1, stlrb);
 2852   %}
 2853 
 2854   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2855     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2856                  rscratch1, stlrh);
 2857   %}
 2858 
 2859   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2860     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2861                  rscratch1, stlrw);
 2862   %}
 2863 
</pre>
<hr />
<pre>
 2925              rscratch1, ldar);
 2926   %}
 2927 
 2928   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2929     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930              rscratch1, ldarw);
 2931     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2935     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2936              rscratch1, ldar);
 2937     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2938   %}
 2939 
 2940   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2941     Register src_reg = as_Register($src$$reg);
 2942     // we sometimes get asked to store the stack pointer into the
 2943     // current thread -- we cannot do that directly on AArch64
 2944     if (src_reg == r31_sp) {
<span class="line-modified"> 2945       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2946       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2947       __ mov(rscratch2, sp);
 2948       src_reg = rscratch2;
 2949     }
 2950     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2951                  rscratch1, stlr);
 2952   %}
 2953 
 2954   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2955     {
<span class="line-modified"> 2956       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2957       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2958       __ fmovs(rscratch2, src_reg);
 2959     }
 2960     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2961                  rscratch1, stlrw);
 2962   %}
 2963 
 2964   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2965     {
<span class="line-modified"> 2966       C2_MacroAssembler _masm(&amp;cbuf);</span>
 2967       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2968       __ fmovd(rscratch2, src_reg);
 2969     }
 2970     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2971                  rscratch1, stlr);
 2972   %}
 2973 
 2974   // synchronized read/update encodings
 2975 
 2976   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
<span class="line-modified"> 2977     C2_MacroAssembler _masm(&amp;cbuf);</span>
 2978     Register dst_reg = as_Register($dst$$reg);
 2979     Register base = as_Register($mem$$base);
 2980     int index = $mem$$index;
 2981     int scale = $mem$$scale;
 2982     int disp = $mem$$disp;
 2983     if (index == -1) {
 2984        if (disp != 0) {
 2985         __ lea(rscratch1, Address(base, disp));
 2986         __ ldaxr(dst_reg, rscratch1);
 2987       } else {
 2988         // TODO
 2989         // should we ever get anything other than this case?
 2990         __ ldaxr(dst_reg, base);
 2991       }
 2992     } else {
 2993       Register index_reg = as_Register(index);
 2994       if (disp == 0) {
 2995         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2996         __ ldaxr(dst_reg, rscratch1);
 2997       } else {
 2998         __ lea(rscratch1, Address(base, disp));
 2999         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3000         __ ldaxr(dst_reg, rscratch1);
 3001       }
 3002     }
 3003   %}
 3004 
 3005   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
<span class="line-modified"> 3006     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3007     Register src_reg = as_Register($src$$reg);
 3008     Register base = as_Register($mem$$base);
 3009     int index = $mem$$index;
 3010     int scale = $mem$$scale;
 3011     int disp = $mem$$disp;
 3012     if (index == -1) {
 3013        if (disp != 0) {
 3014         __ lea(rscratch2, Address(base, disp));
 3015         __ stlxr(rscratch1, src_reg, rscratch2);
 3016       } else {
 3017         // TODO
 3018         // should we ever get anything other than this case?
 3019         __ stlxr(rscratch1, src_reg, base);
 3020       }
 3021     } else {
 3022       Register index_reg = as_Register(index);
 3023       if (disp == 0) {
 3024         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3025         __ stlxr(rscratch1, src_reg, rscratch2);
 3026       } else {
 3027         __ lea(rscratch2, Address(base, disp));
 3028         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3029         __ stlxr(rscratch1, src_reg, rscratch2);
 3030       }
 3031     }
 3032     __ cmpw(rscratch1, zr);
 3033   %}
 3034 
 3035   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<span class="line-modified"> 3036     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3037     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3038     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3039                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3040                /*weak*/ false, noreg);
 3041   %}
 3042 
 3043   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3044     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3045     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3046     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3047                Assembler::word, /*acquire*/ false, /*release*/ true,
 3048                /*weak*/ false, noreg);
 3049   %}
 3050 
 3051   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3052     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3053     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3054     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3055                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3056                /*weak*/ false, noreg);
 3057   %}
 3058 
 3059   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3060     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3061     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3062     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3063                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3064                /*weak*/ false, noreg);
 3065   %}
 3066 
 3067 
 3068   // The only difference between aarch64_enc_cmpxchg and
 3069   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3070   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3071   // lock.
 3072   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
<span class="line-modified"> 3073     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3074     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3075     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3076                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3077                /*weak*/ false, noreg);
 3078   %}
 3079 
 3080   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3081     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3082     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3083     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3084                Assembler::word, /*acquire*/ true, /*release*/ true,
 3085                /*weak*/ false, noreg);
 3086   %}
 3087 
 3088   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3089     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3090     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3091     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3092                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3093                /*weak*/ false, noreg);
 3094   %}
 3095 
 3096   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
<span class="line-modified"> 3097     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3098     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3099     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3100                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3101                /*weak*/ false, noreg);
 3102   %}
 3103 
 3104   // auxiliary used for CompareAndSwapX to set result register
 3105   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
<span class="line-modified"> 3106     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3107     Register res_reg = as_Register($res$$reg);
 3108     __ cset(res_reg, Assembler::EQ);
 3109   %}
 3110 
 3111   // prefetch encodings
 3112 
 3113   enc_class aarch64_enc_prefetchw(memory mem) %{
<span class="line-modified"> 3114     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3115     Register base = as_Register($mem$$base);
 3116     int index = $mem$$index;
 3117     int scale = $mem$$scale;
 3118     int disp = $mem$$disp;
 3119     if (index == -1) {
 3120       __ prfm(Address(base, disp), PSTL1KEEP);
 3121     } else {
 3122       Register index_reg = as_Register(index);
 3123       if (disp == 0) {
 3124         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3125       } else {
 3126         __ lea(rscratch1, Address(base, disp));
 3127 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3128       }
 3129     }
 3130   %}
 3131 
 3132   /// mov envcodings
 3133 
 3134   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
<span class="line-modified"> 3135     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3136     u_int32_t con = (u_int32_t)$src$$constant;
 3137     Register dst_reg = as_Register($dst$$reg);
 3138     if (con == 0) {
 3139       __ movw(dst_reg, zr);
 3140     } else {
 3141       __ movw(dst_reg, con);
 3142     }
 3143   %}
 3144 
 3145   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
<span class="line-modified"> 3146     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3147     Register dst_reg = as_Register($dst$$reg);
 3148     u_int64_t con = (u_int64_t)$src$$constant;
 3149     if (con == 0) {
 3150       __ mov(dst_reg, zr);
 3151     } else {
 3152       __ mov(dst_reg, con);
 3153     }
 3154   %}
 3155 
 3156   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
<span class="line-modified"> 3157     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3158     Register dst_reg = as_Register($dst$$reg);
 3159     address con = (address)$src$$constant;
 3160     if (con == NULL || con == (address)1) {
 3161       ShouldNotReachHere();
 3162     } else {
 3163       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3164       if (rtype == relocInfo::oop_type) {
 3165         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3166       } else if (rtype == relocInfo::metadata_type) {
 3167         __ mov_metadata(dst_reg, (Metadata*)con);
 3168       } else {
 3169         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3170         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3171           __ mov(dst_reg, con);
 3172         } else {
 3173           unsigned long offset;
 3174           __ adrp(dst_reg, con, offset);
 3175           __ add(dst_reg, dst_reg, offset);
 3176         }
 3177       }
 3178     }
 3179   %}
 3180 
 3181   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
<span class="line-modified"> 3182     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3183     Register dst_reg = as_Register($dst$$reg);
 3184     __ mov(dst_reg, zr);
 3185   %}
 3186 
 3187   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
<span class="line-modified"> 3188     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3189     Register dst_reg = as_Register($dst$$reg);
 3190     __ mov(dst_reg, (u_int64_t)1);
 3191   %}
 3192 
 3193   enc_class aarch64_enc_mov_poll_page(iRegP dst, immPollPage src) %{
<span class="line-modified"> 3194     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3195     address page = (address)$src$$constant;
 3196     Register dst_reg = as_Register($dst$$reg);
 3197     unsigned long off;
 3198     __ adrp(dst_reg, Address(page, relocInfo::poll_type), off);
 3199     assert(off == 0, &quot;assumed offset == 0&quot;);
 3200   %}
 3201 
 3202   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
<span class="line-modified"> 3203     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3204     __ load_byte_map_base($dst$$Register);
 3205   %}
 3206 
 3207   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
<span class="line-modified"> 3208     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3209     Register dst_reg = as_Register($dst$$reg);
 3210     address con = (address)$src$$constant;
 3211     if (con == NULL) {
 3212       ShouldNotReachHere();
 3213     } else {
 3214       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3215       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3216       __ set_narrow_oop(dst_reg, (jobject)con);
 3217     }
 3218   %}
 3219 
 3220   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
<span class="line-modified"> 3221     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3222     Register dst_reg = as_Register($dst$$reg);
 3223     __ mov(dst_reg, zr);
 3224   %}
 3225 
 3226   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
<span class="line-modified"> 3227     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3228     Register dst_reg = as_Register($dst$$reg);
 3229     address con = (address)$src$$constant;
 3230     if (con == NULL) {
 3231       ShouldNotReachHere();
 3232     } else {
 3233       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3234       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3235       __ set_narrow_klass(dst_reg, (Klass *)con);
 3236     }
 3237   %}
 3238 
 3239   // arithmetic encodings
 3240 
 3241   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
<span class="line-modified"> 3242     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3243     Register dst_reg = as_Register($dst$$reg);
 3244     Register src_reg = as_Register($src1$$reg);
 3245     int32_t con = (int32_t)$src2$$constant;
 3246     // add has primary == 0, subtract has primary == 1
 3247     if ($primary) { con = -con; }
 3248     if (con &lt; 0) {
 3249       __ subw(dst_reg, src_reg, -con);
 3250     } else {
 3251       __ addw(dst_reg, src_reg, con);
 3252     }
 3253   %}
 3254 
 3255   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
<span class="line-modified"> 3256     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3257     Register dst_reg = as_Register($dst$$reg);
 3258     Register src_reg = as_Register($src1$$reg);
 3259     int32_t con = (int32_t)$src2$$constant;
 3260     // add has primary == 0, subtract has primary == 1
 3261     if ($primary) { con = -con; }
 3262     if (con &lt; 0) {
 3263       __ sub(dst_reg, src_reg, -con);
 3264     } else {
 3265       __ add(dst_reg, src_reg, con);
 3266     }
 3267   %}
 3268 
 3269   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3270     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3271    Register dst_reg = as_Register($dst$$reg);
 3272    Register src1_reg = as_Register($src1$$reg);
 3273    Register src2_reg = as_Register($src2$$reg);
 3274     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3275   %}
 3276 
 3277   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3278     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3279    Register dst_reg = as_Register($dst$$reg);
 3280    Register src1_reg = as_Register($src1$$reg);
 3281    Register src2_reg = as_Register($src2$$reg);
 3282     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3283   %}
 3284 
 3285   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3286     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3287    Register dst_reg = as_Register($dst$$reg);
 3288    Register src1_reg = as_Register($src1$$reg);
 3289    Register src2_reg = as_Register($src2$$reg);
 3290     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3291   %}
 3292 
 3293   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
<span class="line-modified"> 3294     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3295    Register dst_reg = as_Register($dst$$reg);
 3296    Register src1_reg = as_Register($src1$$reg);
 3297    Register src2_reg = as_Register($src2$$reg);
 3298     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3299   %}
 3300 
 3301   // compare instruction encodings
 3302 
 3303   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
<span class="line-modified"> 3304     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3305     Register reg1 = as_Register($src1$$reg);
 3306     Register reg2 = as_Register($src2$$reg);
 3307     __ cmpw(reg1, reg2);
 3308   %}
 3309 
 3310   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
<span class="line-modified"> 3311     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3312     Register reg = as_Register($src1$$reg);
 3313     int32_t val = $src2$$constant;
 3314     if (val &gt;= 0) {
 3315       __ subsw(zr, reg, val);
 3316     } else {
 3317       __ addsw(zr, reg, -val);
 3318     }
 3319   %}
 3320 
 3321   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
<span class="line-modified"> 3322     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3323     Register reg1 = as_Register($src1$$reg);
 3324     u_int32_t val = (u_int32_t)$src2$$constant;
 3325     __ movw(rscratch1, val);
 3326     __ cmpw(reg1, rscratch1);
 3327   %}
 3328 
 3329   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
<span class="line-modified"> 3330     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3331     Register reg1 = as_Register($src1$$reg);
 3332     Register reg2 = as_Register($src2$$reg);
 3333     __ cmp(reg1, reg2);
 3334   %}
 3335 
 3336   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
<span class="line-modified"> 3337     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3338     Register reg = as_Register($src1$$reg);
 3339     int64_t val = $src2$$constant;
 3340     if (val &gt;= 0) {
 3341       __ subs(zr, reg, val);
 3342     } else if (val != -val) {
 3343       __ adds(zr, reg, -val);
 3344     } else {
 3345     // aargh, Long.MIN_VALUE is a special case
 3346       __ orr(rscratch1, zr, (u_int64_t)val);
 3347       __ subs(zr, reg, rscratch1);
 3348     }
 3349   %}
 3350 
 3351   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
<span class="line-modified"> 3352     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3353     Register reg1 = as_Register($src1$$reg);
 3354     u_int64_t val = (u_int64_t)$src2$$constant;
 3355     __ mov(rscratch1, val);
 3356     __ cmp(reg1, rscratch1);
 3357   %}
 3358 
 3359   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
<span class="line-modified"> 3360     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3361     Register reg1 = as_Register($src1$$reg);
 3362     Register reg2 = as_Register($src2$$reg);
 3363     __ cmp(reg1, reg2);
 3364   %}
 3365 
 3366   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
<span class="line-modified"> 3367     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3368     Register reg1 = as_Register($src1$$reg);
 3369     Register reg2 = as_Register($src2$$reg);
 3370     __ cmpw(reg1, reg2);
 3371   %}
 3372 
 3373   enc_class aarch64_enc_testp(iRegP src) %{
<span class="line-modified"> 3374     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3375     Register reg = as_Register($src$$reg);
 3376     __ cmp(reg, zr);
 3377   %}
 3378 
 3379   enc_class aarch64_enc_testn(iRegN src) %{
<span class="line-modified"> 3380     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3381     Register reg = as_Register($src$$reg);
 3382     __ cmpw(reg, zr);
 3383   %}
 3384 
 3385   enc_class aarch64_enc_b(label lbl) %{
<span class="line-modified"> 3386     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3387     Label *L = $lbl$$label;
 3388     __ b(*L);
 3389   %}
 3390 
 3391   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
<span class="line-modified"> 3392     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3393     Label *L = $lbl$$label;
 3394     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3395   %}
 3396 
 3397   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
<span class="line-modified"> 3398     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3399     Label *L = $lbl$$label;
 3400     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3401   %}
 3402 
 3403   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3404   %{
 3405      Register sub_reg = as_Register($sub$$reg);
 3406      Register super_reg = as_Register($super$$reg);
 3407      Register temp_reg = as_Register($temp$$reg);
 3408      Register result_reg = as_Register($result$$reg);
 3409 
 3410      Label miss;
<span class="line-modified"> 3411      C2_MacroAssembler _masm(&amp;cbuf);</span>
 3412      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3413                                      NULL, &amp;miss,
 3414                                      /*set_cond_codes:*/ true);
 3415      if ($primary) {
 3416        __ mov(result_reg, zr);
 3417      }
 3418      __ bind(miss);
 3419   %}
 3420 
 3421   enc_class aarch64_enc_java_static_call(method meth) %{
<span class="line-modified"> 3422     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3423 
 3424     address addr = (address)$meth$$method;
 3425     address call;
 3426     if (!_method) {
 3427       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3428       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3429     } else {
 3430       int method_index = resolved_method_index(cbuf);
 3431       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3432                                                   : static_call_Relocation::spec(method_index);
 3433       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3434 
 3435       // Emit stub for static call
 3436       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3437       if (stub == NULL) {
 3438         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3439         return;
 3440       }
 3441     }
 3442     if (call == NULL) {
 3443       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3444       return;
 3445     }
 3446   %}
 3447 
 3448   enc_class aarch64_enc_java_dynamic_call(method meth) %{
<span class="line-modified"> 3449     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3450     int method_index = resolved_method_index(cbuf);
 3451     address call = __ ic_call((address)$meth$$method, method_index);
 3452     if (call == NULL) {
 3453       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3454       return;
 3455     }
 3456   %}
 3457 
 3458   enc_class aarch64_enc_call_epilog() %{
<span class="line-modified"> 3459     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3460     if (VerifyStackAtCalls) {
 3461       // Check that stack depth is unchanged: find majik cookie on stack
 3462       __ call_Unimplemented();
 3463     }
 3464   %}
 3465 
 3466   enc_class aarch64_enc_java_to_runtime(method meth) %{
<span class="line-modified"> 3467     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3468 
 3469     // some calls to generated routines (arraycopy code) are scheduled
 3470     // by C2 as runtime calls. if so we can call them using a br (they
 3471     // will be in a reachable segment) otherwise we have to use a blr
 3472     // which loads the absolute address into a register.
 3473     address entry = (address)$meth$$method;
 3474     CodeBlob *cb = CodeCache::find_blob(entry);
 3475     if (cb) {
 3476       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3477       if (call == NULL) {
 3478         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3479         return;
 3480       }
 3481     } else {
 3482       Label retaddr;
 3483       __ adr(rscratch2, retaddr);
 3484       __ lea(rscratch1, RuntimeAddress(entry));
 3485       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3486       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3487       __ blr(rscratch1);
 3488       __ bind(retaddr);
 3489       __ add(sp, sp, 2 * wordSize);
 3490     }
 3491   %}
 3492 
 3493   enc_class aarch64_enc_rethrow() %{
<span class="line-modified"> 3494     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3495     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3496   %}
 3497 
 3498   enc_class aarch64_enc_ret() %{
<span class="line-modified"> 3499     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3500     __ ret(lr);
 3501   %}
 3502 
 3503   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
<span class="line-modified"> 3504     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3505     Register target_reg = as_Register($jump_target$$reg);
 3506     __ br(target_reg);
 3507   %}
 3508 
 3509   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
<span class="line-modified"> 3510     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3511     Register target_reg = as_Register($jump_target$$reg);
 3512     // exception oop should be in r0
 3513     // ret addr has been popped into lr
 3514     // callee expects it in r3
 3515     __ mov(r3, lr);
 3516     __ br(target_reg);
 3517   %}
 3518 
 3519   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<span class="line-modified"> 3520     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3521     Register oop = as_Register($object$$reg);
 3522     Register box = as_Register($box$$reg);
 3523     Register disp_hdr = as_Register($tmp$$reg);
 3524     Register tmp = as_Register($tmp2$$reg);
 3525     Label cont;
 3526     Label object_has_monitor;
 3527     Label cas_failed;
 3528 
 3529     assert_different_registers(oop, box, tmp, disp_hdr);
 3530 
 3531     // Load markWord from object into displaced_header.
 3532     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3533 
 3534     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3535       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3536     }
 3537 
 3538     // Check for existing monitor
 3539     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3540 
</pre>
<hr />
<pre>
 3578     // otherwise m-&gt;owner may contain a thread or a stack address.
 3579     //
 3580     // Try to CAS m-&gt;owner from NULL to current thread.
 3581     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3582     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3583                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3584 
 3585     // Store a non-null value into the box to avoid looking like a re-entrant
 3586     // lock. The fast-path monitor unlock code checks for
 3587     // markWord::monitor_value so use markWord::unused_mark which has the
 3588     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3589     __ mov(tmp, (address)markWord::unused_mark().value());
 3590     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3591 
 3592     __ bind(cont);
 3593     // flag == EQ indicates success
 3594     // flag == NE indicates failure
 3595   %}
 3596 
 3597   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
<span class="line-modified"> 3598     C2_MacroAssembler _masm(&amp;cbuf);</span>
 3599     Register oop = as_Register($object$$reg);
 3600     Register box = as_Register($box$$reg);
 3601     Register disp_hdr = as_Register($tmp$$reg);
 3602     Register tmp = as_Register($tmp2$$reg);
 3603     Label cont;
 3604     Label object_has_monitor;
 3605 
 3606     assert_different_registers(oop, box, tmp, disp_hdr);
 3607 
 3608     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3609       __ biased_locking_exit(oop, tmp, cont);
 3610     }
 3611 
 3612     // Find the lock address and load the displaced header from the stack.
 3613     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3614 
 3615     // If the displaced header is 0, we have a recursive unlock.
 3616     __ cmp(disp_hdr, zr);
 3617     __ br(Assembler::EQ, cont);
 3618 
</pre>
<hr />
<pre>
 8071     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8072     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8073     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8074   %}
 8075 
 8076   ins_pipe(pipe_class_default);
 8077 %}
 8078 
 8079 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8080   predicate(UsePopCountInstruction);
 8081   match(Set dst (PopCountI (LoadI mem)));
 8082   effect(TEMP tmp);
 8083   ins_cost(INSN_COST * 13);
 8084 
 8085   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8086             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8087             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8088             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8089   ins_encode %{
 8090     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<span class="line-modified"> 8091     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),</span>
 8092               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8093     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8094     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8095     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8096   %}
 8097 
 8098   ins_pipe(pipe_class_default);
 8099 %}
 8100 
 8101 // Note: Long.bitCount(long) returns an int.
 8102 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8103   predicate(UsePopCountInstruction);
 8104   match(Set dst (PopCountL src));
 8105   effect(TEMP tmp);
 8106   ins_cost(INSN_COST * 13);
 8107 
 8108   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8109             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8110             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8111             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
</pre>
<hr />
<pre>
 8114     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8115     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8116     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8117   %}
 8118 
 8119   ins_pipe(pipe_class_default);
 8120 %}
 8121 
 8122 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8123   predicate(UsePopCountInstruction);
 8124   match(Set dst (PopCountL (LoadL mem)));
 8125   effect(TEMP tmp);
 8126   ins_cost(INSN_COST * 13);
 8127 
 8128   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8129             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8130             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8131             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8132   ins_encode %{
 8133     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
<span class="line-modified"> 8134     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),</span>
 8135               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8136     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8137     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8138     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8139   %}
 8140 
 8141   ins_pipe(pipe_class_default);
 8142 %}
 8143 
 8144 // ============================================================================
 8145 // MemBar Instruction
 8146 
 8147 instruct load_fence() %{
 8148   match(LoadFence);
 8149   ins_cost(VOLATILE_REF_COST);
 8150 
 8151   format %{ &quot;load_fence&quot; %}
 8152 
 8153   ins_encode %{
 8154     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
</pre>
<hr />
<pre>
14961 %}
14962 
14963 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14964   match(If cmp (CmpI op1 op2));
14965   effect(USE labl);
14966 
14967   ins_cost(BRANCH_COST);
14968   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14969   ins_encode %{
14970     Label* L = $labl$$label;
14971     Assembler::Condition cond =
14972       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14973     __ tbr(cond, $op1$$Register, 31, *L);
14974   %}
14975   ins_pipe(pipe_cmp_branch);
14976   ins_short_branch(1);
14977 %}
14978 
14979 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14980   match(If cmp (CmpL (AndL op1 op2) op3));
<span class="line-modified">14981   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
14982   effect(USE labl);
14983 
14984   ins_cost(BRANCH_COST);
14985   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14986   ins_encode %{
14987     Label* L = $labl$$label;
14988     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">14989     int bit = exact_log2_long($op2$$constant);</span>
14990     __ tbr(cond, $op1$$Register, bit, *L);
14991   %}
14992   ins_pipe(pipe_cmp_branch);
14993   ins_short_branch(1);
14994 %}
14995 
14996 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14997   match(If cmp (CmpI (AndI op1 op2) op3));
<span class="line-modified">14998   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
14999   effect(USE labl);
15000 
15001   ins_cost(BRANCH_COST);
15002   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15003   ins_encode %{
15004     Label* L = $labl$$label;
15005     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15006     int bit = exact_log2((juint)$op2$$constant);</span>
15007     __ tbr(cond, $op1$$Register, bit, *L);
15008   %}
15009   ins_pipe(pipe_cmp_branch);
15010   ins_short_branch(1);
15011 %}
15012 
15013 // And far variants
15014 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
15015   match(If cmp (CmpL op1 op2));
15016   effect(USE labl);
15017 
15018   ins_cost(BRANCH_COST);
15019   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
15020   ins_encode %{
15021     Label* L = $labl$$label;
15022     Assembler::Condition cond =
15023       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15024     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
15025   %}
15026   ins_pipe(pipe_cmp_branch);
15027 %}
15028 
15029 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
15030   match(If cmp (CmpI op1 op2));
15031   effect(USE labl);
15032 
15033   ins_cost(BRANCH_COST);
15034   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15035   ins_encode %{
15036     Label* L = $labl$$label;
15037     Assembler::Condition cond =
15038       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15039     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15040   %}
15041   ins_pipe(pipe_cmp_branch);
15042 %}
15043 
15044 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15045   match(If cmp (CmpL (AndL op1 op2) op3));
<span class="line-modified">15046   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));</span>
15047   effect(USE labl);
15048 
15049   ins_cost(BRANCH_COST);
15050   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15051   ins_encode %{
15052     Label* L = $labl$$label;
15053     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15054     int bit = exact_log2_long($op2$$constant);</span>
15055     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15056   %}
15057   ins_pipe(pipe_cmp_branch);
15058 %}
15059 
15060 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15061   match(If cmp (CmpI (AndI op1 op2) op3));
<span class="line-modified">15062   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));</span>
15063   effect(USE labl);
15064 
15065   ins_cost(BRANCH_COST);
15066   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15067   ins_encode %{
15068     Label* L = $labl$$label;
15069     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
<span class="line-modified">15070     int bit = exact_log2((juint)$op2$$constant);</span>
15071     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15072   %}
15073   ins_pipe(pipe_cmp_branch);
15074 %}
15075 
15076 // Test bits
15077 
15078 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15079   match(Set cr (CmpL (AndL op1 op2) op3));
15080   predicate(Assembler::operand_valid_for_logical_immediate
15081             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15082 
15083   ins_cost(INSN_COST);
15084   format %{ &quot;tst $op1, $op2 # long&quot; %}
15085   ins_encode %{
15086     __ tst($op1$$Register, $op2$$constant);
15087   %}
15088   ins_pipe(ialu_reg_reg);
15089 %}
15090 
</pre>
<hr />
<pre>
16991 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16992   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16993   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16994   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16995   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16996   ins_cost(INSN_COST);
16997   ins_encode %{
16998     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16999             as_FloatRegister($src1$$reg),
17000             as_FloatRegister($src2$$reg));
17001   %}
17002   ins_pipe(vmuldiv_fp128);
17003 %}
17004 
17005 // --------------- Vector Multiply-Add Shorts into Integer --------------------
17006 
17007 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
17008   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
17009   match(Set dst (MulAddVS2VI src1 src2));
17010   ins_cost(INSN_COST);
<span class="line-modified">17011   effect(TEMP_DEF dst, TEMP tmp);</span>
17012   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
17013             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
17014             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17015   ins_encode %{
17016     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17017               as_FloatRegister($src1$$reg),
17018               as_FloatRegister($src2$$reg));
17019     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17020               as_FloatRegister($src1$$reg),
17021               as_FloatRegister($src2$$reg));
17022     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17023              as_FloatRegister($tmp$$reg),
17024              as_FloatRegister($dst$$reg));
17025   %}
17026   ins_pipe(vmuldiv_fp128);
17027 %}
17028 
17029 // --------------------------------- DIV --------------------------------------
17030 
17031 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
</pre>
</td>
</tr>
</table>
<center><a href="../../../demo/share/jfc/TableExample/TableSorter.java.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="c1_LIRAssembler_aarch64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>