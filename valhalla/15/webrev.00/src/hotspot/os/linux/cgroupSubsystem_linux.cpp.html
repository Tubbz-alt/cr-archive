<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/os/linux/cgroupSubsystem_linux.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2019, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &lt;string.h&gt;
 26 #include &lt;math.h&gt;
 27 #include &lt;errno.h&gt;
 28 #include &quot;cgroupSubsystem_linux.hpp&quot;
 29 #include &quot;cgroupV1Subsystem_linux.hpp&quot;
 30 #include &quot;cgroupV2Subsystem_linux.hpp&quot;
 31 #include &quot;logging/log.hpp&quot;
 32 #include &quot;memory/allocation.hpp&quot;
 33 #include &quot;runtime/globals.hpp&quot;
 34 #include &quot;runtime/os.hpp&quot;
 35 #include &quot;utilities/globalDefinitions.hpp&quot;
 36 
 37 CgroupSubsystem* CgroupSubsystemFactory::create() {
 38   CgroupV1MemoryController* memory = NULL;
 39   CgroupV1Controller* cpuset = NULL;
 40   CgroupV1Controller* cpu = NULL;
 41   CgroupV1Controller* cpuacct = NULL;
 42   CgroupInfo cg_infos[CG_INFO_LENGTH];
 43   u1 cg_type_flags = INVALID_CGROUPS_GENERIC;
 44   const char* proc_cgroups = &quot;/proc/cgroups&quot;;
 45   const char* proc_self_cgroup = &quot;/proc/self/cgroup&quot;;
 46   const char* proc_self_mountinfo = &quot;/proc/self/mountinfo&quot;;
 47 
 48   bool valid_cgroup = determine_type(cg_infos, proc_cgroups, proc_self_cgroup, proc_self_mountinfo, &amp;cg_type_flags);
 49 
 50   if (!valid_cgroup) {
 51     // Could not detect cgroup type
 52     return NULL;
 53   }
 54   assert(is_valid_cgroup(&amp;cg_type_flags), &quot;Expected valid cgroup type&quot;);
 55 
 56   if (is_cgroup_v2(&amp;cg_type_flags)) {
 57     // Cgroups v2 case, we have all the info we need.
 58     // Construct the subsystem, free resources and return
 59     // Note: any index in cg_infos will do as the path is the same for
 60     //       all controllers.
 61     CgroupController* unified = new CgroupV2Controller(cg_infos[MEMORY_IDX]._mount_path, cg_infos[MEMORY_IDX]._cgroup_path);
 62     log_debug(os, container)(&quot;Detected cgroups v2 unified hierarchy&quot;);
 63     cleanup(cg_infos);
 64     return new CgroupV2Subsystem(unified);
 65   }
 66 
 67   /*
 68    * Cgroup v1 case:
 69    *
 70    * Use info gathered previously from /proc/self/cgroup
 71    * and map host mount point to
 72    * local one via /proc/self/mountinfo content above
 73    *
 74    * Docker example:
 75    * 5:memory:/docker/6558aed8fc662b194323ceab5b964f69cf36b3e8af877a14b80256e93aecb044
 76    *
 77    * Host example:
 78    * 5:memory:/user.slice
 79    *
 80    * Construct a path to the process specific memory and cpuset
 81    * cgroup directory.
 82    *
 83    * For a container running under Docker from memory example above
 84    * the paths would be:
 85    *
 86    * /sys/fs/cgroup/memory
 87    *
 88    * For a Host from memory example above the path would be:
 89    *
 90    * /sys/fs/cgroup/memory/user.slice
 91    *
 92    */
 93   assert(is_cgroup_v1(&amp;cg_type_flags), &quot;Cgroup v1 expected&quot;);
 94   for (int i = 0; i &lt; CG_INFO_LENGTH; i++) {
 95     CgroupInfo info = cg_infos[i];
 96     if (strcmp(info._name, &quot;memory&quot;) == 0) {
 97       memory = new CgroupV1MemoryController(info._root_mount_path, info._mount_path);
 98       memory-&gt;set_subsystem_path(info._cgroup_path);
 99     } else if (strcmp(info._name, &quot;cpuset&quot;) == 0) {
100       cpuset = new CgroupV1Controller(info._root_mount_path, info._mount_path);
101       cpuset-&gt;set_subsystem_path(info._cgroup_path);
102     } else if (strcmp(info._name, &quot;cpu&quot;) == 0) {
103       cpu = new CgroupV1Controller(info._root_mount_path, info._mount_path);
104       cpu-&gt;set_subsystem_path(info._cgroup_path);
105     } else if (strcmp(info._name, &quot;cpuacct&quot;) == 0) {
106       cpuacct = new CgroupV1Controller(info._root_mount_path, info._mount_path);
107       cpuacct-&gt;set_subsystem_path(info._cgroup_path);
108     }
109   }
110   cleanup(cg_infos);
111   return new CgroupV1Subsystem(cpuset, cpu, cpuacct, memory);
112 }
113 
114 bool CgroupSubsystemFactory::determine_type(CgroupInfo* cg_infos,
115                                             const char* proc_cgroups,
116                                             const char* proc_self_cgroup,
117                                             const char* proc_self_mountinfo,
118                                             u1* flags) {
119   FILE *mntinfo = NULL;
120   FILE *cgroups = NULL;
121   FILE *cgroup = NULL;
122   char buf[MAXPATHLEN+1];
123   char *p;
124   bool is_cgroupsV2;
125   // true iff all controllers, memory, cpu, cpuset, cpuacct are enabled
126   // at the kernel level.
127   bool all_controllers_enabled;
128 
129   /*
130    * Read /proc/cgroups so as to be able to distinguish cgroups v2 vs cgroups v1.
131    *
132    * For cgroups v1 hierarchy (hybrid or legacy), cpu, cpuacct, cpuset, memory controllers
133    * must have non-zero for the hierarchy ID field and relevant controllers mounted.
134    * Conversely, for cgroups v2 (unified hierarchy), cpu, cpuacct, cpuset, memory
135    * controllers must have hierarchy ID 0 and the unified controller mounted.
136    */
137   cgroups = fopen(proc_cgroups, &quot;r&quot;);
138   if (cgroups == NULL) {
139       log_debug(os, container)(&quot;Can&#39;t open %s, %s&quot;,
140                                proc_cgroups, os::strerror(errno));
141       *flags = INVALID_CGROUPS_GENERIC;
142       return false;
143   }
144 
145   while ((p = fgets(buf, MAXPATHLEN, cgroups)) != NULL) {
146     char name[MAXPATHLEN+1];
147     int  hierarchy_id;
148     int  enabled;
149 
150     // Format of /proc/cgroups documented via man 7 cgroups
151     if (sscanf(p, &quot;%s %d %*d %d&quot;, name, &amp;hierarchy_id, &amp;enabled) != 3) {
152       continue;
153     }
154     if (strcmp(name, &quot;memory&quot;) == 0) {
155       cg_infos[MEMORY_IDX]._name = os::strdup(name);
156       cg_infos[MEMORY_IDX]._hierarchy_id = hierarchy_id;
157       cg_infos[MEMORY_IDX]._enabled = (enabled == 1);
158     } else if (strcmp(name, &quot;cpuset&quot;) == 0) {
159       cg_infos[CPUSET_IDX]._name = os::strdup(name);
160       cg_infos[CPUSET_IDX]._hierarchy_id = hierarchy_id;
161       cg_infos[CPUSET_IDX]._enabled = (enabled == 1);
162     } else if (strcmp(name, &quot;cpu&quot;) == 0) {
163       cg_infos[CPU_IDX]._name = os::strdup(name);
164       cg_infos[CPU_IDX]._hierarchy_id = hierarchy_id;
165       cg_infos[CPU_IDX]._enabled = (enabled == 1);
166     } else if (strcmp(name, &quot;cpuacct&quot;) == 0) {
167       cg_infos[CPUACCT_IDX]._name = os::strdup(name);
168       cg_infos[CPUACCT_IDX]._hierarchy_id = hierarchy_id;
169       cg_infos[CPUACCT_IDX]._enabled = (enabled == 1);
170     }
171   }
172   fclose(cgroups);
173 
174   is_cgroupsV2 = true;
175   all_controllers_enabled = true;
176   for (int i = 0; i &lt; CG_INFO_LENGTH; i++) {
177     is_cgroupsV2 = is_cgroupsV2 &amp;&amp; cg_infos[i]._hierarchy_id == 0;
178     all_controllers_enabled = all_controllers_enabled &amp;&amp; cg_infos[i]._enabled;
179   }
180 
181   if (!all_controllers_enabled) {
182     // one or more controllers disabled, disable container support
183     log_debug(os, container)(&quot;One or more required controllers disabled at kernel level.&quot;);
184     cleanup(cg_infos);
185     *flags = INVALID_CGROUPS_GENERIC;
186     return false;
187   }
188 
189   /*
190    * Read /proc/self/cgroup and determine:
191    *  - the cgroup path for cgroups v2 or
192    *  - on a cgroups v1 system, collect info for mapping
193    *    the host mount point to the local one via /proc/self/mountinfo below.
194    */
195   cgroup = fopen(proc_self_cgroup, &quot;r&quot;);
196   if (cgroup == NULL) {
197     log_debug(os, container)(&quot;Can&#39;t open %s, %s&quot;,
198                              proc_self_cgroup, os::strerror(errno));
199     cleanup(cg_infos);
200     *flags = INVALID_CGROUPS_GENERIC;
201     return false;
202   }
203 
204   while ((p = fgets(buf, MAXPATHLEN, cgroup)) != NULL) {
205     char *controllers;
206     char *token;
207     char *hierarchy_id_str;
208     int  hierarchy_id;
209     char *cgroup_path;
210 
211     hierarchy_id_str = strsep(&amp;p, &quot;:&quot;);
212     hierarchy_id = atoi(hierarchy_id_str);
213     /* Get controllers and base */
214     controllers = strsep(&amp;p, &quot;:&quot;);
215     cgroup_path = strsep(&amp;p, &quot;\n&quot;);
216 
217     if (controllers == NULL) {
218       continue;
219     }
220 
221     while (!is_cgroupsV2 &amp;&amp; (token = strsep(&amp;controllers, &quot;,&quot;)) != NULL) {
222       if (strcmp(token, &quot;memory&quot;) == 0) {
223         assert(hierarchy_id == cg_infos[MEMORY_IDX]._hierarchy_id, &quot;/proc/cgroups and /proc/self/cgroup hierarchy mismatch&quot;);
224         cg_infos[MEMORY_IDX]._cgroup_path = os::strdup(cgroup_path);
225       } else if (strcmp(token, &quot;cpuset&quot;) == 0) {
226         assert(hierarchy_id == cg_infos[CPUSET_IDX]._hierarchy_id, &quot;/proc/cgroups and /proc/self/cgroup hierarchy mismatch&quot;);
227         cg_infos[CPUSET_IDX]._cgroup_path = os::strdup(cgroup_path);
228       } else if (strcmp(token, &quot;cpu&quot;) == 0) {
229         assert(hierarchy_id == cg_infos[CPU_IDX]._hierarchy_id, &quot;/proc/cgroups and /proc/self/cgroup hierarchy mismatch&quot;);
230         cg_infos[CPU_IDX]._cgroup_path = os::strdup(cgroup_path);
231       } else if (strcmp(token, &quot;cpuacct&quot;) == 0) {
232         assert(hierarchy_id == cg_infos[CPUACCT_IDX]._hierarchy_id, &quot;/proc/cgroups and /proc/self/cgroup hierarchy mismatch&quot;);
233         cg_infos[CPUACCT_IDX]._cgroup_path = os::strdup(cgroup_path);
234       }
235     }
236     if (is_cgroupsV2) {
237       for (int i = 0; i &lt; CG_INFO_LENGTH; i++) {
238         cg_infos[i]._cgroup_path = os::strdup(cgroup_path);
239       }
240     }
241   }
242   fclose(cgroup);
243 
244   // Find various mount points by reading /proc/self/mountinfo
245   // mountinfo format is documented at https://www.kernel.org/doc/Documentation/filesystems/proc.txt
246   mntinfo = fopen(proc_self_mountinfo, &quot;r&quot;);
247   if (mntinfo == NULL) {
248       log_debug(os, container)(&quot;Can&#39;t open %s, %s&quot;,
249                                proc_self_mountinfo, os::strerror(errno));
250       cleanup(cg_infos);
251       *flags = INVALID_CGROUPS_GENERIC;
252       return false;
253   }
254 
255   bool cgroupv2_mount_point_found = false;
256   bool any_cgroup_mounts_found = false;
257   while ((p = fgets(buf, MAXPATHLEN, mntinfo)) != NULL) {
258     char tmp_mount_point[MAXPATHLEN+1];
259     char tmp_fs_type[MAXPATHLEN+1];
260     char tmproot[MAXPATHLEN+1];
261     char tmpmount[MAXPATHLEN+1];
262     char tmpcgroups[MAXPATHLEN+1];
263     char *cptr = tmpcgroups;
264     char *token;
265 
266     // Cgroup v2 relevant info. We only look for the _mount_path iff is_cgroupsV2 so
267     // as to avoid memory stomping of the _mount_path pointer later on in the cgroup v1
268     // block in the hybrid case.
269     //
270     if (is_cgroupsV2 &amp;&amp; sscanf(p, &quot;%*d %*d %*d:%*d %*s %s %*[^-]- %s cgroup2 %*s&quot;, tmp_mount_point, tmp_fs_type) == 2) {
271       // we likely have an early match return (e.g. cgroup fs match), be sure we have cgroup2 as fstype
272       if (!cgroupv2_mount_point_found &amp;&amp; strcmp(&quot;cgroup2&quot;, tmp_fs_type) == 0) {
273         cgroupv2_mount_point_found = true;
274         any_cgroup_mounts_found = true;
275         for (int i = 0; i &lt; CG_INFO_LENGTH; i++) {
276           assert(cg_infos[i]._mount_path == NULL, &quot;_mount_path memory stomping&quot;);
277           cg_infos[i]._mount_path = os::strdup(tmp_mount_point);
278         }
279       }
280     }
281 
282     /* Cgroup v1 relevant info
283      *
284      * Find the cgroup mount point for memory, cpuset, cpu, cpuacct
285      *
286      * Example for docker:
287      * 219 214 0:29 /docker/7208cebd00fa5f2e342b1094f7bed87fa25661471a4637118e65f1c995be8a34 /sys/fs/cgroup/memory ro,nosuid,nodev,noexec,relatime - cgroup cgroup rw,memory
288      *
289      * Example for host:
290      * 34 28 0:29 / /sys/fs/cgroup/memory rw,nosuid,nodev,noexec,relatime shared:16 - cgroup cgroup rw,memory
291      */
292     if (sscanf(p, &quot;%*d %*d %*d:%*d %s %s %*[^-]- %s cgroup %s&quot;, tmproot, tmpmount, tmp_fs_type, tmpcgroups) == 4) {
293       if (strcmp(&quot;cgroup&quot;, tmp_fs_type) != 0) {
294         // Skip cgroup2 fs lines on hybrid or unified hierarchy.
295         continue;
296       }
297       any_cgroup_mounts_found = true;
298       while ((token = strsep(&amp;cptr, &quot;,&quot;)) != NULL) {
299         if (strcmp(token, &quot;memory&quot;) == 0) {
300           assert(cg_infos[MEMORY_IDX]._mount_path == NULL, &quot;stomping of _mount_path&quot;);
301           cg_infos[MEMORY_IDX]._mount_path = os::strdup(tmpmount);
302           cg_infos[MEMORY_IDX]._root_mount_path = os::strdup(tmproot);
303           cg_infos[MEMORY_IDX]._data_complete = true;
304         } else if (strcmp(token, &quot;cpuset&quot;) == 0) {
305           assert(cg_infos[CPUSET_IDX]._mount_path == NULL, &quot;stomping of _mount_path&quot;);
306           cg_infos[CPUSET_IDX]._mount_path = os::strdup(tmpmount);
307           cg_infos[CPUSET_IDX]._root_mount_path = os::strdup(tmproot);
308           cg_infos[CPUSET_IDX]._data_complete = true;
309         } else if (strcmp(token, &quot;cpu&quot;) == 0) {
310           assert(cg_infos[CPU_IDX]._mount_path == NULL, &quot;stomping of _mount_path&quot;);
311           cg_infos[CPU_IDX]._mount_path = os::strdup(tmpmount);
312           cg_infos[CPU_IDX]._root_mount_path = os::strdup(tmproot);
313           cg_infos[CPU_IDX]._data_complete = true;
314         } else if (strcmp(token, &quot;cpuacct&quot;) == 0) {
315           assert(cg_infos[CPUACCT_IDX]._mount_path == NULL, &quot;stomping of _mount_path&quot;);
316           cg_infos[CPUACCT_IDX]._mount_path = os::strdup(tmpmount);
317           cg_infos[CPUACCT_IDX]._root_mount_path = os::strdup(tmproot);
318           cg_infos[CPUACCT_IDX]._data_complete = true;
319         }
320       }
321     }
322   }
323   fclose(mntinfo);
324 
325   // Neither cgroup2 nor cgroup filesystems mounted via /proc/self/mountinfo
326   // No point in continuing.
327   if (!any_cgroup_mounts_found) {
328     log_trace(os, container)(&quot;No cgroup controllers mounted.&quot;);
329     cleanup(cg_infos);
330     *flags = INVALID_CGROUPS_NO_MOUNT;
331     return false;
332   }
333 
334   if (is_cgroupsV2) {
335     if (!cgroupv2_mount_point_found) {
336       log_trace(os, container)(&quot;Mount point for cgroupv2 not found in /proc/self/mountinfo&quot;);
337       cleanup(cg_infos);
338       *flags = INVALID_CGROUPS_V2;
339       return false;
340     }
341     // Cgroups v2 case, we have all the info we need.
342     *flags = CGROUPS_V2;
343     return true;
344   }
345 
346   // What follows is cgroups v1
347   log_debug(os, container)(&quot;Detected cgroups hybrid or legacy hierarchy, using cgroups v1 controllers&quot;);
348 
349   if (!cg_infos[MEMORY_IDX]._data_complete) {
350     log_debug(os, container)(&quot;Required cgroup v1 memory subsystem not found&quot;);
351     cleanup(cg_infos);
352     *flags = INVALID_CGROUPS_V1;
353     return false;
354   }
355   if (!cg_infos[CPUSET_IDX]._data_complete) {
356     log_debug(os, container)(&quot;Required cgroup v1 cpuset subsystem not found&quot;);
357     cleanup(cg_infos);
358     *flags = INVALID_CGROUPS_V1;
359     return false;
360   }
361   if (!cg_infos[CPU_IDX]._data_complete) {
362     log_debug(os, container)(&quot;Required cgroup v1 cpu subsystem not found&quot;);
363     cleanup(cg_infos);
364     *flags = INVALID_CGROUPS_V1;
365     return false;
366   }
367   if (!cg_infos[CPUACCT_IDX]._data_complete) {
368     log_debug(os, container)(&quot;Required cgroup v1 cpuacct subsystem not found&quot;);
369     cleanup(cg_infos);
370     *flags = INVALID_CGROUPS_V1;
371     return false;
372   }
373   // Cgroups v1 case, we have all the info we need.
374   *flags = CGROUPS_V1;
375   return true;
376 
377 };
378 
379 void CgroupSubsystemFactory::cleanup(CgroupInfo* cg_infos) {
380   assert(cg_infos != NULL, &quot;Invariant&quot;);
381   for (int i = 0; i &lt; CG_INFO_LENGTH; i++) {
382     os::free(cg_infos[i]._name);
383     os::free(cg_infos[i]._cgroup_path);
384     os::free(cg_infos[i]._root_mount_path);
385     os::free(cg_infos[i]._mount_path);
386   }
387 }
388 
389 /* active_processor_count
390  *
391  * Calculate an appropriate number of active processors for the
392  * VM to use based on these three inputs.
393  *
394  * cpu affinity
395  * cgroup cpu quota &amp; cpu period
396  * cgroup cpu shares
397  *
398  * Algorithm:
399  *
400  * Determine the number of available CPUs from sched_getaffinity
401  *
402  * If user specified a quota (quota != -1), calculate the number of
403  * required CPUs by dividing quota by period.
404  *
405  * If shares are in effect (shares != -1), calculate the number
406  * of CPUs required for the shares by dividing the share value
407  * by PER_CPU_SHARES.
408  *
409  * All results of division are rounded up to the next whole number.
410  *
411  * If neither shares or quotas have been specified, return the
412  * number of active processors in the system.
413  *
414  * If both shares and quotas have been specified, the results are
415  * based on the flag PreferContainerQuotaForCPUCount.  If true,
416  * return the quota value.  If false return the smallest value
417  * between shares or quotas.
418  *
419  * If shares and/or quotas have been specified, the resulting number
420  * returned will never exceed the number of active processors.
421  *
422  * return:
423  *    number of CPUs
424  */
425 int CgroupSubsystem::active_processor_count() {
426   int quota_count = 0, share_count = 0;
427   int cpu_count, limit_count;
428   int result;
429 
430   // We use a cache with a timeout to avoid performing expensive
431   // computations in the event this function is called frequently.
432   // [See 8227006].
433   CachingCgroupController* contrl = cpu_controller();
434   CachedMetric* cpu_limit = contrl-&gt;metrics_cache();
435   if (!cpu_limit-&gt;should_check_metric()) {
436     int val = (int)cpu_limit-&gt;value();
437     log_trace(os, container)(&quot;CgroupSubsystem::active_processor_count (cached): %d&quot;, val);
438     return val;
439   }
440 
441   cpu_count = limit_count = os::Linux::active_processor_count();
442   int quota  = cpu_quota();
443   int period = cpu_period();
444   int share  = cpu_shares();
445 
446   if (quota &gt; -1 &amp;&amp; period &gt; 0) {
447     quota_count = ceilf((float)quota / (float)period);
448     log_trace(os, container)(&quot;CPU Quota count based on quota/period: %d&quot;, quota_count);
449   }
450   if (share &gt; -1) {
451     share_count = ceilf((float)share / (float)PER_CPU_SHARES);
452     log_trace(os, container)(&quot;CPU Share count based on shares: %d&quot;, share_count);
453   }
454 
455   // If both shares and quotas are setup results depend
456   // on flag PreferContainerQuotaForCPUCount.
457   // If true, limit CPU count to quota
458   // If false, use minimum of shares and quotas
459   if (quota_count !=0 &amp;&amp; share_count != 0) {
460     if (PreferContainerQuotaForCPUCount) {
461       limit_count = quota_count;
462     } else {
463       limit_count = MIN2(quota_count, share_count);
464     }
465   } else if (quota_count != 0) {
466     limit_count = quota_count;
467   } else if (share_count != 0) {
468     limit_count = share_count;
469   }
470 
471   result = MIN2(cpu_count, limit_count);
472   log_trace(os, container)(&quot;OSContainer::active_processor_count: %d&quot;, result);
473 
474   // Update cached metric to avoid re-reading container settings too often
475   cpu_limit-&gt;set_value(result, OSCONTAINER_CACHE_TIMEOUT);
476 
477   return result;
478 }
479 
480 /* memory_limit_in_bytes
481  *
482  * Return the limit of available memory for this process.
483  *
484  * return:
485  *    memory limit in bytes or
486  *    -1 for unlimited
487  *    OSCONTAINER_ERROR for not supported
488  */
489 jlong CgroupSubsystem::memory_limit_in_bytes() {
490   CachingCgroupController* contrl = memory_controller();
491   CachedMetric* memory_limit = contrl-&gt;metrics_cache();
492   if (!memory_limit-&gt;should_check_metric()) {
493     return memory_limit-&gt;value();
494   }
495   jlong mem_limit = read_memory_limit_in_bytes();
496   // Update cached metric to avoid re-reading container settings too often
497   memory_limit-&gt;set_value(mem_limit, OSCONTAINER_CACHE_TIMEOUT);
498   return mem_limit;
499 }
    </pre>
  </body>
</html>