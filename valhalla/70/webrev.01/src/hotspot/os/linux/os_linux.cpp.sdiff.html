<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/os/linux/os_linux.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="gc/z/zPhysicalMemoryBacking_linux.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="os_linux.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/os/linux/os_linux.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 137   FILE_BACKED_PVT_BIT = 1 &lt;&lt; 2,
 138   FILE_BACKED_SHARED_BIT = 1 &lt;&lt; 3,
 139   LARGEPAGES_BIT = 1 &lt;&lt; 6,
 140   DAX_SHARED_BIT = 1 &lt;&lt; 8
 141 };
 142 
 143 ////////////////////////////////////////////////////////////////////////////////
 144 // global variables
 145 julong os::Linux::_physical_memory = 0;
 146 
 147 address   os::Linux::_initial_thread_stack_bottom = NULL;
 148 uintptr_t os::Linux::_initial_thread_stack_size   = 0;
 149 
 150 int (*os::Linux::_pthread_getcpuclockid)(pthread_t, clockid_t *) = NULL;
 151 int (*os::Linux::_pthread_setname_np)(pthread_t, const char*) = NULL;
 152 pthread_t os::Linux::_main_thread;
 153 int os::Linux::_page_size = -1;
 154 bool os::Linux::_supports_fast_thread_cpu_time = false;
 155 const char * os::Linux::_glibc_version = NULL;
 156 const char * os::Linux::_libpthread_version = NULL;

 157 
 158 static jlong initial_time_count=0;
 159 
 160 static int clock_tics_per_sec = 100;
 161 
 162 // If the VM might have been created on the primordial thread, we need to resolve the
 163 // primordial thread stack bounds and check if the current thread might be the
 164 // primordial thread in places. If we know that the primordial thread is never used,
 165 // such as when the VM was created by one of the standard java launchers, we can
 166 // avoid this
 167 static bool suppress_primordial_thread_resolution = false;
 168 
 169 // For diagnostics to print a message once. see run_periodic_checks
 170 static sigset_t check_signal_done;
 171 static bool check_signals = true;
 172 
 173 // Signal number used to suspend/resume a thread
 174 
 175 // do not use any signal number less than SIGSEGV, see 4355769
 176 static int SR_signum = SIGUSR2;
</pre>
<hr />
<pre>
2959 bool os::pd_commit_memory(char* addr, size_t size, bool exec) {
2960   return os::Linux::commit_memory_impl(addr, size, exec) == 0;
2961 }
2962 
2963 void os::pd_commit_memory_or_exit(char* addr, size_t size, bool exec,
2964                                   const char* mesg) {
2965   assert(mesg != NULL, &quot;mesg must be specified&quot;);
2966   int err = os::Linux::commit_memory_impl(addr, size, exec);
2967   if (err != 0) {
2968     // the caller wants all commit errors to exit with the specified mesg:
2969     warn_fail_commit_memory(addr, size, exec, err);
2970     vm_exit_out_of_memory(size, OOM_MMAP_ERROR, &quot;%s&quot;, mesg);
2971   }
2972 }
2973 
2974 // Define MAP_HUGETLB here so we can build HotSpot on old systems.
2975 #ifndef MAP_HUGETLB
2976   #define MAP_HUGETLB 0x40000
2977 #endif
2978 









2979 // Define MADV_HUGEPAGE here so we can build HotSpot on old systems.
2980 #ifndef MADV_HUGEPAGE
2981   #define MADV_HUGEPAGE 14
2982 #endif
2983 
2984 int os::Linux::commit_memory_impl(char* addr, size_t size,
2985                                   size_t alignment_hint, bool exec) {
2986   int err = os::Linux::commit_memory_impl(addr, size, exec);
2987   if (err == 0) {
2988     realign_memory(addr, size, alignment_hint);
2989   }
2990   return err;
2991 }
2992 
2993 bool os::pd_commit_memory(char* addr, size_t size, size_t alignment_hint,
2994                           bool exec) {
2995   return os::Linux::commit_memory_impl(addr, size, alignment_hint, exec) == 0;
2996 }
2997 
2998 void os::pd_commit_memory_or_exit(char* addr, size_t size,
</pre>
<hr />
<pre>
3741   if (fscanf(f, &quot;%lx&quot;, &amp;cdm) != 1) {
3742     fclose(f);
3743     return;
3744   }
3745 
3746   long saved_cdm = cdm;
3747   rewind(f);
3748   cdm |= bit;
3749 
3750   if (cdm != saved_cdm) {
3751     fprintf(f, &quot;%#lx&quot;, cdm);
3752   }
3753 
3754   fclose(f);
3755 }
3756 
3757 // Large page support
3758 
3759 static size_t _large_page_size = 0;
3760 
<span class="line-modified">3761 size_t os::Linux::find_large_page_size() {</span>



3762   size_t large_page_size = 0;
3763 
3764   // large_page_size on Linux is used to round up heap size. x86 uses either
3765   // 2M or 4M page, depending on whether PAE (Physical Address Extensions)
3766   // mode is enabled. AMD64/EM64T uses 2M page in 64bit mode. IA64 can use
3767   // page as large as 256M.
3768   //
3769   // Here we try to figure out page size by parsing /proc/meminfo and looking
3770   // for a line with the following format:
3771   //    Hugepagesize:     2048 kB
3772   //
3773   // If we can&#39;t determine the value (e.g. /proc is not mounted, or the text
3774   // format has been changed), we&#39;ll use the largest page size supported by
3775   // the processor.
3776 
3777 #ifndef ZERO
3778   large_page_size =
3779     AARCH64_ONLY(2 * M)
3780     AMD64_ONLY(2 * M)
3781     ARM32_ONLY(2 * M)
</pre>
<hr />
<pre>
3789   FILE *fp = fopen(&quot;/proc/meminfo&quot;, &quot;r&quot;);
3790   if (fp) {
3791     while (!feof(fp)) {
3792       int x = 0;
3793       char buf[16];
3794       if (fscanf(fp, &quot;Hugepagesize: %d&quot;, &amp;x) == 1) {
3795         if (x &amp;&amp; fgets(buf, sizeof(buf), fp) &amp;&amp; strcmp(buf, &quot; kB\n&quot;) == 0) {
3796           large_page_size = x * K;
3797           break;
3798         }
3799       } else {
3800         // skip to next line
3801         for (;;) {
3802           int ch = fgetc(fp);
3803           if (ch == EOF || ch == (int)&#39;\n&#39;) break;
3804         }
3805       }
3806     }
3807     fclose(fp);
3808   }


3809 
<span class="line-modified">3810   if (!FLAG_IS_DEFAULT(LargePageSizeInBytes) &amp;&amp; LargePageSizeInBytes != large_page_size) {</span>
<span class="line-modified">3811     warning(&quot;Setting LargePageSizeInBytes has no effect on this OS. Large page size is &quot;</span>
<span class="line-modified">3812             SIZE_FORMAT &quot;%s.&quot;, byte_size_in_proper_unit(large_page_size),</span>
<span class="line-removed">3813             proper_unit_for_byte_size(large_page_size));</span>
3814   }



3815 
<span class="line-modified">3816   return large_page_size;</span>


















3817 }
3818 
3819 size_t os::Linux::setup_large_page_size() {
<span class="line-modified">3820   _large_page_size = Linux::find_large_page_size();</span>













3821   const size_t default_page_size = (size_t)Linux::page_size();
3822   if (_large_page_size &gt; default_page_size) {
3823     _page_sizes[0] = _large_page_size;
3824     _page_sizes[1] = default_page_size;
3825     _page_sizes[2] = 0;
3826   }
3827 
3828   return _large_page_size;
3829 }
3830 




3831 bool os::Linux::setup_large_page_type(size_t page_size) {
3832   if (FLAG_IS_DEFAULT(UseHugeTLBFS) &amp;&amp;
3833       FLAG_IS_DEFAULT(UseSHM) &amp;&amp;
3834       FLAG_IS_DEFAULT(UseTransparentHugePages)) {
3835 
3836     // The type of large pages has not been specified by the user.
3837 
3838     // Try UseHugeTLBFS and then UseSHM.
3839     UseHugeTLBFS = UseSHM = true;
3840 
3841     // Don&#39;t try UseTransparentHugePages since there are known
3842     // performance issues with it turned on. This might change in the future.
3843     UseTransparentHugePages = false;
3844   }
3845 
3846   if (UseTransparentHugePages) {
3847     bool warn_on_failure = !FLAG_IS_DEFAULT(UseTransparentHugePages);
3848     if (transparent_huge_pages_sanity_check(warn_on_failure, page_size)) {
3849       UseHugeTLBFS = false;
3850       UseSHM = false;
</pre>
<hr />
<pre>
4039       (!FLAG_IS_DEFAULT(UseLargePages) ||
4040        !FLAG_IS_DEFAULT(UseHugeTLBFS) ||
4041        !FLAG_IS_DEFAULT(LargePageSizeInBytes));
4042 
4043   if (warn_on_failure) {
4044     char msg[128];
4045     jio_snprintf(msg, sizeof(msg), &quot;Failed to reserve large pages memory req_addr: &quot;
4046                  PTR_FORMAT &quot; bytes: &quot; SIZE_FORMAT &quot; (errno = %d).&quot;, req_addr, bytes, error);
4047     warning(&quot;%s&quot;, msg);
4048   }
4049 }
4050 
4051 char* os::Linux::reserve_memory_special_huge_tlbfs_only(size_t bytes,
4052                                                         char* req_addr,
4053                                                         bool exec) {
4054   assert(UseLargePages &amp;&amp; UseHugeTLBFS, &quot;only for Huge TLBFS large pages&quot;);
4055   assert(is_aligned(bytes, os::large_page_size()), &quot;Unaligned size&quot;);
4056   assert(is_aligned(req_addr, os::large_page_size()), &quot;Unaligned address&quot;);
4057 
4058   int prot = exec ? PROT_READ|PROT_WRITE|PROT_EXEC : PROT_READ|PROT_WRITE;
<span class="line-modified">4059   char* addr = (char*)::mmap(req_addr, bytes, prot,</span>
<span class="line-modified">4060                              MAP_PRIVATE|MAP_ANONYMOUS|MAP_HUGETLB,</span>
<span class="line-modified">4061                              -1, 0);</span>



4062 
4063   if (addr == MAP_FAILED) {
4064     warn_on_large_pages_failure(req_addr, bytes, errno);
4065     return NULL;
4066   }
4067 
4068   assert(is_aligned(addr, os::large_page_size()), &quot;Must be&quot;);
4069 
4070   return addr;
4071 }
4072 
4073 // Reserve memory using mmap(MAP_HUGETLB).
4074 //  - bytes shall be a multiple of alignment.
4075 //  - req_addr can be NULL. If not NULL, it must be a multiple of alignment.
4076 //  - alignment sets the alignment at which memory shall be allocated.
4077 //     It must be a multiple of allocation granularity.
4078 // Returns address of memory or NULL. If req_addr was not NULL, will only return
4079 //  req_addr or NULL.
4080 char* os::Linux::reserve_memory_special_huge_tlbfs_mixed(size_t bytes,
4081                                                          size_t alignment,
</pre>
<hr />
<pre>
4097   assert(is_aligned(start, alignment), &quot;Must be&quot;);
4098 
4099   char* end = start + bytes;
4100 
4101   // Find the regions of the allocated chunk that can be promoted to large pages.
4102   char* lp_start = align_up(start, large_page_size);
4103   char* lp_end   = align_down(end, large_page_size);
4104 
4105   size_t lp_bytes = lp_end - lp_start;
4106 
4107   assert(is_aligned(lp_bytes, large_page_size), &quot;Must be&quot;);
4108 
4109   if (lp_bytes == 0) {
4110     // The mapped region doesn&#39;t even span the start and the end of a large page.
4111     // Fall back to allocate a non-special area.
4112     ::munmap(start, end - start);
4113     return NULL;
4114   }
4115 
4116   int prot = exec ? PROT_READ|PROT_WRITE|PROT_EXEC : PROT_READ|PROT_WRITE;
<span class="line-modified">4117 </span>
4118   void* result;
4119 
4120   // Commit small-paged leading area.
4121   if (start != lp_start) {
<span class="line-modified">4122     result = ::mmap(start, lp_start - start, prot,</span>
<span class="line-removed">4123                     MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED,</span>
<span class="line-removed">4124                     -1, 0);</span>
4125     if (result == MAP_FAILED) {
4126       ::munmap(lp_start, end - lp_start);
4127       return NULL;
4128     }
4129   }
4130 
4131   // Commit large-paged area.
<span class="line-modified">4132   result = ::mmap(lp_start, lp_bytes, prot,</span>
<span class="line-modified">4133                   MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED|MAP_HUGETLB,</span>
<span class="line-modified">4134                   -1, 0);</span>




4135   if (result == MAP_FAILED) {
4136     warn_on_large_pages_failure(lp_start, lp_bytes, errno);
4137     // If the mmap above fails, the large pages region will be unmapped and we
4138     // have regions before and after with small pages. Release these regions.
4139     //
4140     // |  mapped  |  unmapped  |  mapped  |
4141     // ^          ^            ^          ^
4142     // start      lp_start     lp_end     end
4143     //
4144     ::munmap(start, lp_start - start);
4145     ::munmap(lp_end, end - lp_end);
4146     return NULL;
4147   }
4148 
4149   // Commit small-paged trailing area.
4150   if (lp_end != end) {
4151     result = ::mmap(lp_end, end - lp_end, prot,
4152                     MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED,
4153                     -1, 0);
4154     if (result == MAP_FAILED) {
</pre>
</td>
<td>
<hr />
<pre>
 137   FILE_BACKED_PVT_BIT = 1 &lt;&lt; 2,
 138   FILE_BACKED_SHARED_BIT = 1 &lt;&lt; 3,
 139   LARGEPAGES_BIT = 1 &lt;&lt; 6,
 140   DAX_SHARED_BIT = 1 &lt;&lt; 8
 141 };
 142 
 143 ////////////////////////////////////////////////////////////////////////////////
 144 // global variables
 145 julong os::Linux::_physical_memory = 0;
 146 
 147 address   os::Linux::_initial_thread_stack_bottom = NULL;
 148 uintptr_t os::Linux::_initial_thread_stack_size   = 0;
 149 
 150 int (*os::Linux::_pthread_getcpuclockid)(pthread_t, clockid_t *) = NULL;
 151 int (*os::Linux::_pthread_setname_np)(pthread_t, const char*) = NULL;
 152 pthread_t os::Linux::_main_thread;
 153 int os::Linux::_page_size = -1;
 154 bool os::Linux::_supports_fast_thread_cpu_time = false;
 155 const char * os::Linux::_glibc_version = NULL;
 156 const char * os::Linux::_libpthread_version = NULL;
<span class="line-added"> 157 size_t os::Linux::_default_large_page_size = 0;</span>
 158 
 159 static jlong initial_time_count=0;
 160 
 161 static int clock_tics_per_sec = 100;
 162 
 163 // If the VM might have been created on the primordial thread, we need to resolve the
 164 // primordial thread stack bounds and check if the current thread might be the
 165 // primordial thread in places. If we know that the primordial thread is never used,
 166 // such as when the VM was created by one of the standard java launchers, we can
 167 // avoid this
 168 static bool suppress_primordial_thread_resolution = false;
 169 
 170 // For diagnostics to print a message once. see run_periodic_checks
 171 static sigset_t check_signal_done;
 172 static bool check_signals = true;
 173 
 174 // Signal number used to suspend/resume a thread
 175 
 176 // do not use any signal number less than SIGSEGV, see 4355769
 177 static int SR_signum = SIGUSR2;
</pre>
<hr />
<pre>
2960 bool os::pd_commit_memory(char* addr, size_t size, bool exec) {
2961   return os::Linux::commit_memory_impl(addr, size, exec) == 0;
2962 }
2963 
2964 void os::pd_commit_memory_or_exit(char* addr, size_t size, bool exec,
2965                                   const char* mesg) {
2966   assert(mesg != NULL, &quot;mesg must be specified&quot;);
2967   int err = os::Linux::commit_memory_impl(addr, size, exec);
2968   if (err != 0) {
2969     // the caller wants all commit errors to exit with the specified mesg:
2970     warn_fail_commit_memory(addr, size, exec, err);
2971     vm_exit_out_of_memory(size, OOM_MMAP_ERROR, &quot;%s&quot;, mesg);
2972   }
2973 }
2974 
2975 // Define MAP_HUGETLB here so we can build HotSpot on old systems.
2976 #ifndef MAP_HUGETLB
2977   #define MAP_HUGETLB 0x40000
2978 #endif
2979 
<span class="line-added">2980 // If mmap flags are set with MAP_HUGETLB and the system supports multiple</span>
<span class="line-added">2981 // huge page sizes, flag bits [26:31] can be used to encode the log2 of the</span>
<span class="line-added">2982 // desired huge page size. Otherwise, the system&#39;s default huge page size will be used.</span>
<span class="line-added">2983 // See mmap(2) man page for more info (since Linux 3.8).</span>
<span class="line-added">2984 // https://lwn.net/Articles/533499/</span>
<span class="line-added">2985 #ifndef MAP_HUGE_SHIFT</span>
<span class="line-added">2986   #define MAP_HUGE_SHIFT 26</span>
<span class="line-added">2987 #endif</span>
<span class="line-added">2988 </span>
2989 // Define MADV_HUGEPAGE here so we can build HotSpot on old systems.
2990 #ifndef MADV_HUGEPAGE
2991   #define MADV_HUGEPAGE 14
2992 #endif
2993 
2994 int os::Linux::commit_memory_impl(char* addr, size_t size,
2995                                   size_t alignment_hint, bool exec) {
2996   int err = os::Linux::commit_memory_impl(addr, size, exec);
2997   if (err == 0) {
2998     realign_memory(addr, size, alignment_hint);
2999   }
3000   return err;
3001 }
3002 
3003 bool os::pd_commit_memory(char* addr, size_t size, size_t alignment_hint,
3004                           bool exec) {
3005   return os::Linux::commit_memory_impl(addr, size, alignment_hint, exec) == 0;
3006 }
3007 
3008 void os::pd_commit_memory_or_exit(char* addr, size_t size,
</pre>
<hr />
<pre>
3751   if (fscanf(f, &quot;%lx&quot;, &amp;cdm) != 1) {
3752     fclose(f);
3753     return;
3754   }
3755 
3756   long saved_cdm = cdm;
3757   rewind(f);
3758   cdm |= bit;
3759 
3760   if (cdm != saved_cdm) {
3761     fprintf(f, &quot;%#lx&quot;, cdm);
3762   }
3763 
3764   fclose(f);
3765 }
3766 
3767 // Large page support
3768 
3769 static size_t _large_page_size = 0;
3770 
<span class="line-modified">3771 size_t os::Linux::find_default_large_page_size() {</span>
<span class="line-added">3772   if (_default_large_page_size != 0) {</span>
<span class="line-added">3773     return _default_large_page_size;</span>
<span class="line-added">3774   }</span>
3775   size_t large_page_size = 0;
3776 
3777   // large_page_size on Linux is used to round up heap size. x86 uses either
3778   // 2M or 4M page, depending on whether PAE (Physical Address Extensions)
3779   // mode is enabled. AMD64/EM64T uses 2M page in 64bit mode. IA64 can use
3780   // page as large as 256M.
3781   //
3782   // Here we try to figure out page size by parsing /proc/meminfo and looking
3783   // for a line with the following format:
3784   //    Hugepagesize:     2048 kB
3785   //
3786   // If we can&#39;t determine the value (e.g. /proc is not mounted, or the text
3787   // format has been changed), we&#39;ll use the largest page size supported by
3788   // the processor.
3789 
3790 #ifndef ZERO
3791   large_page_size =
3792     AARCH64_ONLY(2 * M)
3793     AMD64_ONLY(2 * M)
3794     ARM32_ONLY(2 * M)
</pre>
<hr />
<pre>
3802   FILE *fp = fopen(&quot;/proc/meminfo&quot;, &quot;r&quot;);
3803   if (fp) {
3804     while (!feof(fp)) {
3805       int x = 0;
3806       char buf[16];
3807       if (fscanf(fp, &quot;Hugepagesize: %d&quot;, &amp;x) == 1) {
3808         if (x &amp;&amp; fgets(buf, sizeof(buf), fp) &amp;&amp; strcmp(buf, &quot; kB\n&quot;) == 0) {
3809           large_page_size = x * K;
3810           break;
3811         }
3812       } else {
3813         // skip to next line
3814         for (;;) {
3815           int ch = fgetc(fp);
3816           if (ch == EOF || ch == (int)&#39;\n&#39;) break;
3817         }
3818       }
3819     }
3820     fclose(fp);
3821   }
<span class="line-added">3822   return large_page_size;</span>
<span class="line-added">3823 }</span>
3824 
<span class="line-modified">3825 size_t os::Linux::find_large_page_size(size_t large_page_size) {</span>
<span class="line-modified">3826   if (_default_large_page_size == 0) {</span>
<span class="line-modified">3827     _default_large_page_size = Linux::find_default_large_page_size();</span>

3828   }
<span class="line-added">3829   // We need to scan /sys/kernel/mm/hugepages</span>
<span class="line-added">3830   // to discover the available page sizes</span>
<span class="line-added">3831   const char* sys_hugepages = &quot;/sys/kernel/mm/hugepages&quot;;</span>
3832 
<span class="line-modified">3833   DIR *dir = opendir(sys_hugepages);</span>
<span class="line-added">3834   if (dir == NULL) {</span>
<span class="line-added">3835     return _default_large_page_size;</span>
<span class="line-added">3836   }</span>
<span class="line-added">3837 </span>
<span class="line-added">3838   struct dirent *entry;</span>
<span class="line-added">3839   size_t page_size;</span>
<span class="line-added">3840   while ((entry = readdir(dir)) != NULL) {</span>
<span class="line-added">3841     if (entry-&gt;d_type == DT_DIR &amp;&amp;</span>
<span class="line-added">3842         sscanf(entry-&gt;d_name, &quot;hugepages-%zukB&quot;, &amp;page_size) == 1) {</span>
<span class="line-added">3843       // The kernel is using kB, hotspot uses bytes</span>
<span class="line-added">3844       if (large_page_size == page_size * K) {</span>
<span class="line-added">3845         closedir(dir);</span>
<span class="line-added">3846         return large_page_size;</span>
<span class="line-added">3847       }</span>
<span class="line-added">3848     }</span>
<span class="line-added">3849   }</span>
<span class="line-added">3850   closedir(dir);</span>
<span class="line-added">3851   return _default_large_page_size;</span>
3852 }
3853 
3854 size_t os::Linux::setup_large_page_size() {
<span class="line-modified">3855   _default_large_page_size = Linux::find_default_large_page_size();</span>
<span class="line-added">3856 </span>
<span class="line-added">3857   if (!FLAG_IS_DEFAULT(LargePageSizeInBytes) &amp;&amp; LargePageSizeInBytes != _default_large_page_size ) {</span>
<span class="line-added">3858     _large_page_size = find_large_page_size(LargePageSizeInBytes);</span>
<span class="line-added">3859     if (_large_page_size == _default_large_page_size) {</span>
<span class="line-added">3860       warning(&quot;Setting LargePageSizeInBytes=&quot; SIZE_FORMAT &quot; has no effect on this OS. Using the default large page size &quot;</span>
<span class="line-added">3861               SIZE_FORMAT &quot;%s.&quot;,</span>
<span class="line-added">3862               LargePageSizeInBytes,</span>
<span class="line-added">3863               byte_size_in_proper_unit(_large_page_size), proper_unit_for_byte_size(_large_page_size));</span>
<span class="line-added">3864     }</span>
<span class="line-added">3865   } else {</span>
<span class="line-added">3866     _large_page_size = _default_large_page_size;</span>
<span class="line-added">3867   }</span>
<span class="line-added">3868 </span>
3869   const size_t default_page_size = (size_t)Linux::page_size();
3870   if (_large_page_size &gt; default_page_size) {
3871     _page_sizes[0] = _large_page_size;
3872     _page_sizes[1] = default_page_size;
3873     _page_sizes[2] = 0;
3874   }
3875 
3876   return _large_page_size;
3877 }
3878 
<span class="line-added">3879 size_t os::Linux::default_large_page_size() {</span>
<span class="line-added">3880   return _default_large_page_size;</span>
<span class="line-added">3881 }</span>
<span class="line-added">3882 </span>
3883 bool os::Linux::setup_large_page_type(size_t page_size) {
3884   if (FLAG_IS_DEFAULT(UseHugeTLBFS) &amp;&amp;
3885       FLAG_IS_DEFAULT(UseSHM) &amp;&amp;
3886       FLAG_IS_DEFAULT(UseTransparentHugePages)) {
3887 
3888     // The type of large pages has not been specified by the user.
3889 
3890     // Try UseHugeTLBFS and then UseSHM.
3891     UseHugeTLBFS = UseSHM = true;
3892 
3893     // Don&#39;t try UseTransparentHugePages since there are known
3894     // performance issues with it turned on. This might change in the future.
3895     UseTransparentHugePages = false;
3896   }
3897 
3898   if (UseTransparentHugePages) {
3899     bool warn_on_failure = !FLAG_IS_DEFAULT(UseTransparentHugePages);
3900     if (transparent_huge_pages_sanity_check(warn_on_failure, page_size)) {
3901       UseHugeTLBFS = false;
3902       UseSHM = false;
</pre>
<hr />
<pre>
4091       (!FLAG_IS_DEFAULT(UseLargePages) ||
4092        !FLAG_IS_DEFAULT(UseHugeTLBFS) ||
4093        !FLAG_IS_DEFAULT(LargePageSizeInBytes));
4094 
4095   if (warn_on_failure) {
4096     char msg[128];
4097     jio_snprintf(msg, sizeof(msg), &quot;Failed to reserve large pages memory req_addr: &quot;
4098                  PTR_FORMAT &quot; bytes: &quot; SIZE_FORMAT &quot; (errno = %d).&quot;, req_addr, bytes, error);
4099     warning(&quot;%s&quot;, msg);
4100   }
4101 }
4102 
4103 char* os::Linux::reserve_memory_special_huge_tlbfs_only(size_t bytes,
4104                                                         char* req_addr,
4105                                                         bool exec) {
4106   assert(UseLargePages &amp;&amp; UseHugeTLBFS, &quot;only for Huge TLBFS large pages&quot;);
4107   assert(is_aligned(bytes, os::large_page_size()), &quot;Unaligned size&quot;);
4108   assert(is_aligned(req_addr, os::large_page_size()), &quot;Unaligned address&quot;);
4109 
4110   int prot = exec ? PROT_READ|PROT_WRITE|PROT_EXEC : PROT_READ|PROT_WRITE;
<span class="line-modified">4111   int flags = MAP_PRIVATE|MAP_ANONYMOUS|MAP_HUGETLB;</span>
<span class="line-modified">4112 </span>
<span class="line-modified">4113   if (os::large_page_size() != default_large_page_size()) {</span>
<span class="line-added">4114     flags |= (exact_log2(os::large_page_size()) &lt;&lt; MAP_HUGE_SHIFT);</span>
<span class="line-added">4115   }</span>
<span class="line-added">4116   char* addr = (char*)::mmap(req_addr, bytes, prot, flags, -1, 0);</span>
4117 
4118   if (addr == MAP_FAILED) {
4119     warn_on_large_pages_failure(req_addr, bytes, errno);
4120     return NULL;
4121   }
4122 
4123   assert(is_aligned(addr, os::large_page_size()), &quot;Must be&quot;);
4124 
4125   return addr;
4126 }
4127 
4128 // Reserve memory using mmap(MAP_HUGETLB).
4129 //  - bytes shall be a multiple of alignment.
4130 //  - req_addr can be NULL. If not NULL, it must be a multiple of alignment.
4131 //  - alignment sets the alignment at which memory shall be allocated.
4132 //     It must be a multiple of allocation granularity.
4133 // Returns address of memory or NULL. If req_addr was not NULL, will only return
4134 //  req_addr or NULL.
4135 char* os::Linux::reserve_memory_special_huge_tlbfs_mixed(size_t bytes,
4136                                                          size_t alignment,
</pre>
<hr />
<pre>
4152   assert(is_aligned(start, alignment), &quot;Must be&quot;);
4153 
4154   char* end = start + bytes;
4155 
4156   // Find the regions of the allocated chunk that can be promoted to large pages.
4157   char* lp_start = align_up(start, large_page_size);
4158   char* lp_end   = align_down(end, large_page_size);
4159 
4160   size_t lp_bytes = lp_end - lp_start;
4161 
4162   assert(is_aligned(lp_bytes, large_page_size), &quot;Must be&quot;);
4163 
4164   if (lp_bytes == 0) {
4165     // The mapped region doesn&#39;t even span the start and the end of a large page.
4166     // Fall back to allocate a non-special area.
4167     ::munmap(start, end - start);
4168     return NULL;
4169   }
4170 
4171   int prot = exec ? PROT_READ|PROT_WRITE|PROT_EXEC : PROT_READ|PROT_WRITE;
<span class="line-modified">4172   int flags = MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED;</span>
4173   void* result;
4174 
4175   // Commit small-paged leading area.
4176   if (start != lp_start) {
<span class="line-modified">4177     result = ::mmap(start, lp_start - start, prot, flags, -1, 0);</span>


4178     if (result == MAP_FAILED) {
4179       ::munmap(lp_start, end - lp_start);
4180       return NULL;
4181     }
4182   }
4183 
4184   // Commit large-paged area.
<span class="line-modified">4185   flags |= MAP_HUGETLB;</span>
<span class="line-modified">4186 </span>
<span class="line-modified">4187   if (os::large_page_size() != default_large_page_size()) {</span>
<span class="line-added">4188     flags |= (exact_log2(os::large_page_size()) &lt;&lt; MAP_HUGE_SHIFT);</span>
<span class="line-added">4189   }</span>
<span class="line-added">4190 </span>
<span class="line-added">4191   result = ::mmap(lp_start, lp_bytes, prot, flags, -1, 0);</span>
4192   if (result == MAP_FAILED) {
4193     warn_on_large_pages_failure(lp_start, lp_bytes, errno);
4194     // If the mmap above fails, the large pages region will be unmapped and we
4195     // have regions before and after with small pages. Release these regions.
4196     //
4197     // |  mapped  |  unmapped  |  mapped  |
4198     // ^          ^            ^          ^
4199     // start      lp_start     lp_end     end
4200     //
4201     ::munmap(start, lp_start - start);
4202     ::munmap(lp_end, end - lp_end);
4203     return NULL;
4204   }
4205 
4206   // Commit small-paged trailing area.
4207   if (lp_end != end) {
4208     result = ::mmap(lp_end, end - lp_end, prot,
4209                     MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED,
4210                     -1, 0);
4211     if (result == MAP_FAILED) {
</pre>
</td>
</tr>
</table>
<center><a href="gc/z/zPhysicalMemoryBacking_linux.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="os_linux.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>